\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{subfigure}
\usepackage{multirow}
\usepackage{hyperref}

<<setup, cache=FALSE,echo=FALSE,message=FALSE,warning=FALSE>>=
require(ggplot2)
require(ggthemes)
plotting <- read.csv("data/helicases.csv")
@
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
% \renewcommand\UrlFont{\color{blue}\rmfamily}

\begin{document}
%
\title{EvoMLP: a framework for evolving multilayer perceptrons}
%
\author{\IEEEauthorblockN{Luis Liñán-Villafranca}
  \IEEEauthorblockA{\textit{RTI} \\
    {\tt luis@rti.com}}
  \and
  \IEEEauthorblockN{Mario Garc\'ia-Valdez}
  \IEEEauthorblockA{\textit{Instituto Tecnol\'ogico de Tijuana} \\
    {\tt mario@tectijuana.edu.mx}}
  \and
  \IEEEauthorblockA{J.J. Merelo, Pedro Castillo-Valdivieso}
  \IEEEauthorblockN{Computer Architecture and Technology\\
    University of Granada, Spain\\
    {\tt {jmerelo|pacv}@ugr.es}}
}
%
\maketitle              % typeset the header of the contribution

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
Designing neural networks for classification or regresion can be
considered a search problem, and, as such, can be approached using
different optimization procedures. As such, there are several design
challenges. The first and more important is to constrain the search
space in such a way that proper solutions can be found in a reasonable
amount of time; the second is to take into account that, depending on
how the optimization procedure is formulated, the fitness score used
for it can have a certain degree of uncertainty. This means that
creating a framework for evolving neural networks for classification
implies taking a series of decisions that range from the purely
technical to the algorithmical at different levels: neural or the
optimization framework chosen. This will be the focus of this paper,
where we will introduce DeepGProp, a framework for genetic
optimization of multilayer perceptrons, that is able to explore the
space of neural nets with different layers and layer size and find
good solutions in a reasonable amount of time. The different design
decisions taken and how they affect the output will be presented and
compared with other state of the art frameworks.

\end{abstract}

\begin{IEEEkeywords}
  Neuroevolution, Python, Backpropagation, multilayer perceptrons,
  software frameworks, MLPs.
\end{IEEEkeywords}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

Applying artificial neural networks (ANN) to the solution of
classification problems requires establishing their structure in
layers and connections between them, the initial parameters (such as
initial weights) and a set of learning constants. This is true for
neural as well as deep learning architectures
\cite{goodfellow,nielsen}, where a design parameter is added: the
number of layers in the architecture as well as its type, every one
with its own set of parameters, like the number of neurons in every
layer.

Using an optimization algorithm to solve at least part of the design problem
is an usual approach to this challenge. Evolutionary neural networks are an efficient way of searching for the
architecture, weights, and other ANN parameters (such as learning
constants). This has been proved
repeatedly for {\em shallow} architectures (with a single hidden
layer) since late in the previous century
\cite{yao1993evolutionary,CastilloNPL,stanley2002evolving}. However, in most cases, design
of the structure and connections between different layers, as
indicated by \cite{miikkulainen2019evolving}, is still mostly done by
hand. This is mainly due to the above mentioned fact that search
spaces are huge, so using rules of thumb (such as the ones mentioned
in \cite{qolomany2017parameters}, or using certain formulas to set the
number of layers) to decide on those parameters,
are a way of fixing part of the search space, letting the deep
learning algorithm to figure out the weights themselves, whose
optimization, in these cases, is able to cover big spans of the search
space.

We can also, however, fix a part of the architecture, by choosing a
multi-layer perceptron trained with back-propagation, whose initial
weights as well as biases evolve using an evolutionary algorithm (EA). This
algorithm was called \emph{G-Prop} (as in \emph{Genetic Back-Propagation})
and was originally presented in \cite{castilloNC,CastilloNPL}. This
method leverages the capabilities of two classes of algorithms: the
ability of EA to find a solution close to the global optimum, and the
ability of the back-propagation algorithm (BP) \cite{Rumelhart86} to tune a solution and
reach the nearest local minimum by means of local search from the
solution found by the EA.

This initial G-Prop algorithm was limited, first, by the fact that
most of it had to be programmed from scratch, since there were few (if
any) off-the-shelf software that could do this kind of task;
additionally, available computational capability limited the size of
the search space; this was further limited by the evolution of only single-layer perceptrons.
% Please check, I had the idea that G-Prop was single-layer perceptrons - M

The aim of this paper is to present an algorithm that searches over, the initial weights, number of
hidden layers and hidden layer sizes of a MLP, based on a EA and
Stochastic Gradient Descent (SGD) \cite{bottou2012stochastic}. This
algorithm has been used for training deep neural nets and other kind
of machine learning algorithms
\cite{bottou2012stochastic,bottou2010large}; however, in this case
%there all intermediate (or hidden) layers have the same structure,
intermediate (or hidden) layers have the same structure,
which is the structure of a multi-layer perceptron, justifying our
% In some pleaces there is multilayer or multi layer, we should be consistent.
% I propose multi-layer, changing all - M
denomination of {\sf EvoMLP} for this specific method.
The use of this kind of {\em training} method does not imply that we
are actually doing deep machine learning at large; however, this (and
other possible methods included in the machine learning framework we
are using) are suitable for deep neural nets,
leaving the possibility of using deep neural nets or any other
deep learning methods open for the future.

In this paper what we will do is to first bring the implementation of
the G-Prop concept to current tools and languages, choosing the best
suited for the purpose. Then we will try and reproduce the results
obtained in those classical papers with the basic configuration, to
later try and go beyond the state of the art established there with
new experiments that will widen the search space by using perceptrons
with several layers.

The remainder of this paper is structured as follows:
section \ref{soa} makes a short overview of the methods to design ANN.
In section \ref{method} it is fully described the proposed model.
Section \ref{sec:res} describes the results obtained,
followed by a brief conclusion in Section \ref{sec:conclus}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{State of the Art}
\label{soa}

% This contains a very good
% review. https://www.sciencedirect.com/science/article/pii/S0925231200003027?casa_token=LZtZakZguVsAAAAA:iQNvGVO5fAQO6ED-pnBhQ5Ab-ZuYP7tIdFcpBurr9hdCzNnQAKwwKUoaY6_fEbiQx5fPiktf
Searching the parameter space of neural networks, including deep
learning algorithms, has been a problem traditionally approached
in a limited number of ways, using {\em incremental algorithms}, which, in
general, will depart from a specific architecture, number of layers
and elements in every layer, and offer a series of heuristic
procedures to add/eliminate layers and/or hidden-layer neurons in
them. This way was, for a certain amount of time, the preferred
one for optimizing the size of the neural net along with its weights, according to classical reviews such
as the one by Alpaydim \cite{Alpaydim}. However and simultaneously, a
series of evolutionary heuristics were starting to be applied for the
same purpose, as revealed by Balakrishnan and Honavar's review
\cite{balakrishnan95:EDNA}. They propose a taxonomy, that classifies evolutionary
design of the architecture of neural nets along three different axes
(plus one for application domain): genotype representation, network
topology, and a third axis that includes basically everything else,
``variables of evolution''. % It seems like variables of evolution is disconnected. 
% I think it requires something like "this is called" or "following a voe appproach"  - M
% Check if this is OK - JJ
This classification was much more comprehensive, and included many more degrees of freedom in evolution than simply adding or eliminating neurons. However, it still left some constraints and probably did not emphasize the parameters that are most likely to have the greater influence in the outcome.

This is why, form our point of view, a more precise classification of evolved neural architectures would include
view: \begin{itemize}
  \item Fixed or variable architecture. Irrespective of the kind of
    data structured used to represent it, what is relevant is if that
    representation allows for a variation of the architectural
    parameters, that is, adding or eliminating new nodes, layers, or
    in general nodes and edges in a graph representation of the
    architecture.
  \item Articulation of the neural learning method. There is a whole
    range of possibilities, from letting the evolutionary process set
    all weights and other parameters, to using learning process just
    to find the success rate, with additional possibilities like
    evaluating success {\em before applying learning} (to take
    advantage of the Baldwin effect \cite{castillo-2006}) to applying
    a few cycles of learning that will become part of the codified
    solution.
  \item How the lack of a "crisp" value for the fitness, is taken into account
    % I think some adjective is missing for the kind of determination
    % The lack of a "crisp"|"optimum"|"hard"|"definite"  determination? - M
    % solved - JJ
    during evolution. Either from the fact that an stochastic algorithm is
    used to train the neural net before evaluating fitness, or the
    fact that the data set (or how it's presented for training) might not be totally fixed but subject to
    randomness, the fitness of a neural net cannot be pinned down to a
    single, crisp, number. This randomness in the fitness can be taken
    into account during the selection phase
    \cite{DBLP:conf/ijcci/MereloLFGCCRMG15}, or not. This is related to 
    having models that can generalize better when classifying unseen data,
    reducing overfitting. 
    % Please check or extend the above sentence - M
    % There is also the problem of overfitting - M
    % It's OK - JJ

\end{itemize}

With these axes in mind, the first one, the variation of architecture, has been the one that has developed the most,  lately evolving towards (almost)
unconstrained evolution using Neuroevolution of Augmenting Topologies (NEAT), as shown in the recent review by
Miikkulainen et al. \cite{miikkulainen2019evolving}. Since this blows
up the search space, these methods need computational resources that are
really off the reach of most labs or individuals. This is the reason why most of the latest publications 
still use a fixed model for the network architecture, for instance SVM
or MLPs, and even, in some cases, fixed number of layers and weights
\cite{ecer2020training}; however, recent papers like the one by
Tajmiri et al. \cite{TAJMIRI2020108997} already use a representation
that is able to accommodate a maximum number of layers, as well as the
number of neurons in every layer. This encoding of
architecture does not have any place for initial weights, which in the
case of G-Prop, were proved to be essential for a good performance,
including the emergence of a Baldwin effect \cite{castillo-2006}
during evolution.

In this paper we will extend the principles of variation of a MLP
architecture through the use of genetic operators as well as
codification of initial weights to a modern, standard based
implementation, that will also be released as free software. We show
how this new {\sf EvoMLP} method works next. This means it will again use the architecture axis of evolution, although constraining it to a particular type of neural nets so that, by constraining search, we shrink the search space and make finding good architectures easier.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Proposed Method}
\label{method}

%The general the algorithm will proceed like the \autoref{alg:ga} shows.

% \begin{algorithm}
%   \caption{Genetic Algorithm loop}\label{alg:ga}
%   \begin{algorithmic}[1]
%     \State \textit{evaluate initial population}
%     \While{\textit{max fit is less than ideal and there are generations left}}
%     \If{\textit{max fit hasn't improved in some generations}}
%     \State \textit{Stop algorithm}
%     \EndIf
%     \State \textit{select the offspring from the best population individuals}
%     \State \textit{apply crossover to the offspring}
%     \State \textit{apply mutations to the offspring}
%     \State \textit{replace the worst population individuals with the modified offspring}
%     \EndWhile
%   \end{algorithmic}
% \end{algorithm}

In this work we will use a canonical evolutionary algorithm, as implemented by DEAP. The key of the adaptation of the algorithm for the neuroevolution task we are doing here is in the different parts used, that extend and enhance those used by the
original G-Prop. % Briefly comment on these enhancements, where are they? - M 
                 % (Update) This is done in some places but maybe you should do another pass to see if there are more 
                 % enhancements - M 

\begin{itemize}

  \item An individual is coded as a list of \emph{Layers}. Each layer is
    composed by a matrix of weights and a list of bias (both Numpy
    \cite{py-numpy} ndarrays) joined together with it's configuration (a
    Python dictionary) in a Python class. One column of the weight matrix
    represents all the connections from the previous layer to the nth neuron.
    All the weights and bias are randomly initialized with a uniform
    distribution between -1.0 and 1.0. A random proportion of all this genes
    and biases are muted for all the individuals each generation.

    From this configuration, when the moment of evaluation comes, we create a
    \emph{Sequential} \cite{keras-sequential}  Keras \cite{keras-nn} model and
    append each \emph{Layer} as a \emph{Dense} \cite{keras-dense} Keras layer.

  \item There are three stop conditions that will finish the execution of the
    genetic algorithm: if we reach the maximum number of generations, if after
    10 generations there was no improvement in the best solution and if we find
    the ideal solution ($0\%$ error, 1 on the hidden-score and 1 on the F2
    score).
    % Justify why after 10 generations, or even better make that a parameter, set in this
    % experiments to 10 - M

  \item For each generation we clone the best half individuals of the current
    population and perform all the evolutionary operations to them. Each
    operation has it own probability to occur chosen when running EvoMLP
    CLI. For the weights/bias mutation, a percentage of each (selected too with
    the CLI parameters) are muted randomly. After that, the worst half is
    replaced by this muted group.

  \item The {\em crossover} function will swap the ``neurons'' together with
    their connections. Main difference with respect to original G-Prop is that,
    in this case, there can be several hidden layers, so the connections might
    be either to output or to another layers. The crossover only occurs when
    the two models selected for it have the same structure (same number of
    layers and neurons per layers).
    
    % For future work: the crossover could select structure of one of the parents or mix-them. - M
    % Question: only the initial weights are evolved? or the search is mixed with BP? 
    % i.e., adjust after a few epochs or update the weight matrix after each fitness eval - M
    % Just the initial weights - JJ
    
  \item There are several kinds of {\em mutation} operators: (initial) weights,
    biases, as well as changing the number of neurons and/or
    layers. For the neuron mutator, one neuron will be added last in the
    randomly selected layer, and it will be eliminated in the same way. Since
    we use fully connected neural networks, it does not really matter where the
    neuron is added or eliminated. The layer add/eliminate mutator is the
    main difference with respect to G-Prop, which used only one
    layer. In this case, only the last hidden layer can be eliminated. When a
    layer is eliminated, the weights from the previous layer to the eliminated
    one are kept, adding randomly generated weights and biases if the output
    layer (newly connected with this previous layer) have more ``neurons'' than
    the recently deleted layer. When adding a new hidden layer, the connections
    between the last hidden layer and the output layer are recycled, and the
    connections between the newly created layer and the output layer are
    calculated randomly (running similar fix as when we delete the layer).

    % What is the activation function for the hidden layers? Is this
    % fixed? - M
    % It's answered below - JJ
\end{itemize}

We need the selection process, via the fitness function, to exert parsimony pressure, which is why
we take into account not only the accuracy score reached after
training, but also the overall size of the network $score = (\sum_{i=0}^{nhl} nu_{i}) \times nhl$ ($nhl$ is the number of hidden layers and $nu_{i}$ the number
of neurons for the layer $i$) and the F2 score metric (explained in the
\autoref{sec:res}). At the end, the fitness value is a compound of
three elements: accuracy, hidden-score and F2 score. As the DEAP framework
\cite{deap-ga} was used as a base to create the genetic algorithm, we also
took advantage of its fitness class \cite{deap-fitness} to rank the individuals
of a population. It performs a lexicographical comparison of the three values,
so we chose the order previously mentioned to approach as much as possible to
the fitness function used by G-Prop.
% Question for @jj related with #28. Do we need the whole expression? I don't
% really know how to create an expression for the fitness score since it is a
% tuple - Luis This is important because is related to many principles of ML
% You just return a single value as a tuple, like this: return fitness,  (notice the comma at the end) - M
%
%
% \begin{figure}
%     \centering
%     \caption{
%         {\sf EvoMLP} NN model score equation.
%     }
%     \label{eq:hidden-score}
%     \begin{equation}
%         
%     \end{equation}
% \end{figure}
%
So in summary, the score will be the
global number of neurons multiplied by the number of hidden layers.
%
The whole code for this has been released under a free license in
GitHub. % Add URL later.

{\sf EvoMLP} has been implemented using the Python programming language. Tests with pypy, an accelerated, just-in-time version of the regular interpreter were tested, but although it is supposed to accelerate most numerical workloads, it actually was almost twice as slow as the one using the regular interpreter. There are
many reasons to use this language, but two of the most significant reasons are
the extensive documentation, use and community it has, and the vast amount of
ML ready frameworks that are developed for it. Keras and DEAP are two impressive
frameworks currently in the state-of-art on their respective area.
% Do we want to talk about technical implementation details as suggested in
% #10? Explaining all the code and that stuff - Luis
% In the abstract the bringing to modern languages and tools is highlighted
% Here could be a good place to present and justify these implementation details - M

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Results}
\label{sec:res}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusions and future work}
\label{sec:conclus}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Acknowledgments}

This paper has been supported in part by project DeepBio (TIN2017-85727-C4-2-P)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{IEEEtran}
\bibliography{geneura,deep-g-prop,gprop,gpropnpl}

\end{document}
