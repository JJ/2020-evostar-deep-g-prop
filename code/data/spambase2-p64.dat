Using Theano backend.
20Nov22_195034|Data summary: Train
20Nov22_195034|data.shape = (2300, 57)
20Nov22_195034|labels.shape = (2300,)
20Nov22_195034|Class distribution:
20Nov22_195034|	0 - 1389 (0.60)
20Nov22_195034|	1 - 911 (0.40)
20Nov22_195034|Data summary: Validation
20Nov22_195034|data.shape = (1150, 57)
20Nov22_195034|labels.shape = (1150,)
20Nov22_195034|Class distribution:
20Nov22_195034|	0 - 667 (0.58)
20Nov22_195034|	1 - 483 (0.42)
20Nov22_195034|Data summary: Test
20Nov22_195034|data.shape = (1151, 57)
20Nov22_195034|labels.shape = (1151,)
20Nov22_195034|Class distribution:
20Nov22_195034|	0 - 732 (0.64)
20Nov22_195034|	1 - 419 (0.36)
20Nov22_195034|Selected configuration values
20Nov22_195034|-- Dataset name: spambase2
20Nov22_195034|-- Initial population size: 64
20Nov22_195034|-- Maximun number of generations: 32
20Nov22_195034|-- Neurons per hidden layer range: (2, 20)
20Nov22_195034|-- Hidden layers number range: (1, 3)
20Nov22_195034|-- Crossover probability: 0.5
20Nov22_195034|-- Bias gene mutation probability: 0.2
20Nov22_195034|-- Weights gene mutation probability: 0.75
20Nov22_195034|-- Neuron mutation probability: 0.3
20Nov22_195034|-- Layer mutation probability: 0.3
20Nov22_195034|-- Constant hidden layers: False
20Nov22_195034|-- Seed: None
20Nov22_195034|Entering GA
20Nov22_195034|Start the algorithm
20Nov22_195401|-- Generation 1 --
20Nov22_195401|    -- Crossed 2 individual pairs.
20Nov22_195401|    -- Mutated 32 individuals.
20Nov22_195709|    -- Evaluated 64 individuals.
20Nov22_195709|    Summary of generation 1:
20Nov22_195709| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_195709|-----------  ------------------  --------------------  ----------
20Nov22_195709|    Max            58.00                124.00          0.78358
20Nov22_195709|    Avg            41.55                26.42           0.04053
20Nov22_195709|    Min            26.61                 2.00           0.00000
20Nov22_195709|    Std             3.69                25.94           0.14842
20Nov22_195709|   Best            26.61                66.00           0.60802
20Nov22_195709|-- Generation 2 --
20Nov22_195709|    -- Crossed 3 individual pairs.
20Nov22_195709|    -- Mutated 32 individuals.
20Nov22_200012|    -- Evaluated 64 individuals.
20Nov22_200012|    Summary of generation 2:
20Nov22_200012| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_200012|-----------  ------------------  --------------------  ----------
20Nov22_200012|    Max            42.61                66.00           0.82208
20Nov22_200012|    Avg            41.22                16.47           0.04757
20Nov22_200012|    Min            26.61                 2.00           0.00000
20Nov22_200012|    Std             2.74                17.13           0.15252
20Nov22_200012|   Best            26.61                33.00           0.57481
20Nov22_200012|-- Generation 3 --
20Nov22_200012|    -- Crossed 2 individual pairs.
20Nov22_200012|    -- Mutated 32 individuals.
20Nov22_200317|    -- Evaluated 64 individuals.
20Nov22_200317|    Summary of generation 3:
20Nov22_200317| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_200317|-----------  ------------------  --------------------  ----------
20Nov22_200317|    Max            42.43                78.00           0.75916
20Nov22_200317|    Avg            41.50                19.28           0.02301
20Nov22_200317|    Min            24.35                 2.00           0.00000
20Nov22_200317|    Std             2.46                18.85           0.10332
20Nov22_200317|   Best            24.35                33.00           0.75916
20Nov22_200317|-- Generation 4 --
20Nov22_200317|    -- Crossed 1 individual pairs.
20Nov22_200317|    -- Mutated 32 individuals.
20Nov22_200621|    -- Evaluated 64 individuals.
20Nov22_200621|    Summary of generation 4:
20Nov22_200621| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_200621|-----------  ------------------  --------------------  ----------
20Nov22_200621|    Max            58.00                81.00           0.80063
20Nov22_200621|    Avg            41.53                18.42           0.04822
20Nov22_200621|    Min            23.13                 2.00           0.00000
20Nov22_200621|    Std             3.74                18.37           0.17456
20Nov22_200621|   Best            23.13                33.00           0.80063
20Nov22_200621|-- Generation 5 --
20Nov22_200621|    -- Crossed 2 individual pairs.
20Nov22_200621|    -- Mutated 32 individuals.
20Nov22_200927|    -- Evaluated 64 individuals.
20Nov22_200927|    Summary of generation 5:
20Nov22_200927| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_200927|-----------  ------------------  --------------------  ----------
20Nov22_200927|    Max            42.35                84.00           0.82328
20Nov22_200927|    Avg            41.18                21.14           0.03726
20Nov22_200927|    Min            23.83                 2.00           0.00000
20Nov22_200927|    Std             3.53                22.67           0.15472
20Nov22_200927|   Best            23.83                33.00           0.82328
20Nov22_200927|-- Generation 6 --
20Nov22_200927|    -- Crossed 2 individual pairs.
20Nov22_200927|    -- Mutated 32 individuals.
20Nov22_201232|    -- Evaluated 64 individuals.
20Nov22_201232|    Summary of generation 6:
20Nov22_201232| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_201232|-----------  ------------------  --------------------  ----------
20Nov22_201232|    Max            42.61                99.00           0.80834
20Nov22_201232|    Avg            41.12                22.58           0.04378
20Nov22_201232|    Min            25.04                 2.00           0.00000
20Nov22_201232|    Std             3.43                25.27           0.16044
20Nov22_201232|   Best            25.04                52.00           0.80834
20Nov22_201232|-- Generation 7 --
20Nov22_201232|    -- Crossed 5 individual pairs.
20Nov22_201232|    -- Mutated 32 individuals.
20Nov22_201534|    -- Evaluated 64 individuals.
20Nov22_201534|    Summary of generation 7:
20Nov22_201534| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_201534|-----------  ------------------  --------------------  ----------
20Nov22_201534|    Max            57.83                64.00           0.82698
20Nov22_201534|    Avg            40.79                16.95           0.07719
20Nov22_201534|    Min            23.91                 2.00           0.00000
20Nov22_201534|    Std             5.00                19.21           0.21926
20Nov22_201534|   Best            23.91                33.00           0.70417
20Nov22_201534|-- Generation 8 --
20Nov22_201534|    -- Crossed 6 individual pairs.
20Nov22_201534|    -- Mutated 32 individuals.
20Nov22_201837|    -- Evaluated 64 individuals.
20Nov22_201837|    Summary of generation 8:
20Nov22_201837| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_201837|-----------  ------------------  --------------------  ----------
20Nov22_201837|    Max            42.17                64.00           0.74239
20Nov22_201837|    Avg            40.87                19.03           0.04927
20Nov22_201837|    Min            24.70                 2.00           0.00000
20Nov22_201837|    Std             3.86                19.95           0.16667
20Nov22_201837|   Best            24.70                52.00           0.74239
20Nov22_201837|-- Generation 9 --
20Nov22_201837|    -- Crossed 3 individual pairs.
20Nov22_201837|    -- Mutated 32 individuals.
20Nov22_202142|    -- Evaluated 64 individuals.
20Nov22_202142|    Summary of generation 9:
20Nov22_202142| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_202142|-----------  ------------------  --------------------  ----------
20Nov22_202142|    Max            58.00                111.00          0.81792
20Nov22_202142|    Avg            40.78                21.00           0.10800
20Nov22_202142|    Min            24.43                 2.00           0.00000
20Nov22_202142|    Std             5.54                23.71           0.25049
20Nov22_202142|   Best            24.43                33.00           0.69340
20Nov22_202142|-- Generation 10 --
20Nov22_202142|    -- Crossed 3 individual pairs.
20Nov22_202142|    -- Mutated 32 individuals.
20Nov22_202445|    -- Evaluated 64 individuals.
20Nov22_202445|    Summary of generation 10:
20Nov22_202445| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_202445|-----------  ------------------  --------------------  ----------
20Nov22_202445|    Max            42.70                105.00          0.82019
20Nov22_202445|    Avg            39.21                19.09           0.12572
20Nov22_202445|    Min            22.17                 2.00           0.00000
20Nov22_202445|    Std             6.09                24.36           0.27022
20Nov22_202445|   Best            22.17                90.00           0.82019
20Nov22_202445|-- Generation 11 --
20Nov22_202445|    -- Crossed 3 individual pairs.
20Nov22_202445|    -- Mutated 32 individuals.
20Nov22_202754|    -- Evaluated 64 individuals.
20Nov22_202754|    Summary of generation 11:
20Nov22_202754| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_202754|-----------  ------------------  --------------------  ----------
20Nov22_202754|    Max            58.00                90.00           0.85546
20Nov22_202754|    Avg            39.07                24.64           0.17545
20Nov22_202754|    Min            24.78                 2.00           0.00000
20Nov22_202754|    Std             6.33                23.77           0.29551
20Nov22_202754|   Best            24.78                56.00           0.85546
20Nov22_202754|-- Generation 12 --
20Nov22_202754|    -- Crossed 1 individual pairs.
20Nov22_202754|    -- Mutated 32 individuals.
20Nov22_203108|    -- Evaluated 64 individuals.
20Nov22_203108|    Summary of generation 12:
20Nov22_203108| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_203108|-----------  ------------------  --------------------  ----------
20Nov22_203108|    Max            42.26                138.00          0.82651
20Nov22_203108|    Avg            38.27                31.53           0.16320
20Nov22_203108|    Min            23.04                 2.00           0.00000
20Nov22_203108|    Std             6.61                30.80           0.28616
20Nov22_203108|   Best            23.04                52.00           0.72641
20Nov22_203108|-- Generation 13 --
20Nov22_203108|    -- Crossed 1 individual pairs.
20Nov22_203108|    -- Mutated 32 individuals.
20Nov22_203419|    -- Evaluated 64 individuals.
20Nov22_203419|    Summary of generation 13:
20Nov22_203419| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_203419|-----------  ------------------  --------------------  ----------
20Nov22_203419|    Max            42.26                126.00          0.76878
20Nov22_203419|    Avg            38.00                29.11           0.16877
20Nov22_203419|    Min            24.35                 2.00           0.00000
20Nov22_203419|    Std             6.67                27.13           0.28315
20Nov22_203419|   Best            24.35                52.00           0.73643
20Nov22_203419|-- Generation 14 --
20Nov22_203419|    -- Crossed 4 individual pairs.
20Nov22_203419|    -- Mutated 32 individuals.
20Nov22_203732|    -- Evaluated 64 individuals.
20Nov22_203732|    Summary of generation 14:
20Nov22_203732| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_203732|-----------  ------------------  --------------------  ----------
20Nov22_203732|    Max            42.35                90.00           0.84287
20Nov22_203732|    Avg            37.64                29.36           0.21301
20Nov22_203732|    Min            24.26                 2.00           0.00000
20Nov22_203732|    Std             6.45                23.86           0.31605
20Nov22_203732|   Best            24.26                56.00           0.70150
20Nov22_203732|-- Generation 15 --
20Nov22_203732|    -- Crossed 1 individual pairs.
20Nov22_203732|    -- Mutated 32 individuals.
20Nov22_204052|    -- Evaluated 64 individuals.
20Nov22_204052|    Summary of generation 15:
20Nov22_204052| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_204052|-----------  ------------------  --------------------  ----------
20Nov22_204052|    Max            49.39                95.00           0.82430
20Nov22_204052|    Avg            36.41                38.22           0.26827
20Nov22_204052|    Min            24.09                 4.00           0.00000
20Nov22_204052|    Std             7.47                23.60           0.33418
20Nov22_204052|   Best            24.09                52.00           0.72428
20Nov22_204052|-- Generation 16 --
20Nov22_204052|    -- Crossed 1 individual pairs.
20Nov22_204052|    -- Mutated 32 individuals.
20Nov22_204417|    -- Evaluated 64 individuals.
20Nov22_204417|    Summary of generation 16:
20Nov22_204417| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_204417|-----------  ------------------  --------------------  ----------
20Nov22_204417|    Max            42.26                95.00           0.82614
20Nov22_204417|    Avg            35.76                46.09           0.28625
20Nov22_204417|    Min            24.09                 4.00           0.00000
20Nov22_204417|    Std             7.14                25.21           0.32782
20Nov22_204417|   Best            24.09                95.00           0.70806
20Nov22_204417|-- Generation 17 --
20Nov22_204417|    -- Crossed 1 individual pairs.
20Nov22_204417|    -- Mutated 32 individuals.
20Nov22_204750|    -- Evaluated 64 individuals.
20Nov22_204750|    Summary of generation 17:
20Nov22_204750| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_204750|-----------  ------------------  --------------------  ----------
20Nov22_204750|    Max            45.13                95.00           0.81625
20Nov22_204750|    Avg            32.98                57.00           0.43840
20Nov22_204750|    Min            23.04                 4.00           0.00000
20Nov22_204750|    Std             7.14                20.59           0.32663
20Nov22_204750|   Best            23.04                52.00           0.76237
20Nov22_204750|-- Generation 18 --
20Nov22_204750|    -- Crossed 0 individual pairs.
20Nov22_204750|    -- Mutated 32 individuals.
20Nov22_205124|    -- Evaluated 64 individuals.
20Nov22_205124|    Summary of generation 18:
20Nov22_205124| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_205124|-----------  ------------------  --------------------  ----------
20Nov22_205124|    Max            42.17                138.00          0.84778
20Nov22_205124|    Avg            32.76                61.17           0.43224
20Nov22_205124|    Min            24.43                12.00           0.00000
20Nov22_205124|    Std             6.93                21.05           0.32383
20Nov22_205124|   Best            24.43                56.00           0.67818
20Nov22_205124|-- Generation 19 --
20Nov22_205124|    -- Crossed 1 individual pairs.
20Nov22_205124|    -- Mutated 32 individuals.
20Nov22_205459|    -- Evaluated 64 individuals.
20Nov22_205459|    Summary of generation 19:
20Nov22_205459| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_205459|-----------  ------------------  --------------------  ----------
20Nov22_205459|    Max            54.52                138.00          0.79389
20Nov22_205459|    Avg            35.52                59.73           0.30489
20Nov22_205459|    Min            24.00                33.00           0.00000
20Nov22_205459|    Std             7.80                19.54           0.32606
20Nov22_205459|   Best            24.00                56.00           0.71429
20Nov22_205459|-- Generation 20 --
20Nov22_205459|    -- Crossed 2 individual pairs.
20Nov22_205459|    -- Mutated 32 individuals.
20Nov22_205833|    -- Evaluated 64 individuals.
20Nov22_205833|    Summary of generation 20:
20Nov22_205833| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_205833|-----------  ------------------  --------------------  ----------
20Nov22_205833|    Max            54.17                120.00          0.82461
20Nov22_205833|    Avg            32.97                58.53           0.42389
20Nov22_205833|    Min            24.87                14.00           0.00000
20Nov22_205833|    Std             7.52                16.27           0.32909
20Nov22_205833|   Best            24.87                60.00           0.72015
20Nov22_205833|-- Generation 21 --
20Nov22_205833|    -- Crossed 1 individual pairs.
20Nov22_205833|    -- Mutated 32 individuals.
20Nov22_210208|    -- Evaluated 64 individuals.
20Nov22_210208|    Summary of generation 21:
20Nov22_210208| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_210208|-----------  ------------------  --------------------  ----------
20Nov22_210208|    Max            42.78                100.00          0.80818
20Nov22_210208|    Avg            32.85                56.98           0.39913
20Nov22_210208|    Min            23.13                33.00           0.00000
20Nov22_210208|    Std             7.33                12.05           0.31630
20Nov22_210208|   Best            23.13                52.00           0.73632
20Nov22_210208|-- Generation 22 --
20Nov22_210208|    -- Crossed 0 individual pairs.
20Nov22_210208|    -- Mutated 32 individuals.
20Nov22_210543|    -- Evaluated 64 individuals.
20Nov22_210543|    Summary of generation 22:
20Nov22_210543| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_210543|-----------  ------------------  --------------------  ----------
20Nov22_210543|    Max            42.00                95.00           0.82583
20Nov22_210543|    Avg            34.24                61.48           0.36436
20Nov22_210543|    Min            24.17                30.00           0.00000
20Nov22_210543|    Std             7.14                16.20           0.33875
20Nov22_210543|   Best            24.17                56.00           0.67750
20Nov22_210543|-- Generation 23 --
20Nov22_210543|    -- Crossed 1 individual pairs.
20Nov22_210543|    -- Mutated 32 individuals.
20Nov22_210919|    -- Evaluated 64 individuals.
20Nov22_210919|    Summary of generation 23:
20Nov22_210919| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_210919|-----------  ------------------  --------------------  ----------
20Nov22_210919|    Max            42.09                120.00          0.87949
20Nov22_210919|    Avg            34.02                62.06           0.37869
20Nov22_210919|    Min            18.52                33.00           0.00000
20Nov22_210919|    Std             7.36                15.64           0.34588
20Nov22_210919|   Best            18.52                39.00           0.87949
20Nov22_210919|-- Generation 24 --
20Nov22_210919|    -- Crossed 1 individual pairs.
20Nov22_210919|    -- Mutated 32 individuals.
20Nov22_211256|    -- Evaluated 64 individuals.
20Nov22_211256|    Summary of generation 24:
20Nov22_211256| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_211256|-----------  ------------------  --------------------  ----------
20Nov22_211256|    Max            42.17                95.00           0.81427
20Nov22_211256|    Avg            32.77                63.11           0.42717
20Nov22_211256|    Min            23.65                33.00           0.00000
20Nov22_211256|    Std             7.33                15.21           0.33745
20Nov22_211256|   Best            23.65                75.00           0.79334
20Nov22_211256|-- Generation 25 --
20Nov22_211256|    -- Crossed 0 individual pairs.
20Nov22_211256|    -- Mutated 32 individuals.
20Nov22_211631|    -- Evaluated 64 individuals.
20Nov22_211631|    Summary of generation 25:
20Nov22_211631| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_211631|-----------  ------------------  --------------------  ----------
20Nov22_211631|    Max            42.35                132.00          0.81029
20Nov22_211631|    Avg            33.06                63.31           0.42540
20Nov22_211631|    Min            24.26                14.00           0.00000
20Nov22_211631|    Std             7.09                21.17           0.33726
20Nov22_211631|   Best            24.26                39.00           0.72951
20Nov22_211631|-- Generation 26 --
20Nov22_211631|    -- Crossed 0 individual pairs.
20Nov22_211631|    -- Mutated 32 individuals.
20Nov22_212010|    -- Evaluated 64 individuals.
20Nov22_212010|    Summary of generation 26:
20Nov22_212010| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_212010|-----------  ------------------  --------------------  ----------
20Nov22_212010|    Max            42.00                132.00          0.82152
20Nov22_212010|    Avg            31.82                66.56           0.47022
20Nov22_212010|    Min            23.91                30.00           0.00000
20Nov22_212010|    Std             6.91                18.83           0.31874
20Nov22_212010|   Best            23.91                60.00           0.71754
20Nov22_212010|-- Generation 27 --
20Nov22_212010|    -- Crossed 0 individual pairs.
20Nov22_212010|    -- Mutated 32 individuals.
20Nov22_212349|    -- Evaluated 64 individuals.
20Nov22_212349|    Summary of generation 27:
20Nov22_212349| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_212349|-----------  ------------------  --------------------  ----------
20Nov22_212349|    Max            42.00                150.00          0.81465
20Nov22_212349|    Avg            31.96                67.70           0.46366
20Nov22_212349|    Min            24.09                30.00           0.00000
20Nov22_212349|    Std             7.18                22.64           0.33089
20Nov22_212349|   Best            24.09                39.00           0.69908
20Nov22_212349|-- Generation 28 --
20Nov22_212349|    -- Crossed 0 individual pairs.
20Nov22_212349|    -- Mutated 32 individuals.
20Nov22_212730|    -- Evaluated 64 individuals.
20Nov22_212730|    Summary of generation 28:
20Nov22_212730| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_212730|-----------  ------------------  --------------------  ----------
20Nov22_212730|    Max            42.00                150.00          0.80361
20Nov22_212730|    Avg            32.73                73.00           0.41362
20Nov22_212730|    Min            23.39                30.00           0.00000
20Nov22_212730|    Std             7.50                21.99           0.33239
20Nov22_212730|   Best            23.39                85.00           0.71191
20Nov22_212730|-- Generation 29 --
20Nov22_212730|    -- Crossed 2 individual pairs.
20Nov22_212730|    -- Mutated 32 individuals.
20Nov22_213111|    -- Evaluated 64 individuals.
20Nov22_213111|    Summary of generation 29:
20Nov22_213111| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_213111|-----------  ------------------  --------------------  ----------
20Nov22_213111|    Max            42.17                150.00          0.84416
20Nov22_213111|    Avg            33.77                72.53           0.37797
20Nov22_213111|    Min            23.74                16.00           0.00000
20Nov22_213111|    Std             7.21                23.50           0.33145
20Nov22_213111|   Best            23.74                85.00           0.81309
20Nov22_213111|-- Generation 30 --
20Nov22_213112|    -- Crossed 0 individual pairs.
20Nov22_213112|    -- Mutated 32 individuals.
20Nov22_213458|    -- Evaluated 64 individuals.
20Nov22_213458|    Summary of generation 30:
20Nov22_213458| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_213458|-----------  ------------------  --------------------  ----------
20Nov22_213458|    Max            43.04                144.00          0.81060
20Nov22_213458|    Avg            32.98                79.91           0.40522
20Nov22_213458|    Min            22.61                36.00           0.00000
20Nov22_213458|    Std             7.33                26.15           0.31640
20Nov22_213458|   Best            22.61                114.00          0.81060
20Nov22_213458|-- Generation 31 --
20Nov22_213458|    -- Crossed 0 individual pairs.
20Nov22_213458|    -- Mutated 32 individuals.
20Nov22_213846|    -- Evaluated 64 individuals.
20Nov22_213846|    Summary of generation 31:
20Nov22_213846| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_213846|-----------  ------------------  --------------------  ----------
20Nov22_213846|    Max            42.35                175.00          0.81669
20Nov22_213846|    Avg            32.81                82.69           0.40956
20Nov22_213846|    Min            22.43                33.00           0.00000
20Nov22_213846|    Std             7.31                30.27           0.32188
20Nov22_213846|   Best            22.43                85.00           0.73730
20Nov22_213846|-- Generation 32 --
20Nov22_213846|    -- Crossed 0 individual pairs.
20Nov22_213846|    -- Mutated 32 individuals.
20Nov22_214233|    -- Evaluated 64 individuals.
20Nov22_214233|    Summary of generation 32:
20Nov22_214233| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_214233|-----------  ------------------  --------------------  ----------
20Nov22_214233|    Max            42.43                175.00          0.83113
20Nov22_214233|    Avg            32.12                82.78           0.44512
20Nov22_214233|    Min            23.22                33.00           0.00000
20Nov22_214233|    Std             6.73                35.11           0.30881
20Nov22_214233|   Best            23.22                154.00          0.74180
20Nov22_214233|Best initial individual weights
20Nov22_214233|Individual:
20Nov22_214233|-- Constant hidden layers --
20Nov22_214233|False
20Nov22_214233|Layer 0:
20Nov22_214233|-- Config --
20Nov22_214233|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 15, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214233|-- Weights --
20Nov22_214233|[[-0.25528 -0.86168 -0.73117  0.56223  0.56855  0.94025  0.93797  0.49055
20Nov22_214233|  -0.90216  0.19223 -0.91984 -0.74397 -0.51846 -0.18231 -0.60867]
20Nov22_214233| [ 0.50578 -0.50923 -0.94377 -0.72305 -0.56292 -0.93770 -0.30061 -0.86737
20Nov22_214233|   0.57409  0.73258 -0.49375 -0.88849 -0.61157 -0.09287 -0.03674]
20Nov22_214233| [-0.04697 -0.86169 -0.66510  0.51919  0.97861 -0.54500  0.04261 -0.50539
20Nov22_214233|  -0.80249 -0.42046  0.55741 -0.35765  0.46503  0.41893 -0.48163]
20Nov22_214233| [-0.42833  0.68633  0.11357 -0.29188 -0.27412 -0.20446  0.94137 -0.74845
20Nov22_214233|  -0.21926  0.83029  0.96071  0.24540 -0.93159 -0.53525 -0.96481]
20Nov22_214233| [-0.36714  0.20289 -0.65378  0.97892 -0.84657  0.13932  0.81899 -0.91302
20Nov22_214233|   0.55350  0.64454  0.18329  0.07608  0.39424 -0.95638 -0.26210]
20Nov22_214233| [ 0.38086  0.95175  0.66274  0.82445 -0.57538 -0.01072 -0.42977 -0.63410
20Nov22_214233|  -0.67945  0.38622 -0.19651  0.29771  0.92115  0.86904 -0.91871]
20Nov22_214233| [-0.05142  0.05042  0.38822 -0.39274 -0.43094  0.97907 -0.12815 -0.33304
20Nov22_214233|  -0.72191 -0.37402 -0.86270 -0.01070  0.47804 -0.99314 -0.03874]
20Nov22_214233| [ 0.46707 -0.23772 -0.70722  0.34484 -0.02418 -0.95684 -0.71204 -0.32872
20Nov22_214233|  -0.19540 -0.73903  0.98928  0.83833 -0.99195  0.17213 -0.26824]
20Nov22_214233| [ 0.67862 -0.80453  0.56243 -0.47698  0.49470  0.10995  0.46268 -0.22827
20Nov22_214233|  -0.62617 -0.80346  0.21285  0.46727  0.96051  0.35853 -0.84320]
20Nov22_214233| [ 0.83088 -0.73974  0.30180 -0.64713 -0.67998 -0.15920 -0.67298  0.25497
20Nov22_214233|  -0.40351  0.50747 -0.14152 -0.76442 -0.82399 -0.21962  0.85486]
20Nov22_214233| [ 0.10866 -0.78608 -0.80147  0.90654  0.83233 -0.25757  0.98192  0.62628
20Nov22_214233|  -0.34795  0.73446 -0.38435 -0.80147 -0.99649 -0.42833 -0.12764]
20Nov22_214233| [-0.37281  0.09854 -0.06629 -0.93249 -0.33363  0.03172 -0.69109  0.86287
20Nov22_214233|  -0.69179 -0.28925 -0.44682 -0.04086  0.88393 -0.50432 -0.59179]
20Nov22_214233| [ 0.97059  0.13703  0.58870 -0.23169  0.14577 -0.26610 -0.40338  0.15041
20Nov22_214233|   0.33803 -0.81401  0.99812  0.45870 -0.75315  0.08146 -0.77282]
20Nov22_214233| [-0.47045  0.22080  0.95047 -0.34408 -0.36988  0.02140  0.29274 -0.65909
20Nov22_214233|  -0.03137 -0.44927 -0.81761 -0.49586  0.52815  0.85876 -0.92699]
20Nov22_214233| [ 0.75095 -0.84954  0.24082 -0.79991 -0.75271 -0.52342  0.19803  0.40699
20Nov22_214233|   0.67575 -0.62505 -0.23699  0.97835  0.81295  0.42590 -0.64698]
20Nov22_214233| [-0.69631  0.48962 -0.03261 -0.01758 -0.96069  0.82345  0.40701  0.84969
20Nov22_214233|  -0.70733  0.10167  0.08333 -0.84806 -0.94424  0.76303 -0.57600]
20Nov22_214233| [ 0.54259  0.51520  0.88914  0.72926  0.46631  0.25074 -0.46277  0.64012
20Nov22_214233|  -0.13684 -0.30340  0.61018  0.57459 -0.12004 -0.75819  0.26240]
20Nov22_214233| [ 0.40758 -0.76822  0.32375  0.10215 -0.62882 -0.40732 -0.15432 -0.34543
20Nov22_214233|   0.00659 -0.59950  0.88440 -0.45416  0.98057  0.66633  0.40365]
20Nov22_214233| [ 0.62754 -0.13880  0.78286  0.92155 -0.63367  0.64121 -0.05549  0.81700
20Nov22_214233|  -0.44945  0.81525  0.23126 -0.47160 -0.43072  0.17013  0.50056]
20Nov22_214233| [-0.26063 -0.47099  0.08874  0.41621 -0.90871 -0.17093  0.51210  0.46313
20Nov22_214233|   0.63087 -0.24117 -0.20878 -0.84172 -0.46945  0.84331  0.08309]
20Nov22_214233| [ 0.56992  0.95769 -0.97051 -0.12914 -0.16450  0.78254 -0.33939  0.65954
20Nov22_214233|  -0.60070  0.87347 -0.04910  0.27256  0.47365 -0.16870 -0.32949]
20Nov22_214233| [ 0.65843  0.91399 -0.90432  0.08243 -0.72142  0.39751  0.94974 -0.75912
20Nov22_214233|  -0.56385 -0.28439 -0.84380 -0.57832 -0.68581  0.50422 -0.85811]
20Nov22_214233| [ 0.75654  0.38758  0.31666 -0.48669 -0.65603  0.20891  0.74480 -0.63032
20Nov22_214233|   0.51549 -0.08188  0.44961  0.77567  0.44328 -0.21268 -0.02859]
20Nov22_214233| [ 0.80496 -0.68062  0.19194  0.81473  0.80033  0.89095  0.23118 -0.55396
20Nov22_214233|   0.10402 -0.14863  0.77179  0.61241  0.45206  0.33663  0.44476]
20Nov22_214233| [ 0.82133  0.82925 -0.82595 -0.25258  0.97972 -0.15754 -0.76055  0.46734
20Nov22_214233|   0.03414  0.12085 -0.96031 -0.90735  0.34680 -0.42507 -0.44590]
20Nov22_214233| [-0.71730  0.16937 -0.32200  0.94734 -0.87042  0.01991  0.31635  0.34620
20Nov22_214233|   0.35583 -0.39856 -0.15989  0.21929  0.26867  0.50076  0.83809]
20Nov22_214233| [-0.80164 -0.90515  0.90248  0.31751  0.70877 -0.44576  0.28495 -0.15415
20Nov22_214233|  -0.30485 -0.19304  0.45472  0.59686  0.82461  0.94342 -0.45996]
20Nov22_214233| [ 0.92185  0.36646 -0.11871  0.87619 -0.14443  0.45672 -0.20549 -0.40209
20Nov22_214233|   0.27184  0.65835  0.33882  0.89114  0.50982  0.60342  0.14053]
20Nov22_214233| [ 0.53904  0.03759 -0.29857  0.05105  0.82281 -0.92212 -0.83573 -0.44376
20Nov22_214233|  -0.29722  0.35726 -0.39694 -0.62377 -0.73706  0.15016  0.98328]
20Nov22_214233| [ 0.21108  0.83607  0.52553  0.76113 -0.38090 -0.01337  0.02805  0.90761
20Nov22_214233|  -0.02436  0.62532  0.02420  0.24843 -0.36179 -0.57009  0.78067]
20Nov22_214233| [ 0.73193 -0.71976  0.21545  0.49326  0.77107 -0.37230 -0.27500 -0.96684
20Nov22_214233|   0.35978 -0.48364 -0.64671  0.93392  0.94178  0.58925  0.06601]
20Nov22_214233| [ 0.58215 -0.14945  0.33250  0.69876  0.76504  0.08120  0.23597  0.26515
20Nov22_214233|  -0.96626  0.72418  0.65069  0.17770 -0.90302 -0.90198 -0.99474]
20Nov22_214233| [ 0.48196 -0.03526 -0.57975 -0.49826  0.14527  0.87174 -0.17142 -0.19184
20Nov22_214233|   0.18677 -0.73357  0.66604  0.40962  0.79066 -0.91123 -0.08770]
20Nov22_214233| [-0.55897 -0.55460  0.17594 -0.10695 -0.33731 -0.23169 -0.22361  0.55619
20Nov22_214233|   0.42744  0.48512 -0.26633  0.54867 -0.91251 -0.46849 -0.20017]
20Nov22_214233| [-0.70082 -0.69892  0.66301  0.89161  0.82524 -0.63924  0.27680  0.96511
20Nov22_214233|  -0.36919  0.93068 -0.36496 -0.56311  0.08299 -0.97485  0.48557]
20Nov22_214233| [-0.54544  0.52546  0.83755  0.50036 -0.06373 -0.43687 -0.49110  0.49656
20Nov22_214233|   0.80015 -0.39337  0.50445  0.48115  0.04905 -0.44084 -0.33075]
20Nov22_214233| [ 0.74057 -0.17476 -0.05486  0.10390 -0.42969 -0.08157  0.34570  0.73771
20Nov22_214233|  -0.55786  0.82303 -0.36847 -0.87001  0.76666 -0.22447  0.95686]
20Nov22_214233| [-0.52505 -0.13595 -0.80117 -0.83470  0.32233 -0.67474 -0.00897  0.10351
20Nov22_214233|  -0.12479  0.50632 -0.99999  0.36003  0.82524 -0.52769 -0.83257]
20Nov22_214233| [ 0.00449  0.84133 -0.72034 -0.26296  0.26762  0.23828  0.32137 -0.69144
20Nov22_214233|  -0.54461  0.23034  0.29019 -0.84536 -0.16829  0.72921 -0.02846]
20Nov22_214233| [ 0.31722 -0.02706  0.23136 -0.52811  0.47838 -0.27233  0.43661  0.03407
20Nov22_214233|  -0.35950 -0.04719 -0.84640  0.21635 -0.95339 -0.85516 -0.40972]
20Nov22_214233| [ 0.19059  0.97824  0.66512  0.21959 -0.77879 -0.08724 -0.03319 -0.71024
20Nov22_214233|   0.46778  0.11691 -0.51719 -0.31140  0.67089  0.53488 -0.95100]
20Nov22_214233| [-0.77213 -0.17649  0.11663  0.93437 -0.82593 -0.63432  0.96735  0.50678
20Nov22_214233|  -0.12845 -0.75842  0.71821 -0.10117 -0.16527 -0.54207 -0.13874]
20Nov22_214233| [ 0.10510 -0.47721 -0.98571 -0.46882 -0.28381 -0.47486 -0.48022  0.07634
20Nov22_214233|  -0.55948 -0.32993 -0.20564 -0.61937 -0.42550 -0.81213 -0.81605]
20Nov22_214233| [ 0.82003  0.78769  0.06858  0.47315 -0.56240  0.78500 -0.62950 -0.16376
20Nov22_214233|  -0.85765  0.11734 -0.49136 -0.44232 -0.78892 -0.02030 -0.70383]
20Nov22_214233| [-0.22423 -0.33869 -0.72198 -0.71321 -0.67712  0.93863 -0.41482  0.72283
20Nov22_214233|  -0.73251 -0.58972 -0.08933 -0.35224 -0.56245  0.70387 -0.88189]
20Nov22_214233| [ 0.62234  0.33893 -0.39173  0.79336  0.69885 -0.15310 -0.93369 -0.68767
20Nov22_214233|   0.86429  0.83620  0.07399  0.70964  0.98437 -0.16699  0.19590]
20Nov22_214233| [ 0.72286  0.43810 -0.44644 -0.46347  0.66887 -0.58986 -0.65731 -0.20425
20Nov22_214233|  -0.37348 -0.85897  0.90296  0.53514  0.83730 -0.41357  0.08818]
20Nov22_214233| [-0.51397 -0.61061  0.72857  0.60873  0.33204 -0.29632 -0.81081 -0.90759
20Nov22_214233|   0.25409  0.72113 -0.78702 -0.00949 -0.07413  0.06141 -0.99497]
20Nov22_214233| [-0.54149 -0.06883  0.64674  0.92962 -0.08144  0.60860 -0.40811  0.08392
20Nov22_214233|   0.61544  0.39186 -0.36984  0.60286 -0.82895 -0.49025  0.17372]
20Nov22_214233| [-0.94619  0.81976  0.31280 -0.76935 -0.22455 -0.91118  0.16274 -0.08054
20Nov22_214233|  -0.29229  0.28102 -0.54467 -0.70692 -0.85287  0.38024 -0.34606]
20Nov22_214233| [-0.05094  0.99103  0.02395 -0.94034  0.52339  0.35957 -0.23906 -0.65827
20Nov22_214233|   0.59204 -0.69331  0.61764  0.77975  0.54495 -0.13071 -0.27798]
20Nov22_214233| [-0.21478 -0.47432 -0.96196  0.14106 -0.19486 -0.42166  0.52590  0.80723
20Nov22_214233|  -0.52059  0.45126  0.78556  0.47857 -0.23233 -0.21847 -0.41500]
20Nov22_214233| [-0.56195  0.78353  0.61243  0.53338 -0.13392  0.60135  0.97074 -0.66821
20Nov22_214233|   0.63799  0.34036  0.30257  0.95876  0.59751 -0.99486 -0.62921]
20Nov22_214233| [-0.63372  0.27621  0.05858 -0.36500 -0.09386  0.52690 -0.98451 -0.83009
20Nov22_214233|   0.79636 -0.50349 -0.04766  0.70510 -0.22832 -0.70876 -0.47922]
20Nov22_214233| [-0.20758 -0.01528 -0.60111  0.04991 -0.35875 -0.86345 -0.06337  0.08637
20Nov22_214233|   0.63792 -0.83232 -0.34063  0.79011 -0.87995  0.27456  0.18569]
20Nov22_214233| [ 0.43034  0.71179  0.67930 -0.15071 -0.83669 -0.44335  0.64738  0.15004
20Nov22_214233|  -0.85014 -0.26942  0.90306  0.90737 -0.47698 -0.38817 -0.39808]
20Nov22_214233| [-0.66518 -0.23098 -0.54819 -0.25415  0.74307 -0.08076  0.84381 -0.60912
20Nov22_214233|   0.57721 -0.86679 -0.02389  0.90042  0.70037 -0.41693  0.05131]]
20Nov22_214233|-- Bias --
20Nov22_214233|[-0.22966  0.51046  0.30089  0.71965  0.09292 -0.38440 -0.34131  0.11132
20Nov22_214233|  0.29718 -0.16779 -0.00901  0.04515  0.47578  0.27160 -0.17440]
20Nov22_214233|Layer 1:
20Nov22_214233|-- Config --
20Nov22_214233|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 15], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214233|-- Weights --
20Nov22_214233|[[-0.04852 -0.36719]
20Nov22_214233| [-0.68575 -0.47776]
20Nov22_214233| [ 0.93153 -0.91089]
20Nov22_214233| [ 0.60663  0.79528]
20Nov22_214233| [-0.30677 -0.29863]
20Nov22_214233| [ 0.86867  0.83538]
20Nov22_214233| [ 0.30898  0.14192]
20Nov22_214233| [-0.75920  0.37436]
20Nov22_214233| [-0.51409 -0.58419]
20Nov22_214233| [ 0.43857 -0.21326]
20Nov22_214233| [ 0.46459  0.43505]
20Nov22_214233| [-0.12089 -0.79097]
20Nov22_214233| [ 0.43504  0.93368]
20Nov22_214233| [-0.71407 -0.76399]
20Nov22_214233| [-0.56618 -0.23316]]
20Nov22_214233|-- Bias --
20Nov22_214233|[ 0.90324 -0.85739]
20Nov22_214233|Predicting the validation and test data with the Best initial individual.
20Nov22_214238| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov22_214238|-----------  ------------------  --------------------  ----------
20Nov22_214238|Validation         42.09                  15            0.00000
20Nov22_214238|   Test            36.23                  15            0.00596
20Nov22_214238|-------------------------- Test #0 --------------------------
20Nov22_214238|Best final individual weights
20Nov22_214238|Individual:
20Nov22_214238|-- Constant hidden layers --
20Nov22_214238|False
20Nov22_214238|Layer 0:
20Nov22_214238|-- Config --
20Nov22_214238|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214238|-- Weights --
20Nov22_214238|[[ 0.07602 -0.83965  0.87180]
20Nov22_214238| [ 1.45890  0.86178  0.48983]
20Nov22_214238| [ 0.13198 -1.00734  0.82535]
20Nov22_214238| [ 0.03685  2.25842  1.27459]
20Nov22_214238| [-0.65976 -0.60462 -1.15016]
20Nov22_214238| [-1.40736  0.19479  0.02565]
20Nov22_214238| [-1.60734 -0.34618  0.79108]
20Nov22_214238| [-0.00765  0.20021  0.25913]
20Nov22_214238| [-0.04248 -0.25749 -0.94329]
20Nov22_214238| [ 1.61005  1.21931  1.65239]
20Nov22_214238| [-0.03761  0.55636  2.28794]
20Nov22_214238| [ 0.99758  0.55855 -0.71686]
20Nov22_214238| [ 0.32798  0.35272  0.30685]
20Nov22_214238| [-1.10455 -0.31879 -0.73875]
20Nov22_214238| [ 0.11895 -1.19352  0.74119]
20Nov22_214238| [ 0.83426 -1.34929  0.06396]
20Nov22_214238| [ 0.15006 -2.45478  1.70443]
20Nov22_214238| [-0.05668  0.59741 -0.34134]
20Nov22_214238| [ 0.32002 -0.54423  0.53588]
20Nov22_214238| [-0.01812 -0.84262  0.31989]
20Nov22_214238| [-0.38196  0.08123 -0.13108]
20Nov22_214238| [ 1.38123  1.57210 -0.99499]
20Nov22_214238| [ 1.85160  0.53786 -1.20392]
20Nov22_214238| [ 0.05701  0.67963  2.05135]
20Nov22_214238| [-0.09246 -1.79895  0.60417]
20Nov22_214238| [ 2.24605 -1.53357  0.14214]
20Nov22_214238| [ 0.69718 -0.42131  0.25613]
20Nov22_214238| [ 0.28769 -1.62005  0.36905]
20Nov22_214238| [-0.17885  1.27257  0.46466]
20Nov22_214238| [-1.39109  0.49067 -1.01535]
20Nov22_214238| [ 0.14804 -1.88582 -2.66067]
20Nov22_214238| [ 1.17326  0.24146 -0.39139]
20Nov22_214238| [ 0.39384  1.14256  0.09640]
20Nov22_214238| [ 0.05815  1.48059 -0.43854]
20Nov22_214238| [-0.42954 -1.54853 -1.97259]
20Nov22_214238| [-0.09207 -2.47425  0.03445]
20Nov22_214238| [-0.41718  0.43934  1.34817]
20Nov22_214238| [ 0.84986  0.35673 -0.43734]
20Nov22_214238| [ 1.47436  0.37182 -0.01283]
20Nov22_214238| [-1.06487  0.21861  0.50302]
20Nov22_214238| [-0.99576 -0.14656  1.27285]
20Nov22_214238| [-1.25165  0.36644  0.06431]
20Nov22_214238| [-0.30179 -0.50020  0.99284]
20Nov22_214238| [-0.42883  2.00908  1.70172]
20Nov22_214238| [ 1.44795  0.56861 -1.47182]
20Nov22_214238| [-2.12371  0.23565  0.12508]
20Nov22_214238| [-0.76739  0.76109 -0.51104]
20Nov22_214238| [-0.24939 -1.91051 -0.32771]
20Nov22_214238| [ 0.09604 -1.06803  0.25249]
20Nov22_214238| [ 0.69029 -1.41151 -1.45477]
20Nov22_214238| [-1.03477 -0.14404  0.28921]
20Nov22_214238| [ 1.29210 -0.56450 -0.17348]
20Nov22_214238| [ 0.74149  0.61467  0.88698]
20Nov22_214238| [-2.50133 -0.50198 -0.32709]
20Nov22_214238| [ 0.20918 -0.24368  0.66987]
20Nov22_214238| [-0.55190 -0.42397  0.71150]
20Nov22_214238| [-0.39862  0.23797  0.28748]]
20Nov22_214238|-- Bias --
20Nov22_214238|[ 0.09445 -0.10503  0.58928]
20Nov22_214238|Layer 1:
20Nov22_214238|-- Config --
20Nov22_214238|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214238|-- Weights --
20Nov22_214238|[[ 1.06275 -0.16865]
20Nov22_214238| [-0.52820  1.11843]
20Nov22_214238| [ 0.15968  0.67180]]
20Nov22_214238|-- Bias --
20Nov22_214238|[ 0.06388 -0.11557]
20Nov22_214238|Layer 2:
20Nov22_214238|-- Config --
20Nov22_214238|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214238|-- Weights --
20Nov22_214238|[[-1.06808 -0.31928  1.84373 -0.54443 -0.19449]
20Nov22_214238| [-0.13460 -0.54476 -0.72142 -1.21377  0.17061]]
20Nov22_214238|-- Bias --
20Nov22_214238|[ 1.37936  0.05983 -1.10689 -0.16738 -1.40784]
20Nov22_214238|Layer 3:
20Nov22_214238|-- Config --
20Nov22_214238|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214238|-- Weights --
20Nov22_214238|[[ 1.44608  0.23200]
20Nov22_214238| [ 0.45135 -0.38704]
20Nov22_214238| [ 1.22065  0.22361]
20Nov22_214238| [ 0.22627 -0.97342]
20Nov22_214238| [ 1.18723  0.38059]]
20Nov22_214238|-- Bias --
20Nov22_214238|[-0.08409 -0.42177]
20Nov22_214238|Layer 4:
20Nov22_214238|-- Config --
20Nov22_214238|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214238|-- Weights --
20Nov22_214238|[[-0.22220 -0.61256]
20Nov22_214238| [ 0.68089 -0.39853]]
20Nov22_214238|-- Bias --
20Nov22_214238|[ 0.98157 -0.27541]
20Nov22_214238|Layer 5:
20Nov22_214238|-- Config --
20Nov22_214238|{'name': 'Hidden6', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214238|-- Weights --
20Nov22_214238|[[ 0.45747  0.92311  0.29467 -0.28752]
20Nov22_214238| [-0.22606  0.57253  0.54464 -0.07998]]
20Nov22_214238|-- Bias --
20Nov22_214238|[ 0.08792 -0.47120  0.57435 -0.55291]
20Nov22_214238|Layer 6:
20Nov22_214238|-- Config --
20Nov22_214238|{'name': 'Hidden7', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214238|-- Weights --
20Nov22_214238|[[-0.97182  0.98846  0.95098  0.03687]
20Nov22_214238| [-0.99155  0.19867 -0.31042 -0.79984]
20Nov22_214238| [-0.06133  0.84421 -0.37525 -0.52847]
20Nov22_214238| [-0.19005 -0.18380 -0.62034 -0.44538]]
20Nov22_214238|-- Bias --
20Nov22_214238|[ 0.98163  0.78714 -0.19641  0.94613]
20Nov22_214238|Layer 7:
20Nov22_214238|-- Config --
20Nov22_214238|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214238|-- Weights --
20Nov22_214238|[[-0.43394 -1.28083]
20Nov22_214238| [-1.48533 -1.15640]
20Nov22_214238| [ 1.11545 -0.47869]
20Nov22_214238| [-0.34400  1.19318]]
20Nov22_214238|-- Bias --
20Nov22_214238|[1.87003 0.39544]
20Nov22_214238|Predicting the validation and test data with the Best final individual.
20Nov22_214246| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov22_214246|-----------  ------------------  --------------------  ----------
20Nov22_214246|Validation         40.87                 154            0.04604
20Nov22_214246|   Test            36.40                 154            0.00000
20Nov22_214246|-------------------------- Test #1 --------------------------
20Nov22_214246|Best final individual weights
20Nov22_214246|Individual:
20Nov22_214246|-- Constant hidden layers --
20Nov22_214246|False
20Nov22_214246|Layer 0:
20Nov22_214246|-- Config --
20Nov22_214246|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214246|-- Weights --
20Nov22_214246|[[ 0.07602 -0.83965  0.87180]
20Nov22_214246| [ 1.45890  0.86178  0.48983]
20Nov22_214246| [ 0.13198 -1.00734  0.82535]
20Nov22_214246| [ 0.03685  2.25842  1.27459]
20Nov22_214246| [-0.65976 -0.60462 -1.15016]
20Nov22_214246| [-1.40736  0.19479  0.02565]
20Nov22_214246| [-1.60734 -0.34618  0.79108]
20Nov22_214246| [-0.00765  0.20021  0.25913]
20Nov22_214246| [-0.04248 -0.25749 -0.94329]
20Nov22_214246| [ 1.61005  1.21931  1.65239]
20Nov22_214246| [-0.03761  0.55636  2.28794]
20Nov22_214246| [ 0.99758  0.55855 -0.71686]
20Nov22_214246| [ 0.32798  0.35272  0.30685]
20Nov22_214246| [-1.10455 -0.31879 -0.73875]
20Nov22_214246| [ 0.11895 -1.19352  0.74119]
20Nov22_214246| [ 0.83426 -1.34929  0.06396]
20Nov22_214246| [ 0.15006 -2.45478  1.70443]
20Nov22_214246| [-0.05668  0.59741 -0.34134]
20Nov22_214246| [ 0.32002 -0.54423  0.53588]
20Nov22_214246| [-0.01812 -0.84262  0.31989]
20Nov22_214246| [-0.38196  0.08123 -0.13108]
20Nov22_214246| [ 1.38123  1.57210 -0.99499]
20Nov22_214246| [ 1.85160  0.53786 -1.20392]
20Nov22_214246| [ 0.05701  0.67963  2.05135]
20Nov22_214246| [-0.09246 -1.79895  0.60417]
20Nov22_214246| [ 2.24605 -1.53357  0.14214]
20Nov22_214246| [ 0.69718 -0.42131  0.25613]
20Nov22_214246| [ 0.28769 -1.62005  0.36905]
20Nov22_214246| [-0.17885  1.27257  0.46466]
20Nov22_214246| [-1.39109  0.49067 -1.01535]
20Nov22_214246| [ 0.14804 -1.88582 -2.66067]
20Nov22_214246| [ 1.17326  0.24146 -0.39139]
20Nov22_214246| [ 0.39384  1.14256  0.09640]
20Nov22_214246| [ 0.05815  1.48059 -0.43854]
20Nov22_214246| [-0.42954 -1.54853 -1.97259]
20Nov22_214246| [-0.09207 -2.47425  0.03445]
20Nov22_214246| [-0.41718  0.43934  1.34817]
20Nov22_214246| [ 0.84986  0.35673 -0.43734]
20Nov22_214246| [ 1.47436  0.37182 -0.01283]
20Nov22_214246| [-1.06487  0.21861  0.50302]
20Nov22_214246| [-0.99576 -0.14656  1.27285]
20Nov22_214246| [-1.25165  0.36644  0.06431]
20Nov22_214246| [-0.30179 -0.50020  0.99284]
20Nov22_214246| [-0.42883  2.00908  1.70172]
20Nov22_214246| [ 1.44795  0.56861 -1.47182]
20Nov22_214246| [-2.12371  0.23565  0.12508]
20Nov22_214246| [-0.76739  0.76109 -0.51104]
20Nov22_214246| [-0.24939 -1.91051 -0.32771]
20Nov22_214246| [ 0.09604 -1.06803  0.25249]
20Nov22_214246| [ 0.69029 -1.41151 -1.45477]
20Nov22_214246| [-1.03477 -0.14404  0.28921]
20Nov22_214246| [ 1.29210 -0.56450 -0.17348]
20Nov22_214246| [ 0.74149  0.61467  0.88698]
20Nov22_214246| [-2.50133 -0.50198 -0.32709]
20Nov22_214246| [ 0.20918 -0.24368  0.66987]
20Nov22_214246| [-0.55190 -0.42397  0.71150]
20Nov22_214246| [-0.39862  0.23797  0.28748]]
20Nov22_214246|-- Bias --
20Nov22_214246|[ 0.09445 -0.10503  0.58928]
20Nov22_214246|Layer 1:
20Nov22_214246|-- Config --
20Nov22_214246|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214246|-- Weights --
20Nov22_214246|[[ 1.06275 -0.16865]
20Nov22_214246| [-0.52820  1.11843]
20Nov22_214246| [ 0.15968  0.67180]]
20Nov22_214246|-- Bias --
20Nov22_214246|[ 0.06388 -0.11557]
20Nov22_214246|Layer 2:
20Nov22_214246|-- Config --
20Nov22_214246|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214246|-- Weights --
20Nov22_214246|[[-1.06808 -0.31928  1.84373 -0.54443 -0.19449]
20Nov22_214246| [-0.13460 -0.54476 -0.72142 -1.21377  0.17061]]
20Nov22_214246|-- Bias --
20Nov22_214246|[ 1.37936  0.05983 -1.10689 -0.16738 -1.40784]
20Nov22_214246|Layer 3:
20Nov22_214246|-- Config --
20Nov22_214246|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214246|-- Weights --
20Nov22_214246|[[ 1.44608  0.23200]
20Nov22_214246| [ 0.45135 -0.38704]
20Nov22_214246| [ 1.22065  0.22361]
20Nov22_214246| [ 0.22627 -0.97342]
20Nov22_214246| [ 1.18723  0.38059]]
20Nov22_214246|-- Bias --
20Nov22_214246|[-0.08409 -0.42177]
20Nov22_214246|Layer 4:
20Nov22_214246|-- Config --
20Nov22_214246|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214246|-- Weights --
20Nov22_214246|[[-0.22220 -0.61256]
20Nov22_214246| [ 0.68089 -0.39853]]
20Nov22_214246|-- Bias --
20Nov22_214246|[ 0.98157 -0.27541]
20Nov22_214246|Layer 5:
20Nov22_214246|-- Config --
20Nov22_214246|{'name': 'Hidden6', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214246|-- Weights --
20Nov22_214246|[[ 0.45747  0.92311  0.29467 -0.28752]
20Nov22_214246| [-0.22606  0.57253  0.54464 -0.07998]]
20Nov22_214246|-- Bias --
20Nov22_214246|[ 0.08792 -0.47120  0.57435 -0.55291]
20Nov22_214246|Layer 6:
20Nov22_214246|-- Config --
20Nov22_214246|{'name': 'Hidden7', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214246|-- Weights --
20Nov22_214246|[[-0.97182  0.98846  0.95098  0.03687]
20Nov22_214246| [-0.99155  0.19867 -0.31042 -0.79984]
20Nov22_214246| [-0.06133  0.84421 -0.37525 -0.52847]
20Nov22_214246| [-0.19005 -0.18380 -0.62034 -0.44538]]
20Nov22_214246|-- Bias --
20Nov22_214246|[ 0.98163  0.78714 -0.19641  0.94613]
20Nov22_214246|Layer 7:
20Nov22_214246|-- Config --
20Nov22_214246|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214246|-- Weights --
20Nov22_214246|[[-0.43394 -1.28083]
20Nov22_214246| [-1.48533 -1.15640]
20Nov22_214246| [ 1.11545 -0.47869]
20Nov22_214246| [-0.34400  1.19318]]
20Nov22_214246|-- Bias --
20Nov22_214246|[1.87003 0.39544]
20Nov22_214246|Predicting the validation and test data with the Best final individual.
20Nov22_214254| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov22_214254|-----------  ------------------  --------------------  ----------
20Nov22_214254|Validation         24.17                 154            0.76954
20Nov22_214254|   Test            28.50                 154            0.38667
20Nov22_214254|-------------------------- Test #2 --------------------------
20Nov22_214254|Best final individual weights
20Nov22_214254|Individual:
20Nov22_214254|-- Constant hidden layers --
20Nov22_214254|False
20Nov22_214254|Layer 0:
20Nov22_214254|-- Config --
20Nov22_214254|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214254|-- Weights --
20Nov22_214254|[[ 0.07602 -0.83965  0.87180]
20Nov22_214254| [ 1.45890  0.86178  0.48983]
20Nov22_214254| [ 0.13198 -1.00734  0.82535]
20Nov22_214254| [ 0.03685  2.25842  1.27459]
20Nov22_214254| [-0.65976 -0.60462 -1.15016]
20Nov22_214254| [-1.40736  0.19479  0.02565]
20Nov22_214254| [-1.60734 -0.34618  0.79108]
20Nov22_214254| [-0.00765  0.20021  0.25913]
20Nov22_214254| [-0.04248 -0.25749 -0.94329]
20Nov22_214254| [ 1.61005  1.21931  1.65239]
20Nov22_214254| [-0.03761  0.55636  2.28794]
20Nov22_214254| [ 0.99758  0.55855 -0.71686]
20Nov22_214254| [ 0.32798  0.35272  0.30685]
20Nov22_214254| [-1.10455 -0.31879 -0.73875]
20Nov22_214254| [ 0.11895 -1.19352  0.74119]
20Nov22_214254| [ 0.83426 -1.34929  0.06396]
20Nov22_214254| [ 0.15006 -2.45478  1.70443]
20Nov22_214254| [-0.05668  0.59741 -0.34134]
20Nov22_214254| [ 0.32002 -0.54423  0.53588]
20Nov22_214254| [-0.01812 -0.84262  0.31989]
20Nov22_214254| [-0.38196  0.08123 -0.13108]
20Nov22_214254| [ 1.38123  1.57210 -0.99499]
20Nov22_214254| [ 1.85160  0.53786 -1.20392]
20Nov22_214254| [ 0.05701  0.67963  2.05135]
20Nov22_214254| [-0.09246 -1.79895  0.60417]
20Nov22_214254| [ 2.24605 -1.53357  0.14214]
20Nov22_214254| [ 0.69718 -0.42131  0.25613]
20Nov22_214254| [ 0.28769 -1.62005  0.36905]
20Nov22_214254| [-0.17885  1.27257  0.46466]
20Nov22_214254| [-1.39109  0.49067 -1.01535]
20Nov22_214254| [ 0.14804 -1.88582 -2.66067]
20Nov22_214254| [ 1.17326  0.24146 -0.39139]
20Nov22_214254| [ 0.39384  1.14256  0.09640]
20Nov22_214254| [ 0.05815  1.48059 -0.43854]
20Nov22_214254| [-0.42954 -1.54853 -1.97259]
20Nov22_214254| [-0.09207 -2.47425  0.03445]
20Nov22_214254| [-0.41718  0.43934  1.34817]
20Nov22_214254| [ 0.84986  0.35673 -0.43734]
20Nov22_214254| [ 1.47436  0.37182 -0.01283]
20Nov22_214254| [-1.06487  0.21861  0.50302]
20Nov22_214254| [-0.99576 -0.14656  1.27285]
20Nov22_214254| [-1.25165  0.36644  0.06431]
20Nov22_214254| [-0.30179 -0.50020  0.99284]
20Nov22_214254| [-0.42883  2.00908  1.70172]
20Nov22_214254| [ 1.44795  0.56861 -1.47182]
20Nov22_214254| [-2.12371  0.23565  0.12508]
20Nov22_214254| [-0.76739  0.76109 -0.51104]
20Nov22_214254| [-0.24939 -1.91051 -0.32771]
20Nov22_214254| [ 0.09604 -1.06803  0.25249]
20Nov22_214254| [ 0.69029 -1.41151 -1.45477]
20Nov22_214254| [-1.03477 -0.14404  0.28921]
20Nov22_214254| [ 1.29210 -0.56450 -0.17348]
20Nov22_214254| [ 0.74149  0.61467  0.88698]
20Nov22_214254| [-2.50133 -0.50198 -0.32709]
20Nov22_214254| [ 0.20918 -0.24368  0.66987]
20Nov22_214254| [-0.55190 -0.42397  0.71150]
20Nov22_214254| [-0.39862  0.23797  0.28748]]
20Nov22_214254|-- Bias --
20Nov22_214254|[ 0.09445 -0.10503  0.58928]
20Nov22_214254|Layer 1:
20Nov22_214254|-- Config --
20Nov22_214254|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214254|-- Weights --
20Nov22_214254|[[ 1.06275 -0.16865]
20Nov22_214254| [-0.52820  1.11843]
20Nov22_214254| [ 0.15968  0.67180]]
20Nov22_214254|-- Bias --
20Nov22_214254|[ 0.06388 -0.11557]
20Nov22_214254|Layer 2:
20Nov22_214254|-- Config --
20Nov22_214254|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214254|-- Weights --
20Nov22_214254|[[-1.06808 -0.31928  1.84373 -0.54443 -0.19449]
20Nov22_214254| [-0.13460 -0.54476 -0.72142 -1.21377  0.17061]]
20Nov22_214254|-- Bias --
20Nov22_214254|[ 1.37936  0.05983 -1.10689 -0.16738 -1.40784]
20Nov22_214254|Layer 3:
20Nov22_214254|-- Config --
20Nov22_214254|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214254|-- Weights --
20Nov22_214254|[[ 1.44608  0.23200]
20Nov22_214254| [ 0.45135 -0.38704]
20Nov22_214254| [ 1.22065  0.22361]
20Nov22_214254| [ 0.22627 -0.97342]
20Nov22_214254| [ 1.18723  0.38059]]
20Nov22_214254|-- Bias --
20Nov22_214254|[-0.08409 -0.42177]
20Nov22_214254|Layer 4:
20Nov22_214254|-- Config --
20Nov22_214254|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214254|-- Weights --
20Nov22_214254|[[-0.22220 -0.61256]
20Nov22_214254| [ 0.68089 -0.39853]]
20Nov22_214254|-- Bias --
20Nov22_214254|[ 0.98157 -0.27541]
20Nov22_214254|Layer 5:
20Nov22_214254|-- Config --
20Nov22_214254|{'name': 'Hidden6', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214254|-- Weights --
20Nov22_214254|[[ 0.45747  0.92311  0.29467 -0.28752]
20Nov22_214254| [-0.22606  0.57253  0.54464 -0.07998]]
20Nov22_214254|-- Bias --
20Nov22_214254|[ 0.08792 -0.47120  0.57435 -0.55291]
20Nov22_214254|Layer 6:
20Nov22_214254|-- Config --
20Nov22_214254|{'name': 'Hidden7', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214254|-- Weights --
20Nov22_214254|[[-0.97182  0.98846  0.95098  0.03687]
20Nov22_214254| [-0.99155  0.19867 -0.31042 -0.79984]
20Nov22_214254| [-0.06133  0.84421 -0.37525 -0.52847]
20Nov22_214254| [-0.19005 -0.18380 -0.62034 -0.44538]]
20Nov22_214254|-- Bias --
20Nov22_214254|[ 0.98163  0.78714 -0.19641  0.94613]
20Nov22_214254|Layer 7:
20Nov22_214254|-- Config --
20Nov22_214254|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214254|-- Weights --
20Nov22_214254|[[-0.43394 -1.28083]
20Nov22_214254| [-1.48533 -1.15640]
20Nov22_214254| [ 1.11545 -0.47869]
20Nov22_214254| [-0.34400  1.19318]]
20Nov22_214254|-- Bias --
20Nov22_214254|[1.87003 0.39544]
20Nov22_214254|Predicting the validation and test data with the Best final individual.
20Nov22_214303| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov22_214303|-----------  ------------------  --------------------  ----------
20Nov22_214303|Validation         25.13                 154            0.73804
20Nov22_214303|   Test            24.24                 154            0.75296
20Nov22_214303|-------------------------- Test #3 --------------------------
20Nov22_214303|Best final individual weights
20Nov22_214303|Individual:
20Nov22_214303|-- Constant hidden layers --
20Nov22_214303|False
20Nov22_214303|Layer 0:
20Nov22_214303|-- Config --
20Nov22_214303|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214303|-- Weights --
20Nov22_214303|[[ 0.07602 -0.83965  0.87180]
20Nov22_214303| [ 1.45890  0.86178  0.48983]
20Nov22_214303| [ 0.13198 -1.00734  0.82535]
20Nov22_214303| [ 0.03685  2.25842  1.27459]
20Nov22_214303| [-0.65976 -0.60462 -1.15016]
20Nov22_214303| [-1.40736  0.19479  0.02565]
20Nov22_214303| [-1.60734 -0.34618  0.79108]
20Nov22_214303| [-0.00765  0.20021  0.25913]
20Nov22_214303| [-0.04248 -0.25749 -0.94329]
20Nov22_214303| [ 1.61005  1.21931  1.65239]
20Nov22_214303| [-0.03761  0.55636  2.28794]
20Nov22_214303| [ 0.99758  0.55855 -0.71686]
20Nov22_214303| [ 0.32798  0.35272  0.30685]
20Nov22_214303| [-1.10455 -0.31879 -0.73875]
20Nov22_214303| [ 0.11895 -1.19352  0.74119]
20Nov22_214303| [ 0.83426 -1.34929  0.06396]
20Nov22_214303| [ 0.15006 -2.45478  1.70443]
20Nov22_214303| [-0.05668  0.59741 -0.34134]
20Nov22_214303| [ 0.32002 -0.54423  0.53588]
20Nov22_214303| [-0.01812 -0.84262  0.31989]
20Nov22_214303| [-0.38196  0.08123 -0.13108]
20Nov22_214303| [ 1.38123  1.57210 -0.99499]
20Nov22_214303| [ 1.85160  0.53786 -1.20392]
20Nov22_214303| [ 0.05701  0.67963  2.05135]
20Nov22_214303| [-0.09246 -1.79895  0.60417]
20Nov22_214303| [ 2.24605 -1.53357  0.14214]
20Nov22_214303| [ 0.69718 -0.42131  0.25613]
20Nov22_214303| [ 0.28769 -1.62005  0.36905]
20Nov22_214303| [-0.17885  1.27257  0.46466]
20Nov22_214303| [-1.39109  0.49067 -1.01535]
20Nov22_214303| [ 0.14804 -1.88582 -2.66067]
20Nov22_214303| [ 1.17326  0.24146 -0.39139]
20Nov22_214303| [ 0.39384  1.14256  0.09640]
20Nov22_214303| [ 0.05815  1.48059 -0.43854]
20Nov22_214303| [-0.42954 -1.54853 -1.97259]
20Nov22_214303| [-0.09207 -2.47425  0.03445]
20Nov22_214303| [-0.41718  0.43934  1.34817]
20Nov22_214303| [ 0.84986  0.35673 -0.43734]
20Nov22_214303| [ 1.47436  0.37182 -0.01283]
20Nov22_214303| [-1.06487  0.21861  0.50302]
20Nov22_214303| [-0.99576 -0.14656  1.27285]
20Nov22_214303| [-1.25165  0.36644  0.06431]
20Nov22_214303| [-0.30179 -0.50020  0.99284]
20Nov22_214303| [-0.42883  2.00908  1.70172]
20Nov22_214303| [ 1.44795  0.56861 -1.47182]
20Nov22_214303| [-2.12371  0.23565  0.12508]
20Nov22_214303| [-0.76739  0.76109 -0.51104]
20Nov22_214303| [-0.24939 -1.91051 -0.32771]
20Nov22_214303| [ 0.09604 -1.06803  0.25249]
20Nov22_214303| [ 0.69029 -1.41151 -1.45477]
20Nov22_214303| [-1.03477 -0.14404  0.28921]
20Nov22_214303| [ 1.29210 -0.56450 -0.17348]
20Nov22_214303| [ 0.74149  0.61467  0.88698]
20Nov22_214303| [-2.50133 -0.50198 -0.32709]
20Nov22_214303| [ 0.20918 -0.24368  0.66987]
20Nov22_214303| [-0.55190 -0.42397  0.71150]
20Nov22_214303| [-0.39862  0.23797  0.28748]]
20Nov22_214303|-- Bias --
20Nov22_214303|[ 0.09445 -0.10503  0.58928]
20Nov22_214303|Layer 1:
20Nov22_214303|-- Config --
20Nov22_214303|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214303|-- Weights --
20Nov22_214303|[[ 1.06275 -0.16865]
20Nov22_214303| [-0.52820  1.11843]
20Nov22_214303| [ 0.15968  0.67180]]
20Nov22_214303|-- Bias --
20Nov22_214303|[ 0.06388 -0.11557]
20Nov22_214303|Layer 2:
20Nov22_214303|-- Config --
20Nov22_214303|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214303|-- Weights --
20Nov22_214303|[[-1.06808 -0.31928  1.84373 -0.54443 -0.19449]
20Nov22_214303| [-0.13460 -0.54476 -0.72142 -1.21377  0.17061]]
20Nov22_214303|-- Bias --
20Nov22_214303|[ 1.37936  0.05983 -1.10689 -0.16738 -1.40784]
20Nov22_214303|Layer 3:
20Nov22_214303|-- Config --
20Nov22_214303|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214303|-- Weights --
20Nov22_214303|[[ 1.44608  0.23200]
20Nov22_214303| [ 0.45135 -0.38704]
20Nov22_214303| [ 1.22065  0.22361]
20Nov22_214303| [ 0.22627 -0.97342]
20Nov22_214303| [ 1.18723  0.38059]]
20Nov22_214303|-- Bias --
20Nov22_214303|[-0.08409 -0.42177]
20Nov22_214303|Layer 4:
20Nov22_214303|-- Config --
20Nov22_214303|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214303|-- Weights --
20Nov22_214303|[[-0.22220 -0.61256]
20Nov22_214303| [ 0.68089 -0.39853]]
20Nov22_214303|-- Bias --
20Nov22_214303|[ 0.98157 -0.27541]
20Nov22_214303|Layer 5:
20Nov22_214303|-- Config --
20Nov22_214303|{'name': 'Hidden6', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214303|-- Weights --
20Nov22_214303|[[ 0.45747  0.92311  0.29467 -0.28752]
20Nov22_214303| [-0.22606  0.57253  0.54464 -0.07998]]
20Nov22_214303|-- Bias --
20Nov22_214303|[ 0.08792 -0.47120  0.57435 -0.55291]
20Nov22_214303|Layer 6:
20Nov22_214303|-- Config --
20Nov22_214303|{'name': 'Hidden7', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214303|-- Weights --
20Nov22_214303|[[-0.97182  0.98846  0.95098  0.03687]
20Nov22_214303| [-0.99155  0.19867 -0.31042 -0.79984]
20Nov22_214303| [-0.06133  0.84421 -0.37525 -0.52847]
20Nov22_214303| [-0.19005 -0.18380 -0.62034 -0.44538]]
20Nov22_214303|-- Bias --
20Nov22_214303|[ 0.98163  0.78714 -0.19641  0.94613]
20Nov22_214303|Layer 7:
20Nov22_214303|-- Config --
20Nov22_214303|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214303|-- Weights --
20Nov22_214303|[[-0.43394 -1.28083]
20Nov22_214303| [-1.48533 -1.15640]
20Nov22_214303| [ 1.11545 -0.47869]
20Nov22_214303| [-0.34400  1.19318]]
20Nov22_214303|-- Bias --
20Nov22_214303|[1.87003 0.39544]
20Nov22_214303|Predicting the validation and test data with the Best final individual.
20Nov22_214311| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov22_214311|-----------  ------------------  --------------------  ----------
20Nov22_214311|Validation         42.00                 154            0.00000
20Nov22_214311|   Test            23.89                 154            0.74634
20Nov22_214311|-------------------------- Test #4 --------------------------
20Nov22_214311|Best final individual weights
20Nov22_214311|Individual:
20Nov22_214311|-- Constant hidden layers --
20Nov22_214311|False
20Nov22_214311|Layer 0:
20Nov22_214311|-- Config --
20Nov22_214311|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214311|-- Weights --
20Nov22_214311|[[ 0.07602 -0.83965  0.87180]
20Nov22_214311| [ 1.45890  0.86178  0.48983]
20Nov22_214311| [ 0.13198 -1.00734  0.82535]
20Nov22_214311| [ 0.03685  2.25842  1.27459]
20Nov22_214311| [-0.65976 -0.60462 -1.15016]
20Nov22_214311| [-1.40736  0.19479  0.02565]
20Nov22_214311| [-1.60734 -0.34618  0.79108]
20Nov22_214311| [-0.00765  0.20021  0.25913]
20Nov22_214311| [-0.04248 -0.25749 -0.94329]
20Nov22_214311| [ 1.61005  1.21931  1.65239]
20Nov22_214311| [-0.03761  0.55636  2.28794]
20Nov22_214311| [ 0.99758  0.55855 -0.71686]
20Nov22_214311| [ 0.32798  0.35272  0.30685]
20Nov22_214311| [-1.10455 -0.31879 -0.73875]
20Nov22_214311| [ 0.11895 -1.19352  0.74119]
20Nov22_214311| [ 0.83426 -1.34929  0.06396]
20Nov22_214311| [ 0.15006 -2.45478  1.70443]
20Nov22_214311| [-0.05668  0.59741 -0.34134]
20Nov22_214311| [ 0.32002 -0.54423  0.53588]
20Nov22_214311| [-0.01812 -0.84262  0.31989]
20Nov22_214311| [-0.38196  0.08123 -0.13108]
20Nov22_214311| [ 1.38123  1.57210 -0.99499]
20Nov22_214311| [ 1.85160  0.53786 -1.20392]
20Nov22_214311| [ 0.05701  0.67963  2.05135]
20Nov22_214311| [-0.09246 -1.79895  0.60417]
20Nov22_214311| [ 2.24605 -1.53357  0.14214]
20Nov22_214311| [ 0.69718 -0.42131  0.25613]
20Nov22_214311| [ 0.28769 -1.62005  0.36905]
20Nov22_214311| [-0.17885  1.27257  0.46466]
20Nov22_214311| [-1.39109  0.49067 -1.01535]
20Nov22_214311| [ 0.14804 -1.88582 -2.66067]
20Nov22_214311| [ 1.17326  0.24146 -0.39139]
20Nov22_214311| [ 0.39384  1.14256  0.09640]
20Nov22_214311| [ 0.05815  1.48059 -0.43854]
20Nov22_214311| [-0.42954 -1.54853 -1.97259]
20Nov22_214311| [-0.09207 -2.47425  0.03445]
20Nov22_214311| [-0.41718  0.43934  1.34817]
20Nov22_214311| [ 0.84986  0.35673 -0.43734]
20Nov22_214311| [ 1.47436  0.37182 -0.01283]
20Nov22_214311| [-1.06487  0.21861  0.50302]
20Nov22_214311| [-0.99576 -0.14656  1.27285]
20Nov22_214311| [-1.25165  0.36644  0.06431]
20Nov22_214311| [-0.30179 -0.50020  0.99284]
20Nov22_214311| [-0.42883  2.00908  1.70172]
20Nov22_214311| [ 1.44795  0.56861 -1.47182]
20Nov22_214311| [-2.12371  0.23565  0.12508]
20Nov22_214311| [-0.76739  0.76109 -0.51104]
20Nov22_214311| [-0.24939 -1.91051 -0.32771]
20Nov22_214311| [ 0.09604 -1.06803  0.25249]
20Nov22_214311| [ 0.69029 -1.41151 -1.45477]
20Nov22_214311| [-1.03477 -0.14404  0.28921]
20Nov22_214311| [ 1.29210 -0.56450 -0.17348]
20Nov22_214311| [ 0.74149  0.61467  0.88698]
20Nov22_214311| [-2.50133 -0.50198 -0.32709]
20Nov22_214311| [ 0.20918 -0.24368  0.66987]
20Nov22_214311| [-0.55190 -0.42397  0.71150]
20Nov22_214311| [-0.39862  0.23797  0.28748]]
20Nov22_214311|-- Bias --
20Nov22_214311|[ 0.09445 -0.10503  0.58928]
20Nov22_214311|Layer 1:
20Nov22_214311|-- Config --
20Nov22_214311|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214311|-- Weights --
20Nov22_214311|[[ 1.06275 -0.16865]
20Nov22_214311| [-0.52820  1.11843]
20Nov22_214311| [ 0.15968  0.67180]]
20Nov22_214311|-- Bias --
20Nov22_214311|[ 0.06388 -0.11557]
20Nov22_214311|Layer 2:
20Nov22_214311|-- Config --
20Nov22_214311|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214311|-- Weights --
20Nov22_214311|[[-1.06808 -0.31928  1.84373 -0.54443 -0.19449]
20Nov22_214311| [-0.13460 -0.54476 -0.72142 -1.21377  0.17061]]
20Nov22_214311|-- Bias --
20Nov22_214311|[ 1.37936  0.05983 -1.10689 -0.16738 -1.40784]
20Nov22_214311|Layer 3:
20Nov22_214311|-- Config --
20Nov22_214311|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214311|-- Weights --
20Nov22_214311|[[ 1.44608  0.23200]
20Nov22_214311| [ 0.45135 -0.38704]
20Nov22_214311| [ 1.22065  0.22361]
20Nov22_214311| [ 0.22627 -0.97342]
20Nov22_214311| [ 1.18723  0.38059]]
20Nov22_214311|-- Bias --
20Nov22_214311|[-0.08409 -0.42177]
20Nov22_214311|Layer 4:
20Nov22_214311|-- Config --
20Nov22_214311|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214311|-- Weights --
20Nov22_214311|[[-0.22220 -0.61256]
20Nov22_214311| [ 0.68089 -0.39853]]
20Nov22_214311|-- Bias --
20Nov22_214311|[ 0.98157 -0.27541]
20Nov22_214311|Layer 5:
20Nov22_214311|-- Config --
20Nov22_214311|{'name': 'Hidden6', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214311|-- Weights --
20Nov22_214311|[[ 0.45747  0.92311  0.29467 -0.28752]
20Nov22_214311| [-0.22606  0.57253  0.54464 -0.07998]]
20Nov22_214311|-- Bias --
20Nov22_214311|[ 0.08792 -0.47120  0.57435 -0.55291]
20Nov22_214311|Layer 6:
20Nov22_214311|-- Config --
20Nov22_214311|{'name': 'Hidden7', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214311|-- Weights --
20Nov22_214311|[[-0.97182  0.98846  0.95098  0.03687]
20Nov22_214311| [-0.99155  0.19867 -0.31042 -0.79984]
20Nov22_214311| [-0.06133  0.84421 -0.37525 -0.52847]
20Nov22_214311| [-0.19005 -0.18380 -0.62034 -0.44538]]
20Nov22_214311|-- Bias --
20Nov22_214311|[ 0.98163  0.78714 -0.19641  0.94613]
20Nov22_214311|Layer 7:
20Nov22_214311|-- Config --
20Nov22_214311|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214311|-- Weights --
20Nov22_214311|[[-0.43394 -1.28083]
20Nov22_214311| [-1.48533 -1.15640]
20Nov22_214311| [ 1.11545 -0.47869]
20Nov22_214311| [-0.34400  1.19318]]
20Nov22_214311|-- Bias --
20Nov22_214311|[1.87003 0.39544]
20Nov22_214311|Predicting the validation and test data with the Best final individual.
20Nov22_214319| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov22_214319|-----------  ------------------  --------------------  ----------
20Nov22_214319|Validation         42.00                 154            0.00000
20Nov22_214319|   Test            36.40                 154            0.00000
20Nov22_214319|-------------------------- Test #5 --------------------------
20Nov22_214319|Best final individual weights
20Nov22_214319|Individual:
20Nov22_214319|-- Constant hidden layers --
20Nov22_214319|False
20Nov22_214319|Layer 0:
20Nov22_214319|-- Config --
20Nov22_214319|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214319|-- Weights --
20Nov22_214319|[[ 0.07602 -0.83965  0.87180]
20Nov22_214319| [ 1.45890  0.86178  0.48983]
20Nov22_214319| [ 0.13198 -1.00734  0.82535]
20Nov22_214319| [ 0.03685  2.25842  1.27459]
20Nov22_214319| [-0.65976 -0.60462 -1.15016]
20Nov22_214319| [-1.40736  0.19479  0.02565]
20Nov22_214319| [-1.60734 -0.34618  0.79108]
20Nov22_214319| [-0.00765  0.20021  0.25913]
20Nov22_214319| [-0.04248 -0.25749 -0.94329]
20Nov22_214319| [ 1.61005  1.21931  1.65239]
20Nov22_214319| [-0.03761  0.55636  2.28794]
20Nov22_214319| [ 0.99758  0.55855 -0.71686]
20Nov22_214319| [ 0.32798  0.35272  0.30685]
20Nov22_214319| [-1.10455 -0.31879 -0.73875]
20Nov22_214319| [ 0.11895 -1.19352  0.74119]
20Nov22_214319| [ 0.83426 -1.34929  0.06396]
20Nov22_214319| [ 0.15006 -2.45478  1.70443]
20Nov22_214319| [-0.05668  0.59741 -0.34134]
20Nov22_214319| [ 0.32002 -0.54423  0.53588]
20Nov22_214319| [-0.01812 -0.84262  0.31989]
20Nov22_214319| [-0.38196  0.08123 -0.13108]
20Nov22_214319| [ 1.38123  1.57210 -0.99499]
20Nov22_214319| [ 1.85160  0.53786 -1.20392]
20Nov22_214319| [ 0.05701  0.67963  2.05135]
20Nov22_214319| [-0.09246 -1.79895  0.60417]
20Nov22_214319| [ 2.24605 -1.53357  0.14214]
20Nov22_214319| [ 0.69718 -0.42131  0.25613]
20Nov22_214319| [ 0.28769 -1.62005  0.36905]
20Nov22_214319| [-0.17885  1.27257  0.46466]
20Nov22_214319| [-1.39109  0.49067 -1.01535]
20Nov22_214319| [ 0.14804 -1.88582 -2.66067]
20Nov22_214319| [ 1.17326  0.24146 -0.39139]
20Nov22_214319| [ 0.39384  1.14256  0.09640]
20Nov22_214319| [ 0.05815  1.48059 -0.43854]
20Nov22_214319| [-0.42954 -1.54853 -1.97259]
20Nov22_214319| [-0.09207 -2.47425  0.03445]
20Nov22_214319| [-0.41718  0.43934  1.34817]
20Nov22_214319| [ 0.84986  0.35673 -0.43734]
20Nov22_214319| [ 1.47436  0.37182 -0.01283]
20Nov22_214319| [-1.06487  0.21861  0.50302]
20Nov22_214319| [-0.99576 -0.14656  1.27285]
20Nov22_214319| [-1.25165  0.36644  0.06431]
20Nov22_214319| [-0.30179 -0.50020  0.99284]
20Nov22_214319| [-0.42883  2.00908  1.70172]
20Nov22_214319| [ 1.44795  0.56861 -1.47182]
20Nov22_214319| [-2.12371  0.23565  0.12508]
20Nov22_214319| [-0.76739  0.76109 -0.51104]
20Nov22_214319| [-0.24939 -1.91051 -0.32771]
20Nov22_214319| [ 0.09604 -1.06803  0.25249]
20Nov22_214319| [ 0.69029 -1.41151 -1.45477]
20Nov22_214319| [-1.03477 -0.14404  0.28921]
20Nov22_214319| [ 1.29210 -0.56450 -0.17348]
20Nov22_214319| [ 0.74149  0.61467  0.88698]
20Nov22_214319| [-2.50133 -0.50198 -0.32709]
20Nov22_214319| [ 0.20918 -0.24368  0.66987]
20Nov22_214319| [-0.55190 -0.42397  0.71150]
20Nov22_214319| [-0.39862  0.23797  0.28748]]
20Nov22_214319|-- Bias --
20Nov22_214319|[ 0.09445 -0.10503  0.58928]
20Nov22_214319|Layer 1:
20Nov22_214319|-- Config --
20Nov22_214319|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214319|-- Weights --
20Nov22_214319|[[ 1.06275 -0.16865]
20Nov22_214319| [-0.52820  1.11843]
20Nov22_214319| [ 0.15968  0.67180]]
20Nov22_214319|-- Bias --
20Nov22_214319|[ 0.06388 -0.11557]
20Nov22_214319|Layer 2:
20Nov22_214319|-- Config --
20Nov22_214319|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214319|-- Weights --
20Nov22_214319|[[-1.06808 -0.31928  1.84373 -0.54443 -0.19449]
20Nov22_214319| [-0.13460 -0.54476 -0.72142 -1.21377  0.17061]]
20Nov22_214319|-- Bias --
20Nov22_214319|[ 1.37936  0.05983 -1.10689 -0.16738 -1.40784]
20Nov22_214319|Layer 3:
20Nov22_214319|-- Config --
20Nov22_214319|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214319|-- Weights --
20Nov22_214319|[[ 1.44608  0.23200]
20Nov22_214319| [ 0.45135 -0.38704]
20Nov22_214319| [ 1.22065  0.22361]
20Nov22_214319| [ 0.22627 -0.97342]
20Nov22_214319| [ 1.18723  0.38059]]
20Nov22_214319|-- Bias --
20Nov22_214319|[-0.08409 -0.42177]
20Nov22_214319|Layer 4:
20Nov22_214319|-- Config --
20Nov22_214319|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214319|-- Weights --
20Nov22_214319|[[-0.22220 -0.61256]
20Nov22_214319| [ 0.68089 -0.39853]]
20Nov22_214319|-- Bias --
20Nov22_214319|[ 0.98157 -0.27541]
20Nov22_214319|Layer 5:
20Nov22_214319|-- Config --
20Nov22_214319|{'name': 'Hidden6', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214319|-- Weights --
20Nov22_214319|[[ 0.45747  0.92311  0.29467 -0.28752]
20Nov22_214319| [-0.22606  0.57253  0.54464 -0.07998]]
20Nov22_214319|-- Bias --
20Nov22_214319|[ 0.08792 -0.47120  0.57435 -0.55291]
20Nov22_214319|Layer 6:
20Nov22_214319|-- Config --
20Nov22_214319|{'name': 'Hidden7', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214319|-- Weights --
20Nov22_214319|[[-0.97182  0.98846  0.95098  0.03687]
20Nov22_214319| [-0.99155  0.19867 -0.31042 -0.79984]
20Nov22_214319| [-0.06133  0.84421 -0.37525 -0.52847]
20Nov22_214319| [-0.19005 -0.18380 -0.62034 -0.44538]]
20Nov22_214319|-- Bias --
20Nov22_214319|[ 0.98163  0.78714 -0.19641  0.94613]
20Nov22_214319|Layer 7:
20Nov22_214319|-- Config --
20Nov22_214319|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214319|-- Weights --
20Nov22_214319|[[-0.43394 -1.28083]
20Nov22_214319| [-1.48533 -1.15640]
20Nov22_214319| [ 1.11545 -0.47869]
20Nov22_214319| [-0.34400  1.19318]]
20Nov22_214319|-- Bias --
20Nov22_214319|[1.87003 0.39544]
20Nov22_214319|Predicting the validation and test data with the Best final individual.
20Nov22_214327| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov22_214327|-----------  ------------------  --------------------  ----------
20Nov22_214327|Validation         24.96                 154            0.75282
20Nov22_214327|   Test            26.93                 154            0.59738
20Nov22_214327|-------------------------- Test #6 --------------------------
20Nov22_214327|Best final individual weights
20Nov22_214327|Individual:
20Nov22_214327|-- Constant hidden layers --
20Nov22_214327|False
20Nov22_214327|Layer 0:
20Nov22_214327|-- Config --
20Nov22_214327|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214327|-- Weights --
20Nov22_214327|[[ 0.07602 -0.83965  0.87180]
20Nov22_214327| [ 1.45890  0.86178  0.48983]
20Nov22_214327| [ 0.13198 -1.00734  0.82535]
20Nov22_214327| [ 0.03685  2.25842  1.27459]
20Nov22_214327| [-0.65976 -0.60462 -1.15016]
20Nov22_214327| [-1.40736  0.19479  0.02565]
20Nov22_214327| [-1.60734 -0.34618  0.79108]
20Nov22_214327| [-0.00765  0.20021  0.25913]
20Nov22_214327| [-0.04248 -0.25749 -0.94329]
20Nov22_214327| [ 1.61005  1.21931  1.65239]
20Nov22_214327| [-0.03761  0.55636  2.28794]
20Nov22_214327| [ 0.99758  0.55855 -0.71686]
20Nov22_214327| [ 0.32798  0.35272  0.30685]
20Nov22_214327| [-1.10455 -0.31879 -0.73875]
20Nov22_214327| [ 0.11895 -1.19352  0.74119]
20Nov22_214327| [ 0.83426 -1.34929  0.06396]
20Nov22_214327| [ 0.15006 -2.45478  1.70443]
20Nov22_214327| [-0.05668  0.59741 -0.34134]
20Nov22_214327| [ 0.32002 -0.54423  0.53588]
20Nov22_214327| [-0.01812 -0.84262  0.31989]
20Nov22_214327| [-0.38196  0.08123 -0.13108]
20Nov22_214327| [ 1.38123  1.57210 -0.99499]
20Nov22_214327| [ 1.85160  0.53786 -1.20392]
20Nov22_214327| [ 0.05701  0.67963  2.05135]
20Nov22_214327| [-0.09246 -1.79895  0.60417]
20Nov22_214327| [ 2.24605 -1.53357  0.14214]
20Nov22_214327| [ 0.69718 -0.42131  0.25613]
20Nov22_214327| [ 0.28769 -1.62005  0.36905]
20Nov22_214327| [-0.17885  1.27257  0.46466]
20Nov22_214327| [-1.39109  0.49067 -1.01535]
20Nov22_214327| [ 0.14804 -1.88582 -2.66067]
20Nov22_214327| [ 1.17326  0.24146 -0.39139]
20Nov22_214327| [ 0.39384  1.14256  0.09640]
20Nov22_214327| [ 0.05815  1.48059 -0.43854]
20Nov22_214327| [-0.42954 -1.54853 -1.97259]
20Nov22_214327| [-0.09207 -2.47425  0.03445]
20Nov22_214327| [-0.41718  0.43934  1.34817]
20Nov22_214327| [ 0.84986  0.35673 -0.43734]
20Nov22_214327| [ 1.47436  0.37182 -0.01283]
20Nov22_214327| [-1.06487  0.21861  0.50302]
20Nov22_214327| [-0.99576 -0.14656  1.27285]
20Nov22_214327| [-1.25165  0.36644  0.06431]
20Nov22_214327| [-0.30179 -0.50020  0.99284]
20Nov22_214327| [-0.42883  2.00908  1.70172]
20Nov22_214327| [ 1.44795  0.56861 -1.47182]
20Nov22_214327| [-2.12371  0.23565  0.12508]
20Nov22_214327| [-0.76739  0.76109 -0.51104]
20Nov22_214327| [-0.24939 -1.91051 -0.32771]
20Nov22_214327| [ 0.09604 -1.06803  0.25249]
20Nov22_214327| [ 0.69029 -1.41151 -1.45477]
20Nov22_214327| [-1.03477 -0.14404  0.28921]
20Nov22_214327| [ 1.29210 -0.56450 -0.17348]
20Nov22_214327| [ 0.74149  0.61467  0.88698]
20Nov22_214327| [-2.50133 -0.50198 -0.32709]
20Nov22_214327| [ 0.20918 -0.24368  0.66987]
20Nov22_214327| [-0.55190 -0.42397  0.71150]
20Nov22_214327| [-0.39862  0.23797  0.28748]]
20Nov22_214327|-- Bias --
20Nov22_214327|[ 0.09445 -0.10503  0.58928]
20Nov22_214327|Layer 1:
20Nov22_214327|-- Config --
20Nov22_214327|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214327|-- Weights --
20Nov22_214327|[[ 1.06275 -0.16865]
20Nov22_214327| [-0.52820  1.11843]
20Nov22_214327| [ 0.15968  0.67180]]
20Nov22_214327|-- Bias --
20Nov22_214327|[ 0.06388 -0.11557]
20Nov22_214327|Layer 2:
20Nov22_214327|-- Config --
20Nov22_214327|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214327|-- Weights --
20Nov22_214327|[[-1.06808 -0.31928  1.84373 -0.54443 -0.19449]
20Nov22_214327| [-0.13460 -0.54476 -0.72142 -1.21377  0.17061]]
20Nov22_214327|-- Bias --
20Nov22_214327|[ 1.37936  0.05983 -1.10689 -0.16738 -1.40784]
20Nov22_214327|Layer 3:
20Nov22_214327|-- Config --
20Nov22_214327|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214327|-- Weights --
20Nov22_214327|[[ 1.44608  0.23200]
20Nov22_214327| [ 0.45135 -0.38704]
20Nov22_214327| [ 1.22065  0.22361]
20Nov22_214327| [ 0.22627 -0.97342]
20Nov22_214327| [ 1.18723  0.38059]]
20Nov22_214327|-- Bias --
20Nov22_214327|[-0.08409 -0.42177]
20Nov22_214327|Layer 4:
20Nov22_214327|-- Config --
20Nov22_214327|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214327|-- Weights --
20Nov22_214327|[[-0.22220 -0.61256]
20Nov22_214327| [ 0.68089 -0.39853]]
20Nov22_214327|-- Bias --
20Nov22_214327|[ 0.98157 -0.27541]
20Nov22_214327|Layer 5:
20Nov22_214327|-- Config --
20Nov22_214327|{'name': 'Hidden6', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214327|-- Weights --
20Nov22_214327|[[ 0.45747  0.92311  0.29467 -0.28752]
20Nov22_214327| [-0.22606  0.57253  0.54464 -0.07998]]
20Nov22_214327|-- Bias --
20Nov22_214327|[ 0.08792 -0.47120  0.57435 -0.55291]
20Nov22_214327|Layer 6:
20Nov22_214327|-- Config --
20Nov22_214327|{'name': 'Hidden7', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214327|-- Weights --
20Nov22_214327|[[-0.97182  0.98846  0.95098  0.03687]
20Nov22_214327| [-0.99155  0.19867 -0.31042 -0.79984]
20Nov22_214327| [-0.06133  0.84421 -0.37525 -0.52847]
20Nov22_214327| [-0.19005 -0.18380 -0.62034 -0.44538]]
20Nov22_214327|-- Bias --
20Nov22_214327|[ 0.98163  0.78714 -0.19641  0.94613]
20Nov22_214327|Layer 7:
20Nov22_214327|-- Config --
20Nov22_214327|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214327|-- Weights --
20Nov22_214327|[[-0.43394 -1.28083]
20Nov22_214327| [-1.48533 -1.15640]
20Nov22_214327| [ 1.11545 -0.47869]
20Nov22_214327| [-0.34400  1.19318]]
20Nov22_214327|-- Bias --
20Nov22_214327|[1.87003 0.39544]
20Nov22_214327|Predicting the validation and test data with the Best final individual.
20Nov22_214335| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov22_214335|-----------  ------------------  --------------------  ----------
20Nov22_214335|Validation         21.91                 154            0.77625
20Nov22_214335|   Test            31.45                 154            0.76362
20Nov22_214335|-------------------------- Test #7 --------------------------
20Nov22_214335|Best final individual weights
20Nov22_214335|Individual:
20Nov22_214335|-- Constant hidden layers --
20Nov22_214335|False
20Nov22_214335|Layer 0:
20Nov22_214335|-- Config --
20Nov22_214335|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214335|-- Weights --
20Nov22_214335|[[ 0.07602 -0.83965  0.87180]
20Nov22_214335| [ 1.45890  0.86178  0.48983]
20Nov22_214335| [ 0.13198 -1.00734  0.82535]
20Nov22_214335| [ 0.03685  2.25842  1.27459]
20Nov22_214335| [-0.65976 -0.60462 -1.15016]
20Nov22_214335| [-1.40736  0.19479  0.02565]
20Nov22_214335| [-1.60734 -0.34618  0.79108]
20Nov22_214335| [-0.00765  0.20021  0.25913]
20Nov22_214335| [-0.04248 -0.25749 -0.94329]
20Nov22_214335| [ 1.61005  1.21931  1.65239]
20Nov22_214335| [-0.03761  0.55636  2.28794]
20Nov22_214335| [ 0.99758  0.55855 -0.71686]
20Nov22_214335| [ 0.32798  0.35272  0.30685]
20Nov22_214335| [-1.10455 -0.31879 -0.73875]
20Nov22_214335| [ 0.11895 -1.19352  0.74119]
20Nov22_214335| [ 0.83426 -1.34929  0.06396]
20Nov22_214335| [ 0.15006 -2.45478  1.70443]
20Nov22_214335| [-0.05668  0.59741 -0.34134]
20Nov22_214335| [ 0.32002 -0.54423  0.53588]
20Nov22_214335| [-0.01812 -0.84262  0.31989]
20Nov22_214335| [-0.38196  0.08123 -0.13108]
20Nov22_214335| [ 1.38123  1.57210 -0.99499]
20Nov22_214335| [ 1.85160  0.53786 -1.20392]
20Nov22_214335| [ 0.05701  0.67963  2.05135]
20Nov22_214335| [-0.09246 -1.79895  0.60417]
20Nov22_214335| [ 2.24605 -1.53357  0.14214]
20Nov22_214335| [ 0.69718 -0.42131  0.25613]
20Nov22_214335| [ 0.28769 -1.62005  0.36905]
20Nov22_214335| [-0.17885  1.27257  0.46466]
20Nov22_214335| [-1.39109  0.49067 -1.01535]
20Nov22_214335| [ 0.14804 -1.88582 -2.66067]
20Nov22_214335| [ 1.17326  0.24146 -0.39139]
20Nov22_214335| [ 0.39384  1.14256  0.09640]
20Nov22_214335| [ 0.05815  1.48059 -0.43854]
20Nov22_214335| [-0.42954 -1.54853 -1.97259]
20Nov22_214335| [-0.09207 -2.47425  0.03445]
20Nov22_214335| [-0.41718  0.43934  1.34817]
20Nov22_214335| [ 0.84986  0.35673 -0.43734]
20Nov22_214335| [ 1.47436  0.37182 -0.01283]
20Nov22_214335| [-1.06487  0.21861  0.50302]
20Nov22_214335| [-0.99576 -0.14656  1.27285]
20Nov22_214335| [-1.25165  0.36644  0.06431]
20Nov22_214335| [-0.30179 -0.50020  0.99284]
20Nov22_214335| [-0.42883  2.00908  1.70172]
20Nov22_214335| [ 1.44795  0.56861 -1.47182]
20Nov22_214335| [-2.12371  0.23565  0.12508]
20Nov22_214335| [-0.76739  0.76109 -0.51104]
20Nov22_214335| [-0.24939 -1.91051 -0.32771]
20Nov22_214335| [ 0.09604 -1.06803  0.25249]
20Nov22_214335| [ 0.69029 -1.41151 -1.45477]
20Nov22_214335| [-1.03477 -0.14404  0.28921]
20Nov22_214335| [ 1.29210 -0.56450 -0.17348]
20Nov22_214335| [ 0.74149  0.61467  0.88698]
20Nov22_214335| [-2.50133 -0.50198 -0.32709]
20Nov22_214335| [ 0.20918 -0.24368  0.66987]
20Nov22_214335| [-0.55190 -0.42397  0.71150]
20Nov22_214335| [-0.39862  0.23797  0.28748]]
20Nov22_214335|-- Bias --
20Nov22_214335|[ 0.09445 -0.10503  0.58928]
20Nov22_214335|Layer 1:
20Nov22_214335|-- Config --
20Nov22_214335|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214335|-- Weights --
20Nov22_214335|[[ 1.06275 -0.16865]
20Nov22_214335| [-0.52820  1.11843]
20Nov22_214335| [ 0.15968  0.67180]]
20Nov22_214335|-- Bias --
20Nov22_214335|[ 0.06388 -0.11557]
20Nov22_214335|Layer 2:
20Nov22_214335|-- Config --
20Nov22_214335|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214335|-- Weights --
20Nov22_214335|[[-1.06808 -0.31928  1.84373 -0.54443 -0.19449]
20Nov22_214335| [-0.13460 -0.54476 -0.72142 -1.21377  0.17061]]
20Nov22_214335|-- Bias --
20Nov22_214335|[ 1.37936  0.05983 -1.10689 -0.16738 -1.40784]
20Nov22_214335|Layer 3:
20Nov22_214335|-- Config --
20Nov22_214335|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214335|-- Weights --
20Nov22_214335|[[ 1.44608  0.23200]
20Nov22_214335| [ 0.45135 -0.38704]
20Nov22_214335| [ 1.22065  0.22361]
20Nov22_214335| [ 0.22627 -0.97342]
20Nov22_214335| [ 1.18723  0.38059]]
20Nov22_214335|-- Bias --
20Nov22_214335|[-0.08409 -0.42177]
20Nov22_214335|Layer 4:
20Nov22_214335|-- Config --
20Nov22_214335|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214335|-- Weights --
20Nov22_214335|[[-0.22220 -0.61256]
20Nov22_214335| [ 0.68089 -0.39853]]
20Nov22_214335|-- Bias --
20Nov22_214335|[ 0.98157 -0.27541]
20Nov22_214335|Layer 5:
20Nov22_214335|-- Config --
20Nov22_214335|{'name': 'Hidden6', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214335|-- Weights --
20Nov22_214335|[[ 0.45747  0.92311  0.29467 -0.28752]
20Nov22_214335| [-0.22606  0.57253  0.54464 -0.07998]]
20Nov22_214335|-- Bias --
20Nov22_214335|[ 0.08792 -0.47120  0.57435 -0.55291]
20Nov22_214335|Layer 6:
20Nov22_214335|-- Config --
20Nov22_214335|{'name': 'Hidden7', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214335|-- Weights --
20Nov22_214335|[[-0.97182  0.98846  0.95098  0.03687]
20Nov22_214335| [-0.99155  0.19867 -0.31042 -0.79984]
20Nov22_214335| [-0.06133  0.84421 -0.37525 -0.52847]
20Nov22_214335| [-0.19005 -0.18380 -0.62034 -0.44538]]
20Nov22_214335|-- Bias --
20Nov22_214335|[ 0.98163  0.78714 -0.19641  0.94613]
20Nov22_214335|Layer 7:
20Nov22_214335|-- Config --
20Nov22_214335|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214335|-- Weights --
20Nov22_214335|[[-0.43394 -1.28083]
20Nov22_214335| [-1.48533 -1.15640]
20Nov22_214335| [ 1.11545 -0.47869]
20Nov22_214335| [-0.34400  1.19318]]
20Nov22_214335|-- Bias --
20Nov22_214335|[1.87003 0.39544]
20Nov22_214335|Predicting the validation and test data with the Best final individual.
20Nov22_214343| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov22_214343|-----------  ------------------  --------------------  ----------
20Nov22_214343|Validation         25.30                 154            0.74597
20Nov22_214343|   Test            36.66                 154            0.00000
20Nov22_214343|-------------------------- Test #8 --------------------------
20Nov22_214343|Best final individual weights
20Nov22_214343|Individual:
20Nov22_214343|-- Constant hidden layers --
20Nov22_214343|False
20Nov22_214343|Layer 0:
20Nov22_214343|-- Config --
20Nov22_214343|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214343|-- Weights --
20Nov22_214343|[[ 0.07602 -0.83965  0.87180]
20Nov22_214343| [ 1.45890  0.86178  0.48983]
20Nov22_214343| [ 0.13198 -1.00734  0.82535]
20Nov22_214343| [ 0.03685  2.25842  1.27459]
20Nov22_214343| [-0.65976 -0.60462 -1.15016]
20Nov22_214343| [-1.40736  0.19479  0.02565]
20Nov22_214343| [-1.60734 -0.34618  0.79108]
20Nov22_214343| [-0.00765  0.20021  0.25913]
20Nov22_214343| [-0.04248 -0.25749 -0.94329]
20Nov22_214343| [ 1.61005  1.21931  1.65239]
20Nov22_214343| [-0.03761  0.55636  2.28794]
20Nov22_214343| [ 0.99758  0.55855 -0.71686]
20Nov22_214343| [ 0.32798  0.35272  0.30685]
20Nov22_214343| [-1.10455 -0.31879 -0.73875]
20Nov22_214343| [ 0.11895 -1.19352  0.74119]
20Nov22_214343| [ 0.83426 -1.34929  0.06396]
20Nov22_214343| [ 0.15006 -2.45478  1.70443]
20Nov22_214343| [-0.05668  0.59741 -0.34134]
20Nov22_214343| [ 0.32002 -0.54423  0.53588]
20Nov22_214343| [-0.01812 -0.84262  0.31989]
20Nov22_214343| [-0.38196  0.08123 -0.13108]
20Nov22_214343| [ 1.38123  1.57210 -0.99499]
20Nov22_214343| [ 1.85160  0.53786 -1.20392]
20Nov22_214343| [ 0.05701  0.67963  2.05135]
20Nov22_214343| [-0.09246 -1.79895  0.60417]
20Nov22_214343| [ 2.24605 -1.53357  0.14214]
20Nov22_214343| [ 0.69718 -0.42131  0.25613]
20Nov22_214343| [ 0.28769 -1.62005  0.36905]
20Nov22_214343| [-0.17885  1.27257  0.46466]
20Nov22_214343| [-1.39109  0.49067 -1.01535]
20Nov22_214343| [ 0.14804 -1.88582 -2.66067]
20Nov22_214343| [ 1.17326  0.24146 -0.39139]
20Nov22_214343| [ 0.39384  1.14256  0.09640]
20Nov22_214343| [ 0.05815  1.48059 -0.43854]
20Nov22_214343| [-0.42954 -1.54853 -1.97259]
20Nov22_214343| [-0.09207 -2.47425  0.03445]
20Nov22_214343| [-0.41718  0.43934  1.34817]
20Nov22_214343| [ 0.84986  0.35673 -0.43734]
20Nov22_214343| [ 1.47436  0.37182 -0.01283]
20Nov22_214343| [-1.06487  0.21861  0.50302]
20Nov22_214343| [-0.99576 -0.14656  1.27285]
20Nov22_214343| [-1.25165  0.36644  0.06431]
20Nov22_214343| [-0.30179 -0.50020  0.99284]
20Nov22_214343| [-0.42883  2.00908  1.70172]
20Nov22_214343| [ 1.44795  0.56861 -1.47182]
20Nov22_214343| [-2.12371  0.23565  0.12508]
20Nov22_214343| [-0.76739  0.76109 -0.51104]
20Nov22_214343| [-0.24939 -1.91051 -0.32771]
20Nov22_214343| [ 0.09604 -1.06803  0.25249]
20Nov22_214343| [ 0.69029 -1.41151 -1.45477]
20Nov22_214343| [-1.03477 -0.14404  0.28921]
20Nov22_214343| [ 1.29210 -0.56450 -0.17348]
20Nov22_214343| [ 0.74149  0.61467  0.88698]
20Nov22_214343| [-2.50133 -0.50198 -0.32709]
20Nov22_214343| [ 0.20918 -0.24368  0.66987]
20Nov22_214343| [-0.55190 -0.42397  0.71150]
20Nov22_214343| [-0.39862  0.23797  0.28748]]
20Nov22_214343|-- Bias --
20Nov22_214343|[ 0.09445 -0.10503  0.58928]
20Nov22_214343|Layer 1:
20Nov22_214343|-- Config --
20Nov22_214343|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214343|-- Weights --
20Nov22_214343|[[ 1.06275 -0.16865]
20Nov22_214343| [-0.52820  1.11843]
20Nov22_214343| [ 0.15968  0.67180]]
20Nov22_214343|-- Bias --
20Nov22_214343|[ 0.06388 -0.11557]
20Nov22_214343|Layer 2:
20Nov22_214343|-- Config --
20Nov22_214343|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214343|-- Weights --
20Nov22_214343|[[-1.06808 -0.31928  1.84373 -0.54443 -0.19449]
20Nov22_214343| [-0.13460 -0.54476 -0.72142 -1.21377  0.17061]]
20Nov22_214343|-- Bias --
20Nov22_214343|[ 1.37936  0.05983 -1.10689 -0.16738 -1.40784]
20Nov22_214343|Layer 3:
20Nov22_214343|-- Config --
20Nov22_214343|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214343|-- Weights --
20Nov22_214343|[[ 1.44608  0.23200]
20Nov22_214343| [ 0.45135 -0.38704]
20Nov22_214343| [ 1.22065  0.22361]
20Nov22_214343| [ 0.22627 -0.97342]
20Nov22_214343| [ 1.18723  0.38059]]
20Nov22_214343|-- Bias --
20Nov22_214343|[-0.08409 -0.42177]
20Nov22_214343|Layer 4:
20Nov22_214343|-- Config --
20Nov22_214343|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214343|-- Weights --
20Nov22_214343|[[-0.22220 -0.61256]
20Nov22_214343| [ 0.68089 -0.39853]]
20Nov22_214343|-- Bias --
20Nov22_214343|[ 0.98157 -0.27541]
20Nov22_214343|Layer 5:
20Nov22_214343|-- Config --
20Nov22_214343|{'name': 'Hidden6', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214343|-- Weights --
20Nov22_214343|[[ 0.45747  0.92311  0.29467 -0.28752]
20Nov22_214343| [-0.22606  0.57253  0.54464 -0.07998]]
20Nov22_214343|-- Bias --
20Nov22_214343|[ 0.08792 -0.47120  0.57435 -0.55291]
20Nov22_214343|Layer 6:
20Nov22_214343|-- Config --
20Nov22_214343|{'name': 'Hidden7', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214343|-- Weights --
20Nov22_214343|[[-0.97182  0.98846  0.95098  0.03687]
20Nov22_214343| [-0.99155  0.19867 -0.31042 -0.79984]
20Nov22_214343| [-0.06133  0.84421 -0.37525 -0.52847]
20Nov22_214343| [-0.19005 -0.18380 -0.62034 -0.44538]]
20Nov22_214343|-- Bias --
20Nov22_214343|[ 0.98163  0.78714 -0.19641  0.94613]
20Nov22_214343|Layer 7:
20Nov22_214343|-- Config --
20Nov22_214343|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214343|-- Weights --
20Nov22_214343|[[-0.43394 -1.28083]
20Nov22_214343| [-1.48533 -1.15640]
20Nov22_214343| [ 1.11545 -0.47869]
20Nov22_214343| [-0.34400  1.19318]]
20Nov22_214343|-- Bias --
20Nov22_214343|[1.87003 0.39544]
20Nov22_214343|Predicting the validation and test data with the Best final individual.
20Nov22_214351| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov22_214351|-----------  ------------------  --------------------  ----------
20Nov22_214351|Validation         28.87                 154            0.82550
20Nov22_214351|   Test            36.40                 154            0.00000
20Nov22_214351|-------------------------- Test #9 --------------------------
20Nov22_214351|Best final individual weights
20Nov22_214351|Individual:
20Nov22_214351|-- Constant hidden layers --
20Nov22_214351|False
20Nov22_214351|Layer 0:
20Nov22_214351|-- Config --
20Nov22_214351|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214351|-- Weights --
20Nov22_214351|[[ 0.07602 -0.83965  0.87180]
20Nov22_214351| [ 1.45890  0.86178  0.48983]
20Nov22_214351| [ 0.13198 -1.00734  0.82535]
20Nov22_214351| [ 0.03685  2.25842  1.27459]
20Nov22_214351| [-0.65976 -0.60462 -1.15016]
20Nov22_214351| [-1.40736  0.19479  0.02565]
20Nov22_214351| [-1.60734 -0.34618  0.79108]
20Nov22_214351| [-0.00765  0.20021  0.25913]
20Nov22_214351| [-0.04248 -0.25749 -0.94329]
20Nov22_214351| [ 1.61005  1.21931  1.65239]
20Nov22_214351| [-0.03761  0.55636  2.28794]
20Nov22_214351| [ 0.99758  0.55855 -0.71686]
20Nov22_214351| [ 0.32798  0.35272  0.30685]
20Nov22_214351| [-1.10455 -0.31879 -0.73875]
20Nov22_214351| [ 0.11895 -1.19352  0.74119]
20Nov22_214351| [ 0.83426 -1.34929  0.06396]
20Nov22_214351| [ 0.15006 -2.45478  1.70443]
20Nov22_214351| [-0.05668  0.59741 -0.34134]
20Nov22_214351| [ 0.32002 -0.54423  0.53588]
20Nov22_214351| [-0.01812 -0.84262  0.31989]
20Nov22_214351| [-0.38196  0.08123 -0.13108]
20Nov22_214351| [ 1.38123  1.57210 -0.99499]
20Nov22_214351| [ 1.85160  0.53786 -1.20392]
20Nov22_214351| [ 0.05701  0.67963  2.05135]
20Nov22_214351| [-0.09246 -1.79895  0.60417]
20Nov22_214351| [ 2.24605 -1.53357  0.14214]
20Nov22_214351| [ 0.69718 -0.42131  0.25613]
20Nov22_214351| [ 0.28769 -1.62005  0.36905]
20Nov22_214351| [-0.17885  1.27257  0.46466]
20Nov22_214351| [-1.39109  0.49067 -1.01535]
20Nov22_214351| [ 0.14804 -1.88582 -2.66067]
20Nov22_214351| [ 1.17326  0.24146 -0.39139]
20Nov22_214351| [ 0.39384  1.14256  0.09640]
20Nov22_214351| [ 0.05815  1.48059 -0.43854]
20Nov22_214351| [-0.42954 -1.54853 -1.97259]
20Nov22_214351| [-0.09207 -2.47425  0.03445]
20Nov22_214351| [-0.41718  0.43934  1.34817]
20Nov22_214351| [ 0.84986  0.35673 -0.43734]
20Nov22_214351| [ 1.47436  0.37182 -0.01283]
20Nov22_214351| [-1.06487  0.21861  0.50302]
20Nov22_214351| [-0.99576 -0.14656  1.27285]
20Nov22_214351| [-1.25165  0.36644  0.06431]
20Nov22_214351| [-0.30179 -0.50020  0.99284]
20Nov22_214351| [-0.42883  2.00908  1.70172]
20Nov22_214351| [ 1.44795  0.56861 -1.47182]
20Nov22_214351| [-2.12371  0.23565  0.12508]
20Nov22_214351| [-0.76739  0.76109 -0.51104]
20Nov22_214351| [-0.24939 -1.91051 -0.32771]
20Nov22_214351| [ 0.09604 -1.06803  0.25249]
20Nov22_214351| [ 0.69029 -1.41151 -1.45477]
20Nov22_214351| [-1.03477 -0.14404  0.28921]
20Nov22_214351| [ 1.29210 -0.56450 -0.17348]
20Nov22_214351| [ 0.74149  0.61467  0.88698]
20Nov22_214351| [-2.50133 -0.50198 -0.32709]
20Nov22_214351| [ 0.20918 -0.24368  0.66987]
20Nov22_214351| [-0.55190 -0.42397  0.71150]
20Nov22_214351| [-0.39862  0.23797  0.28748]]
20Nov22_214351|-- Bias --
20Nov22_214351|[ 0.09445 -0.10503  0.58928]
20Nov22_214351|Layer 1:
20Nov22_214351|-- Config --
20Nov22_214351|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214351|-- Weights --
20Nov22_214351|[[ 1.06275 -0.16865]
20Nov22_214351| [-0.52820  1.11843]
20Nov22_214351| [ 0.15968  0.67180]]
20Nov22_214351|-- Bias --
20Nov22_214351|[ 0.06388 -0.11557]
20Nov22_214351|Layer 2:
20Nov22_214351|-- Config --
20Nov22_214351|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214351|-- Weights --
20Nov22_214351|[[-1.06808 -0.31928  1.84373 -0.54443 -0.19449]
20Nov22_214351| [-0.13460 -0.54476 -0.72142 -1.21377  0.17061]]
20Nov22_214351|-- Bias --
20Nov22_214351|[ 1.37936  0.05983 -1.10689 -0.16738 -1.40784]
20Nov22_214351|Layer 3:
20Nov22_214351|-- Config --
20Nov22_214351|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214351|-- Weights --
20Nov22_214351|[[ 1.44608  0.23200]
20Nov22_214351| [ 0.45135 -0.38704]
20Nov22_214351| [ 1.22065  0.22361]
20Nov22_214351| [ 0.22627 -0.97342]
20Nov22_214351| [ 1.18723  0.38059]]
20Nov22_214351|-- Bias --
20Nov22_214351|[-0.08409 -0.42177]
20Nov22_214351|Layer 4:
20Nov22_214351|-- Config --
20Nov22_214351|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214351|-- Weights --
20Nov22_214351|[[-0.22220 -0.61256]
20Nov22_214351| [ 0.68089 -0.39853]]
20Nov22_214351|-- Bias --
20Nov22_214351|[ 0.98157 -0.27541]
20Nov22_214351|Layer 5:
20Nov22_214351|-- Config --
20Nov22_214351|{'name': 'Hidden6', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214351|-- Weights --
20Nov22_214351|[[ 0.45747  0.92311  0.29467 -0.28752]
20Nov22_214351| [-0.22606  0.57253  0.54464 -0.07998]]
20Nov22_214351|-- Bias --
20Nov22_214351|[ 0.08792 -0.47120  0.57435 -0.55291]
20Nov22_214351|Layer 6:
20Nov22_214351|-- Config --
20Nov22_214351|{'name': 'Hidden7', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214351|-- Weights --
20Nov22_214351|[[-0.97182  0.98846  0.95098  0.03687]
20Nov22_214351| [-0.99155  0.19867 -0.31042 -0.79984]
20Nov22_214351| [-0.06133  0.84421 -0.37525 -0.52847]
20Nov22_214351| [-0.19005 -0.18380 -0.62034 -0.44538]]
20Nov22_214351|-- Bias --
20Nov22_214351|[ 0.98163  0.78714 -0.19641  0.94613]
20Nov22_214351|Layer 7:
20Nov22_214351|-- Config --
20Nov22_214351|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214351|-- Weights --
20Nov22_214351|[[-0.43394 -1.28083]
20Nov22_214351| [-1.48533 -1.15640]
20Nov22_214351| [ 1.11545 -0.47869]
20Nov22_214351| [-0.34400  1.19318]]
20Nov22_214351|-- Bias --
20Nov22_214351|[1.87003 0.39544]
20Nov22_214351|Predicting the validation and test data with the Best final individual.
20Nov22_214359| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov22_214359|-----------  ------------------  --------------------  ----------
20Nov22_214359|Validation         27.83                 154            0.70443
20Nov22_214359|   Test            30.50                 154            0.35027
20Nov22_214359|-------------------------- Test #10 --------------------------
20Nov22_214359|Best final individual weights
20Nov22_214359|Individual:
20Nov22_214359|-- Constant hidden layers --
20Nov22_214359|False
20Nov22_214359|Layer 0:
20Nov22_214359|-- Config --
20Nov22_214359|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214359|-- Weights --
20Nov22_214359|[[ 0.07602 -0.83965  0.87180]
20Nov22_214359| [ 1.45890  0.86178  0.48983]
20Nov22_214359| [ 0.13198 -1.00734  0.82535]
20Nov22_214359| [ 0.03685  2.25842  1.27459]
20Nov22_214359| [-0.65976 -0.60462 -1.15016]
20Nov22_214359| [-1.40736  0.19479  0.02565]
20Nov22_214359| [-1.60734 -0.34618  0.79108]
20Nov22_214359| [-0.00765  0.20021  0.25913]
20Nov22_214359| [-0.04248 -0.25749 -0.94329]
20Nov22_214359| [ 1.61005  1.21931  1.65239]
20Nov22_214359| [-0.03761  0.55636  2.28794]
20Nov22_214359| [ 0.99758  0.55855 -0.71686]
20Nov22_214359| [ 0.32798  0.35272  0.30685]
20Nov22_214359| [-1.10455 -0.31879 -0.73875]
20Nov22_214359| [ 0.11895 -1.19352  0.74119]
20Nov22_214359| [ 0.83426 -1.34929  0.06396]
20Nov22_214359| [ 0.15006 -2.45478  1.70443]
20Nov22_214359| [-0.05668  0.59741 -0.34134]
20Nov22_214359| [ 0.32002 -0.54423  0.53588]
20Nov22_214359| [-0.01812 -0.84262  0.31989]
20Nov22_214359| [-0.38196  0.08123 -0.13108]
20Nov22_214359| [ 1.38123  1.57210 -0.99499]
20Nov22_214359| [ 1.85160  0.53786 -1.20392]
20Nov22_214359| [ 0.05701  0.67963  2.05135]
20Nov22_214359| [-0.09246 -1.79895  0.60417]
20Nov22_214359| [ 2.24605 -1.53357  0.14214]
20Nov22_214359| [ 0.69718 -0.42131  0.25613]
20Nov22_214359| [ 0.28769 -1.62005  0.36905]
20Nov22_214359| [-0.17885  1.27257  0.46466]
20Nov22_214359| [-1.39109  0.49067 -1.01535]
20Nov22_214359| [ 0.14804 -1.88582 -2.66067]
20Nov22_214359| [ 1.17326  0.24146 -0.39139]
20Nov22_214359| [ 0.39384  1.14256  0.09640]
20Nov22_214359| [ 0.05815  1.48059 -0.43854]
20Nov22_214359| [-0.42954 -1.54853 -1.97259]
20Nov22_214359| [-0.09207 -2.47425  0.03445]
20Nov22_214359| [-0.41718  0.43934  1.34817]
20Nov22_214359| [ 0.84986  0.35673 -0.43734]
20Nov22_214359| [ 1.47436  0.37182 -0.01283]
20Nov22_214359| [-1.06487  0.21861  0.50302]
20Nov22_214359| [-0.99576 -0.14656  1.27285]
20Nov22_214359| [-1.25165  0.36644  0.06431]
20Nov22_214359| [-0.30179 -0.50020  0.99284]
20Nov22_214359| [-0.42883  2.00908  1.70172]
20Nov22_214359| [ 1.44795  0.56861 -1.47182]
20Nov22_214359| [-2.12371  0.23565  0.12508]
20Nov22_214359| [-0.76739  0.76109 -0.51104]
20Nov22_214359| [-0.24939 -1.91051 -0.32771]
20Nov22_214359| [ 0.09604 -1.06803  0.25249]
20Nov22_214359| [ 0.69029 -1.41151 -1.45477]
20Nov22_214359| [-1.03477 -0.14404  0.28921]
20Nov22_214359| [ 1.29210 -0.56450 -0.17348]
20Nov22_214359| [ 0.74149  0.61467  0.88698]
20Nov22_214359| [-2.50133 -0.50198 -0.32709]
20Nov22_214359| [ 0.20918 -0.24368  0.66987]
20Nov22_214359| [-0.55190 -0.42397  0.71150]
20Nov22_214359| [-0.39862  0.23797  0.28748]]
20Nov22_214359|-- Bias --
20Nov22_214359|[ 0.09445 -0.10503  0.58928]
20Nov22_214359|Layer 1:
20Nov22_214359|-- Config --
20Nov22_214359|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214359|-- Weights --
20Nov22_214359|[[ 1.06275 -0.16865]
20Nov22_214359| [-0.52820  1.11843]
20Nov22_214359| [ 0.15968  0.67180]]
20Nov22_214359|-- Bias --
20Nov22_214359|[ 0.06388 -0.11557]
20Nov22_214359|Layer 2:
20Nov22_214359|-- Config --
20Nov22_214359|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214359|-- Weights --
20Nov22_214359|[[-1.06808 -0.31928  1.84373 -0.54443 -0.19449]
20Nov22_214359| [-0.13460 -0.54476 -0.72142 -1.21377  0.17061]]
20Nov22_214359|-- Bias --
20Nov22_214359|[ 1.37936  0.05983 -1.10689 -0.16738 -1.40784]
20Nov22_214359|Layer 3:
20Nov22_214359|-- Config --
20Nov22_214359|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214359|-- Weights --
20Nov22_214359|[[ 1.44608  0.23200]
20Nov22_214359| [ 0.45135 -0.38704]
20Nov22_214359| [ 1.22065  0.22361]
20Nov22_214359| [ 0.22627 -0.97342]
20Nov22_214359| [ 1.18723  0.38059]]
20Nov22_214359|-- Bias --
20Nov22_214359|[-0.08409 -0.42177]
20Nov22_214359|Layer 4:
20Nov22_214359|-- Config --
20Nov22_214359|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214359|-- Weights --
20Nov22_214359|[[-0.22220 -0.61256]
20Nov22_214359| [ 0.68089 -0.39853]]
20Nov22_214359|-- Bias --
20Nov22_214359|[ 0.98157 -0.27541]
20Nov22_214359|Layer 5:
20Nov22_214359|-- Config --
20Nov22_214359|{'name': 'Hidden6', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214359|-- Weights --
20Nov22_214359|[[ 0.45747  0.92311  0.29467 -0.28752]
20Nov22_214359| [-0.22606  0.57253  0.54464 -0.07998]]
20Nov22_214359|-- Bias --
20Nov22_214359|[ 0.08792 -0.47120  0.57435 -0.55291]
20Nov22_214359|Layer 6:
20Nov22_214359|-- Config --
20Nov22_214359|{'name': 'Hidden7', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214359|-- Weights --
20Nov22_214359|[[-0.97182  0.98846  0.95098  0.03687]
20Nov22_214359| [-0.99155  0.19867 -0.31042 -0.79984]
20Nov22_214359| [-0.06133  0.84421 -0.37525 -0.52847]
20Nov22_214359| [-0.19005 -0.18380 -0.62034 -0.44538]]
20Nov22_214359|-- Bias --
20Nov22_214359|[ 0.98163  0.78714 -0.19641  0.94613]
20Nov22_214359|Layer 7:
20Nov22_214359|-- Config --
20Nov22_214359|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214359|-- Weights --
20Nov22_214359|[[-0.43394 -1.28083]
20Nov22_214359| [-1.48533 -1.15640]
20Nov22_214359| [ 1.11545 -0.47869]
20Nov22_214359| [-0.34400  1.19318]]
20Nov22_214359|-- Bias --
20Nov22_214359|[1.87003 0.39544]
20Nov22_214359|Predicting the validation and test data with the Best final individual.
20Nov22_214407| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov22_214407|-----------  ------------------  --------------------  ----------
20Nov22_214407|Validation         28.00                 154            0.65751
20Nov22_214407|   Test            36.40                 154            0.00000
20Nov22_214407|-------------------------- Test #11 --------------------------
20Nov22_214407|Best final individual weights
20Nov22_214407|Individual:
20Nov22_214407|-- Constant hidden layers --
20Nov22_214407|False
20Nov22_214407|Layer 0:
20Nov22_214407|-- Config --
20Nov22_214407|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214407|-- Weights --
20Nov22_214407|[[ 0.07602 -0.83965  0.87180]
20Nov22_214407| [ 1.45890  0.86178  0.48983]
20Nov22_214407| [ 0.13198 -1.00734  0.82535]
20Nov22_214407| [ 0.03685  2.25842  1.27459]
20Nov22_214407| [-0.65976 -0.60462 -1.15016]
20Nov22_214407| [-1.40736  0.19479  0.02565]
20Nov22_214407| [-1.60734 -0.34618  0.79108]
20Nov22_214407| [-0.00765  0.20021  0.25913]
20Nov22_214407| [-0.04248 -0.25749 -0.94329]
20Nov22_214407| [ 1.61005  1.21931  1.65239]
20Nov22_214407| [-0.03761  0.55636  2.28794]
20Nov22_214407| [ 0.99758  0.55855 -0.71686]
20Nov22_214407| [ 0.32798  0.35272  0.30685]
20Nov22_214407| [-1.10455 -0.31879 -0.73875]
20Nov22_214407| [ 0.11895 -1.19352  0.74119]
20Nov22_214407| [ 0.83426 -1.34929  0.06396]
20Nov22_214407| [ 0.15006 -2.45478  1.70443]
20Nov22_214407| [-0.05668  0.59741 -0.34134]
20Nov22_214407| [ 0.32002 -0.54423  0.53588]
20Nov22_214407| [-0.01812 -0.84262  0.31989]
20Nov22_214407| [-0.38196  0.08123 -0.13108]
20Nov22_214407| [ 1.38123  1.57210 -0.99499]
20Nov22_214407| [ 1.85160  0.53786 -1.20392]
20Nov22_214407| [ 0.05701  0.67963  2.05135]
20Nov22_214407| [-0.09246 -1.79895  0.60417]
20Nov22_214407| [ 2.24605 -1.53357  0.14214]
20Nov22_214407| [ 0.69718 -0.42131  0.25613]
20Nov22_214407| [ 0.28769 -1.62005  0.36905]
20Nov22_214407| [-0.17885  1.27257  0.46466]
20Nov22_214407| [-1.39109  0.49067 -1.01535]
20Nov22_214407| [ 0.14804 -1.88582 -2.66067]
20Nov22_214407| [ 1.17326  0.24146 -0.39139]
20Nov22_214407| [ 0.39384  1.14256  0.09640]
20Nov22_214407| [ 0.05815  1.48059 -0.43854]
20Nov22_214407| [-0.42954 -1.54853 -1.97259]
20Nov22_214407| [-0.09207 -2.47425  0.03445]
20Nov22_214407| [-0.41718  0.43934  1.34817]
20Nov22_214407| [ 0.84986  0.35673 -0.43734]
20Nov22_214407| [ 1.47436  0.37182 -0.01283]
20Nov22_214407| [-1.06487  0.21861  0.50302]
20Nov22_214407| [-0.99576 -0.14656  1.27285]
20Nov22_214407| [-1.25165  0.36644  0.06431]
20Nov22_214407| [-0.30179 -0.50020  0.99284]
20Nov22_214407| [-0.42883  2.00908  1.70172]
20Nov22_214407| [ 1.44795  0.56861 -1.47182]
20Nov22_214407| [-2.12371  0.23565  0.12508]
20Nov22_214407| [-0.76739  0.76109 -0.51104]
20Nov22_214407| [-0.24939 -1.91051 -0.32771]
20Nov22_214407| [ 0.09604 -1.06803  0.25249]
20Nov22_214407| [ 0.69029 -1.41151 -1.45477]
20Nov22_214407| [-1.03477 -0.14404  0.28921]
20Nov22_214407| [ 1.29210 -0.56450 -0.17348]
20Nov22_214407| [ 0.74149  0.61467  0.88698]
20Nov22_214407| [-2.50133 -0.50198 -0.32709]
20Nov22_214407| [ 0.20918 -0.24368  0.66987]
20Nov22_214407| [-0.55190 -0.42397  0.71150]
20Nov22_214407| [-0.39862  0.23797  0.28748]]
20Nov22_214407|-- Bias --
20Nov22_214407|[ 0.09445 -0.10503  0.58928]
20Nov22_214407|Layer 1:
20Nov22_214407|-- Config --
20Nov22_214407|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214407|-- Weights --
20Nov22_214407|[[ 1.06275 -0.16865]
20Nov22_214407| [-0.52820  1.11843]
20Nov22_214407| [ 0.15968  0.67180]]
20Nov22_214407|-- Bias --
20Nov22_214407|[ 0.06388 -0.11557]
20Nov22_214407|Layer 2:
20Nov22_214407|-- Config --
20Nov22_214407|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214407|-- Weights --
20Nov22_214407|[[-1.06808 -0.31928  1.84373 -0.54443 -0.19449]
20Nov22_214407| [-0.13460 -0.54476 -0.72142 -1.21377  0.17061]]
20Nov22_214407|-- Bias --
20Nov22_214407|[ 1.37936  0.05983 -1.10689 -0.16738 -1.40784]
20Nov22_214407|Layer 3:
20Nov22_214407|-- Config --
20Nov22_214407|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214407|-- Weights --
20Nov22_214407|[[ 1.44608  0.23200]
20Nov22_214407| [ 0.45135 -0.38704]
20Nov22_214407| [ 1.22065  0.22361]
20Nov22_214407| [ 0.22627 -0.97342]
20Nov22_214407| [ 1.18723  0.38059]]
20Nov22_214407|-- Bias --
20Nov22_214407|[-0.08409 -0.42177]
20Nov22_214407|Layer 4:
20Nov22_214407|-- Config --
20Nov22_214407|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214407|-- Weights --
20Nov22_214407|[[-0.22220 -0.61256]
20Nov22_214407| [ 0.68089 -0.39853]]
20Nov22_214407|-- Bias --
20Nov22_214407|[ 0.98157 -0.27541]
20Nov22_214407|Layer 5:
20Nov22_214407|-- Config --
20Nov22_214407|{'name': 'Hidden6', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214407|-- Weights --
20Nov22_214407|[[ 0.45747  0.92311  0.29467 -0.28752]
20Nov22_214407| [-0.22606  0.57253  0.54464 -0.07998]]
20Nov22_214407|-- Bias --
20Nov22_214407|[ 0.08792 -0.47120  0.57435 -0.55291]
20Nov22_214407|Layer 6:
20Nov22_214407|-- Config --
20Nov22_214407|{'name': 'Hidden7', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214407|-- Weights --
20Nov22_214407|[[-0.97182  0.98846  0.95098  0.03687]
20Nov22_214407| [-0.99155  0.19867 -0.31042 -0.79984]
20Nov22_214407| [-0.06133  0.84421 -0.37525 -0.52847]
20Nov22_214407| [-0.19005 -0.18380 -0.62034 -0.44538]]
20Nov22_214407|-- Bias --
20Nov22_214407|[ 0.98163  0.78714 -0.19641  0.94613]
20Nov22_214407|Layer 7:
20Nov22_214407|-- Config --
20Nov22_214407|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214407|-- Weights --
20Nov22_214407|[[-0.43394 -1.28083]
20Nov22_214407| [-1.48533 -1.15640]
20Nov22_214407| [ 1.11545 -0.47869]
20Nov22_214407| [-0.34400  1.19318]]
20Nov22_214407|-- Bias --
20Nov22_214407|[1.87003 0.39544]
20Nov22_214407|Predicting the validation and test data with the Best final individual.
20Nov22_214415| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov22_214415|-----------  ------------------  --------------------  ----------
20Nov22_214415|Validation         27.30                 154            0.74332
20Nov22_214415|   Test            26.24                 154            0.81350
20Nov22_214415|-------------------------- Test #12 --------------------------
20Nov22_214415|Best final individual weights
20Nov22_214415|Individual:
20Nov22_214415|-- Constant hidden layers --
20Nov22_214415|False
20Nov22_214415|Layer 0:
20Nov22_214415|-- Config --
20Nov22_214415|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214415|-- Weights --
20Nov22_214415|[[ 0.07602 -0.83965  0.87180]
20Nov22_214415| [ 1.45890  0.86178  0.48983]
20Nov22_214415| [ 0.13198 -1.00734  0.82535]
20Nov22_214415| [ 0.03685  2.25842  1.27459]
20Nov22_214415| [-0.65976 -0.60462 -1.15016]
20Nov22_214415| [-1.40736  0.19479  0.02565]
20Nov22_214415| [-1.60734 -0.34618  0.79108]
20Nov22_214415| [-0.00765  0.20021  0.25913]
20Nov22_214415| [-0.04248 -0.25749 -0.94329]
20Nov22_214415| [ 1.61005  1.21931  1.65239]
20Nov22_214415| [-0.03761  0.55636  2.28794]
20Nov22_214415| [ 0.99758  0.55855 -0.71686]
20Nov22_214415| [ 0.32798  0.35272  0.30685]
20Nov22_214415| [-1.10455 -0.31879 -0.73875]
20Nov22_214415| [ 0.11895 -1.19352  0.74119]
20Nov22_214415| [ 0.83426 -1.34929  0.06396]
20Nov22_214415| [ 0.15006 -2.45478  1.70443]
20Nov22_214415| [-0.05668  0.59741 -0.34134]
20Nov22_214415| [ 0.32002 -0.54423  0.53588]
20Nov22_214415| [-0.01812 -0.84262  0.31989]
20Nov22_214415| [-0.38196  0.08123 -0.13108]
20Nov22_214415| [ 1.38123  1.57210 -0.99499]
20Nov22_214415| [ 1.85160  0.53786 -1.20392]
20Nov22_214415| [ 0.05701  0.67963  2.05135]
20Nov22_214415| [-0.09246 -1.79895  0.60417]
20Nov22_214415| [ 2.24605 -1.53357  0.14214]
20Nov22_214415| [ 0.69718 -0.42131  0.25613]
20Nov22_214415| [ 0.28769 -1.62005  0.36905]
20Nov22_214415| [-0.17885  1.27257  0.46466]
20Nov22_214415| [-1.39109  0.49067 -1.01535]
20Nov22_214415| [ 0.14804 -1.88582 -2.66067]
20Nov22_214415| [ 1.17326  0.24146 -0.39139]
20Nov22_214415| [ 0.39384  1.14256  0.09640]
20Nov22_214415| [ 0.05815  1.48059 -0.43854]
20Nov22_214415| [-0.42954 -1.54853 -1.97259]
20Nov22_214415| [-0.09207 -2.47425  0.03445]
20Nov22_214415| [-0.41718  0.43934  1.34817]
20Nov22_214415| [ 0.84986  0.35673 -0.43734]
20Nov22_214415| [ 1.47436  0.37182 -0.01283]
20Nov22_214415| [-1.06487  0.21861  0.50302]
20Nov22_214415| [-0.99576 -0.14656  1.27285]
20Nov22_214415| [-1.25165  0.36644  0.06431]
20Nov22_214415| [-0.30179 -0.50020  0.99284]
20Nov22_214415| [-0.42883  2.00908  1.70172]
20Nov22_214415| [ 1.44795  0.56861 -1.47182]
20Nov22_214415| [-2.12371  0.23565  0.12508]
20Nov22_214415| [-0.76739  0.76109 -0.51104]
20Nov22_214415| [-0.24939 -1.91051 -0.32771]
20Nov22_214415| [ 0.09604 -1.06803  0.25249]
20Nov22_214415| [ 0.69029 -1.41151 -1.45477]
20Nov22_214415| [-1.03477 -0.14404  0.28921]
20Nov22_214415| [ 1.29210 -0.56450 -0.17348]
20Nov22_214415| [ 0.74149  0.61467  0.88698]
20Nov22_214415| [-2.50133 -0.50198 -0.32709]
20Nov22_214415| [ 0.20918 -0.24368  0.66987]
20Nov22_214415| [-0.55190 -0.42397  0.71150]
20Nov22_214415| [-0.39862  0.23797  0.28748]]
20Nov22_214415|-- Bias --
20Nov22_214415|[ 0.09445 -0.10503  0.58928]
20Nov22_214415|Layer 1:
20Nov22_214415|-- Config --
20Nov22_214415|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214415|-- Weights --
20Nov22_214415|[[ 1.06275 -0.16865]
20Nov22_214415| [-0.52820  1.11843]
20Nov22_214415| [ 0.15968  0.67180]]
20Nov22_214415|-- Bias --
20Nov22_214415|[ 0.06388 -0.11557]
20Nov22_214415|Layer 2:
20Nov22_214415|-- Config --
20Nov22_214415|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214415|-- Weights --
20Nov22_214415|[[-1.06808 -0.31928  1.84373 -0.54443 -0.19449]
20Nov22_214415| [-0.13460 -0.54476 -0.72142 -1.21377  0.17061]]
20Nov22_214415|-- Bias --
20Nov22_214415|[ 1.37936  0.05983 -1.10689 -0.16738 -1.40784]
20Nov22_214415|Layer 3:
20Nov22_214415|-- Config --
20Nov22_214415|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214415|-- Weights --
20Nov22_214415|[[ 1.44608  0.23200]
20Nov22_214415| [ 0.45135 -0.38704]
20Nov22_214415| [ 1.22065  0.22361]
20Nov22_214415| [ 0.22627 -0.97342]
20Nov22_214415| [ 1.18723  0.38059]]
20Nov22_214415|-- Bias --
20Nov22_214415|[-0.08409 -0.42177]
20Nov22_214415|Layer 4:
20Nov22_214415|-- Config --
20Nov22_214415|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214415|-- Weights --
20Nov22_214415|[[-0.22220 -0.61256]
20Nov22_214415| [ 0.68089 -0.39853]]
20Nov22_214415|-- Bias --
20Nov22_214415|[ 0.98157 -0.27541]
20Nov22_214415|Layer 5:
20Nov22_214415|-- Config --
20Nov22_214415|{'name': 'Hidden6', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214415|-- Weights --
20Nov22_214415|[[ 0.45747  0.92311  0.29467 -0.28752]
20Nov22_214415| [-0.22606  0.57253  0.54464 -0.07998]]
20Nov22_214415|-- Bias --
20Nov22_214415|[ 0.08792 -0.47120  0.57435 -0.55291]
20Nov22_214415|Layer 6:
20Nov22_214415|-- Config --
20Nov22_214415|{'name': 'Hidden7', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214415|-- Weights --
20Nov22_214415|[[-0.97182  0.98846  0.95098  0.03687]
20Nov22_214415| [-0.99155  0.19867 -0.31042 -0.79984]
20Nov22_214415| [-0.06133  0.84421 -0.37525 -0.52847]
20Nov22_214415| [-0.19005 -0.18380 -0.62034 -0.44538]]
20Nov22_214415|-- Bias --
20Nov22_214415|[ 0.98163  0.78714 -0.19641  0.94613]
20Nov22_214415|Layer 7:
20Nov22_214415|-- Config --
20Nov22_214415|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214415|-- Weights --
20Nov22_214415|[[-0.43394 -1.28083]
20Nov22_214415| [-1.48533 -1.15640]
20Nov22_214415| [ 1.11545 -0.47869]
20Nov22_214415| [-0.34400  1.19318]]
20Nov22_214415|-- Bias --
20Nov22_214415|[1.87003 0.39544]
20Nov22_214415|Predicting the validation and test data with the Best final individual.
20Nov22_214423| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov22_214423|-----------  ------------------  --------------------  ----------
20Nov22_214423|Validation         38.17                 154            0.18400
20Nov22_214423|   Test            26.93                 154            0.65993
20Nov22_214423|-------------------------- Test #13 --------------------------
20Nov22_214423|Best final individual weights
20Nov22_214423|Individual:
20Nov22_214423|-- Constant hidden layers --
20Nov22_214423|False
20Nov22_214423|Layer 0:
20Nov22_214423|-- Config --
20Nov22_214423|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214423|-- Weights --
20Nov22_214423|[[ 0.07602 -0.83965  0.87180]
20Nov22_214423| [ 1.45890  0.86178  0.48983]
20Nov22_214423| [ 0.13198 -1.00734  0.82535]
20Nov22_214423| [ 0.03685  2.25842  1.27459]
20Nov22_214423| [-0.65976 -0.60462 -1.15016]
20Nov22_214423| [-1.40736  0.19479  0.02565]
20Nov22_214423| [-1.60734 -0.34618  0.79108]
20Nov22_214423| [-0.00765  0.20021  0.25913]
20Nov22_214423| [-0.04248 -0.25749 -0.94329]
20Nov22_214423| [ 1.61005  1.21931  1.65239]
20Nov22_214423| [-0.03761  0.55636  2.28794]
20Nov22_214423| [ 0.99758  0.55855 -0.71686]
20Nov22_214423| [ 0.32798  0.35272  0.30685]
20Nov22_214423| [-1.10455 -0.31879 -0.73875]
20Nov22_214423| [ 0.11895 -1.19352  0.74119]
20Nov22_214423| [ 0.83426 -1.34929  0.06396]
20Nov22_214423| [ 0.15006 -2.45478  1.70443]
20Nov22_214423| [-0.05668  0.59741 -0.34134]
20Nov22_214423| [ 0.32002 -0.54423  0.53588]
20Nov22_214423| [-0.01812 -0.84262  0.31989]
20Nov22_214423| [-0.38196  0.08123 -0.13108]
20Nov22_214423| [ 1.38123  1.57210 -0.99499]
20Nov22_214423| [ 1.85160  0.53786 -1.20392]
20Nov22_214423| [ 0.05701  0.67963  2.05135]
20Nov22_214423| [-0.09246 -1.79895  0.60417]
20Nov22_214423| [ 2.24605 -1.53357  0.14214]
20Nov22_214423| [ 0.69718 -0.42131  0.25613]
20Nov22_214423| [ 0.28769 -1.62005  0.36905]
20Nov22_214423| [-0.17885  1.27257  0.46466]
20Nov22_214423| [-1.39109  0.49067 -1.01535]
20Nov22_214423| [ 0.14804 -1.88582 -2.66067]
20Nov22_214423| [ 1.17326  0.24146 -0.39139]
20Nov22_214423| [ 0.39384  1.14256  0.09640]
20Nov22_214423| [ 0.05815  1.48059 -0.43854]
20Nov22_214423| [-0.42954 -1.54853 -1.97259]
20Nov22_214423| [-0.09207 -2.47425  0.03445]
20Nov22_214423| [-0.41718  0.43934  1.34817]
20Nov22_214423| [ 0.84986  0.35673 -0.43734]
20Nov22_214423| [ 1.47436  0.37182 -0.01283]
20Nov22_214423| [-1.06487  0.21861  0.50302]
20Nov22_214423| [-0.99576 -0.14656  1.27285]
20Nov22_214423| [-1.25165  0.36644  0.06431]
20Nov22_214423| [-0.30179 -0.50020  0.99284]
20Nov22_214423| [-0.42883  2.00908  1.70172]
20Nov22_214423| [ 1.44795  0.56861 -1.47182]
20Nov22_214423| [-2.12371  0.23565  0.12508]
20Nov22_214423| [-0.76739  0.76109 -0.51104]
20Nov22_214423| [-0.24939 -1.91051 -0.32771]
20Nov22_214423| [ 0.09604 -1.06803  0.25249]
20Nov22_214423| [ 0.69029 -1.41151 -1.45477]
20Nov22_214423| [-1.03477 -0.14404  0.28921]
20Nov22_214423| [ 1.29210 -0.56450 -0.17348]
20Nov22_214423| [ 0.74149  0.61467  0.88698]
20Nov22_214423| [-2.50133 -0.50198 -0.32709]
20Nov22_214423| [ 0.20918 -0.24368  0.66987]
20Nov22_214423| [-0.55190 -0.42397  0.71150]
20Nov22_214423| [-0.39862  0.23797  0.28748]]
20Nov22_214423|-- Bias --
20Nov22_214423|[ 0.09445 -0.10503  0.58928]
20Nov22_214423|Layer 1:
20Nov22_214423|-- Config --
20Nov22_214423|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214423|-- Weights --
20Nov22_214423|[[ 1.06275 -0.16865]
20Nov22_214423| [-0.52820  1.11843]
20Nov22_214423| [ 0.15968  0.67180]]
20Nov22_214423|-- Bias --
20Nov22_214423|[ 0.06388 -0.11557]
20Nov22_214423|Layer 2:
20Nov22_214423|-- Config --
20Nov22_214423|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214423|-- Weights --
20Nov22_214423|[[-1.06808 -0.31928  1.84373 -0.54443 -0.19449]
20Nov22_214423| [-0.13460 -0.54476 -0.72142 -1.21377  0.17061]]
20Nov22_214423|-- Bias --
20Nov22_214423|[ 1.37936  0.05983 -1.10689 -0.16738 -1.40784]
20Nov22_214423|Layer 3:
20Nov22_214423|-- Config --
20Nov22_214423|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214423|-- Weights --
20Nov22_214423|[[ 1.44608  0.23200]
20Nov22_214423| [ 0.45135 -0.38704]
20Nov22_214423| [ 1.22065  0.22361]
20Nov22_214423| [ 0.22627 -0.97342]
20Nov22_214423| [ 1.18723  0.38059]]
20Nov22_214423|-- Bias --
20Nov22_214423|[-0.08409 -0.42177]
20Nov22_214423|Layer 4:
20Nov22_214423|-- Config --
20Nov22_214423|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214423|-- Weights --
20Nov22_214423|[[-0.22220 -0.61256]
20Nov22_214423| [ 0.68089 -0.39853]]
20Nov22_214423|-- Bias --
20Nov22_214423|[ 0.98157 -0.27541]
20Nov22_214423|Layer 5:
20Nov22_214423|-- Config --
20Nov22_214423|{'name': 'Hidden6', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214423|-- Weights --
20Nov22_214423|[[ 0.45747  0.92311  0.29467 -0.28752]
20Nov22_214423| [-0.22606  0.57253  0.54464 -0.07998]]
20Nov22_214423|-- Bias --
20Nov22_214423|[ 0.08792 -0.47120  0.57435 -0.55291]
20Nov22_214423|Layer 6:
20Nov22_214423|-- Config --
20Nov22_214423|{'name': 'Hidden7', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214423|-- Weights --
20Nov22_214423|[[-0.97182  0.98846  0.95098  0.03687]
20Nov22_214423| [-0.99155  0.19867 -0.31042 -0.79984]
20Nov22_214423| [-0.06133  0.84421 -0.37525 -0.52847]
20Nov22_214423| [-0.19005 -0.18380 -0.62034 -0.44538]]
20Nov22_214423|-- Bias --
20Nov22_214423|[ 0.98163  0.78714 -0.19641  0.94613]
20Nov22_214423|Layer 7:
20Nov22_214423|-- Config --
20Nov22_214423|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214423|-- Weights --
20Nov22_214423|[[-0.43394 -1.28083]
20Nov22_214423| [-1.48533 -1.15640]
20Nov22_214423| [ 1.11545 -0.47869]
20Nov22_214423| [-0.34400  1.19318]]
20Nov22_214423|-- Bias --
20Nov22_214423|[1.87003 0.39544]
20Nov22_214423|Predicting the validation and test data with the Best final individual.
20Nov22_214432| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov22_214432|-----------  ------------------  --------------------  ----------
20Nov22_214432|Validation         27.48                 154            0.72862
20Nov22_214432|   Test            23.02                 154            0.61072
20Nov22_214432|-------------------------- Test #14 --------------------------
20Nov22_214432|Best final individual weights
20Nov22_214432|Individual:
20Nov22_214432|-- Constant hidden layers --
20Nov22_214432|False
20Nov22_214432|Layer 0:
20Nov22_214432|-- Config --
20Nov22_214432|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214432|-- Weights --
20Nov22_214432|[[ 0.07602 -0.83965  0.87180]
20Nov22_214432| [ 1.45890  0.86178  0.48983]
20Nov22_214432| [ 0.13198 -1.00734  0.82535]
20Nov22_214432| [ 0.03685  2.25842  1.27459]
20Nov22_214432| [-0.65976 -0.60462 -1.15016]
20Nov22_214432| [-1.40736  0.19479  0.02565]
20Nov22_214432| [-1.60734 -0.34618  0.79108]
20Nov22_214432| [-0.00765  0.20021  0.25913]
20Nov22_214432| [-0.04248 -0.25749 -0.94329]
20Nov22_214432| [ 1.61005  1.21931  1.65239]
20Nov22_214432| [-0.03761  0.55636  2.28794]
20Nov22_214432| [ 0.99758  0.55855 -0.71686]
20Nov22_214432| [ 0.32798  0.35272  0.30685]
20Nov22_214432| [-1.10455 -0.31879 -0.73875]
20Nov22_214432| [ 0.11895 -1.19352  0.74119]
20Nov22_214432| [ 0.83426 -1.34929  0.06396]
20Nov22_214432| [ 0.15006 -2.45478  1.70443]
20Nov22_214432| [-0.05668  0.59741 -0.34134]
20Nov22_214432| [ 0.32002 -0.54423  0.53588]
20Nov22_214432| [-0.01812 -0.84262  0.31989]
20Nov22_214432| [-0.38196  0.08123 -0.13108]
20Nov22_214432| [ 1.38123  1.57210 -0.99499]
20Nov22_214432| [ 1.85160  0.53786 -1.20392]
20Nov22_214432| [ 0.05701  0.67963  2.05135]
20Nov22_214432| [-0.09246 -1.79895  0.60417]
20Nov22_214432| [ 2.24605 -1.53357  0.14214]
20Nov22_214432| [ 0.69718 -0.42131  0.25613]
20Nov22_214432| [ 0.28769 -1.62005  0.36905]
20Nov22_214432| [-0.17885  1.27257  0.46466]
20Nov22_214432| [-1.39109  0.49067 -1.01535]
20Nov22_214432| [ 0.14804 -1.88582 -2.66067]
20Nov22_214432| [ 1.17326  0.24146 -0.39139]
20Nov22_214432| [ 0.39384  1.14256  0.09640]
20Nov22_214432| [ 0.05815  1.48059 -0.43854]
20Nov22_214432| [-0.42954 -1.54853 -1.97259]
20Nov22_214432| [-0.09207 -2.47425  0.03445]
20Nov22_214432| [-0.41718  0.43934  1.34817]
20Nov22_214432| [ 0.84986  0.35673 -0.43734]
20Nov22_214432| [ 1.47436  0.37182 -0.01283]
20Nov22_214432| [-1.06487  0.21861  0.50302]
20Nov22_214432| [-0.99576 -0.14656  1.27285]
20Nov22_214432| [-1.25165  0.36644  0.06431]
20Nov22_214432| [-0.30179 -0.50020  0.99284]
20Nov22_214432| [-0.42883  2.00908  1.70172]
20Nov22_214432| [ 1.44795  0.56861 -1.47182]
20Nov22_214432| [-2.12371  0.23565  0.12508]
20Nov22_214432| [-0.76739  0.76109 -0.51104]
20Nov22_214432| [-0.24939 -1.91051 -0.32771]
20Nov22_214432| [ 0.09604 -1.06803  0.25249]
20Nov22_214432| [ 0.69029 -1.41151 -1.45477]
20Nov22_214432| [-1.03477 -0.14404  0.28921]
20Nov22_214432| [ 1.29210 -0.56450 -0.17348]
20Nov22_214432| [ 0.74149  0.61467  0.88698]
20Nov22_214432| [-2.50133 -0.50198 -0.32709]
20Nov22_214432| [ 0.20918 -0.24368  0.66987]
20Nov22_214432| [-0.55190 -0.42397  0.71150]
20Nov22_214432| [-0.39862  0.23797  0.28748]]
20Nov22_214432|-- Bias --
20Nov22_214432|[ 0.09445 -0.10503  0.58928]
20Nov22_214432|Layer 1:
20Nov22_214432|-- Config --
20Nov22_214432|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214432|-- Weights --
20Nov22_214432|[[ 1.06275 -0.16865]
20Nov22_214432| [-0.52820  1.11843]
20Nov22_214432| [ 0.15968  0.67180]]
20Nov22_214432|-- Bias --
20Nov22_214432|[ 0.06388 -0.11557]
20Nov22_214432|Layer 2:
20Nov22_214432|-- Config --
20Nov22_214432|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214432|-- Weights --
20Nov22_214432|[[-1.06808 -0.31928  1.84373 -0.54443 -0.19449]
20Nov22_214432| [-0.13460 -0.54476 -0.72142 -1.21377  0.17061]]
20Nov22_214432|-- Bias --
20Nov22_214432|[ 1.37936  0.05983 -1.10689 -0.16738 -1.40784]
20Nov22_214432|Layer 3:
20Nov22_214432|-- Config --
20Nov22_214432|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214432|-- Weights --
20Nov22_214432|[[ 1.44608  0.23200]
20Nov22_214432| [ 0.45135 -0.38704]
20Nov22_214432| [ 1.22065  0.22361]
20Nov22_214432| [ 0.22627 -0.97342]
20Nov22_214432| [ 1.18723  0.38059]]
20Nov22_214432|-- Bias --
20Nov22_214432|[-0.08409 -0.42177]
20Nov22_214432|Layer 4:
20Nov22_214432|-- Config --
20Nov22_214432|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214432|-- Weights --
20Nov22_214432|[[-0.22220 -0.61256]
20Nov22_214432| [ 0.68089 -0.39853]]
20Nov22_214432|-- Bias --
20Nov22_214432|[ 0.98157 -0.27541]
20Nov22_214432|Layer 5:
20Nov22_214432|-- Config --
20Nov22_214432|{'name': 'Hidden6', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214432|-- Weights --
20Nov22_214432|[[ 0.45747  0.92311  0.29467 -0.28752]
20Nov22_214432| [-0.22606  0.57253  0.54464 -0.07998]]
20Nov22_214432|-- Bias --
20Nov22_214432|[ 0.08792 -0.47120  0.57435 -0.55291]
20Nov22_214432|Layer 6:
20Nov22_214432|-- Config --
20Nov22_214432|{'name': 'Hidden7', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214432|-- Weights --
20Nov22_214432|[[-0.97182  0.98846  0.95098  0.03687]
20Nov22_214432| [-0.99155  0.19867 -0.31042 -0.79984]
20Nov22_214432| [-0.06133  0.84421 -0.37525 -0.52847]
20Nov22_214432| [-0.19005 -0.18380 -0.62034 -0.44538]]
20Nov22_214432|-- Bias --
20Nov22_214432|[ 0.98163  0.78714 -0.19641  0.94613]
20Nov22_214432|Layer 7:
20Nov22_214432|-- Config --
20Nov22_214432|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_214432|-- Weights --
20Nov22_214432|[[-0.43394 -1.28083]
20Nov22_214432| [-1.48533 -1.15640]
20Nov22_214432| [ 1.11545 -0.47869]
20Nov22_214432| [-0.34400  1.19318]]
20Nov22_214432|-- Bias --
20Nov22_214432|[1.87003 0.39544]
20Nov22_214432|Predicting the validation and test data with the Best final individual.
20Nov22_214440| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov22_214440|-----------  ------------------  --------------------  ----------
20Nov22_214440|Validation         33.83                 154            0.38054
20Nov22_214440|   Test            25.11                 154            0.71396
Using Theano backend.
20Nov22_214441|Data summary: Train
20Nov22_214441|data.shape = (2300, 57)
20Nov22_214441|labels.shape = (2300,)
20Nov22_214441|Class distribution:
20Nov22_214441|	0 - 1389 (0.60)
20Nov22_214441|	1 - 911 (0.40)
20Nov22_214441|Data summary: Validation
20Nov22_214441|data.shape = (1150, 57)
20Nov22_214441|labels.shape = (1150,)
20Nov22_214441|Class distribution:
20Nov22_214441|	0 - 667 (0.58)
20Nov22_214441|	1 - 483 (0.42)
20Nov22_214441|Data summary: Test
20Nov22_214441|data.shape = (1151, 57)
20Nov22_214441|labels.shape = (1151,)
20Nov22_214441|Class distribution:
20Nov22_214441|	0 - 732 (0.64)
20Nov22_214441|	1 - 419 (0.36)
20Nov22_214441|Selected configuration values
20Nov22_214441|-- Dataset name: spambase2
20Nov22_214441|-- Initial population size: 64
20Nov22_214441|-- Maximun number of generations: 32
20Nov22_214441|-- Neurons per hidden layer range: (2, 20)
20Nov22_214441|-- Hidden layers number range: (1, 3)
20Nov22_214441|-- Crossover probability: 0.5
20Nov22_214441|-- Bias gene mutation probability: 0.2
20Nov22_214441|-- Weights gene mutation probability: 0.75
20Nov22_214441|-- Neuron mutation probability: 0.3
20Nov22_214441|-- Layer mutation probability: 0.3
20Nov22_214441|-- Constant hidden layers: False
20Nov22_214441|-- Seed: None
20Nov22_214441|Entering GA
20Nov22_214441|Start the algorithm
20Nov22_214800|-- Generation 1 --
20Nov22_214800|    -- Crossed 0 individual pairs.
20Nov22_214800|    -- Mutated 32 individuals.
20Nov22_215107|    -- Evaluated 64 individuals.
20Nov22_215107|    Summary of generation 1:
20Nov22_215107| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_215107|-----------  ------------------  --------------------  ----------
20Nov22_215107|    Max            57.57                81.00           0.78486
20Nov22_215107|    Avg            42.00                28.75           0.02329
20Nov22_215107|    Min            26.43                 2.00           0.00000
20Nov22_215107|    Std             2.75                22.77           0.12312
20Nov22_215107|   Best            26.43                34.00           0.62313
20Nov22_215107|-- Generation 2 --
20Nov22_215107|    -- Crossed 5 individual pairs.
20Nov22_215107|    -- Mutated 32 individuals.
20Nov22_215407|    -- Evaluated 64 individuals.
20Nov22_215407|    Summary of generation 2:
20Nov22_215407| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_215407|-----------  ------------------  --------------------  ----------
20Nov22_215407|    Max            42.70                93.00           0.60831
20Nov22_215407|    Avg            41.51                15.73           0.02651
20Nov22_215407|    Min            28.61                 2.00           0.00000
20Nov22_215407|    Std             2.31                15.58           0.10819
20Nov22_215407|   Best            28.61                 8.00           0.55215
20Nov22_215407|-- Generation 3 --
20Nov22_215407|    -- Crossed 3 individual pairs.
20Nov22_215407|    -- Mutated 32 individuals.
20Nov22_215708|    -- Evaluated 64 individuals.
20Nov22_215708|    Summary of generation 3:
20Nov22_215708| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_215708|-----------  ------------------  --------------------  ----------
20Nov22_215708|    Max            58.00                56.00           0.78358
20Nov22_215708|    Avg            41.69                13.83           0.03894
20Nov22_215708|    Min            27.57                 2.00           0.00000
20Nov22_215708|    Std             3.22                12.89           0.14942
20Nov22_215708|   Best            27.57                21.00           0.67713
20Nov22_215708|-- Generation 4 --
20Nov22_215708|    -- Crossed 5 individual pairs.
20Nov22_215708|    -- Mutated 32 individuals.
20Nov22_220007|    -- Evaluated 64 individuals.
20Nov22_220007|    Summary of generation 4:
20Nov22_220007| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_220007|-----------  ------------------  --------------------  ----------
20Nov22_220007|    Max            42.35                48.00           0.75836
20Nov22_220007|    Avg            40.76                11.17           0.06601
20Nov22_220007|    Min            26.17                 2.00           0.00000
20Nov22_220007|    Std             3.84                11.00           0.19205
20Nov22_220007|   Best            26.17                 8.00           0.75836
20Nov22_220007|-- Generation 5 --
20Nov22_220007|    -- Crossed 4 individual pairs.
20Nov22_220007|    -- Mutated 32 individuals.
20Nov22_220305|    -- Evaluated 64 individuals.
20Nov22_220305|    Summary of generation 5:
20Nov22_220305| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_220305|-----------  ------------------  --------------------  ----------
20Nov22_220305|    Max            42.09                50.00           0.78397
20Nov22_220305|    Avg            40.99                 9.66           0.04391
20Nov22_220305|    Min            24.35                 2.00           0.00000
20Nov22_220305|    Std             3.77                 9.90           0.16606
20Nov22_220305|   Best            24.35                12.00           0.77169
20Nov22_220305|-- Generation 6 --
20Nov22_220305|    -- Crossed 4 individual pairs.
20Nov22_220305|    -- Mutated 32 individuals.
20Nov22_220603|    -- Evaluated 64 individuals.
20Nov22_220603|    Summary of generation 6:
20Nov22_220603| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_220603|-----------  ------------------  --------------------  ----------
20Nov22_220603|    Max            42.52                50.00           0.64598
20Nov22_220603|    Avg            41.28                10.48           0.03159
20Nov22_220603|    Min            25.74                 2.00           0.00000
20Nov22_220603|    Std             3.03                12.08           0.13206
20Nov22_220603|   Best            25.74                21.00           0.64598
20Nov22_220603|-- Generation 7 --
20Nov22_220603|    -- Crossed 4 individual pairs.
20Nov22_220603|    -- Mutated 32 individuals.
20Nov22_220900|    -- Evaluated 64 individuals.
20Nov22_220900|    Summary of generation 7:
20Nov22_220900| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_220900|-----------  ------------------  --------------------  ----------
20Nov22_220900|    Max            42.17                48.00           0.66359
20Nov22_220900|    Avg            40.97                 8.72           0.04401
20Nov22_220900|    Min            25.74                 2.00           0.00000
20Nov22_220900|    Std             3.51                 8.13           0.14294
20Nov22_220900|   Best            25.74                24.00           0.66161
20Nov22_220900|-- Generation 8 --
20Nov22_220900|    -- Crossed 3 individual pairs.
20Nov22_220900|    -- Mutated 32 individuals.
20Nov22_221158|    -- Evaluated 64 individuals.
20Nov22_221158|    Summary of generation 8:
20Nov22_221158| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_221158|-----------  ------------------  --------------------  ----------
20Nov22_221158|    Max            42.96                39.00           0.77267
20Nov22_221158|    Avg            40.42                 9.64           0.07325
20Nov22_221158|    Min            25.65                 2.00           0.00000
20Nov22_221158|    Std             4.42                 7.49           0.20172
20Nov22_221158|   Best            25.65                24.00           0.66189
20Nov22_221158|-- Generation 9 --
20Nov22_221158|    -- Crossed 6 individual pairs.
20Nov22_221158|    -- Mutated 32 individuals.
20Nov22_221458|    -- Evaluated 64 individuals.
20Nov22_221458|    Summary of generation 9:
20Nov22_221458| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_221458|-----------  ------------------  --------------------  ----------
20Nov22_221458|    Max            42.26                30.00           0.72289
20Nov22_221458|    Avg            40.21                10.92           0.08378
20Nov22_221458|    Min            25.91                 2.00           0.00000
20Nov22_221458|    Std             4.60                 8.39           0.21088
20Nov22_221458|   Best            25.91                24.00           0.65484
20Nov22_221458|-- Generation 10 --
20Nov22_221458|    -- Crossed 5 individual pairs.
20Nov22_221458|    -- Mutated 32 individuals.
20Nov22_221758|    -- Evaluated 64 individuals.
20Nov22_221758|    Summary of generation 10:
20Nov22_221758| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_221758|-----------  ------------------  --------------------  ----------
20Nov22_221758|    Max            42.52                32.00           0.76953
20Nov22_221758|    Avg            39.39                10.25           0.11795
20Nov22_221758|    Min            25.65                 2.00           0.00000
20Nov22_221758|    Std             5.17                 8.92           0.23434
20Nov22_221758|   Best            25.65                21.00           0.66189
20Nov22_221758|-- Generation 11 --
20Nov22_221758|    -- Crossed 2 individual pairs.
20Nov22_221758|    -- Mutated 32 individuals.
20Nov22_222101|    -- Evaluated 64 individuals.
20Nov22_222101|    Summary of generation 11:
20Nov22_222101| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_222101|-----------  ------------------  --------------------  ----------
20Nov22_222101|    Max            42.61                40.00           0.74535
20Nov22_222101|    Avg            38.55                13.91           0.15181
20Nov22_222101|    Min            24.78                 2.00           0.00000
20Nov22_222101|    Std             5.98                 9.86           0.26443
20Nov22_222101|   Best            24.78                27.00           0.72190
20Nov22_222101|-- Generation 12 --
20Nov22_222101|    -- Crossed 2 individual pairs.
20Nov22_222101|    -- Mutated 32 individuals.
20Nov22_222405|    -- Evaluated 64 individuals.
20Nov22_222405|    Summary of generation 12:
20Nov22_222405| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_222405|-----------  ------------------  --------------------  ----------
20Nov22_222405|    Max            42.35                52.00           0.75645
20Nov22_222405|    Avg            38.10                14.14           0.17949
20Nov22_222405|    Min            25.57                 2.00           0.00000
20Nov22_222405|    Std             6.04                11.23           0.27192
20Nov22_222405|   Best            25.57                24.00           0.66372
20Nov22_222405|-- Generation 13 --
20Nov22_222405|    -- Crossed 2 individual pairs.
20Nov22_222405|    -- Mutated 32 individuals.
20Nov22_222712|    -- Evaluated 64 individuals.
20Nov22_222712|    Summary of generation 13:
20Nov22_222712| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_222712|-----------  ------------------  --------------------  ----------
20Nov22_222712|    Max            42.17                52.00           0.80698
20Nov22_222712|    Avg            36.38                16.52           0.27654
20Nov22_222712|    Min            25.57                 2.00           0.00000
20Nov22_222712|    Std             6.56                11.85           0.32067
20Nov22_222712|   Best            25.57                24.00           0.68362
20Nov22_222712|-- Generation 14 --
20Nov22_222712|    -- Crossed 2 individual pairs.
20Nov22_222712|    -- Mutated 32 individuals.
20Nov22_223027|    -- Evaluated 64 individuals.
20Nov22_223027|    Summary of generation 14:
20Nov22_223027| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_223027|-----------  ------------------  --------------------  ----------
20Nov22_223027|    Max            42.09                52.00           0.78927
20Nov22_223027|    Avg            34.53                23.83           0.35419
20Nov22_223027|    Min            24.70                 2.00           0.00000
20Nov22_223027|    Std             6.84                11.36           0.32685
20Nov22_223027|   Best            24.70                21.00           0.68800
20Nov22_223027|-- Generation 15 --
20Nov22_223027|    -- Crossed 0 individual pairs.
20Nov22_223027|    -- Mutated 32 individuals.
20Nov22_223348|    -- Evaluated 64 individuals.
20Nov22_223348|    Summary of generation 15:
20Nov22_223348| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_223348|-----------  ------------------  --------------------  ----------
20Nov22_223348|    Max            42.09                85.00           0.81209
20Nov22_223348|    Avg            34.24                30.89           0.38666
20Nov22_223348|    Min            25.91                10.00           0.00000
20Nov22_223348|    Std             6.65                13.34           0.32689
20Nov22_223348|   Best            25.91                21.00           0.69450
20Nov22_223348|-- Generation 16 --
20Nov22_223348|    -- Crossed 2 individual pairs.
20Nov22_223348|    -- Mutated 32 individuals.
20Nov22_223710|    -- Evaluated 64 individuals.
20Nov22_223710|    Summary of generation 16:
20Nov22_223710| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_223710|-----------  ------------------  --------------------  ----------
20Nov22_223710|    Max            42.17                90.00           0.80675
20Nov22_223710|    Avg            30.97                31.73           0.51406
20Nov22_223710|    Min            25.65                10.00           0.00000
20Nov22_223710|    Std             5.49                15.01           0.26331
20Nov22_223710|   Best            25.65                24.00           0.66653
20Nov22_223710|-- Generation 17 --
20Nov22_223710|    -- Crossed 2 individual pairs.
20Nov22_223710|    -- Mutated 32 individuals.
20Nov22_224033|    -- Evaluated 64 individuals.
20Nov22_224033|    Summary of generation 17:
20Nov22_224033| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_224033|-----------  ------------------  --------------------  ----------
20Nov22_224033|    Max            42.09                85.00           0.81184
20Nov22_224033|    Avg            32.16                33.56           0.44527
20Nov22_224033|    Min            24.87                 8.00           0.00000
20Nov22_224033|    Std             6.59                16.95           0.29759
20Nov22_224033|   Best            24.87                27.00           0.69796
20Nov22_224033|-- Generation 18 --
20Nov22_224033|    -- Crossed 1 individual pairs.
20Nov22_224033|    -- Mutated 32 individuals.
20Nov22_224357|    -- Evaluated 64 individuals.
20Nov22_224357|    Summary of generation 18:
20Nov22_224357| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_224357|-----------  ------------------  --------------------  ----------
20Nov22_224357|    Max            42.00                85.00           0.79377
20Nov22_224357|    Avg            32.39                36.06           0.42591
20Nov22_224357|    Min            25.13                10.00           0.00000
20Nov22_224357|    Std             6.95                17.92           0.30448
20Nov22_224357|   Best            25.13                44.00           0.71487
20Nov22_224357|-- Generation 19 --
20Nov22_224357|    -- Crossed 0 individual pairs.
20Nov22_224357|    -- Mutated 32 individuals.
20Nov22_224724|    -- Evaluated 64 individuals.
20Nov22_224724|    Summary of generation 19:
20Nov22_224724| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_224724|-----------  ------------------  --------------------  ----------
20Nov22_224724|    Max            42.00                90.00           0.81081
20Nov22_224724|    Avg            32.03                40.73           0.45360
20Nov22_224724|    Min            23.65                12.00           0.00000
20Nov22_224724|    Std             6.56                21.29           0.29261
20Nov22_224724|   Best            23.65                70.00           0.78654
20Nov22_224724|-- Generation 20 --
20Nov22_224724|    -- Crossed 0 individual pairs.
20Nov22_224724|    -- Mutated 32 individuals.
20Nov22_225047|    -- Evaluated 64 individuals.
20Nov22_225047|    Summary of generation 20:
20Nov22_225047| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_225047|-----------  ------------------  --------------------  ----------
20Nov22_225047|    Max            54.78                85.00           0.79198
20Nov22_225047|    Avg            32.69                36.83           0.43144
20Nov22_225047|    Min            25.57                 8.00           0.00000
20Nov22_225047|    Std             7.14                19.83           0.29529
20Nov22_225047|   Best            25.57                27.00           0.65906
20Nov22_225047|-- Generation 21 --
20Nov22_225047|    -- Crossed 1 individual pairs.
20Nov22_225047|    -- Mutated 32 individuals.
20Nov22_225408|    -- Evaluated 64 individuals.
20Nov22_225408|    Summary of generation 21:
20Nov22_225408| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_225408|-----------  ------------------  --------------------  ----------
20Nov22_225408|    Max            42.00                126.00          0.81449
20Nov22_225408|    Avg            30.10                38.70           0.54109
20Nov22_225408|    Min            24.96                 8.00           0.00000
20Nov22_225408|    Std             5.54                23.41           0.25176
20Nov22_225408|   Best            24.96                27.00           0.70066
20Nov22_225408|-- Generation 22 --
20Nov22_225408|    -- Crossed 1 individual pairs.
20Nov22_225408|    -- Mutated 32 individuals.
20Nov22_225733|    -- Evaluated 64 individuals.
20Nov22_225733|    Summary of generation 22:
20Nov22_225733| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_225733|-----------  ------------------  --------------------  ----------
20Nov22_225733|    Max            48.87                126.00          0.81579
20Nov22_225733|    Avg            31.32                39.45           0.49408
20Nov22_225733|    Min            23.74                10.00           0.00000
20Nov22_225733|    Std             6.72                23.11           0.28363
20Nov22_225733|   Best            23.74                24.00           0.74572
20Nov22_225733|-- Generation 23 --
20Nov22_225733|    -- Crossed 0 individual pairs.
20Nov22_225733|    -- Mutated 32 individuals.
20Nov22_230059|    -- Evaluated 64 individuals.
20Nov22_230059|    Summary of generation 23:
20Nov22_230059| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_230059|-----------  ------------------  --------------------  ----------
20Nov22_230059|    Max            42.17                126.00          0.80742
20Nov22_230059|    Avg            30.30                40.12           0.51820
20Nov22_230059|    Min            22.96                14.00           0.00000
20Nov22_230059|    Std             6.22                23.31           0.27694
20Nov22_230059|   Best            22.96                24.00           0.68615
20Nov22_230059|-- Generation 24 --
20Nov22_230059|    -- Crossed 0 individual pairs.
20Nov22_230059|    -- Mutated 32 individuals.
20Nov22_230421|    -- Evaluated 64 individuals.
20Nov22_230421|    Summary of generation 24:
20Nov22_230421| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_230421|-----------  ------------------  --------------------  ----------
20Nov22_230421|    Max            42.00                126.00          0.77909
20Nov22_230421|    Avg            32.59                36.75           0.42766
20Nov22_230421|    Min            21.13                 8.00           0.00000
20Nov22_230421|    Std             7.32                23.52           0.32795
20Nov22_230421|   Best            21.13                24.00           0.77909
20Nov22_230421|-- Generation 25 --
20Nov22_230421|    -- Crossed 3 individual pairs.
20Nov22_230421|    -- Mutated 32 individuals.
20Nov22_230741|    -- Evaluated 64 individuals.
20Nov22_230741|    Summary of generation 25:
20Nov22_230741| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_230741|-----------  ------------------  --------------------  ----------
20Nov22_230741|    Max            42.00                85.00           0.83140
20Nov22_230741|    Avg            32.51                33.69           0.41518
20Nov22_230741|    Min            23.74                10.00           0.00000
20Nov22_230741|    Std             7.28                15.67           0.31629
20Nov22_230741|   Best            23.74                24.00           0.83140
20Nov22_230741|-- Generation 26 --
20Nov22_230741|    -- Crossed 0 individual pairs.
20Nov22_230741|    -- Mutated 32 individuals.
20Nov22_231103|    -- Evaluated 64 individuals.
20Nov22_231103|    Summary of generation 26:
20Nov22_231103| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_231103|-----------  ------------------  --------------------  ----------
20Nov22_231103|    Max            42.09                75.00           0.83845
20Nov22_231103|    Avg            32.19                33.53           0.47571
20Nov22_231103|    Min            24.61                 8.00           0.00000
20Nov22_231103|    Std             6.89                14.58           0.32164
20Nov22_231103|   Best            24.61                33.00           0.83845
20Nov22_231103|-- Generation 27 --
20Nov22_231103|    -- Crossed 0 individual pairs.
20Nov22_231103|    -- Mutated 32 individuals.
20Nov22_231424|    -- Evaluated 64 individuals.
20Nov22_231424|    Summary of generation 27:
20Nov22_231424| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_231424|-----------  ------------------  --------------------  ----------
20Nov22_231424|    Max            42.00                75.00           0.80288
20Nov22_231424|    Avg            30.69                32.94           0.50260
20Nov22_231424|    Min            23.57                 8.00           0.00000
20Nov22_231424|    Std             6.41                13.75           0.28491
20Nov22_231424|   Best            23.57                24.00           0.73191
20Nov22_231424|-- Generation 28 --
20Nov22_231424|    -- Crossed 3 individual pairs.
20Nov22_231424|    -- Mutated 32 individuals.
20Nov22_231745|    -- Evaluated 64 individuals.
20Nov22_231745|    Summary of generation 28:
20Nov22_231745| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_231745|-----------  ------------------  --------------------  ----------
20Nov22_231745|    Max            42.09                80.00           0.78041
20Nov22_231745|    Avg            30.45                34.17           0.51145
20Nov22_231745|    Min            23.39                 8.00           0.00000
20Nov22_231745|    Std             6.23                15.05           0.27399
20Nov22_231745|   Best            23.39                24.00           0.73831
20Nov22_231745|-- Generation 29 --
20Nov22_231745|    -- Crossed 1 individual pairs.
20Nov22_231745|    -- Mutated 32 individuals.
20Nov22_232109|    -- Evaluated 64 individuals.
20Nov22_232109|    Summary of generation 29:
20Nov22_232109| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_232109|-----------  ------------------  --------------------  ----------
20Nov22_232109|    Max            43.39                80.00           0.80307
20Nov22_232109|    Avg            31.07                35.19           0.47161
20Nov22_232109|    Min            22.87                 8.00           0.00000
20Nov22_232109|    Std             6.82                14.69           0.28978
20Nov22_232109|   Best            22.87                24.00           0.67872
20Nov22_232109|-- Generation 30 --
20Nov22_232109|    -- Crossed 2 individual pairs.
20Nov22_232109|    -- Mutated 32 individuals.
20Nov22_232434|    -- Evaluated 64 individuals.
20Nov22_232434|    Summary of generation 30:
20Nov22_232434| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_232434|-----------  ------------------  --------------------  ----------
20Nov22_232434|    Max            42.00                75.00           0.79299
20Nov22_232434|    Avg            31.59                35.86           0.46346
20Nov22_232434|    Min            24.70                 8.00           0.00000
20Nov22_232434|    Std             6.90                14.45           0.30749
20Nov22_232434|   Best            24.70                24.00           0.78280
20Nov22_232434|-- Generation 31 --
20Nov22_232434|    -- Crossed 2 individual pairs.
20Nov22_232434|    -- Mutated 32 individuals.
20Nov22_232759|    -- Evaluated 64 individuals.
20Nov22_232759|    Summary of generation 31:
20Nov22_232759| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_232759|-----------  ------------------  --------------------  ----------
20Nov22_232759|    Max            42.09                90.00           0.79667
20Nov22_232759|    Avg            30.91                36.31           0.50528
20Nov22_232759|    Min            23.48                12.00           0.00000
20Nov22_232759|    Std             6.51                15.03           0.28656
20Nov22_232759|   Best            23.48                24.00           0.79667
20Nov22_232759|-- Generation 32 --
20Nov22_232759|    -- Crossed 1 individual pairs.
20Nov22_232759|    -- Mutated 32 individuals.
20Nov22_233123|    -- Evaluated 64 individuals.
20Nov22_233123|    Summary of generation 32:
20Nov22_233123| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_233123|-----------  ------------------  --------------------  ----------
20Nov22_233123|    Max            42.09                70.00           0.83120
20Nov22_233123|    Avg            30.85                36.30           0.52356
20Nov22_233123|    Min            24.61                 8.00           0.00000
20Nov22_233123|    Std             6.39                15.27           0.28941
20Nov22_233123|   Best            24.61                48.00           0.70481
20Nov22_233123|Best initial individual weights
20Nov22_233123|Individual:
20Nov22_233123|-- Constant hidden layers --
20Nov22_233123|False
20Nov22_233123|Layer 0:
20Nov22_233123|-- Config --
20Nov22_233123|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233123|-- Weights --
20Nov22_233123|[[ 0.94707  0.11218  0.13644  0.47226]
20Nov22_233123| [-0.64888 -0.22939  0.48687  0.20419]
20Nov22_233123| [-0.69554 -0.96970  0.11549 -0.35952]
20Nov22_233123| [ 0.03704 -0.81420  0.81847 -0.61662]
20Nov22_233123| [-0.10063  0.57483 -0.60856  0.73126]
20Nov22_233123| [ 0.35135  0.72419 -0.64762  0.81577]
20Nov22_233123| [-0.35632  0.02991 -0.00479 -0.39241]
20Nov22_233123| [ 0.16522 -0.30169 -0.79818 -0.66927]
20Nov22_233123| [-0.18491  0.86877  0.54555 -0.50848]
20Nov22_233123| [ 0.17297  0.25885 -0.25500  0.29303]
20Nov22_233123| [-0.21892 -0.26765  0.99204 -0.63949]
20Nov22_233123| [ 0.66846 -0.66752  0.09280 -0.90108]
20Nov22_233123| [-0.96491  0.83817 -0.31665 -0.35326]
20Nov22_233123| [-0.69980 -0.25713 -0.93564  0.89829]
20Nov22_233123| [-0.25626 -0.29870 -0.86967  0.36089]
20Nov22_233123| [ 0.29797 -0.32270  0.17809  0.61703]
20Nov22_233123| [-0.71195 -0.20867 -0.35586 -0.44291]
20Nov22_233123| [ 0.87423  0.80194 -0.18178  0.11410]
20Nov22_233123| [ 0.02085  0.48579  0.21665 -0.75903]
20Nov22_233123| [-0.84228  0.42468  0.99265  0.32883]
20Nov22_233123| [-0.10922 -0.48582  0.12653 -0.64037]
20Nov22_233123| [-0.29237  0.12545  0.89708  0.66784]
20Nov22_233123| [-0.97763 -0.14721 -0.67166  0.18326]
20Nov22_233123| [-0.31653  0.50018  0.49189  0.84435]
20Nov22_233123| [-0.03108  0.68827 -0.93460  0.74501]
20Nov22_233123| [ 0.70519  0.14596  0.72058 -0.91576]
20Nov22_233123| [ 0.53959 -0.21040 -0.82036 -0.67820]
20Nov22_233123| [-0.64375 -0.22297  0.29221  0.05029]
20Nov22_233123| [ 0.29887  0.96874 -0.62259  0.81367]
20Nov22_233123| [ 0.09447  0.43632 -0.42692 -0.38974]
20Nov22_233123| [ 0.42646  0.31660  0.03832 -0.88184]
20Nov22_233123| [ 0.97276  0.67722  0.45710  0.74137]
20Nov22_233123| [-0.41367  0.20730  0.50530  0.13095]
20Nov22_233123| [-0.25837 -0.62979 -0.68055 -0.20405]
20Nov22_233123| [ 0.91806  0.47690 -0.38243 -0.81902]
20Nov22_233123| [-0.78913 -0.77428 -0.06977 -0.38764]
20Nov22_233123| [-0.95558  0.40145 -0.76178  0.03308]
20Nov22_233123| [ 0.44646  0.93020 -0.45485  0.56497]
20Nov22_233123| [-0.51967  0.44533 -0.78903 -0.39060]
20Nov22_233123| [ 0.42324 -0.11297 -0.58462 -0.70651]
20Nov22_233123| [ 0.24887  0.35791 -0.07270 -0.24645]
20Nov22_233123| [-0.40422 -0.75190  0.80456  0.97931]
20Nov22_233123| [-0.46050  0.45140  0.20431 -0.72224]
20Nov22_233123| [-0.06106  0.91457  0.34363  0.14732]
20Nov22_233123| [-0.38936  0.17577  0.53225  0.91102]
20Nov22_233123| [ 0.73805 -0.38057  0.38996 -0.43654]
20Nov22_233123| [ 0.74070 -0.23069 -0.96953  0.23913]
20Nov22_233123| [-0.40542 -0.78904  0.45642 -0.31911]
20Nov22_233123| [ 0.02875 -0.98267 -0.44057 -0.50024]
20Nov22_233123| [ 0.29240 -0.62282 -0.95987  0.23199]
20Nov22_233123| [-0.23417 -0.48211 -0.60761  0.27881]
20Nov22_233123| [-0.54696  0.01489 -0.65886  0.17289]
20Nov22_233123| [ 0.08451  0.86462 -0.99449  0.71944]
20Nov22_233123| [ 0.49824  0.94496  0.61972 -0.25719]
20Nov22_233123| [-0.02228  0.79088 -0.28384  0.83903]
20Nov22_233123| [-0.07729 -0.34024  0.47788  0.47917]
20Nov22_233123| [ 0.31455  0.73850 -0.05142 -0.25923]]
20Nov22_233123|-- Bias --
20Nov22_233123|[ 0.70236 -0.02804  0.00776  0.80242]
20Nov22_233123|Layer 1:
20Nov22_233123|-- Config --
20Nov22_233123|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 16, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233123|-- Weights --
20Nov22_233123|[[ 0.33292  0.41195  0.05676  0.31088  0.53824  0.47210  0.36601  0.71014
20Nov22_233123|  -0.75899 -0.56186  0.19328  0.29416 -0.28803  0.81608  0.80686 -0.38815]
20Nov22_233123| [ 0.34552 -0.98132  0.92932  0.86633  0.91655  0.81957  0.40615 -0.95231
20Nov22_233123|  -0.21938 -0.57173  0.41094  0.69935 -0.85368 -0.34910  0.60613  0.33807]
20Nov22_233123| [-0.09226 -0.40996 -0.66956 -0.06202  0.15938 -0.91139  0.54869  0.25339
20Nov22_233123|  -0.87648 -0.84418  0.86011 -0.59749 -0.81232 -0.37940 -0.99074 -0.21305]
20Nov22_233123| [ 0.87861 -0.02798 -0.95523 -0.81569 -0.55970 -0.80374  0.66729  0.03412
20Nov22_233123|   0.85882 -0.82191 -0.35797 -0.18475  0.80886  0.35377  0.27760  0.74775]]
20Nov22_233123|-- Bias --
20Nov22_233123|[ 0.14481  0.90467 -0.48487  0.00404  0.72988 -0.90496  0.98490 -0.19782
20Nov22_233123| -0.45932  0.35885  0.58755 -0.39588 -0.32080 -0.23864 -0.13764 -0.46300]
20Nov22_233123|Layer 2:
20Nov22_233123|-- Config --
20Nov22_233123|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 16], 'dtype': 'float32', 'units': 7, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233123|-- Weights --
20Nov22_233123|[[ 0.88820 -0.79004 -0.27840  0.43042 -0.91624  0.69845  0.80136]
20Nov22_233123| [-0.17553 -0.59974  0.42204 -0.51274 -0.15066 -0.96933  0.47512]
20Nov22_233123| [-0.77599 -0.79449  0.54218 -0.23702  0.12244 -0.66899  0.07868]
20Nov22_233123| [-0.66668  0.48135 -0.45546  0.17075  0.40360  0.26799 -0.19618]
20Nov22_233123| [-0.71633 -0.00734 -0.11768 -0.14750  0.66065  0.57754 -0.52021]
20Nov22_233123| [-0.56756  0.47680 -0.02219 -0.85157 -0.50495 -0.71132  0.05782]
20Nov22_233123| [-0.07201 -0.65511 -0.83400 -0.57834  0.38211 -0.99278 -0.92244]
20Nov22_233123| [-0.28250 -0.20165  0.84051 -0.68031 -0.30456 -0.05555 -0.75725]
20Nov22_233123| [ 0.41839 -0.93698 -0.76905 -0.42258  0.31748 -0.06709 -0.44941]
20Nov22_233123| [ 0.97782  0.51337  0.06505 -0.33894 -0.51037 -0.16404  0.13207]
20Nov22_233123| [ 0.06278  0.29168 -0.14408  0.97409  0.25612  0.79203  0.64228]
20Nov22_233123| [ 0.99991  0.54166  0.14872  0.90637  0.36884 -0.76817  0.54544]
20Nov22_233123| [ 0.34135  0.80951  0.05134  0.19148 -0.95204  0.72087 -0.31200]
20Nov22_233123| [-0.27373  0.17106  0.14133 -0.39737  0.79588  0.50983 -0.68197]
20Nov22_233123| [ 0.23432 -0.41171 -0.92552  0.60932  0.94919  0.68599 -0.74958]
20Nov22_233123| [ 0.90736 -0.94084 -0.13470 -0.86972  0.59104 -0.11758  0.02685]]
20Nov22_233123|-- Bias --
20Nov22_233123|[ 0.08015 -0.62489 -0.38321  0.19914 -0.82782 -0.06125 -0.83533]
20Nov22_233123|Layer 3:
20Nov22_233123|-- Config --
20Nov22_233123|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 7], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233123|-- Weights --
20Nov22_233123|[[ 0.28491  0.79201]
20Nov22_233123| [-0.66335  0.86165]
20Nov22_233123| [-0.36057  0.34585]
20Nov22_233123| [-0.88412 -0.30035]
20Nov22_233123| [ 0.31699 -0.07607]
20Nov22_233123| [ 0.06608  0.38741]
20Nov22_233123| [-0.36927 -0.75556]]
20Nov22_233123|-- Bias --
20Nov22_233123|[0.55913 0.88209]
20Nov22_233123|Predicting the validation and test data with the Best initial individual.
20Nov22_233130| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov22_233130|-----------  ------------------  --------------------  ----------
20Nov22_233130|Validation         42.00                  81            0.00000
20Nov22_233130|   Test            26.41                  81            0.43409
20Nov22_233130|-------------------------- Test #0 --------------------------
20Nov22_233130|Best final individual weights
20Nov22_233130|Individual:
20Nov22_233130|-- Constant hidden layers --
20Nov22_233130|False
20Nov22_233130|Layer 0:
20Nov22_233130|-- Config --
20Nov22_233130|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233130|-- Weights --
20Nov22_233130|[[ 0.31067  1.04208]
20Nov22_233130| [ 1.22299  0.01432]
20Nov22_233130| [ 0.79550 -0.40760]
20Nov22_233130| [-2.16624 -1.88313]
20Nov22_233130| [ 0.87286  0.94682]
20Nov22_233130| [ 0.66090  1.36365]
20Nov22_233130| [-0.84894  1.51297]
20Nov22_233130| [-1.42130  1.96017]
20Nov22_233130| [ 0.00894 -0.06965]
20Nov22_233130| [ 1.85177 -0.74199]
20Nov22_233130| [-0.97319 -0.63846]
20Nov22_233130| [-0.48237  1.76131]
20Nov22_233130| [ 0.39013  0.25550]
20Nov22_233130| [-0.75703  0.89261]
20Nov22_233130| [-0.42042  1.00725]
20Nov22_233130| [-0.34138  0.17486]
20Nov22_233130| [ 0.88943 -0.46901]
20Nov22_233130| [-0.74247 -0.29372]
20Nov22_233130| [-0.54323 -1.79078]
20Nov22_233130| [-0.79119 -0.42149]
20Nov22_233130| [-1.87179  0.15971]
20Nov22_233130| [ 0.56242  0.52523]
20Nov22_233130| [-0.41700  0.14775]
20Nov22_233130| [ 2.08280 -1.92186]
20Nov22_233130| [ 0.13396  0.59688]
20Nov22_233130| [-0.29457  1.13513]
20Nov22_233130| [ 0.47883 -0.59367]
20Nov22_233130| [ 0.33787  0.69830]
20Nov22_233130| [-0.18090 -0.42958]
20Nov22_233130| [-1.07236 -0.94238]
20Nov22_233130| [-0.39442  0.07831]
20Nov22_233130| [-0.21956  0.71195]
20Nov22_233130| [ 1.79392 -0.48642]
20Nov22_233130| [-0.36856  0.09153]
20Nov22_233130| [-0.12850 -0.24442]
20Nov22_233130| [ 0.39517  0.11028]
20Nov22_233130| [-0.25405  0.32680]
20Nov22_233130| [ 0.71828 -0.70769]
20Nov22_233130| [ 1.22261  0.52275]
20Nov22_233130| [ 0.73888  0.58055]
20Nov22_233130| [-1.34521 -0.45328]
20Nov22_233130| [ 1.26344 -0.48773]
20Nov22_233130| [-0.73363  0.98363]
20Nov22_233130| [ 0.15762  0.47715]
20Nov22_233130| [ 0.04322  2.38047]
20Nov22_233130| [ 0.22812 -1.56141]
20Nov22_233130| [ 0.95421  1.59583]
20Nov22_233130| [-0.44250  0.33349]
20Nov22_233130| [ 1.05130 -0.41546]
20Nov22_233130| [ 1.39962 -1.22635]
20Nov22_233130| [ 0.24162 -0.05621]
20Nov22_233130| [-0.23985 -1.06417]
20Nov22_233130| [-0.05211  0.68172]
20Nov22_233130| [ 0.28536  2.37729]
20Nov22_233130| [-0.51275 -0.81888]
20Nov22_233130| [-0.68859  1.75815]
20Nov22_233130| [-0.11612 -0.06331]]
20Nov22_233130|-- Bias --
20Nov22_233130|[0.72775 0.20467]
20Nov22_233130|Layer 1:
20Nov22_233130|-- Config --
20Nov22_233130|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233130|-- Weights --
20Nov22_233130|[[ 1.70886 -1.05378]
20Nov22_233130| [-1.05881  0.40379]]
20Nov22_233130|-- Bias --
20Nov22_233130|[-1.26979  0.64071]
20Nov22_233130|Layer 2:
20Nov22_233130|-- Config --
20Nov22_233130|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233130|-- Weights --
20Nov22_233130|[[ 1.13276 -0.19138  0.72299 -0.82235]
20Nov22_233130| [ 0.64675  0.16087 -1.97330  0.51762]]
20Nov22_233130|-- Bias --
20Nov22_233130|[ 0.89711 -0.39996  1.01868  0.39897]
20Nov22_233130|Layer 3:
20Nov22_233130|-- Config --
20Nov22_233130|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233130|-- Weights --
20Nov22_233130|[[ 0.32156  0.32873 -0.08875  0.41462]
20Nov22_233130| [-0.84923  0.88443 -0.12856  0.14256]
20Nov22_233130| [ 1.22213  1.14350 -0.11814  0.15883]
20Nov22_233130| [ 0.26940 -0.37695 -0.50873 -0.17207]]
20Nov22_233130|-- Bias --
20Nov22_233130|[ 0.89054  0.79647 -0.41753  0.26091]
20Nov22_233130|Layer 4:
20Nov22_233130|-- Config --
20Nov22_233130|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233130|-- Weights --
20Nov22_233130|[[ 0.03632 -1.06797]
20Nov22_233130| [ 0.30684  1.00972]
20Nov22_233130| [-1.27764  0.99457]
20Nov22_233130| [-0.33613 -0.12665]]
20Nov22_233130|-- Bias --
20Nov22_233130|[-0.70391 -0.35113]
20Nov22_233130|Predicting the validation and test data with the Best final individual.
20Nov22_233136| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov22_233136|-----------  ------------------  --------------------  ----------
20Nov22_233136|Validation         25.83                  48            0.65042
20Nov22_233136|   Test            36.40                  48            0.00000
20Nov22_233136|-------------------------- Test #1 --------------------------
20Nov22_233136|Best final individual weights
20Nov22_233136|Individual:
20Nov22_233136|-- Constant hidden layers --
20Nov22_233136|False
20Nov22_233136|Layer 0:
20Nov22_233136|-- Config --
20Nov22_233136|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233136|-- Weights --
20Nov22_233136|[[ 0.31067  1.04208]
20Nov22_233136| [ 1.22299  0.01432]
20Nov22_233136| [ 0.79550 -0.40760]
20Nov22_233136| [-2.16624 -1.88313]
20Nov22_233136| [ 0.87286  0.94682]
20Nov22_233136| [ 0.66090  1.36365]
20Nov22_233136| [-0.84894  1.51297]
20Nov22_233136| [-1.42130  1.96017]
20Nov22_233136| [ 0.00894 -0.06965]
20Nov22_233136| [ 1.85177 -0.74199]
20Nov22_233136| [-0.97319 -0.63846]
20Nov22_233136| [-0.48237  1.76131]
20Nov22_233136| [ 0.39013  0.25550]
20Nov22_233136| [-0.75703  0.89261]
20Nov22_233136| [-0.42042  1.00725]
20Nov22_233136| [-0.34138  0.17486]
20Nov22_233136| [ 0.88943 -0.46901]
20Nov22_233136| [-0.74247 -0.29372]
20Nov22_233136| [-0.54323 -1.79078]
20Nov22_233136| [-0.79119 -0.42149]
20Nov22_233136| [-1.87179  0.15971]
20Nov22_233136| [ 0.56242  0.52523]
20Nov22_233136| [-0.41700  0.14775]
20Nov22_233136| [ 2.08280 -1.92186]
20Nov22_233136| [ 0.13396  0.59688]
20Nov22_233136| [-0.29457  1.13513]
20Nov22_233136| [ 0.47883 -0.59367]
20Nov22_233136| [ 0.33787  0.69830]
20Nov22_233136| [-0.18090 -0.42958]
20Nov22_233136| [-1.07236 -0.94238]
20Nov22_233136| [-0.39442  0.07831]
20Nov22_233136| [-0.21956  0.71195]
20Nov22_233136| [ 1.79392 -0.48642]
20Nov22_233136| [-0.36856  0.09153]
20Nov22_233136| [-0.12850 -0.24442]
20Nov22_233136| [ 0.39517  0.11028]
20Nov22_233136| [-0.25405  0.32680]
20Nov22_233136| [ 0.71828 -0.70769]
20Nov22_233136| [ 1.22261  0.52275]
20Nov22_233136| [ 0.73888  0.58055]
20Nov22_233136| [-1.34521 -0.45328]
20Nov22_233136| [ 1.26344 -0.48773]
20Nov22_233136| [-0.73363  0.98363]
20Nov22_233136| [ 0.15762  0.47715]
20Nov22_233136| [ 0.04322  2.38047]
20Nov22_233136| [ 0.22812 -1.56141]
20Nov22_233136| [ 0.95421  1.59583]
20Nov22_233136| [-0.44250  0.33349]
20Nov22_233136| [ 1.05130 -0.41546]
20Nov22_233136| [ 1.39962 -1.22635]
20Nov22_233136| [ 0.24162 -0.05621]
20Nov22_233136| [-0.23985 -1.06417]
20Nov22_233136| [-0.05211  0.68172]
20Nov22_233136| [ 0.28536  2.37729]
20Nov22_233136| [-0.51275 -0.81888]
20Nov22_233136| [-0.68859  1.75815]
20Nov22_233136| [-0.11612 -0.06331]]
20Nov22_233136|-- Bias --
20Nov22_233136|[0.72775 0.20467]
20Nov22_233136|Layer 1:
20Nov22_233136|-- Config --
20Nov22_233136|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233136|-- Weights --
20Nov22_233136|[[ 1.70886 -1.05378]
20Nov22_233136| [-1.05881  0.40379]]
20Nov22_233136|-- Bias --
20Nov22_233136|[-1.26979  0.64071]
20Nov22_233136|Layer 2:
20Nov22_233136|-- Config --
20Nov22_233136|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233136|-- Weights --
20Nov22_233136|[[ 1.13276 -0.19138  0.72299 -0.82235]
20Nov22_233136| [ 0.64675  0.16087 -1.97330  0.51762]]
20Nov22_233136|-- Bias --
20Nov22_233136|[ 0.89711 -0.39996  1.01868  0.39897]
20Nov22_233136|Layer 3:
20Nov22_233136|-- Config --
20Nov22_233136|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233136|-- Weights --
20Nov22_233136|[[ 0.32156  0.32873 -0.08875  0.41462]
20Nov22_233136| [-0.84923  0.88443 -0.12856  0.14256]
20Nov22_233136| [ 1.22213  1.14350 -0.11814  0.15883]
20Nov22_233136| [ 0.26940 -0.37695 -0.50873 -0.17207]]
20Nov22_233136|-- Bias --
20Nov22_233136|[ 0.89054  0.79647 -0.41753  0.26091]
20Nov22_233136|Layer 4:
20Nov22_233136|-- Config --
20Nov22_233136|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233136|-- Weights --
20Nov22_233136|[[ 0.03632 -1.06797]
20Nov22_233136| [ 0.30684  1.00972]
20Nov22_233136| [-1.27764  0.99457]
20Nov22_233136| [-0.33613 -0.12665]]
20Nov22_233136|-- Bias --
20Nov22_233136|[-0.70391 -0.35113]
20Nov22_233136|Predicting the validation and test data with the Best final individual.
20Nov22_233143| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov22_233143|-----------  ------------------  --------------------  ----------
20Nov22_233143|Validation         42.00                  48            0.00000
20Nov22_233143|   Test            26.59                  48            0.57985
20Nov22_233143|-------------------------- Test #2 --------------------------
20Nov22_233143|Best final individual weights
20Nov22_233143|Individual:
20Nov22_233143|-- Constant hidden layers --
20Nov22_233143|False
20Nov22_233143|Layer 0:
20Nov22_233143|-- Config --
20Nov22_233143|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233143|-- Weights --
20Nov22_233143|[[ 0.31067  1.04208]
20Nov22_233143| [ 1.22299  0.01432]
20Nov22_233143| [ 0.79550 -0.40760]
20Nov22_233143| [-2.16624 -1.88313]
20Nov22_233143| [ 0.87286  0.94682]
20Nov22_233143| [ 0.66090  1.36365]
20Nov22_233143| [-0.84894  1.51297]
20Nov22_233143| [-1.42130  1.96017]
20Nov22_233143| [ 0.00894 -0.06965]
20Nov22_233143| [ 1.85177 -0.74199]
20Nov22_233143| [-0.97319 -0.63846]
20Nov22_233143| [-0.48237  1.76131]
20Nov22_233143| [ 0.39013  0.25550]
20Nov22_233143| [-0.75703  0.89261]
20Nov22_233143| [-0.42042  1.00725]
20Nov22_233143| [-0.34138  0.17486]
20Nov22_233143| [ 0.88943 -0.46901]
20Nov22_233143| [-0.74247 -0.29372]
20Nov22_233143| [-0.54323 -1.79078]
20Nov22_233143| [-0.79119 -0.42149]
20Nov22_233143| [-1.87179  0.15971]
20Nov22_233143| [ 0.56242  0.52523]
20Nov22_233143| [-0.41700  0.14775]
20Nov22_233143| [ 2.08280 -1.92186]
20Nov22_233143| [ 0.13396  0.59688]
20Nov22_233143| [-0.29457  1.13513]
20Nov22_233143| [ 0.47883 -0.59367]
20Nov22_233143| [ 0.33787  0.69830]
20Nov22_233143| [-0.18090 -0.42958]
20Nov22_233143| [-1.07236 -0.94238]
20Nov22_233143| [-0.39442  0.07831]
20Nov22_233143| [-0.21956  0.71195]
20Nov22_233143| [ 1.79392 -0.48642]
20Nov22_233143| [-0.36856  0.09153]
20Nov22_233143| [-0.12850 -0.24442]
20Nov22_233143| [ 0.39517  0.11028]
20Nov22_233143| [-0.25405  0.32680]
20Nov22_233143| [ 0.71828 -0.70769]
20Nov22_233143| [ 1.22261  0.52275]
20Nov22_233143| [ 0.73888  0.58055]
20Nov22_233143| [-1.34521 -0.45328]
20Nov22_233143| [ 1.26344 -0.48773]
20Nov22_233143| [-0.73363  0.98363]
20Nov22_233143| [ 0.15762  0.47715]
20Nov22_233143| [ 0.04322  2.38047]
20Nov22_233143| [ 0.22812 -1.56141]
20Nov22_233143| [ 0.95421  1.59583]
20Nov22_233143| [-0.44250  0.33349]
20Nov22_233143| [ 1.05130 -0.41546]
20Nov22_233143| [ 1.39962 -1.22635]
20Nov22_233143| [ 0.24162 -0.05621]
20Nov22_233143| [-0.23985 -1.06417]
20Nov22_233143| [-0.05211  0.68172]
20Nov22_233143| [ 0.28536  2.37729]
20Nov22_233143| [-0.51275 -0.81888]
20Nov22_233143| [-0.68859  1.75815]
20Nov22_233143| [-0.11612 -0.06331]]
20Nov22_233143|-- Bias --
20Nov22_233143|[0.72775 0.20467]
20Nov22_233143|Layer 1:
20Nov22_233143|-- Config --
20Nov22_233143|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233143|-- Weights --
20Nov22_233143|[[ 1.70886 -1.05378]
20Nov22_233143| [-1.05881  0.40379]]
20Nov22_233143|-- Bias --
20Nov22_233143|[-1.26979  0.64071]
20Nov22_233143|Layer 2:
20Nov22_233143|-- Config --
20Nov22_233143|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233143|-- Weights --
20Nov22_233143|[[ 1.13276 -0.19138  0.72299 -0.82235]
20Nov22_233143| [ 0.64675  0.16087 -1.97330  0.51762]]
20Nov22_233143|-- Bias --
20Nov22_233143|[ 0.89711 -0.39996  1.01868  0.39897]
20Nov22_233143|Layer 3:
20Nov22_233143|-- Config --
20Nov22_233143|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233143|-- Weights --
20Nov22_233143|[[ 0.32156  0.32873 -0.08875  0.41462]
20Nov22_233143| [-0.84923  0.88443 -0.12856  0.14256]
20Nov22_233143| [ 1.22213  1.14350 -0.11814  0.15883]
20Nov22_233143| [ 0.26940 -0.37695 -0.50873 -0.17207]]
20Nov22_233143|-- Bias --
20Nov22_233143|[ 0.89054  0.79647 -0.41753  0.26091]
20Nov22_233143|Layer 4:
20Nov22_233143|-- Config --
20Nov22_233143|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233143|-- Weights --
20Nov22_233143|[[ 0.03632 -1.06797]
20Nov22_233143| [ 0.30684  1.00972]
20Nov22_233143| [-1.27764  0.99457]
20Nov22_233143| [-0.33613 -0.12665]]
20Nov22_233143|-- Bias --
20Nov22_233143|[-0.70391 -0.35113]
20Nov22_233143|Predicting the validation and test data with the Best final individual.
20Nov22_233150| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov22_233150|-----------  ------------------  --------------------  ----------
20Nov22_233150|Validation         29.65                  48            0.69265
20Nov22_233150|   Test            24.85                  48            0.68128
20Nov22_233150|-------------------------- Test #3 --------------------------
20Nov22_233150|Best final individual weights
20Nov22_233150|Individual:
20Nov22_233150|-- Constant hidden layers --
20Nov22_233150|False
20Nov22_233150|Layer 0:
20Nov22_233150|-- Config --
20Nov22_233150|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233150|-- Weights --
20Nov22_233150|[[ 0.31067  1.04208]
20Nov22_233150| [ 1.22299  0.01432]
20Nov22_233150| [ 0.79550 -0.40760]
20Nov22_233150| [-2.16624 -1.88313]
20Nov22_233150| [ 0.87286  0.94682]
20Nov22_233150| [ 0.66090  1.36365]
20Nov22_233150| [-0.84894  1.51297]
20Nov22_233150| [-1.42130  1.96017]
20Nov22_233150| [ 0.00894 -0.06965]
20Nov22_233150| [ 1.85177 -0.74199]
20Nov22_233150| [-0.97319 -0.63846]
20Nov22_233150| [-0.48237  1.76131]
20Nov22_233150| [ 0.39013  0.25550]
20Nov22_233150| [-0.75703  0.89261]
20Nov22_233150| [-0.42042  1.00725]
20Nov22_233150| [-0.34138  0.17486]
20Nov22_233150| [ 0.88943 -0.46901]
20Nov22_233150| [-0.74247 -0.29372]
20Nov22_233150| [-0.54323 -1.79078]
20Nov22_233150| [-0.79119 -0.42149]
20Nov22_233150| [-1.87179  0.15971]
20Nov22_233150| [ 0.56242  0.52523]
20Nov22_233150| [-0.41700  0.14775]
20Nov22_233150| [ 2.08280 -1.92186]
20Nov22_233150| [ 0.13396  0.59688]
20Nov22_233150| [-0.29457  1.13513]
20Nov22_233150| [ 0.47883 -0.59367]
20Nov22_233150| [ 0.33787  0.69830]
20Nov22_233150| [-0.18090 -0.42958]
20Nov22_233150| [-1.07236 -0.94238]
20Nov22_233150| [-0.39442  0.07831]
20Nov22_233150| [-0.21956  0.71195]
20Nov22_233150| [ 1.79392 -0.48642]
20Nov22_233150| [-0.36856  0.09153]
20Nov22_233150| [-0.12850 -0.24442]
20Nov22_233150| [ 0.39517  0.11028]
20Nov22_233150| [-0.25405  0.32680]
20Nov22_233150| [ 0.71828 -0.70769]
20Nov22_233150| [ 1.22261  0.52275]
20Nov22_233150| [ 0.73888  0.58055]
20Nov22_233150| [-1.34521 -0.45328]
20Nov22_233150| [ 1.26344 -0.48773]
20Nov22_233150| [-0.73363  0.98363]
20Nov22_233150| [ 0.15762  0.47715]
20Nov22_233150| [ 0.04322  2.38047]
20Nov22_233150| [ 0.22812 -1.56141]
20Nov22_233150| [ 0.95421  1.59583]
20Nov22_233150| [-0.44250  0.33349]
20Nov22_233150| [ 1.05130 -0.41546]
20Nov22_233150| [ 1.39962 -1.22635]
20Nov22_233150| [ 0.24162 -0.05621]
20Nov22_233150| [-0.23985 -1.06417]
20Nov22_233150| [-0.05211  0.68172]
20Nov22_233150| [ 0.28536  2.37729]
20Nov22_233150| [-0.51275 -0.81888]
20Nov22_233150| [-0.68859  1.75815]
20Nov22_233150| [-0.11612 -0.06331]]
20Nov22_233150|-- Bias --
20Nov22_233150|[0.72775 0.20467]
20Nov22_233150|Layer 1:
20Nov22_233150|-- Config --
20Nov22_233150|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233150|-- Weights --
20Nov22_233150|[[ 1.70886 -1.05378]
20Nov22_233150| [-1.05881  0.40379]]
20Nov22_233150|-- Bias --
20Nov22_233150|[-1.26979  0.64071]
20Nov22_233150|Layer 2:
20Nov22_233150|-- Config --
20Nov22_233150|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233150|-- Weights --
20Nov22_233150|[[ 1.13276 -0.19138  0.72299 -0.82235]
20Nov22_233150| [ 0.64675  0.16087 -1.97330  0.51762]]
20Nov22_233150|-- Bias --
20Nov22_233150|[ 0.89711 -0.39996  1.01868  0.39897]
20Nov22_233150|Layer 3:
20Nov22_233150|-- Config --
20Nov22_233150|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233150|-- Weights --
20Nov22_233150|[[ 0.32156  0.32873 -0.08875  0.41462]
20Nov22_233150| [-0.84923  0.88443 -0.12856  0.14256]
20Nov22_233150| [ 1.22213  1.14350 -0.11814  0.15883]
20Nov22_233150| [ 0.26940 -0.37695 -0.50873 -0.17207]]
20Nov22_233150|-- Bias --
20Nov22_233150|[ 0.89054  0.79647 -0.41753  0.26091]
20Nov22_233150|Layer 4:
20Nov22_233150|-- Config --
20Nov22_233150|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233150|-- Weights --
20Nov22_233150|[[ 0.03632 -1.06797]
20Nov22_233150| [ 0.30684  1.00972]
20Nov22_233150| [-1.27764  0.99457]
20Nov22_233150| [-0.33613 -0.12665]]
20Nov22_233150|-- Bias --
20Nov22_233150|[-0.70391 -0.35113]
20Nov22_233150|Predicting the validation and test data with the Best final individual.
20Nov22_233156| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov22_233156|-----------  ------------------  --------------------  ----------
20Nov22_233156|Validation         26.17                  48            0.66331
20Nov22_233156|   Test            26.76                  48            0.61809
20Nov22_233156|-------------------------- Test #4 --------------------------
20Nov22_233156|Best final individual weights
20Nov22_233156|Individual:
20Nov22_233156|-- Constant hidden layers --
20Nov22_233156|False
20Nov22_233156|Layer 0:
20Nov22_233156|-- Config --
20Nov22_233156|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233156|-- Weights --
20Nov22_233156|[[ 0.31067  1.04208]
20Nov22_233156| [ 1.22299  0.01432]
20Nov22_233156| [ 0.79550 -0.40760]
20Nov22_233156| [-2.16624 -1.88313]
20Nov22_233156| [ 0.87286  0.94682]
20Nov22_233156| [ 0.66090  1.36365]
20Nov22_233156| [-0.84894  1.51297]
20Nov22_233156| [-1.42130  1.96017]
20Nov22_233156| [ 0.00894 -0.06965]
20Nov22_233156| [ 1.85177 -0.74199]
20Nov22_233156| [-0.97319 -0.63846]
20Nov22_233156| [-0.48237  1.76131]
20Nov22_233156| [ 0.39013  0.25550]
20Nov22_233156| [-0.75703  0.89261]
20Nov22_233156| [-0.42042  1.00725]
20Nov22_233156| [-0.34138  0.17486]
20Nov22_233156| [ 0.88943 -0.46901]
20Nov22_233156| [-0.74247 -0.29372]
20Nov22_233156| [-0.54323 -1.79078]
20Nov22_233156| [-0.79119 -0.42149]
20Nov22_233156| [-1.87179  0.15971]
20Nov22_233156| [ 0.56242  0.52523]
20Nov22_233156| [-0.41700  0.14775]
20Nov22_233156| [ 2.08280 -1.92186]
20Nov22_233156| [ 0.13396  0.59688]
20Nov22_233156| [-0.29457  1.13513]
20Nov22_233156| [ 0.47883 -0.59367]
20Nov22_233156| [ 0.33787  0.69830]
20Nov22_233156| [-0.18090 -0.42958]
20Nov22_233156| [-1.07236 -0.94238]
20Nov22_233156| [-0.39442  0.07831]
20Nov22_233156| [-0.21956  0.71195]
20Nov22_233156| [ 1.79392 -0.48642]
20Nov22_233156| [-0.36856  0.09153]
20Nov22_233156| [-0.12850 -0.24442]
20Nov22_233156| [ 0.39517  0.11028]
20Nov22_233156| [-0.25405  0.32680]
20Nov22_233156| [ 0.71828 -0.70769]
20Nov22_233156| [ 1.22261  0.52275]
20Nov22_233156| [ 0.73888  0.58055]
20Nov22_233156| [-1.34521 -0.45328]
20Nov22_233156| [ 1.26344 -0.48773]
20Nov22_233156| [-0.73363  0.98363]
20Nov22_233156| [ 0.15762  0.47715]
20Nov22_233156| [ 0.04322  2.38047]
20Nov22_233156| [ 0.22812 -1.56141]
20Nov22_233156| [ 0.95421  1.59583]
20Nov22_233156| [-0.44250  0.33349]
20Nov22_233156| [ 1.05130 -0.41546]
20Nov22_233156| [ 1.39962 -1.22635]
20Nov22_233156| [ 0.24162 -0.05621]
20Nov22_233156| [-0.23985 -1.06417]
20Nov22_233156| [-0.05211  0.68172]
20Nov22_233156| [ 0.28536  2.37729]
20Nov22_233156| [-0.51275 -0.81888]
20Nov22_233156| [-0.68859  1.75815]
20Nov22_233156| [-0.11612 -0.06331]]
20Nov22_233156|-- Bias --
20Nov22_233156|[0.72775 0.20467]
20Nov22_233156|Layer 1:
20Nov22_233156|-- Config --
20Nov22_233156|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233156|-- Weights --
20Nov22_233156|[[ 1.70886 -1.05378]
20Nov22_233156| [-1.05881  0.40379]]
20Nov22_233156|-- Bias --
20Nov22_233156|[-1.26979  0.64071]
20Nov22_233156|Layer 2:
20Nov22_233156|-- Config --
20Nov22_233156|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233156|-- Weights --
20Nov22_233156|[[ 1.13276 -0.19138  0.72299 -0.82235]
20Nov22_233156| [ 0.64675  0.16087 -1.97330  0.51762]]
20Nov22_233156|-- Bias --
20Nov22_233156|[ 0.89711 -0.39996  1.01868  0.39897]
20Nov22_233156|Layer 3:
20Nov22_233156|-- Config --
20Nov22_233156|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233156|-- Weights --
20Nov22_233156|[[ 0.32156  0.32873 -0.08875  0.41462]
20Nov22_233156| [-0.84923  0.88443 -0.12856  0.14256]
20Nov22_233156| [ 1.22213  1.14350 -0.11814  0.15883]
20Nov22_233156| [ 0.26940 -0.37695 -0.50873 -0.17207]]
20Nov22_233156|-- Bias --
20Nov22_233156|[ 0.89054  0.79647 -0.41753  0.26091]
20Nov22_233156|Layer 4:
20Nov22_233156|-- Config --
20Nov22_233156|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233156|-- Weights --
20Nov22_233156|[[ 0.03632 -1.06797]
20Nov22_233156| [ 0.30684  1.00972]
20Nov22_233156| [-1.27764  0.99457]
20Nov22_233156| [-0.33613 -0.12665]]
20Nov22_233156|-- Bias --
20Nov22_233156|[-0.70391 -0.35113]
20Nov22_233156|Predicting the validation and test data with the Best final individual.
20Nov22_233203| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov22_233203|-----------  ------------------  --------------------  ----------
20Nov22_233203|Validation         28.17                  48            0.54993
20Nov22_233203|   Test            27.98                  48            0.66991
20Nov22_233203|-------------------------- Test #5 --------------------------
20Nov22_233203|Best final individual weights
20Nov22_233203|Individual:
20Nov22_233203|-- Constant hidden layers --
20Nov22_233203|False
20Nov22_233203|Layer 0:
20Nov22_233203|-- Config --
20Nov22_233203|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233203|-- Weights --
20Nov22_233203|[[ 0.31067  1.04208]
20Nov22_233203| [ 1.22299  0.01432]
20Nov22_233203| [ 0.79550 -0.40760]
20Nov22_233203| [-2.16624 -1.88313]
20Nov22_233203| [ 0.87286  0.94682]
20Nov22_233203| [ 0.66090  1.36365]
20Nov22_233203| [-0.84894  1.51297]
20Nov22_233203| [-1.42130  1.96017]
20Nov22_233203| [ 0.00894 -0.06965]
20Nov22_233203| [ 1.85177 -0.74199]
20Nov22_233203| [-0.97319 -0.63846]
20Nov22_233203| [-0.48237  1.76131]
20Nov22_233203| [ 0.39013  0.25550]
20Nov22_233203| [-0.75703  0.89261]
20Nov22_233203| [-0.42042  1.00725]
20Nov22_233203| [-0.34138  0.17486]
20Nov22_233203| [ 0.88943 -0.46901]
20Nov22_233203| [-0.74247 -0.29372]
20Nov22_233203| [-0.54323 -1.79078]
20Nov22_233203| [-0.79119 -0.42149]
20Nov22_233203| [-1.87179  0.15971]
20Nov22_233203| [ 0.56242  0.52523]
20Nov22_233203| [-0.41700  0.14775]
20Nov22_233203| [ 2.08280 -1.92186]
20Nov22_233203| [ 0.13396  0.59688]
20Nov22_233203| [-0.29457  1.13513]
20Nov22_233203| [ 0.47883 -0.59367]
20Nov22_233203| [ 0.33787  0.69830]
20Nov22_233203| [-0.18090 -0.42958]
20Nov22_233203| [-1.07236 -0.94238]
20Nov22_233203| [-0.39442  0.07831]
20Nov22_233203| [-0.21956  0.71195]
20Nov22_233203| [ 1.79392 -0.48642]
20Nov22_233203| [-0.36856  0.09153]
20Nov22_233203| [-0.12850 -0.24442]
20Nov22_233203| [ 0.39517  0.11028]
20Nov22_233203| [-0.25405  0.32680]
20Nov22_233203| [ 0.71828 -0.70769]
20Nov22_233203| [ 1.22261  0.52275]
20Nov22_233203| [ 0.73888  0.58055]
20Nov22_233203| [-1.34521 -0.45328]
20Nov22_233203| [ 1.26344 -0.48773]
20Nov22_233203| [-0.73363  0.98363]
20Nov22_233203| [ 0.15762  0.47715]
20Nov22_233203| [ 0.04322  2.38047]
20Nov22_233203| [ 0.22812 -1.56141]
20Nov22_233203| [ 0.95421  1.59583]
20Nov22_233203| [-0.44250  0.33349]
20Nov22_233203| [ 1.05130 -0.41546]
20Nov22_233203| [ 1.39962 -1.22635]
20Nov22_233203| [ 0.24162 -0.05621]
20Nov22_233203| [-0.23985 -1.06417]
20Nov22_233203| [-0.05211  0.68172]
20Nov22_233203| [ 0.28536  2.37729]
20Nov22_233203| [-0.51275 -0.81888]
20Nov22_233203| [-0.68859  1.75815]
20Nov22_233203| [-0.11612 -0.06331]]
20Nov22_233203|-- Bias --
20Nov22_233203|[0.72775 0.20467]
20Nov22_233203|Layer 1:
20Nov22_233203|-- Config --
20Nov22_233203|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233203|-- Weights --
20Nov22_233203|[[ 1.70886 -1.05378]
20Nov22_233203| [-1.05881  0.40379]]
20Nov22_233203|-- Bias --
20Nov22_233203|[-1.26979  0.64071]
20Nov22_233203|Layer 2:
20Nov22_233203|-- Config --
20Nov22_233203|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233203|-- Weights --
20Nov22_233203|[[ 1.13276 -0.19138  0.72299 -0.82235]
20Nov22_233203| [ 0.64675  0.16087 -1.97330  0.51762]]
20Nov22_233203|-- Bias --
20Nov22_233203|[ 0.89711 -0.39996  1.01868  0.39897]
20Nov22_233203|Layer 3:
20Nov22_233203|-- Config --
20Nov22_233203|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233203|-- Weights --
20Nov22_233203|[[ 0.32156  0.32873 -0.08875  0.41462]
20Nov22_233203| [-0.84923  0.88443 -0.12856  0.14256]
20Nov22_233203| [ 1.22213  1.14350 -0.11814  0.15883]
20Nov22_233203| [ 0.26940 -0.37695 -0.50873 -0.17207]]
20Nov22_233203|-- Bias --
20Nov22_233203|[ 0.89054  0.79647 -0.41753  0.26091]
20Nov22_233203|Layer 4:
20Nov22_233203|-- Config --
20Nov22_233203|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233203|-- Weights --
20Nov22_233203|[[ 0.03632 -1.06797]
20Nov22_233203| [ 0.30684  1.00972]
20Nov22_233203| [-1.27764  0.99457]
20Nov22_233203| [-0.33613 -0.12665]]
20Nov22_233203|-- Bias --
20Nov22_233203|[-0.70391 -0.35113]
20Nov22_233203|Predicting the validation and test data with the Best final individual.
20Nov22_233209| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov22_233209|-----------  ------------------  --------------------  ----------
20Nov22_233209|Validation         42.00                  48            0.00000
20Nov22_233209|   Test            25.02                  48            0.51821
20Nov22_233209|-------------------------- Test #6 --------------------------
20Nov22_233209|Best final individual weights
20Nov22_233209|Individual:
20Nov22_233209|-- Constant hidden layers --
20Nov22_233209|False
20Nov22_233209|Layer 0:
20Nov22_233209|-- Config --
20Nov22_233209|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233209|-- Weights --
20Nov22_233209|[[ 0.31067  1.04208]
20Nov22_233209| [ 1.22299  0.01432]
20Nov22_233209| [ 0.79550 -0.40760]
20Nov22_233209| [-2.16624 -1.88313]
20Nov22_233209| [ 0.87286  0.94682]
20Nov22_233209| [ 0.66090  1.36365]
20Nov22_233209| [-0.84894  1.51297]
20Nov22_233209| [-1.42130  1.96017]
20Nov22_233209| [ 0.00894 -0.06965]
20Nov22_233209| [ 1.85177 -0.74199]
20Nov22_233209| [-0.97319 -0.63846]
20Nov22_233209| [-0.48237  1.76131]
20Nov22_233209| [ 0.39013  0.25550]
20Nov22_233209| [-0.75703  0.89261]
20Nov22_233209| [-0.42042  1.00725]
20Nov22_233209| [-0.34138  0.17486]
20Nov22_233209| [ 0.88943 -0.46901]
20Nov22_233209| [-0.74247 -0.29372]
20Nov22_233209| [-0.54323 -1.79078]
20Nov22_233209| [-0.79119 -0.42149]
20Nov22_233209| [-1.87179  0.15971]
20Nov22_233209| [ 0.56242  0.52523]
20Nov22_233209| [-0.41700  0.14775]
20Nov22_233209| [ 2.08280 -1.92186]
20Nov22_233209| [ 0.13396  0.59688]
20Nov22_233209| [-0.29457  1.13513]
20Nov22_233209| [ 0.47883 -0.59367]
20Nov22_233209| [ 0.33787  0.69830]
20Nov22_233209| [-0.18090 -0.42958]
20Nov22_233209| [-1.07236 -0.94238]
20Nov22_233209| [-0.39442  0.07831]
20Nov22_233209| [-0.21956  0.71195]
20Nov22_233209| [ 1.79392 -0.48642]
20Nov22_233209| [-0.36856  0.09153]
20Nov22_233209| [-0.12850 -0.24442]
20Nov22_233209| [ 0.39517  0.11028]
20Nov22_233209| [-0.25405  0.32680]
20Nov22_233209| [ 0.71828 -0.70769]
20Nov22_233209| [ 1.22261  0.52275]
20Nov22_233209| [ 0.73888  0.58055]
20Nov22_233209| [-1.34521 -0.45328]
20Nov22_233209| [ 1.26344 -0.48773]
20Nov22_233209| [-0.73363  0.98363]
20Nov22_233209| [ 0.15762  0.47715]
20Nov22_233209| [ 0.04322  2.38047]
20Nov22_233209| [ 0.22812 -1.56141]
20Nov22_233209| [ 0.95421  1.59583]
20Nov22_233209| [-0.44250  0.33349]
20Nov22_233209| [ 1.05130 -0.41546]
20Nov22_233209| [ 1.39962 -1.22635]
20Nov22_233209| [ 0.24162 -0.05621]
20Nov22_233209| [-0.23985 -1.06417]
20Nov22_233209| [-0.05211  0.68172]
20Nov22_233209| [ 0.28536  2.37729]
20Nov22_233209| [-0.51275 -0.81888]
20Nov22_233209| [-0.68859  1.75815]
20Nov22_233209| [-0.11612 -0.06331]]
20Nov22_233209|-- Bias --
20Nov22_233209|[0.72775 0.20467]
20Nov22_233209|Layer 1:
20Nov22_233209|-- Config --
20Nov22_233209|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233209|-- Weights --
20Nov22_233209|[[ 1.70886 -1.05378]
20Nov22_233209| [-1.05881  0.40379]]
20Nov22_233209|-- Bias --
20Nov22_233209|[-1.26979  0.64071]
20Nov22_233209|Layer 2:
20Nov22_233209|-- Config --
20Nov22_233209|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233209|-- Weights --
20Nov22_233209|[[ 1.13276 -0.19138  0.72299 -0.82235]
20Nov22_233209| [ 0.64675  0.16087 -1.97330  0.51762]]
20Nov22_233209|-- Bias --
20Nov22_233209|[ 0.89711 -0.39996  1.01868  0.39897]
20Nov22_233209|Layer 3:
20Nov22_233209|-- Config --
20Nov22_233209|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233209|-- Weights --
20Nov22_233209|[[ 0.32156  0.32873 -0.08875  0.41462]
20Nov22_233209| [-0.84923  0.88443 -0.12856  0.14256]
20Nov22_233209| [ 1.22213  1.14350 -0.11814  0.15883]
20Nov22_233209| [ 0.26940 -0.37695 -0.50873 -0.17207]]
20Nov22_233209|-- Bias --
20Nov22_233209|[ 0.89054  0.79647 -0.41753  0.26091]
20Nov22_233209|Layer 4:
20Nov22_233209|-- Config --
20Nov22_233209|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233209|-- Weights --
20Nov22_233209|[[ 0.03632 -1.06797]
20Nov22_233209| [ 0.30684  1.00972]
20Nov22_233209| [-1.27764  0.99457]
20Nov22_233209| [-0.33613 -0.12665]]
20Nov22_233209|-- Bias --
20Nov22_233209|[-0.70391 -0.35113]
20Nov22_233209|Predicting the validation and test data with the Best final individual.
20Nov22_233216| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov22_233216|-----------  ------------------  --------------------  ----------
20Nov22_233216|Validation         28.17                  48            0.77596
20Nov22_233216|   Test            36.40                  48            0.00000
20Nov22_233216|-------------------------- Test #7 --------------------------
20Nov22_233216|Best final individual weights
20Nov22_233216|Individual:
20Nov22_233216|-- Constant hidden layers --
20Nov22_233216|False
20Nov22_233216|Layer 0:
20Nov22_233216|-- Config --
20Nov22_233216|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233216|-- Weights --
20Nov22_233216|[[ 0.31067  1.04208]
20Nov22_233216| [ 1.22299  0.01432]
20Nov22_233216| [ 0.79550 -0.40760]
20Nov22_233216| [-2.16624 -1.88313]
20Nov22_233216| [ 0.87286  0.94682]
20Nov22_233216| [ 0.66090  1.36365]
20Nov22_233216| [-0.84894  1.51297]
20Nov22_233216| [-1.42130  1.96017]
20Nov22_233216| [ 0.00894 -0.06965]
20Nov22_233216| [ 1.85177 -0.74199]
20Nov22_233216| [-0.97319 -0.63846]
20Nov22_233216| [-0.48237  1.76131]
20Nov22_233216| [ 0.39013  0.25550]
20Nov22_233216| [-0.75703  0.89261]
20Nov22_233216| [-0.42042  1.00725]
20Nov22_233216| [-0.34138  0.17486]
20Nov22_233216| [ 0.88943 -0.46901]
20Nov22_233216| [-0.74247 -0.29372]
20Nov22_233216| [-0.54323 -1.79078]
20Nov22_233216| [-0.79119 -0.42149]
20Nov22_233216| [-1.87179  0.15971]
20Nov22_233216| [ 0.56242  0.52523]
20Nov22_233216| [-0.41700  0.14775]
20Nov22_233216| [ 2.08280 -1.92186]
20Nov22_233216| [ 0.13396  0.59688]
20Nov22_233216| [-0.29457  1.13513]
20Nov22_233216| [ 0.47883 -0.59367]
20Nov22_233216| [ 0.33787  0.69830]
20Nov22_233216| [-0.18090 -0.42958]
20Nov22_233216| [-1.07236 -0.94238]
20Nov22_233216| [-0.39442  0.07831]
20Nov22_233216| [-0.21956  0.71195]
20Nov22_233216| [ 1.79392 -0.48642]
20Nov22_233216| [-0.36856  0.09153]
20Nov22_233216| [-0.12850 -0.24442]
20Nov22_233216| [ 0.39517  0.11028]
20Nov22_233216| [-0.25405  0.32680]
20Nov22_233216| [ 0.71828 -0.70769]
20Nov22_233216| [ 1.22261  0.52275]
20Nov22_233216| [ 0.73888  0.58055]
20Nov22_233216| [-1.34521 -0.45328]
20Nov22_233216| [ 1.26344 -0.48773]
20Nov22_233216| [-0.73363  0.98363]
20Nov22_233216| [ 0.15762  0.47715]
20Nov22_233216| [ 0.04322  2.38047]
20Nov22_233216| [ 0.22812 -1.56141]
20Nov22_233216| [ 0.95421  1.59583]
20Nov22_233216| [-0.44250  0.33349]
20Nov22_233216| [ 1.05130 -0.41546]
20Nov22_233216| [ 1.39962 -1.22635]
20Nov22_233216| [ 0.24162 -0.05621]
20Nov22_233216| [-0.23985 -1.06417]
20Nov22_233216| [-0.05211  0.68172]
20Nov22_233216| [ 0.28536  2.37729]
20Nov22_233216| [-0.51275 -0.81888]
20Nov22_233216| [-0.68859  1.75815]
20Nov22_233216| [-0.11612 -0.06331]]
20Nov22_233216|-- Bias --
20Nov22_233216|[0.72775 0.20467]
20Nov22_233216|Layer 1:
20Nov22_233216|-- Config --
20Nov22_233216|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233216|-- Weights --
20Nov22_233216|[[ 1.70886 -1.05378]
20Nov22_233216| [-1.05881  0.40379]]
20Nov22_233216|-- Bias --
20Nov22_233216|[-1.26979  0.64071]
20Nov22_233216|Layer 2:
20Nov22_233216|-- Config --
20Nov22_233216|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233216|-- Weights --
20Nov22_233216|[[ 1.13276 -0.19138  0.72299 -0.82235]
20Nov22_233216| [ 0.64675  0.16087 -1.97330  0.51762]]
20Nov22_233216|-- Bias --
20Nov22_233216|[ 0.89711 -0.39996  1.01868  0.39897]
20Nov22_233216|Layer 3:
20Nov22_233216|-- Config --
20Nov22_233216|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233216|-- Weights --
20Nov22_233216|[[ 0.32156  0.32873 -0.08875  0.41462]
20Nov22_233216| [-0.84923  0.88443 -0.12856  0.14256]
20Nov22_233216| [ 1.22213  1.14350 -0.11814  0.15883]
20Nov22_233216| [ 0.26940 -0.37695 -0.50873 -0.17207]]
20Nov22_233216|-- Bias --
20Nov22_233216|[ 0.89054  0.79647 -0.41753  0.26091]
20Nov22_233216|Layer 4:
20Nov22_233216|-- Config --
20Nov22_233216|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233216|-- Weights --
20Nov22_233216|[[ 0.03632 -1.06797]
20Nov22_233216| [ 0.30684  1.00972]
20Nov22_233216| [-1.27764  0.99457]
20Nov22_233216| [-0.33613 -0.12665]]
20Nov22_233216|-- Bias --
20Nov22_233216|[-0.70391 -0.35113]
20Nov22_233216|Predicting the validation and test data with the Best final individual.
20Nov22_233223| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov22_233223|-----------  ------------------  --------------------  ----------
20Nov22_233223|Validation         24.70                  48            0.70303
20Nov22_233223|   Test            24.50                  48            0.61119
20Nov22_233223|-------------------------- Test #8 --------------------------
20Nov22_233223|Best final individual weights
20Nov22_233223|Individual:
20Nov22_233223|-- Constant hidden layers --
20Nov22_233223|False
20Nov22_233223|Layer 0:
20Nov22_233223|-- Config --
20Nov22_233223|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233223|-- Weights --
20Nov22_233223|[[ 0.31067  1.04208]
20Nov22_233223| [ 1.22299  0.01432]
20Nov22_233223| [ 0.79550 -0.40760]
20Nov22_233223| [-2.16624 -1.88313]
20Nov22_233223| [ 0.87286  0.94682]
20Nov22_233223| [ 0.66090  1.36365]
20Nov22_233223| [-0.84894  1.51297]
20Nov22_233223| [-1.42130  1.96017]
20Nov22_233223| [ 0.00894 -0.06965]
20Nov22_233223| [ 1.85177 -0.74199]
20Nov22_233223| [-0.97319 -0.63846]
20Nov22_233223| [-0.48237  1.76131]
20Nov22_233223| [ 0.39013  0.25550]
20Nov22_233223| [-0.75703  0.89261]
20Nov22_233223| [-0.42042  1.00725]
20Nov22_233223| [-0.34138  0.17486]
20Nov22_233223| [ 0.88943 -0.46901]
20Nov22_233223| [-0.74247 -0.29372]
20Nov22_233223| [-0.54323 -1.79078]
20Nov22_233223| [-0.79119 -0.42149]
20Nov22_233223| [-1.87179  0.15971]
20Nov22_233223| [ 0.56242  0.52523]
20Nov22_233223| [-0.41700  0.14775]
20Nov22_233223| [ 2.08280 -1.92186]
20Nov22_233223| [ 0.13396  0.59688]
20Nov22_233223| [-0.29457  1.13513]
20Nov22_233223| [ 0.47883 -0.59367]
20Nov22_233223| [ 0.33787  0.69830]
20Nov22_233223| [-0.18090 -0.42958]
20Nov22_233223| [-1.07236 -0.94238]
20Nov22_233223| [-0.39442  0.07831]
20Nov22_233223| [-0.21956  0.71195]
20Nov22_233223| [ 1.79392 -0.48642]
20Nov22_233223| [-0.36856  0.09153]
20Nov22_233223| [-0.12850 -0.24442]
20Nov22_233223| [ 0.39517  0.11028]
20Nov22_233223| [-0.25405  0.32680]
20Nov22_233223| [ 0.71828 -0.70769]
20Nov22_233223| [ 1.22261  0.52275]
20Nov22_233223| [ 0.73888  0.58055]
20Nov22_233223| [-1.34521 -0.45328]
20Nov22_233223| [ 1.26344 -0.48773]
20Nov22_233223| [-0.73363  0.98363]
20Nov22_233223| [ 0.15762  0.47715]
20Nov22_233223| [ 0.04322  2.38047]
20Nov22_233223| [ 0.22812 -1.56141]
20Nov22_233223| [ 0.95421  1.59583]
20Nov22_233223| [-0.44250  0.33349]
20Nov22_233223| [ 1.05130 -0.41546]
20Nov22_233223| [ 1.39962 -1.22635]
20Nov22_233223| [ 0.24162 -0.05621]
20Nov22_233223| [-0.23985 -1.06417]
20Nov22_233223| [-0.05211  0.68172]
20Nov22_233223| [ 0.28536  2.37729]
20Nov22_233223| [-0.51275 -0.81888]
20Nov22_233223| [-0.68859  1.75815]
20Nov22_233223| [-0.11612 -0.06331]]
20Nov22_233223|-- Bias --
20Nov22_233223|[0.72775 0.20467]
20Nov22_233223|Layer 1:
20Nov22_233223|-- Config --
20Nov22_233223|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233223|-- Weights --
20Nov22_233223|[[ 1.70886 -1.05378]
20Nov22_233223| [-1.05881  0.40379]]
20Nov22_233223|-- Bias --
20Nov22_233223|[-1.26979  0.64071]
20Nov22_233223|Layer 2:
20Nov22_233223|-- Config --
20Nov22_233223|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233223|-- Weights --
20Nov22_233223|[[ 1.13276 -0.19138  0.72299 -0.82235]
20Nov22_233223| [ 0.64675  0.16087 -1.97330  0.51762]]
20Nov22_233223|-- Bias --
20Nov22_233223|[ 0.89711 -0.39996  1.01868  0.39897]
20Nov22_233223|Layer 3:
20Nov22_233223|-- Config --
20Nov22_233223|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233223|-- Weights --
20Nov22_233223|[[ 0.32156  0.32873 -0.08875  0.41462]
20Nov22_233223| [-0.84923  0.88443 -0.12856  0.14256]
20Nov22_233223| [ 1.22213  1.14350 -0.11814  0.15883]
20Nov22_233223| [ 0.26940 -0.37695 -0.50873 -0.17207]]
20Nov22_233223|-- Bias --
20Nov22_233223|[ 0.89054  0.79647 -0.41753  0.26091]
20Nov22_233223|Layer 4:
20Nov22_233223|-- Config --
20Nov22_233223|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233223|-- Weights --
20Nov22_233223|[[ 0.03632 -1.06797]
20Nov22_233223| [ 0.30684  1.00972]
20Nov22_233223| [-1.27764  0.99457]
20Nov22_233223| [-0.33613 -0.12665]]
20Nov22_233223|-- Bias --
20Nov22_233223|[-0.70391 -0.35113]
20Nov22_233223|Predicting the validation and test data with the Best final individual.
20Nov22_233229| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov22_233229|-----------  ------------------  --------------------  ----------
20Nov22_233229|Validation         25.83                  48            0.63780
20Nov22_233229|   Test            25.28                  48            0.63224
20Nov22_233229|-------------------------- Test #9 --------------------------
20Nov22_233229|Best final individual weights
20Nov22_233229|Individual:
20Nov22_233229|-- Constant hidden layers --
20Nov22_233229|False
20Nov22_233229|Layer 0:
20Nov22_233229|-- Config --
20Nov22_233229|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233229|-- Weights --
20Nov22_233229|[[ 0.31067  1.04208]
20Nov22_233229| [ 1.22299  0.01432]
20Nov22_233229| [ 0.79550 -0.40760]
20Nov22_233229| [-2.16624 -1.88313]
20Nov22_233229| [ 0.87286  0.94682]
20Nov22_233229| [ 0.66090  1.36365]
20Nov22_233229| [-0.84894  1.51297]
20Nov22_233229| [-1.42130  1.96017]
20Nov22_233229| [ 0.00894 -0.06965]
20Nov22_233229| [ 1.85177 -0.74199]
20Nov22_233229| [-0.97319 -0.63846]
20Nov22_233229| [-0.48237  1.76131]
20Nov22_233229| [ 0.39013  0.25550]
20Nov22_233229| [-0.75703  0.89261]
20Nov22_233229| [-0.42042  1.00725]
20Nov22_233229| [-0.34138  0.17486]
20Nov22_233229| [ 0.88943 -0.46901]
20Nov22_233229| [-0.74247 -0.29372]
20Nov22_233229| [-0.54323 -1.79078]
20Nov22_233229| [-0.79119 -0.42149]
20Nov22_233229| [-1.87179  0.15971]
20Nov22_233229| [ 0.56242  0.52523]
20Nov22_233229| [-0.41700  0.14775]
20Nov22_233229| [ 2.08280 -1.92186]
20Nov22_233229| [ 0.13396  0.59688]
20Nov22_233229| [-0.29457  1.13513]
20Nov22_233229| [ 0.47883 -0.59367]
20Nov22_233229| [ 0.33787  0.69830]
20Nov22_233229| [-0.18090 -0.42958]
20Nov22_233229| [-1.07236 -0.94238]
20Nov22_233229| [-0.39442  0.07831]
20Nov22_233229| [-0.21956  0.71195]
20Nov22_233229| [ 1.79392 -0.48642]
20Nov22_233229| [-0.36856  0.09153]
20Nov22_233229| [-0.12850 -0.24442]
20Nov22_233229| [ 0.39517  0.11028]
20Nov22_233229| [-0.25405  0.32680]
20Nov22_233229| [ 0.71828 -0.70769]
20Nov22_233229| [ 1.22261  0.52275]
20Nov22_233229| [ 0.73888  0.58055]
20Nov22_233229| [-1.34521 -0.45328]
20Nov22_233229| [ 1.26344 -0.48773]
20Nov22_233229| [-0.73363  0.98363]
20Nov22_233229| [ 0.15762  0.47715]
20Nov22_233229| [ 0.04322  2.38047]
20Nov22_233229| [ 0.22812 -1.56141]
20Nov22_233229| [ 0.95421  1.59583]
20Nov22_233229| [-0.44250  0.33349]
20Nov22_233229| [ 1.05130 -0.41546]
20Nov22_233229| [ 1.39962 -1.22635]
20Nov22_233229| [ 0.24162 -0.05621]
20Nov22_233229| [-0.23985 -1.06417]
20Nov22_233229| [-0.05211  0.68172]
20Nov22_233229| [ 0.28536  2.37729]
20Nov22_233229| [-0.51275 -0.81888]
20Nov22_233229| [-0.68859  1.75815]
20Nov22_233229| [-0.11612 -0.06331]]
20Nov22_233229|-- Bias --
20Nov22_233229|[0.72775 0.20467]
20Nov22_233229|Layer 1:
20Nov22_233229|-- Config --
20Nov22_233229|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233229|-- Weights --
20Nov22_233229|[[ 1.70886 -1.05378]
20Nov22_233229| [-1.05881  0.40379]]
20Nov22_233229|-- Bias --
20Nov22_233229|[-1.26979  0.64071]
20Nov22_233229|Layer 2:
20Nov22_233229|-- Config --
20Nov22_233229|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233229|-- Weights --
20Nov22_233229|[[ 1.13276 -0.19138  0.72299 -0.82235]
20Nov22_233229| [ 0.64675  0.16087 -1.97330  0.51762]]
20Nov22_233229|-- Bias --
20Nov22_233229|[ 0.89711 -0.39996  1.01868  0.39897]
20Nov22_233229|Layer 3:
20Nov22_233229|-- Config --
20Nov22_233229|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233229|-- Weights --
20Nov22_233229|[[ 0.32156  0.32873 -0.08875  0.41462]
20Nov22_233229| [-0.84923  0.88443 -0.12856  0.14256]
20Nov22_233229| [ 1.22213  1.14350 -0.11814  0.15883]
20Nov22_233229| [ 0.26940 -0.37695 -0.50873 -0.17207]]
20Nov22_233229|-- Bias --
20Nov22_233229|[ 0.89054  0.79647 -0.41753  0.26091]
20Nov22_233229|Layer 4:
20Nov22_233229|-- Config --
20Nov22_233229|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233229|-- Weights --
20Nov22_233229|[[ 0.03632 -1.06797]
20Nov22_233229| [ 0.30684  1.00972]
20Nov22_233229| [-1.27764  0.99457]
20Nov22_233229| [-0.33613 -0.12665]]
20Nov22_233229|-- Bias --
20Nov22_233229|[-0.70391 -0.35113]
20Nov22_233229|Predicting the validation and test data with the Best final individual.
20Nov22_233236| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov22_233236|-----------  ------------------  --------------------  ----------
20Nov22_233236|Validation         25.74                  48            0.66316
20Nov22_233236|   Test            25.11                  48            0.69224
20Nov22_233236|-------------------------- Test #10 --------------------------
20Nov22_233236|Best final individual weights
20Nov22_233236|Individual:
20Nov22_233236|-- Constant hidden layers --
20Nov22_233236|False
20Nov22_233236|Layer 0:
20Nov22_233236|-- Config --
20Nov22_233236|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233236|-- Weights --
20Nov22_233236|[[ 0.31067  1.04208]
20Nov22_233236| [ 1.22299  0.01432]
20Nov22_233236| [ 0.79550 -0.40760]
20Nov22_233236| [-2.16624 -1.88313]
20Nov22_233236| [ 0.87286  0.94682]
20Nov22_233236| [ 0.66090  1.36365]
20Nov22_233236| [-0.84894  1.51297]
20Nov22_233236| [-1.42130  1.96017]
20Nov22_233236| [ 0.00894 -0.06965]
20Nov22_233236| [ 1.85177 -0.74199]
20Nov22_233236| [-0.97319 -0.63846]
20Nov22_233236| [-0.48237  1.76131]
20Nov22_233236| [ 0.39013  0.25550]
20Nov22_233236| [-0.75703  0.89261]
20Nov22_233236| [-0.42042  1.00725]
20Nov22_233236| [-0.34138  0.17486]
20Nov22_233236| [ 0.88943 -0.46901]
20Nov22_233236| [-0.74247 -0.29372]
20Nov22_233236| [-0.54323 -1.79078]
20Nov22_233236| [-0.79119 -0.42149]
20Nov22_233236| [-1.87179  0.15971]
20Nov22_233236| [ 0.56242  0.52523]
20Nov22_233236| [-0.41700  0.14775]
20Nov22_233236| [ 2.08280 -1.92186]
20Nov22_233236| [ 0.13396  0.59688]
20Nov22_233236| [-0.29457  1.13513]
20Nov22_233236| [ 0.47883 -0.59367]
20Nov22_233236| [ 0.33787  0.69830]
20Nov22_233236| [-0.18090 -0.42958]
20Nov22_233236| [-1.07236 -0.94238]
20Nov22_233236| [-0.39442  0.07831]
20Nov22_233236| [-0.21956  0.71195]
20Nov22_233236| [ 1.79392 -0.48642]
20Nov22_233236| [-0.36856  0.09153]
20Nov22_233236| [-0.12850 -0.24442]
20Nov22_233236| [ 0.39517  0.11028]
20Nov22_233236| [-0.25405  0.32680]
20Nov22_233236| [ 0.71828 -0.70769]
20Nov22_233236| [ 1.22261  0.52275]
20Nov22_233236| [ 0.73888  0.58055]
20Nov22_233236| [-1.34521 -0.45328]
20Nov22_233236| [ 1.26344 -0.48773]
20Nov22_233236| [-0.73363  0.98363]
20Nov22_233236| [ 0.15762  0.47715]
20Nov22_233236| [ 0.04322  2.38047]
20Nov22_233236| [ 0.22812 -1.56141]
20Nov22_233236| [ 0.95421  1.59583]
20Nov22_233236| [-0.44250  0.33349]
20Nov22_233236| [ 1.05130 -0.41546]
20Nov22_233236| [ 1.39962 -1.22635]
20Nov22_233236| [ 0.24162 -0.05621]
20Nov22_233236| [-0.23985 -1.06417]
20Nov22_233236| [-0.05211  0.68172]
20Nov22_233236| [ 0.28536  2.37729]
20Nov22_233236| [-0.51275 -0.81888]
20Nov22_233236| [-0.68859  1.75815]
20Nov22_233236| [-0.11612 -0.06331]]
20Nov22_233236|-- Bias --
20Nov22_233236|[0.72775 0.20467]
20Nov22_233236|Layer 1:
20Nov22_233236|-- Config --
20Nov22_233236|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233236|-- Weights --
20Nov22_233236|[[ 1.70886 -1.05378]
20Nov22_233236| [-1.05881  0.40379]]
20Nov22_233236|-- Bias --
20Nov22_233236|[-1.26979  0.64071]
20Nov22_233236|Layer 2:
20Nov22_233236|-- Config --
20Nov22_233236|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233236|-- Weights --
20Nov22_233236|[[ 1.13276 -0.19138  0.72299 -0.82235]
20Nov22_233236| [ 0.64675  0.16087 -1.97330  0.51762]]
20Nov22_233236|-- Bias --
20Nov22_233236|[ 0.89711 -0.39996  1.01868  0.39897]
20Nov22_233236|Layer 3:
20Nov22_233236|-- Config --
20Nov22_233236|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233236|-- Weights --
20Nov22_233236|[[ 0.32156  0.32873 -0.08875  0.41462]
20Nov22_233236| [-0.84923  0.88443 -0.12856  0.14256]
20Nov22_233236| [ 1.22213  1.14350 -0.11814  0.15883]
20Nov22_233236| [ 0.26940 -0.37695 -0.50873 -0.17207]]
20Nov22_233236|-- Bias --
20Nov22_233236|[ 0.89054  0.79647 -0.41753  0.26091]
20Nov22_233236|Layer 4:
20Nov22_233236|-- Config --
20Nov22_233236|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233236|-- Weights --
20Nov22_233236|[[ 0.03632 -1.06797]
20Nov22_233236| [ 0.30684  1.00972]
20Nov22_233236| [-1.27764  0.99457]
20Nov22_233236| [-0.33613 -0.12665]]
20Nov22_233236|-- Bias --
20Nov22_233236|[-0.70391 -0.35113]
20Nov22_233236|Predicting the validation and test data with the Best final individual.
20Nov22_233243| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov22_233243|-----------  ------------------  --------------------  ----------
20Nov22_233243|Validation         28.70                  48            0.68839
20Nov22_233243|   Test            25.54                  48            0.62772
20Nov22_233243|-------------------------- Test #11 --------------------------
20Nov22_233243|Best final individual weights
20Nov22_233243|Individual:
20Nov22_233243|-- Constant hidden layers --
20Nov22_233243|False
20Nov22_233243|Layer 0:
20Nov22_233243|-- Config --
20Nov22_233243|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233243|-- Weights --
20Nov22_233243|[[ 0.31067  1.04208]
20Nov22_233243| [ 1.22299  0.01432]
20Nov22_233243| [ 0.79550 -0.40760]
20Nov22_233243| [-2.16624 -1.88313]
20Nov22_233243| [ 0.87286  0.94682]
20Nov22_233243| [ 0.66090  1.36365]
20Nov22_233243| [-0.84894  1.51297]
20Nov22_233243| [-1.42130  1.96017]
20Nov22_233243| [ 0.00894 -0.06965]
20Nov22_233243| [ 1.85177 -0.74199]
20Nov22_233243| [-0.97319 -0.63846]
20Nov22_233243| [-0.48237  1.76131]
20Nov22_233243| [ 0.39013  0.25550]
20Nov22_233243| [-0.75703  0.89261]
20Nov22_233243| [-0.42042  1.00725]
20Nov22_233243| [-0.34138  0.17486]
20Nov22_233243| [ 0.88943 -0.46901]
20Nov22_233243| [-0.74247 -0.29372]
20Nov22_233243| [-0.54323 -1.79078]
20Nov22_233243| [-0.79119 -0.42149]
20Nov22_233243| [-1.87179  0.15971]
20Nov22_233243| [ 0.56242  0.52523]
20Nov22_233243| [-0.41700  0.14775]
20Nov22_233243| [ 2.08280 -1.92186]
20Nov22_233243| [ 0.13396  0.59688]
20Nov22_233243| [-0.29457  1.13513]
20Nov22_233243| [ 0.47883 -0.59367]
20Nov22_233243| [ 0.33787  0.69830]
20Nov22_233243| [-0.18090 -0.42958]
20Nov22_233243| [-1.07236 -0.94238]
20Nov22_233243| [-0.39442  0.07831]
20Nov22_233243| [-0.21956  0.71195]
20Nov22_233243| [ 1.79392 -0.48642]
20Nov22_233243| [-0.36856  0.09153]
20Nov22_233243| [-0.12850 -0.24442]
20Nov22_233243| [ 0.39517  0.11028]
20Nov22_233243| [-0.25405  0.32680]
20Nov22_233243| [ 0.71828 -0.70769]
20Nov22_233243| [ 1.22261  0.52275]
20Nov22_233243| [ 0.73888  0.58055]
20Nov22_233243| [-1.34521 -0.45328]
20Nov22_233243| [ 1.26344 -0.48773]
20Nov22_233243| [-0.73363  0.98363]
20Nov22_233243| [ 0.15762  0.47715]
20Nov22_233243| [ 0.04322  2.38047]
20Nov22_233243| [ 0.22812 -1.56141]
20Nov22_233243| [ 0.95421  1.59583]
20Nov22_233243| [-0.44250  0.33349]
20Nov22_233243| [ 1.05130 -0.41546]
20Nov22_233243| [ 1.39962 -1.22635]
20Nov22_233243| [ 0.24162 -0.05621]
20Nov22_233243| [-0.23985 -1.06417]
20Nov22_233243| [-0.05211  0.68172]
20Nov22_233243| [ 0.28536  2.37729]
20Nov22_233243| [-0.51275 -0.81888]
20Nov22_233243| [-0.68859  1.75815]
20Nov22_233243| [-0.11612 -0.06331]]
20Nov22_233243|-- Bias --
20Nov22_233243|[0.72775 0.20467]
20Nov22_233243|Layer 1:
20Nov22_233243|-- Config --
20Nov22_233243|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233243|-- Weights --
20Nov22_233243|[[ 1.70886 -1.05378]
20Nov22_233243| [-1.05881  0.40379]]
20Nov22_233243|-- Bias --
20Nov22_233243|[-1.26979  0.64071]
20Nov22_233243|Layer 2:
20Nov22_233243|-- Config --
20Nov22_233243|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233243|-- Weights --
20Nov22_233243|[[ 1.13276 -0.19138  0.72299 -0.82235]
20Nov22_233243| [ 0.64675  0.16087 -1.97330  0.51762]]
20Nov22_233243|-- Bias --
20Nov22_233243|[ 0.89711 -0.39996  1.01868  0.39897]
20Nov22_233243|Layer 3:
20Nov22_233243|-- Config --
20Nov22_233243|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233243|-- Weights --
20Nov22_233243|[[ 0.32156  0.32873 -0.08875  0.41462]
20Nov22_233243| [-0.84923  0.88443 -0.12856  0.14256]
20Nov22_233243| [ 1.22213  1.14350 -0.11814  0.15883]
20Nov22_233243| [ 0.26940 -0.37695 -0.50873 -0.17207]]
20Nov22_233243|-- Bias --
20Nov22_233243|[ 0.89054  0.79647 -0.41753  0.26091]
20Nov22_233243|Layer 4:
20Nov22_233243|-- Config --
20Nov22_233243|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233243|-- Weights --
20Nov22_233243|[[ 0.03632 -1.06797]
20Nov22_233243| [ 0.30684  1.00972]
20Nov22_233243| [-1.27764  0.99457]
20Nov22_233243| [-0.33613 -0.12665]]
20Nov22_233243|-- Bias --
20Nov22_233243|[-0.70391 -0.35113]
20Nov22_233243|Predicting the validation and test data with the Best final individual.
20Nov22_233249| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov22_233249|-----------  ------------------  --------------------  ----------
20Nov22_233249|Validation         42.00                  48            0.00000
20Nov22_233249|   Test            36.40                  48            0.00000
20Nov22_233249|-------------------------- Test #12 --------------------------
20Nov22_233249|Best final individual weights
20Nov22_233249|Individual:
20Nov22_233249|-- Constant hidden layers --
20Nov22_233249|False
20Nov22_233249|Layer 0:
20Nov22_233249|-- Config --
20Nov22_233249|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233249|-- Weights --
20Nov22_233249|[[ 0.31067  1.04208]
20Nov22_233249| [ 1.22299  0.01432]
20Nov22_233249| [ 0.79550 -0.40760]
20Nov22_233249| [-2.16624 -1.88313]
20Nov22_233249| [ 0.87286  0.94682]
20Nov22_233249| [ 0.66090  1.36365]
20Nov22_233249| [-0.84894  1.51297]
20Nov22_233249| [-1.42130  1.96017]
20Nov22_233249| [ 0.00894 -0.06965]
20Nov22_233249| [ 1.85177 -0.74199]
20Nov22_233249| [-0.97319 -0.63846]
20Nov22_233249| [-0.48237  1.76131]
20Nov22_233249| [ 0.39013  0.25550]
20Nov22_233249| [-0.75703  0.89261]
20Nov22_233249| [-0.42042  1.00725]
20Nov22_233249| [-0.34138  0.17486]
20Nov22_233249| [ 0.88943 -0.46901]
20Nov22_233249| [-0.74247 -0.29372]
20Nov22_233249| [-0.54323 -1.79078]
20Nov22_233249| [-0.79119 -0.42149]
20Nov22_233249| [-1.87179  0.15971]
20Nov22_233249| [ 0.56242  0.52523]
20Nov22_233249| [-0.41700  0.14775]
20Nov22_233249| [ 2.08280 -1.92186]
20Nov22_233249| [ 0.13396  0.59688]
20Nov22_233249| [-0.29457  1.13513]
20Nov22_233249| [ 0.47883 -0.59367]
20Nov22_233249| [ 0.33787  0.69830]
20Nov22_233249| [-0.18090 -0.42958]
20Nov22_233249| [-1.07236 -0.94238]
20Nov22_233249| [-0.39442  0.07831]
20Nov22_233249| [-0.21956  0.71195]
20Nov22_233249| [ 1.79392 -0.48642]
20Nov22_233249| [-0.36856  0.09153]
20Nov22_233249| [-0.12850 -0.24442]
20Nov22_233249| [ 0.39517  0.11028]
20Nov22_233249| [-0.25405  0.32680]
20Nov22_233249| [ 0.71828 -0.70769]
20Nov22_233249| [ 1.22261  0.52275]
20Nov22_233249| [ 0.73888  0.58055]
20Nov22_233249| [-1.34521 -0.45328]
20Nov22_233249| [ 1.26344 -0.48773]
20Nov22_233249| [-0.73363  0.98363]
20Nov22_233249| [ 0.15762  0.47715]
20Nov22_233249| [ 0.04322  2.38047]
20Nov22_233249| [ 0.22812 -1.56141]
20Nov22_233249| [ 0.95421  1.59583]
20Nov22_233249| [-0.44250  0.33349]
20Nov22_233249| [ 1.05130 -0.41546]
20Nov22_233249| [ 1.39962 -1.22635]
20Nov22_233249| [ 0.24162 -0.05621]
20Nov22_233249| [-0.23985 -1.06417]
20Nov22_233249| [-0.05211  0.68172]
20Nov22_233249| [ 0.28536  2.37729]
20Nov22_233249| [-0.51275 -0.81888]
20Nov22_233249| [-0.68859  1.75815]
20Nov22_233249| [-0.11612 -0.06331]]
20Nov22_233249|-- Bias --
20Nov22_233249|[0.72775 0.20467]
20Nov22_233249|Layer 1:
20Nov22_233249|-- Config --
20Nov22_233249|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233249|-- Weights --
20Nov22_233249|[[ 1.70886 -1.05378]
20Nov22_233249| [-1.05881  0.40379]]
20Nov22_233249|-- Bias --
20Nov22_233249|[-1.26979  0.64071]
20Nov22_233249|Layer 2:
20Nov22_233249|-- Config --
20Nov22_233249|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233249|-- Weights --
20Nov22_233249|[[ 1.13276 -0.19138  0.72299 -0.82235]
20Nov22_233249| [ 0.64675  0.16087 -1.97330  0.51762]]
20Nov22_233249|-- Bias --
20Nov22_233249|[ 0.89711 -0.39996  1.01868  0.39897]
20Nov22_233249|Layer 3:
20Nov22_233249|-- Config --
20Nov22_233249|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233249|-- Weights --
20Nov22_233249|[[ 0.32156  0.32873 -0.08875  0.41462]
20Nov22_233249| [-0.84923  0.88443 -0.12856  0.14256]
20Nov22_233249| [ 1.22213  1.14350 -0.11814  0.15883]
20Nov22_233249| [ 0.26940 -0.37695 -0.50873 -0.17207]]
20Nov22_233249|-- Bias --
20Nov22_233249|[ 0.89054  0.79647 -0.41753  0.26091]
20Nov22_233249|Layer 4:
20Nov22_233249|-- Config --
20Nov22_233249|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233249|-- Weights --
20Nov22_233249|[[ 0.03632 -1.06797]
20Nov22_233249| [ 0.30684  1.00972]
20Nov22_233249| [-1.27764  0.99457]
20Nov22_233249| [-0.33613 -0.12665]]
20Nov22_233249|-- Bias --
20Nov22_233249|[-0.70391 -0.35113]
20Nov22_233249|Predicting the validation and test data with the Best final individual.
20Nov22_233256| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov22_233256|-----------  ------------------  --------------------  ----------
20Nov22_233256|Validation         26.00                  48            0.65922
20Nov22_233256|   Test            24.24                  48            0.60089
20Nov22_233256|-------------------------- Test #13 --------------------------
20Nov22_233256|Best final individual weights
20Nov22_233256|Individual:
20Nov22_233256|-- Constant hidden layers --
20Nov22_233256|False
20Nov22_233256|Layer 0:
20Nov22_233256|-- Config --
20Nov22_233256|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233256|-- Weights --
20Nov22_233256|[[ 0.31067  1.04208]
20Nov22_233256| [ 1.22299  0.01432]
20Nov22_233256| [ 0.79550 -0.40760]
20Nov22_233256| [-2.16624 -1.88313]
20Nov22_233256| [ 0.87286  0.94682]
20Nov22_233256| [ 0.66090  1.36365]
20Nov22_233256| [-0.84894  1.51297]
20Nov22_233256| [-1.42130  1.96017]
20Nov22_233256| [ 0.00894 -0.06965]
20Nov22_233256| [ 1.85177 -0.74199]
20Nov22_233256| [-0.97319 -0.63846]
20Nov22_233256| [-0.48237  1.76131]
20Nov22_233256| [ 0.39013  0.25550]
20Nov22_233256| [-0.75703  0.89261]
20Nov22_233256| [-0.42042  1.00725]
20Nov22_233256| [-0.34138  0.17486]
20Nov22_233256| [ 0.88943 -0.46901]
20Nov22_233256| [-0.74247 -0.29372]
20Nov22_233256| [-0.54323 -1.79078]
20Nov22_233256| [-0.79119 -0.42149]
20Nov22_233256| [-1.87179  0.15971]
20Nov22_233256| [ 0.56242  0.52523]
20Nov22_233256| [-0.41700  0.14775]
20Nov22_233256| [ 2.08280 -1.92186]
20Nov22_233256| [ 0.13396  0.59688]
20Nov22_233256| [-0.29457  1.13513]
20Nov22_233256| [ 0.47883 -0.59367]
20Nov22_233256| [ 0.33787  0.69830]
20Nov22_233256| [-0.18090 -0.42958]
20Nov22_233256| [-1.07236 -0.94238]
20Nov22_233256| [-0.39442  0.07831]
20Nov22_233256| [-0.21956  0.71195]
20Nov22_233256| [ 1.79392 -0.48642]
20Nov22_233256| [-0.36856  0.09153]
20Nov22_233256| [-0.12850 -0.24442]
20Nov22_233256| [ 0.39517  0.11028]
20Nov22_233256| [-0.25405  0.32680]
20Nov22_233256| [ 0.71828 -0.70769]
20Nov22_233256| [ 1.22261  0.52275]
20Nov22_233256| [ 0.73888  0.58055]
20Nov22_233256| [-1.34521 -0.45328]
20Nov22_233256| [ 1.26344 -0.48773]
20Nov22_233256| [-0.73363  0.98363]
20Nov22_233256| [ 0.15762  0.47715]
20Nov22_233256| [ 0.04322  2.38047]
20Nov22_233256| [ 0.22812 -1.56141]
20Nov22_233256| [ 0.95421  1.59583]
20Nov22_233256| [-0.44250  0.33349]
20Nov22_233256| [ 1.05130 -0.41546]
20Nov22_233256| [ 1.39962 -1.22635]
20Nov22_233256| [ 0.24162 -0.05621]
20Nov22_233256| [-0.23985 -1.06417]
20Nov22_233256| [-0.05211  0.68172]
20Nov22_233256| [ 0.28536  2.37729]
20Nov22_233256| [-0.51275 -0.81888]
20Nov22_233256| [-0.68859  1.75815]
20Nov22_233256| [-0.11612 -0.06331]]
20Nov22_233256|-- Bias --
20Nov22_233256|[0.72775 0.20467]
20Nov22_233256|Layer 1:
20Nov22_233256|-- Config --
20Nov22_233256|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233256|-- Weights --
20Nov22_233256|[[ 1.70886 -1.05378]
20Nov22_233256| [-1.05881  0.40379]]
20Nov22_233256|-- Bias --
20Nov22_233256|[-1.26979  0.64071]
20Nov22_233256|Layer 2:
20Nov22_233256|-- Config --
20Nov22_233256|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233256|-- Weights --
20Nov22_233256|[[ 1.13276 -0.19138  0.72299 -0.82235]
20Nov22_233256| [ 0.64675  0.16087 -1.97330  0.51762]]
20Nov22_233256|-- Bias --
20Nov22_233256|[ 0.89711 -0.39996  1.01868  0.39897]
20Nov22_233256|Layer 3:
20Nov22_233256|-- Config --
20Nov22_233256|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233256|-- Weights --
20Nov22_233256|[[ 0.32156  0.32873 -0.08875  0.41462]
20Nov22_233256| [-0.84923  0.88443 -0.12856  0.14256]
20Nov22_233256| [ 1.22213  1.14350 -0.11814  0.15883]
20Nov22_233256| [ 0.26940 -0.37695 -0.50873 -0.17207]]
20Nov22_233256|-- Bias --
20Nov22_233256|[ 0.89054  0.79647 -0.41753  0.26091]
20Nov22_233256|Layer 4:
20Nov22_233256|-- Config --
20Nov22_233256|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233256|-- Weights --
20Nov22_233256|[[ 0.03632 -1.06797]
20Nov22_233256| [ 0.30684  1.00972]
20Nov22_233256| [-1.27764  0.99457]
20Nov22_233256| [-0.33613 -0.12665]]
20Nov22_233256|-- Bias --
20Nov22_233256|[-0.70391 -0.35113]
20Nov22_233256|Predicting the validation and test data with the Best final individual.
20Nov22_233303| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov22_233303|-----------  ------------------  --------------------  ----------
20Nov22_233303|Validation         26.00                  48            0.65456
20Nov22_233303|   Test            36.40                  48            0.00000
20Nov22_233303|-------------------------- Test #14 --------------------------
20Nov22_233303|Best final individual weights
20Nov22_233303|Individual:
20Nov22_233303|-- Constant hidden layers --
20Nov22_233303|False
20Nov22_233303|Layer 0:
20Nov22_233303|-- Config --
20Nov22_233303|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233303|-- Weights --
20Nov22_233303|[[ 0.31067  1.04208]
20Nov22_233303| [ 1.22299  0.01432]
20Nov22_233303| [ 0.79550 -0.40760]
20Nov22_233303| [-2.16624 -1.88313]
20Nov22_233303| [ 0.87286  0.94682]
20Nov22_233303| [ 0.66090  1.36365]
20Nov22_233303| [-0.84894  1.51297]
20Nov22_233303| [-1.42130  1.96017]
20Nov22_233303| [ 0.00894 -0.06965]
20Nov22_233303| [ 1.85177 -0.74199]
20Nov22_233303| [-0.97319 -0.63846]
20Nov22_233303| [-0.48237  1.76131]
20Nov22_233303| [ 0.39013  0.25550]
20Nov22_233303| [-0.75703  0.89261]
20Nov22_233303| [-0.42042  1.00725]
20Nov22_233303| [-0.34138  0.17486]
20Nov22_233303| [ 0.88943 -0.46901]
20Nov22_233303| [-0.74247 -0.29372]
20Nov22_233303| [-0.54323 -1.79078]
20Nov22_233303| [-0.79119 -0.42149]
20Nov22_233303| [-1.87179  0.15971]
20Nov22_233303| [ 0.56242  0.52523]
20Nov22_233303| [-0.41700  0.14775]
20Nov22_233303| [ 2.08280 -1.92186]
20Nov22_233303| [ 0.13396  0.59688]
20Nov22_233303| [-0.29457  1.13513]
20Nov22_233303| [ 0.47883 -0.59367]
20Nov22_233303| [ 0.33787  0.69830]
20Nov22_233303| [-0.18090 -0.42958]
20Nov22_233303| [-1.07236 -0.94238]
20Nov22_233303| [-0.39442  0.07831]
20Nov22_233303| [-0.21956  0.71195]
20Nov22_233303| [ 1.79392 -0.48642]
20Nov22_233303| [-0.36856  0.09153]
20Nov22_233303| [-0.12850 -0.24442]
20Nov22_233303| [ 0.39517  0.11028]
20Nov22_233303| [-0.25405  0.32680]
20Nov22_233303| [ 0.71828 -0.70769]
20Nov22_233303| [ 1.22261  0.52275]
20Nov22_233303| [ 0.73888  0.58055]
20Nov22_233303| [-1.34521 -0.45328]
20Nov22_233303| [ 1.26344 -0.48773]
20Nov22_233303| [-0.73363  0.98363]
20Nov22_233303| [ 0.15762  0.47715]
20Nov22_233303| [ 0.04322  2.38047]
20Nov22_233303| [ 0.22812 -1.56141]
20Nov22_233303| [ 0.95421  1.59583]
20Nov22_233303| [-0.44250  0.33349]
20Nov22_233303| [ 1.05130 -0.41546]
20Nov22_233303| [ 1.39962 -1.22635]
20Nov22_233303| [ 0.24162 -0.05621]
20Nov22_233303| [-0.23985 -1.06417]
20Nov22_233303| [-0.05211  0.68172]
20Nov22_233303| [ 0.28536  2.37729]
20Nov22_233303| [-0.51275 -0.81888]
20Nov22_233303| [-0.68859  1.75815]
20Nov22_233303| [-0.11612 -0.06331]]
20Nov22_233303|-- Bias --
20Nov22_233303|[0.72775 0.20467]
20Nov22_233303|Layer 1:
20Nov22_233303|-- Config --
20Nov22_233303|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233303|-- Weights --
20Nov22_233303|[[ 1.70886 -1.05378]
20Nov22_233303| [-1.05881  0.40379]]
20Nov22_233303|-- Bias --
20Nov22_233303|[-1.26979  0.64071]
20Nov22_233303|Layer 2:
20Nov22_233303|-- Config --
20Nov22_233303|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233303|-- Weights --
20Nov22_233303|[[ 1.13276 -0.19138  0.72299 -0.82235]
20Nov22_233303| [ 0.64675  0.16087 -1.97330  0.51762]]
20Nov22_233303|-- Bias --
20Nov22_233303|[ 0.89711 -0.39996  1.01868  0.39897]
20Nov22_233303|Layer 3:
20Nov22_233303|-- Config --
20Nov22_233303|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233303|-- Weights --
20Nov22_233303|[[ 0.32156  0.32873 -0.08875  0.41462]
20Nov22_233303| [-0.84923  0.88443 -0.12856  0.14256]
20Nov22_233303| [ 1.22213  1.14350 -0.11814  0.15883]
20Nov22_233303| [ 0.26940 -0.37695 -0.50873 -0.17207]]
20Nov22_233303|-- Bias --
20Nov22_233303|[ 0.89054  0.79647 -0.41753  0.26091]
20Nov22_233303|Layer 4:
20Nov22_233303|-- Config --
20Nov22_233303|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov22_233303|-- Weights --
20Nov22_233303|[[ 0.03632 -1.06797]
20Nov22_233303| [ 0.30684  1.00972]
20Nov22_233303| [-1.27764  0.99457]
20Nov22_233303| [-0.33613 -0.12665]]
20Nov22_233303|-- Bias --
20Nov22_233303|[-0.70391 -0.35113]
20Nov22_233303|Predicting the validation and test data with the Best final individual.
20Nov22_233309| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov22_233309|-----------  ------------------  --------------------  ----------
20Nov22_233309|Validation         28.61                  48            0.56571
20Nov22_233309|   Test            25.28                  48            0.65890
Using Theano backend.
20Nov22_233310|Data summary: Train
20Nov22_233310|data.shape = (2300, 57)
20Nov22_233310|labels.shape = (2300,)
20Nov22_233310|Class distribution:
20Nov22_233310|	0 - 1389 (0.60)
20Nov22_233310|	1 - 911 (0.40)
20Nov22_233310|Data summary: Validation
20Nov22_233310|data.shape = (1150, 57)
20Nov22_233310|labels.shape = (1150,)
20Nov22_233310|Class distribution:
20Nov22_233310|	0 - 667 (0.58)
20Nov22_233310|	1 - 483 (0.42)
20Nov22_233310|Data summary: Test
20Nov22_233310|data.shape = (1151, 57)
20Nov22_233310|labels.shape = (1151,)
20Nov22_233310|Class distribution:
20Nov22_233310|	0 - 732 (0.64)
20Nov22_233310|	1 - 419 (0.36)
20Nov22_233310|Selected configuration values
20Nov22_233310|-- Dataset name: spambase2
20Nov22_233310|-- Initial population size: 64
20Nov22_233310|-- Maximun number of generations: 32
20Nov22_233310|-- Neurons per hidden layer range: (2, 20)
20Nov22_233310|-- Hidden layers number range: (1, 3)
20Nov22_233310|-- Crossover probability: 0.5
20Nov22_233310|-- Bias gene mutation probability: 0.2
20Nov22_233310|-- Weights gene mutation probability: 0.75
20Nov22_233310|-- Neuron mutation probability: 0.3
20Nov22_233310|-- Layer mutation probability: 0.3
20Nov22_233310|-- Constant hidden layers: False
20Nov22_233310|-- Seed: None
20Nov22_233310|Entering GA
20Nov22_233310|Start the algorithm
20Nov22_233627|-- Generation 1 --
20Nov22_233627|    -- Crossed 0 individual pairs.
20Nov22_233627|    -- Mutated 32 individuals.
20Nov22_233936|    -- Evaluated 64 individuals.
20Nov22_233936|    Summary of generation 1:
20Nov22_233936| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_233936|-----------  ------------------  --------------------  ----------
20Nov22_233936|    Max            58.00                111.00          0.79103
20Nov22_233936|    Avg            42.41                31.27           0.02843
20Nov22_233936|    Min            37.39                 2.00           0.00000
20Nov22_233936|    Std             2.65                24.89           0.13772
20Nov22_233936|   Best            37.39                 5.00           0.15944
20Nov22_233936|-- Generation 2 --
20Nov22_233936|    -- Crossed 1 individual pairs.
20Nov22_233936|    -- Mutated 32 individuals.
20Nov22_234239|    -- Evaluated 64 individuals.
20Nov22_234239|    Summary of generation 2:
20Nov22_234239| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_234239|-----------  ------------------  --------------------  ----------
20Nov22_234239|    Max            42.52                69.00           0.53476
20Nov22_234239|    Avg            41.56                19.58           0.02020
20Nov22_234239|    Min            27.39                 3.00           0.00000
20Nov22_234239|    Std             2.22                13.62           0.08472
20Nov22_234239|   Best            27.39                12.00           0.53476
20Nov22_234239|-- Generation 3 --
20Nov22_234239|    -- Crossed 0 individual pairs.
20Nov22_234239|    -- Mutated 32 individuals.
20Nov22_234538|    -- Evaluated 64 individuals.
20Nov22_234538|    Summary of generation 3:
20Nov22_234538| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_234538|-----------  ------------------  --------------------  ----------
20Nov22_234538|    Max            57.30                75.00           0.82001
20Nov22_234538|    Avg            41.96                13.80           0.02994
20Nov22_234538|    Min            31.13                 3.00           0.00000
20Nov22_234538|    Std             2.37                12.36           0.13929
20Nov22_234538|   Best            31.13                16.00           0.82001
20Nov22_234538|-- Generation 4 --
20Nov22_234538|    -- Crossed 2 individual pairs.
20Nov22_234538|    -- Mutated 32 individuals.
20Nov22_234838|    -- Evaluated 64 individuals.
20Nov22_234838|    Summary of generation 4:
20Nov22_234838| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_234838|-----------  ------------------  --------------------  ----------
20Nov22_234838|    Max            42.26                75.00           0.75800
20Nov22_234838|    Avg            41.47                14.03           0.02272
20Nov22_234838|    Min            25.48                 2.00           0.00000
20Nov22_234838|    Std             2.54                13.55           0.10734
20Nov22_234838|   Best            25.48                16.00           0.75800
20Nov22_234838|-- Generation 5 --
20Nov22_234838|    -- Crossed 4 individual pairs.
20Nov22_234838|    -- Mutated 32 individuals.
20Nov22_235136|    -- Evaluated 64 individuals.
20Nov22_235136|    Summary of generation 5:
20Nov22_235136| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_235136|-----------  ------------------  --------------------  ----------
20Nov22_235136|    Max            47.04                75.00           0.81127
20Nov22_235136|    Avg            42.00                12.94           0.01622
20Nov22_235136|    Min            40.17                 2.00           0.00000
20Nov22_235136|    Std             0.68                13.78           0.10047
20Nov22_235136|   Best            40.17                12.00           0.05876
20Nov22_235136|-- Generation 6 --
20Nov22_235136|    -- Crossed 2 individual pairs.
20Nov22_235136|    -- Mutated 32 individuals.
20Nov22_235435|    -- Evaluated 64 individuals.
20Nov22_235435|    Summary of generation 6:
20Nov22_235435| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_235435|-----------  ------------------  --------------------  ----------
20Nov22_235435|    Max            42.17                75.00           0.13184
20Nov22_235435|    Avg            41.85                14.59           0.00798
20Nov22_235435|    Min            39.39                 2.00           0.00000
20Nov22_235435|    Std             0.50                14.32           0.02137
20Nov22_235435|   Best            39.39                12.00           0.09119
20Nov22_235435|-- Generation 7 --
20Nov22_235435|    -- Crossed 2 individual pairs.
20Nov22_235435|    -- Mutated 32 individuals.
20Nov22_235734|    -- Evaluated 64 individuals.
20Nov22_235734|    Summary of generation 7:
20Nov22_235734| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov22_235734|-----------  ------------------  --------------------  ----------
20Nov22_235734|    Max            46.00                75.00           0.80185
20Nov22_235734|    Avg            41.78                13.91           0.02464
20Nov22_235734|    Min            33.13                 2.00           0.00000
20Nov22_235734|    Std             1.40                14.33           0.11034
20Nov22_235734|   Best            33.13                10.00           0.30048
20Nov22_235734|-- Generation 8 --
20Nov22_235734|    -- Crossed 4 individual pairs.
20Nov22_235734|    -- Mutated 32 individuals.
20Nov23_000033|    -- Evaluated 64 individuals.
20Nov23_000033|    Summary of generation 8:
20Nov23_000033| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_000033|-----------  ------------------  --------------------  ----------
20Nov23_000033|    Max            42.26                120.00          0.46639
20Nov23_000033|    Avg            41.56                14.91           0.01813
20Nov23_000033|    Min            28.70                 2.00           0.00000
20Nov23_000033|    Std             1.76                17.84           0.06612
20Nov23_000033|   Best            28.70                27.00           0.46639
20Nov23_000033|-- Generation 9 --
20Nov23_000033|    -- Crossed 2 individual pairs.
20Nov23_000033|    -- Mutated 32 individuals.
20Nov23_000330|    -- Evaluated 64 individuals.
20Nov23_000330|    Summary of generation 9:
20Nov23_000330| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_000330|-----------  ------------------  --------------------  ----------
20Nov23_000330|    Max            42.17                34.00           0.76667
20Nov23_000330|    Avg            41.43                11.08           0.02514
20Nov23_000330|    Min            27.30                 2.00           0.00000
20Nov23_000330|    Std             2.51                 7.76           0.11354
20Nov23_000330|   Best            27.30                27.00           0.52266
20Nov23_000330|-- Generation 10 --
20Nov23_000330|    -- Crossed 2 individual pairs.
20Nov23_000330|    -- Mutated 32 individuals.
20Nov23_000626|    -- Evaluated 64 individuals.
20Nov23_000626|    Summary of generation 10:
20Nov23_000626| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_000626|-----------  ------------------  --------------------  ----------
20Nov23_000626|    Max            42.26                34.00           0.80989
20Nov23_000626|    Avg            41.24                 9.77           0.03678
20Nov23_000626|    Min            25.74                 2.00           0.00000
20Nov23_000626|    Std             2.66                 7.29           0.13890
20Nov23_000626|   Best            25.74                27.00           0.76403
20Nov23_000626|-- Generation 11 --
20Nov23_000626|    -- Crossed 2 individual pairs.
20Nov23_000626|    -- Mutated 32 individuals.
20Nov23_000922|    -- Evaluated 64 individuals.
20Nov23_000922|    Summary of generation 11:
20Nov23_000922| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_000922|-----------  ------------------  --------------------  ----------
20Nov23_000922|    Max            42.52                28.00           0.12244
20Nov23_000922|    Avg            41.77                 8.86           0.01043
20Nov23_000922|    Min            39.30                 3.00           0.00000
20Nov23_000922|    Std             0.59                 6.02           0.02256
20Nov23_000922|   Best            39.30                12.00           0.09123
20Nov23_000922|-- Generation 12 --
20Nov23_000922|    -- Crossed 3 individual pairs.
20Nov23_000922|    -- Mutated 32 individuals.
20Nov23_001217|    -- Evaluated 64 individuals.
20Nov23_001217|    Summary of generation 12:
20Nov23_001217| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_001217|-----------  ------------------  --------------------  ----------
20Nov23_001217|    Max            42.26                30.00           0.44573
20Nov23_001217|    Avg            41.56                 8.72           0.01720
20Nov23_001217|    Min            28.70                 3.00           0.00000
20Nov23_001217|    Std             1.67                 5.82           0.05664
20Nov23_001217|   Best            28.70                27.00           0.44573
20Nov23_001217|-- Generation 13 --
20Nov23_001217|    -- Crossed 2 individual pairs.
20Nov23_001217|    -- Mutated 32 individuals.
20Nov23_001512|    -- Evaluated 64 individuals.
20Nov23_001512|    Summary of generation 13:
20Nov23_001512| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_001512|-----------  ------------------  --------------------  ----------
20Nov23_001512|    Max            42.35                34.00           0.05360
20Nov23_001512|    Avg            41.86                 9.91           0.00653
20Nov23_001512|    Min            40.70                 3.00           0.00000
20Nov23_001512|    Std             0.23                 7.21           0.00745
20Nov23_001512|   Best            40.70                13.00           0.05360
20Nov23_001512|-- Generation 14 --
20Nov23_001512|    -- Crossed 3 individual pairs.
20Nov23_001512|    -- Mutated 32 individuals.
20Nov23_001807|    -- Evaluated 64 individuals.
20Nov23_001807|    Summary of generation 14:
20Nov23_001807| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_001807|-----------  ------------------  --------------------  ----------
20Nov23_001807|    Max            42.52                34.00           0.14786
20Nov23_001807|    Avg            41.73                 8.66           0.01251
20Nov23_001807|    Min            39.04                 3.00           0.00000
20Nov23_001807|    Std             0.58                 6.04           0.02740
20Nov23_001807|   Best            39.04                 5.00           0.13695
20Nov23_001807|-- Generation 15 --
20Nov23_001807|    -- Crossed 4 individual pairs.
20Nov23_001807|    -- Mutated 32 individuals.
20Nov23_002101|    -- Evaluated 64 individuals.
20Nov23_002101|    Summary of generation 15:
20Nov23_002101| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_002101|-----------  ------------------  --------------------  ----------
20Nov23_002101|    Max            42.52                30.00           0.80614
20Nov23_002101|    Avg            41.53                 8.05           0.02534
20Nov23_002101|    Min            27.48                 3.00           0.00000
20Nov23_002101|    Std             1.87                 6.06           0.10321
20Nov23_002101|   Best            27.48                30.00           0.80614
20Nov23_002101|-- Generation 16 --
20Nov23_002101|    -- Crossed 2 individual pairs.
20Nov23_002101|    -- Mutated 32 individuals.
20Nov23_002358|    -- Evaluated 64 individuals.
20Nov23_002358|    Summary of generation 16:
20Nov23_002358| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_002358|-----------  ------------------  --------------------  ----------
20Nov23_002358|    Max            42.61                30.00           0.75813
20Nov23_002358|    Avg            41.19                 9.33           0.04156
20Nov23_002358|    Min            23.04                 3.00           0.00000
20Nov23_002358|    Std             3.08                 6.73           0.13912
20Nov23_002358|   Best            23.04                22.00           0.75813
20Nov23_002358|-- Generation 17 --
20Nov23_002358|    -- Crossed 2 individual pairs.
20Nov23_002358|    -- Mutated 32 individuals.
20Nov23_002653|    -- Evaluated 64 individuals.
20Nov23_002653|    Summary of generation 17:
20Nov23_002653| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_002653|-----------  ------------------  --------------------  ----------
20Nov23_002653|    Max            42.26                36.00           0.82553
20Nov23_002653|    Avg            41.41                 8.69           0.03035
20Nov23_002653|    Min            28.52                 3.00           0.00000
20Nov23_002653|    Std             2.24                 7.18           0.11768
20Nov23_002653|   Best            28.52                30.00           0.47792
20Nov23_002653|-- Generation 18 --
20Nov23_002653|    -- Crossed 6 individual pairs.
20Nov23_002653|    -- Mutated 32 individuals.
20Nov23_002947|    -- Evaluated 64 individuals.
20Nov23_002947|    Summary of generation 18:
20Nov23_002947| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_002947|-----------  ------------------  --------------------  ----------
20Nov23_002947|    Max            42.17                33.00           0.63543
20Nov23_002947|    Avg            41.17                 7.23           0.03108
20Nov23_002947|    Min            25.57                 2.00           0.00000
20Nov23_002947|    Std             2.82                 6.20           0.10753
20Nov23_002947|   Best            25.57                33.00           0.63543
20Nov23_002947|-- Generation 19 --
20Nov23_002947|    -- Crossed 6 individual pairs.
20Nov23_002947|    -- Mutated 32 individuals.
20Nov23_003241|    -- Evaluated 64 individuals.
20Nov23_003241|    Summary of generation 19:
20Nov23_003241| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_003241|-----------  ------------------  --------------------  ----------
20Nov23_003241|    Max            42.26                33.00           0.83008
20Nov23_003241|    Avg            40.98                 7.56           0.05111
20Nov23_003241|    Min            22.96                 2.00           0.00000
20Nov23_003241|    Std             3.35                 7.24           0.16769
20Nov23_003241|   Best            22.96                30.00           0.65965
20Nov23_003241|-- Generation 20 --
20Nov23_003241|    -- Crossed 3 individual pairs.
20Nov23_003241|    -- Mutated 32 individuals.
20Nov23_003537|    -- Evaluated 64 individuals.
20Nov23_003537|    Summary of generation 20:
20Nov23_003537| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_003537|-----------  ------------------  --------------------  ----------
20Nov23_003537|    Max            42.35                36.00           0.80877
20Nov23_003537|    Avg            39.70                 9.56           0.09998
20Nov23_003537|    Min            23.83                 2.00           0.00000
20Nov23_003537|    Std             5.15                 9.66           0.21955
20Nov23_003537|   Best            23.83                30.00           0.63609
20Nov23_003537|-- Generation 21 --
20Nov23_003537|    -- Crossed 4 individual pairs.
20Nov23_003537|    -- Mutated 32 individuals.
20Nov23_003837|    -- Evaluated 64 individuals.
20Nov23_003837|    Summary of generation 21:
20Nov23_003837| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_003837|-----------  ------------------  --------------------  ----------
20Nov23_003837|    Max            42.26                36.00           0.82121
20Nov23_003837|    Avg            39.51                12.67           0.11484
20Nov23_003837|    Min            23.57                 2.00           0.00000
20Nov23_003837|    Std             5.22                11.53           0.23308
20Nov23_003837|   Best            23.57                33.00           0.76892
20Nov23_003837|-- Generation 22 --
20Nov23_003837|    -- Crossed 2 individual pairs.
20Nov23_003837|    -- Mutated 32 individuals.
20Nov23_004138|    -- Evaluated 64 individuals.
20Nov23_004138|    Summary of generation 22:
20Nov23_004138| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_004138|-----------  ------------------  --------------------  ----------
20Nov23_004138|    Max            42.52                64.00           0.81146
20Nov23_004138|    Avg            39.29                14.58           0.11973
20Nov23_004138|    Min            23.91                 2.00           0.00000
20Nov23_004138|    Std             5.55                13.64           0.23618
20Nov23_004138|   Best            23.91                64.00           0.66752
20Nov23_004138|-- Generation 23 --
20Nov23_004138|    -- Crossed 2 individual pairs.
20Nov23_004138|    -- Mutated 32 individuals.
20Nov23_004441|    -- Evaluated 64 individuals.
20Nov23_004441|    Summary of generation 23:
20Nov23_004441| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_004441|-----------  ------------------  --------------------  ----------
20Nov23_004441|    Max            42.43                64.00           0.78605
20Nov23_004441|    Avg            37.57                17.61           0.17547
20Nov23_004441|    Min            21.39                 2.00           0.00000
20Nov23_004441|    Std             6.62                18.07           0.26480
20Nov23_004441|   Best            21.39                64.00           0.75113
20Nov23_004441|-- Generation 24 --
20Nov23_004441|    -- Crossed 2 individual pairs.
20Nov23_004441|    -- Mutated 32 individuals.
20Nov23_004749|    -- Evaluated 64 individuals.
20Nov23_004749|    Summary of generation 24:
20Nov23_004749| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_004749|-----------  ------------------  --------------------  ----------
20Nov23_004749|    Max            42.09                64.00           0.81488
20Nov23_004749|    Avg            37.30                23.95           0.19798
20Nov23_004749|    Min            23.22                 2.00           0.00000
20Nov23_004749|    Std             6.48                19.35           0.27813
20Nov23_004749|   Best            23.22                36.00           0.76316
20Nov23_004749|-- Generation 25 --
20Nov23_004749|    -- Crossed 0 individual pairs.
20Nov23_004749|    -- Mutated 32 individuals.
20Nov23_005103|    -- Evaluated 64 individuals.
20Nov23_005103|    Summary of generation 25:
20Nov23_005103| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_005103|-----------  ------------------  --------------------  ----------
20Nov23_005103|    Max            42.00                105.00          0.83117
20Nov23_005103|    Avg            35.40                30.70           0.27439
20Nov23_005103|    Min            21.57                 2.00           0.00000
20Nov23_005103|    Std             7.44                23.31           0.31533
20Nov23_005103|   Best            21.57                30.00           0.76907
20Nov23_005103|-- Generation 26 --
20Nov23_005103|    -- Crossed 0 individual pairs.
20Nov23_005103|    -- Mutated 32 individuals.
20Nov23_005420|    -- Evaluated 64 individuals.
20Nov23_005420|    Summary of generation 26:
20Nov23_005420| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_005420|-----------  ------------------  --------------------  ----------
20Nov23_005420|    Max            42.09                64.00           0.83144
20Nov23_005420|    Avg            34.45                34.08           0.30633
20Nov23_005420|    Min            23.65                 3.00           0.00000
20Nov23_005420|    Std             7.50                16.61           0.30338
20Nov23_005420|   Best            23.65                36.00           0.75739
20Nov23_005420|-- Generation 27 --
20Nov23_005420|    -- Crossed 1 individual pairs.
20Nov23_005420|    -- Mutated 32 individuals.
20Nov23_005739|    -- Evaluated 64 individuals.
20Nov23_005739|    Summary of generation 27:
20Nov23_005739| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_005739|-----------  ------------------  --------------------  ----------
20Nov23_005739|    Max            42.87                95.00           0.81668
20Nov23_005739|    Avg            32.58                36.91           0.40678
20Nov23_005739|    Min            20.70                 4.00           0.00000
20Nov23_005739|    Std             7.66                15.13           0.31907
20Nov23_005739|   Best            20.70                33.00           0.69688
20Nov23_005739|-- Generation 28 --
20Nov23_005739|    -- Crossed 2 individual pairs.
20Nov23_005739|    -- Mutated 32 individuals.
20Nov23_010056|    -- Evaluated 64 individuals.
20Nov23_010056|    Summary of generation 28:
20Nov23_010056| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_010056|-----------  ------------------  --------------------  ----------
20Nov23_010056|    Max            49.74                68.00           0.81655
20Nov23_010056|    Avg            33.54                37.98           0.36485
20Nov23_010056|    Min            21.39                12.00           0.00000
20Nov23_010056|    Std             7.98                14.45           0.32470
20Nov23_010056|   Best            21.39                30.00           0.73069
20Nov23_010056|-- Generation 29 --
20Nov23_010056|    -- Crossed 1 individual pairs.
20Nov23_010056|    -- Mutated 32 individuals.
20Nov23_010417|    -- Evaluated 64 individuals.
20Nov23_010417|    Summary of generation 29:
20Nov23_010417| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_010417|-----------  ------------------  --------------------  ----------
20Nov23_010417|    Max            57.65                90.00           0.84835
20Nov23_010417|    Avg            33.44                40.36           0.39924
20Nov23_010417|    Min            20.96                12.00           0.00000
20Nov23_010417|    Std             8.38                16.13           0.32192
20Nov23_010417|   Best            20.96                33.00           0.73958
20Nov23_010417|-- Generation 30 --
20Nov23_010417|    -- Crossed 2 individual pairs.
20Nov23_010417|    -- Mutated 32 individuals.
20Nov23_010739|    -- Evaluated 64 individuals.
20Nov23_010739|    Summary of generation 30:
20Nov23_010739| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_010739|-----------  ------------------  --------------------  ----------
20Nov23_010739|    Max            42.17                120.00          0.83610
20Nov23_010739|    Avg            32.70                41.20           0.39366
20Nov23_010739|    Min            22.17                12.00           0.00000
20Nov23_010739|    Std             7.71                19.31           0.33074
20Nov23_010739|   Best            22.17                60.00           0.76688
20Nov23_010739|-- Generation 31 --
20Nov23_010739|    -- Crossed 2 individual pairs.
20Nov23_010739|    -- Mutated 32 individuals.
20Nov23_011102|    -- Evaluated 64 individuals.
20Nov23_011102|    Summary of generation 31:
20Nov23_011102| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_011102|-----------  ------------------  --------------------  ----------
20Nov23_011102|    Max            47.04                105.00          0.82042
20Nov23_011102|    Avg            33.71                44.30           0.36071
20Nov23_011102|    Min            22.00                12.00           0.00000
20Nov23_011102|    Std             7.85                18.90           0.31997
20Nov23_011102|   Best            22.00                33.00           0.64030
20Nov23_011102|-- Generation 32 --
20Nov23_011102|    -- Crossed 0 individual pairs.
20Nov23_011102|    -- Mutated 32 individuals.
20Nov23_011425|    -- Evaluated 64 individuals.
20Nov23_011425|    Summary of generation 32:
20Nov23_011425| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_011425|-----------  ------------------  --------------------  ----------
20Nov23_011425|    Max            42.09                105.00          0.79890
20Nov23_011425|    Avg            33.18                42.86           0.35843
20Nov23_011425|    Min            20.61                14.00           0.00000
20Nov23_011425|    Std             7.84                18.48           0.32405
20Nov23_011425|   Best            20.61                30.00           0.78240
20Nov23_011425|Best initial individual weights
20Nov23_011425|Individual:
20Nov23_011425|-- Constant hidden layers --
20Nov23_011425|False
20Nov23_011425|Layer 0:
20Nov23_011425|-- Config --
20Nov23_011425|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 12, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011425|-- Weights --
20Nov23_011425|[[ 8.18112e-01 -4.76167e-01  3.15049e-01  9.18041e-01  5.49922e-01
20Nov23_011425|   3.39137e-01  4.11650e-01  3.44509e-01  3.63289e-01 -9.11369e-01
20Nov23_011425|  -2.41221e-01 -6.35207e-01]
20Nov23_011425| [ 8.42843e-01 -2.78195e-01  6.77450e-01  9.01723e-01 -8.40220e-01
20Nov23_011425|  -6.38409e-01 -3.79785e-01  3.40635e-01  1.87684e-01 -4.54595e-01
20Nov23_011425|  -4.60210e-01  1.62211e-01]
20Nov23_011425| [-4.38842e-01 -6.78525e-02 -5.37832e-01 -9.44776e-01 -1.55801e-01
20Nov23_011425|   8.04726e-01  3.45910e-01 -2.74511e-01 -1.14288e-01  5.06124e-01
20Nov23_011425|   7.92959e-01  1.48817e-01]
20Nov23_011425| [-9.35355e-01 -6.22207e-01  7.48149e-01  3.02022e-01  1.96296e-01
20Nov23_011425|  -7.87376e-01 -1.76173e-02 -3.82919e-01  2.30361e-02  3.36325e-01
20Nov23_011425|   9.93457e-01 -9.97040e-01]
20Nov23_011425| [ 1.79793e-01 -2.43036e-01 -4.84666e-01 -4.53172e-01  1.96516e-01
20Nov23_011425|   7.64711e-01  3.42924e-01  5.64092e-01  2.14701e-01  9.69955e-02
20Nov23_011425|  -8.62235e-01  3.45933e-01]
20Nov23_011425| [ 5.00281e-01  3.19671e-01 -5.85569e-01  5.84227e-01  3.51464e-01
20Nov23_011425|  -8.64255e-02  3.25872e-01  3.10298e-01  3.75403e-01 -9.07563e-01
20Nov23_011425|  -1.75327e-01  6.12266e-01]
20Nov23_011425| [-8.78569e-01 -2.44514e-01  8.31572e-01 -7.84246e-01 -1.58370e-01
20Nov23_011425|  -2.58966e-01  5.50107e-01 -8.52430e-01 -6.66305e-01 -2.51749e-01
20Nov23_011425|   3.21319e-01 -9.83676e-02]
20Nov23_011425| [-9.39893e-01 -4.44733e-01  5.03744e-01 -7.98837e-01 -5.85175e-01
20Nov23_011425|   1.54427e-01 -2.25904e-01  8.54447e-01 -2.26761e-01  4.90240e-01
20Nov23_011425|  -1.37978e-01  1.46249e-01]
20Nov23_011425| [ 2.12460e-01 -1.62947e-01  1.14914e-01 -8.25891e-01  6.90930e-01
20Nov23_011425|   2.52721e-02 -4.73558e-01 -3.47707e-01 -2.41709e-01  9.18903e-01
20Nov23_011425|   2.12383e-01 -6.77911e-01]
20Nov23_011425| [-9.26773e-02 -1.35646e-01 -9.81635e-01 -8.88931e-01 -2.57443e-01
20Nov23_011425|  -9.85574e-01 -2.85044e-02 -1.87245e-01 -5.29067e-01 -6.59733e-01
20Nov23_011425|  -7.75112e-01 -3.34017e-01]
20Nov23_011425| [-7.83201e-01 -1.77446e-02  9.70222e-01 -3.10321e-01 -1.64718e-01
20Nov23_011425|  -2.47357e-01 -5.17517e-01 -1.73897e-01 -6.44534e-01  4.74909e-01
20Nov23_011425|  -2.32644e-01  3.59949e-01]
20Nov23_011425| [ 6.32819e-01 -1.11753e-01  7.95440e-01 -3.53301e-01  4.04738e-01
20Nov23_011425|   2.61605e-01 -1.77008e-01  7.80162e-01  1.38699e-01 -1.60455e-01
20Nov23_011425|  -4.00159e-02  3.20608e-01]
20Nov23_011425| [-9.69858e-01  9.22938e-01 -1.08287e-01 -2.25845e-01  1.55249e-01
20Nov23_011425|  -6.57998e-01 -8.52540e-01  6.08083e-01 -6.74458e-01 -8.84738e-01
20Nov23_011425|  -9.57890e-01 -9.75420e-01]
20Nov23_011425| [ 8.09973e-02  7.72844e-01 -2.24602e-01  6.77065e-01 -2.30247e-01
20Nov23_011425|  -7.81134e-02 -2.96472e-01  3.91645e-01 -1.67914e-02 -2.79598e-01
20Nov23_011425|  -1.21169e-01  1.42345e-03]
20Nov23_011425| [-8.63285e-03  4.81866e-01 -6.24808e-01 -3.19994e-01  8.78052e-01
20Nov23_011425|  -8.04083e-01 -9.88894e-01 -4.05123e-01  7.87272e-01 -4.57768e-01
20Nov23_011425|  -6.62057e-01  4.20945e-01]
20Nov23_011425| [ 7.13232e-01  7.00093e-01  1.56664e-01 -2.56613e-01 -2.85254e-01
20Nov23_011425|   6.12928e-01  7.99194e-02  4.36014e-01 -2.82100e-01  4.06612e-01
20Nov23_011425|   5.04129e-01 -5.25204e-01]
20Nov23_011425| [ 6.81008e-01 -1.48349e-02 -3.70263e-01  2.86868e-01 -9.73027e-01
20Nov23_011425|  -6.74880e-01 -4.06758e-01 -8.96094e-01  2.87976e-01 -3.24973e-01
20Nov23_011425|  -2.80179e-01 -7.08540e-01]
20Nov23_011425| [-8.22137e-01  1.73307e-01  2.00387e-01 -9.00322e-01  4.00411e-02
20Nov23_011425|   7.11309e-01 -6.41525e-01 -6.92019e-01  8.96093e-01  9.51555e-01
20Nov23_011425|   7.21853e-01 -1.34235e-01]
20Nov23_011425| [ 5.10898e-01  2.20492e-01  2.70425e-01  6.57114e-01 -7.31433e-01
20Nov23_011425|  -6.63091e-01 -1.80444e-01  3.41455e-01  7.96213e-01 -7.95209e-01
20Nov23_011425|  -4.93062e-02  6.96717e-01]
20Nov23_011425| [-5.28499e-01  4.65443e-01  8.84887e-01 -5.47999e-01 -3.74548e-01
20Nov23_011425|   3.69041e-01 -9.76428e-02 -1.41819e-01 -2.00511e-01 -9.46455e-01
20Nov23_011425|  -1.48273e-01  2.21171e-01]
20Nov23_011425| [-3.75048e-01 -4.79440e-03  1.51184e-01 -1.57914e-02 -1.55240e-01
20Nov23_011425|  -6.01087e-01  7.12939e-01  9.52230e-01 -2.84108e-01 -8.88930e-01
20Nov23_011425|  -1.68932e-01 -3.25501e-01]
20Nov23_011425| [-8.71386e-01  9.95216e-01 -7.19751e-01 -5.49005e-02  5.57804e-01
20Nov23_011425|   3.65116e-01 -4.55609e-01  7.48762e-01 -8.85815e-01  6.42462e-01
20Nov23_011425|   2.99755e-01 -7.63300e-01]
20Nov23_011425| [-7.37389e-01  4.86139e-01 -8.49554e-01 -2.83676e-01 -1.56217e-01
20Nov23_011425|  -4.27279e-01 -3.03399e-01 -5.94745e-02 -1.10038e-01  2.26153e-01
20Nov23_011425|  -6.95810e-01 -2.36456e-01]
20Nov23_011425| [ 5.15456e-01  4.41741e-01  2.08574e-01  3.34874e-01 -9.50705e-01
20Nov23_011425|   3.80784e-01 -3.11870e-01  1.99001e-01 -9.26952e-02 -8.48111e-01
20Nov23_011425|  -8.91195e-01 -7.83179e-01]
20Nov23_011425| [-5.24940e-01 -8.52620e-01 -4.86504e-01  8.62750e-02 -1.65198e-02
20Nov23_011425|  -9.63254e-02 -4.37441e-01 -6.62988e-01  6.87512e-02  5.26264e-01
20Nov23_011425|  -1.00703e-01 -3.92975e-01]
20Nov23_011425| [ 9.19411e-01 -6.01663e-01 -5.60248e-01  2.51487e-01  2.80005e-01
20Nov23_011425|   4.59021e-01  7.01768e-01  5.21567e-01  5.58031e-01  9.64168e-01
20Nov23_011425|  -2.35581e-01 -1.90663e-01]
20Nov23_011425| [ 1.18133e-01 -7.92986e-01  4.94473e-01  7.31121e-02  6.00087e-01
20Nov23_011425|   8.98081e-01 -4.90216e-01  5.07951e-01  1.56296e-01 -2.59947e-01
20Nov23_011425|  -1.72407e-01  2.62131e-01]
20Nov23_011425| [ 2.84204e-01  6.31903e-01  1.37312e-01  3.95591e-01 -6.89018e-01
20Nov23_011425|   2.65194e-01  7.58627e-01 -7.31692e-01  2.45974e-01  9.87022e-01
20Nov23_011425|   9.38028e-01 -4.23679e-01]
20Nov23_011425| [ 5.37645e-01 -3.85845e-01 -2.18941e-01  9.67342e-01 -2.73769e-01
20Nov23_011425|  -7.26643e-01 -2.15809e-01 -1.84719e-01  7.70947e-01 -3.18847e-01
20Nov23_011425|  -2.79120e-01  4.83778e-01]
20Nov23_011425| [ 6.69369e-01  4.90185e-01 -3.31619e-01 -6.79206e-01  7.69882e-01
20Nov23_011425|  -5.39043e-01 -5.64109e-01  4.46899e-01  6.19339e-01  9.58726e-01
20Nov23_011425|   3.37425e-01 -1.42714e-01]
20Nov23_011425| [ 7.60545e-01  6.84411e-01  2.60702e-01 -3.93100e-01 -2.53212e-01
20Nov23_011425|   3.71603e-01 -8.88399e-01 -3.03527e-01 -1.43528e-01 -3.03585e-01
20Nov23_011425|   1.54615e-01  9.98583e-01]
20Nov23_011425| [-4.01249e-01 -6.59513e-01 -2.36904e-01  7.22856e-01  8.39745e-01
20Nov23_011425|  -1.69446e-01 -6.94395e-01 -5.55600e-01 -7.41606e-01  9.69427e-01
20Nov23_011425|  -3.37014e-01 -1.99319e-01]
20Nov23_011425| [-5.12885e-01  6.27742e-01  4.73006e-01 -7.22510e-01 -1.72659e-01
20Nov23_011425|   2.97743e-01  5.00400e-02  7.93290e-01 -9.17953e-01  5.81118e-01
20Nov23_011425|   3.52625e-01 -7.91465e-01]
20Nov23_011425| [-3.84184e-01 -9.82946e-01 -2.91368e-01  1.00836e-02  1.51225e-02
20Nov23_011425|  -3.83065e-01 -5.49402e-01 -4.24141e-01  2.17203e-01  2.26475e-01
20Nov23_011425|   3.38148e-01  3.20983e-01]
20Nov23_011425| [ 5.96785e-01 -5.94528e-01  1.34927e-01 -7.71253e-02  2.15387e-01
20Nov23_011425|  -1.66577e-01 -4.15425e-02  6.17693e-01 -1.60595e-01 -7.40220e-01
20Nov23_011425|  -3.04807e-01 -6.62164e-02]
20Nov23_011425| [-9.86891e-01  6.57850e-01  3.19781e-01  2.16923e-01 -6.48204e-02
20Nov23_011425|   4.39565e-01 -8.26657e-01 -5.54463e-01 -9.10270e-02 -1.83615e-01
20Nov23_011425|  -7.80296e-01  1.98012e-01]
20Nov23_011425| [-4.89021e-01 -5.25718e-01  6.14938e-01  8.50182e-01 -8.21054e-02
20Nov23_011425|  -9.94922e-01  2.00113e-02 -9.00721e-02  4.55298e-01  2.30582e-01
20Nov23_011425|  -2.24554e-01  1.20252e-01]
20Nov23_011425| [ 5.05048e-01  5.31358e-01 -1.71884e-01  2.48831e-01  5.82416e-01
20Nov23_011425|  -2.36919e-01 -2.37716e-01  4.13900e-01  9.42277e-01  1.35732e-01
20Nov23_011425|  -3.01987e-01  4.89618e-01]
20Nov23_011425| [-7.41241e-01 -4.65377e-01  1.85737e-01  3.07826e-01  2.33204e-02
20Nov23_011425|  -9.02730e-02  5.48988e-01  4.34250e-01 -3.09016e-02 -9.59935e-02
20Nov23_011425|   8.99236e-01 -9.77219e-01]
20Nov23_011425| [ 4.36566e-02  8.03251e-01  8.80133e-02  7.25363e-01 -2.78240e-02
20Nov23_011425|  -3.87561e-02  4.88050e-01  8.01989e-01 -9.95620e-01 -5.70174e-01
20Nov23_011425|  -2.41929e-01  6.82351e-02]
20Nov23_011425| [ 9.37121e-02 -6.54601e-01  4.15563e-01 -7.18172e-01 -2.54957e-01
20Nov23_011425|  -5.30188e-01  6.53208e-01  5.96492e-01  5.53966e-01  6.16946e-01
20Nov23_011425|  -3.25480e-02 -9.01650e-01]
20Nov23_011425| [-4.31621e-01 -5.68372e-02  6.19425e-01 -7.38922e-01 -9.26644e-01
20Nov23_011425|   4.44811e-01 -9.48664e-01  1.10433e-01  7.15876e-01 -8.44408e-01
20Nov23_011425|  -3.02878e-01  4.68138e-01]
20Nov23_011425| [ 4.00816e-01 -9.36535e-01 -4.49039e-01  3.12895e-01  6.21458e-01
20Nov23_011425|   9.30800e-01  7.08702e-01 -1.33104e-01  8.96610e-02 -2.32235e-01
20Nov23_011425|  -7.96976e-01  4.94216e-01]
20Nov23_011425| [-5.32717e-01  1.15959e-01 -4.79697e-01 -9.75245e-01 -7.79945e-01
20Nov23_011425|  -7.51336e-01 -4.88294e-01 -3.54361e-02 -9.46496e-01 -3.40454e-01
20Nov23_011425|  -3.87620e-02  3.22783e-01]
20Nov23_011425| [ 3.61122e-01 -9.97182e-02  7.47118e-01 -4.34299e-01 -2.79229e-01
20Nov23_011425|   4.87574e-01 -8.27046e-01  1.50190e-01 -9.88397e-01 -1.50054e-01
20Nov23_011425|   1.03459e-02 -2.62052e-01]
20Nov23_011425| [ 6.33527e-01 -2.02339e-01 -9.85409e-01 -8.71135e-01 -4.63481e-01
20Nov23_011425|   5.99235e-01  5.52079e-01  1.18506e-01 -5.20545e-01  9.46775e-01
20Nov23_011425|   2.63741e-01  1.27913e-01]
20Nov23_011425| [ 5.08773e-01  5.61428e-01 -8.93266e-01 -2.72625e-01 -5.31239e-01
20Nov23_011425|  -7.41407e-01 -1.19191e-01 -5.73044e-03 -4.63459e-01 -6.39745e-01
20Nov23_011425|  -5.77224e-01 -3.57646e-01]
20Nov23_011425| [ 1.82110e-02  1.14244e-01 -8.88624e-01 -9.71748e-01 -4.52590e-01
20Nov23_011425|  -6.28985e-01  1.87610e-01 -7.66753e-02  4.04394e-01 -2.67309e-01
20Nov23_011425|   3.44496e-01 -5.58173e-01]
20Nov23_011425| [ 3.99240e-01 -5.25269e-01 -7.93057e-01 -8.63844e-02  7.47226e-01
20Nov23_011425|   4.02076e-01 -9.93777e-01  6.57911e-01  6.39825e-02  8.07411e-02
20Nov23_011425|   5.29709e-01  5.10900e-01]
20Nov23_011425| [ 3.75338e-01 -2.63596e-01  3.71151e-01  5.73774e-01  1.39545e-01
20Nov23_011425|   4.61077e-01 -4.26413e-01  3.02527e-01 -8.43777e-01 -4.83206e-01
20Nov23_011425|  -8.60219e-01  5.55151e-01]
20Nov23_011425| [-6.93456e-01  9.94926e-02  9.80569e-01 -4.80555e-01 -4.72926e-01
20Nov23_011425|  -1.04601e-01  9.33818e-01 -3.45421e-01 -5.22822e-01  6.67708e-02
20Nov23_011425|  -9.85510e-01 -1.86207e-01]
20Nov23_011425| [-3.71902e-01 -9.32141e-01 -3.48517e-01  4.18711e-01  3.91731e-01
20Nov23_011425|   9.01966e-01  6.56656e-01 -4.17692e-01 -6.00707e-01  4.38268e-01
20Nov23_011425|   9.18464e-01  9.70788e-01]
20Nov23_011425| [-7.37040e-01  2.81192e-02  2.13301e-01  8.34630e-01 -9.27480e-01
20Nov23_011425|  -4.33081e-01 -8.82777e-01  5.19723e-01  5.65216e-01 -5.00961e-02
20Nov23_011425|  -2.61246e-01  6.25121e-01]
20Nov23_011425| [-8.11837e-01  1.58222e-01 -7.21698e-01 -3.89861e-01 -7.98081e-01
20Nov23_011425|  -8.55953e-01 -1.52920e-01  6.34795e-01  9.01708e-01 -1.67017e-01
20Nov23_011425|   2.78695e-01 -6.55287e-01]
20Nov23_011425| [-6.41025e-01  3.09678e-01 -4.27645e-01 -2.34060e-01  6.74305e-01
20Nov23_011425|  -1.51074e-02  3.77702e-01  8.37173e-02  7.82373e-01  7.81189e-01
20Nov23_011425|  -8.48356e-01 -6.45924e-01]
20Nov23_011425| [-2.20125e-01 -9.19199e-01  8.13664e-01  2.77046e-01  8.84419e-03
20Nov23_011425|   3.18794e-02 -6.10423e-01  7.27892e-01 -8.84065e-01  7.25748e-01
20Nov23_011425|   5.84022e-01  6.48472e-01]
20Nov23_011425| [ 3.14706e-01 -5.76015e-01  5.22916e-01 -2.42620e-02 -6.97482e-01
20Nov23_011425|  -4.33946e-01  6.69622e-01 -2.94177e-01 -7.88809e-01 -5.07953e-01
20Nov23_011425|  -6.60594e-02  9.51596e-04]]
20Nov23_011425|-- Bias --
20Nov23_011425|[-0.94371 -0.46903 -0.05573 -0.46736 -0.75528  0.18777 -0.29527  0.63716
20Nov23_011425|  0.05627 -0.74694 -0.96842 -0.99060]
20Nov23_011425|Layer 1:
20Nov23_011425|-- Config --
20Nov23_011425|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 12], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011425|-- Weights --
20Nov23_011425|[[ 0.13977 -0.26202]
20Nov23_011425| [ 0.69216 -0.12247]
20Nov23_011425| [ 0.22686  0.23333]
20Nov23_011425| [ 0.15571  0.70648]
20Nov23_011425| [-0.79126 -0.80812]
20Nov23_011425| [-0.56968 -0.71535]
20Nov23_011425| [ 0.37206  0.68337]
20Nov23_011425| [-0.47668 -0.89128]
20Nov23_011425| [ 0.09211 -0.28544]
20Nov23_011425| [-0.02816 -0.69339]
20Nov23_011425| [-0.41590  0.46024]
20Nov23_011425| [-0.68995 -0.16959]]
20Nov23_011425|-- Bias --
20Nov23_011425|[0.55259 0.44675]
20Nov23_011425|Predicting the validation and test data with the Best initial individual.
20Nov23_011430| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_011430|-----------  ------------------  --------------------  ----------
20Nov23_011430|Validation         41.83                  12            0.00517
20Nov23_011430|   Test            36.49                  12            0.00000
20Nov23_011430|-------------------------- Test #0 --------------------------
20Nov23_011430|Best final individual weights
20Nov23_011430|Individual:
20Nov23_011430|-- Constant hidden layers --
20Nov23_011430|False
20Nov23_011430|Layer 0:
20Nov23_011430|-- Config --
20Nov23_011430|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011430|-- Weights --
20Nov23_011430|[[ 2.81544e-01 -6.05842e-01 -3.21862e-01]
20Nov23_011430| [-7.64574e-02 -2.25410e-01 -7.86841e-01]
20Nov23_011430| [ 5.08219e-01 -2.57665e-01 -8.75233e-01]
20Nov23_011430| [-4.28170e-01  2.49161e-01  9.10295e-01]
20Nov23_011430| [-1.65254e-01 -1.04497e-01  1.86138e+00]
20Nov23_011430| [ 6.03026e-01  1.31698e+00  7.98797e-01]
20Nov23_011430| [ 4.37297e-01  6.21939e-01 -1.89649e+00]
20Nov23_011430| [-2.43418e-01 -1.29067e+00 -7.49600e-01]
20Nov23_011430| [ 6.75794e-01 -1.12743e+00  3.42927e-01]
20Nov23_011430| [-2.07087e-01  9.79404e-01 -9.41263e-01]
20Nov23_011430| [ 8.69844e-01  7.91195e-01 -2.04005e+00]
20Nov23_011430| [ 5.93969e-01  1.18998e+00  5.09909e-03]
20Nov23_011430| [-5.71844e-01 -1.05100e+00  6.64230e-01]
20Nov23_011430| [-1.83662e-02  2.60684e+00 -7.75333e-01]
20Nov23_011430| [-1.18405e+00 -6.30927e-01  1.29120e+00]
20Nov23_011430| [ 3.34434e-01  1.55517e+00  9.41732e-01]
20Nov23_011430| [ 1.35568e+00  9.04461e-01  6.82207e-01]
20Nov23_011430| [ 1.93224e+00  3.91496e-01 -3.90810e-01]
20Nov23_011430| [-1.51525e-01 -7.53769e-01  1.44364e+00]
20Nov23_011430| [ 1.79326e-01  4.31204e-01  4.25079e-01]
20Nov23_011430| [ 1.95318e-01 -3.68398e-01  1.13710e+00]
20Nov23_011430| [-1.56550e-01  2.86035e+00 -7.02992e-01]
20Nov23_011430| [-5.31242e-01 -1.36915e+00  1.06615e+00]
20Nov23_011430| [ 1.04531e+00 -3.20438e-01 -9.39162e-01]
20Nov23_011430| [-1.07150e+00 -1.10448e+00 -9.56850e-01]
20Nov23_011430| [ 2.30780e-01 -2.36734e+00 -5.45672e-01]
20Nov23_011430| [ 1.65837e+00 -1.02596e+00 -3.75298e-01]
20Nov23_011430| [ 2.68860e-01  1.88532e+00  1.45863e+00]
20Nov23_011430| [-6.62057e-01 -1.72122e-01  1.88865e+00]
20Nov23_011430| [ 6.67736e-01 -1.56745e+00  2.07945e+00]
20Nov23_011430| [ 6.52308e-01  1.71595e+00  6.00436e-02]
20Nov23_011430| [-4.84083e-01 -1.83992e+00  7.88743e-01]
20Nov23_011430| [ 2.28388e+00  5.14928e-01 -7.89078e-01]
20Nov23_011430| [-2.05070e-01 -4.94209e-01 -5.11047e-04]
20Nov23_011430| [ 2.76401e-01 -8.45665e-01  4.85630e-01]
20Nov23_011430| [ 1.38631e+00 -2.31534e-01  1.67351e+00]
20Nov23_011430| [ 2.40003e+00  4.30293e-01 -2.96407e-01]
20Nov23_011430| [-1.47168e+00 -1.12201e-01  5.23174e-02]
20Nov23_011430| [-5.99205e-01  5.25595e-02  1.14262e+00]
20Nov23_011430| [ 2.53490e-01  4.60347e-01 -8.13702e-01]
20Nov23_011430| [ 5.70195e-01 -1.38869e+00  8.50057e-01]
20Nov23_011430| [-8.57604e-01  1.35131e-01  6.03295e-01]
20Nov23_011430| [ 1.66056e+00  5.23447e-01  3.67017e-01]
20Nov23_011430| [ 2.05585e+00  2.60901e-01 -5.66920e-01]
20Nov23_011430| [-9.64678e-01 -6.26877e-01 -9.49711e-01]
20Nov23_011430| [-2.45283e-01 -7.14134e-01  1.18386e+00]
20Nov23_011430| [ 2.89841e-01 -3.41799e-01 -1.53665e+00]
20Nov23_011430| [-1.53316e+00 -8.11328e-01 -5.98503e-01]
20Nov23_011430| [-6.02444e-01  1.00080e+00 -3.18191e-01]
20Nov23_011430| [-2.39051e-01  1.05130e-01 -1.06166e-01]
20Nov23_011430| [ 5.54031e-01  7.51923e-01  3.33091e-01]
20Nov23_011430| [-1.21813e+00 -8.37235e-01 -2.16431e-01]
20Nov23_011430| [ 1.05855e+00  1.40560e+00  1.01499e+00]
20Nov23_011430| [-6.41326e-01  1.17562e+00 -1.60862e+00]
20Nov23_011430| [ 1.28062e+00  2.02472e+00 -1.41452e+00]
20Nov23_011430| [-1.25873e+00  6.41406e-01  1.02626e+00]
20Nov23_011430| [-1.36105e+00  4.41459e-01  1.56613e-01]]
20Nov23_011430|-- Bias --
20Nov23_011430|[1.39717 0.90167 0.56598]
20Nov23_011430|Layer 1:
20Nov23_011430|-- Config --
20Nov23_011430|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011430|-- Weights --
20Nov23_011430|[[ 0.02852 -1.07742  0.56125]
20Nov23_011430| [ 0.46639 -1.07916  1.47345]
20Nov23_011430| [-0.12440 -0.62009  0.68029]]
20Nov23_011430|-- Bias --
20Nov23_011430|[-0.38219 -0.88277  0.64332]
20Nov23_011430|Layer 2:
20Nov23_011430|-- Config --
20Nov23_011430|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011430|-- Weights --
20Nov23_011430|[[-0.26708  0.46937  1.25164 -0.79851]
20Nov23_011430| [-0.22042 -0.90964  0.20610 -0.50982]
20Nov23_011430| [-0.57011  0.40682  0.33195 -0.63661]]
20Nov23_011430|-- Bias --
20Nov23_011430|[ 0.08651  0.38057 -0.52568  0.21822]
20Nov23_011430|Layer 3:
20Nov23_011430|-- Config --
20Nov23_011430|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011430|-- Weights --
20Nov23_011430|[[-1.68151  0.96943]
20Nov23_011430| [-1.25774 -0.78998]
20Nov23_011430| [-1.35154  0.53538]
20Nov23_011430| [-0.05379 -0.72412]]
20Nov23_011430|-- Bias --
20Nov23_011430|[-0.07087 -0.43718]
20Nov23_011430|Predicting the validation and test data with the Best final individual.
20Nov23_011437| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_011437|-----------  ------------------  --------------------  ----------
20Nov23_011437|Validation         42.00                  30            0.00000
20Nov23_011437|   Test            28.76                  30            0.83053
20Nov23_011437|-------------------------- Test #1 --------------------------
20Nov23_011437|Best final individual weights
20Nov23_011437|Individual:
20Nov23_011437|-- Constant hidden layers --
20Nov23_011437|False
20Nov23_011437|Layer 0:
20Nov23_011437|-- Config --
20Nov23_011437|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011437|-- Weights --
20Nov23_011437|[[ 2.81544e-01 -6.05842e-01 -3.21862e-01]
20Nov23_011437| [-7.64574e-02 -2.25410e-01 -7.86841e-01]
20Nov23_011437| [ 5.08219e-01 -2.57665e-01 -8.75233e-01]
20Nov23_011437| [-4.28170e-01  2.49161e-01  9.10295e-01]
20Nov23_011437| [-1.65254e-01 -1.04497e-01  1.86138e+00]
20Nov23_011437| [ 6.03026e-01  1.31698e+00  7.98797e-01]
20Nov23_011437| [ 4.37297e-01  6.21939e-01 -1.89649e+00]
20Nov23_011437| [-2.43418e-01 -1.29067e+00 -7.49600e-01]
20Nov23_011437| [ 6.75794e-01 -1.12743e+00  3.42927e-01]
20Nov23_011437| [-2.07087e-01  9.79404e-01 -9.41263e-01]
20Nov23_011437| [ 8.69844e-01  7.91195e-01 -2.04005e+00]
20Nov23_011437| [ 5.93969e-01  1.18998e+00  5.09909e-03]
20Nov23_011437| [-5.71844e-01 -1.05100e+00  6.64230e-01]
20Nov23_011437| [-1.83662e-02  2.60684e+00 -7.75333e-01]
20Nov23_011437| [-1.18405e+00 -6.30927e-01  1.29120e+00]
20Nov23_011437| [ 3.34434e-01  1.55517e+00  9.41732e-01]
20Nov23_011437| [ 1.35568e+00  9.04461e-01  6.82207e-01]
20Nov23_011437| [ 1.93224e+00  3.91496e-01 -3.90810e-01]
20Nov23_011437| [-1.51525e-01 -7.53769e-01  1.44364e+00]
20Nov23_011437| [ 1.79326e-01  4.31204e-01  4.25079e-01]
20Nov23_011437| [ 1.95318e-01 -3.68398e-01  1.13710e+00]
20Nov23_011437| [-1.56550e-01  2.86035e+00 -7.02992e-01]
20Nov23_011437| [-5.31242e-01 -1.36915e+00  1.06615e+00]
20Nov23_011437| [ 1.04531e+00 -3.20438e-01 -9.39162e-01]
20Nov23_011437| [-1.07150e+00 -1.10448e+00 -9.56850e-01]
20Nov23_011437| [ 2.30780e-01 -2.36734e+00 -5.45672e-01]
20Nov23_011437| [ 1.65837e+00 -1.02596e+00 -3.75298e-01]
20Nov23_011437| [ 2.68860e-01  1.88532e+00  1.45863e+00]
20Nov23_011437| [-6.62057e-01 -1.72122e-01  1.88865e+00]
20Nov23_011437| [ 6.67736e-01 -1.56745e+00  2.07945e+00]
20Nov23_011437| [ 6.52308e-01  1.71595e+00  6.00436e-02]
20Nov23_011437| [-4.84083e-01 -1.83992e+00  7.88743e-01]
20Nov23_011437| [ 2.28388e+00  5.14928e-01 -7.89078e-01]
20Nov23_011437| [-2.05070e-01 -4.94209e-01 -5.11047e-04]
20Nov23_011437| [ 2.76401e-01 -8.45665e-01  4.85630e-01]
20Nov23_011437| [ 1.38631e+00 -2.31534e-01  1.67351e+00]
20Nov23_011437| [ 2.40003e+00  4.30293e-01 -2.96407e-01]
20Nov23_011437| [-1.47168e+00 -1.12201e-01  5.23174e-02]
20Nov23_011437| [-5.99205e-01  5.25595e-02  1.14262e+00]
20Nov23_011437| [ 2.53490e-01  4.60347e-01 -8.13702e-01]
20Nov23_011437| [ 5.70195e-01 -1.38869e+00  8.50057e-01]
20Nov23_011437| [-8.57604e-01  1.35131e-01  6.03295e-01]
20Nov23_011437| [ 1.66056e+00  5.23447e-01  3.67017e-01]
20Nov23_011437| [ 2.05585e+00  2.60901e-01 -5.66920e-01]
20Nov23_011437| [-9.64678e-01 -6.26877e-01 -9.49711e-01]
20Nov23_011437| [-2.45283e-01 -7.14134e-01  1.18386e+00]
20Nov23_011437| [ 2.89841e-01 -3.41799e-01 -1.53665e+00]
20Nov23_011437| [-1.53316e+00 -8.11328e-01 -5.98503e-01]
20Nov23_011437| [-6.02444e-01  1.00080e+00 -3.18191e-01]
20Nov23_011437| [-2.39051e-01  1.05130e-01 -1.06166e-01]
20Nov23_011437| [ 5.54031e-01  7.51923e-01  3.33091e-01]
20Nov23_011437| [-1.21813e+00 -8.37235e-01 -2.16431e-01]
20Nov23_011437| [ 1.05855e+00  1.40560e+00  1.01499e+00]
20Nov23_011437| [-6.41326e-01  1.17562e+00 -1.60862e+00]
20Nov23_011437| [ 1.28062e+00  2.02472e+00 -1.41452e+00]
20Nov23_011437| [-1.25873e+00  6.41406e-01  1.02626e+00]
20Nov23_011437| [-1.36105e+00  4.41459e-01  1.56613e-01]]
20Nov23_011437|-- Bias --
20Nov23_011437|[1.39717 0.90167 0.56598]
20Nov23_011437|Layer 1:
20Nov23_011437|-- Config --
20Nov23_011437|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011437|-- Weights --
20Nov23_011437|[[ 0.02852 -1.07742  0.56125]
20Nov23_011437| [ 0.46639 -1.07916  1.47345]
20Nov23_011437| [-0.12440 -0.62009  0.68029]]
20Nov23_011437|-- Bias --
20Nov23_011437|[-0.38219 -0.88277  0.64332]
20Nov23_011437|Layer 2:
20Nov23_011437|-- Config --
20Nov23_011437|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011437|-- Weights --
20Nov23_011437|[[-0.26708  0.46937  1.25164 -0.79851]
20Nov23_011437| [-0.22042 -0.90964  0.20610 -0.50982]
20Nov23_011437| [-0.57011  0.40682  0.33195 -0.63661]]
20Nov23_011437|-- Bias --
20Nov23_011437|[ 0.08651  0.38057 -0.52568  0.21822]
20Nov23_011437|Layer 3:
20Nov23_011437|-- Config --
20Nov23_011437|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011437|-- Weights --
20Nov23_011437|[[-1.68151  0.96943]
20Nov23_011437| [-1.25774 -0.78998]
20Nov23_011437| [-1.35154  0.53538]
20Nov23_011437| [-0.05379 -0.72412]]
20Nov23_011437|-- Bias --
20Nov23_011437|[-0.07087 -0.43718]
20Nov23_011437|Predicting the validation and test data with the Best final individual.
20Nov23_011443| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_011443|-----------  ------------------  --------------------  ----------
20Nov23_011443|Validation         25.83                  30            0.60382
20Nov23_011443|   Test            36.40                  30            0.00000
20Nov23_011443|-------------------------- Test #2 --------------------------
20Nov23_011443|Best final individual weights
20Nov23_011443|Individual:
20Nov23_011443|-- Constant hidden layers --
20Nov23_011443|False
20Nov23_011443|Layer 0:
20Nov23_011443|-- Config --
20Nov23_011443|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011443|-- Weights --
20Nov23_011443|[[ 2.81544e-01 -6.05842e-01 -3.21862e-01]
20Nov23_011443| [-7.64574e-02 -2.25410e-01 -7.86841e-01]
20Nov23_011443| [ 5.08219e-01 -2.57665e-01 -8.75233e-01]
20Nov23_011443| [-4.28170e-01  2.49161e-01  9.10295e-01]
20Nov23_011443| [-1.65254e-01 -1.04497e-01  1.86138e+00]
20Nov23_011443| [ 6.03026e-01  1.31698e+00  7.98797e-01]
20Nov23_011443| [ 4.37297e-01  6.21939e-01 -1.89649e+00]
20Nov23_011443| [-2.43418e-01 -1.29067e+00 -7.49600e-01]
20Nov23_011443| [ 6.75794e-01 -1.12743e+00  3.42927e-01]
20Nov23_011443| [-2.07087e-01  9.79404e-01 -9.41263e-01]
20Nov23_011443| [ 8.69844e-01  7.91195e-01 -2.04005e+00]
20Nov23_011443| [ 5.93969e-01  1.18998e+00  5.09909e-03]
20Nov23_011443| [-5.71844e-01 -1.05100e+00  6.64230e-01]
20Nov23_011443| [-1.83662e-02  2.60684e+00 -7.75333e-01]
20Nov23_011443| [-1.18405e+00 -6.30927e-01  1.29120e+00]
20Nov23_011443| [ 3.34434e-01  1.55517e+00  9.41732e-01]
20Nov23_011443| [ 1.35568e+00  9.04461e-01  6.82207e-01]
20Nov23_011443| [ 1.93224e+00  3.91496e-01 -3.90810e-01]
20Nov23_011443| [-1.51525e-01 -7.53769e-01  1.44364e+00]
20Nov23_011443| [ 1.79326e-01  4.31204e-01  4.25079e-01]
20Nov23_011443| [ 1.95318e-01 -3.68398e-01  1.13710e+00]
20Nov23_011443| [-1.56550e-01  2.86035e+00 -7.02992e-01]
20Nov23_011443| [-5.31242e-01 -1.36915e+00  1.06615e+00]
20Nov23_011443| [ 1.04531e+00 -3.20438e-01 -9.39162e-01]
20Nov23_011443| [-1.07150e+00 -1.10448e+00 -9.56850e-01]
20Nov23_011443| [ 2.30780e-01 -2.36734e+00 -5.45672e-01]
20Nov23_011443| [ 1.65837e+00 -1.02596e+00 -3.75298e-01]
20Nov23_011443| [ 2.68860e-01  1.88532e+00  1.45863e+00]
20Nov23_011443| [-6.62057e-01 -1.72122e-01  1.88865e+00]
20Nov23_011443| [ 6.67736e-01 -1.56745e+00  2.07945e+00]
20Nov23_011443| [ 6.52308e-01  1.71595e+00  6.00436e-02]
20Nov23_011443| [-4.84083e-01 -1.83992e+00  7.88743e-01]
20Nov23_011443| [ 2.28388e+00  5.14928e-01 -7.89078e-01]
20Nov23_011443| [-2.05070e-01 -4.94209e-01 -5.11047e-04]
20Nov23_011443| [ 2.76401e-01 -8.45665e-01  4.85630e-01]
20Nov23_011443| [ 1.38631e+00 -2.31534e-01  1.67351e+00]
20Nov23_011443| [ 2.40003e+00  4.30293e-01 -2.96407e-01]
20Nov23_011443| [-1.47168e+00 -1.12201e-01  5.23174e-02]
20Nov23_011443| [-5.99205e-01  5.25595e-02  1.14262e+00]
20Nov23_011443| [ 2.53490e-01  4.60347e-01 -8.13702e-01]
20Nov23_011443| [ 5.70195e-01 -1.38869e+00  8.50057e-01]
20Nov23_011443| [-8.57604e-01  1.35131e-01  6.03295e-01]
20Nov23_011443| [ 1.66056e+00  5.23447e-01  3.67017e-01]
20Nov23_011443| [ 2.05585e+00  2.60901e-01 -5.66920e-01]
20Nov23_011443| [-9.64678e-01 -6.26877e-01 -9.49711e-01]
20Nov23_011443| [-2.45283e-01 -7.14134e-01  1.18386e+00]
20Nov23_011443| [ 2.89841e-01 -3.41799e-01 -1.53665e+00]
20Nov23_011443| [-1.53316e+00 -8.11328e-01 -5.98503e-01]
20Nov23_011443| [-6.02444e-01  1.00080e+00 -3.18191e-01]
20Nov23_011443| [-2.39051e-01  1.05130e-01 -1.06166e-01]
20Nov23_011443| [ 5.54031e-01  7.51923e-01  3.33091e-01]
20Nov23_011443| [-1.21813e+00 -8.37235e-01 -2.16431e-01]
20Nov23_011443| [ 1.05855e+00  1.40560e+00  1.01499e+00]
20Nov23_011443| [-6.41326e-01  1.17562e+00 -1.60862e+00]
20Nov23_011443| [ 1.28062e+00  2.02472e+00 -1.41452e+00]
20Nov23_011443| [-1.25873e+00  6.41406e-01  1.02626e+00]
20Nov23_011443| [-1.36105e+00  4.41459e-01  1.56613e-01]]
20Nov23_011443|-- Bias --
20Nov23_011443|[1.39717 0.90167 0.56598]
20Nov23_011443|Layer 1:
20Nov23_011443|-- Config --
20Nov23_011443|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011443|-- Weights --
20Nov23_011443|[[ 0.02852 -1.07742  0.56125]
20Nov23_011443| [ 0.46639 -1.07916  1.47345]
20Nov23_011443| [-0.12440 -0.62009  0.68029]]
20Nov23_011443|-- Bias --
20Nov23_011443|[-0.38219 -0.88277  0.64332]
20Nov23_011443|Layer 2:
20Nov23_011443|-- Config --
20Nov23_011443|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011443|-- Weights --
20Nov23_011443|[[-0.26708  0.46937  1.25164 -0.79851]
20Nov23_011443| [-0.22042 -0.90964  0.20610 -0.50982]
20Nov23_011443| [-0.57011  0.40682  0.33195 -0.63661]]
20Nov23_011443|-- Bias --
20Nov23_011443|[ 0.08651  0.38057 -0.52568  0.21822]
20Nov23_011443|Layer 3:
20Nov23_011443|-- Config --
20Nov23_011443|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011443|-- Weights --
20Nov23_011443|[[-1.68151  0.96943]
20Nov23_011443| [-1.25774 -0.78998]
20Nov23_011443| [-1.35154  0.53538]
20Nov23_011443| [-0.05379 -0.72412]]
20Nov23_011443|-- Bias --
20Nov23_011443|[-0.07087 -0.43718]
20Nov23_011443|Predicting the validation and test data with the Best final individual.
20Nov23_011449| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_011449|-----------  ------------------  --------------------  ----------
20Nov23_011449|Validation         42.00                  30            0.00000
20Nov23_011449|   Test            36.40                  30            0.00000
20Nov23_011449|-------------------------- Test #3 --------------------------
20Nov23_011449|Best final individual weights
20Nov23_011449|Individual:
20Nov23_011449|-- Constant hidden layers --
20Nov23_011449|False
20Nov23_011449|Layer 0:
20Nov23_011449|-- Config --
20Nov23_011449|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011449|-- Weights --
20Nov23_011449|[[ 2.81544e-01 -6.05842e-01 -3.21862e-01]
20Nov23_011449| [-7.64574e-02 -2.25410e-01 -7.86841e-01]
20Nov23_011449| [ 5.08219e-01 -2.57665e-01 -8.75233e-01]
20Nov23_011449| [-4.28170e-01  2.49161e-01  9.10295e-01]
20Nov23_011449| [-1.65254e-01 -1.04497e-01  1.86138e+00]
20Nov23_011449| [ 6.03026e-01  1.31698e+00  7.98797e-01]
20Nov23_011449| [ 4.37297e-01  6.21939e-01 -1.89649e+00]
20Nov23_011449| [-2.43418e-01 -1.29067e+00 -7.49600e-01]
20Nov23_011449| [ 6.75794e-01 -1.12743e+00  3.42927e-01]
20Nov23_011449| [-2.07087e-01  9.79404e-01 -9.41263e-01]
20Nov23_011449| [ 8.69844e-01  7.91195e-01 -2.04005e+00]
20Nov23_011449| [ 5.93969e-01  1.18998e+00  5.09909e-03]
20Nov23_011449| [-5.71844e-01 -1.05100e+00  6.64230e-01]
20Nov23_011449| [-1.83662e-02  2.60684e+00 -7.75333e-01]
20Nov23_011449| [-1.18405e+00 -6.30927e-01  1.29120e+00]
20Nov23_011449| [ 3.34434e-01  1.55517e+00  9.41732e-01]
20Nov23_011449| [ 1.35568e+00  9.04461e-01  6.82207e-01]
20Nov23_011449| [ 1.93224e+00  3.91496e-01 -3.90810e-01]
20Nov23_011449| [-1.51525e-01 -7.53769e-01  1.44364e+00]
20Nov23_011449| [ 1.79326e-01  4.31204e-01  4.25079e-01]
20Nov23_011449| [ 1.95318e-01 -3.68398e-01  1.13710e+00]
20Nov23_011449| [-1.56550e-01  2.86035e+00 -7.02992e-01]
20Nov23_011449| [-5.31242e-01 -1.36915e+00  1.06615e+00]
20Nov23_011449| [ 1.04531e+00 -3.20438e-01 -9.39162e-01]
20Nov23_011449| [-1.07150e+00 -1.10448e+00 -9.56850e-01]
20Nov23_011449| [ 2.30780e-01 -2.36734e+00 -5.45672e-01]
20Nov23_011449| [ 1.65837e+00 -1.02596e+00 -3.75298e-01]
20Nov23_011449| [ 2.68860e-01  1.88532e+00  1.45863e+00]
20Nov23_011449| [-6.62057e-01 -1.72122e-01  1.88865e+00]
20Nov23_011449| [ 6.67736e-01 -1.56745e+00  2.07945e+00]
20Nov23_011449| [ 6.52308e-01  1.71595e+00  6.00436e-02]
20Nov23_011449| [-4.84083e-01 -1.83992e+00  7.88743e-01]
20Nov23_011449| [ 2.28388e+00  5.14928e-01 -7.89078e-01]
20Nov23_011449| [-2.05070e-01 -4.94209e-01 -5.11047e-04]
20Nov23_011449| [ 2.76401e-01 -8.45665e-01  4.85630e-01]
20Nov23_011449| [ 1.38631e+00 -2.31534e-01  1.67351e+00]
20Nov23_011449| [ 2.40003e+00  4.30293e-01 -2.96407e-01]
20Nov23_011449| [-1.47168e+00 -1.12201e-01  5.23174e-02]
20Nov23_011449| [-5.99205e-01  5.25595e-02  1.14262e+00]
20Nov23_011449| [ 2.53490e-01  4.60347e-01 -8.13702e-01]
20Nov23_011449| [ 5.70195e-01 -1.38869e+00  8.50057e-01]
20Nov23_011449| [-8.57604e-01  1.35131e-01  6.03295e-01]
20Nov23_011449| [ 1.66056e+00  5.23447e-01  3.67017e-01]
20Nov23_011449| [ 2.05585e+00  2.60901e-01 -5.66920e-01]
20Nov23_011449| [-9.64678e-01 -6.26877e-01 -9.49711e-01]
20Nov23_011449| [-2.45283e-01 -7.14134e-01  1.18386e+00]
20Nov23_011449| [ 2.89841e-01 -3.41799e-01 -1.53665e+00]
20Nov23_011449| [-1.53316e+00 -8.11328e-01 -5.98503e-01]
20Nov23_011449| [-6.02444e-01  1.00080e+00 -3.18191e-01]
20Nov23_011449| [-2.39051e-01  1.05130e-01 -1.06166e-01]
20Nov23_011449| [ 5.54031e-01  7.51923e-01  3.33091e-01]
20Nov23_011449| [-1.21813e+00 -8.37235e-01 -2.16431e-01]
20Nov23_011449| [ 1.05855e+00  1.40560e+00  1.01499e+00]
20Nov23_011449| [-6.41326e-01  1.17562e+00 -1.60862e+00]
20Nov23_011449| [ 1.28062e+00  2.02472e+00 -1.41452e+00]
20Nov23_011449| [-1.25873e+00  6.41406e-01  1.02626e+00]
20Nov23_011449| [-1.36105e+00  4.41459e-01  1.56613e-01]]
20Nov23_011449|-- Bias --
20Nov23_011449|[1.39717 0.90167 0.56598]
20Nov23_011449|Layer 1:
20Nov23_011449|-- Config --
20Nov23_011449|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011449|-- Weights --
20Nov23_011449|[[ 0.02852 -1.07742  0.56125]
20Nov23_011449| [ 0.46639 -1.07916  1.47345]
20Nov23_011449| [-0.12440 -0.62009  0.68029]]
20Nov23_011449|-- Bias --
20Nov23_011449|[-0.38219 -0.88277  0.64332]
20Nov23_011449|Layer 2:
20Nov23_011449|-- Config --
20Nov23_011449|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011449|-- Weights --
20Nov23_011449|[[-0.26708  0.46937  1.25164 -0.79851]
20Nov23_011449| [-0.22042 -0.90964  0.20610 -0.50982]
20Nov23_011449| [-0.57011  0.40682  0.33195 -0.63661]]
20Nov23_011449|-- Bias --
20Nov23_011449|[ 0.08651  0.38057 -0.52568  0.21822]
20Nov23_011449|Layer 3:
20Nov23_011449|-- Config --
20Nov23_011449|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011449|-- Weights --
20Nov23_011449|[[-1.68151  0.96943]
20Nov23_011449| [-1.25774 -0.78998]
20Nov23_011449| [-1.35154  0.53538]
20Nov23_011449| [-0.05379 -0.72412]]
20Nov23_011449|-- Bias --
20Nov23_011449|[-0.07087 -0.43718]
20Nov23_011449|Predicting the validation and test data with the Best final individual.
20Nov23_011455| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_011455|-----------  ------------------  --------------------  ----------
20Nov23_011455|Validation         28.26                  30            0.51299
20Nov23_011455|   Test            36.40                  30            0.00000
20Nov23_011455|-------------------------- Test #4 --------------------------
20Nov23_011455|Best final individual weights
20Nov23_011455|Individual:
20Nov23_011455|-- Constant hidden layers --
20Nov23_011455|False
20Nov23_011455|Layer 0:
20Nov23_011455|-- Config --
20Nov23_011455|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011455|-- Weights --
20Nov23_011455|[[ 2.81544e-01 -6.05842e-01 -3.21862e-01]
20Nov23_011455| [-7.64574e-02 -2.25410e-01 -7.86841e-01]
20Nov23_011455| [ 5.08219e-01 -2.57665e-01 -8.75233e-01]
20Nov23_011455| [-4.28170e-01  2.49161e-01  9.10295e-01]
20Nov23_011455| [-1.65254e-01 -1.04497e-01  1.86138e+00]
20Nov23_011455| [ 6.03026e-01  1.31698e+00  7.98797e-01]
20Nov23_011455| [ 4.37297e-01  6.21939e-01 -1.89649e+00]
20Nov23_011455| [-2.43418e-01 -1.29067e+00 -7.49600e-01]
20Nov23_011455| [ 6.75794e-01 -1.12743e+00  3.42927e-01]
20Nov23_011455| [-2.07087e-01  9.79404e-01 -9.41263e-01]
20Nov23_011455| [ 8.69844e-01  7.91195e-01 -2.04005e+00]
20Nov23_011455| [ 5.93969e-01  1.18998e+00  5.09909e-03]
20Nov23_011455| [-5.71844e-01 -1.05100e+00  6.64230e-01]
20Nov23_011455| [-1.83662e-02  2.60684e+00 -7.75333e-01]
20Nov23_011455| [-1.18405e+00 -6.30927e-01  1.29120e+00]
20Nov23_011455| [ 3.34434e-01  1.55517e+00  9.41732e-01]
20Nov23_011455| [ 1.35568e+00  9.04461e-01  6.82207e-01]
20Nov23_011455| [ 1.93224e+00  3.91496e-01 -3.90810e-01]
20Nov23_011455| [-1.51525e-01 -7.53769e-01  1.44364e+00]
20Nov23_011455| [ 1.79326e-01  4.31204e-01  4.25079e-01]
20Nov23_011455| [ 1.95318e-01 -3.68398e-01  1.13710e+00]
20Nov23_011455| [-1.56550e-01  2.86035e+00 -7.02992e-01]
20Nov23_011455| [-5.31242e-01 -1.36915e+00  1.06615e+00]
20Nov23_011455| [ 1.04531e+00 -3.20438e-01 -9.39162e-01]
20Nov23_011455| [-1.07150e+00 -1.10448e+00 -9.56850e-01]
20Nov23_011455| [ 2.30780e-01 -2.36734e+00 -5.45672e-01]
20Nov23_011455| [ 1.65837e+00 -1.02596e+00 -3.75298e-01]
20Nov23_011455| [ 2.68860e-01  1.88532e+00  1.45863e+00]
20Nov23_011455| [-6.62057e-01 -1.72122e-01  1.88865e+00]
20Nov23_011455| [ 6.67736e-01 -1.56745e+00  2.07945e+00]
20Nov23_011455| [ 6.52308e-01  1.71595e+00  6.00436e-02]
20Nov23_011455| [-4.84083e-01 -1.83992e+00  7.88743e-01]
20Nov23_011455| [ 2.28388e+00  5.14928e-01 -7.89078e-01]
20Nov23_011455| [-2.05070e-01 -4.94209e-01 -5.11047e-04]
20Nov23_011455| [ 2.76401e-01 -8.45665e-01  4.85630e-01]
20Nov23_011455| [ 1.38631e+00 -2.31534e-01  1.67351e+00]
20Nov23_011455| [ 2.40003e+00  4.30293e-01 -2.96407e-01]
20Nov23_011455| [-1.47168e+00 -1.12201e-01  5.23174e-02]
20Nov23_011455| [-5.99205e-01  5.25595e-02  1.14262e+00]
20Nov23_011455| [ 2.53490e-01  4.60347e-01 -8.13702e-01]
20Nov23_011455| [ 5.70195e-01 -1.38869e+00  8.50057e-01]
20Nov23_011455| [-8.57604e-01  1.35131e-01  6.03295e-01]
20Nov23_011455| [ 1.66056e+00  5.23447e-01  3.67017e-01]
20Nov23_011455| [ 2.05585e+00  2.60901e-01 -5.66920e-01]
20Nov23_011455| [-9.64678e-01 -6.26877e-01 -9.49711e-01]
20Nov23_011455| [-2.45283e-01 -7.14134e-01  1.18386e+00]
20Nov23_011455| [ 2.89841e-01 -3.41799e-01 -1.53665e+00]
20Nov23_011455| [-1.53316e+00 -8.11328e-01 -5.98503e-01]
20Nov23_011455| [-6.02444e-01  1.00080e+00 -3.18191e-01]
20Nov23_011455| [-2.39051e-01  1.05130e-01 -1.06166e-01]
20Nov23_011455| [ 5.54031e-01  7.51923e-01  3.33091e-01]
20Nov23_011455| [-1.21813e+00 -8.37235e-01 -2.16431e-01]
20Nov23_011455| [ 1.05855e+00  1.40560e+00  1.01499e+00]
20Nov23_011455| [-6.41326e-01  1.17562e+00 -1.60862e+00]
20Nov23_011455| [ 1.28062e+00  2.02472e+00 -1.41452e+00]
20Nov23_011455| [-1.25873e+00  6.41406e-01  1.02626e+00]
20Nov23_011455| [-1.36105e+00  4.41459e-01  1.56613e-01]]
20Nov23_011455|-- Bias --
20Nov23_011455|[1.39717 0.90167 0.56598]
20Nov23_011455|Layer 1:
20Nov23_011455|-- Config --
20Nov23_011455|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011455|-- Weights --
20Nov23_011455|[[ 0.02852 -1.07742  0.56125]
20Nov23_011455| [ 0.46639 -1.07916  1.47345]
20Nov23_011455| [-0.12440 -0.62009  0.68029]]
20Nov23_011455|-- Bias --
20Nov23_011455|[-0.38219 -0.88277  0.64332]
20Nov23_011455|Layer 2:
20Nov23_011455|-- Config --
20Nov23_011455|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011455|-- Weights --
20Nov23_011455|[[-0.26708  0.46937  1.25164 -0.79851]
20Nov23_011455| [-0.22042 -0.90964  0.20610 -0.50982]
20Nov23_011455| [-0.57011  0.40682  0.33195 -0.63661]]
20Nov23_011455|-- Bias --
20Nov23_011455|[ 0.08651  0.38057 -0.52568  0.21822]
20Nov23_011455|Layer 3:
20Nov23_011455|-- Config --
20Nov23_011455|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011455|-- Weights --
20Nov23_011455|[[-1.68151  0.96943]
20Nov23_011455| [-1.25774 -0.78998]
20Nov23_011455| [-1.35154  0.53538]
20Nov23_011455| [-0.05379 -0.72412]]
20Nov23_011455|-- Bias --
20Nov23_011455|[-0.07087 -0.43718]
20Nov23_011455|Predicting the validation and test data with the Best final individual.
20Nov23_011501| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_011501|-----------  ------------------  --------------------  ----------
20Nov23_011501|Validation         42.00                  30            0.00000
20Nov23_011501|   Test            36.40                  30            0.00000
20Nov23_011501|-------------------------- Test #5 --------------------------
20Nov23_011501|Best final individual weights
20Nov23_011501|Individual:
20Nov23_011501|-- Constant hidden layers --
20Nov23_011501|False
20Nov23_011501|Layer 0:
20Nov23_011501|-- Config --
20Nov23_011501|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011501|-- Weights --
20Nov23_011501|[[ 2.81544e-01 -6.05842e-01 -3.21862e-01]
20Nov23_011501| [-7.64574e-02 -2.25410e-01 -7.86841e-01]
20Nov23_011501| [ 5.08219e-01 -2.57665e-01 -8.75233e-01]
20Nov23_011501| [-4.28170e-01  2.49161e-01  9.10295e-01]
20Nov23_011501| [-1.65254e-01 -1.04497e-01  1.86138e+00]
20Nov23_011501| [ 6.03026e-01  1.31698e+00  7.98797e-01]
20Nov23_011501| [ 4.37297e-01  6.21939e-01 -1.89649e+00]
20Nov23_011501| [-2.43418e-01 -1.29067e+00 -7.49600e-01]
20Nov23_011501| [ 6.75794e-01 -1.12743e+00  3.42927e-01]
20Nov23_011501| [-2.07087e-01  9.79404e-01 -9.41263e-01]
20Nov23_011501| [ 8.69844e-01  7.91195e-01 -2.04005e+00]
20Nov23_011501| [ 5.93969e-01  1.18998e+00  5.09909e-03]
20Nov23_011501| [-5.71844e-01 -1.05100e+00  6.64230e-01]
20Nov23_011501| [-1.83662e-02  2.60684e+00 -7.75333e-01]
20Nov23_011501| [-1.18405e+00 -6.30927e-01  1.29120e+00]
20Nov23_011501| [ 3.34434e-01  1.55517e+00  9.41732e-01]
20Nov23_011501| [ 1.35568e+00  9.04461e-01  6.82207e-01]
20Nov23_011501| [ 1.93224e+00  3.91496e-01 -3.90810e-01]
20Nov23_011501| [-1.51525e-01 -7.53769e-01  1.44364e+00]
20Nov23_011501| [ 1.79326e-01  4.31204e-01  4.25079e-01]
20Nov23_011501| [ 1.95318e-01 -3.68398e-01  1.13710e+00]
20Nov23_011501| [-1.56550e-01  2.86035e+00 -7.02992e-01]
20Nov23_011501| [-5.31242e-01 -1.36915e+00  1.06615e+00]
20Nov23_011501| [ 1.04531e+00 -3.20438e-01 -9.39162e-01]
20Nov23_011501| [-1.07150e+00 -1.10448e+00 -9.56850e-01]
20Nov23_011501| [ 2.30780e-01 -2.36734e+00 -5.45672e-01]
20Nov23_011501| [ 1.65837e+00 -1.02596e+00 -3.75298e-01]
20Nov23_011501| [ 2.68860e-01  1.88532e+00  1.45863e+00]
20Nov23_011501| [-6.62057e-01 -1.72122e-01  1.88865e+00]
20Nov23_011501| [ 6.67736e-01 -1.56745e+00  2.07945e+00]
20Nov23_011501| [ 6.52308e-01  1.71595e+00  6.00436e-02]
20Nov23_011501| [-4.84083e-01 -1.83992e+00  7.88743e-01]
20Nov23_011501| [ 2.28388e+00  5.14928e-01 -7.89078e-01]
20Nov23_011501| [-2.05070e-01 -4.94209e-01 -5.11047e-04]
20Nov23_011501| [ 2.76401e-01 -8.45665e-01  4.85630e-01]
20Nov23_011501| [ 1.38631e+00 -2.31534e-01  1.67351e+00]
20Nov23_011501| [ 2.40003e+00  4.30293e-01 -2.96407e-01]
20Nov23_011501| [-1.47168e+00 -1.12201e-01  5.23174e-02]
20Nov23_011501| [-5.99205e-01  5.25595e-02  1.14262e+00]
20Nov23_011501| [ 2.53490e-01  4.60347e-01 -8.13702e-01]
20Nov23_011501| [ 5.70195e-01 -1.38869e+00  8.50057e-01]
20Nov23_011501| [-8.57604e-01  1.35131e-01  6.03295e-01]
20Nov23_011501| [ 1.66056e+00  5.23447e-01  3.67017e-01]
20Nov23_011501| [ 2.05585e+00  2.60901e-01 -5.66920e-01]
20Nov23_011501| [-9.64678e-01 -6.26877e-01 -9.49711e-01]
20Nov23_011501| [-2.45283e-01 -7.14134e-01  1.18386e+00]
20Nov23_011501| [ 2.89841e-01 -3.41799e-01 -1.53665e+00]
20Nov23_011501| [-1.53316e+00 -8.11328e-01 -5.98503e-01]
20Nov23_011501| [-6.02444e-01  1.00080e+00 -3.18191e-01]
20Nov23_011501| [-2.39051e-01  1.05130e-01 -1.06166e-01]
20Nov23_011501| [ 5.54031e-01  7.51923e-01  3.33091e-01]
20Nov23_011501| [-1.21813e+00 -8.37235e-01 -2.16431e-01]
20Nov23_011501| [ 1.05855e+00  1.40560e+00  1.01499e+00]
20Nov23_011501| [-6.41326e-01  1.17562e+00 -1.60862e+00]
20Nov23_011501| [ 1.28062e+00  2.02472e+00 -1.41452e+00]
20Nov23_011501| [-1.25873e+00  6.41406e-01  1.02626e+00]
20Nov23_011501| [-1.36105e+00  4.41459e-01  1.56613e-01]]
20Nov23_011501|-- Bias --
20Nov23_011501|[1.39717 0.90167 0.56598]
20Nov23_011501|Layer 1:
20Nov23_011501|-- Config --
20Nov23_011501|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011501|-- Weights --
20Nov23_011501|[[ 0.02852 -1.07742  0.56125]
20Nov23_011501| [ 0.46639 -1.07916  1.47345]
20Nov23_011501| [-0.12440 -0.62009  0.68029]]
20Nov23_011501|-- Bias --
20Nov23_011501|[-0.38219 -0.88277  0.64332]
20Nov23_011501|Layer 2:
20Nov23_011501|-- Config --
20Nov23_011501|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011501|-- Weights --
20Nov23_011501|[[-0.26708  0.46937  1.25164 -0.79851]
20Nov23_011501| [-0.22042 -0.90964  0.20610 -0.50982]
20Nov23_011501| [-0.57011  0.40682  0.33195 -0.63661]]
20Nov23_011501|-- Bias --
20Nov23_011501|[ 0.08651  0.38057 -0.52568  0.21822]
20Nov23_011501|Layer 3:
20Nov23_011501|-- Config --
20Nov23_011501|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011501|-- Weights --
20Nov23_011501|[[-1.68151  0.96943]
20Nov23_011501| [-1.25774 -0.78998]
20Nov23_011501| [-1.35154  0.53538]
20Nov23_011501| [-0.05379 -0.72412]]
20Nov23_011501|-- Bias --
20Nov23_011501|[-0.07087 -0.43718]
20Nov23_011501|Predicting the validation and test data with the Best final individual.
20Nov23_011507| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_011507|-----------  ------------------  --------------------  ----------
20Nov23_011507|Validation         42.00                  30            0.00000
20Nov23_011507|   Test            36.40                  30            0.00000
20Nov23_011507|-------------------------- Test #6 --------------------------
20Nov23_011507|Best final individual weights
20Nov23_011507|Individual:
20Nov23_011507|-- Constant hidden layers --
20Nov23_011507|False
20Nov23_011507|Layer 0:
20Nov23_011507|-- Config --
20Nov23_011507|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011507|-- Weights --
20Nov23_011507|[[ 2.81544e-01 -6.05842e-01 -3.21862e-01]
20Nov23_011507| [-7.64574e-02 -2.25410e-01 -7.86841e-01]
20Nov23_011507| [ 5.08219e-01 -2.57665e-01 -8.75233e-01]
20Nov23_011507| [-4.28170e-01  2.49161e-01  9.10295e-01]
20Nov23_011507| [-1.65254e-01 -1.04497e-01  1.86138e+00]
20Nov23_011507| [ 6.03026e-01  1.31698e+00  7.98797e-01]
20Nov23_011507| [ 4.37297e-01  6.21939e-01 -1.89649e+00]
20Nov23_011507| [-2.43418e-01 -1.29067e+00 -7.49600e-01]
20Nov23_011507| [ 6.75794e-01 -1.12743e+00  3.42927e-01]
20Nov23_011507| [-2.07087e-01  9.79404e-01 -9.41263e-01]
20Nov23_011507| [ 8.69844e-01  7.91195e-01 -2.04005e+00]
20Nov23_011507| [ 5.93969e-01  1.18998e+00  5.09909e-03]
20Nov23_011507| [-5.71844e-01 -1.05100e+00  6.64230e-01]
20Nov23_011507| [-1.83662e-02  2.60684e+00 -7.75333e-01]
20Nov23_011507| [-1.18405e+00 -6.30927e-01  1.29120e+00]
20Nov23_011507| [ 3.34434e-01  1.55517e+00  9.41732e-01]
20Nov23_011507| [ 1.35568e+00  9.04461e-01  6.82207e-01]
20Nov23_011507| [ 1.93224e+00  3.91496e-01 -3.90810e-01]
20Nov23_011507| [-1.51525e-01 -7.53769e-01  1.44364e+00]
20Nov23_011507| [ 1.79326e-01  4.31204e-01  4.25079e-01]
20Nov23_011507| [ 1.95318e-01 -3.68398e-01  1.13710e+00]
20Nov23_011507| [-1.56550e-01  2.86035e+00 -7.02992e-01]
20Nov23_011507| [-5.31242e-01 -1.36915e+00  1.06615e+00]
20Nov23_011507| [ 1.04531e+00 -3.20438e-01 -9.39162e-01]
20Nov23_011507| [-1.07150e+00 -1.10448e+00 -9.56850e-01]
20Nov23_011507| [ 2.30780e-01 -2.36734e+00 -5.45672e-01]
20Nov23_011507| [ 1.65837e+00 -1.02596e+00 -3.75298e-01]
20Nov23_011507| [ 2.68860e-01  1.88532e+00  1.45863e+00]
20Nov23_011507| [-6.62057e-01 -1.72122e-01  1.88865e+00]
20Nov23_011507| [ 6.67736e-01 -1.56745e+00  2.07945e+00]
20Nov23_011507| [ 6.52308e-01  1.71595e+00  6.00436e-02]
20Nov23_011507| [-4.84083e-01 -1.83992e+00  7.88743e-01]
20Nov23_011507| [ 2.28388e+00  5.14928e-01 -7.89078e-01]
20Nov23_011507| [-2.05070e-01 -4.94209e-01 -5.11047e-04]
20Nov23_011507| [ 2.76401e-01 -8.45665e-01  4.85630e-01]
20Nov23_011507| [ 1.38631e+00 -2.31534e-01  1.67351e+00]
20Nov23_011507| [ 2.40003e+00  4.30293e-01 -2.96407e-01]
20Nov23_011507| [-1.47168e+00 -1.12201e-01  5.23174e-02]
20Nov23_011507| [-5.99205e-01  5.25595e-02  1.14262e+00]
20Nov23_011507| [ 2.53490e-01  4.60347e-01 -8.13702e-01]
20Nov23_011507| [ 5.70195e-01 -1.38869e+00  8.50057e-01]
20Nov23_011507| [-8.57604e-01  1.35131e-01  6.03295e-01]
20Nov23_011507| [ 1.66056e+00  5.23447e-01  3.67017e-01]
20Nov23_011507| [ 2.05585e+00  2.60901e-01 -5.66920e-01]
20Nov23_011507| [-9.64678e-01 -6.26877e-01 -9.49711e-01]
20Nov23_011507| [-2.45283e-01 -7.14134e-01  1.18386e+00]
20Nov23_011507| [ 2.89841e-01 -3.41799e-01 -1.53665e+00]
20Nov23_011507| [-1.53316e+00 -8.11328e-01 -5.98503e-01]
20Nov23_011507| [-6.02444e-01  1.00080e+00 -3.18191e-01]
20Nov23_011507| [-2.39051e-01  1.05130e-01 -1.06166e-01]
20Nov23_011507| [ 5.54031e-01  7.51923e-01  3.33091e-01]
20Nov23_011507| [-1.21813e+00 -8.37235e-01 -2.16431e-01]
20Nov23_011507| [ 1.05855e+00  1.40560e+00  1.01499e+00]
20Nov23_011507| [-6.41326e-01  1.17562e+00 -1.60862e+00]
20Nov23_011507| [ 1.28062e+00  2.02472e+00 -1.41452e+00]
20Nov23_011507| [-1.25873e+00  6.41406e-01  1.02626e+00]
20Nov23_011507| [-1.36105e+00  4.41459e-01  1.56613e-01]]
20Nov23_011507|-- Bias --
20Nov23_011507|[1.39717 0.90167 0.56598]
20Nov23_011507|Layer 1:
20Nov23_011507|-- Config --
20Nov23_011507|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011507|-- Weights --
20Nov23_011507|[[ 0.02852 -1.07742  0.56125]
20Nov23_011507| [ 0.46639 -1.07916  1.47345]
20Nov23_011507| [-0.12440 -0.62009  0.68029]]
20Nov23_011507|-- Bias --
20Nov23_011507|[-0.38219 -0.88277  0.64332]
20Nov23_011507|Layer 2:
20Nov23_011507|-- Config --
20Nov23_011507|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011507|-- Weights --
20Nov23_011507|[[-0.26708  0.46937  1.25164 -0.79851]
20Nov23_011507| [-0.22042 -0.90964  0.20610 -0.50982]
20Nov23_011507| [-0.57011  0.40682  0.33195 -0.63661]]
20Nov23_011507|-- Bias --
20Nov23_011507|[ 0.08651  0.38057 -0.52568  0.21822]
20Nov23_011507|Layer 3:
20Nov23_011507|-- Config --
20Nov23_011507|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011507|-- Weights --
20Nov23_011507|[[-1.68151  0.96943]
20Nov23_011507| [-1.25774 -0.78998]
20Nov23_011507| [-1.35154  0.53538]
20Nov23_011507| [-0.05379 -0.72412]]
20Nov23_011507|-- Bias --
20Nov23_011507|[-0.07087 -0.43718]
20Nov23_011507|Predicting the validation and test data with the Best final individual.
20Nov23_011514| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_011514|-----------  ------------------  --------------------  ----------
20Nov23_011514|Validation         42.00                  30            0.00000
20Nov23_011514|   Test            36.58                  30            0.00000
20Nov23_011514|-------------------------- Test #7 --------------------------
20Nov23_011514|Best final individual weights
20Nov23_011514|Individual:
20Nov23_011514|-- Constant hidden layers --
20Nov23_011514|False
20Nov23_011514|Layer 0:
20Nov23_011514|-- Config --
20Nov23_011514|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011514|-- Weights --
20Nov23_011514|[[ 2.81544e-01 -6.05842e-01 -3.21862e-01]
20Nov23_011514| [-7.64574e-02 -2.25410e-01 -7.86841e-01]
20Nov23_011514| [ 5.08219e-01 -2.57665e-01 -8.75233e-01]
20Nov23_011514| [-4.28170e-01  2.49161e-01  9.10295e-01]
20Nov23_011514| [-1.65254e-01 -1.04497e-01  1.86138e+00]
20Nov23_011514| [ 6.03026e-01  1.31698e+00  7.98797e-01]
20Nov23_011514| [ 4.37297e-01  6.21939e-01 -1.89649e+00]
20Nov23_011514| [-2.43418e-01 -1.29067e+00 -7.49600e-01]
20Nov23_011514| [ 6.75794e-01 -1.12743e+00  3.42927e-01]
20Nov23_011514| [-2.07087e-01  9.79404e-01 -9.41263e-01]
20Nov23_011514| [ 8.69844e-01  7.91195e-01 -2.04005e+00]
20Nov23_011514| [ 5.93969e-01  1.18998e+00  5.09909e-03]
20Nov23_011514| [-5.71844e-01 -1.05100e+00  6.64230e-01]
20Nov23_011514| [-1.83662e-02  2.60684e+00 -7.75333e-01]
20Nov23_011514| [-1.18405e+00 -6.30927e-01  1.29120e+00]
20Nov23_011514| [ 3.34434e-01  1.55517e+00  9.41732e-01]
20Nov23_011514| [ 1.35568e+00  9.04461e-01  6.82207e-01]
20Nov23_011514| [ 1.93224e+00  3.91496e-01 -3.90810e-01]
20Nov23_011514| [-1.51525e-01 -7.53769e-01  1.44364e+00]
20Nov23_011514| [ 1.79326e-01  4.31204e-01  4.25079e-01]
20Nov23_011514| [ 1.95318e-01 -3.68398e-01  1.13710e+00]
20Nov23_011514| [-1.56550e-01  2.86035e+00 -7.02992e-01]
20Nov23_011514| [-5.31242e-01 -1.36915e+00  1.06615e+00]
20Nov23_011514| [ 1.04531e+00 -3.20438e-01 -9.39162e-01]
20Nov23_011514| [-1.07150e+00 -1.10448e+00 -9.56850e-01]
20Nov23_011514| [ 2.30780e-01 -2.36734e+00 -5.45672e-01]
20Nov23_011514| [ 1.65837e+00 -1.02596e+00 -3.75298e-01]
20Nov23_011514| [ 2.68860e-01  1.88532e+00  1.45863e+00]
20Nov23_011514| [-6.62057e-01 -1.72122e-01  1.88865e+00]
20Nov23_011514| [ 6.67736e-01 -1.56745e+00  2.07945e+00]
20Nov23_011514| [ 6.52308e-01  1.71595e+00  6.00436e-02]
20Nov23_011514| [-4.84083e-01 -1.83992e+00  7.88743e-01]
20Nov23_011514| [ 2.28388e+00  5.14928e-01 -7.89078e-01]
20Nov23_011514| [-2.05070e-01 -4.94209e-01 -5.11047e-04]
20Nov23_011514| [ 2.76401e-01 -8.45665e-01  4.85630e-01]
20Nov23_011514| [ 1.38631e+00 -2.31534e-01  1.67351e+00]
20Nov23_011514| [ 2.40003e+00  4.30293e-01 -2.96407e-01]
20Nov23_011514| [-1.47168e+00 -1.12201e-01  5.23174e-02]
20Nov23_011514| [-5.99205e-01  5.25595e-02  1.14262e+00]
20Nov23_011514| [ 2.53490e-01  4.60347e-01 -8.13702e-01]
20Nov23_011514| [ 5.70195e-01 -1.38869e+00  8.50057e-01]
20Nov23_011514| [-8.57604e-01  1.35131e-01  6.03295e-01]
20Nov23_011514| [ 1.66056e+00  5.23447e-01  3.67017e-01]
20Nov23_011514| [ 2.05585e+00  2.60901e-01 -5.66920e-01]
20Nov23_011514| [-9.64678e-01 -6.26877e-01 -9.49711e-01]
20Nov23_011514| [-2.45283e-01 -7.14134e-01  1.18386e+00]
20Nov23_011514| [ 2.89841e-01 -3.41799e-01 -1.53665e+00]
20Nov23_011514| [-1.53316e+00 -8.11328e-01 -5.98503e-01]
20Nov23_011514| [-6.02444e-01  1.00080e+00 -3.18191e-01]
20Nov23_011514| [-2.39051e-01  1.05130e-01 -1.06166e-01]
20Nov23_011514| [ 5.54031e-01  7.51923e-01  3.33091e-01]
20Nov23_011514| [-1.21813e+00 -8.37235e-01 -2.16431e-01]
20Nov23_011514| [ 1.05855e+00  1.40560e+00  1.01499e+00]
20Nov23_011514| [-6.41326e-01  1.17562e+00 -1.60862e+00]
20Nov23_011514| [ 1.28062e+00  2.02472e+00 -1.41452e+00]
20Nov23_011514| [-1.25873e+00  6.41406e-01  1.02626e+00]
20Nov23_011514| [-1.36105e+00  4.41459e-01  1.56613e-01]]
20Nov23_011514|-- Bias --
20Nov23_011514|[1.39717 0.90167 0.56598]
20Nov23_011514|Layer 1:
20Nov23_011514|-- Config --
20Nov23_011514|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011514|-- Weights --
20Nov23_011514|[[ 0.02852 -1.07742  0.56125]
20Nov23_011514| [ 0.46639 -1.07916  1.47345]
20Nov23_011514| [-0.12440 -0.62009  0.68029]]
20Nov23_011514|-- Bias --
20Nov23_011514|[-0.38219 -0.88277  0.64332]
20Nov23_011514|Layer 2:
20Nov23_011514|-- Config --
20Nov23_011514|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011514|-- Weights --
20Nov23_011514|[[-0.26708  0.46937  1.25164 -0.79851]
20Nov23_011514| [-0.22042 -0.90964  0.20610 -0.50982]
20Nov23_011514| [-0.57011  0.40682  0.33195 -0.63661]]
20Nov23_011514|-- Bias --
20Nov23_011514|[ 0.08651  0.38057 -0.52568  0.21822]
20Nov23_011514|Layer 3:
20Nov23_011514|-- Config --
20Nov23_011514|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011514|-- Weights --
20Nov23_011514|[[-1.68151  0.96943]
20Nov23_011514| [-1.25774 -0.78998]
20Nov23_011514| [-1.35154  0.53538]
20Nov23_011514| [-0.05379 -0.72412]]
20Nov23_011514|-- Bias --
20Nov23_011514|[-0.07087 -0.43718]
20Nov23_011514|Predicting the validation and test data with the Best final individual.
20Nov23_011520| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_011520|-----------  ------------------  --------------------  ----------
20Nov23_011520|Validation         42.00                  30            0.00000
20Nov23_011520|   Test            36.40                  30            0.00000
20Nov23_011520|-------------------------- Test #8 --------------------------
20Nov23_011520|Best final individual weights
20Nov23_011520|Individual:
20Nov23_011520|-- Constant hidden layers --
20Nov23_011520|False
20Nov23_011520|Layer 0:
20Nov23_011520|-- Config --
20Nov23_011520|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011520|-- Weights --
20Nov23_011520|[[ 2.81544e-01 -6.05842e-01 -3.21862e-01]
20Nov23_011520| [-7.64574e-02 -2.25410e-01 -7.86841e-01]
20Nov23_011520| [ 5.08219e-01 -2.57665e-01 -8.75233e-01]
20Nov23_011520| [-4.28170e-01  2.49161e-01  9.10295e-01]
20Nov23_011520| [-1.65254e-01 -1.04497e-01  1.86138e+00]
20Nov23_011520| [ 6.03026e-01  1.31698e+00  7.98797e-01]
20Nov23_011520| [ 4.37297e-01  6.21939e-01 -1.89649e+00]
20Nov23_011520| [-2.43418e-01 -1.29067e+00 -7.49600e-01]
20Nov23_011520| [ 6.75794e-01 -1.12743e+00  3.42927e-01]
20Nov23_011520| [-2.07087e-01  9.79404e-01 -9.41263e-01]
20Nov23_011520| [ 8.69844e-01  7.91195e-01 -2.04005e+00]
20Nov23_011520| [ 5.93969e-01  1.18998e+00  5.09909e-03]
20Nov23_011520| [-5.71844e-01 -1.05100e+00  6.64230e-01]
20Nov23_011520| [-1.83662e-02  2.60684e+00 -7.75333e-01]
20Nov23_011520| [-1.18405e+00 -6.30927e-01  1.29120e+00]
20Nov23_011520| [ 3.34434e-01  1.55517e+00  9.41732e-01]
20Nov23_011520| [ 1.35568e+00  9.04461e-01  6.82207e-01]
20Nov23_011520| [ 1.93224e+00  3.91496e-01 -3.90810e-01]
20Nov23_011520| [-1.51525e-01 -7.53769e-01  1.44364e+00]
20Nov23_011520| [ 1.79326e-01  4.31204e-01  4.25079e-01]
20Nov23_011520| [ 1.95318e-01 -3.68398e-01  1.13710e+00]
20Nov23_011520| [-1.56550e-01  2.86035e+00 -7.02992e-01]
20Nov23_011520| [-5.31242e-01 -1.36915e+00  1.06615e+00]
20Nov23_011520| [ 1.04531e+00 -3.20438e-01 -9.39162e-01]
20Nov23_011520| [-1.07150e+00 -1.10448e+00 -9.56850e-01]
20Nov23_011520| [ 2.30780e-01 -2.36734e+00 -5.45672e-01]
20Nov23_011520| [ 1.65837e+00 -1.02596e+00 -3.75298e-01]
20Nov23_011520| [ 2.68860e-01  1.88532e+00  1.45863e+00]
20Nov23_011520| [-6.62057e-01 -1.72122e-01  1.88865e+00]
20Nov23_011520| [ 6.67736e-01 -1.56745e+00  2.07945e+00]
20Nov23_011520| [ 6.52308e-01  1.71595e+00  6.00436e-02]
20Nov23_011520| [-4.84083e-01 -1.83992e+00  7.88743e-01]
20Nov23_011520| [ 2.28388e+00  5.14928e-01 -7.89078e-01]
20Nov23_011520| [-2.05070e-01 -4.94209e-01 -5.11047e-04]
20Nov23_011520| [ 2.76401e-01 -8.45665e-01  4.85630e-01]
20Nov23_011520| [ 1.38631e+00 -2.31534e-01  1.67351e+00]
20Nov23_011520| [ 2.40003e+00  4.30293e-01 -2.96407e-01]
20Nov23_011520| [-1.47168e+00 -1.12201e-01  5.23174e-02]
20Nov23_011520| [-5.99205e-01  5.25595e-02  1.14262e+00]
20Nov23_011520| [ 2.53490e-01  4.60347e-01 -8.13702e-01]
20Nov23_011520| [ 5.70195e-01 -1.38869e+00  8.50057e-01]
20Nov23_011520| [-8.57604e-01  1.35131e-01  6.03295e-01]
20Nov23_011520| [ 1.66056e+00  5.23447e-01  3.67017e-01]
20Nov23_011520| [ 2.05585e+00  2.60901e-01 -5.66920e-01]
20Nov23_011520| [-9.64678e-01 -6.26877e-01 -9.49711e-01]
20Nov23_011520| [-2.45283e-01 -7.14134e-01  1.18386e+00]
20Nov23_011520| [ 2.89841e-01 -3.41799e-01 -1.53665e+00]
20Nov23_011520| [-1.53316e+00 -8.11328e-01 -5.98503e-01]
20Nov23_011520| [-6.02444e-01  1.00080e+00 -3.18191e-01]
20Nov23_011520| [-2.39051e-01  1.05130e-01 -1.06166e-01]
20Nov23_011520| [ 5.54031e-01  7.51923e-01  3.33091e-01]
20Nov23_011520| [-1.21813e+00 -8.37235e-01 -2.16431e-01]
20Nov23_011520| [ 1.05855e+00  1.40560e+00  1.01499e+00]
20Nov23_011520| [-6.41326e-01  1.17562e+00 -1.60862e+00]
20Nov23_011520| [ 1.28062e+00  2.02472e+00 -1.41452e+00]
20Nov23_011520| [-1.25873e+00  6.41406e-01  1.02626e+00]
20Nov23_011520| [-1.36105e+00  4.41459e-01  1.56613e-01]]
20Nov23_011520|-- Bias --
20Nov23_011520|[1.39717 0.90167 0.56598]
20Nov23_011520|Layer 1:
20Nov23_011520|-- Config --
20Nov23_011520|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011520|-- Weights --
20Nov23_011520|[[ 0.02852 -1.07742  0.56125]
20Nov23_011520| [ 0.46639 -1.07916  1.47345]
20Nov23_011520| [-0.12440 -0.62009  0.68029]]
20Nov23_011520|-- Bias --
20Nov23_011520|[-0.38219 -0.88277  0.64332]
20Nov23_011520|Layer 2:
20Nov23_011520|-- Config --
20Nov23_011520|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011520|-- Weights --
20Nov23_011520|[[-0.26708  0.46937  1.25164 -0.79851]
20Nov23_011520| [-0.22042 -0.90964  0.20610 -0.50982]
20Nov23_011520| [-0.57011  0.40682  0.33195 -0.63661]]
20Nov23_011520|-- Bias --
20Nov23_011520|[ 0.08651  0.38057 -0.52568  0.21822]
20Nov23_011520|Layer 3:
20Nov23_011520|-- Config --
20Nov23_011520|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011520|-- Weights --
20Nov23_011520|[[-1.68151  0.96943]
20Nov23_011520| [-1.25774 -0.78998]
20Nov23_011520| [-1.35154  0.53538]
20Nov23_011520| [-0.05379 -0.72412]]
20Nov23_011520|-- Bias --
20Nov23_011520|[-0.07087 -0.43718]
20Nov23_011520|Predicting the validation and test data with the Best final individual.
20Nov23_011526| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_011526|-----------  ------------------  --------------------  ----------
20Nov23_011526|Validation         29.91                  30            0.78847
20Nov23_011526|   Test            36.49                  30            0.00000
20Nov23_011526|-------------------------- Test #9 --------------------------
20Nov23_011526|Best final individual weights
20Nov23_011526|Individual:
20Nov23_011526|-- Constant hidden layers --
20Nov23_011526|False
20Nov23_011526|Layer 0:
20Nov23_011526|-- Config --
20Nov23_011526|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011526|-- Weights --
20Nov23_011526|[[ 2.81544e-01 -6.05842e-01 -3.21862e-01]
20Nov23_011526| [-7.64574e-02 -2.25410e-01 -7.86841e-01]
20Nov23_011526| [ 5.08219e-01 -2.57665e-01 -8.75233e-01]
20Nov23_011526| [-4.28170e-01  2.49161e-01  9.10295e-01]
20Nov23_011526| [-1.65254e-01 -1.04497e-01  1.86138e+00]
20Nov23_011526| [ 6.03026e-01  1.31698e+00  7.98797e-01]
20Nov23_011526| [ 4.37297e-01  6.21939e-01 -1.89649e+00]
20Nov23_011526| [-2.43418e-01 -1.29067e+00 -7.49600e-01]
20Nov23_011526| [ 6.75794e-01 -1.12743e+00  3.42927e-01]
20Nov23_011526| [-2.07087e-01  9.79404e-01 -9.41263e-01]
20Nov23_011526| [ 8.69844e-01  7.91195e-01 -2.04005e+00]
20Nov23_011526| [ 5.93969e-01  1.18998e+00  5.09909e-03]
20Nov23_011526| [-5.71844e-01 -1.05100e+00  6.64230e-01]
20Nov23_011526| [-1.83662e-02  2.60684e+00 -7.75333e-01]
20Nov23_011526| [-1.18405e+00 -6.30927e-01  1.29120e+00]
20Nov23_011526| [ 3.34434e-01  1.55517e+00  9.41732e-01]
20Nov23_011526| [ 1.35568e+00  9.04461e-01  6.82207e-01]
20Nov23_011526| [ 1.93224e+00  3.91496e-01 -3.90810e-01]
20Nov23_011526| [-1.51525e-01 -7.53769e-01  1.44364e+00]
20Nov23_011526| [ 1.79326e-01  4.31204e-01  4.25079e-01]
20Nov23_011526| [ 1.95318e-01 -3.68398e-01  1.13710e+00]
20Nov23_011526| [-1.56550e-01  2.86035e+00 -7.02992e-01]
20Nov23_011526| [-5.31242e-01 -1.36915e+00  1.06615e+00]
20Nov23_011526| [ 1.04531e+00 -3.20438e-01 -9.39162e-01]
20Nov23_011526| [-1.07150e+00 -1.10448e+00 -9.56850e-01]
20Nov23_011526| [ 2.30780e-01 -2.36734e+00 -5.45672e-01]
20Nov23_011526| [ 1.65837e+00 -1.02596e+00 -3.75298e-01]
20Nov23_011526| [ 2.68860e-01  1.88532e+00  1.45863e+00]
20Nov23_011526| [-6.62057e-01 -1.72122e-01  1.88865e+00]
20Nov23_011526| [ 6.67736e-01 -1.56745e+00  2.07945e+00]
20Nov23_011526| [ 6.52308e-01  1.71595e+00  6.00436e-02]
20Nov23_011526| [-4.84083e-01 -1.83992e+00  7.88743e-01]
20Nov23_011526| [ 2.28388e+00  5.14928e-01 -7.89078e-01]
20Nov23_011526| [-2.05070e-01 -4.94209e-01 -5.11047e-04]
20Nov23_011526| [ 2.76401e-01 -8.45665e-01  4.85630e-01]
20Nov23_011526| [ 1.38631e+00 -2.31534e-01  1.67351e+00]
20Nov23_011526| [ 2.40003e+00  4.30293e-01 -2.96407e-01]
20Nov23_011526| [-1.47168e+00 -1.12201e-01  5.23174e-02]
20Nov23_011526| [-5.99205e-01  5.25595e-02  1.14262e+00]
20Nov23_011526| [ 2.53490e-01  4.60347e-01 -8.13702e-01]
20Nov23_011526| [ 5.70195e-01 -1.38869e+00  8.50057e-01]
20Nov23_011526| [-8.57604e-01  1.35131e-01  6.03295e-01]
20Nov23_011526| [ 1.66056e+00  5.23447e-01  3.67017e-01]
20Nov23_011526| [ 2.05585e+00  2.60901e-01 -5.66920e-01]
20Nov23_011526| [-9.64678e-01 -6.26877e-01 -9.49711e-01]
20Nov23_011526| [-2.45283e-01 -7.14134e-01  1.18386e+00]
20Nov23_011526| [ 2.89841e-01 -3.41799e-01 -1.53665e+00]
20Nov23_011526| [-1.53316e+00 -8.11328e-01 -5.98503e-01]
20Nov23_011526| [-6.02444e-01  1.00080e+00 -3.18191e-01]
20Nov23_011526| [-2.39051e-01  1.05130e-01 -1.06166e-01]
20Nov23_011526| [ 5.54031e-01  7.51923e-01  3.33091e-01]
20Nov23_011526| [-1.21813e+00 -8.37235e-01 -2.16431e-01]
20Nov23_011526| [ 1.05855e+00  1.40560e+00  1.01499e+00]
20Nov23_011526| [-6.41326e-01  1.17562e+00 -1.60862e+00]
20Nov23_011526| [ 1.28062e+00  2.02472e+00 -1.41452e+00]
20Nov23_011526| [-1.25873e+00  6.41406e-01  1.02626e+00]
20Nov23_011526| [-1.36105e+00  4.41459e-01  1.56613e-01]]
20Nov23_011526|-- Bias --
20Nov23_011526|[1.39717 0.90167 0.56598]
20Nov23_011526|Layer 1:
20Nov23_011526|-- Config --
20Nov23_011526|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011526|-- Weights --
20Nov23_011526|[[ 0.02852 -1.07742  0.56125]
20Nov23_011526| [ 0.46639 -1.07916  1.47345]
20Nov23_011526| [-0.12440 -0.62009  0.68029]]
20Nov23_011526|-- Bias --
20Nov23_011526|[-0.38219 -0.88277  0.64332]
20Nov23_011526|Layer 2:
20Nov23_011526|-- Config --
20Nov23_011526|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011526|-- Weights --
20Nov23_011526|[[-0.26708  0.46937  1.25164 -0.79851]
20Nov23_011526| [-0.22042 -0.90964  0.20610 -0.50982]
20Nov23_011526| [-0.57011  0.40682  0.33195 -0.63661]]
20Nov23_011526|-- Bias --
20Nov23_011526|[ 0.08651  0.38057 -0.52568  0.21822]
20Nov23_011526|Layer 3:
20Nov23_011526|-- Config --
20Nov23_011526|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011526|-- Weights --
20Nov23_011526|[[-1.68151  0.96943]
20Nov23_011526| [-1.25774 -0.78998]
20Nov23_011526| [-1.35154  0.53538]
20Nov23_011526| [-0.05379 -0.72412]]
20Nov23_011526|-- Bias --
20Nov23_011526|[-0.07087 -0.43718]
20Nov23_011526|Predicting the validation and test data with the Best final individual.
20Nov23_011532| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_011532|-----------  ------------------  --------------------  ----------
20Nov23_011532|Validation         42.00                  30            0.00000
20Nov23_011532|   Test            36.58                  30            0.00595
20Nov23_011532|-------------------------- Test #10 --------------------------
20Nov23_011532|Best final individual weights
20Nov23_011532|Individual:
20Nov23_011532|-- Constant hidden layers --
20Nov23_011532|False
20Nov23_011532|Layer 0:
20Nov23_011532|-- Config --
20Nov23_011532|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011532|-- Weights --
20Nov23_011532|[[ 2.81544e-01 -6.05842e-01 -3.21862e-01]
20Nov23_011532| [-7.64574e-02 -2.25410e-01 -7.86841e-01]
20Nov23_011532| [ 5.08219e-01 -2.57665e-01 -8.75233e-01]
20Nov23_011532| [-4.28170e-01  2.49161e-01  9.10295e-01]
20Nov23_011532| [-1.65254e-01 -1.04497e-01  1.86138e+00]
20Nov23_011532| [ 6.03026e-01  1.31698e+00  7.98797e-01]
20Nov23_011532| [ 4.37297e-01  6.21939e-01 -1.89649e+00]
20Nov23_011532| [-2.43418e-01 -1.29067e+00 -7.49600e-01]
20Nov23_011532| [ 6.75794e-01 -1.12743e+00  3.42927e-01]
20Nov23_011532| [-2.07087e-01  9.79404e-01 -9.41263e-01]
20Nov23_011532| [ 8.69844e-01  7.91195e-01 -2.04005e+00]
20Nov23_011532| [ 5.93969e-01  1.18998e+00  5.09909e-03]
20Nov23_011532| [-5.71844e-01 -1.05100e+00  6.64230e-01]
20Nov23_011532| [-1.83662e-02  2.60684e+00 -7.75333e-01]
20Nov23_011532| [-1.18405e+00 -6.30927e-01  1.29120e+00]
20Nov23_011532| [ 3.34434e-01  1.55517e+00  9.41732e-01]
20Nov23_011532| [ 1.35568e+00  9.04461e-01  6.82207e-01]
20Nov23_011532| [ 1.93224e+00  3.91496e-01 -3.90810e-01]
20Nov23_011532| [-1.51525e-01 -7.53769e-01  1.44364e+00]
20Nov23_011532| [ 1.79326e-01  4.31204e-01  4.25079e-01]
20Nov23_011532| [ 1.95318e-01 -3.68398e-01  1.13710e+00]
20Nov23_011532| [-1.56550e-01  2.86035e+00 -7.02992e-01]
20Nov23_011532| [-5.31242e-01 -1.36915e+00  1.06615e+00]
20Nov23_011532| [ 1.04531e+00 -3.20438e-01 -9.39162e-01]
20Nov23_011532| [-1.07150e+00 -1.10448e+00 -9.56850e-01]
20Nov23_011532| [ 2.30780e-01 -2.36734e+00 -5.45672e-01]
20Nov23_011532| [ 1.65837e+00 -1.02596e+00 -3.75298e-01]
20Nov23_011532| [ 2.68860e-01  1.88532e+00  1.45863e+00]
20Nov23_011532| [-6.62057e-01 -1.72122e-01  1.88865e+00]
20Nov23_011532| [ 6.67736e-01 -1.56745e+00  2.07945e+00]
20Nov23_011532| [ 6.52308e-01  1.71595e+00  6.00436e-02]
20Nov23_011532| [-4.84083e-01 -1.83992e+00  7.88743e-01]
20Nov23_011532| [ 2.28388e+00  5.14928e-01 -7.89078e-01]
20Nov23_011532| [-2.05070e-01 -4.94209e-01 -5.11047e-04]
20Nov23_011532| [ 2.76401e-01 -8.45665e-01  4.85630e-01]
20Nov23_011532| [ 1.38631e+00 -2.31534e-01  1.67351e+00]
20Nov23_011532| [ 2.40003e+00  4.30293e-01 -2.96407e-01]
20Nov23_011532| [-1.47168e+00 -1.12201e-01  5.23174e-02]
20Nov23_011532| [-5.99205e-01  5.25595e-02  1.14262e+00]
20Nov23_011532| [ 2.53490e-01  4.60347e-01 -8.13702e-01]
20Nov23_011532| [ 5.70195e-01 -1.38869e+00  8.50057e-01]
20Nov23_011532| [-8.57604e-01  1.35131e-01  6.03295e-01]
20Nov23_011532| [ 1.66056e+00  5.23447e-01  3.67017e-01]
20Nov23_011532| [ 2.05585e+00  2.60901e-01 -5.66920e-01]
20Nov23_011532| [-9.64678e-01 -6.26877e-01 -9.49711e-01]
20Nov23_011532| [-2.45283e-01 -7.14134e-01  1.18386e+00]
20Nov23_011532| [ 2.89841e-01 -3.41799e-01 -1.53665e+00]
20Nov23_011532| [-1.53316e+00 -8.11328e-01 -5.98503e-01]
20Nov23_011532| [-6.02444e-01  1.00080e+00 -3.18191e-01]
20Nov23_011532| [-2.39051e-01  1.05130e-01 -1.06166e-01]
20Nov23_011532| [ 5.54031e-01  7.51923e-01  3.33091e-01]
20Nov23_011532| [-1.21813e+00 -8.37235e-01 -2.16431e-01]
20Nov23_011532| [ 1.05855e+00  1.40560e+00  1.01499e+00]
20Nov23_011532| [-6.41326e-01  1.17562e+00 -1.60862e+00]
20Nov23_011532| [ 1.28062e+00  2.02472e+00 -1.41452e+00]
20Nov23_011532| [-1.25873e+00  6.41406e-01  1.02626e+00]
20Nov23_011532| [-1.36105e+00  4.41459e-01  1.56613e-01]]
20Nov23_011532|-- Bias --
20Nov23_011532|[1.39717 0.90167 0.56598]
20Nov23_011532|Layer 1:
20Nov23_011532|-- Config --
20Nov23_011532|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011532|-- Weights --
20Nov23_011532|[[ 0.02852 -1.07742  0.56125]
20Nov23_011532| [ 0.46639 -1.07916  1.47345]
20Nov23_011532| [-0.12440 -0.62009  0.68029]]
20Nov23_011532|-- Bias --
20Nov23_011532|[-0.38219 -0.88277  0.64332]
20Nov23_011532|Layer 2:
20Nov23_011532|-- Config --
20Nov23_011532|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011532|-- Weights --
20Nov23_011532|[[-0.26708  0.46937  1.25164 -0.79851]
20Nov23_011532| [-0.22042 -0.90964  0.20610 -0.50982]
20Nov23_011532| [-0.57011  0.40682  0.33195 -0.63661]]
20Nov23_011532|-- Bias --
20Nov23_011532|[ 0.08651  0.38057 -0.52568  0.21822]
20Nov23_011532|Layer 3:
20Nov23_011532|-- Config --
20Nov23_011532|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011532|-- Weights --
20Nov23_011532|[[-1.68151  0.96943]
20Nov23_011532| [-1.25774 -0.78998]
20Nov23_011532| [-1.35154  0.53538]
20Nov23_011532| [-0.05379 -0.72412]]
20Nov23_011532|-- Bias --
20Nov23_011532|[-0.07087 -0.43718]
20Nov23_011532|Predicting the validation and test data with the Best final individual.
20Nov23_011538| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_011538|-----------  ------------------  --------------------  ----------
20Nov23_011538|Validation         26.17                  30            0.54862
20Nov23_011538|   Test            24.24                  30            0.64313
20Nov23_011538|-------------------------- Test #11 --------------------------
20Nov23_011538|Best final individual weights
20Nov23_011538|Individual:
20Nov23_011538|-- Constant hidden layers --
20Nov23_011538|False
20Nov23_011538|Layer 0:
20Nov23_011538|-- Config --
20Nov23_011538|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011538|-- Weights --
20Nov23_011538|[[ 2.81544e-01 -6.05842e-01 -3.21862e-01]
20Nov23_011538| [-7.64574e-02 -2.25410e-01 -7.86841e-01]
20Nov23_011538| [ 5.08219e-01 -2.57665e-01 -8.75233e-01]
20Nov23_011538| [-4.28170e-01  2.49161e-01  9.10295e-01]
20Nov23_011538| [-1.65254e-01 -1.04497e-01  1.86138e+00]
20Nov23_011538| [ 6.03026e-01  1.31698e+00  7.98797e-01]
20Nov23_011538| [ 4.37297e-01  6.21939e-01 -1.89649e+00]
20Nov23_011538| [-2.43418e-01 -1.29067e+00 -7.49600e-01]
20Nov23_011538| [ 6.75794e-01 -1.12743e+00  3.42927e-01]
20Nov23_011538| [-2.07087e-01  9.79404e-01 -9.41263e-01]
20Nov23_011538| [ 8.69844e-01  7.91195e-01 -2.04005e+00]
20Nov23_011538| [ 5.93969e-01  1.18998e+00  5.09909e-03]
20Nov23_011538| [-5.71844e-01 -1.05100e+00  6.64230e-01]
20Nov23_011538| [-1.83662e-02  2.60684e+00 -7.75333e-01]
20Nov23_011538| [-1.18405e+00 -6.30927e-01  1.29120e+00]
20Nov23_011538| [ 3.34434e-01  1.55517e+00  9.41732e-01]
20Nov23_011538| [ 1.35568e+00  9.04461e-01  6.82207e-01]
20Nov23_011538| [ 1.93224e+00  3.91496e-01 -3.90810e-01]
20Nov23_011538| [-1.51525e-01 -7.53769e-01  1.44364e+00]
20Nov23_011538| [ 1.79326e-01  4.31204e-01  4.25079e-01]
20Nov23_011538| [ 1.95318e-01 -3.68398e-01  1.13710e+00]
20Nov23_011538| [-1.56550e-01  2.86035e+00 -7.02992e-01]
20Nov23_011538| [-5.31242e-01 -1.36915e+00  1.06615e+00]
20Nov23_011538| [ 1.04531e+00 -3.20438e-01 -9.39162e-01]
20Nov23_011538| [-1.07150e+00 -1.10448e+00 -9.56850e-01]
20Nov23_011538| [ 2.30780e-01 -2.36734e+00 -5.45672e-01]
20Nov23_011538| [ 1.65837e+00 -1.02596e+00 -3.75298e-01]
20Nov23_011538| [ 2.68860e-01  1.88532e+00  1.45863e+00]
20Nov23_011538| [-6.62057e-01 -1.72122e-01  1.88865e+00]
20Nov23_011538| [ 6.67736e-01 -1.56745e+00  2.07945e+00]
20Nov23_011538| [ 6.52308e-01  1.71595e+00  6.00436e-02]
20Nov23_011538| [-4.84083e-01 -1.83992e+00  7.88743e-01]
20Nov23_011538| [ 2.28388e+00  5.14928e-01 -7.89078e-01]
20Nov23_011538| [-2.05070e-01 -4.94209e-01 -5.11047e-04]
20Nov23_011538| [ 2.76401e-01 -8.45665e-01  4.85630e-01]
20Nov23_011538| [ 1.38631e+00 -2.31534e-01  1.67351e+00]
20Nov23_011538| [ 2.40003e+00  4.30293e-01 -2.96407e-01]
20Nov23_011538| [-1.47168e+00 -1.12201e-01  5.23174e-02]
20Nov23_011538| [-5.99205e-01  5.25595e-02  1.14262e+00]
20Nov23_011538| [ 2.53490e-01  4.60347e-01 -8.13702e-01]
20Nov23_011538| [ 5.70195e-01 -1.38869e+00  8.50057e-01]
20Nov23_011538| [-8.57604e-01  1.35131e-01  6.03295e-01]
20Nov23_011538| [ 1.66056e+00  5.23447e-01  3.67017e-01]
20Nov23_011538| [ 2.05585e+00  2.60901e-01 -5.66920e-01]
20Nov23_011538| [-9.64678e-01 -6.26877e-01 -9.49711e-01]
20Nov23_011538| [-2.45283e-01 -7.14134e-01  1.18386e+00]
20Nov23_011538| [ 2.89841e-01 -3.41799e-01 -1.53665e+00]
20Nov23_011538| [-1.53316e+00 -8.11328e-01 -5.98503e-01]
20Nov23_011538| [-6.02444e-01  1.00080e+00 -3.18191e-01]
20Nov23_011538| [-2.39051e-01  1.05130e-01 -1.06166e-01]
20Nov23_011538| [ 5.54031e-01  7.51923e-01  3.33091e-01]
20Nov23_011538| [-1.21813e+00 -8.37235e-01 -2.16431e-01]
20Nov23_011538| [ 1.05855e+00  1.40560e+00  1.01499e+00]
20Nov23_011538| [-6.41326e-01  1.17562e+00 -1.60862e+00]
20Nov23_011538| [ 1.28062e+00  2.02472e+00 -1.41452e+00]
20Nov23_011538| [-1.25873e+00  6.41406e-01  1.02626e+00]
20Nov23_011538| [-1.36105e+00  4.41459e-01  1.56613e-01]]
20Nov23_011538|-- Bias --
20Nov23_011538|[1.39717 0.90167 0.56598]
20Nov23_011538|Layer 1:
20Nov23_011538|-- Config --
20Nov23_011538|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011538|-- Weights --
20Nov23_011538|[[ 0.02852 -1.07742  0.56125]
20Nov23_011538| [ 0.46639 -1.07916  1.47345]
20Nov23_011538| [-0.12440 -0.62009  0.68029]]
20Nov23_011538|-- Bias --
20Nov23_011538|[-0.38219 -0.88277  0.64332]
20Nov23_011538|Layer 2:
20Nov23_011538|-- Config --
20Nov23_011538|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011538|-- Weights --
20Nov23_011538|[[-0.26708  0.46937  1.25164 -0.79851]
20Nov23_011538| [-0.22042 -0.90964  0.20610 -0.50982]
20Nov23_011538| [-0.57011  0.40682  0.33195 -0.63661]]
20Nov23_011538|-- Bias --
20Nov23_011538|[ 0.08651  0.38057 -0.52568  0.21822]
20Nov23_011538|Layer 3:
20Nov23_011538|-- Config --
20Nov23_011538|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011538|-- Weights --
20Nov23_011538|[[-1.68151  0.96943]
20Nov23_011538| [-1.25774 -0.78998]
20Nov23_011538| [-1.35154  0.53538]
20Nov23_011538| [-0.05379 -0.72412]]
20Nov23_011538|-- Bias --
20Nov23_011538|[-0.07087 -0.43718]
20Nov23_011538|Predicting the validation and test data with the Best final individual.
20Nov23_011544| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_011544|-----------  ------------------  --------------------  ----------
20Nov23_011544|Validation         42.00                  30            0.00000
20Nov23_011544|   Test            36.40                  30            0.00000
20Nov23_011544|-------------------------- Test #12 --------------------------
20Nov23_011544|Best final individual weights
20Nov23_011544|Individual:
20Nov23_011544|-- Constant hidden layers --
20Nov23_011544|False
20Nov23_011544|Layer 0:
20Nov23_011544|-- Config --
20Nov23_011544|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011544|-- Weights --
20Nov23_011544|[[ 2.81544e-01 -6.05842e-01 -3.21862e-01]
20Nov23_011544| [-7.64574e-02 -2.25410e-01 -7.86841e-01]
20Nov23_011544| [ 5.08219e-01 -2.57665e-01 -8.75233e-01]
20Nov23_011544| [-4.28170e-01  2.49161e-01  9.10295e-01]
20Nov23_011544| [-1.65254e-01 -1.04497e-01  1.86138e+00]
20Nov23_011544| [ 6.03026e-01  1.31698e+00  7.98797e-01]
20Nov23_011544| [ 4.37297e-01  6.21939e-01 -1.89649e+00]
20Nov23_011544| [-2.43418e-01 -1.29067e+00 -7.49600e-01]
20Nov23_011544| [ 6.75794e-01 -1.12743e+00  3.42927e-01]
20Nov23_011544| [-2.07087e-01  9.79404e-01 -9.41263e-01]
20Nov23_011544| [ 8.69844e-01  7.91195e-01 -2.04005e+00]
20Nov23_011544| [ 5.93969e-01  1.18998e+00  5.09909e-03]
20Nov23_011544| [-5.71844e-01 -1.05100e+00  6.64230e-01]
20Nov23_011544| [-1.83662e-02  2.60684e+00 -7.75333e-01]
20Nov23_011544| [-1.18405e+00 -6.30927e-01  1.29120e+00]
20Nov23_011544| [ 3.34434e-01  1.55517e+00  9.41732e-01]
20Nov23_011544| [ 1.35568e+00  9.04461e-01  6.82207e-01]
20Nov23_011544| [ 1.93224e+00  3.91496e-01 -3.90810e-01]
20Nov23_011544| [-1.51525e-01 -7.53769e-01  1.44364e+00]
20Nov23_011544| [ 1.79326e-01  4.31204e-01  4.25079e-01]
20Nov23_011544| [ 1.95318e-01 -3.68398e-01  1.13710e+00]
20Nov23_011544| [-1.56550e-01  2.86035e+00 -7.02992e-01]
20Nov23_011544| [-5.31242e-01 -1.36915e+00  1.06615e+00]
20Nov23_011544| [ 1.04531e+00 -3.20438e-01 -9.39162e-01]
20Nov23_011544| [-1.07150e+00 -1.10448e+00 -9.56850e-01]
20Nov23_011544| [ 2.30780e-01 -2.36734e+00 -5.45672e-01]
20Nov23_011544| [ 1.65837e+00 -1.02596e+00 -3.75298e-01]
20Nov23_011544| [ 2.68860e-01  1.88532e+00  1.45863e+00]
20Nov23_011544| [-6.62057e-01 -1.72122e-01  1.88865e+00]
20Nov23_011544| [ 6.67736e-01 -1.56745e+00  2.07945e+00]
20Nov23_011544| [ 6.52308e-01  1.71595e+00  6.00436e-02]
20Nov23_011544| [-4.84083e-01 -1.83992e+00  7.88743e-01]
20Nov23_011544| [ 2.28388e+00  5.14928e-01 -7.89078e-01]
20Nov23_011544| [-2.05070e-01 -4.94209e-01 -5.11047e-04]
20Nov23_011544| [ 2.76401e-01 -8.45665e-01  4.85630e-01]
20Nov23_011544| [ 1.38631e+00 -2.31534e-01  1.67351e+00]
20Nov23_011544| [ 2.40003e+00  4.30293e-01 -2.96407e-01]
20Nov23_011544| [-1.47168e+00 -1.12201e-01  5.23174e-02]
20Nov23_011544| [-5.99205e-01  5.25595e-02  1.14262e+00]
20Nov23_011544| [ 2.53490e-01  4.60347e-01 -8.13702e-01]
20Nov23_011544| [ 5.70195e-01 -1.38869e+00  8.50057e-01]
20Nov23_011544| [-8.57604e-01  1.35131e-01  6.03295e-01]
20Nov23_011544| [ 1.66056e+00  5.23447e-01  3.67017e-01]
20Nov23_011544| [ 2.05585e+00  2.60901e-01 -5.66920e-01]
20Nov23_011544| [-9.64678e-01 -6.26877e-01 -9.49711e-01]
20Nov23_011544| [-2.45283e-01 -7.14134e-01  1.18386e+00]
20Nov23_011544| [ 2.89841e-01 -3.41799e-01 -1.53665e+00]
20Nov23_011544| [-1.53316e+00 -8.11328e-01 -5.98503e-01]
20Nov23_011544| [-6.02444e-01  1.00080e+00 -3.18191e-01]
20Nov23_011544| [-2.39051e-01  1.05130e-01 -1.06166e-01]
20Nov23_011544| [ 5.54031e-01  7.51923e-01  3.33091e-01]
20Nov23_011544| [-1.21813e+00 -8.37235e-01 -2.16431e-01]
20Nov23_011544| [ 1.05855e+00  1.40560e+00  1.01499e+00]
20Nov23_011544| [-6.41326e-01  1.17562e+00 -1.60862e+00]
20Nov23_011544| [ 1.28062e+00  2.02472e+00 -1.41452e+00]
20Nov23_011544| [-1.25873e+00  6.41406e-01  1.02626e+00]
20Nov23_011544| [-1.36105e+00  4.41459e-01  1.56613e-01]]
20Nov23_011544|-- Bias --
20Nov23_011544|[1.39717 0.90167 0.56598]
20Nov23_011544|Layer 1:
20Nov23_011544|-- Config --
20Nov23_011544|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011544|-- Weights --
20Nov23_011544|[[ 0.02852 -1.07742  0.56125]
20Nov23_011544| [ 0.46639 -1.07916  1.47345]
20Nov23_011544| [-0.12440 -0.62009  0.68029]]
20Nov23_011544|-- Bias --
20Nov23_011544|[-0.38219 -0.88277  0.64332]
20Nov23_011544|Layer 2:
20Nov23_011544|-- Config --
20Nov23_011544|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011544|-- Weights --
20Nov23_011544|[[-0.26708  0.46937  1.25164 -0.79851]
20Nov23_011544| [-0.22042 -0.90964  0.20610 -0.50982]
20Nov23_011544| [-0.57011  0.40682  0.33195 -0.63661]]
20Nov23_011544|-- Bias --
20Nov23_011544|[ 0.08651  0.38057 -0.52568  0.21822]
20Nov23_011544|Layer 3:
20Nov23_011544|-- Config --
20Nov23_011544|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011544|-- Weights --
20Nov23_011544|[[-1.68151  0.96943]
20Nov23_011544| [-1.25774 -0.78998]
20Nov23_011544| [-1.35154  0.53538]
20Nov23_011544| [-0.05379 -0.72412]]
20Nov23_011544|-- Bias --
20Nov23_011544|[-0.07087 -0.43718]
20Nov23_011544|Predicting the validation and test data with the Best final individual.
20Nov23_011550| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_011550|-----------  ------------------  --------------------  ----------
20Nov23_011550|Validation         26.52                  30            0.55111
20Nov23_011550|   Test            36.40                  30            0.00000
20Nov23_011550|-------------------------- Test #13 --------------------------
20Nov23_011550|Best final individual weights
20Nov23_011550|Individual:
20Nov23_011550|-- Constant hidden layers --
20Nov23_011550|False
20Nov23_011550|Layer 0:
20Nov23_011550|-- Config --
20Nov23_011550|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011550|-- Weights --
20Nov23_011550|[[ 2.81544e-01 -6.05842e-01 -3.21862e-01]
20Nov23_011550| [-7.64574e-02 -2.25410e-01 -7.86841e-01]
20Nov23_011550| [ 5.08219e-01 -2.57665e-01 -8.75233e-01]
20Nov23_011550| [-4.28170e-01  2.49161e-01  9.10295e-01]
20Nov23_011550| [-1.65254e-01 -1.04497e-01  1.86138e+00]
20Nov23_011550| [ 6.03026e-01  1.31698e+00  7.98797e-01]
20Nov23_011550| [ 4.37297e-01  6.21939e-01 -1.89649e+00]
20Nov23_011550| [-2.43418e-01 -1.29067e+00 -7.49600e-01]
20Nov23_011550| [ 6.75794e-01 -1.12743e+00  3.42927e-01]
20Nov23_011550| [-2.07087e-01  9.79404e-01 -9.41263e-01]
20Nov23_011550| [ 8.69844e-01  7.91195e-01 -2.04005e+00]
20Nov23_011550| [ 5.93969e-01  1.18998e+00  5.09909e-03]
20Nov23_011550| [-5.71844e-01 -1.05100e+00  6.64230e-01]
20Nov23_011550| [-1.83662e-02  2.60684e+00 -7.75333e-01]
20Nov23_011550| [-1.18405e+00 -6.30927e-01  1.29120e+00]
20Nov23_011550| [ 3.34434e-01  1.55517e+00  9.41732e-01]
20Nov23_011550| [ 1.35568e+00  9.04461e-01  6.82207e-01]
20Nov23_011550| [ 1.93224e+00  3.91496e-01 -3.90810e-01]
20Nov23_011550| [-1.51525e-01 -7.53769e-01  1.44364e+00]
20Nov23_011550| [ 1.79326e-01  4.31204e-01  4.25079e-01]
20Nov23_011550| [ 1.95318e-01 -3.68398e-01  1.13710e+00]
20Nov23_011550| [-1.56550e-01  2.86035e+00 -7.02992e-01]
20Nov23_011550| [-5.31242e-01 -1.36915e+00  1.06615e+00]
20Nov23_011550| [ 1.04531e+00 -3.20438e-01 -9.39162e-01]
20Nov23_011550| [-1.07150e+00 -1.10448e+00 -9.56850e-01]
20Nov23_011550| [ 2.30780e-01 -2.36734e+00 -5.45672e-01]
20Nov23_011550| [ 1.65837e+00 -1.02596e+00 -3.75298e-01]
20Nov23_011550| [ 2.68860e-01  1.88532e+00  1.45863e+00]
20Nov23_011550| [-6.62057e-01 -1.72122e-01  1.88865e+00]
20Nov23_011550| [ 6.67736e-01 -1.56745e+00  2.07945e+00]
20Nov23_011550| [ 6.52308e-01  1.71595e+00  6.00436e-02]
20Nov23_011550| [-4.84083e-01 -1.83992e+00  7.88743e-01]
20Nov23_011550| [ 2.28388e+00  5.14928e-01 -7.89078e-01]
20Nov23_011550| [-2.05070e-01 -4.94209e-01 -5.11047e-04]
20Nov23_011550| [ 2.76401e-01 -8.45665e-01  4.85630e-01]
20Nov23_011550| [ 1.38631e+00 -2.31534e-01  1.67351e+00]
20Nov23_011550| [ 2.40003e+00  4.30293e-01 -2.96407e-01]
20Nov23_011550| [-1.47168e+00 -1.12201e-01  5.23174e-02]
20Nov23_011550| [-5.99205e-01  5.25595e-02  1.14262e+00]
20Nov23_011550| [ 2.53490e-01  4.60347e-01 -8.13702e-01]
20Nov23_011550| [ 5.70195e-01 -1.38869e+00  8.50057e-01]
20Nov23_011550| [-8.57604e-01  1.35131e-01  6.03295e-01]
20Nov23_011550| [ 1.66056e+00  5.23447e-01  3.67017e-01]
20Nov23_011550| [ 2.05585e+00  2.60901e-01 -5.66920e-01]
20Nov23_011550| [-9.64678e-01 -6.26877e-01 -9.49711e-01]
20Nov23_011550| [-2.45283e-01 -7.14134e-01  1.18386e+00]
20Nov23_011550| [ 2.89841e-01 -3.41799e-01 -1.53665e+00]
20Nov23_011550| [-1.53316e+00 -8.11328e-01 -5.98503e-01]
20Nov23_011550| [-6.02444e-01  1.00080e+00 -3.18191e-01]
20Nov23_011550| [-2.39051e-01  1.05130e-01 -1.06166e-01]
20Nov23_011550| [ 5.54031e-01  7.51923e-01  3.33091e-01]
20Nov23_011550| [-1.21813e+00 -8.37235e-01 -2.16431e-01]
20Nov23_011550| [ 1.05855e+00  1.40560e+00  1.01499e+00]
20Nov23_011550| [-6.41326e-01  1.17562e+00 -1.60862e+00]
20Nov23_011550| [ 1.28062e+00  2.02472e+00 -1.41452e+00]
20Nov23_011550| [-1.25873e+00  6.41406e-01  1.02626e+00]
20Nov23_011550| [-1.36105e+00  4.41459e-01  1.56613e-01]]
20Nov23_011550|-- Bias --
20Nov23_011550|[1.39717 0.90167 0.56598]
20Nov23_011550|Layer 1:
20Nov23_011550|-- Config --
20Nov23_011550|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011550|-- Weights --
20Nov23_011550|[[ 0.02852 -1.07742  0.56125]
20Nov23_011550| [ 0.46639 -1.07916  1.47345]
20Nov23_011550| [-0.12440 -0.62009  0.68029]]
20Nov23_011550|-- Bias --
20Nov23_011550|[-0.38219 -0.88277  0.64332]
20Nov23_011550|Layer 2:
20Nov23_011550|-- Config --
20Nov23_011550|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011550|-- Weights --
20Nov23_011550|[[-0.26708  0.46937  1.25164 -0.79851]
20Nov23_011550| [-0.22042 -0.90964  0.20610 -0.50982]
20Nov23_011550| [-0.57011  0.40682  0.33195 -0.63661]]
20Nov23_011550|-- Bias --
20Nov23_011550|[ 0.08651  0.38057 -0.52568  0.21822]
20Nov23_011550|Layer 3:
20Nov23_011550|-- Config --
20Nov23_011550|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011550|-- Weights --
20Nov23_011550|[[-1.68151  0.96943]
20Nov23_011550| [-1.25774 -0.78998]
20Nov23_011550| [-1.35154  0.53538]
20Nov23_011550| [-0.05379 -0.72412]]
20Nov23_011550|-- Bias --
20Nov23_011550|[-0.07087 -0.43718]
20Nov23_011550|Predicting the validation and test data with the Best final individual.
20Nov23_011557| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_011557|-----------  ------------------  --------------------  ----------
20Nov23_011557|Validation         42.00                  30            0.00000
20Nov23_011557|   Test            36.40                  30            0.00000
20Nov23_011557|-------------------------- Test #14 --------------------------
20Nov23_011557|Best final individual weights
20Nov23_011557|Individual:
20Nov23_011557|-- Constant hidden layers --
20Nov23_011557|False
20Nov23_011557|Layer 0:
20Nov23_011557|-- Config --
20Nov23_011557|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011557|-- Weights --
20Nov23_011557|[[ 2.81544e-01 -6.05842e-01 -3.21862e-01]
20Nov23_011557| [-7.64574e-02 -2.25410e-01 -7.86841e-01]
20Nov23_011557| [ 5.08219e-01 -2.57665e-01 -8.75233e-01]
20Nov23_011557| [-4.28170e-01  2.49161e-01  9.10295e-01]
20Nov23_011557| [-1.65254e-01 -1.04497e-01  1.86138e+00]
20Nov23_011557| [ 6.03026e-01  1.31698e+00  7.98797e-01]
20Nov23_011557| [ 4.37297e-01  6.21939e-01 -1.89649e+00]
20Nov23_011557| [-2.43418e-01 -1.29067e+00 -7.49600e-01]
20Nov23_011557| [ 6.75794e-01 -1.12743e+00  3.42927e-01]
20Nov23_011557| [-2.07087e-01  9.79404e-01 -9.41263e-01]
20Nov23_011557| [ 8.69844e-01  7.91195e-01 -2.04005e+00]
20Nov23_011557| [ 5.93969e-01  1.18998e+00  5.09909e-03]
20Nov23_011557| [-5.71844e-01 -1.05100e+00  6.64230e-01]
20Nov23_011557| [-1.83662e-02  2.60684e+00 -7.75333e-01]
20Nov23_011557| [-1.18405e+00 -6.30927e-01  1.29120e+00]
20Nov23_011557| [ 3.34434e-01  1.55517e+00  9.41732e-01]
20Nov23_011557| [ 1.35568e+00  9.04461e-01  6.82207e-01]
20Nov23_011557| [ 1.93224e+00  3.91496e-01 -3.90810e-01]
20Nov23_011557| [-1.51525e-01 -7.53769e-01  1.44364e+00]
20Nov23_011557| [ 1.79326e-01  4.31204e-01  4.25079e-01]
20Nov23_011557| [ 1.95318e-01 -3.68398e-01  1.13710e+00]
20Nov23_011557| [-1.56550e-01  2.86035e+00 -7.02992e-01]
20Nov23_011557| [-5.31242e-01 -1.36915e+00  1.06615e+00]
20Nov23_011557| [ 1.04531e+00 -3.20438e-01 -9.39162e-01]
20Nov23_011557| [-1.07150e+00 -1.10448e+00 -9.56850e-01]
20Nov23_011557| [ 2.30780e-01 -2.36734e+00 -5.45672e-01]
20Nov23_011557| [ 1.65837e+00 -1.02596e+00 -3.75298e-01]
20Nov23_011557| [ 2.68860e-01  1.88532e+00  1.45863e+00]
20Nov23_011557| [-6.62057e-01 -1.72122e-01  1.88865e+00]
20Nov23_011557| [ 6.67736e-01 -1.56745e+00  2.07945e+00]
20Nov23_011557| [ 6.52308e-01  1.71595e+00  6.00436e-02]
20Nov23_011557| [-4.84083e-01 -1.83992e+00  7.88743e-01]
20Nov23_011557| [ 2.28388e+00  5.14928e-01 -7.89078e-01]
20Nov23_011557| [-2.05070e-01 -4.94209e-01 -5.11047e-04]
20Nov23_011557| [ 2.76401e-01 -8.45665e-01  4.85630e-01]
20Nov23_011557| [ 1.38631e+00 -2.31534e-01  1.67351e+00]
20Nov23_011557| [ 2.40003e+00  4.30293e-01 -2.96407e-01]
20Nov23_011557| [-1.47168e+00 -1.12201e-01  5.23174e-02]
20Nov23_011557| [-5.99205e-01  5.25595e-02  1.14262e+00]
20Nov23_011557| [ 2.53490e-01  4.60347e-01 -8.13702e-01]
20Nov23_011557| [ 5.70195e-01 -1.38869e+00  8.50057e-01]
20Nov23_011557| [-8.57604e-01  1.35131e-01  6.03295e-01]
20Nov23_011557| [ 1.66056e+00  5.23447e-01  3.67017e-01]
20Nov23_011557| [ 2.05585e+00  2.60901e-01 -5.66920e-01]
20Nov23_011557| [-9.64678e-01 -6.26877e-01 -9.49711e-01]
20Nov23_011557| [-2.45283e-01 -7.14134e-01  1.18386e+00]
20Nov23_011557| [ 2.89841e-01 -3.41799e-01 -1.53665e+00]
20Nov23_011557| [-1.53316e+00 -8.11328e-01 -5.98503e-01]
20Nov23_011557| [-6.02444e-01  1.00080e+00 -3.18191e-01]
20Nov23_011557| [-2.39051e-01  1.05130e-01 -1.06166e-01]
20Nov23_011557| [ 5.54031e-01  7.51923e-01  3.33091e-01]
20Nov23_011557| [-1.21813e+00 -8.37235e-01 -2.16431e-01]
20Nov23_011557| [ 1.05855e+00  1.40560e+00  1.01499e+00]
20Nov23_011557| [-6.41326e-01  1.17562e+00 -1.60862e+00]
20Nov23_011557| [ 1.28062e+00  2.02472e+00 -1.41452e+00]
20Nov23_011557| [-1.25873e+00  6.41406e-01  1.02626e+00]
20Nov23_011557| [-1.36105e+00  4.41459e-01  1.56613e-01]]
20Nov23_011557|-- Bias --
20Nov23_011557|[1.39717 0.90167 0.56598]
20Nov23_011557|Layer 1:
20Nov23_011557|-- Config --
20Nov23_011557|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011557|-- Weights --
20Nov23_011557|[[ 0.02852 -1.07742  0.56125]
20Nov23_011557| [ 0.46639 -1.07916  1.47345]
20Nov23_011557| [-0.12440 -0.62009  0.68029]]
20Nov23_011557|-- Bias --
20Nov23_011557|[-0.38219 -0.88277  0.64332]
20Nov23_011557|Layer 2:
20Nov23_011557|-- Config --
20Nov23_011557|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011557|-- Weights --
20Nov23_011557|[[-0.26708  0.46937  1.25164 -0.79851]
20Nov23_011557| [-0.22042 -0.90964  0.20610 -0.50982]
20Nov23_011557| [-0.57011  0.40682  0.33195 -0.63661]]
20Nov23_011557|-- Bias --
20Nov23_011557|[ 0.08651  0.38057 -0.52568  0.21822]
20Nov23_011557|Layer 3:
20Nov23_011557|-- Config --
20Nov23_011557|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_011557|-- Weights --
20Nov23_011557|[[-1.68151  0.96943]
20Nov23_011557| [-1.25774 -0.78998]
20Nov23_011557| [-1.35154  0.53538]
20Nov23_011557| [-0.05379 -0.72412]]
20Nov23_011557|-- Bias --
20Nov23_011557|[-0.07087 -0.43718]
20Nov23_011557|Predicting the validation and test data with the Best final individual.
20Nov23_011603| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_011603|-----------  ------------------  --------------------  ----------
20Nov23_011603|Validation         42.00                  30            0.00000
20Nov23_011603|   Test            36.40                  30            0.00000
Using Theano backend.
20Nov23_011604|Data summary: Train
20Nov23_011604|data.shape = (2300, 57)
20Nov23_011604|labels.shape = (2300,)
20Nov23_011604|Class distribution:
20Nov23_011604|	0 - 1389 (0.60)
20Nov23_011604|	1 - 911 (0.40)
20Nov23_011604|Data summary: Validation
20Nov23_011604|data.shape = (1150, 57)
20Nov23_011604|labels.shape = (1150,)
20Nov23_011604|Class distribution:
20Nov23_011604|	0 - 667 (0.58)
20Nov23_011604|	1 - 483 (0.42)
20Nov23_011604|Data summary: Test
20Nov23_011604|data.shape = (1151, 57)
20Nov23_011604|labels.shape = (1151,)
20Nov23_011604|Class distribution:
20Nov23_011604|	0 - 732 (0.64)
20Nov23_011604|	1 - 419 (0.36)
20Nov23_011604|Selected configuration values
20Nov23_011604|-- Dataset name: spambase2
20Nov23_011604|-- Initial population size: 64
20Nov23_011604|-- Maximun number of generations: 32
20Nov23_011604|-- Neurons per hidden layer range: (2, 20)
20Nov23_011604|-- Hidden layers number range: (1, 3)
20Nov23_011604|-- Crossover probability: 0.5
20Nov23_011604|-- Bias gene mutation probability: 0.2
20Nov23_011604|-- Weights gene mutation probability: 0.75
20Nov23_011604|-- Neuron mutation probability: 0.3
20Nov23_011604|-- Layer mutation probability: 0.3
20Nov23_011604|-- Constant hidden layers: False
20Nov23_011604|-- Seed: None
20Nov23_011604|Entering GA
20Nov23_011604|Start the algorithm
20Nov23_011921|-- Generation 1 --
20Nov23_011921|    -- Crossed 1 individual pairs.
20Nov23_011921|    -- Mutated 32 individuals.
20Nov23_012230|    -- Evaluated 64 individuals.
20Nov23_012230|    Summary of generation 1:
20Nov23_012230| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_012230|-----------  ------------------  --------------------  ----------
20Nov23_012230|    Max            58.00                111.00          0.83429
20Nov23_012230|    Avg            41.73                26.39           0.03679
20Nov23_012230|    Min            25.74                 2.00           0.00000
20Nov23_012230|    Std             3.35                21.38           0.15264
20Nov23_012230|   Best            25.74                42.00           0.83429
20Nov23_012230|-- Generation 2 --
20Nov23_012230|    -- Crossed 1 individual pairs.
20Nov23_012230|    -- Mutated 32 individuals.
20Nov23_012537|    -- Evaluated 64 individuals.
20Nov23_012537|    Summary of generation 2:
20Nov23_012537| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_012537|-----------  ------------------  --------------------  ----------
20Nov23_012537|    Max            57.91                111.00          0.80255
20Nov23_012537|    Avg            42.12                24.81           0.03924
20Nov23_012537|    Min            26.26                 2.00           0.00000
20Nov23_012537|    Std             2.96                25.61           0.16547
20Nov23_012537|   Best            26.26                40.00           0.76771
20Nov23_012537|-- Generation 3 --
20Nov23_012537|    -- Crossed 2 individual pairs.
20Nov23_012537|    -- Mutated 32 individuals.
20Nov23_012841|    -- Evaluated 64 individuals.
20Nov23_012841|    Summary of generation 3:
20Nov23_012841| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_012841|-----------  ------------------  --------------------  ----------
20Nov23_012841|    Max            42.09                168.00          0.02316
20Nov23_012841|    Avg            41.96                21.14           0.00242
20Nov23_012841|    Min            41.39                 2.00           0.00000
20Nov23_012841|    Std             0.11                29.92           0.00397
20Nov23_012841|   Best            41.39                 9.00           0.02316
20Nov23_012841|-- Generation 4 --
20Nov23_012841|    -- Crossed 0 individual pairs.
20Nov23_012841|    -- Mutated 32 individuals.
20Nov23_013145|    -- Evaluated 64 individuals.
20Nov23_013145|    Summary of generation 4:
20Nov23_013145| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_013145|-----------  ------------------  --------------------  ----------
20Nov23_013145|    Max            58.00                168.00          0.78384
20Nov23_013145|    Avg            42.66                24.58           0.04135
20Nov23_013145|    Min            39.04                 2.00           0.00000
20Nov23_013145|    Std             3.42                35.85           0.16577
20Nov23_013145|   Best            39.04                11.00           0.14399
20Nov23_013145|-- Generation 5 --
20Nov23_013145|    -- Crossed 1 individual pairs.
20Nov23_013145|    -- Mutated 32 individuals.
20Nov23_013448|    -- Evaluated 64 individuals.
20Nov23_013448|    Summary of generation 5:
20Nov23_013448| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_013448|-----------  ------------------  --------------------  ----------
20Nov23_013448|    Max            42.26                156.00          0.06098
20Nov23_013448|    Avg            41.96                22.20           0.00225
20Nov23_013448|    Min            40.96                 2.00           0.00000
20Nov23_013448|    Std             0.15                29.78           0.00770
20Nov23_013448|   Best            40.96                11.00           0.06098
20Nov23_013448|-- Generation 6 --
20Nov23_013448|    -- Crossed 6 individual pairs.
20Nov23_013448|    -- Mutated 32 individuals.
20Nov23_013753|    -- Evaluated 64 individuals.
20Nov23_013753|    Summary of generation 6:
20Nov23_013753| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_013753|-----------  ------------------  --------------------  ----------
20Nov23_013753|    Max            42.35                156.00          0.08376
20Nov23_013753|    Avg            41.95                24.80           0.00280
20Nov23_013753|    Min            39.57                 2.00           0.00000
20Nov23_013753|    Std             0.31                34.46           0.01045
20Nov23_013753|   Best            39.57                10.00           0.08376
20Nov23_013753|-- Generation 7 --
20Nov23_013753|    -- Crossed 3 individual pairs.
20Nov23_013753|    -- Mutated 32 individuals.
20Nov23_014054|    -- Evaluated 64 individuals.
20Nov23_014054|    Summary of generation 7:
20Nov23_014054| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_014054|-----------  ------------------  --------------------  ----------
20Nov23_014054|    Max            42.09                114.00          0.69550
20Nov23_014054|    Avg            41.79                17.67           0.01288
20Nov23_014054|    Min            31.48                 2.00           0.00000
20Nov23_014054|    Std             1.31                25.40           0.08617
20Nov23_014054|   Best            31.48                38.00           0.69550
20Nov23_014054|-- Generation 8 --
20Nov23_014054|    -- Crossed 4 individual pairs.
20Nov23_014054|    -- Mutated 32 individuals.
20Nov23_014359|    -- Evaluated 64 individuals.
20Nov23_014359|    Summary of generation 8:
20Nov23_014359| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_014359|-----------  ------------------  --------------------  ----------
20Nov23_014359|    Max            58.00                114.00          0.78358
20Nov23_014359|    Avg            42.21                25.73           0.01474
20Nov23_014359|    Min            41.48                 2.00           0.00000
20Nov23_014359|    Std             1.99                31.18           0.09696
20Nov23_014359|   Best            41.48                10.00           0.02315
20Nov23_014359|-- Generation 9 --
20Nov23_014359|    -- Crossed 4 individual pairs.
20Nov23_014359|    -- Mutated 32 individuals.
20Nov23_014706|    -- Evaluated 64 individuals.
20Nov23_014706|    Summary of generation 9:
20Nov23_014706| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_014706|-----------  ------------------  --------------------  ----------
20Nov23_014706|    Max            58.00                114.00          0.78358
20Nov23_014706|    Avg            42.22                27.91           0.01542
20Nov23_014706|    Min            41.04                 2.00           0.00000
20Nov23_014706|    Std             2.00                28.96           0.09697
20Nov23_014706|   Best            41.04                11.00           0.04096
20Nov23_014706|-- Generation 10 --
20Nov23_014706|    -- Crossed 4 individual pairs.
20Nov23_014706|    -- Mutated 32 individuals.
20Nov23_015009|    -- Evaluated 64 individuals.
20Nov23_015009|    Summary of generation 10:
20Nov23_015009| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_015009|-----------  ------------------  --------------------  ----------
20Nov23_015009|    Max            58.00                111.00          0.78358
20Nov23_015009|    Avg            42.16                19.39           0.01658
20Nov23_015009|    Min            40.17                 2.00           0.00000
20Nov23_015009|    Std             2.01                22.10           0.09722
20Nov23_015009|   Best            40.17                11.00           0.07610
20Nov23_015009|-- Generation 11 --
20Nov23_015009|    -- Crossed 2 individual pairs.
20Nov23_015009|    -- Mutated 32 individuals.
20Nov23_015315|    -- Evaluated 64 individuals.
20Nov23_015315|    Summary of generation 11:
20Nov23_015315| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_015315|-----------  ------------------  --------------------  ----------
20Nov23_015315|    Max            42.17                168.00          0.19569
20Nov23_015315|    Avg            41.77                23.23           0.01047
20Nov23_015315|    Min            37.83                 2.00           0.00000
20Nov23_015315|    Std             0.75                26.32           0.03404
20Nov23_015315|   Best            37.83                10.00           0.19118
20Nov23_015315|-- Generation 12 --
20Nov23_015315|    -- Crossed 3 individual pairs.
20Nov23_015315|    -- Mutated 32 individuals.
20Nov23_015621|    -- Evaluated 64 individuals.
20Nov23_015621|    Summary of generation 12:
20Nov23_015621| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_015621|-----------  ------------------  --------------------  ----------
20Nov23_015621|    Max            42.35                160.00          0.07856
20Nov23_015621|    Avg            41.90                22.16           0.00605
20Nov23_015621|    Min            40.17                 2.00           0.00000
20Nov23_015621|    Std             0.32                25.06           0.01336
20Nov23_015621|   Best            40.17                11.00           0.07856
20Nov23_015621|-- Generation 13 --
20Nov23_015621|    -- Crossed 5 individual pairs.
20Nov23_015621|    -- Mutated 32 individuals.
20Nov23_015928|    -- Evaluated 64 individuals.
20Nov23_015928|    Summary of generation 13:
20Nov23_015928| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_015928|-----------  ------------------  --------------------  ----------
20Nov23_015928|    Max            42.35                111.00          0.34742
20Nov23_015928|    Avg            41.79                22.45           0.00993
20Nov23_015928|    Min            33.48                 6.00           0.00000
20Nov23_015928|    Std             1.07                17.24           0.04343
20Nov23_015928|   Best            33.48                13.00           0.34742
20Nov23_015928|-- Generation 14 --
20Nov23_015928|    -- Crossed 2 individual pairs.
20Nov23_015928|    -- Mutated 32 individuals.
20Nov23_020233|    -- Evaluated 64 individuals.
20Nov23_020233|    Summary of generation 14:
20Nov23_020233| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_020233|-----------  ------------------  --------------------  ----------
20Nov23_020233|    Max            58.00                111.00          0.81901
20Nov23_020233|    Avg            42.01                21.06           0.03669
20Nov23_020233|    Min            36.43                 6.00           0.00000
20Nov23_020233|    Std             2.16                19.18           0.14247
20Nov23_020233|   Best            36.43                 9.00           0.27407
20Nov23_020233|-- Generation 15 --
20Nov23_020233|    -- Crossed 2 individual pairs.
20Nov23_020233|    -- Mutated 32 individuals.
20Nov23_020537|    -- Evaluated 64 individuals.
20Nov23_020537|    Summary of generation 15:
20Nov23_020537| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_020537|-----------  ------------------  --------------------  ----------
20Nov23_020537|    Max            58.00                111.00          0.78358
20Nov23_020537|    Avg            42.07                18.88           0.02023
20Nov23_020537|    Min            39.22                 6.00           0.00000
20Nov23_020537|    Std             2.05                18.86           0.09834
20Nov23_020537|   Best            39.22                11.00           0.13917
20Nov23_020537|-- Generation 16 --
20Nov23_020537|    -- Crossed 3 individual pairs.
20Nov23_020537|    -- Mutated 32 individuals.
20Nov23_020840|    -- Evaluated 64 individuals.
20Nov23_020840|    Summary of generation 16:
20Nov23_020840| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_020840|-----------  ------------------  --------------------  ----------
20Nov23_020840|    Max            58.00                111.00          0.78358
20Nov23_020840|    Avg            42.05                18.77           0.02304
20Nov23_020840|    Min            39.22                 6.00           0.00000
20Nov23_020840|    Std             2.08                18.47           0.10041
20Nov23_020840|   Best            39.22                11.00           0.16240
20Nov23_020840|-- Generation 17 --
20Nov23_020840|    -- Crossed 6 individual pairs.
20Nov23_020840|    -- Mutated 32 individuals.
20Nov23_021144|    -- Evaluated 64 individuals.
20Nov23_021144|    Summary of generation 17:
20Nov23_021144| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_021144|-----------  ------------------  --------------------  ----------
20Nov23_021144|    Max            57.91                111.00          0.78161
20Nov23_021144|    Avg            42.06                17.28           0.02192
20Nov23_021144|    Min            35.74                 6.00           0.00000
20Nov23_021144|    Std             2.14                15.51           0.10572
20Nov23_021144|   Best            35.74                30.00           0.36305
20Nov23_021144|-- Generation 18 --
20Nov23_021144|    -- Crossed 5 individual pairs.
20Nov23_021144|    -- Mutated 32 individuals.
20Nov23_021449|    -- Evaluated 64 individuals.
20Nov23_021449|    Summary of generation 18:
20Nov23_021449| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_021449|-----------  ------------------  --------------------  ----------
20Nov23_021449|    Max            42.43                111.00          0.53484
20Nov23_021449|    Avg            41.54                18.70           0.01934
20Nov23_021449|    Min            28.00                 7.00           0.00000
20Nov23_021449|    Std             1.84                18.97           0.07253
20Nov23_021449|   Best            28.00                34.00           0.53484
20Nov23_021449|-- Generation 19 --
20Nov23_021449|    -- Crossed 2 individual pairs.
20Nov23_021449|    -- Mutated 32 individuals.
20Nov23_021753|    -- Evaluated 64 individuals.
20Nov23_021753|    Summary of generation 19:
20Nov23_021753| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_021753|-----------  ------------------  --------------------  ----------
20Nov23_021753|    Max            42.43                111.00          0.10045
20Nov23_021753|    Avg            41.91                18.64           0.00587
20Nov23_021753|    Min            40.17                 7.00           0.00000
20Nov23_021753|    Std             0.36                19.53           0.01509
20Nov23_021753|   Best            40.17                11.00           0.10045
20Nov23_021753|-- Generation 20 --
20Nov23_021753|    -- Crossed 4 individual pairs.
20Nov23_021753|    -- Mutated 32 individuals.
20Nov23_022055|    -- Evaluated 64 individuals.
20Nov23_022055|    Summary of generation 20:
20Nov23_022055| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_022055|-----------  ------------------  --------------------  ----------
20Nov23_022055|    Max            42.17                111.00          0.20823
20Nov23_022055|    Avg            41.78                16.48           0.01060
20Nov23_022055|    Min            38.61                 7.00           0.00000
20Nov23_022055|    Std             0.55                18.38           0.02816
20Nov23_022055|   Best            38.61                 8.00           0.20823
20Nov23_022055|-- Generation 21 --
20Nov23_022055|    -- Crossed 4 individual pairs.
20Nov23_022055|    -- Mutated 32 individuals.
20Nov23_022357|    -- Evaluated 64 individuals.
20Nov23_022357|    Summary of generation 21:
20Nov23_022357| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_022357|-----------  ------------------  --------------------  ----------
20Nov23_022357|    Max            42.26                111.00          0.06599
20Nov23_022357|    Avg            41.87                16.92           0.00562
20Nov23_022357|    Min            40.78                 7.00           0.00000
20Nov23_022357|    Std             0.24                18.83           0.01012
20Nov23_022357|   Best            40.78                11.00           0.06599
20Nov23_022357|-- Generation 22 --
20Nov23_022357|    -- Crossed 7 individual pairs.
20Nov23_022357|    -- Mutated 32 individuals.
20Nov23_022658|    -- Evaluated 64 individuals.
20Nov23_022658|    Summary of generation 22:
20Nov23_022658| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_022658|-----------  ------------------  --------------------  ----------
20Nov23_022658|    Max            51.39                164.00          0.79659
20Nov23_022658|    Avg            42.04                15.66           0.01922
20Nov23_022658|    Min            40.35                 6.00           0.00000
20Nov23_022658|    Std             1.22                22.82           0.09934
20Nov23_022658|   Best            40.35                 9.00           0.11946
20Nov23_022658|-- Generation 23 --
20Nov23_022658|    -- Crossed 4 individual pairs.
20Nov23_022658|    -- Mutated 32 individuals.
20Nov23_023000|    -- Evaluated 64 individuals.
20Nov23_023000|    Summary of generation 23:
20Nov23_023000| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_023000|-----------  ------------------  --------------------  ----------
20Nov23_023000|    Max            42.26                111.00          0.17140
20Nov23_023000|    Avg            41.81                16.22           0.00957
20Nov23_023000|    Min            39.39                 6.00           0.00000
20Nov23_023000|    Std             0.46                18.17           0.02649
20Nov23_023000|   Best            39.39                10.00           0.17140
20Nov23_023000|-- Generation 24 --
20Nov23_023000|    -- Crossed 5 individual pairs.
20Nov23_023000|    -- Mutated 32 individuals.
20Nov23_023302|    -- Evaluated 64 individuals.
20Nov23_023302|    Summary of generation 24:
20Nov23_023302| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_023302|-----------  ------------------  --------------------  ----------
20Nov23_023302|    Max            42.70                111.00          0.47191
20Nov23_023302|    Avg            41.69                16.48           0.01727
20Nov23_023302|    Min            34.70                 6.00           0.00000
20Nov23_023302|    Std             1.05                18.39           0.06342
20Nov23_023302|   Best            34.70                 9.00           0.47191
20Nov23_023302|-- Generation 25 --
20Nov23_023302|    -- Crossed 4 individual pairs.
20Nov23_023302|    -- Mutated 32 individuals.
20Nov23_023606|    -- Evaluated 64 individuals.
20Nov23_023606|    Summary of generation 25:
20Nov23_023606| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_023606|-----------  ------------------  --------------------  ----------
20Nov23_023606|    Max            42.17                111.00          0.01803
20Nov23_023606|    Avg            41.92                18.45           0.00375
20Nov23_023606|    Min            41.57                 6.00           0.00000
20Nov23_023606|    Std             0.12                17.87           0.00381
20Nov23_023606|   Best            41.57                11.00           0.01803
20Nov23_023606|-- Generation 26 --
20Nov23_023606|    -- Crossed 1 individual pairs.
20Nov23_023606|    -- Mutated 32 individuals.
20Nov23_023911|    -- Evaluated 64 individuals.
20Nov23_023911|    Summary of generation 26:
20Nov23_023911| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_023911|-----------  ------------------  --------------------  ----------
20Nov23_023911|    Max            42.17                156.00          0.06619
20Nov23_023911|    Avg            41.82                18.83           0.00643
20Nov23_023911|    Min            40.26                 5.00           0.00000
20Nov23_023911|    Std             0.29                22.03           0.01114
20Nov23_023911|   Best            40.26                11.00           0.06619
20Nov23_023911|-- Generation 27 --
20Nov23_023911|    -- Crossed 3 individual pairs.
20Nov23_023911|    -- Mutated 32 individuals.
20Nov23_024217|    -- Evaluated 64 individuals.
20Nov23_024217|    Summary of generation 27:
20Nov23_024217| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_024217|-----------  ------------------  --------------------  ----------
20Nov23_024217|    Max            42.26                156.00          0.06626
20Nov23_024217|    Avg            41.81                19.81           0.00716
20Nov23_024217|    Min            40.09                 5.00           0.00000
20Nov23_024217|    Std             0.28                21.85           0.01026
20Nov23_024217|   Best            40.09                11.00           0.06626
20Nov23_024217|-- Generation 28 --
20Nov23_024217|    -- Crossed 6 individual pairs.
20Nov23_024217|    -- Mutated 32 individuals.
20Nov23_024525|    -- Evaluated 64 individuals.
20Nov23_024525|    Summary of generation 28:
20Nov23_024525| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_024525|-----------  ------------------  --------------------  ----------
20Nov23_024525|    Max            42.17                111.00          0.13621
20Nov23_024525|    Avg            41.81                21.66           0.00802
20Nov23_024525|    Min            40.00                 6.00           0.00000
20Nov23_024525|    Std             0.27                18.64           0.01685
20Nov23_024525|   Best            40.00                11.00           0.13621
20Nov23_024525|-- Generation 29 --
20Nov23_024525|    -- Crossed 4 individual pairs.
20Nov23_024525|    -- Mutated 32 individuals.
20Nov23_024831|    -- Evaluated 64 individuals.
20Nov23_024831|    Summary of generation 29:
20Nov23_024831| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_024831|-----------  ------------------  --------------------  ----------
20Nov23_024831|    Max            42.35                114.00          0.38586
20Nov23_024831|    Avg            41.72                19.34           0.01140
20Nov23_024831|    Min            33.13                 5.00           0.00000
20Nov23_024831|    Std             1.10                18.51           0.04741
20Nov23_024831|   Best            33.13                11.00           0.38586
20Nov23_024831|-- Generation 30 --
20Nov23_024831|    -- Crossed 3 individual pairs.
20Nov23_024831|    -- Mutated 32 individuals.
20Nov23_025137|    -- Evaluated 64 individuals.
20Nov23_025137|    Summary of generation 30:
20Nov23_025137| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_025137|-----------  ------------------  --------------------  ----------
20Nov23_025137|    Max            42.96                168.00          0.05346
20Nov23_025137|    Avg            41.81                20.95           0.00815
20Nov23_025137|    Min            40.78                 6.00           0.00000
20Nov23_025137|    Std             0.24                23.41           0.01000
20Nov23_025137|   Best            40.78                11.00           0.04103
20Nov23_025137|-- Generation 31 --
20Nov23_025137|    -- Crossed 3 individual pairs.
20Nov23_025137|    -- Mutated 32 individuals.
20Nov23_025444|    -- Evaluated 64 individuals.
20Nov23_025444|    Summary of generation 31:
20Nov23_025444| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_025444|-----------  ------------------  --------------------  ----------
20Nov23_025444|    Max            42.17                111.00          0.16551
20Nov23_025444|    Avg            41.72                21.80           0.01079
20Nov23_025444|    Min            38.35                 9.00           0.00000
20Nov23_025444|    Std             0.51                20.00           0.02189
20Nov23_025444|   Best            38.35                11.00           0.16551
20Nov23_025444|-- Generation 32 --
20Nov23_025444|    -- Crossed 4 individual pairs.
20Nov23_025444|    -- Mutated 32 individuals.
20Nov23_025751|    -- Evaluated 64 individuals.
20Nov23_025751|    Summary of generation 32:
20Nov23_025751| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_025751|-----------  ------------------  --------------------  ----------
20Nov23_025751|    Max            43.39                60.00           0.82684
20Nov23_025751|    Avg            41.62                20.61           0.02850
20Nov23_025751|    Min            38.09                 8.00           0.00000
20Nov23_025751|    Std             0.85                11.34           0.10669
20Nov23_025751|   Best            38.09                28.00           0.21991
20Nov23_025751|Best initial individual weights
20Nov23_025751|Individual:
20Nov23_025751|-- Constant hidden layers --
20Nov23_025751|False
20Nov23_025751|Layer 0:
20Nov23_025751|-- Config --
20Nov23_025751|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 16, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025751|-- Weights --
20Nov23_025751|[[ 1.73956e-01 -4.65401e-01 -4.56701e-03  3.16851e-01 -4.27271e-01
20Nov23_025751|  -5.25215e-02  6.01355e-01  6.87351e-01  8.87619e-02  5.83911e-01
20Nov23_025751|  -5.97452e-01 -1.38018e-02  3.51245e-01  3.66644e-01 -6.88821e-01
20Nov23_025751|  -5.70015e-01]
20Nov23_025751| [ 7.14734e-01 -1.09634e-02 -7.90613e-01 -5.85218e-01  6.24676e-01
20Nov23_025751|  -4.88964e-01 -7.41573e-01 -8.17728e-01 -8.24696e-01 -5.70541e-01
20Nov23_025751|   9.08208e-01 -9.87625e-01  7.83034e-01  7.30272e-01  9.62697e-01
20Nov23_025751|   6.35041e-01]
20Nov23_025751| [ 6.90553e-01 -5.13146e-01  9.62877e-01 -4.46772e-01  7.05525e-01
20Nov23_025751|  -7.44939e-01 -7.76087e-01 -1.00246e-01  8.75466e-02 -4.01657e-01
20Nov23_025751|  -7.89482e-01  1.20878e-01  1.62295e-01  8.29937e-01  3.15945e-01
20Nov23_025751|  -2.74442e-01]
20Nov23_025751| [ 3.86053e-01 -5.34502e-02  3.19891e-01 -4.80265e-01 -1.44718e-01
20Nov23_025751|  -2.09452e-01  6.29077e-01  7.19999e-02 -9.74607e-02  1.03949e-01
20Nov23_025751|   9.58360e-02 -4.83753e-02 -4.35930e-01 -4.07141e-01 -1.73296e-01
20Nov23_025751|   3.59512e-02]
20Nov23_025751| [-2.46353e-01 -5.00801e-01  9.91958e-01  3.24939e-01  4.85348e-01
20Nov23_025751|  -4.58235e-01 -7.22744e-01 -8.54055e-02  7.22772e-01 -1.14755e-01
20Nov23_025751|  -4.15384e-02 -6.05458e-01  6.96288e-01  2.11952e-01  5.94493e-01
20Nov23_025751|   9.70926e-01]
20Nov23_025751| [ 7.83020e-01 -3.11180e-01 -1.02753e-01  7.78968e-01  7.92994e-01
20Nov23_025751|  -6.21612e-01  5.44801e-01  6.31116e-01  7.21598e-01 -4.93997e-01
20Nov23_025751|   2.63038e-01  5.83562e-01 -5.46054e-01 -3.56212e-02  4.46514e-01
20Nov23_025751|   4.29669e-01]
20Nov23_025751| [ 5.92994e-01 -4.61564e-01  3.40532e-01  8.55809e-01  3.18096e-02
20Nov23_025751|   6.26107e-01  7.38279e-01  4.03781e-01 -4.99314e-01  1.64403e-01
20Nov23_025751|  -9.59646e-01 -2.80496e-01 -1.04850e-01 -4.07098e-02  8.93975e-01
20Nov23_025751|   7.34608e-01]
20Nov23_025751| [-5.16763e-01 -9.39363e-02  1.58109e-01  8.74615e-02  5.34623e-01
20Nov23_025751|   1.42082e-01 -6.44715e-01 -9.25673e-01  4.19879e-01 -5.60136e-01
20Nov23_025751|  -8.24044e-02  9.47742e-01 -7.93994e-01 -4.15087e-01  3.73101e-01
20Nov23_025751|   1.03033e-02]
20Nov23_025751| [-9.33312e-01  9.32349e-01  7.37522e-01 -7.33186e-01  2.83711e-01
20Nov23_025751|  -1.82512e-01  9.43603e-01 -4.82876e-01 -5.35475e-01  2.87492e-01
20Nov23_025751|  -3.30484e-01  2.38413e-01 -5.83285e-01  4.72450e-01  1.78932e-01
20Nov23_025751|  -8.76129e-01]
20Nov23_025751| [-1.41289e-01  1.81662e-01 -3.95766e-01 -8.40131e-01  9.40445e-01
20Nov23_025751|   1.75215e-01 -2.75149e-01 -9.54258e-01 -7.15655e-01  2.34501e-01
20Nov23_025751|   9.86081e-01  4.57001e-01 -4.57607e-01  2.08712e-02  2.24917e-01
20Nov23_025751|  -2.13670e-01]
20Nov23_025751| [ 7.25356e-01  2.85525e-01 -4.81141e-01  7.58063e-01 -8.00054e-01
20Nov23_025751|   2.74404e-01  3.08326e-01  1.77319e-03  5.72942e-01 -5.82176e-01
20Nov23_025751|  -7.66789e-01 -9.85161e-01  8.01284e-01  7.10673e-01  4.73307e-01
20Nov23_025751|  -3.09300e-01]
20Nov23_025751| [-7.90699e-01 -9.15490e-03  7.86469e-01  4.13904e-01 -3.79833e-01
20Nov23_025751|  -9.16997e-01  6.23456e-01  9.59226e-01 -2.14426e-01  6.38662e-01
20Nov23_025751|   5.91755e-01 -2.86189e-01 -9.34684e-01  4.62671e-01 -9.99953e-01
20Nov23_025751|   8.43650e-01]
20Nov23_025751| [ 9.94964e-01 -3.26017e-01  7.12058e-01 -4.19734e-01 -7.18752e-01
20Nov23_025751|  -7.86105e-01  2.89534e-01 -7.12466e-01 -8.35654e-01 -7.68778e-01
20Nov23_025751|  -4.47586e-01  4.40521e-01  1.87964e-01  4.25877e-01  4.32429e-01
20Nov23_025751|  -4.45055e-01]
20Nov23_025751| [ 3.64155e-01 -4.35854e-01  1.96846e-01 -8.77402e-01 -3.82254e-01
20Nov23_025751|  -1.50379e-01 -8.49602e-02 -7.70685e-01 -4.18218e-01 -6.83705e-02
20Nov23_025751|   8.90634e-01  5.58892e-01 -9.67628e-01  7.57156e-01 -9.35911e-01
20Nov23_025751|   6.79294e-01]
20Nov23_025751| [ 8.22645e-01  6.21449e-01  8.98100e-01 -7.39648e-01 -5.99242e-01
20Nov23_025751|   1.36252e-01 -3.86496e-01 -2.45102e-01  9.94770e-02  7.03075e-01
20Nov23_025751|  -5.01063e-01  9.09317e-01 -5.91393e-01 -9.65658e-01 -4.28839e-01
20Nov23_025751|  -5.07182e-01]
20Nov23_025751| [-9.71315e-01  9.20142e-01 -2.00600e-01 -7.32802e-01 -9.81076e-02
20Nov23_025751|   9.87520e-01 -5.89811e-01 -6.09725e-01  2.61152e-01 -6.37554e-01
20Nov23_025751|  -6.54965e-01 -5.74720e-01 -5.75647e-01  2.89632e-01  9.04015e-01
20Nov23_025751|  -7.91712e-01]
20Nov23_025751| [-3.22763e-02 -5.88855e-01 -1.38839e-01 -2.93844e-01  4.31771e-01
20Nov23_025751|  -9.16011e-01  3.72629e-01  5.42883e-02  6.74699e-02  9.62030e-01
20Nov23_025751|   2.61476e-01 -1.70482e-01  9.33896e-01  7.81781e-01  7.93165e-01
20Nov23_025751|   2.29677e-01]
20Nov23_025751| [-8.76731e-01  2.42913e-01  9.31465e-01 -8.31775e-01 -5.26384e-01
20Nov23_025751|  -1.41061e-02 -3.16223e-01  4.38946e-01 -4.99536e-01  8.91180e-01
20Nov23_025751|  -4.35164e-01 -7.20327e-01  3.12582e-01 -5.08698e-01  5.92562e-01
20Nov23_025751|   9.56916e-04]
20Nov23_025751| [-1.60549e-01  7.52358e-01 -7.81061e-01  3.96697e-01 -5.49881e-01
20Nov23_025751|   1.10640e-02 -6.93394e-01  4.31169e-01  4.65157e-01 -3.12753e-01
20Nov23_025751|   2.85878e-01 -2.05997e-01  2.62619e-01  8.63134e-02 -8.60537e-01
20Nov23_025751|   2.29647e-01]
20Nov23_025751| [-3.14211e-01 -7.82970e-01 -1.67329e-01  6.82700e-02 -4.23811e-01
20Nov23_025751|   5.23817e-01 -5.39437e-01 -2.64401e-01 -7.93494e-01  2.31497e-02
20Nov23_025751|  -4.71729e-01 -8.99599e-01  4.51595e-01  9.55753e-01  1.52828e-01
20Nov23_025751|   8.61329e-01]
20Nov23_025751| [-9.57922e-01 -2.70540e-02 -9.09896e-01  8.66186e-01 -3.39321e-01
20Nov23_025751|  -2.54354e-01  9.95235e-01  5.22519e-01  4.45213e-01  5.02240e-01
20Nov23_025751|   2.65464e-01  1.95988e-01 -9.41648e-03  1.82852e-02 -1.77841e-01
20Nov23_025751|   7.70425e-01]
20Nov23_025751| [-8.28842e-01 -7.49512e-02 -7.26529e-01 -9.82435e-01 -7.50408e-02
20Nov23_025751|  -6.83221e-01 -4.30182e-01  5.91734e-03  9.39001e-01 -6.46343e-01
20Nov23_025751|   4.63914e-01  6.88062e-01 -5.11306e-03  5.43953e-01  4.29080e-01
20Nov23_025751|   5.65409e-01]
20Nov23_025751| [ 2.93267e-01  8.38475e-01  1.70811e-01 -1.40603e-01  2.89286e-01
20Nov23_025751|  -9.76853e-01 -6.21269e-01 -3.50279e-02  3.74424e-01  8.66226e-01
20Nov23_025751|   8.03490e-01 -7.73577e-01 -3.54433e-02 -3.62964e-01 -1.19127e-01
20Nov23_025751|  -7.46261e-01]
20Nov23_025751| [ 6.42393e-01 -8.86295e-01 -6.22272e-01 -2.94168e-01  9.44822e-01
20Nov23_025751|  -6.63463e-01 -7.56584e-01  1.49569e-01  5.76432e-01  7.68301e-01
20Nov23_025751|  -1.23257e-01 -8.35304e-01 -7.80086e-01  8.69834e-01  6.96618e-01
20Nov23_025751|  -8.86260e-01]
20Nov23_025751| [-8.82200e-01 -6.16439e-01 -2.22874e-01  3.14831e-01 -9.17582e-01
20Nov23_025751|   3.36518e-01 -9.20860e-01 -9.21501e-01 -2.35927e-02  8.98157e-01
20Nov23_025751|   1.89455e-01  6.05349e-01  9.23774e-01  3.20757e-01 -6.24851e-01
20Nov23_025751|  -2.01754e-01]
20Nov23_025751| [-3.59290e-01 -1.17456e-01 -8.07189e-01 -1.72504e-01 -1.35150e-01
20Nov23_025751|   1.94767e-01 -4.01073e-01 -7.64757e-01 -5.02269e-01 -6.01928e-01
20Nov23_025751|   2.80044e-01  9.10876e-01  2.73654e-01  5.99159e-01  9.77315e-01
20Nov23_025751|   9.57823e-01]
20Nov23_025751| [-3.60585e-01 -3.72636e-01  4.61201e-01  3.41680e-01 -1.80789e-03
20Nov23_025751|  -3.76626e-01 -3.61899e-01  1.43631e-02  7.27285e-01 -6.43303e-02
20Nov23_025751|  -5.07258e-01 -6.53486e-01  7.51899e-01  4.40106e-01  8.06714e-01
20Nov23_025751|  -4.85718e-01]
20Nov23_025751| [-8.19103e-01  1.75952e-01  3.81360e-01  2.10843e-02 -1.97008e-01
20Nov23_025751|  -3.77250e-01 -9.65209e-01 -8.88226e-01  4.37619e-01 -7.11198e-01
20Nov23_025751|  -3.21499e-01  7.76223e-01  6.68238e-02  2.61962e-02 -7.21735e-01
20Nov23_025751|  -7.22351e-01]
20Nov23_025751| [-8.99714e-01 -7.58264e-02  5.00882e-01 -5.08914e-01 -7.33604e-01
20Nov23_025751|  -9.01085e-01  4.92045e-01 -1.21607e-01 -1.02726e-02  4.10117e-01
20Nov23_025751|   2.11173e-01 -3.60410e-01  8.64786e-01  4.43480e-01  3.30418e-01
20Nov23_025751|  -9.35650e-01]
20Nov23_025751| [-2.83110e-01 -8.95196e-01  4.26776e-01 -1.41333e-01 -8.79835e-01
20Nov23_025751|  -9.10714e-01 -5.80683e-01 -3.27639e-01 -3.31929e-01 -1.46207e-01
20Nov23_025751|   5.92806e-01  5.75936e-01  7.13206e-01  8.00900e-01 -5.02512e-01
20Nov23_025751|  -6.26163e-01]
20Nov23_025751| [ 8.29750e-02  5.13378e-01  5.74759e-01 -9.77868e-01  6.40914e-01
20Nov23_025751|  -3.98640e-01  5.82398e-01  7.12203e-01  9.59668e-02  9.33142e-01
20Nov23_025751|   9.23490e-02 -8.67209e-01  6.37893e-01 -9.95935e-02  3.29428e-01
20Nov23_025751|   9.02390e-01]
20Nov23_025751| [ 8.04512e-01 -5.03814e-01 -1.55528e-01 -4.43438e-01  2.11975e-01
20Nov23_025751|  -2.50980e-01  1.94347e-01 -1.87796e-02 -7.04803e-01  1.91559e-01
20Nov23_025751|  -2.87944e-01  8.54649e-01  9.26274e-01  2.54066e-01  1.36941e-01
20Nov23_025751|   8.60777e-01]
20Nov23_025751| [-4.92380e-01  9.73642e-01 -4.08785e-01  8.39487e-01 -6.94324e-01
20Nov23_025751|   3.11618e-01  7.17549e-01  7.63871e-02  4.03937e-01  4.76543e-03
20Nov23_025751|  -4.23605e-01 -8.84960e-01  2.56779e-01 -7.20629e-01  6.28957e-01
20Nov23_025751|  -9.54407e-01]
20Nov23_025751| [ 9.60570e-01 -6.01551e-01  5.38304e-01  5.82605e-01 -9.25638e-01
20Nov23_025751|   1.55068e-01 -9.94401e-01 -7.11062e-02  9.88021e-01 -1.87318e-01
20Nov23_025751|  -3.91230e-01 -5.20382e-02 -8.13076e-01 -3.36713e-01 -9.83575e-01
20Nov23_025751|  -8.95021e-01]
20Nov23_025751| [-3.94732e-01  8.57499e-01 -9.73132e-01  5.35268e-01  2.93753e-01
20Nov23_025751|  -5.82149e-01 -7.75761e-01 -4.78065e-01 -7.11912e-01  6.41913e-01
20Nov23_025751|  -7.31533e-01  2.17992e-01 -9.70637e-01 -4.95428e-01 -7.03250e-01
20Nov23_025751|  -7.31042e-01]
20Nov23_025751| [-8.37754e-01 -5.59322e-01  4.25940e-01  7.62605e-01  6.69767e-01
20Nov23_025751|   6.76535e-01 -1.66495e-03 -4.35360e-01  1.23019e-01  8.07226e-01
20Nov23_025751|  -6.98993e-01  5.93672e-01 -9.85090e-01  1.57373e-02 -9.18462e-01
20Nov23_025751|   2.13820e-01]
20Nov23_025751| [ 3.81644e-01 -5.25973e-01 -5.70455e-01  8.84543e-01  2.16344e-02
20Nov23_025751|  -4.15012e-01  3.75571e-01  5.81646e-01  2.08331e-01 -9.45887e-01
20Nov23_025751|  -3.66833e-01  1.79439e-01  9.75071e-01 -3.65976e-01  2.02871e-01
20Nov23_025751|  -5.25061e-01]
20Nov23_025751| [ 9.82516e-01 -6.20723e-01  7.00664e-01 -2.47958e-01 -4.82949e-01
20Nov23_025751|   5.84586e-01 -7.46416e-02 -6.72037e-01  6.43718e-01  1.93653e-01
20Nov23_025751|  -6.40268e-01 -4.10079e-01 -3.70526e-01 -5.73523e-01  2.41458e-01
20Nov23_025751|   2.68595e-01]
20Nov23_025751| [ 9.59540e-01 -5.73291e-01 -5.69436e-01 -7.63575e-01 -6.49689e-01
20Nov23_025751|  -4.13435e-01 -9.96243e-01  4.70853e-01  7.57693e-01  7.64780e-03
20Nov23_025751|  -2.35671e-01  7.63834e-01  8.28462e-01 -4.04463e-01 -6.62258e-01
20Nov23_025751|  -3.87188e-02]
20Nov23_025751| [-3.65269e-01 -8.81753e-02  1.72796e-01 -4.13549e-01 -7.48433e-02
20Nov23_025751|  -8.79849e-01  5.95828e-01  1.30323e-01  2.71003e-01  2.31327e-01
20Nov23_025751|   1.14448e-01  3.47129e-01  5.24549e-01 -6.35163e-01 -3.74723e-01
20Nov23_025751|   7.97166e-01]
20Nov23_025751| [ 8.95318e-01 -8.94873e-01 -4.16635e-01  4.74004e-01 -8.09307e-02
20Nov23_025751|   5.88749e-01 -4.08678e-01  4.49468e-01  2.61787e-01 -7.29568e-01
20Nov23_025751|  -4.31153e-01 -1.94555e-01  6.60365e-01  5.62178e-01  3.45479e-01
20Nov23_025751|   7.44496e-01]
20Nov23_025751| [ 9.13978e-01  1.79673e-01 -4.50467e-01  4.21244e-01 -6.25304e-02
20Nov23_025751|  -6.85339e-01  6.49823e-01 -2.68630e-01 -8.39526e-02 -5.32967e-02
20Nov23_025751|  -3.37626e-02  4.87395e-01 -3.38564e-01 -2.00089e-01 -3.24336e-01
20Nov23_025751|   5.32037e-02]
20Nov23_025751| [ 7.88323e-01 -8.47466e-01 -7.28323e-01 -7.79272e-01  3.49061e-01
20Nov23_025751|  -4.38630e-01  6.46586e-01 -1.12118e-01  2.80694e-02 -6.73052e-01
20Nov23_025751|   3.00658e-01 -4.16926e-01 -5.06235e-02 -6.16957e-01 -5.40005e-01
20Nov23_025751|  -1.20233e-01]
20Nov23_025751| [ 4.23961e-01  4.12406e-01  7.97474e-01 -5.21509e-01  8.11675e-02
20Nov23_025751|  -8.39250e-01  8.86227e-01 -5.96994e-01  2.91381e-01 -8.92151e-02
20Nov23_025751|   4.11959e-01 -1.94292e-01 -3.29518e-01  5.54415e-01  5.70520e-01
20Nov23_025751|  -9.83038e-02]
20Nov23_025751| [ 8.14237e-01 -5.69234e-01  5.64992e-02  7.93664e-01  9.05735e-01
20Nov23_025751|  -4.94695e-01  5.34087e-02 -6.18002e-01 -1.54732e-01 -8.62847e-01
20Nov23_025751|  -6.72599e-01 -4.93906e-01  1.09041e-02  7.23733e-01 -6.62684e-02
20Nov23_025751|   8.01939e-01]
20Nov23_025751| [-5.25639e-01 -9.38082e-01  2.15296e-01  8.34982e-01 -9.85372e-01
20Nov23_025751|  -9.68670e-01 -3.63268e-01 -9.59304e-01  2.71793e-01 -6.00039e-01
20Nov23_025751|  -5.71272e-01  9.49384e-01 -7.71525e-01 -8.64634e-02 -1.68907e-01
20Nov23_025751|  -3.13320e-01]
20Nov23_025751| [-8.78664e-01 -8.09813e-01  3.97395e-01  5.25145e-01 -1.13660e-01
20Nov23_025751|  -8.85067e-01 -3.17220e-01 -6.83477e-01 -1.01815e-01 -8.17415e-01
20Nov23_025751|   9.01608e-01 -3.48089e-01  5.75384e-01  2.09123e-02 -5.25874e-01
20Nov23_025751|  -4.30308e-01]
20Nov23_025751| [-1.83182e-01  6.67472e-01  2.76515e-01  8.52399e-03 -9.27706e-01
20Nov23_025751|   2.55810e-01  3.86019e-01  9.93865e-01  1.40708e-01 -5.97830e-01
20Nov23_025751|   1.46493e-01  6.65591e-01 -8.46059e-02 -3.25321e-01 -1.83088e-01
20Nov23_025751|   7.31910e-01]
20Nov23_025751| [ 8.17010e-01 -6.65672e-01  5.90855e-01  3.58485e-01  7.52762e-01
20Nov23_025751|  -1.29865e-01 -5.79064e-01  9.78329e-01  7.21147e-01  2.50930e-02
20Nov23_025751|  -1.31523e-01 -7.61891e-01  7.45934e-01  7.36755e-01  7.86339e-02
20Nov23_025751|   8.63887e-01]
20Nov23_025751| [ 7.47847e-01  3.35309e-01 -5.04801e-01  8.05870e-01  5.67830e-02
20Nov23_025751|  -7.37208e-02  6.69755e-01 -4.55142e-02  1.29064e-01 -5.64810e-01
20Nov23_025751|  -6.28583e-01 -6.68271e-02  9.49477e-02  2.17211e-01  6.59340e-01
20Nov23_025751|  -1.18712e-01]
20Nov23_025751| [-5.84097e-01 -2.02087e-01  8.91683e-02 -9.18597e-01  8.21501e-01
20Nov23_025751|   8.11080e-01 -9.46926e-01  1.87700e-01 -2.86067e-03 -3.60691e-01
20Nov23_025751|   2.18492e-01  7.65192e-01  7.37385e-01 -1.32996e-01  6.19947e-01
20Nov23_025751|  -8.63802e-01]
20Nov23_025751| [-9.21282e-01 -5.58718e-01 -6.84477e-01 -1.85927e-01  1.90336e-01
20Nov23_025751|   4.25133e-01 -5.88187e-01  1.39868e-02  9.29169e-01 -9.71063e-01
20Nov23_025751|  -5.91025e-01  3.82090e-01 -5.77703e-01 -5.05338e-01  4.47331e-01
20Nov23_025751|  -8.69043e-01]
20Nov23_025751| [ 1.59044e-01  6.38332e-01  2.98946e-01  6.01272e-01 -3.55107e-02
20Nov23_025751|  -5.76566e-02 -4.45627e-01 -7.61983e-01 -4.73040e-01 -1.15765e-01
20Nov23_025751|  -1.76568e-01  7.53425e-01  6.23721e-01  1.24576e-02 -3.15248e-01
20Nov23_025751|  -2.19533e-02]
20Nov23_025751| [ 5.20639e-01 -5.80404e-01  3.01947e-01 -8.09911e-01  7.23112e-01
20Nov23_025751|   7.47657e-03  8.86625e-01  7.54074e-01 -7.02361e-01  4.95982e-01
20Nov23_025751|  -5.75458e-01 -5.42449e-01  7.26132e-01 -8.25617e-01 -8.55989e-01
20Nov23_025751|  -3.83899e-01]
20Nov23_025751| [ 8.33101e-01  6.51940e-01  7.15532e-02  1.92119e-01 -6.60055e-01
20Nov23_025751|  -3.88743e-01 -5.31518e-01 -5.68626e-01 -8.90276e-01  6.49041e-01
20Nov23_025751|  -9.43882e-01 -9.32173e-01  8.36441e-01 -3.94971e-01  2.45574e-01
20Nov23_025751|   1.20156e-01]
20Nov23_025751| [ 6.00247e-01 -3.69151e-01  4.65138e-01  1.63360e-01 -5.30231e-01
20Nov23_025751|   8.02914e-01  9.16042e-02 -1.69626e-01  6.41274e-02  6.62733e-01
20Nov23_025751|   1.98604e-01 -8.97968e-01 -3.04105e-01  1.67269e-01  3.49119e-01
20Nov23_025751|  -4.08471e-01]
20Nov23_025751| [-7.37156e-01  6.29948e-01  9.03363e-01 -7.35415e-01  4.44640e-02
20Nov23_025751|   2.10842e-01  7.58809e-01 -9.78824e-01 -8.57483e-02 -7.50379e-01
20Nov23_025751|   4.78833e-01 -4.45190e-01 -6.62070e-01 -4.72892e-01  2.50725e-02
20Nov23_025751|   9.28766e-01]]
20Nov23_025751|-- Bias --
20Nov23_025751|[-0.76044 -0.72675  0.27371  0.32077  0.19598 -0.09733  0.28802  0.51478
20Nov23_025751| -0.67931  0.51416 -0.74965 -0.91654 -0.36440 -0.26953  0.62908 -0.48850]
20Nov23_025751|Layer 1:
20Nov23_025751|-- Config --
20Nov23_025751|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 16], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025751|-- Weights --
20Nov23_025751|[[-0.61535 -0.52087]
20Nov23_025751| [-0.51768  0.17894]
20Nov23_025751| [-0.77748  0.88387]
20Nov23_025751| [-0.23353 -0.03743]
20Nov23_025751| [ 0.99664 -0.75970]
20Nov23_025751| [ 0.41608  0.64137]
20Nov23_025751| [ 0.25865  0.20053]
20Nov23_025751| [-0.91075 -0.85926]
20Nov23_025751| [ 0.70187  0.00719]
20Nov23_025751| [-0.68795 -0.07107]
20Nov23_025751| [-0.19492  0.78747]
20Nov23_025751| [ 0.63135  0.59340]
20Nov23_025751| [ 0.48533  0.68020]
20Nov23_025751| [-0.73268  0.11457]
20Nov23_025751| [-0.54263  0.13562]
20Nov23_025751| [-0.55787 -0.98918]]
20Nov23_025751|-- Bias --
20Nov23_025751|[-0.47885  0.14373]
20Nov23_025751|Predicting the validation and test data with the Best initial individual.
20Nov23_025757| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_025757|-----------  ------------------  --------------------  ----------
20Nov23_025757|Validation         42.09                  16            0.00258
20Nov23_025757|   Test            36.75                  16            0.00297
20Nov23_025757|-------------------------- Test #0 --------------------------
20Nov23_025757|Best final individual weights
20Nov23_025757|Individual:
20Nov23_025757|-- Constant hidden layers --
20Nov23_025757|False
20Nov23_025757|Layer 0:
20Nov23_025757|-- Config --
20Nov23_025757|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 10, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025757|-- Weights --
20Nov23_025757|[[-3.07041e-01  1.00616e+00  6.34565e-01 -6.61114e-01 -5.46887e-01
20Nov23_025757|  -1.10888e+00  3.20769e-01 -4.30961e-02 -2.31163e-01  2.22718e+00]
20Nov23_025757| [ 3.40553e-01  8.74817e-01 -1.66864e+00 -7.83743e-01  1.10105e+00
20Nov23_025757|  -1.32534e+00  4.10905e-02  1.12271e+00  6.89412e-01 -1.53065e-01]
20Nov23_025757| [-1.26826e+00  5.87994e-01 -4.60418e-02 -3.55128e+00  1.04805e+00
20Nov23_025757|   1.61174e-01  1.16185e+00  5.66952e-01  6.72490e-01 -6.24827e-01]
20Nov23_025757| [-9.79202e-01  1.61247e-01 -1.27518e+00  5.18034e-01  1.98136e+00
20Nov23_025757|  -6.90936e-01  1.26940e-01  5.58500e-01  1.42756e-01  1.03981e+00]
20Nov23_025757| [-1.82313e-01  3.66685e-01  1.34275e+00  4.58416e-01 -1.18038e+00
20Nov23_025757|   2.51182e-01 -7.15217e-01 -1.66193e-01 -3.14859e-01  1.24005e+00]
20Nov23_025757| [ 1.48738e+00 -3.98929e-01  3.64868e-01  5.40263e-01  5.46416e-02
20Nov23_025757|   1.88146e+00  1.19580e+00 -2.43148e+00 -7.75186e-01 -6.49648e-01]
20Nov23_025757| [ 1.21399e+00  6.66074e-01  1.28060e+00 -6.11337e-01 -2.69644e-01
20Nov23_025757|  -2.53230e-03 -6.20683e-01  8.95056e-01 -1.08596e+00  3.64325e-01]
20Nov23_025757| [ 5.88481e-01  8.60948e-02  4.37503e-01 -1.84663e+00 -7.58324e-01
20Nov23_025757|   7.34596e-01  1.44969e+00 -8.81787e-01 -1.50155e-01 -1.06136e-01]
20Nov23_025757| [ 3.27155e-01  1.36855e+00 -2.04781e+00 -1.57615e+00 -4.51258e-01
20Nov23_025757|   3.02165e-01  6.43490e-01 -1.26883e-01 -5.94848e-01 -2.12811e+00]
20Nov23_025757| [-3.45131e-01 -1.81354e+00 -4.97743e-01  5.71362e-01 -8.54879e-01
20Nov23_025757|   3.65188e-01  1.95065e-01 -2.79676e-01  1.48447e-01  2.43540e-01]
20Nov23_025757| [-5.61218e-01  1.44002e+00  9.06417e-01 -3.99731e-01 -7.36291e-01
20Nov23_025757|  -9.66884e-01 -5.37313e-01 -8.49094e-01 -1.50517e+00  4.55984e-01]
20Nov23_025757| [ 1.70948e+00  8.12685e-01  2.75510e-02 -1.86415e+00 -1.60141e+00
20Nov23_025757|  -8.75582e-01 -8.89810e-01  5.20086e-01  7.91316e-01 -1.36802e+00]
20Nov23_025757| [-2.14098e-01  2.45515e-01  2.56778e-01  2.97405e-01 -1.38597e+00
20Nov23_025757|  -5.00160e-01  6.20253e-01 -7.58286e-01  3.35205e-01 -3.43907e+00]
20Nov23_025757| [ 4.03195e-01 -1.20324e-01  1.13366e+00  8.88009e-01 -9.37896e-03
20Nov23_025757|  -2.86522e-01  1.67710e+00  5.86515e-01 -1.06572e+00  1.39802e+00]
20Nov23_025757| [ 6.48180e-01 -1.92738e+00  1.50417e-02  8.68537e-02 -1.13786e+00
20Nov23_025757|  -1.29129e+00 -6.92839e-01 -1.40458e+00 -8.00986e-01  8.15326e-01]
20Nov23_025757| [ 1.57969e+00 -1.30609e-01 -1.29681e-01  1.04108e+00 -1.55760e+00
20Nov23_025757|  -1.01726e+00 -7.49064e-02  1.91418e-01  1.13480e+00 -1.29247e+00]
20Nov23_025757| [ 6.05486e-01 -1.20667e+00  1.83863e+00  1.62026e+00 -1.21907e+00
20Nov23_025757|  -1.85861e+00  6.32947e-01 -6.56312e-01 -1.96676e+00  9.10422e-01]
20Nov23_025757| [-1.17272e+00  1.65220e+00 -1.03529e+00 -8.72294e-02  2.90430e-01
20Nov23_025757|  -2.34656e+00  3.19297e-01 -1.87314e+00  5.04493e-01  4.65741e-01]
20Nov23_025757| [-9.48481e-02 -2.33962e-02 -5.93975e-02  3.19555e-02  3.49339e-01
20Nov23_025757|   6.49964e-01  6.53861e-01  8.66293e-01 -1.16838e+00 -9.17614e-01]
20Nov23_025757| [ 1.19783e+00  3.25987e-01  1.37329e+00  8.63944e-01 -9.03486e-01
20Nov23_025757|   1.38840e+00  1.49831e+00  1.17810e+00 -2.68505e+00  1.62729e+00]
20Nov23_025757| [-1.58344e+00 -2.33544e-01  8.36162e-01 -2.18260e+00 -1.15138e+00
20Nov23_025757|   1.45939e+00 -1.13930e+00 -3.86267e-01 -4.73407e-01 -9.27712e-01]
20Nov23_025757| [ 4.40150e-01 -1.15269e+00  3.37421e-01 -6.98225e-01  2.17269e+00
20Nov23_025757|   9.63798e-01 -1.43930e+00  1.71663e+00  7.51493e-01 -6.28456e-01]
20Nov23_025757| [-1.58838e+00  1.79189e+00  5.00478e-01 -1.25010e+00  7.03498e-01
20Nov23_025757|  -6.38268e-01  1.20227e+00  1.08421e+00  8.40502e-01  2.02490e+00]
20Nov23_025757| [ 3.67353e-01 -6.31589e-04  1.27834e+00 -1.39200e+00 -1.15876e+00
20Nov23_025757|   1.53865e+00 -7.44091e-01  4.73619e-01  2.04884e+00  1.62277e+00]
20Nov23_025757| [-1.55578e+00  1.55922e+00 -6.26084e-02  1.27440e+00  7.76317e-01
20Nov23_025757|  -3.31071e-01 -8.12146e-01  5.32258e-01 -1.03204e-01  5.74448e-01]
20Nov23_025757| [-1.66080e-01  9.27591e-01 -8.26749e-01 -2.02630e+00 -1.69057e+00
20Nov23_025757|   1.57038e+00 -9.36829e-01 -8.09723e-02 -1.40559e+00 -4.68670e-01]
20Nov23_025757| [ 1.31585e+00 -1.35879e+00  6.69832e-02 -6.76034e-01 -7.78053e-02
20Nov23_025757|   9.15890e-01 -2.57551e+00  1.17206e+00 -1.63833e-01 -1.51976e+00]
20Nov23_025757| [ 3.86571e-01  3.76960e-01  1.62203e+00 -6.63494e-01  5.79448e-01
20Nov23_025757|  -2.02899e-01  6.20663e-01 -8.74604e-01  5.65300e-01 -4.78021e-01]
20Nov23_025757| [ 2.84392e-01 -1.30287e+00 -2.40568e-01  1.64154e+00  8.57175e-01
20Nov23_025757|   1.66324e+00 -7.58044e-01  9.58194e-01  1.08895e+00  6.87897e-01]
20Nov23_025757| [ 1.91543e+00 -8.14252e-01 -8.52032e-01  3.78664e-01  1.90764e+00
20Nov23_025757|  -4.47222e-01 -2.69340e+00 -1.03904e+00 -2.00134e+00  2.38100e-01]
20Nov23_025757| [ 1.26019e+00  9.38744e-01 -3.14317e-01  7.86493e-01  4.76806e-01
20Nov23_025757|  -1.35297e-01  4.23375e-01 -2.08811e+00 -2.33768e-01 -6.56785e-01]
20Nov23_025757| [-1.79324e+00  2.42905e-02  1.37542e+00 -2.27793e+00  2.38915e+00
20Nov23_025757|   1.28801e-01 -1.29803e-01  1.69579e+00 -5.80142e-01  2.11689e+00]
20Nov23_025757| [ 9.34165e-01  7.98905e-01  9.33160e-01  1.26228e+00  8.33572e-01
20Nov23_025757|   8.94453e-01 -1.13623e+00  1.39619e+00 -6.78227e-01  8.70115e-01]
20Nov23_025757| [-1.10950e+00  2.87654e-01  2.71057e-01  8.54796e-01  1.22987e+00
20Nov23_025757|  -1.00751e+00 -5.61214e-01 -6.35672e-02 -9.03112e-01 -7.95657e-01]
20Nov23_025757| [-7.55905e-01  2.91320e-01 -1.58683e+00  5.85932e-01  2.65090e-01
20Nov23_025757|   1.77914e-01 -1.04044e-01 -1.09661e+00  9.38082e-02 -5.58226e-01]
20Nov23_025757| [-9.74231e-01  1.36123e+00 -4.42398e-01  1.01758e-01  3.66514e-01
20Nov23_025757|   1.28179e+00 -1.91686e+00  5.51070e-01  1.15574e+00 -7.07965e-01]
20Nov23_025757| [ 4.46124e-02  5.20958e-01  2.14918e+00  4.16463e-01 -8.15995e-03
20Nov23_025757|   1.50900e+00  2.03955e+00 -3.79312e-01  1.23712e+00 -9.03886e-01]
20Nov23_025757| [ 9.53918e-01 -1.00003e+00  1.67585e+00 -3.41251e+00  1.13867e+00
20Nov23_025757|   3.59439e-01  6.13636e-01 -5.79112e-01  1.84630e-01  1.27094e-01]
20Nov23_025757| [ 5.63295e-01 -7.65227e-01  1.14199e-01 -1.63298e+00  2.84249e-01
20Nov23_025757|  -6.66078e-01 -1.57556e+00  1.00746e+00  7.55489e-01 -9.87647e-01]
20Nov23_025757| [-7.69623e-01 -2.82068e-01  2.51158e+00 -7.90434e-01 -1.54072e+00
20Nov23_025757|   2.29525e+00  3.09859e-01  3.83551e-01 -9.54400e-01  7.70518e-01]
20Nov23_025757| [ 2.04135e+00 -1.89705e+00 -2.04564e+00  1.29505e+00  2.31663e-01
20Nov23_025757|  -1.07668e-01 -1.11612e-01 -4.62865e-01  1.10223e+00  9.01401e-01]
20Nov23_025757| [-6.45809e-01  4.89783e-01  2.17360e+00 -6.88799e-01  1.19751e+00
20Nov23_025757|   1.21721e+00 -2.17834e+00 -5.34672e-01  1.33385e+00 -2.08075e+00]
20Nov23_025757| [-4.18249e+00  1.95307e-01 -7.81067e-01  1.37136e+00 -2.13521e-01
20Nov23_025757|   1.59212e+00 -3.82342e-01  2.63593e+00 -1.00001e+00 -9.22583e-01]
20Nov23_025757| [ 7.01133e-01 -1.13910e+00  1.30671e+00 -5.14959e-01 -2.15790e+00
20Nov23_025757|  -9.44361e-01 -7.67735e-01 -1.24544e+00  1.21896e-01  1.44422e-02]
20Nov23_025757| [-5.05253e-01 -9.48834e-01 -1.35498e+00 -5.44439e-01  4.33973e-01
20Nov23_025757|   1.34650e+00 -1.59928e+00 -9.47020e-01  1.00715e+00 -2.13873e-01]
20Nov23_025757| [-4.95534e-01 -1.37437e-01 -7.25293e-01 -1.79721e+00  1.74471e+00
20Nov23_025757|  -9.68677e-01 -8.56409e-02  1.37133e+00 -7.11811e-01 -8.75033e-01]
20Nov23_025757| [ 1.75287e+00  4.58719e-01  6.66106e-01  1.10149e+00  1.57245e+00
20Nov23_025757|  -6.58958e-01 -7.97523e-01  4.49998e-01 -9.37306e-01  7.24107e-01]
20Nov23_025757| [-6.67339e-02  1.37247e+00  4.27743e-01  3.63566e-01  1.53543e+00
20Nov23_025757|  -2.46799e+00  1.38273e-01  9.09795e-01 -1.63558e+00 -2.33811e+00]
20Nov23_025757| [ 4.74738e-01  1.19072e+00  2.53531e-01  1.60539e+00 -1.19259e+00
20Nov23_025757|   8.16734e-01 -1.06184e+00 -8.57672e-01 -4.20009e-02  2.71981e-01]
20Nov23_025757| [-9.28704e-01  2.61080e+00  7.82101e-01  1.51103e+00 -1.65491e+00
20Nov23_025757|   1.67477e+00  1.27955e+00  9.86971e-01  1.12991e+00 -1.88014e+00]
20Nov23_025757| [-1.83175e+00  2.17081e+00 -1.12905e-01 -7.86976e-01  4.64954e-02
20Nov23_025757|   1.73163e+00 -2.10689e+00  2.17379e-01 -2.19104e+00  2.65990e-01]
20Nov23_025757| [ 5.99832e-01  2.26352e+00 -1.26344e+00  1.67205e+00  1.96797e+00
20Nov23_025757|  -1.04196e+00 -1.17036e+00 -5.82210e-01  3.44470e-01 -6.29446e-01]
20Nov23_025757| [-3.74647e-01  1.57396e+00 -1.23393e+00  1.77755e+00 -1.35559e+00
20Nov23_025757|  -3.50392e-01 -1.51221e+00 -3.50933e-01 -2.21108e+00  2.27891e+00]
20Nov23_025757| [ 1.79899e+00  9.29451e-01 -2.38156e+00 -2.95904e-01  5.01510e-02
20Nov23_025757|  -4.89236e-01 -3.81430e-02 -1.93658e-02 -2.81360e+00 -1.61727e+00]
20Nov23_025757| [-6.31664e-01  1.35179e-02 -8.62988e-01 -1.37577e+00 -1.76862e+00
20Nov23_025757|   7.53411e-01  8.42981e-01 -1.16891e+00 -1.94126e-01  1.64820e+00]
20Nov23_025757| [-9.45281e-01 -1.40671e+00 -2.98803e-01 -9.53509e-01 -7.63614e-01
20Nov23_025757|   3.42849e-02  1.95511e+00  1.79314e+00 -7.97121e-01 -1.37916e+00]
20Nov23_025757| [-1.21675e+00 -1.09576e+00 -3.20845e-01  7.37468e-01 -7.22748e-01
20Nov23_025757|  -4.89459e-01 -1.01331e+00  8.35708e-02  1.66520e-01  4.22179e-01]]
20Nov23_025757|-- Bias --
20Nov23_025757|[ 0.60392 -0.49720 -0.40465 -0.97662 -1.18628 -0.32953 -0.72463  1.47398
20Nov23_025757|  0.64550  0.75190]
20Nov23_025757|Layer 1:
20Nov23_025757|-- Config --
20Nov23_025757|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 10], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025757|-- Weights --
20Nov23_025757|[[-0.21679 -0.45691  0.28378  0.33784]
20Nov23_025757| [ 0.06390  0.16042 -0.55690  0.51363]
20Nov23_025757| [ 0.72633  0.93777 -0.75765  0.12993]
20Nov23_025757| [-0.62302  0.49010 -0.52417 -0.18200]
20Nov23_025757| [ 0.40134 -0.38242 -0.19617 -0.96393]
20Nov23_025757| [ 0.32070 -0.40738 -0.02044 -0.76057]
20Nov23_025757| [-0.43581  0.72040 -0.51486 -0.45397]
20Nov23_025757| [-0.62899 -0.42677 -0.34653 -0.07457]
20Nov23_025757| [-0.53423 -0.35014  0.48800 -0.44973]
20Nov23_025757| [ 0.80919  0.06153 -0.03718  0.65188]]
20Nov23_025757|-- Bias --
20Nov23_025757|[ 0.73864 -0.52503 -0.04894  0.56961]
20Nov23_025757|Layer 2:
20Nov23_025757|-- Config --
20Nov23_025757|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025757|-- Weights --
20Nov23_025757|[[ 0.12699 -0.47567]
20Nov23_025757| [ 1.38134  1.35039]
20Nov23_025757| [ 1.14654  1.78430]
20Nov23_025757| [ 0.41573  1.94888]]
20Nov23_025757|-- Bias --
20Nov23_025757|[ 0.02099 -0.36139]
20Nov23_025757|Predicting the validation and test data with the Best final individual.
20Nov23_025803| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_025803|-----------  ------------------  --------------------  ----------
20Nov23_025803|Validation         42.35                  28            0.81944
20Nov23_025803|   Test            28.06                  28            0.32009
20Nov23_025803|-------------------------- Test #1 --------------------------
20Nov23_025803|Best final individual weights
20Nov23_025803|Individual:
20Nov23_025803|-- Constant hidden layers --
20Nov23_025803|False
20Nov23_025803|Layer 0:
20Nov23_025803|-- Config --
20Nov23_025803|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 10, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025803|-- Weights --
20Nov23_025803|[[-3.07041e-01  1.00616e+00  6.34565e-01 -6.61114e-01 -5.46887e-01
20Nov23_025803|  -1.10888e+00  3.20769e-01 -4.30961e-02 -2.31163e-01  2.22718e+00]
20Nov23_025803| [ 3.40553e-01  8.74817e-01 -1.66864e+00 -7.83743e-01  1.10105e+00
20Nov23_025803|  -1.32534e+00  4.10905e-02  1.12271e+00  6.89412e-01 -1.53065e-01]
20Nov23_025803| [-1.26826e+00  5.87994e-01 -4.60418e-02 -3.55128e+00  1.04805e+00
20Nov23_025803|   1.61174e-01  1.16185e+00  5.66952e-01  6.72490e-01 -6.24827e-01]
20Nov23_025803| [-9.79202e-01  1.61247e-01 -1.27518e+00  5.18034e-01  1.98136e+00
20Nov23_025803|  -6.90936e-01  1.26940e-01  5.58500e-01  1.42756e-01  1.03981e+00]
20Nov23_025803| [-1.82313e-01  3.66685e-01  1.34275e+00  4.58416e-01 -1.18038e+00
20Nov23_025803|   2.51182e-01 -7.15217e-01 -1.66193e-01 -3.14859e-01  1.24005e+00]
20Nov23_025803| [ 1.48738e+00 -3.98929e-01  3.64868e-01  5.40263e-01  5.46416e-02
20Nov23_025803|   1.88146e+00  1.19580e+00 -2.43148e+00 -7.75186e-01 -6.49648e-01]
20Nov23_025803| [ 1.21399e+00  6.66074e-01  1.28060e+00 -6.11337e-01 -2.69644e-01
20Nov23_025803|  -2.53230e-03 -6.20683e-01  8.95056e-01 -1.08596e+00  3.64325e-01]
20Nov23_025803| [ 5.88481e-01  8.60948e-02  4.37503e-01 -1.84663e+00 -7.58324e-01
20Nov23_025803|   7.34596e-01  1.44969e+00 -8.81787e-01 -1.50155e-01 -1.06136e-01]
20Nov23_025803| [ 3.27155e-01  1.36855e+00 -2.04781e+00 -1.57615e+00 -4.51258e-01
20Nov23_025803|   3.02165e-01  6.43490e-01 -1.26883e-01 -5.94848e-01 -2.12811e+00]
20Nov23_025803| [-3.45131e-01 -1.81354e+00 -4.97743e-01  5.71362e-01 -8.54879e-01
20Nov23_025803|   3.65188e-01  1.95065e-01 -2.79676e-01  1.48447e-01  2.43540e-01]
20Nov23_025803| [-5.61218e-01  1.44002e+00  9.06417e-01 -3.99731e-01 -7.36291e-01
20Nov23_025803|  -9.66884e-01 -5.37313e-01 -8.49094e-01 -1.50517e+00  4.55984e-01]
20Nov23_025803| [ 1.70948e+00  8.12685e-01  2.75510e-02 -1.86415e+00 -1.60141e+00
20Nov23_025803|  -8.75582e-01 -8.89810e-01  5.20086e-01  7.91316e-01 -1.36802e+00]
20Nov23_025803| [-2.14098e-01  2.45515e-01  2.56778e-01  2.97405e-01 -1.38597e+00
20Nov23_025803|  -5.00160e-01  6.20253e-01 -7.58286e-01  3.35205e-01 -3.43907e+00]
20Nov23_025803| [ 4.03195e-01 -1.20324e-01  1.13366e+00  8.88009e-01 -9.37896e-03
20Nov23_025803|  -2.86522e-01  1.67710e+00  5.86515e-01 -1.06572e+00  1.39802e+00]
20Nov23_025803| [ 6.48180e-01 -1.92738e+00  1.50417e-02  8.68537e-02 -1.13786e+00
20Nov23_025803|  -1.29129e+00 -6.92839e-01 -1.40458e+00 -8.00986e-01  8.15326e-01]
20Nov23_025803| [ 1.57969e+00 -1.30609e-01 -1.29681e-01  1.04108e+00 -1.55760e+00
20Nov23_025803|  -1.01726e+00 -7.49064e-02  1.91418e-01  1.13480e+00 -1.29247e+00]
20Nov23_025803| [ 6.05486e-01 -1.20667e+00  1.83863e+00  1.62026e+00 -1.21907e+00
20Nov23_025803|  -1.85861e+00  6.32947e-01 -6.56312e-01 -1.96676e+00  9.10422e-01]
20Nov23_025803| [-1.17272e+00  1.65220e+00 -1.03529e+00 -8.72294e-02  2.90430e-01
20Nov23_025803|  -2.34656e+00  3.19297e-01 -1.87314e+00  5.04493e-01  4.65741e-01]
20Nov23_025803| [-9.48481e-02 -2.33962e-02 -5.93975e-02  3.19555e-02  3.49339e-01
20Nov23_025803|   6.49964e-01  6.53861e-01  8.66293e-01 -1.16838e+00 -9.17614e-01]
20Nov23_025803| [ 1.19783e+00  3.25987e-01  1.37329e+00  8.63944e-01 -9.03486e-01
20Nov23_025803|   1.38840e+00  1.49831e+00  1.17810e+00 -2.68505e+00  1.62729e+00]
20Nov23_025803| [-1.58344e+00 -2.33544e-01  8.36162e-01 -2.18260e+00 -1.15138e+00
20Nov23_025803|   1.45939e+00 -1.13930e+00 -3.86267e-01 -4.73407e-01 -9.27712e-01]
20Nov23_025803| [ 4.40150e-01 -1.15269e+00  3.37421e-01 -6.98225e-01  2.17269e+00
20Nov23_025803|   9.63798e-01 -1.43930e+00  1.71663e+00  7.51493e-01 -6.28456e-01]
20Nov23_025803| [-1.58838e+00  1.79189e+00  5.00478e-01 -1.25010e+00  7.03498e-01
20Nov23_025803|  -6.38268e-01  1.20227e+00  1.08421e+00  8.40502e-01  2.02490e+00]
20Nov23_025803| [ 3.67353e-01 -6.31589e-04  1.27834e+00 -1.39200e+00 -1.15876e+00
20Nov23_025803|   1.53865e+00 -7.44091e-01  4.73619e-01  2.04884e+00  1.62277e+00]
20Nov23_025803| [-1.55578e+00  1.55922e+00 -6.26084e-02  1.27440e+00  7.76317e-01
20Nov23_025803|  -3.31071e-01 -8.12146e-01  5.32258e-01 -1.03204e-01  5.74448e-01]
20Nov23_025803| [-1.66080e-01  9.27591e-01 -8.26749e-01 -2.02630e+00 -1.69057e+00
20Nov23_025803|   1.57038e+00 -9.36829e-01 -8.09723e-02 -1.40559e+00 -4.68670e-01]
20Nov23_025803| [ 1.31585e+00 -1.35879e+00  6.69832e-02 -6.76034e-01 -7.78053e-02
20Nov23_025803|   9.15890e-01 -2.57551e+00  1.17206e+00 -1.63833e-01 -1.51976e+00]
20Nov23_025803| [ 3.86571e-01  3.76960e-01  1.62203e+00 -6.63494e-01  5.79448e-01
20Nov23_025803|  -2.02899e-01  6.20663e-01 -8.74604e-01  5.65300e-01 -4.78021e-01]
20Nov23_025803| [ 2.84392e-01 -1.30287e+00 -2.40568e-01  1.64154e+00  8.57175e-01
20Nov23_025803|   1.66324e+00 -7.58044e-01  9.58194e-01  1.08895e+00  6.87897e-01]
20Nov23_025803| [ 1.91543e+00 -8.14252e-01 -8.52032e-01  3.78664e-01  1.90764e+00
20Nov23_025803|  -4.47222e-01 -2.69340e+00 -1.03904e+00 -2.00134e+00  2.38100e-01]
20Nov23_025803| [ 1.26019e+00  9.38744e-01 -3.14317e-01  7.86493e-01  4.76806e-01
20Nov23_025803|  -1.35297e-01  4.23375e-01 -2.08811e+00 -2.33768e-01 -6.56785e-01]
20Nov23_025803| [-1.79324e+00  2.42905e-02  1.37542e+00 -2.27793e+00  2.38915e+00
20Nov23_025803|   1.28801e-01 -1.29803e-01  1.69579e+00 -5.80142e-01  2.11689e+00]
20Nov23_025803| [ 9.34165e-01  7.98905e-01  9.33160e-01  1.26228e+00  8.33572e-01
20Nov23_025803|   8.94453e-01 -1.13623e+00  1.39619e+00 -6.78227e-01  8.70115e-01]
20Nov23_025803| [-1.10950e+00  2.87654e-01  2.71057e-01  8.54796e-01  1.22987e+00
20Nov23_025803|  -1.00751e+00 -5.61214e-01 -6.35672e-02 -9.03112e-01 -7.95657e-01]
20Nov23_025803| [-7.55905e-01  2.91320e-01 -1.58683e+00  5.85932e-01  2.65090e-01
20Nov23_025803|   1.77914e-01 -1.04044e-01 -1.09661e+00  9.38082e-02 -5.58226e-01]
20Nov23_025803| [-9.74231e-01  1.36123e+00 -4.42398e-01  1.01758e-01  3.66514e-01
20Nov23_025803|   1.28179e+00 -1.91686e+00  5.51070e-01  1.15574e+00 -7.07965e-01]
20Nov23_025803| [ 4.46124e-02  5.20958e-01  2.14918e+00  4.16463e-01 -8.15995e-03
20Nov23_025803|   1.50900e+00  2.03955e+00 -3.79312e-01  1.23712e+00 -9.03886e-01]
20Nov23_025803| [ 9.53918e-01 -1.00003e+00  1.67585e+00 -3.41251e+00  1.13867e+00
20Nov23_025803|   3.59439e-01  6.13636e-01 -5.79112e-01  1.84630e-01  1.27094e-01]
20Nov23_025803| [ 5.63295e-01 -7.65227e-01  1.14199e-01 -1.63298e+00  2.84249e-01
20Nov23_025803|  -6.66078e-01 -1.57556e+00  1.00746e+00  7.55489e-01 -9.87647e-01]
20Nov23_025803| [-7.69623e-01 -2.82068e-01  2.51158e+00 -7.90434e-01 -1.54072e+00
20Nov23_025803|   2.29525e+00  3.09859e-01  3.83551e-01 -9.54400e-01  7.70518e-01]
20Nov23_025803| [ 2.04135e+00 -1.89705e+00 -2.04564e+00  1.29505e+00  2.31663e-01
20Nov23_025803|  -1.07668e-01 -1.11612e-01 -4.62865e-01  1.10223e+00  9.01401e-01]
20Nov23_025803| [-6.45809e-01  4.89783e-01  2.17360e+00 -6.88799e-01  1.19751e+00
20Nov23_025803|   1.21721e+00 -2.17834e+00 -5.34672e-01  1.33385e+00 -2.08075e+00]
20Nov23_025803| [-4.18249e+00  1.95307e-01 -7.81067e-01  1.37136e+00 -2.13521e-01
20Nov23_025803|   1.59212e+00 -3.82342e-01  2.63593e+00 -1.00001e+00 -9.22583e-01]
20Nov23_025803| [ 7.01133e-01 -1.13910e+00  1.30671e+00 -5.14959e-01 -2.15790e+00
20Nov23_025803|  -9.44361e-01 -7.67735e-01 -1.24544e+00  1.21896e-01  1.44422e-02]
20Nov23_025803| [-5.05253e-01 -9.48834e-01 -1.35498e+00 -5.44439e-01  4.33973e-01
20Nov23_025803|   1.34650e+00 -1.59928e+00 -9.47020e-01  1.00715e+00 -2.13873e-01]
20Nov23_025803| [-4.95534e-01 -1.37437e-01 -7.25293e-01 -1.79721e+00  1.74471e+00
20Nov23_025803|  -9.68677e-01 -8.56409e-02  1.37133e+00 -7.11811e-01 -8.75033e-01]
20Nov23_025803| [ 1.75287e+00  4.58719e-01  6.66106e-01  1.10149e+00  1.57245e+00
20Nov23_025803|  -6.58958e-01 -7.97523e-01  4.49998e-01 -9.37306e-01  7.24107e-01]
20Nov23_025803| [-6.67339e-02  1.37247e+00  4.27743e-01  3.63566e-01  1.53543e+00
20Nov23_025803|  -2.46799e+00  1.38273e-01  9.09795e-01 -1.63558e+00 -2.33811e+00]
20Nov23_025803| [ 4.74738e-01  1.19072e+00  2.53531e-01  1.60539e+00 -1.19259e+00
20Nov23_025803|   8.16734e-01 -1.06184e+00 -8.57672e-01 -4.20009e-02  2.71981e-01]
20Nov23_025803| [-9.28704e-01  2.61080e+00  7.82101e-01  1.51103e+00 -1.65491e+00
20Nov23_025803|   1.67477e+00  1.27955e+00  9.86971e-01  1.12991e+00 -1.88014e+00]
20Nov23_025803| [-1.83175e+00  2.17081e+00 -1.12905e-01 -7.86976e-01  4.64954e-02
20Nov23_025803|   1.73163e+00 -2.10689e+00  2.17379e-01 -2.19104e+00  2.65990e-01]
20Nov23_025803| [ 5.99832e-01  2.26352e+00 -1.26344e+00  1.67205e+00  1.96797e+00
20Nov23_025803|  -1.04196e+00 -1.17036e+00 -5.82210e-01  3.44470e-01 -6.29446e-01]
20Nov23_025803| [-3.74647e-01  1.57396e+00 -1.23393e+00  1.77755e+00 -1.35559e+00
20Nov23_025803|  -3.50392e-01 -1.51221e+00 -3.50933e-01 -2.21108e+00  2.27891e+00]
20Nov23_025803| [ 1.79899e+00  9.29451e-01 -2.38156e+00 -2.95904e-01  5.01510e-02
20Nov23_025803|  -4.89236e-01 -3.81430e-02 -1.93658e-02 -2.81360e+00 -1.61727e+00]
20Nov23_025803| [-6.31664e-01  1.35179e-02 -8.62988e-01 -1.37577e+00 -1.76862e+00
20Nov23_025803|   7.53411e-01  8.42981e-01 -1.16891e+00 -1.94126e-01  1.64820e+00]
20Nov23_025803| [-9.45281e-01 -1.40671e+00 -2.98803e-01 -9.53509e-01 -7.63614e-01
20Nov23_025803|   3.42849e-02  1.95511e+00  1.79314e+00 -7.97121e-01 -1.37916e+00]
20Nov23_025803| [-1.21675e+00 -1.09576e+00 -3.20845e-01  7.37468e-01 -7.22748e-01
20Nov23_025803|  -4.89459e-01 -1.01331e+00  8.35708e-02  1.66520e-01  4.22179e-01]]
20Nov23_025803|-- Bias --
20Nov23_025803|[ 0.60392 -0.49720 -0.40465 -0.97662 -1.18628 -0.32953 -0.72463  1.47398
20Nov23_025803|  0.64550  0.75190]
20Nov23_025803|Layer 1:
20Nov23_025803|-- Config --
20Nov23_025803|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 10], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025803|-- Weights --
20Nov23_025803|[[-0.21679 -0.45691  0.28378  0.33784]
20Nov23_025803| [ 0.06390  0.16042 -0.55690  0.51363]
20Nov23_025803| [ 0.72633  0.93777 -0.75765  0.12993]
20Nov23_025803| [-0.62302  0.49010 -0.52417 -0.18200]
20Nov23_025803| [ 0.40134 -0.38242 -0.19617 -0.96393]
20Nov23_025803| [ 0.32070 -0.40738 -0.02044 -0.76057]
20Nov23_025803| [-0.43581  0.72040 -0.51486 -0.45397]
20Nov23_025803| [-0.62899 -0.42677 -0.34653 -0.07457]
20Nov23_025803| [-0.53423 -0.35014  0.48800 -0.44973]
20Nov23_025803| [ 0.80919  0.06153 -0.03718  0.65188]]
20Nov23_025803|-- Bias --
20Nov23_025803|[ 0.73864 -0.52503 -0.04894  0.56961]
20Nov23_025803|Layer 2:
20Nov23_025803|-- Config --
20Nov23_025803|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025803|-- Weights --
20Nov23_025803|[[ 0.12699 -0.47567]
20Nov23_025803| [ 1.38134  1.35039]
20Nov23_025803| [ 1.14654  1.78430]
20Nov23_025803| [ 0.41573  1.94888]]
20Nov23_025803|-- Bias --
20Nov23_025803|[ 0.02099 -0.36139]
20Nov23_025803|Predicting the validation and test data with the Best final individual.
20Nov23_025809| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_025809|-----------  ------------------  --------------------  ----------
20Nov23_025809|Validation         42.09                  28            0.00000
20Nov23_025809|   Test            36.58                  28            0.00298
20Nov23_025809|-------------------------- Test #2 --------------------------
20Nov23_025809|Best final individual weights
20Nov23_025809|Individual:
20Nov23_025809|-- Constant hidden layers --
20Nov23_025809|False
20Nov23_025809|Layer 0:
20Nov23_025809|-- Config --
20Nov23_025809|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 10, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025809|-- Weights --
20Nov23_025809|[[-3.07041e-01  1.00616e+00  6.34565e-01 -6.61114e-01 -5.46887e-01
20Nov23_025809|  -1.10888e+00  3.20769e-01 -4.30961e-02 -2.31163e-01  2.22718e+00]
20Nov23_025809| [ 3.40553e-01  8.74817e-01 -1.66864e+00 -7.83743e-01  1.10105e+00
20Nov23_025809|  -1.32534e+00  4.10905e-02  1.12271e+00  6.89412e-01 -1.53065e-01]
20Nov23_025809| [-1.26826e+00  5.87994e-01 -4.60418e-02 -3.55128e+00  1.04805e+00
20Nov23_025809|   1.61174e-01  1.16185e+00  5.66952e-01  6.72490e-01 -6.24827e-01]
20Nov23_025809| [-9.79202e-01  1.61247e-01 -1.27518e+00  5.18034e-01  1.98136e+00
20Nov23_025809|  -6.90936e-01  1.26940e-01  5.58500e-01  1.42756e-01  1.03981e+00]
20Nov23_025809| [-1.82313e-01  3.66685e-01  1.34275e+00  4.58416e-01 -1.18038e+00
20Nov23_025809|   2.51182e-01 -7.15217e-01 -1.66193e-01 -3.14859e-01  1.24005e+00]
20Nov23_025809| [ 1.48738e+00 -3.98929e-01  3.64868e-01  5.40263e-01  5.46416e-02
20Nov23_025809|   1.88146e+00  1.19580e+00 -2.43148e+00 -7.75186e-01 -6.49648e-01]
20Nov23_025809| [ 1.21399e+00  6.66074e-01  1.28060e+00 -6.11337e-01 -2.69644e-01
20Nov23_025809|  -2.53230e-03 -6.20683e-01  8.95056e-01 -1.08596e+00  3.64325e-01]
20Nov23_025809| [ 5.88481e-01  8.60948e-02  4.37503e-01 -1.84663e+00 -7.58324e-01
20Nov23_025809|   7.34596e-01  1.44969e+00 -8.81787e-01 -1.50155e-01 -1.06136e-01]
20Nov23_025809| [ 3.27155e-01  1.36855e+00 -2.04781e+00 -1.57615e+00 -4.51258e-01
20Nov23_025809|   3.02165e-01  6.43490e-01 -1.26883e-01 -5.94848e-01 -2.12811e+00]
20Nov23_025809| [-3.45131e-01 -1.81354e+00 -4.97743e-01  5.71362e-01 -8.54879e-01
20Nov23_025809|   3.65188e-01  1.95065e-01 -2.79676e-01  1.48447e-01  2.43540e-01]
20Nov23_025809| [-5.61218e-01  1.44002e+00  9.06417e-01 -3.99731e-01 -7.36291e-01
20Nov23_025809|  -9.66884e-01 -5.37313e-01 -8.49094e-01 -1.50517e+00  4.55984e-01]
20Nov23_025809| [ 1.70948e+00  8.12685e-01  2.75510e-02 -1.86415e+00 -1.60141e+00
20Nov23_025809|  -8.75582e-01 -8.89810e-01  5.20086e-01  7.91316e-01 -1.36802e+00]
20Nov23_025809| [-2.14098e-01  2.45515e-01  2.56778e-01  2.97405e-01 -1.38597e+00
20Nov23_025809|  -5.00160e-01  6.20253e-01 -7.58286e-01  3.35205e-01 -3.43907e+00]
20Nov23_025809| [ 4.03195e-01 -1.20324e-01  1.13366e+00  8.88009e-01 -9.37896e-03
20Nov23_025809|  -2.86522e-01  1.67710e+00  5.86515e-01 -1.06572e+00  1.39802e+00]
20Nov23_025809| [ 6.48180e-01 -1.92738e+00  1.50417e-02  8.68537e-02 -1.13786e+00
20Nov23_025809|  -1.29129e+00 -6.92839e-01 -1.40458e+00 -8.00986e-01  8.15326e-01]
20Nov23_025809| [ 1.57969e+00 -1.30609e-01 -1.29681e-01  1.04108e+00 -1.55760e+00
20Nov23_025809|  -1.01726e+00 -7.49064e-02  1.91418e-01  1.13480e+00 -1.29247e+00]
20Nov23_025809| [ 6.05486e-01 -1.20667e+00  1.83863e+00  1.62026e+00 -1.21907e+00
20Nov23_025809|  -1.85861e+00  6.32947e-01 -6.56312e-01 -1.96676e+00  9.10422e-01]
20Nov23_025809| [-1.17272e+00  1.65220e+00 -1.03529e+00 -8.72294e-02  2.90430e-01
20Nov23_025809|  -2.34656e+00  3.19297e-01 -1.87314e+00  5.04493e-01  4.65741e-01]
20Nov23_025809| [-9.48481e-02 -2.33962e-02 -5.93975e-02  3.19555e-02  3.49339e-01
20Nov23_025809|   6.49964e-01  6.53861e-01  8.66293e-01 -1.16838e+00 -9.17614e-01]
20Nov23_025809| [ 1.19783e+00  3.25987e-01  1.37329e+00  8.63944e-01 -9.03486e-01
20Nov23_025809|   1.38840e+00  1.49831e+00  1.17810e+00 -2.68505e+00  1.62729e+00]
20Nov23_025809| [-1.58344e+00 -2.33544e-01  8.36162e-01 -2.18260e+00 -1.15138e+00
20Nov23_025809|   1.45939e+00 -1.13930e+00 -3.86267e-01 -4.73407e-01 -9.27712e-01]
20Nov23_025809| [ 4.40150e-01 -1.15269e+00  3.37421e-01 -6.98225e-01  2.17269e+00
20Nov23_025809|   9.63798e-01 -1.43930e+00  1.71663e+00  7.51493e-01 -6.28456e-01]
20Nov23_025809| [-1.58838e+00  1.79189e+00  5.00478e-01 -1.25010e+00  7.03498e-01
20Nov23_025809|  -6.38268e-01  1.20227e+00  1.08421e+00  8.40502e-01  2.02490e+00]
20Nov23_025809| [ 3.67353e-01 -6.31589e-04  1.27834e+00 -1.39200e+00 -1.15876e+00
20Nov23_025809|   1.53865e+00 -7.44091e-01  4.73619e-01  2.04884e+00  1.62277e+00]
20Nov23_025809| [-1.55578e+00  1.55922e+00 -6.26084e-02  1.27440e+00  7.76317e-01
20Nov23_025809|  -3.31071e-01 -8.12146e-01  5.32258e-01 -1.03204e-01  5.74448e-01]
20Nov23_025809| [-1.66080e-01  9.27591e-01 -8.26749e-01 -2.02630e+00 -1.69057e+00
20Nov23_025809|   1.57038e+00 -9.36829e-01 -8.09723e-02 -1.40559e+00 -4.68670e-01]
20Nov23_025809| [ 1.31585e+00 -1.35879e+00  6.69832e-02 -6.76034e-01 -7.78053e-02
20Nov23_025809|   9.15890e-01 -2.57551e+00  1.17206e+00 -1.63833e-01 -1.51976e+00]
20Nov23_025809| [ 3.86571e-01  3.76960e-01  1.62203e+00 -6.63494e-01  5.79448e-01
20Nov23_025809|  -2.02899e-01  6.20663e-01 -8.74604e-01  5.65300e-01 -4.78021e-01]
20Nov23_025809| [ 2.84392e-01 -1.30287e+00 -2.40568e-01  1.64154e+00  8.57175e-01
20Nov23_025809|   1.66324e+00 -7.58044e-01  9.58194e-01  1.08895e+00  6.87897e-01]
20Nov23_025809| [ 1.91543e+00 -8.14252e-01 -8.52032e-01  3.78664e-01  1.90764e+00
20Nov23_025809|  -4.47222e-01 -2.69340e+00 -1.03904e+00 -2.00134e+00  2.38100e-01]
20Nov23_025809| [ 1.26019e+00  9.38744e-01 -3.14317e-01  7.86493e-01  4.76806e-01
20Nov23_025809|  -1.35297e-01  4.23375e-01 -2.08811e+00 -2.33768e-01 -6.56785e-01]
20Nov23_025809| [-1.79324e+00  2.42905e-02  1.37542e+00 -2.27793e+00  2.38915e+00
20Nov23_025809|   1.28801e-01 -1.29803e-01  1.69579e+00 -5.80142e-01  2.11689e+00]
20Nov23_025809| [ 9.34165e-01  7.98905e-01  9.33160e-01  1.26228e+00  8.33572e-01
20Nov23_025809|   8.94453e-01 -1.13623e+00  1.39619e+00 -6.78227e-01  8.70115e-01]
20Nov23_025809| [-1.10950e+00  2.87654e-01  2.71057e-01  8.54796e-01  1.22987e+00
20Nov23_025809|  -1.00751e+00 -5.61214e-01 -6.35672e-02 -9.03112e-01 -7.95657e-01]
20Nov23_025809| [-7.55905e-01  2.91320e-01 -1.58683e+00  5.85932e-01  2.65090e-01
20Nov23_025809|   1.77914e-01 -1.04044e-01 -1.09661e+00  9.38082e-02 -5.58226e-01]
20Nov23_025809| [-9.74231e-01  1.36123e+00 -4.42398e-01  1.01758e-01  3.66514e-01
20Nov23_025809|   1.28179e+00 -1.91686e+00  5.51070e-01  1.15574e+00 -7.07965e-01]
20Nov23_025809| [ 4.46124e-02  5.20958e-01  2.14918e+00  4.16463e-01 -8.15995e-03
20Nov23_025809|   1.50900e+00  2.03955e+00 -3.79312e-01  1.23712e+00 -9.03886e-01]
20Nov23_025809| [ 9.53918e-01 -1.00003e+00  1.67585e+00 -3.41251e+00  1.13867e+00
20Nov23_025809|   3.59439e-01  6.13636e-01 -5.79112e-01  1.84630e-01  1.27094e-01]
20Nov23_025809| [ 5.63295e-01 -7.65227e-01  1.14199e-01 -1.63298e+00  2.84249e-01
20Nov23_025809|  -6.66078e-01 -1.57556e+00  1.00746e+00  7.55489e-01 -9.87647e-01]
20Nov23_025809| [-7.69623e-01 -2.82068e-01  2.51158e+00 -7.90434e-01 -1.54072e+00
20Nov23_025809|   2.29525e+00  3.09859e-01  3.83551e-01 -9.54400e-01  7.70518e-01]
20Nov23_025809| [ 2.04135e+00 -1.89705e+00 -2.04564e+00  1.29505e+00  2.31663e-01
20Nov23_025809|  -1.07668e-01 -1.11612e-01 -4.62865e-01  1.10223e+00  9.01401e-01]
20Nov23_025809| [-6.45809e-01  4.89783e-01  2.17360e+00 -6.88799e-01  1.19751e+00
20Nov23_025809|   1.21721e+00 -2.17834e+00 -5.34672e-01  1.33385e+00 -2.08075e+00]
20Nov23_025809| [-4.18249e+00  1.95307e-01 -7.81067e-01  1.37136e+00 -2.13521e-01
20Nov23_025809|   1.59212e+00 -3.82342e-01  2.63593e+00 -1.00001e+00 -9.22583e-01]
20Nov23_025809| [ 7.01133e-01 -1.13910e+00  1.30671e+00 -5.14959e-01 -2.15790e+00
20Nov23_025809|  -9.44361e-01 -7.67735e-01 -1.24544e+00  1.21896e-01  1.44422e-02]
20Nov23_025809| [-5.05253e-01 -9.48834e-01 -1.35498e+00 -5.44439e-01  4.33973e-01
20Nov23_025809|   1.34650e+00 -1.59928e+00 -9.47020e-01  1.00715e+00 -2.13873e-01]
20Nov23_025809| [-4.95534e-01 -1.37437e-01 -7.25293e-01 -1.79721e+00  1.74471e+00
20Nov23_025809|  -9.68677e-01 -8.56409e-02  1.37133e+00 -7.11811e-01 -8.75033e-01]
20Nov23_025809| [ 1.75287e+00  4.58719e-01  6.66106e-01  1.10149e+00  1.57245e+00
20Nov23_025809|  -6.58958e-01 -7.97523e-01  4.49998e-01 -9.37306e-01  7.24107e-01]
20Nov23_025809| [-6.67339e-02  1.37247e+00  4.27743e-01  3.63566e-01  1.53543e+00
20Nov23_025809|  -2.46799e+00  1.38273e-01  9.09795e-01 -1.63558e+00 -2.33811e+00]
20Nov23_025809| [ 4.74738e-01  1.19072e+00  2.53531e-01  1.60539e+00 -1.19259e+00
20Nov23_025809|   8.16734e-01 -1.06184e+00 -8.57672e-01 -4.20009e-02  2.71981e-01]
20Nov23_025809| [-9.28704e-01  2.61080e+00  7.82101e-01  1.51103e+00 -1.65491e+00
20Nov23_025809|   1.67477e+00  1.27955e+00  9.86971e-01  1.12991e+00 -1.88014e+00]
20Nov23_025809| [-1.83175e+00  2.17081e+00 -1.12905e-01 -7.86976e-01  4.64954e-02
20Nov23_025809|   1.73163e+00 -2.10689e+00  2.17379e-01 -2.19104e+00  2.65990e-01]
20Nov23_025809| [ 5.99832e-01  2.26352e+00 -1.26344e+00  1.67205e+00  1.96797e+00
20Nov23_025809|  -1.04196e+00 -1.17036e+00 -5.82210e-01  3.44470e-01 -6.29446e-01]
20Nov23_025809| [-3.74647e-01  1.57396e+00 -1.23393e+00  1.77755e+00 -1.35559e+00
20Nov23_025809|  -3.50392e-01 -1.51221e+00 -3.50933e-01 -2.21108e+00  2.27891e+00]
20Nov23_025809| [ 1.79899e+00  9.29451e-01 -2.38156e+00 -2.95904e-01  5.01510e-02
20Nov23_025809|  -4.89236e-01 -3.81430e-02 -1.93658e-02 -2.81360e+00 -1.61727e+00]
20Nov23_025809| [-6.31664e-01  1.35179e-02 -8.62988e-01 -1.37577e+00 -1.76862e+00
20Nov23_025809|   7.53411e-01  8.42981e-01 -1.16891e+00 -1.94126e-01  1.64820e+00]
20Nov23_025809| [-9.45281e-01 -1.40671e+00 -2.98803e-01 -9.53509e-01 -7.63614e-01
20Nov23_025809|   3.42849e-02  1.95511e+00  1.79314e+00 -7.97121e-01 -1.37916e+00]
20Nov23_025809| [-1.21675e+00 -1.09576e+00 -3.20845e-01  7.37468e-01 -7.22748e-01
20Nov23_025809|  -4.89459e-01 -1.01331e+00  8.35708e-02  1.66520e-01  4.22179e-01]]
20Nov23_025809|-- Bias --
20Nov23_025809|[ 0.60392 -0.49720 -0.40465 -0.97662 -1.18628 -0.32953 -0.72463  1.47398
20Nov23_025809|  0.64550  0.75190]
20Nov23_025809|Layer 1:
20Nov23_025809|-- Config --
20Nov23_025809|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 10], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025809|-- Weights --
20Nov23_025809|[[-0.21679 -0.45691  0.28378  0.33784]
20Nov23_025809| [ 0.06390  0.16042 -0.55690  0.51363]
20Nov23_025809| [ 0.72633  0.93777 -0.75765  0.12993]
20Nov23_025809| [-0.62302  0.49010 -0.52417 -0.18200]
20Nov23_025809| [ 0.40134 -0.38242 -0.19617 -0.96393]
20Nov23_025809| [ 0.32070 -0.40738 -0.02044 -0.76057]
20Nov23_025809| [-0.43581  0.72040 -0.51486 -0.45397]
20Nov23_025809| [-0.62899 -0.42677 -0.34653 -0.07457]
20Nov23_025809| [-0.53423 -0.35014  0.48800 -0.44973]
20Nov23_025809| [ 0.80919  0.06153 -0.03718  0.65188]]
20Nov23_025809|-- Bias --
20Nov23_025809|[ 0.73864 -0.52503 -0.04894  0.56961]
20Nov23_025809|Layer 2:
20Nov23_025809|-- Config --
20Nov23_025809|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025809|-- Weights --
20Nov23_025809|[[ 0.12699 -0.47567]
20Nov23_025809| [ 1.38134  1.35039]
20Nov23_025809| [ 1.14654  1.78430]
20Nov23_025809| [ 0.41573  1.94888]]
20Nov23_025809|-- Bias --
20Nov23_025809|[ 0.02099 -0.36139]
20Nov23_025809|Predicting the validation and test data with the Best final individual.
20Nov23_025815| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_025815|-----------  ------------------  --------------------  ----------
20Nov23_025815|Validation         41.30                  28            0.02572
20Nov23_025815|   Test            36.40                  28            0.00000
20Nov23_025815|-------------------------- Test #3 --------------------------
20Nov23_025815|Best final individual weights
20Nov23_025815|Individual:
20Nov23_025815|-- Constant hidden layers --
20Nov23_025815|False
20Nov23_025815|Layer 0:
20Nov23_025815|-- Config --
20Nov23_025815|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 10, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025815|-- Weights --
20Nov23_025815|[[-3.07041e-01  1.00616e+00  6.34565e-01 -6.61114e-01 -5.46887e-01
20Nov23_025815|  -1.10888e+00  3.20769e-01 -4.30961e-02 -2.31163e-01  2.22718e+00]
20Nov23_025815| [ 3.40553e-01  8.74817e-01 -1.66864e+00 -7.83743e-01  1.10105e+00
20Nov23_025815|  -1.32534e+00  4.10905e-02  1.12271e+00  6.89412e-01 -1.53065e-01]
20Nov23_025815| [-1.26826e+00  5.87994e-01 -4.60418e-02 -3.55128e+00  1.04805e+00
20Nov23_025815|   1.61174e-01  1.16185e+00  5.66952e-01  6.72490e-01 -6.24827e-01]
20Nov23_025815| [-9.79202e-01  1.61247e-01 -1.27518e+00  5.18034e-01  1.98136e+00
20Nov23_025815|  -6.90936e-01  1.26940e-01  5.58500e-01  1.42756e-01  1.03981e+00]
20Nov23_025815| [-1.82313e-01  3.66685e-01  1.34275e+00  4.58416e-01 -1.18038e+00
20Nov23_025815|   2.51182e-01 -7.15217e-01 -1.66193e-01 -3.14859e-01  1.24005e+00]
20Nov23_025815| [ 1.48738e+00 -3.98929e-01  3.64868e-01  5.40263e-01  5.46416e-02
20Nov23_025815|   1.88146e+00  1.19580e+00 -2.43148e+00 -7.75186e-01 -6.49648e-01]
20Nov23_025815| [ 1.21399e+00  6.66074e-01  1.28060e+00 -6.11337e-01 -2.69644e-01
20Nov23_025815|  -2.53230e-03 -6.20683e-01  8.95056e-01 -1.08596e+00  3.64325e-01]
20Nov23_025815| [ 5.88481e-01  8.60948e-02  4.37503e-01 -1.84663e+00 -7.58324e-01
20Nov23_025815|   7.34596e-01  1.44969e+00 -8.81787e-01 -1.50155e-01 -1.06136e-01]
20Nov23_025815| [ 3.27155e-01  1.36855e+00 -2.04781e+00 -1.57615e+00 -4.51258e-01
20Nov23_025815|   3.02165e-01  6.43490e-01 -1.26883e-01 -5.94848e-01 -2.12811e+00]
20Nov23_025815| [-3.45131e-01 -1.81354e+00 -4.97743e-01  5.71362e-01 -8.54879e-01
20Nov23_025815|   3.65188e-01  1.95065e-01 -2.79676e-01  1.48447e-01  2.43540e-01]
20Nov23_025815| [-5.61218e-01  1.44002e+00  9.06417e-01 -3.99731e-01 -7.36291e-01
20Nov23_025815|  -9.66884e-01 -5.37313e-01 -8.49094e-01 -1.50517e+00  4.55984e-01]
20Nov23_025815| [ 1.70948e+00  8.12685e-01  2.75510e-02 -1.86415e+00 -1.60141e+00
20Nov23_025815|  -8.75582e-01 -8.89810e-01  5.20086e-01  7.91316e-01 -1.36802e+00]
20Nov23_025815| [-2.14098e-01  2.45515e-01  2.56778e-01  2.97405e-01 -1.38597e+00
20Nov23_025815|  -5.00160e-01  6.20253e-01 -7.58286e-01  3.35205e-01 -3.43907e+00]
20Nov23_025815| [ 4.03195e-01 -1.20324e-01  1.13366e+00  8.88009e-01 -9.37896e-03
20Nov23_025815|  -2.86522e-01  1.67710e+00  5.86515e-01 -1.06572e+00  1.39802e+00]
20Nov23_025815| [ 6.48180e-01 -1.92738e+00  1.50417e-02  8.68537e-02 -1.13786e+00
20Nov23_025815|  -1.29129e+00 -6.92839e-01 -1.40458e+00 -8.00986e-01  8.15326e-01]
20Nov23_025815| [ 1.57969e+00 -1.30609e-01 -1.29681e-01  1.04108e+00 -1.55760e+00
20Nov23_025815|  -1.01726e+00 -7.49064e-02  1.91418e-01  1.13480e+00 -1.29247e+00]
20Nov23_025815| [ 6.05486e-01 -1.20667e+00  1.83863e+00  1.62026e+00 -1.21907e+00
20Nov23_025815|  -1.85861e+00  6.32947e-01 -6.56312e-01 -1.96676e+00  9.10422e-01]
20Nov23_025815| [-1.17272e+00  1.65220e+00 -1.03529e+00 -8.72294e-02  2.90430e-01
20Nov23_025815|  -2.34656e+00  3.19297e-01 -1.87314e+00  5.04493e-01  4.65741e-01]
20Nov23_025815| [-9.48481e-02 -2.33962e-02 -5.93975e-02  3.19555e-02  3.49339e-01
20Nov23_025815|   6.49964e-01  6.53861e-01  8.66293e-01 -1.16838e+00 -9.17614e-01]
20Nov23_025815| [ 1.19783e+00  3.25987e-01  1.37329e+00  8.63944e-01 -9.03486e-01
20Nov23_025815|   1.38840e+00  1.49831e+00  1.17810e+00 -2.68505e+00  1.62729e+00]
20Nov23_025815| [-1.58344e+00 -2.33544e-01  8.36162e-01 -2.18260e+00 -1.15138e+00
20Nov23_025815|   1.45939e+00 -1.13930e+00 -3.86267e-01 -4.73407e-01 -9.27712e-01]
20Nov23_025815| [ 4.40150e-01 -1.15269e+00  3.37421e-01 -6.98225e-01  2.17269e+00
20Nov23_025815|   9.63798e-01 -1.43930e+00  1.71663e+00  7.51493e-01 -6.28456e-01]
20Nov23_025815| [-1.58838e+00  1.79189e+00  5.00478e-01 -1.25010e+00  7.03498e-01
20Nov23_025815|  -6.38268e-01  1.20227e+00  1.08421e+00  8.40502e-01  2.02490e+00]
20Nov23_025815| [ 3.67353e-01 -6.31589e-04  1.27834e+00 -1.39200e+00 -1.15876e+00
20Nov23_025815|   1.53865e+00 -7.44091e-01  4.73619e-01  2.04884e+00  1.62277e+00]
20Nov23_025815| [-1.55578e+00  1.55922e+00 -6.26084e-02  1.27440e+00  7.76317e-01
20Nov23_025815|  -3.31071e-01 -8.12146e-01  5.32258e-01 -1.03204e-01  5.74448e-01]
20Nov23_025815| [-1.66080e-01  9.27591e-01 -8.26749e-01 -2.02630e+00 -1.69057e+00
20Nov23_025815|   1.57038e+00 -9.36829e-01 -8.09723e-02 -1.40559e+00 -4.68670e-01]
20Nov23_025815| [ 1.31585e+00 -1.35879e+00  6.69832e-02 -6.76034e-01 -7.78053e-02
20Nov23_025815|   9.15890e-01 -2.57551e+00  1.17206e+00 -1.63833e-01 -1.51976e+00]
20Nov23_025815| [ 3.86571e-01  3.76960e-01  1.62203e+00 -6.63494e-01  5.79448e-01
20Nov23_025815|  -2.02899e-01  6.20663e-01 -8.74604e-01  5.65300e-01 -4.78021e-01]
20Nov23_025815| [ 2.84392e-01 -1.30287e+00 -2.40568e-01  1.64154e+00  8.57175e-01
20Nov23_025815|   1.66324e+00 -7.58044e-01  9.58194e-01  1.08895e+00  6.87897e-01]
20Nov23_025815| [ 1.91543e+00 -8.14252e-01 -8.52032e-01  3.78664e-01  1.90764e+00
20Nov23_025815|  -4.47222e-01 -2.69340e+00 -1.03904e+00 -2.00134e+00  2.38100e-01]
20Nov23_025815| [ 1.26019e+00  9.38744e-01 -3.14317e-01  7.86493e-01  4.76806e-01
20Nov23_025815|  -1.35297e-01  4.23375e-01 -2.08811e+00 -2.33768e-01 -6.56785e-01]
20Nov23_025815| [-1.79324e+00  2.42905e-02  1.37542e+00 -2.27793e+00  2.38915e+00
20Nov23_025815|   1.28801e-01 -1.29803e-01  1.69579e+00 -5.80142e-01  2.11689e+00]
20Nov23_025815| [ 9.34165e-01  7.98905e-01  9.33160e-01  1.26228e+00  8.33572e-01
20Nov23_025815|   8.94453e-01 -1.13623e+00  1.39619e+00 -6.78227e-01  8.70115e-01]
20Nov23_025815| [-1.10950e+00  2.87654e-01  2.71057e-01  8.54796e-01  1.22987e+00
20Nov23_025815|  -1.00751e+00 -5.61214e-01 -6.35672e-02 -9.03112e-01 -7.95657e-01]
20Nov23_025815| [-7.55905e-01  2.91320e-01 -1.58683e+00  5.85932e-01  2.65090e-01
20Nov23_025815|   1.77914e-01 -1.04044e-01 -1.09661e+00  9.38082e-02 -5.58226e-01]
20Nov23_025815| [-9.74231e-01  1.36123e+00 -4.42398e-01  1.01758e-01  3.66514e-01
20Nov23_025815|   1.28179e+00 -1.91686e+00  5.51070e-01  1.15574e+00 -7.07965e-01]
20Nov23_025815| [ 4.46124e-02  5.20958e-01  2.14918e+00  4.16463e-01 -8.15995e-03
20Nov23_025815|   1.50900e+00  2.03955e+00 -3.79312e-01  1.23712e+00 -9.03886e-01]
20Nov23_025815| [ 9.53918e-01 -1.00003e+00  1.67585e+00 -3.41251e+00  1.13867e+00
20Nov23_025815|   3.59439e-01  6.13636e-01 -5.79112e-01  1.84630e-01  1.27094e-01]
20Nov23_025815| [ 5.63295e-01 -7.65227e-01  1.14199e-01 -1.63298e+00  2.84249e-01
20Nov23_025815|  -6.66078e-01 -1.57556e+00  1.00746e+00  7.55489e-01 -9.87647e-01]
20Nov23_025815| [-7.69623e-01 -2.82068e-01  2.51158e+00 -7.90434e-01 -1.54072e+00
20Nov23_025815|   2.29525e+00  3.09859e-01  3.83551e-01 -9.54400e-01  7.70518e-01]
20Nov23_025815| [ 2.04135e+00 -1.89705e+00 -2.04564e+00  1.29505e+00  2.31663e-01
20Nov23_025815|  -1.07668e-01 -1.11612e-01 -4.62865e-01  1.10223e+00  9.01401e-01]
20Nov23_025815| [-6.45809e-01  4.89783e-01  2.17360e+00 -6.88799e-01  1.19751e+00
20Nov23_025815|   1.21721e+00 -2.17834e+00 -5.34672e-01  1.33385e+00 -2.08075e+00]
20Nov23_025815| [-4.18249e+00  1.95307e-01 -7.81067e-01  1.37136e+00 -2.13521e-01
20Nov23_025815|   1.59212e+00 -3.82342e-01  2.63593e+00 -1.00001e+00 -9.22583e-01]
20Nov23_025815| [ 7.01133e-01 -1.13910e+00  1.30671e+00 -5.14959e-01 -2.15790e+00
20Nov23_025815|  -9.44361e-01 -7.67735e-01 -1.24544e+00  1.21896e-01  1.44422e-02]
20Nov23_025815| [-5.05253e-01 -9.48834e-01 -1.35498e+00 -5.44439e-01  4.33973e-01
20Nov23_025815|   1.34650e+00 -1.59928e+00 -9.47020e-01  1.00715e+00 -2.13873e-01]
20Nov23_025815| [-4.95534e-01 -1.37437e-01 -7.25293e-01 -1.79721e+00  1.74471e+00
20Nov23_025815|  -9.68677e-01 -8.56409e-02  1.37133e+00 -7.11811e-01 -8.75033e-01]
20Nov23_025815| [ 1.75287e+00  4.58719e-01  6.66106e-01  1.10149e+00  1.57245e+00
20Nov23_025815|  -6.58958e-01 -7.97523e-01  4.49998e-01 -9.37306e-01  7.24107e-01]
20Nov23_025815| [-6.67339e-02  1.37247e+00  4.27743e-01  3.63566e-01  1.53543e+00
20Nov23_025815|  -2.46799e+00  1.38273e-01  9.09795e-01 -1.63558e+00 -2.33811e+00]
20Nov23_025815| [ 4.74738e-01  1.19072e+00  2.53531e-01  1.60539e+00 -1.19259e+00
20Nov23_025815|   8.16734e-01 -1.06184e+00 -8.57672e-01 -4.20009e-02  2.71981e-01]
20Nov23_025815| [-9.28704e-01  2.61080e+00  7.82101e-01  1.51103e+00 -1.65491e+00
20Nov23_025815|   1.67477e+00  1.27955e+00  9.86971e-01  1.12991e+00 -1.88014e+00]
20Nov23_025815| [-1.83175e+00  2.17081e+00 -1.12905e-01 -7.86976e-01  4.64954e-02
20Nov23_025815|   1.73163e+00 -2.10689e+00  2.17379e-01 -2.19104e+00  2.65990e-01]
20Nov23_025815| [ 5.99832e-01  2.26352e+00 -1.26344e+00  1.67205e+00  1.96797e+00
20Nov23_025815|  -1.04196e+00 -1.17036e+00 -5.82210e-01  3.44470e-01 -6.29446e-01]
20Nov23_025815| [-3.74647e-01  1.57396e+00 -1.23393e+00  1.77755e+00 -1.35559e+00
20Nov23_025815|  -3.50392e-01 -1.51221e+00 -3.50933e-01 -2.21108e+00  2.27891e+00]
20Nov23_025815| [ 1.79899e+00  9.29451e-01 -2.38156e+00 -2.95904e-01  5.01510e-02
20Nov23_025815|  -4.89236e-01 -3.81430e-02 -1.93658e-02 -2.81360e+00 -1.61727e+00]
20Nov23_025815| [-6.31664e-01  1.35179e-02 -8.62988e-01 -1.37577e+00 -1.76862e+00
20Nov23_025815|   7.53411e-01  8.42981e-01 -1.16891e+00 -1.94126e-01  1.64820e+00]
20Nov23_025815| [-9.45281e-01 -1.40671e+00 -2.98803e-01 -9.53509e-01 -7.63614e-01
20Nov23_025815|   3.42849e-02  1.95511e+00  1.79314e+00 -7.97121e-01 -1.37916e+00]
20Nov23_025815| [-1.21675e+00 -1.09576e+00 -3.20845e-01  7.37468e-01 -7.22748e-01
20Nov23_025815|  -4.89459e-01 -1.01331e+00  8.35708e-02  1.66520e-01  4.22179e-01]]
20Nov23_025815|-- Bias --
20Nov23_025815|[ 0.60392 -0.49720 -0.40465 -0.97662 -1.18628 -0.32953 -0.72463  1.47398
20Nov23_025815|  0.64550  0.75190]
20Nov23_025815|Layer 1:
20Nov23_025815|-- Config --
20Nov23_025815|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 10], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025815|-- Weights --
20Nov23_025815|[[-0.21679 -0.45691  0.28378  0.33784]
20Nov23_025815| [ 0.06390  0.16042 -0.55690  0.51363]
20Nov23_025815| [ 0.72633  0.93777 -0.75765  0.12993]
20Nov23_025815| [-0.62302  0.49010 -0.52417 -0.18200]
20Nov23_025815| [ 0.40134 -0.38242 -0.19617 -0.96393]
20Nov23_025815| [ 0.32070 -0.40738 -0.02044 -0.76057]
20Nov23_025815| [-0.43581  0.72040 -0.51486 -0.45397]
20Nov23_025815| [-0.62899 -0.42677 -0.34653 -0.07457]
20Nov23_025815| [-0.53423 -0.35014  0.48800 -0.44973]
20Nov23_025815| [ 0.80919  0.06153 -0.03718  0.65188]]
20Nov23_025815|-- Bias --
20Nov23_025815|[ 0.73864 -0.52503 -0.04894  0.56961]
20Nov23_025815|Layer 2:
20Nov23_025815|-- Config --
20Nov23_025815|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025815|-- Weights --
20Nov23_025815|[[ 0.12699 -0.47567]
20Nov23_025815| [ 1.38134  1.35039]
20Nov23_025815| [ 1.14654  1.78430]
20Nov23_025815| [ 0.41573  1.94888]]
20Nov23_025815|-- Bias --
20Nov23_025815|[ 0.02099 -0.36139]
20Nov23_025815|Predicting the validation and test data with the Best final individual.
20Nov23_025821| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_025821|-----------  ------------------  --------------------  ----------
20Nov23_025821|Validation         44.00                  28            0.71689
20Nov23_025821|   Test            36.40                  28            0.00000
20Nov23_025821|-------------------------- Test #4 --------------------------
20Nov23_025821|Best final individual weights
20Nov23_025821|Individual:
20Nov23_025821|-- Constant hidden layers --
20Nov23_025821|False
20Nov23_025821|Layer 0:
20Nov23_025821|-- Config --
20Nov23_025821|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 10, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025821|-- Weights --
20Nov23_025821|[[-3.07041e-01  1.00616e+00  6.34565e-01 -6.61114e-01 -5.46887e-01
20Nov23_025821|  -1.10888e+00  3.20769e-01 -4.30961e-02 -2.31163e-01  2.22718e+00]
20Nov23_025821| [ 3.40553e-01  8.74817e-01 -1.66864e+00 -7.83743e-01  1.10105e+00
20Nov23_025821|  -1.32534e+00  4.10905e-02  1.12271e+00  6.89412e-01 -1.53065e-01]
20Nov23_025821| [-1.26826e+00  5.87994e-01 -4.60418e-02 -3.55128e+00  1.04805e+00
20Nov23_025821|   1.61174e-01  1.16185e+00  5.66952e-01  6.72490e-01 -6.24827e-01]
20Nov23_025821| [-9.79202e-01  1.61247e-01 -1.27518e+00  5.18034e-01  1.98136e+00
20Nov23_025821|  -6.90936e-01  1.26940e-01  5.58500e-01  1.42756e-01  1.03981e+00]
20Nov23_025821| [-1.82313e-01  3.66685e-01  1.34275e+00  4.58416e-01 -1.18038e+00
20Nov23_025821|   2.51182e-01 -7.15217e-01 -1.66193e-01 -3.14859e-01  1.24005e+00]
20Nov23_025821| [ 1.48738e+00 -3.98929e-01  3.64868e-01  5.40263e-01  5.46416e-02
20Nov23_025821|   1.88146e+00  1.19580e+00 -2.43148e+00 -7.75186e-01 -6.49648e-01]
20Nov23_025821| [ 1.21399e+00  6.66074e-01  1.28060e+00 -6.11337e-01 -2.69644e-01
20Nov23_025821|  -2.53230e-03 -6.20683e-01  8.95056e-01 -1.08596e+00  3.64325e-01]
20Nov23_025821| [ 5.88481e-01  8.60948e-02  4.37503e-01 -1.84663e+00 -7.58324e-01
20Nov23_025821|   7.34596e-01  1.44969e+00 -8.81787e-01 -1.50155e-01 -1.06136e-01]
20Nov23_025821| [ 3.27155e-01  1.36855e+00 -2.04781e+00 -1.57615e+00 -4.51258e-01
20Nov23_025821|   3.02165e-01  6.43490e-01 -1.26883e-01 -5.94848e-01 -2.12811e+00]
20Nov23_025821| [-3.45131e-01 -1.81354e+00 -4.97743e-01  5.71362e-01 -8.54879e-01
20Nov23_025821|   3.65188e-01  1.95065e-01 -2.79676e-01  1.48447e-01  2.43540e-01]
20Nov23_025821| [-5.61218e-01  1.44002e+00  9.06417e-01 -3.99731e-01 -7.36291e-01
20Nov23_025821|  -9.66884e-01 -5.37313e-01 -8.49094e-01 -1.50517e+00  4.55984e-01]
20Nov23_025821| [ 1.70948e+00  8.12685e-01  2.75510e-02 -1.86415e+00 -1.60141e+00
20Nov23_025821|  -8.75582e-01 -8.89810e-01  5.20086e-01  7.91316e-01 -1.36802e+00]
20Nov23_025821| [-2.14098e-01  2.45515e-01  2.56778e-01  2.97405e-01 -1.38597e+00
20Nov23_025821|  -5.00160e-01  6.20253e-01 -7.58286e-01  3.35205e-01 -3.43907e+00]
20Nov23_025821| [ 4.03195e-01 -1.20324e-01  1.13366e+00  8.88009e-01 -9.37896e-03
20Nov23_025821|  -2.86522e-01  1.67710e+00  5.86515e-01 -1.06572e+00  1.39802e+00]
20Nov23_025821| [ 6.48180e-01 -1.92738e+00  1.50417e-02  8.68537e-02 -1.13786e+00
20Nov23_025821|  -1.29129e+00 -6.92839e-01 -1.40458e+00 -8.00986e-01  8.15326e-01]
20Nov23_025821| [ 1.57969e+00 -1.30609e-01 -1.29681e-01  1.04108e+00 -1.55760e+00
20Nov23_025821|  -1.01726e+00 -7.49064e-02  1.91418e-01  1.13480e+00 -1.29247e+00]
20Nov23_025821| [ 6.05486e-01 -1.20667e+00  1.83863e+00  1.62026e+00 -1.21907e+00
20Nov23_025821|  -1.85861e+00  6.32947e-01 -6.56312e-01 -1.96676e+00  9.10422e-01]
20Nov23_025821| [-1.17272e+00  1.65220e+00 -1.03529e+00 -8.72294e-02  2.90430e-01
20Nov23_025821|  -2.34656e+00  3.19297e-01 -1.87314e+00  5.04493e-01  4.65741e-01]
20Nov23_025821| [-9.48481e-02 -2.33962e-02 -5.93975e-02  3.19555e-02  3.49339e-01
20Nov23_025821|   6.49964e-01  6.53861e-01  8.66293e-01 -1.16838e+00 -9.17614e-01]
20Nov23_025821| [ 1.19783e+00  3.25987e-01  1.37329e+00  8.63944e-01 -9.03486e-01
20Nov23_025821|   1.38840e+00  1.49831e+00  1.17810e+00 -2.68505e+00  1.62729e+00]
20Nov23_025821| [-1.58344e+00 -2.33544e-01  8.36162e-01 -2.18260e+00 -1.15138e+00
20Nov23_025821|   1.45939e+00 -1.13930e+00 -3.86267e-01 -4.73407e-01 -9.27712e-01]
20Nov23_025821| [ 4.40150e-01 -1.15269e+00  3.37421e-01 -6.98225e-01  2.17269e+00
20Nov23_025821|   9.63798e-01 -1.43930e+00  1.71663e+00  7.51493e-01 -6.28456e-01]
20Nov23_025821| [-1.58838e+00  1.79189e+00  5.00478e-01 -1.25010e+00  7.03498e-01
20Nov23_025821|  -6.38268e-01  1.20227e+00  1.08421e+00  8.40502e-01  2.02490e+00]
20Nov23_025821| [ 3.67353e-01 -6.31589e-04  1.27834e+00 -1.39200e+00 -1.15876e+00
20Nov23_025821|   1.53865e+00 -7.44091e-01  4.73619e-01  2.04884e+00  1.62277e+00]
20Nov23_025821| [-1.55578e+00  1.55922e+00 -6.26084e-02  1.27440e+00  7.76317e-01
20Nov23_025821|  -3.31071e-01 -8.12146e-01  5.32258e-01 -1.03204e-01  5.74448e-01]
20Nov23_025821| [-1.66080e-01  9.27591e-01 -8.26749e-01 -2.02630e+00 -1.69057e+00
20Nov23_025821|   1.57038e+00 -9.36829e-01 -8.09723e-02 -1.40559e+00 -4.68670e-01]
20Nov23_025821| [ 1.31585e+00 -1.35879e+00  6.69832e-02 -6.76034e-01 -7.78053e-02
20Nov23_025821|   9.15890e-01 -2.57551e+00  1.17206e+00 -1.63833e-01 -1.51976e+00]
20Nov23_025821| [ 3.86571e-01  3.76960e-01  1.62203e+00 -6.63494e-01  5.79448e-01
20Nov23_025821|  -2.02899e-01  6.20663e-01 -8.74604e-01  5.65300e-01 -4.78021e-01]
20Nov23_025821| [ 2.84392e-01 -1.30287e+00 -2.40568e-01  1.64154e+00  8.57175e-01
20Nov23_025821|   1.66324e+00 -7.58044e-01  9.58194e-01  1.08895e+00  6.87897e-01]
20Nov23_025821| [ 1.91543e+00 -8.14252e-01 -8.52032e-01  3.78664e-01  1.90764e+00
20Nov23_025821|  -4.47222e-01 -2.69340e+00 -1.03904e+00 -2.00134e+00  2.38100e-01]
20Nov23_025821| [ 1.26019e+00  9.38744e-01 -3.14317e-01  7.86493e-01  4.76806e-01
20Nov23_025821|  -1.35297e-01  4.23375e-01 -2.08811e+00 -2.33768e-01 -6.56785e-01]
20Nov23_025821| [-1.79324e+00  2.42905e-02  1.37542e+00 -2.27793e+00  2.38915e+00
20Nov23_025821|   1.28801e-01 -1.29803e-01  1.69579e+00 -5.80142e-01  2.11689e+00]
20Nov23_025821| [ 9.34165e-01  7.98905e-01  9.33160e-01  1.26228e+00  8.33572e-01
20Nov23_025821|   8.94453e-01 -1.13623e+00  1.39619e+00 -6.78227e-01  8.70115e-01]
20Nov23_025821| [-1.10950e+00  2.87654e-01  2.71057e-01  8.54796e-01  1.22987e+00
20Nov23_025821|  -1.00751e+00 -5.61214e-01 -6.35672e-02 -9.03112e-01 -7.95657e-01]
20Nov23_025821| [-7.55905e-01  2.91320e-01 -1.58683e+00  5.85932e-01  2.65090e-01
20Nov23_025821|   1.77914e-01 -1.04044e-01 -1.09661e+00  9.38082e-02 -5.58226e-01]
20Nov23_025821| [-9.74231e-01  1.36123e+00 -4.42398e-01  1.01758e-01  3.66514e-01
20Nov23_025821|   1.28179e+00 -1.91686e+00  5.51070e-01  1.15574e+00 -7.07965e-01]
20Nov23_025821| [ 4.46124e-02  5.20958e-01  2.14918e+00  4.16463e-01 -8.15995e-03
20Nov23_025821|   1.50900e+00  2.03955e+00 -3.79312e-01  1.23712e+00 -9.03886e-01]
20Nov23_025821| [ 9.53918e-01 -1.00003e+00  1.67585e+00 -3.41251e+00  1.13867e+00
20Nov23_025821|   3.59439e-01  6.13636e-01 -5.79112e-01  1.84630e-01  1.27094e-01]
20Nov23_025821| [ 5.63295e-01 -7.65227e-01  1.14199e-01 -1.63298e+00  2.84249e-01
20Nov23_025821|  -6.66078e-01 -1.57556e+00  1.00746e+00  7.55489e-01 -9.87647e-01]
20Nov23_025821| [-7.69623e-01 -2.82068e-01  2.51158e+00 -7.90434e-01 -1.54072e+00
20Nov23_025821|   2.29525e+00  3.09859e-01  3.83551e-01 -9.54400e-01  7.70518e-01]
20Nov23_025821| [ 2.04135e+00 -1.89705e+00 -2.04564e+00  1.29505e+00  2.31663e-01
20Nov23_025821|  -1.07668e-01 -1.11612e-01 -4.62865e-01  1.10223e+00  9.01401e-01]
20Nov23_025821| [-6.45809e-01  4.89783e-01  2.17360e+00 -6.88799e-01  1.19751e+00
20Nov23_025821|   1.21721e+00 -2.17834e+00 -5.34672e-01  1.33385e+00 -2.08075e+00]
20Nov23_025821| [-4.18249e+00  1.95307e-01 -7.81067e-01  1.37136e+00 -2.13521e-01
20Nov23_025821|   1.59212e+00 -3.82342e-01  2.63593e+00 -1.00001e+00 -9.22583e-01]
20Nov23_025821| [ 7.01133e-01 -1.13910e+00  1.30671e+00 -5.14959e-01 -2.15790e+00
20Nov23_025821|  -9.44361e-01 -7.67735e-01 -1.24544e+00  1.21896e-01  1.44422e-02]
20Nov23_025821| [-5.05253e-01 -9.48834e-01 -1.35498e+00 -5.44439e-01  4.33973e-01
20Nov23_025821|   1.34650e+00 -1.59928e+00 -9.47020e-01  1.00715e+00 -2.13873e-01]
20Nov23_025821| [-4.95534e-01 -1.37437e-01 -7.25293e-01 -1.79721e+00  1.74471e+00
20Nov23_025821|  -9.68677e-01 -8.56409e-02  1.37133e+00 -7.11811e-01 -8.75033e-01]
20Nov23_025821| [ 1.75287e+00  4.58719e-01  6.66106e-01  1.10149e+00  1.57245e+00
20Nov23_025821|  -6.58958e-01 -7.97523e-01  4.49998e-01 -9.37306e-01  7.24107e-01]
20Nov23_025821| [-6.67339e-02  1.37247e+00  4.27743e-01  3.63566e-01  1.53543e+00
20Nov23_025821|  -2.46799e+00  1.38273e-01  9.09795e-01 -1.63558e+00 -2.33811e+00]
20Nov23_025821| [ 4.74738e-01  1.19072e+00  2.53531e-01  1.60539e+00 -1.19259e+00
20Nov23_025821|   8.16734e-01 -1.06184e+00 -8.57672e-01 -4.20009e-02  2.71981e-01]
20Nov23_025821| [-9.28704e-01  2.61080e+00  7.82101e-01  1.51103e+00 -1.65491e+00
20Nov23_025821|   1.67477e+00  1.27955e+00  9.86971e-01  1.12991e+00 -1.88014e+00]
20Nov23_025821| [-1.83175e+00  2.17081e+00 -1.12905e-01 -7.86976e-01  4.64954e-02
20Nov23_025821|   1.73163e+00 -2.10689e+00  2.17379e-01 -2.19104e+00  2.65990e-01]
20Nov23_025821| [ 5.99832e-01  2.26352e+00 -1.26344e+00  1.67205e+00  1.96797e+00
20Nov23_025821|  -1.04196e+00 -1.17036e+00 -5.82210e-01  3.44470e-01 -6.29446e-01]
20Nov23_025821| [-3.74647e-01  1.57396e+00 -1.23393e+00  1.77755e+00 -1.35559e+00
20Nov23_025821|  -3.50392e-01 -1.51221e+00 -3.50933e-01 -2.21108e+00  2.27891e+00]
20Nov23_025821| [ 1.79899e+00  9.29451e-01 -2.38156e+00 -2.95904e-01  5.01510e-02
20Nov23_025821|  -4.89236e-01 -3.81430e-02 -1.93658e-02 -2.81360e+00 -1.61727e+00]
20Nov23_025821| [-6.31664e-01  1.35179e-02 -8.62988e-01 -1.37577e+00 -1.76862e+00
20Nov23_025821|   7.53411e-01  8.42981e-01 -1.16891e+00 -1.94126e-01  1.64820e+00]
20Nov23_025821| [-9.45281e-01 -1.40671e+00 -2.98803e-01 -9.53509e-01 -7.63614e-01
20Nov23_025821|   3.42849e-02  1.95511e+00  1.79314e+00 -7.97121e-01 -1.37916e+00]
20Nov23_025821| [-1.21675e+00 -1.09576e+00 -3.20845e-01  7.37468e-01 -7.22748e-01
20Nov23_025821|  -4.89459e-01 -1.01331e+00  8.35708e-02  1.66520e-01  4.22179e-01]]
20Nov23_025821|-- Bias --
20Nov23_025821|[ 0.60392 -0.49720 -0.40465 -0.97662 -1.18628 -0.32953 -0.72463  1.47398
20Nov23_025821|  0.64550  0.75190]
20Nov23_025821|Layer 1:
20Nov23_025821|-- Config --
20Nov23_025821|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 10], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025821|-- Weights --
20Nov23_025821|[[-0.21679 -0.45691  0.28378  0.33784]
20Nov23_025821| [ 0.06390  0.16042 -0.55690  0.51363]
20Nov23_025821| [ 0.72633  0.93777 -0.75765  0.12993]
20Nov23_025821| [-0.62302  0.49010 -0.52417 -0.18200]
20Nov23_025821| [ 0.40134 -0.38242 -0.19617 -0.96393]
20Nov23_025821| [ 0.32070 -0.40738 -0.02044 -0.76057]
20Nov23_025821| [-0.43581  0.72040 -0.51486 -0.45397]
20Nov23_025821| [-0.62899 -0.42677 -0.34653 -0.07457]
20Nov23_025821| [-0.53423 -0.35014  0.48800 -0.44973]
20Nov23_025821| [ 0.80919  0.06153 -0.03718  0.65188]]
20Nov23_025821|-- Bias --
20Nov23_025821|[ 0.73864 -0.52503 -0.04894  0.56961]
20Nov23_025821|Layer 2:
20Nov23_025821|-- Config --
20Nov23_025821|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025821|-- Weights --
20Nov23_025821|[[ 0.12699 -0.47567]
20Nov23_025821| [ 1.38134  1.35039]
20Nov23_025821| [ 1.14654  1.78430]
20Nov23_025821| [ 0.41573  1.94888]]
20Nov23_025821|-- Bias --
20Nov23_025821|[ 0.02099 -0.36139]
20Nov23_025821|Predicting the validation and test data with the Best final individual.
20Nov23_025827| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_025827|-----------  ------------------  --------------------  ----------
20Nov23_025827|Validation         42.00                  28            0.00000
20Nov23_025827|   Test            36.49                  28            0.00000
20Nov23_025827|-------------------------- Test #5 --------------------------
20Nov23_025827|Best final individual weights
20Nov23_025827|Individual:
20Nov23_025827|-- Constant hidden layers --
20Nov23_025827|False
20Nov23_025827|Layer 0:
20Nov23_025827|-- Config --
20Nov23_025827|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 10, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025827|-- Weights --
20Nov23_025827|[[-3.07041e-01  1.00616e+00  6.34565e-01 -6.61114e-01 -5.46887e-01
20Nov23_025827|  -1.10888e+00  3.20769e-01 -4.30961e-02 -2.31163e-01  2.22718e+00]
20Nov23_025827| [ 3.40553e-01  8.74817e-01 -1.66864e+00 -7.83743e-01  1.10105e+00
20Nov23_025827|  -1.32534e+00  4.10905e-02  1.12271e+00  6.89412e-01 -1.53065e-01]
20Nov23_025827| [-1.26826e+00  5.87994e-01 -4.60418e-02 -3.55128e+00  1.04805e+00
20Nov23_025827|   1.61174e-01  1.16185e+00  5.66952e-01  6.72490e-01 -6.24827e-01]
20Nov23_025827| [-9.79202e-01  1.61247e-01 -1.27518e+00  5.18034e-01  1.98136e+00
20Nov23_025827|  -6.90936e-01  1.26940e-01  5.58500e-01  1.42756e-01  1.03981e+00]
20Nov23_025827| [-1.82313e-01  3.66685e-01  1.34275e+00  4.58416e-01 -1.18038e+00
20Nov23_025827|   2.51182e-01 -7.15217e-01 -1.66193e-01 -3.14859e-01  1.24005e+00]
20Nov23_025827| [ 1.48738e+00 -3.98929e-01  3.64868e-01  5.40263e-01  5.46416e-02
20Nov23_025827|   1.88146e+00  1.19580e+00 -2.43148e+00 -7.75186e-01 -6.49648e-01]
20Nov23_025827| [ 1.21399e+00  6.66074e-01  1.28060e+00 -6.11337e-01 -2.69644e-01
20Nov23_025827|  -2.53230e-03 -6.20683e-01  8.95056e-01 -1.08596e+00  3.64325e-01]
20Nov23_025827| [ 5.88481e-01  8.60948e-02  4.37503e-01 -1.84663e+00 -7.58324e-01
20Nov23_025827|   7.34596e-01  1.44969e+00 -8.81787e-01 -1.50155e-01 -1.06136e-01]
20Nov23_025827| [ 3.27155e-01  1.36855e+00 -2.04781e+00 -1.57615e+00 -4.51258e-01
20Nov23_025827|   3.02165e-01  6.43490e-01 -1.26883e-01 -5.94848e-01 -2.12811e+00]
20Nov23_025827| [-3.45131e-01 -1.81354e+00 -4.97743e-01  5.71362e-01 -8.54879e-01
20Nov23_025827|   3.65188e-01  1.95065e-01 -2.79676e-01  1.48447e-01  2.43540e-01]
20Nov23_025827| [-5.61218e-01  1.44002e+00  9.06417e-01 -3.99731e-01 -7.36291e-01
20Nov23_025827|  -9.66884e-01 -5.37313e-01 -8.49094e-01 -1.50517e+00  4.55984e-01]
20Nov23_025827| [ 1.70948e+00  8.12685e-01  2.75510e-02 -1.86415e+00 -1.60141e+00
20Nov23_025827|  -8.75582e-01 -8.89810e-01  5.20086e-01  7.91316e-01 -1.36802e+00]
20Nov23_025827| [-2.14098e-01  2.45515e-01  2.56778e-01  2.97405e-01 -1.38597e+00
20Nov23_025827|  -5.00160e-01  6.20253e-01 -7.58286e-01  3.35205e-01 -3.43907e+00]
20Nov23_025827| [ 4.03195e-01 -1.20324e-01  1.13366e+00  8.88009e-01 -9.37896e-03
20Nov23_025827|  -2.86522e-01  1.67710e+00  5.86515e-01 -1.06572e+00  1.39802e+00]
20Nov23_025827| [ 6.48180e-01 -1.92738e+00  1.50417e-02  8.68537e-02 -1.13786e+00
20Nov23_025827|  -1.29129e+00 -6.92839e-01 -1.40458e+00 -8.00986e-01  8.15326e-01]
20Nov23_025827| [ 1.57969e+00 -1.30609e-01 -1.29681e-01  1.04108e+00 -1.55760e+00
20Nov23_025827|  -1.01726e+00 -7.49064e-02  1.91418e-01  1.13480e+00 -1.29247e+00]
20Nov23_025827| [ 6.05486e-01 -1.20667e+00  1.83863e+00  1.62026e+00 -1.21907e+00
20Nov23_025827|  -1.85861e+00  6.32947e-01 -6.56312e-01 -1.96676e+00  9.10422e-01]
20Nov23_025827| [-1.17272e+00  1.65220e+00 -1.03529e+00 -8.72294e-02  2.90430e-01
20Nov23_025827|  -2.34656e+00  3.19297e-01 -1.87314e+00  5.04493e-01  4.65741e-01]
20Nov23_025827| [-9.48481e-02 -2.33962e-02 -5.93975e-02  3.19555e-02  3.49339e-01
20Nov23_025827|   6.49964e-01  6.53861e-01  8.66293e-01 -1.16838e+00 -9.17614e-01]
20Nov23_025827| [ 1.19783e+00  3.25987e-01  1.37329e+00  8.63944e-01 -9.03486e-01
20Nov23_025827|   1.38840e+00  1.49831e+00  1.17810e+00 -2.68505e+00  1.62729e+00]
20Nov23_025827| [-1.58344e+00 -2.33544e-01  8.36162e-01 -2.18260e+00 -1.15138e+00
20Nov23_025827|   1.45939e+00 -1.13930e+00 -3.86267e-01 -4.73407e-01 -9.27712e-01]
20Nov23_025827| [ 4.40150e-01 -1.15269e+00  3.37421e-01 -6.98225e-01  2.17269e+00
20Nov23_025827|   9.63798e-01 -1.43930e+00  1.71663e+00  7.51493e-01 -6.28456e-01]
20Nov23_025827| [-1.58838e+00  1.79189e+00  5.00478e-01 -1.25010e+00  7.03498e-01
20Nov23_025827|  -6.38268e-01  1.20227e+00  1.08421e+00  8.40502e-01  2.02490e+00]
20Nov23_025827| [ 3.67353e-01 -6.31589e-04  1.27834e+00 -1.39200e+00 -1.15876e+00
20Nov23_025827|   1.53865e+00 -7.44091e-01  4.73619e-01  2.04884e+00  1.62277e+00]
20Nov23_025827| [-1.55578e+00  1.55922e+00 -6.26084e-02  1.27440e+00  7.76317e-01
20Nov23_025827|  -3.31071e-01 -8.12146e-01  5.32258e-01 -1.03204e-01  5.74448e-01]
20Nov23_025827| [-1.66080e-01  9.27591e-01 -8.26749e-01 -2.02630e+00 -1.69057e+00
20Nov23_025827|   1.57038e+00 -9.36829e-01 -8.09723e-02 -1.40559e+00 -4.68670e-01]
20Nov23_025827| [ 1.31585e+00 -1.35879e+00  6.69832e-02 -6.76034e-01 -7.78053e-02
20Nov23_025827|   9.15890e-01 -2.57551e+00  1.17206e+00 -1.63833e-01 -1.51976e+00]
20Nov23_025827| [ 3.86571e-01  3.76960e-01  1.62203e+00 -6.63494e-01  5.79448e-01
20Nov23_025827|  -2.02899e-01  6.20663e-01 -8.74604e-01  5.65300e-01 -4.78021e-01]
20Nov23_025827| [ 2.84392e-01 -1.30287e+00 -2.40568e-01  1.64154e+00  8.57175e-01
20Nov23_025827|   1.66324e+00 -7.58044e-01  9.58194e-01  1.08895e+00  6.87897e-01]
20Nov23_025827| [ 1.91543e+00 -8.14252e-01 -8.52032e-01  3.78664e-01  1.90764e+00
20Nov23_025827|  -4.47222e-01 -2.69340e+00 -1.03904e+00 -2.00134e+00  2.38100e-01]
20Nov23_025827| [ 1.26019e+00  9.38744e-01 -3.14317e-01  7.86493e-01  4.76806e-01
20Nov23_025827|  -1.35297e-01  4.23375e-01 -2.08811e+00 -2.33768e-01 -6.56785e-01]
20Nov23_025827| [-1.79324e+00  2.42905e-02  1.37542e+00 -2.27793e+00  2.38915e+00
20Nov23_025827|   1.28801e-01 -1.29803e-01  1.69579e+00 -5.80142e-01  2.11689e+00]
20Nov23_025827| [ 9.34165e-01  7.98905e-01  9.33160e-01  1.26228e+00  8.33572e-01
20Nov23_025827|   8.94453e-01 -1.13623e+00  1.39619e+00 -6.78227e-01  8.70115e-01]
20Nov23_025827| [-1.10950e+00  2.87654e-01  2.71057e-01  8.54796e-01  1.22987e+00
20Nov23_025827|  -1.00751e+00 -5.61214e-01 -6.35672e-02 -9.03112e-01 -7.95657e-01]
20Nov23_025827| [-7.55905e-01  2.91320e-01 -1.58683e+00  5.85932e-01  2.65090e-01
20Nov23_025827|   1.77914e-01 -1.04044e-01 -1.09661e+00  9.38082e-02 -5.58226e-01]
20Nov23_025827| [-9.74231e-01  1.36123e+00 -4.42398e-01  1.01758e-01  3.66514e-01
20Nov23_025827|   1.28179e+00 -1.91686e+00  5.51070e-01  1.15574e+00 -7.07965e-01]
20Nov23_025827| [ 4.46124e-02  5.20958e-01  2.14918e+00  4.16463e-01 -8.15995e-03
20Nov23_025827|   1.50900e+00  2.03955e+00 -3.79312e-01  1.23712e+00 -9.03886e-01]
20Nov23_025827| [ 9.53918e-01 -1.00003e+00  1.67585e+00 -3.41251e+00  1.13867e+00
20Nov23_025827|   3.59439e-01  6.13636e-01 -5.79112e-01  1.84630e-01  1.27094e-01]
20Nov23_025827| [ 5.63295e-01 -7.65227e-01  1.14199e-01 -1.63298e+00  2.84249e-01
20Nov23_025827|  -6.66078e-01 -1.57556e+00  1.00746e+00  7.55489e-01 -9.87647e-01]
20Nov23_025827| [-7.69623e-01 -2.82068e-01  2.51158e+00 -7.90434e-01 -1.54072e+00
20Nov23_025827|   2.29525e+00  3.09859e-01  3.83551e-01 -9.54400e-01  7.70518e-01]
20Nov23_025827| [ 2.04135e+00 -1.89705e+00 -2.04564e+00  1.29505e+00  2.31663e-01
20Nov23_025827|  -1.07668e-01 -1.11612e-01 -4.62865e-01  1.10223e+00  9.01401e-01]
20Nov23_025827| [-6.45809e-01  4.89783e-01  2.17360e+00 -6.88799e-01  1.19751e+00
20Nov23_025827|   1.21721e+00 -2.17834e+00 -5.34672e-01  1.33385e+00 -2.08075e+00]
20Nov23_025827| [-4.18249e+00  1.95307e-01 -7.81067e-01  1.37136e+00 -2.13521e-01
20Nov23_025827|   1.59212e+00 -3.82342e-01  2.63593e+00 -1.00001e+00 -9.22583e-01]
20Nov23_025827| [ 7.01133e-01 -1.13910e+00  1.30671e+00 -5.14959e-01 -2.15790e+00
20Nov23_025827|  -9.44361e-01 -7.67735e-01 -1.24544e+00  1.21896e-01  1.44422e-02]
20Nov23_025827| [-5.05253e-01 -9.48834e-01 -1.35498e+00 -5.44439e-01  4.33973e-01
20Nov23_025827|   1.34650e+00 -1.59928e+00 -9.47020e-01  1.00715e+00 -2.13873e-01]
20Nov23_025827| [-4.95534e-01 -1.37437e-01 -7.25293e-01 -1.79721e+00  1.74471e+00
20Nov23_025827|  -9.68677e-01 -8.56409e-02  1.37133e+00 -7.11811e-01 -8.75033e-01]
20Nov23_025827| [ 1.75287e+00  4.58719e-01  6.66106e-01  1.10149e+00  1.57245e+00
20Nov23_025827|  -6.58958e-01 -7.97523e-01  4.49998e-01 -9.37306e-01  7.24107e-01]
20Nov23_025827| [-6.67339e-02  1.37247e+00  4.27743e-01  3.63566e-01  1.53543e+00
20Nov23_025827|  -2.46799e+00  1.38273e-01  9.09795e-01 -1.63558e+00 -2.33811e+00]
20Nov23_025827| [ 4.74738e-01  1.19072e+00  2.53531e-01  1.60539e+00 -1.19259e+00
20Nov23_025827|   8.16734e-01 -1.06184e+00 -8.57672e-01 -4.20009e-02  2.71981e-01]
20Nov23_025827| [-9.28704e-01  2.61080e+00  7.82101e-01  1.51103e+00 -1.65491e+00
20Nov23_025827|   1.67477e+00  1.27955e+00  9.86971e-01  1.12991e+00 -1.88014e+00]
20Nov23_025827| [-1.83175e+00  2.17081e+00 -1.12905e-01 -7.86976e-01  4.64954e-02
20Nov23_025827|   1.73163e+00 -2.10689e+00  2.17379e-01 -2.19104e+00  2.65990e-01]
20Nov23_025827| [ 5.99832e-01  2.26352e+00 -1.26344e+00  1.67205e+00  1.96797e+00
20Nov23_025827|  -1.04196e+00 -1.17036e+00 -5.82210e-01  3.44470e-01 -6.29446e-01]
20Nov23_025827| [-3.74647e-01  1.57396e+00 -1.23393e+00  1.77755e+00 -1.35559e+00
20Nov23_025827|  -3.50392e-01 -1.51221e+00 -3.50933e-01 -2.21108e+00  2.27891e+00]
20Nov23_025827| [ 1.79899e+00  9.29451e-01 -2.38156e+00 -2.95904e-01  5.01510e-02
20Nov23_025827|  -4.89236e-01 -3.81430e-02 -1.93658e-02 -2.81360e+00 -1.61727e+00]
20Nov23_025827| [-6.31664e-01  1.35179e-02 -8.62988e-01 -1.37577e+00 -1.76862e+00
20Nov23_025827|   7.53411e-01  8.42981e-01 -1.16891e+00 -1.94126e-01  1.64820e+00]
20Nov23_025827| [-9.45281e-01 -1.40671e+00 -2.98803e-01 -9.53509e-01 -7.63614e-01
20Nov23_025827|   3.42849e-02  1.95511e+00  1.79314e+00 -7.97121e-01 -1.37916e+00]
20Nov23_025827| [-1.21675e+00 -1.09576e+00 -3.20845e-01  7.37468e-01 -7.22748e-01
20Nov23_025827|  -4.89459e-01 -1.01331e+00  8.35708e-02  1.66520e-01  4.22179e-01]]
20Nov23_025827|-- Bias --
20Nov23_025827|[ 0.60392 -0.49720 -0.40465 -0.97662 -1.18628 -0.32953 -0.72463  1.47398
20Nov23_025827|  0.64550  0.75190]
20Nov23_025827|Layer 1:
20Nov23_025827|-- Config --
20Nov23_025827|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 10], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025827|-- Weights --
20Nov23_025827|[[-0.21679 -0.45691  0.28378  0.33784]
20Nov23_025827| [ 0.06390  0.16042 -0.55690  0.51363]
20Nov23_025827| [ 0.72633  0.93777 -0.75765  0.12993]
20Nov23_025827| [-0.62302  0.49010 -0.52417 -0.18200]
20Nov23_025827| [ 0.40134 -0.38242 -0.19617 -0.96393]
20Nov23_025827| [ 0.32070 -0.40738 -0.02044 -0.76057]
20Nov23_025827| [-0.43581  0.72040 -0.51486 -0.45397]
20Nov23_025827| [-0.62899 -0.42677 -0.34653 -0.07457]
20Nov23_025827| [-0.53423 -0.35014  0.48800 -0.44973]
20Nov23_025827| [ 0.80919  0.06153 -0.03718  0.65188]]
20Nov23_025827|-- Bias --
20Nov23_025827|[ 0.73864 -0.52503 -0.04894  0.56961]
20Nov23_025827|Layer 2:
20Nov23_025827|-- Config --
20Nov23_025827|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025827|-- Weights --
20Nov23_025827|[[ 0.12699 -0.47567]
20Nov23_025827| [ 1.38134  1.35039]
20Nov23_025827| [ 1.14654  1.78430]
20Nov23_025827| [ 0.41573  1.94888]]
20Nov23_025827|-- Bias --
20Nov23_025827|[ 0.02099 -0.36139]
20Nov23_025827|Predicting the validation and test data with the Best final individual.
20Nov23_025833| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_025833|-----------  ------------------  --------------------  ----------
20Nov23_025833|Validation         42.09                  28            0.00000
20Nov23_025833|   Test            36.32                  28            0.00298
20Nov23_025833|-------------------------- Test #6 --------------------------
20Nov23_025833|Best final individual weights
20Nov23_025833|Individual:
20Nov23_025833|-- Constant hidden layers --
20Nov23_025833|False
20Nov23_025833|Layer 0:
20Nov23_025833|-- Config --
20Nov23_025833|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 10, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025833|-- Weights --
20Nov23_025833|[[-3.07041e-01  1.00616e+00  6.34565e-01 -6.61114e-01 -5.46887e-01
20Nov23_025833|  -1.10888e+00  3.20769e-01 -4.30961e-02 -2.31163e-01  2.22718e+00]
20Nov23_025833| [ 3.40553e-01  8.74817e-01 -1.66864e+00 -7.83743e-01  1.10105e+00
20Nov23_025833|  -1.32534e+00  4.10905e-02  1.12271e+00  6.89412e-01 -1.53065e-01]
20Nov23_025833| [-1.26826e+00  5.87994e-01 -4.60418e-02 -3.55128e+00  1.04805e+00
20Nov23_025833|   1.61174e-01  1.16185e+00  5.66952e-01  6.72490e-01 -6.24827e-01]
20Nov23_025833| [-9.79202e-01  1.61247e-01 -1.27518e+00  5.18034e-01  1.98136e+00
20Nov23_025833|  -6.90936e-01  1.26940e-01  5.58500e-01  1.42756e-01  1.03981e+00]
20Nov23_025833| [-1.82313e-01  3.66685e-01  1.34275e+00  4.58416e-01 -1.18038e+00
20Nov23_025833|   2.51182e-01 -7.15217e-01 -1.66193e-01 -3.14859e-01  1.24005e+00]
20Nov23_025833| [ 1.48738e+00 -3.98929e-01  3.64868e-01  5.40263e-01  5.46416e-02
20Nov23_025833|   1.88146e+00  1.19580e+00 -2.43148e+00 -7.75186e-01 -6.49648e-01]
20Nov23_025833| [ 1.21399e+00  6.66074e-01  1.28060e+00 -6.11337e-01 -2.69644e-01
20Nov23_025833|  -2.53230e-03 -6.20683e-01  8.95056e-01 -1.08596e+00  3.64325e-01]
20Nov23_025833| [ 5.88481e-01  8.60948e-02  4.37503e-01 -1.84663e+00 -7.58324e-01
20Nov23_025833|   7.34596e-01  1.44969e+00 -8.81787e-01 -1.50155e-01 -1.06136e-01]
20Nov23_025833| [ 3.27155e-01  1.36855e+00 -2.04781e+00 -1.57615e+00 -4.51258e-01
20Nov23_025833|   3.02165e-01  6.43490e-01 -1.26883e-01 -5.94848e-01 -2.12811e+00]
20Nov23_025833| [-3.45131e-01 -1.81354e+00 -4.97743e-01  5.71362e-01 -8.54879e-01
20Nov23_025833|   3.65188e-01  1.95065e-01 -2.79676e-01  1.48447e-01  2.43540e-01]
20Nov23_025833| [-5.61218e-01  1.44002e+00  9.06417e-01 -3.99731e-01 -7.36291e-01
20Nov23_025833|  -9.66884e-01 -5.37313e-01 -8.49094e-01 -1.50517e+00  4.55984e-01]
20Nov23_025833| [ 1.70948e+00  8.12685e-01  2.75510e-02 -1.86415e+00 -1.60141e+00
20Nov23_025833|  -8.75582e-01 -8.89810e-01  5.20086e-01  7.91316e-01 -1.36802e+00]
20Nov23_025833| [-2.14098e-01  2.45515e-01  2.56778e-01  2.97405e-01 -1.38597e+00
20Nov23_025833|  -5.00160e-01  6.20253e-01 -7.58286e-01  3.35205e-01 -3.43907e+00]
20Nov23_025833| [ 4.03195e-01 -1.20324e-01  1.13366e+00  8.88009e-01 -9.37896e-03
20Nov23_025833|  -2.86522e-01  1.67710e+00  5.86515e-01 -1.06572e+00  1.39802e+00]
20Nov23_025833| [ 6.48180e-01 -1.92738e+00  1.50417e-02  8.68537e-02 -1.13786e+00
20Nov23_025833|  -1.29129e+00 -6.92839e-01 -1.40458e+00 -8.00986e-01  8.15326e-01]
20Nov23_025833| [ 1.57969e+00 -1.30609e-01 -1.29681e-01  1.04108e+00 -1.55760e+00
20Nov23_025833|  -1.01726e+00 -7.49064e-02  1.91418e-01  1.13480e+00 -1.29247e+00]
20Nov23_025833| [ 6.05486e-01 -1.20667e+00  1.83863e+00  1.62026e+00 -1.21907e+00
20Nov23_025833|  -1.85861e+00  6.32947e-01 -6.56312e-01 -1.96676e+00  9.10422e-01]
20Nov23_025833| [-1.17272e+00  1.65220e+00 -1.03529e+00 -8.72294e-02  2.90430e-01
20Nov23_025833|  -2.34656e+00  3.19297e-01 -1.87314e+00  5.04493e-01  4.65741e-01]
20Nov23_025833| [-9.48481e-02 -2.33962e-02 -5.93975e-02  3.19555e-02  3.49339e-01
20Nov23_025833|   6.49964e-01  6.53861e-01  8.66293e-01 -1.16838e+00 -9.17614e-01]
20Nov23_025833| [ 1.19783e+00  3.25987e-01  1.37329e+00  8.63944e-01 -9.03486e-01
20Nov23_025833|   1.38840e+00  1.49831e+00  1.17810e+00 -2.68505e+00  1.62729e+00]
20Nov23_025833| [-1.58344e+00 -2.33544e-01  8.36162e-01 -2.18260e+00 -1.15138e+00
20Nov23_025833|   1.45939e+00 -1.13930e+00 -3.86267e-01 -4.73407e-01 -9.27712e-01]
20Nov23_025833| [ 4.40150e-01 -1.15269e+00  3.37421e-01 -6.98225e-01  2.17269e+00
20Nov23_025833|   9.63798e-01 -1.43930e+00  1.71663e+00  7.51493e-01 -6.28456e-01]
20Nov23_025833| [-1.58838e+00  1.79189e+00  5.00478e-01 -1.25010e+00  7.03498e-01
20Nov23_025833|  -6.38268e-01  1.20227e+00  1.08421e+00  8.40502e-01  2.02490e+00]
20Nov23_025833| [ 3.67353e-01 -6.31589e-04  1.27834e+00 -1.39200e+00 -1.15876e+00
20Nov23_025833|   1.53865e+00 -7.44091e-01  4.73619e-01  2.04884e+00  1.62277e+00]
20Nov23_025833| [-1.55578e+00  1.55922e+00 -6.26084e-02  1.27440e+00  7.76317e-01
20Nov23_025833|  -3.31071e-01 -8.12146e-01  5.32258e-01 -1.03204e-01  5.74448e-01]
20Nov23_025833| [-1.66080e-01  9.27591e-01 -8.26749e-01 -2.02630e+00 -1.69057e+00
20Nov23_025833|   1.57038e+00 -9.36829e-01 -8.09723e-02 -1.40559e+00 -4.68670e-01]
20Nov23_025833| [ 1.31585e+00 -1.35879e+00  6.69832e-02 -6.76034e-01 -7.78053e-02
20Nov23_025833|   9.15890e-01 -2.57551e+00  1.17206e+00 -1.63833e-01 -1.51976e+00]
20Nov23_025833| [ 3.86571e-01  3.76960e-01  1.62203e+00 -6.63494e-01  5.79448e-01
20Nov23_025833|  -2.02899e-01  6.20663e-01 -8.74604e-01  5.65300e-01 -4.78021e-01]
20Nov23_025833| [ 2.84392e-01 -1.30287e+00 -2.40568e-01  1.64154e+00  8.57175e-01
20Nov23_025833|   1.66324e+00 -7.58044e-01  9.58194e-01  1.08895e+00  6.87897e-01]
20Nov23_025833| [ 1.91543e+00 -8.14252e-01 -8.52032e-01  3.78664e-01  1.90764e+00
20Nov23_025833|  -4.47222e-01 -2.69340e+00 -1.03904e+00 -2.00134e+00  2.38100e-01]
20Nov23_025833| [ 1.26019e+00  9.38744e-01 -3.14317e-01  7.86493e-01  4.76806e-01
20Nov23_025833|  -1.35297e-01  4.23375e-01 -2.08811e+00 -2.33768e-01 -6.56785e-01]
20Nov23_025833| [-1.79324e+00  2.42905e-02  1.37542e+00 -2.27793e+00  2.38915e+00
20Nov23_025833|   1.28801e-01 -1.29803e-01  1.69579e+00 -5.80142e-01  2.11689e+00]
20Nov23_025833| [ 9.34165e-01  7.98905e-01  9.33160e-01  1.26228e+00  8.33572e-01
20Nov23_025833|   8.94453e-01 -1.13623e+00  1.39619e+00 -6.78227e-01  8.70115e-01]
20Nov23_025833| [-1.10950e+00  2.87654e-01  2.71057e-01  8.54796e-01  1.22987e+00
20Nov23_025833|  -1.00751e+00 -5.61214e-01 -6.35672e-02 -9.03112e-01 -7.95657e-01]
20Nov23_025833| [-7.55905e-01  2.91320e-01 -1.58683e+00  5.85932e-01  2.65090e-01
20Nov23_025833|   1.77914e-01 -1.04044e-01 -1.09661e+00  9.38082e-02 -5.58226e-01]
20Nov23_025833| [-9.74231e-01  1.36123e+00 -4.42398e-01  1.01758e-01  3.66514e-01
20Nov23_025833|   1.28179e+00 -1.91686e+00  5.51070e-01  1.15574e+00 -7.07965e-01]
20Nov23_025833| [ 4.46124e-02  5.20958e-01  2.14918e+00  4.16463e-01 -8.15995e-03
20Nov23_025833|   1.50900e+00  2.03955e+00 -3.79312e-01  1.23712e+00 -9.03886e-01]
20Nov23_025833| [ 9.53918e-01 -1.00003e+00  1.67585e+00 -3.41251e+00  1.13867e+00
20Nov23_025833|   3.59439e-01  6.13636e-01 -5.79112e-01  1.84630e-01  1.27094e-01]
20Nov23_025833| [ 5.63295e-01 -7.65227e-01  1.14199e-01 -1.63298e+00  2.84249e-01
20Nov23_025833|  -6.66078e-01 -1.57556e+00  1.00746e+00  7.55489e-01 -9.87647e-01]
20Nov23_025833| [-7.69623e-01 -2.82068e-01  2.51158e+00 -7.90434e-01 -1.54072e+00
20Nov23_025833|   2.29525e+00  3.09859e-01  3.83551e-01 -9.54400e-01  7.70518e-01]
20Nov23_025833| [ 2.04135e+00 -1.89705e+00 -2.04564e+00  1.29505e+00  2.31663e-01
20Nov23_025833|  -1.07668e-01 -1.11612e-01 -4.62865e-01  1.10223e+00  9.01401e-01]
20Nov23_025833| [-6.45809e-01  4.89783e-01  2.17360e+00 -6.88799e-01  1.19751e+00
20Nov23_025833|   1.21721e+00 -2.17834e+00 -5.34672e-01  1.33385e+00 -2.08075e+00]
20Nov23_025833| [-4.18249e+00  1.95307e-01 -7.81067e-01  1.37136e+00 -2.13521e-01
20Nov23_025833|   1.59212e+00 -3.82342e-01  2.63593e+00 -1.00001e+00 -9.22583e-01]
20Nov23_025833| [ 7.01133e-01 -1.13910e+00  1.30671e+00 -5.14959e-01 -2.15790e+00
20Nov23_025833|  -9.44361e-01 -7.67735e-01 -1.24544e+00  1.21896e-01  1.44422e-02]
20Nov23_025833| [-5.05253e-01 -9.48834e-01 -1.35498e+00 -5.44439e-01  4.33973e-01
20Nov23_025833|   1.34650e+00 -1.59928e+00 -9.47020e-01  1.00715e+00 -2.13873e-01]
20Nov23_025833| [-4.95534e-01 -1.37437e-01 -7.25293e-01 -1.79721e+00  1.74471e+00
20Nov23_025833|  -9.68677e-01 -8.56409e-02  1.37133e+00 -7.11811e-01 -8.75033e-01]
20Nov23_025833| [ 1.75287e+00  4.58719e-01  6.66106e-01  1.10149e+00  1.57245e+00
20Nov23_025833|  -6.58958e-01 -7.97523e-01  4.49998e-01 -9.37306e-01  7.24107e-01]
20Nov23_025833| [-6.67339e-02  1.37247e+00  4.27743e-01  3.63566e-01  1.53543e+00
20Nov23_025833|  -2.46799e+00  1.38273e-01  9.09795e-01 -1.63558e+00 -2.33811e+00]
20Nov23_025833| [ 4.74738e-01  1.19072e+00  2.53531e-01  1.60539e+00 -1.19259e+00
20Nov23_025833|   8.16734e-01 -1.06184e+00 -8.57672e-01 -4.20009e-02  2.71981e-01]
20Nov23_025833| [-9.28704e-01  2.61080e+00  7.82101e-01  1.51103e+00 -1.65491e+00
20Nov23_025833|   1.67477e+00  1.27955e+00  9.86971e-01  1.12991e+00 -1.88014e+00]
20Nov23_025833| [-1.83175e+00  2.17081e+00 -1.12905e-01 -7.86976e-01  4.64954e-02
20Nov23_025833|   1.73163e+00 -2.10689e+00  2.17379e-01 -2.19104e+00  2.65990e-01]
20Nov23_025833| [ 5.99832e-01  2.26352e+00 -1.26344e+00  1.67205e+00  1.96797e+00
20Nov23_025833|  -1.04196e+00 -1.17036e+00 -5.82210e-01  3.44470e-01 -6.29446e-01]
20Nov23_025833| [-3.74647e-01  1.57396e+00 -1.23393e+00  1.77755e+00 -1.35559e+00
20Nov23_025833|  -3.50392e-01 -1.51221e+00 -3.50933e-01 -2.21108e+00  2.27891e+00]
20Nov23_025833| [ 1.79899e+00  9.29451e-01 -2.38156e+00 -2.95904e-01  5.01510e-02
20Nov23_025833|  -4.89236e-01 -3.81430e-02 -1.93658e-02 -2.81360e+00 -1.61727e+00]
20Nov23_025833| [-6.31664e-01  1.35179e-02 -8.62988e-01 -1.37577e+00 -1.76862e+00
20Nov23_025833|   7.53411e-01  8.42981e-01 -1.16891e+00 -1.94126e-01  1.64820e+00]
20Nov23_025833| [-9.45281e-01 -1.40671e+00 -2.98803e-01 -9.53509e-01 -7.63614e-01
20Nov23_025833|   3.42849e-02  1.95511e+00  1.79314e+00 -7.97121e-01 -1.37916e+00]
20Nov23_025833| [-1.21675e+00 -1.09576e+00 -3.20845e-01  7.37468e-01 -7.22748e-01
20Nov23_025833|  -4.89459e-01 -1.01331e+00  8.35708e-02  1.66520e-01  4.22179e-01]]
20Nov23_025833|-- Bias --
20Nov23_025833|[ 0.60392 -0.49720 -0.40465 -0.97662 -1.18628 -0.32953 -0.72463  1.47398
20Nov23_025833|  0.64550  0.75190]
20Nov23_025833|Layer 1:
20Nov23_025833|-- Config --
20Nov23_025833|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 10], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025833|-- Weights --
20Nov23_025833|[[-0.21679 -0.45691  0.28378  0.33784]
20Nov23_025833| [ 0.06390  0.16042 -0.55690  0.51363]
20Nov23_025833| [ 0.72633  0.93777 -0.75765  0.12993]
20Nov23_025833| [-0.62302  0.49010 -0.52417 -0.18200]
20Nov23_025833| [ 0.40134 -0.38242 -0.19617 -0.96393]
20Nov23_025833| [ 0.32070 -0.40738 -0.02044 -0.76057]
20Nov23_025833| [-0.43581  0.72040 -0.51486 -0.45397]
20Nov23_025833| [-0.62899 -0.42677 -0.34653 -0.07457]
20Nov23_025833| [-0.53423 -0.35014  0.48800 -0.44973]
20Nov23_025833| [ 0.80919  0.06153 -0.03718  0.65188]]
20Nov23_025833|-- Bias --
20Nov23_025833|[ 0.73864 -0.52503 -0.04894  0.56961]
20Nov23_025833|Layer 2:
20Nov23_025833|-- Config --
20Nov23_025833|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025833|-- Weights --
20Nov23_025833|[[ 0.12699 -0.47567]
20Nov23_025833| [ 1.38134  1.35039]
20Nov23_025833| [ 1.14654  1.78430]
20Nov23_025833| [ 0.41573  1.94888]]
20Nov23_025833|-- Bias --
20Nov23_025833|[ 0.02099 -0.36139]
20Nov23_025833|Predicting the validation and test data with the Best final individual.
20Nov23_025838| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_025838|-----------  ------------------  --------------------  ----------
20Nov23_025838|Validation         40.00                  28            0.28744
20Nov23_025838|   Test            36.40                  28            0.00000
20Nov23_025838|-------------------------- Test #7 --------------------------
20Nov23_025838|Best final individual weights
20Nov23_025838|Individual:
20Nov23_025838|-- Constant hidden layers --
20Nov23_025838|False
20Nov23_025838|Layer 0:
20Nov23_025838|-- Config --
20Nov23_025838|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 10, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025838|-- Weights --
20Nov23_025838|[[-3.07041e-01  1.00616e+00  6.34565e-01 -6.61114e-01 -5.46887e-01
20Nov23_025838|  -1.10888e+00  3.20769e-01 -4.30961e-02 -2.31163e-01  2.22718e+00]
20Nov23_025838| [ 3.40553e-01  8.74817e-01 -1.66864e+00 -7.83743e-01  1.10105e+00
20Nov23_025838|  -1.32534e+00  4.10905e-02  1.12271e+00  6.89412e-01 -1.53065e-01]
20Nov23_025838| [-1.26826e+00  5.87994e-01 -4.60418e-02 -3.55128e+00  1.04805e+00
20Nov23_025838|   1.61174e-01  1.16185e+00  5.66952e-01  6.72490e-01 -6.24827e-01]
20Nov23_025838| [-9.79202e-01  1.61247e-01 -1.27518e+00  5.18034e-01  1.98136e+00
20Nov23_025838|  -6.90936e-01  1.26940e-01  5.58500e-01  1.42756e-01  1.03981e+00]
20Nov23_025838| [-1.82313e-01  3.66685e-01  1.34275e+00  4.58416e-01 -1.18038e+00
20Nov23_025838|   2.51182e-01 -7.15217e-01 -1.66193e-01 -3.14859e-01  1.24005e+00]
20Nov23_025838| [ 1.48738e+00 -3.98929e-01  3.64868e-01  5.40263e-01  5.46416e-02
20Nov23_025838|   1.88146e+00  1.19580e+00 -2.43148e+00 -7.75186e-01 -6.49648e-01]
20Nov23_025838| [ 1.21399e+00  6.66074e-01  1.28060e+00 -6.11337e-01 -2.69644e-01
20Nov23_025838|  -2.53230e-03 -6.20683e-01  8.95056e-01 -1.08596e+00  3.64325e-01]
20Nov23_025838| [ 5.88481e-01  8.60948e-02  4.37503e-01 -1.84663e+00 -7.58324e-01
20Nov23_025838|   7.34596e-01  1.44969e+00 -8.81787e-01 -1.50155e-01 -1.06136e-01]
20Nov23_025838| [ 3.27155e-01  1.36855e+00 -2.04781e+00 -1.57615e+00 -4.51258e-01
20Nov23_025838|   3.02165e-01  6.43490e-01 -1.26883e-01 -5.94848e-01 -2.12811e+00]
20Nov23_025838| [-3.45131e-01 -1.81354e+00 -4.97743e-01  5.71362e-01 -8.54879e-01
20Nov23_025838|   3.65188e-01  1.95065e-01 -2.79676e-01  1.48447e-01  2.43540e-01]
20Nov23_025838| [-5.61218e-01  1.44002e+00  9.06417e-01 -3.99731e-01 -7.36291e-01
20Nov23_025838|  -9.66884e-01 -5.37313e-01 -8.49094e-01 -1.50517e+00  4.55984e-01]
20Nov23_025838| [ 1.70948e+00  8.12685e-01  2.75510e-02 -1.86415e+00 -1.60141e+00
20Nov23_025838|  -8.75582e-01 -8.89810e-01  5.20086e-01  7.91316e-01 -1.36802e+00]
20Nov23_025838| [-2.14098e-01  2.45515e-01  2.56778e-01  2.97405e-01 -1.38597e+00
20Nov23_025838|  -5.00160e-01  6.20253e-01 -7.58286e-01  3.35205e-01 -3.43907e+00]
20Nov23_025838| [ 4.03195e-01 -1.20324e-01  1.13366e+00  8.88009e-01 -9.37896e-03
20Nov23_025838|  -2.86522e-01  1.67710e+00  5.86515e-01 -1.06572e+00  1.39802e+00]
20Nov23_025838| [ 6.48180e-01 -1.92738e+00  1.50417e-02  8.68537e-02 -1.13786e+00
20Nov23_025838|  -1.29129e+00 -6.92839e-01 -1.40458e+00 -8.00986e-01  8.15326e-01]
20Nov23_025838| [ 1.57969e+00 -1.30609e-01 -1.29681e-01  1.04108e+00 -1.55760e+00
20Nov23_025838|  -1.01726e+00 -7.49064e-02  1.91418e-01  1.13480e+00 -1.29247e+00]
20Nov23_025838| [ 6.05486e-01 -1.20667e+00  1.83863e+00  1.62026e+00 -1.21907e+00
20Nov23_025838|  -1.85861e+00  6.32947e-01 -6.56312e-01 -1.96676e+00  9.10422e-01]
20Nov23_025838| [-1.17272e+00  1.65220e+00 -1.03529e+00 -8.72294e-02  2.90430e-01
20Nov23_025838|  -2.34656e+00  3.19297e-01 -1.87314e+00  5.04493e-01  4.65741e-01]
20Nov23_025838| [-9.48481e-02 -2.33962e-02 -5.93975e-02  3.19555e-02  3.49339e-01
20Nov23_025838|   6.49964e-01  6.53861e-01  8.66293e-01 -1.16838e+00 -9.17614e-01]
20Nov23_025838| [ 1.19783e+00  3.25987e-01  1.37329e+00  8.63944e-01 -9.03486e-01
20Nov23_025838|   1.38840e+00  1.49831e+00  1.17810e+00 -2.68505e+00  1.62729e+00]
20Nov23_025838| [-1.58344e+00 -2.33544e-01  8.36162e-01 -2.18260e+00 -1.15138e+00
20Nov23_025838|   1.45939e+00 -1.13930e+00 -3.86267e-01 -4.73407e-01 -9.27712e-01]
20Nov23_025838| [ 4.40150e-01 -1.15269e+00  3.37421e-01 -6.98225e-01  2.17269e+00
20Nov23_025838|   9.63798e-01 -1.43930e+00  1.71663e+00  7.51493e-01 -6.28456e-01]
20Nov23_025838| [-1.58838e+00  1.79189e+00  5.00478e-01 -1.25010e+00  7.03498e-01
20Nov23_025838|  -6.38268e-01  1.20227e+00  1.08421e+00  8.40502e-01  2.02490e+00]
20Nov23_025838| [ 3.67353e-01 -6.31589e-04  1.27834e+00 -1.39200e+00 -1.15876e+00
20Nov23_025838|   1.53865e+00 -7.44091e-01  4.73619e-01  2.04884e+00  1.62277e+00]
20Nov23_025838| [-1.55578e+00  1.55922e+00 -6.26084e-02  1.27440e+00  7.76317e-01
20Nov23_025838|  -3.31071e-01 -8.12146e-01  5.32258e-01 -1.03204e-01  5.74448e-01]
20Nov23_025838| [-1.66080e-01  9.27591e-01 -8.26749e-01 -2.02630e+00 -1.69057e+00
20Nov23_025838|   1.57038e+00 -9.36829e-01 -8.09723e-02 -1.40559e+00 -4.68670e-01]
20Nov23_025838| [ 1.31585e+00 -1.35879e+00  6.69832e-02 -6.76034e-01 -7.78053e-02
20Nov23_025838|   9.15890e-01 -2.57551e+00  1.17206e+00 -1.63833e-01 -1.51976e+00]
20Nov23_025838| [ 3.86571e-01  3.76960e-01  1.62203e+00 -6.63494e-01  5.79448e-01
20Nov23_025838|  -2.02899e-01  6.20663e-01 -8.74604e-01  5.65300e-01 -4.78021e-01]
20Nov23_025838| [ 2.84392e-01 -1.30287e+00 -2.40568e-01  1.64154e+00  8.57175e-01
20Nov23_025838|   1.66324e+00 -7.58044e-01  9.58194e-01  1.08895e+00  6.87897e-01]
20Nov23_025838| [ 1.91543e+00 -8.14252e-01 -8.52032e-01  3.78664e-01  1.90764e+00
20Nov23_025838|  -4.47222e-01 -2.69340e+00 -1.03904e+00 -2.00134e+00  2.38100e-01]
20Nov23_025838| [ 1.26019e+00  9.38744e-01 -3.14317e-01  7.86493e-01  4.76806e-01
20Nov23_025838|  -1.35297e-01  4.23375e-01 -2.08811e+00 -2.33768e-01 -6.56785e-01]
20Nov23_025838| [-1.79324e+00  2.42905e-02  1.37542e+00 -2.27793e+00  2.38915e+00
20Nov23_025838|   1.28801e-01 -1.29803e-01  1.69579e+00 -5.80142e-01  2.11689e+00]
20Nov23_025838| [ 9.34165e-01  7.98905e-01  9.33160e-01  1.26228e+00  8.33572e-01
20Nov23_025838|   8.94453e-01 -1.13623e+00  1.39619e+00 -6.78227e-01  8.70115e-01]
20Nov23_025838| [-1.10950e+00  2.87654e-01  2.71057e-01  8.54796e-01  1.22987e+00
20Nov23_025838|  -1.00751e+00 -5.61214e-01 -6.35672e-02 -9.03112e-01 -7.95657e-01]
20Nov23_025838| [-7.55905e-01  2.91320e-01 -1.58683e+00  5.85932e-01  2.65090e-01
20Nov23_025838|   1.77914e-01 -1.04044e-01 -1.09661e+00  9.38082e-02 -5.58226e-01]
20Nov23_025838| [-9.74231e-01  1.36123e+00 -4.42398e-01  1.01758e-01  3.66514e-01
20Nov23_025838|   1.28179e+00 -1.91686e+00  5.51070e-01  1.15574e+00 -7.07965e-01]
20Nov23_025838| [ 4.46124e-02  5.20958e-01  2.14918e+00  4.16463e-01 -8.15995e-03
20Nov23_025838|   1.50900e+00  2.03955e+00 -3.79312e-01  1.23712e+00 -9.03886e-01]
20Nov23_025838| [ 9.53918e-01 -1.00003e+00  1.67585e+00 -3.41251e+00  1.13867e+00
20Nov23_025838|   3.59439e-01  6.13636e-01 -5.79112e-01  1.84630e-01  1.27094e-01]
20Nov23_025838| [ 5.63295e-01 -7.65227e-01  1.14199e-01 -1.63298e+00  2.84249e-01
20Nov23_025838|  -6.66078e-01 -1.57556e+00  1.00746e+00  7.55489e-01 -9.87647e-01]
20Nov23_025838| [-7.69623e-01 -2.82068e-01  2.51158e+00 -7.90434e-01 -1.54072e+00
20Nov23_025838|   2.29525e+00  3.09859e-01  3.83551e-01 -9.54400e-01  7.70518e-01]
20Nov23_025838| [ 2.04135e+00 -1.89705e+00 -2.04564e+00  1.29505e+00  2.31663e-01
20Nov23_025838|  -1.07668e-01 -1.11612e-01 -4.62865e-01  1.10223e+00  9.01401e-01]
20Nov23_025838| [-6.45809e-01  4.89783e-01  2.17360e+00 -6.88799e-01  1.19751e+00
20Nov23_025838|   1.21721e+00 -2.17834e+00 -5.34672e-01  1.33385e+00 -2.08075e+00]
20Nov23_025838| [-4.18249e+00  1.95307e-01 -7.81067e-01  1.37136e+00 -2.13521e-01
20Nov23_025838|   1.59212e+00 -3.82342e-01  2.63593e+00 -1.00001e+00 -9.22583e-01]
20Nov23_025838| [ 7.01133e-01 -1.13910e+00  1.30671e+00 -5.14959e-01 -2.15790e+00
20Nov23_025838|  -9.44361e-01 -7.67735e-01 -1.24544e+00  1.21896e-01  1.44422e-02]
20Nov23_025838| [-5.05253e-01 -9.48834e-01 -1.35498e+00 -5.44439e-01  4.33973e-01
20Nov23_025838|   1.34650e+00 -1.59928e+00 -9.47020e-01  1.00715e+00 -2.13873e-01]
20Nov23_025838| [-4.95534e-01 -1.37437e-01 -7.25293e-01 -1.79721e+00  1.74471e+00
20Nov23_025838|  -9.68677e-01 -8.56409e-02  1.37133e+00 -7.11811e-01 -8.75033e-01]
20Nov23_025838| [ 1.75287e+00  4.58719e-01  6.66106e-01  1.10149e+00  1.57245e+00
20Nov23_025838|  -6.58958e-01 -7.97523e-01  4.49998e-01 -9.37306e-01  7.24107e-01]
20Nov23_025838| [-6.67339e-02  1.37247e+00  4.27743e-01  3.63566e-01  1.53543e+00
20Nov23_025838|  -2.46799e+00  1.38273e-01  9.09795e-01 -1.63558e+00 -2.33811e+00]
20Nov23_025838| [ 4.74738e-01  1.19072e+00  2.53531e-01  1.60539e+00 -1.19259e+00
20Nov23_025838|   8.16734e-01 -1.06184e+00 -8.57672e-01 -4.20009e-02  2.71981e-01]
20Nov23_025838| [-9.28704e-01  2.61080e+00  7.82101e-01  1.51103e+00 -1.65491e+00
20Nov23_025838|   1.67477e+00  1.27955e+00  9.86971e-01  1.12991e+00 -1.88014e+00]
20Nov23_025838| [-1.83175e+00  2.17081e+00 -1.12905e-01 -7.86976e-01  4.64954e-02
20Nov23_025838|   1.73163e+00 -2.10689e+00  2.17379e-01 -2.19104e+00  2.65990e-01]
20Nov23_025838| [ 5.99832e-01  2.26352e+00 -1.26344e+00  1.67205e+00  1.96797e+00
20Nov23_025838|  -1.04196e+00 -1.17036e+00 -5.82210e-01  3.44470e-01 -6.29446e-01]
20Nov23_025838| [-3.74647e-01  1.57396e+00 -1.23393e+00  1.77755e+00 -1.35559e+00
20Nov23_025838|  -3.50392e-01 -1.51221e+00 -3.50933e-01 -2.21108e+00  2.27891e+00]
20Nov23_025838| [ 1.79899e+00  9.29451e-01 -2.38156e+00 -2.95904e-01  5.01510e-02
20Nov23_025838|  -4.89236e-01 -3.81430e-02 -1.93658e-02 -2.81360e+00 -1.61727e+00]
20Nov23_025838| [-6.31664e-01  1.35179e-02 -8.62988e-01 -1.37577e+00 -1.76862e+00
20Nov23_025838|   7.53411e-01  8.42981e-01 -1.16891e+00 -1.94126e-01  1.64820e+00]
20Nov23_025838| [-9.45281e-01 -1.40671e+00 -2.98803e-01 -9.53509e-01 -7.63614e-01
20Nov23_025838|   3.42849e-02  1.95511e+00  1.79314e+00 -7.97121e-01 -1.37916e+00]
20Nov23_025838| [-1.21675e+00 -1.09576e+00 -3.20845e-01  7.37468e-01 -7.22748e-01
20Nov23_025838|  -4.89459e-01 -1.01331e+00  8.35708e-02  1.66520e-01  4.22179e-01]]
20Nov23_025838|-- Bias --
20Nov23_025838|[ 0.60392 -0.49720 -0.40465 -0.97662 -1.18628 -0.32953 -0.72463  1.47398
20Nov23_025838|  0.64550  0.75190]
20Nov23_025838|Layer 1:
20Nov23_025838|-- Config --
20Nov23_025838|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 10], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025838|-- Weights --
20Nov23_025838|[[-0.21679 -0.45691  0.28378  0.33784]
20Nov23_025838| [ 0.06390  0.16042 -0.55690  0.51363]
20Nov23_025838| [ 0.72633  0.93777 -0.75765  0.12993]
20Nov23_025838| [-0.62302  0.49010 -0.52417 -0.18200]
20Nov23_025838| [ 0.40134 -0.38242 -0.19617 -0.96393]
20Nov23_025838| [ 0.32070 -0.40738 -0.02044 -0.76057]
20Nov23_025838| [-0.43581  0.72040 -0.51486 -0.45397]
20Nov23_025838| [-0.62899 -0.42677 -0.34653 -0.07457]
20Nov23_025838| [-0.53423 -0.35014  0.48800 -0.44973]
20Nov23_025838| [ 0.80919  0.06153 -0.03718  0.65188]]
20Nov23_025838|-- Bias --
20Nov23_025838|[ 0.73864 -0.52503 -0.04894  0.56961]
20Nov23_025838|Layer 2:
20Nov23_025838|-- Config --
20Nov23_025838|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025838|-- Weights --
20Nov23_025838|[[ 0.12699 -0.47567]
20Nov23_025838| [ 1.38134  1.35039]
20Nov23_025838| [ 1.14654  1.78430]
20Nov23_025838| [ 0.41573  1.94888]]
20Nov23_025838|-- Bias --
20Nov23_025838|[ 0.02099 -0.36139]
20Nov23_025838|Predicting the validation and test data with the Best final individual.
20Nov23_025844| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_025844|-----------  ------------------  --------------------  ----------
20Nov23_025844|Validation         42.00                  28            0.00000
20Nov23_025844|   Test            36.49                  28            0.00000
20Nov23_025844|-------------------------- Test #8 --------------------------
20Nov23_025844|Best final individual weights
20Nov23_025844|Individual:
20Nov23_025844|-- Constant hidden layers --
20Nov23_025844|False
20Nov23_025844|Layer 0:
20Nov23_025844|-- Config --
20Nov23_025844|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 10, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025844|-- Weights --
20Nov23_025844|[[-3.07041e-01  1.00616e+00  6.34565e-01 -6.61114e-01 -5.46887e-01
20Nov23_025844|  -1.10888e+00  3.20769e-01 -4.30961e-02 -2.31163e-01  2.22718e+00]
20Nov23_025844| [ 3.40553e-01  8.74817e-01 -1.66864e+00 -7.83743e-01  1.10105e+00
20Nov23_025844|  -1.32534e+00  4.10905e-02  1.12271e+00  6.89412e-01 -1.53065e-01]
20Nov23_025844| [-1.26826e+00  5.87994e-01 -4.60418e-02 -3.55128e+00  1.04805e+00
20Nov23_025844|   1.61174e-01  1.16185e+00  5.66952e-01  6.72490e-01 -6.24827e-01]
20Nov23_025844| [-9.79202e-01  1.61247e-01 -1.27518e+00  5.18034e-01  1.98136e+00
20Nov23_025844|  -6.90936e-01  1.26940e-01  5.58500e-01  1.42756e-01  1.03981e+00]
20Nov23_025844| [-1.82313e-01  3.66685e-01  1.34275e+00  4.58416e-01 -1.18038e+00
20Nov23_025844|   2.51182e-01 -7.15217e-01 -1.66193e-01 -3.14859e-01  1.24005e+00]
20Nov23_025844| [ 1.48738e+00 -3.98929e-01  3.64868e-01  5.40263e-01  5.46416e-02
20Nov23_025844|   1.88146e+00  1.19580e+00 -2.43148e+00 -7.75186e-01 -6.49648e-01]
20Nov23_025844| [ 1.21399e+00  6.66074e-01  1.28060e+00 -6.11337e-01 -2.69644e-01
20Nov23_025844|  -2.53230e-03 -6.20683e-01  8.95056e-01 -1.08596e+00  3.64325e-01]
20Nov23_025844| [ 5.88481e-01  8.60948e-02  4.37503e-01 -1.84663e+00 -7.58324e-01
20Nov23_025844|   7.34596e-01  1.44969e+00 -8.81787e-01 -1.50155e-01 -1.06136e-01]
20Nov23_025844| [ 3.27155e-01  1.36855e+00 -2.04781e+00 -1.57615e+00 -4.51258e-01
20Nov23_025844|   3.02165e-01  6.43490e-01 -1.26883e-01 -5.94848e-01 -2.12811e+00]
20Nov23_025844| [-3.45131e-01 -1.81354e+00 -4.97743e-01  5.71362e-01 -8.54879e-01
20Nov23_025844|   3.65188e-01  1.95065e-01 -2.79676e-01  1.48447e-01  2.43540e-01]
20Nov23_025844| [-5.61218e-01  1.44002e+00  9.06417e-01 -3.99731e-01 -7.36291e-01
20Nov23_025844|  -9.66884e-01 -5.37313e-01 -8.49094e-01 -1.50517e+00  4.55984e-01]
20Nov23_025844| [ 1.70948e+00  8.12685e-01  2.75510e-02 -1.86415e+00 -1.60141e+00
20Nov23_025844|  -8.75582e-01 -8.89810e-01  5.20086e-01  7.91316e-01 -1.36802e+00]
20Nov23_025844| [-2.14098e-01  2.45515e-01  2.56778e-01  2.97405e-01 -1.38597e+00
20Nov23_025844|  -5.00160e-01  6.20253e-01 -7.58286e-01  3.35205e-01 -3.43907e+00]
20Nov23_025844| [ 4.03195e-01 -1.20324e-01  1.13366e+00  8.88009e-01 -9.37896e-03
20Nov23_025844|  -2.86522e-01  1.67710e+00  5.86515e-01 -1.06572e+00  1.39802e+00]
20Nov23_025844| [ 6.48180e-01 -1.92738e+00  1.50417e-02  8.68537e-02 -1.13786e+00
20Nov23_025844|  -1.29129e+00 -6.92839e-01 -1.40458e+00 -8.00986e-01  8.15326e-01]
20Nov23_025844| [ 1.57969e+00 -1.30609e-01 -1.29681e-01  1.04108e+00 -1.55760e+00
20Nov23_025844|  -1.01726e+00 -7.49064e-02  1.91418e-01  1.13480e+00 -1.29247e+00]
20Nov23_025844| [ 6.05486e-01 -1.20667e+00  1.83863e+00  1.62026e+00 -1.21907e+00
20Nov23_025844|  -1.85861e+00  6.32947e-01 -6.56312e-01 -1.96676e+00  9.10422e-01]
20Nov23_025844| [-1.17272e+00  1.65220e+00 -1.03529e+00 -8.72294e-02  2.90430e-01
20Nov23_025844|  -2.34656e+00  3.19297e-01 -1.87314e+00  5.04493e-01  4.65741e-01]
20Nov23_025844| [-9.48481e-02 -2.33962e-02 -5.93975e-02  3.19555e-02  3.49339e-01
20Nov23_025844|   6.49964e-01  6.53861e-01  8.66293e-01 -1.16838e+00 -9.17614e-01]
20Nov23_025844| [ 1.19783e+00  3.25987e-01  1.37329e+00  8.63944e-01 -9.03486e-01
20Nov23_025844|   1.38840e+00  1.49831e+00  1.17810e+00 -2.68505e+00  1.62729e+00]
20Nov23_025844| [-1.58344e+00 -2.33544e-01  8.36162e-01 -2.18260e+00 -1.15138e+00
20Nov23_025844|   1.45939e+00 -1.13930e+00 -3.86267e-01 -4.73407e-01 -9.27712e-01]
20Nov23_025844| [ 4.40150e-01 -1.15269e+00  3.37421e-01 -6.98225e-01  2.17269e+00
20Nov23_025844|   9.63798e-01 -1.43930e+00  1.71663e+00  7.51493e-01 -6.28456e-01]
20Nov23_025844| [-1.58838e+00  1.79189e+00  5.00478e-01 -1.25010e+00  7.03498e-01
20Nov23_025844|  -6.38268e-01  1.20227e+00  1.08421e+00  8.40502e-01  2.02490e+00]
20Nov23_025844| [ 3.67353e-01 -6.31589e-04  1.27834e+00 -1.39200e+00 -1.15876e+00
20Nov23_025844|   1.53865e+00 -7.44091e-01  4.73619e-01  2.04884e+00  1.62277e+00]
20Nov23_025844| [-1.55578e+00  1.55922e+00 -6.26084e-02  1.27440e+00  7.76317e-01
20Nov23_025844|  -3.31071e-01 -8.12146e-01  5.32258e-01 -1.03204e-01  5.74448e-01]
20Nov23_025844| [-1.66080e-01  9.27591e-01 -8.26749e-01 -2.02630e+00 -1.69057e+00
20Nov23_025844|   1.57038e+00 -9.36829e-01 -8.09723e-02 -1.40559e+00 -4.68670e-01]
20Nov23_025844| [ 1.31585e+00 -1.35879e+00  6.69832e-02 -6.76034e-01 -7.78053e-02
20Nov23_025844|   9.15890e-01 -2.57551e+00  1.17206e+00 -1.63833e-01 -1.51976e+00]
20Nov23_025844| [ 3.86571e-01  3.76960e-01  1.62203e+00 -6.63494e-01  5.79448e-01
20Nov23_025844|  -2.02899e-01  6.20663e-01 -8.74604e-01  5.65300e-01 -4.78021e-01]
20Nov23_025844| [ 2.84392e-01 -1.30287e+00 -2.40568e-01  1.64154e+00  8.57175e-01
20Nov23_025844|   1.66324e+00 -7.58044e-01  9.58194e-01  1.08895e+00  6.87897e-01]
20Nov23_025844| [ 1.91543e+00 -8.14252e-01 -8.52032e-01  3.78664e-01  1.90764e+00
20Nov23_025844|  -4.47222e-01 -2.69340e+00 -1.03904e+00 -2.00134e+00  2.38100e-01]
20Nov23_025844| [ 1.26019e+00  9.38744e-01 -3.14317e-01  7.86493e-01  4.76806e-01
20Nov23_025844|  -1.35297e-01  4.23375e-01 -2.08811e+00 -2.33768e-01 -6.56785e-01]
20Nov23_025844| [-1.79324e+00  2.42905e-02  1.37542e+00 -2.27793e+00  2.38915e+00
20Nov23_025844|   1.28801e-01 -1.29803e-01  1.69579e+00 -5.80142e-01  2.11689e+00]
20Nov23_025844| [ 9.34165e-01  7.98905e-01  9.33160e-01  1.26228e+00  8.33572e-01
20Nov23_025844|   8.94453e-01 -1.13623e+00  1.39619e+00 -6.78227e-01  8.70115e-01]
20Nov23_025844| [-1.10950e+00  2.87654e-01  2.71057e-01  8.54796e-01  1.22987e+00
20Nov23_025844|  -1.00751e+00 -5.61214e-01 -6.35672e-02 -9.03112e-01 -7.95657e-01]
20Nov23_025844| [-7.55905e-01  2.91320e-01 -1.58683e+00  5.85932e-01  2.65090e-01
20Nov23_025844|   1.77914e-01 -1.04044e-01 -1.09661e+00  9.38082e-02 -5.58226e-01]
20Nov23_025844| [-9.74231e-01  1.36123e+00 -4.42398e-01  1.01758e-01  3.66514e-01
20Nov23_025844|   1.28179e+00 -1.91686e+00  5.51070e-01  1.15574e+00 -7.07965e-01]
20Nov23_025844| [ 4.46124e-02  5.20958e-01  2.14918e+00  4.16463e-01 -8.15995e-03
20Nov23_025844|   1.50900e+00  2.03955e+00 -3.79312e-01  1.23712e+00 -9.03886e-01]
20Nov23_025844| [ 9.53918e-01 -1.00003e+00  1.67585e+00 -3.41251e+00  1.13867e+00
20Nov23_025844|   3.59439e-01  6.13636e-01 -5.79112e-01  1.84630e-01  1.27094e-01]
20Nov23_025844| [ 5.63295e-01 -7.65227e-01  1.14199e-01 -1.63298e+00  2.84249e-01
20Nov23_025844|  -6.66078e-01 -1.57556e+00  1.00746e+00  7.55489e-01 -9.87647e-01]
20Nov23_025844| [-7.69623e-01 -2.82068e-01  2.51158e+00 -7.90434e-01 -1.54072e+00
20Nov23_025844|   2.29525e+00  3.09859e-01  3.83551e-01 -9.54400e-01  7.70518e-01]
20Nov23_025844| [ 2.04135e+00 -1.89705e+00 -2.04564e+00  1.29505e+00  2.31663e-01
20Nov23_025844|  -1.07668e-01 -1.11612e-01 -4.62865e-01  1.10223e+00  9.01401e-01]
20Nov23_025844| [-6.45809e-01  4.89783e-01  2.17360e+00 -6.88799e-01  1.19751e+00
20Nov23_025844|   1.21721e+00 -2.17834e+00 -5.34672e-01  1.33385e+00 -2.08075e+00]
20Nov23_025844| [-4.18249e+00  1.95307e-01 -7.81067e-01  1.37136e+00 -2.13521e-01
20Nov23_025844|   1.59212e+00 -3.82342e-01  2.63593e+00 -1.00001e+00 -9.22583e-01]
20Nov23_025844| [ 7.01133e-01 -1.13910e+00  1.30671e+00 -5.14959e-01 -2.15790e+00
20Nov23_025844|  -9.44361e-01 -7.67735e-01 -1.24544e+00  1.21896e-01  1.44422e-02]
20Nov23_025844| [-5.05253e-01 -9.48834e-01 -1.35498e+00 -5.44439e-01  4.33973e-01
20Nov23_025844|   1.34650e+00 -1.59928e+00 -9.47020e-01  1.00715e+00 -2.13873e-01]
20Nov23_025844| [-4.95534e-01 -1.37437e-01 -7.25293e-01 -1.79721e+00  1.74471e+00
20Nov23_025844|  -9.68677e-01 -8.56409e-02  1.37133e+00 -7.11811e-01 -8.75033e-01]
20Nov23_025844| [ 1.75287e+00  4.58719e-01  6.66106e-01  1.10149e+00  1.57245e+00
20Nov23_025844|  -6.58958e-01 -7.97523e-01  4.49998e-01 -9.37306e-01  7.24107e-01]
20Nov23_025844| [-6.67339e-02  1.37247e+00  4.27743e-01  3.63566e-01  1.53543e+00
20Nov23_025844|  -2.46799e+00  1.38273e-01  9.09795e-01 -1.63558e+00 -2.33811e+00]
20Nov23_025844| [ 4.74738e-01  1.19072e+00  2.53531e-01  1.60539e+00 -1.19259e+00
20Nov23_025844|   8.16734e-01 -1.06184e+00 -8.57672e-01 -4.20009e-02  2.71981e-01]
20Nov23_025844| [-9.28704e-01  2.61080e+00  7.82101e-01  1.51103e+00 -1.65491e+00
20Nov23_025844|   1.67477e+00  1.27955e+00  9.86971e-01  1.12991e+00 -1.88014e+00]
20Nov23_025844| [-1.83175e+00  2.17081e+00 -1.12905e-01 -7.86976e-01  4.64954e-02
20Nov23_025844|   1.73163e+00 -2.10689e+00  2.17379e-01 -2.19104e+00  2.65990e-01]
20Nov23_025844| [ 5.99832e-01  2.26352e+00 -1.26344e+00  1.67205e+00  1.96797e+00
20Nov23_025844|  -1.04196e+00 -1.17036e+00 -5.82210e-01  3.44470e-01 -6.29446e-01]
20Nov23_025844| [-3.74647e-01  1.57396e+00 -1.23393e+00  1.77755e+00 -1.35559e+00
20Nov23_025844|  -3.50392e-01 -1.51221e+00 -3.50933e-01 -2.21108e+00  2.27891e+00]
20Nov23_025844| [ 1.79899e+00  9.29451e-01 -2.38156e+00 -2.95904e-01  5.01510e-02
20Nov23_025844|  -4.89236e-01 -3.81430e-02 -1.93658e-02 -2.81360e+00 -1.61727e+00]
20Nov23_025844| [-6.31664e-01  1.35179e-02 -8.62988e-01 -1.37577e+00 -1.76862e+00
20Nov23_025844|   7.53411e-01  8.42981e-01 -1.16891e+00 -1.94126e-01  1.64820e+00]
20Nov23_025844| [-9.45281e-01 -1.40671e+00 -2.98803e-01 -9.53509e-01 -7.63614e-01
20Nov23_025844|   3.42849e-02  1.95511e+00  1.79314e+00 -7.97121e-01 -1.37916e+00]
20Nov23_025844| [-1.21675e+00 -1.09576e+00 -3.20845e-01  7.37468e-01 -7.22748e-01
20Nov23_025844|  -4.89459e-01 -1.01331e+00  8.35708e-02  1.66520e-01  4.22179e-01]]
20Nov23_025844|-- Bias --
20Nov23_025844|[ 0.60392 -0.49720 -0.40465 -0.97662 -1.18628 -0.32953 -0.72463  1.47398
20Nov23_025844|  0.64550  0.75190]
20Nov23_025844|Layer 1:
20Nov23_025844|-- Config --
20Nov23_025844|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 10], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025844|-- Weights --
20Nov23_025844|[[-0.21679 -0.45691  0.28378  0.33784]
20Nov23_025844| [ 0.06390  0.16042 -0.55690  0.51363]
20Nov23_025844| [ 0.72633  0.93777 -0.75765  0.12993]
20Nov23_025844| [-0.62302  0.49010 -0.52417 -0.18200]
20Nov23_025844| [ 0.40134 -0.38242 -0.19617 -0.96393]
20Nov23_025844| [ 0.32070 -0.40738 -0.02044 -0.76057]
20Nov23_025844| [-0.43581  0.72040 -0.51486 -0.45397]
20Nov23_025844| [-0.62899 -0.42677 -0.34653 -0.07457]
20Nov23_025844| [-0.53423 -0.35014  0.48800 -0.44973]
20Nov23_025844| [ 0.80919  0.06153 -0.03718  0.65188]]
20Nov23_025844|-- Bias --
20Nov23_025844|[ 0.73864 -0.52503 -0.04894  0.56961]
20Nov23_025844|Layer 2:
20Nov23_025844|-- Config --
20Nov23_025844|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025844|-- Weights --
20Nov23_025844|[[ 0.12699 -0.47567]
20Nov23_025844| [ 1.38134  1.35039]
20Nov23_025844| [ 1.14654  1.78430]
20Nov23_025844| [ 0.41573  1.94888]]
20Nov23_025844|-- Bias --
20Nov23_025844|[ 0.02099 -0.36139]
20Nov23_025844|Predicting the validation and test data with the Best final individual.
20Nov23_025850| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_025850|-----------  ------------------  --------------------  ----------
20Nov23_025850|Validation         42.00                  28            0.00000
20Nov23_025850|   Test            36.23                  28            0.01485
20Nov23_025850|-------------------------- Test #9 --------------------------
20Nov23_025850|Best final individual weights
20Nov23_025850|Individual:
20Nov23_025850|-- Constant hidden layers --
20Nov23_025850|False
20Nov23_025850|Layer 0:
20Nov23_025850|-- Config --
20Nov23_025850|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 10, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025850|-- Weights --
20Nov23_025850|[[-3.07041e-01  1.00616e+00  6.34565e-01 -6.61114e-01 -5.46887e-01
20Nov23_025850|  -1.10888e+00  3.20769e-01 -4.30961e-02 -2.31163e-01  2.22718e+00]
20Nov23_025850| [ 3.40553e-01  8.74817e-01 -1.66864e+00 -7.83743e-01  1.10105e+00
20Nov23_025850|  -1.32534e+00  4.10905e-02  1.12271e+00  6.89412e-01 -1.53065e-01]
20Nov23_025850| [-1.26826e+00  5.87994e-01 -4.60418e-02 -3.55128e+00  1.04805e+00
20Nov23_025850|   1.61174e-01  1.16185e+00  5.66952e-01  6.72490e-01 -6.24827e-01]
20Nov23_025850| [-9.79202e-01  1.61247e-01 -1.27518e+00  5.18034e-01  1.98136e+00
20Nov23_025850|  -6.90936e-01  1.26940e-01  5.58500e-01  1.42756e-01  1.03981e+00]
20Nov23_025850| [-1.82313e-01  3.66685e-01  1.34275e+00  4.58416e-01 -1.18038e+00
20Nov23_025850|   2.51182e-01 -7.15217e-01 -1.66193e-01 -3.14859e-01  1.24005e+00]
20Nov23_025850| [ 1.48738e+00 -3.98929e-01  3.64868e-01  5.40263e-01  5.46416e-02
20Nov23_025850|   1.88146e+00  1.19580e+00 -2.43148e+00 -7.75186e-01 -6.49648e-01]
20Nov23_025850| [ 1.21399e+00  6.66074e-01  1.28060e+00 -6.11337e-01 -2.69644e-01
20Nov23_025850|  -2.53230e-03 -6.20683e-01  8.95056e-01 -1.08596e+00  3.64325e-01]
20Nov23_025850| [ 5.88481e-01  8.60948e-02  4.37503e-01 -1.84663e+00 -7.58324e-01
20Nov23_025850|   7.34596e-01  1.44969e+00 -8.81787e-01 -1.50155e-01 -1.06136e-01]
20Nov23_025850| [ 3.27155e-01  1.36855e+00 -2.04781e+00 -1.57615e+00 -4.51258e-01
20Nov23_025850|   3.02165e-01  6.43490e-01 -1.26883e-01 -5.94848e-01 -2.12811e+00]
20Nov23_025850| [-3.45131e-01 -1.81354e+00 -4.97743e-01  5.71362e-01 -8.54879e-01
20Nov23_025850|   3.65188e-01  1.95065e-01 -2.79676e-01  1.48447e-01  2.43540e-01]
20Nov23_025850| [-5.61218e-01  1.44002e+00  9.06417e-01 -3.99731e-01 -7.36291e-01
20Nov23_025850|  -9.66884e-01 -5.37313e-01 -8.49094e-01 -1.50517e+00  4.55984e-01]
20Nov23_025850| [ 1.70948e+00  8.12685e-01  2.75510e-02 -1.86415e+00 -1.60141e+00
20Nov23_025850|  -8.75582e-01 -8.89810e-01  5.20086e-01  7.91316e-01 -1.36802e+00]
20Nov23_025850| [-2.14098e-01  2.45515e-01  2.56778e-01  2.97405e-01 -1.38597e+00
20Nov23_025850|  -5.00160e-01  6.20253e-01 -7.58286e-01  3.35205e-01 -3.43907e+00]
20Nov23_025850| [ 4.03195e-01 -1.20324e-01  1.13366e+00  8.88009e-01 -9.37896e-03
20Nov23_025850|  -2.86522e-01  1.67710e+00  5.86515e-01 -1.06572e+00  1.39802e+00]
20Nov23_025850| [ 6.48180e-01 -1.92738e+00  1.50417e-02  8.68537e-02 -1.13786e+00
20Nov23_025850|  -1.29129e+00 -6.92839e-01 -1.40458e+00 -8.00986e-01  8.15326e-01]
20Nov23_025850| [ 1.57969e+00 -1.30609e-01 -1.29681e-01  1.04108e+00 -1.55760e+00
20Nov23_025850|  -1.01726e+00 -7.49064e-02  1.91418e-01  1.13480e+00 -1.29247e+00]
20Nov23_025850| [ 6.05486e-01 -1.20667e+00  1.83863e+00  1.62026e+00 -1.21907e+00
20Nov23_025850|  -1.85861e+00  6.32947e-01 -6.56312e-01 -1.96676e+00  9.10422e-01]
20Nov23_025850| [-1.17272e+00  1.65220e+00 -1.03529e+00 -8.72294e-02  2.90430e-01
20Nov23_025850|  -2.34656e+00  3.19297e-01 -1.87314e+00  5.04493e-01  4.65741e-01]
20Nov23_025850| [-9.48481e-02 -2.33962e-02 -5.93975e-02  3.19555e-02  3.49339e-01
20Nov23_025850|   6.49964e-01  6.53861e-01  8.66293e-01 -1.16838e+00 -9.17614e-01]
20Nov23_025850| [ 1.19783e+00  3.25987e-01  1.37329e+00  8.63944e-01 -9.03486e-01
20Nov23_025850|   1.38840e+00  1.49831e+00  1.17810e+00 -2.68505e+00  1.62729e+00]
20Nov23_025850| [-1.58344e+00 -2.33544e-01  8.36162e-01 -2.18260e+00 -1.15138e+00
20Nov23_025850|   1.45939e+00 -1.13930e+00 -3.86267e-01 -4.73407e-01 -9.27712e-01]
20Nov23_025850| [ 4.40150e-01 -1.15269e+00  3.37421e-01 -6.98225e-01  2.17269e+00
20Nov23_025850|   9.63798e-01 -1.43930e+00  1.71663e+00  7.51493e-01 -6.28456e-01]
20Nov23_025850| [-1.58838e+00  1.79189e+00  5.00478e-01 -1.25010e+00  7.03498e-01
20Nov23_025850|  -6.38268e-01  1.20227e+00  1.08421e+00  8.40502e-01  2.02490e+00]
20Nov23_025850| [ 3.67353e-01 -6.31589e-04  1.27834e+00 -1.39200e+00 -1.15876e+00
20Nov23_025850|   1.53865e+00 -7.44091e-01  4.73619e-01  2.04884e+00  1.62277e+00]
20Nov23_025850| [-1.55578e+00  1.55922e+00 -6.26084e-02  1.27440e+00  7.76317e-01
20Nov23_025850|  -3.31071e-01 -8.12146e-01  5.32258e-01 -1.03204e-01  5.74448e-01]
20Nov23_025850| [-1.66080e-01  9.27591e-01 -8.26749e-01 -2.02630e+00 -1.69057e+00
20Nov23_025850|   1.57038e+00 -9.36829e-01 -8.09723e-02 -1.40559e+00 -4.68670e-01]
20Nov23_025850| [ 1.31585e+00 -1.35879e+00  6.69832e-02 -6.76034e-01 -7.78053e-02
20Nov23_025850|   9.15890e-01 -2.57551e+00  1.17206e+00 -1.63833e-01 -1.51976e+00]
20Nov23_025850| [ 3.86571e-01  3.76960e-01  1.62203e+00 -6.63494e-01  5.79448e-01
20Nov23_025850|  -2.02899e-01  6.20663e-01 -8.74604e-01  5.65300e-01 -4.78021e-01]
20Nov23_025850| [ 2.84392e-01 -1.30287e+00 -2.40568e-01  1.64154e+00  8.57175e-01
20Nov23_025850|   1.66324e+00 -7.58044e-01  9.58194e-01  1.08895e+00  6.87897e-01]
20Nov23_025850| [ 1.91543e+00 -8.14252e-01 -8.52032e-01  3.78664e-01  1.90764e+00
20Nov23_025850|  -4.47222e-01 -2.69340e+00 -1.03904e+00 -2.00134e+00  2.38100e-01]
20Nov23_025850| [ 1.26019e+00  9.38744e-01 -3.14317e-01  7.86493e-01  4.76806e-01
20Nov23_025850|  -1.35297e-01  4.23375e-01 -2.08811e+00 -2.33768e-01 -6.56785e-01]
20Nov23_025850| [-1.79324e+00  2.42905e-02  1.37542e+00 -2.27793e+00  2.38915e+00
20Nov23_025850|   1.28801e-01 -1.29803e-01  1.69579e+00 -5.80142e-01  2.11689e+00]
20Nov23_025850| [ 9.34165e-01  7.98905e-01  9.33160e-01  1.26228e+00  8.33572e-01
20Nov23_025850|   8.94453e-01 -1.13623e+00  1.39619e+00 -6.78227e-01  8.70115e-01]
20Nov23_025850| [-1.10950e+00  2.87654e-01  2.71057e-01  8.54796e-01  1.22987e+00
20Nov23_025850|  -1.00751e+00 -5.61214e-01 -6.35672e-02 -9.03112e-01 -7.95657e-01]
20Nov23_025850| [-7.55905e-01  2.91320e-01 -1.58683e+00  5.85932e-01  2.65090e-01
20Nov23_025850|   1.77914e-01 -1.04044e-01 -1.09661e+00  9.38082e-02 -5.58226e-01]
20Nov23_025850| [-9.74231e-01  1.36123e+00 -4.42398e-01  1.01758e-01  3.66514e-01
20Nov23_025850|   1.28179e+00 -1.91686e+00  5.51070e-01  1.15574e+00 -7.07965e-01]
20Nov23_025850| [ 4.46124e-02  5.20958e-01  2.14918e+00  4.16463e-01 -8.15995e-03
20Nov23_025850|   1.50900e+00  2.03955e+00 -3.79312e-01  1.23712e+00 -9.03886e-01]
20Nov23_025850| [ 9.53918e-01 -1.00003e+00  1.67585e+00 -3.41251e+00  1.13867e+00
20Nov23_025850|   3.59439e-01  6.13636e-01 -5.79112e-01  1.84630e-01  1.27094e-01]
20Nov23_025850| [ 5.63295e-01 -7.65227e-01  1.14199e-01 -1.63298e+00  2.84249e-01
20Nov23_025850|  -6.66078e-01 -1.57556e+00  1.00746e+00  7.55489e-01 -9.87647e-01]
20Nov23_025850| [-7.69623e-01 -2.82068e-01  2.51158e+00 -7.90434e-01 -1.54072e+00
20Nov23_025850|   2.29525e+00  3.09859e-01  3.83551e-01 -9.54400e-01  7.70518e-01]
20Nov23_025850| [ 2.04135e+00 -1.89705e+00 -2.04564e+00  1.29505e+00  2.31663e-01
20Nov23_025850|  -1.07668e-01 -1.11612e-01 -4.62865e-01  1.10223e+00  9.01401e-01]
20Nov23_025850| [-6.45809e-01  4.89783e-01  2.17360e+00 -6.88799e-01  1.19751e+00
20Nov23_025850|   1.21721e+00 -2.17834e+00 -5.34672e-01  1.33385e+00 -2.08075e+00]
20Nov23_025850| [-4.18249e+00  1.95307e-01 -7.81067e-01  1.37136e+00 -2.13521e-01
20Nov23_025850|   1.59212e+00 -3.82342e-01  2.63593e+00 -1.00001e+00 -9.22583e-01]
20Nov23_025850| [ 7.01133e-01 -1.13910e+00  1.30671e+00 -5.14959e-01 -2.15790e+00
20Nov23_025850|  -9.44361e-01 -7.67735e-01 -1.24544e+00  1.21896e-01  1.44422e-02]
20Nov23_025850| [-5.05253e-01 -9.48834e-01 -1.35498e+00 -5.44439e-01  4.33973e-01
20Nov23_025850|   1.34650e+00 -1.59928e+00 -9.47020e-01  1.00715e+00 -2.13873e-01]
20Nov23_025850| [-4.95534e-01 -1.37437e-01 -7.25293e-01 -1.79721e+00  1.74471e+00
20Nov23_025850|  -9.68677e-01 -8.56409e-02  1.37133e+00 -7.11811e-01 -8.75033e-01]
20Nov23_025850| [ 1.75287e+00  4.58719e-01  6.66106e-01  1.10149e+00  1.57245e+00
20Nov23_025850|  -6.58958e-01 -7.97523e-01  4.49998e-01 -9.37306e-01  7.24107e-01]
20Nov23_025850| [-6.67339e-02  1.37247e+00  4.27743e-01  3.63566e-01  1.53543e+00
20Nov23_025850|  -2.46799e+00  1.38273e-01  9.09795e-01 -1.63558e+00 -2.33811e+00]
20Nov23_025850| [ 4.74738e-01  1.19072e+00  2.53531e-01  1.60539e+00 -1.19259e+00
20Nov23_025850|   8.16734e-01 -1.06184e+00 -8.57672e-01 -4.20009e-02  2.71981e-01]
20Nov23_025850| [-9.28704e-01  2.61080e+00  7.82101e-01  1.51103e+00 -1.65491e+00
20Nov23_025850|   1.67477e+00  1.27955e+00  9.86971e-01  1.12991e+00 -1.88014e+00]
20Nov23_025850| [-1.83175e+00  2.17081e+00 -1.12905e-01 -7.86976e-01  4.64954e-02
20Nov23_025850|   1.73163e+00 -2.10689e+00  2.17379e-01 -2.19104e+00  2.65990e-01]
20Nov23_025850| [ 5.99832e-01  2.26352e+00 -1.26344e+00  1.67205e+00  1.96797e+00
20Nov23_025850|  -1.04196e+00 -1.17036e+00 -5.82210e-01  3.44470e-01 -6.29446e-01]
20Nov23_025850| [-3.74647e-01  1.57396e+00 -1.23393e+00  1.77755e+00 -1.35559e+00
20Nov23_025850|  -3.50392e-01 -1.51221e+00 -3.50933e-01 -2.21108e+00  2.27891e+00]
20Nov23_025850| [ 1.79899e+00  9.29451e-01 -2.38156e+00 -2.95904e-01  5.01510e-02
20Nov23_025850|  -4.89236e-01 -3.81430e-02 -1.93658e-02 -2.81360e+00 -1.61727e+00]
20Nov23_025850| [-6.31664e-01  1.35179e-02 -8.62988e-01 -1.37577e+00 -1.76862e+00
20Nov23_025850|   7.53411e-01  8.42981e-01 -1.16891e+00 -1.94126e-01  1.64820e+00]
20Nov23_025850| [-9.45281e-01 -1.40671e+00 -2.98803e-01 -9.53509e-01 -7.63614e-01
20Nov23_025850|   3.42849e-02  1.95511e+00  1.79314e+00 -7.97121e-01 -1.37916e+00]
20Nov23_025850| [-1.21675e+00 -1.09576e+00 -3.20845e-01  7.37468e-01 -7.22748e-01
20Nov23_025850|  -4.89459e-01 -1.01331e+00  8.35708e-02  1.66520e-01  4.22179e-01]]
20Nov23_025850|-- Bias --
20Nov23_025850|[ 0.60392 -0.49720 -0.40465 -0.97662 -1.18628 -0.32953 -0.72463  1.47398
20Nov23_025850|  0.64550  0.75190]
20Nov23_025850|Layer 1:
20Nov23_025850|-- Config --
20Nov23_025850|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 10], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025850|-- Weights --
20Nov23_025850|[[-0.21679 -0.45691  0.28378  0.33784]
20Nov23_025850| [ 0.06390  0.16042 -0.55690  0.51363]
20Nov23_025850| [ 0.72633  0.93777 -0.75765  0.12993]
20Nov23_025850| [-0.62302  0.49010 -0.52417 -0.18200]
20Nov23_025850| [ 0.40134 -0.38242 -0.19617 -0.96393]
20Nov23_025850| [ 0.32070 -0.40738 -0.02044 -0.76057]
20Nov23_025850| [-0.43581  0.72040 -0.51486 -0.45397]
20Nov23_025850| [-0.62899 -0.42677 -0.34653 -0.07457]
20Nov23_025850| [-0.53423 -0.35014  0.48800 -0.44973]
20Nov23_025850| [ 0.80919  0.06153 -0.03718  0.65188]]
20Nov23_025850|-- Bias --
20Nov23_025850|[ 0.73864 -0.52503 -0.04894  0.56961]
20Nov23_025850|Layer 2:
20Nov23_025850|-- Config --
20Nov23_025850|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025850|-- Weights --
20Nov23_025850|[[ 0.12699 -0.47567]
20Nov23_025850| [ 1.38134  1.35039]
20Nov23_025850| [ 1.14654  1.78430]
20Nov23_025850| [ 0.41573  1.94888]]
20Nov23_025850|-- Bias --
20Nov23_025850|[ 0.02099 -0.36139]
20Nov23_025850|Predicting the validation and test data with the Best final individual.
20Nov23_025856| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_025856|-----------  ------------------  --------------------  ----------
20Nov23_025856|Validation         41.48                  28            0.01804
20Nov23_025856|   Test            36.40                  28            0.00000
20Nov23_025856|-------------------------- Test #10 --------------------------
20Nov23_025856|Best final individual weights
20Nov23_025856|Individual:
20Nov23_025856|-- Constant hidden layers --
20Nov23_025856|False
20Nov23_025856|Layer 0:
20Nov23_025856|-- Config --
20Nov23_025856|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 10, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025856|-- Weights --
20Nov23_025856|[[-3.07041e-01  1.00616e+00  6.34565e-01 -6.61114e-01 -5.46887e-01
20Nov23_025856|  -1.10888e+00  3.20769e-01 -4.30961e-02 -2.31163e-01  2.22718e+00]
20Nov23_025856| [ 3.40553e-01  8.74817e-01 -1.66864e+00 -7.83743e-01  1.10105e+00
20Nov23_025856|  -1.32534e+00  4.10905e-02  1.12271e+00  6.89412e-01 -1.53065e-01]
20Nov23_025856| [-1.26826e+00  5.87994e-01 -4.60418e-02 -3.55128e+00  1.04805e+00
20Nov23_025856|   1.61174e-01  1.16185e+00  5.66952e-01  6.72490e-01 -6.24827e-01]
20Nov23_025856| [-9.79202e-01  1.61247e-01 -1.27518e+00  5.18034e-01  1.98136e+00
20Nov23_025856|  -6.90936e-01  1.26940e-01  5.58500e-01  1.42756e-01  1.03981e+00]
20Nov23_025856| [-1.82313e-01  3.66685e-01  1.34275e+00  4.58416e-01 -1.18038e+00
20Nov23_025856|   2.51182e-01 -7.15217e-01 -1.66193e-01 -3.14859e-01  1.24005e+00]
20Nov23_025856| [ 1.48738e+00 -3.98929e-01  3.64868e-01  5.40263e-01  5.46416e-02
20Nov23_025856|   1.88146e+00  1.19580e+00 -2.43148e+00 -7.75186e-01 -6.49648e-01]
20Nov23_025856| [ 1.21399e+00  6.66074e-01  1.28060e+00 -6.11337e-01 -2.69644e-01
20Nov23_025856|  -2.53230e-03 -6.20683e-01  8.95056e-01 -1.08596e+00  3.64325e-01]
20Nov23_025856| [ 5.88481e-01  8.60948e-02  4.37503e-01 -1.84663e+00 -7.58324e-01
20Nov23_025856|   7.34596e-01  1.44969e+00 -8.81787e-01 -1.50155e-01 -1.06136e-01]
20Nov23_025856| [ 3.27155e-01  1.36855e+00 -2.04781e+00 -1.57615e+00 -4.51258e-01
20Nov23_025856|   3.02165e-01  6.43490e-01 -1.26883e-01 -5.94848e-01 -2.12811e+00]
20Nov23_025856| [-3.45131e-01 -1.81354e+00 -4.97743e-01  5.71362e-01 -8.54879e-01
20Nov23_025856|   3.65188e-01  1.95065e-01 -2.79676e-01  1.48447e-01  2.43540e-01]
20Nov23_025856| [-5.61218e-01  1.44002e+00  9.06417e-01 -3.99731e-01 -7.36291e-01
20Nov23_025856|  -9.66884e-01 -5.37313e-01 -8.49094e-01 -1.50517e+00  4.55984e-01]
20Nov23_025856| [ 1.70948e+00  8.12685e-01  2.75510e-02 -1.86415e+00 -1.60141e+00
20Nov23_025856|  -8.75582e-01 -8.89810e-01  5.20086e-01  7.91316e-01 -1.36802e+00]
20Nov23_025856| [-2.14098e-01  2.45515e-01  2.56778e-01  2.97405e-01 -1.38597e+00
20Nov23_025856|  -5.00160e-01  6.20253e-01 -7.58286e-01  3.35205e-01 -3.43907e+00]
20Nov23_025856| [ 4.03195e-01 -1.20324e-01  1.13366e+00  8.88009e-01 -9.37896e-03
20Nov23_025856|  -2.86522e-01  1.67710e+00  5.86515e-01 -1.06572e+00  1.39802e+00]
20Nov23_025856| [ 6.48180e-01 -1.92738e+00  1.50417e-02  8.68537e-02 -1.13786e+00
20Nov23_025856|  -1.29129e+00 -6.92839e-01 -1.40458e+00 -8.00986e-01  8.15326e-01]
20Nov23_025856| [ 1.57969e+00 -1.30609e-01 -1.29681e-01  1.04108e+00 -1.55760e+00
20Nov23_025856|  -1.01726e+00 -7.49064e-02  1.91418e-01  1.13480e+00 -1.29247e+00]
20Nov23_025856| [ 6.05486e-01 -1.20667e+00  1.83863e+00  1.62026e+00 -1.21907e+00
20Nov23_025856|  -1.85861e+00  6.32947e-01 -6.56312e-01 -1.96676e+00  9.10422e-01]
20Nov23_025856| [-1.17272e+00  1.65220e+00 -1.03529e+00 -8.72294e-02  2.90430e-01
20Nov23_025856|  -2.34656e+00  3.19297e-01 -1.87314e+00  5.04493e-01  4.65741e-01]
20Nov23_025856| [-9.48481e-02 -2.33962e-02 -5.93975e-02  3.19555e-02  3.49339e-01
20Nov23_025856|   6.49964e-01  6.53861e-01  8.66293e-01 -1.16838e+00 -9.17614e-01]
20Nov23_025856| [ 1.19783e+00  3.25987e-01  1.37329e+00  8.63944e-01 -9.03486e-01
20Nov23_025856|   1.38840e+00  1.49831e+00  1.17810e+00 -2.68505e+00  1.62729e+00]
20Nov23_025856| [-1.58344e+00 -2.33544e-01  8.36162e-01 -2.18260e+00 -1.15138e+00
20Nov23_025856|   1.45939e+00 -1.13930e+00 -3.86267e-01 -4.73407e-01 -9.27712e-01]
20Nov23_025856| [ 4.40150e-01 -1.15269e+00  3.37421e-01 -6.98225e-01  2.17269e+00
20Nov23_025856|   9.63798e-01 -1.43930e+00  1.71663e+00  7.51493e-01 -6.28456e-01]
20Nov23_025856| [-1.58838e+00  1.79189e+00  5.00478e-01 -1.25010e+00  7.03498e-01
20Nov23_025856|  -6.38268e-01  1.20227e+00  1.08421e+00  8.40502e-01  2.02490e+00]
20Nov23_025856| [ 3.67353e-01 -6.31589e-04  1.27834e+00 -1.39200e+00 -1.15876e+00
20Nov23_025856|   1.53865e+00 -7.44091e-01  4.73619e-01  2.04884e+00  1.62277e+00]
20Nov23_025856| [-1.55578e+00  1.55922e+00 -6.26084e-02  1.27440e+00  7.76317e-01
20Nov23_025856|  -3.31071e-01 -8.12146e-01  5.32258e-01 -1.03204e-01  5.74448e-01]
20Nov23_025856| [-1.66080e-01  9.27591e-01 -8.26749e-01 -2.02630e+00 -1.69057e+00
20Nov23_025856|   1.57038e+00 -9.36829e-01 -8.09723e-02 -1.40559e+00 -4.68670e-01]
20Nov23_025856| [ 1.31585e+00 -1.35879e+00  6.69832e-02 -6.76034e-01 -7.78053e-02
20Nov23_025856|   9.15890e-01 -2.57551e+00  1.17206e+00 -1.63833e-01 -1.51976e+00]
20Nov23_025856| [ 3.86571e-01  3.76960e-01  1.62203e+00 -6.63494e-01  5.79448e-01
20Nov23_025856|  -2.02899e-01  6.20663e-01 -8.74604e-01  5.65300e-01 -4.78021e-01]
20Nov23_025856| [ 2.84392e-01 -1.30287e+00 -2.40568e-01  1.64154e+00  8.57175e-01
20Nov23_025856|   1.66324e+00 -7.58044e-01  9.58194e-01  1.08895e+00  6.87897e-01]
20Nov23_025856| [ 1.91543e+00 -8.14252e-01 -8.52032e-01  3.78664e-01  1.90764e+00
20Nov23_025856|  -4.47222e-01 -2.69340e+00 -1.03904e+00 -2.00134e+00  2.38100e-01]
20Nov23_025856| [ 1.26019e+00  9.38744e-01 -3.14317e-01  7.86493e-01  4.76806e-01
20Nov23_025856|  -1.35297e-01  4.23375e-01 -2.08811e+00 -2.33768e-01 -6.56785e-01]
20Nov23_025856| [-1.79324e+00  2.42905e-02  1.37542e+00 -2.27793e+00  2.38915e+00
20Nov23_025856|   1.28801e-01 -1.29803e-01  1.69579e+00 -5.80142e-01  2.11689e+00]
20Nov23_025856| [ 9.34165e-01  7.98905e-01  9.33160e-01  1.26228e+00  8.33572e-01
20Nov23_025856|   8.94453e-01 -1.13623e+00  1.39619e+00 -6.78227e-01  8.70115e-01]
20Nov23_025856| [-1.10950e+00  2.87654e-01  2.71057e-01  8.54796e-01  1.22987e+00
20Nov23_025856|  -1.00751e+00 -5.61214e-01 -6.35672e-02 -9.03112e-01 -7.95657e-01]
20Nov23_025856| [-7.55905e-01  2.91320e-01 -1.58683e+00  5.85932e-01  2.65090e-01
20Nov23_025856|   1.77914e-01 -1.04044e-01 -1.09661e+00  9.38082e-02 -5.58226e-01]
20Nov23_025856| [-9.74231e-01  1.36123e+00 -4.42398e-01  1.01758e-01  3.66514e-01
20Nov23_025856|   1.28179e+00 -1.91686e+00  5.51070e-01  1.15574e+00 -7.07965e-01]
20Nov23_025856| [ 4.46124e-02  5.20958e-01  2.14918e+00  4.16463e-01 -8.15995e-03
20Nov23_025856|   1.50900e+00  2.03955e+00 -3.79312e-01  1.23712e+00 -9.03886e-01]
20Nov23_025856| [ 9.53918e-01 -1.00003e+00  1.67585e+00 -3.41251e+00  1.13867e+00
20Nov23_025856|   3.59439e-01  6.13636e-01 -5.79112e-01  1.84630e-01  1.27094e-01]
20Nov23_025856| [ 5.63295e-01 -7.65227e-01  1.14199e-01 -1.63298e+00  2.84249e-01
20Nov23_025856|  -6.66078e-01 -1.57556e+00  1.00746e+00  7.55489e-01 -9.87647e-01]
20Nov23_025856| [-7.69623e-01 -2.82068e-01  2.51158e+00 -7.90434e-01 -1.54072e+00
20Nov23_025856|   2.29525e+00  3.09859e-01  3.83551e-01 -9.54400e-01  7.70518e-01]
20Nov23_025856| [ 2.04135e+00 -1.89705e+00 -2.04564e+00  1.29505e+00  2.31663e-01
20Nov23_025856|  -1.07668e-01 -1.11612e-01 -4.62865e-01  1.10223e+00  9.01401e-01]
20Nov23_025856| [-6.45809e-01  4.89783e-01  2.17360e+00 -6.88799e-01  1.19751e+00
20Nov23_025856|   1.21721e+00 -2.17834e+00 -5.34672e-01  1.33385e+00 -2.08075e+00]
20Nov23_025856| [-4.18249e+00  1.95307e-01 -7.81067e-01  1.37136e+00 -2.13521e-01
20Nov23_025856|   1.59212e+00 -3.82342e-01  2.63593e+00 -1.00001e+00 -9.22583e-01]
20Nov23_025856| [ 7.01133e-01 -1.13910e+00  1.30671e+00 -5.14959e-01 -2.15790e+00
20Nov23_025856|  -9.44361e-01 -7.67735e-01 -1.24544e+00  1.21896e-01  1.44422e-02]
20Nov23_025856| [-5.05253e-01 -9.48834e-01 -1.35498e+00 -5.44439e-01  4.33973e-01
20Nov23_025856|   1.34650e+00 -1.59928e+00 -9.47020e-01  1.00715e+00 -2.13873e-01]
20Nov23_025856| [-4.95534e-01 -1.37437e-01 -7.25293e-01 -1.79721e+00  1.74471e+00
20Nov23_025856|  -9.68677e-01 -8.56409e-02  1.37133e+00 -7.11811e-01 -8.75033e-01]
20Nov23_025856| [ 1.75287e+00  4.58719e-01  6.66106e-01  1.10149e+00  1.57245e+00
20Nov23_025856|  -6.58958e-01 -7.97523e-01  4.49998e-01 -9.37306e-01  7.24107e-01]
20Nov23_025856| [-6.67339e-02  1.37247e+00  4.27743e-01  3.63566e-01  1.53543e+00
20Nov23_025856|  -2.46799e+00  1.38273e-01  9.09795e-01 -1.63558e+00 -2.33811e+00]
20Nov23_025856| [ 4.74738e-01  1.19072e+00  2.53531e-01  1.60539e+00 -1.19259e+00
20Nov23_025856|   8.16734e-01 -1.06184e+00 -8.57672e-01 -4.20009e-02  2.71981e-01]
20Nov23_025856| [-9.28704e-01  2.61080e+00  7.82101e-01  1.51103e+00 -1.65491e+00
20Nov23_025856|   1.67477e+00  1.27955e+00  9.86971e-01  1.12991e+00 -1.88014e+00]
20Nov23_025856| [-1.83175e+00  2.17081e+00 -1.12905e-01 -7.86976e-01  4.64954e-02
20Nov23_025856|   1.73163e+00 -2.10689e+00  2.17379e-01 -2.19104e+00  2.65990e-01]
20Nov23_025856| [ 5.99832e-01  2.26352e+00 -1.26344e+00  1.67205e+00  1.96797e+00
20Nov23_025856|  -1.04196e+00 -1.17036e+00 -5.82210e-01  3.44470e-01 -6.29446e-01]
20Nov23_025856| [-3.74647e-01  1.57396e+00 -1.23393e+00  1.77755e+00 -1.35559e+00
20Nov23_025856|  -3.50392e-01 -1.51221e+00 -3.50933e-01 -2.21108e+00  2.27891e+00]
20Nov23_025856| [ 1.79899e+00  9.29451e-01 -2.38156e+00 -2.95904e-01  5.01510e-02
20Nov23_025856|  -4.89236e-01 -3.81430e-02 -1.93658e-02 -2.81360e+00 -1.61727e+00]
20Nov23_025856| [-6.31664e-01  1.35179e-02 -8.62988e-01 -1.37577e+00 -1.76862e+00
20Nov23_025856|   7.53411e-01  8.42981e-01 -1.16891e+00 -1.94126e-01  1.64820e+00]
20Nov23_025856| [-9.45281e-01 -1.40671e+00 -2.98803e-01 -9.53509e-01 -7.63614e-01
20Nov23_025856|   3.42849e-02  1.95511e+00  1.79314e+00 -7.97121e-01 -1.37916e+00]
20Nov23_025856| [-1.21675e+00 -1.09576e+00 -3.20845e-01  7.37468e-01 -7.22748e-01
20Nov23_025856|  -4.89459e-01 -1.01331e+00  8.35708e-02  1.66520e-01  4.22179e-01]]
20Nov23_025856|-- Bias --
20Nov23_025856|[ 0.60392 -0.49720 -0.40465 -0.97662 -1.18628 -0.32953 -0.72463  1.47398
20Nov23_025856|  0.64550  0.75190]
20Nov23_025856|Layer 1:
20Nov23_025856|-- Config --
20Nov23_025856|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 10], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025856|-- Weights --
20Nov23_025856|[[-0.21679 -0.45691  0.28378  0.33784]
20Nov23_025856| [ 0.06390  0.16042 -0.55690  0.51363]
20Nov23_025856| [ 0.72633  0.93777 -0.75765  0.12993]
20Nov23_025856| [-0.62302  0.49010 -0.52417 -0.18200]
20Nov23_025856| [ 0.40134 -0.38242 -0.19617 -0.96393]
20Nov23_025856| [ 0.32070 -0.40738 -0.02044 -0.76057]
20Nov23_025856| [-0.43581  0.72040 -0.51486 -0.45397]
20Nov23_025856| [-0.62899 -0.42677 -0.34653 -0.07457]
20Nov23_025856| [-0.53423 -0.35014  0.48800 -0.44973]
20Nov23_025856| [ 0.80919  0.06153 -0.03718  0.65188]]
20Nov23_025856|-- Bias --
20Nov23_025856|[ 0.73864 -0.52503 -0.04894  0.56961]
20Nov23_025856|Layer 2:
20Nov23_025856|-- Config --
20Nov23_025856|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025856|-- Weights --
20Nov23_025856|[[ 0.12699 -0.47567]
20Nov23_025856| [ 1.38134  1.35039]
20Nov23_025856| [ 1.14654  1.78430]
20Nov23_025856| [ 0.41573  1.94888]]
20Nov23_025856|-- Bias --
20Nov23_025856|[ 0.02099 -0.36139]
20Nov23_025856|Predicting the validation and test data with the Best final individual.
20Nov23_025902| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_025902|-----------  ------------------  --------------------  ----------
20Nov23_025902|Validation         42.00                  28            0.00000
20Nov23_025902|   Test            37.45                  28            0.09407
20Nov23_025902|-------------------------- Test #11 --------------------------
20Nov23_025902|Best final individual weights
20Nov23_025902|Individual:
20Nov23_025902|-- Constant hidden layers --
20Nov23_025902|False
20Nov23_025902|Layer 0:
20Nov23_025902|-- Config --
20Nov23_025902|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 10, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025902|-- Weights --
20Nov23_025902|[[-3.07041e-01  1.00616e+00  6.34565e-01 -6.61114e-01 -5.46887e-01
20Nov23_025902|  -1.10888e+00  3.20769e-01 -4.30961e-02 -2.31163e-01  2.22718e+00]
20Nov23_025902| [ 3.40553e-01  8.74817e-01 -1.66864e+00 -7.83743e-01  1.10105e+00
20Nov23_025902|  -1.32534e+00  4.10905e-02  1.12271e+00  6.89412e-01 -1.53065e-01]
20Nov23_025902| [-1.26826e+00  5.87994e-01 -4.60418e-02 -3.55128e+00  1.04805e+00
20Nov23_025902|   1.61174e-01  1.16185e+00  5.66952e-01  6.72490e-01 -6.24827e-01]
20Nov23_025902| [-9.79202e-01  1.61247e-01 -1.27518e+00  5.18034e-01  1.98136e+00
20Nov23_025902|  -6.90936e-01  1.26940e-01  5.58500e-01  1.42756e-01  1.03981e+00]
20Nov23_025902| [-1.82313e-01  3.66685e-01  1.34275e+00  4.58416e-01 -1.18038e+00
20Nov23_025902|   2.51182e-01 -7.15217e-01 -1.66193e-01 -3.14859e-01  1.24005e+00]
20Nov23_025902| [ 1.48738e+00 -3.98929e-01  3.64868e-01  5.40263e-01  5.46416e-02
20Nov23_025902|   1.88146e+00  1.19580e+00 -2.43148e+00 -7.75186e-01 -6.49648e-01]
20Nov23_025902| [ 1.21399e+00  6.66074e-01  1.28060e+00 -6.11337e-01 -2.69644e-01
20Nov23_025902|  -2.53230e-03 -6.20683e-01  8.95056e-01 -1.08596e+00  3.64325e-01]
20Nov23_025902| [ 5.88481e-01  8.60948e-02  4.37503e-01 -1.84663e+00 -7.58324e-01
20Nov23_025902|   7.34596e-01  1.44969e+00 -8.81787e-01 -1.50155e-01 -1.06136e-01]
20Nov23_025902| [ 3.27155e-01  1.36855e+00 -2.04781e+00 -1.57615e+00 -4.51258e-01
20Nov23_025902|   3.02165e-01  6.43490e-01 -1.26883e-01 -5.94848e-01 -2.12811e+00]
20Nov23_025902| [-3.45131e-01 -1.81354e+00 -4.97743e-01  5.71362e-01 -8.54879e-01
20Nov23_025902|   3.65188e-01  1.95065e-01 -2.79676e-01  1.48447e-01  2.43540e-01]
20Nov23_025902| [-5.61218e-01  1.44002e+00  9.06417e-01 -3.99731e-01 -7.36291e-01
20Nov23_025902|  -9.66884e-01 -5.37313e-01 -8.49094e-01 -1.50517e+00  4.55984e-01]
20Nov23_025902| [ 1.70948e+00  8.12685e-01  2.75510e-02 -1.86415e+00 -1.60141e+00
20Nov23_025902|  -8.75582e-01 -8.89810e-01  5.20086e-01  7.91316e-01 -1.36802e+00]
20Nov23_025902| [-2.14098e-01  2.45515e-01  2.56778e-01  2.97405e-01 -1.38597e+00
20Nov23_025902|  -5.00160e-01  6.20253e-01 -7.58286e-01  3.35205e-01 -3.43907e+00]
20Nov23_025902| [ 4.03195e-01 -1.20324e-01  1.13366e+00  8.88009e-01 -9.37896e-03
20Nov23_025902|  -2.86522e-01  1.67710e+00  5.86515e-01 -1.06572e+00  1.39802e+00]
20Nov23_025902| [ 6.48180e-01 -1.92738e+00  1.50417e-02  8.68537e-02 -1.13786e+00
20Nov23_025902|  -1.29129e+00 -6.92839e-01 -1.40458e+00 -8.00986e-01  8.15326e-01]
20Nov23_025902| [ 1.57969e+00 -1.30609e-01 -1.29681e-01  1.04108e+00 -1.55760e+00
20Nov23_025902|  -1.01726e+00 -7.49064e-02  1.91418e-01  1.13480e+00 -1.29247e+00]
20Nov23_025902| [ 6.05486e-01 -1.20667e+00  1.83863e+00  1.62026e+00 -1.21907e+00
20Nov23_025902|  -1.85861e+00  6.32947e-01 -6.56312e-01 -1.96676e+00  9.10422e-01]
20Nov23_025902| [-1.17272e+00  1.65220e+00 -1.03529e+00 -8.72294e-02  2.90430e-01
20Nov23_025902|  -2.34656e+00  3.19297e-01 -1.87314e+00  5.04493e-01  4.65741e-01]
20Nov23_025902| [-9.48481e-02 -2.33962e-02 -5.93975e-02  3.19555e-02  3.49339e-01
20Nov23_025902|   6.49964e-01  6.53861e-01  8.66293e-01 -1.16838e+00 -9.17614e-01]
20Nov23_025902| [ 1.19783e+00  3.25987e-01  1.37329e+00  8.63944e-01 -9.03486e-01
20Nov23_025902|   1.38840e+00  1.49831e+00  1.17810e+00 -2.68505e+00  1.62729e+00]
20Nov23_025902| [-1.58344e+00 -2.33544e-01  8.36162e-01 -2.18260e+00 -1.15138e+00
20Nov23_025902|   1.45939e+00 -1.13930e+00 -3.86267e-01 -4.73407e-01 -9.27712e-01]
20Nov23_025902| [ 4.40150e-01 -1.15269e+00  3.37421e-01 -6.98225e-01  2.17269e+00
20Nov23_025902|   9.63798e-01 -1.43930e+00  1.71663e+00  7.51493e-01 -6.28456e-01]
20Nov23_025902| [-1.58838e+00  1.79189e+00  5.00478e-01 -1.25010e+00  7.03498e-01
20Nov23_025902|  -6.38268e-01  1.20227e+00  1.08421e+00  8.40502e-01  2.02490e+00]
20Nov23_025902| [ 3.67353e-01 -6.31589e-04  1.27834e+00 -1.39200e+00 -1.15876e+00
20Nov23_025902|   1.53865e+00 -7.44091e-01  4.73619e-01  2.04884e+00  1.62277e+00]
20Nov23_025902| [-1.55578e+00  1.55922e+00 -6.26084e-02  1.27440e+00  7.76317e-01
20Nov23_025902|  -3.31071e-01 -8.12146e-01  5.32258e-01 -1.03204e-01  5.74448e-01]
20Nov23_025902| [-1.66080e-01  9.27591e-01 -8.26749e-01 -2.02630e+00 -1.69057e+00
20Nov23_025902|   1.57038e+00 -9.36829e-01 -8.09723e-02 -1.40559e+00 -4.68670e-01]
20Nov23_025902| [ 1.31585e+00 -1.35879e+00  6.69832e-02 -6.76034e-01 -7.78053e-02
20Nov23_025902|   9.15890e-01 -2.57551e+00  1.17206e+00 -1.63833e-01 -1.51976e+00]
20Nov23_025902| [ 3.86571e-01  3.76960e-01  1.62203e+00 -6.63494e-01  5.79448e-01
20Nov23_025902|  -2.02899e-01  6.20663e-01 -8.74604e-01  5.65300e-01 -4.78021e-01]
20Nov23_025902| [ 2.84392e-01 -1.30287e+00 -2.40568e-01  1.64154e+00  8.57175e-01
20Nov23_025902|   1.66324e+00 -7.58044e-01  9.58194e-01  1.08895e+00  6.87897e-01]
20Nov23_025902| [ 1.91543e+00 -8.14252e-01 -8.52032e-01  3.78664e-01  1.90764e+00
20Nov23_025902|  -4.47222e-01 -2.69340e+00 -1.03904e+00 -2.00134e+00  2.38100e-01]
20Nov23_025902| [ 1.26019e+00  9.38744e-01 -3.14317e-01  7.86493e-01  4.76806e-01
20Nov23_025902|  -1.35297e-01  4.23375e-01 -2.08811e+00 -2.33768e-01 -6.56785e-01]
20Nov23_025902| [-1.79324e+00  2.42905e-02  1.37542e+00 -2.27793e+00  2.38915e+00
20Nov23_025902|   1.28801e-01 -1.29803e-01  1.69579e+00 -5.80142e-01  2.11689e+00]
20Nov23_025902| [ 9.34165e-01  7.98905e-01  9.33160e-01  1.26228e+00  8.33572e-01
20Nov23_025902|   8.94453e-01 -1.13623e+00  1.39619e+00 -6.78227e-01  8.70115e-01]
20Nov23_025902| [-1.10950e+00  2.87654e-01  2.71057e-01  8.54796e-01  1.22987e+00
20Nov23_025902|  -1.00751e+00 -5.61214e-01 -6.35672e-02 -9.03112e-01 -7.95657e-01]
20Nov23_025902| [-7.55905e-01  2.91320e-01 -1.58683e+00  5.85932e-01  2.65090e-01
20Nov23_025902|   1.77914e-01 -1.04044e-01 -1.09661e+00  9.38082e-02 -5.58226e-01]
20Nov23_025902| [-9.74231e-01  1.36123e+00 -4.42398e-01  1.01758e-01  3.66514e-01
20Nov23_025902|   1.28179e+00 -1.91686e+00  5.51070e-01  1.15574e+00 -7.07965e-01]
20Nov23_025902| [ 4.46124e-02  5.20958e-01  2.14918e+00  4.16463e-01 -8.15995e-03
20Nov23_025902|   1.50900e+00  2.03955e+00 -3.79312e-01  1.23712e+00 -9.03886e-01]
20Nov23_025902| [ 9.53918e-01 -1.00003e+00  1.67585e+00 -3.41251e+00  1.13867e+00
20Nov23_025902|   3.59439e-01  6.13636e-01 -5.79112e-01  1.84630e-01  1.27094e-01]
20Nov23_025902| [ 5.63295e-01 -7.65227e-01  1.14199e-01 -1.63298e+00  2.84249e-01
20Nov23_025902|  -6.66078e-01 -1.57556e+00  1.00746e+00  7.55489e-01 -9.87647e-01]
20Nov23_025902| [-7.69623e-01 -2.82068e-01  2.51158e+00 -7.90434e-01 -1.54072e+00
20Nov23_025902|   2.29525e+00  3.09859e-01  3.83551e-01 -9.54400e-01  7.70518e-01]
20Nov23_025902| [ 2.04135e+00 -1.89705e+00 -2.04564e+00  1.29505e+00  2.31663e-01
20Nov23_025902|  -1.07668e-01 -1.11612e-01 -4.62865e-01  1.10223e+00  9.01401e-01]
20Nov23_025902| [-6.45809e-01  4.89783e-01  2.17360e+00 -6.88799e-01  1.19751e+00
20Nov23_025902|   1.21721e+00 -2.17834e+00 -5.34672e-01  1.33385e+00 -2.08075e+00]
20Nov23_025902| [-4.18249e+00  1.95307e-01 -7.81067e-01  1.37136e+00 -2.13521e-01
20Nov23_025902|   1.59212e+00 -3.82342e-01  2.63593e+00 -1.00001e+00 -9.22583e-01]
20Nov23_025902| [ 7.01133e-01 -1.13910e+00  1.30671e+00 -5.14959e-01 -2.15790e+00
20Nov23_025902|  -9.44361e-01 -7.67735e-01 -1.24544e+00  1.21896e-01  1.44422e-02]
20Nov23_025902| [-5.05253e-01 -9.48834e-01 -1.35498e+00 -5.44439e-01  4.33973e-01
20Nov23_025902|   1.34650e+00 -1.59928e+00 -9.47020e-01  1.00715e+00 -2.13873e-01]
20Nov23_025902| [-4.95534e-01 -1.37437e-01 -7.25293e-01 -1.79721e+00  1.74471e+00
20Nov23_025902|  -9.68677e-01 -8.56409e-02  1.37133e+00 -7.11811e-01 -8.75033e-01]
20Nov23_025902| [ 1.75287e+00  4.58719e-01  6.66106e-01  1.10149e+00  1.57245e+00
20Nov23_025902|  -6.58958e-01 -7.97523e-01  4.49998e-01 -9.37306e-01  7.24107e-01]
20Nov23_025902| [-6.67339e-02  1.37247e+00  4.27743e-01  3.63566e-01  1.53543e+00
20Nov23_025902|  -2.46799e+00  1.38273e-01  9.09795e-01 -1.63558e+00 -2.33811e+00]
20Nov23_025902| [ 4.74738e-01  1.19072e+00  2.53531e-01  1.60539e+00 -1.19259e+00
20Nov23_025902|   8.16734e-01 -1.06184e+00 -8.57672e-01 -4.20009e-02  2.71981e-01]
20Nov23_025902| [-9.28704e-01  2.61080e+00  7.82101e-01  1.51103e+00 -1.65491e+00
20Nov23_025902|   1.67477e+00  1.27955e+00  9.86971e-01  1.12991e+00 -1.88014e+00]
20Nov23_025902| [-1.83175e+00  2.17081e+00 -1.12905e-01 -7.86976e-01  4.64954e-02
20Nov23_025902|   1.73163e+00 -2.10689e+00  2.17379e-01 -2.19104e+00  2.65990e-01]
20Nov23_025902| [ 5.99832e-01  2.26352e+00 -1.26344e+00  1.67205e+00  1.96797e+00
20Nov23_025902|  -1.04196e+00 -1.17036e+00 -5.82210e-01  3.44470e-01 -6.29446e-01]
20Nov23_025902| [-3.74647e-01  1.57396e+00 -1.23393e+00  1.77755e+00 -1.35559e+00
20Nov23_025902|  -3.50392e-01 -1.51221e+00 -3.50933e-01 -2.21108e+00  2.27891e+00]
20Nov23_025902| [ 1.79899e+00  9.29451e-01 -2.38156e+00 -2.95904e-01  5.01510e-02
20Nov23_025902|  -4.89236e-01 -3.81430e-02 -1.93658e-02 -2.81360e+00 -1.61727e+00]
20Nov23_025902| [-6.31664e-01  1.35179e-02 -8.62988e-01 -1.37577e+00 -1.76862e+00
20Nov23_025902|   7.53411e-01  8.42981e-01 -1.16891e+00 -1.94126e-01  1.64820e+00]
20Nov23_025902| [-9.45281e-01 -1.40671e+00 -2.98803e-01 -9.53509e-01 -7.63614e-01
20Nov23_025902|   3.42849e-02  1.95511e+00  1.79314e+00 -7.97121e-01 -1.37916e+00]
20Nov23_025902| [-1.21675e+00 -1.09576e+00 -3.20845e-01  7.37468e-01 -7.22748e-01
20Nov23_025902|  -4.89459e-01 -1.01331e+00  8.35708e-02  1.66520e-01  4.22179e-01]]
20Nov23_025902|-- Bias --
20Nov23_025902|[ 0.60392 -0.49720 -0.40465 -0.97662 -1.18628 -0.32953 -0.72463  1.47398
20Nov23_025902|  0.64550  0.75190]
20Nov23_025902|Layer 1:
20Nov23_025902|-- Config --
20Nov23_025902|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 10], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025902|-- Weights --
20Nov23_025902|[[-0.21679 -0.45691  0.28378  0.33784]
20Nov23_025902| [ 0.06390  0.16042 -0.55690  0.51363]
20Nov23_025902| [ 0.72633  0.93777 -0.75765  0.12993]
20Nov23_025902| [-0.62302  0.49010 -0.52417 -0.18200]
20Nov23_025902| [ 0.40134 -0.38242 -0.19617 -0.96393]
20Nov23_025902| [ 0.32070 -0.40738 -0.02044 -0.76057]
20Nov23_025902| [-0.43581  0.72040 -0.51486 -0.45397]
20Nov23_025902| [-0.62899 -0.42677 -0.34653 -0.07457]
20Nov23_025902| [-0.53423 -0.35014  0.48800 -0.44973]
20Nov23_025902| [ 0.80919  0.06153 -0.03718  0.65188]]
20Nov23_025902|-- Bias --
20Nov23_025902|[ 0.73864 -0.52503 -0.04894  0.56961]
20Nov23_025902|Layer 2:
20Nov23_025902|-- Config --
20Nov23_025902|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025902|-- Weights --
20Nov23_025902|[[ 0.12699 -0.47567]
20Nov23_025902| [ 1.38134  1.35039]
20Nov23_025902| [ 1.14654  1.78430]
20Nov23_025902| [ 0.41573  1.94888]]
20Nov23_025902|-- Bias --
20Nov23_025902|[ 0.02099 -0.36139]
20Nov23_025902|Predicting the validation and test data with the Best final individual.
20Nov23_025908| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_025908|-----------  ------------------  --------------------  ----------
20Nov23_025908|Validation         29.22                  28            0.54705
20Nov23_025908|   Test            36.40                  28            0.00000
20Nov23_025908|-------------------------- Test #12 --------------------------
20Nov23_025908|Best final individual weights
20Nov23_025908|Individual:
20Nov23_025908|-- Constant hidden layers --
20Nov23_025908|False
20Nov23_025908|Layer 0:
20Nov23_025908|-- Config --
20Nov23_025908|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 10, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025908|-- Weights --
20Nov23_025908|[[-3.07041e-01  1.00616e+00  6.34565e-01 -6.61114e-01 -5.46887e-01
20Nov23_025908|  -1.10888e+00  3.20769e-01 -4.30961e-02 -2.31163e-01  2.22718e+00]
20Nov23_025908| [ 3.40553e-01  8.74817e-01 -1.66864e+00 -7.83743e-01  1.10105e+00
20Nov23_025908|  -1.32534e+00  4.10905e-02  1.12271e+00  6.89412e-01 -1.53065e-01]
20Nov23_025908| [-1.26826e+00  5.87994e-01 -4.60418e-02 -3.55128e+00  1.04805e+00
20Nov23_025908|   1.61174e-01  1.16185e+00  5.66952e-01  6.72490e-01 -6.24827e-01]
20Nov23_025908| [-9.79202e-01  1.61247e-01 -1.27518e+00  5.18034e-01  1.98136e+00
20Nov23_025908|  -6.90936e-01  1.26940e-01  5.58500e-01  1.42756e-01  1.03981e+00]
20Nov23_025908| [-1.82313e-01  3.66685e-01  1.34275e+00  4.58416e-01 -1.18038e+00
20Nov23_025908|   2.51182e-01 -7.15217e-01 -1.66193e-01 -3.14859e-01  1.24005e+00]
20Nov23_025908| [ 1.48738e+00 -3.98929e-01  3.64868e-01  5.40263e-01  5.46416e-02
20Nov23_025908|   1.88146e+00  1.19580e+00 -2.43148e+00 -7.75186e-01 -6.49648e-01]
20Nov23_025908| [ 1.21399e+00  6.66074e-01  1.28060e+00 -6.11337e-01 -2.69644e-01
20Nov23_025908|  -2.53230e-03 -6.20683e-01  8.95056e-01 -1.08596e+00  3.64325e-01]
20Nov23_025908| [ 5.88481e-01  8.60948e-02  4.37503e-01 -1.84663e+00 -7.58324e-01
20Nov23_025908|   7.34596e-01  1.44969e+00 -8.81787e-01 -1.50155e-01 -1.06136e-01]
20Nov23_025908| [ 3.27155e-01  1.36855e+00 -2.04781e+00 -1.57615e+00 -4.51258e-01
20Nov23_025908|   3.02165e-01  6.43490e-01 -1.26883e-01 -5.94848e-01 -2.12811e+00]
20Nov23_025908| [-3.45131e-01 -1.81354e+00 -4.97743e-01  5.71362e-01 -8.54879e-01
20Nov23_025908|   3.65188e-01  1.95065e-01 -2.79676e-01  1.48447e-01  2.43540e-01]
20Nov23_025908| [-5.61218e-01  1.44002e+00  9.06417e-01 -3.99731e-01 -7.36291e-01
20Nov23_025908|  -9.66884e-01 -5.37313e-01 -8.49094e-01 -1.50517e+00  4.55984e-01]
20Nov23_025908| [ 1.70948e+00  8.12685e-01  2.75510e-02 -1.86415e+00 -1.60141e+00
20Nov23_025908|  -8.75582e-01 -8.89810e-01  5.20086e-01  7.91316e-01 -1.36802e+00]
20Nov23_025908| [-2.14098e-01  2.45515e-01  2.56778e-01  2.97405e-01 -1.38597e+00
20Nov23_025908|  -5.00160e-01  6.20253e-01 -7.58286e-01  3.35205e-01 -3.43907e+00]
20Nov23_025908| [ 4.03195e-01 -1.20324e-01  1.13366e+00  8.88009e-01 -9.37896e-03
20Nov23_025908|  -2.86522e-01  1.67710e+00  5.86515e-01 -1.06572e+00  1.39802e+00]
20Nov23_025908| [ 6.48180e-01 -1.92738e+00  1.50417e-02  8.68537e-02 -1.13786e+00
20Nov23_025908|  -1.29129e+00 -6.92839e-01 -1.40458e+00 -8.00986e-01  8.15326e-01]
20Nov23_025908| [ 1.57969e+00 -1.30609e-01 -1.29681e-01  1.04108e+00 -1.55760e+00
20Nov23_025908|  -1.01726e+00 -7.49064e-02  1.91418e-01  1.13480e+00 -1.29247e+00]
20Nov23_025908| [ 6.05486e-01 -1.20667e+00  1.83863e+00  1.62026e+00 -1.21907e+00
20Nov23_025908|  -1.85861e+00  6.32947e-01 -6.56312e-01 -1.96676e+00  9.10422e-01]
20Nov23_025908| [-1.17272e+00  1.65220e+00 -1.03529e+00 -8.72294e-02  2.90430e-01
20Nov23_025908|  -2.34656e+00  3.19297e-01 -1.87314e+00  5.04493e-01  4.65741e-01]
20Nov23_025908| [-9.48481e-02 -2.33962e-02 -5.93975e-02  3.19555e-02  3.49339e-01
20Nov23_025908|   6.49964e-01  6.53861e-01  8.66293e-01 -1.16838e+00 -9.17614e-01]
20Nov23_025908| [ 1.19783e+00  3.25987e-01  1.37329e+00  8.63944e-01 -9.03486e-01
20Nov23_025908|   1.38840e+00  1.49831e+00  1.17810e+00 -2.68505e+00  1.62729e+00]
20Nov23_025908| [-1.58344e+00 -2.33544e-01  8.36162e-01 -2.18260e+00 -1.15138e+00
20Nov23_025908|   1.45939e+00 -1.13930e+00 -3.86267e-01 -4.73407e-01 -9.27712e-01]
20Nov23_025908| [ 4.40150e-01 -1.15269e+00  3.37421e-01 -6.98225e-01  2.17269e+00
20Nov23_025908|   9.63798e-01 -1.43930e+00  1.71663e+00  7.51493e-01 -6.28456e-01]
20Nov23_025908| [-1.58838e+00  1.79189e+00  5.00478e-01 -1.25010e+00  7.03498e-01
20Nov23_025908|  -6.38268e-01  1.20227e+00  1.08421e+00  8.40502e-01  2.02490e+00]
20Nov23_025908| [ 3.67353e-01 -6.31589e-04  1.27834e+00 -1.39200e+00 -1.15876e+00
20Nov23_025908|   1.53865e+00 -7.44091e-01  4.73619e-01  2.04884e+00  1.62277e+00]
20Nov23_025908| [-1.55578e+00  1.55922e+00 -6.26084e-02  1.27440e+00  7.76317e-01
20Nov23_025908|  -3.31071e-01 -8.12146e-01  5.32258e-01 -1.03204e-01  5.74448e-01]
20Nov23_025908| [-1.66080e-01  9.27591e-01 -8.26749e-01 -2.02630e+00 -1.69057e+00
20Nov23_025908|   1.57038e+00 -9.36829e-01 -8.09723e-02 -1.40559e+00 -4.68670e-01]
20Nov23_025908| [ 1.31585e+00 -1.35879e+00  6.69832e-02 -6.76034e-01 -7.78053e-02
20Nov23_025908|   9.15890e-01 -2.57551e+00  1.17206e+00 -1.63833e-01 -1.51976e+00]
20Nov23_025908| [ 3.86571e-01  3.76960e-01  1.62203e+00 -6.63494e-01  5.79448e-01
20Nov23_025908|  -2.02899e-01  6.20663e-01 -8.74604e-01  5.65300e-01 -4.78021e-01]
20Nov23_025908| [ 2.84392e-01 -1.30287e+00 -2.40568e-01  1.64154e+00  8.57175e-01
20Nov23_025908|   1.66324e+00 -7.58044e-01  9.58194e-01  1.08895e+00  6.87897e-01]
20Nov23_025908| [ 1.91543e+00 -8.14252e-01 -8.52032e-01  3.78664e-01  1.90764e+00
20Nov23_025908|  -4.47222e-01 -2.69340e+00 -1.03904e+00 -2.00134e+00  2.38100e-01]
20Nov23_025908| [ 1.26019e+00  9.38744e-01 -3.14317e-01  7.86493e-01  4.76806e-01
20Nov23_025908|  -1.35297e-01  4.23375e-01 -2.08811e+00 -2.33768e-01 -6.56785e-01]
20Nov23_025908| [-1.79324e+00  2.42905e-02  1.37542e+00 -2.27793e+00  2.38915e+00
20Nov23_025908|   1.28801e-01 -1.29803e-01  1.69579e+00 -5.80142e-01  2.11689e+00]
20Nov23_025908| [ 9.34165e-01  7.98905e-01  9.33160e-01  1.26228e+00  8.33572e-01
20Nov23_025908|   8.94453e-01 -1.13623e+00  1.39619e+00 -6.78227e-01  8.70115e-01]
20Nov23_025908| [-1.10950e+00  2.87654e-01  2.71057e-01  8.54796e-01  1.22987e+00
20Nov23_025908|  -1.00751e+00 -5.61214e-01 -6.35672e-02 -9.03112e-01 -7.95657e-01]
20Nov23_025908| [-7.55905e-01  2.91320e-01 -1.58683e+00  5.85932e-01  2.65090e-01
20Nov23_025908|   1.77914e-01 -1.04044e-01 -1.09661e+00  9.38082e-02 -5.58226e-01]
20Nov23_025908| [-9.74231e-01  1.36123e+00 -4.42398e-01  1.01758e-01  3.66514e-01
20Nov23_025908|   1.28179e+00 -1.91686e+00  5.51070e-01  1.15574e+00 -7.07965e-01]
20Nov23_025908| [ 4.46124e-02  5.20958e-01  2.14918e+00  4.16463e-01 -8.15995e-03
20Nov23_025908|   1.50900e+00  2.03955e+00 -3.79312e-01  1.23712e+00 -9.03886e-01]
20Nov23_025908| [ 9.53918e-01 -1.00003e+00  1.67585e+00 -3.41251e+00  1.13867e+00
20Nov23_025908|   3.59439e-01  6.13636e-01 -5.79112e-01  1.84630e-01  1.27094e-01]
20Nov23_025908| [ 5.63295e-01 -7.65227e-01  1.14199e-01 -1.63298e+00  2.84249e-01
20Nov23_025908|  -6.66078e-01 -1.57556e+00  1.00746e+00  7.55489e-01 -9.87647e-01]
20Nov23_025908| [-7.69623e-01 -2.82068e-01  2.51158e+00 -7.90434e-01 -1.54072e+00
20Nov23_025908|   2.29525e+00  3.09859e-01  3.83551e-01 -9.54400e-01  7.70518e-01]
20Nov23_025908| [ 2.04135e+00 -1.89705e+00 -2.04564e+00  1.29505e+00  2.31663e-01
20Nov23_025908|  -1.07668e-01 -1.11612e-01 -4.62865e-01  1.10223e+00  9.01401e-01]
20Nov23_025908| [-6.45809e-01  4.89783e-01  2.17360e+00 -6.88799e-01  1.19751e+00
20Nov23_025908|   1.21721e+00 -2.17834e+00 -5.34672e-01  1.33385e+00 -2.08075e+00]
20Nov23_025908| [-4.18249e+00  1.95307e-01 -7.81067e-01  1.37136e+00 -2.13521e-01
20Nov23_025908|   1.59212e+00 -3.82342e-01  2.63593e+00 -1.00001e+00 -9.22583e-01]
20Nov23_025908| [ 7.01133e-01 -1.13910e+00  1.30671e+00 -5.14959e-01 -2.15790e+00
20Nov23_025908|  -9.44361e-01 -7.67735e-01 -1.24544e+00  1.21896e-01  1.44422e-02]
20Nov23_025908| [-5.05253e-01 -9.48834e-01 -1.35498e+00 -5.44439e-01  4.33973e-01
20Nov23_025908|   1.34650e+00 -1.59928e+00 -9.47020e-01  1.00715e+00 -2.13873e-01]
20Nov23_025908| [-4.95534e-01 -1.37437e-01 -7.25293e-01 -1.79721e+00  1.74471e+00
20Nov23_025908|  -9.68677e-01 -8.56409e-02  1.37133e+00 -7.11811e-01 -8.75033e-01]
20Nov23_025908| [ 1.75287e+00  4.58719e-01  6.66106e-01  1.10149e+00  1.57245e+00
20Nov23_025908|  -6.58958e-01 -7.97523e-01  4.49998e-01 -9.37306e-01  7.24107e-01]
20Nov23_025908| [-6.67339e-02  1.37247e+00  4.27743e-01  3.63566e-01  1.53543e+00
20Nov23_025908|  -2.46799e+00  1.38273e-01  9.09795e-01 -1.63558e+00 -2.33811e+00]
20Nov23_025908| [ 4.74738e-01  1.19072e+00  2.53531e-01  1.60539e+00 -1.19259e+00
20Nov23_025908|   8.16734e-01 -1.06184e+00 -8.57672e-01 -4.20009e-02  2.71981e-01]
20Nov23_025908| [-9.28704e-01  2.61080e+00  7.82101e-01  1.51103e+00 -1.65491e+00
20Nov23_025908|   1.67477e+00  1.27955e+00  9.86971e-01  1.12991e+00 -1.88014e+00]
20Nov23_025908| [-1.83175e+00  2.17081e+00 -1.12905e-01 -7.86976e-01  4.64954e-02
20Nov23_025908|   1.73163e+00 -2.10689e+00  2.17379e-01 -2.19104e+00  2.65990e-01]
20Nov23_025908| [ 5.99832e-01  2.26352e+00 -1.26344e+00  1.67205e+00  1.96797e+00
20Nov23_025908|  -1.04196e+00 -1.17036e+00 -5.82210e-01  3.44470e-01 -6.29446e-01]
20Nov23_025908| [-3.74647e-01  1.57396e+00 -1.23393e+00  1.77755e+00 -1.35559e+00
20Nov23_025908|  -3.50392e-01 -1.51221e+00 -3.50933e-01 -2.21108e+00  2.27891e+00]
20Nov23_025908| [ 1.79899e+00  9.29451e-01 -2.38156e+00 -2.95904e-01  5.01510e-02
20Nov23_025908|  -4.89236e-01 -3.81430e-02 -1.93658e-02 -2.81360e+00 -1.61727e+00]
20Nov23_025908| [-6.31664e-01  1.35179e-02 -8.62988e-01 -1.37577e+00 -1.76862e+00
20Nov23_025908|   7.53411e-01  8.42981e-01 -1.16891e+00 -1.94126e-01  1.64820e+00]
20Nov23_025908| [-9.45281e-01 -1.40671e+00 -2.98803e-01 -9.53509e-01 -7.63614e-01
20Nov23_025908|   3.42849e-02  1.95511e+00  1.79314e+00 -7.97121e-01 -1.37916e+00]
20Nov23_025908| [-1.21675e+00 -1.09576e+00 -3.20845e-01  7.37468e-01 -7.22748e-01
20Nov23_025908|  -4.89459e-01 -1.01331e+00  8.35708e-02  1.66520e-01  4.22179e-01]]
20Nov23_025908|-- Bias --
20Nov23_025908|[ 0.60392 -0.49720 -0.40465 -0.97662 -1.18628 -0.32953 -0.72463  1.47398
20Nov23_025908|  0.64550  0.75190]
20Nov23_025908|Layer 1:
20Nov23_025908|-- Config --
20Nov23_025908|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 10], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025908|-- Weights --
20Nov23_025908|[[-0.21679 -0.45691  0.28378  0.33784]
20Nov23_025908| [ 0.06390  0.16042 -0.55690  0.51363]
20Nov23_025908| [ 0.72633  0.93777 -0.75765  0.12993]
20Nov23_025908| [-0.62302  0.49010 -0.52417 -0.18200]
20Nov23_025908| [ 0.40134 -0.38242 -0.19617 -0.96393]
20Nov23_025908| [ 0.32070 -0.40738 -0.02044 -0.76057]
20Nov23_025908| [-0.43581  0.72040 -0.51486 -0.45397]
20Nov23_025908| [-0.62899 -0.42677 -0.34653 -0.07457]
20Nov23_025908| [-0.53423 -0.35014  0.48800 -0.44973]
20Nov23_025908| [ 0.80919  0.06153 -0.03718  0.65188]]
20Nov23_025908|-- Bias --
20Nov23_025908|[ 0.73864 -0.52503 -0.04894  0.56961]
20Nov23_025908|Layer 2:
20Nov23_025908|-- Config --
20Nov23_025908|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025908|-- Weights --
20Nov23_025908|[[ 0.12699 -0.47567]
20Nov23_025908| [ 1.38134  1.35039]
20Nov23_025908| [ 1.14654  1.78430]
20Nov23_025908| [ 0.41573  1.94888]]
20Nov23_025908|-- Bias --
20Nov23_025908|[ 0.02099 -0.36139]
20Nov23_025908|Predicting the validation and test data with the Best final individual.
20Nov23_025914| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_025914|-----------  ------------------  --------------------  ----------
20Nov23_025914|Validation         41.13                  28            0.15152
20Nov23_025914|   Test            36.40                  28            0.00000
20Nov23_025914|-------------------------- Test #13 --------------------------
20Nov23_025914|Best final individual weights
20Nov23_025914|Individual:
20Nov23_025914|-- Constant hidden layers --
20Nov23_025914|False
20Nov23_025914|Layer 0:
20Nov23_025914|-- Config --
20Nov23_025914|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 10, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025914|-- Weights --
20Nov23_025914|[[-3.07041e-01  1.00616e+00  6.34565e-01 -6.61114e-01 -5.46887e-01
20Nov23_025914|  -1.10888e+00  3.20769e-01 -4.30961e-02 -2.31163e-01  2.22718e+00]
20Nov23_025914| [ 3.40553e-01  8.74817e-01 -1.66864e+00 -7.83743e-01  1.10105e+00
20Nov23_025914|  -1.32534e+00  4.10905e-02  1.12271e+00  6.89412e-01 -1.53065e-01]
20Nov23_025914| [-1.26826e+00  5.87994e-01 -4.60418e-02 -3.55128e+00  1.04805e+00
20Nov23_025914|   1.61174e-01  1.16185e+00  5.66952e-01  6.72490e-01 -6.24827e-01]
20Nov23_025914| [-9.79202e-01  1.61247e-01 -1.27518e+00  5.18034e-01  1.98136e+00
20Nov23_025914|  -6.90936e-01  1.26940e-01  5.58500e-01  1.42756e-01  1.03981e+00]
20Nov23_025914| [-1.82313e-01  3.66685e-01  1.34275e+00  4.58416e-01 -1.18038e+00
20Nov23_025914|   2.51182e-01 -7.15217e-01 -1.66193e-01 -3.14859e-01  1.24005e+00]
20Nov23_025914| [ 1.48738e+00 -3.98929e-01  3.64868e-01  5.40263e-01  5.46416e-02
20Nov23_025914|   1.88146e+00  1.19580e+00 -2.43148e+00 -7.75186e-01 -6.49648e-01]
20Nov23_025914| [ 1.21399e+00  6.66074e-01  1.28060e+00 -6.11337e-01 -2.69644e-01
20Nov23_025914|  -2.53230e-03 -6.20683e-01  8.95056e-01 -1.08596e+00  3.64325e-01]
20Nov23_025914| [ 5.88481e-01  8.60948e-02  4.37503e-01 -1.84663e+00 -7.58324e-01
20Nov23_025914|   7.34596e-01  1.44969e+00 -8.81787e-01 -1.50155e-01 -1.06136e-01]
20Nov23_025914| [ 3.27155e-01  1.36855e+00 -2.04781e+00 -1.57615e+00 -4.51258e-01
20Nov23_025914|   3.02165e-01  6.43490e-01 -1.26883e-01 -5.94848e-01 -2.12811e+00]
20Nov23_025914| [-3.45131e-01 -1.81354e+00 -4.97743e-01  5.71362e-01 -8.54879e-01
20Nov23_025914|   3.65188e-01  1.95065e-01 -2.79676e-01  1.48447e-01  2.43540e-01]
20Nov23_025914| [-5.61218e-01  1.44002e+00  9.06417e-01 -3.99731e-01 -7.36291e-01
20Nov23_025914|  -9.66884e-01 -5.37313e-01 -8.49094e-01 -1.50517e+00  4.55984e-01]
20Nov23_025914| [ 1.70948e+00  8.12685e-01  2.75510e-02 -1.86415e+00 -1.60141e+00
20Nov23_025914|  -8.75582e-01 -8.89810e-01  5.20086e-01  7.91316e-01 -1.36802e+00]
20Nov23_025914| [-2.14098e-01  2.45515e-01  2.56778e-01  2.97405e-01 -1.38597e+00
20Nov23_025914|  -5.00160e-01  6.20253e-01 -7.58286e-01  3.35205e-01 -3.43907e+00]
20Nov23_025914| [ 4.03195e-01 -1.20324e-01  1.13366e+00  8.88009e-01 -9.37896e-03
20Nov23_025914|  -2.86522e-01  1.67710e+00  5.86515e-01 -1.06572e+00  1.39802e+00]
20Nov23_025914| [ 6.48180e-01 -1.92738e+00  1.50417e-02  8.68537e-02 -1.13786e+00
20Nov23_025914|  -1.29129e+00 -6.92839e-01 -1.40458e+00 -8.00986e-01  8.15326e-01]
20Nov23_025914| [ 1.57969e+00 -1.30609e-01 -1.29681e-01  1.04108e+00 -1.55760e+00
20Nov23_025914|  -1.01726e+00 -7.49064e-02  1.91418e-01  1.13480e+00 -1.29247e+00]
20Nov23_025914| [ 6.05486e-01 -1.20667e+00  1.83863e+00  1.62026e+00 -1.21907e+00
20Nov23_025914|  -1.85861e+00  6.32947e-01 -6.56312e-01 -1.96676e+00  9.10422e-01]
20Nov23_025914| [-1.17272e+00  1.65220e+00 -1.03529e+00 -8.72294e-02  2.90430e-01
20Nov23_025914|  -2.34656e+00  3.19297e-01 -1.87314e+00  5.04493e-01  4.65741e-01]
20Nov23_025914| [-9.48481e-02 -2.33962e-02 -5.93975e-02  3.19555e-02  3.49339e-01
20Nov23_025914|   6.49964e-01  6.53861e-01  8.66293e-01 -1.16838e+00 -9.17614e-01]
20Nov23_025914| [ 1.19783e+00  3.25987e-01  1.37329e+00  8.63944e-01 -9.03486e-01
20Nov23_025914|   1.38840e+00  1.49831e+00  1.17810e+00 -2.68505e+00  1.62729e+00]
20Nov23_025914| [-1.58344e+00 -2.33544e-01  8.36162e-01 -2.18260e+00 -1.15138e+00
20Nov23_025914|   1.45939e+00 -1.13930e+00 -3.86267e-01 -4.73407e-01 -9.27712e-01]
20Nov23_025914| [ 4.40150e-01 -1.15269e+00  3.37421e-01 -6.98225e-01  2.17269e+00
20Nov23_025914|   9.63798e-01 -1.43930e+00  1.71663e+00  7.51493e-01 -6.28456e-01]
20Nov23_025914| [-1.58838e+00  1.79189e+00  5.00478e-01 -1.25010e+00  7.03498e-01
20Nov23_025914|  -6.38268e-01  1.20227e+00  1.08421e+00  8.40502e-01  2.02490e+00]
20Nov23_025914| [ 3.67353e-01 -6.31589e-04  1.27834e+00 -1.39200e+00 -1.15876e+00
20Nov23_025914|   1.53865e+00 -7.44091e-01  4.73619e-01  2.04884e+00  1.62277e+00]
20Nov23_025914| [-1.55578e+00  1.55922e+00 -6.26084e-02  1.27440e+00  7.76317e-01
20Nov23_025914|  -3.31071e-01 -8.12146e-01  5.32258e-01 -1.03204e-01  5.74448e-01]
20Nov23_025914| [-1.66080e-01  9.27591e-01 -8.26749e-01 -2.02630e+00 -1.69057e+00
20Nov23_025914|   1.57038e+00 -9.36829e-01 -8.09723e-02 -1.40559e+00 -4.68670e-01]
20Nov23_025914| [ 1.31585e+00 -1.35879e+00  6.69832e-02 -6.76034e-01 -7.78053e-02
20Nov23_025914|   9.15890e-01 -2.57551e+00  1.17206e+00 -1.63833e-01 -1.51976e+00]
20Nov23_025914| [ 3.86571e-01  3.76960e-01  1.62203e+00 -6.63494e-01  5.79448e-01
20Nov23_025914|  -2.02899e-01  6.20663e-01 -8.74604e-01  5.65300e-01 -4.78021e-01]
20Nov23_025914| [ 2.84392e-01 -1.30287e+00 -2.40568e-01  1.64154e+00  8.57175e-01
20Nov23_025914|   1.66324e+00 -7.58044e-01  9.58194e-01  1.08895e+00  6.87897e-01]
20Nov23_025914| [ 1.91543e+00 -8.14252e-01 -8.52032e-01  3.78664e-01  1.90764e+00
20Nov23_025914|  -4.47222e-01 -2.69340e+00 -1.03904e+00 -2.00134e+00  2.38100e-01]
20Nov23_025914| [ 1.26019e+00  9.38744e-01 -3.14317e-01  7.86493e-01  4.76806e-01
20Nov23_025914|  -1.35297e-01  4.23375e-01 -2.08811e+00 -2.33768e-01 -6.56785e-01]
20Nov23_025914| [-1.79324e+00  2.42905e-02  1.37542e+00 -2.27793e+00  2.38915e+00
20Nov23_025914|   1.28801e-01 -1.29803e-01  1.69579e+00 -5.80142e-01  2.11689e+00]
20Nov23_025914| [ 9.34165e-01  7.98905e-01  9.33160e-01  1.26228e+00  8.33572e-01
20Nov23_025914|   8.94453e-01 -1.13623e+00  1.39619e+00 -6.78227e-01  8.70115e-01]
20Nov23_025914| [-1.10950e+00  2.87654e-01  2.71057e-01  8.54796e-01  1.22987e+00
20Nov23_025914|  -1.00751e+00 -5.61214e-01 -6.35672e-02 -9.03112e-01 -7.95657e-01]
20Nov23_025914| [-7.55905e-01  2.91320e-01 -1.58683e+00  5.85932e-01  2.65090e-01
20Nov23_025914|   1.77914e-01 -1.04044e-01 -1.09661e+00  9.38082e-02 -5.58226e-01]
20Nov23_025914| [-9.74231e-01  1.36123e+00 -4.42398e-01  1.01758e-01  3.66514e-01
20Nov23_025914|   1.28179e+00 -1.91686e+00  5.51070e-01  1.15574e+00 -7.07965e-01]
20Nov23_025914| [ 4.46124e-02  5.20958e-01  2.14918e+00  4.16463e-01 -8.15995e-03
20Nov23_025914|   1.50900e+00  2.03955e+00 -3.79312e-01  1.23712e+00 -9.03886e-01]
20Nov23_025914| [ 9.53918e-01 -1.00003e+00  1.67585e+00 -3.41251e+00  1.13867e+00
20Nov23_025914|   3.59439e-01  6.13636e-01 -5.79112e-01  1.84630e-01  1.27094e-01]
20Nov23_025914| [ 5.63295e-01 -7.65227e-01  1.14199e-01 -1.63298e+00  2.84249e-01
20Nov23_025914|  -6.66078e-01 -1.57556e+00  1.00746e+00  7.55489e-01 -9.87647e-01]
20Nov23_025914| [-7.69623e-01 -2.82068e-01  2.51158e+00 -7.90434e-01 -1.54072e+00
20Nov23_025914|   2.29525e+00  3.09859e-01  3.83551e-01 -9.54400e-01  7.70518e-01]
20Nov23_025914| [ 2.04135e+00 -1.89705e+00 -2.04564e+00  1.29505e+00  2.31663e-01
20Nov23_025914|  -1.07668e-01 -1.11612e-01 -4.62865e-01  1.10223e+00  9.01401e-01]
20Nov23_025914| [-6.45809e-01  4.89783e-01  2.17360e+00 -6.88799e-01  1.19751e+00
20Nov23_025914|   1.21721e+00 -2.17834e+00 -5.34672e-01  1.33385e+00 -2.08075e+00]
20Nov23_025914| [-4.18249e+00  1.95307e-01 -7.81067e-01  1.37136e+00 -2.13521e-01
20Nov23_025914|   1.59212e+00 -3.82342e-01  2.63593e+00 -1.00001e+00 -9.22583e-01]
20Nov23_025914| [ 7.01133e-01 -1.13910e+00  1.30671e+00 -5.14959e-01 -2.15790e+00
20Nov23_025914|  -9.44361e-01 -7.67735e-01 -1.24544e+00  1.21896e-01  1.44422e-02]
20Nov23_025914| [-5.05253e-01 -9.48834e-01 -1.35498e+00 -5.44439e-01  4.33973e-01
20Nov23_025914|   1.34650e+00 -1.59928e+00 -9.47020e-01  1.00715e+00 -2.13873e-01]
20Nov23_025914| [-4.95534e-01 -1.37437e-01 -7.25293e-01 -1.79721e+00  1.74471e+00
20Nov23_025914|  -9.68677e-01 -8.56409e-02  1.37133e+00 -7.11811e-01 -8.75033e-01]
20Nov23_025914| [ 1.75287e+00  4.58719e-01  6.66106e-01  1.10149e+00  1.57245e+00
20Nov23_025914|  -6.58958e-01 -7.97523e-01  4.49998e-01 -9.37306e-01  7.24107e-01]
20Nov23_025914| [-6.67339e-02  1.37247e+00  4.27743e-01  3.63566e-01  1.53543e+00
20Nov23_025914|  -2.46799e+00  1.38273e-01  9.09795e-01 -1.63558e+00 -2.33811e+00]
20Nov23_025914| [ 4.74738e-01  1.19072e+00  2.53531e-01  1.60539e+00 -1.19259e+00
20Nov23_025914|   8.16734e-01 -1.06184e+00 -8.57672e-01 -4.20009e-02  2.71981e-01]
20Nov23_025914| [-9.28704e-01  2.61080e+00  7.82101e-01  1.51103e+00 -1.65491e+00
20Nov23_025914|   1.67477e+00  1.27955e+00  9.86971e-01  1.12991e+00 -1.88014e+00]
20Nov23_025914| [-1.83175e+00  2.17081e+00 -1.12905e-01 -7.86976e-01  4.64954e-02
20Nov23_025914|   1.73163e+00 -2.10689e+00  2.17379e-01 -2.19104e+00  2.65990e-01]
20Nov23_025914| [ 5.99832e-01  2.26352e+00 -1.26344e+00  1.67205e+00  1.96797e+00
20Nov23_025914|  -1.04196e+00 -1.17036e+00 -5.82210e-01  3.44470e-01 -6.29446e-01]
20Nov23_025914| [-3.74647e-01  1.57396e+00 -1.23393e+00  1.77755e+00 -1.35559e+00
20Nov23_025914|  -3.50392e-01 -1.51221e+00 -3.50933e-01 -2.21108e+00  2.27891e+00]
20Nov23_025914| [ 1.79899e+00  9.29451e-01 -2.38156e+00 -2.95904e-01  5.01510e-02
20Nov23_025914|  -4.89236e-01 -3.81430e-02 -1.93658e-02 -2.81360e+00 -1.61727e+00]
20Nov23_025914| [-6.31664e-01  1.35179e-02 -8.62988e-01 -1.37577e+00 -1.76862e+00
20Nov23_025914|   7.53411e-01  8.42981e-01 -1.16891e+00 -1.94126e-01  1.64820e+00]
20Nov23_025914| [-9.45281e-01 -1.40671e+00 -2.98803e-01 -9.53509e-01 -7.63614e-01
20Nov23_025914|   3.42849e-02  1.95511e+00  1.79314e+00 -7.97121e-01 -1.37916e+00]
20Nov23_025914| [-1.21675e+00 -1.09576e+00 -3.20845e-01  7.37468e-01 -7.22748e-01
20Nov23_025914|  -4.89459e-01 -1.01331e+00  8.35708e-02  1.66520e-01  4.22179e-01]]
20Nov23_025914|-- Bias --
20Nov23_025914|[ 0.60392 -0.49720 -0.40465 -0.97662 -1.18628 -0.32953 -0.72463  1.47398
20Nov23_025914|  0.64550  0.75190]
20Nov23_025914|Layer 1:
20Nov23_025914|-- Config --
20Nov23_025914|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 10], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025914|-- Weights --
20Nov23_025914|[[-0.21679 -0.45691  0.28378  0.33784]
20Nov23_025914| [ 0.06390  0.16042 -0.55690  0.51363]
20Nov23_025914| [ 0.72633  0.93777 -0.75765  0.12993]
20Nov23_025914| [-0.62302  0.49010 -0.52417 -0.18200]
20Nov23_025914| [ 0.40134 -0.38242 -0.19617 -0.96393]
20Nov23_025914| [ 0.32070 -0.40738 -0.02044 -0.76057]
20Nov23_025914| [-0.43581  0.72040 -0.51486 -0.45397]
20Nov23_025914| [-0.62899 -0.42677 -0.34653 -0.07457]
20Nov23_025914| [-0.53423 -0.35014  0.48800 -0.44973]
20Nov23_025914| [ 0.80919  0.06153 -0.03718  0.65188]]
20Nov23_025914|-- Bias --
20Nov23_025914|[ 0.73864 -0.52503 -0.04894  0.56961]
20Nov23_025914|Layer 2:
20Nov23_025914|-- Config --
20Nov23_025914|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025914|-- Weights --
20Nov23_025914|[[ 0.12699 -0.47567]
20Nov23_025914| [ 1.38134  1.35039]
20Nov23_025914| [ 1.14654  1.78430]
20Nov23_025914| [ 0.41573  1.94888]]
20Nov23_025914|-- Bias --
20Nov23_025914|[ 0.02099 -0.36139]
20Nov23_025914|Predicting the validation and test data with the Best final individual.
20Nov23_025920| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_025920|-----------  ------------------  --------------------  ----------
20Nov23_025920|Validation         42.00                  28            0.00000
20Nov23_025920|   Test            36.49                  28            0.00000
20Nov23_025920|-------------------------- Test #14 --------------------------
20Nov23_025920|Best final individual weights
20Nov23_025920|Individual:
20Nov23_025920|-- Constant hidden layers --
20Nov23_025920|False
20Nov23_025920|Layer 0:
20Nov23_025920|-- Config --
20Nov23_025920|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 10, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025920|-- Weights --
20Nov23_025920|[[-3.07041e-01  1.00616e+00  6.34565e-01 -6.61114e-01 -5.46887e-01
20Nov23_025920|  -1.10888e+00  3.20769e-01 -4.30961e-02 -2.31163e-01  2.22718e+00]
20Nov23_025920| [ 3.40553e-01  8.74817e-01 -1.66864e+00 -7.83743e-01  1.10105e+00
20Nov23_025920|  -1.32534e+00  4.10905e-02  1.12271e+00  6.89412e-01 -1.53065e-01]
20Nov23_025920| [-1.26826e+00  5.87994e-01 -4.60418e-02 -3.55128e+00  1.04805e+00
20Nov23_025920|   1.61174e-01  1.16185e+00  5.66952e-01  6.72490e-01 -6.24827e-01]
20Nov23_025920| [-9.79202e-01  1.61247e-01 -1.27518e+00  5.18034e-01  1.98136e+00
20Nov23_025920|  -6.90936e-01  1.26940e-01  5.58500e-01  1.42756e-01  1.03981e+00]
20Nov23_025920| [-1.82313e-01  3.66685e-01  1.34275e+00  4.58416e-01 -1.18038e+00
20Nov23_025920|   2.51182e-01 -7.15217e-01 -1.66193e-01 -3.14859e-01  1.24005e+00]
20Nov23_025920| [ 1.48738e+00 -3.98929e-01  3.64868e-01  5.40263e-01  5.46416e-02
20Nov23_025920|   1.88146e+00  1.19580e+00 -2.43148e+00 -7.75186e-01 -6.49648e-01]
20Nov23_025920| [ 1.21399e+00  6.66074e-01  1.28060e+00 -6.11337e-01 -2.69644e-01
20Nov23_025920|  -2.53230e-03 -6.20683e-01  8.95056e-01 -1.08596e+00  3.64325e-01]
20Nov23_025920| [ 5.88481e-01  8.60948e-02  4.37503e-01 -1.84663e+00 -7.58324e-01
20Nov23_025920|   7.34596e-01  1.44969e+00 -8.81787e-01 -1.50155e-01 -1.06136e-01]
20Nov23_025920| [ 3.27155e-01  1.36855e+00 -2.04781e+00 -1.57615e+00 -4.51258e-01
20Nov23_025920|   3.02165e-01  6.43490e-01 -1.26883e-01 -5.94848e-01 -2.12811e+00]
20Nov23_025920| [-3.45131e-01 -1.81354e+00 -4.97743e-01  5.71362e-01 -8.54879e-01
20Nov23_025920|   3.65188e-01  1.95065e-01 -2.79676e-01  1.48447e-01  2.43540e-01]
20Nov23_025920| [-5.61218e-01  1.44002e+00  9.06417e-01 -3.99731e-01 -7.36291e-01
20Nov23_025920|  -9.66884e-01 -5.37313e-01 -8.49094e-01 -1.50517e+00  4.55984e-01]
20Nov23_025920| [ 1.70948e+00  8.12685e-01  2.75510e-02 -1.86415e+00 -1.60141e+00
20Nov23_025920|  -8.75582e-01 -8.89810e-01  5.20086e-01  7.91316e-01 -1.36802e+00]
20Nov23_025920| [-2.14098e-01  2.45515e-01  2.56778e-01  2.97405e-01 -1.38597e+00
20Nov23_025920|  -5.00160e-01  6.20253e-01 -7.58286e-01  3.35205e-01 -3.43907e+00]
20Nov23_025920| [ 4.03195e-01 -1.20324e-01  1.13366e+00  8.88009e-01 -9.37896e-03
20Nov23_025920|  -2.86522e-01  1.67710e+00  5.86515e-01 -1.06572e+00  1.39802e+00]
20Nov23_025920| [ 6.48180e-01 -1.92738e+00  1.50417e-02  8.68537e-02 -1.13786e+00
20Nov23_025920|  -1.29129e+00 -6.92839e-01 -1.40458e+00 -8.00986e-01  8.15326e-01]
20Nov23_025920| [ 1.57969e+00 -1.30609e-01 -1.29681e-01  1.04108e+00 -1.55760e+00
20Nov23_025920|  -1.01726e+00 -7.49064e-02  1.91418e-01  1.13480e+00 -1.29247e+00]
20Nov23_025920| [ 6.05486e-01 -1.20667e+00  1.83863e+00  1.62026e+00 -1.21907e+00
20Nov23_025920|  -1.85861e+00  6.32947e-01 -6.56312e-01 -1.96676e+00  9.10422e-01]
20Nov23_025920| [-1.17272e+00  1.65220e+00 -1.03529e+00 -8.72294e-02  2.90430e-01
20Nov23_025920|  -2.34656e+00  3.19297e-01 -1.87314e+00  5.04493e-01  4.65741e-01]
20Nov23_025920| [-9.48481e-02 -2.33962e-02 -5.93975e-02  3.19555e-02  3.49339e-01
20Nov23_025920|   6.49964e-01  6.53861e-01  8.66293e-01 -1.16838e+00 -9.17614e-01]
20Nov23_025920| [ 1.19783e+00  3.25987e-01  1.37329e+00  8.63944e-01 -9.03486e-01
20Nov23_025920|   1.38840e+00  1.49831e+00  1.17810e+00 -2.68505e+00  1.62729e+00]
20Nov23_025920| [-1.58344e+00 -2.33544e-01  8.36162e-01 -2.18260e+00 -1.15138e+00
20Nov23_025920|   1.45939e+00 -1.13930e+00 -3.86267e-01 -4.73407e-01 -9.27712e-01]
20Nov23_025920| [ 4.40150e-01 -1.15269e+00  3.37421e-01 -6.98225e-01  2.17269e+00
20Nov23_025920|   9.63798e-01 -1.43930e+00  1.71663e+00  7.51493e-01 -6.28456e-01]
20Nov23_025920| [-1.58838e+00  1.79189e+00  5.00478e-01 -1.25010e+00  7.03498e-01
20Nov23_025920|  -6.38268e-01  1.20227e+00  1.08421e+00  8.40502e-01  2.02490e+00]
20Nov23_025920| [ 3.67353e-01 -6.31589e-04  1.27834e+00 -1.39200e+00 -1.15876e+00
20Nov23_025920|   1.53865e+00 -7.44091e-01  4.73619e-01  2.04884e+00  1.62277e+00]
20Nov23_025920| [-1.55578e+00  1.55922e+00 -6.26084e-02  1.27440e+00  7.76317e-01
20Nov23_025920|  -3.31071e-01 -8.12146e-01  5.32258e-01 -1.03204e-01  5.74448e-01]
20Nov23_025920| [-1.66080e-01  9.27591e-01 -8.26749e-01 -2.02630e+00 -1.69057e+00
20Nov23_025920|   1.57038e+00 -9.36829e-01 -8.09723e-02 -1.40559e+00 -4.68670e-01]
20Nov23_025920| [ 1.31585e+00 -1.35879e+00  6.69832e-02 -6.76034e-01 -7.78053e-02
20Nov23_025920|   9.15890e-01 -2.57551e+00  1.17206e+00 -1.63833e-01 -1.51976e+00]
20Nov23_025920| [ 3.86571e-01  3.76960e-01  1.62203e+00 -6.63494e-01  5.79448e-01
20Nov23_025920|  -2.02899e-01  6.20663e-01 -8.74604e-01  5.65300e-01 -4.78021e-01]
20Nov23_025920| [ 2.84392e-01 -1.30287e+00 -2.40568e-01  1.64154e+00  8.57175e-01
20Nov23_025920|   1.66324e+00 -7.58044e-01  9.58194e-01  1.08895e+00  6.87897e-01]
20Nov23_025920| [ 1.91543e+00 -8.14252e-01 -8.52032e-01  3.78664e-01  1.90764e+00
20Nov23_025920|  -4.47222e-01 -2.69340e+00 -1.03904e+00 -2.00134e+00  2.38100e-01]
20Nov23_025920| [ 1.26019e+00  9.38744e-01 -3.14317e-01  7.86493e-01  4.76806e-01
20Nov23_025920|  -1.35297e-01  4.23375e-01 -2.08811e+00 -2.33768e-01 -6.56785e-01]
20Nov23_025920| [-1.79324e+00  2.42905e-02  1.37542e+00 -2.27793e+00  2.38915e+00
20Nov23_025920|   1.28801e-01 -1.29803e-01  1.69579e+00 -5.80142e-01  2.11689e+00]
20Nov23_025920| [ 9.34165e-01  7.98905e-01  9.33160e-01  1.26228e+00  8.33572e-01
20Nov23_025920|   8.94453e-01 -1.13623e+00  1.39619e+00 -6.78227e-01  8.70115e-01]
20Nov23_025920| [-1.10950e+00  2.87654e-01  2.71057e-01  8.54796e-01  1.22987e+00
20Nov23_025920|  -1.00751e+00 -5.61214e-01 -6.35672e-02 -9.03112e-01 -7.95657e-01]
20Nov23_025920| [-7.55905e-01  2.91320e-01 -1.58683e+00  5.85932e-01  2.65090e-01
20Nov23_025920|   1.77914e-01 -1.04044e-01 -1.09661e+00  9.38082e-02 -5.58226e-01]
20Nov23_025920| [-9.74231e-01  1.36123e+00 -4.42398e-01  1.01758e-01  3.66514e-01
20Nov23_025920|   1.28179e+00 -1.91686e+00  5.51070e-01  1.15574e+00 -7.07965e-01]
20Nov23_025920| [ 4.46124e-02  5.20958e-01  2.14918e+00  4.16463e-01 -8.15995e-03
20Nov23_025920|   1.50900e+00  2.03955e+00 -3.79312e-01  1.23712e+00 -9.03886e-01]
20Nov23_025920| [ 9.53918e-01 -1.00003e+00  1.67585e+00 -3.41251e+00  1.13867e+00
20Nov23_025920|   3.59439e-01  6.13636e-01 -5.79112e-01  1.84630e-01  1.27094e-01]
20Nov23_025920| [ 5.63295e-01 -7.65227e-01  1.14199e-01 -1.63298e+00  2.84249e-01
20Nov23_025920|  -6.66078e-01 -1.57556e+00  1.00746e+00  7.55489e-01 -9.87647e-01]
20Nov23_025920| [-7.69623e-01 -2.82068e-01  2.51158e+00 -7.90434e-01 -1.54072e+00
20Nov23_025920|   2.29525e+00  3.09859e-01  3.83551e-01 -9.54400e-01  7.70518e-01]
20Nov23_025920| [ 2.04135e+00 -1.89705e+00 -2.04564e+00  1.29505e+00  2.31663e-01
20Nov23_025920|  -1.07668e-01 -1.11612e-01 -4.62865e-01  1.10223e+00  9.01401e-01]
20Nov23_025920| [-6.45809e-01  4.89783e-01  2.17360e+00 -6.88799e-01  1.19751e+00
20Nov23_025920|   1.21721e+00 -2.17834e+00 -5.34672e-01  1.33385e+00 -2.08075e+00]
20Nov23_025920| [-4.18249e+00  1.95307e-01 -7.81067e-01  1.37136e+00 -2.13521e-01
20Nov23_025920|   1.59212e+00 -3.82342e-01  2.63593e+00 -1.00001e+00 -9.22583e-01]
20Nov23_025920| [ 7.01133e-01 -1.13910e+00  1.30671e+00 -5.14959e-01 -2.15790e+00
20Nov23_025920|  -9.44361e-01 -7.67735e-01 -1.24544e+00  1.21896e-01  1.44422e-02]
20Nov23_025920| [-5.05253e-01 -9.48834e-01 -1.35498e+00 -5.44439e-01  4.33973e-01
20Nov23_025920|   1.34650e+00 -1.59928e+00 -9.47020e-01  1.00715e+00 -2.13873e-01]
20Nov23_025920| [-4.95534e-01 -1.37437e-01 -7.25293e-01 -1.79721e+00  1.74471e+00
20Nov23_025920|  -9.68677e-01 -8.56409e-02  1.37133e+00 -7.11811e-01 -8.75033e-01]
20Nov23_025920| [ 1.75287e+00  4.58719e-01  6.66106e-01  1.10149e+00  1.57245e+00
20Nov23_025920|  -6.58958e-01 -7.97523e-01  4.49998e-01 -9.37306e-01  7.24107e-01]
20Nov23_025920| [-6.67339e-02  1.37247e+00  4.27743e-01  3.63566e-01  1.53543e+00
20Nov23_025920|  -2.46799e+00  1.38273e-01  9.09795e-01 -1.63558e+00 -2.33811e+00]
20Nov23_025920| [ 4.74738e-01  1.19072e+00  2.53531e-01  1.60539e+00 -1.19259e+00
20Nov23_025920|   8.16734e-01 -1.06184e+00 -8.57672e-01 -4.20009e-02  2.71981e-01]
20Nov23_025920| [-9.28704e-01  2.61080e+00  7.82101e-01  1.51103e+00 -1.65491e+00
20Nov23_025920|   1.67477e+00  1.27955e+00  9.86971e-01  1.12991e+00 -1.88014e+00]
20Nov23_025920| [-1.83175e+00  2.17081e+00 -1.12905e-01 -7.86976e-01  4.64954e-02
20Nov23_025920|   1.73163e+00 -2.10689e+00  2.17379e-01 -2.19104e+00  2.65990e-01]
20Nov23_025920| [ 5.99832e-01  2.26352e+00 -1.26344e+00  1.67205e+00  1.96797e+00
20Nov23_025920|  -1.04196e+00 -1.17036e+00 -5.82210e-01  3.44470e-01 -6.29446e-01]
20Nov23_025920| [-3.74647e-01  1.57396e+00 -1.23393e+00  1.77755e+00 -1.35559e+00
20Nov23_025920|  -3.50392e-01 -1.51221e+00 -3.50933e-01 -2.21108e+00  2.27891e+00]
20Nov23_025920| [ 1.79899e+00  9.29451e-01 -2.38156e+00 -2.95904e-01  5.01510e-02
20Nov23_025920|  -4.89236e-01 -3.81430e-02 -1.93658e-02 -2.81360e+00 -1.61727e+00]
20Nov23_025920| [-6.31664e-01  1.35179e-02 -8.62988e-01 -1.37577e+00 -1.76862e+00
20Nov23_025920|   7.53411e-01  8.42981e-01 -1.16891e+00 -1.94126e-01  1.64820e+00]
20Nov23_025920| [-9.45281e-01 -1.40671e+00 -2.98803e-01 -9.53509e-01 -7.63614e-01
20Nov23_025920|   3.42849e-02  1.95511e+00  1.79314e+00 -7.97121e-01 -1.37916e+00]
20Nov23_025920| [-1.21675e+00 -1.09576e+00 -3.20845e-01  7.37468e-01 -7.22748e-01
20Nov23_025920|  -4.89459e-01 -1.01331e+00  8.35708e-02  1.66520e-01  4.22179e-01]]
20Nov23_025920|-- Bias --
20Nov23_025920|[ 0.60392 -0.49720 -0.40465 -0.97662 -1.18628 -0.32953 -0.72463  1.47398
20Nov23_025920|  0.64550  0.75190]
20Nov23_025920|Layer 1:
20Nov23_025920|-- Config --
20Nov23_025920|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 10], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025920|-- Weights --
20Nov23_025920|[[-0.21679 -0.45691  0.28378  0.33784]
20Nov23_025920| [ 0.06390  0.16042 -0.55690  0.51363]
20Nov23_025920| [ 0.72633  0.93777 -0.75765  0.12993]
20Nov23_025920| [-0.62302  0.49010 -0.52417 -0.18200]
20Nov23_025920| [ 0.40134 -0.38242 -0.19617 -0.96393]
20Nov23_025920| [ 0.32070 -0.40738 -0.02044 -0.76057]
20Nov23_025920| [-0.43581  0.72040 -0.51486 -0.45397]
20Nov23_025920| [-0.62899 -0.42677 -0.34653 -0.07457]
20Nov23_025920| [-0.53423 -0.35014  0.48800 -0.44973]
20Nov23_025920| [ 0.80919  0.06153 -0.03718  0.65188]]
20Nov23_025920|-- Bias --
20Nov23_025920|[ 0.73864 -0.52503 -0.04894  0.56961]
20Nov23_025920|Layer 2:
20Nov23_025920|-- Config --
20Nov23_025920|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_025920|-- Weights --
20Nov23_025920|[[ 0.12699 -0.47567]
20Nov23_025920| [ 1.38134  1.35039]
20Nov23_025920| [ 1.14654  1.78430]
20Nov23_025920| [ 0.41573  1.94888]]
20Nov23_025920|-- Bias --
20Nov23_025920|[ 0.02099 -0.36139]
20Nov23_025920|Predicting the validation and test data with the Best final individual.
20Nov23_025926| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_025926|-----------  ------------------  --------------------  ----------
20Nov23_025926|Validation         42.00                  28            0.00000
20Nov23_025926|   Test            53.87                  28            0.76653
Using Theano backend.
20Nov23_025927|Data summary: Train
20Nov23_025927|data.shape = (2300, 57)
20Nov23_025927|labels.shape = (2300,)
20Nov23_025927|Class distribution:
20Nov23_025927|	0 - 1389 (0.60)
20Nov23_025927|	1 - 911 (0.40)
20Nov23_025927|Data summary: Validation
20Nov23_025927|data.shape = (1150, 57)
20Nov23_025927|labels.shape = (1150,)
20Nov23_025927|Class distribution:
20Nov23_025927|	0 - 667 (0.58)
20Nov23_025927|	1 - 483 (0.42)
20Nov23_025927|Data summary: Test
20Nov23_025927|data.shape = (1151, 57)
20Nov23_025927|labels.shape = (1151,)
20Nov23_025927|Class distribution:
20Nov23_025927|	0 - 732 (0.64)
20Nov23_025927|	1 - 419 (0.36)
20Nov23_025927|Selected configuration values
20Nov23_025927|-- Dataset name: spambase2
20Nov23_025927|-- Initial population size: 64
20Nov23_025927|-- Maximun number of generations: 32
20Nov23_025927|-- Neurons per hidden layer range: (2, 20)
20Nov23_025927|-- Hidden layers number range: (1, 3)
20Nov23_025927|-- Crossover probability: 0.5
20Nov23_025927|-- Bias gene mutation probability: 0.2
20Nov23_025927|-- Weights gene mutation probability: 0.75
20Nov23_025927|-- Neuron mutation probability: 0.3
20Nov23_025927|-- Layer mutation probability: 0.3
20Nov23_025927|-- Constant hidden layers: False
20Nov23_025927|-- Seed: None
20Nov23_025927|Entering GA
20Nov23_025927|Start the algorithm
20Nov23_030240|-- Generation 1 --
20Nov23_030240|    -- Crossed 0 individual pairs.
20Nov23_030240|    -- Mutated 32 individuals.
20Nov23_030544|    -- Evaluated 64 individuals.
20Nov23_030544|    Summary of generation 1:
20Nov23_030544| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_030544|-----------  ------------------  --------------------  ----------
20Nov23_030544|    Max            42.17                93.00           0.21887
20Nov23_030544|    Avg            41.83                22.78           0.00840
20Nov23_030544|    Min            37.13                 2.00           0.00000
20Nov23_030544|    Std             0.76                18.92           0.03326
20Nov23_030544|   Best            37.13                18.00           0.21887
20Nov23_030544|-- Generation 2 --
20Nov23_030544|    -- Crossed 3 individual pairs.
20Nov23_030544|    -- Mutated 32 individuals.
20Nov23_030846|    -- Evaluated 64 individuals.
20Nov23_030846|    Summary of generation 2:
20Nov23_030846| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_030846|-----------  ------------------  --------------------  ----------
20Nov23_030846|    Max            42.35                69.00           0.14144
20Nov23_030846|    Avg            41.84                15.45           0.00785
20Nov23_030846|    Min            39.30                 2.00           0.00000
20Nov23_030846|    Std             0.51                13.62           0.02211
20Nov23_030846|   Best            39.30                18.00           0.14144
20Nov23_030846|-- Generation 3 --
20Nov23_030846|    -- Crossed 2 individual pairs.
20Nov23_030846|    -- Mutated 32 individuals.
20Nov23_031148|    -- Evaluated 64 individuals.
20Nov23_031148|    Summary of generation 3:
20Nov23_031148| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_031148|-----------  ------------------  --------------------  ----------
20Nov23_031148|    Max            42.17                84.00           0.71604
20Nov23_031148|    Avg            41.64                18.31           0.01531
20Nov23_031148|    Min            25.22                 2.00           0.00000
20Nov23_031148|    Std             2.10                17.33           0.08918
20Nov23_031148|   Best            25.22                39.00           0.71604
20Nov23_031148|-- Generation 4 --
20Nov23_031148|    -- Crossed 3 individual pairs.
20Nov23_031148|    -- Mutated 32 individuals.
20Nov23_031448|    -- Evaluated 64 individuals.
20Nov23_031448|    Summary of generation 4:
20Nov23_031448| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_031448|-----------  ------------------  --------------------  ----------
20Nov23_031448|    Max            42.26                78.00           0.73442
20Nov23_031448|    Avg            41.67                16.77           0.01849
20Nov23_031448|    Min            28.70                 2.00           0.00000
20Nov23_031448|    Std             1.70                16.75           0.09426
20Nov23_031448|   Best            28.70                39.00           0.73442
20Nov23_031448|-- Generation 5 --
20Nov23_031448|    -- Crossed 3 individual pairs.
20Nov23_031448|    -- Mutated 32 individuals.
20Nov23_031751|    -- Evaluated 64 individuals.
20Nov23_031751|    Summary of generation 5:
20Nov23_031751| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_031751|-----------  ------------------  --------------------  ----------
20Nov23_031751|    Max            42.35                112.00          0.71137
20Nov23_031751|    Avg            41.69                19.52           0.01452
20Nov23_031751|    Min            26.61                 2.00           0.00000
20Nov23_031751|    Std             1.93                21.13           0.08845
20Nov23_031751|   Best            26.61                14.00           0.71137
20Nov23_031751|-- Generation 6 --
20Nov23_031751|    -- Crossed 2 individual pairs.
20Nov23_031751|    -- Mutated 32 individuals.
20Nov23_032053|    -- Evaluated 64 individuals.
20Nov23_032053|    Summary of generation 6:
20Nov23_032053| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_032053|-----------  ------------------  --------------------  ----------
20Nov23_032053|    Max            42.35                78.00           0.66018
20Nov23_032053|    Avg            41.51                18.69           0.02280
20Nov23_032053|    Min            28.61                 2.00           0.00000
20Nov23_032053|    Std             2.28                19.33           0.10422
20Nov23_032053|   Best            28.61                14.00           0.66018
20Nov23_032053|-- Generation 7 --
20Nov23_032053|    -- Crossed 3 individual pairs.
20Nov23_032053|    -- Mutated 32 individuals.
20Nov23_032356|    -- Evaluated 64 individuals.
20Nov23_032356|    Summary of generation 7:
20Nov23_032356| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_032356|-----------  ------------------  --------------------  ----------
20Nov23_032356|    Max            58.00                81.00           0.78358
20Nov23_032356|    Avg            41.98                20.45           0.04919
20Nov23_032356|    Min            28.52                 2.00           0.00000
20Nov23_032356|    Std             3.60                19.27           0.16499
20Nov23_032356|   Best            28.52                33.00           0.62790
20Nov23_032356|-- Generation 8 --
20Nov23_032356|    -- Crossed 4 individual pairs.
20Nov23_032356|    -- Mutated 32 individuals.
20Nov23_032701|    -- Evaluated 64 individuals.
20Nov23_032701|    Summary of generation 8:
20Nov23_032701| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_032701|-----------  ------------------  --------------------  ----------
20Nov23_032701|    Max            58.00                78.00           0.79746
20Nov23_032701|    Avg            42.43                22.59           0.04973
20Nov23_032701|    Min            36.09                 2.00           0.00000
20Nov23_032701|    Std             3.15                19.84           0.17057
20Nov23_032701|   Best            36.09                14.00           0.31835
20Nov23_032701|-- Generation 9 --
20Nov23_032701|    -- Crossed 5 individual pairs.
20Nov23_032701|    -- Mutated 32 individuals.
20Nov23_033011|    -- Evaluated 64 individuals.
20Nov23_033011|    Summary of generation 9:
20Nov23_033011| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_033011|-----------  ------------------  --------------------  ----------
20Nov23_033011|    Max            42.43                78.00           0.37523
20Nov23_033011|    Avg            41.81                28.08           0.01270
20Nov23_033011|    Min            37.48                 2.00           0.00000
20Nov23_033011|    Std             0.66                18.88           0.04827
20Nov23_033011|   Best            37.48                14.00           0.37523
20Nov23_033011|-- Generation 10 --
20Nov23_033011|    -- Crossed 2 individual pairs.
20Nov23_033011|    -- Mutated 32 individuals.
20Nov23_033321|    -- Evaluated 64 individuals.
20Nov23_033321|    Summary of generation 10:
20Nov23_033321| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_033321|-----------  ------------------  --------------------  ----------
20Nov23_033321|    Max            42.35                78.00           0.52818
20Nov23_033321|    Avg            41.62                26.31           0.01744
20Nov23_033321|    Min            28.52                 2.00           0.00000
20Nov23_033321|    Std             1.71                16.74           0.06933
20Nov23_033321|   Best            28.52                20.00           0.52818
20Nov23_033321|-- Generation 11 --
20Nov23_033321|    -- Crossed 2 individual pairs.
20Nov23_033321|    -- Mutated 32 individuals.
20Nov23_033632|    -- Evaluated 64 individuals.
20Nov23_033632|    Summary of generation 11:
20Nov23_033632| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_033632|-----------  ------------------  --------------------  ----------
20Nov23_033632|    Max            58.00                84.00           0.78358
20Nov23_033632|    Avg            41.71                30.92           0.03835
20Nov23_033632|    Min            27.57                 2.00           0.00000
20Nov23_033632|    Std             2.83                17.22           0.12840
20Nov23_033632|   Best            27.57                24.00           0.64184
20Nov23_033632|-- Generation 12 --
20Nov23_033632|    -- Crossed 2 individual pairs.
20Nov23_033632|    -- Mutated 32 individuals.
20Nov23_033941|    -- Evaluated 64 individuals.
20Nov23_033941|    Summary of generation 12:
20Nov23_033941| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_033941|-----------  ------------------  --------------------  ----------
20Nov23_033941|    Max            58.00                72.00           0.78358
20Nov23_033941|    Avg            42.12                25.92           0.02149
20Nov23_033941|    Min            39.65                 2.00           0.00000
20Nov23_033941|    Std             2.05                15.53           0.10057
20Nov23_033941|   Best            39.65                17.00           0.12469
20Nov23_033941|-- Generation 13 --
20Nov23_033941|    -- Crossed 1 individual pairs.
20Nov23_033941|    -- Mutated 32 individuals.
20Nov23_034251|    -- Evaluated 64 individuals.
20Nov23_034251|    Summary of generation 13:
20Nov23_034251| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_034251|-----------  ------------------  --------------------  ----------
20Nov23_034251|    Max            58.00                72.00           0.78358
20Nov23_034251|    Avg            41.95                26.52           0.02805
20Nov23_034251|    Min            37.39                 2.00           0.00000
20Nov23_034251|    Std             2.18                15.22           0.10520
20Nov23_034251|   Best            37.39                17.00           0.29357
20Nov23_034251|-- Generation 14 --
20Nov23_034251|    -- Crossed 3 individual pairs.
20Nov23_034251|    -- Mutated 32 individuals.
20Nov23_034600|    -- Evaluated 64 individuals.
20Nov23_034600|    Summary of generation 14:
20Nov23_034600| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_034600|-----------  ------------------  --------------------  ----------
20Nov23_034600|    Max            58.00                72.00           0.78358
20Nov23_034600|    Avg            42.11                25.34           0.02103
20Nov23_034600|    Min            39.39                 2.00           0.00000
20Nov23_034600|    Std             2.06                15.92           0.09887
20Nov23_034600|   Best            39.39                17.00           0.13903
20Nov23_034600|-- Generation 15 --
20Nov23_034600|    -- Crossed 3 individual pairs.
20Nov23_034600|    -- Mutated 32 individuals.
20Nov23_034911|    -- Evaluated 64 individuals.
20Nov23_034911|    Summary of generation 15:
20Nov23_034911| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_034911|-----------  ------------------  --------------------  ----------
20Nov23_034911|    Max            58.00                75.00           0.79180
20Nov23_034911|    Avg            42.68                26.81           0.06246
20Nov23_034911|    Min            34.26                 2.00           0.00000
20Nov23_034911|    Std             3.92                14.63           0.19510
20Nov23_034911|   Best            34.26                75.00           0.44766
20Nov23_034911|-- Generation 16 --
20Nov23_034911|    -- Crossed 3 individual pairs.
20Nov23_034911|    -- Mutated 32 individuals.
20Nov23_035219|    -- Evaluated 64 individuals.
20Nov23_035219|    Summary of generation 16:
20Nov23_035219| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_035219|-----------  ------------------  --------------------  ----------
20Nov23_035219|    Max            42.26                116.00          0.17796
20Nov23_035219|    Avg            41.73                23.94           0.01286
20Nov23_035219|    Min            38.78                 2.00           0.00000
20Nov23_035219|    Std             0.64                17.15           0.03385
20Nov23_035219|   Best            38.78                17.00           0.15121
20Nov23_035219|-- Generation 17 --
20Nov23_035219|    -- Crossed 1 individual pairs.
20Nov23_035219|    -- Mutated 32 individuals.
20Nov23_035528|    -- Evaluated 64 individuals.
20Nov23_035528|    Summary of generation 17:
20Nov23_035528| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_035528|-----------  ------------------  --------------------  ----------
20Nov23_035528|    Max            58.00                72.00           0.78358
20Nov23_035528|    Avg            42.16                24.03           0.04048
20Nov23_035528|    Min            36.00                 8.00           0.00000
20Nov23_035528|    Std             3.00                12.94           0.14011
20Nov23_035528|   Best            36.00                17.00           0.28531
20Nov23_035528|-- Generation 18 --
20Nov23_035528|    -- Crossed 5 individual pairs.
20Nov23_035528|    -- Mutated 32 individuals.
20Nov23_035836|    -- Evaluated 64 individuals.
20Nov23_035836|    Summary of generation 18:
20Nov23_035836| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_035836|-----------  ------------------  --------------------  ----------
20Nov23_035836|    Max            53.74                46.00           0.79399
20Nov23_035836|    Avg            41.86                20.34           0.02816
20Nov23_035836|    Min            35.83                 8.00           0.00000
20Nov23_035836|    Std             1.74                 7.92           0.10480
20Nov23_035836|   Best            35.83                18.00           0.25999
20Nov23_035836|-- Generation 19 --
20Nov23_035836|    -- Crossed 4 individual pairs.
20Nov23_035836|    -- Mutated 32 individuals.
20Nov23_040143|    -- Evaluated 64 individuals.
20Nov23_040143|    Summary of generation 19:
20Nov23_040143| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_040143|-----------  ------------------  --------------------  ----------
20Nov23_040143|    Max            52.61                44.00           0.79967
20Nov23_040143|    Avg            41.99                19.95           0.02029
20Nov23_040143|    Min            40.17                 8.00           0.00000
20Nov23_040143|    Std             1.39                 7.01           0.09945
20Nov23_040143|   Best            40.17                14.00           0.09804
20Nov23_040143|-- Generation 20 --
20Nov23_040143|    -- Crossed 3 individual pairs.
20Nov23_040143|    -- Mutated 32 individuals.
20Nov23_040450|    -- Evaluated 64 individuals.
20Nov23_040450|    Summary of generation 20:
20Nov23_040450| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_040450|-----------  ------------------  --------------------  ----------
20Nov23_040450|    Max            45.22                48.00           0.82887
20Nov23_040450|    Avg            41.45                20.52           0.04361
20Nov23_040450|    Min            25.83                 6.00           0.00000
20Nov23_040450|    Std             2.24                 8.05           0.14819
20Nov23_040450|   Best            25.83                14.00           0.82887
20Nov23_040450|-- Generation 21 --
20Nov23_040450|    -- Crossed 3 individual pairs.
20Nov23_040450|    -- Mutated 32 individuals.
20Nov23_040756|    -- Evaluated 64 individuals.
20Nov23_040756|    Summary of generation 21:
20Nov23_040756| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_040756|-----------  ------------------  --------------------  ----------
20Nov23_040756|    Max            58.00                46.00           0.78358
20Nov23_040756|    Avg            41.75                19.50           0.03851
20Nov23_040756|    Min            29.48                 4.00           0.00000
20Nov23_040756|    Std             2.62                 9.37           0.12649
20Nov23_040756|   Best            29.48                24.00           0.60433
20Nov23_040756|-- Generation 22 --
20Nov23_040756|    -- Crossed 4 individual pairs.
20Nov23_040756|    -- Mutated 32 individuals.
20Nov23_041102|    -- Evaluated 64 individuals.
20Nov23_041102|    Summary of generation 22:
20Nov23_041102| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_041102|-----------  ------------------  --------------------  ----------
20Nov23_041102|    Max            42.70                44.00           0.58585
20Nov23_041102|    Avg            41.63                18.86           0.01987
20Nov23_041102|    Min            30.26                 6.00           0.00000
20Nov23_041102|    Std             1.48                 7.81           0.07406
20Nov23_041102|   Best            30.26                24.00           0.58585
20Nov23_041102|-- Generation 23 --
20Nov23_041102|    -- Crossed 2 individual pairs.
20Nov23_041102|    -- Mutated 32 individuals.
20Nov23_041407|    -- Evaluated 64 individuals.
20Nov23_041407|    Summary of generation 23:
20Nov23_041407| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_041407|-----------  ------------------  --------------------  ----------
20Nov23_041407|    Max            42.43                46.00           0.81189
20Nov23_041407|    Avg            41.68                17.83           0.02205
20Nov23_041407|    Min            36.00                 6.00           0.00000
20Nov23_041407|    Std             0.83                 8.09           0.10084
20Nov23_041407|   Best            36.00                24.00           0.81189
20Nov23_041407|-- Generation 24 --
20Nov23_041407|    -- Crossed 2 individual pairs.
20Nov23_041407|    -- Mutated 32 individuals.
20Nov23_041713|    -- Evaluated 64 individuals.
20Nov23_041713|    Summary of generation 24:
20Nov23_041713| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_041713|-----------  ------------------  --------------------  ----------
20Nov23_041713|    Max            42.78                48.00           0.77603
20Nov23_041713|    Avg            41.21                20.19           0.03628
20Nov23_041713|    Min            25.57                 6.00           0.00000
20Nov23_041713|    Std             2.79                10.57           0.12914
20Nov23_041713|   Best            25.57                24.00           0.69864
20Nov23_041713|-- Generation 25 --
20Nov23_041713|    -- Crossed 3 individual pairs.
20Nov23_041713|    -- Mutated 32 individuals.
20Nov23_042016|    -- Evaluated 64 individuals.
20Nov23_042016|    Summary of generation 25:
20Nov23_042016| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_042016|-----------  ------------------  --------------------  ----------
20Nov23_042016|    Max            55.39                44.00           0.79128
20Nov23_042016|    Avg            41.93                18.80           0.02417
20Nov23_042016|    Min            39.30                 6.00           0.00000
20Nov23_042016|    Std             1.77                 9.69           0.09954
20Nov23_042016|   Best            39.30                18.00           0.15540
20Nov23_042016|-- Generation 26 --
20Nov23_042016|    -- Crossed 4 individual pairs.
20Nov23_042016|    -- Mutated 32 individuals.
20Nov23_042320|    -- Evaluated 64 individuals.
20Nov23_042320|    Summary of generation 26:
20Nov23_042320| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_042320|-----------  ------------------  --------------------  ----------
20Nov23_042320|    Max            57.91                46.00           0.78409
20Nov23_042320|    Avg            42.32                17.52           0.03326
20Nov23_042320|    Min            39.74                 5.00           0.00000
20Nov23_042320|    Std             2.82                 8.39           0.13579
20Nov23_042320|   Best            39.74                16.00           0.10312
20Nov23_042320|-- Generation 27 --
20Nov23_042320|    -- Crossed 5 individual pairs.
20Nov23_042320|    -- Mutated 32 individuals.
20Nov23_042626|    -- Evaluated 64 individuals.
20Nov23_042626|    Summary of generation 27:
20Nov23_042626| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_042626|-----------  ------------------  --------------------  ----------
20Nov23_042626|    Max            58.00                44.00           0.78358
20Nov23_042626|    Avg            41.79                18.42           0.03029
20Nov23_042626|    Min            35.39                 6.00           0.00000
20Nov23_042626|    Std             2.30                 8.69           0.10465
20Nov23_042626|   Best            35.39                18.00           0.25411
20Nov23_042626|-- Generation 28 --
20Nov23_042626|    -- Crossed 2 individual pairs.
20Nov23_042626|    -- Mutated 32 individuals.
20Nov23_042931|    -- Evaluated 64 individuals.
20Nov23_042931|    Summary of generation 28:
20Nov23_042931| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_042931|-----------  ------------------  --------------------  ----------
20Nov23_042931|    Max            55.30                44.00           0.79042
20Nov23_042931|    Avg            41.85                18.17           0.03015
20Nov23_042931|    Min            39.30                 6.00           0.00000
20Nov23_042931|    Std             1.80                 8.12           0.10086
20Nov23_042931|   Best            39.30                17.00           0.13204
20Nov23_042931|-- Generation 29 --
20Nov23_042931|    -- Crossed 5 individual pairs.
20Nov23_042931|    -- Mutated 32 individuals.
20Nov23_043238|    -- Evaluated 64 individuals.
20Nov23_043238|    Summary of generation 29:
20Nov23_043238| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_043238|-----------  ------------------  --------------------  ----------
20Nov23_043238|    Max            42.61                45.00           0.16928
20Nov23_043238|    Avg            41.60                18.75           0.02007
20Nov23_043238|    Min            39.04                 6.00           0.00000
20Nov23_043238|    Std             0.72                 9.13           0.03614
20Nov23_043238|   Best            39.04                17.00           0.16486
20Nov23_043238|-- Generation 30 --
20Nov23_043238|    -- Crossed 8 individual pairs.
20Nov23_043238|    -- Mutated 32 individuals.
20Nov23_043544|    -- Evaluated 64 individuals.
20Nov23_043544|    Summary of generation 30:
20Nov23_043544| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_043544|-----------  ------------------  --------------------  ----------
20Nov23_043544|    Max            58.00                46.00           0.78247
20Nov23_043544|    Avg            41.89                19.12           0.02937
20Nov23_043544|    Min            39.91                 6.00           0.00000
20Nov23_043544|    Std             2.12                 9.23           0.09904
20Nov23_043544|   Best            39.91                16.00           0.06881
20Nov23_043544|-- Generation 31 --
20Nov23_043544|    -- Crossed 1 individual pairs.
20Nov23_043544|    -- Mutated 32 individuals.
20Nov23_043850|    -- Evaluated 64 individuals.
20Nov23_043850|    Summary of generation 31:
20Nov23_043850| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_043850|-----------  ------------------  --------------------  ----------
20Nov23_043850|    Max            58.00                46.00           0.79741
20Nov23_043850|    Avg            42.12                20.19           0.03920
20Nov23_043850|    Min            40.00                 6.00           0.00000
20Nov23_043850|    Std             2.47                 9.42           0.13695
20Nov23_043850|   Best            40.00                15.00           0.06629
20Nov23_043850|-- Generation 32 --
20Nov23_043850|    -- Crossed 2 individual pairs.
20Nov23_043850|    -- Mutated 32 individuals.
20Nov23_044156|    -- Evaluated 64 individuals.
20Nov23_044156|    Summary of generation 32:
20Nov23_044156| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_044156|-----------  ------------------  --------------------  ----------
20Nov23_044156|    Max            47.83                46.00           0.79611
20Nov23_044156|    Avg            41.74                18.61           0.02875
20Nov23_044156|    Min            39.48                 6.00           0.00000
20Nov23_044156|    Std             1.00                 8.46           0.10131
20Nov23_044156|   Best            39.48                15.00           0.13896
20Nov23_044156|Best initial individual weights
20Nov23_044156|Individual:
20Nov23_044156|-- Constant hidden layers --
20Nov23_044156|False
20Nov23_044156|Layer 0:
20Nov23_044156|-- Config --
20Nov23_044156|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 16, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_044156|-- Weights --
20Nov23_044156|[[ 0.97312  0.86102  0.97632  0.20348 -0.54203  0.35095  0.42917 -0.49067
20Nov23_044156|   0.61623  0.78103 -0.75483 -0.18599  0.82195  0.43769 -0.75606 -0.00717]
20Nov23_044156| [ 0.38707  0.68474 -0.85682  0.30732  0.27101  0.82381 -0.42963  0.39071
20Nov23_044156|   0.56290 -0.13476  0.76933 -0.97187 -0.80876 -0.91923  0.70293  0.12715]
20Nov23_044156| [-0.62771  0.95133  0.14747  0.97643 -0.47637  0.31224 -0.54605 -0.57190
20Nov23_044156|   0.34499  0.19484  0.75419  0.37427  0.67720  0.62445 -0.11568 -0.72112]
20Nov23_044156| [-0.70626 -0.12118 -0.77438 -0.15519  0.44125  0.20995  0.94322 -0.78741
20Nov23_044156|   0.93240  0.59874 -0.11955 -0.26697 -0.36716 -0.27487  0.20961  0.98060]
20Nov23_044156| [-0.19814 -0.82326 -0.65669 -0.26481  0.70817  0.79873 -0.76071  0.88392
20Nov23_044156|   0.40007 -0.19515  0.37312 -0.80305  0.02468  0.93413  0.41587 -0.35957]
20Nov23_044156| [ 0.41488 -0.47747 -0.60187  0.70590  0.80744 -0.72026 -0.09372 -0.62080
20Nov23_044156|   0.46330  0.14913  0.91233  0.80261 -0.38061  0.76451  0.04418 -0.62455]
20Nov23_044156| [ 0.94722  0.47801  0.98884 -0.69344  0.56648 -0.20815 -0.34413 -0.06619
20Nov23_044156|  -0.50035 -0.42761  0.91667  0.46557 -0.15165 -0.17836  0.00356 -0.74802]
20Nov23_044156| [ 0.05442 -0.12307 -0.67706  0.63130 -0.71596  0.66118 -0.48753  0.83542
20Nov23_044156|  -0.70407  0.56292 -0.47131  0.67624 -0.70665 -0.73189 -0.30172 -0.59112]
20Nov23_044156| [-0.14561 -0.81767 -0.85680  0.17601 -0.32783 -0.58837  0.34247  0.57567
20Nov23_044156|  -0.76984 -0.85003 -0.16384  0.46897 -0.50361 -0.56888 -0.41025 -0.46422]
20Nov23_044156| [ 0.28173 -0.07355  0.77289 -0.07833  0.19687  0.82259  0.75322  0.22215
20Nov23_044156|  -0.00323  0.45720  0.28255 -0.69285  0.50215  0.53147  0.67898 -0.32061]
20Nov23_044156| [ 0.08214 -0.90324 -0.86564 -0.59864 -0.29708 -0.72284  0.89104 -0.85122
20Nov23_044156|  -0.25566 -0.45994 -0.87831  0.61664  0.47630  0.14132 -0.33856  0.56852]
20Nov23_044156| [ 0.77660  0.66126 -0.53842  0.96314 -0.55355  0.37467  0.79617  0.84712
20Nov23_044156|  -0.82377  0.20567 -0.66194 -0.98859 -0.16377 -0.84717  0.35329  0.25020]
20Nov23_044156| [-0.45616 -0.04469  0.26974 -0.20403  0.37160 -0.22238  0.08332  0.79602
20Nov23_044156|   0.91417 -0.70772  0.52831 -0.92867 -0.36253  0.42193  0.68961  0.06106]
20Nov23_044156| [ 0.99310  0.71159  0.59494 -0.56246  0.29029 -0.37550  0.68251  0.02704
20Nov23_044156|   0.00260 -0.17845 -0.71075 -0.28412 -0.04568  0.38156 -0.31505 -0.98724]
20Nov23_044156| [-0.43764  0.50035  0.68992  0.18239 -0.24293 -0.57351  0.48932 -0.73096
20Nov23_044156|   0.31323 -0.78466 -0.28128  0.11948  0.40351 -0.14443 -0.51684  0.53557]
20Nov23_044156| [ 0.08036  0.01186  0.89830  0.96475  0.22393 -0.38859 -0.57062 -0.45919
20Nov23_044156|   0.92659 -0.54755 -0.52063 -0.10752  0.27017 -0.01988 -0.64705 -0.23028]
20Nov23_044156| [ 0.11644  0.16985 -0.64138 -0.11014 -0.81252  0.11358 -0.64935  0.94484
20Nov23_044156|  -0.75547 -0.51078  0.56685  0.91277  0.92793 -0.53717  0.86772 -0.48825]
20Nov23_044156| [-0.89251  0.13034 -0.66054  0.57632  0.64202 -0.42618 -0.69436 -0.39009
20Nov23_044156|   0.74421  0.58489 -0.44979  0.28644 -0.64769 -0.66079 -0.59345  0.52270]
20Nov23_044156| [ 0.28832 -0.99579 -0.52999  0.08706 -0.37707  0.80529 -0.57377 -0.35443
20Nov23_044156|  -0.69167  0.54390 -0.45795 -0.88927 -0.97036  0.80498  0.06258 -0.85575]
20Nov23_044156| [-0.76962  0.48701 -0.95368 -0.47278  0.81976  0.79957  0.89037  0.88833
20Nov23_044156|   0.45415  0.64524 -0.53429 -0.17111  0.65967 -0.97302 -0.88970 -0.23131]
20Nov23_044156| [ 0.61429 -0.80576  0.41055  0.83225 -0.40534 -0.69411  0.43677  0.56571
20Nov23_044156|   0.69222  0.63968  0.82849 -0.28778  0.34091  0.94507  0.94812 -0.16954]
20Nov23_044156| [-0.41054  0.22385 -0.77940 -0.85361  0.15702  0.85378  0.40750 -0.86858
20Nov23_044156|  -0.86196 -0.61767 -0.39230 -0.20328 -0.51998 -0.43909 -0.56684  0.74912]
20Nov23_044156| [-0.68352  0.12912 -0.01429 -0.10110  0.88411 -0.36376  0.23285 -0.58459
20Nov23_044156|   0.41109 -0.89477 -0.54648 -0.94053  0.61710  0.12834  0.32662  0.96774]
20Nov23_044156| [-0.11892  0.73504 -0.14115 -0.08121  0.30102 -0.11110 -0.64525 -0.26599
20Nov23_044156|   0.50059 -0.06697  0.18524 -0.15228  0.74182  0.74553 -0.03065  0.85238]
20Nov23_044156| [ 0.95684 -0.83669 -0.98775 -0.15429  0.37017 -0.53374 -0.84595  0.93922
20Nov23_044156|   0.77062  0.43117  0.72074  0.20219 -0.25865  0.38239  0.28232  0.40561]
20Nov23_044156| [-0.10257  0.74005  0.35160 -0.65130 -0.29269  0.30393 -0.71810 -0.81866
20Nov23_044156|  -0.20670 -0.68659  0.32946 -0.46091  0.99209  0.79590 -0.11632 -0.52652]
20Nov23_044156| [-0.16543  0.68424 -0.50999 -0.24641  0.56520 -0.33066  0.95545  0.29146
20Nov23_044156|   0.32438  0.96157 -0.18146  0.01545  0.14601 -0.84621 -0.18608 -0.54510]
20Nov23_044156| [-0.05058 -0.98209 -0.52022 -0.81251  0.24781 -0.54229 -0.02940  0.21292
20Nov23_044156|   0.87616 -0.33148  0.57633  0.78014  0.44758  0.51254  0.78680 -0.42344]
20Nov23_044156| [ 0.65038  0.77312  0.36809 -0.28883 -0.27509 -0.63668  0.22343 -0.44390
20Nov23_044156|  -0.50271 -0.89571  0.33045  0.94759  0.71141 -0.03777  0.01686  0.10977]
20Nov23_044156| [ 0.74091 -0.49613  0.04480  0.88892  0.09660 -0.94946  0.23772 -0.58666
20Nov23_044156|  -0.16159  0.23789  0.52567  0.85042 -0.01557 -0.97705 -0.43028  0.12241]
20Nov23_044156| [-0.88938 -0.48443 -0.72504 -0.21850 -0.05962  0.87076 -0.74311  0.56346
20Nov23_044156|  -0.68618  0.60504 -0.40308 -0.92643  0.89608 -0.99788  0.52553  0.88867]
20Nov23_044156| [-0.03452 -0.60076  0.77593 -0.98719 -0.56215  0.72686  0.14051  0.92847
20Nov23_044156|   0.58577 -0.93248  0.17363 -0.58713 -0.73985  0.41107  0.82129 -0.85863]
20Nov23_044156| [ 0.34014  0.63437 -0.68514 -0.32386 -0.52825 -0.87593  0.20724 -0.82469
20Nov23_044156|   0.40209  0.50446 -0.57929  0.48767  0.49773  0.78849  0.98131 -0.39235]
20Nov23_044156| [ 0.33860 -0.44397  0.79520 -0.21676 -0.55751  0.63232 -0.79310  0.89019
20Nov23_044156|  -0.77260 -0.69689  0.21619 -0.15465 -0.82189 -0.32503  0.93626 -0.65062]
20Nov23_044156| [ 0.68472 -0.49435 -0.25832  0.06313 -0.32655  0.01547 -0.30972  0.12076
20Nov23_044156|  -0.48450  0.31553  0.91333  0.12698  0.17342 -0.18040 -0.52939  0.02831]
20Nov23_044156| [-0.65794  0.04524  0.85246  0.73969  0.80038 -0.48904 -0.76179 -0.23491
20Nov23_044156|   0.74176  0.50181 -0.72582  0.09271 -0.09433  0.07047  0.08717  0.35994]
20Nov23_044156| [-0.18686 -0.95293  0.24213  0.30537  0.40541 -0.01409 -0.84411  0.80307
20Nov23_044156|   0.82483 -0.23926  0.67892  0.38028  0.66041 -0.55185 -0.17355  0.23872]
20Nov23_044156| [-0.56029 -0.55553  0.02488 -0.62478  0.03488 -0.24547 -0.21871  0.24815
20Nov23_044156|   0.41661 -0.14966  0.42873  0.27355 -0.93925  0.56844  0.51849 -0.56907]
20Nov23_044156| [-0.74436  0.61379  0.65986 -0.02617 -0.35454  0.12791 -0.67717 -0.32838
20Nov23_044156|  -0.29973  0.40212  0.81888  0.14573  0.24846  0.49293 -0.48286 -0.01606]
20Nov23_044156| [ 0.48705 -0.97991  0.53334  0.81994 -0.34963  0.53245 -0.68547 -0.77215
20Nov23_044156|  -0.94379  0.10953  0.61491 -0.44773 -0.43312  0.96325 -0.90221 -0.94766]
20Nov23_044156| [-0.67508  0.26940 -0.32241 -0.24846 -0.12288  0.91551 -0.96546  0.50988
20Nov23_044156|   0.50674 -0.53432 -0.01112  0.60400 -0.98399  0.86722 -0.68127  0.86321]
20Nov23_044156| [-0.11454  0.12427  0.45225 -0.27808  0.73763  0.34058  0.03336  0.93132
20Nov23_044156|  -0.16115  0.91106  0.99072 -0.08949  0.85279  0.28724  0.15922  0.91325]
20Nov23_044156| [-0.64691  0.02902  0.71850 -0.05201  0.76539  0.90788 -0.18066  0.12401
20Nov23_044156|  -0.86629 -0.26040  0.48519  0.28092 -0.55318 -0.25088  0.75013  0.81723]
20Nov23_044156| [ 0.42074 -0.74324  0.90619  0.34462  0.56529  0.11278 -0.65895 -0.44454
20Nov23_044156|  -0.14456  0.95799  0.52668 -0.48303  0.99719  0.16484 -0.01503 -0.37834]
20Nov23_044156| [ 0.33218  0.03268 -0.83608 -0.70774  0.30762 -0.65056  0.47767  0.21338
20Nov23_044156|  -0.48494  0.32815 -0.07747 -0.34087  0.33497  0.03510  0.39870 -0.74882]
20Nov23_044156| [ 0.35478 -0.79458 -0.70299 -0.49378 -0.79122  0.48751 -0.32826  0.74004
20Nov23_044156|  -0.80463  0.68828 -0.54405 -0.45922 -0.88677  0.36374  0.15449  0.10618]
20Nov23_044156| [ 0.78907  0.58894  0.91976 -0.79229 -0.48151 -0.61340  0.58800  0.58842
20Nov23_044156|   0.36735  0.29391  0.92042 -0.95968 -0.12460  0.99245 -0.41429  0.28286]
20Nov23_044156| [-0.96345  0.66898  0.62451 -0.93944 -0.47182 -0.21300  0.52254 -0.59976
20Nov23_044156|  -0.16905 -0.47467 -0.08481 -0.42358 -0.13253 -0.87341  0.84628 -0.31287]
20Nov23_044156| [-0.98076 -0.00119 -0.45624 -0.44819  0.51674 -0.17810  0.51001  0.92123
20Nov23_044156|   0.13485 -0.26808 -0.05035 -0.35574 -0.17254 -0.89165 -0.19224  0.22274]
20Nov23_044156| [ 0.28021  0.66450  0.69227  0.21197  0.33323  0.11072  0.34130 -0.26246
20Nov23_044156|   0.32190 -0.64848  0.23011 -0.71812  0.13070 -0.24443 -0.23803  0.17755]
20Nov23_044156| [-0.19179  0.64885  0.27711  0.72864  0.06853  0.72975  0.00916 -0.06173
20Nov23_044156|  -0.03737 -0.88203 -0.74084  0.63040  0.41288  0.71312  0.64157 -0.77577]
20Nov23_044156| [ 0.76737  0.54712  0.52182 -0.12174 -0.91922  0.66619  0.71097  0.52972
20Nov23_044156|  -0.98203  0.42593 -0.67934 -0.01729 -0.13258 -0.45979  0.78851 -0.80253]
20Nov23_044156| [-0.64058 -0.41307  0.17045  0.30193  0.54317  0.65983  0.55836 -0.30160
20Nov23_044156|   0.33587 -0.25774  0.55049 -0.69421 -0.72735 -0.46059  0.22918  0.97080]
20Nov23_044156| [-0.63321 -0.06681 -0.56188  0.84482  0.94387 -0.12317 -0.79934 -0.64264
20Nov23_044156|   0.50826 -0.40011  0.88837 -0.98522 -0.73514 -0.98286  0.53123 -0.32077]
20Nov23_044156| [-0.26710 -0.99103 -0.23590 -0.91062  0.19478 -0.97148 -0.10563 -0.81651
20Nov23_044156|  -0.31459 -0.52532 -0.06585 -0.04129 -0.14136 -0.85097 -0.82479 -0.38607]
20Nov23_044156| [-0.69376 -0.78629  0.92644  0.43960  0.48070  0.53141 -0.78530 -0.63761
20Nov23_044156|   0.50182 -0.15646  0.58292 -0.99555 -0.05201 -0.06582  0.74698 -0.79152]
20Nov23_044156| [ 0.55703 -0.21917 -0.52068  0.32961 -0.30856  0.38926 -0.68458 -0.51639
20Nov23_044156|  -0.68534 -0.45138  0.89726 -0.53554  0.78264 -0.67732 -0.21207 -0.43035]]
20Nov23_044156|-- Bias --
20Nov23_044156|[ 0.74424  0.59769 -0.94294 -0.95057  0.70854 -0.39673 -0.18396  0.54979
20Nov23_044156| -0.83740 -0.47309 -0.93434 -0.79501 -0.77343  0.47907 -0.83951  0.27316]
20Nov23_044156|Layer 1:
20Nov23_044156|-- Config --
20Nov23_044156|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 16], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_044156|-- Weights --
20Nov23_044156|[[ 0.82493  0.98981]
20Nov23_044156| [ 0.93499 -0.12381]
20Nov23_044156| [-0.75257  0.28331]
20Nov23_044156| [-0.34593  0.74066]
20Nov23_044156| [ 0.24078  0.64272]
20Nov23_044156| [ 0.62721 -0.98117]
20Nov23_044156| [ 0.63540 -0.30723]
20Nov23_044156| [ 0.83644 -0.50969]
20Nov23_044156| [ 0.18215 -0.65227]
20Nov23_044156| [-0.41982 -0.71033]
20Nov23_044156| [-0.81175 -0.08040]
20Nov23_044156| [-0.03823 -0.79809]
20Nov23_044156| [ 0.26826 -0.98599]
20Nov23_044156| [ 0.50536 -0.02837]
20Nov23_044156| [ 0.50681  0.62866]
20Nov23_044156| [-0.14772  0.57486]]
20Nov23_044156|-- Bias --
20Nov23_044156|[ 0.56382 -0.10241]
20Nov23_044156|Predicting the validation and test data with the Best initial individual.
20Nov23_044202| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_044202|-----------  ------------------  --------------------  ----------
20Nov23_044202|Validation         42.09                  16            0.00516
20Nov23_044202|   Test            36.14                  16            0.02368
20Nov23_044202|-------------------------- Test #0 --------------------------
20Nov23_044202|Best final individual weights
20Nov23_044202|Individual:
20Nov23_044202|-- Constant hidden layers --
20Nov23_044202|False
20Nov23_044202|Layer 0:
20Nov23_044202|-- Config --
20Nov23_044202|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 15, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_044202|-- Weights --
20Nov23_044202|[[ 0.42691  0.29758  0.52422 -0.54807 -0.00317 -1.10737  0.66615 -0.46744
20Nov23_044202|   0.89578  0.22818 -0.07631 -0.76947 -0.46817 -0.21265 -0.85367]
20Nov23_044202| [-0.77699  0.41355 -1.18759  0.58503  0.11262 -0.77177 -0.87309  0.55877
20Nov23_044202|   0.49143  0.60359  0.78317 -2.01143 -0.18524  0.77837 -1.58646]
20Nov23_044202| [-0.05520  1.48797 -0.98303  0.44607  0.57229  0.01093  0.45399 -0.36869
20Nov23_044202|   1.25502 -2.04679  0.52420 -0.63251 -1.20841 -1.23667 -0.50506]
20Nov23_044202| [-0.15390 -0.12069  0.93121  0.62856 -0.47194  1.90773  0.12418 -0.02385
20Nov23_044202|   0.25845  0.67909 -0.74973 -1.14428 -0.54709 -1.03812  0.41810]
20Nov23_044202| [ 0.78184 -1.02634 -0.50414 -1.33713 -0.12806 -0.25092  1.03068 -1.53814
20Nov23_044202|   0.61719 -0.37364 -0.16927  0.25844 -1.59357  0.03242 -0.43857]
20Nov23_044202| [-1.51161  0.28379  0.11711  1.41276  1.94477 -1.13581 -0.16030 -0.98811
20Nov23_044202|  -0.74563  0.47408  1.31199  0.25822 -0.39431  0.99731  0.10765]
20Nov23_044202| [-0.06246 -0.55106 -0.66587 -0.81741 -0.90947 -0.55317  0.91670 -0.20333
20Nov23_044202|   0.16840 -0.45981  0.55694  1.11849  2.39357 -0.67350  0.20551]
20Nov23_044202| [ 0.47039 -1.74884  1.06361  0.87013 -1.27871 -0.23461 -0.85571  0.11193
20Nov23_044202|   1.28638  1.75207 -0.89037 -0.68407  0.35909 -0.54462 -0.10916]
20Nov23_044202| [-0.66100  1.52516  0.33780 -0.06402 -1.30311  2.21049  0.94191 -0.16126
20Nov23_044202|   0.77832 -0.93202  0.12018  0.28667  0.60154  0.67235  0.59619]
20Nov23_044202| [ 0.75099  1.36528 -1.73960 -1.50392  0.42261 -0.97005 -0.91943 -1.36861
20Nov23_044202|  -0.67430 -0.64244 -0.75113  1.74554  0.65154 -0.07884  0.24832]
20Nov23_044202| [ 1.53921 -0.26881 -0.59691  0.18529  0.48024 -0.98931 -1.54877  0.09832
20Nov23_044202|   1.16540  1.02141 -0.79718  1.33652  1.32572 -1.05063 -0.59539]
20Nov23_044202| [ 0.24418  0.35593 -0.10494 -1.30488  1.09288 -0.42662 -0.57142  0.49472
20Nov23_044202|   0.69921  0.62190  1.18692  0.10424 -0.45179  0.21910  0.01208]
20Nov23_044202| [ 0.67743 -0.19633  0.24381 -0.30061  0.08343 -0.33063 -0.09417 -0.29616
20Nov23_044202|  -0.06241 -1.05399  2.07564 -0.84708  0.83477 -0.41045  1.39502]
20Nov23_044202| [-0.03313 -0.77540  0.75142 -1.09279  1.86636 -0.79280 -0.54517 -0.28329
20Nov23_044202|   1.65999 -1.12225 -1.39221  0.11678 -1.17849 -0.62609 -0.37682]
20Nov23_044202| [ 0.05688 -0.19939 -0.40529 -0.51524 -0.26279  0.50723  0.33124  0.59534
20Nov23_044202|   0.83706  0.14251  0.82221 -0.63467  0.55955 -1.01568  0.21284]
20Nov23_044202| [ 0.01208  0.01410  1.11235 -0.49398  1.55853  0.43249  0.08756  0.00921
20Nov23_044202|  -0.71567 -0.38946 -0.90949 -0.83809 -0.05624  0.23786  0.05994]
20Nov23_044202| [-0.35205 -0.09450  2.24445  0.53880 -0.40180 -0.46765 -0.12446 -1.32593
20Nov23_044202|   1.41826 -0.76602  0.63376  1.18055 -0.53400  0.37624 -0.97579]
20Nov23_044202| [ 2.22050  0.05952 -1.19940  0.70861  1.41717 -0.26877 -0.94211 -1.40332
20Nov23_044202|   0.43003 -0.89869 -1.10584 -0.06625  0.31384 -0.10143  1.04961]
20Nov23_044202| [ 0.21289 -0.11012  1.49023  1.14376 -0.65338  0.26810 -0.85944  1.17660
20Nov23_044202|  -0.47870 -0.86877  0.44700  0.03584 -0.98074 -0.78054  0.03734]
20Nov23_044202| [ 0.28067  0.39235  1.41028 -0.15688 -0.54646  1.67606  0.42347  0.49702
20Nov23_044202|  -0.87937 -0.46845  1.00348 -0.53170 -1.12293 -1.01729  0.08005]
20Nov23_044202| [-1.14499  0.21662  0.15572  0.25399 -0.11350  0.09781 -0.60481 -0.96573
20Nov23_044202|   1.28182 -0.69592 -0.07493 -0.15830  1.71185 -1.62962  0.07644]
20Nov23_044202| [ 0.22980  0.61617 -0.58762 -1.53387  0.28371 -0.27785 -1.01772  0.18418
20Nov23_044202|   2.29950 -0.81522 -0.54903  0.50229  0.43645 -1.39068  1.50836]
20Nov23_044202| [ 1.26701  0.34500 -0.87987 -0.44065  1.23200 -1.45523  0.41462 -0.45891
20Nov23_044202|  -1.65629  1.36545 -0.16045  0.01440 -0.19117  1.01491 -1.56428]
20Nov23_044202| [-0.50801 -0.18680 -0.13795 -0.82892  0.04078  1.05055 -0.42182  0.28003
20Nov23_044202|  -0.17800 -0.94982 -1.60567 -0.74657 -0.37202 -0.77117  0.22728]
20Nov23_044202| [ 0.11223 -0.88960 -0.03771  0.68481 -1.13907 -1.64770 -2.08633  2.59999
20Nov23_044202|   0.70704 -1.10352 -0.73587  0.64618  0.18789 -0.56185 -0.00473]
20Nov23_044202| [-0.44394  1.09725  0.51635  0.38580 -1.13990  0.40442 -0.52209  0.10404
20Nov23_044202|  -0.15833  0.12255 -0.21853 -0.42496  1.00447  0.73146 -0.63667]
20Nov23_044202| [ 0.10066  1.40237  0.09464  0.72661 -1.80184 -0.06104 -0.34136 -0.51537
20Nov23_044202|  -1.66542 -0.55066 -2.56233 -0.02383 -0.84513 -1.61262 -0.51402]
20Nov23_044202| [-0.87960  0.23358 -0.52134  0.40047 -0.71106 -1.34728 -0.41823 -0.22333
20Nov23_044202|  -0.24686  1.65698 -1.30747 -0.69169 -0.66251  0.75459 -0.96660]
20Nov23_044202| [ 0.06230  1.20678 -0.23045 -0.84286 -0.22852  0.93298  0.14893  0.50809
20Nov23_044202|   0.14889 -0.72929 -0.24429  1.56028  1.22272  0.91747  0.36855]
20Nov23_044202| [-0.17377  1.14562  0.85539 -0.63699 -1.04190  0.12303 -0.72049 -0.08881
20Nov23_044202|  -0.90310  1.31653 -0.05204  0.40329 -0.48401 -0.36525 -0.46378]
20Nov23_044202| [ 0.09015 -0.62972 -0.73537  0.17011  0.27345 -0.55471  0.04517 -1.18609
20Nov23_044202|  -0.58628  0.49196 -0.58326  0.30330  0.51502  0.03433  0.04217]
20Nov23_044202| [ 0.86282 -0.84858 -1.43016 -0.52856  0.03054  0.44886  0.57046 -0.35864
20Nov23_044202|  -1.71832  0.24280 -0.89086 -0.78176  0.35162  0.30409 -0.02131]
20Nov23_044202| [ 1.05695  0.97767 -1.00230 -0.01291  0.04290 -0.09954  0.88877 -1.02809
20Nov23_044202|  -1.32144  0.07652  0.09972 -1.00606 -1.32542  0.05830 -0.38045]
20Nov23_044202| [ 0.43701 -1.48958 -0.15290 -0.28863  0.74501  0.03579 -1.09314 -0.86026
20Nov23_044202|   1.02886  1.16551 -1.01948 -1.43095 -1.82196 -0.89176 -0.81819]
20Nov23_044202| [-0.73966  0.22000  1.42394  0.53847 -2.33016 -0.57383  0.30702 -0.26322
20Nov23_044202|  -1.01442  0.05468 -0.23153 -0.06345  1.16376 -0.09296 -0.53408]
20Nov23_044202| [ 0.21706  1.28120  0.03908 -0.45157  0.48998  0.08854  0.00582  0.77533
20Nov23_044202|  -0.45924  0.03863 -0.73519 -0.00919 -1.16571  1.56297 -0.69370]
20Nov23_044202| [-2.08881 -0.97910  0.17069  0.79842  0.31541 -0.19526  0.45634  1.01009
20Nov23_044202|   0.59365 -0.01322  1.78356  1.44269  0.58775 -0.50228 -0.28648]
20Nov23_044202| [-1.12486  0.73663  0.56411  0.18444 -1.61639  1.08550  0.08219 -0.90988
20Nov23_044202|  -0.32404  0.81985  0.42006 -0.30815 -0.23312 -1.18708 -0.01110]
20Nov23_044202| [-0.30490 -1.30488 -1.53248 -0.79287  1.01787 -0.71421 -1.83065  0.46204
20Nov23_044202|  -0.31745  0.01163 -0.78217 -0.08380 -0.93485  0.93025 -1.11372]
20Nov23_044202| [-0.16328  1.13418 -0.55347 -0.46779  1.07552  0.66229 -0.21371  0.92252
20Nov23_044202|   0.55318  0.22002 -0.20203  0.71337  0.07093 -0.67508 -0.36308]
20Nov23_044202| [-0.14015 -0.56332  0.42102 -0.18024 -0.17774 -1.39429  0.65512  0.86385
20Nov23_044202|   0.74911  0.68266 -0.21078 -0.90494  0.19014 -0.64455  0.30027]
20Nov23_044202| [-0.74732 -0.00467  0.93348 -0.20600  0.55633 -0.56408 -0.45634 -0.20303
20Nov23_044202|  -0.13201 -1.51600  0.26075 -0.89582 -1.24197  0.63267  1.55172]
20Nov23_044202| [ 0.41456 -0.85489  0.02298  0.06353  0.81855  0.03156 -0.48615 -0.00658
20Nov23_044202|  -0.04895 -0.57287  0.20380  1.04986  0.97412 -0.47486  0.49494]
20Nov23_044202| [ 0.77080 -0.45784  0.11136  0.71105 -0.39395  0.40195 -0.43665  1.07323
20Nov23_044202|   0.43760  0.26785 -0.30587 -0.09075  0.40279  1.01923 -1.75405]
20Nov23_044202| [-0.88852  0.02533  1.17656  0.61764 -0.88512 -2.05323 -0.20657  0.56943
20Nov23_044202|  -0.79923 -0.05065  0.86607  1.99813 -0.99948 -0.10370  0.97637]
20Nov23_044202| [ 0.15692 -0.81947 -0.03219  0.05575  0.45531  1.62288 -0.76175 -0.80154
20Nov23_044202|  -1.50942 -0.89066 -0.37832  0.57865  2.24774  1.50483 -0.01312]
20Nov23_044202| [ 0.88566 -1.32158  1.07146  0.66710  0.27661  0.21144  0.50741  1.07543
20Nov23_044202|  -0.76611 -1.39540  0.28672  0.51751  0.72656 -0.65978  0.44566]
20Nov23_044202| [-1.03893  0.46076 -0.08662 -0.52243 -0.41836  0.85811 -0.86078  0.93975
20Nov23_044202|  -0.17006 -0.63327  0.74410  0.70958  1.39514  0.35044  0.87490]
20Nov23_044202| [ 1.54246 -0.70391 -0.91033  1.89604  0.46300 -0.13194 -0.43312  0.91185
20Nov23_044202|  -0.49534 -1.06771  0.38325 -1.29257 -0.73563 -1.04282 -0.39890]
20Nov23_044202| [-0.79484 -0.73094  1.55911 -0.27683  0.74301  0.65244 -1.70505  0.26757
20Nov23_044202|  -1.24152 -0.51986 -0.91341 -0.27940 -0.78858 -0.03302  0.36902]
20Nov23_044202| [-0.52894 -0.45939  0.71874 -1.10270 -0.31797 -1.23160 -0.28378  0.28717
20Nov23_044202|  -0.95275  0.83782 -0.51558 -0.40856 -0.70669 -0.31466  0.04528]
20Nov23_044202| [-0.81167 -0.21989  0.25817 -0.60778 -0.97270  0.42051  0.05410  0.81779
20Nov23_044202|  -0.94129  0.37341 -0.02587 -1.69395 -1.66843  0.14977 -1.29684]
20Nov23_044202| [ 0.18812 -1.04226 -0.19694 -0.90997  0.07427 -1.36961 -0.68391  1.29857
20Nov23_044202|  -1.58449 -1.19082 -1.19331 -0.28466  0.45438  0.59896 -0.09320]
20Nov23_044202| [ 0.46661 -1.82518  0.34643  0.42851  0.74486  1.16437 -1.33420  0.48093
20Nov23_044202|   0.66350 -1.58536  1.36313  1.64685  0.50624 -0.08332  0.16742]
20Nov23_044202| [ 0.83611 -1.02550  0.80906  0.82930  0.96028  0.21344  0.43399 -1.26536
20Nov23_044202|  -0.08786  0.56148  0.56968 -0.83275  0.47723  1.01280 -0.61349]
20Nov23_044202| [ 0.38265 -1.34334  0.19600 -0.79295  0.52286  0.28619  1.51312  0.85224
20Nov23_044202|   1.62111  1.09962  0.16420 -0.44606 -1.11225  1.26263  1.87372]
20Nov23_044202| [-0.57357 -0.55004 -1.15617  0.42990  0.23652 -0.13154 -1.45382  0.27475
20Nov23_044202|  -0.64777 -0.51002 -0.63579 -0.59520 -0.00340  0.31749  0.18432]]
20Nov23_044202|-- Bias --
20Nov23_044202|[ 1.38477 -0.37130 -0.13609 -0.85960 -0.92209 -0.27950  0.84767 -0.72498
20Nov23_044202| -0.02423  1.22888 -0.06124 -0.44945 -0.13271 -0.02930 -0.90463]
20Nov23_044202|Layer 1:
20Nov23_044202|-- Config --
20Nov23_044202|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 15], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_044202|-- Weights --
20Nov23_044202|[[ 0.67379 -1.05055]
20Nov23_044202| [-0.28290 -0.06835]
20Nov23_044202| [ 0.37387  0.47814]
20Nov23_044202| [ 0.58602 -0.61286]
20Nov23_044202| [-0.34764  0.50916]
20Nov23_044202| [-0.54241 -0.48178]
20Nov23_044202| [ 0.78853 -0.03736]
20Nov23_044202| [-0.61206 -0.05827]
20Nov23_044202| [-0.21855  1.26722]
20Nov23_044202| [-1.67530  1.48281]
20Nov23_044202| [-0.42903  0.74587]
20Nov23_044202| [ 0.09435 -1.16066]
20Nov23_044202| [-0.06102 -0.22933]
20Nov23_044202| [ 1.05118 -0.41105]
20Nov23_044202| [ 0.89464  0.71066]]
20Nov23_044202|-- Bias --
20Nov23_044202|[-0.89499  0.52392]
20Nov23_044202|Predicting the validation and test data with the Best final individual.
20Nov23_044208| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_044208|-----------  ------------------  --------------------  ----------
20Nov23_044208|Validation         41.91                  15            0.00259
20Nov23_044208|   Test            33.88                  15            0.13498
20Nov23_044208|-------------------------- Test #1 --------------------------
20Nov23_044208|Best final individual weights
20Nov23_044208|Individual:
20Nov23_044208|-- Constant hidden layers --
20Nov23_044208|False
20Nov23_044208|Layer 0:
20Nov23_044208|-- Config --
20Nov23_044208|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 15, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_044208|-- Weights --
20Nov23_044208|[[ 0.42691  0.29758  0.52422 -0.54807 -0.00317 -1.10737  0.66615 -0.46744
20Nov23_044208|   0.89578  0.22818 -0.07631 -0.76947 -0.46817 -0.21265 -0.85367]
20Nov23_044208| [-0.77699  0.41355 -1.18759  0.58503  0.11262 -0.77177 -0.87309  0.55877
20Nov23_044208|   0.49143  0.60359  0.78317 -2.01143 -0.18524  0.77837 -1.58646]
20Nov23_044208| [-0.05520  1.48797 -0.98303  0.44607  0.57229  0.01093  0.45399 -0.36869
20Nov23_044208|   1.25502 -2.04679  0.52420 -0.63251 -1.20841 -1.23667 -0.50506]
20Nov23_044208| [-0.15390 -0.12069  0.93121  0.62856 -0.47194  1.90773  0.12418 -0.02385
20Nov23_044208|   0.25845  0.67909 -0.74973 -1.14428 -0.54709 -1.03812  0.41810]
20Nov23_044208| [ 0.78184 -1.02634 -0.50414 -1.33713 -0.12806 -0.25092  1.03068 -1.53814
20Nov23_044208|   0.61719 -0.37364 -0.16927  0.25844 -1.59357  0.03242 -0.43857]
20Nov23_044208| [-1.51161  0.28379  0.11711  1.41276  1.94477 -1.13581 -0.16030 -0.98811
20Nov23_044208|  -0.74563  0.47408  1.31199  0.25822 -0.39431  0.99731  0.10765]
20Nov23_044208| [-0.06246 -0.55106 -0.66587 -0.81741 -0.90947 -0.55317  0.91670 -0.20333
20Nov23_044208|   0.16840 -0.45981  0.55694  1.11849  2.39357 -0.67350  0.20551]
20Nov23_044208| [ 0.47039 -1.74884  1.06361  0.87013 -1.27871 -0.23461 -0.85571  0.11193
20Nov23_044208|   1.28638  1.75207 -0.89037 -0.68407  0.35909 -0.54462 -0.10916]
20Nov23_044208| [-0.66100  1.52516  0.33780 -0.06402 -1.30311  2.21049  0.94191 -0.16126
20Nov23_044208|   0.77832 -0.93202  0.12018  0.28667  0.60154  0.67235  0.59619]
20Nov23_044208| [ 0.75099  1.36528 -1.73960 -1.50392  0.42261 -0.97005 -0.91943 -1.36861
20Nov23_044208|  -0.67430 -0.64244 -0.75113  1.74554  0.65154 -0.07884  0.24832]
20Nov23_044208| [ 1.53921 -0.26881 -0.59691  0.18529  0.48024 -0.98931 -1.54877  0.09832
20Nov23_044208|   1.16540  1.02141 -0.79718  1.33652  1.32572 -1.05063 -0.59539]
20Nov23_044208| [ 0.24418  0.35593 -0.10494 -1.30488  1.09288 -0.42662 -0.57142  0.49472
20Nov23_044208|   0.69921  0.62190  1.18692  0.10424 -0.45179  0.21910  0.01208]
20Nov23_044208| [ 0.67743 -0.19633  0.24381 -0.30061  0.08343 -0.33063 -0.09417 -0.29616
20Nov23_044208|  -0.06241 -1.05399  2.07564 -0.84708  0.83477 -0.41045  1.39502]
20Nov23_044208| [-0.03313 -0.77540  0.75142 -1.09279  1.86636 -0.79280 -0.54517 -0.28329
20Nov23_044208|   1.65999 -1.12225 -1.39221  0.11678 -1.17849 -0.62609 -0.37682]
20Nov23_044208| [ 0.05688 -0.19939 -0.40529 -0.51524 -0.26279  0.50723  0.33124  0.59534
20Nov23_044208|   0.83706  0.14251  0.82221 -0.63467  0.55955 -1.01568  0.21284]
20Nov23_044208| [ 0.01208  0.01410  1.11235 -0.49398  1.55853  0.43249  0.08756  0.00921
20Nov23_044208|  -0.71567 -0.38946 -0.90949 -0.83809 -0.05624  0.23786  0.05994]
20Nov23_044208| [-0.35205 -0.09450  2.24445  0.53880 -0.40180 -0.46765 -0.12446 -1.32593
20Nov23_044208|   1.41826 -0.76602  0.63376  1.18055 -0.53400  0.37624 -0.97579]
20Nov23_044208| [ 2.22050  0.05952 -1.19940  0.70861  1.41717 -0.26877 -0.94211 -1.40332
20Nov23_044208|   0.43003 -0.89869 -1.10584 -0.06625  0.31384 -0.10143  1.04961]
20Nov23_044208| [ 0.21289 -0.11012  1.49023  1.14376 -0.65338  0.26810 -0.85944  1.17660
20Nov23_044208|  -0.47870 -0.86877  0.44700  0.03584 -0.98074 -0.78054  0.03734]
20Nov23_044208| [ 0.28067  0.39235  1.41028 -0.15688 -0.54646  1.67606  0.42347  0.49702
20Nov23_044208|  -0.87937 -0.46845  1.00348 -0.53170 -1.12293 -1.01729  0.08005]
20Nov23_044208| [-1.14499  0.21662  0.15572  0.25399 -0.11350  0.09781 -0.60481 -0.96573
20Nov23_044208|   1.28182 -0.69592 -0.07493 -0.15830  1.71185 -1.62962  0.07644]
20Nov23_044208| [ 0.22980  0.61617 -0.58762 -1.53387  0.28371 -0.27785 -1.01772  0.18418
20Nov23_044208|   2.29950 -0.81522 -0.54903  0.50229  0.43645 -1.39068  1.50836]
20Nov23_044208| [ 1.26701  0.34500 -0.87987 -0.44065  1.23200 -1.45523  0.41462 -0.45891
20Nov23_044208|  -1.65629  1.36545 -0.16045  0.01440 -0.19117  1.01491 -1.56428]
20Nov23_044208| [-0.50801 -0.18680 -0.13795 -0.82892  0.04078  1.05055 -0.42182  0.28003
20Nov23_044208|  -0.17800 -0.94982 -1.60567 -0.74657 -0.37202 -0.77117  0.22728]
20Nov23_044208| [ 0.11223 -0.88960 -0.03771  0.68481 -1.13907 -1.64770 -2.08633  2.59999
20Nov23_044208|   0.70704 -1.10352 -0.73587  0.64618  0.18789 -0.56185 -0.00473]
20Nov23_044208| [-0.44394  1.09725  0.51635  0.38580 -1.13990  0.40442 -0.52209  0.10404
20Nov23_044208|  -0.15833  0.12255 -0.21853 -0.42496  1.00447  0.73146 -0.63667]
20Nov23_044208| [ 0.10066  1.40237  0.09464  0.72661 -1.80184 -0.06104 -0.34136 -0.51537
20Nov23_044208|  -1.66542 -0.55066 -2.56233 -0.02383 -0.84513 -1.61262 -0.51402]
20Nov23_044208| [-0.87960  0.23358 -0.52134  0.40047 -0.71106 -1.34728 -0.41823 -0.22333
20Nov23_044208|  -0.24686  1.65698 -1.30747 -0.69169 -0.66251  0.75459 -0.96660]
20Nov23_044208| [ 0.06230  1.20678 -0.23045 -0.84286 -0.22852  0.93298  0.14893  0.50809
20Nov23_044208|   0.14889 -0.72929 -0.24429  1.56028  1.22272  0.91747  0.36855]
20Nov23_044208| [-0.17377  1.14562  0.85539 -0.63699 -1.04190  0.12303 -0.72049 -0.08881
20Nov23_044208|  -0.90310  1.31653 -0.05204  0.40329 -0.48401 -0.36525 -0.46378]
20Nov23_044208| [ 0.09015 -0.62972 -0.73537  0.17011  0.27345 -0.55471  0.04517 -1.18609
20Nov23_044208|  -0.58628  0.49196 -0.58326  0.30330  0.51502  0.03433  0.04217]
20Nov23_044208| [ 0.86282 -0.84858 -1.43016 -0.52856  0.03054  0.44886  0.57046 -0.35864
20Nov23_044208|  -1.71832  0.24280 -0.89086 -0.78176  0.35162  0.30409 -0.02131]
20Nov23_044208| [ 1.05695  0.97767 -1.00230 -0.01291  0.04290 -0.09954  0.88877 -1.02809
20Nov23_044208|  -1.32144  0.07652  0.09972 -1.00606 -1.32542  0.05830 -0.38045]
20Nov23_044208| [ 0.43701 -1.48958 -0.15290 -0.28863  0.74501  0.03579 -1.09314 -0.86026
20Nov23_044208|   1.02886  1.16551 -1.01948 -1.43095 -1.82196 -0.89176 -0.81819]
20Nov23_044208| [-0.73966  0.22000  1.42394  0.53847 -2.33016 -0.57383  0.30702 -0.26322
20Nov23_044208|  -1.01442  0.05468 -0.23153 -0.06345  1.16376 -0.09296 -0.53408]
20Nov23_044208| [ 0.21706  1.28120  0.03908 -0.45157  0.48998  0.08854  0.00582  0.77533
20Nov23_044208|  -0.45924  0.03863 -0.73519 -0.00919 -1.16571  1.56297 -0.69370]
20Nov23_044208| [-2.08881 -0.97910  0.17069  0.79842  0.31541 -0.19526  0.45634  1.01009
20Nov23_044208|   0.59365 -0.01322  1.78356  1.44269  0.58775 -0.50228 -0.28648]
20Nov23_044208| [-1.12486  0.73663  0.56411  0.18444 -1.61639  1.08550  0.08219 -0.90988
20Nov23_044208|  -0.32404  0.81985  0.42006 -0.30815 -0.23312 -1.18708 -0.01110]
20Nov23_044208| [-0.30490 -1.30488 -1.53248 -0.79287  1.01787 -0.71421 -1.83065  0.46204
20Nov23_044208|  -0.31745  0.01163 -0.78217 -0.08380 -0.93485  0.93025 -1.11372]
20Nov23_044208| [-0.16328  1.13418 -0.55347 -0.46779  1.07552  0.66229 -0.21371  0.92252
20Nov23_044208|   0.55318  0.22002 -0.20203  0.71337  0.07093 -0.67508 -0.36308]
20Nov23_044208| [-0.14015 -0.56332  0.42102 -0.18024 -0.17774 -1.39429  0.65512  0.86385
20Nov23_044208|   0.74911  0.68266 -0.21078 -0.90494  0.19014 -0.64455  0.30027]
20Nov23_044208| [-0.74732 -0.00467  0.93348 -0.20600  0.55633 -0.56408 -0.45634 -0.20303
20Nov23_044208|  -0.13201 -1.51600  0.26075 -0.89582 -1.24197  0.63267  1.55172]
20Nov23_044208| [ 0.41456 -0.85489  0.02298  0.06353  0.81855  0.03156 -0.48615 -0.00658
20Nov23_044208|  -0.04895 -0.57287  0.20380  1.04986  0.97412 -0.47486  0.49494]
20Nov23_044208| [ 0.77080 -0.45784  0.11136  0.71105 -0.39395  0.40195 -0.43665  1.07323
20Nov23_044208|   0.43760  0.26785 -0.30587 -0.09075  0.40279  1.01923 -1.75405]
20Nov23_044208| [-0.88852  0.02533  1.17656  0.61764 -0.88512 -2.05323 -0.20657  0.56943
20Nov23_044208|  -0.79923 -0.05065  0.86607  1.99813 -0.99948 -0.10370  0.97637]
20Nov23_044208| [ 0.15692 -0.81947 -0.03219  0.05575  0.45531  1.62288 -0.76175 -0.80154
20Nov23_044208|  -1.50942 -0.89066 -0.37832  0.57865  2.24774  1.50483 -0.01312]
20Nov23_044208| [ 0.88566 -1.32158  1.07146  0.66710  0.27661  0.21144  0.50741  1.07543
20Nov23_044208|  -0.76611 -1.39540  0.28672  0.51751  0.72656 -0.65978  0.44566]
20Nov23_044208| [-1.03893  0.46076 -0.08662 -0.52243 -0.41836  0.85811 -0.86078  0.93975
20Nov23_044208|  -0.17006 -0.63327  0.74410  0.70958  1.39514  0.35044  0.87490]
20Nov23_044208| [ 1.54246 -0.70391 -0.91033  1.89604  0.46300 -0.13194 -0.43312  0.91185
20Nov23_044208|  -0.49534 -1.06771  0.38325 -1.29257 -0.73563 -1.04282 -0.39890]
20Nov23_044208| [-0.79484 -0.73094  1.55911 -0.27683  0.74301  0.65244 -1.70505  0.26757
20Nov23_044208|  -1.24152 -0.51986 -0.91341 -0.27940 -0.78858 -0.03302  0.36902]
20Nov23_044208| [-0.52894 -0.45939  0.71874 -1.10270 -0.31797 -1.23160 -0.28378  0.28717
20Nov23_044208|  -0.95275  0.83782 -0.51558 -0.40856 -0.70669 -0.31466  0.04528]
20Nov23_044208| [-0.81167 -0.21989  0.25817 -0.60778 -0.97270  0.42051  0.05410  0.81779
20Nov23_044208|  -0.94129  0.37341 -0.02587 -1.69395 -1.66843  0.14977 -1.29684]
20Nov23_044208| [ 0.18812 -1.04226 -0.19694 -0.90997  0.07427 -1.36961 -0.68391  1.29857
20Nov23_044208|  -1.58449 -1.19082 -1.19331 -0.28466  0.45438  0.59896 -0.09320]
20Nov23_044208| [ 0.46661 -1.82518  0.34643  0.42851  0.74486  1.16437 -1.33420  0.48093
20Nov23_044208|   0.66350 -1.58536  1.36313  1.64685  0.50624 -0.08332  0.16742]
20Nov23_044208| [ 0.83611 -1.02550  0.80906  0.82930  0.96028  0.21344  0.43399 -1.26536
20Nov23_044208|  -0.08786  0.56148  0.56968 -0.83275  0.47723  1.01280 -0.61349]
20Nov23_044208| [ 0.38265 -1.34334  0.19600 -0.79295  0.52286  0.28619  1.51312  0.85224
20Nov23_044208|   1.62111  1.09962  0.16420 -0.44606 -1.11225  1.26263  1.87372]
20Nov23_044208| [-0.57357 -0.55004 -1.15617  0.42990  0.23652 -0.13154 -1.45382  0.27475
20Nov23_044208|  -0.64777 -0.51002 -0.63579 -0.59520 -0.00340  0.31749  0.18432]]
20Nov23_044208|-- Bias --
20Nov23_044208|[ 1.38477 -0.37130 -0.13609 -0.85960 -0.92209 -0.27950  0.84767 -0.72498
20Nov23_044208| -0.02423  1.22888 -0.06124 -0.44945 -0.13271 -0.02930 -0.90463]
20Nov23_044208|Layer 1:
20Nov23_044208|-- Config --
20Nov23_044208|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 15], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_044208|-- Weights --
20Nov23_044208|[[ 0.67379 -1.05055]
20Nov23_044208| [-0.28290 -0.06835]
20Nov23_044208| [ 0.37387  0.47814]
20Nov23_044208| [ 0.58602 -0.61286]
20Nov23_044208| [-0.34764  0.50916]
20Nov23_044208| [-0.54241 -0.48178]
20Nov23_044208| [ 0.78853 -0.03736]
20Nov23_044208| [-0.61206 -0.05827]
20Nov23_044208| [-0.21855  1.26722]
20Nov23_044208| [-1.67530  1.48281]
20Nov23_044208| [-0.42903  0.74587]
20Nov23_044208| [ 0.09435 -1.16066]
20Nov23_044208| [-0.06102 -0.22933]
20Nov23_044208| [ 1.05118 -0.41105]
20Nov23_044208| [ 0.89464  0.71066]]
20Nov23_044208|-- Bias --
20Nov23_044208|[-0.89499  0.52392]
20Nov23_044208|Predicting the validation and test data with the Best final individual.
20Nov23_044213| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_044213|-----------  ------------------  --------------------  ----------
20Nov23_044213|Validation         42.00                  15            0.00000
20Nov23_044213|   Test            36.14                  15            0.02953
20Nov23_044213|-------------------------- Test #2 --------------------------
20Nov23_044213|Best final individual weights
20Nov23_044213|Individual:
20Nov23_044213|-- Constant hidden layers --
20Nov23_044213|False
20Nov23_044213|Layer 0:
20Nov23_044213|-- Config --
20Nov23_044213|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 15, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_044213|-- Weights --
20Nov23_044213|[[ 0.42691  0.29758  0.52422 -0.54807 -0.00317 -1.10737  0.66615 -0.46744
20Nov23_044213|   0.89578  0.22818 -0.07631 -0.76947 -0.46817 -0.21265 -0.85367]
20Nov23_044213| [-0.77699  0.41355 -1.18759  0.58503  0.11262 -0.77177 -0.87309  0.55877
20Nov23_044213|   0.49143  0.60359  0.78317 -2.01143 -0.18524  0.77837 -1.58646]
20Nov23_044213| [-0.05520  1.48797 -0.98303  0.44607  0.57229  0.01093  0.45399 -0.36869
20Nov23_044213|   1.25502 -2.04679  0.52420 -0.63251 -1.20841 -1.23667 -0.50506]
20Nov23_044213| [-0.15390 -0.12069  0.93121  0.62856 -0.47194  1.90773  0.12418 -0.02385
20Nov23_044213|   0.25845  0.67909 -0.74973 -1.14428 -0.54709 -1.03812  0.41810]
20Nov23_044213| [ 0.78184 -1.02634 -0.50414 -1.33713 -0.12806 -0.25092  1.03068 -1.53814
20Nov23_044213|   0.61719 -0.37364 -0.16927  0.25844 -1.59357  0.03242 -0.43857]
20Nov23_044213| [-1.51161  0.28379  0.11711  1.41276  1.94477 -1.13581 -0.16030 -0.98811
20Nov23_044213|  -0.74563  0.47408  1.31199  0.25822 -0.39431  0.99731  0.10765]
20Nov23_044213| [-0.06246 -0.55106 -0.66587 -0.81741 -0.90947 -0.55317  0.91670 -0.20333
20Nov23_044213|   0.16840 -0.45981  0.55694  1.11849  2.39357 -0.67350  0.20551]
20Nov23_044213| [ 0.47039 -1.74884  1.06361  0.87013 -1.27871 -0.23461 -0.85571  0.11193
20Nov23_044213|   1.28638  1.75207 -0.89037 -0.68407  0.35909 -0.54462 -0.10916]
20Nov23_044213| [-0.66100  1.52516  0.33780 -0.06402 -1.30311  2.21049  0.94191 -0.16126
20Nov23_044213|   0.77832 -0.93202  0.12018  0.28667  0.60154  0.67235  0.59619]
20Nov23_044213| [ 0.75099  1.36528 -1.73960 -1.50392  0.42261 -0.97005 -0.91943 -1.36861
20Nov23_044213|  -0.67430 -0.64244 -0.75113  1.74554  0.65154 -0.07884  0.24832]
20Nov23_044213| [ 1.53921 -0.26881 -0.59691  0.18529  0.48024 -0.98931 -1.54877  0.09832
20Nov23_044213|   1.16540  1.02141 -0.79718  1.33652  1.32572 -1.05063 -0.59539]
20Nov23_044213| [ 0.24418  0.35593 -0.10494 -1.30488  1.09288 -0.42662 -0.57142  0.49472
20Nov23_044213|   0.69921  0.62190  1.18692  0.10424 -0.45179  0.21910  0.01208]
20Nov23_044213| [ 0.67743 -0.19633  0.24381 -0.30061  0.08343 -0.33063 -0.09417 -0.29616
20Nov23_044213|  -0.06241 -1.05399  2.07564 -0.84708  0.83477 -0.41045  1.39502]
20Nov23_044213| [-0.03313 -0.77540  0.75142 -1.09279  1.86636 -0.79280 -0.54517 -0.28329
20Nov23_044213|   1.65999 -1.12225 -1.39221  0.11678 -1.17849 -0.62609 -0.37682]
20Nov23_044213| [ 0.05688 -0.19939 -0.40529 -0.51524 -0.26279  0.50723  0.33124  0.59534
20Nov23_044213|   0.83706  0.14251  0.82221 -0.63467  0.55955 -1.01568  0.21284]
20Nov23_044213| [ 0.01208  0.01410  1.11235 -0.49398  1.55853  0.43249  0.08756  0.00921
20Nov23_044213|  -0.71567 -0.38946 -0.90949 -0.83809 -0.05624  0.23786  0.05994]
20Nov23_044213| [-0.35205 -0.09450  2.24445  0.53880 -0.40180 -0.46765 -0.12446 -1.32593
20Nov23_044213|   1.41826 -0.76602  0.63376  1.18055 -0.53400  0.37624 -0.97579]
20Nov23_044213| [ 2.22050  0.05952 -1.19940  0.70861  1.41717 -0.26877 -0.94211 -1.40332
20Nov23_044213|   0.43003 -0.89869 -1.10584 -0.06625  0.31384 -0.10143  1.04961]
20Nov23_044213| [ 0.21289 -0.11012  1.49023  1.14376 -0.65338  0.26810 -0.85944  1.17660
20Nov23_044213|  -0.47870 -0.86877  0.44700  0.03584 -0.98074 -0.78054  0.03734]
20Nov23_044213| [ 0.28067  0.39235  1.41028 -0.15688 -0.54646  1.67606  0.42347  0.49702
20Nov23_044213|  -0.87937 -0.46845  1.00348 -0.53170 -1.12293 -1.01729  0.08005]
20Nov23_044213| [-1.14499  0.21662  0.15572  0.25399 -0.11350  0.09781 -0.60481 -0.96573
20Nov23_044213|   1.28182 -0.69592 -0.07493 -0.15830  1.71185 -1.62962  0.07644]
20Nov23_044213| [ 0.22980  0.61617 -0.58762 -1.53387  0.28371 -0.27785 -1.01772  0.18418
20Nov23_044213|   2.29950 -0.81522 -0.54903  0.50229  0.43645 -1.39068  1.50836]
20Nov23_044213| [ 1.26701  0.34500 -0.87987 -0.44065  1.23200 -1.45523  0.41462 -0.45891
20Nov23_044213|  -1.65629  1.36545 -0.16045  0.01440 -0.19117  1.01491 -1.56428]
20Nov23_044213| [-0.50801 -0.18680 -0.13795 -0.82892  0.04078  1.05055 -0.42182  0.28003
20Nov23_044213|  -0.17800 -0.94982 -1.60567 -0.74657 -0.37202 -0.77117  0.22728]
20Nov23_044213| [ 0.11223 -0.88960 -0.03771  0.68481 -1.13907 -1.64770 -2.08633  2.59999
20Nov23_044213|   0.70704 -1.10352 -0.73587  0.64618  0.18789 -0.56185 -0.00473]
20Nov23_044213| [-0.44394  1.09725  0.51635  0.38580 -1.13990  0.40442 -0.52209  0.10404
20Nov23_044213|  -0.15833  0.12255 -0.21853 -0.42496  1.00447  0.73146 -0.63667]
20Nov23_044213| [ 0.10066  1.40237  0.09464  0.72661 -1.80184 -0.06104 -0.34136 -0.51537
20Nov23_044213|  -1.66542 -0.55066 -2.56233 -0.02383 -0.84513 -1.61262 -0.51402]
20Nov23_044213| [-0.87960  0.23358 -0.52134  0.40047 -0.71106 -1.34728 -0.41823 -0.22333
20Nov23_044213|  -0.24686  1.65698 -1.30747 -0.69169 -0.66251  0.75459 -0.96660]
20Nov23_044213| [ 0.06230  1.20678 -0.23045 -0.84286 -0.22852  0.93298  0.14893  0.50809
20Nov23_044213|   0.14889 -0.72929 -0.24429  1.56028  1.22272  0.91747  0.36855]
20Nov23_044213| [-0.17377  1.14562  0.85539 -0.63699 -1.04190  0.12303 -0.72049 -0.08881
20Nov23_044213|  -0.90310  1.31653 -0.05204  0.40329 -0.48401 -0.36525 -0.46378]
20Nov23_044213| [ 0.09015 -0.62972 -0.73537  0.17011  0.27345 -0.55471  0.04517 -1.18609
20Nov23_044213|  -0.58628  0.49196 -0.58326  0.30330  0.51502  0.03433  0.04217]
20Nov23_044213| [ 0.86282 -0.84858 -1.43016 -0.52856  0.03054  0.44886  0.57046 -0.35864
20Nov23_044213|  -1.71832  0.24280 -0.89086 -0.78176  0.35162  0.30409 -0.02131]
20Nov23_044213| [ 1.05695  0.97767 -1.00230 -0.01291  0.04290 -0.09954  0.88877 -1.02809
20Nov23_044213|  -1.32144  0.07652  0.09972 -1.00606 -1.32542  0.05830 -0.38045]
20Nov23_044213| [ 0.43701 -1.48958 -0.15290 -0.28863  0.74501  0.03579 -1.09314 -0.86026
20Nov23_044213|   1.02886  1.16551 -1.01948 -1.43095 -1.82196 -0.89176 -0.81819]
20Nov23_044213| [-0.73966  0.22000  1.42394  0.53847 -2.33016 -0.57383  0.30702 -0.26322
20Nov23_044213|  -1.01442  0.05468 -0.23153 -0.06345  1.16376 -0.09296 -0.53408]
20Nov23_044213| [ 0.21706  1.28120  0.03908 -0.45157  0.48998  0.08854  0.00582  0.77533
20Nov23_044213|  -0.45924  0.03863 -0.73519 -0.00919 -1.16571  1.56297 -0.69370]
20Nov23_044213| [-2.08881 -0.97910  0.17069  0.79842  0.31541 -0.19526  0.45634  1.01009
20Nov23_044213|   0.59365 -0.01322  1.78356  1.44269  0.58775 -0.50228 -0.28648]
20Nov23_044213| [-1.12486  0.73663  0.56411  0.18444 -1.61639  1.08550  0.08219 -0.90988
20Nov23_044213|  -0.32404  0.81985  0.42006 -0.30815 -0.23312 -1.18708 -0.01110]
20Nov23_044213| [-0.30490 -1.30488 -1.53248 -0.79287  1.01787 -0.71421 -1.83065  0.46204
20Nov23_044213|  -0.31745  0.01163 -0.78217 -0.08380 -0.93485  0.93025 -1.11372]
20Nov23_044213| [-0.16328  1.13418 -0.55347 -0.46779  1.07552  0.66229 -0.21371  0.92252
20Nov23_044213|   0.55318  0.22002 -0.20203  0.71337  0.07093 -0.67508 -0.36308]
20Nov23_044213| [-0.14015 -0.56332  0.42102 -0.18024 -0.17774 -1.39429  0.65512  0.86385
20Nov23_044213|   0.74911  0.68266 -0.21078 -0.90494  0.19014 -0.64455  0.30027]
20Nov23_044213| [-0.74732 -0.00467  0.93348 -0.20600  0.55633 -0.56408 -0.45634 -0.20303
20Nov23_044213|  -0.13201 -1.51600  0.26075 -0.89582 -1.24197  0.63267  1.55172]
20Nov23_044213| [ 0.41456 -0.85489  0.02298  0.06353  0.81855  0.03156 -0.48615 -0.00658
20Nov23_044213|  -0.04895 -0.57287  0.20380  1.04986  0.97412 -0.47486  0.49494]
20Nov23_044213| [ 0.77080 -0.45784  0.11136  0.71105 -0.39395  0.40195 -0.43665  1.07323
20Nov23_044213|   0.43760  0.26785 -0.30587 -0.09075  0.40279  1.01923 -1.75405]
20Nov23_044213| [-0.88852  0.02533  1.17656  0.61764 -0.88512 -2.05323 -0.20657  0.56943
20Nov23_044213|  -0.79923 -0.05065  0.86607  1.99813 -0.99948 -0.10370  0.97637]
20Nov23_044213| [ 0.15692 -0.81947 -0.03219  0.05575  0.45531  1.62288 -0.76175 -0.80154
20Nov23_044213|  -1.50942 -0.89066 -0.37832  0.57865  2.24774  1.50483 -0.01312]
20Nov23_044213| [ 0.88566 -1.32158  1.07146  0.66710  0.27661  0.21144  0.50741  1.07543
20Nov23_044213|  -0.76611 -1.39540  0.28672  0.51751  0.72656 -0.65978  0.44566]
20Nov23_044213| [-1.03893  0.46076 -0.08662 -0.52243 -0.41836  0.85811 -0.86078  0.93975
20Nov23_044213|  -0.17006 -0.63327  0.74410  0.70958  1.39514  0.35044  0.87490]
20Nov23_044213| [ 1.54246 -0.70391 -0.91033  1.89604  0.46300 -0.13194 -0.43312  0.91185
20Nov23_044213|  -0.49534 -1.06771  0.38325 -1.29257 -0.73563 -1.04282 -0.39890]
20Nov23_044213| [-0.79484 -0.73094  1.55911 -0.27683  0.74301  0.65244 -1.70505  0.26757
20Nov23_044213|  -1.24152 -0.51986 -0.91341 -0.27940 -0.78858 -0.03302  0.36902]
20Nov23_044213| [-0.52894 -0.45939  0.71874 -1.10270 -0.31797 -1.23160 -0.28378  0.28717
20Nov23_044213|  -0.95275  0.83782 -0.51558 -0.40856 -0.70669 -0.31466  0.04528]
20Nov23_044213| [-0.81167 -0.21989  0.25817 -0.60778 -0.97270  0.42051  0.05410  0.81779
20Nov23_044213|  -0.94129  0.37341 -0.02587 -1.69395 -1.66843  0.14977 -1.29684]
20Nov23_044213| [ 0.18812 -1.04226 -0.19694 -0.90997  0.07427 -1.36961 -0.68391  1.29857
20Nov23_044213|  -1.58449 -1.19082 -1.19331 -0.28466  0.45438  0.59896 -0.09320]
20Nov23_044213| [ 0.46661 -1.82518  0.34643  0.42851  0.74486  1.16437 -1.33420  0.48093
20Nov23_044213|   0.66350 -1.58536  1.36313  1.64685  0.50624 -0.08332  0.16742]
20Nov23_044213| [ 0.83611 -1.02550  0.80906  0.82930  0.96028  0.21344  0.43399 -1.26536
20Nov23_044213|  -0.08786  0.56148  0.56968 -0.83275  0.47723  1.01280 -0.61349]
20Nov23_044213| [ 0.38265 -1.34334  0.19600 -0.79295  0.52286  0.28619  1.51312  0.85224
20Nov23_044213|   1.62111  1.09962  0.16420 -0.44606 -1.11225  1.26263  1.87372]
20Nov23_044213| [-0.57357 -0.55004 -1.15617  0.42990  0.23652 -0.13154 -1.45382  0.27475
20Nov23_044213|  -0.64777 -0.51002 -0.63579 -0.59520 -0.00340  0.31749  0.18432]]
20Nov23_044213|-- Bias --
20Nov23_044213|[ 1.38477 -0.37130 -0.13609 -0.85960 -0.92209 -0.27950  0.84767 -0.72498
20Nov23_044213| -0.02423  1.22888 -0.06124 -0.44945 -0.13271 -0.02930 -0.90463]
20Nov23_044213|Layer 1:
20Nov23_044213|-- Config --
20Nov23_044213|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 15], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_044213|-- Weights --
20Nov23_044213|[[ 0.67379 -1.05055]
20Nov23_044213| [-0.28290 -0.06835]
20Nov23_044213| [ 0.37387  0.47814]
20Nov23_044213| [ 0.58602 -0.61286]
20Nov23_044213| [-0.34764  0.50916]
20Nov23_044213| [-0.54241 -0.48178]
20Nov23_044213| [ 0.78853 -0.03736]
20Nov23_044213| [-0.61206 -0.05827]
20Nov23_044213| [-0.21855  1.26722]
20Nov23_044213| [-1.67530  1.48281]
20Nov23_044213| [-0.42903  0.74587]
20Nov23_044213| [ 0.09435 -1.16066]
20Nov23_044213| [-0.06102 -0.22933]
20Nov23_044213| [ 1.05118 -0.41105]
20Nov23_044213| [ 0.89464  0.71066]]
20Nov23_044213|-- Bias --
20Nov23_044213|[-0.89499  0.52392]
20Nov23_044213|Predicting the validation and test data with the Best final individual.
20Nov23_044219| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_044219|-----------  ------------------  --------------------  ----------
20Nov23_044219|Validation         39.83                  15            0.07379
20Nov23_044219|   Test            36.49                  15            0.01482
20Nov23_044219|-------------------------- Test #3 --------------------------
20Nov23_044219|Best final individual weights
20Nov23_044219|Individual:
20Nov23_044219|-- Constant hidden layers --
20Nov23_044219|False
20Nov23_044219|Layer 0:
20Nov23_044219|-- Config --
20Nov23_044219|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 15, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_044219|-- Weights --
20Nov23_044219|[[ 0.42691  0.29758  0.52422 -0.54807 -0.00317 -1.10737  0.66615 -0.46744
20Nov23_044219|   0.89578  0.22818 -0.07631 -0.76947 -0.46817 -0.21265 -0.85367]
20Nov23_044219| [-0.77699  0.41355 -1.18759  0.58503  0.11262 -0.77177 -0.87309  0.55877
20Nov23_044219|   0.49143  0.60359  0.78317 -2.01143 -0.18524  0.77837 -1.58646]
20Nov23_044219| [-0.05520  1.48797 -0.98303  0.44607  0.57229  0.01093  0.45399 -0.36869
20Nov23_044219|   1.25502 -2.04679  0.52420 -0.63251 -1.20841 -1.23667 -0.50506]
20Nov23_044219| [-0.15390 -0.12069  0.93121  0.62856 -0.47194  1.90773  0.12418 -0.02385
20Nov23_044219|   0.25845  0.67909 -0.74973 -1.14428 -0.54709 -1.03812  0.41810]
20Nov23_044219| [ 0.78184 -1.02634 -0.50414 -1.33713 -0.12806 -0.25092  1.03068 -1.53814
20Nov23_044219|   0.61719 -0.37364 -0.16927  0.25844 -1.59357  0.03242 -0.43857]
20Nov23_044219| [-1.51161  0.28379  0.11711  1.41276  1.94477 -1.13581 -0.16030 -0.98811
20Nov23_044219|  -0.74563  0.47408  1.31199  0.25822 -0.39431  0.99731  0.10765]
20Nov23_044219| [-0.06246 -0.55106 -0.66587 -0.81741 -0.90947 -0.55317  0.91670 -0.20333
20Nov23_044219|   0.16840 -0.45981  0.55694  1.11849  2.39357 -0.67350  0.20551]
20Nov23_044219| [ 0.47039 -1.74884  1.06361  0.87013 -1.27871 -0.23461 -0.85571  0.11193
20Nov23_044219|   1.28638  1.75207 -0.89037 -0.68407  0.35909 -0.54462 -0.10916]
20Nov23_044219| [-0.66100  1.52516  0.33780 -0.06402 -1.30311  2.21049  0.94191 -0.16126
20Nov23_044219|   0.77832 -0.93202  0.12018  0.28667  0.60154  0.67235  0.59619]
20Nov23_044219| [ 0.75099  1.36528 -1.73960 -1.50392  0.42261 -0.97005 -0.91943 -1.36861
20Nov23_044219|  -0.67430 -0.64244 -0.75113  1.74554  0.65154 -0.07884  0.24832]
20Nov23_044219| [ 1.53921 -0.26881 -0.59691  0.18529  0.48024 -0.98931 -1.54877  0.09832
20Nov23_044219|   1.16540  1.02141 -0.79718  1.33652  1.32572 -1.05063 -0.59539]
20Nov23_044219| [ 0.24418  0.35593 -0.10494 -1.30488  1.09288 -0.42662 -0.57142  0.49472
20Nov23_044219|   0.69921  0.62190  1.18692  0.10424 -0.45179  0.21910  0.01208]
20Nov23_044219| [ 0.67743 -0.19633  0.24381 -0.30061  0.08343 -0.33063 -0.09417 -0.29616
20Nov23_044219|  -0.06241 -1.05399  2.07564 -0.84708  0.83477 -0.41045  1.39502]
20Nov23_044219| [-0.03313 -0.77540  0.75142 -1.09279  1.86636 -0.79280 -0.54517 -0.28329
20Nov23_044219|   1.65999 -1.12225 -1.39221  0.11678 -1.17849 -0.62609 -0.37682]
20Nov23_044219| [ 0.05688 -0.19939 -0.40529 -0.51524 -0.26279  0.50723  0.33124  0.59534
20Nov23_044219|   0.83706  0.14251  0.82221 -0.63467  0.55955 -1.01568  0.21284]
20Nov23_044219| [ 0.01208  0.01410  1.11235 -0.49398  1.55853  0.43249  0.08756  0.00921
20Nov23_044219|  -0.71567 -0.38946 -0.90949 -0.83809 -0.05624  0.23786  0.05994]
20Nov23_044219| [-0.35205 -0.09450  2.24445  0.53880 -0.40180 -0.46765 -0.12446 -1.32593
20Nov23_044219|   1.41826 -0.76602  0.63376  1.18055 -0.53400  0.37624 -0.97579]
20Nov23_044219| [ 2.22050  0.05952 -1.19940  0.70861  1.41717 -0.26877 -0.94211 -1.40332
20Nov23_044219|   0.43003 -0.89869 -1.10584 -0.06625  0.31384 -0.10143  1.04961]
20Nov23_044219| [ 0.21289 -0.11012  1.49023  1.14376 -0.65338  0.26810 -0.85944  1.17660
20Nov23_044219|  -0.47870 -0.86877  0.44700  0.03584 -0.98074 -0.78054  0.03734]
20Nov23_044219| [ 0.28067  0.39235  1.41028 -0.15688 -0.54646  1.67606  0.42347  0.49702
20Nov23_044219|  -0.87937 -0.46845  1.00348 -0.53170 -1.12293 -1.01729  0.08005]
20Nov23_044219| [-1.14499  0.21662  0.15572  0.25399 -0.11350  0.09781 -0.60481 -0.96573
20Nov23_044219|   1.28182 -0.69592 -0.07493 -0.15830  1.71185 -1.62962  0.07644]
20Nov23_044219| [ 0.22980  0.61617 -0.58762 -1.53387  0.28371 -0.27785 -1.01772  0.18418
20Nov23_044219|   2.29950 -0.81522 -0.54903  0.50229  0.43645 -1.39068  1.50836]
20Nov23_044219| [ 1.26701  0.34500 -0.87987 -0.44065  1.23200 -1.45523  0.41462 -0.45891
20Nov23_044219|  -1.65629  1.36545 -0.16045  0.01440 -0.19117  1.01491 -1.56428]
20Nov23_044219| [-0.50801 -0.18680 -0.13795 -0.82892  0.04078  1.05055 -0.42182  0.28003
20Nov23_044219|  -0.17800 -0.94982 -1.60567 -0.74657 -0.37202 -0.77117  0.22728]
20Nov23_044219| [ 0.11223 -0.88960 -0.03771  0.68481 -1.13907 -1.64770 -2.08633  2.59999
20Nov23_044219|   0.70704 -1.10352 -0.73587  0.64618  0.18789 -0.56185 -0.00473]
20Nov23_044219| [-0.44394  1.09725  0.51635  0.38580 -1.13990  0.40442 -0.52209  0.10404
20Nov23_044219|  -0.15833  0.12255 -0.21853 -0.42496  1.00447  0.73146 -0.63667]
20Nov23_044219| [ 0.10066  1.40237  0.09464  0.72661 -1.80184 -0.06104 -0.34136 -0.51537
20Nov23_044219|  -1.66542 -0.55066 -2.56233 -0.02383 -0.84513 -1.61262 -0.51402]
20Nov23_044219| [-0.87960  0.23358 -0.52134  0.40047 -0.71106 -1.34728 -0.41823 -0.22333
20Nov23_044219|  -0.24686  1.65698 -1.30747 -0.69169 -0.66251  0.75459 -0.96660]
20Nov23_044219| [ 0.06230  1.20678 -0.23045 -0.84286 -0.22852  0.93298  0.14893  0.50809
20Nov23_044219|   0.14889 -0.72929 -0.24429  1.56028  1.22272  0.91747  0.36855]
20Nov23_044219| [-0.17377  1.14562  0.85539 -0.63699 -1.04190  0.12303 -0.72049 -0.08881
20Nov23_044219|  -0.90310  1.31653 -0.05204  0.40329 -0.48401 -0.36525 -0.46378]
20Nov23_044219| [ 0.09015 -0.62972 -0.73537  0.17011  0.27345 -0.55471  0.04517 -1.18609
20Nov23_044219|  -0.58628  0.49196 -0.58326  0.30330  0.51502  0.03433  0.04217]
20Nov23_044219| [ 0.86282 -0.84858 -1.43016 -0.52856  0.03054  0.44886  0.57046 -0.35864
20Nov23_044219|  -1.71832  0.24280 -0.89086 -0.78176  0.35162  0.30409 -0.02131]
20Nov23_044219| [ 1.05695  0.97767 -1.00230 -0.01291  0.04290 -0.09954  0.88877 -1.02809
20Nov23_044219|  -1.32144  0.07652  0.09972 -1.00606 -1.32542  0.05830 -0.38045]
20Nov23_044219| [ 0.43701 -1.48958 -0.15290 -0.28863  0.74501  0.03579 -1.09314 -0.86026
20Nov23_044219|   1.02886  1.16551 -1.01948 -1.43095 -1.82196 -0.89176 -0.81819]
20Nov23_044219| [-0.73966  0.22000  1.42394  0.53847 -2.33016 -0.57383  0.30702 -0.26322
20Nov23_044219|  -1.01442  0.05468 -0.23153 -0.06345  1.16376 -0.09296 -0.53408]
20Nov23_044219| [ 0.21706  1.28120  0.03908 -0.45157  0.48998  0.08854  0.00582  0.77533
20Nov23_044219|  -0.45924  0.03863 -0.73519 -0.00919 -1.16571  1.56297 -0.69370]
20Nov23_044219| [-2.08881 -0.97910  0.17069  0.79842  0.31541 -0.19526  0.45634  1.01009
20Nov23_044219|   0.59365 -0.01322  1.78356  1.44269  0.58775 -0.50228 -0.28648]
20Nov23_044219| [-1.12486  0.73663  0.56411  0.18444 -1.61639  1.08550  0.08219 -0.90988
20Nov23_044219|  -0.32404  0.81985  0.42006 -0.30815 -0.23312 -1.18708 -0.01110]
20Nov23_044219| [-0.30490 -1.30488 -1.53248 -0.79287  1.01787 -0.71421 -1.83065  0.46204
20Nov23_044219|  -0.31745  0.01163 -0.78217 -0.08380 -0.93485  0.93025 -1.11372]
20Nov23_044219| [-0.16328  1.13418 -0.55347 -0.46779  1.07552  0.66229 -0.21371  0.92252
20Nov23_044219|   0.55318  0.22002 -0.20203  0.71337  0.07093 -0.67508 -0.36308]
20Nov23_044219| [-0.14015 -0.56332  0.42102 -0.18024 -0.17774 -1.39429  0.65512  0.86385
20Nov23_044219|   0.74911  0.68266 -0.21078 -0.90494  0.19014 -0.64455  0.30027]
20Nov23_044219| [-0.74732 -0.00467  0.93348 -0.20600  0.55633 -0.56408 -0.45634 -0.20303
20Nov23_044219|  -0.13201 -1.51600  0.26075 -0.89582 -1.24197  0.63267  1.55172]
20Nov23_044219| [ 0.41456 -0.85489  0.02298  0.06353  0.81855  0.03156 -0.48615 -0.00658
20Nov23_044219|  -0.04895 -0.57287  0.20380  1.04986  0.97412 -0.47486  0.49494]
20Nov23_044219| [ 0.77080 -0.45784  0.11136  0.71105 -0.39395  0.40195 -0.43665  1.07323
20Nov23_044219|   0.43760  0.26785 -0.30587 -0.09075  0.40279  1.01923 -1.75405]
20Nov23_044219| [-0.88852  0.02533  1.17656  0.61764 -0.88512 -2.05323 -0.20657  0.56943
20Nov23_044219|  -0.79923 -0.05065  0.86607  1.99813 -0.99948 -0.10370  0.97637]
20Nov23_044219| [ 0.15692 -0.81947 -0.03219  0.05575  0.45531  1.62288 -0.76175 -0.80154
20Nov23_044219|  -1.50942 -0.89066 -0.37832  0.57865  2.24774  1.50483 -0.01312]
20Nov23_044219| [ 0.88566 -1.32158  1.07146  0.66710  0.27661  0.21144  0.50741  1.07543
20Nov23_044219|  -0.76611 -1.39540  0.28672  0.51751  0.72656 -0.65978  0.44566]
20Nov23_044219| [-1.03893  0.46076 -0.08662 -0.52243 -0.41836  0.85811 -0.86078  0.93975
20Nov23_044219|  -0.17006 -0.63327  0.74410  0.70958  1.39514  0.35044  0.87490]
20Nov23_044219| [ 1.54246 -0.70391 -0.91033  1.89604  0.46300 -0.13194 -0.43312  0.91185
20Nov23_044219|  -0.49534 -1.06771  0.38325 -1.29257 -0.73563 -1.04282 -0.39890]
20Nov23_044219| [-0.79484 -0.73094  1.55911 -0.27683  0.74301  0.65244 -1.70505  0.26757
20Nov23_044219|  -1.24152 -0.51986 -0.91341 -0.27940 -0.78858 -0.03302  0.36902]
20Nov23_044219| [-0.52894 -0.45939  0.71874 -1.10270 -0.31797 -1.23160 -0.28378  0.28717
20Nov23_044219|  -0.95275  0.83782 -0.51558 -0.40856 -0.70669 -0.31466  0.04528]
20Nov23_044219| [-0.81167 -0.21989  0.25817 -0.60778 -0.97270  0.42051  0.05410  0.81779
20Nov23_044219|  -0.94129  0.37341 -0.02587 -1.69395 -1.66843  0.14977 -1.29684]
20Nov23_044219| [ 0.18812 -1.04226 -0.19694 -0.90997  0.07427 -1.36961 -0.68391  1.29857
20Nov23_044219|  -1.58449 -1.19082 -1.19331 -0.28466  0.45438  0.59896 -0.09320]
20Nov23_044219| [ 0.46661 -1.82518  0.34643  0.42851  0.74486  1.16437 -1.33420  0.48093
20Nov23_044219|   0.66350 -1.58536  1.36313  1.64685  0.50624 -0.08332  0.16742]
20Nov23_044219| [ 0.83611 -1.02550  0.80906  0.82930  0.96028  0.21344  0.43399 -1.26536
20Nov23_044219|  -0.08786  0.56148  0.56968 -0.83275  0.47723  1.01280 -0.61349]
20Nov23_044219| [ 0.38265 -1.34334  0.19600 -0.79295  0.52286  0.28619  1.51312  0.85224
20Nov23_044219|   1.62111  1.09962  0.16420 -0.44606 -1.11225  1.26263  1.87372]
20Nov23_044219| [-0.57357 -0.55004 -1.15617  0.42990  0.23652 -0.13154 -1.45382  0.27475
20Nov23_044219|  -0.64777 -0.51002 -0.63579 -0.59520 -0.00340  0.31749  0.18432]]
20Nov23_044219|-- Bias --
20Nov23_044219|[ 1.38477 -0.37130 -0.13609 -0.85960 -0.92209 -0.27950  0.84767 -0.72498
20Nov23_044219| -0.02423  1.22888 -0.06124 -0.44945 -0.13271 -0.02930 -0.90463]
20Nov23_044219|Layer 1:
20Nov23_044219|-- Config --
20Nov23_044219|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 15], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_044219|-- Weights --
20Nov23_044219|[[ 0.67379 -1.05055]
20Nov23_044219| [-0.28290 -0.06835]
20Nov23_044219| [ 0.37387  0.47814]
20Nov23_044219| [ 0.58602 -0.61286]
20Nov23_044219| [-0.34764  0.50916]
20Nov23_044219| [-0.54241 -0.48178]
20Nov23_044219| [ 0.78853 -0.03736]
20Nov23_044219| [-0.61206 -0.05827]
20Nov23_044219| [-0.21855  1.26722]
20Nov23_044219| [-1.67530  1.48281]
20Nov23_044219| [-0.42903  0.74587]
20Nov23_044219| [ 0.09435 -1.16066]
20Nov23_044219| [-0.06102 -0.22933]
20Nov23_044219| [ 1.05118 -0.41105]
20Nov23_044219| [ 0.89464  0.71066]]
20Nov23_044219|-- Bias --
20Nov23_044219|[-0.89499  0.52392]
20Nov23_044219|Predicting the validation and test data with the Best final individual.
20Nov23_044225| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_044225|-----------  ------------------  --------------------  ----------
20Nov23_044225|Validation         41.30                  15            0.07071
20Nov23_044225|   Test            35.36                  15            0.06440
20Nov23_044225|-------------------------- Test #4 --------------------------
20Nov23_044225|Best final individual weights
20Nov23_044225|Individual:
20Nov23_044225|-- Constant hidden layers --
20Nov23_044225|False
20Nov23_044225|Layer 0:
20Nov23_044225|-- Config --
20Nov23_044225|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 15, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_044225|-- Weights --
20Nov23_044225|[[ 0.42691  0.29758  0.52422 -0.54807 -0.00317 -1.10737  0.66615 -0.46744
20Nov23_044225|   0.89578  0.22818 -0.07631 -0.76947 -0.46817 -0.21265 -0.85367]
20Nov23_044225| [-0.77699  0.41355 -1.18759  0.58503  0.11262 -0.77177 -0.87309  0.55877
20Nov23_044225|   0.49143  0.60359  0.78317 -2.01143 -0.18524  0.77837 -1.58646]
20Nov23_044225| [-0.05520  1.48797 -0.98303  0.44607  0.57229  0.01093  0.45399 -0.36869
20Nov23_044225|   1.25502 -2.04679  0.52420 -0.63251 -1.20841 -1.23667 -0.50506]
20Nov23_044225| [-0.15390 -0.12069  0.93121  0.62856 -0.47194  1.90773  0.12418 -0.02385
20Nov23_044225|   0.25845  0.67909 -0.74973 -1.14428 -0.54709 -1.03812  0.41810]
20Nov23_044225| [ 0.78184 -1.02634 -0.50414 -1.33713 -0.12806 -0.25092  1.03068 -1.53814
20Nov23_044225|   0.61719 -0.37364 -0.16927  0.25844 -1.59357  0.03242 -0.43857]
20Nov23_044225| [-1.51161  0.28379  0.11711  1.41276  1.94477 -1.13581 -0.16030 -0.98811
20Nov23_044225|  -0.74563  0.47408  1.31199  0.25822 -0.39431  0.99731  0.10765]
20Nov23_044225| [-0.06246 -0.55106 -0.66587 -0.81741 -0.90947 -0.55317  0.91670 -0.20333
20Nov23_044225|   0.16840 -0.45981  0.55694  1.11849  2.39357 -0.67350  0.20551]
20Nov23_044225| [ 0.47039 -1.74884  1.06361  0.87013 -1.27871 -0.23461 -0.85571  0.11193
20Nov23_044225|   1.28638  1.75207 -0.89037 -0.68407  0.35909 -0.54462 -0.10916]
20Nov23_044225| [-0.66100  1.52516  0.33780 -0.06402 -1.30311  2.21049  0.94191 -0.16126
20Nov23_044225|   0.77832 -0.93202  0.12018  0.28667  0.60154  0.67235  0.59619]
20Nov23_044225| [ 0.75099  1.36528 -1.73960 -1.50392  0.42261 -0.97005 -0.91943 -1.36861
20Nov23_044225|  -0.67430 -0.64244 -0.75113  1.74554  0.65154 -0.07884  0.24832]
20Nov23_044225| [ 1.53921 -0.26881 -0.59691  0.18529  0.48024 -0.98931 -1.54877  0.09832
20Nov23_044225|   1.16540  1.02141 -0.79718  1.33652  1.32572 -1.05063 -0.59539]
20Nov23_044225| [ 0.24418  0.35593 -0.10494 -1.30488  1.09288 -0.42662 -0.57142  0.49472
20Nov23_044225|   0.69921  0.62190  1.18692  0.10424 -0.45179  0.21910  0.01208]
20Nov23_044225| [ 0.67743 -0.19633  0.24381 -0.30061  0.08343 -0.33063 -0.09417 -0.29616
20Nov23_044225|  -0.06241 -1.05399  2.07564 -0.84708  0.83477 -0.41045  1.39502]
20Nov23_044225| [-0.03313 -0.77540  0.75142 -1.09279  1.86636 -0.79280 -0.54517 -0.28329
20Nov23_044225|   1.65999 -1.12225 -1.39221  0.11678 -1.17849 -0.62609 -0.37682]
20Nov23_044225| [ 0.05688 -0.19939 -0.40529 -0.51524 -0.26279  0.50723  0.33124  0.59534
20Nov23_044225|   0.83706  0.14251  0.82221 -0.63467  0.55955 -1.01568  0.21284]
20Nov23_044225| [ 0.01208  0.01410  1.11235 -0.49398  1.55853  0.43249  0.08756  0.00921
20Nov23_044225|  -0.71567 -0.38946 -0.90949 -0.83809 -0.05624  0.23786  0.05994]
20Nov23_044225| [-0.35205 -0.09450  2.24445  0.53880 -0.40180 -0.46765 -0.12446 -1.32593
20Nov23_044225|   1.41826 -0.76602  0.63376  1.18055 -0.53400  0.37624 -0.97579]
20Nov23_044225| [ 2.22050  0.05952 -1.19940  0.70861  1.41717 -0.26877 -0.94211 -1.40332
20Nov23_044225|   0.43003 -0.89869 -1.10584 -0.06625  0.31384 -0.10143  1.04961]
20Nov23_044225| [ 0.21289 -0.11012  1.49023  1.14376 -0.65338  0.26810 -0.85944  1.17660
20Nov23_044225|  -0.47870 -0.86877  0.44700  0.03584 -0.98074 -0.78054  0.03734]
20Nov23_044225| [ 0.28067  0.39235  1.41028 -0.15688 -0.54646  1.67606  0.42347  0.49702
20Nov23_044225|  -0.87937 -0.46845  1.00348 -0.53170 -1.12293 -1.01729  0.08005]
20Nov23_044225| [-1.14499  0.21662  0.15572  0.25399 -0.11350  0.09781 -0.60481 -0.96573
20Nov23_044225|   1.28182 -0.69592 -0.07493 -0.15830  1.71185 -1.62962  0.07644]
20Nov23_044225| [ 0.22980  0.61617 -0.58762 -1.53387  0.28371 -0.27785 -1.01772  0.18418
20Nov23_044225|   2.29950 -0.81522 -0.54903  0.50229  0.43645 -1.39068  1.50836]
20Nov23_044225| [ 1.26701  0.34500 -0.87987 -0.44065  1.23200 -1.45523  0.41462 -0.45891
20Nov23_044225|  -1.65629  1.36545 -0.16045  0.01440 -0.19117  1.01491 -1.56428]
20Nov23_044225| [-0.50801 -0.18680 -0.13795 -0.82892  0.04078  1.05055 -0.42182  0.28003
20Nov23_044225|  -0.17800 -0.94982 -1.60567 -0.74657 -0.37202 -0.77117  0.22728]
20Nov23_044225| [ 0.11223 -0.88960 -0.03771  0.68481 -1.13907 -1.64770 -2.08633  2.59999
20Nov23_044225|   0.70704 -1.10352 -0.73587  0.64618  0.18789 -0.56185 -0.00473]
20Nov23_044225| [-0.44394  1.09725  0.51635  0.38580 -1.13990  0.40442 -0.52209  0.10404
20Nov23_044225|  -0.15833  0.12255 -0.21853 -0.42496  1.00447  0.73146 -0.63667]
20Nov23_044225| [ 0.10066  1.40237  0.09464  0.72661 -1.80184 -0.06104 -0.34136 -0.51537
20Nov23_044225|  -1.66542 -0.55066 -2.56233 -0.02383 -0.84513 -1.61262 -0.51402]
20Nov23_044225| [-0.87960  0.23358 -0.52134  0.40047 -0.71106 -1.34728 -0.41823 -0.22333
20Nov23_044225|  -0.24686  1.65698 -1.30747 -0.69169 -0.66251  0.75459 -0.96660]
20Nov23_044225| [ 0.06230  1.20678 -0.23045 -0.84286 -0.22852  0.93298  0.14893  0.50809
20Nov23_044225|   0.14889 -0.72929 -0.24429  1.56028  1.22272  0.91747  0.36855]
20Nov23_044225| [-0.17377  1.14562  0.85539 -0.63699 -1.04190  0.12303 -0.72049 -0.08881
20Nov23_044225|  -0.90310  1.31653 -0.05204  0.40329 -0.48401 -0.36525 -0.46378]
20Nov23_044225| [ 0.09015 -0.62972 -0.73537  0.17011  0.27345 -0.55471  0.04517 -1.18609
20Nov23_044225|  -0.58628  0.49196 -0.58326  0.30330  0.51502  0.03433  0.04217]
20Nov23_044225| [ 0.86282 -0.84858 -1.43016 -0.52856  0.03054  0.44886  0.57046 -0.35864
20Nov23_044225|  -1.71832  0.24280 -0.89086 -0.78176  0.35162  0.30409 -0.02131]
20Nov23_044225| [ 1.05695  0.97767 -1.00230 -0.01291  0.04290 -0.09954  0.88877 -1.02809
20Nov23_044225|  -1.32144  0.07652  0.09972 -1.00606 -1.32542  0.05830 -0.38045]
20Nov23_044225| [ 0.43701 -1.48958 -0.15290 -0.28863  0.74501  0.03579 -1.09314 -0.86026
20Nov23_044225|   1.02886  1.16551 -1.01948 -1.43095 -1.82196 -0.89176 -0.81819]
20Nov23_044225| [-0.73966  0.22000  1.42394  0.53847 -2.33016 -0.57383  0.30702 -0.26322
20Nov23_044225|  -1.01442  0.05468 -0.23153 -0.06345  1.16376 -0.09296 -0.53408]
20Nov23_044225| [ 0.21706  1.28120  0.03908 -0.45157  0.48998  0.08854  0.00582  0.77533
20Nov23_044225|  -0.45924  0.03863 -0.73519 -0.00919 -1.16571  1.56297 -0.69370]
20Nov23_044225| [-2.08881 -0.97910  0.17069  0.79842  0.31541 -0.19526  0.45634  1.01009
20Nov23_044225|   0.59365 -0.01322  1.78356  1.44269  0.58775 -0.50228 -0.28648]
20Nov23_044225| [-1.12486  0.73663  0.56411  0.18444 -1.61639  1.08550  0.08219 -0.90988
20Nov23_044225|  -0.32404  0.81985  0.42006 -0.30815 -0.23312 -1.18708 -0.01110]
20Nov23_044225| [-0.30490 -1.30488 -1.53248 -0.79287  1.01787 -0.71421 -1.83065  0.46204
20Nov23_044225|  -0.31745  0.01163 -0.78217 -0.08380 -0.93485  0.93025 -1.11372]
20Nov23_044225| [-0.16328  1.13418 -0.55347 -0.46779  1.07552  0.66229 -0.21371  0.92252
20Nov23_044225|   0.55318  0.22002 -0.20203  0.71337  0.07093 -0.67508 -0.36308]
20Nov23_044225| [-0.14015 -0.56332  0.42102 -0.18024 -0.17774 -1.39429  0.65512  0.86385
20Nov23_044225|   0.74911  0.68266 -0.21078 -0.90494  0.19014 -0.64455  0.30027]
20Nov23_044225| [-0.74732 -0.00467  0.93348 -0.20600  0.55633 -0.56408 -0.45634 -0.20303
20Nov23_044225|  -0.13201 -1.51600  0.26075 -0.89582 -1.24197  0.63267  1.55172]
20Nov23_044225| [ 0.41456 -0.85489  0.02298  0.06353  0.81855  0.03156 -0.48615 -0.00658
20Nov23_044225|  -0.04895 -0.57287  0.20380  1.04986  0.97412 -0.47486  0.49494]
20Nov23_044225| [ 0.77080 -0.45784  0.11136  0.71105 -0.39395  0.40195 -0.43665  1.07323
20Nov23_044225|   0.43760  0.26785 -0.30587 -0.09075  0.40279  1.01923 -1.75405]
20Nov23_044225| [-0.88852  0.02533  1.17656  0.61764 -0.88512 -2.05323 -0.20657  0.56943
20Nov23_044225|  -0.79923 -0.05065  0.86607  1.99813 -0.99948 -0.10370  0.97637]
20Nov23_044225| [ 0.15692 -0.81947 -0.03219  0.05575  0.45531  1.62288 -0.76175 -0.80154
20Nov23_044225|  -1.50942 -0.89066 -0.37832  0.57865  2.24774  1.50483 -0.01312]
20Nov23_044225| [ 0.88566 -1.32158  1.07146  0.66710  0.27661  0.21144  0.50741  1.07543
20Nov23_044225|  -0.76611 -1.39540  0.28672  0.51751  0.72656 -0.65978  0.44566]
20Nov23_044225| [-1.03893  0.46076 -0.08662 -0.52243 -0.41836  0.85811 -0.86078  0.93975
20Nov23_044225|  -0.17006 -0.63327  0.74410  0.70958  1.39514  0.35044  0.87490]
20Nov23_044225| [ 1.54246 -0.70391 -0.91033  1.89604  0.46300 -0.13194 -0.43312  0.91185
20Nov23_044225|  -0.49534 -1.06771  0.38325 -1.29257 -0.73563 -1.04282 -0.39890]
20Nov23_044225| [-0.79484 -0.73094  1.55911 -0.27683  0.74301  0.65244 -1.70505  0.26757
20Nov23_044225|  -1.24152 -0.51986 -0.91341 -0.27940 -0.78858 -0.03302  0.36902]
20Nov23_044225| [-0.52894 -0.45939  0.71874 -1.10270 -0.31797 -1.23160 -0.28378  0.28717
20Nov23_044225|  -0.95275  0.83782 -0.51558 -0.40856 -0.70669 -0.31466  0.04528]
20Nov23_044225| [-0.81167 -0.21989  0.25817 -0.60778 -0.97270  0.42051  0.05410  0.81779
20Nov23_044225|  -0.94129  0.37341 -0.02587 -1.69395 -1.66843  0.14977 -1.29684]
20Nov23_044225| [ 0.18812 -1.04226 -0.19694 -0.90997  0.07427 -1.36961 -0.68391  1.29857
20Nov23_044225|  -1.58449 -1.19082 -1.19331 -0.28466  0.45438  0.59896 -0.09320]
20Nov23_044225| [ 0.46661 -1.82518  0.34643  0.42851  0.74486  1.16437 -1.33420  0.48093
20Nov23_044225|   0.66350 -1.58536  1.36313  1.64685  0.50624 -0.08332  0.16742]
20Nov23_044225| [ 0.83611 -1.02550  0.80906  0.82930  0.96028  0.21344  0.43399 -1.26536
20Nov23_044225|  -0.08786  0.56148  0.56968 -0.83275  0.47723  1.01280 -0.61349]
20Nov23_044225| [ 0.38265 -1.34334  0.19600 -0.79295  0.52286  0.28619  1.51312  0.85224
20Nov23_044225|   1.62111  1.09962  0.16420 -0.44606 -1.11225  1.26263  1.87372]
20Nov23_044225| [-0.57357 -0.55004 -1.15617  0.42990  0.23652 -0.13154 -1.45382  0.27475
20Nov23_044225|  -0.64777 -0.51002 -0.63579 -0.59520 -0.00340  0.31749  0.18432]]
20Nov23_044225|-- Bias --
20Nov23_044225|[ 1.38477 -0.37130 -0.13609 -0.85960 -0.92209 -0.27950  0.84767 -0.72498
20Nov23_044225| -0.02423  1.22888 -0.06124 -0.44945 -0.13271 -0.02930 -0.90463]
20Nov23_044225|Layer 1:
20Nov23_044225|-- Config --
20Nov23_044225|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 15], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_044225|-- Weights --
20Nov23_044225|[[ 0.67379 -1.05055]
20Nov23_044225| [-0.28290 -0.06835]
20Nov23_044225| [ 0.37387  0.47814]
20Nov23_044225| [ 0.58602 -0.61286]
20Nov23_044225| [-0.34764  0.50916]
20Nov23_044225| [-0.54241 -0.48178]
20Nov23_044225| [ 0.78853 -0.03736]
20Nov23_044225| [-0.61206 -0.05827]
20Nov23_044225| [-0.21855  1.26722]
20Nov23_044225| [-1.67530  1.48281]
20Nov23_044225| [-0.42903  0.74587]
20Nov23_044225| [ 0.09435 -1.16066]
20Nov23_044225| [-0.06102 -0.22933]
20Nov23_044225| [ 1.05118 -0.41105]
20Nov23_044225| [ 0.89464  0.71066]]
20Nov23_044225|-- Bias --
20Nov23_044225|[-0.89499  0.52392]
20Nov23_044225|Predicting the validation and test data with the Best final individual.
20Nov23_044230| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_044230|-----------  ------------------  --------------------  ----------
20Nov23_044230|Validation         42.43                  15            0.00258
20Nov23_044230|   Test            36.14                  15            0.00893
20Nov23_044230|-------------------------- Test #5 --------------------------
20Nov23_044230|Best final individual weights
20Nov23_044230|Individual:
20Nov23_044230|-- Constant hidden layers --
20Nov23_044230|False
20Nov23_044230|Layer 0:
20Nov23_044230|-- Config --
20Nov23_044230|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 15, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_044230|-- Weights --
20Nov23_044230|[[ 0.42691  0.29758  0.52422 -0.54807 -0.00317 -1.10737  0.66615 -0.46744
20Nov23_044230|   0.89578  0.22818 -0.07631 -0.76947 -0.46817 -0.21265 -0.85367]
20Nov23_044230| [-0.77699  0.41355 -1.18759  0.58503  0.11262 -0.77177 -0.87309  0.55877
20Nov23_044230|   0.49143  0.60359  0.78317 -2.01143 -0.18524  0.77837 -1.58646]
20Nov23_044230| [-0.05520  1.48797 -0.98303  0.44607  0.57229  0.01093  0.45399 -0.36869
20Nov23_044230|   1.25502 -2.04679  0.52420 -0.63251 -1.20841 -1.23667 -0.50506]
20Nov23_044230| [-0.15390 -0.12069  0.93121  0.62856 -0.47194  1.90773  0.12418 -0.02385
20Nov23_044230|   0.25845  0.67909 -0.74973 -1.14428 -0.54709 -1.03812  0.41810]
20Nov23_044230| [ 0.78184 -1.02634 -0.50414 -1.33713 -0.12806 -0.25092  1.03068 -1.53814
20Nov23_044230|   0.61719 -0.37364 -0.16927  0.25844 -1.59357  0.03242 -0.43857]
20Nov23_044230| [-1.51161  0.28379  0.11711  1.41276  1.94477 -1.13581 -0.16030 -0.98811
20Nov23_044230|  -0.74563  0.47408  1.31199  0.25822 -0.39431  0.99731  0.10765]
20Nov23_044230| [-0.06246 -0.55106 -0.66587 -0.81741 -0.90947 -0.55317  0.91670 -0.20333
20Nov23_044230|   0.16840 -0.45981  0.55694  1.11849  2.39357 -0.67350  0.20551]
20Nov23_044230| [ 0.47039 -1.74884  1.06361  0.87013 -1.27871 -0.23461 -0.85571  0.11193
20Nov23_044230|   1.28638  1.75207 -0.89037 -0.68407  0.35909 -0.54462 -0.10916]
20Nov23_044230| [-0.66100  1.52516  0.33780 -0.06402 -1.30311  2.21049  0.94191 -0.16126
20Nov23_044230|   0.77832 -0.93202  0.12018  0.28667  0.60154  0.67235  0.59619]
20Nov23_044230| [ 0.75099  1.36528 -1.73960 -1.50392  0.42261 -0.97005 -0.91943 -1.36861
20Nov23_044230|  -0.67430 -0.64244 -0.75113  1.74554  0.65154 -0.07884  0.24832]
20Nov23_044230| [ 1.53921 -0.26881 -0.59691  0.18529  0.48024 -0.98931 -1.54877  0.09832
20Nov23_044230|   1.16540  1.02141 -0.79718  1.33652  1.32572 -1.05063 -0.59539]
20Nov23_044230| [ 0.24418  0.35593 -0.10494 -1.30488  1.09288 -0.42662 -0.57142  0.49472
20Nov23_044230|   0.69921  0.62190  1.18692  0.10424 -0.45179  0.21910  0.01208]
20Nov23_044230| [ 0.67743 -0.19633  0.24381 -0.30061  0.08343 -0.33063 -0.09417 -0.29616
20Nov23_044230|  -0.06241 -1.05399  2.07564 -0.84708  0.83477 -0.41045  1.39502]
20Nov23_044230| [-0.03313 -0.77540  0.75142 -1.09279  1.86636 -0.79280 -0.54517 -0.28329
20Nov23_044230|   1.65999 -1.12225 -1.39221  0.11678 -1.17849 -0.62609 -0.37682]
20Nov23_044230| [ 0.05688 -0.19939 -0.40529 -0.51524 -0.26279  0.50723  0.33124  0.59534
20Nov23_044230|   0.83706  0.14251  0.82221 -0.63467  0.55955 -1.01568  0.21284]
20Nov23_044230| [ 0.01208  0.01410  1.11235 -0.49398  1.55853  0.43249  0.08756  0.00921
20Nov23_044230|  -0.71567 -0.38946 -0.90949 -0.83809 -0.05624  0.23786  0.05994]
20Nov23_044230| [-0.35205 -0.09450  2.24445  0.53880 -0.40180 -0.46765 -0.12446 -1.32593
20Nov23_044230|   1.41826 -0.76602  0.63376  1.18055 -0.53400  0.37624 -0.97579]
20Nov23_044230| [ 2.22050  0.05952 -1.19940  0.70861  1.41717 -0.26877 -0.94211 -1.40332
20Nov23_044230|   0.43003 -0.89869 -1.10584 -0.06625  0.31384 -0.10143  1.04961]
20Nov23_044230| [ 0.21289 -0.11012  1.49023  1.14376 -0.65338  0.26810 -0.85944  1.17660
20Nov23_044230|  -0.47870 -0.86877  0.44700  0.03584 -0.98074 -0.78054  0.03734]
20Nov23_044230| [ 0.28067  0.39235  1.41028 -0.15688 -0.54646  1.67606  0.42347  0.49702
20Nov23_044230|  -0.87937 -0.46845  1.00348 -0.53170 -1.12293 -1.01729  0.08005]
20Nov23_044230| [-1.14499  0.21662  0.15572  0.25399 -0.11350  0.09781 -0.60481 -0.96573
20Nov23_044230|   1.28182 -0.69592 -0.07493 -0.15830  1.71185 -1.62962  0.07644]
20Nov23_044230| [ 0.22980  0.61617 -0.58762 -1.53387  0.28371 -0.27785 -1.01772  0.18418
20Nov23_044230|   2.29950 -0.81522 -0.54903  0.50229  0.43645 -1.39068  1.50836]
20Nov23_044230| [ 1.26701  0.34500 -0.87987 -0.44065  1.23200 -1.45523  0.41462 -0.45891
20Nov23_044230|  -1.65629  1.36545 -0.16045  0.01440 -0.19117  1.01491 -1.56428]
20Nov23_044230| [-0.50801 -0.18680 -0.13795 -0.82892  0.04078  1.05055 -0.42182  0.28003
20Nov23_044230|  -0.17800 -0.94982 -1.60567 -0.74657 -0.37202 -0.77117  0.22728]
20Nov23_044230| [ 0.11223 -0.88960 -0.03771  0.68481 -1.13907 -1.64770 -2.08633  2.59999
20Nov23_044230|   0.70704 -1.10352 -0.73587  0.64618  0.18789 -0.56185 -0.00473]
20Nov23_044230| [-0.44394  1.09725  0.51635  0.38580 -1.13990  0.40442 -0.52209  0.10404
20Nov23_044230|  -0.15833  0.12255 -0.21853 -0.42496  1.00447  0.73146 -0.63667]
20Nov23_044230| [ 0.10066  1.40237  0.09464  0.72661 -1.80184 -0.06104 -0.34136 -0.51537
20Nov23_044230|  -1.66542 -0.55066 -2.56233 -0.02383 -0.84513 -1.61262 -0.51402]
20Nov23_044230| [-0.87960  0.23358 -0.52134  0.40047 -0.71106 -1.34728 -0.41823 -0.22333
20Nov23_044230|  -0.24686  1.65698 -1.30747 -0.69169 -0.66251  0.75459 -0.96660]
20Nov23_044230| [ 0.06230  1.20678 -0.23045 -0.84286 -0.22852  0.93298  0.14893  0.50809
20Nov23_044230|   0.14889 -0.72929 -0.24429  1.56028  1.22272  0.91747  0.36855]
20Nov23_044230| [-0.17377  1.14562  0.85539 -0.63699 -1.04190  0.12303 -0.72049 -0.08881
20Nov23_044230|  -0.90310  1.31653 -0.05204  0.40329 -0.48401 -0.36525 -0.46378]
20Nov23_044230| [ 0.09015 -0.62972 -0.73537  0.17011  0.27345 -0.55471  0.04517 -1.18609
20Nov23_044230|  -0.58628  0.49196 -0.58326  0.30330  0.51502  0.03433  0.04217]
20Nov23_044230| [ 0.86282 -0.84858 -1.43016 -0.52856  0.03054  0.44886  0.57046 -0.35864
20Nov23_044230|  -1.71832  0.24280 -0.89086 -0.78176  0.35162  0.30409 -0.02131]
20Nov23_044230| [ 1.05695  0.97767 -1.00230 -0.01291  0.04290 -0.09954  0.88877 -1.02809
20Nov23_044230|  -1.32144  0.07652  0.09972 -1.00606 -1.32542  0.05830 -0.38045]
20Nov23_044230| [ 0.43701 -1.48958 -0.15290 -0.28863  0.74501  0.03579 -1.09314 -0.86026
20Nov23_044230|   1.02886  1.16551 -1.01948 -1.43095 -1.82196 -0.89176 -0.81819]
20Nov23_044230| [-0.73966  0.22000  1.42394  0.53847 -2.33016 -0.57383  0.30702 -0.26322
20Nov23_044230|  -1.01442  0.05468 -0.23153 -0.06345  1.16376 -0.09296 -0.53408]
20Nov23_044230| [ 0.21706  1.28120  0.03908 -0.45157  0.48998  0.08854  0.00582  0.77533
20Nov23_044230|  -0.45924  0.03863 -0.73519 -0.00919 -1.16571  1.56297 -0.69370]
20Nov23_044230| [-2.08881 -0.97910  0.17069  0.79842  0.31541 -0.19526  0.45634  1.01009
20Nov23_044230|   0.59365 -0.01322  1.78356  1.44269  0.58775 -0.50228 -0.28648]
20Nov23_044230| [-1.12486  0.73663  0.56411  0.18444 -1.61639  1.08550  0.08219 -0.90988
20Nov23_044230|  -0.32404  0.81985  0.42006 -0.30815 -0.23312 -1.18708 -0.01110]
20Nov23_044230| [-0.30490 -1.30488 -1.53248 -0.79287  1.01787 -0.71421 -1.83065  0.46204
20Nov23_044230|  -0.31745  0.01163 -0.78217 -0.08380 -0.93485  0.93025 -1.11372]
20Nov23_044230| [-0.16328  1.13418 -0.55347 -0.46779  1.07552  0.66229 -0.21371  0.92252
20Nov23_044230|   0.55318  0.22002 -0.20203  0.71337  0.07093 -0.67508 -0.36308]
20Nov23_044230| [-0.14015 -0.56332  0.42102 -0.18024 -0.17774 -1.39429  0.65512  0.86385
20Nov23_044230|   0.74911  0.68266 -0.21078 -0.90494  0.19014 -0.64455  0.30027]
20Nov23_044230| [-0.74732 -0.00467  0.93348 -0.20600  0.55633 -0.56408 -0.45634 -0.20303
20Nov23_044230|  -0.13201 -1.51600  0.26075 -0.89582 -1.24197  0.63267  1.55172]
20Nov23_044230| [ 0.41456 -0.85489  0.02298  0.06353  0.81855  0.03156 -0.48615 -0.00658
20Nov23_044230|  -0.04895 -0.57287  0.20380  1.04986  0.97412 -0.47486  0.49494]
20Nov23_044230| [ 0.77080 -0.45784  0.11136  0.71105 -0.39395  0.40195 -0.43665  1.07323
20Nov23_044230|   0.43760  0.26785 -0.30587 -0.09075  0.40279  1.01923 -1.75405]
20Nov23_044230| [-0.88852  0.02533  1.17656  0.61764 -0.88512 -2.05323 -0.20657  0.56943
20Nov23_044230|  -0.79923 -0.05065  0.86607  1.99813 -0.99948 -0.10370  0.97637]
20Nov23_044230| [ 0.15692 -0.81947 -0.03219  0.05575  0.45531  1.62288 -0.76175 -0.80154
20Nov23_044230|  -1.50942 -0.89066 -0.37832  0.57865  2.24774  1.50483 -0.01312]
20Nov23_044230| [ 0.88566 -1.32158  1.07146  0.66710  0.27661  0.21144  0.50741  1.07543
20Nov23_044230|  -0.76611 -1.39540  0.28672  0.51751  0.72656 -0.65978  0.44566]
20Nov23_044230| [-1.03893  0.46076 -0.08662 -0.52243 -0.41836  0.85811 -0.86078  0.93975
20Nov23_044230|  -0.17006 -0.63327  0.74410  0.70958  1.39514  0.35044  0.87490]
20Nov23_044230| [ 1.54246 -0.70391 -0.91033  1.89604  0.46300 -0.13194 -0.43312  0.91185
20Nov23_044230|  -0.49534 -1.06771  0.38325 -1.29257 -0.73563 -1.04282 -0.39890]
20Nov23_044230| [-0.79484 -0.73094  1.55911 -0.27683  0.74301  0.65244 -1.70505  0.26757
20Nov23_044230|  -1.24152 -0.51986 -0.91341 -0.27940 -0.78858 -0.03302  0.36902]
20Nov23_044230| [-0.52894 -0.45939  0.71874 -1.10270 -0.31797 -1.23160 -0.28378  0.28717
20Nov23_044230|  -0.95275  0.83782 -0.51558 -0.40856 -0.70669 -0.31466  0.04528]
20Nov23_044230| [-0.81167 -0.21989  0.25817 -0.60778 -0.97270  0.42051  0.05410  0.81779
20Nov23_044230|  -0.94129  0.37341 -0.02587 -1.69395 -1.66843  0.14977 -1.29684]
20Nov23_044230| [ 0.18812 -1.04226 -0.19694 -0.90997  0.07427 -1.36961 -0.68391  1.29857
20Nov23_044230|  -1.58449 -1.19082 -1.19331 -0.28466  0.45438  0.59896 -0.09320]
20Nov23_044230| [ 0.46661 -1.82518  0.34643  0.42851  0.74486  1.16437 -1.33420  0.48093
20Nov23_044230|   0.66350 -1.58536  1.36313  1.64685  0.50624 -0.08332  0.16742]
20Nov23_044230| [ 0.83611 -1.02550  0.80906  0.82930  0.96028  0.21344  0.43399 -1.26536
20Nov23_044230|  -0.08786  0.56148  0.56968 -0.83275  0.47723  1.01280 -0.61349]
20Nov23_044230| [ 0.38265 -1.34334  0.19600 -0.79295  0.52286  0.28619  1.51312  0.85224
20Nov23_044230|   1.62111  1.09962  0.16420 -0.44606 -1.11225  1.26263  1.87372]
20Nov23_044230| [-0.57357 -0.55004 -1.15617  0.42990  0.23652 -0.13154 -1.45382  0.27475
20Nov23_044230|  -0.64777 -0.51002 -0.63579 -0.59520 -0.00340  0.31749  0.18432]]
20Nov23_044230|-- Bias --
20Nov23_044230|[ 1.38477 -0.37130 -0.13609 -0.85960 -0.92209 -0.27950  0.84767 -0.72498
20Nov23_044230| -0.02423  1.22888 -0.06124 -0.44945 -0.13271 -0.02930 -0.90463]
20Nov23_044230|Layer 1:
20Nov23_044230|-- Config --
20Nov23_044230|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 15], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_044230|-- Weights --
20Nov23_044230|[[ 0.67379 -1.05055]
20Nov23_044230| [-0.28290 -0.06835]
20Nov23_044230| [ 0.37387  0.47814]
20Nov23_044230| [ 0.58602 -0.61286]
20Nov23_044230| [-0.34764  0.50916]
20Nov23_044230| [-0.54241 -0.48178]
20Nov23_044230| [ 0.78853 -0.03736]
20Nov23_044230| [-0.61206 -0.05827]
20Nov23_044230| [-0.21855  1.26722]
20Nov23_044230| [-1.67530  1.48281]
20Nov23_044230| [-0.42903  0.74587]
20Nov23_044230| [ 0.09435 -1.16066]
20Nov23_044230| [-0.06102 -0.22933]
20Nov23_044230| [ 1.05118 -0.41105]
20Nov23_044230| [ 0.89464  0.71066]]
20Nov23_044230|-- Bias --
20Nov23_044230|[-0.89499  0.52392]
20Nov23_044230|Predicting the validation and test data with the Best final individual.
20Nov23_044236| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_044236|-----------  ------------------  --------------------  ----------
20Nov23_044236|Validation         42.35                  15            0.00515
20Nov23_044236|   Test            34.75                  15            0.09576
20Nov23_044236|-------------------------- Test #6 --------------------------
20Nov23_044236|Best final individual weights
20Nov23_044236|Individual:
20Nov23_044236|-- Constant hidden layers --
20Nov23_044236|False
20Nov23_044236|Layer 0:
20Nov23_044236|-- Config --
20Nov23_044236|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 15, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_044236|-- Weights --
20Nov23_044236|[[ 0.42691  0.29758  0.52422 -0.54807 -0.00317 -1.10737  0.66615 -0.46744
20Nov23_044236|   0.89578  0.22818 -0.07631 -0.76947 -0.46817 -0.21265 -0.85367]
20Nov23_044236| [-0.77699  0.41355 -1.18759  0.58503  0.11262 -0.77177 -0.87309  0.55877
20Nov23_044236|   0.49143  0.60359  0.78317 -2.01143 -0.18524  0.77837 -1.58646]
20Nov23_044236| [-0.05520  1.48797 -0.98303  0.44607  0.57229  0.01093  0.45399 -0.36869
20Nov23_044236|   1.25502 -2.04679  0.52420 -0.63251 -1.20841 -1.23667 -0.50506]
20Nov23_044236| [-0.15390 -0.12069  0.93121  0.62856 -0.47194  1.90773  0.12418 -0.02385
20Nov23_044236|   0.25845  0.67909 -0.74973 -1.14428 -0.54709 -1.03812  0.41810]
20Nov23_044236| [ 0.78184 -1.02634 -0.50414 -1.33713 -0.12806 -0.25092  1.03068 -1.53814
20Nov23_044236|   0.61719 -0.37364 -0.16927  0.25844 -1.59357  0.03242 -0.43857]
20Nov23_044236| [-1.51161  0.28379  0.11711  1.41276  1.94477 -1.13581 -0.16030 -0.98811
20Nov23_044236|  -0.74563  0.47408  1.31199  0.25822 -0.39431  0.99731  0.10765]
20Nov23_044236| [-0.06246 -0.55106 -0.66587 -0.81741 -0.90947 -0.55317  0.91670 -0.20333
20Nov23_044236|   0.16840 -0.45981  0.55694  1.11849  2.39357 -0.67350  0.20551]
20Nov23_044236| [ 0.47039 -1.74884  1.06361  0.87013 -1.27871 -0.23461 -0.85571  0.11193
20Nov23_044236|   1.28638  1.75207 -0.89037 -0.68407  0.35909 -0.54462 -0.10916]
20Nov23_044236| [-0.66100  1.52516  0.33780 -0.06402 -1.30311  2.21049  0.94191 -0.16126
20Nov23_044236|   0.77832 -0.93202  0.12018  0.28667  0.60154  0.67235  0.59619]
20Nov23_044236| [ 0.75099  1.36528 -1.73960 -1.50392  0.42261 -0.97005 -0.91943 -1.36861
20Nov23_044236|  -0.67430 -0.64244 -0.75113  1.74554  0.65154 -0.07884  0.24832]
20Nov23_044236| [ 1.53921 -0.26881 -0.59691  0.18529  0.48024 -0.98931 -1.54877  0.09832
20Nov23_044236|   1.16540  1.02141 -0.79718  1.33652  1.32572 -1.05063 -0.59539]
20Nov23_044236| [ 0.24418  0.35593 -0.10494 -1.30488  1.09288 -0.42662 -0.57142  0.49472
20Nov23_044236|   0.69921  0.62190  1.18692  0.10424 -0.45179  0.21910  0.01208]
20Nov23_044236| [ 0.67743 -0.19633  0.24381 -0.30061  0.08343 -0.33063 -0.09417 -0.29616
20Nov23_044236|  -0.06241 -1.05399  2.07564 -0.84708  0.83477 -0.41045  1.39502]
20Nov23_044236| [-0.03313 -0.77540  0.75142 -1.09279  1.86636 -0.79280 -0.54517 -0.28329
20Nov23_044236|   1.65999 -1.12225 -1.39221  0.11678 -1.17849 -0.62609 -0.37682]
20Nov23_044236| [ 0.05688 -0.19939 -0.40529 -0.51524 -0.26279  0.50723  0.33124  0.59534
20Nov23_044236|   0.83706  0.14251  0.82221 -0.63467  0.55955 -1.01568  0.21284]
20Nov23_044236| [ 0.01208  0.01410  1.11235 -0.49398  1.55853  0.43249  0.08756  0.00921
20Nov23_044236|  -0.71567 -0.38946 -0.90949 -0.83809 -0.05624  0.23786  0.05994]
20Nov23_044236| [-0.35205 -0.09450  2.24445  0.53880 -0.40180 -0.46765 -0.12446 -1.32593
20Nov23_044236|   1.41826 -0.76602  0.63376  1.18055 -0.53400  0.37624 -0.97579]
20Nov23_044236| [ 2.22050  0.05952 -1.19940  0.70861  1.41717 -0.26877 -0.94211 -1.40332
20Nov23_044236|   0.43003 -0.89869 -1.10584 -0.06625  0.31384 -0.10143  1.04961]
20Nov23_044236| [ 0.21289 -0.11012  1.49023  1.14376 -0.65338  0.26810 -0.85944  1.17660
20Nov23_044236|  -0.47870 -0.86877  0.44700  0.03584 -0.98074 -0.78054  0.03734]
20Nov23_044236| [ 0.28067  0.39235  1.41028 -0.15688 -0.54646  1.67606  0.42347  0.49702
20Nov23_044236|  -0.87937 -0.46845  1.00348 -0.53170 -1.12293 -1.01729  0.08005]
20Nov23_044236| [-1.14499  0.21662  0.15572  0.25399 -0.11350  0.09781 -0.60481 -0.96573
20Nov23_044236|   1.28182 -0.69592 -0.07493 -0.15830  1.71185 -1.62962  0.07644]
20Nov23_044236| [ 0.22980  0.61617 -0.58762 -1.53387  0.28371 -0.27785 -1.01772  0.18418
20Nov23_044236|   2.29950 -0.81522 -0.54903  0.50229  0.43645 -1.39068  1.50836]
20Nov23_044236| [ 1.26701  0.34500 -0.87987 -0.44065  1.23200 -1.45523  0.41462 -0.45891
20Nov23_044236|  -1.65629  1.36545 -0.16045  0.01440 -0.19117  1.01491 -1.56428]
20Nov23_044236| [-0.50801 -0.18680 -0.13795 -0.82892  0.04078  1.05055 -0.42182  0.28003
20Nov23_044236|  -0.17800 -0.94982 -1.60567 -0.74657 -0.37202 -0.77117  0.22728]
20Nov23_044236| [ 0.11223 -0.88960 -0.03771  0.68481 -1.13907 -1.64770 -2.08633  2.59999
20Nov23_044236|   0.70704 -1.10352 -0.73587  0.64618  0.18789 -0.56185 -0.00473]
20Nov23_044236| [-0.44394  1.09725  0.51635  0.38580 -1.13990  0.40442 -0.52209  0.10404
20Nov23_044236|  -0.15833  0.12255 -0.21853 -0.42496  1.00447  0.73146 -0.63667]
20Nov23_044236| [ 0.10066  1.40237  0.09464  0.72661 -1.80184 -0.06104 -0.34136 -0.51537
20Nov23_044236|  -1.66542 -0.55066 -2.56233 -0.02383 -0.84513 -1.61262 -0.51402]
20Nov23_044236| [-0.87960  0.23358 -0.52134  0.40047 -0.71106 -1.34728 -0.41823 -0.22333
20Nov23_044236|  -0.24686  1.65698 -1.30747 -0.69169 -0.66251  0.75459 -0.96660]
20Nov23_044236| [ 0.06230  1.20678 -0.23045 -0.84286 -0.22852  0.93298  0.14893  0.50809
20Nov23_044236|   0.14889 -0.72929 -0.24429  1.56028  1.22272  0.91747  0.36855]
20Nov23_044236| [-0.17377  1.14562  0.85539 -0.63699 -1.04190  0.12303 -0.72049 -0.08881
20Nov23_044236|  -0.90310  1.31653 -0.05204  0.40329 -0.48401 -0.36525 -0.46378]
20Nov23_044236| [ 0.09015 -0.62972 -0.73537  0.17011  0.27345 -0.55471  0.04517 -1.18609
20Nov23_044236|  -0.58628  0.49196 -0.58326  0.30330  0.51502  0.03433  0.04217]
20Nov23_044236| [ 0.86282 -0.84858 -1.43016 -0.52856  0.03054  0.44886  0.57046 -0.35864
20Nov23_044236|  -1.71832  0.24280 -0.89086 -0.78176  0.35162  0.30409 -0.02131]
20Nov23_044236| [ 1.05695  0.97767 -1.00230 -0.01291  0.04290 -0.09954  0.88877 -1.02809
20Nov23_044236|  -1.32144  0.07652  0.09972 -1.00606 -1.32542  0.05830 -0.38045]
20Nov23_044236| [ 0.43701 -1.48958 -0.15290 -0.28863  0.74501  0.03579 -1.09314 -0.86026
20Nov23_044236|   1.02886  1.16551 -1.01948 -1.43095 -1.82196 -0.89176 -0.81819]
20Nov23_044236| [-0.73966  0.22000  1.42394  0.53847 -2.33016 -0.57383  0.30702 -0.26322
20Nov23_044236|  -1.01442  0.05468 -0.23153 -0.06345  1.16376 -0.09296 -0.53408]
20Nov23_044236| [ 0.21706  1.28120  0.03908 -0.45157  0.48998  0.08854  0.00582  0.77533
20Nov23_044236|  -0.45924  0.03863 -0.73519 -0.00919 -1.16571  1.56297 -0.69370]
20Nov23_044236| [-2.08881 -0.97910  0.17069  0.79842  0.31541 -0.19526  0.45634  1.01009
20Nov23_044236|   0.59365 -0.01322  1.78356  1.44269  0.58775 -0.50228 -0.28648]
20Nov23_044236| [-1.12486  0.73663  0.56411  0.18444 -1.61639  1.08550  0.08219 -0.90988
20Nov23_044236|  -0.32404  0.81985  0.42006 -0.30815 -0.23312 -1.18708 -0.01110]
20Nov23_044236| [-0.30490 -1.30488 -1.53248 -0.79287  1.01787 -0.71421 -1.83065  0.46204
20Nov23_044236|  -0.31745  0.01163 -0.78217 -0.08380 -0.93485  0.93025 -1.11372]
20Nov23_044236| [-0.16328  1.13418 -0.55347 -0.46779  1.07552  0.66229 -0.21371  0.92252
20Nov23_044236|   0.55318  0.22002 -0.20203  0.71337  0.07093 -0.67508 -0.36308]
20Nov23_044236| [-0.14015 -0.56332  0.42102 -0.18024 -0.17774 -1.39429  0.65512  0.86385
20Nov23_044236|   0.74911  0.68266 -0.21078 -0.90494  0.19014 -0.64455  0.30027]
20Nov23_044236| [-0.74732 -0.00467  0.93348 -0.20600  0.55633 -0.56408 -0.45634 -0.20303
20Nov23_044236|  -0.13201 -1.51600  0.26075 -0.89582 -1.24197  0.63267  1.55172]
20Nov23_044236| [ 0.41456 -0.85489  0.02298  0.06353  0.81855  0.03156 -0.48615 -0.00658
20Nov23_044236|  -0.04895 -0.57287  0.20380  1.04986  0.97412 -0.47486  0.49494]
20Nov23_044236| [ 0.77080 -0.45784  0.11136  0.71105 -0.39395  0.40195 -0.43665  1.07323
20Nov23_044236|   0.43760  0.26785 -0.30587 -0.09075  0.40279  1.01923 -1.75405]
20Nov23_044236| [-0.88852  0.02533  1.17656  0.61764 -0.88512 -2.05323 -0.20657  0.56943
20Nov23_044236|  -0.79923 -0.05065  0.86607  1.99813 -0.99948 -0.10370  0.97637]
20Nov23_044236| [ 0.15692 -0.81947 -0.03219  0.05575  0.45531  1.62288 -0.76175 -0.80154
20Nov23_044236|  -1.50942 -0.89066 -0.37832  0.57865  2.24774  1.50483 -0.01312]
20Nov23_044236| [ 0.88566 -1.32158  1.07146  0.66710  0.27661  0.21144  0.50741  1.07543
20Nov23_044236|  -0.76611 -1.39540  0.28672  0.51751  0.72656 -0.65978  0.44566]
20Nov23_044236| [-1.03893  0.46076 -0.08662 -0.52243 -0.41836  0.85811 -0.86078  0.93975
20Nov23_044236|  -0.17006 -0.63327  0.74410  0.70958  1.39514  0.35044  0.87490]
20Nov23_044236| [ 1.54246 -0.70391 -0.91033  1.89604  0.46300 -0.13194 -0.43312  0.91185
20Nov23_044236|  -0.49534 -1.06771  0.38325 -1.29257 -0.73563 -1.04282 -0.39890]
20Nov23_044236| [-0.79484 -0.73094  1.55911 -0.27683  0.74301  0.65244 -1.70505  0.26757
20Nov23_044236|  -1.24152 -0.51986 -0.91341 -0.27940 -0.78858 -0.03302  0.36902]
20Nov23_044236| [-0.52894 -0.45939  0.71874 -1.10270 -0.31797 -1.23160 -0.28378  0.28717
20Nov23_044236|  -0.95275  0.83782 -0.51558 -0.40856 -0.70669 -0.31466  0.04528]
20Nov23_044236| [-0.81167 -0.21989  0.25817 -0.60778 -0.97270  0.42051  0.05410  0.81779
20Nov23_044236|  -0.94129  0.37341 -0.02587 -1.69395 -1.66843  0.14977 -1.29684]
20Nov23_044236| [ 0.18812 -1.04226 -0.19694 -0.90997  0.07427 -1.36961 -0.68391  1.29857
20Nov23_044236|  -1.58449 -1.19082 -1.19331 -0.28466  0.45438  0.59896 -0.09320]
20Nov23_044236| [ 0.46661 -1.82518  0.34643  0.42851  0.74486  1.16437 -1.33420  0.48093
20Nov23_044236|   0.66350 -1.58536  1.36313  1.64685  0.50624 -0.08332  0.16742]
20Nov23_044236| [ 0.83611 -1.02550  0.80906  0.82930  0.96028  0.21344  0.43399 -1.26536
20Nov23_044236|  -0.08786  0.56148  0.56968 -0.83275  0.47723  1.01280 -0.61349]
20Nov23_044236| [ 0.38265 -1.34334  0.19600 -0.79295  0.52286  0.28619  1.51312  0.85224
20Nov23_044236|   1.62111  1.09962  0.16420 -0.44606 -1.11225  1.26263  1.87372]
20Nov23_044236| [-0.57357 -0.55004 -1.15617  0.42990  0.23652 -0.13154 -1.45382  0.27475
20Nov23_044236|  -0.64777 -0.51002 -0.63579 -0.59520 -0.00340  0.31749  0.18432]]
20Nov23_044236|-- Bias --
20Nov23_044236|[ 1.38477 -0.37130 -0.13609 -0.85960 -0.92209 -0.27950  0.84767 -0.72498
20Nov23_044236| -0.02423  1.22888 -0.06124 -0.44945 -0.13271 -0.02930 -0.90463]
20Nov23_044236|Layer 1:
20Nov23_044236|-- Config --
20Nov23_044236|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 15], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_044236|-- Weights --
20Nov23_044236|[[ 0.67379 -1.05055]
20Nov23_044236| [-0.28290 -0.06835]
20Nov23_044236| [ 0.37387  0.47814]
20Nov23_044236| [ 0.58602 -0.61286]
20Nov23_044236| [-0.34764  0.50916]
20Nov23_044236| [-0.54241 -0.48178]
20Nov23_044236| [ 0.78853 -0.03736]
20Nov23_044236| [-0.61206 -0.05827]
20Nov23_044236| [-0.21855  1.26722]
20Nov23_044236| [-1.67530  1.48281]
20Nov23_044236| [-0.42903  0.74587]
20Nov23_044236| [ 0.09435 -1.16066]
20Nov23_044236| [-0.06102 -0.22933]
20Nov23_044236| [ 1.05118 -0.41105]
20Nov23_044236| [ 0.89464  0.71066]]
20Nov23_044236|-- Bias --
20Nov23_044236|[-0.89499  0.52392]
20Nov23_044236|Predicting the validation and test data with the Best final individual.
20Nov23_044242| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_044242|-----------  ------------------  --------------------  ----------
20Nov23_044242|Validation         41.91                  15            0.00259
20Nov23_044242|   Test            35.01                  15            0.07876
20Nov23_044242|-------------------------- Test #7 --------------------------
20Nov23_044242|Best final individual weights
20Nov23_044242|Individual:
20Nov23_044242|-- Constant hidden layers --
20Nov23_044242|False
20Nov23_044242|Layer 0:
20Nov23_044242|-- Config --
20Nov23_044242|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 15, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_044242|-- Weights --
20Nov23_044242|[[ 0.42691  0.29758  0.52422 -0.54807 -0.00317 -1.10737  0.66615 -0.46744
20Nov23_044242|   0.89578  0.22818 -0.07631 -0.76947 -0.46817 -0.21265 -0.85367]
20Nov23_044242| [-0.77699  0.41355 -1.18759  0.58503  0.11262 -0.77177 -0.87309  0.55877
20Nov23_044242|   0.49143  0.60359  0.78317 -2.01143 -0.18524  0.77837 -1.58646]
20Nov23_044242| [-0.05520  1.48797 -0.98303  0.44607  0.57229  0.01093  0.45399 -0.36869
20Nov23_044242|   1.25502 -2.04679  0.52420 -0.63251 -1.20841 -1.23667 -0.50506]
20Nov23_044242| [-0.15390 -0.12069  0.93121  0.62856 -0.47194  1.90773  0.12418 -0.02385
20Nov23_044242|   0.25845  0.67909 -0.74973 -1.14428 -0.54709 -1.03812  0.41810]
20Nov23_044242| [ 0.78184 -1.02634 -0.50414 -1.33713 -0.12806 -0.25092  1.03068 -1.53814
20Nov23_044242|   0.61719 -0.37364 -0.16927  0.25844 -1.59357  0.03242 -0.43857]
20Nov23_044242| [-1.51161  0.28379  0.11711  1.41276  1.94477 -1.13581 -0.16030 -0.98811
20Nov23_044242|  -0.74563  0.47408  1.31199  0.25822 -0.39431  0.99731  0.10765]
20Nov23_044242| [-0.06246 -0.55106 -0.66587 -0.81741 -0.90947 -0.55317  0.91670 -0.20333
20Nov23_044242|   0.16840 -0.45981  0.55694  1.11849  2.39357 -0.67350  0.20551]
20Nov23_044242| [ 0.47039 -1.74884  1.06361  0.87013 -1.27871 -0.23461 -0.85571  0.11193
20Nov23_044242|   1.28638  1.75207 -0.89037 -0.68407  0.35909 -0.54462 -0.10916]
20Nov23_044242| [-0.66100  1.52516  0.33780 -0.06402 -1.30311  2.21049  0.94191 -0.16126
20Nov23_044242|   0.77832 -0.93202  0.12018  0.28667  0.60154  0.67235  0.59619]
20Nov23_044242| [ 0.75099  1.36528 -1.73960 -1.50392  0.42261 -0.97005 -0.91943 -1.36861
20Nov23_044242|  -0.67430 -0.64244 -0.75113  1.74554  0.65154 -0.07884  0.24832]
20Nov23_044242| [ 1.53921 -0.26881 -0.59691  0.18529  0.48024 -0.98931 -1.54877  0.09832
20Nov23_044242|   1.16540  1.02141 -0.79718  1.33652  1.32572 -1.05063 -0.59539]
20Nov23_044242| [ 0.24418  0.35593 -0.10494 -1.30488  1.09288 -0.42662 -0.57142  0.49472
20Nov23_044242|   0.69921  0.62190  1.18692  0.10424 -0.45179  0.21910  0.01208]
20Nov23_044242| [ 0.67743 -0.19633  0.24381 -0.30061  0.08343 -0.33063 -0.09417 -0.29616
20Nov23_044242|  -0.06241 -1.05399  2.07564 -0.84708  0.83477 -0.41045  1.39502]
20Nov23_044242| [-0.03313 -0.77540  0.75142 -1.09279  1.86636 -0.79280 -0.54517 -0.28329
20Nov23_044242|   1.65999 -1.12225 -1.39221  0.11678 -1.17849 -0.62609 -0.37682]
20Nov23_044242| [ 0.05688 -0.19939 -0.40529 -0.51524 -0.26279  0.50723  0.33124  0.59534
20Nov23_044242|   0.83706  0.14251  0.82221 -0.63467  0.55955 -1.01568  0.21284]
20Nov23_044242| [ 0.01208  0.01410  1.11235 -0.49398  1.55853  0.43249  0.08756  0.00921
20Nov23_044242|  -0.71567 -0.38946 -0.90949 -0.83809 -0.05624  0.23786  0.05994]
20Nov23_044242| [-0.35205 -0.09450  2.24445  0.53880 -0.40180 -0.46765 -0.12446 -1.32593
20Nov23_044242|   1.41826 -0.76602  0.63376  1.18055 -0.53400  0.37624 -0.97579]
20Nov23_044242| [ 2.22050  0.05952 -1.19940  0.70861  1.41717 -0.26877 -0.94211 -1.40332
20Nov23_044242|   0.43003 -0.89869 -1.10584 -0.06625  0.31384 -0.10143  1.04961]
20Nov23_044242| [ 0.21289 -0.11012  1.49023  1.14376 -0.65338  0.26810 -0.85944  1.17660
20Nov23_044242|  -0.47870 -0.86877  0.44700  0.03584 -0.98074 -0.78054  0.03734]
20Nov23_044242| [ 0.28067  0.39235  1.41028 -0.15688 -0.54646  1.67606  0.42347  0.49702
20Nov23_044242|  -0.87937 -0.46845  1.00348 -0.53170 -1.12293 -1.01729  0.08005]
20Nov23_044242| [-1.14499  0.21662  0.15572  0.25399 -0.11350  0.09781 -0.60481 -0.96573
20Nov23_044242|   1.28182 -0.69592 -0.07493 -0.15830  1.71185 -1.62962  0.07644]
20Nov23_044242| [ 0.22980  0.61617 -0.58762 -1.53387  0.28371 -0.27785 -1.01772  0.18418
20Nov23_044242|   2.29950 -0.81522 -0.54903  0.50229  0.43645 -1.39068  1.50836]
20Nov23_044242| [ 1.26701  0.34500 -0.87987 -0.44065  1.23200 -1.45523  0.41462 -0.45891
20Nov23_044242|  -1.65629  1.36545 -0.16045  0.01440 -0.19117  1.01491 -1.56428]
20Nov23_044242| [-0.50801 -0.18680 -0.13795 -0.82892  0.04078  1.05055 -0.42182  0.28003
20Nov23_044242|  -0.17800 -0.94982 -1.60567 -0.74657 -0.37202 -0.77117  0.22728]
20Nov23_044242| [ 0.11223 -0.88960 -0.03771  0.68481 -1.13907 -1.64770 -2.08633  2.59999
20Nov23_044242|   0.70704 -1.10352 -0.73587  0.64618  0.18789 -0.56185 -0.00473]
20Nov23_044242| [-0.44394  1.09725  0.51635  0.38580 -1.13990  0.40442 -0.52209  0.10404
20Nov23_044242|  -0.15833  0.12255 -0.21853 -0.42496  1.00447  0.73146 -0.63667]
20Nov23_044242| [ 0.10066  1.40237  0.09464  0.72661 -1.80184 -0.06104 -0.34136 -0.51537
20Nov23_044242|  -1.66542 -0.55066 -2.56233 -0.02383 -0.84513 -1.61262 -0.51402]
20Nov23_044242| [-0.87960  0.23358 -0.52134  0.40047 -0.71106 -1.34728 -0.41823 -0.22333
20Nov23_044242|  -0.24686  1.65698 -1.30747 -0.69169 -0.66251  0.75459 -0.96660]
20Nov23_044242| [ 0.06230  1.20678 -0.23045 -0.84286 -0.22852  0.93298  0.14893  0.50809
20Nov23_044242|   0.14889 -0.72929 -0.24429  1.56028  1.22272  0.91747  0.36855]
20Nov23_044242| [-0.17377  1.14562  0.85539 -0.63699 -1.04190  0.12303 -0.72049 -0.08881
20Nov23_044242|  -0.90310  1.31653 -0.05204  0.40329 -0.48401 -0.36525 -0.46378]
20Nov23_044242| [ 0.09015 -0.62972 -0.73537  0.17011  0.27345 -0.55471  0.04517 -1.18609
20Nov23_044242|  -0.58628  0.49196 -0.58326  0.30330  0.51502  0.03433  0.04217]
20Nov23_044242| [ 0.86282 -0.84858 -1.43016 -0.52856  0.03054  0.44886  0.57046 -0.35864
20Nov23_044242|  -1.71832  0.24280 -0.89086 -0.78176  0.35162  0.30409 -0.02131]
20Nov23_044242| [ 1.05695  0.97767 -1.00230 -0.01291  0.04290 -0.09954  0.88877 -1.02809
20Nov23_044242|  -1.32144  0.07652  0.09972 -1.00606 -1.32542  0.05830 -0.38045]
20Nov23_044242| [ 0.43701 -1.48958 -0.15290 -0.28863  0.74501  0.03579 -1.09314 -0.86026
20Nov23_044242|   1.02886  1.16551 -1.01948 -1.43095 -1.82196 -0.89176 -0.81819]
20Nov23_044242| [-0.73966  0.22000  1.42394  0.53847 -2.33016 -0.57383  0.30702 -0.26322
20Nov23_044242|  -1.01442  0.05468 -0.23153 -0.06345  1.16376 -0.09296 -0.53408]
20Nov23_044242| [ 0.21706  1.28120  0.03908 -0.45157  0.48998  0.08854  0.00582  0.77533
20Nov23_044242|  -0.45924  0.03863 -0.73519 -0.00919 -1.16571  1.56297 -0.69370]
20Nov23_044242| [-2.08881 -0.97910  0.17069  0.79842  0.31541 -0.19526  0.45634  1.01009
20Nov23_044242|   0.59365 -0.01322  1.78356  1.44269  0.58775 -0.50228 -0.28648]
20Nov23_044242| [-1.12486  0.73663  0.56411  0.18444 -1.61639  1.08550  0.08219 -0.90988
20Nov23_044242|  -0.32404  0.81985  0.42006 -0.30815 -0.23312 -1.18708 -0.01110]
20Nov23_044242| [-0.30490 -1.30488 -1.53248 -0.79287  1.01787 -0.71421 -1.83065  0.46204
20Nov23_044242|  -0.31745  0.01163 -0.78217 -0.08380 -0.93485  0.93025 -1.11372]
20Nov23_044242| [-0.16328  1.13418 -0.55347 -0.46779  1.07552  0.66229 -0.21371  0.92252
20Nov23_044242|   0.55318  0.22002 -0.20203  0.71337  0.07093 -0.67508 -0.36308]
20Nov23_044242| [-0.14015 -0.56332  0.42102 -0.18024 -0.17774 -1.39429  0.65512  0.86385
20Nov23_044242|   0.74911  0.68266 -0.21078 -0.90494  0.19014 -0.64455  0.30027]
20Nov23_044242| [-0.74732 -0.00467  0.93348 -0.20600  0.55633 -0.56408 -0.45634 -0.20303
20Nov23_044242|  -0.13201 -1.51600  0.26075 -0.89582 -1.24197  0.63267  1.55172]
20Nov23_044242| [ 0.41456 -0.85489  0.02298  0.06353  0.81855  0.03156 -0.48615 -0.00658
20Nov23_044242|  -0.04895 -0.57287  0.20380  1.04986  0.97412 -0.47486  0.49494]
20Nov23_044242| [ 0.77080 -0.45784  0.11136  0.71105 -0.39395  0.40195 -0.43665  1.07323
20Nov23_044242|   0.43760  0.26785 -0.30587 -0.09075  0.40279  1.01923 -1.75405]
20Nov23_044242| [-0.88852  0.02533  1.17656  0.61764 -0.88512 -2.05323 -0.20657  0.56943
20Nov23_044242|  -0.79923 -0.05065  0.86607  1.99813 -0.99948 -0.10370  0.97637]
20Nov23_044242| [ 0.15692 -0.81947 -0.03219  0.05575  0.45531  1.62288 -0.76175 -0.80154
20Nov23_044242|  -1.50942 -0.89066 -0.37832  0.57865  2.24774  1.50483 -0.01312]
20Nov23_044242| [ 0.88566 -1.32158  1.07146  0.66710  0.27661  0.21144  0.50741  1.07543
20Nov23_044242|  -0.76611 -1.39540  0.28672  0.51751  0.72656 -0.65978  0.44566]
20Nov23_044242| [-1.03893  0.46076 -0.08662 -0.52243 -0.41836  0.85811 -0.86078  0.93975
20Nov23_044242|  -0.17006 -0.63327  0.74410  0.70958  1.39514  0.35044  0.87490]
20Nov23_044242| [ 1.54246 -0.70391 -0.91033  1.89604  0.46300 -0.13194 -0.43312  0.91185
20Nov23_044242|  -0.49534 -1.06771  0.38325 -1.29257 -0.73563 -1.04282 -0.39890]
20Nov23_044242| [-0.79484 -0.73094  1.55911 -0.27683  0.74301  0.65244 -1.70505  0.26757
20Nov23_044242|  -1.24152 -0.51986 -0.91341 -0.27940 -0.78858 -0.03302  0.36902]
20Nov23_044242| [-0.52894 -0.45939  0.71874 -1.10270 -0.31797 -1.23160 -0.28378  0.28717
20Nov23_044242|  -0.95275  0.83782 -0.51558 -0.40856 -0.70669 -0.31466  0.04528]
20Nov23_044242| [-0.81167 -0.21989  0.25817 -0.60778 -0.97270  0.42051  0.05410  0.81779
20Nov23_044242|  -0.94129  0.37341 -0.02587 -1.69395 -1.66843  0.14977 -1.29684]
20Nov23_044242| [ 0.18812 -1.04226 -0.19694 -0.90997  0.07427 -1.36961 -0.68391  1.29857
20Nov23_044242|  -1.58449 -1.19082 -1.19331 -0.28466  0.45438  0.59896 -0.09320]
20Nov23_044242| [ 0.46661 -1.82518  0.34643  0.42851  0.74486  1.16437 -1.33420  0.48093
20Nov23_044242|   0.66350 -1.58536  1.36313  1.64685  0.50624 -0.08332  0.16742]
20Nov23_044242| [ 0.83611 -1.02550  0.80906  0.82930  0.96028  0.21344  0.43399 -1.26536
20Nov23_044242|  -0.08786  0.56148  0.56968 -0.83275  0.47723  1.01280 -0.61349]
20Nov23_044242| [ 0.38265 -1.34334  0.19600 -0.79295  0.52286  0.28619  1.51312  0.85224
20Nov23_044242|   1.62111  1.09962  0.16420 -0.44606 -1.11225  1.26263  1.87372]
20Nov23_044242| [-0.57357 -0.55004 -1.15617  0.42990  0.23652 -0.13154 -1.45382  0.27475
20Nov23_044242|  -0.64777 -0.51002 -0.63579 -0.59520 -0.00340  0.31749  0.18432]]
20Nov23_044242|-- Bias --
20Nov23_044242|[ 1.38477 -0.37130 -0.13609 -0.85960 -0.92209 -0.27950  0.84767 -0.72498
20Nov23_044242| -0.02423  1.22888 -0.06124 -0.44945 -0.13271 -0.02930 -0.90463]
20Nov23_044242|Layer 1:
20Nov23_044242|-- Config --
20Nov23_044242|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 15], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_044242|-- Weights --
20Nov23_044242|[[ 0.67379 -1.05055]
20Nov23_044242| [-0.28290 -0.06835]
20Nov23_044242| [ 0.37387  0.47814]
20Nov23_044242| [ 0.58602 -0.61286]
20Nov23_044242| [-0.34764  0.50916]
20Nov23_044242| [-0.54241 -0.48178]
20Nov23_044242| [ 0.78853 -0.03736]
20Nov23_044242| [-0.61206 -0.05827]
20Nov23_044242| [-0.21855  1.26722]
20Nov23_044242| [-1.67530  1.48281]
20Nov23_044242| [-0.42903  0.74587]
20Nov23_044242| [ 0.09435 -1.16066]
20Nov23_044242| [-0.06102 -0.22933]
20Nov23_044242| [ 1.05118 -0.41105]
20Nov23_044242| [ 0.89464  0.71066]]
20Nov23_044242|-- Bias --
20Nov23_044242|[-0.89499  0.52392]
20Nov23_044242|Predicting the validation and test data with the Best final individual.
20Nov23_044247| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_044247|-----------  ------------------  --------------------  ----------
20Nov23_044247|Validation         41.74                  15            0.01033
20Nov23_044247|   Test            33.80                  15            0.15927
20Nov23_044247|-------------------------- Test #8 --------------------------
20Nov23_044247|Best final individual weights
20Nov23_044247|Individual:
20Nov23_044247|-- Constant hidden layers --
20Nov23_044247|False
20Nov23_044247|Layer 0:
20Nov23_044247|-- Config --
20Nov23_044247|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 15, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_044247|-- Weights --
20Nov23_044247|[[ 0.42691  0.29758  0.52422 -0.54807 -0.00317 -1.10737  0.66615 -0.46744
20Nov23_044247|   0.89578  0.22818 -0.07631 -0.76947 -0.46817 -0.21265 -0.85367]
20Nov23_044247| [-0.77699  0.41355 -1.18759  0.58503  0.11262 -0.77177 -0.87309  0.55877
20Nov23_044247|   0.49143  0.60359  0.78317 -2.01143 -0.18524  0.77837 -1.58646]
20Nov23_044247| [-0.05520  1.48797 -0.98303  0.44607  0.57229  0.01093  0.45399 -0.36869
20Nov23_044247|   1.25502 -2.04679  0.52420 -0.63251 -1.20841 -1.23667 -0.50506]
20Nov23_044247| [-0.15390 -0.12069  0.93121  0.62856 -0.47194  1.90773  0.12418 -0.02385
20Nov23_044247|   0.25845  0.67909 -0.74973 -1.14428 -0.54709 -1.03812  0.41810]
20Nov23_044247| [ 0.78184 -1.02634 -0.50414 -1.33713 -0.12806 -0.25092  1.03068 -1.53814
20Nov23_044247|   0.61719 -0.37364 -0.16927  0.25844 -1.59357  0.03242 -0.43857]
20Nov23_044247| [-1.51161  0.28379  0.11711  1.41276  1.94477 -1.13581 -0.16030 -0.98811
20Nov23_044247|  -0.74563  0.47408  1.31199  0.25822 -0.39431  0.99731  0.10765]
20Nov23_044247| [-0.06246 -0.55106 -0.66587 -0.81741 -0.90947 -0.55317  0.91670 -0.20333
20Nov23_044247|   0.16840 -0.45981  0.55694  1.11849  2.39357 -0.67350  0.20551]
20Nov23_044247| [ 0.47039 -1.74884  1.06361  0.87013 -1.27871 -0.23461 -0.85571  0.11193
20Nov23_044247|   1.28638  1.75207 -0.89037 -0.68407  0.35909 -0.54462 -0.10916]
20Nov23_044247| [-0.66100  1.52516  0.33780 -0.06402 -1.30311  2.21049  0.94191 -0.16126
20Nov23_044247|   0.77832 -0.93202  0.12018  0.28667  0.60154  0.67235  0.59619]
20Nov23_044247| [ 0.75099  1.36528 -1.73960 -1.50392  0.42261 -0.97005 -0.91943 -1.36861
20Nov23_044247|  -0.67430 -0.64244 -0.75113  1.74554  0.65154 -0.07884  0.24832]
20Nov23_044247| [ 1.53921 -0.26881 -0.59691  0.18529  0.48024 -0.98931 -1.54877  0.09832
20Nov23_044247|   1.16540  1.02141 -0.79718  1.33652  1.32572 -1.05063 -0.59539]
20Nov23_044247| [ 0.24418  0.35593 -0.10494 -1.30488  1.09288 -0.42662 -0.57142  0.49472
20Nov23_044247|   0.69921  0.62190  1.18692  0.10424 -0.45179  0.21910  0.01208]
20Nov23_044247| [ 0.67743 -0.19633  0.24381 -0.30061  0.08343 -0.33063 -0.09417 -0.29616
20Nov23_044247|  -0.06241 -1.05399  2.07564 -0.84708  0.83477 -0.41045  1.39502]
20Nov23_044247| [-0.03313 -0.77540  0.75142 -1.09279  1.86636 -0.79280 -0.54517 -0.28329
20Nov23_044247|   1.65999 -1.12225 -1.39221  0.11678 -1.17849 -0.62609 -0.37682]
20Nov23_044247| [ 0.05688 -0.19939 -0.40529 -0.51524 -0.26279  0.50723  0.33124  0.59534
20Nov23_044247|   0.83706  0.14251  0.82221 -0.63467  0.55955 -1.01568  0.21284]
20Nov23_044247| [ 0.01208  0.01410  1.11235 -0.49398  1.55853  0.43249  0.08756  0.00921
20Nov23_044247|  -0.71567 -0.38946 -0.90949 -0.83809 -0.05624  0.23786  0.05994]
20Nov23_044247| [-0.35205 -0.09450  2.24445  0.53880 -0.40180 -0.46765 -0.12446 -1.32593
20Nov23_044247|   1.41826 -0.76602  0.63376  1.18055 -0.53400  0.37624 -0.97579]
20Nov23_044247| [ 2.22050  0.05952 -1.19940  0.70861  1.41717 -0.26877 -0.94211 -1.40332
20Nov23_044247|   0.43003 -0.89869 -1.10584 -0.06625  0.31384 -0.10143  1.04961]
20Nov23_044247| [ 0.21289 -0.11012  1.49023  1.14376 -0.65338  0.26810 -0.85944  1.17660
20Nov23_044247|  -0.47870 -0.86877  0.44700  0.03584 -0.98074 -0.78054  0.03734]
20Nov23_044247| [ 0.28067  0.39235  1.41028 -0.15688 -0.54646  1.67606  0.42347  0.49702
20Nov23_044247|  -0.87937 -0.46845  1.00348 -0.53170 -1.12293 -1.01729  0.08005]
20Nov23_044247| [-1.14499  0.21662  0.15572  0.25399 -0.11350  0.09781 -0.60481 -0.96573
20Nov23_044247|   1.28182 -0.69592 -0.07493 -0.15830  1.71185 -1.62962  0.07644]
20Nov23_044247| [ 0.22980  0.61617 -0.58762 -1.53387  0.28371 -0.27785 -1.01772  0.18418
20Nov23_044247|   2.29950 -0.81522 -0.54903  0.50229  0.43645 -1.39068  1.50836]
20Nov23_044247| [ 1.26701  0.34500 -0.87987 -0.44065  1.23200 -1.45523  0.41462 -0.45891
20Nov23_044247|  -1.65629  1.36545 -0.16045  0.01440 -0.19117  1.01491 -1.56428]
20Nov23_044247| [-0.50801 -0.18680 -0.13795 -0.82892  0.04078  1.05055 -0.42182  0.28003
20Nov23_044247|  -0.17800 -0.94982 -1.60567 -0.74657 -0.37202 -0.77117  0.22728]
20Nov23_044247| [ 0.11223 -0.88960 -0.03771  0.68481 -1.13907 -1.64770 -2.08633  2.59999
20Nov23_044247|   0.70704 -1.10352 -0.73587  0.64618  0.18789 -0.56185 -0.00473]
20Nov23_044247| [-0.44394  1.09725  0.51635  0.38580 -1.13990  0.40442 -0.52209  0.10404
20Nov23_044247|  -0.15833  0.12255 -0.21853 -0.42496  1.00447  0.73146 -0.63667]
20Nov23_044247| [ 0.10066  1.40237  0.09464  0.72661 -1.80184 -0.06104 -0.34136 -0.51537
20Nov23_044247|  -1.66542 -0.55066 -2.56233 -0.02383 -0.84513 -1.61262 -0.51402]
20Nov23_044247| [-0.87960  0.23358 -0.52134  0.40047 -0.71106 -1.34728 -0.41823 -0.22333
20Nov23_044247|  -0.24686  1.65698 -1.30747 -0.69169 -0.66251  0.75459 -0.96660]
20Nov23_044247| [ 0.06230  1.20678 -0.23045 -0.84286 -0.22852  0.93298  0.14893  0.50809
20Nov23_044247|   0.14889 -0.72929 -0.24429  1.56028  1.22272  0.91747  0.36855]
20Nov23_044247| [-0.17377  1.14562  0.85539 -0.63699 -1.04190  0.12303 -0.72049 -0.08881
20Nov23_044247|  -0.90310  1.31653 -0.05204  0.40329 -0.48401 -0.36525 -0.46378]
20Nov23_044247| [ 0.09015 -0.62972 -0.73537  0.17011  0.27345 -0.55471  0.04517 -1.18609
20Nov23_044247|  -0.58628  0.49196 -0.58326  0.30330  0.51502  0.03433  0.04217]
20Nov23_044247| [ 0.86282 -0.84858 -1.43016 -0.52856  0.03054  0.44886  0.57046 -0.35864
20Nov23_044247|  -1.71832  0.24280 -0.89086 -0.78176  0.35162  0.30409 -0.02131]
20Nov23_044247| [ 1.05695  0.97767 -1.00230 -0.01291  0.04290 -0.09954  0.88877 -1.02809
20Nov23_044247|  -1.32144  0.07652  0.09972 -1.00606 -1.32542  0.05830 -0.38045]
20Nov23_044247| [ 0.43701 -1.48958 -0.15290 -0.28863  0.74501  0.03579 -1.09314 -0.86026
20Nov23_044247|   1.02886  1.16551 -1.01948 -1.43095 -1.82196 -0.89176 -0.81819]
20Nov23_044247| [-0.73966  0.22000  1.42394  0.53847 -2.33016 -0.57383  0.30702 -0.26322
20Nov23_044247|  -1.01442  0.05468 -0.23153 -0.06345  1.16376 -0.09296 -0.53408]
20Nov23_044247| [ 0.21706  1.28120  0.03908 -0.45157  0.48998  0.08854  0.00582  0.77533
20Nov23_044247|  -0.45924  0.03863 -0.73519 -0.00919 -1.16571  1.56297 -0.69370]
20Nov23_044247| [-2.08881 -0.97910  0.17069  0.79842  0.31541 -0.19526  0.45634  1.01009
20Nov23_044247|   0.59365 -0.01322  1.78356  1.44269  0.58775 -0.50228 -0.28648]
20Nov23_044247| [-1.12486  0.73663  0.56411  0.18444 -1.61639  1.08550  0.08219 -0.90988
20Nov23_044247|  -0.32404  0.81985  0.42006 -0.30815 -0.23312 -1.18708 -0.01110]
20Nov23_044247| [-0.30490 -1.30488 -1.53248 -0.79287  1.01787 -0.71421 -1.83065  0.46204
20Nov23_044247|  -0.31745  0.01163 -0.78217 -0.08380 -0.93485  0.93025 -1.11372]
20Nov23_044247| [-0.16328  1.13418 -0.55347 -0.46779  1.07552  0.66229 -0.21371  0.92252
20Nov23_044247|   0.55318  0.22002 -0.20203  0.71337  0.07093 -0.67508 -0.36308]
20Nov23_044247| [-0.14015 -0.56332  0.42102 -0.18024 -0.17774 -1.39429  0.65512  0.86385
20Nov23_044247|   0.74911  0.68266 -0.21078 -0.90494  0.19014 -0.64455  0.30027]
20Nov23_044247| [-0.74732 -0.00467  0.93348 -0.20600  0.55633 -0.56408 -0.45634 -0.20303
20Nov23_044247|  -0.13201 -1.51600  0.26075 -0.89582 -1.24197  0.63267  1.55172]
20Nov23_044247| [ 0.41456 -0.85489  0.02298  0.06353  0.81855  0.03156 -0.48615 -0.00658
20Nov23_044247|  -0.04895 -0.57287  0.20380  1.04986  0.97412 -0.47486  0.49494]
20Nov23_044247| [ 0.77080 -0.45784  0.11136  0.71105 -0.39395  0.40195 -0.43665  1.07323
20Nov23_044247|   0.43760  0.26785 -0.30587 -0.09075  0.40279  1.01923 -1.75405]
20Nov23_044247| [-0.88852  0.02533  1.17656  0.61764 -0.88512 -2.05323 -0.20657  0.56943
20Nov23_044247|  -0.79923 -0.05065  0.86607  1.99813 -0.99948 -0.10370  0.97637]
20Nov23_044247| [ 0.15692 -0.81947 -0.03219  0.05575  0.45531  1.62288 -0.76175 -0.80154
20Nov23_044247|  -1.50942 -0.89066 -0.37832  0.57865  2.24774  1.50483 -0.01312]
20Nov23_044247| [ 0.88566 -1.32158  1.07146  0.66710  0.27661  0.21144  0.50741  1.07543
20Nov23_044247|  -0.76611 -1.39540  0.28672  0.51751  0.72656 -0.65978  0.44566]
20Nov23_044247| [-1.03893  0.46076 -0.08662 -0.52243 -0.41836  0.85811 -0.86078  0.93975
20Nov23_044247|  -0.17006 -0.63327  0.74410  0.70958  1.39514  0.35044  0.87490]
20Nov23_044247| [ 1.54246 -0.70391 -0.91033  1.89604  0.46300 -0.13194 -0.43312  0.91185
20Nov23_044247|  -0.49534 -1.06771  0.38325 -1.29257 -0.73563 -1.04282 -0.39890]
20Nov23_044247| [-0.79484 -0.73094  1.55911 -0.27683  0.74301  0.65244 -1.70505  0.26757
20Nov23_044247|  -1.24152 -0.51986 -0.91341 -0.27940 -0.78858 -0.03302  0.36902]
20Nov23_044247| [-0.52894 -0.45939  0.71874 -1.10270 -0.31797 -1.23160 -0.28378  0.28717
20Nov23_044247|  -0.95275  0.83782 -0.51558 -0.40856 -0.70669 -0.31466  0.04528]
20Nov23_044247| [-0.81167 -0.21989  0.25817 -0.60778 -0.97270  0.42051  0.05410  0.81779
20Nov23_044247|  -0.94129  0.37341 -0.02587 -1.69395 -1.66843  0.14977 -1.29684]
20Nov23_044247| [ 0.18812 -1.04226 -0.19694 -0.90997  0.07427 -1.36961 -0.68391  1.29857
20Nov23_044247|  -1.58449 -1.19082 -1.19331 -0.28466  0.45438  0.59896 -0.09320]
20Nov23_044247| [ 0.46661 -1.82518  0.34643  0.42851  0.74486  1.16437 -1.33420  0.48093
20Nov23_044247|   0.66350 -1.58536  1.36313  1.64685  0.50624 -0.08332  0.16742]
20Nov23_044247| [ 0.83611 -1.02550  0.80906  0.82930  0.96028  0.21344  0.43399 -1.26536
20Nov23_044247|  -0.08786  0.56148  0.56968 -0.83275  0.47723  1.01280 -0.61349]
20Nov23_044247| [ 0.38265 -1.34334  0.19600 -0.79295  0.52286  0.28619  1.51312  0.85224
20Nov23_044247|   1.62111  1.09962  0.16420 -0.44606 -1.11225  1.26263  1.87372]
20Nov23_044247| [-0.57357 -0.55004 -1.15617  0.42990  0.23652 -0.13154 -1.45382  0.27475
20Nov23_044247|  -0.64777 -0.51002 -0.63579 -0.59520 -0.00340  0.31749  0.18432]]
20Nov23_044247|-- Bias --
20Nov23_044247|[ 1.38477 -0.37130 -0.13609 -0.85960 -0.92209 -0.27950  0.84767 -0.72498
20Nov23_044247| -0.02423  1.22888 -0.06124 -0.44945 -0.13271 -0.02930 -0.90463]
20Nov23_044247|Layer 1:
20Nov23_044247|-- Config --
20Nov23_044247|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 15], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_044247|-- Weights --
20Nov23_044247|[[ 0.67379 -1.05055]
20Nov23_044247| [-0.28290 -0.06835]
20Nov23_044247| [ 0.37387  0.47814]
20Nov23_044247| [ 0.58602 -0.61286]
20Nov23_044247| [-0.34764  0.50916]
20Nov23_044247| [-0.54241 -0.48178]
20Nov23_044247| [ 0.78853 -0.03736]
20Nov23_044247| [-0.61206 -0.05827]
20Nov23_044247| [-0.21855  1.26722]
20Nov23_044247| [-1.67530  1.48281]
20Nov23_044247| [-0.42903  0.74587]
20Nov23_044247| [ 0.09435 -1.16066]
20Nov23_044247| [-0.06102 -0.22933]
20Nov23_044247| [ 1.05118 -0.41105]
20Nov23_044247| [ 0.89464  0.71066]]
20Nov23_044247|-- Bias --
20Nov23_044247|[-0.89499  0.52392]
20Nov23_044247|Predicting the validation and test data with the Best final individual.
20Nov23_044253| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_044253|-----------  ------------------  --------------------  ----------
20Nov23_044253|Validation         40.00                  15            0.06877
20Nov23_044253|   Test            36.40                  15            0.00595
20Nov23_044253|-------------------------- Test #9 --------------------------
20Nov23_044253|Best final individual weights
20Nov23_044253|Individual:
20Nov23_044253|-- Constant hidden layers --
20Nov23_044253|False
20Nov23_044253|Layer 0:
20Nov23_044253|-- Config --
20Nov23_044253|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 15, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_044253|-- Weights --
20Nov23_044253|[[ 0.42691  0.29758  0.52422 -0.54807 -0.00317 -1.10737  0.66615 -0.46744
20Nov23_044253|   0.89578  0.22818 -0.07631 -0.76947 -0.46817 -0.21265 -0.85367]
20Nov23_044253| [-0.77699  0.41355 -1.18759  0.58503  0.11262 -0.77177 -0.87309  0.55877
20Nov23_044253|   0.49143  0.60359  0.78317 -2.01143 -0.18524  0.77837 -1.58646]
20Nov23_044253| [-0.05520  1.48797 -0.98303  0.44607  0.57229  0.01093  0.45399 -0.36869
20Nov23_044253|   1.25502 -2.04679  0.52420 -0.63251 -1.20841 -1.23667 -0.50506]
20Nov23_044253| [-0.15390 -0.12069  0.93121  0.62856 -0.47194  1.90773  0.12418 -0.02385
20Nov23_044253|   0.25845  0.67909 -0.74973 -1.14428 -0.54709 -1.03812  0.41810]
20Nov23_044253| [ 0.78184 -1.02634 -0.50414 -1.33713 -0.12806 -0.25092  1.03068 -1.53814
20Nov23_044253|   0.61719 -0.37364 -0.16927  0.25844 -1.59357  0.03242 -0.43857]
20Nov23_044253| [-1.51161  0.28379  0.11711  1.41276  1.94477 -1.13581 -0.16030 -0.98811
20Nov23_044253|  -0.74563  0.47408  1.31199  0.25822 -0.39431  0.99731  0.10765]
20Nov23_044253| [-0.06246 -0.55106 -0.66587 -0.81741 -0.90947 -0.55317  0.91670 -0.20333
20Nov23_044253|   0.16840 -0.45981  0.55694  1.11849  2.39357 -0.67350  0.20551]
20Nov23_044253| [ 0.47039 -1.74884  1.06361  0.87013 -1.27871 -0.23461 -0.85571  0.11193
20Nov23_044253|   1.28638  1.75207 -0.89037 -0.68407  0.35909 -0.54462 -0.10916]
20Nov23_044253| [-0.66100  1.52516  0.33780 -0.06402 -1.30311  2.21049  0.94191 -0.16126
20Nov23_044253|   0.77832 -0.93202  0.12018  0.28667  0.60154  0.67235  0.59619]
20Nov23_044253| [ 0.75099  1.36528 -1.73960 -1.50392  0.42261 -0.97005 -0.91943 -1.36861
20Nov23_044253|  -0.67430 -0.64244 -0.75113  1.74554  0.65154 -0.07884  0.24832]
20Nov23_044253| [ 1.53921 -0.26881 -0.59691  0.18529  0.48024 -0.98931 -1.54877  0.09832
20Nov23_044253|   1.16540  1.02141 -0.79718  1.33652  1.32572 -1.05063 -0.59539]
20Nov23_044253| [ 0.24418  0.35593 -0.10494 -1.30488  1.09288 -0.42662 -0.57142  0.49472
20Nov23_044253|   0.69921  0.62190  1.18692  0.10424 -0.45179  0.21910  0.01208]
20Nov23_044253| [ 0.67743 -0.19633  0.24381 -0.30061  0.08343 -0.33063 -0.09417 -0.29616
20Nov23_044253|  -0.06241 -1.05399  2.07564 -0.84708  0.83477 -0.41045  1.39502]
20Nov23_044253| [-0.03313 -0.77540  0.75142 -1.09279  1.86636 -0.79280 -0.54517 -0.28329
20Nov23_044253|   1.65999 -1.12225 -1.39221  0.11678 -1.17849 -0.62609 -0.37682]
20Nov23_044253| [ 0.05688 -0.19939 -0.40529 -0.51524 -0.26279  0.50723  0.33124  0.59534
20Nov23_044253|   0.83706  0.14251  0.82221 -0.63467  0.55955 -1.01568  0.21284]
20Nov23_044253| [ 0.01208  0.01410  1.11235 -0.49398  1.55853  0.43249  0.08756  0.00921
20Nov23_044253|  -0.71567 -0.38946 -0.90949 -0.83809 -0.05624  0.23786  0.05994]
20Nov23_044253| [-0.35205 -0.09450  2.24445  0.53880 -0.40180 -0.46765 -0.12446 -1.32593
20Nov23_044253|   1.41826 -0.76602  0.63376  1.18055 -0.53400  0.37624 -0.97579]
20Nov23_044253| [ 2.22050  0.05952 -1.19940  0.70861  1.41717 -0.26877 -0.94211 -1.40332
20Nov23_044253|   0.43003 -0.89869 -1.10584 -0.06625  0.31384 -0.10143  1.04961]
20Nov23_044253| [ 0.21289 -0.11012  1.49023  1.14376 -0.65338  0.26810 -0.85944  1.17660
20Nov23_044253|  -0.47870 -0.86877  0.44700  0.03584 -0.98074 -0.78054  0.03734]
20Nov23_044253| [ 0.28067  0.39235  1.41028 -0.15688 -0.54646  1.67606  0.42347  0.49702
20Nov23_044253|  -0.87937 -0.46845  1.00348 -0.53170 -1.12293 -1.01729  0.08005]
20Nov23_044253| [-1.14499  0.21662  0.15572  0.25399 -0.11350  0.09781 -0.60481 -0.96573
20Nov23_044253|   1.28182 -0.69592 -0.07493 -0.15830  1.71185 -1.62962  0.07644]
20Nov23_044253| [ 0.22980  0.61617 -0.58762 -1.53387  0.28371 -0.27785 -1.01772  0.18418
20Nov23_044253|   2.29950 -0.81522 -0.54903  0.50229  0.43645 -1.39068  1.50836]
20Nov23_044253| [ 1.26701  0.34500 -0.87987 -0.44065  1.23200 -1.45523  0.41462 -0.45891
20Nov23_044253|  -1.65629  1.36545 -0.16045  0.01440 -0.19117  1.01491 -1.56428]
20Nov23_044253| [-0.50801 -0.18680 -0.13795 -0.82892  0.04078  1.05055 -0.42182  0.28003
20Nov23_044253|  -0.17800 -0.94982 -1.60567 -0.74657 -0.37202 -0.77117  0.22728]
20Nov23_044253| [ 0.11223 -0.88960 -0.03771  0.68481 -1.13907 -1.64770 -2.08633  2.59999
20Nov23_044253|   0.70704 -1.10352 -0.73587  0.64618  0.18789 -0.56185 -0.00473]
20Nov23_044253| [-0.44394  1.09725  0.51635  0.38580 -1.13990  0.40442 -0.52209  0.10404
20Nov23_044253|  -0.15833  0.12255 -0.21853 -0.42496  1.00447  0.73146 -0.63667]
20Nov23_044253| [ 0.10066  1.40237  0.09464  0.72661 -1.80184 -0.06104 -0.34136 -0.51537
20Nov23_044253|  -1.66542 -0.55066 -2.56233 -0.02383 -0.84513 -1.61262 -0.51402]
20Nov23_044253| [-0.87960  0.23358 -0.52134  0.40047 -0.71106 -1.34728 -0.41823 -0.22333
20Nov23_044253|  -0.24686  1.65698 -1.30747 -0.69169 -0.66251  0.75459 -0.96660]
20Nov23_044253| [ 0.06230  1.20678 -0.23045 -0.84286 -0.22852  0.93298  0.14893  0.50809
20Nov23_044253|   0.14889 -0.72929 -0.24429  1.56028  1.22272  0.91747  0.36855]
20Nov23_044253| [-0.17377  1.14562  0.85539 -0.63699 -1.04190  0.12303 -0.72049 -0.08881
20Nov23_044253|  -0.90310  1.31653 -0.05204  0.40329 -0.48401 -0.36525 -0.46378]
20Nov23_044253| [ 0.09015 -0.62972 -0.73537  0.17011  0.27345 -0.55471  0.04517 -1.18609
20Nov23_044253|  -0.58628  0.49196 -0.58326  0.30330  0.51502  0.03433  0.04217]
20Nov23_044253| [ 0.86282 -0.84858 -1.43016 -0.52856  0.03054  0.44886  0.57046 -0.35864
20Nov23_044253|  -1.71832  0.24280 -0.89086 -0.78176  0.35162  0.30409 -0.02131]
20Nov23_044253| [ 1.05695  0.97767 -1.00230 -0.01291  0.04290 -0.09954  0.88877 -1.02809
20Nov23_044253|  -1.32144  0.07652  0.09972 -1.00606 -1.32542  0.05830 -0.38045]
20Nov23_044253| [ 0.43701 -1.48958 -0.15290 -0.28863  0.74501  0.03579 -1.09314 -0.86026
20Nov23_044253|   1.02886  1.16551 -1.01948 -1.43095 -1.82196 -0.89176 -0.81819]
20Nov23_044253| [-0.73966  0.22000  1.42394  0.53847 -2.33016 -0.57383  0.30702 -0.26322
20Nov23_044253|  -1.01442  0.05468 -0.23153 -0.06345  1.16376 -0.09296 -0.53408]
20Nov23_044253| [ 0.21706  1.28120  0.03908 -0.45157  0.48998  0.08854  0.00582  0.77533
20Nov23_044253|  -0.45924  0.03863 -0.73519 -0.00919 -1.16571  1.56297 -0.69370]
20Nov23_044253| [-2.08881 -0.97910  0.17069  0.79842  0.31541 -0.19526  0.45634  1.01009
20Nov23_044253|   0.59365 -0.01322  1.78356  1.44269  0.58775 -0.50228 -0.28648]
20Nov23_044253| [-1.12486  0.73663  0.56411  0.18444 -1.61639  1.08550  0.08219 -0.90988
20Nov23_044253|  -0.32404  0.81985  0.42006 -0.30815 -0.23312 -1.18708 -0.01110]
20Nov23_044253| [-0.30490 -1.30488 -1.53248 -0.79287  1.01787 -0.71421 -1.83065  0.46204
20Nov23_044253|  -0.31745  0.01163 -0.78217 -0.08380 -0.93485  0.93025 -1.11372]
20Nov23_044253| [-0.16328  1.13418 -0.55347 -0.46779  1.07552  0.66229 -0.21371  0.92252
20Nov23_044253|   0.55318  0.22002 -0.20203  0.71337  0.07093 -0.67508 -0.36308]
20Nov23_044253| [-0.14015 -0.56332  0.42102 -0.18024 -0.17774 -1.39429  0.65512  0.86385
20Nov23_044253|   0.74911  0.68266 -0.21078 -0.90494  0.19014 -0.64455  0.30027]
20Nov23_044253| [-0.74732 -0.00467  0.93348 -0.20600  0.55633 -0.56408 -0.45634 -0.20303
20Nov23_044253|  -0.13201 -1.51600  0.26075 -0.89582 -1.24197  0.63267  1.55172]
20Nov23_044253| [ 0.41456 -0.85489  0.02298  0.06353  0.81855  0.03156 -0.48615 -0.00658
20Nov23_044253|  -0.04895 -0.57287  0.20380  1.04986  0.97412 -0.47486  0.49494]
20Nov23_044253| [ 0.77080 -0.45784  0.11136  0.71105 -0.39395  0.40195 -0.43665  1.07323
20Nov23_044253|   0.43760  0.26785 -0.30587 -0.09075  0.40279  1.01923 -1.75405]
20Nov23_044253| [-0.88852  0.02533  1.17656  0.61764 -0.88512 -2.05323 -0.20657  0.56943
20Nov23_044253|  -0.79923 -0.05065  0.86607  1.99813 -0.99948 -0.10370  0.97637]
20Nov23_044253| [ 0.15692 -0.81947 -0.03219  0.05575  0.45531  1.62288 -0.76175 -0.80154
20Nov23_044253|  -1.50942 -0.89066 -0.37832  0.57865  2.24774  1.50483 -0.01312]
20Nov23_044253| [ 0.88566 -1.32158  1.07146  0.66710  0.27661  0.21144  0.50741  1.07543
20Nov23_044253|  -0.76611 -1.39540  0.28672  0.51751  0.72656 -0.65978  0.44566]
20Nov23_044253| [-1.03893  0.46076 -0.08662 -0.52243 -0.41836  0.85811 -0.86078  0.93975
20Nov23_044253|  -0.17006 -0.63327  0.74410  0.70958  1.39514  0.35044  0.87490]
20Nov23_044253| [ 1.54246 -0.70391 -0.91033  1.89604  0.46300 -0.13194 -0.43312  0.91185
20Nov23_044253|  -0.49534 -1.06771  0.38325 -1.29257 -0.73563 -1.04282 -0.39890]
20Nov23_044253| [-0.79484 -0.73094  1.55911 -0.27683  0.74301  0.65244 -1.70505  0.26757
20Nov23_044253|  -1.24152 -0.51986 -0.91341 -0.27940 -0.78858 -0.03302  0.36902]
20Nov23_044253| [-0.52894 -0.45939  0.71874 -1.10270 -0.31797 -1.23160 -0.28378  0.28717
20Nov23_044253|  -0.95275  0.83782 -0.51558 -0.40856 -0.70669 -0.31466  0.04528]
20Nov23_044253| [-0.81167 -0.21989  0.25817 -0.60778 -0.97270  0.42051  0.05410  0.81779
20Nov23_044253|  -0.94129  0.37341 -0.02587 -1.69395 -1.66843  0.14977 -1.29684]
20Nov23_044253| [ 0.18812 -1.04226 -0.19694 -0.90997  0.07427 -1.36961 -0.68391  1.29857
20Nov23_044253|  -1.58449 -1.19082 -1.19331 -0.28466  0.45438  0.59896 -0.09320]
20Nov23_044253| [ 0.46661 -1.82518  0.34643  0.42851  0.74486  1.16437 -1.33420  0.48093
20Nov23_044253|   0.66350 -1.58536  1.36313  1.64685  0.50624 -0.08332  0.16742]
20Nov23_044253| [ 0.83611 -1.02550  0.80906  0.82930  0.96028  0.21344  0.43399 -1.26536
20Nov23_044253|  -0.08786  0.56148  0.56968 -0.83275  0.47723  1.01280 -0.61349]
20Nov23_044253| [ 0.38265 -1.34334  0.19600 -0.79295  0.52286  0.28619  1.51312  0.85224
20Nov23_044253|   1.62111  1.09962  0.16420 -0.44606 -1.11225  1.26263  1.87372]
20Nov23_044253| [-0.57357 -0.55004 -1.15617  0.42990  0.23652 -0.13154 -1.45382  0.27475
20Nov23_044253|  -0.64777 -0.51002 -0.63579 -0.59520 -0.00340  0.31749  0.18432]]
20Nov23_044253|-- Bias --
20Nov23_044253|[ 1.38477 -0.37130 -0.13609 -0.85960 -0.92209 -0.27950  0.84767 -0.72498
20Nov23_044253| -0.02423  1.22888 -0.06124 -0.44945 -0.13271 -0.02930 -0.90463]
20Nov23_044253|Layer 1:
20Nov23_044253|-- Config --
20Nov23_044253|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 15], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_044253|-- Weights --
20Nov23_044253|[[ 0.67379 -1.05055]
20Nov23_044253| [-0.28290 -0.06835]
20Nov23_044253| [ 0.37387  0.47814]
20Nov23_044253| [ 0.58602 -0.61286]
20Nov23_044253| [-0.34764  0.50916]
20Nov23_044253| [-0.54241 -0.48178]
20Nov23_044253| [ 0.78853 -0.03736]
20Nov23_044253| [-0.61206 -0.05827]
20Nov23_044253| [-0.21855  1.26722]
20Nov23_044253| [-1.67530  1.48281]
20Nov23_044253| [-0.42903  0.74587]
20Nov23_044253| [ 0.09435 -1.16066]
20Nov23_044253| [-0.06102 -0.22933]
20Nov23_044253| [ 1.05118 -0.41105]
20Nov23_044253| [ 0.89464  0.71066]]
20Nov23_044253|-- Bias --
20Nov23_044253|[-0.89499  0.52392]
20Nov23_044253|Predicting the validation and test data with the Best final individual.
20Nov23_044259| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_044259|-----------  ------------------  --------------------  ----------
20Nov23_044259|Validation         41.91                  15            0.00259
20Nov23_044259|   Test            33.62                  15            0.14605
20Nov23_044259|-------------------------- Test #10 --------------------------
20Nov23_044259|Best final individual weights
20Nov23_044259|Individual:
20Nov23_044259|-- Constant hidden layers --
20Nov23_044259|False
20Nov23_044259|Layer 0:
20Nov23_044259|-- Config --
20Nov23_044259|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 15, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_044259|-- Weights --
20Nov23_044259|[[ 0.42691  0.29758  0.52422 -0.54807 -0.00317 -1.10737  0.66615 -0.46744
20Nov23_044259|   0.89578  0.22818 -0.07631 -0.76947 -0.46817 -0.21265 -0.85367]
20Nov23_044259| [-0.77699  0.41355 -1.18759  0.58503  0.11262 -0.77177 -0.87309  0.55877
20Nov23_044259|   0.49143  0.60359  0.78317 -2.01143 -0.18524  0.77837 -1.58646]
20Nov23_044259| [-0.05520  1.48797 -0.98303  0.44607  0.57229  0.01093  0.45399 -0.36869
20Nov23_044259|   1.25502 -2.04679  0.52420 -0.63251 -1.20841 -1.23667 -0.50506]
20Nov23_044259| [-0.15390 -0.12069  0.93121  0.62856 -0.47194  1.90773  0.12418 -0.02385
20Nov23_044259|   0.25845  0.67909 -0.74973 -1.14428 -0.54709 -1.03812  0.41810]
20Nov23_044259| [ 0.78184 -1.02634 -0.50414 -1.33713 -0.12806 -0.25092  1.03068 -1.53814
20Nov23_044259|   0.61719 -0.37364 -0.16927  0.25844 -1.59357  0.03242 -0.43857]
20Nov23_044259| [-1.51161  0.28379  0.11711  1.41276  1.94477 -1.13581 -0.16030 -0.98811
20Nov23_044259|  -0.74563  0.47408  1.31199  0.25822 -0.39431  0.99731  0.10765]
20Nov23_044259| [-0.06246 -0.55106 -0.66587 -0.81741 -0.90947 -0.55317  0.91670 -0.20333
20Nov23_044259|   0.16840 -0.45981  0.55694  1.11849  2.39357 -0.67350  0.20551]
20Nov23_044259| [ 0.47039 -1.74884  1.06361  0.87013 -1.27871 -0.23461 -0.85571  0.11193
20Nov23_044259|   1.28638  1.75207 -0.89037 -0.68407  0.35909 -0.54462 -0.10916]
20Nov23_044259| [-0.66100  1.52516  0.33780 -0.06402 -1.30311  2.21049  0.94191 -0.16126
20Nov23_044259|   0.77832 -0.93202  0.12018  0.28667  0.60154  0.67235  0.59619]
20Nov23_044259| [ 0.75099  1.36528 -1.73960 -1.50392  0.42261 -0.97005 -0.91943 -1.36861
20Nov23_044259|  -0.67430 -0.64244 -0.75113  1.74554  0.65154 -0.07884  0.24832]
20Nov23_044259| [ 1.53921 -0.26881 -0.59691  0.18529  0.48024 -0.98931 -1.54877  0.09832
20Nov23_044259|   1.16540  1.02141 -0.79718  1.33652  1.32572 -1.05063 -0.59539]
20Nov23_044259| [ 0.24418  0.35593 -0.10494 -1.30488  1.09288 -0.42662 -0.57142  0.49472
20Nov23_044259|   0.69921  0.62190  1.18692  0.10424 -0.45179  0.21910  0.01208]
20Nov23_044259| [ 0.67743 -0.19633  0.24381 -0.30061  0.08343 -0.33063 -0.09417 -0.29616
20Nov23_044259|  -0.06241 -1.05399  2.07564 -0.84708  0.83477 -0.41045  1.39502]
20Nov23_044259| [-0.03313 -0.77540  0.75142 -1.09279  1.86636 -0.79280 -0.54517 -0.28329
20Nov23_044259|   1.65999 -1.12225 -1.39221  0.11678 -1.17849 -0.62609 -0.37682]
20Nov23_044259| [ 0.05688 -0.19939 -0.40529 -0.51524 -0.26279  0.50723  0.33124  0.59534
20Nov23_044259|   0.83706  0.14251  0.82221 -0.63467  0.55955 -1.01568  0.21284]
20Nov23_044259| [ 0.01208  0.01410  1.11235 -0.49398  1.55853  0.43249  0.08756  0.00921
20Nov23_044259|  -0.71567 -0.38946 -0.90949 -0.83809 -0.05624  0.23786  0.05994]
20Nov23_044259| [-0.35205 -0.09450  2.24445  0.53880 -0.40180 -0.46765 -0.12446 -1.32593
20Nov23_044259|   1.41826 -0.76602  0.63376  1.18055 -0.53400  0.37624 -0.97579]
20Nov23_044259| [ 2.22050  0.05952 -1.19940  0.70861  1.41717 -0.26877 -0.94211 -1.40332
20Nov23_044259|   0.43003 -0.89869 -1.10584 -0.06625  0.31384 -0.10143  1.04961]
20Nov23_044259| [ 0.21289 -0.11012  1.49023  1.14376 -0.65338  0.26810 -0.85944  1.17660
20Nov23_044259|  -0.47870 -0.86877  0.44700  0.03584 -0.98074 -0.78054  0.03734]
20Nov23_044259| [ 0.28067  0.39235  1.41028 -0.15688 -0.54646  1.67606  0.42347  0.49702
20Nov23_044259|  -0.87937 -0.46845  1.00348 -0.53170 -1.12293 -1.01729  0.08005]
20Nov23_044259| [-1.14499  0.21662  0.15572  0.25399 -0.11350  0.09781 -0.60481 -0.96573
20Nov23_044259|   1.28182 -0.69592 -0.07493 -0.15830  1.71185 -1.62962  0.07644]
20Nov23_044259| [ 0.22980  0.61617 -0.58762 -1.53387  0.28371 -0.27785 -1.01772  0.18418
20Nov23_044259|   2.29950 -0.81522 -0.54903  0.50229  0.43645 -1.39068  1.50836]
20Nov23_044259| [ 1.26701  0.34500 -0.87987 -0.44065  1.23200 -1.45523  0.41462 -0.45891
20Nov23_044259|  -1.65629  1.36545 -0.16045  0.01440 -0.19117  1.01491 -1.56428]
20Nov23_044259| [-0.50801 -0.18680 -0.13795 -0.82892  0.04078  1.05055 -0.42182  0.28003
20Nov23_044259|  -0.17800 -0.94982 -1.60567 -0.74657 -0.37202 -0.77117  0.22728]
20Nov23_044259| [ 0.11223 -0.88960 -0.03771  0.68481 -1.13907 -1.64770 -2.08633  2.59999
20Nov23_044259|   0.70704 -1.10352 -0.73587  0.64618  0.18789 -0.56185 -0.00473]
20Nov23_044259| [-0.44394  1.09725  0.51635  0.38580 -1.13990  0.40442 -0.52209  0.10404
20Nov23_044259|  -0.15833  0.12255 -0.21853 -0.42496  1.00447  0.73146 -0.63667]
20Nov23_044259| [ 0.10066  1.40237  0.09464  0.72661 -1.80184 -0.06104 -0.34136 -0.51537
20Nov23_044259|  -1.66542 -0.55066 -2.56233 -0.02383 -0.84513 -1.61262 -0.51402]
20Nov23_044259| [-0.87960  0.23358 -0.52134  0.40047 -0.71106 -1.34728 -0.41823 -0.22333
20Nov23_044259|  -0.24686  1.65698 -1.30747 -0.69169 -0.66251  0.75459 -0.96660]
20Nov23_044259| [ 0.06230  1.20678 -0.23045 -0.84286 -0.22852  0.93298  0.14893  0.50809
20Nov23_044259|   0.14889 -0.72929 -0.24429  1.56028  1.22272  0.91747  0.36855]
20Nov23_044259| [-0.17377  1.14562  0.85539 -0.63699 -1.04190  0.12303 -0.72049 -0.08881
20Nov23_044259|  -0.90310  1.31653 -0.05204  0.40329 -0.48401 -0.36525 -0.46378]
20Nov23_044259| [ 0.09015 -0.62972 -0.73537  0.17011  0.27345 -0.55471  0.04517 -1.18609
20Nov23_044259|  -0.58628  0.49196 -0.58326  0.30330  0.51502  0.03433  0.04217]
20Nov23_044259| [ 0.86282 -0.84858 -1.43016 -0.52856  0.03054  0.44886  0.57046 -0.35864
20Nov23_044259|  -1.71832  0.24280 -0.89086 -0.78176  0.35162  0.30409 -0.02131]
20Nov23_044259| [ 1.05695  0.97767 -1.00230 -0.01291  0.04290 -0.09954  0.88877 -1.02809
20Nov23_044259|  -1.32144  0.07652  0.09972 -1.00606 -1.32542  0.05830 -0.38045]
20Nov23_044259| [ 0.43701 -1.48958 -0.15290 -0.28863  0.74501  0.03579 -1.09314 -0.86026
20Nov23_044259|   1.02886  1.16551 -1.01948 -1.43095 -1.82196 -0.89176 -0.81819]
20Nov23_044259| [-0.73966  0.22000  1.42394  0.53847 -2.33016 -0.57383  0.30702 -0.26322
20Nov23_044259|  -1.01442  0.05468 -0.23153 -0.06345  1.16376 -0.09296 -0.53408]
20Nov23_044259| [ 0.21706  1.28120  0.03908 -0.45157  0.48998  0.08854  0.00582  0.77533
20Nov23_044259|  -0.45924  0.03863 -0.73519 -0.00919 -1.16571  1.56297 -0.69370]
20Nov23_044259| [-2.08881 -0.97910  0.17069  0.79842  0.31541 -0.19526  0.45634  1.01009
20Nov23_044259|   0.59365 -0.01322  1.78356  1.44269  0.58775 -0.50228 -0.28648]
20Nov23_044259| [-1.12486  0.73663  0.56411  0.18444 -1.61639  1.08550  0.08219 -0.90988
20Nov23_044259|  -0.32404  0.81985  0.42006 -0.30815 -0.23312 -1.18708 -0.01110]
20Nov23_044259| [-0.30490 -1.30488 -1.53248 -0.79287  1.01787 -0.71421 -1.83065  0.46204
20Nov23_044259|  -0.31745  0.01163 -0.78217 -0.08380 -0.93485  0.93025 -1.11372]
20Nov23_044259| [-0.16328  1.13418 -0.55347 -0.46779  1.07552  0.66229 -0.21371  0.92252
20Nov23_044259|   0.55318  0.22002 -0.20203  0.71337  0.07093 -0.67508 -0.36308]
20Nov23_044259| [-0.14015 -0.56332  0.42102 -0.18024 -0.17774 -1.39429  0.65512  0.86385
20Nov23_044259|   0.74911  0.68266 -0.21078 -0.90494  0.19014 -0.64455  0.30027]
20Nov23_044259| [-0.74732 -0.00467  0.93348 -0.20600  0.55633 -0.56408 -0.45634 -0.20303
20Nov23_044259|  -0.13201 -1.51600  0.26075 -0.89582 -1.24197  0.63267  1.55172]
20Nov23_044259| [ 0.41456 -0.85489  0.02298  0.06353  0.81855  0.03156 -0.48615 -0.00658
20Nov23_044259|  -0.04895 -0.57287  0.20380  1.04986  0.97412 -0.47486  0.49494]
20Nov23_044259| [ 0.77080 -0.45784  0.11136  0.71105 -0.39395  0.40195 -0.43665  1.07323
20Nov23_044259|   0.43760  0.26785 -0.30587 -0.09075  0.40279  1.01923 -1.75405]
20Nov23_044259| [-0.88852  0.02533  1.17656  0.61764 -0.88512 -2.05323 -0.20657  0.56943
20Nov23_044259|  -0.79923 -0.05065  0.86607  1.99813 -0.99948 -0.10370  0.97637]
20Nov23_044259| [ 0.15692 -0.81947 -0.03219  0.05575  0.45531  1.62288 -0.76175 -0.80154
20Nov23_044259|  -1.50942 -0.89066 -0.37832  0.57865  2.24774  1.50483 -0.01312]
20Nov23_044259| [ 0.88566 -1.32158  1.07146  0.66710  0.27661  0.21144  0.50741  1.07543
20Nov23_044259|  -0.76611 -1.39540  0.28672  0.51751  0.72656 -0.65978  0.44566]
20Nov23_044259| [-1.03893  0.46076 -0.08662 -0.52243 -0.41836  0.85811 -0.86078  0.93975
20Nov23_044259|  -0.17006 -0.63327  0.74410  0.70958  1.39514  0.35044  0.87490]
20Nov23_044259| [ 1.54246 -0.70391 -0.91033  1.89604  0.46300 -0.13194 -0.43312  0.91185
20Nov23_044259|  -0.49534 -1.06771  0.38325 -1.29257 -0.73563 -1.04282 -0.39890]
20Nov23_044259| [-0.79484 -0.73094  1.55911 -0.27683  0.74301  0.65244 -1.70505  0.26757
20Nov23_044259|  -1.24152 -0.51986 -0.91341 -0.27940 -0.78858 -0.03302  0.36902]
20Nov23_044259| [-0.52894 -0.45939  0.71874 -1.10270 -0.31797 -1.23160 -0.28378  0.28717
20Nov23_044259|  -0.95275  0.83782 -0.51558 -0.40856 -0.70669 -0.31466  0.04528]
20Nov23_044259| [-0.81167 -0.21989  0.25817 -0.60778 -0.97270  0.42051  0.05410  0.81779
20Nov23_044259|  -0.94129  0.37341 -0.02587 -1.69395 -1.66843  0.14977 -1.29684]
20Nov23_044259| [ 0.18812 -1.04226 -0.19694 -0.90997  0.07427 -1.36961 -0.68391  1.29857
20Nov23_044259|  -1.58449 -1.19082 -1.19331 -0.28466  0.45438  0.59896 -0.09320]
20Nov23_044259| [ 0.46661 -1.82518  0.34643  0.42851  0.74486  1.16437 -1.33420  0.48093
20Nov23_044259|   0.66350 -1.58536  1.36313  1.64685  0.50624 -0.08332  0.16742]
20Nov23_044259| [ 0.83611 -1.02550  0.80906  0.82930  0.96028  0.21344  0.43399 -1.26536
20Nov23_044259|  -0.08786  0.56148  0.56968 -0.83275  0.47723  1.01280 -0.61349]
20Nov23_044259| [ 0.38265 -1.34334  0.19600 -0.79295  0.52286  0.28619  1.51312  0.85224
20Nov23_044259|   1.62111  1.09962  0.16420 -0.44606 -1.11225  1.26263  1.87372]
20Nov23_044259| [-0.57357 -0.55004 -1.15617  0.42990  0.23652 -0.13154 -1.45382  0.27475
20Nov23_044259|  -0.64777 -0.51002 -0.63579 -0.59520 -0.00340  0.31749  0.18432]]
20Nov23_044259|-- Bias --
20Nov23_044259|[ 1.38477 -0.37130 -0.13609 -0.85960 -0.92209 -0.27950  0.84767 -0.72498
20Nov23_044259| -0.02423  1.22888 -0.06124 -0.44945 -0.13271 -0.02930 -0.90463]
20Nov23_044259|Layer 1:
20Nov23_044259|-- Config --
20Nov23_044259|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 15], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_044259|-- Weights --
20Nov23_044259|[[ 0.67379 -1.05055]
20Nov23_044259| [-0.28290 -0.06835]
20Nov23_044259| [ 0.37387  0.47814]
20Nov23_044259| [ 0.58602 -0.61286]
20Nov23_044259| [-0.34764  0.50916]
20Nov23_044259| [-0.54241 -0.48178]
20Nov23_044259| [ 0.78853 -0.03736]
20Nov23_044259| [-0.61206 -0.05827]
20Nov23_044259| [-0.21855  1.26722]
20Nov23_044259| [-1.67530  1.48281]
20Nov23_044259| [-0.42903  0.74587]
20Nov23_044259| [ 0.09435 -1.16066]
20Nov23_044259| [-0.06102 -0.22933]
20Nov23_044259| [ 1.05118 -0.41105]
20Nov23_044259| [ 0.89464  0.71066]]
20Nov23_044259|-- Bias --
20Nov23_044259|[-0.89499  0.52392]
20Nov23_044259|Predicting the validation and test data with the Best final individual.
20Nov23_044304| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_044304|-----------  ------------------  --------------------  ----------
20Nov23_044304|Validation         41.30                  15            0.02062
20Nov23_044304|   Test            36.32                  15            0.00596
20Nov23_044304|-------------------------- Test #11 --------------------------
20Nov23_044304|Best final individual weights
20Nov23_044304|Individual:
20Nov23_044304|-- Constant hidden layers --
20Nov23_044304|False
20Nov23_044304|Layer 0:
20Nov23_044304|-- Config --
20Nov23_044304|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 15, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_044304|-- Weights --
20Nov23_044304|[[ 0.42691  0.29758  0.52422 -0.54807 -0.00317 -1.10737  0.66615 -0.46744
20Nov23_044304|   0.89578  0.22818 -0.07631 -0.76947 -0.46817 -0.21265 -0.85367]
20Nov23_044304| [-0.77699  0.41355 -1.18759  0.58503  0.11262 -0.77177 -0.87309  0.55877
20Nov23_044304|   0.49143  0.60359  0.78317 -2.01143 -0.18524  0.77837 -1.58646]
20Nov23_044304| [-0.05520  1.48797 -0.98303  0.44607  0.57229  0.01093  0.45399 -0.36869
20Nov23_044304|   1.25502 -2.04679  0.52420 -0.63251 -1.20841 -1.23667 -0.50506]
20Nov23_044304| [-0.15390 -0.12069  0.93121  0.62856 -0.47194  1.90773  0.12418 -0.02385
20Nov23_044304|   0.25845  0.67909 -0.74973 -1.14428 -0.54709 -1.03812  0.41810]
20Nov23_044304| [ 0.78184 -1.02634 -0.50414 -1.33713 -0.12806 -0.25092  1.03068 -1.53814
20Nov23_044304|   0.61719 -0.37364 -0.16927  0.25844 -1.59357  0.03242 -0.43857]
20Nov23_044304| [-1.51161  0.28379  0.11711  1.41276  1.94477 -1.13581 -0.16030 -0.98811
20Nov23_044304|  -0.74563  0.47408  1.31199  0.25822 -0.39431  0.99731  0.10765]
20Nov23_044304| [-0.06246 -0.55106 -0.66587 -0.81741 -0.90947 -0.55317  0.91670 -0.20333
20Nov23_044304|   0.16840 -0.45981  0.55694  1.11849  2.39357 -0.67350  0.20551]
20Nov23_044304| [ 0.47039 -1.74884  1.06361  0.87013 -1.27871 -0.23461 -0.85571  0.11193
20Nov23_044304|   1.28638  1.75207 -0.89037 -0.68407  0.35909 -0.54462 -0.10916]
20Nov23_044304| [-0.66100  1.52516  0.33780 -0.06402 -1.30311  2.21049  0.94191 -0.16126
20Nov23_044304|   0.77832 -0.93202  0.12018  0.28667  0.60154  0.67235  0.59619]
20Nov23_044304| [ 0.75099  1.36528 -1.73960 -1.50392  0.42261 -0.97005 -0.91943 -1.36861
20Nov23_044304|  -0.67430 -0.64244 -0.75113  1.74554  0.65154 -0.07884  0.24832]
20Nov23_044304| [ 1.53921 -0.26881 -0.59691  0.18529  0.48024 -0.98931 -1.54877  0.09832
20Nov23_044304|   1.16540  1.02141 -0.79718  1.33652  1.32572 -1.05063 -0.59539]
20Nov23_044304| [ 0.24418  0.35593 -0.10494 -1.30488  1.09288 -0.42662 -0.57142  0.49472
20Nov23_044304|   0.69921  0.62190  1.18692  0.10424 -0.45179  0.21910  0.01208]
20Nov23_044304| [ 0.67743 -0.19633  0.24381 -0.30061  0.08343 -0.33063 -0.09417 -0.29616
20Nov23_044304|  -0.06241 -1.05399  2.07564 -0.84708  0.83477 -0.41045  1.39502]
20Nov23_044304| [-0.03313 -0.77540  0.75142 -1.09279  1.86636 -0.79280 -0.54517 -0.28329
20Nov23_044304|   1.65999 -1.12225 -1.39221  0.11678 -1.17849 -0.62609 -0.37682]
20Nov23_044304| [ 0.05688 -0.19939 -0.40529 -0.51524 -0.26279  0.50723  0.33124  0.59534
20Nov23_044304|   0.83706  0.14251  0.82221 -0.63467  0.55955 -1.01568  0.21284]
20Nov23_044304| [ 0.01208  0.01410  1.11235 -0.49398  1.55853  0.43249  0.08756  0.00921
20Nov23_044304|  -0.71567 -0.38946 -0.90949 -0.83809 -0.05624  0.23786  0.05994]
20Nov23_044304| [-0.35205 -0.09450  2.24445  0.53880 -0.40180 -0.46765 -0.12446 -1.32593
20Nov23_044304|   1.41826 -0.76602  0.63376  1.18055 -0.53400  0.37624 -0.97579]
20Nov23_044304| [ 2.22050  0.05952 -1.19940  0.70861  1.41717 -0.26877 -0.94211 -1.40332
20Nov23_044304|   0.43003 -0.89869 -1.10584 -0.06625  0.31384 -0.10143  1.04961]
20Nov23_044304| [ 0.21289 -0.11012  1.49023  1.14376 -0.65338  0.26810 -0.85944  1.17660
20Nov23_044304|  -0.47870 -0.86877  0.44700  0.03584 -0.98074 -0.78054  0.03734]
20Nov23_044304| [ 0.28067  0.39235  1.41028 -0.15688 -0.54646  1.67606  0.42347  0.49702
20Nov23_044304|  -0.87937 -0.46845  1.00348 -0.53170 -1.12293 -1.01729  0.08005]
20Nov23_044304| [-1.14499  0.21662  0.15572  0.25399 -0.11350  0.09781 -0.60481 -0.96573
20Nov23_044304|   1.28182 -0.69592 -0.07493 -0.15830  1.71185 -1.62962  0.07644]
20Nov23_044304| [ 0.22980  0.61617 -0.58762 -1.53387  0.28371 -0.27785 -1.01772  0.18418
20Nov23_044304|   2.29950 -0.81522 -0.54903  0.50229  0.43645 -1.39068  1.50836]
20Nov23_044304| [ 1.26701  0.34500 -0.87987 -0.44065  1.23200 -1.45523  0.41462 -0.45891
20Nov23_044304|  -1.65629  1.36545 -0.16045  0.01440 -0.19117  1.01491 -1.56428]
20Nov23_044304| [-0.50801 -0.18680 -0.13795 -0.82892  0.04078  1.05055 -0.42182  0.28003
20Nov23_044304|  -0.17800 -0.94982 -1.60567 -0.74657 -0.37202 -0.77117  0.22728]
20Nov23_044304| [ 0.11223 -0.88960 -0.03771  0.68481 -1.13907 -1.64770 -2.08633  2.59999
20Nov23_044304|   0.70704 -1.10352 -0.73587  0.64618  0.18789 -0.56185 -0.00473]
20Nov23_044304| [-0.44394  1.09725  0.51635  0.38580 -1.13990  0.40442 -0.52209  0.10404
20Nov23_044304|  -0.15833  0.12255 -0.21853 -0.42496  1.00447  0.73146 -0.63667]
20Nov23_044304| [ 0.10066  1.40237  0.09464  0.72661 -1.80184 -0.06104 -0.34136 -0.51537
20Nov23_044304|  -1.66542 -0.55066 -2.56233 -0.02383 -0.84513 -1.61262 -0.51402]
20Nov23_044304| [-0.87960  0.23358 -0.52134  0.40047 -0.71106 -1.34728 -0.41823 -0.22333
20Nov23_044304|  -0.24686  1.65698 -1.30747 -0.69169 -0.66251  0.75459 -0.96660]
20Nov23_044304| [ 0.06230  1.20678 -0.23045 -0.84286 -0.22852  0.93298  0.14893  0.50809
20Nov23_044304|   0.14889 -0.72929 -0.24429  1.56028  1.22272  0.91747  0.36855]
20Nov23_044304| [-0.17377  1.14562  0.85539 -0.63699 -1.04190  0.12303 -0.72049 -0.08881
20Nov23_044304|  -0.90310  1.31653 -0.05204  0.40329 -0.48401 -0.36525 -0.46378]
20Nov23_044304| [ 0.09015 -0.62972 -0.73537  0.17011  0.27345 -0.55471  0.04517 -1.18609
20Nov23_044304|  -0.58628  0.49196 -0.58326  0.30330  0.51502  0.03433  0.04217]
20Nov23_044304| [ 0.86282 -0.84858 -1.43016 -0.52856  0.03054  0.44886  0.57046 -0.35864
20Nov23_044304|  -1.71832  0.24280 -0.89086 -0.78176  0.35162  0.30409 -0.02131]
20Nov23_044304| [ 1.05695  0.97767 -1.00230 -0.01291  0.04290 -0.09954  0.88877 -1.02809
20Nov23_044304|  -1.32144  0.07652  0.09972 -1.00606 -1.32542  0.05830 -0.38045]
20Nov23_044304| [ 0.43701 -1.48958 -0.15290 -0.28863  0.74501  0.03579 -1.09314 -0.86026
20Nov23_044304|   1.02886  1.16551 -1.01948 -1.43095 -1.82196 -0.89176 -0.81819]
20Nov23_044304| [-0.73966  0.22000  1.42394  0.53847 -2.33016 -0.57383  0.30702 -0.26322
20Nov23_044304|  -1.01442  0.05468 -0.23153 -0.06345  1.16376 -0.09296 -0.53408]
20Nov23_044304| [ 0.21706  1.28120  0.03908 -0.45157  0.48998  0.08854  0.00582  0.77533
20Nov23_044304|  -0.45924  0.03863 -0.73519 -0.00919 -1.16571  1.56297 -0.69370]
20Nov23_044304| [-2.08881 -0.97910  0.17069  0.79842  0.31541 -0.19526  0.45634  1.01009
20Nov23_044304|   0.59365 -0.01322  1.78356  1.44269  0.58775 -0.50228 -0.28648]
20Nov23_044304| [-1.12486  0.73663  0.56411  0.18444 -1.61639  1.08550  0.08219 -0.90988
20Nov23_044304|  -0.32404  0.81985  0.42006 -0.30815 -0.23312 -1.18708 -0.01110]
20Nov23_044304| [-0.30490 -1.30488 -1.53248 -0.79287  1.01787 -0.71421 -1.83065  0.46204
20Nov23_044304|  -0.31745  0.01163 -0.78217 -0.08380 -0.93485  0.93025 -1.11372]
20Nov23_044304| [-0.16328  1.13418 -0.55347 -0.46779  1.07552  0.66229 -0.21371  0.92252
20Nov23_044304|   0.55318  0.22002 -0.20203  0.71337  0.07093 -0.67508 -0.36308]
20Nov23_044304| [-0.14015 -0.56332  0.42102 -0.18024 -0.17774 -1.39429  0.65512  0.86385
20Nov23_044304|   0.74911  0.68266 -0.21078 -0.90494  0.19014 -0.64455  0.30027]
20Nov23_044304| [-0.74732 -0.00467  0.93348 -0.20600  0.55633 -0.56408 -0.45634 -0.20303
20Nov23_044304|  -0.13201 -1.51600  0.26075 -0.89582 -1.24197  0.63267  1.55172]
20Nov23_044304| [ 0.41456 -0.85489  0.02298  0.06353  0.81855  0.03156 -0.48615 -0.00658
20Nov23_044304|  -0.04895 -0.57287  0.20380  1.04986  0.97412 -0.47486  0.49494]
20Nov23_044304| [ 0.77080 -0.45784  0.11136  0.71105 -0.39395  0.40195 -0.43665  1.07323
20Nov23_044304|   0.43760  0.26785 -0.30587 -0.09075  0.40279  1.01923 -1.75405]
20Nov23_044304| [-0.88852  0.02533  1.17656  0.61764 -0.88512 -2.05323 -0.20657  0.56943
20Nov23_044304|  -0.79923 -0.05065  0.86607  1.99813 -0.99948 -0.10370  0.97637]
20Nov23_044304| [ 0.15692 -0.81947 -0.03219  0.05575  0.45531  1.62288 -0.76175 -0.80154
20Nov23_044304|  -1.50942 -0.89066 -0.37832  0.57865  2.24774  1.50483 -0.01312]
20Nov23_044304| [ 0.88566 -1.32158  1.07146  0.66710  0.27661  0.21144  0.50741  1.07543
20Nov23_044304|  -0.76611 -1.39540  0.28672  0.51751  0.72656 -0.65978  0.44566]
20Nov23_044304| [-1.03893  0.46076 -0.08662 -0.52243 -0.41836  0.85811 -0.86078  0.93975
20Nov23_044304|  -0.17006 -0.63327  0.74410  0.70958  1.39514  0.35044  0.87490]
20Nov23_044304| [ 1.54246 -0.70391 -0.91033  1.89604  0.46300 -0.13194 -0.43312  0.91185
20Nov23_044304|  -0.49534 -1.06771  0.38325 -1.29257 -0.73563 -1.04282 -0.39890]
20Nov23_044304| [-0.79484 -0.73094  1.55911 -0.27683  0.74301  0.65244 -1.70505  0.26757
20Nov23_044304|  -1.24152 -0.51986 -0.91341 -0.27940 -0.78858 -0.03302  0.36902]
20Nov23_044304| [-0.52894 -0.45939  0.71874 -1.10270 -0.31797 -1.23160 -0.28378  0.28717
20Nov23_044304|  -0.95275  0.83782 -0.51558 -0.40856 -0.70669 -0.31466  0.04528]
20Nov23_044304| [-0.81167 -0.21989  0.25817 -0.60778 -0.97270  0.42051  0.05410  0.81779
20Nov23_044304|  -0.94129  0.37341 -0.02587 -1.69395 -1.66843  0.14977 -1.29684]
20Nov23_044304| [ 0.18812 -1.04226 -0.19694 -0.90997  0.07427 -1.36961 -0.68391  1.29857
20Nov23_044304|  -1.58449 -1.19082 -1.19331 -0.28466  0.45438  0.59896 -0.09320]
20Nov23_044304| [ 0.46661 -1.82518  0.34643  0.42851  0.74486  1.16437 -1.33420  0.48093
20Nov23_044304|   0.66350 -1.58536  1.36313  1.64685  0.50624 -0.08332  0.16742]
20Nov23_044304| [ 0.83611 -1.02550  0.80906  0.82930  0.96028  0.21344  0.43399 -1.26536
20Nov23_044304|  -0.08786  0.56148  0.56968 -0.83275  0.47723  1.01280 -0.61349]
20Nov23_044304| [ 0.38265 -1.34334  0.19600 -0.79295  0.52286  0.28619  1.51312  0.85224
20Nov23_044304|   1.62111  1.09962  0.16420 -0.44606 -1.11225  1.26263  1.87372]
20Nov23_044304| [-0.57357 -0.55004 -1.15617  0.42990  0.23652 -0.13154 -1.45382  0.27475
20Nov23_044304|  -0.64777 -0.51002 -0.63579 -0.59520 -0.00340  0.31749  0.18432]]
20Nov23_044304|-- Bias --
20Nov23_044304|[ 1.38477 -0.37130 -0.13609 -0.85960 -0.92209 -0.27950  0.84767 -0.72498
20Nov23_044304| -0.02423  1.22888 -0.06124 -0.44945 -0.13271 -0.02930 -0.90463]
20Nov23_044304|Layer 1:
20Nov23_044304|-- Config --
20Nov23_044304|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 15], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_044304|-- Weights --
20Nov23_044304|[[ 0.67379 -1.05055]
20Nov23_044304| [-0.28290 -0.06835]
20Nov23_044304| [ 0.37387  0.47814]
20Nov23_044304| [ 0.58602 -0.61286]
20Nov23_044304| [-0.34764  0.50916]
20Nov23_044304| [-0.54241 -0.48178]
20Nov23_044304| [ 0.78853 -0.03736]
20Nov23_044304| [-0.61206 -0.05827]
20Nov23_044304| [-0.21855  1.26722]
20Nov23_044304| [-1.67530  1.48281]
20Nov23_044304| [-0.42903  0.74587]
20Nov23_044304| [ 0.09435 -1.16066]
20Nov23_044304| [-0.06102 -0.22933]
20Nov23_044304| [ 1.05118 -0.41105]
20Nov23_044304| [ 0.89464  0.71066]]
20Nov23_044304|-- Bias --
20Nov23_044304|[-0.89499  0.52392]
20Nov23_044304|Predicting the validation and test data with the Best final individual.
20Nov23_044310| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_044310|-----------  ------------------  --------------------  ----------
20Nov23_044310|Validation         39.83                  15            0.09581
20Nov23_044310|   Test            34.93                  15            0.09286
20Nov23_044310|-------------------------- Test #12 --------------------------
20Nov23_044310|Best final individual weights
20Nov23_044310|Individual:
20Nov23_044310|-- Constant hidden layers --
20Nov23_044310|False
20Nov23_044310|Layer 0:
20Nov23_044310|-- Config --
20Nov23_044310|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 15, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_044310|-- Weights --
20Nov23_044310|[[ 0.42691  0.29758  0.52422 -0.54807 -0.00317 -1.10737  0.66615 -0.46744
20Nov23_044310|   0.89578  0.22818 -0.07631 -0.76947 -0.46817 -0.21265 -0.85367]
20Nov23_044310| [-0.77699  0.41355 -1.18759  0.58503  0.11262 -0.77177 -0.87309  0.55877
20Nov23_044310|   0.49143  0.60359  0.78317 -2.01143 -0.18524  0.77837 -1.58646]
20Nov23_044310| [-0.05520  1.48797 -0.98303  0.44607  0.57229  0.01093  0.45399 -0.36869
20Nov23_044310|   1.25502 -2.04679  0.52420 -0.63251 -1.20841 -1.23667 -0.50506]
20Nov23_044310| [-0.15390 -0.12069  0.93121  0.62856 -0.47194  1.90773  0.12418 -0.02385
20Nov23_044310|   0.25845  0.67909 -0.74973 -1.14428 -0.54709 -1.03812  0.41810]
20Nov23_044310| [ 0.78184 -1.02634 -0.50414 -1.33713 -0.12806 -0.25092  1.03068 -1.53814
20Nov23_044310|   0.61719 -0.37364 -0.16927  0.25844 -1.59357  0.03242 -0.43857]
20Nov23_044310| [-1.51161  0.28379  0.11711  1.41276  1.94477 -1.13581 -0.16030 -0.98811
20Nov23_044310|  -0.74563  0.47408  1.31199  0.25822 -0.39431  0.99731  0.10765]
20Nov23_044310| [-0.06246 -0.55106 -0.66587 -0.81741 -0.90947 -0.55317  0.91670 -0.20333
20Nov23_044310|   0.16840 -0.45981  0.55694  1.11849  2.39357 -0.67350  0.20551]
20Nov23_044310| [ 0.47039 -1.74884  1.06361  0.87013 -1.27871 -0.23461 -0.85571  0.11193
20Nov23_044310|   1.28638  1.75207 -0.89037 -0.68407  0.35909 -0.54462 -0.10916]
20Nov23_044310| [-0.66100  1.52516  0.33780 -0.06402 -1.30311  2.21049  0.94191 -0.16126
20Nov23_044310|   0.77832 -0.93202  0.12018  0.28667  0.60154  0.67235  0.59619]
20Nov23_044310| [ 0.75099  1.36528 -1.73960 -1.50392  0.42261 -0.97005 -0.91943 -1.36861
20Nov23_044310|  -0.67430 -0.64244 -0.75113  1.74554  0.65154 -0.07884  0.24832]
20Nov23_044310| [ 1.53921 -0.26881 -0.59691  0.18529  0.48024 -0.98931 -1.54877  0.09832
20Nov23_044310|   1.16540  1.02141 -0.79718  1.33652  1.32572 -1.05063 -0.59539]
20Nov23_044310| [ 0.24418  0.35593 -0.10494 -1.30488  1.09288 -0.42662 -0.57142  0.49472
20Nov23_044310|   0.69921  0.62190  1.18692  0.10424 -0.45179  0.21910  0.01208]
20Nov23_044310| [ 0.67743 -0.19633  0.24381 -0.30061  0.08343 -0.33063 -0.09417 -0.29616
20Nov23_044310|  -0.06241 -1.05399  2.07564 -0.84708  0.83477 -0.41045  1.39502]
20Nov23_044310| [-0.03313 -0.77540  0.75142 -1.09279  1.86636 -0.79280 -0.54517 -0.28329
20Nov23_044310|   1.65999 -1.12225 -1.39221  0.11678 -1.17849 -0.62609 -0.37682]
20Nov23_044310| [ 0.05688 -0.19939 -0.40529 -0.51524 -0.26279  0.50723  0.33124  0.59534
20Nov23_044310|   0.83706  0.14251  0.82221 -0.63467  0.55955 -1.01568  0.21284]
20Nov23_044310| [ 0.01208  0.01410  1.11235 -0.49398  1.55853  0.43249  0.08756  0.00921
20Nov23_044310|  -0.71567 -0.38946 -0.90949 -0.83809 -0.05624  0.23786  0.05994]
20Nov23_044310| [-0.35205 -0.09450  2.24445  0.53880 -0.40180 -0.46765 -0.12446 -1.32593
20Nov23_044310|   1.41826 -0.76602  0.63376  1.18055 -0.53400  0.37624 -0.97579]
20Nov23_044310| [ 2.22050  0.05952 -1.19940  0.70861  1.41717 -0.26877 -0.94211 -1.40332
20Nov23_044310|   0.43003 -0.89869 -1.10584 -0.06625  0.31384 -0.10143  1.04961]
20Nov23_044310| [ 0.21289 -0.11012  1.49023  1.14376 -0.65338  0.26810 -0.85944  1.17660
20Nov23_044310|  -0.47870 -0.86877  0.44700  0.03584 -0.98074 -0.78054  0.03734]
20Nov23_044310| [ 0.28067  0.39235  1.41028 -0.15688 -0.54646  1.67606  0.42347  0.49702
20Nov23_044310|  -0.87937 -0.46845  1.00348 -0.53170 -1.12293 -1.01729  0.08005]
20Nov23_044310| [-1.14499  0.21662  0.15572  0.25399 -0.11350  0.09781 -0.60481 -0.96573
20Nov23_044310|   1.28182 -0.69592 -0.07493 -0.15830  1.71185 -1.62962  0.07644]
20Nov23_044310| [ 0.22980  0.61617 -0.58762 -1.53387  0.28371 -0.27785 -1.01772  0.18418
20Nov23_044310|   2.29950 -0.81522 -0.54903  0.50229  0.43645 -1.39068  1.50836]
20Nov23_044310| [ 1.26701  0.34500 -0.87987 -0.44065  1.23200 -1.45523  0.41462 -0.45891
20Nov23_044310|  -1.65629  1.36545 -0.16045  0.01440 -0.19117  1.01491 -1.56428]
20Nov23_044310| [-0.50801 -0.18680 -0.13795 -0.82892  0.04078  1.05055 -0.42182  0.28003
20Nov23_044310|  -0.17800 -0.94982 -1.60567 -0.74657 -0.37202 -0.77117  0.22728]
20Nov23_044310| [ 0.11223 -0.88960 -0.03771  0.68481 -1.13907 -1.64770 -2.08633  2.59999
20Nov23_044310|   0.70704 -1.10352 -0.73587  0.64618  0.18789 -0.56185 -0.00473]
20Nov23_044310| [-0.44394  1.09725  0.51635  0.38580 -1.13990  0.40442 -0.52209  0.10404
20Nov23_044310|  -0.15833  0.12255 -0.21853 -0.42496  1.00447  0.73146 -0.63667]
20Nov23_044310| [ 0.10066  1.40237  0.09464  0.72661 -1.80184 -0.06104 -0.34136 -0.51537
20Nov23_044310|  -1.66542 -0.55066 -2.56233 -0.02383 -0.84513 -1.61262 -0.51402]
20Nov23_044310| [-0.87960  0.23358 -0.52134  0.40047 -0.71106 -1.34728 -0.41823 -0.22333
20Nov23_044310|  -0.24686  1.65698 -1.30747 -0.69169 -0.66251  0.75459 -0.96660]
20Nov23_044310| [ 0.06230  1.20678 -0.23045 -0.84286 -0.22852  0.93298  0.14893  0.50809
20Nov23_044310|   0.14889 -0.72929 -0.24429  1.56028  1.22272  0.91747  0.36855]
20Nov23_044310| [-0.17377  1.14562  0.85539 -0.63699 -1.04190  0.12303 -0.72049 -0.08881
20Nov23_044310|  -0.90310  1.31653 -0.05204  0.40329 -0.48401 -0.36525 -0.46378]
20Nov23_044310| [ 0.09015 -0.62972 -0.73537  0.17011  0.27345 -0.55471  0.04517 -1.18609
20Nov23_044310|  -0.58628  0.49196 -0.58326  0.30330  0.51502  0.03433  0.04217]
20Nov23_044310| [ 0.86282 -0.84858 -1.43016 -0.52856  0.03054  0.44886  0.57046 -0.35864
20Nov23_044310|  -1.71832  0.24280 -0.89086 -0.78176  0.35162  0.30409 -0.02131]
20Nov23_044310| [ 1.05695  0.97767 -1.00230 -0.01291  0.04290 -0.09954  0.88877 -1.02809
20Nov23_044310|  -1.32144  0.07652  0.09972 -1.00606 -1.32542  0.05830 -0.38045]
20Nov23_044310| [ 0.43701 -1.48958 -0.15290 -0.28863  0.74501  0.03579 -1.09314 -0.86026
20Nov23_044310|   1.02886  1.16551 -1.01948 -1.43095 -1.82196 -0.89176 -0.81819]
20Nov23_044310| [-0.73966  0.22000  1.42394  0.53847 -2.33016 -0.57383  0.30702 -0.26322
20Nov23_044310|  -1.01442  0.05468 -0.23153 -0.06345  1.16376 -0.09296 -0.53408]
20Nov23_044310| [ 0.21706  1.28120  0.03908 -0.45157  0.48998  0.08854  0.00582  0.77533
20Nov23_044310|  -0.45924  0.03863 -0.73519 -0.00919 -1.16571  1.56297 -0.69370]
20Nov23_044310| [-2.08881 -0.97910  0.17069  0.79842  0.31541 -0.19526  0.45634  1.01009
20Nov23_044310|   0.59365 -0.01322  1.78356  1.44269  0.58775 -0.50228 -0.28648]
20Nov23_044310| [-1.12486  0.73663  0.56411  0.18444 -1.61639  1.08550  0.08219 -0.90988
20Nov23_044310|  -0.32404  0.81985  0.42006 -0.30815 -0.23312 -1.18708 -0.01110]
20Nov23_044310| [-0.30490 -1.30488 -1.53248 -0.79287  1.01787 -0.71421 -1.83065  0.46204
20Nov23_044310|  -0.31745  0.01163 -0.78217 -0.08380 -0.93485  0.93025 -1.11372]
20Nov23_044310| [-0.16328  1.13418 -0.55347 -0.46779  1.07552  0.66229 -0.21371  0.92252
20Nov23_044310|   0.55318  0.22002 -0.20203  0.71337  0.07093 -0.67508 -0.36308]
20Nov23_044310| [-0.14015 -0.56332  0.42102 -0.18024 -0.17774 -1.39429  0.65512  0.86385
20Nov23_044310|   0.74911  0.68266 -0.21078 -0.90494  0.19014 -0.64455  0.30027]
20Nov23_044310| [-0.74732 -0.00467  0.93348 -0.20600  0.55633 -0.56408 -0.45634 -0.20303
20Nov23_044310|  -0.13201 -1.51600  0.26075 -0.89582 -1.24197  0.63267  1.55172]
20Nov23_044310| [ 0.41456 -0.85489  0.02298  0.06353  0.81855  0.03156 -0.48615 -0.00658
20Nov23_044310|  -0.04895 -0.57287  0.20380  1.04986  0.97412 -0.47486  0.49494]
20Nov23_044310| [ 0.77080 -0.45784  0.11136  0.71105 -0.39395  0.40195 -0.43665  1.07323
20Nov23_044310|   0.43760  0.26785 -0.30587 -0.09075  0.40279  1.01923 -1.75405]
20Nov23_044310| [-0.88852  0.02533  1.17656  0.61764 -0.88512 -2.05323 -0.20657  0.56943
20Nov23_044310|  -0.79923 -0.05065  0.86607  1.99813 -0.99948 -0.10370  0.97637]
20Nov23_044310| [ 0.15692 -0.81947 -0.03219  0.05575  0.45531  1.62288 -0.76175 -0.80154
20Nov23_044310|  -1.50942 -0.89066 -0.37832  0.57865  2.24774  1.50483 -0.01312]
20Nov23_044310| [ 0.88566 -1.32158  1.07146  0.66710  0.27661  0.21144  0.50741  1.07543
20Nov23_044310|  -0.76611 -1.39540  0.28672  0.51751  0.72656 -0.65978  0.44566]
20Nov23_044310| [-1.03893  0.46076 -0.08662 -0.52243 -0.41836  0.85811 -0.86078  0.93975
20Nov23_044310|  -0.17006 -0.63327  0.74410  0.70958  1.39514  0.35044  0.87490]
20Nov23_044310| [ 1.54246 -0.70391 -0.91033  1.89604  0.46300 -0.13194 -0.43312  0.91185
20Nov23_044310|  -0.49534 -1.06771  0.38325 -1.29257 -0.73563 -1.04282 -0.39890]
20Nov23_044310| [-0.79484 -0.73094  1.55911 -0.27683  0.74301  0.65244 -1.70505  0.26757
20Nov23_044310|  -1.24152 -0.51986 -0.91341 -0.27940 -0.78858 -0.03302  0.36902]
20Nov23_044310| [-0.52894 -0.45939  0.71874 -1.10270 -0.31797 -1.23160 -0.28378  0.28717
20Nov23_044310|  -0.95275  0.83782 -0.51558 -0.40856 -0.70669 -0.31466  0.04528]
20Nov23_044310| [-0.81167 -0.21989  0.25817 -0.60778 -0.97270  0.42051  0.05410  0.81779
20Nov23_044310|  -0.94129  0.37341 -0.02587 -1.69395 -1.66843  0.14977 -1.29684]
20Nov23_044310| [ 0.18812 -1.04226 -0.19694 -0.90997  0.07427 -1.36961 -0.68391  1.29857
20Nov23_044310|  -1.58449 -1.19082 -1.19331 -0.28466  0.45438  0.59896 -0.09320]
20Nov23_044310| [ 0.46661 -1.82518  0.34643  0.42851  0.74486  1.16437 -1.33420  0.48093
20Nov23_044310|   0.66350 -1.58536  1.36313  1.64685  0.50624 -0.08332  0.16742]
20Nov23_044310| [ 0.83611 -1.02550  0.80906  0.82930  0.96028  0.21344  0.43399 -1.26536
20Nov23_044310|  -0.08786  0.56148  0.56968 -0.83275  0.47723  1.01280 -0.61349]
20Nov23_044310| [ 0.38265 -1.34334  0.19600 -0.79295  0.52286  0.28619  1.51312  0.85224
20Nov23_044310|   1.62111  1.09962  0.16420 -0.44606 -1.11225  1.26263  1.87372]
20Nov23_044310| [-0.57357 -0.55004 -1.15617  0.42990  0.23652 -0.13154 -1.45382  0.27475
20Nov23_044310|  -0.64777 -0.51002 -0.63579 -0.59520 -0.00340  0.31749  0.18432]]
20Nov23_044310|-- Bias --
20Nov23_044310|[ 1.38477 -0.37130 -0.13609 -0.85960 -0.92209 -0.27950  0.84767 -0.72498
20Nov23_044310| -0.02423  1.22888 -0.06124 -0.44945 -0.13271 -0.02930 -0.90463]
20Nov23_044310|Layer 1:
20Nov23_044310|-- Config --
20Nov23_044310|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 15], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_044310|-- Weights --
20Nov23_044310|[[ 0.67379 -1.05055]
20Nov23_044310| [-0.28290 -0.06835]
20Nov23_044310| [ 0.37387  0.47814]
20Nov23_044310| [ 0.58602 -0.61286]
20Nov23_044310| [-0.34764  0.50916]
20Nov23_044310| [-0.54241 -0.48178]
20Nov23_044310| [ 0.78853 -0.03736]
20Nov23_044310| [-0.61206 -0.05827]
20Nov23_044310| [-0.21855  1.26722]
20Nov23_044310| [-1.67530  1.48281]
20Nov23_044310| [-0.42903  0.74587]
20Nov23_044310| [ 0.09435 -1.16066]
20Nov23_044310| [-0.06102 -0.22933]
20Nov23_044310| [ 1.05118 -0.41105]
20Nov23_044310| [ 0.89464  0.71066]]
20Nov23_044310|-- Bias --
20Nov23_044310|[-0.89499  0.52392]
20Nov23_044310|Predicting the validation and test data with the Best final individual.
20Nov23_044316| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_044316|-----------  ------------------  --------------------  ----------
20Nov23_044316|Validation         40.61                  15            0.06606
20Nov23_044316|   Test            36.23                  15            0.02073
20Nov23_044316|-------------------------- Test #13 --------------------------
20Nov23_044316|Best final individual weights
20Nov23_044316|Individual:
20Nov23_044316|-- Constant hidden layers --
20Nov23_044316|False
20Nov23_044316|Layer 0:
20Nov23_044316|-- Config --
20Nov23_044316|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 15, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_044316|-- Weights --
20Nov23_044316|[[ 0.42691  0.29758  0.52422 -0.54807 -0.00317 -1.10737  0.66615 -0.46744
20Nov23_044316|   0.89578  0.22818 -0.07631 -0.76947 -0.46817 -0.21265 -0.85367]
20Nov23_044316| [-0.77699  0.41355 -1.18759  0.58503  0.11262 -0.77177 -0.87309  0.55877
20Nov23_044316|   0.49143  0.60359  0.78317 -2.01143 -0.18524  0.77837 -1.58646]
20Nov23_044316| [-0.05520  1.48797 -0.98303  0.44607  0.57229  0.01093  0.45399 -0.36869
20Nov23_044316|   1.25502 -2.04679  0.52420 -0.63251 -1.20841 -1.23667 -0.50506]
20Nov23_044316| [-0.15390 -0.12069  0.93121  0.62856 -0.47194  1.90773  0.12418 -0.02385
20Nov23_044316|   0.25845  0.67909 -0.74973 -1.14428 -0.54709 -1.03812  0.41810]
20Nov23_044316| [ 0.78184 -1.02634 -0.50414 -1.33713 -0.12806 -0.25092  1.03068 -1.53814
20Nov23_044316|   0.61719 -0.37364 -0.16927  0.25844 -1.59357  0.03242 -0.43857]
20Nov23_044316| [-1.51161  0.28379  0.11711  1.41276  1.94477 -1.13581 -0.16030 -0.98811
20Nov23_044316|  -0.74563  0.47408  1.31199  0.25822 -0.39431  0.99731  0.10765]
20Nov23_044316| [-0.06246 -0.55106 -0.66587 -0.81741 -0.90947 -0.55317  0.91670 -0.20333
20Nov23_044316|   0.16840 -0.45981  0.55694  1.11849  2.39357 -0.67350  0.20551]
20Nov23_044316| [ 0.47039 -1.74884  1.06361  0.87013 -1.27871 -0.23461 -0.85571  0.11193
20Nov23_044316|   1.28638  1.75207 -0.89037 -0.68407  0.35909 -0.54462 -0.10916]
20Nov23_044316| [-0.66100  1.52516  0.33780 -0.06402 -1.30311  2.21049  0.94191 -0.16126
20Nov23_044316|   0.77832 -0.93202  0.12018  0.28667  0.60154  0.67235  0.59619]
20Nov23_044316| [ 0.75099  1.36528 -1.73960 -1.50392  0.42261 -0.97005 -0.91943 -1.36861
20Nov23_044316|  -0.67430 -0.64244 -0.75113  1.74554  0.65154 -0.07884  0.24832]
20Nov23_044316| [ 1.53921 -0.26881 -0.59691  0.18529  0.48024 -0.98931 -1.54877  0.09832
20Nov23_044316|   1.16540  1.02141 -0.79718  1.33652  1.32572 -1.05063 -0.59539]
20Nov23_044316| [ 0.24418  0.35593 -0.10494 -1.30488  1.09288 -0.42662 -0.57142  0.49472
20Nov23_044316|   0.69921  0.62190  1.18692  0.10424 -0.45179  0.21910  0.01208]
20Nov23_044316| [ 0.67743 -0.19633  0.24381 -0.30061  0.08343 -0.33063 -0.09417 -0.29616
20Nov23_044316|  -0.06241 -1.05399  2.07564 -0.84708  0.83477 -0.41045  1.39502]
20Nov23_044316| [-0.03313 -0.77540  0.75142 -1.09279  1.86636 -0.79280 -0.54517 -0.28329
20Nov23_044316|   1.65999 -1.12225 -1.39221  0.11678 -1.17849 -0.62609 -0.37682]
20Nov23_044316| [ 0.05688 -0.19939 -0.40529 -0.51524 -0.26279  0.50723  0.33124  0.59534
20Nov23_044316|   0.83706  0.14251  0.82221 -0.63467  0.55955 -1.01568  0.21284]
20Nov23_044316| [ 0.01208  0.01410  1.11235 -0.49398  1.55853  0.43249  0.08756  0.00921
20Nov23_044316|  -0.71567 -0.38946 -0.90949 -0.83809 -0.05624  0.23786  0.05994]
20Nov23_044316| [-0.35205 -0.09450  2.24445  0.53880 -0.40180 -0.46765 -0.12446 -1.32593
20Nov23_044316|   1.41826 -0.76602  0.63376  1.18055 -0.53400  0.37624 -0.97579]
20Nov23_044316| [ 2.22050  0.05952 -1.19940  0.70861  1.41717 -0.26877 -0.94211 -1.40332
20Nov23_044316|   0.43003 -0.89869 -1.10584 -0.06625  0.31384 -0.10143  1.04961]
20Nov23_044316| [ 0.21289 -0.11012  1.49023  1.14376 -0.65338  0.26810 -0.85944  1.17660
20Nov23_044316|  -0.47870 -0.86877  0.44700  0.03584 -0.98074 -0.78054  0.03734]
20Nov23_044316| [ 0.28067  0.39235  1.41028 -0.15688 -0.54646  1.67606  0.42347  0.49702
20Nov23_044316|  -0.87937 -0.46845  1.00348 -0.53170 -1.12293 -1.01729  0.08005]
20Nov23_044316| [-1.14499  0.21662  0.15572  0.25399 -0.11350  0.09781 -0.60481 -0.96573
20Nov23_044316|   1.28182 -0.69592 -0.07493 -0.15830  1.71185 -1.62962  0.07644]
20Nov23_044316| [ 0.22980  0.61617 -0.58762 -1.53387  0.28371 -0.27785 -1.01772  0.18418
20Nov23_044316|   2.29950 -0.81522 -0.54903  0.50229  0.43645 -1.39068  1.50836]
20Nov23_044316| [ 1.26701  0.34500 -0.87987 -0.44065  1.23200 -1.45523  0.41462 -0.45891
20Nov23_044316|  -1.65629  1.36545 -0.16045  0.01440 -0.19117  1.01491 -1.56428]
20Nov23_044316| [-0.50801 -0.18680 -0.13795 -0.82892  0.04078  1.05055 -0.42182  0.28003
20Nov23_044316|  -0.17800 -0.94982 -1.60567 -0.74657 -0.37202 -0.77117  0.22728]
20Nov23_044316| [ 0.11223 -0.88960 -0.03771  0.68481 -1.13907 -1.64770 -2.08633  2.59999
20Nov23_044316|   0.70704 -1.10352 -0.73587  0.64618  0.18789 -0.56185 -0.00473]
20Nov23_044316| [-0.44394  1.09725  0.51635  0.38580 -1.13990  0.40442 -0.52209  0.10404
20Nov23_044316|  -0.15833  0.12255 -0.21853 -0.42496  1.00447  0.73146 -0.63667]
20Nov23_044316| [ 0.10066  1.40237  0.09464  0.72661 -1.80184 -0.06104 -0.34136 -0.51537
20Nov23_044316|  -1.66542 -0.55066 -2.56233 -0.02383 -0.84513 -1.61262 -0.51402]
20Nov23_044316| [-0.87960  0.23358 -0.52134  0.40047 -0.71106 -1.34728 -0.41823 -0.22333
20Nov23_044316|  -0.24686  1.65698 -1.30747 -0.69169 -0.66251  0.75459 -0.96660]
20Nov23_044316| [ 0.06230  1.20678 -0.23045 -0.84286 -0.22852  0.93298  0.14893  0.50809
20Nov23_044316|   0.14889 -0.72929 -0.24429  1.56028  1.22272  0.91747  0.36855]
20Nov23_044316| [-0.17377  1.14562  0.85539 -0.63699 -1.04190  0.12303 -0.72049 -0.08881
20Nov23_044316|  -0.90310  1.31653 -0.05204  0.40329 -0.48401 -0.36525 -0.46378]
20Nov23_044316| [ 0.09015 -0.62972 -0.73537  0.17011  0.27345 -0.55471  0.04517 -1.18609
20Nov23_044316|  -0.58628  0.49196 -0.58326  0.30330  0.51502  0.03433  0.04217]
20Nov23_044316| [ 0.86282 -0.84858 -1.43016 -0.52856  0.03054  0.44886  0.57046 -0.35864
20Nov23_044316|  -1.71832  0.24280 -0.89086 -0.78176  0.35162  0.30409 -0.02131]
20Nov23_044316| [ 1.05695  0.97767 -1.00230 -0.01291  0.04290 -0.09954  0.88877 -1.02809
20Nov23_044316|  -1.32144  0.07652  0.09972 -1.00606 -1.32542  0.05830 -0.38045]
20Nov23_044316| [ 0.43701 -1.48958 -0.15290 -0.28863  0.74501  0.03579 -1.09314 -0.86026
20Nov23_044316|   1.02886  1.16551 -1.01948 -1.43095 -1.82196 -0.89176 -0.81819]
20Nov23_044316| [-0.73966  0.22000  1.42394  0.53847 -2.33016 -0.57383  0.30702 -0.26322
20Nov23_044316|  -1.01442  0.05468 -0.23153 -0.06345  1.16376 -0.09296 -0.53408]
20Nov23_044316| [ 0.21706  1.28120  0.03908 -0.45157  0.48998  0.08854  0.00582  0.77533
20Nov23_044316|  -0.45924  0.03863 -0.73519 -0.00919 -1.16571  1.56297 -0.69370]
20Nov23_044316| [-2.08881 -0.97910  0.17069  0.79842  0.31541 -0.19526  0.45634  1.01009
20Nov23_044316|   0.59365 -0.01322  1.78356  1.44269  0.58775 -0.50228 -0.28648]
20Nov23_044316| [-1.12486  0.73663  0.56411  0.18444 -1.61639  1.08550  0.08219 -0.90988
20Nov23_044316|  -0.32404  0.81985  0.42006 -0.30815 -0.23312 -1.18708 -0.01110]
20Nov23_044316| [-0.30490 -1.30488 -1.53248 -0.79287  1.01787 -0.71421 -1.83065  0.46204
20Nov23_044316|  -0.31745  0.01163 -0.78217 -0.08380 -0.93485  0.93025 -1.11372]
20Nov23_044316| [-0.16328  1.13418 -0.55347 -0.46779  1.07552  0.66229 -0.21371  0.92252
20Nov23_044316|   0.55318  0.22002 -0.20203  0.71337  0.07093 -0.67508 -0.36308]
20Nov23_044316| [-0.14015 -0.56332  0.42102 -0.18024 -0.17774 -1.39429  0.65512  0.86385
20Nov23_044316|   0.74911  0.68266 -0.21078 -0.90494  0.19014 -0.64455  0.30027]
20Nov23_044316| [-0.74732 -0.00467  0.93348 -0.20600  0.55633 -0.56408 -0.45634 -0.20303
20Nov23_044316|  -0.13201 -1.51600  0.26075 -0.89582 -1.24197  0.63267  1.55172]
20Nov23_044316| [ 0.41456 -0.85489  0.02298  0.06353  0.81855  0.03156 -0.48615 -0.00658
20Nov23_044316|  -0.04895 -0.57287  0.20380  1.04986  0.97412 -0.47486  0.49494]
20Nov23_044316| [ 0.77080 -0.45784  0.11136  0.71105 -0.39395  0.40195 -0.43665  1.07323
20Nov23_044316|   0.43760  0.26785 -0.30587 -0.09075  0.40279  1.01923 -1.75405]
20Nov23_044316| [-0.88852  0.02533  1.17656  0.61764 -0.88512 -2.05323 -0.20657  0.56943
20Nov23_044316|  -0.79923 -0.05065  0.86607  1.99813 -0.99948 -0.10370  0.97637]
20Nov23_044316| [ 0.15692 -0.81947 -0.03219  0.05575  0.45531  1.62288 -0.76175 -0.80154
20Nov23_044316|  -1.50942 -0.89066 -0.37832  0.57865  2.24774  1.50483 -0.01312]
20Nov23_044316| [ 0.88566 -1.32158  1.07146  0.66710  0.27661  0.21144  0.50741  1.07543
20Nov23_044316|  -0.76611 -1.39540  0.28672  0.51751  0.72656 -0.65978  0.44566]
20Nov23_044316| [-1.03893  0.46076 -0.08662 -0.52243 -0.41836  0.85811 -0.86078  0.93975
20Nov23_044316|  -0.17006 -0.63327  0.74410  0.70958  1.39514  0.35044  0.87490]
20Nov23_044316| [ 1.54246 -0.70391 -0.91033  1.89604  0.46300 -0.13194 -0.43312  0.91185
20Nov23_044316|  -0.49534 -1.06771  0.38325 -1.29257 -0.73563 -1.04282 -0.39890]
20Nov23_044316| [-0.79484 -0.73094  1.55911 -0.27683  0.74301  0.65244 -1.70505  0.26757
20Nov23_044316|  -1.24152 -0.51986 -0.91341 -0.27940 -0.78858 -0.03302  0.36902]
20Nov23_044316| [-0.52894 -0.45939  0.71874 -1.10270 -0.31797 -1.23160 -0.28378  0.28717
20Nov23_044316|  -0.95275  0.83782 -0.51558 -0.40856 -0.70669 -0.31466  0.04528]
20Nov23_044316| [-0.81167 -0.21989  0.25817 -0.60778 -0.97270  0.42051  0.05410  0.81779
20Nov23_044316|  -0.94129  0.37341 -0.02587 -1.69395 -1.66843  0.14977 -1.29684]
20Nov23_044316| [ 0.18812 -1.04226 -0.19694 -0.90997  0.07427 -1.36961 -0.68391  1.29857
20Nov23_044316|  -1.58449 -1.19082 -1.19331 -0.28466  0.45438  0.59896 -0.09320]
20Nov23_044316| [ 0.46661 -1.82518  0.34643  0.42851  0.74486  1.16437 -1.33420  0.48093
20Nov23_044316|   0.66350 -1.58536  1.36313  1.64685  0.50624 -0.08332  0.16742]
20Nov23_044316| [ 0.83611 -1.02550  0.80906  0.82930  0.96028  0.21344  0.43399 -1.26536
20Nov23_044316|  -0.08786  0.56148  0.56968 -0.83275  0.47723  1.01280 -0.61349]
20Nov23_044316| [ 0.38265 -1.34334  0.19600 -0.79295  0.52286  0.28619  1.51312  0.85224
20Nov23_044316|   1.62111  1.09962  0.16420 -0.44606 -1.11225  1.26263  1.87372]
20Nov23_044316| [-0.57357 -0.55004 -1.15617  0.42990  0.23652 -0.13154 -1.45382  0.27475
20Nov23_044316|  -0.64777 -0.51002 -0.63579 -0.59520 -0.00340  0.31749  0.18432]]
20Nov23_044316|-- Bias --
20Nov23_044316|[ 1.38477 -0.37130 -0.13609 -0.85960 -0.92209 -0.27950  0.84767 -0.72498
20Nov23_044316| -0.02423  1.22888 -0.06124 -0.44945 -0.13271 -0.02930 -0.90463]
20Nov23_044316|Layer 1:
20Nov23_044316|-- Config --
20Nov23_044316|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 15], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_044316|-- Weights --
20Nov23_044316|[[ 0.67379 -1.05055]
20Nov23_044316| [-0.28290 -0.06835]
20Nov23_044316| [ 0.37387  0.47814]
20Nov23_044316| [ 0.58602 -0.61286]
20Nov23_044316| [-0.34764  0.50916]
20Nov23_044316| [-0.54241 -0.48178]
20Nov23_044316| [ 0.78853 -0.03736]
20Nov23_044316| [-0.61206 -0.05827]
20Nov23_044316| [-0.21855  1.26722]
20Nov23_044316| [-1.67530  1.48281]
20Nov23_044316| [-0.42903  0.74587]
20Nov23_044316| [ 0.09435 -1.16066]
20Nov23_044316| [-0.06102 -0.22933]
20Nov23_044316| [ 1.05118 -0.41105]
20Nov23_044316| [ 0.89464  0.71066]]
20Nov23_044316|-- Bias --
20Nov23_044316|[-0.89499  0.52392]
20Nov23_044316|Predicting the validation and test data with the Best final individual.
20Nov23_044321| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_044321|-----------  ------------------  --------------------  ----------
20Nov23_044321|Validation         41.91                  15            0.00517
20Nov23_044321|   Test            36.40                  15            0.01188
20Nov23_044321|-------------------------- Test #14 --------------------------
20Nov23_044321|Best final individual weights
20Nov23_044321|Individual:
20Nov23_044321|-- Constant hidden layers --
20Nov23_044321|False
20Nov23_044321|Layer 0:
20Nov23_044321|-- Config --
20Nov23_044321|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 15, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_044321|-- Weights --
20Nov23_044321|[[ 0.42691  0.29758  0.52422 -0.54807 -0.00317 -1.10737  0.66615 -0.46744
20Nov23_044321|   0.89578  0.22818 -0.07631 -0.76947 -0.46817 -0.21265 -0.85367]
20Nov23_044321| [-0.77699  0.41355 -1.18759  0.58503  0.11262 -0.77177 -0.87309  0.55877
20Nov23_044321|   0.49143  0.60359  0.78317 -2.01143 -0.18524  0.77837 -1.58646]
20Nov23_044321| [-0.05520  1.48797 -0.98303  0.44607  0.57229  0.01093  0.45399 -0.36869
20Nov23_044321|   1.25502 -2.04679  0.52420 -0.63251 -1.20841 -1.23667 -0.50506]
20Nov23_044321| [-0.15390 -0.12069  0.93121  0.62856 -0.47194  1.90773  0.12418 -0.02385
20Nov23_044321|   0.25845  0.67909 -0.74973 -1.14428 -0.54709 -1.03812  0.41810]
20Nov23_044321| [ 0.78184 -1.02634 -0.50414 -1.33713 -0.12806 -0.25092  1.03068 -1.53814
20Nov23_044321|   0.61719 -0.37364 -0.16927  0.25844 -1.59357  0.03242 -0.43857]
20Nov23_044321| [-1.51161  0.28379  0.11711  1.41276  1.94477 -1.13581 -0.16030 -0.98811
20Nov23_044321|  -0.74563  0.47408  1.31199  0.25822 -0.39431  0.99731  0.10765]
20Nov23_044321| [-0.06246 -0.55106 -0.66587 -0.81741 -0.90947 -0.55317  0.91670 -0.20333
20Nov23_044321|   0.16840 -0.45981  0.55694  1.11849  2.39357 -0.67350  0.20551]
20Nov23_044321| [ 0.47039 -1.74884  1.06361  0.87013 -1.27871 -0.23461 -0.85571  0.11193
20Nov23_044321|   1.28638  1.75207 -0.89037 -0.68407  0.35909 -0.54462 -0.10916]
20Nov23_044321| [-0.66100  1.52516  0.33780 -0.06402 -1.30311  2.21049  0.94191 -0.16126
20Nov23_044321|   0.77832 -0.93202  0.12018  0.28667  0.60154  0.67235  0.59619]
20Nov23_044321| [ 0.75099  1.36528 -1.73960 -1.50392  0.42261 -0.97005 -0.91943 -1.36861
20Nov23_044321|  -0.67430 -0.64244 -0.75113  1.74554  0.65154 -0.07884  0.24832]
20Nov23_044321| [ 1.53921 -0.26881 -0.59691  0.18529  0.48024 -0.98931 -1.54877  0.09832
20Nov23_044321|   1.16540  1.02141 -0.79718  1.33652  1.32572 -1.05063 -0.59539]
20Nov23_044321| [ 0.24418  0.35593 -0.10494 -1.30488  1.09288 -0.42662 -0.57142  0.49472
20Nov23_044321|   0.69921  0.62190  1.18692  0.10424 -0.45179  0.21910  0.01208]
20Nov23_044321| [ 0.67743 -0.19633  0.24381 -0.30061  0.08343 -0.33063 -0.09417 -0.29616
20Nov23_044321|  -0.06241 -1.05399  2.07564 -0.84708  0.83477 -0.41045  1.39502]
20Nov23_044321| [-0.03313 -0.77540  0.75142 -1.09279  1.86636 -0.79280 -0.54517 -0.28329
20Nov23_044321|   1.65999 -1.12225 -1.39221  0.11678 -1.17849 -0.62609 -0.37682]
20Nov23_044321| [ 0.05688 -0.19939 -0.40529 -0.51524 -0.26279  0.50723  0.33124  0.59534
20Nov23_044321|   0.83706  0.14251  0.82221 -0.63467  0.55955 -1.01568  0.21284]
20Nov23_044321| [ 0.01208  0.01410  1.11235 -0.49398  1.55853  0.43249  0.08756  0.00921
20Nov23_044321|  -0.71567 -0.38946 -0.90949 -0.83809 -0.05624  0.23786  0.05994]
20Nov23_044321| [-0.35205 -0.09450  2.24445  0.53880 -0.40180 -0.46765 -0.12446 -1.32593
20Nov23_044321|   1.41826 -0.76602  0.63376  1.18055 -0.53400  0.37624 -0.97579]
20Nov23_044321| [ 2.22050  0.05952 -1.19940  0.70861  1.41717 -0.26877 -0.94211 -1.40332
20Nov23_044321|   0.43003 -0.89869 -1.10584 -0.06625  0.31384 -0.10143  1.04961]
20Nov23_044321| [ 0.21289 -0.11012  1.49023  1.14376 -0.65338  0.26810 -0.85944  1.17660
20Nov23_044321|  -0.47870 -0.86877  0.44700  0.03584 -0.98074 -0.78054  0.03734]
20Nov23_044321| [ 0.28067  0.39235  1.41028 -0.15688 -0.54646  1.67606  0.42347  0.49702
20Nov23_044321|  -0.87937 -0.46845  1.00348 -0.53170 -1.12293 -1.01729  0.08005]
20Nov23_044321| [-1.14499  0.21662  0.15572  0.25399 -0.11350  0.09781 -0.60481 -0.96573
20Nov23_044321|   1.28182 -0.69592 -0.07493 -0.15830  1.71185 -1.62962  0.07644]
20Nov23_044321| [ 0.22980  0.61617 -0.58762 -1.53387  0.28371 -0.27785 -1.01772  0.18418
20Nov23_044321|   2.29950 -0.81522 -0.54903  0.50229  0.43645 -1.39068  1.50836]
20Nov23_044321| [ 1.26701  0.34500 -0.87987 -0.44065  1.23200 -1.45523  0.41462 -0.45891
20Nov23_044321|  -1.65629  1.36545 -0.16045  0.01440 -0.19117  1.01491 -1.56428]
20Nov23_044321| [-0.50801 -0.18680 -0.13795 -0.82892  0.04078  1.05055 -0.42182  0.28003
20Nov23_044321|  -0.17800 -0.94982 -1.60567 -0.74657 -0.37202 -0.77117  0.22728]
20Nov23_044321| [ 0.11223 -0.88960 -0.03771  0.68481 -1.13907 -1.64770 -2.08633  2.59999
20Nov23_044321|   0.70704 -1.10352 -0.73587  0.64618  0.18789 -0.56185 -0.00473]
20Nov23_044321| [-0.44394  1.09725  0.51635  0.38580 -1.13990  0.40442 -0.52209  0.10404
20Nov23_044321|  -0.15833  0.12255 -0.21853 -0.42496  1.00447  0.73146 -0.63667]
20Nov23_044321| [ 0.10066  1.40237  0.09464  0.72661 -1.80184 -0.06104 -0.34136 -0.51537
20Nov23_044321|  -1.66542 -0.55066 -2.56233 -0.02383 -0.84513 -1.61262 -0.51402]
20Nov23_044321| [-0.87960  0.23358 -0.52134  0.40047 -0.71106 -1.34728 -0.41823 -0.22333
20Nov23_044321|  -0.24686  1.65698 -1.30747 -0.69169 -0.66251  0.75459 -0.96660]
20Nov23_044321| [ 0.06230  1.20678 -0.23045 -0.84286 -0.22852  0.93298  0.14893  0.50809
20Nov23_044321|   0.14889 -0.72929 -0.24429  1.56028  1.22272  0.91747  0.36855]
20Nov23_044321| [-0.17377  1.14562  0.85539 -0.63699 -1.04190  0.12303 -0.72049 -0.08881
20Nov23_044321|  -0.90310  1.31653 -0.05204  0.40329 -0.48401 -0.36525 -0.46378]
20Nov23_044321| [ 0.09015 -0.62972 -0.73537  0.17011  0.27345 -0.55471  0.04517 -1.18609
20Nov23_044321|  -0.58628  0.49196 -0.58326  0.30330  0.51502  0.03433  0.04217]
20Nov23_044321| [ 0.86282 -0.84858 -1.43016 -0.52856  0.03054  0.44886  0.57046 -0.35864
20Nov23_044321|  -1.71832  0.24280 -0.89086 -0.78176  0.35162  0.30409 -0.02131]
20Nov23_044321| [ 1.05695  0.97767 -1.00230 -0.01291  0.04290 -0.09954  0.88877 -1.02809
20Nov23_044321|  -1.32144  0.07652  0.09972 -1.00606 -1.32542  0.05830 -0.38045]
20Nov23_044321| [ 0.43701 -1.48958 -0.15290 -0.28863  0.74501  0.03579 -1.09314 -0.86026
20Nov23_044321|   1.02886  1.16551 -1.01948 -1.43095 -1.82196 -0.89176 -0.81819]
20Nov23_044321| [-0.73966  0.22000  1.42394  0.53847 -2.33016 -0.57383  0.30702 -0.26322
20Nov23_044321|  -1.01442  0.05468 -0.23153 -0.06345  1.16376 -0.09296 -0.53408]
20Nov23_044321| [ 0.21706  1.28120  0.03908 -0.45157  0.48998  0.08854  0.00582  0.77533
20Nov23_044321|  -0.45924  0.03863 -0.73519 -0.00919 -1.16571  1.56297 -0.69370]
20Nov23_044321| [-2.08881 -0.97910  0.17069  0.79842  0.31541 -0.19526  0.45634  1.01009
20Nov23_044321|   0.59365 -0.01322  1.78356  1.44269  0.58775 -0.50228 -0.28648]
20Nov23_044321| [-1.12486  0.73663  0.56411  0.18444 -1.61639  1.08550  0.08219 -0.90988
20Nov23_044321|  -0.32404  0.81985  0.42006 -0.30815 -0.23312 -1.18708 -0.01110]
20Nov23_044321| [-0.30490 -1.30488 -1.53248 -0.79287  1.01787 -0.71421 -1.83065  0.46204
20Nov23_044321|  -0.31745  0.01163 -0.78217 -0.08380 -0.93485  0.93025 -1.11372]
20Nov23_044321| [-0.16328  1.13418 -0.55347 -0.46779  1.07552  0.66229 -0.21371  0.92252
20Nov23_044321|   0.55318  0.22002 -0.20203  0.71337  0.07093 -0.67508 -0.36308]
20Nov23_044321| [-0.14015 -0.56332  0.42102 -0.18024 -0.17774 -1.39429  0.65512  0.86385
20Nov23_044321|   0.74911  0.68266 -0.21078 -0.90494  0.19014 -0.64455  0.30027]
20Nov23_044321| [-0.74732 -0.00467  0.93348 -0.20600  0.55633 -0.56408 -0.45634 -0.20303
20Nov23_044321|  -0.13201 -1.51600  0.26075 -0.89582 -1.24197  0.63267  1.55172]
20Nov23_044321| [ 0.41456 -0.85489  0.02298  0.06353  0.81855  0.03156 -0.48615 -0.00658
20Nov23_044321|  -0.04895 -0.57287  0.20380  1.04986  0.97412 -0.47486  0.49494]
20Nov23_044321| [ 0.77080 -0.45784  0.11136  0.71105 -0.39395  0.40195 -0.43665  1.07323
20Nov23_044321|   0.43760  0.26785 -0.30587 -0.09075  0.40279  1.01923 -1.75405]
20Nov23_044321| [-0.88852  0.02533  1.17656  0.61764 -0.88512 -2.05323 -0.20657  0.56943
20Nov23_044321|  -0.79923 -0.05065  0.86607  1.99813 -0.99948 -0.10370  0.97637]
20Nov23_044321| [ 0.15692 -0.81947 -0.03219  0.05575  0.45531  1.62288 -0.76175 -0.80154
20Nov23_044321|  -1.50942 -0.89066 -0.37832  0.57865  2.24774  1.50483 -0.01312]
20Nov23_044321| [ 0.88566 -1.32158  1.07146  0.66710  0.27661  0.21144  0.50741  1.07543
20Nov23_044321|  -0.76611 -1.39540  0.28672  0.51751  0.72656 -0.65978  0.44566]
20Nov23_044321| [-1.03893  0.46076 -0.08662 -0.52243 -0.41836  0.85811 -0.86078  0.93975
20Nov23_044321|  -0.17006 -0.63327  0.74410  0.70958  1.39514  0.35044  0.87490]
20Nov23_044321| [ 1.54246 -0.70391 -0.91033  1.89604  0.46300 -0.13194 -0.43312  0.91185
20Nov23_044321|  -0.49534 -1.06771  0.38325 -1.29257 -0.73563 -1.04282 -0.39890]
20Nov23_044321| [-0.79484 -0.73094  1.55911 -0.27683  0.74301  0.65244 -1.70505  0.26757
20Nov23_044321|  -1.24152 -0.51986 -0.91341 -0.27940 -0.78858 -0.03302  0.36902]
20Nov23_044321| [-0.52894 -0.45939  0.71874 -1.10270 -0.31797 -1.23160 -0.28378  0.28717
20Nov23_044321|  -0.95275  0.83782 -0.51558 -0.40856 -0.70669 -0.31466  0.04528]
20Nov23_044321| [-0.81167 -0.21989  0.25817 -0.60778 -0.97270  0.42051  0.05410  0.81779
20Nov23_044321|  -0.94129  0.37341 -0.02587 -1.69395 -1.66843  0.14977 -1.29684]
20Nov23_044321| [ 0.18812 -1.04226 -0.19694 -0.90997  0.07427 -1.36961 -0.68391  1.29857
20Nov23_044321|  -1.58449 -1.19082 -1.19331 -0.28466  0.45438  0.59896 -0.09320]
20Nov23_044321| [ 0.46661 -1.82518  0.34643  0.42851  0.74486  1.16437 -1.33420  0.48093
20Nov23_044321|   0.66350 -1.58536  1.36313  1.64685  0.50624 -0.08332  0.16742]
20Nov23_044321| [ 0.83611 -1.02550  0.80906  0.82930  0.96028  0.21344  0.43399 -1.26536
20Nov23_044321|  -0.08786  0.56148  0.56968 -0.83275  0.47723  1.01280 -0.61349]
20Nov23_044321| [ 0.38265 -1.34334  0.19600 -0.79295  0.52286  0.28619  1.51312  0.85224
20Nov23_044321|   1.62111  1.09962  0.16420 -0.44606 -1.11225  1.26263  1.87372]
20Nov23_044321| [-0.57357 -0.55004 -1.15617  0.42990  0.23652 -0.13154 -1.45382  0.27475
20Nov23_044321|  -0.64777 -0.51002 -0.63579 -0.59520 -0.00340  0.31749  0.18432]]
20Nov23_044321|-- Bias --
20Nov23_044321|[ 1.38477 -0.37130 -0.13609 -0.85960 -0.92209 -0.27950  0.84767 -0.72498
20Nov23_044321| -0.02423  1.22888 -0.06124 -0.44945 -0.13271 -0.02930 -0.90463]
20Nov23_044321|Layer 1:
20Nov23_044321|-- Config --
20Nov23_044321|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 15], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_044321|-- Weights --
20Nov23_044321|[[ 0.67379 -1.05055]
20Nov23_044321| [-0.28290 -0.06835]
20Nov23_044321| [ 0.37387  0.47814]
20Nov23_044321| [ 0.58602 -0.61286]
20Nov23_044321| [-0.34764  0.50916]
20Nov23_044321| [-0.54241 -0.48178]
20Nov23_044321| [ 0.78853 -0.03736]
20Nov23_044321| [-0.61206 -0.05827]
20Nov23_044321| [-0.21855  1.26722]
20Nov23_044321| [-1.67530  1.48281]
20Nov23_044321| [-0.42903  0.74587]
20Nov23_044321| [ 0.09435 -1.16066]
20Nov23_044321| [-0.06102 -0.22933]
20Nov23_044321| [ 1.05118 -0.41105]
20Nov23_044321| [ 0.89464  0.71066]]
20Nov23_044321|-- Bias --
20Nov23_044321|[-0.89499  0.52392]
20Nov23_044321|Predicting the validation and test data with the Best final individual.
20Nov23_044327| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_044327|-----------  ------------------  --------------------  ----------
20Nov23_044327|Validation         41.91                  15            0.00259
20Nov23_044327|   Test            36.32                  15            0.00298
Using Theano backend.
20Nov23_044328|Data summary: Train
20Nov23_044328|data.shape = (2300, 57)
20Nov23_044328|labels.shape = (2300,)
20Nov23_044328|Class distribution:
20Nov23_044328|	0 - 1389 (0.60)
20Nov23_044328|	1 - 911 (0.40)
20Nov23_044328|Data summary: Validation
20Nov23_044328|data.shape = (1150, 57)
20Nov23_044328|labels.shape = (1150,)
20Nov23_044328|Class distribution:
20Nov23_044328|	0 - 667 (0.58)
20Nov23_044328|	1 - 483 (0.42)
20Nov23_044328|Data summary: Test
20Nov23_044328|data.shape = (1151, 57)
20Nov23_044328|labels.shape = (1151,)
20Nov23_044328|Class distribution:
20Nov23_044328|	0 - 732 (0.64)
20Nov23_044328|	1 - 419 (0.36)
20Nov23_044328|Selected configuration values
20Nov23_044328|-- Dataset name: spambase2
20Nov23_044328|-- Initial population size: 64
20Nov23_044328|-- Maximun number of generations: 32
20Nov23_044328|-- Neurons per hidden layer range: (2, 20)
20Nov23_044328|-- Hidden layers number range: (1, 3)
20Nov23_044328|-- Crossover probability: 0.5
20Nov23_044328|-- Bias gene mutation probability: 0.2
20Nov23_044328|-- Weights gene mutation probability: 0.75
20Nov23_044328|-- Neuron mutation probability: 0.3
20Nov23_044328|-- Layer mutation probability: 0.3
20Nov23_044328|-- Constant hidden layers: False
20Nov23_044328|-- Seed: None
20Nov23_044328|Entering GA
20Nov23_044328|Start the algorithm
20Nov23_044641|-- Generation 1 --
20Nov23_044641|    -- Crossed 1 individual pairs.
20Nov23_044641|    -- Mutated 32 individuals.
20Nov23_044948|    -- Evaluated 64 individuals.
20Nov23_044948|    Summary of generation 1:
20Nov23_044948| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_044948|-----------  ------------------  --------------------  ----------
20Nov23_044948|    Max            58.00                99.00           0.85357
20Nov23_044948|    Avg            41.92                24.94           0.03276
20Nov23_044948|    Min            29.65                 3.00           0.00000
20Nov23_044948|    Std             2.65                18.54           0.14598
20Nov23_044948|   Best            29.65                42.00           0.85357
20Nov23_044948|-- Generation 2 --
20Nov23_044948|    -- Crossed 2 individual pairs.
20Nov23_044948|    -- Mutated 32 individuals.
20Nov23_045252|    -- Evaluated 64 individuals.
20Nov23_045252|    Summary of generation 2:
20Nov23_045252| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_045252|-----------  ------------------  --------------------  ----------
20Nov23_045252|    Max            43.13                75.00           0.81855
20Nov23_045252|    Avg            41.82                19.02           0.01592
20Nov23_045252|    Min            32.26                 3.00           0.00000
20Nov23_045252|    Std             1.26                15.73           0.10201
20Nov23_045252|   Best            32.26                14.00           0.81855
20Nov23_045252|-- Generation 3 --
20Nov23_045252|    -- Crossed 3 individual pairs.
20Nov23_045252|    -- Mutated 32 individuals.
20Nov23_045551|    -- Evaluated 64 individuals.
20Nov23_045551|    Summary of generation 3:
20Nov23_045551| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_045551|-----------  ------------------  --------------------  ----------
20Nov23_045551|    Max            42.17                54.00           0.01033
20Nov23_045551|    Avg            41.98                14.16           0.00157
20Nov23_045551|    Min            41.74                 3.00           0.00000
20Nov23_045551|    Std             0.08                11.73           0.00240
20Nov23_045551|   Best            41.74                13.00           0.01033
20Nov23_045551|-- Generation 4 --
20Nov23_045551|    -- Crossed 6 individual pairs.
20Nov23_045551|    -- Mutated 32 individuals.
20Nov23_045851|    -- Evaluated 64 individuals.
20Nov23_045851|    Summary of generation 4:
20Nov23_045851| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_045851|-----------  ------------------  --------------------  ----------
20Nov23_045851|    Max            42.17                56.00           0.76833
20Nov23_045851|    Avg            41.73                15.14           0.01705
20Nov23_045851|    Min            28.43                 3.00           0.00000
20Nov23_045851|    Std             1.71                13.91           0.09771
20Nov23_045851|   Best            28.43                18.00           0.76833
20Nov23_045851|-- Generation 5 --
20Nov23_045851|    -- Crossed 2 individual pairs.
20Nov23_045851|    -- Mutated 32 individuals.
20Nov23_050153|    -- Evaluated 64 individuals.
20Nov23_050153|    Summary of generation 5:
20Nov23_050153| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_050153|-----------  ------------------  --------------------  ----------
20Nov23_050153|    Max            42.26                72.00           0.79628
20Nov23_050153|    Avg            41.02                16.88           0.05598
20Nov23_050153|    Min            25.04                 3.00           0.00000
20Nov23_050153|    Std             3.46                15.55           0.18839
20Nov23_050153|   Best            25.04                20.00           0.71075
20Nov23_050153|-- Generation 6 --
20Nov23_050153|    -- Crossed 3 individual pairs.
20Nov23_050153|    -- Mutated 32 individuals.
20Nov23_050457|    -- Evaluated 64 individuals.
20Nov23_050457|    Summary of generation 6:
20Nov23_050457| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_050457|-----------  ------------------  --------------------  ----------
20Nov23_050457|    Max            42.09                75.00           0.82687
20Nov23_050457|    Avg            41.57                19.38           0.03777
20Nov23_050457|    Min            29.13                 2.00           0.00000
20Nov23_050457|    Std             1.79                18.73           0.14217
20Nov23_050457|   Best            29.13                20.00           0.46347
20Nov23_050457|-- Generation 7 --
20Nov23_050457|    -- Crossed 1 individual pairs.
20Nov23_050457|    -- Mutated 32 individuals.
20Nov23_050802|    -- Evaluated 64 individuals.
20Nov23_050802|    Summary of generation 7:
20Nov23_050802| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_050802|-----------  ------------------  --------------------  ----------
20Nov23_050802|    Max            47.91                69.00           0.81888
20Nov23_050802|    Avg            41.83                20.36           0.03883
20Nov23_050802|    Min            28.61                 2.00           0.00000
20Nov23_050802|    Std             1.84                17.81           0.16209
20Nov23_050802|   Best            28.61                20.00           0.66777
20Nov23_050802|-- Generation 8 --
20Nov23_050802|    -- Crossed 0 individual pairs.
20Nov23_050802|    -- Mutated 32 individuals.
20Nov23_051103|    -- Evaluated 64 individuals.
20Nov23_051103|    Summary of generation 8:
20Nov23_051103| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_051103|-----------  ------------------  --------------------  ----------
20Nov23_051103|    Max            42.78                93.00           0.72976
20Nov23_051103|    Avg            41.34                15.70           0.03711
20Nov23_051103|    Min            29.74                 2.00           0.00000
20Nov23_051103|    Std             2.41                16.48           0.13383
20Nov23_051103|   Best            29.74                18.00           0.52840
20Nov23_051103|-- Generation 9 --
20Nov23_051103|    -- Crossed 4 individual pairs.
20Nov23_051103|    -- Mutated 32 individuals.
20Nov23_051405|    -- Evaluated 64 individuals.
20Nov23_051405|    Summary of generation 9:
20Nov23_051405| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_051405|-----------  ------------------  --------------------  ----------
20Nov23_051405|    Max            57.83                72.00           0.78409
20Nov23_051405|    Avg            42.04                16.94           0.02598
20Nov23_051405|    Min            36.87                 2.00           0.00000
20Nov23_051405|    Std             2.11                16.70           0.11920
20Nov23_051405|   Best            36.87                20.00           0.56907
20Nov23_051405|-- Generation 10 --
20Nov23_051405|    -- Crossed 4 individual pairs.
20Nov23_051405|    -- Mutated 32 individuals.
20Nov23_051708|    -- Evaluated 64 individuals.
20Nov23_051708|    Summary of generation 10:
20Nov23_051708| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_051708|-----------  ------------------  --------------------  ----------
20Nov23_051708|    Max            57.91                80.00           0.79893
20Nov23_051708|    Avg            41.52                19.17           0.05550
20Nov23_051708|    Min            22.09                 2.00           0.00000
20Nov23_051708|    Std             3.59                19.26           0.18067
20Nov23_051708|   Best            22.09                30.00           0.75727
20Nov23_051708|-- Generation 11 --
20Nov23_051708|    -- Crossed 0 individual pairs.
20Nov23_051708|    -- Mutated 32 individuals.
20Nov23_052014|    -- Evaluated 64 individuals.
20Nov23_052014|    Summary of generation 11:
20Nov23_052014| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_052014|-----------  ------------------  --------------------  ----------
20Nov23_052014|    Max            42.17                115.00          0.76740
20Nov23_052014|    Avg            41.10                21.92           0.03819
20Nov23_052014|    Min            24.52                 2.00           0.00000
20Nov23_052014|    Std             3.45                21.33           0.14560
20Nov23_052014|   Best            24.52                30.00           0.66398
20Nov23_052014|-- Generation 12 --
20Nov23_052014|    -- Crossed 2 individual pairs.
20Nov23_052014|    -- Mutated 32 individuals.
20Nov23_052320|    -- Evaluated 64 individuals.
20Nov23_052320|    Summary of generation 12:
20Nov23_052320| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_052320|-----------  ------------------  --------------------  ----------
20Nov23_052320|    Max            42.09                80.00           0.77795
20Nov23_052320|    Avg            40.71                20.20           0.05985
20Nov23_052320|    Min            24.52                 2.00           0.00000
20Nov23_052320|    Std             3.93                17.47           0.18183
20Nov23_052320|   Best            24.52                30.00           0.77795
20Nov23_052320|-- Generation 13 --
20Nov23_052320|    -- Crossed 3 individual pairs.
20Nov23_052320|    -- Mutated 32 individuals.
20Nov23_052623|    -- Evaluated 64 individuals.
20Nov23_052623|    Summary of generation 13:
20Nov23_052623| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_052623|-----------  ------------------  --------------------  ----------
20Nov23_052623|    Max            58.00                80.00           0.78358
20Nov23_052623|    Avg            41.45                16.05           0.05527
20Nov23_052623|    Min            29.13                 2.00           0.00000
20Nov23_052623|    Std             3.40                17.28           0.17790
20Nov23_052623|   Best            29.13                80.00           0.71743
20Nov23_052623|-- Generation 14 --
20Nov23_052623|    -- Crossed 1 individual pairs.
20Nov23_052623|    -- Mutated 32 individuals.
20Nov23_052925|    -- Evaluated 64 individuals.
20Nov23_052925|    Summary of generation 14:
20Nov23_052925| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_052925|-----------  ------------------  --------------------  ----------
20Nov23_052925|    Max            42.52                84.00           0.67356
20Nov23_052925|    Avg            41.07                14.70           0.03894
20Nov23_052925|    Min            24.43                 2.00           0.00000
20Nov23_052925|    Std             3.32                19.42           0.13633
20Nov23_052925|   Best            24.43                80.00           0.67356
20Nov23_052925|-- Generation 15 --
20Nov23_052925|    -- Crossed 6 individual pairs.
20Nov23_052925|    -- Mutated 32 individuals.
20Nov23_053225|    -- Evaluated 64 individuals.
20Nov23_053225|    Summary of generation 15:
20Nov23_053225| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_053225|-----------  ------------------  --------------------  ----------
20Nov23_053225|    Max            42.61                110.00          0.73751
20Nov23_053225|    Avg            41.21                14.58           0.03741
20Nov23_053225|    Min            26.09                 2.00           0.00000
20Nov23_053225|    Std             3.18                23.55           0.14890
20Nov23_053225|   Best            26.09                80.00           0.71166
20Nov23_053225|-- Generation 16 --
20Nov23_053225|    -- Crossed 4 individual pairs.
20Nov23_053225|    -- Mutated 32 individuals.
20Nov23_053524|    -- Evaluated 64 individuals.
20Nov23_053524|    Summary of generation 16:
20Nov23_053524| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_053524|-----------  ------------------  --------------------  ----------
20Nov23_053524|    Max            42.26                115.00          0.65767
20Nov23_053524|    Avg            40.86                12.31           0.04957
20Nov23_053524|    Min            25.57                 2.00           0.00000
20Nov23_053524|    Std             3.78                21.51           0.15691
20Nov23_053524|   Best            25.57                45.00           0.65438
20Nov23_053524|-- Generation 17 --
20Nov23_053524|    -- Crossed 4 individual pairs.
20Nov23_053524|    -- Mutated 32 individuals.
20Nov23_053824|    -- Evaluated 64 individuals.
20Nov23_053824|    Summary of generation 17:
20Nov23_053824| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_053824|-----------  ------------------  --------------------  ----------
20Nov23_053824|    Max            42.09                80.00           0.76368
20Nov23_053824|    Avg            40.57                13.94           0.06321
20Nov23_053824|    Min            25.57                 2.00           0.00000
20Nov23_053824|    Std             4.02                22.17           0.18030
20Nov23_053824|   Best            25.57                80.00           0.64179
20Nov23_053824|-- Generation 18 --
20Nov23_053824|    -- Crossed 4 individual pairs.
20Nov23_053824|    -- Mutated 32 individuals.
20Nov23_054129|    -- Evaluated 64 individuals.
20Nov23_054129|    Summary of generation 18:
20Nov23_054129| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_054129|-----------  ------------------  --------------------  ----------
20Nov23_054129|    Max            46.43                130.00          0.80744
20Nov23_054129|    Avg            39.59                20.97           0.12191
20Nov23_054129|    Min            24.70                 2.00           0.00000
20Nov23_054129|    Std             5.52                30.89           0.25466
20Nov23_054129|   Best            24.70                45.00           0.71487
20Nov23_054129|-- Generation 19 --
20Nov23_054129|    -- Crossed 5 individual pairs.
20Nov23_054129|    -- Mutated 32 individuals.
20Nov23_054437|    -- Evaluated 64 individuals.
20Nov23_054437|    Summary of generation 19:
20Nov23_054437| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_054437|-----------  ------------------  --------------------  ----------
20Nov23_054437|    Max            42.17                110.00          0.82111
20Nov23_054437|    Avg            39.49                25.14           0.15628
20Nov23_054437|    Min            26.00                 2.00           0.00000
20Nov23_054437|    Std             4.89                30.46           0.28919
20Nov23_054437|   Best            26.00                45.00           0.67460
20Nov23_054437|-- Generation 20 --
20Nov23_054437|    -- Crossed 3 individual pairs.
20Nov23_054437|    -- Mutated 32 individuals.
20Nov23_054748|    -- Evaluated 64 individuals.
20Nov23_054748|    Summary of generation 20:
20Nov23_054748| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_054748|-----------  ------------------  --------------------  ----------
20Nov23_054748|    Max            42.96                120.00          0.81129
20Nov23_054748|    Avg            38.13                28.77           0.17162
20Nov23_054748|    Min            23.65                 2.00           0.00000
20Nov23_054748|    Std             6.62                31.47           0.28573
20Nov23_054748|   Best            23.65                80.00           0.77555
20Nov23_054748|-- Generation 21 --
20Nov23_054748|    -- Crossed 1 individual pairs.
20Nov23_054749|    -- Mutated 32 individuals.
20Nov23_055105|    -- Evaluated 64 individuals.
20Nov23_055105|    Summary of generation 21:
20Nov23_055105| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_055105|-----------  ------------------  --------------------  ----------
20Nov23_055105|    Max            45.13                125.00          0.82580
20Nov23_055105|    Avg            38.38                37.95           0.19951
20Nov23_055105|    Min            25.48                 2.00           0.00000
20Nov23_055105|    Std             5.91                34.78           0.29631
20Nov23_055105|   Best            25.48                24.00           0.75661
20Nov23_055105|-- Generation 22 --
20Nov23_055105|    -- Crossed 0 individual pairs.
20Nov23_055105|    -- Mutated 32 individuals.
20Nov23_055423|    -- Evaluated 64 individuals.
20Nov23_055423|    Summary of generation 22:
20Nov23_055423| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_055423|-----------  ------------------  --------------------  ----------
20Nov23_055423|    Max            58.00                110.00          0.82127
20Nov23_055423|    Avg            37.52                40.09           0.24602
20Nov23_055423|    Min            23.13                 3.00           0.00000
20Nov23_055423|    Std             7.14                33.20           0.32482
20Nov23_055423|   Best            23.13                44.00           0.72022
20Nov23_055423|-- Generation 23 --
20Nov23_055423|    -- Crossed 2 individual pairs.
20Nov23_055423|    -- Mutated 32 individuals.
20Nov23_055744|    -- Evaluated 64 individuals.
20Nov23_055744|    Summary of generation 23:
20Nov23_055744| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_055744|-----------  ------------------  --------------------  ----------
20Nov23_055744|    Max            58.00                120.00          0.83032
20Nov23_055744|    Avg            36.84                45.39           0.27921
20Nov23_055744|    Min            23.91                 3.00           0.00000
20Nov23_055744|    Std             7.21                35.31           0.32451
20Nov23_055744|   Best            23.91                40.00           0.82816
20Nov23_055744|-- Generation 24 --
20Nov23_055744|    -- Crossed 0 individual pairs.
20Nov23_055744|    -- Mutated 32 individuals.
20Nov23_060113|    -- Evaluated 64 individuals.
20Nov23_060113|    Summary of generation 24:
20Nov23_060113| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_060113|-----------  ------------------  --------------------  ----------
20Nov23_060113|    Max            42.26                125.00          0.82665
20Nov23_060113|    Avg            35.56                60.34           0.30059
20Nov23_060113|    Min            24.26                 4.00           0.00000
20Nov23_060113|    Std             7.16                33.10           0.32864
20Nov23_060113|   Best            24.26                88.00           0.69699
20Nov23_060113|-- Generation 25 --
20Nov23_060113|    -- Crossed 1 individual pairs.
20Nov23_060113|    -- Mutated 32 individuals.
20Nov23_060447|    -- Evaluated 64 individuals.
20Nov23_060447|    Summary of generation 25:
20Nov23_060447| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_060447|-----------  ------------------  --------------------  ----------
20Nov23_060447|    Max            42.09                135.00          0.75412
20Nov23_060447|    Avg            35.83                69.39           0.28668
20Nov23_060447|    Min            24.87                12.00           0.00000
20Nov23_060447|    Std             7.11                28.02           0.31707
20Nov23_060447|   Best            24.87                80.00           0.64874
20Nov23_060447|-- Generation 26 --
20Nov23_060447|    -- Crossed 1 individual pairs.
20Nov23_060447|    -- Mutated 32 individuals.
20Nov23_060821|    -- Evaluated 64 individuals.
20Nov23_060821|    Summary of generation 26:
20Nov23_060821| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_060821|-----------  ------------------  --------------------  ----------
20Nov23_060821|    Max            42.43                135.00          0.77045
20Nov23_060821|    Avg            33.46                70.22           0.37373
20Nov23_060821|    Min            25.13                12.00           0.00000
20Nov23_060821|    Std             7.04                27.90           0.30888
20Nov23_060821|   Best            25.13                88.00           0.65734
20Nov23_060821|-- Generation 27 --
20Nov23_060821|    -- Crossed 1 individual pairs.
20Nov23_060821|    -- Mutated 32 individuals.
20Nov23_061156|    -- Evaluated 64 individuals.
20Nov23_061156|    Summary of generation 27:
20Nov23_061156| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_061156|-----------  ------------------  --------------------  ----------
20Nov23_061156|    Max            42.35                135.00          0.81970
20Nov23_061156|    Avg            33.91                76.95           0.38376
20Nov23_061156|    Min            20.87                20.00           0.00000
20Nov23_061156|    Std             7.22                24.06           0.32942
20Nov23_061156|   Best            20.87                88.00           0.76876
20Nov23_061156|-- Generation 28 --
20Nov23_061156|    -- Crossed 1 individual pairs.
20Nov23_061156|    -- Mutated 32 individuals.
20Nov23_061530|    -- Evaluated 64 individuals.
20Nov23_061530|    Summary of generation 28:
20Nov23_061530| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_061530|-----------  ------------------  --------------------  ----------
20Nov23_061530|    Max            46.09                135.00          0.79338
20Nov23_061530|    Avg            34.21                75.50           0.38468
20Nov23_061530|    Min            20.52                20.00           0.00000
20Nov23_061530|    Std             7.19                26.31           0.33466
20Nov23_061530|   Best            20.52                88.00           0.77991
20Nov23_061530|-- Generation 29 --
20Nov23_061530|    -- Crossed 0 individual pairs.
20Nov23_061530|    -- Mutated 32 individuals.
20Nov23_061903|    -- Evaluated 64 individuals.
20Nov23_061903|    Summary of generation 29:
20Nov23_061903| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_061903|-----------  ------------------  --------------------  ----------
20Nov23_061903|    Max            42.09                174.00          0.78428
20Nov23_061903|    Avg            35.04                73.27           0.32446
20Nov23_061903|    Min            24.09                20.00           0.00000
20Nov23_061903|    Std             7.06                28.30           0.31316
20Nov23_061903|   Best            24.09                80.00           0.70507
20Nov23_061903|-- Generation 30 --
20Nov23_061903|    -- Crossed 1 individual pairs.
20Nov23_061903|    -- Mutated 32 individuals.
20Nov23_062236|    -- Evaluated 64 individuals.
20Nov23_062236|    Summary of generation 30:
20Nov23_062236| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_062236|-----------  ------------------  --------------------  ----------
20Nov23_062236|    Max            42.09                130.00          0.84659
20Nov23_062236|    Avg            31.88                72.56           0.46034
20Nov23_062236|    Min            24.00                22.00           0.00000
20Nov23_062236|    Std             6.47                23.39           0.28887
20Nov23_062236|   Best            24.00                80.00           0.70835
20Nov23_062236|-- Generation 31 --
20Nov23_062236|    -- Crossed 3 individual pairs.
20Nov23_062236|    -- Mutated 32 individuals.
20Nov23_062608|    -- Evaluated 64 individuals.
20Nov23_062608|    Summary of generation 31:
20Nov23_062608| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_062608|-----------  ------------------  --------------------  ----------
20Nov23_062608|    Max            42.61                125.00          0.77203
20Nov23_062608|    Avg            33.38                70.91           0.39513
20Nov23_062608|    Min            24.09                20.00           0.00000
20Nov23_062608|    Std             6.96                26.40           0.30908
20Nov23_062608|   Best            24.09                125.00          0.73156
20Nov23_062608|-- Generation 32 --
20Nov23_062608|    -- Crossed 0 individual pairs.
20Nov23_062608|    -- Mutated 32 individuals.
20Nov23_062941|    -- Evaluated 64 individuals.
20Nov23_062941|    Summary of generation 32:
20Nov23_062941| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_062941|-----------  ------------------  --------------------  ----------
20Nov23_062941|    Max            42.17                130.00          0.78239
20Nov23_062941|    Avg            34.30                73.22           0.36296
20Nov23_062941|    Min            25.30                18.00           0.00000
20Nov23_062941|    Std             6.93                27.96           0.31742
20Nov23_062941|   Best            25.30                84.00           0.71867
20Nov23_062941|Best initial individual weights
20Nov23_062941|Individual:
20Nov23_062941|-- Constant hidden layers --
20Nov23_062941|False
20Nov23_062941|Layer 0:
20Nov23_062941|-- Config --
20Nov23_062941|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 20, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_062941|-- Weights --
20Nov23_062941|[[ 0.33406 -0.77796 -0.03079 ...  0.74951 -0.40593 -0.97336]
20Nov23_062941| [ 0.62745 -0.41850 -0.06774 ... -0.49889  0.05070  0.37917]
20Nov23_062941| [-0.19799 -0.60355  0.87276 ...  0.61835  0.27745 -0.73781]
20Nov23_062941| ...
20Nov23_062941| [ 0.08362 -0.33296 -0.87848 ... -0.75393 -0.85112 -0.73382]
20Nov23_062941| [ 0.13194  0.34412 -0.49502 ... -0.88252 -0.55163  0.01636]
20Nov23_062941| [ 0.49341 -0.01408 -0.11062 ...  0.77821  0.90277 -0.05234]]
20Nov23_062941|-- Bias --
20Nov23_062941|[ 0.59463  0.02357 -0.31916 -0.42044  0.44381  0.82091  0.73706  0.56641
20Nov23_062941|  0.70585 -0.77890 -0.36611 -0.70445  0.67835  0.48869 -0.67868  0.71090
20Nov23_062941| -0.75144  0.24405  0.60210  0.39510]
20Nov23_062941|Layer 1:
20Nov23_062941|-- Config --
20Nov23_062941|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 20], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_062941|-- Weights --
20Nov23_062941|[[ 0.00759 -0.35506]
20Nov23_062941| [-0.97167  0.74607]
20Nov23_062941| [ 0.64865 -0.01100]
20Nov23_062941| [ 0.53630 -0.45122]
20Nov23_062941| [ 0.67913 -0.52801]
20Nov23_062941| [ 0.93688  0.04425]
20Nov23_062941| [-0.45372 -0.05682]
20Nov23_062941| [-0.17311  0.48204]
20Nov23_062941| [-0.67391 -0.42928]
20Nov23_062941| [ 0.34638 -0.61009]
20Nov23_062941| [-0.99870 -0.25995]
20Nov23_062941| [ 0.88433 -0.78104]
20Nov23_062941| [ 0.34280  0.76390]
20Nov23_062941| [ 0.54620 -0.49842]
20Nov23_062941| [ 0.95085  0.35147]
20Nov23_062941| [ 0.53727  0.99312]
20Nov23_062941| [ 0.10626 -0.11348]
20Nov23_062941| [-0.74250 -0.77514]
20Nov23_062941| [ 0.47468  0.24400]
20Nov23_062941| [ 0.71422  0.42906]]
20Nov23_062941|-- Bias --
20Nov23_062941|[0.15805 0.52468]
20Nov23_062941|Predicting the validation and test data with the Best initial individual.
20Nov23_062947| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_062947|-----------  ------------------  --------------------  ----------
20Nov23_062947|Validation         42.17                  20            0.00000
20Nov23_062947|   Test            36.40                  20            0.00000
20Nov23_062947|-------------------------- Test #0 --------------------------
20Nov23_062947|Best final individual weights
20Nov23_062947|Individual:
20Nov23_062947|-- Constant hidden layers --
20Nov23_062947|False
20Nov23_062947|Layer 0:
20Nov23_062947|-- Config --
20Nov23_062947|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_062947|-- Weights --
20Nov23_062947|[[ 0.37246  0.50348 -0.38721 -0.36688  2.11975  1.13385]
20Nov23_062947| [ 0.85547  0.24143 -1.64877 -0.78124 -0.43609 -2.21237]
20Nov23_062947| [ 0.42721 -0.76527 -0.51440 -0.75447  0.32484 -0.87275]
20Nov23_062947| [ 0.40346  0.73991  1.07205 -0.69045 -0.65947 -0.69401]
20Nov23_062947| [-0.42540  1.05687  1.57639 -0.19852 -0.01890 -1.25550]
20Nov23_062947| [ 1.01099 -1.20961  1.25712  1.12731 -2.11193 -0.16926]
20Nov23_062947| [ 1.24861  1.19184  0.77574  1.39326 -0.67107  0.80633]
20Nov23_062947| [-1.23263 -0.57257  1.51785  0.29112 -0.35951  0.26049]
20Nov23_062947| [ 0.34632  0.47098 -0.18577 -0.40163 -0.19665 -0.79876]
20Nov23_062947| [ 0.37496 -0.29597  1.24258 -0.16212 -0.65061  0.43949]
20Nov23_062947| [ 0.69488  0.81509 -2.27263  0.15914 -0.46454 -0.23901]
20Nov23_062947| [-0.75193 -1.91140 -1.01764 -0.74874 -0.08376  0.19787]
20Nov23_062947| [ 0.32119 -0.01971  0.44310 -1.10615 -0.05645  0.79914]
20Nov23_062947| [-0.32188  1.83930 -1.27440  1.32363 -0.58820 -1.55631]
20Nov23_062947| [-0.95047 -0.79252  0.53185  1.12978 -2.21543  0.23448]
20Nov23_062947| [ 0.83000 -0.27012  0.28352 -0.87504 -0.14749  0.55266]
20Nov23_062947| [ 1.13130 -0.03457 -0.21537 -0.55833 -1.49729 -0.36937]
20Nov23_062947| [-1.79056 -1.86836 -1.52421 -2.43591  0.70215 -0.37284]
20Nov23_062947| [-0.99829  0.58787 -0.49641  0.56679 -1.24154 -0.79487]
20Nov23_062947| [ 0.28588 -0.57617 -0.68829 -0.21789 -0.08347 -0.22650]
20Nov23_062947| [ 0.57393  0.27574 -0.47918  0.06886 -0.02632 -0.86438]
20Nov23_062947| [-2.37699  0.90398 -1.20198 -0.13722  1.11758  0.95157]
20Nov23_062947| [ 0.80080 -1.27768  0.47634  0.15233 -2.17593  0.08481]
20Nov23_062947| [ 0.96978 -1.60896  0.26377  1.17514 -0.48422 -1.14618]
20Nov23_062947| [-0.58915 -0.04214  1.08863 -1.31963  1.38578  0.43376]
20Nov23_062947| [-0.55311 -0.11218 -1.57961  0.61144  0.21090  0.85095]
20Nov23_062947| [ 0.95030  1.36585 -0.88436  0.55456 -0.29468 -0.06177]
20Nov23_062947| [-0.22244  2.02469 -2.20220  0.51991 -0.32656 -1.13757]
20Nov23_062947| [-1.02569 -0.75926  0.43686  0.74239 -0.03544  0.84045]
20Nov23_062947| [ 1.66723  0.36779  1.48881  1.78736  0.10982 -0.47841]
20Nov23_062947| [ 1.19031 -0.31012 -1.89834 -1.26765 -0.70409 -1.17102]
20Nov23_062947| [ 0.86965  0.28328  0.67962  0.19979 -0.07761  0.88232]
20Nov23_062947| [-0.37120 -0.21892 -0.63646  0.25970  0.09547  0.33285]
20Nov23_062947| [ 0.50033 -0.52733 -0.61247 -1.32671 -0.64064  0.80882]
20Nov23_062947| [-0.28304 -1.42711 -0.62821 -0.16242 -0.56235 -0.05706]
20Nov23_062947| [-1.16828  1.41397 -1.62729 -0.34079  0.64029  0.13870]
20Nov23_062947| [-1.25923 -1.77860  1.33062 -1.19801 -0.63088  0.01647]
20Nov23_062947| [-0.06558 -1.13347 -1.19374  0.35032  1.82112 -1.10971]
20Nov23_062947| [-0.71351  0.94623 -0.04997  0.34918 -0.63262  0.37683]
20Nov23_062947| [ 0.19848 -0.83013 -1.92147 -1.36939  0.83033 -0.13095]
20Nov23_062947| [-0.61376  0.80335  0.24413  0.96333 -1.14089  0.85802]
20Nov23_062947| [-0.36928 -0.42211  0.24520 -1.30295 -1.93237 -0.02548]
20Nov23_062947| [ 0.20256 -0.42818 -1.94283  0.77496  0.53459  1.61769]
20Nov23_062947| [ 0.68188  0.47057  0.20435  1.09097  0.15765  1.04190]
20Nov23_062947| [ 1.33491  0.24345  0.21908  0.18090  1.34449 -0.17898]
20Nov23_062947| [ 0.27847  0.70360  0.51300  1.26013 -1.36985 -0.78610]
20Nov23_062947| [ 1.84673  0.34176  1.17368  0.06267  0.80454 -1.08971]
20Nov23_062947| [-1.55035 -0.68663 -0.37203  0.80163 -0.26877  0.01660]
20Nov23_062947| [ 1.09088 -1.16331  0.24986 -0.12997  1.33586 -1.57542]
20Nov23_062947| [-0.65292 -1.51801  0.65628 -0.59370  2.42713 -0.62132]
20Nov23_062947| [-0.24412 -0.93150 -0.95428  2.12486 -1.66742  0.38608]
20Nov23_062947| [-0.12629 -1.50991  1.01674 -1.39436  0.05675  0.29722]
20Nov23_062947| [ 0.97103 -0.96420  0.21034 -1.70519  1.10287 -1.04466]
20Nov23_062947| [-0.08849  0.34404  1.21360  1.35353  0.10154 -0.21929]
20Nov23_062947| [ 2.57606  0.55820 -0.39108  0.68623 -1.25579 -0.40213]
20Nov23_062947| [-1.14612  0.04346  0.06719  0.49167  1.02429  0.57897]
20Nov23_062947| [-0.52130 -0.28448 -0.88990 -0.47006  0.38699 -1.63998]]
20Nov23_062947|-- Bias --
20Nov23_062947|[-1.43356  1.08152  0.41815  0.00424 -0.24154  0.48990]
20Nov23_062947|Layer 1:
20Nov23_062947|-- Config --
20Nov23_062947|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_062947|-- Weights --
20Nov23_062947|[[-1.12283 -0.64585  0.37135  0.93805  0.50152]
20Nov23_062947| [-0.45128 -0.33951  2.35894 -0.23711  0.47670]
20Nov23_062947| [ 1.07740 -1.29532 -1.29629  0.87008  0.40993]
20Nov23_062947| [ 0.03760  1.27456 -1.39564  0.16391  0.14825]
20Nov23_062947| [-1.16091 -1.49048  0.95524 -0.46229  0.11068]
20Nov23_062947| [-0.26762  1.19525  1.35283  2.28556 -0.02087]]
20Nov23_062947|-- Bias --
20Nov23_062947|[-0.01568 -0.30813  0.67368 -0.55501  0.11533]
20Nov23_062947|Layer 2:
20Nov23_062947|-- Config --
20Nov23_062947|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_062947|-- Weights --
20Nov23_062947|[[ 0.73189  0.25994  0.61296 -0.76909  0.25937]
20Nov23_062947| [-0.88936 -0.61503 -0.69177 -0.58393  0.75519]
20Nov23_062947| [ 0.27706 -1.82774  0.74789  0.24210  0.70912]
20Nov23_062947| [-0.71073 -0.66461 -0.05384  0.42014 -0.09637]
20Nov23_062947| [ 0.18630 -0.67560  0.79441  0.18604 -0.70347]]
20Nov23_062947|-- Bias --
20Nov23_062947|[ 1.74623  0.69730  0.72008 -0.20004  0.15599]
20Nov23_062947|Layer 3:
20Nov23_062947|-- Config --
20Nov23_062947|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_062947|-- Weights --
20Nov23_062947|[[ 0.78512  0.58495  1.01708  1.05505 -0.47074]
20Nov23_062947| [ 0.09227 -0.27877  0.05296  0.69659  0.56285]
20Nov23_062947| [ 0.08212 -0.85808  1.14160 -0.25897 -0.73503]
20Nov23_062947| [-1.34393 -0.15823  0.51240 -0.30438 -0.15319]
20Nov23_062947| [-0.18853  0.79089 -0.34260 -0.42000  0.98012]]
20Nov23_062947|-- Bias --
20Nov23_062947|[ 0.02020 -0.47953 -0.29788  0.95327  0.93818]
20Nov23_062947|Layer 4:
20Nov23_062947|-- Config --
20Nov23_062947|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_062947|-- Weights --
20Nov23_062947|[[-1.15005 -1.14488]
20Nov23_062947| [-0.70732 -0.77066]
20Nov23_062947| [-0.92771 -0.61093]
20Nov23_062947| [-0.90771 -1.04766]
20Nov23_062947| [ 1.53415  1.37750]]
20Nov23_062947|-- Bias --
20Nov23_062947|[-0.45752 -0.43811]
20Nov23_062947|Predicting the validation and test data with the Best final individual.
20Nov23_062954| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_062954|-----------  ------------------  --------------------  ----------
20Nov23_062954|Validation         42.09                  84            0.00258
20Nov23_062954|   Test            26.06                  84            0.66131
20Nov23_062954|-------------------------- Test #1 --------------------------
20Nov23_062954|Best final individual weights
20Nov23_062954|Individual:
20Nov23_062954|-- Constant hidden layers --
20Nov23_062954|False
20Nov23_062954|Layer 0:
20Nov23_062954|-- Config --
20Nov23_062954|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_062954|-- Weights --
20Nov23_062954|[[ 0.37246  0.50348 -0.38721 -0.36688  2.11975  1.13385]
20Nov23_062954| [ 0.85547  0.24143 -1.64877 -0.78124 -0.43609 -2.21237]
20Nov23_062954| [ 0.42721 -0.76527 -0.51440 -0.75447  0.32484 -0.87275]
20Nov23_062954| [ 0.40346  0.73991  1.07205 -0.69045 -0.65947 -0.69401]
20Nov23_062954| [-0.42540  1.05687  1.57639 -0.19852 -0.01890 -1.25550]
20Nov23_062954| [ 1.01099 -1.20961  1.25712  1.12731 -2.11193 -0.16926]
20Nov23_062954| [ 1.24861  1.19184  0.77574  1.39326 -0.67107  0.80633]
20Nov23_062954| [-1.23263 -0.57257  1.51785  0.29112 -0.35951  0.26049]
20Nov23_062954| [ 0.34632  0.47098 -0.18577 -0.40163 -0.19665 -0.79876]
20Nov23_062954| [ 0.37496 -0.29597  1.24258 -0.16212 -0.65061  0.43949]
20Nov23_062954| [ 0.69488  0.81509 -2.27263  0.15914 -0.46454 -0.23901]
20Nov23_062954| [-0.75193 -1.91140 -1.01764 -0.74874 -0.08376  0.19787]
20Nov23_062954| [ 0.32119 -0.01971  0.44310 -1.10615 -0.05645  0.79914]
20Nov23_062954| [-0.32188  1.83930 -1.27440  1.32363 -0.58820 -1.55631]
20Nov23_062954| [-0.95047 -0.79252  0.53185  1.12978 -2.21543  0.23448]
20Nov23_062954| [ 0.83000 -0.27012  0.28352 -0.87504 -0.14749  0.55266]
20Nov23_062954| [ 1.13130 -0.03457 -0.21537 -0.55833 -1.49729 -0.36937]
20Nov23_062954| [-1.79056 -1.86836 -1.52421 -2.43591  0.70215 -0.37284]
20Nov23_062954| [-0.99829  0.58787 -0.49641  0.56679 -1.24154 -0.79487]
20Nov23_062954| [ 0.28588 -0.57617 -0.68829 -0.21789 -0.08347 -0.22650]
20Nov23_062954| [ 0.57393  0.27574 -0.47918  0.06886 -0.02632 -0.86438]
20Nov23_062954| [-2.37699  0.90398 -1.20198 -0.13722  1.11758  0.95157]
20Nov23_062954| [ 0.80080 -1.27768  0.47634  0.15233 -2.17593  0.08481]
20Nov23_062954| [ 0.96978 -1.60896  0.26377  1.17514 -0.48422 -1.14618]
20Nov23_062954| [-0.58915 -0.04214  1.08863 -1.31963  1.38578  0.43376]
20Nov23_062954| [-0.55311 -0.11218 -1.57961  0.61144  0.21090  0.85095]
20Nov23_062954| [ 0.95030  1.36585 -0.88436  0.55456 -0.29468 -0.06177]
20Nov23_062954| [-0.22244  2.02469 -2.20220  0.51991 -0.32656 -1.13757]
20Nov23_062954| [-1.02569 -0.75926  0.43686  0.74239 -0.03544  0.84045]
20Nov23_062954| [ 1.66723  0.36779  1.48881  1.78736  0.10982 -0.47841]
20Nov23_062954| [ 1.19031 -0.31012 -1.89834 -1.26765 -0.70409 -1.17102]
20Nov23_062954| [ 0.86965  0.28328  0.67962  0.19979 -0.07761  0.88232]
20Nov23_062954| [-0.37120 -0.21892 -0.63646  0.25970  0.09547  0.33285]
20Nov23_062954| [ 0.50033 -0.52733 -0.61247 -1.32671 -0.64064  0.80882]
20Nov23_062954| [-0.28304 -1.42711 -0.62821 -0.16242 -0.56235 -0.05706]
20Nov23_062954| [-1.16828  1.41397 -1.62729 -0.34079  0.64029  0.13870]
20Nov23_062954| [-1.25923 -1.77860  1.33062 -1.19801 -0.63088  0.01647]
20Nov23_062954| [-0.06558 -1.13347 -1.19374  0.35032  1.82112 -1.10971]
20Nov23_062954| [-0.71351  0.94623 -0.04997  0.34918 -0.63262  0.37683]
20Nov23_062954| [ 0.19848 -0.83013 -1.92147 -1.36939  0.83033 -0.13095]
20Nov23_062954| [-0.61376  0.80335  0.24413  0.96333 -1.14089  0.85802]
20Nov23_062954| [-0.36928 -0.42211  0.24520 -1.30295 -1.93237 -0.02548]
20Nov23_062954| [ 0.20256 -0.42818 -1.94283  0.77496  0.53459  1.61769]
20Nov23_062954| [ 0.68188  0.47057  0.20435  1.09097  0.15765  1.04190]
20Nov23_062954| [ 1.33491  0.24345  0.21908  0.18090  1.34449 -0.17898]
20Nov23_062954| [ 0.27847  0.70360  0.51300  1.26013 -1.36985 -0.78610]
20Nov23_062954| [ 1.84673  0.34176  1.17368  0.06267  0.80454 -1.08971]
20Nov23_062954| [-1.55035 -0.68663 -0.37203  0.80163 -0.26877  0.01660]
20Nov23_062954| [ 1.09088 -1.16331  0.24986 -0.12997  1.33586 -1.57542]
20Nov23_062954| [-0.65292 -1.51801  0.65628 -0.59370  2.42713 -0.62132]
20Nov23_062954| [-0.24412 -0.93150 -0.95428  2.12486 -1.66742  0.38608]
20Nov23_062954| [-0.12629 -1.50991  1.01674 -1.39436  0.05675  0.29722]
20Nov23_062954| [ 0.97103 -0.96420  0.21034 -1.70519  1.10287 -1.04466]
20Nov23_062954| [-0.08849  0.34404  1.21360  1.35353  0.10154 -0.21929]
20Nov23_062954| [ 2.57606  0.55820 -0.39108  0.68623 -1.25579 -0.40213]
20Nov23_062954| [-1.14612  0.04346  0.06719  0.49167  1.02429  0.57897]
20Nov23_062954| [-0.52130 -0.28448 -0.88990 -0.47006  0.38699 -1.63998]]
20Nov23_062954|-- Bias --
20Nov23_062954|[-1.43356  1.08152  0.41815  0.00424 -0.24154  0.48990]
20Nov23_062954|Layer 1:
20Nov23_062954|-- Config --
20Nov23_062954|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_062954|-- Weights --
20Nov23_062954|[[-1.12283 -0.64585  0.37135  0.93805  0.50152]
20Nov23_062954| [-0.45128 -0.33951  2.35894 -0.23711  0.47670]
20Nov23_062954| [ 1.07740 -1.29532 -1.29629  0.87008  0.40993]
20Nov23_062954| [ 0.03760  1.27456 -1.39564  0.16391  0.14825]
20Nov23_062954| [-1.16091 -1.49048  0.95524 -0.46229  0.11068]
20Nov23_062954| [-0.26762  1.19525  1.35283  2.28556 -0.02087]]
20Nov23_062954|-- Bias --
20Nov23_062954|[-0.01568 -0.30813  0.67368 -0.55501  0.11533]
20Nov23_062954|Layer 2:
20Nov23_062954|-- Config --
20Nov23_062954|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_062954|-- Weights --
20Nov23_062954|[[ 0.73189  0.25994  0.61296 -0.76909  0.25937]
20Nov23_062954| [-0.88936 -0.61503 -0.69177 -0.58393  0.75519]
20Nov23_062954| [ 0.27706 -1.82774  0.74789  0.24210  0.70912]
20Nov23_062954| [-0.71073 -0.66461 -0.05384  0.42014 -0.09637]
20Nov23_062954| [ 0.18630 -0.67560  0.79441  0.18604 -0.70347]]
20Nov23_062954|-- Bias --
20Nov23_062954|[ 1.74623  0.69730  0.72008 -0.20004  0.15599]
20Nov23_062954|Layer 3:
20Nov23_062954|-- Config --
20Nov23_062954|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_062954|-- Weights --
20Nov23_062954|[[ 0.78512  0.58495  1.01708  1.05505 -0.47074]
20Nov23_062954| [ 0.09227 -0.27877  0.05296  0.69659  0.56285]
20Nov23_062954| [ 0.08212 -0.85808  1.14160 -0.25897 -0.73503]
20Nov23_062954| [-1.34393 -0.15823  0.51240 -0.30438 -0.15319]
20Nov23_062954| [-0.18853  0.79089 -0.34260 -0.42000  0.98012]]
20Nov23_062954|-- Bias --
20Nov23_062954|[ 0.02020 -0.47953 -0.29788  0.95327  0.93818]
20Nov23_062954|Layer 4:
20Nov23_062954|-- Config --
20Nov23_062954|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_062954|-- Weights --
20Nov23_062954|[[-1.15005 -1.14488]
20Nov23_062954| [-0.70732 -0.77066]
20Nov23_062954| [-0.92771 -0.61093]
20Nov23_062954| [-0.90771 -1.04766]
20Nov23_062954| [ 1.53415  1.37750]]
20Nov23_062954|-- Bias --
20Nov23_062954|[-0.45752 -0.43811]
20Nov23_062954|Predicting the validation and test data with the Best final individual.
20Nov23_063001| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_063001|-----------  ------------------  --------------------  ----------
20Nov23_063001|Validation         42.09                  84            0.00000
20Nov23_063001|   Test            26.59                  84            0.68846
20Nov23_063001|-------------------------- Test #2 --------------------------
20Nov23_063001|Best final individual weights
20Nov23_063001|Individual:
20Nov23_063001|-- Constant hidden layers --
20Nov23_063001|False
20Nov23_063001|Layer 0:
20Nov23_063001|-- Config --
20Nov23_063001|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063001|-- Weights --
20Nov23_063001|[[ 0.37246  0.50348 -0.38721 -0.36688  2.11975  1.13385]
20Nov23_063001| [ 0.85547  0.24143 -1.64877 -0.78124 -0.43609 -2.21237]
20Nov23_063001| [ 0.42721 -0.76527 -0.51440 -0.75447  0.32484 -0.87275]
20Nov23_063001| [ 0.40346  0.73991  1.07205 -0.69045 -0.65947 -0.69401]
20Nov23_063001| [-0.42540  1.05687  1.57639 -0.19852 -0.01890 -1.25550]
20Nov23_063001| [ 1.01099 -1.20961  1.25712  1.12731 -2.11193 -0.16926]
20Nov23_063001| [ 1.24861  1.19184  0.77574  1.39326 -0.67107  0.80633]
20Nov23_063001| [-1.23263 -0.57257  1.51785  0.29112 -0.35951  0.26049]
20Nov23_063001| [ 0.34632  0.47098 -0.18577 -0.40163 -0.19665 -0.79876]
20Nov23_063001| [ 0.37496 -0.29597  1.24258 -0.16212 -0.65061  0.43949]
20Nov23_063001| [ 0.69488  0.81509 -2.27263  0.15914 -0.46454 -0.23901]
20Nov23_063001| [-0.75193 -1.91140 -1.01764 -0.74874 -0.08376  0.19787]
20Nov23_063001| [ 0.32119 -0.01971  0.44310 -1.10615 -0.05645  0.79914]
20Nov23_063001| [-0.32188  1.83930 -1.27440  1.32363 -0.58820 -1.55631]
20Nov23_063001| [-0.95047 -0.79252  0.53185  1.12978 -2.21543  0.23448]
20Nov23_063001| [ 0.83000 -0.27012  0.28352 -0.87504 -0.14749  0.55266]
20Nov23_063001| [ 1.13130 -0.03457 -0.21537 -0.55833 -1.49729 -0.36937]
20Nov23_063001| [-1.79056 -1.86836 -1.52421 -2.43591  0.70215 -0.37284]
20Nov23_063001| [-0.99829  0.58787 -0.49641  0.56679 -1.24154 -0.79487]
20Nov23_063001| [ 0.28588 -0.57617 -0.68829 -0.21789 -0.08347 -0.22650]
20Nov23_063001| [ 0.57393  0.27574 -0.47918  0.06886 -0.02632 -0.86438]
20Nov23_063001| [-2.37699  0.90398 -1.20198 -0.13722  1.11758  0.95157]
20Nov23_063001| [ 0.80080 -1.27768  0.47634  0.15233 -2.17593  0.08481]
20Nov23_063001| [ 0.96978 -1.60896  0.26377  1.17514 -0.48422 -1.14618]
20Nov23_063001| [-0.58915 -0.04214  1.08863 -1.31963  1.38578  0.43376]
20Nov23_063001| [-0.55311 -0.11218 -1.57961  0.61144  0.21090  0.85095]
20Nov23_063001| [ 0.95030  1.36585 -0.88436  0.55456 -0.29468 -0.06177]
20Nov23_063001| [-0.22244  2.02469 -2.20220  0.51991 -0.32656 -1.13757]
20Nov23_063001| [-1.02569 -0.75926  0.43686  0.74239 -0.03544  0.84045]
20Nov23_063001| [ 1.66723  0.36779  1.48881  1.78736  0.10982 -0.47841]
20Nov23_063001| [ 1.19031 -0.31012 -1.89834 -1.26765 -0.70409 -1.17102]
20Nov23_063001| [ 0.86965  0.28328  0.67962  0.19979 -0.07761  0.88232]
20Nov23_063001| [-0.37120 -0.21892 -0.63646  0.25970  0.09547  0.33285]
20Nov23_063001| [ 0.50033 -0.52733 -0.61247 -1.32671 -0.64064  0.80882]
20Nov23_063001| [-0.28304 -1.42711 -0.62821 -0.16242 -0.56235 -0.05706]
20Nov23_063001| [-1.16828  1.41397 -1.62729 -0.34079  0.64029  0.13870]
20Nov23_063001| [-1.25923 -1.77860  1.33062 -1.19801 -0.63088  0.01647]
20Nov23_063001| [-0.06558 -1.13347 -1.19374  0.35032  1.82112 -1.10971]
20Nov23_063001| [-0.71351  0.94623 -0.04997  0.34918 -0.63262  0.37683]
20Nov23_063001| [ 0.19848 -0.83013 -1.92147 -1.36939  0.83033 -0.13095]
20Nov23_063001| [-0.61376  0.80335  0.24413  0.96333 -1.14089  0.85802]
20Nov23_063001| [-0.36928 -0.42211  0.24520 -1.30295 -1.93237 -0.02548]
20Nov23_063001| [ 0.20256 -0.42818 -1.94283  0.77496  0.53459  1.61769]
20Nov23_063001| [ 0.68188  0.47057  0.20435  1.09097  0.15765  1.04190]
20Nov23_063001| [ 1.33491  0.24345  0.21908  0.18090  1.34449 -0.17898]
20Nov23_063001| [ 0.27847  0.70360  0.51300  1.26013 -1.36985 -0.78610]
20Nov23_063001| [ 1.84673  0.34176  1.17368  0.06267  0.80454 -1.08971]
20Nov23_063001| [-1.55035 -0.68663 -0.37203  0.80163 -0.26877  0.01660]
20Nov23_063001| [ 1.09088 -1.16331  0.24986 -0.12997  1.33586 -1.57542]
20Nov23_063001| [-0.65292 -1.51801  0.65628 -0.59370  2.42713 -0.62132]
20Nov23_063001| [-0.24412 -0.93150 -0.95428  2.12486 -1.66742  0.38608]
20Nov23_063001| [-0.12629 -1.50991  1.01674 -1.39436  0.05675  0.29722]
20Nov23_063001| [ 0.97103 -0.96420  0.21034 -1.70519  1.10287 -1.04466]
20Nov23_063001| [-0.08849  0.34404  1.21360  1.35353  0.10154 -0.21929]
20Nov23_063001| [ 2.57606  0.55820 -0.39108  0.68623 -1.25579 -0.40213]
20Nov23_063001| [-1.14612  0.04346  0.06719  0.49167  1.02429  0.57897]
20Nov23_063001| [-0.52130 -0.28448 -0.88990 -0.47006  0.38699 -1.63998]]
20Nov23_063001|-- Bias --
20Nov23_063001|[-1.43356  1.08152  0.41815  0.00424 -0.24154  0.48990]
20Nov23_063001|Layer 1:
20Nov23_063001|-- Config --
20Nov23_063001|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063001|-- Weights --
20Nov23_063001|[[-1.12283 -0.64585  0.37135  0.93805  0.50152]
20Nov23_063001| [-0.45128 -0.33951  2.35894 -0.23711  0.47670]
20Nov23_063001| [ 1.07740 -1.29532 -1.29629  0.87008  0.40993]
20Nov23_063001| [ 0.03760  1.27456 -1.39564  0.16391  0.14825]
20Nov23_063001| [-1.16091 -1.49048  0.95524 -0.46229  0.11068]
20Nov23_063001| [-0.26762  1.19525  1.35283  2.28556 -0.02087]]
20Nov23_063001|-- Bias --
20Nov23_063001|[-0.01568 -0.30813  0.67368 -0.55501  0.11533]
20Nov23_063001|Layer 2:
20Nov23_063001|-- Config --
20Nov23_063001|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063001|-- Weights --
20Nov23_063001|[[ 0.73189  0.25994  0.61296 -0.76909  0.25937]
20Nov23_063001| [-0.88936 -0.61503 -0.69177 -0.58393  0.75519]
20Nov23_063001| [ 0.27706 -1.82774  0.74789  0.24210  0.70912]
20Nov23_063001| [-0.71073 -0.66461 -0.05384  0.42014 -0.09637]
20Nov23_063001| [ 0.18630 -0.67560  0.79441  0.18604 -0.70347]]
20Nov23_063001|-- Bias --
20Nov23_063001|[ 1.74623  0.69730  0.72008 -0.20004  0.15599]
20Nov23_063001|Layer 3:
20Nov23_063001|-- Config --
20Nov23_063001|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063001|-- Weights --
20Nov23_063001|[[ 0.78512  0.58495  1.01708  1.05505 -0.47074]
20Nov23_063001| [ 0.09227 -0.27877  0.05296  0.69659  0.56285]
20Nov23_063001| [ 0.08212 -0.85808  1.14160 -0.25897 -0.73503]
20Nov23_063001| [-1.34393 -0.15823  0.51240 -0.30438 -0.15319]
20Nov23_063001| [-0.18853  0.79089 -0.34260 -0.42000  0.98012]]
20Nov23_063001|-- Bias --
20Nov23_063001|[ 0.02020 -0.47953 -0.29788  0.95327  0.93818]
20Nov23_063001|Layer 4:
20Nov23_063001|-- Config --
20Nov23_063001|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063001|-- Weights --
20Nov23_063001|[[-1.15005 -1.14488]
20Nov23_063001| [-0.70732 -0.77066]
20Nov23_063001| [-0.92771 -0.61093]
20Nov23_063001| [-0.90771 -1.04766]
20Nov23_063001| [ 1.53415  1.37750]]
20Nov23_063001|-- Bias --
20Nov23_063001|[-0.45752 -0.43811]
20Nov23_063001|Predicting the validation and test data with the Best final individual.
20Nov23_063007| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_063007|-----------  ------------------  --------------------  ----------
20Nov23_063007|Validation         42.00                  84            0.00000
20Nov23_063007|   Test            28.50                  84            0.56424
20Nov23_063007|-------------------------- Test #3 --------------------------
20Nov23_063007|Best final individual weights
20Nov23_063007|Individual:
20Nov23_063007|-- Constant hidden layers --
20Nov23_063007|False
20Nov23_063007|Layer 0:
20Nov23_063007|-- Config --
20Nov23_063007|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063007|-- Weights --
20Nov23_063007|[[ 0.37246  0.50348 -0.38721 -0.36688  2.11975  1.13385]
20Nov23_063007| [ 0.85547  0.24143 -1.64877 -0.78124 -0.43609 -2.21237]
20Nov23_063007| [ 0.42721 -0.76527 -0.51440 -0.75447  0.32484 -0.87275]
20Nov23_063007| [ 0.40346  0.73991  1.07205 -0.69045 -0.65947 -0.69401]
20Nov23_063007| [-0.42540  1.05687  1.57639 -0.19852 -0.01890 -1.25550]
20Nov23_063007| [ 1.01099 -1.20961  1.25712  1.12731 -2.11193 -0.16926]
20Nov23_063007| [ 1.24861  1.19184  0.77574  1.39326 -0.67107  0.80633]
20Nov23_063007| [-1.23263 -0.57257  1.51785  0.29112 -0.35951  0.26049]
20Nov23_063007| [ 0.34632  0.47098 -0.18577 -0.40163 -0.19665 -0.79876]
20Nov23_063007| [ 0.37496 -0.29597  1.24258 -0.16212 -0.65061  0.43949]
20Nov23_063007| [ 0.69488  0.81509 -2.27263  0.15914 -0.46454 -0.23901]
20Nov23_063007| [-0.75193 -1.91140 -1.01764 -0.74874 -0.08376  0.19787]
20Nov23_063007| [ 0.32119 -0.01971  0.44310 -1.10615 -0.05645  0.79914]
20Nov23_063007| [-0.32188  1.83930 -1.27440  1.32363 -0.58820 -1.55631]
20Nov23_063007| [-0.95047 -0.79252  0.53185  1.12978 -2.21543  0.23448]
20Nov23_063007| [ 0.83000 -0.27012  0.28352 -0.87504 -0.14749  0.55266]
20Nov23_063007| [ 1.13130 -0.03457 -0.21537 -0.55833 -1.49729 -0.36937]
20Nov23_063007| [-1.79056 -1.86836 -1.52421 -2.43591  0.70215 -0.37284]
20Nov23_063007| [-0.99829  0.58787 -0.49641  0.56679 -1.24154 -0.79487]
20Nov23_063007| [ 0.28588 -0.57617 -0.68829 -0.21789 -0.08347 -0.22650]
20Nov23_063007| [ 0.57393  0.27574 -0.47918  0.06886 -0.02632 -0.86438]
20Nov23_063007| [-2.37699  0.90398 -1.20198 -0.13722  1.11758  0.95157]
20Nov23_063007| [ 0.80080 -1.27768  0.47634  0.15233 -2.17593  0.08481]
20Nov23_063007| [ 0.96978 -1.60896  0.26377  1.17514 -0.48422 -1.14618]
20Nov23_063007| [-0.58915 -0.04214  1.08863 -1.31963  1.38578  0.43376]
20Nov23_063007| [-0.55311 -0.11218 -1.57961  0.61144  0.21090  0.85095]
20Nov23_063007| [ 0.95030  1.36585 -0.88436  0.55456 -0.29468 -0.06177]
20Nov23_063007| [-0.22244  2.02469 -2.20220  0.51991 -0.32656 -1.13757]
20Nov23_063007| [-1.02569 -0.75926  0.43686  0.74239 -0.03544  0.84045]
20Nov23_063007| [ 1.66723  0.36779  1.48881  1.78736  0.10982 -0.47841]
20Nov23_063007| [ 1.19031 -0.31012 -1.89834 -1.26765 -0.70409 -1.17102]
20Nov23_063007| [ 0.86965  0.28328  0.67962  0.19979 -0.07761  0.88232]
20Nov23_063007| [-0.37120 -0.21892 -0.63646  0.25970  0.09547  0.33285]
20Nov23_063007| [ 0.50033 -0.52733 -0.61247 -1.32671 -0.64064  0.80882]
20Nov23_063007| [-0.28304 -1.42711 -0.62821 -0.16242 -0.56235 -0.05706]
20Nov23_063007| [-1.16828  1.41397 -1.62729 -0.34079  0.64029  0.13870]
20Nov23_063007| [-1.25923 -1.77860  1.33062 -1.19801 -0.63088  0.01647]
20Nov23_063007| [-0.06558 -1.13347 -1.19374  0.35032  1.82112 -1.10971]
20Nov23_063007| [-0.71351  0.94623 -0.04997  0.34918 -0.63262  0.37683]
20Nov23_063007| [ 0.19848 -0.83013 -1.92147 -1.36939  0.83033 -0.13095]
20Nov23_063007| [-0.61376  0.80335  0.24413  0.96333 -1.14089  0.85802]
20Nov23_063007| [-0.36928 -0.42211  0.24520 -1.30295 -1.93237 -0.02548]
20Nov23_063007| [ 0.20256 -0.42818 -1.94283  0.77496  0.53459  1.61769]
20Nov23_063007| [ 0.68188  0.47057  0.20435  1.09097  0.15765  1.04190]
20Nov23_063007| [ 1.33491  0.24345  0.21908  0.18090  1.34449 -0.17898]
20Nov23_063007| [ 0.27847  0.70360  0.51300  1.26013 -1.36985 -0.78610]
20Nov23_063007| [ 1.84673  0.34176  1.17368  0.06267  0.80454 -1.08971]
20Nov23_063007| [-1.55035 -0.68663 -0.37203  0.80163 -0.26877  0.01660]
20Nov23_063007| [ 1.09088 -1.16331  0.24986 -0.12997  1.33586 -1.57542]
20Nov23_063007| [-0.65292 -1.51801  0.65628 -0.59370  2.42713 -0.62132]
20Nov23_063007| [-0.24412 -0.93150 -0.95428  2.12486 -1.66742  0.38608]
20Nov23_063007| [-0.12629 -1.50991  1.01674 -1.39436  0.05675  0.29722]
20Nov23_063007| [ 0.97103 -0.96420  0.21034 -1.70519  1.10287 -1.04466]
20Nov23_063007| [-0.08849  0.34404  1.21360  1.35353  0.10154 -0.21929]
20Nov23_063007| [ 2.57606  0.55820 -0.39108  0.68623 -1.25579 -0.40213]
20Nov23_063007| [-1.14612  0.04346  0.06719  0.49167  1.02429  0.57897]
20Nov23_063007| [-0.52130 -0.28448 -0.88990 -0.47006  0.38699 -1.63998]]
20Nov23_063007|-- Bias --
20Nov23_063007|[-1.43356  1.08152  0.41815  0.00424 -0.24154  0.48990]
20Nov23_063007|Layer 1:
20Nov23_063007|-- Config --
20Nov23_063007|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063007|-- Weights --
20Nov23_063007|[[-1.12283 -0.64585  0.37135  0.93805  0.50152]
20Nov23_063007| [-0.45128 -0.33951  2.35894 -0.23711  0.47670]
20Nov23_063007| [ 1.07740 -1.29532 -1.29629  0.87008  0.40993]
20Nov23_063007| [ 0.03760  1.27456 -1.39564  0.16391  0.14825]
20Nov23_063007| [-1.16091 -1.49048  0.95524 -0.46229  0.11068]
20Nov23_063007| [-0.26762  1.19525  1.35283  2.28556 -0.02087]]
20Nov23_063007|-- Bias --
20Nov23_063007|[-0.01568 -0.30813  0.67368 -0.55501  0.11533]
20Nov23_063007|Layer 2:
20Nov23_063007|-- Config --
20Nov23_063007|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063007|-- Weights --
20Nov23_063007|[[ 0.73189  0.25994  0.61296 -0.76909  0.25937]
20Nov23_063007| [-0.88936 -0.61503 -0.69177 -0.58393  0.75519]
20Nov23_063007| [ 0.27706 -1.82774  0.74789  0.24210  0.70912]
20Nov23_063007| [-0.71073 -0.66461 -0.05384  0.42014 -0.09637]
20Nov23_063007| [ 0.18630 -0.67560  0.79441  0.18604 -0.70347]]
20Nov23_063007|-- Bias --
20Nov23_063007|[ 1.74623  0.69730  0.72008 -0.20004  0.15599]
20Nov23_063007|Layer 3:
20Nov23_063007|-- Config --
20Nov23_063007|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063007|-- Weights --
20Nov23_063007|[[ 0.78512  0.58495  1.01708  1.05505 -0.47074]
20Nov23_063007| [ 0.09227 -0.27877  0.05296  0.69659  0.56285]
20Nov23_063007| [ 0.08212 -0.85808  1.14160 -0.25897 -0.73503]
20Nov23_063007| [-1.34393 -0.15823  0.51240 -0.30438 -0.15319]
20Nov23_063007| [-0.18853  0.79089 -0.34260 -0.42000  0.98012]]
20Nov23_063007|-- Bias --
20Nov23_063007|[ 0.02020 -0.47953 -0.29788  0.95327  0.93818]
20Nov23_063007|Layer 4:
20Nov23_063007|-- Config --
20Nov23_063007|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063007|-- Weights --
20Nov23_063007|[[-1.15005 -1.14488]
20Nov23_063007| [-0.70732 -0.77066]
20Nov23_063007| [-0.92771 -0.61093]
20Nov23_063007| [-0.90771 -1.04766]
20Nov23_063007| [ 1.53415  1.37750]]
20Nov23_063007|-- Bias --
20Nov23_063007|[-0.45752 -0.43811]
20Nov23_063007|Predicting the validation and test data with the Best final individual.
20Nov23_063014| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_063014|-----------  ------------------  --------------------  ----------
20Nov23_063014|Validation         24.87                  84            0.70690
20Nov23_063014|   Test            60.12                  84            0.74667
20Nov23_063014|-------------------------- Test #4 --------------------------
20Nov23_063014|Best final individual weights
20Nov23_063014|Individual:
20Nov23_063014|-- Constant hidden layers --
20Nov23_063014|False
20Nov23_063014|Layer 0:
20Nov23_063014|-- Config --
20Nov23_063014|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063014|-- Weights --
20Nov23_063014|[[ 0.37246  0.50348 -0.38721 -0.36688  2.11975  1.13385]
20Nov23_063014| [ 0.85547  0.24143 -1.64877 -0.78124 -0.43609 -2.21237]
20Nov23_063014| [ 0.42721 -0.76527 -0.51440 -0.75447  0.32484 -0.87275]
20Nov23_063014| [ 0.40346  0.73991  1.07205 -0.69045 -0.65947 -0.69401]
20Nov23_063014| [-0.42540  1.05687  1.57639 -0.19852 -0.01890 -1.25550]
20Nov23_063014| [ 1.01099 -1.20961  1.25712  1.12731 -2.11193 -0.16926]
20Nov23_063014| [ 1.24861  1.19184  0.77574  1.39326 -0.67107  0.80633]
20Nov23_063014| [-1.23263 -0.57257  1.51785  0.29112 -0.35951  0.26049]
20Nov23_063014| [ 0.34632  0.47098 -0.18577 -0.40163 -0.19665 -0.79876]
20Nov23_063014| [ 0.37496 -0.29597  1.24258 -0.16212 -0.65061  0.43949]
20Nov23_063014| [ 0.69488  0.81509 -2.27263  0.15914 -0.46454 -0.23901]
20Nov23_063014| [-0.75193 -1.91140 -1.01764 -0.74874 -0.08376  0.19787]
20Nov23_063014| [ 0.32119 -0.01971  0.44310 -1.10615 -0.05645  0.79914]
20Nov23_063014| [-0.32188  1.83930 -1.27440  1.32363 -0.58820 -1.55631]
20Nov23_063014| [-0.95047 -0.79252  0.53185  1.12978 -2.21543  0.23448]
20Nov23_063014| [ 0.83000 -0.27012  0.28352 -0.87504 -0.14749  0.55266]
20Nov23_063014| [ 1.13130 -0.03457 -0.21537 -0.55833 -1.49729 -0.36937]
20Nov23_063014| [-1.79056 -1.86836 -1.52421 -2.43591  0.70215 -0.37284]
20Nov23_063014| [-0.99829  0.58787 -0.49641  0.56679 -1.24154 -0.79487]
20Nov23_063014| [ 0.28588 -0.57617 -0.68829 -0.21789 -0.08347 -0.22650]
20Nov23_063014| [ 0.57393  0.27574 -0.47918  0.06886 -0.02632 -0.86438]
20Nov23_063014| [-2.37699  0.90398 -1.20198 -0.13722  1.11758  0.95157]
20Nov23_063014| [ 0.80080 -1.27768  0.47634  0.15233 -2.17593  0.08481]
20Nov23_063014| [ 0.96978 -1.60896  0.26377  1.17514 -0.48422 -1.14618]
20Nov23_063014| [-0.58915 -0.04214  1.08863 -1.31963  1.38578  0.43376]
20Nov23_063014| [-0.55311 -0.11218 -1.57961  0.61144  0.21090  0.85095]
20Nov23_063014| [ 0.95030  1.36585 -0.88436  0.55456 -0.29468 -0.06177]
20Nov23_063014| [-0.22244  2.02469 -2.20220  0.51991 -0.32656 -1.13757]
20Nov23_063014| [-1.02569 -0.75926  0.43686  0.74239 -0.03544  0.84045]
20Nov23_063014| [ 1.66723  0.36779  1.48881  1.78736  0.10982 -0.47841]
20Nov23_063014| [ 1.19031 -0.31012 -1.89834 -1.26765 -0.70409 -1.17102]
20Nov23_063014| [ 0.86965  0.28328  0.67962  0.19979 -0.07761  0.88232]
20Nov23_063014| [-0.37120 -0.21892 -0.63646  0.25970  0.09547  0.33285]
20Nov23_063014| [ 0.50033 -0.52733 -0.61247 -1.32671 -0.64064  0.80882]
20Nov23_063014| [-0.28304 -1.42711 -0.62821 -0.16242 -0.56235 -0.05706]
20Nov23_063014| [-1.16828  1.41397 -1.62729 -0.34079  0.64029  0.13870]
20Nov23_063014| [-1.25923 -1.77860  1.33062 -1.19801 -0.63088  0.01647]
20Nov23_063014| [-0.06558 -1.13347 -1.19374  0.35032  1.82112 -1.10971]
20Nov23_063014| [-0.71351  0.94623 -0.04997  0.34918 -0.63262  0.37683]
20Nov23_063014| [ 0.19848 -0.83013 -1.92147 -1.36939  0.83033 -0.13095]
20Nov23_063014| [-0.61376  0.80335  0.24413  0.96333 -1.14089  0.85802]
20Nov23_063014| [-0.36928 -0.42211  0.24520 -1.30295 -1.93237 -0.02548]
20Nov23_063014| [ 0.20256 -0.42818 -1.94283  0.77496  0.53459  1.61769]
20Nov23_063014| [ 0.68188  0.47057  0.20435  1.09097  0.15765  1.04190]
20Nov23_063014| [ 1.33491  0.24345  0.21908  0.18090  1.34449 -0.17898]
20Nov23_063014| [ 0.27847  0.70360  0.51300  1.26013 -1.36985 -0.78610]
20Nov23_063014| [ 1.84673  0.34176  1.17368  0.06267  0.80454 -1.08971]
20Nov23_063014| [-1.55035 -0.68663 -0.37203  0.80163 -0.26877  0.01660]
20Nov23_063014| [ 1.09088 -1.16331  0.24986 -0.12997  1.33586 -1.57542]
20Nov23_063014| [-0.65292 -1.51801  0.65628 -0.59370  2.42713 -0.62132]
20Nov23_063014| [-0.24412 -0.93150 -0.95428  2.12486 -1.66742  0.38608]
20Nov23_063014| [-0.12629 -1.50991  1.01674 -1.39436  0.05675  0.29722]
20Nov23_063014| [ 0.97103 -0.96420  0.21034 -1.70519  1.10287 -1.04466]
20Nov23_063014| [-0.08849  0.34404  1.21360  1.35353  0.10154 -0.21929]
20Nov23_063014| [ 2.57606  0.55820 -0.39108  0.68623 -1.25579 -0.40213]
20Nov23_063014| [-1.14612  0.04346  0.06719  0.49167  1.02429  0.57897]
20Nov23_063014| [-0.52130 -0.28448 -0.88990 -0.47006  0.38699 -1.63998]]
20Nov23_063014|-- Bias --
20Nov23_063014|[-1.43356  1.08152  0.41815  0.00424 -0.24154  0.48990]
20Nov23_063014|Layer 1:
20Nov23_063014|-- Config --
20Nov23_063014|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063014|-- Weights --
20Nov23_063014|[[-1.12283 -0.64585  0.37135  0.93805  0.50152]
20Nov23_063014| [-0.45128 -0.33951  2.35894 -0.23711  0.47670]
20Nov23_063014| [ 1.07740 -1.29532 -1.29629  0.87008  0.40993]
20Nov23_063014| [ 0.03760  1.27456 -1.39564  0.16391  0.14825]
20Nov23_063014| [-1.16091 -1.49048  0.95524 -0.46229  0.11068]
20Nov23_063014| [-0.26762  1.19525  1.35283  2.28556 -0.02087]]
20Nov23_063014|-- Bias --
20Nov23_063014|[-0.01568 -0.30813  0.67368 -0.55501  0.11533]
20Nov23_063014|Layer 2:
20Nov23_063014|-- Config --
20Nov23_063014|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063014|-- Weights --
20Nov23_063014|[[ 0.73189  0.25994  0.61296 -0.76909  0.25937]
20Nov23_063014| [-0.88936 -0.61503 -0.69177 -0.58393  0.75519]
20Nov23_063014| [ 0.27706 -1.82774  0.74789  0.24210  0.70912]
20Nov23_063014| [-0.71073 -0.66461 -0.05384  0.42014 -0.09637]
20Nov23_063014| [ 0.18630 -0.67560  0.79441  0.18604 -0.70347]]
20Nov23_063014|-- Bias --
20Nov23_063014|[ 1.74623  0.69730  0.72008 -0.20004  0.15599]
20Nov23_063014|Layer 3:
20Nov23_063014|-- Config --
20Nov23_063014|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063014|-- Weights --
20Nov23_063014|[[ 0.78512  0.58495  1.01708  1.05505 -0.47074]
20Nov23_063014| [ 0.09227 -0.27877  0.05296  0.69659  0.56285]
20Nov23_063014| [ 0.08212 -0.85808  1.14160 -0.25897 -0.73503]
20Nov23_063014| [-1.34393 -0.15823  0.51240 -0.30438 -0.15319]
20Nov23_063014| [-0.18853  0.79089 -0.34260 -0.42000  0.98012]]
20Nov23_063014|-- Bias --
20Nov23_063014|[ 0.02020 -0.47953 -0.29788  0.95327  0.93818]
20Nov23_063014|Layer 4:
20Nov23_063014|-- Config --
20Nov23_063014|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063014|-- Weights --
20Nov23_063014|[[-1.15005 -1.14488]
20Nov23_063014| [-0.70732 -0.77066]
20Nov23_063014| [-0.92771 -0.61093]
20Nov23_063014| [-0.90771 -1.04766]
20Nov23_063014| [ 1.53415  1.37750]]
20Nov23_063014|-- Bias --
20Nov23_063014|[-0.45752 -0.43811]
20Nov23_063014|Predicting the validation and test data with the Best final individual.
20Nov23_063021| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_063021|-----------  ------------------  --------------------  ----------
20Nov23_063021|Validation         27.48                  84            0.71139
20Nov23_063021|   Test            36.40                  84            0.00000
20Nov23_063021|-------------------------- Test #5 --------------------------
20Nov23_063021|Best final individual weights
20Nov23_063021|Individual:
20Nov23_063021|-- Constant hidden layers --
20Nov23_063021|False
20Nov23_063021|Layer 0:
20Nov23_063021|-- Config --
20Nov23_063021|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063021|-- Weights --
20Nov23_063021|[[ 0.37246  0.50348 -0.38721 -0.36688  2.11975  1.13385]
20Nov23_063021| [ 0.85547  0.24143 -1.64877 -0.78124 -0.43609 -2.21237]
20Nov23_063021| [ 0.42721 -0.76527 -0.51440 -0.75447  0.32484 -0.87275]
20Nov23_063021| [ 0.40346  0.73991  1.07205 -0.69045 -0.65947 -0.69401]
20Nov23_063021| [-0.42540  1.05687  1.57639 -0.19852 -0.01890 -1.25550]
20Nov23_063021| [ 1.01099 -1.20961  1.25712  1.12731 -2.11193 -0.16926]
20Nov23_063021| [ 1.24861  1.19184  0.77574  1.39326 -0.67107  0.80633]
20Nov23_063021| [-1.23263 -0.57257  1.51785  0.29112 -0.35951  0.26049]
20Nov23_063021| [ 0.34632  0.47098 -0.18577 -0.40163 -0.19665 -0.79876]
20Nov23_063021| [ 0.37496 -0.29597  1.24258 -0.16212 -0.65061  0.43949]
20Nov23_063021| [ 0.69488  0.81509 -2.27263  0.15914 -0.46454 -0.23901]
20Nov23_063021| [-0.75193 -1.91140 -1.01764 -0.74874 -0.08376  0.19787]
20Nov23_063021| [ 0.32119 -0.01971  0.44310 -1.10615 -0.05645  0.79914]
20Nov23_063021| [-0.32188  1.83930 -1.27440  1.32363 -0.58820 -1.55631]
20Nov23_063021| [-0.95047 -0.79252  0.53185  1.12978 -2.21543  0.23448]
20Nov23_063021| [ 0.83000 -0.27012  0.28352 -0.87504 -0.14749  0.55266]
20Nov23_063021| [ 1.13130 -0.03457 -0.21537 -0.55833 -1.49729 -0.36937]
20Nov23_063021| [-1.79056 -1.86836 -1.52421 -2.43591  0.70215 -0.37284]
20Nov23_063021| [-0.99829  0.58787 -0.49641  0.56679 -1.24154 -0.79487]
20Nov23_063021| [ 0.28588 -0.57617 -0.68829 -0.21789 -0.08347 -0.22650]
20Nov23_063021| [ 0.57393  0.27574 -0.47918  0.06886 -0.02632 -0.86438]
20Nov23_063021| [-2.37699  0.90398 -1.20198 -0.13722  1.11758  0.95157]
20Nov23_063021| [ 0.80080 -1.27768  0.47634  0.15233 -2.17593  0.08481]
20Nov23_063021| [ 0.96978 -1.60896  0.26377  1.17514 -0.48422 -1.14618]
20Nov23_063021| [-0.58915 -0.04214  1.08863 -1.31963  1.38578  0.43376]
20Nov23_063021| [-0.55311 -0.11218 -1.57961  0.61144  0.21090  0.85095]
20Nov23_063021| [ 0.95030  1.36585 -0.88436  0.55456 -0.29468 -0.06177]
20Nov23_063021| [-0.22244  2.02469 -2.20220  0.51991 -0.32656 -1.13757]
20Nov23_063021| [-1.02569 -0.75926  0.43686  0.74239 -0.03544  0.84045]
20Nov23_063021| [ 1.66723  0.36779  1.48881  1.78736  0.10982 -0.47841]
20Nov23_063021| [ 1.19031 -0.31012 -1.89834 -1.26765 -0.70409 -1.17102]
20Nov23_063021| [ 0.86965  0.28328  0.67962  0.19979 -0.07761  0.88232]
20Nov23_063021| [-0.37120 -0.21892 -0.63646  0.25970  0.09547  0.33285]
20Nov23_063021| [ 0.50033 -0.52733 -0.61247 -1.32671 -0.64064  0.80882]
20Nov23_063021| [-0.28304 -1.42711 -0.62821 -0.16242 -0.56235 -0.05706]
20Nov23_063021| [-1.16828  1.41397 -1.62729 -0.34079  0.64029  0.13870]
20Nov23_063021| [-1.25923 -1.77860  1.33062 -1.19801 -0.63088  0.01647]
20Nov23_063021| [-0.06558 -1.13347 -1.19374  0.35032  1.82112 -1.10971]
20Nov23_063021| [-0.71351  0.94623 -0.04997  0.34918 -0.63262  0.37683]
20Nov23_063021| [ 0.19848 -0.83013 -1.92147 -1.36939  0.83033 -0.13095]
20Nov23_063021| [-0.61376  0.80335  0.24413  0.96333 -1.14089  0.85802]
20Nov23_063021| [-0.36928 -0.42211  0.24520 -1.30295 -1.93237 -0.02548]
20Nov23_063021| [ 0.20256 -0.42818 -1.94283  0.77496  0.53459  1.61769]
20Nov23_063021| [ 0.68188  0.47057  0.20435  1.09097  0.15765  1.04190]
20Nov23_063021| [ 1.33491  0.24345  0.21908  0.18090  1.34449 -0.17898]
20Nov23_063021| [ 0.27847  0.70360  0.51300  1.26013 -1.36985 -0.78610]
20Nov23_063021| [ 1.84673  0.34176  1.17368  0.06267  0.80454 -1.08971]
20Nov23_063021| [-1.55035 -0.68663 -0.37203  0.80163 -0.26877  0.01660]
20Nov23_063021| [ 1.09088 -1.16331  0.24986 -0.12997  1.33586 -1.57542]
20Nov23_063021| [-0.65292 -1.51801  0.65628 -0.59370  2.42713 -0.62132]
20Nov23_063021| [-0.24412 -0.93150 -0.95428  2.12486 -1.66742  0.38608]
20Nov23_063021| [-0.12629 -1.50991  1.01674 -1.39436  0.05675  0.29722]
20Nov23_063021| [ 0.97103 -0.96420  0.21034 -1.70519  1.10287 -1.04466]
20Nov23_063021| [-0.08849  0.34404  1.21360  1.35353  0.10154 -0.21929]
20Nov23_063021| [ 2.57606  0.55820 -0.39108  0.68623 -1.25579 -0.40213]
20Nov23_063021| [-1.14612  0.04346  0.06719  0.49167  1.02429  0.57897]
20Nov23_063021| [-0.52130 -0.28448 -0.88990 -0.47006  0.38699 -1.63998]]
20Nov23_063021|-- Bias --
20Nov23_063021|[-1.43356  1.08152  0.41815  0.00424 -0.24154  0.48990]
20Nov23_063021|Layer 1:
20Nov23_063021|-- Config --
20Nov23_063021|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063021|-- Weights --
20Nov23_063021|[[-1.12283 -0.64585  0.37135  0.93805  0.50152]
20Nov23_063021| [-0.45128 -0.33951  2.35894 -0.23711  0.47670]
20Nov23_063021| [ 1.07740 -1.29532 -1.29629  0.87008  0.40993]
20Nov23_063021| [ 0.03760  1.27456 -1.39564  0.16391  0.14825]
20Nov23_063021| [-1.16091 -1.49048  0.95524 -0.46229  0.11068]
20Nov23_063021| [-0.26762  1.19525  1.35283  2.28556 -0.02087]]
20Nov23_063021|-- Bias --
20Nov23_063021|[-0.01568 -0.30813  0.67368 -0.55501  0.11533]
20Nov23_063021|Layer 2:
20Nov23_063021|-- Config --
20Nov23_063021|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063021|-- Weights --
20Nov23_063021|[[ 0.73189  0.25994  0.61296 -0.76909  0.25937]
20Nov23_063021| [-0.88936 -0.61503 -0.69177 -0.58393  0.75519]
20Nov23_063021| [ 0.27706 -1.82774  0.74789  0.24210  0.70912]
20Nov23_063021| [-0.71073 -0.66461 -0.05384  0.42014 -0.09637]
20Nov23_063021| [ 0.18630 -0.67560  0.79441  0.18604 -0.70347]]
20Nov23_063021|-- Bias --
20Nov23_063021|[ 1.74623  0.69730  0.72008 -0.20004  0.15599]
20Nov23_063021|Layer 3:
20Nov23_063021|-- Config --
20Nov23_063021|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063021|-- Weights --
20Nov23_063021|[[ 0.78512  0.58495  1.01708  1.05505 -0.47074]
20Nov23_063021| [ 0.09227 -0.27877  0.05296  0.69659  0.56285]
20Nov23_063021| [ 0.08212 -0.85808  1.14160 -0.25897 -0.73503]
20Nov23_063021| [-1.34393 -0.15823  0.51240 -0.30438 -0.15319]
20Nov23_063021| [-0.18853  0.79089 -0.34260 -0.42000  0.98012]]
20Nov23_063021|-- Bias --
20Nov23_063021|[ 0.02020 -0.47953 -0.29788  0.95327  0.93818]
20Nov23_063021|Layer 4:
20Nov23_063021|-- Config --
20Nov23_063021|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063021|-- Weights --
20Nov23_063021|[[-1.15005 -1.14488]
20Nov23_063021| [-0.70732 -0.77066]
20Nov23_063021| [-0.92771 -0.61093]
20Nov23_063021| [-0.90771 -1.04766]
20Nov23_063021| [ 1.53415  1.37750]]
20Nov23_063021|-- Bias --
20Nov23_063021|[-0.45752 -0.43811]
20Nov23_063021|Predicting the validation and test data with the Best final individual.
20Nov23_063028| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_063028|-----------  ------------------  --------------------  ----------
20Nov23_063028|Validation         25.13                  84            0.69260
20Nov23_063028|   Test            36.49                  84            0.00000
20Nov23_063028|-------------------------- Test #6 --------------------------
20Nov23_063028|Best final individual weights
20Nov23_063028|Individual:
20Nov23_063028|-- Constant hidden layers --
20Nov23_063028|False
20Nov23_063028|Layer 0:
20Nov23_063028|-- Config --
20Nov23_063028|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063028|-- Weights --
20Nov23_063028|[[ 0.37246  0.50348 -0.38721 -0.36688  2.11975  1.13385]
20Nov23_063028| [ 0.85547  0.24143 -1.64877 -0.78124 -0.43609 -2.21237]
20Nov23_063028| [ 0.42721 -0.76527 -0.51440 -0.75447  0.32484 -0.87275]
20Nov23_063028| [ 0.40346  0.73991  1.07205 -0.69045 -0.65947 -0.69401]
20Nov23_063028| [-0.42540  1.05687  1.57639 -0.19852 -0.01890 -1.25550]
20Nov23_063028| [ 1.01099 -1.20961  1.25712  1.12731 -2.11193 -0.16926]
20Nov23_063028| [ 1.24861  1.19184  0.77574  1.39326 -0.67107  0.80633]
20Nov23_063028| [-1.23263 -0.57257  1.51785  0.29112 -0.35951  0.26049]
20Nov23_063028| [ 0.34632  0.47098 -0.18577 -0.40163 -0.19665 -0.79876]
20Nov23_063028| [ 0.37496 -0.29597  1.24258 -0.16212 -0.65061  0.43949]
20Nov23_063028| [ 0.69488  0.81509 -2.27263  0.15914 -0.46454 -0.23901]
20Nov23_063028| [-0.75193 -1.91140 -1.01764 -0.74874 -0.08376  0.19787]
20Nov23_063028| [ 0.32119 -0.01971  0.44310 -1.10615 -0.05645  0.79914]
20Nov23_063028| [-0.32188  1.83930 -1.27440  1.32363 -0.58820 -1.55631]
20Nov23_063028| [-0.95047 -0.79252  0.53185  1.12978 -2.21543  0.23448]
20Nov23_063028| [ 0.83000 -0.27012  0.28352 -0.87504 -0.14749  0.55266]
20Nov23_063028| [ 1.13130 -0.03457 -0.21537 -0.55833 -1.49729 -0.36937]
20Nov23_063028| [-1.79056 -1.86836 -1.52421 -2.43591  0.70215 -0.37284]
20Nov23_063028| [-0.99829  0.58787 -0.49641  0.56679 -1.24154 -0.79487]
20Nov23_063028| [ 0.28588 -0.57617 -0.68829 -0.21789 -0.08347 -0.22650]
20Nov23_063028| [ 0.57393  0.27574 -0.47918  0.06886 -0.02632 -0.86438]
20Nov23_063028| [-2.37699  0.90398 -1.20198 -0.13722  1.11758  0.95157]
20Nov23_063028| [ 0.80080 -1.27768  0.47634  0.15233 -2.17593  0.08481]
20Nov23_063028| [ 0.96978 -1.60896  0.26377  1.17514 -0.48422 -1.14618]
20Nov23_063028| [-0.58915 -0.04214  1.08863 -1.31963  1.38578  0.43376]
20Nov23_063028| [-0.55311 -0.11218 -1.57961  0.61144  0.21090  0.85095]
20Nov23_063028| [ 0.95030  1.36585 -0.88436  0.55456 -0.29468 -0.06177]
20Nov23_063028| [-0.22244  2.02469 -2.20220  0.51991 -0.32656 -1.13757]
20Nov23_063028| [-1.02569 -0.75926  0.43686  0.74239 -0.03544  0.84045]
20Nov23_063028| [ 1.66723  0.36779  1.48881  1.78736  0.10982 -0.47841]
20Nov23_063028| [ 1.19031 -0.31012 -1.89834 -1.26765 -0.70409 -1.17102]
20Nov23_063028| [ 0.86965  0.28328  0.67962  0.19979 -0.07761  0.88232]
20Nov23_063028| [-0.37120 -0.21892 -0.63646  0.25970  0.09547  0.33285]
20Nov23_063028| [ 0.50033 -0.52733 -0.61247 -1.32671 -0.64064  0.80882]
20Nov23_063028| [-0.28304 -1.42711 -0.62821 -0.16242 -0.56235 -0.05706]
20Nov23_063028| [-1.16828  1.41397 -1.62729 -0.34079  0.64029  0.13870]
20Nov23_063028| [-1.25923 -1.77860  1.33062 -1.19801 -0.63088  0.01647]
20Nov23_063028| [-0.06558 -1.13347 -1.19374  0.35032  1.82112 -1.10971]
20Nov23_063028| [-0.71351  0.94623 -0.04997  0.34918 -0.63262  0.37683]
20Nov23_063028| [ 0.19848 -0.83013 -1.92147 -1.36939  0.83033 -0.13095]
20Nov23_063028| [-0.61376  0.80335  0.24413  0.96333 -1.14089  0.85802]
20Nov23_063028| [-0.36928 -0.42211  0.24520 -1.30295 -1.93237 -0.02548]
20Nov23_063028| [ 0.20256 -0.42818 -1.94283  0.77496  0.53459  1.61769]
20Nov23_063028| [ 0.68188  0.47057  0.20435  1.09097  0.15765  1.04190]
20Nov23_063028| [ 1.33491  0.24345  0.21908  0.18090  1.34449 -0.17898]
20Nov23_063028| [ 0.27847  0.70360  0.51300  1.26013 -1.36985 -0.78610]
20Nov23_063028| [ 1.84673  0.34176  1.17368  0.06267  0.80454 -1.08971]
20Nov23_063028| [-1.55035 -0.68663 -0.37203  0.80163 -0.26877  0.01660]
20Nov23_063028| [ 1.09088 -1.16331  0.24986 -0.12997  1.33586 -1.57542]
20Nov23_063028| [-0.65292 -1.51801  0.65628 -0.59370  2.42713 -0.62132]
20Nov23_063028| [-0.24412 -0.93150 -0.95428  2.12486 -1.66742  0.38608]
20Nov23_063028| [-0.12629 -1.50991  1.01674 -1.39436  0.05675  0.29722]
20Nov23_063028| [ 0.97103 -0.96420  0.21034 -1.70519  1.10287 -1.04466]
20Nov23_063028| [-0.08849  0.34404  1.21360  1.35353  0.10154 -0.21929]
20Nov23_063028| [ 2.57606  0.55820 -0.39108  0.68623 -1.25579 -0.40213]
20Nov23_063028| [-1.14612  0.04346  0.06719  0.49167  1.02429  0.57897]
20Nov23_063028| [-0.52130 -0.28448 -0.88990 -0.47006  0.38699 -1.63998]]
20Nov23_063028|-- Bias --
20Nov23_063028|[-1.43356  1.08152  0.41815  0.00424 -0.24154  0.48990]
20Nov23_063028|Layer 1:
20Nov23_063028|-- Config --
20Nov23_063028|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063028|-- Weights --
20Nov23_063028|[[-1.12283 -0.64585  0.37135  0.93805  0.50152]
20Nov23_063028| [-0.45128 -0.33951  2.35894 -0.23711  0.47670]
20Nov23_063028| [ 1.07740 -1.29532 -1.29629  0.87008  0.40993]
20Nov23_063028| [ 0.03760  1.27456 -1.39564  0.16391  0.14825]
20Nov23_063028| [-1.16091 -1.49048  0.95524 -0.46229  0.11068]
20Nov23_063028| [-0.26762  1.19525  1.35283  2.28556 -0.02087]]
20Nov23_063028|-- Bias --
20Nov23_063028|[-0.01568 -0.30813  0.67368 -0.55501  0.11533]
20Nov23_063028|Layer 2:
20Nov23_063028|-- Config --
20Nov23_063028|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063028|-- Weights --
20Nov23_063028|[[ 0.73189  0.25994  0.61296 -0.76909  0.25937]
20Nov23_063028| [-0.88936 -0.61503 -0.69177 -0.58393  0.75519]
20Nov23_063028| [ 0.27706 -1.82774  0.74789  0.24210  0.70912]
20Nov23_063028| [-0.71073 -0.66461 -0.05384  0.42014 -0.09637]
20Nov23_063028| [ 0.18630 -0.67560  0.79441  0.18604 -0.70347]]
20Nov23_063028|-- Bias --
20Nov23_063028|[ 1.74623  0.69730  0.72008 -0.20004  0.15599]
20Nov23_063028|Layer 3:
20Nov23_063028|-- Config --
20Nov23_063028|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063028|-- Weights --
20Nov23_063028|[[ 0.78512  0.58495  1.01708  1.05505 -0.47074]
20Nov23_063028| [ 0.09227 -0.27877  0.05296  0.69659  0.56285]
20Nov23_063028| [ 0.08212 -0.85808  1.14160 -0.25897 -0.73503]
20Nov23_063028| [-1.34393 -0.15823  0.51240 -0.30438 -0.15319]
20Nov23_063028| [-0.18853  0.79089 -0.34260 -0.42000  0.98012]]
20Nov23_063028|-- Bias --
20Nov23_063028|[ 0.02020 -0.47953 -0.29788  0.95327  0.93818]
20Nov23_063028|Layer 4:
20Nov23_063028|-- Config --
20Nov23_063028|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063028|-- Weights --
20Nov23_063028|[[-1.15005 -1.14488]
20Nov23_063028| [-0.70732 -0.77066]
20Nov23_063028| [-0.92771 -0.61093]
20Nov23_063028| [-0.90771 -1.04766]
20Nov23_063028| [ 1.53415  1.37750]]
20Nov23_063028|-- Bias --
20Nov23_063028|[-0.45752 -0.43811]
20Nov23_063028|Predicting the validation and test data with the Best final individual.
20Nov23_063034| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_063034|-----------  ------------------  --------------------  ----------
20Nov23_063034|Validation         25.65                  84            0.67573
20Nov23_063034|   Test            36.40                  84            0.00000
20Nov23_063034|-------------------------- Test #7 --------------------------
20Nov23_063034|Best final individual weights
20Nov23_063034|Individual:
20Nov23_063034|-- Constant hidden layers --
20Nov23_063034|False
20Nov23_063034|Layer 0:
20Nov23_063034|-- Config --
20Nov23_063034|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063034|-- Weights --
20Nov23_063034|[[ 0.37246  0.50348 -0.38721 -0.36688  2.11975  1.13385]
20Nov23_063034| [ 0.85547  0.24143 -1.64877 -0.78124 -0.43609 -2.21237]
20Nov23_063034| [ 0.42721 -0.76527 -0.51440 -0.75447  0.32484 -0.87275]
20Nov23_063034| [ 0.40346  0.73991  1.07205 -0.69045 -0.65947 -0.69401]
20Nov23_063034| [-0.42540  1.05687  1.57639 -0.19852 -0.01890 -1.25550]
20Nov23_063034| [ 1.01099 -1.20961  1.25712  1.12731 -2.11193 -0.16926]
20Nov23_063034| [ 1.24861  1.19184  0.77574  1.39326 -0.67107  0.80633]
20Nov23_063034| [-1.23263 -0.57257  1.51785  0.29112 -0.35951  0.26049]
20Nov23_063034| [ 0.34632  0.47098 -0.18577 -0.40163 -0.19665 -0.79876]
20Nov23_063034| [ 0.37496 -0.29597  1.24258 -0.16212 -0.65061  0.43949]
20Nov23_063034| [ 0.69488  0.81509 -2.27263  0.15914 -0.46454 -0.23901]
20Nov23_063034| [-0.75193 -1.91140 -1.01764 -0.74874 -0.08376  0.19787]
20Nov23_063034| [ 0.32119 -0.01971  0.44310 -1.10615 -0.05645  0.79914]
20Nov23_063034| [-0.32188  1.83930 -1.27440  1.32363 -0.58820 -1.55631]
20Nov23_063034| [-0.95047 -0.79252  0.53185  1.12978 -2.21543  0.23448]
20Nov23_063034| [ 0.83000 -0.27012  0.28352 -0.87504 -0.14749  0.55266]
20Nov23_063034| [ 1.13130 -0.03457 -0.21537 -0.55833 -1.49729 -0.36937]
20Nov23_063034| [-1.79056 -1.86836 -1.52421 -2.43591  0.70215 -0.37284]
20Nov23_063034| [-0.99829  0.58787 -0.49641  0.56679 -1.24154 -0.79487]
20Nov23_063034| [ 0.28588 -0.57617 -0.68829 -0.21789 -0.08347 -0.22650]
20Nov23_063034| [ 0.57393  0.27574 -0.47918  0.06886 -0.02632 -0.86438]
20Nov23_063034| [-2.37699  0.90398 -1.20198 -0.13722  1.11758  0.95157]
20Nov23_063034| [ 0.80080 -1.27768  0.47634  0.15233 -2.17593  0.08481]
20Nov23_063034| [ 0.96978 -1.60896  0.26377  1.17514 -0.48422 -1.14618]
20Nov23_063034| [-0.58915 -0.04214  1.08863 -1.31963  1.38578  0.43376]
20Nov23_063034| [-0.55311 -0.11218 -1.57961  0.61144  0.21090  0.85095]
20Nov23_063034| [ 0.95030  1.36585 -0.88436  0.55456 -0.29468 -0.06177]
20Nov23_063034| [-0.22244  2.02469 -2.20220  0.51991 -0.32656 -1.13757]
20Nov23_063034| [-1.02569 -0.75926  0.43686  0.74239 -0.03544  0.84045]
20Nov23_063034| [ 1.66723  0.36779  1.48881  1.78736  0.10982 -0.47841]
20Nov23_063034| [ 1.19031 -0.31012 -1.89834 -1.26765 -0.70409 -1.17102]
20Nov23_063034| [ 0.86965  0.28328  0.67962  0.19979 -0.07761  0.88232]
20Nov23_063034| [-0.37120 -0.21892 -0.63646  0.25970  0.09547  0.33285]
20Nov23_063034| [ 0.50033 -0.52733 -0.61247 -1.32671 -0.64064  0.80882]
20Nov23_063034| [-0.28304 -1.42711 -0.62821 -0.16242 -0.56235 -0.05706]
20Nov23_063034| [-1.16828  1.41397 -1.62729 -0.34079  0.64029  0.13870]
20Nov23_063034| [-1.25923 -1.77860  1.33062 -1.19801 -0.63088  0.01647]
20Nov23_063034| [-0.06558 -1.13347 -1.19374  0.35032  1.82112 -1.10971]
20Nov23_063034| [-0.71351  0.94623 -0.04997  0.34918 -0.63262  0.37683]
20Nov23_063034| [ 0.19848 -0.83013 -1.92147 -1.36939  0.83033 -0.13095]
20Nov23_063034| [-0.61376  0.80335  0.24413  0.96333 -1.14089  0.85802]
20Nov23_063034| [-0.36928 -0.42211  0.24520 -1.30295 -1.93237 -0.02548]
20Nov23_063034| [ 0.20256 -0.42818 -1.94283  0.77496  0.53459  1.61769]
20Nov23_063034| [ 0.68188  0.47057  0.20435  1.09097  0.15765  1.04190]
20Nov23_063034| [ 1.33491  0.24345  0.21908  0.18090  1.34449 -0.17898]
20Nov23_063034| [ 0.27847  0.70360  0.51300  1.26013 -1.36985 -0.78610]
20Nov23_063034| [ 1.84673  0.34176  1.17368  0.06267  0.80454 -1.08971]
20Nov23_063034| [-1.55035 -0.68663 -0.37203  0.80163 -0.26877  0.01660]
20Nov23_063034| [ 1.09088 -1.16331  0.24986 -0.12997  1.33586 -1.57542]
20Nov23_063034| [-0.65292 -1.51801  0.65628 -0.59370  2.42713 -0.62132]
20Nov23_063034| [-0.24412 -0.93150 -0.95428  2.12486 -1.66742  0.38608]
20Nov23_063034| [-0.12629 -1.50991  1.01674 -1.39436  0.05675  0.29722]
20Nov23_063034| [ 0.97103 -0.96420  0.21034 -1.70519  1.10287 -1.04466]
20Nov23_063034| [-0.08849  0.34404  1.21360  1.35353  0.10154 -0.21929]
20Nov23_063034| [ 2.57606  0.55820 -0.39108  0.68623 -1.25579 -0.40213]
20Nov23_063034| [-1.14612  0.04346  0.06719  0.49167  1.02429  0.57897]
20Nov23_063034| [-0.52130 -0.28448 -0.88990 -0.47006  0.38699 -1.63998]]
20Nov23_063034|-- Bias --
20Nov23_063034|[-1.43356  1.08152  0.41815  0.00424 -0.24154  0.48990]
20Nov23_063034|Layer 1:
20Nov23_063034|-- Config --
20Nov23_063034|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063034|-- Weights --
20Nov23_063034|[[-1.12283 -0.64585  0.37135  0.93805  0.50152]
20Nov23_063034| [-0.45128 -0.33951  2.35894 -0.23711  0.47670]
20Nov23_063034| [ 1.07740 -1.29532 -1.29629  0.87008  0.40993]
20Nov23_063034| [ 0.03760  1.27456 -1.39564  0.16391  0.14825]
20Nov23_063034| [-1.16091 -1.49048  0.95524 -0.46229  0.11068]
20Nov23_063034| [-0.26762  1.19525  1.35283  2.28556 -0.02087]]
20Nov23_063034|-- Bias --
20Nov23_063034|[-0.01568 -0.30813  0.67368 -0.55501  0.11533]
20Nov23_063034|Layer 2:
20Nov23_063034|-- Config --
20Nov23_063034|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063034|-- Weights --
20Nov23_063034|[[ 0.73189  0.25994  0.61296 -0.76909  0.25937]
20Nov23_063034| [-0.88936 -0.61503 -0.69177 -0.58393  0.75519]
20Nov23_063034| [ 0.27706 -1.82774  0.74789  0.24210  0.70912]
20Nov23_063034| [-0.71073 -0.66461 -0.05384  0.42014 -0.09637]
20Nov23_063034| [ 0.18630 -0.67560  0.79441  0.18604 -0.70347]]
20Nov23_063034|-- Bias --
20Nov23_063034|[ 1.74623  0.69730  0.72008 -0.20004  0.15599]
20Nov23_063034|Layer 3:
20Nov23_063034|-- Config --
20Nov23_063034|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063034|-- Weights --
20Nov23_063034|[[ 0.78512  0.58495  1.01708  1.05505 -0.47074]
20Nov23_063034| [ 0.09227 -0.27877  0.05296  0.69659  0.56285]
20Nov23_063034| [ 0.08212 -0.85808  1.14160 -0.25897 -0.73503]
20Nov23_063034| [-1.34393 -0.15823  0.51240 -0.30438 -0.15319]
20Nov23_063034| [-0.18853  0.79089 -0.34260 -0.42000  0.98012]]
20Nov23_063034|-- Bias --
20Nov23_063034|[ 0.02020 -0.47953 -0.29788  0.95327  0.93818]
20Nov23_063034|Layer 4:
20Nov23_063034|-- Config --
20Nov23_063034|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063034|-- Weights --
20Nov23_063034|[[-1.15005 -1.14488]
20Nov23_063034| [-0.70732 -0.77066]
20Nov23_063034| [-0.92771 -0.61093]
20Nov23_063034| [-0.90771 -1.04766]
20Nov23_063034| [ 1.53415  1.37750]]
20Nov23_063034|-- Bias --
20Nov23_063034|[-0.45752 -0.43811]
20Nov23_063034|Predicting the validation and test data with the Best final individual.
20Nov23_063041| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_063041|-----------  ------------------  --------------------  ----------
20Nov23_063041|Validation         26.17                  84            0.64776
20Nov23_063041|   Test            27.80                  84            0.70223
20Nov23_063041|-------------------------- Test #8 --------------------------
20Nov23_063041|Best final individual weights
20Nov23_063041|Individual:
20Nov23_063041|-- Constant hidden layers --
20Nov23_063041|False
20Nov23_063041|Layer 0:
20Nov23_063041|-- Config --
20Nov23_063041|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063041|-- Weights --
20Nov23_063041|[[ 0.37246  0.50348 -0.38721 -0.36688  2.11975  1.13385]
20Nov23_063041| [ 0.85547  0.24143 -1.64877 -0.78124 -0.43609 -2.21237]
20Nov23_063041| [ 0.42721 -0.76527 -0.51440 -0.75447  0.32484 -0.87275]
20Nov23_063041| [ 0.40346  0.73991  1.07205 -0.69045 -0.65947 -0.69401]
20Nov23_063041| [-0.42540  1.05687  1.57639 -0.19852 -0.01890 -1.25550]
20Nov23_063041| [ 1.01099 -1.20961  1.25712  1.12731 -2.11193 -0.16926]
20Nov23_063041| [ 1.24861  1.19184  0.77574  1.39326 -0.67107  0.80633]
20Nov23_063041| [-1.23263 -0.57257  1.51785  0.29112 -0.35951  0.26049]
20Nov23_063041| [ 0.34632  0.47098 -0.18577 -0.40163 -0.19665 -0.79876]
20Nov23_063041| [ 0.37496 -0.29597  1.24258 -0.16212 -0.65061  0.43949]
20Nov23_063041| [ 0.69488  0.81509 -2.27263  0.15914 -0.46454 -0.23901]
20Nov23_063041| [-0.75193 -1.91140 -1.01764 -0.74874 -0.08376  0.19787]
20Nov23_063041| [ 0.32119 -0.01971  0.44310 -1.10615 -0.05645  0.79914]
20Nov23_063041| [-0.32188  1.83930 -1.27440  1.32363 -0.58820 -1.55631]
20Nov23_063041| [-0.95047 -0.79252  0.53185  1.12978 -2.21543  0.23448]
20Nov23_063041| [ 0.83000 -0.27012  0.28352 -0.87504 -0.14749  0.55266]
20Nov23_063041| [ 1.13130 -0.03457 -0.21537 -0.55833 -1.49729 -0.36937]
20Nov23_063041| [-1.79056 -1.86836 -1.52421 -2.43591  0.70215 -0.37284]
20Nov23_063041| [-0.99829  0.58787 -0.49641  0.56679 -1.24154 -0.79487]
20Nov23_063041| [ 0.28588 -0.57617 -0.68829 -0.21789 -0.08347 -0.22650]
20Nov23_063041| [ 0.57393  0.27574 -0.47918  0.06886 -0.02632 -0.86438]
20Nov23_063041| [-2.37699  0.90398 -1.20198 -0.13722  1.11758  0.95157]
20Nov23_063041| [ 0.80080 -1.27768  0.47634  0.15233 -2.17593  0.08481]
20Nov23_063041| [ 0.96978 -1.60896  0.26377  1.17514 -0.48422 -1.14618]
20Nov23_063041| [-0.58915 -0.04214  1.08863 -1.31963  1.38578  0.43376]
20Nov23_063041| [-0.55311 -0.11218 -1.57961  0.61144  0.21090  0.85095]
20Nov23_063041| [ 0.95030  1.36585 -0.88436  0.55456 -0.29468 -0.06177]
20Nov23_063041| [-0.22244  2.02469 -2.20220  0.51991 -0.32656 -1.13757]
20Nov23_063041| [-1.02569 -0.75926  0.43686  0.74239 -0.03544  0.84045]
20Nov23_063041| [ 1.66723  0.36779  1.48881  1.78736  0.10982 -0.47841]
20Nov23_063041| [ 1.19031 -0.31012 -1.89834 -1.26765 -0.70409 -1.17102]
20Nov23_063041| [ 0.86965  0.28328  0.67962  0.19979 -0.07761  0.88232]
20Nov23_063041| [-0.37120 -0.21892 -0.63646  0.25970  0.09547  0.33285]
20Nov23_063041| [ 0.50033 -0.52733 -0.61247 -1.32671 -0.64064  0.80882]
20Nov23_063041| [-0.28304 -1.42711 -0.62821 -0.16242 -0.56235 -0.05706]
20Nov23_063041| [-1.16828  1.41397 -1.62729 -0.34079  0.64029  0.13870]
20Nov23_063041| [-1.25923 -1.77860  1.33062 -1.19801 -0.63088  0.01647]
20Nov23_063041| [-0.06558 -1.13347 -1.19374  0.35032  1.82112 -1.10971]
20Nov23_063041| [-0.71351  0.94623 -0.04997  0.34918 -0.63262  0.37683]
20Nov23_063041| [ 0.19848 -0.83013 -1.92147 -1.36939  0.83033 -0.13095]
20Nov23_063041| [-0.61376  0.80335  0.24413  0.96333 -1.14089  0.85802]
20Nov23_063041| [-0.36928 -0.42211  0.24520 -1.30295 -1.93237 -0.02548]
20Nov23_063041| [ 0.20256 -0.42818 -1.94283  0.77496  0.53459  1.61769]
20Nov23_063041| [ 0.68188  0.47057  0.20435  1.09097  0.15765  1.04190]
20Nov23_063041| [ 1.33491  0.24345  0.21908  0.18090  1.34449 -0.17898]
20Nov23_063041| [ 0.27847  0.70360  0.51300  1.26013 -1.36985 -0.78610]
20Nov23_063041| [ 1.84673  0.34176  1.17368  0.06267  0.80454 -1.08971]
20Nov23_063041| [-1.55035 -0.68663 -0.37203  0.80163 -0.26877  0.01660]
20Nov23_063041| [ 1.09088 -1.16331  0.24986 -0.12997  1.33586 -1.57542]
20Nov23_063041| [-0.65292 -1.51801  0.65628 -0.59370  2.42713 -0.62132]
20Nov23_063041| [-0.24412 -0.93150 -0.95428  2.12486 -1.66742  0.38608]
20Nov23_063041| [-0.12629 -1.50991  1.01674 -1.39436  0.05675  0.29722]
20Nov23_063041| [ 0.97103 -0.96420  0.21034 -1.70519  1.10287 -1.04466]
20Nov23_063041| [-0.08849  0.34404  1.21360  1.35353  0.10154 -0.21929]
20Nov23_063041| [ 2.57606  0.55820 -0.39108  0.68623 -1.25579 -0.40213]
20Nov23_063041| [-1.14612  0.04346  0.06719  0.49167  1.02429  0.57897]
20Nov23_063041| [-0.52130 -0.28448 -0.88990 -0.47006  0.38699 -1.63998]]
20Nov23_063041|-- Bias --
20Nov23_063041|[-1.43356  1.08152  0.41815  0.00424 -0.24154  0.48990]
20Nov23_063041|Layer 1:
20Nov23_063041|-- Config --
20Nov23_063041|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063041|-- Weights --
20Nov23_063041|[[-1.12283 -0.64585  0.37135  0.93805  0.50152]
20Nov23_063041| [-0.45128 -0.33951  2.35894 -0.23711  0.47670]
20Nov23_063041| [ 1.07740 -1.29532 -1.29629  0.87008  0.40993]
20Nov23_063041| [ 0.03760  1.27456 -1.39564  0.16391  0.14825]
20Nov23_063041| [-1.16091 -1.49048  0.95524 -0.46229  0.11068]
20Nov23_063041| [-0.26762  1.19525  1.35283  2.28556 -0.02087]]
20Nov23_063041|-- Bias --
20Nov23_063041|[-0.01568 -0.30813  0.67368 -0.55501  0.11533]
20Nov23_063041|Layer 2:
20Nov23_063041|-- Config --
20Nov23_063041|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063041|-- Weights --
20Nov23_063041|[[ 0.73189  0.25994  0.61296 -0.76909  0.25937]
20Nov23_063041| [-0.88936 -0.61503 -0.69177 -0.58393  0.75519]
20Nov23_063041| [ 0.27706 -1.82774  0.74789  0.24210  0.70912]
20Nov23_063041| [-0.71073 -0.66461 -0.05384  0.42014 -0.09637]
20Nov23_063041| [ 0.18630 -0.67560  0.79441  0.18604 -0.70347]]
20Nov23_063041|-- Bias --
20Nov23_063041|[ 1.74623  0.69730  0.72008 -0.20004  0.15599]
20Nov23_063041|Layer 3:
20Nov23_063041|-- Config --
20Nov23_063041|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063041|-- Weights --
20Nov23_063041|[[ 0.78512  0.58495  1.01708  1.05505 -0.47074]
20Nov23_063041| [ 0.09227 -0.27877  0.05296  0.69659  0.56285]
20Nov23_063041| [ 0.08212 -0.85808  1.14160 -0.25897 -0.73503]
20Nov23_063041| [-1.34393 -0.15823  0.51240 -0.30438 -0.15319]
20Nov23_063041| [-0.18853  0.79089 -0.34260 -0.42000  0.98012]]
20Nov23_063041|-- Bias --
20Nov23_063041|[ 0.02020 -0.47953 -0.29788  0.95327  0.93818]
20Nov23_063041|Layer 4:
20Nov23_063041|-- Config --
20Nov23_063041|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063041|-- Weights --
20Nov23_063041|[[-1.15005 -1.14488]
20Nov23_063041| [-0.70732 -0.77066]
20Nov23_063041| [-0.92771 -0.61093]
20Nov23_063041| [-0.90771 -1.04766]
20Nov23_063041| [ 1.53415  1.37750]]
20Nov23_063041|-- Bias --
20Nov23_063041|[-0.45752 -0.43811]
20Nov23_063041|Predicting the validation and test data with the Best final individual.
20Nov23_063048| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_063048|-----------  ------------------  --------------------  ----------
20Nov23_063048|Validation         26.35                  84            0.72096
20Nov23_063048|   Test            24.15                  84            0.55696
20Nov23_063048|-------------------------- Test #9 --------------------------
20Nov23_063048|Best final individual weights
20Nov23_063048|Individual:
20Nov23_063048|-- Constant hidden layers --
20Nov23_063048|False
20Nov23_063048|Layer 0:
20Nov23_063048|-- Config --
20Nov23_063048|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063048|-- Weights --
20Nov23_063048|[[ 0.37246  0.50348 -0.38721 -0.36688  2.11975  1.13385]
20Nov23_063048| [ 0.85547  0.24143 -1.64877 -0.78124 -0.43609 -2.21237]
20Nov23_063048| [ 0.42721 -0.76527 -0.51440 -0.75447  0.32484 -0.87275]
20Nov23_063048| [ 0.40346  0.73991  1.07205 -0.69045 -0.65947 -0.69401]
20Nov23_063048| [-0.42540  1.05687  1.57639 -0.19852 -0.01890 -1.25550]
20Nov23_063048| [ 1.01099 -1.20961  1.25712  1.12731 -2.11193 -0.16926]
20Nov23_063048| [ 1.24861  1.19184  0.77574  1.39326 -0.67107  0.80633]
20Nov23_063048| [-1.23263 -0.57257  1.51785  0.29112 -0.35951  0.26049]
20Nov23_063048| [ 0.34632  0.47098 -0.18577 -0.40163 -0.19665 -0.79876]
20Nov23_063048| [ 0.37496 -0.29597  1.24258 -0.16212 -0.65061  0.43949]
20Nov23_063048| [ 0.69488  0.81509 -2.27263  0.15914 -0.46454 -0.23901]
20Nov23_063048| [-0.75193 -1.91140 -1.01764 -0.74874 -0.08376  0.19787]
20Nov23_063048| [ 0.32119 -0.01971  0.44310 -1.10615 -0.05645  0.79914]
20Nov23_063048| [-0.32188  1.83930 -1.27440  1.32363 -0.58820 -1.55631]
20Nov23_063048| [-0.95047 -0.79252  0.53185  1.12978 -2.21543  0.23448]
20Nov23_063048| [ 0.83000 -0.27012  0.28352 -0.87504 -0.14749  0.55266]
20Nov23_063048| [ 1.13130 -0.03457 -0.21537 -0.55833 -1.49729 -0.36937]
20Nov23_063048| [-1.79056 -1.86836 -1.52421 -2.43591  0.70215 -0.37284]
20Nov23_063048| [-0.99829  0.58787 -0.49641  0.56679 -1.24154 -0.79487]
20Nov23_063048| [ 0.28588 -0.57617 -0.68829 -0.21789 -0.08347 -0.22650]
20Nov23_063048| [ 0.57393  0.27574 -0.47918  0.06886 -0.02632 -0.86438]
20Nov23_063048| [-2.37699  0.90398 -1.20198 -0.13722  1.11758  0.95157]
20Nov23_063048| [ 0.80080 -1.27768  0.47634  0.15233 -2.17593  0.08481]
20Nov23_063048| [ 0.96978 -1.60896  0.26377  1.17514 -0.48422 -1.14618]
20Nov23_063048| [-0.58915 -0.04214  1.08863 -1.31963  1.38578  0.43376]
20Nov23_063048| [-0.55311 -0.11218 -1.57961  0.61144  0.21090  0.85095]
20Nov23_063048| [ 0.95030  1.36585 -0.88436  0.55456 -0.29468 -0.06177]
20Nov23_063048| [-0.22244  2.02469 -2.20220  0.51991 -0.32656 -1.13757]
20Nov23_063048| [-1.02569 -0.75926  0.43686  0.74239 -0.03544  0.84045]
20Nov23_063048| [ 1.66723  0.36779  1.48881  1.78736  0.10982 -0.47841]
20Nov23_063048| [ 1.19031 -0.31012 -1.89834 -1.26765 -0.70409 -1.17102]
20Nov23_063048| [ 0.86965  0.28328  0.67962  0.19979 -0.07761  0.88232]
20Nov23_063048| [-0.37120 -0.21892 -0.63646  0.25970  0.09547  0.33285]
20Nov23_063048| [ 0.50033 -0.52733 -0.61247 -1.32671 -0.64064  0.80882]
20Nov23_063048| [-0.28304 -1.42711 -0.62821 -0.16242 -0.56235 -0.05706]
20Nov23_063048| [-1.16828  1.41397 -1.62729 -0.34079  0.64029  0.13870]
20Nov23_063048| [-1.25923 -1.77860  1.33062 -1.19801 -0.63088  0.01647]
20Nov23_063048| [-0.06558 -1.13347 -1.19374  0.35032  1.82112 -1.10971]
20Nov23_063048| [-0.71351  0.94623 -0.04997  0.34918 -0.63262  0.37683]
20Nov23_063048| [ 0.19848 -0.83013 -1.92147 -1.36939  0.83033 -0.13095]
20Nov23_063048| [-0.61376  0.80335  0.24413  0.96333 -1.14089  0.85802]
20Nov23_063048| [-0.36928 -0.42211  0.24520 -1.30295 -1.93237 -0.02548]
20Nov23_063048| [ 0.20256 -0.42818 -1.94283  0.77496  0.53459  1.61769]
20Nov23_063048| [ 0.68188  0.47057  0.20435  1.09097  0.15765  1.04190]
20Nov23_063048| [ 1.33491  0.24345  0.21908  0.18090  1.34449 -0.17898]
20Nov23_063048| [ 0.27847  0.70360  0.51300  1.26013 -1.36985 -0.78610]
20Nov23_063048| [ 1.84673  0.34176  1.17368  0.06267  0.80454 -1.08971]
20Nov23_063048| [-1.55035 -0.68663 -0.37203  0.80163 -0.26877  0.01660]
20Nov23_063048| [ 1.09088 -1.16331  0.24986 -0.12997  1.33586 -1.57542]
20Nov23_063048| [-0.65292 -1.51801  0.65628 -0.59370  2.42713 -0.62132]
20Nov23_063048| [-0.24412 -0.93150 -0.95428  2.12486 -1.66742  0.38608]
20Nov23_063048| [-0.12629 -1.50991  1.01674 -1.39436  0.05675  0.29722]
20Nov23_063048| [ 0.97103 -0.96420  0.21034 -1.70519  1.10287 -1.04466]
20Nov23_063048| [-0.08849  0.34404  1.21360  1.35353  0.10154 -0.21929]
20Nov23_063048| [ 2.57606  0.55820 -0.39108  0.68623 -1.25579 -0.40213]
20Nov23_063048| [-1.14612  0.04346  0.06719  0.49167  1.02429  0.57897]
20Nov23_063048| [-0.52130 -0.28448 -0.88990 -0.47006  0.38699 -1.63998]]
20Nov23_063048|-- Bias --
20Nov23_063048|[-1.43356  1.08152  0.41815  0.00424 -0.24154  0.48990]
20Nov23_063048|Layer 1:
20Nov23_063048|-- Config --
20Nov23_063048|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063048|-- Weights --
20Nov23_063048|[[-1.12283 -0.64585  0.37135  0.93805  0.50152]
20Nov23_063048| [-0.45128 -0.33951  2.35894 -0.23711  0.47670]
20Nov23_063048| [ 1.07740 -1.29532 -1.29629  0.87008  0.40993]
20Nov23_063048| [ 0.03760  1.27456 -1.39564  0.16391  0.14825]
20Nov23_063048| [-1.16091 -1.49048  0.95524 -0.46229  0.11068]
20Nov23_063048| [-0.26762  1.19525  1.35283  2.28556 -0.02087]]
20Nov23_063048|-- Bias --
20Nov23_063048|[-0.01568 -0.30813  0.67368 -0.55501  0.11533]
20Nov23_063048|Layer 2:
20Nov23_063048|-- Config --
20Nov23_063048|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063048|-- Weights --
20Nov23_063048|[[ 0.73189  0.25994  0.61296 -0.76909  0.25937]
20Nov23_063048| [-0.88936 -0.61503 -0.69177 -0.58393  0.75519]
20Nov23_063048| [ 0.27706 -1.82774  0.74789  0.24210  0.70912]
20Nov23_063048| [-0.71073 -0.66461 -0.05384  0.42014 -0.09637]
20Nov23_063048| [ 0.18630 -0.67560  0.79441  0.18604 -0.70347]]
20Nov23_063048|-- Bias --
20Nov23_063048|[ 1.74623  0.69730  0.72008 -0.20004  0.15599]
20Nov23_063048|Layer 3:
20Nov23_063048|-- Config --
20Nov23_063048|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063048|-- Weights --
20Nov23_063048|[[ 0.78512  0.58495  1.01708  1.05505 -0.47074]
20Nov23_063048| [ 0.09227 -0.27877  0.05296  0.69659  0.56285]
20Nov23_063048| [ 0.08212 -0.85808  1.14160 -0.25897 -0.73503]
20Nov23_063048| [-1.34393 -0.15823  0.51240 -0.30438 -0.15319]
20Nov23_063048| [-0.18853  0.79089 -0.34260 -0.42000  0.98012]]
20Nov23_063048|-- Bias --
20Nov23_063048|[ 0.02020 -0.47953 -0.29788  0.95327  0.93818]
20Nov23_063048|Layer 4:
20Nov23_063048|-- Config --
20Nov23_063048|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063048|-- Weights --
20Nov23_063048|[[-1.15005 -1.14488]
20Nov23_063048| [-0.70732 -0.77066]
20Nov23_063048| [-0.92771 -0.61093]
20Nov23_063048| [-0.90771 -1.04766]
20Nov23_063048| [ 1.53415  1.37750]]
20Nov23_063048|-- Bias --
20Nov23_063048|[-0.45752 -0.43811]
20Nov23_063048|Predicting the validation and test data with the Best final individual.
20Nov23_063055| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_063055|-----------  ------------------  --------------------  ----------
20Nov23_063055|Validation         25.39                  84            0.71106
20Nov23_063055|   Test            24.59                  84            0.65082
20Nov23_063055|-------------------------- Test #10 --------------------------
20Nov23_063055|Best final individual weights
20Nov23_063055|Individual:
20Nov23_063055|-- Constant hidden layers --
20Nov23_063055|False
20Nov23_063055|Layer 0:
20Nov23_063055|-- Config --
20Nov23_063055|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063055|-- Weights --
20Nov23_063055|[[ 0.37246  0.50348 -0.38721 -0.36688  2.11975  1.13385]
20Nov23_063055| [ 0.85547  0.24143 -1.64877 -0.78124 -0.43609 -2.21237]
20Nov23_063055| [ 0.42721 -0.76527 -0.51440 -0.75447  0.32484 -0.87275]
20Nov23_063055| [ 0.40346  0.73991  1.07205 -0.69045 -0.65947 -0.69401]
20Nov23_063055| [-0.42540  1.05687  1.57639 -0.19852 -0.01890 -1.25550]
20Nov23_063055| [ 1.01099 -1.20961  1.25712  1.12731 -2.11193 -0.16926]
20Nov23_063055| [ 1.24861  1.19184  0.77574  1.39326 -0.67107  0.80633]
20Nov23_063055| [-1.23263 -0.57257  1.51785  0.29112 -0.35951  0.26049]
20Nov23_063055| [ 0.34632  0.47098 -0.18577 -0.40163 -0.19665 -0.79876]
20Nov23_063055| [ 0.37496 -0.29597  1.24258 -0.16212 -0.65061  0.43949]
20Nov23_063055| [ 0.69488  0.81509 -2.27263  0.15914 -0.46454 -0.23901]
20Nov23_063055| [-0.75193 -1.91140 -1.01764 -0.74874 -0.08376  0.19787]
20Nov23_063055| [ 0.32119 -0.01971  0.44310 -1.10615 -0.05645  0.79914]
20Nov23_063055| [-0.32188  1.83930 -1.27440  1.32363 -0.58820 -1.55631]
20Nov23_063055| [-0.95047 -0.79252  0.53185  1.12978 -2.21543  0.23448]
20Nov23_063055| [ 0.83000 -0.27012  0.28352 -0.87504 -0.14749  0.55266]
20Nov23_063055| [ 1.13130 -0.03457 -0.21537 -0.55833 -1.49729 -0.36937]
20Nov23_063055| [-1.79056 -1.86836 -1.52421 -2.43591  0.70215 -0.37284]
20Nov23_063055| [-0.99829  0.58787 -0.49641  0.56679 -1.24154 -0.79487]
20Nov23_063055| [ 0.28588 -0.57617 -0.68829 -0.21789 -0.08347 -0.22650]
20Nov23_063055| [ 0.57393  0.27574 -0.47918  0.06886 -0.02632 -0.86438]
20Nov23_063055| [-2.37699  0.90398 -1.20198 -0.13722  1.11758  0.95157]
20Nov23_063055| [ 0.80080 -1.27768  0.47634  0.15233 -2.17593  0.08481]
20Nov23_063055| [ 0.96978 -1.60896  0.26377  1.17514 -0.48422 -1.14618]
20Nov23_063055| [-0.58915 -0.04214  1.08863 -1.31963  1.38578  0.43376]
20Nov23_063055| [-0.55311 -0.11218 -1.57961  0.61144  0.21090  0.85095]
20Nov23_063055| [ 0.95030  1.36585 -0.88436  0.55456 -0.29468 -0.06177]
20Nov23_063055| [-0.22244  2.02469 -2.20220  0.51991 -0.32656 -1.13757]
20Nov23_063055| [-1.02569 -0.75926  0.43686  0.74239 -0.03544  0.84045]
20Nov23_063055| [ 1.66723  0.36779  1.48881  1.78736  0.10982 -0.47841]
20Nov23_063055| [ 1.19031 -0.31012 -1.89834 -1.26765 -0.70409 -1.17102]
20Nov23_063055| [ 0.86965  0.28328  0.67962  0.19979 -0.07761  0.88232]
20Nov23_063055| [-0.37120 -0.21892 -0.63646  0.25970  0.09547  0.33285]
20Nov23_063055| [ 0.50033 -0.52733 -0.61247 -1.32671 -0.64064  0.80882]
20Nov23_063055| [-0.28304 -1.42711 -0.62821 -0.16242 -0.56235 -0.05706]
20Nov23_063055| [-1.16828  1.41397 -1.62729 -0.34079  0.64029  0.13870]
20Nov23_063055| [-1.25923 -1.77860  1.33062 -1.19801 -0.63088  0.01647]
20Nov23_063055| [-0.06558 -1.13347 -1.19374  0.35032  1.82112 -1.10971]
20Nov23_063055| [-0.71351  0.94623 -0.04997  0.34918 -0.63262  0.37683]
20Nov23_063055| [ 0.19848 -0.83013 -1.92147 -1.36939  0.83033 -0.13095]
20Nov23_063055| [-0.61376  0.80335  0.24413  0.96333 -1.14089  0.85802]
20Nov23_063055| [-0.36928 -0.42211  0.24520 -1.30295 -1.93237 -0.02548]
20Nov23_063055| [ 0.20256 -0.42818 -1.94283  0.77496  0.53459  1.61769]
20Nov23_063055| [ 0.68188  0.47057  0.20435  1.09097  0.15765  1.04190]
20Nov23_063055| [ 1.33491  0.24345  0.21908  0.18090  1.34449 -0.17898]
20Nov23_063055| [ 0.27847  0.70360  0.51300  1.26013 -1.36985 -0.78610]
20Nov23_063055| [ 1.84673  0.34176  1.17368  0.06267  0.80454 -1.08971]
20Nov23_063055| [-1.55035 -0.68663 -0.37203  0.80163 -0.26877  0.01660]
20Nov23_063055| [ 1.09088 -1.16331  0.24986 -0.12997  1.33586 -1.57542]
20Nov23_063055| [-0.65292 -1.51801  0.65628 -0.59370  2.42713 -0.62132]
20Nov23_063055| [-0.24412 -0.93150 -0.95428  2.12486 -1.66742  0.38608]
20Nov23_063055| [-0.12629 -1.50991  1.01674 -1.39436  0.05675  0.29722]
20Nov23_063055| [ 0.97103 -0.96420  0.21034 -1.70519  1.10287 -1.04466]
20Nov23_063055| [-0.08849  0.34404  1.21360  1.35353  0.10154 -0.21929]
20Nov23_063055| [ 2.57606  0.55820 -0.39108  0.68623 -1.25579 -0.40213]
20Nov23_063055| [-1.14612  0.04346  0.06719  0.49167  1.02429  0.57897]
20Nov23_063055| [-0.52130 -0.28448 -0.88990 -0.47006  0.38699 -1.63998]]
20Nov23_063055|-- Bias --
20Nov23_063055|[-1.43356  1.08152  0.41815  0.00424 -0.24154  0.48990]
20Nov23_063055|Layer 1:
20Nov23_063055|-- Config --
20Nov23_063055|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063055|-- Weights --
20Nov23_063055|[[-1.12283 -0.64585  0.37135  0.93805  0.50152]
20Nov23_063055| [-0.45128 -0.33951  2.35894 -0.23711  0.47670]
20Nov23_063055| [ 1.07740 -1.29532 -1.29629  0.87008  0.40993]
20Nov23_063055| [ 0.03760  1.27456 -1.39564  0.16391  0.14825]
20Nov23_063055| [-1.16091 -1.49048  0.95524 -0.46229  0.11068]
20Nov23_063055| [-0.26762  1.19525  1.35283  2.28556 -0.02087]]
20Nov23_063055|-- Bias --
20Nov23_063055|[-0.01568 -0.30813  0.67368 -0.55501  0.11533]
20Nov23_063055|Layer 2:
20Nov23_063055|-- Config --
20Nov23_063055|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063055|-- Weights --
20Nov23_063055|[[ 0.73189  0.25994  0.61296 -0.76909  0.25937]
20Nov23_063055| [-0.88936 -0.61503 -0.69177 -0.58393  0.75519]
20Nov23_063055| [ 0.27706 -1.82774  0.74789  0.24210  0.70912]
20Nov23_063055| [-0.71073 -0.66461 -0.05384  0.42014 -0.09637]
20Nov23_063055| [ 0.18630 -0.67560  0.79441  0.18604 -0.70347]]
20Nov23_063055|-- Bias --
20Nov23_063055|[ 1.74623  0.69730  0.72008 -0.20004  0.15599]
20Nov23_063055|Layer 3:
20Nov23_063055|-- Config --
20Nov23_063055|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063055|-- Weights --
20Nov23_063055|[[ 0.78512  0.58495  1.01708  1.05505 -0.47074]
20Nov23_063055| [ 0.09227 -0.27877  0.05296  0.69659  0.56285]
20Nov23_063055| [ 0.08212 -0.85808  1.14160 -0.25897 -0.73503]
20Nov23_063055| [-1.34393 -0.15823  0.51240 -0.30438 -0.15319]
20Nov23_063055| [-0.18853  0.79089 -0.34260 -0.42000  0.98012]]
20Nov23_063055|-- Bias --
20Nov23_063055|[ 0.02020 -0.47953 -0.29788  0.95327  0.93818]
20Nov23_063055|Layer 4:
20Nov23_063055|-- Config --
20Nov23_063055|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063055|-- Weights --
20Nov23_063055|[[-1.15005 -1.14488]
20Nov23_063055| [-0.70732 -0.77066]
20Nov23_063055| [-0.92771 -0.61093]
20Nov23_063055| [-0.90771 -1.04766]
20Nov23_063055| [ 1.53415  1.37750]]
20Nov23_063055|-- Bias --
20Nov23_063055|[-0.45752 -0.43811]
20Nov23_063055|Predicting the validation and test data with the Best final individual.
20Nov23_063102| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_063102|-----------  ------------------  --------------------  ----------
20Nov23_063102|Validation         42.00                  84            0.00000
20Nov23_063102|   Test            36.40                  84            0.00000
20Nov23_063102|-------------------------- Test #11 --------------------------
20Nov23_063102|Best final individual weights
20Nov23_063102|Individual:
20Nov23_063102|-- Constant hidden layers --
20Nov23_063102|False
20Nov23_063102|Layer 0:
20Nov23_063102|-- Config --
20Nov23_063102|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063102|-- Weights --
20Nov23_063102|[[ 0.37246  0.50348 -0.38721 -0.36688  2.11975  1.13385]
20Nov23_063102| [ 0.85547  0.24143 -1.64877 -0.78124 -0.43609 -2.21237]
20Nov23_063102| [ 0.42721 -0.76527 -0.51440 -0.75447  0.32484 -0.87275]
20Nov23_063102| [ 0.40346  0.73991  1.07205 -0.69045 -0.65947 -0.69401]
20Nov23_063102| [-0.42540  1.05687  1.57639 -0.19852 -0.01890 -1.25550]
20Nov23_063102| [ 1.01099 -1.20961  1.25712  1.12731 -2.11193 -0.16926]
20Nov23_063102| [ 1.24861  1.19184  0.77574  1.39326 -0.67107  0.80633]
20Nov23_063102| [-1.23263 -0.57257  1.51785  0.29112 -0.35951  0.26049]
20Nov23_063102| [ 0.34632  0.47098 -0.18577 -0.40163 -0.19665 -0.79876]
20Nov23_063102| [ 0.37496 -0.29597  1.24258 -0.16212 -0.65061  0.43949]
20Nov23_063102| [ 0.69488  0.81509 -2.27263  0.15914 -0.46454 -0.23901]
20Nov23_063102| [-0.75193 -1.91140 -1.01764 -0.74874 -0.08376  0.19787]
20Nov23_063102| [ 0.32119 -0.01971  0.44310 -1.10615 -0.05645  0.79914]
20Nov23_063102| [-0.32188  1.83930 -1.27440  1.32363 -0.58820 -1.55631]
20Nov23_063102| [-0.95047 -0.79252  0.53185  1.12978 -2.21543  0.23448]
20Nov23_063102| [ 0.83000 -0.27012  0.28352 -0.87504 -0.14749  0.55266]
20Nov23_063102| [ 1.13130 -0.03457 -0.21537 -0.55833 -1.49729 -0.36937]
20Nov23_063102| [-1.79056 -1.86836 -1.52421 -2.43591  0.70215 -0.37284]
20Nov23_063102| [-0.99829  0.58787 -0.49641  0.56679 -1.24154 -0.79487]
20Nov23_063102| [ 0.28588 -0.57617 -0.68829 -0.21789 -0.08347 -0.22650]
20Nov23_063102| [ 0.57393  0.27574 -0.47918  0.06886 -0.02632 -0.86438]
20Nov23_063102| [-2.37699  0.90398 -1.20198 -0.13722  1.11758  0.95157]
20Nov23_063102| [ 0.80080 -1.27768  0.47634  0.15233 -2.17593  0.08481]
20Nov23_063102| [ 0.96978 -1.60896  0.26377  1.17514 -0.48422 -1.14618]
20Nov23_063102| [-0.58915 -0.04214  1.08863 -1.31963  1.38578  0.43376]
20Nov23_063102| [-0.55311 -0.11218 -1.57961  0.61144  0.21090  0.85095]
20Nov23_063102| [ 0.95030  1.36585 -0.88436  0.55456 -0.29468 -0.06177]
20Nov23_063102| [-0.22244  2.02469 -2.20220  0.51991 -0.32656 -1.13757]
20Nov23_063102| [-1.02569 -0.75926  0.43686  0.74239 -0.03544  0.84045]
20Nov23_063102| [ 1.66723  0.36779  1.48881  1.78736  0.10982 -0.47841]
20Nov23_063102| [ 1.19031 -0.31012 -1.89834 -1.26765 -0.70409 -1.17102]
20Nov23_063102| [ 0.86965  0.28328  0.67962  0.19979 -0.07761  0.88232]
20Nov23_063102| [-0.37120 -0.21892 -0.63646  0.25970  0.09547  0.33285]
20Nov23_063102| [ 0.50033 -0.52733 -0.61247 -1.32671 -0.64064  0.80882]
20Nov23_063102| [-0.28304 -1.42711 -0.62821 -0.16242 -0.56235 -0.05706]
20Nov23_063102| [-1.16828  1.41397 -1.62729 -0.34079  0.64029  0.13870]
20Nov23_063102| [-1.25923 -1.77860  1.33062 -1.19801 -0.63088  0.01647]
20Nov23_063102| [-0.06558 -1.13347 -1.19374  0.35032  1.82112 -1.10971]
20Nov23_063102| [-0.71351  0.94623 -0.04997  0.34918 -0.63262  0.37683]
20Nov23_063102| [ 0.19848 -0.83013 -1.92147 -1.36939  0.83033 -0.13095]
20Nov23_063102| [-0.61376  0.80335  0.24413  0.96333 -1.14089  0.85802]
20Nov23_063102| [-0.36928 -0.42211  0.24520 -1.30295 -1.93237 -0.02548]
20Nov23_063102| [ 0.20256 -0.42818 -1.94283  0.77496  0.53459  1.61769]
20Nov23_063102| [ 0.68188  0.47057  0.20435  1.09097  0.15765  1.04190]
20Nov23_063102| [ 1.33491  0.24345  0.21908  0.18090  1.34449 -0.17898]
20Nov23_063102| [ 0.27847  0.70360  0.51300  1.26013 -1.36985 -0.78610]
20Nov23_063102| [ 1.84673  0.34176  1.17368  0.06267  0.80454 -1.08971]
20Nov23_063102| [-1.55035 -0.68663 -0.37203  0.80163 -0.26877  0.01660]
20Nov23_063102| [ 1.09088 -1.16331  0.24986 -0.12997  1.33586 -1.57542]
20Nov23_063102| [-0.65292 -1.51801  0.65628 -0.59370  2.42713 -0.62132]
20Nov23_063102| [-0.24412 -0.93150 -0.95428  2.12486 -1.66742  0.38608]
20Nov23_063102| [-0.12629 -1.50991  1.01674 -1.39436  0.05675  0.29722]
20Nov23_063102| [ 0.97103 -0.96420  0.21034 -1.70519  1.10287 -1.04466]
20Nov23_063102| [-0.08849  0.34404  1.21360  1.35353  0.10154 -0.21929]
20Nov23_063102| [ 2.57606  0.55820 -0.39108  0.68623 -1.25579 -0.40213]
20Nov23_063102| [-1.14612  0.04346  0.06719  0.49167  1.02429  0.57897]
20Nov23_063102| [-0.52130 -0.28448 -0.88990 -0.47006  0.38699 -1.63998]]
20Nov23_063102|-- Bias --
20Nov23_063102|[-1.43356  1.08152  0.41815  0.00424 -0.24154  0.48990]
20Nov23_063102|Layer 1:
20Nov23_063102|-- Config --
20Nov23_063102|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063102|-- Weights --
20Nov23_063102|[[-1.12283 -0.64585  0.37135  0.93805  0.50152]
20Nov23_063102| [-0.45128 -0.33951  2.35894 -0.23711  0.47670]
20Nov23_063102| [ 1.07740 -1.29532 -1.29629  0.87008  0.40993]
20Nov23_063102| [ 0.03760  1.27456 -1.39564  0.16391  0.14825]
20Nov23_063102| [-1.16091 -1.49048  0.95524 -0.46229  0.11068]
20Nov23_063102| [-0.26762  1.19525  1.35283  2.28556 -0.02087]]
20Nov23_063102|-- Bias --
20Nov23_063102|[-0.01568 -0.30813  0.67368 -0.55501  0.11533]
20Nov23_063102|Layer 2:
20Nov23_063102|-- Config --
20Nov23_063102|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063102|-- Weights --
20Nov23_063102|[[ 0.73189  0.25994  0.61296 -0.76909  0.25937]
20Nov23_063102| [-0.88936 -0.61503 -0.69177 -0.58393  0.75519]
20Nov23_063102| [ 0.27706 -1.82774  0.74789  0.24210  0.70912]
20Nov23_063102| [-0.71073 -0.66461 -0.05384  0.42014 -0.09637]
20Nov23_063102| [ 0.18630 -0.67560  0.79441  0.18604 -0.70347]]
20Nov23_063102|-- Bias --
20Nov23_063102|[ 1.74623  0.69730  0.72008 -0.20004  0.15599]
20Nov23_063102|Layer 3:
20Nov23_063102|-- Config --
20Nov23_063102|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063102|-- Weights --
20Nov23_063102|[[ 0.78512  0.58495  1.01708  1.05505 -0.47074]
20Nov23_063102| [ 0.09227 -0.27877  0.05296  0.69659  0.56285]
20Nov23_063102| [ 0.08212 -0.85808  1.14160 -0.25897 -0.73503]
20Nov23_063102| [-1.34393 -0.15823  0.51240 -0.30438 -0.15319]
20Nov23_063102| [-0.18853  0.79089 -0.34260 -0.42000  0.98012]]
20Nov23_063102|-- Bias --
20Nov23_063102|[ 0.02020 -0.47953 -0.29788  0.95327  0.93818]
20Nov23_063102|Layer 4:
20Nov23_063102|-- Config --
20Nov23_063102|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063102|-- Weights --
20Nov23_063102|[[-1.15005 -1.14488]
20Nov23_063102| [-0.70732 -0.77066]
20Nov23_063102| [-0.92771 -0.61093]
20Nov23_063102| [-0.90771 -1.04766]
20Nov23_063102| [ 1.53415  1.37750]]
20Nov23_063102|-- Bias --
20Nov23_063102|[-0.45752 -0.43811]
20Nov23_063102|Predicting the validation and test data with the Best final individual.
20Nov23_063108| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_063108|-----------  ------------------  --------------------  ----------
20Nov23_063108|Validation         27.39                  84            0.69558
20Nov23_063108|   Test            26.41                  84            0.68065
20Nov23_063108|-------------------------- Test #12 --------------------------
20Nov23_063108|Best final individual weights
20Nov23_063108|Individual:
20Nov23_063108|-- Constant hidden layers --
20Nov23_063108|False
20Nov23_063108|Layer 0:
20Nov23_063108|-- Config --
20Nov23_063108|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063108|-- Weights --
20Nov23_063108|[[ 0.37246  0.50348 -0.38721 -0.36688  2.11975  1.13385]
20Nov23_063108| [ 0.85547  0.24143 -1.64877 -0.78124 -0.43609 -2.21237]
20Nov23_063108| [ 0.42721 -0.76527 -0.51440 -0.75447  0.32484 -0.87275]
20Nov23_063108| [ 0.40346  0.73991  1.07205 -0.69045 -0.65947 -0.69401]
20Nov23_063108| [-0.42540  1.05687  1.57639 -0.19852 -0.01890 -1.25550]
20Nov23_063108| [ 1.01099 -1.20961  1.25712  1.12731 -2.11193 -0.16926]
20Nov23_063108| [ 1.24861  1.19184  0.77574  1.39326 -0.67107  0.80633]
20Nov23_063108| [-1.23263 -0.57257  1.51785  0.29112 -0.35951  0.26049]
20Nov23_063108| [ 0.34632  0.47098 -0.18577 -0.40163 -0.19665 -0.79876]
20Nov23_063108| [ 0.37496 -0.29597  1.24258 -0.16212 -0.65061  0.43949]
20Nov23_063108| [ 0.69488  0.81509 -2.27263  0.15914 -0.46454 -0.23901]
20Nov23_063108| [-0.75193 -1.91140 -1.01764 -0.74874 -0.08376  0.19787]
20Nov23_063108| [ 0.32119 -0.01971  0.44310 -1.10615 -0.05645  0.79914]
20Nov23_063108| [-0.32188  1.83930 -1.27440  1.32363 -0.58820 -1.55631]
20Nov23_063108| [-0.95047 -0.79252  0.53185  1.12978 -2.21543  0.23448]
20Nov23_063108| [ 0.83000 -0.27012  0.28352 -0.87504 -0.14749  0.55266]
20Nov23_063108| [ 1.13130 -0.03457 -0.21537 -0.55833 -1.49729 -0.36937]
20Nov23_063108| [-1.79056 -1.86836 -1.52421 -2.43591  0.70215 -0.37284]
20Nov23_063108| [-0.99829  0.58787 -0.49641  0.56679 -1.24154 -0.79487]
20Nov23_063108| [ 0.28588 -0.57617 -0.68829 -0.21789 -0.08347 -0.22650]
20Nov23_063108| [ 0.57393  0.27574 -0.47918  0.06886 -0.02632 -0.86438]
20Nov23_063108| [-2.37699  0.90398 -1.20198 -0.13722  1.11758  0.95157]
20Nov23_063108| [ 0.80080 -1.27768  0.47634  0.15233 -2.17593  0.08481]
20Nov23_063108| [ 0.96978 -1.60896  0.26377  1.17514 -0.48422 -1.14618]
20Nov23_063108| [-0.58915 -0.04214  1.08863 -1.31963  1.38578  0.43376]
20Nov23_063108| [-0.55311 -0.11218 -1.57961  0.61144  0.21090  0.85095]
20Nov23_063108| [ 0.95030  1.36585 -0.88436  0.55456 -0.29468 -0.06177]
20Nov23_063108| [-0.22244  2.02469 -2.20220  0.51991 -0.32656 -1.13757]
20Nov23_063108| [-1.02569 -0.75926  0.43686  0.74239 -0.03544  0.84045]
20Nov23_063108| [ 1.66723  0.36779  1.48881  1.78736  0.10982 -0.47841]
20Nov23_063108| [ 1.19031 -0.31012 -1.89834 -1.26765 -0.70409 -1.17102]
20Nov23_063108| [ 0.86965  0.28328  0.67962  0.19979 -0.07761  0.88232]
20Nov23_063108| [-0.37120 -0.21892 -0.63646  0.25970  0.09547  0.33285]
20Nov23_063108| [ 0.50033 -0.52733 -0.61247 -1.32671 -0.64064  0.80882]
20Nov23_063108| [-0.28304 -1.42711 -0.62821 -0.16242 -0.56235 -0.05706]
20Nov23_063108| [-1.16828  1.41397 -1.62729 -0.34079  0.64029  0.13870]
20Nov23_063108| [-1.25923 -1.77860  1.33062 -1.19801 -0.63088  0.01647]
20Nov23_063108| [-0.06558 -1.13347 -1.19374  0.35032  1.82112 -1.10971]
20Nov23_063108| [-0.71351  0.94623 -0.04997  0.34918 -0.63262  0.37683]
20Nov23_063108| [ 0.19848 -0.83013 -1.92147 -1.36939  0.83033 -0.13095]
20Nov23_063108| [-0.61376  0.80335  0.24413  0.96333 -1.14089  0.85802]
20Nov23_063108| [-0.36928 -0.42211  0.24520 -1.30295 -1.93237 -0.02548]
20Nov23_063108| [ 0.20256 -0.42818 -1.94283  0.77496  0.53459  1.61769]
20Nov23_063108| [ 0.68188  0.47057  0.20435  1.09097  0.15765  1.04190]
20Nov23_063108| [ 1.33491  0.24345  0.21908  0.18090  1.34449 -0.17898]
20Nov23_063108| [ 0.27847  0.70360  0.51300  1.26013 -1.36985 -0.78610]
20Nov23_063108| [ 1.84673  0.34176  1.17368  0.06267  0.80454 -1.08971]
20Nov23_063108| [-1.55035 -0.68663 -0.37203  0.80163 -0.26877  0.01660]
20Nov23_063108| [ 1.09088 -1.16331  0.24986 -0.12997  1.33586 -1.57542]
20Nov23_063108| [-0.65292 -1.51801  0.65628 -0.59370  2.42713 -0.62132]
20Nov23_063108| [-0.24412 -0.93150 -0.95428  2.12486 -1.66742  0.38608]
20Nov23_063108| [-0.12629 -1.50991  1.01674 -1.39436  0.05675  0.29722]
20Nov23_063108| [ 0.97103 -0.96420  0.21034 -1.70519  1.10287 -1.04466]
20Nov23_063108| [-0.08849  0.34404  1.21360  1.35353  0.10154 -0.21929]
20Nov23_063108| [ 2.57606  0.55820 -0.39108  0.68623 -1.25579 -0.40213]
20Nov23_063108| [-1.14612  0.04346  0.06719  0.49167  1.02429  0.57897]
20Nov23_063108| [-0.52130 -0.28448 -0.88990 -0.47006  0.38699 -1.63998]]
20Nov23_063108|-- Bias --
20Nov23_063108|[-1.43356  1.08152  0.41815  0.00424 -0.24154  0.48990]
20Nov23_063108|Layer 1:
20Nov23_063108|-- Config --
20Nov23_063108|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063108|-- Weights --
20Nov23_063108|[[-1.12283 -0.64585  0.37135  0.93805  0.50152]
20Nov23_063108| [-0.45128 -0.33951  2.35894 -0.23711  0.47670]
20Nov23_063108| [ 1.07740 -1.29532 -1.29629  0.87008  0.40993]
20Nov23_063108| [ 0.03760  1.27456 -1.39564  0.16391  0.14825]
20Nov23_063108| [-1.16091 -1.49048  0.95524 -0.46229  0.11068]
20Nov23_063108| [-0.26762  1.19525  1.35283  2.28556 -0.02087]]
20Nov23_063108|-- Bias --
20Nov23_063108|[-0.01568 -0.30813  0.67368 -0.55501  0.11533]
20Nov23_063108|Layer 2:
20Nov23_063108|-- Config --
20Nov23_063108|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063108|-- Weights --
20Nov23_063108|[[ 0.73189  0.25994  0.61296 -0.76909  0.25937]
20Nov23_063108| [-0.88936 -0.61503 -0.69177 -0.58393  0.75519]
20Nov23_063108| [ 0.27706 -1.82774  0.74789  0.24210  0.70912]
20Nov23_063108| [-0.71073 -0.66461 -0.05384  0.42014 -0.09637]
20Nov23_063108| [ 0.18630 -0.67560  0.79441  0.18604 -0.70347]]
20Nov23_063108|-- Bias --
20Nov23_063108|[ 1.74623  0.69730  0.72008 -0.20004  0.15599]
20Nov23_063108|Layer 3:
20Nov23_063108|-- Config --
20Nov23_063108|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063108|-- Weights --
20Nov23_063108|[[ 0.78512  0.58495  1.01708  1.05505 -0.47074]
20Nov23_063108| [ 0.09227 -0.27877  0.05296  0.69659  0.56285]
20Nov23_063108| [ 0.08212 -0.85808  1.14160 -0.25897 -0.73503]
20Nov23_063108| [-1.34393 -0.15823  0.51240 -0.30438 -0.15319]
20Nov23_063108| [-0.18853  0.79089 -0.34260 -0.42000  0.98012]]
20Nov23_063108|-- Bias --
20Nov23_063108|[ 0.02020 -0.47953 -0.29788  0.95327  0.93818]
20Nov23_063108|Layer 4:
20Nov23_063108|-- Config --
20Nov23_063108|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063108|-- Weights --
20Nov23_063108|[[-1.15005 -1.14488]
20Nov23_063108| [-0.70732 -0.77066]
20Nov23_063108| [-0.92771 -0.61093]
20Nov23_063108| [-0.90771 -1.04766]
20Nov23_063108| [ 1.53415  1.37750]]
20Nov23_063108|-- Bias --
20Nov23_063108|[-0.45752 -0.43811]
20Nov23_063108|Predicting the validation and test data with the Best final individual.
20Nov23_063115| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_063115|-----------  ------------------  --------------------  ----------
20Nov23_063115|Validation         42.00                  84            0.00000
20Nov23_063115|   Test            24.15                  84            0.56870
20Nov23_063115|-------------------------- Test #13 --------------------------
20Nov23_063115|Best final individual weights
20Nov23_063115|Individual:
20Nov23_063115|-- Constant hidden layers --
20Nov23_063115|False
20Nov23_063115|Layer 0:
20Nov23_063115|-- Config --
20Nov23_063115|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063115|-- Weights --
20Nov23_063115|[[ 0.37246  0.50348 -0.38721 -0.36688  2.11975  1.13385]
20Nov23_063115| [ 0.85547  0.24143 -1.64877 -0.78124 -0.43609 -2.21237]
20Nov23_063115| [ 0.42721 -0.76527 -0.51440 -0.75447  0.32484 -0.87275]
20Nov23_063115| [ 0.40346  0.73991  1.07205 -0.69045 -0.65947 -0.69401]
20Nov23_063115| [-0.42540  1.05687  1.57639 -0.19852 -0.01890 -1.25550]
20Nov23_063115| [ 1.01099 -1.20961  1.25712  1.12731 -2.11193 -0.16926]
20Nov23_063115| [ 1.24861  1.19184  0.77574  1.39326 -0.67107  0.80633]
20Nov23_063115| [-1.23263 -0.57257  1.51785  0.29112 -0.35951  0.26049]
20Nov23_063115| [ 0.34632  0.47098 -0.18577 -0.40163 -0.19665 -0.79876]
20Nov23_063115| [ 0.37496 -0.29597  1.24258 -0.16212 -0.65061  0.43949]
20Nov23_063115| [ 0.69488  0.81509 -2.27263  0.15914 -0.46454 -0.23901]
20Nov23_063115| [-0.75193 -1.91140 -1.01764 -0.74874 -0.08376  0.19787]
20Nov23_063115| [ 0.32119 -0.01971  0.44310 -1.10615 -0.05645  0.79914]
20Nov23_063115| [-0.32188  1.83930 -1.27440  1.32363 -0.58820 -1.55631]
20Nov23_063115| [-0.95047 -0.79252  0.53185  1.12978 -2.21543  0.23448]
20Nov23_063115| [ 0.83000 -0.27012  0.28352 -0.87504 -0.14749  0.55266]
20Nov23_063115| [ 1.13130 -0.03457 -0.21537 -0.55833 -1.49729 -0.36937]
20Nov23_063115| [-1.79056 -1.86836 -1.52421 -2.43591  0.70215 -0.37284]
20Nov23_063115| [-0.99829  0.58787 -0.49641  0.56679 -1.24154 -0.79487]
20Nov23_063115| [ 0.28588 -0.57617 -0.68829 -0.21789 -0.08347 -0.22650]
20Nov23_063115| [ 0.57393  0.27574 -0.47918  0.06886 -0.02632 -0.86438]
20Nov23_063115| [-2.37699  0.90398 -1.20198 -0.13722  1.11758  0.95157]
20Nov23_063115| [ 0.80080 -1.27768  0.47634  0.15233 -2.17593  0.08481]
20Nov23_063115| [ 0.96978 -1.60896  0.26377  1.17514 -0.48422 -1.14618]
20Nov23_063115| [-0.58915 -0.04214  1.08863 -1.31963  1.38578  0.43376]
20Nov23_063115| [-0.55311 -0.11218 -1.57961  0.61144  0.21090  0.85095]
20Nov23_063115| [ 0.95030  1.36585 -0.88436  0.55456 -0.29468 -0.06177]
20Nov23_063115| [-0.22244  2.02469 -2.20220  0.51991 -0.32656 -1.13757]
20Nov23_063115| [-1.02569 -0.75926  0.43686  0.74239 -0.03544  0.84045]
20Nov23_063115| [ 1.66723  0.36779  1.48881  1.78736  0.10982 -0.47841]
20Nov23_063115| [ 1.19031 -0.31012 -1.89834 -1.26765 -0.70409 -1.17102]
20Nov23_063115| [ 0.86965  0.28328  0.67962  0.19979 -0.07761  0.88232]
20Nov23_063115| [-0.37120 -0.21892 -0.63646  0.25970  0.09547  0.33285]
20Nov23_063115| [ 0.50033 -0.52733 -0.61247 -1.32671 -0.64064  0.80882]
20Nov23_063115| [-0.28304 -1.42711 -0.62821 -0.16242 -0.56235 -0.05706]
20Nov23_063115| [-1.16828  1.41397 -1.62729 -0.34079  0.64029  0.13870]
20Nov23_063115| [-1.25923 -1.77860  1.33062 -1.19801 -0.63088  0.01647]
20Nov23_063115| [-0.06558 -1.13347 -1.19374  0.35032  1.82112 -1.10971]
20Nov23_063115| [-0.71351  0.94623 -0.04997  0.34918 -0.63262  0.37683]
20Nov23_063115| [ 0.19848 -0.83013 -1.92147 -1.36939  0.83033 -0.13095]
20Nov23_063115| [-0.61376  0.80335  0.24413  0.96333 -1.14089  0.85802]
20Nov23_063115| [-0.36928 -0.42211  0.24520 -1.30295 -1.93237 -0.02548]
20Nov23_063115| [ 0.20256 -0.42818 -1.94283  0.77496  0.53459  1.61769]
20Nov23_063115| [ 0.68188  0.47057  0.20435  1.09097  0.15765  1.04190]
20Nov23_063115| [ 1.33491  0.24345  0.21908  0.18090  1.34449 -0.17898]
20Nov23_063115| [ 0.27847  0.70360  0.51300  1.26013 -1.36985 -0.78610]
20Nov23_063115| [ 1.84673  0.34176  1.17368  0.06267  0.80454 -1.08971]
20Nov23_063115| [-1.55035 -0.68663 -0.37203  0.80163 -0.26877  0.01660]
20Nov23_063115| [ 1.09088 -1.16331  0.24986 -0.12997  1.33586 -1.57542]
20Nov23_063115| [-0.65292 -1.51801  0.65628 -0.59370  2.42713 -0.62132]
20Nov23_063115| [-0.24412 -0.93150 -0.95428  2.12486 -1.66742  0.38608]
20Nov23_063115| [-0.12629 -1.50991  1.01674 -1.39436  0.05675  0.29722]
20Nov23_063115| [ 0.97103 -0.96420  0.21034 -1.70519  1.10287 -1.04466]
20Nov23_063115| [-0.08849  0.34404  1.21360  1.35353  0.10154 -0.21929]
20Nov23_063115| [ 2.57606  0.55820 -0.39108  0.68623 -1.25579 -0.40213]
20Nov23_063115| [-1.14612  0.04346  0.06719  0.49167  1.02429  0.57897]
20Nov23_063115| [-0.52130 -0.28448 -0.88990 -0.47006  0.38699 -1.63998]]
20Nov23_063115|-- Bias --
20Nov23_063115|[-1.43356  1.08152  0.41815  0.00424 -0.24154  0.48990]
20Nov23_063115|Layer 1:
20Nov23_063115|-- Config --
20Nov23_063115|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063115|-- Weights --
20Nov23_063115|[[-1.12283 -0.64585  0.37135  0.93805  0.50152]
20Nov23_063115| [-0.45128 -0.33951  2.35894 -0.23711  0.47670]
20Nov23_063115| [ 1.07740 -1.29532 -1.29629  0.87008  0.40993]
20Nov23_063115| [ 0.03760  1.27456 -1.39564  0.16391  0.14825]
20Nov23_063115| [-1.16091 -1.49048  0.95524 -0.46229  0.11068]
20Nov23_063115| [-0.26762  1.19525  1.35283  2.28556 -0.02087]]
20Nov23_063115|-- Bias --
20Nov23_063115|[-0.01568 -0.30813  0.67368 -0.55501  0.11533]
20Nov23_063115|Layer 2:
20Nov23_063115|-- Config --
20Nov23_063115|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063115|-- Weights --
20Nov23_063115|[[ 0.73189  0.25994  0.61296 -0.76909  0.25937]
20Nov23_063115| [-0.88936 -0.61503 -0.69177 -0.58393  0.75519]
20Nov23_063115| [ 0.27706 -1.82774  0.74789  0.24210  0.70912]
20Nov23_063115| [-0.71073 -0.66461 -0.05384  0.42014 -0.09637]
20Nov23_063115| [ 0.18630 -0.67560  0.79441  0.18604 -0.70347]]
20Nov23_063115|-- Bias --
20Nov23_063115|[ 1.74623  0.69730  0.72008 -0.20004  0.15599]
20Nov23_063115|Layer 3:
20Nov23_063115|-- Config --
20Nov23_063115|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063115|-- Weights --
20Nov23_063115|[[ 0.78512  0.58495  1.01708  1.05505 -0.47074]
20Nov23_063115| [ 0.09227 -0.27877  0.05296  0.69659  0.56285]
20Nov23_063115| [ 0.08212 -0.85808  1.14160 -0.25897 -0.73503]
20Nov23_063115| [-1.34393 -0.15823  0.51240 -0.30438 -0.15319]
20Nov23_063115| [-0.18853  0.79089 -0.34260 -0.42000  0.98012]]
20Nov23_063115|-- Bias --
20Nov23_063115|[ 0.02020 -0.47953 -0.29788  0.95327  0.93818]
20Nov23_063115|Layer 4:
20Nov23_063115|-- Config --
20Nov23_063115|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063115|-- Weights --
20Nov23_063115|[[-1.15005 -1.14488]
20Nov23_063115| [-0.70732 -0.77066]
20Nov23_063115| [-0.92771 -0.61093]
20Nov23_063115| [-0.90771 -1.04766]
20Nov23_063115| [ 1.53415  1.37750]]
20Nov23_063115|-- Bias --
20Nov23_063115|[-0.45752 -0.43811]
20Nov23_063115|Predicting the validation and test data with the Best final individual.
20Nov23_063122| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_063122|-----------  ------------------  --------------------  ----------
20Nov23_063122|Validation         41.91                  84            0.00259
20Nov23_063122|   Test            25.63                  84            0.65238
20Nov23_063122|-------------------------- Test #14 --------------------------
20Nov23_063122|Best final individual weights
20Nov23_063122|Individual:
20Nov23_063122|-- Constant hidden layers --
20Nov23_063122|False
20Nov23_063122|Layer 0:
20Nov23_063122|-- Config --
20Nov23_063122|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063122|-- Weights --
20Nov23_063122|[[ 0.37246  0.50348 -0.38721 -0.36688  2.11975  1.13385]
20Nov23_063122| [ 0.85547  0.24143 -1.64877 -0.78124 -0.43609 -2.21237]
20Nov23_063122| [ 0.42721 -0.76527 -0.51440 -0.75447  0.32484 -0.87275]
20Nov23_063122| [ 0.40346  0.73991  1.07205 -0.69045 -0.65947 -0.69401]
20Nov23_063122| [-0.42540  1.05687  1.57639 -0.19852 -0.01890 -1.25550]
20Nov23_063122| [ 1.01099 -1.20961  1.25712  1.12731 -2.11193 -0.16926]
20Nov23_063122| [ 1.24861  1.19184  0.77574  1.39326 -0.67107  0.80633]
20Nov23_063122| [-1.23263 -0.57257  1.51785  0.29112 -0.35951  0.26049]
20Nov23_063122| [ 0.34632  0.47098 -0.18577 -0.40163 -0.19665 -0.79876]
20Nov23_063122| [ 0.37496 -0.29597  1.24258 -0.16212 -0.65061  0.43949]
20Nov23_063122| [ 0.69488  0.81509 -2.27263  0.15914 -0.46454 -0.23901]
20Nov23_063122| [-0.75193 -1.91140 -1.01764 -0.74874 -0.08376  0.19787]
20Nov23_063122| [ 0.32119 -0.01971  0.44310 -1.10615 -0.05645  0.79914]
20Nov23_063122| [-0.32188  1.83930 -1.27440  1.32363 -0.58820 -1.55631]
20Nov23_063122| [-0.95047 -0.79252  0.53185  1.12978 -2.21543  0.23448]
20Nov23_063122| [ 0.83000 -0.27012  0.28352 -0.87504 -0.14749  0.55266]
20Nov23_063122| [ 1.13130 -0.03457 -0.21537 -0.55833 -1.49729 -0.36937]
20Nov23_063122| [-1.79056 -1.86836 -1.52421 -2.43591  0.70215 -0.37284]
20Nov23_063122| [-0.99829  0.58787 -0.49641  0.56679 -1.24154 -0.79487]
20Nov23_063122| [ 0.28588 -0.57617 -0.68829 -0.21789 -0.08347 -0.22650]
20Nov23_063122| [ 0.57393  0.27574 -0.47918  0.06886 -0.02632 -0.86438]
20Nov23_063122| [-2.37699  0.90398 -1.20198 -0.13722  1.11758  0.95157]
20Nov23_063122| [ 0.80080 -1.27768  0.47634  0.15233 -2.17593  0.08481]
20Nov23_063122| [ 0.96978 -1.60896  0.26377  1.17514 -0.48422 -1.14618]
20Nov23_063122| [-0.58915 -0.04214  1.08863 -1.31963  1.38578  0.43376]
20Nov23_063122| [-0.55311 -0.11218 -1.57961  0.61144  0.21090  0.85095]
20Nov23_063122| [ 0.95030  1.36585 -0.88436  0.55456 -0.29468 -0.06177]
20Nov23_063122| [-0.22244  2.02469 -2.20220  0.51991 -0.32656 -1.13757]
20Nov23_063122| [-1.02569 -0.75926  0.43686  0.74239 -0.03544  0.84045]
20Nov23_063122| [ 1.66723  0.36779  1.48881  1.78736  0.10982 -0.47841]
20Nov23_063122| [ 1.19031 -0.31012 -1.89834 -1.26765 -0.70409 -1.17102]
20Nov23_063122| [ 0.86965  0.28328  0.67962  0.19979 -0.07761  0.88232]
20Nov23_063122| [-0.37120 -0.21892 -0.63646  0.25970  0.09547  0.33285]
20Nov23_063122| [ 0.50033 -0.52733 -0.61247 -1.32671 -0.64064  0.80882]
20Nov23_063122| [-0.28304 -1.42711 -0.62821 -0.16242 -0.56235 -0.05706]
20Nov23_063122| [-1.16828  1.41397 -1.62729 -0.34079  0.64029  0.13870]
20Nov23_063122| [-1.25923 -1.77860  1.33062 -1.19801 -0.63088  0.01647]
20Nov23_063122| [-0.06558 -1.13347 -1.19374  0.35032  1.82112 -1.10971]
20Nov23_063122| [-0.71351  0.94623 -0.04997  0.34918 -0.63262  0.37683]
20Nov23_063122| [ 0.19848 -0.83013 -1.92147 -1.36939  0.83033 -0.13095]
20Nov23_063122| [-0.61376  0.80335  0.24413  0.96333 -1.14089  0.85802]
20Nov23_063122| [-0.36928 -0.42211  0.24520 -1.30295 -1.93237 -0.02548]
20Nov23_063122| [ 0.20256 -0.42818 -1.94283  0.77496  0.53459  1.61769]
20Nov23_063122| [ 0.68188  0.47057  0.20435  1.09097  0.15765  1.04190]
20Nov23_063122| [ 1.33491  0.24345  0.21908  0.18090  1.34449 -0.17898]
20Nov23_063122| [ 0.27847  0.70360  0.51300  1.26013 -1.36985 -0.78610]
20Nov23_063122| [ 1.84673  0.34176  1.17368  0.06267  0.80454 -1.08971]
20Nov23_063122| [-1.55035 -0.68663 -0.37203  0.80163 -0.26877  0.01660]
20Nov23_063122| [ 1.09088 -1.16331  0.24986 -0.12997  1.33586 -1.57542]
20Nov23_063122| [-0.65292 -1.51801  0.65628 -0.59370  2.42713 -0.62132]
20Nov23_063122| [-0.24412 -0.93150 -0.95428  2.12486 -1.66742  0.38608]
20Nov23_063122| [-0.12629 -1.50991  1.01674 -1.39436  0.05675  0.29722]
20Nov23_063122| [ 0.97103 -0.96420  0.21034 -1.70519  1.10287 -1.04466]
20Nov23_063122| [-0.08849  0.34404  1.21360  1.35353  0.10154 -0.21929]
20Nov23_063122| [ 2.57606  0.55820 -0.39108  0.68623 -1.25579 -0.40213]
20Nov23_063122| [-1.14612  0.04346  0.06719  0.49167  1.02429  0.57897]
20Nov23_063122| [-0.52130 -0.28448 -0.88990 -0.47006  0.38699 -1.63998]]
20Nov23_063122|-- Bias --
20Nov23_063122|[-1.43356  1.08152  0.41815  0.00424 -0.24154  0.48990]
20Nov23_063122|Layer 1:
20Nov23_063122|-- Config --
20Nov23_063122|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063122|-- Weights --
20Nov23_063122|[[-1.12283 -0.64585  0.37135  0.93805  0.50152]
20Nov23_063122| [-0.45128 -0.33951  2.35894 -0.23711  0.47670]
20Nov23_063122| [ 1.07740 -1.29532 -1.29629  0.87008  0.40993]
20Nov23_063122| [ 0.03760  1.27456 -1.39564  0.16391  0.14825]
20Nov23_063122| [-1.16091 -1.49048  0.95524 -0.46229  0.11068]
20Nov23_063122| [-0.26762  1.19525  1.35283  2.28556 -0.02087]]
20Nov23_063122|-- Bias --
20Nov23_063122|[-0.01568 -0.30813  0.67368 -0.55501  0.11533]
20Nov23_063122|Layer 2:
20Nov23_063122|-- Config --
20Nov23_063122|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063122|-- Weights --
20Nov23_063122|[[ 0.73189  0.25994  0.61296 -0.76909  0.25937]
20Nov23_063122| [-0.88936 -0.61503 -0.69177 -0.58393  0.75519]
20Nov23_063122| [ 0.27706 -1.82774  0.74789  0.24210  0.70912]
20Nov23_063122| [-0.71073 -0.66461 -0.05384  0.42014 -0.09637]
20Nov23_063122| [ 0.18630 -0.67560  0.79441  0.18604 -0.70347]]
20Nov23_063122|-- Bias --
20Nov23_063122|[ 1.74623  0.69730  0.72008 -0.20004  0.15599]
20Nov23_063122|Layer 3:
20Nov23_063122|-- Config --
20Nov23_063122|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063122|-- Weights --
20Nov23_063122|[[ 0.78512  0.58495  1.01708  1.05505 -0.47074]
20Nov23_063122| [ 0.09227 -0.27877  0.05296  0.69659  0.56285]
20Nov23_063122| [ 0.08212 -0.85808  1.14160 -0.25897 -0.73503]
20Nov23_063122| [-1.34393 -0.15823  0.51240 -0.30438 -0.15319]
20Nov23_063122| [-0.18853  0.79089 -0.34260 -0.42000  0.98012]]
20Nov23_063122|-- Bias --
20Nov23_063122|[ 0.02020 -0.47953 -0.29788  0.95327  0.93818]
20Nov23_063122|Layer 4:
20Nov23_063122|-- Config --
20Nov23_063122|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_063122|-- Weights --
20Nov23_063122|[[-1.15005 -1.14488]
20Nov23_063122| [-0.70732 -0.77066]
20Nov23_063122| [-0.92771 -0.61093]
20Nov23_063122| [-0.90771 -1.04766]
20Nov23_063122| [ 1.53415  1.37750]]
20Nov23_063122|-- Bias --
20Nov23_063122|[-0.45752 -0.43811]
20Nov23_063122|Predicting the validation and test data with the Best final individual.
20Nov23_063129| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_063129|-----------  ------------------  --------------------  ----------
20Nov23_063129|Validation         25.74                  84            0.71136
20Nov23_063129|   Test            36.40                  84            0.00000
Using Theano backend.
20Nov23_063130|Data summary: Train
20Nov23_063130|data.shape = (2300, 57)
20Nov23_063130|labels.shape = (2300,)
20Nov23_063130|Class distribution:
20Nov23_063130|	0 - 1389 (0.60)
20Nov23_063130|	1 - 911 (0.40)
20Nov23_063130|Data summary: Validation
20Nov23_063130|data.shape = (1150, 57)
20Nov23_063130|labels.shape = (1150,)
20Nov23_063130|Class distribution:
20Nov23_063130|	0 - 667 (0.58)
20Nov23_063130|	1 - 483 (0.42)
20Nov23_063130|Data summary: Test
20Nov23_063130|data.shape = (1151, 57)
20Nov23_063130|labels.shape = (1151,)
20Nov23_063130|Class distribution:
20Nov23_063130|	0 - 732 (0.64)
20Nov23_063130|	1 - 419 (0.36)
20Nov23_063130|Selected configuration values
20Nov23_063130|-- Dataset name: spambase2
20Nov23_063130|-- Initial population size: 64
20Nov23_063130|-- Maximun number of generations: 32
20Nov23_063130|-- Neurons per hidden layer range: (2, 20)
20Nov23_063130|-- Hidden layers number range: (1, 3)
20Nov23_063130|-- Crossover probability: 0.5
20Nov23_063130|-- Bias gene mutation probability: 0.2
20Nov23_063130|-- Weights gene mutation probability: 0.75
20Nov23_063130|-- Neuron mutation probability: 0.3
20Nov23_063130|-- Layer mutation probability: 0.3
20Nov23_063130|-- Constant hidden layers: False
20Nov23_063130|-- Seed: None
20Nov23_063130|Entering GA
20Nov23_063130|Start the algorithm
20Nov23_063444|-- Generation 1 --
20Nov23_063444|    -- Crossed 0 individual pairs.
20Nov23_063444|    -- Mutated 32 individuals.
20Nov23_063749|    -- Evaluated 64 individuals.
20Nov23_063749|    Summary of generation 1:
20Nov23_063749| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_063749|-----------  ------------------  --------------------  ----------
20Nov23_063749|    Max            58.00                156.00          0.78358
20Nov23_063749|    Avg            42.26                26.73           0.01378
20Nov23_063749|    Min            41.57                 2.00           0.00000
20Nov23_063749|    Std             1.99                28.38           0.09703
20Nov23_063749|   Best            41.57                16.00           0.01803
20Nov23_063749|-- Generation 2 --
20Nov23_063749|    -- Crossed 3 individual pairs.
20Nov23_063749|    -- Mutated 32 individuals.
20Nov23_064051|    -- Evaluated 64 individuals.
20Nov23_064051|    Summary of generation 2:
20Nov23_064051| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_064051|-----------  ------------------  --------------------  ----------
20Nov23_064051|    Max            58.00                156.00          0.78358
20Nov23_064051|    Avg            41.97                18.97           0.02433
20Nov23_064051|    Min            28.70                 2.00           0.00000
20Nov23_064051|    Std             2.62                26.67           0.11766
20Nov23_064051|   Best            28.70                48.00           0.55020
20Nov23_064051|-- Generation 3 --
20Nov23_064051|    -- Crossed 4 individual pairs.
20Nov23_064051|    -- Mutated 32 individuals.
20Nov23_064351|    -- Evaluated 64 individuals.
20Nov23_064351|    Summary of generation 3:
20Nov23_064351| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_064351|-----------  ------------------  --------------------  ----------
20Nov23_064351|    Max            58.00                224.00          0.78358
20Nov23_064351|    Avg            41.92                16.98           0.02574
20Nov23_064351|    Min            29.83                 2.00           0.00000
20Nov23_064351|    Std             2.58                33.25           0.11117
20Nov23_064351|   Best            29.83                48.00           0.40850
20Nov23_064351|-- Generation 4 --
20Nov23_064351|    -- Crossed 2 individual pairs.
20Nov23_064351|    -- Mutated 32 individuals.
20Nov23_064649|    -- Evaluated 64 individuals.
20Nov23_064649|    Summary of generation 4:
20Nov23_064649| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_064649|-----------  ------------------  --------------------  ----------
20Nov23_064649|    Max            42.17                156.00          0.70507
20Nov23_064649|    Avg            41.55                15.27           0.01882
20Nov23_064649|    Min            24.09                 2.00           0.00000
20Nov23_064649|    Std             2.28                27.38           0.09022
20Nov23_064649|   Best            24.09                48.00           0.70507
20Nov23_064649|-- Generation 5 --
20Nov23_064649|    -- Crossed 6 individual pairs.
20Nov23_064649|    -- Mutated 32 individuals.
20Nov23_064948|    -- Evaluated 64 individuals.
20Nov23_064948|    Summary of generation 5:
20Nov23_064948| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_064948|-----------  ------------------  --------------------  ----------
20Nov23_064948|    Max            58.00                156.00          0.78889
20Nov23_064948|    Avg            41.95                18.64           0.03287
20Nov23_064948|    Min            34.70                 2.00           0.00000
20Nov23_064948|    Std             2.30                36.47           0.13881
20Nov23_064948|   Best            34.70                10.00           0.78889
20Nov23_064948|-- Generation 6 --
20Nov23_064948|    -- Crossed 3 individual pairs.
20Nov23_064948|    -- Mutated 32 individuals.
20Nov23_065248|    -- Evaluated 64 individuals.
20Nov23_065248|    Summary of generation 6:
20Nov23_065248| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_065248|-----------  ------------------  --------------------  ----------
20Nov23_065248|    Max            42.17                159.00          0.82885
20Nov23_065248|    Avg            41.77                21.78           0.01937
20Nov23_065248|    Min            36.00                 2.00           0.00000
20Nov23_065248|    Std             0.84                40.90           0.10346
20Nov23_065248|   Best            36.00                30.00           0.82885
20Nov23_065248|-- Generation 7 --
20Nov23_065248|    -- Crossed 5 individual pairs.
20Nov23_065248|    -- Mutated 32 individuals.
20Nov23_065550|    -- Evaluated 64 individuals.
20Nov23_065550|    Summary of generation 7:
20Nov23_065550| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_065550|-----------  ------------------  --------------------  ----------
20Nov23_065550|    Max            42.09                159.00          0.68440
20Nov23_065550|    Avg            41.45                24.02           0.02578
20Nov23_065550|    Min            29.48                 2.00           0.00000
20Nov23_065550|    Std             1.94                43.30           0.09662
20Nov23_065550|   Best            29.48                30.00           0.68440
20Nov23_065550|-- Generation 8 --
20Nov23_065550|    -- Crossed 3 individual pairs.
20Nov23_065550|    -- Mutated 32 individuals.
20Nov23_065847|    -- Evaluated 64 individuals.
20Nov23_065847|    Summary of generation 8:
20Nov23_065847| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_065847|-----------  ------------------  --------------------  ----------
20Nov23_065847|    Max            58.00                159.00          0.79128
20Nov23_065847|    Avg            41.75                14.62           0.03813
20Nov23_065847|    Min            29.48                 2.00           0.00000
20Nov23_065847|    Std             2.66                27.26           0.13880
20Nov23_065847|   Best            29.48                30.00           0.79128
20Nov23_065847|-- Generation 9 --
20Nov23_065847|    -- Crossed 4 individual pairs.
20Nov23_065847|    -- Mutated 32 individuals.
20Nov23_070145|    -- Evaluated 64 individuals.
20Nov23_070145|    Summary of generation 9:
20Nov23_070145| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_070145|-----------  ------------------  --------------------  ----------
20Nov23_070145|    Max            42.26                63.00           0.33209
20Nov23_070145|    Avg            41.64                11.05           0.01613
20Nov23_070145|    Min            35.22                 2.00           0.00000
20Nov23_070145|    Std             0.99                 9.39           0.04626
20Nov23_070145|   Best            35.22                 9.00           0.33209
20Nov23_070145|-- Generation 10 --
20Nov23_070145|    -- Crossed 2 individual pairs.
20Nov23_070145|    -- Mutated 32 individuals.
20Nov23_070441|    -- Evaluated 64 individuals.
20Nov23_070441|    Summary of generation 10:
20Nov23_070441| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_070441|-----------  ------------------  --------------------  ----------
20Nov23_070441|    Max            42.17                28.00           0.12756
20Nov23_070441|    Avg            41.71                 9.58           0.01167
20Nov23_070441|    Min            38.78                 2.00           0.00000
20Nov23_070441|    Std             0.63                 5.50           0.02400
20Nov23_070441|   Best            38.78                 8.00           0.12054
20Nov23_070441|-- Generation 11 --
20Nov23_070441|    -- Crossed 6 individual pairs.
20Nov23_070441|    -- Mutated 32 individuals.
20Nov23_070739|    -- Evaluated 64 individuals.
20Nov23_070739|    Summary of generation 11:
20Nov23_070739| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_070739|-----------  ------------------  --------------------  ----------
20Nov23_070739|    Max            43.04                30.00           0.22472
20Nov23_070739|    Avg            41.70                10.59           0.01699
20Nov23_070739|    Min            37.65                 2.00           0.00000
20Nov23_070739|    Std             0.80                 7.18           0.04203
20Nov23_070739|   Best            37.65                 8.00           0.21823
20Nov23_070739|-- Generation 12 --
20Nov23_070739|    -- Crossed 4 individual pairs.
20Nov23_070739|    -- Mutated 32 individuals.
20Nov23_071036|    -- Evaluated 64 individuals.
20Nov23_071036|    Summary of generation 12:
20Nov23_071036| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_071036|-----------  ------------------  --------------------  ----------
20Nov23_071036|    Max            42.17                28.00           0.25301
20Nov23_071036|    Avg            41.59                 8.92           0.01801
20Nov23_071036|    Min            36.17                 2.00           0.00000
20Nov23_071036|    Std             0.99                 5.25           0.04468
20Nov23_071036|   Best            36.17                 9.00           0.25301
20Nov23_071036|-- Generation 13 --
20Nov23_071036|    -- Crossed 4 individual pairs.
20Nov23_071036|    -- Mutated 32 individuals.
20Nov23_071334|    -- Evaluated 64 individuals.
20Nov23_071334|    Summary of generation 13:
20Nov23_071334| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_071334|-----------  ------------------  --------------------  ----------
20Nov23_071334|    Max            42.09                28.00           0.65923
20Nov23_071334|    Avg            41.31                10.30           0.03392
20Nov23_071334|    Min            31.83                 2.00           0.00000
20Nov23_071334|    Std             1.60                 6.79           0.09298
20Nov23_071334|   Best            31.83                14.00           0.65923
20Nov23_071334|-- Generation 14 --
20Nov23_071334|    -- Crossed 4 individual pairs.
20Nov23_071334|    -- Mutated 32 individuals.
20Nov23_071631|    -- Evaluated 64 individuals.
20Nov23_071631|    Summary of generation 14:
20Nov23_071631| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_071631|-----------  ------------------  --------------------  ----------
20Nov23_071631|    Max            42.61                36.00           0.23267
20Nov23_071631|    Avg            41.49                 9.20           0.02236
20Nov23_071631|    Min            36.70                 2.00           0.00000
20Nov23_071631|    Std             1.01                 5.99           0.04495
20Nov23_071631|   Best            36.70                 8.00           0.23267
20Nov23_071631|-- Generation 15 --
20Nov23_071631|    -- Crossed 3 individual pairs.
20Nov23_071631|    -- Mutated 32 individuals.
20Nov23_071928|    -- Evaluated 64 individuals.
20Nov23_071928|    Summary of generation 15:
20Nov23_071928| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_071928|-----------  ------------------  --------------------  ----------
20Nov23_071928|    Max            49.13                28.00           0.80357
20Nov23_071928|    Avg            41.64                 9.92           0.03382
20Nov23_071928|    Min            37.74                 2.00           0.00000
20Nov23_071928|    Std             1.30                 6.42           0.10570
20Nov23_071928|   Best            37.74                 8.00           0.19127
20Nov23_071928|-- Generation 16 --
20Nov23_071928|    -- Crossed 1 individual pairs.
20Nov23_071928|    -- Mutated 32 individuals.
20Nov23_072223|    -- Evaluated 64 individuals.
20Nov23_072223|    Summary of generation 16:
20Nov23_072223| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_072223|-----------  ------------------  --------------------  ----------
20Nov23_072223|    Max            57.91                28.00           0.78384
20Nov23_072223|    Avg            41.80                 9.55           0.03187
20Nov23_072223|    Min            38.09                 3.00           0.00000
20Nov23_072223|    Std             2.19                 5.55           0.10089
20Nov23_072223|   Best            38.09                 9.00           0.16345
20Nov23_072223|-- Generation 17 --
20Nov23_072223|    -- Crossed 4 individual pairs.
20Nov23_072223|    -- Mutated 32 individuals.
20Nov23_072520|    -- Evaluated 64 individuals.
20Nov23_072520|    Summary of generation 17:
20Nov23_072520| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_072520|-----------  ------------------  --------------------  ----------
20Nov23_072520|    Max            42.26                28.00           0.13661
20Nov23_072520|    Avg            41.40                 9.66           0.02430
20Nov23_072520|    Min            38.43                 4.00           0.00000
20Nov23_072520|    Std             0.91                 5.86           0.03550
20Nov23_072520|   Best            38.43                 9.00           0.13270
20Nov23_072520|-- Generation 18 --
20Nov23_072520|    -- Crossed 8 individual pairs.
20Nov23_072520|    -- Mutated 32 individuals.
20Nov23_072815|    -- Evaluated 64 individuals.
20Nov23_072815|    Summary of generation 18:
20Nov23_072815| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_072815|-----------  ------------------  --------------------  ----------
20Nov23_072815|    Max            42.17                26.00           0.41244
20Nov23_072815|    Avg            41.07                 8.38           0.03874
20Nov23_072815|    Min            31.57                 4.00           0.00000
20Nov23_072815|    Std             1.53                 3.98           0.06216
20Nov23_072815|   Best            31.57                26.00           0.41244
20Nov23_072815|-- Generation 19 --
20Nov23_072815|    -- Crossed 3 individual pairs.
20Nov23_072815|    -- Mutated 32 individuals.
20Nov23_073113|    -- Evaluated 64 individuals.
20Nov23_073113|    Summary of generation 19:
20Nov23_073113| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_073113|-----------  ------------------  --------------------  ----------
20Nov23_073113|    Max            42.26                30.00           0.34579
20Nov23_073113|    Avg            41.01                10.95           0.04231
20Nov23_073113|    Min            34.35                 6.00           0.00000
20Nov23_073113|    Std             1.44                 6.42           0.06507
20Nov23_073113|   Best            34.35                 8.00           0.34579
20Nov23_073113|-- Generation 20 --
20Nov23_073113|    -- Crossed 5 individual pairs.
20Nov23_073113|    -- Mutated 32 individuals.
20Nov23_073412|    -- Evaluated 64 individuals.
20Nov23_073412|    Summary of generation 20:
20Nov23_073412| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_073412|-----------  ------------------  --------------------  ----------
20Nov23_073412|    Max            42.26                28.00           0.21959
20Nov23_073412|    Avg            41.03                10.69           0.04645
20Nov23_073412|    Min            37.13                 6.00           0.00000
20Nov23_073412|    Std             1.14                 6.09           0.05591
20Nov23_073412|   Best            37.13                 9.00           0.21220
20Nov23_073412|-- Generation 21 --
20Nov23_073412|    -- Crossed 2 individual pairs.
20Nov23_073412|    -- Mutated 32 individuals.
20Nov23_073711|    -- Evaluated 64 individuals.
20Nov23_073711|    Summary of generation 21:
20Nov23_073711| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_073711|-----------  ------------------  --------------------  ----------
20Nov23_073711|    Max            42.35                28.00           0.23994
20Nov23_073711|    Avg            41.00                11.58           0.04149
20Nov23_073711|    Min            36.17                 7.00           0.00000
20Nov23_073711|    Std             1.08                 6.69           0.04469
20Nov23_073711|   Best            36.17                 9.00           0.23994
20Nov23_073711|-- Generation 22 --
20Nov23_073711|    -- Crossed 2 individual pairs.
20Nov23_073711|    -- Mutated 32 individuals.
20Nov23_074011|    -- Evaluated 64 individuals.
20Nov23_074011|    Summary of generation 22:
20Nov23_074011| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_074011|-----------  ------------------  --------------------  ----------
20Nov23_074011|    Max            55.30                28.00           0.79154
20Nov23_074011|    Avg            41.15                11.88           0.05635
20Nov23_074011|    Min            37.22                 7.00           0.00000
20Nov23_074011|    Std             2.08                 6.55           0.10496
20Nov23_074011|   Best            37.22                 8.00           0.16658
20Nov23_074011|-- Generation 23 --
20Nov23_074011|    -- Crossed 2 individual pairs.
20Nov23_074011|    -- Mutated 32 individuals.
20Nov23_074311|    -- Evaluated 64 individuals.
20Nov23_074311|    Summary of generation 23:
20Nov23_074311| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_074311|-----------  ------------------  --------------------  ----------
20Nov23_074311|    Max            42.17                28.00           0.62791
20Nov23_074311|    Avg            40.72                12.67           0.05295
20Nov23_074311|    Min            28.00                 8.00           0.00000
20Nov23_074311|    Std             1.91                 7.06           0.08497
20Nov23_074311|   Best            28.00                28.00           0.62791
20Nov23_074311|-- Generation 24 --
20Nov23_074311|    -- Crossed 3 individual pairs.
20Nov23_074311|    -- Mutated 32 individuals.
20Nov23_074610|    -- Evaluated 64 individuals.
20Nov23_074610|    Summary of generation 24:
20Nov23_074610| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_074610|-----------  ------------------  --------------------  ----------
20Nov23_074610|    Max            58.00                30.00           0.78358
20Nov23_074610|    Avg            41.17                12.03           0.05919
20Nov23_074610|    Min            37.48                 7.00           0.00000
20Nov23_074610|    Std             2.33                 6.77           0.10581
20Nov23_074610|   Best            37.48                10.00           0.21623
20Nov23_074610|-- Generation 25 --
20Nov23_074610|    -- Crossed 2 individual pairs.
20Nov23_074610|    -- Mutated 32 individuals.
20Nov23_074910|    -- Evaluated 64 individuals.
20Nov23_074910|    Summary of generation 25:
20Nov23_074910| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_074910|-----------  ------------------  --------------------  ----------
20Nov23_074910|    Max            58.00                32.00           0.78358
20Nov23_074910|    Avg            41.48                12.70           0.05041
20Nov23_074910|    Min            38.87                 7.00           0.00000
20Nov23_074910|    Std             2.25                 7.02           0.11499
20Nov23_074910|   Best            38.87                 9.00           0.15114
20Nov23_074910|-- Generation 26 --
20Nov23_074910|    -- Crossed 4 individual pairs.
20Nov23_074910|    -- Mutated 32 individuals.
20Nov23_075210|    -- Evaluated 64 individuals.
20Nov23_075210|    Summary of generation 26:
20Nov23_075210| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_075210|-----------  ------------------  --------------------  ----------
20Nov23_075210|    Max            42.26                32.00           0.55359
20Nov23_075210|    Avg            40.86                13.09           0.04459
20Nov23_075210|    Min            26.87                 7.00           0.00000
20Nov23_075210|    Std             2.04                 7.43           0.07589
20Nov23_075210|   Best            26.87                24.00           0.55359
20Nov23_075210|-- Generation 27 --
20Nov23_075210|    -- Crossed 3 individual pairs.
20Nov23_075210|    -- Mutated 32 individuals.
20Nov23_075509|    -- Evaluated 64 individuals.
20Nov23_075509|    Summary of generation 27:
20Nov23_075509| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_075509|-----------  ------------------  --------------------  ----------
20Nov23_075509|    Max            57.91                45.00           0.78384
20Nov23_075509|    Avg            41.06                11.84           0.06219
20Nov23_075509|    Min            36.09                 7.00           0.00000
20Nov23_075509|    Std             2.40                 7.67           0.10471
20Nov23_075509|   Best            36.09                 9.00           0.27247
20Nov23_075509|-- Generation 28 --
20Nov23_075509|    -- Crossed 2 individual pairs.
20Nov23_075509|    -- Mutated 32 individuals.
20Nov23_075808|    -- Evaluated 64 individuals.
20Nov23_075808|    Summary of generation 28:
20Nov23_075808| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_075808|-----------  ------------------  --------------------  ----------
20Nov23_075808|    Max            42.17                45.00           0.40308
20Nov23_075808|    Avg            40.90                12.05           0.04228
20Nov23_075808|    Min            30.52                 7.00           0.00000
20Nov23_075808|    Std             1.64                 8.24           0.06063
20Nov23_075808|   Best            30.52                22.00           0.40308
20Nov23_075808|-- Generation 29 --
20Nov23_075808|    -- Crossed 2 individual pairs.
20Nov23_075808|    -- Mutated 32 individuals.
20Nov23_080107|    -- Evaluated 64 individuals.
20Nov23_080107|    Summary of generation 29:
20Nov23_080107| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_080107|-----------  ------------------  --------------------  ----------
20Nov23_080107|    Max            42.43                26.00           0.17132
20Nov23_080107|    Avg            41.21                11.11           0.03237
20Nov23_080107|    Min            38.78                 7.00           0.00000
20Nov23_080107|    Std             0.87                 5.53           0.03565
20Nov23_080107|   Best            38.78                 8.00           0.12531
20Nov23_080107|-- Generation 30 --
20Nov23_080107|    -- Crossed 6 individual pairs.
20Nov23_080107|    -- Mutated 32 individuals.
20Nov23_080405|    -- Evaluated 64 individuals.
20Nov23_080405|    Summary of generation 30:
20Nov23_080405| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_080405|-----------  ------------------  --------------------  ----------
20Nov23_080405|    Max            42.26                28.00           0.41833
20Nov23_080405|    Avg            41.00                11.81           0.04769
20Nov23_080405|    Min            37.57                 7.00           0.00000
20Nov23_080405|    Std             1.13                 6.60           0.06931
20Nov23_080405|   Best            37.57                28.00           0.41833
20Nov23_080405|-- Generation 31 --
20Nov23_080405|    -- Crossed 4 individual pairs.
20Nov23_080405|    -- Mutated 32 individuals.
20Nov23_080704|    -- Evaluated 64 individuals.
20Nov23_080704|    Summary of generation 31:
20Nov23_080704| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_080704|-----------  ------------------  --------------------  ----------
20Nov23_080704|    Max            50.09                28.00           0.80174
20Nov23_080704|    Avg            41.45                11.75           0.03976
20Nov23_080704|    Min            38.87                 7.00           0.00000
20Nov23_080704|    Std             1.33                 6.48           0.10046
20Nov23_080704|   Best            38.87                 9.00           0.12525
20Nov23_080704|-- Generation 32 --
20Nov23_080704|    -- Crossed 4 individual pairs.
20Nov23_080704|    -- Mutated 32 individuals.
20Nov23_081002|    -- Evaluated 64 individuals.
20Nov23_081002|    Summary of generation 32:
20Nov23_081002| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_081002|-----------  ------------------  --------------------  ----------
20Nov23_081002|    Max            42.26                28.00           0.22384
20Nov23_081002|    Avg            40.80                 9.64           0.04755
20Nov23_081002|    Min            36.70                 7.00           0.00000
20Nov23_081002|    Std             1.05                 4.41           0.04410
20Nov23_081002|   Best            36.70                 9.00           0.22384
20Nov23_081002|Best initial individual weights
20Nov23_081002|Individual:
20Nov23_081002|-- Constant hidden layers --
20Nov23_081002|False
20Nov23_081002|Layer 0:
20Nov23_081002|-- Config --
20Nov23_081002|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 9, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_081002|-- Weights --
20Nov23_081002|[[-0.63367  0.60899  0.83478  0.61676 -0.06439 -0.03856  0.87931  0.23210
20Nov23_081002|   0.57222]
20Nov23_081002| [ 0.42757 -0.15503 -0.96393 -0.21209  0.67074 -0.67172  0.09578 -0.01354
20Nov23_081002|   0.72954]
20Nov23_081002| [ 0.04898 -0.00673  0.17120  0.56493 -0.58608 -0.54289 -0.37421  0.33799
20Nov23_081002|  -0.30967]
20Nov23_081002| [-0.46430  0.78038  0.13780  0.97398  0.52913  0.33901 -0.52290 -0.61772
20Nov23_081002|   0.24021]
20Nov23_081002| [ 0.12327 -0.70488 -0.76014  0.46230 -0.48127  0.82322 -0.31494  0.03241
20Nov23_081002|   0.49533]
20Nov23_081002| [ 0.97436  0.58423  0.99683  0.87738  0.85449 -0.97864 -0.19242 -0.96308
20Nov23_081002|   0.15186]
20Nov23_081002| [-0.18663 -0.03839  0.37421  0.43125 -0.65567 -0.54443  0.48221  0.50056
20Nov23_081002|   0.88804]
20Nov23_081002| [ 0.38628 -0.71562 -0.02938 -0.77467  0.21173 -0.76071 -0.88732 -0.15587
20Nov23_081002|   0.76494]
20Nov23_081002| [-0.38472 -0.59903  0.30665 -0.74574  0.41233 -0.63366  0.84576  0.32978
20Nov23_081002|   0.29585]
20Nov23_081002| [ 0.57070  0.56063 -0.89501 -0.85320 -0.31528  0.81901  0.12494 -0.14512
20Nov23_081002|  -0.92774]
20Nov23_081002| [ 0.82918 -0.85173 -0.39008  0.23042  0.25329  0.55465  0.61318  0.79739
20Nov23_081002|  -0.77286]
20Nov23_081002| [ 0.90788 -0.62072  0.45232  0.39527  0.99135  0.31159 -0.04526 -0.50254
20Nov23_081002|  -0.32571]
20Nov23_081002| [ 0.47116 -0.80083 -0.89583  0.98952  0.36247 -0.47563  0.01634 -0.36188
20Nov23_081002|   0.99426]
20Nov23_081002| [ 0.58858 -0.54473  0.55209 -0.15974 -0.24661  0.24669 -0.10177  0.14578
20Nov23_081002|   0.11571]
20Nov23_081002| [ 0.11867  0.62016 -0.64928  0.69595  0.14762 -0.06593  0.49901 -0.80999
20Nov23_081002|   0.52548]
20Nov23_081002| [-0.69219 -0.17982 -0.19685 -0.29362  0.33812  0.21100  0.99553  0.50109
20Nov23_081002|  -0.04925]
20Nov23_081002| [ 0.61097  0.51476  0.53894  0.84698  0.38783  0.74139 -0.35822 -0.53577
20Nov23_081002|   0.27103]
20Nov23_081002| [-0.68375 -0.63422 -0.75374  0.16935  0.04855 -0.05672  0.69986 -0.27338
20Nov23_081002|   0.12070]
20Nov23_081002| [-0.64028 -0.51337  0.24040 -0.54452 -0.73434  0.37600 -0.30737  0.73388
20Nov23_081002|  -0.04042]
20Nov23_081002| [-0.77943 -0.31107 -0.98230  0.10499  0.12940 -0.84321 -0.42268  0.20726
20Nov23_081002|  -0.51976]
20Nov23_081002| [-0.80528 -0.19414  0.54834 -0.11003  0.59831  0.88676  0.57665  0.31559
20Nov23_081002|  -0.10188]
20Nov23_081002| [ 0.79546 -0.52740  0.19041 -0.19539  0.47623 -0.25553  0.19885 -0.10556
20Nov23_081002|  -0.69681]
20Nov23_081002| [ 0.57052  0.79756  0.56161  0.93146 -0.74117  0.50695  0.15903 -0.41009
20Nov23_081002|  -0.16428]
20Nov23_081002| [-0.77229  0.69330 -0.40215 -0.47426  0.93548 -0.22966 -0.81762 -0.51327
20Nov23_081002|  -0.83020]
20Nov23_081002| [-0.94463  0.56285 -0.18322  0.18300 -0.12065 -0.81072 -0.58768 -0.72770
20Nov23_081002|   0.36181]
20Nov23_081002| [-0.97348 -0.06928 -0.36532 -0.55753  0.14899  0.64512  0.40089 -0.01556
20Nov23_081002|  -0.48643]
20Nov23_081002| [ 0.08118 -0.51725 -0.27229  0.03734 -0.58999 -0.64682 -0.66985 -0.60500
20Nov23_081002|   0.47307]
20Nov23_081002| [-0.25883  0.95471  0.60987  0.51637 -0.66250 -0.56608 -0.30401 -0.23517
20Nov23_081002|  -0.42718]
20Nov23_081002| [ 0.48792  0.06652  0.67243  0.00667  0.35448 -0.04048  0.58905 -0.02704
20Nov23_081002|   0.19498]
20Nov23_081002| [-0.79096 -0.51930 -0.03656  0.42585 -0.88535  0.16647  0.13731  0.28694
20Nov23_081002|  -0.08383]
20Nov23_081002| [ 0.39711 -0.43284  0.60892  0.99649 -0.29277  0.89252  0.59008 -0.37781
20Nov23_081002|  -0.06071]
20Nov23_081002| [-0.49985  0.30927  0.21075  0.00245 -0.97576  0.54582 -0.07441  0.73744
20Nov23_081002|   0.44039]
20Nov23_081002| [-0.82204 -0.65892 -0.25874  0.65191 -0.42156  0.55153  0.28415  0.75619
20Nov23_081002|  -0.25120]
20Nov23_081002| [ 0.62785  0.92643  0.88864 -0.62144 -0.52956  0.04732  0.06771 -0.03263
20Nov23_081002|   0.78723]
20Nov23_081002| [-0.12665 -0.26037  0.93929 -0.20912  0.29486 -0.49861  0.05801  0.84210
20Nov23_081002|   0.51400]
20Nov23_081002| [ 0.86076 -0.42897 -0.87468 -0.53512  0.24138 -0.50786 -0.15497  0.42607
20Nov23_081002|   0.39931]
20Nov23_081002| [ 0.32441  0.05842 -0.34047  0.17155  0.31975  0.64442 -0.38950 -0.39182
20Nov23_081002|  -0.68936]
20Nov23_081002| [ 0.78782  0.07348  0.37470  0.59208  0.86198 -0.77979  0.27003 -0.25122
20Nov23_081002|   0.86453]
20Nov23_081002| [ 0.42317 -0.23321 -0.08329  0.43578 -0.77095  0.35433  0.42400 -0.95621
20Nov23_081002|   0.77182]
20Nov23_081002| [ 0.03529  0.45907  0.24323  0.35646  0.25548  0.04363  0.01335 -0.63628
20Nov23_081002|  -0.19985]
20Nov23_081002| [ 0.32799 -0.83296  0.35950 -0.84384  0.53962  0.25459 -0.12801 -0.76436
20Nov23_081002|  -0.48185]
20Nov23_081002| [-0.08745 -0.11822  0.01838 -0.97565  0.13033 -0.43597 -0.41423 -0.83219
20Nov23_081002|  -0.78286]
20Nov23_081002| [ 0.29844 -0.54283 -0.17823 -0.45556 -0.88191 -0.41967  0.18376 -0.49025
20Nov23_081002|   0.07239]
20Nov23_081002| [-0.21571  0.12608 -0.31114  0.62868  0.16183 -0.73490 -0.17703 -0.07192
20Nov23_081002|   0.15025]
20Nov23_081002| [-0.50087 -0.73452 -0.13626  0.73205  0.30418 -0.42448  0.57710 -0.08745
20Nov23_081002|  -0.25801]
20Nov23_081002| [-0.87342  0.82576 -0.69582 -0.17711 -0.16518 -0.79400  0.41836 -0.21347
20Nov23_081002|   0.62229]
20Nov23_081002| [-0.65485 -0.63328  0.91173  0.37398  0.86622 -0.05576  0.91775  0.20205
20Nov23_081002|  -0.87244]
20Nov23_081002| [-0.48298 -0.90349  0.91474  0.81889 -0.88765  0.10896 -0.24813 -0.93639
20Nov23_081002|  -0.15084]
20Nov23_081002| [-0.52996  0.91352 -0.07315  0.04497  0.58982 -0.92839  0.96565 -0.89041
20Nov23_081002|  -0.13368]
20Nov23_081002| [ 0.26707  0.95749  0.24483 -0.14385  0.51138  0.86363  0.57777 -0.67682
20Nov23_081002|  -0.64631]
20Nov23_081002| [-0.60821  0.70122 -0.18029 -0.54173  0.76435 -0.98613  0.03815 -0.74684
20Nov23_081002|  -0.21303]
20Nov23_081002| [-0.48883  0.86690  0.46056 -0.85816 -0.72493 -0.39400 -0.60544  0.14551
20Nov23_081002|  -0.27068]
20Nov23_081002| [-0.21266 -0.45172  0.52545  0.76609 -0.38595 -0.91858 -0.95522  0.44471
20Nov23_081002|   0.48839]
20Nov23_081002| [-0.74062 -0.03407  0.23019  0.53575 -0.60671  0.83439 -0.49958 -0.52250
20Nov23_081002|  -0.67794]
20Nov23_081002| [-0.37698  0.58525 -0.49161  0.83360 -0.35719  0.04950 -0.81803 -0.12305
20Nov23_081002|   0.18390]
20Nov23_081002| [ 0.22933 -0.45123  0.80871 -0.80717 -0.95771  0.61468 -0.92624  0.91854
20Nov23_081002|   0.13431]
20Nov23_081002| [-0.78255 -0.43556 -0.27739  0.61573 -0.57572 -0.56878 -0.44643  0.71755
20Nov23_081002|  -0.96107]]
20Nov23_081002|-- Bias --
20Nov23_081002|[ 0.03656 -0.68570 -0.06830 -0.33777 -0.51449 -0.92500  0.54020 -0.67519
20Nov23_081002|  0.54064]
20Nov23_081002|Layer 1:
20Nov23_081002|-- Config --
20Nov23_081002|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 9], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_081002|-- Weights --
20Nov23_081002|[[-0.11760 -0.78969]
20Nov23_081002| [-0.80956  0.86375]
20Nov23_081002| [-0.55317  0.20123]
20Nov23_081002| [-0.18424  0.22796]
20Nov23_081002| [-0.23057 -0.34878]
20Nov23_081002| [ 0.16986  0.24701]
20Nov23_081002| [ 0.43056  0.26705]
20Nov23_081002| [ 0.44925  0.71010]
20Nov23_081002| [ 0.21361  0.98530]]
20Nov23_081002|-- Bias --
20Nov23_081002|[ 0.10992 -0.13281]
20Nov23_081002|Predicting the validation and test data with the Best initial individual.
20Nov23_081008| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_081008|-----------  ------------------  --------------------  ----------
20Nov23_081008|Validation         42.09                  9             0.00516
20Nov23_081008|   Test            35.19                  9             0.05875
20Nov23_081008|-------------------------- Test #0 --------------------------
20Nov23_081008|Best final individual weights
20Nov23_081008|Individual:
20Nov23_081008|-- Constant hidden layers --
20Nov23_081008|False
20Nov23_081008|Layer 0:
20Nov23_081008|-- Config --
20Nov23_081008|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 9, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_081008|-- Weights --
20Nov23_081008|[[ 0.17602  1.37005  0.94134  1.05414 -0.21995 -0.52384  1.64542 -0.30457
20Nov23_081008|   0.01296]
20Nov23_081008| [-1.00766  0.55531 -1.99234  0.25526  1.25030 -0.49747 -0.03963 -0.09871
20Nov23_081008|  -0.82622]
20Nov23_081008| [ 0.00435 -0.99825 -0.50688  0.37209 -1.65379 -0.48515 -0.08885  0.45705
20Nov23_081008|   0.37833]
20Nov23_081008| [-0.06184  0.76090  1.13704  1.50787  0.60159  0.44759 -1.32216 -1.49004
20Nov23_081008|  -0.31006]
20Nov23_081008| [ 0.15529 -1.20693 -0.59482  0.77745 -1.52902  1.47965 -0.18784  0.01618
20Nov23_081008|  -0.37143]
20Nov23_081008| [-0.74608  0.51489  0.44418  1.61057  1.02837 -0.39362 -1.59788 -1.41381
20Nov23_081008|  -0.46460]
20Nov23_081008| [-1.22317 -1.34170  0.81731  0.39239 -1.09585 -0.98934 -0.06814  0.95451
20Nov23_081008|   0.34325]
20Nov23_081008| [ 0.18246 -1.70586 -1.09053 -2.24079  1.80462 -0.74800 -1.48499 -0.16259
20Nov23_081008|   0.12309]
20Nov23_081008| [ 0.96105 -1.07518 -0.27790 -0.90632 -0.38456 -0.70881 -0.15062  0.71637
20Nov23_081008|   0.28111]
20Nov23_081008| [ 0.55264  1.68334 -2.12589 -1.32606 -0.58478  0.44290  0.14816 -0.88333
20Nov23_081008|   0.18307]
20Nov23_081008| [ 0.13988 -0.06929  0.19289 -0.32611  0.40154  0.59037 -0.19791  2.35651
20Nov23_081008|   0.17229]
20Nov23_081008| [ 0.30252 -0.30499  1.13260 -0.65187  0.67200  0.80110 -1.14151 -1.25115
20Nov23_081008|  -0.26380]
20Nov23_081008| [ 0.59178 -0.51172 -0.07961  0.79639  1.05492  0.01977 -0.15418 -0.03723
20Nov23_081008|  -0.35638]
20Nov23_081008| [ 0.13793 -0.25043  0.84681  1.03833 -0.43156  0.03462  0.75354 -0.59958
20Nov23_081008|  -0.45743]
20Nov23_081008| [-1.13800  0.66296 -0.55458  0.97392  0.70267 -0.01965 -0.21929 -0.24260
20Nov23_081008|  -0.05331]
20Nov23_081008| [-2.28186 -0.69856 -0.10021 -0.56269  0.03000 -0.45043  0.16882 -0.65293
20Nov23_081008|  -0.27847]
20Nov23_081008| [ 1.79644  1.28884  0.01848  1.38631  1.80935 -0.08050  0.45143 -0.96041
20Nov23_081008|  -0.12371]
20Nov23_081008| [-0.15386 -0.99409 -1.24233 -0.21473 -0.82358 -0.50121  0.06181 -0.86836
20Nov23_081008|   0.07519]
20Nov23_081008| [-0.73128 -0.17146 -0.58581 -0.82587 -1.27548 -0.17385  0.99249  0.11953
20Nov23_081008|  -0.68291]
20Nov23_081008| [-0.76081 -1.42621 -0.45821  0.05531 -0.23330 -0.74949  0.67051  0.32599
20Nov23_081008|  -0.05493]
20Nov23_081008| [-0.29383 -0.96288 -0.35742 -0.56094  0.45025  2.05842  1.07941  0.36440
20Nov23_081008|  -0.04810]
20Nov23_081008| [ 0.16564 -2.39074  1.24141  0.48639 -0.33374  0.61272  1.00614 -0.45470
20Nov23_081008|  -0.06425]
20Nov23_081008| [ 0.05723  1.47602  0.25261  0.41500 -1.05226  0.39387  1.28792 -0.81318
20Nov23_081008|  -0.63875]
20Nov23_081008| [-1.93770  1.50868  0.70201 -1.00910 -0.43689 -1.09291 -0.95173 -2.17974
20Nov23_081008|  -0.40959]
20Nov23_081008| [-1.34704 -0.06302  0.03764  0.27825  0.39591 -0.36483  0.00780 -0.09740
20Nov23_081008|   0.12410]
20Nov23_081008| [-0.74172 -0.16476 -0.61182  0.16789 -0.92203  1.07919  1.19033 -0.36009
20Nov23_081008|  -0.09485]
20Nov23_081008| [ 0.07440  0.36258 -0.18559  0.15582 -0.03425 -0.76748 -0.29371  0.48534
20Nov23_081008|  -0.77123]
20Nov23_081008| [ 0.23529  1.44463  0.89996  0.74943  0.33310 -0.70402  0.64131  0.80355
20Nov23_081008|  -0.07107]
20Nov23_081008| [ 0.91938  0.71058  0.22984 -0.16823 -0.13721  0.86600  0.44650 -0.13527
20Nov23_081008|  -0.38005]
20Nov23_081008| [-0.39765  0.03921 -0.03567  1.00847 -1.22486  0.79469  0.13971  0.28072
20Nov23_081008|  -0.71548]
20Nov23_081008| [-0.64580 -0.15922 -0.29468  0.58904 -0.15741  0.62625  1.90757 -0.29279
20Nov23_081008|   0.32812]
20Nov23_081008| [-0.38675 -0.71577  0.42643 -0.76070 -1.53681  0.05780 -0.06157  0.39549
20Nov23_081008|  -0.21361]
20Nov23_081008| [-1.61786  0.04702 -0.94962  1.39037 -0.53169  0.85972  0.89185 -0.34408
20Nov23_081008|  -0.73590]
20Nov23_081008| [ 0.98571  0.77837  1.07569 -0.35187 -1.37874 -0.14937  0.22572 -0.82999
20Nov23_081008|   0.44736]
20Nov23_081008| [-1.21003 -1.45838  1.02095  0.61951 -0.22765 -1.21435 -0.22443  0.92740
20Nov23_081008|  -0.77073]
20Nov23_081008| [ 0.59707 -0.56453 -0.65358 -2.34672 -0.32341  0.16786 -1.05250  0.29119
20Nov23_081008|  -0.15825]
20Nov23_081008| [ 1.88803  0.48220 -0.31526  0.39790 -0.28680  0.67641  0.65311 -0.46018
20Nov23_081008|  -0.78346]
20Nov23_081008| [ 1.53749  0.76150 -0.06152  0.94539  1.37221 -1.25450  0.55485  0.75678
20Nov23_081008|   0.28596]
20Nov23_081008| [-0.69501 -0.66292 -0.70443 -0.23586 -1.84727  0.50000  0.72449 -0.29577
20Nov23_081008|  -0.01265]
20Nov23_081008| [ 0.42279  0.38086  0.19830  0.96482 -0.26064  0.21820 -1.36254 -1.67737
20Nov23_081008|   0.09949]
20Nov23_081008| [-0.89380 -0.66418  0.66312 -0.34192  0.52278 -0.76123  0.17047 -2.11020
20Nov23_081008|   0.53196]
20Nov23_081008| [ 0.15779 -0.69696  1.32238 -0.74687 -1.52683 -0.33643 -1.23399 -0.94856
20Nov23_081008|   0.09857]
20Nov23_081008| [ 1.05131 -0.67318 -1.24615 -0.87618 -1.49284 -0.06874  1.07900 -1.14795
20Nov23_081008|   0.17446]
20Nov23_081008| [-0.65091  0.36390  0.43736 -0.20295  0.73984 -1.82535  1.54797 -0.54226
20Nov23_081008|  -0.45832]
20Nov23_081008| [-1.47230 -1.01292 -1.22577  0.13909 -0.22777 -0.64598  0.63506  0.16394
20Nov23_081008|  -0.77675]
20Nov23_081008| [-0.81090  0.15932 -0.32886  0.65237 -0.90740 -1.49863  0.52335  0.66660
20Nov23_081008|  -0.35570]
20Nov23_081008| [-0.38692 -1.11881  1.10759 -0.22649  0.73540 -0.46981  1.45865 -0.85465
20Nov23_081008|   0.06884]
20Nov23_081008| [-0.70397 -0.48164  1.26245  2.11535 -1.40169 -0.46342 -1.17306 -1.46933
20Nov23_081008|  -0.49080]
20Nov23_081008| [-1.10460  1.43416 -0.48554  1.51377  0.64254 -1.76552  1.65956 -0.50608
20Nov23_081008|  -0.54698]
20Nov23_081008| [-0.31011  1.98690  0.38783  0.35508  0.03083  1.34938  1.53292 -0.53171
20Nov23_081008|   0.12150]
20Nov23_081008| [ 0.36149 -0.26401 -0.01935  0.42299  1.37095 -1.27051 -0.18245  0.31588
20Nov23_081008|  -0.29268]
20Nov23_081008| [-1.06074  1.99965  0.69902 -0.86402 -1.29065 -2.35002 -1.28412 -0.72877
20Nov23_081008|  -0.41804]
20Nov23_081008| [-0.84514  0.53515  1.45650  1.07456 -0.31276 -1.39673 -0.46390 -0.11888
20Nov23_081008|  -0.62786]
20Nov23_081008| [-0.68851  1.03186 -0.46824  0.65608 -2.15624  0.15132 -0.07458 -0.29261
20Nov23_081008|   0.83517]
20Nov23_081008| [ 0.33518 -0.03880 -0.91495  0.27963 -1.52199  0.44892 -0.59121 -0.83967
20Nov23_081008|  -0.89924]
20Nov23_081008| [ 1.32436 -0.23291  2.16960 -0.32631 -0.78017  0.23003 -0.45617  2.55819
20Nov23_081008|   0.34619]
20Nov23_081008| [ 0.94408 -0.05989 -0.56402  0.71193 -0.81660 -0.55225 -0.29669  0.64528
20Nov23_081008|   0.32030]]
20Nov23_081008|-- Bias --
20Nov23_081008|[ 0.07637 -0.83169 -0.11893 -0.05433  0.08749 -1.35431  0.38599 -0.57607
20Nov23_081008| -0.06108]
20Nov23_081008|Layer 1:
20Nov23_081008|-- Config --
20Nov23_081008|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 9], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_081008|-- Weights --
20Nov23_081008|[[ 0.70918 -0.98308]
20Nov23_081008| [-0.29153 -0.01013]
20Nov23_081008| [-1.87688 -0.30242]
20Nov23_081008| [-0.40156  0.63724]
20Nov23_081008| [-0.19569  0.07574]
20Nov23_081008| [ 0.27194  0.47916]
20Nov23_081008| [-0.77374 -0.16853]
20Nov23_081008| [ 0.70173  2.03695]
20Nov23_081008| [-0.37282  0.05925]]
20Nov23_081008|-- Bias --
20Nov23_081008|[-0.02520 -0.26371]
20Nov23_081008|Predicting the validation and test data with the Best final individual.
20Nov23_081013| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_081013|-----------  ------------------  --------------------  ----------
20Nov23_081013|Validation         40.96                  9             0.03593
20Nov23_081013|   Test            63.51                  9             0.74133
20Nov23_081013|-------------------------- Test #1 --------------------------
20Nov23_081013|Best final individual weights
20Nov23_081013|Individual:
20Nov23_081013|-- Constant hidden layers --
20Nov23_081013|False
20Nov23_081013|Layer 0:
20Nov23_081013|-- Config --
20Nov23_081013|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 9, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_081013|-- Weights --
20Nov23_081013|[[ 0.17602  1.37005  0.94134  1.05414 -0.21995 -0.52384  1.64542 -0.30457
20Nov23_081013|   0.01296]
20Nov23_081013| [-1.00766  0.55531 -1.99234  0.25526  1.25030 -0.49747 -0.03963 -0.09871
20Nov23_081013|  -0.82622]
20Nov23_081013| [ 0.00435 -0.99825 -0.50688  0.37209 -1.65379 -0.48515 -0.08885  0.45705
20Nov23_081013|   0.37833]
20Nov23_081013| [-0.06184  0.76090  1.13704  1.50787  0.60159  0.44759 -1.32216 -1.49004
20Nov23_081013|  -0.31006]
20Nov23_081013| [ 0.15529 -1.20693 -0.59482  0.77745 -1.52902  1.47965 -0.18784  0.01618
20Nov23_081013|  -0.37143]
20Nov23_081013| [-0.74608  0.51489  0.44418  1.61057  1.02837 -0.39362 -1.59788 -1.41381
20Nov23_081013|  -0.46460]
20Nov23_081013| [-1.22317 -1.34170  0.81731  0.39239 -1.09585 -0.98934 -0.06814  0.95451
20Nov23_081013|   0.34325]
20Nov23_081013| [ 0.18246 -1.70586 -1.09053 -2.24079  1.80462 -0.74800 -1.48499 -0.16259
20Nov23_081013|   0.12309]
20Nov23_081013| [ 0.96105 -1.07518 -0.27790 -0.90632 -0.38456 -0.70881 -0.15062  0.71637
20Nov23_081013|   0.28111]
20Nov23_081013| [ 0.55264  1.68334 -2.12589 -1.32606 -0.58478  0.44290  0.14816 -0.88333
20Nov23_081013|   0.18307]
20Nov23_081013| [ 0.13988 -0.06929  0.19289 -0.32611  0.40154  0.59037 -0.19791  2.35651
20Nov23_081013|   0.17229]
20Nov23_081013| [ 0.30252 -0.30499  1.13260 -0.65187  0.67200  0.80110 -1.14151 -1.25115
20Nov23_081013|  -0.26380]
20Nov23_081013| [ 0.59178 -0.51172 -0.07961  0.79639  1.05492  0.01977 -0.15418 -0.03723
20Nov23_081013|  -0.35638]
20Nov23_081013| [ 0.13793 -0.25043  0.84681  1.03833 -0.43156  0.03462  0.75354 -0.59958
20Nov23_081013|  -0.45743]
20Nov23_081013| [-1.13800  0.66296 -0.55458  0.97392  0.70267 -0.01965 -0.21929 -0.24260
20Nov23_081013|  -0.05331]
20Nov23_081013| [-2.28186 -0.69856 -0.10021 -0.56269  0.03000 -0.45043  0.16882 -0.65293
20Nov23_081013|  -0.27847]
20Nov23_081013| [ 1.79644  1.28884  0.01848  1.38631  1.80935 -0.08050  0.45143 -0.96041
20Nov23_081013|  -0.12371]
20Nov23_081013| [-0.15386 -0.99409 -1.24233 -0.21473 -0.82358 -0.50121  0.06181 -0.86836
20Nov23_081013|   0.07519]
20Nov23_081013| [-0.73128 -0.17146 -0.58581 -0.82587 -1.27548 -0.17385  0.99249  0.11953
20Nov23_081013|  -0.68291]
20Nov23_081013| [-0.76081 -1.42621 -0.45821  0.05531 -0.23330 -0.74949  0.67051  0.32599
20Nov23_081013|  -0.05493]
20Nov23_081013| [-0.29383 -0.96288 -0.35742 -0.56094  0.45025  2.05842  1.07941  0.36440
20Nov23_081013|  -0.04810]
20Nov23_081013| [ 0.16564 -2.39074  1.24141  0.48639 -0.33374  0.61272  1.00614 -0.45470
20Nov23_081013|  -0.06425]
20Nov23_081013| [ 0.05723  1.47602  0.25261  0.41500 -1.05226  0.39387  1.28792 -0.81318
20Nov23_081013|  -0.63875]
20Nov23_081013| [-1.93770  1.50868  0.70201 -1.00910 -0.43689 -1.09291 -0.95173 -2.17974
20Nov23_081013|  -0.40959]
20Nov23_081013| [-1.34704 -0.06302  0.03764  0.27825  0.39591 -0.36483  0.00780 -0.09740
20Nov23_081013|   0.12410]
20Nov23_081013| [-0.74172 -0.16476 -0.61182  0.16789 -0.92203  1.07919  1.19033 -0.36009
20Nov23_081013|  -0.09485]
20Nov23_081013| [ 0.07440  0.36258 -0.18559  0.15582 -0.03425 -0.76748 -0.29371  0.48534
20Nov23_081013|  -0.77123]
20Nov23_081013| [ 0.23529  1.44463  0.89996  0.74943  0.33310 -0.70402  0.64131  0.80355
20Nov23_081013|  -0.07107]
20Nov23_081013| [ 0.91938  0.71058  0.22984 -0.16823 -0.13721  0.86600  0.44650 -0.13527
20Nov23_081013|  -0.38005]
20Nov23_081013| [-0.39765  0.03921 -0.03567  1.00847 -1.22486  0.79469  0.13971  0.28072
20Nov23_081013|  -0.71548]
20Nov23_081013| [-0.64580 -0.15922 -0.29468  0.58904 -0.15741  0.62625  1.90757 -0.29279
20Nov23_081013|   0.32812]
20Nov23_081013| [-0.38675 -0.71577  0.42643 -0.76070 -1.53681  0.05780 -0.06157  0.39549
20Nov23_081013|  -0.21361]
20Nov23_081013| [-1.61786  0.04702 -0.94962  1.39037 -0.53169  0.85972  0.89185 -0.34408
20Nov23_081013|  -0.73590]
20Nov23_081013| [ 0.98571  0.77837  1.07569 -0.35187 -1.37874 -0.14937  0.22572 -0.82999
20Nov23_081013|   0.44736]
20Nov23_081013| [-1.21003 -1.45838  1.02095  0.61951 -0.22765 -1.21435 -0.22443  0.92740
20Nov23_081013|  -0.77073]
20Nov23_081013| [ 0.59707 -0.56453 -0.65358 -2.34672 -0.32341  0.16786 -1.05250  0.29119
20Nov23_081013|  -0.15825]
20Nov23_081013| [ 1.88803  0.48220 -0.31526  0.39790 -0.28680  0.67641  0.65311 -0.46018
20Nov23_081013|  -0.78346]
20Nov23_081013| [ 1.53749  0.76150 -0.06152  0.94539  1.37221 -1.25450  0.55485  0.75678
20Nov23_081013|   0.28596]
20Nov23_081013| [-0.69501 -0.66292 -0.70443 -0.23586 -1.84727  0.50000  0.72449 -0.29577
20Nov23_081013|  -0.01265]
20Nov23_081013| [ 0.42279  0.38086  0.19830  0.96482 -0.26064  0.21820 -1.36254 -1.67737
20Nov23_081013|   0.09949]
20Nov23_081013| [-0.89380 -0.66418  0.66312 -0.34192  0.52278 -0.76123  0.17047 -2.11020
20Nov23_081013|   0.53196]
20Nov23_081013| [ 0.15779 -0.69696  1.32238 -0.74687 -1.52683 -0.33643 -1.23399 -0.94856
20Nov23_081013|   0.09857]
20Nov23_081013| [ 1.05131 -0.67318 -1.24615 -0.87618 -1.49284 -0.06874  1.07900 -1.14795
20Nov23_081013|   0.17446]
20Nov23_081013| [-0.65091  0.36390  0.43736 -0.20295  0.73984 -1.82535  1.54797 -0.54226
20Nov23_081013|  -0.45832]
20Nov23_081013| [-1.47230 -1.01292 -1.22577  0.13909 -0.22777 -0.64598  0.63506  0.16394
20Nov23_081013|  -0.77675]
20Nov23_081013| [-0.81090  0.15932 -0.32886  0.65237 -0.90740 -1.49863  0.52335  0.66660
20Nov23_081013|  -0.35570]
20Nov23_081013| [-0.38692 -1.11881  1.10759 -0.22649  0.73540 -0.46981  1.45865 -0.85465
20Nov23_081013|   0.06884]
20Nov23_081013| [-0.70397 -0.48164  1.26245  2.11535 -1.40169 -0.46342 -1.17306 -1.46933
20Nov23_081013|  -0.49080]
20Nov23_081013| [-1.10460  1.43416 -0.48554  1.51377  0.64254 -1.76552  1.65956 -0.50608
20Nov23_081013|  -0.54698]
20Nov23_081013| [-0.31011  1.98690  0.38783  0.35508  0.03083  1.34938  1.53292 -0.53171
20Nov23_081013|   0.12150]
20Nov23_081013| [ 0.36149 -0.26401 -0.01935  0.42299  1.37095 -1.27051 -0.18245  0.31588
20Nov23_081013|  -0.29268]
20Nov23_081013| [-1.06074  1.99965  0.69902 -0.86402 -1.29065 -2.35002 -1.28412 -0.72877
20Nov23_081013|  -0.41804]
20Nov23_081013| [-0.84514  0.53515  1.45650  1.07456 -0.31276 -1.39673 -0.46390 -0.11888
20Nov23_081013|  -0.62786]
20Nov23_081013| [-0.68851  1.03186 -0.46824  0.65608 -2.15624  0.15132 -0.07458 -0.29261
20Nov23_081013|   0.83517]
20Nov23_081013| [ 0.33518 -0.03880 -0.91495  0.27963 -1.52199  0.44892 -0.59121 -0.83967
20Nov23_081013|  -0.89924]
20Nov23_081013| [ 1.32436 -0.23291  2.16960 -0.32631 -0.78017  0.23003 -0.45617  2.55819
20Nov23_081013|   0.34619]
20Nov23_081013| [ 0.94408 -0.05989 -0.56402  0.71193 -0.81660 -0.55225 -0.29669  0.64528
20Nov23_081013|   0.32030]]
20Nov23_081013|-- Bias --
20Nov23_081013|[ 0.07637 -0.83169 -0.11893 -0.05433  0.08749 -1.35431  0.38599 -0.57607
20Nov23_081013| -0.06108]
20Nov23_081013|Layer 1:
20Nov23_081013|-- Config --
20Nov23_081013|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 9], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_081013|-- Weights --
20Nov23_081013|[[ 0.70918 -0.98308]
20Nov23_081013| [-0.29153 -0.01013]
20Nov23_081013| [-1.87688 -0.30242]
20Nov23_081013| [-0.40156  0.63724]
20Nov23_081013| [-0.19569  0.07574]
20Nov23_081013| [ 0.27194  0.47916]
20Nov23_081013| [-0.77374 -0.16853]
20Nov23_081013| [ 0.70173  2.03695]
20Nov23_081013| [-0.37282  0.05925]]
20Nov23_081013|-- Bias --
20Nov23_081013|[-0.02520 -0.26371]
20Nov23_081013|Predicting the validation and test data with the Best final individual.
20Nov23_081019| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_081019|-----------  ------------------  --------------------  ----------
20Nov23_081019|Validation         39.13                  9             0.08643
20Nov23_081019|   Test            36.40                  9             0.00298
20Nov23_081019|-------------------------- Test #2 --------------------------
20Nov23_081019|Best final individual weights
20Nov23_081019|Individual:
20Nov23_081019|-- Constant hidden layers --
20Nov23_081019|False
20Nov23_081019|Layer 0:
20Nov23_081019|-- Config --
20Nov23_081019|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 9, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_081019|-- Weights --
20Nov23_081019|[[ 0.17602  1.37005  0.94134  1.05414 -0.21995 -0.52384  1.64542 -0.30457
20Nov23_081019|   0.01296]
20Nov23_081019| [-1.00766  0.55531 -1.99234  0.25526  1.25030 -0.49747 -0.03963 -0.09871
20Nov23_081019|  -0.82622]
20Nov23_081019| [ 0.00435 -0.99825 -0.50688  0.37209 -1.65379 -0.48515 -0.08885  0.45705
20Nov23_081019|   0.37833]
20Nov23_081019| [-0.06184  0.76090  1.13704  1.50787  0.60159  0.44759 -1.32216 -1.49004
20Nov23_081019|  -0.31006]
20Nov23_081019| [ 0.15529 -1.20693 -0.59482  0.77745 -1.52902  1.47965 -0.18784  0.01618
20Nov23_081019|  -0.37143]
20Nov23_081019| [-0.74608  0.51489  0.44418  1.61057  1.02837 -0.39362 -1.59788 -1.41381
20Nov23_081019|  -0.46460]
20Nov23_081019| [-1.22317 -1.34170  0.81731  0.39239 -1.09585 -0.98934 -0.06814  0.95451
20Nov23_081019|   0.34325]
20Nov23_081019| [ 0.18246 -1.70586 -1.09053 -2.24079  1.80462 -0.74800 -1.48499 -0.16259
20Nov23_081019|   0.12309]
20Nov23_081019| [ 0.96105 -1.07518 -0.27790 -0.90632 -0.38456 -0.70881 -0.15062  0.71637
20Nov23_081019|   0.28111]
20Nov23_081019| [ 0.55264  1.68334 -2.12589 -1.32606 -0.58478  0.44290  0.14816 -0.88333
20Nov23_081019|   0.18307]
20Nov23_081019| [ 0.13988 -0.06929  0.19289 -0.32611  0.40154  0.59037 -0.19791  2.35651
20Nov23_081019|   0.17229]
20Nov23_081019| [ 0.30252 -0.30499  1.13260 -0.65187  0.67200  0.80110 -1.14151 -1.25115
20Nov23_081019|  -0.26380]
20Nov23_081019| [ 0.59178 -0.51172 -0.07961  0.79639  1.05492  0.01977 -0.15418 -0.03723
20Nov23_081019|  -0.35638]
20Nov23_081019| [ 0.13793 -0.25043  0.84681  1.03833 -0.43156  0.03462  0.75354 -0.59958
20Nov23_081019|  -0.45743]
20Nov23_081019| [-1.13800  0.66296 -0.55458  0.97392  0.70267 -0.01965 -0.21929 -0.24260
20Nov23_081019|  -0.05331]
20Nov23_081019| [-2.28186 -0.69856 -0.10021 -0.56269  0.03000 -0.45043  0.16882 -0.65293
20Nov23_081019|  -0.27847]
20Nov23_081019| [ 1.79644  1.28884  0.01848  1.38631  1.80935 -0.08050  0.45143 -0.96041
20Nov23_081019|  -0.12371]
20Nov23_081019| [-0.15386 -0.99409 -1.24233 -0.21473 -0.82358 -0.50121  0.06181 -0.86836
20Nov23_081019|   0.07519]
20Nov23_081019| [-0.73128 -0.17146 -0.58581 -0.82587 -1.27548 -0.17385  0.99249  0.11953
20Nov23_081019|  -0.68291]
20Nov23_081019| [-0.76081 -1.42621 -0.45821  0.05531 -0.23330 -0.74949  0.67051  0.32599
20Nov23_081019|  -0.05493]
20Nov23_081019| [-0.29383 -0.96288 -0.35742 -0.56094  0.45025  2.05842  1.07941  0.36440
20Nov23_081019|  -0.04810]
20Nov23_081019| [ 0.16564 -2.39074  1.24141  0.48639 -0.33374  0.61272  1.00614 -0.45470
20Nov23_081019|  -0.06425]
20Nov23_081019| [ 0.05723  1.47602  0.25261  0.41500 -1.05226  0.39387  1.28792 -0.81318
20Nov23_081019|  -0.63875]
20Nov23_081019| [-1.93770  1.50868  0.70201 -1.00910 -0.43689 -1.09291 -0.95173 -2.17974
20Nov23_081019|  -0.40959]
20Nov23_081019| [-1.34704 -0.06302  0.03764  0.27825  0.39591 -0.36483  0.00780 -0.09740
20Nov23_081019|   0.12410]
20Nov23_081019| [-0.74172 -0.16476 -0.61182  0.16789 -0.92203  1.07919  1.19033 -0.36009
20Nov23_081019|  -0.09485]
20Nov23_081019| [ 0.07440  0.36258 -0.18559  0.15582 -0.03425 -0.76748 -0.29371  0.48534
20Nov23_081019|  -0.77123]
20Nov23_081019| [ 0.23529  1.44463  0.89996  0.74943  0.33310 -0.70402  0.64131  0.80355
20Nov23_081019|  -0.07107]
20Nov23_081019| [ 0.91938  0.71058  0.22984 -0.16823 -0.13721  0.86600  0.44650 -0.13527
20Nov23_081019|  -0.38005]
20Nov23_081019| [-0.39765  0.03921 -0.03567  1.00847 -1.22486  0.79469  0.13971  0.28072
20Nov23_081019|  -0.71548]
20Nov23_081019| [-0.64580 -0.15922 -0.29468  0.58904 -0.15741  0.62625  1.90757 -0.29279
20Nov23_081019|   0.32812]
20Nov23_081019| [-0.38675 -0.71577  0.42643 -0.76070 -1.53681  0.05780 -0.06157  0.39549
20Nov23_081019|  -0.21361]
20Nov23_081019| [-1.61786  0.04702 -0.94962  1.39037 -0.53169  0.85972  0.89185 -0.34408
20Nov23_081019|  -0.73590]
20Nov23_081019| [ 0.98571  0.77837  1.07569 -0.35187 -1.37874 -0.14937  0.22572 -0.82999
20Nov23_081019|   0.44736]
20Nov23_081019| [-1.21003 -1.45838  1.02095  0.61951 -0.22765 -1.21435 -0.22443  0.92740
20Nov23_081019|  -0.77073]
20Nov23_081019| [ 0.59707 -0.56453 -0.65358 -2.34672 -0.32341  0.16786 -1.05250  0.29119
20Nov23_081019|  -0.15825]
20Nov23_081019| [ 1.88803  0.48220 -0.31526  0.39790 -0.28680  0.67641  0.65311 -0.46018
20Nov23_081019|  -0.78346]
20Nov23_081019| [ 1.53749  0.76150 -0.06152  0.94539  1.37221 -1.25450  0.55485  0.75678
20Nov23_081019|   0.28596]
20Nov23_081019| [-0.69501 -0.66292 -0.70443 -0.23586 -1.84727  0.50000  0.72449 -0.29577
20Nov23_081019|  -0.01265]
20Nov23_081019| [ 0.42279  0.38086  0.19830  0.96482 -0.26064  0.21820 -1.36254 -1.67737
20Nov23_081019|   0.09949]
20Nov23_081019| [-0.89380 -0.66418  0.66312 -0.34192  0.52278 -0.76123  0.17047 -2.11020
20Nov23_081019|   0.53196]
20Nov23_081019| [ 0.15779 -0.69696  1.32238 -0.74687 -1.52683 -0.33643 -1.23399 -0.94856
20Nov23_081019|   0.09857]
20Nov23_081019| [ 1.05131 -0.67318 -1.24615 -0.87618 -1.49284 -0.06874  1.07900 -1.14795
20Nov23_081019|   0.17446]
20Nov23_081019| [-0.65091  0.36390  0.43736 -0.20295  0.73984 -1.82535  1.54797 -0.54226
20Nov23_081019|  -0.45832]
20Nov23_081019| [-1.47230 -1.01292 -1.22577  0.13909 -0.22777 -0.64598  0.63506  0.16394
20Nov23_081019|  -0.77675]
20Nov23_081019| [-0.81090  0.15932 -0.32886  0.65237 -0.90740 -1.49863  0.52335  0.66660
20Nov23_081019|  -0.35570]
20Nov23_081019| [-0.38692 -1.11881  1.10759 -0.22649  0.73540 -0.46981  1.45865 -0.85465
20Nov23_081019|   0.06884]
20Nov23_081019| [-0.70397 -0.48164  1.26245  2.11535 -1.40169 -0.46342 -1.17306 -1.46933
20Nov23_081019|  -0.49080]
20Nov23_081019| [-1.10460  1.43416 -0.48554  1.51377  0.64254 -1.76552  1.65956 -0.50608
20Nov23_081019|  -0.54698]
20Nov23_081019| [-0.31011  1.98690  0.38783  0.35508  0.03083  1.34938  1.53292 -0.53171
20Nov23_081019|   0.12150]
20Nov23_081019| [ 0.36149 -0.26401 -0.01935  0.42299  1.37095 -1.27051 -0.18245  0.31588
20Nov23_081019|  -0.29268]
20Nov23_081019| [-1.06074  1.99965  0.69902 -0.86402 -1.29065 -2.35002 -1.28412 -0.72877
20Nov23_081019|  -0.41804]
20Nov23_081019| [-0.84514  0.53515  1.45650  1.07456 -0.31276 -1.39673 -0.46390 -0.11888
20Nov23_081019|  -0.62786]
20Nov23_081019| [-0.68851  1.03186 -0.46824  0.65608 -2.15624  0.15132 -0.07458 -0.29261
20Nov23_081019|   0.83517]
20Nov23_081019| [ 0.33518 -0.03880 -0.91495  0.27963 -1.52199  0.44892 -0.59121 -0.83967
20Nov23_081019|  -0.89924]
20Nov23_081019| [ 1.32436 -0.23291  2.16960 -0.32631 -0.78017  0.23003 -0.45617  2.55819
20Nov23_081019|   0.34619]
20Nov23_081019| [ 0.94408 -0.05989 -0.56402  0.71193 -0.81660 -0.55225 -0.29669  0.64528
20Nov23_081019|   0.32030]]
20Nov23_081019|-- Bias --
20Nov23_081019|[ 0.07637 -0.83169 -0.11893 -0.05433  0.08749 -1.35431  0.38599 -0.57607
20Nov23_081019| -0.06108]
20Nov23_081019|Layer 1:
20Nov23_081019|-- Config --
20Nov23_081019|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 9], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_081019|-- Weights --
20Nov23_081019|[[ 0.70918 -0.98308]
20Nov23_081019| [-0.29153 -0.01013]
20Nov23_081019| [-1.87688 -0.30242]
20Nov23_081019| [-0.40156  0.63724]
20Nov23_081019| [-0.19569  0.07574]
20Nov23_081019| [ 0.27194  0.47916]
20Nov23_081019| [-0.77374 -0.16853]
20Nov23_081019| [ 0.70173  2.03695]
20Nov23_081019| [-0.37282  0.05925]]
20Nov23_081019|-- Bias --
20Nov23_081019|[-0.02520 -0.26371]
20Nov23_081019|Predicting the validation and test data with the Best final individual.
20Nov23_081024| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_081024|-----------  ------------------  --------------------  ----------
20Nov23_081024|Validation         41.13                  9             0.03337
20Nov23_081024|   Test            32.15                  9             0.21617
20Nov23_081024|-------------------------- Test #3 --------------------------
20Nov23_081024|Best final individual weights
20Nov23_081024|Individual:
20Nov23_081024|-- Constant hidden layers --
20Nov23_081024|False
20Nov23_081024|Layer 0:
20Nov23_081024|-- Config --
20Nov23_081024|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 9, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_081024|-- Weights --
20Nov23_081024|[[ 0.17602  1.37005  0.94134  1.05414 -0.21995 -0.52384  1.64542 -0.30457
20Nov23_081024|   0.01296]
20Nov23_081024| [-1.00766  0.55531 -1.99234  0.25526  1.25030 -0.49747 -0.03963 -0.09871
20Nov23_081024|  -0.82622]
20Nov23_081024| [ 0.00435 -0.99825 -0.50688  0.37209 -1.65379 -0.48515 -0.08885  0.45705
20Nov23_081024|   0.37833]
20Nov23_081024| [-0.06184  0.76090  1.13704  1.50787  0.60159  0.44759 -1.32216 -1.49004
20Nov23_081024|  -0.31006]
20Nov23_081024| [ 0.15529 -1.20693 -0.59482  0.77745 -1.52902  1.47965 -0.18784  0.01618
20Nov23_081024|  -0.37143]
20Nov23_081024| [-0.74608  0.51489  0.44418  1.61057  1.02837 -0.39362 -1.59788 -1.41381
20Nov23_081024|  -0.46460]
20Nov23_081024| [-1.22317 -1.34170  0.81731  0.39239 -1.09585 -0.98934 -0.06814  0.95451
20Nov23_081024|   0.34325]
20Nov23_081024| [ 0.18246 -1.70586 -1.09053 -2.24079  1.80462 -0.74800 -1.48499 -0.16259
20Nov23_081024|   0.12309]
20Nov23_081024| [ 0.96105 -1.07518 -0.27790 -0.90632 -0.38456 -0.70881 -0.15062  0.71637
20Nov23_081024|   0.28111]
20Nov23_081024| [ 0.55264  1.68334 -2.12589 -1.32606 -0.58478  0.44290  0.14816 -0.88333
20Nov23_081024|   0.18307]
20Nov23_081024| [ 0.13988 -0.06929  0.19289 -0.32611  0.40154  0.59037 -0.19791  2.35651
20Nov23_081024|   0.17229]
20Nov23_081024| [ 0.30252 -0.30499  1.13260 -0.65187  0.67200  0.80110 -1.14151 -1.25115
20Nov23_081024|  -0.26380]
20Nov23_081024| [ 0.59178 -0.51172 -0.07961  0.79639  1.05492  0.01977 -0.15418 -0.03723
20Nov23_081024|  -0.35638]
20Nov23_081024| [ 0.13793 -0.25043  0.84681  1.03833 -0.43156  0.03462  0.75354 -0.59958
20Nov23_081024|  -0.45743]
20Nov23_081024| [-1.13800  0.66296 -0.55458  0.97392  0.70267 -0.01965 -0.21929 -0.24260
20Nov23_081024|  -0.05331]
20Nov23_081024| [-2.28186 -0.69856 -0.10021 -0.56269  0.03000 -0.45043  0.16882 -0.65293
20Nov23_081024|  -0.27847]
20Nov23_081024| [ 1.79644  1.28884  0.01848  1.38631  1.80935 -0.08050  0.45143 -0.96041
20Nov23_081024|  -0.12371]
20Nov23_081024| [-0.15386 -0.99409 -1.24233 -0.21473 -0.82358 -0.50121  0.06181 -0.86836
20Nov23_081024|   0.07519]
20Nov23_081024| [-0.73128 -0.17146 -0.58581 -0.82587 -1.27548 -0.17385  0.99249  0.11953
20Nov23_081024|  -0.68291]
20Nov23_081024| [-0.76081 -1.42621 -0.45821  0.05531 -0.23330 -0.74949  0.67051  0.32599
20Nov23_081024|  -0.05493]
20Nov23_081024| [-0.29383 -0.96288 -0.35742 -0.56094  0.45025  2.05842  1.07941  0.36440
20Nov23_081024|  -0.04810]
20Nov23_081024| [ 0.16564 -2.39074  1.24141  0.48639 -0.33374  0.61272  1.00614 -0.45470
20Nov23_081024|  -0.06425]
20Nov23_081024| [ 0.05723  1.47602  0.25261  0.41500 -1.05226  0.39387  1.28792 -0.81318
20Nov23_081024|  -0.63875]
20Nov23_081024| [-1.93770  1.50868  0.70201 -1.00910 -0.43689 -1.09291 -0.95173 -2.17974
20Nov23_081024|  -0.40959]
20Nov23_081024| [-1.34704 -0.06302  0.03764  0.27825  0.39591 -0.36483  0.00780 -0.09740
20Nov23_081024|   0.12410]
20Nov23_081024| [-0.74172 -0.16476 -0.61182  0.16789 -0.92203  1.07919  1.19033 -0.36009
20Nov23_081024|  -0.09485]
20Nov23_081024| [ 0.07440  0.36258 -0.18559  0.15582 -0.03425 -0.76748 -0.29371  0.48534
20Nov23_081024|  -0.77123]
20Nov23_081024| [ 0.23529  1.44463  0.89996  0.74943  0.33310 -0.70402  0.64131  0.80355
20Nov23_081024|  -0.07107]
20Nov23_081024| [ 0.91938  0.71058  0.22984 -0.16823 -0.13721  0.86600  0.44650 -0.13527
20Nov23_081024|  -0.38005]
20Nov23_081024| [-0.39765  0.03921 -0.03567  1.00847 -1.22486  0.79469  0.13971  0.28072
20Nov23_081024|  -0.71548]
20Nov23_081024| [-0.64580 -0.15922 -0.29468  0.58904 -0.15741  0.62625  1.90757 -0.29279
20Nov23_081024|   0.32812]
20Nov23_081024| [-0.38675 -0.71577  0.42643 -0.76070 -1.53681  0.05780 -0.06157  0.39549
20Nov23_081024|  -0.21361]
20Nov23_081024| [-1.61786  0.04702 -0.94962  1.39037 -0.53169  0.85972  0.89185 -0.34408
20Nov23_081024|  -0.73590]
20Nov23_081024| [ 0.98571  0.77837  1.07569 -0.35187 -1.37874 -0.14937  0.22572 -0.82999
20Nov23_081024|   0.44736]
20Nov23_081024| [-1.21003 -1.45838  1.02095  0.61951 -0.22765 -1.21435 -0.22443  0.92740
20Nov23_081024|  -0.77073]
20Nov23_081024| [ 0.59707 -0.56453 -0.65358 -2.34672 -0.32341  0.16786 -1.05250  0.29119
20Nov23_081024|  -0.15825]
20Nov23_081024| [ 1.88803  0.48220 -0.31526  0.39790 -0.28680  0.67641  0.65311 -0.46018
20Nov23_081024|  -0.78346]
20Nov23_081024| [ 1.53749  0.76150 -0.06152  0.94539  1.37221 -1.25450  0.55485  0.75678
20Nov23_081024|   0.28596]
20Nov23_081024| [-0.69501 -0.66292 -0.70443 -0.23586 -1.84727  0.50000  0.72449 -0.29577
20Nov23_081024|  -0.01265]
20Nov23_081024| [ 0.42279  0.38086  0.19830  0.96482 -0.26064  0.21820 -1.36254 -1.67737
20Nov23_081024|   0.09949]
20Nov23_081024| [-0.89380 -0.66418  0.66312 -0.34192  0.52278 -0.76123  0.17047 -2.11020
20Nov23_081024|   0.53196]
20Nov23_081024| [ 0.15779 -0.69696  1.32238 -0.74687 -1.52683 -0.33643 -1.23399 -0.94856
20Nov23_081024|   0.09857]
20Nov23_081024| [ 1.05131 -0.67318 -1.24615 -0.87618 -1.49284 -0.06874  1.07900 -1.14795
20Nov23_081024|   0.17446]
20Nov23_081024| [-0.65091  0.36390  0.43736 -0.20295  0.73984 -1.82535  1.54797 -0.54226
20Nov23_081024|  -0.45832]
20Nov23_081024| [-1.47230 -1.01292 -1.22577  0.13909 -0.22777 -0.64598  0.63506  0.16394
20Nov23_081024|  -0.77675]
20Nov23_081024| [-0.81090  0.15932 -0.32886  0.65237 -0.90740 -1.49863  0.52335  0.66660
20Nov23_081024|  -0.35570]
20Nov23_081024| [-0.38692 -1.11881  1.10759 -0.22649  0.73540 -0.46981  1.45865 -0.85465
20Nov23_081024|   0.06884]
20Nov23_081024| [-0.70397 -0.48164  1.26245  2.11535 -1.40169 -0.46342 -1.17306 -1.46933
20Nov23_081024|  -0.49080]
20Nov23_081024| [-1.10460  1.43416 -0.48554  1.51377  0.64254 -1.76552  1.65956 -0.50608
20Nov23_081024|  -0.54698]
20Nov23_081024| [-0.31011  1.98690  0.38783  0.35508  0.03083  1.34938  1.53292 -0.53171
20Nov23_081024|   0.12150]
20Nov23_081024| [ 0.36149 -0.26401 -0.01935  0.42299  1.37095 -1.27051 -0.18245  0.31588
20Nov23_081024|  -0.29268]
20Nov23_081024| [-1.06074  1.99965  0.69902 -0.86402 -1.29065 -2.35002 -1.28412 -0.72877
20Nov23_081024|  -0.41804]
20Nov23_081024| [-0.84514  0.53515  1.45650  1.07456 -0.31276 -1.39673 -0.46390 -0.11888
20Nov23_081024|  -0.62786]
20Nov23_081024| [-0.68851  1.03186 -0.46824  0.65608 -2.15624  0.15132 -0.07458 -0.29261
20Nov23_081024|   0.83517]
20Nov23_081024| [ 0.33518 -0.03880 -0.91495  0.27963 -1.52199  0.44892 -0.59121 -0.83967
20Nov23_081024|  -0.89924]
20Nov23_081024| [ 1.32436 -0.23291  2.16960 -0.32631 -0.78017  0.23003 -0.45617  2.55819
20Nov23_081024|   0.34619]
20Nov23_081024| [ 0.94408 -0.05989 -0.56402  0.71193 -0.81660 -0.55225 -0.29669  0.64528
20Nov23_081024|   0.32030]]
20Nov23_081024|-- Bias --
20Nov23_081024|[ 0.07637 -0.83169 -0.11893 -0.05433  0.08749 -1.35431  0.38599 -0.57607
20Nov23_081024| -0.06108]
20Nov23_081024|Layer 1:
20Nov23_081024|-- Config --
20Nov23_081024|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 9], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_081024|-- Weights --
20Nov23_081024|[[ 0.70918 -0.98308]
20Nov23_081024| [-0.29153 -0.01013]
20Nov23_081024| [-1.87688 -0.30242]
20Nov23_081024| [-0.40156  0.63724]
20Nov23_081024| [-0.19569  0.07574]
20Nov23_081024| [ 0.27194  0.47916]
20Nov23_081024| [-0.77374 -0.16853]
20Nov23_081024| [ 0.70173  2.03695]
20Nov23_081024| [-0.37282  0.05925]]
20Nov23_081024|-- Bias --
20Nov23_081024|[-0.02520 -0.26371]
20Nov23_081024|Predicting the validation and test data with the Best final individual.
20Nov23_081030| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_081030|-----------  ------------------  --------------------  ----------
20Nov23_081030|Validation         40.96                  9             0.03340
20Nov23_081030|   Test            35.88                  9             0.02666
20Nov23_081030|-------------------------- Test #4 --------------------------
20Nov23_081030|Best final individual weights
20Nov23_081030|Individual:
20Nov23_081030|-- Constant hidden layers --
20Nov23_081030|False
20Nov23_081030|Layer 0:
20Nov23_081030|-- Config --
20Nov23_081030|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 9, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_081030|-- Weights --
20Nov23_081030|[[ 0.17602  1.37005  0.94134  1.05414 -0.21995 -0.52384  1.64542 -0.30457
20Nov23_081030|   0.01296]
20Nov23_081030| [-1.00766  0.55531 -1.99234  0.25526  1.25030 -0.49747 -0.03963 -0.09871
20Nov23_081030|  -0.82622]
20Nov23_081030| [ 0.00435 -0.99825 -0.50688  0.37209 -1.65379 -0.48515 -0.08885  0.45705
20Nov23_081030|   0.37833]
20Nov23_081030| [-0.06184  0.76090  1.13704  1.50787  0.60159  0.44759 -1.32216 -1.49004
20Nov23_081030|  -0.31006]
20Nov23_081030| [ 0.15529 -1.20693 -0.59482  0.77745 -1.52902  1.47965 -0.18784  0.01618
20Nov23_081030|  -0.37143]
20Nov23_081030| [-0.74608  0.51489  0.44418  1.61057  1.02837 -0.39362 -1.59788 -1.41381
20Nov23_081030|  -0.46460]
20Nov23_081030| [-1.22317 -1.34170  0.81731  0.39239 -1.09585 -0.98934 -0.06814  0.95451
20Nov23_081030|   0.34325]
20Nov23_081030| [ 0.18246 -1.70586 -1.09053 -2.24079  1.80462 -0.74800 -1.48499 -0.16259
20Nov23_081030|   0.12309]
20Nov23_081030| [ 0.96105 -1.07518 -0.27790 -0.90632 -0.38456 -0.70881 -0.15062  0.71637
20Nov23_081030|   0.28111]
20Nov23_081030| [ 0.55264  1.68334 -2.12589 -1.32606 -0.58478  0.44290  0.14816 -0.88333
20Nov23_081030|   0.18307]
20Nov23_081030| [ 0.13988 -0.06929  0.19289 -0.32611  0.40154  0.59037 -0.19791  2.35651
20Nov23_081030|   0.17229]
20Nov23_081030| [ 0.30252 -0.30499  1.13260 -0.65187  0.67200  0.80110 -1.14151 -1.25115
20Nov23_081030|  -0.26380]
20Nov23_081030| [ 0.59178 -0.51172 -0.07961  0.79639  1.05492  0.01977 -0.15418 -0.03723
20Nov23_081030|  -0.35638]
20Nov23_081030| [ 0.13793 -0.25043  0.84681  1.03833 -0.43156  0.03462  0.75354 -0.59958
20Nov23_081030|  -0.45743]
20Nov23_081030| [-1.13800  0.66296 -0.55458  0.97392  0.70267 -0.01965 -0.21929 -0.24260
20Nov23_081030|  -0.05331]
20Nov23_081030| [-2.28186 -0.69856 -0.10021 -0.56269  0.03000 -0.45043  0.16882 -0.65293
20Nov23_081030|  -0.27847]
20Nov23_081030| [ 1.79644  1.28884  0.01848  1.38631  1.80935 -0.08050  0.45143 -0.96041
20Nov23_081030|  -0.12371]
20Nov23_081030| [-0.15386 -0.99409 -1.24233 -0.21473 -0.82358 -0.50121  0.06181 -0.86836
20Nov23_081030|   0.07519]
20Nov23_081030| [-0.73128 -0.17146 -0.58581 -0.82587 -1.27548 -0.17385  0.99249  0.11953
20Nov23_081030|  -0.68291]
20Nov23_081030| [-0.76081 -1.42621 -0.45821  0.05531 -0.23330 -0.74949  0.67051  0.32599
20Nov23_081030|  -0.05493]
20Nov23_081030| [-0.29383 -0.96288 -0.35742 -0.56094  0.45025  2.05842  1.07941  0.36440
20Nov23_081030|  -0.04810]
20Nov23_081030| [ 0.16564 -2.39074  1.24141  0.48639 -0.33374  0.61272  1.00614 -0.45470
20Nov23_081030|  -0.06425]
20Nov23_081030| [ 0.05723  1.47602  0.25261  0.41500 -1.05226  0.39387  1.28792 -0.81318
20Nov23_081030|  -0.63875]
20Nov23_081030| [-1.93770  1.50868  0.70201 -1.00910 -0.43689 -1.09291 -0.95173 -2.17974
20Nov23_081030|  -0.40959]
20Nov23_081030| [-1.34704 -0.06302  0.03764  0.27825  0.39591 -0.36483  0.00780 -0.09740
20Nov23_081030|   0.12410]
20Nov23_081030| [-0.74172 -0.16476 -0.61182  0.16789 -0.92203  1.07919  1.19033 -0.36009
20Nov23_081030|  -0.09485]
20Nov23_081030| [ 0.07440  0.36258 -0.18559  0.15582 -0.03425 -0.76748 -0.29371  0.48534
20Nov23_081030|  -0.77123]
20Nov23_081030| [ 0.23529  1.44463  0.89996  0.74943  0.33310 -0.70402  0.64131  0.80355
20Nov23_081030|  -0.07107]
20Nov23_081030| [ 0.91938  0.71058  0.22984 -0.16823 -0.13721  0.86600  0.44650 -0.13527
20Nov23_081030|  -0.38005]
20Nov23_081030| [-0.39765  0.03921 -0.03567  1.00847 -1.22486  0.79469  0.13971  0.28072
20Nov23_081030|  -0.71548]
20Nov23_081030| [-0.64580 -0.15922 -0.29468  0.58904 -0.15741  0.62625  1.90757 -0.29279
20Nov23_081030|   0.32812]
20Nov23_081030| [-0.38675 -0.71577  0.42643 -0.76070 -1.53681  0.05780 -0.06157  0.39549
20Nov23_081030|  -0.21361]
20Nov23_081030| [-1.61786  0.04702 -0.94962  1.39037 -0.53169  0.85972  0.89185 -0.34408
20Nov23_081030|  -0.73590]
20Nov23_081030| [ 0.98571  0.77837  1.07569 -0.35187 -1.37874 -0.14937  0.22572 -0.82999
20Nov23_081030|   0.44736]
20Nov23_081030| [-1.21003 -1.45838  1.02095  0.61951 -0.22765 -1.21435 -0.22443  0.92740
20Nov23_081030|  -0.77073]
20Nov23_081030| [ 0.59707 -0.56453 -0.65358 -2.34672 -0.32341  0.16786 -1.05250  0.29119
20Nov23_081030|  -0.15825]
20Nov23_081030| [ 1.88803  0.48220 -0.31526  0.39790 -0.28680  0.67641  0.65311 -0.46018
20Nov23_081030|  -0.78346]
20Nov23_081030| [ 1.53749  0.76150 -0.06152  0.94539  1.37221 -1.25450  0.55485  0.75678
20Nov23_081030|   0.28596]
20Nov23_081030| [-0.69501 -0.66292 -0.70443 -0.23586 -1.84727  0.50000  0.72449 -0.29577
20Nov23_081030|  -0.01265]
20Nov23_081030| [ 0.42279  0.38086  0.19830  0.96482 -0.26064  0.21820 -1.36254 -1.67737
20Nov23_081030|   0.09949]
20Nov23_081030| [-0.89380 -0.66418  0.66312 -0.34192  0.52278 -0.76123  0.17047 -2.11020
20Nov23_081030|   0.53196]
20Nov23_081030| [ 0.15779 -0.69696  1.32238 -0.74687 -1.52683 -0.33643 -1.23399 -0.94856
20Nov23_081030|   0.09857]
20Nov23_081030| [ 1.05131 -0.67318 -1.24615 -0.87618 -1.49284 -0.06874  1.07900 -1.14795
20Nov23_081030|   0.17446]
20Nov23_081030| [-0.65091  0.36390  0.43736 -0.20295  0.73984 -1.82535  1.54797 -0.54226
20Nov23_081030|  -0.45832]
20Nov23_081030| [-1.47230 -1.01292 -1.22577  0.13909 -0.22777 -0.64598  0.63506  0.16394
20Nov23_081030|  -0.77675]
20Nov23_081030| [-0.81090  0.15932 -0.32886  0.65237 -0.90740 -1.49863  0.52335  0.66660
20Nov23_081030|  -0.35570]
20Nov23_081030| [-0.38692 -1.11881  1.10759 -0.22649  0.73540 -0.46981  1.45865 -0.85465
20Nov23_081030|   0.06884]
20Nov23_081030| [-0.70397 -0.48164  1.26245  2.11535 -1.40169 -0.46342 -1.17306 -1.46933
20Nov23_081030|  -0.49080]
20Nov23_081030| [-1.10460  1.43416 -0.48554  1.51377  0.64254 -1.76552  1.65956 -0.50608
20Nov23_081030|  -0.54698]
20Nov23_081030| [-0.31011  1.98690  0.38783  0.35508  0.03083  1.34938  1.53292 -0.53171
20Nov23_081030|   0.12150]
20Nov23_081030| [ 0.36149 -0.26401 -0.01935  0.42299  1.37095 -1.27051 -0.18245  0.31588
20Nov23_081030|  -0.29268]
20Nov23_081030| [-1.06074  1.99965  0.69902 -0.86402 -1.29065 -2.35002 -1.28412 -0.72877
20Nov23_081030|  -0.41804]
20Nov23_081030| [-0.84514  0.53515  1.45650  1.07456 -0.31276 -1.39673 -0.46390 -0.11888
20Nov23_081030|  -0.62786]
20Nov23_081030| [-0.68851  1.03186 -0.46824  0.65608 -2.15624  0.15132 -0.07458 -0.29261
20Nov23_081030|   0.83517]
20Nov23_081030| [ 0.33518 -0.03880 -0.91495  0.27963 -1.52199  0.44892 -0.59121 -0.83967
20Nov23_081030|  -0.89924]
20Nov23_081030| [ 1.32436 -0.23291  2.16960 -0.32631 -0.78017  0.23003 -0.45617  2.55819
20Nov23_081030|   0.34619]
20Nov23_081030| [ 0.94408 -0.05989 -0.56402  0.71193 -0.81660 -0.55225 -0.29669  0.64528
20Nov23_081030|   0.32030]]
20Nov23_081030|-- Bias --
20Nov23_081030|[ 0.07637 -0.83169 -0.11893 -0.05433  0.08749 -1.35431  0.38599 -0.57607
20Nov23_081030| -0.06108]
20Nov23_081030|Layer 1:
20Nov23_081030|-- Config --
20Nov23_081030|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 9], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_081030|-- Weights --
20Nov23_081030|[[ 0.70918 -0.98308]
20Nov23_081030| [-0.29153 -0.01013]
20Nov23_081030| [-1.87688 -0.30242]
20Nov23_081030| [-0.40156  0.63724]
20Nov23_081030| [-0.19569  0.07574]
20Nov23_081030| [ 0.27194  0.47916]
20Nov23_081030| [-0.77374 -0.16853]
20Nov23_081030| [ 0.70173  2.03695]
20Nov23_081030| [-0.37282  0.05925]]
20Nov23_081030|-- Bias --
20Nov23_081030|[-0.02520 -0.26371]
20Nov23_081030|Predicting the validation and test data with the Best final individual.
20Nov23_081035| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_081035|-----------  ------------------  --------------------  ----------
20Nov23_081035|Validation         40.78                  9             0.03850
20Nov23_081035|   Test            35.45                  9             0.04425
20Nov23_081035|-------------------------- Test #5 --------------------------
20Nov23_081035|Best final individual weights
20Nov23_081035|Individual:
20Nov23_081035|-- Constant hidden layers --
20Nov23_081035|False
20Nov23_081035|Layer 0:
20Nov23_081035|-- Config --
20Nov23_081035|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 9, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_081035|-- Weights --
20Nov23_081035|[[ 0.17602  1.37005  0.94134  1.05414 -0.21995 -0.52384  1.64542 -0.30457
20Nov23_081035|   0.01296]
20Nov23_081035| [-1.00766  0.55531 -1.99234  0.25526  1.25030 -0.49747 -0.03963 -0.09871
20Nov23_081035|  -0.82622]
20Nov23_081035| [ 0.00435 -0.99825 -0.50688  0.37209 -1.65379 -0.48515 -0.08885  0.45705
20Nov23_081035|   0.37833]
20Nov23_081035| [-0.06184  0.76090  1.13704  1.50787  0.60159  0.44759 -1.32216 -1.49004
20Nov23_081035|  -0.31006]
20Nov23_081035| [ 0.15529 -1.20693 -0.59482  0.77745 -1.52902  1.47965 -0.18784  0.01618
20Nov23_081035|  -0.37143]
20Nov23_081035| [-0.74608  0.51489  0.44418  1.61057  1.02837 -0.39362 -1.59788 -1.41381
20Nov23_081035|  -0.46460]
20Nov23_081035| [-1.22317 -1.34170  0.81731  0.39239 -1.09585 -0.98934 -0.06814  0.95451
20Nov23_081035|   0.34325]
20Nov23_081035| [ 0.18246 -1.70586 -1.09053 -2.24079  1.80462 -0.74800 -1.48499 -0.16259
20Nov23_081035|   0.12309]
20Nov23_081035| [ 0.96105 -1.07518 -0.27790 -0.90632 -0.38456 -0.70881 -0.15062  0.71637
20Nov23_081035|   0.28111]
20Nov23_081035| [ 0.55264  1.68334 -2.12589 -1.32606 -0.58478  0.44290  0.14816 -0.88333
20Nov23_081035|   0.18307]
20Nov23_081035| [ 0.13988 -0.06929  0.19289 -0.32611  0.40154  0.59037 -0.19791  2.35651
20Nov23_081035|   0.17229]
20Nov23_081035| [ 0.30252 -0.30499  1.13260 -0.65187  0.67200  0.80110 -1.14151 -1.25115
20Nov23_081035|  -0.26380]
20Nov23_081035| [ 0.59178 -0.51172 -0.07961  0.79639  1.05492  0.01977 -0.15418 -0.03723
20Nov23_081035|  -0.35638]
20Nov23_081035| [ 0.13793 -0.25043  0.84681  1.03833 -0.43156  0.03462  0.75354 -0.59958
20Nov23_081035|  -0.45743]
20Nov23_081035| [-1.13800  0.66296 -0.55458  0.97392  0.70267 -0.01965 -0.21929 -0.24260
20Nov23_081035|  -0.05331]
20Nov23_081035| [-2.28186 -0.69856 -0.10021 -0.56269  0.03000 -0.45043  0.16882 -0.65293
20Nov23_081035|  -0.27847]
20Nov23_081035| [ 1.79644  1.28884  0.01848  1.38631  1.80935 -0.08050  0.45143 -0.96041
20Nov23_081035|  -0.12371]
20Nov23_081035| [-0.15386 -0.99409 -1.24233 -0.21473 -0.82358 -0.50121  0.06181 -0.86836
20Nov23_081035|   0.07519]
20Nov23_081035| [-0.73128 -0.17146 -0.58581 -0.82587 -1.27548 -0.17385  0.99249  0.11953
20Nov23_081035|  -0.68291]
20Nov23_081035| [-0.76081 -1.42621 -0.45821  0.05531 -0.23330 -0.74949  0.67051  0.32599
20Nov23_081035|  -0.05493]
20Nov23_081035| [-0.29383 -0.96288 -0.35742 -0.56094  0.45025  2.05842  1.07941  0.36440
20Nov23_081035|  -0.04810]
20Nov23_081035| [ 0.16564 -2.39074  1.24141  0.48639 -0.33374  0.61272  1.00614 -0.45470
20Nov23_081035|  -0.06425]
20Nov23_081035| [ 0.05723  1.47602  0.25261  0.41500 -1.05226  0.39387  1.28792 -0.81318
20Nov23_081035|  -0.63875]
20Nov23_081035| [-1.93770  1.50868  0.70201 -1.00910 -0.43689 -1.09291 -0.95173 -2.17974
20Nov23_081035|  -0.40959]
20Nov23_081035| [-1.34704 -0.06302  0.03764  0.27825  0.39591 -0.36483  0.00780 -0.09740
20Nov23_081035|   0.12410]
20Nov23_081035| [-0.74172 -0.16476 -0.61182  0.16789 -0.92203  1.07919  1.19033 -0.36009
20Nov23_081035|  -0.09485]
20Nov23_081035| [ 0.07440  0.36258 -0.18559  0.15582 -0.03425 -0.76748 -0.29371  0.48534
20Nov23_081035|  -0.77123]
20Nov23_081035| [ 0.23529  1.44463  0.89996  0.74943  0.33310 -0.70402  0.64131  0.80355
20Nov23_081035|  -0.07107]
20Nov23_081035| [ 0.91938  0.71058  0.22984 -0.16823 -0.13721  0.86600  0.44650 -0.13527
20Nov23_081035|  -0.38005]
20Nov23_081035| [-0.39765  0.03921 -0.03567  1.00847 -1.22486  0.79469  0.13971  0.28072
20Nov23_081035|  -0.71548]
20Nov23_081035| [-0.64580 -0.15922 -0.29468  0.58904 -0.15741  0.62625  1.90757 -0.29279
20Nov23_081035|   0.32812]
20Nov23_081035| [-0.38675 -0.71577  0.42643 -0.76070 -1.53681  0.05780 -0.06157  0.39549
20Nov23_081035|  -0.21361]
20Nov23_081035| [-1.61786  0.04702 -0.94962  1.39037 -0.53169  0.85972  0.89185 -0.34408
20Nov23_081035|  -0.73590]
20Nov23_081035| [ 0.98571  0.77837  1.07569 -0.35187 -1.37874 -0.14937  0.22572 -0.82999
20Nov23_081035|   0.44736]
20Nov23_081035| [-1.21003 -1.45838  1.02095  0.61951 -0.22765 -1.21435 -0.22443  0.92740
20Nov23_081035|  -0.77073]
20Nov23_081035| [ 0.59707 -0.56453 -0.65358 -2.34672 -0.32341  0.16786 -1.05250  0.29119
20Nov23_081035|  -0.15825]
20Nov23_081035| [ 1.88803  0.48220 -0.31526  0.39790 -0.28680  0.67641  0.65311 -0.46018
20Nov23_081035|  -0.78346]
20Nov23_081035| [ 1.53749  0.76150 -0.06152  0.94539  1.37221 -1.25450  0.55485  0.75678
20Nov23_081035|   0.28596]
20Nov23_081035| [-0.69501 -0.66292 -0.70443 -0.23586 -1.84727  0.50000  0.72449 -0.29577
20Nov23_081035|  -0.01265]
20Nov23_081035| [ 0.42279  0.38086  0.19830  0.96482 -0.26064  0.21820 -1.36254 -1.67737
20Nov23_081035|   0.09949]
20Nov23_081035| [-0.89380 -0.66418  0.66312 -0.34192  0.52278 -0.76123  0.17047 -2.11020
20Nov23_081035|   0.53196]
20Nov23_081035| [ 0.15779 -0.69696  1.32238 -0.74687 -1.52683 -0.33643 -1.23399 -0.94856
20Nov23_081035|   0.09857]
20Nov23_081035| [ 1.05131 -0.67318 -1.24615 -0.87618 -1.49284 -0.06874  1.07900 -1.14795
20Nov23_081035|   0.17446]
20Nov23_081035| [-0.65091  0.36390  0.43736 -0.20295  0.73984 -1.82535  1.54797 -0.54226
20Nov23_081035|  -0.45832]
20Nov23_081035| [-1.47230 -1.01292 -1.22577  0.13909 -0.22777 -0.64598  0.63506  0.16394
20Nov23_081035|  -0.77675]
20Nov23_081035| [-0.81090  0.15932 -0.32886  0.65237 -0.90740 -1.49863  0.52335  0.66660
20Nov23_081035|  -0.35570]
20Nov23_081035| [-0.38692 -1.11881  1.10759 -0.22649  0.73540 -0.46981  1.45865 -0.85465
20Nov23_081035|   0.06884]
20Nov23_081035| [-0.70397 -0.48164  1.26245  2.11535 -1.40169 -0.46342 -1.17306 -1.46933
20Nov23_081035|  -0.49080]
20Nov23_081035| [-1.10460  1.43416 -0.48554  1.51377  0.64254 -1.76552  1.65956 -0.50608
20Nov23_081035|  -0.54698]
20Nov23_081035| [-0.31011  1.98690  0.38783  0.35508  0.03083  1.34938  1.53292 -0.53171
20Nov23_081035|   0.12150]
20Nov23_081035| [ 0.36149 -0.26401 -0.01935  0.42299  1.37095 -1.27051 -0.18245  0.31588
20Nov23_081035|  -0.29268]
20Nov23_081035| [-1.06074  1.99965  0.69902 -0.86402 -1.29065 -2.35002 -1.28412 -0.72877
20Nov23_081035|  -0.41804]
20Nov23_081035| [-0.84514  0.53515  1.45650  1.07456 -0.31276 -1.39673 -0.46390 -0.11888
20Nov23_081035|  -0.62786]
20Nov23_081035| [-0.68851  1.03186 -0.46824  0.65608 -2.15624  0.15132 -0.07458 -0.29261
20Nov23_081035|   0.83517]
20Nov23_081035| [ 0.33518 -0.03880 -0.91495  0.27963 -1.52199  0.44892 -0.59121 -0.83967
20Nov23_081035|  -0.89924]
20Nov23_081035| [ 1.32436 -0.23291  2.16960 -0.32631 -0.78017  0.23003 -0.45617  2.55819
20Nov23_081035|   0.34619]
20Nov23_081035| [ 0.94408 -0.05989 -0.56402  0.71193 -0.81660 -0.55225 -0.29669  0.64528
20Nov23_081035|   0.32030]]
20Nov23_081035|-- Bias --
20Nov23_081035|[ 0.07637 -0.83169 -0.11893 -0.05433  0.08749 -1.35431  0.38599 -0.57607
20Nov23_081035| -0.06108]
20Nov23_081035|Layer 1:
20Nov23_081035|-- Config --
20Nov23_081035|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 9], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_081035|-- Weights --
20Nov23_081035|[[ 0.70918 -0.98308]
20Nov23_081035| [-0.29153 -0.01013]
20Nov23_081035| [-1.87688 -0.30242]
20Nov23_081035| [-0.40156  0.63724]
20Nov23_081035| [-0.19569  0.07574]
20Nov23_081035| [ 0.27194  0.47916]
20Nov23_081035| [-0.77374 -0.16853]
20Nov23_081035| [ 0.70173  2.03695]
20Nov23_081035| [-0.37282  0.05925]]
20Nov23_081035|-- Bias --
20Nov23_081035|[-0.02520 -0.26371]
20Nov23_081035|Predicting the validation and test data with the Best final individual.
20Nov23_081041| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_081041|-----------  ------------------  --------------------  ----------
20Nov23_081041|Validation         41.13                  9             0.03337
20Nov23_081041|   Test            35.88                  9             0.02959
20Nov23_081041|-------------------------- Test #6 --------------------------
20Nov23_081041|Best final individual weights
20Nov23_081041|Individual:
20Nov23_081041|-- Constant hidden layers --
20Nov23_081041|False
20Nov23_081041|Layer 0:
20Nov23_081041|-- Config --
20Nov23_081041|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 9, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_081041|-- Weights --
20Nov23_081041|[[ 0.17602  1.37005  0.94134  1.05414 -0.21995 -0.52384  1.64542 -0.30457
20Nov23_081041|   0.01296]
20Nov23_081041| [-1.00766  0.55531 -1.99234  0.25526  1.25030 -0.49747 -0.03963 -0.09871
20Nov23_081041|  -0.82622]
20Nov23_081041| [ 0.00435 -0.99825 -0.50688  0.37209 -1.65379 -0.48515 -0.08885  0.45705
20Nov23_081041|   0.37833]
20Nov23_081041| [-0.06184  0.76090  1.13704  1.50787  0.60159  0.44759 -1.32216 -1.49004
20Nov23_081041|  -0.31006]
20Nov23_081041| [ 0.15529 -1.20693 -0.59482  0.77745 -1.52902  1.47965 -0.18784  0.01618
20Nov23_081041|  -0.37143]
20Nov23_081041| [-0.74608  0.51489  0.44418  1.61057  1.02837 -0.39362 -1.59788 -1.41381
20Nov23_081041|  -0.46460]
20Nov23_081041| [-1.22317 -1.34170  0.81731  0.39239 -1.09585 -0.98934 -0.06814  0.95451
20Nov23_081041|   0.34325]
20Nov23_081041| [ 0.18246 -1.70586 -1.09053 -2.24079  1.80462 -0.74800 -1.48499 -0.16259
20Nov23_081041|   0.12309]
20Nov23_081041| [ 0.96105 -1.07518 -0.27790 -0.90632 -0.38456 -0.70881 -0.15062  0.71637
20Nov23_081041|   0.28111]
20Nov23_081041| [ 0.55264  1.68334 -2.12589 -1.32606 -0.58478  0.44290  0.14816 -0.88333
20Nov23_081041|   0.18307]
20Nov23_081041| [ 0.13988 -0.06929  0.19289 -0.32611  0.40154  0.59037 -0.19791  2.35651
20Nov23_081041|   0.17229]
20Nov23_081041| [ 0.30252 -0.30499  1.13260 -0.65187  0.67200  0.80110 -1.14151 -1.25115
20Nov23_081041|  -0.26380]
20Nov23_081041| [ 0.59178 -0.51172 -0.07961  0.79639  1.05492  0.01977 -0.15418 -0.03723
20Nov23_081041|  -0.35638]
20Nov23_081041| [ 0.13793 -0.25043  0.84681  1.03833 -0.43156  0.03462  0.75354 -0.59958
20Nov23_081041|  -0.45743]
20Nov23_081041| [-1.13800  0.66296 -0.55458  0.97392  0.70267 -0.01965 -0.21929 -0.24260
20Nov23_081041|  -0.05331]
20Nov23_081041| [-2.28186 -0.69856 -0.10021 -0.56269  0.03000 -0.45043  0.16882 -0.65293
20Nov23_081041|  -0.27847]
20Nov23_081041| [ 1.79644  1.28884  0.01848  1.38631  1.80935 -0.08050  0.45143 -0.96041
20Nov23_081041|  -0.12371]
20Nov23_081041| [-0.15386 -0.99409 -1.24233 -0.21473 -0.82358 -0.50121  0.06181 -0.86836
20Nov23_081041|   0.07519]
20Nov23_081041| [-0.73128 -0.17146 -0.58581 -0.82587 -1.27548 -0.17385  0.99249  0.11953
20Nov23_081041|  -0.68291]
20Nov23_081041| [-0.76081 -1.42621 -0.45821  0.05531 -0.23330 -0.74949  0.67051  0.32599
20Nov23_081041|  -0.05493]
20Nov23_081041| [-0.29383 -0.96288 -0.35742 -0.56094  0.45025  2.05842  1.07941  0.36440
20Nov23_081041|  -0.04810]
20Nov23_081041| [ 0.16564 -2.39074  1.24141  0.48639 -0.33374  0.61272  1.00614 -0.45470
20Nov23_081041|  -0.06425]
20Nov23_081041| [ 0.05723  1.47602  0.25261  0.41500 -1.05226  0.39387  1.28792 -0.81318
20Nov23_081041|  -0.63875]
20Nov23_081041| [-1.93770  1.50868  0.70201 -1.00910 -0.43689 -1.09291 -0.95173 -2.17974
20Nov23_081041|  -0.40959]
20Nov23_081041| [-1.34704 -0.06302  0.03764  0.27825  0.39591 -0.36483  0.00780 -0.09740
20Nov23_081041|   0.12410]
20Nov23_081041| [-0.74172 -0.16476 -0.61182  0.16789 -0.92203  1.07919  1.19033 -0.36009
20Nov23_081041|  -0.09485]
20Nov23_081041| [ 0.07440  0.36258 -0.18559  0.15582 -0.03425 -0.76748 -0.29371  0.48534
20Nov23_081041|  -0.77123]
20Nov23_081041| [ 0.23529  1.44463  0.89996  0.74943  0.33310 -0.70402  0.64131  0.80355
20Nov23_081041|  -0.07107]
20Nov23_081041| [ 0.91938  0.71058  0.22984 -0.16823 -0.13721  0.86600  0.44650 -0.13527
20Nov23_081041|  -0.38005]
20Nov23_081041| [-0.39765  0.03921 -0.03567  1.00847 -1.22486  0.79469  0.13971  0.28072
20Nov23_081041|  -0.71548]
20Nov23_081041| [-0.64580 -0.15922 -0.29468  0.58904 -0.15741  0.62625  1.90757 -0.29279
20Nov23_081041|   0.32812]
20Nov23_081041| [-0.38675 -0.71577  0.42643 -0.76070 -1.53681  0.05780 -0.06157  0.39549
20Nov23_081041|  -0.21361]
20Nov23_081041| [-1.61786  0.04702 -0.94962  1.39037 -0.53169  0.85972  0.89185 -0.34408
20Nov23_081041|  -0.73590]
20Nov23_081041| [ 0.98571  0.77837  1.07569 -0.35187 -1.37874 -0.14937  0.22572 -0.82999
20Nov23_081041|   0.44736]
20Nov23_081041| [-1.21003 -1.45838  1.02095  0.61951 -0.22765 -1.21435 -0.22443  0.92740
20Nov23_081041|  -0.77073]
20Nov23_081041| [ 0.59707 -0.56453 -0.65358 -2.34672 -0.32341  0.16786 -1.05250  0.29119
20Nov23_081041|  -0.15825]
20Nov23_081041| [ 1.88803  0.48220 -0.31526  0.39790 -0.28680  0.67641  0.65311 -0.46018
20Nov23_081041|  -0.78346]
20Nov23_081041| [ 1.53749  0.76150 -0.06152  0.94539  1.37221 -1.25450  0.55485  0.75678
20Nov23_081041|   0.28596]
20Nov23_081041| [-0.69501 -0.66292 -0.70443 -0.23586 -1.84727  0.50000  0.72449 -0.29577
20Nov23_081041|  -0.01265]
20Nov23_081041| [ 0.42279  0.38086  0.19830  0.96482 -0.26064  0.21820 -1.36254 -1.67737
20Nov23_081041|   0.09949]
20Nov23_081041| [-0.89380 -0.66418  0.66312 -0.34192  0.52278 -0.76123  0.17047 -2.11020
20Nov23_081041|   0.53196]
20Nov23_081041| [ 0.15779 -0.69696  1.32238 -0.74687 -1.52683 -0.33643 -1.23399 -0.94856
20Nov23_081041|   0.09857]
20Nov23_081041| [ 1.05131 -0.67318 -1.24615 -0.87618 -1.49284 -0.06874  1.07900 -1.14795
20Nov23_081041|   0.17446]
20Nov23_081041| [-0.65091  0.36390  0.43736 -0.20295  0.73984 -1.82535  1.54797 -0.54226
20Nov23_081041|  -0.45832]
20Nov23_081041| [-1.47230 -1.01292 -1.22577  0.13909 -0.22777 -0.64598  0.63506  0.16394
20Nov23_081041|  -0.77675]
20Nov23_081041| [-0.81090  0.15932 -0.32886  0.65237 -0.90740 -1.49863  0.52335  0.66660
20Nov23_081041|  -0.35570]
20Nov23_081041| [-0.38692 -1.11881  1.10759 -0.22649  0.73540 -0.46981  1.45865 -0.85465
20Nov23_081041|   0.06884]
20Nov23_081041| [-0.70397 -0.48164  1.26245  2.11535 -1.40169 -0.46342 -1.17306 -1.46933
20Nov23_081041|  -0.49080]
20Nov23_081041| [-1.10460  1.43416 -0.48554  1.51377  0.64254 -1.76552  1.65956 -0.50608
20Nov23_081041|  -0.54698]
20Nov23_081041| [-0.31011  1.98690  0.38783  0.35508  0.03083  1.34938  1.53292 -0.53171
20Nov23_081041|   0.12150]
20Nov23_081041| [ 0.36149 -0.26401 -0.01935  0.42299  1.37095 -1.27051 -0.18245  0.31588
20Nov23_081041|  -0.29268]
20Nov23_081041| [-1.06074  1.99965  0.69902 -0.86402 -1.29065 -2.35002 -1.28412 -0.72877
20Nov23_081041|  -0.41804]
20Nov23_081041| [-0.84514  0.53515  1.45650  1.07456 -0.31276 -1.39673 -0.46390 -0.11888
20Nov23_081041|  -0.62786]
20Nov23_081041| [-0.68851  1.03186 -0.46824  0.65608 -2.15624  0.15132 -0.07458 -0.29261
20Nov23_081041|   0.83517]
20Nov23_081041| [ 0.33518 -0.03880 -0.91495  0.27963 -1.52199  0.44892 -0.59121 -0.83967
20Nov23_081041|  -0.89924]
20Nov23_081041| [ 1.32436 -0.23291  2.16960 -0.32631 -0.78017  0.23003 -0.45617  2.55819
20Nov23_081041|   0.34619]
20Nov23_081041| [ 0.94408 -0.05989 -0.56402  0.71193 -0.81660 -0.55225 -0.29669  0.64528
20Nov23_081041|   0.32030]]
20Nov23_081041|-- Bias --
20Nov23_081041|[ 0.07637 -0.83169 -0.11893 -0.05433  0.08749 -1.35431  0.38599 -0.57607
20Nov23_081041| -0.06108]
20Nov23_081041|Layer 1:
20Nov23_081041|-- Config --
20Nov23_081041|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 9], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_081041|-- Weights --
20Nov23_081041|[[ 0.70918 -0.98308]
20Nov23_081041| [-0.29153 -0.01013]
20Nov23_081041| [-1.87688 -0.30242]
20Nov23_081041| [-0.40156  0.63724]
20Nov23_081041| [-0.19569  0.07574]
20Nov23_081041| [ 0.27194  0.47916]
20Nov23_081041| [-0.77374 -0.16853]
20Nov23_081041| [ 0.70173  2.03695]
20Nov23_081041| [-0.37282  0.05925]]
20Nov23_081041|-- Bias --
20Nov23_081041|[-0.02520 -0.26371]
20Nov23_081041|Predicting the validation and test data with the Best final individual.
20Nov23_081047| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_081047|-----------  ------------------  --------------------  ----------
20Nov23_081047|Validation         40.43                  9             0.05368
20Nov23_081047|   Test            35.88                  9             0.02666
20Nov23_081047|-------------------------- Test #7 --------------------------
20Nov23_081047|Best final individual weights
20Nov23_081047|Individual:
20Nov23_081047|-- Constant hidden layers --
20Nov23_081047|False
20Nov23_081047|Layer 0:
20Nov23_081047|-- Config --
20Nov23_081047|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 9, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_081047|-- Weights --
20Nov23_081047|[[ 0.17602  1.37005  0.94134  1.05414 -0.21995 -0.52384  1.64542 -0.30457
20Nov23_081047|   0.01296]
20Nov23_081047| [-1.00766  0.55531 -1.99234  0.25526  1.25030 -0.49747 -0.03963 -0.09871
20Nov23_081047|  -0.82622]
20Nov23_081047| [ 0.00435 -0.99825 -0.50688  0.37209 -1.65379 -0.48515 -0.08885  0.45705
20Nov23_081047|   0.37833]
20Nov23_081047| [-0.06184  0.76090  1.13704  1.50787  0.60159  0.44759 -1.32216 -1.49004
20Nov23_081047|  -0.31006]
20Nov23_081047| [ 0.15529 -1.20693 -0.59482  0.77745 -1.52902  1.47965 -0.18784  0.01618
20Nov23_081047|  -0.37143]
20Nov23_081047| [-0.74608  0.51489  0.44418  1.61057  1.02837 -0.39362 -1.59788 -1.41381
20Nov23_081047|  -0.46460]
20Nov23_081047| [-1.22317 -1.34170  0.81731  0.39239 -1.09585 -0.98934 -0.06814  0.95451
20Nov23_081047|   0.34325]
20Nov23_081047| [ 0.18246 -1.70586 -1.09053 -2.24079  1.80462 -0.74800 -1.48499 -0.16259
20Nov23_081047|   0.12309]
20Nov23_081047| [ 0.96105 -1.07518 -0.27790 -0.90632 -0.38456 -0.70881 -0.15062  0.71637
20Nov23_081047|   0.28111]
20Nov23_081047| [ 0.55264  1.68334 -2.12589 -1.32606 -0.58478  0.44290  0.14816 -0.88333
20Nov23_081047|   0.18307]
20Nov23_081047| [ 0.13988 -0.06929  0.19289 -0.32611  0.40154  0.59037 -0.19791  2.35651
20Nov23_081047|   0.17229]
20Nov23_081047| [ 0.30252 -0.30499  1.13260 -0.65187  0.67200  0.80110 -1.14151 -1.25115
20Nov23_081047|  -0.26380]
20Nov23_081047| [ 0.59178 -0.51172 -0.07961  0.79639  1.05492  0.01977 -0.15418 -0.03723
20Nov23_081047|  -0.35638]
20Nov23_081047| [ 0.13793 -0.25043  0.84681  1.03833 -0.43156  0.03462  0.75354 -0.59958
20Nov23_081047|  -0.45743]
20Nov23_081047| [-1.13800  0.66296 -0.55458  0.97392  0.70267 -0.01965 -0.21929 -0.24260
20Nov23_081047|  -0.05331]
20Nov23_081047| [-2.28186 -0.69856 -0.10021 -0.56269  0.03000 -0.45043  0.16882 -0.65293
20Nov23_081047|  -0.27847]
20Nov23_081047| [ 1.79644  1.28884  0.01848  1.38631  1.80935 -0.08050  0.45143 -0.96041
20Nov23_081047|  -0.12371]
20Nov23_081047| [-0.15386 -0.99409 -1.24233 -0.21473 -0.82358 -0.50121  0.06181 -0.86836
20Nov23_081047|   0.07519]
20Nov23_081047| [-0.73128 -0.17146 -0.58581 -0.82587 -1.27548 -0.17385  0.99249  0.11953
20Nov23_081047|  -0.68291]
20Nov23_081047| [-0.76081 -1.42621 -0.45821  0.05531 -0.23330 -0.74949  0.67051  0.32599
20Nov23_081047|  -0.05493]
20Nov23_081047| [-0.29383 -0.96288 -0.35742 -0.56094  0.45025  2.05842  1.07941  0.36440
20Nov23_081047|  -0.04810]
20Nov23_081047| [ 0.16564 -2.39074  1.24141  0.48639 -0.33374  0.61272  1.00614 -0.45470
20Nov23_081047|  -0.06425]
20Nov23_081047| [ 0.05723  1.47602  0.25261  0.41500 -1.05226  0.39387  1.28792 -0.81318
20Nov23_081047|  -0.63875]
20Nov23_081047| [-1.93770  1.50868  0.70201 -1.00910 -0.43689 -1.09291 -0.95173 -2.17974
20Nov23_081047|  -0.40959]
20Nov23_081047| [-1.34704 -0.06302  0.03764  0.27825  0.39591 -0.36483  0.00780 -0.09740
20Nov23_081047|   0.12410]
20Nov23_081047| [-0.74172 -0.16476 -0.61182  0.16789 -0.92203  1.07919  1.19033 -0.36009
20Nov23_081047|  -0.09485]
20Nov23_081047| [ 0.07440  0.36258 -0.18559  0.15582 -0.03425 -0.76748 -0.29371  0.48534
20Nov23_081047|  -0.77123]
20Nov23_081047| [ 0.23529  1.44463  0.89996  0.74943  0.33310 -0.70402  0.64131  0.80355
20Nov23_081047|  -0.07107]
20Nov23_081047| [ 0.91938  0.71058  0.22984 -0.16823 -0.13721  0.86600  0.44650 -0.13527
20Nov23_081047|  -0.38005]
20Nov23_081047| [-0.39765  0.03921 -0.03567  1.00847 -1.22486  0.79469  0.13971  0.28072
20Nov23_081047|  -0.71548]
20Nov23_081047| [-0.64580 -0.15922 -0.29468  0.58904 -0.15741  0.62625  1.90757 -0.29279
20Nov23_081047|   0.32812]
20Nov23_081047| [-0.38675 -0.71577  0.42643 -0.76070 -1.53681  0.05780 -0.06157  0.39549
20Nov23_081047|  -0.21361]
20Nov23_081047| [-1.61786  0.04702 -0.94962  1.39037 -0.53169  0.85972  0.89185 -0.34408
20Nov23_081047|  -0.73590]
20Nov23_081047| [ 0.98571  0.77837  1.07569 -0.35187 -1.37874 -0.14937  0.22572 -0.82999
20Nov23_081047|   0.44736]
20Nov23_081047| [-1.21003 -1.45838  1.02095  0.61951 -0.22765 -1.21435 -0.22443  0.92740
20Nov23_081047|  -0.77073]
20Nov23_081047| [ 0.59707 -0.56453 -0.65358 -2.34672 -0.32341  0.16786 -1.05250  0.29119
20Nov23_081047|  -0.15825]
20Nov23_081047| [ 1.88803  0.48220 -0.31526  0.39790 -0.28680  0.67641  0.65311 -0.46018
20Nov23_081047|  -0.78346]
20Nov23_081047| [ 1.53749  0.76150 -0.06152  0.94539  1.37221 -1.25450  0.55485  0.75678
20Nov23_081047|   0.28596]
20Nov23_081047| [-0.69501 -0.66292 -0.70443 -0.23586 -1.84727  0.50000  0.72449 -0.29577
20Nov23_081047|  -0.01265]
20Nov23_081047| [ 0.42279  0.38086  0.19830  0.96482 -0.26064  0.21820 -1.36254 -1.67737
20Nov23_081047|   0.09949]
20Nov23_081047| [-0.89380 -0.66418  0.66312 -0.34192  0.52278 -0.76123  0.17047 -2.11020
20Nov23_081047|   0.53196]
20Nov23_081047| [ 0.15779 -0.69696  1.32238 -0.74687 -1.52683 -0.33643 -1.23399 -0.94856
20Nov23_081047|   0.09857]
20Nov23_081047| [ 1.05131 -0.67318 -1.24615 -0.87618 -1.49284 -0.06874  1.07900 -1.14795
20Nov23_081047|   0.17446]
20Nov23_081047| [-0.65091  0.36390  0.43736 -0.20295  0.73984 -1.82535  1.54797 -0.54226
20Nov23_081047|  -0.45832]
20Nov23_081047| [-1.47230 -1.01292 -1.22577  0.13909 -0.22777 -0.64598  0.63506  0.16394
20Nov23_081047|  -0.77675]
20Nov23_081047| [-0.81090  0.15932 -0.32886  0.65237 -0.90740 -1.49863  0.52335  0.66660
20Nov23_081047|  -0.35570]
20Nov23_081047| [-0.38692 -1.11881  1.10759 -0.22649  0.73540 -0.46981  1.45865 -0.85465
20Nov23_081047|   0.06884]
20Nov23_081047| [-0.70397 -0.48164  1.26245  2.11535 -1.40169 -0.46342 -1.17306 -1.46933
20Nov23_081047|  -0.49080]
20Nov23_081047| [-1.10460  1.43416 -0.48554  1.51377  0.64254 -1.76552  1.65956 -0.50608
20Nov23_081047|  -0.54698]
20Nov23_081047| [-0.31011  1.98690  0.38783  0.35508  0.03083  1.34938  1.53292 -0.53171
20Nov23_081047|   0.12150]
20Nov23_081047| [ 0.36149 -0.26401 -0.01935  0.42299  1.37095 -1.27051 -0.18245  0.31588
20Nov23_081047|  -0.29268]
20Nov23_081047| [-1.06074  1.99965  0.69902 -0.86402 -1.29065 -2.35002 -1.28412 -0.72877
20Nov23_081047|  -0.41804]
20Nov23_081047| [-0.84514  0.53515  1.45650  1.07456 -0.31276 -1.39673 -0.46390 -0.11888
20Nov23_081047|  -0.62786]
20Nov23_081047| [-0.68851  1.03186 -0.46824  0.65608 -2.15624  0.15132 -0.07458 -0.29261
20Nov23_081047|   0.83517]
20Nov23_081047| [ 0.33518 -0.03880 -0.91495  0.27963 -1.52199  0.44892 -0.59121 -0.83967
20Nov23_081047|  -0.89924]
20Nov23_081047| [ 1.32436 -0.23291  2.16960 -0.32631 -0.78017  0.23003 -0.45617  2.55819
20Nov23_081047|   0.34619]
20Nov23_081047| [ 0.94408 -0.05989 -0.56402  0.71193 -0.81660 -0.55225 -0.29669  0.64528
20Nov23_081047|   0.32030]]
20Nov23_081047|-- Bias --
20Nov23_081047|[ 0.07637 -0.83169 -0.11893 -0.05433  0.08749 -1.35431  0.38599 -0.57607
20Nov23_081047| -0.06108]
20Nov23_081047|Layer 1:
20Nov23_081047|-- Config --
20Nov23_081047|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 9], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_081047|-- Weights --
20Nov23_081047|[[ 0.70918 -0.98308]
20Nov23_081047| [-0.29153 -0.01013]
20Nov23_081047| [-1.87688 -0.30242]
20Nov23_081047| [-0.40156  0.63724]
20Nov23_081047| [-0.19569  0.07574]
20Nov23_081047| [ 0.27194  0.47916]
20Nov23_081047| [-0.77374 -0.16853]
20Nov23_081047| [ 0.70173  2.03695]
20Nov23_081047| [-0.37282  0.05925]]
20Nov23_081047|-- Bias --
20Nov23_081047|[-0.02520 -0.26371]
20Nov23_081047|Predicting the validation and test data with the Best final individual.
20Nov23_081052| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_081052|-----------  ------------------  --------------------  ----------
20Nov23_081052|Validation         41.04                  9             0.03085
20Nov23_081052|   Test            35.71                  9             0.03254
20Nov23_081052|-------------------------- Test #8 --------------------------
20Nov23_081052|Best final individual weights
20Nov23_081052|Individual:
20Nov23_081052|-- Constant hidden layers --
20Nov23_081052|False
20Nov23_081052|Layer 0:
20Nov23_081052|-- Config --
20Nov23_081052|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 9, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_081052|-- Weights --
20Nov23_081052|[[ 0.17602  1.37005  0.94134  1.05414 -0.21995 -0.52384  1.64542 -0.30457
20Nov23_081052|   0.01296]
20Nov23_081052| [-1.00766  0.55531 -1.99234  0.25526  1.25030 -0.49747 -0.03963 -0.09871
20Nov23_081052|  -0.82622]
20Nov23_081052| [ 0.00435 -0.99825 -0.50688  0.37209 -1.65379 -0.48515 -0.08885  0.45705
20Nov23_081052|   0.37833]
20Nov23_081052| [-0.06184  0.76090  1.13704  1.50787  0.60159  0.44759 -1.32216 -1.49004
20Nov23_081052|  -0.31006]
20Nov23_081052| [ 0.15529 -1.20693 -0.59482  0.77745 -1.52902  1.47965 -0.18784  0.01618
20Nov23_081052|  -0.37143]
20Nov23_081052| [-0.74608  0.51489  0.44418  1.61057  1.02837 -0.39362 -1.59788 -1.41381
20Nov23_081052|  -0.46460]
20Nov23_081052| [-1.22317 -1.34170  0.81731  0.39239 -1.09585 -0.98934 -0.06814  0.95451
20Nov23_081052|   0.34325]
20Nov23_081052| [ 0.18246 -1.70586 -1.09053 -2.24079  1.80462 -0.74800 -1.48499 -0.16259
20Nov23_081052|   0.12309]
20Nov23_081052| [ 0.96105 -1.07518 -0.27790 -0.90632 -0.38456 -0.70881 -0.15062  0.71637
20Nov23_081052|   0.28111]
20Nov23_081052| [ 0.55264  1.68334 -2.12589 -1.32606 -0.58478  0.44290  0.14816 -0.88333
20Nov23_081052|   0.18307]
20Nov23_081052| [ 0.13988 -0.06929  0.19289 -0.32611  0.40154  0.59037 -0.19791  2.35651
20Nov23_081052|   0.17229]
20Nov23_081052| [ 0.30252 -0.30499  1.13260 -0.65187  0.67200  0.80110 -1.14151 -1.25115
20Nov23_081052|  -0.26380]
20Nov23_081052| [ 0.59178 -0.51172 -0.07961  0.79639  1.05492  0.01977 -0.15418 -0.03723
20Nov23_081052|  -0.35638]
20Nov23_081052| [ 0.13793 -0.25043  0.84681  1.03833 -0.43156  0.03462  0.75354 -0.59958
20Nov23_081052|  -0.45743]
20Nov23_081052| [-1.13800  0.66296 -0.55458  0.97392  0.70267 -0.01965 -0.21929 -0.24260
20Nov23_081052|  -0.05331]
20Nov23_081052| [-2.28186 -0.69856 -0.10021 -0.56269  0.03000 -0.45043  0.16882 -0.65293
20Nov23_081052|  -0.27847]
20Nov23_081052| [ 1.79644  1.28884  0.01848  1.38631  1.80935 -0.08050  0.45143 -0.96041
20Nov23_081052|  -0.12371]
20Nov23_081052| [-0.15386 -0.99409 -1.24233 -0.21473 -0.82358 -0.50121  0.06181 -0.86836
20Nov23_081052|   0.07519]
20Nov23_081052| [-0.73128 -0.17146 -0.58581 -0.82587 -1.27548 -0.17385  0.99249  0.11953
20Nov23_081052|  -0.68291]
20Nov23_081052| [-0.76081 -1.42621 -0.45821  0.05531 -0.23330 -0.74949  0.67051  0.32599
20Nov23_081052|  -0.05493]
20Nov23_081052| [-0.29383 -0.96288 -0.35742 -0.56094  0.45025  2.05842  1.07941  0.36440
20Nov23_081052|  -0.04810]
20Nov23_081052| [ 0.16564 -2.39074  1.24141  0.48639 -0.33374  0.61272  1.00614 -0.45470
20Nov23_081052|  -0.06425]
20Nov23_081052| [ 0.05723  1.47602  0.25261  0.41500 -1.05226  0.39387  1.28792 -0.81318
20Nov23_081052|  -0.63875]
20Nov23_081052| [-1.93770  1.50868  0.70201 -1.00910 -0.43689 -1.09291 -0.95173 -2.17974
20Nov23_081052|  -0.40959]
20Nov23_081052| [-1.34704 -0.06302  0.03764  0.27825  0.39591 -0.36483  0.00780 -0.09740
20Nov23_081052|   0.12410]
20Nov23_081052| [-0.74172 -0.16476 -0.61182  0.16789 -0.92203  1.07919  1.19033 -0.36009
20Nov23_081052|  -0.09485]
20Nov23_081052| [ 0.07440  0.36258 -0.18559  0.15582 -0.03425 -0.76748 -0.29371  0.48534
20Nov23_081052|  -0.77123]
20Nov23_081052| [ 0.23529  1.44463  0.89996  0.74943  0.33310 -0.70402  0.64131  0.80355
20Nov23_081052|  -0.07107]
20Nov23_081052| [ 0.91938  0.71058  0.22984 -0.16823 -0.13721  0.86600  0.44650 -0.13527
20Nov23_081052|  -0.38005]
20Nov23_081052| [-0.39765  0.03921 -0.03567  1.00847 -1.22486  0.79469  0.13971  0.28072
20Nov23_081052|  -0.71548]
20Nov23_081052| [-0.64580 -0.15922 -0.29468  0.58904 -0.15741  0.62625  1.90757 -0.29279
20Nov23_081052|   0.32812]
20Nov23_081052| [-0.38675 -0.71577  0.42643 -0.76070 -1.53681  0.05780 -0.06157  0.39549
20Nov23_081052|  -0.21361]
20Nov23_081052| [-1.61786  0.04702 -0.94962  1.39037 -0.53169  0.85972  0.89185 -0.34408
20Nov23_081052|  -0.73590]
20Nov23_081052| [ 0.98571  0.77837  1.07569 -0.35187 -1.37874 -0.14937  0.22572 -0.82999
20Nov23_081052|   0.44736]
20Nov23_081052| [-1.21003 -1.45838  1.02095  0.61951 -0.22765 -1.21435 -0.22443  0.92740
20Nov23_081052|  -0.77073]
20Nov23_081052| [ 0.59707 -0.56453 -0.65358 -2.34672 -0.32341  0.16786 -1.05250  0.29119
20Nov23_081052|  -0.15825]
20Nov23_081052| [ 1.88803  0.48220 -0.31526  0.39790 -0.28680  0.67641  0.65311 -0.46018
20Nov23_081052|  -0.78346]
20Nov23_081052| [ 1.53749  0.76150 -0.06152  0.94539  1.37221 -1.25450  0.55485  0.75678
20Nov23_081052|   0.28596]
20Nov23_081052| [-0.69501 -0.66292 -0.70443 -0.23586 -1.84727  0.50000  0.72449 -0.29577
20Nov23_081052|  -0.01265]
20Nov23_081052| [ 0.42279  0.38086  0.19830  0.96482 -0.26064  0.21820 -1.36254 -1.67737
20Nov23_081052|   0.09949]
20Nov23_081052| [-0.89380 -0.66418  0.66312 -0.34192  0.52278 -0.76123  0.17047 -2.11020
20Nov23_081052|   0.53196]
20Nov23_081052| [ 0.15779 -0.69696  1.32238 -0.74687 -1.52683 -0.33643 -1.23399 -0.94856
20Nov23_081052|   0.09857]
20Nov23_081052| [ 1.05131 -0.67318 -1.24615 -0.87618 -1.49284 -0.06874  1.07900 -1.14795
20Nov23_081052|   0.17446]
20Nov23_081052| [-0.65091  0.36390  0.43736 -0.20295  0.73984 -1.82535  1.54797 -0.54226
20Nov23_081052|  -0.45832]
20Nov23_081052| [-1.47230 -1.01292 -1.22577  0.13909 -0.22777 -0.64598  0.63506  0.16394
20Nov23_081052|  -0.77675]
20Nov23_081052| [-0.81090  0.15932 -0.32886  0.65237 -0.90740 -1.49863  0.52335  0.66660
20Nov23_081052|  -0.35570]
20Nov23_081052| [-0.38692 -1.11881  1.10759 -0.22649  0.73540 -0.46981  1.45865 -0.85465
20Nov23_081052|   0.06884]
20Nov23_081052| [-0.70397 -0.48164  1.26245  2.11535 -1.40169 -0.46342 -1.17306 -1.46933
20Nov23_081052|  -0.49080]
20Nov23_081052| [-1.10460  1.43416 -0.48554  1.51377  0.64254 -1.76552  1.65956 -0.50608
20Nov23_081052|  -0.54698]
20Nov23_081052| [-0.31011  1.98690  0.38783  0.35508  0.03083  1.34938  1.53292 -0.53171
20Nov23_081052|   0.12150]
20Nov23_081052| [ 0.36149 -0.26401 -0.01935  0.42299  1.37095 -1.27051 -0.18245  0.31588
20Nov23_081052|  -0.29268]
20Nov23_081052| [-1.06074  1.99965  0.69902 -0.86402 -1.29065 -2.35002 -1.28412 -0.72877
20Nov23_081052|  -0.41804]
20Nov23_081052| [-0.84514  0.53515  1.45650  1.07456 -0.31276 -1.39673 -0.46390 -0.11888
20Nov23_081052|  -0.62786]
20Nov23_081052| [-0.68851  1.03186 -0.46824  0.65608 -2.15624  0.15132 -0.07458 -0.29261
20Nov23_081052|   0.83517]
20Nov23_081052| [ 0.33518 -0.03880 -0.91495  0.27963 -1.52199  0.44892 -0.59121 -0.83967
20Nov23_081052|  -0.89924]
20Nov23_081052| [ 1.32436 -0.23291  2.16960 -0.32631 -0.78017  0.23003 -0.45617  2.55819
20Nov23_081052|   0.34619]
20Nov23_081052| [ 0.94408 -0.05989 -0.56402  0.71193 -0.81660 -0.55225 -0.29669  0.64528
20Nov23_081052|   0.32030]]
20Nov23_081052|-- Bias --
20Nov23_081052|[ 0.07637 -0.83169 -0.11893 -0.05433  0.08749 -1.35431  0.38599 -0.57607
20Nov23_081052| -0.06108]
20Nov23_081052|Layer 1:
20Nov23_081052|-- Config --
20Nov23_081052|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 9], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_081052|-- Weights --
20Nov23_081052|[[ 0.70918 -0.98308]
20Nov23_081052| [-0.29153 -0.01013]
20Nov23_081052| [-1.87688 -0.30242]
20Nov23_081052| [-0.40156  0.63724]
20Nov23_081052| [-0.19569  0.07574]
20Nov23_081052| [ 0.27194  0.47916]
20Nov23_081052| [-0.77374 -0.16853]
20Nov23_081052| [ 0.70173  2.03695]
20Nov23_081052| [-0.37282  0.05925]]
20Nov23_081052|-- Bias --
20Nov23_081052|[-0.02520 -0.26371]
20Nov23_081052|Predicting the validation and test data with the Best final individual.
20Nov23_081058| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_081058|-----------  ------------------  --------------------  ----------
20Nov23_081058|Validation         40.96                  9             0.03593
20Nov23_081058|   Test            35.79                  9             0.02667
20Nov23_081058|-------------------------- Test #9 --------------------------
20Nov23_081058|Best final individual weights
20Nov23_081058|Individual:
20Nov23_081058|-- Constant hidden layers --
20Nov23_081058|False
20Nov23_081058|Layer 0:
20Nov23_081058|-- Config --
20Nov23_081058|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 9, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_081058|-- Weights --
20Nov23_081058|[[ 0.17602  1.37005  0.94134  1.05414 -0.21995 -0.52384  1.64542 -0.30457
20Nov23_081058|   0.01296]
20Nov23_081058| [-1.00766  0.55531 -1.99234  0.25526  1.25030 -0.49747 -0.03963 -0.09871
20Nov23_081058|  -0.82622]
20Nov23_081058| [ 0.00435 -0.99825 -0.50688  0.37209 -1.65379 -0.48515 -0.08885  0.45705
20Nov23_081058|   0.37833]
20Nov23_081058| [-0.06184  0.76090  1.13704  1.50787  0.60159  0.44759 -1.32216 -1.49004
20Nov23_081058|  -0.31006]
20Nov23_081058| [ 0.15529 -1.20693 -0.59482  0.77745 -1.52902  1.47965 -0.18784  0.01618
20Nov23_081058|  -0.37143]
20Nov23_081058| [-0.74608  0.51489  0.44418  1.61057  1.02837 -0.39362 -1.59788 -1.41381
20Nov23_081058|  -0.46460]
20Nov23_081058| [-1.22317 -1.34170  0.81731  0.39239 -1.09585 -0.98934 -0.06814  0.95451
20Nov23_081058|   0.34325]
20Nov23_081058| [ 0.18246 -1.70586 -1.09053 -2.24079  1.80462 -0.74800 -1.48499 -0.16259
20Nov23_081058|   0.12309]
20Nov23_081058| [ 0.96105 -1.07518 -0.27790 -0.90632 -0.38456 -0.70881 -0.15062  0.71637
20Nov23_081058|   0.28111]
20Nov23_081058| [ 0.55264  1.68334 -2.12589 -1.32606 -0.58478  0.44290  0.14816 -0.88333
20Nov23_081058|   0.18307]
20Nov23_081058| [ 0.13988 -0.06929  0.19289 -0.32611  0.40154  0.59037 -0.19791  2.35651
20Nov23_081058|   0.17229]
20Nov23_081058| [ 0.30252 -0.30499  1.13260 -0.65187  0.67200  0.80110 -1.14151 -1.25115
20Nov23_081058|  -0.26380]
20Nov23_081058| [ 0.59178 -0.51172 -0.07961  0.79639  1.05492  0.01977 -0.15418 -0.03723
20Nov23_081058|  -0.35638]
20Nov23_081058| [ 0.13793 -0.25043  0.84681  1.03833 -0.43156  0.03462  0.75354 -0.59958
20Nov23_081058|  -0.45743]
20Nov23_081058| [-1.13800  0.66296 -0.55458  0.97392  0.70267 -0.01965 -0.21929 -0.24260
20Nov23_081058|  -0.05331]
20Nov23_081058| [-2.28186 -0.69856 -0.10021 -0.56269  0.03000 -0.45043  0.16882 -0.65293
20Nov23_081058|  -0.27847]
20Nov23_081058| [ 1.79644  1.28884  0.01848  1.38631  1.80935 -0.08050  0.45143 -0.96041
20Nov23_081058|  -0.12371]
20Nov23_081058| [-0.15386 -0.99409 -1.24233 -0.21473 -0.82358 -0.50121  0.06181 -0.86836
20Nov23_081058|   0.07519]
20Nov23_081058| [-0.73128 -0.17146 -0.58581 -0.82587 -1.27548 -0.17385  0.99249  0.11953
20Nov23_081058|  -0.68291]
20Nov23_081058| [-0.76081 -1.42621 -0.45821  0.05531 -0.23330 -0.74949  0.67051  0.32599
20Nov23_081058|  -0.05493]
20Nov23_081058| [-0.29383 -0.96288 -0.35742 -0.56094  0.45025  2.05842  1.07941  0.36440
20Nov23_081058|  -0.04810]
20Nov23_081058| [ 0.16564 -2.39074  1.24141  0.48639 -0.33374  0.61272  1.00614 -0.45470
20Nov23_081058|  -0.06425]
20Nov23_081058| [ 0.05723  1.47602  0.25261  0.41500 -1.05226  0.39387  1.28792 -0.81318
20Nov23_081058|  -0.63875]
20Nov23_081058| [-1.93770  1.50868  0.70201 -1.00910 -0.43689 -1.09291 -0.95173 -2.17974
20Nov23_081058|  -0.40959]
20Nov23_081058| [-1.34704 -0.06302  0.03764  0.27825  0.39591 -0.36483  0.00780 -0.09740
20Nov23_081058|   0.12410]
20Nov23_081058| [-0.74172 -0.16476 -0.61182  0.16789 -0.92203  1.07919  1.19033 -0.36009
20Nov23_081058|  -0.09485]
20Nov23_081058| [ 0.07440  0.36258 -0.18559  0.15582 -0.03425 -0.76748 -0.29371  0.48534
20Nov23_081058|  -0.77123]
20Nov23_081058| [ 0.23529  1.44463  0.89996  0.74943  0.33310 -0.70402  0.64131  0.80355
20Nov23_081058|  -0.07107]
20Nov23_081058| [ 0.91938  0.71058  0.22984 -0.16823 -0.13721  0.86600  0.44650 -0.13527
20Nov23_081058|  -0.38005]
20Nov23_081058| [-0.39765  0.03921 -0.03567  1.00847 -1.22486  0.79469  0.13971  0.28072
20Nov23_081058|  -0.71548]
20Nov23_081058| [-0.64580 -0.15922 -0.29468  0.58904 -0.15741  0.62625  1.90757 -0.29279
20Nov23_081058|   0.32812]
20Nov23_081058| [-0.38675 -0.71577  0.42643 -0.76070 -1.53681  0.05780 -0.06157  0.39549
20Nov23_081058|  -0.21361]
20Nov23_081058| [-1.61786  0.04702 -0.94962  1.39037 -0.53169  0.85972  0.89185 -0.34408
20Nov23_081058|  -0.73590]
20Nov23_081058| [ 0.98571  0.77837  1.07569 -0.35187 -1.37874 -0.14937  0.22572 -0.82999
20Nov23_081058|   0.44736]
20Nov23_081058| [-1.21003 -1.45838  1.02095  0.61951 -0.22765 -1.21435 -0.22443  0.92740
20Nov23_081058|  -0.77073]
20Nov23_081058| [ 0.59707 -0.56453 -0.65358 -2.34672 -0.32341  0.16786 -1.05250  0.29119
20Nov23_081058|  -0.15825]
20Nov23_081058| [ 1.88803  0.48220 -0.31526  0.39790 -0.28680  0.67641  0.65311 -0.46018
20Nov23_081058|  -0.78346]
20Nov23_081058| [ 1.53749  0.76150 -0.06152  0.94539  1.37221 -1.25450  0.55485  0.75678
20Nov23_081058|   0.28596]
20Nov23_081058| [-0.69501 -0.66292 -0.70443 -0.23586 -1.84727  0.50000  0.72449 -0.29577
20Nov23_081058|  -0.01265]
20Nov23_081058| [ 0.42279  0.38086  0.19830  0.96482 -0.26064  0.21820 -1.36254 -1.67737
20Nov23_081058|   0.09949]
20Nov23_081058| [-0.89380 -0.66418  0.66312 -0.34192  0.52278 -0.76123  0.17047 -2.11020
20Nov23_081058|   0.53196]
20Nov23_081058| [ 0.15779 -0.69696  1.32238 -0.74687 -1.52683 -0.33643 -1.23399 -0.94856
20Nov23_081058|   0.09857]
20Nov23_081058| [ 1.05131 -0.67318 -1.24615 -0.87618 -1.49284 -0.06874  1.07900 -1.14795
20Nov23_081058|   0.17446]
20Nov23_081058| [-0.65091  0.36390  0.43736 -0.20295  0.73984 -1.82535  1.54797 -0.54226
20Nov23_081058|  -0.45832]
20Nov23_081058| [-1.47230 -1.01292 -1.22577  0.13909 -0.22777 -0.64598  0.63506  0.16394
20Nov23_081058|  -0.77675]
20Nov23_081058| [-0.81090  0.15932 -0.32886  0.65237 -0.90740 -1.49863  0.52335  0.66660
20Nov23_081058|  -0.35570]
20Nov23_081058| [-0.38692 -1.11881  1.10759 -0.22649  0.73540 -0.46981  1.45865 -0.85465
20Nov23_081058|   0.06884]
20Nov23_081058| [-0.70397 -0.48164  1.26245  2.11535 -1.40169 -0.46342 -1.17306 -1.46933
20Nov23_081058|  -0.49080]
20Nov23_081058| [-1.10460  1.43416 -0.48554  1.51377  0.64254 -1.76552  1.65956 -0.50608
20Nov23_081058|  -0.54698]
20Nov23_081058| [-0.31011  1.98690  0.38783  0.35508  0.03083  1.34938  1.53292 -0.53171
20Nov23_081058|   0.12150]
20Nov23_081058| [ 0.36149 -0.26401 -0.01935  0.42299  1.37095 -1.27051 -0.18245  0.31588
20Nov23_081058|  -0.29268]
20Nov23_081058| [-1.06074  1.99965  0.69902 -0.86402 -1.29065 -2.35002 -1.28412 -0.72877
20Nov23_081058|  -0.41804]
20Nov23_081058| [-0.84514  0.53515  1.45650  1.07456 -0.31276 -1.39673 -0.46390 -0.11888
20Nov23_081058|  -0.62786]
20Nov23_081058| [-0.68851  1.03186 -0.46824  0.65608 -2.15624  0.15132 -0.07458 -0.29261
20Nov23_081058|   0.83517]
20Nov23_081058| [ 0.33518 -0.03880 -0.91495  0.27963 -1.52199  0.44892 -0.59121 -0.83967
20Nov23_081058|  -0.89924]
20Nov23_081058| [ 1.32436 -0.23291  2.16960 -0.32631 -0.78017  0.23003 -0.45617  2.55819
20Nov23_081058|   0.34619]
20Nov23_081058| [ 0.94408 -0.05989 -0.56402  0.71193 -0.81660 -0.55225 -0.29669  0.64528
20Nov23_081058|   0.32030]]
20Nov23_081058|-- Bias --
20Nov23_081058|[ 0.07637 -0.83169 -0.11893 -0.05433  0.08749 -1.35431  0.38599 -0.57607
20Nov23_081058| -0.06108]
20Nov23_081058|Layer 1:
20Nov23_081058|-- Config --
20Nov23_081058|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 9], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_081058|-- Weights --
20Nov23_081058|[[ 0.70918 -0.98308]
20Nov23_081058| [-0.29153 -0.01013]
20Nov23_081058| [-1.87688 -0.30242]
20Nov23_081058| [-0.40156  0.63724]
20Nov23_081058| [-0.19569  0.07574]
20Nov23_081058| [ 0.27194  0.47916]
20Nov23_081058| [-0.77374 -0.16853]
20Nov23_081058| [ 0.70173  2.03695]
20Nov23_081058| [-0.37282  0.05925]]
20Nov23_081058|-- Bias --
20Nov23_081058|[-0.02520 -0.26371]
20Nov23_081058|Predicting the validation and test data with the Best final individual.
20Nov23_081103| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_081103|-----------  ------------------  --------------------  ----------
20Nov23_081103|Validation         38.70                  9             0.16057
20Nov23_081103|   Test            35.97                  9             0.02077
20Nov23_081103|-------------------------- Test #10 --------------------------
20Nov23_081103|Best final individual weights
20Nov23_081103|Individual:
20Nov23_081103|-- Constant hidden layers --
20Nov23_081103|False
20Nov23_081103|Layer 0:
20Nov23_081103|-- Config --
20Nov23_081103|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 9, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_081103|-- Weights --
20Nov23_081103|[[ 0.17602  1.37005  0.94134  1.05414 -0.21995 -0.52384  1.64542 -0.30457
20Nov23_081103|   0.01296]
20Nov23_081103| [-1.00766  0.55531 -1.99234  0.25526  1.25030 -0.49747 -0.03963 -0.09871
20Nov23_081103|  -0.82622]
20Nov23_081103| [ 0.00435 -0.99825 -0.50688  0.37209 -1.65379 -0.48515 -0.08885  0.45705
20Nov23_081103|   0.37833]
20Nov23_081103| [-0.06184  0.76090  1.13704  1.50787  0.60159  0.44759 -1.32216 -1.49004
20Nov23_081103|  -0.31006]
20Nov23_081103| [ 0.15529 -1.20693 -0.59482  0.77745 -1.52902  1.47965 -0.18784  0.01618
20Nov23_081103|  -0.37143]
20Nov23_081103| [-0.74608  0.51489  0.44418  1.61057  1.02837 -0.39362 -1.59788 -1.41381
20Nov23_081103|  -0.46460]
20Nov23_081103| [-1.22317 -1.34170  0.81731  0.39239 -1.09585 -0.98934 -0.06814  0.95451
20Nov23_081103|   0.34325]
20Nov23_081103| [ 0.18246 -1.70586 -1.09053 -2.24079  1.80462 -0.74800 -1.48499 -0.16259
20Nov23_081103|   0.12309]
20Nov23_081103| [ 0.96105 -1.07518 -0.27790 -0.90632 -0.38456 -0.70881 -0.15062  0.71637
20Nov23_081103|   0.28111]
20Nov23_081103| [ 0.55264  1.68334 -2.12589 -1.32606 -0.58478  0.44290  0.14816 -0.88333
20Nov23_081103|   0.18307]
20Nov23_081103| [ 0.13988 -0.06929  0.19289 -0.32611  0.40154  0.59037 -0.19791  2.35651
20Nov23_081103|   0.17229]
20Nov23_081103| [ 0.30252 -0.30499  1.13260 -0.65187  0.67200  0.80110 -1.14151 -1.25115
20Nov23_081103|  -0.26380]
20Nov23_081103| [ 0.59178 -0.51172 -0.07961  0.79639  1.05492  0.01977 -0.15418 -0.03723
20Nov23_081103|  -0.35638]
20Nov23_081103| [ 0.13793 -0.25043  0.84681  1.03833 -0.43156  0.03462  0.75354 -0.59958
20Nov23_081103|  -0.45743]
20Nov23_081103| [-1.13800  0.66296 -0.55458  0.97392  0.70267 -0.01965 -0.21929 -0.24260
20Nov23_081103|  -0.05331]
20Nov23_081103| [-2.28186 -0.69856 -0.10021 -0.56269  0.03000 -0.45043  0.16882 -0.65293
20Nov23_081103|  -0.27847]
20Nov23_081103| [ 1.79644  1.28884  0.01848  1.38631  1.80935 -0.08050  0.45143 -0.96041
20Nov23_081103|  -0.12371]
20Nov23_081103| [-0.15386 -0.99409 -1.24233 -0.21473 -0.82358 -0.50121  0.06181 -0.86836
20Nov23_081103|   0.07519]
20Nov23_081103| [-0.73128 -0.17146 -0.58581 -0.82587 -1.27548 -0.17385  0.99249  0.11953
20Nov23_081103|  -0.68291]
20Nov23_081103| [-0.76081 -1.42621 -0.45821  0.05531 -0.23330 -0.74949  0.67051  0.32599
20Nov23_081103|  -0.05493]
20Nov23_081103| [-0.29383 -0.96288 -0.35742 -0.56094  0.45025  2.05842  1.07941  0.36440
20Nov23_081103|  -0.04810]
20Nov23_081103| [ 0.16564 -2.39074  1.24141  0.48639 -0.33374  0.61272  1.00614 -0.45470
20Nov23_081103|  -0.06425]
20Nov23_081103| [ 0.05723  1.47602  0.25261  0.41500 -1.05226  0.39387  1.28792 -0.81318
20Nov23_081103|  -0.63875]
20Nov23_081103| [-1.93770  1.50868  0.70201 -1.00910 -0.43689 -1.09291 -0.95173 -2.17974
20Nov23_081103|  -0.40959]
20Nov23_081103| [-1.34704 -0.06302  0.03764  0.27825  0.39591 -0.36483  0.00780 -0.09740
20Nov23_081103|   0.12410]
20Nov23_081103| [-0.74172 -0.16476 -0.61182  0.16789 -0.92203  1.07919  1.19033 -0.36009
20Nov23_081103|  -0.09485]
20Nov23_081103| [ 0.07440  0.36258 -0.18559  0.15582 -0.03425 -0.76748 -0.29371  0.48534
20Nov23_081103|  -0.77123]
20Nov23_081103| [ 0.23529  1.44463  0.89996  0.74943  0.33310 -0.70402  0.64131  0.80355
20Nov23_081103|  -0.07107]
20Nov23_081103| [ 0.91938  0.71058  0.22984 -0.16823 -0.13721  0.86600  0.44650 -0.13527
20Nov23_081103|  -0.38005]
20Nov23_081103| [-0.39765  0.03921 -0.03567  1.00847 -1.22486  0.79469  0.13971  0.28072
20Nov23_081103|  -0.71548]
20Nov23_081103| [-0.64580 -0.15922 -0.29468  0.58904 -0.15741  0.62625  1.90757 -0.29279
20Nov23_081103|   0.32812]
20Nov23_081103| [-0.38675 -0.71577  0.42643 -0.76070 -1.53681  0.05780 -0.06157  0.39549
20Nov23_081103|  -0.21361]
20Nov23_081103| [-1.61786  0.04702 -0.94962  1.39037 -0.53169  0.85972  0.89185 -0.34408
20Nov23_081103|  -0.73590]
20Nov23_081103| [ 0.98571  0.77837  1.07569 -0.35187 -1.37874 -0.14937  0.22572 -0.82999
20Nov23_081103|   0.44736]
20Nov23_081103| [-1.21003 -1.45838  1.02095  0.61951 -0.22765 -1.21435 -0.22443  0.92740
20Nov23_081103|  -0.77073]
20Nov23_081103| [ 0.59707 -0.56453 -0.65358 -2.34672 -0.32341  0.16786 -1.05250  0.29119
20Nov23_081103|  -0.15825]
20Nov23_081103| [ 1.88803  0.48220 -0.31526  0.39790 -0.28680  0.67641  0.65311 -0.46018
20Nov23_081103|  -0.78346]
20Nov23_081103| [ 1.53749  0.76150 -0.06152  0.94539  1.37221 -1.25450  0.55485  0.75678
20Nov23_081103|   0.28596]
20Nov23_081103| [-0.69501 -0.66292 -0.70443 -0.23586 -1.84727  0.50000  0.72449 -0.29577
20Nov23_081103|  -0.01265]
20Nov23_081103| [ 0.42279  0.38086  0.19830  0.96482 -0.26064  0.21820 -1.36254 -1.67737
20Nov23_081103|   0.09949]
20Nov23_081103| [-0.89380 -0.66418  0.66312 -0.34192  0.52278 -0.76123  0.17047 -2.11020
20Nov23_081103|   0.53196]
20Nov23_081103| [ 0.15779 -0.69696  1.32238 -0.74687 -1.52683 -0.33643 -1.23399 -0.94856
20Nov23_081103|   0.09857]
20Nov23_081103| [ 1.05131 -0.67318 -1.24615 -0.87618 -1.49284 -0.06874  1.07900 -1.14795
20Nov23_081103|   0.17446]
20Nov23_081103| [-0.65091  0.36390  0.43736 -0.20295  0.73984 -1.82535  1.54797 -0.54226
20Nov23_081103|  -0.45832]
20Nov23_081103| [-1.47230 -1.01292 -1.22577  0.13909 -0.22777 -0.64598  0.63506  0.16394
20Nov23_081103|  -0.77675]
20Nov23_081103| [-0.81090  0.15932 -0.32886  0.65237 -0.90740 -1.49863  0.52335  0.66660
20Nov23_081103|  -0.35570]
20Nov23_081103| [-0.38692 -1.11881  1.10759 -0.22649  0.73540 -0.46981  1.45865 -0.85465
20Nov23_081103|   0.06884]
20Nov23_081103| [-0.70397 -0.48164  1.26245  2.11535 -1.40169 -0.46342 -1.17306 -1.46933
20Nov23_081103|  -0.49080]
20Nov23_081103| [-1.10460  1.43416 -0.48554  1.51377  0.64254 -1.76552  1.65956 -0.50608
20Nov23_081103|  -0.54698]
20Nov23_081103| [-0.31011  1.98690  0.38783  0.35508  0.03083  1.34938  1.53292 -0.53171
20Nov23_081103|   0.12150]
20Nov23_081103| [ 0.36149 -0.26401 -0.01935  0.42299  1.37095 -1.27051 -0.18245  0.31588
20Nov23_081103|  -0.29268]
20Nov23_081103| [-1.06074  1.99965  0.69902 -0.86402 -1.29065 -2.35002 -1.28412 -0.72877
20Nov23_081103|  -0.41804]
20Nov23_081103| [-0.84514  0.53515  1.45650  1.07456 -0.31276 -1.39673 -0.46390 -0.11888
20Nov23_081103|  -0.62786]
20Nov23_081103| [-0.68851  1.03186 -0.46824  0.65608 -2.15624  0.15132 -0.07458 -0.29261
20Nov23_081103|   0.83517]
20Nov23_081103| [ 0.33518 -0.03880 -0.91495  0.27963 -1.52199  0.44892 -0.59121 -0.83967
20Nov23_081103|  -0.89924]
20Nov23_081103| [ 1.32436 -0.23291  2.16960 -0.32631 -0.78017  0.23003 -0.45617  2.55819
20Nov23_081103|   0.34619]
20Nov23_081103| [ 0.94408 -0.05989 -0.56402  0.71193 -0.81660 -0.55225 -0.29669  0.64528
20Nov23_081103|   0.32030]]
20Nov23_081103|-- Bias --
20Nov23_081103|[ 0.07637 -0.83169 -0.11893 -0.05433  0.08749 -1.35431  0.38599 -0.57607
20Nov23_081103| -0.06108]
20Nov23_081103|Layer 1:
20Nov23_081103|-- Config --
20Nov23_081103|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 9], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_081103|-- Weights --
20Nov23_081103|[[ 0.70918 -0.98308]
20Nov23_081103| [-0.29153 -0.01013]
20Nov23_081103| [-1.87688 -0.30242]
20Nov23_081103| [-0.40156  0.63724]
20Nov23_081103| [-0.19569  0.07574]
20Nov23_081103| [ 0.27194  0.47916]
20Nov23_081103| [-0.77374 -0.16853]
20Nov23_081103| [ 0.70173  2.03695]
20Nov23_081103| [-0.37282  0.05925]]
20Nov23_081103|-- Bias --
20Nov23_081103|[-0.02520 -0.26371]
20Nov23_081103|Predicting the validation and test data with the Best final individual.
20Nov23_081109| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_081109|-----------  ------------------  --------------------  ----------
20Nov23_081109|Validation         28.96                  9             0.51471
20Nov23_081109|   Test            35.79                  9             0.02960
20Nov23_081109|-------------------------- Test #11 --------------------------
20Nov23_081109|Best final individual weights
20Nov23_081109|Individual:
20Nov23_081109|-- Constant hidden layers --
20Nov23_081109|False
20Nov23_081109|Layer 0:
20Nov23_081109|-- Config --
20Nov23_081109|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 9, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_081109|-- Weights --
20Nov23_081109|[[ 0.17602  1.37005  0.94134  1.05414 -0.21995 -0.52384  1.64542 -0.30457
20Nov23_081109|   0.01296]
20Nov23_081109| [-1.00766  0.55531 -1.99234  0.25526  1.25030 -0.49747 -0.03963 -0.09871
20Nov23_081109|  -0.82622]
20Nov23_081109| [ 0.00435 -0.99825 -0.50688  0.37209 -1.65379 -0.48515 -0.08885  0.45705
20Nov23_081109|   0.37833]
20Nov23_081109| [-0.06184  0.76090  1.13704  1.50787  0.60159  0.44759 -1.32216 -1.49004
20Nov23_081109|  -0.31006]
20Nov23_081109| [ 0.15529 -1.20693 -0.59482  0.77745 -1.52902  1.47965 -0.18784  0.01618
20Nov23_081109|  -0.37143]
20Nov23_081109| [-0.74608  0.51489  0.44418  1.61057  1.02837 -0.39362 -1.59788 -1.41381
20Nov23_081109|  -0.46460]
20Nov23_081109| [-1.22317 -1.34170  0.81731  0.39239 -1.09585 -0.98934 -0.06814  0.95451
20Nov23_081109|   0.34325]
20Nov23_081109| [ 0.18246 -1.70586 -1.09053 -2.24079  1.80462 -0.74800 -1.48499 -0.16259
20Nov23_081109|   0.12309]
20Nov23_081109| [ 0.96105 -1.07518 -0.27790 -0.90632 -0.38456 -0.70881 -0.15062  0.71637
20Nov23_081109|   0.28111]
20Nov23_081109| [ 0.55264  1.68334 -2.12589 -1.32606 -0.58478  0.44290  0.14816 -0.88333
20Nov23_081109|   0.18307]
20Nov23_081109| [ 0.13988 -0.06929  0.19289 -0.32611  0.40154  0.59037 -0.19791  2.35651
20Nov23_081109|   0.17229]
20Nov23_081109| [ 0.30252 -0.30499  1.13260 -0.65187  0.67200  0.80110 -1.14151 -1.25115
20Nov23_081109|  -0.26380]
20Nov23_081109| [ 0.59178 -0.51172 -0.07961  0.79639  1.05492  0.01977 -0.15418 -0.03723
20Nov23_081109|  -0.35638]
20Nov23_081109| [ 0.13793 -0.25043  0.84681  1.03833 -0.43156  0.03462  0.75354 -0.59958
20Nov23_081109|  -0.45743]
20Nov23_081109| [-1.13800  0.66296 -0.55458  0.97392  0.70267 -0.01965 -0.21929 -0.24260
20Nov23_081109|  -0.05331]
20Nov23_081109| [-2.28186 -0.69856 -0.10021 -0.56269  0.03000 -0.45043  0.16882 -0.65293
20Nov23_081109|  -0.27847]
20Nov23_081109| [ 1.79644  1.28884  0.01848  1.38631  1.80935 -0.08050  0.45143 -0.96041
20Nov23_081109|  -0.12371]
20Nov23_081109| [-0.15386 -0.99409 -1.24233 -0.21473 -0.82358 -0.50121  0.06181 -0.86836
20Nov23_081109|   0.07519]
20Nov23_081109| [-0.73128 -0.17146 -0.58581 -0.82587 -1.27548 -0.17385  0.99249  0.11953
20Nov23_081109|  -0.68291]
20Nov23_081109| [-0.76081 -1.42621 -0.45821  0.05531 -0.23330 -0.74949  0.67051  0.32599
20Nov23_081109|  -0.05493]
20Nov23_081109| [-0.29383 -0.96288 -0.35742 -0.56094  0.45025  2.05842  1.07941  0.36440
20Nov23_081109|  -0.04810]
20Nov23_081109| [ 0.16564 -2.39074  1.24141  0.48639 -0.33374  0.61272  1.00614 -0.45470
20Nov23_081109|  -0.06425]
20Nov23_081109| [ 0.05723  1.47602  0.25261  0.41500 -1.05226  0.39387  1.28792 -0.81318
20Nov23_081109|  -0.63875]
20Nov23_081109| [-1.93770  1.50868  0.70201 -1.00910 -0.43689 -1.09291 -0.95173 -2.17974
20Nov23_081109|  -0.40959]
20Nov23_081109| [-1.34704 -0.06302  0.03764  0.27825  0.39591 -0.36483  0.00780 -0.09740
20Nov23_081109|   0.12410]
20Nov23_081109| [-0.74172 -0.16476 -0.61182  0.16789 -0.92203  1.07919  1.19033 -0.36009
20Nov23_081109|  -0.09485]
20Nov23_081109| [ 0.07440  0.36258 -0.18559  0.15582 -0.03425 -0.76748 -0.29371  0.48534
20Nov23_081109|  -0.77123]
20Nov23_081109| [ 0.23529  1.44463  0.89996  0.74943  0.33310 -0.70402  0.64131  0.80355
20Nov23_081109|  -0.07107]
20Nov23_081109| [ 0.91938  0.71058  0.22984 -0.16823 -0.13721  0.86600  0.44650 -0.13527
20Nov23_081109|  -0.38005]
20Nov23_081109| [-0.39765  0.03921 -0.03567  1.00847 -1.22486  0.79469  0.13971  0.28072
20Nov23_081109|  -0.71548]
20Nov23_081109| [-0.64580 -0.15922 -0.29468  0.58904 -0.15741  0.62625  1.90757 -0.29279
20Nov23_081109|   0.32812]
20Nov23_081109| [-0.38675 -0.71577  0.42643 -0.76070 -1.53681  0.05780 -0.06157  0.39549
20Nov23_081109|  -0.21361]
20Nov23_081109| [-1.61786  0.04702 -0.94962  1.39037 -0.53169  0.85972  0.89185 -0.34408
20Nov23_081109|  -0.73590]
20Nov23_081109| [ 0.98571  0.77837  1.07569 -0.35187 -1.37874 -0.14937  0.22572 -0.82999
20Nov23_081109|   0.44736]
20Nov23_081109| [-1.21003 -1.45838  1.02095  0.61951 -0.22765 -1.21435 -0.22443  0.92740
20Nov23_081109|  -0.77073]
20Nov23_081109| [ 0.59707 -0.56453 -0.65358 -2.34672 -0.32341  0.16786 -1.05250  0.29119
20Nov23_081109|  -0.15825]
20Nov23_081109| [ 1.88803  0.48220 -0.31526  0.39790 -0.28680  0.67641  0.65311 -0.46018
20Nov23_081109|  -0.78346]
20Nov23_081109| [ 1.53749  0.76150 -0.06152  0.94539  1.37221 -1.25450  0.55485  0.75678
20Nov23_081109|   0.28596]
20Nov23_081109| [-0.69501 -0.66292 -0.70443 -0.23586 -1.84727  0.50000  0.72449 -0.29577
20Nov23_081109|  -0.01265]
20Nov23_081109| [ 0.42279  0.38086  0.19830  0.96482 -0.26064  0.21820 -1.36254 -1.67737
20Nov23_081109|   0.09949]
20Nov23_081109| [-0.89380 -0.66418  0.66312 -0.34192  0.52278 -0.76123  0.17047 -2.11020
20Nov23_081109|   0.53196]
20Nov23_081109| [ 0.15779 -0.69696  1.32238 -0.74687 -1.52683 -0.33643 -1.23399 -0.94856
20Nov23_081109|   0.09857]
20Nov23_081109| [ 1.05131 -0.67318 -1.24615 -0.87618 -1.49284 -0.06874  1.07900 -1.14795
20Nov23_081109|   0.17446]
20Nov23_081109| [-0.65091  0.36390  0.43736 -0.20295  0.73984 -1.82535  1.54797 -0.54226
20Nov23_081109|  -0.45832]
20Nov23_081109| [-1.47230 -1.01292 -1.22577  0.13909 -0.22777 -0.64598  0.63506  0.16394
20Nov23_081109|  -0.77675]
20Nov23_081109| [-0.81090  0.15932 -0.32886  0.65237 -0.90740 -1.49863  0.52335  0.66660
20Nov23_081109|  -0.35570]
20Nov23_081109| [-0.38692 -1.11881  1.10759 -0.22649  0.73540 -0.46981  1.45865 -0.85465
20Nov23_081109|   0.06884]
20Nov23_081109| [-0.70397 -0.48164  1.26245  2.11535 -1.40169 -0.46342 -1.17306 -1.46933
20Nov23_081109|  -0.49080]
20Nov23_081109| [-1.10460  1.43416 -0.48554  1.51377  0.64254 -1.76552  1.65956 -0.50608
20Nov23_081109|  -0.54698]
20Nov23_081109| [-0.31011  1.98690  0.38783  0.35508  0.03083  1.34938  1.53292 -0.53171
20Nov23_081109|   0.12150]
20Nov23_081109| [ 0.36149 -0.26401 -0.01935  0.42299  1.37095 -1.27051 -0.18245  0.31588
20Nov23_081109|  -0.29268]
20Nov23_081109| [-1.06074  1.99965  0.69902 -0.86402 -1.29065 -2.35002 -1.28412 -0.72877
20Nov23_081109|  -0.41804]
20Nov23_081109| [-0.84514  0.53515  1.45650  1.07456 -0.31276 -1.39673 -0.46390 -0.11888
20Nov23_081109|  -0.62786]
20Nov23_081109| [-0.68851  1.03186 -0.46824  0.65608 -2.15624  0.15132 -0.07458 -0.29261
20Nov23_081109|   0.83517]
20Nov23_081109| [ 0.33518 -0.03880 -0.91495  0.27963 -1.52199  0.44892 -0.59121 -0.83967
20Nov23_081109|  -0.89924]
20Nov23_081109| [ 1.32436 -0.23291  2.16960 -0.32631 -0.78017  0.23003 -0.45617  2.55819
20Nov23_081109|   0.34619]
20Nov23_081109| [ 0.94408 -0.05989 -0.56402  0.71193 -0.81660 -0.55225 -0.29669  0.64528
20Nov23_081109|   0.32030]]
20Nov23_081109|-- Bias --
20Nov23_081109|[ 0.07637 -0.83169 -0.11893 -0.05433  0.08749 -1.35431  0.38599 -0.57607
20Nov23_081109| -0.06108]
20Nov23_081109|Layer 1:
20Nov23_081109|-- Config --
20Nov23_081109|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 9], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_081109|-- Weights --
20Nov23_081109|[[ 0.70918 -0.98308]
20Nov23_081109| [-0.29153 -0.01013]
20Nov23_081109| [-1.87688 -0.30242]
20Nov23_081109| [-0.40156  0.63724]
20Nov23_081109| [-0.19569  0.07574]
20Nov23_081109| [ 0.27194  0.47916]
20Nov23_081109| [-0.77374 -0.16853]
20Nov23_081109| [ 0.70173  2.03695]
20Nov23_081109| [-0.37282  0.05925]]
20Nov23_081109|-- Bias --
20Nov23_081109|[-0.02520 -0.26371]
20Nov23_081109|Predicting the validation and test data with the Best final individual.
20Nov23_081114| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_081114|-----------  ------------------  --------------------  ----------
20Nov23_081114|Validation         40.43                  9             0.05618
20Nov23_081114|   Test            35.19                  9             0.05875
20Nov23_081114|-------------------------- Test #12 --------------------------
20Nov23_081114|Best final individual weights
20Nov23_081114|Individual:
20Nov23_081114|-- Constant hidden layers --
20Nov23_081114|False
20Nov23_081114|Layer 0:
20Nov23_081114|-- Config --
20Nov23_081114|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 9, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_081114|-- Weights --
20Nov23_081114|[[ 0.17602  1.37005  0.94134  1.05414 -0.21995 -0.52384  1.64542 -0.30457
20Nov23_081114|   0.01296]
20Nov23_081114| [-1.00766  0.55531 -1.99234  0.25526  1.25030 -0.49747 -0.03963 -0.09871
20Nov23_081114|  -0.82622]
20Nov23_081114| [ 0.00435 -0.99825 -0.50688  0.37209 -1.65379 -0.48515 -0.08885  0.45705
20Nov23_081114|   0.37833]
20Nov23_081114| [-0.06184  0.76090  1.13704  1.50787  0.60159  0.44759 -1.32216 -1.49004
20Nov23_081114|  -0.31006]
20Nov23_081114| [ 0.15529 -1.20693 -0.59482  0.77745 -1.52902  1.47965 -0.18784  0.01618
20Nov23_081114|  -0.37143]
20Nov23_081114| [-0.74608  0.51489  0.44418  1.61057  1.02837 -0.39362 -1.59788 -1.41381
20Nov23_081114|  -0.46460]
20Nov23_081114| [-1.22317 -1.34170  0.81731  0.39239 -1.09585 -0.98934 -0.06814  0.95451
20Nov23_081114|   0.34325]
20Nov23_081114| [ 0.18246 -1.70586 -1.09053 -2.24079  1.80462 -0.74800 -1.48499 -0.16259
20Nov23_081114|   0.12309]
20Nov23_081114| [ 0.96105 -1.07518 -0.27790 -0.90632 -0.38456 -0.70881 -0.15062  0.71637
20Nov23_081114|   0.28111]
20Nov23_081114| [ 0.55264  1.68334 -2.12589 -1.32606 -0.58478  0.44290  0.14816 -0.88333
20Nov23_081114|   0.18307]
20Nov23_081114| [ 0.13988 -0.06929  0.19289 -0.32611  0.40154  0.59037 -0.19791  2.35651
20Nov23_081114|   0.17229]
20Nov23_081114| [ 0.30252 -0.30499  1.13260 -0.65187  0.67200  0.80110 -1.14151 -1.25115
20Nov23_081114|  -0.26380]
20Nov23_081114| [ 0.59178 -0.51172 -0.07961  0.79639  1.05492  0.01977 -0.15418 -0.03723
20Nov23_081114|  -0.35638]
20Nov23_081114| [ 0.13793 -0.25043  0.84681  1.03833 -0.43156  0.03462  0.75354 -0.59958
20Nov23_081114|  -0.45743]
20Nov23_081114| [-1.13800  0.66296 -0.55458  0.97392  0.70267 -0.01965 -0.21929 -0.24260
20Nov23_081114|  -0.05331]
20Nov23_081114| [-2.28186 -0.69856 -0.10021 -0.56269  0.03000 -0.45043  0.16882 -0.65293
20Nov23_081114|  -0.27847]
20Nov23_081114| [ 1.79644  1.28884  0.01848  1.38631  1.80935 -0.08050  0.45143 -0.96041
20Nov23_081114|  -0.12371]
20Nov23_081114| [-0.15386 -0.99409 -1.24233 -0.21473 -0.82358 -0.50121  0.06181 -0.86836
20Nov23_081114|   0.07519]
20Nov23_081114| [-0.73128 -0.17146 -0.58581 -0.82587 -1.27548 -0.17385  0.99249  0.11953
20Nov23_081114|  -0.68291]
20Nov23_081114| [-0.76081 -1.42621 -0.45821  0.05531 -0.23330 -0.74949  0.67051  0.32599
20Nov23_081114|  -0.05493]
20Nov23_081114| [-0.29383 -0.96288 -0.35742 -0.56094  0.45025  2.05842  1.07941  0.36440
20Nov23_081114|  -0.04810]
20Nov23_081114| [ 0.16564 -2.39074  1.24141  0.48639 -0.33374  0.61272  1.00614 -0.45470
20Nov23_081114|  -0.06425]
20Nov23_081114| [ 0.05723  1.47602  0.25261  0.41500 -1.05226  0.39387  1.28792 -0.81318
20Nov23_081114|  -0.63875]
20Nov23_081114| [-1.93770  1.50868  0.70201 -1.00910 -0.43689 -1.09291 -0.95173 -2.17974
20Nov23_081114|  -0.40959]
20Nov23_081114| [-1.34704 -0.06302  0.03764  0.27825  0.39591 -0.36483  0.00780 -0.09740
20Nov23_081114|   0.12410]
20Nov23_081114| [-0.74172 -0.16476 -0.61182  0.16789 -0.92203  1.07919  1.19033 -0.36009
20Nov23_081114|  -0.09485]
20Nov23_081114| [ 0.07440  0.36258 -0.18559  0.15582 -0.03425 -0.76748 -0.29371  0.48534
20Nov23_081114|  -0.77123]
20Nov23_081114| [ 0.23529  1.44463  0.89996  0.74943  0.33310 -0.70402  0.64131  0.80355
20Nov23_081114|  -0.07107]
20Nov23_081114| [ 0.91938  0.71058  0.22984 -0.16823 -0.13721  0.86600  0.44650 -0.13527
20Nov23_081114|  -0.38005]
20Nov23_081114| [-0.39765  0.03921 -0.03567  1.00847 -1.22486  0.79469  0.13971  0.28072
20Nov23_081114|  -0.71548]
20Nov23_081114| [-0.64580 -0.15922 -0.29468  0.58904 -0.15741  0.62625  1.90757 -0.29279
20Nov23_081114|   0.32812]
20Nov23_081114| [-0.38675 -0.71577  0.42643 -0.76070 -1.53681  0.05780 -0.06157  0.39549
20Nov23_081114|  -0.21361]
20Nov23_081114| [-1.61786  0.04702 -0.94962  1.39037 -0.53169  0.85972  0.89185 -0.34408
20Nov23_081114|  -0.73590]
20Nov23_081114| [ 0.98571  0.77837  1.07569 -0.35187 -1.37874 -0.14937  0.22572 -0.82999
20Nov23_081114|   0.44736]
20Nov23_081114| [-1.21003 -1.45838  1.02095  0.61951 -0.22765 -1.21435 -0.22443  0.92740
20Nov23_081114|  -0.77073]
20Nov23_081114| [ 0.59707 -0.56453 -0.65358 -2.34672 -0.32341  0.16786 -1.05250  0.29119
20Nov23_081114|  -0.15825]
20Nov23_081114| [ 1.88803  0.48220 -0.31526  0.39790 -0.28680  0.67641  0.65311 -0.46018
20Nov23_081114|  -0.78346]
20Nov23_081114| [ 1.53749  0.76150 -0.06152  0.94539  1.37221 -1.25450  0.55485  0.75678
20Nov23_081114|   0.28596]
20Nov23_081114| [-0.69501 -0.66292 -0.70443 -0.23586 -1.84727  0.50000  0.72449 -0.29577
20Nov23_081114|  -0.01265]
20Nov23_081114| [ 0.42279  0.38086  0.19830  0.96482 -0.26064  0.21820 -1.36254 -1.67737
20Nov23_081114|   0.09949]
20Nov23_081114| [-0.89380 -0.66418  0.66312 -0.34192  0.52278 -0.76123  0.17047 -2.11020
20Nov23_081114|   0.53196]
20Nov23_081114| [ 0.15779 -0.69696  1.32238 -0.74687 -1.52683 -0.33643 -1.23399 -0.94856
20Nov23_081114|   0.09857]
20Nov23_081114| [ 1.05131 -0.67318 -1.24615 -0.87618 -1.49284 -0.06874  1.07900 -1.14795
20Nov23_081114|   0.17446]
20Nov23_081114| [-0.65091  0.36390  0.43736 -0.20295  0.73984 -1.82535  1.54797 -0.54226
20Nov23_081114|  -0.45832]
20Nov23_081114| [-1.47230 -1.01292 -1.22577  0.13909 -0.22777 -0.64598  0.63506  0.16394
20Nov23_081114|  -0.77675]
20Nov23_081114| [-0.81090  0.15932 -0.32886  0.65237 -0.90740 -1.49863  0.52335  0.66660
20Nov23_081114|  -0.35570]
20Nov23_081114| [-0.38692 -1.11881  1.10759 -0.22649  0.73540 -0.46981  1.45865 -0.85465
20Nov23_081114|   0.06884]
20Nov23_081114| [-0.70397 -0.48164  1.26245  2.11535 -1.40169 -0.46342 -1.17306 -1.46933
20Nov23_081114|  -0.49080]
20Nov23_081114| [-1.10460  1.43416 -0.48554  1.51377  0.64254 -1.76552  1.65956 -0.50608
20Nov23_081114|  -0.54698]
20Nov23_081114| [-0.31011  1.98690  0.38783  0.35508  0.03083  1.34938  1.53292 -0.53171
20Nov23_081114|   0.12150]
20Nov23_081114| [ 0.36149 -0.26401 -0.01935  0.42299  1.37095 -1.27051 -0.18245  0.31588
20Nov23_081114|  -0.29268]
20Nov23_081114| [-1.06074  1.99965  0.69902 -0.86402 -1.29065 -2.35002 -1.28412 -0.72877
20Nov23_081114|  -0.41804]
20Nov23_081114| [-0.84514  0.53515  1.45650  1.07456 -0.31276 -1.39673 -0.46390 -0.11888
20Nov23_081114|  -0.62786]
20Nov23_081114| [-0.68851  1.03186 -0.46824  0.65608 -2.15624  0.15132 -0.07458 -0.29261
20Nov23_081114|   0.83517]
20Nov23_081114| [ 0.33518 -0.03880 -0.91495  0.27963 -1.52199  0.44892 -0.59121 -0.83967
20Nov23_081114|  -0.89924]
20Nov23_081114| [ 1.32436 -0.23291  2.16960 -0.32631 -0.78017  0.23003 -0.45617  2.55819
20Nov23_081114|   0.34619]
20Nov23_081114| [ 0.94408 -0.05989 -0.56402  0.71193 -0.81660 -0.55225 -0.29669  0.64528
20Nov23_081114|   0.32030]]
20Nov23_081114|-- Bias --
20Nov23_081114|[ 0.07637 -0.83169 -0.11893 -0.05433  0.08749 -1.35431  0.38599 -0.57607
20Nov23_081114| -0.06108]
20Nov23_081114|Layer 1:
20Nov23_081114|-- Config --
20Nov23_081114|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 9], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_081114|-- Weights --
20Nov23_081114|[[ 0.70918 -0.98308]
20Nov23_081114| [-0.29153 -0.01013]
20Nov23_081114| [-1.87688 -0.30242]
20Nov23_081114| [-0.40156  0.63724]
20Nov23_081114| [-0.19569  0.07574]
20Nov23_081114| [ 0.27194  0.47916]
20Nov23_081114| [-0.77374 -0.16853]
20Nov23_081114| [ 0.70173  2.03695]
20Nov23_081114| [-0.37282  0.05925]]
20Nov23_081114|-- Bias --
20Nov23_081114|[-0.02520 -0.26371]
20Nov23_081114|Predicting the validation and test data with the Best final individual.
20Nov23_081120| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_081120|-----------  ------------------  --------------------  ----------
20Nov23_081120|Validation         40.96                  9             0.03340
20Nov23_081120|   Test            35.88                  9             0.02078
20Nov23_081120|-------------------------- Test #13 --------------------------
20Nov23_081120|Best final individual weights
20Nov23_081120|Individual:
20Nov23_081120|-- Constant hidden layers --
20Nov23_081120|False
20Nov23_081120|Layer 0:
20Nov23_081120|-- Config --
20Nov23_081120|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 9, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_081120|-- Weights --
20Nov23_081120|[[ 0.17602  1.37005  0.94134  1.05414 -0.21995 -0.52384  1.64542 -0.30457
20Nov23_081120|   0.01296]
20Nov23_081120| [-1.00766  0.55531 -1.99234  0.25526  1.25030 -0.49747 -0.03963 -0.09871
20Nov23_081120|  -0.82622]
20Nov23_081120| [ 0.00435 -0.99825 -0.50688  0.37209 -1.65379 -0.48515 -0.08885  0.45705
20Nov23_081120|   0.37833]
20Nov23_081120| [-0.06184  0.76090  1.13704  1.50787  0.60159  0.44759 -1.32216 -1.49004
20Nov23_081120|  -0.31006]
20Nov23_081120| [ 0.15529 -1.20693 -0.59482  0.77745 -1.52902  1.47965 -0.18784  0.01618
20Nov23_081120|  -0.37143]
20Nov23_081120| [-0.74608  0.51489  0.44418  1.61057  1.02837 -0.39362 -1.59788 -1.41381
20Nov23_081120|  -0.46460]
20Nov23_081120| [-1.22317 -1.34170  0.81731  0.39239 -1.09585 -0.98934 -0.06814  0.95451
20Nov23_081120|   0.34325]
20Nov23_081120| [ 0.18246 -1.70586 -1.09053 -2.24079  1.80462 -0.74800 -1.48499 -0.16259
20Nov23_081120|   0.12309]
20Nov23_081120| [ 0.96105 -1.07518 -0.27790 -0.90632 -0.38456 -0.70881 -0.15062  0.71637
20Nov23_081120|   0.28111]
20Nov23_081120| [ 0.55264  1.68334 -2.12589 -1.32606 -0.58478  0.44290  0.14816 -0.88333
20Nov23_081120|   0.18307]
20Nov23_081120| [ 0.13988 -0.06929  0.19289 -0.32611  0.40154  0.59037 -0.19791  2.35651
20Nov23_081120|   0.17229]
20Nov23_081120| [ 0.30252 -0.30499  1.13260 -0.65187  0.67200  0.80110 -1.14151 -1.25115
20Nov23_081120|  -0.26380]
20Nov23_081120| [ 0.59178 -0.51172 -0.07961  0.79639  1.05492  0.01977 -0.15418 -0.03723
20Nov23_081120|  -0.35638]
20Nov23_081120| [ 0.13793 -0.25043  0.84681  1.03833 -0.43156  0.03462  0.75354 -0.59958
20Nov23_081120|  -0.45743]
20Nov23_081120| [-1.13800  0.66296 -0.55458  0.97392  0.70267 -0.01965 -0.21929 -0.24260
20Nov23_081120|  -0.05331]
20Nov23_081120| [-2.28186 -0.69856 -0.10021 -0.56269  0.03000 -0.45043  0.16882 -0.65293
20Nov23_081120|  -0.27847]
20Nov23_081120| [ 1.79644  1.28884  0.01848  1.38631  1.80935 -0.08050  0.45143 -0.96041
20Nov23_081120|  -0.12371]
20Nov23_081120| [-0.15386 -0.99409 -1.24233 -0.21473 -0.82358 -0.50121  0.06181 -0.86836
20Nov23_081120|   0.07519]
20Nov23_081120| [-0.73128 -0.17146 -0.58581 -0.82587 -1.27548 -0.17385  0.99249  0.11953
20Nov23_081120|  -0.68291]
20Nov23_081120| [-0.76081 -1.42621 -0.45821  0.05531 -0.23330 -0.74949  0.67051  0.32599
20Nov23_081120|  -0.05493]
20Nov23_081120| [-0.29383 -0.96288 -0.35742 -0.56094  0.45025  2.05842  1.07941  0.36440
20Nov23_081120|  -0.04810]
20Nov23_081120| [ 0.16564 -2.39074  1.24141  0.48639 -0.33374  0.61272  1.00614 -0.45470
20Nov23_081120|  -0.06425]
20Nov23_081120| [ 0.05723  1.47602  0.25261  0.41500 -1.05226  0.39387  1.28792 -0.81318
20Nov23_081120|  -0.63875]
20Nov23_081120| [-1.93770  1.50868  0.70201 -1.00910 -0.43689 -1.09291 -0.95173 -2.17974
20Nov23_081120|  -0.40959]
20Nov23_081120| [-1.34704 -0.06302  0.03764  0.27825  0.39591 -0.36483  0.00780 -0.09740
20Nov23_081120|   0.12410]
20Nov23_081120| [-0.74172 -0.16476 -0.61182  0.16789 -0.92203  1.07919  1.19033 -0.36009
20Nov23_081120|  -0.09485]
20Nov23_081120| [ 0.07440  0.36258 -0.18559  0.15582 -0.03425 -0.76748 -0.29371  0.48534
20Nov23_081120|  -0.77123]
20Nov23_081120| [ 0.23529  1.44463  0.89996  0.74943  0.33310 -0.70402  0.64131  0.80355
20Nov23_081120|  -0.07107]
20Nov23_081120| [ 0.91938  0.71058  0.22984 -0.16823 -0.13721  0.86600  0.44650 -0.13527
20Nov23_081120|  -0.38005]
20Nov23_081120| [-0.39765  0.03921 -0.03567  1.00847 -1.22486  0.79469  0.13971  0.28072
20Nov23_081120|  -0.71548]
20Nov23_081120| [-0.64580 -0.15922 -0.29468  0.58904 -0.15741  0.62625  1.90757 -0.29279
20Nov23_081120|   0.32812]
20Nov23_081120| [-0.38675 -0.71577  0.42643 -0.76070 -1.53681  0.05780 -0.06157  0.39549
20Nov23_081120|  -0.21361]
20Nov23_081120| [-1.61786  0.04702 -0.94962  1.39037 -0.53169  0.85972  0.89185 -0.34408
20Nov23_081120|  -0.73590]
20Nov23_081120| [ 0.98571  0.77837  1.07569 -0.35187 -1.37874 -0.14937  0.22572 -0.82999
20Nov23_081120|   0.44736]
20Nov23_081120| [-1.21003 -1.45838  1.02095  0.61951 -0.22765 -1.21435 -0.22443  0.92740
20Nov23_081120|  -0.77073]
20Nov23_081120| [ 0.59707 -0.56453 -0.65358 -2.34672 -0.32341  0.16786 -1.05250  0.29119
20Nov23_081120|  -0.15825]
20Nov23_081120| [ 1.88803  0.48220 -0.31526  0.39790 -0.28680  0.67641  0.65311 -0.46018
20Nov23_081120|  -0.78346]
20Nov23_081120| [ 1.53749  0.76150 -0.06152  0.94539  1.37221 -1.25450  0.55485  0.75678
20Nov23_081120|   0.28596]
20Nov23_081120| [-0.69501 -0.66292 -0.70443 -0.23586 -1.84727  0.50000  0.72449 -0.29577
20Nov23_081120|  -0.01265]
20Nov23_081120| [ 0.42279  0.38086  0.19830  0.96482 -0.26064  0.21820 -1.36254 -1.67737
20Nov23_081120|   0.09949]
20Nov23_081120| [-0.89380 -0.66418  0.66312 -0.34192  0.52278 -0.76123  0.17047 -2.11020
20Nov23_081120|   0.53196]
20Nov23_081120| [ 0.15779 -0.69696  1.32238 -0.74687 -1.52683 -0.33643 -1.23399 -0.94856
20Nov23_081120|   0.09857]
20Nov23_081120| [ 1.05131 -0.67318 -1.24615 -0.87618 -1.49284 -0.06874  1.07900 -1.14795
20Nov23_081120|   0.17446]
20Nov23_081120| [-0.65091  0.36390  0.43736 -0.20295  0.73984 -1.82535  1.54797 -0.54226
20Nov23_081120|  -0.45832]
20Nov23_081120| [-1.47230 -1.01292 -1.22577  0.13909 -0.22777 -0.64598  0.63506  0.16394
20Nov23_081120|  -0.77675]
20Nov23_081120| [-0.81090  0.15932 -0.32886  0.65237 -0.90740 -1.49863  0.52335  0.66660
20Nov23_081120|  -0.35570]
20Nov23_081120| [-0.38692 -1.11881  1.10759 -0.22649  0.73540 -0.46981  1.45865 -0.85465
20Nov23_081120|   0.06884]
20Nov23_081120| [-0.70397 -0.48164  1.26245  2.11535 -1.40169 -0.46342 -1.17306 -1.46933
20Nov23_081120|  -0.49080]
20Nov23_081120| [-1.10460  1.43416 -0.48554  1.51377  0.64254 -1.76552  1.65956 -0.50608
20Nov23_081120|  -0.54698]
20Nov23_081120| [-0.31011  1.98690  0.38783  0.35508  0.03083  1.34938  1.53292 -0.53171
20Nov23_081120|   0.12150]
20Nov23_081120| [ 0.36149 -0.26401 -0.01935  0.42299  1.37095 -1.27051 -0.18245  0.31588
20Nov23_081120|  -0.29268]
20Nov23_081120| [-1.06074  1.99965  0.69902 -0.86402 -1.29065 -2.35002 -1.28412 -0.72877
20Nov23_081120|  -0.41804]
20Nov23_081120| [-0.84514  0.53515  1.45650  1.07456 -0.31276 -1.39673 -0.46390 -0.11888
20Nov23_081120|  -0.62786]
20Nov23_081120| [-0.68851  1.03186 -0.46824  0.65608 -2.15624  0.15132 -0.07458 -0.29261
20Nov23_081120|   0.83517]
20Nov23_081120| [ 0.33518 -0.03880 -0.91495  0.27963 -1.52199  0.44892 -0.59121 -0.83967
20Nov23_081120|  -0.89924]
20Nov23_081120| [ 1.32436 -0.23291  2.16960 -0.32631 -0.78017  0.23003 -0.45617  2.55819
20Nov23_081120|   0.34619]
20Nov23_081120| [ 0.94408 -0.05989 -0.56402  0.71193 -0.81660 -0.55225 -0.29669  0.64528
20Nov23_081120|   0.32030]]
20Nov23_081120|-- Bias --
20Nov23_081120|[ 0.07637 -0.83169 -0.11893 -0.05433  0.08749 -1.35431  0.38599 -0.57607
20Nov23_081120| -0.06108]
20Nov23_081120|Layer 1:
20Nov23_081120|-- Config --
20Nov23_081120|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 9], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_081120|-- Weights --
20Nov23_081120|[[ 0.70918 -0.98308]
20Nov23_081120| [-0.29153 -0.01013]
20Nov23_081120| [-1.87688 -0.30242]
20Nov23_081120| [-0.40156  0.63724]
20Nov23_081120| [-0.19569  0.07574]
20Nov23_081120| [ 0.27194  0.47916]
20Nov23_081120| [-0.77374 -0.16853]
20Nov23_081120| [ 0.70173  2.03695]
20Nov23_081120| [-0.37282  0.05925]]
20Nov23_081120|-- Bias --
20Nov23_081120|[-0.02520 -0.26371]
20Nov23_081120|Predicting the validation and test data with the Best final individual.
20Nov23_081126| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_081126|-----------  ------------------  --------------------  ----------
20Nov23_081126|Validation         40.17                  9             0.05627
20Nov23_081126|   Test            35.88                  9             0.02666
20Nov23_081126|-------------------------- Test #14 --------------------------
20Nov23_081126|Best final individual weights
20Nov23_081126|Individual:
20Nov23_081126|-- Constant hidden layers --
20Nov23_081126|False
20Nov23_081126|Layer 0:
20Nov23_081126|-- Config --
20Nov23_081126|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 9, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_081126|-- Weights --
20Nov23_081126|[[ 0.17602  1.37005  0.94134  1.05414 -0.21995 -0.52384  1.64542 -0.30457
20Nov23_081126|   0.01296]
20Nov23_081126| [-1.00766  0.55531 -1.99234  0.25526  1.25030 -0.49747 -0.03963 -0.09871
20Nov23_081126|  -0.82622]
20Nov23_081126| [ 0.00435 -0.99825 -0.50688  0.37209 -1.65379 -0.48515 -0.08885  0.45705
20Nov23_081126|   0.37833]
20Nov23_081126| [-0.06184  0.76090  1.13704  1.50787  0.60159  0.44759 -1.32216 -1.49004
20Nov23_081126|  -0.31006]
20Nov23_081126| [ 0.15529 -1.20693 -0.59482  0.77745 -1.52902  1.47965 -0.18784  0.01618
20Nov23_081126|  -0.37143]
20Nov23_081126| [-0.74608  0.51489  0.44418  1.61057  1.02837 -0.39362 -1.59788 -1.41381
20Nov23_081126|  -0.46460]
20Nov23_081126| [-1.22317 -1.34170  0.81731  0.39239 -1.09585 -0.98934 -0.06814  0.95451
20Nov23_081126|   0.34325]
20Nov23_081126| [ 0.18246 -1.70586 -1.09053 -2.24079  1.80462 -0.74800 -1.48499 -0.16259
20Nov23_081126|   0.12309]
20Nov23_081126| [ 0.96105 -1.07518 -0.27790 -0.90632 -0.38456 -0.70881 -0.15062  0.71637
20Nov23_081126|   0.28111]
20Nov23_081126| [ 0.55264  1.68334 -2.12589 -1.32606 -0.58478  0.44290  0.14816 -0.88333
20Nov23_081126|   0.18307]
20Nov23_081126| [ 0.13988 -0.06929  0.19289 -0.32611  0.40154  0.59037 -0.19791  2.35651
20Nov23_081126|   0.17229]
20Nov23_081126| [ 0.30252 -0.30499  1.13260 -0.65187  0.67200  0.80110 -1.14151 -1.25115
20Nov23_081126|  -0.26380]
20Nov23_081126| [ 0.59178 -0.51172 -0.07961  0.79639  1.05492  0.01977 -0.15418 -0.03723
20Nov23_081126|  -0.35638]
20Nov23_081126| [ 0.13793 -0.25043  0.84681  1.03833 -0.43156  0.03462  0.75354 -0.59958
20Nov23_081126|  -0.45743]
20Nov23_081126| [-1.13800  0.66296 -0.55458  0.97392  0.70267 -0.01965 -0.21929 -0.24260
20Nov23_081126|  -0.05331]
20Nov23_081126| [-2.28186 -0.69856 -0.10021 -0.56269  0.03000 -0.45043  0.16882 -0.65293
20Nov23_081126|  -0.27847]
20Nov23_081126| [ 1.79644  1.28884  0.01848  1.38631  1.80935 -0.08050  0.45143 -0.96041
20Nov23_081126|  -0.12371]
20Nov23_081126| [-0.15386 -0.99409 -1.24233 -0.21473 -0.82358 -0.50121  0.06181 -0.86836
20Nov23_081126|   0.07519]
20Nov23_081126| [-0.73128 -0.17146 -0.58581 -0.82587 -1.27548 -0.17385  0.99249  0.11953
20Nov23_081126|  -0.68291]
20Nov23_081126| [-0.76081 -1.42621 -0.45821  0.05531 -0.23330 -0.74949  0.67051  0.32599
20Nov23_081126|  -0.05493]
20Nov23_081126| [-0.29383 -0.96288 -0.35742 -0.56094  0.45025  2.05842  1.07941  0.36440
20Nov23_081126|  -0.04810]
20Nov23_081126| [ 0.16564 -2.39074  1.24141  0.48639 -0.33374  0.61272  1.00614 -0.45470
20Nov23_081126|  -0.06425]
20Nov23_081126| [ 0.05723  1.47602  0.25261  0.41500 -1.05226  0.39387  1.28792 -0.81318
20Nov23_081126|  -0.63875]
20Nov23_081126| [-1.93770  1.50868  0.70201 -1.00910 -0.43689 -1.09291 -0.95173 -2.17974
20Nov23_081126|  -0.40959]
20Nov23_081126| [-1.34704 -0.06302  0.03764  0.27825  0.39591 -0.36483  0.00780 -0.09740
20Nov23_081126|   0.12410]
20Nov23_081126| [-0.74172 -0.16476 -0.61182  0.16789 -0.92203  1.07919  1.19033 -0.36009
20Nov23_081126|  -0.09485]
20Nov23_081126| [ 0.07440  0.36258 -0.18559  0.15582 -0.03425 -0.76748 -0.29371  0.48534
20Nov23_081126|  -0.77123]
20Nov23_081126| [ 0.23529  1.44463  0.89996  0.74943  0.33310 -0.70402  0.64131  0.80355
20Nov23_081126|  -0.07107]
20Nov23_081126| [ 0.91938  0.71058  0.22984 -0.16823 -0.13721  0.86600  0.44650 -0.13527
20Nov23_081126|  -0.38005]
20Nov23_081126| [-0.39765  0.03921 -0.03567  1.00847 -1.22486  0.79469  0.13971  0.28072
20Nov23_081126|  -0.71548]
20Nov23_081126| [-0.64580 -0.15922 -0.29468  0.58904 -0.15741  0.62625  1.90757 -0.29279
20Nov23_081126|   0.32812]
20Nov23_081126| [-0.38675 -0.71577  0.42643 -0.76070 -1.53681  0.05780 -0.06157  0.39549
20Nov23_081126|  -0.21361]
20Nov23_081126| [-1.61786  0.04702 -0.94962  1.39037 -0.53169  0.85972  0.89185 -0.34408
20Nov23_081126|  -0.73590]
20Nov23_081126| [ 0.98571  0.77837  1.07569 -0.35187 -1.37874 -0.14937  0.22572 -0.82999
20Nov23_081126|   0.44736]
20Nov23_081126| [-1.21003 -1.45838  1.02095  0.61951 -0.22765 -1.21435 -0.22443  0.92740
20Nov23_081126|  -0.77073]
20Nov23_081126| [ 0.59707 -0.56453 -0.65358 -2.34672 -0.32341  0.16786 -1.05250  0.29119
20Nov23_081126|  -0.15825]
20Nov23_081126| [ 1.88803  0.48220 -0.31526  0.39790 -0.28680  0.67641  0.65311 -0.46018
20Nov23_081126|  -0.78346]
20Nov23_081126| [ 1.53749  0.76150 -0.06152  0.94539  1.37221 -1.25450  0.55485  0.75678
20Nov23_081126|   0.28596]
20Nov23_081126| [-0.69501 -0.66292 -0.70443 -0.23586 -1.84727  0.50000  0.72449 -0.29577
20Nov23_081126|  -0.01265]
20Nov23_081126| [ 0.42279  0.38086  0.19830  0.96482 -0.26064  0.21820 -1.36254 -1.67737
20Nov23_081126|   0.09949]
20Nov23_081126| [-0.89380 -0.66418  0.66312 -0.34192  0.52278 -0.76123  0.17047 -2.11020
20Nov23_081126|   0.53196]
20Nov23_081126| [ 0.15779 -0.69696  1.32238 -0.74687 -1.52683 -0.33643 -1.23399 -0.94856
20Nov23_081126|   0.09857]
20Nov23_081126| [ 1.05131 -0.67318 -1.24615 -0.87618 -1.49284 -0.06874  1.07900 -1.14795
20Nov23_081126|   0.17446]
20Nov23_081126| [-0.65091  0.36390  0.43736 -0.20295  0.73984 -1.82535  1.54797 -0.54226
20Nov23_081126|  -0.45832]
20Nov23_081126| [-1.47230 -1.01292 -1.22577  0.13909 -0.22777 -0.64598  0.63506  0.16394
20Nov23_081126|  -0.77675]
20Nov23_081126| [-0.81090  0.15932 -0.32886  0.65237 -0.90740 -1.49863  0.52335  0.66660
20Nov23_081126|  -0.35570]
20Nov23_081126| [-0.38692 -1.11881  1.10759 -0.22649  0.73540 -0.46981  1.45865 -0.85465
20Nov23_081126|   0.06884]
20Nov23_081126| [-0.70397 -0.48164  1.26245  2.11535 -1.40169 -0.46342 -1.17306 -1.46933
20Nov23_081126|  -0.49080]
20Nov23_081126| [-1.10460  1.43416 -0.48554  1.51377  0.64254 -1.76552  1.65956 -0.50608
20Nov23_081126|  -0.54698]
20Nov23_081126| [-0.31011  1.98690  0.38783  0.35508  0.03083  1.34938  1.53292 -0.53171
20Nov23_081126|   0.12150]
20Nov23_081126| [ 0.36149 -0.26401 -0.01935  0.42299  1.37095 -1.27051 -0.18245  0.31588
20Nov23_081126|  -0.29268]
20Nov23_081126| [-1.06074  1.99965  0.69902 -0.86402 -1.29065 -2.35002 -1.28412 -0.72877
20Nov23_081126|  -0.41804]
20Nov23_081126| [-0.84514  0.53515  1.45650  1.07456 -0.31276 -1.39673 -0.46390 -0.11888
20Nov23_081126|  -0.62786]
20Nov23_081126| [-0.68851  1.03186 -0.46824  0.65608 -2.15624  0.15132 -0.07458 -0.29261
20Nov23_081126|   0.83517]
20Nov23_081126| [ 0.33518 -0.03880 -0.91495  0.27963 -1.52199  0.44892 -0.59121 -0.83967
20Nov23_081126|  -0.89924]
20Nov23_081126| [ 1.32436 -0.23291  2.16960 -0.32631 -0.78017  0.23003 -0.45617  2.55819
20Nov23_081126|   0.34619]
20Nov23_081126| [ 0.94408 -0.05989 -0.56402  0.71193 -0.81660 -0.55225 -0.29669  0.64528
20Nov23_081126|   0.32030]]
20Nov23_081126|-- Bias --
20Nov23_081126|[ 0.07637 -0.83169 -0.11893 -0.05433  0.08749 -1.35431  0.38599 -0.57607
20Nov23_081126| -0.06108]
20Nov23_081126|Layer 1:
20Nov23_081126|-- Config --
20Nov23_081126|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 9], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_081126|-- Weights --
20Nov23_081126|[[ 0.70918 -0.98308]
20Nov23_081126| [-0.29153 -0.01013]
20Nov23_081126| [-1.87688 -0.30242]
20Nov23_081126| [-0.40156  0.63724]
20Nov23_081126| [-0.19569  0.07574]
20Nov23_081126| [ 0.27194  0.47916]
20Nov23_081126| [-0.77374 -0.16853]
20Nov23_081126| [ 0.70173  2.03695]
20Nov23_081126| [-0.37282  0.05925]]
20Nov23_081126|-- Bias --
20Nov23_081126|[-0.02520 -0.26371]
20Nov23_081126|Predicting the validation and test data with the Best final individual.
20Nov23_081131| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_081131|-----------  ------------------  --------------------  ----------
20Nov23_081131|Validation         38.52                  9             0.16304
20Nov23_081131|   Test            34.84                  9             0.08450
Using Theano backend.
20Nov23_081132|Data summary: Train
20Nov23_081132|data.shape = (2300, 57)
20Nov23_081132|labels.shape = (2300,)
20Nov23_081132|Class distribution:
20Nov23_081132|	0 - 1389 (0.60)
20Nov23_081132|	1 - 911 (0.40)
20Nov23_081132|Data summary: Validation
20Nov23_081132|data.shape = (1150, 57)
20Nov23_081132|labels.shape = (1150,)
20Nov23_081132|Class distribution:
20Nov23_081132|	0 - 667 (0.58)
20Nov23_081132|	1 - 483 (0.42)
20Nov23_081132|Data summary: Test
20Nov23_081132|data.shape = (1151, 57)
20Nov23_081132|labels.shape = (1151,)
20Nov23_081132|Class distribution:
20Nov23_081132|	0 - 732 (0.64)
20Nov23_081132|	1 - 419 (0.36)
20Nov23_081132|Selected configuration values
20Nov23_081132|-- Dataset name: spambase2
20Nov23_081132|-- Initial population size: 64
20Nov23_081132|-- Maximun number of generations: 32
20Nov23_081132|-- Neurons per hidden layer range: (2, 20)
20Nov23_081132|-- Hidden layers number range: (1, 3)
20Nov23_081132|-- Crossover probability: 0.5
20Nov23_081132|-- Bias gene mutation probability: 0.2
20Nov23_081132|-- Weights gene mutation probability: 0.75
20Nov23_081132|-- Neuron mutation probability: 0.3
20Nov23_081132|-- Layer mutation probability: 0.3
20Nov23_081132|-- Constant hidden layers: False
20Nov23_081132|-- Seed: None
20Nov23_081132|Entering GA
20Nov23_081132|Start the algorithm
20Nov23_081453|-- Generation 1 --
20Nov23_081453|    -- Crossed 0 individual pairs.
20Nov23_081453|    -- Mutated 32 individuals.
20Nov23_081803|    -- Evaluated 64 individuals.
20Nov23_081803|    Summary of generation 1:
20Nov23_081803| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_081803|-----------  ------------------  --------------------  ----------
20Nov23_081803|    Max            42.61                132.00          0.26871
20Nov23_081803|    Avg            41.85                32.42           0.00904
20Nov23_081803|    Min            35.74                 2.00           0.00000
20Nov23_081803|    Std             0.92                26.31           0.04259
20Nov23_081803|   Best            35.74                132.00          0.26871
20Nov23_081803|-- Generation 2 --
20Nov23_081803|    -- Crossed 1 individual pairs.
20Nov23_081803|    -- Mutated 32 individuals.
20Nov23_082108|    -- Evaluated 64 individuals.
20Nov23_082108|    Summary of generation 2:
20Nov23_082108| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_082108|-----------  ------------------  --------------------  ----------
20Nov23_082108|    Max            43.13                196.00          0.78585
20Nov23_082108|    Avg            41.73                22.62           0.01477
20Nov23_082108|    Min            25.74                 2.00           0.00000
20Nov23_082108|    Std             2.03                30.19           0.09746
20Nov23_082108|   Best            25.74                24.00           0.78585
20Nov23_082108|-- Generation 3 --
20Nov23_082108|    -- Crossed 4 individual pairs.
20Nov23_082108|    -- Mutated 32 individuals.
20Nov23_082409|    -- Evaluated 64 individuals.
20Nov23_082409|    Summary of generation 3:
20Nov23_082409| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_082409|-----------  ------------------  --------------------  ----------
20Nov23_082409|    Max            42.26                75.00           0.70844
20Nov23_082409|    Avg            41.68                15.94           0.01464
20Nov23_082409|    Min            26.17                 2.00           0.00000
20Nov23_082409|    Std             2.00                16.64           0.08883
20Nov23_082409|   Best            26.17                24.00           0.70844
20Nov23_082409|-- Generation 4 --
20Nov23_082409|    -- Crossed 3 individual pairs.
20Nov23_082409|    -- Mutated 32 individuals.
20Nov23_082712|    -- Evaluated 64 individuals.
20Nov23_082712|    Summary of generation 4:
20Nov23_082712| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_082712|-----------  ------------------  --------------------  ----------
20Nov23_082712|    Max            42.26                75.00           0.03579
20Nov23_082712|    Avg            41.98                17.91           0.00173
20Nov23_082712|    Min            41.39                 2.00           0.00000
20Nov23_082712|    Std             0.11                17.19           0.00498
20Nov23_082712|   Best            41.39                10.00           0.01805
20Nov23_082712|-- Generation 5 --
20Nov23_082712|    -- Crossed 5 individual pairs.
20Nov23_082712|    -- Mutated 32 individuals.
20Nov23_083012|    -- Evaluated 64 individuals.
20Nov23_083012|    Summary of generation 5:
20Nov23_083012| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_083012|-----------  ------------------  --------------------  ----------
20Nov23_083012|    Max            58.00                48.00           0.82170
20Nov23_083012|    Avg            42.20                14.75           0.02769
20Nov23_083012|    Min            41.13                 2.00           0.00000
20Nov23_083012|    Std             2.00                15.86           0.13940
20Nov23_083012|   Best            41.13                11.00           0.04847
20Nov23_083012|-- Generation 6 --
20Nov23_083012|    -- Crossed 4 individual pairs.
20Nov23_083012|    -- Mutated 32 individuals.
20Nov23_083313|    -- Evaluated 64 individuals.
20Nov23_083313|    Summary of generation 6:
20Nov23_083313| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_083313|-----------  ------------------  --------------------  ----------
20Nov23_083313|    Max            42.09                84.00           0.06371
20Nov23_083313|    Avg            41.94                15.59           0.00233
20Nov23_083313|    Min            40.26                 2.00           0.00000
20Nov23_083313|    Std             0.23                17.48           0.00816
20Nov23_083313|   Best            40.26                 4.00           0.06371
20Nov23_083313|-- Generation 7 --
20Nov23_083313|    -- Crossed 5 individual pairs.
20Nov23_083313|    -- Mutated 32 individuals.
20Nov23_083613|    -- Evaluated 64 individuals.
20Nov23_083613|    Summary of generation 7:
20Nov23_083613| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_083613|-----------  ------------------  --------------------  ----------
20Nov23_083613|    Max            42.26                81.00           0.01033
20Nov23_083613|    Avg            41.98                14.56           0.00182
20Nov23_083613|    Min            41.65                 2.00           0.00000
20Nov23_083613|    Std             0.10                17.40           0.00244
20Nov23_083613|   Best            41.65                 5.00           0.01033
20Nov23_083613|-- Generation 8 --
20Nov23_083613|    -- Crossed 3 individual pairs.
20Nov23_083613|    -- Mutated 32 individuals.
20Nov23_083913|    -- Evaluated 64 individuals.
20Nov23_083913|    Summary of generation 8:
20Nov23_083913| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_083913|-----------  ------------------  --------------------  ----------
20Nov23_083913|    Max            42.35                78.00           0.54758
20Nov23_083913|    Avg            41.85                16.00           0.01416
20Nov23_083913|    Min            36.00                 2.00           0.00000
20Nov23_083913|    Std             0.80                18.04           0.07435
20Nov23_083913|   Best            36.00                 5.00           0.25758
20Nov23_083913|-- Generation 9 --
20Nov23_083913|    -- Crossed 8 individual pairs.
20Nov23_083913|    -- Mutated 32 individuals.
20Nov23_084217|    -- Evaluated 64 individuals.
20Nov23_084217|    Summary of generation 9:
20Nov23_084217| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_084217|-----------  ------------------  --------------------  ----------
20Nov23_084217|    Max            58.00                81.00           0.78358
20Nov23_084217|    Avg            42.04                22.05           0.02300
20Nov23_084217|    Min            29.30                 2.00           0.00000
20Nov23_084217|    Std             2.55                21.42           0.12010
20Nov23_084217|   Best            29.30                18.00           0.58533
20Nov23_084217|-- Generation 10 --
20Nov23_084217|    -- Crossed 3 individual pairs.
20Nov23_084217|    -- Mutated 32 individuals.
20Nov23_084521|    -- Evaluated 64 individuals.
20Nov23_084521|    Summary of generation 10:
20Nov23_084521| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_084521|-----------  ------------------  --------------------  ----------
20Nov23_084521|    Max            48.52                78.00           0.80547
20Nov23_084521|    Avg            41.74                19.19           0.03348
20Nov23_084521|    Min            24.96                 2.00           0.00000
20Nov23_084521|    Std             2.29                17.21           0.14299
20Nov23_084521|   Best            24.96                14.00           0.78458
20Nov23_084521|-- Generation 11 --
20Nov23_084521|    -- Crossed 3 individual pairs.
20Nov23_084521|    -- Mutated 32 individuals.
20Nov23_084828|    -- Evaluated 64 individuals.
20Nov23_084828|    Summary of generation 11:
20Nov23_084828| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_084828|-----------  ------------------  --------------------  ----------
20Nov23_084828|    Max            43.91                78.00           0.17400
20Nov23_084828|    Avg            41.99                23.69           0.00446
20Nov23_084828|    Min            41.39                 2.00           0.00000
20Nov23_084828|    Std             0.27                18.79           0.02141
20Nov23_084828|   Best            41.39                10.00           0.17400
20Nov23_084828|-- Generation 12 --
20Nov23_084828|    -- Crossed 5 individual pairs.
20Nov23_084828|    -- Mutated 32 individuals.
20Nov23_085136|    -- Evaluated 64 individuals.
20Nov23_085136|    Summary of generation 12:
20Nov23_085136| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_085136|-----------  ------------------  --------------------  ----------
20Nov23_085136|    Max            58.00                75.00           0.78358
20Nov23_085136|    Avg            42.43                21.81           0.03165
20Nov23_085136|    Min            40.52                 2.00           0.00000
20Nov23_085136|    Std             2.80                14.39           0.14093
20Nov23_085136|   Best            40.52                10.00           0.32683
20Nov23_085136|-- Generation 13 --
20Nov23_085136|    -- Crossed 6 individual pairs.
20Nov23_085136|    -- Mutated 32 individuals.
20Nov23_085441|    -- Evaluated 64 individuals.
20Nov23_085441|    Summary of generation 13:
20Nov23_085441| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_085441|-----------  ------------------  --------------------  ----------
20Nov23_085441|    Max            42.09                78.00           0.37644
20Nov23_085441|    Avg            41.81                17.56           0.01567
20Nov23_085441|    Min            38.17                 2.00           0.00000
20Nov23_085441|    Std             0.56                12.04           0.06110
20Nov23_085441|   Best            38.17                 5.00           0.18400
20Nov23_085441|-- Generation 14 --
20Nov23_085441|    -- Crossed 3 individual pairs.
20Nov23_085441|    -- Mutated 32 individuals.
20Nov23_085746|    -- Evaluated 64 individuals.
20Nov23_085746|    Summary of generation 14:
20Nov23_085746| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_085746|-----------  ------------------  --------------------  ----------
20Nov23_085746|    Max            42.09                39.00           0.50700
20Nov23_085746|    Avg            41.83                14.67           0.01601
20Nov23_085746|    Min            37.39                 2.00           0.00000
20Nov23_085746|    Std             0.64                 7.33           0.07726
20Nov23_085746|   Best            37.39                14.00           0.50700
20Nov23_085746|-- Generation 15 --
20Nov23_085746|    -- Crossed 4 individual pairs.
20Nov23_085746|    -- Mutated 32 individuals.
20Nov23_090051|    -- Evaluated 64 individuals.
20Nov23_090051|    Summary of generation 15:
20Nov23_090051| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_090051|-----------  ------------------  --------------------  ----------
20Nov23_090051|    Max            58.00                39.00           0.78358
20Nov23_090051|    Avg            42.19                14.84           0.01467
20Nov23_090051|    Min            41.74                 2.00           0.00000
20Nov23_090051|    Std             1.99                 8.60           0.09689
20Nov23_090051|   Best            41.74                14.00           0.00775
20Nov23_090051|-- Generation 16 --
20Nov23_090051|    -- Crossed 5 individual pairs.
20Nov23_090051|    -- Mutated 32 individuals.
20Nov23_090357|    -- Evaluated 64 individuals.
20Nov23_090357|    Summary of generation 16:
20Nov23_090357| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_090357|-----------  ------------------  --------------------  ----------
20Nov23_090357|    Max            42.26                39.00           0.78740
20Nov23_090357|    Avg            41.69                13.28           0.01465
20Nov23_090357|    Min            25.30                 2.00           0.00000
20Nov23_090357|    Std             2.07                 8.19           0.09738
20Nov23_090357|   Best            25.30                10.00           0.78740
20Nov23_090357|-- Generation 17 --
20Nov23_090357|    -- Crossed 2 individual pairs.
20Nov23_090357|    -- Mutated 32 individuals.
20Nov23_090701|    -- Evaluated 64 individuals.
20Nov23_090701|    Summary of generation 17:
20Nov23_090701| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_090701|-----------  ------------------  --------------------  ----------
20Nov23_090701|    Max            42.35                42.00           0.00775
20Nov23_090701|    Avg            41.95                13.47           0.00242
20Nov23_090701|    Min            41.74                 2.00           0.00000
20Nov23_090701|    Std             0.10                 8.79           0.00193
20Nov23_090701|   Best            41.74                14.00           0.00775
20Nov23_090701|-- Generation 18 --
20Nov23_090701|    -- Crossed 1 individual pairs.
20Nov23_090701|    -- Mutated 32 individuals.
20Nov23_091004|    -- Evaluated 64 individuals.
20Nov23_091004|    Summary of generation 18:
20Nov23_091004| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_091004|-----------  ------------------  --------------------  ----------
20Nov23_091004|    Max            42.17                39.00           0.81379
20Nov23_091004|    Avg            41.93                12.27           0.01518
20Nov23_091004|    Min            41.57                 2.00           0.00000
20Nov23_091004|    Std             0.08                 7.18           0.10063
20Nov23_091004|   Best            41.57                10.00           0.81379
20Nov23_091004|-- Generation 19 --
20Nov23_091004|    -- Crossed 4 individual pairs.
20Nov23_091004|    -- Mutated 32 individuals.
20Nov23_091305|    -- Evaluated 64 individuals.
20Nov23_091305|    Summary of generation 19:
20Nov23_091305| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_091305|-----------  ------------------  --------------------  ----------
20Nov23_091305|    Max            42.17                60.00           0.00775
20Nov23_091305|    Avg            41.93                11.80           0.00287
20Nov23_091305|    Min            41.74                 2.00           0.00000
20Nov23_091305|    Std             0.08                 9.37           0.00215
20Nov23_091305|   Best            41.74                 9.00           0.00775
20Nov23_091305|-- Generation 20 --
20Nov23_091305|    -- Crossed 4 individual pairs.
20Nov23_091305|    -- Mutated 32 individuals.
20Nov23_091603|    -- Evaluated 64 individuals.
20Nov23_091603|    Summary of generation 20:
20Nov23_091603| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_091603|-----------  ------------------  --------------------  ----------
20Nov23_091603|    Max            58.00                39.00           0.78358
20Nov23_091603|    Avg            42.15                10.05           0.01560
20Nov23_091603|    Min            41.74                 2.00           0.00000
20Nov23_091603|    Std             2.00                 7.06           0.09678
20Nov23_091603|   Best            41.74                 9.00           0.00775
20Nov23_091603|-- Generation 21 --
20Nov23_091603|    -- Crossed 3 individual pairs.
20Nov23_091603|    -- Mutated 32 individuals.
20Nov23_091902|    -- Evaluated 64 individuals.
20Nov23_091902|    Summary of generation 21:
20Nov23_091902| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_091902|-----------  ------------------  --------------------  ----------
20Nov23_091902|    Max            42.09                39.00           0.00775
20Nov23_091902|    Avg            41.91                10.20           0.00323
20Nov23_091902|    Min            41.74                 2.00           0.00000
20Nov23_091902|    Std             0.08                 7.39           0.00237
20Nov23_091902|   Best            41.74                 3.00           0.00775
20Nov23_091902|-- Generation 22 --
20Nov23_091902|    -- Crossed 4 individual pairs.
20Nov23_091902|    -- Mutated 32 individuals.
20Nov23_092200|    -- Evaluated 64 individuals.
20Nov23_092200|    Summary of generation 22:
20Nov23_092200| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_092200|-----------  ------------------  --------------------  ----------
20Nov23_092200|    Max            42.00                39.00           0.01031
20Nov23_092200|    Avg            41.90                 9.78           0.00367
20Nov23_092200|    Min            41.74                 2.00           0.00000
20Nov23_092200|    Std             0.07                 7.84           0.00241
20Nov23_092200|   Best            41.74                 9.00           0.00775
20Nov23_092200|-- Generation 23 --
20Nov23_092200|    -- Crossed 5 individual pairs.
20Nov23_092200|    -- Mutated 32 individuals.
20Nov23_092459|    -- Evaluated 64 individuals.
20Nov23_092459|    Summary of generation 23:
20Nov23_092459| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_092459|-----------  ------------------  --------------------  ----------
20Nov23_092459|    Max            57.91                39.00           0.78384
20Nov23_092459|    Avg            42.20                10.44           0.01766
20Nov23_092459|    Min            41.74                 2.00           0.00000
20Nov23_092459|    Std             1.99                 9.50           0.09858
20Nov23_092459|   Best            41.74                 2.00           0.00775
20Nov23_092459|-- Generation 24 --
20Nov23_092459|    -- Crossed 4 individual pairs.
20Nov23_092459|    -- Mutated 32 individuals.
20Nov23_092757|    -- Evaluated 64 individuals.
20Nov23_092757|    Summary of generation 24:
20Nov23_092757| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_092757|-----------  ------------------  --------------------  ----------
20Nov23_092757|    Max            42.17                64.00           0.00775
20Nov23_092757|    Avg            41.90                 9.55           0.00343
20Nov23_092757|    Min            41.74                 2.00           0.00000
20Nov23_092757|    Std             0.09                10.25           0.00229
20Nov23_092757|   Best            41.74                 2.00           0.00775
20Nov23_092757|-- Generation 25 --
20Nov23_092757|    -- Crossed 2 individual pairs.
20Nov23_092757|    -- Mutated 32 individuals.
20Nov23_093054|    -- Evaluated 64 individuals.
20Nov23_093054|    Summary of generation 25:
20Nov23_093054| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_093054|-----------  ------------------  --------------------  ----------
20Nov23_093054|    Max            58.00                42.00           0.78358
20Nov23_093054|    Avg            42.17                 9.30           0.01564
20Nov23_093054|    Min            41.74                 2.00           0.00000
20Nov23_093054|    Std             2.00                 8.48           0.09678
20Nov23_093054|   Best            41.74                 2.00           0.00775
20Nov23_093054|-- Generation 26 --
20Nov23_093054|    -- Crossed 4 individual pairs.
20Nov23_093054|    -- Mutated 32 individuals.
20Nov23_093351|    -- Evaluated 64 individuals.
20Nov23_093351|    Summary of generation 26:
20Nov23_093351| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_093351|-----------  ------------------  --------------------  ----------
20Nov23_093351|    Max            42.43                28.00           0.00775
20Nov23_093351|    Avg            41.93                 8.17           0.00299
20Nov23_093351|    Min            41.74                 2.00           0.00000
20Nov23_093351|    Std             0.11                 5.95           0.00238
20Nov23_093351|   Best            41.74                 9.00           0.00775
20Nov23_093351|-- Generation 27 --
20Nov23_093351|    -- Crossed 5 individual pairs.
20Nov23_093351|    -- Mutated 32 individuals.
20Nov23_093647|    -- Evaluated 64 individuals.
20Nov23_093647|    Summary of generation 27:
20Nov23_093647| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_093647|-----------  ------------------  --------------------  ----------
20Nov23_093647|    Max            42.26                26.00           0.01291
20Nov23_093647|    Avg            41.92                 7.95           0.00343
20Nov23_093647|    Min            41.57                 2.00           0.00000
20Nov23_093647|    Std             0.13                 5.75           0.00259
20Nov23_093647|   Best            41.57                12.00           0.01291
20Nov23_093647|-- Generation 28 --
20Nov23_093647|    -- Crossed 8 individual pairs.
20Nov23_093647|    -- Mutated 32 individuals.
20Nov23_093946|    -- Evaluated 64 individuals.
20Nov23_093946|    Summary of generation 28:
20Nov23_093946| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_093946|-----------  ------------------  --------------------  ----------
20Nov23_093946|    Max            42.35                36.00           0.01548
20Nov23_093946|    Avg            41.91                 9.00           0.00355
20Nov23_093946|    Min            41.48                 2.00           0.00000
20Nov23_093946|    Std             0.12                 7.31           0.00283
20Nov23_093946|   Best            41.48                12.00           0.01548
20Nov23_093946|-- Generation 29 --
20Nov23_093946|    -- Crossed 4 individual pairs.
20Nov23_093946|    -- Mutated 32 individuals.
20Nov23_094243|    -- Evaluated 64 individuals.
20Nov23_094243|    Summary of generation 29:
20Nov23_094243| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_094243|-----------  ------------------  --------------------  ----------
20Nov23_094243|    Max            42.43                28.00           0.01033
20Nov23_094243|    Avg            41.91                 8.38           0.00339
20Nov23_094243|    Min            41.65                 2.00           0.00000
20Nov23_094243|    Std             0.11                 6.11           0.00241
20Nov23_094243|   Best            41.65                12.00           0.01033
20Nov23_094243|-- Generation 30 --
20Nov23_094243|    -- Crossed 2 individual pairs.
20Nov23_094243|    -- Mutated 32 individuals.
20Nov23_094539|    -- Evaluated 64 individuals.
20Nov23_094539|    Summary of generation 30:
20Nov23_094539| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_094539|-----------  ------------------  --------------------  ----------
20Nov23_094539|    Max            42.26                39.00           0.01547
20Nov23_094539|    Avg            41.89                 7.86           0.00408
20Nov23_094539|    Min            41.57                 2.00           0.00000
20Nov23_094539|    Std             0.12                 7.09           0.00265
20Nov23_094539|   Best            41.57                12.00           0.01547
20Nov23_094539|-- Generation 31 --
20Nov23_094539|    -- Crossed 5 individual pairs.
20Nov23_094539|    -- Mutated 32 individuals.
20Nov23_094838|    -- Evaluated 64 individuals.
20Nov23_094838|    Summary of generation 31:
20Nov23_094838| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_094838|-----------  ------------------  --------------------  ----------
20Nov23_094838|    Max            42.52                36.00           0.01804
20Nov23_094838|    Avg            41.88                10.02           0.00444
20Nov23_094838|    Min            41.48                 2.00           0.00000
20Nov23_094838|    Std             0.14                 7.28           0.00324
20Nov23_094838|   Best            41.48                12.00           0.01548
20Nov23_094838|-- Generation 32 --
20Nov23_094838|    -- Crossed 4 individual pairs.
20Nov23_094838|    -- Mutated 32 individuals.
20Nov23_095136|    -- Evaluated 64 individuals.
20Nov23_095136|    Summary of generation 32:
20Nov23_095136| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_095136|-----------  ------------------  --------------------  ----------
20Nov23_095136|    Max            42.17                30.00           0.01548
20Nov23_095136|    Avg            41.89                 9.73           0.00392
20Nov23_095136|    Min            41.48                 2.00           0.00000
20Nov23_095136|    Std             0.13                 7.12           0.00289
20Nov23_095136|   Best            41.48                12.00           0.01548
20Nov23_095136|Best initial individual weights
20Nov23_095136|Individual:
20Nov23_095136|-- Constant hidden layers --
20Nov23_095136|False
20Nov23_095136|Layer 0:
20Nov23_095136|-- Config --
20Nov23_095136|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095136|-- Weights --
20Nov23_095136|[[-0.44569 -0.84936]
20Nov23_095136| [ 0.42064  0.82246]
20Nov23_095136| [ 0.74706 -0.44073]
20Nov23_095136| [ 0.61901  0.89820]
20Nov23_095136| [ 0.15898 -0.62454]
20Nov23_095136| [-0.36058 -0.67508]
20Nov23_095136| [ 0.67815  0.63403]
20Nov23_095136| [-0.20672  0.63489]
20Nov23_095136| [ 0.17399 -0.37931]
20Nov23_095136| [ 0.47331  0.68682]
20Nov23_095136| [-0.45942 -0.98180]
20Nov23_095136| [-0.75528  0.78863]
20Nov23_095136| [-0.07344 -0.23229]
20Nov23_095136| [-0.97589  0.83854]
20Nov23_095136| [ 0.51055 -0.62717]
20Nov23_095136| [ 0.20938 -0.57372]
20Nov23_095136| [-0.38376  0.53235]
20Nov23_095136| [-0.65106 -0.71502]
20Nov23_095136| [-0.40441  0.96199]
20Nov23_095136| [ 0.38223 -0.23201]
20Nov23_095136| [-0.74986 -0.32117]
20Nov23_095136| [-0.60097 -0.77066]
20Nov23_095136| [-0.61303 -0.72602]
20Nov23_095136| [ 0.13900  0.94123]
20Nov23_095136| [ 0.47020  0.29368]
20Nov23_095136| [-0.24137 -0.76524]
20Nov23_095136| [ 0.34074 -0.61495]
20Nov23_095136| [ 0.34977 -0.95400]
20Nov23_095136| [-0.82219 -0.00735]
20Nov23_095136| [-0.83015  0.72595]
20Nov23_095136| [-0.76190 -0.25832]
20Nov23_095136| [ 0.92816 -0.63873]
20Nov23_095136| [-0.94505  0.56200]
20Nov23_095136| [-0.65908 -0.93341]
20Nov23_095136| [ 0.74522  0.98256]
20Nov23_095136| [-0.93819 -0.91335]
20Nov23_095136| [-0.07649  0.65248]
20Nov23_095136| [-0.16600 -0.24669]
20Nov23_095136| [-0.30205 -0.17070]
20Nov23_095136| [-0.85888 -0.96490]
20Nov23_095136| [-0.30302 -0.94494]
20Nov23_095136| [ 0.25060  0.63964]
20Nov23_095136| [ 0.10246  0.10691]
20Nov23_095136| [ 0.31007  0.87853]
20Nov23_095136| [ 0.28529  0.68858]
20Nov23_095136| [ 0.12560  0.70385]
20Nov23_095136| [ 0.17147 -0.91898]
20Nov23_095136| [-0.14375  0.98347]
20Nov23_095136| [ 0.40442 -0.78584]
20Nov23_095136| [ 0.74603 -0.77626]
20Nov23_095136| [-0.28762 -0.53365]
20Nov23_095136| [-0.78017  0.78083]
20Nov23_095136| [ 0.04835 -0.32566]
20Nov23_095136| [ 0.30379 -0.16683]
20Nov23_095136| [ 0.18261 -0.06466]
20Nov23_095136| [-0.95172  0.10006]
20Nov23_095136| [-0.57806 -0.07686]]
20Nov23_095136|-- Bias --
20Nov23_095136|[0.85874 0.08244]
20Nov23_095136|Layer 1:
20Nov23_095136|-- Config --
20Nov23_095136|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095136|-- Weights --
20Nov23_095136|[[-0.64062  0.05292  0.25744]
20Nov23_095136| [ 0.07320 -0.55929 -0.34111]]
20Nov23_095136|-- Bias --
20Nov23_095136|[-0.74442 -0.07702  0.96194]
20Nov23_095136|Layer 2:
20Nov23_095136|-- Config --
20Nov23_095136|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095136|-- Weights --
20Nov23_095136|[[ 0.55464 -0.26531  0.06654]
20Nov23_095136| [-0.01685  0.36208  0.30449]
20Nov23_095136| [-0.42465 -0.26691  0.02901]]
20Nov23_095136|-- Bias --
20Nov23_095136|[ 0.86785  0.50808 -0.05015]
20Nov23_095136|Layer 3:
20Nov23_095136|-- Config --
20Nov23_095136|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095136|-- Weights --
20Nov23_095136|[[-0.75425 -0.46477]
20Nov23_095136| [-0.21327 -0.95771]
20Nov23_095136| [ 0.76222 -0.40827]]
20Nov23_095136|-- Bias --
20Nov23_095136|[0.10699 0.93261]
20Nov23_095136|Predicting the validation and test data with the Best initial individual.
20Nov23_095142| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_095142|-----------  ------------------  --------------------  ----------
20Nov23_095142|Validation         42.00                  24            0.00000
20Nov23_095142|   Test            25.72                  24            0.74242
20Nov23_095142|-------------------------- Test #0 --------------------------
20Nov23_095142|Best final individual weights
20Nov23_095142|Individual:
20Nov23_095142|-- Constant hidden layers --
20Nov23_095142|False
20Nov23_095142|Layer 0:
20Nov23_095142|-- Config --
20Nov23_095142|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095142|-- Weights --
20Nov23_095142|[[-4.78093e-01 -1.32987e-01 -1.98602e-01]
20Nov23_095142| [ 5.70296e-01  1.10707e-01 -2.04917e-01]
20Nov23_095142| [ 1.35368e-02  1.77761e+00 -2.52685e-01]
20Nov23_095142| [-1.26644e+00  3.57369e-01 -1.65181e-01]
20Nov23_095142| [-1.05634e+00  1.94476e+00  3.96681e-01]
20Nov23_095142| [-3.13175e-01 -8.64222e-01  7.56146e-02]
20Nov23_095142| [ 9.64959e-01  1.21650e+00  7.43693e-02]
20Nov23_095142| [ 2.00262e-01  1.09055e+00  3.21193e-01]
20Nov23_095142| [-1.02545e+00  2.09448e-01 -2.03886e-01]
20Nov23_095142| [ 3.44070e-01  2.59404e-01  1.48387e-02]
20Nov23_095142| [-1.22205e+00 -5.78311e-01 -4.46069e-01]
20Nov23_095142| [ 1.27455e-01  6.53705e-01 -4.11728e-01]
20Nov23_095142| [-8.22001e-01 -7.07268e-01 -4.60801e-01]
20Nov23_095142| [ 1.17331e-02  1.00342e+00 -2.38681e-01]
20Nov23_095142| [ 9.67231e-01  9.92537e-01  4.70941e-01]
20Nov23_095142| [ 3.28565e-01  6.93736e-01  1.20231e-01]
20Nov23_095142| [ 8.14875e-01 -9.84338e-02  1.18653e-02]
20Nov23_095142| [ 2.21745e-01 -1.17971e-01  3.13766e-01]
20Nov23_095142| [-6.10808e-01  1.17938e-01  4.57614e-03]
20Nov23_095142| [ 2.50763e-01 -1.14777e+00 -1.08223e-01]
20Nov23_095142| [-1.36903e-01  2.03549e-01  1.68996e-01]
20Nov23_095142| [ 8.39934e-01 -9.21186e-01 -3.08707e-01]
20Nov23_095142| [-6.47800e-01  1.47232e-01  1.00589e-01]
20Nov23_095142| [-1.63393e+00 -4.77786e-01 -4.84560e-01]
20Nov23_095142| [ 1.75349e-01  2.15510e-01 -9.56645e-02]
20Nov23_095142| [-5.44939e-01 -6.84742e-01 -2.11610e-01]
20Nov23_095142| [-1.18869e+00 -1.31627e+00  2.10714e-01]
20Nov23_095142| [-1.09169e+00  1.33832e+00 -3.63987e-01]
20Nov23_095142| [-1.82071e-01 -1.51525e-01  1.21841e-01]
20Nov23_095142| [ 2.93676e-01  4.31694e-01 -1.52107e-01]
20Nov23_095142| [ 7.99207e-01  6.13471e-01  1.34435e-01]
20Nov23_095142| [ 9.32988e-01  9.45293e-01  2.64422e-01]
20Nov23_095142| [ 5.17947e-01 -7.64332e-01 -4.78027e-01]
20Nov23_095142| [ 7.02416e-01 -1.51632e-01 -3.33041e-01]
20Nov23_095142| [ 6.69652e-01  8.72101e-01 -1.64085e-01]
20Nov23_095142| [ 3.41736e-01  8.98305e-02  4.05198e-01]
20Nov23_095142| [ 2.27074e-01  8.46331e-01 -1.44322e-01]
20Nov23_095142| [ 6.03573e-01 -8.16247e-01 -7.74988e-02]
20Nov23_095142| [ 6.20717e-03  8.60449e-01 -2.75791e-01]
20Nov23_095142| [ 9.61293e-01  5.78074e-04 -6.99620e-02]
20Nov23_095142| [ 2.25284e-01 -9.64720e-01  1.38483e-01]
20Nov23_095142| [-2.69333e-01  7.96826e-01 -4.47025e-01]
20Nov23_095142| [-3.94057e-01 -5.68296e-01 -3.09060e-01]
20Nov23_095142| [ 1.13462e-01 -6.62818e-01 -4.94233e-01]
20Nov23_095142| [ 8.43231e-02  1.02165e+00  3.84557e-01]
20Nov23_095142| [ 4.76439e-01  3.90610e-01 -9.34270e-02]
20Nov23_095142| [-3.52813e-01  1.01680e+00 -1.56756e-01]
20Nov23_095142| [ 7.44184e-01 -6.22559e-01  4.71656e-01]
20Nov23_095142| [-3.25724e-02  8.04856e-01 -4.74885e-01]
20Nov23_095142| [-7.77151e-01 -5.56192e-01 -3.64250e-01]
20Nov23_095142| [ 4.19055e-01  1.05048e+00  1.13302e-01]
20Nov23_095142| [-2.11603e-01 -1.14325e-01 -1.91534e-01]
20Nov23_095142| [-1.57604e+00 -8.33752e-01  4.40403e-01]
20Nov23_095142| [-2.32387e-02 -2.84182e-01  2.42507e-01]
20Nov23_095142| [ 9.29496e-01 -1.06917e-01  2.47643e-01]
20Nov23_095142| [ 5.51908e-01  8.53966e-01 -3.68319e-01]
20Nov23_095142| [-7.43625e-01 -1.09987e+00 -4.07496e-02]]
20Nov23_095142|-- Bias --
20Nov23_095142|[0.65700 0.08603 0.07316]
20Nov23_095142|Layer 1:
20Nov23_095142|-- Config --
20Nov23_095142|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095142|-- Weights --
20Nov23_095142|[[ 0.78377 -0.55499 -0.47708]
20Nov23_095142| [-0.59071  0.65028 -0.40958]
20Nov23_095142| [-0.79088 -0.47553 -0.26780]]
20Nov23_095142|-- Bias --
20Nov23_095142|[ 0.25453 -0.37598 -0.43393]
20Nov23_095142|Layer 2:
20Nov23_095142|-- Config --
20Nov23_095142|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095142|-- Weights --
20Nov23_095142|[[-0.18759  0.25690]
20Nov23_095142| [-0.63942  0.79732]
20Nov23_095142| [ 0.19193 -0.35600]]
20Nov23_095142|-- Bias --
20Nov23_095142|[-1.29423 -0.06155]
20Nov23_095142|Predicting the validation and test data with the Best final individual.
20Nov23_095148| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_095148|-----------  ------------------  --------------------  ----------
20Nov23_095148|Validation         41.57                  12            0.01547
20Nov23_095148|   Test            36.32                  12            0.00596
20Nov23_095148|-------------------------- Test #1 --------------------------
20Nov23_095148|Best final individual weights
20Nov23_095148|Individual:
20Nov23_095148|-- Constant hidden layers --
20Nov23_095148|False
20Nov23_095148|Layer 0:
20Nov23_095148|-- Config --
20Nov23_095148|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095148|-- Weights --
20Nov23_095148|[[-4.78093e-01 -1.32987e-01 -1.98602e-01]
20Nov23_095148| [ 5.70296e-01  1.10707e-01 -2.04917e-01]
20Nov23_095148| [ 1.35368e-02  1.77761e+00 -2.52685e-01]
20Nov23_095148| [-1.26644e+00  3.57369e-01 -1.65181e-01]
20Nov23_095148| [-1.05634e+00  1.94476e+00  3.96681e-01]
20Nov23_095148| [-3.13175e-01 -8.64222e-01  7.56146e-02]
20Nov23_095148| [ 9.64959e-01  1.21650e+00  7.43693e-02]
20Nov23_095148| [ 2.00262e-01  1.09055e+00  3.21193e-01]
20Nov23_095148| [-1.02545e+00  2.09448e-01 -2.03886e-01]
20Nov23_095148| [ 3.44070e-01  2.59404e-01  1.48387e-02]
20Nov23_095148| [-1.22205e+00 -5.78311e-01 -4.46069e-01]
20Nov23_095148| [ 1.27455e-01  6.53705e-01 -4.11728e-01]
20Nov23_095148| [-8.22001e-01 -7.07268e-01 -4.60801e-01]
20Nov23_095148| [ 1.17331e-02  1.00342e+00 -2.38681e-01]
20Nov23_095148| [ 9.67231e-01  9.92537e-01  4.70941e-01]
20Nov23_095148| [ 3.28565e-01  6.93736e-01  1.20231e-01]
20Nov23_095148| [ 8.14875e-01 -9.84338e-02  1.18653e-02]
20Nov23_095148| [ 2.21745e-01 -1.17971e-01  3.13766e-01]
20Nov23_095148| [-6.10808e-01  1.17938e-01  4.57614e-03]
20Nov23_095148| [ 2.50763e-01 -1.14777e+00 -1.08223e-01]
20Nov23_095148| [-1.36903e-01  2.03549e-01  1.68996e-01]
20Nov23_095148| [ 8.39934e-01 -9.21186e-01 -3.08707e-01]
20Nov23_095148| [-6.47800e-01  1.47232e-01  1.00589e-01]
20Nov23_095148| [-1.63393e+00 -4.77786e-01 -4.84560e-01]
20Nov23_095148| [ 1.75349e-01  2.15510e-01 -9.56645e-02]
20Nov23_095148| [-5.44939e-01 -6.84742e-01 -2.11610e-01]
20Nov23_095148| [-1.18869e+00 -1.31627e+00  2.10714e-01]
20Nov23_095148| [-1.09169e+00  1.33832e+00 -3.63987e-01]
20Nov23_095148| [-1.82071e-01 -1.51525e-01  1.21841e-01]
20Nov23_095148| [ 2.93676e-01  4.31694e-01 -1.52107e-01]
20Nov23_095148| [ 7.99207e-01  6.13471e-01  1.34435e-01]
20Nov23_095148| [ 9.32988e-01  9.45293e-01  2.64422e-01]
20Nov23_095148| [ 5.17947e-01 -7.64332e-01 -4.78027e-01]
20Nov23_095148| [ 7.02416e-01 -1.51632e-01 -3.33041e-01]
20Nov23_095148| [ 6.69652e-01  8.72101e-01 -1.64085e-01]
20Nov23_095148| [ 3.41736e-01  8.98305e-02  4.05198e-01]
20Nov23_095148| [ 2.27074e-01  8.46331e-01 -1.44322e-01]
20Nov23_095148| [ 6.03573e-01 -8.16247e-01 -7.74988e-02]
20Nov23_095148| [ 6.20717e-03  8.60449e-01 -2.75791e-01]
20Nov23_095148| [ 9.61293e-01  5.78074e-04 -6.99620e-02]
20Nov23_095148| [ 2.25284e-01 -9.64720e-01  1.38483e-01]
20Nov23_095148| [-2.69333e-01  7.96826e-01 -4.47025e-01]
20Nov23_095148| [-3.94057e-01 -5.68296e-01 -3.09060e-01]
20Nov23_095148| [ 1.13462e-01 -6.62818e-01 -4.94233e-01]
20Nov23_095148| [ 8.43231e-02  1.02165e+00  3.84557e-01]
20Nov23_095148| [ 4.76439e-01  3.90610e-01 -9.34270e-02]
20Nov23_095148| [-3.52813e-01  1.01680e+00 -1.56756e-01]
20Nov23_095148| [ 7.44184e-01 -6.22559e-01  4.71656e-01]
20Nov23_095148| [-3.25724e-02  8.04856e-01 -4.74885e-01]
20Nov23_095148| [-7.77151e-01 -5.56192e-01 -3.64250e-01]
20Nov23_095148| [ 4.19055e-01  1.05048e+00  1.13302e-01]
20Nov23_095148| [-2.11603e-01 -1.14325e-01 -1.91534e-01]
20Nov23_095148| [-1.57604e+00 -8.33752e-01  4.40403e-01]
20Nov23_095148| [-2.32387e-02 -2.84182e-01  2.42507e-01]
20Nov23_095148| [ 9.29496e-01 -1.06917e-01  2.47643e-01]
20Nov23_095148| [ 5.51908e-01  8.53966e-01 -3.68319e-01]
20Nov23_095148| [-7.43625e-01 -1.09987e+00 -4.07496e-02]]
20Nov23_095148|-- Bias --
20Nov23_095148|[0.65700 0.08603 0.07316]
20Nov23_095148|Layer 1:
20Nov23_095148|-- Config --
20Nov23_095148|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095148|-- Weights --
20Nov23_095148|[[ 0.78377 -0.55499 -0.47708]
20Nov23_095148| [-0.59071  0.65028 -0.40958]
20Nov23_095148| [-0.79088 -0.47553 -0.26780]]
20Nov23_095148|-- Bias --
20Nov23_095148|[ 0.25453 -0.37598 -0.43393]
20Nov23_095148|Layer 2:
20Nov23_095148|-- Config --
20Nov23_095148|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095148|-- Weights --
20Nov23_095148|[[-0.18759  0.25690]
20Nov23_095148| [-0.63942  0.79732]
20Nov23_095148| [ 0.19193 -0.35600]]
20Nov23_095148|-- Bias --
20Nov23_095148|[-1.29423 -0.06155]
20Nov23_095148|Predicting the validation and test data with the Best final individual.
20Nov23_095154| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_095154|-----------  ------------------  --------------------  ----------
20Nov23_095154|Validation         41.48                  12            0.01548
20Nov23_095154|   Test            36.40                  12            0.00595
20Nov23_095154|-------------------------- Test #2 --------------------------
20Nov23_095154|Best final individual weights
20Nov23_095154|Individual:
20Nov23_095154|-- Constant hidden layers --
20Nov23_095154|False
20Nov23_095154|Layer 0:
20Nov23_095154|-- Config --
20Nov23_095154|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095154|-- Weights --
20Nov23_095154|[[-4.78093e-01 -1.32987e-01 -1.98602e-01]
20Nov23_095154| [ 5.70296e-01  1.10707e-01 -2.04917e-01]
20Nov23_095154| [ 1.35368e-02  1.77761e+00 -2.52685e-01]
20Nov23_095154| [-1.26644e+00  3.57369e-01 -1.65181e-01]
20Nov23_095154| [-1.05634e+00  1.94476e+00  3.96681e-01]
20Nov23_095154| [-3.13175e-01 -8.64222e-01  7.56146e-02]
20Nov23_095154| [ 9.64959e-01  1.21650e+00  7.43693e-02]
20Nov23_095154| [ 2.00262e-01  1.09055e+00  3.21193e-01]
20Nov23_095154| [-1.02545e+00  2.09448e-01 -2.03886e-01]
20Nov23_095154| [ 3.44070e-01  2.59404e-01  1.48387e-02]
20Nov23_095154| [-1.22205e+00 -5.78311e-01 -4.46069e-01]
20Nov23_095154| [ 1.27455e-01  6.53705e-01 -4.11728e-01]
20Nov23_095154| [-8.22001e-01 -7.07268e-01 -4.60801e-01]
20Nov23_095154| [ 1.17331e-02  1.00342e+00 -2.38681e-01]
20Nov23_095154| [ 9.67231e-01  9.92537e-01  4.70941e-01]
20Nov23_095154| [ 3.28565e-01  6.93736e-01  1.20231e-01]
20Nov23_095154| [ 8.14875e-01 -9.84338e-02  1.18653e-02]
20Nov23_095154| [ 2.21745e-01 -1.17971e-01  3.13766e-01]
20Nov23_095154| [-6.10808e-01  1.17938e-01  4.57614e-03]
20Nov23_095154| [ 2.50763e-01 -1.14777e+00 -1.08223e-01]
20Nov23_095154| [-1.36903e-01  2.03549e-01  1.68996e-01]
20Nov23_095154| [ 8.39934e-01 -9.21186e-01 -3.08707e-01]
20Nov23_095154| [-6.47800e-01  1.47232e-01  1.00589e-01]
20Nov23_095154| [-1.63393e+00 -4.77786e-01 -4.84560e-01]
20Nov23_095154| [ 1.75349e-01  2.15510e-01 -9.56645e-02]
20Nov23_095154| [-5.44939e-01 -6.84742e-01 -2.11610e-01]
20Nov23_095154| [-1.18869e+00 -1.31627e+00  2.10714e-01]
20Nov23_095154| [-1.09169e+00  1.33832e+00 -3.63987e-01]
20Nov23_095154| [-1.82071e-01 -1.51525e-01  1.21841e-01]
20Nov23_095154| [ 2.93676e-01  4.31694e-01 -1.52107e-01]
20Nov23_095154| [ 7.99207e-01  6.13471e-01  1.34435e-01]
20Nov23_095154| [ 9.32988e-01  9.45293e-01  2.64422e-01]
20Nov23_095154| [ 5.17947e-01 -7.64332e-01 -4.78027e-01]
20Nov23_095154| [ 7.02416e-01 -1.51632e-01 -3.33041e-01]
20Nov23_095154| [ 6.69652e-01  8.72101e-01 -1.64085e-01]
20Nov23_095154| [ 3.41736e-01  8.98305e-02  4.05198e-01]
20Nov23_095154| [ 2.27074e-01  8.46331e-01 -1.44322e-01]
20Nov23_095154| [ 6.03573e-01 -8.16247e-01 -7.74988e-02]
20Nov23_095154| [ 6.20717e-03  8.60449e-01 -2.75791e-01]
20Nov23_095154| [ 9.61293e-01  5.78074e-04 -6.99620e-02]
20Nov23_095154| [ 2.25284e-01 -9.64720e-01  1.38483e-01]
20Nov23_095154| [-2.69333e-01  7.96826e-01 -4.47025e-01]
20Nov23_095154| [-3.94057e-01 -5.68296e-01 -3.09060e-01]
20Nov23_095154| [ 1.13462e-01 -6.62818e-01 -4.94233e-01]
20Nov23_095154| [ 8.43231e-02  1.02165e+00  3.84557e-01]
20Nov23_095154| [ 4.76439e-01  3.90610e-01 -9.34270e-02]
20Nov23_095154| [-3.52813e-01  1.01680e+00 -1.56756e-01]
20Nov23_095154| [ 7.44184e-01 -6.22559e-01  4.71656e-01]
20Nov23_095154| [-3.25724e-02  8.04856e-01 -4.74885e-01]
20Nov23_095154| [-7.77151e-01 -5.56192e-01 -3.64250e-01]
20Nov23_095154| [ 4.19055e-01  1.05048e+00  1.13302e-01]
20Nov23_095154| [-2.11603e-01 -1.14325e-01 -1.91534e-01]
20Nov23_095154| [-1.57604e+00 -8.33752e-01  4.40403e-01]
20Nov23_095154| [-2.32387e-02 -2.84182e-01  2.42507e-01]
20Nov23_095154| [ 9.29496e-01 -1.06917e-01  2.47643e-01]
20Nov23_095154| [ 5.51908e-01  8.53966e-01 -3.68319e-01]
20Nov23_095154| [-7.43625e-01 -1.09987e+00 -4.07496e-02]]
20Nov23_095154|-- Bias --
20Nov23_095154|[0.65700 0.08603 0.07316]
20Nov23_095154|Layer 1:
20Nov23_095154|-- Config --
20Nov23_095154|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095154|-- Weights --
20Nov23_095154|[[ 0.78377 -0.55499 -0.47708]
20Nov23_095154| [-0.59071  0.65028 -0.40958]
20Nov23_095154| [-0.79088 -0.47553 -0.26780]]
20Nov23_095154|-- Bias --
20Nov23_095154|[ 0.25453 -0.37598 -0.43393]
20Nov23_095154|Layer 2:
20Nov23_095154|-- Config --
20Nov23_095154|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095154|-- Weights --
20Nov23_095154|[[-0.18759  0.25690]
20Nov23_095154| [-0.63942  0.79732]
20Nov23_095154| [ 0.19193 -0.35600]]
20Nov23_095154|-- Bias --
20Nov23_095154|[-1.29423 -0.06155]
20Nov23_095154|Predicting the validation and test data with the Best final individual.
20Nov23_095159| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_095159|-----------  ------------------  --------------------  ----------
20Nov23_095159|Validation         41.48                  12            0.01548
20Nov23_095159|   Test            36.32                  12            0.00596
20Nov23_095159|-------------------------- Test #3 --------------------------
20Nov23_095159|Best final individual weights
20Nov23_095159|Individual:
20Nov23_095159|-- Constant hidden layers --
20Nov23_095159|False
20Nov23_095159|Layer 0:
20Nov23_095159|-- Config --
20Nov23_095159|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095159|-- Weights --
20Nov23_095159|[[-4.78093e-01 -1.32987e-01 -1.98602e-01]
20Nov23_095159| [ 5.70296e-01  1.10707e-01 -2.04917e-01]
20Nov23_095159| [ 1.35368e-02  1.77761e+00 -2.52685e-01]
20Nov23_095159| [-1.26644e+00  3.57369e-01 -1.65181e-01]
20Nov23_095159| [-1.05634e+00  1.94476e+00  3.96681e-01]
20Nov23_095159| [-3.13175e-01 -8.64222e-01  7.56146e-02]
20Nov23_095159| [ 9.64959e-01  1.21650e+00  7.43693e-02]
20Nov23_095159| [ 2.00262e-01  1.09055e+00  3.21193e-01]
20Nov23_095159| [-1.02545e+00  2.09448e-01 -2.03886e-01]
20Nov23_095159| [ 3.44070e-01  2.59404e-01  1.48387e-02]
20Nov23_095159| [-1.22205e+00 -5.78311e-01 -4.46069e-01]
20Nov23_095159| [ 1.27455e-01  6.53705e-01 -4.11728e-01]
20Nov23_095159| [-8.22001e-01 -7.07268e-01 -4.60801e-01]
20Nov23_095159| [ 1.17331e-02  1.00342e+00 -2.38681e-01]
20Nov23_095159| [ 9.67231e-01  9.92537e-01  4.70941e-01]
20Nov23_095159| [ 3.28565e-01  6.93736e-01  1.20231e-01]
20Nov23_095159| [ 8.14875e-01 -9.84338e-02  1.18653e-02]
20Nov23_095159| [ 2.21745e-01 -1.17971e-01  3.13766e-01]
20Nov23_095159| [-6.10808e-01  1.17938e-01  4.57614e-03]
20Nov23_095159| [ 2.50763e-01 -1.14777e+00 -1.08223e-01]
20Nov23_095159| [-1.36903e-01  2.03549e-01  1.68996e-01]
20Nov23_095159| [ 8.39934e-01 -9.21186e-01 -3.08707e-01]
20Nov23_095159| [-6.47800e-01  1.47232e-01  1.00589e-01]
20Nov23_095159| [-1.63393e+00 -4.77786e-01 -4.84560e-01]
20Nov23_095159| [ 1.75349e-01  2.15510e-01 -9.56645e-02]
20Nov23_095159| [-5.44939e-01 -6.84742e-01 -2.11610e-01]
20Nov23_095159| [-1.18869e+00 -1.31627e+00  2.10714e-01]
20Nov23_095159| [-1.09169e+00  1.33832e+00 -3.63987e-01]
20Nov23_095159| [-1.82071e-01 -1.51525e-01  1.21841e-01]
20Nov23_095159| [ 2.93676e-01  4.31694e-01 -1.52107e-01]
20Nov23_095159| [ 7.99207e-01  6.13471e-01  1.34435e-01]
20Nov23_095159| [ 9.32988e-01  9.45293e-01  2.64422e-01]
20Nov23_095159| [ 5.17947e-01 -7.64332e-01 -4.78027e-01]
20Nov23_095159| [ 7.02416e-01 -1.51632e-01 -3.33041e-01]
20Nov23_095159| [ 6.69652e-01  8.72101e-01 -1.64085e-01]
20Nov23_095159| [ 3.41736e-01  8.98305e-02  4.05198e-01]
20Nov23_095159| [ 2.27074e-01  8.46331e-01 -1.44322e-01]
20Nov23_095159| [ 6.03573e-01 -8.16247e-01 -7.74988e-02]
20Nov23_095159| [ 6.20717e-03  8.60449e-01 -2.75791e-01]
20Nov23_095159| [ 9.61293e-01  5.78074e-04 -6.99620e-02]
20Nov23_095159| [ 2.25284e-01 -9.64720e-01  1.38483e-01]
20Nov23_095159| [-2.69333e-01  7.96826e-01 -4.47025e-01]
20Nov23_095159| [-3.94057e-01 -5.68296e-01 -3.09060e-01]
20Nov23_095159| [ 1.13462e-01 -6.62818e-01 -4.94233e-01]
20Nov23_095159| [ 8.43231e-02  1.02165e+00  3.84557e-01]
20Nov23_095159| [ 4.76439e-01  3.90610e-01 -9.34270e-02]
20Nov23_095159| [-3.52813e-01  1.01680e+00 -1.56756e-01]
20Nov23_095159| [ 7.44184e-01 -6.22559e-01  4.71656e-01]
20Nov23_095159| [-3.25724e-02  8.04856e-01 -4.74885e-01]
20Nov23_095159| [-7.77151e-01 -5.56192e-01 -3.64250e-01]
20Nov23_095159| [ 4.19055e-01  1.05048e+00  1.13302e-01]
20Nov23_095159| [-2.11603e-01 -1.14325e-01 -1.91534e-01]
20Nov23_095159| [-1.57604e+00 -8.33752e-01  4.40403e-01]
20Nov23_095159| [-2.32387e-02 -2.84182e-01  2.42507e-01]
20Nov23_095159| [ 9.29496e-01 -1.06917e-01  2.47643e-01]
20Nov23_095159| [ 5.51908e-01  8.53966e-01 -3.68319e-01]
20Nov23_095159| [-7.43625e-01 -1.09987e+00 -4.07496e-02]]
20Nov23_095159|-- Bias --
20Nov23_095159|[0.65700 0.08603 0.07316]
20Nov23_095159|Layer 1:
20Nov23_095159|-- Config --
20Nov23_095159|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095159|-- Weights --
20Nov23_095159|[[ 0.78377 -0.55499 -0.47708]
20Nov23_095159| [-0.59071  0.65028 -0.40958]
20Nov23_095159| [-0.79088 -0.47553 -0.26780]]
20Nov23_095159|-- Bias --
20Nov23_095159|[ 0.25453 -0.37598 -0.43393]
20Nov23_095159|Layer 2:
20Nov23_095159|-- Config --
20Nov23_095159|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095159|-- Weights --
20Nov23_095159|[[-0.18759  0.25690]
20Nov23_095159| [-0.63942  0.79732]
20Nov23_095159| [ 0.19193 -0.35600]]
20Nov23_095159|-- Bias --
20Nov23_095159|[-1.29423 -0.06155]
20Nov23_095159|Predicting the validation and test data with the Best final individual.
20Nov23_095205| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_095205|-----------  ------------------  --------------------  ----------
20Nov23_095205|Validation         41.48                  12            0.01548
20Nov23_095205|   Test            36.32                  12            0.00596
20Nov23_095205|-------------------------- Test #4 --------------------------
20Nov23_095205|Best final individual weights
20Nov23_095205|Individual:
20Nov23_095205|-- Constant hidden layers --
20Nov23_095205|False
20Nov23_095205|Layer 0:
20Nov23_095205|-- Config --
20Nov23_095205|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095205|-- Weights --
20Nov23_095205|[[-4.78093e-01 -1.32987e-01 -1.98602e-01]
20Nov23_095205| [ 5.70296e-01  1.10707e-01 -2.04917e-01]
20Nov23_095205| [ 1.35368e-02  1.77761e+00 -2.52685e-01]
20Nov23_095205| [-1.26644e+00  3.57369e-01 -1.65181e-01]
20Nov23_095205| [-1.05634e+00  1.94476e+00  3.96681e-01]
20Nov23_095205| [-3.13175e-01 -8.64222e-01  7.56146e-02]
20Nov23_095205| [ 9.64959e-01  1.21650e+00  7.43693e-02]
20Nov23_095205| [ 2.00262e-01  1.09055e+00  3.21193e-01]
20Nov23_095205| [-1.02545e+00  2.09448e-01 -2.03886e-01]
20Nov23_095205| [ 3.44070e-01  2.59404e-01  1.48387e-02]
20Nov23_095205| [-1.22205e+00 -5.78311e-01 -4.46069e-01]
20Nov23_095205| [ 1.27455e-01  6.53705e-01 -4.11728e-01]
20Nov23_095205| [-8.22001e-01 -7.07268e-01 -4.60801e-01]
20Nov23_095205| [ 1.17331e-02  1.00342e+00 -2.38681e-01]
20Nov23_095205| [ 9.67231e-01  9.92537e-01  4.70941e-01]
20Nov23_095205| [ 3.28565e-01  6.93736e-01  1.20231e-01]
20Nov23_095205| [ 8.14875e-01 -9.84338e-02  1.18653e-02]
20Nov23_095205| [ 2.21745e-01 -1.17971e-01  3.13766e-01]
20Nov23_095205| [-6.10808e-01  1.17938e-01  4.57614e-03]
20Nov23_095205| [ 2.50763e-01 -1.14777e+00 -1.08223e-01]
20Nov23_095205| [-1.36903e-01  2.03549e-01  1.68996e-01]
20Nov23_095205| [ 8.39934e-01 -9.21186e-01 -3.08707e-01]
20Nov23_095205| [-6.47800e-01  1.47232e-01  1.00589e-01]
20Nov23_095205| [-1.63393e+00 -4.77786e-01 -4.84560e-01]
20Nov23_095205| [ 1.75349e-01  2.15510e-01 -9.56645e-02]
20Nov23_095205| [-5.44939e-01 -6.84742e-01 -2.11610e-01]
20Nov23_095205| [-1.18869e+00 -1.31627e+00  2.10714e-01]
20Nov23_095205| [-1.09169e+00  1.33832e+00 -3.63987e-01]
20Nov23_095205| [-1.82071e-01 -1.51525e-01  1.21841e-01]
20Nov23_095205| [ 2.93676e-01  4.31694e-01 -1.52107e-01]
20Nov23_095205| [ 7.99207e-01  6.13471e-01  1.34435e-01]
20Nov23_095205| [ 9.32988e-01  9.45293e-01  2.64422e-01]
20Nov23_095205| [ 5.17947e-01 -7.64332e-01 -4.78027e-01]
20Nov23_095205| [ 7.02416e-01 -1.51632e-01 -3.33041e-01]
20Nov23_095205| [ 6.69652e-01  8.72101e-01 -1.64085e-01]
20Nov23_095205| [ 3.41736e-01  8.98305e-02  4.05198e-01]
20Nov23_095205| [ 2.27074e-01  8.46331e-01 -1.44322e-01]
20Nov23_095205| [ 6.03573e-01 -8.16247e-01 -7.74988e-02]
20Nov23_095205| [ 6.20717e-03  8.60449e-01 -2.75791e-01]
20Nov23_095205| [ 9.61293e-01  5.78074e-04 -6.99620e-02]
20Nov23_095205| [ 2.25284e-01 -9.64720e-01  1.38483e-01]
20Nov23_095205| [-2.69333e-01  7.96826e-01 -4.47025e-01]
20Nov23_095205| [-3.94057e-01 -5.68296e-01 -3.09060e-01]
20Nov23_095205| [ 1.13462e-01 -6.62818e-01 -4.94233e-01]
20Nov23_095205| [ 8.43231e-02  1.02165e+00  3.84557e-01]
20Nov23_095205| [ 4.76439e-01  3.90610e-01 -9.34270e-02]
20Nov23_095205| [-3.52813e-01  1.01680e+00 -1.56756e-01]
20Nov23_095205| [ 7.44184e-01 -6.22559e-01  4.71656e-01]
20Nov23_095205| [-3.25724e-02  8.04856e-01 -4.74885e-01]
20Nov23_095205| [-7.77151e-01 -5.56192e-01 -3.64250e-01]
20Nov23_095205| [ 4.19055e-01  1.05048e+00  1.13302e-01]
20Nov23_095205| [-2.11603e-01 -1.14325e-01 -1.91534e-01]
20Nov23_095205| [-1.57604e+00 -8.33752e-01  4.40403e-01]
20Nov23_095205| [-2.32387e-02 -2.84182e-01  2.42507e-01]
20Nov23_095205| [ 9.29496e-01 -1.06917e-01  2.47643e-01]
20Nov23_095205| [ 5.51908e-01  8.53966e-01 -3.68319e-01]
20Nov23_095205| [-7.43625e-01 -1.09987e+00 -4.07496e-02]]
20Nov23_095205|-- Bias --
20Nov23_095205|[0.65700 0.08603 0.07316]
20Nov23_095205|Layer 1:
20Nov23_095205|-- Config --
20Nov23_095205|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095205|-- Weights --
20Nov23_095205|[[ 0.78377 -0.55499 -0.47708]
20Nov23_095205| [-0.59071  0.65028 -0.40958]
20Nov23_095205| [-0.79088 -0.47553 -0.26780]]
20Nov23_095205|-- Bias --
20Nov23_095205|[ 0.25453 -0.37598 -0.43393]
20Nov23_095205|Layer 2:
20Nov23_095205|-- Config --
20Nov23_095205|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095205|-- Weights --
20Nov23_095205|[[-0.18759  0.25690]
20Nov23_095205| [-0.63942  0.79732]
20Nov23_095205| [ 0.19193 -0.35600]]
20Nov23_095205|-- Bias --
20Nov23_095205|[-1.29423 -0.06155]
20Nov23_095205|Predicting the validation and test data with the Best final individual.
20Nov23_095211| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_095211|-----------  ------------------  --------------------  ----------
20Nov23_095211|Validation         41.57                  12            0.01547
20Nov23_095211|   Test            36.32                  12            0.00298
20Nov23_095211|-------------------------- Test #5 --------------------------
20Nov23_095211|Best final individual weights
20Nov23_095211|Individual:
20Nov23_095211|-- Constant hidden layers --
20Nov23_095211|False
20Nov23_095211|Layer 0:
20Nov23_095211|-- Config --
20Nov23_095211|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095211|-- Weights --
20Nov23_095211|[[-4.78093e-01 -1.32987e-01 -1.98602e-01]
20Nov23_095211| [ 5.70296e-01  1.10707e-01 -2.04917e-01]
20Nov23_095211| [ 1.35368e-02  1.77761e+00 -2.52685e-01]
20Nov23_095211| [-1.26644e+00  3.57369e-01 -1.65181e-01]
20Nov23_095211| [-1.05634e+00  1.94476e+00  3.96681e-01]
20Nov23_095211| [-3.13175e-01 -8.64222e-01  7.56146e-02]
20Nov23_095211| [ 9.64959e-01  1.21650e+00  7.43693e-02]
20Nov23_095211| [ 2.00262e-01  1.09055e+00  3.21193e-01]
20Nov23_095211| [-1.02545e+00  2.09448e-01 -2.03886e-01]
20Nov23_095211| [ 3.44070e-01  2.59404e-01  1.48387e-02]
20Nov23_095211| [-1.22205e+00 -5.78311e-01 -4.46069e-01]
20Nov23_095211| [ 1.27455e-01  6.53705e-01 -4.11728e-01]
20Nov23_095211| [-8.22001e-01 -7.07268e-01 -4.60801e-01]
20Nov23_095211| [ 1.17331e-02  1.00342e+00 -2.38681e-01]
20Nov23_095211| [ 9.67231e-01  9.92537e-01  4.70941e-01]
20Nov23_095211| [ 3.28565e-01  6.93736e-01  1.20231e-01]
20Nov23_095211| [ 8.14875e-01 -9.84338e-02  1.18653e-02]
20Nov23_095211| [ 2.21745e-01 -1.17971e-01  3.13766e-01]
20Nov23_095211| [-6.10808e-01  1.17938e-01  4.57614e-03]
20Nov23_095211| [ 2.50763e-01 -1.14777e+00 -1.08223e-01]
20Nov23_095211| [-1.36903e-01  2.03549e-01  1.68996e-01]
20Nov23_095211| [ 8.39934e-01 -9.21186e-01 -3.08707e-01]
20Nov23_095211| [-6.47800e-01  1.47232e-01  1.00589e-01]
20Nov23_095211| [-1.63393e+00 -4.77786e-01 -4.84560e-01]
20Nov23_095211| [ 1.75349e-01  2.15510e-01 -9.56645e-02]
20Nov23_095211| [-5.44939e-01 -6.84742e-01 -2.11610e-01]
20Nov23_095211| [-1.18869e+00 -1.31627e+00  2.10714e-01]
20Nov23_095211| [-1.09169e+00  1.33832e+00 -3.63987e-01]
20Nov23_095211| [-1.82071e-01 -1.51525e-01  1.21841e-01]
20Nov23_095211| [ 2.93676e-01  4.31694e-01 -1.52107e-01]
20Nov23_095211| [ 7.99207e-01  6.13471e-01  1.34435e-01]
20Nov23_095211| [ 9.32988e-01  9.45293e-01  2.64422e-01]
20Nov23_095211| [ 5.17947e-01 -7.64332e-01 -4.78027e-01]
20Nov23_095211| [ 7.02416e-01 -1.51632e-01 -3.33041e-01]
20Nov23_095211| [ 6.69652e-01  8.72101e-01 -1.64085e-01]
20Nov23_095211| [ 3.41736e-01  8.98305e-02  4.05198e-01]
20Nov23_095211| [ 2.27074e-01  8.46331e-01 -1.44322e-01]
20Nov23_095211| [ 6.03573e-01 -8.16247e-01 -7.74988e-02]
20Nov23_095211| [ 6.20717e-03  8.60449e-01 -2.75791e-01]
20Nov23_095211| [ 9.61293e-01  5.78074e-04 -6.99620e-02]
20Nov23_095211| [ 2.25284e-01 -9.64720e-01  1.38483e-01]
20Nov23_095211| [-2.69333e-01  7.96826e-01 -4.47025e-01]
20Nov23_095211| [-3.94057e-01 -5.68296e-01 -3.09060e-01]
20Nov23_095211| [ 1.13462e-01 -6.62818e-01 -4.94233e-01]
20Nov23_095211| [ 8.43231e-02  1.02165e+00  3.84557e-01]
20Nov23_095211| [ 4.76439e-01  3.90610e-01 -9.34270e-02]
20Nov23_095211| [-3.52813e-01  1.01680e+00 -1.56756e-01]
20Nov23_095211| [ 7.44184e-01 -6.22559e-01  4.71656e-01]
20Nov23_095211| [-3.25724e-02  8.04856e-01 -4.74885e-01]
20Nov23_095211| [-7.77151e-01 -5.56192e-01 -3.64250e-01]
20Nov23_095211| [ 4.19055e-01  1.05048e+00  1.13302e-01]
20Nov23_095211| [-2.11603e-01 -1.14325e-01 -1.91534e-01]
20Nov23_095211| [-1.57604e+00 -8.33752e-01  4.40403e-01]
20Nov23_095211| [-2.32387e-02 -2.84182e-01  2.42507e-01]
20Nov23_095211| [ 9.29496e-01 -1.06917e-01  2.47643e-01]
20Nov23_095211| [ 5.51908e-01  8.53966e-01 -3.68319e-01]
20Nov23_095211| [-7.43625e-01 -1.09987e+00 -4.07496e-02]]
20Nov23_095211|-- Bias --
20Nov23_095211|[0.65700 0.08603 0.07316]
20Nov23_095211|Layer 1:
20Nov23_095211|-- Config --
20Nov23_095211|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095211|-- Weights --
20Nov23_095211|[[ 0.78377 -0.55499 -0.47708]
20Nov23_095211| [-0.59071  0.65028 -0.40958]
20Nov23_095211| [-0.79088 -0.47553 -0.26780]]
20Nov23_095211|-- Bias --
20Nov23_095211|[ 0.25453 -0.37598 -0.43393]
20Nov23_095211|Layer 2:
20Nov23_095211|-- Config --
20Nov23_095211|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095211|-- Weights --
20Nov23_095211|[[-0.18759  0.25690]
20Nov23_095211| [-0.63942  0.79732]
20Nov23_095211| [ 0.19193 -0.35600]]
20Nov23_095211|-- Bias --
20Nov23_095211|[-1.29423 -0.06155]
20Nov23_095211|Predicting the validation and test data with the Best final individual.
20Nov23_095217| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_095217|-----------  ------------------  --------------------  ----------
20Nov23_095217|Validation         41.48                  12            0.01548
20Nov23_095217|   Test            36.32                  12            0.00596
20Nov23_095217|-------------------------- Test #6 --------------------------
20Nov23_095217|Best final individual weights
20Nov23_095217|Individual:
20Nov23_095217|-- Constant hidden layers --
20Nov23_095217|False
20Nov23_095217|Layer 0:
20Nov23_095217|-- Config --
20Nov23_095217|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095217|-- Weights --
20Nov23_095217|[[-4.78093e-01 -1.32987e-01 -1.98602e-01]
20Nov23_095217| [ 5.70296e-01  1.10707e-01 -2.04917e-01]
20Nov23_095217| [ 1.35368e-02  1.77761e+00 -2.52685e-01]
20Nov23_095217| [-1.26644e+00  3.57369e-01 -1.65181e-01]
20Nov23_095217| [-1.05634e+00  1.94476e+00  3.96681e-01]
20Nov23_095217| [-3.13175e-01 -8.64222e-01  7.56146e-02]
20Nov23_095217| [ 9.64959e-01  1.21650e+00  7.43693e-02]
20Nov23_095217| [ 2.00262e-01  1.09055e+00  3.21193e-01]
20Nov23_095217| [-1.02545e+00  2.09448e-01 -2.03886e-01]
20Nov23_095217| [ 3.44070e-01  2.59404e-01  1.48387e-02]
20Nov23_095217| [-1.22205e+00 -5.78311e-01 -4.46069e-01]
20Nov23_095217| [ 1.27455e-01  6.53705e-01 -4.11728e-01]
20Nov23_095217| [-8.22001e-01 -7.07268e-01 -4.60801e-01]
20Nov23_095217| [ 1.17331e-02  1.00342e+00 -2.38681e-01]
20Nov23_095217| [ 9.67231e-01  9.92537e-01  4.70941e-01]
20Nov23_095217| [ 3.28565e-01  6.93736e-01  1.20231e-01]
20Nov23_095217| [ 8.14875e-01 -9.84338e-02  1.18653e-02]
20Nov23_095217| [ 2.21745e-01 -1.17971e-01  3.13766e-01]
20Nov23_095217| [-6.10808e-01  1.17938e-01  4.57614e-03]
20Nov23_095217| [ 2.50763e-01 -1.14777e+00 -1.08223e-01]
20Nov23_095217| [-1.36903e-01  2.03549e-01  1.68996e-01]
20Nov23_095217| [ 8.39934e-01 -9.21186e-01 -3.08707e-01]
20Nov23_095217| [-6.47800e-01  1.47232e-01  1.00589e-01]
20Nov23_095217| [-1.63393e+00 -4.77786e-01 -4.84560e-01]
20Nov23_095217| [ 1.75349e-01  2.15510e-01 -9.56645e-02]
20Nov23_095217| [-5.44939e-01 -6.84742e-01 -2.11610e-01]
20Nov23_095217| [-1.18869e+00 -1.31627e+00  2.10714e-01]
20Nov23_095217| [-1.09169e+00  1.33832e+00 -3.63987e-01]
20Nov23_095217| [-1.82071e-01 -1.51525e-01  1.21841e-01]
20Nov23_095217| [ 2.93676e-01  4.31694e-01 -1.52107e-01]
20Nov23_095217| [ 7.99207e-01  6.13471e-01  1.34435e-01]
20Nov23_095217| [ 9.32988e-01  9.45293e-01  2.64422e-01]
20Nov23_095217| [ 5.17947e-01 -7.64332e-01 -4.78027e-01]
20Nov23_095217| [ 7.02416e-01 -1.51632e-01 -3.33041e-01]
20Nov23_095217| [ 6.69652e-01  8.72101e-01 -1.64085e-01]
20Nov23_095217| [ 3.41736e-01  8.98305e-02  4.05198e-01]
20Nov23_095217| [ 2.27074e-01  8.46331e-01 -1.44322e-01]
20Nov23_095217| [ 6.03573e-01 -8.16247e-01 -7.74988e-02]
20Nov23_095217| [ 6.20717e-03  8.60449e-01 -2.75791e-01]
20Nov23_095217| [ 9.61293e-01  5.78074e-04 -6.99620e-02]
20Nov23_095217| [ 2.25284e-01 -9.64720e-01  1.38483e-01]
20Nov23_095217| [-2.69333e-01  7.96826e-01 -4.47025e-01]
20Nov23_095217| [-3.94057e-01 -5.68296e-01 -3.09060e-01]
20Nov23_095217| [ 1.13462e-01 -6.62818e-01 -4.94233e-01]
20Nov23_095217| [ 8.43231e-02  1.02165e+00  3.84557e-01]
20Nov23_095217| [ 4.76439e-01  3.90610e-01 -9.34270e-02]
20Nov23_095217| [-3.52813e-01  1.01680e+00 -1.56756e-01]
20Nov23_095217| [ 7.44184e-01 -6.22559e-01  4.71656e-01]
20Nov23_095217| [-3.25724e-02  8.04856e-01 -4.74885e-01]
20Nov23_095217| [-7.77151e-01 -5.56192e-01 -3.64250e-01]
20Nov23_095217| [ 4.19055e-01  1.05048e+00  1.13302e-01]
20Nov23_095217| [-2.11603e-01 -1.14325e-01 -1.91534e-01]
20Nov23_095217| [-1.57604e+00 -8.33752e-01  4.40403e-01]
20Nov23_095217| [-2.32387e-02 -2.84182e-01  2.42507e-01]
20Nov23_095217| [ 9.29496e-01 -1.06917e-01  2.47643e-01]
20Nov23_095217| [ 5.51908e-01  8.53966e-01 -3.68319e-01]
20Nov23_095217| [-7.43625e-01 -1.09987e+00 -4.07496e-02]]
20Nov23_095217|-- Bias --
20Nov23_095217|[0.65700 0.08603 0.07316]
20Nov23_095217|Layer 1:
20Nov23_095217|-- Config --
20Nov23_095217|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095217|-- Weights --
20Nov23_095217|[[ 0.78377 -0.55499 -0.47708]
20Nov23_095217| [-0.59071  0.65028 -0.40958]
20Nov23_095217| [-0.79088 -0.47553 -0.26780]]
20Nov23_095217|-- Bias --
20Nov23_095217|[ 0.25453 -0.37598 -0.43393]
20Nov23_095217|Layer 2:
20Nov23_095217|-- Config --
20Nov23_095217|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095217|-- Weights --
20Nov23_095217|[[-0.18759  0.25690]
20Nov23_095217| [-0.63942  0.79732]
20Nov23_095217| [ 0.19193 -0.35600]]
20Nov23_095217|-- Bias --
20Nov23_095217|[-1.29423 -0.06155]
20Nov23_095217|Predicting the validation and test data with the Best final individual.
20Nov23_095222| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_095222|-----------  ------------------  --------------------  ----------
20Nov23_095222|Validation         41.57                  12            0.01547
20Nov23_095222|   Test            36.32                  12            0.00596
20Nov23_095222|-------------------------- Test #7 --------------------------
20Nov23_095222|Best final individual weights
20Nov23_095222|Individual:
20Nov23_095222|-- Constant hidden layers --
20Nov23_095222|False
20Nov23_095222|Layer 0:
20Nov23_095222|-- Config --
20Nov23_095222|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095222|-- Weights --
20Nov23_095222|[[-4.78093e-01 -1.32987e-01 -1.98602e-01]
20Nov23_095222| [ 5.70296e-01  1.10707e-01 -2.04917e-01]
20Nov23_095222| [ 1.35368e-02  1.77761e+00 -2.52685e-01]
20Nov23_095222| [-1.26644e+00  3.57369e-01 -1.65181e-01]
20Nov23_095222| [-1.05634e+00  1.94476e+00  3.96681e-01]
20Nov23_095222| [-3.13175e-01 -8.64222e-01  7.56146e-02]
20Nov23_095222| [ 9.64959e-01  1.21650e+00  7.43693e-02]
20Nov23_095222| [ 2.00262e-01  1.09055e+00  3.21193e-01]
20Nov23_095222| [-1.02545e+00  2.09448e-01 -2.03886e-01]
20Nov23_095222| [ 3.44070e-01  2.59404e-01  1.48387e-02]
20Nov23_095222| [-1.22205e+00 -5.78311e-01 -4.46069e-01]
20Nov23_095222| [ 1.27455e-01  6.53705e-01 -4.11728e-01]
20Nov23_095222| [-8.22001e-01 -7.07268e-01 -4.60801e-01]
20Nov23_095222| [ 1.17331e-02  1.00342e+00 -2.38681e-01]
20Nov23_095222| [ 9.67231e-01  9.92537e-01  4.70941e-01]
20Nov23_095222| [ 3.28565e-01  6.93736e-01  1.20231e-01]
20Nov23_095222| [ 8.14875e-01 -9.84338e-02  1.18653e-02]
20Nov23_095222| [ 2.21745e-01 -1.17971e-01  3.13766e-01]
20Nov23_095222| [-6.10808e-01  1.17938e-01  4.57614e-03]
20Nov23_095222| [ 2.50763e-01 -1.14777e+00 -1.08223e-01]
20Nov23_095222| [-1.36903e-01  2.03549e-01  1.68996e-01]
20Nov23_095222| [ 8.39934e-01 -9.21186e-01 -3.08707e-01]
20Nov23_095222| [-6.47800e-01  1.47232e-01  1.00589e-01]
20Nov23_095222| [-1.63393e+00 -4.77786e-01 -4.84560e-01]
20Nov23_095222| [ 1.75349e-01  2.15510e-01 -9.56645e-02]
20Nov23_095222| [-5.44939e-01 -6.84742e-01 -2.11610e-01]
20Nov23_095222| [-1.18869e+00 -1.31627e+00  2.10714e-01]
20Nov23_095222| [-1.09169e+00  1.33832e+00 -3.63987e-01]
20Nov23_095222| [-1.82071e-01 -1.51525e-01  1.21841e-01]
20Nov23_095222| [ 2.93676e-01  4.31694e-01 -1.52107e-01]
20Nov23_095222| [ 7.99207e-01  6.13471e-01  1.34435e-01]
20Nov23_095222| [ 9.32988e-01  9.45293e-01  2.64422e-01]
20Nov23_095222| [ 5.17947e-01 -7.64332e-01 -4.78027e-01]
20Nov23_095222| [ 7.02416e-01 -1.51632e-01 -3.33041e-01]
20Nov23_095222| [ 6.69652e-01  8.72101e-01 -1.64085e-01]
20Nov23_095222| [ 3.41736e-01  8.98305e-02  4.05198e-01]
20Nov23_095222| [ 2.27074e-01  8.46331e-01 -1.44322e-01]
20Nov23_095222| [ 6.03573e-01 -8.16247e-01 -7.74988e-02]
20Nov23_095222| [ 6.20717e-03  8.60449e-01 -2.75791e-01]
20Nov23_095222| [ 9.61293e-01  5.78074e-04 -6.99620e-02]
20Nov23_095222| [ 2.25284e-01 -9.64720e-01  1.38483e-01]
20Nov23_095222| [-2.69333e-01  7.96826e-01 -4.47025e-01]
20Nov23_095222| [-3.94057e-01 -5.68296e-01 -3.09060e-01]
20Nov23_095222| [ 1.13462e-01 -6.62818e-01 -4.94233e-01]
20Nov23_095222| [ 8.43231e-02  1.02165e+00  3.84557e-01]
20Nov23_095222| [ 4.76439e-01  3.90610e-01 -9.34270e-02]
20Nov23_095222| [-3.52813e-01  1.01680e+00 -1.56756e-01]
20Nov23_095222| [ 7.44184e-01 -6.22559e-01  4.71656e-01]
20Nov23_095222| [-3.25724e-02  8.04856e-01 -4.74885e-01]
20Nov23_095222| [-7.77151e-01 -5.56192e-01 -3.64250e-01]
20Nov23_095222| [ 4.19055e-01  1.05048e+00  1.13302e-01]
20Nov23_095222| [-2.11603e-01 -1.14325e-01 -1.91534e-01]
20Nov23_095222| [-1.57604e+00 -8.33752e-01  4.40403e-01]
20Nov23_095222| [-2.32387e-02 -2.84182e-01  2.42507e-01]
20Nov23_095222| [ 9.29496e-01 -1.06917e-01  2.47643e-01]
20Nov23_095222| [ 5.51908e-01  8.53966e-01 -3.68319e-01]
20Nov23_095222| [-7.43625e-01 -1.09987e+00 -4.07496e-02]]
20Nov23_095222|-- Bias --
20Nov23_095222|[0.65700 0.08603 0.07316]
20Nov23_095222|Layer 1:
20Nov23_095222|-- Config --
20Nov23_095222|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095222|-- Weights --
20Nov23_095222|[[ 0.78377 -0.55499 -0.47708]
20Nov23_095222| [-0.59071  0.65028 -0.40958]
20Nov23_095222| [-0.79088 -0.47553 -0.26780]]
20Nov23_095222|-- Bias --
20Nov23_095222|[ 0.25453 -0.37598 -0.43393]
20Nov23_095222|Layer 2:
20Nov23_095222|-- Config --
20Nov23_095222|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095222|-- Weights --
20Nov23_095222|[[-0.18759  0.25690]
20Nov23_095222| [-0.63942  0.79732]
20Nov23_095222| [ 0.19193 -0.35600]]
20Nov23_095222|-- Bias --
20Nov23_095222|[-1.29423 -0.06155]
20Nov23_095222|Predicting the validation and test data with the Best final individual.
20Nov23_095228| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_095228|-----------  ------------------  --------------------  ----------
20Nov23_095228|Validation         41.57                  12            0.01547
20Nov23_095228|   Test            36.40                  12            0.00595
20Nov23_095228|-------------------------- Test #8 --------------------------
20Nov23_095228|Best final individual weights
20Nov23_095228|Individual:
20Nov23_095228|-- Constant hidden layers --
20Nov23_095228|False
20Nov23_095228|Layer 0:
20Nov23_095228|-- Config --
20Nov23_095228|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095228|-- Weights --
20Nov23_095228|[[-4.78093e-01 -1.32987e-01 -1.98602e-01]
20Nov23_095228| [ 5.70296e-01  1.10707e-01 -2.04917e-01]
20Nov23_095228| [ 1.35368e-02  1.77761e+00 -2.52685e-01]
20Nov23_095228| [-1.26644e+00  3.57369e-01 -1.65181e-01]
20Nov23_095228| [-1.05634e+00  1.94476e+00  3.96681e-01]
20Nov23_095228| [-3.13175e-01 -8.64222e-01  7.56146e-02]
20Nov23_095228| [ 9.64959e-01  1.21650e+00  7.43693e-02]
20Nov23_095228| [ 2.00262e-01  1.09055e+00  3.21193e-01]
20Nov23_095228| [-1.02545e+00  2.09448e-01 -2.03886e-01]
20Nov23_095228| [ 3.44070e-01  2.59404e-01  1.48387e-02]
20Nov23_095228| [-1.22205e+00 -5.78311e-01 -4.46069e-01]
20Nov23_095228| [ 1.27455e-01  6.53705e-01 -4.11728e-01]
20Nov23_095228| [-8.22001e-01 -7.07268e-01 -4.60801e-01]
20Nov23_095228| [ 1.17331e-02  1.00342e+00 -2.38681e-01]
20Nov23_095228| [ 9.67231e-01  9.92537e-01  4.70941e-01]
20Nov23_095228| [ 3.28565e-01  6.93736e-01  1.20231e-01]
20Nov23_095228| [ 8.14875e-01 -9.84338e-02  1.18653e-02]
20Nov23_095228| [ 2.21745e-01 -1.17971e-01  3.13766e-01]
20Nov23_095228| [-6.10808e-01  1.17938e-01  4.57614e-03]
20Nov23_095228| [ 2.50763e-01 -1.14777e+00 -1.08223e-01]
20Nov23_095228| [-1.36903e-01  2.03549e-01  1.68996e-01]
20Nov23_095228| [ 8.39934e-01 -9.21186e-01 -3.08707e-01]
20Nov23_095228| [-6.47800e-01  1.47232e-01  1.00589e-01]
20Nov23_095228| [-1.63393e+00 -4.77786e-01 -4.84560e-01]
20Nov23_095228| [ 1.75349e-01  2.15510e-01 -9.56645e-02]
20Nov23_095228| [-5.44939e-01 -6.84742e-01 -2.11610e-01]
20Nov23_095228| [-1.18869e+00 -1.31627e+00  2.10714e-01]
20Nov23_095228| [-1.09169e+00  1.33832e+00 -3.63987e-01]
20Nov23_095228| [-1.82071e-01 -1.51525e-01  1.21841e-01]
20Nov23_095228| [ 2.93676e-01  4.31694e-01 -1.52107e-01]
20Nov23_095228| [ 7.99207e-01  6.13471e-01  1.34435e-01]
20Nov23_095228| [ 9.32988e-01  9.45293e-01  2.64422e-01]
20Nov23_095228| [ 5.17947e-01 -7.64332e-01 -4.78027e-01]
20Nov23_095228| [ 7.02416e-01 -1.51632e-01 -3.33041e-01]
20Nov23_095228| [ 6.69652e-01  8.72101e-01 -1.64085e-01]
20Nov23_095228| [ 3.41736e-01  8.98305e-02  4.05198e-01]
20Nov23_095228| [ 2.27074e-01  8.46331e-01 -1.44322e-01]
20Nov23_095228| [ 6.03573e-01 -8.16247e-01 -7.74988e-02]
20Nov23_095228| [ 6.20717e-03  8.60449e-01 -2.75791e-01]
20Nov23_095228| [ 9.61293e-01  5.78074e-04 -6.99620e-02]
20Nov23_095228| [ 2.25284e-01 -9.64720e-01  1.38483e-01]
20Nov23_095228| [-2.69333e-01  7.96826e-01 -4.47025e-01]
20Nov23_095228| [-3.94057e-01 -5.68296e-01 -3.09060e-01]
20Nov23_095228| [ 1.13462e-01 -6.62818e-01 -4.94233e-01]
20Nov23_095228| [ 8.43231e-02  1.02165e+00  3.84557e-01]
20Nov23_095228| [ 4.76439e-01  3.90610e-01 -9.34270e-02]
20Nov23_095228| [-3.52813e-01  1.01680e+00 -1.56756e-01]
20Nov23_095228| [ 7.44184e-01 -6.22559e-01  4.71656e-01]
20Nov23_095228| [-3.25724e-02  8.04856e-01 -4.74885e-01]
20Nov23_095228| [-7.77151e-01 -5.56192e-01 -3.64250e-01]
20Nov23_095228| [ 4.19055e-01  1.05048e+00  1.13302e-01]
20Nov23_095228| [-2.11603e-01 -1.14325e-01 -1.91534e-01]
20Nov23_095228| [-1.57604e+00 -8.33752e-01  4.40403e-01]
20Nov23_095228| [-2.32387e-02 -2.84182e-01  2.42507e-01]
20Nov23_095228| [ 9.29496e-01 -1.06917e-01  2.47643e-01]
20Nov23_095228| [ 5.51908e-01  8.53966e-01 -3.68319e-01]
20Nov23_095228| [-7.43625e-01 -1.09987e+00 -4.07496e-02]]
20Nov23_095228|-- Bias --
20Nov23_095228|[0.65700 0.08603 0.07316]
20Nov23_095228|Layer 1:
20Nov23_095228|-- Config --
20Nov23_095228|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095228|-- Weights --
20Nov23_095228|[[ 0.78377 -0.55499 -0.47708]
20Nov23_095228| [-0.59071  0.65028 -0.40958]
20Nov23_095228| [-0.79088 -0.47553 -0.26780]]
20Nov23_095228|-- Bias --
20Nov23_095228|[ 0.25453 -0.37598 -0.43393]
20Nov23_095228|Layer 2:
20Nov23_095228|-- Config --
20Nov23_095228|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095228|-- Weights --
20Nov23_095228|[[-0.18759  0.25690]
20Nov23_095228| [-0.63942  0.79732]
20Nov23_095228| [ 0.19193 -0.35600]]
20Nov23_095228|-- Bias --
20Nov23_095228|[-1.29423 -0.06155]
20Nov23_095228|Predicting the validation and test data with the Best final individual.
20Nov23_095234| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_095234|-----------  ------------------  --------------------  ----------
20Nov23_095234|Validation         42.00                  12            0.00000
20Nov23_095234|   Test            36.32                  12            0.00596
20Nov23_095234|-------------------------- Test #9 --------------------------
20Nov23_095234|Best final individual weights
20Nov23_095234|Individual:
20Nov23_095234|-- Constant hidden layers --
20Nov23_095234|False
20Nov23_095234|Layer 0:
20Nov23_095234|-- Config --
20Nov23_095234|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095234|-- Weights --
20Nov23_095234|[[-4.78093e-01 -1.32987e-01 -1.98602e-01]
20Nov23_095234| [ 5.70296e-01  1.10707e-01 -2.04917e-01]
20Nov23_095234| [ 1.35368e-02  1.77761e+00 -2.52685e-01]
20Nov23_095234| [-1.26644e+00  3.57369e-01 -1.65181e-01]
20Nov23_095234| [-1.05634e+00  1.94476e+00  3.96681e-01]
20Nov23_095234| [-3.13175e-01 -8.64222e-01  7.56146e-02]
20Nov23_095234| [ 9.64959e-01  1.21650e+00  7.43693e-02]
20Nov23_095234| [ 2.00262e-01  1.09055e+00  3.21193e-01]
20Nov23_095234| [-1.02545e+00  2.09448e-01 -2.03886e-01]
20Nov23_095234| [ 3.44070e-01  2.59404e-01  1.48387e-02]
20Nov23_095234| [-1.22205e+00 -5.78311e-01 -4.46069e-01]
20Nov23_095234| [ 1.27455e-01  6.53705e-01 -4.11728e-01]
20Nov23_095234| [-8.22001e-01 -7.07268e-01 -4.60801e-01]
20Nov23_095234| [ 1.17331e-02  1.00342e+00 -2.38681e-01]
20Nov23_095234| [ 9.67231e-01  9.92537e-01  4.70941e-01]
20Nov23_095234| [ 3.28565e-01  6.93736e-01  1.20231e-01]
20Nov23_095234| [ 8.14875e-01 -9.84338e-02  1.18653e-02]
20Nov23_095234| [ 2.21745e-01 -1.17971e-01  3.13766e-01]
20Nov23_095234| [-6.10808e-01  1.17938e-01  4.57614e-03]
20Nov23_095234| [ 2.50763e-01 -1.14777e+00 -1.08223e-01]
20Nov23_095234| [-1.36903e-01  2.03549e-01  1.68996e-01]
20Nov23_095234| [ 8.39934e-01 -9.21186e-01 -3.08707e-01]
20Nov23_095234| [-6.47800e-01  1.47232e-01  1.00589e-01]
20Nov23_095234| [-1.63393e+00 -4.77786e-01 -4.84560e-01]
20Nov23_095234| [ 1.75349e-01  2.15510e-01 -9.56645e-02]
20Nov23_095234| [-5.44939e-01 -6.84742e-01 -2.11610e-01]
20Nov23_095234| [-1.18869e+00 -1.31627e+00  2.10714e-01]
20Nov23_095234| [-1.09169e+00  1.33832e+00 -3.63987e-01]
20Nov23_095234| [-1.82071e-01 -1.51525e-01  1.21841e-01]
20Nov23_095234| [ 2.93676e-01  4.31694e-01 -1.52107e-01]
20Nov23_095234| [ 7.99207e-01  6.13471e-01  1.34435e-01]
20Nov23_095234| [ 9.32988e-01  9.45293e-01  2.64422e-01]
20Nov23_095234| [ 5.17947e-01 -7.64332e-01 -4.78027e-01]
20Nov23_095234| [ 7.02416e-01 -1.51632e-01 -3.33041e-01]
20Nov23_095234| [ 6.69652e-01  8.72101e-01 -1.64085e-01]
20Nov23_095234| [ 3.41736e-01  8.98305e-02  4.05198e-01]
20Nov23_095234| [ 2.27074e-01  8.46331e-01 -1.44322e-01]
20Nov23_095234| [ 6.03573e-01 -8.16247e-01 -7.74988e-02]
20Nov23_095234| [ 6.20717e-03  8.60449e-01 -2.75791e-01]
20Nov23_095234| [ 9.61293e-01  5.78074e-04 -6.99620e-02]
20Nov23_095234| [ 2.25284e-01 -9.64720e-01  1.38483e-01]
20Nov23_095234| [-2.69333e-01  7.96826e-01 -4.47025e-01]
20Nov23_095234| [-3.94057e-01 -5.68296e-01 -3.09060e-01]
20Nov23_095234| [ 1.13462e-01 -6.62818e-01 -4.94233e-01]
20Nov23_095234| [ 8.43231e-02  1.02165e+00  3.84557e-01]
20Nov23_095234| [ 4.76439e-01  3.90610e-01 -9.34270e-02]
20Nov23_095234| [-3.52813e-01  1.01680e+00 -1.56756e-01]
20Nov23_095234| [ 7.44184e-01 -6.22559e-01  4.71656e-01]
20Nov23_095234| [-3.25724e-02  8.04856e-01 -4.74885e-01]
20Nov23_095234| [-7.77151e-01 -5.56192e-01 -3.64250e-01]
20Nov23_095234| [ 4.19055e-01  1.05048e+00  1.13302e-01]
20Nov23_095234| [-2.11603e-01 -1.14325e-01 -1.91534e-01]
20Nov23_095234| [-1.57604e+00 -8.33752e-01  4.40403e-01]
20Nov23_095234| [-2.32387e-02 -2.84182e-01  2.42507e-01]
20Nov23_095234| [ 9.29496e-01 -1.06917e-01  2.47643e-01]
20Nov23_095234| [ 5.51908e-01  8.53966e-01 -3.68319e-01]
20Nov23_095234| [-7.43625e-01 -1.09987e+00 -4.07496e-02]]
20Nov23_095234|-- Bias --
20Nov23_095234|[0.65700 0.08603 0.07316]
20Nov23_095234|Layer 1:
20Nov23_095234|-- Config --
20Nov23_095234|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095234|-- Weights --
20Nov23_095234|[[ 0.78377 -0.55499 -0.47708]
20Nov23_095234| [-0.59071  0.65028 -0.40958]
20Nov23_095234| [-0.79088 -0.47553 -0.26780]]
20Nov23_095234|-- Bias --
20Nov23_095234|[ 0.25453 -0.37598 -0.43393]
20Nov23_095234|Layer 2:
20Nov23_095234|-- Config --
20Nov23_095234|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095234|-- Weights --
20Nov23_095234|[[-0.18759  0.25690]
20Nov23_095234| [-0.63942  0.79732]
20Nov23_095234| [ 0.19193 -0.35600]]
20Nov23_095234|-- Bias --
20Nov23_095234|[-1.29423 -0.06155]
20Nov23_095234|Predicting the validation and test data with the Best final individual.
20Nov23_095240| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_095240|-----------  ------------------  --------------------  ----------
20Nov23_095240|Validation         41.48                  12            0.01548
20Nov23_095240|   Test            36.32                  12            0.00892
20Nov23_095240|-------------------------- Test #10 --------------------------
20Nov23_095240|Best final individual weights
20Nov23_095240|Individual:
20Nov23_095240|-- Constant hidden layers --
20Nov23_095240|False
20Nov23_095240|Layer 0:
20Nov23_095240|-- Config --
20Nov23_095240|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095240|-- Weights --
20Nov23_095240|[[-4.78093e-01 -1.32987e-01 -1.98602e-01]
20Nov23_095240| [ 5.70296e-01  1.10707e-01 -2.04917e-01]
20Nov23_095240| [ 1.35368e-02  1.77761e+00 -2.52685e-01]
20Nov23_095240| [-1.26644e+00  3.57369e-01 -1.65181e-01]
20Nov23_095240| [-1.05634e+00  1.94476e+00  3.96681e-01]
20Nov23_095240| [-3.13175e-01 -8.64222e-01  7.56146e-02]
20Nov23_095240| [ 9.64959e-01  1.21650e+00  7.43693e-02]
20Nov23_095240| [ 2.00262e-01  1.09055e+00  3.21193e-01]
20Nov23_095240| [-1.02545e+00  2.09448e-01 -2.03886e-01]
20Nov23_095240| [ 3.44070e-01  2.59404e-01  1.48387e-02]
20Nov23_095240| [-1.22205e+00 -5.78311e-01 -4.46069e-01]
20Nov23_095240| [ 1.27455e-01  6.53705e-01 -4.11728e-01]
20Nov23_095240| [-8.22001e-01 -7.07268e-01 -4.60801e-01]
20Nov23_095240| [ 1.17331e-02  1.00342e+00 -2.38681e-01]
20Nov23_095240| [ 9.67231e-01  9.92537e-01  4.70941e-01]
20Nov23_095240| [ 3.28565e-01  6.93736e-01  1.20231e-01]
20Nov23_095240| [ 8.14875e-01 -9.84338e-02  1.18653e-02]
20Nov23_095240| [ 2.21745e-01 -1.17971e-01  3.13766e-01]
20Nov23_095240| [-6.10808e-01  1.17938e-01  4.57614e-03]
20Nov23_095240| [ 2.50763e-01 -1.14777e+00 -1.08223e-01]
20Nov23_095240| [-1.36903e-01  2.03549e-01  1.68996e-01]
20Nov23_095240| [ 8.39934e-01 -9.21186e-01 -3.08707e-01]
20Nov23_095240| [-6.47800e-01  1.47232e-01  1.00589e-01]
20Nov23_095240| [-1.63393e+00 -4.77786e-01 -4.84560e-01]
20Nov23_095240| [ 1.75349e-01  2.15510e-01 -9.56645e-02]
20Nov23_095240| [-5.44939e-01 -6.84742e-01 -2.11610e-01]
20Nov23_095240| [-1.18869e+00 -1.31627e+00  2.10714e-01]
20Nov23_095240| [-1.09169e+00  1.33832e+00 -3.63987e-01]
20Nov23_095240| [-1.82071e-01 -1.51525e-01  1.21841e-01]
20Nov23_095240| [ 2.93676e-01  4.31694e-01 -1.52107e-01]
20Nov23_095240| [ 7.99207e-01  6.13471e-01  1.34435e-01]
20Nov23_095240| [ 9.32988e-01  9.45293e-01  2.64422e-01]
20Nov23_095240| [ 5.17947e-01 -7.64332e-01 -4.78027e-01]
20Nov23_095240| [ 7.02416e-01 -1.51632e-01 -3.33041e-01]
20Nov23_095240| [ 6.69652e-01  8.72101e-01 -1.64085e-01]
20Nov23_095240| [ 3.41736e-01  8.98305e-02  4.05198e-01]
20Nov23_095240| [ 2.27074e-01  8.46331e-01 -1.44322e-01]
20Nov23_095240| [ 6.03573e-01 -8.16247e-01 -7.74988e-02]
20Nov23_095240| [ 6.20717e-03  8.60449e-01 -2.75791e-01]
20Nov23_095240| [ 9.61293e-01  5.78074e-04 -6.99620e-02]
20Nov23_095240| [ 2.25284e-01 -9.64720e-01  1.38483e-01]
20Nov23_095240| [-2.69333e-01  7.96826e-01 -4.47025e-01]
20Nov23_095240| [-3.94057e-01 -5.68296e-01 -3.09060e-01]
20Nov23_095240| [ 1.13462e-01 -6.62818e-01 -4.94233e-01]
20Nov23_095240| [ 8.43231e-02  1.02165e+00  3.84557e-01]
20Nov23_095240| [ 4.76439e-01  3.90610e-01 -9.34270e-02]
20Nov23_095240| [-3.52813e-01  1.01680e+00 -1.56756e-01]
20Nov23_095240| [ 7.44184e-01 -6.22559e-01  4.71656e-01]
20Nov23_095240| [-3.25724e-02  8.04856e-01 -4.74885e-01]
20Nov23_095240| [-7.77151e-01 -5.56192e-01 -3.64250e-01]
20Nov23_095240| [ 4.19055e-01  1.05048e+00  1.13302e-01]
20Nov23_095240| [-2.11603e-01 -1.14325e-01 -1.91534e-01]
20Nov23_095240| [-1.57604e+00 -8.33752e-01  4.40403e-01]
20Nov23_095240| [-2.32387e-02 -2.84182e-01  2.42507e-01]
20Nov23_095240| [ 9.29496e-01 -1.06917e-01  2.47643e-01]
20Nov23_095240| [ 5.51908e-01  8.53966e-01 -3.68319e-01]
20Nov23_095240| [-7.43625e-01 -1.09987e+00 -4.07496e-02]]
20Nov23_095240|-- Bias --
20Nov23_095240|[0.65700 0.08603 0.07316]
20Nov23_095240|Layer 1:
20Nov23_095240|-- Config --
20Nov23_095240|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095240|-- Weights --
20Nov23_095240|[[ 0.78377 -0.55499 -0.47708]
20Nov23_095240| [-0.59071  0.65028 -0.40958]
20Nov23_095240| [-0.79088 -0.47553 -0.26780]]
20Nov23_095240|-- Bias --
20Nov23_095240|[ 0.25453 -0.37598 -0.43393]
20Nov23_095240|Layer 2:
20Nov23_095240|-- Config --
20Nov23_095240|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095240|-- Weights --
20Nov23_095240|[[-0.18759  0.25690]
20Nov23_095240| [-0.63942  0.79732]
20Nov23_095240| [ 0.19193 -0.35600]]
20Nov23_095240|-- Bias --
20Nov23_095240|[-1.29423 -0.06155]
20Nov23_095240|Predicting the validation and test data with the Best final individual.
20Nov23_095245| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_095245|-----------  ------------------  --------------------  ----------
20Nov23_095245|Validation         41.48                  12            0.01548
20Nov23_095245|   Test            36.32                  12            0.00892
20Nov23_095245|-------------------------- Test #11 --------------------------
20Nov23_095245|Best final individual weights
20Nov23_095245|Individual:
20Nov23_095245|-- Constant hidden layers --
20Nov23_095245|False
20Nov23_095245|Layer 0:
20Nov23_095245|-- Config --
20Nov23_095245|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095245|-- Weights --
20Nov23_095245|[[-4.78093e-01 -1.32987e-01 -1.98602e-01]
20Nov23_095245| [ 5.70296e-01  1.10707e-01 -2.04917e-01]
20Nov23_095245| [ 1.35368e-02  1.77761e+00 -2.52685e-01]
20Nov23_095245| [-1.26644e+00  3.57369e-01 -1.65181e-01]
20Nov23_095245| [-1.05634e+00  1.94476e+00  3.96681e-01]
20Nov23_095245| [-3.13175e-01 -8.64222e-01  7.56146e-02]
20Nov23_095245| [ 9.64959e-01  1.21650e+00  7.43693e-02]
20Nov23_095245| [ 2.00262e-01  1.09055e+00  3.21193e-01]
20Nov23_095245| [-1.02545e+00  2.09448e-01 -2.03886e-01]
20Nov23_095245| [ 3.44070e-01  2.59404e-01  1.48387e-02]
20Nov23_095245| [-1.22205e+00 -5.78311e-01 -4.46069e-01]
20Nov23_095245| [ 1.27455e-01  6.53705e-01 -4.11728e-01]
20Nov23_095245| [-8.22001e-01 -7.07268e-01 -4.60801e-01]
20Nov23_095245| [ 1.17331e-02  1.00342e+00 -2.38681e-01]
20Nov23_095245| [ 9.67231e-01  9.92537e-01  4.70941e-01]
20Nov23_095245| [ 3.28565e-01  6.93736e-01  1.20231e-01]
20Nov23_095245| [ 8.14875e-01 -9.84338e-02  1.18653e-02]
20Nov23_095245| [ 2.21745e-01 -1.17971e-01  3.13766e-01]
20Nov23_095245| [-6.10808e-01  1.17938e-01  4.57614e-03]
20Nov23_095245| [ 2.50763e-01 -1.14777e+00 -1.08223e-01]
20Nov23_095245| [-1.36903e-01  2.03549e-01  1.68996e-01]
20Nov23_095245| [ 8.39934e-01 -9.21186e-01 -3.08707e-01]
20Nov23_095245| [-6.47800e-01  1.47232e-01  1.00589e-01]
20Nov23_095245| [-1.63393e+00 -4.77786e-01 -4.84560e-01]
20Nov23_095245| [ 1.75349e-01  2.15510e-01 -9.56645e-02]
20Nov23_095245| [-5.44939e-01 -6.84742e-01 -2.11610e-01]
20Nov23_095245| [-1.18869e+00 -1.31627e+00  2.10714e-01]
20Nov23_095245| [-1.09169e+00  1.33832e+00 -3.63987e-01]
20Nov23_095245| [-1.82071e-01 -1.51525e-01  1.21841e-01]
20Nov23_095245| [ 2.93676e-01  4.31694e-01 -1.52107e-01]
20Nov23_095245| [ 7.99207e-01  6.13471e-01  1.34435e-01]
20Nov23_095245| [ 9.32988e-01  9.45293e-01  2.64422e-01]
20Nov23_095245| [ 5.17947e-01 -7.64332e-01 -4.78027e-01]
20Nov23_095245| [ 7.02416e-01 -1.51632e-01 -3.33041e-01]
20Nov23_095245| [ 6.69652e-01  8.72101e-01 -1.64085e-01]
20Nov23_095245| [ 3.41736e-01  8.98305e-02  4.05198e-01]
20Nov23_095245| [ 2.27074e-01  8.46331e-01 -1.44322e-01]
20Nov23_095245| [ 6.03573e-01 -8.16247e-01 -7.74988e-02]
20Nov23_095245| [ 6.20717e-03  8.60449e-01 -2.75791e-01]
20Nov23_095245| [ 9.61293e-01  5.78074e-04 -6.99620e-02]
20Nov23_095245| [ 2.25284e-01 -9.64720e-01  1.38483e-01]
20Nov23_095245| [-2.69333e-01  7.96826e-01 -4.47025e-01]
20Nov23_095245| [-3.94057e-01 -5.68296e-01 -3.09060e-01]
20Nov23_095245| [ 1.13462e-01 -6.62818e-01 -4.94233e-01]
20Nov23_095245| [ 8.43231e-02  1.02165e+00  3.84557e-01]
20Nov23_095245| [ 4.76439e-01  3.90610e-01 -9.34270e-02]
20Nov23_095245| [-3.52813e-01  1.01680e+00 -1.56756e-01]
20Nov23_095245| [ 7.44184e-01 -6.22559e-01  4.71656e-01]
20Nov23_095245| [-3.25724e-02  8.04856e-01 -4.74885e-01]
20Nov23_095245| [-7.77151e-01 -5.56192e-01 -3.64250e-01]
20Nov23_095245| [ 4.19055e-01  1.05048e+00  1.13302e-01]
20Nov23_095245| [-2.11603e-01 -1.14325e-01 -1.91534e-01]
20Nov23_095245| [-1.57604e+00 -8.33752e-01  4.40403e-01]
20Nov23_095245| [-2.32387e-02 -2.84182e-01  2.42507e-01]
20Nov23_095245| [ 9.29496e-01 -1.06917e-01  2.47643e-01]
20Nov23_095245| [ 5.51908e-01  8.53966e-01 -3.68319e-01]
20Nov23_095245| [-7.43625e-01 -1.09987e+00 -4.07496e-02]]
20Nov23_095245|-- Bias --
20Nov23_095245|[0.65700 0.08603 0.07316]
20Nov23_095245|Layer 1:
20Nov23_095245|-- Config --
20Nov23_095245|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095245|-- Weights --
20Nov23_095245|[[ 0.78377 -0.55499 -0.47708]
20Nov23_095245| [-0.59071  0.65028 -0.40958]
20Nov23_095245| [-0.79088 -0.47553 -0.26780]]
20Nov23_095245|-- Bias --
20Nov23_095245|[ 0.25453 -0.37598 -0.43393]
20Nov23_095245|Layer 2:
20Nov23_095245|-- Config --
20Nov23_095245|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095245|-- Weights --
20Nov23_095245|[[-0.18759  0.25690]
20Nov23_095245| [-0.63942  0.79732]
20Nov23_095245| [ 0.19193 -0.35600]]
20Nov23_095245|-- Bias --
20Nov23_095245|[-1.29423 -0.06155]
20Nov23_095245|Predicting the validation and test data with the Best final individual.
20Nov23_095251| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_095251|-----------  ------------------  --------------------  ----------
20Nov23_095251|Validation         41.48                  12            0.01548
20Nov23_095251|   Test            36.32                  12            0.00596
20Nov23_095251|-------------------------- Test #12 --------------------------
20Nov23_095251|Best final individual weights
20Nov23_095251|Individual:
20Nov23_095251|-- Constant hidden layers --
20Nov23_095251|False
20Nov23_095251|Layer 0:
20Nov23_095251|-- Config --
20Nov23_095251|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095251|-- Weights --
20Nov23_095251|[[-4.78093e-01 -1.32987e-01 -1.98602e-01]
20Nov23_095251| [ 5.70296e-01  1.10707e-01 -2.04917e-01]
20Nov23_095251| [ 1.35368e-02  1.77761e+00 -2.52685e-01]
20Nov23_095251| [-1.26644e+00  3.57369e-01 -1.65181e-01]
20Nov23_095251| [-1.05634e+00  1.94476e+00  3.96681e-01]
20Nov23_095251| [-3.13175e-01 -8.64222e-01  7.56146e-02]
20Nov23_095251| [ 9.64959e-01  1.21650e+00  7.43693e-02]
20Nov23_095251| [ 2.00262e-01  1.09055e+00  3.21193e-01]
20Nov23_095251| [-1.02545e+00  2.09448e-01 -2.03886e-01]
20Nov23_095251| [ 3.44070e-01  2.59404e-01  1.48387e-02]
20Nov23_095251| [-1.22205e+00 -5.78311e-01 -4.46069e-01]
20Nov23_095251| [ 1.27455e-01  6.53705e-01 -4.11728e-01]
20Nov23_095251| [-8.22001e-01 -7.07268e-01 -4.60801e-01]
20Nov23_095251| [ 1.17331e-02  1.00342e+00 -2.38681e-01]
20Nov23_095251| [ 9.67231e-01  9.92537e-01  4.70941e-01]
20Nov23_095251| [ 3.28565e-01  6.93736e-01  1.20231e-01]
20Nov23_095251| [ 8.14875e-01 -9.84338e-02  1.18653e-02]
20Nov23_095251| [ 2.21745e-01 -1.17971e-01  3.13766e-01]
20Nov23_095251| [-6.10808e-01  1.17938e-01  4.57614e-03]
20Nov23_095251| [ 2.50763e-01 -1.14777e+00 -1.08223e-01]
20Nov23_095251| [-1.36903e-01  2.03549e-01  1.68996e-01]
20Nov23_095251| [ 8.39934e-01 -9.21186e-01 -3.08707e-01]
20Nov23_095251| [-6.47800e-01  1.47232e-01  1.00589e-01]
20Nov23_095251| [-1.63393e+00 -4.77786e-01 -4.84560e-01]
20Nov23_095251| [ 1.75349e-01  2.15510e-01 -9.56645e-02]
20Nov23_095251| [-5.44939e-01 -6.84742e-01 -2.11610e-01]
20Nov23_095251| [-1.18869e+00 -1.31627e+00  2.10714e-01]
20Nov23_095251| [-1.09169e+00  1.33832e+00 -3.63987e-01]
20Nov23_095251| [-1.82071e-01 -1.51525e-01  1.21841e-01]
20Nov23_095251| [ 2.93676e-01  4.31694e-01 -1.52107e-01]
20Nov23_095251| [ 7.99207e-01  6.13471e-01  1.34435e-01]
20Nov23_095251| [ 9.32988e-01  9.45293e-01  2.64422e-01]
20Nov23_095251| [ 5.17947e-01 -7.64332e-01 -4.78027e-01]
20Nov23_095251| [ 7.02416e-01 -1.51632e-01 -3.33041e-01]
20Nov23_095251| [ 6.69652e-01  8.72101e-01 -1.64085e-01]
20Nov23_095251| [ 3.41736e-01  8.98305e-02  4.05198e-01]
20Nov23_095251| [ 2.27074e-01  8.46331e-01 -1.44322e-01]
20Nov23_095251| [ 6.03573e-01 -8.16247e-01 -7.74988e-02]
20Nov23_095251| [ 6.20717e-03  8.60449e-01 -2.75791e-01]
20Nov23_095251| [ 9.61293e-01  5.78074e-04 -6.99620e-02]
20Nov23_095251| [ 2.25284e-01 -9.64720e-01  1.38483e-01]
20Nov23_095251| [-2.69333e-01  7.96826e-01 -4.47025e-01]
20Nov23_095251| [-3.94057e-01 -5.68296e-01 -3.09060e-01]
20Nov23_095251| [ 1.13462e-01 -6.62818e-01 -4.94233e-01]
20Nov23_095251| [ 8.43231e-02  1.02165e+00  3.84557e-01]
20Nov23_095251| [ 4.76439e-01  3.90610e-01 -9.34270e-02]
20Nov23_095251| [-3.52813e-01  1.01680e+00 -1.56756e-01]
20Nov23_095251| [ 7.44184e-01 -6.22559e-01  4.71656e-01]
20Nov23_095251| [-3.25724e-02  8.04856e-01 -4.74885e-01]
20Nov23_095251| [-7.77151e-01 -5.56192e-01 -3.64250e-01]
20Nov23_095251| [ 4.19055e-01  1.05048e+00  1.13302e-01]
20Nov23_095251| [-2.11603e-01 -1.14325e-01 -1.91534e-01]
20Nov23_095251| [-1.57604e+00 -8.33752e-01  4.40403e-01]
20Nov23_095251| [-2.32387e-02 -2.84182e-01  2.42507e-01]
20Nov23_095251| [ 9.29496e-01 -1.06917e-01  2.47643e-01]
20Nov23_095251| [ 5.51908e-01  8.53966e-01 -3.68319e-01]
20Nov23_095251| [-7.43625e-01 -1.09987e+00 -4.07496e-02]]
20Nov23_095251|-- Bias --
20Nov23_095251|[0.65700 0.08603 0.07316]
20Nov23_095251|Layer 1:
20Nov23_095251|-- Config --
20Nov23_095251|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095251|-- Weights --
20Nov23_095251|[[ 0.78377 -0.55499 -0.47708]
20Nov23_095251| [-0.59071  0.65028 -0.40958]
20Nov23_095251| [-0.79088 -0.47553 -0.26780]]
20Nov23_095251|-- Bias --
20Nov23_095251|[ 0.25453 -0.37598 -0.43393]
20Nov23_095251|Layer 2:
20Nov23_095251|-- Config --
20Nov23_095251|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095251|-- Weights --
20Nov23_095251|[[-0.18759  0.25690]
20Nov23_095251| [-0.63942  0.79732]
20Nov23_095251| [ 0.19193 -0.35600]]
20Nov23_095251|-- Bias --
20Nov23_095251|[-1.29423 -0.06155]
20Nov23_095251|Predicting the validation and test data with the Best final individual.
20Nov23_095257| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_095257|-----------  ------------------  --------------------  ----------
20Nov23_095257|Validation         41.39                  12            0.01805
20Nov23_095257|   Test            36.32                  12            0.00596
20Nov23_095257|-------------------------- Test #13 --------------------------
20Nov23_095257|Best final individual weights
20Nov23_095257|Individual:
20Nov23_095257|-- Constant hidden layers --
20Nov23_095257|False
20Nov23_095257|Layer 0:
20Nov23_095257|-- Config --
20Nov23_095257|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095257|-- Weights --
20Nov23_095257|[[-4.78093e-01 -1.32987e-01 -1.98602e-01]
20Nov23_095257| [ 5.70296e-01  1.10707e-01 -2.04917e-01]
20Nov23_095257| [ 1.35368e-02  1.77761e+00 -2.52685e-01]
20Nov23_095257| [-1.26644e+00  3.57369e-01 -1.65181e-01]
20Nov23_095257| [-1.05634e+00  1.94476e+00  3.96681e-01]
20Nov23_095257| [-3.13175e-01 -8.64222e-01  7.56146e-02]
20Nov23_095257| [ 9.64959e-01  1.21650e+00  7.43693e-02]
20Nov23_095257| [ 2.00262e-01  1.09055e+00  3.21193e-01]
20Nov23_095257| [-1.02545e+00  2.09448e-01 -2.03886e-01]
20Nov23_095257| [ 3.44070e-01  2.59404e-01  1.48387e-02]
20Nov23_095257| [-1.22205e+00 -5.78311e-01 -4.46069e-01]
20Nov23_095257| [ 1.27455e-01  6.53705e-01 -4.11728e-01]
20Nov23_095257| [-8.22001e-01 -7.07268e-01 -4.60801e-01]
20Nov23_095257| [ 1.17331e-02  1.00342e+00 -2.38681e-01]
20Nov23_095257| [ 9.67231e-01  9.92537e-01  4.70941e-01]
20Nov23_095257| [ 3.28565e-01  6.93736e-01  1.20231e-01]
20Nov23_095257| [ 8.14875e-01 -9.84338e-02  1.18653e-02]
20Nov23_095257| [ 2.21745e-01 -1.17971e-01  3.13766e-01]
20Nov23_095257| [-6.10808e-01  1.17938e-01  4.57614e-03]
20Nov23_095257| [ 2.50763e-01 -1.14777e+00 -1.08223e-01]
20Nov23_095257| [-1.36903e-01  2.03549e-01  1.68996e-01]
20Nov23_095257| [ 8.39934e-01 -9.21186e-01 -3.08707e-01]
20Nov23_095257| [-6.47800e-01  1.47232e-01  1.00589e-01]
20Nov23_095257| [-1.63393e+00 -4.77786e-01 -4.84560e-01]
20Nov23_095257| [ 1.75349e-01  2.15510e-01 -9.56645e-02]
20Nov23_095257| [-5.44939e-01 -6.84742e-01 -2.11610e-01]
20Nov23_095257| [-1.18869e+00 -1.31627e+00  2.10714e-01]
20Nov23_095257| [-1.09169e+00  1.33832e+00 -3.63987e-01]
20Nov23_095257| [-1.82071e-01 -1.51525e-01  1.21841e-01]
20Nov23_095257| [ 2.93676e-01  4.31694e-01 -1.52107e-01]
20Nov23_095257| [ 7.99207e-01  6.13471e-01  1.34435e-01]
20Nov23_095257| [ 9.32988e-01  9.45293e-01  2.64422e-01]
20Nov23_095257| [ 5.17947e-01 -7.64332e-01 -4.78027e-01]
20Nov23_095257| [ 7.02416e-01 -1.51632e-01 -3.33041e-01]
20Nov23_095257| [ 6.69652e-01  8.72101e-01 -1.64085e-01]
20Nov23_095257| [ 3.41736e-01  8.98305e-02  4.05198e-01]
20Nov23_095257| [ 2.27074e-01  8.46331e-01 -1.44322e-01]
20Nov23_095257| [ 6.03573e-01 -8.16247e-01 -7.74988e-02]
20Nov23_095257| [ 6.20717e-03  8.60449e-01 -2.75791e-01]
20Nov23_095257| [ 9.61293e-01  5.78074e-04 -6.99620e-02]
20Nov23_095257| [ 2.25284e-01 -9.64720e-01  1.38483e-01]
20Nov23_095257| [-2.69333e-01  7.96826e-01 -4.47025e-01]
20Nov23_095257| [-3.94057e-01 -5.68296e-01 -3.09060e-01]
20Nov23_095257| [ 1.13462e-01 -6.62818e-01 -4.94233e-01]
20Nov23_095257| [ 8.43231e-02  1.02165e+00  3.84557e-01]
20Nov23_095257| [ 4.76439e-01  3.90610e-01 -9.34270e-02]
20Nov23_095257| [-3.52813e-01  1.01680e+00 -1.56756e-01]
20Nov23_095257| [ 7.44184e-01 -6.22559e-01  4.71656e-01]
20Nov23_095257| [-3.25724e-02  8.04856e-01 -4.74885e-01]
20Nov23_095257| [-7.77151e-01 -5.56192e-01 -3.64250e-01]
20Nov23_095257| [ 4.19055e-01  1.05048e+00  1.13302e-01]
20Nov23_095257| [-2.11603e-01 -1.14325e-01 -1.91534e-01]
20Nov23_095257| [-1.57604e+00 -8.33752e-01  4.40403e-01]
20Nov23_095257| [-2.32387e-02 -2.84182e-01  2.42507e-01]
20Nov23_095257| [ 9.29496e-01 -1.06917e-01  2.47643e-01]
20Nov23_095257| [ 5.51908e-01  8.53966e-01 -3.68319e-01]
20Nov23_095257| [-7.43625e-01 -1.09987e+00 -4.07496e-02]]
20Nov23_095257|-- Bias --
20Nov23_095257|[0.65700 0.08603 0.07316]
20Nov23_095257|Layer 1:
20Nov23_095257|-- Config --
20Nov23_095257|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095257|-- Weights --
20Nov23_095257|[[ 0.78377 -0.55499 -0.47708]
20Nov23_095257| [-0.59071  0.65028 -0.40958]
20Nov23_095257| [-0.79088 -0.47553 -0.26780]]
20Nov23_095257|-- Bias --
20Nov23_095257|[ 0.25453 -0.37598 -0.43393]
20Nov23_095257|Layer 2:
20Nov23_095257|-- Config --
20Nov23_095257|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095257|-- Weights --
20Nov23_095257|[[-0.18759  0.25690]
20Nov23_095257| [-0.63942  0.79732]
20Nov23_095257| [ 0.19193 -0.35600]]
20Nov23_095257|-- Bias --
20Nov23_095257|[-1.29423 -0.06155]
20Nov23_095257|Predicting the validation and test data with the Best final individual.
20Nov23_095303| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_095303|-----------  ------------------  --------------------  ----------
20Nov23_095303|Validation         41.65                  12            0.01033
20Nov23_095303|   Test            36.32                  12            0.00596
20Nov23_095303|-------------------------- Test #14 --------------------------
20Nov23_095303|Best final individual weights
20Nov23_095303|Individual:
20Nov23_095303|-- Constant hidden layers --
20Nov23_095303|False
20Nov23_095303|Layer 0:
20Nov23_095303|-- Config --
20Nov23_095303|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095303|-- Weights --
20Nov23_095303|[[-4.78093e-01 -1.32987e-01 -1.98602e-01]
20Nov23_095303| [ 5.70296e-01  1.10707e-01 -2.04917e-01]
20Nov23_095303| [ 1.35368e-02  1.77761e+00 -2.52685e-01]
20Nov23_095303| [-1.26644e+00  3.57369e-01 -1.65181e-01]
20Nov23_095303| [-1.05634e+00  1.94476e+00  3.96681e-01]
20Nov23_095303| [-3.13175e-01 -8.64222e-01  7.56146e-02]
20Nov23_095303| [ 9.64959e-01  1.21650e+00  7.43693e-02]
20Nov23_095303| [ 2.00262e-01  1.09055e+00  3.21193e-01]
20Nov23_095303| [-1.02545e+00  2.09448e-01 -2.03886e-01]
20Nov23_095303| [ 3.44070e-01  2.59404e-01  1.48387e-02]
20Nov23_095303| [-1.22205e+00 -5.78311e-01 -4.46069e-01]
20Nov23_095303| [ 1.27455e-01  6.53705e-01 -4.11728e-01]
20Nov23_095303| [-8.22001e-01 -7.07268e-01 -4.60801e-01]
20Nov23_095303| [ 1.17331e-02  1.00342e+00 -2.38681e-01]
20Nov23_095303| [ 9.67231e-01  9.92537e-01  4.70941e-01]
20Nov23_095303| [ 3.28565e-01  6.93736e-01  1.20231e-01]
20Nov23_095303| [ 8.14875e-01 -9.84338e-02  1.18653e-02]
20Nov23_095303| [ 2.21745e-01 -1.17971e-01  3.13766e-01]
20Nov23_095303| [-6.10808e-01  1.17938e-01  4.57614e-03]
20Nov23_095303| [ 2.50763e-01 -1.14777e+00 -1.08223e-01]
20Nov23_095303| [-1.36903e-01  2.03549e-01  1.68996e-01]
20Nov23_095303| [ 8.39934e-01 -9.21186e-01 -3.08707e-01]
20Nov23_095303| [-6.47800e-01  1.47232e-01  1.00589e-01]
20Nov23_095303| [-1.63393e+00 -4.77786e-01 -4.84560e-01]
20Nov23_095303| [ 1.75349e-01  2.15510e-01 -9.56645e-02]
20Nov23_095303| [-5.44939e-01 -6.84742e-01 -2.11610e-01]
20Nov23_095303| [-1.18869e+00 -1.31627e+00  2.10714e-01]
20Nov23_095303| [-1.09169e+00  1.33832e+00 -3.63987e-01]
20Nov23_095303| [-1.82071e-01 -1.51525e-01  1.21841e-01]
20Nov23_095303| [ 2.93676e-01  4.31694e-01 -1.52107e-01]
20Nov23_095303| [ 7.99207e-01  6.13471e-01  1.34435e-01]
20Nov23_095303| [ 9.32988e-01  9.45293e-01  2.64422e-01]
20Nov23_095303| [ 5.17947e-01 -7.64332e-01 -4.78027e-01]
20Nov23_095303| [ 7.02416e-01 -1.51632e-01 -3.33041e-01]
20Nov23_095303| [ 6.69652e-01  8.72101e-01 -1.64085e-01]
20Nov23_095303| [ 3.41736e-01  8.98305e-02  4.05198e-01]
20Nov23_095303| [ 2.27074e-01  8.46331e-01 -1.44322e-01]
20Nov23_095303| [ 6.03573e-01 -8.16247e-01 -7.74988e-02]
20Nov23_095303| [ 6.20717e-03  8.60449e-01 -2.75791e-01]
20Nov23_095303| [ 9.61293e-01  5.78074e-04 -6.99620e-02]
20Nov23_095303| [ 2.25284e-01 -9.64720e-01  1.38483e-01]
20Nov23_095303| [-2.69333e-01  7.96826e-01 -4.47025e-01]
20Nov23_095303| [-3.94057e-01 -5.68296e-01 -3.09060e-01]
20Nov23_095303| [ 1.13462e-01 -6.62818e-01 -4.94233e-01]
20Nov23_095303| [ 8.43231e-02  1.02165e+00  3.84557e-01]
20Nov23_095303| [ 4.76439e-01  3.90610e-01 -9.34270e-02]
20Nov23_095303| [-3.52813e-01  1.01680e+00 -1.56756e-01]
20Nov23_095303| [ 7.44184e-01 -6.22559e-01  4.71656e-01]
20Nov23_095303| [-3.25724e-02  8.04856e-01 -4.74885e-01]
20Nov23_095303| [-7.77151e-01 -5.56192e-01 -3.64250e-01]
20Nov23_095303| [ 4.19055e-01  1.05048e+00  1.13302e-01]
20Nov23_095303| [-2.11603e-01 -1.14325e-01 -1.91534e-01]
20Nov23_095303| [-1.57604e+00 -8.33752e-01  4.40403e-01]
20Nov23_095303| [-2.32387e-02 -2.84182e-01  2.42507e-01]
20Nov23_095303| [ 9.29496e-01 -1.06917e-01  2.47643e-01]
20Nov23_095303| [ 5.51908e-01  8.53966e-01 -3.68319e-01]
20Nov23_095303| [-7.43625e-01 -1.09987e+00 -4.07496e-02]]
20Nov23_095303|-- Bias --
20Nov23_095303|[0.65700 0.08603 0.07316]
20Nov23_095303|Layer 1:
20Nov23_095303|-- Config --
20Nov23_095303|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095303|-- Weights --
20Nov23_095303|[[ 0.78377 -0.55499 -0.47708]
20Nov23_095303| [-0.59071  0.65028 -0.40958]
20Nov23_095303| [-0.79088 -0.47553 -0.26780]]
20Nov23_095303|-- Bias --
20Nov23_095303|[ 0.25453 -0.37598 -0.43393]
20Nov23_095303|Layer 2:
20Nov23_095303|-- Config --
20Nov23_095303|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
20Nov23_095303|-- Weights --
20Nov23_095303|[[-0.18759  0.25690]
20Nov23_095303| [-0.63942  0.79732]
20Nov23_095303| [ 0.19193 -0.35600]]
20Nov23_095303|-- Bias --
20Nov23_095303|[-1.29423 -0.06155]
20Nov23_095303|Predicting the validation and test data with the Best final individual.
20Nov23_095308| Partition    Accuracy error %    Neuron/layer score    F2 score
20Nov23_095308|-----------  ------------------  --------------------  ----------
20Nov23_095308|Validation         41.48                  12            0.01548
20Nov23_095308|   Test            36.32                  12            0.00596
Using Theano backend.
20Nov23_095309|Data summary: Train
20Nov23_095309|data.shape = (2300, 57)
20Nov23_095309|labels.shape = (2300,)
20Nov23_095309|Class distribution:
20Nov23_095309|	0 - 1389 (0.60)
20Nov23_095309|	1 - 911 (0.40)
20Nov23_095309|Data summary: Validation
20Nov23_095309|data.shape = (1150, 57)
20Nov23_095309|labels.shape = (1150,)
20Nov23_095309|Class distribution:
20Nov23_095309|	0 - 667 (0.58)
20Nov23_095309|	1 - 483 (0.42)
20Nov23_095309|Data summary: Test
20Nov23_095309|data.shape = (1151, 57)
20Nov23_095309|labels.shape = (1151,)
20Nov23_095309|Class distribution:
20Nov23_095309|	0 - 732 (0.64)
20Nov23_095309|	1 - 419 (0.36)
20Nov23_095309|Selected configuration values
20Nov23_095309|-- Dataset name: spambase2
20Nov23_095309|-- Initial population size: 64
20Nov23_095309|-- Maximun number of generations: 32
20Nov23_095309|-- Neurons per hidden layer range: (2, 20)
20Nov23_095309|-- Hidden layers number range: (1, 3)
20Nov23_095309|-- Crossover probability: 0.5
20Nov23_095309|-- Bias gene mutation probability: 0.2
20Nov23_095309|-- Weights gene mutation probability: 0.75
20Nov23_095309|-- Neuron mutation probability: 0.3
20Nov23_095309|-- Layer mutation probability: 0.3
20Nov23_095309|-- Constant hidden layers: False
20Nov23_095309|-- Seed: None
20Nov23_095309|Entering GA
20Nov23_095309|Start the algorithm
20Nov23_095634|-- Generation 1 --
20Nov23_095634|    -- Crossed 1 individual pairs.
20Nov23_095634|    -- Mutated 32 individuals.
20Nov23_095949|    -- Evaluated 64 individuals.
20Nov23_095949|    Summary of generation 1:
20Nov23_095949| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_095949|-----------  ------------------  --------------------  ----------
20Nov23_095949|    Max            54.26                141.00          0.79017
20Nov23_095949|    Avg            42.02                37.64           0.02214
20Nov23_095949|    Min            36.17                 4.00           0.00000
20Nov23_095949|    Std             1.75                30.70           0.10499
20Nov23_095949|   Best            36.17                18.00           0.31000
20Nov23_095949|-- Generation 2 --
20Nov23_095949|    -- Crossed 3 individual pairs.
20Nov23_095949|    -- Mutated 32 individuals.
20Nov23_100259|    -- Evaluated 64 individuals.
20Nov23_100259|    Summary of generation 2:
20Nov23_100259| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_100259|-----------  ------------------  --------------------  ----------
20Nov23_100259|    Max            42.43                141.00          0.15121
20Nov23_100259|    Avg            41.95                26.47           0.00545
20Nov23_100259|    Min            38.78                 7.00           0.00000
20Nov23_100259|    Std             0.43                22.84           0.01969
20Nov23_100259|   Best            38.78                18.00           0.15121
20Nov23_100259|-- Generation 3 --
20Nov23_100259|    -- Crossed 1 individual pairs.
20Nov23_100259|    -- Mutated 32 individuals.
20Nov23_100604|    -- Evaluated 64 individuals.
20Nov23_100604|    Summary of generation 3:
20Nov23_100604| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_100604|-----------  ------------------  --------------------  ----------
20Nov23_100604|    Max            58.00                48.00           0.78358
20Nov23_100604|    Avg            42.12                17.22           0.01994
20Nov23_100604|    Min            38.26                 3.00           0.00000
20Nov23_100604|    Std             2.07                 8.91           0.09969
20Nov23_100604|   Best            38.26                19.00           0.19971
20Nov23_100604|-- Generation 4 --
20Nov23_100604|    -- Crossed 3 individual pairs.
20Nov23_100604|    -- Mutated 32 individuals.
20Nov23_100910|    -- Evaluated 64 individuals.
20Nov23_100910|    Summary of generation 4:
20Nov23_100910| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_100910|-----------  ------------------  --------------------  ----------
20Nov23_100910|    Max            58.00                51.00           0.79681
20Nov23_100910|    Avg            42.07                17.36           0.04455
20Nov23_100910|    Min            28.87                 2.00           0.00000
20Nov23_100910|    Std             2.94                10.35           0.16334
20Nov23_100910|   Best            28.87                22.00           0.74220
20Nov23_100910|-- Generation 5 --
20Nov23_100910|    -- Crossed 5 individual pairs.
20Nov23_100910|    -- Mutated 32 individuals.
20Nov23_101215|    -- Evaluated 64 individuals.
20Nov23_101215|    Summary of generation 5:
20Nov23_101215| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_101215|-----------  ------------------  --------------------  ----------
20Nov23_101215|    Max            42.35                36.00           0.12494
20Nov23_101215|    Avg            41.90                14.92           0.00553
20Nov23_101215|    Min            39.30                 2.00           0.00000
20Nov23_101215|    Std             0.45                 8.31           0.01790
20Nov23_101215|   Best            39.30                15.00           0.12494
20Nov23_101215|-- Generation 6 --
20Nov23_101215|    -- Crossed 0 individual pairs.
20Nov23_101215|    -- Mutated 32 individuals.
20Nov23_101517|    -- Evaluated 64 individuals.
20Nov23_101517|    Summary of generation 6:
20Nov23_101517| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_101517|-----------  ------------------  --------------------  ----------
20Nov23_101517|    Max            58.09                38.00           0.78358
20Nov23_101517|    Avg            42.64                13.33           0.04351
20Nov23_101517|    Min            38.96                 2.00           0.00000
20Nov23_101517|    Std             3.45                 7.20           0.16584
20Nov23_101517|   Best            38.96                12.00           0.11564
20Nov23_101517|-- Generation 7 --
20Nov23_101517|    -- Crossed 4 individual pairs.
20Nov23_101517|    -- Mutated 32 individuals.
20Nov23_101820|    -- Evaluated 64 individuals.
20Nov23_101820|    Summary of generation 7:
20Nov23_101820| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_101820|-----------  ------------------  --------------------  ----------
20Nov23_101820|    Max            58.00                69.00           0.78358
20Nov23_101820|    Avg            42.03                15.22           0.02332
20Nov23_101820|    Min            37.74                 2.00           0.00000
20Nov23_101820|    Std             2.17                11.91           0.10392
20Nov23_101820|   Best            37.74                 9.00           0.20478
20Nov23_101820|-- Generation 8 --
20Nov23_101820|    -- Crossed 3 individual pairs.
20Nov23_101820|    -- Mutated 32 individuals.
20Nov23_102120|    -- Evaluated 64 individuals.
20Nov23_102120|    Summary of generation 8:
20Nov23_102120| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_102120|-----------  ------------------  --------------------  ----------
20Nov23_102120|    Max            42.17                45.00           0.27420
20Nov23_102120|    Avg            41.74                13.70           0.01289
20Nov23_102120|    Min            36.35                 2.00           0.00000
20Nov23_102120|    Std             0.98                10.71           0.04595
20Nov23_102120|   Best            36.35                11.00           0.27420
20Nov23_102120|-- Generation 9 --
20Nov23_102120|    -- Crossed 5 individual pairs.
20Nov23_102120|    -- Mutated 32 individuals.
20Nov23_102421|    -- Evaluated 64 individuals.
20Nov23_102421|    Summary of generation 9:
20Nov23_102421| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_102421|-----------  ------------------  --------------------  ----------
20Nov23_102421|    Max            58.00                38.00           0.78358
20Nov23_102421|    Avg            42.14                12.17           0.01720
20Nov23_102421|    Min            40.17                 2.00           0.00000
20Nov23_102421|    Std             2.03                 8.23           0.09751
20Nov23_102421|   Best            40.17                17.00           0.07117
20Nov23_102421|-- Generation 10 --
20Nov23_102421|    -- Crossed 3 individual pairs.
20Nov23_102421|    -- Mutated 32 individuals.
20Nov23_102721|    -- Evaluated 64 individuals.
20Nov23_102721|    Summary of generation 10:
20Nov23_102721| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_102721|-----------  ------------------  --------------------  ----------
20Nov23_102721|    Max            42.43                42.00           0.83063
20Nov23_102721|    Avg            41.78                11.61           0.01819
20Nov23_102721|    Min            35.13                 2.00           0.00000
20Nov23_102721|    Std             0.92                10.06           0.10321
20Nov23_102721|   Best            35.13                16.00           0.83063
20Nov23_102721|-- Generation 11 --
20Nov23_102721|    -- Crossed 3 individual pairs.
20Nov23_102721|    -- Mutated 32 individuals.
20Nov23_103017|    -- Evaluated 64 individuals.
20Nov23_103017|    Summary of generation 11:
20Nov23_103017| Statistic    Accuracy error %    Neuron/Layer score    F2 score
20Nov23_103017|-----------  ------------------  --------------------  ----------
20Nov23_103017|    Max            55.48                30.00           0.79103
20Nov23_103017|    Avg            42.13                 8.30           0.01721
20Nov23_103017|    Min            39.30                 2.00           0.00000
20Nov23_103017|    Std             1.73                 5.63           0.09882
20Nov23_103017|   Best            39.30                 8.00           0.12256
20Nov23_103017|-- Generation 12 --
20Nov23_103017|    -- Crossed 5 individual pairs.
20Nov23_103017|    -- Mutated 32 individuals.
nohup: no se tendrá en cuenta la entrada
Using Theano backend.
WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.
2021-02-16 18:51:37.280288: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-02-16 18:51:37.280347: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
21Feb16_185142|Data summary: Train
21Feb16_185142|data.shape = (2300, 57)
21Feb16_185142|labels.shape = (2300,)
21Feb16_185142|Class distribution:
21Feb16_185142|	0 - 1389 (0.60)
21Feb16_185142|	1 - 911 (0.40)
21Feb16_185142|Data summary: Validation
21Feb16_185142|data.shape = (1150, 57)
21Feb16_185142|labels.shape = (1150,)
21Feb16_185142|Class distribution:
21Feb16_185142|	0 - 667 (0.58)
21Feb16_185142|	1 - 483 (0.42)
21Feb16_185142|Data summary: Test
21Feb16_185142|data.shape = (1151, 57)
21Feb16_185142|labels.shape = (1151,)
21Feb16_185142|Class distribution:
21Feb16_185142|	0 - 732 (0.64)
21Feb16_185142|	1 - 419 (0.36)
21Feb16_185142|Selected configuration values
21Feb16_185142|-- Dataset name: spambase2
21Feb16_185142|-- Initial population size: 64
21Feb16_185142|-- Maximun number of generations: 32
21Feb16_185142|-- Neurons per hidden layer range: (2, 20)
21Feb16_185142|-- Hidden layers number range: (1, 3)
21Feb16_185142|-- Crossover probability: 0.5
21Feb16_185142|-- Bias gene mutation probability: 0.2
21Feb16_185142|-- Weights gene mutation probability: 0.75
21Feb16_185142|-- Neuron mutation probability: 0.3
21Feb16_185142|-- Layer mutation probability: 0.3
21Feb16_185142|-- Constant hidden layers: False
21Feb16_185142|-- Seed: 31415
21Feb16_185142|Entering GA
21Feb16_185142|Start the algorithm
21Feb16_185527|-- Generation 1 --
21Feb16_185527|    -- Crossed 0 individual pairs.
21Feb16_185527|    -- Mutated 32 individuals.
21Feb16_185850|    -- Evaluated 64 individuals.
21Feb16_185850|    Summary of generation 1:
21Feb16_185850| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_185850|-----------  ------------------  --------------------  ----------
21Feb16_185850|    Max            42.70                78.00           0.43478
21Feb16_185850|    Avg            41.90                26.28           0.00941
21Feb16_185850|    Min            35.91                 2.00           0.00000
21Feb16_185850|    Std             0.81                18.75           0.05509
21Feb16_185850|   Best            35.91                18.00           0.43478
21Feb16_185850|-- Generation 2 --
21Feb16_185850|    -- Crossed 1 individual pairs.
21Feb16_185850|    -- Mutated 32 individuals.
21Feb16_190208|    -- Evaluated 64 individuals.
21Feb16_190208|    Summary of generation 2:
21Feb16_190208| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_190208|-----------  ------------------  --------------------  ----------
21Feb16_190208|    Max            58.00                84.00           0.79977
21Feb16_190208|    Avg            41.99                15.92           0.02879
21Feb16_190208|    Min            29.65                 2.00           0.00000
21Feb16_190208|    Std             2.55                13.60           0.13781
21Feb16_190208|   Best            29.65                18.00           0.79977
21Feb16_190208|-- Generation 3 --
21Feb16_190208|    -- Crossed 3 individual pairs.
21Feb16_190208|    -- Mutated 32 individuals.
21Feb16_190522|    -- Evaluated 64 individuals.
21Feb16_190522|    Summary of generation 3:
21Feb16_190522| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_190522|-----------  ------------------  --------------------  ----------
21Feb16_190522|    Max            58.00                50.00           0.78358
21Feb16_190522|    Avg            41.97                13.73           0.02564
21Feb16_190522|    Min            26.09                 2.00           0.00000
21Feb16_190522|    Std             2.83                12.88           0.13211
21Feb16_190522|   Best            26.09                18.00           0.73476
21Feb16_190522|-- Generation 4 --
21Feb16_190522|    -- Crossed 4 individual pairs.
21Feb16_190522|    -- Mutated 32 individuals.
21Feb16_190833|    -- Evaluated 64 individuals.
21Feb16_190833|    Summary of generation 4:
21Feb16_190833| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_190833|-----------  ------------------  --------------------  ----------
21Feb16_190833|    Max            42.17                63.00           0.00517
21Feb16_190833|    Avg            42.01                 8.34           0.00085
21Feb16_190833|    Min            41.91                 2.00           0.00000
21Feb16_190833|    Std             0.06                 9.60           0.00165
21Feb16_190833|   Best            41.91                 4.00           0.00517
21Feb16_190833|-- Generation 5 --
21Feb16_190833|    -- Crossed 6 individual pairs.
21Feb16_190833|    -- Mutated 32 individuals.
21Feb16_191142|    -- Evaluated 64 individuals.
21Feb16_191142|    Summary of generation 5:
21Feb16_191142| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_191142|-----------  ------------------  --------------------  ----------
21Feb16_191142|    Max            42.09                20.00           0.05344
21Feb16_191142|    Avg            41.98                 5.28           0.00172
21Feb16_191142|    Min            41.22                 2.00           0.00000
21Feb16_191142|    Std             0.11                 4.46           0.00681
21Feb16_191142|   Best            41.22                14.00           0.05344
21Feb16_191142|-- Generation 6 --
21Feb16_191142|    -- Crossed 7 individual pairs.
21Feb16_191142|    -- Mutated 32 individuals.
21Feb16_191453|    -- Evaluated 64 individuals.
21Feb16_191453|    Summary of generation 6:
21Feb16_191453| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_191453|-----------  ------------------  --------------------  ----------
21Feb16_191453|    Max            42.26                18.00           0.01548
21Feb16_191453|    Avg            41.99                 6.00           0.00105
21Feb16_191453|    Min            41.48                 2.00           0.00000
21Feb16_191453|    Std             0.09                 4.81           0.00231
21Feb16_191453|   Best            41.48                 3.00           0.01548
21Feb16_191453|-- Generation 7 --
21Feb16_191453|    -- Crossed 9 individual pairs.
21Feb16_191453|    -- Mutated 32 individuals.
21Feb16_191804|    -- Evaluated 64 individuals.
21Feb16_191804|    Summary of generation 7:
21Feb16_191804| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_191804|-----------  ------------------  --------------------  ----------
21Feb16_191804|    Max            42.09                36.00           0.01033
21Feb16_191804|    Avg            41.99                 5.98           0.00089
21Feb16_191804|    Min            41.65                 2.00           0.00000
21Feb16_191804|    Std             0.06                 6.14           0.00184
21Feb16_191804|   Best            41.65                 3.00           0.01033
21Feb16_191804|-- Generation 8 --
21Feb16_191804|    -- Crossed 9 individual pairs.
21Feb16_191804|    -- Mutated 32 individuals.
21Feb16_192113|    -- Evaluated 64 individuals.
21Feb16_192113|    Summary of generation 8:
21Feb16_192113| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_192113|-----------  ------------------  --------------------  ----------
21Feb16_192113|    Max            42.17                18.00           0.04103
21Feb16_192113|    Avg            41.97                 5.09           0.00169
21Feb16_192113|    Min            40.78                 2.00           0.00000
21Feb16_192113|    Std             0.16                 4.37           0.00529
21Feb16_192113|   Best            40.78                12.00           0.04103
21Feb16_192113|-- Generation 9 --
21Feb16_192113|    -- Crossed 8 individual pairs.
21Feb16_192113|    -- Mutated 32 individuals.
21Feb16_192423|    -- Evaluated 64 individuals.
21Feb16_192423|    Summary of generation 9:
21Feb16_192423| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_192423|-----------  ------------------  --------------------  ----------
21Feb16_192423|    Max            48.87                18.00           0.80667
21Feb16_192423|    Avg            41.71                 6.17           0.03823
21Feb16_192423|    Min            30.61                 2.00           0.00000
21Feb16_192423|    Std             2.17                 5.04           0.16210
21Feb16_192423|   Best            30.61                 8.00           0.78607
21Feb16_192423|-- Generation 10 --
21Feb16_192423|    -- Crossed 5 individual pairs.
21Feb16_192423|    -- Mutated 32 individuals.
21Feb16_192733|    -- Evaluated 64 individuals.
21Feb16_192733|    Summary of generation 10:
21Feb16_192733| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_192733|-----------  ------------------  --------------------  ----------
21Feb16_192733|    Max            42.26                18.00           0.58344
21Feb16_192733|    Avg            41.43                 6.23           0.02714
21Feb16_192733|    Min            27.74                 2.00           0.00000
21Feb16_192733|    Std             2.43                 4.89           0.10887
21Feb16_192733|   Best            27.74                18.00           0.51616
21Feb16_192733|-- Generation 11 --
21Feb16_192733|    -- Crossed 8 individual pairs.
21Feb16_192733|    -- Mutated 32 individuals.
21Feb16_193046|    -- Evaluated 64 individuals.
21Feb16_193046|    Summary of generation 11:
21Feb16_193046| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_193046|-----------  ------------------  --------------------  ----------
21Feb16_193046|    Max            58.00                34.00           0.78358
21Feb16_193046|    Avg            41.87                 7.95           0.03476
21Feb16_193046|    Min            28.00                 2.00           0.00000
21Feb16_193046|    Std             2.88                 6.49           0.14854
21Feb16_193046|   Best            28.00                 8.00           0.52079
21Feb16_193046|-- Generation 12 --
21Feb16_193046|    -- Crossed 3 individual pairs.
21Feb16_193046|    -- Mutated 32 individuals.
21Feb16_193357|    -- Evaluated 64 individuals.
21Feb16_193358|    Summary of generation 12:
21Feb16_193358| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_193358|-----------  ------------------  --------------------  ----------
21Feb16_193358|    Max            42.35                36.00           0.67494
21Feb16_193358|    Avg            41.46                 7.03           0.02217
21Feb16_193358|    Min            24.96                 2.00           0.00000
21Feb16_193358|    Std             2.67                 5.88           0.11025
21Feb16_193358|   Best            24.96                18.00           0.67494
21Feb16_193358|-- Generation 13 --
21Feb16_193358|    -- Crossed 5 individual pairs.
21Feb16_193358|    -- Mutated 32 individuals.
21Feb16_193710|    -- Evaluated 64 individuals.
21Feb16_193710|    Summary of generation 13:
21Feb16_193710| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_193710|-----------  ------------------  --------------------  ----------
21Feb16_193710|    Max            42.61                36.00           0.61562
21Feb16_193710|    Avg            41.50                 8.56           0.02210
21Feb16_193710|    Min            26.78                 2.00           0.00000
21Feb16_193710|    Std             2.40                 7.93           0.10577
21Feb16_193710|   Best            26.78                18.00           0.61562
21Feb16_193710|-- Generation 14 --
21Feb16_193710|    -- Crossed 7 individual pairs.
21Feb16_193710|    -- Mutated 32 individuals.
21Feb16_194023|    -- Evaluated 64 individuals.
21Feb16_194023|    Summary of generation 14:
21Feb16_194023| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_194023|-----------  ------------------  --------------------  ----------
21Feb16_194023|    Max            42.09                40.00           0.75188
21Feb16_194023|    Avg            41.48                 8.12           0.02679
21Feb16_194023|    Min            27.65                 2.00           0.00000
21Feb16_194023|    Std             2.42                 6.72           0.13015
21Feb16_194023|   Best            27.65                18.00           0.75188
21Feb16_194023|-- Generation 15 --
21Feb16_194023|    -- Crossed 6 individual pairs.
21Feb16_194023|    -- Mutated 32 individuals.
21Feb16_194336|    -- Evaluated 64 individuals.
21Feb16_194336|    Summary of generation 15:
21Feb16_194336| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_194336|-----------  ------------------  --------------------  ----------
21Feb16_194336|    Max            42.09                40.00           0.73387
21Feb16_194336|    Avg            41.42                 7.69           0.02610
21Feb16_194336|    Min            26.35                 2.00           0.00000
21Feb16_194336|    Std             2.71                 6.44           0.12590
21Feb16_194336|   Best            26.35                18.00           0.71951
21Feb16_194336|-- Generation 16 --
21Feb16_194336|    -- Crossed 5 individual pairs.
21Feb16_194336|    -- Mutated 32 individuals.
21Feb16_194649|    -- Evaluated 64 individuals.
21Feb16_194649|    Summary of generation 16:
21Feb16_194649| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_194649|-----------  ------------------  --------------------  ----------
21Feb16_194649|    Max            42.26                44.00           0.82855
21Feb16_194649|    Avg            41.21                 7.83           0.03973
21Feb16_194649|    Min            24.87                 2.00           0.00000
21Feb16_194649|    Std             3.23                 7.99           0.16234
21Feb16_194649|   Best            24.87                21.00           0.68287
21Feb16_194649|-- Generation 17 --
21Feb16_194649|    -- Crossed 8 individual pairs.
21Feb16_194649|    -- Mutated 32 individuals.
21Feb16_195004|    -- Evaluated 64 individuals.
21Feb16_195004|    Summary of generation 17:
21Feb16_195004| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_195004|-----------  ------------------  --------------------  ----------
21Feb16_195004|    Max            42.26                44.00           0.80877
21Feb16_195004|    Avg            40.86                 8.81           0.06413
21Feb16_195004|    Min            25.04                 2.00           0.00000
21Feb16_195004|    Std             3.59                 8.94           0.19340
21Feb16_195004|   Best            25.04                10.00           0.72247
21Feb16_195004|-- Generation 18 --
21Feb16_195004|    -- Crossed 2 individual pairs.
21Feb16_195004|    -- Mutated 32 individuals.
21Feb16_195322|    -- Evaluated 64 individuals.
21Feb16_195322|    Summary of generation 18:
21Feb16_195322| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_195322|-----------  ------------------  --------------------  ----------
21Feb16_195322|    Max            47.04                44.00           0.81211
21Feb16_195322|    Avg            39.55                10.78           0.12108
21Feb16_195322|    Min            24.35                 3.00           0.00000
21Feb16_195322|    Std             5.74                11.16           0.25939
21Feb16_195322|   Best            24.35                44.00           0.72485
21Feb16_195322|-- Generation 19 --
21Feb16_195322|    -- Crossed 7 individual pairs.
21Feb16_195322|    -- Mutated 32 individuals.
21Feb16_195645|    -- Evaluated 64 individuals.
21Feb16_195645|    Summary of generation 19:
21Feb16_195645| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_195645|-----------  ------------------  --------------------  ----------
21Feb16_195645|    Max            42.87                70.00           0.81774
21Feb16_195645|    Avg            39.09                14.53           0.14606
21Feb16_195645|    Min            24.70                 3.00           0.00000
21Feb16_195645|    Std             5.78                15.60           0.27609
21Feb16_195645|   Best            24.70                44.00           0.69102
21Feb16_195645|-- Generation 20 --
21Feb16_195645|    -- Crossed 3 individual pairs.
21Feb16_195645|    -- Mutated 32 individuals.
21Feb16_200013|    -- Evaluated 64 individuals.
21Feb16_200013|    Summary of generation 20:
21Feb16_200013| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_200013|-----------  ------------------  --------------------  ----------
21Feb16_200013|    Max            42.17                60.00           0.79174
21Feb16_200013|    Avg            39.05                15.47           0.15453
21Feb16_200013|    Min            24.09                 3.00           0.00000
21Feb16_200013|    Std             5.60                16.03           0.28335
21Feb16_200013|   Best            24.09                48.00           0.76568
21Feb16_200013|-- Generation 21 --
21Feb16_200013|    -- Crossed 4 individual pairs.
21Feb16_200013|    -- Mutated 32 individuals.
21Feb16_200346|    -- Evaluated 64 individuals.
21Feb16_200346|    Summary of generation 21:
21Feb16_200346| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_200346|-----------  ------------------  --------------------  ----------
21Feb16_200346|    Max            42.17                90.00           0.80579
21Feb16_200346|    Avg            38.34                18.45           0.19938
21Feb16_200346|    Min            23.91                 2.00           0.00000
21Feb16_200346|    Std             5.87                19.09           0.30554
21Feb16_200346|   Best            23.91                48.00           0.71458
21Feb16_200346|-- Generation 22 --
21Feb16_200346|    -- Crossed 2 individual pairs.
21Feb16_200346|    -- Mutated 32 individuals.
21Feb16_200724|    -- Evaluated 64 individuals.
21Feb16_200724|    Summary of generation 22:
21Feb16_200724| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_200724|-----------  ------------------  --------------------  ----------
21Feb16_200724|    Max            42.09                60.00           0.82362
21Feb16_200724|    Avg            36.71                21.28           0.25981
21Feb16_200724|    Min            24.26                 2.00           0.00000
21Feb16_200724|    Std             6.98                18.25           0.33831
21Feb16_200724|   Best            24.26                52.00           0.76087
21Feb16_200724|-- Generation 23 --
21Feb16_200724|    -- Crossed 2 individual pairs.
21Feb16_200724|    -- Mutated 32 individuals.
21Feb16_201112|    -- Evaluated 64 individuals.
21Feb16_201112|    Summary of generation 23:
21Feb16_201112| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_201112|-----------  ------------------  --------------------  ----------
21Feb16_201112|    Max            42.09                96.00           0.78772
21Feb16_201112|    Avg            35.35                29.28           0.32114
21Feb16_201112|    Min            23.39                 2.00           0.00000
21Feb16_201112|    Std             7.15                21.95           0.34435
21Feb16_201112|   Best            23.39                52.00           0.72814
21Feb16_201112|-- Generation 24 --
21Feb16_201112|    -- Crossed 0 individual pairs.
21Feb16_201112|    -- Mutated 32 individuals.
21Feb16_201510|    -- Evaluated 64 individuals.
21Feb16_201510|    Summary of generation 24:
21Feb16_201510| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_201510|-----------  ------------------  --------------------  ----------
21Feb16_201510|    Max            43.30                80.00           0.82075
21Feb16_201510|    Avg            33.81                36.61           0.38588
21Feb16_201510|    Min            23.22                 2.00           0.00000
21Feb16_201510|    Std             7.30                19.72           0.34184
21Feb16_201510|   Best            23.22                52.00           0.73602
21Feb16_201510|-- Generation 25 --
21Feb16_201510|    -- Crossed 3 individual pairs.
21Feb16_201510|    -- Mutated 32 individuals.
21Feb16_201916|    -- Evaluated 64 individuals.
21Feb16_201916|    Summary of generation 25:
21Feb16_201916| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_201916|-----------  ------------------  --------------------  ----------
21Feb16_201916|    Max            51.74                114.00          0.82799
21Feb16_201916|    Avg            33.58                45.08           0.45457
21Feb16_201916|    Min            23.91                 8.00           0.00000
21Feb16_201916|    Std             7.24                19.61           0.35022
21Feb16_201916|   Best            23.91                48.00           0.72048
21Feb16_201916|-- Generation 26 --
21Feb16_201916|    -- Crossed 1 individual pairs.
21Feb16_201916|    -- Mutated 32 individuals.
21Feb16_202325|    -- Evaluated 64 individuals.
21Feb16_202325|    Summary of generation 26:
21Feb16_202325| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_202325|-----------  ------------------  --------------------  ----------
21Feb16_202325|    Max            42.35                108.00          0.84388
21Feb16_202325|    Avg            32.71                48.80           0.44554
21Feb16_202325|    Min            23.30                 2.00           0.00000
21Feb16_202325|    Std             7.16                22.53           0.33996
21Feb16_202325|   Best            23.30                24.00           0.69415
21Feb16_202325|-- Generation 27 --
21Feb16_202325|    -- Crossed 1 individual pairs.
21Feb16_202325|    -- Mutated 32 individuals.
21Feb16_202734|    -- Evaluated 64 individuals.
21Feb16_202734|    Summary of generation 27:
21Feb16_202734| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_202734|-----------  ------------------  --------------------  ----------
21Feb16_202734|    Max            42.26                132.00          0.82552
21Feb16_202734|    Avg            32.16                51.20           0.45948
21Feb16_202734|    Min            21.74                 8.00           0.00000
21Feb16_202734|    Std             7.19                22.48           0.32234
21Feb16_202734|   Best            21.74                18.00           0.76278
21Feb16_202734|-- Generation 28 --
21Feb16_202734|    -- Crossed 0 individual pairs.
21Feb16_202734|    -- Mutated 32 individuals.
21Feb16_203146|    -- Evaluated 64 individuals.
21Feb16_203146|    Summary of generation 28:
21Feb16_203146| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_203146|-----------  ------------------  --------------------  ----------
21Feb16_203146|    Max            42.00                132.00          0.83850
21Feb16_203146|    Avg            31.52                51.11           0.49187
21Feb16_203146|    Min            23.04                12.00           0.00000
21Feb16_203146|    Std             6.86                24.66           0.32040
21Feb16_203146|   Best            23.04                24.00           0.73226
21Feb16_203146|-- Generation 29 --
21Feb16_203146|    -- Crossed 0 individual pairs.
21Feb16_203146|    -- Mutated 32 individuals.
21Feb16_203555|    -- Evaluated 64 individuals.
21Feb16_203555|    Summary of generation 29:
21Feb16_203555| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_203555|-----------  ------------------  --------------------  ----------
21Feb16_203555|    Max            42.09                132.00          0.82871
21Feb16_203555|    Avg            32.10                49.19           0.44677
21Feb16_203555|    Min            22.26                12.00           0.00000
21Feb16_203555|    Std             7.60                23.20           0.33800
21Feb16_203555|   Best            22.26                56.00           0.74227
21Feb16_203555|-- Generation 30 --
21Feb16_203555|    -- Crossed 0 individual pairs.
21Feb16_203555|    -- Mutated 32 individuals.
21Feb16_204004|    -- Evaluated 64 individuals.
21Feb16_204004|    Summary of generation 30:
21Feb16_204004| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_204004|-----------  ------------------  --------------------  ----------
21Feb16_204004|    Max            42.09                100.00          0.82371
21Feb16_204004|    Avg            31.14                49.09           0.49033
21Feb16_204004|    Min            22.00                14.00           0.00000
21Feb16_204004|    Std             7.06                18.85           0.31415
21Feb16_204004|   Best            22.00                56.00           0.78704
21Feb16_204004|-- Generation 31 --
21Feb16_204004|    -- Crossed 1 individual pairs.
21Feb16_204004|    -- Mutated 32 individuals.
21Feb16_204414|    -- Evaluated 64 individuals.
21Feb16_204414|    Summary of generation 31:
21Feb16_204414| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_204414|-----------  ------------------  --------------------  ----------
21Feb16_204414|    Max            42.52                100.00          0.83333
21Feb16_204414|    Avg            32.54                52.38           0.44410
21Feb16_204414|    Min            22.96                 8.00           0.00000
21Feb16_204414|    Std             7.42                21.79           0.34342
21Feb16_204414|   Best            22.96                44.00           0.72671
21Feb16_204414|-- Generation 32 --
21Feb16_204414|    -- Crossed 1 individual pairs.
21Feb16_204414|    -- Mutated 32 individuals.
21Feb16_204823|    -- Evaluated 64 individuals.
21Feb16_204823|    Summary of generation 32:
21Feb16_204823| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_204823|-----------  ------------------  --------------------  ----------
21Feb16_204823|    Max            42.00                85.00           0.83038
21Feb16_204823|    Avg            32.40                52.83           0.43440
21Feb16_204823|    Min            21.57                 8.00           0.00000
21Feb16_204823|    Std             7.70                18.10           0.34013
21Feb16_204823|   Best            21.57                56.00           0.83038
21Feb16_204823|Best initial individual weights
21Feb16_204823|Individual:
21Feb16_204823|-- Constant hidden layers --
21Feb16_204823|False
21Feb16_204823|Layer 0:
21Feb16_204823|-- Config --
21Feb16_204823|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 12, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204823|-- Weights --
21Feb16_204823|[[-3.50529e-01 -6.53069e-03 -7.03730e-01 -6.33906e-01  6.10835e-02
21Feb16_204823|   4.57449e-01 -3.77835e-01  6.38481e-01  4.24141e-01  6.68786e-01
21Feb16_204823|  -4.86511e-01 -9.28542e-01]
21Feb16_204823| [-8.31270e-01 -3.94586e-01  5.51697e-02 -8.86387e-01 -6.99786e-01
21Feb16_204823|   6.44047e-01 -5.40571e-01  3.77503e-01  1.70193e-01  5.92883e-01
21Feb16_204823|   2.06540e-01  2.18639e-01]
21Feb16_204823| [-8.13637e-01  7.25044e-01  6.66092e-01  5.31057e-01 -4.48634e-01
21Feb16_204823|  -1.62601e-01 -1.57458e-02  7.74238e-02 -4.81841e-01  3.55485e-02
21Feb16_204823|  -7.21169e-01  1.05129e-01]
21Feb16_204823| [ 6.07201e-01  6.23643e-01  8.87343e-01  6.04285e-01  5.70453e-02
21Feb16_204823|   5.99381e-01 -3.21663e-03  6.64196e-01 -5.25584e-01 -1.74507e-02
21Feb16_204823|   3.80029e-01 -4.59585e-01]
21Feb16_204823| [-9.00078e-01  8.63133e-01  8.49324e-01  4.34648e-01 -5.67121e-01
21Feb16_204823|   6.24299e-01 -6.46637e-01  9.34620e-01 -5.42838e-01 -4.04257e-01
21Feb16_204823|  -4.70046e-01  4.29712e-01]
21Feb16_204823| [ 9.51731e-02  8.42954e-01 -7.44806e-01 -5.56045e-02 -4.89209e-01
21Feb16_204823|   8.07612e-01  2.77691e-01 -5.77946e-02  4.30356e-01 -9.05718e-01
21Feb16_204823|  -7.61358e-01 -4.56367e-01]
21Feb16_204823| [-9.06447e-01 -4.46566e-01 -4.40669e-01  6.09161e-01 -3.32587e-01
21Feb16_204823|  -9.31356e-01  9.62597e-02 -1.83060e-01  5.91585e-01 -2.78230e-01
21Feb16_204823|  -3.70976e-01 -3.38510e-01]
21Feb16_204823| [ 5.92999e-02 -5.35945e-01 -8.52259e-01  1.62766e-01 -2.64657e-01
21Feb16_204823|   6.65182e-01  2.45597e-01  2.99711e-01  7.14862e-01 -4.00362e-01
21Feb16_204823|   3.40170e-01 -1.14174e-01]
21Feb16_204823| [-4.26995e-01  8.46146e-01  9.81523e-01 -2.62996e-01  8.65377e-01
21Feb16_204823|  -6.86144e-01 -3.53983e-01 -2.18499e-01  3.29010e-01 -8.26088e-01
21Feb16_204823|   1.48202e-01  5.27152e-01]
21Feb16_204823| [-1.97937e-01  5.44304e-02  9.68680e-01  1.96012e-01  6.66432e-01
21Feb16_204823|  -1.15663e-01  1.01696e-01 -9.91833e-01  5.54656e-02  5.06069e-01
21Feb16_204823|  -8.39702e-01  6.07914e-02]
21Feb16_204823| [ 8.22409e-01 -3.07988e-01 -4.87097e-01 -2.67403e-01 -3.17115e-01
21Feb16_204823|   6.20877e-01  2.45721e-01  1.47039e-01  8.22748e-02 -4.61491e-01
21Feb16_204823|   5.08690e-01 -8.10093e-01]
21Feb16_204823| [-1.03463e-01 -7.13247e-01 -5.27190e-01 -8.14055e-01 -2.20069e-01
21Feb16_204823|   7.58689e-01  7.72478e-01 -3.75243e-01 -1.74773e-01  4.33018e-02
21Feb16_204823|   5.76591e-01 -9.04182e-01]
21Feb16_204823| [ 6.39880e-01 -2.76473e-01  4.48413e-01  7.92996e-01  6.12921e-01
21Feb16_204823|   8.45232e-01 -3.59434e-01 -1.65084e-01  6.00279e-01 -9.07135e-01
21Feb16_204823|  -9.18766e-01 -3.84510e-02]
21Feb16_204823| [-4.35982e-01  3.53117e-01 -4.33635e-01  4.41189e-01  2.02385e-01
21Feb16_204823|  -2.15156e-01 -3.32093e-01 -9.46393e-01  7.49818e-01  7.56840e-01
21Feb16_204823|  -2.97280e-01  3.76513e-01]
21Feb16_204823| [ 2.00098e-01 -3.94368e-01  4.74964e-01 -5.14077e-01 -5.02985e-01
21Feb16_204823|   6.57337e-01  4.54284e-01  7.99434e-01  1.18259e-01  7.90625e-01
21Feb16_204823|  -8.45168e-01 -7.22624e-01]
21Feb16_204823| [ 5.21361e-01 -9.37087e-01  6.98489e-01  7.45747e-01  9.84330e-01
21Feb16_204823|  -1.70463e-01 -4.14211e-01  4.94059e-01 -4.89685e-03 -7.22161e-02
21Feb16_204823|   3.28119e-01 -2.96382e-01]
21Feb16_204823| [ 9.97912e-02 -3.45331e-01 -3.32041e-01 -8.83410e-01  4.64194e-01
21Feb16_204823|  -2.94905e-01 -7.11116e-01 -2.12420e-01  8.93334e-01  5.60374e-01
21Feb16_204823|  -8.11522e-01  3.94537e-01]
21Feb16_204823| [ 2.39284e-01 -9.68110e-02 -3.48403e-01  6.68017e-01  1.07039e-01
21Feb16_204823|  -1.80014e-01 -1.28612e-01 -3.28318e-01  7.99371e-01  7.45882e-01
21Feb16_204823|   4.50426e-01 -9.94601e-02]
21Feb16_204823| [-9.32040e-02 -4.99896e-01 -3.18835e-01 -3.21963e-01  8.88030e-02
21Feb16_204823|   8.24115e-01  3.93190e-01  2.14054e-01 -4.70631e-02  5.36199e-01
21Feb16_204823|   7.72001e-01 -1.38053e-01]
21Feb16_204823| [ 8.31611e-01  7.46409e-01  2.18558e-01  7.47226e-01 -4.35942e-01
21Feb16_204823|  -6.59230e-01  3.39715e-02  8.14827e-01 -7.32488e-02 -1.12845e-01
21Feb16_204823|  -5.06295e-01  2.18074e-01]
21Feb16_204823| [-3.26563e-01  6.22846e-01  3.85669e-01 -9.86028e-01 -7.51629e-02
21Feb16_204823|  -1.88021e-01  7.27322e-01  5.61207e-04  1.34321e-01  7.19415e-01
21Feb16_204823|  -5.83277e-01 -4.45815e-01]
21Feb16_204823| [ 7.83756e-01  9.31803e-02  4.99853e-01 -9.31861e-01  7.91593e-01
21Feb16_204823|   1.96250e-01 -8.00498e-02  7.34271e-01 -2.68771e-01  7.49220e-01
21Feb16_204823|   1.24815e-01  6.17245e-01]
21Feb16_204823| [ 2.20500e-01 -9.26851e-01 -5.03545e-02  9.91366e-01  9.07862e-01
21Feb16_204823|   6.95839e-01  2.07702e-01  1.55262e-01  7.17753e-01 -6.02225e-01
21Feb16_204823|  -2.43972e-02  7.83904e-01]
21Feb16_204823| [-7.35179e-01 -4.04922e-01 -7.64988e-01  6.94764e-03 -5.74469e-01
21Feb16_204823|  -8.82582e-01 -4.25720e-01  4.48261e-01  9.38039e-01 -6.02162e-01
21Feb16_204823|   1.85138e-01  8.19467e-01]
21Feb16_204823| [-2.42564e-01  5.05630e-02 -6.53631e-01  8.89456e-01  3.73267e-02
21Feb16_204823|  -4.57479e-01  5.78190e-01 -8.65769e-01  4.43846e-01  9.21993e-01
21Feb16_204823|  -4.59642e-01  4.55887e-01]
21Feb16_204823| [ 1.79502e-01  5.97755e-01 -5.91581e-01  6.50878e-01 -3.20822e-02
21Feb16_204823|   7.98103e-01  9.23662e-01 -3.15762e-01  3.95919e-01 -9.74799e-01
21Feb16_204823|  -9.18783e-01  9.04381e-01]
21Feb16_204823| [-9.77544e-01 -9.84191e-01 -3.78989e-01  1.57093e-01 -1.19240e-01
21Feb16_204823|   7.04336e-01  9.20317e-01 -9.23300e-02  7.24512e-01 -4.73620e-01
21Feb16_204823|   4.32204e-01  1.96422e-01]
21Feb16_204823| [-9.94008e-01  1.23345e-01 -2.91311e-01  3.86181e-01  3.50519e-01
21Feb16_204823|   8.97293e-02  1.28693e-01  7.64175e-01  9.70172e-01 -9.36008e-01
21Feb16_204823|   2.31190e-01 -3.81352e-01]
21Feb16_204823| [-8.68842e-01 -3.08689e-01 -7.85613e-02 -7.75421e-01 -2.62711e-01
21Feb16_204823|  -9.13854e-01  5.58996e-01  8.97445e-01 -4.78631e-01 -4.79708e-02
21Feb16_204823|  -2.09270e-01  1.03320e-01]
21Feb16_204823| [ 2.47190e-01  8.94828e-01 -8.83655e-01  1.67368e-01 -1.09226e-01
21Feb16_204823|   5.39374e-01  3.22158e-01  7.22802e-01 -4.76431e-01 -3.98606e-01
21Feb16_204823|   3.91466e-01 -5.89172e-01]
21Feb16_204823| [ 2.03966e-01 -8.11217e-01  8.56319e-01 -5.26108e-01 -9.29896e-01
21Feb16_204823|   5.92077e-01  8.52854e-01  6.15086e-01  5.45676e-01 -8.13950e-01
21Feb16_204823|   6.24771e-01 -9.57171e-01]
21Feb16_204823| [-7.59457e-01  2.18652e-01 -9.40198e-01 -1.94388e-03 -3.63300e-01
21Feb16_204823|   2.19527e-01 -3.86609e-01  6.57866e-02  8.04643e-01  4.37489e-01
21Feb16_204823|   6.39988e-01 -8.42788e-01]
21Feb16_204823| [-2.79911e-01  8.89651e-01  5.38994e-02  7.45843e-01 -9.32154e-01
21Feb16_204823|   5.56522e-01  5.04658e-01  3.56409e-01 -5.15289e-01  6.99550e-01
21Feb16_204823|  -7.31032e-01  1.61260e-01]
21Feb16_204823| [ 8.41582e-01 -5.25391e-01  4.65437e-01  4.40808e-01 -6.03761e-01
21Feb16_204823|   6.23036e-01  9.46114e-01  5.92328e-01  2.08190e-01 -6.69715e-01
21Feb16_204823|  -7.35264e-02  5.96491e-01]
21Feb16_204823| [ 3.20347e-01  1.37290e-01  1.72843e-02 -4.70187e-01  5.92987e-01
21Feb16_204823|   3.57672e-01  2.73873e-01 -8.65750e-02 -3.09144e-01 -9.20603e-01
21Feb16_204823|   2.82912e-01  6.38325e-01]
21Feb16_204823| [-8.91399e-01 -1.24857e-01 -4.86431e-01 -9.05166e-01  8.47373e-01
21Feb16_204823|   3.18146e-01  2.73494e-02 -5.33112e-01  5.63862e-01 -5.12821e-01
21Feb16_204823|  -9.38474e-01 -9.90043e-01]
21Feb16_204823| [-8.25448e-01 -1.90141e-02 -5.51276e-01 -8.23215e-01  7.26222e-02
21Feb16_204823|   3.49894e-01  5.17693e-01 -5.57217e-01 -3.26301e-01  7.78564e-01
21Feb16_204823|   6.58213e-01 -2.83929e-01]
21Feb16_204823| [ 6.18012e-02 -4.92329e-01  5.41071e-01  2.13013e-01  6.35700e-01
21Feb16_204823|  -1.65529e-01  5.77357e-01  2.45531e-01  2.54855e-01 -8.48854e-01
21Feb16_204823|   6.46386e-01 -4.13404e-01]
21Feb16_204823| [-3.41116e-01 -4.75918e-01  3.59165e-01  6.02895e-01 -4.31688e-01
21Feb16_204823|  -8.51757e-01  2.31464e-01 -9.57407e-01  2.83436e-01 -4.51744e-01
21Feb16_204823|   4.80022e-02 -8.35007e-01]
21Feb16_204823| [ 9.67499e-01  5.85047e-02  7.21540e-01  3.12459e-01  3.50272e-01
21Feb16_204823|   2.14450e-01 -3.30294e-01 -7.99000e-01  1.11959e-01  2.74091e-01
21Feb16_204823|  -1.78234e-01  9.40235e-01]
21Feb16_204823| [-1.14387e-01  4.31319e-01  3.73789e-01 -4.62497e-01  4.50407e-01
21Feb16_204823|  -4.00668e-01 -8.26575e-01  2.39589e-01 -5.24611e-01  3.30691e-01
21Feb16_204823|  -3.99504e-01  1.44547e-01]
21Feb16_204823| [ 7.34826e-01 -5.37352e-01 -6.62895e-01  1.04258e-01  2.15046e-03
21Feb16_204823|   2.71790e-01  8.51151e-01 -6.31948e-01  1.94011e-01 -6.41830e-01
21Feb16_204823|   1.67802e-01 -4.29449e-01]
21Feb16_204823| [-6.18752e-01  1.18069e-01 -7.98263e-01  4.75266e-01 -9.95474e-01
21Feb16_204823|  -1.79698e-01  6.90455e-01  3.44607e-01 -5.80013e-01 -6.16218e-02
21Feb16_204823|   7.01329e-01  8.33298e-02]
21Feb16_204823| [-2.69227e-01 -1.43165e-02 -3.33533e-01 -1.69954e-01 -1.26476e-02
21Feb16_204823|   7.69653e-01 -6.99893e-01  5.22539e-01 -1.67862e-01  4.44416e-01
21Feb16_204823|   6.72372e-01  5.52923e-01]
21Feb16_204823| [-7.10479e-01  1.61800e-01  2.53825e-01 -3.00634e-01 -5.06805e-01
21Feb16_204823|   2.02091e-01 -4.94980e-02 -1.44363e-01 -6.18371e-01  5.74350e-01
21Feb16_204823|  -1.85073e-01 -8.11049e-01]
21Feb16_204823| [-6.60846e-01 -1.69003e-01  6.00733e-01 -8.28618e-01 -3.99034e-01
21Feb16_204823|  -5.82553e-01  7.34428e-02  5.57096e-01 -1.50695e-01  1.26307e-01
21Feb16_204823|   8.92712e-01 -8.75142e-01]
21Feb16_204823| [ 7.58158e-01  5.89907e-01 -1.92304e-01 -3.86200e-01 -2.63049e-01
21Feb16_204823|  -3.41209e-03  4.05030e-01 -8.95945e-02  9.79113e-01  6.78942e-02
21Feb16_204823|  -9.53580e-01  7.06162e-01]
21Feb16_204823| [-1.23045e-01  9.25694e-01  5.20030e-01  4.57808e-01 -9.99639e-01
21Feb16_204823|  -9.80069e-02  3.03598e-01  4.26167e-02 -3.64595e-01 -7.17635e-01
21Feb16_204823|   1.61128e-01  6.30329e-01]
21Feb16_204823| [ 2.02232e-02 -3.24113e-01  7.43999e-01 -3.75983e-01  4.63558e-01
21Feb16_204823|  -2.04941e-01 -5.28404e-02  4.26576e-01 -2.53802e-01  1.74976e-01
21Feb16_204823|  -8.35763e-01  8.54548e-01]
21Feb16_204823| [-5.76875e-01  5.40954e-01 -4.91777e-01  4.40209e-01 -9.16379e-01
21Feb16_204823|   6.01728e-01  1.25226e-02  2.05876e-01  8.45524e-01 -8.34178e-01
21Feb16_204823|  -7.87379e-01  8.63352e-01]
21Feb16_204823| [-3.15102e-01  7.00213e-01  6.69503e-01  7.15510e-01 -9.53550e-01
21Feb16_204823|   4.07885e-02  4.25336e-01  6.24629e-01  9.90858e-01  6.36989e-01
21Feb16_204823|  -6.44355e-01 -5.47589e-01]
21Feb16_204823| [-8.25051e-01 -4.37574e-01  4.76334e-01 -7.71092e-01  7.98467e-01
21Feb16_204823|  -1.52347e-01  3.34469e-01  1.51889e-01 -9.60611e-01  4.62484e-01
21Feb16_204823|   4.10115e-01 -1.60555e-01]
21Feb16_204823| [ 1.77712e-01  6.55776e-01  8.97735e-01 -9.20852e-01 -9.69032e-01
21Feb16_204823|  -4.79756e-02 -3.24015e-01 -1.57490e-01 -6.25919e-01  9.94240e-01
21Feb16_204823|  -4.74141e-01 -1.00993e-01]
21Feb16_204823| [ 3.66246e-01  8.06205e-01  3.37216e-01 -3.17040e-01  9.19693e-01
21Feb16_204823|   8.28581e-01  2.22724e-01 -5.57410e-01 -8.17434e-01 -8.65693e-01
21Feb16_204823|  -4.72960e-01  7.15176e-01]
21Feb16_204823| [-8.25000e-01 -4.67253e-01 -1.84646e-02  3.88053e-01 -8.75853e-01
21Feb16_204823|  -2.34509e-01  9.53471e-01  8.05489e-02  2.71744e-01 -7.15129e-01
21Feb16_204823|   9.24875e-01 -6.07435e-01]
21Feb16_204823| [-2.79447e-01  2.39105e-01  1.32962e-01 -7.68103e-01  7.58443e-01
21Feb16_204823|  -1.69646e-01 -7.52460e-01 -7.30195e-01 -4.68985e-01 -2.88784e-01
21Feb16_204823|   3.77655e-02 -5.72024e-01]
21Feb16_204823| [-8.37481e-01 -8.22188e-02  8.45547e-01 -5.53876e-01  5.72703e-01
21Feb16_204823|   3.09970e-01  8.96552e-01  3.97690e-01 -7.19080e-01  2.37714e-01
21Feb16_204823|   6.60752e-01  1.69435e-01]]
21Feb16_204823|-- Bias --
21Feb16_204823|[-0.28065  0.08142 -0.20194  0.96969  0.45180  0.54884  0.16606 -0.15804
21Feb16_204823|  0.47362  0.17133  0.43345 -0.35803]
21Feb16_204823|Layer 1:
21Feb16_204823|-- Config --
21Feb16_204823|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 12], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204823|-- Weights --
21Feb16_204823|[[-0.88546  0.72941]
21Feb16_204823| [ 0.79196 -0.05477]
21Feb16_204823| [-0.89752 -0.49343]
21Feb16_204823| [ 0.78974 -0.41510]
21Feb16_204823| [ 0.29561 -0.94575]
21Feb16_204823| [-0.14754  0.69148]
21Feb16_204823| [-0.33558  0.37910]
21Feb16_204823| [-0.82387  0.15998]
21Feb16_204823| [-0.77760  0.88462]
21Feb16_204823| [ 0.98329 -0.68363]
21Feb16_204823| [ 0.88895  0.40387]
21Feb16_204823| [ 0.39015 -0.38652]]
21Feb16_204823|-- Bias --
21Feb16_204823|[ 0.28702 -0.70976]
21Feb16_204823|Predicting the validation and test data with the Best initial individual.
21Feb16_204829| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb16_204829|-----------  ------------------  --------------------  ----------
21Feb16_204829|Validation         42.00                  12            0.00000
21Feb16_204829|   Test            36.32                  12            0.00298
21Feb16_204829|-------------------- Test #0 --------------------
21Feb16_204829|Best final individual weights
21Feb16_204829|Individual:
21Feb16_204829|-- Constant hidden layers --
21Feb16_204829|False
21Feb16_204829|Layer 0:
21Feb16_204829|-- Config --
21Feb16_204829|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204829|-- Weights --
21Feb16_204829|[[-0.73212  1.32861  0.10200]
21Feb16_204829| [ 1.48746 -2.97273 -0.42944]
21Feb16_204829| [ 0.53095 -1.50623  0.79224]
21Feb16_204829| [-1.07292 -0.83175 -0.90105]
21Feb16_204829| [-0.48696 -0.89325  0.27226]
21Feb16_204829| [-3.02511  0.34155 -0.03837]
21Feb16_204829| [-0.76747  0.57140 -0.46892]
21Feb16_204829| [-0.07581  0.14713  0.85910]
21Feb16_204829| [-1.37488  0.52170 -0.36205]
21Feb16_204829| [ 1.60981 -0.08727 -0.11267]
21Feb16_204829| [ 0.50986  1.58916 -0.35287]
21Feb16_204829| [-0.34599  1.27113 -0.16393]
21Feb16_204829| [ 1.29203  1.19467  0.37695]
21Feb16_204829| [ 0.58704  0.06328 -0.24240]
21Feb16_204829| [-0.93888 -0.89760  0.57087]
21Feb16_204829| [ 0.99159 -0.66387  0.35177]
21Feb16_204829| [-0.67119  1.06910 -0.12512]
21Feb16_204829| [-0.91534  1.23744 -0.40465]
21Feb16_204829| [ 1.39278  0.08069  0.23328]
21Feb16_204829| [ 0.09880  0.57603 -0.96101]
21Feb16_204829| [ 0.01621 -0.13343 -0.27624]
21Feb16_204829| [-1.28286 -2.28909  0.37931]
21Feb16_204829| [-0.28370  0.09336  0.01547]
21Feb16_204829| [-0.51894  1.84280 -0.25906]
21Feb16_204829| [-0.83075 -0.04508  0.12107]
21Feb16_204829| [ 0.37343  1.18436 -0.07358]
21Feb16_204829| [-2.38657 -0.35191  0.01962]
21Feb16_204829| [ 0.95757 -0.91760 -0.08971]
21Feb16_204829| [ 0.38792 -0.01880  0.69717]
21Feb16_204829| [ 1.66877 -0.58078 -1.21129]
21Feb16_204829| [-0.50943  0.59080  0.30856]
21Feb16_204829| [ 0.30163  1.11518  0.98185]
21Feb16_204829| [-0.73226  0.32281 -0.66712]
21Feb16_204829| [-0.62054 -2.21049  1.40981]
21Feb16_204829| [ 1.23185 -0.58090  0.35844]
21Feb16_204829| [-0.05616  0.24219 -0.02853]
21Feb16_204829| [-1.05085 -2.30259 -0.16276]
21Feb16_204829| [ 0.71087  0.14900  1.13430]
21Feb16_204829| [-2.45877 -1.20999 -1.04986]
21Feb16_204829| [-1.00480  1.36344 -0.13998]
21Feb16_204829| [ 1.83140 -0.91532  0.07616]
21Feb16_204829| [-0.60404 -2.05184  0.76948]
21Feb16_204829| [ 0.52617  0.76042 -1.76746]
21Feb16_204829| [-0.22134  0.17324  0.99530]
21Feb16_204829| [-0.36427  1.34655  0.02110]
21Feb16_204829| [-0.93125 -0.33620 -0.25012]
21Feb16_204829| [-2.76428  0.14487  0.48096]
21Feb16_204829| [-0.10518  0.35052  1.71840]
21Feb16_204829| [-1.27998  1.12568  1.26523]
21Feb16_204829| [-0.60698  1.53230 -0.60824]
21Feb16_204829| [ 0.02898  2.98718 -0.59153]
21Feb16_204829| [ 0.17588 -0.00449  0.50797]
21Feb16_204829| [-1.42674 -0.54967 -0.21310]
21Feb16_204829| [ 1.03196  1.18733  0.36755]
21Feb16_204829| [ 1.04748 -1.47444 -0.08469]
21Feb16_204829| [ 0.49410  0.38745  0.68469]
21Feb16_204829| [-0.62880  0.73245  0.19964]]
21Feb16_204829|-- Bias --
21Feb16_204829|[-0.18798  0.64571 -0.23142]
21Feb16_204829|Layer 1:
21Feb16_204829|-- Config --
21Feb16_204829|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204829|-- Weights --
21Feb16_204829|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb16_204829| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb16_204829| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb16_204829|-- Bias --
21Feb16_204829|[0.60477 0.03773 0.26452 0.12222]
21Feb16_204829|Layer 2:
21Feb16_204829|-- Config --
21Feb16_204829|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204829|-- Weights --
21Feb16_204829|[[ 0.67920  0.12119]
21Feb16_204829| [ 0.44836  0.02916]
21Feb16_204829| [ 0.68939  0.31516]
21Feb16_204829| [-0.58995 -0.05861]]
21Feb16_204829|-- Bias --
21Feb16_204829|[ 0.59649 -0.08079]
21Feb16_204829|Layer 3:
21Feb16_204829|-- Config --
21Feb16_204829|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204829|-- Weights --
21Feb16_204829|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb16_204829| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb16_204829|-- Bias --
21Feb16_204829|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb16_204829|Layer 4:
21Feb16_204829|-- Config --
21Feb16_204829|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204829|-- Weights --
21Feb16_204829|[[-0.03514 -1.04833]
21Feb16_204829| [ 1.25238  0.62094]
21Feb16_204829| [ 0.99203  0.37406]
21Feb16_204829| [ 0.49902  0.67158]
21Feb16_204829| [-1.35709  0.38335]]
21Feb16_204829|-- Bias --
21Feb16_204829|[0.31435 0.36299]
21Feb16_204829|Predicting the validation and test data with the Best final individual.
21Feb16_204837| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb16_204837|-----------  ------------------  --------------------  ----------
21Feb16_204837|Validation         40.17                  56            0.05627
21Feb16_204837|   Test            21.37                  56            0.70301
21Feb16_204837|-------------------- Test #1 --------------------
21Feb16_204837|Best final individual weights
21Feb16_204837|Individual:
21Feb16_204837|-- Constant hidden layers --
21Feb16_204837|False
21Feb16_204837|Layer 0:
21Feb16_204837|-- Config --
21Feb16_204837|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204837|-- Weights --
21Feb16_204837|[[-0.73212  1.32861  0.10200]
21Feb16_204837| [ 1.48746 -2.97273 -0.42944]
21Feb16_204837| [ 0.53095 -1.50623  0.79224]
21Feb16_204837| [-1.07292 -0.83175 -0.90105]
21Feb16_204837| [-0.48696 -0.89325  0.27226]
21Feb16_204837| [-3.02511  0.34155 -0.03837]
21Feb16_204837| [-0.76747  0.57140 -0.46892]
21Feb16_204837| [-0.07581  0.14713  0.85910]
21Feb16_204837| [-1.37488  0.52170 -0.36205]
21Feb16_204837| [ 1.60981 -0.08727 -0.11267]
21Feb16_204837| [ 0.50986  1.58916 -0.35287]
21Feb16_204837| [-0.34599  1.27113 -0.16393]
21Feb16_204837| [ 1.29203  1.19467  0.37695]
21Feb16_204837| [ 0.58704  0.06328 -0.24240]
21Feb16_204837| [-0.93888 -0.89760  0.57087]
21Feb16_204837| [ 0.99159 -0.66387  0.35177]
21Feb16_204837| [-0.67119  1.06910 -0.12512]
21Feb16_204837| [-0.91534  1.23744 -0.40465]
21Feb16_204837| [ 1.39278  0.08069  0.23328]
21Feb16_204837| [ 0.09880  0.57603 -0.96101]
21Feb16_204837| [ 0.01621 -0.13343 -0.27624]
21Feb16_204837| [-1.28286 -2.28909  0.37931]
21Feb16_204837| [-0.28370  0.09336  0.01547]
21Feb16_204837| [-0.51894  1.84280 -0.25906]
21Feb16_204837| [-0.83075 -0.04508  0.12107]
21Feb16_204837| [ 0.37343  1.18436 -0.07358]
21Feb16_204837| [-2.38657 -0.35191  0.01962]
21Feb16_204837| [ 0.95757 -0.91760 -0.08971]
21Feb16_204837| [ 0.38792 -0.01880  0.69717]
21Feb16_204837| [ 1.66877 -0.58078 -1.21129]
21Feb16_204837| [-0.50943  0.59080  0.30856]
21Feb16_204837| [ 0.30163  1.11518  0.98185]
21Feb16_204837| [-0.73226  0.32281 -0.66712]
21Feb16_204837| [-0.62054 -2.21049  1.40981]
21Feb16_204837| [ 1.23185 -0.58090  0.35844]
21Feb16_204837| [-0.05616  0.24219 -0.02853]
21Feb16_204837| [-1.05085 -2.30259 -0.16276]
21Feb16_204837| [ 0.71087  0.14900  1.13430]
21Feb16_204837| [-2.45877 -1.20999 -1.04986]
21Feb16_204837| [-1.00480  1.36344 -0.13998]
21Feb16_204837| [ 1.83140 -0.91532  0.07616]
21Feb16_204837| [-0.60404 -2.05184  0.76948]
21Feb16_204837| [ 0.52617  0.76042 -1.76746]
21Feb16_204837| [-0.22134  0.17324  0.99530]
21Feb16_204837| [-0.36427  1.34655  0.02110]
21Feb16_204837| [-0.93125 -0.33620 -0.25012]
21Feb16_204837| [-2.76428  0.14487  0.48096]
21Feb16_204837| [-0.10518  0.35052  1.71840]
21Feb16_204837| [-1.27998  1.12568  1.26523]
21Feb16_204837| [-0.60698  1.53230 -0.60824]
21Feb16_204837| [ 0.02898  2.98718 -0.59153]
21Feb16_204837| [ 0.17588 -0.00449  0.50797]
21Feb16_204837| [-1.42674 -0.54967 -0.21310]
21Feb16_204837| [ 1.03196  1.18733  0.36755]
21Feb16_204837| [ 1.04748 -1.47444 -0.08469]
21Feb16_204837| [ 0.49410  0.38745  0.68469]
21Feb16_204837| [-0.62880  0.73245  0.19964]]
21Feb16_204837|-- Bias --
21Feb16_204837|[-0.18798  0.64571 -0.23142]
21Feb16_204837|Layer 1:
21Feb16_204837|-- Config --
21Feb16_204837|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204837|-- Weights --
21Feb16_204837|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb16_204837| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb16_204837| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb16_204837|-- Bias --
21Feb16_204837|[0.60477 0.03773 0.26452 0.12222]
21Feb16_204837|Layer 2:
21Feb16_204837|-- Config --
21Feb16_204837|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204837|-- Weights --
21Feb16_204837|[[ 0.67920  0.12119]
21Feb16_204837| [ 0.44836  0.02916]
21Feb16_204837| [ 0.68939  0.31516]
21Feb16_204837| [-0.58995 -0.05861]]
21Feb16_204837|-- Bias --
21Feb16_204837|[ 0.59649 -0.08079]
21Feb16_204837|Layer 3:
21Feb16_204837|-- Config --
21Feb16_204837|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204837|-- Weights --
21Feb16_204837|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb16_204837| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb16_204837|-- Bias --
21Feb16_204837|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb16_204837|Layer 4:
21Feb16_204837|-- Config --
21Feb16_204837|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204837|-- Weights --
21Feb16_204837|[[-0.03514 -1.04833]
21Feb16_204837| [ 1.25238  0.62094]
21Feb16_204837| [ 0.99203  0.37406]
21Feb16_204837| [ 0.49902  0.67158]
21Feb16_204837| [-1.35709  0.38335]]
21Feb16_204837|-- Bias --
21Feb16_204837|[0.31435 0.36299]
21Feb16_204837|Predicting the validation and test data with the Best final individual.
21Feb16_204844| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb16_204844|-----------  ------------------  --------------------  ----------
21Feb16_204844|Validation         23.83                  56            0.86651
21Feb16_204844|   Test            22.68                  56            0.77969
21Feb16_204844|-------------------- Test #2 --------------------
21Feb16_204844|Best final individual weights
21Feb16_204844|Individual:
21Feb16_204844|-- Constant hidden layers --
21Feb16_204844|False
21Feb16_204844|Layer 0:
21Feb16_204844|-- Config --
21Feb16_204844|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204844|-- Weights --
21Feb16_204844|[[-0.73212  1.32861  0.10200]
21Feb16_204844| [ 1.48746 -2.97273 -0.42944]
21Feb16_204844| [ 0.53095 -1.50623  0.79224]
21Feb16_204844| [-1.07292 -0.83175 -0.90105]
21Feb16_204844| [-0.48696 -0.89325  0.27226]
21Feb16_204844| [-3.02511  0.34155 -0.03837]
21Feb16_204844| [-0.76747  0.57140 -0.46892]
21Feb16_204844| [-0.07581  0.14713  0.85910]
21Feb16_204844| [-1.37488  0.52170 -0.36205]
21Feb16_204844| [ 1.60981 -0.08727 -0.11267]
21Feb16_204844| [ 0.50986  1.58916 -0.35287]
21Feb16_204844| [-0.34599  1.27113 -0.16393]
21Feb16_204844| [ 1.29203  1.19467  0.37695]
21Feb16_204844| [ 0.58704  0.06328 -0.24240]
21Feb16_204844| [-0.93888 -0.89760  0.57087]
21Feb16_204844| [ 0.99159 -0.66387  0.35177]
21Feb16_204844| [-0.67119  1.06910 -0.12512]
21Feb16_204844| [-0.91534  1.23744 -0.40465]
21Feb16_204844| [ 1.39278  0.08069  0.23328]
21Feb16_204844| [ 0.09880  0.57603 -0.96101]
21Feb16_204844| [ 0.01621 -0.13343 -0.27624]
21Feb16_204844| [-1.28286 -2.28909  0.37931]
21Feb16_204844| [-0.28370  0.09336  0.01547]
21Feb16_204844| [-0.51894  1.84280 -0.25906]
21Feb16_204844| [-0.83075 -0.04508  0.12107]
21Feb16_204844| [ 0.37343  1.18436 -0.07358]
21Feb16_204844| [-2.38657 -0.35191  0.01962]
21Feb16_204844| [ 0.95757 -0.91760 -0.08971]
21Feb16_204844| [ 0.38792 -0.01880  0.69717]
21Feb16_204844| [ 1.66877 -0.58078 -1.21129]
21Feb16_204844| [-0.50943  0.59080  0.30856]
21Feb16_204844| [ 0.30163  1.11518  0.98185]
21Feb16_204844| [-0.73226  0.32281 -0.66712]
21Feb16_204844| [-0.62054 -2.21049  1.40981]
21Feb16_204844| [ 1.23185 -0.58090  0.35844]
21Feb16_204844| [-0.05616  0.24219 -0.02853]
21Feb16_204844| [-1.05085 -2.30259 -0.16276]
21Feb16_204844| [ 0.71087  0.14900  1.13430]
21Feb16_204844| [-2.45877 -1.20999 -1.04986]
21Feb16_204844| [-1.00480  1.36344 -0.13998]
21Feb16_204844| [ 1.83140 -0.91532  0.07616]
21Feb16_204844| [-0.60404 -2.05184  0.76948]
21Feb16_204844| [ 0.52617  0.76042 -1.76746]
21Feb16_204844| [-0.22134  0.17324  0.99530]
21Feb16_204844| [-0.36427  1.34655  0.02110]
21Feb16_204844| [-0.93125 -0.33620 -0.25012]
21Feb16_204844| [-2.76428  0.14487  0.48096]
21Feb16_204844| [-0.10518  0.35052  1.71840]
21Feb16_204844| [-1.27998  1.12568  1.26523]
21Feb16_204844| [-0.60698  1.53230 -0.60824]
21Feb16_204844| [ 0.02898  2.98718 -0.59153]
21Feb16_204844| [ 0.17588 -0.00449  0.50797]
21Feb16_204844| [-1.42674 -0.54967 -0.21310]
21Feb16_204844| [ 1.03196  1.18733  0.36755]
21Feb16_204844| [ 1.04748 -1.47444 -0.08469]
21Feb16_204844| [ 0.49410  0.38745  0.68469]
21Feb16_204844| [-0.62880  0.73245  0.19964]]
21Feb16_204844|-- Bias --
21Feb16_204844|[-0.18798  0.64571 -0.23142]
21Feb16_204844|Layer 1:
21Feb16_204844|-- Config --
21Feb16_204844|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204844|-- Weights --
21Feb16_204844|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb16_204844| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb16_204844| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb16_204844|-- Bias --
21Feb16_204844|[0.60477 0.03773 0.26452 0.12222]
21Feb16_204844|Layer 2:
21Feb16_204844|-- Config --
21Feb16_204844|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204844|-- Weights --
21Feb16_204844|[[ 0.67920  0.12119]
21Feb16_204844| [ 0.44836  0.02916]
21Feb16_204844| [ 0.68939  0.31516]
21Feb16_204844| [-0.58995 -0.05861]]
21Feb16_204844|-- Bias --
21Feb16_204844|[ 0.59649 -0.08079]
21Feb16_204844|Layer 3:
21Feb16_204844|-- Config --
21Feb16_204844|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204844|-- Weights --
21Feb16_204844|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb16_204844| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb16_204844|-- Bias --
21Feb16_204844|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb16_204844|Layer 4:
21Feb16_204844|-- Config --
21Feb16_204844|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204844|-- Weights --
21Feb16_204844|[[-0.03514 -1.04833]
21Feb16_204844| [ 1.25238  0.62094]
21Feb16_204844| [ 0.99203  0.37406]
21Feb16_204844| [ 0.49902  0.67158]
21Feb16_204844| [-1.35709  0.38335]]
21Feb16_204844|-- Bias --
21Feb16_204844|[0.31435 0.36299]
21Feb16_204844|Predicting the validation and test data with the Best final individual.
21Feb16_204852| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb16_204852|-----------  ------------------  --------------------  ----------
21Feb16_204852|Validation         23.91                  56            0.70865
21Feb16_204852|   Test            29.45                  56            0.70270
21Feb16_204852|-------------------- Test #3 --------------------
21Feb16_204852|Best final individual weights
21Feb16_204852|Individual:
21Feb16_204852|-- Constant hidden layers --
21Feb16_204852|False
21Feb16_204852|Layer 0:
21Feb16_204852|-- Config --
21Feb16_204852|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204852|-- Weights --
21Feb16_204852|[[-0.73212  1.32861  0.10200]
21Feb16_204852| [ 1.48746 -2.97273 -0.42944]
21Feb16_204852| [ 0.53095 -1.50623  0.79224]
21Feb16_204852| [-1.07292 -0.83175 -0.90105]
21Feb16_204852| [-0.48696 -0.89325  0.27226]
21Feb16_204852| [-3.02511  0.34155 -0.03837]
21Feb16_204852| [-0.76747  0.57140 -0.46892]
21Feb16_204852| [-0.07581  0.14713  0.85910]
21Feb16_204852| [-1.37488  0.52170 -0.36205]
21Feb16_204852| [ 1.60981 -0.08727 -0.11267]
21Feb16_204852| [ 0.50986  1.58916 -0.35287]
21Feb16_204852| [-0.34599  1.27113 -0.16393]
21Feb16_204852| [ 1.29203  1.19467  0.37695]
21Feb16_204852| [ 0.58704  0.06328 -0.24240]
21Feb16_204852| [-0.93888 -0.89760  0.57087]
21Feb16_204852| [ 0.99159 -0.66387  0.35177]
21Feb16_204852| [-0.67119  1.06910 -0.12512]
21Feb16_204852| [-0.91534  1.23744 -0.40465]
21Feb16_204852| [ 1.39278  0.08069  0.23328]
21Feb16_204852| [ 0.09880  0.57603 -0.96101]
21Feb16_204852| [ 0.01621 -0.13343 -0.27624]
21Feb16_204852| [-1.28286 -2.28909  0.37931]
21Feb16_204852| [-0.28370  0.09336  0.01547]
21Feb16_204852| [-0.51894  1.84280 -0.25906]
21Feb16_204852| [-0.83075 -0.04508  0.12107]
21Feb16_204852| [ 0.37343  1.18436 -0.07358]
21Feb16_204852| [-2.38657 -0.35191  0.01962]
21Feb16_204852| [ 0.95757 -0.91760 -0.08971]
21Feb16_204852| [ 0.38792 -0.01880  0.69717]
21Feb16_204852| [ 1.66877 -0.58078 -1.21129]
21Feb16_204852| [-0.50943  0.59080  0.30856]
21Feb16_204852| [ 0.30163  1.11518  0.98185]
21Feb16_204852| [-0.73226  0.32281 -0.66712]
21Feb16_204852| [-0.62054 -2.21049  1.40981]
21Feb16_204852| [ 1.23185 -0.58090  0.35844]
21Feb16_204852| [-0.05616  0.24219 -0.02853]
21Feb16_204852| [-1.05085 -2.30259 -0.16276]
21Feb16_204852| [ 0.71087  0.14900  1.13430]
21Feb16_204852| [-2.45877 -1.20999 -1.04986]
21Feb16_204852| [-1.00480  1.36344 -0.13998]
21Feb16_204852| [ 1.83140 -0.91532  0.07616]
21Feb16_204852| [-0.60404 -2.05184  0.76948]
21Feb16_204852| [ 0.52617  0.76042 -1.76746]
21Feb16_204852| [-0.22134  0.17324  0.99530]
21Feb16_204852| [-0.36427  1.34655  0.02110]
21Feb16_204852| [-0.93125 -0.33620 -0.25012]
21Feb16_204852| [-2.76428  0.14487  0.48096]
21Feb16_204852| [-0.10518  0.35052  1.71840]
21Feb16_204852| [-1.27998  1.12568  1.26523]
21Feb16_204852| [-0.60698  1.53230 -0.60824]
21Feb16_204852| [ 0.02898  2.98718 -0.59153]
21Feb16_204852| [ 0.17588 -0.00449  0.50797]
21Feb16_204852| [-1.42674 -0.54967 -0.21310]
21Feb16_204852| [ 1.03196  1.18733  0.36755]
21Feb16_204852| [ 1.04748 -1.47444 -0.08469]
21Feb16_204852| [ 0.49410  0.38745  0.68469]
21Feb16_204852| [-0.62880  0.73245  0.19964]]
21Feb16_204852|-- Bias --
21Feb16_204852|[-0.18798  0.64571 -0.23142]
21Feb16_204852|Layer 1:
21Feb16_204852|-- Config --
21Feb16_204852|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204852|-- Weights --
21Feb16_204852|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb16_204852| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb16_204852| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb16_204852|-- Bias --
21Feb16_204852|[0.60477 0.03773 0.26452 0.12222]
21Feb16_204852|Layer 2:
21Feb16_204852|-- Config --
21Feb16_204852|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204852|-- Weights --
21Feb16_204852|[[ 0.67920  0.12119]
21Feb16_204852| [ 0.44836  0.02916]
21Feb16_204852| [ 0.68939  0.31516]
21Feb16_204852| [-0.58995 -0.05861]]
21Feb16_204852|-- Bias --
21Feb16_204852|[ 0.59649 -0.08079]
21Feb16_204852|Layer 3:
21Feb16_204852|-- Config --
21Feb16_204852|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204852|-- Weights --
21Feb16_204852|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb16_204852| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb16_204852|-- Bias --
21Feb16_204852|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb16_204852|Layer 4:
21Feb16_204852|-- Config --
21Feb16_204852|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204852|-- Weights --
21Feb16_204852|[[-0.03514 -1.04833]
21Feb16_204852| [ 1.25238  0.62094]
21Feb16_204852| [ 0.99203  0.37406]
21Feb16_204852| [ 0.49902  0.67158]
21Feb16_204852| [-1.35709  0.38335]]
21Feb16_204852|-- Bias --
21Feb16_204852|[0.31435 0.36299]
21Feb16_204852|Predicting the validation and test data with the Best final individual.
21Feb16_204900| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb16_204900|-----------  ------------------  --------------------  ----------
21Feb16_204900|Validation         24.35                  56            0.84577
21Feb16_204900|   Test            21.63                  56            0.70714
21Feb16_204900|-------------------- Test #4 --------------------
21Feb16_204900|Best final individual weights
21Feb16_204900|Individual:
21Feb16_204900|-- Constant hidden layers --
21Feb16_204900|False
21Feb16_204900|Layer 0:
21Feb16_204900|-- Config --
21Feb16_204900|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204900|-- Weights --
21Feb16_204900|[[-0.73212  1.32861  0.10200]
21Feb16_204900| [ 1.48746 -2.97273 -0.42944]
21Feb16_204900| [ 0.53095 -1.50623  0.79224]
21Feb16_204900| [-1.07292 -0.83175 -0.90105]
21Feb16_204900| [-0.48696 -0.89325  0.27226]
21Feb16_204900| [-3.02511  0.34155 -0.03837]
21Feb16_204900| [-0.76747  0.57140 -0.46892]
21Feb16_204900| [-0.07581  0.14713  0.85910]
21Feb16_204900| [-1.37488  0.52170 -0.36205]
21Feb16_204900| [ 1.60981 -0.08727 -0.11267]
21Feb16_204900| [ 0.50986  1.58916 -0.35287]
21Feb16_204900| [-0.34599  1.27113 -0.16393]
21Feb16_204900| [ 1.29203  1.19467  0.37695]
21Feb16_204900| [ 0.58704  0.06328 -0.24240]
21Feb16_204900| [-0.93888 -0.89760  0.57087]
21Feb16_204900| [ 0.99159 -0.66387  0.35177]
21Feb16_204900| [-0.67119  1.06910 -0.12512]
21Feb16_204900| [-0.91534  1.23744 -0.40465]
21Feb16_204900| [ 1.39278  0.08069  0.23328]
21Feb16_204900| [ 0.09880  0.57603 -0.96101]
21Feb16_204900| [ 0.01621 -0.13343 -0.27624]
21Feb16_204900| [-1.28286 -2.28909  0.37931]
21Feb16_204900| [-0.28370  0.09336  0.01547]
21Feb16_204900| [-0.51894  1.84280 -0.25906]
21Feb16_204900| [-0.83075 -0.04508  0.12107]
21Feb16_204900| [ 0.37343  1.18436 -0.07358]
21Feb16_204900| [-2.38657 -0.35191  0.01962]
21Feb16_204900| [ 0.95757 -0.91760 -0.08971]
21Feb16_204900| [ 0.38792 -0.01880  0.69717]
21Feb16_204900| [ 1.66877 -0.58078 -1.21129]
21Feb16_204900| [-0.50943  0.59080  0.30856]
21Feb16_204900| [ 0.30163  1.11518  0.98185]
21Feb16_204900| [-0.73226  0.32281 -0.66712]
21Feb16_204900| [-0.62054 -2.21049  1.40981]
21Feb16_204900| [ 1.23185 -0.58090  0.35844]
21Feb16_204900| [-0.05616  0.24219 -0.02853]
21Feb16_204900| [-1.05085 -2.30259 -0.16276]
21Feb16_204900| [ 0.71087  0.14900  1.13430]
21Feb16_204900| [-2.45877 -1.20999 -1.04986]
21Feb16_204900| [-1.00480  1.36344 -0.13998]
21Feb16_204900| [ 1.83140 -0.91532  0.07616]
21Feb16_204900| [-0.60404 -2.05184  0.76948]
21Feb16_204900| [ 0.52617  0.76042 -1.76746]
21Feb16_204900| [-0.22134  0.17324  0.99530]
21Feb16_204900| [-0.36427  1.34655  0.02110]
21Feb16_204900| [-0.93125 -0.33620 -0.25012]
21Feb16_204900| [-2.76428  0.14487  0.48096]
21Feb16_204900| [-0.10518  0.35052  1.71840]
21Feb16_204900| [-1.27998  1.12568  1.26523]
21Feb16_204900| [-0.60698  1.53230 -0.60824]
21Feb16_204900| [ 0.02898  2.98718 -0.59153]
21Feb16_204900| [ 0.17588 -0.00449  0.50797]
21Feb16_204900| [-1.42674 -0.54967 -0.21310]
21Feb16_204900| [ 1.03196  1.18733  0.36755]
21Feb16_204900| [ 1.04748 -1.47444 -0.08469]
21Feb16_204900| [ 0.49410  0.38745  0.68469]
21Feb16_204900| [-0.62880  0.73245  0.19964]]
21Feb16_204900|-- Bias --
21Feb16_204900|[-0.18798  0.64571 -0.23142]
21Feb16_204900|Layer 1:
21Feb16_204900|-- Config --
21Feb16_204900|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204900|-- Weights --
21Feb16_204900|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb16_204900| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb16_204900| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb16_204900|-- Bias --
21Feb16_204900|[0.60477 0.03773 0.26452 0.12222]
21Feb16_204900|Layer 2:
21Feb16_204900|-- Config --
21Feb16_204900|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204900|-- Weights --
21Feb16_204900|[[ 0.67920  0.12119]
21Feb16_204900| [ 0.44836  0.02916]
21Feb16_204900| [ 0.68939  0.31516]
21Feb16_204900| [-0.58995 -0.05861]]
21Feb16_204900|-- Bias --
21Feb16_204900|[ 0.59649 -0.08079]
21Feb16_204900|Layer 3:
21Feb16_204900|-- Config --
21Feb16_204900|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204900|-- Weights --
21Feb16_204900|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb16_204900| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb16_204900|-- Bias --
21Feb16_204900|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb16_204900|Layer 4:
21Feb16_204900|-- Config --
21Feb16_204900|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204900|-- Weights --
21Feb16_204900|[[-0.03514 -1.04833]
21Feb16_204900| [ 1.25238  0.62094]
21Feb16_204900| [ 0.99203  0.37406]
21Feb16_204900| [ 0.49902  0.67158]
21Feb16_204900| [-1.35709  0.38335]]
21Feb16_204900|-- Bias --
21Feb16_204900|[0.31435 0.36299]
21Feb16_204900|Predicting the validation and test data with the Best final individual.
21Feb16_204908| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb16_204908|-----------  ------------------  --------------------  ----------
21Feb16_204908|Validation         21.57                  56            0.82113
21Feb16_204908|   Test            31.19                  56            0.83333
21Feb16_204908|-------------------- Test #5 --------------------
21Feb16_204908|Best final individual weights
21Feb16_204908|Individual:
21Feb16_204908|-- Constant hidden layers --
21Feb16_204908|False
21Feb16_204908|Layer 0:
21Feb16_204908|-- Config --
21Feb16_204908|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204908|-- Weights --
21Feb16_204908|[[-0.73212  1.32861  0.10200]
21Feb16_204908| [ 1.48746 -2.97273 -0.42944]
21Feb16_204908| [ 0.53095 -1.50623  0.79224]
21Feb16_204908| [-1.07292 -0.83175 -0.90105]
21Feb16_204908| [-0.48696 -0.89325  0.27226]
21Feb16_204908| [-3.02511  0.34155 -0.03837]
21Feb16_204908| [-0.76747  0.57140 -0.46892]
21Feb16_204908| [-0.07581  0.14713  0.85910]
21Feb16_204908| [-1.37488  0.52170 -0.36205]
21Feb16_204908| [ 1.60981 -0.08727 -0.11267]
21Feb16_204908| [ 0.50986  1.58916 -0.35287]
21Feb16_204908| [-0.34599  1.27113 -0.16393]
21Feb16_204908| [ 1.29203  1.19467  0.37695]
21Feb16_204908| [ 0.58704  0.06328 -0.24240]
21Feb16_204908| [-0.93888 -0.89760  0.57087]
21Feb16_204908| [ 0.99159 -0.66387  0.35177]
21Feb16_204908| [-0.67119  1.06910 -0.12512]
21Feb16_204908| [-0.91534  1.23744 -0.40465]
21Feb16_204908| [ 1.39278  0.08069  0.23328]
21Feb16_204908| [ 0.09880  0.57603 -0.96101]
21Feb16_204908| [ 0.01621 -0.13343 -0.27624]
21Feb16_204908| [-1.28286 -2.28909  0.37931]
21Feb16_204908| [-0.28370  0.09336  0.01547]
21Feb16_204908| [-0.51894  1.84280 -0.25906]
21Feb16_204908| [-0.83075 -0.04508  0.12107]
21Feb16_204908| [ 0.37343  1.18436 -0.07358]
21Feb16_204908| [-2.38657 -0.35191  0.01962]
21Feb16_204908| [ 0.95757 -0.91760 -0.08971]
21Feb16_204908| [ 0.38792 -0.01880  0.69717]
21Feb16_204908| [ 1.66877 -0.58078 -1.21129]
21Feb16_204908| [-0.50943  0.59080  0.30856]
21Feb16_204908| [ 0.30163  1.11518  0.98185]
21Feb16_204908| [-0.73226  0.32281 -0.66712]
21Feb16_204908| [-0.62054 -2.21049  1.40981]
21Feb16_204908| [ 1.23185 -0.58090  0.35844]
21Feb16_204908| [-0.05616  0.24219 -0.02853]
21Feb16_204908| [-1.05085 -2.30259 -0.16276]
21Feb16_204908| [ 0.71087  0.14900  1.13430]
21Feb16_204908| [-2.45877 -1.20999 -1.04986]
21Feb16_204908| [-1.00480  1.36344 -0.13998]
21Feb16_204908| [ 1.83140 -0.91532  0.07616]
21Feb16_204908| [-0.60404 -2.05184  0.76948]
21Feb16_204908| [ 0.52617  0.76042 -1.76746]
21Feb16_204908| [-0.22134  0.17324  0.99530]
21Feb16_204908| [-0.36427  1.34655  0.02110]
21Feb16_204908| [-0.93125 -0.33620 -0.25012]
21Feb16_204908| [-2.76428  0.14487  0.48096]
21Feb16_204908| [-0.10518  0.35052  1.71840]
21Feb16_204908| [-1.27998  1.12568  1.26523]
21Feb16_204908| [-0.60698  1.53230 -0.60824]
21Feb16_204908| [ 0.02898  2.98718 -0.59153]
21Feb16_204908| [ 0.17588 -0.00449  0.50797]
21Feb16_204908| [-1.42674 -0.54967 -0.21310]
21Feb16_204908| [ 1.03196  1.18733  0.36755]
21Feb16_204908| [ 1.04748 -1.47444 -0.08469]
21Feb16_204908| [ 0.49410  0.38745  0.68469]
21Feb16_204908| [-0.62880  0.73245  0.19964]]
21Feb16_204908|-- Bias --
21Feb16_204908|[-0.18798  0.64571 -0.23142]
21Feb16_204908|Layer 1:
21Feb16_204908|-- Config --
21Feb16_204908|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204908|-- Weights --
21Feb16_204908|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb16_204908| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb16_204908| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb16_204908|-- Bias --
21Feb16_204908|[0.60477 0.03773 0.26452 0.12222]
21Feb16_204908|Layer 2:
21Feb16_204908|-- Config --
21Feb16_204908|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204908|-- Weights --
21Feb16_204908|[[ 0.67920  0.12119]
21Feb16_204908| [ 0.44836  0.02916]
21Feb16_204908| [ 0.68939  0.31516]
21Feb16_204908| [-0.58995 -0.05861]]
21Feb16_204908|-- Bias --
21Feb16_204908|[ 0.59649 -0.08079]
21Feb16_204908|Layer 3:
21Feb16_204908|-- Config --
21Feb16_204908|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204908|-- Weights --
21Feb16_204908|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb16_204908| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb16_204908|-- Bias --
21Feb16_204908|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb16_204908|Layer 4:
21Feb16_204908|-- Config --
21Feb16_204908|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204908|-- Weights --
21Feb16_204908|[[-0.03514 -1.04833]
21Feb16_204908| [ 1.25238  0.62094]
21Feb16_204908| [ 0.99203  0.37406]
21Feb16_204908| [ 0.49902  0.67158]
21Feb16_204908| [-1.35709  0.38335]]
21Feb16_204908|-- Bias --
21Feb16_204908|[0.31435 0.36299]
21Feb16_204908|Predicting the validation and test data with the Best final individual.
21Feb16_204915| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb16_204915|-----------  ------------------  --------------------  ----------
21Feb16_204916|Validation         23.22                  56            0.86009
21Feb16_204916|   Test            26.15                  56            0.85097
21Feb16_204916|-------------------- Test #6 --------------------
21Feb16_204916|Best final individual weights
21Feb16_204916|Individual:
21Feb16_204916|-- Constant hidden layers --
21Feb16_204916|False
21Feb16_204916|Layer 0:
21Feb16_204916|-- Config --
21Feb16_204916|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204916|-- Weights --
21Feb16_204916|[[-0.73212  1.32861  0.10200]
21Feb16_204916| [ 1.48746 -2.97273 -0.42944]
21Feb16_204916| [ 0.53095 -1.50623  0.79224]
21Feb16_204916| [-1.07292 -0.83175 -0.90105]
21Feb16_204916| [-0.48696 -0.89325  0.27226]
21Feb16_204916| [-3.02511  0.34155 -0.03837]
21Feb16_204916| [-0.76747  0.57140 -0.46892]
21Feb16_204916| [-0.07581  0.14713  0.85910]
21Feb16_204916| [-1.37488  0.52170 -0.36205]
21Feb16_204916| [ 1.60981 -0.08727 -0.11267]
21Feb16_204916| [ 0.50986  1.58916 -0.35287]
21Feb16_204916| [-0.34599  1.27113 -0.16393]
21Feb16_204916| [ 1.29203  1.19467  0.37695]
21Feb16_204916| [ 0.58704  0.06328 -0.24240]
21Feb16_204916| [-0.93888 -0.89760  0.57087]
21Feb16_204916| [ 0.99159 -0.66387  0.35177]
21Feb16_204916| [-0.67119  1.06910 -0.12512]
21Feb16_204916| [-0.91534  1.23744 -0.40465]
21Feb16_204916| [ 1.39278  0.08069  0.23328]
21Feb16_204916| [ 0.09880  0.57603 -0.96101]
21Feb16_204916| [ 0.01621 -0.13343 -0.27624]
21Feb16_204916| [-1.28286 -2.28909  0.37931]
21Feb16_204916| [-0.28370  0.09336  0.01547]
21Feb16_204916| [-0.51894  1.84280 -0.25906]
21Feb16_204916| [-0.83075 -0.04508  0.12107]
21Feb16_204916| [ 0.37343  1.18436 -0.07358]
21Feb16_204916| [-2.38657 -0.35191  0.01962]
21Feb16_204916| [ 0.95757 -0.91760 -0.08971]
21Feb16_204916| [ 0.38792 -0.01880  0.69717]
21Feb16_204916| [ 1.66877 -0.58078 -1.21129]
21Feb16_204916| [-0.50943  0.59080  0.30856]
21Feb16_204916| [ 0.30163  1.11518  0.98185]
21Feb16_204916| [-0.73226  0.32281 -0.66712]
21Feb16_204916| [-0.62054 -2.21049  1.40981]
21Feb16_204916| [ 1.23185 -0.58090  0.35844]
21Feb16_204916| [-0.05616  0.24219 -0.02853]
21Feb16_204916| [-1.05085 -2.30259 -0.16276]
21Feb16_204916| [ 0.71087  0.14900  1.13430]
21Feb16_204916| [-2.45877 -1.20999 -1.04986]
21Feb16_204916| [-1.00480  1.36344 -0.13998]
21Feb16_204916| [ 1.83140 -0.91532  0.07616]
21Feb16_204916| [-0.60404 -2.05184  0.76948]
21Feb16_204916| [ 0.52617  0.76042 -1.76746]
21Feb16_204916| [-0.22134  0.17324  0.99530]
21Feb16_204916| [-0.36427  1.34655  0.02110]
21Feb16_204916| [-0.93125 -0.33620 -0.25012]
21Feb16_204916| [-2.76428  0.14487  0.48096]
21Feb16_204916| [-0.10518  0.35052  1.71840]
21Feb16_204916| [-1.27998  1.12568  1.26523]
21Feb16_204916| [-0.60698  1.53230 -0.60824]
21Feb16_204916| [ 0.02898  2.98718 -0.59153]
21Feb16_204916| [ 0.17588 -0.00449  0.50797]
21Feb16_204916| [-1.42674 -0.54967 -0.21310]
21Feb16_204916| [ 1.03196  1.18733  0.36755]
21Feb16_204916| [ 1.04748 -1.47444 -0.08469]
21Feb16_204916| [ 0.49410  0.38745  0.68469]
21Feb16_204916| [-0.62880  0.73245  0.19964]]
21Feb16_204916|-- Bias --
21Feb16_204916|[-0.18798  0.64571 -0.23142]
21Feb16_204916|Layer 1:
21Feb16_204916|-- Config --
21Feb16_204916|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204916|-- Weights --
21Feb16_204916|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb16_204916| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb16_204916| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb16_204916|-- Bias --
21Feb16_204916|[0.60477 0.03773 0.26452 0.12222]
21Feb16_204916|Layer 2:
21Feb16_204916|-- Config --
21Feb16_204916|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204916|-- Weights --
21Feb16_204916|[[ 0.67920  0.12119]
21Feb16_204916| [ 0.44836  0.02916]
21Feb16_204916| [ 0.68939  0.31516]
21Feb16_204916| [-0.58995 -0.05861]]
21Feb16_204916|-- Bias --
21Feb16_204916|[ 0.59649 -0.08079]
21Feb16_204916|Layer 3:
21Feb16_204916|-- Config --
21Feb16_204916|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204916|-- Weights --
21Feb16_204916|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb16_204916| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb16_204916|-- Bias --
21Feb16_204916|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb16_204916|Layer 4:
21Feb16_204916|-- Config --
21Feb16_204916|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204916|-- Weights --
21Feb16_204916|[[-0.03514 -1.04833]
21Feb16_204916| [ 1.25238  0.62094]
21Feb16_204916| [ 0.99203  0.37406]
21Feb16_204916| [ 0.49902  0.67158]
21Feb16_204916| [-1.35709  0.38335]]
21Feb16_204916|-- Bias --
21Feb16_204916|[0.31435 0.36299]
21Feb16_204916|Predicting the validation and test data with the Best final individual.
21Feb16_204923| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb16_204923|-----------  ------------------  --------------------  ----------
21Feb16_204923|Validation         22.78                  56            0.83496
21Feb16_204923|   Test            21.11                  56            0.79855
21Feb16_204923|-------------------- Test #7 --------------------
21Feb16_204923|Best final individual weights
21Feb16_204923|Individual:
21Feb16_204923|-- Constant hidden layers --
21Feb16_204923|False
21Feb16_204923|Layer 0:
21Feb16_204923|-- Config --
21Feb16_204923|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204923|-- Weights --
21Feb16_204923|[[-0.73212  1.32861  0.10200]
21Feb16_204923| [ 1.48746 -2.97273 -0.42944]
21Feb16_204923| [ 0.53095 -1.50623  0.79224]
21Feb16_204923| [-1.07292 -0.83175 -0.90105]
21Feb16_204923| [-0.48696 -0.89325  0.27226]
21Feb16_204923| [-3.02511  0.34155 -0.03837]
21Feb16_204923| [-0.76747  0.57140 -0.46892]
21Feb16_204923| [-0.07581  0.14713  0.85910]
21Feb16_204923| [-1.37488  0.52170 -0.36205]
21Feb16_204923| [ 1.60981 -0.08727 -0.11267]
21Feb16_204923| [ 0.50986  1.58916 -0.35287]
21Feb16_204923| [-0.34599  1.27113 -0.16393]
21Feb16_204923| [ 1.29203  1.19467  0.37695]
21Feb16_204923| [ 0.58704  0.06328 -0.24240]
21Feb16_204923| [-0.93888 -0.89760  0.57087]
21Feb16_204923| [ 0.99159 -0.66387  0.35177]
21Feb16_204923| [-0.67119  1.06910 -0.12512]
21Feb16_204923| [-0.91534  1.23744 -0.40465]
21Feb16_204923| [ 1.39278  0.08069  0.23328]
21Feb16_204923| [ 0.09880  0.57603 -0.96101]
21Feb16_204923| [ 0.01621 -0.13343 -0.27624]
21Feb16_204923| [-1.28286 -2.28909  0.37931]
21Feb16_204923| [-0.28370  0.09336  0.01547]
21Feb16_204923| [-0.51894  1.84280 -0.25906]
21Feb16_204923| [-0.83075 -0.04508  0.12107]
21Feb16_204923| [ 0.37343  1.18436 -0.07358]
21Feb16_204923| [-2.38657 -0.35191  0.01962]
21Feb16_204923| [ 0.95757 -0.91760 -0.08971]
21Feb16_204923| [ 0.38792 -0.01880  0.69717]
21Feb16_204923| [ 1.66877 -0.58078 -1.21129]
21Feb16_204923| [-0.50943  0.59080  0.30856]
21Feb16_204923| [ 0.30163  1.11518  0.98185]
21Feb16_204923| [-0.73226  0.32281 -0.66712]
21Feb16_204923| [-0.62054 -2.21049  1.40981]
21Feb16_204923| [ 1.23185 -0.58090  0.35844]
21Feb16_204923| [-0.05616  0.24219 -0.02853]
21Feb16_204923| [-1.05085 -2.30259 -0.16276]
21Feb16_204923| [ 0.71087  0.14900  1.13430]
21Feb16_204923| [-2.45877 -1.20999 -1.04986]
21Feb16_204923| [-1.00480  1.36344 -0.13998]
21Feb16_204923| [ 1.83140 -0.91532  0.07616]
21Feb16_204923| [-0.60404 -2.05184  0.76948]
21Feb16_204923| [ 0.52617  0.76042 -1.76746]
21Feb16_204923| [-0.22134  0.17324  0.99530]
21Feb16_204923| [-0.36427  1.34655  0.02110]
21Feb16_204923| [-0.93125 -0.33620 -0.25012]
21Feb16_204923| [-2.76428  0.14487  0.48096]
21Feb16_204923| [-0.10518  0.35052  1.71840]
21Feb16_204923| [-1.27998  1.12568  1.26523]
21Feb16_204923| [-0.60698  1.53230 -0.60824]
21Feb16_204923| [ 0.02898  2.98718 -0.59153]
21Feb16_204923| [ 0.17588 -0.00449  0.50797]
21Feb16_204923| [-1.42674 -0.54967 -0.21310]
21Feb16_204923| [ 1.03196  1.18733  0.36755]
21Feb16_204923| [ 1.04748 -1.47444 -0.08469]
21Feb16_204923| [ 0.49410  0.38745  0.68469]
21Feb16_204923| [-0.62880  0.73245  0.19964]]
21Feb16_204923|-- Bias --
21Feb16_204923|[-0.18798  0.64571 -0.23142]
21Feb16_204923|Layer 1:
21Feb16_204923|-- Config --
21Feb16_204923|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204923|-- Weights --
21Feb16_204923|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb16_204923| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb16_204923| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb16_204923|-- Bias --
21Feb16_204923|[0.60477 0.03773 0.26452 0.12222]
21Feb16_204923|Layer 2:
21Feb16_204923|-- Config --
21Feb16_204923|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204923|-- Weights --
21Feb16_204923|[[ 0.67920  0.12119]
21Feb16_204923| [ 0.44836  0.02916]
21Feb16_204923| [ 0.68939  0.31516]
21Feb16_204923| [-0.58995 -0.05861]]
21Feb16_204923|-- Bias --
21Feb16_204923|[ 0.59649 -0.08079]
21Feb16_204923|Layer 3:
21Feb16_204923|-- Config --
21Feb16_204923|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204923|-- Weights --
21Feb16_204923|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb16_204923| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb16_204923|-- Bias --
21Feb16_204923|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb16_204923|Layer 4:
21Feb16_204923|-- Config --
21Feb16_204923|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204923|-- Weights --
21Feb16_204923|[[-0.03514 -1.04833]
21Feb16_204923| [ 1.25238  0.62094]
21Feb16_204923| [ 0.99203  0.37406]
21Feb16_204923| [ 0.49902  0.67158]
21Feb16_204923| [-1.35709  0.38335]]
21Feb16_204923|-- Bias --
21Feb16_204923|[0.31435 0.36299]
21Feb16_204923|Predicting the validation and test data with the Best final individual.
21Feb16_204931| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb16_204931|-----------  ------------------  --------------------  ----------
21Feb16_204931|Validation         28.96                  56            0.48780
21Feb16_204931|   Test            25.46                  56            0.49431
21Feb16_204931|-------------------- Test #8 --------------------
21Feb16_204931|Best final individual weights
21Feb16_204931|Individual:
21Feb16_204931|-- Constant hidden layers --
21Feb16_204931|False
21Feb16_204931|Layer 0:
21Feb16_204931|-- Config --
21Feb16_204931|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204931|-- Weights --
21Feb16_204931|[[-0.73212  1.32861  0.10200]
21Feb16_204931| [ 1.48746 -2.97273 -0.42944]
21Feb16_204931| [ 0.53095 -1.50623  0.79224]
21Feb16_204931| [-1.07292 -0.83175 -0.90105]
21Feb16_204931| [-0.48696 -0.89325  0.27226]
21Feb16_204931| [-3.02511  0.34155 -0.03837]
21Feb16_204931| [-0.76747  0.57140 -0.46892]
21Feb16_204931| [-0.07581  0.14713  0.85910]
21Feb16_204931| [-1.37488  0.52170 -0.36205]
21Feb16_204931| [ 1.60981 -0.08727 -0.11267]
21Feb16_204931| [ 0.50986  1.58916 -0.35287]
21Feb16_204931| [-0.34599  1.27113 -0.16393]
21Feb16_204931| [ 1.29203  1.19467  0.37695]
21Feb16_204931| [ 0.58704  0.06328 -0.24240]
21Feb16_204931| [-0.93888 -0.89760  0.57087]
21Feb16_204931| [ 0.99159 -0.66387  0.35177]
21Feb16_204931| [-0.67119  1.06910 -0.12512]
21Feb16_204931| [-0.91534  1.23744 -0.40465]
21Feb16_204931| [ 1.39278  0.08069  0.23328]
21Feb16_204931| [ 0.09880  0.57603 -0.96101]
21Feb16_204931| [ 0.01621 -0.13343 -0.27624]
21Feb16_204931| [-1.28286 -2.28909  0.37931]
21Feb16_204931| [-0.28370  0.09336  0.01547]
21Feb16_204931| [-0.51894  1.84280 -0.25906]
21Feb16_204931| [-0.83075 -0.04508  0.12107]
21Feb16_204931| [ 0.37343  1.18436 -0.07358]
21Feb16_204931| [-2.38657 -0.35191  0.01962]
21Feb16_204931| [ 0.95757 -0.91760 -0.08971]
21Feb16_204931| [ 0.38792 -0.01880  0.69717]
21Feb16_204931| [ 1.66877 -0.58078 -1.21129]
21Feb16_204931| [-0.50943  0.59080  0.30856]
21Feb16_204931| [ 0.30163  1.11518  0.98185]
21Feb16_204931| [-0.73226  0.32281 -0.66712]
21Feb16_204931| [-0.62054 -2.21049  1.40981]
21Feb16_204931| [ 1.23185 -0.58090  0.35844]
21Feb16_204931| [-0.05616  0.24219 -0.02853]
21Feb16_204931| [-1.05085 -2.30259 -0.16276]
21Feb16_204931| [ 0.71087  0.14900  1.13430]
21Feb16_204931| [-2.45877 -1.20999 -1.04986]
21Feb16_204931| [-1.00480  1.36344 -0.13998]
21Feb16_204931| [ 1.83140 -0.91532  0.07616]
21Feb16_204931| [-0.60404 -2.05184  0.76948]
21Feb16_204931| [ 0.52617  0.76042 -1.76746]
21Feb16_204931| [-0.22134  0.17324  0.99530]
21Feb16_204931| [-0.36427  1.34655  0.02110]
21Feb16_204931| [-0.93125 -0.33620 -0.25012]
21Feb16_204931| [-2.76428  0.14487  0.48096]
21Feb16_204931| [-0.10518  0.35052  1.71840]
21Feb16_204931| [-1.27998  1.12568  1.26523]
21Feb16_204931| [-0.60698  1.53230 -0.60824]
21Feb16_204931| [ 0.02898  2.98718 -0.59153]
21Feb16_204931| [ 0.17588 -0.00449  0.50797]
21Feb16_204931| [-1.42674 -0.54967 -0.21310]
21Feb16_204931| [ 1.03196  1.18733  0.36755]
21Feb16_204931| [ 1.04748 -1.47444 -0.08469]
21Feb16_204931| [ 0.49410  0.38745  0.68469]
21Feb16_204931| [-0.62880  0.73245  0.19964]]
21Feb16_204931|-- Bias --
21Feb16_204931|[-0.18798  0.64571 -0.23142]
21Feb16_204931|Layer 1:
21Feb16_204931|-- Config --
21Feb16_204931|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204931|-- Weights --
21Feb16_204931|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb16_204931| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb16_204931| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb16_204931|-- Bias --
21Feb16_204931|[0.60477 0.03773 0.26452 0.12222]
21Feb16_204931|Layer 2:
21Feb16_204931|-- Config --
21Feb16_204931|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204931|-- Weights --
21Feb16_204931|[[ 0.67920  0.12119]
21Feb16_204931| [ 0.44836  0.02916]
21Feb16_204931| [ 0.68939  0.31516]
21Feb16_204931| [-0.58995 -0.05861]]
21Feb16_204931|-- Bias --
21Feb16_204931|[ 0.59649 -0.08079]
21Feb16_204931|Layer 3:
21Feb16_204931|-- Config --
21Feb16_204931|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204931|-- Weights --
21Feb16_204931|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb16_204931| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb16_204931|-- Bias --
21Feb16_204931|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb16_204931|Layer 4:
21Feb16_204931|-- Config --
21Feb16_204931|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204931|-- Weights --
21Feb16_204931|[[-0.03514 -1.04833]
21Feb16_204931| [ 1.25238  0.62094]
21Feb16_204931| [ 0.99203  0.37406]
21Feb16_204931| [ 0.49902  0.67158]
21Feb16_204931| [-1.35709  0.38335]]
21Feb16_204931|-- Bias --
21Feb16_204931|[0.31435 0.36299]
21Feb16_204931|Predicting the validation and test data with the Best final individual.
21Feb16_204939| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb16_204939|-----------  ------------------  --------------------  ----------
21Feb16_204939|Validation         21.30                  56            0.82476
21Feb16_204939|   Test            21.81                  56            0.83186
21Feb16_204939|-------------------- Test #9 --------------------
21Feb16_204939|Best final individual weights
21Feb16_204939|Individual:
21Feb16_204939|-- Constant hidden layers --
21Feb16_204939|False
21Feb16_204939|Layer 0:
21Feb16_204939|-- Config --
21Feb16_204939|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204939|-- Weights --
21Feb16_204939|[[-0.73212  1.32861  0.10200]
21Feb16_204939| [ 1.48746 -2.97273 -0.42944]
21Feb16_204939| [ 0.53095 -1.50623  0.79224]
21Feb16_204939| [-1.07292 -0.83175 -0.90105]
21Feb16_204939| [-0.48696 -0.89325  0.27226]
21Feb16_204939| [-3.02511  0.34155 -0.03837]
21Feb16_204939| [-0.76747  0.57140 -0.46892]
21Feb16_204939| [-0.07581  0.14713  0.85910]
21Feb16_204939| [-1.37488  0.52170 -0.36205]
21Feb16_204939| [ 1.60981 -0.08727 -0.11267]
21Feb16_204939| [ 0.50986  1.58916 -0.35287]
21Feb16_204939| [-0.34599  1.27113 -0.16393]
21Feb16_204939| [ 1.29203  1.19467  0.37695]
21Feb16_204939| [ 0.58704  0.06328 -0.24240]
21Feb16_204939| [-0.93888 -0.89760  0.57087]
21Feb16_204939| [ 0.99159 -0.66387  0.35177]
21Feb16_204939| [-0.67119  1.06910 -0.12512]
21Feb16_204939| [-0.91534  1.23744 -0.40465]
21Feb16_204939| [ 1.39278  0.08069  0.23328]
21Feb16_204939| [ 0.09880  0.57603 -0.96101]
21Feb16_204939| [ 0.01621 -0.13343 -0.27624]
21Feb16_204939| [-1.28286 -2.28909  0.37931]
21Feb16_204939| [-0.28370  0.09336  0.01547]
21Feb16_204939| [-0.51894  1.84280 -0.25906]
21Feb16_204939| [-0.83075 -0.04508  0.12107]
21Feb16_204939| [ 0.37343  1.18436 -0.07358]
21Feb16_204939| [-2.38657 -0.35191  0.01962]
21Feb16_204939| [ 0.95757 -0.91760 -0.08971]
21Feb16_204939| [ 0.38792 -0.01880  0.69717]
21Feb16_204939| [ 1.66877 -0.58078 -1.21129]
21Feb16_204939| [-0.50943  0.59080  0.30856]
21Feb16_204939| [ 0.30163  1.11518  0.98185]
21Feb16_204939| [-0.73226  0.32281 -0.66712]
21Feb16_204939| [-0.62054 -2.21049  1.40981]
21Feb16_204939| [ 1.23185 -0.58090  0.35844]
21Feb16_204939| [-0.05616  0.24219 -0.02853]
21Feb16_204939| [-1.05085 -2.30259 -0.16276]
21Feb16_204939| [ 0.71087  0.14900  1.13430]
21Feb16_204939| [-2.45877 -1.20999 -1.04986]
21Feb16_204939| [-1.00480  1.36344 -0.13998]
21Feb16_204939| [ 1.83140 -0.91532  0.07616]
21Feb16_204939| [-0.60404 -2.05184  0.76948]
21Feb16_204939| [ 0.52617  0.76042 -1.76746]
21Feb16_204939| [-0.22134  0.17324  0.99530]
21Feb16_204939| [-0.36427  1.34655  0.02110]
21Feb16_204939| [-0.93125 -0.33620 -0.25012]
21Feb16_204939| [-2.76428  0.14487  0.48096]
21Feb16_204939| [-0.10518  0.35052  1.71840]
21Feb16_204939| [-1.27998  1.12568  1.26523]
21Feb16_204939| [-0.60698  1.53230 -0.60824]
21Feb16_204939| [ 0.02898  2.98718 -0.59153]
21Feb16_204939| [ 0.17588 -0.00449  0.50797]
21Feb16_204939| [-1.42674 -0.54967 -0.21310]
21Feb16_204939| [ 1.03196  1.18733  0.36755]
21Feb16_204939| [ 1.04748 -1.47444 -0.08469]
21Feb16_204939| [ 0.49410  0.38745  0.68469]
21Feb16_204939| [-0.62880  0.73245  0.19964]]
21Feb16_204939|-- Bias --
21Feb16_204939|[-0.18798  0.64571 -0.23142]
21Feb16_204939|Layer 1:
21Feb16_204939|-- Config --
21Feb16_204939|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204939|-- Weights --
21Feb16_204939|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb16_204939| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb16_204939| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb16_204939|-- Bias --
21Feb16_204939|[0.60477 0.03773 0.26452 0.12222]
21Feb16_204939|Layer 2:
21Feb16_204939|-- Config --
21Feb16_204939|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204939|-- Weights --
21Feb16_204939|[[ 0.67920  0.12119]
21Feb16_204939| [ 0.44836  0.02916]
21Feb16_204939| [ 0.68939  0.31516]
21Feb16_204939| [-0.58995 -0.05861]]
21Feb16_204939|-- Bias --
21Feb16_204939|[ 0.59649 -0.08079]
21Feb16_204939|Layer 3:
21Feb16_204939|-- Config --
21Feb16_204939|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204939|-- Weights --
21Feb16_204939|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb16_204939| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb16_204939|-- Bias --
21Feb16_204939|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb16_204939|Layer 4:
21Feb16_204939|-- Config --
21Feb16_204939|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204939|-- Weights --
21Feb16_204939|[[-0.03514 -1.04833]
21Feb16_204939| [ 1.25238  0.62094]
21Feb16_204939| [ 0.99203  0.37406]
21Feb16_204939| [ 0.49902  0.67158]
21Feb16_204939| [-1.35709  0.38335]]
21Feb16_204939|-- Bias --
21Feb16_204939|[0.31435 0.36299]
21Feb16_204939|Predicting the validation and test data with the Best final individual.
21Feb16_204947| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb16_204947|-----------  ------------------  --------------------  ----------
21Feb16_204947|Validation         26.43                  56            0.71922
21Feb16_204947|   Test            29.54                  56            0.67444
21Feb16_204947|-------------------- Test #10 --------------------
21Feb16_204947|Best final individual weights
21Feb16_204947|Individual:
21Feb16_204947|-- Constant hidden layers --
21Feb16_204947|False
21Feb16_204947|Layer 0:
21Feb16_204947|-- Config --
21Feb16_204947|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204947|-- Weights --
21Feb16_204947|[[-0.73212  1.32861  0.10200]
21Feb16_204947| [ 1.48746 -2.97273 -0.42944]
21Feb16_204947| [ 0.53095 -1.50623  0.79224]
21Feb16_204947| [-1.07292 -0.83175 -0.90105]
21Feb16_204947| [-0.48696 -0.89325  0.27226]
21Feb16_204947| [-3.02511  0.34155 -0.03837]
21Feb16_204947| [-0.76747  0.57140 -0.46892]
21Feb16_204947| [-0.07581  0.14713  0.85910]
21Feb16_204947| [-1.37488  0.52170 -0.36205]
21Feb16_204947| [ 1.60981 -0.08727 -0.11267]
21Feb16_204947| [ 0.50986  1.58916 -0.35287]
21Feb16_204947| [-0.34599  1.27113 -0.16393]
21Feb16_204947| [ 1.29203  1.19467  0.37695]
21Feb16_204947| [ 0.58704  0.06328 -0.24240]
21Feb16_204947| [-0.93888 -0.89760  0.57087]
21Feb16_204947| [ 0.99159 -0.66387  0.35177]
21Feb16_204947| [-0.67119  1.06910 -0.12512]
21Feb16_204947| [-0.91534  1.23744 -0.40465]
21Feb16_204947| [ 1.39278  0.08069  0.23328]
21Feb16_204947| [ 0.09880  0.57603 -0.96101]
21Feb16_204947| [ 0.01621 -0.13343 -0.27624]
21Feb16_204947| [-1.28286 -2.28909  0.37931]
21Feb16_204947| [-0.28370  0.09336  0.01547]
21Feb16_204947| [-0.51894  1.84280 -0.25906]
21Feb16_204947| [-0.83075 -0.04508  0.12107]
21Feb16_204947| [ 0.37343  1.18436 -0.07358]
21Feb16_204947| [-2.38657 -0.35191  0.01962]
21Feb16_204947| [ 0.95757 -0.91760 -0.08971]
21Feb16_204947| [ 0.38792 -0.01880  0.69717]
21Feb16_204947| [ 1.66877 -0.58078 -1.21129]
21Feb16_204947| [-0.50943  0.59080  0.30856]
21Feb16_204947| [ 0.30163  1.11518  0.98185]
21Feb16_204947| [-0.73226  0.32281 -0.66712]
21Feb16_204947| [-0.62054 -2.21049  1.40981]
21Feb16_204947| [ 1.23185 -0.58090  0.35844]
21Feb16_204947| [-0.05616  0.24219 -0.02853]
21Feb16_204947| [-1.05085 -2.30259 -0.16276]
21Feb16_204947| [ 0.71087  0.14900  1.13430]
21Feb16_204947| [-2.45877 -1.20999 -1.04986]
21Feb16_204947| [-1.00480  1.36344 -0.13998]
21Feb16_204947| [ 1.83140 -0.91532  0.07616]
21Feb16_204947| [-0.60404 -2.05184  0.76948]
21Feb16_204947| [ 0.52617  0.76042 -1.76746]
21Feb16_204947| [-0.22134  0.17324  0.99530]
21Feb16_204947| [-0.36427  1.34655  0.02110]
21Feb16_204947| [-0.93125 -0.33620 -0.25012]
21Feb16_204947| [-2.76428  0.14487  0.48096]
21Feb16_204947| [-0.10518  0.35052  1.71840]
21Feb16_204947| [-1.27998  1.12568  1.26523]
21Feb16_204947| [-0.60698  1.53230 -0.60824]
21Feb16_204947| [ 0.02898  2.98718 -0.59153]
21Feb16_204947| [ 0.17588 -0.00449  0.50797]
21Feb16_204947| [-1.42674 -0.54967 -0.21310]
21Feb16_204947| [ 1.03196  1.18733  0.36755]
21Feb16_204947| [ 1.04748 -1.47444 -0.08469]
21Feb16_204947| [ 0.49410  0.38745  0.68469]
21Feb16_204947| [-0.62880  0.73245  0.19964]]
21Feb16_204947|-- Bias --
21Feb16_204947|[-0.18798  0.64571 -0.23142]
21Feb16_204947|Layer 1:
21Feb16_204947|-- Config --
21Feb16_204947|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204947|-- Weights --
21Feb16_204947|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb16_204947| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb16_204947| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb16_204947|-- Bias --
21Feb16_204947|[0.60477 0.03773 0.26452 0.12222]
21Feb16_204947|Layer 2:
21Feb16_204947|-- Config --
21Feb16_204947|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204947|-- Weights --
21Feb16_204947|[[ 0.67920  0.12119]
21Feb16_204947| [ 0.44836  0.02916]
21Feb16_204947| [ 0.68939  0.31516]
21Feb16_204947| [-0.58995 -0.05861]]
21Feb16_204947|-- Bias --
21Feb16_204947|[ 0.59649 -0.08079]
21Feb16_204947|Layer 3:
21Feb16_204947|-- Config --
21Feb16_204947|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204947|-- Weights --
21Feb16_204947|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb16_204947| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb16_204947|-- Bias --
21Feb16_204947|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb16_204947|Layer 4:
21Feb16_204947|-- Config --
21Feb16_204947|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204947|-- Weights --
21Feb16_204947|[[-0.03514 -1.04833]
21Feb16_204947| [ 1.25238  0.62094]
21Feb16_204947| [ 0.99203  0.37406]
21Feb16_204947| [ 0.49902  0.67158]
21Feb16_204947| [-1.35709  0.38335]]
21Feb16_204947|-- Bias --
21Feb16_204947|[0.31435 0.36299]
21Feb16_204947|Predicting the validation and test data with the Best final individual.
21Feb16_204955| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb16_204955|-----------  ------------------  --------------------  ----------
21Feb16_204955|Validation         23.65                  56            0.85845
21Feb16_204955|   Test            26.67                  56            0.71298
21Feb16_204955|-------------------- Test #11 --------------------
21Feb16_204955|Best final individual weights
21Feb16_204955|Individual:
21Feb16_204955|-- Constant hidden layers --
21Feb16_204955|False
21Feb16_204955|Layer 0:
21Feb16_204955|-- Config --
21Feb16_204955|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204955|-- Weights --
21Feb16_204955|[[-0.73212  1.32861  0.10200]
21Feb16_204955| [ 1.48746 -2.97273 -0.42944]
21Feb16_204955| [ 0.53095 -1.50623  0.79224]
21Feb16_204955| [-1.07292 -0.83175 -0.90105]
21Feb16_204955| [-0.48696 -0.89325  0.27226]
21Feb16_204955| [-3.02511  0.34155 -0.03837]
21Feb16_204955| [-0.76747  0.57140 -0.46892]
21Feb16_204955| [-0.07581  0.14713  0.85910]
21Feb16_204955| [-1.37488  0.52170 -0.36205]
21Feb16_204955| [ 1.60981 -0.08727 -0.11267]
21Feb16_204955| [ 0.50986  1.58916 -0.35287]
21Feb16_204955| [-0.34599  1.27113 -0.16393]
21Feb16_204955| [ 1.29203  1.19467  0.37695]
21Feb16_204955| [ 0.58704  0.06328 -0.24240]
21Feb16_204955| [-0.93888 -0.89760  0.57087]
21Feb16_204955| [ 0.99159 -0.66387  0.35177]
21Feb16_204955| [-0.67119  1.06910 -0.12512]
21Feb16_204955| [-0.91534  1.23744 -0.40465]
21Feb16_204955| [ 1.39278  0.08069  0.23328]
21Feb16_204955| [ 0.09880  0.57603 -0.96101]
21Feb16_204955| [ 0.01621 -0.13343 -0.27624]
21Feb16_204955| [-1.28286 -2.28909  0.37931]
21Feb16_204955| [-0.28370  0.09336  0.01547]
21Feb16_204955| [-0.51894  1.84280 -0.25906]
21Feb16_204955| [-0.83075 -0.04508  0.12107]
21Feb16_204955| [ 0.37343  1.18436 -0.07358]
21Feb16_204955| [-2.38657 -0.35191  0.01962]
21Feb16_204955| [ 0.95757 -0.91760 -0.08971]
21Feb16_204955| [ 0.38792 -0.01880  0.69717]
21Feb16_204955| [ 1.66877 -0.58078 -1.21129]
21Feb16_204955| [-0.50943  0.59080  0.30856]
21Feb16_204955| [ 0.30163  1.11518  0.98185]
21Feb16_204955| [-0.73226  0.32281 -0.66712]
21Feb16_204955| [-0.62054 -2.21049  1.40981]
21Feb16_204955| [ 1.23185 -0.58090  0.35844]
21Feb16_204955| [-0.05616  0.24219 -0.02853]
21Feb16_204955| [-1.05085 -2.30259 -0.16276]
21Feb16_204955| [ 0.71087  0.14900  1.13430]
21Feb16_204955| [-2.45877 -1.20999 -1.04986]
21Feb16_204955| [-1.00480  1.36344 -0.13998]
21Feb16_204955| [ 1.83140 -0.91532  0.07616]
21Feb16_204955| [-0.60404 -2.05184  0.76948]
21Feb16_204955| [ 0.52617  0.76042 -1.76746]
21Feb16_204955| [-0.22134  0.17324  0.99530]
21Feb16_204955| [-0.36427  1.34655  0.02110]
21Feb16_204955| [-0.93125 -0.33620 -0.25012]
21Feb16_204955| [-2.76428  0.14487  0.48096]
21Feb16_204955| [-0.10518  0.35052  1.71840]
21Feb16_204955| [-1.27998  1.12568  1.26523]
21Feb16_204955| [-0.60698  1.53230 -0.60824]
21Feb16_204955| [ 0.02898  2.98718 -0.59153]
21Feb16_204955| [ 0.17588 -0.00449  0.50797]
21Feb16_204955| [-1.42674 -0.54967 -0.21310]
21Feb16_204955| [ 1.03196  1.18733  0.36755]
21Feb16_204955| [ 1.04748 -1.47444 -0.08469]
21Feb16_204955| [ 0.49410  0.38745  0.68469]
21Feb16_204955| [-0.62880  0.73245  0.19964]]
21Feb16_204955|-- Bias --
21Feb16_204955|[-0.18798  0.64571 -0.23142]
21Feb16_204955|Layer 1:
21Feb16_204955|-- Config --
21Feb16_204955|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204955|-- Weights --
21Feb16_204955|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb16_204955| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb16_204955| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb16_204955|-- Bias --
21Feb16_204955|[0.60477 0.03773 0.26452 0.12222]
21Feb16_204955|Layer 2:
21Feb16_204955|-- Config --
21Feb16_204955|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204955|-- Weights --
21Feb16_204955|[[ 0.67920  0.12119]
21Feb16_204955| [ 0.44836  0.02916]
21Feb16_204955| [ 0.68939  0.31516]
21Feb16_204955| [-0.58995 -0.05861]]
21Feb16_204955|-- Bias --
21Feb16_204955|[ 0.59649 -0.08079]
21Feb16_204955|Layer 3:
21Feb16_204955|-- Config --
21Feb16_204955|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204955|-- Weights --
21Feb16_204955|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb16_204955| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb16_204955|-- Bias --
21Feb16_204955|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb16_204955|Layer 4:
21Feb16_204955|-- Config --
21Feb16_204955|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_204955|-- Weights --
21Feb16_204955|[[-0.03514 -1.04833]
21Feb16_204955| [ 1.25238  0.62094]
21Feb16_204955| [ 0.99203  0.37406]
21Feb16_204955| [ 0.49902  0.67158]
21Feb16_204955| [-1.35709  0.38335]]
21Feb16_204955|-- Bias --
21Feb16_204955|[0.31435 0.36299]
21Feb16_204955|Predicting the validation and test data with the Best final individual.
21Feb16_205002| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb16_205002|-----------  ------------------  --------------------  ----------
21Feb16_205002|Validation         23.48                  56            0.78306
21Feb16_205002|   Test            22.07                  56            0.85403
21Feb16_205002|-------------------- Test #12 --------------------
21Feb16_205002|Best final individual weights
21Feb16_205002|Individual:
21Feb16_205002|-- Constant hidden layers --
21Feb16_205002|False
21Feb16_205002|Layer 0:
21Feb16_205002|-- Config --
21Feb16_205002|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_205002|-- Weights --
21Feb16_205002|[[-0.73212  1.32861  0.10200]
21Feb16_205002| [ 1.48746 -2.97273 -0.42944]
21Feb16_205002| [ 0.53095 -1.50623  0.79224]
21Feb16_205002| [-1.07292 -0.83175 -0.90105]
21Feb16_205002| [-0.48696 -0.89325  0.27226]
21Feb16_205002| [-3.02511  0.34155 -0.03837]
21Feb16_205002| [-0.76747  0.57140 -0.46892]
21Feb16_205002| [-0.07581  0.14713  0.85910]
21Feb16_205002| [-1.37488  0.52170 -0.36205]
21Feb16_205002| [ 1.60981 -0.08727 -0.11267]
21Feb16_205002| [ 0.50986  1.58916 -0.35287]
21Feb16_205002| [-0.34599  1.27113 -0.16393]
21Feb16_205002| [ 1.29203  1.19467  0.37695]
21Feb16_205002| [ 0.58704  0.06328 -0.24240]
21Feb16_205002| [-0.93888 -0.89760  0.57087]
21Feb16_205002| [ 0.99159 -0.66387  0.35177]
21Feb16_205002| [-0.67119  1.06910 -0.12512]
21Feb16_205002| [-0.91534  1.23744 -0.40465]
21Feb16_205002| [ 1.39278  0.08069  0.23328]
21Feb16_205002| [ 0.09880  0.57603 -0.96101]
21Feb16_205002| [ 0.01621 -0.13343 -0.27624]
21Feb16_205002| [-1.28286 -2.28909  0.37931]
21Feb16_205002| [-0.28370  0.09336  0.01547]
21Feb16_205002| [-0.51894  1.84280 -0.25906]
21Feb16_205002| [-0.83075 -0.04508  0.12107]
21Feb16_205002| [ 0.37343  1.18436 -0.07358]
21Feb16_205002| [-2.38657 -0.35191  0.01962]
21Feb16_205002| [ 0.95757 -0.91760 -0.08971]
21Feb16_205002| [ 0.38792 -0.01880  0.69717]
21Feb16_205002| [ 1.66877 -0.58078 -1.21129]
21Feb16_205002| [-0.50943  0.59080  0.30856]
21Feb16_205002| [ 0.30163  1.11518  0.98185]
21Feb16_205002| [-0.73226  0.32281 -0.66712]
21Feb16_205002| [-0.62054 -2.21049  1.40981]
21Feb16_205002| [ 1.23185 -0.58090  0.35844]
21Feb16_205002| [-0.05616  0.24219 -0.02853]
21Feb16_205002| [-1.05085 -2.30259 -0.16276]
21Feb16_205002| [ 0.71087  0.14900  1.13430]
21Feb16_205002| [-2.45877 -1.20999 -1.04986]
21Feb16_205002| [-1.00480  1.36344 -0.13998]
21Feb16_205002| [ 1.83140 -0.91532  0.07616]
21Feb16_205002| [-0.60404 -2.05184  0.76948]
21Feb16_205002| [ 0.52617  0.76042 -1.76746]
21Feb16_205002| [-0.22134  0.17324  0.99530]
21Feb16_205002| [-0.36427  1.34655  0.02110]
21Feb16_205002| [-0.93125 -0.33620 -0.25012]
21Feb16_205002| [-2.76428  0.14487  0.48096]
21Feb16_205002| [-0.10518  0.35052  1.71840]
21Feb16_205002| [-1.27998  1.12568  1.26523]
21Feb16_205002| [-0.60698  1.53230 -0.60824]
21Feb16_205002| [ 0.02898  2.98718 -0.59153]
21Feb16_205002| [ 0.17588 -0.00449  0.50797]
21Feb16_205002| [-1.42674 -0.54967 -0.21310]
21Feb16_205002| [ 1.03196  1.18733  0.36755]
21Feb16_205002| [ 1.04748 -1.47444 -0.08469]
21Feb16_205002| [ 0.49410  0.38745  0.68469]
21Feb16_205002| [-0.62880  0.73245  0.19964]]
21Feb16_205002|-- Bias --
21Feb16_205002|[-0.18798  0.64571 -0.23142]
21Feb16_205002|Layer 1:
21Feb16_205002|-- Config --
21Feb16_205002|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_205002|-- Weights --
21Feb16_205002|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb16_205002| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb16_205002| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb16_205002|-- Bias --
21Feb16_205002|[0.60477 0.03773 0.26452 0.12222]
21Feb16_205002|Layer 2:
21Feb16_205002|-- Config --
21Feb16_205002|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_205002|-- Weights --
21Feb16_205002|[[ 0.67920  0.12119]
21Feb16_205002| [ 0.44836  0.02916]
21Feb16_205002| [ 0.68939  0.31516]
21Feb16_205002| [-0.58995 -0.05861]]
21Feb16_205002|-- Bias --
21Feb16_205002|[ 0.59649 -0.08079]
21Feb16_205002|Layer 3:
21Feb16_205002|-- Config --
21Feb16_205002|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_205002|-- Weights --
21Feb16_205002|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb16_205002| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb16_205002|-- Bias --
21Feb16_205002|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb16_205002|Layer 4:
21Feb16_205002|-- Config --
21Feb16_205002|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_205002|-- Weights --
21Feb16_205002|[[-0.03514 -1.04833]
21Feb16_205002| [ 1.25238  0.62094]
21Feb16_205002| [ 0.99203  0.37406]
21Feb16_205002| [ 0.49902  0.67158]
21Feb16_205002| [-1.35709  0.38335]]
21Feb16_205002|-- Bias --
21Feb16_205002|[0.31435 0.36299]
21Feb16_205002|Predicting the validation and test data with the Best final individual.
21Feb16_205010| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb16_205010|-----------  ------------------  --------------------  ----------
21Feb16_205010|Validation         24.43                  56            0.85301
21Feb16_205010|   Test            37.01                  56            0.82036
21Feb16_205010|-------------------- Test #13 --------------------
21Feb16_205010|Best final individual weights
21Feb16_205010|Individual:
21Feb16_205010|-- Constant hidden layers --
21Feb16_205010|False
21Feb16_205010|Layer 0:
21Feb16_205010|-- Config --
21Feb16_205010|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_205010|-- Weights --
21Feb16_205010|[[-0.73212  1.32861  0.10200]
21Feb16_205010| [ 1.48746 -2.97273 -0.42944]
21Feb16_205010| [ 0.53095 -1.50623  0.79224]
21Feb16_205010| [-1.07292 -0.83175 -0.90105]
21Feb16_205010| [-0.48696 -0.89325  0.27226]
21Feb16_205010| [-3.02511  0.34155 -0.03837]
21Feb16_205010| [-0.76747  0.57140 -0.46892]
21Feb16_205010| [-0.07581  0.14713  0.85910]
21Feb16_205010| [-1.37488  0.52170 -0.36205]
21Feb16_205010| [ 1.60981 -0.08727 -0.11267]
21Feb16_205010| [ 0.50986  1.58916 -0.35287]
21Feb16_205010| [-0.34599  1.27113 -0.16393]
21Feb16_205010| [ 1.29203  1.19467  0.37695]
21Feb16_205010| [ 0.58704  0.06328 -0.24240]
21Feb16_205010| [-0.93888 -0.89760  0.57087]
21Feb16_205010| [ 0.99159 -0.66387  0.35177]
21Feb16_205010| [-0.67119  1.06910 -0.12512]
21Feb16_205010| [-0.91534  1.23744 -0.40465]
21Feb16_205010| [ 1.39278  0.08069  0.23328]
21Feb16_205010| [ 0.09880  0.57603 -0.96101]
21Feb16_205010| [ 0.01621 -0.13343 -0.27624]
21Feb16_205010| [-1.28286 -2.28909  0.37931]
21Feb16_205010| [-0.28370  0.09336  0.01547]
21Feb16_205010| [-0.51894  1.84280 -0.25906]
21Feb16_205010| [-0.83075 -0.04508  0.12107]
21Feb16_205010| [ 0.37343  1.18436 -0.07358]
21Feb16_205010| [-2.38657 -0.35191  0.01962]
21Feb16_205010| [ 0.95757 -0.91760 -0.08971]
21Feb16_205010| [ 0.38792 -0.01880  0.69717]
21Feb16_205010| [ 1.66877 -0.58078 -1.21129]
21Feb16_205010| [-0.50943  0.59080  0.30856]
21Feb16_205010| [ 0.30163  1.11518  0.98185]
21Feb16_205010| [-0.73226  0.32281 -0.66712]
21Feb16_205010| [-0.62054 -2.21049  1.40981]
21Feb16_205010| [ 1.23185 -0.58090  0.35844]
21Feb16_205010| [-0.05616  0.24219 -0.02853]
21Feb16_205010| [-1.05085 -2.30259 -0.16276]
21Feb16_205010| [ 0.71087  0.14900  1.13430]
21Feb16_205010| [-2.45877 -1.20999 -1.04986]
21Feb16_205010| [-1.00480  1.36344 -0.13998]
21Feb16_205010| [ 1.83140 -0.91532  0.07616]
21Feb16_205010| [-0.60404 -2.05184  0.76948]
21Feb16_205010| [ 0.52617  0.76042 -1.76746]
21Feb16_205010| [-0.22134  0.17324  0.99530]
21Feb16_205010| [-0.36427  1.34655  0.02110]
21Feb16_205010| [-0.93125 -0.33620 -0.25012]
21Feb16_205010| [-2.76428  0.14487  0.48096]
21Feb16_205010| [-0.10518  0.35052  1.71840]
21Feb16_205010| [-1.27998  1.12568  1.26523]
21Feb16_205010| [-0.60698  1.53230 -0.60824]
21Feb16_205010| [ 0.02898  2.98718 -0.59153]
21Feb16_205010| [ 0.17588 -0.00449  0.50797]
21Feb16_205010| [-1.42674 -0.54967 -0.21310]
21Feb16_205010| [ 1.03196  1.18733  0.36755]
21Feb16_205010| [ 1.04748 -1.47444 -0.08469]
21Feb16_205010| [ 0.49410  0.38745  0.68469]
21Feb16_205010| [-0.62880  0.73245  0.19964]]
21Feb16_205010|-- Bias --
21Feb16_205010|[-0.18798  0.64571 -0.23142]
21Feb16_205010|Layer 1:
21Feb16_205010|-- Config --
21Feb16_205010|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_205010|-- Weights --
21Feb16_205010|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb16_205010| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb16_205010| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb16_205010|-- Bias --
21Feb16_205010|[0.60477 0.03773 0.26452 0.12222]
21Feb16_205010|Layer 2:
21Feb16_205010|-- Config --
21Feb16_205010|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_205010|-- Weights --
21Feb16_205010|[[ 0.67920  0.12119]
21Feb16_205010| [ 0.44836  0.02916]
21Feb16_205010| [ 0.68939  0.31516]
21Feb16_205010| [-0.58995 -0.05861]]
21Feb16_205010|-- Bias --
21Feb16_205010|[ 0.59649 -0.08079]
21Feb16_205010|Layer 3:
21Feb16_205010|-- Config --
21Feb16_205010|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_205010|-- Weights --
21Feb16_205010|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb16_205010| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb16_205010|-- Bias --
21Feb16_205010|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb16_205010|Layer 4:
21Feb16_205010|-- Config --
21Feb16_205010|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_205010|-- Weights --
21Feb16_205010|[[-0.03514 -1.04833]
21Feb16_205010| [ 1.25238  0.62094]
21Feb16_205010| [ 0.99203  0.37406]
21Feb16_205010| [ 0.49902  0.67158]
21Feb16_205010| [-1.35709  0.38335]]
21Feb16_205010|-- Bias --
21Feb16_205010|[0.31435 0.36299]
21Feb16_205010|Predicting the validation and test data with the Best final individual.
21Feb16_205018| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb16_205018|-----------  ------------------  --------------------  ----------
21Feb16_205018|Validation         21.74                  56            0.74120
21Feb16_205018|   Test            25.80                  56            0.72926
21Feb16_205018|-------------------- Test #14 --------------------
21Feb16_205018|Best final individual weights
21Feb16_205018|Individual:
21Feb16_205018|-- Constant hidden layers --
21Feb16_205018|False
21Feb16_205018|Layer 0:
21Feb16_205018|-- Config --
21Feb16_205018|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_205018|-- Weights --
21Feb16_205018|[[-0.73212  1.32861  0.10200]
21Feb16_205018| [ 1.48746 -2.97273 -0.42944]
21Feb16_205018| [ 0.53095 -1.50623  0.79224]
21Feb16_205018| [-1.07292 -0.83175 -0.90105]
21Feb16_205018| [-0.48696 -0.89325  0.27226]
21Feb16_205018| [-3.02511  0.34155 -0.03837]
21Feb16_205018| [-0.76747  0.57140 -0.46892]
21Feb16_205018| [-0.07581  0.14713  0.85910]
21Feb16_205018| [-1.37488  0.52170 -0.36205]
21Feb16_205018| [ 1.60981 -0.08727 -0.11267]
21Feb16_205018| [ 0.50986  1.58916 -0.35287]
21Feb16_205018| [-0.34599  1.27113 -0.16393]
21Feb16_205018| [ 1.29203  1.19467  0.37695]
21Feb16_205018| [ 0.58704  0.06328 -0.24240]
21Feb16_205018| [-0.93888 -0.89760  0.57087]
21Feb16_205018| [ 0.99159 -0.66387  0.35177]
21Feb16_205018| [-0.67119  1.06910 -0.12512]
21Feb16_205018| [-0.91534  1.23744 -0.40465]
21Feb16_205018| [ 1.39278  0.08069  0.23328]
21Feb16_205018| [ 0.09880  0.57603 -0.96101]
21Feb16_205018| [ 0.01621 -0.13343 -0.27624]
21Feb16_205018| [-1.28286 -2.28909  0.37931]
21Feb16_205018| [-0.28370  0.09336  0.01547]
21Feb16_205018| [-0.51894  1.84280 -0.25906]
21Feb16_205018| [-0.83075 -0.04508  0.12107]
21Feb16_205018| [ 0.37343  1.18436 -0.07358]
21Feb16_205018| [-2.38657 -0.35191  0.01962]
21Feb16_205018| [ 0.95757 -0.91760 -0.08971]
21Feb16_205018| [ 0.38792 -0.01880  0.69717]
21Feb16_205018| [ 1.66877 -0.58078 -1.21129]
21Feb16_205018| [-0.50943  0.59080  0.30856]
21Feb16_205018| [ 0.30163  1.11518  0.98185]
21Feb16_205018| [-0.73226  0.32281 -0.66712]
21Feb16_205018| [-0.62054 -2.21049  1.40981]
21Feb16_205018| [ 1.23185 -0.58090  0.35844]
21Feb16_205018| [-0.05616  0.24219 -0.02853]
21Feb16_205018| [-1.05085 -2.30259 -0.16276]
21Feb16_205018| [ 0.71087  0.14900  1.13430]
21Feb16_205018| [-2.45877 -1.20999 -1.04986]
21Feb16_205018| [-1.00480  1.36344 -0.13998]
21Feb16_205018| [ 1.83140 -0.91532  0.07616]
21Feb16_205018| [-0.60404 -2.05184  0.76948]
21Feb16_205018| [ 0.52617  0.76042 -1.76746]
21Feb16_205018| [-0.22134  0.17324  0.99530]
21Feb16_205018| [-0.36427  1.34655  0.02110]
21Feb16_205018| [-0.93125 -0.33620 -0.25012]
21Feb16_205018| [-2.76428  0.14487  0.48096]
21Feb16_205018| [-0.10518  0.35052  1.71840]
21Feb16_205018| [-1.27998  1.12568  1.26523]
21Feb16_205018| [-0.60698  1.53230 -0.60824]
21Feb16_205018| [ 0.02898  2.98718 -0.59153]
21Feb16_205018| [ 0.17588 -0.00449  0.50797]
21Feb16_205018| [-1.42674 -0.54967 -0.21310]
21Feb16_205018| [ 1.03196  1.18733  0.36755]
21Feb16_205018| [ 1.04748 -1.47444 -0.08469]
21Feb16_205018| [ 0.49410  0.38745  0.68469]
21Feb16_205018| [-0.62880  0.73245  0.19964]]
21Feb16_205018|-- Bias --
21Feb16_205018|[-0.18798  0.64571 -0.23142]
21Feb16_205018|Layer 1:
21Feb16_205018|-- Config --
21Feb16_205018|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_205018|-- Weights --
21Feb16_205018|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb16_205018| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb16_205018| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb16_205018|-- Bias --
21Feb16_205018|[0.60477 0.03773 0.26452 0.12222]
21Feb16_205018|Layer 2:
21Feb16_205018|-- Config --
21Feb16_205018|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_205018|-- Weights --
21Feb16_205018|[[ 0.67920  0.12119]
21Feb16_205018| [ 0.44836  0.02916]
21Feb16_205018| [ 0.68939  0.31516]
21Feb16_205018| [-0.58995 -0.05861]]
21Feb16_205018|-- Bias --
21Feb16_205018|[ 0.59649 -0.08079]
21Feb16_205018|Layer 3:
21Feb16_205018|-- Config --
21Feb16_205018|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_205018|-- Weights --
21Feb16_205018|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb16_205018| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb16_205018|-- Bias --
21Feb16_205018|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb16_205018|Layer 4:
21Feb16_205018|-- Config --
21Feb16_205018|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_205018|-- Weights --
21Feb16_205018|[[-0.03514 -1.04833]
21Feb16_205018| [ 1.25238  0.62094]
21Feb16_205018| [ 0.99203  0.37406]
21Feb16_205018| [ 0.49902  0.67158]
21Feb16_205018| [-1.35709  0.38335]]
21Feb16_205018|-- Bias --
21Feb16_205018|[0.31435 0.36299]
21Feb16_205018|Predicting the validation and test data with the Best final individual.
21Feb16_205026| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb16_205026|-----------  ------------------  --------------------  ----------
21Feb16_205026|Validation         22.70                  56            0.74363
21Feb16_205026|   Test            19.46                  56            0.73101
Using Theano backend.
WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.
2021-02-16 20:50:29.298727: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-02-16 20:50:29.298785: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
21Feb16_205030|Data summary: Train
21Feb16_205030|data.shape = (2300, 57)
21Feb16_205030|labels.shape = (2300,)
21Feb16_205030|Class distribution:
21Feb16_205030|	0 - 1389 (0.60)
21Feb16_205030|	1 - 911 (0.40)
21Feb16_205030|Data summary: Validation
21Feb16_205030|data.shape = (1150, 57)
21Feb16_205030|labels.shape = (1150,)
21Feb16_205030|Class distribution:
21Feb16_205030|	0 - 667 (0.58)
21Feb16_205030|	1 - 483 (0.42)
21Feb16_205030|Data summary: Test
21Feb16_205030|data.shape = (1151, 57)
21Feb16_205030|labels.shape = (1151,)
21Feb16_205030|Class distribution:
21Feb16_205030|	0 - 732 (0.64)
21Feb16_205030|	1 - 419 (0.36)
21Feb16_205030|Selected configuration values
21Feb16_205030|-- Dataset name: spambase2
21Feb16_205030|-- Initial population size: 64
21Feb16_205030|-- Maximun number of generations: 32
21Feb16_205030|-- Neurons per hidden layer range: (2, 20)
21Feb16_205030|-- Hidden layers number range: (1, 3)
21Feb16_205030|-- Crossover probability: 0.5
21Feb16_205030|-- Bias gene mutation probability: 0.2
21Feb16_205030|-- Weights gene mutation probability: 0.75
21Feb16_205030|-- Neuron mutation probability: 0.3
21Feb16_205030|-- Layer mutation probability: 0.3
21Feb16_205030|-- Constant hidden layers: False
21Feb16_205030|-- Seed: 31415
21Feb16_205030|Entering GA
21Feb16_205030|Start the algorithm
21Feb16_205412|-- Generation 1 --
21Feb16_205412|    -- Crossed 0 individual pairs.
21Feb16_205412|    -- Mutated 32 individuals.
21Feb16_205733|    -- Evaluated 64 individuals.
21Feb16_205733|    Summary of generation 1:
21Feb16_205733| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_205733|-----------  ------------------  --------------------  ----------
21Feb16_205733|    Max            42.70                78.00           0.43478
21Feb16_205733|    Avg            41.90                26.28           0.00941
21Feb16_205733|    Min            35.91                 2.00           0.00000
21Feb16_205733|    Std             0.81                18.75           0.05509
21Feb16_205733|   Best            35.91                18.00           0.43478
21Feb16_205733|-- Generation 2 --
21Feb16_205733|    -- Crossed 1 individual pairs.
21Feb16_205733|    -- Mutated 32 individuals.
21Feb16_210049|    -- Evaluated 64 individuals.
21Feb16_210049|    Summary of generation 2:
21Feb16_210049| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_210049|-----------  ------------------  --------------------  ----------
21Feb16_210049|    Max            58.00                84.00           0.79977
21Feb16_210049|    Avg            41.99                15.92           0.02879
21Feb16_210049|    Min            29.65                 2.00           0.00000
21Feb16_210049|    Std             2.55                13.60           0.13781
21Feb16_210049|   Best            29.65                18.00           0.79977
21Feb16_210049|-- Generation 3 --
21Feb16_210049|    -- Crossed 3 individual pairs.
21Feb16_210049|    -- Mutated 32 individuals.
21Feb16_210401|    -- Evaluated 64 individuals.
21Feb16_210401|    Summary of generation 3:
21Feb16_210401| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_210401|-----------  ------------------  --------------------  ----------
21Feb16_210401|    Max            58.00                50.00           0.78358
21Feb16_210401|    Avg            41.97                13.73           0.02564
21Feb16_210401|    Min            26.09                 2.00           0.00000
21Feb16_210401|    Std             2.83                12.88           0.13211
21Feb16_210401|   Best            26.09                18.00           0.73476
21Feb16_210401|-- Generation 4 --
21Feb16_210401|    -- Crossed 4 individual pairs.
21Feb16_210401|    -- Mutated 32 individuals.
21Feb16_210707|    -- Evaluated 64 individuals.
21Feb16_210707|    Summary of generation 4:
21Feb16_210707| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_210707|-----------  ------------------  --------------------  ----------
21Feb16_210707|    Max            42.17                63.00           0.00517
21Feb16_210707|    Avg            42.01                 8.34           0.00085
21Feb16_210707|    Min            41.91                 2.00           0.00000
21Feb16_210707|    Std             0.06                 9.60           0.00165
21Feb16_210707|   Best            41.91                 4.00           0.00517
21Feb16_210707|-- Generation 5 --
21Feb16_210707|    -- Crossed 6 individual pairs.
21Feb16_210707|    -- Mutated 32 individuals.
21Feb16_211013|    -- Evaluated 64 individuals.
21Feb16_211013|    Summary of generation 5:
21Feb16_211013| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_211013|-----------  ------------------  --------------------  ----------
21Feb16_211013|    Max            42.09                20.00           0.05344
21Feb16_211013|    Avg            41.98                 5.28           0.00172
21Feb16_211013|    Min            41.22                 2.00           0.00000
21Feb16_211013|    Std             0.11                 4.46           0.00681
21Feb16_211013|   Best            41.22                14.00           0.05344
21Feb16_211013|-- Generation 6 --
21Feb16_211013|    -- Crossed 7 individual pairs.
21Feb16_211013|    -- Mutated 32 individuals.
21Feb16_211323|    -- Evaluated 64 individuals.
21Feb16_211323|    Summary of generation 6:
21Feb16_211323| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_211323|-----------  ------------------  --------------------  ----------
21Feb16_211323|    Max            42.26                18.00           0.01548
21Feb16_211323|    Avg            41.99                 6.00           0.00105
21Feb16_211323|    Min            41.48                 2.00           0.00000
21Feb16_211323|    Std             0.09                 4.81           0.00231
21Feb16_211323|   Best            41.48                 3.00           0.01548
21Feb16_211323|-- Generation 7 --
21Feb16_211323|    -- Crossed 9 individual pairs.
21Feb16_211323|    -- Mutated 32 individuals.
21Feb16_211633|    -- Evaluated 64 individuals.
21Feb16_211633|    Summary of generation 7:
21Feb16_211633| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_211633|-----------  ------------------  --------------------  ----------
21Feb16_211633|    Max            42.09                36.00           0.01033
21Feb16_211633|    Avg            41.99                 5.98           0.00089
21Feb16_211633|    Min            41.65                 2.00           0.00000
21Feb16_211633|    Std             0.06                 6.14           0.00184
21Feb16_211633|   Best            41.65                 3.00           0.01033
21Feb16_211633|-- Generation 8 --
21Feb16_211633|    -- Crossed 9 individual pairs.
21Feb16_211633|    -- Mutated 32 individuals.
21Feb16_211942|    -- Evaluated 64 individuals.
21Feb16_211942|    Summary of generation 8:
21Feb16_211942| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_211942|-----------  ------------------  --------------------  ----------
21Feb16_211942|    Max            42.17                18.00           0.04103
21Feb16_211942|    Avg            41.97                 5.09           0.00169
21Feb16_211942|    Min            40.78                 2.00           0.00000
21Feb16_211942|    Std             0.16                 4.37           0.00529
21Feb16_211942|   Best            40.78                12.00           0.04103
21Feb16_211942|-- Generation 9 --
21Feb16_211942|    -- Crossed 8 individual pairs.
21Feb16_211942|    -- Mutated 32 individuals.
21Feb16_212253|    -- Evaluated 64 individuals.
21Feb16_212253|    Summary of generation 9:
21Feb16_212253| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_212253|-----------  ------------------  --------------------  ----------
21Feb16_212253|    Max            48.87                18.00           0.80667
21Feb16_212253|    Avg            41.71                 6.17           0.03823
21Feb16_212253|    Min            30.61                 2.00           0.00000
21Feb16_212253|    Std             2.17                 5.04           0.16210
21Feb16_212253|   Best            30.61                 8.00           0.78607
21Feb16_212253|-- Generation 10 --
21Feb16_212253|    -- Crossed 5 individual pairs.
21Feb16_212253|    -- Mutated 32 individuals.
21Feb16_212603|    -- Evaluated 64 individuals.
21Feb16_212603|    Summary of generation 10:
21Feb16_212603| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_212603|-----------  ------------------  --------------------  ----------
21Feb16_212603|    Max            42.26                18.00           0.58344
21Feb16_212603|    Avg            41.43                 6.23           0.02714
21Feb16_212603|    Min            27.74                 2.00           0.00000
21Feb16_212603|    Std             2.43                 4.89           0.10887
21Feb16_212603|   Best            27.74                18.00           0.51616
21Feb16_212603|-- Generation 11 --
21Feb16_212603|    -- Crossed 8 individual pairs.
21Feb16_212603|    -- Mutated 32 individuals.
21Feb16_212916|    -- Evaluated 64 individuals.
21Feb16_212916|    Summary of generation 11:
21Feb16_212916| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_212916|-----------  ------------------  --------------------  ----------
21Feb16_212916|    Max            58.00                34.00           0.78358
21Feb16_212916|    Avg            41.87                 7.95           0.03476
21Feb16_212916|    Min            28.00                 2.00           0.00000
21Feb16_212916|    Std             2.88                 6.49           0.14854
21Feb16_212916|   Best            28.00                 8.00           0.52079
21Feb16_212916|-- Generation 12 --
21Feb16_212916|    -- Crossed 3 individual pairs.
21Feb16_212916|    -- Mutated 32 individuals.
21Feb16_213227|    -- Evaluated 64 individuals.
21Feb16_213227|    Summary of generation 12:
21Feb16_213227| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_213227|-----------  ------------------  --------------------  ----------
21Feb16_213227|    Max            42.35                36.00           0.67494
21Feb16_213227|    Avg            41.46                 7.03           0.02217
21Feb16_213227|    Min            24.96                 2.00           0.00000
21Feb16_213227|    Std             2.67                 5.88           0.11025
21Feb16_213227|   Best            24.96                18.00           0.67494
21Feb16_213227|-- Generation 13 --
21Feb16_213227|    -- Crossed 5 individual pairs.
21Feb16_213227|    -- Mutated 32 individuals.
21Feb16_213539|    -- Evaluated 64 individuals.
21Feb16_213539|    Summary of generation 13:
21Feb16_213539| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_213539|-----------  ------------------  --------------------  ----------
21Feb16_213539|    Max            42.61                36.00           0.61562
21Feb16_213539|    Avg            41.50                 8.56           0.02210
21Feb16_213539|    Min            26.78                 2.00           0.00000
21Feb16_213539|    Std             2.40                 7.93           0.10577
21Feb16_213539|   Best            26.78                18.00           0.61562
21Feb16_213539|-- Generation 14 --
21Feb16_213539|    -- Crossed 7 individual pairs.
21Feb16_213539|    -- Mutated 32 individuals.
21Feb16_213852|    -- Evaluated 64 individuals.
21Feb16_213852|    Summary of generation 14:
21Feb16_213852| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_213852|-----------  ------------------  --------------------  ----------
21Feb16_213852|    Max            42.09                40.00           0.75188
21Feb16_213852|    Avg            41.48                 8.12           0.02679
21Feb16_213852|    Min            27.65                 2.00           0.00000
21Feb16_213852|    Std             2.42                 6.72           0.13015
21Feb16_213852|   Best            27.65                18.00           0.75188
21Feb16_213852|-- Generation 15 --
21Feb16_213852|    -- Crossed 6 individual pairs.
21Feb16_213852|    -- Mutated 32 individuals.
21Feb16_214205|    -- Evaluated 64 individuals.
21Feb16_214205|    Summary of generation 15:
21Feb16_214205| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_214205|-----------  ------------------  --------------------  ----------
21Feb16_214205|    Max            42.09                40.00           0.73387
21Feb16_214205|    Avg            41.42                 7.69           0.02610
21Feb16_214205|    Min            26.35                 2.00           0.00000
21Feb16_214205|    Std             2.71                 6.44           0.12590
21Feb16_214205|   Best            26.35                18.00           0.71951
21Feb16_214205|-- Generation 16 --
21Feb16_214205|    -- Crossed 5 individual pairs.
21Feb16_214205|    -- Mutated 32 individuals.
21Feb16_214517|    -- Evaluated 64 individuals.
21Feb16_214517|    Summary of generation 16:
21Feb16_214517| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_214517|-----------  ------------------  --------------------  ----------
21Feb16_214517|    Max            42.26                44.00           0.82855
21Feb16_214517|    Avg            41.21                 7.83           0.03973
21Feb16_214517|    Min            24.87                 2.00           0.00000
21Feb16_214517|    Std             3.23                 7.99           0.16234
21Feb16_214517|   Best            24.87                21.00           0.68287
21Feb16_214517|-- Generation 17 --
21Feb16_214517|    -- Crossed 8 individual pairs.
21Feb16_214517|    -- Mutated 32 individuals.
21Feb16_214831|    -- Evaluated 64 individuals.
21Feb16_214831|    Summary of generation 17:
21Feb16_214831| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_214831|-----------  ------------------  --------------------  ----------
21Feb16_214831|    Max            42.26                44.00           0.80877
21Feb16_214831|    Avg            40.86                 8.81           0.06413
21Feb16_214831|    Min            25.04                 2.00           0.00000
21Feb16_214831|    Std             3.59                 8.94           0.19340
21Feb16_214831|   Best            25.04                10.00           0.72247
21Feb16_214831|-- Generation 18 --
21Feb16_214831|    -- Crossed 2 individual pairs.
21Feb16_214831|    -- Mutated 32 individuals.
21Feb16_215149|    -- Evaluated 64 individuals.
21Feb16_215149|    Summary of generation 18:
21Feb16_215149| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_215149|-----------  ------------------  --------------------  ----------
21Feb16_215149|    Max            47.04                44.00           0.81211
21Feb16_215149|    Avg            39.55                10.78           0.12108
21Feb16_215149|    Min            24.35                 3.00           0.00000
21Feb16_215149|    Std             5.74                11.16           0.25939
21Feb16_215149|   Best            24.35                44.00           0.72485
21Feb16_215149|-- Generation 19 --
21Feb16_215149|    -- Crossed 7 individual pairs.
21Feb16_215149|    -- Mutated 32 individuals.
21Feb16_215512|    -- Evaluated 64 individuals.
21Feb16_215512|    Summary of generation 19:
21Feb16_215512| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_215512|-----------  ------------------  --------------------  ----------
21Feb16_215512|    Max            42.87                70.00           0.81774
21Feb16_215512|    Avg            39.09                14.53           0.14606
21Feb16_215512|    Min            24.70                 3.00           0.00000
21Feb16_215512|    Std             5.78                15.60           0.27609
21Feb16_215512|   Best            24.70                44.00           0.69102
21Feb16_215512|-- Generation 20 --
21Feb16_215512|    -- Crossed 3 individual pairs.
21Feb16_215512|    -- Mutated 32 individuals.
21Feb16_215840|    -- Evaluated 64 individuals.
21Feb16_215840|    Summary of generation 20:
21Feb16_215840| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_215840|-----------  ------------------  --------------------  ----------
21Feb16_215840|    Max            42.17                60.00           0.79174
21Feb16_215840|    Avg            39.05                15.47           0.15453
21Feb16_215840|    Min            24.09                 3.00           0.00000
21Feb16_215840|    Std             5.60                16.03           0.28335
21Feb16_215840|   Best            24.09                48.00           0.76568
21Feb16_215840|-- Generation 21 --
21Feb16_215840|    -- Crossed 4 individual pairs.
21Feb16_215840|    -- Mutated 32 individuals.
21Feb16_220212|    -- Evaluated 64 individuals.
21Feb16_220212|    Summary of generation 21:
21Feb16_220212| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_220212|-----------  ------------------  --------------------  ----------
21Feb16_220212|    Max            42.17                90.00           0.80579
21Feb16_220212|    Avg            38.34                18.45           0.19938
21Feb16_220212|    Min            23.91                 2.00           0.00000
21Feb16_220212|    Std             5.87                19.09           0.30554
21Feb16_220212|   Best            23.91                48.00           0.71458
21Feb16_220212|-- Generation 22 --
21Feb16_220212|    -- Crossed 2 individual pairs.
21Feb16_220212|    -- Mutated 32 individuals.
21Feb16_220548|    -- Evaluated 64 individuals.
21Feb16_220548|    Summary of generation 22:
21Feb16_220548| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_220548|-----------  ------------------  --------------------  ----------
21Feb16_220548|    Max            42.09                60.00           0.82362
21Feb16_220548|    Avg            36.71                21.28           0.25981
21Feb16_220548|    Min            24.26                 2.00           0.00000
21Feb16_220548|    Std             6.98                18.25           0.33831
21Feb16_220548|   Best            24.26                52.00           0.76087
21Feb16_220548|-- Generation 23 --
21Feb16_220548|    -- Crossed 2 individual pairs.
21Feb16_220548|    -- Mutated 32 individuals.
21Feb16_220935|    -- Evaluated 64 individuals.
21Feb16_220935|    Summary of generation 23:
21Feb16_220935| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_220935|-----------  ------------------  --------------------  ----------
21Feb16_220935|    Max            42.09                96.00           0.78772
21Feb16_220935|    Avg            35.35                29.28           0.32114
21Feb16_220935|    Min            23.39                 2.00           0.00000
21Feb16_220935|    Std             7.15                21.95           0.34435
21Feb16_220935|   Best            23.39                52.00           0.72814
21Feb16_220935|-- Generation 24 --
21Feb16_220935|    -- Crossed 0 individual pairs.
21Feb16_220935|    -- Mutated 32 individuals.
21Feb16_221332|    -- Evaluated 64 individuals.
21Feb16_221332|    Summary of generation 24:
21Feb16_221332| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_221332|-----------  ------------------  --------------------  ----------
21Feb16_221332|    Max            43.30                80.00           0.82075
21Feb16_221332|    Avg            33.81                36.61           0.38588
21Feb16_221332|    Min            23.22                 2.00           0.00000
21Feb16_221332|    Std             7.30                19.72           0.34184
21Feb16_221332|   Best            23.22                52.00           0.73602
21Feb16_221332|-- Generation 25 --
21Feb16_221332|    -- Crossed 3 individual pairs.
21Feb16_221332|    -- Mutated 32 individuals.
21Feb16_221740|    -- Evaluated 64 individuals.
21Feb16_221740|    Summary of generation 25:
21Feb16_221740| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_221740|-----------  ------------------  --------------------  ----------
21Feb16_221740|    Max            51.74                114.00          0.82799
21Feb16_221740|    Avg            33.58                45.08           0.45457
21Feb16_221740|    Min            23.91                 8.00           0.00000
21Feb16_221740|    Std             7.24                19.61           0.35022
21Feb16_221740|   Best            23.91                48.00           0.72048
21Feb16_221740|-- Generation 26 --
21Feb16_221740|    -- Crossed 1 individual pairs.
21Feb16_221740|    -- Mutated 32 individuals.
21Feb16_222149|    -- Evaluated 64 individuals.
21Feb16_222149|    Summary of generation 26:
21Feb16_222149| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_222149|-----------  ------------------  --------------------  ----------
21Feb16_222149|    Max            42.35                108.00          0.84388
21Feb16_222149|    Avg            32.71                48.80           0.44554
21Feb16_222149|    Min            23.30                 2.00           0.00000
21Feb16_222149|    Std             7.16                22.53           0.33996
21Feb16_222149|   Best            23.30                24.00           0.69415
21Feb16_222149|-- Generation 27 --
21Feb16_222149|    -- Crossed 1 individual pairs.
21Feb16_222149|    -- Mutated 32 individuals.
21Feb16_222559|    -- Evaluated 64 individuals.
21Feb16_222559|    Summary of generation 27:
21Feb16_222559| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_222559|-----------  ------------------  --------------------  ----------
21Feb16_222559|    Max            42.26                132.00          0.82552
21Feb16_222559|    Avg            32.16                51.20           0.45948
21Feb16_222559|    Min            21.74                 8.00           0.00000
21Feb16_222559|    Std             7.19                22.48           0.32234
21Feb16_222559|   Best            21.74                18.00           0.76278
21Feb16_222559|-- Generation 28 --
21Feb16_222559|    -- Crossed 0 individual pairs.
21Feb16_222559|    -- Mutated 32 individuals.
21Feb16_223009|    -- Evaluated 64 individuals.
21Feb16_223009|    Summary of generation 28:
21Feb16_223009| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_223009|-----------  ------------------  --------------------  ----------
21Feb16_223009|    Max            42.00                132.00          0.83850
21Feb16_223009|    Avg            31.52                51.11           0.49187
21Feb16_223009|    Min            23.04                12.00           0.00000
21Feb16_223009|    Std             6.86                24.66           0.32040
21Feb16_223009|   Best            23.04                24.00           0.73226
21Feb16_223009|-- Generation 29 --
21Feb16_223009|    -- Crossed 0 individual pairs.
21Feb16_223009|    -- Mutated 32 individuals.
21Feb16_223416|    -- Evaluated 64 individuals.
21Feb16_223416|    Summary of generation 29:
21Feb16_223416| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_223416|-----------  ------------------  --------------------  ----------
21Feb16_223416|    Max            42.09                132.00          0.82871
21Feb16_223416|    Avg            32.10                49.19           0.44677
21Feb16_223416|    Min            22.26                12.00           0.00000
21Feb16_223416|    Std             7.60                23.20           0.33800
21Feb16_223416|   Best            22.26                56.00           0.74227
21Feb16_223416|-- Generation 30 --
21Feb16_223416|    -- Crossed 0 individual pairs.
21Feb16_223416|    -- Mutated 32 individuals.
21Feb16_223824|    -- Evaluated 64 individuals.
21Feb16_223824|    Summary of generation 30:
21Feb16_223824| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_223824|-----------  ------------------  --------------------  ----------
21Feb16_223824|    Max            42.09                100.00          0.82371
21Feb16_223824|    Avg            31.14                49.09           0.49033
21Feb16_223824|    Min            22.00                14.00           0.00000
21Feb16_223824|    Std             7.06                18.85           0.31415
21Feb16_223824|   Best            22.00                56.00           0.78704
21Feb16_223824|-- Generation 31 --
21Feb16_223824|    -- Crossed 1 individual pairs.
21Feb16_223824|    -- Mutated 32 individuals.
21Feb16_224233|    -- Evaluated 64 individuals.
21Feb16_224233|    Summary of generation 31:
21Feb16_224233| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_224233|-----------  ------------------  --------------------  ----------
21Feb16_224233|    Max            42.52                100.00          0.83333
21Feb16_224233|    Avg            32.54                52.38           0.44410
21Feb16_224233|    Min            22.96                 8.00           0.00000
21Feb16_224233|    Std             7.42                21.79           0.34342
21Feb16_224233|   Best            22.96                44.00           0.72671
21Feb16_224233|-- Generation 32 --
21Feb16_224233|    -- Crossed 1 individual pairs.
21Feb16_224233|    -- Mutated 32 individuals.
21Feb16_224643|    -- Evaluated 64 individuals.
21Feb16_224643|    Summary of generation 32:
21Feb16_224643| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_224643|-----------  ------------------  --------------------  ----------
21Feb16_224643|    Max            42.00                85.00           0.83038
21Feb16_224643|    Avg            32.40                52.83           0.43440
21Feb16_224643|    Min            21.57                 8.00           0.00000
21Feb16_224643|    Std             7.70                18.10           0.34013
21Feb16_224643|   Best            21.57                56.00           0.83038
21Feb16_224643|Best initial individual weights
21Feb16_224643|Individual:
21Feb16_224643|-- Constant hidden layers --
21Feb16_224643|False
21Feb16_224643|Layer 0:
21Feb16_224643|-- Config --
21Feb16_224643|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 12, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224643|-- Weights --
21Feb16_224643|[[-3.50529e-01 -6.53069e-03 -7.03730e-01 -6.33906e-01  6.10835e-02
21Feb16_224643|   4.57449e-01 -3.77835e-01  6.38481e-01  4.24141e-01  6.68786e-01
21Feb16_224643|  -4.86511e-01 -9.28542e-01]
21Feb16_224643| [-8.31270e-01 -3.94586e-01  5.51697e-02 -8.86387e-01 -6.99786e-01
21Feb16_224643|   6.44047e-01 -5.40571e-01  3.77503e-01  1.70193e-01  5.92883e-01
21Feb16_224643|   2.06540e-01  2.18639e-01]
21Feb16_224643| [-8.13637e-01  7.25044e-01  6.66092e-01  5.31057e-01 -4.48634e-01
21Feb16_224643|  -1.62601e-01 -1.57458e-02  7.74238e-02 -4.81841e-01  3.55485e-02
21Feb16_224643|  -7.21169e-01  1.05129e-01]
21Feb16_224643| [ 6.07201e-01  6.23643e-01  8.87343e-01  6.04285e-01  5.70453e-02
21Feb16_224643|   5.99381e-01 -3.21663e-03  6.64196e-01 -5.25584e-01 -1.74507e-02
21Feb16_224643|   3.80029e-01 -4.59585e-01]
21Feb16_224643| [-9.00078e-01  8.63133e-01  8.49324e-01  4.34648e-01 -5.67121e-01
21Feb16_224643|   6.24299e-01 -6.46637e-01  9.34620e-01 -5.42838e-01 -4.04257e-01
21Feb16_224643|  -4.70046e-01  4.29712e-01]
21Feb16_224643| [ 9.51731e-02  8.42954e-01 -7.44806e-01 -5.56045e-02 -4.89209e-01
21Feb16_224643|   8.07612e-01  2.77691e-01 -5.77946e-02  4.30356e-01 -9.05718e-01
21Feb16_224643|  -7.61358e-01 -4.56367e-01]
21Feb16_224643| [-9.06447e-01 -4.46566e-01 -4.40669e-01  6.09161e-01 -3.32587e-01
21Feb16_224643|  -9.31356e-01  9.62597e-02 -1.83060e-01  5.91585e-01 -2.78230e-01
21Feb16_224643|  -3.70976e-01 -3.38510e-01]
21Feb16_224643| [ 5.92999e-02 -5.35945e-01 -8.52259e-01  1.62766e-01 -2.64657e-01
21Feb16_224643|   6.65182e-01  2.45597e-01  2.99711e-01  7.14862e-01 -4.00362e-01
21Feb16_224643|   3.40170e-01 -1.14174e-01]
21Feb16_224643| [-4.26995e-01  8.46146e-01  9.81523e-01 -2.62996e-01  8.65377e-01
21Feb16_224643|  -6.86144e-01 -3.53983e-01 -2.18499e-01  3.29010e-01 -8.26088e-01
21Feb16_224643|   1.48202e-01  5.27152e-01]
21Feb16_224643| [-1.97937e-01  5.44304e-02  9.68680e-01  1.96012e-01  6.66432e-01
21Feb16_224643|  -1.15663e-01  1.01696e-01 -9.91833e-01  5.54656e-02  5.06069e-01
21Feb16_224643|  -8.39702e-01  6.07914e-02]
21Feb16_224643| [ 8.22409e-01 -3.07988e-01 -4.87097e-01 -2.67403e-01 -3.17115e-01
21Feb16_224643|   6.20877e-01  2.45721e-01  1.47039e-01  8.22748e-02 -4.61491e-01
21Feb16_224643|   5.08690e-01 -8.10093e-01]
21Feb16_224643| [-1.03463e-01 -7.13247e-01 -5.27190e-01 -8.14055e-01 -2.20069e-01
21Feb16_224643|   7.58689e-01  7.72478e-01 -3.75243e-01 -1.74773e-01  4.33018e-02
21Feb16_224643|   5.76591e-01 -9.04182e-01]
21Feb16_224643| [ 6.39880e-01 -2.76473e-01  4.48413e-01  7.92996e-01  6.12921e-01
21Feb16_224643|   8.45232e-01 -3.59434e-01 -1.65084e-01  6.00279e-01 -9.07135e-01
21Feb16_224643|  -9.18766e-01 -3.84510e-02]
21Feb16_224643| [-4.35982e-01  3.53117e-01 -4.33635e-01  4.41189e-01  2.02385e-01
21Feb16_224643|  -2.15156e-01 -3.32093e-01 -9.46393e-01  7.49818e-01  7.56840e-01
21Feb16_224643|  -2.97280e-01  3.76513e-01]
21Feb16_224643| [ 2.00098e-01 -3.94368e-01  4.74964e-01 -5.14077e-01 -5.02985e-01
21Feb16_224643|   6.57337e-01  4.54284e-01  7.99434e-01  1.18259e-01  7.90625e-01
21Feb16_224643|  -8.45168e-01 -7.22624e-01]
21Feb16_224643| [ 5.21361e-01 -9.37087e-01  6.98489e-01  7.45747e-01  9.84330e-01
21Feb16_224643|  -1.70463e-01 -4.14211e-01  4.94059e-01 -4.89685e-03 -7.22161e-02
21Feb16_224643|   3.28119e-01 -2.96382e-01]
21Feb16_224643| [ 9.97912e-02 -3.45331e-01 -3.32041e-01 -8.83410e-01  4.64194e-01
21Feb16_224643|  -2.94905e-01 -7.11116e-01 -2.12420e-01  8.93334e-01  5.60374e-01
21Feb16_224643|  -8.11522e-01  3.94537e-01]
21Feb16_224643| [ 2.39284e-01 -9.68110e-02 -3.48403e-01  6.68017e-01  1.07039e-01
21Feb16_224643|  -1.80014e-01 -1.28612e-01 -3.28318e-01  7.99371e-01  7.45882e-01
21Feb16_224643|   4.50426e-01 -9.94601e-02]
21Feb16_224643| [-9.32040e-02 -4.99896e-01 -3.18835e-01 -3.21963e-01  8.88030e-02
21Feb16_224643|   8.24115e-01  3.93190e-01  2.14054e-01 -4.70631e-02  5.36199e-01
21Feb16_224643|   7.72001e-01 -1.38053e-01]
21Feb16_224643| [ 8.31611e-01  7.46409e-01  2.18558e-01  7.47226e-01 -4.35942e-01
21Feb16_224643|  -6.59230e-01  3.39715e-02  8.14827e-01 -7.32488e-02 -1.12845e-01
21Feb16_224643|  -5.06295e-01  2.18074e-01]
21Feb16_224643| [-3.26563e-01  6.22846e-01  3.85669e-01 -9.86028e-01 -7.51629e-02
21Feb16_224643|  -1.88021e-01  7.27322e-01  5.61207e-04  1.34321e-01  7.19415e-01
21Feb16_224643|  -5.83277e-01 -4.45815e-01]
21Feb16_224643| [ 7.83756e-01  9.31803e-02  4.99853e-01 -9.31861e-01  7.91593e-01
21Feb16_224643|   1.96250e-01 -8.00498e-02  7.34271e-01 -2.68771e-01  7.49220e-01
21Feb16_224643|   1.24815e-01  6.17245e-01]
21Feb16_224643| [ 2.20500e-01 -9.26851e-01 -5.03545e-02  9.91366e-01  9.07862e-01
21Feb16_224643|   6.95839e-01  2.07702e-01  1.55262e-01  7.17753e-01 -6.02225e-01
21Feb16_224643|  -2.43972e-02  7.83904e-01]
21Feb16_224643| [-7.35179e-01 -4.04922e-01 -7.64988e-01  6.94764e-03 -5.74469e-01
21Feb16_224643|  -8.82582e-01 -4.25720e-01  4.48261e-01  9.38039e-01 -6.02162e-01
21Feb16_224643|   1.85138e-01  8.19467e-01]
21Feb16_224643| [-2.42564e-01  5.05630e-02 -6.53631e-01  8.89456e-01  3.73267e-02
21Feb16_224643|  -4.57479e-01  5.78190e-01 -8.65769e-01  4.43846e-01  9.21993e-01
21Feb16_224643|  -4.59642e-01  4.55887e-01]
21Feb16_224643| [ 1.79502e-01  5.97755e-01 -5.91581e-01  6.50878e-01 -3.20822e-02
21Feb16_224643|   7.98103e-01  9.23662e-01 -3.15762e-01  3.95919e-01 -9.74799e-01
21Feb16_224643|  -9.18783e-01  9.04381e-01]
21Feb16_224643| [-9.77544e-01 -9.84191e-01 -3.78989e-01  1.57093e-01 -1.19240e-01
21Feb16_224643|   7.04336e-01  9.20317e-01 -9.23300e-02  7.24512e-01 -4.73620e-01
21Feb16_224643|   4.32204e-01  1.96422e-01]
21Feb16_224643| [-9.94008e-01  1.23345e-01 -2.91311e-01  3.86181e-01  3.50519e-01
21Feb16_224643|   8.97293e-02  1.28693e-01  7.64175e-01  9.70172e-01 -9.36008e-01
21Feb16_224643|   2.31190e-01 -3.81352e-01]
21Feb16_224643| [-8.68842e-01 -3.08689e-01 -7.85613e-02 -7.75421e-01 -2.62711e-01
21Feb16_224643|  -9.13854e-01  5.58996e-01  8.97445e-01 -4.78631e-01 -4.79708e-02
21Feb16_224643|  -2.09270e-01  1.03320e-01]
21Feb16_224643| [ 2.47190e-01  8.94828e-01 -8.83655e-01  1.67368e-01 -1.09226e-01
21Feb16_224643|   5.39374e-01  3.22158e-01  7.22802e-01 -4.76431e-01 -3.98606e-01
21Feb16_224643|   3.91466e-01 -5.89172e-01]
21Feb16_224643| [ 2.03966e-01 -8.11217e-01  8.56319e-01 -5.26108e-01 -9.29896e-01
21Feb16_224643|   5.92077e-01  8.52854e-01  6.15086e-01  5.45676e-01 -8.13950e-01
21Feb16_224643|   6.24771e-01 -9.57171e-01]
21Feb16_224643| [-7.59457e-01  2.18652e-01 -9.40198e-01 -1.94388e-03 -3.63300e-01
21Feb16_224643|   2.19527e-01 -3.86609e-01  6.57866e-02  8.04643e-01  4.37489e-01
21Feb16_224643|   6.39988e-01 -8.42788e-01]
21Feb16_224643| [-2.79911e-01  8.89651e-01  5.38994e-02  7.45843e-01 -9.32154e-01
21Feb16_224643|   5.56522e-01  5.04658e-01  3.56409e-01 -5.15289e-01  6.99550e-01
21Feb16_224643|  -7.31032e-01  1.61260e-01]
21Feb16_224643| [ 8.41582e-01 -5.25391e-01  4.65437e-01  4.40808e-01 -6.03761e-01
21Feb16_224643|   6.23036e-01  9.46114e-01  5.92328e-01  2.08190e-01 -6.69715e-01
21Feb16_224643|  -7.35264e-02  5.96491e-01]
21Feb16_224643| [ 3.20347e-01  1.37290e-01  1.72843e-02 -4.70187e-01  5.92987e-01
21Feb16_224643|   3.57672e-01  2.73873e-01 -8.65750e-02 -3.09144e-01 -9.20603e-01
21Feb16_224643|   2.82912e-01  6.38325e-01]
21Feb16_224643| [-8.91399e-01 -1.24857e-01 -4.86431e-01 -9.05166e-01  8.47373e-01
21Feb16_224643|   3.18146e-01  2.73494e-02 -5.33112e-01  5.63862e-01 -5.12821e-01
21Feb16_224643|  -9.38474e-01 -9.90043e-01]
21Feb16_224643| [-8.25448e-01 -1.90141e-02 -5.51276e-01 -8.23215e-01  7.26222e-02
21Feb16_224643|   3.49894e-01  5.17693e-01 -5.57217e-01 -3.26301e-01  7.78564e-01
21Feb16_224643|   6.58213e-01 -2.83929e-01]
21Feb16_224643| [ 6.18012e-02 -4.92329e-01  5.41071e-01  2.13013e-01  6.35700e-01
21Feb16_224643|  -1.65529e-01  5.77357e-01  2.45531e-01  2.54855e-01 -8.48854e-01
21Feb16_224643|   6.46386e-01 -4.13404e-01]
21Feb16_224643| [-3.41116e-01 -4.75918e-01  3.59165e-01  6.02895e-01 -4.31688e-01
21Feb16_224643|  -8.51757e-01  2.31464e-01 -9.57407e-01  2.83436e-01 -4.51744e-01
21Feb16_224643|   4.80022e-02 -8.35007e-01]
21Feb16_224643| [ 9.67499e-01  5.85047e-02  7.21540e-01  3.12459e-01  3.50272e-01
21Feb16_224643|   2.14450e-01 -3.30294e-01 -7.99000e-01  1.11959e-01  2.74091e-01
21Feb16_224643|  -1.78234e-01  9.40235e-01]
21Feb16_224643| [-1.14387e-01  4.31319e-01  3.73789e-01 -4.62497e-01  4.50407e-01
21Feb16_224643|  -4.00668e-01 -8.26575e-01  2.39589e-01 -5.24611e-01  3.30691e-01
21Feb16_224643|  -3.99504e-01  1.44547e-01]
21Feb16_224643| [ 7.34826e-01 -5.37352e-01 -6.62895e-01  1.04258e-01  2.15046e-03
21Feb16_224643|   2.71790e-01  8.51151e-01 -6.31948e-01  1.94011e-01 -6.41830e-01
21Feb16_224643|   1.67802e-01 -4.29449e-01]
21Feb16_224643| [-6.18752e-01  1.18069e-01 -7.98263e-01  4.75266e-01 -9.95474e-01
21Feb16_224643|  -1.79698e-01  6.90455e-01  3.44607e-01 -5.80013e-01 -6.16218e-02
21Feb16_224643|   7.01329e-01  8.33298e-02]
21Feb16_224643| [-2.69227e-01 -1.43165e-02 -3.33533e-01 -1.69954e-01 -1.26476e-02
21Feb16_224643|   7.69653e-01 -6.99893e-01  5.22539e-01 -1.67862e-01  4.44416e-01
21Feb16_224643|   6.72372e-01  5.52923e-01]
21Feb16_224643| [-7.10479e-01  1.61800e-01  2.53825e-01 -3.00634e-01 -5.06805e-01
21Feb16_224643|   2.02091e-01 -4.94980e-02 -1.44363e-01 -6.18371e-01  5.74350e-01
21Feb16_224643|  -1.85073e-01 -8.11049e-01]
21Feb16_224643| [-6.60846e-01 -1.69003e-01  6.00733e-01 -8.28618e-01 -3.99034e-01
21Feb16_224643|  -5.82553e-01  7.34428e-02  5.57096e-01 -1.50695e-01  1.26307e-01
21Feb16_224643|   8.92712e-01 -8.75142e-01]
21Feb16_224643| [ 7.58158e-01  5.89907e-01 -1.92304e-01 -3.86200e-01 -2.63049e-01
21Feb16_224643|  -3.41209e-03  4.05030e-01 -8.95945e-02  9.79113e-01  6.78942e-02
21Feb16_224643|  -9.53580e-01  7.06162e-01]
21Feb16_224643| [-1.23045e-01  9.25694e-01  5.20030e-01  4.57808e-01 -9.99639e-01
21Feb16_224643|  -9.80069e-02  3.03598e-01  4.26167e-02 -3.64595e-01 -7.17635e-01
21Feb16_224643|   1.61128e-01  6.30329e-01]
21Feb16_224643| [ 2.02232e-02 -3.24113e-01  7.43999e-01 -3.75983e-01  4.63558e-01
21Feb16_224643|  -2.04941e-01 -5.28404e-02  4.26576e-01 -2.53802e-01  1.74976e-01
21Feb16_224643|  -8.35763e-01  8.54548e-01]
21Feb16_224643| [-5.76875e-01  5.40954e-01 -4.91777e-01  4.40209e-01 -9.16379e-01
21Feb16_224643|   6.01728e-01  1.25226e-02  2.05876e-01  8.45524e-01 -8.34178e-01
21Feb16_224643|  -7.87379e-01  8.63352e-01]
21Feb16_224643| [-3.15102e-01  7.00213e-01  6.69503e-01  7.15510e-01 -9.53550e-01
21Feb16_224643|   4.07885e-02  4.25336e-01  6.24629e-01  9.90858e-01  6.36989e-01
21Feb16_224643|  -6.44355e-01 -5.47589e-01]
21Feb16_224643| [-8.25051e-01 -4.37574e-01  4.76334e-01 -7.71092e-01  7.98467e-01
21Feb16_224643|  -1.52347e-01  3.34469e-01  1.51889e-01 -9.60611e-01  4.62484e-01
21Feb16_224643|   4.10115e-01 -1.60555e-01]
21Feb16_224643| [ 1.77712e-01  6.55776e-01  8.97735e-01 -9.20852e-01 -9.69032e-01
21Feb16_224643|  -4.79756e-02 -3.24015e-01 -1.57490e-01 -6.25919e-01  9.94240e-01
21Feb16_224643|  -4.74141e-01 -1.00993e-01]
21Feb16_224643| [ 3.66246e-01  8.06205e-01  3.37216e-01 -3.17040e-01  9.19693e-01
21Feb16_224643|   8.28581e-01  2.22724e-01 -5.57410e-01 -8.17434e-01 -8.65693e-01
21Feb16_224643|  -4.72960e-01  7.15176e-01]
21Feb16_224643| [-8.25000e-01 -4.67253e-01 -1.84646e-02  3.88053e-01 -8.75853e-01
21Feb16_224643|  -2.34509e-01  9.53471e-01  8.05489e-02  2.71744e-01 -7.15129e-01
21Feb16_224643|   9.24875e-01 -6.07435e-01]
21Feb16_224643| [-2.79447e-01  2.39105e-01  1.32962e-01 -7.68103e-01  7.58443e-01
21Feb16_224643|  -1.69646e-01 -7.52460e-01 -7.30195e-01 -4.68985e-01 -2.88784e-01
21Feb16_224643|   3.77655e-02 -5.72024e-01]
21Feb16_224643| [-8.37481e-01 -8.22188e-02  8.45547e-01 -5.53876e-01  5.72703e-01
21Feb16_224643|   3.09970e-01  8.96552e-01  3.97690e-01 -7.19080e-01  2.37714e-01
21Feb16_224643|   6.60752e-01  1.69435e-01]]
21Feb16_224643|-- Bias --
21Feb16_224643|[-0.28065  0.08142 -0.20194  0.96969  0.45180  0.54884  0.16606 -0.15804
21Feb16_224643|  0.47362  0.17133  0.43345 -0.35803]
21Feb16_224643|Layer 1:
21Feb16_224643|-- Config --
21Feb16_224643|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 12], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224643|-- Weights --
21Feb16_224643|[[-0.88546  0.72941]
21Feb16_224643| [ 0.79196 -0.05477]
21Feb16_224643| [-0.89752 -0.49343]
21Feb16_224643| [ 0.78974 -0.41510]
21Feb16_224643| [ 0.29561 -0.94575]
21Feb16_224643| [-0.14754  0.69148]
21Feb16_224643| [-0.33558  0.37910]
21Feb16_224643| [-0.82387  0.15998]
21Feb16_224643| [-0.77760  0.88462]
21Feb16_224643| [ 0.98329 -0.68363]
21Feb16_224643| [ 0.88895  0.40387]
21Feb16_224643| [ 0.39015 -0.38652]]
21Feb16_224643|-- Bias --
21Feb16_224643|[ 0.28702 -0.70976]
21Feb16_224643|Predicting the validation and test data with the Best initial individual.
21Feb16_224649| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb16_224649|-----------  ------------------  --------------------  ----------
21Feb16_224649|Validation         42.00                  12            0.00000
21Feb16_224649|   Test            36.32                  12            0.00298
21Feb16_224649|-------------------- Test #0 --------------------
21Feb16_224649|Best final individual weights
21Feb16_224649|Individual:
21Feb16_224649|-- Constant hidden layers --
21Feb16_224649|False
21Feb16_224649|Layer 0:
21Feb16_224649|-- Config --
21Feb16_224649|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224649|-- Weights --
21Feb16_224649|[[-0.73212  1.32861  0.10200]
21Feb16_224649| [ 1.48746 -2.97273 -0.42944]
21Feb16_224649| [ 0.53095 -1.50623  0.79224]
21Feb16_224649| [-1.07292 -0.83175 -0.90105]
21Feb16_224649| [-0.48696 -0.89325  0.27226]
21Feb16_224649| [-3.02511  0.34155 -0.03837]
21Feb16_224649| [-0.76747  0.57140 -0.46892]
21Feb16_224649| [-0.07581  0.14713  0.85910]
21Feb16_224649| [-1.37488  0.52170 -0.36205]
21Feb16_224649| [ 1.60981 -0.08727 -0.11267]
21Feb16_224649| [ 0.50986  1.58916 -0.35287]
21Feb16_224649| [-0.34599  1.27113 -0.16393]
21Feb16_224649| [ 1.29203  1.19467  0.37695]
21Feb16_224649| [ 0.58704  0.06328 -0.24240]
21Feb16_224649| [-0.93888 -0.89760  0.57087]
21Feb16_224649| [ 0.99159 -0.66387  0.35177]
21Feb16_224649| [-0.67119  1.06910 -0.12512]
21Feb16_224649| [-0.91534  1.23744 -0.40465]
21Feb16_224649| [ 1.39278  0.08069  0.23328]
21Feb16_224649| [ 0.09880  0.57603 -0.96101]
21Feb16_224649| [ 0.01621 -0.13343 -0.27624]
21Feb16_224649| [-1.28286 -2.28909  0.37931]
21Feb16_224649| [-0.28370  0.09336  0.01547]
21Feb16_224649| [-0.51894  1.84280 -0.25906]
21Feb16_224649| [-0.83075 -0.04508  0.12107]
21Feb16_224649| [ 0.37343  1.18436 -0.07358]
21Feb16_224649| [-2.38657 -0.35191  0.01962]
21Feb16_224649| [ 0.95757 -0.91760 -0.08971]
21Feb16_224649| [ 0.38792 -0.01880  0.69717]
21Feb16_224649| [ 1.66877 -0.58078 -1.21129]
21Feb16_224649| [-0.50943  0.59080  0.30856]
21Feb16_224649| [ 0.30163  1.11518  0.98185]
21Feb16_224649| [-0.73226  0.32281 -0.66712]
21Feb16_224649| [-0.62054 -2.21049  1.40981]
21Feb16_224649| [ 1.23185 -0.58090  0.35844]
21Feb16_224649| [-0.05616  0.24219 -0.02853]
21Feb16_224649| [-1.05085 -2.30259 -0.16276]
21Feb16_224649| [ 0.71087  0.14900  1.13430]
21Feb16_224649| [-2.45877 -1.20999 -1.04986]
21Feb16_224649| [-1.00480  1.36344 -0.13998]
21Feb16_224649| [ 1.83140 -0.91532  0.07616]
21Feb16_224649| [-0.60404 -2.05184  0.76948]
21Feb16_224649| [ 0.52617  0.76042 -1.76746]
21Feb16_224649| [-0.22134  0.17324  0.99530]
21Feb16_224649| [-0.36427  1.34655  0.02110]
21Feb16_224649| [-0.93125 -0.33620 -0.25012]
21Feb16_224649| [-2.76428  0.14487  0.48096]
21Feb16_224649| [-0.10518  0.35052  1.71840]
21Feb16_224649| [-1.27998  1.12568  1.26523]
21Feb16_224649| [-0.60698  1.53230 -0.60824]
21Feb16_224649| [ 0.02898  2.98718 -0.59153]
21Feb16_224649| [ 0.17588 -0.00449  0.50797]
21Feb16_224649| [-1.42674 -0.54967 -0.21310]
21Feb16_224649| [ 1.03196  1.18733  0.36755]
21Feb16_224649| [ 1.04748 -1.47444 -0.08469]
21Feb16_224649| [ 0.49410  0.38745  0.68469]
21Feb16_224649| [-0.62880  0.73245  0.19964]]
21Feb16_224649|-- Bias --
21Feb16_224649|[-0.18798  0.64571 -0.23142]
21Feb16_224649|Layer 1:
21Feb16_224649|-- Config --
21Feb16_224649|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224649|-- Weights --
21Feb16_224649|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb16_224649| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb16_224649| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb16_224649|-- Bias --
21Feb16_224649|[0.60477 0.03773 0.26452 0.12222]
21Feb16_224649|Layer 2:
21Feb16_224649|-- Config --
21Feb16_224649|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224649|-- Weights --
21Feb16_224649|[[ 0.67920  0.12119]
21Feb16_224649| [ 0.44836  0.02916]
21Feb16_224649| [ 0.68939  0.31516]
21Feb16_224649| [-0.58995 -0.05861]]
21Feb16_224649|-- Bias --
21Feb16_224649|[ 0.59649 -0.08079]
21Feb16_224649|Layer 3:
21Feb16_224649|-- Config --
21Feb16_224649|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224649|-- Weights --
21Feb16_224649|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb16_224649| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb16_224649|-- Bias --
21Feb16_224649|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb16_224649|Layer 4:
21Feb16_224649|-- Config --
21Feb16_224649|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224649|-- Weights --
21Feb16_224649|[[-0.03514 -1.04833]
21Feb16_224649| [ 1.25238  0.62094]
21Feb16_224649| [ 0.99203  0.37406]
21Feb16_224649| [ 0.49902  0.67158]
21Feb16_224649| [-1.35709  0.38335]]
21Feb16_224649|-- Bias --
21Feb16_224649|[0.31435 0.36299]
21Feb16_224649|Predicting the validation and test data with the Best final individual.
21Feb16_224657| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb16_224657|-----------  ------------------  --------------------  ----------
21Feb16_224657|Validation         40.17                  56            0.05627
21Feb16_224657|   Test            21.37                  56            0.70301
21Feb16_224657|-------------------- Test #1 --------------------
21Feb16_224657|Best final individual weights
21Feb16_224657|Individual:
21Feb16_224657|-- Constant hidden layers --
21Feb16_224657|False
21Feb16_224657|Layer 0:
21Feb16_224657|-- Config --
21Feb16_224657|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224657|-- Weights --
21Feb16_224657|[[-0.73212  1.32861  0.10200]
21Feb16_224657| [ 1.48746 -2.97273 -0.42944]
21Feb16_224657| [ 0.53095 -1.50623  0.79224]
21Feb16_224657| [-1.07292 -0.83175 -0.90105]
21Feb16_224657| [-0.48696 -0.89325  0.27226]
21Feb16_224657| [-3.02511  0.34155 -0.03837]
21Feb16_224657| [-0.76747  0.57140 -0.46892]
21Feb16_224657| [-0.07581  0.14713  0.85910]
21Feb16_224657| [-1.37488  0.52170 -0.36205]
21Feb16_224657| [ 1.60981 -0.08727 -0.11267]
21Feb16_224657| [ 0.50986  1.58916 -0.35287]
21Feb16_224657| [-0.34599  1.27113 -0.16393]
21Feb16_224657| [ 1.29203  1.19467  0.37695]
21Feb16_224657| [ 0.58704  0.06328 -0.24240]
21Feb16_224657| [-0.93888 -0.89760  0.57087]
21Feb16_224657| [ 0.99159 -0.66387  0.35177]
21Feb16_224657| [-0.67119  1.06910 -0.12512]
21Feb16_224657| [-0.91534  1.23744 -0.40465]
21Feb16_224657| [ 1.39278  0.08069  0.23328]
21Feb16_224657| [ 0.09880  0.57603 -0.96101]
21Feb16_224657| [ 0.01621 -0.13343 -0.27624]
21Feb16_224657| [-1.28286 -2.28909  0.37931]
21Feb16_224657| [-0.28370  0.09336  0.01547]
21Feb16_224657| [-0.51894  1.84280 -0.25906]
21Feb16_224657| [-0.83075 -0.04508  0.12107]
21Feb16_224657| [ 0.37343  1.18436 -0.07358]
21Feb16_224657| [-2.38657 -0.35191  0.01962]
21Feb16_224657| [ 0.95757 -0.91760 -0.08971]
21Feb16_224657| [ 0.38792 -0.01880  0.69717]
21Feb16_224657| [ 1.66877 -0.58078 -1.21129]
21Feb16_224657| [-0.50943  0.59080  0.30856]
21Feb16_224657| [ 0.30163  1.11518  0.98185]
21Feb16_224657| [-0.73226  0.32281 -0.66712]
21Feb16_224657| [-0.62054 -2.21049  1.40981]
21Feb16_224657| [ 1.23185 -0.58090  0.35844]
21Feb16_224657| [-0.05616  0.24219 -0.02853]
21Feb16_224657| [-1.05085 -2.30259 -0.16276]
21Feb16_224657| [ 0.71087  0.14900  1.13430]
21Feb16_224657| [-2.45877 -1.20999 -1.04986]
21Feb16_224657| [-1.00480  1.36344 -0.13998]
21Feb16_224657| [ 1.83140 -0.91532  0.07616]
21Feb16_224657| [-0.60404 -2.05184  0.76948]
21Feb16_224657| [ 0.52617  0.76042 -1.76746]
21Feb16_224657| [-0.22134  0.17324  0.99530]
21Feb16_224657| [-0.36427  1.34655  0.02110]
21Feb16_224657| [-0.93125 -0.33620 -0.25012]
21Feb16_224657| [-2.76428  0.14487  0.48096]
21Feb16_224657| [-0.10518  0.35052  1.71840]
21Feb16_224657| [-1.27998  1.12568  1.26523]
21Feb16_224657| [-0.60698  1.53230 -0.60824]
21Feb16_224657| [ 0.02898  2.98718 -0.59153]
21Feb16_224657| [ 0.17588 -0.00449  0.50797]
21Feb16_224657| [-1.42674 -0.54967 -0.21310]
21Feb16_224657| [ 1.03196  1.18733  0.36755]
21Feb16_224657| [ 1.04748 -1.47444 -0.08469]
21Feb16_224657| [ 0.49410  0.38745  0.68469]
21Feb16_224657| [-0.62880  0.73245  0.19964]]
21Feb16_224657|-- Bias --
21Feb16_224657|[-0.18798  0.64571 -0.23142]
21Feb16_224657|Layer 1:
21Feb16_224657|-- Config --
21Feb16_224657|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224657|-- Weights --
21Feb16_224657|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb16_224657| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb16_224657| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb16_224657|-- Bias --
21Feb16_224657|[0.60477 0.03773 0.26452 0.12222]
21Feb16_224657|Layer 2:
21Feb16_224657|-- Config --
21Feb16_224657|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224657|-- Weights --
21Feb16_224657|[[ 0.67920  0.12119]
21Feb16_224657| [ 0.44836  0.02916]
21Feb16_224657| [ 0.68939  0.31516]
21Feb16_224657| [-0.58995 -0.05861]]
21Feb16_224657|-- Bias --
21Feb16_224657|[ 0.59649 -0.08079]
21Feb16_224657|Layer 3:
21Feb16_224657|-- Config --
21Feb16_224657|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224657|-- Weights --
21Feb16_224657|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb16_224657| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb16_224657|-- Bias --
21Feb16_224657|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb16_224657|Layer 4:
21Feb16_224657|-- Config --
21Feb16_224657|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224657|-- Weights --
21Feb16_224657|[[-0.03514 -1.04833]
21Feb16_224657| [ 1.25238  0.62094]
21Feb16_224657| [ 0.99203  0.37406]
21Feb16_224657| [ 0.49902  0.67158]
21Feb16_224657| [-1.35709  0.38335]]
21Feb16_224657|-- Bias --
21Feb16_224657|[0.31435 0.36299]
21Feb16_224657|Predicting the validation and test data with the Best final individual.
21Feb16_224704| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb16_224704|-----------  ------------------  --------------------  ----------
21Feb16_224704|Validation         23.83                  56            0.86651
21Feb16_224704|   Test            22.68                  56            0.77969
21Feb16_224704|-------------------- Test #2 --------------------
21Feb16_224704|Best final individual weights
21Feb16_224704|Individual:
21Feb16_224704|-- Constant hidden layers --
21Feb16_224704|False
21Feb16_224704|Layer 0:
21Feb16_224704|-- Config --
21Feb16_224704|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224704|-- Weights --
21Feb16_224704|[[-0.73212  1.32861  0.10200]
21Feb16_224704| [ 1.48746 -2.97273 -0.42944]
21Feb16_224704| [ 0.53095 -1.50623  0.79224]
21Feb16_224704| [-1.07292 -0.83175 -0.90105]
21Feb16_224704| [-0.48696 -0.89325  0.27226]
21Feb16_224704| [-3.02511  0.34155 -0.03837]
21Feb16_224704| [-0.76747  0.57140 -0.46892]
21Feb16_224704| [-0.07581  0.14713  0.85910]
21Feb16_224704| [-1.37488  0.52170 -0.36205]
21Feb16_224704| [ 1.60981 -0.08727 -0.11267]
21Feb16_224704| [ 0.50986  1.58916 -0.35287]
21Feb16_224704| [-0.34599  1.27113 -0.16393]
21Feb16_224704| [ 1.29203  1.19467  0.37695]
21Feb16_224704| [ 0.58704  0.06328 -0.24240]
21Feb16_224704| [-0.93888 -0.89760  0.57087]
21Feb16_224704| [ 0.99159 -0.66387  0.35177]
21Feb16_224704| [-0.67119  1.06910 -0.12512]
21Feb16_224704| [-0.91534  1.23744 -0.40465]
21Feb16_224704| [ 1.39278  0.08069  0.23328]
21Feb16_224704| [ 0.09880  0.57603 -0.96101]
21Feb16_224704| [ 0.01621 -0.13343 -0.27624]
21Feb16_224704| [-1.28286 -2.28909  0.37931]
21Feb16_224704| [-0.28370  0.09336  0.01547]
21Feb16_224704| [-0.51894  1.84280 -0.25906]
21Feb16_224704| [-0.83075 -0.04508  0.12107]
21Feb16_224704| [ 0.37343  1.18436 -0.07358]
21Feb16_224704| [-2.38657 -0.35191  0.01962]
21Feb16_224704| [ 0.95757 -0.91760 -0.08971]
21Feb16_224704| [ 0.38792 -0.01880  0.69717]
21Feb16_224704| [ 1.66877 -0.58078 -1.21129]
21Feb16_224704| [-0.50943  0.59080  0.30856]
21Feb16_224704| [ 0.30163  1.11518  0.98185]
21Feb16_224704| [-0.73226  0.32281 -0.66712]
21Feb16_224704| [-0.62054 -2.21049  1.40981]
21Feb16_224704| [ 1.23185 -0.58090  0.35844]
21Feb16_224704| [-0.05616  0.24219 -0.02853]
21Feb16_224704| [-1.05085 -2.30259 -0.16276]
21Feb16_224704| [ 0.71087  0.14900  1.13430]
21Feb16_224704| [-2.45877 -1.20999 -1.04986]
21Feb16_224704| [-1.00480  1.36344 -0.13998]
21Feb16_224704| [ 1.83140 -0.91532  0.07616]
21Feb16_224704| [-0.60404 -2.05184  0.76948]
21Feb16_224704| [ 0.52617  0.76042 -1.76746]
21Feb16_224704| [-0.22134  0.17324  0.99530]
21Feb16_224704| [-0.36427  1.34655  0.02110]
21Feb16_224704| [-0.93125 -0.33620 -0.25012]
21Feb16_224704| [-2.76428  0.14487  0.48096]
21Feb16_224704| [-0.10518  0.35052  1.71840]
21Feb16_224704| [-1.27998  1.12568  1.26523]
21Feb16_224704| [-0.60698  1.53230 -0.60824]
21Feb16_224704| [ 0.02898  2.98718 -0.59153]
21Feb16_224704| [ 0.17588 -0.00449  0.50797]
21Feb16_224704| [-1.42674 -0.54967 -0.21310]
21Feb16_224704| [ 1.03196  1.18733  0.36755]
21Feb16_224704| [ 1.04748 -1.47444 -0.08469]
21Feb16_224704| [ 0.49410  0.38745  0.68469]
21Feb16_224704| [-0.62880  0.73245  0.19964]]
21Feb16_224704|-- Bias --
21Feb16_224704|[-0.18798  0.64571 -0.23142]
21Feb16_224704|Layer 1:
21Feb16_224704|-- Config --
21Feb16_224704|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224704|-- Weights --
21Feb16_224704|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb16_224704| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb16_224704| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb16_224704|-- Bias --
21Feb16_224704|[0.60477 0.03773 0.26452 0.12222]
21Feb16_224704|Layer 2:
21Feb16_224704|-- Config --
21Feb16_224704|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224704|-- Weights --
21Feb16_224704|[[ 0.67920  0.12119]
21Feb16_224704| [ 0.44836  0.02916]
21Feb16_224704| [ 0.68939  0.31516]
21Feb16_224704| [-0.58995 -0.05861]]
21Feb16_224704|-- Bias --
21Feb16_224704|[ 0.59649 -0.08079]
21Feb16_224704|Layer 3:
21Feb16_224704|-- Config --
21Feb16_224704|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224704|-- Weights --
21Feb16_224704|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb16_224704| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb16_224704|-- Bias --
21Feb16_224704|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb16_224704|Layer 4:
21Feb16_224704|-- Config --
21Feb16_224704|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224704|-- Weights --
21Feb16_224704|[[-0.03514 -1.04833]
21Feb16_224704| [ 1.25238  0.62094]
21Feb16_224704| [ 0.99203  0.37406]
21Feb16_224704| [ 0.49902  0.67158]
21Feb16_224704| [-1.35709  0.38335]]
21Feb16_224704|-- Bias --
21Feb16_224704|[0.31435 0.36299]
21Feb16_224704|Predicting the validation and test data with the Best final individual.
21Feb16_224712| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb16_224712|-----------  ------------------  --------------------  ----------
21Feb16_224712|Validation         23.91                  56            0.70865
21Feb16_224712|   Test            29.45                  56            0.70270
21Feb16_224712|-------------------- Test #3 --------------------
21Feb16_224712|Best final individual weights
21Feb16_224712|Individual:
21Feb16_224712|-- Constant hidden layers --
21Feb16_224712|False
21Feb16_224712|Layer 0:
21Feb16_224712|-- Config --
21Feb16_224712|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224712|-- Weights --
21Feb16_224712|[[-0.73212  1.32861  0.10200]
21Feb16_224712| [ 1.48746 -2.97273 -0.42944]
21Feb16_224712| [ 0.53095 -1.50623  0.79224]
21Feb16_224712| [-1.07292 -0.83175 -0.90105]
21Feb16_224712| [-0.48696 -0.89325  0.27226]
21Feb16_224712| [-3.02511  0.34155 -0.03837]
21Feb16_224712| [-0.76747  0.57140 -0.46892]
21Feb16_224712| [-0.07581  0.14713  0.85910]
21Feb16_224712| [-1.37488  0.52170 -0.36205]
21Feb16_224712| [ 1.60981 -0.08727 -0.11267]
21Feb16_224712| [ 0.50986  1.58916 -0.35287]
21Feb16_224712| [-0.34599  1.27113 -0.16393]
21Feb16_224712| [ 1.29203  1.19467  0.37695]
21Feb16_224712| [ 0.58704  0.06328 -0.24240]
21Feb16_224712| [-0.93888 -0.89760  0.57087]
21Feb16_224712| [ 0.99159 -0.66387  0.35177]
21Feb16_224712| [-0.67119  1.06910 -0.12512]
21Feb16_224712| [-0.91534  1.23744 -0.40465]
21Feb16_224712| [ 1.39278  0.08069  0.23328]
21Feb16_224712| [ 0.09880  0.57603 -0.96101]
21Feb16_224712| [ 0.01621 -0.13343 -0.27624]
21Feb16_224712| [-1.28286 -2.28909  0.37931]
21Feb16_224712| [-0.28370  0.09336  0.01547]
21Feb16_224712| [-0.51894  1.84280 -0.25906]
21Feb16_224712| [-0.83075 -0.04508  0.12107]
21Feb16_224712| [ 0.37343  1.18436 -0.07358]
21Feb16_224712| [-2.38657 -0.35191  0.01962]
21Feb16_224712| [ 0.95757 -0.91760 -0.08971]
21Feb16_224712| [ 0.38792 -0.01880  0.69717]
21Feb16_224712| [ 1.66877 -0.58078 -1.21129]
21Feb16_224712| [-0.50943  0.59080  0.30856]
21Feb16_224712| [ 0.30163  1.11518  0.98185]
21Feb16_224712| [-0.73226  0.32281 -0.66712]
21Feb16_224712| [-0.62054 -2.21049  1.40981]
21Feb16_224712| [ 1.23185 -0.58090  0.35844]
21Feb16_224712| [-0.05616  0.24219 -0.02853]
21Feb16_224712| [-1.05085 -2.30259 -0.16276]
21Feb16_224712| [ 0.71087  0.14900  1.13430]
21Feb16_224712| [-2.45877 -1.20999 -1.04986]
21Feb16_224712| [-1.00480  1.36344 -0.13998]
21Feb16_224712| [ 1.83140 -0.91532  0.07616]
21Feb16_224712| [-0.60404 -2.05184  0.76948]
21Feb16_224712| [ 0.52617  0.76042 -1.76746]
21Feb16_224712| [-0.22134  0.17324  0.99530]
21Feb16_224712| [-0.36427  1.34655  0.02110]
21Feb16_224712| [-0.93125 -0.33620 -0.25012]
21Feb16_224712| [-2.76428  0.14487  0.48096]
21Feb16_224712| [-0.10518  0.35052  1.71840]
21Feb16_224712| [-1.27998  1.12568  1.26523]
21Feb16_224712| [-0.60698  1.53230 -0.60824]
21Feb16_224712| [ 0.02898  2.98718 -0.59153]
21Feb16_224712| [ 0.17588 -0.00449  0.50797]
21Feb16_224712| [-1.42674 -0.54967 -0.21310]
21Feb16_224712| [ 1.03196  1.18733  0.36755]
21Feb16_224712| [ 1.04748 -1.47444 -0.08469]
21Feb16_224712| [ 0.49410  0.38745  0.68469]
21Feb16_224712| [-0.62880  0.73245  0.19964]]
21Feb16_224712|-- Bias --
21Feb16_224712|[-0.18798  0.64571 -0.23142]
21Feb16_224712|Layer 1:
21Feb16_224712|-- Config --
21Feb16_224712|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224712|-- Weights --
21Feb16_224712|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb16_224712| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb16_224712| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb16_224712|-- Bias --
21Feb16_224712|[0.60477 0.03773 0.26452 0.12222]
21Feb16_224712|Layer 2:
21Feb16_224712|-- Config --
21Feb16_224712|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224712|-- Weights --
21Feb16_224712|[[ 0.67920  0.12119]
21Feb16_224712| [ 0.44836  0.02916]
21Feb16_224712| [ 0.68939  0.31516]
21Feb16_224712| [-0.58995 -0.05861]]
21Feb16_224712|-- Bias --
21Feb16_224712|[ 0.59649 -0.08079]
21Feb16_224712|Layer 3:
21Feb16_224712|-- Config --
21Feb16_224712|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224712|-- Weights --
21Feb16_224712|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb16_224712| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb16_224712|-- Bias --
21Feb16_224712|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb16_224712|Layer 4:
21Feb16_224712|-- Config --
21Feb16_224712|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224712|-- Weights --
21Feb16_224712|[[-0.03514 -1.04833]
21Feb16_224712| [ 1.25238  0.62094]
21Feb16_224712| [ 0.99203  0.37406]
21Feb16_224712| [ 0.49902  0.67158]
21Feb16_224712| [-1.35709  0.38335]]
21Feb16_224712|-- Bias --
21Feb16_224712|[0.31435 0.36299]
21Feb16_224712|Predicting the validation and test data with the Best final individual.
21Feb16_224720| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb16_224720|-----------  ------------------  --------------------  ----------
21Feb16_224720|Validation         24.35                  56            0.84577
21Feb16_224720|   Test            21.63                  56            0.70714
21Feb16_224720|-------------------- Test #4 --------------------
21Feb16_224720|Best final individual weights
21Feb16_224720|Individual:
21Feb16_224720|-- Constant hidden layers --
21Feb16_224720|False
21Feb16_224720|Layer 0:
21Feb16_224720|-- Config --
21Feb16_224720|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224720|-- Weights --
21Feb16_224720|[[-0.73212  1.32861  0.10200]
21Feb16_224720| [ 1.48746 -2.97273 -0.42944]
21Feb16_224720| [ 0.53095 -1.50623  0.79224]
21Feb16_224720| [-1.07292 -0.83175 -0.90105]
21Feb16_224720| [-0.48696 -0.89325  0.27226]
21Feb16_224720| [-3.02511  0.34155 -0.03837]
21Feb16_224720| [-0.76747  0.57140 -0.46892]
21Feb16_224720| [-0.07581  0.14713  0.85910]
21Feb16_224720| [-1.37488  0.52170 -0.36205]
21Feb16_224720| [ 1.60981 -0.08727 -0.11267]
21Feb16_224720| [ 0.50986  1.58916 -0.35287]
21Feb16_224720| [-0.34599  1.27113 -0.16393]
21Feb16_224720| [ 1.29203  1.19467  0.37695]
21Feb16_224720| [ 0.58704  0.06328 -0.24240]
21Feb16_224720| [-0.93888 -0.89760  0.57087]
21Feb16_224720| [ 0.99159 -0.66387  0.35177]
21Feb16_224720| [-0.67119  1.06910 -0.12512]
21Feb16_224720| [-0.91534  1.23744 -0.40465]
21Feb16_224720| [ 1.39278  0.08069  0.23328]
21Feb16_224720| [ 0.09880  0.57603 -0.96101]
21Feb16_224720| [ 0.01621 -0.13343 -0.27624]
21Feb16_224720| [-1.28286 -2.28909  0.37931]
21Feb16_224720| [-0.28370  0.09336  0.01547]
21Feb16_224720| [-0.51894  1.84280 -0.25906]
21Feb16_224720| [-0.83075 -0.04508  0.12107]
21Feb16_224720| [ 0.37343  1.18436 -0.07358]
21Feb16_224720| [-2.38657 -0.35191  0.01962]
21Feb16_224720| [ 0.95757 -0.91760 -0.08971]
21Feb16_224720| [ 0.38792 -0.01880  0.69717]
21Feb16_224720| [ 1.66877 -0.58078 -1.21129]
21Feb16_224720| [-0.50943  0.59080  0.30856]
21Feb16_224720| [ 0.30163  1.11518  0.98185]
21Feb16_224720| [-0.73226  0.32281 -0.66712]
21Feb16_224720| [-0.62054 -2.21049  1.40981]
21Feb16_224720| [ 1.23185 -0.58090  0.35844]
21Feb16_224720| [-0.05616  0.24219 -0.02853]
21Feb16_224720| [-1.05085 -2.30259 -0.16276]
21Feb16_224720| [ 0.71087  0.14900  1.13430]
21Feb16_224720| [-2.45877 -1.20999 -1.04986]
21Feb16_224720| [-1.00480  1.36344 -0.13998]
21Feb16_224720| [ 1.83140 -0.91532  0.07616]
21Feb16_224720| [-0.60404 -2.05184  0.76948]
21Feb16_224720| [ 0.52617  0.76042 -1.76746]
21Feb16_224720| [-0.22134  0.17324  0.99530]
21Feb16_224720| [-0.36427  1.34655  0.02110]
21Feb16_224720| [-0.93125 -0.33620 -0.25012]
21Feb16_224720| [-2.76428  0.14487  0.48096]
21Feb16_224720| [-0.10518  0.35052  1.71840]
21Feb16_224720| [-1.27998  1.12568  1.26523]
21Feb16_224720| [-0.60698  1.53230 -0.60824]
21Feb16_224720| [ 0.02898  2.98718 -0.59153]
21Feb16_224720| [ 0.17588 -0.00449  0.50797]
21Feb16_224720| [-1.42674 -0.54967 -0.21310]
21Feb16_224720| [ 1.03196  1.18733  0.36755]
21Feb16_224720| [ 1.04748 -1.47444 -0.08469]
21Feb16_224720| [ 0.49410  0.38745  0.68469]
21Feb16_224720| [-0.62880  0.73245  0.19964]]
21Feb16_224720|-- Bias --
21Feb16_224720|[-0.18798  0.64571 -0.23142]
21Feb16_224720|Layer 1:
21Feb16_224720|-- Config --
21Feb16_224720|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224720|-- Weights --
21Feb16_224720|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb16_224720| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb16_224720| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb16_224720|-- Bias --
21Feb16_224720|[0.60477 0.03773 0.26452 0.12222]
21Feb16_224720|Layer 2:
21Feb16_224720|-- Config --
21Feb16_224720|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224720|-- Weights --
21Feb16_224720|[[ 0.67920  0.12119]
21Feb16_224720| [ 0.44836  0.02916]
21Feb16_224720| [ 0.68939  0.31516]
21Feb16_224720| [-0.58995 -0.05861]]
21Feb16_224720|-- Bias --
21Feb16_224720|[ 0.59649 -0.08079]
21Feb16_224720|Layer 3:
21Feb16_224720|-- Config --
21Feb16_224720|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224720|-- Weights --
21Feb16_224720|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb16_224720| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb16_224720|-- Bias --
21Feb16_224720|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb16_224720|Layer 4:
21Feb16_224720|-- Config --
21Feb16_224720|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224720|-- Weights --
21Feb16_224720|[[-0.03514 -1.04833]
21Feb16_224720| [ 1.25238  0.62094]
21Feb16_224720| [ 0.99203  0.37406]
21Feb16_224720| [ 0.49902  0.67158]
21Feb16_224720| [-1.35709  0.38335]]
21Feb16_224720|-- Bias --
21Feb16_224720|[0.31435 0.36299]
21Feb16_224720|Predicting the validation and test data with the Best final individual.
21Feb16_224728| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb16_224728|-----------  ------------------  --------------------  ----------
21Feb16_224728|Validation         21.57                  56            0.82113
21Feb16_224728|   Test            31.19                  56            0.83333
21Feb16_224728|-------------------- Test #5 --------------------
21Feb16_224728|Best final individual weights
21Feb16_224728|Individual:
21Feb16_224728|-- Constant hidden layers --
21Feb16_224728|False
21Feb16_224728|Layer 0:
21Feb16_224728|-- Config --
21Feb16_224728|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224728|-- Weights --
21Feb16_224728|[[-0.73212  1.32861  0.10200]
21Feb16_224728| [ 1.48746 -2.97273 -0.42944]
21Feb16_224728| [ 0.53095 -1.50623  0.79224]
21Feb16_224728| [-1.07292 -0.83175 -0.90105]
21Feb16_224728| [-0.48696 -0.89325  0.27226]
21Feb16_224728| [-3.02511  0.34155 -0.03837]
21Feb16_224728| [-0.76747  0.57140 -0.46892]
21Feb16_224728| [-0.07581  0.14713  0.85910]
21Feb16_224728| [-1.37488  0.52170 -0.36205]
21Feb16_224728| [ 1.60981 -0.08727 -0.11267]
21Feb16_224728| [ 0.50986  1.58916 -0.35287]
21Feb16_224728| [-0.34599  1.27113 -0.16393]
21Feb16_224728| [ 1.29203  1.19467  0.37695]
21Feb16_224728| [ 0.58704  0.06328 -0.24240]
21Feb16_224728| [-0.93888 -0.89760  0.57087]
21Feb16_224728| [ 0.99159 -0.66387  0.35177]
21Feb16_224728| [-0.67119  1.06910 -0.12512]
21Feb16_224728| [-0.91534  1.23744 -0.40465]
21Feb16_224728| [ 1.39278  0.08069  0.23328]
21Feb16_224728| [ 0.09880  0.57603 -0.96101]
21Feb16_224728| [ 0.01621 -0.13343 -0.27624]
21Feb16_224728| [-1.28286 -2.28909  0.37931]
21Feb16_224728| [-0.28370  0.09336  0.01547]
21Feb16_224728| [-0.51894  1.84280 -0.25906]
21Feb16_224728| [-0.83075 -0.04508  0.12107]
21Feb16_224728| [ 0.37343  1.18436 -0.07358]
21Feb16_224728| [-2.38657 -0.35191  0.01962]
21Feb16_224728| [ 0.95757 -0.91760 -0.08971]
21Feb16_224728| [ 0.38792 -0.01880  0.69717]
21Feb16_224728| [ 1.66877 -0.58078 -1.21129]
21Feb16_224728| [-0.50943  0.59080  0.30856]
21Feb16_224728| [ 0.30163  1.11518  0.98185]
21Feb16_224728| [-0.73226  0.32281 -0.66712]
21Feb16_224728| [-0.62054 -2.21049  1.40981]
21Feb16_224728| [ 1.23185 -0.58090  0.35844]
21Feb16_224728| [-0.05616  0.24219 -0.02853]
21Feb16_224728| [-1.05085 -2.30259 -0.16276]
21Feb16_224728| [ 0.71087  0.14900  1.13430]
21Feb16_224728| [-2.45877 -1.20999 -1.04986]
21Feb16_224728| [-1.00480  1.36344 -0.13998]
21Feb16_224728| [ 1.83140 -0.91532  0.07616]
21Feb16_224728| [-0.60404 -2.05184  0.76948]
21Feb16_224728| [ 0.52617  0.76042 -1.76746]
21Feb16_224728| [-0.22134  0.17324  0.99530]
21Feb16_224728| [-0.36427  1.34655  0.02110]
21Feb16_224728| [-0.93125 -0.33620 -0.25012]
21Feb16_224728| [-2.76428  0.14487  0.48096]
21Feb16_224728| [-0.10518  0.35052  1.71840]
21Feb16_224728| [-1.27998  1.12568  1.26523]
21Feb16_224728| [-0.60698  1.53230 -0.60824]
21Feb16_224728| [ 0.02898  2.98718 -0.59153]
21Feb16_224728| [ 0.17588 -0.00449  0.50797]
21Feb16_224728| [-1.42674 -0.54967 -0.21310]
21Feb16_224728| [ 1.03196  1.18733  0.36755]
21Feb16_224728| [ 1.04748 -1.47444 -0.08469]
21Feb16_224728| [ 0.49410  0.38745  0.68469]
21Feb16_224728| [-0.62880  0.73245  0.19964]]
21Feb16_224728|-- Bias --
21Feb16_224728|[-0.18798  0.64571 -0.23142]
21Feb16_224728|Layer 1:
21Feb16_224728|-- Config --
21Feb16_224728|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224728|-- Weights --
21Feb16_224728|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb16_224728| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb16_224728| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb16_224728|-- Bias --
21Feb16_224728|[0.60477 0.03773 0.26452 0.12222]
21Feb16_224728|Layer 2:
21Feb16_224728|-- Config --
21Feb16_224728|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224728|-- Weights --
21Feb16_224728|[[ 0.67920  0.12119]
21Feb16_224728| [ 0.44836  0.02916]
21Feb16_224728| [ 0.68939  0.31516]
21Feb16_224728| [-0.58995 -0.05861]]
21Feb16_224728|-- Bias --
21Feb16_224728|[ 0.59649 -0.08079]
21Feb16_224728|Layer 3:
21Feb16_224728|-- Config --
21Feb16_224728|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224728|-- Weights --
21Feb16_224728|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb16_224728| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb16_224728|-- Bias --
21Feb16_224728|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb16_224728|Layer 4:
21Feb16_224728|-- Config --
21Feb16_224728|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224728|-- Weights --
21Feb16_224728|[[-0.03514 -1.04833]
21Feb16_224728| [ 1.25238  0.62094]
21Feb16_224728| [ 0.99203  0.37406]
21Feb16_224728| [ 0.49902  0.67158]
21Feb16_224728| [-1.35709  0.38335]]
21Feb16_224728|-- Bias --
21Feb16_224728|[0.31435 0.36299]
21Feb16_224728|Predicting the validation and test data with the Best final individual.
21Feb16_224735| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb16_224735|-----------  ------------------  --------------------  ----------
21Feb16_224735|Validation         23.22                  56            0.86009
21Feb16_224735|   Test            26.15                  56            0.85097
21Feb16_224735|-------------------- Test #6 --------------------
21Feb16_224735|Best final individual weights
21Feb16_224735|Individual:
21Feb16_224735|-- Constant hidden layers --
21Feb16_224735|False
21Feb16_224735|Layer 0:
21Feb16_224735|-- Config --
21Feb16_224735|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224735|-- Weights --
21Feb16_224735|[[-0.73212  1.32861  0.10200]
21Feb16_224735| [ 1.48746 -2.97273 -0.42944]
21Feb16_224735| [ 0.53095 -1.50623  0.79224]
21Feb16_224735| [-1.07292 -0.83175 -0.90105]
21Feb16_224735| [-0.48696 -0.89325  0.27226]
21Feb16_224735| [-3.02511  0.34155 -0.03837]
21Feb16_224735| [-0.76747  0.57140 -0.46892]
21Feb16_224735| [-0.07581  0.14713  0.85910]
21Feb16_224735| [-1.37488  0.52170 -0.36205]
21Feb16_224735| [ 1.60981 -0.08727 -0.11267]
21Feb16_224735| [ 0.50986  1.58916 -0.35287]
21Feb16_224735| [-0.34599  1.27113 -0.16393]
21Feb16_224735| [ 1.29203  1.19467  0.37695]
21Feb16_224735| [ 0.58704  0.06328 -0.24240]
21Feb16_224735| [-0.93888 -0.89760  0.57087]
21Feb16_224735| [ 0.99159 -0.66387  0.35177]
21Feb16_224735| [-0.67119  1.06910 -0.12512]
21Feb16_224735| [-0.91534  1.23744 -0.40465]
21Feb16_224735| [ 1.39278  0.08069  0.23328]
21Feb16_224735| [ 0.09880  0.57603 -0.96101]
21Feb16_224735| [ 0.01621 -0.13343 -0.27624]
21Feb16_224735| [-1.28286 -2.28909  0.37931]
21Feb16_224735| [-0.28370  0.09336  0.01547]
21Feb16_224735| [-0.51894  1.84280 -0.25906]
21Feb16_224735| [-0.83075 -0.04508  0.12107]
21Feb16_224735| [ 0.37343  1.18436 -0.07358]
21Feb16_224735| [-2.38657 -0.35191  0.01962]
21Feb16_224735| [ 0.95757 -0.91760 -0.08971]
21Feb16_224735| [ 0.38792 -0.01880  0.69717]
21Feb16_224735| [ 1.66877 -0.58078 -1.21129]
21Feb16_224735| [-0.50943  0.59080  0.30856]
21Feb16_224735| [ 0.30163  1.11518  0.98185]
21Feb16_224735| [-0.73226  0.32281 -0.66712]
21Feb16_224735| [-0.62054 -2.21049  1.40981]
21Feb16_224735| [ 1.23185 -0.58090  0.35844]
21Feb16_224735| [-0.05616  0.24219 -0.02853]
21Feb16_224735| [-1.05085 -2.30259 -0.16276]
21Feb16_224735| [ 0.71087  0.14900  1.13430]
21Feb16_224735| [-2.45877 -1.20999 -1.04986]
21Feb16_224735| [-1.00480  1.36344 -0.13998]
21Feb16_224735| [ 1.83140 -0.91532  0.07616]
21Feb16_224735| [-0.60404 -2.05184  0.76948]
21Feb16_224735| [ 0.52617  0.76042 -1.76746]
21Feb16_224735| [-0.22134  0.17324  0.99530]
21Feb16_224735| [-0.36427  1.34655  0.02110]
21Feb16_224735| [-0.93125 -0.33620 -0.25012]
21Feb16_224735| [-2.76428  0.14487  0.48096]
21Feb16_224735| [-0.10518  0.35052  1.71840]
21Feb16_224735| [-1.27998  1.12568  1.26523]
21Feb16_224735| [-0.60698  1.53230 -0.60824]
21Feb16_224735| [ 0.02898  2.98718 -0.59153]
21Feb16_224735| [ 0.17588 -0.00449  0.50797]
21Feb16_224735| [-1.42674 -0.54967 -0.21310]
21Feb16_224735| [ 1.03196  1.18733  0.36755]
21Feb16_224735| [ 1.04748 -1.47444 -0.08469]
21Feb16_224735| [ 0.49410  0.38745  0.68469]
21Feb16_224735| [-0.62880  0.73245  0.19964]]
21Feb16_224735|-- Bias --
21Feb16_224735|[-0.18798  0.64571 -0.23142]
21Feb16_224735|Layer 1:
21Feb16_224735|-- Config --
21Feb16_224735|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224735|-- Weights --
21Feb16_224735|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb16_224735| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb16_224735| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb16_224735|-- Bias --
21Feb16_224735|[0.60477 0.03773 0.26452 0.12222]
21Feb16_224735|Layer 2:
21Feb16_224735|-- Config --
21Feb16_224735|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224735|-- Weights --
21Feb16_224735|[[ 0.67920  0.12119]
21Feb16_224735| [ 0.44836  0.02916]
21Feb16_224735| [ 0.68939  0.31516]
21Feb16_224735| [-0.58995 -0.05861]]
21Feb16_224735|-- Bias --
21Feb16_224735|[ 0.59649 -0.08079]
21Feb16_224735|Layer 3:
21Feb16_224735|-- Config --
21Feb16_224735|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224735|-- Weights --
21Feb16_224735|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb16_224735| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb16_224735|-- Bias --
21Feb16_224735|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb16_224735|Layer 4:
21Feb16_224735|-- Config --
21Feb16_224735|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224735|-- Weights --
21Feb16_224735|[[-0.03514 -1.04833]
21Feb16_224735| [ 1.25238  0.62094]
21Feb16_224735| [ 0.99203  0.37406]
21Feb16_224735| [ 0.49902  0.67158]
21Feb16_224735| [-1.35709  0.38335]]
21Feb16_224735|-- Bias --
21Feb16_224735|[0.31435 0.36299]
21Feb16_224735|Predicting the validation and test data with the Best final individual.
21Feb16_224743| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb16_224743|-----------  ------------------  --------------------  ----------
21Feb16_224743|Validation         22.78                  56            0.83496
21Feb16_224743|   Test            21.11                  56            0.79855
21Feb16_224743|-------------------- Test #7 --------------------
21Feb16_224743|Best final individual weights
21Feb16_224743|Individual:
21Feb16_224743|-- Constant hidden layers --
21Feb16_224743|False
21Feb16_224743|Layer 0:
21Feb16_224743|-- Config --
21Feb16_224743|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224743|-- Weights --
21Feb16_224743|[[-0.73212  1.32861  0.10200]
21Feb16_224743| [ 1.48746 -2.97273 -0.42944]
21Feb16_224743| [ 0.53095 -1.50623  0.79224]
21Feb16_224743| [-1.07292 -0.83175 -0.90105]
21Feb16_224743| [-0.48696 -0.89325  0.27226]
21Feb16_224743| [-3.02511  0.34155 -0.03837]
21Feb16_224743| [-0.76747  0.57140 -0.46892]
21Feb16_224743| [-0.07581  0.14713  0.85910]
21Feb16_224743| [-1.37488  0.52170 -0.36205]
21Feb16_224743| [ 1.60981 -0.08727 -0.11267]
21Feb16_224743| [ 0.50986  1.58916 -0.35287]
21Feb16_224743| [-0.34599  1.27113 -0.16393]
21Feb16_224743| [ 1.29203  1.19467  0.37695]
21Feb16_224743| [ 0.58704  0.06328 -0.24240]
21Feb16_224743| [-0.93888 -0.89760  0.57087]
21Feb16_224743| [ 0.99159 -0.66387  0.35177]
21Feb16_224743| [-0.67119  1.06910 -0.12512]
21Feb16_224743| [-0.91534  1.23744 -0.40465]
21Feb16_224743| [ 1.39278  0.08069  0.23328]
21Feb16_224743| [ 0.09880  0.57603 -0.96101]
21Feb16_224743| [ 0.01621 -0.13343 -0.27624]
21Feb16_224743| [-1.28286 -2.28909  0.37931]
21Feb16_224743| [-0.28370  0.09336  0.01547]
21Feb16_224743| [-0.51894  1.84280 -0.25906]
21Feb16_224743| [-0.83075 -0.04508  0.12107]
21Feb16_224743| [ 0.37343  1.18436 -0.07358]
21Feb16_224743| [-2.38657 -0.35191  0.01962]
21Feb16_224743| [ 0.95757 -0.91760 -0.08971]
21Feb16_224743| [ 0.38792 -0.01880  0.69717]
21Feb16_224743| [ 1.66877 -0.58078 -1.21129]
21Feb16_224743| [-0.50943  0.59080  0.30856]
21Feb16_224743| [ 0.30163  1.11518  0.98185]
21Feb16_224743| [-0.73226  0.32281 -0.66712]
21Feb16_224743| [-0.62054 -2.21049  1.40981]
21Feb16_224743| [ 1.23185 -0.58090  0.35844]
21Feb16_224743| [-0.05616  0.24219 -0.02853]
21Feb16_224743| [-1.05085 -2.30259 -0.16276]
21Feb16_224743| [ 0.71087  0.14900  1.13430]
21Feb16_224743| [-2.45877 -1.20999 -1.04986]
21Feb16_224743| [-1.00480  1.36344 -0.13998]
21Feb16_224743| [ 1.83140 -0.91532  0.07616]
21Feb16_224743| [-0.60404 -2.05184  0.76948]
21Feb16_224743| [ 0.52617  0.76042 -1.76746]
21Feb16_224743| [-0.22134  0.17324  0.99530]
21Feb16_224743| [-0.36427  1.34655  0.02110]
21Feb16_224743| [-0.93125 -0.33620 -0.25012]
21Feb16_224743| [-2.76428  0.14487  0.48096]
21Feb16_224743| [-0.10518  0.35052  1.71840]
21Feb16_224743| [-1.27998  1.12568  1.26523]
21Feb16_224743| [-0.60698  1.53230 -0.60824]
21Feb16_224743| [ 0.02898  2.98718 -0.59153]
21Feb16_224743| [ 0.17588 -0.00449  0.50797]
21Feb16_224743| [-1.42674 -0.54967 -0.21310]
21Feb16_224743| [ 1.03196  1.18733  0.36755]
21Feb16_224743| [ 1.04748 -1.47444 -0.08469]
21Feb16_224743| [ 0.49410  0.38745  0.68469]
21Feb16_224743| [-0.62880  0.73245  0.19964]]
21Feb16_224743|-- Bias --
21Feb16_224743|[-0.18798  0.64571 -0.23142]
21Feb16_224743|Layer 1:
21Feb16_224743|-- Config --
21Feb16_224743|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224743|-- Weights --
21Feb16_224743|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb16_224743| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb16_224743| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb16_224743|-- Bias --
21Feb16_224743|[0.60477 0.03773 0.26452 0.12222]
21Feb16_224743|Layer 2:
21Feb16_224743|-- Config --
21Feb16_224743|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224743|-- Weights --
21Feb16_224743|[[ 0.67920  0.12119]
21Feb16_224743| [ 0.44836  0.02916]
21Feb16_224743| [ 0.68939  0.31516]
21Feb16_224743| [-0.58995 -0.05861]]
21Feb16_224743|-- Bias --
21Feb16_224743|[ 0.59649 -0.08079]
21Feb16_224743|Layer 3:
21Feb16_224743|-- Config --
21Feb16_224743|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224743|-- Weights --
21Feb16_224743|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb16_224743| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb16_224743|-- Bias --
21Feb16_224743|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb16_224743|Layer 4:
21Feb16_224743|-- Config --
21Feb16_224743|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224743|-- Weights --
21Feb16_224743|[[-0.03514 -1.04833]
21Feb16_224743| [ 1.25238  0.62094]
21Feb16_224743| [ 0.99203  0.37406]
21Feb16_224743| [ 0.49902  0.67158]
21Feb16_224743| [-1.35709  0.38335]]
21Feb16_224743|-- Bias --
21Feb16_224743|[0.31435 0.36299]
21Feb16_224743|Predicting the validation and test data with the Best final individual.
21Feb16_224751| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb16_224751|-----------  ------------------  --------------------  ----------
21Feb16_224751|Validation         28.96                  56            0.48780
21Feb16_224751|   Test            25.46                  56            0.49431
21Feb16_224751|-------------------- Test #8 --------------------
21Feb16_224751|Best final individual weights
21Feb16_224751|Individual:
21Feb16_224751|-- Constant hidden layers --
21Feb16_224751|False
21Feb16_224751|Layer 0:
21Feb16_224751|-- Config --
21Feb16_224751|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224751|-- Weights --
21Feb16_224751|[[-0.73212  1.32861  0.10200]
21Feb16_224751| [ 1.48746 -2.97273 -0.42944]
21Feb16_224751| [ 0.53095 -1.50623  0.79224]
21Feb16_224751| [-1.07292 -0.83175 -0.90105]
21Feb16_224751| [-0.48696 -0.89325  0.27226]
21Feb16_224751| [-3.02511  0.34155 -0.03837]
21Feb16_224751| [-0.76747  0.57140 -0.46892]
21Feb16_224751| [-0.07581  0.14713  0.85910]
21Feb16_224751| [-1.37488  0.52170 -0.36205]
21Feb16_224751| [ 1.60981 -0.08727 -0.11267]
21Feb16_224751| [ 0.50986  1.58916 -0.35287]
21Feb16_224751| [-0.34599  1.27113 -0.16393]
21Feb16_224751| [ 1.29203  1.19467  0.37695]
21Feb16_224751| [ 0.58704  0.06328 -0.24240]
21Feb16_224751| [-0.93888 -0.89760  0.57087]
21Feb16_224751| [ 0.99159 -0.66387  0.35177]
21Feb16_224751| [-0.67119  1.06910 -0.12512]
21Feb16_224751| [-0.91534  1.23744 -0.40465]
21Feb16_224751| [ 1.39278  0.08069  0.23328]
21Feb16_224751| [ 0.09880  0.57603 -0.96101]
21Feb16_224751| [ 0.01621 -0.13343 -0.27624]
21Feb16_224751| [-1.28286 -2.28909  0.37931]
21Feb16_224751| [-0.28370  0.09336  0.01547]
21Feb16_224751| [-0.51894  1.84280 -0.25906]
21Feb16_224751| [-0.83075 -0.04508  0.12107]
21Feb16_224751| [ 0.37343  1.18436 -0.07358]
21Feb16_224751| [-2.38657 -0.35191  0.01962]
21Feb16_224751| [ 0.95757 -0.91760 -0.08971]
21Feb16_224751| [ 0.38792 -0.01880  0.69717]
21Feb16_224751| [ 1.66877 -0.58078 -1.21129]
21Feb16_224751| [-0.50943  0.59080  0.30856]
21Feb16_224751| [ 0.30163  1.11518  0.98185]
21Feb16_224751| [-0.73226  0.32281 -0.66712]
21Feb16_224751| [-0.62054 -2.21049  1.40981]
21Feb16_224751| [ 1.23185 -0.58090  0.35844]
21Feb16_224751| [-0.05616  0.24219 -0.02853]
21Feb16_224751| [-1.05085 -2.30259 -0.16276]
21Feb16_224751| [ 0.71087  0.14900  1.13430]
21Feb16_224751| [-2.45877 -1.20999 -1.04986]
21Feb16_224751| [-1.00480  1.36344 -0.13998]
21Feb16_224751| [ 1.83140 -0.91532  0.07616]
21Feb16_224751| [-0.60404 -2.05184  0.76948]
21Feb16_224751| [ 0.52617  0.76042 -1.76746]
21Feb16_224751| [-0.22134  0.17324  0.99530]
21Feb16_224751| [-0.36427  1.34655  0.02110]
21Feb16_224751| [-0.93125 -0.33620 -0.25012]
21Feb16_224751| [-2.76428  0.14487  0.48096]
21Feb16_224751| [-0.10518  0.35052  1.71840]
21Feb16_224751| [-1.27998  1.12568  1.26523]
21Feb16_224751| [-0.60698  1.53230 -0.60824]
21Feb16_224751| [ 0.02898  2.98718 -0.59153]
21Feb16_224751| [ 0.17588 -0.00449  0.50797]
21Feb16_224751| [-1.42674 -0.54967 -0.21310]
21Feb16_224751| [ 1.03196  1.18733  0.36755]
21Feb16_224751| [ 1.04748 -1.47444 -0.08469]
21Feb16_224751| [ 0.49410  0.38745  0.68469]
21Feb16_224751| [-0.62880  0.73245  0.19964]]
21Feb16_224751|-- Bias --
21Feb16_224751|[-0.18798  0.64571 -0.23142]
21Feb16_224751|Layer 1:
21Feb16_224751|-- Config --
21Feb16_224751|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224751|-- Weights --
21Feb16_224751|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb16_224751| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb16_224751| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb16_224751|-- Bias --
21Feb16_224751|[0.60477 0.03773 0.26452 0.12222]
21Feb16_224751|Layer 2:
21Feb16_224751|-- Config --
21Feb16_224751|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224751|-- Weights --
21Feb16_224751|[[ 0.67920  0.12119]
21Feb16_224751| [ 0.44836  0.02916]
21Feb16_224751| [ 0.68939  0.31516]
21Feb16_224751| [-0.58995 -0.05861]]
21Feb16_224751|-- Bias --
21Feb16_224751|[ 0.59649 -0.08079]
21Feb16_224751|Layer 3:
21Feb16_224751|-- Config --
21Feb16_224751|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224751|-- Weights --
21Feb16_224751|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb16_224751| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb16_224751|-- Bias --
21Feb16_224751|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb16_224751|Layer 4:
21Feb16_224751|-- Config --
21Feb16_224751|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224751|-- Weights --
21Feb16_224751|[[-0.03514 -1.04833]
21Feb16_224751| [ 1.25238  0.62094]
21Feb16_224751| [ 0.99203  0.37406]
21Feb16_224751| [ 0.49902  0.67158]
21Feb16_224751| [-1.35709  0.38335]]
21Feb16_224751|-- Bias --
21Feb16_224751|[0.31435 0.36299]
21Feb16_224751|Predicting the validation and test data with the Best final individual.
21Feb16_224759| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb16_224759|-----------  ------------------  --------------------  ----------
21Feb16_224759|Validation         21.30                  56            0.82476
21Feb16_224759|   Test            21.81                  56            0.83186
21Feb16_224759|-------------------- Test #9 --------------------
21Feb16_224759|Best final individual weights
21Feb16_224759|Individual:
21Feb16_224759|-- Constant hidden layers --
21Feb16_224759|False
21Feb16_224759|Layer 0:
21Feb16_224759|-- Config --
21Feb16_224759|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224759|-- Weights --
21Feb16_224759|[[-0.73212  1.32861  0.10200]
21Feb16_224759| [ 1.48746 -2.97273 -0.42944]
21Feb16_224759| [ 0.53095 -1.50623  0.79224]
21Feb16_224759| [-1.07292 -0.83175 -0.90105]
21Feb16_224759| [-0.48696 -0.89325  0.27226]
21Feb16_224759| [-3.02511  0.34155 -0.03837]
21Feb16_224759| [-0.76747  0.57140 -0.46892]
21Feb16_224759| [-0.07581  0.14713  0.85910]
21Feb16_224759| [-1.37488  0.52170 -0.36205]
21Feb16_224759| [ 1.60981 -0.08727 -0.11267]
21Feb16_224759| [ 0.50986  1.58916 -0.35287]
21Feb16_224759| [-0.34599  1.27113 -0.16393]
21Feb16_224759| [ 1.29203  1.19467  0.37695]
21Feb16_224759| [ 0.58704  0.06328 -0.24240]
21Feb16_224759| [-0.93888 -0.89760  0.57087]
21Feb16_224759| [ 0.99159 -0.66387  0.35177]
21Feb16_224759| [-0.67119  1.06910 -0.12512]
21Feb16_224759| [-0.91534  1.23744 -0.40465]
21Feb16_224759| [ 1.39278  0.08069  0.23328]
21Feb16_224759| [ 0.09880  0.57603 -0.96101]
21Feb16_224759| [ 0.01621 -0.13343 -0.27624]
21Feb16_224759| [-1.28286 -2.28909  0.37931]
21Feb16_224759| [-0.28370  0.09336  0.01547]
21Feb16_224759| [-0.51894  1.84280 -0.25906]
21Feb16_224759| [-0.83075 -0.04508  0.12107]
21Feb16_224759| [ 0.37343  1.18436 -0.07358]
21Feb16_224759| [-2.38657 -0.35191  0.01962]
21Feb16_224759| [ 0.95757 -0.91760 -0.08971]
21Feb16_224759| [ 0.38792 -0.01880  0.69717]
21Feb16_224759| [ 1.66877 -0.58078 -1.21129]
21Feb16_224759| [-0.50943  0.59080  0.30856]
21Feb16_224759| [ 0.30163  1.11518  0.98185]
21Feb16_224759| [-0.73226  0.32281 -0.66712]
21Feb16_224759| [-0.62054 -2.21049  1.40981]
21Feb16_224759| [ 1.23185 -0.58090  0.35844]
21Feb16_224759| [-0.05616  0.24219 -0.02853]
21Feb16_224759| [-1.05085 -2.30259 -0.16276]
21Feb16_224759| [ 0.71087  0.14900  1.13430]
21Feb16_224759| [-2.45877 -1.20999 -1.04986]
21Feb16_224759| [-1.00480  1.36344 -0.13998]
21Feb16_224759| [ 1.83140 -0.91532  0.07616]
21Feb16_224759| [-0.60404 -2.05184  0.76948]
21Feb16_224759| [ 0.52617  0.76042 -1.76746]
21Feb16_224759| [-0.22134  0.17324  0.99530]
21Feb16_224759| [-0.36427  1.34655  0.02110]
21Feb16_224759| [-0.93125 -0.33620 -0.25012]
21Feb16_224759| [-2.76428  0.14487  0.48096]
21Feb16_224759| [-0.10518  0.35052  1.71840]
21Feb16_224759| [-1.27998  1.12568  1.26523]
21Feb16_224759| [-0.60698  1.53230 -0.60824]
21Feb16_224759| [ 0.02898  2.98718 -0.59153]
21Feb16_224759| [ 0.17588 -0.00449  0.50797]
21Feb16_224759| [-1.42674 -0.54967 -0.21310]
21Feb16_224759| [ 1.03196  1.18733  0.36755]
21Feb16_224759| [ 1.04748 -1.47444 -0.08469]
21Feb16_224759| [ 0.49410  0.38745  0.68469]
21Feb16_224759| [-0.62880  0.73245  0.19964]]
21Feb16_224759|-- Bias --
21Feb16_224759|[-0.18798  0.64571 -0.23142]
21Feb16_224759|Layer 1:
21Feb16_224759|-- Config --
21Feb16_224759|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224759|-- Weights --
21Feb16_224759|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb16_224759| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb16_224759| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb16_224759|-- Bias --
21Feb16_224759|[0.60477 0.03773 0.26452 0.12222]
21Feb16_224759|Layer 2:
21Feb16_224759|-- Config --
21Feb16_224759|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224759|-- Weights --
21Feb16_224759|[[ 0.67920  0.12119]
21Feb16_224759| [ 0.44836  0.02916]
21Feb16_224759| [ 0.68939  0.31516]
21Feb16_224759| [-0.58995 -0.05861]]
21Feb16_224759|-- Bias --
21Feb16_224759|[ 0.59649 -0.08079]
21Feb16_224759|Layer 3:
21Feb16_224759|-- Config --
21Feb16_224759|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224759|-- Weights --
21Feb16_224759|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb16_224759| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb16_224759|-- Bias --
21Feb16_224759|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb16_224759|Layer 4:
21Feb16_224759|-- Config --
21Feb16_224759|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224759|-- Weights --
21Feb16_224759|[[-0.03514 -1.04833]
21Feb16_224759| [ 1.25238  0.62094]
21Feb16_224759| [ 0.99203  0.37406]
21Feb16_224759| [ 0.49902  0.67158]
21Feb16_224759| [-1.35709  0.38335]]
21Feb16_224759|-- Bias --
21Feb16_224759|[0.31435 0.36299]
21Feb16_224759|Predicting the validation and test data with the Best final individual.
21Feb16_224806| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb16_224806|-----------  ------------------  --------------------  ----------
21Feb16_224806|Validation         26.43                  56            0.71922
21Feb16_224806|   Test            29.54                  56            0.67444
21Feb16_224806|-------------------- Test #10 --------------------
21Feb16_224806|Best final individual weights
21Feb16_224806|Individual:
21Feb16_224806|-- Constant hidden layers --
21Feb16_224806|False
21Feb16_224806|Layer 0:
21Feb16_224806|-- Config --
21Feb16_224806|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224806|-- Weights --
21Feb16_224806|[[-0.73212  1.32861  0.10200]
21Feb16_224806| [ 1.48746 -2.97273 -0.42944]
21Feb16_224806| [ 0.53095 -1.50623  0.79224]
21Feb16_224806| [-1.07292 -0.83175 -0.90105]
21Feb16_224806| [-0.48696 -0.89325  0.27226]
21Feb16_224806| [-3.02511  0.34155 -0.03837]
21Feb16_224806| [-0.76747  0.57140 -0.46892]
21Feb16_224806| [-0.07581  0.14713  0.85910]
21Feb16_224806| [-1.37488  0.52170 -0.36205]
21Feb16_224806| [ 1.60981 -0.08727 -0.11267]
21Feb16_224806| [ 0.50986  1.58916 -0.35287]
21Feb16_224806| [-0.34599  1.27113 -0.16393]
21Feb16_224806| [ 1.29203  1.19467  0.37695]
21Feb16_224806| [ 0.58704  0.06328 -0.24240]
21Feb16_224806| [-0.93888 -0.89760  0.57087]
21Feb16_224806| [ 0.99159 -0.66387  0.35177]
21Feb16_224806| [-0.67119  1.06910 -0.12512]
21Feb16_224806| [-0.91534  1.23744 -0.40465]
21Feb16_224806| [ 1.39278  0.08069  0.23328]
21Feb16_224806| [ 0.09880  0.57603 -0.96101]
21Feb16_224806| [ 0.01621 -0.13343 -0.27624]
21Feb16_224806| [-1.28286 -2.28909  0.37931]
21Feb16_224806| [-0.28370  0.09336  0.01547]
21Feb16_224806| [-0.51894  1.84280 -0.25906]
21Feb16_224806| [-0.83075 -0.04508  0.12107]
21Feb16_224806| [ 0.37343  1.18436 -0.07358]
21Feb16_224806| [-2.38657 -0.35191  0.01962]
21Feb16_224806| [ 0.95757 -0.91760 -0.08971]
21Feb16_224806| [ 0.38792 -0.01880  0.69717]
21Feb16_224806| [ 1.66877 -0.58078 -1.21129]
21Feb16_224806| [-0.50943  0.59080  0.30856]
21Feb16_224806| [ 0.30163  1.11518  0.98185]
21Feb16_224806| [-0.73226  0.32281 -0.66712]
21Feb16_224806| [-0.62054 -2.21049  1.40981]
21Feb16_224806| [ 1.23185 -0.58090  0.35844]
21Feb16_224806| [-0.05616  0.24219 -0.02853]
21Feb16_224806| [-1.05085 -2.30259 -0.16276]
21Feb16_224806| [ 0.71087  0.14900  1.13430]
21Feb16_224806| [-2.45877 -1.20999 -1.04986]
21Feb16_224806| [-1.00480  1.36344 -0.13998]
21Feb16_224806| [ 1.83140 -0.91532  0.07616]
21Feb16_224806| [-0.60404 -2.05184  0.76948]
21Feb16_224806| [ 0.52617  0.76042 -1.76746]
21Feb16_224806| [-0.22134  0.17324  0.99530]
21Feb16_224806| [-0.36427  1.34655  0.02110]
21Feb16_224806| [-0.93125 -0.33620 -0.25012]
21Feb16_224806| [-2.76428  0.14487  0.48096]
21Feb16_224806| [-0.10518  0.35052  1.71840]
21Feb16_224806| [-1.27998  1.12568  1.26523]
21Feb16_224806| [-0.60698  1.53230 -0.60824]
21Feb16_224806| [ 0.02898  2.98718 -0.59153]
21Feb16_224806| [ 0.17588 -0.00449  0.50797]
21Feb16_224806| [-1.42674 -0.54967 -0.21310]
21Feb16_224806| [ 1.03196  1.18733  0.36755]
21Feb16_224806| [ 1.04748 -1.47444 -0.08469]
21Feb16_224806| [ 0.49410  0.38745  0.68469]
21Feb16_224806| [-0.62880  0.73245  0.19964]]
21Feb16_224806|-- Bias --
21Feb16_224806|[-0.18798  0.64571 -0.23142]
21Feb16_224806|Layer 1:
21Feb16_224806|-- Config --
21Feb16_224806|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224806|-- Weights --
21Feb16_224806|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb16_224806| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb16_224806| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb16_224806|-- Bias --
21Feb16_224806|[0.60477 0.03773 0.26452 0.12222]
21Feb16_224806|Layer 2:
21Feb16_224806|-- Config --
21Feb16_224806|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224806|-- Weights --
21Feb16_224806|[[ 0.67920  0.12119]
21Feb16_224806| [ 0.44836  0.02916]
21Feb16_224806| [ 0.68939  0.31516]
21Feb16_224806| [-0.58995 -0.05861]]
21Feb16_224806|-- Bias --
21Feb16_224806|[ 0.59649 -0.08079]
21Feb16_224806|Layer 3:
21Feb16_224806|-- Config --
21Feb16_224806|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224806|-- Weights --
21Feb16_224806|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb16_224806| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb16_224806|-- Bias --
21Feb16_224806|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb16_224806|Layer 4:
21Feb16_224806|-- Config --
21Feb16_224806|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224806|-- Weights --
21Feb16_224806|[[-0.03514 -1.04833]
21Feb16_224806| [ 1.25238  0.62094]
21Feb16_224806| [ 0.99203  0.37406]
21Feb16_224806| [ 0.49902  0.67158]
21Feb16_224806| [-1.35709  0.38335]]
21Feb16_224806|-- Bias --
21Feb16_224806|[0.31435 0.36299]
21Feb16_224806|Predicting the validation and test data with the Best final individual.
21Feb16_224814| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb16_224814|-----------  ------------------  --------------------  ----------
21Feb16_224814|Validation         23.65                  56            0.85845
21Feb16_224814|   Test            26.67                  56            0.71298
21Feb16_224814|-------------------- Test #11 --------------------
21Feb16_224814|Best final individual weights
21Feb16_224814|Individual:
21Feb16_224814|-- Constant hidden layers --
21Feb16_224814|False
21Feb16_224814|Layer 0:
21Feb16_224814|-- Config --
21Feb16_224814|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224814|-- Weights --
21Feb16_224814|[[-0.73212  1.32861  0.10200]
21Feb16_224814| [ 1.48746 -2.97273 -0.42944]
21Feb16_224814| [ 0.53095 -1.50623  0.79224]
21Feb16_224814| [-1.07292 -0.83175 -0.90105]
21Feb16_224814| [-0.48696 -0.89325  0.27226]
21Feb16_224814| [-3.02511  0.34155 -0.03837]
21Feb16_224814| [-0.76747  0.57140 -0.46892]
21Feb16_224814| [-0.07581  0.14713  0.85910]
21Feb16_224814| [-1.37488  0.52170 -0.36205]
21Feb16_224814| [ 1.60981 -0.08727 -0.11267]
21Feb16_224814| [ 0.50986  1.58916 -0.35287]
21Feb16_224814| [-0.34599  1.27113 -0.16393]
21Feb16_224814| [ 1.29203  1.19467  0.37695]
21Feb16_224814| [ 0.58704  0.06328 -0.24240]
21Feb16_224814| [-0.93888 -0.89760  0.57087]
21Feb16_224814| [ 0.99159 -0.66387  0.35177]
21Feb16_224814| [-0.67119  1.06910 -0.12512]
21Feb16_224814| [-0.91534  1.23744 -0.40465]
21Feb16_224814| [ 1.39278  0.08069  0.23328]
21Feb16_224814| [ 0.09880  0.57603 -0.96101]
21Feb16_224814| [ 0.01621 -0.13343 -0.27624]
21Feb16_224814| [-1.28286 -2.28909  0.37931]
21Feb16_224814| [-0.28370  0.09336  0.01547]
21Feb16_224814| [-0.51894  1.84280 -0.25906]
21Feb16_224814| [-0.83075 -0.04508  0.12107]
21Feb16_224814| [ 0.37343  1.18436 -0.07358]
21Feb16_224814| [-2.38657 -0.35191  0.01962]
21Feb16_224814| [ 0.95757 -0.91760 -0.08971]
21Feb16_224814| [ 0.38792 -0.01880  0.69717]
21Feb16_224814| [ 1.66877 -0.58078 -1.21129]
21Feb16_224814| [-0.50943  0.59080  0.30856]
21Feb16_224814| [ 0.30163  1.11518  0.98185]
21Feb16_224814| [-0.73226  0.32281 -0.66712]
21Feb16_224814| [-0.62054 -2.21049  1.40981]
21Feb16_224814| [ 1.23185 -0.58090  0.35844]
21Feb16_224814| [-0.05616  0.24219 -0.02853]
21Feb16_224814| [-1.05085 -2.30259 -0.16276]
21Feb16_224814| [ 0.71087  0.14900  1.13430]
21Feb16_224814| [-2.45877 -1.20999 -1.04986]
21Feb16_224814| [-1.00480  1.36344 -0.13998]
21Feb16_224814| [ 1.83140 -0.91532  0.07616]
21Feb16_224814| [-0.60404 -2.05184  0.76948]
21Feb16_224814| [ 0.52617  0.76042 -1.76746]
21Feb16_224814| [-0.22134  0.17324  0.99530]
21Feb16_224814| [-0.36427  1.34655  0.02110]
21Feb16_224814| [-0.93125 -0.33620 -0.25012]
21Feb16_224814| [-2.76428  0.14487  0.48096]
21Feb16_224814| [-0.10518  0.35052  1.71840]
21Feb16_224814| [-1.27998  1.12568  1.26523]
21Feb16_224814| [-0.60698  1.53230 -0.60824]
21Feb16_224814| [ 0.02898  2.98718 -0.59153]
21Feb16_224814| [ 0.17588 -0.00449  0.50797]
21Feb16_224814| [-1.42674 -0.54967 -0.21310]
21Feb16_224814| [ 1.03196  1.18733  0.36755]
21Feb16_224814| [ 1.04748 -1.47444 -0.08469]
21Feb16_224814| [ 0.49410  0.38745  0.68469]
21Feb16_224814| [-0.62880  0.73245  0.19964]]
21Feb16_224814|-- Bias --
21Feb16_224814|[-0.18798  0.64571 -0.23142]
21Feb16_224814|Layer 1:
21Feb16_224814|-- Config --
21Feb16_224814|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224814|-- Weights --
21Feb16_224814|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb16_224814| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb16_224814| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb16_224814|-- Bias --
21Feb16_224814|[0.60477 0.03773 0.26452 0.12222]
21Feb16_224814|Layer 2:
21Feb16_224814|-- Config --
21Feb16_224814|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224814|-- Weights --
21Feb16_224814|[[ 0.67920  0.12119]
21Feb16_224814| [ 0.44836  0.02916]
21Feb16_224814| [ 0.68939  0.31516]
21Feb16_224814| [-0.58995 -0.05861]]
21Feb16_224814|-- Bias --
21Feb16_224814|[ 0.59649 -0.08079]
21Feb16_224814|Layer 3:
21Feb16_224814|-- Config --
21Feb16_224814|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224814|-- Weights --
21Feb16_224814|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb16_224814| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb16_224814|-- Bias --
21Feb16_224814|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb16_224814|Layer 4:
21Feb16_224814|-- Config --
21Feb16_224814|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224814|-- Weights --
21Feb16_224814|[[-0.03514 -1.04833]
21Feb16_224814| [ 1.25238  0.62094]
21Feb16_224814| [ 0.99203  0.37406]
21Feb16_224814| [ 0.49902  0.67158]
21Feb16_224814| [-1.35709  0.38335]]
21Feb16_224814|-- Bias --
21Feb16_224814|[0.31435 0.36299]
21Feb16_224814|Predicting the validation and test data with the Best final individual.
21Feb16_224822| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb16_224822|-----------  ------------------  --------------------  ----------
21Feb16_224822|Validation         23.48                  56            0.78306
21Feb16_224822|   Test            22.07                  56            0.85403
21Feb16_224822|-------------------- Test #12 --------------------
21Feb16_224822|Best final individual weights
21Feb16_224822|Individual:
21Feb16_224822|-- Constant hidden layers --
21Feb16_224822|False
21Feb16_224822|Layer 0:
21Feb16_224822|-- Config --
21Feb16_224822|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224822|-- Weights --
21Feb16_224822|[[-0.73212  1.32861  0.10200]
21Feb16_224822| [ 1.48746 -2.97273 -0.42944]
21Feb16_224822| [ 0.53095 -1.50623  0.79224]
21Feb16_224822| [-1.07292 -0.83175 -0.90105]
21Feb16_224822| [-0.48696 -0.89325  0.27226]
21Feb16_224822| [-3.02511  0.34155 -0.03837]
21Feb16_224822| [-0.76747  0.57140 -0.46892]
21Feb16_224822| [-0.07581  0.14713  0.85910]
21Feb16_224822| [-1.37488  0.52170 -0.36205]
21Feb16_224822| [ 1.60981 -0.08727 -0.11267]
21Feb16_224822| [ 0.50986  1.58916 -0.35287]
21Feb16_224822| [-0.34599  1.27113 -0.16393]
21Feb16_224822| [ 1.29203  1.19467  0.37695]
21Feb16_224822| [ 0.58704  0.06328 -0.24240]
21Feb16_224822| [-0.93888 -0.89760  0.57087]
21Feb16_224822| [ 0.99159 -0.66387  0.35177]
21Feb16_224822| [-0.67119  1.06910 -0.12512]
21Feb16_224822| [-0.91534  1.23744 -0.40465]
21Feb16_224822| [ 1.39278  0.08069  0.23328]
21Feb16_224822| [ 0.09880  0.57603 -0.96101]
21Feb16_224822| [ 0.01621 -0.13343 -0.27624]
21Feb16_224822| [-1.28286 -2.28909  0.37931]
21Feb16_224822| [-0.28370  0.09336  0.01547]
21Feb16_224822| [-0.51894  1.84280 -0.25906]
21Feb16_224822| [-0.83075 -0.04508  0.12107]
21Feb16_224822| [ 0.37343  1.18436 -0.07358]
21Feb16_224822| [-2.38657 -0.35191  0.01962]
21Feb16_224822| [ 0.95757 -0.91760 -0.08971]
21Feb16_224822| [ 0.38792 -0.01880  0.69717]
21Feb16_224822| [ 1.66877 -0.58078 -1.21129]
21Feb16_224822| [-0.50943  0.59080  0.30856]
21Feb16_224822| [ 0.30163  1.11518  0.98185]
21Feb16_224822| [-0.73226  0.32281 -0.66712]
21Feb16_224822| [-0.62054 -2.21049  1.40981]
21Feb16_224822| [ 1.23185 -0.58090  0.35844]
21Feb16_224822| [-0.05616  0.24219 -0.02853]
21Feb16_224822| [-1.05085 -2.30259 -0.16276]
21Feb16_224822| [ 0.71087  0.14900  1.13430]
21Feb16_224822| [-2.45877 -1.20999 -1.04986]
21Feb16_224822| [-1.00480  1.36344 -0.13998]
21Feb16_224822| [ 1.83140 -0.91532  0.07616]
21Feb16_224822| [-0.60404 -2.05184  0.76948]
21Feb16_224822| [ 0.52617  0.76042 -1.76746]
21Feb16_224822| [-0.22134  0.17324  0.99530]
21Feb16_224822| [-0.36427  1.34655  0.02110]
21Feb16_224822| [-0.93125 -0.33620 -0.25012]
21Feb16_224822| [-2.76428  0.14487  0.48096]
21Feb16_224822| [-0.10518  0.35052  1.71840]
21Feb16_224822| [-1.27998  1.12568  1.26523]
21Feb16_224822| [-0.60698  1.53230 -0.60824]
21Feb16_224822| [ 0.02898  2.98718 -0.59153]
21Feb16_224822| [ 0.17588 -0.00449  0.50797]
21Feb16_224822| [-1.42674 -0.54967 -0.21310]
21Feb16_224822| [ 1.03196  1.18733  0.36755]
21Feb16_224822| [ 1.04748 -1.47444 -0.08469]
21Feb16_224822| [ 0.49410  0.38745  0.68469]
21Feb16_224822| [-0.62880  0.73245  0.19964]]
21Feb16_224822|-- Bias --
21Feb16_224822|[-0.18798  0.64571 -0.23142]
21Feb16_224822|Layer 1:
21Feb16_224822|-- Config --
21Feb16_224822|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224822|-- Weights --
21Feb16_224822|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb16_224822| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb16_224822| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb16_224822|-- Bias --
21Feb16_224822|[0.60477 0.03773 0.26452 0.12222]
21Feb16_224822|Layer 2:
21Feb16_224822|-- Config --
21Feb16_224822|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224822|-- Weights --
21Feb16_224822|[[ 0.67920  0.12119]
21Feb16_224822| [ 0.44836  0.02916]
21Feb16_224822| [ 0.68939  0.31516]
21Feb16_224822| [-0.58995 -0.05861]]
21Feb16_224822|-- Bias --
21Feb16_224822|[ 0.59649 -0.08079]
21Feb16_224822|Layer 3:
21Feb16_224822|-- Config --
21Feb16_224822|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224822|-- Weights --
21Feb16_224822|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb16_224822| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb16_224822|-- Bias --
21Feb16_224822|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb16_224822|Layer 4:
21Feb16_224822|-- Config --
21Feb16_224822|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224822|-- Weights --
21Feb16_224822|[[-0.03514 -1.04833]
21Feb16_224822| [ 1.25238  0.62094]
21Feb16_224822| [ 0.99203  0.37406]
21Feb16_224822| [ 0.49902  0.67158]
21Feb16_224822| [-1.35709  0.38335]]
21Feb16_224822|-- Bias --
21Feb16_224822|[0.31435 0.36299]
21Feb16_224822|Predicting the validation and test data with the Best final individual.
21Feb16_224830| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb16_224830|-----------  ------------------  --------------------  ----------
21Feb16_224830|Validation         24.43                  56            0.85301
21Feb16_224830|   Test            37.01                  56            0.82036
21Feb16_224830|-------------------- Test #13 --------------------
21Feb16_224830|Best final individual weights
21Feb16_224830|Individual:
21Feb16_224830|-- Constant hidden layers --
21Feb16_224830|False
21Feb16_224830|Layer 0:
21Feb16_224830|-- Config --
21Feb16_224830|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224830|-- Weights --
21Feb16_224830|[[-0.73212  1.32861  0.10200]
21Feb16_224830| [ 1.48746 -2.97273 -0.42944]
21Feb16_224830| [ 0.53095 -1.50623  0.79224]
21Feb16_224830| [-1.07292 -0.83175 -0.90105]
21Feb16_224830| [-0.48696 -0.89325  0.27226]
21Feb16_224830| [-3.02511  0.34155 -0.03837]
21Feb16_224830| [-0.76747  0.57140 -0.46892]
21Feb16_224830| [-0.07581  0.14713  0.85910]
21Feb16_224830| [-1.37488  0.52170 -0.36205]
21Feb16_224830| [ 1.60981 -0.08727 -0.11267]
21Feb16_224830| [ 0.50986  1.58916 -0.35287]
21Feb16_224830| [-0.34599  1.27113 -0.16393]
21Feb16_224830| [ 1.29203  1.19467  0.37695]
21Feb16_224830| [ 0.58704  0.06328 -0.24240]
21Feb16_224830| [-0.93888 -0.89760  0.57087]
21Feb16_224830| [ 0.99159 -0.66387  0.35177]
21Feb16_224830| [-0.67119  1.06910 -0.12512]
21Feb16_224830| [-0.91534  1.23744 -0.40465]
21Feb16_224830| [ 1.39278  0.08069  0.23328]
21Feb16_224830| [ 0.09880  0.57603 -0.96101]
21Feb16_224830| [ 0.01621 -0.13343 -0.27624]
21Feb16_224830| [-1.28286 -2.28909  0.37931]
21Feb16_224830| [-0.28370  0.09336  0.01547]
21Feb16_224830| [-0.51894  1.84280 -0.25906]
21Feb16_224830| [-0.83075 -0.04508  0.12107]
21Feb16_224830| [ 0.37343  1.18436 -0.07358]
21Feb16_224830| [-2.38657 -0.35191  0.01962]
21Feb16_224830| [ 0.95757 -0.91760 -0.08971]
21Feb16_224830| [ 0.38792 -0.01880  0.69717]
21Feb16_224830| [ 1.66877 -0.58078 -1.21129]
21Feb16_224830| [-0.50943  0.59080  0.30856]
21Feb16_224830| [ 0.30163  1.11518  0.98185]
21Feb16_224830| [-0.73226  0.32281 -0.66712]
21Feb16_224830| [-0.62054 -2.21049  1.40981]
21Feb16_224830| [ 1.23185 -0.58090  0.35844]
21Feb16_224830| [-0.05616  0.24219 -0.02853]
21Feb16_224830| [-1.05085 -2.30259 -0.16276]
21Feb16_224830| [ 0.71087  0.14900  1.13430]
21Feb16_224830| [-2.45877 -1.20999 -1.04986]
21Feb16_224830| [-1.00480  1.36344 -0.13998]
21Feb16_224830| [ 1.83140 -0.91532  0.07616]
21Feb16_224830| [-0.60404 -2.05184  0.76948]
21Feb16_224830| [ 0.52617  0.76042 -1.76746]
21Feb16_224830| [-0.22134  0.17324  0.99530]
21Feb16_224830| [-0.36427  1.34655  0.02110]
21Feb16_224830| [-0.93125 -0.33620 -0.25012]
21Feb16_224830| [-2.76428  0.14487  0.48096]
21Feb16_224830| [-0.10518  0.35052  1.71840]
21Feb16_224830| [-1.27998  1.12568  1.26523]
21Feb16_224830| [-0.60698  1.53230 -0.60824]
21Feb16_224830| [ 0.02898  2.98718 -0.59153]
21Feb16_224830| [ 0.17588 -0.00449  0.50797]
21Feb16_224830| [-1.42674 -0.54967 -0.21310]
21Feb16_224830| [ 1.03196  1.18733  0.36755]
21Feb16_224830| [ 1.04748 -1.47444 -0.08469]
21Feb16_224830| [ 0.49410  0.38745  0.68469]
21Feb16_224830| [-0.62880  0.73245  0.19964]]
21Feb16_224830|-- Bias --
21Feb16_224830|[-0.18798  0.64571 -0.23142]
21Feb16_224830|Layer 1:
21Feb16_224830|-- Config --
21Feb16_224830|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224830|-- Weights --
21Feb16_224830|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb16_224830| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb16_224830| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb16_224830|-- Bias --
21Feb16_224830|[0.60477 0.03773 0.26452 0.12222]
21Feb16_224830|Layer 2:
21Feb16_224830|-- Config --
21Feb16_224830|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224830|-- Weights --
21Feb16_224830|[[ 0.67920  0.12119]
21Feb16_224830| [ 0.44836  0.02916]
21Feb16_224830| [ 0.68939  0.31516]
21Feb16_224830| [-0.58995 -0.05861]]
21Feb16_224830|-- Bias --
21Feb16_224830|[ 0.59649 -0.08079]
21Feb16_224830|Layer 3:
21Feb16_224830|-- Config --
21Feb16_224830|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224830|-- Weights --
21Feb16_224830|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb16_224830| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb16_224830|-- Bias --
21Feb16_224830|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb16_224830|Layer 4:
21Feb16_224830|-- Config --
21Feb16_224830|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224830|-- Weights --
21Feb16_224830|[[-0.03514 -1.04833]
21Feb16_224830| [ 1.25238  0.62094]
21Feb16_224830| [ 0.99203  0.37406]
21Feb16_224830| [ 0.49902  0.67158]
21Feb16_224830| [-1.35709  0.38335]]
21Feb16_224830|-- Bias --
21Feb16_224830|[0.31435 0.36299]
21Feb16_224830|Predicting the validation and test data with the Best final individual.
21Feb16_224837| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb16_224837|-----------  ------------------  --------------------  ----------
21Feb16_224837|Validation         21.74                  56            0.74120
21Feb16_224837|   Test            25.80                  56            0.72926
21Feb16_224837|-------------------- Test #14 --------------------
21Feb16_224837|Best final individual weights
21Feb16_224837|Individual:
21Feb16_224837|-- Constant hidden layers --
21Feb16_224837|False
21Feb16_224837|Layer 0:
21Feb16_224837|-- Config --
21Feb16_224837|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224837|-- Weights --
21Feb16_224837|[[-0.73212  1.32861  0.10200]
21Feb16_224837| [ 1.48746 -2.97273 -0.42944]
21Feb16_224837| [ 0.53095 -1.50623  0.79224]
21Feb16_224837| [-1.07292 -0.83175 -0.90105]
21Feb16_224837| [-0.48696 -0.89325  0.27226]
21Feb16_224837| [-3.02511  0.34155 -0.03837]
21Feb16_224837| [-0.76747  0.57140 -0.46892]
21Feb16_224837| [-0.07581  0.14713  0.85910]
21Feb16_224837| [-1.37488  0.52170 -0.36205]
21Feb16_224837| [ 1.60981 -0.08727 -0.11267]
21Feb16_224837| [ 0.50986  1.58916 -0.35287]
21Feb16_224837| [-0.34599  1.27113 -0.16393]
21Feb16_224837| [ 1.29203  1.19467  0.37695]
21Feb16_224837| [ 0.58704  0.06328 -0.24240]
21Feb16_224837| [-0.93888 -0.89760  0.57087]
21Feb16_224837| [ 0.99159 -0.66387  0.35177]
21Feb16_224837| [-0.67119  1.06910 -0.12512]
21Feb16_224837| [-0.91534  1.23744 -0.40465]
21Feb16_224837| [ 1.39278  0.08069  0.23328]
21Feb16_224837| [ 0.09880  0.57603 -0.96101]
21Feb16_224837| [ 0.01621 -0.13343 -0.27624]
21Feb16_224837| [-1.28286 -2.28909  0.37931]
21Feb16_224837| [-0.28370  0.09336  0.01547]
21Feb16_224837| [-0.51894  1.84280 -0.25906]
21Feb16_224837| [-0.83075 -0.04508  0.12107]
21Feb16_224837| [ 0.37343  1.18436 -0.07358]
21Feb16_224837| [-2.38657 -0.35191  0.01962]
21Feb16_224837| [ 0.95757 -0.91760 -0.08971]
21Feb16_224837| [ 0.38792 -0.01880  0.69717]
21Feb16_224837| [ 1.66877 -0.58078 -1.21129]
21Feb16_224837| [-0.50943  0.59080  0.30856]
21Feb16_224837| [ 0.30163  1.11518  0.98185]
21Feb16_224837| [-0.73226  0.32281 -0.66712]
21Feb16_224837| [-0.62054 -2.21049  1.40981]
21Feb16_224837| [ 1.23185 -0.58090  0.35844]
21Feb16_224837| [-0.05616  0.24219 -0.02853]
21Feb16_224837| [-1.05085 -2.30259 -0.16276]
21Feb16_224837| [ 0.71087  0.14900  1.13430]
21Feb16_224837| [-2.45877 -1.20999 -1.04986]
21Feb16_224837| [-1.00480  1.36344 -0.13998]
21Feb16_224837| [ 1.83140 -0.91532  0.07616]
21Feb16_224837| [-0.60404 -2.05184  0.76948]
21Feb16_224837| [ 0.52617  0.76042 -1.76746]
21Feb16_224837| [-0.22134  0.17324  0.99530]
21Feb16_224837| [-0.36427  1.34655  0.02110]
21Feb16_224837| [-0.93125 -0.33620 -0.25012]
21Feb16_224837| [-2.76428  0.14487  0.48096]
21Feb16_224837| [-0.10518  0.35052  1.71840]
21Feb16_224837| [-1.27998  1.12568  1.26523]
21Feb16_224837| [-0.60698  1.53230 -0.60824]
21Feb16_224837| [ 0.02898  2.98718 -0.59153]
21Feb16_224837| [ 0.17588 -0.00449  0.50797]
21Feb16_224837| [-1.42674 -0.54967 -0.21310]
21Feb16_224837| [ 1.03196  1.18733  0.36755]
21Feb16_224837| [ 1.04748 -1.47444 -0.08469]
21Feb16_224837| [ 0.49410  0.38745  0.68469]
21Feb16_224837| [-0.62880  0.73245  0.19964]]
21Feb16_224837|-- Bias --
21Feb16_224837|[-0.18798  0.64571 -0.23142]
21Feb16_224837|Layer 1:
21Feb16_224837|-- Config --
21Feb16_224837|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224837|-- Weights --
21Feb16_224837|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb16_224837| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb16_224837| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb16_224837|-- Bias --
21Feb16_224837|[0.60477 0.03773 0.26452 0.12222]
21Feb16_224837|Layer 2:
21Feb16_224837|-- Config --
21Feb16_224837|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224837|-- Weights --
21Feb16_224837|[[ 0.67920  0.12119]
21Feb16_224837| [ 0.44836  0.02916]
21Feb16_224837| [ 0.68939  0.31516]
21Feb16_224837| [-0.58995 -0.05861]]
21Feb16_224837|-- Bias --
21Feb16_224837|[ 0.59649 -0.08079]
21Feb16_224837|Layer 3:
21Feb16_224837|-- Config --
21Feb16_224837|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224837|-- Weights --
21Feb16_224837|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb16_224837| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb16_224837|-- Bias --
21Feb16_224837|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb16_224837|Layer 4:
21Feb16_224837|-- Config --
21Feb16_224837|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb16_224837|-- Weights --
21Feb16_224837|[[-0.03514 -1.04833]
21Feb16_224837| [ 1.25238  0.62094]
21Feb16_224837| [ 0.99203  0.37406]
21Feb16_224837| [ 0.49902  0.67158]
21Feb16_224837| [-1.35709  0.38335]]
21Feb16_224837|-- Bias --
21Feb16_224837|[0.31435 0.36299]
21Feb16_224837|Predicting the validation and test data with the Best final individual.
21Feb16_224845| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb16_224845|-----------  ------------------  --------------------  ----------
21Feb16_224845|Validation         22.70                  56            0.74363
21Feb16_224845|   Test            19.46                  56            0.73101
Using Theano backend.
WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.
2021-02-16 22:48:47.983045: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-02-16 22:48:47.983112: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
21Feb16_224848|Data summary: Train
21Feb16_224848|data.shape = (2300, 57)
21Feb16_224848|labels.shape = (2300,)
21Feb16_224848|Class distribution:
21Feb16_224848|	0 - 1389 (0.60)
21Feb16_224848|	1 - 911 (0.40)
21Feb16_224848|Data summary: Validation
21Feb16_224848|data.shape = (1150, 57)
21Feb16_224848|labels.shape = (1150,)
21Feb16_224848|Class distribution:
21Feb16_224848|	0 - 667 (0.58)
21Feb16_224848|	1 - 483 (0.42)
21Feb16_224848|Data summary: Test
21Feb16_224848|data.shape = (1151, 57)
21Feb16_224848|labels.shape = (1151,)
21Feb16_224848|Class distribution:
21Feb16_224848|	0 - 732 (0.64)
21Feb16_224848|	1 - 419 (0.36)
21Feb16_224848|Selected configuration values
21Feb16_224848|-- Dataset name: spambase2
21Feb16_224848|-- Initial population size: 64
21Feb16_224848|-- Maximun number of generations: 32
21Feb16_224848|-- Neurons per hidden layer range: (2, 20)
21Feb16_224848|-- Hidden layers number range: (1, 3)
21Feb16_224848|-- Crossover probability: 0.5
21Feb16_224848|-- Bias gene mutation probability: 0.2
21Feb16_224848|-- Weights gene mutation probability: 0.75
21Feb16_224848|-- Neuron mutation probability: 0.3
21Feb16_224848|-- Layer mutation probability: 0.3
21Feb16_224848|-- Constant hidden layers: False
21Feb16_224848|-- Seed: 31415
21Feb16_224848|Entering GA
21Feb16_224848|Start the algorithm
21Feb16_225232|-- Generation 1 --
21Feb16_225232|    -- Crossed 0 individual pairs.
21Feb16_225232|    -- Mutated 32 individuals.
21Feb16_225553|    -- Evaluated 64 individuals.
21Feb16_225553|    Summary of generation 1:
21Feb16_225553| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_225553|-----------  ------------------  --------------------  ----------
21Feb16_225553|    Max            42.70                78.00           0.43478
21Feb16_225553|    Avg            41.90                26.28           0.00941
21Feb16_225553|    Min            35.91                 2.00           0.00000
21Feb16_225553|    Std             0.81                18.75           0.05509
21Feb16_225553|   Best            35.91                18.00           0.43478
21Feb16_225553|-- Generation 2 --
21Feb16_225553|    -- Crossed 1 individual pairs.
21Feb16_225553|    -- Mutated 32 individuals.
21Feb16_225908|    -- Evaluated 64 individuals.
21Feb16_225908|    Summary of generation 2:
21Feb16_225908| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_225908|-----------  ------------------  --------------------  ----------
21Feb16_225908|    Max            58.00                84.00           0.79977
21Feb16_225908|    Avg            41.99                15.92           0.02879
21Feb16_225908|    Min            29.65                 2.00           0.00000
21Feb16_225908|    Std             2.55                13.60           0.13781
21Feb16_225908|   Best            29.65                18.00           0.79977
21Feb16_225908|-- Generation 3 --
21Feb16_225908|    -- Crossed 3 individual pairs.
21Feb16_225908|    -- Mutated 32 individuals.
21Feb16_230221|    -- Evaluated 64 individuals.
21Feb16_230221|    Summary of generation 3:
21Feb16_230221| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_230221|-----------  ------------------  --------------------  ----------
21Feb16_230221|    Max            58.00                50.00           0.78358
21Feb16_230221|    Avg            41.97                13.73           0.02564
21Feb16_230221|    Min            26.09                 2.00           0.00000
21Feb16_230221|    Std             2.83                12.88           0.13211
21Feb16_230221|   Best            26.09                18.00           0.73476
21Feb16_230221|-- Generation 4 --
21Feb16_230221|    -- Crossed 4 individual pairs.
21Feb16_230221|    -- Mutated 32 individuals.
21Feb16_230530|    -- Evaluated 64 individuals.
21Feb16_230530|    Summary of generation 4:
21Feb16_230530| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_230530|-----------  ------------------  --------------------  ----------
21Feb16_230530|    Max            42.17                63.00           0.00517
21Feb16_230530|    Avg            42.01                 8.34           0.00085
21Feb16_230530|    Min            41.91                 2.00           0.00000
21Feb16_230530|    Std             0.06                 9.60           0.00165
21Feb16_230530|   Best            41.91                 4.00           0.00517
21Feb16_230530|-- Generation 5 --
21Feb16_230530|    -- Crossed 6 individual pairs.
21Feb16_230530|    -- Mutated 32 individuals.
21Feb16_230837|    -- Evaluated 64 individuals.
21Feb16_230837|    Summary of generation 5:
21Feb16_230837| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_230837|-----------  ------------------  --------------------  ----------
21Feb16_230837|    Max            42.09                20.00           0.05344
21Feb16_230837|    Avg            41.98                 5.28           0.00172
21Feb16_230837|    Min            41.22                 2.00           0.00000
21Feb16_230837|    Std             0.11                 4.46           0.00681
21Feb16_230837|   Best            41.22                14.00           0.05344
21Feb16_230837|-- Generation 6 --
21Feb16_230837|    -- Crossed 7 individual pairs.
21Feb16_230837|    -- Mutated 32 individuals.
21Feb16_231147|    -- Evaluated 64 individuals.
21Feb16_231147|    Summary of generation 6:
21Feb16_231147| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_231147|-----------  ------------------  --------------------  ----------
21Feb16_231147|    Max            42.26                18.00           0.01548
21Feb16_231147|    Avg            41.99                 6.00           0.00105
21Feb16_231147|    Min            41.48                 2.00           0.00000
21Feb16_231147|    Std             0.09                 4.81           0.00231
21Feb16_231147|   Best            41.48                 3.00           0.01548
21Feb16_231147|-- Generation 7 --
21Feb16_231147|    -- Crossed 9 individual pairs.
21Feb16_231147|    -- Mutated 32 individuals.
21Feb16_231456|    -- Evaluated 64 individuals.
21Feb16_231456|    Summary of generation 7:
21Feb16_231456| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_231456|-----------  ------------------  --------------------  ----------
21Feb16_231456|    Max            42.09                36.00           0.01033
21Feb16_231456|    Avg            41.99                 5.98           0.00089
21Feb16_231456|    Min            41.65                 2.00           0.00000
21Feb16_231456|    Std             0.06                 6.14           0.00184
21Feb16_231456|   Best            41.65                 3.00           0.01033
21Feb16_231456|-- Generation 8 --
21Feb16_231456|    -- Crossed 9 individual pairs.
21Feb16_231456|    -- Mutated 32 individuals.
21Feb16_231804|    -- Evaluated 64 individuals.
21Feb16_231804|    Summary of generation 8:
21Feb16_231804| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_231804|-----------  ------------------  --------------------  ----------
21Feb16_231804|    Max            42.17                18.00           0.04103
21Feb16_231804|    Avg            41.97                 5.09           0.00169
21Feb16_231804|    Min            40.78                 2.00           0.00000
21Feb16_231804|    Std             0.16                 4.37           0.00529
21Feb16_231804|   Best            40.78                12.00           0.04103
21Feb16_231804|-- Generation 9 --
21Feb16_231804|    -- Crossed 8 individual pairs.
21Feb16_231804|    -- Mutated 32 individuals.
21Feb16_232114|    -- Evaluated 64 individuals.
21Feb16_232114|    Summary of generation 9:
21Feb16_232114| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_232114|-----------  ------------------  --------------------  ----------
21Feb16_232114|    Max            48.87                18.00           0.80667
21Feb16_232114|    Avg            41.71                 6.17           0.03823
21Feb16_232114|    Min            30.61                 2.00           0.00000
21Feb16_232114|    Std             2.17                 5.04           0.16210
21Feb16_232114|   Best            30.61                 8.00           0.78607
21Feb16_232114|-- Generation 10 --
21Feb16_232114|    -- Crossed 5 individual pairs.
21Feb16_232114|    -- Mutated 32 individuals.
21Feb16_232423|    -- Evaluated 64 individuals.
21Feb16_232423|    Summary of generation 10:
21Feb16_232423| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_232423|-----------  ------------------  --------------------  ----------
21Feb16_232423|    Max            42.26                18.00           0.58344
21Feb16_232423|    Avg            41.43                 6.23           0.02714
21Feb16_232423|    Min            27.74                 2.00           0.00000
21Feb16_232423|    Std             2.43                 4.89           0.10887
21Feb16_232423|   Best            27.74                18.00           0.51616
21Feb16_232423|-- Generation 11 --
21Feb16_232423|    -- Crossed 8 individual pairs.
21Feb16_232423|    -- Mutated 32 individuals.
21Feb16_232735|    -- Evaluated 64 individuals.
21Feb16_232735|    Summary of generation 11:
21Feb16_232735| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_232735|-----------  ------------------  --------------------  ----------
21Feb16_232735|    Max            58.00                34.00           0.78358
21Feb16_232735|    Avg            41.87                 7.95           0.03476
21Feb16_232735|    Min            28.00                 2.00           0.00000
21Feb16_232735|    Std             2.88                 6.49           0.14854
21Feb16_232735|   Best            28.00                 8.00           0.52079
21Feb16_232735|-- Generation 12 --
21Feb16_232735|    -- Crossed 3 individual pairs.
21Feb16_232735|    -- Mutated 32 individuals.
21Feb16_233046|    -- Evaluated 64 individuals.
21Feb16_233046|    Summary of generation 12:
21Feb16_233046| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_233046|-----------  ------------------  --------------------  ----------
21Feb16_233046|    Max            42.35                36.00           0.67494
21Feb16_233046|    Avg            41.46                 7.03           0.02217
21Feb16_233046|    Min            24.96                 2.00           0.00000
21Feb16_233046|    Std             2.67                 5.88           0.11025
21Feb16_233046|   Best            24.96                18.00           0.67494
21Feb16_233046|-- Generation 13 --
21Feb16_233046|    -- Crossed 5 individual pairs.
21Feb16_233046|    -- Mutated 32 individuals.
21Feb16_233357|    -- Evaluated 64 individuals.
21Feb16_233357|    Summary of generation 13:
21Feb16_233357| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_233357|-----------  ------------------  --------------------  ----------
21Feb16_233357|    Max            42.61                36.00           0.61562
21Feb16_233357|    Avg            41.50                 8.56           0.02210
21Feb16_233357|    Min            26.78                 2.00           0.00000
21Feb16_233357|    Std             2.40                 7.93           0.10577
21Feb16_233357|   Best            26.78                18.00           0.61562
21Feb16_233357|-- Generation 14 --
21Feb16_233357|    -- Crossed 7 individual pairs.
21Feb16_233357|    -- Mutated 32 individuals.
21Feb16_233709|    -- Evaluated 64 individuals.
21Feb16_233709|    Summary of generation 14:
21Feb16_233709| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_233709|-----------  ------------------  --------------------  ----------
21Feb16_233709|    Max            42.09                40.00           0.75188
21Feb16_233709|    Avg            41.48                 8.12           0.02679
21Feb16_233709|    Min            27.65                 2.00           0.00000
21Feb16_233709|    Std             2.42                 6.72           0.13015
21Feb16_233709|   Best            27.65                18.00           0.75188
21Feb16_233709|-- Generation 15 --
21Feb16_233709|    -- Crossed 6 individual pairs.
21Feb16_233709|    -- Mutated 32 individuals.
21Feb16_234021|    -- Evaluated 64 individuals.
21Feb16_234021|    Summary of generation 15:
21Feb16_234021| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_234021|-----------  ------------------  --------------------  ----------
21Feb16_234021|    Max            42.09                40.00           0.73387
21Feb16_234021|    Avg            41.42                 7.69           0.02610
21Feb16_234021|    Min            26.35                 2.00           0.00000
21Feb16_234021|    Std             2.71                 6.44           0.12590
21Feb16_234021|   Best            26.35                18.00           0.71951
21Feb16_234021|-- Generation 16 --
21Feb16_234021|    -- Crossed 5 individual pairs.
21Feb16_234021|    -- Mutated 32 individuals.
21Feb16_234334|    -- Evaluated 64 individuals.
21Feb16_234334|    Summary of generation 16:
21Feb16_234334| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_234334|-----------  ------------------  --------------------  ----------
21Feb16_234334|    Max            42.26                44.00           0.82855
21Feb16_234334|    Avg            41.21                 7.83           0.03973
21Feb16_234334|    Min            24.87                 2.00           0.00000
21Feb16_234334|    Std             3.23                 7.99           0.16234
21Feb16_234334|   Best            24.87                21.00           0.68287
21Feb16_234334|-- Generation 17 --
21Feb16_234334|    -- Crossed 8 individual pairs.
21Feb16_234334|    -- Mutated 32 individuals.
21Feb16_234647|    -- Evaluated 64 individuals.
21Feb16_234647|    Summary of generation 17:
21Feb16_234647| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_234647|-----------  ------------------  --------------------  ----------
21Feb16_234647|    Max            42.26                44.00           0.80877
21Feb16_234647|    Avg            40.86                 8.81           0.06413
21Feb16_234647|    Min            25.04                 2.00           0.00000
21Feb16_234647|    Std             3.59                 8.94           0.19340
21Feb16_234647|   Best            25.04                10.00           0.72247
21Feb16_234647|-- Generation 18 --
21Feb16_234647|    -- Crossed 2 individual pairs.
21Feb16_234647|    -- Mutated 32 individuals.
21Feb16_235003|    -- Evaluated 64 individuals.
21Feb16_235003|    Summary of generation 18:
21Feb16_235003| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_235003|-----------  ------------------  --------------------  ----------
21Feb16_235003|    Max            47.04                44.00           0.81211
21Feb16_235003|    Avg            39.55                10.78           0.12108
21Feb16_235003|    Min            24.35                 3.00           0.00000
21Feb16_235003|    Std             5.74                11.16           0.25939
21Feb16_235003|   Best            24.35                44.00           0.72485
21Feb16_235003|-- Generation 19 --
21Feb16_235003|    -- Crossed 7 individual pairs.
21Feb16_235003|    -- Mutated 32 individuals.
21Feb16_235325|    -- Evaluated 64 individuals.
21Feb16_235325|    Summary of generation 19:
21Feb16_235325| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_235325|-----------  ------------------  --------------------  ----------
21Feb16_235325|    Max            42.87                70.00           0.81774
21Feb16_235325|    Avg            39.09                14.53           0.14606
21Feb16_235325|    Min            24.70                 3.00           0.00000
21Feb16_235325|    Std             5.78                15.60           0.27609
21Feb16_235325|   Best            24.70                44.00           0.69102
21Feb16_235325|-- Generation 20 --
21Feb16_235325|    -- Crossed 3 individual pairs.
21Feb16_235325|    -- Mutated 32 individuals.
21Feb16_235651|    -- Evaluated 64 individuals.
21Feb16_235651|    Summary of generation 20:
21Feb16_235651| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb16_235651|-----------  ------------------  --------------------  ----------
21Feb16_235651|    Max            42.17                60.00           0.79174
21Feb16_235651|    Avg            39.05                15.47           0.15453
21Feb16_235651|    Min            24.09                 3.00           0.00000
21Feb16_235651|    Std             5.60                16.03           0.28335
21Feb16_235651|   Best            24.09                48.00           0.76568
21Feb16_235651|-- Generation 21 --
21Feb16_235651|    -- Crossed 4 individual pairs.
21Feb16_235651|    -- Mutated 32 individuals.
21Feb17_000021|    -- Evaluated 64 individuals.
21Feb17_000021|    Summary of generation 21:
21Feb17_000021| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_000021|-----------  ------------------  --------------------  ----------
21Feb17_000021|    Max            42.17                90.00           0.80579
21Feb17_000021|    Avg            38.34                18.45           0.19938
21Feb17_000021|    Min            23.91                 2.00           0.00000
21Feb17_000021|    Std             5.87                19.09           0.30554
21Feb17_000021|   Best            23.91                48.00           0.71458
21Feb17_000021|-- Generation 22 --
21Feb17_000021|    -- Crossed 2 individual pairs.
21Feb17_000021|    -- Mutated 32 individuals.
21Feb17_000357|    -- Evaluated 64 individuals.
21Feb17_000357|    Summary of generation 22:
21Feb17_000357| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_000357|-----------  ------------------  --------------------  ----------
21Feb17_000357|    Max            42.09                60.00           0.82362
21Feb17_000357|    Avg            36.71                21.28           0.25981
21Feb17_000357|    Min            24.26                 2.00           0.00000
21Feb17_000357|    Std             6.98                18.25           0.33831
21Feb17_000357|   Best            24.26                52.00           0.76087
21Feb17_000357|-- Generation 23 --
21Feb17_000357|    -- Crossed 2 individual pairs.
21Feb17_000357|    -- Mutated 32 individuals.
21Feb17_000742|    -- Evaluated 64 individuals.
21Feb17_000742|    Summary of generation 23:
21Feb17_000742| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_000742|-----------  ------------------  --------------------  ----------
21Feb17_000742|    Max            42.09                96.00           0.78772
21Feb17_000742|    Avg            35.35                29.28           0.32114
21Feb17_000742|    Min            23.39                 2.00           0.00000
21Feb17_000742|    Std             7.15                21.95           0.34435
21Feb17_000742|   Best            23.39                52.00           0.72814
21Feb17_000742|-- Generation 24 --
21Feb17_000742|    -- Crossed 0 individual pairs.
21Feb17_000742|    -- Mutated 32 individuals.
21Feb17_001139|    -- Evaluated 64 individuals.
21Feb17_001139|    Summary of generation 24:
21Feb17_001139| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_001139|-----------  ------------------  --------------------  ----------
21Feb17_001139|    Max            43.30                80.00           0.82075
21Feb17_001139|    Avg            33.81                36.61           0.38588
21Feb17_001139|    Min            23.22                 2.00           0.00000
21Feb17_001139|    Std             7.30                19.72           0.34184
21Feb17_001139|   Best            23.22                52.00           0.73602
21Feb17_001139|-- Generation 25 --
21Feb17_001139|    -- Crossed 3 individual pairs.
21Feb17_001139|    -- Mutated 32 individuals.
21Feb17_001545|    -- Evaluated 64 individuals.
21Feb17_001545|    Summary of generation 25:
21Feb17_001545| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_001545|-----------  ------------------  --------------------  ----------
21Feb17_001545|    Max            51.74                114.00          0.82799
21Feb17_001545|    Avg            33.58                45.08           0.45457
21Feb17_001545|    Min            23.91                 8.00           0.00000
21Feb17_001545|    Std             7.24                19.61           0.35022
21Feb17_001545|   Best            23.91                48.00           0.72048
21Feb17_001545|-- Generation 26 --
21Feb17_001545|    -- Crossed 1 individual pairs.
21Feb17_001545|    -- Mutated 32 individuals.
21Feb17_001953|    -- Evaluated 64 individuals.
21Feb17_001953|    Summary of generation 26:
21Feb17_001953| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_001953|-----------  ------------------  --------------------  ----------
21Feb17_001953|    Max            42.35                108.00          0.84388
21Feb17_001953|    Avg            32.71                48.80           0.44554
21Feb17_001953|    Min            23.30                 2.00           0.00000
21Feb17_001953|    Std             7.16                22.53           0.33996
21Feb17_001953|   Best            23.30                24.00           0.69415
21Feb17_001953|-- Generation 27 --
21Feb17_001953|    -- Crossed 1 individual pairs.
21Feb17_001953|    -- Mutated 32 individuals.
21Feb17_002403|    -- Evaluated 64 individuals.
21Feb17_002403|    Summary of generation 27:
21Feb17_002403| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_002403|-----------  ------------------  --------------------  ----------
21Feb17_002403|    Max            42.26                132.00          0.82552
21Feb17_002403|    Avg            32.16                51.20           0.45948
21Feb17_002403|    Min            21.74                 8.00           0.00000
21Feb17_002403|    Std             7.19                22.48           0.32234
21Feb17_002403|   Best            21.74                18.00           0.76278
21Feb17_002403|-- Generation 28 --
21Feb17_002403|    -- Crossed 0 individual pairs.
21Feb17_002403|    -- Mutated 32 individuals.
21Feb17_002813|    -- Evaluated 64 individuals.
21Feb17_002813|    Summary of generation 28:
21Feb17_002813| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_002813|-----------  ------------------  --------------------  ----------
21Feb17_002813|    Max            42.00                132.00          0.83850
21Feb17_002813|    Avg            31.52                51.11           0.49187
21Feb17_002813|    Min            23.04                12.00           0.00000
21Feb17_002813|    Std             6.86                24.66           0.32040
21Feb17_002813|   Best            23.04                24.00           0.73226
21Feb17_002813|-- Generation 29 --
21Feb17_002813|    -- Crossed 0 individual pairs.
21Feb17_002813|    -- Mutated 32 individuals.
21Feb17_003220|    -- Evaluated 64 individuals.
21Feb17_003220|    Summary of generation 29:
21Feb17_003220| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_003220|-----------  ------------------  --------------------  ----------
21Feb17_003220|    Max            42.09                132.00          0.82871
21Feb17_003220|    Avg            32.10                49.19           0.44677
21Feb17_003220|    Min            22.26                12.00           0.00000
21Feb17_003220|    Std             7.60                23.20           0.33800
21Feb17_003220|   Best            22.26                56.00           0.74227
21Feb17_003220|-- Generation 30 --
21Feb17_003220|    -- Crossed 0 individual pairs.
21Feb17_003220|    -- Mutated 32 individuals.
21Feb17_003627|    -- Evaluated 64 individuals.
21Feb17_003627|    Summary of generation 30:
21Feb17_003627| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_003627|-----------  ------------------  --------------------  ----------
21Feb17_003627|    Max            42.09                100.00          0.82371
21Feb17_003627|    Avg            31.14                49.09           0.49033
21Feb17_003627|    Min            22.00                14.00           0.00000
21Feb17_003627|    Std             7.06                18.85           0.31415
21Feb17_003627|   Best            22.00                56.00           0.78704
21Feb17_003627|-- Generation 31 --
21Feb17_003627|    -- Crossed 1 individual pairs.
21Feb17_003627|    -- Mutated 32 individuals.
21Feb17_004035|    -- Evaluated 64 individuals.
21Feb17_004035|    Summary of generation 31:
21Feb17_004035| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_004035|-----------  ------------------  --------------------  ----------
21Feb17_004035|    Max            42.52                100.00          0.83333
21Feb17_004035|    Avg            32.54                52.38           0.44410
21Feb17_004035|    Min            22.96                 8.00           0.00000
21Feb17_004035|    Std             7.42                21.79           0.34342
21Feb17_004035|   Best            22.96                44.00           0.72671
21Feb17_004035|-- Generation 32 --
21Feb17_004035|    -- Crossed 1 individual pairs.
21Feb17_004035|    -- Mutated 32 individuals.
21Feb17_004443|    -- Evaluated 64 individuals.
21Feb17_004443|    Summary of generation 32:
21Feb17_004443| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_004443|-----------  ------------------  --------------------  ----------
21Feb17_004443|    Max            42.00                85.00           0.83038
21Feb17_004443|    Avg            32.40                52.83           0.43440
21Feb17_004443|    Min            21.57                 8.00           0.00000
21Feb17_004443|    Std             7.70                18.10           0.34013
21Feb17_004443|   Best            21.57                56.00           0.83038
21Feb17_004443|Best initial individual weights
21Feb17_004443|Individual:
21Feb17_004443|-- Constant hidden layers --
21Feb17_004443|False
21Feb17_004443|Layer 0:
21Feb17_004443|-- Config --
21Feb17_004443|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 12, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004443|-- Weights --
21Feb17_004443|[[-3.50529e-01 -6.53069e-03 -7.03730e-01 -6.33906e-01  6.10835e-02
21Feb17_004443|   4.57449e-01 -3.77835e-01  6.38481e-01  4.24141e-01  6.68786e-01
21Feb17_004443|  -4.86511e-01 -9.28542e-01]
21Feb17_004443| [-8.31270e-01 -3.94586e-01  5.51697e-02 -8.86387e-01 -6.99786e-01
21Feb17_004443|   6.44047e-01 -5.40571e-01  3.77503e-01  1.70193e-01  5.92883e-01
21Feb17_004443|   2.06540e-01  2.18639e-01]
21Feb17_004443| [-8.13637e-01  7.25044e-01  6.66092e-01  5.31057e-01 -4.48634e-01
21Feb17_004443|  -1.62601e-01 -1.57458e-02  7.74238e-02 -4.81841e-01  3.55485e-02
21Feb17_004443|  -7.21169e-01  1.05129e-01]
21Feb17_004443| [ 6.07201e-01  6.23643e-01  8.87343e-01  6.04285e-01  5.70453e-02
21Feb17_004443|   5.99381e-01 -3.21663e-03  6.64196e-01 -5.25584e-01 -1.74507e-02
21Feb17_004443|   3.80029e-01 -4.59585e-01]
21Feb17_004443| [-9.00078e-01  8.63133e-01  8.49324e-01  4.34648e-01 -5.67121e-01
21Feb17_004443|   6.24299e-01 -6.46637e-01  9.34620e-01 -5.42838e-01 -4.04257e-01
21Feb17_004443|  -4.70046e-01  4.29712e-01]
21Feb17_004443| [ 9.51731e-02  8.42954e-01 -7.44806e-01 -5.56045e-02 -4.89209e-01
21Feb17_004443|   8.07612e-01  2.77691e-01 -5.77946e-02  4.30356e-01 -9.05718e-01
21Feb17_004443|  -7.61358e-01 -4.56367e-01]
21Feb17_004443| [-9.06447e-01 -4.46566e-01 -4.40669e-01  6.09161e-01 -3.32587e-01
21Feb17_004443|  -9.31356e-01  9.62597e-02 -1.83060e-01  5.91585e-01 -2.78230e-01
21Feb17_004443|  -3.70976e-01 -3.38510e-01]
21Feb17_004443| [ 5.92999e-02 -5.35945e-01 -8.52259e-01  1.62766e-01 -2.64657e-01
21Feb17_004443|   6.65182e-01  2.45597e-01  2.99711e-01  7.14862e-01 -4.00362e-01
21Feb17_004443|   3.40170e-01 -1.14174e-01]
21Feb17_004443| [-4.26995e-01  8.46146e-01  9.81523e-01 -2.62996e-01  8.65377e-01
21Feb17_004443|  -6.86144e-01 -3.53983e-01 -2.18499e-01  3.29010e-01 -8.26088e-01
21Feb17_004443|   1.48202e-01  5.27152e-01]
21Feb17_004443| [-1.97937e-01  5.44304e-02  9.68680e-01  1.96012e-01  6.66432e-01
21Feb17_004443|  -1.15663e-01  1.01696e-01 -9.91833e-01  5.54656e-02  5.06069e-01
21Feb17_004443|  -8.39702e-01  6.07914e-02]
21Feb17_004443| [ 8.22409e-01 -3.07988e-01 -4.87097e-01 -2.67403e-01 -3.17115e-01
21Feb17_004443|   6.20877e-01  2.45721e-01  1.47039e-01  8.22748e-02 -4.61491e-01
21Feb17_004443|   5.08690e-01 -8.10093e-01]
21Feb17_004443| [-1.03463e-01 -7.13247e-01 -5.27190e-01 -8.14055e-01 -2.20069e-01
21Feb17_004443|   7.58689e-01  7.72478e-01 -3.75243e-01 -1.74773e-01  4.33018e-02
21Feb17_004443|   5.76591e-01 -9.04182e-01]
21Feb17_004443| [ 6.39880e-01 -2.76473e-01  4.48413e-01  7.92996e-01  6.12921e-01
21Feb17_004443|   8.45232e-01 -3.59434e-01 -1.65084e-01  6.00279e-01 -9.07135e-01
21Feb17_004443|  -9.18766e-01 -3.84510e-02]
21Feb17_004443| [-4.35982e-01  3.53117e-01 -4.33635e-01  4.41189e-01  2.02385e-01
21Feb17_004443|  -2.15156e-01 -3.32093e-01 -9.46393e-01  7.49818e-01  7.56840e-01
21Feb17_004443|  -2.97280e-01  3.76513e-01]
21Feb17_004443| [ 2.00098e-01 -3.94368e-01  4.74964e-01 -5.14077e-01 -5.02985e-01
21Feb17_004443|   6.57337e-01  4.54284e-01  7.99434e-01  1.18259e-01  7.90625e-01
21Feb17_004443|  -8.45168e-01 -7.22624e-01]
21Feb17_004443| [ 5.21361e-01 -9.37087e-01  6.98489e-01  7.45747e-01  9.84330e-01
21Feb17_004443|  -1.70463e-01 -4.14211e-01  4.94059e-01 -4.89685e-03 -7.22161e-02
21Feb17_004443|   3.28119e-01 -2.96382e-01]
21Feb17_004443| [ 9.97912e-02 -3.45331e-01 -3.32041e-01 -8.83410e-01  4.64194e-01
21Feb17_004443|  -2.94905e-01 -7.11116e-01 -2.12420e-01  8.93334e-01  5.60374e-01
21Feb17_004443|  -8.11522e-01  3.94537e-01]
21Feb17_004443| [ 2.39284e-01 -9.68110e-02 -3.48403e-01  6.68017e-01  1.07039e-01
21Feb17_004443|  -1.80014e-01 -1.28612e-01 -3.28318e-01  7.99371e-01  7.45882e-01
21Feb17_004443|   4.50426e-01 -9.94601e-02]
21Feb17_004443| [-9.32040e-02 -4.99896e-01 -3.18835e-01 -3.21963e-01  8.88030e-02
21Feb17_004443|   8.24115e-01  3.93190e-01  2.14054e-01 -4.70631e-02  5.36199e-01
21Feb17_004443|   7.72001e-01 -1.38053e-01]
21Feb17_004443| [ 8.31611e-01  7.46409e-01  2.18558e-01  7.47226e-01 -4.35942e-01
21Feb17_004443|  -6.59230e-01  3.39715e-02  8.14827e-01 -7.32488e-02 -1.12845e-01
21Feb17_004443|  -5.06295e-01  2.18074e-01]
21Feb17_004443| [-3.26563e-01  6.22846e-01  3.85669e-01 -9.86028e-01 -7.51629e-02
21Feb17_004443|  -1.88021e-01  7.27322e-01  5.61207e-04  1.34321e-01  7.19415e-01
21Feb17_004443|  -5.83277e-01 -4.45815e-01]
21Feb17_004443| [ 7.83756e-01  9.31803e-02  4.99853e-01 -9.31861e-01  7.91593e-01
21Feb17_004443|   1.96250e-01 -8.00498e-02  7.34271e-01 -2.68771e-01  7.49220e-01
21Feb17_004443|   1.24815e-01  6.17245e-01]
21Feb17_004443| [ 2.20500e-01 -9.26851e-01 -5.03545e-02  9.91366e-01  9.07862e-01
21Feb17_004443|   6.95839e-01  2.07702e-01  1.55262e-01  7.17753e-01 -6.02225e-01
21Feb17_004443|  -2.43972e-02  7.83904e-01]
21Feb17_004443| [-7.35179e-01 -4.04922e-01 -7.64988e-01  6.94764e-03 -5.74469e-01
21Feb17_004443|  -8.82582e-01 -4.25720e-01  4.48261e-01  9.38039e-01 -6.02162e-01
21Feb17_004443|   1.85138e-01  8.19467e-01]
21Feb17_004443| [-2.42564e-01  5.05630e-02 -6.53631e-01  8.89456e-01  3.73267e-02
21Feb17_004443|  -4.57479e-01  5.78190e-01 -8.65769e-01  4.43846e-01  9.21993e-01
21Feb17_004443|  -4.59642e-01  4.55887e-01]
21Feb17_004443| [ 1.79502e-01  5.97755e-01 -5.91581e-01  6.50878e-01 -3.20822e-02
21Feb17_004443|   7.98103e-01  9.23662e-01 -3.15762e-01  3.95919e-01 -9.74799e-01
21Feb17_004443|  -9.18783e-01  9.04381e-01]
21Feb17_004443| [-9.77544e-01 -9.84191e-01 -3.78989e-01  1.57093e-01 -1.19240e-01
21Feb17_004443|   7.04336e-01  9.20317e-01 -9.23300e-02  7.24512e-01 -4.73620e-01
21Feb17_004443|   4.32204e-01  1.96422e-01]
21Feb17_004443| [-9.94008e-01  1.23345e-01 -2.91311e-01  3.86181e-01  3.50519e-01
21Feb17_004443|   8.97293e-02  1.28693e-01  7.64175e-01  9.70172e-01 -9.36008e-01
21Feb17_004443|   2.31190e-01 -3.81352e-01]
21Feb17_004443| [-8.68842e-01 -3.08689e-01 -7.85613e-02 -7.75421e-01 -2.62711e-01
21Feb17_004443|  -9.13854e-01  5.58996e-01  8.97445e-01 -4.78631e-01 -4.79708e-02
21Feb17_004443|  -2.09270e-01  1.03320e-01]
21Feb17_004443| [ 2.47190e-01  8.94828e-01 -8.83655e-01  1.67368e-01 -1.09226e-01
21Feb17_004443|   5.39374e-01  3.22158e-01  7.22802e-01 -4.76431e-01 -3.98606e-01
21Feb17_004443|   3.91466e-01 -5.89172e-01]
21Feb17_004443| [ 2.03966e-01 -8.11217e-01  8.56319e-01 -5.26108e-01 -9.29896e-01
21Feb17_004443|   5.92077e-01  8.52854e-01  6.15086e-01  5.45676e-01 -8.13950e-01
21Feb17_004443|   6.24771e-01 -9.57171e-01]
21Feb17_004443| [-7.59457e-01  2.18652e-01 -9.40198e-01 -1.94388e-03 -3.63300e-01
21Feb17_004443|   2.19527e-01 -3.86609e-01  6.57866e-02  8.04643e-01  4.37489e-01
21Feb17_004443|   6.39988e-01 -8.42788e-01]
21Feb17_004443| [-2.79911e-01  8.89651e-01  5.38994e-02  7.45843e-01 -9.32154e-01
21Feb17_004443|   5.56522e-01  5.04658e-01  3.56409e-01 -5.15289e-01  6.99550e-01
21Feb17_004443|  -7.31032e-01  1.61260e-01]
21Feb17_004443| [ 8.41582e-01 -5.25391e-01  4.65437e-01  4.40808e-01 -6.03761e-01
21Feb17_004443|   6.23036e-01  9.46114e-01  5.92328e-01  2.08190e-01 -6.69715e-01
21Feb17_004443|  -7.35264e-02  5.96491e-01]
21Feb17_004443| [ 3.20347e-01  1.37290e-01  1.72843e-02 -4.70187e-01  5.92987e-01
21Feb17_004443|   3.57672e-01  2.73873e-01 -8.65750e-02 -3.09144e-01 -9.20603e-01
21Feb17_004443|   2.82912e-01  6.38325e-01]
21Feb17_004443| [-8.91399e-01 -1.24857e-01 -4.86431e-01 -9.05166e-01  8.47373e-01
21Feb17_004443|   3.18146e-01  2.73494e-02 -5.33112e-01  5.63862e-01 -5.12821e-01
21Feb17_004443|  -9.38474e-01 -9.90043e-01]
21Feb17_004443| [-8.25448e-01 -1.90141e-02 -5.51276e-01 -8.23215e-01  7.26222e-02
21Feb17_004443|   3.49894e-01  5.17693e-01 -5.57217e-01 -3.26301e-01  7.78564e-01
21Feb17_004443|   6.58213e-01 -2.83929e-01]
21Feb17_004443| [ 6.18012e-02 -4.92329e-01  5.41071e-01  2.13013e-01  6.35700e-01
21Feb17_004443|  -1.65529e-01  5.77357e-01  2.45531e-01  2.54855e-01 -8.48854e-01
21Feb17_004443|   6.46386e-01 -4.13404e-01]
21Feb17_004443| [-3.41116e-01 -4.75918e-01  3.59165e-01  6.02895e-01 -4.31688e-01
21Feb17_004443|  -8.51757e-01  2.31464e-01 -9.57407e-01  2.83436e-01 -4.51744e-01
21Feb17_004443|   4.80022e-02 -8.35007e-01]
21Feb17_004443| [ 9.67499e-01  5.85047e-02  7.21540e-01  3.12459e-01  3.50272e-01
21Feb17_004443|   2.14450e-01 -3.30294e-01 -7.99000e-01  1.11959e-01  2.74091e-01
21Feb17_004443|  -1.78234e-01  9.40235e-01]
21Feb17_004443| [-1.14387e-01  4.31319e-01  3.73789e-01 -4.62497e-01  4.50407e-01
21Feb17_004443|  -4.00668e-01 -8.26575e-01  2.39589e-01 -5.24611e-01  3.30691e-01
21Feb17_004443|  -3.99504e-01  1.44547e-01]
21Feb17_004443| [ 7.34826e-01 -5.37352e-01 -6.62895e-01  1.04258e-01  2.15046e-03
21Feb17_004443|   2.71790e-01  8.51151e-01 -6.31948e-01  1.94011e-01 -6.41830e-01
21Feb17_004443|   1.67802e-01 -4.29449e-01]
21Feb17_004443| [-6.18752e-01  1.18069e-01 -7.98263e-01  4.75266e-01 -9.95474e-01
21Feb17_004443|  -1.79698e-01  6.90455e-01  3.44607e-01 -5.80013e-01 -6.16218e-02
21Feb17_004443|   7.01329e-01  8.33298e-02]
21Feb17_004443| [-2.69227e-01 -1.43165e-02 -3.33533e-01 -1.69954e-01 -1.26476e-02
21Feb17_004443|   7.69653e-01 -6.99893e-01  5.22539e-01 -1.67862e-01  4.44416e-01
21Feb17_004443|   6.72372e-01  5.52923e-01]
21Feb17_004443| [-7.10479e-01  1.61800e-01  2.53825e-01 -3.00634e-01 -5.06805e-01
21Feb17_004443|   2.02091e-01 -4.94980e-02 -1.44363e-01 -6.18371e-01  5.74350e-01
21Feb17_004443|  -1.85073e-01 -8.11049e-01]
21Feb17_004443| [-6.60846e-01 -1.69003e-01  6.00733e-01 -8.28618e-01 -3.99034e-01
21Feb17_004443|  -5.82553e-01  7.34428e-02  5.57096e-01 -1.50695e-01  1.26307e-01
21Feb17_004443|   8.92712e-01 -8.75142e-01]
21Feb17_004443| [ 7.58158e-01  5.89907e-01 -1.92304e-01 -3.86200e-01 -2.63049e-01
21Feb17_004443|  -3.41209e-03  4.05030e-01 -8.95945e-02  9.79113e-01  6.78942e-02
21Feb17_004443|  -9.53580e-01  7.06162e-01]
21Feb17_004443| [-1.23045e-01  9.25694e-01  5.20030e-01  4.57808e-01 -9.99639e-01
21Feb17_004443|  -9.80069e-02  3.03598e-01  4.26167e-02 -3.64595e-01 -7.17635e-01
21Feb17_004443|   1.61128e-01  6.30329e-01]
21Feb17_004443| [ 2.02232e-02 -3.24113e-01  7.43999e-01 -3.75983e-01  4.63558e-01
21Feb17_004443|  -2.04941e-01 -5.28404e-02  4.26576e-01 -2.53802e-01  1.74976e-01
21Feb17_004443|  -8.35763e-01  8.54548e-01]
21Feb17_004443| [-5.76875e-01  5.40954e-01 -4.91777e-01  4.40209e-01 -9.16379e-01
21Feb17_004443|   6.01728e-01  1.25226e-02  2.05876e-01  8.45524e-01 -8.34178e-01
21Feb17_004443|  -7.87379e-01  8.63352e-01]
21Feb17_004443| [-3.15102e-01  7.00213e-01  6.69503e-01  7.15510e-01 -9.53550e-01
21Feb17_004443|   4.07885e-02  4.25336e-01  6.24629e-01  9.90858e-01  6.36989e-01
21Feb17_004443|  -6.44355e-01 -5.47589e-01]
21Feb17_004443| [-8.25051e-01 -4.37574e-01  4.76334e-01 -7.71092e-01  7.98467e-01
21Feb17_004443|  -1.52347e-01  3.34469e-01  1.51889e-01 -9.60611e-01  4.62484e-01
21Feb17_004443|   4.10115e-01 -1.60555e-01]
21Feb17_004443| [ 1.77712e-01  6.55776e-01  8.97735e-01 -9.20852e-01 -9.69032e-01
21Feb17_004443|  -4.79756e-02 -3.24015e-01 -1.57490e-01 -6.25919e-01  9.94240e-01
21Feb17_004443|  -4.74141e-01 -1.00993e-01]
21Feb17_004443| [ 3.66246e-01  8.06205e-01  3.37216e-01 -3.17040e-01  9.19693e-01
21Feb17_004443|   8.28581e-01  2.22724e-01 -5.57410e-01 -8.17434e-01 -8.65693e-01
21Feb17_004443|  -4.72960e-01  7.15176e-01]
21Feb17_004443| [-8.25000e-01 -4.67253e-01 -1.84646e-02  3.88053e-01 -8.75853e-01
21Feb17_004443|  -2.34509e-01  9.53471e-01  8.05489e-02  2.71744e-01 -7.15129e-01
21Feb17_004443|   9.24875e-01 -6.07435e-01]
21Feb17_004443| [-2.79447e-01  2.39105e-01  1.32962e-01 -7.68103e-01  7.58443e-01
21Feb17_004443|  -1.69646e-01 -7.52460e-01 -7.30195e-01 -4.68985e-01 -2.88784e-01
21Feb17_004443|   3.77655e-02 -5.72024e-01]
21Feb17_004443| [-8.37481e-01 -8.22188e-02  8.45547e-01 -5.53876e-01  5.72703e-01
21Feb17_004443|   3.09970e-01  8.96552e-01  3.97690e-01 -7.19080e-01  2.37714e-01
21Feb17_004443|   6.60752e-01  1.69435e-01]]
21Feb17_004443|-- Bias --
21Feb17_004443|[-0.28065  0.08142 -0.20194  0.96969  0.45180  0.54884  0.16606 -0.15804
21Feb17_004443|  0.47362  0.17133  0.43345 -0.35803]
21Feb17_004443|Layer 1:
21Feb17_004443|-- Config --
21Feb17_004443|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 12], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004443|-- Weights --
21Feb17_004443|[[-0.88546  0.72941]
21Feb17_004443| [ 0.79196 -0.05477]
21Feb17_004443| [-0.89752 -0.49343]
21Feb17_004443| [ 0.78974 -0.41510]
21Feb17_004443| [ 0.29561 -0.94575]
21Feb17_004443| [-0.14754  0.69148]
21Feb17_004443| [-0.33558  0.37910]
21Feb17_004443| [-0.82387  0.15998]
21Feb17_004443| [-0.77760  0.88462]
21Feb17_004443| [ 0.98329 -0.68363]
21Feb17_004443| [ 0.88895  0.40387]
21Feb17_004443| [ 0.39015 -0.38652]]
21Feb17_004443|-- Bias --
21Feb17_004443|[ 0.28702 -0.70976]
21Feb17_004443|Predicting the validation and test data with the Best initial individual.
21Feb17_004449| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_004449|-----------  ------------------  --------------------  ----------
21Feb17_004449|Validation         42.00                  12            0.00000
21Feb17_004449|   Test            36.32                  12            0.00298
21Feb17_004449|-------------------- Test #0 --------------------
21Feb17_004449|Best final individual weights
21Feb17_004449|Individual:
21Feb17_004449|-- Constant hidden layers --
21Feb17_004449|False
21Feb17_004449|Layer 0:
21Feb17_004449|-- Config --
21Feb17_004449|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004449|-- Weights --
21Feb17_004449|[[-0.73212  1.32861  0.10200]
21Feb17_004449| [ 1.48746 -2.97273 -0.42944]
21Feb17_004449| [ 0.53095 -1.50623  0.79224]
21Feb17_004449| [-1.07292 -0.83175 -0.90105]
21Feb17_004449| [-0.48696 -0.89325  0.27226]
21Feb17_004449| [-3.02511  0.34155 -0.03837]
21Feb17_004449| [-0.76747  0.57140 -0.46892]
21Feb17_004449| [-0.07581  0.14713  0.85910]
21Feb17_004449| [-1.37488  0.52170 -0.36205]
21Feb17_004449| [ 1.60981 -0.08727 -0.11267]
21Feb17_004449| [ 0.50986  1.58916 -0.35287]
21Feb17_004449| [-0.34599  1.27113 -0.16393]
21Feb17_004449| [ 1.29203  1.19467  0.37695]
21Feb17_004449| [ 0.58704  0.06328 -0.24240]
21Feb17_004449| [-0.93888 -0.89760  0.57087]
21Feb17_004449| [ 0.99159 -0.66387  0.35177]
21Feb17_004449| [-0.67119  1.06910 -0.12512]
21Feb17_004449| [-0.91534  1.23744 -0.40465]
21Feb17_004449| [ 1.39278  0.08069  0.23328]
21Feb17_004449| [ 0.09880  0.57603 -0.96101]
21Feb17_004449| [ 0.01621 -0.13343 -0.27624]
21Feb17_004449| [-1.28286 -2.28909  0.37931]
21Feb17_004449| [-0.28370  0.09336  0.01547]
21Feb17_004449| [-0.51894  1.84280 -0.25906]
21Feb17_004449| [-0.83075 -0.04508  0.12107]
21Feb17_004449| [ 0.37343  1.18436 -0.07358]
21Feb17_004449| [-2.38657 -0.35191  0.01962]
21Feb17_004449| [ 0.95757 -0.91760 -0.08971]
21Feb17_004449| [ 0.38792 -0.01880  0.69717]
21Feb17_004449| [ 1.66877 -0.58078 -1.21129]
21Feb17_004449| [-0.50943  0.59080  0.30856]
21Feb17_004449| [ 0.30163  1.11518  0.98185]
21Feb17_004449| [-0.73226  0.32281 -0.66712]
21Feb17_004449| [-0.62054 -2.21049  1.40981]
21Feb17_004449| [ 1.23185 -0.58090  0.35844]
21Feb17_004449| [-0.05616  0.24219 -0.02853]
21Feb17_004449| [-1.05085 -2.30259 -0.16276]
21Feb17_004449| [ 0.71087  0.14900  1.13430]
21Feb17_004449| [-2.45877 -1.20999 -1.04986]
21Feb17_004449| [-1.00480  1.36344 -0.13998]
21Feb17_004449| [ 1.83140 -0.91532  0.07616]
21Feb17_004449| [-0.60404 -2.05184  0.76948]
21Feb17_004449| [ 0.52617  0.76042 -1.76746]
21Feb17_004449| [-0.22134  0.17324  0.99530]
21Feb17_004449| [-0.36427  1.34655  0.02110]
21Feb17_004449| [-0.93125 -0.33620 -0.25012]
21Feb17_004449| [-2.76428  0.14487  0.48096]
21Feb17_004449| [-0.10518  0.35052  1.71840]
21Feb17_004449| [-1.27998  1.12568  1.26523]
21Feb17_004449| [-0.60698  1.53230 -0.60824]
21Feb17_004449| [ 0.02898  2.98718 -0.59153]
21Feb17_004449| [ 0.17588 -0.00449  0.50797]
21Feb17_004449| [-1.42674 -0.54967 -0.21310]
21Feb17_004449| [ 1.03196  1.18733  0.36755]
21Feb17_004449| [ 1.04748 -1.47444 -0.08469]
21Feb17_004449| [ 0.49410  0.38745  0.68469]
21Feb17_004449| [-0.62880  0.73245  0.19964]]
21Feb17_004449|-- Bias --
21Feb17_004449|[-0.18798  0.64571 -0.23142]
21Feb17_004449|Layer 1:
21Feb17_004449|-- Config --
21Feb17_004449|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004449|-- Weights --
21Feb17_004449|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_004449| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_004449| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_004449|-- Bias --
21Feb17_004449|[0.60477 0.03773 0.26452 0.12222]
21Feb17_004449|Layer 2:
21Feb17_004449|-- Config --
21Feb17_004449|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004449|-- Weights --
21Feb17_004449|[[ 0.67920  0.12119]
21Feb17_004449| [ 0.44836  0.02916]
21Feb17_004449| [ 0.68939  0.31516]
21Feb17_004449| [-0.58995 -0.05861]]
21Feb17_004449|-- Bias --
21Feb17_004449|[ 0.59649 -0.08079]
21Feb17_004449|Layer 3:
21Feb17_004449|-- Config --
21Feb17_004449|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004449|-- Weights --
21Feb17_004449|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_004449| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_004449|-- Bias --
21Feb17_004449|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_004449|Layer 4:
21Feb17_004449|-- Config --
21Feb17_004449|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004449|-- Weights --
21Feb17_004449|[[-0.03514 -1.04833]
21Feb17_004449| [ 1.25238  0.62094]
21Feb17_004449| [ 0.99203  0.37406]
21Feb17_004449| [ 0.49902  0.67158]
21Feb17_004449| [-1.35709  0.38335]]
21Feb17_004449|-- Bias --
21Feb17_004449|[0.31435 0.36299]
21Feb17_004449|Predicting the validation and test data with the Best final individual.
21Feb17_004456| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_004456|-----------  ------------------  --------------------  ----------
21Feb17_004456|Validation         40.17                  56            0.05627
21Feb17_004456|   Test            21.37                  56            0.70301
21Feb17_004456|-------------------- Test #1 --------------------
21Feb17_004456|Best final individual weights
21Feb17_004456|Individual:
21Feb17_004456|-- Constant hidden layers --
21Feb17_004456|False
21Feb17_004456|Layer 0:
21Feb17_004456|-- Config --
21Feb17_004456|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004456|-- Weights --
21Feb17_004456|[[-0.73212  1.32861  0.10200]
21Feb17_004456| [ 1.48746 -2.97273 -0.42944]
21Feb17_004456| [ 0.53095 -1.50623  0.79224]
21Feb17_004456| [-1.07292 -0.83175 -0.90105]
21Feb17_004456| [-0.48696 -0.89325  0.27226]
21Feb17_004456| [-3.02511  0.34155 -0.03837]
21Feb17_004456| [-0.76747  0.57140 -0.46892]
21Feb17_004456| [-0.07581  0.14713  0.85910]
21Feb17_004456| [-1.37488  0.52170 -0.36205]
21Feb17_004456| [ 1.60981 -0.08727 -0.11267]
21Feb17_004456| [ 0.50986  1.58916 -0.35287]
21Feb17_004456| [-0.34599  1.27113 -0.16393]
21Feb17_004456| [ 1.29203  1.19467  0.37695]
21Feb17_004456| [ 0.58704  0.06328 -0.24240]
21Feb17_004456| [-0.93888 -0.89760  0.57087]
21Feb17_004456| [ 0.99159 -0.66387  0.35177]
21Feb17_004456| [-0.67119  1.06910 -0.12512]
21Feb17_004456| [-0.91534  1.23744 -0.40465]
21Feb17_004456| [ 1.39278  0.08069  0.23328]
21Feb17_004456| [ 0.09880  0.57603 -0.96101]
21Feb17_004456| [ 0.01621 -0.13343 -0.27624]
21Feb17_004456| [-1.28286 -2.28909  0.37931]
21Feb17_004456| [-0.28370  0.09336  0.01547]
21Feb17_004456| [-0.51894  1.84280 -0.25906]
21Feb17_004456| [-0.83075 -0.04508  0.12107]
21Feb17_004456| [ 0.37343  1.18436 -0.07358]
21Feb17_004456| [-2.38657 -0.35191  0.01962]
21Feb17_004456| [ 0.95757 -0.91760 -0.08971]
21Feb17_004456| [ 0.38792 -0.01880  0.69717]
21Feb17_004456| [ 1.66877 -0.58078 -1.21129]
21Feb17_004456| [-0.50943  0.59080  0.30856]
21Feb17_004456| [ 0.30163  1.11518  0.98185]
21Feb17_004456| [-0.73226  0.32281 -0.66712]
21Feb17_004456| [-0.62054 -2.21049  1.40981]
21Feb17_004456| [ 1.23185 -0.58090  0.35844]
21Feb17_004456| [-0.05616  0.24219 -0.02853]
21Feb17_004456| [-1.05085 -2.30259 -0.16276]
21Feb17_004456| [ 0.71087  0.14900  1.13430]
21Feb17_004456| [-2.45877 -1.20999 -1.04986]
21Feb17_004456| [-1.00480  1.36344 -0.13998]
21Feb17_004456| [ 1.83140 -0.91532  0.07616]
21Feb17_004456| [-0.60404 -2.05184  0.76948]
21Feb17_004456| [ 0.52617  0.76042 -1.76746]
21Feb17_004456| [-0.22134  0.17324  0.99530]
21Feb17_004456| [-0.36427  1.34655  0.02110]
21Feb17_004456| [-0.93125 -0.33620 -0.25012]
21Feb17_004456| [-2.76428  0.14487  0.48096]
21Feb17_004456| [-0.10518  0.35052  1.71840]
21Feb17_004456| [-1.27998  1.12568  1.26523]
21Feb17_004456| [-0.60698  1.53230 -0.60824]
21Feb17_004456| [ 0.02898  2.98718 -0.59153]
21Feb17_004456| [ 0.17588 -0.00449  0.50797]
21Feb17_004456| [-1.42674 -0.54967 -0.21310]
21Feb17_004456| [ 1.03196  1.18733  0.36755]
21Feb17_004456| [ 1.04748 -1.47444 -0.08469]
21Feb17_004456| [ 0.49410  0.38745  0.68469]
21Feb17_004456| [-0.62880  0.73245  0.19964]]
21Feb17_004456|-- Bias --
21Feb17_004456|[-0.18798  0.64571 -0.23142]
21Feb17_004456|Layer 1:
21Feb17_004456|-- Config --
21Feb17_004456|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004456|-- Weights --
21Feb17_004456|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_004456| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_004456| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_004456|-- Bias --
21Feb17_004456|[0.60477 0.03773 0.26452 0.12222]
21Feb17_004456|Layer 2:
21Feb17_004456|-- Config --
21Feb17_004456|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004456|-- Weights --
21Feb17_004456|[[ 0.67920  0.12119]
21Feb17_004456| [ 0.44836  0.02916]
21Feb17_004456| [ 0.68939  0.31516]
21Feb17_004456| [-0.58995 -0.05861]]
21Feb17_004456|-- Bias --
21Feb17_004456|[ 0.59649 -0.08079]
21Feb17_004456|Layer 3:
21Feb17_004456|-- Config --
21Feb17_004456|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004456|-- Weights --
21Feb17_004456|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_004456| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_004456|-- Bias --
21Feb17_004456|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_004456|Layer 4:
21Feb17_004456|-- Config --
21Feb17_004456|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004456|-- Weights --
21Feb17_004456|[[-0.03514 -1.04833]
21Feb17_004456| [ 1.25238  0.62094]
21Feb17_004456| [ 0.99203  0.37406]
21Feb17_004456| [ 0.49902  0.67158]
21Feb17_004456| [-1.35709  0.38335]]
21Feb17_004456|-- Bias --
21Feb17_004456|[0.31435 0.36299]
21Feb17_004456|Predicting the validation and test data with the Best final individual.
21Feb17_004504| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_004504|-----------  ------------------  --------------------  ----------
21Feb17_004504|Validation         23.83                  56            0.86651
21Feb17_004504|   Test            22.68                  56            0.77969
21Feb17_004504|-------------------- Test #2 --------------------
21Feb17_004504|Best final individual weights
21Feb17_004504|Individual:
21Feb17_004504|-- Constant hidden layers --
21Feb17_004504|False
21Feb17_004504|Layer 0:
21Feb17_004504|-- Config --
21Feb17_004504|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004504|-- Weights --
21Feb17_004504|[[-0.73212  1.32861  0.10200]
21Feb17_004504| [ 1.48746 -2.97273 -0.42944]
21Feb17_004504| [ 0.53095 -1.50623  0.79224]
21Feb17_004504| [-1.07292 -0.83175 -0.90105]
21Feb17_004504| [-0.48696 -0.89325  0.27226]
21Feb17_004504| [-3.02511  0.34155 -0.03837]
21Feb17_004504| [-0.76747  0.57140 -0.46892]
21Feb17_004504| [-0.07581  0.14713  0.85910]
21Feb17_004504| [-1.37488  0.52170 -0.36205]
21Feb17_004504| [ 1.60981 -0.08727 -0.11267]
21Feb17_004504| [ 0.50986  1.58916 -0.35287]
21Feb17_004504| [-0.34599  1.27113 -0.16393]
21Feb17_004504| [ 1.29203  1.19467  0.37695]
21Feb17_004504| [ 0.58704  0.06328 -0.24240]
21Feb17_004504| [-0.93888 -0.89760  0.57087]
21Feb17_004504| [ 0.99159 -0.66387  0.35177]
21Feb17_004504| [-0.67119  1.06910 -0.12512]
21Feb17_004504| [-0.91534  1.23744 -0.40465]
21Feb17_004504| [ 1.39278  0.08069  0.23328]
21Feb17_004504| [ 0.09880  0.57603 -0.96101]
21Feb17_004504| [ 0.01621 -0.13343 -0.27624]
21Feb17_004504| [-1.28286 -2.28909  0.37931]
21Feb17_004504| [-0.28370  0.09336  0.01547]
21Feb17_004504| [-0.51894  1.84280 -0.25906]
21Feb17_004504| [-0.83075 -0.04508  0.12107]
21Feb17_004504| [ 0.37343  1.18436 -0.07358]
21Feb17_004504| [-2.38657 -0.35191  0.01962]
21Feb17_004504| [ 0.95757 -0.91760 -0.08971]
21Feb17_004504| [ 0.38792 -0.01880  0.69717]
21Feb17_004504| [ 1.66877 -0.58078 -1.21129]
21Feb17_004504| [-0.50943  0.59080  0.30856]
21Feb17_004504| [ 0.30163  1.11518  0.98185]
21Feb17_004504| [-0.73226  0.32281 -0.66712]
21Feb17_004504| [-0.62054 -2.21049  1.40981]
21Feb17_004504| [ 1.23185 -0.58090  0.35844]
21Feb17_004504| [-0.05616  0.24219 -0.02853]
21Feb17_004504| [-1.05085 -2.30259 -0.16276]
21Feb17_004504| [ 0.71087  0.14900  1.13430]
21Feb17_004504| [-2.45877 -1.20999 -1.04986]
21Feb17_004504| [-1.00480  1.36344 -0.13998]
21Feb17_004504| [ 1.83140 -0.91532  0.07616]
21Feb17_004504| [-0.60404 -2.05184  0.76948]
21Feb17_004504| [ 0.52617  0.76042 -1.76746]
21Feb17_004504| [-0.22134  0.17324  0.99530]
21Feb17_004504| [-0.36427  1.34655  0.02110]
21Feb17_004504| [-0.93125 -0.33620 -0.25012]
21Feb17_004504| [-2.76428  0.14487  0.48096]
21Feb17_004504| [-0.10518  0.35052  1.71840]
21Feb17_004504| [-1.27998  1.12568  1.26523]
21Feb17_004504| [-0.60698  1.53230 -0.60824]
21Feb17_004504| [ 0.02898  2.98718 -0.59153]
21Feb17_004504| [ 0.17588 -0.00449  0.50797]
21Feb17_004504| [-1.42674 -0.54967 -0.21310]
21Feb17_004504| [ 1.03196  1.18733  0.36755]
21Feb17_004504| [ 1.04748 -1.47444 -0.08469]
21Feb17_004504| [ 0.49410  0.38745  0.68469]
21Feb17_004504| [-0.62880  0.73245  0.19964]]
21Feb17_004504|-- Bias --
21Feb17_004504|[-0.18798  0.64571 -0.23142]
21Feb17_004504|Layer 1:
21Feb17_004504|-- Config --
21Feb17_004504|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004504|-- Weights --
21Feb17_004504|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_004504| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_004504| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_004504|-- Bias --
21Feb17_004504|[0.60477 0.03773 0.26452 0.12222]
21Feb17_004504|Layer 2:
21Feb17_004504|-- Config --
21Feb17_004504|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004504|-- Weights --
21Feb17_004504|[[ 0.67920  0.12119]
21Feb17_004504| [ 0.44836  0.02916]
21Feb17_004504| [ 0.68939  0.31516]
21Feb17_004504| [-0.58995 -0.05861]]
21Feb17_004504|-- Bias --
21Feb17_004504|[ 0.59649 -0.08079]
21Feb17_004504|Layer 3:
21Feb17_004504|-- Config --
21Feb17_004504|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004504|-- Weights --
21Feb17_004504|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_004504| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_004504|-- Bias --
21Feb17_004504|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_004504|Layer 4:
21Feb17_004504|-- Config --
21Feb17_004504|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004504|-- Weights --
21Feb17_004504|[[-0.03514 -1.04833]
21Feb17_004504| [ 1.25238  0.62094]
21Feb17_004504| [ 0.99203  0.37406]
21Feb17_004504| [ 0.49902  0.67158]
21Feb17_004504| [-1.35709  0.38335]]
21Feb17_004504|-- Bias --
21Feb17_004504|[0.31435 0.36299]
21Feb17_004504|Predicting the validation and test data with the Best final individual.
21Feb17_004511| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_004511|-----------  ------------------  --------------------  ----------
21Feb17_004511|Validation         23.91                  56            0.70865
21Feb17_004511|   Test            29.45                  56            0.70270
21Feb17_004511|-------------------- Test #3 --------------------
21Feb17_004511|Best final individual weights
21Feb17_004511|Individual:
21Feb17_004511|-- Constant hidden layers --
21Feb17_004511|False
21Feb17_004511|Layer 0:
21Feb17_004511|-- Config --
21Feb17_004511|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004511|-- Weights --
21Feb17_004511|[[-0.73212  1.32861  0.10200]
21Feb17_004511| [ 1.48746 -2.97273 -0.42944]
21Feb17_004511| [ 0.53095 -1.50623  0.79224]
21Feb17_004511| [-1.07292 -0.83175 -0.90105]
21Feb17_004511| [-0.48696 -0.89325  0.27226]
21Feb17_004511| [-3.02511  0.34155 -0.03837]
21Feb17_004511| [-0.76747  0.57140 -0.46892]
21Feb17_004511| [-0.07581  0.14713  0.85910]
21Feb17_004511| [-1.37488  0.52170 -0.36205]
21Feb17_004511| [ 1.60981 -0.08727 -0.11267]
21Feb17_004511| [ 0.50986  1.58916 -0.35287]
21Feb17_004511| [-0.34599  1.27113 -0.16393]
21Feb17_004511| [ 1.29203  1.19467  0.37695]
21Feb17_004511| [ 0.58704  0.06328 -0.24240]
21Feb17_004511| [-0.93888 -0.89760  0.57087]
21Feb17_004511| [ 0.99159 -0.66387  0.35177]
21Feb17_004511| [-0.67119  1.06910 -0.12512]
21Feb17_004511| [-0.91534  1.23744 -0.40465]
21Feb17_004511| [ 1.39278  0.08069  0.23328]
21Feb17_004511| [ 0.09880  0.57603 -0.96101]
21Feb17_004511| [ 0.01621 -0.13343 -0.27624]
21Feb17_004511| [-1.28286 -2.28909  0.37931]
21Feb17_004511| [-0.28370  0.09336  0.01547]
21Feb17_004511| [-0.51894  1.84280 -0.25906]
21Feb17_004511| [-0.83075 -0.04508  0.12107]
21Feb17_004511| [ 0.37343  1.18436 -0.07358]
21Feb17_004511| [-2.38657 -0.35191  0.01962]
21Feb17_004511| [ 0.95757 -0.91760 -0.08971]
21Feb17_004511| [ 0.38792 -0.01880  0.69717]
21Feb17_004511| [ 1.66877 -0.58078 -1.21129]
21Feb17_004511| [-0.50943  0.59080  0.30856]
21Feb17_004511| [ 0.30163  1.11518  0.98185]
21Feb17_004511| [-0.73226  0.32281 -0.66712]
21Feb17_004511| [-0.62054 -2.21049  1.40981]
21Feb17_004511| [ 1.23185 -0.58090  0.35844]
21Feb17_004511| [-0.05616  0.24219 -0.02853]
21Feb17_004511| [-1.05085 -2.30259 -0.16276]
21Feb17_004511| [ 0.71087  0.14900  1.13430]
21Feb17_004511| [-2.45877 -1.20999 -1.04986]
21Feb17_004511| [-1.00480  1.36344 -0.13998]
21Feb17_004511| [ 1.83140 -0.91532  0.07616]
21Feb17_004511| [-0.60404 -2.05184  0.76948]
21Feb17_004511| [ 0.52617  0.76042 -1.76746]
21Feb17_004511| [-0.22134  0.17324  0.99530]
21Feb17_004511| [-0.36427  1.34655  0.02110]
21Feb17_004511| [-0.93125 -0.33620 -0.25012]
21Feb17_004511| [-2.76428  0.14487  0.48096]
21Feb17_004511| [-0.10518  0.35052  1.71840]
21Feb17_004511| [-1.27998  1.12568  1.26523]
21Feb17_004511| [-0.60698  1.53230 -0.60824]
21Feb17_004511| [ 0.02898  2.98718 -0.59153]
21Feb17_004511| [ 0.17588 -0.00449  0.50797]
21Feb17_004511| [-1.42674 -0.54967 -0.21310]
21Feb17_004511| [ 1.03196  1.18733  0.36755]
21Feb17_004511| [ 1.04748 -1.47444 -0.08469]
21Feb17_004511| [ 0.49410  0.38745  0.68469]
21Feb17_004511| [-0.62880  0.73245  0.19964]]
21Feb17_004511|-- Bias --
21Feb17_004511|[-0.18798  0.64571 -0.23142]
21Feb17_004511|Layer 1:
21Feb17_004511|-- Config --
21Feb17_004511|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004511|-- Weights --
21Feb17_004511|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_004511| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_004511| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_004511|-- Bias --
21Feb17_004511|[0.60477 0.03773 0.26452 0.12222]
21Feb17_004511|Layer 2:
21Feb17_004511|-- Config --
21Feb17_004511|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004511|-- Weights --
21Feb17_004511|[[ 0.67920  0.12119]
21Feb17_004511| [ 0.44836  0.02916]
21Feb17_004511| [ 0.68939  0.31516]
21Feb17_004511| [-0.58995 -0.05861]]
21Feb17_004511|-- Bias --
21Feb17_004511|[ 0.59649 -0.08079]
21Feb17_004511|Layer 3:
21Feb17_004511|-- Config --
21Feb17_004511|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004511|-- Weights --
21Feb17_004511|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_004511| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_004511|-- Bias --
21Feb17_004511|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_004511|Layer 4:
21Feb17_004511|-- Config --
21Feb17_004511|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004511|-- Weights --
21Feb17_004511|[[-0.03514 -1.04833]
21Feb17_004511| [ 1.25238  0.62094]
21Feb17_004511| [ 0.99203  0.37406]
21Feb17_004511| [ 0.49902  0.67158]
21Feb17_004511| [-1.35709  0.38335]]
21Feb17_004511|-- Bias --
21Feb17_004511|[0.31435 0.36299]
21Feb17_004511|Predicting the validation and test data with the Best final individual.
21Feb17_004519| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_004519|-----------  ------------------  --------------------  ----------
21Feb17_004519|Validation         24.35                  56            0.84577
21Feb17_004519|   Test            21.63                  56            0.70714
21Feb17_004519|-------------------- Test #4 --------------------
21Feb17_004519|Best final individual weights
21Feb17_004519|Individual:
21Feb17_004519|-- Constant hidden layers --
21Feb17_004519|False
21Feb17_004519|Layer 0:
21Feb17_004519|-- Config --
21Feb17_004519|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004519|-- Weights --
21Feb17_004519|[[-0.73212  1.32861  0.10200]
21Feb17_004519| [ 1.48746 -2.97273 -0.42944]
21Feb17_004519| [ 0.53095 -1.50623  0.79224]
21Feb17_004519| [-1.07292 -0.83175 -0.90105]
21Feb17_004519| [-0.48696 -0.89325  0.27226]
21Feb17_004519| [-3.02511  0.34155 -0.03837]
21Feb17_004519| [-0.76747  0.57140 -0.46892]
21Feb17_004519| [-0.07581  0.14713  0.85910]
21Feb17_004519| [-1.37488  0.52170 -0.36205]
21Feb17_004519| [ 1.60981 -0.08727 -0.11267]
21Feb17_004519| [ 0.50986  1.58916 -0.35287]
21Feb17_004519| [-0.34599  1.27113 -0.16393]
21Feb17_004519| [ 1.29203  1.19467  0.37695]
21Feb17_004519| [ 0.58704  0.06328 -0.24240]
21Feb17_004519| [-0.93888 -0.89760  0.57087]
21Feb17_004519| [ 0.99159 -0.66387  0.35177]
21Feb17_004519| [-0.67119  1.06910 -0.12512]
21Feb17_004519| [-0.91534  1.23744 -0.40465]
21Feb17_004519| [ 1.39278  0.08069  0.23328]
21Feb17_004519| [ 0.09880  0.57603 -0.96101]
21Feb17_004519| [ 0.01621 -0.13343 -0.27624]
21Feb17_004519| [-1.28286 -2.28909  0.37931]
21Feb17_004519| [-0.28370  0.09336  0.01547]
21Feb17_004519| [-0.51894  1.84280 -0.25906]
21Feb17_004519| [-0.83075 -0.04508  0.12107]
21Feb17_004519| [ 0.37343  1.18436 -0.07358]
21Feb17_004519| [-2.38657 -0.35191  0.01962]
21Feb17_004519| [ 0.95757 -0.91760 -0.08971]
21Feb17_004519| [ 0.38792 -0.01880  0.69717]
21Feb17_004519| [ 1.66877 -0.58078 -1.21129]
21Feb17_004519| [-0.50943  0.59080  0.30856]
21Feb17_004519| [ 0.30163  1.11518  0.98185]
21Feb17_004519| [-0.73226  0.32281 -0.66712]
21Feb17_004519| [-0.62054 -2.21049  1.40981]
21Feb17_004519| [ 1.23185 -0.58090  0.35844]
21Feb17_004519| [-0.05616  0.24219 -0.02853]
21Feb17_004519| [-1.05085 -2.30259 -0.16276]
21Feb17_004519| [ 0.71087  0.14900  1.13430]
21Feb17_004519| [-2.45877 -1.20999 -1.04986]
21Feb17_004519| [-1.00480  1.36344 -0.13998]
21Feb17_004519| [ 1.83140 -0.91532  0.07616]
21Feb17_004519| [-0.60404 -2.05184  0.76948]
21Feb17_004519| [ 0.52617  0.76042 -1.76746]
21Feb17_004519| [-0.22134  0.17324  0.99530]
21Feb17_004519| [-0.36427  1.34655  0.02110]
21Feb17_004519| [-0.93125 -0.33620 -0.25012]
21Feb17_004519| [-2.76428  0.14487  0.48096]
21Feb17_004519| [-0.10518  0.35052  1.71840]
21Feb17_004519| [-1.27998  1.12568  1.26523]
21Feb17_004519| [-0.60698  1.53230 -0.60824]
21Feb17_004519| [ 0.02898  2.98718 -0.59153]
21Feb17_004519| [ 0.17588 -0.00449  0.50797]
21Feb17_004519| [-1.42674 -0.54967 -0.21310]
21Feb17_004519| [ 1.03196  1.18733  0.36755]
21Feb17_004519| [ 1.04748 -1.47444 -0.08469]
21Feb17_004519| [ 0.49410  0.38745  0.68469]
21Feb17_004519| [-0.62880  0.73245  0.19964]]
21Feb17_004519|-- Bias --
21Feb17_004519|[-0.18798  0.64571 -0.23142]
21Feb17_004519|Layer 1:
21Feb17_004519|-- Config --
21Feb17_004519|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004519|-- Weights --
21Feb17_004519|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_004519| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_004519| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_004519|-- Bias --
21Feb17_004519|[0.60477 0.03773 0.26452 0.12222]
21Feb17_004519|Layer 2:
21Feb17_004519|-- Config --
21Feb17_004519|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004519|-- Weights --
21Feb17_004519|[[ 0.67920  0.12119]
21Feb17_004519| [ 0.44836  0.02916]
21Feb17_004519| [ 0.68939  0.31516]
21Feb17_004519| [-0.58995 -0.05861]]
21Feb17_004519|-- Bias --
21Feb17_004519|[ 0.59649 -0.08079]
21Feb17_004519|Layer 3:
21Feb17_004519|-- Config --
21Feb17_004519|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004519|-- Weights --
21Feb17_004519|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_004519| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_004519|-- Bias --
21Feb17_004519|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_004519|Layer 4:
21Feb17_004519|-- Config --
21Feb17_004519|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004519|-- Weights --
21Feb17_004519|[[-0.03514 -1.04833]
21Feb17_004519| [ 1.25238  0.62094]
21Feb17_004519| [ 0.99203  0.37406]
21Feb17_004519| [ 0.49902  0.67158]
21Feb17_004519| [-1.35709  0.38335]]
21Feb17_004519|-- Bias --
21Feb17_004519|[0.31435 0.36299]
21Feb17_004519|Predicting the validation and test data with the Best final individual.
21Feb17_004526| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_004526|-----------  ------------------  --------------------  ----------
21Feb17_004526|Validation         21.57                  56            0.82113
21Feb17_004526|   Test            31.19                  56            0.83333
21Feb17_004526|-------------------- Test #5 --------------------
21Feb17_004526|Best final individual weights
21Feb17_004526|Individual:
21Feb17_004526|-- Constant hidden layers --
21Feb17_004526|False
21Feb17_004526|Layer 0:
21Feb17_004526|-- Config --
21Feb17_004526|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004526|-- Weights --
21Feb17_004526|[[-0.73212  1.32861  0.10200]
21Feb17_004526| [ 1.48746 -2.97273 -0.42944]
21Feb17_004526| [ 0.53095 -1.50623  0.79224]
21Feb17_004526| [-1.07292 -0.83175 -0.90105]
21Feb17_004526| [-0.48696 -0.89325  0.27226]
21Feb17_004526| [-3.02511  0.34155 -0.03837]
21Feb17_004526| [-0.76747  0.57140 -0.46892]
21Feb17_004526| [-0.07581  0.14713  0.85910]
21Feb17_004526| [-1.37488  0.52170 -0.36205]
21Feb17_004526| [ 1.60981 -0.08727 -0.11267]
21Feb17_004526| [ 0.50986  1.58916 -0.35287]
21Feb17_004526| [-0.34599  1.27113 -0.16393]
21Feb17_004526| [ 1.29203  1.19467  0.37695]
21Feb17_004526| [ 0.58704  0.06328 -0.24240]
21Feb17_004526| [-0.93888 -0.89760  0.57087]
21Feb17_004526| [ 0.99159 -0.66387  0.35177]
21Feb17_004526| [-0.67119  1.06910 -0.12512]
21Feb17_004526| [-0.91534  1.23744 -0.40465]
21Feb17_004526| [ 1.39278  0.08069  0.23328]
21Feb17_004526| [ 0.09880  0.57603 -0.96101]
21Feb17_004526| [ 0.01621 -0.13343 -0.27624]
21Feb17_004526| [-1.28286 -2.28909  0.37931]
21Feb17_004526| [-0.28370  0.09336  0.01547]
21Feb17_004526| [-0.51894  1.84280 -0.25906]
21Feb17_004526| [-0.83075 -0.04508  0.12107]
21Feb17_004526| [ 0.37343  1.18436 -0.07358]
21Feb17_004526| [-2.38657 -0.35191  0.01962]
21Feb17_004526| [ 0.95757 -0.91760 -0.08971]
21Feb17_004526| [ 0.38792 -0.01880  0.69717]
21Feb17_004526| [ 1.66877 -0.58078 -1.21129]
21Feb17_004526| [-0.50943  0.59080  0.30856]
21Feb17_004526| [ 0.30163  1.11518  0.98185]
21Feb17_004526| [-0.73226  0.32281 -0.66712]
21Feb17_004526| [-0.62054 -2.21049  1.40981]
21Feb17_004526| [ 1.23185 -0.58090  0.35844]
21Feb17_004526| [-0.05616  0.24219 -0.02853]
21Feb17_004526| [-1.05085 -2.30259 -0.16276]
21Feb17_004526| [ 0.71087  0.14900  1.13430]
21Feb17_004526| [-2.45877 -1.20999 -1.04986]
21Feb17_004526| [-1.00480  1.36344 -0.13998]
21Feb17_004526| [ 1.83140 -0.91532  0.07616]
21Feb17_004526| [-0.60404 -2.05184  0.76948]
21Feb17_004526| [ 0.52617  0.76042 -1.76746]
21Feb17_004526| [-0.22134  0.17324  0.99530]
21Feb17_004526| [-0.36427  1.34655  0.02110]
21Feb17_004526| [-0.93125 -0.33620 -0.25012]
21Feb17_004526| [-2.76428  0.14487  0.48096]
21Feb17_004526| [-0.10518  0.35052  1.71840]
21Feb17_004526| [-1.27998  1.12568  1.26523]
21Feb17_004526| [-0.60698  1.53230 -0.60824]
21Feb17_004526| [ 0.02898  2.98718 -0.59153]
21Feb17_004526| [ 0.17588 -0.00449  0.50797]
21Feb17_004526| [-1.42674 -0.54967 -0.21310]
21Feb17_004526| [ 1.03196  1.18733  0.36755]
21Feb17_004526| [ 1.04748 -1.47444 -0.08469]
21Feb17_004526| [ 0.49410  0.38745  0.68469]
21Feb17_004526| [-0.62880  0.73245  0.19964]]
21Feb17_004526|-- Bias --
21Feb17_004526|[-0.18798  0.64571 -0.23142]
21Feb17_004526|Layer 1:
21Feb17_004526|-- Config --
21Feb17_004526|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004526|-- Weights --
21Feb17_004526|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_004526| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_004526| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_004526|-- Bias --
21Feb17_004526|[0.60477 0.03773 0.26452 0.12222]
21Feb17_004526|Layer 2:
21Feb17_004526|-- Config --
21Feb17_004526|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004526|-- Weights --
21Feb17_004526|[[ 0.67920  0.12119]
21Feb17_004526| [ 0.44836  0.02916]
21Feb17_004526| [ 0.68939  0.31516]
21Feb17_004526| [-0.58995 -0.05861]]
21Feb17_004526|-- Bias --
21Feb17_004526|[ 0.59649 -0.08079]
21Feb17_004526|Layer 3:
21Feb17_004526|-- Config --
21Feb17_004526|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004526|-- Weights --
21Feb17_004526|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_004526| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_004526|-- Bias --
21Feb17_004526|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_004526|Layer 4:
21Feb17_004526|-- Config --
21Feb17_004526|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004526|-- Weights --
21Feb17_004526|[[-0.03514 -1.04833]
21Feb17_004526| [ 1.25238  0.62094]
21Feb17_004526| [ 0.99203  0.37406]
21Feb17_004526| [ 0.49902  0.67158]
21Feb17_004526| [-1.35709  0.38335]]
21Feb17_004526|-- Bias --
21Feb17_004526|[0.31435 0.36299]
21Feb17_004526|Predicting the validation and test data with the Best final individual.
21Feb17_004534| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_004534|-----------  ------------------  --------------------  ----------
21Feb17_004534|Validation         23.22                  56            0.86009
21Feb17_004534|   Test            26.15                  56            0.85097
21Feb17_004534|-------------------- Test #6 --------------------
21Feb17_004534|Best final individual weights
21Feb17_004534|Individual:
21Feb17_004534|-- Constant hidden layers --
21Feb17_004534|False
21Feb17_004534|Layer 0:
21Feb17_004534|-- Config --
21Feb17_004534|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004534|-- Weights --
21Feb17_004534|[[-0.73212  1.32861  0.10200]
21Feb17_004534| [ 1.48746 -2.97273 -0.42944]
21Feb17_004534| [ 0.53095 -1.50623  0.79224]
21Feb17_004534| [-1.07292 -0.83175 -0.90105]
21Feb17_004534| [-0.48696 -0.89325  0.27226]
21Feb17_004534| [-3.02511  0.34155 -0.03837]
21Feb17_004534| [-0.76747  0.57140 -0.46892]
21Feb17_004534| [-0.07581  0.14713  0.85910]
21Feb17_004534| [-1.37488  0.52170 -0.36205]
21Feb17_004534| [ 1.60981 -0.08727 -0.11267]
21Feb17_004534| [ 0.50986  1.58916 -0.35287]
21Feb17_004534| [-0.34599  1.27113 -0.16393]
21Feb17_004534| [ 1.29203  1.19467  0.37695]
21Feb17_004534| [ 0.58704  0.06328 -0.24240]
21Feb17_004534| [-0.93888 -0.89760  0.57087]
21Feb17_004534| [ 0.99159 -0.66387  0.35177]
21Feb17_004534| [-0.67119  1.06910 -0.12512]
21Feb17_004534| [-0.91534  1.23744 -0.40465]
21Feb17_004534| [ 1.39278  0.08069  0.23328]
21Feb17_004534| [ 0.09880  0.57603 -0.96101]
21Feb17_004534| [ 0.01621 -0.13343 -0.27624]
21Feb17_004534| [-1.28286 -2.28909  0.37931]
21Feb17_004534| [-0.28370  0.09336  0.01547]
21Feb17_004534| [-0.51894  1.84280 -0.25906]
21Feb17_004534| [-0.83075 -0.04508  0.12107]
21Feb17_004534| [ 0.37343  1.18436 -0.07358]
21Feb17_004534| [-2.38657 -0.35191  0.01962]
21Feb17_004534| [ 0.95757 -0.91760 -0.08971]
21Feb17_004534| [ 0.38792 -0.01880  0.69717]
21Feb17_004534| [ 1.66877 -0.58078 -1.21129]
21Feb17_004534| [-0.50943  0.59080  0.30856]
21Feb17_004534| [ 0.30163  1.11518  0.98185]
21Feb17_004534| [-0.73226  0.32281 -0.66712]
21Feb17_004534| [-0.62054 -2.21049  1.40981]
21Feb17_004534| [ 1.23185 -0.58090  0.35844]
21Feb17_004534| [-0.05616  0.24219 -0.02853]
21Feb17_004534| [-1.05085 -2.30259 -0.16276]
21Feb17_004534| [ 0.71087  0.14900  1.13430]
21Feb17_004534| [-2.45877 -1.20999 -1.04986]
21Feb17_004534| [-1.00480  1.36344 -0.13998]
21Feb17_004534| [ 1.83140 -0.91532  0.07616]
21Feb17_004534| [-0.60404 -2.05184  0.76948]
21Feb17_004534| [ 0.52617  0.76042 -1.76746]
21Feb17_004534| [-0.22134  0.17324  0.99530]
21Feb17_004534| [-0.36427  1.34655  0.02110]
21Feb17_004534| [-0.93125 -0.33620 -0.25012]
21Feb17_004534| [-2.76428  0.14487  0.48096]
21Feb17_004534| [-0.10518  0.35052  1.71840]
21Feb17_004534| [-1.27998  1.12568  1.26523]
21Feb17_004534| [-0.60698  1.53230 -0.60824]
21Feb17_004534| [ 0.02898  2.98718 -0.59153]
21Feb17_004534| [ 0.17588 -0.00449  0.50797]
21Feb17_004534| [-1.42674 -0.54967 -0.21310]
21Feb17_004534| [ 1.03196  1.18733  0.36755]
21Feb17_004534| [ 1.04748 -1.47444 -0.08469]
21Feb17_004534| [ 0.49410  0.38745  0.68469]
21Feb17_004534| [-0.62880  0.73245  0.19964]]
21Feb17_004534|-- Bias --
21Feb17_004534|[-0.18798  0.64571 -0.23142]
21Feb17_004534|Layer 1:
21Feb17_004534|-- Config --
21Feb17_004534|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004534|-- Weights --
21Feb17_004534|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_004534| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_004534| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_004534|-- Bias --
21Feb17_004534|[0.60477 0.03773 0.26452 0.12222]
21Feb17_004534|Layer 2:
21Feb17_004534|-- Config --
21Feb17_004534|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004534|-- Weights --
21Feb17_004534|[[ 0.67920  0.12119]
21Feb17_004534| [ 0.44836  0.02916]
21Feb17_004534| [ 0.68939  0.31516]
21Feb17_004534| [-0.58995 -0.05861]]
21Feb17_004534|-- Bias --
21Feb17_004534|[ 0.59649 -0.08079]
21Feb17_004534|Layer 3:
21Feb17_004534|-- Config --
21Feb17_004534|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004534|-- Weights --
21Feb17_004534|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_004534| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_004534|-- Bias --
21Feb17_004534|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_004534|Layer 4:
21Feb17_004534|-- Config --
21Feb17_004534|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004534|-- Weights --
21Feb17_004534|[[-0.03514 -1.04833]
21Feb17_004534| [ 1.25238  0.62094]
21Feb17_004534| [ 0.99203  0.37406]
21Feb17_004534| [ 0.49902  0.67158]
21Feb17_004534| [-1.35709  0.38335]]
21Feb17_004534|-- Bias --
21Feb17_004534|[0.31435 0.36299]
21Feb17_004534|Predicting the validation and test data with the Best final individual.
21Feb17_004541| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_004541|-----------  ------------------  --------------------  ----------
21Feb17_004541|Validation         22.78                  56            0.83496
21Feb17_004541|   Test            21.11                  56            0.79855
21Feb17_004541|-------------------- Test #7 --------------------
21Feb17_004541|Best final individual weights
21Feb17_004541|Individual:
21Feb17_004541|-- Constant hidden layers --
21Feb17_004541|False
21Feb17_004541|Layer 0:
21Feb17_004541|-- Config --
21Feb17_004541|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004541|-- Weights --
21Feb17_004541|[[-0.73212  1.32861  0.10200]
21Feb17_004541| [ 1.48746 -2.97273 -0.42944]
21Feb17_004541| [ 0.53095 -1.50623  0.79224]
21Feb17_004541| [-1.07292 -0.83175 -0.90105]
21Feb17_004541| [-0.48696 -0.89325  0.27226]
21Feb17_004541| [-3.02511  0.34155 -0.03837]
21Feb17_004541| [-0.76747  0.57140 -0.46892]
21Feb17_004541| [-0.07581  0.14713  0.85910]
21Feb17_004541| [-1.37488  0.52170 -0.36205]
21Feb17_004541| [ 1.60981 -0.08727 -0.11267]
21Feb17_004541| [ 0.50986  1.58916 -0.35287]
21Feb17_004541| [-0.34599  1.27113 -0.16393]
21Feb17_004541| [ 1.29203  1.19467  0.37695]
21Feb17_004541| [ 0.58704  0.06328 -0.24240]
21Feb17_004541| [-0.93888 -0.89760  0.57087]
21Feb17_004541| [ 0.99159 -0.66387  0.35177]
21Feb17_004541| [-0.67119  1.06910 -0.12512]
21Feb17_004541| [-0.91534  1.23744 -0.40465]
21Feb17_004541| [ 1.39278  0.08069  0.23328]
21Feb17_004541| [ 0.09880  0.57603 -0.96101]
21Feb17_004541| [ 0.01621 -0.13343 -0.27624]
21Feb17_004541| [-1.28286 -2.28909  0.37931]
21Feb17_004541| [-0.28370  0.09336  0.01547]
21Feb17_004541| [-0.51894  1.84280 -0.25906]
21Feb17_004541| [-0.83075 -0.04508  0.12107]
21Feb17_004541| [ 0.37343  1.18436 -0.07358]
21Feb17_004541| [-2.38657 -0.35191  0.01962]
21Feb17_004541| [ 0.95757 -0.91760 -0.08971]
21Feb17_004541| [ 0.38792 -0.01880  0.69717]
21Feb17_004541| [ 1.66877 -0.58078 -1.21129]
21Feb17_004541| [-0.50943  0.59080  0.30856]
21Feb17_004541| [ 0.30163  1.11518  0.98185]
21Feb17_004541| [-0.73226  0.32281 -0.66712]
21Feb17_004541| [-0.62054 -2.21049  1.40981]
21Feb17_004541| [ 1.23185 -0.58090  0.35844]
21Feb17_004541| [-0.05616  0.24219 -0.02853]
21Feb17_004541| [-1.05085 -2.30259 -0.16276]
21Feb17_004541| [ 0.71087  0.14900  1.13430]
21Feb17_004541| [-2.45877 -1.20999 -1.04986]
21Feb17_004541| [-1.00480  1.36344 -0.13998]
21Feb17_004541| [ 1.83140 -0.91532  0.07616]
21Feb17_004541| [-0.60404 -2.05184  0.76948]
21Feb17_004541| [ 0.52617  0.76042 -1.76746]
21Feb17_004541| [-0.22134  0.17324  0.99530]
21Feb17_004541| [-0.36427  1.34655  0.02110]
21Feb17_004541| [-0.93125 -0.33620 -0.25012]
21Feb17_004541| [-2.76428  0.14487  0.48096]
21Feb17_004541| [-0.10518  0.35052  1.71840]
21Feb17_004541| [-1.27998  1.12568  1.26523]
21Feb17_004541| [-0.60698  1.53230 -0.60824]
21Feb17_004541| [ 0.02898  2.98718 -0.59153]
21Feb17_004541| [ 0.17588 -0.00449  0.50797]
21Feb17_004541| [-1.42674 -0.54967 -0.21310]
21Feb17_004541| [ 1.03196  1.18733  0.36755]
21Feb17_004541| [ 1.04748 -1.47444 -0.08469]
21Feb17_004541| [ 0.49410  0.38745  0.68469]
21Feb17_004541| [-0.62880  0.73245  0.19964]]
21Feb17_004541|-- Bias --
21Feb17_004541|[-0.18798  0.64571 -0.23142]
21Feb17_004541|Layer 1:
21Feb17_004541|-- Config --
21Feb17_004541|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004541|-- Weights --
21Feb17_004541|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_004541| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_004541| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_004541|-- Bias --
21Feb17_004541|[0.60477 0.03773 0.26452 0.12222]
21Feb17_004541|Layer 2:
21Feb17_004541|-- Config --
21Feb17_004541|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004541|-- Weights --
21Feb17_004541|[[ 0.67920  0.12119]
21Feb17_004541| [ 0.44836  0.02916]
21Feb17_004541| [ 0.68939  0.31516]
21Feb17_004541| [-0.58995 -0.05861]]
21Feb17_004541|-- Bias --
21Feb17_004541|[ 0.59649 -0.08079]
21Feb17_004541|Layer 3:
21Feb17_004541|-- Config --
21Feb17_004541|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004541|-- Weights --
21Feb17_004541|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_004541| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_004541|-- Bias --
21Feb17_004541|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_004541|Layer 4:
21Feb17_004541|-- Config --
21Feb17_004541|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004541|-- Weights --
21Feb17_004541|[[-0.03514 -1.04833]
21Feb17_004541| [ 1.25238  0.62094]
21Feb17_004541| [ 0.99203  0.37406]
21Feb17_004541| [ 0.49902  0.67158]
21Feb17_004541| [-1.35709  0.38335]]
21Feb17_004541|-- Bias --
21Feb17_004541|[0.31435 0.36299]
21Feb17_004541|Predicting the validation and test data with the Best final individual.
21Feb17_004549| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_004549|-----------  ------------------  --------------------  ----------
21Feb17_004549|Validation         28.96                  56            0.48780
21Feb17_004549|   Test            25.46                  56            0.49431
21Feb17_004549|-------------------- Test #8 --------------------
21Feb17_004549|Best final individual weights
21Feb17_004549|Individual:
21Feb17_004549|-- Constant hidden layers --
21Feb17_004549|False
21Feb17_004549|Layer 0:
21Feb17_004549|-- Config --
21Feb17_004549|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004549|-- Weights --
21Feb17_004549|[[-0.73212  1.32861  0.10200]
21Feb17_004549| [ 1.48746 -2.97273 -0.42944]
21Feb17_004549| [ 0.53095 -1.50623  0.79224]
21Feb17_004549| [-1.07292 -0.83175 -0.90105]
21Feb17_004549| [-0.48696 -0.89325  0.27226]
21Feb17_004549| [-3.02511  0.34155 -0.03837]
21Feb17_004549| [-0.76747  0.57140 -0.46892]
21Feb17_004549| [-0.07581  0.14713  0.85910]
21Feb17_004549| [-1.37488  0.52170 -0.36205]
21Feb17_004549| [ 1.60981 -0.08727 -0.11267]
21Feb17_004549| [ 0.50986  1.58916 -0.35287]
21Feb17_004549| [-0.34599  1.27113 -0.16393]
21Feb17_004549| [ 1.29203  1.19467  0.37695]
21Feb17_004549| [ 0.58704  0.06328 -0.24240]
21Feb17_004549| [-0.93888 -0.89760  0.57087]
21Feb17_004549| [ 0.99159 -0.66387  0.35177]
21Feb17_004549| [-0.67119  1.06910 -0.12512]
21Feb17_004549| [-0.91534  1.23744 -0.40465]
21Feb17_004549| [ 1.39278  0.08069  0.23328]
21Feb17_004549| [ 0.09880  0.57603 -0.96101]
21Feb17_004549| [ 0.01621 -0.13343 -0.27624]
21Feb17_004549| [-1.28286 -2.28909  0.37931]
21Feb17_004549| [-0.28370  0.09336  0.01547]
21Feb17_004549| [-0.51894  1.84280 -0.25906]
21Feb17_004549| [-0.83075 -0.04508  0.12107]
21Feb17_004549| [ 0.37343  1.18436 -0.07358]
21Feb17_004549| [-2.38657 -0.35191  0.01962]
21Feb17_004549| [ 0.95757 -0.91760 -0.08971]
21Feb17_004549| [ 0.38792 -0.01880  0.69717]
21Feb17_004549| [ 1.66877 -0.58078 -1.21129]
21Feb17_004549| [-0.50943  0.59080  0.30856]
21Feb17_004549| [ 0.30163  1.11518  0.98185]
21Feb17_004549| [-0.73226  0.32281 -0.66712]
21Feb17_004549| [-0.62054 -2.21049  1.40981]
21Feb17_004549| [ 1.23185 -0.58090  0.35844]
21Feb17_004549| [-0.05616  0.24219 -0.02853]
21Feb17_004549| [-1.05085 -2.30259 -0.16276]
21Feb17_004549| [ 0.71087  0.14900  1.13430]
21Feb17_004549| [-2.45877 -1.20999 -1.04986]
21Feb17_004549| [-1.00480  1.36344 -0.13998]
21Feb17_004549| [ 1.83140 -0.91532  0.07616]
21Feb17_004549| [-0.60404 -2.05184  0.76948]
21Feb17_004549| [ 0.52617  0.76042 -1.76746]
21Feb17_004549| [-0.22134  0.17324  0.99530]
21Feb17_004549| [-0.36427  1.34655  0.02110]
21Feb17_004549| [-0.93125 -0.33620 -0.25012]
21Feb17_004549| [-2.76428  0.14487  0.48096]
21Feb17_004549| [-0.10518  0.35052  1.71840]
21Feb17_004549| [-1.27998  1.12568  1.26523]
21Feb17_004549| [-0.60698  1.53230 -0.60824]
21Feb17_004549| [ 0.02898  2.98718 -0.59153]
21Feb17_004549| [ 0.17588 -0.00449  0.50797]
21Feb17_004549| [-1.42674 -0.54967 -0.21310]
21Feb17_004549| [ 1.03196  1.18733  0.36755]
21Feb17_004549| [ 1.04748 -1.47444 -0.08469]
21Feb17_004549| [ 0.49410  0.38745  0.68469]
21Feb17_004549| [-0.62880  0.73245  0.19964]]
21Feb17_004549|-- Bias --
21Feb17_004549|[-0.18798  0.64571 -0.23142]
21Feb17_004549|Layer 1:
21Feb17_004549|-- Config --
21Feb17_004549|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004549|-- Weights --
21Feb17_004549|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_004549| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_004549| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_004549|-- Bias --
21Feb17_004549|[0.60477 0.03773 0.26452 0.12222]
21Feb17_004549|Layer 2:
21Feb17_004549|-- Config --
21Feb17_004549|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004549|-- Weights --
21Feb17_004549|[[ 0.67920  0.12119]
21Feb17_004549| [ 0.44836  0.02916]
21Feb17_004549| [ 0.68939  0.31516]
21Feb17_004549| [-0.58995 -0.05861]]
21Feb17_004549|-- Bias --
21Feb17_004549|[ 0.59649 -0.08079]
21Feb17_004549|Layer 3:
21Feb17_004549|-- Config --
21Feb17_004549|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004549|-- Weights --
21Feb17_004549|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_004549| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_004549|-- Bias --
21Feb17_004549|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_004549|Layer 4:
21Feb17_004549|-- Config --
21Feb17_004549|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004549|-- Weights --
21Feb17_004549|[[-0.03514 -1.04833]
21Feb17_004549| [ 1.25238  0.62094]
21Feb17_004549| [ 0.99203  0.37406]
21Feb17_004549| [ 0.49902  0.67158]
21Feb17_004549| [-1.35709  0.38335]]
21Feb17_004549|-- Bias --
21Feb17_004549|[0.31435 0.36299]
21Feb17_004549|Predicting the validation and test data with the Best final individual.
21Feb17_004556| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_004556|-----------  ------------------  --------------------  ----------
21Feb17_004556|Validation         21.30                  56            0.82476
21Feb17_004556|   Test            21.81                  56            0.83186
21Feb17_004556|-------------------- Test #9 --------------------
21Feb17_004556|Best final individual weights
21Feb17_004556|Individual:
21Feb17_004556|-- Constant hidden layers --
21Feb17_004556|False
21Feb17_004556|Layer 0:
21Feb17_004556|-- Config --
21Feb17_004556|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004556|-- Weights --
21Feb17_004556|[[-0.73212  1.32861  0.10200]
21Feb17_004556| [ 1.48746 -2.97273 -0.42944]
21Feb17_004556| [ 0.53095 -1.50623  0.79224]
21Feb17_004556| [-1.07292 -0.83175 -0.90105]
21Feb17_004556| [-0.48696 -0.89325  0.27226]
21Feb17_004556| [-3.02511  0.34155 -0.03837]
21Feb17_004556| [-0.76747  0.57140 -0.46892]
21Feb17_004556| [-0.07581  0.14713  0.85910]
21Feb17_004556| [-1.37488  0.52170 -0.36205]
21Feb17_004556| [ 1.60981 -0.08727 -0.11267]
21Feb17_004556| [ 0.50986  1.58916 -0.35287]
21Feb17_004556| [-0.34599  1.27113 -0.16393]
21Feb17_004556| [ 1.29203  1.19467  0.37695]
21Feb17_004556| [ 0.58704  0.06328 -0.24240]
21Feb17_004556| [-0.93888 -0.89760  0.57087]
21Feb17_004556| [ 0.99159 -0.66387  0.35177]
21Feb17_004556| [-0.67119  1.06910 -0.12512]
21Feb17_004556| [-0.91534  1.23744 -0.40465]
21Feb17_004556| [ 1.39278  0.08069  0.23328]
21Feb17_004556| [ 0.09880  0.57603 -0.96101]
21Feb17_004556| [ 0.01621 -0.13343 -0.27624]
21Feb17_004556| [-1.28286 -2.28909  0.37931]
21Feb17_004556| [-0.28370  0.09336  0.01547]
21Feb17_004556| [-0.51894  1.84280 -0.25906]
21Feb17_004556| [-0.83075 -0.04508  0.12107]
21Feb17_004556| [ 0.37343  1.18436 -0.07358]
21Feb17_004556| [-2.38657 -0.35191  0.01962]
21Feb17_004556| [ 0.95757 -0.91760 -0.08971]
21Feb17_004556| [ 0.38792 -0.01880  0.69717]
21Feb17_004556| [ 1.66877 -0.58078 -1.21129]
21Feb17_004556| [-0.50943  0.59080  0.30856]
21Feb17_004556| [ 0.30163  1.11518  0.98185]
21Feb17_004556| [-0.73226  0.32281 -0.66712]
21Feb17_004556| [-0.62054 -2.21049  1.40981]
21Feb17_004556| [ 1.23185 -0.58090  0.35844]
21Feb17_004556| [-0.05616  0.24219 -0.02853]
21Feb17_004556| [-1.05085 -2.30259 -0.16276]
21Feb17_004556| [ 0.71087  0.14900  1.13430]
21Feb17_004556| [-2.45877 -1.20999 -1.04986]
21Feb17_004556| [-1.00480  1.36344 -0.13998]
21Feb17_004556| [ 1.83140 -0.91532  0.07616]
21Feb17_004556| [-0.60404 -2.05184  0.76948]
21Feb17_004556| [ 0.52617  0.76042 -1.76746]
21Feb17_004556| [-0.22134  0.17324  0.99530]
21Feb17_004556| [-0.36427  1.34655  0.02110]
21Feb17_004556| [-0.93125 -0.33620 -0.25012]
21Feb17_004556| [-2.76428  0.14487  0.48096]
21Feb17_004556| [-0.10518  0.35052  1.71840]
21Feb17_004556| [-1.27998  1.12568  1.26523]
21Feb17_004556| [-0.60698  1.53230 -0.60824]
21Feb17_004556| [ 0.02898  2.98718 -0.59153]
21Feb17_004556| [ 0.17588 -0.00449  0.50797]
21Feb17_004556| [-1.42674 -0.54967 -0.21310]
21Feb17_004556| [ 1.03196  1.18733  0.36755]
21Feb17_004556| [ 1.04748 -1.47444 -0.08469]
21Feb17_004556| [ 0.49410  0.38745  0.68469]
21Feb17_004556| [-0.62880  0.73245  0.19964]]
21Feb17_004556|-- Bias --
21Feb17_004556|[-0.18798  0.64571 -0.23142]
21Feb17_004556|Layer 1:
21Feb17_004556|-- Config --
21Feb17_004556|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004556|-- Weights --
21Feb17_004556|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_004556| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_004556| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_004556|-- Bias --
21Feb17_004556|[0.60477 0.03773 0.26452 0.12222]
21Feb17_004556|Layer 2:
21Feb17_004556|-- Config --
21Feb17_004556|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004556|-- Weights --
21Feb17_004556|[[ 0.67920  0.12119]
21Feb17_004556| [ 0.44836  0.02916]
21Feb17_004556| [ 0.68939  0.31516]
21Feb17_004556| [-0.58995 -0.05861]]
21Feb17_004556|-- Bias --
21Feb17_004556|[ 0.59649 -0.08079]
21Feb17_004556|Layer 3:
21Feb17_004556|-- Config --
21Feb17_004556|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004556|-- Weights --
21Feb17_004556|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_004556| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_004556|-- Bias --
21Feb17_004556|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_004556|Layer 4:
21Feb17_004556|-- Config --
21Feb17_004556|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004556|-- Weights --
21Feb17_004556|[[-0.03514 -1.04833]
21Feb17_004556| [ 1.25238  0.62094]
21Feb17_004556| [ 0.99203  0.37406]
21Feb17_004556| [ 0.49902  0.67158]
21Feb17_004556| [-1.35709  0.38335]]
21Feb17_004556|-- Bias --
21Feb17_004556|[0.31435 0.36299]
21Feb17_004556|Predicting the validation and test data with the Best final individual.
21Feb17_004604| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_004604|-----------  ------------------  --------------------  ----------
21Feb17_004604|Validation         26.43                  56            0.71922
21Feb17_004604|   Test            29.54                  56            0.67444
21Feb17_004604|-------------------- Test #10 --------------------
21Feb17_004604|Best final individual weights
21Feb17_004604|Individual:
21Feb17_004604|-- Constant hidden layers --
21Feb17_004604|False
21Feb17_004604|Layer 0:
21Feb17_004604|-- Config --
21Feb17_004604|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004604|-- Weights --
21Feb17_004604|[[-0.73212  1.32861  0.10200]
21Feb17_004604| [ 1.48746 -2.97273 -0.42944]
21Feb17_004604| [ 0.53095 -1.50623  0.79224]
21Feb17_004604| [-1.07292 -0.83175 -0.90105]
21Feb17_004604| [-0.48696 -0.89325  0.27226]
21Feb17_004604| [-3.02511  0.34155 -0.03837]
21Feb17_004604| [-0.76747  0.57140 -0.46892]
21Feb17_004604| [-0.07581  0.14713  0.85910]
21Feb17_004604| [-1.37488  0.52170 -0.36205]
21Feb17_004604| [ 1.60981 -0.08727 -0.11267]
21Feb17_004604| [ 0.50986  1.58916 -0.35287]
21Feb17_004604| [-0.34599  1.27113 -0.16393]
21Feb17_004604| [ 1.29203  1.19467  0.37695]
21Feb17_004604| [ 0.58704  0.06328 -0.24240]
21Feb17_004604| [-0.93888 -0.89760  0.57087]
21Feb17_004604| [ 0.99159 -0.66387  0.35177]
21Feb17_004604| [-0.67119  1.06910 -0.12512]
21Feb17_004604| [-0.91534  1.23744 -0.40465]
21Feb17_004604| [ 1.39278  0.08069  0.23328]
21Feb17_004604| [ 0.09880  0.57603 -0.96101]
21Feb17_004604| [ 0.01621 -0.13343 -0.27624]
21Feb17_004604| [-1.28286 -2.28909  0.37931]
21Feb17_004604| [-0.28370  0.09336  0.01547]
21Feb17_004604| [-0.51894  1.84280 -0.25906]
21Feb17_004604| [-0.83075 -0.04508  0.12107]
21Feb17_004604| [ 0.37343  1.18436 -0.07358]
21Feb17_004604| [-2.38657 -0.35191  0.01962]
21Feb17_004604| [ 0.95757 -0.91760 -0.08971]
21Feb17_004604| [ 0.38792 -0.01880  0.69717]
21Feb17_004604| [ 1.66877 -0.58078 -1.21129]
21Feb17_004604| [-0.50943  0.59080  0.30856]
21Feb17_004604| [ 0.30163  1.11518  0.98185]
21Feb17_004604| [-0.73226  0.32281 -0.66712]
21Feb17_004604| [-0.62054 -2.21049  1.40981]
21Feb17_004604| [ 1.23185 -0.58090  0.35844]
21Feb17_004604| [-0.05616  0.24219 -0.02853]
21Feb17_004604| [-1.05085 -2.30259 -0.16276]
21Feb17_004604| [ 0.71087  0.14900  1.13430]
21Feb17_004604| [-2.45877 -1.20999 -1.04986]
21Feb17_004604| [-1.00480  1.36344 -0.13998]
21Feb17_004604| [ 1.83140 -0.91532  0.07616]
21Feb17_004604| [-0.60404 -2.05184  0.76948]
21Feb17_004604| [ 0.52617  0.76042 -1.76746]
21Feb17_004604| [-0.22134  0.17324  0.99530]
21Feb17_004604| [-0.36427  1.34655  0.02110]
21Feb17_004604| [-0.93125 -0.33620 -0.25012]
21Feb17_004604| [-2.76428  0.14487  0.48096]
21Feb17_004604| [-0.10518  0.35052  1.71840]
21Feb17_004604| [-1.27998  1.12568  1.26523]
21Feb17_004604| [-0.60698  1.53230 -0.60824]
21Feb17_004604| [ 0.02898  2.98718 -0.59153]
21Feb17_004604| [ 0.17588 -0.00449  0.50797]
21Feb17_004604| [-1.42674 -0.54967 -0.21310]
21Feb17_004604| [ 1.03196  1.18733  0.36755]
21Feb17_004604| [ 1.04748 -1.47444 -0.08469]
21Feb17_004604| [ 0.49410  0.38745  0.68469]
21Feb17_004604| [-0.62880  0.73245  0.19964]]
21Feb17_004604|-- Bias --
21Feb17_004604|[-0.18798  0.64571 -0.23142]
21Feb17_004604|Layer 1:
21Feb17_004604|-- Config --
21Feb17_004604|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004604|-- Weights --
21Feb17_004604|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_004604| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_004604| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_004604|-- Bias --
21Feb17_004604|[0.60477 0.03773 0.26452 0.12222]
21Feb17_004604|Layer 2:
21Feb17_004604|-- Config --
21Feb17_004604|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004604|-- Weights --
21Feb17_004604|[[ 0.67920  0.12119]
21Feb17_004604| [ 0.44836  0.02916]
21Feb17_004604| [ 0.68939  0.31516]
21Feb17_004604| [-0.58995 -0.05861]]
21Feb17_004604|-- Bias --
21Feb17_004604|[ 0.59649 -0.08079]
21Feb17_004604|Layer 3:
21Feb17_004604|-- Config --
21Feb17_004604|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004604|-- Weights --
21Feb17_004604|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_004604| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_004604|-- Bias --
21Feb17_004604|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_004604|Layer 4:
21Feb17_004604|-- Config --
21Feb17_004604|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004604|-- Weights --
21Feb17_004604|[[-0.03514 -1.04833]
21Feb17_004604| [ 1.25238  0.62094]
21Feb17_004604| [ 0.99203  0.37406]
21Feb17_004604| [ 0.49902  0.67158]
21Feb17_004604| [-1.35709  0.38335]]
21Feb17_004604|-- Bias --
21Feb17_004604|[0.31435 0.36299]
21Feb17_004604|Predicting the validation and test data with the Best final individual.
21Feb17_004612| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_004612|-----------  ------------------  --------------------  ----------
21Feb17_004612|Validation         23.65                  56            0.85845
21Feb17_004612|   Test            26.67                  56            0.71298
21Feb17_004612|-------------------- Test #11 --------------------
21Feb17_004612|Best final individual weights
21Feb17_004612|Individual:
21Feb17_004612|-- Constant hidden layers --
21Feb17_004612|False
21Feb17_004612|Layer 0:
21Feb17_004612|-- Config --
21Feb17_004612|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004612|-- Weights --
21Feb17_004612|[[-0.73212  1.32861  0.10200]
21Feb17_004612| [ 1.48746 -2.97273 -0.42944]
21Feb17_004612| [ 0.53095 -1.50623  0.79224]
21Feb17_004612| [-1.07292 -0.83175 -0.90105]
21Feb17_004612| [-0.48696 -0.89325  0.27226]
21Feb17_004612| [-3.02511  0.34155 -0.03837]
21Feb17_004612| [-0.76747  0.57140 -0.46892]
21Feb17_004612| [-0.07581  0.14713  0.85910]
21Feb17_004612| [-1.37488  0.52170 -0.36205]
21Feb17_004612| [ 1.60981 -0.08727 -0.11267]
21Feb17_004612| [ 0.50986  1.58916 -0.35287]
21Feb17_004612| [-0.34599  1.27113 -0.16393]
21Feb17_004612| [ 1.29203  1.19467  0.37695]
21Feb17_004612| [ 0.58704  0.06328 -0.24240]
21Feb17_004612| [-0.93888 -0.89760  0.57087]
21Feb17_004612| [ 0.99159 -0.66387  0.35177]
21Feb17_004612| [-0.67119  1.06910 -0.12512]
21Feb17_004612| [-0.91534  1.23744 -0.40465]
21Feb17_004612| [ 1.39278  0.08069  0.23328]
21Feb17_004612| [ 0.09880  0.57603 -0.96101]
21Feb17_004612| [ 0.01621 -0.13343 -0.27624]
21Feb17_004612| [-1.28286 -2.28909  0.37931]
21Feb17_004612| [-0.28370  0.09336  0.01547]
21Feb17_004612| [-0.51894  1.84280 -0.25906]
21Feb17_004612| [-0.83075 -0.04508  0.12107]
21Feb17_004612| [ 0.37343  1.18436 -0.07358]
21Feb17_004612| [-2.38657 -0.35191  0.01962]
21Feb17_004612| [ 0.95757 -0.91760 -0.08971]
21Feb17_004612| [ 0.38792 -0.01880  0.69717]
21Feb17_004612| [ 1.66877 -0.58078 -1.21129]
21Feb17_004612| [-0.50943  0.59080  0.30856]
21Feb17_004612| [ 0.30163  1.11518  0.98185]
21Feb17_004612| [-0.73226  0.32281 -0.66712]
21Feb17_004612| [-0.62054 -2.21049  1.40981]
21Feb17_004612| [ 1.23185 -0.58090  0.35844]
21Feb17_004612| [-0.05616  0.24219 -0.02853]
21Feb17_004612| [-1.05085 -2.30259 -0.16276]
21Feb17_004612| [ 0.71087  0.14900  1.13430]
21Feb17_004612| [-2.45877 -1.20999 -1.04986]
21Feb17_004612| [-1.00480  1.36344 -0.13998]
21Feb17_004612| [ 1.83140 -0.91532  0.07616]
21Feb17_004612| [-0.60404 -2.05184  0.76948]
21Feb17_004612| [ 0.52617  0.76042 -1.76746]
21Feb17_004612| [-0.22134  0.17324  0.99530]
21Feb17_004612| [-0.36427  1.34655  0.02110]
21Feb17_004612| [-0.93125 -0.33620 -0.25012]
21Feb17_004612| [-2.76428  0.14487  0.48096]
21Feb17_004612| [-0.10518  0.35052  1.71840]
21Feb17_004612| [-1.27998  1.12568  1.26523]
21Feb17_004612| [-0.60698  1.53230 -0.60824]
21Feb17_004612| [ 0.02898  2.98718 -0.59153]
21Feb17_004612| [ 0.17588 -0.00449  0.50797]
21Feb17_004612| [-1.42674 -0.54967 -0.21310]
21Feb17_004612| [ 1.03196  1.18733  0.36755]
21Feb17_004612| [ 1.04748 -1.47444 -0.08469]
21Feb17_004612| [ 0.49410  0.38745  0.68469]
21Feb17_004612| [-0.62880  0.73245  0.19964]]
21Feb17_004612|-- Bias --
21Feb17_004612|[-0.18798  0.64571 -0.23142]
21Feb17_004612|Layer 1:
21Feb17_004612|-- Config --
21Feb17_004612|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004612|-- Weights --
21Feb17_004612|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_004612| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_004612| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_004612|-- Bias --
21Feb17_004612|[0.60477 0.03773 0.26452 0.12222]
21Feb17_004612|Layer 2:
21Feb17_004612|-- Config --
21Feb17_004612|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004612|-- Weights --
21Feb17_004612|[[ 0.67920  0.12119]
21Feb17_004612| [ 0.44836  0.02916]
21Feb17_004612| [ 0.68939  0.31516]
21Feb17_004612| [-0.58995 -0.05861]]
21Feb17_004612|-- Bias --
21Feb17_004612|[ 0.59649 -0.08079]
21Feb17_004612|Layer 3:
21Feb17_004612|-- Config --
21Feb17_004612|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004612|-- Weights --
21Feb17_004612|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_004612| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_004612|-- Bias --
21Feb17_004612|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_004612|Layer 4:
21Feb17_004612|-- Config --
21Feb17_004612|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004612|-- Weights --
21Feb17_004612|[[-0.03514 -1.04833]
21Feb17_004612| [ 1.25238  0.62094]
21Feb17_004612| [ 0.99203  0.37406]
21Feb17_004612| [ 0.49902  0.67158]
21Feb17_004612| [-1.35709  0.38335]]
21Feb17_004612|-- Bias --
21Feb17_004612|[0.31435 0.36299]
21Feb17_004612|Predicting the validation and test data with the Best final individual.
21Feb17_004619| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_004619|-----------  ------------------  --------------------  ----------
21Feb17_004619|Validation         23.48                  56            0.78306
21Feb17_004619|   Test            22.07                  56            0.85403
21Feb17_004619|-------------------- Test #12 --------------------
21Feb17_004619|Best final individual weights
21Feb17_004619|Individual:
21Feb17_004619|-- Constant hidden layers --
21Feb17_004619|False
21Feb17_004619|Layer 0:
21Feb17_004619|-- Config --
21Feb17_004619|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004619|-- Weights --
21Feb17_004619|[[-0.73212  1.32861  0.10200]
21Feb17_004619| [ 1.48746 -2.97273 -0.42944]
21Feb17_004619| [ 0.53095 -1.50623  0.79224]
21Feb17_004619| [-1.07292 -0.83175 -0.90105]
21Feb17_004619| [-0.48696 -0.89325  0.27226]
21Feb17_004619| [-3.02511  0.34155 -0.03837]
21Feb17_004619| [-0.76747  0.57140 -0.46892]
21Feb17_004619| [-0.07581  0.14713  0.85910]
21Feb17_004619| [-1.37488  0.52170 -0.36205]
21Feb17_004619| [ 1.60981 -0.08727 -0.11267]
21Feb17_004619| [ 0.50986  1.58916 -0.35287]
21Feb17_004619| [-0.34599  1.27113 -0.16393]
21Feb17_004619| [ 1.29203  1.19467  0.37695]
21Feb17_004619| [ 0.58704  0.06328 -0.24240]
21Feb17_004619| [-0.93888 -0.89760  0.57087]
21Feb17_004619| [ 0.99159 -0.66387  0.35177]
21Feb17_004619| [-0.67119  1.06910 -0.12512]
21Feb17_004619| [-0.91534  1.23744 -0.40465]
21Feb17_004619| [ 1.39278  0.08069  0.23328]
21Feb17_004619| [ 0.09880  0.57603 -0.96101]
21Feb17_004619| [ 0.01621 -0.13343 -0.27624]
21Feb17_004619| [-1.28286 -2.28909  0.37931]
21Feb17_004619| [-0.28370  0.09336  0.01547]
21Feb17_004619| [-0.51894  1.84280 -0.25906]
21Feb17_004619| [-0.83075 -0.04508  0.12107]
21Feb17_004619| [ 0.37343  1.18436 -0.07358]
21Feb17_004619| [-2.38657 -0.35191  0.01962]
21Feb17_004619| [ 0.95757 -0.91760 -0.08971]
21Feb17_004619| [ 0.38792 -0.01880  0.69717]
21Feb17_004619| [ 1.66877 -0.58078 -1.21129]
21Feb17_004619| [-0.50943  0.59080  0.30856]
21Feb17_004619| [ 0.30163  1.11518  0.98185]
21Feb17_004619| [-0.73226  0.32281 -0.66712]
21Feb17_004619| [-0.62054 -2.21049  1.40981]
21Feb17_004619| [ 1.23185 -0.58090  0.35844]
21Feb17_004619| [-0.05616  0.24219 -0.02853]
21Feb17_004619| [-1.05085 -2.30259 -0.16276]
21Feb17_004619| [ 0.71087  0.14900  1.13430]
21Feb17_004619| [-2.45877 -1.20999 -1.04986]
21Feb17_004619| [-1.00480  1.36344 -0.13998]
21Feb17_004619| [ 1.83140 -0.91532  0.07616]
21Feb17_004619| [-0.60404 -2.05184  0.76948]
21Feb17_004619| [ 0.52617  0.76042 -1.76746]
21Feb17_004619| [-0.22134  0.17324  0.99530]
21Feb17_004619| [-0.36427  1.34655  0.02110]
21Feb17_004619| [-0.93125 -0.33620 -0.25012]
21Feb17_004619| [-2.76428  0.14487  0.48096]
21Feb17_004619| [-0.10518  0.35052  1.71840]
21Feb17_004619| [-1.27998  1.12568  1.26523]
21Feb17_004619| [-0.60698  1.53230 -0.60824]
21Feb17_004619| [ 0.02898  2.98718 -0.59153]
21Feb17_004619| [ 0.17588 -0.00449  0.50797]
21Feb17_004619| [-1.42674 -0.54967 -0.21310]
21Feb17_004619| [ 1.03196  1.18733  0.36755]
21Feb17_004619| [ 1.04748 -1.47444 -0.08469]
21Feb17_004619| [ 0.49410  0.38745  0.68469]
21Feb17_004619| [-0.62880  0.73245  0.19964]]
21Feb17_004619|-- Bias --
21Feb17_004619|[-0.18798  0.64571 -0.23142]
21Feb17_004619|Layer 1:
21Feb17_004619|-- Config --
21Feb17_004619|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004619|-- Weights --
21Feb17_004619|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_004619| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_004619| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_004619|-- Bias --
21Feb17_004619|[0.60477 0.03773 0.26452 0.12222]
21Feb17_004619|Layer 2:
21Feb17_004619|-- Config --
21Feb17_004619|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004619|-- Weights --
21Feb17_004619|[[ 0.67920  0.12119]
21Feb17_004619| [ 0.44836  0.02916]
21Feb17_004619| [ 0.68939  0.31516]
21Feb17_004619| [-0.58995 -0.05861]]
21Feb17_004619|-- Bias --
21Feb17_004619|[ 0.59649 -0.08079]
21Feb17_004619|Layer 3:
21Feb17_004619|-- Config --
21Feb17_004619|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004619|-- Weights --
21Feb17_004619|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_004619| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_004619|-- Bias --
21Feb17_004619|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_004619|Layer 4:
21Feb17_004619|-- Config --
21Feb17_004619|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004619|-- Weights --
21Feb17_004619|[[-0.03514 -1.04833]
21Feb17_004619| [ 1.25238  0.62094]
21Feb17_004619| [ 0.99203  0.37406]
21Feb17_004619| [ 0.49902  0.67158]
21Feb17_004619| [-1.35709  0.38335]]
21Feb17_004619|-- Bias --
21Feb17_004619|[0.31435 0.36299]
21Feb17_004619|Predicting the validation and test data with the Best final individual.
21Feb17_004627| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_004627|-----------  ------------------  --------------------  ----------
21Feb17_004627|Validation         24.43                  56            0.85301
21Feb17_004627|   Test            37.01                  56            0.82036
21Feb17_004627|-------------------- Test #13 --------------------
21Feb17_004627|Best final individual weights
21Feb17_004627|Individual:
21Feb17_004627|-- Constant hidden layers --
21Feb17_004627|False
21Feb17_004627|Layer 0:
21Feb17_004627|-- Config --
21Feb17_004627|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004627|-- Weights --
21Feb17_004627|[[-0.73212  1.32861  0.10200]
21Feb17_004627| [ 1.48746 -2.97273 -0.42944]
21Feb17_004627| [ 0.53095 -1.50623  0.79224]
21Feb17_004627| [-1.07292 -0.83175 -0.90105]
21Feb17_004627| [-0.48696 -0.89325  0.27226]
21Feb17_004627| [-3.02511  0.34155 -0.03837]
21Feb17_004627| [-0.76747  0.57140 -0.46892]
21Feb17_004627| [-0.07581  0.14713  0.85910]
21Feb17_004627| [-1.37488  0.52170 -0.36205]
21Feb17_004627| [ 1.60981 -0.08727 -0.11267]
21Feb17_004627| [ 0.50986  1.58916 -0.35287]
21Feb17_004627| [-0.34599  1.27113 -0.16393]
21Feb17_004627| [ 1.29203  1.19467  0.37695]
21Feb17_004627| [ 0.58704  0.06328 -0.24240]
21Feb17_004627| [-0.93888 -0.89760  0.57087]
21Feb17_004627| [ 0.99159 -0.66387  0.35177]
21Feb17_004627| [-0.67119  1.06910 -0.12512]
21Feb17_004627| [-0.91534  1.23744 -0.40465]
21Feb17_004627| [ 1.39278  0.08069  0.23328]
21Feb17_004627| [ 0.09880  0.57603 -0.96101]
21Feb17_004627| [ 0.01621 -0.13343 -0.27624]
21Feb17_004627| [-1.28286 -2.28909  0.37931]
21Feb17_004627| [-0.28370  0.09336  0.01547]
21Feb17_004627| [-0.51894  1.84280 -0.25906]
21Feb17_004627| [-0.83075 -0.04508  0.12107]
21Feb17_004627| [ 0.37343  1.18436 -0.07358]
21Feb17_004627| [-2.38657 -0.35191  0.01962]
21Feb17_004627| [ 0.95757 -0.91760 -0.08971]
21Feb17_004627| [ 0.38792 -0.01880  0.69717]
21Feb17_004627| [ 1.66877 -0.58078 -1.21129]
21Feb17_004627| [-0.50943  0.59080  0.30856]
21Feb17_004627| [ 0.30163  1.11518  0.98185]
21Feb17_004627| [-0.73226  0.32281 -0.66712]
21Feb17_004627| [-0.62054 -2.21049  1.40981]
21Feb17_004627| [ 1.23185 -0.58090  0.35844]
21Feb17_004627| [-0.05616  0.24219 -0.02853]
21Feb17_004627| [-1.05085 -2.30259 -0.16276]
21Feb17_004627| [ 0.71087  0.14900  1.13430]
21Feb17_004627| [-2.45877 -1.20999 -1.04986]
21Feb17_004627| [-1.00480  1.36344 -0.13998]
21Feb17_004627| [ 1.83140 -0.91532  0.07616]
21Feb17_004627| [-0.60404 -2.05184  0.76948]
21Feb17_004627| [ 0.52617  0.76042 -1.76746]
21Feb17_004627| [-0.22134  0.17324  0.99530]
21Feb17_004627| [-0.36427  1.34655  0.02110]
21Feb17_004627| [-0.93125 -0.33620 -0.25012]
21Feb17_004627| [-2.76428  0.14487  0.48096]
21Feb17_004627| [-0.10518  0.35052  1.71840]
21Feb17_004627| [-1.27998  1.12568  1.26523]
21Feb17_004627| [-0.60698  1.53230 -0.60824]
21Feb17_004627| [ 0.02898  2.98718 -0.59153]
21Feb17_004627| [ 0.17588 -0.00449  0.50797]
21Feb17_004627| [-1.42674 -0.54967 -0.21310]
21Feb17_004627| [ 1.03196  1.18733  0.36755]
21Feb17_004627| [ 1.04748 -1.47444 -0.08469]
21Feb17_004627| [ 0.49410  0.38745  0.68469]
21Feb17_004627| [-0.62880  0.73245  0.19964]]
21Feb17_004627|-- Bias --
21Feb17_004627|[-0.18798  0.64571 -0.23142]
21Feb17_004627|Layer 1:
21Feb17_004627|-- Config --
21Feb17_004627|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004627|-- Weights --
21Feb17_004627|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_004627| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_004627| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_004627|-- Bias --
21Feb17_004627|[0.60477 0.03773 0.26452 0.12222]
21Feb17_004627|Layer 2:
21Feb17_004627|-- Config --
21Feb17_004627|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004627|-- Weights --
21Feb17_004627|[[ 0.67920  0.12119]
21Feb17_004627| [ 0.44836  0.02916]
21Feb17_004627| [ 0.68939  0.31516]
21Feb17_004627| [-0.58995 -0.05861]]
21Feb17_004627|-- Bias --
21Feb17_004627|[ 0.59649 -0.08079]
21Feb17_004627|Layer 3:
21Feb17_004627|-- Config --
21Feb17_004627|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004627|-- Weights --
21Feb17_004627|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_004627| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_004627|-- Bias --
21Feb17_004627|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_004627|Layer 4:
21Feb17_004627|-- Config --
21Feb17_004627|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004627|-- Weights --
21Feb17_004627|[[-0.03514 -1.04833]
21Feb17_004627| [ 1.25238  0.62094]
21Feb17_004627| [ 0.99203  0.37406]
21Feb17_004627| [ 0.49902  0.67158]
21Feb17_004627| [-1.35709  0.38335]]
21Feb17_004627|-- Bias --
21Feb17_004627|[0.31435 0.36299]
21Feb17_004627|Predicting the validation and test data with the Best final individual.
21Feb17_004634| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_004634|-----------  ------------------  --------------------  ----------
21Feb17_004634|Validation         21.74                  56            0.74120
21Feb17_004634|   Test            25.80                  56            0.72926
21Feb17_004634|-------------------- Test #14 --------------------
21Feb17_004634|Best final individual weights
21Feb17_004634|Individual:
21Feb17_004634|-- Constant hidden layers --
21Feb17_004634|False
21Feb17_004634|Layer 0:
21Feb17_004634|-- Config --
21Feb17_004634|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004634|-- Weights --
21Feb17_004634|[[-0.73212  1.32861  0.10200]
21Feb17_004634| [ 1.48746 -2.97273 -0.42944]
21Feb17_004634| [ 0.53095 -1.50623  0.79224]
21Feb17_004634| [-1.07292 -0.83175 -0.90105]
21Feb17_004634| [-0.48696 -0.89325  0.27226]
21Feb17_004634| [-3.02511  0.34155 -0.03837]
21Feb17_004634| [-0.76747  0.57140 -0.46892]
21Feb17_004634| [-0.07581  0.14713  0.85910]
21Feb17_004634| [-1.37488  0.52170 -0.36205]
21Feb17_004634| [ 1.60981 -0.08727 -0.11267]
21Feb17_004634| [ 0.50986  1.58916 -0.35287]
21Feb17_004634| [-0.34599  1.27113 -0.16393]
21Feb17_004634| [ 1.29203  1.19467  0.37695]
21Feb17_004634| [ 0.58704  0.06328 -0.24240]
21Feb17_004634| [-0.93888 -0.89760  0.57087]
21Feb17_004634| [ 0.99159 -0.66387  0.35177]
21Feb17_004634| [-0.67119  1.06910 -0.12512]
21Feb17_004634| [-0.91534  1.23744 -0.40465]
21Feb17_004634| [ 1.39278  0.08069  0.23328]
21Feb17_004634| [ 0.09880  0.57603 -0.96101]
21Feb17_004634| [ 0.01621 -0.13343 -0.27624]
21Feb17_004634| [-1.28286 -2.28909  0.37931]
21Feb17_004634| [-0.28370  0.09336  0.01547]
21Feb17_004634| [-0.51894  1.84280 -0.25906]
21Feb17_004634| [-0.83075 -0.04508  0.12107]
21Feb17_004634| [ 0.37343  1.18436 -0.07358]
21Feb17_004634| [-2.38657 -0.35191  0.01962]
21Feb17_004634| [ 0.95757 -0.91760 -0.08971]
21Feb17_004634| [ 0.38792 -0.01880  0.69717]
21Feb17_004634| [ 1.66877 -0.58078 -1.21129]
21Feb17_004634| [-0.50943  0.59080  0.30856]
21Feb17_004634| [ 0.30163  1.11518  0.98185]
21Feb17_004634| [-0.73226  0.32281 -0.66712]
21Feb17_004634| [-0.62054 -2.21049  1.40981]
21Feb17_004634| [ 1.23185 -0.58090  0.35844]
21Feb17_004634| [-0.05616  0.24219 -0.02853]
21Feb17_004634| [-1.05085 -2.30259 -0.16276]
21Feb17_004634| [ 0.71087  0.14900  1.13430]
21Feb17_004634| [-2.45877 -1.20999 -1.04986]
21Feb17_004634| [-1.00480  1.36344 -0.13998]
21Feb17_004634| [ 1.83140 -0.91532  0.07616]
21Feb17_004634| [-0.60404 -2.05184  0.76948]
21Feb17_004634| [ 0.52617  0.76042 -1.76746]
21Feb17_004634| [-0.22134  0.17324  0.99530]
21Feb17_004634| [-0.36427  1.34655  0.02110]
21Feb17_004634| [-0.93125 -0.33620 -0.25012]
21Feb17_004634| [-2.76428  0.14487  0.48096]
21Feb17_004634| [-0.10518  0.35052  1.71840]
21Feb17_004634| [-1.27998  1.12568  1.26523]
21Feb17_004634| [-0.60698  1.53230 -0.60824]
21Feb17_004634| [ 0.02898  2.98718 -0.59153]
21Feb17_004634| [ 0.17588 -0.00449  0.50797]
21Feb17_004634| [-1.42674 -0.54967 -0.21310]
21Feb17_004634| [ 1.03196  1.18733  0.36755]
21Feb17_004634| [ 1.04748 -1.47444 -0.08469]
21Feb17_004634| [ 0.49410  0.38745  0.68469]
21Feb17_004634| [-0.62880  0.73245  0.19964]]
21Feb17_004634|-- Bias --
21Feb17_004634|[-0.18798  0.64571 -0.23142]
21Feb17_004634|Layer 1:
21Feb17_004634|-- Config --
21Feb17_004634|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004634|-- Weights --
21Feb17_004634|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_004634| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_004634| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_004634|-- Bias --
21Feb17_004634|[0.60477 0.03773 0.26452 0.12222]
21Feb17_004634|Layer 2:
21Feb17_004634|-- Config --
21Feb17_004634|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004634|-- Weights --
21Feb17_004634|[[ 0.67920  0.12119]
21Feb17_004634| [ 0.44836  0.02916]
21Feb17_004634| [ 0.68939  0.31516]
21Feb17_004634| [-0.58995 -0.05861]]
21Feb17_004634|-- Bias --
21Feb17_004634|[ 0.59649 -0.08079]
21Feb17_004634|Layer 3:
21Feb17_004634|-- Config --
21Feb17_004634|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004634|-- Weights --
21Feb17_004634|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_004634| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_004634|-- Bias --
21Feb17_004634|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_004634|Layer 4:
21Feb17_004634|-- Config --
21Feb17_004634|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_004634|-- Weights --
21Feb17_004634|[[-0.03514 -1.04833]
21Feb17_004634| [ 1.25238  0.62094]
21Feb17_004634| [ 0.99203  0.37406]
21Feb17_004634| [ 0.49902  0.67158]
21Feb17_004634| [-1.35709  0.38335]]
21Feb17_004634|-- Bias --
21Feb17_004634|[0.31435 0.36299]
21Feb17_004634|Predicting the validation and test data with the Best final individual.
21Feb17_004642| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_004642|-----------  ------------------  --------------------  ----------
21Feb17_004642|Validation         22.70                  56            0.74363
21Feb17_004642|   Test            19.46                  56            0.73101
Using Theano backend.
WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.
2021-02-17 00:46:44.925387: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-02-17 00:46:44.925448: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
21Feb17_004645|Data summary: Train
21Feb17_004645|data.shape = (2300, 57)
21Feb17_004645|labels.shape = (2300,)
21Feb17_004645|Class distribution:
21Feb17_004645|	0 - 1389 (0.60)
21Feb17_004645|	1 - 911 (0.40)
21Feb17_004645|Data summary: Validation
21Feb17_004645|data.shape = (1150, 57)
21Feb17_004645|labels.shape = (1150,)
21Feb17_004645|Class distribution:
21Feb17_004645|	0 - 667 (0.58)
21Feb17_004645|	1 - 483 (0.42)
21Feb17_004645|Data summary: Test
21Feb17_004645|data.shape = (1151, 57)
21Feb17_004645|labels.shape = (1151,)
21Feb17_004645|Class distribution:
21Feb17_004645|	0 - 732 (0.64)
21Feb17_004645|	1 - 419 (0.36)
21Feb17_004645|Selected configuration values
21Feb17_004645|-- Dataset name: spambase2
21Feb17_004645|-- Initial population size: 64
21Feb17_004645|-- Maximun number of generations: 32
21Feb17_004645|-- Neurons per hidden layer range: (2, 20)
21Feb17_004645|-- Hidden layers number range: (1, 3)
21Feb17_004645|-- Crossover probability: 0.5
21Feb17_004645|-- Bias gene mutation probability: 0.2
21Feb17_004645|-- Weights gene mutation probability: 0.75
21Feb17_004645|-- Neuron mutation probability: 0.3
21Feb17_004645|-- Layer mutation probability: 0.3
21Feb17_004645|-- Constant hidden layers: False
21Feb17_004645|-- Seed: 31415
21Feb17_004645|Entering GA
21Feb17_004645|Start the algorithm
21Feb17_005027|-- Generation 1 --
21Feb17_005027|    -- Crossed 0 individual pairs.
21Feb17_005027|    -- Mutated 32 individuals.
21Feb17_005346|    -- Evaluated 64 individuals.
21Feb17_005346|    Summary of generation 1:
21Feb17_005346| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_005346|-----------  ------------------  --------------------  ----------
21Feb17_005346|    Max            42.70                78.00           0.43478
21Feb17_005346|    Avg            41.90                26.28           0.00941
21Feb17_005346|    Min            35.91                 2.00           0.00000
21Feb17_005346|    Std             0.81                18.75           0.05509
21Feb17_005346|   Best            35.91                18.00           0.43478
21Feb17_005346|-- Generation 2 --
21Feb17_005346|    -- Crossed 1 individual pairs.
21Feb17_005346|    -- Mutated 32 individuals.
21Feb17_005701|    -- Evaluated 64 individuals.
21Feb17_005701|    Summary of generation 2:
21Feb17_005701| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_005701|-----------  ------------------  --------------------  ----------
21Feb17_005701|    Max            58.00                84.00           0.79977
21Feb17_005701|    Avg            41.99                15.92           0.02879
21Feb17_005701|    Min            29.65                 2.00           0.00000
21Feb17_005701|    Std             2.55                13.60           0.13781
21Feb17_005701|   Best            29.65                18.00           0.79977
21Feb17_005701|-- Generation 3 --
21Feb17_005701|    -- Crossed 3 individual pairs.
21Feb17_005701|    -- Mutated 32 individuals.
21Feb17_010011|    -- Evaluated 64 individuals.
21Feb17_010011|    Summary of generation 3:
21Feb17_010011| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_010011|-----------  ------------------  --------------------  ----------
21Feb17_010011|    Max            58.00                50.00           0.78358
21Feb17_010011|    Avg            41.97                13.73           0.02564
21Feb17_010011|    Min            26.09                 2.00           0.00000
21Feb17_010011|    Std             2.83                12.88           0.13211
21Feb17_010011|   Best            26.09                18.00           0.73476
21Feb17_010011|-- Generation 4 --
21Feb17_010011|    -- Crossed 4 individual pairs.
21Feb17_010011|    -- Mutated 32 individuals.
21Feb17_010315|    -- Evaluated 64 individuals.
21Feb17_010315|    Summary of generation 4:
21Feb17_010315| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_010315|-----------  ------------------  --------------------  ----------
21Feb17_010315|    Max            42.17                63.00           0.00517
21Feb17_010315|    Avg            42.01                 8.34           0.00085
21Feb17_010315|    Min            41.91                 2.00           0.00000
21Feb17_010315|    Std             0.06                 9.60           0.00165
21Feb17_010315|   Best            41.91                 4.00           0.00517
21Feb17_010315|-- Generation 5 --
21Feb17_010315|    -- Crossed 6 individual pairs.
21Feb17_010315|    -- Mutated 32 individuals.
21Feb17_010621|    -- Evaluated 64 individuals.
21Feb17_010621|    Summary of generation 5:
21Feb17_010621| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_010621|-----------  ------------------  --------------------  ----------
21Feb17_010621|    Max            42.09                20.00           0.05344
21Feb17_010621|    Avg            41.98                 5.28           0.00172
21Feb17_010621|    Min            41.22                 2.00           0.00000
21Feb17_010621|    Std             0.11                 4.46           0.00681
21Feb17_010621|   Best            41.22                14.00           0.05344
21Feb17_010621|-- Generation 6 --
21Feb17_010621|    -- Crossed 7 individual pairs.
21Feb17_010621|    -- Mutated 32 individuals.
21Feb17_010930|    -- Evaluated 64 individuals.
21Feb17_010930|    Summary of generation 6:
21Feb17_010930| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_010930|-----------  ------------------  --------------------  ----------
21Feb17_010930|    Max            42.26                18.00           0.01548
21Feb17_010930|    Avg            41.99                 6.00           0.00105
21Feb17_010930|    Min            41.48                 2.00           0.00000
21Feb17_010930|    Std             0.09                 4.81           0.00231
21Feb17_010930|   Best            41.48                 3.00           0.01548
21Feb17_010930|-- Generation 7 --
21Feb17_010930|    -- Crossed 9 individual pairs.
21Feb17_010930|    -- Mutated 32 individuals.
21Feb17_011238|    -- Evaluated 64 individuals.
21Feb17_011238|    Summary of generation 7:
21Feb17_011238| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_011238|-----------  ------------------  --------------------  ----------
21Feb17_011238|    Max            42.09                36.00           0.01033
21Feb17_011238|    Avg            41.99                 5.98           0.00089
21Feb17_011238|    Min            41.65                 2.00           0.00000
21Feb17_011238|    Std             0.06                 6.14           0.00184
21Feb17_011238|   Best            41.65                 3.00           0.01033
21Feb17_011238|-- Generation 8 --
21Feb17_011238|    -- Crossed 9 individual pairs.
21Feb17_011238|    -- Mutated 32 individuals.
21Feb17_011542|    -- Evaluated 64 individuals.
21Feb17_011542|    Summary of generation 8:
21Feb17_011542| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_011542|-----------  ------------------  --------------------  ----------
21Feb17_011542|    Max            42.17                18.00           0.04103
21Feb17_011542|    Avg            41.97                 5.09           0.00169
21Feb17_011542|    Min            40.78                 2.00           0.00000
21Feb17_011542|    Std             0.16                 4.37           0.00529
21Feb17_011542|   Best            40.78                12.00           0.04103
21Feb17_011542|-- Generation 9 --
21Feb17_011542|    -- Crossed 8 individual pairs.
21Feb17_011542|    -- Mutated 32 individuals.
21Feb17_011850|    -- Evaluated 64 individuals.
21Feb17_011850|    Summary of generation 9:
21Feb17_011850| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_011850|-----------  ------------------  --------------------  ----------
21Feb17_011850|    Max            48.87                18.00           0.80667
21Feb17_011850|    Avg            41.71                 6.17           0.03823
21Feb17_011850|    Min            30.61                 2.00           0.00000
21Feb17_011850|    Std             2.17                 5.04           0.16210
21Feb17_011850|   Best            30.61                 8.00           0.78607
21Feb17_011850|-- Generation 10 --
21Feb17_011850|    -- Crossed 5 individual pairs.
21Feb17_011850|    -- Mutated 32 individuals.
21Feb17_012157|    -- Evaluated 64 individuals.
21Feb17_012157|    Summary of generation 10:
21Feb17_012157| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_012157|-----------  ------------------  --------------------  ----------
21Feb17_012157|    Max            42.26                18.00           0.58344
21Feb17_012157|    Avg            41.43                 6.23           0.02714
21Feb17_012157|    Min            27.74                 2.00           0.00000
21Feb17_012157|    Std             2.43                 4.89           0.10887
21Feb17_012157|   Best            27.74                18.00           0.51616
21Feb17_012157|-- Generation 11 --
21Feb17_012157|    -- Crossed 8 individual pairs.
21Feb17_012157|    -- Mutated 32 individuals.
21Feb17_012506|    -- Evaluated 64 individuals.
21Feb17_012506|    Summary of generation 11:
21Feb17_012506| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_012506|-----------  ------------------  --------------------  ----------
21Feb17_012506|    Max            58.00                34.00           0.78358
21Feb17_012506|    Avg            41.87                 7.95           0.03476
21Feb17_012506|    Min            28.00                 2.00           0.00000
21Feb17_012506|    Std             2.88                 6.49           0.14854
21Feb17_012506|   Best            28.00                 8.00           0.52079
21Feb17_012506|-- Generation 12 --
21Feb17_012506|    -- Crossed 3 individual pairs.
21Feb17_012506|    -- Mutated 32 individuals.
21Feb17_012813|    -- Evaluated 64 individuals.
21Feb17_012813|    Summary of generation 12:
21Feb17_012813| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_012813|-----------  ------------------  --------------------  ----------
21Feb17_012813|    Max            42.35                36.00           0.67494
21Feb17_012813|    Avg            41.46                 7.03           0.02217
21Feb17_012813|    Min            24.96                 2.00           0.00000
21Feb17_012813|    Std             2.67                 5.88           0.11025
21Feb17_012813|   Best            24.96                18.00           0.67494
21Feb17_012813|-- Generation 13 --
21Feb17_012813|    -- Crossed 5 individual pairs.
21Feb17_012813|    -- Mutated 32 individuals.
21Feb17_013124|    -- Evaluated 64 individuals.
21Feb17_013124|    Summary of generation 13:
21Feb17_013124| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_013124|-----------  ------------------  --------------------  ----------
21Feb17_013124|    Max            42.61                36.00           0.61562
21Feb17_013124|    Avg            41.50                 8.56           0.02210
21Feb17_013124|    Min            26.78                 2.00           0.00000
21Feb17_013124|    Std             2.40                 7.93           0.10577
21Feb17_013124|   Best            26.78                18.00           0.61562
21Feb17_013124|-- Generation 14 --
21Feb17_013124|    -- Crossed 7 individual pairs.
21Feb17_013124|    -- Mutated 32 individuals.
21Feb17_013435|    -- Evaluated 64 individuals.
21Feb17_013435|    Summary of generation 14:
21Feb17_013435| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_013435|-----------  ------------------  --------------------  ----------
21Feb17_013435|    Max            42.09                40.00           0.75188
21Feb17_013435|    Avg            41.48                 8.12           0.02679
21Feb17_013435|    Min            27.65                 2.00           0.00000
21Feb17_013435|    Std             2.42                 6.72           0.13015
21Feb17_013435|   Best            27.65                18.00           0.75188
21Feb17_013435|-- Generation 15 --
21Feb17_013435|    -- Crossed 6 individual pairs.
21Feb17_013435|    -- Mutated 32 individuals.
21Feb17_013745|    -- Evaluated 64 individuals.
21Feb17_013745|    Summary of generation 15:
21Feb17_013745| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_013745|-----------  ------------------  --------------------  ----------
21Feb17_013745|    Max            42.09                40.00           0.73387
21Feb17_013745|    Avg            41.42                 7.69           0.02610
21Feb17_013745|    Min            26.35                 2.00           0.00000
21Feb17_013745|    Std             2.71                 6.44           0.12590
21Feb17_013745|   Best            26.35                18.00           0.71951
21Feb17_013745|-- Generation 16 --
21Feb17_013745|    -- Crossed 5 individual pairs.
21Feb17_013745|    -- Mutated 32 individuals.
21Feb17_014055|    -- Evaluated 64 individuals.
21Feb17_014055|    Summary of generation 16:
21Feb17_014055| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_014055|-----------  ------------------  --------------------  ----------
21Feb17_014055|    Max            42.26                44.00           0.82855
21Feb17_014055|    Avg            41.21                 7.83           0.03973
21Feb17_014055|    Min            24.87                 2.00           0.00000
21Feb17_014055|    Std             3.23                 7.99           0.16234
21Feb17_014055|   Best            24.87                21.00           0.68287
21Feb17_014055|-- Generation 17 --
21Feb17_014055|    -- Crossed 8 individual pairs.
21Feb17_014055|    -- Mutated 32 individuals.
21Feb17_014407|    -- Evaluated 64 individuals.
21Feb17_014407|    Summary of generation 17:
21Feb17_014407| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_014407|-----------  ------------------  --------------------  ----------
21Feb17_014407|    Max            42.26                44.00           0.80877
21Feb17_014407|    Avg            40.86                 8.81           0.06413
21Feb17_014407|    Min            25.04                 2.00           0.00000
21Feb17_014407|    Std             3.59                 8.94           0.19340
21Feb17_014407|   Best            25.04                10.00           0.72247
21Feb17_014407|-- Generation 18 --
21Feb17_014407|    -- Crossed 2 individual pairs.
21Feb17_014407|    -- Mutated 32 individuals.
21Feb17_014723|    -- Evaluated 64 individuals.
21Feb17_014723|    Summary of generation 18:
21Feb17_014723| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_014723|-----------  ------------------  --------------------  ----------
21Feb17_014723|    Max            47.04                44.00           0.81211
21Feb17_014723|    Avg            39.55                10.78           0.12108
21Feb17_014723|    Min            24.35                 3.00           0.00000
21Feb17_014723|    Std             5.74                11.16           0.25939
21Feb17_014723|   Best            24.35                44.00           0.72485
21Feb17_014723|-- Generation 19 --
21Feb17_014723|    -- Crossed 7 individual pairs.
21Feb17_014723|    -- Mutated 32 individuals.
21Feb17_015044|    -- Evaluated 64 individuals.
21Feb17_015044|    Summary of generation 19:
21Feb17_015044| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_015044|-----------  ------------------  --------------------  ----------
21Feb17_015044|    Max            42.87                70.00           0.81774
21Feb17_015044|    Avg            39.09                14.53           0.14606
21Feb17_015044|    Min            24.70                 3.00           0.00000
21Feb17_015044|    Std             5.78                15.60           0.27609
21Feb17_015044|   Best            24.70                44.00           0.69102
21Feb17_015044|-- Generation 20 --
21Feb17_015044|    -- Crossed 3 individual pairs.
21Feb17_015044|    -- Mutated 32 individuals.
21Feb17_015407|    -- Evaluated 64 individuals.
21Feb17_015407|    Summary of generation 20:
21Feb17_015407| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_015407|-----------  ------------------  --------------------  ----------
21Feb17_015407|    Max            42.17                60.00           0.79174
21Feb17_015407|    Avg            39.05                15.47           0.15453
21Feb17_015407|    Min            24.09                 3.00           0.00000
21Feb17_015407|    Std             5.60                16.03           0.28335
21Feb17_015407|   Best            24.09                48.00           0.76568
21Feb17_015407|-- Generation 21 --
21Feb17_015407|    -- Crossed 4 individual pairs.
21Feb17_015407|    -- Mutated 32 individuals.
21Feb17_015736|    -- Evaluated 64 individuals.
21Feb17_015736|    Summary of generation 21:
21Feb17_015736| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_015736|-----------  ------------------  --------------------  ----------
21Feb17_015736|    Max            42.17                90.00           0.80579
21Feb17_015736|    Avg            38.34                18.45           0.19938
21Feb17_015736|    Min            23.91                 2.00           0.00000
21Feb17_015736|    Std             5.87                19.09           0.30554
21Feb17_015736|   Best            23.91                48.00           0.71458
21Feb17_015736|-- Generation 22 --
21Feb17_015736|    -- Crossed 2 individual pairs.
21Feb17_015736|    -- Mutated 32 individuals.
21Feb17_020109|    -- Evaluated 64 individuals.
21Feb17_020109|    Summary of generation 22:
21Feb17_020109| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_020109|-----------  ------------------  --------------------  ----------
21Feb17_020109|    Max            42.09                60.00           0.82362
21Feb17_020109|    Avg            36.71                21.28           0.25981
21Feb17_020109|    Min            24.26                 2.00           0.00000
21Feb17_020109|    Std             6.98                18.25           0.33831
21Feb17_020109|   Best            24.26                52.00           0.76087
21Feb17_020109|-- Generation 23 --
21Feb17_020109|    -- Crossed 2 individual pairs.
21Feb17_020109|    -- Mutated 32 individuals.
21Feb17_020454|    -- Evaluated 64 individuals.
21Feb17_020454|    Summary of generation 23:
21Feb17_020454| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_020454|-----------  ------------------  --------------------  ----------
21Feb17_020454|    Max            42.09                96.00           0.78772
21Feb17_020454|    Avg            35.35                29.28           0.32114
21Feb17_020454|    Min            23.39                 2.00           0.00000
21Feb17_020454|    Std             7.15                21.95           0.34435
21Feb17_020454|   Best            23.39                52.00           0.72814
21Feb17_020454|-- Generation 24 --
21Feb17_020454|    -- Crossed 0 individual pairs.
21Feb17_020454|    -- Mutated 32 individuals.
21Feb17_020849|    -- Evaluated 64 individuals.
21Feb17_020849|    Summary of generation 24:
21Feb17_020849| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_020849|-----------  ------------------  --------------------  ----------
21Feb17_020849|    Max            43.30                80.00           0.82075
21Feb17_020849|    Avg            33.81                36.61           0.38588
21Feb17_020849|    Min            23.22                 2.00           0.00000
21Feb17_020849|    Std             7.30                19.72           0.34184
21Feb17_020849|   Best            23.22                52.00           0.73602
21Feb17_020849|-- Generation 25 --
21Feb17_020849|    -- Crossed 3 individual pairs.
21Feb17_020849|    -- Mutated 32 individuals.
21Feb17_021251|    -- Evaluated 64 individuals.
21Feb17_021251|    Summary of generation 25:
21Feb17_021251| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_021251|-----------  ------------------  --------------------  ----------
21Feb17_021251|    Max            51.74                114.00          0.82799
21Feb17_021251|    Avg            33.58                45.08           0.45457
21Feb17_021251|    Min            23.91                 8.00           0.00000
21Feb17_021251|    Std             7.24                19.61           0.35022
21Feb17_021251|   Best            23.91                48.00           0.72048
21Feb17_021251|-- Generation 26 --
21Feb17_021251|    -- Crossed 1 individual pairs.
21Feb17_021251|    -- Mutated 32 individuals.
21Feb17_021656|    -- Evaluated 64 individuals.
21Feb17_021656|    Summary of generation 26:
21Feb17_021656| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_021656|-----------  ------------------  --------------------  ----------
21Feb17_021656|    Max            42.35                108.00          0.84388
21Feb17_021656|    Avg            32.71                48.80           0.44554
21Feb17_021656|    Min            23.30                 2.00           0.00000
21Feb17_021656|    Std             7.16                22.53           0.33996
21Feb17_021656|   Best            23.30                24.00           0.69415
21Feb17_021656|-- Generation 27 --
21Feb17_021656|    -- Crossed 1 individual pairs.
21Feb17_021656|    -- Mutated 32 individuals.
21Feb17_022104|    -- Evaluated 64 individuals.
21Feb17_022104|    Summary of generation 27:
21Feb17_022104| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_022104|-----------  ------------------  --------------------  ----------
21Feb17_022104|    Max            42.26                132.00          0.82552
21Feb17_022104|    Avg            32.16                51.20           0.45948
21Feb17_022104|    Min            21.74                 8.00           0.00000
21Feb17_022104|    Std             7.19                22.48           0.32234
21Feb17_022104|   Best            21.74                18.00           0.76278
21Feb17_022104|-- Generation 28 --
21Feb17_022104|    -- Crossed 0 individual pairs.
21Feb17_022104|    -- Mutated 32 individuals.
21Feb17_022511|    -- Evaluated 64 individuals.
21Feb17_022511|    Summary of generation 28:
21Feb17_022511| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_022511|-----------  ------------------  --------------------  ----------
21Feb17_022511|    Max            42.00                132.00          0.83850
21Feb17_022511|    Avg            31.52                51.11           0.49187
21Feb17_022511|    Min            23.04                12.00           0.00000
21Feb17_022511|    Std             6.86                24.66           0.32040
21Feb17_022511|   Best            23.04                24.00           0.73226
21Feb17_022511|-- Generation 29 --
21Feb17_022511|    -- Crossed 0 individual pairs.
21Feb17_022511|    -- Mutated 32 individuals.
21Feb17_022915|    -- Evaluated 64 individuals.
21Feb17_022915|    Summary of generation 29:
21Feb17_022915| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_022915|-----------  ------------------  --------------------  ----------
21Feb17_022915|    Max            42.09                132.00          0.82871
21Feb17_022915|    Avg            32.10                49.19           0.44677
21Feb17_022915|    Min            22.26                12.00           0.00000
21Feb17_022915|    Std             7.60                23.20           0.33800
21Feb17_022915|   Best            22.26                56.00           0.74227
21Feb17_022915|-- Generation 30 --
21Feb17_022915|    -- Crossed 0 individual pairs.
21Feb17_022915|    -- Mutated 32 individuals.
21Feb17_023320|    -- Evaluated 64 individuals.
21Feb17_023320|    Summary of generation 30:
21Feb17_023320| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_023320|-----------  ------------------  --------------------  ----------
21Feb17_023320|    Max            42.09                100.00          0.82371
21Feb17_023320|    Avg            31.14                49.09           0.49033
21Feb17_023320|    Min            22.00                14.00           0.00000
21Feb17_023320|    Std             7.06                18.85           0.31415
21Feb17_023320|   Best            22.00                56.00           0.78704
21Feb17_023320|-- Generation 31 --
21Feb17_023320|    -- Crossed 1 individual pairs.
21Feb17_023320|    -- Mutated 32 individuals.
21Feb17_023728|    -- Evaluated 64 individuals.
21Feb17_023728|    Summary of generation 31:
21Feb17_023728| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_023728|-----------  ------------------  --------------------  ----------
21Feb17_023728|    Max            42.52                100.00          0.83333
21Feb17_023728|    Avg            32.54                52.38           0.44410
21Feb17_023728|    Min            22.96                 8.00           0.00000
21Feb17_023728|    Std             7.42                21.79           0.34342
21Feb17_023728|   Best            22.96                44.00           0.72671
21Feb17_023728|-- Generation 32 --
21Feb17_023728|    -- Crossed 1 individual pairs.
21Feb17_023728|    -- Mutated 32 individuals.
21Feb17_024136|    -- Evaluated 64 individuals.
21Feb17_024136|    Summary of generation 32:
21Feb17_024136| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_024136|-----------  ------------------  --------------------  ----------
21Feb17_024136|    Max            42.00                85.00           0.83038
21Feb17_024136|    Avg            32.40                52.83           0.43440
21Feb17_024136|    Min            21.57                 8.00           0.00000
21Feb17_024136|    Std             7.70                18.10           0.34013
21Feb17_024136|   Best            21.57                56.00           0.83038
21Feb17_024136|Best initial individual weights
21Feb17_024136|Individual:
21Feb17_024136|-- Constant hidden layers --
21Feb17_024136|False
21Feb17_024136|Layer 0:
21Feb17_024136|-- Config --
21Feb17_024136|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 12, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024136|-- Weights --
21Feb17_024136|[[-3.50529e-01 -6.53069e-03 -7.03730e-01 -6.33906e-01  6.10835e-02
21Feb17_024136|   4.57449e-01 -3.77835e-01  6.38481e-01  4.24141e-01  6.68786e-01
21Feb17_024136|  -4.86511e-01 -9.28542e-01]
21Feb17_024136| [-8.31270e-01 -3.94586e-01  5.51697e-02 -8.86387e-01 -6.99786e-01
21Feb17_024136|   6.44047e-01 -5.40571e-01  3.77503e-01  1.70193e-01  5.92883e-01
21Feb17_024136|   2.06540e-01  2.18639e-01]
21Feb17_024136| [-8.13637e-01  7.25044e-01  6.66092e-01  5.31057e-01 -4.48634e-01
21Feb17_024136|  -1.62601e-01 -1.57458e-02  7.74238e-02 -4.81841e-01  3.55485e-02
21Feb17_024136|  -7.21169e-01  1.05129e-01]
21Feb17_024136| [ 6.07201e-01  6.23643e-01  8.87343e-01  6.04285e-01  5.70453e-02
21Feb17_024136|   5.99381e-01 -3.21663e-03  6.64196e-01 -5.25584e-01 -1.74507e-02
21Feb17_024136|   3.80029e-01 -4.59585e-01]
21Feb17_024136| [-9.00078e-01  8.63133e-01  8.49324e-01  4.34648e-01 -5.67121e-01
21Feb17_024136|   6.24299e-01 -6.46637e-01  9.34620e-01 -5.42838e-01 -4.04257e-01
21Feb17_024136|  -4.70046e-01  4.29712e-01]
21Feb17_024136| [ 9.51731e-02  8.42954e-01 -7.44806e-01 -5.56045e-02 -4.89209e-01
21Feb17_024136|   8.07612e-01  2.77691e-01 -5.77946e-02  4.30356e-01 -9.05718e-01
21Feb17_024136|  -7.61358e-01 -4.56367e-01]
21Feb17_024136| [-9.06447e-01 -4.46566e-01 -4.40669e-01  6.09161e-01 -3.32587e-01
21Feb17_024136|  -9.31356e-01  9.62597e-02 -1.83060e-01  5.91585e-01 -2.78230e-01
21Feb17_024136|  -3.70976e-01 -3.38510e-01]
21Feb17_024136| [ 5.92999e-02 -5.35945e-01 -8.52259e-01  1.62766e-01 -2.64657e-01
21Feb17_024136|   6.65182e-01  2.45597e-01  2.99711e-01  7.14862e-01 -4.00362e-01
21Feb17_024136|   3.40170e-01 -1.14174e-01]
21Feb17_024136| [-4.26995e-01  8.46146e-01  9.81523e-01 -2.62996e-01  8.65377e-01
21Feb17_024136|  -6.86144e-01 -3.53983e-01 -2.18499e-01  3.29010e-01 -8.26088e-01
21Feb17_024136|   1.48202e-01  5.27152e-01]
21Feb17_024136| [-1.97937e-01  5.44304e-02  9.68680e-01  1.96012e-01  6.66432e-01
21Feb17_024136|  -1.15663e-01  1.01696e-01 -9.91833e-01  5.54656e-02  5.06069e-01
21Feb17_024136|  -8.39702e-01  6.07914e-02]
21Feb17_024136| [ 8.22409e-01 -3.07988e-01 -4.87097e-01 -2.67403e-01 -3.17115e-01
21Feb17_024136|   6.20877e-01  2.45721e-01  1.47039e-01  8.22748e-02 -4.61491e-01
21Feb17_024136|   5.08690e-01 -8.10093e-01]
21Feb17_024136| [-1.03463e-01 -7.13247e-01 -5.27190e-01 -8.14055e-01 -2.20069e-01
21Feb17_024136|   7.58689e-01  7.72478e-01 -3.75243e-01 -1.74773e-01  4.33018e-02
21Feb17_024136|   5.76591e-01 -9.04182e-01]
21Feb17_024136| [ 6.39880e-01 -2.76473e-01  4.48413e-01  7.92996e-01  6.12921e-01
21Feb17_024136|   8.45232e-01 -3.59434e-01 -1.65084e-01  6.00279e-01 -9.07135e-01
21Feb17_024136|  -9.18766e-01 -3.84510e-02]
21Feb17_024136| [-4.35982e-01  3.53117e-01 -4.33635e-01  4.41189e-01  2.02385e-01
21Feb17_024136|  -2.15156e-01 -3.32093e-01 -9.46393e-01  7.49818e-01  7.56840e-01
21Feb17_024136|  -2.97280e-01  3.76513e-01]
21Feb17_024136| [ 2.00098e-01 -3.94368e-01  4.74964e-01 -5.14077e-01 -5.02985e-01
21Feb17_024136|   6.57337e-01  4.54284e-01  7.99434e-01  1.18259e-01  7.90625e-01
21Feb17_024136|  -8.45168e-01 -7.22624e-01]
21Feb17_024136| [ 5.21361e-01 -9.37087e-01  6.98489e-01  7.45747e-01  9.84330e-01
21Feb17_024136|  -1.70463e-01 -4.14211e-01  4.94059e-01 -4.89685e-03 -7.22161e-02
21Feb17_024136|   3.28119e-01 -2.96382e-01]
21Feb17_024136| [ 9.97912e-02 -3.45331e-01 -3.32041e-01 -8.83410e-01  4.64194e-01
21Feb17_024136|  -2.94905e-01 -7.11116e-01 -2.12420e-01  8.93334e-01  5.60374e-01
21Feb17_024136|  -8.11522e-01  3.94537e-01]
21Feb17_024136| [ 2.39284e-01 -9.68110e-02 -3.48403e-01  6.68017e-01  1.07039e-01
21Feb17_024136|  -1.80014e-01 -1.28612e-01 -3.28318e-01  7.99371e-01  7.45882e-01
21Feb17_024136|   4.50426e-01 -9.94601e-02]
21Feb17_024136| [-9.32040e-02 -4.99896e-01 -3.18835e-01 -3.21963e-01  8.88030e-02
21Feb17_024136|   8.24115e-01  3.93190e-01  2.14054e-01 -4.70631e-02  5.36199e-01
21Feb17_024136|   7.72001e-01 -1.38053e-01]
21Feb17_024136| [ 8.31611e-01  7.46409e-01  2.18558e-01  7.47226e-01 -4.35942e-01
21Feb17_024136|  -6.59230e-01  3.39715e-02  8.14827e-01 -7.32488e-02 -1.12845e-01
21Feb17_024136|  -5.06295e-01  2.18074e-01]
21Feb17_024136| [-3.26563e-01  6.22846e-01  3.85669e-01 -9.86028e-01 -7.51629e-02
21Feb17_024136|  -1.88021e-01  7.27322e-01  5.61207e-04  1.34321e-01  7.19415e-01
21Feb17_024136|  -5.83277e-01 -4.45815e-01]
21Feb17_024136| [ 7.83756e-01  9.31803e-02  4.99853e-01 -9.31861e-01  7.91593e-01
21Feb17_024136|   1.96250e-01 -8.00498e-02  7.34271e-01 -2.68771e-01  7.49220e-01
21Feb17_024136|   1.24815e-01  6.17245e-01]
21Feb17_024136| [ 2.20500e-01 -9.26851e-01 -5.03545e-02  9.91366e-01  9.07862e-01
21Feb17_024136|   6.95839e-01  2.07702e-01  1.55262e-01  7.17753e-01 -6.02225e-01
21Feb17_024136|  -2.43972e-02  7.83904e-01]
21Feb17_024136| [-7.35179e-01 -4.04922e-01 -7.64988e-01  6.94764e-03 -5.74469e-01
21Feb17_024136|  -8.82582e-01 -4.25720e-01  4.48261e-01  9.38039e-01 -6.02162e-01
21Feb17_024136|   1.85138e-01  8.19467e-01]
21Feb17_024136| [-2.42564e-01  5.05630e-02 -6.53631e-01  8.89456e-01  3.73267e-02
21Feb17_024136|  -4.57479e-01  5.78190e-01 -8.65769e-01  4.43846e-01  9.21993e-01
21Feb17_024136|  -4.59642e-01  4.55887e-01]
21Feb17_024136| [ 1.79502e-01  5.97755e-01 -5.91581e-01  6.50878e-01 -3.20822e-02
21Feb17_024136|   7.98103e-01  9.23662e-01 -3.15762e-01  3.95919e-01 -9.74799e-01
21Feb17_024136|  -9.18783e-01  9.04381e-01]
21Feb17_024136| [-9.77544e-01 -9.84191e-01 -3.78989e-01  1.57093e-01 -1.19240e-01
21Feb17_024136|   7.04336e-01  9.20317e-01 -9.23300e-02  7.24512e-01 -4.73620e-01
21Feb17_024136|   4.32204e-01  1.96422e-01]
21Feb17_024136| [-9.94008e-01  1.23345e-01 -2.91311e-01  3.86181e-01  3.50519e-01
21Feb17_024136|   8.97293e-02  1.28693e-01  7.64175e-01  9.70172e-01 -9.36008e-01
21Feb17_024136|   2.31190e-01 -3.81352e-01]
21Feb17_024136| [-8.68842e-01 -3.08689e-01 -7.85613e-02 -7.75421e-01 -2.62711e-01
21Feb17_024136|  -9.13854e-01  5.58996e-01  8.97445e-01 -4.78631e-01 -4.79708e-02
21Feb17_024136|  -2.09270e-01  1.03320e-01]
21Feb17_024136| [ 2.47190e-01  8.94828e-01 -8.83655e-01  1.67368e-01 -1.09226e-01
21Feb17_024136|   5.39374e-01  3.22158e-01  7.22802e-01 -4.76431e-01 -3.98606e-01
21Feb17_024136|   3.91466e-01 -5.89172e-01]
21Feb17_024136| [ 2.03966e-01 -8.11217e-01  8.56319e-01 -5.26108e-01 -9.29896e-01
21Feb17_024136|   5.92077e-01  8.52854e-01  6.15086e-01  5.45676e-01 -8.13950e-01
21Feb17_024136|   6.24771e-01 -9.57171e-01]
21Feb17_024136| [-7.59457e-01  2.18652e-01 -9.40198e-01 -1.94388e-03 -3.63300e-01
21Feb17_024136|   2.19527e-01 -3.86609e-01  6.57866e-02  8.04643e-01  4.37489e-01
21Feb17_024136|   6.39988e-01 -8.42788e-01]
21Feb17_024136| [-2.79911e-01  8.89651e-01  5.38994e-02  7.45843e-01 -9.32154e-01
21Feb17_024136|   5.56522e-01  5.04658e-01  3.56409e-01 -5.15289e-01  6.99550e-01
21Feb17_024136|  -7.31032e-01  1.61260e-01]
21Feb17_024136| [ 8.41582e-01 -5.25391e-01  4.65437e-01  4.40808e-01 -6.03761e-01
21Feb17_024136|   6.23036e-01  9.46114e-01  5.92328e-01  2.08190e-01 -6.69715e-01
21Feb17_024136|  -7.35264e-02  5.96491e-01]
21Feb17_024136| [ 3.20347e-01  1.37290e-01  1.72843e-02 -4.70187e-01  5.92987e-01
21Feb17_024136|   3.57672e-01  2.73873e-01 -8.65750e-02 -3.09144e-01 -9.20603e-01
21Feb17_024136|   2.82912e-01  6.38325e-01]
21Feb17_024136| [-8.91399e-01 -1.24857e-01 -4.86431e-01 -9.05166e-01  8.47373e-01
21Feb17_024136|   3.18146e-01  2.73494e-02 -5.33112e-01  5.63862e-01 -5.12821e-01
21Feb17_024136|  -9.38474e-01 -9.90043e-01]
21Feb17_024136| [-8.25448e-01 -1.90141e-02 -5.51276e-01 -8.23215e-01  7.26222e-02
21Feb17_024136|   3.49894e-01  5.17693e-01 -5.57217e-01 -3.26301e-01  7.78564e-01
21Feb17_024136|   6.58213e-01 -2.83929e-01]
21Feb17_024136| [ 6.18012e-02 -4.92329e-01  5.41071e-01  2.13013e-01  6.35700e-01
21Feb17_024136|  -1.65529e-01  5.77357e-01  2.45531e-01  2.54855e-01 -8.48854e-01
21Feb17_024136|   6.46386e-01 -4.13404e-01]
21Feb17_024136| [-3.41116e-01 -4.75918e-01  3.59165e-01  6.02895e-01 -4.31688e-01
21Feb17_024136|  -8.51757e-01  2.31464e-01 -9.57407e-01  2.83436e-01 -4.51744e-01
21Feb17_024136|   4.80022e-02 -8.35007e-01]
21Feb17_024136| [ 9.67499e-01  5.85047e-02  7.21540e-01  3.12459e-01  3.50272e-01
21Feb17_024136|   2.14450e-01 -3.30294e-01 -7.99000e-01  1.11959e-01  2.74091e-01
21Feb17_024136|  -1.78234e-01  9.40235e-01]
21Feb17_024136| [-1.14387e-01  4.31319e-01  3.73789e-01 -4.62497e-01  4.50407e-01
21Feb17_024136|  -4.00668e-01 -8.26575e-01  2.39589e-01 -5.24611e-01  3.30691e-01
21Feb17_024136|  -3.99504e-01  1.44547e-01]
21Feb17_024136| [ 7.34826e-01 -5.37352e-01 -6.62895e-01  1.04258e-01  2.15046e-03
21Feb17_024136|   2.71790e-01  8.51151e-01 -6.31948e-01  1.94011e-01 -6.41830e-01
21Feb17_024136|   1.67802e-01 -4.29449e-01]
21Feb17_024136| [-6.18752e-01  1.18069e-01 -7.98263e-01  4.75266e-01 -9.95474e-01
21Feb17_024136|  -1.79698e-01  6.90455e-01  3.44607e-01 -5.80013e-01 -6.16218e-02
21Feb17_024136|   7.01329e-01  8.33298e-02]
21Feb17_024136| [-2.69227e-01 -1.43165e-02 -3.33533e-01 -1.69954e-01 -1.26476e-02
21Feb17_024136|   7.69653e-01 -6.99893e-01  5.22539e-01 -1.67862e-01  4.44416e-01
21Feb17_024136|   6.72372e-01  5.52923e-01]
21Feb17_024136| [-7.10479e-01  1.61800e-01  2.53825e-01 -3.00634e-01 -5.06805e-01
21Feb17_024136|   2.02091e-01 -4.94980e-02 -1.44363e-01 -6.18371e-01  5.74350e-01
21Feb17_024136|  -1.85073e-01 -8.11049e-01]
21Feb17_024136| [-6.60846e-01 -1.69003e-01  6.00733e-01 -8.28618e-01 -3.99034e-01
21Feb17_024136|  -5.82553e-01  7.34428e-02  5.57096e-01 -1.50695e-01  1.26307e-01
21Feb17_024136|   8.92712e-01 -8.75142e-01]
21Feb17_024136| [ 7.58158e-01  5.89907e-01 -1.92304e-01 -3.86200e-01 -2.63049e-01
21Feb17_024136|  -3.41209e-03  4.05030e-01 -8.95945e-02  9.79113e-01  6.78942e-02
21Feb17_024136|  -9.53580e-01  7.06162e-01]
21Feb17_024136| [-1.23045e-01  9.25694e-01  5.20030e-01  4.57808e-01 -9.99639e-01
21Feb17_024136|  -9.80069e-02  3.03598e-01  4.26167e-02 -3.64595e-01 -7.17635e-01
21Feb17_024136|   1.61128e-01  6.30329e-01]
21Feb17_024136| [ 2.02232e-02 -3.24113e-01  7.43999e-01 -3.75983e-01  4.63558e-01
21Feb17_024136|  -2.04941e-01 -5.28404e-02  4.26576e-01 -2.53802e-01  1.74976e-01
21Feb17_024136|  -8.35763e-01  8.54548e-01]
21Feb17_024136| [-5.76875e-01  5.40954e-01 -4.91777e-01  4.40209e-01 -9.16379e-01
21Feb17_024136|   6.01728e-01  1.25226e-02  2.05876e-01  8.45524e-01 -8.34178e-01
21Feb17_024136|  -7.87379e-01  8.63352e-01]
21Feb17_024136| [-3.15102e-01  7.00213e-01  6.69503e-01  7.15510e-01 -9.53550e-01
21Feb17_024136|   4.07885e-02  4.25336e-01  6.24629e-01  9.90858e-01  6.36989e-01
21Feb17_024136|  -6.44355e-01 -5.47589e-01]
21Feb17_024136| [-8.25051e-01 -4.37574e-01  4.76334e-01 -7.71092e-01  7.98467e-01
21Feb17_024136|  -1.52347e-01  3.34469e-01  1.51889e-01 -9.60611e-01  4.62484e-01
21Feb17_024136|   4.10115e-01 -1.60555e-01]
21Feb17_024136| [ 1.77712e-01  6.55776e-01  8.97735e-01 -9.20852e-01 -9.69032e-01
21Feb17_024136|  -4.79756e-02 -3.24015e-01 -1.57490e-01 -6.25919e-01  9.94240e-01
21Feb17_024136|  -4.74141e-01 -1.00993e-01]
21Feb17_024136| [ 3.66246e-01  8.06205e-01  3.37216e-01 -3.17040e-01  9.19693e-01
21Feb17_024136|   8.28581e-01  2.22724e-01 -5.57410e-01 -8.17434e-01 -8.65693e-01
21Feb17_024136|  -4.72960e-01  7.15176e-01]
21Feb17_024136| [-8.25000e-01 -4.67253e-01 -1.84646e-02  3.88053e-01 -8.75853e-01
21Feb17_024136|  -2.34509e-01  9.53471e-01  8.05489e-02  2.71744e-01 -7.15129e-01
21Feb17_024136|   9.24875e-01 -6.07435e-01]
21Feb17_024136| [-2.79447e-01  2.39105e-01  1.32962e-01 -7.68103e-01  7.58443e-01
21Feb17_024136|  -1.69646e-01 -7.52460e-01 -7.30195e-01 -4.68985e-01 -2.88784e-01
21Feb17_024136|   3.77655e-02 -5.72024e-01]
21Feb17_024136| [-8.37481e-01 -8.22188e-02  8.45547e-01 -5.53876e-01  5.72703e-01
21Feb17_024136|   3.09970e-01  8.96552e-01  3.97690e-01 -7.19080e-01  2.37714e-01
21Feb17_024136|   6.60752e-01  1.69435e-01]]
21Feb17_024136|-- Bias --
21Feb17_024136|[-0.28065  0.08142 -0.20194  0.96969  0.45180  0.54884  0.16606 -0.15804
21Feb17_024136|  0.47362  0.17133  0.43345 -0.35803]
21Feb17_024136|Layer 1:
21Feb17_024136|-- Config --
21Feb17_024136|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 12], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024136|-- Weights --
21Feb17_024136|[[-0.88546  0.72941]
21Feb17_024136| [ 0.79196 -0.05477]
21Feb17_024136| [-0.89752 -0.49343]
21Feb17_024136| [ 0.78974 -0.41510]
21Feb17_024136| [ 0.29561 -0.94575]
21Feb17_024136| [-0.14754  0.69148]
21Feb17_024136| [-0.33558  0.37910]
21Feb17_024136| [-0.82387  0.15998]
21Feb17_024136| [-0.77760  0.88462]
21Feb17_024136| [ 0.98329 -0.68363]
21Feb17_024136| [ 0.88895  0.40387]
21Feb17_024136| [ 0.39015 -0.38652]]
21Feb17_024136|-- Bias --
21Feb17_024136|[ 0.28702 -0.70976]
21Feb17_024136|Predicting the validation and test data with the Best initial individual.
21Feb17_024142| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_024142|-----------  ------------------  --------------------  ----------
21Feb17_024142|Validation         42.00                  12            0.00000
21Feb17_024142|   Test            36.32                  12            0.00298
21Feb17_024142|-------------------- Test #0 --------------------
21Feb17_024142|Best final individual weights
21Feb17_024142|Individual:
21Feb17_024142|-- Constant hidden layers --
21Feb17_024142|False
21Feb17_024142|Layer 0:
21Feb17_024142|-- Config --
21Feb17_024142|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024142|-- Weights --
21Feb17_024142|[[-0.73212  1.32861  0.10200]
21Feb17_024142| [ 1.48746 -2.97273 -0.42944]
21Feb17_024142| [ 0.53095 -1.50623  0.79224]
21Feb17_024142| [-1.07292 -0.83175 -0.90105]
21Feb17_024142| [-0.48696 -0.89325  0.27226]
21Feb17_024142| [-3.02511  0.34155 -0.03837]
21Feb17_024142| [-0.76747  0.57140 -0.46892]
21Feb17_024142| [-0.07581  0.14713  0.85910]
21Feb17_024142| [-1.37488  0.52170 -0.36205]
21Feb17_024142| [ 1.60981 -0.08727 -0.11267]
21Feb17_024142| [ 0.50986  1.58916 -0.35287]
21Feb17_024142| [-0.34599  1.27113 -0.16393]
21Feb17_024142| [ 1.29203  1.19467  0.37695]
21Feb17_024142| [ 0.58704  0.06328 -0.24240]
21Feb17_024142| [-0.93888 -0.89760  0.57087]
21Feb17_024142| [ 0.99159 -0.66387  0.35177]
21Feb17_024142| [-0.67119  1.06910 -0.12512]
21Feb17_024142| [-0.91534  1.23744 -0.40465]
21Feb17_024142| [ 1.39278  0.08069  0.23328]
21Feb17_024142| [ 0.09880  0.57603 -0.96101]
21Feb17_024142| [ 0.01621 -0.13343 -0.27624]
21Feb17_024142| [-1.28286 -2.28909  0.37931]
21Feb17_024142| [-0.28370  0.09336  0.01547]
21Feb17_024142| [-0.51894  1.84280 -0.25906]
21Feb17_024142| [-0.83075 -0.04508  0.12107]
21Feb17_024142| [ 0.37343  1.18436 -0.07358]
21Feb17_024142| [-2.38657 -0.35191  0.01962]
21Feb17_024142| [ 0.95757 -0.91760 -0.08971]
21Feb17_024142| [ 0.38792 -0.01880  0.69717]
21Feb17_024142| [ 1.66877 -0.58078 -1.21129]
21Feb17_024142| [-0.50943  0.59080  0.30856]
21Feb17_024142| [ 0.30163  1.11518  0.98185]
21Feb17_024142| [-0.73226  0.32281 -0.66712]
21Feb17_024142| [-0.62054 -2.21049  1.40981]
21Feb17_024142| [ 1.23185 -0.58090  0.35844]
21Feb17_024142| [-0.05616  0.24219 -0.02853]
21Feb17_024142| [-1.05085 -2.30259 -0.16276]
21Feb17_024142| [ 0.71087  0.14900  1.13430]
21Feb17_024142| [-2.45877 -1.20999 -1.04986]
21Feb17_024142| [-1.00480  1.36344 -0.13998]
21Feb17_024142| [ 1.83140 -0.91532  0.07616]
21Feb17_024142| [-0.60404 -2.05184  0.76948]
21Feb17_024142| [ 0.52617  0.76042 -1.76746]
21Feb17_024142| [-0.22134  0.17324  0.99530]
21Feb17_024142| [-0.36427  1.34655  0.02110]
21Feb17_024142| [-0.93125 -0.33620 -0.25012]
21Feb17_024142| [-2.76428  0.14487  0.48096]
21Feb17_024142| [-0.10518  0.35052  1.71840]
21Feb17_024142| [-1.27998  1.12568  1.26523]
21Feb17_024142| [-0.60698  1.53230 -0.60824]
21Feb17_024142| [ 0.02898  2.98718 -0.59153]
21Feb17_024142| [ 0.17588 -0.00449  0.50797]
21Feb17_024142| [-1.42674 -0.54967 -0.21310]
21Feb17_024142| [ 1.03196  1.18733  0.36755]
21Feb17_024142| [ 1.04748 -1.47444 -0.08469]
21Feb17_024142| [ 0.49410  0.38745  0.68469]
21Feb17_024142| [-0.62880  0.73245  0.19964]]
21Feb17_024142|-- Bias --
21Feb17_024142|[-0.18798  0.64571 -0.23142]
21Feb17_024142|Layer 1:
21Feb17_024142|-- Config --
21Feb17_024142|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024142|-- Weights --
21Feb17_024142|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_024142| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_024142| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_024142|-- Bias --
21Feb17_024142|[0.60477 0.03773 0.26452 0.12222]
21Feb17_024142|Layer 2:
21Feb17_024142|-- Config --
21Feb17_024142|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024142|-- Weights --
21Feb17_024142|[[ 0.67920  0.12119]
21Feb17_024142| [ 0.44836  0.02916]
21Feb17_024142| [ 0.68939  0.31516]
21Feb17_024142| [-0.58995 -0.05861]]
21Feb17_024142|-- Bias --
21Feb17_024142|[ 0.59649 -0.08079]
21Feb17_024142|Layer 3:
21Feb17_024142|-- Config --
21Feb17_024142|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024142|-- Weights --
21Feb17_024142|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_024142| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_024142|-- Bias --
21Feb17_024142|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_024142|Layer 4:
21Feb17_024142|-- Config --
21Feb17_024142|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024142|-- Weights --
21Feb17_024142|[[-0.03514 -1.04833]
21Feb17_024142| [ 1.25238  0.62094]
21Feb17_024142| [ 0.99203  0.37406]
21Feb17_024142| [ 0.49902  0.67158]
21Feb17_024142| [-1.35709  0.38335]]
21Feb17_024142|-- Bias --
21Feb17_024142|[0.31435 0.36299]
21Feb17_024142|Predicting the validation and test data with the Best final individual.
21Feb17_024150| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_024150|-----------  ------------------  --------------------  ----------
21Feb17_024150|Validation         40.17                  56            0.05627
21Feb17_024150|   Test            21.37                  56            0.70301
21Feb17_024150|-------------------- Test #1 --------------------
21Feb17_024150|Best final individual weights
21Feb17_024150|Individual:
21Feb17_024150|-- Constant hidden layers --
21Feb17_024150|False
21Feb17_024150|Layer 0:
21Feb17_024150|-- Config --
21Feb17_024150|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024150|-- Weights --
21Feb17_024150|[[-0.73212  1.32861  0.10200]
21Feb17_024150| [ 1.48746 -2.97273 -0.42944]
21Feb17_024150| [ 0.53095 -1.50623  0.79224]
21Feb17_024150| [-1.07292 -0.83175 -0.90105]
21Feb17_024150| [-0.48696 -0.89325  0.27226]
21Feb17_024150| [-3.02511  0.34155 -0.03837]
21Feb17_024150| [-0.76747  0.57140 -0.46892]
21Feb17_024150| [-0.07581  0.14713  0.85910]
21Feb17_024150| [-1.37488  0.52170 -0.36205]
21Feb17_024150| [ 1.60981 -0.08727 -0.11267]
21Feb17_024150| [ 0.50986  1.58916 -0.35287]
21Feb17_024150| [-0.34599  1.27113 -0.16393]
21Feb17_024150| [ 1.29203  1.19467  0.37695]
21Feb17_024150| [ 0.58704  0.06328 -0.24240]
21Feb17_024150| [-0.93888 -0.89760  0.57087]
21Feb17_024150| [ 0.99159 -0.66387  0.35177]
21Feb17_024150| [-0.67119  1.06910 -0.12512]
21Feb17_024150| [-0.91534  1.23744 -0.40465]
21Feb17_024150| [ 1.39278  0.08069  0.23328]
21Feb17_024150| [ 0.09880  0.57603 -0.96101]
21Feb17_024150| [ 0.01621 -0.13343 -0.27624]
21Feb17_024150| [-1.28286 -2.28909  0.37931]
21Feb17_024150| [-0.28370  0.09336  0.01547]
21Feb17_024150| [-0.51894  1.84280 -0.25906]
21Feb17_024150| [-0.83075 -0.04508  0.12107]
21Feb17_024150| [ 0.37343  1.18436 -0.07358]
21Feb17_024150| [-2.38657 -0.35191  0.01962]
21Feb17_024150| [ 0.95757 -0.91760 -0.08971]
21Feb17_024150| [ 0.38792 -0.01880  0.69717]
21Feb17_024150| [ 1.66877 -0.58078 -1.21129]
21Feb17_024150| [-0.50943  0.59080  0.30856]
21Feb17_024150| [ 0.30163  1.11518  0.98185]
21Feb17_024150| [-0.73226  0.32281 -0.66712]
21Feb17_024150| [-0.62054 -2.21049  1.40981]
21Feb17_024150| [ 1.23185 -0.58090  0.35844]
21Feb17_024150| [-0.05616  0.24219 -0.02853]
21Feb17_024150| [-1.05085 -2.30259 -0.16276]
21Feb17_024150| [ 0.71087  0.14900  1.13430]
21Feb17_024150| [-2.45877 -1.20999 -1.04986]
21Feb17_024150| [-1.00480  1.36344 -0.13998]
21Feb17_024150| [ 1.83140 -0.91532  0.07616]
21Feb17_024150| [-0.60404 -2.05184  0.76948]
21Feb17_024150| [ 0.52617  0.76042 -1.76746]
21Feb17_024150| [-0.22134  0.17324  0.99530]
21Feb17_024150| [-0.36427  1.34655  0.02110]
21Feb17_024150| [-0.93125 -0.33620 -0.25012]
21Feb17_024150| [-2.76428  0.14487  0.48096]
21Feb17_024150| [-0.10518  0.35052  1.71840]
21Feb17_024150| [-1.27998  1.12568  1.26523]
21Feb17_024150| [-0.60698  1.53230 -0.60824]
21Feb17_024150| [ 0.02898  2.98718 -0.59153]
21Feb17_024150| [ 0.17588 -0.00449  0.50797]
21Feb17_024150| [-1.42674 -0.54967 -0.21310]
21Feb17_024150| [ 1.03196  1.18733  0.36755]
21Feb17_024150| [ 1.04748 -1.47444 -0.08469]
21Feb17_024150| [ 0.49410  0.38745  0.68469]
21Feb17_024150| [-0.62880  0.73245  0.19964]]
21Feb17_024150|-- Bias --
21Feb17_024150|[-0.18798  0.64571 -0.23142]
21Feb17_024150|Layer 1:
21Feb17_024150|-- Config --
21Feb17_024150|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024150|-- Weights --
21Feb17_024150|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_024150| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_024150| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_024150|-- Bias --
21Feb17_024150|[0.60477 0.03773 0.26452 0.12222]
21Feb17_024150|Layer 2:
21Feb17_024150|-- Config --
21Feb17_024150|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024150|-- Weights --
21Feb17_024150|[[ 0.67920  0.12119]
21Feb17_024150| [ 0.44836  0.02916]
21Feb17_024150| [ 0.68939  0.31516]
21Feb17_024150| [-0.58995 -0.05861]]
21Feb17_024150|-- Bias --
21Feb17_024150|[ 0.59649 -0.08079]
21Feb17_024150|Layer 3:
21Feb17_024150|-- Config --
21Feb17_024150|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024150|-- Weights --
21Feb17_024150|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_024150| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_024150|-- Bias --
21Feb17_024150|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_024150|Layer 4:
21Feb17_024150|-- Config --
21Feb17_024150|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024150|-- Weights --
21Feb17_024150|[[-0.03514 -1.04833]
21Feb17_024150| [ 1.25238  0.62094]
21Feb17_024150| [ 0.99203  0.37406]
21Feb17_024150| [ 0.49902  0.67158]
21Feb17_024150| [-1.35709  0.38335]]
21Feb17_024150|-- Bias --
21Feb17_024150|[0.31435 0.36299]
21Feb17_024150|Predicting the validation and test data with the Best final individual.
21Feb17_024157| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_024157|-----------  ------------------  --------------------  ----------
21Feb17_024157|Validation         23.83                  56            0.86651
21Feb17_024157|   Test            22.68                  56            0.77969
21Feb17_024157|-------------------- Test #2 --------------------
21Feb17_024157|Best final individual weights
21Feb17_024157|Individual:
21Feb17_024157|-- Constant hidden layers --
21Feb17_024157|False
21Feb17_024157|Layer 0:
21Feb17_024157|-- Config --
21Feb17_024157|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024157|-- Weights --
21Feb17_024157|[[-0.73212  1.32861  0.10200]
21Feb17_024157| [ 1.48746 -2.97273 -0.42944]
21Feb17_024157| [ 0.53095 -1.50623  0.79224]
21Feb17_024157| [-1.07292 -0.83175 -0.90105]
21Feb17_024157| [-0.48696 -0.89325  0.27226]
21Feb17_024157| [-3.02511  0.34155 -0.03837]
21Feb17_024157| [-0.76747  0.57140 -0.46892]
21Feb17_024157| [-0.07581  0.14713  0.85910]
21Feb17_024157| [-1.37488  0.52170 -0.36205]
21Feb17_024157| [ 1.60981 -0.08727 -0.11267]
21Feb17_024157| [ 0.50986  1.58916 -0.35287]
21Feb17_024157| [-0.34599  1.27113 -0.16393]
21Feb17_024157| [ 1.29203  1.19467  0.37695]
21Feb17_024157| [ 0.58704  0.06328 -0.24240]
21Feb17_024157| [-0.93888 -0.89760  0.57087]
21Feb17_024157| [ 0.99159 -0.66387  0.35177]
21Feb17_024157| [-0.67119  1.06910 -0.12512]
21Feb17_024157| [-0.91534  1.23744 -0.40465]
21Feb17_024157| [ 1.39278  0.08069  0.23328]
21Feb17_024157| [ 0.09880  0.57603 -0.96101]
21Feb17_024157| [ 0.01621 -0.13343 -0.27624]
21Feb17_024157| [-1.28286 -2.28909  0.37931]
21Feb17_024157| [-0.28370  0.09336  0.01547]
21Feb17_024157| [-0.51894  1.84280 -0.25906]
21Feb17_024157| [-0.83075 -0.04508  0.12107]
21Feb17_024157| [ 0.37343  1.18436 -0.07358]
21Feb17_024157| [-2.38657 -0.35191  0.01962]
21Feb17_024157| [ 0.95757 -0.91760 -0.08971]
21Feb17_024157| [ 0.38792 -0.01880  0.69717]
21Feb17_024157| [ 1.66877 -0.58078 -1.21129]
21Feb17_024157| [-0.50943  0.59080  0.30856]
21Feb17_024157| [ 0.30163  1.11518  0.98185]
21Feb17_024157| [-0.73226  0.32281 -0.66712]
21Feb17_024157| [-0.62054 -2.21049  1.40981]
21Feb17_024157| [ 1.23185 -0.58090  0.35844]
21Feb17_024157| [-0.05616  0.24219 -0.02853]
21Feb17_024157| [-1.05085 -2.30259 -0.16276]
21Feb17_024157| [ 0.71087  0.14900  1.13430]
21Feb17_024157| [-2.45877 -1.20999 -1.04986]
21Feb17_024157| [-1.00480  1.36344 -0.13998]
21Feb17_024157| [ 1.83140 -0.91532  0.07616]
21Feb17_024157| [-0.60404 -2.05184  0.76948]
21Feb17_024157| [ 0.52617  0.76042 -1.76746]
21Feb17_024157| [-0.22134  0.17324  0.99530]
21Feb17_024157| [-0.36427  1.34655  0.02110]
21Feb17_024157| [-0.93125 -0.33620 -0.25012]
21Feb17_024157| [-2.76428  0.14487  0.48096]
21Feb17_024157| [-0.10518  0.35052  1.71840]
21Feb17_024157| [-1.27998  1.12568  1.26523]
21Feb17_024157| [-0.60698  1.53230 -0.60824]
21Feb17_024157| [ 0.02898  2.98718 -0.59153]
21Feb17_024157| [ 0.17588 -0.00449  0.50797]
21Feb17_024157| [-1.42674 -0.54967 -0.21310]
21Feb17_024157| [ 1.03196  1.18733  0.36755]
21Feb17_024157| [ 1.04748 -1.47444 -0.08469]
21Feb17_024157| [ 0.49410  0.38745  0.68469]
21Feb17_024157| [-0.62880  0.73245  0.19964]]
21Feb17_024157|-- Bias --
21Feb17_024157|[-0.18798  0.64571 -0.23142]
21Feb17_024157|Layer 1:
21Feb17_024157|-- Config --
21Feb17_024157|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024157|-- Weights --
21Feb17_024157|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_024157| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_024157| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_024157|-- Bias --
21Feb17_024157|[0.60477 0.03773 0.26452 0.12222]
21Feb17_024157|Layer 2:
21Feb17_024157|-- Config --
21Feb17_024157|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024157|-- Weights --
21Feb17_024157|[[ 0.67920  0.12119]
21Feb17_024157| [ 0.44836  0.02916]
21Feb17_024157| [ 0.68939  0.31516]
21Feb17_024157| [-0.58995 -0.05861]]
21Feb17_024157|-- Bias --
21Feb17_024157|[ 0.59649 -0.08079]
21Feb17_024157|Layer 3:
21Feb17_024157|-- Config --
21Feb17_024157|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024157|-- Weights --
21Feb17_024157|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_024157| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_024157|-- Bias --
21Feb17_024157|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_024157|Layer 4:
21Feb17_024157|-- Config --
21Feb17_024157|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024157|-- Weights --
21Feb17_024157|[[-0.03514 -1.04833]
21Feb17_024157| [ 1.25238  0.62094]
21Feb17_024157| [ 0.99203  0.37406]
21Feb17_024157| [ 0.49902  0.67158]
21Feb17_024157| [-1.35709  0.38335]]
21Feb17_024157|-- Bias --
21Feb17_024157|[0.31435 0.36299]
21Feb17_024157|Predicting the validation and test data with the Best final individual.
21Feb17_024205| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_024205|-----------  ------------------  --------------------  ----------
21Feb17_024205|Validation         23.91                  56            0.70865
21Feb17_024205|   Test            29.45                  56            0.70270
21Feb17_024205|-------------------- Test #3 --------------------
21Feb17_024205|Best final individual weights
21Feb17_024205|Individual:
21Feb17_024205|-- Constant hidden layers --
21Feb17_024205|False
21Feb17_024205|Layer 0:
21Feb17_024205|-- Config --
21Feb17_024205|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024205|-- Weights --
21Feb17_024205|[[-0.73212  1.32861  0.10200]
21Feb17_024205| [ 1.48746 -2.97273 -0.42944]
21Feb17_024205| [ 0.53095 -1.50623  0.79224]
21Feb17_024205| [-1.07292 -0.83175 -0.90105]
21Feb17_024205| [-0.48696 -0.89325  0.27226]
21Feb17_024205| [-3.02511  0.34155 -0.03837]
21Feb17_024205| [-0.76747  0.57140 -0.46892]
21Feb17_024205| [-0.07581  0.14713  0.85910]
21Feb17_024205| [-1.37488  0.52170 -0.36205]
21Feb17_024205| [ 1.60981 -0.08727 -0.11267]
21Feb17_024205| [ 0.50986  1.58916 -0.35287]
21Feb17_024205| [-0.34599  1.27113 -0.16393]
21Feb17_024205| [ 1.29203  1.19467  0.37695]
21Feb17_024205| [ 0.58704  0.06328 -0.24240]
21Feb17_024205| [-0.93888 -0.89760  0.57087]
21Feb17_024205| [ 0.99159 -0.66387  0.35177]
21Feb17_024205| [-0.67119  1.06910 -0.12512]
21Feb17_024205| [-0.91534  1.23744 -0.40465]
21Feb17_024205| [ 1.39278  0.08069  0.23328]
21Feb17_024205| [ 0.09880  0.57603 -0.96101]
21Feb17_024205| [ 0.01621 -0.13343 -0.27624]
21Feb17_024205| [-1.28286 -2.28909  0.37931]
21Feb17_024205| [-0.28370  0.09336  0.01547]
21Feb17_024205| [-0.51894  1.84280 -0.25906]
21Feb17_024205| [-0.83075 -0.04508  0.12107]
21Feb17_024205| [ 0.37343  1.18436 -0.07358]
21Feb17_024205| [-2.38657 -0.35191  0.01962]
21Feb17_024205| [ 0.95757 -0.91760 -0.08971]
21Feb17_024205| [ 0.38792 -0.01880  0.69717]
21Feb17_024205| [ 1.66877 -0.58078 -1.21129]
21Feb17_024205| [-0.50943  0.59080  0.30856]
21Feb17_024205| [ 0.30163  1.11518  0.98185]
21Feb17_024205| [-0.73226  0.32281 -0.66712]
21Feb17_024205| [-0.62054 -2.21049  1.40981]
21Feb17_024205| [ 1.23185 -0.58090  0.35844]
21Feb17_024205| [-0.05616  0.24219 -0.02853]
21Feb17_024205| [-1.05085 -2.30259 -0.16276]
21Feb17_024205| [ 0.71087  0.14900  1.13430]
21Feb17_024205| [-2.45877 -1.20999 -1.04986]
21Feb17_024205| [-1.00480  1.36344 -0.13998]
21Feb17_024205| [ 1.83140 -0.91532  0.07616]
21Feb17_024205| [-0.60404 -2.05184  0.76948]
21Feb17_024205| [ 0.52617  0.76042 -1.76746]
21Feb17_024205| [-0.22134  0.17324  0.99530]
21Feb17_024205| [-0.36427  1.34655  0.02110]
21Feb17_024205| [-0.93125 -0.33620 -0.25012]
21Feb17_024205| [-2.76428  0.14487  0.48096]
21Feb17_024205| [-0.10518  0.35052  1.71840]
21Feb17_024205| [-1.27998  1.12568  1.26523]
21Feb17_024205| [-0.60698  1.53230 -0.60824]
21Feb17_024205| [ 0.02898  2.98718 -0.59153]
21Feb17_024205| [ 0.17588 -0.00449  0.50797]
21Feb17_024205| [-1.42674 -0.54967 -0.21310]
21Feb17_024205| [ 1.03196  1.18733  0.36755]
21Feb17_024205| [ 1.04748 -1.47444 -0.08469]
21Feb17_024205| [ 0.49410  0.38745  0.68469]
21Feb17_024205| [-0.62880  0.73245  0.19964]]
21Feb17_024205|-- Bias --
21Feb17_024205|[-0.18798  0.64571 -0.23142]
21Feb17_024205|Layer 1:
21Feb17_024205|-- Config --
21Feb17_024205|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024205|-- Weights --
21Feb17_024205|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_024205| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_024205| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_024205|-- Bias --
21Feb17_024205|[0.60477 0.03773 0.26452 0.12222]
21Feb17_024205|Layer 2:
21Feb17_024205|-- Config --
21Feb17_024205|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024205|-- Weights --
21Feb17_024205|[[ 0.67920  0.12119]
21Feb17_024205| [ 0.44836  0.02916]
21Feb17_024205| [ 0.68939  0.31516]
21Feb17_024205| [-0.58995 -0.05861]]
21Feb17_024205|-- Bias --
21Feb17_024205|[ 0.59649 -0.08079]
21Feb17_024205|Layer 3:
21Feb17_024205|-- Config --
21Feb17_024205|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024205|-- Weights --
21Feb17_024205|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_024205| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_024205|-- Bias --
21Feb17_024205|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_024205|Layer 4:
21Feb17_024205|-- Config --
21Feb17_024205|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024205|-- Weights --
21Feb17_024205|[[-0.03514 -1.04833]
21Feb17_024205| [ 1.25238  0.62094]
21Feb17_024205| [ 0.99203  0.37406]
21Feb17_024205| [ 0.49902  0.67158]
21Feb17_024205| [-1.35709  0.38335]]
21Feb17_024205|-- Bias --
21Feb17_024205|[0.31435 0.36299]
21Feb17_024205|Predicting the validation and test data with the Best final individual.
21Feb17_024213| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_024213|-----------  ------------------  --------------------  ----------
21Feb17_024213|Validation         24.35                  56            0.84577
21Feb17_024213|   Test            21.63                  56            0.70714
21Feb17_024213|-------------------- Test #4 --------------------
21Feb17_024213|Best final individual weights
21Feb17_024213|Individual:
21Feb17_024213|-- Constant hidden layers --
21Feb17_024213|False
21Feb17_024213|Layer 0:
21Feb17_024213|-- Config --
21Feb17_024213|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024213|-- Weights --
21Feb17_024213|[[-0.73212  1.32861  0.10200]
21Feb17_024213| [ 1.48746 -2.97273 -0.42944]
21Feb17_024213| [ 0.53095 -1.50623  0.79224]
21Feb17_024213| [-1.07292 -0.83175 -0.90105]
21Feb17_024213| [-0.48696 -0.89325  0.27226]
21Feb17_024213| [-3.02511  0.34155 -0.03837]
21Feb17_024213| [-0.76747  0.57140 -0.46892]
21Feb17_024213| [-0.07581  0.14713  0.85910]
21Feb17_024213| [-1.37488  0.52170 -0.36205]
21Feb17_024213| [ 1.60981 -0.08727 -0.11267]
21Feb17_024213| [ 0.50986  1.58916 -0.35287]
21Feb17_024213| [-0.34599  1.27113 -0.16393]
21Feb17_024213| [ 1.29203  1.19467  0.37695]
21Feb17_024213| [ 0.58704  0.06328 -0.24240]
21Feb17_024213| [-0.93888 -0.89760  0.57087]
21Feb17_024213| [ 0.99159 -0.66387  0.35177]
21Feb17_024213| [-0.67119  1.06910 -0.12512]
21Feb17_024213| [-0.91534  1.23744 -0.40465]
21Feb17_024213| [ 1.39278  0.08069  0.23328]
21Feb17_024213| [ 0.09880  0.57603 -0.96101]
21Feb17_024213| [ 0.01621 -0.13343 -0.27624]
21Feb17_024213| [-1.28286 -2.28909  0.37931]
21Feb17_024213| [-0.28370  0.09336  0.01547]
21Feb17_024213| [-0.51894  1.84280 -0.25906]
21Feb17_024213| [-0.83075 -0.04508  0.12107]
21Feb17_024213| [ 0.37343  1.18436 -0.07358]
21Feb17_024213| [-2.38657 -0.35191  0.01962]
21Feb17_024213| [ 0.95757 -0.91760 -0.08971]
21Feb17_024213| [ 0.38792 -0.01880  0.69717]
21Feb17_024213| [ 1.66877 -0.58078 -1.21129]
21Feb17_024213| [-0.50943  0.59080  0.30856]
21Feb17_024213| [ 0.30163  1.11518  0.98185]
21Feb17_024213| [-0.73226  0.32281 -0.66712]
21Feb17_024213| [-0.62054 -2.21049  1.40981]
21Feb17_024213| [ 1.23185 -0.58090  0.35844]
21Feb17_024213| [-0.05616  0.24219 -0.02853]
21Feb17_024213| [-1.05085 -2.30259 -0.16276]
21Feb17_024213| [ 0.71087  0.14900  1.13430]
21Feb17_024213| [-2.45877 -1.20999 -1.04986]
21Feb17_024213| [-1.00480  1.36344 -0.13998]
21Feb17_024213| [ 1.83140 -0.91532  0.07616]
21Feb17_024213| [-0.60404 -2.05184  0.76948]
21Feb17_024213| [ 0.52617  0.76042 -1.76746]
21Feb17_024213| [-0.22134  0.17324  0.99530]
21Feb17_024213| [-0.36427  1.34655  0.02110]
21Feb17_024213| [-0.93125 -0.33620 -0.25012]
21Feb17_024213| [-2.76428  0.14487  0.48096]
21Feb17_024213| [-0.10518  0.35052  1.71840]
21Feb17_024213| [-1.27998  1.12568  1.26523]
21Feb17_024213| [-0.60698  1.53230 -0.60824]
21Feb17_024213| [ 0.02898  2.98718 -0.59153]
21Feb17_024213| [ 0.17588 -0.00449  0.50797]
21Feb17_024213| [-1.42674 -0.54967 -0.21310]
21Feb17_024213| [ 1.03196  1.18733  0.36755]
21Feb17_024213| [ 1.04748 -1.47444 -0.08469]
21Feb17_024213| [ 0.49410  0.38745  0.68469]
21Feb17_024213| [-0.62880  0.73245  0.19964]]
21Feb17_024213|-- Bias --
21Feb17_024213|[-0.18798  0.64571 -0.23142]
21Feb17_024213|Layer 1:
21Feb17_024213|-- Config --
21Feb17_024213|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024213|-- Weights --
21Feb17_024213|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_024213| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_024213| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_024213|-- Bias --
21Feb17_024213|[0.60477 0.03773 0.26452 0.12222]
21Feb17_024213|Layer 2:
21Feb17_024213|-- Config --
21Feb17_024213|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024213|-- Weights --
21Feb17_024213|[[ 0.67920  0.12119]
21Feb17_024213| [ 0.44836  0.02916]
21Feb17_024213| [ 0.68939  0.31516]
21Feb17_024213| [-0.58995 -0.05861]]
21Feb17_024213|-- Bias --
21Feb17_024213|[ 0.59649 -0.08079]
21Feb17_024213|Layer 3:
21Feb17_024213|-- Config --
21Feb17_024213|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024213|-- Weights --
21Feb17_024213|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_024213| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_024213|-- Bias --
21Feb17_024213|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_024213|Layer 4:
21Feb17_024213|-- Config --
21Feb17_024213|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024213|-- Weights --
21Feb17_024213|[[-0.03514 -1.04833]
21Feb17_024213| [ 1.25238  0.62094]
21Feb17_024213| [ 0.99203  0.37406]
21Feb17_024213| [ 0.49902  0.67158]
21Feb17_024213| [-1.35709  0.38335]]
21Feb17_024213|-- Bias --
21Feb17_024213|[0.31435 0.36299]
21Feb17_024213|Predicting the validation and test data with the Best final individual.
21Feb17_024220| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_024220|-----------  ------------------  --------------------  ----------
21Feb17_024220|Validation         21.57                  56            0.82113
21Feb17_024220|   Test            31.19                  56            0.83333
21Feb17_024220|-------------------- Test #5 --------------------
21Feb17_024220|Best final individual weights
21Feb17_024220|Individual:
21Feb17_024220|-- Constant hidden layers --
21Feb17_024220|False
21Feb17_024220|Layer 0:
21Feb17_024220|-- Config --
21Feb17_024220|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024220|-- Weights --
21Feb17_024220|[[-0.73212  1.32861  0.10200]
21Feb17_024220| [ 1.48746 -2.97273 -0.42944]
21Feb17_024220| [ 0.53095 -1.50623  0.79224]
21Feb17_024220| [-1.07292 -0.83175 -0.90105]
21Feb17_024220| [-0.48696 -0.89325  0.27226]
21Feb17_024220| [-3.02511  0.34155 -0.03837]
21Feb17_024220| [-0.76747  0.57140 -0.46892]
21Feb17_024220| [-0.07581  0.14713  0.85910]
21Feb17_024220| [-1.37488  0.52170 -0.36205]
21Feb17_024220| [ 1.60981 -0.08727 -0.11267]
21Feb17_024220| [ 0.50986  1.58916 -0.35287]
21Feb17_024220| [-0.34599  1.27113 -0.16393]
21Feb17_024220| [ 1.29203  1.19467  0.37695]
21Feb17_024220| [ 0.58704  0.06328 -0.24240]
21Feb17_024220| [-0.93888 -0.89760  0.57087]
21Feb17_024220| [ 0.99159 -0.66387  0.35177]
21Feb17_024220| [-0.67119  1.06910 -0.12512]
21Feb17_024220| [-0.91534  1.23744 -0.40465]
21Feb17_024220| [ 1.39278  0.08069  0.23328]
21Feb17_024220| [ 0.09880  0.57603 -0.96101]
21Feb17_024220| [ 0.01621 -0.13343 -0.27624]
21Feb17_024220| [-1.28286 -2.28909  0.37931]
21Feb17_024220| [-0.28370  0.09336  0.01547]
21Feb17_024220| [-0.51894  1.84280 -0.25906]
21Feb17_024220| [-0.83075 -0.04508  0.12107]
21Feb17_024220| [ 0.37343  1.18436 -0.07358]
21Feb17_024220| [-2.38657 -0.35191  0.01962]
21Feb17_024220| [ 0.95757 -0.91760 -0.08971]
21Feb17_024220| [ 0.38792 -0.01880  0.69717]
21Feb17_024220| [ 1.66877 -0.58078 -1.21129]
21Feb17_024220| [-0.50943  0.59080  0.30856]
21Feb17_024220| [ 0.30163  1.11518  0.98185]
21Feb17_024220| [-0.73226  0.32281 -0.66712]
21Feb17_024220| [-0.62054 -2.21049  1.40981]
21Feb17_024220| [ 1.23185 -0.58090  0.35844]
21Feb17_024220| [-0.05616  0.24219 -0.02853]
21Feb17_024220| [-1.05085 -2.30259 -0.16276]
21Feb17_024220| [ 0.71087  0.14900  1.13430]
21Feb17_024220| [-2.45877 -1.20999 -1.04986]
21Feb17_024220| [-1.00480  1.36344 -0.13998]
21Feb17_024220| [ 1.83140 -0.91532  0.07616]
21Feb17_024220| [-0.60404 -2.05184  0.76948]
21Feb17_024220| [ 0.52617  0.76042 -1.76746]
21Feb17_024220| [-0.22134  0.17324  0.99530]
21Feb17_024220| [-0.36427  1.34655  0.02110]
21Feb17_024220| [-0.93125 -0.33620 -0.25012]
21Feb17_024220| [-2.76428  0.14487  0.48096]
21Feb17_024220| [-0.10518  0.35052  1.71840]
21Feb17_024220| [-1.27998  1.12568  1.26523]
21Feb17_024220| [-0.60698  1.53230 -0.60824]
21Feb17_024220| [ 0.02898  2.98718 -0.59153]
21Feb17_024220| [ 0.17588 -0.00449  0.50797]
21Feb17_024220| [-1.42674 -0.54967 -0.21310]
21Feb17_024220| [ 1.03196  1.18733  0.36755]
21Feb17_024220| [ 1.04748 -1.47444 -0.08469]
21Feb17_024220| [ 0.49410  0.38745  0.68469]
21Feb17_024220| [-0.62880  0.73245  0.19964]]
21Feb17_024220|-- Bias --
21Feb17_024220|[-0.18798  0.64571 -0.23142]
21Feb17_024220|Layer 1:
21Feb17_024220|-- Config --
21Feb17_024220|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024220|-- Weights --
21Feb17_024220|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_024220| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_024220| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_024220|-- Bias --
21Feb17_024220|[0.60477 0.03773 0.26452 0.12222]
21Feb17_024220|Layer 2:
21Feb17_024220|-- Config --
21Feb17_024220|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024220|-- Weights --
21Feb17_024220|[[ 0.67920  0.12119]
21Feb17_024220| [ 0.44836  0.02916]
21Feb17_024220| [ 0.68939  0.31516]
21Feb17_024220| [-0.58995 -0.05861]]
21Feb17_024220|-- Bias --
21Feb17_024220|[ 0.59649 -0.08079]
21Feb17_024220|Layer 3:
21Feb17_024220|-- Config --
21Feb17_024220|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024220|-- Weights --
21Feb17_024220|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_024220| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_024220|-- Bias --
21Feb17_024220|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_024220|Layer 4:
21Feb17_024220|-- Config --
21Feb17_024220|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024220|-- Weights --
21Feb17_024220|[[-0.03514 -1.04833]
21Feb17_024220| [ 1.25238  0.62094]
21Feb17_024220| [ 0.99203  0.37406]
21Feb17_024220| [ 0.49902  0.67158]
21Feb17_024220| [-1.35709  0.38335]]
21Feb17_024220|-- Bias --
21Feb17_024220|[0.31435 0.36299]
21Feb17_024220|Predicting the validation and test data with the Best final individual.
21Feb17_024228| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_024228|-----------  ------------------  --------------------  ----------
21Feb17_024228|Validation         23.22                  56            0.86009
21Feb17_024228|   Test            26.15                  56            0.85097
21Feb17_024228|-------------------- Test #6 --------------------
21Feb17_024228|Best final individual weights
21Feb17_024228|Individual:
21Feb17_024228|-- Constant hidden layers --
21Feb17_024228|False
21Feb17_024228|Layer 0:
21Feb17_024228|-- Config --
21Feb17_024228|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024228|-- Weights --
21Feb17_024228|[[-0.73212  1.32861  0.10200]
21Feb17_024228| [ 1.48746 -2.97273 -0.42944]
21Feb17_024228| [ 0.53095 -1.50623  0.79224]
21Feb17_024228| [-1.07292 -0.83175 -0.90105]
21Feb17_024228| [-0.48696 -0.89325  0.27226]
21Feb17_024228| [-3.02511  0.34155 -0.03837]
21Feb17_024228| [-0.76747  0.57140 -0.46892]
21Feb17_024228| [-0.07581  0.14713  0.85910]
21Feb17_024228| [-1.37488  0.52170 -0.36205]
21Feb17_024228| [ 1.60981 -0.08727 -0.11267]
21Feb17_024228| [ 0.50986  1.58916 -0.35287]
21Feb17_024228| [-0.34599  1.27113 -0.16393]
21Feb17_024228| [ 1.29203  1.19467  0.37695]
21Feb17_024228| [ 0.58704  0.06328 -0.24240]
21Feb17_024228| [-0.93888 -0.89760  0.57087]
21Feb17_024228| [ 0.99159 -0.66387  0.35177]
21Feb17_024228| [-0.67119  1.06910 -0.12512]
21Feb17_024228| [-0.91534  1.23744 -0.40465]
21Feb17_024228| [ 1.39278  0.08069  0.23328]
21Feb17_024228| [ 0.09880  0.57603 -0.96101]
21Feb17_024228| [ 0.01621 -0.13343 -0.27624]
21Feb17_024228| [-1.28286 -2.28909  0.37931]
21Feb17_024228| [-0.28370  0.09336  0.01547]
21Feb17_024228| [-0.51894  1.84280 -0.25906]
21Feb17_024228| [-0.83075 -0.04508  0.12107]
21Feb17_024228| [ 0.37343  1.18436 -0.07358]
21Feb17_024228| [-2.38657 -0.35191  0.01962]
21Feb17_024228| [ 0.95757 -0.91760 -0.08971]
21Feb17_024228| [ 0.38792 -0.01880  0.69717]
21Feb17_024228| [ 1.66877 -0.58078 -1.21129]
21Feb17_024228| [-0.50943  0.59080  0.30856]
21Feb17_024228| [ 0.30163  1.11518  0.98185]
21Feb17_024228| [-0.73226  0.32281 -0.66712]
21Feb17_024228| [-0.62054 -2.21049  1.40981]
21Feb17_024228| [ 1.23185 -0.58090  0.35844]
21Feb17_024228| [-0.05616  0.24219 -0.02853]
21Feb17_024228| [-1.05085 -2.30259 -0.16276]
21Feb17_024228| [ 0.71087  0.14900  1.13430]
21Feb17_024228| [-2.45877 -1.20999 -1.04986]
21Feb17_024228| [-1.00480  1.36344 -0.13998]
21Feb17_024228| [ 1.83140 -0.91532  0.07616]
21Feb17_024228| [-0.60404 -2.05184  0.76948]
21Feb17_024228| [ 0.52617  0.76042 -1.76746]
21Feb17_024228| [-0.22134  0.17324  0.99530]
21Feb17_024228| [-0.36427  1.34655  0.02110]
21Feb17_024228| [-0.93125 -0.33620 -0.25012]
21Feb17_024228| [-2.76428  0.14487  0.48096]
21Feb17_024228| [-0.10518  0.35052  1.71840]
21Feb17_024228| [-1.27998  1.12568  1.26523]
21Feb17_024228| [-0.60698  1.53230 -0.60824]
21Feb17_024228| [ 0.02898  2.98718 -0.59153]
21Feb17_024228| [ 0.17588 -0.00449  0.50797]
21Feb17_024228| [-1.42674 -0.54967 -0.21310]
21Feb17_024228| [ 1.03196  1.18733  0.36755]
21Feb17_024228| [ 1.04748 -1.47444 -0.08469]
21Feb17_024228| [ 0.49410  0.38745  0.68469]
21Feb17_024228| [-0.62880  0.73245  0.19964]]
21Feb17_024228|-- Bias --
21Feb17_024228|[-0.18798  0.64571 -0.23142]
21Feb17_024228|Layer 1:
21Feb17_024228|-- Config --
21Feb17_024228|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024228|-- Weights --
21Feb17_024228|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_024228| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_024228| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_024228|-- Bias --
21Feb17_024228|[0.60477 0.03773 0.26452 0.12222]
21Feb17_024228|Layer 2:
21Feb17_024228|-- Config --
21Feb17_024228|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024228|-- Weights --
21Feb17_024228|[[ 0.67920  0.12119]
21Feb17_024228| [ 0.44836  0.02916]
21Feb17_024228| [ 0.68939  0.31516]
21Feb17_024228| [-0.58995 -0.05861]]
21Feb17_024228|-- Bias --
21Feb17_024228|[ 0.59649 -0.08079]
21Feb17_024228|Layer 3:
21Feb17_024228|-- Config --
21Feb17_024228|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024228|-- Weights --
21Feb17_024228|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_024228| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_024228|-- Bias --
21Feb17_024228|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_024228|Layer 4:
21Feb17_024228|-- Config --
21Feb17_024228|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024228|-- Weights --
21Feb17_024228|[[-0.03514 -1.04833]
21Feb17_024228| [ 1.25238  0.62094]
21Feb17_024228| [ 0.99203  0.37406]
21Feb17_024228| [ 0.49902  0.67158]
21Feb17_024228| [-1.35709  0.38335]]
21Feb17_024228|-- Bias --
21Feb17_024228|[0.31435 0.36299]
21Feb17_024228|Predicting the validation and test data with the Best final individual.
21Feb17_024236| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_024236|-----------  ------------------  --------------------  ----------
21Feb17_024236|Validation         22.78                  56            0.83496
21Feb17_024236|   Test            21.11                  56            0.79855
21Feb17_024236|-------------------- Test #7 --------------------
21Feb17_024236|Best final individual weights
21Feb17_024236|Individual:
21Feb17_024236|-- Constant hidden layers --
21Feb17_024236|False
21Feb17_024236|Layer 0:
21Feb17_024236|-- Config --
21Feb17_024236|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024236|-- Weights --
21Feb17_024236|[[-0.73212  1.32861  0.10200]
21Feb17_024236| [ 1.48746 -2.97273 -0.42944]
21Feb17_024236| [ 0.53095 -1.50623  0.79224]
21Feb17_024236| [-1.07292 -0.83175 -0.90105]
21Feb17_024236| [-0.48696 -0.89325  0.27226]
21Feb17_024236| [-3.02511  0.34155 -0.03837]
21Feb17_024236| [-0.76747  0.57140 -0.46892]
21Feb17_024236| [-0.07581  0.14713  0.85910]
21Feb17_024236| [-1.37488  0.52170 -0.36205]
21Feb17_024236| [ 1.60981 -0.08727 -0.11267]
21Feb17_024236| [ 0.50986  1.58916 -0.35287]
21Feb17_024236| [-0.34599  1.27113 -0.16393]
21Feb17_024236| [ 1.29203  1.19467  0.37695]
21Feb17_024236| [ 0.58704  0.06328 -0.24240]
21Feb17_024236| [-0.93888 -0.89760  0.57087]
21Feb17_024236| [ 0.99159 -0.66387  0.35177]
21Feb17_024236| [-0.67119  1.06910 -0.12512]
21Feb17_024236| [-0.91534  1.23744 -0.40465]
21Feb17_024236| [ 1.39278  0.08069  0.23328]
21Feb17_024236| [ 0.09880  0.57603 -0.96101]
21Feb17_024236| [ 0.01621 -0.13343 -0.27624]
21Feb17_024236| [-1.28286 -2.28909  0.37931]
21Feb17_024236| [-0.28370  0.09336  0.01547]
21Feb17_024236| [-0.51894  1.84280 -0.25906]
21Feb17_024236| [-0.83075 -0.04508  0.12107]
21Feb17_024236| [ 0.37343  1.18436 -0.07358]
21Feb17_024236| [-2.38657 -0.35191  0.01962]
21Feb17_024236| [ 0.95757 -0.91760 -0.08971]
21Feb17_024236| [ 0.38792 -0.01880  0.69717]
21Feb17_024236| [ 1.66877 -0.58078 -1.21129]
21Feb17_024236| [-0.50943  0.59080  0.30856]
21Feb17_024236| [ 0.30163  1.11518  0.98185]
21Feb17_024236| [-0.73226  0.32281 -0.66712]
21Feb17_024236| [-0.62054 -2.21049  1.40981]
21Feb17_024236| [ 1.23185 -0.58090  0.35844]
21Feb17_024236| [-0.05616  0.24219 -0.02853]
21Feb17_024236| [-1.05085 -2.30259 -0.16276]
21Feb17_024236| [ 0.71087  0.14900  1.13430]
21Feb17_024236| [-2.45877 -1.20999 -1.04986]
21Feb17_024236| [-1.00480  1.36344 -0.13998]
21Feb17_024236| [ 1.83140 -0.91532  0.07616]
21Feb17_024236| [-0.60404 -2.05184  0.76948]
21Feb17_024236| [ 0.52617  0.76042 -1.76746]
21Feb17_024236| [-0.22134  0.17324  0.99530]
21Feb17_024236| [-0.36427  1.34655  0.02110]
21Feb17_024236| [-0.93125 -0.33620 -0.25012]
21Feb17_024236| [-2.76428  0.14487  0.48096]
21Feb17_024236| [-0.10518  0.35052  1.71840]
21Feb17_024236| [-1.27998  1.12568  1.26523]
21Feb17_024236| [-0.60698  1.53230 -0.60824]
21Feb17_024236| [ 0.02898  2.98718 -0.59153]
21Feb17_024236| [ 0.17588 -0.00449  0.50797]
21Feb17_024236| [-1.42674 -0.54967 -0.21310]
21Feb17_024236| [ 1.03196  1.18733  0.36755]
21Feb17_024236| [ 1.04748 -1.47444 -0.08469]
21Feb17_024236| [ 0.49410  0.38745  0.68469]
21Feb17_024236| [-0.62880  0.73245  0.19964]]
21Feb17_024236|-- Bias --
21Feb17_024236|[-0.18798  0.64571 -0.23142]
21Feb17_024236|Layer 1:
21Feb17_024236|-- Config --
21Feb17_024236|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024236|-- Weights --
21Feb17_024236|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_024236| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_024236| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_024236|-- Bias --
21Feb17_024236|[0.60477 0.03773 0.26452 0.12222]
21Feb17_024236|Layer 2:
21Feb17_024236|-- Config --
21Feb17_024236|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024236|-- Weights --
21Feb17_024236|[[ 0.67920  0.12119]
21Feb17_024236| [ 0.44836  0.02916]
21Feb17_024236| [ 0.68939  0.31516]
21Feb17_024236| [-0.58995 -0.05861]]
21Feb17_024236|-- Bias --
21Feb17_024236|[ 0.59649 -0.08079]
21Feb17_024236|Layer 3:
21Feb17_024236|-- Config --
21Feb17_024236|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024236|-- Weights --
21Feb17_024236|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_024236| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_024236|-- Bias --
21Feb17_024236|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_024236|Layer 4:
21Feb17_024236|-- Config --
21Feb17_024236|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024236|-- Weights --
21Feb17_024236|[[-0.03514 -1.04833]
21Feb17_024236| [ 1.25238  0.62094]
21Feb17_024236| [ 0.99203  0.37406]
21Feb17_024236| [ 0.49902  0.67158]
21Feb17_024236| [-1.35709  0.38335]]
21Feb17_024236|-- Bias --
21Feb17_024236|[0.31435 0.36299]
21Feb17_024236|Predicting the validation and test data with the Best final individual.
21Feb17_024244| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_024244|-----------  ------------------  --------------------  ----------
21Feb17_024244|Validation         28.96                  56            0.48780
21Feb17_024244|   Test            25.46                  56            0.49431
21Feb17_024244|-------------------- Test #8 --------------------
21Feb17_024244|Best final individual weights
21Feb17_024244|Individual:
21Feb17_024244|-- Constant hidden layers --
21Feb17_024244|False
21Feb17_024244|Layer 0:
21Feb17_024244|-- Config --
21Feb17_024244|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024244|-- Weights --
21Feb17_024244|[[-0.73212  1.32861  0.10200]
21Feb17_024244| [ 1.48746 -2.97273 -0.42944]
21Feb17_024244| [ 0.53095 -1.50623  0.79224]
21Feb17_024244| [-1.07292 -0.83175 -0.90105]
21Feb17_024244| [-0.48696 -0.89325  0.27226]
21Feb17_024244| [-3.02511  0.34155 -0.03837]
21Feb17_024244| [-0.76747  0.57140 -0.46892]
21Feb17_024244| [-0.07581  0.14713  0.85910]
21Feb17_024244| [-1.37488  0.52170 -0.36205]
21Feb17_024244| [ 1.60981 -0.08727 -0.11267]
21Feb17_024244| [ 0.50986  1.58916 -0.35287]
21Feb17_024244| [-0.34599  1.27113 -0.16393]
21Feb17_024244| [ 1.29203  1.19467  0.37695]
21Feb17_024244| [ 0.58704  0.06328 -0.24240]
21Feb17_024244| [-0.93888 -0.89760  0.57087]
21Feb17_024244| [ 0.99159 -0.66387  0.35177]
21Feb17_024244| [-0.67119  1.06910 -0.12512]
21Feb17_024244| [-0.91534  1.23744 -0.40465]
21Feb17_024244| [ 1.39278  0.08069  0.23328]
21Feb17_024244| [ 0.09880  0.57603 -0.96101]
21Feb17_024244| [ 0.01621 -0.13343 -0.27624]
21Feb17_024244| [-1.28286 -2.28909  0.37931]
21Feb17_024244| [-0.28370  0.09336  0.01547]
21Feb17_024244| [-0.51894  1.84280 -0.25906]
21Feb17_024244| [-0.83075 -0.04508  0.12107]
21Feb17_024244| [ 0.37343  1.18436 -0.07358]
21Feb17_024244| [-2.38657 -0.35191  0.01962]
21Feb17_024244| [ 0.95757 -0.91760 -0.08971]
21Feb17_024244| [ 0.38792 -0.01880  0.69717]
21Feb17_024244| [ 1.66877 -0.58078 -1.21129]
21Feb17_024244| [-0.50943  0.59080  0.30856]
21Feb17_024244| [ 0.30163  1.11518  0.98185]
21Feb17_024244| [-0.73226  0.32281 -0.66712]
21Feb17_024244| [-0.62054 -2.21049  1.40981]
21Feb17_024244| [ 1.23185 -0.58090  0.35844]
21Feb17_024244| [-0.05616  0.24219 -0.02853]
21Feb17_024244| [-1.05085 -2.30259 -0.16276]
21Feb17_024244| [ 0.71087  0.14900  1.13430]
21Feb17_024244| [-2.45877 -1.20999 -1.04986]
21Feb17_024244| [-1.00480  1.36344 -0.13998]
21Feb17_024244| [ 1.83140 -0.91532  0.07616]
21Feb17_024244| [-0.60404 -2.05184  0.76948]
21Feb17_024244| [ 0.52617  0.76042 -1.76746]
21Feb17_024244| [-0.22134  0.17324  0.99530]
21Feb17_024244| [-0.36427  1.34655  0.02110]
21Feb17_024244| [-0.93125 -0.33620 -0.25012]
21Feb17_024244| [-2.76428  0.14487  0.48096]
21Feb17_024244| [-0.10518  0.35052  1.71840]
21Feb17_024244| [-1.27998  1.12568  1.26523]
21Feb17_024244| [-0.60698  1.53230 -0.60824]
21Feb17_024244| [ 0.02898  2.98718 -0.59153]
21Feb17_024244| [ 0.17588 -0.00449  0.50797]
21Feb17_024244| [-1.42674 -0.54967 -0.21310]
21Feb17_024244| [ 1.03196  1.18733  0.36755]
21Feb17_024244| [ 1.04748 -1.47444 -0.08469]
21Feb17_024244| [ 0.49410  0.38745  0.68469]
21Feb17_024244| [-0.62880  0.73245  0.19964]]
21Feb17_024244|-- Bias --
21Feb17_024244|[-0.18798  0.64571 -0.23142]
21Feb17_024244|Layer 1:
21Feb17_024244|-- Config --
21Feb17_024244|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024244|-- Weights --
21Feb17_024244|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_024244| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_024244| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_024244|-- Bias --
21Feb17_024244|[0.60477 0.03773 0.26452 0.12222]
21Feb17_024244|Layer 2:
21Feb17_024244|-- Config --
21Feb17_024244|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024244|-- Weights --
21Feb17_024244|[[ 0.67920  0.12119]
21Feb17_024244| [ 0.44836  0.02916]
21Feb17_024244| [ 0.68939  0.31516]
21Feb17_024244| [-0.58995 -0.05861]]
21Feb17_024244|-- Bias --
21Feb17_024244|[ 0.59649 -0.08079]
21Feb17_024244|Layer 3:
21Feb17_024244|-- Config --
21Feb17_024244|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024244|-- Weights --
21Feb17_024244|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_024244| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_024244|-- Bias --
21Feb17_024244|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_024244|Layer 4:
21Feb17_024244|-- Config --
21Feb17_024244|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024244|-- Weights --
21Feb17_024244|[[-0.03514 -1.04833]
21Feb17_024244| [ 1.25238  0.62094]
21Feb17_024244| [ 0.99203  0.37406]
21Feb17_024244| [ 0.49902  0.67158]
21Feb17_024244| [-1.35709  0.38335]]
21Feb17_024244|-- Bias --
21Feb17_024244|[0.31435 0.36299]
21Feb17_024244|Predicting the validation and test data with the Best final individual.
21Feb17_024251| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_024251|-----------  ------------------  --------------------  ----------
21Feb17_024251|Validation         21.30                  56            0.82476
21Feb17_024251|   Test            21.81                  56            0.83186
21Feb17_024251|-------------------- Test #9 --------------------
21Feb17_024251|Best final individual weights
21Feb17_024251|Individual:
21Feb17_024251|-- Constant hidden layers --
21Feb17_024251|False
21Feb17_024251|Layer 0:
21Feb17_024251|-- Config --
21Feb17_024251|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024251|-- Weights --
21Feb17_024251|[[-0.73212  1.32861  0.10200]
21Feb17_024251| [ 1.48746 -2.97273 -0.42944]
21Feb17_024251| [ 0.53095 -1.50623  0.79224]
21Feb17_024251| [-1.07292 -0.83175 -0.90105]
21Feb17_024251| [-0.48696 -0.89325  0.27226]
21Feb17_024251| [-3.02511  0.34155 -0.03837]
21Feb17_024251| [-0.76747  0.57140 -0.46892]
21Feb17_024251| [-0.07581  0.14713  0.85910]
21Feb17_024251| [-1.37488  0.52170 -0.36205]
21Feb17_024251| [ 1.60981 -0.08727 -0.11267]
21Feb17_024251| [ 0.50986  1.58916 -0.35287]
21Feb17_024251| [-0.34599  1.27113 -0.16393]
21Feb17_024251| [ 1.29203  1.19467  0.37695]
21Feb17_024251| [ 0.58704  0.06328 -0.24240]
21Feb17_024251| [-0.93888 -0.89760  0.57087]
21Feb17_024251| [ 0.99159 -0.66387  0.35177]
21Feb17_024251| [-0.67119  1.06910 -0.12512]
21Feb17_024251| [-0.91534  1.23744 -0.40465]
21Feb17_024251| [ 1.39278  0.08069  0.23328]
21Feb17_024251| [ 0.09880  0.57603 -0.96101]
21Feb17_024251| [ 0.01621 -0.13343 -0.27624]
21Feb17_024251| [-1.28286 -2.28909  0.37931]
21Feb17_024251| [-0.28370  0.09336  0.01547]
21Feb17_024251| [-0.51894  1.84280 -0.25906]
21Feb17_024251| [-0.83075 -0.04508  0.12107]
21Feb17_024251| [ 0.37343  1.18436 -0.07358]
21Feb17_024251| [-2.38657 -0.35191  0.01962]
21Feb17_024251| [ 0.95757 -0.91760 -0.08971]
21Feb17_024251| [ 0.38792 -0.01880  0.69717]
21Feb17_024251| [ 1.66877 -0.58078 -1.21129]
21Feb17_024251| [-0.50943  0.59080  0.30856]
21Feb17_024251| [ 0.30163  1.11518  0.98185]
21Feb17_024251| [-0.73226  0.32281 -0.66712]
21Feb17_024251| [-0.62054 -2.21049  1.40981]
21Feb17_024251| [ 1.23185 -0.58090  0.35844]
21Feb17_024251| [-0.05616  0.24219 -0.02853]
21Feb17_024251| [-1.05085 -2.30259 -0.16276]
21Feb17_024251| [ 0.71087  0.14900  1.13430]
21Feb17_024251| [-2.45877 -1.20999 -1.04986]
21Feb17_024251| [-1.00480  1.36344 -0.13998]
21Feb17_024251| [ 1.83140 -0.91532  0.07616]
21Feb17_024251| [-0.60404 -2.05184  0.76948]
21Feb17_024251| [ 0.52617  0.76042 -1.76746]
21Feb17_024251| [-0.22134  0.17324  0.99530]
21Feb17_024251| [-0.36427  1.34655  0.02110]
21Feb17_024251| [-0.93125 -0.33620 -0.25012]
21Feb17_024251| [-2.76428  0.14487  0.48096]
21Feb17_024251| [-0.10518  0.35052  1.71840]
21Feb17_024251| [-1.27998  1.12568  1.26523]
21Feb17_024251| [-0.60698  1.53230 -0.60824]
21Feb17_024251| [ 0.02898  2.98718 -0.59153]
21Feb17_024251| [ 0.17588 -0.00449  0.50797]
21Feb17_024251| [-1.42674 -0.54967 -0.21310]
21Feb17_024251| [ 1.03196  1.18733  0.36755]
21Feb17_024251| [ 1.04748 -1.47444 -0.08469]
21Feb17_024251| [ 0.49410  0.38745  0.68469]
21Feb17_024251| [-0.62880  0.73245  0.19964]]
21Feb17_024251|-- Bias --
21Feb17_024251|[-0.18798  0.64571 -0.23142]
21Feb17_024251|Layer 1:
21Feb17_024251|-- Config --
21Feb17_024251|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024251|-- Weights --
21Feb17_024251|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_024251| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_024251| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_024251|-- Bias --
21Feb17_024251|[0.60477 0.03773 0.26452 0.12222]
21Feb17_024251|Layer 2:
21Feb17_024251|-- Config --
21Feb17_024251|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024251|-- Weights --
21Feb17_024251|[[ 0.67920  0.12119]
21Feb17_024251| [ 0.44836  0.02916]
21Feb17_024251| [ 0.68939  0.31516]
21Feb17_024251| [-0.58995 -0.05861]]
21Feb17_024251|-- Bias --
21Feb17_024251|[ 0.59649 -0.08079]
21Feb17_024251|Layer 3:
21Feb17_024251|-- Config --
21Feb17_024251|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024251|-- Weights --
21Feb17_024251|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_024251| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_024251|-- Bias --
21Feb17_024251|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_024251|Layer 4:
21Feb17_024251|-- Config --
21Feb17_024251|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024251|-- Weights --
21Feb17_024251|[[-0.03514 -1.04833]
21Feb17_024251| [ 1.25238  0.62094]
21Feb17_024251| [ 0.99203  0.37406]
21Feb17_024251| [ 0.49902  0.67158]
21Feb17_024251| [-1.35709  0.38335]]
21Feb17_024251|-- Bias --
21Feb17_024251|[0.31435 0.36299]
21Feb17_024251|Predicting the validation and test data with the Best final individual.
21Feb17_024259| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_024259|-----------  ------------------  --------------------  ----------
21Feb17_024259|Validation         26.43                  56            0.71922
21Feb17_024259|   Test            29.54                  56            0.67444
21Feb17_024259|-------------------- Test #10 --------------------
21Feb17_024259|Best final individual weights
21Feb17_024259|Individual:
21Feb17_024259|-- Constant hidden layers --
21Feb17_024259|False
21Feb17_024259|Layer 0:
21Feb17_024259|-- Config --
21Feb17_024259|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024259|-- Weights --
21Feb17_024259|[[-0.73212  1.32861  0.10200]
21Feb17_024259| [ 1.48746 -2.97273 -0.42944]
21Feb17_024259| [ 0.53095 -1.50623  0.79224]
21Feb17_024259| [-1.07292 -0.83175 -0.90105]
21Feb17_024259| [-0.48696 -0.89325  0.27226]
21Feb17_024259| [-3.02511  0.34155 -0.03837]
21Feb17_024259| [-0.76747  0.57140 -0.46892]
21Feb17_024259| [-0.07581  0.14713  0.85910]
21Feb17_024259| [-1.37488  0.52170 -0.36205]
21Feb17_024259| [ 1.60981 -0.08727 -0.11267]
21Feb17_024259| [ 0.50986  1.58916 -0.35287]
21Feb17_024259| [-0.34599  1.27113 -0.16393]
21Feb17_024259| [ 1.29203  1.19467  0.37695]
21Feb17_024259| [ 0.58704  0.06328 -0.24240]
21Feb17_024259| [-0.93888 -0.89760  0.57087]
21Feb17_024259| [ 0.99159 -0.66387  0.35177]
21Feb17_024259| [-0.67119  1.06910 -0.12512]
21Feb17_024259| [-0.91534  1.23744 -0.40465]
21Feb17_024259| [ 1.39278  0.08069  0.23328]
21Feb17_024259| [ 0.09880  0.57603 -0.96101]
21Feb17_024259| [ 0.01621 -0.13343 -0.27624]
21Feb17_024259| [-1.28286 -2.28909  0.37931]
21Feb17_024259| [-0.28370  0.09336  0.01547]
21Feb17_024259| [-0.51894  1.84280 -0.25906]
21Feb17_024259| [-0.83075 -0.04508  0.12107]
21Feb17_024259| [ 0.37343  1.18436 -0.07358]
21Feb17_024259| [-2.38657 -0.35191  0.01962]
21Feb17_024259| [ 0.95757 -0.91760 -0.08971]
21Feb17_024259| [ 0.38792 -0.01880  0.69717]
21Feb17_024259| [ 1.66877 -0.58078 -1.21129]
21Feb17_024259| [-0.50943  0.59080  0.30856]
21Feb17_024259| [ 0.30163  1.11518  0.98185]
21Feb17_024259| [-0.73226  0.32281 -0.66712]
21Feb17_024259| [-0.62054 -2.21049  1.40981]
21Feb17_024259| [ 1.23185 -0.58090  0.35844]
21Feb17_024259| [-0.05616  0.24219 -0.02853]
21Feb17_024259| [-1.05085 -2.30259 -0.16276]
21Feb17_024259| [ 0.71087  0.14900  1.13430]
21Feb17_024259| [-2.45877 -1.20999 -1.04986]
21Feb17_024259| [-1.00480  1.36344 -0.13998]
21Feb17_024259| [ 1.83140 -0.91532  0.07616]
21Feb17_024259| [-0.60404 -2.05184  0.76948]
21Feb17_024259| [ 0.52617  0.76042 -1.76746]
21Feb17_024259| [-0.22134  0.17324  0.99530]
21Feb17_024259| [-0.36427  1.34655  0.02110]
21Feb17_024259| [-0.93125 -0.33620 -0.25012]
21Feb17_024259| [-2.76428  0.14487  0.48096]
21Feb17_024259| [-0.10518  0.35052  1.71840]
21Feb17_024259| [-1.27998  1.12568  1.26523]
21Feb17_024259| [-0.60698  1.53230 -0.60824]
21Feb17_024259| [ 0.02898  2.98718 -0.59153]
21Feb17_024259| [ 0.17588 -0.00449  0.50797]
21Feb17_024259| [-1.42674 -0.54967 -0.21310]
21Feb17_024259| [ 1.03196  1.18733  0.36755]
21Feb17_024259| [ 1.04748 -1.47444 -0.08469]
21Feb17_024259| [ 0.49410  0.38745  0.68469]
21Feb17_024259| [-0.62880  0.73245  0.19964]]
21Feb17_024259|-- Bias --
21Feb17_024259|[-0.18798  0.64571 -0.23142]
21Feb17_024259|Layer 1:
21Feb17_024259|-- Config --
21Feb17_024259|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024259|-- Weights --
21Feb17_024259|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_024259| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_024259| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_024259|-- Bias --
21Feb17_024259|[0.60477 0.03773 0.26452 0.12222]
21Feb17_024259|Layer 2:
21Feb17_024259|-- Config --
21Feb17_024259|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024259|-- Weights --
21Feb17_024259|[[ 0.67920  0.12119]
21Feb17_024259| [ 0.44836  0.02916]
21Feb17_024259| [ 0.68939  0.31516]
21Feb17_024259| [-0.58995 -0.05861]]
21Feb17_024259|-- Bias --
21Feb17_024259|[ 0.59649 -0.08079]
21Feb17_024259|Layer 3:
21Feb17_024259|-- Config --
21Feb17_024259|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024259|-- Weights --
21Feb17_024259|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_024259| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_024259|-- Bias --
21Feb17_024259|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_024259|Layer 4:
21Feb17_024259|-- Config --
21Feb17_024259|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024259|-- Weights --
21Feb17_024259|[[-0.03514 -1.04833]
21Feb17_024259| [ 1.25238  0.62094]
21Feb17_024259| [ 0.99203  0.37406]
21Feb17_024259| [ 0.49902  0.67158]
21Feb17_024259| [-1.35709  0.38335]]
21Feb17_024259|-- Bias --
21Feb17_024259|[0.31435 0.36299]
21Feb17_024259|Predicting the validation and test data with the Best final individual.
21Feb17_024306| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_024306|-----------  ------------------  --------------------  ----------
21Feb17_024306|Validation         23.65                  56            0.85845
21Feb17_024306|   Test            26.67                  56            0.71298
21Feb17_024306|-------------------- Test #11 --------------------
21Feb17_024306|Best final individual weights
21Feb17_024306|Individual:
21Feb17_024306|-- Constant hidden layers --
21Feb17_024306|False
21Feb17_024306|Layer 0:
21Feb17_024306|-- Config --
21Feb17_024306|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024306|-- Weights --
21Feb17_024306|[[-0.73212  1.32861  0.10200]
21Feb17_024306| [ 1.48746 -2.97273 -0.42944]
21Feb17_024306| [ 0.53095 -1.50623  0.79224]
21Feb17_024306| [-1.07292 -0.83175 -0.90105]
21Feb17_024306| [-0.48696 -0.89325  0.27226]
21Feb17_024306| [-3.02511  0.34155 -0.03837]
21Feb17_024306| [-0.76747  0.57140 -0.46892]
21Feb17_024306| [-0.07581  0.14713  0.85910]
21Feb17_024306| [-1.37488  0.52170 -0.36205]
21Feb17_024306| [ 1.60981 -0.08727 -0.11267]
21Feb17_024306| [ 0.50986  1.58916 -0.35287]
21Feb17_024306| [-0.34599  1.27113 -0.16393]
21Feb17_024306| [ 1.29203  1.19467  0.37695]
21Feb17_024306| [ 0.58704  0.06328 -0.24240]
21Feb17_024306| [-0.93888 -0.89760  0.57087]
21Feb17_024306| [ 0.99159 -0.66387  0.35177]
21Feb17_024306| [-0.67119  1.06910 -0.12512]
21Feb17_024306| [-0.91534  1.23744 -0.40465]
21Feb17_024306| [ 1.39278  0.08069  0.23328]
21Feb17_024306| [ 0.09880  0.57603 -0.96101]
21Feb17_024306| [ 0.01621 -0.13343 -0.27624]
21Feb17_024306| [-1.28286 -2.28909  0.37931]
21Feb17_024306| [-0.28370  0.09336  0.01547]
21Feb17_024306| [-0.51894  1.84280 -0.25906]
21Feb17_024306| [-0.83075 -0.04508  0.12107]
21Feb17_024306| [ 0.37343  1.18436 -0.07358]
21Feb17_024306| [-2.38657 -0.35191  0.01962]
21Feb17_024306| [ 0.95757 -0.91760 -0.08971]
21Feb17_024306| [ 0.38792 -0.01880  0.69717]
21Feb17_024306| [ 1.66877 -0.58078 -1.21129]
21Feb17_024306| [-0.50943  0.59080  0.30856]
21Feb17_024306| [ 0.30163  1.11518  0.98185]
21Feb17_024306| [-0.73226  0.32281 -0.66712]
21Feb17_024306| [-0.62054 -2.21049  1.40981]
21Feb17_024306| [ 1.23185 -0.58090  0.35844]
21Feb17_024306| [-0.05616  0.24219 -0.02853]
21Feb17_024306| [-1.05085 -2.30259 -0.16276]
21Feb17_024306| [ 0.71087  0.14900  1.13430]
21Feb17_024306| [-2.45877 -1.20999 -1.04986]
21Feb17_024306| [-1.00480  1.36344 -0.13998]
21Feb17_024306| [ 1.83140 -0.91532  0.07616]
21Feb17_024306| [-0.60404 -2.05184  0.76948]
21Feb17_024306| [ 0.52617  0.76042 -1.76746]
21Feb17_024306| [-0.22134  0.17324  0.99530]
21Feb17_024306| [-0.36427  1.34655  0.02110]
21Feb17_024306| [-0.93125 -0.33620 -0.25012]
21Feb17_024306| [-2.76428  0.14487  0.48096]
21Feb17_024306| [-0.10518  0.35052  1.71840]
21Feb17_024306| [-1.27998  1.12568  1.26523]
21Feb17_024306| [-0.60698  1.53230 -0.60824]
21Feb17_024306| [ 0.02898  2.98718 -0.59153]
21Feb17_024306| [ 0.17588 -0.00449  0.50797]
21Feb17_024306| [-1.42674 -0.54967 -0.21310]
21Feb17_024306| [ 1.03196  1.18733  0.36755]
21Feb17_024306| [ 1.04748 -1.47444 -0.08469]
21Feb17_024306| [ 0.49410  0.38745  0.68469]
21Feb17_024306| [-0.62880  0.73245  0.19964]]
21Feb17_024306|-- Bias --
21Feb17_024306|[-0.18798  0.64571 -0.23142]
21Feb17_024306|Layer 1:
21Feb17_024306|-- Config --
21Feb17_024306|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024306|-- Weights --
21Feb17_024306|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_024306| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_024306| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_024306|-- Bias --
21Feb17_024306|[0.60477 0.03773 0.26452 0.12222]
21Feb17_024306|Layer 2:
21Feb17_024306|-- Config --
21Feb17_024306|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024306|-- Weights --
21Feb17_024306|[[ 0.67920  0.12119]
21Feb17_024306| [ 0.44836  0.02916]
21Feb17_024306| [ 0.68939  0.31516]
21Feb17_024306| [-0.58995 -0.05861]]
21Feb17_024306|-- Bias --
21Feb17_024306|[ 0.59649 -0.08079]
21Feb17_024306|Layer 3:
21Feb17_024306|-- Config --
21Feb17_024306|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024306|-- Weights --
21Feb17_024306|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_024306| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_024306|-- Bias --
21Feb17_024306|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_024306|Layer 4:
21Feb17_024306|-- Config --
21Feb17_024306|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024306|-- Weights --
21Feb17_024306|[[-0.03514 -1.04833]
21Feb17_024306| [ 1.25238  0.62094]
21Feb17_024306| [ 0.99203  0.37406]
21Feb17_024306| [ 0.49902  0.67158]
21Feb17_024306| [-1.35709  0.38335]]
21Feb17_024306|-- Bias --
21Feb17_024306|[0.31435 0.36299]
21Feb17_024306|Predicting the validation and test data with the Best final individual.
21Feb17_024314| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_024314|-----------  ------------------  --------------------  ----------
21Feb17_024314|Validation         23.48                  56            0.78306
21Feb17_024314|   Test            22.07                  56            0.85403
21Feb17_024314|-------------------- Test #12 --------------------
21Feb17_024314|Best final individual weights
21Feb17_024314|Individual:
21Feb17_024314|-- Constant hidden layers --
21Feb17_024314|False
21Feb17_024314|Layer 0:
21Feb17_024314|-- Config --
21Feb17_024314|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024314|-- Weights --
21Feb17_024314|[[-0.73212  1.32861  0.10200]
21Feb17_024314| [ 1.48746 -2.97273 -0.42944]
21Feb17_024314| [ 0.53095 -1.50623  0.79224]
21Feb17_024314| [-1.07292 -0.83175 -0.90105]
21Feb17_024314| [-0.48696 -0.89325  0.27226]
21Feb17_024314| [-3.02511  0.34155 -0.03837]
21Feb17_024314| [-0.76747  0.57140 -0.46892]
21Feb17_024314| [-0.07581  0.14713  0.85910]
21Feb17_024314| [-1.37488  0.52170 -0.36205]
21Feb17_024314| [ 1.60981 -0.08727 -0.11267]
21Feb17_024314| [ 0.50986  1.58916 -0.35287]
21Feb17_024314| [-0.34599  1.27113 -0.16393]
21Feb17_024314| [ 1.29203  1.19467  0.37695]
21Feb17_024314| [ 0.58704  0.06328 -0.24240]
21Feb17_024314| [-0.93888 -0.89760  0.57087]
21Feb17_024314| [ 0.99159 -0.66387  0.35177]
21Feb17_024314| [-0.67119  1.06910 -0.12512]
21Feb17_024314| [-0.91534  1.23744 -0.40465]
21Feb17_024314| [ 1.39278  0.08069  0.23328]
21Feb17_024314| [ 0.09880  0.57603 -0.96101]
21Feb17_024314| [ 0.01621 -0.13343 -0.27624]
21Feb17_024314| [-1.28286 -2.28909  0.37931]
21Feb17_024314| [-0.28370  0.09336  0.01547]
21Feb17_024314| [-0.51894  1.84280 -0.25906]
21Feb17_024314| [-0.83075 -0.04508  0.12107]
21Feb17_024314| [ 0.37343  1.18436 -0.07358]
21Feb17_024314| [-2.38657 -0.35191  0.01962]
21Feb17_024314| [ 0.95757 -0.91760 -0.08971]
21Feb17_024314| [ 0.38792 -0.01880  0.69717]
21Feb17_024314| [ 1.66877 -0.58078 -1.21129]
21Feb17_024314| [-0.50943  0.59080  0.30856]
21Feb17_024314| [ 0.30163  1.11518  0.98185]
21Feb17_024314| [-0.73226  0.32281 -0.66712]
21Feb17_024314| [-0.62054 -2.21049  1.40981]
21Feb17_024314| [ 1.23185 -0.58090  0.35844]
21Feb17_024314| [-0.05616  0.24219 -0.02853]
21Feb17_024314| [-1.05085 -2.30259 -0.16276]
21Feb17_024314| [ 0.71087  0.14900  1.13430]
21Feb17_024314| [-2.45877 -1.20999 -1.04986]
21Feb17_024314| [-1.00480  1.36344 -0.13998]
21Feb17_024314| [ 1.83140 -0.91532  0.07616]
21Feb17_024314| [-0.60404 -2.05184  0.76948]
21Feb17_024314| [ 0.52617  0.76042 -1.76746]
21Feb17_024314| [-0.22134  0.17324  0.99530]
21Feb17_024314| [-0.36427  1.34655  0.02110]
21Feb17_024314| [-0.93125 -0.33620 -0.25012]
21Feb17_024314| [-2.76428  0.14487  0.48096]
21Feb17_024314| [-0.10518  0.35052  1.71840]
21Feb17_024314| [-1.27998  1.12568  1.26523]
21Feb17_024314| [-0.60698  1.53230 -0.60824]
21Feb17_024314| [ 0.02898  2.98718 -0.59153]
21Feb17_024314| [ 0.17588 -0.00449  0.50797]
21Feb17_024314| [-1.42674 -0.54967 -0.21310]
21Feb17_024314| [ 1.03196  1.18733  0.36755]
21Feb17_024314| [ 1.04748 -1.47444 -0.08469]
21Feb17_024314| [ 0.49410  0.38745  0.68469]
21Feb17_024314| [-0.62880  0.73245  0.19964]]
21Feb17_024314|-- Bias --
21Feb17_024314|[-0.18798  0.64571 -0.23142]
21Feb17_024314|Layer 1:
21Feb17_024314|-- Config --
21Feb17_024314|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024314|-- Weights --
21Feb17_024314|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_024314| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_024314| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_024314|-- Bias --
21Feb17_024314|[0.60477 0.03773 0.26452 0.12222]
21Feb17_024314|Layer 2:
21Feb17_024314|-- Config --
21Feb17_024314|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024314|-- Weights --
21Feb17_024314|[[ 0.67920  0.12119]
21Feb17_024314| [ 0.44836  0.02916]
21Feb17_024314| [ 0.68939  0.31516]
21Feb17_024314| [-0.58995 -0.05861]]
21Feb17_024314|-- Bias --
21Feb17_024314|[ 0.59649 -0.08079]
21Feb17_024314|Layer 3:
21Feb17_024314|-- Config --
21Feb17_024314|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024314|-- Weights --
21Feb17_024314|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_024314| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_024314|-- Bias --
21Feb17_024314|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_024314|Layer 4:
21Feb17_024314|-- Config --
21Feb17_024314|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024314|-- Weights --
21Feb17_024314|[[-0.03514 -1.04833]
21Feb17_024314| [ 1.25238  0.62094]
21Feb17_024314| [ 0.99203  0.37406]
21Feb17_024314| [ 0.49902  0.67158]
21Feb17_024314| [-1.35709  0.38335]]
21Feb17_024314|-- Bias --
21Feb17_024314|[0.31435 0.36299]
21Feb17_024314|Predicting the validation and test data with the Best final individual.
21Feb17_024321| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_024321|-----------  ------------------  --------------------  ----------
21Feb17_024321|Validation         24.43                  56            0.85301
21Feb17_024321|   Test            37.01                  56            0.82036
21Feb17_024321|-------------------- Test #13 --------------------
21Feb17_024321|Best final individual weights
21Feb17_024321|Individual:
21Feb17_024321|-- Constant hidden layers --
21Feb17_024321|False
21Feb17_024321|Layer 0:
21Feb17_024321|-- Config --
21Feb17_024321|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024321|-- Weights --
21Feb17_024321|[[-0.73212  1.32861  0.10200]
21Feb17_024321| [ 1.48746 -2.97273 -0.42944]
21Feb17_024321| [ 0.53095 -1.50623  0.79224]
21Feb17_024321| [-1.07292 -0.83175 -0.90105]
21Feb17_024321| [-0.48696 -0.89325  0.27226]
21Feb17_024321| [-3.02511  0.34155 -0.03837]
21Feb17_024321| [-0.76747  0.57140 -0.46892]
21Feb17_024321| [-0.07581  0.14713  0.85910]
21Feb17_024321| [-1.37488  0.52170 -0.36205]
21Feb17_024321| [ 1.60981 -0.08727 -0.11267]
21Feb17_024321| [ 0.50986  1.58916 -0.35287]
21Feb17_024321| [-0.34599  1.27113 -0.16393]
21Feb17_024321| [ 1.29203  1.19467  0.37695]
21Feb17_024321| [ 0.58704  0.06328 -0.24240]
21Feb17_024321| [-0.93888 -0.89760  0.57087]
21Feb17_024321| [ 0.99159 -0.66387  0.35177]
21Feb17_024321| [-0.67119  1.06910 -0.12512]
21Feb17_024321| [-0.91534  1.23744 -0.40465]
21Feb17_024321| [ 1.39278  0.08069  0.23328]
21Feb17_024321| [ 0.09880  0.57603 -0.96101]
21Feb17_024321| [ 0.01621 -0.13343 -0.27624]
21Feb17_024321| [-1.28286 -2.28909  0.37931]
21Feb17_024321| [-0.28370  0.09336  0.01547]
21Feb17_024321| [-0.51894  1.84280 -0.25906]
21Feb17_024321| [-0.83075 -0.04508  0.12107]
21Feb17_024321| [ 0.37343  1.18436 -0.07358]
21Feb17_024321| [-2.38657 -0.35191  0.01962]
21Feb17_024321| [ 0.95757 -0.91760 -0.08971]
21Feb17_024321| [ 0.38792 -0.01880  0.69717]
21Feb17_024321| [ 1.66877 -0.58078 -1.21129]
21Feb17_024321| [-0.50943  0.59080  0.30856]
21Feb17_024321| [ 0.30163  1.11518  0.98185]
21Feb17_024321| [-0.73226  0.32281 -0.66712]
21Feb17_024321| [-0.62054 -2.21049  1.40981]
21Feb17_024321| [ 1.23185 -0.58090  0.35844]
21Feb17_024321| [-0.05616  0.24219 -0.02853]
21Feb17_024321| [-1.05085 -2.30259 -0.16276]
21Feb17_024321| [ 0.71087  0.14900  1.13430]
21Feb17_024321| [-2.45877 -1.20999 -1.04986]
21Feb17_024321| [-1.00480  1.36344 -0.13998]
21Feb17_024321| [ 1.83140 -0.91532  0.07616]
21Feb17_024321| [-0.60404 -2.05184  0.76948]
21Feb17_024321| [ 0.52617  0.76042 -1.76746]
21Feb17_024321| [-0.22134  0.17324  0.99530]
21Feb17_024321| [-0.36427  1.34655  0.02110]
21Feb17_024321| [-0.93125 -0.33620 -0.25012]
21Feb17_024321| [-2.76428  0.14487  0.48096]
21Feb17_024321| [-0.10518  0.35052  1.71840]
21Feb17_024321| [-1.27998  1.12568  1.26523]
21Feb17_024321| [-0.60698  1.53230 -0.60824]
21Feb17_024321| [ 0.02898  2.98718 -0.59153]
21Feb17_024321| [ 0.17588 -0.00449  0.50797]
21Feb17_024321| [-1.42674 -0.54967 -0.21310]
21Feb17_024321| [ 1.03196  1.18733  0.36755]
21Feb17_024321| [ 1.04748 -1.47444 -0.08469]
21Feb17_024321| [ 0.49410  0.38745  0.68469]
21Feb17_024321| [-0.62880  0.73245  0.19964]]
21Feb17_024321|-- Bias --
21Feb17_024321|[-0.18798  0.64571 -0.23142]
21Feb17_024321|Layer 1:
21Feb17_024321|-- Config --
21Feb17_024321|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024321|-- Weights --
21Feb17_024321|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_024321| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_024321| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_024321|-- Bias --
21Feb17_024321|[0.60477 0.03773 0.26452 0.12222]
21Feb17_024321|Layer 2:
21Feb17_024321|-- Config --
21Feb17_024321|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024321|-- Weights --
21Feb17_024321|[[ 0.67920  0.12119]
21Feb17_024321| [ 0.44836  0.02916]
21Feb17_024321| [ 0.68939  0.31516]
21Feb17_024321| [-0.58995 -0.05861]]
21Feb17_024321|-- Bias --
21Feb17_024321|[ 0.59649 -0.08079]
21Feb17_024321|Layer 3:
21Feb17_024321|-- Config --
21Feb17_024321|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024321|-- Weights --
21Feb17_024321|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_024321| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_024321|-- Bias --
21Feb17_024321|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_024321|Layer 4:
21Feb17_024321|-- Config --
21Feb17_024321|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024321|-- Weights --
21Feb17_024321|[[-0.03514 -1.04833]
21Feb17_024321| [ 1.25238  0.62094]
21Feb17_024321| [ 0.99203  0.37406]
21Feb17_024321| [ 0.49902  0.67158]
21Feb17_024321| [-1.35709  0.38335]]
21Feb17_024321|-- Bias --
21Feb17_024321|[0.31435 0.36299]
21Feb17_024321|Predicting the validation and test data with the Best final individual.
21Feb17_024329| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_024329|-----------  ------------------  --------------------  ----------
21Feb17_024329|Validation         21.74                  56            0.74120
21Feb17_024329|   Test            25.80                  56            0.72926
21Feb17_024329|-------------------- Test #14 --------------------
21Feb17_024329|Best final individual weights
21Feb17_024329|Individual:
21Feb17_024329|-- Constant hidden layers --
21Feb17_024329|False
21Feb17_024329|Layer 0:
21Feb17_024329|-- Config --
21Feb17_024329|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024329|-- Weights --
21Feb17_024329|[[-0.73212  1.32861  0.10200]
21Feb17_024329| [ 1.48746 -2.97273 -0.42944]
21Feb17_024329| [ 0.53095 -1.50623  0.79224]
21Feb17_024329| [-1.07292 -0.83175 -0.90105]
21Feb17_024329| [-0.48696 -0.89325  0.27226]
21Feb17_024329| [-3.02511  0.34155 -0.03837]
21Feb17_024329| [-0.76747  0.57140 -0.46892]
21Feb17_024329| [-0.07581  0.14713  0.85910]
21Feb17_024329| [-1.37488  0.52170 -0.36205]
21Feb17_024329| [ 1.60981 -0.08727 -0.11267]
21Feb17_024329| [ 0.50986  1.58916 -0.35287]
21Feb17_024329| [-0.34599  1.27113 -0.16393]
21Feb17_024329| [ 1.29203  1.19467  0.37695]
21Feb17_024329| [ 0.58704  0.06328 -0.24240]
21Feb17_024329| [-0.93888 -0.89760  0.57087]
21Feb17_024329| [ 0.99159 -0.66387  0.35177]
21Feb17_024329| [-0.67119  1.06910 -0.12512]
21Feb17_024329| [-0.91534  1.23744 -0.40465]
21Feb17_024329| [ 1.39278  0.08069  0.23328]
21Feb17_024329| [ 0.09880  0.57603 -0.96101]
21Feb17_024329| [ 0.01621 -0.13343 -0.27624]
21Feb17_024329| [-1.28286 -2.28909  0.37931]
21Feb17_024329| [-0.28370  0.09336  0.01547]
21Feb17_024329| [-0.51894  1.84280 -0.25906]
21Feb17_024329| [-0.83075 -0.04508  0.12107]
21Feb17_024329| [ 0.37343  1.18436 -0.07358]
21Feb17_024329| [-2.38657 -0.35191  0.01962]
21Feb17_024329| [ 0.95757 -0.91760 -0.08971]
21Feb17_024329| [ 0.38792 -0.01880  0.69717]
21Feb17_024329| [ 1.66877 -0.58078 -1.21129]
21Feb17_024329| [-0.50943  0.59080  0.30856]
21Feb17_024329| [ 0.30163  1.11518  0.98185]
21Feb17_024329| [-0.73226  0.32281 -0.66712]
21Feb17_024329| [-0.62054 -2.21049  1.40981]
21Feb17_024329| [ 1.23185 -0.58090  0.35844]
21Feb17_024329| [-0.05616  0.24219 -0.02853]
21Feb17_024329| [-1.05085 -2.30259 -0.16276]
21Feb17_024329| [ 0.71087  0.14900  1.13430]
21Feb17_024329| [-2.45877 -1.20999 -1.04986]
21Feb17_024329| [-1.00480  1.36344 -0.13998]
21Feb17_024329| [ 1.83140 -0.91532  0.07616]
21Feb17_024329| [-0.60404 -2.05184  0.76948]
21Feb17_024329| [ 0.52617  0.76042 -1.76746]
21Feb17_024329| [-0.22134  0.17324  0.99530]
21Feb17_024329| [-0.36427  1.34655  0.02110]
21Feb17_024329| [-0.93125 -0.33620 -0.25012]
21Feb17_024329| [-2.76428  0.14487  0.48096]
21Feb17_024329| [-0.10518  0.35052  1.71840]
21Feb17_024329| [-1.27998  1.12568  1.26523]
21Feb17_024329| [-0.60698  1.53230 -0.60824]
21Feb17_024329| [ 0.02898  2.98718 -0.59153]
21Feb17_024329| [ 0.17588 -0.00449  0.50797]
21Feb17_024329| [-1.42674 -0.54967 -0.21310]
21Feb17_024329| [ 1.03196  1.18733  0.36755]
21Feb17_024329| [ 1.04748 -1.47444 -0.08469]
21Feb17_024329| [ 0.49410  0.38745  0.68469]
21Feb17_024329| [-0.62880  0.73245  0.19964]]
21Feb17_024329|-- Bias --
21Feb17_024329|[-0.18798  0.64571 -0.23142]
21Feb17_024329|Layer 1:
21Feb17_024329|-- Config --
21Feb17_024329|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024329|-- Weights --
21Feb17_024329|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_024329| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_024329| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_024329|-- Bias --
21Feb17_024329|[0.60477 0.03773 0.26452 0.12222]
21Feb17_024329|Layer 2:
21Feb17_024329|-- Config --
21Feb17_024329|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024329|-- Weights --
21Feb17_024329|[[ 0.67920  0.12119]
21Feb17_024329| [ 0.44836  0.02916]
21Feb17_024329| [ 0.68939  0.31516]
21Feb17_024329| [-0.58995 -0.05861]]
21Feb17_024329|-- Bias --
21Feb17_024329|[ 0.59649 -0.08079]
21Feb17_024329|Layer 3:
21Feb17_024329|-- Config --
21Feb17_024329|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024329|-- Weights --
21Feb17_024329|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_024329| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_024329|-- Bias --
21Feb17_024329|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_024329|Layer 4:
21Feb17_024329|-- Config --
21Feb17_024329|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_024329|-- Weights --
21Feb17_024329|[[-0.03514 -1.04833]
21Feb17_024329| [ 1.25238  0.62094]
21Feb17_024329| [ 0.99203  0.37406]
21Feb17_024329| [ 0.49902  0.67158]
21Feb17_024329| [-1.35709  0.38335]]
21Feb17_024329|-- Bias --
21Feb17_024329|[0.31435 0.36299]
21Feb17_024329|Predicting the validation and test data with the Best final individual.
21Feb17_024336| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_024336|-----------  ------------------  --------------------  ----------
21Feb17_024336|Validation         22.70                  56            0.74363
21Feb17_024336|   Test            19.46                  56            0.73101
Using Theano backend.
WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.
2021-02-17 02:43:39.287622: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-02-17 02:43:39.287682: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
21Feb17_024340|Data summary: Train
21Feb17_024340|data.shape = (2300, 57)
21Feb17_024340|labels.shape = (2300,)
21Feb17_024340|Class distribution:
21Feb17_024340|	0 - 1389 (0.60)
21Feb17_024340|	1 - 911 (0.40)
21Feb17_024340|Data summary: Validation
21Feb17_024340|data.shape = (1150, 57)
21Feb17_024340|labels.shape = (1150,)
21Feb17_024340|Class distribution:
21Feb17_024340|	0 - 667 (0.58)
21Feb17_024340|	1 - 483 (0.42)
21Feb17_024340|Data summary: Test
21Feb17_024340|data.shape = (1151, 57)
21Feb17_024340|labels.shape = (1151,)
21Feb17_024340|Class distribution:
21Feb17_024340|	0 - 732 (0.64)
21Feb17_024340|	1 - 419 (0.36)
21Feb17_024340|Selected configuration values
21Feb17_024340|-- Dataset name: spambase2
21Feb17_024340|-- Initial population size: 64
21Feb17_024340|-- Maximun number of generations: 32
21Feb17_024340|-- Neurons per hidden layer range: (2, 20)
21Feb17_024340|-- Hidden layers number range: (1, 3)
21Feb17_024340|-- Crossover probability: 0.5
21Feb17_024340|-- Bias gene mutation probability: 0.2
21Feb17_024340|-- Weights gene mutation probability: 0.75
21Feb17_024340|-- Neuron mutation probability: 0.3
21Feb17_024340|-- Layer mutation probability: 0.3
21Feb17_024340|-- Constant hidden layers: False
21Feb17_024340|-- Seed: 31415
21Feb17_024340|Entering GA
21Feb17_024340|Start the algorithm
21Feb17_024722|-- Generation 1 --
21Feb17_024722|    -- Crossed 0 individual pairs.
21Feb17_024722|    -- Mutated 32 individuals.
21Feb17_025043|    -- Evaluated 64 individuals.
21Feb17_025043|    Summary of generation 1:
21Feb17_025043| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_025043|-----------  ------------------  --------------------  ----------
21Feb17_025043|    Max            42.70                78.00           0.43478
21Feb17_025043|    Avg            41.90                26.28           0.00941
21Feb17_025043|    Min            35.91                 2.00           0.00000
21Feb17_025043|    Std             0.81                18.75           0.05509
21Feb17_025043|   Best            35.91                18.00           0.43478
21Feb17_025043|-- Generation 2 --
21Feb17_025043|    -- Crossed 1 individual pairs.
21Feb17_025043|    -- Mutated 32 individuals.
21Feb17_025359|    -- Evaluated 64 individuals.
21Feb17_025359|    Summary of generation 2:
21Feb17_025359| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_025359|-----------  ------------------  --------------------  ----------
21Feb17_025359|    Max            58.00                84.00           0.79977
21Feb17_025359|    Avg            41.99                15.92           0.02879
21Feb17_025359|    Min            29.65                 2.00           0.00000
21Feb17_025359|    Std             2.55                13.60           0.13781
21Feb17_025359|   Best            29.65                18.00           0.79977
21Feb17_025359|-- Generation 3 --
21Feb17_025359|    -- Crossed 3 individual pairs.
21Feb17_025359|    -- Mutated 32 individuals.
21Feb17_025712|    -- Evaluated 64 individuals.
21Feb17_025712|    Summary of generation 3:
21Feb17_025712| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_025712|-----------  ------------------  --------------------  ----------
21Feb17_025712|    Max            58.00                50.00           0.78358
21Feb17_025712|    Avg            41.97                13.73           0.02564
21Feb17_025712|    Min            26.09                 2.00           0.00000
21Feb17_025712|    Std             2.83                12.88           0.13211
21Feb17_025712|   Best            26.09                18.00           0.73476
21Feb17_025712|-- Generation 4 --
21Feb17_025712|    -- Crossed 4 individual pairs.
21Feb17_025712|    -- Mutated 32 individuals.
21Feb17_030021|    -- Evaluated 64 individuals.
21Feb17_030021|    Summary of generation 4:
21Feb17_030021| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_030021|-----------  ------------------  --------------------  ----------
21Feb17_030021|    Max            42.17                63.00           0.00517
21Feb17_030021|    Avg            42.01                 8.34           0.00085
21Feb17_030021|    Min            41.91                 2.00           0.00000
21Feb17_030021|    Std             0.06                 9.60           0.00165
21Feb17_030021|   Best            41.91                 4.00           0.00517
21Feb17_030021|-- Generation 5 --
21Feb17_030021|    -- Crossed 6 individual pairs.
21Feb17_030021|    -- Mutated 32 individuals.
21Feb17_030328|    -- Evaluated 64 individuals.
21Feb17_030328|    Summary of generation 5:
21Feb17_030328| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_030328|-----------  ------------------  --------------------  ----------
21Feb17_030328|    Max            42.09                20.00           0.05344
21Feb17_030328|    Avg            41.98                 5.28           0.00172
21Feb17_030328|    Min            41.22                 2.00           0.00000
21Feb17_030328|    Std             0.11                 4.46           0.00681
21Feb17_030328|   Best            41.22                14.00           0.05344
21Feb17_030328|-- Generation 6 --
21Feb17_030328|    -- Crossed 7 individual pairs.
21Feb17_030328|    -- Mutated 32 individuals.
21Feb17_030637|    -- Evaluated 64 individuals.
21Feb17_030637|    Summary of generation 6:
21Feb17_030637| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_030637|-----------  ------------------  --------------------  ----------
21Feb17_030637|    Max            42.26                18.00           0.01548
21Feb17_030637|    Avg            41.99                 6.00           0.00105
21Feb17_030637|    Min            41.48                 2.00           0.00000
21Feb17_030637|    Std             0.09                 4.81           0.00231
21Feb17_030637|   Best            41.48                 3.00           0.01548
21Feb17_030637|-- Generation 7 --
21Feb17_030637|    -- Crossed 9 individual pairs.
21Feb17_030637|    -- Mutated 32 individuals.
21Feb17_030944|    -- Evaluated 64 individuals.
21Feb17_030944|    Summary of generation 7:
21Feb17_030944| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_030944|-----------  ------------------  --------------------  ----------
21Feb17_030944|    Max            42.09                36.00           0.01033
21Feb17_030944|    Avg            41.99                 5.98           0.00089
21Feb17_030944|    Min            41.65                 2.00           0.00000
21Feb17_030944|    Std             0.06                 6.14           0.00184
21Feb17_030944|   Best            41.65                 3.00           0.01033
21Feb17_030944|-- Generation 8 --
21Feb17_030944|    -- Crossed 9 individual pairs.
21Feb17_030944|    -- Mutated 32 individuals.
21Feb17_031250|    -- Evaluated 64 individuals.
21Feb17_031250|    Summary of generation 8:
21Feb17_031250| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_031250|-----------  ------------------  --------------------  ----------
21Feb17_031250|    Max            42.17                18.00           0.04103
21Feb17_031250|    Avg            41.97                 5.09           0.00169
21Feb17_031250|    Min            40.78                 2.00           0.00000
21Feb17_031250|    Std             0.16                 4.37           0.00529
21Feb17_031250|   Best            40.78                12.00           0.04103
21Feb17_031250|-- Generation 9 --
21Feb17_031250|    -- Crossed 8 individual pairs.
21Feb17_031250|    -- Mutated 32 individuals.
21Feb17_031559|    -- Evaluated 64 individuals.
21Feb17_031559|    Summary of generation 9:
21Feb17_031559| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_031559|-----------  ------------------  --------------------  ----------
21Feb17_031559|    Max            48.87                18.00           0.80667
21Feb17_031559|    Avg            41.71                 6.17           0.03823
21Feb17_031559|    Min            30.61                 2.00           0.00000
21Feb17_031559|    Std             2.17                 5.04           0.16210
21Feb17_031559|   Best            30.61                 8.00           0.78607
21Feb17_031559|-- Generation 10 --
21Feb17_031559|    -- Crossed 5 individual pairs.
21Feb17_031559|    -- Mutated 32 individuals.
21Feb17_031909|    -- Evaluated 64 individuals.
21Feb17_031909|    Summary of generation 10:
21Feb17_031909| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_031909|-----------  ------------------  --------------------  ----------
21Feb17_031909|    Max            42.26                18.00           0.58344
21Feb17_031909|    Avg            41.43                 6.23           0.02714
21Feb17_031909|    Min            27.74                 2.00           0.00000
21Feb17_031909|    Std             2.43                 4.89           0.10887
21Feb17_031909|   Best            27.74                18.00           0.51616
21Feb17_031909|-- Generation 11 --
21Feb17_031909|    -- Crossed 8 individual pairs.
21Feb17_031909|    -- Mutated 32 individuals.
21Feb17_032221|    -- Evaluated 64 individuals.
21Feb17_032221|    Summary of generation 11:
21Feb17_032221| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_032221|-----------  ------------------  --------------------  ----------
21Feb17_032221|    Max            58.00                34.00           0.78358
21Feb17_032221|    Avg            41.87                 7.95           0.03476
21Feb17_032221|    Min            28.00                 2.00           0.00000
21Feb17_032221|    Std             2.88                 6.49           0.14854
21Feb17_032221|   Best            28.00                 8.00           0.52079
21Feb17_032221|-- Generation 12 --
21Feb17_032221|    -- Crossed 3 individual pairs.
21Feb17_032221|    -- Mutated 32 individuals.
21Feb17_032533|    -- Evaluated 64 individuals.
21Feb17_032533|    Summary of generation 12:
21Feb17_032533| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_032533|-----------  ------------------  --------------------  ----------
21Feb17_032533|    Max            42.35                36.00           0.67494
21Feb17_032533|    Avg            41.46                 7.03           0.02217
21Feb17_032533|    Min            24.96                 2.00           0.00000
21Feb17_032533|    Std             2.67                 5.88           0.11025
21Feb17_032533|   Best            24.96                18.00           0.67494
21Feb17_032533|-- Generation 13 --
21Feb17_032533|    -- Crossed 5 individual pairs.
21Feb17_032533|    -- Mutated 32 individuals.
21Feb17_032845|    -- Evaluated 64 individuals.
21Feb17_032845|    Summary of generation 13:
21Feb17_032845| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_032845|-----------  ------------------  --------------------  ----------
21Feb17_032845|    Max            42.61                36.00           0.61562
21Feb17_032845|    Avg            41.50                 8.56           0.02210
21Feb17_032845|    Min            26.78                 2.00           0.00000
21Feb17_032845|    Std             2.40                 7.93           0.10577
21Feb17_032845|   Best            26.78                18.00           0.61562
21Feb17_032845|-- Generation 14 --
21Feb17_032845|    -- Crossed 7 individual pairs.
21Feb17_032845|    -- Mutated 32 individuals.
21Feb17_033158|    -- Evaluated 64 individuals.
21Feb17_033158|    Summary of generation 14:
21Feb17_033158| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_033158|-----------  ------------------  --------------------  ----------
21Feb17_033158|    Max            42.09                40.00           0.75188
21Feb17_033158|    Avg            41.48                 8.12           0.02679
21Feb17_033158|    Min            27.65                 2.00           0.00000
21Feb17_033158|    Std             2.42                 6.72           0.13015
21Feb17_033158|   Best            27.65                18.00           0.75188
21Feb17_033158|-- Generation 15 --
21Feb17_033158|    -- Crossed 6 individual pairs.
21Feb17_033158|    -- Mutated 32 individuals.
21Feb17_033510|    -- Evaluated 64 individuals.
21Feb17_033510|    Summary of generation 15:
21Feb17_033510| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_033510|-----------  ------------------  --------------------  ----------
21Feb17_033510|    Max            42.09                40.00           0.73387
21Feb17_033510|    Avg            41.42                 7.69           0.02610
21Feb17_033510|    Min            26.35                 2.00           0.00000
21Feb17_033510|    Std             2.71                 6.44           0.12590
21Feb17_033510|   Best            26.35                18.00           0.71951
21Feb17_033510|-- Generation 16 --
21Feb17_033510|    -- Crossed 5 individual pairs.
21Feb17_033510|    -- Mutated 32 individuals.
21Feb17_033823|    -- Evaluated 64 individuals.
21Feb17_033823|    Summary of generation 16:
21Feb17_033823| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_033823|-----------  ------------------  --------------------  ----------
21Feb17_033823|    Max            42.26                44.00           0.82855
21Feb17_033823|    Avg            41.21                 7.83           0.03973
21Feb17_033823|    Min            24.87                 2.00           0.00000
21Feb17_033823|    Std             3.23                 7.99           0.16234
21Feb17_033823|   Best            24.87                21.00           0.68287
21Feb17_033823|-- Generation 17 --
21Feb17_033823|    -- Crossed 8 individual pairs.
21Feb17_033823|    -- Mutated 32 individuals.
21Feb17_034137|    -- Evaluated 64 individuals.
21Feb17_034137|    Summary of generation 17:
21Feb17_034137| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_034137|-----------  ------------------  --------------------  ----------
21Feb17_034137|    Max            42.26                44.00           0.80877
21Feb17_034137|    Avg            40.86                 8.81           0.06413
21Feb17_034137|    Min            25.04                 2.00           0.00000
21Feb17_034137|    Std             3.59                 8.94           0.19340
21Feb17_034137|   Best            25.04                10.00           0.72247
21Feb17_034137|-- Generation 18 --
21Feb17_034137|    -- Crossed 2 individual pairs.
21Feb17_034137|    -- Mutated 32 individuals.
21Feb17_034455|    -- Evaluated 64 individuals.
21Feb17_034455|    Summary of generation 18:
21Feb17_034455| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_034455|-----------  ------------------  --------------------  ----------
21Feb17_034455|    Max            47.04                44.00           0.81211
21Feb17_034455|    Avg            39.55                10.78           0.12108
21Feb17_034455|    Min            24.35                 3.00           0.00000
21Feb17_034455|    Std             5.74                11.16           0.25939
21Feb17_034455|   Best            24.35                44.00           0.72485
21Feb17_034455|-- Generation 19 --
21Feb17_034455|    -- Crossed 7 individual pairs.
21Feb17_034455|    -- Mutated 32 individuals.
21Feb17_034819|    -- Evaluated 64 individuals.
21Feb17_034819|    Summary of generation 19:
21Feb17_034819| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_034819|-----------  ------------------  --------------------  ----------
21Feb17_034819|    Max            42.87                70.00           0.81774
21Feb17_034819|    Avg            39.09                14.53           0.14606
21Feb17_034819|    Min            24.70                 3.00           0.00000
21Feb17_034819|    Std             5.78                15.60           0.27609
21Feb17_034819|   Best            24.70                44.00           0.69102
21Feb17_034819|-- Generation 20 --
21Feb17_034819|    -- Crossed 3 individual pairs.
21Feb17_034819|    -- Mutated 32 individuals.
21Feb17_035146|    -- Evaluated 64 individuals.
21Feb17_035146|    Summary of generation 20:
21Feb17_035146| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_035146|-----------  ------------------  --------------------  ----------
21Feb17_035146|    Max            42.17                60.00           0.79174
21Feb17_035146|    Avg            39.05                15.47           0.15453
21Feb17_035146|    Min            24.09                 3.00           0.00000
21Feb17_035146|    Std             5.60                16.03           0.28335
21Feb17_035146|   Best            24.09                48.00           0.76568
21Feb17_035146|-- Generation 21 --
21Feb17_035146|    -- Crossed 4 individual pairs.
21Feb17_035146|    -- Mutated 32 individuals.
21Feb17_035517|    -- Evaluated 64 individuals.
21Feb17_035517|    Summary of generation 21:
21Feb17_035517| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_035517|-----------  ------------------  --------------------  ----------
21Feb17_035517|    Max            42.17                90.00           0.80579
21Feb17_035517|    Avg            38.34                18.45           0.19938
21Feb17_035517|    Min            23.91                 2.00           0.00000
21Feb17_035517|    Std             5.87                19.09           0.30554
21Feb17_035517|   Best            23.91                48.00           0.71458
21Feb17_035517|-- Generation 22 --
21Feb17_035517|    -- Crossed 2 individual pairs.
21Feb17_035517|    -- Mutated 32 individuals.
21Feb17_035853|    -- Evaluated 64 individuals.
21Feb17_035853|    Summary of generation 22:
21Feb17_035853| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_035853|-----------  ------------------  --------------------  ----------
21Feb17_035853|    Max            42.09                60.00           0.82362
21Feb17_035853|    Avg            36.71                21.28           0.25981
21Feb17_035853|    Min            24.26                 2.00           0.00000
21Feb17_035853|    Std             6.98                18.25           0.33831
21Feb17_035853|   Best            24.26                52.00           0.76087
21Feb17_035853|-- Generation 23 --
21Feb17_035853|    -- Crossed 2 individual pairs.
21Feb17_035853|    -- Mutated 32 individuals.
21Feb17_040239|    -- Evaluated 64 individuals.
21Feb17_040239|    Summary of generation 23:
21Feb17_040239| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_040239|-----------  ------------------  --------------------  ----------
21Feb17_040239|    Max            42.09                96.00           0.78772
21Feb17_040239|    Avg            35.35                29.28           0.32114
21Feb17_040239|    Min            23.39                 2.00           0.00000
21Feb17_040239|    Std             7.15                21.95           0.34435
21Feb17_040239|   Best            23.39                52.00           0.72814
21Feb17_040239|-- Generation 24 --
21Feb17_040239|    -- Crossed 0 individual pairs.
21Feb17_040239|    -- Mutated 32 individuals.
21Feb17_040635|    -- Evaluated 64 individuals.
21Feb17_040635|    Summary of generation 24:
21Feb17_040635| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_040635|-----------  ------------------  --------------------  ----------
21Feb17_040635|    Max            43.30                80.00           0.82075
21Feb17_040635|    Avg            33.81                36.61           0.38588
21Feb17_040635|    Min            23.22                 2.00           0.00000
21Feb17_040635|    Std             7.30                19.72           0.34184
21Feb17_040635|   Best            23.22                52.00           0.73602
21Feb17_040635|-- Generation 25 --
21Feb17_040635|    -- Crossed 3 individual pairs.
21Feb17_040635|    -- Mutated 32 individuals.
21Feb17_041042|    -- Evaluated 64 individuals.
21Feb17_041042|    Summary of generation 25:
21Feb17_041042| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_041042|-----------  ------------------  --------------------  ----------
21Feb17_041042|    Max            51.74                114.00          0.82799
21Feb17_041042|    Avg            33.58                45.08           0.45457
21Feb17_041042|    Min            23.91                 8.00           0.00000
21Feb17_041042|    Std             7.24                19.61           0.35022
21Feb17_041042|   Best            23.91                48.00           0.72048
21Feb17_041042|-- Generation 26 --
21Feb17_041042|    -- Crossed 1 individual pairs.
21Feb17_041042|    -- Mutated 32 individuals.
21Feb17_041450|    -- Evaluated 64 individuals.
21Feb17_041450|    Summary of generation 26:
21Feb17_041450| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_041450|-----------  ------------------  --------------------  ----------
21Feb17_041450|    Max            42.35                108.00          0.84388
21Feb17_041450|    Avg            32.71                48.80           0.44554
21Feb17_041450|    Min            23.30                 2.00           0.00000
21Feb17_041450|    Std             7.16                22.53           0.33996
21Feb17_041450|   Best            23.30                24.00           0.69415
21Feb17_041450|-- Generation 27 --
21Feb17_041450|    -- Crossed 1 individual pairs.
21Feb17_041450|    -- Mutated 32 individuals.
21Feb17_041902|    -- Evaluated 64 individuals.
21Feb17_041902|    Summary of generation 27:
21Feb17_041902| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_041902|-----------  ------------------  --------------------  ----------
21Feb17_041902|    Max            42.26                132.00          0.82552
21Feb17_041902|    Avg            32.16                51.20           0.45948
21Feb17_041902|    Min            21.74                 8.00           0.00000
21Feb17_041902|    Std             7.19                22.48           0.32234
21Feb17_041902|   Best            21.74                18.00           0.76278
21Feb17_041902|-- Generation 28 --
21Feb17_041902|    -- Crossed 0 individual pairs.
21Feb17_041902|    -- Mutated 32 individuals.
21Feb17_042312|    -- Evaluated 64 individuals.
21Feb17_042312|    Summary of generation 28:
21Feb17_042312| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_042312|-----------  ------------------  --------------------  ----------
21Feb17_042312|    Max            42.00                132.00          0.83850
21Feb17_042312|    Avg            31.52                51.11           0.49187
21Feb17_042312|    Min            23.04                12.00           0.00000
21Feb17_042312|    Std             6.86                24.66           0.32040
21Feb17_042312|   Best            23.04                24.00           0.73226
21Feb17_042312|-- Generation 29 --
21Feb17_042312|    -- Crossed 0 individual pairs.
21Feb17_042312|    -- Mutated 32 individuals.
21Feb17_042716|    -- Evaluated 64 individuals.
21Feb17_042716|    Summary of generation 29:
21Feb17_042716| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_042716|-----------  ------------------  --------------------  ----------
21Feb17_042716|    Max            42.09                132.00          0.82871
21Feb17_042716|    Avg            32.10                49.19           0.44677
21Feb17_042716|    Min            22.26                12.00           0.00000
21Feb17_042716|    Std             7.60                23.20           0.33800
21Feb17_042716|   Best            22.26                56.00           0.74227
21Feb17_042716|-- Generation 30 --
21Feb17_042716|    -- Crossed 0 individual pairs.
21Feb17_042716|    -- Mutated 32 individuals.
21Feb17_043122|    -- Evaluated 64 individuals.
21Feb17_043122|    Summary of generation 30:
21Feb17_043122| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_043122|-----------  ------------------  --------------------  ----------
21Feb17_043122|    Max            42.09                100.00          0.82371
21Feb17_043122|    Avg            31.14                49.09           0.49033
21Feb17_043122|    Min            22.00                14.00           0.00000
21Feb17_043122|    Std             7.06                18.85           0.31415
21Feb17_043122|   Best            22.00                56.00           0.78704
21Feb17_043122|-- Generation 31 --
21Feb17_043122|    -- Crossed 1 individual pairs.
21Feb17_043122|    -- Mutated 32 individuals.
21Feb17_043531|    -- Evaluated 64 individuals.
21Feb17_043531|    Summary of generation 31:
21Feb17_043531| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_043531|-----------  ------------------  --------------------  ----------
21Feb17_043531|    Max            42.52                100.00          0.83333
21Feb17_043531|    Avg            32.54                52.38           0.44410
21Feb17_043531|    Min            22.96                 8.00           0.00000
21Feb17_043531|    Std             7.42                21.79           0.34342
21Feb17_043531|   Best            22.96                44.00           0.72671
21Feb17_043531|-- Generation 32 --
21Feb17_043531|    -- Crossed 1 individual pairs.
21Feb17_043531|    -- Mutated 32 individuals.
21Feb17_043940|    -- Evaluated 64 individuals.
21Feb17_043940|    Summary of generation 32:
21Feb17_043940| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_043940|-----------  ------------------  --------------------  ----------
21Feb17_043940|    Max            42.00                85.00           0.83038
21Feb17_043940|    Avg            32.40                52.83           0.43440
21Feb17_043940|    Min            21.57                 8.00           0.00000
21Feb17_043940|    Std             7.70                18.10           0.34013
21Feb17_043940|   Best            21.57                56.00           0.83038
21Feb17_043940|Best initial individual weights
21Feb17_043940|Individual:
21Feb17_043940|-- Constant hidden layers --
21Feb17_043940|False
21Feb17_043940|Layer 0:
21Feb17_043940|-- Config --
21Feb17_043940|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 12, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_043940|-- Weights --
21Feb17_043940|[[-3.50529e-01 -6.53069e-03 -7.03730e-01 -6.33906e-01  6.10835e-02
21Feb17_043940|   4.57449e-01 -3.77835e-01  6.38481e-01  4.24141e-01  6.68786e-01
21Feb17_043940|  -4.86511e-01 -9.28542e-01]
21Feb17_043940| [-8.31270e-01 -3.94586e-01  5.51697e-02 -8.86387e-01 -6.99786e-01
21Feb17_043940|   6.44047e-01 -5.40571e-01  3.77503e-01  1.70193e-01  5.92883e-01
21Feb17_043940|   2.06540e-01  2.18639e-01]
21Feb17_043940| [-8.13637e-01  7.25044e-01  6.66092e-01  5.31057e-01 -4.48634e-01
21Feb17_043940|  -1.62601e-01 -1.57458e-02  7.74238e-02 -4.81841e-01  3.55485e-02
21Feb17_043940|  -7.21169e-01  1.05129e-01]
21Feb17_043940| [ 6.07201e-01  6.23643e-01  8.87343e-01  6.04285e-01  5.70453e-02
21Feb17_043940|   5.99381e-01 -3.21663e-03  6.64196e-01 -5.25584e-01 -1.74507e-02
21Feb17_043940|   3.80029e-01 -4.59585e-01]
21Feb17_043940| [-9.00078e-01  8.63133e-01  8.49324e-01  4.34648e-01 -5.67121e-01
21Feb17_043940|   6.24299e-01 -6.46637e-01  9.34620e-01 -5.42838e-01 -4.04257e-01
21Feb17_043940|  -4.70046e-01  4.29712e-01]
21Feb17_043940| [ 9.51731e-02  8.42954e-01 -7.44806e-01 -5.56045e-02 -4.89209e-01
21Feb17_043940|   8.07612e-01  2.77691e-01 -5.77946e-02  4.30356e-01 -9.05718e-01
21Feb17_043940|  -7.61358e-01 -4.56367e-01]
21Feb17_043940| [-9.06447e-01 -4.46566e-01 -4.40669e-01  6.09161e-01 -3.32587e-01
21Feb17_043940|  -9.31356e-01  9.62597e-02 -1.83060e-01  5.91585e-01 -2.78230e-01
21Feb17_043940|  -3.70976e-01 -3.38510e-01]
21Feb17_043940| [ 5.92999e-02 -5.35945e-01 -8.52259e-01  1.62766e-01 -2.64657e-01
21Feb17_043940|   6.65182e-01  2.45597e-01  2.99711e-01  7.14862e-01 -4.00362e-01
21Feb17_043940|   3.40170e-01 -1.14174e-01]
21Feb17_043940| [-4.26995e-01  8.46146e-01  9.81523e-01 -2.62996e-01  8.65377e-01
21Feb17_043940|  -6.86144e-01 -3.53983e-01 -2.18499e-01  3.29010e-01 -8.26088e-01
21Feb17_043940|   1.48202e-01  5.27152e-01]
21Feb17_043940| [-1.97937e-01  5.44304e-02  9.68680e-01  1.96012e-01  6.66432e-01
21Feb17_043940|  -1.15663e-01  1.01696e-01 -9.91833e-01  5.54656e-02  5.06069e-01
21Feb17_043940|  -8.39702e-01  6.07914e-02]
21Feb17_043940| [ 8.22409e-01 -3.07988e-01 -4.87097e-01 -2.67403e-01 -3.17115e-01
21Feb17_043940|   6.20877e-01  2.45721e-01  1.47039e-01  8.22748e-02 -4.61491e-01
21Feb17_043940|   5.08690e-01 -8.10093e-01]
21Feb17_043940| [-1.03463e-01 -7.13247e-01 -5.27190e-01 -8.14055e-01 -2.20069e-01
21Feb17_043940|   7.58689e-01  7.72478e-01 -3.75243e-01 -1.74773e-01  4.33018e-02
21Feb17_043940|   5.76591e-01 -9.04182e-01]
21Feb17_043940| [ 6.39880e-01 -2.76473e-01  4.48413e-01  7.92996e-01  6.12921e-01
21Feb17_043940|   8.45232e-01 -3.59434e-01 -1.65084e-01  6.00279e-01 -9.07135e-01
21Feb17_043940|  -9.18766e-01 -3.84510e-02]
21Feb17_043940| [-4.35982e-01  3.53117e-01 -4.33635e-01  4.41189e-01  2.02385e-01
21Feb17_043940|  -2.15156e-01 -3.32093e-01 -9.46393e-01  7.49818e-01  7.56840e-01
21Feb17_043940|  -2.97280e-01  3.76513e-01]
21Feb17_043940| [ 2.00098e-01 -3.94368e-01  4.74964e-01 -5.14077e-01 -5.02985e-01
21Feb17_043940|   6.57337e-01  4.54284e-01  7.99434e-01  1.18259e-01  7.90625e-01
21Feb17_043940|  -8.45168e-01 -7.22624e-01]
21Feb17_043940| [ 5.21361e-01 -9.37087e-01  6.98489e-01  7.45747e-01  9.84330e-01
21Feb17_043940|  -1.70463e-01 -4.14211e-01  4.94059e-01 -4.89685e-03 -7.22161e-02
21Feb17_043940|   3.28119e-01 -2.96382e-01]
21Feb17_043940| [ 9.97912e-02 -3.45331e-01 -3.32041e-01 -8.83410e-01  4.64194e-01
21Feb17_043940|  -2.94905e-01 -7.11116e-01 -2.12420e-01  8.93334e-01  5.60374e-01
21Feb17_043940|  -8.11522e-01  3.94537e-01]
21Feb17_043940| [ 2.39284e-01 -9.68110e-02 -3.48403e-01  6.68017e-01  1.07039e-01
21Feb17_043940|  -1.80014e-01 -1.28612e-01 -3.28318e-01  7.99371e-01  7.45882e-01
21Feb17_043940|   4.50426e-01 -9.94601e-02]
21Feb17_043940| [-9.32040e-02 -4.99896e-01 -3.18835e-01 -3.21963e-01  8.88030e-02
21Feb17_043940|   8.24115e-01  3.93190e-01  2.14054e-01 -4.70631e-02  5.36199e-01
21Feb17_043940|   7.72001e-01 -1.38053e-01]
21Feb17_043940| [ 8.31611e-01  7.46409e-01  2.18558e-01  7.47226e-01 -4.35942e-01
21Feb17_043940|  -6.59230e-01  3.39715e-02  8.14827e-01 -7.32488e-02 -1.12845e-01
21Feb17_043940|  -5.06295e-01  2.18074e-01]
21Feb17_043940| [-3.26563e-01  6.22846e-01  3.85669e-01 -9.86028e-01 -7.51629e-02
21Feb17_043940|  -1.88021e-01  7.27322e-01  5.61207e-04  1.34321e-01  7.19415e-01
21Feb17_043940|  -5.83277e-01 -4.45815e-01]
21Feb17_043940| [ 7.83756e-01  9.31803e-02  4.99853e-01 -9.31861e-01  7.91593e-01
21Feb17_043940|   1.96250e-01 -8.00498e-02  7.34271e-01 -2.68771e-01  7.49220e-01
21Feb17_043940|   1.24815e-01  6.17245e-01]
21Feb17_043940| [ 2.20500e-01 -9.26851e-01 -5.03545e-02  9.91366e-01  9.07862e-01
21Feb17_043940|   6.95839e-01  2.07702e-01  1.55262e-01  7.17753e-01 -6.02225e-01
21Feb17_043940|  -2.43972e-02  7.83904e-01]
21Feb17_043940| [-7.35179e-01 -4.04922e-01 -7.64988e-01  6.94764e-03 -5.74469e-01
21Feb17_043940|  -8.82582e-01 -4.25720e-01  4.48261e-01  9.38039e-01 -6.02162e-01
21Feb17_043940|   1.85138e-01  8.19467e-01]
21Feb17_043940| [-2.42564e-01  5.05630e-02 -6.53631e-01  8.89456e-01  3.73267e-02
21Feb17_043940|  -4.57479e-01  5.78190e-01 -8.65769e-01  4.43846e-01  9.21993e-01
21Feb17_043940|  -4.59642e-01  4.55887e-01]
21Feb17_043940| [ 1.79502e-01  5.97755e-01 -5.91581e-01  6.50878e-01 -3.20822e-02
21Feb17_043940|   7.98103e-01  9.23662e-01 -3.15762e-01  3.95919e-01 -9.74799e-01
21Feb17_043940|  -9.18783e-01  9.04381e-01]
21Feb17_043940| [-9.77544e-01 -9.84191e-01 -3.78989e-01  1.57093e-01 -1.19240e-01
21Feb17_043940|   7.04336e-01  9.20317e-01 -9.23300e-02  7.24512e-01 -4.73620e-01
21Feb17_043940|   4.32204e-01  1.96422e-01]
21Feb17_043940| [-9.94008e-01  1.23345e-01 -2.91311e-01  3.86181e-01  3.50519e-01
21Feb17_043940|   8.97293e-02  1.28693e-01  7.64175e-01  9.70172e-01 -9.36008e-01
21Feb17_043940|   2.31190e-01 -3.81352e-01]
21Feb17_043940| [-8.68842e-01 -3.08689e-01 -7.85613e-02 -7.75421e-01 -2.62711e-01
21Feb17_043940|  -9.13854e-01  5.58996e-01  8.97445e-01 -4.78631e-01 -4.79708e-02
21Feb17_043940|  -2.09270e-01  1.03320e-01]
21Feb17_043940| [ 2.47190e-01  8.94828e-01 -8.83655e-01  1.67368e-01 -1.09226e-01
21Feb17_043940|   5.39374e-01  3.22158e-01  7.22802e-01 -4.76431e-01 -3.98606e-01
21Feb17_043940|   3.91466e-01 -5.89172e-01]
21Feb17_043940| [ 2.03966e-01 -8.11217e-01  8.56319e-01 -5.26108e-01 -9.29896e-01
21Feb17_043940|   5.92077e-01  8.52854e-01  6.15086e-01  5.45676e-01 -8.13950e-01
21Feb17_043940|   6.24771e-01 -9.57171e-01]
21Feb17_043940| [-7.59457e-01  2.18652e-01 -9.40198e-01 -1.94388e-03 -3.63300e-01
21Feb17_043940|   2.19527e-01 -3.86609e-01  6.57866e-02  8.04643e-01  4.37489e-01
21Feb17_043940|   6.39988e-01 -8.42788e-01]
21Feb17_043940| [-2.79911e-01  8.89651e-01  5.38994e-02  7.45843e-01 -9.32154e-01
21Feb17_043940|   5.56522e-01  5.04658e-01  3.56409e-01 -5.15289e-01  6.99550e-01
21Feb17_043940|  -7.31032e-01  1.61260e-01]
21Feb17_043940| [ 8.41582e-01 -5.25391e-01  4.65437e-01  4.40808e-01 -6.03761e-01
21Feb17_043940|   6.23036e-01  9.46114e-01  5.92328e-01  2.08190e-01 -6.69715e-01
21Feb17_043940|  -7.35264e-02  5.96491e-01]
21Feb17_043940| [ 3.20347e-01  1.37290e-01  1.72843e-02 -4.70187e-01  5.92987e-01
21Feb17_043940|   3.57672e-01  2.73873e-01 -8.65750e-02 -3.09144e-01 -9.20603e-01
21Feb17_043940|   2.82912e-01  6.38325e-01]
21Feb17_043940| [-8.91399e-01 -1.24857e-01 -4.86431e-01 -9.05166e-01  8.47373e-01
21Feb17_043940|   3.18146e-01  2.73494e-02 -5.33112e-01  5.63862e-01 -5.12821e-01
21Feb17_043940|  -9.38474e-01 -9.90043e-01]
21Feb17_043940| [-8.25448e-01 -1.90141e-02 -5.51276e-01 -8.23215e-01  7.26222e-02
21Feb17_043940|   3.49894e-01  5.17693e-01 -5.57217e-01 -3.26301e-01  7.78564e-01
21Feb17_043940|   6.58213e-01 -2.83929e-01]
21Feb17_043940| [ 6.18012e-02 -4.92329e-01  5.41071e-01  2.13013e-01  6.35700e-01
21Feb17_043940|  -1.65529e-01  5.77357e-01  2.45531e-01  2.54855e-01 -8.48854e-01
21Feb17_043940|   6.46386e-01 -4.13404e-01]
21Feb17_043940| [-3.41116e-01 -4.75918e-01  3.59165e-01  6.02895e-01 -4.31688e-01
21Feb17_043940|  -8.51757e-01  2.31464e-01 -9.57407e-01  2.83436e-01 -4.51744e-01
21Feb17_043940|   4.80022e-02 -8.35007e-01]
21Feb17_043940| [ 9.67499e-01  5.85047e-02  7.21540e-01  3.12459e-01  3.50272e-01
21Feb17_043940|   2.14450e-01 -3.30294e-01 -7.99000e-01  1.11959e-01  2.74091e-01
21Feb17_043940|  -1.78234e-01  9.40235e-01]
21Feb17_043940| [-1.14387e-01  4.31319e-01  3.73789e-01 -4.62497e-01  4.50407e-01
21Feb17_043940|  -4.00668e-01 -8.26575e-01  2.39589e-01 -5.24611e-01  3.30691e-01
21Feb17_043940|  -3.99504e-01  1.44547e-01]
21Feb17_043940| [ 7.34826e-01 -5.37352e-01 -6.62895e-01  1.04258e-01  2.15046e-03
21Feb17_043940|   2.71790e-01  8.51151e-01 -6.31948e-01  1.94011e-01 -6.41830e-01
21Feb17_043940|   1.67802e-01 -4.29449e-01]
21Feb17_043940| [-6.18752e-01  1.18069e-01 -7.98263e-01  4.75266e-01 -9.95474e-01
21Feb17_043940|  -1.79698e-01  6.90455e-01  3.44607e-01 -5.80013e-01 -6.16218e-02
21Feb17_043940|   7.01329e-01  8.33298e-02]
21Feb17_043940| [-2.69227e-01 -1.43165e-02 -3.33533e-01 -1.69954e-01 -1.26476e-02
21Feb17_043940|   7.69653e-01 -6.99893e-01  5.22539e-01 -1.67862e-01  4.44416e-01
21Feb17_043940|   6.72372e-01  5.52923e-01]
21Feb17_043940| [-7.10479e-01  1.61800e-01  2.53825e-01 -3.00634e-01 -5.06805e-01
21Feb17_043940|   2.02091e-01 -4.94980e-02 -1.44363e-01 -6.18371e-01  5.74350e-01
21Feb17_043940|  -1.85073e-01 -8.11049e-01]
21Feb17_043940| [-6.60846e-01 -1.69003e-01  6.00733e-01 -8.28618e-01 -3.99034e-01
21Feb17_043940|  -5.82553e-01  7.34428e-02  5.57096e-01 -1.50695e-01  1.26307e-01
21Feb17_043940|   8.92712e-01 -8.75142e-01]
21Feb17_043940| [ 7.58158e-01  5.89907e-01 -1.92304e-01 -3.86200e-01 -2.63049e-01
21Feb17_043940|  -3.41209e-03  4.05030e-01 -8.95945e-02  9.79113e-01  6.78942e-02
21Feb17_043940|  -9.53580e-01  7.06162e-01]
21Feb17_043940| [-1.23045e-01  9.25694e-01  5.20030e-01  4.57808e-01 -9.99639e-01
21Feb17_043940|  -9.80069e-02  3.03598e-01  4.26167e-02 -3.64595e-01 -7.17635e-01
21Feb17_043940|   1.61128e-01  6.30329e-01]
21Feb17_043940| [ 2.02232e-02 -3.24113e-01  7.43999e-01 -3.75983e-01  4.63558e-01
21Feb17_043940|  -2.04941e-01 -5.28404e-02  4.26576e-01 -2.53802e-01  1.74976e-01
21Feb17_043940|  -8.35763e-01  8.54548e-01]
21Feb17_043940| [-5.76875e-01  5.40954e-01 -4.91777e-01  4.40209e-01 -9.16379e-01
21Feb17_043940|   6.01728e-01  1.25226e-02  2.05876e-01  8.45524e-01 -8.34178e-01
21Feb17_043940|  -7.87379e-01  8.63352e-01]
21Feb17_043940| [-3.15102e-01  7.00213e-01  6.69503e-01  7.15510e-01 -9.53550e-01
21Feb17_043940|   4.07885e-02  4.25336e-01  6.24629e-01  9.90858e-01  6.36989e-01
21Feb17_043940|  -6.44355e-01 -5.47589e-01]
21Feb17_043940| [-8.25051e-01 -4.37574e-01  4.76334e-01 -7.71092e-01  7.98467e-01
21Feb17_043940|  -1.52347e-01  3.34469e-01  1.51889e-01 -9.60611e-01  4.62484e-01
21Feb17_043940|   4.10115e-01 -1.60555e-01]
21Feb17_043940| [ 1.77712e-01  6.55776e-01  8.97735e-01 -9.20852e-01 -9.69032e-01
21Feb17_043940|  -4.79756e-02 -3.24015e-01 -1.57490e-01 -6.25919e-01  9.94240e-01
21Feb17_043940|  -4.74141e-01 -1.00993e-01]
21Feb17_043940| [ 3.66246e-01  8.06205e-01  3.37216e-01 -3.17040e-01  9.19693e-01
21Feb17_043940|   8.28581e-01  2.22724e-01 -5.57410e-01 -8.17434e-01 -8.65693e-01
21Feb17_043940|  -4.72960e-01  7.15176e-01]
21Feb17_043940| [-8.25000e-01 -4.67253e-01 -1.84646e-02  3.88053e-01 -8.75853e-01
21Feb17_043940|  -2.34509e-01  9.53471e-01  8.05489e-02  2.71744e-01 -7.15129e-01
21Feb17_043940|   9.24875e-01 -6.07435e-01]
21Feb17_043940| [-2.79447e-01  2.39105e-01  1.32962e-01 -7.68103e-01  7.58443e-01
21Feb17_043940|  -1.69646e-01 -7.52460e-01 -7.30195e-01 -4.68985e-01 -2.88784e-01
21Feb17_043940|   3.77655e-02 -5.72024e-01]
21Feb17_043940| [-8.37481e-01 -8.22188e-02  8.45547e-01 -5.53876e-01  5.72703e-01
21Feb17_043940|   3.09970e-01  8.96552e-01  3.97690e-01 -7.19080e-01  2.37714e-01
21Feb17_043940|   6.60752e-01  1.69435e-01]]
21Feb17_043940|-- Bias --
21Feb17_043940|[-0.28065  0.08142 -0.20194  0.96969  0.45180  0.54884  0.16606 -0.15804
21Feb17_043940|  0.47362  0.17133  0.43345 -0.35803]
21Feb17_043940|Layer 1:
21Feb17_043940|-- Config --
21Feb17_043940|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 12], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_043940|-- Weights --
21Feb17_043940|[[-0.88546  0.72941]
21Feb17_043940| [ 0.79196 -0.05477]
21Feb17_043940| [-0.89752 -0.49343]
21Feb17_043940| [ 0.78974 -0.41510]
21Feb17_043940| [ 0.29561 -0.94575]
21Feb17_043940| [-0.14754  0.69148]
21Feb17_043940| [-0.33558  0.37910]
21Feb17_043940| [-0.82387  0.15998]
21Feb17_043940| [-0.77760  0.88462]
21Feb17_043940| [ 0.98329 -0.68363]
21Feb17_043940| [ 0.88895  0.40387]
21Feb17_043940| [ 0.39015 -0.38652]]
21Feb17_043940|-- Bias --
21Feb17_043940|[ 0.28702 -0.70976]
21Feb17_043940|Predicting the validation and test data with the Best initial individual.
21Feb17_043946| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_043946|-----------  ------------------  --------------------  ----------
21Feb17_043946|Validation         42.00                  12            0.00000
21Feb17_043946|   Test            36.32                  12            0.00298
21Feb17_043946|-------------------- Test #0 --------------------
21Feb17_043946|Best final individual weights
21Feb17_043946|Individual:
21Feb17_043946|-- Constant hidden layers --
21Feb17_043946|False
21Feb17_043946|Layer 0:
21Feb17_043946|-- Config --
21Feb17_043946|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_043946|-- Weights --
21Feb17_043946|[[-0.73212  1.32861  0.10200]
21Feb17_043946| [ 1.48746 -2.97273 -0.42944]
21Feb17_043946| [ 0.53095 -1.50623  0.79224]
21Feb17_043946| [-1.07292 -0.83175 -0.90105]
21Feb17_043946| [-0.48696 -0.89325  0.27226]
21Feb17_043946| [-3.02511  0.34155 -0.03837]
21Feb17_043946| [-0.76747  0.57140 -0.46892]
21Feb17_043946| [-0.07581  0.14713  0.85910]
21Feb17_043946| [-1.37488  0.52170 -0.36205]
21Feb17_043946| [ 1.60981 -0.08727 -0.11267]
21Feb17_043946| [ 0.50986  1.58916 -0.35287]
21Feb17_043946| [-0.34599  1.27113 -0.16393]
21Feb17_043946| [ 1.29203  1.19467  0.37695]
21Feb17_043946| [ 0.58704  0.06328 -0.24240]
21Feb17_043946| [-0.93888 -0.89760  0.57087]
21Feb17_043946| [ 0.99159 -0.66387  0.35177]
21Feb17_043946| [-0.67119  1.06910 -0.12512]
21Feb17_043946| [-0.91534  1.23744 -0.40465]
21Feb17_043946| [ 1.39278  0.08069  0.23328]
21Feb17_043946| [ 0.09880  0.57603 -0.96101]
21Feb17_043946| [ 0.01621 -0.13343 -0.27624]
21Feb17_043946| [-1.28286 -2.28909  0.37931]
21Feb17_043946| [-0.28370  0.09336  0.01547]
21Feb17_043946| [-0.51894  1.84280 -0.25906]
21Feb17_043946| [-0.83075 -0.04508  0.12107]
21Feb17_043946| [ 0.37343  1.18436 -0.07358]
21Feb17_043946| [-2.38657 -0.35191  0.01962]
21Feb17_043946| [ 0.95757 -0.91760 -0.08971]
21Feb17_043946| [ 0.38792 -0.01880  0.69717]
21Feb17_043946| [ 1.66877 -0.58078 -1.21129]
21Feb17_043946| [-0.50943  0.59080  0.30856]
21Feb17_043946| [ 0.30163  1.11518  0.98185]
21Feb17_043946| [-0.73226  0.32281 -0.66712]
21Feb17_043946| [-0.62054 -2.21049  1.40981]
21Feb17_043946| [ 1.23185 -0.58090  0.35844]
21Feb17_043946| [-0.05616  0.24219 -0.02853]
21Feb17_043946| [-1.05085 -2.30259 -0.16276]
21Feb17_043946| [ 0.71087  0.14900  1.13430]
21Feb17_043946| [-2.45877 -1.20999 -1.04986]
21Feb17_043946| [-1.00480  1.36344 -0.13998]
21Feb17_043946| [ 1.83140 -0.91532  0.07616]
21Feb17_043946| [-0.60404 -2.05184  0.76948]
21Feb17_043946| [ 0.52617  0.76042 -1.76746]
21Feb17_043946| [-0.22134  0.17324  0.99530]
21Feb17_043946| [-0.36427  1.34655  0.02110]
21Feb17_043946| [-0.93125 -0.33620 -0.25012]
21Feb17_043946| [-2.76428  0.14487  0.48096]
21Feb17_043946| [-0.10518  0.35052  1.71840]
21Feb17_043946| [-1.27998  1.12568  1.26523]
21Feb17_043946| [-0.60698  1.53230 -0.60824]
21Feb17_043946| [ 0.02898  2.98718 -0.59153]
21Feb17_043946| [ 0.17588 -0.00449  0.50797]
21Feb17_043946| [-1.42674 -0.54967 -0.21310]
21Feb17_043946| [ 1.03196  1.18733  0.36755]
21Feb17_043946| [ 1.04748 -1.47444 -0.08469]
21Feb17_043946| [ 0.49410  0.38745  0.68469]
21Feb17_043946| [-0.62880  0.73245  0.19964]]
21Feb17_043946|-- Bias --
21Feb17_043946|[-0.18798  0.64571 -0.23142]
21Feb17_043946|Layer 1:
21Feb17_043946|-- Config --
21Feb17_043946|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_043946|-- Weights --
21Feb17_043946|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_043946| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_043946| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_043946|-- Bias --
21Feb17_043946|[0.60477 0.03773 0.26452 0.12222]
21Feb17_043946|Layer 2:
21Feb17_043946|-- Config --
21Feb17_043946|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_043946|-- Weights --
21Feb17_043946|[[ 0.67920  0.12119]
21Feb17_043946| [ 0.44836  0.02916]
21Feb17_043946| [ 0.68939  0.31516]
21Feb17_043946| [-0.58995 -0.05861]]
21Feb17_043946|-- Bias --
21Feb17_043946|[ 0.59649 -0.08079]
21Feb17_043946|Layer 3:
21Feb17_043946|-- Config --
21Feb17_043946|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_043946|-- Weights --
21Feb17_043946|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_043946| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_043946|-- Bias --
21Feb17_043946|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_043946|Layer 4:
21Feb17_043946|-- Config --
21Feb17_043946|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_043946|-- Weights --
21Feb17_043946|[[-0.03514 -1.04833]
21Feb17_043946| [ 1.25238  0.62094]
21Feb17_043946| [ 0.99203  0.37406]
21Feb17_043946| [ 0.49902  0.67158]
21Feb17_043946| [-1.35709  0.38335]]
21Feb17_043946|-- Bias --
21Feb17_043946|[0.31435 0.36299]
21Feb17_043946|Predicting the validation and test data with the Best final individual.
21Feb17_043954| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_043954|-----------  ------------------  --------------------  ----------
21Feb17_043954|Validation         40.17                  56            0.05627
21Feb17_043954|   Test            21.37                  56            0.70301
21Feb17_043954|-------------------- Test #1 --------------------
21Feb17_043954|Best final individual weights
21Feb17_043954|Individual:
21Feb17_043954|-- Constant hidden layers --
21Feb17_043954|False
21Feb17_043954|Layer 0:
21Feb17_043954|-- Config --
21Feb17_043954|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_043954|-- Weights --
21Feb17_043954|[[-0.73212  1.32861  0.10200]
21Feb17_043954| [ 1.48746 -2.97273 -0.42944]
21Feb17_043954| [ 0.53095 -1.50623  0.79224]
21Feb17_043954| [-1.07292 -0.83175 -0.90105]
21Feb17_043954| [-0.48696 -0.89325  0.27226]
21Feb17_043954| [-3.02511  0.34155 -0.03837]
21Feb17_043954| [-0.76747  0.57140 -0.46892]
21Feb17_043954| [-0.07581  0.14713  0.85910]
21Feb17_043954| [-1.37488  0.52170 -0.36205]
21Feb17_043954| [ 1.60981 -0.08727 -0.11267]
21Feb17_043954| [ 0.50986  1.58916 -0.35287]
21Feb17_043954| [-0.34599  1.27113 -0.16393]
21Feb17_043954| [ 1.29203  1.19467  0.37695]
21Feb17_043954| [ 0.58704  0.06328 -0.24240]
21Feb17_043954| [-0.93888 -0.89760  0.57087]
21Feb17_043954| [ 0.99159 -0.66387  0.35177]
21Feb17_043954| [-0.67119  1.06910 -0.12512]
21Feb17_043954| [-0.91534  1.23744 -0.40465]
21Feb17_043954| [ 1.39278  0.08069  0.23328]
21Feb17_043954| [ 0.09880  0.57603 -0.96101]
21Feb17_043954| [ 0.01621 -0.13343 -0.27624]
21Feb17_043954| [-1.28286 -2.28909  0.37931]
21Feb17_043954| [-0.28370  0.09336  0.01547]
21Feb17_043954| [-0.51894  1.84280 -0.25906]
21Feb17_043954| [-0.83075 -0.04508  0.12107]
21Feb17_043954| [ 0.37343  1.18436 -0.07358]
21Feb17_043954| [-2.38657 -0.35191  0.01962]
21Feb17_043954| [ 0.95757 -0.91760 -0.08971]
21Feb17_043954| [ 0.38792 -0.01880  0.69717]
21Feb17_043954| [ 1.66877 -0.58078 -1.21129]
21Feb17_043954| [-0.50943  0.59080  0.30856]
21Feb17_043954| [ 0.30163  1.11518  0.98185]
21Feb17_043954| [-0.73226  0.32281 -0.66712]
21Feb17_043954| [-0.62054 -2.21049  1.40981]
21Feb17_043954| [ 1.23185 -0.58090  0.35844]
21Feb17_043954| [-0.05616  0.24219 -0.02853]
21Feb17_043954| [-1.05085 -2.30259 -0.16276]
21Feb17_043954| [ 0.71087  0.14900  1.13430]
21Feb17_043954| [-2.45877 -1.20999 -1.04986]
21Feb17_043954| [-1.00480  1.36344 -0.13998]
21Feb17_043954| [ 1.83140 -0.91532  0.07616]
21Feb17_043954| [-0.60404 -2.05184  0.76948]
21Feb17_043954| [ 0.52617  0.76042 -1.76746]
21Feb17_043954| [-0.22134  0.17324  0.99530]
21Feb17_043954| [-0.36427  1.34655  0.02110]
21Feb17_043954| [-0.93125 -0.33620 -0.25012]
21Feb17_043954| [-2.76428  0.14487  0.48096]
21Feb17_043954| [-0.10518  0.35052  1.71840]
21Feb17_043954| [-1.27998  1.12568  1.26523]
21Feb17_043954| [-0.60698  1.53230 -0.60824]
21Feb17_043954| [ 0.02898  2.98718 -0.59153]
21Feb17_043954| [ 0.17588 -0.00449  0.50797]
21Feb17_043954| [-1.42674 -0.54967 -0.21310]
21Feb17_043954| [ 1.03196  1.18733  0.36755]
21Feb17_043954| [ 1.04748 -1.47444 -0.08469]
21Feb17_043954| [ 0.49410  0.38745  0.68469]
21Feb17_043954| [-0.62880  0.73245  0.19964]]
21Feb17_043954|-- Bias --
21Feb17_043954|[-0.18798  0.64571 -0.23142]
21Feb17_043954|Layer 1:
21Feb17_043954|-- Config --
21Feb17_043954|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_043954|-- Weights --
21Feb17_043954|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_043954| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_043954| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_043954|-- Bias --
21Feb17_043954|[0.60477 0.03773 0.26452 0.12222]
21Feb17_043954|Layer 2:
21Feb17_043954|-- Config --
21Feb17_043954|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_043954|-- Weights --
21Feb17_043954|[[ 0.67920  0.12119]
21Feb17_043954| [ 0.44836  0.02916]
21Feb17_043954| [ 0.68939  0.31516]
21Feb17_043954| [-0.58995 -0.05861]]
21Feb17_043954|-- Bias --
21Feb17_043954|[ 0.59649 -0.08079]
21Feb17_043954|Layer 3:
21Feb17_043954|-- Config --
21Feb17_043954|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_043954|-- Weights --
21Feb17_043954|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_043954| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_043954|-- Bias --
21Feb17_043954|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_043954|Layer 4:
21Feb17_043954|-- Config --
21Feb17_043954|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_043954|-- Weights --
21Feb17_043954|[[-0.03514 -1.04833]
21Feb17_043954| [ 1.25238  0.62094]
21Feb17_043954| [ 0.99203  0.37406]
21Feb17_043954| [ 0.49902  0.67158]
21Feb17_043954| [-1.35709  0.38335]]
21Feb17_043954|-- Bias --
21Feb17_043954|[0.31435 0.36299]
21Feb17_043954|Predicting the validation and test data with the Best final individual.
21Feb17_044002| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_044002|-----------  ------------------  --------------------  ----------
21Feb17_044002|Validation         23.83                  56            0.86651
21Feb17_044002|   Test            22.68                  56            0.77969
21Feb17_044002|-------------------- Test #2 --------------------
21Feb17_044002|Best final individual weights
21Feb17_044002|Individual:
21Feb17_044002|-- Constant hidden layers --
21Feb17_044002|False
21Feb17_044002|Layer 0:
21Feb17_044002|-- Config --
21Feb17_044002|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044002|-- Weights --
21Feb17_044002|[[-0.73212  1.32861  0.10200]
21Feb17_044002| [ 1.48746 -2.97273 -0.42944]
21Feb17_044002| [ 0.53095 -1.50623  0.79224]
21Feb17_044002| [-1.07292 -0.83175 -0.90105]
21Feb17_044002| [-0.48696 -0.89325  0.27226]
21Feb17_044002| [-3.02511  0.34155 -0.03837]
21Feb17_044002| [-0.76747  0.57140 -0.46892]
21Feb17_044002| [-0.07581  0.14713  0.85910]
21Feb17_044002| [-1.37488  0.52170 -0.36205]
21Feb17_044002| [ 1.60981 -0.08727 -0.11267]
21Feb17_044002| [ 0.50986  1.58916 -0.35287]
21Feb17_044002| [-0.34599  1.27113 -0.16393]
21Feb17_044002| [ 1.29203  1.19467  0.37695]
21Feb17_044002| [ 0.58704  0.06328 -0.24240]
21Feb17_044002| [-0.93888 -0.89760  0.57087]
21Feb17_044002| [ 0.99159 -0.66387  0.35177]
21Feb17_044002| [-0.67119  1.06910 -0.12512]
21Feb17_044002| [-0.91534  1.23744 -0.40465]
21Feb17_044002| [ 1.39278  0.08069  0.23328]
21Feb17_044002| [ 0.09880  0.57603 -0.96101]
21Feb17_044002| [ 0.01621 -0.13343 -0.27624]
21Feb17_044002| [-1.28286 -2.28909  0.37931]
21Feb17_044002| [-0.28370  0.09336  0.01547]
21Feb17_044002| [-0.51894  1.84280 -0.25906]
21Feb17_044002| [-0.83075 -0.04508  0.12107]
21Feb17_044002| [ 0.37343  1.18436 -0.07358]
21Feb17_044002| [-2.38657 -0.35191  0.01962]
21Feb17_044002| [ 0.95757 -0.91760 -0.08971]
21Feb17_044002| [ 0.38792 -0.01880  0.69717]
21Feb17_044002| [ 1.66877 -0.58078 -1.21129]
21Feb17_044002| [-0.50943  0.59080  0.30856]
21Feb17_044002| [ 0.30163  1.11518  0.98185]
21Feb17_044002| [-0.73226  0.32281 -0.66712]
21Feb17_044002| [-0.62054 -2.21049  1.40981]
21Feb17_044002| [ 1.23185 -0.58090  0.35844]
21Feb17_044002| [-0.05616  0.24219 -0.02853]
21Feb17_044002| [-1.05085 -2.30259 -0.16276]
21Feb17_044002| [ 0.71087  0.14900  1.13430]
21Feb17_044002| [-2.45877 -1.20999 -1.04986]
21Feb17_044002| [-1.00480  1.36344 -0.13998]
21Feb17_044002| [ 1.83140 -0.91532  0.07616]
21Feb17_044002| [-0.60404 -2.05184  0.76948]
21Feb17_044002| [ 0.52617  0.76042 -1.76746]
21Feb17_044002| [-0.22134  0.17324  0.99530]
21Feb17_044002| [-0.36427  1.34655  0.02110]
21Feb17_044002| [-0.93125 -0.33620 -0.25012]
21Feb17_044002| [-2.76428  0.14487  0.48096]
21Feb17_044002| [-0.10518  0.35052  1.71840]
21Feb17_044002| [-1.27998  1.12568  1.26523]
21Feb17_044002| [-0.60698  1.53230 -0.60824]
21Feb17_044002| [ 0.02898  2.98718 -0.59153]
21Feb17_044002| [ 0.17588 -0.00449  0.50797]
21Feb17_044002| [-1.42674 -0.54967 -0.21310]
21Feb17_044002| [ 1.03196  1.18733  0.36755]
21Feb17_044002| [ 1.04748 -1.47444 -0.08469]
21Feb17_044002| [ 0.49410  0.38745  0.68469]
21Feb17_044002| [-0.62880  0.73245  0.19964]]
21Feb17_044002|-- Bias --
21Feb17_044002|[-0.18798  0.64571 -0.23142]
21Feb17_044002|Layer 1:
21Feb17_044002|-- Config --
21Feb17_044002|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044002|-- Weights --
21Feb17_044002|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_044002| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_044002| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_044002|-- Bias --
21Feb17_044002|[0.60477 0.03773 0.26452 0.12222]
21Feb17_044002|Layer 2:
21Feb17_044002|-- Config --
21Feb17_044002|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044002|-- Weights --
21Feb17_044002|[[ 0.67920  0.12119]
21Feb17_044002| [ 0.44836  0.02916]
21Feb17_044002| [ 0.68939  0.31516]
21Feb17_044002| [-0.58995 -0.05861]]
21Feb17_044002|-- Bias --
21Feb17_044002|[ 0.59649 -0.08079]
21Feb17_044002|Layer 3:
21Feb17_044002|-- Config --
21Feb17_044002|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044002|-- Weights --
21Feb17_044002|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_044002| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_044002|-- Bias --
21Feb17_044002|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_044002|Layer 4:
21Feb17_044002|-- Config --
21Feb17_044002|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044002|-- Weights --
21Feb17_044002|[[-0.03514 -1.04833]
21Feb17_044002| [ 1.25238  0.62094]
21Feb17_044002| [ 0.99203  0.37406]
21Feb17_044002| [ 0.49902  0.67158]
21Feb17_044002| [-1.35709  0.38335]]
21Feb17_044002|-- Bias --
21Feb17_044002|[0.31435 0.36299]
21Feb17_044002|Predicting the validation and test data with the Best final individual.
21Feb17_044009| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_044009|-----------  ------------------  --------------------  ----------
21Feb17_044009|Validation         23.91                  56            0.70865
21Feb17_044009|   Test            29.45                  56            0.70270
21Feb17_044009|-------------------- Test #3 --------------------
21Feb17_044009|Best final individual weights
21Feb17_044009|Individual:
21Feb17_044009|-- Constant hidden layers --
21Feb17_044009|False
21Feb17_044009|Layer 0:
21Feb17_044009|-- Config --
21Feb17_044009|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044009|-- Weights --
21Feb17_044009|[[-0.73212  1.32861  0.10200]
21Feb17_044009| [ 1.48746 -2.97273 -0.42944]
21Feb17_044009| [ 0.53095 -1.50623  0.79224]
21Feb17_044009| [-1.07292 -0.83175 -0.90105]
21Feb17_044009| [-0.48696 -0.89325  0.27226]
21Feb17_044009| [-3.02511  0.34155 -0.03837]
21Feb17_044009| [-0.76747  0.57140 -0.46892]
21Feb17_044009| [-0.07581  0.14713  0.85910]
21Feb17_044009| [-1.37488  0.52170 -0.36205]
21Feb17_044009| [ 1.60981 -0.08727 -0.11267]
21Feb17_044009| [ 0.50986  1.58916 -0.35287]
21Feb17_044009| [-0.34599  1.27113 -0.16393]
21Feb17_044009| [ 1.29203  1.19467  0.37695]
21Feb17_044009| [ 0.58704  0.06328 -0.24240]
21Feb17_044009| [-0.93888 -0.89760  0.57087]
21Feb17_044009| [ 0.99159 -0.66387  0.35177]
21Feb17_044009| [-0.67119  1.06910 -0.12512]
21Feb17_044009| [-0.91534  1.23744 -0.40465]
21Feb17_044009| [ 1.39278  0.08069  0.23328]
21Feb17_044009| [ 0.09880  0.57603 -0.96101]
21Feb17_044009| [ 0.01621 -0.13343 -0.27624]
21Feb17_044009| [-1.28286 -2.28909  0.37931]
21Feb17_044009| [-0.28370  0.09336  0.01547]
21Feb17_044009| [-0.51894  1.84280 -0.25906]
21Feb17_044009| [-0.83075 -0.04508  0.12107]
21Feb17_044009| [ 0.37343  1.18436 -0.07358]
21Feb17_044009| [-2.38657 -0.35191  0.01962]
21Feb17_044009| [ 0.95757 -0.91760 -0.08971]
21Feb17_044009| [ 0.38792 -0.01880  0.69717]
21Feb17_044009| [ 1.66877 -0.58078 -1.21129]
21Feb17_044009| [-0.50943  0.59080  0.30856]
21Feb17_044009| [ 0.30163  1.11518  0.98185]
21Feb17_044009| [-0.73226  0.32281 -0.66712]
21Feb17_044009| [-0.62054 -2.21049  1.40981]
21Feb17_044009| [ 1.23185 -0.58090  0.35844]
21Feb17_044009| [-0.05616  0.24219 -0.02853]
21Feb17_044009| [-1.05085 -2.30259 -0.16276]
21Feb17_044009| [ 0.71087  0.14900  1.13430]
21Feb17_044009| [-2.45877 -1.20999 -1.04986]
21Feb17_044009| [-1.00480  1.36344 -0.13998]
21Feb17_044009| [ 1.83140 -0.91532  0.07616]
21Feb17_044009| [-0.60404 -2.05184  0.76948]
21Feb17_044009| [ 0.52617  0.76042 -1.76746]
21Feb17_044009| [-0.22134  0.17324  0.99530]
21Feb17_044009| [-0.36427  1.34655  0.02110]
21Feb17_044009| [-0.93125 -0.33620 -0.25012]
21Feb17_044009| [-2.76428  0.14487  0.48096]
21Feb17_044009| [-0.10518  0.35052  1.71840]
21Feb17_044009| [-1.27998  1.12568  1.26523]
21Feb17_044009| [-0.60698  1.53230 -0.60824]
21Feb17_044009| [ 0.02898  2.98718 -0.59153]
21Feb17_044009| [ 0.17588 -0.00449  0.50797]
21Feb17_044009| [-1.42674 -0.54967 -0.21310]
21Feb17_044009| [ 1.03196  1.18733  0.36755]
21Feb17_044009| [ 1.04748 -1.47444 -0.08469]
21Feb17_044009| [ 0.49410  0.38745  0.68469]
21Feb17_044009| [-0.62880  0.73245  0.19964]]
21Feb17_044009|-- Bias --
21Feb17_044009|[-0.18798  0.64571 -0.23142]
21Feb17_044009|Layer 1:
21Feb17_044009|-- Config --
21Feb17_044009|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044009|-- Weights --
21Feb17_044009|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_044009| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_044009| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_044009|-- Bias --
21Feb17_044009|[0.60477 0.03773 0.26452 0.12222]
21Feb17_044009|Layer 2:
21Feb17_044009|-- Config --
21Feb17_044009|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044009|-- Weights --
21Feb17_044009|[[ 0.67920  0.12119]
21Feb17_044009| [ 0.44836  0.02916]
21Feb17_044009| [ 0.68939  0.31516]
21Feb17_044009| [-0.58995 -0.05861]]
21Feb17_044009|-- Bias --
21Feb17_044009|[ 0.59649 -0.08079]
21Feb17_044009|Layer 3:
21Feb17_044009|-- Config --
21Feb17_044009|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044009|-- Weights --
21Feb17_044009|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_044009| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_044009|-- Bias --
21Feb17_044009|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_044009|Layer 4:
21Feb17_044009|-- Config --
21Feb17_044009|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044009|-- Weights --
21Feb17_044009|[[-0.03514 -1.04833]
21Feb17_044009| [ 1.25238  0.62094]
21Feb17_044009| [ 0.99203  0.37406]
21Feb17_044009| [ 0.49902  0.67158]
21Feb17_044009| [-1.35709  0.38335]]
21Feb17_044009|-- Bias --
21Feb17_044009|[0.31435 0.36299]
21Feb17_044009|Predicting the validation and test data with the Best final individual.
21Feb17_044017| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_044017|-----------  ------------------  --------------------  ----------
21Feb17_044017|Validation         24.35                  56            0.84577
21Feb17_044017|   Test            21.63                  56            0.70714
21Feb17_044017|-------------------- Test #4 --------------------
21Feb17_044017|Best final individual weights
21Feb17_044017|Individual:
21Feb17_044017|-- Constant hidden layers --
21Feb17_044017|False
21Feb17_044017|Layer 0:
21Feb17_044017|-- Config --
21Feb17_044017|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044017|-- Weights --
21Feb17_044017|[[-0.73212  1.32861  0.10200]
21Feb17_044017| [ 1.48746 -2.97273 -0.42944]
21Feb17_044017| [ 0.53095 -1.50623  0.79224]
21Feb17_044017| [-1.07292 -0.83175 -0.90105]
21Feb17_044017| [-0.48696 -0.89325  0.27226]
21Feb17_044017| [-3.02511  0.34155 -0.03837]
21Feb17_044017| [-0.76747  0.57140 -0.46892]
21Feb17_044017| [-0.07581  0.14713  0.85910]
21Feb17_044017| [-1.37488  0.52170 -0.36205]
21Feb17_044017| [ 1.60981 -0.08727 -0.11267]
21Feb17_044017| [ 0.50986  1.58916 -0.35287]
21Feb17_044017| [-0.34599  1.27113 -0.16393]
21Feb17_044017| [ 1.29203  1.19467  0.37695]
21Feb17_044017| [ 0.58704  0.06328 -0.24240]
21Feb17_044017| [-0.93888 -0.89760  0.57087]
21Feb17_044017| [ 0.99159 -0.66387  0.35177]
21Feb17_044017| [-0.67119  1.06910 -0.12512]
21Feb17_044017| [-0.91534  1.23744 -0.40465]
21Feb17_044017| [ 1.39278  0.08069  0.23328]
21Feb17_044017| [ 0.09880  0.57603 -0.96101]
21Feb17_044017| [ 0.01621 -0.13343 -0.27624]
21Feb17_044017| [-1.28286 -2.28909  0.37931]
21Feb17_044017| [-0.28370  0.09336  0.01547]
21Feb17_044017| [-0.51894  1.84280 -0.25906]
21Feb17_044017| [-0.83075 -0.04508  0.12107]
21Feb17_044017| [ 0.37343  1.18436 -0.07358]
21Feb17_044017| [-2.38657 -0.35191  0.01962]
21Feb17_044017| [ 0.95757 -0.91760 -0.08971]
21Feb17_044017| [ 0.38792 -0.01880  0.69717]
21Feb17_044017| [ 1.66877 -0.58078 -1.21129]
21Feb17_044017| [-0.50943  0.59080  0.30856]
21Feb17_044017| [ 0.30163  1.11518  0.98185]
21Feb17_044017| [-0.73226  0.32281 -0.66712]
21Feb17_044017| [-0.62054 -2.21049  1.40981]
21Feb17_044017| [ 1.23185 -0.58090  0.35844]
21Feb17_044017| [-0.05616  0.24219 -0.02853]
21Feb17_044017| [-1.05085 -2.30259 -0.16276]
21Feb17_044017| [ 0.71087  0.14900  1.13430]
21Feb17_044017| [-2.45877 -1.20999 -1.04986]
21Feb17_044017| [-1.00480  1.36344 -0.13998]
21Feb17_044017| [ 1.83140 -0.91532  0.07616]
21Feb17_044017| [-0.60404 -2.05184  0.76948]
21Feb17_044017| [ 0.52617  0.76042 -1.76746]
21Feb17_044017| [-0.22134  0.17324  0.99530]
21Feb17_044017| [-0.36427  1.34655  0.02110]
21Feb17_044017| [-0.93125 -0.33620 -0.25012]
21Feb17_044017| [-2.76428  0.14487  0.48096]
21Feb17_044017| [-0.10518  0.35052  1.71840]
21Feb17_044017| [-1.27998  1.12568  1.26523]
21Feb17_044017| [-0.60698  1.53230 -0.60824]
21Feb17_044017| [ 0.02898  2.98718 -0.59153]
21Feb17_044017| [ 0.17588 -0.00449  0.50797]
21Feb17_044017| [-1.42674 -0.54967 -0.21310]
21Feb17_044017| [ 1.03196  1.18733  0.36755]
21Feb17_044017| [ 1.04748 -1.47444 -0.08469]
21Feb17_044017| [ 0.49410  0.38745  0.68469]
21Feb17_044017| [-0.62880  0.73245  0.19964]]
21Feb17_044017|-- Bias --
21Feb17_044017|[-0.18798  0.64571 -0.23142]
21Feb17_044017|Layer 1:
21Feb17_044017|-- Config --
21Feb17_044017|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044017|-- Weights --
21Feb17_044017|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_044017| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_044017| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_044017|-- Bias --
21Feb17_044017|[0.60477 0.03773 0.26452 0.12222]
21Feb17_044017|Layer 2:
21Feb17_044017|-- Config --
21Feb17_044017|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044017|-- Weights --
21Feb17_044017|[[ 0.67920  0.12119]
21Feb17_044017| [ 0.44836  0.02916]
21Feb17_044017| [ 0.68939  0.31516]
21Feb17_044017| [-0.58995 -0.05861]]
21Feb17_044017|-- Bias --
21Feb17_044017|[ 0.59649 -0.08079]
21Feb17_044017|Layer 3:
21Feb17_044017|-- Config --
21Feb17_044017|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044017|-- Weights --
21Feb17_044017|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_044017| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_044017|-- Bias --
21Feb17_044017|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_044017|Layer 4:
21Feb17_044017|-- Config --
21Feb17_044017|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044017|-- Weights --
21Feb17_044017|[[-0.03514 -1.04833]
21Feb17_044017| [ 1.25238  0.62094]
21Feb17_044017| [ 0.99203  0.37406]
21Feb17_044017| [ 0.49902  0.67158]
21Feb17_044017| [-1.35709  0.38335]]
21Feb17_044017|-- Bias --
21Feb17_044017|[0.31435 0.36299]
21Feb17_044017|Predicting the validation and test data with the Best final individual.
21Feb17_044025| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_044025|-----------  ------------------  --------------------  ----------
21Feb17_044025|Validation         21.57                  56            0.82113
21Feb17_044025|   Test            31.19                  56            0.83333
21Feb17_044025|-------------------- Test #5 --------------------
21Feb17_044025|Best final individual weights
21Feb17_044025|Individual:
21Feb17_044025|-- Constant hidden layers --
21Feb17_044025|False
21Feb17_044025|Layer 0:
21Feb17_044025|-- Config --
21Feb17_044025|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044025|-- Weights --
21Feb17_044025|[[-0.73212  1.32861  0.10200]
21Feb17_044025| [ 1.48746 -2.97273 -0.42944]
21Feb17_044025| [ 0.53095 -1.50623  0.79224]
21Feb17_044025| [-1.07292 -0.83175 -0.90105]
21Feb17_044025| [-0.48696 -0.89325  0.27226]
21Feb17_044025| [-3.02511  0.34155 -0.03837]
21Feb17_044025| [-0.76747  0.57140 -0.46892]
21Feb17_044025| [-0.07581  0.14713  0.85910]
21Feb17_044025| [-1.37488  0.52170 -0.36205]
21Feb17_044025| [ 1.60981 -0.08727 -0.11267]
21Feb17_044025| [ 0.50986  1.58916 -0.35287]
21Feb17_044025| [-0.34599  1.27113 -0.16393]
21Feb17_044025| [ 1.29203  1.19467  0.37695]
21Feb17_044025| [ 0.58704  0.06328 -0.24240]
21Feb17_044025| [-0.93888 -0.89760  0.57087]
21Feb17_044025| [ 0.99159 -0.66387  0.35177]
21Feb17_044025| [-0.67119  1.06910 -0.12512]
21Feb17_044025| [-0.91534  1.23744 -0.40465]
21Feb17_044025| [ 1.39278  0.08069  0.23328]
21Feb17_044025| [ 0.09880  0.57603 -0.96101]
21Feb17_044025| [ 0.01621 -0.13343 -0.27624]
21Feb17_044025| [-1.28286 -2.28909  0.37931]
21Feb17_044025| [-0.28370  0.09336  0.01547]
21Feb17_044025| [-0.51894  1.84280 -0.25906]
21Feb17_044025| [-0.83075 -0.04508  0.12107]
21Feb17_044025| [ 0.37343  1.18436 -0.07358]
21Feb17_044025| [-2.38657 -0.35191  0.01962]
21Feb17_044025| [ 0.95757 -0.91760 -0.08971]
21Feb17_044025| [ 0.38792 -0.01880  0.69717]
21Feb17_044025| [ 1.66877 -0.58078 -1.21129]
21Feb17_044025| [-0.50943  0.59080  0.30856]
21Feb17_044025| [ 0.30163  1.11518  0.98185]
21Feb17_044025| [-0.73226  0.32281 -0.66712]
21Feb17_044025| [-0.62054 -2.21049  1.40981]
21Feb17_044025| [ 1.23185 -0.58090  0.35844]
21Feb17_044025| [-0.05616  0.24219 -0.02853]
21Feb17_044025| [-1.05085 -2.30259 -0.16276]
21Feb17_044025| [ 0.71087  0.14900  1.13430]
21Feb17_044025| [-2.45877 -1.20999 -1.04986]
21Feb17_044025| [-1.00480  1.36344 -0.13998]
21Feb17_044025| [ 1.83140 -0.91532  0.07616]
21Feb17_044025| [-0.60404 -2.05184  0.76948]
21Feb17_044025| [ 0.52617  0.76042 -1.76746]
21Feb17_044025| [-0.22134  0.17324  0.99530]
21Feb17_044025| [-0.36427  1.34655  0.02110]
21Feb17_044025| [-0.93125 -0.33620 -0.25012]
21Feb17_044025| [-2.76428  0.14487  0.48096]
21Feb17_044025| [-0.10518  0.35052  1.71840]
21Feb17_044025| [-1.27998  1.12568  1.26523]
21Feb17_044025| [-0.60698  1.53230 -0.60824]
21Feb17_044025| [ 0.02898  2.98718 -0.59153]
21Feb17_044025| [ 0.17588 -0.00449  0.50797]
21Feb17_044025| [-1.42674 -0.54967 -0.21310]
21Feb17_044025| [ 1.03196  1.18733  0.36755]
21Feb17_044025| [ 1.04748 -1.47444 -0.08469]
21Feb17_044025| [ 0.49410  0.38745  0.68469]
21Feb17_044025| [-0.62880  0.73245  0.19964]]
21Feb17_044025|-- Bias --
21Feb17_044025|[-0.18798  0.64571 -0.23142]
21Feb17_044025|Layer 1:
21Feb17_044025|-- Config --
21Feb17_044025|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044025|-- Weights --
21Feb17_044025|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_044025| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_044025| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_044025|-- Bias --
21Feb17_044025|[0.60477 0.03773 0.26452 0.12222]
21Feb17_044025|Layer 2:
21Feb17_044025|-- Config --
21Feb17_044025|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044025|-- Weights --
21Feb17_044025|[[ 0.67920  0.12119]
21Feb17_044025| [ 0.44836  0.02916]
21Feb17_044025| [ 0.68939  0.31516]
21Feb17_044025| [-0.58995 -0.05861]]
21Feb17_044025|-- Bias --
21Feb17_044025|[ 0.59649 -0.08079]
21Feb17_044025|Layer 3:
21Feb17_044025|-- Config --
21Feb17_044025|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044025|-- Weights --
21Feb17_044025|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_044025| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_044025|-- Bias --
21Feb17_044025|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_044025|Layer 4:
21Feb17_044025|-- Config --
21Feb17_044025|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044025|-- Weights --
21Feb17_044025|[[-0.03514 -1.04833]
21Feb17_044025| [ 1.25238  0.62094]
21Feb17_044025| [ 0.99203  0.37406]
21Feb17_044025| [ 0.49902  0.67158]
21Feb17_044025| [-1.35709  0.38335]]
21Feb17_044025|-- Bias --
21Feb17_044025|[0.31435 0.36299]
21Feb17_044025|Predicting the validation and test data with the Best final individual.
21Feb17_044033| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_044033|-----------  ------------------  --------------------  ----------
21Feb17_044033|Validation         23.22                  56            0.86009
21Feb17_044033|   Test            26.15                  56            0.85097
21Feb17_044033|-------------------- Test #6 --------------------
21Feb17_044033|Best final individual weights
21Feb17_044033|Individual:
21Feb17_044033|-- Constant hidden layers --
21Feb17_044033|False
21Feb17_044033|Layer 0:
21Feb17_044033|-- Config --
21Feb17_044033|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044033|-- Weights --
21Feb17_044033|[[-0.73212  1.32861  0.10200]
21Feb17_044033| [ 1.48746 -2.97273 -0.42944]
21Feb17_044033| [ 0.53095 -1.50623  0.79224]
21Feb17_044033| [-1.07292 -0.83175 -0.90105]
21Feb17_044033| [-0.48696 -0.89325  0.27226]
21Feb17_044033| [-3.02511  0.34155 -0.03837]
21Feb17_044033| [-0.76747  0.57140 -0.46892]
21Feb17_044033| [-0.07581  0.14713  0.85910]
21Feb17_044033| [-1.37488  0.52170 -0.36205]
21Feb17_044033| [ 1.60981 -0.08727 -0.11267]
21Feb17_044033| [ 0.50986  1.58916 -0.35287]
21Feb17_044033| [-0.34599  1.27113 -0.16393]
21Feb17_044033| [ 1.29203  1.19467  0.37695]
21Feb17_044033| [ 0.58704  0.06328 -0.24240]
21Feb17_044033| [-0.93888 -0.89760  0.57087]
21Feb17_044033| [ 0.99159 -0.66387  0.35177]
21Feb17_044033| [-0.67119  1.06910 -0.12512]
21Feb17_044033| [-0.91534  1.23744 -0.40465]
21Feb17_044033| [ 1.39278  0.08069  0.23328]
21Feb17_044033| [ 0.09880  0.57603 -0.96101]
21Feb17_044033| [ 0.01621 -0.13343 -0.27624]
21Feb17_044033| [-1.28286 -2.28909  0.37931]
21Feb17_044033| [-0.28370  0.09336  0.01547]
21Feb17_044033| [-0.51894  1.84280 -0.25906]
21Feb17_044033| [-0.83075 -0.04508  0.12107]
21Feb17_044033| [ 0.37343  1.18436 -0.07358]
21Feb17_044033| [-2.38657 -0.35191  0.01962]
21Feb17_044033| [ 0.95757 -0.91760 -0.08971]
21Feb17_044033| [ 0.38792 -0.01880  0.69717]
21Feb17_044033| [ 1.66877 -0.58078 -1.21129]
21Feb17_044033| [-0.50943  0.59080  0.30856]
21Feb17_044033| [ 0.30163  1.11518  0.98185]
21Feb17_044033| [-0.73226  0.32281 -0.66712]
21Feb17_044033| [-0.62054 -2.21049  1.40981]
21Feb17_044033| [ 1.23185 -0.58090  0.35844]
21Feb17_044033| [-0.05616  0.24219 -0.02853]
21Feb17_044033| [-1.05085 -2.30259 -0.16276]
21Feb17_044033| [ 0.71087  0.14900  1.13430]
21Feb17_044033| [-2.45877 -1.20999 -1.04986]
21Feb17_044033| [-1.00480  1.36344 -0.13998]
21Feb17_044033| [ 1.83140 -0.91532  0.07616]
21Feb17_044033| [-0.60404 -2.05184  0.76948]
21Feb17_044033| [ 0.52617  0.76042 -1.76746]
21Feb17_044033| [-0.22134  0.17324  0.99530]
21Feb17_044033| [-0.36427  1.34655  0.02110]
21Feb17_044033| [-0.93125 -0.33620 -0.25012]
21Feb17_044033| [-2.76428  0.14487  0.48096]
21Feb17_044033| [-0.10518  0.35052  1.71840]
21Feb17_044033| [-1.27998  1.12568  1.26523]
21Feb17_044033| [-0.60698  1.53230 -0.60824]
21Feb17_044033| [ 0.02898  2.98718 -0.59153]
21Feb17_044033| [ 0.17588 -0.00449  0.50797]
21Feb17_044033| [-1.42674 -0.54967 -0.21310]
21Feb17_044033| [ 1.03196  1.18733  0.36755]
21Feb17_044033| [ 1.04748 -1.47444 -0.08469]
21Feb17_044033| [ 0.49410  0.38745  0.68469]
21Feb17_044033| [-0.62880  0.73245  0.19964]]
21Feb17_044033|-- Bias --
21Feb17_044033|[-0.18798  0.64571 -0.23142]
21Feb17_044033|Layer 1:
21Feb17_044033|-- Config --
21Feb17_044033|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044033|-- Weights --
21Feb17_044033|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_044033| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_044033| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_044033|-- Bias --
21Feb17_044033|[0.60477 0.03773 0.26452 0.12222]
21Feb17_044033|Layer 2:
21Feb17_044033|-- Config --
21Feb17_044033|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044033|-- Weights --
21Feb17_044033|[[ 0.67920  0.12119]
21Feb17_044033| [ 0.44836  0.02916]
21Feb17_044033| [ 0.68939  0.31516]
21Feb17_044033| [-0.58995 -0.05861]]
21Feb17_044033|-- Bias --
21Feb17_044033|[ 0.59649 -0.08079]
21Feb17_044033|Layer 3:
21Feb17_044033|-- Config --
21Feb17_044033|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044033|-- Weights --
21Feb17_044033|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_044033| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_044033|-- Bias --
21Feb17_044033|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_044033|Layer 4:
21Feb17_044033|-- Config --
21Feb17_044033|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044033|-- Weights --
21Feb17_044033|[[-0.03514 -1.04833]
21Feb17_044033| [ 1.25238  0.62094]
21Feb17_044033| [ 0.99203  0.37406]
21Feb17_044033| [ 0.49902  0.67158]
21Feb17_044033| [-1.35709  0.38335]]
21Feb17_044033|-- Bias --
21Feb17_044033|[0.31435 0.36299]
21Feb17_044033|Predicting the validation and test data with the Best final individual.
21Feb17_044040| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_044040|-----------  ------------------  --------------------  ----------
21Feb17_044040|Validation         22.78                  56            0.83496
21Feb17_044040|   Test            21.11                  56            0.79855
21Feb17_044040|-------------------- Test #7 --------------------
21Feb17_044040|Best final individual weights
21Feb17_044040|Individual:
21Feb17_044040|-- Constant hidden layers --
21Feb17_044040|False
21Feb17_044040|Layer 0:
21Feb17_044040|-- Config --
21Feb17_044040|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044040|-- Weights --
21Feb17_044040|[[-0.73212  1.32861  0.10200]
21Feb17_044040| [ 1.48746 -2.97273 -0.42944]
21Feb17_044040| [ 0.53095 -1.50623  0.79224]
21Feb17_044040| [-1.07292 -0.83175 -0.90105]
21Feb17_044040| [-0.48696 -0.89325  0.27226]
21Feb17_044040| [-3.02511  0.34155 -0.03837]
21Feb17_044040| [-0.76747  0.57140 -0.46892]
21Feb17_044040| [-0.07581  0.14713  0.85910]
21Feb17_044040| [-1.37488  0.52170 -0.36205]
21Feb17_044040| [ 1.60981 -0.08727 -0.11267]
21Feb17_044040| [ 0.50986  1.58916 -0.35287]
21Feb17_044040| [-0.34599  1.27113 -0.16393]
21Feb17_044040| [ 1.29203  1.19467  0.37695]
21Feb17_044040| [ 0.58704  0.06328 -0.24240]
21Feb17_044040| [-0.93888 -0.89760  0.57087]
21Feb17_044040| [ 0.99159 -0.66387  0.35177]
21Feb17_044040| [-0.67119  1.06910 -0.12512]
21Feb17_044040| [-0.91534  1.23744 -0.40465]
21Feb17_044040| [ 1.39278  0.08069  0.23328]
21Feb17_044040| [ 0.09880  0.57603 -0.96101]
21Feb17_044040| [ 0.01621 -0.13343 -0.27624]
21Feb17_044040| [-1.28286 -2.28909  0.37931]
21Feb17_044040| [-0.28370  0.09336  0.01547]
21Feb17_044040| [-0.51894  1.84280 -0.25906]
21Feb17_044040| [-0.83075 -0.04508  0.12107]
21Feb17_044040| [ 0.37343  1.18436 -0.07358]
21Feb17_044040| [-2.38657 -0.35191  0.01962]
21Feb17_044040| [ 0.95757 -0.91760 -0.08971]
21Feb17_044040| [ 0.38792 -0.01880  0.69717]
21Feb17_044040| [ 1.66877 -0.58078 -1.21129]
21Feb17_044040| [-0.50943  0.59080  0.30856]
21Feb17_044040| [ 0.30163  1.11518  0.98185]
21Feb17_044040| [-0.73226  0.32281 -0.66712]
21Feb17_044040| [-0.62054 -2.21049  1.40981]
21Feb17_044040| [ 1.23185 -0.58090  0.35844]
21Feb17_044040| [-0.05616  0.24219 -0.02853]
21Feb17_044040| [-1.05085 -2.30259 -0.16276]
21Feb17_044040| [ 0.71087  0.14900  1.13430]
21Feb17_044040| [-2.45877 -1.20999 -1.04986]
21Feb17_044040| [-1.00480  1.36344 -0.13998]
21Feb17_044040| [ 1.83140 -0.91532  0.07616]
21Feb17_044040| [-0.60404 -2.05184  0.76948]
21Feb17_044040| [ 0.52617  0.76042 -1.76746]
21Feb17_044040| [-0.22134  0.17324  0.99530]
21Feb17_044040| [-0.36427  1.34655  0.02110]
21Feb17_044040| [-0.93125 -0.33620 -0.25012]
21Feb17_044040| [-2.76428  0.14487  0.48096]
21Feb17_044040| [-0.10518  0.35052  1.71840]
21Feb17_044040| [-1.27998  1.12568  1.26523]
21Feb17_044040| [-0.60698  1.53230 -0.60824]
21Feb17_044040| [ 0.02898  2.98718 -0.59153]
21Feb17_044040| [ 0.17588 -0.00449  0.50797]
21Feb17_044040| [-1.42674 -0.54967 -0.21310]
21Feb17_044040| [ 1.03196  1.18733  0.36755]
21Feb17_044040| [ 1.04748 -1.47444 -0.08469]
21Feb17_044040| [ 0.49410  0.38745  0.68469]
21Feb17_044040| [-0.62880  0.73245  0.19964]]
21Feb17_044040|-- Bias --
21Feb17_044040|[-0.18798  0.64571 -0.23142]
21Feb17_044040|Layer 1:
21Feb17_044040|-- Config --
21Feb17_044040|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044040|-- Weights --
21Feb17_044040|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_044040| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_044040| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_044040|-- Bias --
21Feb17_044040|[0.60477 0.03773 0.26452 0.12222]
21Feb17_044040|Layer 2:
21Feb17_044040|-- Config --
21Feb17_044040|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044040|-- Weights --
21Feb17_044040|[[ 0.67920  0.12119]
21Feb17_044040| [ 0.44836  0.02916]
21Feb17_044040| [ 0.68939  0.31516]
21Feb17_044040| [-0.58995 -0.05861]]
21Feb17_044040|-- Bias --
21Feb17_044040|[ 0.59649 -0.08079]
21Feb17_044040|Layer 3:
21Feb17_044040|-- Config --
21Feb17_044040|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044040|-- Weights --
21Feb17_044040|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_044040| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_044040|-- Bias --
21Feb17_044040|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_044040|Layer 4:
21Feb17_044040|-- Config --
21Feb17_044040|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044040|-- Weights --
21Feb17_044040|[[-0.03514 -1.04833]
21Feb17_044040| [ 1.25238  0.62094]
21Feb17_044040| [ 0.99203  0.37406]
21Feb17_044040| [ 0.49902  0.67158]
21Feb17_044040| [-1.35709  0.38335]]
21Feb17_044040|-- Bias --
21Feb17_044040|[0.31435 0.36299]
21Feb17_044040|Predicting the validation and test data with the Best final individual.
21Feb17_044048| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_044048|-----------  ------------------  --------------------  ----------
21Feb17_044048|Validation         28.96                  56            0.48780
21Feb17_044048|   Test            25.46                  56            0.49431
21Feb17_044048|-------------------- Test #8 --------------------
21Feb17_044048|Best final individual weights
21Feb17_044048|Individual:
21Feb17_044048|-- Constant hidden layers --
21Feb17_044048|False
21Feb17_044048|Layer 0:
21Feb17_044048|-- Config --
21Feb17_044048|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044048|-- Weights --
21Feb17_044048|[[-0.73212  1.32861  0.10200]
21Feb17_044048| [ 1.48746 -2.97273 -0.42944]
21Feb17_044048| [ 0.53095 -1.50623  0.79224]
21Feb17_044048| [-1.07292 -0.83175 -0.90105]
21Feb17_044048| [-0.48696 -0.89325  0.27226]
21Feb17_044048| [-3.02511  0.34155 -0.03837]
21Feb17_044048| [-0.76747  0.57140 -0.46892]
21Feb17_044048| [-0.07581  0.14713  0.85910]
21Feb17_044048| [-1.37488  0.52170 -0.36205]
21Feb17_044048| [ 1.60981 -0.08727 -0.11267]
21Feb17_044048| [ 0.50986  1.58916 -0.35287]
21Feb17_044048| [-0.34599  1.27113 -0.16393]
21Feb17_044048| [ 1.29203  1.19467  0.37695]
21Feb17_044048| [ 0.58704  0.06328 -0.24240]
21Feb17_044048| [-0.93888 -0.89760  0.57087]
21Feb17_044048| [ 0.99159 -0.66387  0.35177]
21Feb17_044048| [-0.67119  1.06910 -0.12512]
21Feb17_044048| [-0.91534  1.23744 -0.40465]
21Feb17_044048| [ 1.39278  0.08069  0.23328]
21Feb17_044048| [ 0.09880  0.57603 -0.96101]
21Feb17_044048| [ 0.01621 -0.13343 -0.27624]
21Feb17_044048| [-1.28286 -2.28909  0.37931]
21Feb17_044048| [-0.28370  0.09336  0.01547]
21Feb17_044048| [-0.51894  1.84280 -0.25906]
21Feb17_044048| [-0.83075 -0.04508  0.12107]
21Feb17_044048| [ 0.37343  1.18436 -0.07358]
21Feb17_044048| [-2.38657 -0.35191  0.01962]
21Feb17_044048| [ 0.95757 -0.91760 -0.08971]
21Feb17_044048| [ 0.38792 -0.01880  0.69717]
21Feb17_044048| [ 1.66877 -0.58078 -1.21129]
21Feb17_044048| [-0.50943  0.59080  0.30856]
21Feb17_044048| [ 0.30163  1.11518  0.98185]
21Feb17_044048| [-0.73226  0.32281 -0.66712]
21Feb17_044048| [-0.62054 -2.21049  1.40981]
21Feb17_044048| [ 1.23185 -0.58090  0.35844]
21Feb17_044048| [-0.05616  0.24219 -0.02853]
21Feb17_044048| [-1.05085 -2.30259 -0.16276]
21Feb17_044048| [ 0.71087  0.14900  1.13430]
21Feb17_044048| [-2.45877 -1.20999 -1.04986]
21Feb17_044048| [-1.00480  1.36344 -0.13998]
21Feb17_044048| [ 1.83140 -0.91532  0.07616]
21Feb17_044048| [-0.60404 -2.05184  0.76948]
21Feb17_044048| [ 0.52617  0.76042 -1.76746]
21Feb17_044048| [-0.22134  0.17324  0.99530]
21Feb17_044048| [-0.36427  1.34655  0.02110]
21Feb17_044048| [-0.93125 -0.33620 -0.25012]
21Feb17_044048| [-2.76428  0.14487  0.48096]
21Feb17_044048| [-0.10518  0.35052  1.71840]
21Feb17_044048| [-1.27998  1.12568  1.26523]
21Feb17_044048| [-0.60698  1.53230 -0.60824]
21Feb17_044048| [ 0.02898  2.98718 -0.59153]
21Feb17_044048| [ 0.17588 -0.00449  0.50797]
21Feb17_044048| [-1.42674 -0.54967 -0.21310]
21Feb17_044048| [ 1.03196  1.18733  0.36755]
21Feb17_044048| [ 1.04748 -1.47444 -0.08469]
21Feb17_044048| [ 0.49410  0.38745  0.68469]
21Feb17_044048| [-0.62880  0.73245  0.19964]]
21Feb17_044048|-- Bias --
21Feb17_044048|[-0.18798  0.64571 -0.23142]
21Feb17_044048|Layer 1:
21Feb17_044048|-- Config --
21Feb17_044048|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044048|-- Weights --
21Feb17_044048|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_044048| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_044048| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_044048|-- Bias --
21Feb17_044048|[0.60477 0.03773 0.26452 0.12222]
21Feb17_044048|Layer 2:
21Feb17_044048|-- Config --
21Feb17_044048|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044048|-- Weights --
21Feb17_044048|[[ 0.67920  0.12119]
21Feb17_044048| [ 0.44836  0.02916]
21Feb17_044048| [ 0.68939  0.31516]
21Feb17_044048| [-0.58995 -0.05861]]
21Feb17_044048|-- Bias --
21Feb17_044048|[ 0.59649 -0.08079]
21Feb17_044048|Layer 3:
21Feb17_044048|-- Config --
21Feb17_044048|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044048|-- Weights --
21Feb17_044048|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_044048| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_044048|-- Bias --
21Feb17_044048|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_044048|Layer 4:
21Feb17_044048|-- Config --
21Feb17_044048|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044048|-- Weights --
21Feb17_044048|[[-0.03514 -1.04833]
21Feb17_044048| [ 1.25238  0.62094]
21Feb17_044048| [ 0.99203  0.37406]
21Feb17_044048| [ 0.49902  0.67158]
21Feb17_044048| [-1.35709  0.38335]]
21Feb17_044048|-- Bias --
21Feb17_044048|[0.31435 0.36299]
21Feb17_044048|Predicting the validation and test data with the Best final individual.
21Feb17_044056| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_044056|-----------  ------------------  --------------------  ----------
21Feb17_044056|Validation         21.30                  56            0.82476
21Feb17_044056|   Test            21.81                  56            0.83186
21Feb17_044056|-------------------- Test #9 --------------------
21Feb17_044056|Best final individual weights
21Feb17_044056|Individual:
21Feb17_044056|-- Constant hidden layers --
21Feb17_044056|False
21Feb17_044056|Layer 0:
21Feb17_044056|-- Config --
21Feb17_044056|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044056|-- Weights --
21Feb17_044056|[[-0.73212  1.32861  0.10200]
21Feb17_044056| [ 1.48746 -2.97273 -0.42944]
21Feb17_044056| [ 0.53095 -1.50623  0.79224]
21Feb17_044056| [-1.07292 -0.83175 -0.90105]
21Feb17_044056| [-0.48696 -0.89325  0.27226]
21Feb17_044056| [-3.02511  0.34155 -0.03837]
21Feb17_044056| [-0.76747  0.57140 -0.46892]
21Feb17_044056| [-0.07581  0.14713  0.85910]
21Feb17_044056| [-1.37488  0.52170 -0.36205]
21Feb17_044056| [ 1.60981 -0.08727 -0.11267]
21Feb17_044056| [ 0.50986  1.58916 -0.35287]
21Feb17_044056| [-0.34599  1.27113 -0.16393]
21Feb17_044056| [ 1.29203  1.19467  0.37695]
21Feb17_044056| [ 0.58704  0.06328 -0.24240]
21Feb17_044056| [-0.93888 -0.89760  0.57087]
21Feb17_044056| [ 0.99159 -0.66387  0.35177]
21Feb17_044056| [-0.67119  1.06910 -0.12512]
21Feb17_044056| [-0.91534  1.23744 -0.40465]
21Feb17_044056| [ 1.39278  0.08069  0.23328]
21Feb17_044056| [ 0.09880  0.57603 -0.96101]
21Feb17_044056| [ 0.01621 -0.13343 -0.27624]
21Feb17_044056| [-1.28286 -2.28909  0.37931]
21Feb17_044056| [-0.28370  0.09336  0.01547]
21Feb17_044056| [-0.51894  1.84280 -0.25906]
21Feb17_044056| [-0.83075 -0.04508  0.12107]
21Feb17_044056| [ 0.37343  1.18436 -0.07358]
21Feb17_044056| [-2.38657 -0.35191  0.01962]
21Feb17_044056| [ 0.95757 -0.91760 -0.08971]
21Feb17_044056| [ 0.38792 -0.01880  0.69717]
21Feb17_044056| [ 1.66877 -0.58078 -1.21129]
21Feb17_044056| [-0.50943  0.59080  0.30856]
21Feb17_044056| [ 0.30163  1.11518  0.98185]
21Feb17_044056| [-0.73226  0.32281 -0.66712]
21Feb17_044056| [-0.62054 -2.21049  1.40981]
21Feb17_044056| [ 1.23185 -0.58090  0.35844]
21Feb17_044056| [-0.05616  0.24219 -0.02853]
21Feb17_044056| [-1.05085 -2.30259 -0.16276]
21Feb17_044056| [ 0.71087  0.14900  1.13430]
21Feb17_044056| [-2.45877 -1.20999 -1.04986]
21Feb17_044056| [-1.00480  1.36344 -0.13998]
21Feb17_044056| [ 1.83140 -0.91532  0.07616]
21Feb17_044056| [-0.60404 -2.05184  0.76948]
21Feb17_044056| [ 0.52617  0.76042 -1.76746]
21Feb17_044056| [-0.22134  0.17324  0.99530]
21Feb17_044056| [-0.36427  1.34655  0.02110]
21Feb17_044056| [-0.93125 -0.33620 -0.25012]
21Feb17_044056| [-2.76428  0.14487  0.48096]
21Feb17_044056| [-0.10518  0.35052  1.71840]
21Feb17_044056| [-1.27998  1.12568  1.26523]
21Feb17_044056| [-0.60698  1.53230 -0.60824]
21Feb17_044056| [ 0.02898  2.98718 -0.59153]
21Feb17_044056| [ 0.17588 -0.00449  0.50797]
21Feb17_044056| [-1.42674 -0.54967 -0.21310]
21Feb17_044056| [ 1.03196  1.18733  0.36755]
21Feb17_044056| [ 1.04748 -1.47444 -0.08469]
21Feb17_044056| [ 0.49410  0.38745  0.68469]
21Feb17_044056| [-0.62880  0.73245  0.19964]]
21Feb17_044056|-- Bias --
21Feb17_044056|[-0.18798  0.64571 -0.23142]
21Feb17_044056|Layer 1:
21Feb17_044056|-- Config --
21Feb17_044056|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044056|-- Weights --
21Feb17_044056|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_044056| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_044056| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_044056|-- Bias --
21Feb17_044056|[0.60477 0.03773 0.26452 0.12222]
21Feb17_044056|Layer 2:
21Feb17_044056|-- Config --
21Feb17_044056|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044056|-- Weights --
21Feb17_044056|[[ 0.67920  0.12119]
21Feb17_044056| [ 0.44836  0.02916]
21Feb17_044056| [ 0.68939  0.31516]
21Feb17_044056| [-0.58995 -0.05861]]
21Feb17_044056|-- Bias --
21Feb17_044056|[ 0.59649 -0.08079]
21Feb17_044056|Layer 3:
21Feb17_044056|-- Config --
21Feb17_044056|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044056|-- Weights --
21Feb17_044056|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_044056| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_044056|-- Bias --
21Feb17_044056|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_044056|Layer 4:
21Feb17_044056|-- Config --
21Feb17_044056|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044056|-- Weights --
21Feb17_044056|[[-0.03514 -1.04833]
21Feb17_044056| [ 1.25238  0.62094]
21Feb17_044056| [ 0.99203  0.37406]
21Feb17_044056| [ 0.49902  0.67158]
21Feb17_044056| [-1.35709  0.38335]]
21Feb17_044056|-- Bias --
21Feb17_044056|[0.31435 0.36299]
21Feb17_044056|Predicting the validation and test data with the Best final individual.
21Feb17_044104| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_044104|-----------  ------------------  --------------------  ----------
21Feb17_044104|Validation         26.43                  56            0.71922
21Feb17_044104|   Test            29.54                  56            0.67444
21Feb17_044104|-------------------- Test #10 --------------------
21Feb17_044104|Best final individual weights
21Feb17_044104|Individual:
21Feb17_044104|-- Constant hidden layers --
21Feb17_044104|False
21Feb17_044104|Layer 0:
21Feb17_044104|-- Config --
21Feb17_044104|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044104|-- Weights --
21Feb17_044104|[[-0.73212  1.32861  0.10200]
21Feb17_044104| [ 1.48746 -2.97273 -0.42944]
21Feb17_044104| [ 0.53095 -1.50623  0.79224]
21Feb17_044104| [-1.07292 -0.83175 -0.90105]
21Feb17_044104| [-0.48696 -0.89325  0.27226]
21Feb17_044104| [-3.02511  0.34155 -0.03837]
21Feb17_044104| [-0.76747  0.57140 -0.46892]
21Feb17_044104| [-0.07581  0.14713  0.85910]
21Feb17_044104| [-1.37488  0.52170 -0.36205]
21Feb17_044104| [ 1.60981 -0.08727 -0.11267]
21Feb17_044104| [ 0.50986  1.58916 -0.35287]
21Feb17_044104| [-0.34599  1.27113 -0.16393]
21Feb17_044104| [ 1.29203  1.19467  0.37695]
21Feb17_044104| [ 0.58704  0.06328 -0.24240]
21Feb17_044104| [-0.93888 -0.89760  0.57087]
21Feb17_044104| [ 0.99159 -0.66387  0.35177]
21Feb17_044104| [-0.67119  1.06910 -0.12512]
21Feb17_044104| [-0.91534  1.23744 -0.40465]
21Feb17_044104| [ 1.39278  0.08069  0.23328]
21Feb17_044104| [ 0.09880  0.57603 -0.96101]
21Feb17_044104| [ 0.01621 -0.13343 -0.27624]
21Feb17_044104| [-1.28286 -2.28909  0.37931]
21Feb17_044104| [-0.28370  0.09336  0.01547]
21Feb17_044104| [-0.51894  1.84280 -0.25906]
21Feb17_044104| [-0.83075 -0.04508  0.12107]
21Feb17_044104| [ 0.37343  1.18436 -0.07358]
21Feb17_044104| [-2.38657 -0.35191  0.01962]
21Feb17_044104| [ 0.95757 -0.91760 -0.08971]
21Feb17_044104| [ 0.38792 -0.01880  0.69717]
21Feb17_044104| [ 1.66877 -0.58078 -1.21129]
21Feb17_044104| [-0.50943  0.59080  0.30856]
21Feb17_044104| [ 0.30163  1.11518  0.98185]
21Feb17_044104| [-0.73226  0.32281 -0.66712]
21Feb17_044104| [-0.62054 -2.21049  1.40981]
21Feb17_044104| [ 1.23185 -0.58090  0.35844]
21Feb17_044104| [-0.05616  0.24219 -0.02853]
21Feb17_044104| [-1.05085 -2.30259 -0.16276]
21Feb17_044104| [ 0.71087  0.14900  1.13430]
21Feb17_044104| [-2.45877 -1.20999 -1.04986]
21Feb17_044104| [-1.00480  1.36344 -0.13998]
21Feb17_044104| [ 1.83140 -0.91532  0.07616]
21Feb17_044104| [-0.60404 -2.05184  0.76948]
21Feb17_044104| [ 0.52617  0.76042 -1.76746]
21Feb17_044104| [-0.22134  0.17324  0.99530]
21Feb17_044104| [-0.36427  1.34655  0.02110]
21Feb17_044104| [-0.93125 -0.33620 -0.25012]
21Feb17_044104| [-2.76428  0.14487  0.48096]
21Feb17_044104| [-0.10518  0.35052  1.71840]
21Feb17_044104| [-1.27998  1.12568  1.26523]
21Feb17_044104| [-0.60698  1.53230 -0.60824]
21Feb17_044104| [ 0.02898  2.98718 -0.59153]
21Feb17_044104| [ 0.17588 -0.00449  0.50797]
21Feb17_044104| [-1.42674 -0.54967 -0.21310]
21Feb17_044104| [ 1.03196  1.18733  0.36755]
21Feb17_044104| [ 1.04748 -1.47444 -0.08469]
21Feb17_044104| [ 0.49410  0.38745  0.68469]
21Feb17_044104| [-0.62880  0.73245  0.19964]]
21Feb17_044104|-- Bias --
21Feb17_044104|[-0.18798  0.64571 -0.23142]
21Feb17_044104|Layer 1:
21Feb17_044104|-- Config --
21Feb17_044104|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044104|-- Weights --
21Feb17_044104|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_044104| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_044104| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_044104|-- Bias --
21Feb17_044104|[0.60477 0.03773 0.26452 0.12222]
21Feb17_044104|Layer 2:
21Feb17_044104|-- Config --
21Feb17_044104|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044104|-- Weights --
21Feb17_044104|[[ 0.67920  0.12119]
21Feb17_044104| [ 0.44836  0.02916]
21Feb17_044104| [ 0.68939  0.31516]
21Feb17_044104| [-0.58995 -0.05861]]
21Feb17_044104|-- Bias --
21Feb17_044104|[ 0.59649 -0.08079]
21Feb17_044104|Layer 3:
21Feb17_044104|-- Config --
21Feb17_044104|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044104|-- Weights --
21Feb17_044104|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_044104| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_044104|-- Bias --
21Feb17_044104|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_044104|Layer 4:
21Feb17_044104|-- Config --
21Feb17_044104|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044104|-- Weights --
21Feb17_044104|[[-0.03514 -1.04833]
21Feb17_044104| [ 1.25238  0.62094]
21Feb17_044104| [ 0.99203  0.37406]
21Feb17_044104| [ 0.49902  0.67158]
21Feb17_044104| [-1.35709  0.38335]]
21Feb17_044104|-- Bias --
21Feb17_044104|[0.31435 0.36299]
21Feb17_044104|Predicting the validation and test data with the Best final individual.
21Feb17_044111| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_044111|-----------  ------------------  --------------------  ----------
21Feb17_044111|Validation         23.65                  56            0.85845
21Feb17_044111|   Test            26.67                  56            0.71298
21Feb17_044111|-------------------- Test #11 --------------------
21Feb17_044111|Best final individual weights
21Feb17_044111|Individual:
21Feb17_044111|-- Constant hidden layers --
21Feb17_044111|False
21Feb17_044111|Layer 0:
21Feb17_044111|-- Config --
21Feb17_044111|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044111|-- Weights --
21Feb17_044111|[[-0.73212  1.32861  0.10200]
21Feb17_044111| [ 1.48746 -2.97273 -0.42944]
21Feb17_044111| [ 0.53095 -1.50623  0.79224]
21Feb17_044111| [-1.07292 -0.83175 -0.90105]
21Feb17_044111| [-0.48696 -0.89325  0.27226]
21Feb17_044111| [-3.02511  0.34155 -0.03837]
21Feb17_044111| [-0.76747  0.57140 -0.46892]
21Feb17_044111| [-0.07581  0.14713  0.85910]
21Feb17_044111| [-1.37488  0.52170 -0.36205]
21Feb17_044111| [ 1.60981 -0.08727 -0.11267]
21Feb17_044111| [ 0.50986  1.58916 -0.35287]
21Feb17_044111| [-0.34599  1.27113 -0.16393]
21Feb17_044111| [ 1.29203  1.19467  0.37695]
21Feb17_044111| [ 0.58704  0.06328 -0.24240]
21Feb17_044111| [-0.93888 -0.89760  0.57087]
21Feb17_044111| [ 0.99159 -0.66387  0.35177]
21Feb17_044111| [-0.67119  1.06910 -0.12512]
21Feb17_044111| [-0.91534  1.23744 -0.40465]
21Feb17_044111| [ 1.39278  0.08069  0.23328]
21Feb17_044111| [ 0.09880  0.57603 -0.96101]
21Feb17_044111| [ 0.01621 -0.13343 -0.27624]
21Feb17_044111| [-1.28286 -2.28909  0.37931]
21Feb17_044111| [-0.28370  0.09336  0.01547]
21Feb17_044111| [-0.51894  1.84280 -0.25906]
21Feb17_044111| [-0.83075 -0.04508  0.12107]
21Feb17_044111| [ 0.37343  1.18436 -0.07358]
21Feb17_044111| [-2.38657 -0.35191  0.01962]
21Feb17_044111| [ 0.95757 -0.91760 -0.08971]
21Feb17_044111| [ 0.38792 -0.01880  0.69717]
21Feb17_044111| [ 1.66877 -0.58078 -1.21129]
21Feb17_044111| [-0.50943  0.59080  0.30856]
21Feb17_044111| [ 0.30163  1.11518  0.98185]
21Feb17_044111| [-0.73226  0.32281 -0.66712]
21Feb17_044111| [-0.62054 -2.21049  1.40981]
21Feb17_044111| [ 1.23185 -0.58090  0.35844]
21Feb17_044111| [-0.05616  0.24219 -0.02853]
21Feb17_044111| [-1.05085 -2.30259 -0.16276]
21Feb17_044111| [ 0.71087  0.14900  1.13430]
21Feb17_044111| [-2.45877 -1.20999 -1.04986]
21Feb17_044111| [-1.00480  1.36344 -0.13998]
21Feb17_044111| [ 1.83140 -0.91532  0.07616]
21Feb17_044111| [-0.60404 -2.05184  0.76948]
21Feb17_044111| [ 0.52617  0.76042 -1.76746]
21Feb17_044111| [-0.22134  0.17324  0.99530]
21Feb17_044111| [-0.36427  1.34655  0.02110]
21Feb17_044111| [-0.93125 -0.33620 -0.25012]
21Feb17_044111| [-2.76428  0.14487  0.48096]
21Feb17_044111| [-0.10518  0.35052  1.71840]
21Feb17_044111| [-1.27998  1.12568  1.26523]
21Feb17_044111| [-0.60698  1.53230 -0.60824]
21Feb17_044111| [ 0.02898  2.98718 -0.59153]
21Feb17_044111| [ 0.17588 -0.00449  0.50797]
21Feb17_044111| [-1.42674 -0.54967 -0.21310]
21Feb17_044111| [ 1.03196  1.18733  0.36755]
21Feb17_044111| [ 1.04748 -1.47444 -0.08469]
21Feb17_044111| [ 0.49410  0.38745  0.68469]
21Feb17_044111| [-0.62880  0.73245  0.19964]]
21Feb17_044111|-- Bias --
21Feb17_044111|[-0.18798  0.64571 -0.23142]
21Feb17_044111|Layer 1:
21Feb17_044111|-- Config --
21Feb17_044111|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044111|-- Weights --
21Feb17_044111|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_044111| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_044111| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_044111|-- Bias --
21Feb17_044111|[0.60477 0.03773 0.26452 0.12222]
21Feb17_044111|Layer 2:
21Feb17_044111|-- Config --
21Feb17_044111|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044111|-- Weights --
21Feb17_044111|[[ 0.67920  0.12119]
21Feb17_044111| [ 0.44836  0.02916]
21Feb17_044111| [ 0.68939  0.31516]
21Feb17_044111| [-0.58995 -0.05861]]
21Feb17_044111|-- Bias --
21Feb17_044111|[ 0.59649 -0.08079]
21Feb17_044111|Layer 3:
21Feb17_044111|-- Config --
21Feb17_044111|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044111|-- Weights --
21Feb17_044111|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_044111| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_044111|-- Bias --
21Feb17_044111|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_044111|Layer 4:
21Feb17_044111|-- Config --
21Feb17_044111|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044111|-- Weights --
21Feb17_044111|[[-0.03514 -1.04833]
21Feb17_044111| [ 1.25238  0.62094]
21Feb17_044111| [ 0.99203  0.37406]
21Feb17_044111| [ 0.49902  0.67158]
21Feb17_044111| [-1.35709  0.38335]]
21Feb17_044111|-- Bias --
21Feb17_044111|[0.31435 0.36299]
21Feb17_044111|Predicting the validation and test data with the Best final individual.
21Feb17_044119| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_044119|-----------  ------------------  --------------------  ----------
21Feb17_044119|Validation         23.48                  56            0.78306
21Feb17_044119|   Test            22.07                  56            0.85403
21Feb17_044119|-------------------- Test #12 --------------------
21Feb17_044119|Best final individual weights
21Feb17_044119|Individual:
21Feb17_044119|-- Constant hidden layers --
21Feb17_044119|False
21Feb17_044119|Layer 0:
21Feb17_044119|-- Config --
21Feb17_044119|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044119|-- Weights --
21Feb17_044119|[[-0.73212  1.32861  0.10200]
21Feb17_044119| [ 1.48746 -2.97273 -0.42944]
21Feb17_044119| [ 0.53095 -1.50623  0.79224]
21Feb17_044119| [-1.07292 -0.83175 -0.90105]
21Feb17_044119| [-0.48696 -0.89325  0.27226]
21Feb17_044119| [-3.02511  0.34155 -0.03837]
21Feb17_044119| [-0.76747  0.57140 -0.46892]
21Feb17_044119| [-0.07581  0.14713  0.85910]
21Feb17_044119| [-1.37488  0.52170 -0.36205]
21Feb17_044119| [ 1.60981 -0.08727 -0.11267]
21Feb17_044119| [ 0.50986  1.58916 -0.35287]
21Feb17_044119| [-0.34599  1.27113 -0.16393]
21Feb17_044119| [ 1.29203  1.19467  0.37695]
21Feb17_044119| [ 0.58704  0.06328 -0.24240]
21Feb17_044119| [-0.93888 -0.89760  0.57087]
21Feb17_044119| [ 0.99159 -0.66387  0.35177]
21Feb17_044119| [-0.67119  1.06910 -0.12512]
21Feb17_044119| [-0.91534  1.23744 -0.40465]
21Feb17_044119| [ 1.39278  0.08069  0.23328]
21Feb17_044119| [ 0.09880  0.57603 -0.96101]
21Feb17_044119| [ 0.01621 -0.13343 -0.27624]
21Feb17_044119| [-1.28286 -2.28909  0.37931]
21Feb17_044119| [-0.28370  0.09336  0.01547]
21Feb17_044119| [-0.51894  1.84280 -0.25906]
21Feb17_044119| [-0.83075 -0.04508  0.12107]
21Feb17_044119| [ 0.37343  1.18436 -0.07358]
21Feb17_044119| [-2.38657 -0.35191  0.01962]
21Feb17_044119| [ 0.95757 -0.91760 -0.08971]
21Feb17_044119| [ 0.38792 -0.01880  0.69717]
21Feb17_044119| [ 1.66877 -0.58078 -1.21129]
21Feb17_044119| [-0.50943  0.59080  0.30856]
21Feb17_044119| [ 0.30163  1.11518  0.98185]
21Feb17_044119| [-0.73226  0.32281 -0.66712]
21Feb17_044119| [-0.62054 -2.21049  1.40981]
21Feb17_044119| [ 1.23185 -0.58090  0.35844]
21Feb17_044119| [-0.05616  0.24219 -0.02853]
21Feb17_044119| [-1.05085 -2.30259 -0.16276]
21Feb17_044119| [ 0.71087  0.14900  1.13430]
21Feb17_044119| [-2.45877 -1.20999 -1.04986]
21Feb17_044119| [-1.00480  1.36344 -0.13998]
21Feb17_044119| [ 1.83140 -0.91532  0.07616]
21Feb17_044119| [-0.60404 -2.05184  0.76948]
21Feb17_044119| [ 0.52617  0.76042 -1.76746]
21Feb17_044119| [-0.22134  0.17324  0.99530]
21Feb17_044119| [-0.36427  1.34655  0.02110]
21Feb17_044119| [-0.93125 -0.33620 -0.25012]
21Feb17_044119| [-2.76428  0.14487  0.48096]
21Feb17_044119| [-0.10518  0.35052  1.71840]
21Feb17_044119| [-1.27998  1.12568  1.26523]
21Feb17_044119| [-0.60698  1.53230 -0.60824]
21Feb17_044119| [ 0.02898  2.98718 -0.59153]
21Feb17_044119| [ 0.17588 -0.00449  0.50797]
21Feb17_044119| [-1.42674 -0.54967 -0.21310]
21Feb17_044119| [ 1.03196  1.18733  0.36755]
21Feb17_044119| [ 1.04748 -1.47444 -0.08469]
21Feb17_044119| [ 0.49410  0.38745  0.68469]
21Feb17_044119| [-0.62880  0.73245  0.19964]]
21Feb17_044119|-- Bias --
21Feb17_044119|[-0.18798  0.64571 -0.23142]
21Feb17_044119|Layer 1:
21Feb17_044119|-- Config --
21Feb17_044119|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044119|-- Weights --
21Feb17_044119|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_044119| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_044119| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_044119|-- Bias --
21Feb17_044119|[0.60477 0.03773 0.26452 0.12222]
21Feb17_044119|Layer 2:
21Feb17_044119|-- Config --
21Feb17_044119|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044119|-- Weights --
21Feb17_044119|[[ 0.67920  0.12119]
21Feb17_044119| [ 0.44836  0.02916]
21Feb17_044119| [ 0.68939  0.31516]
21Feb17_044119| [-0.58995 -0.05861]]
21Feb17_044119|-- Bias --
21Feb17_044119|[ 0.59649 -0.08079]
21Feb17_044119|Layer 3:
21Feb17_044119|-- Config --
21Feb17_044119|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044119|-- Weights --
21Feb17_044119|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_044119| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_044119|-- Bias --
21Feb17_044119|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_044119|Layer 4:
21Feb17_044119|-- Config --
21Feb17_044119|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044119|-- Weights --
21Feb17_044119|[[-0.03514 -1.04833]
21Feb17_044119| [ 1.25238  0.62094]
21Feb17_044119| [ 0.99203  0.37406]
21Feb17_044119| [ 0.49902  0.67158]
21Feb17_044119| [-1.35709  0.38335]]
21Feb17_044119|-- Bias --
21Feb17_044119|[0.31435 0.36299]
21Feb17_044119|Predicting the validation and test data with the Best final individual.
21Feb17_044127| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_044127|-----------  ------------------  --------------------  ----------
21Feb17_044127|Validation         24.43                  56            0.85301
21Feb17_044127|   Test            37.01                  56            0.82036
21Feb17_044127|-------------------- Test #13 --------------------
21Feb17_044127|Best final individual weights
21Feb17_044127|Individual:
21Feb17_044127|-- Constant hidden layers --
21Feb17_044127|False
21Feb17_044127|Layer 0:
21Feb17_044127|-- Config --
21Feb17_044127|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044127|-- Weights --
21Feb17_044127|[[-0.73212  1.32861  0.10200]
21Feb17_044127| [ 1.48746 -2.97273 -0.42944]
21Feb17_044127| [ 0.53095 -1.50623  0.79224]
21Feb17_044127| [-1.07292 -0.83175 -0.90105]
21Feb17_044127| [-0.48696 -0.89325  0.27226]
21Feb17_044127| [-3.02511  0.34155 -0.03837]
21Feb17_044127| [-0.76747  0.57140 -0.46892]
21Feb17_044127| [-0.07581  0.14713  0.85910]
21Feb17_044127| [-1.37488  0.52170 -0.36205]
21Feb17_044127| [ 1.60981 -0.08727 -0.11267]
21Feb17_044127| [ 0.50986  1.58916 -0.35287]
21Feb17_044127| [-0.34599  1.27113 -0.16393]
21Feb17_044127| [ 1.29203  1.19467  0.37695]
21Feb17_044127| [ 0.58704  0.06328 -0.24240]
21Feb17_044127| [-0.93888 -0.89760  0.57087]
21Feb17_044127| [ 0.99159 -0.66387  0.35177]
21Feb17_044127| [-0.67119  1.06910 -0.12512]
21Feb17_044127| [-0.91534  1.23744 -0.40465]
21Feb17_044127| [ 1.39278  0.08069  0.23328]
21Feb17_044127| [ 0.09880  0.57603 -0.96101]
21Feb17_044127| [ 0.01621 -0.13343 -0.27624]
21Feb17_044127| [-1.28286 -2.28909  0.37931]
21Feb17_044127| [-0.28370  0.09336  0.01547]
21Feb17_044127| [-0.51894  1.84280 -0.25906]
21Feb17_044127| [-0.83075 -0.04508  0.12107]
21Feb17_044127| [ 0.37343  1.18436 -0.07358]
21Feb17_044127| [-2.38657 -0.35191  0.01962]
21Feb17_044127| [ 0.95757 -0.91760 -0.08971]
21Feb17_044127| [ 0.38792 -0.01880  0.69717]
21Feb17_044127| [ 1.66877 -0.58078 -1.21129]
21Feb17_044127| [-0.50943  0.59080  0.30856]
21Feb17_044127| [ 0.30163  1.11518  0.98185]
21Feb17_044127| [-0.73226  0.32281 -0.66712]
21Feb17_044127| [-0.62054 -2.21049  1.40981]
21Feb17_044127| [ 1.23185 -0.58090  0.35844]
21Feb17_044127| [-0.05616  0.24219 -0.02853]
21Feb17_044127| [-1.05085 -2.30259 -0.16276]
21Feb17_044127| [ 0.71087  0.14900  1.13430]
21Feb17_044127| [-2.45877 -1.20999 -1.04986]
21Feb17_044127| [-1.00480  1.36344 -0.13998]
21Feb17_044127| [ 1.83140 -0.91532  0.07616]
21Feb17_044127| [-0.60404 -2.05184  0.76948]
21Feb17_044127| [ 0.52617  0.76042 -1.76746]
21Feb17_044127| [-0.22134  0.17324  0.99530]
21Feb17_044127| [-0.36427  1.34655  0.02110]
21Feb17_044127| [-0.93125 -0.33620 -0.25012]
21Feb17_044127| [-2.76428  0.14487  0.48096]
21Feb17_044127| [-0.10518  0.35052  1.71840]
21Feb17_044127| [-1.27998  1.12568  1.26523]
21Feb17_044127| [-0.60698  1.53230 -0.60824]
21Feb17_044127| [ 0.02898  2.98718 -0.59153]
21Feb17_044127| [ 0.17588 -0.00449  0.50797]
21Feb17_044127| [-1.42674 -0.54967 -0.21310]
21Feb17_044127| [ 1.03196  1.18733  0.36755]
21Feb17_044127| [ 1.04748 -1.47444 -0.08469]
21Feb17_044127| [ 0.49410  0.38745  0.68469]
21Feb17_044127| [-0.62880  0.73245  0.19964]]
21Feb17_044127|-- Bias --
21Feb17_044127|[-0.18798  0.64571 -0.23142]
21Feb17_044127|Layer 1:
21Feb17_044127|-- Config --
21Feb17_044127|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044127|-- Weights --
21Feb17_044127|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_044127| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_044127| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_044127|-- Bias --
21Feb17_044127|[0.60477 0.03773 0.26452 0.12222]
21Feb17_044127|Layer 2:
21Feb17_044127|-- Config --
21Feb17_044127|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044127|-- Weights --
21Feb17_044127|[[ 0.67920  0.12119]
21Feb17_044127| [ 0.44836  0.02916]
21Feb17_044127| [ 0.68939  0.31516]
21Feb17_044127| [-0.58995 -0.05861]]
21Feb17_044127|-- Bias --
21Feb17_044127|[ 0.59649 -0.08079]
21Feb17_044127|Layer 3:
21Feb17_044127|-- Config --
21Feb17_044127|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044127|-- Weights --
21Feb17_044127|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_044127| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_044127|-- Bias --
21Feb17_044127|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_044127|Layer 4:
21Feb17_044127|-- Config --
21Feb17_044127|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044127|-- Weights --
21Feb17_044127|[[-0.03514 -1.04833]
21Feb17_044127| [ 1.25238  0.62094]
21Feb17_044127| [ 0.99203  0.37406]
21Feb17_044127| [ 0.49902  0.67158]
21Feb17_044127| [-1.35709  0.38335]]
21Feb17_044127|-- Bias --
21Feb17_044127|[0.31435 0.36299]
21Feb17_044127|Predicting the validation and test data with the Best final individual.
21Feb17_044134| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_044134|-----------  ------------------  --------------------  ----------
21Feb17_044134|Validation         21.74                  56            0.74120
21Feb17_044134|   Test            25.80                  56            0.72926
21Feb17_044134|-------------------- Test #14 --------------------
21Feb17_044134|Best final individual weights
21Feb17_044134|Individual:
21Feb17_044134|-- Constant hidden layers --
21Feb17_044134|False
21Feb17_044134|Layer 0:
21Feb17_044134|-- Config --
21Feb17_044134|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044134|-- Weights --
21Feb17_044134|[[-0.73212  1.32861  0.10200]
21Feb17_044134| [ 1.48746 -2.97273 -0.42944]
21Feb17_044134| [ 0.53095 -1.50623  0.79224]
21Feb17_044134| [-1.07292 -0.83175 -0.90105]
21Feb17_044134| [-0.48696 -0.89325  0.27226]
21Feb17_044134| [-3.02511  0.34155 -0.03837]
21Feb17_044134| [-0.76747  0.57140 -0.46892]
21Feb17_044134| [-0.07581  0.14713  0.85910]
21Feb17_044134| [-1.37488  0.52170 -0.36205]
21Feb17_044134| [ 1.60981 -0.08727 -0.11267]
21Feb17_044134| [ 0.50986  1.58916 -0.35287]
21Feb17_044134| [-0.34599  1.27113 -0.16393]
21Feb17_044134| [ 1.29203  1.19467  0.37695]
21Feb17_044134| [ 0.58704  0.06328 -0.24240]
21Feb17_044134| [-0.93888 -0.89760  0.57087]
21Feb17_044134| [ 0.99159 -0.66387  0.35177]
21Feb17_044134| [-0.67119  1.06910 -0.12512]
21Feb17_044134| [-0.91534  1.23744 -0.40465]
21Feb17_044134| [ 1.39278  0.08069  0.23328]
21Feb17_044134| [ 0.09880  0.57603 -0.96101]
21Feb17_044134| [ 0.01621 -0.13343 -0.27624]
21Feb17_044134| [-1.28286 -2.28909  0.37931]
21Feb17_044134| [-0.28370  0.09336  0.01547]
21Feb17_044134| [-0.51894  1.84280 -0.25906]
21Feb17_044134| [-0.83075 -0.04508  0.12107]
21Feb17_044134| [ 0.37343  1.18436 -0.07358]
21Feb17_044134| [-2.38657 -0.35191  0.01962]
21Feb17_044134| [ 0.95757 -0.91760 -0.08971]
21Feb17_044134| [ 0.38792 -0.01880  0.69717]
21Feb17_044134| [ 1.66877 -0.58078 -1.21129]
21Feb17_044134| [-0.50943  0.59080  0.30856]
21Feb17_044134| [ 0.30163  1.11518  0.98185]
21Feb17_044134| [-0.73226  0.32281 -0.66712]
21Feb17_044134| [-0.62054 -2.21049  1.40981]
21Feb17_044134| [ 1.23185 -0.58090  0.35844]
21Feb17_044134| [-0.05616  0.24219 -0.02853]
21Feb17_044134| [-1.05085 -2.30259 -0.16276]
21Feb17_044134| [ 0.71087  0.14900  1.13430]
21Feb17_044134| [-2.45877 -1.20999 -1.04986]
21Feb17_044134| [-1.00480  1.36344 -0.13998]
21Feb17_044134| [ 1.83140 -0.91532  0.07616]
21Feb17_044134| [-0.60404 -2.05184  0.76948]
21Feb17_044134| [ 0.52617  0.76042 -1.76746]
21Feb17_044134| [-0.22134  0.17324  0.99530]
21Feb17_044134| [-0.36427  1.34655  0.02110]
21Feb17_044134| [-0.93125 -0.33620 -0.25012]
21Feb17_044134| [-2.76428  0.14487  0.48096]
21Feb17_044134| [-0.10518  0.35052  1.71840]
21Feb17_044134| [-1.27998  1.12568  1.26523]
21Feb17_044134| [-0.60698  1.53230 -0.60824]
21Feb17_044134| [ 0.02898  2.98718 -0.59153]
21Feb17_044134| [ 0.17588 -0.00449  0.50797]
21Feb17_044134| [-1.42674 -0.54967 -0.21310]
21Feb17_044134| [ 1.03196  1.18733  0.36755]
21Feb17_044134| [ 1.04748 -1.47444 -0.08469]
21Feb17_044134| [ 0.49410  0.38745  0.68469]
21Feb17_044134| [-0.62880  0.73245  0.19964]]
21Feb17_044134|-- Bias --
21Feb17_044134|[-0.18798  0.64571 -0.23142]
21Feb17_044134|Layer 1:
21Feb17_044134|-- Config --
21Feb17_044134|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044134|-- Weights --
21Feb17_044134|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_044134| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_044134| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_044134|-- Bias --
21Feb17_044134|[0.60477 0.03773 0.26452 0.12222]
21Feb17_044134|Layer 2:
21Feb17_044134|-- Config --
21Feb17_044134|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044134|-- Weights --
21Feb17_044134|[[ 0.67920  0.12119]
21Feb17_044134| [ 0.44836  0.02916]
21Feb17_044134| [ 0.68939  0.31516]
21Feb17_044134| [-0.58995 -0.05861]]
21Feb17_044134|-- Bias --
21Feb17_044134|[ 0.59649 -0.08079]
21Feb17_044134|Layer 3:
21Feb17_044134|-- Config --
21Feb17_044134|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044134|-- Weights --
21Feb17_044134|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_044134| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_044134|-- Bias --
21Feb17_044134|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_044134|Layer 4:
21Feb17_044134|-- Config --
21Feb17_044134|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_044134|-- Weights --
21Feb17_044134|[[-0.03514 -1.04833]
21Feb17_044134| [ 1.25238  0.62094]
21Feb17_044134| [ 0.99203  0.37406]
21Feb17_044134| [ 0.49902  0.67158]
21Feb17_044134| [-1.35709  0.38335]]
21Feb17_044134|-- Bias --
21Feb17_044134|[0.31435 0.36299]
21Feb17_044134|Predicting the validation and test data with the Best final individual.
21Feb17_044142| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_044142|-----------  ------------------  --------------------  ----------
21Feb17_044142|Validation         22.70                  56            0.74363
21Feb17_044142|   Test            19.46                  56            0.73101
Using Theano backend.
WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.
2021-02-17 04:41:45.146492: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-02-17 04:41:45.146551: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
21Feb17_044146|Data summary: Train
21Feb17_044146|data.shape = (2300, 57)
21Feb17_044146|labels.shape = (2300,)
21Feb17_044146|Class distribution:
21Feb17_044146|	0 - 1389 (0.60)
21Feb17_044146|	1 - 911 (0.40)
21Feb17_044146|Data summary: Validation
21Feb17_044146|data.shape = (1150, 57)
21Feb17_044146|labels.shape = (1150,)
21Feb17_044146|Class distribution:
21Feb17_044146|	0 - 667 (0.58)
21Feb17_044146|	1 - 483 (0.42)
21Feb17_044146|Data summary: Test
21Feb17_044146|data.shape = (1151, 57)
21Feb17_044146|labels.shape = (1151,)
21Feb17_044146|Class distribution:
21Feb17_044146|	0 - 732 (0.64)
21Feb17_044146|	1 - 419 (0.36)
21Feb17_044146|Selected configuration values
21Feb17_044146|-- Dataset name: spambase2
21Feb17_044146|-- Initial population size: 64
21Feb17_044146|-- Maximun number of generations: 32
21Feb17_044146|-- Neurons per hidden layer range: (2, 20)
21Feb17_044146|-- Hidden layers number range: (1, 3)
21Feb17_044146|-- Crossover probability: 0.5
21Feb17_044146|-- Bias gene mutation probability: 0.2
21Feb17_044146|-- Weights gene mutation probability: 0.75
21Feb17_044146|-- Neuron mutation probability: 0.3
21Feb17_044146|-- Layer mutation probability: 0.3
21Feb17_044146|-- Constant hidden layers: False
21Feb17_044146|-- Seed: 31415
21Feb17_044146|Entering GA
21Feb17_044146|Start the algorithm
21Feb17_044527|-- Generation 1 --
21Feb17_044527|    -- Crossed 0 individual pairs.
21Feb17_044527|    -- Mutated 32 individuals.
21Feb17_044847|    -- Evaluated 64 individuals.
21Feb17_044847|    Summary of generation 1:
21Feb17_044847| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_044847|-----------  ------------------  --------------------  ----------
21Feb17_044847|    Max            42.70                78.00           0.43478
21Feb17_044847|    Avg            41.90                26.28           0.00941
21Feb17_044847|    Min            35.91                 2.00           0.00000
21Feb17_044847|    Std             0.81                18.75           0.05509
21Feb17_044847|   Best            35.91                18.00           0.43478
21Feb17_044847|-- Generation 2 --
21Feb17_044847|    -- Crossed 1 individual pairs.
21Feb17_044847|    -- Mutated 32 individuals.
21Feb17_045202|    -- Evaluated 64 individuals.
21Feb17_045202|    Summary of generation 2:
21Feb17_045202| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_045202|-----------  ------------------  --------------------  ----------
21Feb17_045202|    Max            58.00                84.00           0.79977
21Feb17_045202|    Avg            41.99                15.92           0.02879
21Feb17_045202|    Min            29.65                 2.00           0.00000
21Feb17_045202|    Std             2.55                13.60           0.13781
21Feb17_045202|   Best            29.65                18.00           0.79977
21Feb17_045202|-- Generation 3 --
21Feb17_045202|    -- Crossed 3 individual pairs.
21Feb17_045202|    -- Mutated 32 individuals.
21Feb17_045511|    -- Evaluated 64 individuals.
21Feb17_045511|    Summary of generation 3:
21Feb17_045511| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_045511|-----------  ------------------  --------------------  ----------
21Feb17_045511|    Max            58.00                50.00           0.78358
21Feb17_045511|    Avg            41.97                13.73           0.02564
21Feb17_045511|    Min            26.09                 2.00           0.00000
21Feb17_045511|    Std             2.83                12.88           0.13211
21Feb17_045511|   Best            26.09                18.00           0.73476
21Feb17_045511|-- Generation 4 --
21Feb17_045511|    -- Crossed 4 individual pairs.
21Feb17_045511|    -- Mutated 32 individuals.
21Feb17_045818|    -- Evaluated 64 individuals.
21Feb17_045818|    Summary of generation 4:
21Feb17_045818| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_045818|-----------  ------------------  --------------------  ----------
21Feb17_045818|    Max            42.17                63.00           0.00517
21Feb17_045818|    Avg            42.01                 8.34           0.00085
21Feb17_045818|    Min            41.91                 2.00           0.00000
21Feb17_045818|    Std             0.06                 9.60           0.00165
21Feb17_045818|   Best            41.91                 4.00           0.00517
21Feb17_045818|-- Generation 5 --
21Feb17_045818|    -- Crossed 6 individual pairs.
21Feb17_045818|    -- Mutated 32 individuals.
21Feb17_050122|    -- Evaluated 64 individuals.
21Feb17_050122|    Summary of generation 5:
21Feb17_050122| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_050122|-----------  ------------------  --------------------  ----------
21Feb17_050122|    Max            42.09                20.00           0.05344
21Feb17_050122|    Avg            41.98                 5.28           0.00172
21Feb17_050122|    Min            41.22                 2.00           0.00000
21Feb17_050122|    Std             0.11                 4.46           0.00681
21Feb17_050122|   Best            41.22                14.00           0.05344
21Feb17_050122|-- Generation 6 --
21Feb17_050122|    -- Crossed 7 individual pairs.
21Feb17_050122|    -- Mutated 32 individuals.
21Feb17_050426|    -- Evaluated 64 individuals.
21Feb17_050426|    Summary of generation 6:
21Feb17_050426| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_050426|-----------  ------------------  --------------------  ----------
21Feb17_050426|    Max            42.26                18.00           0.01548
21Feb17_050426|    Avg            41.99                 6.00           0.00105
21Feb17_050426|    Min            41.48                 2.00           0.00000
21Feb17_050426|    Std             0.09                 4.81           0.00231
21Feb17_050426|   Best            41.48                 3.00           0.01548
21Feb17_050426|-- Generation 7 --
21Feb17_050426|    -- Crossed 9 individual pairs.
21Feb17_050426|    -- Mutated 32 individuals.
21Feb17_050733|    -- Evaluated 64 individuals.
21Feb17_050733|    Summary of generation 7:
21Feb17_050733| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_050733|-----------  ------------------  --------------------  ----------
21Feb17_050733|    Max            42.09                36.00           0.01033
21Feb17_050733|    Avg            41.99                 5.98           0.00089
21Feb17_050733|    Min            41.65                 2.00           0.00000
21Feb17_050733|    Std             0.06                 6.14           0.00184
21Feb17_050733|   Best            41.65                 3.00           0.01033
21Feb17_050733|-- Generation 8 --
21Feb17_050733|    -- Crossed 9 individual pairs.
21Feb17_050733|    -- Mutated 32 individuals.
21Feb17_051038|    -- Evaluated 64 individuals.
21Feb17_051038|    Summary of generation 8:
21Feb17_051038| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_051038|-----------  ------------------  --------------------  ----------
21Feb17_051038|    Max            42.17                18.00           0.04103
21Feb17_051038|    Avg            41.97                 5.09           0.00169
21Feb17_051038|    Min            40.78                 2.00           0.00000
21Feb17_051038|    Std             0.16                 4.37           0.00529
21Feb17_051038|   Best            40.78                12.00           0.04103
21Feb17_051038|-- Generation 9 --
21Feb17_051038|    -- Crossed 8 individual pairs.
21Feb17_051038|    -- Mutated 32 individuals.
21Feb17_051346|    -- Evaluated 64 individuals.
21Feb17_051346|    Summary of generation 9:
21Feb17_051346| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_051346|-----------  ------------------  --------------------  ----------
21Feb17_051346|    Max            48.87                18.00           0.80667
21Feb17_051346|    Avg            41.71                 6.17           0.03823
21Feb17_051346|    Min            30.61                 2.00           0.00000
21Feb17_051346|    Std             2.17                 5.04           0.16210
21Feb17_051346|   Best            30.61                 8.00           0.78607
21Feb17_051346|-- Generation 10 --
21Feb17_051346|    -- Crossed 5 individual pairs.
21Feb17_051346|    -- Mutated 32 individuals.
21Feb17_051654|    -- Evaluated 64 individuals.
21Feb17_051654|    Summary of generation 10:
21Feb17_051654| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_051654|-----------  ------------------  --------------------  ----------
21Feb17_051654|    Max            42.26                18.00           0.58344
21Feb17_051654|    Avg            41.43                 6.23           0.02714
21Feb17_051654|    Min            27.74                 2.00           0.00000
21Feb17_051654|    Std             2.43                 4.89           0.10887
21Feb17_051654|   Best            27.74                18.00           0.51616
21Feb17_051654|-- Generation 11 --
21Feb17_051654|    -- Crossed 8 individual pairs.
21Feb17_051654|    -- Mutated 32 individuals.
21Feb17_052006|    -- Evaluated 64 individuals.
21Feb17_052006|    Summary of generation 11:
21Feb17_052006| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_052006|-----------  ------------------  --------------------  ----------
21Feb17_052006|    Max            58.00                34.00           0.78358
21Feb17_052006|    Avg            41.87                 7.95           0.03476
21Feb17_052006|    Min            28.00                 2.00           0.00000
21Feb17_052006|    Std             2.88                 6.49           0.14854
21Feb17_052006|   Best            28.00                 8.00           0.52079
21Feb17_052006|-- Generation 12 --
21Feb17_052006|    -- Crossed 3 individual pairs.
21Feb17_052006|    -- Mutated 32 individuals.
21Feb17_052316|    -- Evaluated 64 individuals.
21Feb17_052316|    Summary of generation 12:
21Feb17_052316| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_052316|-----------  ------------------  --------------------  ----------
21Feb17_052316|    Max            42.35                36.00           0.67494
21Feb17_052316|    Avg            41.46                 7.03           0.02217
21Feb17_052316|    Min            24.96                 2.00           0.00000
21Feb17_052316|    Std             2.67                 5.88           0.11025
21Feb17_052316|   Best            24.96                18.00           0.67494
21Feb17_052316|-- Generation 13 --
21Feb17_052316|    -- Crossed 5 individual pairs.
21Feb17_052316|    -- Mutated 32 individuals.
21Feb17_052627|    -- Evaluated 64 individuals.
21Feb17_052627|    Summary of generation 13:
21Feb17_052627| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_052627|-----------  ------------------  --------------------  ----------
21Feb17_052627|    Max            42.61                36.00           0.61562
21Feb17_052627|    Avg            41.50                 8.56           0.02210
21Feb17_052627|    Min            26.78                 2.00           0.00000
21Feb17_052627|    Std             2.40                 7.93           0.10577
21Feb17_052627|   Best            26.78                18.00           0.61562
21Feb17_052627|-- Generation 14 --
21Feb17_052627|    -- Crossed 7 individual pairs.
21Feb17_052627|    -- Mutated 32 individuals.
21Feb17_052939|    -- Evaluated 64 individuals.
21Feb17_052939|    Summary of generation 14:
21Feb17_052939| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_052939|-----------  ------------------  --------------------  ----------
21Feb17_052939|    Max            42.09                40.00           0.75188
21Feb17_052939|    Avg            41.48                 8.12           0.02679
21Feb17_052939|    Min            27.65                 2.00           0.00000
21Feb17_052939|    Std             2.42                 6.72           0.13015
21Feb17_052939|   Best            27.65                18.00           0.75188
21Feb17_052939|-- Generation 15 --
21Feb17_052939|    -- Crossed 6 individual pairs.
21Feb17_052939|    -- Mutated 32 individuals.
21Feb17_053251|    -- Evaluated 64 individuals.
21Feb17_053251|    Summary of generation 15:
21Feb17_053251| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_053251|-----------  ------------------  --------------------  ----------
21Feb17_053251|    Max            42.09                40.00           0.73387
21Feb17_053251|    Avg            41.42                 7.69           0.02610
21Feb17_053251|    Min            26.35                 2.00           0.00000
21Feb17_053251|    Std             2.71                 6.44           0.12590
21Feb17_053251|   Best            26.35                18.00           0.71951
21Feb17_053251|-- Generation 16 --
21Feb17_053251|    -- Crossed 5 individual pairs.
21Feb17_053251|    -- Mutated 32 individuals.
21Feb17_053602|    -- Evaluated 64 individuals.
21Feb17_053602|    Summary of generation 16:
21Feb17_053602| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_053602|-----------  ------------------  --------------------  ----------
21Feb17_053602|    Max            42.26                44.00           0.82855
21Feb17_053602|    Avg            41.21                 7.83           0.03973
21Feb17_053602|    Min            24.87                 2.00           0.00000
21Feb17_053602|    Std             3.23                 7.99           0.16234
21Feb17_053602|   Best            24.87                21.00           0.68287
21Feb17_053602|-- Generation 17 --
21Feb17_053602|    -- Crossed 8 individual pairs.
21Feb17_053602|    -- Mutated 32 individuals.
21Feb17_053914|    -- Evaluated 64 individuals.
21Feb17_053914|    Summary of generation 17:
21Feb17_053914| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_053914|-----------  ------------------  --------------------  ----------
21Feb17_053914|    Max            42.26                44.00           0.80877
21Feb17_053914|    Avg            40.86                 8.81           0.06413
21Feb17_053914|    Min            25.04                 2.00           0.00000
21Feb17_053914|    Std             3.59                 8.94           0.19340
21Feb17_053914|   Best            25.04                10.00           0.72247
21Feb17_053914|-- Generation 18 --
21Feb17_053914|    -- Crossed 2 individual pairs.
21Feb17_053914|    -- Mutated 32 individuals.
21Feb17_054229|    -- Evaluated 64 individuals.
21Feb17_054229|    Summary of generation 18:
21Feb17_054229| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_054229|-----------  ------------------  --------------------  ----------
21Feb17_054229|    Max            47.04                44.00           0.81211
21Feb17_054229|    Avg            39.55                10.78           0.12108
21Feb17_054229|    Min            24.35                 3.00           0.00000
21Feb17_054229|    Std             5.74                11.16           0.25939
21Feb17_054229|   Best            24.35                44.00           0.72485
21Feb17_054229|-- Generation 19 --
21Feb17_054229|    -- Crossed 7 individual pairs.
21Feb17_054229|    -- Mutated 32 individuals.
21Feb17_054549|    -- Evaluated 64 individuals.
21Feb17_054549|    Summary of generation 19:
21Feb17_054549| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_054549|-----------  ------------------  --------------------  ----------
21Feb17_054549|    Max            42.87                70.00           0.81774
21Feb17_054549|    Avg            39.09                14.53           0.14606
21Feb17_054549|    Min            24.70                 3.00           0.00000
21Feb17_054549|    Std             5.78                15.60           0.27609
21Feb17_054549|   Best            24.70                44.00           0.69102
21Feb17_054549|-- Generation 20 --
21Feb17_054549|    -- Crossed 3 individual pairs.
21Feb17_054549|    -- Mutated 32 individuals.
21Feb17_054913|    -- Evaluated 64 individuals.
21Feb17_054913|    Summary of generation 20:
21Feb17_054913| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_054913|-----------  ------------------  --------------------  ----------
21Feb17_054913|    Max            42.17                60.00           0.79174
21Feb17_054913|    Avg            39.05                15.47           0.15453
21Feb17_054913|    Min            24.09                 3.00           0.00000
21Feb17_054913|    Std             5.60                16.03           0.28335
21Feb17_054913|   Best            24.09                48.00           0.76568
21Feb17_054913|-- Generation 21 --
21Feb17_054913|    -- Crossed 4 individual pairs.
21Feb17_054913|    -- Mutated 32 individuals.
21Feb17_055242|    -- Evaluated 64 individuals.
21Feb17_055242|    Summary of generation 21:
21Feb17_055242| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_055242|-----------  ------------------  --------------------  ----------
21Feb17_055242|    Max            42.17                90.00           0.80579
21Feb17_055242|    Avg            38.34                18.45           0.19938
21Feb17_055242|    Min            23.91                 2.00           0.00000
21Feb17_055242|    Std             5.87                19.09           0.30554
21Feb17_055242|   Best            23.91                48.00           0.71458
21Feb17_055242|-- Generation 22 --
21Feb17_055242|    -- Crossed 2 individual pairs.
21Feb17_055242|    -- Mutated 32 individuals.
21Feb17_055614|    -- Evaluated 64 individuals.
21Feb17_055614|    Summary of generation 22:
21Feb17_055614| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_055614|-----------  ------------------  --------------------  ----------
21Feb17_055614|    Max            42.09                60.00           0.82362
21Feb17_055614|    Avg            36.71                21.28           0.25981
21Feb17_055614|    Min            24.26                 2.00           0.00000
21Feb17_055614|    Std             6.98                18.25           0.33831
21Feb17_055614|   Best            24.26                52.00           0.76087
21Feb17_055614|-- Generation 23 --
21Feb17_055614|    -- Crossed 2 individual pairs.
21Feb17_055614|    -- Mutated 32 individuals.
21Feb17_055958|    -- Evaluated 64 individuals.
21Feb17_055958|    Summary of generation 23:
21Feb17_055958| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_055958|-----------  ------------------  --------------------  ----------
21Feb17_055958|    Max            42.09                96.00           0.78772
21Feb17_055958|    Avg            35.35                29.28           0.32114
21Feb17_055958|    Min            23.39                 2.00           0.00000
21Feb17_055958|    Std             7.15                21.95           0.34435
21Feb17_055958|   Best            23.39                52.00           0.72814
21Feb17_055958|-- Generation 24 --
21Feb17_055958|    -- Crossed 0 individual pairs.
21Feb17_055958|    -- Mutated 32 individuals.
21Feb17_060354|    -- Evaluated 64 individuals.
21Feb17_060354|    Summary of generation 24:
21Feb17_060354| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_060354|-----------  ------------------  --------------------  ----------
21Feb17_060354|    Max            43.30                80.00           0.82075
21Feb17_060354|    Avg            33.81                36.61           0.38588
21Feb17_060354|    Min            23.22                 2.00           0.00000
21Feb17_060354|    Std             7.30                19.72           0.34184
21Feb17_060354|   Best            23.22                52.00           0.73602
21Feb17_060354|-- Generation 25 --
21Feb17_060354|    -- Crossed 3 individual pairs.
21Feb17_060354|    -- Mutated 32 individuals.
21Feb17_060800|    -- Evaluated 64 individuals.
21Feb17_060800|    Summary of generation 25:
21Feb17_060800| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_060800|-----------  ------------------  --------------------  ----------
21Feb17_060800|    Max            51.74                114.00          0.82799
21Feb17_060800|    Avg            33.58                45.08           0.45457
21Feb17_060800|    Min            23.91                 8.00           0.00000
21Feb17_060800|    Std             7.24                19.61           0.35022
21Feb17_060800|   Best            23.91                48.00           0.72048
21Feb17_060800|-- Generation 26 --
21Feb17_060800|    -- Crossed 1 individual pairs.
21Feb17_060800|    -- Mutated 32 individuals.
21Feb17_061210|    -- Evaluated 64 individuals.
21Feb17_061210|    Summary of generation 26:
21Feb17_061210| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_061210|-----------  ------------------  --------------------  ----------
21Feb17_061210|    Max            42.35                108.00          0.84388
21Feb17_061210|    Avg            32.71                48.80           0.44554
21Feb17_061210|    Min            23.30                 2.00           0.00000
21Feb17_061210|    Std             7.16                22.53           0.33996
21Feb17_061210|   Best            23.30                24.00           0.69415
21Feb17_061210|-- Generation 27 --
21Feb17_061210|    -- Crossed 1 individual pairs.
21Feb17_061210|    -- Mutated 32 individuals.
21Feb17_061620|    -- Evaluated 64 individuals.
21Feb17_061620|    Summary of generation 27:
21Feb17_061620| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_061620|-----------  ------------------  --------------------  ----------
21Feb17_061620|    Max            42.26                132.00          0.82552
21Feb17_061620|    Avg            32.16                51.20           0.45948
21Feb17_061620|    Min            21.74                 8.00           0.00000
21Feb17_061620|    Std             7.19                22.48           0.32234
21Feb17_061620|   Best            21.74                18.00           0.76278
21Feb17_061620|-- Generation 28 --
21Feb17_061620|    -- Crossed 0 individual pairs.
21Feb17_061620|    -- Mutated 32 individuals.
21Feb17_062030|    -- Evaluated 64 individuals.
21Feb17_062030|    Summary of generation 28:
21Feb17_062030| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_062030|-----------  ------------------  --------------------  ----------
21Feb17_062030|    Max            42.00                132.00          0.83850
21Feb17_062030|    Avg            31.52                51.11           0.49187
21Feb17_062030|    Min            23.04                12.00           0.00000
21Feb17_062030|    Std             6.86                24.66           0.32040
21Feb17_062030|   Best            23.04                24.00           0.73226
21Feb17_062030|-- Generation 29 --
21Feb17_062030|    -- Crossed 0 individual pairs.
21Feb17_062030|    -- Mutated 32 individuals.
21Feb17_062436|    -- Evaluated 64 individuals.
21Feb17_062436|    Summary of generation 29:
21Feb17_062436| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_062436|-----------  ------------------  --------------------  ----------
21Feb17_062436|    Max            42.09                132.00          0.82871
21Feb17_062436|    Avg            32.10                49.19           0.44677
21Feb17_062436|    Min            22.26                12.00           0.00000
21Feb17_062436|    Std             7.60                23.20           0.33800
21Feb17_062436|   Best            22.26                56.00           0.74227
21Feb17_062436|-- Generation 30 --
21Feb17_062436|    -- Crossed 0 individual pairs.
21Feb17_062437|    -- Mutated 32 individuals.
21Feb17_062844|    -- Evaluated 64 individuals.
21Feb17_062844|    Summary of generation 30:
21Feb17_062844| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_062844|-----------  ------------------  --------------------  ----------
21Feb17_062844|    Max            42.09                100.00          0.82371
21Feb17_062844|    Avg            31.14                49.09           0.49033
21Feb17_062844|    Min            22.00                14.00           0.00000
21Feb17_062844|    Std             7.06                18.85           0.31415
21Feb17_062844|   Best            22.00                56.00           0.78704
21Feb17_062844|-- Generation 31 --
21Feb17_062844|    -- Crossed 1 individual pairs.
21Feb17_062844|    -- Mutated 32 individuals.
21Feb17_063253|    -- Evaluated 64 individuals.
21Feb17_063253|    Summary of generation 31:
21Feb17_063253| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_063253|-----------  ------------------  --------------------  ----------
21Feb17_063253|    Max            42.52                100.00          0.83333
21Feb17_063253|    Avg            32.54                52.38           0.44410
21Feb17_063253|    Min            22.96                 8.00           0.00000
21Feb17_063253|    Std             7.42                21.79           0.34342
21Feb17_063253|   Best            22.96                44.00           0.72671
21Feb17_063253|-- Generation 32 --
21Feb17_063253|    -- Crossed 1 individual pairs.
21Feb17_063253|    -- Mutated 32 individuals.
21Feb17_063702|    -- Evaluated 64 individuals.
21Feb17_063702|    Summary of generation 32:
21Feb17_063702| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_063702|-----------  ------------------  --------------------  ----------
21Feb17_063702|    Max            42.00                85.00           0.83038
21Feb17_063702|    Avg            32.40                52.83           0.43440
21Feb17_063702|    Min            21.57                 8.00           0.00000
21Feb17_063702|    Std             7.70                18.10           0.34013
21Feb17_063702|   Best            21.57                56.00           0.83038
21Feb17_063702|Best initial individual weights
21Feb17_063702|Individual:
21Feb17_063702|-- Constant hidden layers --
21Feb17_063702|False
21Feb17_063702|Layer 0:
21Feb17_063702|-- Config --
21Feb17_063702|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 12, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063702|-- Weights --
21Feb17_063702|[[-3.50529e-01 -6.53069e-03 -7.03730e-01 -6.33906e-01  6.10835e-02
21Feb17_063702|   4.57449e-01 -3.77835e-01  6.38481e-01  4.24141e-01  6.68786e-01
21Feb17_063702|  -4.86511e-01 -9.28542e-01]
21Feb17_063702| [-8.31270e-01 -3.94586e-01  5.51697e-02 -8.86387e-01 -6.99786e-01
21Feb17_063702|   6.44047e-01 -5.40571e-01  3.77503e-01  1.70193e-01  5.92883e-01
21Feb17_063702|   2.06540e-01  2.18639e-01]
21Feb17_063702| [-8.13637e-01  7.25044e-01  6.66092e-01  5.31057e-01 -4.48634e-01
21Feb17_063702|  -1.62601e-01 -1.57458e-02  7.74238e-02 -4.81841e-01  3.55485e-02
21Feb17_063702|  -7.21169e-01  1.05129e-01]
21Feb17_063702| [ 6.07201e-01  6.23643e-01  8.87343e-01  6.04285e-01  5.70453e-02
21Feb17_063702|   5.99381e-01 -3.21663e-03  6.64196e-01 -5.25584e-01 -1.74507e-02
21Feb17_063702|   3.80029e-01 -4.59585e-01]
21Feb17_063702| [-9.00078e-01  8.63133e-01  8.49324e-01  4.34648e-01 -5.67121e-01
21Feb17_063702|   6.24299e-01 -6.46637e-01  9.34620e-01 -5.42838e-01 -4.04257e-01
21Feb17_063702|  -4.70046e-01  4.29712e-01]
21Feb17_063702| [ 9.51731e-02  8.42954e-01 -7.44806e-01 -5.56045e-02 -4.89209e-01
21Feb17_063702|   8.07612e-01  2.77691e-01 -5.77946e-02  4.30356e-01 -9.05718e-01
21Feb17_063702|  -7.61358e-01 -4.56367e-01]
21Feb17_063702| [-9.06447e-01 -4.46566e-01 -4.40669e-01  6.09161e-01 -3.32587e-01
21Feb17_063702|  -9.31356e-01  9.62597e-02 -1.83060e-01  5.91585e-01 -2.78230e-01
21Feb17_063702|  -3.70976e-01 -3.38510e-01]
21Feb17_063702| [ 5.92999e-02 -5.35945e-01 -8.52259e-01  1.62766e-01 -2.64657e-01
21Feb17_063702|   6.65182e-01  2.45597e-01  2.99711e-01  7.14862e-01 -4.00362e-01
21Feb17_063702|   3.40170e-01 -1.14174e-01]
21Feb17_063702| [-4.26995e-01  8.46146e-01  9.81523e-01 -2.62996e-01  8.65377e-01
21Feb17_063702|  -6.86144e-01 -3.53983e-01 -2.18499e-01  3.29010e-01 -8.26088e-01
21Feb17_063702|   1.48202e-01  5.27152e-01]
21Feb17_063702| [-1.97937e-01  5.44304e-02  9.68680e-01  1.96012e-01  6.66432e-01
21Feb17_063702|  -1.15663e-01  1.01696e-01 -9.91833e-01  5.54656e-02  5.06069e-01
21Feb17_063702|  -8.39702e-01  6.07914e-02]
21Feb17_063702| [ 8.22409e-01 -3.07988e-01 -4.87097e-01 -2.67403e-01 -3.17115e-01
21Feb17_063702|   6.20877e-01  2.45721e-01  1.47039e-01  8.22748e-02 -4.61491e-01
21Feb17_063702|   5.08690e-01 -8.10093e-01]
21Feb17_063702| [-1.03463e-01 -7.13247e-01 -5.27190e-01 -8.14055e-01 -2.20069e-01
21Feb17_063702|   7.58689e-01  7.72478e-01 -3.75243e-01 -1.74773e-01  4.33018e-02
21Feb17_063702|   5.76591e-01 -9.04182e-01]
21Feb17_063702| [ 6.39880e-01 -2.76473e-01  4.48413e-01  7.92996e-01  6.12921e-01
21Feb17_063702|   8.45232e-01 -3.59434e-01 -1.65084e-01  6.00279e-01 -9.07135e-01
21Feb17_063702|  -9.18766e-01 -3.84510e-02]
21Feb17_063702| [-4.35982e-01  3.53117e-01 -4.33635e-01  4.41189e-01  2.02385e-01
21Feb17_063702|  -2.15156e-01 -3.32093e-01 -9.46393e-01  7.49818e-01  7.56840e-01
21Feb17_063702|  -2.97280e-01  3.76513e-01]
21Feb17_063702| [ 2.00098e-01 -3.94368e-01  4.74964e-01 -5.14077e-01 -5.02985e-01
21Feb17_063702|   6.57337e-01  4.54284e-01  7.99434e-01  1.18259e-01  7.90625e-01
21Feb17_063702|  -8.45168e-01 -7.22624e-01]
21Feb17_063702| [ 5.21361e-01 -9.37087e-01  6.98489e-01  7.45747e-01  9.84330e-01
21Feb17_063702|  -1.70463e-01 -4.14211e-01  4.94059e-01 -4.89685e-03 -7.22161e-02
21Feb17_063702|   3.28119e-01 -2.96382e-01]
21Feb17_063702| [ 9.97912e-02 -3.45331e-01 -3.32041e-01 -8.83410e-01  4.64194e-01
21Feb17_063702|  -2.94905e-01 -7.11116e-01 -2.12420e-01  8.93334e-01  5.60374e-01
21Feb17_063702|  -8.11522e-01  3.94537e-01]
21Feb17_063702| [ 2.39284e-01 -9.68110e-02 -3.48403e-01  6.68017e-01  1.07039e-01
21Feb17_063702|  -1.80014e-01 -1.28612e-01 -3.28318e-01  7.99371e-01  7.45882e-01
21Feb17_063702|   4.50426e-01 -9.94601e-02]
21Feb17_063702| [-9.32040e-02 -4.99896e-01 -3.18835e-01 -3.21963e-01  8.88030e-02
21Feb17_063702|   8.24115e-01  3.93190e-01  2.14054e-01 -4.70631e-02  5.36199e-01
21Feb17_063702|   7.72001e-01 -1.38053e-01]
21Feb17_063702| [ 8.31611e-01  7.46409e-01  2.18558e-01  7.47226e-01 -4.35942e-01
21Feb17_063702|  -6.59230e-01  3.39715e-02  8.14827e-01 -7.32488e-02 -1.12845e-01
21Feb17_063702|  -5.06295e-01  2.18074e-01]
21Feb17_063702| [-3.26563e-01  6.22846e-01  3.85669e-01 -9.86028e-01 -7.51629e-02
21Feb17_063702|  -1.88021e-01  7.27322e-01  5.61207e-04  1.34321e-01  7.19415e-01
21Feb17_063702|  -5.83277e-01 -4.45815e-01]
21Feb17_063702| [ 7.83756e-01  9.31803e-02  4.99853e-01 -9.31861e-01  7.91593e-01
21Feb17_063702|   1.96250e-01 -8.00498e-02  7.34271e-01 -2.68771e-01  7.49220e-01
21Feb17_063702|   1.24815e-01  6.17245e-01]
21Feb17_063702| [ 2.20500e-01 -9.26851e-01 -5.03545e-02  9.91366e-01  9.07862e-01
21Feb17_063702|   6.95839e-01  2.07702e-01  1.55262e-01  7.17753e-01 -6.02225e-01
21Feb17_063702|  -2.43972e-02  7.83904e-01]
21Feb17_063702| [-7.35179e-01 -4.04922e-01 -7.64988e-01  6.94764e-03 -5.74469e-01
21Feb17_063702|  -8.82582e-01 -4.25720e-01  4.48261e-01  9.38039e-01 -6.02162e-01
21Feb17_063702|   1.85138e-01  8.19467e-01]
21Feb17_063702| [-2.42564e-01  5.05630e-02 -6.53631e-01  8.89456e-01  3.73267e-02
21Feb17_063702|  -4.57479e-01  5.78190e-01 -8.65769e-01  4.43846e-01  9.21993e-01
21Feb17_063702|  -4.59642e-01  4.55887e-01]
21Feb17_063702| [ 1.79502e-01  5.97755e-01 -5.91581e-01  6.50878e-01 -3.20822e-02
21Feb17_063702|   7.98103e-01  9.23662e-01 -3.15762e-01  3.95919e-01 -9.74799e-01
21Feb17_063702|  -9.18783e-01  9.04381e-01]
21Feb17_063702| [-9.77544e-01 -9.84191e-01 -3.78989e-01  1.57093e-01 -1.19240e-01
21Feb17_063702|   7.04336e-01  9.20317e-01 -9.23300e-02  7.24512e-01 -4.73620e-01
21Feb17_063702|   4.32204e-01  1.96422e-01]
21Feb17_063702| [-9.94008e-01  1.23345e-01 -2.91311e-01  3.86181e-01  3.50519e-01
21Feb17_063702|   8.97293e-02  1.28693e-01  7.64175e-01  9.70172e-01 -9.36008e-01
21Feb17_063702|   2.31190e-01 -3.81352e-01]
21Feb17_063702| [-8.68842e-01 -3.08689e-01 -7.85613e-02 -7.75421e-01 -2.62711e-01
21Feb17_063702|  -9.13854e-01  5.58996e-01  8.97445e-01 -4.78631e-01 -4.79708e-02
21Feb17_063702|  -2.09270e-01  1.03320e-01]
21Feb17_063702| [ 2.47190e-01  8.94828e-01 -8.83655e-01  1.67368e-01 -1.09226e-01
21Feb17_063702|   5.39374e-01  3.22158e-01  7.22802e-01 -4.76431e-01 -3.98606e-01
21Feb17_063702|   3.91466e-01 -5.89172e-01]
21Feb17_063702| [ 2.03966e-01 -8.11217e-01  8.56319e-01 -5.26108e-01 -9.29896e-01
21Feb17_063702|   5.92077e-01  8.52854e-01  6.15086e-01  5.45676e-01 -8.13950e-01
21Feb17_063702|   6.24771e-01 -9.57171e-01]
21Feb17_063702| [-7.59457e-01  2.18652e-01 -9.40198e-01 -1.94388e-03 -3.63300e-01
21Feb17_063702|   2.19527e-01 -3.86609e-01  6.57866e-02  8.04643e-01  4.37489e-01
21Feb17_063702|   6.39988e-01 -8.42788e-01]
21Feb17_063702| [-2.79911e-01  8.89651e-01  5.38994e-02  7.45843e-01 -9.32154e-01
21Feb17_063702|   5.56522e-01  5.04658e-01  3.56409e-01 -5.15289e-01  6.99550e-01
21Feb17_063702|  -7.31032e-01  1.61260e-01]
21Feb17_063702| [ 8.41582e-01 -5.25391e-01  4.65437e-01  4.40808e-01 -6.03761e-01
21Feb17_063702|   6.23036e-01  9.46114e-01  5.92328e-01  2.08190e-01 -6.69715e-01
21Feb17_063702|  -7.35264e-02  5.96491e-01]
21Feb17_063702| [ 3.20347e-01  1.37290e-01  1.72843e-02 -4.70187e-01  5.92987e-01
21Feb17_063702|   3.57672e-01  2.73873e-01 -8.65750e-02 -3.09144e-01 -9.20603e-01
21Feb17_063702|   2.82912e-01  6.38325e-01]
21Feb17_063702| [-8.91399e-01 -1.24857e-01 -4.86431e-01 -9.05166e-01  8.47373e-01
21Feb17_063702|   3.18146e-01  2.73494e-02 -5.33112e-01  5.63862e-01 -5.12821e-01
21Feb17_063702|  -9.38474e-01 -9.90043e-01]
21Feb17_063702| [-8.25448e-01 -1.90141e-02 -5.51276e-01 -8.23215e-01  7.26222e-02
21Feb17_063702|   3.49894e-01  5.17693e-01 -5.57217e-01 -3.26301e-01  7.78564e-01
21Feb17_063702|   6.58213e-01 -2.83929e-01]
21Feb17_063702| [ 6.18012e-02 -4.92329e-01  5.41071e-01  2.13013e-01  6.35700e-01
21Feb17_063702|  -1.65529e-01  5.77357e-01  2.45531e-01  2.54855e-01 -8.48854e-01
21Feb17_063702|   6.46386e-01 -4.13404e-01]
21Feb17_063702| [-3.41116e-01 -4.75918e-01  3.59165e-01  6.02895e-01 -4.31688e-01
21Feb17_063702|  -8.51757e-01  2.31464e-01 -9.57407e-01  2.83436e-01 -4.51744e-01
21Feb17_063702|   4.80022e-02 -8.35007e-01]
21Feb17_063702| [ 9.67499e-01  5.85047e-02  7.21540e-01  3.12459e-01  3.50272e-01
21Feb17_063702|   2.14450e-01 -3.30294e-01 -7.99000e-01  1.11959e-01  2.74091e-01
21Feb17_063702|  -1.78234e-01  9.40235e-01]
21Feb17_063702| [-1.14387e-01  4.31319e-01  3.73789e-01 -4.62497e-01  4.50407e-01
21Feb17_063702|  -4.00668e-01 -8.26575e-01  2.39589e-01 -5.24611e-01  3.30691e-01
21Feb17_063702|  -3.99504e-01  1.44547e-01]
21Feb17_063702| [ 7.34826e-01 -5.37352e-01 -6.62895e-01  1.04258e-01  2.15046e-03
21Feb17_063702|   2.71790e-01  8.51151e-01 -6.31948e-01  1.94011e-01 -6.41830e-01
21Feb17_063702|   1.67802e-01 -4.29449e-01]
21Feb17_063702| [-6.18752e-01  1.18069e-01 -7.98263e-01  4.75266e-01 -9.95474e-01
21Feb17_063702|  -1.79698e-01  6.90455e-01  3.44607e-01 -5.80013e-01 -6.16218e-02
21Feb17_063702|   7.01329e-01  8.33298e-02]
21Feb17_063702| [-2.69227e-01 -1.43165e-02 -3.33533e-01 -1.69954e-01 -1.26476e-02
21Feb17_063702|   7.69653e-01 -6.99893e-01  5.22539e-01 -1.67862e-01  4.44416e-01
21Feb17_063702|   6.72372e-01  5.52923e-01]
21Feb17_063702| [-7.10479e-01  1.61800e-01  2.53825e-01 -3.00634e-01 -5.06805e-01
21Feb17_063702|   2.02091e-01 -4.94980e-02 -1.44363e-01 -6.18371e-01  5.74350e-01
21Feb17_063702|  -1.85073e-01 -8.11049e-01]
21Feb17_063702| [-6.60846e-01 -1.69003e-01  6.00733e-01 -8.28618e-01 -3.99034e-01
21Feb17_063702|  -5.82553e-01  7.34428e-02  5.57096e-01 -1.50695e-01  1.26307e-01
21Feb17_063702|   8.92712e-01 -8.75142e-01]
21Feb17_063702| [ 7.58158e-01  5.89907e-01 -1.92304e-01 -3.86200e-01 -2.63049e-01
21Feb17_063702|  -3.41209e-03  4.05030e-01 -8.95945e-02  9.79113e-01  6.78942e-02
21Feb17_063702|  -9.53580e-01  7.06162e-01]
21Feb17_063702| [-1.23045e-01  9.25694e-01  5.20030e-01  4.57808e-01 -9.99639e-01
21Feb17_063702|  -9.80069e-02  3.03598e-01  4.26167e-02 -3.64595e-01 -7.17635e-01
21Feb17_063702|   1.61128e-01  6.30329e-01]
21Feb17_063702| [ 2.02232e-02 -3.24113e-01  7.43999e-01 -3.75983e-01  4.63558e-01
21Feb17_063702|  -2.04941e-01 -5.28404e-02  4.26576e-01 -2.53802e-01  1.74976e-01
21Feb17_063702|  -8.35763e-01  8.54548e-01]
21Feb17_063702| [-5.76875e-01  5.40954e-01 -4.91777e-01  4.40209e-01 -9.16379e-01
21Feb17_063702|   6.01728e-01  1.25226e-02  2.05876e-01  8.45524e-01 -8.34178e-01
21Feb17_063702|  -7.87379e-01  8.63352e-01]
21Feb17_063702| [-3.15102e-01  7.00213e-01  6.69503e-01  7.15510e-01 -9.53550e-01
21Feb17_063702|   4.07885e-02  4.25336e-01  6.24629e-01  9.90858e-01  6.36989e-01
21Feb17_063702|  -6.44355e-01 -5.47589e-01]
21Feb17_063702| [-8.25051e-01 -4.37574e-01  4.76334e-01 -7.71092e-01  7.98467e-01
21Feb17_063702|  -1.52347e-01  3.34469e-01  1.51889e-01 -9.60611e-01  4.62484e-01
21Feb17_063702|   4.10115e-01 -1.60555e-01]
21Feb17_063702| [ 1.77712e-01  6.55776e-01  8.97735e-01 -9.20852e-01 -9.69032e-01
21Feb17_063702|  -4.79756e-02 -3.24015e-01 -1.57490e-01 -6.25919e-01  9.94240e-01
21Feb17_063702|  -4.74141e-01 -1.00993e-01]
21Feb17_063702| [ 3.66246e-01  8.06205e-01  3.37216e-01 -3.17040e-01  9.19693e-01
21Feb17_063702|   8.28581e-01  2.22724e-01 -5.57410e-01 -8.17434e-01 -8.65693e-01
21Feb17_063702|  -4.72960e-01  7.15176e-01]
21Feb17_063702| [-8.25000e-01 -4.67253e-01 -1.84646e-02  3.88053e-01 -8.75853e-01
21Feb17_063702|  -2.34509e-01  9.53471e-01  8.05489e-02  2.71744e-01 -7.15129e-01
21Feb17_063702|   9.24875e-01 -6.07435e-01]
21Feb17_063702| [-2.79447e-01  2.39105e-01  1.32962e-01 -7.68103e-01  7.58443e-01
21Feb17_063702|  -1.69646e-01 -7.52460e-01 -7.30195e-01 -4.68985e-01 -2.88784e-01
21Feb17_063702|   3.77655e-02 -5.72024e-01]
21Feb17_063702| [-8.37481e-01 -8.22188e-02  8.45547e-01 -5.53876e-01  5.72703e-01
21Feb17_063702|   3.09970e-01  8.96552e-01  3.97690e-01 -7.19080e-01  2.37714e-01
21Feb17_063702|   6.60752e-01  1.69435e-01]]
21Feb17_063702|-- Bias --
21Feb17_063702|[-0.28065  0.08142 -0.20194  0.96969  0.45180  0.54884  0.16606 -0.15804
21Feb17_063702|  0.47362  0.17133  0.43345 -0.35803]
21Feb17_063702|Layer 1:
21Feb17_063702|-- Config --
21Feb17_063702|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 12], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063702|-- Weights --
21Feb17_063702|[[-0.88546  0.72941]
21Feb17_063702| [ 0.79196 -0.05477]
21Feb17_063702| [-0.89752 -0.49343]
21Feb17_063702| [ 0.78974 -0.41510]
21Feb17_063702| [ 0.29561 -0.94575]
21Feb17_063702| [-0.14754  0.69148]
21Feb17_063702| [-0.33558  0.37910]
21Feb17_063702| [-0.82387  0.15998]
21Feb17_063702| [-0.77760  0.88462]
21Feb17_063702| [ 0.98329 -0.68363]
21Feb17_063702| [ 0.88895  0.40387]
21Feb17_063702| [ 0.39015 -0.38652]]
21Feb17_063702|-- Bias --
21Feb17_063702|[ 0.28702 -0.70976]
21Feb17_063702|Predicting the validation and test data with the Best initial individual.
21Feb17_063708| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_063708|-----------  ------------------  --------------------  ----------
21Feb17_063708|Validation         42.00                  12            0.00000
21Feb17_063708|   Test            36.32                  12            0.00298
21Feb17_063708|-------------------- Test #0 --------------------
21Feb17_063708|Best final individual weights
21Feb17_063708|Individual:
21Feb17_063708|-- Constant hidden layers --
21Feb17_063708|False
21Feb17_063708|Layer 0:
21Feb17_063708|-- Config --
21Feb17_063708|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063708|-- Weights --
21Feb17_063708|[[-0.73212  1.32861  0.10200]
21Feb17_063708| [ 1.48746 -2.97273 -0.42944]
21Feb17_063708| [ 0.53095 -1.50623  0.79224]
21Feb17_063708| [-1.07292 -0.83175 -0.90105]
21Feb17_063708| [-0.48696 -0.89325  0.27226]
21Feb17_063708| [-3.02511  0.34155 -0.03837]
21Feb17_063708| [-0.76747  0.57140 -0.46892]
21Feb17_063708| [-0.07581  0.14713  0.85910]
21Feb17_063708| [-1.37488  0.52170 -0.36205]
21Feb17_063708| [ 1.60981 -0.08727 -0.11267]
21Feb17_063708| [ 0.50986  1.58916 -0.35287]
21Feb17_063708| [-0.34599  1.27113 -0.16393]
21Feb17_063708| [ 1.29203  1.19467  0.37695]
21Feb17_063708| [ 0.58704  0.06328 -0.24240]
21Feb17_063708| [-0.93888 -0.89760  0.57087]
21Feb17_063708| [ 0.99159 -0.66387  0.35177]
21Feb17_063708| [-0.67119  1.06910 -0.12512]
21Feb17_063708| [-0.91534  1.23744 -0.40465]
21Feb17_063708| [ 1.39278  0.08069  0.23328]
21Feb17_063708| [ 0.09880  0.57603 -0.96101]
21Feb17_063708| [ 0.01621 -0.13343 -0.27624]
21Feb17_063708| [-1.28286 -2.28909  0.37931]
21Feb17_063708| [-0.28370  0.09336  0.01547]
21Feb17_063708| [-0.51894  1.84280 -0.25906]
21Feb17_063708| [-0.83075 -0.04508  0.12107]
21Feb17_063708| [ 0.37343  1.18436 -0.07358]
21Feb17_063708| [-2.38657 -0.35191  0.01962]
21Feb17_063708| [ 0.95757 -0.91760 -0.08971]
21Feb17_063708| [ 0.38792 -0.01880  0.69717]
21Feb17_063708| [ 1.66877 -0.58078 -1.21129]
21Feb17_063708| [-0.50943  0.59080  0.30856]
21Feb17_063708| [ 0.30163  1.11518  0.98185]
21Feb17_063708| [-0.73226  0.32281 -0.66712]
21Feb17_063708| [-0.62054 -2.21049  1.40981]
21Feb17_063708| [ 1.23185 -0.58090  0.35844]
21Feb17_063708| [-0.05616  0.24219 -0.02853]
21Feb17_063708| [-1.05085 -2.30259 -0.16276]
21Feb17_063708| [ 0.71087  0.14900  1.13430]
21Feb17_063708| [-2.45877 -1.20999 -1.04986]
21Feb17_063708| [-1.00480  1.36344 -0.13998]
21Feb17_063708| [ 1.83140 -0.91532  0.07616]
21Feb17_063708| [-0.60404 -2.05184  0.76948]
21Feb17_063708| [ 0.52617  0.76042 -1.76746]
21Feb17_063708| [-0.22134  0.17324  0.99530]
21Feb17_063708| [-0.36427  1.34655  0.02110]
21Feb17_063708| [-0.93125 -0.33620 -0.25012]
21Feb17_063708| [-2.76428  0.14487  0.48096]
21Feb17_063708| [-0.10518  0.35052  1.71840]
21Feb17_063708| [-1.27998  1.12568  1.26523]
21Feb17_063708| [-0.60698  1.53230 -0.60824]
21Feb17_063708| [ 0.02898  2.98718 -0.59153]
21Feb17_063708| [ 0.17588 -0.00449  0.50797]
21Feb17_063708| [-1.42674 -0.54967 -0.21310]
21Feb17_063708| [ 1.03196  1.18733  0.36755]
21Feb17_063708| [ 1.04748 -1.47444 -0.08469]
21Feb17_063708| [ 0.49410  0.38745  0.68469]
21Feb17_063708| [-0.62880  0.73245  0.19964]]
21Feb17_063708|-- Bias --
21Feb17_063708|[-0.18798  0.64571 -0.23142]
21Feb17_063708|Layer 1:
21Feb17_063708|-- Config --
21Feb17_063708|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063708|-- Weights --
21Feb17_063708|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_063708| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_063708| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_063708|-- Bias --
21Feb17_063708|[0.60477 0.03773 0.26452 0.12222]
21Feb17_063708|Layer 2:
21Feb17_063708|-- Config --
21Feb17_063708|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063708|-- Weights --
21Feb17_063708|[[ 0.67920  0.12119]
21Feb17_063708| [ 0.44836  0.02916]
21Feb17_063708| [ 0.68939  0.31516]
21Feb17_063708| [-0.58995 -0.05861]]
21Feb17_063708|-- Bias --
21Feb17_063708|[ 0.59649 -0.08079]
21Feb17_063708|Layer 3:
21Feb17_063708|-- Config --
21Feb17_063708|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063708|-- Weights --
21Feb17_063708|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_063708| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_063708|-- Bias --
21Feb17_063708|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_063708|Layer 4:
21Feb17_063708|-- Config --
21Feb17_063708|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063708|-- Weights --
21Feb17_063708|[[-0.03514 -1.04833]
21Feb17_063708| [ 1.25238  0.62094]
21Feb17_063708| [ 0.99203  0.37406]
21Feb17_063708| [ 0.49902  0.67158]
21Feb17_063708| [-1.35709  0.38335]]
21Feb17_063708|-- Bias --
21Feb17_063708|[0.31435 0.36299]
21Feb17_063708|Predicting the validation and test data with the Best final individual.
21Feb17_063716| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_063716|-----------  ------------------  --------------------  ----------
21Feb17_063716|Validation         40.17                  56            0.05627
21Feb17_063716|   Test            21.37                  56            0.70301
21Feb17_063716|-------------------- Test #1 --------------------
21Feb17_063716|Best final individual weights
21Feb17_063716|Individual:
21Feb17_063716|-- Constant hidden layers --
21Feb17_063716|False
21Feb17_063716|Layer 0:
21Feb17_063716|-- Config --
21Feb17_063716|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063716|-- Weights --
21Feb17_063716|[[-0.73212  1.32861  0.10200]
21Feb17_063716| [ 1.48746 -2.97273 -0.42944]
21Feb17_063716| [ 0.53095 -1.50623  0.79224]
21Feb17_063716| [-1.07292 -0.83175 -0.90105]
21Feb17_063716| [-0.48696 -0.89325  0.27226]
21Feb17_063716| [-3.02511  0.34155 -0.03837]
21Feb17_063716| [-0.76747  0.57140 -0.46892]
21Feb17_063716| [-0.07581  0.14713  0.85910]
21Feb17_063716| [-1.37488  0.52170 -0.36205]
21Feb17_063716| [ 1.60981 -0.08727 -0.11267]
21Feb17_063716| [ 0.50986  1.58916 -0.35287]
21Feb17_063716| [-0.34599  1.27113 -0.16393]
21Feb17_063716| [ 1.29203  1.19467  0.37695]
21Feb17_063716| [ 0.58704  0.06328 -0.24240]
21Feb17_063716| [-0.93888 -0.89760  0.57087]
21Feb17_063716| [ 0.99159 -0.66387  0.35177]
21Feb17_063716| [-0.67119  1.06910 -0.12512]
21Feb17_063716| [-0.91534  1.23744 -0.40465]
21Feb17_063716| [ 1.39278  0.08069  0.23328]
21Feb17_063716| [ 0.09880  0.57603 -0.96101]
21Feb17_063716| [ 0.01621 -0.13343 -0.27624]
21Feb17_063716| [-1.28286 -2.28909  0.37931]
21Feb17_063716| [-0.28370  0.09336  0.01547]
21Feb17_063716| [-0.51894  1.84280 -0.25906]
21Feb17_063716| [-0.83075 -0.04508  0.12107]
21Feb17_063716| [ 0.37343  1.18436 -0.07358]
21Feb17_063716| [-2.38657 -0.35191  0.01962]
21Feb17_063716| [ 0.95757 -0.91760 -0.08971]
21Feb17_063716| [ 0.38792 -0.01880  0.69717]
21Feb17_063716| [ 1.66877 -0.58078 -1.21129]
21Feb17_063716| [-0.50943  0.59080  0.30856]
21Feb17_063716| [ 0.30163  1.11518  0.98185]
21Feb17_063716| [-0.73226  0.32281 -0.66712]
21Feb17_063716| [-0.62054 -2.21049  1.40981]
21Feb17_063716| [ 1.23185 -0.58090  0.35844]
21Feb17_063716| [-0.05616  0.24219 -0.02853]
21Feb17_063716| [-1.05085 -2.30259 -0.16276]
21Feb17_063716| [ 0.71087  0.14900  1.13430]
21Feb17_063716| [-2.45877 -1.20999 -1.04986]
21Feb17_063716| [-1.00480  1.36344 -0.13998]
21Feb17_063716| [ 1.83140 -0.91532  0.07616]
21Feb17_063716| [-0.60404 -2.05184  0.76948]
21Feb17_063716| [ 0.52617  0.76042 -1.76746]
21Feb17_063716| [-0.22134  0.17324  0.99530]
21Feb17_063716| [-0.36427  1.34655  0.02110]
21Feb17_063716| [-0.93125 -0.33620 -0.25012]
21Feb17_063716| [-2.76428  0.14487  0.48096]
21Feb17_063716| [-0.10518  0.35052  1.71840]
21Feb17_063716| [-1.27998  1.12568  1.26523]
21Feb17_063716| [-0.60698  1.53230 -0.60824]
21Feb17_063716| [ 0.02898  2.98718 -0.59153]
21Feb17_063716| [ 0.17588 -0.00449  0.50797]
21Feb17_063716| [-1.42674 -0.54967 -0.21310]
21Feb17_063716| [ 1.03196  1.18733  0.36755]
21Feb17_063716| [ 1.04748 -1.47444 -0.08469]
21Feb17_063716| [ 0.49410  0.38745  0.68469]
21Feb17_063716| [-0.62880  0.73245  0.19964]]
21Feb17_063716|-- Bias --
21Feb17_063716|[-0.18798  0.64571 -0.23142]
21Feb17_063716|Layer 1:
21Feb17_063716|-- Config --
21Feb17_063716|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063716|-- Weights --
21Feb17_063716|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_063716| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_063716| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_063716|-- Bias --
21Feb17_063716|[0.60477 0.03773 0.26452 0.12222]
21Feb17_063716|Layer 2:
21Feb17_063716|-- Config --
21Feb17_063716|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063716|-- Weights --
21Feb17_063716|[[ 0.67920  0.12119]
21Feb17_063716| [ 0.44836  0.02916]
21Feb17_063716| [ 0.68939  0.31516]
21Feb17_063716| [-0.58995 -0.05861]]
21Feb17_063716|-- Bias --
21Feb17_063716|[ 0.59649 -0.08079]
21Feb17_063716|Layer 3:
21Feb17_063716|-- Config --
21Feb17_063716|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063716|-- Weights --
21Feb17_063716|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_063716| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_063716|-- Bias --
21Feb17_063716|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_063716|Layer 4:
21Feb17_063716|-- Config --
21Feb17_063716|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063716|-- Weights --
21Feb17_063716|[[-0.03514 -1.04833]
21Feb17_063716| [ 1.25238  0.62094]
21Feb17_063716| [ 0.99203  0.37406]
21Feb17_063716| [ 0.49902  0.67158]
21Feb17_063716| [-1.35709  0.38335]]
21Feb17_063716|-- Bias --
21Feb17_063716|[0.31435 0.36299]
21Feb17_063716|Predicting the validation and test data with the Best final individual.
21Feb17_063724| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_063724|-----------  ------------------  --------------------  ----------
21Feb17_063724|Validation         23.83                  56            0.86651
21Feb17_063724|   Test            22.68                  56            0.77969
21Feb17_063724|-------------------- Test #2 --------------------
21Feb17_063724|Best final individual weights
21Feb17_063724|Individual:
21Feb17_063724|-- Constant hidden layers --
21Feb17_063724|False
21Feb17_063724|Layer 0:
21Feb17_063724|-- Config --
21Feb17_063724|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063724|-- Weights --
21Feb17_063724|[[-0.73212  1.32861  0.10200]
21Feb17_063724| [ 1.48746 -2.97273 -0.42944]
21Feb17_063724| [ 0.53095 -1.50623  0.79224]
21Feb17_063724| [-1.07292 -0.83175 -0.90105]
21Feb17_063724| [-0.48696 -0.89325  0.27226]
21Feb17_063724| [-3.02511  0.34155 -0.03837]
21Feb17_063724| [-0.76747  0.57140 -0.46892]
21Feb17_063724| [-0.07581  0.14713  0.85910]
21Feb17_063724| [-1.37488  0.52170 -0.36205]
21Feb17_063724| [ 1.60981 -0.08727 -0.11267]
21Feb17_063724| [ 0.50986  1.58916 -0.35287]
21Feb17_063724| [-0.34599  1.27113 -0.16393]
21Feb17_063724| [ 1.29203  1.19467  0.37695]
21Feb17_063724| [ 0.58704  0.06328 -0.24240]
21Feb17_063724| [-0.93888 -0.89760  0.57087]
21Feb17_063724| [ 0.99159 -0.66387  0.35177]
21Feb17_063724| [-0.67119  1.06910 -0.12512]
21Feb17_063724| [-0.91534  1.23744 -0.40465]
21Feb17_063724| [ 1.39278  0.08069  0.23328]
21Feb17_063724| [ 0.09880  0.57603 -0.96101]
21Feb17_063724| [ 0.01621 -0.13343 -0.27624]
21Feb17_063724| [-1.28286 -2.28909  0.37931]
21Feb17_063724| [-0.28370  0.09336  0.01547]
21Feb17_063724| [-0.51894  1.84280 -0.25906]
21Feb17_063724| [-0.83075 -0.04508  0.12107]
21Feb17_063724| [ 0.37343  1.18436 -0.07358]
21Feb17_063724| [-2.38657 -0.35191  0.01962]
21Feb17_063724| [ 0.95757 -0.91760 -0.08971]
21Feb17_063724| [ 0.38792 -0.01880  0.69717]
21Feb17_063724| [ 1.66877 -0.58078 -1.21129]
21Feb17_063724| [-0.50943  0.59080  0.30856]
21Feb17_063724| [ 0.30163  1.11518  0.98185]
21Feb17_063724| [-0.73226  0.32281 -0.66712]
21Feb17_063724| [-0.62054 -2.21049  1.40981]
21Feb17_063724| [ 1.23185 -0.58090  0.35844]
21Feb17_063724| [-0.05616  0.24219 -0.02853]
21Feb17_063724| [-1.05085 -2.30259 -0.16276]
21Feb17_063724| [ 0.71087  0.14900  1.13430]
21Feb17_063724| [-2.45877 -1.20999 -1.04986]
21Feb17_063724| [-1.00480  1.36344 -0.13998]
21Feb17_063724| [ 1.83140 -0.91532  0.07616]
21Feb17_063724| [-0.60404 -2.05184  0.76948]
21Feb17_063724| [ 0.52617  0.76042 -1.76746]
21Feb17_063724| [-0.22134  0.17324  0.99530]
21Feb17_063724| [-0.36427  1.34655  0.02110]
21Feb17_063724| [-0.93125 -0.33620 -0.25012]
21Feb17_063724| [-2.76428  0.14487  0.48096]
21Feb17_063724| [-0.10518  0.35052  1.71840]
21Feb17_063724| [-1.27998  1.12568  1.26523]
21Feb17_063724| [-0.60698  1.53230 -0.60824]
21Feb17_063724| [ 0.02898  2.98718 -0.59153]
21Feb17_063724| [ 0.17588 -0.00449  0.50797]
21Feb17_063724| [-1.42674 -0.54967 -0.21310]
21Feb17_063724| [ 1.03196  1.18733  0.36755]
21Feb17_063724| [ 1.04748 -1.47444 -0.08469]
21Feb17_063724| [ 0.49410  0.38745  0.68469]
21Feb17_063724| [-0.62880  0.73245  0.19964]]
21Feb17_063724|-- Bias --
21Feb17_063724|[-0.18798  0.64571 -0.23142]
21Feb17_063724|Layer 1:
21Feb17_063724|-- Config --
21Feb17_063724|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063724|-- Weights --
21Feb17_063724|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_063724| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_063724| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_063724|-- Bias --
21Feb17_063724|[0.60477 0.03773 0.26452 0.12222]
21Feb17_063724|Layer 2:
21Feb17_063724|-- Config --
21Feb17_063724|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063724|-- Weights --
21Feb17_063724|[[ 0.67920  0.12119]
21Feb17_063724| [ 0.44836  0.02916]
21Feb17_063724| [ 0.68939  0.31516]
21Feb17_063724| [-0.58995 -0.05861]]
21Feb17_063724|-- Bias --
21Feb17_063724|[ 0.59649 -0.08079]
21Feb17_063724|Layer 3:
21Feb17_063724|-- Config --
21Feb17_063724|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063724|-- Weights --
21Feb17_063724|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_063724| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_063724|-- Bias --
21Feb17_063724|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_063724|Layer 4:
21Feb17_063724|-- Config --
21Feb17_063724|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063724|-- Weights --
21Feb17_063724|[[-0.03514 -1.04833]
21Feb17_063724| [ 1.25238  0.62094]
21Feb17_063724| [ 0.99203  0.37406]
21Feb17_063724| [ 0.49902  0.67158]
21Feb17_063724| [-1.35709  0.38335]]
21Feb17_063724|-- Bias --
21Feb17_063724|[0.31435 0.36299]
21Feb17_063724|Predicting the validation and test data with the Best final individual.
21Feb17_063732| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_063732|-----------  ------------------  --------------------  ----------
21Feb17_063732|Validation         23.91                  56            0.70865
21Feb17_063732|   Test            29.45                  56            0.70270
21Feb17_063732|-------------------- Test #3 --------------------
21Feb17_063732|Best final individual weights
21Feb17_063732|Individual:
21Feb17_063732|-- Constant hidden layers --
21Feb17_063732|False
21Feb17_063732|Layer 0:
21Feb17_063732|-- Config --
21Feb17_063732|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063732|-- Weights --
21Feb17_063732|[[-0.73212  1.32861  0.10200]
21Feb17_063732| [ 1.48746 -2.97273 -0.42944]
21Feb17_063732| [ 0.53095 -1.50623  0.79224]
21Feb17_063732| [-1.07292 -0.83175 -0.90105]
21Feb17_063732| [-0.48696 -0.89325  0.27226]
21Feb17_063732| [-3.02511  0.34155 -0.03837]
21Feb17_063732| [-0.76747  0.57140 -0.46892]
21Feb17_063732| [-0.07581  0.14713  0.85910]
21Feb17_063732| [-1.37488  0.52170 -0.36205]
21Feb17_063732| [ 1.60981 -0.08727 -0.11267]
21Feb17_063732| [ 0.50986  1.58916 -0.35287]
21Feb17_063732| [-0.34599  1.27113 -0.16393]
21Feb17_063732| [ 1.29203  1.19467  0.37695]
21Feb17_063732| [ 0.58704  0.06328 -0.24240]
21Feb17_063732| [-0.93888 -0.89760  0.57087]
21Feb17_063732| [ 0.99159 -0.66387  0.35177]
21Feb17_063732| [-0.67119  1.06910 -0.12512]
21Feb17_063732| [-0.91534  1.23744 -0.40465]
21Feb17_063732| [ 1.39278  0.08069  0.23328]
21Feb17_063732| [ 0.09880  0.57603 -0.96101]
21Feb17_063732| [ 0.01621 -0.13343 -0.27624]
21Feb17_063732| [-1.28286 -2.28909  0.37931]
21Feb17_063732| [-0.28370  0.09336  0.01547]
21Feb17_063732| [-0.51894  1.84280 -0.25906]
21Feb17_063732| [-0.83075 -0.04508  0.12107]
21Feb17_063732| [ 0.37343  1.18436 -0.07358]
21Feb17_063732| [-2.38657 -0.35191  0.01962]
21Feb17_063732| [ 0.95757 -0.91760 -0.08971]
21Feb17_063732| [ 0.38792 -0.01880  0.69717]
21Feb17_063732| [ 1.66877 -0.58078 -1.21129]
21Feb17_063732| [-0.50943  0.59080  0.30856]
21Feb17_063732| [ 0.30163  1.11518  0.98185]
21Feb17_063732| [-0.73226  0.32281 -0.66712]
21Feb17_063732| [-0.62054 -2.21049  1.40981]
21Feb17_063732| [ 1.23185 -0.58090  0.35844]
21Feb17_063732| [-0.05616  0.24219 -0.02853]
21Feb17_063732| [-1.05085 -2.30259 -0.16276]
21Feb17_063732| [ 0.71087  0.14900  1.13430]
21Feb17_063732| [-2.45877 -1.20999 -1.04986]
21Feb17_063732| [-1.00480  1.36344 -0.13998]
21Feb17_063732| [ 1.83140 -0.91532  0.07616]
21Feb17_063732| [-0.60404 -2.05184  0.76948]
21Feb17_063732| [ 0.52617  0.76042 -1.76746]
21Feb17_063732| [-0.22134  0.17324  0.99530]
21Feb17_063732| [-0.36427  1.34655  0.02110]
21Feb17_063732| [-0.93125 -0.33620 -0.25012]
21Feb17_063732| [-2.76428  0.14487  0.48096]
21Feb17_063732| [-0.10518  0.35052  1.71840]
21Feb17_063732| [-1.27998  1.12568  1.26523]
21Feb17_063732| [-0.60698  1.53230 -0.60824]
21Feb17_063732| [ 0.02898  2.98718 -0.59153]
21Feb17_063732| [ 0.17588 -0.00449  0.50797]
21Feb17_063732| [-1.42674 -0.54967 -0.21310]
21Feb17_063732| [ 1.03196  1.18733  0.36755]
21Feb17_063732| [ 1.04748 -1.47444 -0.08469]
21Feb17_063732| [ 0.49410  0.38745  0.68469]
21Feb17_063732| [-0.62880  0.73245  0.19964]]
21Feb17_063732|-- Bias --
21Feb17_063732|[-0.18798  0.64571 -0.23142]
21Feb17_063732|Layer 1:
21Feb17_063732|-- Config --
21Feb17_063732|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063732|-- Weights --
21Feb17_063732|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_063732| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_063732| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_063732|-- Bias --
21Feb17_063732|[0.60477 0.03773 0.26452 0.12222]
21Feb17_063732|Layer 2:
21Feb17_063732|-- Config --
21Feb17_063732|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063732|-- Weights --
21Feb17_063732|[[ 0.67920  0.12119]
21Feb17_063732| [ 0.44836  0.02916]
21Feb17_063732| [ 0.68939  0.31516]
21Feb17_063732| [-0.58995 -0.05861]]
21Feb17_063732|-- Bias --
21Feb17_063732|[ 0.59649 -0.08079]
21Feb17_063732|Layer 3:
21Feb17_063732|-- Config --
21Feb17_063732|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063732|-- Weights --
21Feb17_063732|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_063732| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_063732|-- Bias --
21Feb17_063732|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_063732|Layer 4:
21Feb17_063732|-- Config --
21Feb17_063732|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063732|-- Weights --
21Feb17_063732|[[-0.03514 -1.04833]
21Feb17_063732| [ 1.25238  0.62094]
21Feb17_063732| [ 0.99203  0.37406]
21Feb17_063732| [ 0.49902  0.67158]
21Feb17_063732| [-1.35709  0.38335]]
21Feb17_063732|-- Bias --
21Feb17_063732|[0.31435 0.36299]
21Feb17_063732|Predicting the validation and test data with the Best final individual.
21Feb17_063740| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_063740|-----------  ------------------  --------------------  ----------
21Feb17_063740|Validation         24.35                  56            0.84577
21Feb17_063740|   Test            21.63                  56            0.70714
21Feb17_063740|-------------------- Test #4 --------------------
21Feb17_063740|Best final individual weights
21Feb17_063740|Individual:
21Feb17_063740|-- Constant hidden layers --
21Feb17_063740|False
21Feb17_063740|Layer 0:
21Feb17_063740|-- Config --
21Feb17_063740|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063740|-- Weights --
21Feb17_063740|[[-0.73212  1.32861  0.10200]
21Feb17_063740| [ 1.48746 -2.97273 -0.42944]
21Feb17_063740| [ 0.53095 -1.50623  0.79224]
21Feb17_063740| [-1.07292 -0.83175 -0.90105]
21Feb17_063740| [-0.48696 -0.89325  0.27226]
21Feb17_063740| [-3.02511  0.34155 -0.03837]
21Feb17_063740| [-0.76747  0.57140 -0.46892]
21Feb17_063740| [-0.07581  0.14713  0.85910]
21Feb17_063740| [-1.37488  0.52170 -0.36205]
21Feb17_063740| [ 1.60981 -0.08727 -0.11267]
21Feb17_063740| [ 0.50986  1.58916 -0.35287]
21Feb17_063740| [-0.34599  1.27113 -0.16393]
21Feb17_063740| [ 1.29203  1.19467  0.37695]
21Feb17_063740| [ 0.58704  0.06328 -0.24240]
21Feb17_063740| [-0.93888 -0.89760  0.57087]
21Feb17_063740| [ 0.99159 -0.66387  0.35177]
21Feb17_063740| [-0.67119  1.06910 -0.12512]
21Feb17_063740| [-0.91534  1.23744 -0.40465]
21Feb17_063740| [ 1.39278  0.08069  0.23328]
21Feb17_063740| [ 0.09880  0.57603 -0.96101]
21Feb17_063740| [ 0.01621 -0.13343 -0.27624]
21Feb17_063740| [-1.28286 -2.28909  0.37931]
21Feb17_063740| [-0.28370  0.09336  0.01547]
21Feb17_063740| [-0.51894  1.84280 -0.25906]
21Feb17_063740| [-0.83075 -0.04508  0.12107]
21Feb17_063740| [ 0.37343  1.18436 -0.07358]
21Feb17_063740| [-2.38657 -0.35191  0.01962]
21Feb17_063740| [ 0.95757 -0.91760 -0.08971]
21Feb17_063740| [ 0.38792 -0.01880  0.69717]
21Feb17_063740| [ 1.66877 -0.58078 -1.21129]
21Feb17_063740| [-0.50943  0.59080  0.30856]
21Feb17_063740| [ 0.30163  1.11518  0.98185]
21Feb17_063740| [-0.73226  0.32281 -0.66712]
21Feb17_063740| [-0.62054 -2.21049  1.40981]
21Feb17_063740| [ 1.23185 -0.58090  0.35844]
21Feb17_063740| [-0.05616  0.24219 -0.02853]
21Feb17_063740| [-1.05085 -2.30259 -0.16276]
21Feb17_063740| [ 0.71087  0.14900  1.13430]
21Feb17_063740| [-2.45877 -1.20999 -1.04986]
21Feb17_063740| [-1.00480  1.36344 -0.13998]
21Feb17_063740| [ 1.83140 -0.91532  0.07616]
21Feb17_063740| [-0.60404 -2.05184  0.76948]
21Feb17_063740| [ 0.52617  0.76042 -1.76746]
21Feb17_063740| [-0.22134  0.17324  0.99530]
21Feb17_063740| [-0.36427  1.34655  0.02110]
21Feb17_063740| [-0.93125 -0.33620 -0.25012]
21Feb17_063740| [-2.76428  0.14487  0.48096]
21Feb17_063740| [-0.10518  0.35052  1.71840]
21Feb17_063740| [-1.27998  1.12568  1.26523]
21Feb17_063740| [-0.60698  1.53230 -0.60824]
21Feb17_063740| [ 0.02898  2.98718 -0.59153]
21Feb17_063740| [ 0.17588 -0.00449  0.50797]
21Feb17_063740| [-1.42674 -0.54967 -0.21310]
21Feb17_063740| [ 1.03196  1.18733  0.36755]
21Feb17_063740| [ 1.04748 -1.47444 -0.08469]
21Feb17_063740| [ 0.49410  0.38745  0.68469]
21Feb17_063740| [-0.62880  0.73245  0.19964]]
21Feb17_063740|-- Bias --
21Feb17_063740|[-0.18798  0.64571 -0.23142]
21Feb17_063740|Layer 1:
21Feb17_063740|-- Config --
21Feb17_063740|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063740|-- Weights --
21Feb17_063740|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_063740| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_063740| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_063740|-- Bias --
21Feb17_063740|[0.60477 0.03773 0.26452 0.12222]
21Feb17_063740|Layer 2:
21Feb17_063740|-- Config --
21Feb17_063740|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063740|-- Weights --
21Feb17_063740|[[ 0.67920  0.12119]
21Feb17_063740| [ 0.44836  0.02916]
21Feb17_063740| [ 0.68939  0.31516]
21Feb17_063740| [-0.58995 -0.05861]]
21Feb17_063740|-- Bias --
21Feb17_063740|[ 0.59649 -0.08079]
21Feb17_063740|Layer 3:
21Feb17_063740|-- Config --
21Feb17_063740|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063740|-- Weights --
21Feb17_063740|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_063740| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_063740|-- Bias --
21Feb17_063740|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_063740|Layer 4:
21Feb17_063740|-- Config --
21Feb17_063740|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063740|-- Weights --
21Feb17_063740|[[-0.03514 -1.04833]
21Feb17_063740| [ 1.25238  0.62094]
21Feb17_063740| [ 0.99203  0.37406]
21Feb17_063740| [ 0.49902  0.67158]
21Feb17_063740| [-1.35709  0.38335]]
21Feb17_063740|-- Bias --
21Feb17_063740|[0.31435 0.36299]
21Feb17_063740|Predicting the validation and test data with the Best final individual.
21Feb17_063747| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_063747|-----------  ------------------  --------------------  ----------
21Feb17_063747|Validation         21.57                  56            0.82113
21Feb17_063747|   Test            31.19                  56            0.83333
21Feb17_063747|-------------------- Test #5 --------------------
21Feb17_063747|Best final individual weights
21Feb17_063747|Individual:
21Feb17_063747|-- Constant hidden layers --
21Feb17_063747|False
21Feb17_063747|Layer 0:
21Feb17_063747|-- Config --
21Feb17_063747|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063747|-- Weights --
21Feb17_063747|[[-0.73212  1.32861  0.10200]
21Feb17_063747| [ 1.48746 -2.97273 -0.42944]
21Feb17_063747| [ 0.53095 -1.50623  0.79224]
21Feb17_063747| [-1.07292 -0.83175 -0.90105]
21Feb17_063747| [-0.48696 -0.89325  0.27226]
21Feb17_063747| [-3.02511  0.34155 -0.03837]
21Feb17_063747| [-0.76747  0.57140 -0.46892]
21Feb17_063747| [-0.07581  0.14713  0.85910]
21Feb17_063747| [-1.37488  0.52170 -0.36205]
21Feb17_063747| [ 1.60981 -0.08727 -0.11267]
21Feb17_063747| [ 0.50986  1.58916 -0.35287]
21Feb17_063747| [-0.34599  1.27113 -0.16393]
21Feb17_063747| [ 1.29203  1.19467  0.37695]
21Feb17_063747| [ 0.58704  0.06328 -0.24240]
21Feb17_063747| [-0.93888 -0.89760  0.57087]
21Feb17_063747| [ 0.99159 -0.66387  0.35177]
21Feb17_063747| [-0.67119  1.06910 -0.12512]
21Feb17_063747| [-0.91534  1.23744 -0.40465]
21Feb17_063747| [ 1.39278  0.08069  0.23328]
21Feb17_063747| [ 0.09880  0.57603 -0.96101]
21Feb17_063747| [ 0.01621 -0.13343 -0.27624]
21Feb17_063747| [-1.28286 -2.28909  0.37931]
21Feb17_063747| [-0.28370  0.09336  0.01547]
21Feb17_063747| [-0.51894  1.84280 -0.25906]
21Feb17_063747| [-0.83075 -0.04508  0.12107]
21Feb17_063747| [ 0.37343  1.18436 -0.07358]
21Feb17_063747| [-2.38657 -0.35191  0.01962]
21Feb17_063747| [ 0.95757 -0.91760 -0.08971]
21Feb17_063747| [ 0.38792 -0.01880  0.69717]
21Feb17_063747| [ 1.66877 -0.58078 -1.21129]
21Feb17_063747| [-0.50943  0.59080  0.30856]
21Feb17_063747| [ 0.30163  1.11518  0.98185]
21Feb17_063747| [-0.73226  0.32281 -0.66712]
21Feb17_063747| [-0.62054 -2.21049  1.40981]
21Feb17_063747| [ 1.23185 -0.58090  0.35844]
21Feb17_063747| [-0.05616  0.24219 -0.02853]
21Feb17_063747| [-1.05085 -2.30259 -0.16276]
21Feb17_063747| [ 0.71087  0.14900  1.13430]
21Feb17_063747| [-2.45877 -1.20999 -1.04986]
21Feb17_063747| [-1.00480  1.36344 -0.13998]
21Feb17_063747| [ 1.83140 -0.91532  0.07616]
21Feb17_063747| [-0.60404 -2.05184  0.76948]
21Feb17_063747| [ 0.52617  0.76042 -1.76746]
21Feb17_063747| [-0.22134  0.17324  0.99530]
21Feb17_063747| [-0.36427  1.34655  0.02110]
21Feb17_063747| [-0.93125 -0.33620 -0.25012]
21Feb17_063747| [-2.76428  0.14487  0.48096]
21Feb17_063747| [-0.10518  0.35052  1.71840]
21Feb17_063747| [-1.27998  1.12568  1.26523]
21Feb17_063747| [-0.60698  1.53230 -0.60824]
21Feb17_063747| [ 0.02898  2.98718 -0.59153]
21Feb17_063747| [ 0.17588 -0.00449  0.50797]
21Feb17_063747| [-1.42674 -0.54967 -0.21310]
21Feb17_063747| [ 1.03196  1.18733  0.36755]
21Feb17_063747| [ 1.04748 -1.47444 -0.08469]
21Feb17_063747| [ 0.49410  0.38745  0.68469]
21Feb17_063747| [-0.62880  0.73245  0.19964]]
21Feb17_063747|-- Bias --
21Feb17_063747|[-0.18798  0.64571 -0.23142]
21Feb17_063747|Layer 1:
21Feb17_063747|-- Config --
21Feb17_063747|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063747|-- Weights --
21Feb17_063747|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_063747| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_063747| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_063747|-- Bias --
21Feb17_063747|[0.60477 0.03773 0.26452 0.12222]
21Feb17_063747|Layer 2:
21Feb17_063747|-- Config --
21Feb17_063747|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063747|-- Weights --
21Feb17_063747|[[ 0.67920  0.12119]
21Feb17_063747| [ 0.44836  0.02916]
21Feb17_063747| [ 0.68939  0.31516]
21Feb17_063747| [-0.58995 -0.05861]]
21Feb17_063747|-- Bias --
21Feb17_063747|[ 0.59649 -0.08079]
21Feb17_063747|Layer 3:
21Feb17_063747|-- Config --
21Feb17_063747|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063747|-- Weights --
21Feb17_063747|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_063747| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_063747|-- Bias --
21Feb17_063747|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_063747|Layer 4:
21Feb17_063747|-- Config --
21Feb17_063747|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063747|-- Weights --
21Feb17_063747|[[-0.03514 -1.04833]
21Feb17_063747| [ 1.25238  0.62094]
21Feb17_063747| [ 0.99203  0.37406]
21Feb17_063747| [ 0.49902  0.67158]
21Feb17_063747| [-1.35709  0.38335]]
21Feb17_063747|-- Bias --
21Feb17_063747|[0.31435 0.36299]
21Feb17_063747|Predicting the validation and test data with the Best final individual.
21Feb17_063755| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_063755|-----------  ------------------  --------------------  ----------
21Feb17_063755|Validation         23.22                  56            0.86009
21Feb17_063755|   Test            26.15                  56            0.85097
21Feb17_063755|-------------------- Test #6 --------------------
21Feb17_063755|Best final individual weights
21Feb17_063755|Individual:
21Feb17_063755|-- Constant hidden layers --
21Feb17_063755|False
21Feb17_063755|Layer 0:
21Feb17_063755|-- Config --
21Feb17_063755|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063755|-- Weights --
21Feb17_063755|[[-0.73212  1.32861  0.10200]
21Feb17_063755| [ 1.48746 -2.97273 -0.42944]
21Feb17_063755| [ 0.53095 -1.50623  0.79224]
21Feb17_063755| [-1.07292 -0.83175 -0.90105]
21Feb17_063755| [-0.48696 -0.89325  0.27226]
21Feb17_063755| [-3.02511  0.34155 -0.03837]
21Feb17_063755| [-0.76747  0.57140 -0.46892]
21Feb17_063755| [-0.07581  0.14713  0.85910]
21Feb17_063755| [-1.37488  0.52170 -0.36205]
21Feb17_063755| [ 1.60981 -0.08727 -0.11267]
21Feb17_063755| [ 0.50986  1.58916 -0.35287]
21Feb17_063755| [-0.34599  1.27113 -0.16393]
21Feb17_063755| [ 1.29203  1.19467  0.37695]
21Feb17_063755| [ 0.58704  0.06328 -0.24240]
21Feb17_063755| [-0.93888 -0.89760  0.57087]
21Feb17_063755| [ 0.99159 -0.66387  0.35177]
21Feb17_063755| [-0.67119  1.06910 -0.12512]
21Feb17_063755| [-0.91534  1.23744 -0.40465]
21Feb17_063755| [ 1.39278  0.08069  0.23328]
21Feb17_063755| [ 0.09880  0.57603 -0.96101]
21Feb17_063755| [ 0.01621 -0.13343 -0.27624]
21Feb17_063755| [-1.28286 -2.28909  0.37931]
21Feb17_063755| [-0.28370  0.09336  0.01547]
21Feb17_063755| [-0.51894  1.84280 -0.25906]
21Feb17_063755| [-0.83075 -0.04508  0.12107]
21Feb17_063755| [ 0.37343  1.18436 -0.07358]
21Feb17_063755| [-2.38657 -0.35191  0.01962]
21Feb17_063755| [ 0.95757 -0.91760 -0.08971]
21Feb17_063755| [ 0.38792 -0.01880  0.69717]
21Feb17_063755| [ 1.66877 -0.58078 -1.21129]
21Feb17_063755| [-0.50943  0.59080  0.30856]
21Feb17_063755| [ 0.30163  1.11518  0.98185]
21Feb17_063755| [-0.73226  0.32281 -0.66712]
21Feb17_063755| [-0.62054 -2.21049  1.40981]
21Feb17_063755| [ 1.23185 -0.58090  0.35844]
21Feb17_063755| [-0.05616  0.24219 -0.02853]
21Feb17_063755| [-1.05085 -2.30259 -0.16276]
21Feb17_063755| [ 0.71087  0.14900  1.13430]
21Feb17_063755| [-2.45877 -1.20999 -1.04986]
21Feb17_063755| [-1.00480  1.36344 -0.13998]
21Feb17_063755| [ 1.83140 -0.91532  0.07616]
21Feb17_063755| [-0.60404 -2.05184  0.76948]
21Feb17_063755| [ 0.52617  0.76042 -1.76746]
21Feb17_063755| [-0.22134  0.17324  0.99530]
21Feb17_063755| [-0.36427  1.34655  0.02110]
21Feb17_063755| [-0.93125 -0.33620 -0.25012]
21Feb17_063755| [-2.76428  0.14487  0.48096]
21Feb17_063755| [-0.10518  0.35052  1.71840]
21Feb17_063755| [-1.27998  1.12568  1.26523]
21Feb17_063755| [-0.60698  1.53230 -0.60824]
21Feb17_063755| [ 0.02898  2.98718 -0.59153]
21Feb17_063755| [ 0.17588 -0.00449  0.50797]
21Feb17_063755| [-1.42674 -0.54967 -0.21310]
21Feb17_063755| [ 1.03196  1.18733  0.36755]
21Feb17_063755| [ 1.04748 -1.47444 -0.08469]
21Feb17_063755| [ 0.49410  0.38745  0.68469]
21Feb17_063755| [-0.62880  0.73245  0.19964]]
21Feb17_063755|-- Bias --
21Feb17_063755|[-0.18798  0.64571 -0.23142]
21Feb17_063755|Layer 1:
21Feb17_063755|-- Config --
21Feb17_063755|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063755|-- Weights --
21Feb17_063755|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_063755| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_063755| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_063755|-- Bias --
21Feb17_063755|[0.60477 0.03773 0.26452 0.12222]
21Feb17_063755|Layer 2:
21Feb17_063755|-- Config --
21Feb17_063755|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063755|-- Weights --
21Feb17_063755|[[ 0.67920  0.12119]
21Feb17_063755| [ 0.44836  0.02916]
21Feb17_063755| [ 0.68939  0.31516]
21Feb17_063755| [-0.58995 -0.05861]]
21Feb17_063755|-- Bias --
21Feb17_063755|[ 0.59649 -0.08079]
21Feb17_063755|Layer 3:
21Feb17_063755|-- Config --
21Feb17_063755|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063755|-- Weights --
21Feb17_063755|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_063755| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_063755|-- Bias --
21Feb17_063755|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_063755|Layer 4:
21Feb17_063755|-- Config --
21Feb17_063755|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063755|-- Weights --
21Feb17_063755|[[-0.03514 -1.04833]
21Feb17_063755| [ 1.25238  0.62094]
21Feb17_063755| [ 0.99203  0.37406]
21Feb17_063755| [ 0.49902  0.67158]
21Feb17_063755| [-1.35709  0.38335]]
21Feb17_063755|-- Bias --
21Feb17_063755|[0.31435 0.36299]
21Feb17_063755|Predicting the validation and test data with the Best final individual.
21Feb17_063803| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_063803|-----------  ------------------  --------------------  ----------
21Feb17_063803|Validation         22.78                  56            0.83496
21Feb17_063803|   Test            21.11                  56            0.79855
21Feb17_063803|-------------------- Test #7 --------------------
21Feb17_063803|Best final individual weights
21Feb17_063803|Individual:
21Feb17_063803|-- Constant hidden layers --
21Feb17_063803|False
21Feb17_063803|Layer 0:
21Feb17_063803|-- Config --
21Feb17_063803|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063803|-- Weights --
21Feb17_063803|[[-0.73212  1.32861  0.10200]
21Feb17_063803| [ 1.48746 -2.97273 -0.42944]
21Feb17_063803| [ 0.53095 -1.50623  0.79224]
21Feb17_063803| [-1.07292 -0.83175 -0.90105]
21Feb17_063803| [-0.48696 -0.89325  0.27226]
21Feb17_063803| [-3.02511  0.34155 -0.03837]
21Feb17_063803| [-0.76747  0.57140 -0.46892]
21Feb17_063803| [-0.07581  0.14713  0.85910]
21Feb17_063803| [-1.37488  0.52170 -0.36205]
21Feb17_063803| [ 1.60981 -0.08727 -0.11267]
21Feb17_063803| [ 0.50986  1.58916 -0.35287]
21Feb17_063803| [-0.34599  1.27113 -0.16393]
21Feb17_063803| [ 1.29203  1.19467  0.37695]
21Feb17_063803| [ 0.58704  0.06328 -0.24240]
21Feb17_063803| [-0.93888 -0.89760  0.57087]
21Feb17_063803| [ 0.99159 -0.66387  0.35177]
21Feb17_063803| [-0.67119  1.06910 -0.12512]
21Feb17_063803| [-0.91534  1.23744 -0.40465]
21Feb17_063803| [ 1.39278  0.08069  0.23328]
21Feb17_063803| [ 0.09880  0.57603 -0.96101]
21Feb17_063803| [ 0.01621 -0.13343 -0.27624]
21Feb17_063803| [-1.28286 -2.28909  0.37931]
21Feb17_063803| [-0.28370  0.09336  0.01547]
21Feb17_063803| [-0.51894  1.84280 -0.25906]
21Feb17_063803| [-0.83075 -0.04508  0.12107]
21Feb17_063803| [ 0.37343  1.18436 -0.07358]
21Feb17_063803| [-2.38657 -0.35191  0.01962]
21Feb17_063803| [ 0.95757 -0.91760 -0.08971]
21Feb17_063803| [ 0.38792 -0.01880  0.69717]
21Feb17_063803| [ 1.66877 -0.58078 -1.21129]
21Feb17_063803| [-0.50943  0.59080  0.30856]
21Feb17_063803| [ 0.30163  1.11518  0.98185]
21Feb17_063803| [-0.73226  0.32281 -0.66712]
21Feb17_063803| [-0.62054 -2.21049  1.40981]
21Feb17_063803| [ 1.23185 -0.58090  0.35844]
21Feb17_063803| [-0.05616  0.24219 -0.02853]
21Feb17_063803| [-1.05085 -2.30259 -0.16276]
21Feb17_063803| [ 0.71087  0.14900  1.13430]
21Feb17_063803| [-2.45877 -1.20999 -1.04986]
21Feb17_063803| [-1.00480  1.36344 -0.13998]
21Feb17_063803| [ 1.83140 -0.91532  0.07616]
21Feb17_063803| [-0.60404 -2.05184  0.76948]
21Feb17_063803| [ 0.52617  0.76042 -1.76746]
21Feb17_063803| [-0.22134  0.17324  0.99530]
21Feb17_063803| [-0.36427  1.34655  0.02110]
21Feb17_063803| [-0.93125 -0.33620 -0.25012]
21Feb17_063803| [-2.76428  0.14487  0.48096]
21Feb17_063803| [-0.10518  0.35052  1.71840]
21Feb17_063803| [-1.27998  1.12568  1.26523]
21Feb17_063803| [-0.60698  1.53230 -0.60824]
21Feb17_063803| [ 0.02898  2.98718 -0.59153]
21Feb17_063803| [ 0.17588 -0.00449  0.50797]
21Feb17_063803| [-1.42674 -0.54967 -0.21310]
21Feb17_063803| [ 1.03196  1.18733  0.36755]
21Feb17_063803| [ 1.04748 -1.47444 -0.08469]
21Feb17_063803| [ 0.49410  0.38745  0.68469]
21Feb17_063803| [-0.62880  0.73245  0.19964]]
21Feb17_063803|-- Bias --
21Feb17_063803|[-0.18798  0.64571 -0.23142]
21Feb17_063803|Layer 1:
21Feb17_063803|-- Config --
21Feb17_063803|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063803|-- Weights --
21Feb17_063803|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_063803| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_063803| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_063803|-- Bias --
21Feb17_063803|[0.60477 0.03773 0.26452 0.12222]
21Feb17_063803|Layer 2:
21Feb17_063803|-- Config --
21Feb17_063803|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063803|-- Weights --
21Feb17_063803|[[ 0.67920  0.12119]
21Feb17_063803| [ 0.44836  0.02916]
21Feb17_063803| [ 0.68939  0.31516]
21Feb17_063803| [-0.58995 -0.05861]]
21Feb17_063803|-- Bias --
21Feb17_063803|[ 0.59649 -0.08079]
21Feb17_063803|Layer 3:
21Feb17_063803|-- Config --
21Feb17_063803|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063803|-- Weights --
21Feb17_063803|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_063803| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_063803|-- Bias --
21Feb17_063803|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_063803|Layer 4:
21Feb17_063803|-- Config --
21Feb17_063803|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063803|-- Weights --
21Feb17_063803|[[-0.03514 -1.04833]
21Feb17_063803| [ 1.25238  0.62094]
21Feb17_063803| [ 0.99203  0.37406]
21Feb17_063803| [ 0.49902  0.67158]
21Feb17_063803| [-1.35709  0.38335]]
21Feb17_063803|-- Bias --
21Feb17_063803|[0.31435 0.36299]
21Feb17_063803|Predicting the validation and test data with the Best final individual.
21Feb17_063811| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_063811|-----------  ------------------  --------------------  ----------
21Feb17_063811|Validation         28.96                  56            0.48780
21Feb17_063811|   Test            25.46                  56            0.49431
21Feb17_063811|-------------------- Test #8 --------------------
21Feb17_063811|Best final individual weights
21Feb17_063811|Individual:
21Feb17_063811|-- Constant hidden layers --
21Feb17_063811|False
21Feb17_063811|Layer 0:
21Feb17_063811|-- Config --
21Feb17_063811|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063811|-- Weights --
21Feb17_063811|[[-0.73212  1.32861  0.10200]
21Feb17_063811| [ 1.48746 -2.97273 -0.42944]
21Feb17_063811| [ 0.53095 -1.50623  0.79224]
21Feb17_063811| [-1.07292 -0.83175 -0.90105]
21Feb17_063811| [-0.48696 -0.89325  0.27226]
21Feb17_063811| [-3.02511  0.34155 -0.03837]
21Feb17_063811| [-0.76747  0.57140 -0.46892]
21Feb17_063811| [-0.07581  0.14713  0.85910]
21Feb17_063811| [-1.37488  0.52170 -0.36205]
21Feb17_063811| [ 1.60981 -0.08727 -0.11267]
21Feb17_063811| [ 0.50986  1.58916 -0.35287]
21Feb17_063811| [-0.34599  1.27113 -0.16393]
21Feb17_063811| [ 1.29203  1.19467  0.37695]
21Feb17_063811| [ 0.58704  0.06328 -0.24240]
21Feb17_063811| [-0.93888 -0.89760  0.57087]
21Feb17_063811| [ 0.99159 -0.66387  0.35177]
21Feb17_063811| [-0.67119  1.06910 -0.12512]
21Feb17_063811| [-0.91534  1.23744 -0.40465]
21Feb17_063811| [ 1.39278  0.08069  0.23328]
21Feb17_063811| [ 0.09880  0.57603 -0.96101]
21Feb17_063811| [ 0.01621 -0.13343 -0.27624]
21Feb17_063811| [-1.28286 -2.28909  0.37931]
21Feb17_063811| [-0.28370  0.09336  0.01547]
21Feb17_063811| [-0.51894  1.84280 -0.25906]
21Feb17_063811| [-0.83075 -0.04508  0.12107]
21Feb17_063811| [ 0.37343  1.18436 -0.07358]
21Feb17_063811| [-2.38657 -0.35191  0.01962]
21Feb17_063811| [ 0.95757 -0.91760 -0.08971]
21Feb17_063811| [ 0.38792 -0.01880  0.69717]
21Feb17_063811| [ 1.66877 -0.58078 -1.21129]
21Feb17_063811| [-0.50943  0.59080  0.30856]
21Feb17_063811| [ 0.30163  1.11518  0.98185]
21Feb17_063811| [-0.73226  0.32281 -0.66712]
21Feb17_063811| [-0.62054 -2.21049  1.40981]
21Feb17_063811| [ 1.23185 -0.58090  0.35844]
21Feb17_063811| [-0.05616  0.24219 -0.02853]
21Feb17_063811| [-1.05085 -2.30259 -0.16276]
21Feb17_063811| [ 0.71087  0.14900  1.13430]
21Feb17_063811| [-2.45877 -1.20999 -1.04986]
21Feb17_063811| [-1.00480  1.36344 -0.13998]
21Feb17_063811| [ 1.83140 -0.91532  0.07616]
21Feb17_063811| [-0.60404 -2.05184  0.76948]
21Feb17_063811| [ 0.52617  0.76042 -1.76746]
21Feb17_063811| [-0.22134  0.17324  0.99530]
21Feb17_063811| [-0.36427  1.34655  0.02110]
21Feb17_063811| [-0.93125 -0.33620 -0.25012]
21Feb17_063811| [-2.76428  0.14487  0.48096]
21Feb17_063811| [-0.10518  0.35052  1.71840]
21Feb17_063811| [-1.27998  1.12568  1.26523]
21Feb17_063811| [-0.60698  1.53230 -0.60824]
21Feb17_063811| [ 0.02898  2.98718 -0.59153]
21Feb17_063811| [ 0.17588 -0.00449  0.50797]
21Feb17_063811| [-1.42674 -0.54967 -0.21310]
21Feb17_063811| [ 1.03196  1.18733  0.36755]
21Feb17_063811| [ 1.04748 -1.47444 -0.08469]
21Feb17_063811| [ 0.49410  0.38745  0.68469]
21Feb17_063811| [-0.62880  0.73245  0.19964]]
21Feb17_063811|-- Bias --
21Feb17_063811|[-0.18798  0.64571 -0.23142]
21Feb17_063811|Layer 1:
21Feb17_063811|-- Config --
21Feb17_063811|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063811|-- Weights --
21Feb17_063811|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_063811| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_063811| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_063811|-- Bias --
21Feb17_063811|[0.60477 0.03773 0.26452 0.12222]
21Feb17_063811|Layer 2:
21Feb17_063811|-- Config --
21Feb17_063811|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063811|-- Weights --
21Feb17_063811|[[ 0.67920  0.12119]
21Feb17_063811| [ 0.44836  0.02916]
21Feb17_063811| [ 0.68939  0.31516]
21Feb17_063811| [-0.58995 -0.05861]]
21Feb17_063811|-- Bias --
21Feb17_063811|[ 0.59649 -0.08079]
21Feb17_063811|Layer 3:
21Feb17_063811|-- Config --
21Feb17_063811|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063811|-- Weights --
21Feb17_063811|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_063811| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_063811|-- Bias --
21Feb17_063811|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_063811|Layer 4:
21Feb17_063811|-- Config --
21Feb17_063811|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063811|-- Weights --
21Feb17_063811|[[-0.03514 -1.04833]
21Feb17_063811| [ 1.25238  0.62094]
21Feb17_063811| [ 0.99203  0.37406]
21Feb17_063811| [ 0.49902  0.67158]
21Feb17_063811| [-1.35709  0.38335]]
21Feb17_063811|-- Bias --
21Feb17_063811|[0.31435 0.36299]
21Feb17_063811|Predicting the validation and test data with the Best final individual.
21Feb17_063819| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_063819|-----------  ------------------  --------------------  ----------
21Feb17_063819|Validation         21.30                  56            0.82476
21Feb17_063819|   Test            21.81                  56            0.83186
21Feb17_063819|-------------------- Test #9 --------------------
21Feb17_063819|Best final individual weights
21Feb17_063819|Individual:
21Feb17_063819|-- Constant hidden layers --
21Feb17_063819|False
21Feb17_063819|Layer 0:
21Feb17_063819|-- Config --
21Feb17_063819|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063819|-- Weights --
21Feb17_063819|[[-0.73212  1.32861  0.10200]
21Feb17_063819| [ 1.48746 -2.97273 -0.42944]
21Feb17_063819| [ 0.53095 -1.50623  0.79224]
21Feb17_063819| [-1.07292 -0.83175 -0.90105]
21Feb17_063819| [-0.48696 -0.89325  0.27226]
21Feb17_063819| [-3.02511  0.34155 -0.03837]
21Feb17_063819| [-0.76747  0.57140 -0.46892]
21Feb17_063819| [-0.07581  0.14713  0.85910]
21Feb17_063819| [-1.37488  0.52170 -0.36205]
21Feb17_063819| [ 1.60981 -0.08727 -0.11267]
21Feb17_063819| [ 0.50986  1.58916 -0.35287]
21Feb17_063819| [-0.34599  1.27113 -0.16393]
21Feb17_063819| [ 1.29203  1.19467  0.37695]
21Feb17_063819| [ 0.58704  0.06328 -0.24240]
21Feb17_063819| [-0.93888 -0.89760  0.57087]
21Feb17_063819| [ 0.99159 -0.66387  0.35177]
21Feb17_063819| [-0.67119  1.06910 -0.12512]
21Feb17_063819| [-0.91534  1.23744 -0.40465]
21Feb17_063819| [ 1.39278  0.08069  0.23328]
21Feb17_063819| [ 0.09880  0.57603 -0.96101]
21Feb17_063819| [ 0.01621 -0.13343 -0.27624]
21Feb17_063819| [-1.28286 -2.28909  0.37931]
21Feb17_063819| [-0.28370  0.09336  0.01547]
21Feb17_063819| [-0.51894  1.84280 -0.25906]
21Feb17_063819| [-0.83075 -0.04508  0.12107]
21Feb17_063819| [ 0.37343  1.18436 -0.07358]
21Feb17_063819| [-2.38657 -0.35191  0.01962]
21Feb17_063819| [ 0.95757 -0.91760 -0.08971]
21Feb17_063819| [ 0.38792 -0.01880  0.69717]
21Feb17_063819| [ 1.66877 -0.58078 -1.21129]
21Feb17_063819| [-0.50943  0.59080  0.30856]
21Feb17_063819| [ 0.30163  1.11518  0.98185]
21Feb17_063819| [-0.73226  0.32281 -0.66712]
21Feb17_063819| [-0.62054 -2.21049  1.40981]
21Feb17_063819| [ 1.23185 -0.58090  0.35844]
21Feb17_063819| [-0.05616  0.24219 -0.02853]
21Feb17_063819| [-1.05085 -2.30259 -0.16276]
21Feb17_063819| [ 0.71087  0.14900  1.13430]
21Feb17_063819| [-2.45877 -1.20999 -1.04986]
21Feb17_063819| [-1.00480  1.36344 -0.13998]
21Feb17_063819| [ 1.83140 -0.91532  0.07616]
21Feb17_063819| [-0.60404 -2.05184  0.76948]
21Feb17_063819| [ 0.52617  0.76042 -1.76746]
21Feb17_063819| [-0.22134  0.17324  0.99530]
21Feb17_063819| [-0.36427  1.34655  0.02110]
21Feb17_063819| [-0.93125 -0.33620 -0.25012]
21Feb17_063819| [-2.76428  0.14487  0.48096]
21Feb17_063819| [-0.10518  0.35052  1.71840]
21Feb17_063819| [-1.27998  1.12568  1.26523]
21Feb17_063819| [-0.60698  1.53230 -0.60824]
21Feb17_063819| [ 0.02898  2.98718 -0.59153]
21Feb17_063819| [ 0.17588 -0.00449  0.50797]
21Feb17_063819| [-1.42674 -0.54967 -0.21310]
21Feb17_063819| [ 1.03196  1.18733  0.36755]
21Feb17_063819| [ 1.04748 -1.47444 -0.08469]
21Feb17_063819| [ 0.49410  0.38745  0.68469]
21Feb17_063819| [-0.62880  0.73245  0.19964]]
21Feb17_063819|-- Bias --
21Feb17_063819|[-0.18798  0.64571 -0.23142]
21Feb17_063819|Layer 1:
21Feb17_063819|-- Config --
21Feb17_063819|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063819|-- Weights --
21Feb17_063819|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_063819| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_063819| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_063819|-- Bias --
21Feb17_063819|[0.60477 0.03773 0.26452 0.12222]
21Feb17_063819|Layer 2:
21Feb17_063819|-- Config --
21Feb17_063819|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063819|-- Weights --
21Feb17_063819|[[ 0.67920  0.12119]
21Feb17_063819| [ 0.44836  0.02916]
21Feb17_063819| [ 0.68939  0.31516]
21Feb17_063819| [-0.58995 -0.05861]]
21Feb17_063819|-- Bias --
21Feb17_063819|[ 0.59649 -0.08079]
21Feb17_063819|Layer 3:
21Feb17_063819|-- Config --
21Feb17_063819|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063819|-- Weights --
21Feb17_063819|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_063819| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_063819|-- Bias --
21Feb17_063819|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_063819|Layer 4:
21Feb17_063819|-- Config --
21Feb17_063819|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063819|-- Weights --
21Feb17_063819|[[-0.03514 -1.04833]
21Feb17_063819| [ 1.25238  0.62094]
21Feb17_063819| [ 0.99203  0.37406]
21Feb17_063819| [ 0.49902  0.67158]
21Feb17_063819| [-1.35709  0.38335]]
21Feb17_063819|-- Bias --
21Feb17_063819|[0.31435 0.36299]
21Feb17_063819|Predicting the validation and test data with the Best final individual.
21Feb17_063826| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_063826|-----------  ------------------  --------------------  ----------
21Feb17_063826|Validation         26.43                  56            0.71922
21Feb17_063826|   Test            29.54                  56            0.67444
21Feb17_063826|-------------------- Test #10 --------------------
21Feb17_063826|Best final individual weights
21Feb17_063826|Individual:
21Feb17_063826|-- Constant hidden layers --
21Feb17_063826|False
21Feb17_063826|Layer 0:
21Feb17_063826|-- Config --
21Feb17_063826|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063826|-- Weights --
21Feb17_063826|[[-0.73212  1.32861  0.10200]
21Feb17_063826| [ 1.48746 -2.97273 -0.42944]
21Feb17_063826| [ 0.53095 -1.50623  0.79224]
21Feb17_063826| [-1.07292 -0.83175 -0.90105]
21Feb17_063826| [-0.48696 -0.89325  0.27226]
21Feb17_063826| [-3.02511  0.34155 -0.03837]
21Feb17_063826| [-0.76747  0.57140 -0.46892]
21Feb17_063826| [-0.07581  0.14713  0.85910]
21Feb17_063826| [-1.37488  0.52170 -0.36205]
21Feb17_063826| [ 1.60981 -0.08727 -0.11267]
21Feb17_063826| [ 0.50986  1.58916 -0.35287]
21Feb17_063826| [-0.34599  1.27113 -0.16393]
21Feb17_063826| [ 1.29203  1.19467  0.37695]
21Feb17_063826| [ 0.58704  0.06328 -0.24240]
21Feb17_063826| [-0.93888 -0.89760  0.57087]
21Feb17_063826| [ 0.99159 -0.66387  0.35177]
21Feb17_063826| [-0.67119  1.06910 -0.12512]
21Feb17_063826| [-0.91534  1.23744 -0.40465]
21Feb17_063826| [ 1.39278  0.08069  0.23328]
21Feb17_063826| [ 0.09880  0.57603 -0.96101]
21Feb17_063826| [ 0.01621 -0.13343 -0.27624]
21Feb17_063826| [-1.28286 -2.28909  0.37931]
21Feb17_063826| [-0.28370  0.09336  0.01547]
21Feb17_063826| [-0.51894  1.84280 -0.25906]
21Feb17_063826| [-0.83075 -0.04508  0.12107]
21Feb17_063826| [ 0.37343  1.18436 -0.07358]
21Feb17_063826| [-2.38657 -0.35191  0.01962]
21Feb17_063826| [ 0.95757 -0.91760 -0.08971]
21Feb17_063826| [ 0.38792 -0.01880  0.69717]
21Feb17_063826| [ 1.66877 -0.58078 -1.21129]
21Feb17_063826| [-0.50943  0.59080  0.30856]
21Feb17_063826| [ 0.30163  1.11518  0.98185]
21Feb17_063826| [-0.73226  0.32281 -0.66712]
21Feb17_063826| [-0.62054 -2.21049  1.40981]
21Feb17_063826| [ 1.23185 -0.58090  0.35844]
21Feb17_063826| [-0.05616  0.24219 -0.02853]
21Feb17_063826| [-1.05085 -2.30259 -0.16276]
21Feb17_063826| [ 0.71087  0.14900  1.13430]
21Feb17_063826| [-2.45877 -1.20999 -1.04986]
21Feb17_063826| [-1.00480  1.36344 -0.13998]
21Feb17_063826| [ 1.83140 -0.91532  0.07616]
21Feb17_063826| [-0.60404 -2.05184  0.76948]
21Feb17_063826| [ 0.52617  0.76042 -1.76746]
21Feb17_063826| [-0.22134  0.17324  0.99530]
21Feb17_063826| [-0.36427  1.34655  0.02110]
21Feb17_063826| [-0.93125 -0.33620 -0.25012]
21Feb17_063826| [-2.76428  0.14487  0.48096]
21Feb17_063826| [-0.10518  0.35052  1.71840]
21Feb17_063826| [-1.27998  1.12568  1.26523]
21Feb17_063826| [-0.60698  1.53230 -0.60824]
21Feb17_063826| [ 0.02898  2.98718 -0.59153]
21Feb17_063826| [ 0.17588 -0.00449  0.50797]
21Feb17_063826| [-1.42674 -0.54967 -0.21310]
21Feb17_063826| [ 1.03196  1.18733  0.36755]
21Feb17_063826| [ 1.04748 -1.47444 -0.08469]
21Feb17_063826| [ 0.49410  0.38745  0.68469]
21Feb17_063826| [-0.62880  0.73245  0.19964]]
21Feb17_063826|-- Bias --
21Feb17_063826|[-0.18798  0.64571 -0.23142]
21Feb17_063826|Layer 1:
21Feb17_063826|-- Config --
21Feb17_063826|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063826|-- Weights --
21Feb17_063826|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_063826| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_063826| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_063826|-- Bias --
21Feb17_063826|[0.60477 0.03773 0.26452 0.12222]
21Feb17_063826|Layer 2:
21Feb17_063826|-- Config --
21Feb17_063826|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063826|-- Weights --
21Feb17_063826|[[ 0.67920  0.12119]
21Feb17_063826| [ 0.44836  0.02916]
21Feb17_063826| [ 0.68939  0.31516]
21Feb17_063826| [-0.58995 -0.05861]]
21Feb17_063826|-- Bias --
21Feb17_063826|[ 0.59649 -0.08079]
21Feb17_063826|Layer 3:
21Feb17_063826|-- Config --
21Feb17_063826|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063826|-- Weights --
21Feb17_063826|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_063826| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_063826|-- Bias --
21Feb17_063826|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_063826|Layer 4:
21Feb17_063826|-- Config --
21Feb17_063826|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063826|-- Weights --
21Feb17_063826|[[-0.03514 -1.04833]
21Feb17_063826| [ 1.25238  0.62094]
21Feb17_063826| [ 0.99203  0.37406]
21Feb17_063826| [ 0.49902  0.67158]
21Feb17_063826| [-1.35709  0.38335]]
21Feb17_063826|-- Bias --
21Feb17_063826|[0.31435 0.36299]
21Feb17_063826|Predicting the validation and test data with the Best final individual.
21Feb17_063834| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_063834|-----------  ------------------  --------------------  ----------
21Feb17_063834|Validation         23.65                  56            0.85845
21Feb17_063834|   Test            26.67                  56            0.71298
21Feb17_063834|-------------------- Test #11 --------------------
21Feb17_063834|Best final individual weights
21Feb17_063834|Individual:
21Feb17_063834|-- Constant hidden layers --
21Feb17_063834|False
21Feb17_063834|Layer 0:
21Feb17_063834|-- Config --
21Feb17_063834|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063834|-- Weights --
21Feb17_063834|[[-0.73212  1.32861  0.10200]
21Feb17_063834| [ 1.48746 -2.97273 -0.42944]
21Feb17_063834| [ 0.53095 -1.50623  0.79224]
21Feb17_063834| [-1.07292 -0.83175 -0.90105]
21Feb17_063834| [-0.48696 -0.89325  0.27226]
21Feb17_063834| [-3.02511  0.34155 -0.03837]
21Feb17_063834| [-0.76747  0.57140 -0.46892]
21Feb17_063834| [-0.07581  0.14713  0.85910]
21Feb17_063834| [-1.37488  0.52170 -0.36205]
21Feb17_063834| [ 1.60981 -0.08727 -0.11267]
21Feb17_063834| [ 0.50986  1.58916 -0.35287]
21Feb17_063834| [-0.34599  1.27113 -0.16393]
21Feb17_063834| [ 1.29203  1.19467  0.37695]
21Feb17_063834| [ 0.58704  0.06328 -0.24240]
21Feb17_063834| [-0.93888 -0.89760  0.57087]
21Feb17_063834| [ 0.99159 -0.66387  0.35177]
21Feb17_063834| [-0.67119  1.06910 -0.12512]
21Feb17_063834| [-0.91534  1.23744 -0.40465]
21Feb17_063834| [ 1.39278  0.08069  0.23328]
21Feb17_063834| [ 0.09880  0.57603 -0.96101]
21Feb17_063834| [ 0.01621 -0.13343 -0.27624]
21Feb17_063834| [-1.28286 -2.28909  0.37931]
21Feb17_063834| [-0.28370  0.09336  0.01547]
21Feb17_063834| [-0.51894  1.84280 -0.25906]
21Feb17_063834| [-0.83075 -0.04508  0.12107]
21Feb17_063834| [ 0.37343  1.18436 -0.07358]
21Feb17_063834| [-2.38657 -0.35191  0.01962]
21Feb17_063834| [ 0.95757 -0.91760 -0.08971]
21Feb17_063834| [ 0.38792 -0.01880  0.69717]
21Feb17_063834| [ 1.66877 -0.58078 -1.21129]
21Feb17_063834| [-0.50943  0.59080  0.30856]
21Feb17_063834| [ 0.30163  1.11518  0.98185]
21Feb17_063834| [-0.73226  0.32281 -0.66712]
21Feb17_063834| [-0.62054 -2.21049  1.40981]
21Feb17_063834| [ 1.23185 -0.58090  0.35844]
21Feb17_063834| [-0.05616  0.24219 -0.02853]
21Feb17_063834| [-1.05085 -2.30259 -0.16276]
21Feb17_063834| [ 0.71087  0.14900  1.13430]
21Feb17_063834| [-2.45877 -1.20999 -1.04986]
21Feb17_063834| [-1.00480  1.36344 -0.13998]
21Feb17_063834| [ 1.83140 -0.91532  0.07616]
21Feb17_063834| [-0.60404 -2.05184  0.76948]
21Feb17_063834| [ 0.52617  0.76042 -1.76746]
21Feb17_063834| [-0.22134  0.17324  0.99530]
21Feb17_063834| [-0.36427  1.34655  0.02110]
21Feb17_063834| [-0.93125 -0.33620 -0.25012]
21Feb17_063834| [-2.76428  0.14487  0.48096]
21Feb17_063834| [-0.10518  0.35052  1.71840]
21Feb17_063834| [-1.27998  1.12568  1.26523]
21Feb17_063834| [-0.60698  1.53230 -0.60824]
21Feb17_063834| [ 0.02898  2.98718 -0.59153]
21Feb17_063834| [ 0.17588 -0.00449  0.50797]
21Feb17_063834| [-1.42674 -0.54967 -0.21310]
21Feb17_063834| [ 1.03196  1.18733  0.36755]
21Feb17_063834| [ 1.04748 -1.47444 -0.08469]
21Feb17_063834| [ 0.49410  0.38745  0.68469]
21Feb17_063834| [-0.62880  0.73245  0.19964]]
21Feb17_063834|-- Bias --
21Feb17_063834|[-0.18798  0.64571 -0.23142]
21Feb17_063834|Layer 1:
21Feb17_063834|-- Config --
21Feb17_063834|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063834|-- Weights --
21Feb17_063834|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_063834| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_063834| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_063834|-- Bias --
21Feb17_063834|[0.60477 0.03773 0.26452 0.12222]
21Feb17_063834|Layer 2:
21Feb17_063834|-- Config --
21Feb17_063834|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063834|-- Weights --
21Feb17_063834|[[ 0.67920  0.12119]
21Feb17_063834| [ 0.44836  0.02916]
21Feb17_063834| [ 0.68939  0.31516]
21Feb17_063834| [-0.58995 -0.05861]]
21Feb17_063834|-- Bias --
21Feb17_063834|[ 0.59649 -0.08079]
21Feb17_063834|Layer 3:
21Feb17_063834|-- Config --
21Feb17_063834|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063834|-- Weights --
21Feb17_063834|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_063834| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_063834|-- Bias --
21Feb17_063834|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_063834|Layer 4:
21Feb17_063834|-- Config --
21Feb17_063834|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063834|-- Weights --
21Feb17_063834|[[-0.03514 -1.04833]
21Feb17_063834| [ 1.25238  0.62094]
21Feb17_063834| [ 0.99203  0.37406]
21Feb17_063834| [ 0.49902  0.67158]
21Feb17_063834| [-1.35709  0.38335]]
21Feb17_063834|-- Bias --
21Feb17_063834|[0.31435 0.36299]
21Feb17_063834|Predicting the validation and test data with the Best final individual.
21Feb17_063842| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_063842|-----------  ------------------  --------------------  ----------
21Feb17_063842|Validation         23.48                  56            0.78306
21Feb17_063842|   Test            22.07                  56            0.85403
21Feb17_063842|-------------------- Test #12 --------------------
21Feb17_063842|Best final individual weights
21Feb17_063842|Individual:
21Feb17_063842|-- Constant hidden layers --
21Feb17_063842|False
21Feb17_063842|Layer 0:
21Feb17_063842|-- Config --
21Feb17_063842|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063842|-- Weights --
21Feb17_063842|[[-0.73212  1.32861  0.10200]
21Feb17_063842| [ 1.48746 -2.97273 -0.42944]
21Feb17_063842| [ 0.53095 -1.50623  0.79224]
21Feb17_063842| [-1.07292 -0.83175 -0.90105]
21Feb17_063842| [-0.48696 -0.89325  0.27226]
21Feb17_063842| [-3.02511  0.34155 -0.03837]
21Feb17_063842| [-0.76747  0.57140 -0.46892]
21Feb17_063842| [-0.07581  0.14713  0.85910]
21Feb17_063842| [-1.37488  0.52170 -0.36205]
21Feb17_063842| [ 1.60981 -0.08727 -0.11267]
21Feb17_063842| [ 0.50986  1.58916 -0.35287]
21Feb17_063842| [-0.34599  1.27113 -0.16393]
21Feb17_063842| [ 1.29203  1.19467  0.37695]
21Feb17_063842| [ 0.58704  0.06328 -0.24240]
21Feb17_063842| [-0.93888 -0.89760  0.57087]
21Feb17_063842| [ 0.99159 -0.66387  0.35177]
21Feb17_063842| [-0.67119  1.06910 -0.12512]
21Feb17_063842| [-0.91534  1.23744 -0.40465]
21Feb17_063842| [ 1.39278  0.08069  0.23328]
21Feb17_063842| [ 0.09880  0.57603 -0.96101]
21Feb17_063842| [ 0.01621 -0.13343 -0.27624]
21Feb17_063842| [-1.28286 -2.28909  0.37931]
21Feb17_063842| [-0.28370  0.09336  0.01547]
21Feb17_063842| [-0.51894  1.84280 -0.25906]
21Feb17_063842| [-0.83075 -0.04508  0.12107]
21Feb17_063842| [ 0.37343  1.18436 -0.07358]
21Feb17_063842| [-2.38657 -0.35191  0.01962]
21Feb17_063842| [ 0.95757 -0.91760 -0.08971]
21Feb17_063842| [ 0.38792 -0.01880  0.69717]
21Feb17_063842| [ 1.66877 -0.58078 -1.21129]
21Feb17_063842| [-0.50943  0.59080  0.30856]
21Feb17_063842| [ 0.30163  1.11518  0.98185]
21Feb17_063842| [-0.73226  0.32281 -0.66712]
21Feb17_063842| [-0.62054 -2.21049  1.40981]
21Feb17_063842| [ 1.23185 -0.58090  0.35844]
21Feb17_063842| [-0.05616  0.24219 -0.02853]
21Feb17_063842| [-1.05085 -2.30259 -0.16276]
21Feb17_063842| [ 0.71087  0.14900  1.13430]
21Feb17_063842| [-2.45877 -1.20999 -1.04986]
21Feb17_063842| [-1.00480  1.36344 -0.13998]
21Feb17_063842| [ 1.83140 -0.91532  0.07616]
21Feb17_063842| [-0.60404 -2.05184  0.76948]
21Feb17_063842| [ 0.52617  0.76042 -1.76746]
21Feb17_063842| [-0.22134  0.17324  0.99530]
21Feb17_063842| [-0.36427  1.34655  0.02110]
21Feb17_063842| [-0.93125 -0.33620 -0.25012]
21Feb17_063842| [-2.76428  0.14487  0.48096]
21Feb17_063842| [-0.10518  0.35052  1.71840]
21Feb17_063842| [-1.27998  1.12568  1.26523]
21Feb17_063842| [-0.60698  1.53230 -0.60824]
21Feb17_063842| [ 0.02898  2.98718 -0.59153]
21Feb17_063842| [ 0.17588 -0.00449  0.50797]
21Feb17_063842| [-1.42674 -0.54967 -0.21310]
21Feb17_063842| [ 1.03196  1.18733  0.36755]
21Feb17_063842| [ 1.04748 -1.47444 -0.08469]
21Feb17_063842| [ 0.49410  0.38745  0.68469]
21Feb17_063842| [-0.62880  0.73245  0.19964]]
21Feb17_063842|-- Bias --
21Feb17_063842|[-0.18798  0.64571 -0.23142]
21Feb17_063842|Layer 1:
21Feb17_063842|-- Config --
21Feb17_063842|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063842|-- Weights --
21Feb17_063842|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_063842| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_063842| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_063842|-- Bias --
21Feb17_063842|[0.60477 0.03773 0.26452 0.12222]
21Feb17_063842|Layer 2:
21Feb17_063842|-- Config --
21Feb17_063842|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063842|-- Weights --
21Feb17_063842|[[ 0.67920  0.12119]
21Feb17_063842| [ 0.44836  0.02916]
21Feb17_063842| [ 0.68939  0.31516]
21Feb17_063842| [-0.58995 -0.05861]]
21Feb17_063842|-- Bias --
21Feb17_063842|[ 0.59649 -0.08079]
21Feb17_063842|Layer 3:
21Feb17_063842|-- Config --
21Feb17_063842|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063842|-- Weights --
21Feb17_063842|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_063842| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_063842|-- Bias --
21Feb17_063842|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_063842|Layer 4:
21Feb17_063842|-- Config --
21Feb17_063842|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063842|-- Weights --
21Feb17_063842|[[-0.03514 -1.04833]
21Feb17_063842| [ 1.25238  0.62094]
21Feb17_063842| [ 0.99203  0.37406]
21Feb17_063842| [ 0.49902  0.67158]
21Feb17_063842| [-1.35709  0.38335]]
21Feb17_063842|-- Bias --
21Feb17_063842|[0.31435 0.36299]
21Feb17_063842|Predicting the validation and test data with the Best final individual.
21Feb17_063850| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_063850|-----------  ------------------  --------------------  ----------
21Feb17_063850|Validation         24.43                  56            0.85301
21Feb17_063850|   Test            37.01                  56            0.82036
21Feb17_063850|-------------------- Test #13 --------------------
21Feb17_063850|Best final individual weights
21Feb17_063850|Individual:
21Feb17_063850|-- Constant hidden layers --
21Feb17_063850|False
21Feb17_063850|Layer 0:
21Feb17_063850|-- Config --
21Feb17_063850|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063850|-- Weights --
21Feb17_063850|[[-0.73212  1.32861  0.10200]
21Feb17_063850| [ 1.48746 -2.97273 -0.42944]
21Feb17_063850| [ 0.53095 -1.50623  0.79224]
21Feb17_063850| [-1.07292 -0.83175 -0.90105]
21Feb17_063850| [-0.48696 -0.89325  0.27226]
21Feb17_063850| [-3.02511  0.34155 -0.03837]
21Feb17_063850| [-0.76747  0.57140 -0.46892]
21Feb17_063850| [-0.07581  0.14713  0.85910]
21Feb17_063850| [-1.37488  0.52170 -0.36205]
21Feb17_063850| [ 1.60981 -0.08727 -0.11267]
21Feb17_063850| [ 0.50986  1.58916 -0.35287]
21Feb17_063850| [-0.34599  1.27113 -0.16393]
21Feb17_063850| [ 1.29203  1.19467  0.37695]
21Feb17_063850| [ 0.58704  0.06328 -0.24240]
21Feb17_063850| [-0.93888 -0.89760  0.57087]
21Feb17_063850| [ 0.99159 -0.66387  0.35177]
21Feb17_063850| [-0.67119  1.06910 -0.12512]
21Feb17_063850| [-0.91534  1.23744 -0.40465]
21Feb17_063850| [ 1.39278  0.08069  0.23328]
21Feb17_063850| [ 0.09880  0.57603 -0.96101]
21Feb17_063850| [ 0.01621 -0.13343 -0.27624]
21Feb17_063850| [-1.28286 -2.28909  0.37931]
21Feb17_063850| [-0.28370  0.09336  0.01547]
21Feb17_063850| [-0.51894  1.84280 -0.25906]
21Feb17_063850| [-0.83075 -0.04508  0.12107]
21Feb17_063850| [ 0.37343  1.18436 -0.07358]
21Feb17_063850| [-2.38657 -0.35191  0.01962]
21Feb17_063850| [ 0.95757 -0.91760 -0.08971]
21Feb17_063850| [ 0.38792 -0.01880  0.69717]
21Feb17_063850| [ 1.66877 -0.58078 -1.21129]
21Feb17_063850| [-0.50943  0.59080  0.30856]
21Feb17_063850| [ 0.30163  1.11518  0.98185]
21Feb17_063850| [-0.73226  0.32281 -0.66712]
21Feb17_063850| [-0.62054 -2.21049  1.40981]
21Feb17_063850| [ 1.23185 -0.58090  0.35844]
21Feb17_063850| [-0.05616  0.24219 -0.02853]
21Feb17_063850| [-1.05085 -2.30259 -0.16276]
21Feb17_063850| [ 0.71087  0.14900  1.13430]
21Feb17_063850| [-2.45877 -1.20999 -1.04986]
21Feb17_063850| [-1.00480  1.36344 -0.13998]
21Feb17_063850| [ 1.83140 -0.91532  0.07616]
21Feb17_063850| [-0.60404 -2.05184  0.76948]
21Feb17_063850| [ 0.52617  0.76042 -1.76746]
21Feb17_063850| [-0.22134  0.17324  0.99530]
21Feb17_063850| [-0.36427  1.34655  0.02110]
21Feb17_063850| [-0.93125 -0.33620 -0.25012]
21Feb17_063850| [-2.76428  0.14487  0.48096]
21Feb17_063850| [-0.10518  0.35052  1.71840]
21Feb17_063850| [-1.27998  1.12568  1.26523]
21Feb17_063850| [-0.60698  1.53230 -0.60824]
21Feb17_063850| [ 0.02898  2.98718 -0.59153]
21Feb17_063850| [ 0.17588 -0.00449  0.50797]
21Feb17_063850| [-1.42674 -0.54967 -0.21310]
21Feb17_063850| [ 1.03196  1.18733  0.36755]
21Feb17_063850| [ 1.04748 -1.47444 -0.08469]
21Feb17_063850| [ 0.49410  0.38745  0.68469]
21Feb17_063850| [-0.62880  0.73245  0.19964]]
21Feb17_063850|-- Bias --
21Feb17_063850|[-0.18798  0.64571 -0.23142]
21Feb17_063850|Layer 1:
21Feb17_063850|-- Config --
21Feb17_063850|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063850|-- Weights --
21Feb17_063850|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_063850| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_063850| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_063850|-- Bias --
21Feb17_063850|[0.60477 0.03773 0.26452 0.12222]
21Feb17_063850|Layer 2:
21Feb17_063850|-- Config --
21Feb17_063850|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063850|-- Weights --
21Feb17_063850|[[ 0.67920  0.12119]
21Feb17_063850| [ 0.44836  0.02916]
21Feb17_063850| [ 0.68939  0.31516]
21Feb17_063850| [-0.58995 -0.05861]]
21Feb17_063850|-- Bias --
21Feb17_063850|[ 0.59649 -0.08079]
21Feb17_063850|Layer 3:
21Feb17_063850|-- Config --
21Feb17_063850|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063850|-- Weights --
21Feb17_063850|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_063850| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_063850|-- Bias --
21Feb17_063850|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_063850|Layer 4:
21Feb17_063850|-- Config --
21Feb17_063850|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063850|-- Weights --
21Feb17_063850|[[-0.03514 -1.04833]
21Feb17_063850| [ 1.25238  0.62094]
21Feb17_063850| [ 0.99203  0.37406]
21Feb17_063850| [ 0.49902  0.67158]
21Feb17_063850| [-1.35709  0.38335]]
21Feb17_063850|-- Bias --
21Feb17_063850|[0.31435 0.36299]
21Feb17_063850|Predicting the validation and test data with the Best final individual.
21Feb17_063857| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_063857|-----------  ------------------  --------------------  ----------
21Feb17_063857|Validation         21.74                  56            0.74120
21Feb17_063857|   Test            25.80                  56            0.72926
21Feb17_063857|-------------------- Test #14 --------------------
21Feb17_063857|Best final individual weights
21Feb17_063857|Individual:
21Feb17_063857|-- Constant hidden layers --
21Feb17_063857|False
21Feb17_063857|Layer 0:
21Feb17_063857|-- Config --
21Feb17_063857|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063857|-- Weights --
21Feb17_063857|[[-0.73212  1.32861  0.10200]
21Feb17_063857| [ 1.48746 -2.97273 -0.42944]
21Feb17_063857| [ 0.53095 -1.50623  0.79224]
21Feb17_063857| [-1.07292 -0.83175 -0.90105]
21Feb17_063857| [-0.48696 -0.89325  0.27226]
21Feb17_063857| [-3.02511  0.34155 -0.03837]
21Feb17_063857| [-0.76747  0.57140 -0.46892]
21Feb17_063857| [-0.07581  0.14713  0.85910]
21Feb17_063857| [-1.37488  0.52170 -0.36205]
21Feb17_063857| [ 1.60981 -0.08727 -0.11267]
21Feb17_063857| [ 0.50986  1.58916 -0.35287]
21Feb17_063857| [-0.34599  1.27113 -0.16393]
21Feb17_063857| [ 1.29203  1.19467  0.37695]
21Feb17_063857| [ 0.58704  0.06328 -0.24240]
21Feb17_063857| [-0.93888 -0.89760  0.57087]
21Feb17_063857| [ 0.99159 -0.66387  0.35177]
21Feb17_063857| [-0.67119  1.06910 -0.12512]
21Feb17_063857| [-0.91534  1.23744 -0.40465]
21Feb17_063857| [ 1.39278  0.08069  0.23328]
21Feb17_063857| [ 0.09880  0.57603 -0.96101]
21Feb17_063857| [ 0.01621 -0.13343 -0.27624]
21Feb17_063857| [-1.28286 -2.28909  0.37931]
21Feb17_063857| [-0.28370  0.09336  0.01547]
21Feb17_063857| [-0.51894  1.84280 -0.25906]
21Feb17_063857| [-0.83075 -0.04508  0.12107]
21Feb17_063857| [ 0.37343  1.18436 -0.07358]
21Feb17_063857| [-2.38657 -0.35191  0.01962]
21Feb17_063857| [ 0.95757 -0.91760 -0.08971]
21Feb17_063857| [ 0.38792 -0.01880  0.69717]
21Feb17_063857| [ 1.66877 -0.58078 -1.21129]
21Feb17_063857| [-0.50943  0.59080  0.30856]
21Feb17_063857| [ 0.30163  1.11518  0.98185]
21Feb17_063857| [-0.73226  0.32281 -0.66712]
21Feb17_063857| [-0.62054 -2.21049  1.40981]
21Feb17_063857| [ 1.23185 -0.58090  0.35844]
21Feb17_063857| [-0.05616  0.24219 -0.02853]
21Feb17_063857| [-1.05085 -2.30259 -0.16276]
21Feb17_063857| [ 0.71087  0.14900  1.13430]
21Feb17_063857| [-2.45877 -1.20999 -1.04986]
21Feb17_063857| [-1.00480  1.36344 -0.13998]
21Feb17_063857| [ 1.83140 -0.91532  0.07616]
21Feb17_063857| [-0.60404 -2.05184  0.76948]
21Feb17_063857| [ 0.52617  0.76042 -1.76746]
21Feb17_063857| [-0.22134  0.17324  0.99530]
21Feb17_063857| [-0.36427  1.34655  0.02110]
21Feb17_063857| [-0.93125 -0.33620 -0.25012]
21Feb17_063857| [-2.76428  0.14487  0.48096]
21Feb17_063857| [-0.10518  0.35052  1.71840]
21Feb17_063857| [-1.27998  1.12568  1.26523]
21Feb17_063857| [-0.60698  1.53230 -0.60824]
21Feb17_063857| [ 0.02898  2.98718 -0.59153]
21Feb17_063857| [ 0.17588 -0.00449  0.50797]
21Feb17_063857| [-1.42674 -0.54967 -0.21310]
21Feb17_063857| [ 1.03196  1.18733  0.36755]
21Feb17_063857| [ 1.04748 -1.47444 -0.08469]
21Feb17_063857| [ 0.49410  0.38745  0.68469]
21Feb17_063857| [-0.62880  0.73245  0.19964]]
21Feb17_063857|-- Bias --
21Feb17_063857|[-0.18798  0.64571 -0.23142]
21Feb17_063857|Layer 1:
21Feb17_063857|-- Config --
21Feb17_063857|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063857|-- Weights --
21Feb17_063857|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_063857| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_063857| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_063857|-- Bias --
21Feb17_063857|[0.60477 0.03773 0.26452 0.12222]
21Feb17_063857|Layer 2:
21Feb17_063857|-- Config --
21Feb17_063857|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063857|-- Weights --
21Feb17_063857|[[ 0.67920  0.12119]
21Feb17_063857| [ 0.44836  0.02916]
21Feb17_063857| [ 0.68939  0.31516]
21Feb17_063857| [-0.58995 -0.05861]]
21Feb17_063857|-- Bias --
21Feb17_063857|[ 0.59649 -0.08079]
21Feb17_063857|Layer 3:
21Feb17_063857|-- Config --
21Feb17_063857|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063857|-- Weights --
21Feb17_063857|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_063857| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_063857|-- Bias --
21Feb17_063857|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_063857|Layer 4:
21Feb17_063857|-- Config --
21Feb17_063857|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_063857|-- Weights --
21Feb17_063857|[[-0.03514 -1.04833]
21Feb17_063857| [ 1.25238  0.62094]
21Feb17_063857| [ 0.99203  0.37406]
21Feb17_063857| [ 0.49902  0.67158]
21Feb17_063857| [-1.35709  0.38335]]
21Feb17_063857|-- Bias --
21Feb17_063857|[0.31435 0.36299]
21Feb17_063857|Predicting the validation and test data with the Best final individual.
21Feb17_063905| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_063905|-----------  ------------------  --------------------  ----------
21Feb17_063905|Validation         22.70                  56            0.74363
21Feb17_063905|   Test            19.46                  56            0.73101
Using Theano backend.
WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.
2021-02-17 06:39:08.256716: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-02-17 06:39:08.256773: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
21Feb17_063909|Data summary: Train
21Feb17_063909|data.shape = (2300, 57)
21Feb17_063909|labels.shape = (2300,)
21Feb17_063909|Class distribution:
21Feb17_063909|	0 - 1389 (0.60)
21Feb17_063909|	1 - 911 (0.40)
21Feb17_063909|Data summary: Validation
21Feb17_063909|data.shape = (1150, 57)
21Feb17_063909|labels.shape = (1150,)
21Feb17_063909|Class distribution:
21Feb17_063909|	0 - 667 (0.58)
21Feb17_063909|	1 - 483 (0.42)
21Feb17_063909|Data summary: Test
21Feb17_063909|data.shape = (1151, 57)
21Feb17_063909|labels.shape = (1151,)
21Feb17_063909|Class distribution:
21Feb17_063909|	0 - 732 (0.64)
21Feb17_063909|	1 - 419 (0.36)
21Feb17_063909|Selected configuration values
21Feb17_063909|-- Dataset name: spambase2
21Feb17_063909|-- Initial population size: 64
21Feb17_063909|-- Maximun number of generations: 32
21Feb17_063909|-- Neurons per hidden layer range: (2, 20)
21Feb17_063909|-- Hidden layers number range: (1, 3)
21Feb17_063909|-- Crossover probability: 0.5
21Feb17_063909|-- Bias gene mutation probability: 0.2
21Feb17_063909|-- Weights gene mutation probability: 0.75
21Feb17_063909|-- Neuron mutation probability: 0.3
21Feb17_063909|-- Layer mutation probability: 0.3
21Feb17_063909|-- Constant hidden layers: False
21Feb17_063909|-- Seed: 31415
21Feb17_063909|Entering GA
21Feb17_063909|Start the algorithm
21Feb17_064252|-- Generation 1 --
21Feb17_064252|    -- Crossed 0 individual pairs.
21Feb17_064252|    -- Mutated 32 individuals.
21Feb17_064614|    -- Evaluated 64 individuals.
21Feb17_064614|    Summary of generation 1:
21Feb17_064614| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_064614|-----------  ------------------  --------------------  ----------
21Feb17_064614|    Max            42.70                78.00           0.43478
21Feb17_064614|    Avg            41.90                26.28           0.00941
21Feb17_064614|    Min            35.91                 2.00           0.00000
21Feb17_064614|    Std             0.81                18.75           0.05509
21Feb17_064614|   Best            35.91                18.00           0.43478
21Feb17_064614|-- Generation 2 --
21Feb17_064614|    -- Crossed 1 individual pairs.
21Feb17_064614|    -- Mutated 32 individuals.
21Feb17_064930|    -- Evaluated 64 individuals.
21Feb17_064930|    Summary of generation 2:
21Feb17_064930| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_064930|-----------  ------------------  --------------------  ----------
21Feb17_064930|    Max            58.00                84.00           0.79977
21Feb17_064930|    Avg            41.99                15.92           0.02879
21Feb17_064930|    Min            29.65                 2.00           0.00000
21Feb17_064930|    Std             2.55                13.60           0.13781
21Feb17_064930|   Best            29.65                18.00           0.79977
21Feb17_064930|-- Generation 3 --
21Feb17_064930|    -- Crossed 3 individual pairs.
21Feb17_064930|    -- Mutated 32 individuals.
21Feb17_065244|    -- Evaluated 64 individuals.
21Feb17_065244|    Summary of generation 3:
21Feb17_065244| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_065244|-----------  ------------------  --------------------  ----------
21Feb17_065244|    Max            58.00                50.00           0.78358
21Feb17_065244|    Avg            41.97                13.73           0.02564
21Feb17_065244|    Min            26.09                 2.00           0.00000
21Feb17_065244|    Std             2.83                12.88           0.13211
21Feb17_065244|   Best            26.09                18.00           0.73476
21Feb17_065244|-- Generation 4 --
21Feb17_065244|    -- Crossed 4 individual pairs.
21Feb17_065244|    -- Mutated 32 individuals.
21Feb17_065553|    -- Evaluated 64 individuals.
21Feb17_065553|    Summary of generation 4:
21Feb17_065553| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_065553|-----------  ------------------  --------------------  ----------
21Feb17_065553|    Max            42.17                63.00           0.00517
21Feb17_065553|    Avg            42.01                 8.34           0.00085
21Feb17_065553|    Min            41.91                 2.00           0.00000
21Feb17_065553|    Std             0.06                 9.60           0.00165
21Feb17_065553|   Best            41.91                 4.00           0.00517
21Feb17_065553|-- Generation 5 --
21Feb17_065553|    -- Crossed 6 individual pairs.
21Feb17_065553|    -- Mutated 32 individuals.
21Feb17_065900|    -- Evaluated 64 individuals.
21Feb17_065900|    Summary of generation 5:
21Feb17_065900| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_065900|-----------  ------------------  --------------------  ----------
21Feb17_065900|    Max            42.09                20.00           0.05344
21Feb17_065900|    Avg            41.98                 5.28           0.00172
21Feb17_065900|    Min            41.22                 2.00           0.00000
21Feb17_065900|    Std             0.11                 4.46           0.00681
21Feb17_065900|   Best            41.22                14.00           0.05344
21Feb17_065900|-- Generation 6 --
21Feb17_065900|    -- Crossed 7 individual pairs.
21Feb17_065900|    -- Mutated 32 individuals.
21Feb17_070209|    -- Evaluated 64 individuals.
21Feb17_070209|    Summary of generation 6:
21Feb17_070209| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_070209|-----------  ------------------  --------------------  ----------
21Feb17_070209|    Max            42.26                18.00           0.01548
21Feb17_070209|    Avg            41.99                 6.00           0.00105
21Feb17_070209|    Min            41.48                 2.00           0.00000
21Feb17_070209|    Std             0.09                 4.81           0.00231
21Feb17_070209|   Best            41.48                 3.00           0.01548
21Feb17_070209|-- Generation 7 --
21Feb17_070209|    -- Crossed 9 individual pairs.
21Feb17_070209|    -- Mutated 32 individuals.
21Feb17_070519|    -- Evaluated 64 individuals.
21Feb17_070519|    Summary of generation 7:
21Feb17_070519| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_070519|-----------  ------------------  --------------------  ----------
21Feb17_070519|    Max            42.09                36.00           0.01033
21Feb17_070519|    Avg            41.99                 5.98           0.00089
21Feb17_070519|    Min            41.65                 2.00           0.00000
21Feb17_070519|    Std             0.06                 6.14           0.00184
21Feb17_070519|   Best            41.65                 3.00           0.01033
21Feb17_070519|-- Generation 8 --
21Feb17_070519|    -- Crossed 9 individual pairs.
21Feb17_070519|    -- Mutated 32 individuals.
21Feb17_070828|    -- Evaluated 64 individuals.
21Feb17_070828|    Summary of generation 8:
21Feb17_070828| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_070828|-----------  ------------------  --------------------  ----------
21Feb17_070828|    Max            42.17                18.00           0.04103
21Feb17_070828|    Avg            41.97                 5.09           0.00169
21Feb17_070828|    Min            40.78                 2.00           0.00000
21Feb17_070828|    Std             0.16                 4.37           0.00529
21Feb17_070828|   Best            40.78                12.00           0.04103
21Feb17_070828|-- Generation 9 --
21Feb17_070828|    -- Crossed 8 individual pairs.
21Feb17_070828|    -- Mutated 32 individuals.
21Feb17_071139|    -- Evaluated 64 individuals.
21Feb17_071139|    Summary of generation 9:
21Feb17_071139| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_071139|-----------  ------------------  --------------------  ----------
21Feb17_071139|    Max            48.87                18.00           0.80667
21Feb17_071139|    Avg            41.71                 6.17           0.03823
21Feb17_071139|    Min            30.61                 2.00           0.00000
21Feb17_071139|    Std             2.17                 5.04           0.16210
21Feb17_071139|   Best            30.61                 8.00           0.78607
21Feb17_071139|-- Generation 10 --
21Feb17_071139|    -- Crossed 5 individual pairs.
21Feb17_071139|    -- Mutated 32 individuals.
21Feb17_071449|    -- Evaluated 64 individuals.
21Feb17_071449|    Summary of generation 10:
21Feb17_071449| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_071449|-----------  ------------------  --------------------  ----------
21Feb17_071449|    Max            42.26                18.00           0.58344
21Feb17_071449|    Avg            41.43                 6.23           0.02714
21Feb17_071449|    Min            27.74                 2.00           0.00000
21Feb17_071449|    Std             2.43                 4.89           0.10887
21Feb17_071449|   Best            27.74                18.00           0.51616
21Feb17_071449|-- Generation 11 --
21Feb17_071449|    -- Crossed 8 individual pairs.
21Feb17_071449|    -- Mutated 32 individuals.
21Feb17_071803|    -- Evaluated 64 individuals.
21Feb17_071803|    Summary of generation 11:
21Feb17_071803| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_071803|-----------  ------------------  --------------------  ----------
21Feb17_071803|    Max            58.00                34.00           0.78358
21Feb17_071803|    Avg            41.87                 7.95           0.03476
21Feb17_071803|    Min            28.00                 2.00           0.00000
21Feb17_071803|    Std             2.88                 6.49           0.14854
21Feb17_071803|   Best            28.00                 8.00           0.52079
21Feb17_071803|-- Generation 12 --
21Feb17_071803|    -- Crossed 3 individual pairs.
21Feb17_071803|    -- Mutated 32 individuals.
21Feb17_072113|    -- Evaluated 64 individuals.
21Feb17_072113|    Summary of generation 12:
21Feb17_072113| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_072113|-----------  ------------------  --------------------  ----------
21Feb17_072113|    Max            42.35                36.00           0.67494
21Feb17_072113|    Avg            41.46                 7.03           0.02217
21Feb17_072113|    Min            24.96                 2.00           0.00000
21Feb17_072113|    Std             2.67                 5.88           0.11025
21Feb17_072113|   Best            24.96                18.00           0.67494
21Feb17_072113|-- Generation 13 --
21Feb17_072113|    -- Crossed 5 individual pairs.
21Feb17_072113|    -- Mutated 32 individuals.
21Feb17_072424|    -- Evaluated 64 individuals.
21Feb17_072424|    Summary of generation 13:
21Feb17_072424| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_072424|-----------  ------------------  --------------------  ----------
21Feb17_072424|    Max            42.61                36.00           0.61562
21Feb17_072424|    Avg            41.50                 8.56           0.02210
21Feb17_072424|    Min            26.78                 2.00           0.00000
21Feb17_072424|    Std             2.40                 7.93           0.10577
21Feb17_072424|   Best            26.78                18.00           0.61562
21Feb17_072424|-- Generation 14 --
21Feb17_072424|    -- Crossed 7 individual pairs.
21Feb17_072424|    -- Mutated 32 individuals.
21Feb17_072736|    -- Evaluated 64 individuals.
21Feb17_072736|    Summary of generation 14:
21Feb17_072736| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_072736|-----------  ------------------  --------------------  ----------
21Feb17_072736|    Max            42.09                40.00           0.75188
21Feb17_072736|    Avg            41.48                 8.12           0.02679
21Feb17_072736|    Min            27.65                 2.00           0.00000
21Feb17_072736|    Std             2.42                 6.72           0.13015
21Feb17_072736|   Best            27.65                18.00           0.75188
21Feb17_072736|-- Generation 15 --
21Feb17_072736|    -- Crossed 6 individual pairs.
21Feb17_072736|    -- Mutated 32 individuals.
21Feb17_073048|    -- Evaluated 64 individuals.
21Feb17_073048|    Summary of generation 15:
21Feb17_073048| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_073048|-----------  ------------------  --------------------  ----------
21Feb17_073048|    Max            42.09                40.00           0.73387
21Feb17_073048|    Avg            41.42                 7.69           0.02610
21Feb17_073048|    Min            26.35                 2.00           0.00000
21Feb17_073048|    Std             2.71                 6.44           0.12590
21Feb17_073048|   Best            26.35                18.00           0.71951
21Feb17_073048|-- Generation 16 --
21Feb17_073048|    -- Crossed 5 individual pairs.
21Feb17_073048|    -- Mutated 32 individuals.
21Feb17_073401|    -- Evaluated 64 individuals.
21Feb17_073401|    Summary of generation 16:
21Feb17_073401| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_073401|-----------  ------------------  --------------------  ----------
21Feb17_073401|    Max            42.26                44.00           0.82855
21Feb17_073401|    Avg            41.21                 7.83           0.03973
21Feb17_073401|    Min            24.87                 2.00           0.00000
21Feb17_073401|    Std             3.23                 7.99           0.16234
21Feb17_073401|   Best            24.87                21.00           0.68287
21Feb17_073401|-- Generation 17 --
21Feb17_073401|    -- Crossed 8 individual pairs.
21Feb17_073401|    -- Mutated 32 individuals.
21Feb17_073716|    -- Evaluated 64 individuals.
21Feb17_073716|    Summary of generation 17:
21Feb17_073716| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_073716|-----------  ------------------  --------------------  ----------
21Feb17_073716|    Max            42.26                44.00           0.80877
21Feb17_073716|    Avg            40.86                 8.81           0.06413
21Feb17_073716|    Min            25.04                 2.00           0.00000
21Feb17_073716|    Std             3.59                 8.94           0.19340
21Feb17_073716|   Best            25.04                10.00           0.72247
21Feb17_073716|-- Generation 18 --
21Feb17_073716|    -- Crossed 2 individual pairs.
21Feb17_073716|    -- Mutated 32 individuals.
21Feb17_074034|    -- Evaluated 64 individuals.
21Feb17_074034|    Summary of generation 18:
21Feb17_074034| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_074034|-----------  ------------------  --------------------  ----------
21Feb17_074034|    Max            47.04                44.00           0.81211
21Feb17_074034|    Avg            39.55                10.78           0.12108
21Feb17_074034|    Min            24.35                 3.00           0.00000
21Feb17_074034|    Std             5.74                11.16           0.25939
21Feb17_074034|   Best            24.35                44.00           0.72485
21Feb17_074034|-- Generation 19 --
21Feb17_074034|    -- Crossed 7 individual pairs.
21Feb17_074034|    -- Mutated 32 individuals.
21Feb17_074357|    -- Evaluated 64 individuals.
21Feb17_074357|    Summary of generation 19:
21Feb17_074357| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_074357|-----------  ------------------  --------------------  ----------
21Feb17_074357|    Max            42.87                70.00           0.81774
21Feb17_074357|    Avg            39.09                14.53           0.14606
21Feb17_074357|    Min            24.70                 3.00           0.00000
21Feb17_074357|    Std             5.78                15.60           0.27609
21Feb17_074357|   Best            24.70                44.00           0.69102
21Feb17_074357|-- Generation 20 --
21Feb17_074357|    -- Crossed 3 individual pairs.
21Feb17_074357|    -- Mutated 32 individuals.
21Feb17_074724|    -- Evaluated 64 individuals.
21Feb17_074724|    Summary of generation 20:
21Feb17_074724| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_074724|-----------  ------------------  --------------------  ----------
21Feb17_074724|    Max            42.17                60.00           0.79174
21Feb17_074724|    Avg            39.05                15.47           0.15453
21Feb17_074724|    Min            24.09                 3.00           0.00000
21Feb17_074724|    Std             5.60                16.03           0.28335
21Feb17_074724|   Best            24.09                48.00           0.76568
21Feb17_074724|-- Generation 21 --
21Feb17_074724|    -- Crossed 4 individual pairs.
21Feb17_074724|    -- Mutated 32 individuals.
21Feb17_075055|    -- Evaluated 64 individuals.
21Feb17_075055|    Summary of generation 21:
21Feb17_075055| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_075055|-----------  ------------------  --------------------  ----------
21Feb17_075055|    Max            42.17                90.00           0.80579
21Feb17_075055|    Avg            38.34                18.45           0.19938
21Feb17_075055|    Min            23.91                 2.00           0.00000
21Feb17_075055|    Std             5.87                19.09           0.30554
21Feb17_075055|   Best            23.91                48.00           0.71458
21Feb17_075055|-- Generation 22 --
21Feb17_075055|    -- Crossed 2 individual pairs.
21Feb17_075055|    -- Mutated 32 individuals.
21Feb17_075431|    -- Evaluated 64 individuals.
21Feb17_075431|    Summary of generation 22:
21Feb17_075431| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_075431|-----------  ------------------  --------------------  ----------
21Feb17_075431|    Max            42.09                60.00           0.82362
21Feb17_075431|    Avg            36.71                21.28           0.25981
21Feb17_075431|    Min            24.26                 2.00           0.00000
21Feb17_075431|    Std             6.98                18.25           0.33831
21Feb17_075431|   Best            24.26                52.00           0.76087
21Feb17_075431|-- Generation 23 --
21Feb17_075431|    -- Crossed 2 individual pairs.
21Feb17_075431|    -- Mutated 32 individuals.
21Feb17_075817|    -- Evaluated 64 individuals.
21Feb17_075817|    Summary of generation 23:
21Feb17_075817| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_075817|-----------  ------------------  --------------------  ----------
21Feb17_075817|    Max            42.09                96.00           0.78772
21Feb17_075817|    Avg            35.35                29.28           0.32114
21Feb17_075817|    Min            23.39                 2.00           0.00000
21Feb17_075817|    Std             7.15                21.95           0.34435
21Feb17_075817|   Best            23.39                52.00           0.72814
21Feb17_075817|-- Generation 24 --
21Feb17_075817|    -- Crossed 0 individual pairs.
21Feb17_075817|    -- Mutated 32 individuals.
21Feb17_080215|    -- Evaluated 64 individuals.
21Feb17_080215|    Summary of generation 24:
21Feb17_080215| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_080215|-----------  ------------------  --------------------  ----------
21Feb17_080215|    Max            43.30                80.00           0.82075
21Feb17_080215|    Avg            33.81                36.61           0.38588
21Feb17_080215|    Min            23.22                 2.00           0.00000
21Feb17_080215|    Std             7.30                19.72           0.34184
21Feb17_080215|   Best            23.22                52.00           0.73602
21Feb17_080215|-- Generation 25 --
21Feb17_080215|    -- Crossed 3 individual pairs.
21Feb17_080215|    -- Mutated 32 individuals.
21Feb17_080620|    -- Evaluated 64 individuals.
21Feb17_080620|    Summary of generation 25:
21Feb17_080620| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_080620|-----------  ------------------  --------------------  ----------
21Feb17_080620|    Max            51.74                114.00          0.82799
21Feb17_080620|    Avg            33.58                45.08           0.45457
21Feb17_080620|    Min            23.91                 8.00           0.00000
21Feb17_080620|    Std             7.24                19.61           0.35022
21Feb17_080620|   Best            23.91                48.00           0.72048
21Feb17_080620|-- Generation 26 --
21Feb17_080620|    -- Crossed 1 individual pairs.
21Feb17_080620|    -- Mutated 32 individuals.
21Feb17_081028|    -- Evaluated 64 individuals.
21Feb17_081028|    Summary of generation 26:
21Feb17_081028| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_081028|-----------  ------------------  --------------------  ----------
21Feb17_081028|    Max            42.35                108.00          0.84388
21Feb17_081028|    Avg            32.71                48.80           0.44554
21Feb17_081028|    Min            23.30                 2.00           0.00000
21Feb17_081028|    Std             7.16                22.53           0.33996
21Feb17_081028|   Best            23.30                24.00           0.69415
21Feb17_081028|-- Generation 27 --
21Feb17_081028|    -- Crossed 1 individual pairs.
21Feb17_081028|    -- Mutated 32 individuals.
21Feb17_081436|    -- Evaluated 64 individuals.
21Feb17_081436|    Summary of generation 27:
21Feb17_081436| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_081436|-----------  ------------------  --------------------  ----------
21Feb17_081436|    Max            42.26                132.00          0.82552
21Feb17_081436|    Avg            32.16                51.20           0.45948
21Feb17_081436|    Min            21.74                 8.00           0.00000
21Feb17_081436|    Std             7.19                22.48           0.32234
21Feb17_081436|   Best            21.74                18.00           0.76278
21Feb17_081436|-- Generation 28 --
21Feb17_081436|    -- Crossed 0 individual pairs.
21Feb17_081436|    -- Mutated 32 individuals.
21Feb17_081845|    -- Evaluated 64 individuals.
21Feb17_081845|    Summary of generation 28:
21Feb17_081845| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_081845|-----------  ------------------  --------------------  ----------
21Feb17_081845|    Max            42.00                132.00          0.83850
21Feb17_081845|    Avg            31.52                51.11           0.49187
21Feb17_081845|    Min            23.04                12.00           0.00000
21Feb17_081845|    Std             6.86                24.66           0.32040
21Feb17_081845|   Best            23.04                24.00           0.73226
21Feb17_081845|-- Generation 29 --
21Feb17_081845|    -- Crossed 0 individual pairs.
21Feb17_081845|    -- Mutated 32 individuals.
21Feb17_082252|    -- Evaluated 64 individuals.
21Feb17_082252|    Summary of generation 29:
21Feb17_082252| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_082252|-----------  ------------------  --------------------  ----------
21Feb17_082252|    Max            42.09                132.00          0.82871
21Feb17_082252|    Avg            32.10                49.19           0.44677
21Feb17_082252|    Min            22.26                12.00           0.00000
21Feb17_082252|    Std             7.60                23.20           0.33800
21Feb17_082252|   Best            22.26                56.00           0.74227
21Feb17_082252|-- Generation 30 --
21Feb17_082252|    -- Crossed 0 individual pairs.
21Feb17_082252|    -- Mutated 32 individuals.
21Feb17_082701|    -- Evaluated 64 individuals.
21Feb17_082701|    Summary of generation 30:
21Feb17_082701| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_082701|-----------  ------------------  --------------------  ----------
21Feb17_082701|    Max            42.09                100.00          0.82371
21Feb17_082701|    Avg            31.14                49.09           0.49033
21Feb17_082701|    Min            22.00                14.00           0.00000
21Feb17_082701|    Std             7.06                18.85           0.31415
21Feb17_082701|   Best            22.00                56.00           0.78704
21Feb17_082701|-- Generation 31 --
21Feb17_082701|    -- Crossed 1 individual pairs.
21Feb17_082701|    -- Mutated 32 individuals.
21Feb17_083110|    -- Evaluated 64 individuals.
21Feb17_083110|    Summary of generation 31:
21Feb17_083110| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_083110|-----------  ------------------  --------------------  ----------
21Feb17_083110|    Max            42.52                100.00          0.83333
21Feb17_083110|    Avg            32.54                52.38           0.44410
21Feb17_083110|    Min            22.96                 8.00           0.00000
21Feb17_083110|    Std             7.42                21.79           0.34342
21Feb17_083110|   Best            22.96                44.00           0.72671
21Feb17_083110|-- Generation 32 --
21Feb17_083110|    -- Crossed 1 individual pairs.
21Feb17_083110|    -- Mutated 32 individuals.
21Feb17_083520|    -- Evaluated 64 individuals.
21Feb17_083520|    Summary of generation 32:
21Feb17_083520| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_083520|-----------  ------------------  --------------------  ----------
21Feb17_083520|    Max            42.00                85.00           0.83038
21Feb17_083520|    Avg            32.40                52.83           0.43440
21Feb17_083520|    Min            21.57                 8.00           0.00000
21Feb17_083520|    Std             7.70                18.10           0.34013
21Feb17_083520|   Best            21.57                56.00           0.83038
21Feb17_083520|Best initial individual weights
21Feb17_083520|Individual:
21Feb17_083520|-- Constant hidden layers --
21Feb17_083520|False
21Feb17_083520|Layer 0:
21Feb17_083520|-- Config --
21Feb17_083520|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 12, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083520|-- Weights --
21Feb17_083520|[[-3.50529e-01 -6.53069e-03 -7.03730e-01 -6.33906e-01  6.10835e-02
21Feb17_083520|   4.57449e-01 -3.77835e-01  6.38481e-01  4.24141e-01  6.68786e-01
21Feb17_083520|  -4.86511e-01 -9.28542e-01]
21Feb17_083520| [-8.31270e-01 -3.94586e-01  5.51697e-02 -8.86387e-01 -6.99786e-01
21Feb17_083520|   6.44047e-01 -5.40571e-01  3.77503e-01  1.70193e-01  5.92883e-01
21Feb17_083520|   2.06540e-01  2.18639e-01]
21Feb17_083520| [-8.13637e-01  7.25044e-01  6.66092e-01  5.31057e-01 -4.48634e-01
21Feb17_083520|  -1.62601e-01 -1.57458e-02  7.74238e-02 -4.81841e-01  3.55485e-02
21Feb17_083520|  -7.21169e-01  1.05129e-01]
21Feb17_083520| [ 6.07201e-01  6.23643e-01  8.87343e-01  6.04285e-01  5.70453e-02
21Feb17_083520|   5.99381e-01 -3.21663e-03  6.64196e-01 -5.25584e-01 -1.74507e-02
21Feb17_083520|   3.80029e-01 -4.59585e-01]
21Feb17_083520| [-9.00078e-01  8.63133e-01  8.49324e-01  4.34648e-01 -5.67121e-01
21Feb17_083520|   6.24299e-01 -6.46637e-01  9.34620e-01 -5.42838e-01 -4.04257e-01
21Feb17_083520|  -4.70046e-01  4.29712e-01]
21Feb17_083520| [ 9.51731e-02  8.42954e-01 -7.44806e-01 -5.56045e-02 -4.89209e-01
21Feb17_083520|   8.07612e-01  2.77691e-01 -5.77946e-02  4.30356e-01 -9.05718e-01
21Feb17_083520|  -7.61358e-01 -4.56367e-01]
21Feb17_083520| [-9.06447e-01 -4.46566e-01 -4.40669e-01  6.09161e-01 -3.32587e-01
21Feb17_083520|  -9.31356e-01  9.62597e-02 -1.83060e-01  5.91585e-01 -2.78230e-01
21Feb17_083520|  -3.70976e-01 -3.38510e-01]
21Feb17_083520| [ 5.92999e-02 -5.35945e-01 -8.52259e-01  1.62766e-01 -2.64657e-01
21Feb17_083520|   6.65182e-01  2.45597e-01  2.99711e-01  7.14862e-01 -4.00362e-01
21Feb17_083520|   3.40170e-01 -1.14174e-01]
21Feb17_083520| [-4.26995e-01  8.46146e-01  9.81523e-01 -2.62996e-01  8.65377e-01
21Feb17_083520|  -6.86144e-01 -3.53983e-01 -2.18499e-01  3.29010e-01 -8.26088e-01
21Feb17_083520|   1.48202e-01  5.27152e-01]
21Feb17_083520| [-1.97937e-01  5.44304e-02  9.68680e-01  1.96012e-01  6.66432e-01
21Feb17_083520|  -1.15663e-01  1.01696e-01 -9.91833e-01  5.54656e-02  5.06069e-01
21Feb17_083520|  -8.39702e-01  6.07914e-02]
21Feb17_083520| [ 8.22409e-01 -3.07988e-01 -4.87097e-01 -2.67403e-01 -3.17115e-01
21Feb17_083520|   6.20877e-01  2.45721e-01  1.47039e-01  8.22748e-02 -4.61491e-01
21Feb17_083520|   5.08690e-01 -8.10093e-01]
21Feb17_083520| [-1.03463e-01 -7.13247e-01 -5.27190e-01 -8.14055e-01 -2.20069e-01
21Feb17_083520|   7.58689e-01  7.72478e-01 -3.75243e-01 -1.74773e-01  4.33018e-02
21Feb17_083520|   5.76591e-01 -9.04182e-01]
21Feb17_083520| [ 6.39880e-01 -2.76473e-01  4.48413e-01  7.92996e-01  6.12921e-01
21Feb17_083520|   8.45232e-01 -3.59434e-01 -1.65084e-01  6.00279e-01 -9.07135e-01
21Feb17_083520|  -9.18766e-01 -3.84510e-02]
21Feb17_083520| [-4.35982e-01  3.53117e-01 -4.33635e-01  4.41189e-01  2.02385e-01
21Feb17_083520|  -2.15156e-01 -3.32093e-01 -9.46393e-01  7.49818e-01  7.56840e-01
21Feb17_083520|  -2.97280e-01  3.76513e-01]
21Feb17_083520| [ 2.00098e-01 -3.94368e-01  4.74964e-01 -5.14077e-01 -5.02985e-01
21Feb17_083520|   6.57337e-01  4.54284e-01  7.99434e-01  1.18259e-01  7.90625e-01
21Feb17_083520|  -8.45168e-01 -7.22624e-01]
21Feb17_083520| [ 5.21361e-01 -9.37087e-01  6.98489e-01  7.45747e-01  9.84330e-01
21Feb17_083520|  -1.70463e-01 -4.14211e-01  4.94059e-01 -4.89685e-03 -7.22161e-02
21Feb17_083520|   3.28119e-01 -2.96382e-01]
21Feb17_083520| [ 9.97912e-02 -3.45331e-01 -3.32041e-01 -8.83410e-01  4.64194e-01
21Feb17_083520|  -2.94905e-01 -7.11116e-01 -2.12420e-01  8.93334e-01  5.60374e-01
21Feb17_083520|  -8.11522e-01  3.94537e-01]
21Feb17_083520| [ 2.39284e-01 -9.68110e-02 -3.48403e-01  6.68017e-01  1.07039e-01
21Feb17_083520|  -1.80014e-01 -1.28612e-01 -3.28318e-01  7.99371e-01  7.45882e-01
21Feb17_083520|   4.50426e-01 -9.94601e-02]
21Feb17_083520| [-9.32040e-02 -4.99896e-01 -3.18835e-01 -3.21963e-01  8.88030e-02
21Feb17_083520|   8.24115e-01  3.93190e-01  2.14054e-01 -4.70631e-02  5.36199e-01
21Feb17_083520|   7.72001e-01 -1.38053e-01]
21Feb17_083520| [ 8.31611e-01  7.46409e-01  2.18558e-01  7.47226e-01 -4.35942e-01
21Feb17_083520|  -6.59230e-01  3.39715e-02  8.14827e-01 -7.32488e-02 -1.12845e-01
21Feb17_083520|  -5.06295e-01  2.18074e-01]
21Feb17_083520| [-3.26563e-01  6.22846e-01  3.85669e-01 -9.86028e-01 -7.51629e-02
21Feb17_083520|  -1.88021e-01  7.27322e-01  5.61207e-04  1.34321e-01  7.19415e-01
21Feb17_083520|  -5.83277e-01 -4.45815e-01]
21Feb17_083520| [ 7.83756e-01  9.31803e-02  4.99853e-01 -9.31861e-01  7.91593e-01
21Feb17_083520|   1.96250e-01 -8.00498e-02  7.34271e-01 -2.68771e-01  7.49220e-01
21Feb17_083520|   1.24815e-01  6.17245e-01]
21Feb17_083520| [ 2.20500e-01 -9.26851e-01 -5.03545e-02  9.91366e-01  9.07862e-01
21Feb17_083520|   6.95839e-01  2.07702e-01  1.55262e-01  7.17753e-01 -6.02225e-01
21Feb17_083520|  -2.43972e-02  7.83904e-01]
21Feb17_083520| [-7.35179e-01 -4.04922e-01 -7.64988e-01  6.94764e-03 -5.74469e-01
21Feb17_083520|  -8.82582e-01 -4.25720e-01  4.48261e-01  9.38039e-01 -6.02162e-01
21Feb17_083520|   1.85138e-01  8.19467e-01]
21Feb17_083520| [-2.42564e-01  5.05630e-02 -6.53631e-01  8.89456e-01  3.73267e-02
21Feb17_083520|  -4.57479e-01  5.78190e-01 -8.65769e-01  4.43846e-01  9.21993e-01
21Feb17_083520|  -4.59642e-01  4.55887e-01]
21Feb17_083520| [ 1.79502e-01  5.97755e-01 -5.91581e-01  6.50878e-01 -3.20822e-02
21Feb17_083520|   7.98103e-01  9.23662e-01 -3.15762e-01  3.95919e-01 -9.74799e-01
21Feb17_083520|  -9.18783e-01  9.04381e-01]
21Feb17_083520| [-9.77544e-01 -9.84191e-01 -3.78989e-01  1.57093e-01 -1.19240e-01
21Feb17_083520|   7.04336e-01  9.20317e-01 -9.23300e-02  7.24512e-01 -4.73620e-01
21Feb17_083520|   4.32204e-01  1.96422e-01]
21Feb17_083520| [-9.94008e-01  1.23345e-01 -2.91311e-01  3.86181e-01  3.50519e-01
21Feb17_083520|   8.97293e-02  1.28693e-01  7.64175e-01  9.70172e-01 -9.36008e-01
21Feb17_083520|   2.31190e-01 -3.81352e-01]
21Feb17_083520| [-8.68842e-01 -3.08689e-01 -7.85613e-02 -7.75421e-01 -2.62711e-01
21Feb17_083520|  -9.13854e-01  5.58996e-01  8.97445e-01 -4.78631e-01 -4.79708e-02
21Feb17_083520|  -2.09270e-01  1.03320e-01]
21Feb17_083520| [ 2.47190e-01  8.94828e-01 -8.83655e-01  1.67368e-01 -1.09226e-01
21Feb17_083520|   5.39374e-01  3.22158e-01  7.22802e-01 -4.76431e-01 -3.98606e-01
21Feb17_083520|   3.91466e-01 -5.89172e-01]
21Feb17_083520| [ 2.03966e-01 -8.11217e-01  8.56319e-01 -5.26108e-01 -9.29896e-01
21Feb17_083520|   5.92077e-01  8.52854e-01  6.15086e-01  5.45676e-01 -8.13950e-01
21Feb17_083520|   6.24771e-01 -9.57171e-01]
21Feb17_083520| [-7.59457e-01  2.18652e-01 -9.40198e-01 -1.94388e-03 -3.63300e-01
21Feb17_083520|   2.19527e-01 -3.86609e-01  6.57866e-02  8.04643e-01  4.37489e-01
21Feb17_083520|   6.39988e-01 -8.42788e-01]
21Feb17_083520| [-2.79911e-01  8.89651e-01  5.38994e-02  7.45843e-01 -9.32154e-01
21Feb17_083520|   5.56522e-01  5.04658e-01  3.56409e-01 -5.15289e-01  6.99550e-01
21Feb17_083520|  -7.31032e-01  1.61260e-01]
21Feb17_083520| [ 8.41582e-01 -5.25391e-01  4.65437e-01  4.40808e-01 -6.03761e-01
21Feb17_083520|   6.23036e-01  9.46114e-01  5.92328e-01  2.08190e-01 -6.69715e-01
21Feb17_083520|  -7.35264e-02  5.96491e-01]
21Feb17_083520| [ 3.20347e-01  1.37290e-01  1.72843e-02 -4.70187e-01  5.92987e-01
21Feb17_083520|   3.57672e-01  2.73873e-01 -8.65750e-02 -3.09144e-01 -9.20603e-01
21Feb17_083520|   2.82912e-01  6.38325e-01]
21Feb17_083520| [-8.91399e-01 -1.24857e-01 -4.86431e-01 -9.05166e-01  8.47373e-01
21Feb17_083520|   3.18146e-01  2.73494e-02 -5.33112e-01  5.63862e-01 -5.12821e-01
21Feb17_083520|  -9.38474e-01 -9.90043e-01]
21Feb17_083520| [-8.25448e-01 -1.90141e-02 -5.51276e-01 -8.23215e-01  7.26222e-02
21Feb17_083520|   3.49894e-01  5.17693e-01 -5.57217e-01 -3.26301e-01  7.78564e-01
21Feb17_083520|   6.58213e-01 -2.83929e-01]
21Feb17_083520| [ 6.18012e-02 -4.92329e-01  5.41071e-01  2.13013e-01  6.35700e-01
21Feb17_083520|  -1.65529e-01  5.77357e-01  2.45531e-01  2.54855e-01 -8.48854e-01
21Feb17_083520|   6.46386e-01 -4.13404e-01]
21Feb17_083520| [-3.41116e-01 -4.75918e-01  3.59165e-01  6.02895e-01 -4.31688e-01
21Feb17_083520|  -8.51757e-01  2.31464e-01 -9.57407e-01  2.83436e-01 -4.51744e-01
21Feb17_083520|   4.80022e-02 -8.35007e-01]
21Feb17_083520| [ 9.67499e-01  5.85047e-02  7.21540e-01  3.12459e-01  3.50272e-01
21Feb17_083520|   2.14450e-01 -3.30294e-01 -7.99000e-01  1.11959e-01  2.74091e-01
21Feb17_083520|  -1.78234e-01  9.40235e-01]
21Feb17_083520| [-1.14387e-01  4.31319e-01  3.73789e-01 -4.62497e-01  4.50407e-01
21Feb17_083520|  -4.00668e-01 -8.26575e-01  2.39589e-01 -5.24611e-01  3.30691e-01
21Feb17_083520|  -3.99504e-01  1.44547e-01]
21Feb17_083520| [ 7.34826e-01 -5.37352e-01 -6.62895e-01  1.04258e-01  2.15046e-03
21Feb17_083520|   2.71790e-01  8.51151e-01 -6.31948e-01  1.94011e-01 -6.41830e-01
21Feb17_083520|   1.67802e-01 -4.29449e-01]
21Feb17_083520| [-6.18752e-01  1.18069e-01 -7.98263e-01  4.75266e-01 -9.95474e-01
21Feb17_083520|  -1.79698e-01  6.90455e-01  3.44607e-01 -5.80013e-01 -6.16218e-02
21Feb17_083520|   7.01329e-01  8.33298e-02]
21Feb17_083520| [-2.69227e-01 -1.43165e-02 -3.33533e-01 -1.69954e-01 -1.26476e-02
21Feb17_083520|   7.69653e-01 -6.99893e-01  5.22539e-01 -1.67862e-01  4.44416e-01
21Feb17_083520|   6.72372e-01  5.52923e-01]
21Feb17_083520| [-7.10479e-01  1.61800e-01  2.53825e-01 -3.00634e-01 -5.06805e-01
21Feb17_083520|   2.02091e-01 -4.94980e-02 -1.44363e-01 -6.18371e-01  5.74350e-01
21Feb17_083520|  -1.85073e-01 -8.11049e-01]
21Feb17_083520| [-6.60846e-01 -1.69003e-01  6.00733e-01 -8.28618e-01 -3.99034e-01
21Feb17_083520|  -5.82553e-01  7.34428e-02  5.57096e-01 -1.50695e-01  1.26307e-01
21Feb17_083520|   8.92712e-01 -8.75142e-01]
21Feb17_083520| [ 7.58158e-01  5.89907e-01 -1.92304e-01 -3.86200e-01 -2.63049e-01
21Feb17_083520|  -3.41209e-03  4.05030e-01 -8.95945e-02  9.79113e-01  6.78942e-02
21Feb17_083520|  -9.53580e-01  7.06162e-01]
21Feb17_083520| [-1.23045e-01  9.25694e-01  5.20030e-01  4.57808e-01 -9.99639e-01
21Feb17_083520|  -9.80069e-02  3.03598e-01  4.26167e-02 -3.64595e-01 -7.17635e-01
21Feb17_083520|   1.61128e-01  6.30329e-01]
21Feb17_083520| [ 2.02232e-02 -3.24113e-01  7.43999e-01 -3.75983e-01  4.63558e-01
21Feb17_083520|  -2.04941e-01 -5.28404e-02  4.26576e-01 -2.53802e-01  1.74976e-01
21Feb17_083520|  -8.35763e-01  8.54548e-01]
21Feb17_083520| [-5.76875e-01  5.40954e-01 -4.91777e-01  4.40209e-01 -9.16379e-01
21Feb17_083520|   6.01728e-01  1.25226e-02  2.05876e-01  8.45524e-01 -8.34178e-01
21Feb17_083520|  -7.87379e-01  8.63352e-01]
21Feb17_083520| [-3.15102e-01  7.00213e-01  6.69503e-01  7.15510e-01 -9.53550e-01
21Feb17_083520|   4.07885e-02  4.25336e-01  6.24629e-01  9.90858e-01  6.36989e-01
21Feb17_083520|  -6.44355e-01 -5.47589e-01]
21Feb17_083520| [-8.25051e-01 -4.37574e-01  4.76334e-01 -7.71092e-01  7.98467e-01
21Feb17_083520|  -1.52347e-01  3.34469e-01  1.51889e-01 -9.60611e-01  4.62484e-01
21Feb17_083520|   4.10115e-01 -1.60555e-01]
21Feb17_083520| [ 1.77712e-01  6.55776e-01  8.97735e-01 -9.20852e-01 -9.69032e-01
21Feb17_083520|  -4.79756e-02 -3.24015e-01 -1.57490e-01 -6.25919e-01  9.94240e-01
21Feb17_083520|  -4.74141e-01 -1.00993e-01]
21Feb17_083520| [ 3.66246e-01  8.06205e-01  3.37216e-01 -3.17040e-01  9.19693e-01
21Feb17_083520|   8.28581e-01  2.22724e-01 -5.57410e-01 -8.17434e-01 -8.65693e-01
21Feb17_083520|  -4.72960e-01  7.15176e-01]
21Feb17_083520| [-8.25000e-01 -4.67253e-01 -1.84646e-02  3.88053e-01 -8.75853e-01
21Feb17_083520|  -2.34509e-01  9.53471e-01  8.05489e-02  2.71744e-01 -7.15129e-01
21Feb17_083520|   9.24875e-01 -6.07435e-01]
21Feb17_083520| [-2.79447e-01  2.39105e-01  1.32962e-01 -7.68103e-01  7.58443e-01
21Feb17_083520|  -1.69646e-01 -7.52460e-01 -7.30195e-01 -4.68985e-01 -2.88784e-01
21Feb17_083520|   3.77655e-02 -5.72024e-01]
21Feb17_083520| [-8.37481e-01 -8.22188e-02  8.45547e-01 -5.53876e-01  5.72703e-01
21Feb17_083520|   3.09970e-01  8.96552e-01  3.97690e-01 -7.19080e-01  2.37714e-01
21Feb17_083520|   6.60752e-01  1.69435e-01]]
21Feb17_083520|-- Bias --
21Feb17_083520|[-0.28065  0.08142 -0.20194  0.96969  0.45180  0.54884  0.16606 -0.15804
21Feb17_083520|  0.47362  0.17133  0.43345 -0.35803]
21Feb17_083520|Layer 1:
21Feb17_083520|-- Config --
21Feb17_083520|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 12], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083520|-- Weights --
21Feb17_083520|[[-0.88546  0.72941]
21Feb17_083520| [ 0.79196 -0.05477]
21Feb17_083520| [-0.89752 -0.49343]
21Feb17_083520| [ 0.78974 -0.41510]
21Feb17_083520| [ 0.29561 -0.94575]
21Feb17_083520| [-0.14754  0.69148]
21Feb17_083520| [-0.33558  0.37910]
21Feb17_083520| [-0.82387  0.15998]
21Feb17_083520| [-0.77760  0.88462]
21Feb17_083520| [ 0.98329 -0.68363]
21Feb17_083520| [ 0.88895  0.40387]
21Feb17_083520| [ 0.39015 -0.38652]]
21Feb17_083520|-- Bias --
21Feb17_083520|[ 0.28702 -0.70976]
21Feb17_083520|Predicting the validation and test data with the Best initial individual.
21Feb17_083526| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_083526|-----------  ------------------  --------------------  ----------
21Feb17_083526|Validation         42.00                  12            0.00000
21Feb17_083526|   Test            36.32                  12            0.00298
21Feb17_083526|-------------------- Test #0 --------------------
21Feb17_083526|Best final individual weights
21Feb17_083526|Individual:
21Feb17_083526|-- Constant hidden layers --
21Feb17_083526|False
21Feb17_083526|Layer 0:
21Feb17_083526|-- Config --
21Feb17_083526|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083526|-- Weights --
21Feb17_083526|[[-0.73212  1.32861  0.10200]
21Feb17_083526| [ 1.48746 -2.97273 -0.42944]
21Feb17_083526| [ 0.53095 -1.50623  0.79224]
21Feb17_083526| [-1.07292 -0.83175 -0.90105]
21Feb17_083526| [-0.48696 -0.89325  0.27226]
21Feb17_083526| [-3.02511  0.34155 -0.03837]
21Feb17_083526| [-0.76747  0.57140 -0.46892]
21Feb17_083526| [-0.07581  0.14713  0.85910]
21Feb17_083526| [-1.37488  0.52170 -0.36205]
21Feb17_083526| [ 1.60981 -0.08727 -0.11267]
21Feb17_083526| [ 0.50986  1.58916 -0.35287]
21Feb17_083526| [-0.34599  1.27113 -0.16393]
21Feb17_083526| [ 1.29203  1.19467  0.37695]
21Feb17_083526| [ 0.58704  0.06328 -0.24240]
21Feb17_083526| [-0.93888 -0.89760  0.57087]
21Feb17_083526| [ 0.99159 -0.66387  0.35177]
21Feb17_083526| [-0.67119  1.06910 -0.12512]
21Feb17_083526| [-0.91534  1.23744 -0.40465]
21Feb17_083526| [ 1.39278  0.08069  0.23328]
21Feb17_083526| [ 0.09880  0.57603 -0.96101]
21Feb17_083526| [ 0.01621 -0.13343 -0.27624]
21Feb17_083526| [-1.28286 -2.28909  0.37931]
21Feb17_083526| [-0.28370  0.09336  0.01547]
21Feb17_083526| [-0.51894  1.84280 -0.25906]
21Feb17_083526| [-0.83075 -0.04508  0.12107]
21Feb17_083526| [ 0.37343  1.18436 -0.07358]
21Feb17_083526| [-2.38657 -0.35191  0.01962]
21Feb17_083526| [ 0.95757 -0.91760 -0.08971]
21Feb17_083526| [ 0.38792 -0.01880  0.69717]
21Feb17_083526| [ 1.66877 -0.58078 -1.21129]
21Feb17_083526| [-0.50943  0.59080  0.30856]
21Feb17_083526| [ 0.30163  1.11518  0.98185]
21Feb17_083526| [-0.73226  0.32281 -0.66712]
21Feb17_083526| [-0.62054 -2.21049  1.40981]
21Feb17_083526| [ 1.23185 -0.58090  0.35844]
21Feb17_083526| [-0.05616  0.24219 -0.02853]
21Feb17_083526| [-1.05085 -2.30259 -0.16276]
21Feb17_083526| [ 0.71087  0.14900  1.13430]
21Feb17_083526| [-2.45877 -1.20999 -1.04986]
21Feb17_083526| [-1.00480  1.36344 -0.13998]
21Feb17_083526| [ 1.83140 -0.91532  0.07616]
21Feb17_083526| [-0.60404 -2.05184  0.76948]
21Feb17_083526| [ 0.52617  0.76042 -1.76746]
21Feb17_083526| [-0.22134  0.17324  0.99530]
21Feb17_083526| [-0.36427  1.34655  0.02110]
21Feb17_083526| [-0.93125 -0.33620 -0.25012]
21Feb17_083526| [-2.76428  0.14487  0.48096]
21Feb17_083526| [-0.10518  0.35052  1.71840]
21Feb17_083526| [-1.27998  1.12568  1.26523]
21Feb17_083526| [-0.60698  1.53230 -0.60824]
21Feb17_083526| [ 0.02898  2.98718 -0.59153]
21Feb17_083526| [ 0.17588 -0.00449  0.50797]
21Feb17_083526| [-1.42674 -0.54967 -0.21310]
21Feb17_083526| [ 1.03196  1.18733  0.36755]
21Feb17_083526| [ 1.04748 -1.47444 -0.08469]
21Feb17_083526| [ 0.49410  0.38745  0.68469]
21Feb17_083526| [-0.62880  0.73245  0.19964]]
21Feb17_083526|-- Bias --
21Feb17_083526|[-0.18798  0.64571 -0.23142]
21Feb17_083526|Layer 1:
21Feb17_083526|-- Config --
21Feb17_083526|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083526|-- Weights --
21Feb17_083526|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_083526| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_083526| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_083526|-- Bias --
21Feb17_083526|[0.60477 0.03773 0.26452 0.12222]
21Feb17_083526|Layer 2:
21Feb17_083526|-- Config --
21Feb17_083526|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083526|-- Weights --
21Feb17_083526|[[ 0.67920  0.12119]
21Feb17_083526| [ 0.44836  0.02916]
21Feb17_083526| [ 0.68939  0.31516]
21Feb17_083526| [-0.58995 -0.05861]]
21Feb17_083526|-- Bias --
21Feb17_083526|[ 0.59649 -0.08079]
21Feb17_083526|Layer 3:
21Feb17_083526|-- Config --
21Feb17_083526|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083526|-- Weights --
21Feb17_083526|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_083526| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_083526|-- Bias --
21Feb17_083526|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_083526|Layer 4:
21Feb17_083526|-- Config --
21Feb17_083526|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083526|-- Weights --
21Feb17_083526|[[-0.03514 -1.04833]
21Feb17_083526| [ 1.25238  0.62094]
21Feb17_083526| [ 0.99203  0.37406]
21Feb17_083526| [ 0.49902  0.67158]
21Feb17_083526| [-1.35709  0.38335]]
21Feb17_083526|-- Bias --
21Feb17_083526|[0.31435 0.36299]
21Feb17_083526|Predicting the validation and test data with the Best final individual.
21Feb17_083534| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_083534|-----------  ------------------  --------------------  ----------
21Feb17_083534|Validation         40.17                  56            0.05627
21Feb17_083534|   Test            21.37                  56            0.70301
21Feb17_083534|-------------------- Test #1 --------------------
21Feb17_083534|Best final individual weights
21Feb17_083534|Individual:
21Feb17_083534|-- Constant hidden layers --
21Feb17_083534|False
21Feb17_083534|Layer 0:
21Feb17_083534|-- Config --
21Feb17_083534|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083534|-- Weights --
21Feb17_083534|[[-0.73212  1.32861  0.10200]
21Feb17_083534| [ 1.48746 -2.97273 -0.42944]
21Feb17_083534| [ 0.53095 -1.50623  0.79224]
21Feb17_083534| [-1.07292 -0.83175 -0.90105]
21Feb17_083534| [-0.48696 -0.89325  0.27226]
21Feb17_083534| [-3.02511  0.34155 -0.03837]
21Feb17_083534| [-0.76747  0.57140 -0.46892]
21Feb17_083534| [-0.07581  0.14713  0.85910]
21Feb17_083534| [-1.37488  0.52170 -0.36205]
21Feb17_083534| [ 1.60981 -0.08727 -0.11267]
21Feb17_083534| [ 0.50986  1.58916 -0.35287]
21Feb17_083534| [-0.34599  1.27113 -0.16393]
21Feb17_083534| [ 1.29203  1.19467  0.37695]
21Feb17_083534| [ 0.58704  0.06328 -0.24240]
21Feb17_083534| [-0.93888 -0.89760  0.57087]
21Feb17_083534| [ 0.99159 -0.66387  0.35177]
21Feb17_083534| [-0.67119  1.06910 -0.12512]
21Feb17_083534| [-0.91534  1.23744 -0.40465]
21Feb17_083534| [ 1.39278  0.08069  0.23328]
21Feb17_083534| [ 0.09880  0.57603 -0.96101]
21Feb17_083534| [ 0.01621 -0.13343 -0.27624]
21Feb17_083534| [-1.28286 -2.28909  0.37931]
21Feb17_083534| [-0.28370  0.09336  0.01547]
21Feb17_083534| [-0.51894  1.84280 -0.25906]
21Feb17_083534| [-0.83075 -0.04508  0.12107]
21Feb17_083534| [ 0.37343  1.18436 -0.07358]
21Feb17_083534| [-2.38657 -0.35191  0.01962]
21Feb17_083534| [ 0.95757 -0.91760 -0.08971]
21Feb17_083534| [ 0.38792 -0.01880  0.69717]
21Feb17_083534| [ 1.66877 -0.58078 -1.21129]
21Feb17_083534| [-0.50943  0.59080  0.30856]
21Feb17_083534| [ 0.30163  1.11518  0.98185]
21Feb17_083534| [-0.73226  0.32281 -0.66712]
21Feb17_083534| [-0.62054 -2.21049  1.40981]
21Feb17_083534| [ 1.23185 -0.58090  0.35844]
21Feb17_083534| [-0.05616  0.24219 -0.02853]
21Feb17_083534| [-1.05085 -2.30259 -0.16276]
21Feb17_083534| [ 0.71087  0.14900  1.13430]
21Feb17_083534| [-2.45877 -1.20999 -1.04986]
21Feb17_083534| [-1.00480  1.36344 -0.13998]
21Feb17_083534| [ 1.83140 -0.91532  0.07616]
21Feb17_083534| [-0.60404 -2.05184  0.76948]
21Feb17_083534| [ 0.52617  0.76042 -1.76746]
21Feb17_083534| [-0.22134  0.17324  0.99530]
21Feb17_083534| [-0.36427  1.34655  0.02110]
21Feb17_083534| [-0.93125 -0.33620 -0.25012]
21Feb17_083534| [-2.76428  0.14487  0.48096]
21Feb17_083534| [-0.10518  0.35052  1.71840]
21Feb17_083534| [-1.27998  1.12568  1.26523]
21Feb17_083534| [-0.60698  1.53230 -0.60824]
21Feb17_083534| [ 0.02898  2.98718 -0.59153]
21Feb17_083534| [ 0.17588 -0.00449  0.50797]
21Feb17_083534| [-1.42674 -0.54967 -0.21310]
21Feb17_083534| [ 1.03196  1.18733  0.36755]
21Feb17_083534| [ 1.04748 -1.47444 -0.08469]
21Feb17_083534| [ 0.49410  0.38745  0.68469]
21Feb17_083534| [-0.62880  0.73245  0.19964]]
21Feb17_083534|-- Bias --
21Feb17_083534|[-0.18798  0.64571 -0.23142]
21Feb17_083534|Layer 1:
21Feb17_083534|-- Config --
21Feb17_083534|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083534|-- Weights --
21Feb17_083534|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_083534| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_083534| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_083534|-- Bias --
21Feb17_083534|[0.60477 0.03773 0.26452 0.12222]
21Feb17_083534|Layer 2:
21Feb17_083534|-- Config --
21Feb17_083534|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083534|-- Weights --
21Feb17_083534|[[ 0.67920  0.12119]
21Feb17_083534| [ 0.44836  0.02916]
21Feb17_083534| [ 0.68939  0.31516]
21Feb17_083534| [-0.58995 -0.05861]]
21Feb17_083534|-- Bias --
21Feb17_083534|[ 0.59649 -0.08079]
21Feb17_083534|Layer 3:
21Feb17_083534|-- Config --
21Feb17_083534|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083534|-- Weights --
21Feb17_083534|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_083534| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_083534|-- Bias --
21Feb17_083534|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_083534|Layer 4:
21Feb17_083534|-- Config --
21Feb17_083534|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083534|-- Weights --
21Feb17_083534|[[-0.03514 -1.04833]
21Feb17_083534| [ 1.25238  0.62094]
21Feb17_083534| [ 0.99203  0.37406]
21Feb17_083534| [ 0.49902  0.67158]
21Feb17_083534| [-1.35709  0.38335]]
21Feb17_083534|-- Bias --
21Feb17_083534|[0.31435 0.36299]
21Feb17_083534|Predicting the validation and test data with the Best final individual.
21Feb17_083541| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_083541|-----------  ------------------  --------------------  ----------
21Feb17_083541|Validation         23.83                  56            0.86651
21Feb17_083541|   Test            22.68                  56            0.77969
21Feb17_083541|-------------------- Test #2 --------------------
21Feb17_083541|Best final individual weights
21Feb17_083541|Individual:
21Feb17_083541|-- Constant hidden layers --
21Feb17_083541|False
21Feb17_083541|Layer 0:
21Feb17_083541|-- Config --
21Feb17_083541|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083541|-- Weights --
21Feb17_083541|[[-0.73212  1.32861  0.10200]
21Feb17_083541| [ 1.48746 -2.97273 -0.42944]
21Feb17_083541| [ 0.53095 -1.50623  0.79224]
21Feb17_083541| [-1.07292 -0.83175 -0.90105]
21Feb17_083541| [-0.48696 -0.89325  0.27226]
21Feb17_083541| [-3.02511  0.34155 -0.03837]
21Feb17_083541| [-0.76747  0.57140 -0.46892]
21Feb17_083541| [-0.07581  0.14713  0.85910]
21Feb17_083541| [-1.37488  0.52170 -0.36205]
21Feb17_083541| [ 1.60981 -0.08727 -0.11267]
21Feb17_083541| [ 0.50986  1.58916 -0.35287]
21Feb17_083541| [-0.34599  1.27113 -0.16393]
21Feb17_083541| [ 1.29203  1.19467  0.37695]
21Feb17_083541| [ 0.58704  0.06328 -0.24240]
21Feb17_083541| [-0.93888 -0.89760  0.57087]
21Feb17_083541| [ 0.99159 -0.66387  0.35177]
21Feb17_083541| [-0.67119  1.06910 -0.12512]
21Feb17_083541| [-0.91534  1.23744 -0.40465]
21Feb17_083541| [ 1.39278  0.08069  0.23328]
21Feb17_083541| [ 0.09880  0.57603 -0.96101]
21Feb17_083541| [ 0.01621 -0.13343 -0.27624]
21Feb17_083541| [-1.28286 -2.28909  0.37931]
21Feb17_083541| [-0.28370  0.09336  0.01547]
21Feb17_083541| [-0.51894  1.84280 -0.25906]
21Feb17_083541| [-0.83075 -0.04508  0.12107]
21Feb17_083541| [ 0.37343  1.18436 -0.07358]
21Feb17_083541| [-2.38657 -0.35191  0.01962]
21Feb17_083541| [ 0.95757 -0.91760 -0.08971]
21Feb17_083541| [ 0.38792 -0.01880  0.69717]
21Feb17_083541| [ 1.66877 -0.58078 -1.21129]
21Feb17_083541| [-0.50943  0.59080  0.30856]
21Feb17_083541| [ 0.30163  1.11518  0.98185]
21Feb17_083541| [-0.73226  0.32281 -0.66712]
21Feb17_083541| [-0.62054 -2.21049  1.40981]
21Feb17_083541| [ 1.23185 -0.58090  0.35844]
21Feb17_083541| [-0.05616  0.24219 -0.02853]
21Feb17_083541| [-1.05085 -2.30259 -0.16276]
21Feb17_083541| [ 0.71087  0.14900  1.13430]
21Feb17_083541| [-2.45877 -1.20999 -1.04986]
21Feb17_083541| [-1.00480  1.36344 -0.13998]
21Feb17_083541| [ 1.83140 -0.91532  0.07616]
21Feb17_083541| [-0.60404 -2.05184  0.76948]
21Feb17_083541| [ 0.52617  0.76042 -1.76746]
21Feb17_083541| [-0.22134  0.17324  0.99530]
21Feb17_083541| [-0.36427  1.34655  0.02110]
21Feb17_083541| [-0.93125 -0.33620 -0.25012]
21Feb17_083541| [-2.76428  0.14487  0.48096]
21Feb17_083541| [-0.10518  0.35052  1.71840]
21Feb17_083541| [-1.27998  1.12568  1.26523]
21Feb17_083541| [-0.60698  1.53230 -0.60824]
21Feb17_083541| [ 0.02898  2.98718 -0.59153]
21Feb17_083541| [ 0.17588 -0.00449  0.50797]
21Feb17_083541| [-1.42674 -0.54967 -0.21310]
21Feb17_083541| [ 1.03196  1.18733  0.36755]
21Feb17_083541| [ 1.04748 -1.47444 -0.08469]
21Feb17_083541| [ 0.49410  0.38745  0.68469]
21Feb17_083541| [-0.62880  0.73245  0.19964]]
21Feb17_083541|-- Bias --
21Feb17_083541|[-0.18798  0.64571 -0.23142]
21Feb17_083541|Layer 1:
21Feb17_083541|-- Config --
21Feb17_083541|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083541|-- Weights --
21Feb17_083541|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_083541| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_083541| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_083541|-- Bias --
21Feb17_083541|[0.60477 0.03773 0.26452 0.12222]
21Feb17_083541|Layer 2:
21Feb17_083541|-- Config --
21Feb17_083541|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083541|-- Weights --
21Feb17_083541|[[ 0.67920  0.12119]
21Feb17_083541| [ 0.44836  0.02916]
21Feb17_083541| [ 0.68939  0.31516]
21Feb17_083541| [-0.58995 -0.05861]]
21Feb17_083541|-- Bias --
21Feb17_083541|[ 0.59649 -0.08079]
21Feb17_083541|Layer 3:
21Feb17_083541|-- Config --
21Feb17_083541|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083541|-- Weights --
21Feb17_083541|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_083541| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_083541|-- Bias --
21Feb17_083541|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_083541|Layer 4:
21Feb17_083541|-- Config --
21Feb17_083541|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083541|-- Weights --
21Feb17_083541|[[-0.03514 -1.04833]
21Feb17_083541| [ 1.25238  0.62094]
21Feb17_083541| [ 0.99203  0.37406]
21Feb17_083541| [ 0.49902  0.67158]
21Feb17_083541| [-1.35709  0.38335]]
21Feb17_083541|-- Bias --
21Feb17_083541|[0.31435 0.36299]
21Feb17_083541|Predicting the validation and test data with the Best final individual.
21Feb17_083549| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_083549|-----------  ------------------  --------------------  ----------
21Feb17_083549|Validation         23.91                  56            0.70865
21Feb17_083549|   Test            29.45                  56            0.70270
21Feb17_083549|-------------------- Test #3 --------------------
21Feb17_083549|Best final individual weights
21Feb17_083549|Individual:
21Feb17_083549|-- Constant hidden layers --
21Feb17_083549|False
21Feb17_083549|Layer 0:
21Feb17_083549|-- Config --
21Feb17_083549|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083549|-- Weights --
21Feb17_083549|[[-0.73212  1.32861  0.10200]
21Feb17_083549| [ 1.48746 -2.97273 -0.42944]
21Feb17_083549| [ 0.53095 -1.50623  0.79224]
21Feb17_083549| [-1.07292 -0.83175 -0.90105]
21Feb17_083549| [-0.48696 -0.89325  0.27226]
21Feb17_083549| [-3.02511  0.34155 -0.03837]
21Feb17_083549| [-0.76747  0.57140 -0.46892]
21Feb17_083549| [-0.07581  0.14713  0.85910]
21Feb17_083549| [-1.37488  0.52170 -0.36205]
21Feb17_083549| [ 1.60981 -0.08727 -0.11267]
21Feb17_083549| [ 0.50986  1.58916 -0.35287]
21Feb17_083549| [-0.34599  1.27113 -0.16393]
21Feb17_083549| [ 1.29203  1.19467  0.37695]
21Feb17_083549| [ 0.58704  0.06328 -0.24240]
21Feb17_083549| [-0.93888 -0.89760  0.57087]
21Feb17_083549| [ 0.99159 -0.66387  0.35177]
21Feb17_083549| [-0.67119  1.06910 -0.12512]
21Feb17_083549| [-0.91534  1.23744 -0.40465]
21Feb17_083549| [ 1.39278  0.08069  0.23328]
21Feb17_083549| [ 0.09880  0.57603 -0.96101]
21Feb17_083549| [ 0.01621 -0.13343 -0.27624]
21Feb17_083549| [-1.28286 -2.28909  0.37931]
21Feb17_083549| [-0.28370  0.09336  0.01547]
21Feb17_083549| [-0.51894  1.84280 -0.25906]
21Feb17_083549| [-0.83075 -0.04508  0.12107]
21Feb17_083549| [ 0.37343  1.18436 -0.07358]
21Feb17_083549| [-2.38657 -0.35191  0.01962]
21Feb17_083549| [ 0.95757 -0.91760 -0.08971]
21Feb17_083549| [ 0.38792 -0.01880  0.69717]
21Feb17_083549| [ 1.66877 -0.58078 -1.21129]
21Feb17_083549| [-0.50943  0.59080  0.30856]
21Feb17_083549| [ 0.30163  1.11518  0.98185]
21Feb17_083549| [-0.73226  0.32281 -0.66712]
21Feb17_083549| [-0.62054 -2.21049  1.40981]
21Feb17_083549| [ 1.23185 -0.58090  0.35844]
21Feb17_083549| [-0.05616  0.24219 -0.02853]
21Feb17_083549| [-1.05085 -2.30259 -0.16276]
21Feb17_083549| [ 0.71087  0.14900  1.13430]
21Feb17_083549| [-2.45877 -1.20999 -1.04986]
21Feb17_083549| [-1.00480  1.36344 -0.13998]
21Feb17_083549| [ 1.83140 -0.91532  0.07616]
21Feb17_083549| [-0.60404 -2.05184  0.76948]
21Feb17_083549| [ 0.52617  0.76042 -1.76746]
21Feb17_083549| [-0.22134  0.17324  0.99530]
21Feb17_083549| [-0.36427  1.34655  0.02110]
21Feb17_083549| [-0.93125 -0.33620 -0.25012]
21Feb17_083549| [-2.76428  0.14487  0.48096]
21Feb17_083549| [-0.10518  0.35052  1.71840]
21Feb17_083549| [-1.27998  1.12568  1.26523]
21Feb17_083549| [-0.60698  1.53230 -0.60824]
21Feb17_083549| [ 0.02898  2.98718 -0.59153]
21Feb17_083549| [ 0.17588 -0.00449  0.50797]
21Feb17_083549| [-1.42674 -0.54967 -0.21310]
21Feb17_083549| [ 1.03196  1.18733  0.36755]
21Feb17_083549| [ 1.04748 -1.47444 -0.08469]
21Feb17_083549| [ 0.49410  0.38745  0.68469]
21Feb17_083549| [-0.62880  0.73245  0.19964]]
21Feb17_083549|-- Bias --
21Feb17_083549|[-0.18798  0.64571 -0.23142]
21Feb17_083549|Layer 1:
21Feb17_083549|-- Config --
21Feb17_083549|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083549|-- Weights --
21Feb17_083549|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_083549| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_083549| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_083549|-- Bias --
21Feb17_083549|[0.60477 0.03773 0.26452 0.12222]
21Feb17_083549|Layer 2:
21Feb17_083549|-- Config --
21Feb17_083549|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083549|-- Weights --
21Feb17_083549|[[ 0.67920  0.12119]
21Feb17_083549| [ 0.44836  0.02916]
21Feb17_083549| [ 0.68939  0.31516]
21Feb17_083549| [-0.58995 -0.05861]]
21Feb17_083549|-- Bias --
21Feb17_083549|[ 0.59649 -0.08079]
21Feb17_083549|Layer 3:
21Feb17_083549|-- Config --
21Feb17_083549|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083549|-- Weights --
21Feb17_083549|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_083549| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_083549|-- Bias --
21Feb17_083549|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_083549|Layer 4:
21Feb17_083549|-- Config --
21Feb17_083549|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083549|-- Weights --
21Feb17_083549|[[-0.03514 -1.04833]
21Feb17_083549| [ 1.25238  0.62094]
21Feb17_083549| [ 0.99203  0.37406]
21Feb17_083549| [ 0.49902  0.67158]
21Feb17_083549| [-1.35709  0.38335]]
21Feb17_083549|-- Bias --
21Feb17_083549|[0.31435 0.36299]
21Feb17_083549|Predicting the validation and test data with the Best final individual.
21Feb17_083557| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_083557|-----------  ------------------  --------------------  ----------
21Feb17_083557|Validation         24.35                  56            0.84577
21Feb17_083557|   Test            21.63                  56            0.70714
21Feb17_083557|-------------------- Test #4 --------------------
21Feb17_083557|Best final individual weights
21Feb17_083557|Individual:
21Feb17_083557|-- Constant hidden layers --
21Feb17_083557|False
21Feb17_083557|Layer 0:
21Feb17_083557|-- Config --
21Feb17_083557|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083557|-- Weights --
21Feb17_083557|[[-0.73212  1.32861  0.10200]
21Feb17_083557| [ 1.48746 -2.97273 -0.42944]
21Feb17_083557| [ 0.53095 -1.50623  0.79224]
21Feb17_083557| [-1.07292 -0.83175 -0.90105]
21Feb17_083557| [-0.48696 -0.89325  0.27226]
21Feb17_083557| [-3.02511  0.34155 -0.03837]
21Feb17_083557| [-0.76747  0.57140 -0.46892]
21Feb17_083557| [-0.07581  0.14713  0.85910]
21Feb17_083557| [-1.37488  0.52170 -0.36205]
21Feb17_083557| [ 1.60981 -0.08727 -0.11267]
21Feb17_083557| [ 0.50986  1.58916 -0.35287]
21Feb17_083557| [-0.34599  1.27113 -0.16393]
21Feb17_083557| [ 1.29203  1.19467  0.37695]
21Feb17_083557| [ 0.58704  0.06328 -0.24240]
21Feb17_083557| [-0.93888 -0.89760  0.57087]
21Feb17_083557| [ 0.99159 -0.66387  0.35177]
21Feb17_083557| [-0.67119  1.06910 -0.12512]
21Feb17_083557| [-0.91534  1.23744 -0.40465]
21Feb17_083557| [ 1.39278  0.08069  0.23328]
21Feb17_083557| [ 0.09880  0.57603 -0.96101]
21Feb17_083557| [ 0.01621 -0.13343 -0.27624]
21Feb17_083557| [-1.28286 -2.28909  0.37931]
21Feb17_083557| [-0.28370  0.09336  0.01547]
21Feb17_083557| [-0.51894  1.84280 -0.25906]
21Feb17_083557| [-0.83075 -0.04508  0.12107]
21Feb17_083557| [ 0.37343  1.18436 -0.07358]
21Feb17_083557| [-2.38657 -0.35191  0.01962]
21Feb17_083557| [ 0.95757 -0.91760 -0.08971]
21Feb17_083557| [ 0.38792 -0.01880  0.69717]
21Feb17_083557| [ 1.66877 -0.58078 -1.21129]
21Feb17_083557| [-0.50943  0.59080  0.30856]
21Feb17_083557| [ 0.30163  1.11518  0.98185]
21Feb17_083557| [-0.73226  0.32281 -0.66712]
21Feb17_083557| [-0.62054 -2.21049  1.40981]
21Feb17_083557| [ 1.23185 -0.58090  0.35844]
21Feb17_083557| [-0.05616  0.24219 -0.02853]
21Feb17_083557| [-1.05085 -2.30259 -0.16276]
21Feb17_083557| [ 0.71087  0.14900  1.13430]
21Feb17_083557| [-2.45877 -1.20999 -1.04986]
21Feb17_083557| [-1.00480  1.36344 -0.13998]
21Feb17_083557| [ 1.83140 -0.91532  0.07616]
21Feb17_083557| [-0.60404 -2.05184  0.76948]
21Feb17_083557| [ 0.52617  0.76042 -1.76746]
21Feb17_083557| [-0.22134  0.17324  0.99530]
21Feb17_083557| [-0.36427  1.34655  0.02110]
21Feb17_083557| [-0.93125 -0.33620 -0.25012]
21Feb17_083557| [-2.76428  0.14487  0.48096]
21Feb17_083557| [-0.10518  0.35052  1.71840]
21Feb17_083557| [-1.27998  1.12568  1.26523]
21Feb17_083557| [-0.60698  1.53230 -0.60824]
21Feb17_083557| [ 0.02898  2.98718 -0.59153]
21Feb17_083557| [ 0.17588 -0.00449  0.50797]
21Feb17_083557| [-1.42674 -0.54967 -0.21310]
21Feb17_083557| [ 1.03196  1.18733  0.36755]
21Feb17_083557| [ 1.04748 -1.47444 -0.08469]
21Feb17_083557| [ 0.49410  0.38745  0.68469]
21Feb17_083557| [-0.62880  0.73245  0.19964]]
21Feb17_083557|-- Bias --
21Feb17_083557|[-0.18798  0.64571 -0.23142]
21Feb17_083557|Layer 1:
21Feb17_083557|-- Config --
21Feb17_083557|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083557|-- Weights --
21Feb17_083557|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_083557| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_083557| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_083557|-- Bias --
21Feb17_083557|[0.60477 0.03773 0.26452 0.12222]
21Feb17_083557|Layer 2:
21Feb17_083557|-- Config --
21Feb17_083557|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083557|-- Weights --
21Feb17_083557|[[ 0.67920  0.12119]
21Feb17_083557| [ 0.44836  0.02916]
21Feb17_083557| [ 0.68939  0.31516]
21Feb17_083557| [-0.58995 -0.05861]]
21Feb17_083557|-- Bias --
21Feb17_083557|[ 0.59649 -0.08079]
21Feb17_083557|Layer 3:
21Feb17_083557|-- Config --
21Feb17_083557|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083557|-- Weights --
21Feb17_083557|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_083557| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_083557|-- Bias --
21Feb17_083557|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_083557|Layer 4:
21Feb17_083557|-- Config --
21Feb17_083557|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083557|-- Weights --
21Feb17_083557|[[-0.03514 -1.04833]
21Feb17_083557| [ 1.25238  0.62094]
21Feb17_083557| [ 0.99203  0.37406]
21Feb17_083557| [ 0.49902  0.67158]
21Feb17_083557| [-1.35709  0.38335]]
21Feb17_083557|-- Bias --
21Feb17_083557|[0.31435 0.36299]
21Feb17_083557|Predicting the validation and test data with the Best final individual.
21Feb17_083605| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_083605|-----------  ------------------  --------------------  ----------
21Feb17_083605|Validation         21.57                  56            0.82113
21Feb17_083605|   Test            31.19                  56            0.83333
21Feb17_083605|-------------------- Test #5 --------------------
21Feb17_083605|Best final individual weights
21Feb17_083605|Individual:
21Feb17_083605|-- Constant hidden layers --
21Feb17_083605|False
21Feb17_083605|Layer 0:
21Feb17_083605|-- Config --
21Feb17_083605|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083605|-- Weights --
21Feb17_083605|[[-0.73212  1.32861  0.10200]
21Feb17_083605| [ 1.48746 -2.97273 -0.42944]
21Feb17_083605| [ 0.53095 -1.50623  0.79224]
21Feb17_083605| [-1.07292 -0.83175 -0.90105]
21Feb17_083605| [-0.48696 -0.89325  0.27226]
21Feb17_083605| [-3.02511  0.34155 -0.03837]
21Feb17_083605| [-0.76747  0.57140 -0.46892]
21Feb17_083605| [-0.07581  0.14713  0.85910]
21Feb17_083605| [-1.37488  0.52170 -0.36205]
21Feb17_083605| [ 1.60981 -0.08727 -0.11267]
21Feb17_083605| [ 0.50986  1.58916 -0.35287]
21Feb17_083605| [-0.34599  1.27113 -0.16393]
21Feb17_083605| [ 1.29203  1.19467  0.37695]
21Feb17_083605| [ 0.58704  0.06328 -0.24240]
21Feb17_083605| [-0.93888 -0.89760  0.57087]
21Feb17_083605| [ 0.99159 -0.66387  0.35177]
21Feb17_083605| [-0.67119  1.06910 -0.12512]
21Feb17_083605| [-0.91534  1.23744 -0.40465]
21Feb17_083605| [ 1.39278  0.08069  0.23328]
21Feb17_083605| [ 0.09880  0.57603 -0.96101]
21Feb17_083605| [ 0.01621 -0.13343 -0.27624]
21Feb17_083605| [-1.28286 -2.28909  0.37931]
21Feb17_083605| [-0.28370  0.09336  0.01547]
21Feb17_083605| [-0.51894  1.84280 -0.25906]
21Feb17_083605| [-0.83075 -0.04508  0.12107]
21Feb17_083605| [ 0.37343  1.18436 -0.07358]
21Feb17_083605| [-2.38657 -0.35191  0.01962]
21Feb17_083605| [ 0.95757 -0.91760 -0.08971]
21Feb17_083605| [ 0.38792 -0.01880  0.69717]
21Feb17_083605| [ 1.66877 -0.58078 -1.21129]
21Feb17_083605| [-0.50943  0.59080  0.30856]
21Feb17_083605| [ 0.30163  1.11518  0.98185]
21Feb17_083605| [-0.73226  0.32281 -0.66712]
21Feb17_083605| [-0.62054 -2.21049  1.40981]
21Feb17_083605| [ 1.23185 -0.58090  0.35844]
21Feb17_083605| [-0.05616  0.24219 -0.02853]
21Feb17_083605| [-1.05085 -2.30259 -0.16276]
21Feb17_083605| [ 0.71087  0.14900  1.13430]
21Feb17_083605| [-2.45877 -1.20999 -1.04986]
21Feb17_083605| [-1.00480  1.36344 -0.13998]
21Feb17_083605| [ 1.83140 -0.91532  0.07616]
21Feb17_083605| [-0.60404 -2.05184  0.76948]
21Feb17_083605| [ 0.52617  0.76042 -1.76746]
21Feb17_083605| [-0.22134  0.17324  0.99530]
21Feb17_083605| [-0.36427  1.34655  0.02110]
21Feb17_083605| [-0.93125 -0.33620 -0.25012]
21Feb17_083605| [-2.76428  0.14487  0.48096]
21Feb17_083605| [-0.10518  0.35052  1.71840]
21Feb17_083605| [-1.27998  1.12568  1.26523]
21Feb17_083605| [-0.60698  1.53230 -0.60824]
21Feb17_083605| [ 0.02898  2.98718 -0.59153]
21Feb17_083605| [ 0.17588 -0.00449  0.50797]
21Feb17_083605| [-1.42674 -0.54967 -0.21310]
21Feb17_083605| [ 1.03196  1.18733  0.36755]
21Feb17_083605| [ 1.04748 -1.47444 -0.08469]
21Feb17_083605| [ 0.49410  0.38745  0.68469]
21Feb17_083605| [-0.62880  0.73245  0.19964]]
21Feb17_083605|-- Bias --
21Feb17_083605|[-0.18798  0.64571 -0.23142]
21Feb17_083605|Layer 1:
21Feb17_083605|-- Config --
21Feb17_083605|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083605|-- Weights --
21Feb17_083605|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_083605| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_083605| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_083605|-- Bias --
21Feb17_083605|[0.60477 0.03773 0.26452 0.12222]
21Feb17_083605|Layer 2:
21Feb17_083605|-- Config --
21Feb17_083605|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083605|-- Weights --
21Feb17_083605|[[ 0.67920  0.12119]
21Feb17_083605| [ 0.44836  0.02916]
21Feb17_083605| [ 0.68939  0.31516]
21Feb17_083605| [-0.58995 -0.05861]]
21Feb17_083605|-- Bias --
21Feb17_083605|[ 0.59649 -0.08079]
21Feb17_083605|Layer 3:
21Feb17_083605|-- Config --
21Feb17_083605|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083605|-- Weights --
21Feb17_083605|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_083605| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_083605|-- Bias --
21Feb17_083605|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_083605|Layer 4:
21Feb17_083605|-- Config --
21Feb17_083605|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083605|-- Weights --
21Feb17_083605|[[-0.03514 -1.04833]
21Feb17_083605| [ 1.25238  0.62094]
21Feb17_083605| [ 0.99203  0.37406]
21Feb17_083605| [ 0.49902  0.67158]
21Feb17_083605| [-1.35709  0.38335]]
21Feb17_083605|-- Bias --
21Feb17_083605|[0.31435 0.36299]
21Feb17_083605|Predicting the validation and test data with the Best final individual.
21Feb17_083612| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_083612|-----------  ------------------  --------------------  ----------
21Feb17_083612|Validation         23.22                  56            0.86009
21Feb17_083612|   Test            26.15                  56            0.85097
21Feb17_083612|-------------------- Test #6 --------------------
21Feb17_083612|Best final individual weights
21Feb17_083612|Individual:
21Feb17_083612|-- Constant hidden layers --
21Feb17_083612|False
21Feb17_083612|Layer 0:
21Feb17_083612|-- Config --
21Feb17_083612|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083612|-- Weights --
21Feb17_083612|[[-0.73212  1.32861  0.10200]
21Feb17_083612| [ 1.48746 -2.97273 -0.42944]
21Feb17_083612| [ 0.53095 -1.50623  0.79224]
21Feb17_083612| [-1.07292 -0.83175 -0.90105]
21Feb17_083612| [-0.48696 -0.89325  0.27226]
21Feb17_083612| [-3.02511  0.34155 -0.03837]
21Feb17_083612| [-0.76747  0.57140 -0.46892]
21Feb17_083612| [-0.07581  0.14713  0.85910]
21Feb17_083612| [-1.37488  0.52170 -0.36205]
21Feb17_083612| [ 1.60981 -0.08727 -0.11267]
21Feb17_083612| [ 0.50986  1.58916 -0.35287]
21Feb17_083612| [-0.34599  1.27113 -0.16393]
21Feb17_083612| [ 1.29203  1.19467  0.37695]
21Feb17_083612| [ 0.58704  0.06328 -0.24240]
21Feb17_083612| [-0.93888 -0.89760  0.57087]
21Feb17_083612| [ 0.99159 -0.66387  0.35177]
21Feb17_083612| [-0.67119  1.06910 -0.12512]
21Feb17_083612| [-0.91534  1.23744 -0.40465]
21Feb17_083612| [ 1.39278  0.08069  0.23328]
21Feb17_083612| [ 0.09880  0.57603 -0.96101]
21Feb17_083612| [ 0.01621 -0.13343 -0.27624]
21Feb17_083612| [-1.28286 -2.28909  0.37931]
21Feb17_083612| [-0.28370  0.09336  0.01547]
21Feb17_083612| [-0.51894  1.84280 -0.25906]
21Feb17_083612| [-0.83075 -0.04508  0.12107]
21Feb17_083612| [ 0.37343  1.18436 -0.07358]
21Feb17_083612| [-2.38657 -0.35191  0.01962]
21Feb17_083612| [ 0.95757 -0.91760 -0.08971]
21Feb17_083612| [ 0.38792 -0.01880  0.69717]
21Feb17_083612| [ 1.66877 -0.58078 -1.21129]
21Feb17_083612| [-0.50943  0.59080  0.30856]
21Feb17_083612| [ 0.30163  1.11518  0.98185]
21Feb17_083612| [-0.73226  0.32281 -0.66712]
21Feb17_083612| [-0.62054 -2.21049  1.40981]
21Feb17_083612| [ 1.23185 -0.58090  0.35844]
21Feb17_083612| [-0.05616  0.24219 -0.02853]
21Feb17_083612| [-1.05085 -2.30259 -0.16276]
21Feb17_083612| [ 0.71087  0.14900  1.13430]
21Feb17_083612| [-2.45877 -1.20999 -1.04986]
21Feb17_083612| [-1.00480  1.36344 -0.13998]
21Feb17_083612| [ 1.83140 -0.91532  0.07616]
21Feb17_083612| [-0.60404 -2.05184  0.76948]
21Feb17_083612| [ 0.52617  0.76042 -1.76746]
21Feb17_083612| [-0.22134  0.17324  0.99530]
21Feb17_083612| [-0.36427  1.34655  0.02110]
21Feb17_083612| [-0.93125 -0.33620 -0.25012]
21Feb17_083612| [-2.76428  0.14487  0.48096]
21Feb17_083612| [-0.10518  0.35052  1.71840]
21Feb17_083612| [-1.27998  1.12568  1.26523]
21Feb17_083612| [-0.60698  1.53230 -0.60824]
21Feb17_083612| [ 0.02898  2.98718 -0.59153]
21Feb17_083612| [ 0.17588 -0.00449  0.50797]
21Feb17_083612| [-1.42674 -0.54967 -0.21310]
21Feb17_083612| [ 1.03196  1.18733  0.36755]
21Feb17_083612| [ 1.04748 -1.47444 -0.08469]
21Feb17_083612| [ 0.49410  0.38745  0.68469]
21Feb17_083612| [-0.62880  0.73245  0.19964]]
21Feb17_083612|-- Bias --
21Feb17_083612|[-0.18798  0.64571 -0.23142]
21Feb17_083612|Layer 1:
21Feb17_083612|-- Config --
21Feb17_083612|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083612|-- Weights --
21Feb17_083612|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_083612| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_083612| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_083612|-- Bias --
21Feb17_083612|[0.60477 0.03773 0.26452 0.12222]
21Feb17_083612|Layer 2:
21Feb17_083612|-- Config --
21Feb17_083612|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083612|-- Weights --
21Feb17_083612|[[ 0.67920  0.12119]
21Feb17_083612| [ 0.44836  0.02916]
21Feb17_083612| [ 0.68939  0.31516]
21Feb17_083612| [-0.58995 -0.05861]]
21Feb17_083612|-- Bias --
21Feb17_083612|[ 0.59649 -0.08079]
21Feb17_083612|Layer 3:
21Feb17_083612|-- Config --
21Feb17_083612|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083612|-- Weights --
21Feb17_083612|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_083612| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_083612|-- Bias --
21Feb17_083612|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_083612|Layer 4:
21Feb17_083612|-- Config --
21Feb17_083612|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083612|-- Weights --
21Feb17_083612|[[-0.03514 -1.04833]
21Feb17_083612| [ 1.25238  0.62094]
21Feb17_083612| [ 0.99203  0.37406]
21Feb17_083612| [ 0.49902  0.67158]
21Feb17_083612| [-1.35709  0.38335]]
21Feb17_083612|-- Bias --
21Feb17_083612|[0.31435 0.36299]
21Feb17_083612|Predicting the validation and test data with the Best final individual.
21Feb17_083620| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_083620|-----------  ------------------  --------------------  ----------
21Feb17_083620|Validation         22.78                  56            0.83496
21Feb17_083620|   Test            21.11                  56            0.79855
21Feb17_083620|-------------------- Test #7 --------------------
21Feb17_083620|Best final individual weights
21Feb17_083620|Individual:
21Feb17_083620|-- Constant hidden layers --
21Feb17_083620|False
21Feb17_083620|Layer 0:
21Feb17_083620|-- Config --
21Feb17_083620|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083620|-- Weights --
21Feb17_083620|[[-0.73212  1.32861  0.10200]
21Feb17_083620| [ 1.48746 -2.97273 -0.42944]
21Feb17_083620| [ 0.53095 -1.50623  0.79224]
21Feb17_083620| [-1.07292 -0.83175 -0.90105]
21Feb17_083620| [-0.48696 -0.89325  0.27226]
21Feb17_083620| [-3.02511  0.34155 -0.03837]
21Feb17_083620| [-0.76747  0.57140 -0.46892]
21Feb17_083620| [-0.07581  0.14713  0.85910]
21Feb17_083620| [-1.37488  0.52170 -0.36205]
21Feb17_083620| [ 1.60981 -0.08727 -0.11267]
21Feb17_083620| [ 0.50986  1.58916 -0.35287]
21Feb17_083620| [-0.34599  1.27113 -0.16393]
21Feb17_083620| [ 1.29203  1.19467  0.37695]
21Feb17_083620| [ 0.58704  0.06328 -0.24240]
21Feb17_083620| [-0.93888 -0.89760  0.57087]
21Feb17_083620| [ 0.99159 -0.66387  0.35177]
21Feb17_083620| [-0.67119  1.06910 -0.12512]
21Feb17_083620| [-0.91534  1.23744 -0.40465]
21Feb17_083620| [ 1.39278  0.08069  0.23328]
21Feb17_083620| [ 0.09880  0.57603 -0.96101]
21Feb17_083620| [ 0.01621 -0.13343 -0.27624]
21Feb17_083620| [-1.28286 -2.28909  0.37931]
21Feb17_083620| [-0.28370  0.09336  0.01547]
21Feb17_083620| [-0.51894  1.84280 -0.25906]
21Feb17_083620| [-0.83075 -0.04508  0.12107]
21Feb17_083620| [ 0.37343  1.18436 -0.07358]
21Feb17_083620| [-2.38657 -0.35191  0.01962]
21Feb17_083620| [ 0.95757 -0.91760 -0.08971]
21Feb17_083620| [ 0.38792 -0.01880  0.69717]
21Feb17_083620| [ 1.66877 -0.58078 -1.21129]
21Feb17_083620| [-0.50943  0.59080  0.30856]
21Feb17_083620| [ 0.30163  1.11518  0.98185]
21Feb17_083620| [-0.73226  0.32281 -0.66712]
21Feb17_083620| [-0.62054 -2.21049  1.40981]
21Feb17_083620| [ 1.23185 -0.58090  0.35844]
21Feb17_083620| [-0.05616  0.24219 -0.02853]
21Feb17_083620| [-1.05085 -2.30259 -0.16276]
21Feb17_083620| [ 0.71087  0.14900  1.13430]
21Feb17_083620| [-2.45877 -1.20999 -1.04986]
21Feb17_083620| [-1.00480  1.36344 -0.13998]
21Feb17_083620| [ 1.83140 -0.91532  0.07616]
21Feb17_083620| [-0.60404 -2.05184  0.76948]
21Feb17_083620| [ 0.52617  0.76042 -1.76746]
21Feb17_083620| [-0.22134  0.17324  0.99530]
21Feb17_083620| [-0.36427  1.34655  0.02110]
21Feb17_083620| [-0.93125 -0.33620 -0.25012]
21Feb17_083620| [-2.76428  0.14487  0.48096]
21Feb17_083620| [-0.10518  0.35052  1.71840]
21Feb17_083620| [-1.27998  1.12568  1.26523]
21Feb17_083620| [-0.60698  1.53230 -0.60824]
21Feb17_083620| [ 0.02898  2.98718 -0.59153]
21Feb17_083620| [ 0.17588 -0.00449  0.50797]
21Feb17_083620| [-1.42674 -0.54967 -0.21310]
21Feb17_083620| [ 1.03196  1.18733  0.36755]
21Feb17_083620| [ 1.04748 -1.47444 -0.08469]
21Feb17_083620| [ 0.49410  0.38745  0.68469]
21Feb17_083620| [-0.62880  0.73245  0.19964]]
21Feb17_083620|-- Bias --
21Feb17_083620|[-0.18798  0.64571 -0.23142]
21Feb17_083620|Layer 1:
21Feb17_083620|-- Config --
21Feb17_083620|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083620|-- Weights --
21Feb17_083620|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_083620| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_083620| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_083620|-- Bias --
21Feb17_083620|[0.60477 0.03773 0.26452 0.12222]
21Feb17_083620|Layer 2:
21Feb17_083620|-- Config --
21Feb17_083620|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083620|-- Weights --
21Feb17_083620|[[ 0.67920  0.12119]
21Feb17_083620| [ 0.44836  0.02916]
21Feb17_083620| [ 0.68939  0.31516]
21Feb17_083620| [-0.58995 -0.05861]]
21Feb17_083620|-- Bias --
21Feb17_083620|[ 0.59649 -0.08079]
21Feb17_083620|Layer 3:
21Feb17_083620|-- Config --
21Feb17_083620|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083620|-- Weights --
21Feb17_083620|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_083620| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_083620|-- Bias --
21Feb17_083620|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_083620|Layer 4:
21Feb17_083620|-- Config --
21Feb17_083620|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083620|-- Weights --
21Feb17_083620|[[-0.03514 -1.04833]
21Feb17_083620| [ 1.25238  0.62094]
21Feb17_083620| [ 0.99203  0.37406]
21Feb17_083620| [ 0.49902  0.67158]
21Feb17_083620| [-1.35709  0.38335]]
21Feb17_083620|-- Bias --
21Feb17_083620|[0.31435 0.36299]
21Feb17_083620|Predicting the validation and test data with the Best final individual.
21Feb17_083628| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_083628|-----------  ------------------  --------------------  ----------
21Feb17_083628|Validation         28.96                  56            0.48780
21Feb17_083628|   Test            25.46                  56            0.49431
21Feb17_083628|-------------------- Test #8 --------------------
21Feb17_083628|Best final individual weights
21Feb17_083628|Individual:
21Feb17_083628|-- Constant hidden layers --
21Feb17_083628|False
21Feb17_083628|Layer 0:
21Feb17_083628|-- Config --
21Feb17_083628|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083628|-- Weights --
21Feb17_083628|[[-0.73212  1.32861  0.10200]
21Feb17_083628| [ 1.48746 -2.97273 -0.42944]
21Feb17_083628| [ 0.53095 -1.50623  0.79224]
21Feb17_083628| [-1.07292 -0.83175 -0.90105]
21Feb17_083628| [-0.48696 -0.89325  0.27226]
21Feb17_083628| [-3.02511  0.34155 -0.03837]
21Feb17_083628| [-0.76747  0.57140 -0.46892]
21Feb17_083628| [-0.07581  0.14713  0.85910]
21Feb17_083628| [-1.37488  0.52170 -0.36205]
21Feb17_083628| [ 1.60981 -0.08727 -0.11267]
21Feb17_083628| [ 0.50986  1.58916 -0.35287]
21Feb17_083628| [-0.34599  1.27113 -0.16393]
21Feb17_083628| [ 1.29203  1.19467  0.37695]
21Feb17_083628| [ 0.58704  0.06328 -0.24240]
21Feb17_083628| [-0.93888 -0.89760  0.57087]
21Feb17_083628| [ 0.99159 -0.66387  0.35177]
21Feb17_083628| [-0.67119  1.06910 -0.12512]
21Feb17_083628| [-0.91534  1.23744 -0.40465]
21Feb17_083628| [ 1.39278  0.08069  0.23328]
21Feb17_083628| [ 0.09880  0.57603 -0.96101]
21Feb17_083628| [ 0.01621 -0.13343 -0.27624]
21Feb17_083628| [-1.28286 -2.28909  0.37931]
21Feb17_083628| [-0.28370  0.09336  0.01547]
21Feb17_083628| [-0.51894  1.84280 -0.25906]
21Feb17_083628| [-0.83075 -0.04508  0.12107]
21Feb17_083628| [ 0.37343  1.18436 -0.07358]
21Feb17_083628| [-2.38657 -0.35191  0.01962]
21Feb17_083628| [ 0.95757 -0.91760 -0.08971]
21Feb17_083628| [ 0.38792 -0.01880  0.69717]
21Feb17_083628| [ 1.66877 -0.58078 -1.21129]
21Feb17_083628| [-0.50943  0.59080  0.30856]
21Feb17_083628| [ 0.30163  1.11518  0.98185]
21Feb17_083628| [-0.73226  0.32281 -0.66712]
21Feb17_083628| [-0.62054 -2.21049  1.40981]
21Feb17_083628| [ 1.23185 -0.58090  0.35844]
21Feb17_083628| [-0.05616  0.24219 -0.02853]
21Feb17_083628| [-1.05085 -2.30259 -0.16276]
21Feb17_083628| [ 0.71087  0.14900  1.13430]
21Feb17_083628| [-2.45877 -1.20999 -1.04986]
21Feb17_083628| [-1.00480  1.36344 -0.13998]
21Feb17_083628| [ 1.83140 -0.91532  0.07616]
21Feb17_083628| [-0.60404 -2.05184  0.76948]
21Feb17_083628| [ 0.52617  0.76042 -1.76746]
21Feb17_083628| [-0.22134  0.17324  0.99530]
21Feb17_083628| [-0.36427  1.34655  0.02110]
21Feb17_083628| [-0.93125 -0.33620 -0.25012]
21Feb17_083628| [-2.76428  0.14487  0.48096]
21Feb17_083628| [-0.10518  0.35052  1.71840]
21Feb17_083628| [-1.27998  1.12568  1.26523]
21Feb17_083628| [-0.60698  1.53230 -0.60824]
21Feb17_083628| [ 0.02898  2.98718 -0.59153]
21Feb17_083628| [ 0.17588 -0.00449  0.50797]
21Feb17_083628| [-1.42674 -0.54967 -0.21310]
21Feb17_083628| [ 1.03196  1.18733  0.36755]
21Feb17_083628| [ 1.04748 -1.47444 -0.08469]
21Feb17_083628| [ 0.49410  0.38745  0.68469]
21Feb17_083628| [-0.62880  0.73245  0.19964]]
21Feb17_083628|-- Bias --
21Feb17_083628|[-0.18798  0.64571 -0.23142]
21Feb17_083628|Layer 1:
21Feb17_083628|-- Config --
21Feb17_083628|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083628|-- Weights --
21Feb17_083628|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_083628| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_083628| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_083628|-- Bias --
21Feb17_083628|[0.60477 0.03773 0.26452 0.12222]
21Feb17_083628|Layer 2:
21Feb17_083628|-- Config --
21Feb17_083628|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083628|-- Weights --
21Feb17_083628|[[ 0.67920  0.12119]
21Feb17_083628| [ 0.44836  0.02916]
21Feb17_083628| [ 0.68939  0.31516]
21Feb17_083628| [-0.58995 -0.05861]]
21Feb17_083628|-- Bias --
21Feb17_083628|[ 0.59649 -0.08079]
21Feb17_083628|Layer 3:
21Feb17_083628|-- Config --
21Feb17_083628|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083628|-- Weights --
21Feb17_083628|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_083628| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_083628|-- Bias --
21Feb17_083628|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_083628|Layer 4:
21Feb17_083628|-- Config --
21Feb17_083628|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083628|-- Weights --
21Feb17_083628|[[-0.03514 -1.04833]
21Feb17_083628| [ 1.25238  0.62094]
21Feb17_083628| [ 0.99203  0.37406]
21Feb17_083628| [ 0.49902  0.67158]
21Feb17_083628| [-1.35709  0.38335]]
21Feb17_083628|-- Bias --
21Feb17_083628|[0.31435 0.36299]
21Feb17_083628|Predicting the validation and test data with the Best final individual.
21Feb17_083636| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_083636|-----------  ------------------  --------------------  ----------
21Feb17_083636|Validation         21.30                  56            0.82476
21Feb17_083636|   Test            21.81                  56            0.83186
21Feb17_083636|-------------------- Test #9 --------------------
21Feb17_083636|Best final individual weights
21Feb17_083636|Individual:
21Feb17_083636|-- Constant hidden layers --
21Feb17_083636|False
21Feb17_083636|Layer 0:
21Feb17_083636|-- Config --
21Feb17_083636|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083636|-- Weights --
21Feb17_083636|[[-0.73212  1.32861  0.10200]
21Feb17_083636| [ 1.48746 -2.97273 -0.42944]
21Feb17_083636| [ 0.53095 -1.50623  0.79224]
21Feb17_083636| [-1.07292 -0.83175 -0.90105]
21Feb17_083636| [-0.48696 -0.89325  0.27226]
21Feb17_083636| [-3.02511  0.34155 -0.03837]
21Feb17_083636| [-0.76747  0.57140 -0.46892]
21Feb17_083636| [-0.07581  0.14713  0.85910]
21Feb17_083636| [-1.37488  0.52170 -0.36205]
21Feb17_083636| [ 1.60981 -0.08727 -0.11267]
21Feb17_083636| [ 0.50986  1.58916 -0.35287]
21Feb17_083636| [-0.34599  1.27113 -0.16393]
21Feb17_083636| [ 1.29203  1.19467  0.37695]
21Feb17_083636| [ 0.58704  0.06328 -0.24240]
21Feb17_083636| [-0.93888 -0.89760  0.57087]
21Feb17_083636| [ 0.99159 -0.66387  0.35177]
21Feb17_083636| [-0.67119  1.06910 -0.12512]
21Feb17_083636| [-0.91534  1.23744 -0.40465]
21Feb17_083636| [ 1.39278  0.08069  0.23328]
21Feb17_083636| [ 0.09880  0.57603 -0.96101]
21Feb17_083636| [ 0.01621 -0.13343 -0.27624]
21Feb17_083636| [-1.28286 -2.28909  0.37931]
21Feb17_083636| [-0.28370  0.09336  0.01547]
21Feb17_083636| [-0.51894  1.84280 -0.25906]
21Feb17_083636| [-0.83075 -0.04508  0.12107]
21Feb17_083636| [ 0.37343  1.18436 -0.07358]
21Feb17_083636| [-2.38657 -0.35191  0.01962]
21Feb17_083636| [ 0.95757 -0.91760 -0.08971]
21Feb17_083636| [ 0.38792 -0.01880  0.69717]
21Feb17_083636| [ 1.66877 -0.58078 -1.21129]
21Feb17_083636| [-0.50943  0.59080  0.30856]
21Feb17_083636| [ 0.30163  1.11518  0.98185]
21Feb17_083636| [-0.73226  0.32281 -0.66712]
21Feb17_083636| [-0.62054 -2.21049  1.40981]
21Feb17_083636| [ 1.23185 -0.58090  0.35844]
21Feb17_083636| [-0.05616  0.24219 -0.02853]
21Feb17_083636| [-1.05085 -2.30259 -0.16276]
21Feb17_083636| [ 0.71087  0.14900  1.13430]
21Feb17_083636| [-2.45877 -1.20999 -1.04986]
21Feb17_083636| [-1.00480  1.36344 -0.13998]
21Feb17_083636| [ 1.83140 -0.91532  0.07616]
21Feb17_083636| [-0.60404 -2.05184  0.76948]
21Feb17_083636| [ 0.52617  0.76042 -1.76746]
21Feb17_083636| [-0.22134  0.17324  0.99530]
21Feb17_083636| [-0.36427  1.34655  0.02110]
21Feb17_083636| [-0.93125 -0.33620 -0.25012]
21Feb17_083636| [-2.76428  0.14487  0.48096]
21Feb17_083636| [-0.10518  0.35052  1.71840]
21Feb17_083636| [-1.27998  1.12568  1.26523]
21Feb17_083636| [-0.60698  1.53230 -0.60824]
21Feb17_083636| [ 0.02898  2.98718 -0.59153]
21Feb17_083636| [ 0.17588 -0.00449  0.50797]
21Feb17_083636| [-1.42674 -0.54967 -0.21310]
21Feb17_083636| [ 1.03196  1.18733  0.36755]
21Feb17_083636| [ 1.04748 -1.47444 -0.08469]
21Feb17_083636| [ 0.49410  0.38745  0.68469]
21Feb17_083636| [-0.62880  0.73245  0.19964]]
21Feb17_083636|-- Bias --
21Feb17_083636|[-0.18798  0.64571 -0.23142]
21Feb17_083636|Layer 1:
21Feb17_083636|-- Config --
21Feb17_083636|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083636|-- Weights --
21Feb17_083636|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_083636| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_083636| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_083636|-- Bias --
21Feb17_083636|[0.60477 0.03773 0.26452 0.12222]
21Feb17_083636|Layer 2:
21Feb17_083636|-- Config --
21Feb17_083636|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083636|-- Weights --
21Feb17_083636|[[ 0.67920  0.12119]
21Feb17_083636| [ 0.44836  0.02916]
21Feb17_083636| [ 0.68939  0.31516]
21Feb17_083636| [-0.58995 -0.05861]]
21Feb17_083636|-- Bias --
21Feb17_083636|[ 0.59649 -0.08079]
21Feb17_083636|Layer 3:
21Feb17_083636|-- Config --
21Feb17_083636|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083636|-- Weights --
21Feb17_083636|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_083636| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_083636|-- Bias --
21Feb17_083636|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_083636|Layer 4:
21Feb17_083636|-- Config --
21Feb17_083636|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083636|-- Weights --
21Feb17_083636|[[-0.03514 -1.04833]
21Feb17_083636| [ 1.25238  0.62094]
21Feb17_083636| [ 0.99203  0.37406]
21Feb17_083636| [ 0.49902  0.67158]
21Feb17_083636| [-1.35709  0.38335]]
21Feb17_083636|-- Bias --
21Feb17_083636|[0.31435 0.36299]
21Feb17_083636|Predicting the validation and test data with the Best final individual.
21Feb17_083643| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_083643|-----------  ------------------  --------------------  ----------
21Feb17_083643|Validation         26.43                  56            0.71922
21Feb17_083643|   Test            29.54                  56            0.67444
21Feb17_083643|-------------------- Test #10 --------------------
21Feb17_083643|Best final individual weights
21Feb17_083643|Individual:
21Feb17_083643|-- Constant hidden layers --
21Feb17_083643|False
21Feb17_083643|Layer 0:
21Feb17_083643|-- Config --
21Feb17_083643|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083643|-- Weights --
21Feb17_083643|[[-0.73212  1.32861  0.10200]
21Feb17_083643| [ 1.48746 -2.97273 -0.42944]
21Feb17_083643| [ 0.53095 -1.50623  0.79224]
21Feb17_083643| [-1.07292 -0.83175 -0.90105]
21Feb17_083643| [-0.48696 -0.89325  0.27226]
21Feb17_083643| [-3.02511  0.34155 -0.03837]
21Feb17_083643| [-0.76747  0.57140 -0.46892]
21Feb17_083643| [-0.07581  0.14713  0.85910]
21Feb17_083643| [-1.37488  0.52170 -0.36205]
21Feb17_083643| [ 1.60981 -0.08727 -0.11267]
21Feb17_083643| [ 0.50986  1.58916 -0.35287]
21Feb17_083643| [-0.34599  1.27113 -0.16393]
21Feb17_083643| [ 1.29203  1.19467  0.37695]
21Feb17_083643| [ 0.58704  0.06328 -0.24240]
21Feb17_083643| [-0.93888 -0.89760  0.57087]
21Feb17_083643| [ 0.99159 -0.66387  0.35177]
21Feb17_083643| [-0.67119  1.06910 -0.12512]
21Feb17_083643| [-0.91534  1.23744 -0.40465]
21Feb17_083643| [ 1.39278  0.08069  0.23328]
21Feb17_083643| [ 0.09880  0.57603 -0.96101]
21Feb17_083643| [ 0.01621 -0.13343 -0.27624]
21Feb17_083643| [-1.28286 -2.28909  0.37931]
21Feb17_083643| [-0.28370  0.09336  0.01547]
21Feb17_083643| [-0.51894  1.84280 -0.25906]
21Feb17_083643| [-0.83075 -0.04508  0.12107]
21Feb17_083643| [ 0.37343  1.18436 -0.07358]
21Feb17_083643| [-2.38657 -0.35191  0.01962]
21Feb17_083643| [ 0.95757 -0.91760 -0.08971]
21Feb17_083643| [ 0.38792 -0.01880  0.69717]
21Feb17_083643| [ 1.66877 -0.58078 -1.21129]
21Feb17_083643| [-0.50943  0.59080  0.30856]
21Feb17_083643| [ 0.30163  1.11518  0.98185]
21Feb17_083643| [-0.73226  0.32281 -0.66712]
21Feb17_083643| [-0.62054 -2.21049  1.40981]
21Feb17_083643| [ 1.23185 -0.58090  0.35844]
21Feb17_083643| [-0.05616  0.24219 -0.02853]
21Feb17_083643| [-1.05085 -2.30259 -0.16276]
21Feb17_083643| [ 0.71087  0.14900  1.13430]
21Feb17_083643| [-2.45877 -1.20999 -1.04986]
21Feb17_083643| [-1.00480  1.36344 -0.13998]
21Feb17_083643| [ 1.83140 -0.91532  0.07616]
21Feb17_083643| [-0.60404 -2.05184  0.76948]
21Feb17_083643| [ 0.52617  0.76042 -1.76746]
21Feb17_083643| [-0.22134  0.17324  0.99530]
21Feb17_083643| [-0.36427  1.34655  0.02110]
21Feb17_083643| [-0.93125 -0.33620 -0.25012]
21Feb17_083643| [-2.76428  0.14487  0.48096]
21Feb17_083643| [-0.10518  0.35052  1.71840]
21Feb17_083643| [-1.27998  1.12568  1.26523]
21Feb17_083643| [-0.60698  1.53230 -0.60824]
21Feb17_083643| [ 0.02898  2.98718 -0.59153]
21Feb17_083643| [ 0.17588 -0.00449  0.50797]
21Feb17_083643| [-1.42674 -0.54967 -0.21310]
21Feb17_083643| [ 1.03196  1.18733  0.36755]
21Feb17_083643| [ 1.04748 -1.47444 -0.08469]
21Feb17_083643| [ 0.49410  0.38745  0.68469]
21Feb17_083643| [-0.62880  0.73245  0.19964]]
21Feb17_083643|-- Bias --
21Feb17_083643|[-0.18798  0.64571 -0.23142]
21Feb17_083643|Layer 1:
21Feb17_083643|-- Config --
21Feb17_083643|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083643|-- Weights --
21Feb17_083643|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_083643| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_083643| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_083643|-- Bias --
21Feb17_083643|[0.60477 0.03773 0.26452 0.12222]
21Feb17_083643|Layer 2:
21Feb17_083643|-- Config --
21Feb17_083643|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083643|-- Weights --
21Feb17_083643|[[ 0.67920  0.12119]
21Feb17_083643| [ 0.44836  0.02916]
21Feb17_083643| [ 0.68939  0.31516]
21Feb17_083643| [-0.58995 -0.05861]]
21Feb17_083643|-- Bias --
21Feb17_083643|[ 0.59649 -0.08079]
21Feb17_083643|Layer 3:
21Feb17_083643|-- Config --
21Feb17_083643|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083643|-- Weights --
21Feb17_083643|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_083643| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_083643|-- Bias --
21Feb17_083643|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_083643|Layer 4:
21Feb17_083643|-- Config --
21Feb17_083643|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083643|-- Weights --
21Feb17_083643|[[-0.03514 -1.04833]
21Feb17_083643| [ 1.25238  0.62094]
21Feb17_083643| [ 0.99203  0.37406]
21Feb17_083643| [ 0.49902  0.67158]
21Feb17_083643| [-1.35709  0.38335]]
21Feb17_083643|-- Bias --
21Feb17_083643|[0.31435 0.36299]
21Feb17_083643|Predicting the validation and test data with the Best final individual.
21Feb17_083651| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_083651|-----------  ------------------  --------------------  ----------
21Feb17_083651|Validation         23.65                  56            0.85845
21Feb17_083651|   Test            26.67                  56            0.71298
21Feb17_083651|-------------------- Test #11 --------------------
21Feb17_083651|Best final individual weights
21Feb17_083651|Individual:
21Feb17_083651|-- Constant hidden layers --
21Feb17_083651|False
21Feb17_083651|Layer 0:
21Feb17_083651|-- Config --
21Feb17_083651|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083651|-- Weights --
21Feb17_083651|[[-0.73212  1.32861  0.10200]
21Feb17_083651| [ 1.48746 -2.97273 -0.42944]
21Feb17_083651| [ 0.53095 -1.50623  0.79224]
21Feb17_083651| [-1.07292 -0.83175 -0.90105]
21Feb17_083651| [-0.48696 -0.89325  0.27226]
21Feb17_083651| [-3.02511  0.34155 -0.03837]
21Feb17_083651| [-0.76747  0.57140 -0.46892]
21Feb17_083651| [-0.07581  0.14713  0.85910]
21Feb17_083651| [-1.37488  0.52170 -0.36205]
21Feb17_083651| [ 1.60981 -0.08727 -0.11267]
21Feb17_083651| [ 0.50986  1.58916 -0.35287]
21Feb17_083651| [-0.34599  1.27113 -0.16393]
21Feb17_083651| [ 1.29203  1.19467  0.37695]
21Feb17_083651| [ 0.58704  0.06328 -0.24240]
21Feb17_083651| [-0.93888 -0.89760  0.57087]
21Feb17_083651| [ 0.99159 -0.66387  0.35177]
21Feb17_083651| [-0.67119  1.06910 -0.12512]
21Feb17_083651| [-0.91534  1.23744 -0.40465]
21Feb17_083651| [ 1.39278  0.08069  0.23328]
21Feb17_083651| [ 0.09880  0.57603 -0.96101]
21Feb17_083651| [ 0.01621 -0.13343 -0.27624]
21Feb17_083651| [-1.28286 -2.28909  0.37931]
21Feb17_083651| [-0.28370  0.09336  0.01547]
21Feb17_083651| [-0.51894  1.84280 -0.25906]
21Feb17_083651| [-0.83075 -0.04508  0.12107]
21Feb17_083651| [ 0.37343  1.18436 -0.07358]
21Feb17_083651| [-2.38657 -0.35191  0.01962]
21Feb17_083651| [ 0.95757 -0.91760 -0.08971]
21Feb17_083651| [ 0.38792 -0.01880  0.69717]
21Feb17_083651| [ 1.66877 -0.58078 -1.21129]
21Feb17_083651| [-0.50943  0.59080  0.30856]
21Feb17_083651| [ 0.30163  1.11518  0.98185]
21Feb17_083651| [-0.73226  0.32281 -0.66712]
21Feb17_083651| [-0.62054 -2.21049  1.40981]
21Feb17_083651| [ 1.23185 -0.58090  0.35844]
21Feb17_083651| [-0.05616  0.24219 -0.02853]
21Feb17_083651| [-1.05085 -2.30259 -0.16276]
21Feb17_083651| [ 0.71087  0.14900  1.13430]
21Feb17_083651| [-2.45877 -1.20999 -1.04986]
21Feb17_083651| [-1.00480  1.36344 -0.13998]
21Feb17_083651| [ 1.83140 -0.91532  0.07616]
21Feb17_083651| [-0.60404 -2.05184  0.76948]
21Feb17_083651| [ 0.52617  0.76042 -1.76746]
21Feb17_083651| [-0.22134  0.17324  0.99530]
21Feb17_083651| [-0.36427  1.34655  0.02110]
21Feb17_083651| [-0.93125 -0.33620 -0.25012]
21Feb17_083651| [-2.76428  0.14487  0.48096]
21Feb17_083651| [-0.10518  0.35052  1.71840]
21Feb17_083651| [-1.27998  1.12568  1.26523]
21Feb17_083651| [-0.60698  1.53230 -0.60824]
21Feb17_083651| [ 0.02898  2.98718 -0.59153]
21Feb17_083651| [ 0.17588 -0.00449  0.50797]
21Feb17_083651| [-1.42674 -0.54967 -0.21310]
21Feb17_083651| [ 1.03196  1.18733  0.36755]
21Feb17_083651| [ 1.04748 -1.47444 -0.08469]
21Feb17_083651| [ 0.49410  0.38745  0.68469]
21Feb17_083651| [-0.62880  0.73245  0.19964]]
21Feb17_083651|-- Bias --
21Feb17_083651|[-0.18798  0.64571 -0.23142]
21Feb17_083651|Layer 1:
21Feb17_083651|-- Config --
21Feb17_083651|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083651|-- Weights --
21Feb17_083651|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_083651| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_083651| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_083651|-- Bias --
21Feb17_083651|[0.60477 0.03773 0.26452 0.12222]
21Feb17_083651|Layer 2:
21Feb17_083651|-- Config --
21Feb17_083651|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083651|-- Weights --
21Feb17_083651|[[ 0.67920  0.12119]
21Feb17_083651| [ 0.44836  0.02916]
21Feb17_083651| [ 0.68939  0.31516]
21Feb17_083651| [-0.58995 -0.05861]]
21Feb17_083651|-- Bias --
21Feb17_083651|[ 0.59649 -0.08079]
21Feb17_083651|Layer 3:
21Feb17_083651|-- Config --
21Feb17_083651|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083651|-- Weights --
21Feb17_083651|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_083651| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_083651|-- Bias --
21Feb17_083651|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_083651|Layer 4:
21Feb17_083651|-- Config --
21Feb17_083651|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083651|-- Weights --
21Feb17_083651|[[-0.03514 -1.04833]
21Feb17_083651| [ 1.25238  0.62094]
21Feb17_083651| [ 0.99203  0.37406]
21Feb17_083651| [ 0.49902  0.67158]
21Feb17_083651| [-1.35709  0.38335]]
21Feb17_083651|-- Bias --
21Feb17_083651|[0.31435 0.36299]
21Feb17_083651|Predicting the validation and test data with the Best final individual.
21Feb17_083659| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_083659|-----------  ------------------  --------------------  ----------
21Feb17_083659|Validation         23.48                  56            0.78306
21Feb17_083659|   Test            22.07                  56            0.85403
21Feb17_083659|-------------------- Test #12 --------------------
21Feb17_083659|Best final individual weights
21Feb17_083659|Individual:
21Feb17_083659|-- Constant hidden layers --
21Feb17_083659|False
21Feb17_083659|Layer 0:
21Feb17_083659|-- Config --
21Feb17_083659|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083659|-- Weights --
21Feb17_083659|[[-0.73212  1.32861  0.10200]
21Feb17_083659| [ 1.48746 -2.97273 -0.42944]
21Feb17_083659| [ 0.53095 -1.50623  0.79224]
21Feb17_083659| [-1.07292 -0.83175 -0.90105]
21Feb17_083659| [-0.48696 -0.89325  0.27226]
21Feb17_083659| [-3.02511  0.34155 -0.03837]
21Feb17_083659| [-0.76747  0.57140 -0.46892]
21Feb17_083659| [-0.07581  0.14713  0.85910]
21Feb17_083659| [-1.37488  0.52170 -0.36205]
21Feb17_083659| [ 1.60981 -0.08727 -0.11267]
21Feb17_083659| [ 0.50986  1.58916 -0.35287]
21Feb17_083659| [-0.34599  1.27113 -0.16393]
21Feb17_083659| [ 1.29203  1.19467  0.37695]
21Feb17_083659| [ 0.58704  0.06328 -0.24240]
21Feb17_083659| [-0.93888 -0.89760  0.57087]
21Feb17_083659| [ 0.99159 -0.66387  0.35177]
21Feb17_083659| [-0.67119  1.06910 -0.12512]
21Feb17_083659| [-0.91534  1.23744 -0.40465]
21Feb17_083659| [ 1.39278  0.08069  0.23328]
21Feb17_083659| [ 0.09880  0.57603 -0.96101]
21Feb17_083659| [ 0.01621 -0.13343 -0.27624]
21Feb17_083659| [-1.28286 -2.28909  0.37931]
21Feb17_083659| [-0.28370  0.09336  0.01547]
21Feb17_083659| [-0.51894  1.84280 -0.25906]
21Feb17_083659| [-0.83075 -0.04508  0.12107]
21Feb17_083659| [ 0.37343  1.18436 -0.07358]
21Feb17_083659| [-2.38657 -0.35191  0.01962]
21Feb17_083659| [ 0.95757 -0.91760 -0.08971]
21Feb17_083659| [ 0.38792 -0.01880  0.69717]
21Feb17_083659| [ 1.66877 -0.58078 -1.21129]
21Feb17_083659| [-0.50943  0.59080  0.30856]
21Feb17_083659| [ 0.30163  1.11518  0.98185]
21Feb17_083659| [-0.73226  0.32281 -0.66712]
21Feb17_083659| [-0.62054 -2.21049  1.40981]
21Feb17_083659| [ 1.23185 -0.58090  0.35844]
21Feb17_083659| [-0.05616  0.24219 -0.02853]
21Feb17_083659| [-1.05085 -2.30259 -0.16276]
21Feb17_083659| [ 0.71087  0.14900  1.13430]
21Feb17_083659| [-2.45877 -1.20999 -1.04986]
21Feb17_083659| [-1.00480  1.36344 -0.13998]
21Feb17_083659| [ 1.83140 -0.91532  0.07616]
21Feb17_083659| [-0.60404 -2.05184  0.76948]
21Feb17_083659| [ 0.52617  0.76042 -1.76746]
21Feb17_083659| [-0.22134  0.17324  0.99530]
21Feb17_083659| [-0.36427  1.34655  0.02110]
21Feb17_083659| [-0.93125 -0.33620 -0.25012]
21Feb17_083659| [-2.76428  0.14487  0.48096]
21Feb17_083659| [-0.10518  0.35052  1.71840]
21Feb17_083659| [-1.27998  1.12568  1.26523]
21Feb17_083659| [-0.60698  1.53230 -0.60824]
21Feb17_083659| [ 0.02898  2.98718 -0.59153]
21Feb17_083659| [ 0.17588 -0.00449  0.50797]
21Feb17_083659| [-1.42674 -0.54967 -0.21310]
21Feb17_083659| [ 1.03196  1.18733  0.36755]
21Feb17_083659| [ 1.04748 -1.47444 -0.08469]
21Feb17_083659| [ 0.49410  0.38745  0.68469]
21Feb17_083659| [-0.62880  0.73245  0.19964]]
21Feb17_083659|-- Bias --
21Feb17_083659|[-0.18798  0.64571 -0.23142]
21Feb17_083659|Layer 1:
21Feb17_083659|-- Config --
21Feb17_083659|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083659|-- Weights --
21Feb17_083659|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_083659| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_083659| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_083659|-- Bias --
21Feb17_083659|[0.60477 0.03773 0.26452 0.12222]
21Feb17_083659|Layer 2:
21Feb17_083659|-- Config --
21Feb17_083659|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083659|-- Weights --
21Feb17_083659|[[ 0.67920  0.12119]
21Feb17_083659| [ 0.44836  0.02916]
21Feb17_083659| [ 0.68939  0.31516]
21Feb17_083659| [-0.58995 -0.05861]]
21Feb17_083659|-- Bias --
21Feb17_083659|[ 0.59649 -0.08079]
21Feb17_083659|Layer 3:
21Feb17_083659|-- Config --
21Feb17_083659|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083659|-- Weights --
21Feb17_083659|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_083659| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_083659|-- Bias --
21Feb17_083659|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_083659|Layer 4:
21Feb17_083659|-- Config --
21Feb17_083659|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083659|-- Weights --
21Feb17_083659|[[-0.03514 -1.04833]
21Feb17_083659| [ 1.25238  0.62094]
21Feb17_083659| [ 0.99203  0.37406]
21Feb17_083659| [ 0.49902  0.67158]
21Feb17_083659| [-1.35709  0.38335]]
21Feb17_083659|-- Bias --
21Feb17_083659|[0.31435 0.36299]
21Feb17_083659|Predicting the validation and test data with the Best final individual.
21Feb17_083706| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_083706|-----------  ------------------  --------------------  ----------
21Feb17_083706|Validation         24.43                  56            0.85301
21Feb17_083706|   Test            37.01                  56            0.82036
21Feb17_083706|-------------------- Test #13 --------------------
21Feb17_083706|Best final individual weights
21Feb17_083706|Individual:
21Feb17_083706|-- Constant hidden layers --
21Feb17_083706|False
21Feb17_083706|Layer 0:
21Feb17_083706|-- Config --
21Feb17_083706|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083706|-- Weights --
21Feb17_083706|[[-0.73212  1.32861  0.10200]
21Feb17_083706| [ 1.48746 -2.97273 -0.42944]
21Feb17_083706| [ 0.53095 -1.50623  0.79224]
21Feb17_083706| [-1.07292 -0.83175 -0.90105]
21Feb17_083706| [-0.48696 -0.89325  0.27226]
21Feb17_083706| [-3.02511  0.34155 -0.03837]
21Feb17_083706| [-0.76747  0.57140 -0.46892]
21Feb17_083706| [-0.07581  0.14713  0.85910]
21Feb17_083706| [-1.37488  0.52170 -0.36205]
21Feb17_083706| [ 1.60981 -0.08727 -0.11267]
21Feb17_083706| [ 0.50986  1.58916 -0.35287]
21Feb17_083706| [-0.34599  1.27113 -0.16393]
21Feb17_083706| [ 1.29203  1.19467  0.37695]
21Feb17_083706| [ 0.58704  0.06328 -0.24240]
21Feb17_083706| [-0.93888 -0.89760  0.57087]
21Feb17_083706| [ 0.99159 -0.66387  0.35177]
21Feb17_083706| [-0.67119  1.06910 -0.12512]
21Feb17_083706| [-0.91534  1.23744 -0.40465]
21Feb17_083706| [ 1.39278  0.08069  0.23328]
21Feb17_083706| [ 0.09880  0.57603 -0.96101]
21Feb17_083706| [ 0.01621 -0.13343 -0.27624]
21Feb17_083706| [-1.28286 -2.28909  0.37931]
21Feb17_083706| [-0.28370  0.09336  0.01547]
21Feb17_083706| [-0.51894  1.84280 -0.25906]
21Feb17_083706| [-0.83075 -0.04508  0.12107]
21Feb17_083706| [ 0.37343  1.18436 -0.07358]
21Feb17_083706| [-2.38657 -0.35191  0.01962]
21Feb17_083706| [ 0.95757 -0.91760 -0.08971]
21Feb17_083706| [ 0.38792 -0.01880  0.69717]
21Feb17_083706| [ 1.66877 -0.58078 -1.21129]
21Feb17_083706| [-0.50943  0.59080  0.30856]
21Feb17_083706| [ 0.30163  1.11518  0.98185]
21Feb17_083706| [-0.73226  0.32281 -0.66712]
21Feb17_083706| [-0.62054 -2.21049  1.40981]
21Feb17_083706| [ 1.23185 -0.58090  0.35844]
21Feb17_083706| [-0.05616  0.24219 -0.02853]
21Feb17_083706| [-1.05085 -2.30259 -0.16276]
21Feb17_083706| [ 0.71087  0.14900  1.13430]
21Feb17_083706| [-2.45877 -1.20999 -1.04986]
21Feb17_083706| [-1.00480  1.36344 -0.13998]
21Feb17_083706| [ 1.83140 -0.91532  0.07616]
21Feb17_083706| [-0.60404 -2.05184  0.76948]
21Feb17_083706| [ 0.52617  0.76042 -1.76746]
21Feb17_083706| [-0.22134  0.17324  0.99530]
21Feb17_083706| [-0.36427  1.34655  0.02110]
21Feb17_083706| [-0.93125 -0.33620 -0.25012]
21Feb17_083706| [-2.76428  0.14487  0.48096]
21Feb17_083706| [-0.10518  0.35052  1.71840]
21Feb17_083706| [-1.27998  1.12568  1.26523]
21Feb17_083706| [-0.60698  1.53230 -0.60824]
21Feb17_083706| [ 0.02898  2.98718 -0.59153]
21Feb17_083706| [ 0.17588 -0.00449  0.50797]
21Feb17_083706| [-1.42674 -0.54967 -0.21310]
21Feb17_083706| [ 1.03196  1.18733  0.36755]
21Feb17_083706| [ 1.04748 -1.47444 -0.08469]
21Feb17_083706| [ 0.49410  0.38745  0.68469]
21Feb17_083706| [-0.62880  0.73245  0.19964]]
21Feb17_083706|-- Bias --
21Feb17_083706|[-0.18798  0.64571 -0.23142]
21Feb17_083706|Layer 1:
21Feb17_083706|-- Config --
21Feb17_083706|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083706|-- Weights --
21Feb17_083706|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_083706| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_083706| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_083706|-- Bias --
21Feb17_083706|[0.60477 0.03773 0.26452 0.12222]
21Feb17_083706|Layer 2:
21Feb17_083706|-- Config --
21Feb17_083706|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083706|-- Weights --
21Feb17_083706|[[ 0.67920  0.12119]
21Feb17_083706| [ 0.44836  0.02916]
21Feb17_083706| [ 0.68939  0.31516]
21Feb17_083706| [-0.58995 -0.05861]]
21Feb17_083706|-- Bias --
21Feb17_083706|[ 0.59649 -0.08079]
21Feb17_083706|Layer 3:
21Feb17_083706|-- Config --
21Feb17_083706|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083706|-- Weights --
21Feb17_083706|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_083706| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_083706|-- Bias --
21Feb17_083706|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_083706|Layer 4:
21Feb17_083706|-- Config --
21Feb17_083706|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083706|-- Weights --
21Feb17_083706|[[-0.03514 -1.04833]
21Feb17_083706| [ 1.25238  0.62094]
21Feb17_083706| [ 0.99203  0.37406]
21Feb17_083706| [ 0.49902  0.67158]
21Feb17_083706| [-1.35709  0.38335]]
21Feb17_083706|-- Bias --
21Feb17_083706|[0.31435 0.36299]
21Feb17_083706|Predicting the validation and test data with the Best final individual.
21Feb17_083714| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_083714|-----------  ------------------  --------------------  ----------
21Feb17_083714|Validation         21.74                  56            0.74120
21Feb17_083714|   Test            25.80                  56            0.72926
21Feb17_083714|-------------------- Test #14 --------------------
21Feb17_083714|Best final individual weights
21Feb17_083714|Individual:
21Feb17_083714|-- Constant hidden layers --
21Feb17_083714|False
21Feb17_083714|Layer 0:
21Feb17_083714|-- Config --
21Feb17_083714|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083714|-- Weights --
21Feb17_083714|[[-0.73212  1.32861  0.10200]
21Feb17_083714| [ 1.48746 -2.97273 -0.42944]
21Feb17_083714| [ 0.53095 -1.50623  0.79224]
21Feb17_083714| [-1.07292 -0.83175 -0.90105]
21Feb17_083714| [-0.48696 -0.89325  0.27226]
21Feb17_083714| [-3.02511  0.34155 -0.03837]
21Feb17_083714| [-0.76747  0.57140 -0.46892]
21Feb17_083714| [-0.07581  0.14713  0.85910]
21Feb17_083714| [-1.37488  0.52170 -0.36205]
21Feb17_083714| [ 1.60981 -0.08727 -0.11267]
21Feb17_083714| [ 0.50986  1.58916 -0.35287]
21Feb17_083714| [-0.34599  1.27113 -0.16393]
21Feb17_083714| [ 1.29203  1.19467  0.37695]
21Feb17_083714| [ 0.58704  0.06328 -0.24240]
21Feb17_083714| [-0.93888 -0.89760  0.57087]
21Feb17_083714| [ 0.99159 -0.66387  0.35177]
21Feb17_083714| [-0.67119  1.06910 -0.12512]
21Feb17_083714| [-0.91534  1.23744 -0.40465]
21Feb17_083714| [ 1.39278  0.08069  0.23328]
21Feb17_083714| [ 0.09880  0.57603 -0.96101]
21Feb17_083714| [ 0.01621 -0.13343 -0.27624]
21Feb17_083714| [-1.28286 -2.28909  0.37931]
21Feb17_083714| [-0.28370  0.09336  0.01547]
21Feb17_083714| [-0.51894  1.84280 -0.25906]
21Feb17_083714| [-0.83075 -0.04508  0.12107]
21Feb17_083714| [ 0.37343  1.18436 -0.07358]
21Feb17_083714| [-2.38657 -0.35191  0.01962]
21Feb17_083714| [ 0.95757 -0.91760 -0.08971]
21Feb17_083714| [ 0.38792 -0.01880  0.69717]
21Feb17_083714| [ 1.66877 -0.58078 -1.21129]
21Feb17_083714| [-0.50943  0.59080  0.30856]
21Feb17_083714| [ 0.30163  1.11518  0.98185]
21Feb17_083714| [-0.73226  0.32281 -0.66712]
21Feb17_083714| [-0.62054 -2.21049  1.40981]
21Feb17_083714| [ 1.23185 -0.58090  0.35844]
21Feb17_083714| [-0.05616  0.24219 -0.02853]
21Feb17_083714| [-1.05085 -2.30259 -0.16276]
21Feb17_083714| [ 0.71087  0.14900  1.13430]
21Feb17_083714| [-2.45877 -1.20999 -1.04986]
21Feb17_083714| [-1.00480  1.36344 -0.13998]
21Feb17_083714| [ 1.83140 -0.91532  0.07616]
21Feb17_083714| [-0.60404 -2.05184  0.76948]
21Feb17_083714| [ 0.52617  0.76042 -1.76746]
21Feb17_083714| [-0.22134  0.17324  0.99530]
21Feb17_083714| [-0.36427  1.34655  0.02110]
21Feb17_083714| [-0.93125 -0.33620 -0.25012]
21Feb17_083714| [-2.76428  0.14487  0.48096]
21Feb17_083714| [-0.10518  0.35052  1.71840]
21Feb17_083714| [-1.27998  1.12568  1.26523]
21Feb17_083714| [-0.60698  1.53230 -0.60824]
21Feb17_083714| [ 0.02898  2.98718 -0.59153]
21Feb17_083714| [ 0.17588 -0.00449  0.50797]
21Feb17_083714| [-1.42674 -0.54967 -0.21310]
21Feb17_083714| [ 1.03196  1.18733  0.36755]
21Feb17_083714| [ 1.04748 -1.47444 -0.08469]
21Feb17_083714| [ 0.49410  0.38745  0.68469]
21Feb17_083714| [-0.62880  0.73245  0.19964]]
21Feb17_083714|-- Bias --
21Feb17_083714|[-0.18798  0.64571 -0.23142]
21Feb17_083714|Layer 1:
21Feb17_083714|-- Config --
21Feb17_083714|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083714|-- Weights --
21Feb17_083714|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_083714| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_083714| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_083714|-- Bias --
21Feb17_083714|[0.60477 0.03773 0.26452 0.12222]
21Feb17_083714|Layer 2:
21Feb17_083714|-- Config --
21Feb17_083714|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083714|-- Weights --
21Feb17_083714|[[ 0.67920  0.12119]
21Feb17_083714| [ 0.44836  0.02916]
21Feb17_083714| [ 0.68939  0.31516]
21Feb17_083714| [-0.58995 -0.05861]]
21Feb17_083714|-- Bias --
21Feb17_083714|[ 0.59649 -0.08079]
21Feb17_083714|Layer 3:
21Feb17_083714|-- Config --
21Feb17_083714|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083714|-- Weights --
21Feb17_083714|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_083714| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_083714|-- Bias --
21Feb17_083714|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_083714|Layer 4:
21Feb17_083714|-- Config --
21Feb17_083714|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_083714|-- Weights --
21Feb17_083714|[[-0.03514 -1.04833]
21Feb17_083714| [ 1.25238  0.62094]
21Feb17_083714| [ 0.99203  0.37406]
21Feb17_083714| [ 0.49902  0.67158]
21Feb17_083714| [-1.35709  0.38335]]
21Feb17_083714|-- Bias --
21Feb17_083714|[0.31435 0.36299]
21Feb17_083714|Predicting the validation and test data with the Best final individual.
21Feb17_083722| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_083722|-----------  ------------------  --------------------  ----------
21Feb17_083722|Validation         22.70                  56            0.74363
21Feb17_083722|   Test            19.46                  56            0.73101
Using Theano backend.
WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.
2021-02-17 08:37:24.763207: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-02-17 08:37:24.763264: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
21Feb17_083725|Data summary: Train
21Feb17_083725|data.shape = (2300, 57)
21Feb17_083725|labels.shape = (2300,)
21Feb17_083725|Class distribution:
21Feb17_083725|	0 - 1389 (0.60)
21Feb17_083725|	1 - 911 (0.40)
21Feb17_083725|Data summary: Validation
21Feb17_083725|data.shape = (1150, 57)
21Feb17_083725|labels.shape = (1150,)
21Feb17_083725|Class distribution:
21Feb17_083725|	0 - 667 (0.58)
21Feb17_083725|	1 - 483 (0.42)
21Feb17_083725|Data summary: Test
21Feb17_083725|data.shape = (1151, 57)
21Feb17_083725|labels.shape = (1151,)
21Feb17_083725|Class distribution:
21Feb17_083725|	0 - 732 (0.64)
21Feb17_083725|	1 - 419 (0.36)
21Feb17_083725|Selected configuration values
21Feb17_083725|-- Dataset name: spambase2
21Feb17_083725|-- Initial population size: 64
21Feb17_083725|-- Maximun number of generations: 32
21Feb17_083725|-- Neurons per hidden layer range: (2, 20)
21Feb17_083725|-- Hidden layers number range: (1, 3)
21Feb17_083725|-- Crossover probability: 0.5
21Feb17_083725|-- Bias gene mutation probability: 0.2
21Feb17_083725|-- Weights gene mutation probability: 0.75
21Feb17_083725|-- Neuron mutation probability: 0.3
21Feb17_083725|-- Layer mutation probability: 0.3
21Feb17_083725|-- Constant hidden layers: False
21Feb17_083725|-- Seed: 31415
21Feb17_083725|Entering GA
21Feb17_083725|Start the algorithm
21Feb17_084108|-- Generation 1 --
21Feb17_084108|    -- Crossed 0 individual pairs.
21Feb17_084108|    -- Mutated 32 individuals.
21Feb17_084428|    -- Evaluated 64 individuals.
21Feb17_084428|    Summary of generation 1:
21Feb17_084428| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_084428|-----------  ------------------  --------------------  ----------
21Feb17_084428|    Max            42.70                78.00           0.43478
21Feb17_084428|    Avg            41.90                26.28           0.00941
21Feb17_084428|    Min            35.91                 2.00           0.00000
21Feb17_084428|    Std             0.81                18.75           0.05509
21Feb17_084428|   Best            35.91                18.00           0.43478
21Feb17_084428|-- Generation 2 --
21Feb17_084428|    -- Crossed 1 individual pairs.
21Feb17_084428|    -- Mutated 32 individuals.
21Feb17_084742|    -- Evaluated 64 individuals.
21Feb17_084742|    Summary of generation 2:
21Feb17_084742| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_084742|-----------  ------------------  --------------------  ----------
21Feb17_084742|    Max            58.00                84.00           0.79977
21Feb17_084742|    Avg            41.99                15.92           0.02879
21Feb17_084742|    Min            29.65                 2.00           0.00000
21Feb17_084742|    Std             2.55                13.60           0.13781
21Feb17_084742|   Best            29.65                18.00           0.79977
21Feb17_084742|-- Generation 3 --
21Feb17_084742|    -- Crossed 3 individual pairs.
21Feb17_084742|    -- Mutated 32 individuals.
21Feb17_085057|    -- Evaluated 64 individuals.
21Feb17_085057|    Summary of generation 3:
21Feb17_085057| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_085057|-----------  ------------------  --------------------  ----------
21Feb17_085057|    Max            58.00                50.00           0.78358
21Feb17_085057|    Avg            41.97                13.73           0.02564
21Feb17_085057|    Min            26.09                 2.00           0.00000
21Feb17_085057|    Std             2.83                12.88           0.13211
21Feb17_085057|   Best            26.09                18.00           0.73476
21Feb17_085057|-- Generation 4 --
21Feb17_085057|    -- Crossed 4 individual pairs.
21Feb17_085057|    -- Mutated 32 individuals.
21Feb17_085409|    -- Evaluated 64 individuals.
21Feb17_085409|    Summary of generation 4:
21Feb17_085409| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_085409|-----------  ------------------  --------------------  ----------
21Feb17_085409|    Max            42.17                63.00           0.00517
21Feb17_085409|    Avg            42.01                 8.34           0.00085
21Feb17_085409|    Min            41.91                 2.00           0.00000
21Feb17_085409|    Std             0.06                 9.60           0.00165
21Feb17_085409|   Best            41.91                 4.00           0.00517
21Feb17_085409|-- Generation 5 --
21Feb17_085409|    -- Crossed 6 individual pairs.
21Feb17_085409|    -- Mutated 32 individuals.
21Feb17_085718|    -- Evaluated 64 individuals.
21Feb17_085718|    Summary of generation 5:
21Feb17_085718| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_085718|-----------  ------------------  --------------------  ----------
21Feb17_085718|    Max            42.09                20.00           0.05344
21Feb17_085718|    Avg            41.98                 5.28           0.00172
21Feb17_085718|    Min            41.22                 2.00           0.00000
21Feb17_085718|    Std             0.11                 4.46           0.00681
21Feb17_085718|   Best            41.22                14.00           0.05344
21Feb17_085718|-- Generation 6 --
21Feb17_085718|    -- Crossed 7 individual pairs.
21Feb17_085718|    -- Mutated 32 individuals.
21Feb17_090030|    -- Evaluated 64 individuals.
21Feb17_090030|    Summary of generation 6:
21Feb17_090030| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_090030|-----------  ------------------  --------------------  ----------
21Feb17_090030|    Max            42.26                18.00           0.01548
21Feb17_090030|    Avg            41.99                 6.00           0.00105
21Feb17_090030|    Min            41.48                 2.00           0.00000
21Feb17_090030|    Std             0.09                 4.81           0.00231
21Feb17_090030|   Best            41.48                 3.00           0.01548
21Feb17_090030|-- Generation 7 --
21Feb17_090030|    -- Crossed 9 individual pairs.
21Feb17_090030|    -- Mutated 32 individuals.
21Feb17_090340|    -- Evaluated 64 individuals.
21Feb17_090340|    Summary of generation 7:
21Feb17_090340| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_090340|-----------  ------------------  --------------------  ----------
21Feb17_090340|    Max            42.09                36.00           0.01033
21Feb17_090340|    Avg            41.99                 5.98           0.00089
21Feb17_090340|    Min            41.65                 2.00           0.00000
21Feb17_090340|    Std             0.06                 6.14           0.00184
21Feb17_090340|   Best            41.65                 3.00           0.01033
21Feb17_090340|-- Generation 8 --
21Feb17_090340|    -- Crossed 9 individual pairs.
21Feb17_090340|    -- Mutated 32 individuals.
21Feb17_090648|    -- Evaluated 64 individuals.
21Feb17_090648|    Summary of generation 8:
21Feb17_090648| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_090648|-----------  ------------------  --------------------  ----------
21Feb17_090648|    Max            42.17                18.00           0.04103
21Feb17_090648|    Avg            41.97                 5.09           0.00169
21Feb17_090648|    Min            40.78                 2.00           0.00000
21Feb17_090648|    Std             0.16                 4.37           0.00529
21Feb17_090648|   Best            40.78                12.00           0.04103
21Feb17_090648|-- Generation 9 --
21Feb17_090648|    -- Crossed 8 individual pairs.
21Feb17_090648|    -- Mutated 32 individuals.
21Feb17_091000|    -- Evaluated 64 individuals.
21Feb17_091000|    Summary of generation 9:
21Feb17_091000| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_091000|-----------  ------------------  --------------------  ----------
21Feb17_091000|    Max            48.87                18.00           0.80667
21Feb17_091000|    Avg            41.71                 6.17           0.03823
21Feb17_091000|    Min            30.61                 2.00           0.00000
21Feb17_091000|    Std             2.17                 5.04           0.16210
21Feb17_091000|   Best            30.61                 8.00           0.78607
21Feb17_091000|-- Generation 10 --
21Feb17_091000|    -- Crossed 5 individual pairs.
21Feb17_091000|    -- Mutated 32 individuals.
21Feb17_091309|    -- Evaluated 64 individuals.
21Feb17_091309|    Summary of generation 10:
21Feb17_091309| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_091309|-----------  ------------------  --------------------  ----------
21Feb17_091309|    Max            42.26                18.00           0.58344
21Feb17_091309|    Avg            41.43                 6.23           0.02714
21Feb17_091309|    Min            27.74                 2.00           0.00000
21Feb17_091309|    Std             2.43                 4.89           0.10887
21Feb17_091309|   Best            27.74                18.00           0.51616
21Feb17_091309|-- Generation 11 --
21Feb17_091309|    -- Crossed 8 individual pairs.
21Feb17_091309|    -- Mutated 32 individuals.
21Feb17_091622|    -- Evaluated 64 individuals.
21Feb17_091622|    Summary of generation 11:
21Feb17_091622| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_091622|-----------  ------------------  --------------------  ----------
21Feb17_091622|    Max            58.00                34.00           0.78358
21Feb17_091622|    Avg            41.87                 7.95           0.03476
21Feb17_091622|    Min            28.00                 2.00           0.00000
21Feb17_091622|    Std             2.88                 6.49           0.14854
21Feb17_091622|   Best            28.00                 8.00           0.52079
21Feb17_091622|-- Generation 12 --
21Feb17_091622|    -- Crossed 3 individual pairs.
21Feb17_091622|    -- Mutated 32 individuals.
21Feb17_091933|    -- Evaluated 64 individuals.
21Feb17_091933|    Summary of generation 12:
21Feb17_091933| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_091933|-----------  ------------------  --------------------  ----------
21Feb17_091933|    Max            42.35                36.00           0.67494
21Feb17_091933|    Avg            41.46                 7.03           0.02217
21Feb17_091933|    Min            24.96                 2.00           0.00000
21Feb17_091933|    Std             2.67                 5.88           0.11025
21Feb17_091933|   Best            24.96                18.00           0.67494
21Feb17_091933|-- Generation 13 --
21Feb17_091933|    -- Crossed 5 individual pairs.
21Feb17_091933|    -- Mutated 32 individuals.
21Feb17_092245|    -- Evaluated 64 individuals.
21Feb17_092245|    Summary of generation 13:
21Feb17_092245| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_092245|-----------  ------------------  --------------------  ----------
21Feb17_092245|    Max            42.61                36.00           0.61562
21Feb17_092245|    Avg            41.50                 8.56           0.02210
21Feb17_092245|    Min            26.78                 2.00           0.00000
21Feb17_092245|    Std             2.40                 7.93           0.10577
21Feb17_092245|   Best            26.78                18.00           0.61562
21Feb17_092245|-- Generation 14 --
21Feb17_092245|    -- Crossed 7 individual pairs.
21Feb17_092245|    -- Mutated 32 individuals.
21Feb17_092559|    -- Evaluated 64 individuals.
21Feb17_092559|    Summary of generation 14:
21Feb17_092559| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_092559|-----------  ------------------  --------------------  ----------
21Feb17_092559|    Max            42.09                40.00           0.75188
21Feb17_092559|    Avg            41.48                 8.12           0.02679
21Feb17_092559|    Min            27.65                 2.00           0.00000
21Feb17_092559|    Std             2.42                 6.72           0.13015
21Feb17_092559|   Best            27.65                18.00           0.75188
21Feb17_092559|-- Generation 15 --
21Feb17_092559|    -- Crossed 6 individual pairs.
21Feb17_092559|    -- Mutated 32 individuals.
21Feb17_092911|    -- Evaluated 64 individuals.
21Feb17_092911|    Summary of generation 15:
21Feb17_092911| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_092911|-----------  ------------------  --------------------  ----------
21Feb17_092911|    Max            42.09                40.00           0.73387
21Feb17_092911|    Avg            41.42                 7.69           0.02610
21Feb17_092911|    Min            26.35                 2.00           0.00000
21Feb17_092911|    Std             2.71                 6.44           0.12590
21Feb17_092911|   Best            26.35                18.00           0.71951
21Feb17_092911|-- Generation 16 --
21Feb17_092911|    -- Crossed 5 individual pairs.
21Feb17_092911|    -- Mutated 32 individuals.
21Feb17_093225|    -- Evaluated 64 individuals.
21Feb17_093225|    Summary of generation 16:
21Feb17_093225| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_093225|-----------  ------------------  --------------------  ----------
21Feb17_093225|    Max            42.26                44.00           0.82855
21Feb17_093225|    Avg            41.21                 7.83           0.03973
21Feb17_093225|    Min            24.87                 2.00           0.00000
21Feb17_093225|    Std             3.23                 7.99           0.16234
21Feb17_093225|   Best            24.87                21.00           0.68287
21Feb17_093225|-- Generation 17 --
21Feb17_093225|    -- Crossed 8 individual pairs.
21Feb17_093225|    -- Mutated 32 individuals.
21Feb17_093541|    -- Evaluated 64 individuals.
21Feb17_093541|    Summary of generation 17:
21Feb17_093541| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_093541|-----------  ------------------  --------------------  ----------
21Feb17_093541|    Max            42.26                44.00           0.80877
21Feb17_093541|    Avg            40.86                 8.81           0.06413
21Feb17_093541|    Min            25.04                 2.00           0.00000
21Feb17_093541|    Std             3.59                 8.94           0.19340
21Feb17_093541|   Best            25.04                10.00           0.72247
21Feb17_093541|-- Generation 18 --
21Feb17_093541|    -- Crossed 2 individual pairs.
21Feb17_093541|    -- Mutated 32 individuals.
21Feb17_093859|    -- Evaluated 64 individuals.
21Feb17_093859|    Summary of generation 18:
21Feb17_093859| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_093859|-----------  ------------------  --------------------  ----------
21Feb17_093859|    Max            47.04                44.00           0.81211
21Feb17_093859|    Avg            39.55                10.78           0.12108
21Feb17_093859|    Min            24.35                 3.00           0.00000
21Feb17_093859|    Std             5.74                11.16           0.25939
21Feb17_093859|   Best            24.35                44.00           0.72485
21Feb17_093859|-- Generation 19 --
21Feb17_093859|    -- Crossed 7 individual pairs.
21Feb17_093859|    -- Mutated 32 individuals.
21Feb17_094223|    -- Evaluated 64 individuals.
21Feb17_094223|    Summary of generation 19:
21Feb17_094223| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_094223|-----------  ------------------  --------------------  ----------
21Feb17_094223|    Max            42.87                70.00           0.81774
21Feb17_094223|    Avg            39.09                14.53           0.14606
21Feb17_094223|    Min            24.70                 3.00           0.00000
21Feb17_094223|    Std             5.78                15.60           0.27609
21Feb17_094223|   Best            24.70                44.00           0.69102
21Feb17_094223|-- Generation 20 --
21Feb17_094223|    -- Crossed 3 individual pairs.
21Feb17_094223|    -- Mutated 32 individuals.
21Feb17_094551|    -- Evaluated 64 individuals.
21Feb17_094551|    Summary of generation 20:
21Feb17_094551| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_094551|-----------  ------------------  --------------------  ----------
21Feb17_094551|    Max            42.17                60.00           0.79174
21Feb17_094551|    Avg            39.05                15.47           0.15453
21Feb17_094551|    Min            24.09                 3.00           0.00000
21Feb17_094551|    Std             5.60                16.03           0.28335
21Feb17_094551|   Best            24.09                48.00           0.76568
21Feb17_094551|-- Generation 21 --
21Feb17_094551|    -- Crossed 4 individual pairs.
21Feb17_094551|    -- Mutated 32 individuals.
21Feb17_094923|    -- Evaluated 64 individuals.
21Feb17_094923|    Summary of generation 21:
21Feb17_094923| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_094923|-----------  ------------------  --------------------  ----------
21Feb17_094923|    Max            42.17                90.00           0.80579
21Feb17_094923|    Avg            38.34                18.45           0.19938
21Feb17_094923|    Min            23.91                 2.00           0.00000
21Feb17_094923|    Std             5.87                19.09           0.30554
21Feb17_094923|   Best            23.91                48.00           0.71458
21Feb17_094923|-- Generation 22 --
21Feb17_094923|    -- Crossed 2 individual pairs.
21Feb17_094923|    -- Mutated 32 individuals.
21Feb17_095300|    -- Evaluated 64 individuals.
21Feb17_095300|    Summary of generation 22:
21Feb17_095300| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_095300|-----------  ------------------  --------------------  ----------
21Feb17_095300|    Max            42.09                60.00           0.82362
21Feb17_095300|    Avg            36.71                21.28           0.25981
21Feb17_095300|    Min            24.26                 2.00           0.00000
21Feb17_095300|    Std             6.98                18.25           0.33831
21Feb17_095300|   Best            24.26                52.00           0.76087
21Feb17_095300|-- Generation 23 --
21Feb17_095300|    -- Crossed 2 individual pairs.
21Feb17_095300|    -- Mutated 32 individuals.
21Feb17_095647|    -- Evaluated 64 individuals.
21Feb17_095647|    Summary of generation 23:
21Feb17_095647| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_095647|-----------  ------------------  --------------------  ----------
21Feb17_095647|    Max            42.09                96.00           0.78772
21Feb17_095647|    Avg            35.35                29.28           0.32114
21Feb17_095647|    Min            23.39                 2.00           0.00000
21Feb17_095647|    Std             7.15                21.95           0.34435
21Feb17_095647|   Best            23.39                52.00           0.72814
21Feb17_095647|-- Generation 24 --
21Feb17_095647|    -- Crossed 0 individual pairs.
21Feb17_095647|    -- Mutated 32 individuals.
21Feb17_100045|    -- Evaluated 64 individuals.
21Feb17_100045|    Summary of generation 24:
21Feb17_100045| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_100045|-----------  ------------------  --------------------  ----------
21Feb17_100045|    Max            43.30                80.00           0.82075
21Feb17_100045|    Avg            33.81                36.61           0.38588
21Feb17_100045|    Min            23.22                 2.00           0.00000
21Feb17_100045|    Std             7.30                19.72           0.34184
21Feb17_100045|   Best            23.22                52.00           0.73602
21Feb17_100045|-- Generation 25 --
21Feb17_100045|    -- Crossed 3 individual pairs.
21Feb17_100045|    -- Mutated 32 individuals.
21Feb17_100451|    -- Evaluated 64 individuals.
21Feb17_100451|    Summary of generation 25:
21Feb17_100451| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_100451|-----------  ------------------  --------------------  ----------
21Feb17_100451|    Max            51.74                114.00          0.82799
21Feb17_100451|    Avg            33.58                45.08           0.45457
21Feb17_100451|    Min            23.91                 8.00           0.00000
21Feb17_100451|    Std             7.24                19.61           0.35022
21Feb17_100451|   Best            23.91                48.00           0.72048
21Feb17_100451|-- Generation 26 --
21Feb17_100451|    -- Crossed 1 individual pairs.
21Feb17_100451|    -- Mutated 32 individuals.
21Feb17_100901|    -- Evaluated 64 individuals.
21Feb17_100901|    Summary of generation 26:
21Feb17_100901| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_100901|-----------  ------------------  --------------------  ----------
21Feb17_100901|    Max            42.35                108.00          0.84388
21Feb17_100901|    Avg            32.71                48.80           0.44554
21Feb17_100901|    Min            23.30                 2.00           0.00000
21Feb17_100901|    Std             7.16                22.53           0.33996
21Feb17_100901|   Best            23.30                24.00           0.69415
21Feb17_100901|-- Generation 27 --
21Feb17_100901|    -- Crossed 1 individual pairs.
21Feb17_100901|    -- Mutated 32 individuals.
21Feb17_101309|    -- Evaluated 64 individuals.
21Feb17_101309|    Summary of generation 27:
21Feb17_101309| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_101309|-----------  ------------------  --------------------  ----------
21Feb17_101309|    Max            42.26                132.00          0.82552
21Feb17_101309|    Avg            32.16                51.20           0.45948
21Feb17_101309|    Min            21.74                 8.00           0.00000
21Feb17_101309|    Std             7.19                22.48           0.32234
21Feb17_101309|   Best            21.74                18.00           0.76278
21Feb17_101309|-- Generation 28 --
21Feb17_101309|    -- Crossed 0 individual pairs.
21Feb17_101309|    -- Mutated 32 individuals.
21Feb17_101718|    -- Evaluated 64 individuals.
21Feb17_101718|    Summary of generation 28:
21Feb17_101718| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_101718|-----------  ------------------  --------------------  ----------
21Feb17_101718|    Max            42.00                132.00          0.83850
21Feb17_101718|    Avg            31.52                51.11           0.49187
21Feb17_101718|    Min            23.04                12.00           0.00000
21Feb17_101718|    Std             6.86                24.66           0.32040
21Feb17_101718|   Best            23.04                24.00           0.73226
21Feb17_101718|-- Generation 29 --
21Feb17_101718|    -- Crossed 0 individual pairs.
21Feb17_101718|    -- Mutated 32 individuals.
21Feb17_102126|    -- Evaluated 64 individuals.
21Feb17_102126|    Summary of generation 29:
21Feb17_102126| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_102126|-----------  ------------------  --------------------  ----------
21Feb17_102126|    Max            42.09                132.00          0.82871
21Feb17_102126|    Avg            32.10                49.19           0.44677
21Feb17_102126|    Min            22.26                12.00           0.00000
21Feb17_102126|    Std             7.60                23.20           0.33800
21Feb17_102126|   Best            22.26                56.00           0.74227
21Feb17_102126|-- Generation 30 --
21Feb17_102126|    -- Crossed 0 individual pairs.
21Feb17_102126|    -- Mutated 32 individuals.
21Feb17_102532|    -- Evaluated 64 individuals.
21Feb17_102532|    Summary of generation 30:
21Feb17_102532| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_102532|-----------  ------------------  --------------------  ----------
21Feb17_102532|    Max            42.09                100.00          0.82371
21Feb17_102532|    Avg            31.14                49.09           0.49033
21Feb17_102532|    Min            22.00                14.00           0.00000
21Feb17_102532|    Std             7.06                18.85           0.31415
21Feb17_102532|   Best            22.00                56.00           0.78704
21Feb17_102532|-- Generation 31 --
21Feb17_102532|    -- Crossed 1 individual pairs.
21Feb17_102532|    -- Mutated 32 individuals.
21Feb17_102941|    -- Evaluated 64 individuals.
21Feb17_102941|    Summary of generation 31:
21Feb17_102941| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_102941|-----------  ------------------  --------------------  ----------
21Feb17_102941|    Max            42.52                100.00          0.83333
21Feb17_102941|    Avg            32.54                52.38           0.44410
21Feb17_102941|    Min            22.96                 8.00           0.00000
21Feb17_102941|    Std             7.42                21.79           0.34342
21Feb17_102941|   Best            22.96                44.00           0.72671
21Feb17_102941|-- Generation 32 --
21Feb17_102941|    -- Crossed 1 individual pairs.
21Feb17_102941|    -- Mutated 32 individuals.
21Feb17_103352|    -- Evaluated 64 individuals.
21Feb17_103352|    Summary of generation 32:
21Feb17_103352| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_103352|-----------  ------------------  --------------------  ----------
21Feb17_103352|    Max            42.00                85.00           0.83038
21Feb17_103352|    Avg            32.40                52.83           0.43440
21Feb17_103352|    Min            21.57                 8.00           0.00000
21Feb17_103352|    Std             7.70                18.10           0.34013
21Feb17_103352|   Best            21.57                56.00           0.83038
21Feb17_103352|Best initial individual weights
21Feb17_103352|Individual:
21Feb17_103352|-- Constant hidden layers --
21Feb17_103352|False
21Feb17_103352|Layer 0:
21Feb17_103352|-- Config --
21Feb17_103352|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 12, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103352|-- Weights --
21Feb17_103352|[[-3.50529e-01 -6.53069e-03 -7.03730e-01 -6.33906e-01  6.10835e-02
21Feb17_103352|   4.57449e-01 -3.77835e-01  6.38481e-01  4.24141e-01  6.68786e-01
21Feb17_103352|  -4.86511e-01 -9.28542e-01]
21Feb17_103352| [-8.31270e-01 -3.94586e-01  5.51697e-02 -8.86387e-01 -6.99786e-01
21Feb17_103352|   6.44047e-01 -5.40571e-01  3.77503e-01  1.70193e-01  5.92883e-01
21Feb17_103352|   2.06540e-01  2.18639e-01]
21Feb17_103352| [-8.13637e-01  7.25044e-01  6.66092e-01  5.31057e-01 -4.48634e-01
21Feb17_103352|  -1.62601e-01 -1.57458e-02  7.74238e-02 -4.81841e-01  3.55485e-02
21Feb17_103352|  -7.21169e-01  1.05129e-01]
21Feb17_103352| [ 6.07201e-01  6.23643e-01  8.87343e-01  6.04285e-01  5.70453e-02
21Feb17_103352|   5.99381e-01 -3.21663e-03  6.64196e-01 -5.25584e-01 -1.74507e-02
21Feb17_103352|   3.80029e-01 -4.59585e-01]
21Feb17_103352| [-9.00078e-01  8.63133e-01  8.49324e-01  4.34648e-01 -5.67121e-01
21Feb17_103352|   6.24299e-01 -6.46637e-01  9.34620e-01 -5.42838e-01 -4.04257e-01
21Feb17_103352|  -4.70046e-01  4.29712e-01]
21Feb17_103352| [ 9.51731e-02  8.42954e-01 -7.44806e-01 -5.56045e-02 -4.89209e-01
21Feb17_103352|   8.07612e-01  2.77691e-01 -5.77946e-02  4.30356e-01 -9.05718e-01
21Feb17_103352|  -7.61358e-01 -4.56367e-01]
21Feb17_103352| [-9.06447e-01 -4.46566e-01 -4.40669e-01  6.09161e-01 -3.32587e-01
21Feb17_103352|  -9.31356e-01  9.62597e-02 -1.83060e-01  5.91585e-01 -2.78230e-01
21Feb17_103352|  -3.70976e-01 -3.38510e-01]
21Feb17_103352| [ 5.92999e-02 -5.35945e-01 -8.52259e-01  1.62766e-01 -2.64657e-01
21Feb17_103352|   6.65182e-01  2.45597e-01  2.99711e-01  7.14862e-01 -4.00362e-01
21Feb17_103352|   3.40170e-01 -1.14174e-01]
21Feb17_103352| [-4.26995e-01  8.46146e-01  9.81523e-01 -2.62996e-01  8.65377e-01
21Feb17_103352|  -6.86144e-01 -3.53983e-01 -2.18499e-01  3.29010e-01 -8.26088e-01
21Feb17_103352|   1.48202e-01  5.27152e-01]
21Feb17_103352| [-1.97937e-01  5.44304e-02  9.68680e-01  1.96012e-01  6.66432e-01
21Feb17_103352|  -1.15663e-01  1.01696e-01 -9.91833e-01  5.54656e-02  5.06069e-01
21Feb17_103352|  -8.39702e-01  6.07914e-02]
21Feb17_103352| [ 8.22409e-01 -3.07988e-01 -4.87097e-01 -2.67403e-01 -3.17115e-01
21Feb17_103352|   6.20877e-01  2.45721e-01  1.47039e-01  8.22748e-02 -4.61491e-01
21Feb17_103352|   5.08690e-01 -8.10093e-01]
21Feb17_103352| [-1.03463e-01 -7.13247e-01 -5.27190e-01 -8.14055e-01 -2.20069e-01
21Feb17_103352|   7.58689e-01  7.72478e-01 -3.75243e-01 -1.74773e-01  4.33018e-02
21Feb17_103352|   5.76591e-01 -9.04182e-01]
21Feb17_103352| [ 6.39880e-01 -2.76473e-01  4.48413e-01  7.92996e-01  6.12921e-01
21Feb17_103352|   8.45232e-01 -3.59434e-01 -1.65084e-01  6.00279e-01 -9.07135e-01
21Feb17_103352|  -9.18766e-01 -3.84510e-02]
21Feb17_103352| [-4.35982e-01  3.53117e-01 -4.33635e-01  4.41189e-01  2.02385e-01
21Feb17_103352|  -2.15156e-01 -3.32093e-01 -9.46393e-01  7.49818e-01  7.56840e-01
21Feb17_103352|  -2.97280e-01  3.76513e-01]
21Feb17_103352| [ 2.00098e-01 -3.94368e-01  4.74964e-01 -5.14077e-01 -5.02985e-01
21Feb17_103352|   6.57337e-01  4.54284e-01  7.99434e-01  1.18259e-01  7.90625e-01
21Feb17_103352|  -8.45168e-01 -7.22624e-01]
21Feb17_103352| [ 5.21361e-01 -9.37087e-01  6.98489e-01  7.45747e-01  9.84330e-01
21Feb17_103352|  -1.70463e-01 -4.14211e-01  4.94059e-01 -4.89685e-03 -7.22161e-02
21Feb17_103352|   3.28119e-01 -2.96382e-01]
21Feb17_103352| [ 9.97912e-02 -3.45331e-01 -3.32041e-01 -8.83410e-01  4.64194e-01
21Feb17_103352|  -2.94905e-01 -7.11116e-01 -2.12420e-01  8.93334e-01  5.60374e-01
21Feb17_103352|  -8.11522e-01  3.94537e-01]
21Feb17_103352| [ 2.39284e-01 -9.68110e-02 -3.48403e-01  6.68017e-01  1.07039e-01
21Feb17_103352|  -1.80014e-01 -1.28612e-01 -3.28318e-01  7.99371e-01  7.45882e-01
21Feb17_103352|   4.50426e-01 -9.94601e-02]
21Feb17_103352| [-9.32040e-02 -4.99896e-01 -3.18835e-01 -3.21963e-01  8.88030e-02
21Feb17_103352|   8.24115e-01  3.93190e-01  2.14054e-01 -4.70631e-02  5.36199e-01
21Feb17_103352|   7.72001e-01 -1.38053e-01]
21Feb17_103352| [ 8.31611e-01  7.46409e-01  2.18558e-01  7.47226e-01 -4.35942e-01
21Feb17_103352|  -6.59230e-01  3.39715e-02  8.14827e-01 -7.32488e-02 -1.12845e-01
21Feb17_103352|  -5.06295e-01  2.18074e-01]
21Feb17_103352| [-3.26563e-01  6.22846e-01  3.85669e-01 -9.86028e-01 -7.51629e-02
21Feb17_103352|  -1.88021e-01  7.27322e-01  5.61207e-04  1.34321e-01  7.19415e-01
21Feb17_103352|  -5.83277e-01 -4.45815e-01]
21Feb17_103352| [ 7.83756e-01  9.31803e-02  4.99853e-01 -9.31861e-01  7.91593e-01
21Feb17_103352|   1.96250e-01 -8.00498e-02  7.34271e-01 -2.68771e-01  7.49220e-01
21Feb17_103352|   1.24815e-01  6.17245e-01]
21Feb17_103352| [ 2.20500e-01 -9.26851e-01 -5.03545e-02  9.91366e-01  9.07862e-01
21Feb17_103352|   6.95839e-01  2.07702e-01  1.55262e-01  7.17753e-01 -6.02225e-01
21Feb17_103352|  -2.43972e-02  7.83904e-01]
21Feb17_103352| [-7.35179e-01 -4.04922e-01 -7.64988e-01  6.94764e-03 -5.74469e-01
21Feb17_103352|  -8.82582e-01 -4.25720e-01  4.48261e-01  9.38039e-01 -6.02162e-01
21Feb17_103352|   1.85138e-01  8.19467e-01]
21Feb17_103352| [-2.42564e-01  5.05630e-02 -6.53631e-01  8.89456e-01  3.73267e-02
21Feb17_103352|  -4.57479e-01  5.78190e-01 -8.65769e-01  4.43846e-01  9.21993e-01
21Feb17_103352|  -4.59642e-01  4.55887e-01]
21Feb17_103352| [ 1.79502e-01  5.97755e-01 -5.91581e-01  6.50878e-01 -3.20822e-02
21Feb17_103352|   7.98103e-01  9.23662e-01 -3.15762e-01  3.95919e-01 -9.74799e-01
21Feb17_103352|  -9.18783e-01  9.04381e-01]
21Feb17_103352| [-9.77544e-01 -9.84191e-01 -3.78989e-01  1.57093e-01 -1.19240e-01
21Feb17_103352|   7.04336e-01  9.20317e-01 -9.23300e-02  7.24512e-01 -4.73620e-01
21Feb17_103352|   4.32204e-01  1.96422e-01]
21Feb17_103352| [-9.94008e-01  1.23345e-01 -2.91311e-01  3.86181e-01  3.50519e-01
21Feb17_103352|   8.97293e-02  1.28693e-01  7.64175e-01  9.70172e-01 -9.36008e-01
21Feb17_103352|   2.31190e-01 -3.81352e-01]
21Feb17_103352| [-8.68842e-01 -3.08689e-01 -7.85613e-02 -7.75421e-01 -2.62711e-01
21Feb17_103352|  -9.13854e-01  5.58996e-01  8.97445e-01 -4.78631e-01 -4.79708e-02
21Feb17_103352|  -2.09270e-01  1.03320e-01]
21Feb17_103352| [ 2.47190e-01  8.94828e-01 -8.83655e-01  1.67368e-01 -1.09226e-01
21Feb17_103352|   5.39374e-01  3.22158e-01  7.22802e-01 -4.76431e-01 -3.98606e-01
21Feb17_103352|   3.91466e-01 -5.89172e-01]
21Feb17_103352| [ 2.03966e-01 -8.11217e-01  8.56319e-01 -5.26108e-01 -9.29896e-01
21Feb17_103352|   5.92077e-01  8.52854e-01  6.15086e-01  5.45676e-01 -8.13950e-01
21Feb17_103352|   6.24771e-01 -9.57171e-01]
21Feb17_103352| [-7.59457e-01  2.18652e-01 -9.40198e-01 -1.94388e-03 -3.63300e-01
21Feb17_103352|   2.19527e-01 -3.86609e-01  6.57866e-02  8.04643e-01  4.37489e-01
21Feb17_103352|   6.39988e-01 -8.42788e-01]
21Feb17_103352| [-2.79911e-01  8.89651e-01  5.38994e-02  7.45843e-01 -9.32154e-01
21Feb17_103352|   5.56522e-01  5.04658e-01  3.56409e-01 -5.15289e-01  6.99550e-01
21Feb17_103352|  -7.31032e-01  1.61260e-01]
21Feb17_103352| [ 8.41582e-01 -5.25391e-01  4.65437e-01  4.40808e-01 -6.03761e-01
21Feb17_103352|   6.23036e-01  9.46114e-01  5.92328e-01  2.08190e-01 -6.69715e-01
21Feb17_103352|  -7.35264e-02  5.96491e-01]
21Feb17_103352| [ 3.20347e-01  1.37290e-01  1.72843e-02 -4.70187e-01  5.92987e-01
21Feb17_103352|   3.57672e-01  2.73873e-01 -8.65750e-02 -3.09144e-01 -9.20603e-01
21Feb17_103352|   2.82912e-01  6.38325e-01]
21Feb17_103352| [-8.91399e-01 -1.24857e-01 -4.86431e-01 -9.05166e-01  8.47373e-01
21Feb17_103352|   3.18146e-01  2.73494e-02 -5.33112e-01  5.63862e-01 -5.12821e-01
21Feb17_103352|  -9.38474e-01 -9.90043e-01]
21Feb17_103352| [-8.25448e-01 -1.90141e-02 -5.51276e-01 -8.23215e-01  7.26222e-02
21Feb17_103352|   3.49894e-01  5.17693e-01 -5.57217e-01 -3.26301e-01  7.78564e-01
21Feb17_103352|   6.58213e-01 -2.83929e-01]
21Feb17_103352| [ 6.18012e-02 -4.92329e-01  5.41071e-01  2.13013e-01  6.35700e-01
21Feb17_103352|  -1.65529e-01  5.77357e-01  2.45531e-01  2.54855e-01 -8.48854e-01
21Feb17_103352|   6.46386e-01 -4.13404e-01]
21Feb17_103352| [-3.41116e-01 -4.75918e-01  3.59165e-01  6.02895e-01 -4.31688e-01
21Feb17_103352|  -8.51757e-01  2.31464e-01 -9.57407e-01  2.83436e-01 -4.51744e-01
21Feb17_103352|   4.80022e-02 -8.35007e-01]
21Feb17_103352| [ 9.67499e-01  5.85047e-02  7.21540e-01  3.12459e-01  3.50272e-01
21Feb17_103352|   2.14450e-01 -3.30294e-01 -7.99000e-01  1.11959e-01  2.74091e-01
21Feb17_103352|  -1.78234e-01  9.40235e-01]
21Feb17_103352| [-1.14387e-01  4.31319e-01  3.73789e-01 -4.62497e-01  4.50407e-01
21Feb17_103352|  -4.00668e-01 -8.26575e-01  2.39589e-01 -5.24611e-01  3.30691e-01
21Feb17_103352|  -3.99504e-01  1.44547e-01]
21Feb17_103352| [ 7.34826e-01 -5.37352e-01 -6.62895e-01  1.04258e-01  2.15046e-03
21Feb17_103352|   2.71790e-01  8.51151e-01 -6.31948e-01  1.94011e-01 -6.41830e-01
21Feb17_103352|   1.67802e-01 -4.29449e-01]
21Feb17_103352| [-6.18752e-01  1.18069e-01 -7.98263e-01  4.75266e-01 -9.95474e-01
21Feb17_103352|  -1.79698e-01  6.90455e-01  3.44607e-01 -5.80013e-01 -6.16218e-02
21Feb17_103352|   7.01329e-01  8.33298e-02]
21Feb17_103352| [-2.69227e-01 -1.43165e-02 -3.33533e-01 -1.69954e-01 -1.26476e-02
21Feb17_103352|   7.69653e-01 -6.99893e-01  5.22539e-01 -1.67862e-01  4.44416e-01
21Feb17_103352|   6.72372e-01  5.52923e-01]
21Feb17_103352| [-7.10479e-01  1.61800e-01  2.53825e-01 -3.00634e-01 -5.06805e-01
21Feb17_103352|   2.02091e-01 -4.94980e-02 -1.44363e-01 -6.18371e-01  5.74350e-01
21Feb17_103352|  -1.85073e-01 -8.11049e-01]
21Feb17_103352| [-6.60846e-01 -1.69003e-01  6.00733e-01 -8.28618e-01 -3.99034e-01
21Feb17_103352|  -5.82553e-01  7.34428e-02  5.57096e-01 -1.50695e-01  1.26307e-01
21Feb17_103352|   8.92712e-01 -8.75142e-01]
21Feb17_103352| [ 7.58158e-01  5.89907e-01 -1.92304e-01 -3.86200e-01 -2.63049e-01
21Feb17_103352|  -3.41209e-03  4.05030e-01 -8.95945e-02  9.79113e-01  6.78942e-02
21Feb17_103352|  -9.53580e-01  7.06162e-01]
21Feb17_103352| [-1.23045e-01  9.25694e-01  5.20030e-01  4.57808e-01 -9.99639e-01
21Feb17_103352|  -9.80069e-02  3.03598e-01  4.26167e-02 -3.64595e-01 -7.17635e-01
21Feb17_103352|   1.61128e-01  6.30329e-01]
21Feb17_103352| [ 2.02232e-02 -3.24113e-01  7.43999e-01 -3.75983e-01  4.63558e-01
21Feb17_103352|  -2.04941e-01 -5.28404e-02  4.26576e-01 -2.53802e-01  1.74976e-01
21Feb17_103352|  -8.35763e-01  8.54548e-01]
21Feb17_103352| [-5.76875e-01  5.40954e-01 -4.91777e-01  4.40209e-01 -9.16379e-01
21Feb17_103352|   6.01728e-01  1.25226e-02  2.05876e-01  8.45524e-01 -8.34178e-01
21Feb17_103352|  -7.87379e-01  8.63352e-01]
21Feb17_103352| [-3.15102e-01  7.00213e-01  6.69503e-01  7.15510e-01 -9.53550e-01
21Feb17_103352|   4.07885e-02  4.25336e-01  6.24629e-01  9.90858e-01  6.36989e-01
21Feb17_103352|  -6.44355e-01 -5.47589e-01]
21Feb17_103352| [-8.25051e-01 -4.37574e-01  4.76334e-01 -7.71092e-01  7.98467e-01
21Feb17_103352|  -1.52347e-01  3.34469e-01  1.51889e-01 -9.60611e-01  4.62484e-01
21Feb17_103352|   4.10115e-01 -1.60555e-01]
21Feb17_103352| [ 1.77712e-01  6.55776e-01  8.97735e-01 -9.20852e-01 -9.69032e-01
21Feb17_103352|  -4.79756e-02 -3.24015e-01 -1.57490e-01 -6.25919e-01  9.94240e-01
21Feb17_103352|  -4.74141e-01 -1.00993e-01]
21Feb17_103352| [ 3.66246e-01  8.06205e-01  3.37216e-01 -3.17040e-01  9.19693e-01
21Feb17_103352|   8.28581e-01  2.22724e-01 -5.57410e-01 -8.17434e-01 -8.65693e-01
21Feb17_103352|  -4.72960e-01  7.15176e-01]
21Feb17_103352| [-8.25000e-01 -4.67253e-01 -1.84646e-02  3.88053e-01 -8.75853e-01
21Feb17_103352|  -2.34509e-01  9.53471e-01  8.05489e-02  2.71744e-01 -7.15129e-01
21Feb17_103352|   9.24875e-01 -6.07435e-01]
21Feb17_103352| [-2.79447e-01  2.39105e-01  1.32962e-01 -7.68103e-01  7.58443e-01
21Feb17_103352|  -1.69646e-01 -7.52460e-01 -7.30195e-01 -4.68985e-01 -2.88784e-01
21Feb17_103352|   3.77655e-02 -5.72024e-01]
21Feb17_103352| [-8.37481e-01 -8.22188e-02  8.45547e-01 -5.53876e-01  5.72703e-01
21Feb17_103352|   3.09970e-01  8.96552e-01  3.97690e-01 -7.19080e-01  2.37714e-01
21Feb17_103352|   6.60752e-01  1.69435e-01]]
21Feb17_103352|-- Bias --
21Feb17_103352|[-0.28065  0.08142 -0.20194  0.96969  0.45180  0.54884  0.16606 -0.15804
21Feb17_103352|  0.47362  0.17133  0.43345 -0.35803]
21Feb17_103352|Layer 1:
21Feb17_103352|-- Config --
21Feb17_103352|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 12], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103352|-- Weights --
21Feb17_103352|[[-0.88546  0.72941]
21Feb17_103352| [ 0.79196 -0.05477]
21Feb17_103352| [-0.89752 -0.49343]
21Feb17_103352| [ 0.78974 -0.41510]
21Feb17_103352| [ 0.29561 -0.94575]
21Feb17_103352| [-0.14754  0.69148]
21Feb17_103352| [-0.33558  0.37910]
21Feb17_103352| [-0.82387  0.15998]
21Feb17_103352| [-0.77760  0.88462]
21Feb17_103352| [ 0.98329 -0.68363]
21Feb17_103352| [ 0.88895  0.40387]
21Feb17_103352| [ 0.39015 -0.38652]]
21Feb17_103352|-- Bias --
21Feb17_103352|[ 0.28702 -0.70976]
21Feb17_103352|Predicting the validation and test data with the Best initial individual.
21Feb17_103358| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_103358|-----------  ------------------  --------------------  ----------
21Feb17_103358|Validation         42.00                  12            0.00000
21Feb17_103358|   Test            36.32                  12            0.00298
21Feb17_103358|-------------------- Test #0 --------------------
21Feb17_103358|Best final individual weights
21Feb17_103358|Individual:
21Feb17_103358|-- Constant hidden layers --
21Feb17_103358|False
21Feb17_103358|Layer 0:
21Feb17_103358|-- Config --
21Feb17_103358|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103358|-- Weights --
21Feb17_103358|[[-0.73212  1.32861  0.10200]
21Feb17_103358| [ 1.48746 -2.97273 -0.42944]
21Feb17_103358| [ 0.53095 -1.50623  0.79224]
21Feb17_103358| [-1.07292 -0.83175 -0.90105]
21Feb17_103358| [-0.48696 -0.89325  0.27226]
21Feb17_103358| [-3.02511  0.34155 -0.03837]
21Feb17_103358| [-0.76747  0.57140 -0.46892]
21Feb17_103358| [-0.07581  0.14713  0.85910]
21Feb17_103358| [-1.37488  0.52170 -0.36205]
21Feb17_103358| [ 1.60981 -0.08727 -0.11267]
21Feb17_103358| [ 0.50986  1.58916 -0.35287]
21Feb17_103358| [-0.34599  1.27113 -0.16393]
21Feb17_103358| [ 1.29203  1.19467  0.37695]
21Feb17_103358| [ 0.58704  0.06328 -0.24240]
21Feb17_103358| [-0.93888 -0.89760  0.57087]
21Feb17_103358| [ 0.99159 -0.66387  0.35177]
21Feb17_103358| [-0.67119  1.06910 -0.12512]
21Feb17_103358| [-0.91534  1.23744 -0.40465]
21Feb17_103358| [ 1.39278  0.08069  0.23328]
21Feb17_103358| [ 0.09880  0.57603 -0.96101]
21Feb17_103358| [ 0.01621 -0.13343 -0.27624]
21Feb17_103358| [-1.28286 -2.28909  0.37931]
21Feb17_103358| [-0.28370  0.09336  0.01547]
21Feb17_103358| [-0.51894  1.84280 -0.25906]
21Feb17_103358| [-0.83075 -0.04508  0.12107]
21Feb17_103358| [ 0.37343  1.18436 -0.07358]
21Feb17_103358| [-2.38657 -0.35191  0.01962]
21Feb17_103358| [ 0.95757 -0.91760 -0.08971]
21Feb17_103358| [ 0.38792 -0.01880  0.69717]
21Feb17_103358| [ 1.66877 -0.58078 -1.21129]
21Feb17_103358| [-0.50943  0.59080  0.30856]
21Feb17_103358| [ 0.30163  1.11518  0.98185]
21Feb17_103358| [-0.73226  0.32281 -0.66712]
21Feb17_103358| [-0.62054 -2.21049  1.40981]
21Feb17_103358| [ 1.23185 -0.58090  0.35844]
21Feb17_103358| [-0.05616  0.24219 -0.02853]
21Feb17_103358| [-1.05085 -2.30259 -0.16276]
21Feb17_103358| [ 0.71087  0.14900  1.13430]
21Feb17_103358| [-2.45877 -1.20999 -1.04986]
21Feb17_103358| [-1.00480  1.36344 -0.13998]
21Feb17_103358| [ 1.83140 -0.91532  0.07616]
21Feb17_103358| [-0.60404 -2.05184  0.76948]
21Feb17_103358| [ 0.52617  0.76042 -1.76746]
21Feb17_103358| [-0.22134  0.17324  0.99530]
21Feb17_103358| [-0.36427  1.34655  0.02110]
21Feb17_103358| [-0.93125 -0.33620 -0.25012]
21Feb17_103358| [-2.76428  0.14487  0.48096]
21Feb17_103358| [-0.10518  0.35052  1.71840]
21Feb17_103358| [-1.27998  1.12568  1.26523]
21Feb17_103358| [-0.60698  1.53230 -0.60824]
21Feb17_103358| [ 0.02898  2.98718 -0.59153]
21Feb17_103358| [ 0.17588 -0.00449  0.50797]
21Feb17_103358| [-1.42674 -0.54967 -0.21310]
21Feb17_103358| [ 1.03196  1.18733  0.36755]
21Feb17_103358| [ 1.04748 -1.47444 -0.08469]
21Feb17_103358| [ 0.49410  0.38745  0.68469]
21Feb17_103358| [-0.62880  0.73245  0.19964]]
21Feb17_103358|-- Bias --
21Feb17_103358|[-0.18798  0.64571 -0.23142]
21Feb17_103358|Layer 1:
21Feb17_103358|-- Config --
21Feb17_103358|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103358|-- Weights --
21Feb17_103358|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_103358| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_103358| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_103358|-- Bias --
21Feb17_103358|[0.60477 0.03773 0.26452 0.12222]
21Feb17_103358|Layer 2:
21Feb17_103358|-- Config --
21Feb17_103358|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103358|-- Weights --
21Feb17_103358|[[ 0.67920  0.12119]
21Feb17_103358| [ 0.44836  0.02916]
21Feb17_103358| [ 0.68939  0.31516]
21Feb17_103358| [-0.58995 -0.05861]]
21Feb17_103358|-- Bias --
21Feb17_103358|[ 0.59649 -0.08079]
21Feb17_103358|Layer 3:
21Feb17_103358|-- Config --
21Feb17_103358|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103358|-- Weights --
21Feb17_103358|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_103358| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_103358|-- Bias --
21Feb17_103358|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_103358|Layer 4:
21Feb17_103358|-- Config --
21Feb17_103358|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103358|-- Weights --
21Feb17_103358|[[-0.03514 -1.04833]
21Feb17_103358| [ 1.25238  0.62094]
21Feb17_103358| [ 0.99203  0.37406]
21Feb17_103358| [ 0.49902  0.67158]
21Feb17_103358| [-1.35709  0.38335]]
21Feb17_103358|-- Bias --
21Feb17_103358|[0.31435 0.36299]
21Feb17_103358|Predicting the validation and test data with the Best final individual.
21Feb17_103405| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_103405|-----------  ------------------  --------------------  ----------
21Feb17_103405|Validation         40.17                  56            0.05627
21Feb17_103405|   Test            21.37                  56            0.70301
21Feb17_103405|-------------------- Test #1 --------------------
21Feb17_103405|Best final individual weights
21Feb17_103405|Individual:
21Feb17_103405|-- Constant hidden layers --
21Feb17_103405|False
21Feb17_103405|Layer 0:
21Feb17_103405|-- Config --
21Feb17_103405|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103405|-- Weights --
21Feb17_103405|[[-0.73212  1.32861  0.10200]
21Feb17_103405| [ 1.48746 -2.97273 -0.42944]
21Feb17_103405| [ 0.53095 -1.50623  0.79224]
21Feb17_103405| [-1.07292 -0.83175 -0.90105]
21Feb17_103405| [-0.48696 -0.89325  0.27226]
21Feb17_103405| [-3.02511  0.34155 -0.03837]
21Feb17_103405| [-0.76747  0.57140 -0.46892]
21Feb17_103405| [-0.07581  0.14713  0.85910]
21Feb17_103405| [-1.37488  0.52170 -0.36205]
21Feb17_103405| [ 1.60981 -0.08727 -0.11267]
21Feb17_103405| [ 0.50986  1.58916 -0.35287]
21Feb17_103405| [-0.34599  1.27113 -0.16393]
21Feb17_103405| [ 1.29203  1.19467  0.37695]
21Feb17_103405| [ 0.58704  0.06328 -0.24240]
21Feb17_103405| [-0.93888 -0.89760  0.57087]
21Feb17_103405| [ 0.99159 -0.66387  0.35177]
21Feb17_103405| [-0.67119  1.06910 -0.12512]
21Feb17_103405| [-0.91534  1.23744 -0.40465]
21Feb17_103405| [ 1.39278  0.08069  0.23328]
21Feb17_103405| [ 0.09880  0.57603 -0.96101]
21Feb17_103405| [ 0.01621 -0.13343 -0.27624]
21Feb17_103405| [-1.28286 -2.28909  0.37931]
21Feb17_103405| [-0.28370  0.09336  0.01547]
21Feb17_103405| [-0.51894  1.84280 -0.25906]
21Feb17_103405| [-0.83075 -0.04508  0.12107]
21Feb17_103405| [ 0.37343  1.18436 -0.07358]
21Feb17_103405| [-2.38657 -0.35191  0.01962]
21Feb17_103405| [ 0.95757 -0.91760 -0.08971]
21Feb17_103405| [ 0.38792 -0.01880  0.69717]
21Feb17_103405| [ 1.66877 -0.58078 -1.21129]
21Feb17_103405| [-0.50943  0.59080  0.30856]
21Feb17_103405| [ 0.30163  1.11518  0.98185]
21Feb17_103405| [-0.73226  0.32281 -0.66712]
21Feb17_103405| [-0.62054 -2.21049  1.40981]
21Feb17_103405| [ 1.23185 -0.58090  0.35844]
21Feb17_103405| [-0.05616  0.24219 -0.02853]
21Feb17_103405| [-1.05085 -2.30259 -0.16276]
21Feb17_103405| [ 0.71087  0.14900  1.13430]
21Feb17_103405| [-2.45877 -1.20999 -1.04986]
21Feb17_103405| [-1.00480  1.36344 -0.13998]
21Feb17_103405| [ 1.83140 -0.91532  0.07616]
21Feb17_103405| [-0.60404 -2.05184  0.76948]
21Feb17_103405| [ 0.52617  0.76042 -1.76746]
21Feb17_103405| [-0.22134  0.17324  0.99530]
21Feb17_103405| [-0.36427  1.34655  0.02110]
21Feb17_103405| [-0.93125 -0.33620 -0.25012]
21Feb17_103405| [-2.76428  0.14487  0.48096]
21Feb17_103405| [-0.10518  0.35052  1.71840]
21Feb17_103405| [-1.27998  1.12568  1.26523]
21Feb17_103405| [-0.60698  1.53230 -0.60824]
21Feb17_103405| [ 0.02898  2.98718 -0.59153]
21Feb17_103405| [ 0.17588 -0.00449  0.50797]
21Feb17_103405| [-1.42674 -0.54967 -0.21310]
21Feb17_103405| [ 1.03196  1.18733  0.36755]
21Feb17_103405| [ 1.04748 -1.47444 -0.08469]
21Feb17_103405| [ 0.49410  0.38745  0.68469]
21Feb17_103405| [-0.62880  0.73245  0.19964]]
21Feb17_103405|-- Bias --
21Feb17_103405|[-0.18798  0.64571 -0.23142]
21Feb17_103405|Layer 1:
21Feb17_103405|-- Config --
21Feb17_103405|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103405|-- Weights --
21Feb17_103405|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_103405| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_103405| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_103405|-- Bias --
21Feb17_103405|[0.60477 0.03773 0.26452 0.12222]
21Feb17_103405|Layer 2:
21Feb17_103405|-- Config --
21Feb17_103405|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103405|-- Weights --
21Feb17_103405|[[ 0.67920  0.12119]
21Feb17_103405| [ 0.44836  0.02916]
21Feb17_103405| [ 0.68939  0.31516]
21Feb17_103405| [-0.58995 -0.05861]]
21Feb17_103405|-- Bias --
21Feb17_103405|[ 0.59649 -0.08079]
21Feb17_103405|Layer 3:
21Feb17_103405|-- Config --
21Feb17_103405|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103405|-- Weights --
21Feb17_103405|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_103405| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_103405|-- Bias --
21Feb17_103405|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_103405|Layer 4:
21Feb17_103405|-- Config --
21Feb17_103405|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103405|-- Weights --
21Feb17_103405|[[-0.03514 -1.04833]
21Feb17_103405| [ 1.25238  0.62094]
21Feb17_103405| [ 0.99203  0.37406]
21Feb17_103405| [ 0.49902  0.67158]
21Feb17_103405| [-1.35709  0.38335]]
21Feb17_103405|-- Bias --
21Feb17_103405|[0.31435 0.36299]
21Feb17_103405|Predicting the validation and test data with the Best final individual.
21Feb17_103413| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_103413|-----------  ------------------  --------------------  ----------
21Feb17_103413|Validation         23.83                  56            0.86651
21Feb17_103413|   Test            22.68                  56            0.77969
21Feb17_103413|-------------------- Test #2 --------------------
21Feb17_103413|Best final individual weights
21Feb17_103413|Individual:
21Feb17_103413|-- Constant hidden layers --
21Feb17_103413|False
21Feb17_103413|Layer 0:
21Feb17_103413|-- Config --
21Feb17_103413|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103413|-- Weights --
21Feb17_103413|[[-0.73212  1.32861  0.10200]
21Feb17_103413| [ 1.48746 -2.97273 -0.42944]
21Feb17_103413| [ 0.53095 -1.50623  0.79224]
21Feb17_103413| [-1.07292 -0.83175 -0.90105]
21Feb17_103413| [-0.48696 -0.89325  0.27226]
21Feb17_103413| [-3.02511  0.34155 -0.03837]
21Feb17_103413| [-0.76747  0.57140 -0.46892]
21Feb17_103413| [-0.07581  0.14713  0.85910]
21Feb17_103413| [-1.37488  0.52170 -0.36205]
21Feb17_103413| [ 1.60981 -0.08727 -0.11267]
21Feb17_103413| [ 0.50986  1.58916 -0.35287]
21Feb17_103413| [-0.34599  1.27113 -0.16393]
21Feb17_103413| [ 1.29203  1.19467  0.37695]
21Feb17_103413| [ 0.58704  0.06328 -0.24240]
21Feb17_103413| [-0.93888 -0.89760  0.57087]
21Feb17_103413| [ 0.99159 -0.66387  0.35177]
21Feb17_103413| [-0.67119  1.06910 -0.12512]
21Feb17_103413| [-0.91534  1.23744 -0.40465]
21Feb17_103413| [ 1.39278  0.08069  0.23328]
21Feb17_103413| [ 0.09880  0.57603 -0.96101]
21Feb17_103413| [ 0.01621 -0.13343 -0.27624]
21Feb17_103413| [-1.28286 -2.28909  0.37931]
21Feb17_103413| [-0.28370  0.09336  0.01547]
21Feb17_103413| [-0.51894  1.84280 -0.25906]
21Feb17_103413| [-0.83075 -0.04508  0.12107]
21Feb17_103413| [ 0.37343  1.18436 -0.07358]
21Feb17_103413| [-2.38657 -0.35191  0.01962]
21Feb17_103413| [ 0.95757 -0.91760 -0.08971]
21Feb17_103413| [ 0.38792 -0.01880  0.69717]
21Feb17_103413| [ 1.66877 -0.58078 -1.21129]
21Feb17_103413| [-0.50943  0.59080  0.30856]
21Feb17_103413| [ 0.30163  1.11518  0.98185]
21Feb17_103413| [-0.73226  0.32281 -0.66712]
21Feb17_103413| [-0.62054 -2.21049  1.40981]
21Feb17_103413| [ 1.23185 -0.58090  0.35844]
21Feb17_103413| [-0.05616  0.24219 -0.02853]
21Feb17_103413| [-1.05085 -2.30259 -0.16276]
21Feb17_103413| [ 0.71087  0.14900  1.13430]
21Feb17_103413| [-2.45877 -1.20999 -1.04986]
21Feb17_103413| [-1.00480  1.36344 -0.13998]
21Feb17_103413| [ 1.83140 -0.91532  0.07616]
21Feb17_103413| [-0.60404 -2.05184  0.76948]
21Feb17_103413| [ 0.52617  0.76042 -1.76746]
21Feb17_103413| [-0.22134  0.17324  0.99530]
21Feb17_103413| [-0.36427  1.34655  0.02110]
21Feb17_103413| [-0.93125 -0.33620 -0.25012]
21Feb17_103413| [-2.76428  0.14487  0.48096]
21Feb17_103413| [-0.10518  0.35052  1.71840]
21Feb17_103413| [-1.27998  1.12568  1.26523]
21Feb17_103413| [-0.60698  1.53230 -0.60824]
21Feb17_103413| [ 0.02898  2.98718 -0.59153]
21Feb17_103413| [ 0.17588 -0.00449  0.50797]
21Feb17_103413| [-1.42674 -0.54967 -0.21310]
21Feb17_103413| [ 1.03196  1.18733  0.36755]
21Feb17_103413| [ 1.04748 -1.47444 -0.08469]
21Feb17_103413| [ 0.49410  0.38745  0.68469]
21Feb17_103413| [-0.62880  0.73245  0.19964]]
21Feb17_103413|-- Bias --
21Feb17_103413|[-0.18798  0.64571 -0.23142]
21Feb17_103413|Layer 1:
21Feb17_103413|-- Config --
21Feb17_103413|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103413|-- Weights --
21Feb17_103413|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_103413| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_103413| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_103413|-- Bias --
21Feb17_103413|[0.60477 0.03773 0.26452 0.12222]
21Feb17_103413|Layer 2:
21Feb17_103413|-- Config --
21Feb17_103413|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103413|-- Weights --
21Feb17_103413|[[ 0.67920  0.12119]
21Feb17_103413| [ 0.44836  0.02916]
21Feb17_103413| [ 0.68939  0.31516]
21Feb17_103413| [-0.58995 -0.05861]]
21Feb17_103413|-- Bias --
21Feb17_103413|[ 0.59649 -0.08079]
21Feb17_103413|Layer 3:
21Feb17_103413|-- Config --
21Feb17_103413|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103413|-- Weights --
21Feb17_103413|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_103413| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_103413|-- Bias --
21Feb17_103413|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_103413|Layer 4:
21Feb17_103413|-- Config --
21Feb17_103413|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103413|-- Weights --
21Feb17_103413|[[-0.03514 -1.04833]
21Feb17_103413| [ 1.25238  0.62094]
21Feb17_103413| [ 0.99203  0.37406]
21Feb17_103413| [ 0.49902  0.67158]
21Feb17_103413| [-1.35709  0.38335]]
21Feb17_103413|-- Bias --
21Feb17_103413|[0.31435 0.36299]
21Feb17_103413|Predicting the validation and test data with the Best final individual.
21Feb17_103421| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_103421|-----------  ------------------  --------------------  ----------
21Feb17_103421|Validation         23.91                  56            0.70865
21Feb17_103421|   Test            29.45                  56            0.70270
21Feb17_103421|-------------------- Test #3 --------------------
21Feb17_103421|Best final individual weights
21Feb17_103421|Individual:
21Feb17_103421|-- Constant hidden layers --
21Feb17_103421|False
21Feb17_103421|Layer 0:
21Feb17_103421|-- Config --
21Feb17_103421|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103421|-- Weights --
21Feb17_103421|[[-0.73212  1.32861  0.10200]
21Feb17_103421| [ 1.48746 -2.97273 -0.42944]
21Feb17_103421| [ 0.53095 -1.50623  0.79224]
21Feb17_103421| [-1.07292 -0.83175 -0.90105]
21Feb17_103421| [-0.48696 -0.89325  0.27226]
21Feb17_103421| [-3.02511  0.34155 -0.03837]
21Feb17_103421| [-0.76747  0.57140 -0.46892]
21Feb17_103421| [-0.07581  0.14713  0.85910]
21Feb17_103421| [-1.37488  0.52170 -0.36205]
21Feb17_103421| [ 1.60981 -0.08727 -0.11267]
21Feb17_103421| [ 0.50986  1.58916 -0.35287]
21Feb17_103421| [-0.34599  1.27113 -0.16393]
21Feb17_103421| [ 1.29203  1.19467  0.37695]
21Feb17_103421| [ 0.58704  0.06328 -0.24240]
21Feb17_103421| [-0.93888 -0.89760  0.57087]
21Feb17_103421| [ 0.99159 -0.66387  0.35177]
21Feb17_103421| [-0.67119  1.06910 -0.12512]
21Feb17_103421| [-0.91534  1.23744 -0.40465]
21Feb17_103421| [ 1.39278  0.08069  0.23328]
21Feb17_103421| [ 0.09880  0.57603 -0.96101]
21Feb17_103421| [ 0.01621 -0.13343 -0.27624]
21Feb17_103421| [-1.28286 -2.28909  0.37931]
21Feb17_103421| [-0.28370  0.09336  0.01547]
21Feb17_103421| [-0.51894  1.84280 -0.25906]
21Feb17_103421| [-0.83075 -0.04508  0.12107]
21Feb17_103421| [ 0.37343  1.18436 -0.07358]
21Feb17_103421| [-2.38657 -0.35191  0.01962]
21Feb17_103421| [ 0.95757 -0.91760 -0.08971]
21Feb17_103421| [ 0.38792 -0.01880  0.69717]
21Feb17_103421| [ 1.66877 -0.58078 -1.21129]
21Feb17_103421| [-0.50943  0.59080  0.30856]
21Feb17_103421| [ 0.30163  1.11518  0.98185]
21Feb17_103421| [-0.73226  0.32281 -0.66712]
21Feb17_103421| [-0.62054 -2.21049  1.40981]
21Feb17_103421| [ 1.23185 -0.58090  0.35844]
21Feb17_103421| [-0.05616  0.24219 -0.02853]
21Feb17_103421| [-1.05085 -2.30259 -0.16276]
21Feb17_103421| [ 0.71087  0.14900  1.13430]
21Feb17_103421| [-2.45877 -1.20999 -1.04986]
21Feb17_103421| [-1.00480  1.36344 -0.13998]
21Feb17_103421| [ 1.83140 -0.91532  0.07616]
21Feb17_103421| [-0.60404 -2.05184  0.76948]
21Feb17_103421| [ 0.52617  0.76042 -1.76746]
21Feb17_103421| [-0.22134  0.17324  0.99530]
21Feb17_103421| [-0.36427  1.34655  0.02110]
21Feb17_103421| [-0.93125 -0.33620 -0.25012]
21Feb17_103421| [-2.76428  0.14487  0.48096]
21Feb17_103421| [-0.10518  0.35052  1.71840]
21Feb17_103421| [-1.27998  1.12568  1.26523]
21Feb17_103421| [-0.60698  1.53230 -0.60824]
21Feb17_103421| [ 0.02898  2.98718 -0.59153]
21Feb17_103421| [ 0.17588 -0.00449  0.50797]
21Feb17_103421| [-1.42674 -0.54967 -0.21310]
21Feb17_103421| [ 1.03196  1.18733  0.36755]
21Feb17_103421| [ 1.04748 -1.47444 -0.08469]
21Feb17_103421| [ 0.49410  0.38745  0.68469]
21Feb17_103421| [-0.62880  0.73245  0.19964]]
21Feb17_103421|-- Bias --
21Feb17_103421|[-0.18798  0.64571 -0.23142]
21Feb17_103421|Layer 1:
21Feb17_103421|-- Config --
21Feb17_103421|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103421|-- Weights --
21Feb17_103421|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_103421| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_103421| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_103421|-- Bias --
21Feb17_103421|[0.60477 0.03773 0.26452 0.12222]
21Feb17_103421|Layer 2:
21Feb17_103421|-- Config --
21Feb17_103421|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103421|-- Weights --
21Feb17_103421|[[ 0.67920  0.12119]
21Feb17_103421| [ 0.44836  0.02916]
21Feb17_103421| [ 0.68939  0.31516]
21Feb17_103421| [-0.58995 -0.05861]]
21Feb17_103421|-- Bias --
21Feb17_103421|[ 0.59649 -0.08079]
21Feb17_103421|Layer 3:
21Feb17_103421|-- Config --
21Feb17_103421|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103421|-- Weights --
21Feb17_103421|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_103421| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_103421|-- Bias --
21Feb17_103421|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_103421|Layer 4:
21Feb17_103421|-- Config --
21Feb17_103421|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103421|-- Weights --
21Feb17_103421|[[-0.03514 -1.04833]
21Feb17_103421| [ 1.25238  0.62094]
21Feb17_103421| [ 0.99203  0.37406]
21Feb17_103421| [ 0.49902  0.67158]
21Feb17_103421| [-1.35709  0.38335]]
21Feb17_103421|-- Bias --
21Feb17_103421|[0.31435 0.36299]
21Feb17_103421|Predicting the validation and test data with the Best final individual.
21Feb17_103429| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_103429|-----------  ------------------  --------------------  ----------
21Feb17_103429|Validation         24.35                  56            0.84577
21Feb17_103429|   Test            21.63                  56            0.70714
21Feb17_103429|-------------------- Test #4 --------------------
21Feb17_103429|Best final individual weights
21Feb17_103429|Individual:
21Feb17_103429|-- Constant hidden layers --
21Feb17_103429|False
21Feb17_103429|Layer 0:
21Feb17_103429|-- Config --
21Feb17_103429|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103429|-- Weights --
21Feb17_103429|[[-0.73212  1.32861  0.10200]
21Feb17_103429| [ 1.48746 -2.97273 -0.42944]
21Feb17_103429| [ 0.53095 -1.50623  0.79224]
21Feb17_103429| [-1.07292 -0.83175 -0.90105]
21Feb17_103429| [-0.48696 -0.89325  0.27226]
21Feb17_103429| [-3.02511  0.34155 -0.03837]
21Feb17_103429| [-0.76747  0.57140 -0.46892]
21Feb17_103429| [-0.07581  0.14713  0.85910]
21Feb17_103429| [-1.37488  0.52170 -0.36205]
21Feb17_103429| [ 1.60981 -0.08727 -0.11267]
21Feb17_103429| [ 0.50986  1.58916 -0.35287]
21Feb17_103429| [-0.34599  1.27113 -0.16393]
21Feb17_103429| [ 1.29203  1.19467  0.37695]
21Feb17_103429| [ 0.58704  0.06328 -0.24240]
21Feb17_103429| [-0.93888 -0.89760  0.57087]
21Feb17_103429| [ 0.99159 -0.66387  0.35177]
21Feb17_103429| [-0.67119  1.06910 -0.12512]
21Feb17_103429| [-0.91534  1.23744 -0.40465]
21Feb17_103429| [ 1.39278  0.08069  0.23328]
21Feb17_103429| [ 0.09880  0.57603 -0.96101]
21Feb17_103429| [ 0.01621 -0.13343 -0.27624]
21Feb17_103429| [-1.28286 -2.28909  0.37931]
21Feb17_103429| [-0.28370  0.09336  0.01547]
21Feb17_103429| [-0.51894  1.84280 -0.25906]
21Feb17_103429| [-0.83075 -0.04508  0.12107]
21Feb17_103429| [ 0.37343  1.18436 -0.07358]
21Feb17_103429| [-2.38657 -0.35191  0.01962]
21Feb17_103429| [ 0.95757 -0.91760 -0.08971]
21Feb17_103429| [ 0.38792 -0.01880  0.69717]
21Feb17_103429| [ 1.66877 -0.58078 -1.21129]
21Feb17_103429| [-0.50943  0.59080  0.30856]
21Feb17_103429| [ 0.30163  1.11518  0.98185]
21Feb17_103429| [-0.73226  0.32281 -0.66712]
21Feb17_103429| [-0.62054 -2.21049  1.40981]
21Feb17_103429| [ 1.23185 -0.58090  0.35844]
21Feb17_103429| [-0.05616  0.24219 -0.02853]
21Feb17_103429| [-1.05085 -2.30259 -0.16276]
21Feb17_103429| [ 0.71087  0.14900  1.13430]
21Feb17_103429| [-2.45877 -1.20999 -1.04986]
21Feb17_103429| [-1.00480  1.36344 -0.13998]
21Feb17_103429| [ 1.83140 -0.91532  0.07616]
21Feb17_103429| [-0.60404 -2.05184  0.76948]
21Feb17_103429| [ 0.52617  0.76042 -1.76746]
21Feb17_103429| [-0.22134  0.17324  0.99530]
21Feb17_103429| [-0.36427  1.34655  0.02110]
21Feb17_103429| [-0.93125 -0.33620 -0.25012]
21Feb17_103429| [-2.76428  0.14487  0.48096]
21Feb17_103429| [-0.10518  0.35052  1.71840]
21Feb17_103429| [-1.27998  1.12568  1.26523]
21Feb17_103429| [-0.60698  1.53230 -0.60824]
21Feb17_103429| [ 0.02898  2.98718 -0.59153]
21Feb17_103429| [ 0.17588 -0.00449  0.50797]
21Feb17_103429| [-1.42674 -0.54967 -0.21310]
21Feb17_103429| [ 1.03196  1.18733  0.36755]
21Feb17_103429| [ 1.04748 -1.47444 -0.08469]
21Feb17_103429| [ 0.49410  0.38745  0.68469]
21Feb17_103429| [-0.62880  0.73245  0.19964]]
21Feb17_103429|-- Bias --
21Feb17_103429|[-0.18798  0.64571 -0.23142]
21Feb17_103429|Layer 1:
21Feb17_103429|-- Config --
21Feb17_103429|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103429|-- Weights --
21Feb17_103429|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_103429| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_103429| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_103429|-- Bias --
21Feb17_103429|[0.60477 0.03773 0.26452 0.12222]
21Feb17_103429|Layer 2:
21Feb17_103429|-- Config --
21Feb17_103429|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103429|-- Weights --
21Feb17_103429|[[ 0.67920  0.12119]
21Feb17_103429| [ 0.44836  0.02916]
21Feb17_103429| [ 0.68939  0.31516]
21Feb17_103429| [-0.58995 -0.05861]]
21Feb17_103429|-- Bias --
21Feb17_103429|[ 0.59649 -0.08079]
21Feb17_103429|Layer 3:
21Feb17_103429|-- Config --
21Feb17_103429|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103429|-- Weights --
21Feb17_103429|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_103429| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_103429|-- Bias --
21Feb17_103429|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_103429|Layer 4:
21Feb17_103429|-- Config --
21Feb17_103429|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103429|-- Weights --
21Feb17_103429|[[-0.03514 -1.04833]
21Feb17_103429| [ 1.25238  0.62094]
21Feb17_103429| [ 0.99203  0.37406]
21Feb17_103429| [ 0.49902  0.67158]
21Feb17_103429| [-1.35709  0.38335]]
21Feb17_103429|-- Bias --
21Feb17_103429|[0.31435 0.36299]
21Feb17_103429|Predicting the validation and test data with the Best final individual.
21Feb17_103437| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_103437|-----------  ------------------  --------------------  ----------
21Feb17_103437|Validation         21.57                  56            0.82113
21Feb17_103437|   Test            31.19                  56            0.83333
21Feb17_103437|-------------------- Test #5 --------------------
21Feb17_103437|Best final individual weights
21Feb17_103437|Individual:
21Feb17_103437|-- Constant hidden layers --
21Feb17_103437|False
21Feb17_103437|Layer 0:
21Feb17_103437|-- Config --
21Feb17_103437|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103437|-- Weights --
21Feb17_103437|[[-0.73212  1.32861  0.10200]
21Feb17_103437| [ 1.48746 -2.97273 -0.42944]
21Feb17_103437| [ 0.53095 -1.50623  0.79224]
21Feb17_103437| [-1.07292 -0.83175 -0.90105]
21Feb17_103437| [-0.48696 -0.89325  0.27226]
21Feb17_103437| [-3.02511  0.34155 -0.03837]
21Feb17_103437| [-0.76747  0.57140 -0.46892]
21Feb17_103437| [-0.07581  0.14713  0.85910]
21Feb17_103437| [-1.37488  0.52170 -0.36205]
21Feb17_103437| [ 1.60981 -0.08727 -0.11267]
21Feb17_103437| [ 0.50986  1.58916 -0.35287]
21Feb17_103437| [-0.34599  1.27113 -0.16393]
21Feb17_103437| [ 1.29203  1.19467  0.37695]
21Feb17_103437| [ 0.58704  0.06328 -0.24240]
21Feb17_103437| [-0.93888 -0.89760  0.57087]
21Feb17_103437| [ 0.99159 -0.66387  0.35177]
21Feb17_103437| [-0.67119  1.06910 -0.12512]
21Feb17_103437| [-0.91534  1.23744 -0.40465]
21Feb17_103437| [ 1.39278  0.08069  0.23328]
21Feb17_103437| [ 0.09880  0.57603 -0.96101]
21Feb17_103437| [ 0.01621 -0.13343 -0.27624]
21Feb17_103437| [-1.28286 -2.28909  0.37931]
21Feb17_103437| [-0.28370  0.09336  0.01547]
21Feb17_103437| [-0.51894  1.84280 -0.25906]
21Feb17_103437| [-0.83075 -0.04508  0.12107]
21Feb17_103437| [ 0.37343  1.18436 -0.07358]
21Feb17_103437| [-2.38657 -0.35191  0.01962]
21Feb17_103437| [ 0.95757 -0.91760 -0.08971]
21Feb17_103437| [ 0.38792 -0.01880  0.69717]
21Feb17_103437| [ 1.66877 -0.58078 -1.21129]
21Feb17_103437| [-0.50943  0.59080  0.30856]
21Feb17_103437| [ 0.30163  1.11518  0.98185]
21Feb17_103437| [-0.73226  0.32281 -0.66712]
21Feb17_103437| [-0.62054 -2.21049  1.40981]
21Feb17_103437| [ 1.23185 -0.58090  0.35844]
21Feb17_103437| [-0.05616  0.24219 -0.02853]
21Feb17_103437| [-1.05085 -2.30259 -0.16276]
21Feb17_103437| [ 0.71087  0.14900  1.13430]
21Feb17_103437| [-2.45877 -1.20999 -1.04986]
21Feb17_103437| [-1.00480  1.36344 -0.13998]
21Feb17_103437| [ 1.83140 -0.91532  0.07616]
21Feb17_103437| [-0.60404 -2.05184  0.76948]
21Feb17_103437| [ 0.52617  0.76042 -1.76746]
21Feb17_103437| [-0.22134  0.17324  0.99530]
21Feb17_103437| [-0.36427  1.34655  0.02110]
21Feb17_103437| [-0.93125 -0.33620 -0.25012]
21Feb17_103437| [-2.76428  0.14487  0.48096]
21Feb17_103437| [-0.10518  0.35052  1.71840]
21Feb17_103437| [-1.27998  1.12568  1.26523]
21Feb17_103437| [-0.60698  1.53230 -0.60824]
21Feb17_103437| [ 0.02898  2.98718 -0.59153]
21Feb17_103437| [ 0.17588 -0.00449  0.50797]
21Feb17_103437| [-1.42674 -0.54967 -0.21310]
21Feb17_103437| [ 1.03196  1.18733  0.36755]
21Feb17_103437| [ 1.04748 -1.47444 -0.08469]
21Feb17_103437| [ 0.49410  0.38745  0.68469]
21Feb17_103437| [-0.62880  0.73245  0.19964]]
21Feb17_103437|-- Bias --
21Feb17_103437|[-0.18798  0.64571 -0.23142]
21Feb17_103437|Layer 1:
21Feb17_103437|-- Config --
21Feb17_103437|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103437|-- Weights --
21Feb17_103437|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_103437| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_103437| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_103437|-- Bias --
21Feb17_103437|[0.60477 0.03773 0.26452 0.12222]
21Feb17_103437|Layer 2:
21Feb17_103437|-- Config --
21Feb17_103437|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103437|-- Weights --
21Feb17_103437|[[ 0.67920  0.12119]
21Feb17_103437| [ 0.44836  0.02916]
21Feb17_103437| [ 0.68939  0.31516]
21Feb17_103437| [-0.58995 -0.05861]]
21Feb17_103437|-- Bias --
21Feb17_103437|[ 0.59649 -0.08079]
21Feb17_103437|Layer 3:
21Feb17_103437|-- Config --
21Feb17_103437|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103437|-- Weights --
21Feb17_103437|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_103437| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_103437|-- Bias --
21Feb17_103437|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_103437|Layer 4:
21Feb17_103437|-- Config --
21Feb17_103437|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103437|-- Weights --
21Feb17_103437|[[-0.03514 -1.04833]
21Feb17_103437| [ 1.25238  0.62094]
21Feb17_103437| [ 0.99203  0.37406]
21Feb17_103437| [ 0.49902  0.67158]
21Feb17_103437| [-1.35709  0.38335]]
21Feb17_103437|-- Bias --
21Feb17_103437|[0.31435 0.36299]
21Feb17_103437|Predicting the validation and test data with the Best final individual.
21Feb17_103444| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_103444|-----------  ------------------  --------------------  ----------
21Feb17_103444|Validation         23.22                  56            0.86009
21Feb17_103444|   Test            26.15                  56            0.85097
21Feb17_103444|-------------------- Test #6 --------------------
21Feb17_103444|Best final individual weights
21Feb17_103444|Individual:
21Feb17_103444|-- Constant hidden layers --
21Feb17_103444|False
21Feb17_103444|Layer 0:
21Feb17_103444|-- Config --
21Feb17_103444|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103444|-- Weights --
21Feb17_103444|[[-0.73212  1.32861  0.10200]
21Feb17_103444| [ 1.48746 -2.97273 -0.42944]
21Feb17_103444| [ 0.53095 -1.50623  0.79224]
21Feb17_103444| [-1.07292 -0.83175 -0.90105]
21Feb17_103444| [-0.48696 -0.89325  0.27226]
21Feb17_103444| [-3.02511  0.34155 -0.03837]
21Feb17_103444| [-0.76747  0.57140 -0.46892]
21Feb17_103444| [-0.07581  0.14713  0.85910]
21Feb17_103444| [-1.37488  0.52170 -0.36205]
21Feb17_103444| [ 1.60981 -0.08727 -0.11267]
21Feb17_103444| [ 0.50986  1.58916 -0.35287]
21Feb17_103444| [-0.34599  1.27113 -0.16393]
21Feb17_103444| [ 1.29203  1.19467  0.37695]
21Feb17_103444| [ 0.58704  0.06328 -0.24240]
21Feb17_103444| [-0.93888 -0.89760  0.57087]
21Feb17_103444| [ 0.99159 -0.66387  0.35177]
21Feb17_103444| [-0.67119  1.06910 -0.12512]
21Feb17_103444| [-0.91534  1.23744 -0.40465]
21Feb17_103444| [ 1.39278  0.08069  0.23328]
21Feb17_103444| [ 0.09880  0.57603 -0.96101]
21Feb17_103444| [ 0.01621 -0.13343 -0.27624]
21Feb17_103444| [-1.28286 -2.28909  0.37931]
21Feb17_103444| [-0.28370  0.09336  0.01547]
21Feb17_103444| [-0.51894  1.84280 -0.25906]
21Feb17_103444| [-0.83075 -0.04508  0.12107]
21Feb17_103444| [ 0.37343  1.18436 -0.07358]
21Feb17_103444| [-2.38657 -0.35191  0.01962]
21Feb17_103444| [ 0.95757 -0.91760 -0.08971]
21Feb17_103444| [ 0.38792 -0.01880  0.69717]
21Feb17_103444| [ 1.66877 -0.58078 -1.21129]
21Feb17_103444| [-0.50943  0.59080  0.30856]
21Feb17_103444| [ 0.30163  1.11518  0.98185]
21Feb17_103444| [-0.73226  0.32281 -0.66712]
21Feb17_103444| [-0.62054 -2.21049  1.40981]
21Feb17_103444| [ 1.23185 -0.58090  0.35844]
21Feb17_103444| [-0.05616  0.24219 -0.02853]
21Feb17_103444| [-1.05085 -2.30259 -0.16276]
21Feb17_103444| [ 0.71087  0.14900  1.13430]
21Feb17_103444| [-2.45877 -1.20999 -1.04986]
21Feb17_103444| [-1.00480  1.36344 -0.13998]
21Feb17_103444| [ 1.83140 -0.91532  0.07616]
21Feb17_103444| [-0.60404 -2.05184  0.76948]
21Feb17_103444| [ 0.52617  0.76042 -1.76746]
21Feb17_103444| [-0.22134  0.17324  0.99530]
21Feb17_103444| [-0.36427  1.34655  0.02110]
21Feb17_103444| [-0.93125 -0.33620 -0.25012]
21Feb17_103444| [-2.76428  0.14487  0.48096]
21Feb17_103444| [-0.10518  0.35052  1.71840]
21Feb17_103444| [-1.27998  1.12568  1.26523]
21Feb17_103444| [-0.60698  1.53230 -0.60824]
21Feb17_103444| [ 0.02898  2.98718 -0.59153]
21Feb17_103444| [ 0.17588 -0.00449  0.50797]
21Feb17_103444| [-1.42674 -0.54967 -0.21310]
21Feb17_103444| [ 1.03196  1.18733  0.36755]
21Feb17_103444| [ 1.04748 -1.47444 -0.08469]
21Feb17_103444| [ 0.49410  0.38745  0.68469]
21Feb17_103444| [-0.62880  0.73245  0.19964]]
21Feb17_103444|-- Bias --
21Feb17_103444|[-0.18798  0.64571 -0.23142]
21Feb17_103444|Layer 1:
21Feb17_103444|-- Config --
21Feb17_103444|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103444|-- Weights --
21Feb17_103444|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_103444| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_103444| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_103444|-- Bias --
21Feb17_103444|[0.60477 0.03773 0.26452 0.12222]
21Feb17_103444|Layer 2:
21Feb17_103444|-- Config --
21Feb17_103444|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103444|-- Weights --
21Feb17_103444|[[ 0.67920  0.12119]
21Feb17_103444| [ 0.44836  0.02916]
21Feb17_103444| [ 0.68939  0.31516]
21Feb17_103444| [-0.58995 -0.05861]]
21Feb17_103444|-- Bias --
21Feb17_103444|[ 0.59649 -0.08079]
21Feb17_103444|Layer 3:
21Feb17_103444|-- Config --
21Feb17_103444|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103444|-- Weights --
21Feb17_103444|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_103444| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_103444|-- Bias --
21Feb17_103444|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_103444|Layer 4:
21Feb17_103444|-- Config --
21Feb17_103444|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103444|-- Weights --
21Feb17_103444|[[-0.03514 -1.04833]
21Feb17_103444| [ 1.25238  0.62094]
21Feb17_103444| [ 0.99203  0.37406]
21Feb17_103444| [ 0.49902  0.67158]
21Feb17_103444| [-1.35709  0.38335]]
21Feb17_103444|-- Bias --
21Feb17_103444|[0.31435 0.36299]
21Feb17_103444|Predicting the validation and test data with the Best final individual.
21Feb17_103452| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_103452|-----------  ------------------  --------------------  ----------
21Feb17_103452|Validation         22.78                  56            0.83496
21Feb17_103452|   Test            21.11                  56            0.79855
21Feb17_103452|-------------------- Test #7 --------------------
21Feb17_103452|Best final individual weights
21Feb17_103452|Individual:
21Feb17_103452|-- Constant hidden layers --
21Feb17_103452|False
21Feb17_103452|Layer 0:
21Feb17_103452|-- Config --
21Feb17_103452|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103452|-- Weights --
21Feb17_103452|[[-0.73212  1.32861  0.10200]
21Feb17_103452| [ 1.48746 -2.97273 -0.42944]
21Feb17_103452| [ 0.53095 -1.50623  0.79224]
21Feb17_103452| [-1.07292 -0.83175 -0.90105]
21Feb17_103452| [-0.48696 -0.89325  0.27226]
21Feb17_103452| [-3.02511  0.34155 -0.03837]
21Feb17_103452| [-0.76747  0.57140 -0.46892]
21Feb17_103452| [-0.07581  0.14713  0.85910]
21Feb17_103452| [-1.37488  0.52170 -0.36205]
21Feb17_103452| [ 1.60981 -0.08727 -0.11267]
21Feb17_103452| [ 0.50986  1.58916 -0.35287]
21Feb17_103452| [-0.34599  1.27113 -0.16393]
21Feb17_103452| [ 1.29203  1.19467  0.37695]
21Feb17_103452| [ 0.58704  0.06328 -0.24240]
21Feb17_103452| [-0.93888 -0.89760  0.57087]
21Feb17_103452| [ 0.99159 -0.66387  0.35177]
21Feb17_103452| [-0.67119  1.06910 -0.12512]
21Feb17_103452| [-0.91534  1.23744 -0.40465]
21Feb17_103452| [ 1.39278  0.08069  0.23328]
21Feb17_103452| [ 0.09880  0.57603 -0.96101]
21Feb17_103452| [ 0.01621 -0.13343 -0.27624]
21Feb17_103452| [-1.28286 -2.28909  0.37931]
21Feb17_103452| [-0.28370  0.09336  0.01547]
21Feb17_103452| [-0.51894  1.84280 -0.25906]
21Feb17_103452| [-0.83075 -0.04508  0.12107]
21Feb17_103452| [ 0.37343  1.18436 -0.07358]
21Feb17_103452| [-2.38657 -0.35191  0.01962]
21Feb17_103452| [ 0.95757 -0.91760 -0.08971]
21Feb17_103452| [ 0.38792 -0.01880  0.69717]
21Feb17_103452| [ 1.66877 -0.58078 -1.21129]
21Feb17_103452| [-0.50943  0.59080  0.30856]
21Feb17_103452| [ 0.30163  1.11518  0.98185]
21Feb17_103452| [-0.73226  0.32281 -0.66712]
21Feb17_103452| [-0.62054 -2.21049  1.40981]
21Feb17_103452| [ 1.23185 -0.58090  0.35844]
21Feb17_103452| [-0.05616  0.24219 -0.02853]
21Feb17_103452| [-1.05085 -2.30259 -0.16276]
21Feb17_103452| [ 0.71087  0.14900  1.13430]
21Feb17_103452| [-2.45877 -1.20999 -1.04986]
21Feb17_103452| [-1.00480  1.36344 -0.13998]
21Feb17_103452| [ 1.83140 -0.91532  0.07616]
21Feb17_103452| [-0.60404 -2.05184  0.76948]
21Feb17_103452| [ 0.52617  0.76042 -1.76746]
21Feb17_103452| [-0.22134  0.17324  0.99530]
21Feb17_103452| [-0.36427  1.34655  0.02110]
21Feb17_103452| [-0.93125 -0.33620 -0.25012]
21Feb17_103452| [-2.76428  0.14487  0.48096]
21Feb17_103452| [-0.10518  0.35052  1.71840]
21Feb17_103452| [-1.27998  1.12568  1.26523]
21Feb17_103452| [-0.60698  1.53230 -0.60824]
21Feb17_103452| [ 0.02898  2.98718 -0.59153]
21Feb17_103452| [ 0.17588 -0.00449  0.50797]
21Feb17_103452| [-1.42674 -0.54967 -0.21310]
21Feb17_103452| [ 1.03196  1.18733  0.36755]
21Feb17_103452| [ 1.04748 -1.47444 -0.08469]
21Feb17_103452| [ 0.49410  0.38745  0.68469]
21Feb17_103452| [-0.62880  0.73245  0.19964]]
21Feb17_103452|-- Bias --
21Feb17_103452|[-0.18798  0.64571 -0.23142]
21Feb17_103452|Layer 1:
21Feb17_103452|-- Config --
21Feb17_103452|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103452|-- Weights --
21Feb17_103452|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_103452| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_103452| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_103452|-- Bias --
21Feb17_103452|[0.60477 0.03773 0.26452 0.12222]
21Feb17_103452|Layer 2:
21Feb17_103452|-- Config --
21Feb17_103452|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103452|-- Weights --
21Feb17_103452|[[ 0.67920  0.12119]
21Feb17_103452| [ 0.44836  0.02916]
21Feb17_103452| [ 0.68939  0.31516]
21Feb17_103452| [-0.58995 -0.05861]]
21Feb17_103452|-- Bias --
21Feb17_103452|[ 0.59649 -0.08079]
21Feb17_103452|Layer 3:
21Feb17_103452|-- Config --
21Feb17_103452|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103452|-- Weights --
21Feb17_103452|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_103452| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_103452|-- Bias --
21Feb17_103452|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_103452|Layer 4:
21Feb17_103452|-- Config --
21Feb17_103452|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103452|-- Weights --
21Feb17_103452|[[-0.03514 -1.04833]
21Feb17_103452| [ 1.25238  0.62094]
21Feb17_103452| [ 0.99203  0.37406]
21Feb17_103452| [ 0.49902  0.67158]
21Feb17_103452| [-1.35709  0.38335]]
21Feb17_103452|-- Bias --
21Feb17_103452|[0.31435 0.36299]
21Feb17_103452|Predicting the validation and test data with the Best final individual.
21Feb17_103500| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_103500|-----------  ------------------  --------------------  ----------
21Feb17_103500|Validation         28.96                  56            0.48780
21Feb17_103500|   Test            25.46                  56            0.49431
21Feb17_103500|-------------------- Test #8 --------------------
21Feb17_103500|Best final individual weights
21Feb17_103500|Individual:
21Feb17_103500|-- Constant hidden layers --
21Feb17_103500|False
21Feb17_103500|Layer 0:
21Feb17_103500|-- Config --
21Feb17_103500|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103500|-- Weights --
21Feb17_103500|[[-0.73212  1.32861  0.10200]
21Feb17_103500| [ 1.48746 -2.97273 -0.42944]
21Feb17_103500| [ 0.53095 -1.50623  0.79224]
21Feb17_103500| [-1.07292 -0.83175 -0.90105]
21Feb17_103500| [-0.48696 -0.89325  0.27226]
21Feb17_103500| [-3.02511  0.34155 -0.03837]
21Feb17_103500| [-0.76747  0.57140 -0.46892]
21Feb17_103500| [-0.07581  0.14713  0.85910]
21Feb17_103500| [-1.37488  0.52170 -0.36205]
21Feb17_103500| [ 1.60981 -0.08727 -0.11267]
21Feb17_103500| [ 0.50986  1.58916 -0.35287]
21Feb17_103500| [-0.34599  1.27113 -0.16393]
21Feb17_103500| [ 1.29203  1.19467  0.37695]
21Feb17_103500| [ 0.58704  0.06328 -0.24240]
21Feb17_103500| [-0.93888 -0.89760  0.57087]
21Feb17_103500| [ 0.99159 -0.66387  0.35177]
21Feb17_103500| [-0.67119  1.06910 -0.12512]
21Feb17_103500| [-0.91534  1.23744 -0.40465]
21Feb17_103500| [ 1.39278  0.08069  0.23328]
21Feb17_103500| [ 0.09880  0.57603 -0.96101]
21Feb17_103500| [ 0.01621 -0.13343 -0.27624]
21Feb17_103500| [-1.28286 -2.28909  0.37931]
21Feb17_103500| [-0.28370  0.09336  0.01547]
21Feb17_103500| [-0.51894  1.84280 -0.25906]
21Feb17_103500| [-0.83075 -0.04508  0.12107]
21Feb17_103500| [ 0.37343  1.18436 -0.07358]
21Feb17_103500| [-2.38657 -0.35191  0.01962]
21Feb17_103500| [ 0.95757 -0.91760 -0.08971]
21Feb17_103500| [ 0.38792 -0.01880  0.69717]
21Feb17_103500| [ 1.66877 -0.58078 -1.21129]
21Feb17_103500| [-0.50943  0.59080  0.30856]
21Feb17_103500| [ 0.30163  1.11518  0.98185]
21Feb17_103500| [-0.73226  0.32281 -0.66712]
21Feb17_103500| [-0.62054 -2.21049  1.40981]
21Feb17_103500| [ 1.23185 -0.58090  0.35844]
21Feb17_103500| [-0.05616  0.24219 -0.02853]
21Feb17_103500| [-1.05085 -2.30259 -0.16276]
21Feb17_103500| [ 0.71087  0.14900  1.13430]
21Feb17_103500| [-2.45877 -1.20999 -1.04986]
21Feb17_103500| [-1.00480  1.36344 -0.13998]
21Feb17_103500| [ 1.83140 -0.91532  0.07616]
21Feb17_103500| [-0.60404 -2.05184  0.76948]
21Feb17_103500| [ 0.52617  0.76042 -1.76746]
21Feb17_103500| [-0.22134  0.17324  0.99530]
21Feb17_103500| [-0.36427  1.34655  0.02110]
21Feb17_103500| [-0.93125 -0.33620 -0.25012]
21Feb17_103500| [-2.76428  0.14487  0.48096]
21Feb17_103500| [-0.10518  0.35052  1.71840]
21Feb17_103500| [-1.27998  1.12568  1.26523]
21Feb17_103500| [-0.60698  1.53230 -0.60824]
21Feb17_103500| [ 0.02898  2.98718 -0.59153]
21Feb17_103500| [ 0.17588 -0.00449  0.50797]
21Feb17_103500| [-1.42674 -0.54967 -0.21310]
21Feb17_103500| [ 1.03196  1.18733  0.36755]
21Feb17_103500| [ 1.04748 -1.47444 -0.08469]
21Feb17_103500| [ 0.49410  0.38745  0.68469]
21Feb17_103500| [-0.62880  0.73245  0.19964]]
21Feb17_103500|-- Bias --
21Feb17_103500|[-0.18798  0.64571 -0.23142]
21Feb17_103500|Layer 1:
21Feb17_103500|-- Config --
21Feb17_103500|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103500|-- Weights --
21Feb17_103500|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_103500| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_103500| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_103500|-- Bias --
21Feb17_103500|[0.60477 0.03773 0.26452 0.12222]
21Feb17_103500|Layer 2:
21Feb17_103500|-- Config --
21Feb17_103500|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103500|-- Weights --
21Feb17_103500|[[ 0.67920  0.12119]
21Feb17_103500| [ 0.44836  0.02916]
21Feb17_103500| [ 0.68939  0.31516]
21Feb17_103500| [-0.58995 -0.05861]]
21Feb17_103500|-- Bias --
21Feb17_103500|[ 0.59649 -0.08079]
21Feb17_103500|Layer 3:
21Feb17_103500|-- Config --
21Feb17_103500|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103500|-- Weights --
21Feb17_103500|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_103500| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_103500|-- Bias --
21Feb17_103500|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_103500|Layer 4:
21Feb17_103500|-- Config --
21Feb17_103500|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103500|-- Weights --
21Feb17_103500|[[-0.03514 -1.04833]
21Feb17_103500| [ 1.25238  0.62094]
21Feb17_103500| [ 0.99203  0.37406]
21Feb17_103500| [ 0.49902  0.67158]
21Feb17_103500| [-1.35709  0.38335]]
21Feb17_103500|-- Bias --
21Feb17_103500|[0.31435 0.36299]
21Feb17_103500|Predicting the validation and test data with the Best final individual.
21Feb17_103508| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_103508|-----------  ------------------  --------------------  ----------
21Feb17_103508|Validation         21.30                  56            0.82476
21Feb17_103508|   Test            21.81                  56            0.83186
21Feb17_103508|-------------------- Test #9 --------------------
21Feb17_103508|Best final individual weights
21Feb17_103508|Individual:
21Feb17_103508|-- Constant hidden layers --
21Feb17_103508|False
21Feb17_103508|Layer 0:
21Feb17_103508|-- Config --
21Feb17_103508|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103508|-- Weights --
21Feb17_103508|[[-0.73212  1.32861  0.10200]
21Feb17_103508| [ 1.48746 -2.97273 -0.42944]
21Feb17_103508| [ 0.53095 -1.50623  0.79224]
21Feb17_103508| [-1.07292 -0.83175 -0.90105]
21Feb17_103508| [-0.48696 -0.89325  0.27226]
21Feb17_103508| [-3.02511  0.34155 -0.03837]
21Feb17_103508| [-0.76747  0.57140 -0.46892]
21Feb17_103508| [-0.07581  0.14713  0.85910]
21Feb17_103508| [-1.37488  0.52170 -0.36205]
21Feb17_103508| [ 1.60981 -0.08727 -0.11267]
21Feb17_103508| [ 0.50986  1.58916 -0.35287]
21Feb17_103508| [-0.34599  1.27113 -0.16393]
21Feb17_103508| [ 1.29203  1.19467  0.37695]
21Feb17_103508| [ 0.58704  0.06328 -0.24240]
21Feb17_103508| [-0.93888 -0.89760  0.57087]
21Feb17_103508| [ 0.99159 -0.66387  0.35177]
21Feb17_103508| [-0.67119  1.06910 -0.12512]
21Feb17_103508| [-0.91534  1.23744 -0.40465]
21Feb17_103508| [ 1.39278  0.08069  0.23328]
21Feb17_103508| [ 0.09880  0.57603 -0.96101]
21Feb17_103508| [ 0.01621 -0.13343 -0.27624]
21Feb17_103508| [-1.28286 -2.28909  0.37931]
21Feb17_103508| [-0.28370  0.09336  0.01547]
21Feb17_103508| [-0.51894  1.84280 -0.25906]
21Feb17_103508| [-0.83075 -0.04508  0.12107]
21Feb17_103508| [ 0.37343  1.18436 -0.07358]
21Feb17_103508| [-2.38657 -0.35191  0.01962]
21Feb17_103508| [ 0.95757 -0.91760 -0.08971]
21Feb17_103508| [ 0.38792 -0.01880  0.69717]
21Feb17_103508| [ 1.66877 -0.58078 -1.21129]
21Feb17_103508| [-0.50943  0.59080  0.30856]
21Feb17_103508| [ 0.30163  1.11518  0.98185]
21Feb17_103508| [-0.73226  0.32281 -0.66712]
21Feb17_103508| [-0.62054 -2.21049  1.40981]
21Feb17_103508| [ 1.23185 -0.58090  0.35844]
21Feb17_103508| [-0.05616  0.24219 -0.02853]
21Feb17_103508| [-1.05085 -2.30259 -0.16276]
21Feb17_103508| [ 0.71087  0.14900  1.13430]
21Feb17_103508| [-2.45877 -1.20999 -1.04986]
21Feb17_103508| [-1.00480  1.36344 -0.13998]
21Feb17_103508| [ 1.83140 -0.91532  0.07616]
21Feb17_103508| [-0.60404 -2.05184  0.76948]
21Feb17_103508| [ 0.52617  0.76042 -1.76746]
21Feb17_103508| [-0.22134  0.17324  0.99530]
21Feb17_103508| [-0.36427  1.34655  0.02110]
21Feb17_103508| [-0.93125 -0.33620 -0.25012]
21Feb17_103508| [-2.76428  0.14487  0.48096]
21Feb17_103508| [-0.10518  0.35052  1.71840]
21Feb17_103508| [-1.27998  1.12568  1.26523]
21Feb17_103508| [-0.60698  1.53230 -0.60824]
21Feb17_103508| [ 0.02898  2.98718 -0.59153]
21Feb17_103508| [ 0.17588 -0.00449  0.50797]
21Feb17_103508| [-1.42674 -0.54967 -0.21310]
21Feb17_103508| [ 1.03196  1.18733  0.36755]
21Feb17_103508| [ 1.04748 -1.47444 -0.08469]
21Feb17_103508| [ 0.49410  0.38745  0.68469]
21Feb17_103508| [-0.62880  0.73245  0.19964]]
21Feb17_103508|-- Bias --
21Feb17_103508|[-0.18798  0.64571 -0.23142]
21Feb17_103508|Layer 1:
21Feb17_103508|-- Config --
21Feb17_103508|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103508|-- Weights --
21Feb17_103508|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_103508| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_103508| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_103508|-- Bias --
21Feb17_103508|[0.60477 0.03773 0.26452 0.12222]
21Feb17_103508|Layer 2:
21Feb17_103508|-- Config --
21Feb17_103508|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103508|-- Weights --
21Feb17_103508|[[ 0.67920  0.12119]
21Feb17_103508| [ 0.44836  0.02916]
21Feb17_103508| [ 0.68939  0.31516]
21Feb17_103508| [-0.58995 -0.05861]]
21Feb17_103508|-- Bias --
21Feb17_103508|[ 0.59649 -0.08079]
21Feb17_103508|Layer 3:
21Feb17_103508|-- Config --
21Feb17_103508|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103508|-- Weights --
21Feb17_103508|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_103508| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_103508|-- Bias --
21Feb17_103508|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_103508|Layer 4:
21Feb17_103508|-- Config --
21Feb17_103508|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103508|-- Weights --
21Feb17_103508|[[-0.03514 -1.04833]
21Feb17_103508| [ 1.25238  0.62094]
21Feb17_103508| [ 0.99203  0.37406]
21Feb17_103508| [ 0.49902  0.67158]
21Feb17_103508| [-1.35709  0.38335]]
21Feb17_103508|-- Bias --
21Feb17_103508|[0.31435 0.36299]
21Feb17_103508|Predicting the validation and test data with the Best final individual.
21Feb17_103516| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_103516|-----------  ------------------  --------------------  ----------
21Feb17_103516|Validation         26.43                  56            0.71922
21Feb17_103516|   Test            29.54                  56            0.67444
21Feb17_103516|-------------------- Test #10 --------------------
21Feb17_103516|Best final individual weights
21Feb17_103516|Individual:
21Feb17_103516|-- Constant hidden layers --
21Feb17_103516|False
21Feb17_103516|Layer 0:
21Feb17_103516|-- Config --
21Feb17_103516|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103516|-- Weights --
21Feb17_103516|[[-0.73212  1.32861  0.10200]
21Feb17_103516| [ 1.48746 -2.97273 -0.42944]
21Feb17_103516| [ 0.53095 -1.50623  0.79224]
21Feb17_103516| [-1.07292 -0.83175 -0.90105]
21Feb17_103516| [-0.48696 -0.89325  0.27226]
21Feb17_103516| [-3.02511  0.34155 -0.03837]
21Feb17_103516| [-0.76747  0.57140 -0.46892]
21Feb17_103516| [-0.07581  0.14713  0.85910]
21Feb17_103516| [-1.37488  0.52170 -0.36205]
21Feb17_103516| [ 1.60981 -0.08727 -0.11267]
21Feb17_103516| [ 0.50986  1.58916 -0.35287]
21Feb17_103516| [-0.34599  1.27113 -0.16393]
21Feb17_103516| [ 1.29203  1.19467  0.37695]
21Feb17_103516| [ 0.58704  0.06328 -0.24240]
21Feb17_103516| [-0.93888 -0.89760  0.57087]
21Feb17_103516| [ 0.99159 -0.66387  0.35177]
21Feb17_103516| [-0.67119  1.06910 -0.12512]
21Feb17_103516| [-0.91534  1.23744 -0.40465]
21Feb17_103516| [ 1.39278  0.08069  0.23328]
21Feb17_103516| [ 0.09880  0.57603 -0.96101]
21Feb17_103516| [ 0.01621 -0.13343 -0.27624]
21Feb17_103516| [-1.28286 -2.28909  0.37931]
21Feb17_103516| [-0.28370  0.09336  0.01547]
21Feb17_103516| [-0.51894  1.84280 -0.25906]
21Feb17_103516| [-0.83075 -0.04508  0.12107]
21Feb17_103516| [ 0.37343  1.18436 -0.07358]
21Feb17_103516| [-2.38657 -0.35191  0.01962]
21Feb17_103516| [ 0.95757 -0.91760 -0.08971]
21Feb17_103516| [ 0.38792 -0.01880  0.69717]
21Feb17_103516| [ 1.66877 -0.58078 -1.21129]
21Feb17_103516| [-0.50943  0.59080  0.30856]
21Feb17_103516| [ 0.30163  1.11518  0.98185]
21Feb17_103516| [-0.73226  0.32281 -0.66712]
21Feb17_103516| [-0.62054 -2.21049  1.40981]
21Feb17_103516| [ 1.23185 -0.58090  0.35844]
21Feb17_103516| [-0.05616  0.24219 -0.02853]
21Feb17_103516| [-1.05085 -2.30259 -0.16276]
21Feb17_103516| [ 0.71087  0.14900  1.13430]
21Feb17_103516| [-2.45877 -1.20999 -1.04986]
21Feb17_103516| [-1.00480  1.36344 -0.13998]
21Feb17_103516| [ 1.83140 -0.91532  0.07616]
21Feb17_103516| [-0.60404 -2.05184  0.76948]
21Feb17_103516| [ 0.52617  0.76042 -1.76746]
21Feb17_103516| [-0.22134  0.17324  0.99530]
21Feb17_103516| [-0.36427  1.34655  0.02110]
21Feb17_103516| [-0.93125 -0.33620 -0.25012]
21Feb17_103516| [-2.76428  0.14487  0.48096]
21Feb17_103516| [-0.10518  0.35052  1.71840]
21Feb17_103516| [-1.27998  1.12568  1.26523]
21Feb17_103516| [-0.60698  1.53230 -0.60824]
21Feb17_103516| [ 0.02898  2.98718 -0.59153]
21Feb17_103516| [ 0.17588 -0.00449  0.50797]
21Feb17_103516| [-1.42674 -0.54967 -0.21310]
21Feb17_103516| [ 1.03196  1.18733  0.36755]
21Feb17_103516| [ 1.04748 -1.47444 -0.08469]
21Feb17_103516| [ 0.49410  0.38745  0.68469]
21Feb17_103516| [-0.62880  0.73245  0.19964]]
21Feb17_103516|-- Bias --
21Feb17_103516|[-0.18798  0.64571 -0.23142]
21Feb17_103516|Layer 1:
21Feb17_103516|-- Config --
21Feb17_103516|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103516|-- Weights --
21Feb17_103516|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_103516| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_103516| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_103516|-- Bias --
21Feb17_103516|[0.60477 0.03773 0.26452 0.12222]
21Feb17_103516|Layer 2:
21Feb17_103516|-- Config --
21Feb17_103516|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103516|-- Weights --
21Feb17_103516|[[ 0.67920  0.12119]
21Feb17_103516| [ 0.44836  0.02916]
21Feb17_103516| [ 0.68939  0.31516]
21Feb17_103516| [-0.58995 -0.05861]]
21Feb17_103516|-- Bias --
21Feb17_103516|[ 0.59649 -0.08079]
21Feb17_103516|Layer 3:
21Feb17_103516|-- Config --
21Feb17_103516|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103516|-- Weights --
21Feb17_103516|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_103516| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_103516|-- Bias --
21Feb17_103516|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_103516|Layer 4:
21Feb17_103516|-- Config --
21Feb17_103516|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103516|-- Weights --
21Feb17_103516|[[-0.03514 -1.04833]
21Feb17_103516| [ 1.25238  0.62094]
21Feb17_103516| [ 0.99203  0.37406]
21Feb17_103516| [ 0.49902  0.67158]
21Feb17_103516| [-1.35709  0.38335]]
21Feb17_103516|-- Bias --
21Feb17_103516|[0.31435 0.36299]
21Feb17_103516|Predicting the validation and test data with the Best final individual.
21Feb17_103523| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_103523|-----------  ------------------  --------------------  ----------
21Feb17_103523|Validation         23.65                  56            0.85845
21Feb17_103523|   Test            26.67                  56            0.71298
21Feb17_103523|-------------------- Test #11 --------------------
21Feb17_103523|Best final individual weights
21Feb17_103523|Individual:
21Feb17_103523|-- Constant hidden layers --
21Feb17_103523|False
21Feb17_103523|Layer 0:
21Feb17_103523|-- Config --
21Feb17_103523|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103523|-- Weights --
21Feb17_103523|[[-0.73212  1.32861  0.10200]
21Feb17_103523| [ 1.48746 -2.97273 -0.42944]
21Feb17_103523| [ 0.53095 -1.50623  0.79224]
21Feb17_103523| [-1.07292 -0.83175 -0.90105]
21Feb17_103523| [-0.48696 -0.89325  0.27226]
21Feb17_103523| [-3.02511  0.34155 -0.03837]
21Feb17_103523| [-0.76747  0.57140 -0.46892]
21Feb17_103523| [-0.07581  0.14713  0.85910]
21Feb17_103523| [-1.37488  0.52170 -0.36205]
21Feb17_103523| [ 1.60981 -0.08727 -0.11267]
21Feb17_103523| [ 0.50986  1.58916 -0.35287]
21Feb17_103523| [-0.34599  1.27113 -0.16393]
21Feb17_103523| [ 1.29203  1.19467  0.37695]
21Feb17_103523| [ 0.58704  0.06328 -0.24240]
21Feb17_103523| [-0.93888 -0.89760  0.57087]
21Feb17_103523| [ 0.99159 -0.66387  0.35177]
21Feb17_103523| [-0.67119  1.06910 -0.12512]
21Feb17_103523| [-0.91534  1.23744 -0.40465]
21Feb17_103523| [ 1.39278  0.08069  0.23328]
21Feb17_103523| [ 0.09880  0.57603 -0.96101]
21Feb17_103523| [ 0.01621 -0.13343 -0.27624]
21Feb17_103523| [-1.28286 -2.28909  0.37931]
21Feb17_103523| [-0.28370  0.09336  0.01547]
21Feb17_103523| [-0.51894  1.84280 -0.25906]
21Feb17_103523| [-0.83075 -0.04508  0.12107]
21Feb17_103523| [ 0.37343  1.18436 -0.07358]
21Feb17_103523| [-2.38657 -0.35191  0.01962]
21Feb17_103523| [ 0.95757 -0.91760 -0.08971]
21Feb17_103523| [ 0.38792 -0.01880  0.69717]
21Feb17_103523| [ 1.66877 -0.58078 -1.21129]
21Feb17_103523| [-0.50943  0.59080  0.30856]
21Feb17_103523| [ 0.30163  1.11518  0.98185]
21Feb17_103523| [-0.73226  0.32281 -0.66712]
21Feb17_103523| [-0.62054 -2.21049  1.40981]
21Feb17_103523| [ 1.23185 -0.58090  0.35844]
21Feb17_103523| [-0.05616  0.24219 -0.02853]
21Feb17_103523| [-1.05085 -2.30259 -0.16276]
21Feb17_103523| [ 0.71087  0.14900  1.13430]
21Feb17_103523| [-2.45877 -1.20999 -1.04986]
21Feb17_103523| [-1.00480  1.36344 -0.13998]
21Feb17_103523| [ 1.83140 -0.91532  0.07616]
21Feb17_103523| [-0.60404 -2.05184  0.76948]
21Feb17_103523| [ 0.52617  0.76042 -1.76746]
21Feb17_103523| [-0.22134  0.17324  0.99530]
21Feb17_103523| [-0.36427  1.34655  0.02110]
21Feb17_103523| [-0.93125 -0.33620 -0.25012]
21Feb17_103523| [-2.76428  0.14487  0.48096]
21Feb17_103523| [-0.10518  0.35052  1.71840]
21Feb17_103523| [-1.27998  1.12568  1.26523]
21Feb17_103523| [-0.60698  1.53230 -0.60824]
21Feb17_103523| [ 0.02898  2.98718 -0.59153]
21Feb17_103523| [ 0.17588 -0.00449  0.50797]
21Feb17_103523| [-1.42674 -0.54967 -0.21310]
21Feb17_103523| [ 1.03196  1.18733  0.36755]
21Feb17_103523| [ 1.04748 -1.47444 -0.08469]
21Feb17_103523| [ 0.49410  0.38745  0.68469]
21Feb17_103523| [-0.62880  0.73245  0.19964]]
21Feb17_103523|-- Bias --
21Feb17_103523|[-0.18798  0.64571 -0.23142]
21Feb17_103523|Layer 1:
21Feb17_103523|-- Config --
21Feb17_103523|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103523|-- Weights --
21Feb17_103523|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_103523| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_103523| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_103523|-- Bias --
21Feb17_103523|[0.60477 0.03773 0.26452 0.12222]
21Feb17_103523|Layer 2:
21Feb17_103523|-- Config --
21Feb17_103523|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103523|-- Weights --
21Feb17_103523|[[ 0.67920  0.12119]
21Feb17_103523| [ 0.44836  0.02916]
21Feb17_103523| [ 0.68939  0.31516]
21Feb17_103523| [-0.58995 -0.05861]]
21Feb17_103523|-- Bias --
21Feb17_103523|[ 0.59649 -0.08079]
21Feb17_103523|Layer 3:
21Feb17_103523|-- Config --
21Feb17_103523|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103523|-- Weights --
21Feb17_103523|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_103523| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_103523|-- Bias --
21Feb17_103523|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_103523|Layer 4:
21Feb17_103523|-- Config --
21Feb17_103523|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103523|-- Weights --
21Feb17_103523|[[-0.03514 -1.04833]
21Feb17_103523| [ 1.25238  0.62094]
21Feb17_103523| [ 0.99203  0.37406]
21Feb17_103523| [ 0.49902  0.67158]
21Feb17_103523| [-1.35709  0.38335]]
21Feb17_103523|-- Bias --
21Feb17_103523|[0.31435 0.36299]
21Feb17_103523|Predicting the validation and test data with the Best final individual.
21Feb17_103531| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_103531|-----------  ------------------  --------------------  ----------
21Feb17_103531|Validation         23.48                  56            0.78306
21Feb17_103531|   Test            22.07                  56            0.85403
21Feb17_103531|-------------------- Test #12 --------------------
21Feb17_103531|Best final individual weights
21Feb17_103531|Individual:
21Feb17_103531|-- Constant hidden layers --
21Feb17_103531|False
21Feb17_103531|Layer 0:
21Feb17_103531|-- Config --
21Feb17_103531|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103531|-- Weights --
21Feb17_103531|[[-0.73212  1.32861  0.10200]
21Feb17_103531| [ 1.48746 -2.97273 -0.42944]
21Feb17_103531| [ 0.53095 -1.50623  0.79224]
21Feb17_103531| [-1.07292 -0.83175 -0.90105]
21Feb17_103531| [-0.48696 -0.89325  0.27226]
21Feb17_103531| [-3.02511  0.34155 -0.03837]
21Feb17_103531| [-0.76747  0.57140 -0.46892]
21Feb17_103531| [-0.07581  0.14713  0.85910]
21Feb17_103531| [-1.37488  0.52170 -0.36205]
21Feb17_103531| [ 1.60981 -0.08727 -0.11267]
21Feb17_103531| [ 0.50986  1.58916 -0.35287]
21Feb17_103531| [-0.34599  1.27113 -0.16393]
21Feb17_103531| [ 1.29203  1.19467  0.37695]
21Feb17_103531| [ 0.58704  0.06328 -0.24240]
21Feb17_103531| [-0.93888 -0.89760  0.57087]
21Feb17_103531| [ 0.99159 -0.66387  0.35177]
21Feb17_103531| [-0.67119  1.06910 -0.12512]
21Feb17_103531| [-0.91534  1.23744 -0.40465]
21Feb17_103531| [ 1.39278  0.08069  0.23328]
21Feb17_103531| [ 0.09880  0.57603 -0.96101]
21Feb17_103531| [ 0.01621 -0.13343 -0.27624]
21Feb17_103531| [-1.28286 -2.28909  0.37931]
21Feb17_103531| [-0.28370  0.09336  0.01547]
21Feb17_103531| [-0.51894  1.84280 -0.25906]
21Feb17_103531| [-0.83075 -0.04508  0.12107]
21Feb17_103531| [ 0.37343  1.18436 -0.07358]
21Feb17_103531| [-2.38657 -0.35191  0.01962]
21Feb17_103531| [ 0.95757 -0.91760 -0.08971]
21Feb17_103531| [ 0.38792 -0.01880  0.69717]
21Feb17_103531| [ 1.66877 -0.58078 -1.21129]
21Feb17_103531| [-0.50943  0.59080  0.30856]
21Feb17_103531| [ 0.30163  1.11518  0.98185]
21Feb17_103531| [-0.73226  0.32281 -0.66712]
21Feb17_103531| [-0.62054 -2.21049  1.40981]
21Feb17_103531| [ 1.23185 -0.58090  0.35844]
21Feb17_103531| [-0.05616  0.24219 -0.02853]
21Feb17_103531| [-1.05085 -2.30259 -0.16276]
21Feb17_103531| [ 0.71087  0.14900  1.13430]
21Feb17_103531| [-2.45877 -1.20999 -1.04986]
21Feb17_103531| [-1.00480  1.36344 -0.13998]
21Feb17_103531| [ 1.83140 -0.91532  0.07616]
21Feb17_103531| [-0.60404 -2.05184  0.76948]
21Feb17_103531| [ 0.52617  0.76042 -1.76746]
21Feb17_103531| [-0.22134  0.17324  0.99530]
21Feb17_103531| [-0.36427  1.34655  0.02110]
21Feb17_103531| [-0.93125 -0.33620 -0.25012]
21Feb17_103531| [-2.76428  0.14487  0.48096]
21Feb17_103531| [-0.10518  0.35052  1.71840]
21Feb17_103531| [-1.27998  1.12568  1.26523]
21Feb17_103531| [-0.60698  1.53230 -0.60824]
21Feb17_103531| [ 0.02898  2.98718 -0.59153]
21Feb17_103531| [ 0.17588 -0.00449  0.50797]
21Feb17_103531| [-1.42674 -0.54967 -0.21310]
21Feb17_103531| [ 1.03196  1.18733  0.36755]
21Feb17_103531| [ 1.04748 -1.47444 -0.08469]
21Feb17_103531| [ 0.49410  0.38745  0.68469]
21Feb17_103531| [-0.62880  0.73245  0.19964]]
21Feb17_103531|-- Bias --
21Feb17_103531|[-0.18798  0.64571 -0.23142]
21Feb17_103531|Layer 1:
21Feb17_103531|-- Config --
21Feb17_103531|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103531|-- Weights --
21Feb17_103531|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_103531| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_103531| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_103531|-- Bias --
21Feb17_103531|[0.60477 0.03773 0.26452 0.12222]
21Feb17_103531|Layer 2:
21Feb17_103531|-- Config --
21Feb17_103531|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103531|-- Weights --
21Feb17_103531|[[ 0.67920  0.12119]
21Feb17_103531| [ 0.44836  0.02916]
21Feb17_103531| [ 0.68939  0.31516]
21Feb17_103531| [-0.58995 -0.05861]]
21Feb17_103531|-- Bias --
21Feb17_103531|[ 0.59649 -0.08079]
21Feb17_103531|Layer 3:
21Feb17_103531|-- Config --
21Feb17_103531|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103531|-- Weights --
21Feb17_103531|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_103531| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_103531|-- Bias --
21Feb17_103531|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_103531|Layer 4:
21Feb17_103531|-- Config --
21Feb17_103531|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103531|-- Weights --
21Feb17_103531|[[-0.03514 -1.04833]
21Feb17_103531| [ 1.25238  0.62094]
21Feb17_103531| [ 0.99203  0.37406]
21Feb17_103531| [ 0.49902  0.67158]
21Feb17_103531| [-1.35709  0.38335]]
21Feb17_103531|-- Bias --
21Feb17_103531|[0.31435 0.36299]
21Feb17_103531|Predicting the validation and test data with the Best final individual.
21Feb17_103539| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_103539|-----------  ------------------  --------------------  ----------
21Feb17_103539|Validation         24.43                  56            0.85301
21Feb17_103539|   Test            37.01                  56            0.82036
21Feb17_103539|-------------------- Test #13 --------------------
21Feb17_103539|Best final individual weights
21Feb17_103539|Individual:
21Feb17_103539|-- Constant hidden layers --
21Feb17_103539|False
21Feb17_103539|Layer 0:
21Feb17_103539|-- Config --
21Feb17_103539|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103539|-- Weights --
21Feb17_103539|[[-0.73212  1.32861  0.10200]
21Feb17_103539| [ 1.48746 -2.97273 -0.42944]
21Feb17_103539| [ 0.53095 -1.50623  0.79224]
21Feb17_103539| [-1.07292 -0.83175 -0.90105]
21Feb17_103539| [-0.48696 -0.89325  0.27226]
21Feb17_103539| [-3.02511  0.34155 -0.03837]
21Feb17_103539| [-0.76747  0.57140 -0.46892]
21Feb17_103539| [-0.07581  0.14713  0.85910]
21Feb17_103539| [-1.37488  0.52170 -0.36205]
21Feb17_103539| [ 1.60981 -0.08727 -0.11267]
21Feb17_103539| [ 0.50986  1.58916 -0.35287]
21Feb17_103539| [-0.34599  1.27113 -0.16393]
21Feb17_103539| [ 1.29203  1.19467  0.37695]
21Feb17_103539| [ 0.58704  0.06328 -0.24240]
21Feb17_103539| [-0.93888 -0.89760  0.57087]
21Feb17_103539| [ 0.99159 -0.66387  0.35177]
21Feb17_103539| [-0.67119  1.06910 -0.12512]
21Feb17_103539| [-0.91534  1.23744 -0.40465]
21Feb17_103539| [ 1.39278  0.08069  0.23328]
21Feb17_103539| [ 0.09880  0.57603 -0.96101]
21Feb17_103539| [ 0.01621 -0.13343 -0.27624]
21Feb17_103539| [-1.28286 -2.28909  0.37931]
21Feb17_103539| [-0.28370  0.09336  0.01547]
21Feb17_103539| [-0.51894  1.84280 -0.25906]
21Feb17_103539| [-0.83075 -0.04508  0.12107]
21Feb17_103539| [ 0.37343  1.18436 -0.07358]
21Feb17_103539| [-2.38657 -0.35191  0.01962]
21Feb17_103539| [ 0.95757 -0.91760 -0.08971]
21Feb17_103539| [ 0.38792 -0.01880  0.69717]
21Feb17_103539| [ 1.66877 -0.58078 -1.21129]
21Feb17_103539| [-0.50943  0.59080  0.30856]
21Feb17_103539| [ 0.30163  1.11518  0.98185]
21Feb17_103539| [-0.73226  0.32281 -0.66712]
21Feb17_103539| [-0.62054 -2.21049  1.40981]
21Feb17_103539| [ 1.23185 -0.58090  0.35844]
21Feb17_103539| [-0.05616  0.24219 -0.02853]
21Feb17_103539| [-1.05085 -2.30259 -0.16276]
21Feb17_103539| [ 0.71087  0.14900  1.13430]
21Feb17_103539| [-2.45877 -1.20999 -1.04986]
21Feb17_103539| [-1.00480  1.36344 -0.13998]
21Feb17_103539| [ 1.83140 -0.91532  0.07616]
21Feb17_103539| [-0.60404 -2.05184  0.76948]
21Feb17_103539| [ 0.52617  0.76042 -1.76746]
21Feb17_103539| [-0.22134  0.17324  0.99530]
21Feb17_103539| [-0.36427  1.34655  0.02110]
21Feb17_103539| [-0.93125 -0.33620 -0.25012]
21Feb17_103539| [-2.76428  0.14487  0.48096]
21Feb17_103539| [-0.10518  0.35052  1.71840]
21Feb17_103539| [-1.27998  1.12568  1.26523]
21Feb17_103539| [-0.60698  1.53230 -0.60824]
21Feb17_103539| [ 0.02898  2.98718 -0.59153]
21Feb17_103539| [ 0.17588 -0.00449  0.50797]
21Feb17_103539| [-1.42674 -0.54967 -0.21310]
21Feb17_103539| [ 1.03196  1.18733  0.36755]
21Feb17_103539| [ 1.04748 -1.47444 -0.08469]
21Feb17_103539| [ 0.49410  0.38745  0.68469]
21Feb17_103539| [-0.62880  0.73245  0.19964]]
21Feb17_103539|-- Bias --
21Feb17_103539|[-0.18798  0.64571 -0.23142]
21Feb17_103539|Layer 1:
21Feb17_103539|-- Config --
21Feb17_103539|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103539|-- Weights --
21Feb17_103539|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_103539| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_103539| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_103539|-- Bias --
21Feb17_103539|[0.60477 0.03773 0.26452 0.12222]
21Feb17_103539|Layer 2:
21Feb17_103539|-- Config --
21Feb17_103539|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103539|-- Weights --
21Feb17_103539|[[ 0.67920  0.12119]
21Feb17_103539| [ 0.44836  0.02916]
21Feb17_103539| [ 0.68939  0.31516]
21Feb17_103539| [-0.58995 -0.05861]]
21Feb17_103539|-- Bias --
21Feb17_103539|[ 0.59649 -0.08079]
21Feb17_103539|Layer 3:
21Feb17_103539|-- Config --
21Feb17_103539|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103539|-- Weights --
21Feb17_103539|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_103539| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_103539|-- Bias --
21Feb17_103539|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_103539|Layer 4:
21Feb17_103539|-- Config --
21Feb17_103539|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103539|-- Weights --
21Feb17_103539|[[-0.03514 -1.04833]
21Feb17_103539| [ 1.25238  0.62094]
21Feb17_103539| [ 0.99203  0.37406]
21Feb17_103539| [ 0.49902  0.67158]
21Feb17_103539| [-1.35709  0.38335]]
21Feb17_103539|-- Bias --
21Feb17_103539|[0.31435 0.36299]
21Feb17_103539|Predicting the validation and test data with the Best final individual.
21Feb17_103547| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_103547|-----------  ------------------  --------------------  ----------
21Feb17_103547|Validation         21.74                  56            0.74120
21Feb17_103547|   Test            25.80                  56            0.72926
21Feb17_103547|-------------------- Test #14 --------------------
21Feb17_103547|Best final individual weights
21Feb17_103547|Individual:
21Feb17_103547|-- Constant hidden layers --
21Feb17_103547|False
21Feb17_103547|Layer 0:
21Feb17_103547|-- Config --
21Feb17_103547|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103547|-- Weights --
21Feb17_103547|[[-0.73212  1.32861  0.10200]
21Feb17_103547| [ 1.48746 -2.97273 -0.42944]
21Feb17_103547| [ 0.53095 -1.50623  0.79224]
21Feb17_103547| [-1.07292 -0.83175 -0.90105]
21Feb17_103547| [-0.48696 -0.89325  0.27226]
21Feb17_103547| [-3.02511  0.34155 -0.03837]
21Feb17_103547| [-0.76747  0.57140 -0.46892]
21Feb17_103547| [-0.07581  0.14713  0.85910]
21Feb17_103547| [-1.37488  0.52170 -0.36205]
21Feb17_103547| [ 1.60981 -0.08727 -0.11267]
21Feb17_103547| [ 0.50986  1.58916 -0.35287]
21Feb17_103547| [-0.34599  1.27113 -0.16393]
21Feb17_103547| [ 1.29203  1.19467  0.37695]
21Feb17_103547| [ 0.58704  0.06328 -0.24240]
21Feb17_103547| [-0.93888 -0.89760  0.57087]
21Feb17_103547| [ 0.99159 -0.66387  0.35177]
21Feb17_103547| [-0.67119  1.06910 -0.12512]
21Feb17_103547| [-0.91534  1.23744 -0.40465]
21Feb17_103547| [ 1.39278  0.08069  0.23328]
21Feb17_103547| [ 0.09880  0.57603 -0.96101]
21Feb17_103547| [ 0.01621 -0.13343 -0.27624]
21Feb17_103547| [-1.28286 -2.28909  0.37931]
21Feb17_103547| [-0.28370  0.09336  0.01547]
21Feb17_103547| [-0.51894  1.84280 -0.25906]
21Feb17_103547| [-0.83075 -0.04508  0.12107]
21Feb17_103547| [ 0.37343  1.18436 -0.07358]
21Feb17_103547| [-2.38657 -0.35191  0.01962]
21Feb17_103547| [ 0.95757 -0.91760 -0.08971]
21Feb17_103547| [ 0.38792 -0.01880  0.69717]
21Feb17_103547| [ 1.66877 -0.58078 -1.21129]
21Feb17_103547| [-0.50943  0.59080  0.30856]
21Feb17_103547| [ 0.30163  1.11518  0.98185]
21Feb17_103547| [-0.73226  0.32281 -0.66712]
21Feb17_103547| [-0.62054 -2.21049  1.40981]
21Feb17_103547| [ 1.23185 -0.58090  0.35844]
21Feb17_103547| [-0.05616  0.24219 -0.02853]
21Feb17_103547| [-1.05085 -2.30259 -0.16276]
21Feb17_103547| [ 0.71087  0.14900  1.13430]
21Feb17_103547| [-2.45877 -1.20999 -1.04986]
21Feb17_103547| [-1.00480  1.36344 -0.13998]
21Feb17_103547| [ 1.83140 -0.91532  0.07616]
21Feb17_103547| [-0.60404 -2.05184  0.76948]
21Feb17_103547| [ 0.52617  0.76042 -1.76746]
21Feb17_103547| [-0.22134  0.17324  0.99530]
21Feb17_103547| [-0.36427  1.34655  0.02110]
21Feb17_103547| [-0.93125 -0.33620 -0.25012]
21Feb17_103547| [-2.76428  0.14487  0.48096]
21Feb17_103547| [-0.10518  0.35052  1.71840]
21Feb17_103547| [-1.27998  1.12568  1.26523]
21Feb17_103547| [-0.60698  1.53230 -0.60824]
21Feb17_103547| [ 0.02898  2.98718 -0.59153]
21Feb17_103547| [ 0.17588 -0.00449  0.50797]
21Feb17_103547| [-1.42674 -0.54967 -0.21310]
21Feb17_103547| [ 1.03196  1.18733  0.36755]
21Feb17_103547| [ 1.04748 -1.47444 -0.08469]
21Feb17_103547| [ 0.49410  0.38745  0.68469]
21Feb17_103547| [-0.62880  0.73245  0.19964]]
21Feb17_103547|-- Bias --
21Feb17_103547|[-0.18798  0.64571 -0.23142]
21Feb17_103547|Layer 1:
21Feb17_103547|-- Config --
21Feb17_103547|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103547|-- Weights --
21Feb17_103547|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_103547| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_103547| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_103547|-- Bias --
21Feb17_103547|[0.60477 0.03773 0.26452 0.12222]
21Feb17_103547|Layer 2:
21Feb17_103547|-- Config --
21Feb17_103547|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103547|-- Weights --
21Feb17_103547|[[ 0.67920  0.12119]
21Feb17_103547| [ 0.44836  0.02916]
21Feb17_103547| [ 0.68939  0.31516]
21Feb17_103547| [-0.58995 -0.05861]]
21Feb17_103547|-- Bias --
21Feb17_103547|[ 0.59649 -0.08079]
21Feb17_103547|Layer 3:
21Feb17_103547|-- Config --
21Feb17_103547|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103547|-- Weights --
21Feb17_103547|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_103547| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_103547|-- Bias --
21Feb17_103547|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_103547|Layer 4:
21Feb17_103547|-- Config --
21Feb17_103547|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_103547|-- Weights --
21Feb17_103547|[[-0.03514 -1.04833]
21Feb17_103547| [ 1.25238  0.62094]
21Feb17_103547| [ 0.99203  0.37406]
21Feb17_103547| [ 0.49902  0.67158]
21Feb17_103547| [-1.35709  0.38335]]
21Feb17_103547|-- Bias --
21Feb17_103547|[0.31435 0.36299]
21Feb17_103547|Predicting the validation and test data with the Best final individual.
21Feb17_103555| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_103555|-----------  ------------------  --------------------  ----------
21Feb17_103555|Validation         22.70                  56            0.74363
21Feb17_103555|   Test            19.46                  56            0.73101
Using Theano backend.
WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.
2021-02-17 10:35:57.387988: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-02-17 10:35:57.388056: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
21Feb17_103558|Data summary: Train
21Feb17_103558|data.shape = (2300, 57)
21Feb17_103558|labels.shape = (2300,)
21Feb17_103558|Class distribution:
21Feb17_103558|	0 - 1389 (0.60)
21Feb17_103558|	1 - 911 (0.40)
21Feb17_103558|Data summary: Validation
21Feb17_103558|data.shape = (1150, 57)
21Feb17_103558|labels.shape = (1150,)
21Feb17_103558|Class distribution:
21Feb17_103558|	0 - 667 (0.58)
21Feb17_103558|	1 - 483 (0.42)
21Feb17_103558|Data summary: Test
21Feb17_103558|data.shape = (1151, 57)
21Feb17_103558|labels.shape = (1151,)
21Feb17_103558|Class distribution:
21Feb17_103558|	0 - 732 (0.64)
21Feb17_103558|	1 - 419 (0.36)
21Feb17_103558|Selected configuration values
21Feb17_103558|-- Dataset name: spambase2
21Feb17_103558|-- Initial population size: 64
21Feb17_103558|-- Maximun number of generations: 32
21Feb17_103558|-- Neurons per hidden layer range: (2, 20)
21Feb17_103558|-- Hidden layers number range: (1, 3)
21Feb17_103558|-- Crossover probability: 0.5
21Feb17_103558|-- Bias gene mutation probability: 0.2
21Feb17_103558|-- Weights gene mutation probability: 0.75
21Feb17_103558|-- Neuron mutation probability: 0.3
21Feb17_103558|-- Layer mutation probability: 0.3
21Feb17_103558|-- Constant hidden layers: False
21Feb17_103558|-- Seed: 31415
21Feb17_103558|Entering GA
21Feb17_103558|Start the algorithm
21Feb17_103939|-- Generation 1 --
21Feb17_103939|    -- Crossed 0 individual pairs.
21Feb17_103939|    -- Mutated 32 individuals.
21Feb17_104259|    -- Evaluated 64 individuals.
21Feb17_104259|    Summary of generation 1:
21Feb17_104259| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_104259|-----------  ------------------  --------------------  ----------
21Feb17_104259|    Max            42.70                78.00           0.43478
21Feb17_104259|    Avg            41.90                26.28           0.00941
21Feb17_104259|    Min            35.91                 2.00           0.00000
21Feb17_104259|    Std             0.81                18.75           0.05509
21Feb17_104259|   Best            35.91                18.00           0.43478
21Feb17_104259|-- Generation 2 --
21Feb17_104259|    -- Crossed 1 individual pairs.
21Feb17_104259|    -- Mutated 32 individuals.
21Feb17_104613|    -- Evaluated 64 individuals.
21Feb17_104613|    Summary of generation 2:
21Feb17_104613| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_104613|-----------  ------------------  --------------------  ----------
21Feb17_104613|    Max            58.00                84.00           0.79977
21Feb17_104613|    Avg            41.99                15.92           0.02879
21Feb17_104613|    Min            29.65                 2.00           0.00000
21Feb17_104613|    Std             2.55                13.60           0.13781
21Feb17_104613|   Best            29.65                18.00           0.79977
21Feb17_104613|-- Generation 3 --
21Feb17_104613|    -- Crossed 3 individual pairs.
21Feb17_104613|    -- Mutated 32 individuals.
21Feb17_104926|    -- Evaluated 64 individuals.
21Feb17_104926|    Summary of generation 3:
21Feb17_104926| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_104926|-----------  ------------------  --------------------  ----------
21Feb17_104926|    Max            58.00                50.00           0.78358
21Feb17_104926|    Avg            41.97                13.73           0.02564
21Feb17_104926|    Min            26.09                 2.00           0.00000
21Feb17_104926|    Std             2.83                12.88           0.13211
21Feb17_104926|   Best            26.09                18.00           0.73476
21Feb17_104926|-- Generation 4 --
21Feb17_104926|    -- Crossed 4 individual pairs.
21Feb17_104926|    -- Mutated 32 individuals.
21Feb17_105235|    -- Evaluated 64 individuals.
21Feb17_105235|    Summary of generation 4:
21Feb17_105235| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_105235|-----------  ------------------  --------------------  ----------
21Feb17_105235|    Max            42.17                63.00           0.00517
21Feb17_105235|    Avg            42.01                 8.34           0.00085
21Feb17_105235|    Min            41.91                 2.00           0.00000
21Feb17_105235|    Std             0.06                 9.60           0.00165
21Feb17_105235|   Best            41.91                 4.00           0.00517
21Feb17_105235|-- Generation 5 --
21Feb17_105235|    -- Crossed 6 individual pairs.
21Feb17_105235|    -- Mutated 32 individuals.
21Feb17_105541|    -- Evaluated 64 individuals.
21Feb17_105541|    Summary of generation 5:
21Feb17_105541| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_105541|-----------  ------------------  --------------------  ----------
21Feb17_105541|    Max            42.09                20.00           0.05344
21Feb17_105541|    Avg            41.98                 5.28           0.00172
21Feb17_105541|    Min            41.22                 2.00           0.00000
21Feb17_105541|    Std             0.11                 4.46           0.00681
21Feb17_105541|   Best            41.22                14.00           0.05344
21Feb17_105541|-- Generation 6 --
21Feb17_105541|    -- Crossed 7 individual pairs.
21Feb17_105541|    -- Mutated 32 individuals.
21Feb17_105849|    -- Evaluated 64 individuals.
21Feb17_105849|    Summary of generation 6:
21Feb17_105849| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_105849|-----------  ------------------  --------------------  ----------
21Feb17_105849|    Max            42.26                18.00           0.01548
21Feb17_105849|    Avg            41.99                 6.00           0.00105
21Feb17_105849|    Min            41.48                 2.00           0.00000
21Feb17_105849|    Std             0.09                 4.81           0.00231
21Feb17_105849|   Best            41.48                 3.00           0.01548
21Feb17_105849|-- Generation 7 --
21Feb17_105849|    -- Crossed 9 individual pairs.
21Feb17_105849|    -- Mutated 32 individuals.
21Feb17_110157|    -- Evaluated 64 individuals.
21Feb17_110157|    Summary of generation 7:
21Feb17_110157| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_110157|-----------  ------------------  --------------------  ----------
21Feb17_110157|    Max            42.09                36.00           0.01033
21Feb17_110157|    Avg            41.99                 5.98           0.00089
21Feb17_110157|    Min            41.65                 2.00           0.00000
21Feb17_110157|    Std             0.06                 6.14           0.00184
21Feb17_110157|   Best            41.65                 3.00           0.01033
21Feb17_110157|-- Generation 8 --
21Feb17_110157|    -- Crossed 9 individual pairs.
21Feb17_110157|    -- Mutated 32 individuals.
21Feb17_110503|    -- Evaluated 64 individuals.
21Feb17_110503|    Summary of generation 8:
21Feb17_110503| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_110503|-----------  ------------------  --------------------  ----------
21Feb17_110503|    Max            42.17                18.00           0.04103
21Feb17_110503|    Avg            41.97                 5.09           0.00169
21Feb17_110503|    Min            40.78                 2.00           0.00000
21Feb17_110503|    Std             0.16                 4.37           0.00529
21Feb17_110503|   Best            40.78                12.00           0.04103
21Feb17_110503|-- Generation 9 --
21Feb17_110503|    -- Crossed 8 individual pairs.
21Feb17_110503|    -- Mutated 32 individuals.
21Feb17_110811|    -- Evaluated 64 individuals.
21Feb17_110811|    Summary of generation 9:
21Feb17_110811| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_110811|-----------  ------------------  --------------------  ----------
21Feb17_110811|    Max            48.87                18.00           0.80667
21Feb17_110811|    Avg            41.71                 6.17           0.03823
21Feb17_110811|    Min            30.61                 2.00           0.00000
21Feb17_110811|    Std             2.17                 5.04           0.16210
21Feb17_110811|   Best            30.61                 8.00           0.78607
21Feb17_110811|-- Generation 10 --
21Feb17_110811|    -- Crossed 5 individual pairs.
21Feb17_110811|    -- Mutated 32 individuals.
21Feb17_111117|    -- Evaluated 64 individuals.
21Feb17_111117|    Summary of generation 10:
21Feb17_111117| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_111117|-----------  ------------------  --------------------  ----------
21Feb17_111117|    Max            42.26                18.00           0.58344
21Feb17_111117|    Avg            41.43                 6.23           0.02714
21Feb17_111117|    Min            27.74                 2.00           0.00000
21Feb17_111117|    Std             2.43                 4.89           0.10887
21Feb17_111117|   Best            27.74                18.00           0.51616
21Feb17_111117|-- Generation 11 --
21Feb17_111117|    -- Crossed 8 individual pairs.
21Feb17_111117|    -- Mutated 32 individuals.
21Feb17_111428|    -- Evaluated 64 individuals.
21Feb17_111428|    Summary of generation 11:
21Feb17_111428| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_111428|-----------  ------------------  --------------------  ----------
21Feb17_111428|    Max            58.00                34.00           0.78358
21Feb17_111428|    Avg            41.87                 7.95           0.03476
21Feb17_111428|    Min            28.00                 2.00           0.00000
21Feb17_111428|    Std             2.88                 6.49           0.14854
21Feb17_111428|   Best            28.00                 8.00           0.52079
21Feb17_111428|-- Generation 12 --
21Feb17_111428|    -- Crossed 3 individual pairs.
21Feb17_111428|    -- Mutated 32 individuals.
21Feb17_111736|    -- Evaluated 64 individuals.
21Feb17_111736|    Summary of generation 12:
21Feb17_111736| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_111736|-----------  ------------------  --------------------  ----------
21Feb17_111736|    Max            42.35                36.00           0.67494
21Feb17_111736|    Avg            41.46                 7.03           0.02217
21Feb17_111736|    Min            24.96                 2.00           0.00000
21Feb17_111736|    Std             2.67                 5.88           0.11025
21Feb17_111736|   Best            24.96                18.00           0.67494
21Feb17_111736|-- Generation 13 --
21Feb17_111736|    -- Crossed 5 individual pairs.
21Feb17_111736|    -- Mutated 32 individuals.
21Feb17_112046|    -- Evaluated 64 individuals.
21Feb17_112046|    Summary of generation 13:
21Feb17_112046| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_112046|-----------  ------------------  --------------------  ----------
21Feb17_112046|    Max            42.61                36.00           0.61562
21Feb17_112046|    Avg            41.50                 8.56           0.02210
21Feb17_112046|    Min            26.78                 2.00           0.00000
21Feb17_112046|    Std             2.40                 7.93           0.10577
21Feb17_112046|   Best            26.78                18.00           0.61562
21Feb17_112046|-- Generation 14 --
21Feb17_112046|    -- Crossed 7 individual pairs.
21Feb17_112046|    -- Mutated 32 individuals.
21Feb17_112356|    -- Evaluated 64 individuals.
21Feb17_112356|    Summary of generation 14:
21Feb17_112356| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_112356|-----------  ------------------  --------------------  ----------
21Feb17_112356|    Max            42.09                40.00           0.75188
21Feb17_112356|    Avg            41.48                 8.12           0.02679
21Feb17_112356|    Min            27.65                 2.00           0.00000
21Feb17_112356|    Std             2.42                 6.72           0.13015
21Feb17_112356|   Best            27.65                18.00           0.75188
21Feb17_112356|-- Generation 15 --
21Feb17_112356|    -- Crossed 6 individual pairs.
21Feb17_112356|    -- Mutated 32 individuals.
21Feb17_112706|    -- Evaluated 64 individuals.
21Feb17_112706|    Summary of generation 15:
21Feb17_112706| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_112706|-----------  ------------------  --------------------  ----------
21Feb17_112706|    Max            42.09                40.00           0.73387
21Feb17_112706|    Avg            41.42                 7.69           0.02610
21Feb17_112706|    Min            26.35                 2.00           0.00000
21Feb17_112706|    Std             2.71                 6.44           0.12590
21Feb17_112706|   Best            26.35                18.00           0.71951
21Feb17_112706|-- Generation 16 --
21Feb17_112706|    -- Crossed 5 individual pairs.
21Feb17_112706|    -- Mutated 32 individuals.
21Feb17_113015|    -- Evaluated 64 individuals.
21Feb17_113015|    Summary of generation 16:
21Feb17_113015| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_113015|-----------  ------------------  --------------------  ----------
21Feb17_113015|    Max            42.26                44.00           0.82855
21Feb17_113015|    Avg            41.21                 7.83           0.03973
21Feb17_113015|    Min            24.87                 2.00           0.00000
21Feb17_113015|    Std             3.23                 7.99           0.16234
21Feb17_113015|   Best            24.87                21.00           0.68287
21Feb17_113015|-- Generation 17 --
21Feb17_113015|    -- Crossed 8 individual pairs.
21Feb17_113015|    -- Mutated 32 individuals.
21Feb17_113326|    -- Evaluated 64 individuals.
21Feb17_113326|    Summary of generation 17:
21Feb17_113326| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_113326|-----------  ------------------  --------------------  ----------
21Feb17_113326|    Max            42.26                44.00           0.80877
21Feb17_113326|    Avg            40.86                 8.81           0.06413
21Feb17_113326|    Min            25.04                 2.00           0.00000
21Feb17_113326|    Std             3.59                 8.94           0.19340
21Feb17_113326|   Best            25.04                10.00           0.72247
21Feb17_113326|-- Generation 18 --
21Feb17_113326|    -- Crossed 2 individual pairs.
21Feb17_113326|    -- Mutated 32 individuals.
21Feb17_113640|    -- Evaluated 64 individuals.
21Feb17_113640|    Summary of generation 18:
21Feb17_113640| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_113640|-----------  ------------------  --------------------  ----------
21Feb17_113640|    Max            47.04                44.00           0.81211
21Feb17_113640|    Avg            39.55                10.78           0.12108
21Feb17_113640|    Min            24.35                 3.00           0.00000
21Feb17_113640|    Std             5.74                11.16           0.25939
21Feb17_113640|   Best            24.35                44.00           0.72485
21Feb17_113640|-- Generation 19 --
21Feb17_113640|    -- Crossed 7 individual pairs.
21Feb17_113640|    -- Mutated 32 individuals.
21Feb17_114000|    -- Evaluated 64 individuals.
21Feb17_114000|    Summary of generation 19:
21Feb17_114000| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_114000|-----------  ------------------  --------------------  ----------
21Feb17_114000|    Max            42.87                70.00           0.81774
21Feb17_114000|    Avg            39.09                14.53           0.14606
21Feb17_114000|    Min            24.70                 3.00           0.00000
21Feb17_114000|    Std             5.78                15.60           0.27609
21Feb17_114000|   Best            24.70                44.00           0.69102
21Feb17_114000|-- Generation 20 --
21Feb17_114000|    -- Crossed 3 individual pairs.
21Feb17_114000|    -- Mutated 32 individuals.
21Feb17_114324|    -- Evaluated 64 individuals.
21Feb17_114324|    Summary of generation 20:
21Feb17_114324| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_114324|-----------  ------------------  --------------------  ----------
21Feb17_114324|    Max            42.17                60.00           0.79174
21Feb17_114324|    Avg            39.05                15.47           0.15453
21Feb17_114324|    Min            24.09                 3.00           0.00000
21Feb17_114324|    Std             5.60                16.03           0.28335
21Feb17_114324|   Best            24.09                48.00           0.76568
21Feb17_114324|-- Generation 21 --
21Feb17_114324|    -- Crossed 4 individual pairs.
21Feb17_114324|    -- Mutated 32 individuals.
21Feb17_114653|    -- Evaluated 64 individuals.
21Feb17_114653|    Summary of generation 21:
21Feb17_114653| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_114653|-----------  ------------------  --------------------  ----------
21Feb17_114653|    Max            42.17                90.00           0.80579
21Feb17_114653|    Avg            38.34                18.45           0.19938
21Feb17_114653|    Min            23.91                 2.00           0.00000
21Feb17_114653|    Std             5.87                19.09           0.30554
21Feb17_114653|   Best            23.91                48.00           0.71458
21Feb17_114653|-- Generation 22 --
21Feb17_114653|    -- Crossed 2 individual pairs.
21Feb17_114653|    -- Mutated 32 individuals.
21Feb17_115028|    -- Evaluated 64 individuals.
21Feb17_115028|    Summary of generation 22:
21Feb17_115028| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_115028|-----------  ------------------  --------------------  ----------
21Feb17_115028|    Max            42.09                60.00           0.82362
21Feb17_115028|    Avg            36.71                21.28           0.25981
21Feb17_115028|    Min            24.26                 2.00           0.00000
21Feb17_115028|    Std             6.98                18.25           0.33831
21Feb17_115028|   Best            24.26                52.00           0.76087
21Feb17_115028|-- Generation 23 --
21Feb17_115028|    -- Crossed 2 individual pairs.
21Feb17_115028|    -- Mutated 32 individuals.
21Feb17_115413|    -- Evaluated 64 individuals.
21Feb17_115413|    Summary of generation 23:
21Feb17_115413| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_115413|-----------  ------------------  --------------------  ----------
21Feb17_115413|    Max            42.09                96.00           0.78772
21Feb17_115413|    Avg            35.35                29.28           0.32114
21Feb17_115413|    Min            23.39                 2.00           0.00000
21Feb17_115413|    Std             7.15                21.95           0.34435
21Feb17_115413|   Best            23.39                52.00           0.72814
21Feb17_115413|-- Generation 24 --
21Feb17_115413|    -- Crossed 0 individual pairs.
21Feb17_115413|    -- Mutated 32 individuals.
21Feb17_115809|    -- Evaluated 64 individuals.
21Feb17_115809|    Summary of generation 24:
21Feb17_115809| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_115809|-----------  ------------------  --------------------  ----------
21Feb17_115809|    Max            43.30                80.00           0.82075
21Feb17_115809|    Avg            33.81                36.61           0.38588
21Feb17_115809|    Min            23.22                 2.00           0.00000
21Feb17_115809|    Std             7.30                19.72           0.34184
21Feb17_115809|   Best            23.22                52.00           0.73602
21Feb17_115809|-- Generation 25 --
21Feb17_115809|    -- Crossed 3 individual pairs.
21Feb17_115809|    -- Mutated 32 individuals.
21Feb17_120215|    -- Evaluated 64 individuals.
21Feb17_120215|    Summary of generation 25:
21Feb17_120215| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_120215|-----------  ------------------  --------------------  ----------
21Feb17_120215|    Max            51.74                114.00          0.82799
21Feb17_120215|    Avg            33.58                45.08           0.45457
21Feb17_120215|    Min            23.91                 8.00           0.00000
21Feb17_120215|    Std             7.24                19.61           0.35022
21Feb17_120215|   Best            23.91                48.00           0.72048
21Feb17_120215|-- Generation 26 --
21Feb17_120215|    -- Crossed 1 individual pairs.
21Feb17_120215|    -- Mutated 32 individuals.
21Feb17_120622|    -- Evaluated 64 individuals.
21Feb17_120622|    Summary of generation 26:
21Feb17_120622| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_120622|-----------  ------------------  --------------------  ----------
21Feb17_120622|    Max            42.35                108.00          0.84388
21Feb17_120622|    Avg            32.71                48.80           0.44554
21Feb17_120622|    Min            23.30                 2.00           0.00000
21Feb17_120622|    Std             7.16                22.53           0.33996
21Feb17_120622|   Best            23.30                24.00           0.69415
21Feb17_120622|-- Generation 27 --
21Feb17_120622|    -- Crossed 1 individual pairs.
21Feb17_120622|    -- Mutated 32 individuals.
21Feb17_121032|    -- Evaluated 64 individuals.
21Feb17_121032|    Summary of generation 27:
21Feb17_121032| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_121032|-----------  ------------------  --------------------  ----------
21Feb17_121032|    Max            42.26                132.00          0.82552
21Feb17_121032|    Avg            32.16                51.20           0.45948
21Feb17_121032|    Min            21.74                 8.00           0.00000
21Feb17_121032|    Std             7.19                22.48           0.32234
21Feb17_121032|   Best            21.74                18.00           0.76278
21Feb17_121032|-- Generation 28 --
21Feb17_121032|    -- Crossed 0 individual pairs.
21Feb17_121032|    -- Mutated 32 individuals.
21Feb17_121440|    -- Evaluated 64 individuals.
21Feb17_121440|    Summary of generation 28:
21Feb17_121440| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_121440|-----------  ------------------  --------------------  ----------
21Feb17_121440|    Max            42.00                132.00          0.83850
21Feb17_121440|    Avg            31.52                51.11           0.49187
21Feb17_121440|    Min            23.04                12.00           0.00000
21Feb17_121440|    Std             6.86                24.66           0.32040
21Feb17_121440|   Best            23.04                24.00           0.73226
21Feb17_121440|-- Generation 29 --
21Feb17_121440|    -- Crossed 0 individual pairs.
21Feb17_121440|    -- Mutated 32 individuals.
21Feb17_121845|    -- Evaluated 64 individuals.
21Feb17_121845|    Summary of generation 29:
21Feb17_121845| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_121845|-----------  ------------------  --------------------  ----------
21Feb17_121845|    Max            42.09                132.00          0.82871
21Feb17_121845|    Avg            32.10                49.19           0.44677
21Feb17_121845|    Min            22.26                12.00           0.00000
21Feb17_121845|    Std             7.60                23.20           0.33800
21Feb17_121845|   Best            22.26                56.00           0.74227
21Feb17_121845|-- Generation 30 --
21Feb17_121845|    -- Crossed 0 individual pairs.
21Feb17_121845|    -- Mutated 32 individuals.
21Feb17_122251|    -- Evaluated 64 individuals.
21Feb17_122251|    Summary of generation 30:
21Feb17_122251| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_122251|-----------  ------------------  --------------------  ----------
21Feb17_122251|    Max            42.09                100.00          0.82371
21Feb17_122251|    Avg            31.14                49.09           0.49033
21Feb17_122251|    Min            22.00                14.00           0.00000
21Feb17_122251|    Std             7.06                18.85           0.31415
21Feb17_122251|   Best            22.00                56.00           0.78704
21Feb17_122251|-- Generation 31 --
21Feb17_122251|    -- Crossed 1 individual pairs.
21Feb17_122251|    -- Mutated 32 individuals.
21Feb17_122659|    -- Evaluated 64 individuals.
21Feb17_122659|    Summary of generation 31:
21Feb17_122659| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_122659|-----------  ------------------  --------------------  ----------
21Feb17_122659|    Max            42.52                100.00          0.83333
21Feb17_122659|    Avg            32.54                52.38           0.44410
21Feb17_122659|    Min            22.96                 8.00           0.00000
21Feb17_122659|    Std             7.42                21.79           0.34342
21Feb17_122659|   Best            22.96                44.00           0.72671
21Feb17_122659|-- Generation 32 --
21Feb17_122659|    -- Crossed 1 individual pairs.
21Feb17_122659|    -- Mutated 32 individuals.
21Feb17_123107|    -- Evaluated 64 individuals.
21Feb17_123107|    Summary of generation 32:
21Feb17_123107| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_123107|-----------  ------------------  --------------------  ----------
21Feb17_123107|    Max            42.00                85.00           0.83038
21Feb17_123107|    Avg            32.40                52.83           0.43440
21Feb17_123107|    Min            21.57                 8.00           0.00000
21Feb17_123107|    Std             7.70                18.10           0.34013
21Feb17_123107|   Best            21.57                56.00           0.83038
21Feb17_123107|Best initial individual weights
21Feb17_123107|Individual:
21Feb17_123107|-- Constant hidden layers --
21Feb17_123107|False
21Feb17_123107|Layer 0:
21Feb17_123107|-- Config --
21Feb17_123107|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 12, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123107|-- Weights --
21Feb17_123107|[[-3.50529e-01 -6.53069e-03 -7.03730e-01 -6.33906e-01  6.10835e-02
21Feb17_123107|   4.57449e-01 -3.77835e-01  6.38481e-01  4.24141e-01  6.68786e-01
21Feb17_123107|  -4.86511e-01 -9.28542e-01]
21Feb17_123107| [-8.31270e-01 -3.94586e-01  5.51697e-02 -8.86387e-01 -6.99786e-01
21Feb17_123107|   6.44047e-01 -5.40571e-01  3.77503e-01  1.70193e-01  5.92883e-01
21Feb17_123107|   2.06540e-01  2.18639e-01]
21Feb17_123107| [-8.13637e-01  7.25044e-01  6.66092e-01  5.31057e-01 -4.48634e-01
21Feb17_123107|  -1.62601e-01 -1.57458e-02  7.74238e-02 -4.81841e-01  3.55485e-02
21Feb17_123107|  -7.21169e-01  1.05129e-01]
21Feb17_123107| [ 6.07201e-01  6.23643e-01  8.87343e-01  6.04285e-01  5.70453e-02
21Feb17_123107|   5.99381e-01 -3.21663e-03  6.64196e-01 -5.25584e-01 -1.74507e-02
21Feb17_123107|   3.80029e-01 -4.59585e-01]
21Feb17_123107| [-9.00078e-01  8.63133e-01  8.49324e-01  4.34648e-01 -5.67121e-01
21Feb17_123107|   6.24299e-01 -6.46637e-01  9.34620e-01 -5.42838e-01 -4.04257e-01
21Feb17_123107|  -4.70046e-01  4.29712e-01]
21Feb17_123107| [ 9.51731e-02  8.42954e-01 -7.44806e-01 -5.56045e-02 -4.89209e-01
21Feb17_123107|   8.07612e-01  2.77691e-01 -5.77946e-02  4.30356e-01 -9.05718e-01
21Feb17_123107|  -7.61358e-01 -4.56367e-01]
21Feb17_123107| [-9.06447e-01 -4.46566e-01 -4.40669e-01  6.09161e-01 -3.32587e-01
21Feb17_123107|  -9.31356e-01  9.62597e-02 -1.83060e-01  5.91585e-01 -2.78230e-01
21Feb17_123107|  -3.70976e-01 -3.38510e-01]
21Feb17_123107| [ 5.92999e-02 -5.35945e-01 -8.52259e-01  1.62766e-01 -2.64657e-01
21Feb17_123107|   6.65182e-01  2.45597e-01  2.99711e-01  7.14862e-01 -4.00362e-01
21Feb17_123107|   3.40170e-01 -1.14174e-01]
21Feb17_123107| [-4.26995e-01  8.46146e-01  9.81523e-01 -2.62996e-01  8.65377e-01
21Feb17_123107|  -6.86144e-01 -3.53983e-01 -2.18499e-01  3.29010e-01 -8.26088e-01
21Feb17_123107|   1.48202e-01  5.27152e-01]
21Feb17_123107| [-1.97937e-01  5.44304e-02  9.68680e-01  1.96012e-01  6.66432e-01
21Feb17_123107|  -1.15663e-01  1.01696e-01 -9.91833e-01  5.54656e-02  5.06069e-01
21Feb17_123107|  -8.39702e-01  6.07914e-02]
21Feb17_123107| [ 8.22409e-01 -3.07988e-01 -4.87097e-01 -2.67403e-01 -3.17115e-01
21Feb17_123107|   6.20877e-01  2.45721e-01  1.47039e-01  8.22748e-02 -4.61491e-01
21Feb17_123107|   5.08690e-01 -8.10093e-01]
21Feb17_123107| [-1.03463e-01 -7.13247e-01 -5.27190e-01 -8.14055e-01 -2.20069e-01
21Feb17_123107|   7.58689e-01  7.72478e-01 -3.75243e-01 -1.74773e-01  4.33018e-02
21Feb17_123107|   5.76591e-01 -9.04182e-01]
21Feb17_123107| [ 6.39880e-01 -2.76473e-01  4.48413e-01  7.92996e-01  6.12921e-01
21Feb17_123107|   8.45232e-01 -3.59434e-01 -1.65084e-01  6.00279e-01 -9.07135e-01
21Feb17_123107|  -9.18766e-01 -3.84510e-02]
21Feb17_123107| [-4.35982e-01  3.53117e-01 -4.33635e-01  4.41189e-01  2.02385e-01
21Feb17_123107|  -2.15156e-01 -3.32093e-01 -9.46393e-01  7.49818e-01  7.56840e-01
21Feb17_123107|  -2.97280e-01  3.76513e-01]
21Feb17_123107| [ 2.00098e-01 -3.94368e-01  4.74964e-01 -5.14077e-01 -5.02985e-01
21Feb17_123107|   6.57337e-01  4.54284e-01  7.99434e-01  1.18259e-01  7.90625e-01
21Feb17_123107|  -8.45168e-01 -7.22624e-01]
21Feb17_123107| [ 5.21361e-01 -9.37087e-01  6.98489e-01  7.45747e-01  9.84330e-01
21Feb17_123107|  -1.70463e-01 -4.14211e-01  4.94059e-01 -4.89685e-03 -7.22161e-02
21Feb17_123107|   3.28119e-01 -2.96382e-01]
21Feb17_123107| [ 9.97912e-02 -3.45331e-01 -3.32041e-01 -8.83410e-01  4.64194e-01
21Feb17_123107|  -2.94905e-01 -7.11116e-01 -2.12420e-01  8.93334e-01  5.60374e-01
21Feb17_123107|  -8.11522e-01  3.94537e-01]
21Feb17_123107| [ 2.39284e-01 -9.68110e-02 -3.48403e-01  6.68017e-01  1.07039e-01
21Feb17_123107|  -1.80014e-01 -1.28612e-01 -3.28318e-01  7.99371e-01  7.45882e-01
21Feb17_123107|   4.50426e-01 -9.94601e-02]
21Feb17_123107| [-9.32040e-02 -4.99896e-01 -3.18835e-01 -3.21963e-01  8.88030e-02
21Feb17_123107|   8.24115e-01  3.93190e-01  2.14054e-01 -4.70631e-02  5.36199e-01
21Feb17_123107|   7.72001e-01 -1.38053e-01]
21Feb17_123107| [ 8.31611e-01  7.46409e-01  2.18558e-01  7.47226e-01 -4.35942e-01
21Feb17_123107|  -6.59230e-01  3.39715e-02  8.14827e-01 -7.32488e-02 -1.12845e-01
21Feb17_123107|  -5.06295e-01  2.18074e-01]
21Feb17_123107| [-3.26563e-01  6.22846e-01  3.85669e-01 -9.86028e-01 -7.51629e-02
21Feb17_123107|  -1.88021e-01  7.27322e-01  5.61207e-04  1.34321e-01  7.19415e-01
21Feb17_123107|  -5.83277e-01 -4.45815e-01]
21Feb17_123107| [ 7.83756e-01  9.31803e-02  4.99853e-01 -9.31861e-01  7.91593e-01
21Feb17_123107|   1.96250e-01 -8.00498e-02  7.34271e-01 -2.68771e-01  7.49220e-01
21Feb17_123107|   1.24815e-01  6.17245e-01]
21Feb17_123107| [ 2.20500e-01 -9.26851e-01 -5.03545e-02  9.91366e-01  9.07862e-01
21Feb17_123107|   6.95839e-01  2.07702e-01  1.55262e-01  7.17753e-01 -6.02225e-01
21Feb17_123107|  -2.43972e-02  7.83904e-01]
21Feb17_123107| [-7.35179e-01 -4.04922e-01 -7.64988e-01  6.94764e-03 -5.74469e-01
21Feb17_123107|  -8.82582e-01 -4.25720e-01  4.48261e-01  9.38039e-01 -6.02162e-01
21Feb17_123107|   1.85138e-01  8.19467e-01]
21Feb17_123107| [-2.42564e-01  5.05630e-02 -6.53631e-01  8.89456e-01  3.73267e-02
21Feb17_123107|  -4.57479e-01  5.78190e-01 -8.65769e-01  4.43846e-01  9.21993e-01
21Feb17_123107|  -4.59642e-01  4.55887e-01]
21Feb17_123107| [ 1.79502e-01  5.97755e-01 -5.91581e-01  6.50878e-01 -3.20822e-02
21Feb17_123107|   7.98103e-01  9.23662e-01 -3.15762e-01  3.95919e-01 -9.74799e-01
21Feb17_123107|  -9.18783e-01  9.04381e-01]
21Feb17_123107| [-9.77544e-01 -9.84191e-01 -3.78989e-01  1.57093e-01 -1.19240e-01
21Feb17_123107|   7.04336e-01  9.20317e-01 -9.23300e-02  7.24512e-01 -4.73620e-01
21Feb17_123107|   4.32204e-01  1.96422e-01]
21Feb17_123107| [-9.94008e-01  1.23345e-01 -2.91311e-01  3.86181e-01  3.50519e-01
21Feb17_123107|   8.97293e-02  1.28693e-01  7.64175e-01  9.70172e-01 -9.36008e-01
21Feb17_123107|   2.31190e-01 -3.81352e-01]
21Feb17_123107| [-8.68842e-01 -3.08689e-01 -7.85613e-02 -7.75421e-01 -2.62711e-01
21Feb17_123107|  -9.13854e-01  5.58996e-01  8.97445e-01 -4.78631e-01 -4.79708e-02
21Feb17_123107|  -2.09270e-01  1.03320e-01]
21Feb17_123107| [ 2.47190e-01  8.94828e-01 -8.83655e-01  1.67368e-01 -1.09226e-01
21Feb17_123107|   5.39374e-01  3.22158e-01  7.22802e-01 -4.76431e-01 -3.98606e-01
21Feb17_123107|   3.91466e-01 -5.89172e-01]
21Feb17_123107| [ 2.03966e-01 -8.11217e-01  8.56319e-01 -5.26108e-01 -9.29896e-01
21Feb17_123107|   5.92077e-01  8.52854e-01  6.15086e-01  5.45676e-01 -8.13950e-01
21Feb17_123107|   6.24771e-01 -9.57171e-01]
21Feb17_123107| [-7.59457e-01  2.18652e-01 -9.40198e-01 -1.94388e-03 -3.63300e-01
21Feb17_123107|   2.19527e-01 -3.86609e-01  6.57866e-02  8.04643e-01  4.37489e-01
21Feb17_123107|   6.39988e-01 -8.42788e-01]
21Feb17_123107| [-2.79911e-01  8.89651e-01  5.38994e-02  7.45843e-01 -9.32154e-01
21Feb17_123107|   5.56522e-01  5.04658e-01  3.56409e-01 -5.15289e-01  6.99550e-01
21Feb17_123107|  -7.31032e-01  1.61260e-01]
21Feb17_123107| [ 8.41582e-01 -5.25391e-01  4.65437e-01  4.40808e-01 -6.03761e-01
21Feb17_123107|   6.23036e-01  9.46114e-01  5.92328e-01  2.08190e-01 -6.69715e-01
21Feb17_123107|  -7.35264e-02  5.96491e-01]
21Feb17_123107| [ 3.20347e-01  1.37290e-01  1.72843e-02 -4.70187e-01  5.92987e-01
21Feb17_123107|   3.57672e-01  2.73873e-01 -8.65750e-02 -3.09144e-01 -9.20603e-01
21Feb17_123107|   2.82912e-01  6.38325e-01]
21Feb17_123107| [-8.91399e-01 -1.24857e-01 -4.86431e-01 -9.05166e-01  8.47373e-01
21Feb17_123107|   3.18146e-01  2.73494e-02 -5.33112e-01  5.63862e-01 -5.12821e-01
21Feb17_123107|  -9.38474e-01 -9.90043e-01]
21Feb17_123107| [-8.25448e-01 -1.90141e-02 -5.51276e-01 -8.23215e-01  7.26222e-02
21Feb17_123107|   3.49894e-01  5.17693e-01 -5.57217e-01 -3.26301e-01  7.78564e-01
21Feb17_123107|   6.58213e-01 -2.83929e-01]
21Feb17_123107| [ 6.18012e-02 -4.92329e-01  5.41071e-01  2.13013e-01  6.35700e-01
21Feb17_123107|  -1.65529e-01  5.77357e-01  2.45531e-01  2.54855e-01 -8.48854e-01
21Feb17_123107|   6.46386e-01 -4.13404e-01]
21Feb17_123107| [-3.41116e-01 -4.75918e-01  3.59165e-01  6.02895e-01 -4.31688e-01
21Feb17_123107|  -8.51757e-01  2.31464e-01 -9.57407e-01  2.83436e-01 -4.51744e-01
21Feb17_123107|   4.80022e-02 -8.35007e-01]
21Feb17_123107| [ 9.67499e-01  5.85047e-02  7.21540e-01  3.12459e-01  3.50272e-01
21Feb17_123107|   2.14450e-01 -3.30294e-01 -7.99000e-01  1.11959e-01  2.74091e-01
21Feb17_123107|  -1.78234e-01  9.40235e-01]
21Feb17_123107| [-1.14387e-01  4.31319e-01  3.73789e-01 -4.62497e-01  4.50407e-01
21Feb17_123107|  -4.00668e-01 -8.26575e-01  2.39589e-01 -5.24611e-01  3.30691e-01
21Feb17_123107|  -3.99504e-01  1.44547e-01]
21Feb17_123107| [ 7.34826e-01 -5.37352e-01 -6.62895e-01  1.04258e-01  2.15046e-03
21Feb17_123107|   2.71790e-01  8.51151e-01 -6.31948e-01  1.94011e-01 -6.41830e-01
21Feb17_123107|   1.67802e-01 -4.29449e-01]
21Feb17_123107| [-6.18752e-01  1.18069e-01 -7.98263e-01  4.75266e-01 -9.95474e-01
21Feb17_123107|  -1.79698e-01  6.90455e-01  3.44607e-01 -5.80013e-01 -6.16218e-02
21Feb17_123107|   7.01329e-01  8.33298e-02]
21Feb17_123107| [-2.69227e-01 -1.43165e-02 -3.33533e-01 -1.69954e-01 -1.26476e-02
21Feb17_123107|   7.69653e-01 -6.99893e-01  5.22539e-01 -1.67862e-01  4.44416e-01
21Feb17_123107|   6.72372e-01  5.52923e-01]
21Feb17_123107| [-7.10479e-01  1.61800e-01  2.53825e-01 -3.00634e-01 -5.06805e-01
21Feb17_123107|   2.02091e-01 -4.94980e-02 -1.44363e-01 -6.18371e-01  5.74350e-01
21Feb17_123107|  -1.85073e-01 -8.11049e-01]
21Feb17_123107| [-6.60846e-01 -1.69003e-01  6.00733e-01 -8.28618e-01 -3.99034e-01
21Feb17_123107|  -5.82553e-01  7.34428e-02  5.57096e-01 -1.50695e-01  1.26307e-01
21Feb17_123107|   8.92712e-01 -8.75142e-01]
21Feb17_123107| [ 7.58158e-01  5.89907e-01 -1.92304e-01 -3.86200e-01 -2.63049e-01
21Feb17_123107|  -3.41209e-03  4.05030e-01 -8.95945e-02  9.79113e-01  6.78942e-02
21Feb17_123107|  -9.53580e-01  7.06162e-01]
21Feb17_123107| [-1.23045e-01  9.25694e-01  5.20030e-01  4.57808e-01 -9.99639e-01
21Feb17_123107|  -9.80069e-02  3.03598e-01  4.26167e-02 -3.64595e-01 -7.17635e-01
21Feb17_123107|   1.61128e-01  6.30329e-01]
21Feb17_123107| [ 2.02232e-02 -3.24113e-01  7.43999e-01 -3.75983e-01  4.63558e-01
21Feb17_123107|  -2.04941e-01 -5.28404e-02  4.26576e-01 -2.53802e-01  1.74976e-01
21Feb17_123107|  -8.35763e-01  8.54548e-01]
21Feb17_123107| [-5.76875e-01  5.40954e-01 -4.91777e-01  4.40209e-01 -9.16379e-01
21Feb17_123107|   6.01728e-01  1.25226e-02  2.05876e-01  8.45524e-01 -8.34178e-01
21Feb17_123107|  -7.87379e-01  8.63352e-01]
21Feb17_123107| [-3.15102e-01  7.00213e-01  6.69503e-01  7.15510e-01 -9.53550e-01
21Feb17_123107|   4.07885e-02  4.25336e-01  6.24629e-01  9.90858e-01  6.36989e-01
21Feb17_123107|  -6.44355e-01 -5.47589e-01]
21Feb17_123107| [-8.25051e-01 -4.37574e-01  4.76334e-01 -7.71092e-01  7.98467e-01
21Feb17_123107|  -1.52347e-01  3.34469e-01  1.51889e-01 -9.60611e-01  4.62484e-01
21Feb17_123107|   4.10115e-01 -1.60555e-01]
21Feb17_123107| [ 1.77712e-01  6.55776e-01  8.97735e-01 -9.20852e-01 -9.69032e-01
21Feb17_123107|  -4.79756e-02 -3.24015e-01 -1.57490e-01 -6.25919e-01  9.94240e-01
21Feb17_123107|  -4.74141e-01 -1.00993e-01]
21Feb17_123107| [ 3.66246e-01  8.06205e-01  3.37216e-01 -3.17040e-01  9.19693e-01
21Feb17_123107|   8.28581e-01  2.22724e-01 -5.57410e-01 -8.17434e-01 -8.65693e-01
21Feb17_123107|  -4.72960e-01  7.15176e-01]
21Feb17_123107| [-8.25000e-01 -4.67253e-01 -1.84646e-02  3.88053e-01 -8.75853e-01
21Feb17_123107|  -2.34509e-01  9.53471e-01  8.05489e-02  2.71744e-01 -7.15129e-01
21Feb17_123107|   9.24875e-01 -6.07435e-01]
21Feb17_123107| [-2.79447e-01  2.39105e-01  1.32962e-01 -7.68103e-01  7.58443e-01
21Feb17_123107|  -1.69646e-01 -7.52460e-01 -7.30195e-01 -4.68985e-01 -2.88784e-01
21Feb17_123107|   3.77655e-02 -5.72024e-01]
21Feb17_123107| [-8.37481e-01 -8.22188e-02  8.45547e-01 -5.53876e-01  5.72703e-01
21Feb17_123107|   3.09970e-01  8.96552e-01  3.97690e-01 -7.19080e-01  2.37714e-01
21Feb17_123107|   6.60752e-01  1.69435e-01]]
21Feb17_123107|-- Bias --
21Feb17_123107|[-0.28065  0.08142 -0.20194  0.96969  0.45180  0.54884  0.16606 -0.15804
21Feb17_123107|  0.47362  0.17133  0.43345 -0.35803]
21Feb17_123107|Layer 1:
21Feb17_123107|-- Config --
21Feb17_123107|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 12], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123107|-- Weights --
21Feb17_123107|[[-0.88546  0.72941]
21Feb17_123107| [ 0.79196 -0.05477]
21Feb17_123107| [-0.89752 -0.49343]
21Feb17_123107| [ 0.78974 -0.41510]
21Feb17_123107| [ 0.29561 -0.94575]
21Feb17_123107| [-0.14754  0.69148]
21Feb17_123107| [-0.33558  0.37910]
21Feb17_123107| [-0.82387  0.15998]
21Feb17_123107| [-0.77760  0.88462]
21Feb17_123107| [ 0.98329 -0.68363]
21Feb17_123107| [ 0.88895  0.40387]
21Feb17_123107| [ 0.39015 -0.38652]]
21Feb17_123107|-- Bias --
21Feb17_123107|[ 0.28702 -0.70976]
21Feb17_123107|Predicting the validation and test data with the Best initial individual.
21Feb17_123113| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_123113|-----------  ------------------  --------------------  ----------
21Feb17_123113|Validation         42.00                  12            0.00000
21Feb17_123113|   Test            36.32                  12            0.00298
21Feb17_123113|-------------------- Test #0 --------------------
21Feb17_123113|Best final individual weights
21Feb17_123113|Individual:
21Feb17_123113|-- Constant hidden layers --
21Feb17_123113|False
21Feb17_123113|Layer 0:
21Feb17_123113|-- Config --
21Feb17_123113|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123113|-- Weights --
21Feb17_123113|[[-0.73212  1.32861  0.10200]
21Feb17_123113| [ 1.48746 -2.97273 -0.42944]
21Feb17_123113| [ 0.53095 -1.50623  0.79224]
21Feb17_123113| [-1.07292 -0.83175 -0.90105]
21Feb17_123113| [-0.48696 -0.89325  0.27226]
21Feb17_123113| [-3.02511  0.34155 -0.03837]
21Feb17_123113| [-0.76747  0.57140 -0.46892]
21Feb17_123113| [-0.07581  0.14713  0.85910]
21Feb17_123113| [-1.37488  0.52170 -0.36205]
21Feb17_123113| [ 1.60981 -0.08727 -0.11267]
21Feb17_123113| [ 0.50986  1.58916 -0.35287]
21Feb17_123113| [-0.34599  1.27113 -0.16393]
21Feb17_123113| [ 1.29203  1.19467  0.37695]
21Feb17_123113| [ 0.58704  0.06328 -0.24240]
21Feb17_123113| [-0.93888 -0.89760  0.57087]
21Feb17_123113| [ 0.99159 -0.66387  0.35177]
21Feb17_123113| [-0.67119  1.06910 -0.12512]
21Feb17_123113| [-0.91534  1.23744 -0.40465]
21Feb17_123113| [ 1.39278  0.08069  0.23328]
21Feb17_123113| [ 0.09880  0.57603 -0.96101]
21Feb17_123113| [ 0.01621 -0.13343 -0.27624]
21Feb17_123113| [-1.28286 -2.28909  0.37931]
21Feb17_123113| [-0.28370  0.09336  0.01547]
21Feb17_123113| [-0.51894  1.84280 -0.25906]
21Feb17_123113| [-0.83075 -0.04508  0.12107]
21Feb17_123113| [ 0.37343  1.18436 -0.07358]
21Feb17_123113| [-2.38657 -0.35191  0.01962]
21Feb17_123113| [ 0.95757 -0.91760 -0.08971]
21Feb17_123113| [ 0.38792 -0.01880  0.69717]
21Feb17_123113| [ 1.66877 -0.58078 -1.21129]
21Feb17_123113| [-0.50943  0.59080  0.30856]
21Feb17_123113| [ 0.30163  1.11518  0.98185]
21Feb17_123113| [-0.73226  0.32281 -0.66712]
21Feb17_123113| [-0.62054 -2.21049  1.40981]
21Feb17_123113| [ 1.23185 -0.58090  0.35844]
21Feb17_123113| [-0.05616  0.24219 -0.02853]
21Feb17_123113| [-1.05085 -2.30259 -0.16276]
21Feb17_123113| [ 0.71087  0.14900  1.13430]
21Feb17_123113| [-2.45877 -1.20999 -1.04986]
21Feb17_123113| [-1.00480  1.36344 -0.13998]
21Feb17_123113| [ 1.83140 -0.91532  0.07616]
21Feb17_123113| [-0.60404 -2.05184  0.76948]
21Feb17_123113| [ 0.52617  0.76042 -1.76746]
21Feb17_123113| [-0.22134  0.17324  0.99530]
21Feb17_123113| [-0.36427  1.34655  0.02110]
21Feb17_123113| [-0.93125 -0.33620 -0.25012]
21Feb17_123113| [-2.76428  0.14487  0.48096]
21Feb17_123113| [-0.10518  0.35052  1.71840]
21Feb17_123113| [-1.27998  1.12568  1.26523]
21Feb17_123113| [-0.60698  1.53230 -0.60824]
21Feb17_123113| [ 0.02898  2.98718 -0.59153]
21Feb17_123113| [ 0.17588 -0.00449  0.50797]
21Feb17_123113| [-1.42674 -0.54967 -0.21310]
21Feb17_123113| [ 1.03196  1.18733  0.36755]
21Feb17_123113| [ 1.04748 -1.47444 -0.08469]
21Feb17_123113| [ 0.49410  0.38745  0.68469]
21Feb17_123113| [-0.62880  0.73245  0.19964]]
21Feb17_123113|-- Bias --
21Feb17_123113|[-0.18798  0.64571 -0.23142]
21Feb17_123113|Layer 1:
21Feb17_123113|-- Config --
21Feb17_123113|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123113|-- Weights --
21Feb17_123113|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_123113| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_123113| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_123113|-- Bias --
21Feb17_123113|[0.60477 0.03773 0.26452 0.12222]
21Feb17_123113|Layer 2:
21Feb17_123113|-- Config --
21Feb17_123113|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123113|-- Weights --
21Feb17_123113|[[ 0.67920  0.12119]
21Feb17_123113| [ 0.44836  0.02916]
21Feb17_123113| [ 0.68939  0.31516]
21Feb17_123113| [-0.58995 -0.05861]]
21Feb17_123113|-- Bias --
21Feb17_123113|[ 0.59649 -0.08079]
21Feb17_123113|Layer 3:
21Feb17_123113|-- Config --
21Feb17_123113|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123113|-- Weights --
21Feb17_123113|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_123113| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_123113|-- Bias --
21Feb17_123113|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_123113|Layer 4:
21Feb17_123113|-- Config --
21Feb17_123113|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123113|-- Weights --
21Feb17_123113|[[-0.03514 -1.04833]
21Feb17_123113| [ 1.25238  0.62094]
21Feb17_123113| [ 0.99203  0.37406]
21Feb17_123113| [ 0.49902  0.67158]
21Feb17_123113| [-1.35709  0.38335]]
21Feb17_123113|-- Bias --
21Feb17_123113|[0.31435 0.36299]
21Feb17_123113|Predicting the validation and test data with the Best final individual.
21Feb17_123120| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_123120|-----------  ------------------  --------------------  ----------
21Feb17_123120|Validation         40.17                  56            0.05627
21Feb17_123120|   Test            21.37                  56            0.70301
21Feb17_123120|-------------------- Test #1 --------------------
21Feb17_123120|Best final individual weights
21Feb17_123120|Individual:
21Feb17_123120|-- Constant hidden layers --
21Feb17_123120|False
21Feb17_123120|Layer 0:
21Feb17_123120|-- Config --
21Feb17_123120|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123120|-- Weights --
21Feb17_123120|[[-0.73212  1.32861  0.10200]
21Feb17_123120| [ 1.48746 -2.97273 -0.42944]
21Feb17_123120| [ 0.53095 -1.50623  0.79224]
21Feb17_123120| [-1.07292 -0.83175 -0.90105]
21Feb17_123120| [-0.48696 -0.89325  0.27226]
21Feb17_123120| [-3.02511  0.34155 -0.03837]
21Feb17_123120| [-0.76747  0.57140 -0.46892]
21Feb17_123120| [-0.07581  0.14713  0.85910]
21Feb17_123120| [-1.37488  0.52170 -0.36205]
21Feb17_123120| [ 1.60981 -0.08727 -0.11267]
21Feb17_123120| [ 0.50986  1.58916 -0.35287]
21Feb17_123120| [-0.34599  1.27113 -0.16393]
21Feb17_123120| [ 1.29203  1.19467  0.37695]
21Feb17_123120| [ 0.58704  0.06328 -0.24240]
21Feb17_123120| [-0.93888 -0.89760  0.57087]
21Feb17_123120| [ 0.99159 -0.66387  0.35177]
21Feb17_123120| [-0.67119  1.06910 -0.12512]
21Feb17_123120| [-0.91534  1.23744 -0.40465]
21Feb17_123120| [ 1.39278  0.08069  0.23328]
21Feb17_123120| [ 0.09880  0.57603 -0.96101]
21Feb17_123120| [ 0.01621 -0.13343 -0.27624]
21Feb17_123120| [-1.28286 -2.28909  0.37931]
21Feb17_123120| [-0.28370  0.09336  0.01547]
21Feb17_123120| [-0.51894  1.84280 -0.25906]
21Feb17_123120| [-0.83075 -0.04508  0.12107]
21Feb17_123120| [ 0.37343  1.18436 -0.07358]
21Feb17_123120| [-2.38657 -0.35191  0.01962]
21Feb17_123120| [ 0.95757 -0.91760 -0.08971]
21Feb17_123120| [ 0.38792 -0.01880  0.69717]
21Feb17_123120| [ 1.66877 -0.58078 -1.21129]
21Feb17_123120| [-0.50943  0.59080  0.30856]
21Feb17_123120| [ 0.30163  1.11518  0.98185]
21Feb17_123120| [-0.73226  0.32281 -0.66712]
21Feb17_123120| [-0.62054 -2.21049  1.40981]
21Feb17_123120| [ 1.23185 -0.58090  0.35844]
21Feb17_123120| [-0.05616  0.24219 -0.02853]
21Feb17_123120| [-1.05085 -2.30259 -0.16276]
21Feb17_123120| [ 0.71087  0.14900  1.13430]
21Feb17_123120| [-2.45877 -1.20999 -1.04986]
21Feb17_123120| [-1.00480  1.36344 -0.13998]
21Feb17_123120| [ 1.83140 -0.91532  0.07616]
21Feb17_123120| [-0.60404 -2.05184  0.76948]
21Feb17_123120| [ 0.52617  0.76042 -1.76746]
21Feb17_123120| [-0.22134  0.17324  0.99530]
21Feb17_123120| [-0.36427  1.34655  0.02110]
21Feb17_123120| [-0.93125 -0.33620 -0.25012]
21Feb17_123120| [-2.76428  0.14487  0.48096]
21Feb17_123120| [-0.10518  0.35052  1.71840]
21Feb17_123120| [-1.27998  1.12568  1.26523]
21Feb17_123120| [-0.60698  1.53230 -0.60824]
21Feb17_123120| [ 0.02898  2.98718 -0.59153]
21Feb17_123120| [ 0.17588 -0.00449  0.50797]
21Feb17_123120| [-1.42674 -0.54967 -0.21310]
21Feb17_123120| [ 1.03196  1.18733  0.36755]
21Feb17_123120| [ 1.04748 -1.47444 -0.08469]
21Feb17_123120| [ 0.49410  0.38745  0.68469]
21Feb17_123120| [-0.62880  0.73245  0.19964]]
21Feb17_123120|-- Bias --
21Feb17_123120|[-0.18798  0.64571 -0.23142]
21Feb17_123120|Layer 1:
21Feb17_123120|-- Config --
21Feb17_123120|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123120|-- Weights --
21Feb17_123120|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_123120| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_123120| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_123120|-- Bias --
21Feb17_123120|[0.60477 0.03773 0.26452 0.12222]
21Feb17_123120|Layer 2:
21Feb17_123120|-- Config --
21Feb17_123120|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123120|-- Weights --
21Feb17_123120|[[ 0.67920  0.12119]
21Feb17_123120| [ 0.44836  0.02916]
21Feb17_123120| [ 0.68939  0.31516]
21Feb17_123120| [-0.58995 -0.05861]]
21Feb17_123120|-- Bias --
21Feb17_123120|[ 0.59649 -0.08079]
21Feb17_123120|Layer 3:
21Feb17_123120|-- Config --
21Feb17_123120|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123120|-- Weights --
21Feb17_123120|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_123120| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_123120|-- Bias --
21Feb17_123120|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_123120|Layer 4:
21Feb17_123120|-- Config --
21Feb17_123120|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123120|-- Weights --
21Feb17_123120|[[-0.03514 -1.04833]
21Feb17_123120| [ 1.25238  0.62094]
21Feb17_123120| [ 0.99203  0.37406]
21Feb17_123120| [ 0.49902  0.67158]
21Feb17_123120| [-1.35709  0.38335]]
21Feb17_123120|-- Bias --
21Feb17_123120|[0.31435 0.36299]
21Feb17_123120|Predicting the validation and test data with the Best final individual.
21Feb17_123128| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_123128|-----------  ------------------  --------------------  ----------
21Feb17_123128|Validation         23.83                  56            0.86651
21Feb17_123128|   Test            22.68                  56            0.77969
21Feb17_123128|-------------------- Test #2 --------------------
21Feb17_123128|Best final individual weights
21Feb17_123128|Individual:
21Feb17_123128|-- Constant hidden layers --
21Feb17_123128|False
21Feb17_123128|Layer 0:
21Feb17_123128|-- Config --
21Feb17_123128|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123128|-- Weights --
21Feb17_123128|[[-0.73212  1.32861  0.10200]
21Feb17_123128| [ 1.48746 -2.97273 -0.42944]
21Feb17_123128| [ 0.53095 -1.50623  0.79224]
21Feb17_123128| [-1.07292 -0.83175 -0.90105]
21Feb17_123128| [-0.48696 -0.89325  0.27226]
21Feb17_123128| [-3.02511  0.34155 -0.03837]
21Feb17_123128| [-0.76747  0.57140 -0.46892]
21Feb17_123128| [-0.07581  0.14713  0.85910]
21Feb17_123128| [-1.37488  0.52170 -0.36205]
21Feb17_123128| [ 1.60981 -0.08727 -0.11267]
21Feb17_123128| [ 0.50986  1.58916 -0.35287]
21Feb17_123128| [-0.34599  1.27113 -0.16393]
21Feb17_123128| [ 1.29203  1.19467  0.37695]
21Feb17_123128| [ 0.58704  0.06328 -0.24240]
21Feb17_123128| [-0.93888 -0.89760  0.57087]
21Feb17_123128| [ 0.99159 -0.66387  0.35177]
21Feb17_123128| [-0.67119  1.06910 -0.12512]
21Feb17_123128| [-0.91534  1.23744 -0.40465]
21Feb17_123128| [ 1.39278  0.08069  0.23328]
21Feb17_123128| [ 0.09880  0.57603 -0.96101]
21Feb17_123128| [ 0.01621 -0.13343 -0.27624]
21Feb17_123128| [-1.28286 -2.28909  0.37931]
21Feb17_123128| [-0.28370  0.09336  0.01547]
21Feb17_123128| [-0.51894  1.84280 -0.25906]
21Feb17_123128| [-0.83075 -0.04508  0.12107]
21Feb17_123128| [ 0.37343  1.18436 -0.07358]
21Feb17_123128| [-2.38657 -0.35191  0.01962]
21Feb17_123128| [ 0.95757 -0.91760 -0.08971]
21Feb17_123128| [ 0.38792 -0.01880  0.69717]
21Feb17_123128| [ 1.66877 -0.58078 -1.21129]
21Feb17_123128| [-0.50943  0.59080  0.30856]
21Feb17_123128| [ 0.30163  1.11518  0.98185]
21Feb17_123128| [-0.73226  0.32281 -0.66712]
21Feb17_123128| [-0.62054 -2.21049  1.40981]
21Feb17_123128| [ 1.23185 -0.58090  0.35844]
21Feb17_123128| [-0.05616  0.24219 -0.02853]
21Feb17_123128| [-1.05085 -2.30259 -0.16276]
21Feb17_123128| [ 0.71087  0.14900  1.13430]
21Feb17_123128| [-2.45877 -1.20999 -1.04986]
21Feb17_123128| [-1.00480  1.36344 -0.13998]
21Feb17_123128| [ 1.83140 -0.91532  0.07616]
21Feb17_123128| [-0.60404 -2.05184  0.76948]
21Feb17_123128| [ 0.52617  0.76042 -1.76746]
21Feb17_123128| [-0.22134  0.17324  0.99530]
21Feb17_123128| [-0.36427  1.34655  0.02110]
21Feb17_123128| [-0.93125 -0.33620 -0.25012]
21Feb17_123128| [-2.76428  0.14487  0.48096]
21Feb17_123128| [-0.10518  0.35052  1.71840]
21Feb17_123128| [-1.27998  1.12568  1.26523]
21Feb17_123128| [-0.60698  1.53230 -0.60824]
21Feb17_123128| [ 0.02898  2.98718 -0.59153]
21Feb17_123128| [ 0.17588 -0.00449  0.50797]
21Feb17_123128| [-1.42674 -0.54967 -0.21310]
21Feb17_123128| [ 1.03196  1.18733  0.36755]
21Feb17_123128| [ 1.04748 -1.47444 -0.08469]
21Feb17_123128| [ 0.49410  0.38745  0.68469]
21Feb17_123128| [-0.62880  0.73245  0.19964]]
21Feb17_123128|-- Bias --
21Feb17_123128|[-0.18798  0.64571 -0.23142]
21Feb17_123128|Layer 1:
21Feb17_123128|-- Config --
21Feb17_123128|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123128|-- Weights --
21Feb17_123128|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_123128| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_123128| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_123128|-- Bias --
21Feb17_123128|[0.60477 0.03773 0.26452 0.12222]
21Feb17_123128|Layer 2:
21Feb17_123128|-- Config --
21Feb17_123128|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123128|-- Weights --
21Feb17_123128|[[ 0.67920  0.12119]
21Feb17_123128| [ 0.44836  0.02916]
21Feb17_123128| [ 0.68939  0.31516]
21Feb17_123128| [-0.58995 -0.05861]]
21Feb17_123128|-- Bias --
21Feb17_123128|[ 0.59649 -0.08079]
21Feb17_123128|Layer 3:
21Feb17_123128|-- Config --
21Feb17_123128|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123128|-- Weights --
21Feb17_123128|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_123128| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_123128|-- Bias --
21Feb17_123128|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_123128|Layer 4:
21Feb17_123128|-- Config --
21Feb17_123128|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123128|-- Weights --
21Feb17_123128|[[-0.03514 -1.04833]
21Feb17_123128| [ 1.25238  0.62094]
21Feb17_123128| [ 0.99203  0.37406]
21Feb17_123128| [ 0.49902  0.67158]
21Feb17_123128| [-1.35709  0.38335]]
21Feb17_123128|-- Bias --
21Feb17_123128|[0.31435 0.36299]
21Feb17_123128|Predicting the validation and test data with the Best final individual.
21Feb17_123136| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_123136|-----------  ------------------  --------------------  ----------
21Feb17_123136|Validation         23.91                  56            0.70865
21Feb17_123136|   Test            29.45                  56            0.70270
21Feb17_123136|-------------------- Test #3 --------------------
21Feb17_123136|Best final individual weights
21Feb17_123136|Individual:
21Feb17_123136|-- Constant hidden layers --
21Feb17_123136|False
21Feb17_123136|Layer 0:
21Feb17_123136|-- Config --
21Feb17_123136|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123136|-- Weights --
21Feb17_123136|[[-0.73212  1.32861  0.10200]
21Feb17_123136| [ 1.48746 -2.97273 -0.42944]
21Feb17_123136| [ 0.53095 -1.50623  0.79224]
21Feb17_123136| [-1.07292 -0.83175 -0.90105]
21Feb17_123136| [-0.48696 -0.89325  0.27226]
21Feb17_123136| [-3.02511  0.34155 -0.03837]
21Feb17_123136| [-0.76747  0.57140 -0.46892]
21Feb17_123136| [-0.07581  0.14713  0.85910]
21Feb17_123136| [-1.37488  0.52170 -0.36205]
21Feb17_123136| [ 1.60981 -0.08727 -0.11267]
21Feb17_123136| [ 0.50986  1.58916 -0.35287]
21Feb17_123136| [-0.34599  1.27113 -0.16393]
21Feb17_123136| [ 1.29203  1.19467  0.37695]
21Feb17_123136| [ 0.58704  0.06328 -0.24240]
21Feb17_123136| [-0.93888 -0.89760  0.57087]
21Feb17_123136| [ 0.99159 -0.66387  0.35177]
21Feb17_123136| [-0.67119  1.06910 -0.12512]
21Feb17_123136| [-0.91534  1.23744 -0.40465]
21Feb17_123136| [ 1.39278  0.08069  0.23328]
21Feb17_123136| [ 0.09880  0.57603 -0.96101]
21Feb17_123136| [ 0.01621 -0.13343 -0.27624]
21Feb17_123136| [-1.28286 -2.28909  0.37931]
21Feb17_123136| [-0.28370  0.09336  0.01547]
21Feb17_123136| [-0.51894  1.84280 -0.25906]
21Feb17_123136| [-0.83075 -0.04508  0.12107]
21Feb17_123136| [ 0.37343  1.18436 -0.07358]
21Feb17_123136| [-2.38657 -0.35191  0.01962]
21Feb17_123136| [ 0.95757 -0.91760 -0.08971]
21Feb17_123136| [ 0.38792 -0.01880  0.69717]
21Feb17_123136| [ 1.66877 -0.58078 -1.21129]
21Feb17_123136| [-0.50943  0.59080  0.30856]
21Feb17_123136| [ 0.30163  1.11518  0.98185]
21Feb17_123136| [-0.73226  0.32281 -0.66712]
21Feb17_123136| [-0.62054 -2.21049  1.40981]
21Feb17_123136| [ 1.23185 -0.58090  0.35844]
21Feb17_123136| [-0.05616  0.24219 -0.02853]
21Feb17_123136| [-1.05085 -2.30259 -0.16276]
21Feb17_123136| [ 0.71087  0.14900  1.13430]
21Feb17_123136| [-2.45877 -1.20999 -1.04986]
21Feb17_123136| [-1.00480  1.36344 -0.13998]
21Feb17_123136| [ 1.83140 -0.91532  0.07616]
21Feb17_123136| [-0.60404 -2.05184  0.76948]
21Feb17_123136| [ 0.52617  0.76042 -1.76746]
21Feb17_123136| [-0.22134  0.17324  0.99530]
21Feb17_123136| [-0.36427  1.34655  0.02110]
21Feb17_123136| [-0.93125 -0.33620 -0.25012]
21Feb17_123136| [-2.76428  0.14487  0.48096]
21Feb17_123136| [-0.10518  0.35052  1.71840]
21Feb17_123136| [-1.27998  1.12568  1.26523]
21Feb17_123136| [-0.60698  1.53230 -0.60824]
21Feb17_123136| [ 0.02898  2.98718 -0.59153]
21Feb17_123136| [ 0.17588 -0.00449  0.50797]
21Feb17_123136| [-1.42674 -0.54967 -0.21310]
21Feb17_123136| [ 1.03196  1.18733  0.36755]
21Feb17_123136| [ 1.04748 -1.47444 -0.08469]
21Feb17_123136| [ 0.49410  0.38745  0.68469]
21Feb17_123136| [-0.62880  0.73245  0.19964]]
21Feb17_123136|-- Bias --
21Feb17_123136|[-0.18798  0.64571 -0.23142]
21Feb17_123136|Layer 1:
21Feb17_123136|-- Config --
21Feb17_123136|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123136|-- Weights --
21Feb17_123136|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_123136| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_123136| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_123136|-- Bias --
21Feb17_123136|[0.60477 0.03773 0.26452 0.12222]
21Feb17_123136|Layer 2:
21Feb17_123136|-- Config --
21Feb17_123136|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123136|-- Weights --
21Feb17_123136|[[ 0.67920  0.12119]
21Feb17_123136| [ 0.44836  0.02916]
21Feb17_123136| [ 0.68939  0.31516]
21Feb17_123136| [-0.58995 -0.05861]]
21Feb17_123136|-- Bias --
21Feb17_123136|[ 0.59649 -0.08079]
21Feb17_123136|Layer 3:
21Feb17_123136|-- Config --
21Feb17_123136|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123136|-- Weights --
21Feb17_123136|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_123136| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_123136|-- Bias --
21Feb17_123136|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_123136|Layer 4:
21Feb17_123136|-- Config --
21Feb17_123136|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123136|-- Weights --
21Feb17_123136|[[-0.03514 -1.04833]
21Feb17_123136| [ 1.25238  0.62094]
21Feb17_123136| [ 0.99203  0.37406]
21Feb17_123136| [ 0.49902  0.67158]
21Feb17_123136| [-1.35709  0.38335]]
21Feb17_123136|-- Bias --
21Feb17_123136|[0.31435 0.36299]
21Feb17_123136|Predicting the validation and test data with the Best final individual.
21Feb17_123144| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_123144|-----------  ------------------  --------------------  ----------
21Feb17_123144|Validation         24.35                  56            0.84577
21Feb17_123144|   Test            21.63                  56            0.70714
21Feb17_123144|-------------------- Test #4 --------------------
21Feb17_123144|Best final individual weights
21Feb17_123144|Individual:
21Feb17_123144|-- Constant hidden layers --
21Feb17_123144|False
21Feb17_123144|Layer 0:
21Feb17_123144|-- Config --
21Feb17_123144|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123144|-- Weights --
21Feb17_123144|[[-0.73212  1.32861  0.10200]
21Feb17_123144| [ 1.48746 -2.97273 -0.42944]
21Feb17_123144| [ 0.53095 -1.50623  0.79224]
21Feb17_123144| [-1.07292 -0.83175 -0.90105]
21Feb17_123144| [-0.48696 -0.89325  0.27226]
21Feb17_123144| [-3.02511  0.34155 -0.03837]
21Feb17_123144| [-0.76747  0.57140 -0.46892]
21Feb17_123144| [-0.07581  0.14713  0.85910]
21Feb17_123144| [-1.37488  0.52170 -0.36205]
21Feb17_123144| [ 1.60981 -0.08727 -0.11267]
21Feb17_123144| [ 0.50986  1.58916 -0.35287]
21Feb17_123144| [-0.34599  1.27113 -0.16393]
21Feb17_123144| [ 1.29203  1.19467  0.37695]
21Feb17_123144| [ 0.58704  0.06328 -0.24240]
21Feb17_123144| [-0.93888 -0.89760  0.57087]
21Feb17_123144| [ 0.99159 -0.66387  0.35177]
21Feb17_123144| [-0.67119  1.06910 -0.12512]
21Feb17_123144| [-0.91534  1.23744 -0.40465]
21Feb17_123144| [ 1.39278  0.08069  0.23328]
21Feb17_123144| [ 0.09880  0.57603 -0.96101]
21Feb17_123144| [ 0.01621 -0.13343 -0.27624]
21Feb17_123144| [-1.28286 -2.28909  0.37931]
21Feb17_123144| [-0.28370  0.09336  0.01547]
21Feb17_123144| [-0.51894  1.84280 -0.25906]
21Feb17_123144| [-0.83075 -0.04508  0.12107]
21Feb17_123144| [ 0.37343  1.18436 -0.07358]
21Feb17_123144| [-2.38657 -0.35191  0.01962]
21Feb17_123144| [ 0.95757 -0.91760 -0.08971]
21Feb17_123144| [ 0.38792 -0.01880  0.69717]
21Feb17_123144| [ 1.66877 -0.58078 -1.21129]
21Feb17_123144| [-0.50943  0.59080  0.30856]
21Feb17_123144| [ 0.30163  1.11518  0.98185]
21Feb17_123144| [-0.73226  0.32281 -0.66712]
21Feb17_123144| [-0.62054 -2.21049  1.40981]
21Feb17_123144| [ 1.23185 -0.58090  0.35844]
21Feb17_123144| [-0.05616  0.24219 -0.02853]
21Feb17_123144| [-1.05085 -2.30259 -0.16276]
21Feb17_123144| [ 0.71087  0.14900  1.13430]
21Feb17_123144| [-2.45877 -1.20999 -1.04986]
21Feb17_123144| [-1.00480  1.36344 -0.13998]
21Feb17_123144| [ 1.83140 -0.91532  0.07616]
21Feb17_123144| [-0.60404 -2.05184  0.76948]
21Feb17_123144| [ 0.52617  0.76042 -1.76746]
21Feb17_123144| [-0.22134  0.17324  0.99530]
21Feb17_123144| [-0.36427  1.34655  0.02110]
21Feb17_123144| [-0.93125 -0.33620 -0.25012]
21Feb17_123144| [-2.76428  0.14487  0.48096]
21Feb17_123144| [-0.10518  0.35052  1.71840]
21Feb17_123144| [-1.27998  1.12568  1.26523]
21Feb17_123144| [-0.60698  1.53230 -0.60824]
21Feb17_123144| [ 0.02898  2.98718 -0.59153]
21Feb17_123144| [ 0.17588 -0.00449  0.50797]
21Feb17_123144| [-1.42674 -0.54967 -0.21310]
21Feb17_123144| [ 1.03196  1.18733  0.36755]
21Feb17_123144| [ 1.04748 -1.47444 -0.08469]
21Feb17_123144| [ 0.49410  0.38745  0.68469]
21Feb17_123144| [-0.62880  0.73245  0.19964]]
21Feb17_123144|-- Bias --
21Feb17_123144|[-0.18798  0.64571 -0.23142]
21Feb17_123144|Layer 1:
21Feb17_123144|-- Config --
21Feb17_123144|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123144|-- Weights --
21Feb17_123144|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_123144| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_123144| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_123144|-- Bias --
21Feb17_123144|[0.60477 0.03773 0.26452 0.12222]
21Feb17_123144|Layer 2:
21Feb17_123144|-- Config --
21Feb17_123144|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123144|-- Weights --
21Feb17_123144|[[ 0.67920  0.12119]
21Feb17_123144| [ 0.44836  0.02916]
21Feb17_123144| [ 0.68939  0.31516]
21Feb17_123144| [-0.58995 -0.05861]]
21Feb17_123144|-- Bias --
21Feb17_123144|[ 0.59649 -0.08079]
21Feb17_123144|Layer 3:
21Feb17_123144|-- Config --
21Feb17_123144|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123144|-- Weights --
21Feb17_123144|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_123144| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_123144|-- Bias --
21Feb17_123144|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_123144|Layer 4:
21Feb17_123144|-- Config --
21Feb17_123144|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123144|-- Weights --
21Feb17_123144|[[-0.03514 -1.04833]
21Feb17_123144| [ 1.25238  0.62094]
21Feb17_123144| [ 0.99203  0.37406]
21Feb17_123144| [ 0.49902  0.67158]
21Feb17_123144| [-1.35709  0.38335]]
21Feb17_123144|-- Bias --
21Feb17_123144|[0.31435 0.36299]
21Feb17_123144|Predicting the validation and test data with the Best final individual.
21Feb17_123151| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_123151|-----------  ------------------  --------------------  ----------
21Feb17_123151|Validation         21.57                  56            0.82113
21Feb17_123151|   Test            31.19                  56            0.83333
21Feb17_123151|-------------------- Test #5 --------------------
21Feb17_123151|Best final individual weights
21Feb17_123151|Individual:
21Feb17_123151|-- Constant hidden layers --
21Feb17_123151|False
21Feb17_123151|Layer 0:
21Feb17_123151|-- Config --
21Feb17_123151|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123151|-- Weights --
21Feb17_123151|[[-0.73212  1.32861  0.10200]
21Feb17_123151| [ 1.48746 -2.97273 -0.42944]
21Feb17_123151| [ 0.53095 -1.50623  0.79224]
21Feb17_123151| [-1.07292 -0.83175 -0.90105]
21Feb17_123151| [-0.48696 -0.89325  0.27226]
21Feb17_123151| [-3.02511  0.34155 -0.03837]
21Feb17_123151| [-0.76747  0.57140 -0.46892]
21Feb17_123151| [-0.07581  0.14713  0.85910]
21Feb17_123151| [-1.37488  0.52170 -0.36205]
21Feb17_123151| [ 1.60981 -0.08727 -0.11267]
21Feb17_123151| [ 0.50986  1.58916 -0.35287]
21Feb17_123151| [-0.34599  1.27113 -0.16393]
21Feb17_123151| [ 1.29203  1.19467  0.37695]
21Feb17_123151| [ 0.58704  0.06328 -0.24240]
21Feb17_123151| [-0.93888 -0.89760  0.57087]
21Feb17_123151| [ 0.99159 -0.66387  0.35177]
21Feb17_123151| [-0.67119  1.06910 -0.12512]
21Feb17_123151| [-0.91534  1.23744 -0.40465]
21Feb17_123151| [ 1.39278  0.08069  0.23328]
21Feb17_123151| [ 0.09880  0.57603 -0.96101]
21Feb17_123151| [ 0.01621 -0.13343 -0.27624]
21Feb17_123151| [-1.28286 -2.28909  0.37931]
21Feb17_123151| [-0.28370  0.09336  0.01547]
21Feb17_123151| [-0.51894  1.84280 -0.25906]
21Feb17_123151| [-0.83075 -0.04508  0.12107]
21Feb17_123151| [ 0.37343  1.18436 -0.07358]
21Feb17_123151| [-2.38657 -0.35191  0.01962]
21Feb17_123151| [ 0.95757 -0.91760 -0.08971]
21Feb17_123151| [ 0.38792 -0.01880  0.69717]
21Feb17_123151| [ 1.66877 -0.58078 -1.21129]
21Feb17_123151| [-0.50943  0.59080  0.30856]
21Feb17_123151| [ 0.30163  1.11518  0.98185]
21Feb17_123151| [-0.73226  0.32281 -0.66712]
21Feb17_123151| [-0.62054 -2.21049  1.40981]
21Feb17_123151| [ 1.23185 -0.58090  0.35844]
21Feb17_123151| [-0.05616  0.24219 -0.02853]
21Feb17_123151| [-1.05085 -2.30259 -0.16276]
21Feb17_123151| [ 0.71087  0.14900  1.13430]
21Feb17_123151| [-2.45877 -1.20999 -1.04986]
21Feb17_123151| [-1.00480  1.36344 -0.13998]
21Feb17_123151| [ 1.83140 -0.91532  0.07616]
21Feb17_123151| [-0.60404 -2.05184  0.76948]
21Feb17_123151| [ 0.52617  0.76042 -1.76746]
21Feb17_123151| [-0.22134  0.17324  0.99530]
21Feb17_123151| [-0.36427  1.34655  0.02110]
21Feb17_123151| [-0.93125 -0.33620 -0.25012]
21Feb17_123151| [-2.76428  0.14487  0.48096]
21Feb17_123151| [-0.10518  0.35052  1.71840]
21Feb17_123151| [-1.27998  1.12568  1.26523]
21Feb17_123151| [-0.60698  1.53230 -0.60824]
21Feb17_123151| [ 0.02898  2.98718 -0.59153]
21Feb17_123151| [ 0.17588 -0.00449  0.50797]
21Feb17_123151| [-1.42674 -0.54967 -0.21310]
21Feb17_123151| [ 1.03196  1.18733  0.36755]
21Feb17_123151| [ 1.04748 -1.47444 -0.08469]
21Feb17_123151| [ 0.49410  0.38745  0.68469]
21Feb17_123151| [-0.62880  0.73245  0.19964]]
21Feb17_123151|-- Bias --
21Feb17_123151|[-0.18798  0.64571 -0.23142]
21Feb17_123151|Layer 1:
21Feb17_123151|-- Config --
21Feb17_123151|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123151|-- Weights --
21Feb17_123151|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_123151| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_123151| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_123151|-- Bias --
21Feb17_123151|[0.60477 0.03773 0.26452 0.12222]
21Feb17_123151|Layer 2:
21Feb17_123151|-- Config --
21Feb17_123151|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123151|-- Weights --
21Feb17_123151|[[ 0.67920  0.12119]
21Feb17_123151| [ 0.44836  0.02916]
21Feb17_123151| [ 0.68939  0.31516]
21Feb17_123151| [-0.58995 -0.05861]]
21Feb17_123151|-- Bias --
21Feb17_123151|[ 0.59649 -0.08079]
21Feb17_123151|Layer 3:
21Feb17_123151|-- Config --
21Feb17_123151|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123151|-- Weights --
21Feb17_123151|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_123151| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_123151|-- Bias --
21Feb17_123151|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_123151|Layer 4:
21Feb17_123151|-- Config --
21Feb17_123151|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123151|-- Weights --
21Feb17_123151|[[-0.03514 -1.04833]
21Feb17_123151| [ 1.25238  0.62094]
21Feb17_123151| [ 0.99203  0.37406]
21Feb17_123151| [ 0.49902  0.67158]
21Feb17_123151| [-1.35709  0.38335]]
21Feb17_123151|-- Bias --
21Feb17_123151|[0.31435 0.36299]
21Feb17_123151|Predicting the validation and test data with the Best final individual.
21Feb17_123159| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_123159|-----------  ------------------  --------------------  ----------
21Feb17_123159|Validation         23.22                  56            0.86009
21Feb17_123159|   Test            26.15                  56            0.85097
21Feb17_123159|-------------------- Test #6 --------------------
21Feb17_123159|Best final individual weights
21Feb17_123159|Individual:
21Feb17_123159|-- Constant hidden layers --
21Feb17_123159|False
21Feb17_123159|Layer 0:
21Feb17_123159|-- Config --
21Feb17_123159|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123159|-- Weights --
21Feb17_123159|[[-0.73212  1.32861  0.10200]
21Feb17_123159| [ 1.48746 -2.97273 -0.42944]
21Feb17_123159| [ 0.53095 -1.50623  0.79224]
21Feb17_123159| [-1.07292 -0.83175 -0.90105]
21Feb17_123159| [-0.48696 -0.89325  0.27226]
21Feb17_123159| [-3.02511  0.34155 -0.03837]
21Feb17_123159| [-0.76747  0.57140 -0.46892]
21Feb17_123159| [-0.07581  0.14713  0.85910]
21Feb17_123159| [-1.37488  0.52170 -0.36205]
21Feb17_123159| [ 1.60981 -0.08727 -0.11267]
21Feb17_123159| [ 0.50986  1.58916 -0.35287]
21Feb17_123159| [-0.34599  1.27113 -0.16393]
21Feb17_123159| [ 1.29203  1.19467  0.37695]
21Feb17_123159| [ 0.58704  0.06328 -0.24240]
21Feb17_123159| [-0.93888 -0.89760  0.57087]
21Feb17_123159| [ 0.99159 -0.66387  0.35177]
21Feb17_123159| [-0.67119  1.06910 -0.12512]
21Feb17_123159| [-0.91534  1.23744 -0.40465]
21Feb17_123159| [ 1.39278  0.08069  0.23328]
21Feb17_123159| [ 0.09880  0.57603 -0.96101]
21Feb17_123159| [ 0.01621 -0.13343 -0.27624]
21Feb17_123159| [-1.28286 -2.28909  0.37931]
21Feb17_123159| [-0.28370  0.09336  0.01547]
21Feb17_123159| [-0.51894  1.84280 -0.25906]
21Feb17_123159| [-0.83075 -0.04508  0.12107]
21Feb17_123159| [ 0.37343  1.18436 -0.07358]
21Feb17_123159| [-2.38657 -0.35191  0.01962]
21Feb17_123159| [ 0.95757 -0.91760 -0.08971]
21Feb17_123159| [ 0.38792 -0.01880  0.69717]
21Feb17_123159| [ 1.66877 -0.58078 -1.21129]
21Feb17_123159| [-0.50943  0.59080  0.30856]
21Feb17_123159| [ 0.30163  1.11518  0.98185]
21Feb17_123159| [-0.73226  0.32281 -0.66712]
21Feb17_123159| [-0.62054 -2.21049  1.40981]
21Feb17_123159| [ 1.23185 -0.58090  0.35844]
21Feb17_123159| [-0.05616  0.24219 -0.02853]
21Feb17_123159| [-1.05085 -2.30259 -0.16276]
21Feb17_123159| [ 0.71087  0.14900  1.13430]
21Feb17_123159| [-2.45877 -1.20999 -1.04986]
21Feb17_123159| [-1.00480  1.36344 -0.13998]
21Feb17_123159| [ 1.83140 -0.91532  0.07616]
21Feb17_123159| [-0.60404 -2.05184  0.76948]
21Feb17_123159| [ 0.52617  0.76042 -1.76746]
21Feb17_123159| [-0.22134  0.17324  0.99530]
21Feb17_123159| [-0.36427  1.34655  0.02110]
21Feb17_123159| [-0.93125 -0.33620 -0.25012]
21Feb17_123159| [-2.76428  0.14487  0.48096]
21Feb17_123159| [-0.10518  0.35052  1.71840]
21Feb17_123159| [-1.27998  1.12568  1.26523]
21Feb17_123159| [-0.60698  1.53230 -0.60824]
21Feb17_123159| [ 0.02898  2.98718 -0.59153]
21Feb17_123159| [ 0.17588 -0.00449  0.50797]
21Feb17_123159| [-1.42674 -0.54967 -0.21310]
21Feb17_123159| [ 1.03196  1.18733  0.36755]
21Feb17_123159| [ 1.04748 -1.47444 -0.08469]
21Feb17_123159| [ 0.49410  0.38745  0.68469]
21Feb17_123159| [-0.62880  0.73245  0.19964]]
21Feb17_123159|-- Bias --
21Feb17_123159|[-0.18798  0.64571 -0.23142]
21Feb17_123159|Layer 1:
21Feb17_123159|-- Config --
21Feb17_123159|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123159|-- Weights --
21Feb17_123159|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_123159| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_123159| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_123159|-- Bias --
21Feb17_123159|[0.60477 0.03773 0.26452 0.12222]
21Feb17_123159|Layer 2:
21Feb17_123159|-- Config --
21Feb17_123159|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123159|-- Weights --
21Feb17_123159|[[ 0.67920  0.12119]
21Feb17_123159| [ 0.44836  0.02916]
21Feb17_123159| [ 0.68939  0.31516]
21Feb17_123159| [-0.58995 -0.05861]]
21Feb17_123159|-- Bias --
21Feb17_123159|[ 0.59649 -0.08079]
21Feb17_123159|Layer 3:
21Feb17_123159|-- Config --
21Feb17_123159|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123159|-- Weights --
21Feb17_123159|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_123159| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_123159|-- Bias --
21Feb17_123159|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_123159|Layer 4:
21Feb17_123159|-- Config --
21Feb17_123159|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123159|-- Weights --
21Feb17_123159|[[-0.03514 -1.04833]
21Feb17_123159| [ 1.25238  0.62094]
21Feb17_123159| [ 0.99203  0.37406]
21Feb17_123159| [ 0.49902  0.67158]
21Feb17_123159| [-1.35709  0.38335]]
21Feb17_123159|-- Bias --
21Feb17_123159|[0.31435 0.36299]
21Feb17_123159|Predicting the validation and test data with the Best final individual.
21Feb17_123207| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_123207|-----------  ------------------  --------------------  ----------
21Feb17_123207|Validation         22.78                  56            0.83496
21Feb17_123207|   Test            21.11                  56            0.79855
21Feb17_123207|-------------------- Test #7 --------------------
21Feb17_123207|Best final individual weights
21Feb17_123207|Individual:
21Feb17_123207|-- Constant hidden layers --
21Feb17_123207|False
21Feb17_123207|Layer 0:
21Feb17_123207|-- Config --
21Feb17_123207|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123207|-- Weights --
21Feb17_123207|[[-0.73212  1.32861  0.10200]
21Feb17_123207| [ 1.48746 -2.97273 -0.42944]
21Feb17_123207| [ 0.53095 -1.50623  0.79224]
21Feb17_123207| [-1.07292 -0.83175 -0.90105]
21Feb17_123207| [-0.48696 -0.89325  0.27226]
21Feb17_123207| [-3.02511  0.34155 -0.03837]
21Feb17_123207| [-0.76747  0.57140 -0.46892]
21Feb17_123207| [-0.07581  0.14713  0.85910]
21Feb17_123207| [-1.37488  0.52170 -0.36205]
21Feb17_123207| [ 1.60981 -0.08727 -0.11267]
21Feb17_123207| [ 0.50986  1.58916 -0.35287]
21Feb17_123207| [-0.34599  1.27113 -0.16393]
21Feb17_123207| [ 1.29203  1.19467  0.37695]
21Feb17_123207| [ 0.58704  0.06328 -0.24240]
21Feb17_123207| [-0.93888 -0.89760  0.57087]
21Feb17_123207| [ 0.99159 -0.66387  0.35177]
21Feb17_123207| [-0.67119  1.06910 -0.12512]
21Feb17_123207| [-0.91534  1.23744 -0.40465]
21Feb17_123207| [ 1.39278  0.08069  0.23328]
21Feb17_123207| [ 0.09880  0.57603 -0.96101]
21Feb17_123207| [ 0.01621 -0.13343 -0.27624]
21Feb17_123207| [-1.28286 -2.28909  0.37931]
21Feb17_123207| [-0.28370  0.09336  0.01547]
21Feb17_123207| [-0.51894  1.84280 -0.25906]
21Feb17_123207| [-0.83075 -0.04508  0.12107]
21Feb17_123207| [ 0.37343  1.18436 -0.07358]
21Feb17_123207| [-2.38657 -0.35191  0.01962]
21Feb17_123207| [ 0.95757 -0.91760 -0.08971]
21Feb17_123207| [ 0.38792 -0.01880  0.69717]
21Feb17_123207| [ 1.66877 -0.58078 -1.21129]
21Feb17_123207| [-0.50943  0.59080  0.30856]
21Feb17_123207| [ 0.30163  1.11518  0.98185]
21Feb17_123207| [-0.73226  0.32281 -0.66712]
21Feb17_123207| [-0.62054 -2.21049  1.40981]
21Feb17_123207| [ 1.23185 -0.58090  0.35844]
21Feb17_123207| [-0.05616  0.24219 -0.02853]
21Feb17_123207| [-1.05085 -2.30259 -0.16276]
21Feb17_123207| [ 0.71087  0.14900  1.13430]
21Feb17_123207| [-2.45877 -1.20999 -1.04986]
21Feb17_123207| [-1.00480  1.36344 -0.13998]
21Feb17_123207| [ 1.83140 -0.91532  0.07616]
21Feb17_123207| [-0.60404 -2.05184  0.76948]
21Feb17_123207| [ 0.52617  0.76042 -1.76746]
21Feb17_123207| [-0.22134  0.17324  0.99530]
21Feb17_123207| [-0.36427  1.34655  0.02110]
21Feb17_123207| [-0.93125 -0.33620 -0.25012]
21Feb17_123207| [-2.76428  0.14487  0.48096]
21Feb17_123207| [-0.10518  0.35052  1.71840]
21Feb17_123207| [-1.27998  1.12568  1.26523]
21Feb17_123207| [-0.60698  1.53230 -0.60824]
21Feb17_123207| [ 0.02898  2.98718 -0.59153]
21Feb17_123207| [ 0.17588 -0.00449  0.50797]
21Feb17_123207| [-1.42674 -0.54967 -0.21310]
21Feb17_123207| [ 1.03196  1.18733  0.36755]
21Feb17_123207| [ 1.04748 -1.47444 -0.08469]
21Feb17_123207| [ 0.49410  0.38745  0.68469]
21Feb17_123207| [-0.62880  0.73245  0.19964]]
21Feb17_123207|-- Bias --
21Feb17_123207|[-0.18798  0.64571 -0.23142]
21Feb17_123207|Layer 1:
21Feb17_123207|-- Config --
21Feb17_123207|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123207|-- Weights --
21Feb17_123207|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_123207| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_123207| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_123207|-- Bias --
21Feb17_123207|[0.60477 0.03773 0.26452 0.12222]
21Feb17_123207|Layer 2:
21Feb17_123207|-- Config --
21Feb17_123207|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123207|-- Weights --
21Feb17_123207|[[ 0.67920  0.12119]
21Feb17_123207| [ 0.44836  0.02916]
21Feb17_123207| [ 0.68939  0.31516]
21Feb17_123207| [-0.58995 -0.05861]]
21Feb17_123207|-- Bias --
21Feb17_123207|[ 0.59649 -0.08079]
21Feb17_123207|Layer 3:
21Feb17_123207|-- Config --
21Feb17_123207|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123207|-- Weights --
21Feb17_123207|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_123207| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_123207|-- Bias --
21Feb17_123207|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_123207|Layer 4:
21Feb17_123207|-- Config --
21Feb17_123207|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123207|-- Weights --
21Feb17_123207|[[-0.03514 -1.04833]
21Feb17_123207| [ 1.25238  0.62094]
21Feb17_123207| [ 0.99203  0.37406]
21Feb17_123207| [ 0.49902  0.67158]
21Feb17_123207| [-1.35709  0.38335]]
21Feb17_123207|-- Bias --
21Feb17_123207|[0.31435 0.36299]
21Feb17_123207|Predicting the validation and test data with the Best final individual.
21Feb17_123214| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_123214|-----------  ------------------  --------------------  ----------
21Feb17_123214|Validation         28.96                  56            0.48780
21Feb17_123214|   Test            25.46                  56            0.49431
21Feb17_123214|-------------------- Test #8 --------------------
21Feb17_123214|Best final individual weights
21Feb17_123214|Individual:
21Feb17_123214|-- Constant hidden layers --
21Feb17_123214|False
21Feb17_123214|Layer 0:
21Feb17_123214|-- Config --
21Feb17_123214|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123214|-- Weights --
21Feb17_123214|[[-0.73212  1.32861  0.10200]
21Feb17_123214| [ 1.48746 -2.97273 -0.42944]
21Feb17_123214| [ 0.53095 -1.50623  0.79224]
21Feb17_123214| [-1.07292 -0.83175 -0.90105]
21Feb17_123214| [-0.48696 -0.89325  0.27226]
21Feb17_123214| [-3.02511  0.34155 -0.03837]
21Feb17_123214| [-0.76747  0.57140 -0.46892]
21Feb17_123214| [-0.07581  0.14713  0.85910]
21Feb17_123214| [-1.37488  0.52170 -0.36205]
21Feb17_123214| [ 1.60981 -0.08727 -0.11267]
21Feb17_123214| [ 0.50986  1.58916 -0.35287]
21Feb17_123214| [-0.34599  1.27113 -0.16393]
21Feb17_123214| [ 1.29203  1.19467  0.37695]
21Feb17_123214| [ 0.58704  0.06328 -0.24240]
21Feb17_123214| [-0.93888 -0.89760  0.57087]
21Feb17_123214| [ 0.99159 -0.66387  0.35177]
21Feb17_123214| [-0.67119  1.06910 -0.12512]
21Feb17_123214| [-0.91534  1.23744 -0.40465]
21Feb17_123214| [ 1.39278  0.08069  0.23328]
21Feb17_123214| [ 0.09880  0.57603 -0.96101]
21Feb17_123214| [ 0.01621 -0.13343 -0.27624]
21Feb17_123214| [-1.28286 -2.28909  0.37931]
21Feb17_123214| [-0.28370  0.09336  0.01547]
21Feb17_123214| [-0.51894  1.84280 -0.25906]
21Feb17_123214| [-0.83075 -0.04508  0.12107]
21Feb17_123214| [ 0.37343  1.18436 -0.07358]
21Feb17_123214| [-2.38657 -0.35191  0.01962]
21Feb17_123214| [ 0.95757 -0.91760 -0.08971]
21Feb17_123214| [ 0.38792 -0.01880  0.69717]
21Feb17_123214| [ 1.66877 -0.58078 -1.21129]
21Feb17_123214| [-0.50943  0.59080  0.30856]
21Feb17_123214| [ 0.30163  1.11518  0.98185]
21Feb17_123214| [-0.73226  0.32281 -0.66712]
21Feb17_123214| [-0.62054 -2.21049  1.40981]
21Feb17_123214| [ 1.23185 -0.58090  0.35844]
21Feb17_123214| [-0.05616  0.24219 -0.02853]
21Feb17_123214| [-1.05085 -2.30259 -0.16276]
21Feb17_123214| [ 0.71087  0.14900  1.13430]
21Feb17_123214| [-2.45877 -1.20999 -1.04986]
21Feb17_123214| [-1.00480  1.36344 -0.13998]
21Feb17_123214| [ 1.83140 -0.91532  0.07616]
21Feb17_123214| [-0.60404 -2.05184  0.76948]
21Feb17_123214| [ 0.52617  0.76042 -1.76746]
21Feb17_123214| [-0.22134  0.17324  0.99530]
21Feb17_123214| [-0.36427  1.34655  0.02110]
21Feb17_123214| [-0.93125 -0.33620 -0.25012]
21Feb17_123214| [-2.76428  0.14487  0.48096]
21Feb17_123214| [-0.10518  0.35052  1.71840]
21Feb17_123214| [-1.27998  1.12568  1.26523]
21Feb17_123214| [-0.60698  1.53230 -0.60824]
21Feb17_123214| [ 0.02898  2.98718 -0.59153]
21Feb17_123214| [ 0.17588 -0.00449  0.50797]
21Feb17_123214| [-1.42674 -0.54967 -0.21310]
21Feb17_123214| [ 1.03196  1.18733  0.36755]
21Feb17_123214| [ 1.04748 -1.47444 -0.08469]
21Feb17_123214| [ 0.49410  0.38745  0.68469]
21Feb17_123214| [-0.62880  0.73245  0.19964]]
21Feb17_123214|-- Bias --
21Feb17_123214|[-0.18798  0.64571 -0.23142]
21Feb17_123214|Layer 1:
21Feb17_123214|-- Config --
21Feb17_123214|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123214|-- Weights --
21Feb17_123214|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_123214| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_123214| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_123214|-- Bias --
21Feb17_123214|[0.60477 0.03773 0.26452 0.12222]
21Feb17_123214|Layer 2:
21Feb17_123214|-- Config --
21Feb17_123214|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123214|-- Weights --
21Feb17_123214|[[ 0.67920  0.12119]
21Feb17_123214| [ 0.44836  0.02916]
21Feb17_123214| [ 0.68939  0.31516]
21Feb17_123214| [-0.58995 -0.05861]]
21Feb17_123214|-- Bias --
21Feb17_123214|[ 0.59649 -0.08079]
21Feb17_123214|Layer 3:
21Feb17_123214|-- Config --
21Feb17_123214|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123214|-- Weights --
21Feb17_123214|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_123214| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_123214|-- Bias --
21Feb17_123214|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_123214|Layer 4:
21Feb17_123214|-- Config --
21Feb17_123214|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123214|-- Weights --
21Feb17_123214|[[-0.03514 -1.04833]
21Feb17_123214| [ 1.25238  0.62094]
21Feb17_123214| [ 0.99203  0.37406]
21Feb17_123214| [ 0.49902  0.67158]
21Feb17_123214| [-1.35709  0.38335]]
21Feb17_123214|-- Bias --
21Feb17_123214|[0.31435 0.36299]
21Feb17_123214|Predicting the validation and test data with the Best final individual.
21Feb17_123222| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_123222|-----------  ------------------  --------------------  ----------
21Feb17_123222|Validation         21.30                  56            0.82476
21Feb17_123222|   Test            21.81                  56            0.83186
21Feb17_123222|-------------------- Test #9 --------------------
21Feb17_123222|Best final individual weights
21Feb17_123222|Individual:
21Feb17_123222|-- Constant hidden layers --
21Feb17_123222|False
21Feb17_123222|Layer 0:
21Feb17_123222|-- Config --
21Feb17_123222|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123222|-- Weights --
21Feb17_123222|[[-0.73212  1.32861  0.10200]
21Feb17_123222| [ 1.48746 -2.97273 -0.42944]
21Feb17_123222| [ 0.53095 -1.50623  0.79224]
21Feb17_123222| [-1.07292 -0.83175 -0.90105]
21Feb17_123222| [-0.48696 -0.89325  0.27226]
21Feb17_123222| [-3.02511  0.34155 -0.03837]
21Feb17_123222| [-0.76747  0.57140 -0.46892]
21Feb17_123222| [-0.07581  0.14713  0.85910]
21Feb17_123222| [-1.37488  0.52170 -0.36205]
21Feb17_123222| [ 1.60981 -0.08727 -0.11267]
21Feb17_123222| [ 0.50986  1.58916 -0.35287]
21Feb17_123222| [-0.34599  1.27113 -0.16393]
21Feb17_123222| [ 1.29203  1.19467  0.37695]
21Feb17_123222| [ 0.58704  0.06328 -0.24240]
21Feb17_123222| [-0.93888 -0.89760  0.57087]
21Feb17_123222| [ 0.99159 -0.66387  0.35177]
21Feb17_123222| [-0.67119  1.06910 -0.12512]
21Feb17_123222| [-0.91534  1.23744 -0.40465]
21Feb17_123222| [ 1.39278  0.08069  0.23328]
21Feb17_123222| [ 0.09880  0.57603 -0.96101]
21Feb17_123222| [ 0.01621 -0.13343 -0.27624]
21Feb17_123222| [-1.28286 -2.28909  0.37931]
21Feb17_123222| [-0.28370  0.09336  0.01547]
21Feb17_123222| [-0.51894  1.84280 -0.25906]
21Feb17_123222| [-0.83075 -0.04508  0.12107]
21Feb17_123222| [ 0.37343  1.18436 -0.07358]
21Feb17_123222| [-2.38657 -0.35191  0.01962]
21Feb17_123222| [ 0.95757 -0.91760 -0.08971]
21Feb17_123222| [ 0.38792 -0.01880  0.69717]
21Feb17_123222| [ 1.66877 -0.58078 -1.21129]
21Feb17_123222| [-0.50943  0.59080  0.30856]
21Feb17_123222| [ 0.30163  1.11518  0.98185]
21Feb17_123222| [-0.73226  0.32281 -0.66712]
21Feb17_123222| [-0.62054 -2.21049  1.40981]
21Feb17_123222| [ 1.23185 -0.58090  0.35844]
21Feb17_123222| [-0.05616  0.24219 -0.02853]
21Feb17_123222| [-1.05085 -2.30259 -0.16276]
21Feb17_123222| [ 0.71087  0.14900  1.13430]
21Feb17_123222| [-2.45877 -1.20999 -1.04986]
21Feb17_123222| [-1.00480  1.36344 -0.13998]
21Feb17_123222| [ 1.83140 -0.91532  0.07616]
21Feb17_123222| [-0.60404 -2.05184  0.76948]
21Feb17_123222| [ 0.52617  0.76042 -1.76746]
21Feb17_123222| [-0.22134  0.17324  0.99530]
21Feb17_123222| [-0.36427  1.34655  0.02110]
21Feb17_123222| [-0.93125 -0.33620 -0.25012]
21Feb17_123222| [-2.76428  0.14487  0.48096]
21Feb17_123222| [-0.10518  0.35052  1.71840]
21Feb17_123222| [-1.27998  1.12568  1.26523]
21Feb17_123222| [-0.60698  1.53230 -0.60824]
21Feb17_123222| [ 0.02898  2.98718 -0.59153]
21Feb17_123222| [ 0.17588 -0.00449  0.50797]
21Feb17_123222| [-1.42674 -0.54967 -0.21310]
21Feb17_123222| [ 1.03196  1.18733  0.36755]
21Feb17_123222| [ 1.04748 -1.47444 -0.08469]
21Feb17_123222| [ 0.49410  0.38745  0.68469]
21Feb17_123222| [-0.62880  0.73245  0.19964]]
21Feb17_123222|-- Bias --
21Feb17_123222|[-0.18798  0.64571 -0.23142]
21Feb17_123222|Layer 1:
21Feb17_123222|-- Config --
21Feb17_123222|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123222|-- Weights --
21Feb17_123222|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_123222| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_123222| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_123222|-- Bias --
21Feb17_123222|[0.60477 0.03773 0.26452 0.12222]
21Feb17_123222|Layer 2:
21Feb17_123222|-- Config --
21Feb17_123222|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123222|-- Weights --
21Feb17_123222|[[ 0.67920  0.12119]
21Feb17_123222| [ 0.44836  0.02916]
21Feb17_123222| [ 0.68939  0.31516]
21Feb17_123222| [-0.58995 -0.05861]]
21Feb17_123222|-- Bias --
21Feb17_123222|[ 0.59649 -0.08079]
21Feb17_123222|Layer 3:
21Feb17_123222|-- Config --
21Feb17_123222|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123222|-- Weights --
21Feb17_123222|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_123222| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_123222|-- Bias --
21Feb17_123222|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_123222|Layer 4:
21Feb17_123222|-- Config --
21Feb17_123222|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123222|-- Weights --
21Feb17_123222|[[-0.03514 -1.04833]
21Feb17_123222| [ 1.25238  0.62094]
21Feb17_123222| [ 0.99203  0.37406]
21Feb17_123222| [ 0.49902  0.67158]
21Feb17_123222| [-1.35709  0.38335]]
21Feb17_123222|-- Bias --
21Feb17_123222|[0.31435 0.36299]
21Feb17_123222|Predicting the validation and test data with the Best final individual.
21Feb17_123230| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_123230|-----------  ------------------  --------------------  ----------
21Feb17_123230|Validation         26.43                  56            0.71922
21Feb17_123230|   Test            29.54                  56            0.67444
21Feb17_123230|-------------------- Test #10 --------------------
21Feb17_123230|Best final individual weights
21Feb17_123230|Individual:
21Feb17_123230|-- Constant hidden layers --
21Feb17_123230|False
21Feb17_123230|Layer 0:
21Feb17_123230|-- Config --
21Feb17_123230|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123230|-- Weights --
21Feb17_123230|[[-0.73212  1.32861  0.10200]
21Feb17_123230| [ 1.48746 -2.97273 -0.42944]
21Feb17_123230| [ 0.53095 -1.50623  0.79224]
21Feb17_123230| [-1.07292 -0.83175 -0.90105]
21Feb17_123230| [-0.48696 -0.89325  0.27226]
21Feb17_123230| [-3.02511  0.34155 -0.03837]
21Feb17_123230| [-0.76747  0.57140 -0.46892]
21Feb17_123230| [-0.07581  0.14713  0.85910]
21Feb17_123230| [-1.37488  0.52170 -0.36205]
21Feb17_123230| [ 1.60981 -0.08727 -0.11267]
21Feb17_123230| [ 0.50986  1.58916 -0.35287]
21Feb17_123230| [-0.34599  1.27113 -0.16393]
21Feb17_123230| [ 1.29203  1.19467  0.37695]
21Feb17_123230| [ 0.58704  0.06328 -0.24240]
21Feb17_123230| [-0.93888 -0.89760  0.57087]
21Feb17_123230| [ 0.99159 -0.66387  0.35177]
21Feb17_123230| [-0.67119  1.06910 -0.12512]
21Feb17_123230| [-0.91534  1.23744 -0.40465]
21Feb17_123230| [ 1.39278  0.08069  0.23328]
21Feb17_123230| [ 0.09880  0.57603 -0.96101]
21Feb17_123230| [ 0.01621 -0.13343 -0.27624]
21Feb17_123230| [-1.28286 -2.28909  0.37931]
21Feb17_123230| [-0.28370  0.09336  0.01547]
21Feb17_123230| [-0.51894  1.84280 -0.25906]
21Feb17_123230| [-0.83075 -0.04508  0.12107]
21Feb17_123230| [ 0.37343  1.18436 -0.07358]
21Feb17_123230| [-2.38657 -0.35191  0.01962]
21Feb17_123230| [ 0.95757 -0.91760 -0.08971]
21Feb17_123230| [ 0.38792 -0.01880  0.69717]
21Feb17_123230| [ 1.66877 -0.58078 -1.21129]
21Feb17_123230| [-0.50943  0.59080  0.30856]
21Feb17_123230| [ 0.30163  1.11518  0.98185]
21Feb17_123230| [-0.73226  0.32281 -0.66712]
21Feb17_123230| [-0.62054 -2.21049  1.40981]
21Feb17_123230| [ 1.23185 -0.58090  0.35844]
21Feb17_123230| [-0.05616  0.24219 -0.02853]
21Feb17_123230| [-1.05085 -2.30259 -0.16276]
21Feb17_123230| [ 0.71087  0.14900  1.13430]
21Feb17_123230| [-2.45877 -1.20999 -1.04986]
21Feb17_123230| [-1.00480  1.36344 -0.13998]
21Feb17_123230| [ 1.83140 -0.91532  0.07616]
21Feb17_123230| [-0.60404 -2.05184  0.76948]
21Feb17_123230| [ 0.52617  0.76042 -1.76746]
21Feb17_123230| [-0.22134  0.17324  0.99530]
21Feb17_123230| [-0.36427  1.34655  0.02110]
21Feb17_123230| [-0.93125 -0.33620 -0.25012]
21Feb17_123230| [-2.76428  0.14487  0.48096]
21Feb17_123230| [-0.10518  0.35052  1.71840]
21Feb17_123230| [-1.27998  1.12568  1.26523]
21Feb17_123230| [-0.60698  1.53230 -0.60824]
21Feb17_123230| [ 0.02898  2.98718 -0.59153]
21Feb17_123230| [ 0.17588 -0.00449  0.50797]
21Feb17_123230| [-1.42674 -0.54967 -0.21310]
21Feb17_123230| [ 1.03196  1.18733  0.36755]
21Feb17_123230| [ 1.04748 -1.47444 -0.08469]
21Feb17_123230| [ 0.49410  0.38745  0.68469]
21Feb17_123230| [-0.62880  0.73245  0.19964]]
21Feb17_123230|-- Bias --
21Feb17_123230|[-0.18798  0.64571 -0.23142]
21Feb17_123230|Layer 1:
21Feb17_123230|-- Config --
21Feb17_123230|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123230|-- Weights --
21Feb17_123230|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_123230| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_123230| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_123230|-- Bias --
21Feb17_123230|[0.60477 0.03773 0.26452 0.12222]
21Feb17_123230|Layer 2:
21Feb17_123230|-- Config --
21Feb17_123230|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123230|-- Weights --
21Feb17_123230|[[ 0.67920  0.12119]
21Feb17_123230| [ 0.44836  0.02916]
21Feb17_123230| [ 0.68939  0.31516]
21Feb17_123230| [-0.58995 -0.05861]]
21Feb17_123230|-- Bias --
21Feb17_123230|[ 0.59649 -0.08079]
21Feb17_123230|Layer 3:
21Feb17_123230|-- Config --
21Feb17_123230|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123230|-- Weights --
21Feb17_123230|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_123230| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_123230|-- Bias --
21Feb17_123230|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_123230|Layer 4:
21Feb17_123230|-- Config --
21Feb17_123230|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123230|-- Weights --
21Feb17_123230|[[-0.03514 -1.04833]
21Feb17_123230| [ 1.25238  0.62094]
21Feb17_123230| [ 0.99203  0.37406]
21Feb17_123230| [ 0.49902  0.67158]
21Feb17_123230| [-1.35709  0.38335]]
21Feb17_123230|-- Bias --
21Feb17_123230|[0.31435 0.36299]
21Feb17_123230|Predicting the validation and test data with the Best final individual.
21Feb17_123237| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_123237|-----------  ------------------  --------------------  ----------
21Feb17_123237|Validation         23.65                  56            0.85845
21Feb17_123237|   Test            26.67                  56            0.71298
21Feb17_123237|-------------------- Test #11 --------------------
21Feb17_123237|Best final individual weights
21Feb17_123237|Individual:
21Feb17_123237|-- Constant hidden layers --
21Feb17_123237|False
21Feb17_123237|Layer 0:
21Feb17_123237|-- Config --
21Feb17_123237|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123237|-- Weights --
21Feb17_123237|[[-0.73212  1.32861  0.10200]
21Feb17_123237| [ 1.48746 -2.97273 -0.42944]
21Feb17_123237| [ 0.53095 -1.50623  0.79224]
21Feb17_123237| [-1.07292 -0.83175 -0.90105]
21Feb17_123237| [-0.48696 -0.89325  0.27226]
21Feb17_123237| [-3.02511  0.34155 -0.03837]
21Feb17_123237| [-0.76747  0.57140 -0.46892]
21Feb17_123237| [-0.07581  0.14713  0.85910]
21Feb17_123237| [-1.37488  0.52170 -0.36205]
21Feb17_123237| [ 1.60981 -0.08727 -0.11267]
21Feb17_123237| [ 0.50986  1.58916 -0.35287]
21Feb17_123237| [-0.34599  1.27113 -0.16393]
21Feb17_123237| [ 1.29203  1.19467  0.37695]
21Feb17_123237| [ 0.58704  0.06328 -0.24240]
21Feb17_123237| [-0.93888 -0.89760  0.57087]
21Feb17_123237| [ 0.99159 -0.66387  0.35177]
21Feb17_123237| [-0.67119  1.06910 -0.12512]
21Feb17_123237| [-0.91534  1.23744 -0.40465]
21Feb17_123237| [ 1.39278  0.08069  0.23328]
21Feb17_123237| [ 0.09880  0.57603 -0.96101]
21Feb17_123237| [ 0.01621 -0.13343 -0.27624]
21Feb17_123237| [-1.28286 -2.28909  0.37931]
21Feb17_123237| [-0.28370  0.09336  0.01547]
21Feb17_123237| [-0.51894  1.84280 -0.25906]
21Feb17_123237| [-0.83075 -0.04508  0.12107]
21Feb17_123237| [ 0.37343  1.18436 -0.07358]
21Feb17_123237| [-2.38657 -0.35191  0.01962]
21Feb17_123237| [ 0.95757 -0.91760 -0.08971]
21Feb17_123237| [ 0.38792 -0.01880  0.69717]
21Feb17_123237| [ 1.66877 -0.58078 -1.21129]
21Feb17_123237| [-0.50943  0.59080  0.30856]
21Feb17_123237| [ 0.30163  1.11518  0.98185]
21Feb17_123237| [-0.73226  0.32281 -0.66712]
21Feb17_123237| [-0.62054 -2.21049  1.40981]
21Feb17_123237| [ 1.23185 -0.58090  0.35844]
21Feb17_123237| [-0.05616  0.24219 -0.02853]
21Feb17_123237| [-1.05085 -2.30259 -0.16276]
21Feb17_123237| [ 0.71087  0.14900  1.13430]
21Feb17_123237| [-2.45877 -1.20999 -1.04986]
21Feb17_123237| [-1.00480  1.36344 -0.13998]
21Feb17_123237| [ 1.83140 -0.91532  0.07616]
21Feb17_123237| [-0.60404 -2.05184  0.76948]
21Feb17_123237| [ 0.52617  0.76042 -1.76746]
21Feb17_123237| [-0.22134  0.17324  0.99530]
21Feb17_123237| [-0.36427  1.34655  0.02110]
21Feb17_123237| [-0.93125 -0.33620 -0.25012]
21Feb17_123237| [-2.76428  0.14487  0.48096]
21Feb17_123237| [-0.10518  0.35052  1.71840]
21Feb17_123237| [-1.27998  1.12568  1.26523]
21Feb17_123237| [-0.60698  1.53230 -0.60824]
21Feb17_123237| [ 0.02898  2.98718 -0.59153]
21Feb17_123237| [ 0.17588 -0.00449  0.50797]
21Feb17_123237| [-1.42674 -0.54967 -0.21310]
21Feb17_123237| [ 1.03196  1.18733  0.36755]
21Feb17_123237| [ 1.04748 -1.47444 -0.08469]
21Feb17_123237| [ 0.49410  0.38745  0.68469]
21Feb17_123237| [-0.62880  0.73245  0.19964]]
21Feb17_123237|-- Bias --
21Feb17_123237|[-0.18798  0.64571 -0.23142]
21Feb17_123237|Layer 1:
21Feb17_123237|-- Config --
21Feb17_123237|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123237|-- Weights --
21Feb17_123237|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_123237| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_123237| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_123237|-- Bias --
21Feb17_123237|[0.60477 0.03773 0.26452 0.12222]
21Feb17_123237|Layer 2:
21Feb17_123237|-- Config --
21Feb17_123237|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123237|-- Weights --
21Feb17_123237|[[ 0.67920  0.12119]
21Feb17_123237| [ 0.44836  0.02916]
21Feb17_123237| [ 0.68939  0.31516]
21Feb17_123237| [-0.58995 -0.05861]]
21Feb17_123237|-- Bias --
21Feb17_123237|[ 0.59649 -0.08079]
21Feb17_123237|Layer 3:
21Feb17_123237|-- Config --
21Feb17_123237|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123237|-- Weights --
21Feb17_123237|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_123237| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_123237|-- Bias --
21Feb17_123237|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_123237|Layer 4:
21Feb17_123237|-- Config --
21Feb17_123237|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123237|-- Weights --
21Feb17_123237|[[-0.03514 -1.04833]
21Feb17_123237| [ 1.25238  0.62094]
21Feb17_123237| [ 0.99203  0.37406]
21Feb17_123237| [ 0.49902  0.67158]
21Feb17_123237| [-1.35709  0.38335]]
21Feb17_123237|-- Bias --
21Feb17_123237|[0.31435 0.36299]
21Feb17_123237|Predicting the validation and test data with the Best final individual.
21Feb17_123245| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_123245|-----------  ------------------  --------------------  ----------
21Feb17_123245|Validation         23.48                  56            0.78306
21Feb17_123245|   Test            22.07                  56            0.85403
21Feb17_123245|-------------------- Test #12 --------------------
21Feb17_123245|Best final individual weights
21Feb17_123245|Individual:
21Feb17_123245|-- Constant hidden layers --
21Feb17_123245|False
21Feb17_123245|Layer 0:
21Feb17_123245|-- Config --
21Feb17_123245|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123245|-- Weights --
21Feb17_123245|[[-0.73212  1.32861  0.10200]
21Feb17_123245| [ 1.48746 -2.97273 -0.42944]
21Feb17_123245| [ 0.53095 -1.50623  0.79224]
21Feb17_123245| [-1.07292 -0.83175 -0.90105]
21Feb17_123245| [-0.48696 -0.89325  0.27226]
21Feb17_123245| [-3.02511  0.34155 -0.03837]
21Feb17_123245| [-0.76747  0.57140 -0.46892]
21Feb17_123245| [-0.07581  0.14713  0.85910]
21Feb17_123245| [-1.37488  0.52170 -0.36205]
21Feb17_123245| [ 1.60981 -0.08727 -0.11267]
21Feb17_123245| [ 0.50986  1.58916 -0.35287]
21Feb17_123245| [-0.34599  1.27113 -0.16393]
21Feb17_123245| [ 1.29203  1.19467  0.37695]
21Feb17_123245| [ 0.58704  0.06328 -0.24240]
21Feb17_123245| [-0.93888 -0.89760  0.57087]
21Feb17_123245| [ 0.99159 -0.66387  0.35177]
21Feb17_123245| [-0.67119  1.06910 -0.12512]
21Feb17_123245| [-0.91534  1.23744 -0.40465]
21Feb17_123245| [ 1.39278  0.08069  0.23328]
21Feb17_123245| [ 0.09880  0.57603 -0.96101]
21Feb17_123245| [ 0.01621 -0.13343 -0.27624]
21Feb17_123245| [-1.28286 -2.28909  0.37931]
21Feb17_123245| [-0.28370  0.09336  0.01547]
21Feb17_123245| [-0.51894  1.84280 -0.25906]
21Feb17_123245| [-0.83075 -0.04508  0.12107]
21Feb17_123245| [ 0.37343  1.18436 -0.07358]
21Feb17_123245| [-2.38657 -0.35191  0.01962]
21Feb17_123245| [ 0.95757 -0.91760 -0.08971]
21Feb17_123245| [ 0.38792 -0.01880  0.69717]
21Feb17_123245| [ 1.66877 -0.58078 -1.21129]
21Feb17_123245| [-0.50943  0.59080  0.30856]
21Feb17_123245| [ 0.30163  1.11518  0.98185]
21Feb17_123245| [-0.73226  0.32281 -0.66712]
21Feb17_123245| [-0.62054 -2.21049  1.40981]
21Feb17_123245| [ 1.23185 -0.58090  0.35844]
21Feb17_123245| [-0.05616  0.24219 -0.02853]
21Feb17_123245| [-1.05085 -2.30259 -0.16276]
21Feb17_123245| [ 0.71087  0.14900  1.13430]
21Feb17_123245| [-2.45877 -1.20999 -1.04986]
21Feb17_123245| [-1.00480  1.36344 -0.13998]
21Feb17_123245| [ 1.83140 -0.91532  0.07616]
21Feb17_123245| [-0.60404 -2.05184  0.76948]
21Feb17_123245| [ 0.52617  0.76042 -1.76746]
21Feb17_123245| [-0.22134  0.17324  0.99530]
21Feb17_123245| [-0.36427  1.34655  0.02110]
21Feb17_123245| [-0.93125 -0.33620 -0.25012]
21Feb17_123245| [-2.76428  0.14487  0.48096]
21Feb17_123245| [-0.10518  0.35052  1.71840]
21Feb17_123245| [-1.27998  1.12568  1.26523]
21Feb17_123245| [-0.60698  1.53230 -0.60824]
21Feb17_123245| [ 0.02898  2.98718 -0.59153]
21Feb17_123245| [ 0.17588 -0.00449  0.50797]
21Feb17_123245| [-1.42674 -0.54967 -0.21310]
21Feb17_123245| [ 1.03196  1.18733  0.36755]
21Feb17_123245| [ 1.04748 -1.47444 -0.08469]
21Feb17_123245| [ 0.49410  0.38745  0.68469]
21Feb17_123245| [-0.62880  0.73245  0.19964]]
21Feb17_123245|-- Bias --
21Feb17_123245|[-0.18798  0.64571 -0.23142]
21Feb17_123245|Layer 1:
21Feb17_123245|-- Config --
21Feb17_123245|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123245|-- Weights --
21Feb17_123245|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_123245| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_123245| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_123245|-- Bias --
21Feb17_123245|[0.60477 0.03773 0.26452 0.12222]
21Feb17_123245|Layer 2:
21Feb17_123245|-- Config --
21Feb17_123245|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123245|-- Weights --
21Feb17_123245|[[ 0.67920  0.12119]
21Feb17_123245| [ 0.44836  0.02916]
21Feb17_123245| [ 0.68939  0.31516]
21Feb17_123245| [-0.58995 -0.05861]]
21Feb17_123245|-- Bias --
21Feb17_123245|[ 0.59649 -0.08079]
21Feb17_123245|Layer 3:
21Feb17_123245|-- Config --
21Feb17_123245|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123245|-- Weights --
21Feb17_123245|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_123245| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_123245|-- Bias --
21Feb17_123245|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_123245|Layer 4:
21Feb17_123245|-- Config --
21Feb17_123245|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123245|-- Weights --
21Feb17_123245|[[-0.03514 -1.04833]
21Feb17_123245| [ 1.25238  0.62094]
21Feb17_123245| [ 0.99203  0.37406]
21Feb17_123245| [ 0.49902  0.67158]
21Feb17_123245| [-1.35709  0.38335]]
21Feb17_123245|-- Bias --
21Feb17_123245|[0.31435 0.36299]
21Feb17_123245|Predicting the validation and test data with the Best final individual.
21Feb17_123253| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_123253|-----------  ------------------  --------------------  ----------
21Feb17_123253|Validation         24.43                  56            0.85301
21Feb17_123253|   Test            37.01                  56            0.82036
21Feb17_123253|-------------------- Test #13 --------------------
21Feb17_123253|Best final individual weights
21Feb17_123253|Individual:
21Feb17_123253|-- Constant hidden layers --
21Feb17_123253|False
21Feb17_123253|Layer 0:
21Feb17_123253|-- Config --
21Feb17_123253|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123253|-- Weights --
21Feb17_123253|[[-0.73212  1.32861  0.10200]
21Feb17_123253| [ 1.48746 -2.97273 -0.42944]
21Feb17_123253| [ 0.53095 -1.50623  0.79224]
21Feb17_123253| [-1.07292 -0.83175 -0.90105]
21Feb17_123253| [-0.48696 -0.89325  0.27226]
21Feb17_123253| [-3.02511  0.34155 -0.03837]
21Feb17_123253| [-0.76747  0.57140 -0.46892]
21Feb17_123253| [-0.07581  0.14713  0.85910]
21Feb17_123253| [-1.37488  0.52170 -0.36205]
21Feb17_123253| [ 1.60981 -0.08727 -0.11267]
21Feb17_123253| [ 0.50986  1.58916 -0.35287]
21Feb17_123253| [-0.34599  1.27113 -0.16393]
21Feb17_123253| [ 1.29203  1.19467  0.37695]
21Feb17_123253| [ 0.58704  0.06328 -0.24240]
21Feb17_123253| [-0.93888 -0.89760  0.57087]
21Feb17_123253| [ 0.99159 -0.66387  0.35177]
21Feb17_123253| [-0.67119  1.06910 -0.12512]
21Feb17_123253| [-0.91534  1.23744 -0.40465]
21Feb17_123253| [ 1.39278  0.08069  0.23328]
21Feb17_123253| [ 0.09880  0.57603 -0.96101]
21Feb17_123253| [ 0.01621 -0.13343 -0.27624]
21Feb17_123253| [-1.28286 -2.28909  0.37931]
21Feb17_123253| [-0.28370  0.09336  0.01547]
21Feb17_123253| [-0.51894  1.84280 -0.25906]
21Feb17_123253| [-0.83075 -0.04508  0.12107]
21Feb17_123253| [ 0.37343  1.18436 -0.07358]
21Feb17_123253| [-2.38657 -0.35191  0.01962]
21Feb17_123253| [ 0.95757 -0.91760 -0.08971]
21Feb17_123253| [ 0.38792 -0.01880  0.69717]
21Feb17_123253| [ 1.66877 -0.58078 -1.21129]
21Feb17_123253| [-0.50943  0.59080  0.30856]
21Feb17_123253| [ 0.30163  1.11518  0.98185]
21Feb17_123253| [-0.73226  0.32281 -0.66712]
21Feb17_123253| [-0.62054 -2.21049  1.40981]
21Feb17_123253| [ 1.23185 -0.58090  0.35844]
21Feb17_123253| [-0.05616  0.24219 -0.02853]
21Feb17_123253| [-1.05085 -2.30259 -0.16276]
21Feb17_123253| [ 0.71087  0.14900  1.13430]
21Feb17_123253| [-2.45877 -1.20999 -1.04986]
21Feb17_123253| [-1.00480  1.36344 -0.13998]
21Feb17_123253| [ 1.83140 -0.91532  0.07616]
21Feb17_123253| [-0.60404 -2.05184  0.76948]
21Feb17_123253| [ 0.52617  0.76042 -1.76746]
21Feb17_123253| [-0.22134  0.17324  0.99530]
21Feb17_123253| [-0.36427  1.34655  0.02110]
21Feb17_123253| [-0.93125 -0.33620 -0.25012]
21Feb17_123253| [-2.76428  0.14487  0.48096]
21Feb17_123253| [-0.10518  0.35052  1.71840]
21Feb17_123253| [-1.27998  1.12568  1.26523]
21Feb17_123253| [-0.60698  1.53230 -0.60824]
21Feb17_123253| [ 0.02898  2.98718 -0.59153]
21Feb17_123253| [ 0.17588 -0.00449  0.50797]
21Feb17_123253| [-1.42674 -0.54967 -0.21310]
21Feb17_123253| [ 1.03196  1.18733  0.36755]
21Feb17_123253| [ 1.04748 -1.47444 -0.08469]
21Feb17_123253| [ 0.49410  0.38745  0.68469]
21Feb17_123253| [-0.62880  0.73245  0.19964]]
21Feb17_123253|-- Bias --
21Feb17_123253|[-0.18798  0.64571 -0.23142]
21Feb17_123253|Layer 1:
21Feb17_123253|-- Config --
21Feb17_123253|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123253|-- Weights --
21Feb17_123253|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_123253| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_123253| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_123253|-- Bias --
21Feb17_123253|[0.60477 0.03773 0.26452 0.12222]
21Feb17_123253|Layer 2:
21Feb17_123253|-- Config --
21Feb17_123253|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123253|-- Weights --
21Feb17_123253|[[ 0.67920  0.12119]
21Feb17_123253| [ 0.44836  0.02916]
21Feb17_123253| [ 0.68939  0.31516]
21Feb17_123253| [-0.58995 -0.05861]]
21Feb17_123253|-- Bias --
21Feb17_123253|[ 0.59649 -0.08079]
21Feb17_123253|Layer 3:
21Feb17_123253|-- Config --
21Feb17_123253|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123253|-- Weights --
21Feb17_123253|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_123253| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_123253|-- Bias --
21Feb17_123253|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_123253|Layer 4:
21Feb17_123253|-- Config --
21Feb17_123253|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123253|-- Weights --
21Feb17_123253|[[-0.03514 -1.04833]
21Feb17_123253| [ 1.25238  0.62094]
21Feb17_123253| [ 0.99203  0.37406]
21Feb17_123253| [ 0.49902  0.67158]
21Feb17_123253| [-1.35709  0.38335]]
21Feb17_123253|-- Bias --
21Feb17_123253|[0.31435 0.36299]
21Feb17_123253|Predicting the validation and test data with the Best final individual.
21Feb17_123301| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_123301|-----------  ------------------  --------------------  ----------
21Feb17_123301|Validation         21.74                  56            0.74120
21Feb17_123301|   Test            25.80                  56            0.72926
21Feb17_123301|-------------------- Test #14 --------------------
21Feb17_123301|Best final individual weights
21Feb17_123301|Individual:
21Feb17_123301|-- Constant hidden layers --
21Feb17_123301|False
21Feb17_123301|Layer 0:
21Feb17_123301|-- Config --
21Feb17_123301|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123301|-- Weights --
21Feb17_123301|[[-0.73212  1.32861  0.10200]
21Feb17_123301| [ 1.48746 -2.97273 -0.42944]
21Feb17_123301| [ 0.53095 -1.50623  0.79224]
21Feb17_123301| [-1.07292 -0.83175 -0.90105]
21Feb17_123301| [-0.48696 -0.89325  0.27226]
21Feb17_123301| [-3.02511  0.34155 -0.03837]
21Feb17_123301| [-0.76747  0.57140 -0.46892]
21Feb17_123301| [-0.07581  0.14713  0.85910]
21Feb17_123301| [-1.37488  0.52170 -0.36205]
21Feb17_123301| [ 1.60981 -0.08727 -0.11267]
21Feb17_123301| [ 0.50986  1.58916 -0.35287]
21Feb17_123301| [-0.34599  1.27113 -0.16393]
21Feb17_123301| [ 1.29203  1.19467  0.37695]
21Feb17_123301| [ 0.58704  0.06328 -0.24240]
21Feb17_123301| [-0.93888 -0.89760  0.57087]
21Feb17_123301| [ 0.99159 -0.66387  0.35177]
21Feb17_123301| [-0.67119  1.06910 -0.12512]
21Feb17_123301| [-0.91534  1.23744 -0.40465]
21Feb17_123301| [ 1.39278  0.08069  0.23328]
21Feb17_123301| [ 0.09880  0.57603 -0.96101]
21Feb17_123301| [ 0.01621 -0.13343 -0.27624]
21Feb17_123301| [-1.28286 -2.28909  0.37931]
21Feb17_123301| [-0.28370  0.09336  0.01547]
21Feb17_123301| [-0.51894  1.84280 -0.25906]
21Feb17_123301| [-0.83075 -0.04508  0.12107]
21Feb17_123301| [ 0.37343  1.18436 -0.07358]
21Feb17_123301| [-2.38657 -0.35191  0.01962]
21Feb17_123301| [ 0.95757 -0.91760 -0.08971]
21Feb17_123301| [ 0.38792 -0.01880  0.69717]
21Feb17_123301| [ 1.66877 -0.58078 -1.21129]
21Feb17_123301| [-0.50943  0.59080  0.30856]
21Feb17_123301| [ 0.30163  1.11518  0.98185]
21Feb17_123301| [-0.73226  0.32281 -0.66712]
21Feb17_123301| [-0.62054 -2.21049  1.40981]
21Feb17_123301| [ 1.23185 -0.58090  0.35844]
21Feb17_123301| [-0.05616  0.24219 -0.02853]
21Feb17_123301| [-1.05085 -2.30259 -0.16276]
21Feb17_123301| [ 0.71087  0.14900  1.13430]
21Feb17_123301| [-2.45877 -1.20999 -1.04986]
21Feb17_123301| [-1.00480  1.36344 -0.13998]
21Feb17_123301| [ 1.83140 -0.91532  0.07616]
21Feb17_123301| [-0.60404 -2.05184  0.76948]
21Feb17_123301| [ 0.52617  0.76042 -1.76746]
21Feb17_123301| [-0.22134  0.17324  0.99530]
21Feb17_123301| [-0.36427  1.34655  0.02110]
21Feb17_123301| [-0.93125 -0.33620 -0.25012]
21Feb17_123301| [-2.76428  0.14487  0.48096]
21Feb17_123301| [-0.10518  0.35052  1.71840]
21Feb17_123301| [-1.27998  1.12568  1.26523]
21Feb17_123301| [-0.60698  1.53230 -0.60824]
21Feb17_123301| [ 0.02898  2.98718 -0.59153]
21Feb17_123301| [ 0.17588 -0.00449  0.50797]
21Feb17_123301| [-1.42674 -0.54967 -0.21310]
21Feb17_123301| [ 1.03196  1.18733  0.36755]
21Feb17_123301| [ 1.04748 -1.47444 -0.08469]
21Feb17_123301| [ 0.49410  0.38745  0.68469]
21Feb17_123301| [-0.62880  0.73245  0.19964]]
21Feb17_123301|-- Bias --
21Feb17_123301|[-0.18798  0.64571 -0.23142]
21Feb17_123301|Layer 1:
21Feb17_123301|-- Config --
21Feb17_123301|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123301|-- Weights --
21Feb17_123301|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_123301| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_123301| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_123301|-- Bias --
21Feb17_123301|[0.60477 0.03773 0.26452 0.12222]
21Feb17_123301|Layer 2:
21Feb17_123301|-- Config --
21Feb17_123301|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123301|-- Weights --
21Feb17_123301|[[ 0.67920  0.12119]
21Feb17_123301| [ 0.44836  0.02916]
21Feb17_123301| [ 0.68939  0.31516]
21Feb17_123301| [-0.58995 -0.05861]]
21Feb17_123301|-- Bias --
21Feb17_123301|[ 0.59649 -0.08079]
21Feb17_123301|Layer 3:
21Feb17_123301|-- Config --
21Feb17_123301|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123301|-- Weights --
21Feb17_123301|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_123301| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_123301|-- Bias --
21Feb17_123301|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_123301|Layer 4:
21Feb17_123301|-- Config --
21Feb17_123301|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_123301|-- Weights --
21Feb17_123301|[[-0.03514 -1.04833]
21Feb17_123301| [ 1.25238  0.62094]
21Feb17_123301| [ 0.99203  0.37406]
21Feb17_123301| [ 0.49902  0.67158]
21Feb17_123301| [-1.35709  0.38335]]
21Feb17_123301|-- Bias --
21Feb17_123301|[0.31435 0.36299]
21Feb17_123301|Predicting the validation and test data with the Best final individual.
21Feb17_123308| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_123308|-----------  ------------------  --------------------  ----------
21Feb17_123308|Validation         22.70                  56            0.74363
21Feb17_123308|   Test            19.46                  56            0.73101
Using Theano backend.
WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.
2021-02-17 12:33:11.449099: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-02-17 12:33:11.449165: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
21Feb17_123312|Data summary: Train
21Feb17_123312|data.shape = (2300, 57)
21Feb17_123312|labels.shape = (2300,)
21Feb17_123312|Class distribution:
21Feb17_123312|	0 - 1389 (0.60)
21Feb17_123312|	1 - 911 (0.40)
21Feb17_123312|Data summary: Validation
21Feb17_123312|data.shape = (1150, 57)
21Feb17_123312|labels.shape = (1150,)
21Feb17_123312|Class distribution:
21Feb17_123312|	0 - 667 (0.58)
21Feb17_123312|	1 - 483 (0.42)
21Feb17_123312|Data summary: Test
21Feb17_123312|data.shape = (1151, 57)
21Feb17_123312|labels.shape = (1151,)
21Feb17_123312|Class distribution:
21Feb17_123312|	0 - 732 (0.64)
21Feb17_123312|	1 - 419 (0.36)
21Feb17_123312|Selected configuration values
21Feb17_123312|-- Dataset name: spambase2
21Feb17_123312|-- Initial population size: 64
21Feb17_123312|-- Maximun number of generations: 32
21Feb17_123312|-- Neurons per hidden layer range: (2, 20)
21Feb17_123312|-- Hidden layers number range: (1, 3)
21Feb17_123312|-- Crossover probability: 0.5
21Feb17_123312|-- Bias gene mutation probability: 0.2
21Feb17_123312|-- Weights gene mutation probability: 0.75
21Feb17_123312|-- Neuron mutation probability: 0.3
21Feb17_123312|-- Layer mutation probability: 0.3
21Feb17_123312|-- Constant hidden layers: False
21Feb17_123312|-- Seed: 31415
21Feb17_123312|Entering GA
21Feb17_123312|Start the algorithm
21Feb17_123657|-- Generation 1 --
21Feb17_123657|    -- Crossed 0 individual pairs.
21Feb17_123657|    -- Mutated 32 individuals.
21Feb17_124020|    -- Evaluated 64 individuals.
21Feb17_124020|    Summary of generation 1:
21Feb17_124020| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_124020|-----------  ------------------  --------------------  ----------
21Feb17_124020|    Max            42.70                78.00           0.43478
21Feb17_124020|    Avg            41.90                26.28           0.00941
21Feb17_124020|    Min            35.91                 2.00           0.00000
21Feb17_124020|    Std             0.81                18.75           0.05509
21Feb17_124020|   Best            35.91                18.00           0.43478
21Feb17_124020|-- Generation 2 --
21Feb17_124020|    -- Crossed 1 individual pairs.
21Feb17_124020|    -- Mutated 32 individuals.
21Feb17_124337|    -- Evaluated 64 individuals.
21Feb17_124337|    Summary of generation 2:
21Feb17_124337| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_124337|-----------  ------------------  --------------------  ----------
21Feb17_124337|    Max            58.00                84.00           0.79977
21Feb17_124337|    Avg            41.99                15.92           0.02879
21Feb17_124337|    Min            29.65                 2.00           0.00000
21Feb17_124337|    Std             2.55                13.60           0.13781
21Feb17_124337|   Best            29.65                18.00           0.79977
21Feb17_124337|-- Generation 3 --
21Feb17_124337|    -- Crossed 3 individual pairs.
21Feb17_124337|    -- Mutated 32 individuals.
21Feb17_124652|    -- Evaluated 64 individuals.
21Feb17_124652|    Summary of generation 3:
21Feb17_124652| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_124652|-----------  ------------------  --------------------  ----------
21Feb17_124652|    Max            58.00                50.00           0.78358
21Feb17_124652|    Avg            41.97                13.73           0.02564
21Feb17_124652|    Min            26.09                 2.00           0.00000
21Feb17_124652|    Std             2.83                12.88           0.13211
21Feb17_124652|   Best            26.09                18.00           0.73476
21Feb17_124652|-- Generation 4 --
21Feb17_124652|    -- Crossed 4 individual pairs.
21Feb17_124652|    -- Mutated 32 individuals.
21Feb17_125003|    -- Evaluated 64 individuals.
21Feb17_125003|    Summary of generation 4:
21Feb17_125003| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_125003|-----------  ------------------  --------------------  ----------
21Feb17_125003|    Max            42.17                63.00           0.00517
21Feb17_125003|    Avg            42.01                 8.34           0.00085
21Feb17_125003|    Min            41.91                 2.00           0.00000
21Feb17_125003|    Std             0.06                 9.60           0.00165
21Feb17_125003|   Best            41.91                 4.00           0.00517
21Feb17_125003|-- Generation 5 --
21Feb17_125003|    -- Crossed 6 individual pairs.
21Feb17_125003|    -- Mutated 32 individuals.
21Feb17_125312|    -- Evaluated 64 individuals.
21Feb17_125312|    Summary of generation 5:
21Feb17_125312| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_125312|-----------  ------------------  --------------------  ----------
21Feb17_125312|    Max            42.09                20.00           0.05344
21Feb17_125312|    Avg            41.98                 5.28           0.00172
21Feb17_125312|    Min            41.22                 2.00           0.00000
21Feb17_125312|    Std             0.11                 4.46           0.00681
21Feb17_125312|   Best            41.22                14.00           0.05344
21Feb17_125312|-- Generation 6 --
21Feb17_125312|    -- Crossed 7 individual pairs.
21Feb17_125312|    -- Mutated 32 individuals.
21Feb17_125624|    -- Evaluated 64 individuals.
21Feb17_125624|    Summary of generation 6:
21Feb17_125624| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_125624|-----------  ------------------  --------------------  ----------
21Feb17_125624|    Max            42.26                18.00           0.01548
21Feb17_125624|    Avg            41.99                 6.00           0.00105
21Feb17_125624|    Min            41.48                 2.00           0.00000
21Feb17_125624|    Std             0.09                 4.81           0.00231
21Feb17_125624|   Best            41.48                 3.00           0.01548
21Feb17_125624|-- Generation 7 --
21Feb17_125624|    -- Crossed 9 individual pairs.
21Feb17_125624|    -- Mutated 32 individuals.
21Feb17_125935|    -- Evaluated 64 individuals.
21Feb17_125935|    Summary of generation 7:
21Feb17_125935| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_125935|-----------  ------------------  --------------------  ----------
21Feb17_125935|    Max            42.09                36.00           0.01033
21Feb17_125935|    Avg            41.99                 5.98           0.00089
21Feb17_125935|    Min            41.65                 2.00           0.00000
21Feb17_125935|    Std             0.06                 6.14           0.00184
21Feb17_125935|   Best            41.65                 3.00           0.01033
21Feb17_125935|-- Generation 8 --
21Feb17_125935|    -- Crossed 9 individual pairs.
21Feb17_125935|    -- Mutated 32 individuals.
21Feb17_130245|    -- Evaluated 64 individuals.
21Feb17_130245|    Summary of generation 8:
21Feb17_130245| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_130245|-----------  ------------------  --------------------  ----------
21Feb17_130245|    Max            42.17                18.00           0.04103
21Feb17_130245|    Avg            41.97                 5.09           0.00169
21Feb17_130245|    Min            40.78                 2.00           0.00000
21Feb17_130245|    Std             0.16                 4.37           0.00529
21Feb17_130245|   Best            40.78                12.00           0.04103
21Feb17_130245|-- Generation 9 --
21Feb17_130245|    -- Crossed 8 individual pairs.
21Feb17_130245|    -- Mutated 32 individuals.
21Feb17_130556|    -- Evaluated 64 individuals.
21Feb17_130556|    Summary of generation 9:
21Feb17_130556| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_130556|-----------  ------------------  --------------------  ----------
21Feb17_130556|    Max            48.87                18.00           0.80667
21Feb17_130556|    Avg            41.71                 6.17           0.03823
21Feb17_130556|    Min            30.61                 2.00           0.00000
21Feb17_130556|    Std             2.17                 5.04           0.16210
21Feb17_130556|   Best            30.61                 8.00           0.78607
21Feb17_130556|-- Generation 10 --
21Feb17_130556|    -- Crossed 5 individual pairs.
21Feb17_130556|    -- Mutated 32 individuals.
21Feb17_130908|    -- Evaluated 64 individuals.
21Feb17_130908|    Summary of generation 10:
21Feb17_130908| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_130908|-----------  ------------------  --------------------  ----------
21Feb17_130908|    Max            42.26                18.00           0.58344
21Feb17_130908|    Avg            41.43                 6.23           0.02714
21Feb17_130908|    Min            27.74                 2.00           0.00000
21Feb17_130908|    Std             2.43                 4.89           0.10887
21Feb17_130908|   Best            27.74                18.00           0.51616
21Feb17_130908|-- Generation 11 --
21Feb17_130908|    -- Crossed 8 individual pairs.
21Feb17_130908|    -- Mutated 32 individuals.
21Feb17_131223|    -- Evaluated 64 individuals.
21Feb17_131223|    Summary of generation 11:
21Feb17_131223| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_131223|-----------  ------------------  --------------------  ----------
21Feb17_131223|    Max            58.00                34.00           0.78358
21Feb17_131223|    Avg            41.87                 7.95           0.03476
21Feb17_131223|    Min            28.00                 2.00           0.00000
21Feb17_131223|    Std             2.88                 6.49           0.14854
21Feb17_131223|   Best            28.00                 8.00           0.52079
21Feb17_131223|-- Generation 12 --
21Feb17_131223|    -- Crossed 3 individual pairs.
21Feb17_131223|    -- Mutated 32 individuals.
21Feb17_131536|    -- Evaluated 64 individuals.
21Feb17_131536|    Summary of generation 12:
21Feb17_131536| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_131536|-----------  ------------------  --------------------  ----------
21Feb17_131536|    Max            42.35                36.00           0.67494
21Feb17_131536|    Avg            41.46                 7.03           0.02217
21Feb17_131536|    Min            24.96                 2.00           0.00000
21Feb17_131536|    Std             2.67                 5.88           0.11025
21Feb17_131536|   Best            24.96                18.00           0.67494
21Feb17_131536|-- Generation 13 --
21Feb17_131536|    -- Crossed 5 individual pairs.
21Feb17_131536|    -- Mutated 32 individuals.
21Feb17_131851|    -- Evaluated 64 individuals.
21Feb17_131851|    Summary of generation 13:
21Feb17_131851| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_131851|-----------  ------------------  --------------------  ----------
21Feb17_131851|    Max            42.61                36.00           0.61562
21Feb17_131851|    Avg            41.50                 8.56           0.02210
21Feb17_131851|    Min            26.78                 2.00           0.00000
21Feb17_131851|    Std             2.40                 7.93           0.10577
21Feb17_131851|   Best            26.78                18.00           0.61562
21Feb17_131851|-- Generation 14 --
21Feb17_131851|    -- Crossed 7 individual pairs.
21Feb17_131851|    -- Mutated 32 individuals.
21Feb17_132206|    -- Evaluated 64 individuals.
21Feb17_132206|    Summary of generation 14:
21Feb17_132206| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_132206|-----------  ------------------  --------------------  ----------
21Feb17_132206|    Max            42.09                40.00           0.75188
21Feb17_132206|    Avg            41.48                 8.12           0.02679
21Feb17_132206|    Min            27.65                 2.00           0.00000
21Feb17_132206|    Std             2.42                 6.72           0.13015
21Feb17_132206|   Best            27.65                18.00           0.75188
21Feb17_132206|-- Generation 15 --
21Feb17_132206|    -- Crossed 6 individual pairs.
21Feb17_132206|    -- Mutated 32 individuals.
21Feb17_132519|    -- Evaluated 64 individuals.
21Feb17_132519|    Summary of generation 15:
21Feb17_132519| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_132519|-----------  ------------------  --------------------  ----------
21Feb17_132519|    Max            42.09                40.00           0.73387
21Feb17_132519|    Avg            41.42                 7.69           0.02610
21Feb17_132519|    Min            26.35                 2.00           0.00000
21Feb17_132519|    Std             2.71                 6.44           0.12590
21Feb17_132519|   Best            26.35                18.00           0.71951
21Feb17_132519|-- Generation 16 --
21Feb17_132519|    -- Crossed 5 individual pairs.
21Feb17_132519|    -- Mutated 32 individuals.
21Feb17_132831|    -- Evaluated 64 individuals.
21Feb17_132831|    Summary of generation 16:
21Feb17_132831| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_132831|-----------  ------------------  --------------------  ----------
21Feb17_132831|    Max            42.26                44.00           0.82855
21Feb17_132831|    Avg            41.21                 7.83           0.03973
21Feb17_132831|    Min            24.87                 2.00           0.00000
21Feb17_132831|    Std             3.23                 7.99           0.16234
21Feb17_132831|   Best            24.87                21.00           0.68287
21Feb17_132831|-- Generation 17 --
21Feb17_132831|    -- Crossed 8 individual pairs.
21Feb17_132831|    -- Mutated 32 individuals.
21Feb17_133148|    -- Evaluated 64 individuals.
21Feb17_133148|    Summary of generation 17:
21Feb17_133148| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_133148|-----------  ------------------  --------------------  ----------
21Feb17_133148|    Max            42.26                44.00           0.80877
21Feb17_133148|    Avg            40.86                 8.81           0.06413
21Feb17_133148|    Min            25.04                 2.00           0.00000
21Feb17_133148|    Std             3.59                 8.94           0.19340
21Feb17_133148|   Best            25.04                10.00           0.72247
21Feb17_133148|-- Generation 18 --
21Feb17_133148|    -- Crossed 2 individual pairs.
21Feb17_133148|    -- Mutated 32 individuals.
21Feb17_133506|    -- Evaluated 64 individuals.
21Feb17_133506|    Summary of generation 18:
21Feb17_133506| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_133506|-----------  ------------------  --------------------  ----------
21Feb17_133506|    Max            47.04                44.00           0.81211
21Feb17_133506|    Avg            39.55                10.78           0.12108
21Feb17_133506|    Min            24.35                 3.00           0.00000
21Feb17_133506|    Std             5.74                11.16           0.25939
21Feb17_133506|   Best            24.35                44.00           0.72485
21Feb17_133506|-- Generation 19 --
21Feb17_133507|    -- Crossed 7 individual pairs.
21Feb17_133507|    -- Mutated 32 individuals.
21Feb17_133832|    -- Evaluated 64 individuals.
21Feb17_133832|    Summary of generation 19:
21Feb17_133832| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_133832|-----------  ------------------  --------------------  ----------
21Feb17_133832|    Max            42.87                70.00           0.81774
21Feb17_133832|    Avg            39.09                14.53           0.14606
21Feb17_133832|    Min            24.70                 3.00           0.00000
21Feb17_133832|    Std             5.78                15.60           0.27609
21Feb17_133832|   Best            24.70                44.00           0.69102
21Feb17_133832|-- Generation 20 --
21Feb17_133832|    -- Crossed 3 individual pairs.
21Feb17_133832|    -- Mutated 32 individuals.
21Feb17_134201|    -- Evaluated 64 individuals.
21Feb17_134201|    Summary of generation 20:
21Feb17_134201| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_134201|-----------  ------------------  --------------------  ----------
21Feb17_134201|    Max            42.17                60.00           0.79174
21Feb17_134201|    Avg            39.05                15.47           0.15453
21Feb17_134201|    Min            24.09                 3.00           0.00000
21Feb17_134201|    Std             5.60                16.03           0.28335
21Feb17_134201|   Best            24.09                48.00           0.76568
21Feb17_134201|-- Generation 21 --
21Feb17_134201|    -- Crossed 4 individual pairs.
21Feb17_134201|    -- Mutated 32 individuals.
21Feb17_134534|    -- Evaluated 64 individuals.
21Feb17_134534|    Summary of generation 21:
21Feb17_134534| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_134534|-----------  ------------------  --------------------  ----------
21Feb17_134534|    Max            42.17                90.00           0.80579
21Feb17_134534|    Avg            38.34                18.45           0.19938
21Feb17_134534|    Min            23.91                 2.00           0.00000
21Feb17_134534|    Std             5.87                19.09           0.30554
21Feb17_134534|   Best            23.91                48.00           0.71458
21Feb17_134534|-- Generation 22 --
21Feb17_134534|    -- Crossed 2 individual pairs.
21Feb17_134534|    -- Mutated 32 individuals.
21Feb17_134913|    -- Evaluated 64 individuals.
21Feb17_134913|    Summary of generation 22:
21Feb17_134913| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_134913|-----------  ------------------  --------------------  ----------
21Feb17_134913|    Max            42.09                60.00           0.82362
21Feb17_134913|    Avg            36.71                21.28           0.25981
21Feb17_134913|    Min            24.26                 2.00           0.00000
21Feb17_134913|    Std             6.98                18.25           0.33831
21Feb17_134913|   Best            24.26                52.00           0.76087
21Feb17_134913|-- Generation 23 --
21Feb17_134913|    -- Crossed 2 individual pairs.
21Feb17_134913|    -- Mutated 32 individuals.
21Feb17_135301|    -- Evaluated 64 individuals.
21Feb17_135301|    Summary of generation 23:
21Feb17_135301| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_135301|-----------  ------------------  --------------------  ----------
21Feb17_135301|    Max            42.09                96.00           0.78772
21Feb17_135301|    Avg            35.35                29.28           0.32114
21Feb17_135301|    Min            23.39                 2.00           0.00000
21Feb17_135301|    Std             7.15                21.95           0.34435
21Feb17_135301|   Best            23.39                52.00           0.72814
21Feb17_135301|-- Generation 24 --
21Feb17_135301|    -- Crossed 0 individual pairs.
21Feb17_135301|    -- Mutated 32 individuals.
21Feb17_135701|    -- Evaluated 64 individuals.
21Feb17_135701|    Summary of generation 24:
21Feb17_135701| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_135701|-----------  ------------------  --------------------  ----------
21Feb17_135701|    Max            43.30                80.00           0.82075
21Feb17_135701|    Avg            33.81                36.61           0.38588
21Feb17_135701|    Min            23.22                 2.00           0.00000
21Feb17_135701|    Std             7.30                19.72           0.34184
21Feb17_135701|   Best            23.22                52.00           0.73602
21Feb17_135701|-- Generation 25 --
21Feb17_135701|    -- Crossed 3 individual pairs.
21Feb17_135701|    -- Mutated 32 individuals.
21Feb17_140110|    -- Evaluated 64 individuals.
21Feb17_140110|    Summary of generation 25:
21Feb17_140110| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_140110|-----------  ------------------  --------------------  ----------
21Feb17_140110|    Max            51.74                114.00          0.82799
21Feb17_140110|    Avg            33.58                45.08           0.45457
21Feb17_140110|    Min            23.91                 8.00           0.00000
21Feb17_140110|    Std             7.24                19.61           0.35022
21Feb17_140110|   Best            23.91                48.00           0.72048
21Feb17_140110|-- Generation 26 --
21Feb17_140110|    -- Crossed 1 individual pairs.
21Feb17_140110|    -- Mutated 32 individuals.
21Feb17_140522|    -- Evaluated 64 individuals.
21Feb17_140522|    Summary of generation 26:
21Feb17_140522| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_140522|-----------  ------------------  --------------------  ----------
21Feb17_140522|    Max            42.35                108.00          0.84388
21Feb17_140522|    Avg            32.71                48.80           0.44554
21Feb17_140522|    Min            23.30                 2.00           0.00000
21Feb17_140522|    Std             7.16                22.53           0.33996
21Feb17_140522|   Best            23.30                24.00           0.69415
21Feb17_140522|-- Generation 27 --
21Feb17_140522|    -- Crossed 1 individual pairs.
21Feb17_140522|    -- Mutated 32 individuals.
21Feb17_140934|    -- Evaluated 64 individuals.
21Feb17_140934|    Summary of generation 27:
21Feb17_140934| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_140934|-----------  ------------------  --------------------  ----------
21Feb17_140934|    Max            42.26                132.00          0.82552
21Feb17_140934|    Avg            32.16                51.20           0.45948
21Feb17_140934|    Min            21.74                 8.00           0.00000
21Feb17_140934|    Std             7.19                22.48           0.32234
21Feb17_140934|   Best            21.74                18.00           0.76278
21Feb17_140934|-- Generation 28 --
21Feb17_140934|    -- Crossed 0 individual pairs.
21Feb17_140934|    -- Mutated 32 individuals.
21Feb17_141348|    -- Evaluated 64 individuals.
21Feb17_141348|    Summary of generation 28:
21Feb17_141348| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_141348|-----------  ------------------  --------------------  ----------
21Feb17_141348|    Max            42.00                132.00          0.83850
21Feb17_141348|    Avg            31.52                51.11           0.49187
21Feb17_141348|    Min            23.04                12.00           0.00000
21Feb17_141348|    Std             6.86                24.66           0.32040
21Feb17_141348|   Best            23.04                24.00           0.73226
21Feb17_141348|-- Generation 29 --
21Feb17_141348|    -- Crossed 0 individual pairs.
21Feb17_141348|    -- Mutated 32 individuals.
21Feb17_141759|    -- Evaluated 64 individuals.
21Feb17_141759|    Summary of generation 29:
21Feb17_141759| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_141759|-----------  ------------------  --------------------  ----------
21Feb17_141759|    Max            42.09                132.00          0.82871
21Feb17_141759|    Avg            32.10                49.19           0.44677
21Feb17_141759|    Min            22.26                12.00           0.00000
21Feb17_141759|    Std             7.60                23.20           0.33800
21Feb17_141759|   Best            22.26                56.00           0.74227
21Feb17_141759|-- Generation 30 --
21Feb17_141759|    -- Crossed 0 individual pairs.
21Feb17_141759|    -- Mutated 32 individuals.
21Feb17_142208|    -- Evaluated 64 individuals.
21Feb17_142208|    Summary of generation 30:
21Feb17_142208| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_142208|-----------  ------------------  --------------------  ----------
21Feb17_142208|    Max            42.09                100.00          0.82371
21Feb17_142208|    Avg            31.14                49.09           0.49033
21Feb17_142208|    Min            22.00                14.00           0.00000
21Feb17_142208|    Std             7.06                18.85           0.31415
21Feb17_142208|   Best            22.00                56.00           0.78704
21Feb17_142208|-- Generation 31 --
21Feb17_142208|    -- Crossed 1 individual pairs.
21Feb17_142208|    -- Mutated 32 individuals.
21Feb17_142618|    -- Evaluated 64 individuals.
21Feb17_142618|    Summary of generation 31:
21Feb17_142618| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_142618|-----------  ------------------  --------------------  ----------
21Feb17_142618|    Max            42.52                100.00          0.83333
21Feb17_142618|    Avg            32.54                52.38           0.44410
21Feb17_142618|    Min            22.96                 8.00           0.00000
21Feb17_142618|    Std             7.42                21.79           0.34342
21Feb17_142618|   Best            22.96                44.00           0.72671
21Feb17_142618|-- Generation 32 --
21Feb17_142618|    -- Crossed 1 individual pairs.
21Feb17_142618|    -- Mutated 32 individuals.
21Feb17_143026|    -- Evaluated 64 individuals.
21Feb17_143026|    Summary of generation 32:
21Feb17_143026| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb17_143026|-----------  ------------------  --------------------  ----------
21Feb17_143026|    Max            42.00                85.00           0.83038
21Feb17_143026|    Avg            32.40                52.83           0.43440
21Feb17_143026|    Min            21.57                 8.00           0.00000
21Feb17_143026|    Std             7.70                18.10           0.34013
21Feb17_143026|   Best            21.57                56.00           0.83038
21Feb17_143026|Best initial individual weights
21Feb17_143026|Individual:
21Feb17_143026|-- Constant hidden layers --
21Feb17_143026|False
21Feb17_143026|Layer 0:
21Feb17_143026|-- Config --
21Feb17_143026|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 12, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143026|-- Weights --
21Feb17_143026|[[-3.50529e-01 -6.53069e-03 -7.03730e-01 -6.33906e-01  6.10835e-02
21Feb17_143026|   4.57449e-01 -3.77835e-01  6.38481e-01  4.24141e-01  6.68786e-01
21Feb17_143026|  -4.86511e-01 -9.28542e-01]
21Feb17_143026| [-8.31270e-01 -3.94586e-01  5.51697e-02 -8.86387e-01 -6.99786e-01
21Feb17_143026|   6.44047e-01 -5.40571e-01  3.77503e-01  1.70193e-01  5.92883e-01
21Feb17_143026|   2.06540e-01  2.18639e-01]
21Feb17_143026| [-8.13637e-01  7.25044e-01  6.66092e-01  5.31057e-01 -4.48634e-01
21Feb17_143026|  -1.62601e-01 -1.57458e-02  7.74238e-02 -4.81841e-01  3.55485e-02
21Feb17_143026|  -7.21169e-01  1.05129e-01]
21Feb17_143026| [ 6.07201e-01  6.23643e-01  8.87343e-01  6.04285e-01  5.70453e-02
21Feb17_143026|   5.99381e-01 -3.21663e-03  6.64196e-01 -5.25584e-01 -1.74507e-02
21Feb17_143026|   3.80029e-01 -4.59585e-01]
21Feb17_143026| [-9.00078e-01  8.63133e-01  8.49324e-01  4.34648e-01 -5.67121e-01
21Feb17_143026|   6.24299e-01 -6.46637e-01  9.34620e-01 -5.42838e-01 -4.04257e-01
21Feb17_143026|  -4.70046e-01  4.29712e-01]
21Feb17_143026| [ 9.51731e-02  8.42954e-01 -7.44806e-01 -5.56045e-02 -4.89209e-01
21Feb17_143026|   8.07612e-01  2.77691e-01 -5.77946e-02  4.30356e-01 -9.05718e-01
21Feb17_143026|  -7.61358e-01 -4.56367e-01]
21Feb17_143026| [-9.06447e-01 -4.46566e-01 -4.40669e-01  6.09161e-01 -3.32587e-01
21Feb17_143026|  -9.31356e-01  9.62597e-02 -1.83060e-01  5.91585e-01 -2.78230e-01
21Feb17_143026|  -3.70976e-01 -3.38510e-01]
21Feb17_143026| [ 5.92999e-02 -5.35945e-01 -8.52259e-01  1.62766e-01 -2.64657e-01
21Feb17_143026|   6.65182e-01  2.45597e-01  2.99711e-01  7.14862e-01 -4.00362e-01
21Feb17_143026|   3.40170e-01 -1.14174e-01]
21Feb17_143026| [-4.26995e-01  8.46146e-01  9.81523e-01 -2.62996e-01  8.65377e-01
21Feb17_143026|  -6.86144e-01 -3.53983e-01 -2.18499e-01  3.29010e-01 -8.26088e-01
21Feb17_143026|   1.48202e-01  5.27152e-01]
21Feb17_143026| [-1.97937e-01  5.44304e-02  9.68680e-01  1.96012e-01  6.66432e-01
21Feb17_143026|  -1.15663e-01  1.01696e-01 -9.91833e-01  5.54656e-02  5.06069e-01
21Feb17_143026|  -8.39702e-01  6.07914e-02]
21Feb17_143026| [ 8.22409e-01 -3.07988e-01 -4.87097e-01 -2.67403e-01 -3.17115e-01
21Feb17_143026|   6.20877e-01  2.45721e-01  1.47039e-01  8.22748e-02 -4.61491e-01
21Feb17_143026|   5.08690e-01 -8.10093e-01]
21Feb17_143026| [-1.03463e-01 -7.13247e-01 -5.27190e-01 -8.14055e-01 -2.20069e-01
21Feb17_143026|   7.58689e-01  7.72478e-01 -3.75243e-01 -1.74773e-01  4.33018e-02
21Feb17_143026|   5.76591e-01 -9.04182e-01]
21Feb17_143026| [ 6.39880e-01 -2.76473e-01  4.48413e-01  7.92996e-01  6.12921e-01
21Feb17_143026|   8.45232e-01 -3.59434e-01 -1.65084e-01  6.00279e-01 -9.07135e-01
21Feb17_143026|  -9.18766e-01 -3.84510e-02]
21Feb17_143026| [-4.35982e-01  3.53117e-01 -4.33635e-01  4.41189e-01  2.02385e-01
21Feb17_143026|  -2.15156e-01 -3.32093e-01 -9.46393e-01  7.49818e-01  7.56840e-01
21Feb17_143026|  -2.97280e-01  3.76513e-01]
21Feb17_143026| [ 2.00098e-01 -3.94368e-01  4.74964e-01 -5.14077e-01 -5.02985e-01
21Feb17_143026|   6.57337e-01  4.54284e-01  7.99434e-01  1.18259e-01  7.90625e-01
21Feb17_143026|  -8.45168e-01 -7.22624e-01]
21Feb17_143026| [ 5.21361e-01 -9.37087e-01  6.98489e-01  7.45747e-01  9.84330e-01
21Feb17_143026|  -1.70463e-01 -4.14211e-01  4.94059e-01 -4.89685e-03 -7.22161e-02
21Feb17_143026|   3.28119e-01 -2.96382e-01]
21Feb17_143026| [ 9.97912e-02 -3.45331e-01 -3.32041e-01 -8.83410e-01  4.64194e-01
21Feb17_143026|  -2.94905e-01 -7.11116e-01 -2.12420e-01  8.93334e-01  5.60374e-01
21Feb17_143026|  -8.11522e-01  3.94537e-01]
21Feb17_143026| [ 2.39284e-01 -9.68110e-02 -3.48403e-01  6.68017e-01  1.07039e-01
21Feb17_143026|  -1.80014e-01 -1.28612e-01 -3.28318e-01  7.99371e-01  7.45882e-01
21Feb17_143026|   4.50426e-01 -9.94601e-02]
21Feb17_143026| [-9.32040e-02 -4.99896e-01 -3.18835e-01 -3.21963e-01  8.88030e-02
21Feb17_143026|   8.24115e-01  3.93190e-01  2.14054e-01 -4.70631e-02  5.36199e-01
21Feb17_143026|   7.72001e-01 -1.38053e-01]
21Feb17_143026| [ 8.31611e-01  7.46409e-01  2.18558e-01  7.47226e-01 -4.35942e-01
21Feb17_143026|  -6.59230e-01  3.39715e-02  8.14827e-01 -7.32488e-02 -1.12845e-01
21Feb17_143026|  -5.06295e-01  2.18074e-01]
21Feb17_143026| [-3.26563e-01  6.22846e-01  3.85669e-01 -9.86028e-01 -7.51629e-02
21Feb17_143026|  -1.88021e-01  7.27322e-01  5.61207e-04  1.34321e-01  7.19415e-01
21Feb17_143026|  -5.83277e-01 -4.45815e-01]
21Feb17_143026| [ 7.83756e-01  9.31803e-02  4.99853e-01 -9.31861e-01  7.91593e-01
21Feb17_143026|   1.96250e-01 -8.00498e-02  7.34271e-01 -2.68771e-01  7.49220e-01
21Feb17_143026|   1.24815e-01  6.17245e-01]
21Feb17_143026| [ 2.20500e-01 -9.26851e-01 -5.03545e-02  9.91366e-01  9.07862e-01
21Feb17_143026|   6.95839e-01  2.07702e-01  1.55262e-01  7.17753e-01 -6.02225e-01
21Feb17_143026|  -2.43972e-02  7.83904e-01]
21Feb17_143026| [-7.35179e-01 -4.04922e-01 -7.64988e-01  6.94764e-03 -5.74469e-01
21Feb17_143026|  -8.82582e-01 -4.25720e-01  4.48261e-01  9.38039e-01 -6.02162e-01
21Feb17_143026|   1.85138e-01  8.19467e-01]
21Feb17_143026| [-2.42564e-01  5.05630e-02 -6.53631e-01  8.89456e-01  3.73267e-02
21Feb17_143026|  -4.57479e-01  5.78190e-01 -8.65769e-01  4.43846e-01  9.21993e-01
21Feb17_143026|  -4.59642e-01  4.55887e-01]
21Feb17_143026| [ 1.79502e-01  5.97755e-01 -5.91581e-01  6.50878e-01 -3.20822e-02
21Feb17_143026|   7.98103e-01  9.23662e-01 -3.15762e-01  3.95919e-01 -9.74799e-01
21Feb17_143026|  -9.18783e-01  9.04381e-01]
21Feb17_143026| [-9.77544e-01 -9.84191e-01 -3.78989e-01  1.57093e-01 -1.19240e-01
21Feb17_143026|   7.04336e-01  9.20317e-01 -9.23300e-02  7.24512e-01 -4.73620e-01
21Feb17_143026|   4.32204e-01  1.96422e-01]
21Feb17_143026| [-9.94008e-01  1.23345e-01 -2.91311e-01  3.86181e-01  3.50519e-01
21Feb17_143026|   8.97293e-02  1.28693e-01  7.64175e-01  9.70172e-01 -9.36008e-01
21Feb17_143026|   2.31190e-01 -3.81352e-01]
21Feb17_143026| [-8.68842e-01 -3.08689e-01 -7.85613e-02 -7.75421e-01 -2.62711e-01
21Feb17_143026|  -9.13854e-01  5.58996e-01  8.97445e-01 -4.78631e-01 -4.79708e-02
21Feb17_143026|  -2.09270e-01  1.03320e-01]
21Feb17_143026| [ 2.47190e-01  8.94828e-01 -8.83655e-01  1.67368e-01 -1.09226e-01
21Feb17_143026|   5.39374e-01  3.22158e-01  7.22802e-01 -4.76431e-01 -3.98606e-01
21Feb17_143026|   3.91466e-01 -5.89172e-01]
21Feb17_143026| [ 2.03966e-01 -8.11217e-01  8.56319e-01 -5.26108e-01 -9.29896e-01
21Feb17_143026|   5.92077e-01  8.52854e-01  6.15086e-01  5.45676e-01 -8.13950e-01
21Feb17_143026|   6.24771e-01 -9.57171e-01]
21Feb17_143026| [-7.59457e-01  2.18652e-01 -9.40198e-01 -1.94388e-03 -3.63300e-01
21Feb17_143026|   2.19527e-01 -3.86609e-01  6.57866e-02  8.04643e-01  4.37489e-01
21Feb17_143026|   6.39988e-01 -8.42788e-01]
21Feb17_143026| [-2.79911e-01  8.89651e-01  5.38994e-02  7.45843e-01 -9.32154e-01
21Feb17_143026|   5.56522e-01  5.04658e-01  3.56409e-01 -5.15289e-01  6.99550e-01
21Feb17_143026|  -7.31032e-01  1.61260e-01]
21Feb17_143026| [ 8.41582e-01 -5.25391e-01  4.65437e-01  4.40808e-01 -6.03761e-01
21Feb17_143026|   6.23036e-01  9.46114e-01  5.92328e-01  2.08190e-01 -6.69715e-01
21Feb17_143026|  -7.35264e-02  5.96491e-01]
21Feb17_143026| [ 3.20347e-01  1.37290e-01  1.72843e-02 -4.70187e-01  5.92987e-01
21Feb17_143026|   3.57672e-01  2.73873e-01 -8.65750e-02 -3.09144e-01 -9.20603e-01
21Feb17_143026|   2.82912e-01  6.38325e-01]
21Feb17_143026| [-8.91399e-01 -1.24857e-01 -4.86431e-01 -9.05166e-01  8.47373e-01
21Feb17_143026|   3.18146e-01  2.73494e-02 -5.33112e-01  5.63862e-01 -5.12821e-01
21Feb17_143026|  -9.38474e-01 -9.90043e-01]
21Feb17_143026| [-8.25448e-01 -1.90141e-02 -5.51276e-01 -8.23215e-01  7.26222e-02
21Feb17_143026|   3.49894e-01  5.17693e-01 -5.57217e-01 -3.26301e-01  7.78564e-01
21Feb17_143026|   6.58213e-01 -2.83929e-01]
21Feb17_143026| [ 6.18012e-02 -4.92329e-01  5.41071e-01  2.13013e-01  6.35700e-01
21Feb17_143026|  -1.65529e-01  5.77357e-01  2.45531e-01  2.54855e-01 -8.48854e-01
21Feb17_143026|   6.46386e-01 -4.13404e-01]
21Feb17_143026| [-3.41116e-01 -4.75918e-01  3.59165e-01  6.02895e-01 -4.31688e-01
21Feb17_143026|  -8.51757e-01  2.31464e-01 -9.57407e-01  2.83436e-01 -4.51744e-01
21Feb17_143026|   4.80022e-02 -8.35007e-01]
21Feb17_143026| [ 9.67499e-01  5.85047e-02  7.21540e-01  3.12459e-01  3.50272e-01
21Feb17_143026|   2.14450e-01 -3.30294e-01 -7.99000e-01  1.11959e-01  2.74091e-01
21Feb17_143026|  -1.78234e-01  9.40235e-01]
21Feb17_143026| [-1.14387e-01  4.31319e-01  3.73789e-01 -4.62497e-01  4.50407e-01
21Feb17_143026|  -4.00668e-01 -8.26575e-01  2.39589e-01 -5.24611e-01  3.30691e-01
21Feb17_143026|  -3.99504e-01  1.44547e-01]
21Feb17_143026| [ 7.34826e-01 -5.37352e-01 -6.62895e-01  1.04258e-01  2.15046e-03
21Feb17_143026|   2.71790e-01  8.51151e-01 -6.31948e-01  1.94011e-01 -6.41830e-01
21Feb17_143026|   1.67802e-01 -4.29449e-01]
21Feb17_143026| [-6.18752e-01  1.18069e-01 -7.98263e-01  4.75266e-01 -9.95474e-01
21Feb17_143026|  -1.79698e-01  6.90455e-01  3.44607e-01 -5.80013e-01 -6.16218e-02
21Feb17_143026|   7.01329e-01  8.33298e-02]
21Feb17_143026| [-2.69227e-01 -1.43165e-02 -3.33533e-01 -1.69954e-01 -1.26476e-02
21Feb17_143026|   7.69653e-01 -6.99893e-01  5.22539e-01 -1.67862e-01  4.44416e-01
21Feb17_143026|   6.72372e-01  5.52923e-01]
21Feb17_143026| [-7.10479e-01  1.61800e-01  2.53825e-01 -3.00634e-01 -5.06805e-01
21Feb17_143026|   2.02091e-01 -4.94980e-02 -1.44363e-01 -6.18371e-01  5.74350e-01
21Feb17_143026|  -1.85073e-01 -8.11049e-01]
21Feb17_143026| [-6.60846e-01 -1.69003e-01  6.00733e-01 -8.28618e-01 -3.99034e-01
21Feb17_143026|  -5.82553e-01  7.34428e-02  5.57096e-01 -1.50695e-01  1.26307e-01
21Feb17_143026|   8.92712e-01 -8.75142e-01]
21Feb17_143026| [ 7.58158e-01  5.89907e-01 -1.92304e-01 -3.86200e-01 -2.63049e-01
21Feb17_143026|  -3.41209e-03  4.05030e-01 -8.95945e-02  9.79113e-01  6.78942e-02
21Feb17_143026|  -9.53580e-01  7.06162e-01]
21Feb17_143026| [-1.23045e-01  9.25694e-01  5.20030e-01  4.57808e-01 -9.99639e-01
21Feb17_143026|  -9.80069e-02  3.03598e-01  4.26167e-02 -3.64595e-01 -7.17635e-01
21Feb17_143026|   1.61128e-01  6.30329e-01]
21Feb17_143026| [ 2.02232e-02 -3.24113e-01  7.43999e-01 -3.75983e-01  4.63558e-01
21Feb17_143026|  -2.04941e-01 -5.28404e-02  4.26576e-01 -2.53802e-01  1.74976e-01
21Feb17_143026|  -8.35763e-01  8.54548e-01]
21Feb17_143026| [-5.76875e-01  5.40954e-01 -4.91777e-01  4.40209e-01 -9.16379e-01
21Feb17_143026|   6.01728e-01  1.25226e-02  2.05876e-01  8.45524e-01 -8.34178e-01
21Feb17_143026|  -7.87379e-01  8.63352e-01]
21Feb17_143026| [-3.15102e-01  7.00213e-01  6.69503e-01  7.15510e-01 -9.53550e-01
21Feb17_143026|   4.07885e-02  4.25336e-01  6.24629e-01  9.90858e-01  6.36989e-01
21Feb17_143026|  -6.44355e-01 -5.47589e-01]
21Feb17_143026| [-8.25051e-01 -4.37574e-01  4.76334e-01 -7.71092e-01  7.98467e-01
21Feb17_143026|  -1.52347e-01  3.34469e-01  1.51889e-01 -9.60611e-01  4.62484e-01
21Feb17_143026|   4.10115e-01 -1.60555e-01]
21Feb17_143026| [ 1.77712e-01  6.55776e-01  8.97735e-01 -9.20852e-01 -9.69032e-01
21Feb17_143026|  -4.79756e-02 -3.24015e-01 -1.57490e-01 -6.25919e-01  9.94240e-01
21Feb17_143026|  -4.74141e-01 -1.00993e-01]
21Feb17_143026| [ 3.66246e-01  8.06205e-01  3.37216e-01 -3.17040e-01  9.19693e-01
21Feb17_143026|   8.28581e-01  2.22724e-01 -5.57410e-01 -8.17434e-01 -8.65693e-01
21Feb17_143026|  -4.72960e-01  7.15176e-01]
21Feb17_143026| [-8.25000e-01 -4.67253e-01 -1.84646e-02  3.88053e-01 -8.75853e-01
21Feb17_143026|  -2.34509e-01  9.53471e-01  8.05489e-02  2.71744e-01 -7.15129e-01
21Feb17_143026|   9.24875e-01 -6.07435e-01]
21Feb17_143026| [-2.79447e-01  2.39105e-01  1.32962e-01 -7.68103e-01  7.58443e-01
21Feb17_143026|  -1.69646e-01 -7.52460e-01 -7.30195e-01 -4.68985e-01 -2.88784e-01
21Feb17_143026|   3.77655e-02 -5.72024e-01]
21Feb17_143026| [-8.37481e-01 -8.22188e-02  8.45547e-01 -5.53876e-01  5.72703e-01
21Feb17_143026|   3.09970e-01  8.96552e-01  3.97690e-01 -7.19080e-01  2.37714e-01
21Feb17_143026|   6.60752e-01  1.69435e-01]]
21Feb17_143026|-- Bias --
21Feb17_143026|[-0.28065  0.08142 -0.20194  0.96969  0.45180  0.54884  0.16606 -0.15804
21Feb17_143026|  0.47362  0.17133  0.43345 -0.35803]
21Feb17_143026|Layer 1:
21Feb17_143026|-- Config --
21Feb17_143026|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 12], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143026|-- Weights --
21Feb17_143026|[[-0.88546  0.72941]
21Feb17_143026| [ 0.79196 -0.05477]
21Feb17_143026| [-0.89752 -0.49343]
21Feb17_143026| [ 0.78974 -0.41510]
21Feb17_143026| [ 0.29561 -0.94575]
21Feb17_143026| [-0.14754  0.69148]
21Feb17_143026| [-0.33558  0.37910]
21Feb17_143026| [-0.82387  0.15998]
21Feb17_143026| [-0.77760  0.88462]
21Feb17_143026| [ 0.98329 -0.68363]
21Feb17_143026| [ 0.88895  0.40387]
21Feb17_143026| [ 0.39015 -0.38652]]
21Feb17_143026|-- Bias --
21Feb17_143026|[ 0.28702 -0.70976]
21Feb17_143026|Predicting the validation and test data with the Best initial individual.
21Feb17_143031| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_143031|-----------  ------------------  --------------------  ----------
21Feb17_143031|Validation         42.00                  12            0.00000
21Feb17_143031|   Test            36.32                  12            0.00298
21Feb17_143031|-------------------- Test #0 --------------------
21Feb17_143031|Best final individual weights
21Feb17_143031|Individual:
21Feb17_143031|-- Constant hidden layers --
21Feb17_143031|False
21Feb17_143031|Layer 0:
21Feb17_143031|-- Config --
21Feb17_143031|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143031|-- Weights --
21Feb17_143031|[[-0.73212  1.32861  0.10200]
21Feb17_143031| [ 1.48746 -2.97273 -0.42944]
21Feb17_143031| [ 0.53095 -1.50623  0.79224]
21Feb17_143031| [-1.07292 -0.83175 -0.90105]
21Feb17_143031| [-0.48696 -0.89325  0.27226]
21Feb17_143031| [-3.02511  0.34155 -0.03837]
21Feb17_143031| [-0.76747  0.57140 -0.46892]
21Feb17_143031| [-0.07581  0.14713  0.85910]
21Feb17_143031| [-1.37488  0.52170 -0.36205]
21Feb17_143031| [ 1.60981 -0.08727 -0.11267]
21Feb17_143031| [ 0.50986  1.58916 -0.35287]
21Feb17_143031| [-0.34599  1.27113 -0.16393]
21Feb17_143031| [ 1.29203  1.19467  0.37695]
21Feb17_143031| [ 0.58704  0.06328 -0.24240]
21Feb17_143031| [-0.93888 -0.89760  0.57087]
21Feb17_143031| [ 0.99159 -0.66387  0.35177]
21Feb17_143031| [-0.67119  1.06910 -0.12512]
21Feb17_143031| [-0.91534  1.23744 -0.40465]
21Feb17_143031| [ 1.39278  0.08069  0.23328]
21Feb17_143031| [ 0.09880  0.57603 -0.96101]
21Feb17_143031| [ 0.01621 -0.13343 -0.27624]
21Feb17_143031| [-1.28286 -2.28909  0.37931]
21Feb17_143031| [-0.28370  0.09336  0.01547]
21Feb17_143031| [-0.51894  1.84280 -0.25906]
21Feb17_143031| [-0.83075 -0.04508  0.12107]
21Feb17_143031| [ 0.37343  1.18436 -0.07358]
21Feb17_143031| [-2.38657 -0.35191  0.01962]
21Feb17_143031| [ 0.95757 -0.91760 -0.08971]
21Feb17_143031| [ 0.38792 -0.01880  0.69717]
21Feb17_143031| [ 1.66877 -0.58078 -1.21129]
21Feb17_143031| [-0.50943  0.59080  0.30856]
21Feb17_143031| [ 0.30163  1.11518  0.98185]
21Feb17_143031| [-0.73226  0.32281 -0.66712]
21Feb17_143031| [-0.62054 -2.21049  1.40981]
21Feb17_143031| [ 1.23185 -0.58090  0.35844]
21Feb17_143031| [-0.05616  0.24219 -0.02853]
21Feb17_143031| [-1.05085 -2.30259 -0.16276]
21Feb17_143031| [ 0.71087  0.14900  1.13430]
21Feb17_143031| [-2.45877 -1.20999 -1.04986]
21Feb17_143031| [-1.00480  1.36344 -0.13998]
21Feb17_143031| [ 1.83140 -0.91532  0.07616]
21Feb17_143031| [-0.60404 -2.05184  0.76948]
21Feb17_143031| [ 0.52617  0.76042 -1.76746]
21Feb17_143031| [-0.22134  0.17324  0.99530]
21Feb17_143031| [-0.36427  1.34655  0.02110]
21Feb17_143031| [-0.93125 -0.33620 -0.25012]
21Feb17_143031| [-2.76428  0.14487  0.48096]
21Feb17_143031| [-0.10518  0.35052  1.71840]
21Feb17_143031| [-1.27998  1.12568  1.26523]
21Feb17_143031| [-0.60698  1.53230 -0.60824]
21Feb17_143031| [ 0.02898  2.98718 -0.59153]
21Feb17_143031| [ 0.17588 -0.00449  0.50797]
21Feb17_143031| [-1.42674 -0.54967 -0.21310]
21Feb17_143031| [ 1.03196  1.18733  0.36755]
21Feb17_143031| [ 1.04748 -1.47444 -0.08469]
21Feb17_143031| [ 0.49410  0.38745  0.68469]
21Feb17_143031| [-0.62880  0.73245  0.19964]]
21Feb17_143031|-- Bias --
21Feb17_143031|[-0.18798  0.64571 -0.23142]
21Feb17_143031|Layer 1:
21Feb17_143031|-- Config --
21Feb17_143031|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143031|-- Weights --
21Feb17_143031|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_143031| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_143031| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_143031|-- Bias --
21Feb17_143031|[0.60477 0.03773 0.26452 0.12222]
21Feb17_143031|Layer 2:
21Feb17_143031|-- Config --
21Feb17_143031|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143031|-- Weights --
21Feb17_143031|[[ 0.67920  0.12119]
21Feb17_143031| [ 0.44836  0.02916]
21Feb17_143031| [ 0.68939  0.31516]
21Feb17_143031| [-0.58995 -0.05861]]
21Feb17_143031|-- Bias --
21Feb17_143031|[ 0.59649 -0.08079]
21Feb17_143031|Layer 3:
21Feb17_143031|-- Config --
21Feb17_143031|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143031|-- Weights --
21Feb17_143031|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_143031| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_143031|-- Bias --
21Feb17_143031|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_143031|Layer 4:
21Feb17_143031|-- Config --
21Feb17_143031|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143031|-- Weights --
21Feb17_143031|[[-0.03514 -1.04833]
21Feb17_143031| [ 1.25238  0.62094]
21Feb17_143031| [ 0.99203  0.37406]
21Feb17_143031| [ 0.49902  0.67158]
21Feb17_143031| [-1.35709  0.38335]]
21Feb17_143031|-- Bias --
21Feb17_143031|[0.31435 0.36299]
21Feb17_143031|Predicting the validation and test data with the Best final individual.
21Feb17_143039| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_143039|-----------  ------------------  --------------------  ----------
21Feb17_143039|Validation         40.17                  56            0.05627
21Feb17_143039|   Test            21.37                  56            0.70301
21Feb17_143039|-------------------- Test #1 --------------------
21Feb17_143039|Best final individual weights
21Feb17_143039|Individual:
21Feb17_143039|-- Constant hidden layers --
21Feb17_143039|False
21Feb17_143039|Layer 0:
21Feb17_143039|-- Config --
21Feb17_143039|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143039|-- Weights --
21Feb17_143039|[[-0.73212  1.32861  0.10200]
21Feb17_143039| [ 1.48746 -2.97273 -0.42944]
21Feb17_143039| [ 0.53095 -1.50623  0.79224]
21Feb17_143039| [-1.07292 -0.83175 -0.90105]
21Feb17_143039| [-0.48696 -0.89325  0.27226]
21Feb17_143039| [-3.02511  0.34155 -0.03837]
21Feb17_143039| [-0.76747  0.57140 -0.46892]
21Feb17_143039| [-0.07581  0.14713  0.85910]
21Feb17_143039| [-1.37488  0.52170 -0.36205]
21Feb17_143039| [ 1.60981 -0.08727 -0.11267]
21Feb17_143039| [ 0.50986  1.58916 -0.35287]
21Feb17_143039| [-0.34599  1.27113 -0.16393]
21Feb17_143039| [ 1.29203  1.19467  0.37695]
21Feb17_143039| [ 0.58704  0.06328 -0.24240]
21Feb17_143039| [-0.93888 -0.89760  0.57087]
21Feb17_143039| [ 0.99159 -0.66387  0.35177]
21Feb17_143039| [-0.67119  1.06910 -0.12512]
21Feb17_143039| [-0.91534  1.23744 -0.40465]
21Feb17_143039| [ 1.39278  0.08069  0.23328]
21Feb17_143039| [ 0.09880  0.57603 -0.96101]
21Feb17_143039| [ 0.01621 -0.13343 -0.27624]
21Feb17_143039| [-1.28286 -2.28909  0.37931]
21Feb17_143039| [-0.28370  0.09336  0.01547]
21Feb17_143039| [-0.51894  1.84280 -0.25906]
21Feb17_143039| [-0.83075 -0.04508  0.12107]
21Feb17_143039| [ 0.37343  1.18436 -0.07358]
21Feb17_143039| [-2.38657 -0.35191  0.01962]
21Feb17_143039| [ 0.95757 -0.91760 -0.08971]
21Feb17_143039| [ 0.38792 -0.01880  0.69717]
21Feb17_143039| [ 1.66877 -0.58078 -1.21129]
21Feb17_143039| [-0.50943  0.59080  0.30856]
21Feb17_143039| [ 0.30163  1.11518  0.98185]
21Feb17_143039| [-0.73226  0.32281 -0.66712]
21Feb17_143039| [-0.62054 -2.21049  1.40981]
21Feb17_143039| [ 1.23185 -0.58090  0.35844]
21Feb17_143039| [-0.05616  0.24219 -0.02853]
21Feb17_143039| [-1.05085 -2.30259 -0.16276]
21Feb17_143039| [ 0.71087  0.14900  1.13430]
21Feb17_143039| [-2.45877 -1.20999 -1.04986]
21Feb17_143039| [-1.00480  1.36344 -0.13998]
21Feb17_143039| [ 1.83140 -0.91532  0.07616]
21Feb17_143039| [-0.60404 -2.05184  0.76948]
21Feb17_143039| [ 0.52617  0.76042 -1.76746]
21Feb17_143039| [-0.22134  0.17324  0.99530]
21Feb17_143039| [-0.36427  1.34655  0.02110]
21Feb17_143039| [-0.93125 -0.33620 -0.25012]
21Feb17_143039| [-2.76428  0.14487  0.48096]
21Feb17_143039| [-0.10518  0.35052  1.71840]
21Feb17_143039| [-1.27998  1.12568  1.26523]
21Feb17_143039| [-0.60698  1.53230 -0.60824]
21Feb17_143039| [ 0.02898  2.98718 -0.59153]
21Feb17_143039| [ 0.17588 -0.00449  0.50797]
21Feb17_143039| [-1.42674 -0.54967 -0.21310]
21Feb17_143039| [ 1.03196  1.18733  0.36755]
21Feb17_143039| [ 1.04748 -1.47444 -0.08469]
21Feb17_143039| [ 0.49410  0.38745  0.68469]
21Feb17_143039| [-0.62880  0.73245  0.19964]]
21Feb17_143039|-- Bias --
21Feb17_143039|[-0.18798  0.64571 -0.23142]
21Feb17_143039|Layer 1:
21Feb17_143039|-- Config --
21Feb17_143039|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143039|-- Weights --
21Feb17_143039|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_143039| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_143039| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_143039|-- Bias --
21Feb17_143039|[0.60477 0.03773 0.26452 0.12222]
21Feb17_143039|Layer 2:
21Feb17_143039|-- Config --
21Feb17_143039|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143039|-- Weights --
21Feb17_143039|[[ 0.67920  0.12119]
21Feb17_143039| [ 0.44836  0.02916]
21Feb17_143039| [ 0.68939  0.31516]
21Feb17_143039| [-0.58995 -0.05861]]
21Feb17_143039|-- Bias --
21Feb17_143039|[ 0.59649 -0.08079]
21Feb17_143039|Layer 3:
21Feb17_143039|-- Config --
21Feb17_143039|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143039|-- Weights --
21Feb17_143039|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_143039| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_143039|-- Bias --
21Feb17_143039|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_143039|Layer 4:
21Feb17_143039|-- Config --
21Feb17_143039|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143039|-- Weights --
21Feb17_143039|[[-0.03514 -1.04833]
21Feb17_143039| [ 1.25238  0.62094]
21Feb17_143039| [ 0.99203  0.37406]
21Feb17_143039| [ 0.49902  0.67158]
21Feb17_143039| [-1.35709  0.38335]]
21Feb17_143039|-- Bias --
21Feb17_143039|[0.31435 0.36299]
21Feb17_143039|Predicting the validation and test data with the Best final individual.
21Feb17_143047| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_143047|-----------  ------------------  --------------------  ----------
21Feb17_143047|Validation         23.83                  56            0.86651
21Feb17_143047|   Test            22.68                  56            0.77969
21Feb17_143047|-------------------- Test #2 --------------------
21Feb17_143047|Best final individual weights
21Feb17_143047|Individual:
21Feb17_143047|-- Constant hidden layers --
21Feb17_143047|False
21Feb17_143047|Layer 0:
21Feb17_143047|-- Config --
21Feb17_143047|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143047|-- Weights --
21Feb17_143047|[[-0.73212  1.32861  0.10200]
21Feb17_143047| [ 1.48746 -2.97273 -0.42944]
21Feb17_143047| [ 0.53095 -1.50623  0.79224]
21Feb17_143047| [-1.07292 -0.83175 -0.90105]
21Feb17_143047| [-0.48696 -0.89325  0.27226]
21Feb17_143047| [-3.02511  0.34155 -0.03837]
21Feb17_143047| [-0.76747  0.57140 -0.46892]
21Feb17_143047| [-0.07581  0.14713  0.85910]
21Feb17_143047| [-1.37488  0.52170 -0.36205]
21Feb17_143047| [ 1.60981 -0.08727 -0.11267]
21Feb17_143047| [ 0.50986  1.58916 -0.35287]
21Feb17_143047| [-0.34599  1.27113 -0.16393]
21Feb17_143047| [ 1.29203  1.19467  0.37695]
21Feb17_143047| [ 0.58704  0.06328 -0.24240]
21Feb17_143047| [-0.93888 -0.89760  0.57087]
21Feb17_143047| [ 0.99159 -0.66387  0.35177]
21Feb17_143047| [-0.67119  1.06910 -0.12512]
21Feb17_143047| [-0.91534  1.23744 -0.40465]
21Feb17_143047| [ 1.39278  0.08069  0.23328]
21Feb17_143047| [ 0.09880  0.57603 -0.96101]
21Feb17_143047| [ 0.01621 -0.13343 -0.27624]
21Feb17_143047| [-1.28286 -2.28909  0.37931]
21Feb17_143047| [-0.28370  0.09336  0.01547]
21Feb17_143047| [-0.51894  1.84280 -0.25906]
21Feb17_143047| [-0.83075 -0.04508  0.12107]
21Feb17_143047| [ 0.37343  1.18436 -0.07358]
21Feb17_143047| [-2.38657 -0.35191  0.01962]
21Feb17_143047| [ 0.95757 -0.91760 -0.08971]
21Feb17_143047| [ 0.38792 -0.01880  0.69717]
21Feb17_143047| [ 1.66877 -0.58078 -1.21129]
21Feb17_143047| [-0.50943  0.59080  0.30856]
21Feb17_143047| [ 0.30163  1.11518  0.98185]
21Feb17_143047| [-0.73226  0.32281 -0.66712]
21Feb17_143047| [-0.62054 -2.21049  1.40981]
21Feb17_143047| [ 1.23185 -0.58090  0.35844]
21Feb17_143047| [-0.05616  0.24219 -0.02853]
21Feb17_143047| [-1.05085 -2.30259 -0.16276]
21Feb17_143047| [ 0.71087  0.14900  1.13430]
21Feb17_143047| [-2.45877 -1.20999 -1.04986]
21Feb17_143047| [-1.00480  1.36344 -0.13998]
21Feb17_143047| [ 1.83140 -0.91532  0.07616]
21Feb17_143047| [-0.60404 -2.05184  0.76948]
21Feb17_143047| [ 0.52617  0.76042 -1.76746]
21Feb17_143047| [-0.22134  0.17324  0.99530]
21Feb17_143047| [-0.36427  1.34655  0.02110]
21Feb17_143047| [-0.93125 -0.33620 -0.25012]
21Feb17_143047| [-2.76428  0.14487  0.48096]
21Feb17_143047| [-0.10518  0.35052  1.71840]
21Feb17_143047| [-1.27998  1.12568  1.26523]
21Feb17_143047| [-0.60698  1.53230 -0.60824]
21Feb17_143047| [ 0.02898  2.98718 -0.59153]
21Feb17_143047| [ 0.17588 -0.00449  0.50797]
21Feb17_143047| [-1.42674 -0.54967 -0.21310]
21Feb17_143047| [ 1.03196  1.18733  0.36755]
21Feb17_143047| [ 1.04748 -1.47444 -0.08469]
21Feb17_143047| [ 0.49410  0.38745  0.68469]
21Feb17_143047| [-0.62880  0.73245  0.19964]]
21Feb17_143047|-- Bias --
21Feb17_143047|[-0.18798  0.64571 -0.23142]
21Feb17_143047|Layer 1:
21Feb17_143047|-- Config --
21Feb17_143047|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143047|-- Weights --
21Feb17_143047|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_143047| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_143047| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_143047|-- Bias --
21Feb17_143047|[0.60477 0.03773 0.26452 0.12222]
21Feb17_143047|Layer 2:
21Feb17_143047|-- Config --
21Feb17_143047|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143047|-- Weights --
21Feb17_143047|[[ 0.67920  0.12119]
21Feb17_143047| [ 0.44836  0.02916]
21Feb17_143047| [ 0.68939  0.31516]
21Feb17_143047| [-0.58995 -0.05861]]
21Feb17_143047|-- Bias --
21Feb17_143047|[ 0.59649 -0.08079]
21Feb17_143047|Layer 3:
21Feb17_143047|-- Config --
21Feb17_143047|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143047|-- Weights --
21Feb17_143047|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_143047| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_143047|-- Bias --
21Feb17_143047|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_143047|Layer 4:
21Feb17_143047|-- Config --
21Feb17_143047|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143047|-- Weights --
21Feb17_143047|[[-0.03514 -1.04833]
21Feb17_143047| [ 1.25238  0.62094]
21Feb17_143047| [ 0.99203  0.37406]
21Feb17_143047| [ 0.49902  0.67158]
21Feb17_143047| [-1.35709  0.38335]]
21Feb17_143047|-- Bias --
21Feb17_143047|[0.31435 0.36299]
21Feb17_143047|Predicting the validation and test data with the Best final individual.
21Feb17_143054| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_143054|-----------  ------------------  --------------------  ----------
21Feb17_143054|Validation         23.91                  56            0.70865
21Feb17_143054|   Test            29.45                  56            0.70270
21Feb17_143054|-------------------- Test #3 --------------------
21Feb17_143054|Best final individual weights
21Feb17_143054|Individual:
21Feb17_143054|-- Constant hidden layers --
21Feb17_143054|False
21Feb17_143054|Layer 0:
21Feb17_143054|-- Config --
21Feb17_143054|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143054|-- Weights --
21Feb17_143054|[[-0.73212  1.32861  0.10200]
21Feb17_143054| [ 1.48746 -2.97273 -0.42944]
21Feb17_143054| [ 0.53095 -1.50623  0.79224]
21Feb17_143054| [-1.07292 -0.83175 -0.90105]
21Feb17_143054| [-0.48696 -0.89325  0.27226]
21Feb17_143054| [-3.02511  0.34155 -0.03837]
21Feb17_143054| [-0.76747  0.57140 -0.46892]
21Feb17_143054| [-0.07581  0.14713  0.85910]
21Feb17_143054| [-1.37488  0.52170 -0.36205]
21Feb17_143054| [ 1.60981 -0.08727 -0.11267]
21Feb17_143054| [ 0.50986  1.58916 -0.35287]
21Feb17_143054| [-0.34599  1.27113 -0.16393]
21Feb17_143054| [ 1.29203  1.19467  0.37695]
21Feb17_143054| [ 0.58704  0.06328 -0.24240]
21Feb17_143054| [-0.93888 -0.89760  0.57087]
21Feb17_143054| [ 0.99159 -0.66387  0.35177]
21Feb17_143054| [-0.67119  1.06910 -0.12512]
21Feb17_143054| [-0.91534  1.23744 -0.40465]
21Feb17_143054| [ 1.39278  0.08069  0.23328]
21Feb17_143054| [ 0.09880  0.57603 -0.96101]
21Feb17_143054| [ 0.01621 -0.13343 -0.27624]
21Feb17_143054| [-1.28286 -2.28909  0.37931]
21Feb17_143054| [-0.28370  0.09336  0.01547]
21Feb17_143054| [-0.51894  1.84280 -0.25906]
21Feb17_143054| [-0.83075 -0.04508  0.12107]
21Feb17_143054| [ 0.37343  1.18436 -0.07358]
21Feb17_143054| [-2.38657 -0.35191  0.01962]
21Feb17_143054| [ 0.95757 -0.91760 -0.08971]
21Feb17_143054| [ 0.38792 -0.01880  0.69717]
21Feb17_143054| [ 1.66877 -0.58078 -1.21129]
21Feb17_143054| [-0.50943  0.59080  0.30856]
21Feb17_143054| [ 0.30163  1.11518  0.98185]
21Feb17_143054| [-0.73226  0.32281 -0.66712]
21Feb17_143054| [-0.62054 -2.21049  1.40981]
21Feb17_143054| [ 1.23185 -0.58090  0.35844]
21Feb17_143054| [-0.05616  0.24219 -0.02853]
21Feb17_143054| [-1.05085 -2.30259 -0.16276]
21Feb17_143054| [ 0.71087  0.14900  1.13430]
21Feb17_143054| [-2.45877 -1.20999 -1.04986]
21Feb17_143054| [-1.00480  1.36344 -0.13998]
21Feb17_143054| [ 1.83140 -0.91532  0.07616]
21Feb17_143054| [-0.60404 -2.05184  0.76948]
21Feb17_143054| [ 0.52617  0.76042 -1.76746]
21Feb17_143054| [-0.22134  0.17324  0.99530]
21Feb17_143054| [-0.36427  1.34655  0.02110]
21Feb17_143054| [-0.93125 -0.33620 -0.25012]
21Feb17_143054| [-2.76428  0.14487  0.48096]
21Feb17_143054| [-0.10518  0.35052  1.71840]
21Feb17_143054| [-1.27998  1.12568  1.26523]
21Feb17_143054| [-0.60698  1.53230 -0.60824]
21Feb17_143054| [ 0.02898  2.98718 -0.59153]
21Feb17_143054| [ 0.17588 -0.00449  0.50797]
21Feb17_143054| [-1.42674 -0.54967 -0.21310]
21Feb17_143054| [ 1.03196  1.18733  0.36755]
21Feb17_143054| [ 1.04748 -1.47444 -0.08469]
21Feb17_143054| [ 0.49410  0.38745  0.68469]
21Feb17_143054| [-0.62880  0.73245  0.19964]]
21Feb17_143054|-- Bias --
21Feb17_143054|[-0.18798  0.64571 -0.23142]
21Feb17_143054|Layer 1:
21Feb17_143054|-- Config --
21Feb17_143054|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143054|-- Weights --
21Feb17_143054|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_143054| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_143054| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_143054|-- Bias --
21Feb17_143054|[0.60477 0.03773 0.26452 0.12222]
21Feb17_143054|Layer 2:
21Feb17_143054|-- Config --
21Feb17_143054|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143054|-- Weights --
21Feb17_143054|[[ 0.67920  0.12119]
21Feb17_143054| [ 0.44836  0.02916]
21Feb17_143054| [ 0.68939  0.31516]
21Feb17_143054| [-0.58995 -0.05861]]
21Feb17_143054|-- Bias --
21Feb17_143054|[ 0.59649 -0.08079]
21Feb17_143054|Layer 3:
21Feb17_143054|-- Config --
21Feb17_143054|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143054|-- Weights --
21Feb17_143054|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_143054| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_143054|-- Bias --
21Feb17_143054|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_143054|Layer 4:
21Feb17_143054|-- Config --
21Feb17_143054|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143054|-- Weights --
21Feb17_143054|[[-0.03514 -1.04833]
21Feb17_143054| [ 1.25238  0.62094]
21Feb17_143054| [ 0.99203  0.37406]
21Feb17_143054| [ 0.49902  0.67158]
21Feb17_143054| [-1.35709  0.38335]]
21Feb17_143054|-- Bias --
21Feb17_143054|[0.31435 0.36299]
21Feb17_143054|Predicting the validation and test data with the Best final individual.
21Feb17_143102| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_143102|-----------  ------------------  --------------------  ----------
21Feb17_143102|Validation         24.35                  56            0.84577
21Feb17_143102|   Test            21.63                  56            0.70714
21Feb17_143102|-------------------- Test #4 --------------------
21Feb17_143102|Best final individual weights
21Feb17_143102|Individual:
21Feb17_143102|-- Constant hidden layers --
21Feb17_143102|False
21Feb17_143102|Layer 0:
21Feb17_143102|-- Config --
21Feb17_143102|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143102|-- Weights --
21Feb17_143102|[[-0.73212  1.32861  0.10200]
21Feb17_143102| [ 1.48746 -2.97273 -0.42944]
21Feb17_143102| [ 0.53095 -1.50623  0.79224]
21Feb17_143102| [-1.07292 -0.83175 -0.90105]
21Feb17_143102| [-0.48696 -0.89325  0.27226]
21Feb17_143102| [-3.02511  0.34155 -0.03837]
21Feb17_143102| [-0.76747  0.57140 -0.46892]
21Feb17_143102| [-0.07581  0.14713  0.85910]
21Feb17_143102| [-1.37488  0.52170 -0.36205]
21Feb17_143102| [ 1.60981 -0.08727 -0.11267]
21Feb17_143102| [ 0.50986  1.58916 -0.35287]
21Feb17_143102| [-0.34599  1.27113 -0.16393]
21Feb17_143102| [ 1.29203  1.19467  0.37695]
21Feb17_143102| [ 0.58704  0.06328 -0.24240]
21Feb17_143102| [-0.93888 -0.89760  0.57087]
21Feb17_143102| [ 0.99159 -0.66387  0.35177]
21Feb17_143102| [-0.67119  1.06910 -0.12512]
21Feb17_143102| [-0.91534  1.23744 -0.40465]
21Feb17_143102| [ 1.39278  0.08069  0.23328]
21Feb17_143102| [ 0.09880  0.57603 -0.96101]
21Feb17_143102| [ 0.01621 -0.13343 -0.27624]
21Feb17_143102| [-1.28286 -2.28909  0.37931]
21Feb17_143102| [-0.28370  0.09336  0.01547]
21Feb17_143102| [-0.51894  1.84280 -0.25906]
21Feb17_143102| [-0.83075 -0.04508  0.12107]
21Feb17_143102| [ 0.37343  1.18436 -0.07358]
21Feb17_143102| [-2.38657 -0.35191  0.01962]
21Feb17_143102| [ 0.95757 -0.91760 -0.08971]
21Feb17_143102| [ 0.38792 -0.01880  0.69717]
21Feb17_143102| [ 1.66877 -0.58078 -1.21129]
21Feb17_143102| [-0.50943  0.59080  0.30856]
21Feb17_143102| [ 0.30163  1.11518  0.98185]
21Feb17_143102| [-0.73226  0.32281 -0.66712]
21Feb17_143102| [-0.62054 -2.21049  1.40981]
21Feb17_143102| [ 1.23185 -0.58090  0.35844]
21Feb17_143102| [-0.05616  0.24219 -0.02853]
21Feb17_143102| [-1.05085 -2.30259 -0.16276]
21Feb17_143102| [ 0.71087  0.14900  1.13430]
21Feb17_143102| [-2.45877 -1.20999 -1.04986]
21Feb17_143102| [-1.00480  1.36344 -0.13998]
21Feb17_143102| [ 1.83140 -0.91532  0.07616]
21Feb17_143102| [-0.60404 -2.05184  0.76948]
21Feb17_143102| [ 0.52617  0.76042 -1.76746]
21Feb17_143102| [-0.22134  0.17324  0.99530]
21Feb17_143102| [-0.36427  1.34655  0.02110]
21Feb17_143102| [-0.93125 -0.33620 -0.25012]
21Feb17_143102| [-2.76428  0.14487  0.48096]
21Feb17_143102| [-0.10518  0.35052  1.71840]
21Feb17_143102| [-1.27998  1.12568  1.26523]
21Feb17_143102| [-0.60698  1.53230 -0.60824]
21Feb17_143102| [ 0.02898  2.98718 -0.59153]
21Feb17_143102| [ 0.17588 -0.00449  0.50797]
21Feb17_143102| [-1.42674 -0.54967 -0.21310]
21Feb17_143102| [ 1.03196  1.18733  0.36755]
21Feb17_143102| [ 1.04748 -1.47444 -0.08469]
21Feb17_143102| [ 0.49410  0.38745  0.68469]
21Feb17_143102| [-0.62880  0.73245  0.19964]]
21Feb17_143102|-- Bias --
21Feb17_143102|[-0.18798  0.64571 -0.23142]
21Feb17_143102|Layer 1:
21Feb17_143102|-- Config --
21Feb17_143102|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143102|-- Weights --
21Feb17_143102|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_143102| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_143102| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_143102|-- Bias --
21Feb17_143102|[0.60477 0.03773 0.26452 0.12222]
21Feb17_143102|Layer 2:
21Feb17_143102|-- Config --
21Feb17_143102|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143102|-- Weights --
21Feb17_143102|[[ 0.67920  0.12119]
21Feb17_143102| [ 0.44836  0.02916]
21Feb17_143102| [ 0.68939  0.31516]
21Feb17_143102| [-0.58995 -0.05861]]
21Feb17_143102|-- Bias --
21Feb17_143102|[ 0.59649 -0.08079]
21Feb17_143102|Layer 3:
21Feb17_143102|-- Config --
21Feb17_143102|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143102|-- Weights --
21Feb17_143102|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_143102| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_143102|-- Bias --
21Feb17_143102|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_143102|Layer 4:
21Feb17_143102|-- Config --
21Feb17_143102|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143102|-- Weights --
21Feb17_143102|[[-0.03514 -1.04833]
21Feb17_143102| [ 1.25238  0.62094]
21Feb17_143102| [ 0.99203  0.37406]
21Feb17_143102| [ 0.49902  0.67158]
21Feb17_143102| [-1.35709  0.38335]]
21Feb17_143102|-- Bias --
21Feb17_143102|[0.31435 0.36299]
21Feb17_143102|Predicting the validation and test data with the Best final individual.
21Feb17_143110| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_143110|-----------  ------------------  --------------------  ----------
21Feb17_143110|Validation         21.57                  56            0.82113
21Feb17_143110|   Test            31.19                  56            0.83333
21Feb17_143110|-------------------- Test #5 --------------------
21Feb17_143110|Best final individual weights
21Feb17_143110|Individual:
21Feb17_143110|-- Constant hidden layers --
21Feb17_143110|False
21Feb17_143110|Layer 0:
21Feb17_143110|-- Config --
21Feb17_143110|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143110|-- Weights --
21Feb17_143110|[[-0.73212  1.32861  0.10200]
21Feb17_143110| [ 1.48746 -2.97273 -0.42944]
21Feb17_143110| [ 0.53095 -1.50623  0.79224]
21Feb17_143110| [-1.07292 -0.83175 -0.90105]
21Feb17_143110| [-0.48696 -0.89325  0.27226]
21Feb17_143110| [-3.02511  0.34155 -0.03837]
21Feb17_143110| [-0.76747  0.57140 -0.46892]
21Feb17_143110| [-0.07581  0.14713  0.85910]
21Feb17_143110| [-1.37488  0.52170 -0.36205]
21Feb17_143110| [ 1.60981 -0.08727 -0.11267]
21Feb17_143110| [ 0.50986  1.58916 -0.35287]
21Feb17_143110| [-0.34599  1.27113 -0.16393]
21Feb17_143110| [ 1.29203  1.19467  0.37695]
21Feb17_143110| [ 0.58704  0.06328 -0.24240]
21Feb17_143110| [-0.93888 -0.89760  0.57087]
21Feb17_143110| [ 0.99159 -0.66387  0.35177]
21Feb17_143110| [-0.67119  1.06910 -0.12512]
21Feb17_143110| [-0.91534  1.23744 -0.40465]
21Feb17_143110| [ 1.39278  0.08069  0.23328]
21Feb17_143110| [ 0.09880  0.57603 -0.96101]
21Feb17_143110| [ 0.01621 -0.13343 -0.27624]
21Feb17_143110| [-1.28286 -2.28909  0.37931]
21Feb17_143110| [-0.28370  0.09336  0.01547]
21Feb17_143110| [-0.51894  1.84280 -0.25906]
21Feb17_143110| [-0.83075 -0.04508  0.12107]
21Feb17_143110| [ 0.37343  1.18436 -0.07358]
21Feb17_143110| [-2.38657 -0.35191  0.01962]
21Feb17_143110| [ 0.95757 -0.91760 -0.08971]
21Feb17_143110| [ 0.38792 -0.01880  0.69717]
21Feb17_143110| [ 1.66877 -0.58078 -1.21129]
21Feb17_143110| [-0.50943  0.59080  0.30856]
21Feb17_143110| [ 0.30163  1.11518  0.98185]
21Feb17_143110| [-0.73226  0.32281 -0.66712]
21Feb17_143110| [-0.62054 -2.21049  1.40981]
21Feb17_143110| [ 1.23185 -0.58090  0.35844]
21Feb17_143110| [-0.05616  0.24219 -0.02853]
21Feb17_143110| [-1.05085 -2.30259 -0.16276]
21Feb17_143110| [ 0.71087  0.14900  1.13430]
21Feb17_143110| [-2.45877 -1.20999 -1.04986]
21Feb17_143110| [-1.00480  1.36344 -0.13998]
21Feb17_143110| [ 1.83140 -0.91532  0.07616]
21Feb17_143110| [-0.60404 -2.05184  0.76948]
21Feb17_143110| [ 0.52617  0.76042 -1.76746]
21Feb17_143110| [-0.22134  0.17324  0.99530]
21Feb17_143110| [-0.36427  1.34655  0.02110]
21Feb17_143110| [-0.93125 -0.33620 -0.25012]
21Feb17_143110| [-2.76428  0.14487  0.48096]
21Feb17_143110| [-0.10518  0.35052  1.71840]
21Feb17_143110| [-1.27998  1.12568  1.26523]
21Feb17_143110| [-0.60698  1.53230 -0.60824]
21Feb17_143110| [ 0.02898  2.98718 -0.59153]
21Feb17_143110| [ 0.17588 -0.00449  0.50797]
21Feb17_143110| [-1.42674 -0.54967 -0.21310]
21Feb17_143110| [ 1.03196  1.18733  0.36755]
21Feb17_143110| [ 1.04748 -1.47444 -0.08469]
21Feb17_143110| [ 0.49410  0.38745  0.68469]
21Feb17_143110| [-0.62880  0.73245  0.19964]]
21Feb17_143110|-- Bias --
21Feb17_143110|[-0.18798  0.64571 -0.23142]
21Feb17_143110|Layer 1:
21Feb17_143110|-- Config --
21Feb17_143110|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143110|-- Weights --
21Feb17_143110|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_143110| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_143110| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_143110|-- Bias --
21Feb17_143110|[0.60477 0.03773 0.26452 0.12222]
21Feb17_143110|Layer 2:
21Feb17_143110|-- Config --
21Feb17_143110|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143110|-- Weights --
21Feb17_143110|[[ 0.67920  0.12119]
21Feb17_143110| [ 0.44836  0.02916]
21Feb17_143110| [ 0.68939  0.31516]
21Feb17_143110| [-0.58995 -0.05861]]
21Feb17_143110|-- Bias --
21Feb17_143110|[ 0.59649 -0.08079]
21Feb17_143110|Layer 3:
21Feb17_143110|-- Config --
21Feb17_143110|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143110|-- Weights --
21Feb17_143110|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_143110| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_143110|-- Bias --
21Feb17_143110|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_143110|Layer 4:
21Feb17_143110|-- Config --
21Feb17_143110|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143110|-- Weights --
21Feb17_143110|[[-0.03514 -1.04833]
21Feb17_143110| [ 1.25238  0.62094]
21Feb17_143110| [ 0.99203  0.37406]
21Feb17_143110| [ 0.49902  0.67158]
21Feb17_143110| [-1.35709  0.38335]]
21Feb17_143110|-- Bias --
21Feb17_143110|[0.31435 0.36299]
21Feb17_143110|Predicting the validation and test data with the Best final individual.
21Feb17_143117| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_143117|-----------  ------------------  --------------------  ----------
21Feb17_143117|Validation         23.22                  56            0.86009
21Feb17_143117|   Test            26.15                  56            0.85097
21Feb17_143117|-------------------- Test #6 --------------------
21Feb17_143117|Best final individual weights
21Feb17_143117|Individual:
21Feb17_143117|-- Constant hidden layers --
21Feb17_143117|False
21Feb17_143117|Layer 0:
21Feb17_143117|-- Config --
21Feb17_143117|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143117|-- Weights --
21Feb17_143117|[[-0.73212  1.32861  0.10200]
21Feb17_143117| [ 1.48746 -2.97273 -0.42944]
21Feb17_143117| [ 0.53095 -1.50623  0.79224]
21Feb17_143117| [-1.07292 -0.83175 -0.90105]
21Feb17_143117| [-0.48696 -0.89325  0.27226]
21Feb17_143117| [-3.02511  0.34155 -0.03837]
21Feb17_143117| [-0.76747  0.57140 -0.46892]
21Feb17_143117| [-0.07581  0.14713  0.85910]
21Feb17_143117| [-1.37488  0.52170 -0.36205]
21Feb17_143117| [ 1.60981 -0.08727 -0.11267]
21Feb17_143117| [ 0.50986  1.58916 -0.35287]
21Feb17_143117| [-0.34599  1.27113 -0.16393]
21Feb17_143117| [ 1.29203  1.19467  0.37695]
21Feb17_143117| [ 0.58704  0.06328 -0.24240]
21Feb17_143117| [-0.93888 -0.89760  0.57087]
21Feb17_143117| [ 0.99159 -0.66387  0.35177]
21Feb17_143117| [-0.67119  1.06910 -0.12512]
21Feb17_143117| [-0.91534  1.23744 -0.40465]
21Feb17_143117| [ 1.39278  0.08069  0.23328]
21Feb17_143117| [ 0.09880  0.57603 -0.96101]
21Feb17_143117| [ 0.01621 -0.13343 -0.27624]
21Feb17_143117| [-1.28286 -2.28909  0.37931]
21Feb17_143117| [-0.28370  0.09336  0.01547]
21Feb17_143117| [-0.51894  1.84280 -0.25906]
21Feb17_143117| [-0.83075 -0.04508  0.12107]
21Feb17_143117| [ 0.37343  1.18436 -0.07358]
21Feb17_143117| [-2.38657 -0.35191  0.01962]
21Feb17_143117| [ 0.95757 -0.91760 -0.08971]
21Feb17_143117| [ 0.38792 -0.01880  0.69717]
21Feb17_143117| [ 1.66877 -0.58078 -1.21129]
21Feb17_143117| [-0.50943  0.59080  0.30856]
21Feb17_143117| [ 0.30163  1.11518  0.98185]
21Feb17_143117| [-0.73226  0.32281 -0.66712]
21Feb17_143117| [-0.62054 -2.21049  1.40981]
21Feb17_143117| [ 1.23185 -0.58090  0.35844]
21Feb17_143117| [-0.05616  0.24219 -0.02853]
21Feb17_143117| [-1.05085 -2.30259 -0.16276]
21Feb17_143117| [ 0.71087  0.14900  1.13430]
21Feb17_143117| [-2.45877 -1.20999 -1.04986]
21Feb17_143117| [-1.00480  1.36344 -0.13998]
21Feb17_143117| [ 1.83140 -0.91532  0.07616]
21Feb17_143117| [-0.60404 -2.05184  0.76948]
21Feb17_143117| [ 0.52617  0.76042 -1.76746]
21Feb17_143117| [-0.22134  0.17324  0.99530]
21Feb17_143117| [-0.36427  1.34655  0.02110]
21Feb17_143117| [-0.93125 -0.33620 -0.25012]
21Feb17_143117| [-2.76428  0.14487  0.48096]
21Feb17_143117| [-0.10518  0.35052  1.71840]
21Feb17_143117| [-1.27998  1.12568  1.26523]
21Feb17_143117| [-0.60698  1.53230 -0.60824]
21Feb17_143117| [ 0.02898  2.98718 -0.59153]
21Feb17_143117| [ 0.17588 -0.00449  0.50797]
21Feb17_143117| [-1.42674 -0.54967 -0.21310]
21Feb17_143117| [ 1.03196  1.18733  0.36755]
21Feb17_143117| [ 1.04748 -1.47444 -0.08469]
21Feb17_143117| [ 0.49410  0.38745  0.68469]
21Feb17_143117| [-0.62880  0.73245  0.19964]]
21Feb17_143117|-- Bias --
21Feb17_143117|[-0.18798  0.64571 -0.23142]
21Feb17_143117|Layer 1:
21Feb17_143117|-- Config --
21Feb17_143117|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143117|-- Weights --
21Feb17_143117|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_143117| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_143117| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_143117|-- Bias --
21Feb17_143117|[0.60477 0.03773 0.26452 0.12222]
21Feb17_143117|Layer 2:
21Feb17_143117|-- Config --
21Feb17_143117|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143117|-- Weights --
21Feb17_143117|[[ 0.67920  0.12119]
21Feb17_143117| [ 0.44836  0.02916]
21Feb17_143117| [ 0.68939  0.31516]
21Feb17_143117| [-0.58995 -0.05861]]
21Feb17_143117|-- Bias --
21Feb17_143117|[ 0.59649 -0.08079]
21Feb17_143117|Layer 3:
21Feb17_143117|-- Config --
21Feb17_143117|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143117|-- Weights --
21Feb17_143117|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_143117| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_143117|-- Bias --
21Feb17_143117|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_143117|Layer 4:
21Feb17_143117|-- Config --
21Feb17_143117|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143117|-- Weights --
21Feb17_143117|[[-0.03514 -1.04833]
21Feb17_143117| [ 1.25238  0.62094]
21Feb17_143117| [ 0.99203  0.37406]
21Feb17_143117| [ 0.49902  0.67158]
21Feb17_143117| [-1.35709  0.38335]]
21Feb17_143117|-- Bias --
21Feb17_143117|[0.31435 0.36299]
21Feb17_143117|Predicting the validation and test data with the Best final individual.
21Feb17_143125| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_143125|-----------  ------------------  --------------------  ----------
21Feb17_143125|Validation         22.78                  56            0.83496
21Feb17_143125|   Test            21.11                  56            0.79855
21Feb17_143125|-------------------- Test #7 --------------------
21Feb17_143125|Best final individual weights
21Feb17_143125|Individual:
21Feb17_143125|-- Constant hidden layers --
21Feb17_143125|False
21Feb17_143125|Layer 0:
21Feb17_143125|-- Config --
21Feb17_143125|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143125|-- Weights --
21Feb17_143125|[[-0.73212  1.32861  0.10200]
21Feb17_143125| [ 1.48746 -2.97273 -0.42944]
21Feb17_143125| [ 0.53095 -1.50623  0.79224]
21Feb17_143125| [-1.07292 -0.83175 -0.90105]
21Feb17_143125| [-0.48696 -0.89325  0.27226]
21Feb17_143125| [-3.02511  0.34155 -0.03837]
21Feb17_143125| [-0.76747  0.57140 -0.46892]
21Feb17_143125| [-0.07581  0.14713  0.85910]
21Feb17_143125| [-1.37488  0.52170 -0.36205]
21Feb17_143125| [ 1.60981 -0.08727 -0.11267]
21Feb17_143125| [ 0.50986  1.58916 -0.35287]
21Feb17_143125| [-0.34599  1.27113 -0.16393]
21Feb17_143125| [ 1.29203  1.19467  0.37695]
21Feb17_143125| [ 0.58704  0.06328 -0.24240]
21Feb17_143125| [-0.93888 -0.89760  0.57087]
21Feb17_143125| [ 0.99159 -0.66387  0.35177]
21Feb17_143125| [-0.67119  1.06910 -0.12512]
21Feb17_143125| [-0.91534  1.23744 -0.40465]
21Feb17_143125| [ 1.39278  0.08069  0.23328]
21Feb17_143125| [ 0.09880  0.57603 -0.96101]
21Feb17_143125| [ 0.01621 -0.13343 -0.27624]
21Feb17_143125| [-1.28286 -2.28909  0.37931]
21Feb17_143125| [-0.28370  0.09336  0.01547]
21Feb17_143125| [-0.51894  1.84280 -0.25906]
21Feb17_143125| [-0.83075 -0.04508  0.12107]
21Feb17_143125| [ 0.37343  1.18436 -0.07358]
21Feb17_143125| [-2.38657 -0.35191  0.01962]
21Feb17_143125| [ 0.95757 -0.91760 -0.08971]
21Feb17_143125| [ 0.38792 -0.01880  0.69717]
21Feb17_143125| [ 1.66877 -0.58078 -1.21129]
21Feb17_143125| [-0.50943  0.59080  0.30856]
21Feb17_143125| [ 0.30163  1.11518  0.98185]
21Feb17_143125| [-0.73226  0.32281 -0.66712]
21Feb17_143125| [-0.62054 -2.21049  1.40981]
21Feb17_143125| [ 1.23185 -0.58090  0.35844]
21Feb17_143125| [-0.05616  0.24219 -0.02853]
21Feb17_143125| [-1.05085 -2.30259 -0.16276]
21Feb17_143125| [ 0.71087  0.14900  1.13430]
21Feb17_143125| [-2.45877 -1.20999 -1.04986]
21Feb17_143125| [-1.00480  1.36344 -0.13998]
21Feb17_143125| [ 1.83140 -0.91532  0.07616]
21Feb17_143125| [-0.60404 -2.05184  0.76948]
21Feb17_143125| [ 0.52617  0.76042 -1.76746]
21Feb17_143125| [-0.22134  0.17324  0.99530]
21Feb17_143125| [-0.36427  1.34655  0.02110]
21Feb17_143125| [-0.93125 -0.33620 -0.25012]
21Feb17_143125| [-2.76428  0.14487  0.48096]
21Feb17_143125| [-0.10518  0.35052  1.71840]
21Feb17_143125| [-1.27998  1.12568  1.26523]
21Feb17_143125| [-0.60698  1.53230 -0.60824]
21Feb17_143125| [ 0.02898  2.98718 -0.59153]
21Feb17_143125| [ 0.17588 -0.00449  0.50797]
21Feb17_143125| [-1.42674 -0.54967 -0.21310]
21Feb17_143125| [ 1.03196  1.18733  0.36755]
21Feb17_143125| [ 1.04748 -1.47444 -0.08469]
21Feb17_143125| [ 0.49410  0.38745  0.68469]
21Feb17_143125| [-0.62880  0.73245  0.19964]]
21Feb17_143125|-- Bias --
21Feb17_143125|[-0.18798  0.64571 -0.23142]
21Feb17_143125|Layer 1:
21Feb17_143125|-- Config --
21Feb17_143125|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143125|-- Weights --
21Feb17_143125|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_143125| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_143125| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_143125|-- Bias --
21Feb17_143125|[0.60477 0.03773 0.26452 0.12222]
21Feb17_143125|Layer 2:
21Feb17_143125|-- Config --
21Feb17_143125|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143125|-- Weights --
21Feb17_143125|[[ 0.67920  0.12119]
21Feb17_143125| [ 0.44836  0.02916]
21Feb17_143125| [ 0.68939  0.31516]
21Feb17_143125| [-0.58995 -0.05861]]
21Feb17_143125|-- Bias --
21Feb17_143125|[ 0.59649 -0.08079]
21Feb17_143125|Layer 3:
21Feb17_143125|-- Config --
21Feb17_143125|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143125|-- Weights --
21Feb17_143125|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_143125| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_143125|-- Bias --
21Feb17_143125|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_143125|Layer 4:
21Feb17_143125|-- Config --
21Feb17_143125|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143125|-- Weights --
21Feb17_143125|[[-0.03514 -1.04833]
21Feb17_143125| [ 1.25238  0.62094]
21Feb17_143125| [ 0.99203  0.37406]
21Feb17_143125| [ 0.49902  0.67158]
21Feb17_143125| [-1.35709  0.38335]]
21Feb17_143125|-- Bias --
21Feb17_143125|[0.31435 0.36299]
21Feb17_143125|Predicting the validation and test data with the Best final individual.
21Feb17_143133| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_143133|-----------  ------------------  --------------------  ----------
21Feb17_143133|Validation         28.96                  56            0.48780
21Feb17_143133|   Test            25.46                  56            0.49431
21Feb17_143133|-------------------- Test #8 --------------------
21Feb17_143133|Best final individual weights
21Feb17_143133|Individual:
21Feb17_143133|-- Constant hidden layers --
21Feb17_143133|False
21Feb17_143133|Layer 0:
21Feb17_143133|-- Config --
21Feb17_143133|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143133|-- Weights --
21Feb17_143133|[[-0.73212  1.32861  0.10200]
21Feb17_143133| [ 1.48746 -2.97273 -0.42944]
21Feb17_143133| [ 0.53095 -1.50623  0.79224]
21Feb17_143133| [-1.07292 -0.83175 -0.90105]
21Feb17_143133| [-0.48696 -0.89325  0.27226]
21Feb17_143133| [-3.02511  0.34155 -0.03837]
21Feb17_143133| [-0.76747  0.57140 -0.46892]
21Feb17_143133| [-0.07581  0.14713  0.85910]
21Feb17_143133| [-1.37488  0.52170 -0.36205]
21Feb17_143133| [ 1.60981 -0.08727 -0.11267]
21Feb17_143133| [ 0.50986  1.58916 -0.35287]
21Feb17_143133| [-0.34599  1.27113 -0.16393]
21Feb17_143133| [ 1.29203  1.19467  0.37695]
21Feb17_143133| [ 0.58704  0.06328 -0.24240]
21Feb17_143133| [-0.93888 -0.89760  0.57087]
21Feb17_143133| [ 0.99159 -0.66387  0.35177]
21Feb17_143133| [-0.67119  1.06910 -0.12512]
21Feb17_143133| [-0.91534  1.23744 -0.40465]
21Feb17_143133| [ 1.39278  0.08069  0.23328]
21Feb17_143133| [ 0.09880  0.57603 -0.96101]
21Feb17_143133| [ 0.01621 -0.13343 -0.27624]
21Feb17_143133| [-1.28286 -2.28909  0.37931]
21Feb17_143133| [-0.28370  0.09336  0.01547]
21Feb17_143133| [-0.51894  1.84280 -0.25906]
21Feb17_143133| [-0.83075 -0.04508  0.12107]
21Feb17_143133| [ 0.37343  1.18436 -0.07358]
21Feb17_143133| [-2.38657 -0.35191  0.01962]
21Feb17_143133| [ 0.95757 -0.91760 -0.08971]
21Feb17_143133| [ 0.38792 -0.01880  0.69717]
21Feb17_143133| [ 1.66877 -0.58078 -1.21129]
21Feb17_143133| [-0.50943  0.59080  0.30856]
21Feb17_143133| [ 0.30163  1.11518  0.98185]
21Feb17_143133| [-0.73226  0.32281 -0.66712]
21Feb17_143133| [-0.62054 -2.21049  1.40981]
21Feb17_143133| [ 1.23185 -0.58090  0.35844]
21Feb17_143133| [-0.05616  0.24219 -0.02853]
21Feb17_143133| [-1.05085 -2.30259 -0.16276]
21Feb17_143133| [ 0.71087  0.14900  1.13430]
21Feb17_143133| [-2.45877 -1.20999 -1.04986]
21Feb17_143133| [-1.00480  1.36344 -0.13998]
21Feb17_143133| [ 1.83140 -0.91532  0.07616]
21Feb17_143133| [-0.60404 -2.05184  0.76948]
21Feb17_143133| [ 0.52617  0.76042 -1.76746]
21Feb17_143133| [-0.22134  0.17324  0.99530]
21Feb17_143133| [-0.36427  1.34655  0.02110]
21Feb17_143133| [-0.93125 -0.33620 -0.25012]
21Feb17_143133| [-2.76428  0.14487  0.48096]
21Feb17_143133| [-0.10518  0.35052  1.71840]
21Feb17_143133| [-1.27998  1.12568  1.26523]
21Feb17_143133| [-0.60698  1.53230 -0.60824]
21Feb17_143133| [ 0.02898  2.98718 -0.59153]
21Feb17_143133| [ 0.17588 -0.00449  0.50797]
21Feb17_143133| [-1.42674 -0.54967 -0.21310]
21Feb17_143133| [ 1.03196  1.18733  0.36755]
21Feb17_143133| [ 1.04748 -1.47444 -0.08469]
21Feb17_143133| [ 0.49410  0.38745  0.68469]
21Feb17_143133| [-0.62880  0.73245  0.19964]]
21Feb17_143133|-- Bias --
21Feb17_143133|[-0.18798  0.64571 -0.23142]
21Feb17_143133|Layer 1:
21Feb17_143133|-- Config --
21Feb17_143133|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143133|-- Weights --
21Feb17_143133|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_143133| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_143133| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_143133|-- Bias --
21Feb17_143133|[0.60477 0.03773 0.26452 0.12222]
21Feb17_143133|Layer 2:
21Feb17_143133|-- Config --
21Feb17_143133|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143133|-- Weights --
21Feb17_143133|[[ 0.67920  0.12119]
21Feb17_143133| [ 0.44836  0.02916]
21Feb17_143133| [ 0.68939  0.31516]
21Feb17_143133| [-0.58995 -0.05861]]
21Feb17_143133|-- Bias --
21Feb17_143133|[ 0.59649 -0.08079]
21Feb17_143133|Layer 3:
21Feb17_143133|-- Config --
21Feb17_143133|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143133|-- Weights --
21Feb17_143133|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_143133| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_143133|-- Bias --
21Feb17_143133|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_143133|Layer 4:
21Feb17_143133|-- Config --
21Feb17_143133|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143133|-- Weights --
21Feb17_143133|[[-0.03514 -1.04833]
21Feb17_143133| [ 1.25238  0.62094]
21Feb17_143133| [ 0.99203  0.37406]
21Feb17_143133| [ 0.49902  0.67158]
21Feb17_143133| [-1.35709  0.38335]]
21Feb17_143133|-- Bias --
21Feb17_143133|[0.31435 0.36299]
21Feb17_143133|Predicting the validation and test data with the Best final individual.
21Feb17_143141| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_143141|-----------  ------------------  --------------------  ----------
21Feb17_143141|Validation         21.30                  56            0.82476
21Feb17_143141|   Test            21.81                  56            0.83186
21Feb17_143141|-------------------- Test #9 --------------------
21Feb17_143141|Best final individual weights
21Feb17_143141|Individual:
21Feb17_143141|-- Constant hidden layers --
21Feb17_143141|False
21Feb17_143141|Layer 0:
21Feb17_143141|-- Config --
21Feb17_143141|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143141|-- Weights --
21Feb17_143141|[[-0.73212  1.32861  0.10200]
21Feb17_143141| [ 1.48746 -2.97273 -0.42944]
21Feb17_143141| [ 0.53095 -1.50623  0.79224]
21Feb17_143141| [-1.07292 -0.83175 -0.90105]
21Feb17_143141| [-0.48696 -0.89325  0.27226]
21Feb17_143141| [-3.02511  0.34155 -0.03837]
21Feb17_143141| [-0.76747  0.57140 -0.46892]
21Feb17_143141| [-0.07581  0.14713  0.85910]
21Feb17_143141| [-1.37488  0.52170 -0.36205]
21Feb17_143141| [ 1.60981 -0.08727 -0.11267]
21Feb17_143141| [ 0.50986  1.58916 -0.35287]
21Feb17_143141| [-0.34599  1.27113 -0.16393]
21Feb17_143141| [ 1.29203  1.19467  0.37695]
21Feb17_143141| [ 0.58704  0.06328 -0.24240]
21Feb17_143141| [-0.93888 -0.89760  0.57087]
21Feb17_143141| [ 0.99159 -0.66387  0.35177]
21Feb17_143141| [-0.67119  1.06910 -0.12512]
21Feb17_143141| [-0.91534  1.23744 -0.40465]
21Feb17_143141| [ 1.39278  0.08069  0.23328]
21Feb17_143141| [ 0.09880  0.57603 -0.96101]
21Feb17_143141| [ 0.01621 -0.13343 -0.27624]
21Feb17_143141| [-1.28286 -2.28909  0.37931]
21Feb17_143141| [-0.28370  0.09336  0.01547]
21Feb17_143141| [-0.51894  1.84280 -0.25906]
21Feb17_143141| [-0.83075 -0.04508  0.12107]
21Feb17_143141| [ 0.37343  1.18436 -0.07358]
21Feb17_143141| [-2.38657 -0.35191  0.01962]
21Feb17_143141| [ 0.95757 -0.91760 -0.08971]
21Feb17_143141| [ 0.38792 -0.01880  0.69717]
21Feb17_143141| [ 1.66877 -0.58078 -1.21129]
21Feb17_143141| [-0.50943  0.59080  0.30856]
21Feb17_143141| [ 0.30163  1.11518  0.98185]
21Feb17_143141| [-0.73226  0.32281 -0.66712]
21Feb17_143141| [-0.62054 -2.21049  1.40981]
21Feb17_143141| [ 1.23185 -0.58090  0.35844]
21Feb17_143141| [-0.05616  0.24219 -0.02853]
21Feb17_143141| [-1.05085 -2.30259 -0.16276]
21Feb17_143141| [ 0.71087  0.14900  1.13430]
21Feb17_143141| [-2.45877 -1.20999 -1.04986]
21Feb17_143141| [-1.00480  1.36344 -0.13998]
21Feb17_143141| [ 1.83140 -0.91532  0.07616]
21Feb17_143141| [-0.60404 -2.05184  0.76948]
21Feb17_143141| [ 0.52617  0.76042 -1.76746]
21Feb17_143141| [-0.22134  0.17324  0.99530]
21Feb17_143141| [-0.36427  1.34655  0.02110]
21Feb17_143141| [-0.93125 -0.33620 -0.25012]
21Feb17_143141| [-2.76428  0.14487  0.48096]
21Feb17_143141| [-0.10518  0.35052  1.71840]
21Feb17_143141| [-1.27998  1.12568  1.26523]
21Feb17_143141| [-0.60698  1.53230 -0.60824]
21Feb17_143141| [ 0.02898  2.98718 -0.59153]
21Feb17_143141| [ 0.17588 -0.00449  0.50797]
21Feb17_143141| [-1.42674 -0.54967 -0.21310]
21Feb17_143141| [ 1.03196  1.18733  0.36755]
21Feb17_143141| [ 1.04748 -1.47444 -0.08469]
21Feb17_143141| [ 0.49410  0.38745  0.68469]
21Feb17_143141| [-0.62880  0.73245  0.19964]]
21Feb17_143141|-- Bias --
21Feb17_143141|[-0.18798  0.64571 -0.23142]
21Feb17_143141|Layer 1:
21Feb17_143141|-- Config --
21Feb17_143141|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143141|-- Weights --
21Feb17_143141|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_143141| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_143141| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_143141|-- Bias --
21Feb17_143141|[0.60477 0.03773 0.26452 0.12222]
21Feb17_143141|Layer 2:
21Feb17_143141|-- Config --
21Feb17_143141|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143141|-- Weights --
21Feb17_143141|[[ 0.67920  0.12119]
21Feb17_143141| [ 0.44836  0.02916]
21Feb17_143141| [ 0.68939  0.31516]
21Feb17_143141| [-0.58995 -0.05861]]
21Feb17_143141|-- Bias --
21Feb17_143141|[ 0.59649 -0.08079]
21Feb17_143141|Layer 3:
21Feb17_143141|-- Config --
21Feb17_143141|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143141|-- Weights --
21Feb17_143141|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_143141| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_143141|-- Bias --
21Feb17_143141|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_143141|Layer 4:
21Feb17_143141|-- Config --
21Feb17_143141|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143141|-- Weights --
21Feb17_143141|[[-0.03514 -1.04833]
21Feb17_143141| [ 1.25238  0.62094]
21Feb17_143141| [ 0.99203  0.37406]
21Feb17_143141| [ 0.49902  0.67158]
21Feb17_143141| [-1.35709  0.38335]]
21Feb17_143141|-- Bias --
21Feb17_143141|[0.31435 0.36299]
21Feb17_143141|Predicting the validation and test data with the Best final individual.
21Feb17_143148| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_143148|-----------  ------------------  --------------------  ----------
21Feb17_143148|Validation         26.43                  56            0.71922
21Feb17_143148|   Test            29.54                  56            0.67444
21Feb17_143148|-------------------- Test #10 --------------------
21Feb17_143148|Best final individual weights
21Feb17_143148|Individual:
21Feb17_143148|-- Constant hidden layers --
21Feb17_143148|False
21Feb17_143148|Layer 0:
21Feb17_143148|-- Config --
21Feb17_143148|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143148|-- Weights --
21Feb17_143148|[[-0.73212  1.32861  0.10200]
21Feb17_143148| [ 1.48746 -2.97273 -0.42944]
21Feb17_143148| [ 0.53095 -1.50623  0.79224]
21Feb17_143148| [-1.07292 -0.83175 -0.90105]
21Feb17_143148| [-0.48696 -0.89325  0.27226]
21Feb17_143148| [-3.02511  0.34155 -0.03837]
21Feb17_143148| [-0.76747  0.57140 -0.46892]
21Feb17_143148| [-0.07581  0.14713  0.85910]
21Feb17_143148| [-1.37488  0.52170 -0.36205]
21Feb17_143148| [ 1.60981 -0.08727 -0.11267]
21Feb17_143148| [ 0.50986  1.58916 -0.35287]
21Feb17_143148| [-0.34599  1.27113 -0.16393]
21Feb17_143148| [ 1.29203  1.19467  0.37695]
21Feb17_143148| [ 0.58704  0.06328 -0.24240]
21Feb17_143148| [-0.93888 -0.89760  0.57087]
21Feb17_143148| [ 0.99159 -0.66387  0.35177]
21Feb17_143148| [-0.67119  1.06910 -0.12512]
21Feb17_143148| [-0.91534  1.23744 -0.40465]
21Feb17_143148| [ 1.39278  0.08069  0.23328]
21Feb17_143148| [ 0.09880  0.57603 -0.96101]
21Feb17_143148| [ 0.01621 -0.13343 -0.27624]
21Feb17_143148| [-1.28286 -2.28909  0.37931]
21Feb17_143148| [-0.28370  0.09336  0.01547]
21Feb17_143148| [-0.51894  1.84280 -0.25906]
21Feb17_143148| [-0.83075 -0.04508  0.12107]
21Feb17_143148| [ 0.37343  1.18436 -0.07358]
21Feb17_143148| [-2.38657 -0.35191  0.01962]
21Feb17_143148| [ 0.95757 -0.91760 -0.08971]
21Feb17_143148| [ 0.38792 -0.01880  0.69717]
21Feb17_143148| [ 1.66877 -0.58078 -1.21129]
21Feb17_143148| [-0.50943  0.59080  0.30856]
21Feb17_143148| [ 0.30163  1.11518  0.98185]
21Feb17_143148| [-0.73226  0.32281 -0.66712]
21Feb17_143148| [-0.62054 -2.21049  1.40981]
21Feb17_143148| [ 1.23185 -0.58090  0.35844]
21Feb17_143148| [-0.05616  0.24219 -0.02853]
21Feb17_143148| [-1.05085 -2.30259 -0.16276]
21Feb17_143148| [ 0.71087  0.14900  1.13430]
21Feb17_143148| [-2.45877 -1.20999 -1.04986]
21Feb17_143148| [-1.00480  1.36344 -0.13998]
21Feb17_143148| [ 1.83140 -0.91532  0.07616]
21Feb17_143148| [-0.60404 -2.05184  0.76948]
21Feb17_143148| [ 0.52617  0.76042 -1.76746]
21Feb17_143148| [-0.22134  0.17324  0.99530]
21Feb17_143148| [-0.36427  1.34655  0.02110]
21Feb17_143148| [-0.93125 -0.33620 -0.25012]
21Feb17_143148| [-2.76428  0.14487  0.48096]
21Feb17_143148| [-0.10518  0.35052  1.71840]
21Feb17_143148| [-1.27998  1.12568  1.26523]
21Feb17_143148| [-0.60698  1.53230 -0.60824]
21Feb17_143148| [ 0.02898  2.98718 -0.59153]
21Feb17_143148| [ 0.17588 -0.00449  0.50797]
21Feb17_143148| [-1.42674 -0.54967 -0.21310]
21Feb17_143148| [ 1.03196  1.18733  0.36755]
21Feb17_143148| [ 1.04748 -1.47444 -0.08469]
21Feb17_143148| [ 0.49410  0.38745  0.68469]
21Feb17_143148| [-0.62880  0.73245  0.19964]]
21Feb17_143148|-- Bias --
21Feb17_143148|[-0.18798  0.64571 -0.23142]
21Feb17_143148|Layer 1:
21Feb17_143148|-- Config --
21Feb17_143148|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143148|-- Weights --
21Feb17_143148|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_143148| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_143148| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_143148|-- Bias --
21Feb17_143148|[0.60477 0.03773 0.26452 0.12222]
21Feb17_143148|Layer 2:
21Feb17_143148|-- Config --
21Feb17_143148|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143148|-- Weights --
21Feb17_143148|[[ 0.67920  0.12119]
21Feb17_143148| [ 0.44836  0.02916]
21Feb17_143148| [ 0.68939  0.31516]
21Feb17_143148| [-0.58995 -0.05861]]
21Feb17_143148|-- Bias --
21Feb17_143148|[ 0.59649 -0.08079]
21Feb17_143148|Layer 3:
21Feb17_143148|-- Config --
21Feb17_143148|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143148|-- Weights --
21Feb17_143148|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_143148| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_143148|-- Bias --
21Feb17_143148|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_143148|Layer 4:
21Feb17_143148|-- Config --
21Feb17_143148|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143148|-- Weights --
21Feb17_143148|[[-0.03514 -1.04833]
21Feb17_143148| [ 1.25238  0.62094]
21Feb17_143148| [ 0.99203  0.37406]
21Feb17_143148| [ 0.49902  0.67158]
21Feb17_143148| [-1.35709  0.38335]]
21Feb17_143148|-- Bias --
21Feb17_143148|[0.31435 0.36299]
21Feb17_143148|Predicting the validation and test data with the Best final individual.
21Feb17_143156| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_143156|-----------  ------------------  --------------------  ----------
21Feb17_143156|Validation         23.65                  56            0.85845
21Feb17_143156|   Test            26.67                  56            0.71298
21Feb17_143156|-------------------- Test #11 --------------------
21Feb17_143156|Best final individual weights
21Feb17_143156|Individual:
21Feb17_143156|-- Constant hidden layers --
21Feb17_143156|False
21Feb17_143156|Layer 0:
21Feb17_143156|-- Config --
21Feb17_143156|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143156|-- Weights --
21Feb17_143156|[[-0.73212  1.32861  0.10200]
21Feb17_143156| [ 1.48746 -2.97273 -0.42944]
21Feb17_143156| [ 0.53095 -1.50623  0.79224]
21Feb17_143156| [-1.07292 -0.83175 -0.90105]
21Feb17_143156| [-0.48696 -0.89325  0.27226]
21Feb17_143156| [-3.02511  0.34155 -0.03837]
21Feb17_143156| [-0.76747  0.57140 -0.46892]
21Feb17_143156| [-0.07581  0.14713  0.85910]
21Feb17_143156| [-1.37488  0.52170 -0.36205]
21Feb17_143156| [ 1.60981 -0.08727 -0.11267]
21Feb17_143156| [ 0.50986  1.58916 -0.35287]
21Feb17_143156| [-0.34599  1.27113 -0.16393]
21Feb17_143156| [ 1.29203  1.19467  0.37695]
21Feb17_143156| [ 0.58704  0.06328 -0.24240]
21Feb17_143156| [-0.93888 -0.89760  0.57087]
21Feb17_143156| [ 0.99159 -0.66387  0.35177]
21Feb17_143156| [-0.67119  1.06910 -0.12512]
21Feb17_143156| [-0.91534  1.23744 -0.40465]
21Feb17_143156| [ 1.39278  0.08069  0.23328]
21Feb17_143156| [ 0.09880  0.57603 -0.96101]
21Feb17_143156| [ 0.01621 -0.13343 -0.27624]
21Feb17_143156| [-1.28286 -2.28909  0.37931]
21Feb17_143156| [-0.28370  0.09336  0.01547]
21Feb17_143156| [-0.51894  1.84280 -0.25906]
21Feb17_143156| [-0.83075 -0.04508  0.12107]
21Feb17_143156| [ 0.37343  1.18436 -0.07358]
21Feb17_143156| [-2.38657 -0.35191  0.01962]
21Feb17_143156| [ 0.95757 -0.91760 -0.08971]
21Feb17_143156| [ 0.38792 -0.01880  0.69717]
21Feb17_143156| [ 1.66877 -0.58078 -1.21129]
21Feb17_143156| [-0.50943  0.59080  0.30856]
21Feb17_143156| [ 0.30163  1.11518  0.98185]
21Feb17_143156| [-0.73226  0.32281 -0.66712]
21Feb17_143156| [-0.62054 -2.21049  1.40981]
21Feb17_143156| [ 1.23185 -0.58090  0.35844]
21Feb17_143156| [-0.05616  0.24219 -0.02853]
21Feb17_143156| [-1.05085 -2.30259 -0.16276]
21Feb17_143156| [ 0.71087  0.14900  1.13430]
21Feb17_143156| [-2.45877 -1.20999 -1.04986]
21Feb17_143156| [-1.00480  1.36344 -0.13998]
21Feb17_143156| [ 1.83140 -0.91532  0.07616]
21Feb17_143156| [-0.60404 -2.05184  0.76948]
21Feb17_143156| [ 0.52617  0.76042 -1.76746]
21Feb17_143156| [-0.22134  0.17324  0.99530]
21Feb17_143156| [-0.36427  1.34655  0.02110]
21Feb17_143156| [-0.93125 -0.33620 -0.25012]
21Feb17_143156| [-2.76428  0.14487  0.48096]
21Feb17_143156| [-0.10518  0.35052  1.71840]
21Feb17_143156| [-1.27998  1.12568  1.26523]
21Feb17_143156| [-0.60698  1.53230 -0.60824]
21Feb17_143156| [ 0.02898  2.98718 -0.59153]
21Feb17_143156| [ 0.17588 -0.00449  0.50797]
21Feb17_143156| [-1.42674 -0.54967 -0.21310]
21Feb17_143156| [ 1.03196  1.18733  0.36755]
21Feb17_143156| [ 1.04748 -1.47444 -0.08469]
21Feb17_143156| [ 0.49410  0.38745  0.68469]
21Feb17_143156| [-0.62880  0.73245  0.19964]]
21Feb17_143156|-- Bias --
21Feb17_143156|[-0.18798  0.64571 -0.23142]
21Feb17_143156|Layer 1:
21Feb17_143156|-- Config --
21Feb17_143156|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143156|-- Weights --
21Feb17_143156|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_143156| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_143156| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_143156|-- Bias --
21Feb17_143156|[0.60477 0.03773 0.26452 0.12222]
21Feb17_143156|Layer 2:
21Feb17_143156|-- Config --
21Feb17_143156|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143156|-- Weights --
21Feb17_143156|[[ 0.67920  0.12119]
21Feb17_143156| [ 0.44836  0.02916]
21Feb17_143156| [ 0.68939  0.31516]
21Feb17_143156| [-0.58995 -0.05861]]
21Feb17_143156|-- Bias --
21Feb17_143156|[ 0.59649 -0.08079]
21Feb17_143156|Layer 3:
21Feb17_143156|-- Config --
21Feb17_143156|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143156|-- Weights --
21Feb17_143156|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_143156| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_143156|-- Bias --
21Feb17_143156|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_143156|Layer 4:
21Feb17_143156|-- Config --
21Feb17_143156|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143156|-- Weights --
21Feb17_143156|[[-0.03514 -1.04833]
21Feb17_143156| [ 1.25238  0.62094]
21Feb17_143156| [ 0.99203  0.37406]
21Feb17_143156| [ 0.49902  0.67158]
21Feb17_143156| [-1.35709  0.38335]]
21Feb17_143156|-- Bias --
21Feb17_143156|[0.31435 0.36299]
21Feb17_143156|Predicting the validation and test data with the Best final individual.
21Feb17_143204| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_143204|-----------  ------------------  --------------------  ----------
21Feb17_143204|Validation         23.48                  56            0.78306
21Feb17_143204|   Test            22.07                  56            0.85403
21Feb17_143204|-------------------- Test #12 --------------------
21Feb17_143204|Best final individual weights
21Feb17_143204|Individual:
21Feb17_143204|-- Constant hidden layers --
21Feb17_143204|False
21Feb17_143204|Layer 0:
21Feb17_143204|-- Config --
21Feb17_143204|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143204|-- Weights --
21Feb17_143204|[[-0.73212  1.32861  0.10200]
21Feb17_143204| [ 1.48746 -2.97273 -0.42944]
21Feb17_143204| [ 0.53095 -1.50623  0.79224]
21Feb17_143204| [-1.07292 -0.83175 -0.90105]
21Feb17_143204| [-0.48696 -0.89325  0.27226]
21Feb17_143204| [-3.02511  0.34155 -0.03837]
21Feb17_143204| [-0.76747  0.57140 -0.46892]
21Feb17_143204| [-0.07581  0.14713  0.85910]
21Feb17_143204| [-1.37488  0.52170 -0.36205]
21Feb17_143204| [ 1.60981 -0.08727 -0.11267]
21Feb17_143204| [ 0.50986  1.58916 -0.35287]
21Feb17_143204| [-0.34599  1.27113 -0.16393]
21Feb17_143204| [ 1.29203  1.19467  0.37695]
21Feb17_143204| [ 0.58704  0.06328 -0.24240]
21Feb17_143204| [-0.93888 -0.89760  0.57087]
21Feb17_143204| [ 0.99159 -0.66387  0.35177]
21Feb17_143204| [-0.67119  1.06910 -0.12512]
21Feb17_143204| [-0.91534  1.23744 -0.40465]
21Feb17_143204| [ 1.39278  0.08069  0.23328]
21Feb17_143204| [ 0.09880  0.57603 -0.96101]
21Feb17_143204| [ 0.01621 -0.13343 -0.27624]
21Feb17_143204| [-1.28286 -2.28909  0.37931]
21Feb17_143204| [-0.28370  0.09336  0.01547]
21Feb17_143204| [-0.51894  1.84280 -0.25906]
21Feb17_143204| [-0.83075 -0.04508  0.12107]
21Feb17_143204| [ 0.37343  1.18436 -0.07358]
21Feb17_143204| [-2.38657 -0.35191  0.01962]
21Feb17_143204| [ 0.95757 -0.91760 -0.08971]
21Feb17_143204| [ 0.38792 -0.01880  0.69717]
21Feb17_143204| [ 1.66877 -0.58078 -1.21129]
21Feb17_143204| [-0.50943  0.59080  0.30856]
21Feb17_143204| [ 0.30163  1.11518  0.98185]
21Feb17_143204| [-0.73226  0.32281 -0.66712]
21Feb17_143204| [-0.62054 -2.21049  1.40981]
21Feb17_143204| [ 1.23185 -0.58090  0.35844]
21Feb17_143204| [-0.05616  0.24219 -0.02853]
21Feb17_143204| [-1.05085 -2.30259 -0.16276]
21Feb17_143204| [ 0.71087  0.14900  1.13430]
21Feb17_143204| [-2.45877 -1.20999 -1.04986]
21Feb17_143204| [-1.00480  1.36344 -0.13998]
21Feb17_143204| [ 1.83140 -0.91532  0.07616]
21Feb17_143204| [-0.60404 -2.05184  0.76948]
21Feb17_143204| [ 0.52617  0.76042 -1.76746]
21Feb17_143204| [-0.22134  0.17324  0.99530]
21Feb17_143204| [-0.36427  1.34655  0.02110]
21Feb17_143204| [-0.93125 -0.33620 -0.25012]
21Feb17_143204| [-2.76428  0.14487  0.48096]
21Feb17_143204| [-0.10518  0.35052  1.71840]
21Feb17_143204| [-1.27998  1.12568  1.26523]
21Feb17_143204| [-0.60698  1.53230 -0.60824]
21Feb17_143204| [ 0.02898  2.98718 -0.59153]
21Feb17_143204| [ 0.17588 -0.00449  0.50797]
21Feb17_143204| [-1.42674 -0.54967 -0.21310]
21Feb17_143204| [ 1.03196  1.18733  0.36755]
21Feb17_143204| [ 1.04748 -1.47444 -0.08469]
21Feb17_143204| [ 0.49410  0.38745  0.68469]
21Feb17_143204| [-0.62880  0.73245  0.19964]]
21Feb17_143204|-- Bias --
21Feb17_143204|[-0.18798  0.64571 -0.23142]
21Feb17_143204|Layer 1:
21Feb17_143204|-- Config --
21Feb17_143204|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143204|-- Weights --
21Feb17_143204|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_143204| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_143204| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_143204|-- Bias --
21Feb17_143204|[0.60477 0.03773 0.26452 0.12222]
21Feb17_143204|Layer 2:
21Feb17_143204|-- Config --
21Feb17_143204|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143204|-- Weights --
21Feb17_143204|[[ 0.67920  0.12119]
21Feb17_143204| [ 0.44836  0.02916]
21Feb17_143204| [ 0.68939  0.31516]
21Feb17_143204| [-0.58995 -0.05861]]
21Feb17_143204|-- Bias --
21Feb17_143204|[ 0.59649 -0.08079]
21Feb17_143204|Layer 3:
21Feb17_143204|-- Config --
21Feb17_143204|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143204|-- Weights --
21Feb17_143204|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_143204| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_143204|-- Bias --
21Feb17_143204|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_143204|Layer 4:
21Feb17_143204|-- Config --
21Feb17_143204|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143204|-- Weights --
21Feb17_143204|[[-0.03514 -1.04833]
21Feb17_143204| [ 1.25238  0.62094]
21Feb17_143204| [ 0.99203  0.37406]
21Feb17_143204| [ 0.49902  0.67158]
21Feb17_143204| [-1.35709  0.38335]]
21Feb17_143204|-- Bias --
21Feb17_143204|[0.31435 0.36299]
21Feb17_143204|Predicting the validation and test data with the Best final individual.
21Feb17_143212| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_143212|-----------  ------------------  --------------------  ----------
21Feb17_143212|Validation         24.43                  56            0.85301
21Feb17_143212|   Test            37.01                  56            0.82036
21Feb17_143212|-------------------- Test #13 --------------------
21Feb17_143212|Best final individual weights
21Feb17_143212|Individual:
21Feb17_143212|-- Constant hidden layers --
21Feb17_143212|False
21Feb17_143212|Layer 0:
21Feb17_143212|-- Config --
21Feb17_143212|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143212|-- Weights --
21Feb17_143212|[[-0.73212  1.32861  0.10200]
21Feb17_143212| [ 1.48746 -2.97273 -0.42944]
21Feb17_143212| [ 0.53095 -1.50623  0.79224]
21Feb17_143212| [-1.07292 -0.83175 -0.90105]
21Feb17_143212| [-0.48696 -0.89325  0.27226]
21Feb17_143212| [-3.02511  0.34155 -0.03837]
21Feb17_143212| [-0.76747  0.57140 -0.46892]
21Feb17_143212| [-0.07581  0.14713  0.85910]
21Feb17_143212| [-1.37488  0.52170 -0.36205]
21Feb17_143212| [ 1.60981 -0.08727 -0.11267]
21Feb17_143212| [ 0.50986  1.58916 -0.35287]
21Feb17_143212| [-0.34599  1.27113 -0.16393]
21Feb17_143212| [ 1.29203  1.19467  0.37695]
21Feb17_143212| [ 0.58704  0.06328 -0.24240]
21Feb17_143212| [-0.93888 -0.89760  0.57087]
21Feb17_143212| [ 0.99159 -0.66387  0.35177]
21Feb17_143212| [-0.67119  1.06910 -0.12512]
21Feb17_143212| [-0.91534  1.23744 -0.40465]
21Feb17_143212| [ 1.39278  0.08069  0.23328]
21Feb17_143212| [ 0.09880  0.57603 -0.96101]
21Feb17_143212| [ 0.01621 -0.13343 -0.27624]
21Feb17_143212| [-1.28286 -2.28909  0.37931]
21Feb17_143212| [-0.28370  0.09336  0.01547]
21Feb17_143212| [-0.51894  1.84280 -0.25906]
21Feb17_143212| [-0.83075 -0.04508  0.12107]
21Feb17_143212| [ 0.37343  1.18436 -0.07358]
21Feb17_143212| [-2.38657 -0.35191  0.01962]
21Feb17_143212| [ 0.95757 -0.91760 -0.08971]
21Feb17_143212| [ 0.38792 -0.01880  0.69717]
21Feb17_143212| [ 1.66877 -0.58078 -1.21129]
21Feb17_143212| [-0.50943  0.59080  0.30856]
21Feb17_143212| [ 0.30163  1.11518  0.98185]
21Feb17_143212| [-0.73226  0.32281 -0.66712]
21Feb17_143212| [-0.62054 -2.21049  1.40981]
21Feb17_143212| [ 1.23185 -0.58090  0.35844]
21Feb17_143212| [-0.05616  0.24219 -0.02853]
21Feb17_143212| [-1.05085 -2.30259 -0.16276]
21Feb17_143212| [ 0.71087  0.14900  1.13430]
21Feb17_143212| [-2.45877 -1.20999 -1.04986]
21Feb17_143212| [-1.00480  1.36344 -0.13998]
21Feb17_143212| [ 1.83140 -0.91532  0.07616]
21Feb17_143212| [-0.60404 -2.05184  0.76948]
21Feb17_143212| [ 0.52617  0.76042 -1.76746]
21Feb17_143212| [-0.22134  0.17324  0.99530]
21Feb17_143212| [-0.36427  1.34655  0.02110]
21Feb17_143212| [-0.93125 -0.33620 -0.25012]
21Feb17_143212| [-2.76428  0.14487  0.48096]
21Feb17_143212| [-0.10518  0.35052  1.71840]
21Feb17_143212| [-1.27998  1.12568  1.26523]
21Feb17_143212| [-0.60698  1.53230 -0.60824]
21Feb17_143212| [ 0.02898  2.98718 -0.59153]
21Feb17_143212| [ 0.17588 -0.00449  0.50797]
21Feb17_143212| [-1.42674 -0.54967 -0.21310]
21Feb17_143212| [ 1.03196  1.18733  0.36755]
21Feb17_143212| [ 1.04748 -1.47444 -0.08469]
21Feb17_143212| [ 0.49410  0.38745  0.68469]
21Feb17_143212| [-0.62880  0.73245  0.19964]]
21Feb17_143212|-- Bias --
21Feb17_143212|[-0.18798  0.64571 -0.23142]
21Feb17_143212|Layer 1:
21Feb17_143212|-- Config --
21Feb17_143212|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143212|-- Weights --
21Feb17_143212|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_143212| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_143212| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_143212|-- Bias --
21Feb17_143212|[0.60477 0.03773 0.26452 0.12222]
21Feb17_143212|Layer 2:
21Feb17_143212|-- Config --
21Feb17_143212|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143212|-- Weights --
21Feb17_143212|[[ 0.67920  0.12119]
21Feb17_143212| [ 0.44836  0.02916]
21Feb17_143212| [ 0.68939  0.31516]
21Feb17_143212| [-0.58995 -0.05861]]
21Feb17_143212|-- Bias --
21Feb17_143212|[ 0.59649 -0.08079]
21Feb17_143212|Layer 3:
21Feb17_143212|-- Config --
21Feb17_143212|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143212|-- Weights --
21Feb17_143212|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_143212| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_143212|-- Bias --
21Feb17_143212|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_143212|Layer 4:
21Feb17_143212|-- Config --
21Feb17_143212|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143212|-- Weights --
21Feb17_143212|[[-0.03514 -1.04833]
21Feb17_143212| [ 1.25238  0.62094]
21Feb17_143212| [ 0.99203  0.37406]
21Feb17_143212| [ 0.49902  0.67158]
21Feb17_143212| [-1.35709  0.38335]]
21Feb17_143212|-- Bias --
21Feb17_143212|[0.31435 0.36299]
21Feb17_143212|Predicting the validation and test data with the Best final individual.
21Feb17_143219| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_143219|-----------  ------------------  --------------------  ----------
21Feb17_143219|Validation         21.74                  56            0.74120
21Feb17_143219|   Test            25.80                  56            0.72926
21Feb17_143219|-------------------- Test #14 --------------------
21Feb17_143219|Best final individual weights
21Feb17_143219|Individual:
21Feb17_143219|-- Constant hidden layers --
21Feb17_143219|False
21Feb17_143219|Layer 0:
21Feb17_143219|-- Config --
21Feb17_143219|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143219|-- Weights --
21Feb17_143219|[[-0.73212  1.32861  0.10200]
21Feb17_143219| [ 1.48746 -2.97273 -0.42944]
21Feb17_143219| [ 0.53095 -1.50623  0.79224]
21Feb17_143219| [-1.07292 -0.83175 -0.90105]
21Feb17_143219| [-0.48696 -0.89325  0.27226]
21Feb17_143219| [-3.02511  0.34155 -0.03837]
21Feb17_143219| [-0.76747  0.57140 -0.46892]
21Feb17_143219| [-0.07581  0.14713  0.85910]
21Feb17_143219| [-1.37488  0.52170 -0.36205]
21Feb17_143219| [ 1.60981 -0.08727 -0.11267]
21Feb17_143219| [ 0.50986  1.58916 -0.35287]
21Feb17_143219| [-0.34599  1.27113 -0.16393]
21Feb17_143219| [ 1.29203  1.19467  0.37695]
21Feb17_143219| [ 0.58704  0.06328 -0.24240]
21Feb17_143219| [-0.93888 -0.89760  0.57087]
21Feb17_143219| [ 0.99159 -0.66387  0.35177]
21Feb17_143219| [-0.67119  1.06910 -0.12512]
21Feb17_143219| [-0.91534  1.23744 -0.40465]
21Feb17_143219| [ 1.39278  0.08069  0.23328]
21Feb17_143219| [ 0.09880  0.57603 -0.96101]
21Feb17_143219| [ 0.01621 -0.13343 -0.27624]
21Feb17_143219| [-1.28286 -2.28909  0.37931]
21Feb17_143219| [-0.28370  0.09336  0.01547]
21Feb17_143219| [-0.51894  1.84280 -0.25906]
21Feb17_143219| [-0.83075 -0.04508  0.12107]
21Feb17_143219| [ 0.37343  1.18436 -0.07358]
21Feb17_143219| [-2.38657 -0.35191  0.01962]
21Feb17_143219| [ 0.95757 -0.91760 -0.08971]
21Feb17_143219| [ 0.38792 -0.01880  0.69717]
21Feb17_143219| [ 1.66877 -0.58078 -1.21129]
21Feb17_143219| [-0.50943  0.59080  0.30856]
21Feb17_143219| [ 0.30163  1.11518  0.98185]
21Feb17_143219| [-0.73226  0.32281 -0.66712]
21Feb17_143219| [-0.62054 -2.21049  1.40981]
21Feb17_143219| [ 1.23185 -0.58090  0.35844]
21Feb17_143219| [-0.05616  0.24219 -0.02853]
21Feb17_143219| [-1.05085 -2.30259 -0.16276]
21Feb17_143219| [ 0.71087  0.14900  1.13430]
21Feb17_143219| [-2.45877 -1.20999 -1.04986]
21Feb17_143219| [-1.00480  1.36344 -0.13998]
21Feb17_143219| [ 1.83140 -0.91532  0.07616]
21Feb17_143219| [-0.60404 -2.05184  0.76948]
21Feb17_143219| [ 0.52617  0.76042 -1.76746]
21Feb17_143219| [-0.22134  0.17324  0.99530]
21Feb17_143219| [-0.36427  1.34655  0.02110]
21Feb17_143219| [-0.93125 -0.33620 -0.25012]
21Feb17_143219| [-2.76428  0.14487  0.48096]
21Feb17_143219| [-0.10518  0.35052  1.71840]
21Feb17_143219| [-1.27998  1.12568  1.26523]
21Feb17_143219| [-0.60698  1.53230 -0.60824]
21Feb17_143219| [ 0.02898  2.98718 -0.59153]
21Feb17_143219| [ 0.17588 -0.00449  0.50797]
21Feb17_143219| [-1.42674 -0.54967 -0.21310]
21Feb17_143219| [ 1.03196  1.18733  0.36755]
21Feb17_143219| [ 1.04748 -1.47444 -0.08469]
21Feb17_143219| [ 0.49410  0.38745  0.68469]
21Feb17_143219| [-0.62880  0.73245  0.19964]]
21Feb17_143219|-- Bias --
21Feb17_143219|[-0.18798  0.64571 -0.23142]
21Feb17_143219|Layer 1:
21Feb17_143219|-- Config --
21Feb17_143219|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143219|-- Weights --
21Feb17_143219|[[ 1.05567 -0.26707 -0.68567 -0.21721]
21Feb17_143219| [ 0.59596 -1.62444  0.26778  0.12586]
21Feb17_143219| [-0.24975 -0.21263  0.76717  0.40119]]
21Feb17_143219|-- Bias --
21Feb17_143219|[0.60477 0.03773 0.26452 0.12222]
21Feb17_143219|Layer 2:
21Feb17_143219|-- Config --
21Feb17_143219|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143219|-- Weights --
21Feb17_143219|[[ 0.67920  0.12119]
21Feb17_143219| [ 0.44836  0.02916]
21Feb17_143219| [ 0.68939  0.31516]
21Feb17_143219| [-0.58995 -0.05861]]
21Feb17_143219|-- Bias --
21Feb17_143219|[ 0.59649 -0.08079]
21Feb17_143219|Layer 3:
21Feb17_143219|-- Config --
21Feb17_143219|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143219|-- Weights --
21Feb17_143219|[[-0.52933 -0.81476 -0.74098  0.01144 -1.21485]
21Feb17_143219| [-0.49101  0.13657 -0.19176  0.07319 -0.26418]]
21Feb17_143219|-- Bias --
21Feb17_143219|[ 0.44536 -0.29385  1.36942 -0.31228  0.81725]
21Feb17_143219|Layer 4:
21Feb17_143219|-- Config --
21Feb17_143219|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb17_143219|-- Weights --
21Feb17_143219|[[-0.03514 -1.04833]
21Feb17_143219| [ 1.25238  0.62094]
21Feb17_143219| [ 0.99203  0.37406]
21Feb17_143219| [ 0.49902  0.67158]
21Feb17_143219| [-1.35709  0.38335]]
21Feb17_143219|-- Bias --
21Feb17_143219|[0.31435 0.36299]
21Feb17_143219|Predicting the validation and test data with the Best final individual.
21Feb17_143227| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb17_143227|-----------  ------------------  --------------------  ----------
21Feb17_143227|Validation         22.70                  56            0.74363
21Feb17_143227|   Test            19.46                  56            0.73101
