2021-02-12 10:15:31.470211: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
21Feb12_101532|Data summary: Train
21Feb12_101532|data.shape = (2300, 57)
21Feb12_101532|labels.shape = (2300,)
21Feb12_101532|Class distribution:
21Feb12_101532|	0 - 1382 (0.60)
21Feb12_101532|	1 - 918 (0.40)
21Feb12_101532|Data summary: Validation
21Feb12_101532|data.shape = (1150, 57)
21Feb12_101532|labels.shape = (1150,)
21Feb12_101532|Class distribution:
21Feb12_101532|	0 - 704 (0.61)
21Feb12_101532|	1 - 446 (0.39)
21Feb12_101532|Data summary: Test
21Feb12_101532|data.shape = (1151, 57)
21Feb12_101532|labels.shape = (1151,)
21Feb12_101532|Class distribution:
21Feb12_101532|	0 - 702 (0.61)
21Feb12_101532|	1 - 449 (0.39)
21Feb12_101532|Selected configuration values
21Feb12_101532|-- Dataset name: spambase1
21Feb12_101532|-- Initial population size: 64
21Feb12_101532|-- Maximun number of generations: 32
21Feb12_101532|-- Neurons per hidden layer range: (2, 20)
21Feb12_101532|-- Hidden layers number range: (1, 3)
21Feb12_101532|-- Crossover probability: 0.5
21Feb12_101532|-- Bias gene mutation probability: 0.2
21Feb12_101532|-- Weights gene mutation probability: 0.75
21Feb12_101532|-- Neuron mutation probability: 0.3
21Feb12_101532|-- Layer mutation probability: 0.3
21Feb12_101532|-- Constant hidden layers: False
21Feb12_101532|-- Seed: 31415
21Feb12_101532|Entering GA
21Feb12_101532|Start the algorithm
2021-02-12 10:15:32.360246: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-12 10:15:32.360742: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-02-12 10:15:32.382699: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-12 10:15:32.383017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.71GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s
2021-02-12 10:15:32.383031: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-02-12 10:15:32.384392: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-02-12 10:15:32.384420: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-02-12 10:15:32.384892: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-02-12 10:15:32.385023: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-02-12 10:15:32.385093: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-12 10:15:32.385473: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-02-12 10:15:32.385516: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-12 10:15:32.385521: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-02-12 10:15:32.385726: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-02-12 10:15:32.386444: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-12 10:15:32.386458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-12 10:15:32.386461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      
2021-02-12 10:15:32.431870: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-02-12 10:15:32.432168: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3493635000 Hz
/home/jmerelo/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype("int32")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn('`model.predict_classes()` is deprecated and '
21Feb12_101932|-- Generation 1 --
21Feb12_101932|    -- Crossed 1 individual pairs.
21Feb12_101932|    -- Mutated 32 individuals.
21Feb12_102331|    -- Evaluated 64 individuals.
21Feb12_102331|    Summary of generation 1:
21Feb12_102331| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_102331|-----------  ------------------  --------------------  ----------
21Feb12_102331|    Max            39.30                180.00          0.79340
21Feb12_102331|    Avg            38.73                55.62           0.01352
21Feb12_102331|    Min            31.04                 3.00           0.00000
21Feb12_102331|    Std             0.98                45.95           0.09846
21Feb12_102331|   Best            31.04                63.00           0.79340
21Feb12_102331|-- Generation 2 --
21Feb12_102331|    -- Crossed 3 individual pairs.
21Feb12_102331|    -- Mutated 32 individuals.
21Feb12_102731|    -- Evaluated 64 individuals.
21Feb12_102731|    Summary of generation 2:
21Feb12_102731| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_102731|-----------  ------------------  --------------------  ----------
21Feb12_102731|    Max            39.22                128.00          0.57583
21Feb12_102731|    Avg            38.55                47.50           0.01269
21Feb12_102731|    Min            24.87                 3.00           0.00000
21Feb12_102731|    Std             1.74                36.43           0.07243
21Feb12_102731|   Best            24.87                20.00           0.57583
21Feb12_102731|-- Generation 3 --
21Feb12_102731|    -- Crossed 3 individual pairs.
21Feb12_102731|    -- Mutated 32 individuals.
21Feb12_103124|    -- Evaluated 64 individuals.
21Feb12_103124|    Summary of generation 3:
21Feb12_103124| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_103124|-----------  ------------------  --------------------  ----------
21Feb12_103124|    Max            39.30                54.00           0.55156
21Feb12_103124|    Avg            38.19                19.69           0.03302
21Feb12_103124|    Min            24.96                 3.00           0.00000
21Feb12_103124|    Std             2.69                14.61           0.11921
21Feb12_103124|   Best            24.96                20.00           0.55156
21Feb12_103124|-- Generation 4 --
21Feb12_103124|    -- Crossed 3 individual pairs.
21Feb12_103124|    -- Mutated 32 individuals.
21Feb12_103514|    -- Evaluated 64 individuals.
21Feb12_103514|    Summary of generation 4:
21Feb12_103514| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_103514|-----------  ------------------  --------------------  ----------
21Feb12_103514|    Max            39.13                30.00           0.80000
21Feb12_103514|    Avg            38.10                12.36           0.03956
21Feb12_103514|    Min            25.30                 2.00           0.00000
21Feb12_103514|    Std             2.79                 7.73           0.15005
21Feb12_103514|   Best            25.30                22.00           0.62241
21Feb12_103514|-- Generation 5 --
21Feb12_103514|    -- Crossed 2 individual pairs.
21Feb12_103514|    -- Mutated 32 individuals.
21Feb12_103901|    -- Evaluated 64 individuals.
21Feb12_103901|    Summary of generation 5:
21Feb12_103901| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_103901|-----------  ------------------  --------------------  ----------
21Feb12_103901|    Max            42.61                22.00           0.78839
21Feb12_103901|    Avg            38.49                 8.47           0.03507
21Feb12_103901|    Min            25.39                 2.00           0.00000
21Feb12_103901|    Std             2.31                 5.84           0.15392
21Feb12_103901|   Best            25.39                 4.00           0.64097
21Feb12_103901|-- Generation 6 --
21Feb12_103901|    -- Crossed 8 individual pairs.
21Feb12_103901|    -- Mutated 32 individuals.
21Feb12_104250|    -- Evaluated 64 individuals.
21Feb12_104250|    Summary of generation 6:
21Feb12_104250| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_104250|-----------  ------------------  --------------------  ----------
21Feb12_104250|    Max            40.52                22.00           0.50831
21Feb12_104250|    Avg            38.40                 7.58           0.01825
21Feb12_104250|    Min            25.30                 2.00           0.00000
21Feb12_104250|    Std             2.40                 5.88           0.08755
21Feb12_104250|   Best            25.30                10.00           0.47690
21Feb12_104250|-- Generation 7 --
21Feb12_104250|    -- Crossed 9 individual pairs.
21Feb12_104250|    -- Mutated 32 individuals.
21Feb12_104636|    -- Evaluated 64 individuals.
21Feb12_104636|    Summary of generation 7:
21Feb12_104636| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_104636|-----------  ------------------  --------------------  ----------
21Feb12_104636|    Max            42.61                24.00           0.80112
21Feb12_104636|    Avg            38.36                 6.34           0.03188
21Feb12_104636|    Min            26.26                 2.00           0.00000
21Feb12_104636|    Std             2.31                 6.04           0.12800
21Feb12_104636|   Best            26.26                21.00           0.45409
21Feb12_104636|-- Generation 8 --
21Feb12_104636|    -- Crossed 7 individual pairs.
21Feb12_104636|    -- Mutated 32 individuals.
21Feb12_105020|    -- Evaluated 64 individuals.
21Feb12_105020|    Summary of generation 8:
21Feb12_105020| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_105020|-----------  ------------------  --------------------  ----------
21Feb12_105020|    Max            39.22                21.00           0.76242
21Feb12_105020|    Avg            38.33                 5.95           0.02114
21Feb12_105020|    Min            23.57                 2.00           0.00000
21Feb12_105020|    Std             2.48                 5.96           0.11229
21Feb12_105020|   Best            23.57                12.00           0.76242
21Feb12_105020|-- Generation 9 --
21Feb12_105021|    -- Crossed 6 individual pairs.
21Feb12_105021|    -- Mutated 32 individuals.
21Feb12_105409|    -- Evaluated 64 individuals.
21Feb12_105409|    Summary of generation 9:
21Feb12_105409| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_105409|-----------  ------------------  --------------------  ----------
21Feb12_105409|    Max            38.96                50.00           0.28861
21Feb12_105409|    Avg            38.67                 6.75           0.00529
21Feb12_105409|    Min            31.57                 2.00           0.00000
21Feb12_105409|    Std             0.90                 8.08           0.03597
21Feb12_105409|   Best            31.57                21.00           0.28861
21Feb12_105409|-- Generation 10 --
21Feb12_105409|    -- Crossed 8 individual pairs.
21Feb12_105409|    -- Mutated 32 individuals.
21Feb12_105758|    -- Evaluated 64 individuals.
21Feb12_105758|    Summary of generation 10:
21Feb12_105758| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_105758|-----------  ------------------  --------------------  ----------
21Feb12_105758|    Max            39.30                48.00           0.80768
21Feb12_105758|    Avg            38.56                 5.67           0.01288
21Feb12_105758|    Min            23.22                 2.00           0.00000
21Feb12_105758|    Std             1.93                 7.31           0.10015
21Feb12_105758|   Best            23.22                21.00           0.80768
21Feb12_105758|-- Generation 11 --
21Feb12_105758|    -- Crossed 10 individual pairs.
21Feb12_105758|    -- Mutated 32 individuals.
21Feb12_110145|    -- Evaluated 64 individuals.
21Feb12_110145|    Summary of generation 11:
21Feb12_110145| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_110145|-----------  ------------------  --------------------  ----------
21Feb12_110145|    Max            39.13                21.00           0.41605
21Feb12_110145|    Avg            38.49                 4.91           0.01298
21Feb12_110145|    Min            28.78                 2.00           0.00000
21Feb12_110145|    Std             1.64                 4.86           0.06861
21Feb12_110145|   Best            28.78                14.00           0.37009
21Feb12_110145|-- Generation 12 --
21Feb12_110145|    -- Crossed 6 individual pairs.
21Feb12_110145|    -- Mutated 32 individuals.
21Feb12_110533|    -- Evaluated 64 individuals.
21Feb12_110533|    Summary of generation 12:
21Feb12_110533| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_110533|-----------  ------------------  --------------------  ----------
21Feb12_110533|    Max            39.04                52.00           0.03059
21Feb12_110533|    Avg            38.79                 5.52           0.00057
21Feb12_110533|    Min            38.09                 2.00           0.00000
21Feb12_110533|    Std             0.11                 8.46           0.00385
21Feb12_110533|   Best            38.09                21.00           0.03059
21Feb12_110533|-- Generation 13 --
21Feb12_110533|    -- Crossed 6 individual pairs.
21Feb12_110533|    -- Mutated 32 individuals.
21Feb12_110919|    -- Evaluated 64 individuals.
21Feb12_110919|    Summary of generation 13:
21Feb12_110919| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_110919|-----------  ------------------  --------------------  ----------
21Feb12_110919|    Max            39.30                21.00           0.35969
21Feb12_110919|    Avg            38.66                 3.72           0.00562
21Feb12_110919|    Min            29.57                 2.00           0.00000
21Feb12_110919|    Std             1.15                 4.42           0.04461
21Feb12_110919|   Best            29.57                21.00           0.35969
21Feb12_110919|-- Generation 14 --
21Feb12_110919|    -- Crossed 8 individual pairs.
21Feb12_110919|    -- Mutated 32 individuals.
21Feb12_111306|    -- Evaluated 64 individuals.
21Feb12_111306|    Summary of generation 14:
21Feb12_111306| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_111306|-----------  ------------------  --------------------  ----------
21Feb12_111306|    Max            39.04                48.00           0.82930
21Feb12_111306|    Avg            38.62                 4.47           0.01296
21Feb12_111306|    Min            27.65                 2.00           0.00000
21Feb12_111306|    Std             1.38                 6.90           0.10285
21Feb12_111306|   Best            27.65                21.00           0.82930
21Feb12_111306|-- Generation 15 --
21Feb12_111306|    -- Crossed 9 individual pairs.
21Feb12_111306|    -- Mutated 32 individuals.
21Feb12_111654|    -- Evaluated 64 individuals.
21Feb12_111654|    Summary of generation 15:
21Feb12_111654| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_111654|-----------  ------------------  --------------------  ----------
21Feb12_111654|    Max            39.39                22.00           0.82240
21Feb12_111654|    Avg            38.59                 4.23           0.01285
21Feb12_111654|    Min            25.91                 2.00           0.00000
21Feb12_111654|    Std             1.60                 4.62           0.10199
21Feb12_111654|   Best            25.91                22.00           0.82240
21Feb12_111654|-- Generation 16 --
21Feb12_111654|    -- Crossed 6 individual pairs.
21Feb12_111654|    -- Mutated 32 individuals.
21Feb12_112042|    -- Evaluated 64 individuals.
21Feb12_112042|    Summary of generation 16:
21Feb12_112042| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_112042|-----------  ------------------  --------------------  ----------
21Feb12_112042|    Max            39.57                22.00           0.03059
21Feb12_112042|    Avg            38.79                 4.41           0.00048
21Feb12_112042|    Min            38.09                 2.00           0.00000
21Feb12_112042|    Std             0.14                 4.89           0.00379
21Feb12_112042|   Best            38.09                22.00           0.03059
21Feb12_112042|-- Generation 17 --
21Feb12_112042|    -- Crossed 6 individual pairs.
21Feb12_112042|    -- Mutated 32 individuals.
21Feb12_112427|    -- Evaluated 64 individuals.
21Feb12_112427|    Summary of generation 17:
21Feb12_112427| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_112427|-----------  ------------------  --------------------  ----------
21Feb12_112427|    Max            39.30                22.00           0.01665
21Feb12_112427|    Avg            38.80                 3.95           0.00035
21Feb12_112427|    Min            38.78                 2.00           0.00000
21Feb12_112427|    Std             0.08                 4.38           0.00217
21Feb12_112427|   Best            38.78                 2.00           0.00000
21Feb12_112427|-- Generation 18 --
21Feb12_112427|    -- Crossed 6 individual pairs.
21Feb12_112427|    -- Mutated 32 individuals.
21Feb12_112812|    -- Evaluated 64 individuals.
21Feb12_112812|    Summary of generation 18:
21Feb12_112812| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_112812|-----------  ------------------  --------------------  ----------
21Feb12_112812|    Max            38.87                14.00           0.00560
21Feb12_112812|    Avg            38.79                 3.30           0.00009
21Feb12_112812|    Min            38.61                 2.00           0.00000
21Feb12_112812|    Std             0.03                 3.26           0.00069
21Feb12_112812|   Best            38.61                14.00           0.00560
21Feb12_112812|-- Generation 19 --
21Feb12_112812|    -- Crossed 7 individual pairs.
21Feb12_112812|    -- Mutated 32 individuals.
21Feb12_113158|    -- Evaluated 64 individuals.
21Feb12_113158|    Summary of generation 19:
21Feb12_113158| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_113158|-----------  ------------------  --------------------  ----------
21Feb12_113158|    Max            39.04                16.00           0.07642
21Feb12_113158|    Avg            38.77                 3.92           0.00176
21Feb12_113158|    Min            37.74                 2.00           0.00000
21Feb12_113158|    Std             0.16                 4.21           0.01042
21Feb12_113158|   Best            37.74                14.00           0.03615
21Feb12_113158|-- Generation 20 --
21Feb12_113158|    -- Crossed 7 individual pairs.
21Feb12_113158|    -- Mutated 32 individuals.
21Feb12_113544|    -- Evaluated 64 individuals.
21Feb12_113544|    Summary of generation 20:
21Feb12_113544| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_113544|-----------  ------------------  --------------------  ----------
21Feb12_113544|    Max            38.96                18.00           0.55873
21Feb12_113544|    Avg            38.40                 3.86           0.01565
21Feb12_113544|    Min            25.65                 2.00           0.00000
21Feb12_113544|    Std             2.13                 4.00           0.08527
21Feb12_113544|   Best            25.65                14.00           0.55873
21Feb12_113544|-- Generation 21 --
21Feb12_113544|    -- Crossed 8 individual pairs.
21Feb12_113544|    -- Mutated 32 individuals.
21Feb12_113929|    -- Evaluated 64 individuals.
21Feb12_113929|    Summary of generation 21:
21Feb12_113929| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_113929|-----------  ------------------  --------------------  ----------
21Feb12_113929|    Max            39.04                33.00           0.50756
21Feb12_113929|    Avg            38.37                 4.45           0.01810
21Feb12_113929|    Min            25.65                 2.00           0.00000
21Feb12_113929|    Std             2.11                 5.35           0.08123
21Feb12_113929|   Best            25.65                12.00           0.50756
21Feb12_113929|-- Generation 22 --
21Feb12_113929|    -- Crossed 10 individual pairs.
21Feb12_113929|    -- Mutated 32 individuals.
21Feb12_114315|    -- Evaluated 64 individuals.
21Feb12_114315|    Summary of generation 22:
21Feb12_114315| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_114315|-----------  ------------------  --------------------  ----------
21Feb12_114315|    Max            39.04                27.00           0.57838
21Feb12_114315|    Avg            38.38                 5.05           0.01734
21Feb12_114315|    Min            25.22                 2.00           0.00000
21Feb12_114315|    Std             2.25                 5.29           0.09369
21Feb12_114315|   Best            25.22                 8.00           0.57838
21Feb12_114315|-- Generation 23 --
21Feb12_114315|    -- Crossed 8 individual pairs.
21Feb12_114315|    -- Mutated 32 individuals.
21Feb12_114702|    -- Evaluated 64 individuals.
21Feb12_114702|    Summary of generation 23:
21Feb12_114702| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_114702|-----------  ------------------  --------------------  ----------
21Feb12_114702|    Max            39.22                27.00           0.53563
21Feb12_114702|    Avg            38.58                 4.83           0.00837
21Feb12_114702|    Min            24.61                 2.00           0.00000
21Feb12_114702|    Std             1.76                 5.28           0.06643
21Feb12_114702|   Best            24.61                 8.00           0.53563
21Feb12_114702|-- Generation 24 --
21Feb12_114702|    -- Crossed 8 individual pairs.
21Feb12_114702|    -- Mutated 32 individuals.
21Feb12_115048|    -- Evaluated 64 individuals.
21Feb12_115048|    Summary of generation 24:
21Feb12_115048| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_115048|-----------  ------------------  --------------------  ----------
21Feb12_115048|    Max            38.87                14.00           0.54837
21Feb12_115048|    Avg            38.37                 3.80           0.01684
21Feb12_115048|    Min            25.39                 2.00           0.00000
21Feb12_115048|    Std             2.33                 3.62           0.09379
21Feb12_115048|   Best            25.39                 8.00           0.54837
21Feb12_115048|-- Generation 25 --
21Feb12_115048|    -- Crossed 6 individual pairs.
21Feb12_115048|    -- Mutated 32 individuals.
21Feb12_115434|    -- Evaluated 64 individuals.
21Feb12_115434|    Summary of generation 25:
21Feb12_115434| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_115434|-----------  ------------------  --------------------  ----------
21Feb12_115434|    Max            46.78                18.00           0.80441
21Feb12_115434|    Avg            38.44                 4.06           0.03514
21Feb12_115434|    Min            25.30                 2.00           0.00000
21Feb12_115434|    Std             2.57                 4.19           0.15081
21Feb12_115434|   Best            25.30                18.00           0.72704
21Feb12_115434|-- Generation 26 --
21Feb12_115434|    -- Crossed 8 individual pairs.
21Feb12_115434|    -- Mutated 32 individuals.
21Feb12_115820|    -- Evaluated 64 individuals.
21Feb12_115820|    Summary of generation 26:
21Feb12_115820| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_115820|-----------  ------------------  --------------------  ----------
21Feb12_115820|    Max            39.22                36.00           0.54301
21Feb12_115820|    Avg            38.55                 4.70           0.01027
21Feb12_115820|    Min            25.30                 2.00           0.00000
21Feb12_115820|    Std             1.71                 5.96           0.06861
21Feb12_115820|   Best            25.30                 8.00           0.54301
21Feb12_115820|-- Generation 27 --
21Feb12_115820|    -- Crossed 8 individual pairs.
21Feb12_115820|    -- Mutated 32 individuals.
21Feb12_120206|    -- Evaluated 64 individuals.
21Feb12_120206|    Summary of generation 27:
21Feb12_120206| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_120206|-----------  ------------------  --------------------  ----------
21Feb12_120206|    Max            38.96                16.00           0.62443
21Feb12_120206|    Avg            38.17                 3.53           0.02918
21Feb12_120206|    Min            25.39                 2.00           0.00000
21Feb12_120206|    Std             2.70                 3.46           0.12810
21Feb12_120206|   Best            25.39                 8.00           0.60641
21Feb12_120206|-- Generation 28 --
21Feb12_120206|    -- Crossed 6 individual pairs.
21Feb12_120206|    -- Mutated 32 individuals.
21Feb12_120552|    -- Evaluated 64 individuals.
21Feb12_120552|    Summary of generation 28:
21Feb12_120552| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_120552|-----------  ------------------  --------------------  ----------
21Feb12_120552|    Max            38.87                27.00           0.55714
21Feb12_120552|    Avg            38.15                 4.64           0.02464
21Feb12_120552|    Min            25.39                 2.00           0.00000
21Feb12_120552|    Std             2.78                 4.84           0.10876
21Feb12_120552|   Best            25.39                12.00           0.50831
21Feb12_120552|-- Generation 29 --
21Feb12_120552|    -- Crossed 6 individual pairs.
21Feb12_120552|    -- Mutated 32 individuals.
21Feb12_120940|    -- Evaluated 64 individuals.
21Feb12_120940|    Summary of generation 29:
21Feb12_120940| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_120940|-----------  ------------------  --------------------  ----------
21Feb12_120940|    Max            40.52                14.00           0.54139
21Feb12_120940|    Avg            38.24                 4.33           0.02270
21Feb12_120940|    Min            25.22                 2.00           0.00000
21Feb12_120940|    Std             2.66                 4.19           0.09928
21Feb12_120940|   Best            25.22                 8.00           0.54139
21Feb12_120940|-- Generation 30 --
21Feb12_120940|    -- Crossed 6 individual pairs.
21Feb12_120940|    -- Mutated 32 individuals.
21Feb12_121326|    -- Evaluated 64 individuals.
21Feb12_121326|    Summary of generation 30:
21Feb12_121326| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_121326|-----------  ------------------  --------------------  ----------
21Feb12_121326|    Max            38.96                14.00           0.82665
21Feb12_121326|    Avg            37.92                 4.00           0.04718
21Feb12_121326|    Min            24.96                 2.00           0.00000
21Feb12_121326|    Std             3.23                 3.66           0.16315
21Feb12_121326|   Best            24.96                 8.00           0.53839
21Feb12_121326|-- Generation 31 --
21Feb12_121326|    -- Crossed 6 individual pairs.
21Feb12_121326|    -- Mutated 32 individuals.
21Feb12_121714|    -- Evaluated 64 individuals.
21Feb12_121714|    Summary of generation 31:
21Feb12_121714| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_121714|-----------  ------------------  --------------------  ----------
21Feb12_121714|    Max            39.04                14.00           0.54113
21Feb12_121714|    Avg            37.71                 4.52           0.03866
21Feb12_121714|    Min            24.87                 2.00           0.00000
21Feb12_121714|    Std             3.41                 3.83           0.12313
21Feb12_121714|   Best            24.87                 8.00           0.50393
21Feb12_121714|-- Generation 32 --
21Feb12_121714|    -- Crossed 2 individual pairs.
21Feb12_121714|    -- Mutated 32 individuals.
21Feb12_122101|    -- Evaluated 64 individuals.
21Feb12_122101|    Summary of generation 32:
21Feb12_122101| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_122101|-----------  ------------------  --------------------  ----------
21Feb12_122101|    Max            38.96                14.00           0.56214
21Feb12_122101|    Avg            37.33                 4.28           0.05888
21Feb12_122101|    Min            25.30                 2.00           0.00000
21Feb12_122101|    Std             4.02                 3.81           0.15775
21Feb12_122101|   Best            25.30                 8.00           0.48091
21Feb12_122101|Best initial individual weights
21Feb12_122101|Individual:
21Feb12_122101|-- Constant hidden layers --
21Feb12_122101|False
21Feb12_122101|Layer 0:
21Feb12_122101|-- Config --
21Feb12_122101|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122101|-- Weights --
21Feb12_122101|[[ 2.05453e-01  2.40281e-01 -7.54603e-01  7.16228e-01 -7.57650e-02
21Feb12_122101|   2.08511e-02]
21Feb12_122101| [-2.03060e-01 -7.90602e-01  9.82103e-01 -8.82175e-01 -6.14685e-01
21Feb12_122101|   2.20016e-01]
21Feb12_122101| [-3.07831e-01 -2.84194e-01  5.21180e-01  2.03421e-02  6.17902e-01
21Feb12_122101|   1.20319e-01]
21Feb12_122101| [-3.22398e-01  9.94485e-01 -9.69271e-01  7.06681e-01  6.70556e-01
21Feb12_122101|   3.59215e-01]
21Feb12_122101| [ 3.00717e-01 -4.35732e-01  6.70899e-01  2.20914e-01  6.12131e-01
21Feb12_122101|   8.97200e-01]
21Feb12_122101| [-2.95959e-01  3.53135e-01 -2.74368e-01 -9.35870e-02  9.90778e-01
21Feb12_122101|   3.89516e-01]
21Feb12_122101| [-8.83311e-01 -8.52944e-03  2.43365e-01 -6.27401e-01  6.85372e-01
21Feb12_122101|  -2.72216e-01]
21Feb12_122101| [ 7.64435e-01  9.08194e-01  1.58142e-01  9.13629e-01 -1.48384e-02
21Feb12_122101|   6.05382e-01]
21Feb12_122101| [ 9.85575e-01  7.29938e-02  7.56451e-01  2.33183e-01  3.58583e-01
21Feb12_122101|   2.32468e-01]
21Feb12_122101| [ 5.60964e-01  3.04390e-01 -7.31761e-01  9.54175e-01 -5.45522e-01
21Feb12_122101|   3.18286e-01]
21Feb12_122101| [ 8.26429e-01 -1.00531e-01 -9.01894e-02 -5.83139e-01 -6.88457e-02
21Feb12_122101|  -2.49506e-01]
21Feb12_122101| [-9.41787e-01  9.81853e-01 -4.81411e-01  9.76769e-01 -2.34769e-01
21Feb12_122101|   1.55017e-01]
21Feb12_122101| [ 2.68918e-01  2.72488e-01  8.66892e-01 -6.83203e-01  1.07056e-01
21Feb12_122101|   7.73257e-01]
21Feb12_122101| [-7.45481e-01 -5.53253e-01 -1.24204e-01  4.32756e-01  7.70491e-01
21Feb12_122101|   8.97188e-01]
21Feb12_122101| [-7.01585e-02 -6.41040e-01 -2.29809e-01 -1.74012e-01  1.85937e-01
21Feb12_122101|  -5.39251e-01]
21Feb12_122101| [ 2.98936e-01 -2.24555e-01  3.88811e-02  1.34617e-01 -6.09751e-01
21Feb12_122101|   6.68858e-01]
21Feb12_122101| [-3.41917e-01 -4.98518e-01  7.03936e-01 -6.81198e-01  5.09803e-02
21Feb12_122101|   5.78854e-01]
21Feb12_122101| [-5.82400e-01  9.78389e-01 -1.88321e-01  2.48687e-01  8.54196e-01
21Feb12_122101|   9.11317e-01]
21Feb12_122101| [-8.28451e-01 -2.43926e-01  9.76970e-01 -4.22840e-01  2.62790e-01
21Feb12_122101|  -4.78129e-02]
21Feb12_122101| [-7.37828e-01  2.67156e-01  7.48375e-01 -8.51984e-02 -8.01038e-01
21Feb12_122101|   8.78378e-01]
21Feb12_122101| [ 3.57454e-01  3.97925e-01  8.10639e-04 -5.33179e-01  2.40777e-01
21Feb12_122101|  -5.04065e-01]
21Feb12_122101| [ 9.05701e-02  7.55374e-01 -4.51562e-01  2.57692e-01 -9.85221e-01
21Feb12_122101|  -9.25115e-02]
21Feb12_122101| [ 9.16715e-01 -4.83419e-01 -3.00433e-01  9.54487e-01  7.18822e-01
21Feb12_122101|   2.58820e-01]
21Feb12_122101| [-7.52101e-01 -9.88134e-01  5.91929e-01  7.33580e-01  2.11599e-01
21Feb12_122101|  -7.11706e-01]
21Feb12_122101| [-5.62645e-01  4.59268e-01  3.71560e-01  8.28584e-01 -6.51797e-01
21Feb12_122101|   5.76989e-01]
21Feb12_122101| [-5.15820e-01  4.60086e-01 -7.44685e-01  7.23130e-01 -1.43834e-02
21Feb12_122101|   7.29971e-01]
21Feb12_122101| [ 8.58676e-01 -8.63098e-01 -4.01233e-01 -8.27818e-01 -7.06831e-01
21Feb12_122101|   8.58721e-01]
21Feb12_122101| [ 3.60389e-01  9.27617e-01  1.00214e-02 -1.78040e-01 -9.86467e-01
21Feb12_122101|  -1.21538e-01]
21Feb12_122101| [ 9.45951e-01 -9.86985e-01  4.33716e-01  4.62007e-01 -2.19586e-01
21Feb12_122101|  -2.30755e-01]
21Feb12_122101| [-5.09225e-01 -3.17668e-01 -3.58626e-01  9.20066e-01 -3.91723e-01
21Feb12_122101|  -1.07046e-01]
21Feb12_122101| [ 8.48771e-01 -4.36887e-01  8.72485e-01 -9.49147e-01 -9.42630e-01
21Feb12_122101|   2.62531e-01]
21Feb12_122101| [-1.97704e-01  9.40576e-01 -5.87429e-01 -4.55889e-01  1.16224e-01
21Feb12_122101|  -1.45974e-01]
21Feb12_122101| [ 2.78042e-01  8.90041e-01  3.54504e-01  1.76955e-01  8.76801e-01
21Feb12_122101|  -4.48610e-01]
21Feb12_122101| [ 7.02530e-01 -5.98662e-03 -2.74664e-01 -4.36310e-01  9.41656e-01
21Feb12_122101|   1.68841e-01]
21Feb12_122101| [ 3.18705e-01 -9.86809e-01 -8.73820e-01  3.12904e-01 -3.29772e-01
21Feb12_122101|   7.56181e-01]
21Feb12_122101| [-1.57971e-01 -8.24696e-01  5.34725e-01  8.38160e-01 -5.16749e-01
21Feb12_122101|   2.36025e-01]
21Feb12_122101| [-2.11981e-01  3.23506e-01  6.64217e-01 -8.87489e-02  9.38967e-01
21Feb12_122101|   5.68705e-02]
21Feb12_122101| [-3.07697e-01  5.12924e-01 -2.31436e-01 -4.76066e-01 -2.33871e-01
21Feb12_122101|   2.94128e-01]
21Feb12_122101| [-6.76016e-01 -4.75290e-01  9.77898e-01  2.24810e-01  3.55045e-01
21Feb12_122101|  -4.49541e-01]
21Feb12_122101| [ 7.88949e-02 -4.04072e-01 -4.11516e-01 -4.02284e-01  2.42905e-01
21Feb12_122101|  -4.76482e-01]
21Feb12_122101| [-1.58774e-01  7.29435e-01  6.36086e-01 -8.71596e-01  3.95791e-01
21Feb12_122101|   1.69866e-01]
21Feb12_122101| [-2.71198e-01 -2.86129e-01  5.96988e-01  1.37675e-01  3.05343e-01
21Feb12_122101|  -1.48690e-01]
21Feb12_122101| [ 4.44679e-02  7.97139e-01 -3.38467e-01  5.36430e-01 -3.25996e-02
21Feb12_122101|  -7.66236e-01]
21Feb12_122101| [-3.97485e-01 -4.38782e-01 -2.56226e-01 -8.05937e-01  4.67706e-01
21Feb12_122101|  -4.73571e-01]
21Feb12_122101| [-8.12576e-01 -7.88954e-01 -8.23676e-01 -6.96511e-01 -9.15567e-01
21Feb12_122101|   2.93278e-01]
21Feb12_122101| [-2.56317e-01 -3.86742e-01  4.11186e-01 -9.71835e-01 -6.83767e-01
21Feb12_122101|  -6.17732e-01]
21Feb12_122101| [ 1.65672e-01  4.58718e-01  9.12074e-01 -1.61814e-01  2.49346e-01
21Feb12_122101|   1.43828e-02]
21Feb12_122101| [-5.56934e-01 -9.24008e-01  3.75689e-02 -1.14099e-01 -6.40632e-02
21Feb12_122101|  -1.80178e-01]
21Feb12_122101| [ 2.06897e-01  5.07664e-01  6.96980e-01 -6.81197e-01  7.04958e-01
21Feb12_122101|   2.09232e-02]
21Feb12_122101| [-5.38630e-02 -3.04470e-01  4.84457e-02  8.92214e-01  3.97532e-01
21Feb12_122101|   3.42008e-01]
21Feb12_122101| [-1.67492e-01  8.62670e-01 -1.71900e-01  9.57978e-01 -7.10748e-01
21Feb12_122101|  -5.61818e-03]
21Feb12_122101| [ 8.28472e-01 -4.95210e-02 -7.78317e-01  1.34853e-01  4.89439e-01
21Feb12_122101|   1.76648e-01]
21Feb12_122101| [-4.02844e-01 -2.70205e-01  9.61545e-01 -3.77396e-01 -9.57623e-01
21Feb12_122101|   9.82526e-01]
21Feb12_122101| [ 9.15300e-01  7.74874e-01  5.09634e-01 -7.83800e-01  3.08488e-01
21Feb12_122101|   3.21057e-01]
21Feb12_122101| [ 2.68569e-01  7.96609e-01  4.05142e-01 -6.69766e-01 -9.06985e-01
21Feb12_122101|   1.50499e-01]
21Feb12_122101| [ 7.18530e-02  9.86427e-01  7.32232e-01  8.45162e-01 -8.50260e-02
21Feb12_122101|  -6.09453e-01]
21Feb12_122101| [ 8.33609e-01 -8.99869e-01  3.37351e-01  3.26977e-01  5.74522e-01
21Feb12_122101|  -6.09782e-01]]
21Feb12_122101|-- Bias --
21Feb12_122101|[ 0.54133 -0.24016 -0.62185 -0.09939  0.73356  0.26252]
21Feb12_122101|Layer 1:
21Feb12_122101|-- Config --
21Feb12_122101|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122101|-- Weights --
21Feb12_122101|[[ 0.24724 -0.61686]
21Feb12_122101| [-0.45397  0.69474]
21Feb12_122101| [-0.50014 -0.49302]
21Feb12_122101| [-0.87028  0.91722]
21Feb12_122101| [ 0.99055  0.20154]
21Feb12_122101| [ 0.01615 -0.17764]]
21Feb12_122101|-- Bias --
21Feb12_122101|[-0.71594 -0.78011]
21Feb12_122101|Predicting the validation and test data with the Best initial individual.
21Feb12_122108| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_122108|-----------  ------------------  --------------------  ----------
21Feb12_122108|Validation         38.78                  6             0.00000
21Feb12_122108|   Test            39.10                  6             0.00000
21Feb12_122108|-------------------- Test #0 --------------------
21Feb12_122108|Best final individual weights
21Feb12_122108|Individual:
21Feb12_122108|-- Constant hidden layers --
21Feb12_122108|False
21Feb12_122108|Layer 0:
21Feb12_122108|-- Config --
21Feb12_122108|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122108|-- Weights --
21Feb12_122108|[[ 0.54269  0.51745]
21Feb12_122108| [ 0.78114 -0.02898]
21Feb12_122108| [ 0.42664  0.87820]
21Feb12_122108| [ 1.85692  1.00930]
21Feb12_122108| [-0.36428 -0.48201]
21Feb12_122108| [ 0.54257  0.40133]
21Feb12_122108| [ 0.37987  0.92260]
21Feb12_122108| [-0.97562  0.87485]
21Feb12_122108| [ 0.48492 -0.23554]
21Feb12_122108| [-0.02288  1.99097]
21Feb12_122108| [ 0.22312 -0.49929]
21Feb12_122108| [ 0.68677 -0.78589]
21Feb12_122108| [-0.64122 -1.02198]
21Feb12_122108| [ 0.97663 -0.19794]
21Feb12_122108| [ 1.11202 -0.74660]
21Feb12_122108| [ 0.01647  0.19142]
21Feb12_122108| [-0.26626 -1.74040]
21Feb12_122108| [ 0.89390 -1.94504]
21Feb12_122108| [-2.08531  0.76000]
21Feb12_122108| [-0.18604  0.05780]
21Feb12_122108| [-2.08234 -1.73501]
21Feb12_122108| [ 0.04846  0.89203]
21Feb12_122108| [ 1.43956 -0.85473]
21Feb12_122108| [ 0.28847 -0.31479]
21Feb12_122108| [-1.08681 -0.19438]
21Feb12_122108| [-0.53087  0.12354]
21Feb12_122108| [-0.56659  0.07287]
21Feb12_122108| [ 0.43632  0.61482]
21Feb12_122108| [-0.35397 -0.35099]
21Feb12_122108| [ 0.89931 -1.13776]
21Feb12_122108| [ 0.21615  0.57464]
21Feb12_122108| [-0.83112 -0.25842]
21Feb12_122108| [-1.85057 -0.01704]
21Feb12_122108| [-0.23908 -1.01627]
21Feb12_122108| [-1.85263  0.15697]
21Feb12_122108| [-0.43090  2.29957]
21Feb12_122108| [ 1.14946 -1.26716]
21Feb12_122108| [-0.89750 -2.21506]
21Feb12_122108| [-1.29923  0.73287]
21Feb12_122108| [-0.48238 -0.38642]
21Feb12_122108| [ 0.32489  0.44316]
21Feb12_122108| [ 0.52012 -0.36925]
21Feb12_122108| [-2.74548 -0.25594]
21Feb12_122108| [-0.84227 -0.05914]
21Feb12_122108| [-0.37258 -0.55981]
21Feb12_122108| [-0.46020 -0.43090]
21Feb12_122108| [-1.50862  1.34654]
21Feb12_122108| [ 0.86416  0.10203]
21Feb12_122108| [ 0.67670 -0.43189]
21Feb12_122108| [-0.04188 -0.59892]
21Feb12_122108| [-0.66711  0.05767]
21Feb12_122108| [ 0.35540  0.28841]
21Feb12_122108| [ 0.86502 -1.28510]
21Feb12_122108| [-0.43590  1.17894]
21Feb12_122108| [-1.29418  1.20010]
21Feb12_122108| [ 0.24850  1.02727]
21Feb12_122108| [-0.89739 -0.02376]]
21Feb12_122108|-- Bias --
21Feb12_122108|[ 1.04304 -0.72724]
21Feb12_122108|Layer 1:
21Feb12_122108|-- Config --
21Feb12_122108|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122108|-- Weights --
21Feb12_122108|[[-0.43766  0.46756]
21Feb12_122108| [ 0.28013 -0.84945]]
21Feb12_122108|-- Bias --
21Feb12_122108|[ 0.63986 -0.69735]
21Feb12_122108|Layer 2:
21Feb12_122108|-- Config --
21Feb12_122108|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122108|-- Weights --
21Feb12_122108|[[ 0.10104 -0.15548]
21Feb12_122108| [ 1.53171 -1.52201]]
21Feb12_122108|-- Bias --
21Feb12_122108|[-0.11042 -0.11664]
21Feb12_122108|Predicting the validation and test data with the Best final individual.
21Feb12_122115| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_122115|-----------  ------------------  --------------------  ----------
21Feb12_122115|Validation         25.65                  8             0.52873
21Feb12_122115|   Test            30.41                  8             0.30067
21Feb12_122115|-------------------- Test #1 --------------------
21Feb12_122115|Best final individual weights
21Feb12_122115|Individual:
21Feb12_122115|-- Constant hidden layers --
21Feb12_122115|False
21Feb12_122115|Layer 0:
21Feb12_122115|-- Config --
21Feb12_122115|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122115|-- Weights --
21Feb12_122115|[[ 0.54269  0.51745]
21Feb12_122115| [ 0.78114 -0.02898]
21Feb12_122115| [ 0.42664  0.87820]
21Feb12_122115| [ 1.85692  1.00930]
21Feb12_122115| [-0.36428 -0.48201]
21Feb12_122115| [ 0.54257  0.40133]
21Feb12_122115| [ 0.37987  0.92260]
21Feb12_122115| [-0.97562  0.87485]
21Feb12_122115| [ 0.48492 -0.23554]
21Feb12_122115| [-0.02288  1.99097]
21Feb12_122115| [ 0.22312 -0.49929]
21Feb12_122115| [ 0.68677 -0.78589]
21Feb12_122115| [-0.64122 -1.02198]
21Feb12_122115| [ 0.97663 -0.19794]
21Feb12_122115| [ 1.11202 -0.74660]
21Feb12_122115| [ 0.01647  0.19142]
21Feb12_122115| [-0.26626 -1.74040]
21Feb12_122115| [ 0.89390 -1.94504]
21Feb12_122115| [-2.08531  0.76000]
21Feb12_122115| [-0.18604  0.05780]
21Feb12_122115| [-2.08234 -1.73501]
21Feb12_122115| [ 0.04846  0.89203]
21Feb12_122115| [ 1.43956 -0.85473]
21Feb12_122115| [ 0.28847 -0.31479]
21Feb12_122115| [-1.08681 -0.19438]
21Feb12_122115| [-0.53087  0.12354]
21Feb12_122115| [-0.56659  0.07287]
21Feb12_122115| [ 0.43632  0.61482]
21Feb12_122115| [-0.35397 -0.35099]
21Feb12_122115| [ 0.89931 -1.13776]
21Feb12_122115| [ 0.21615  0.57464]
21Feb12_122115| [-0.83112 -0.25842]
21Feb12_122115| [-1.85057 -0.01704]
21Feb12_122115| [-0.23908 -1.01627]
21Feb12_122115| [-1.85263  0.15697]
21Feb12_122115| [-0.43090  2.29957]
21Feb12_122115| [ 1.14946 -1.26716]
21Feb12_122115| [-0.89750 -2.21506]
21Feb12_122115| [-1.29923  0.73287]
21Feb12_122115| [-0.48238 -0.38642]
21Feb12_122115| [ 0.32489  0.44316]
21Feb12_122115| [ 0.52012 -0.36925]
21Feb12_122115| [-2.74548 -0.25594]
21Feb12_122115| [-0.84227 -0.05914]
21Feb12_122115| [-0.37258 -0.55981]
21Feb12_122115| [-0.46020 -0.43090]
21Feb12_122115| [-1.50862  1.34654]
21Feb12_122115| [ 0.86416  0.10203]
21Feb12_122115| [ 0.67670 -0.43189]
21Feb12_122115| [-0.04188 -0.59892]
21Feb12_122115| [-0.66711  0.05767]
21Feb12_122115| [ 0.35540  0.28841]
21Feb12_122115| [ 0.86502 -1.28510]
21Feb12_122115| [-0.43590  1.17894]
21Feb12_122115| [-1.29418  1.20010]
21Feb12_122115| [ 0.24850  1.02727]
21Feb12_122115| [-0.89739 -0.02376]]
21Feb12_122115|-- Bias --
21Feb12_122115|[ 1.04304 -0.72724]
21Feb12_122115|Layer 1:
21Feb12_122115|-- Config --
21Feb12_122115|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122115|-- Weights --
21Feb12_122115|[[-0.43766  0.46756]
21Feb12_122115| [ 0.28013 -0.84945]]
21Feb12_122115|-- Bias --
21Feb12_122115|[ 0.63986 -0.69735]
21Feb12_122115|Layer 2:
21Feb12_122115|-- Config --
21Feb12_122115|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122115|-- Weights --
21Feb12_122115|[[ 0.10104 -0.15548]
21Feb12_122115| [ 1.53171 -1.52201]]
21Feb12_122115|-- Bias --
21Feb12_122115|[-0.11042 -0.11664]
21Feb12_122115|Predicting the validation and test data with the Best final individual.
21Feb12_122122| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_122122|-----------  ------------------  --------------------  ----------
21Feb12_122122|Validation         28.17                  8             0.36045
21Feb12_122122|   Test            27.11                  8             0.57541
21Feb12_122122|-------------------- Test #2 --------------------
21Feb12_122122|Best final individual weights
21Feb12_122122|Individual:
21Feb12_122122|-- Constant hidden layers --
21Feb12_122122|False
21Feb12_122122|Layer 0:
21Feb12_122122|-- Config --
21Feb12_122122|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122122|-- Weights --
21Feb12_122122|[[ 0.54269  0.51745]
21Feb12_122122| [ 0.78114 -0.02898]
21Feb12_122122| [ 0.42664  0.87820]
21Feb12_122122| [ 1.85692  1.00930]
21Feb12_122122| [-0.36428 -0.48201]
21Feb12_122122| [ 0.54257  0.40133]
21Feb12_122122| [ 0.37987  0.92260]
21Feb12_122122| [-0.97562  0.87485]
21Feb12_122122| [ 0.48492 -0.23554]
21Feb12_122122| [-0.02288  1.99097]
21Feb12_122122| [ 0.22312 -0.49929]
21Feb12_122122| [ 0.68677 -0.78589]
21Feb12_122122| [-0.64122 -1.02198]
21Feb12_122122| [ 0.97663 -0.19794]
21Feb12_122122| [ 1.11202 -0.74660]
21Feb12_122122| [ 0.01647  0.19142]
21Feb12_122122| [-0.26626 -1.74040]
21Feb12_122122| [ 0.89390 -1.94504]
21Feb12_122122| [-2.08531  0.76000]
21Feb12_122122| [-0.18604  0.05780]
21Feb12_122122| [-2.08234 -1.73501]
21Feb12_122122| [ 0.04846  0.89203]
21Feb12_122122| [ 1.43956 -0.85473]
21Feb12_122122| [ 0.28847 -0.31479]
21Feb12_122122| [-1.08681 -0.19438]
21Feb12_122122| [-0.53087  0.12354]
21Feb12_122122| [-0.56659  0.07287]
21Feb12_122122| [ 0.43632  0.61482]
21Feb12_122122| [-0.35397 -0.35099]
21Feb12_122122| [ 0.89931 -1.13776]
21Feb12_122122| [ 0.21615  0.57464]
21Feb12_122122| [-0.83112 -0.25842]
21Feb12_122122| [-1.85057 -0.01704]
21Feb12_122122| [-0.23908 -1.01627]
21Feb12_122122| [-1.85263  0.15697]
21Feb12_122122| [-0.43090  2.29957]
21Feb12_122122| [ 1.14946 -1.26716]
21Feb12_122122| [-0.89750 -2.21506]
21Feb12_122122| [-1.29923  0.73287]
21Feb12_122122| [-0.48238 -0.38642]
21Feb12_122122| [ 0.32489  0.44316]
21Feb12_122122| [ 0.52012 -0.36925]
21Feb12_122122| [-2.74548 -0.25594]
21Feb12_122122| [-0.84227 -0.05914]
21Feb12_122122| [-0.37258 -0.55981]
21Feb12_122122| [-0.46020 -0.43090]
21Feb12_122122| [-1.50862  1.34654]
21Feb12_122122| [ 0.86416  0.10203]
21Feb12_122122| [ 0.67670 -0.43189]
21Feb12_122122| [-0.04188 -0.59892]
21Feb12_122122| [-0.66711  0.05767]
21Feb12_122122| [ 0.35540  0.28841]
21Feb12_122122| [ 0.86502 -1.28510]
21Feb12_122122| [-0.43590  1.17894]
21Feb12_122122| [-1.29418  1.20010]
21Feb12_122122| [ 0.24850  1.02727]
21Feb12_122122| [-0.89739 -0.02376]]
21Feb12_122122|-- Bias --
21Feb12_122122|[ 1.04304 -0.72724]
21Feb12_122122|Layer 1:
21Feb12_122122|-- Config --
21Feb12_122122|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122122|-- Weights --
21Feb12_122122|[[-0.43766  0.46756]
21Feb12_122122| [ 0.28013 -0.84945]]
21Feb12_122122|-- Bias --
21Feb12_122122|[ 0.63986 -0.69735]
21Feb12_122122|Layer 2:
21Feb12_122122|-- Config --
21Feb12_122122|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122122|-- Weights --
21Feb12_122122|[[ 0.10104 -0.15548]
21Feb12_122122| [ 1.53171 -1.52201]]
21Feb12_122122|-- Bias --
21Feb12_122122|[-0.11042 -0.11664]
21Feb12_122122|Predicting the validation and test data with the Best final individual.
21Feb12_122129| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_122129|-----------  ------------------  --------------------  ----------
21Feb12_122129|Validation         25.39                  8             0.56321
21Feb12_122129|   Test            25.89                  8             0.55372
21Feb12_122129|-------------------- Test #3 --------------------
21Feb12_122129|Best final individual weights
21Feb12_122129|Individual:
21Feb12_122129|-- Constant hidden layers --
21Feb12_122129|False
21Feb12_122129|Layer 0:
21Feb12_122129|-- Config --
21Feb12_122129|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122129|-- Weights --
21Feb12_122129|[[ 0.54269  0.51745]
21Feb12_122129| [ 0.78114 -0.02898]
21Feb12_122129| [ 0.42664  0.87820]
21Feb12_122129| [ 1.85692  1.00930]
21Feb12_122129| [-0.36428 -0.48201]
21Feb12_122129| [ 0.54257  0.40133]
21Feb12_122129| [ 0.37987  0.92260]
21Feb12_122129| [-0.97562  0.87485]
21Feb12_122129| [ 0.48492 -0.23554]
21Feb12_122129| [-0.02288  1.99097]
21Feb12_122129| [ 0.22312 -0.49929]
21Feb12_122129| [ 0.68677 -0.78589]
21Feb12_122129| [-0.64122 -1.02198]
21Feb12_122129| [ 0.97663 -0.19794]
21Feb12_122129| [ 1.11202 -0.74660]
21Feb12_122129| [ 0.01647  0.19142]
21Feb12_122129| [-0.26626 -1.74040]
21Feb12_122129| [ 0.89390 -1.94504]
21Feb12_122129| [-2.08531  0.76000]
21Feb12_122129| [-0.18604  0.05780]
21Feb12_122129| [-2.08234 -1.73501]
21Feb12_122129| [ 0.04846  0.89203]
21Feb12_122129| [ 1.43956 -0.85473]
21Feb12_122129| [ 0.28847 -0.31479]
21Feb12_122129| [-1.08681 -0.19438]
21Feb12_122129| [-0.53087  0.12354]
21Feb12_122129| [-0.56659  0.07287]
21Feb12_122129| [ 0.43632  0.61482]
21Feb12_122129| [-0.35397 -0.35099]
21Feb12_122129| [ 0.89931 -1.13776]
21Feb12_122129| [ 0.21615  0.57464]
21Feb12_122129| [-0.83112 -0.25842]
21Feb12_122129| [-1.85057 -0.01704]
21Feb12_122129| [-0.23908 -1.01627]
21Feb12_122129| [-1.85263  0.15697]
21Feb12_122129| [-0.43090  2.29957]
21Feb12_122129| [ 1.14946 -1.26716]
21Feb12_122129| [-0.89750 -2.21506]
21Feb12_122129| [-1.29923  0.73287]
21Feb12_122129| [-0.48238 -0.38642]
21Feb12_122129| [ 0.32489  0.44316]
21Feb12_122129| [ 0.52012 -0.36925]
21Feb12_122129| [-2.74548 -0.25594]
21Feb12_122129| [-0.84227 -0.05914]
21Feb12_122129| [-0.37258 -0.55981]
21Feb12_122129| [-0.46020 -0.43090]
21Feb12_122129| [-1.50862  1.34654]
21Feb12_122129| [ 0.86416  0.10203]
21Feb12_122129| [ 0.67670 -0.43189]
21Feb12_122129| [-0.04188 -0.59892]
21Feb12_122129| [-0.66711  0.05767]
21Feb12_122129| [ 0.35540  0.28841]
21Feb12_122129| [ 0.86502 -1.28510]
21Feb12_122129| [-0.43590  1.17894]
21Feb12_122129| [-1.29418  1.20010]
21Feb12_122129| [ 0.24850  1.02727]
21Feb12_122129| [-0.89739 -0.02376]]
21Feb12_122129|-- Bias --
21Feb12_122129|[ 1.04304 -0.72724]
21Feb12_122129|Layer 1:
21Feb12_122129|-- Config --
21Feb12_122129|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122129|-- Weights --
21Feb12_122129|[[-0.43766  0.46756]
21Feb12_122129| [ 0.28013 -0.84945]]
21Feb12_122129|-- Bias --
21Feb12_122129|[ 0.63986 -0.69735]
21Feb12_122129|Layer 2:
21Feb12_122129|-- Config --
21Feb12_122129|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122129|-- Weights --
21Feb12_122129|[[ 0.10104 -0.15548]
21Feb12_122129| [ 1.53171 -1.52201]]
21Feb12_122129|-- Bias --
21Feb12_122129|[-0.11042 -0.11664]
21Feb12_122129|Predicting the validation and test data with the Best final individual.
21Feb12_122137| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_122137|-----------  ------------------  --------------------  ----------
21Feb12_122137|Validation         26.43                  8             0.43095
21Feb12_122137|   Test            26.06                  8             0.50798
21Feb12_122137|-------------------- Test #4 --------------------
21Feb12_122137|Best final individual weights
21Feb12_122137|Individual:
21Feb12_122137|-- Constant hidden layers --
21Feb12_122137|False
21Feb12_122137|Layer 0:
21Feb12_122137|-- Config --
21Feb12_122137|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122137|-- Weights --
21Feb12_122137|[[ 0.54269  0.51745]
21Feb12_122137| [ 0.78114 -0.02898]
21Feb12_122137| [ 0.42664  0.87820]
21Feb12_122137| [ 1.85692  1.00930]
21Feb12_122137| [-0.36428 -0.48201]
21Feb12_122137| [ 0.54257  0.40133]
21Feb12_122137| [ 0.37987  0.92260]
21Feb12_122137| [-0.97562  0.87485]
21Feb12_122137| [ 0.48492 -0.23554]
21Feb12_122137| [-0.02288  1.99097]
21Feb12_122137| [ 0.22312 -0.49929]
21Feb12_122137| [ 0.68677 -0.78589]
21Feb12_122137| [-0.64122 -1.02198]
21Feb12_122137| [ 0.97663 -0.19794]
21Feb12_122137| [ 1.11202 -0.74660]
21Feb12_122137| [ 0.01647  0.19142]
21Feb12_122137| [-0.26626 -1.74040]
21Feb12_122137| [ 0.89390 -1.94504]
21Feb12_122137| [-2.08531  0.76000]
21Feb12_122137| [-0.18604  0.05780]
21Feb12_122137| [-2.08234 -1.73501]
21Feb12_122137| [ 0.04846  0.89203]
21Feb12_122137| [ 1.43956 -0.85473]
21Feb12_122137| [ 0.28847 -0.31479]
21Feb12_122137| [-1.08681 -0.19438]
21Feb12_122137| [-0.53087  0.12354]
21Feb12_122137| [-0.56659  0.07287]
21Feb12_122137| [ 0.43632  0.61482]
21Feb12_122137| [-0.35397 -0.35099]
21Feb12_122137| [ 0.89931 -1.13776]
21Feb12_122137| [ 0.21615  0.57464]
21Feb12_122137| [-0.83112 -0.25842]
21Feb12_122137| [-1.85057 -0.01704]
21Feb12_122137| [-0.23908 -1.01627]
21Feb12_122137| [-1.85263  0.15697]
21Feb12_122137| [-0.43090  2.29957]
21Feb12_122137| [ 1.14946 -1.26716]
21Feb12_122137| [-0.89750 -2.21506]
21Feb12_122137| [-1.29923  0.73287]
21Feb12_122137| [-0.48238 -0.38642]
21Feb12_122137| [ 0.32489  0.44316]
21Feb12_122137| [ 0.52012 -0.36925]
21Feb12_122137| [-2.74548 -0.25594]
21Feb12_122137| [-0.84227 -0.05914]
21Feb12_122137| [-0.37258 -0.55981]
21Feb12_122137| [-0.46020 -0.43090]
21Feb12_122137| [-1.50862  1.34654]
21Feb12_122137| [ 0.86416  0.10203]
21Feb12_122137| [ 0.67670 -0.43189]
21Feb12_122137| [-0.04188 -0.59892]
21Feb12_122137| [-0.66711  0.05767]
21Feb12_122137| [ 0.35540  0.28841]
21Feb12_122137| [ 0.86502 -1.28510]
21Feb12_122137| [-0.43590  1.17894]
21Feb12_122137| [-1.29418  1.20010]
21Feb12_122137| [ 0.24850  1.02727]
21Feb12_122137| [-0.89739 -0.02376]]
21Feb12_122137|-- Bias --
21Feb12_122137|[ 1.04304 -0.72724]
21Feb12_122137|Layer 1:
21Feb12_122137|-- Config --
21Feb12_122137|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122137|-- Weights --
21Feb12_122137|[[-0.43766  0.46756]
21Feb12_122137| [ 0.28013 -0.84945]]
21Feb12_122137|-- Bias --
21Feb12_122137|[ 0.63986 -0.69735]
21Feb12_122137|Layer 2:
21Feb12_122137|-- Config --
21Feb12_122137|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122137|-- Weights --
21Feb12_122137|[[ 0.10104 -0.15548]
21Feb12_122137| [ 1.53171 -1.52201]]
21Feb12_122137|-- Bias --
21Feb12_122137|[-0.11042 -0.11664]
21Feb12_122137|Predicting the validation and test data with the Best final individual.
21Feb12_122144| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_122144|-----------  ------------------  --------------------  ----------
21Feb12_122144|Validation         26.43                  8             0.45771
21Feb12_122144|   Test            39.01                  8             0.00000
21Feb12_122144|-------------------- Test #5 --------------------
21Feb12_122144|Best final individual weights
21Feb12_122144|Individual:
21Feb12_122144|-- Constant hidden layers --
21Feb12_122144|False
21Feb12_122144|Layer 0:
21Feb12_122144|-- Config --
21Feb12_122144|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122144|-- Weights --
21Feb12_122144|[[ 0.54269  0.51745]
21Feb12_122144| [ 0.78114 -0.02898]
21Feb12_122144| [ 0.42664  0.87820]
21Feb12_122144| [ 1.85692  1.00930]
21Feb12_122144| [-0.36428 -0.48201]
21Feb12_122144| [ 0.54257  0.40133]
21Feb12_122144| [ 0.37987  0.92260]
21Feb12_122144| [-0.97562  0.87485]
21Feb12_122144| [ 0.48492 -0.23554]
21Feb12_122144| [-0.02288  1.99097]
21Feb12_122144| [ 0.22312 -0.49929]
21Feb12_122144| [ 0.68677 -0.78589]
21Feb12_122144| [-0.64122 -1.02198]
21Feb12_122144| [ 0.97663 -0.19794]
21Feb12_122144| [ 1.11202 -0.74660]
21Feb12_122144| [ 0.01647  0.19142]
21Feb12_122144| [-0.26626 -1.74040]
21Feb12_122144| [ 0.89390 -1.94504]
21Feb12_122144| [-2.08531  0.76000]
21Feb12_122144| [-0.18604  0.05780]
21Feb12_122144| [-2.08234 -1.73501]
21Feb12_122144| [ 0.04846  0.89203]
21Feb12_122144| [ 1.43956 -0.85473]
21Feb12_122144| [ 0.28847 -0.31479]
21Feb12_122144| [-1.08681 -0.19438]
21Feb12_122144| [-0.53087  0.12354]
21Feb12_122144| [-0.56659  0.07287]
21Feb12_122144| [ 0.43632  0.61482]
21Feb12_122144| [-0.35397 -0.35099]
21Feb12_122144| [ 0.89931 -1.13776]
21Feb12_122144| [ 0.21615  0.57464]
21Feb12_122144| [-0.83112 -0.25842]
21Feb12_122144| [-1.85057 -0.01704]
21Feb12_122144| [-0.23908 -1.01627]
21Feb12_122144| [-1.85263  0.15697]
21Feb12_122144| [-0.43090  2.29957]
21Feb12_122144| [ 1.14946 -1.26716]
21Feb12_122144| [-0.89750 -2.21506]
21Feb12_122144| [-1.29923  0.73287]
21Feb12_122144| [-0.48238 -0.38642]
21Feb12_122144| [ 0.32489  0.44316]
21Feb12_122144| [ 0.52012 -0.36925]
21Feb12_122144| [-2.74548 -0.25594]
21Feb12_122144| [-0.84227 -0.05914]
21Feb12_122144| [-0.37258 -0.55981]
21Feb12_122144| [-0.46020 -0.43090]
21Feb12_122144| [-1.50862  1.34654]
21Feb12_122144| [ 0.86416  0.10203]
21Feb12_122144| [ 0.67670 -0.43189]
21Feb12_122144| [-0.04188 -0.59892]
21Feb12_122144| [-0.66711  0.05767]
21Feb12_122144| [ 0.35540  0.28841]
21Feb12_122144| [ 0.86502 -1.28510]
21Feb12_122144| [-0.43590  1.17894]
21Feb12_122144| [-1.29418  1.20010]
21Feb12_122144| [ 0.24850  1.02727]
21Feb12_122144| [-0.89739 -0.02376]]
21Feb12_122144|-- Bias --
21Feb12_122144|[ 1.04304 -0.72724]
21Feb12_122144|Layer 1:
21Feb12_122144|-- Config --
21Feb12_122144|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122144|-- Weights --
21Feb12_122144|[[-0.43766  0.46756]
21Feb12_122144| [ 0.28013 -0.84945]]
21Feb12_122144|-- Bias --
21Feb12_122144|[ 0.63986 -0.69735]
21Feb12_122144|Layer 2:
21Feb12_122144|-- Config --
21Feb12_122144|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122144|-- Weights --
21Feb12_122144|[[ 0.10104 -0.15548]
21Feb12_122144| [ 1.53171 -1.52201]]
21Feb12_122144|-- Bias --
21Feb12_122144|[-0.11042 -0.11664]
21Feb12_122144|Predicting the validation and test data with the Best final individual.
21Feb12_122151| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_122151|-----------  ------------------  --------------------  ----------
21Feb12_122151|Validation         26.26                  8             0.62271
21Feb12_122151|   Test            26.50                  8             0.42462
21Feb12_122151|-------------------- Test #6 --------------------
21Feb12_122151|Best final individual weights
21Feb12_122151|Individual:
21Feb12_122151|-- Constant hidden layers --
21Feb12_122151|False
21Feb12_122151|Layer 0:
21Feb12_122151|-- Config --
21Feb12_122151|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122151|-- Weights --
21Feb12_122151|[[ 0.54269  0.51745]
21Feb12_122151| [ 0.78114 -0.02898]
21Feb12_122151| [ 0.42664  0.87820]
21Feb12_122151| [ 1.85692  1.00930]
21Feb12_122151| [-0.36428 -0.48201]
21Feb12_122151| [ 0.54257  0.40133]
21Feb12_122151| [ 0.37987  0.92260]
21Feb12_122151| [-0.97562  0.87485]
21Feb12_122151| [ 0.48492 -0.23554]
21Feb12_122151| [-0.02288  1.99097]
21Feb12_122151| [ 0.22312 -0.49929]
21Feb12_122151| [ 0.68677 -0.78589]
21Feb12_122151| [-0.64122 -1.02198]
21Feb12_122151| [ 0.97663 -0.19794]
21Feb12_122151| [ 1.11202 -0.74660]
21Feb12_122151| [ 0.01647  0.19142]
21Feb12_122151| [-0.26626 -1.74040]
21Feb12_122151| [ 0.89390 -1.94504]
21Feb12_122151| [-2.08531  0.76000]
21Feb12_122151| [-0.18604  0.05780]
21Feb12_122151| [-2.08234 -1.73501]
21Feb12_122151| [ 0.04846  0.89203]
21Feb12_122151| [ 1.43956 -0.85473]
21Feb12_122151| [ 0.28847 -0.31479]
21Feb12_122151| [-1.08681 -0.19438]
21Feb12_122151| [-0.53087  0.12354]
21Feb12_122151| [-0.56659  0.07287]
21Feb12_122151| [ 0.43632  0.61482]
21Feb12_122151| [-0.35397 -0.35099]
21Feb12_122151| [ 0.89931 -1.13776]
21Feb12_122151| [ 0.21615  0.57464]
21Feb12_122151| [-0.83112 -0.25842]
21Feb12_122151| [-1.85057 -0.01704]
21Feb12_122151| [-0.23908 -1.01627]
21Feb12_122151| [-1.85263  0.15697]
21Feb12_122151| [-0.43090  2.29957]
21Feb12_122151| [ 1.14946 -1.26716]
21Feb12_122151| [-0.89750 -2.21506]
21Feb12_122151| [-1.29923  0.73287]
21Feb12_122151| [-0.48238 -0.38642]
21Feb12_122151| [ 0.32489  0.44316]
21Feb12_122151| [ 0.52012 -0.36925]
21Feb12_122151| [-2.74548 -0.25594]
21Feb12_122151| [-0.84227 -0.05914]
21Feb12_122151| [-0.37258 -0.55981]
21Feb12_122151| [-0.46020 -0.43090]
21Feb12_122151| [-1.50862  1.34654]
21Feb12_122151| [ 0.86416  0.10203]
21Feb12_122151| [ 0.67670 -0.43189]
21Feb12_122151| [-0.04188 -0.59892]
21Feb12_122151| [-0.66711  0.05767]
21Feb12_122151| [ 0.35540  0.28841]
21Feb12_122151| [ 0.86502 -1.28510]
21Feb12_122151| [-0.43590  1.17894]
21Feb12_122151| [-1.29418  1.20010]
21Feb12_122151| [ 0.24850  1.02727]
21Feb12_122151| [-0.89739 -0.02376]]
21Feb12_122151|-- Bias --
21Feb12_122151|[ 1.04304 -0.72724]
21Feb12_122151|Layer 1:
21Feb12_122151|-- Config --
21Feb12_122151|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122151|-- Weights --
21Feb12_122151|[[-0.43766  0.46756]
21Feb12_122151| [ 0.28013 -0.84945]]
21Feb12_122151|-- Bias --
21Feb12_122151|[ 0.63986 -0.69735]
21Feb12_122151|Layer 2:
21Feb12_122151|-- Config --
21Feb12_122151|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122151|-- Weights --
21Feb12_122151|[[ 0.10104 -0.15548]
21Feb12_122151| [ 1.53171 -1.52201]]
21Feb12_122151|-- Bias --
21Feb12_122151|[-0.11042 -0.11664]
21Feb12_122151|Predicting the validation and test data with the Best final individual.
21Feb12_122159| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_122159|-----------  ------------------  --------------------  ----------
21Feb12_122159|Validation         25.57                  8             0.58090
21Feb12_122159|   Test            26.32                  8             0.46196
21Feb12_122159|-------------------- Test #7 --------------------
21Feb12_122159|Best final individual weights
21Feb12_122159|Individual:
21Feb12_122159|-- Constant hidden layers --
21Feb12_122159|False
21Feb12_122159|Layer 0:
21Feb12_122159|-- Config --
21Feb12_122159|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122159|-- Weights --
21Feb12_122159|[[ 0.54269  0.51745]
21Feb12_122159| [ 0.78114 -0.02898]
21Feb12_122159| [ 0.42664  0.87820]
21Feb12_122159| [ 1.85692  1.00930]
21Feb12_122159| [-0.36428 -0.48201]
21Feb12_122159| [ 0.54257  0.40133]
21Feb12_122159| [ 0.37987  0.92260]
21Feb12_122159| [-0.97562  0.87485]
21Feb12_122159| [ 0.48492 -0.23554]
21Feb12_122159| [-0.02288  1.99097]
21Feb12_122159| [ 0.22312 -0.49929]
21Feb12_122159| [ 0.68677 -0.78589]
21Feb12_122159| [-0.64122 -1.02198]
21Feb12_122159| [ 0.97663 -0.19794]
21Feb12_122159| [ 1.11202 -0.74660]
21Feb12_122159| [ 0.01647  0.19142]
21Feb12_122159| [-0.26626 -1.74040]
21Feb12_122159| [ 0.89390 -1.94504]
21Feb12_122159| [-2.08531  0.76000]
21Feb12_122159| [-0.18604  0.05780]
21Feb12_122159| [-2.08234 -1.73501]
21Feb12_122159| [ 0.04846  0.89203]
21Feb12_122159| [ 1.43956 -0.85473]
21Feb12_122159| [ 0.28847 -0.31479]
21Feb12_122159| [-1.08681 -0.19438]
21Feb12_122159| [-0.53087  0.12354]
21Feb12_122159| [-0.56659  0.07287]
21Feb12_122159| [ 0.43632  0.61482]
21Feb12_122159| [-0.35397 -0.35099]
21Feb12_122159| [ 0.89931 -1.13776]
21Feb12_122159| [ 0.21615  0.57464]
21Feb12_122159| [-0.83112 -0.25842]
21Feb12_122159| [-1.85057 -0.01704]
21Feb12_122159| [-0.23908 -1.01627]
21Feb12_122159| [-1.85263  0.15697]
21Feb12_122159| [-0.43090  2.29957]
21Feb12_122159| [ 1.14946 -1.26716]
21Feb12_122159| [-0.89750 -2.21506]
21Feb12_122159| [-1.29923  0.73287]
21Feb12_122159| [-0.48238 -0.38642]
21Feb12_122159| [ 0.32489  0.44316]
21Feb12_122159| [ 0.52012 -0.36925]
21Feb12_122159| [-2.74548 -0.25594]
21Feb12_122159| [-0.84227 -0.05914]
21Feb12_122159| [-0.37258 -0.55981]
21Feb12_122159| [-0.46020 -0.43090]
21Feb12_122159| [-1.50862  1.34654]
21Feb12_122159| [ 0.86416  0.10203]
21Feb12_122159| [ 0.67670 -0.43189]
21Feb12_122159| [-0.04188 -0.59892]
21Feb12_122159| [-0.66711  0.05767]
21Feb12_122159| [ 0.35540  0.28841]
21Feb12_122159| [ 0.86502 -1.28510]
21Feb12_122159| [-0.43590  1.17894]
21Feb12_122159| [-1.29418  1.20010]
21Feb12_122159| [ 0.24850  1.02727]
21Feb12_122159| [-0.89739 -0.02376]]
21Feb12_122159|-- Bias --
21Feb12_122159|[ 1.04304 -0.72724]
21Feb12_122159|Layer 1:
21Feb12_122159|-- Config --
21Feb12_122159|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122159|-- Weights --
21Feb12_122159|[[-0.43766  0.46756]
21Feb12_122159| [ 0.28013 -0.84945]]
21Feb12_122159|-- Bias --
21Feb12_122159|[ 0.63986 -0.69735]
21Feb12_122159|Layer 2:
21Feb12_122159|-- Config --
21Feb12_122159|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122159|-- Weights --
21Feb12_122159|[[ 0.10104 -0.15548]
21Feb12_122159| [ 1.53171 -1.52201]]
21Feb12_122159|-- Bias --
21Feb12_122159|[-0.11042 -0.11664]
21Feb12_122159|Predicting the validation and test data with the Best final individual.
21Feb12_122206| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_122206|-----------  ------------------  --------------------  ----------
21Feb12_122206|Validation         25.57                  8             0.47820
21Feb12_122206|   Test            26.76                  8             0.48269
21Feb12_122206|-------------------- Test #8 --------------------
21Feb12_122206|Best final individual weights
21Feb12_122206|Individual:
21Feb12_122206|-- Constant hidden layers --
21Feb12_122206|False
21Feb12_122206|Layer 0:
21Feb12_122206|-- Config --
21Feb12_122206|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122206|-- Weights --
21Feb12_122206|[[ 0.54269  0.51745]
21Feb12_122206| [ 0.78114 -0.02898]
21Feb12_122206| [ 0.42664  0.87820]
21Feb12_122206| [ 1.85692  1.00930]
21Feb12_122206| [-0.36428 -0.48201]
21Feb12_122206| [ 0.54257  0.40133]
21Feb12_122206| [ 0.37987  0.92260]
21Feb12_122206| [-0.97562  0.87485]
21Feb12_122206| [ 0.48492 -0.23554]
21Feb12_122206| [-0.02288  1.99097]
21Feb12_122206| [ 0.22312 -0.49929]
21Feb12_122206| [ 0.68677 -0.78589]
21Feb12_122206| [-0.64122 -1.02198]
21Feb12_122206| [ 0.97663 -0.19794]
21Feb12_122206| [ 1.11202 -0.74660]
21Feb12_122206| [ 0.01647  0.19142]
21Feb12_122206| [-0.26626 -1.74040]
21Feb12_122206| [ 0.89390 -1.94504]
21Feb12_122206| [-2.08531  0.76000]
21Feb12_122206| [-0.18604  0.05780]
21Feb12_122206| [-2.08234 -1.73501]
21Feb12_122206| [ 0.04846  0.89203]
21Feb12_122206| [ 1.43956 -0.85473]
21Feb12_122206| [ 0.28847 -0.31479]
21Feb12_122206| [-1.08681 -0.19438]
21Feb12_122206| [-0.53087  0.12354]
21Feb12_122206| [-0.56659  0.07287]
21Feb12_122206| [ 0.43632  0.61482]
21Feb12_122206| [-0.35397 -0.35099]
21Feb12_122206| [ 0.89931 -1.13776]
21Feb12_122206| [ 0.21615  0.57464]
21Feb12_122206| [-0.83112 -0.25842]
21Feb12_122206| [-1.85057 -0.01704]
21Feb12_122206| [-0.23908 -1.01627]
21Feb12_122206| [-1.85263  0.15697]
21Feb12_122206| [-0.43090  2.29957]
21Feb12_122206| [ 1.14946 -1.26716]
21Feb12_122206| [-0.89750 -2.21506]
21Feb12_122206| [-1.29923  0.73287]
21Feb12_122206| [-0.48238 -0.38642]
21Feb12_122206| [ 0.32489  0.44316]
21Feb12_122206| [ 0.52012 -0.36925]
21Feb12_122206| [-2.74548 -0.25594]
21Feb12_122206| [-0.84227 -0.05914]
21Feb12_122206| [-0.37258 -0.55981]
21Feb12_122206| [-0.46020 -0.43090]
21Feb12_122206| [-1.50862  1.34654]
21Feb12_122206| [ 0.86416  0.10203]
21Feb12_122206| [ 0.67670 -0.43189]
21Feb12_122206| [-0.04188 -0.59892]
21Feb12_122206| [-0.66711  0.05767]
21Feb12_122206| [ 0.35540  0.28841]
21Feb12_122206| [ 0.86502 -1.28510]
21Feb12_122206| [-0.43590  1.17894]
21Feb12_122206| [-1.29418  1.20010]
21Feb12_122206| [ 0.24850  1.02727]
21Feb12_122206| [-0.89739 -0.02376]]
21Feb12_122206|-- Bias --
21Feb12_122206|[ 1.04304 -0.72724]
21Feb12_122206|Layer 1:
21Feb12_122206|-- Config --
21Feb12_122206|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122206|-- Weights --
21Feb12_122206|[[-0.43766  0.46756]
21Feb12_122206| [ 0.28013 -0.84945]]
21Feb12_122206|-- Bias --
21Feb12_122206|[ 0.63986 -0.69735]
21Feb12_122206|Layer 2:
21Feb12_122206|-- Config --
21Feb12_122206|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122206|-- Weights --
21Feb12_122206|[[ 0.10104 -0.15548]
21Feb12_122206| [ 1.53171 -1.52201]]
21Feb12_122206|-- Bias --
21Feb12_122206|[-0.11042 -0.11664]
21Feb12_122206|Predicting the validation and test data with the Best final individual.
21Feb12_122213| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_122213|-----------  ------------------  --------------------  ----------
21Feb12_122213|Validation         26.96                  8             0.56754
21Feb12_122213|   Test            30.50                  8             0.28906
21Feb12_122213|-------------------- Test #9 --------------------
21Feb12_122213|Best final individual weights
21Feb12_122213|Individual:
21Feb12_122213|-- Constant hidden layers --
21Feb12_122213|False
21Feb12_122213|Layer 0:
21Feb12_122213|-- Config --
21Feb12_122213|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122213|-- Weights --
21Feb12_122213|[[ 0.54269  0.51745]
21Feb12_122213| [ 0.78114 -0.02898]
21Feb12_122213| [ 0.42664  0.87820]
21Feb12_122213| [ 1.85692  1.00930]
21Feb12_122213| [-0.36428 -0.48201]
21Feb12_122213| [ 0.54257  0.40133]
21Feb12_122213| [ 0.37987  0.92260]
21Feb12_122213| [-0.97562  0.87485]
21Feb12_122213| [ 0.48492 -0.23554]
21Feb12_122213| [-0.02288  1.99097]
21Feb12_122213| [ 0.22312 -0.49929]
21Feb12_122213| [ 0.68677 -0.78589]
21Feb12_122213| [-0.64122 -1.02198]
21Feb12_122213| [ 0.97663 -0.19794]
21Feb12_122213| [ 1.11202 -0.74660]
21Feb12_122213| [ 0.01647  0.19142]
21Feb12_122213| [-0.26626 -1.74040]
21Feb12_122213| [ 0.89390 -1.94504]
21Feb12_122213| [-2.08531  0.76000]
21Feb12_122213| [-0.18604  0.05780]
21Feb12_122213| [-2.08234 -1.73501]
21Feb12_122213| [ 0.04846  0.89203]
21Feb12_122213| [ 1.43956 -0.85473]
21Feb12_122213| [ 0.28847 -0.31479]
21Feb12_122213| [-1.08681 -0.19438]
21Feb12_122213| [-0.53087  0.12354]
21Feb12_122213| [-0.56659  0.07287]
21Feb12_122213| [ 0.43632  0.61482]
21Feb12_122213| [-0.35397 -0.35099]
21Feb12_122213| [ 0.89931 -1.13776]
21Feb12_122213| [ 0.21615  0.57464]
21Feb12_122213| [-0.83112 -0.25842]
21Feb12_122213| [-1.85057 -0.01704]
21Feb12_122213| [-0.23908 -1.01627]
21Feb12_122213| [-1.85263  0.15697]
21Feb12_122213| [-0.43090  2.29957]
21Feb12_122213| [ 1.14946 -1.26716]
21Feb12_122213| [-0.89750 -2.21506]
21Feb12_122213| [-1.29923  0.73287]
21Feb12_122213| [-0.48238 -0.38642]
21Feb12_122213| [ 0.32489  0.44316]
21Feb12_122213| [ 0.52012 -0.36925]
21Feb12_122213| [-2.74548 -0.25594]
21Feb12_122213| [-0.84227 -0.05914]
21Feb12_122213| [-0.37258 -0.55981]
21Feb12_122213| [-0.46020 -0.43090]
21Feb12_122213| [-1.50862  1.34654]
21Feb12_122213| [ 0.86416  0.10203]
21Feb12_122213| [ 0.67670 -0.43189]
21Feb12_122213| [-0.04188 -0.59892]
21Feb12_122213| [-0.66711  0.05767]
21Feb12_122213| [ 0.35540  0.28841]
21Feb12_122213| [ 0.86502 -1.28510]
21Feb12_122213| [-0.43590  1.17894]
21Feb12_122213| [-1.29418  1.20010]
21Feb12_122213| [ 0.24850  1.02727]
21Feb12_122213| [-0.89739 -0.02376]]
21Feb12_122213|-- Bias --
21Feb12_122213|[ 1.04304 -0.72724]
21Feb12_122213|Layer 1:
21Feb12_122213|-- Config --
21Feb12_122213|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122213|-- Weights --
21Feb12_122213|[[-0.43766  0.46756]
21Feb12_122213| [ 0.28013 -0.84945]]
21Feb12_122213|-- Bias --
21Feb12_122213|[ 0.63986 -0.69735]
21Feb12_122213|Layer 2:
21Feb12_122213|-- Config --
21Feb12_122213|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122213|-- Weights --
21Feb12_122213|[[ 0.10104 -0.15548]
21Feb12_122213| [ 1.53171 -1.52201]]
21Feb12_122213|-- Bias --
21Feb12_122213|[-0.11042 -0.11664]
21Feb12_122213|Predicting the validation and test data with the Best final individual.
21Feb12_122221| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_122221|-----------  ------------------  --------------------  ----------
21Feb12_122221|Validation         24.96                  8             0.49383
21Feb12_122221|   Test            26.85                  8             0.43207
21Feb12_122221|-------------------- Test #10 --------------------
21Feb12_122221|Best final individual weights
21Feb12_122221|Individual:
21Feb12_122221|-- Constant hidden layers --
21Feb12_122221|False
21Feb12_122221|Layer 0:
21Feb12_122221|-- Config --
21Feb12_122221|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122221|-- Weights --
21Feb12_122221|[[ 0.54269  0.51745]
21Feb12_122221| [ 0.78114 -0.02898]
21Feb12_122221| [ 0.42664  0.87820]
21Feb12_122221| [ 1.85692  1.00930]
21Feb12_122221| [-0.36428 -0.48201]
21Feb12_122221| [ 0.54257  0.40133]
21Feb12_122221| [ 0.37987  0.92260]
21Feb12_122221| [-0.97562  0.87485]
21Feb12_122221| [ 0.48492 -0.23554]
21Feb12_122221| [-0.02288  1.99097]
21Feb12_122221| [ 0.22312 -0.49929]
21Feb12_122221| [ 0.68677 -0.78589]
21Feb12_122221| [-0.64122 -1.02198]
21Feb12_122221| [ 0.97663 -0.19794]
21Feb12_122221| [ 1.11202 -0.74660]
21Feb12_122221| [ 0.01647  0.19142]
21Feb12_122221| [-0.26626 -1.74040]
21Feb12_122221| [ 0.89390 -1.94504]
21Feb12_122221| [-2.08531  0.76000]
21Feb12_122221| [-0.18604  0.05780]
21Feb12_122221| [-2.08234 -1.73501]
21Feb12_122221| [ 0.04846  0.89203]
21Feb12_122221| [ 1.43956 -0.85473]
21Feb12_122221| [ 0.28847 -0.31479]
21Feb12_122221| [-1.08681 -0.19438]
21Feb12_122221| [-0.53087  0.12354]
21Feb12_122221| [-0.56659  0.07287]
21Feb12_122221| [ 0.43632  0.61482]
21Feb12_122221| [-0.35397 -0.35099]
21Feb12_122221| [ 0.89931 -1.13776]
21Feb12_122221| [ 0.21615  0.57464]
21Feb12_122221| [-0.83112 -0.25842]
21Feb12_122221| [-1.85057 -0.01704]
21Feb12_122221| [-0.23908 -1.01627]
21Feb12_122221| [-1.85263  0.15697]
21Feb12_122221| [-0.43090  2.29957]
21Feb12_122221| [ 1.14946 -1.26716]
21Feb12_122221| [-0.89750 -2.21506]
21Feb12_122221| [-1.29923  0.73287]
21Feb12_122221| [-0.48238 -0.38642]
21Feb12_122221| [ 0.32489  0.44316]
21Feb12_122221| [ 0.52012 -0.36925]
21Feb12_122221| [-2.74548 -0.25594]
21Feb12_122221| [-0.84227 -0.05914]
21Feb12_122221| [-0.37258 -0.55981]
21Feb12_122221| [-0.46020 -0.43090]
21Feb12_122221| [-1.50862  1.34654]
21Feb12_122221| [ 0.86416  0.10203]
21Feb12_122221| [ 0.67670 -0.43189]
21Feb12_122221| [-0.04188 -0.59892]
21Feb12_122221| [-0.66711  0.05767]
21Feb12_122221| [ 0.35540  0.28841]
21Feb12_122221| [ 0.86502 -1.28510]
21Feb12_122221| [-0.43590  1.17894]
21Feb12_122221| [-1.29418  1.20010]
21Feb12_122221| [ 0.24850  1.02727]
21Feb12_122221| [-0.89739 -0.02376]]
21Feb12_122221|-- Bias --
21Feb12_122221|[ 1.04304 -0.72724]
21Feb12_122221|Layer 1:
21Feb12_122221|-- Config --
21Feb12_122221|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122221|-- Weights --
21Feb12_122221|[[-0.43766  0.46756]
21Feb12_122221| [ 0.28013 -0.84945]]
21Feb12_122221|-- Bias --
21Feb12_122221|[ 0.63986 -0.69735]
21Feb12_122221|Layer 2:
21Feb12_122221|-- Config --
21Feb12_122221|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122221|-- Weights --
21Feb12_122221|[[ 0.10104 -0.15548]
21Feb12_122221| [ 1.53171 -1.52201]]
21Feb12_122221|-- Bias --
21Feb12_122221|[-0.11042 -0.11664]
21Feb12_122221|Predicting the validation and test data with the Best final individual.
21Feb12_122228| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_122228|-----------  ------------------  --------------------  ----------
21Feb12_122228|Validation         27.13                  8             0.41245
21Feb12_122228|   Test            29.80                  8             0.32665
21Feb12_122228|-------------------- Test #11 --------------------
21Feb12_122228|Best final individual weights
21Feb12_122228|Individual:
21Feb12_122228|-- Constant hidden layers --
21Feb12_122228|False
21Feb12_122228|Layer 0:
21Feb12_122228|-- Config --
21Feb12_122228|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122228|-- Weights --
21Feb12_122228|[[ 0.54269  0.51745]
21Feb12_122228| [ 0.78114 -0.02898]
21Feb12_122228| [ 0.42664  0.87820]
21Feb12_122228| [ 1.85692  1.00930]
21Feb12_122228| [-0.36428 -0.48201]
21Feb12_122228| [ 0.54257  0.40133]
21Feb12_122228| [ 0.37987  0.92260]
21Feb12_122228| [-0.97562  0.87485]
21Feb12_122228| [ 0.48492 -0.23554]
21Feb12_122228| [-0.02288  1.99097]
21Feb12_122228| [ 0.22312 -0.49929]
21Feb12_122228| [ 0.68677 -0.78589]
21Feb12_122228| [-0.64122 -1.02198]
21Feb12_122228| [ 0.97663 -0.19794]
21Feb12_122228| [ 1.11202 -0.74660]
21Feb12_122228| [ 0.01647  0.19142]
21Feb12_122228| [-0.26626 -1.74040]
21Feb12_122228| [ 0.89390 -1.94504]
21Feb12_122228| [-2.08531  0.76000]
21Feb12_122228| [-0.18604  0.05780]
21Feb12_122228| [-2.08234 -1.73501]
21Feb12_122228| [ 0.04846  0.89203]
21Feb12_122228| [ 1.43956 -0.85473]
21Feb12_122228| [ 0.28847 -0.31479]
21Feb12_122228| [-1.08681 -0.19438]
21Feb12_122228| [-0.53087  0.12354]
21Feb12_122228| [-0.56659  0.07287]
21Feb12_122228| [ 0.43632  0.61482]
21Feb12_122228| [-0.35397 -0.35099]
21Feb12_122228| [ 0.89931 -1.13776]
21Feb12_122228| [ 0.21615  0.57464]
21Feb12_122228| [-0.83112 -0.25842]
21Feb12_122228| [-1.85057 -0.01704]
21Feb12_122228| [-0.23908 -1.01627]
21Feb12_122228| [-1.85263  0.15697]
21Feb12_122228| [-0.43090  2.29957]
21Feb12_122228| [ 1.14946 -1.26716]
21Feb12_122228| [-0.89750 -2.21506]
21Feb12_122228| [-1.29923  0.73287]
21Feb12_122228| [-0.48238 -0.38642]
21Feb12_122228| [ 0.32489  0.44316]
21Feb12_122228| [ 0.52012 -0.36925]
21Feb12_122228| [-2.74548 -0.25594]
21Feb12_122228| [-0.84227 -0.05914]
21Feb12_122228| [-0.37258 -0.55981]
21Feb12_122228| [-0.46020 -0.43090]
21Feb12_122228| [-1.50862  1.34654]
21Feb12_122228| [ 0.86416  0.10203]
21Feb12_122228| [ 0.67670 -0.43189]
21Feb12_122228| [-0.04188 -0.59892]
21Feb12_122228| [-0.66711  0.05767]
21Feb12_122228| [ 0.35540  0.28841]
21Feb12_122228| [ 0.86502 -1.28510]
21Feb12_122228| [-0.43590  1.17894]
21Feb12_122228| [-1.29418  1.20010]
21Feb12_122228| [ 0.24850  1.02727]
21Feb12_122228| [-0.89739 -0.02376]]
21Feb12_122228|-- Bias --
21Feb12_122228|[ 1.04304 -0.72724]
21Feb12_122228|Layer 1:
21Feb12_122228|-- Config --
21Feb12_122228|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122228|-- Weights --
21Feb12_122228|[[-0.43766  0.46756]
21Feb12_122228| [ 0.28013 -0.84945]]
21Feb12_122228|-- Bias --
21Feb12_122228|[ 0.63986 -0.69735]
21Feb12_122228|Layer 2:
21Feb12_122228|-- Config --
21Feb12_122228|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122228|-- Weights --
21Feb12_122228|[[ 0.10104 -0.15548]
21Feb12_122228| [ 1.53171 -1.52201]]
21Feb12_122228|-- Bias --
21Feb12_122228|[-0.11042 -0.11664]
21Feb12_122228|Predicting the validation and test data with the Best final individual.
21Feb12_122235| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_122235|-----------  ------------------  --------------------  ----------
21Feb12_122235|Validation         26.00                  8             0.49486
21Feb12_122235|   Test            25.54                  8             0.53802
21Feb12_122235|-------------------- Test #12 --------------------
21Feb12_122235|Best final individual weights
21Feb12_122235|Individual:
21Feb12_122235|-- Constant hidden layers --
21Feb12_122235|False
21Feb12_122235|Layer 0:
21Feb12_122235|-- Config --
21Feb12_122235|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122235|-- Weights --
21Feb12_122235|[[ 0.54269  0.51745]
21Feb12_122235| [ 0.78114 -0.02898]
21Feb12_122235| [ 0.42664  0.87820]
21Feb12_122235| [ 1.85692  1.00930]
21Feb12_122235| [-0.36428 -0.48201]
21Feb12_122235| [ 0.54257  0.40133]
21Feb12_122235| [ 0.37987  0.92260]
21Feb12_122235| [-0.97562  0.87485]
21Feb12_122235| [ 0.48492 -0.23554]
21Feb12_122235| [-0.02288  1.99097]
21Feb12_122235| [ 0.22312 -0.49929]
21Feb12_122235| [ 0.68677 -0.78589]
21Feb12_122235| [-0.64122 -1.02198]
21Feb12_122235| [ 0.97663 -0.19794]
21Feb12_122235| [ 1.11202 -0.74660]
21Feb12_122235| [ 0.01647  0.19142]
21Feb12_122235| [-0.26626 -1.74040]
21Feb12_122235| [ 0.89390 -1.94504]
21Feb12_122235| [-2.08531  0.76000]
21Feb12_122235| [-0.18604  0.05780]
21Feb12_122235| [-2.08234 -1.73501]
21Feb12_122235| [ 0.04846  0.89203]
21Feb12_122235| [ 1.43956 -0.85473]
21Feb12_122235| [ 0.28847 -0.31479]
21Feb12_122235| [-1.08681 -0.19438]
21Feb12_122235| [-0.53087  0.12354]
21Feb12_122235| [-0.56659  0.07287]
21Feb12_122235| [ 0.43632  0.61482]
21Feb12_122235| [-0.35397 -0.35099]
21Feb12_122235| [ 0.89931 -1.13776]
21Feb12_122235| [ 0.21615  0.57464]
21Feb12_122235| [-0.83112 -0.25842]
21Feb12_122235| [-1.85057 -0.01704]
21Feb12_122235| [-0.23908 -1.01627]
21Feb12_122235| [-1.85263  0.15697]
21Feb12_122235| [-0.43090  2.29957]
21Feb12_122235| [ 1.14946 -1.26716]
21Feb12_122235| [-0.89750 -2.21506]
21Feb12_122235| [-1.29923  0.73287]
21Feb12_122235| [-0.48238 -0.38642]
21Feb12_122235| [ 0.32489  0.44316]
21Feb12_122235| [ 0.52012 -0.36925]
21Feb12_122235| [-2.74548 -0.25594]
21Feb12_122235| [-0.84227 -0.05914]
21Feb12_122235| [-0.37258 -0.55981]
21Feb12_122235| [-0.46020 -0.43090]
21Feb12_122235| [-1.50862  1.34654]
21Feb12_122235| [ 0.86416  0.10203]
21Feb12_122235| [ 0.67670 -0.43189]
21Feb12_122235| [-0.04188 -0.59892]
21Feb12_122235| [-0.66711  0.05767]
21Feb12_122235| [ 0.35540  0.28841]
21Feb12_122235| [ 0.86502 -1.28510]
21Feb12_122235| [-0.43590  1.17894]
21Feb12_122235| [-1.29418  1.20010]
21Feb12_122235| [ 0.24850  1.02727]
21Feb12_122235| [-0.89739 -0.02376]]
21Feb12_122235|-- Bias --
21Feb12_122235|[ 1.04304 -0.72724]
21Feb12_122235|Layer 1:
21Feb12_122235|-- Config --
21Feb12_122235|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122235|-- Weights --
21Feb12_122235|[[-0.43766  0.46756]
21Feb12_122235| [ 0.28013 -0.84945]]
21Feb12_122235|-- Bias --
21Feb12_122235|[ 0.63986 -0.69735]
21Feb12_122235|Layer 2:
21Feb12_122235|-- Config --
21Feb12_122235|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122235|-- Weights --
21Feb12_122235|[[ 0.10104 -0.15548]
21Feb12_122235| [ 1.53171 -1.52201]]
21Feb12_122235|-- Bias --
21Feb12_122235|[-0.11042 -0.11664]
21Feb12_122235|Predicting the validation and test data with the Best final individual.
21Feb12_122243| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_122243|-----------  ------------------  --------------------  ----------
21Feb12_122243|Validation         25.22                  8             0.54515
21Feb12_122243|   Test            28.67                  8             0.36206
21Feb12_122243|-------------------- Test #13 --------------------
21Feb12_122243|Best final individual weights
21Feb12_122243|Individual:
21Feb12_122243|-- Constant hidden layers --
21Feb12_122243|False
21Feb12_122243|Layer 0:
21Feb12_122243|-- Config --
21Feb12_122243|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122243|-- Weights --
21Feb12_122243|[[ 0.54269  0.51745]
21Feb12_122243| [ 0.78114 -0.02898]
21Feb12_122243| [ 0.42664  0.87820]
21Feb12_122243| [ 1.85692  1.00930]
21Feb12_122243| [-0.36428 -0.48201]
21Feb12_122243| [ 0.54257  0.40133]
21Feb12_122243| [ 0.37987  0.92260]
21Feb12_122243| [-0.97562  0.87485]
21Feb12_122243| [ 0.48492 -0.23554]
21Feb12_122243| [-0.02288  1.99097]
21Feb12_122243| [ 0.22312 -0.49929]
21Feb12_122243| [ 0.68677 -0.78589]
21Feb12_122243| [-0.64122 -1.02198]
21Feb12_122243| [ 0.97663 -0.19794]
21Feb12_122243| [ 1.11202 -0.74660]
21Feb12_122243| [ 0.01647  0.19142]
21Feb12_122243| [-0.26626 -1.74040]
21Feb12_122243| [ 0.89390 -1.94504]
21Feb12_122243| [-2.08531  0.76000]
21Feb12_122243| [-0.18604  0.05780]
21Feb12_122243| [-2.08234 -1.73501]
21Feb12_122243| [ 0.04846  0.89203]
21Feb12_122243| [ 1.43956 -0.85473]
21Feb12_122243| [ 0.28847 -0.31479]
21Feb12_122243| [-1.08681 -0.19438]
21Feb12_122243| [-0.53087  0.12354]
21Feb12_122243| [-0.56659  0.07287]
21Feb12_122243| [ 0.43632  0.61482]
21Feb12_122243| [-0.35397 -0.35099]
21Feb12_122243| [ 0.89931 -1.13776]
21Feb12_122243| [ 0.21615  0.57464]
21Feb12_122243| [-0.83112 -0.25842]
21Feb12_122243| [-1.85057 -0.01704]
21Feb12_122243| [-0.23908 -1.01627]
21Feb12_122243| [-1.85263  0.15697]
21Feb12_122243| [-0.43090  2.29957]
21Feb12_122243| [ 1.14946 -1.26716]
21Feb12_122243| [-0.89750 -2.21506]
21Feb12_122243| [-1.29923  0.73287]
21Feb12_122243| [-0.48238 -0.38642]
21Feb12_122243| [ 0.32489  0.44316]
21Feb12_122243| [ 0.52012 -0.36925]
21Feb12_122243| [-2.74548 -0.25594]
21Feb12_122243| [-0.84227 -0.05914]
21Feb12_122243| [-0.37258 -0.55981]
21Feb12_122243| [-0.46020 -0.43090]
21Feb12_122243| [-1.50862  1.34654]
21Feb12_122243| [ 0.86416  0.10203]
21Feb12_122243| [ 0.67670 -0.43189]
21Feb12_122243| [-0.04188 -0.59892]
21Feb12_122243| [-0.66711  0.05767]
21Feb12_122243| [ 0.35540  0.28841]
21Feb12_122243| [ 0.86502 -1.28510]
21Feb12_122243| [-0.43590  1.17894]
21Feb12_122243| [-1.29418  1.20010]
21Feb12_122243| [ 0.24850  1.02727]
21Feb12_122243| [-0.89739 -0.02376]]
21Feb12_122243|-- Bias --
21Feb12_122243|[ 1.04304 -0.72724]
21Feb12_122243|Layer 1:
21Feb12_122243|-- Config --
21Feb12_122243|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122243|-- Weights --
21Feb12_122243|[[-0.43766  0.46756]
21Feb12_122243| [ 0.28013 -0.84945]]
21Feb12_122243|-- Bias --
21Feb12_122243|[ 0.63986 -0.69735]
21Feb12_122243|Layer 2:
21Feb12_122243|-- Config --
21Feb12_122243|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122243|-- Weights --
21Feb12_122243|[[ 0.10104 -0.15548]
21Feb12_122243| [ 1.53171 -1.52201]]
21Feb12_122243|-- Bias --
21Feb12_122243|[-0.11042 -0.11664]
21Feb12_122243|Predicting the validation and test data with the Best final individual.
21Feb12_122250| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_122250|-----------  ------------------  --------------------  ----------
21Feb12_122250|Validation         25.57                  8             0.60761
21Feb12_122250|   Test            26.50                  8             0.49125
21Feb12_122250|-------------------- Test #14 --------------------
21Feb12_122250|Best final individual weights
21Feb12_122250|Individual:
21Feb12_122250|-- Constant hidden layers --
21Feb12_122250|False
21Feb12_122250|Layer 0:
21Feb12_122250|-- Config --
21Feb12_122250|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122250|-- Weights --
21Feb12_122250|[[ 0.54269  0.51745]
21Feb12_122250| [ 0.78114 -0.02898]
21Feb12_122250| [ 0.42664  0.87820]
21Feb12_122250| [ 1.85692  1.00930]
21Feb12_122250| [-0.36428 -0.48201]
21Feb12_122250| [ 0.54257  0.40133]
21Feb12_122250| [ 0.37987  0.92260]
21Feb12_122250| [-0.97562  0.87485]
21Feb12_122250| [ 0.48492 -0.23554]
21Feb12_122250| [-0.02288  1.99097]
21Feb12_122250| [ 0.22312 -0.49929]
21Feb12_122250| [ 0.68677 -0.78589]
21Feb12_122250| [-0.64122 -1.02198]
21Feb12_122250| [ 0.97663 -0.19794]
21Feb12_122250| [ 1.11202 -0.74660]
21Feb12_122250| [ 0.01647  0.19142]
21Feb12_122250| [-0.26626 -1.74040]
21Feb12_122250| [ 0.89390 -1.94504]
21Feb12_122250| [-2.08531  0.76000]
21Feb12_122250| [-0.18604  0.05780]
21Feb12_122250| [-2.08234 -1.73501]
21Feb12_122250| [ 0.04846  0.89203]
21Feb12_122250| [ 1.43956 -0.85473]
21Feb12_122250| [ 0.28847 -0.31479]
21Feb12_122250| [-1.08681 -0.19438]
21Feb12_122250| [-0.53087  0.12354]
21Feb12_122250| [-0.56659  0.07287]
21Feb12_122250| [ 0.43632  0.61482]
21Feb12_122250| [-0.35397 -0.35099]
21Feb12_122250| [ 0.89931 -1.13776]
21Feb12_122250| [ 0.21615  0.57464]
21Feb12_122250| [-0.83112 -0.25842]
21Feb12_122250| [-1.85057 -0.01704]
21Feb12_122250| [-0.23908 -1.01627]
21Feb12_122250| [-1.85263  0.15697]
21Feb12_122250| [-0.43090  2.29957]
21Feb12_122250| [ 1.14946 -1.26716]
21Feb12_122250| [-0.89750 -2.21506]
21Feb12_122250| [-1.29923  0.73287]
21Feb12_122250| [-0.48238 -0.38642]
21Feb12_122250| [ 0.32489  0.44316]
21Feb12_122250| [ 0.52012 -0.36925]
21Feb12_122250| [-2.74548 -0.25594]
21Feb12_122250| [-0.84227 -0.05914]
21Feb12_122250| [-0.37258 -0.55981]
21Feb12_122250| [-0.46020 -0.43090]
21Feb12_122250| [-1.50862  1.34654]
21Feb12_122250| [ 0.86416  0.10203]
21Feb12_122250| [ 0.67670 -0.43189]
21Feb12_122250| [-0.04188 -0.59892]
21Feb12_122250| [-0.66711  0.05767]
21Feb12_122250| [ 0.35540  0.28841]
21Feb12_122250| [ 0.86502 -1.28510]
21Feb12_122250| [-0.43590  1.17894]
21Feb12_122250| [-1.29418  1.20010]
21Feb12_122250| [ 0.24850  1.02727]
21Feb12_122250| [-0.89739 -0.02376]]
21Feb12_122250|-- Bias --
21Feb12_122250|[ 1.04304 -0.72724]
21Feb12_122250|Layer 1:
21Feb12_122250|-- Config --
21Feb12_122250|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122250|-- Weights --
21Feb12_122250|[[-0.43766  0.46756]
21Feb12_122250| [ 0.28013 -0.84945]]
21Feb12_122250|-- Bias --
21Feb12_122250|[ 0.63986 -0.69735]
21Feb12_122250|Layer 2:
21Feb12_122250|-- Config --
21Feb12_122250|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122250|-- Weights --
21Feb12_122250|[[ 0.10104 -0.15548]
21Feb12_122250| [ 1.53171 -1.52201]]
21Feb12_122250|-- Bias --
21Feb12_122250|[-0.11042 -0.11664]
21Feb12_122250|Predicting the validation and test data with the Best final individual.
21Feb12_122257| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_122257|-----------  ------------------  --------------------  ----------
21Feb12_122257|Validation         25.65                  8             0.51917
21Feb12_122257|   Test            26.06                  8             0.53835
2021-02-12 12:22:58.303032: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
21Feb12_122259|Data summary: Train
21Feb12_122259|data.shape = (2300, 57)
21Feb12_122259|labels.shape = (2300,)
21Feb12_122259|Class distribution:
21Feb12_122259|	0 - 1382 (0.60)
21Feb12_122259|	1 - 918 (0.40)
21Feb12_122259|Data summary: Validation
21Feb12_122259|data.shape = (1150, 57)
21Feb12_122259|labels.shape = (1150,)
21Feb12_122259|Class distribution:
21Feb12_122259|	0 - 704 (0.61)
21Feb12_122259|	1 - 446 (0.39)
21Feb12_122259|Data summary: Test
21Feb12_122259|data.shape = (1151, 57)
21Feb12_122259|labels.shape = (1151,)
21Feb12_122259|Class distribution:
21Feb12_122259|	0 - 702 (0.61)
21Feb12_122259|	1 - 449 (0.39)
21Feb12_122259|Selected configuration values
21Feb12_122259|-- Dataset name: spambase1
21Feb12_122259|-- Initial population size: 64
21Feb12_122259|-- Maximun number of generations: 32
21Feb12_122259|-- Neurons per hidden layer range: (2, 20)
21Feb12_122259|-- Hidden layers number range: (1, 3)
21Feb12_122259|-- Crossover probability: 0.5
21Feb12_122259|-- Bias gene mutation probability: 0.2
21Feb12_122259|-- Weights gene mutation probability: 0.75
21Feb12_122259|-- Neuron mutation probability: 0.3
21Feb12_122259|-- Layer mutation probability: 0.3
21Feb12_122259|-- Constant hidden layers: False
21Feb12_122259|-- Seed: 31415
21Feb12_122259|Entering GA
21Feb12_122259|Start the algorithm
2021-02-12 12:22:59.229872: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-12 12:22:59.230412: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-02-12 12:22:59.250785: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-12 12:22:59.251144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.71GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s
2021-02-12 12:22:59.251161: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-02-12 12:22:59.252738: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-02-12 12:22:59.252769: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-02-12 12:22:59.253328: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-02-12 12:22:59.253472: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-02-12 12:22:59.253548: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-12 12:22:59.254000: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-02-12 12:22:59.254061: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-12 12:22:59.254071: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-02-12 12:22:59.254311: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-02-12 12:22:59.255167: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-12 12:22:59.255185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-12 12:22:59.255189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      
2021-02-12 12:22:59.306020: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-02-12 12:22:59.306338: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3493635000 Hz
/home/jmerelo/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype("int32")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn('`model.predict_classes()` is deprecated and '
21Feb12_122659|-- Generation 1 --
21Feb12_122659|    -- Crossed 1 individual pairs.
21Feb12_122659|    -- Mutated 32 individuals.
21Feb12_123059|    -- Evaluated 64 individuals.
21Feb12_123059|    Summary of generation 1:
21Feb12_123059| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_123059|-----------  ------------------  --------------------  ----------
21Feb12_123059|    Max            39.39                172.00          0.73915
21Feb12_123059|    Avg            38.61                47.88           0.01529
21Feb12_123059|    Min            26.17                 2.00           0.00000
21Feb12_123059|    Std             1.66                42.21           0.09471
21Feb12_123059|   Best            26.17                69.00           0.73915
21Feb12_123059|-- Generation 2 --
21Feb12_123059|    -- Crossed 1 individual pairs.
21Feb12_123059|    -- Mutated 32 individuals.
21Feb12_123456|    -- Evaluated 64 individuals.
21Feb12_123456|    Summary of generation 2:
21Feb12_123456| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_123456|-----------  ------------------  --------------------  ----------
21Feb12_123456|    Max            39.39                96.00           0.73134
21Feb12_123456|    Avg            38.13                36.75           0.04176
21Feb12_123456|    Min            25.13                 2.00           0.00000
21Feb12_123456|    Std             2.92                30.07           0.14792
21Feb12_123456|   Best            25.13                87.00           0.61428
21Feb12_123456|-- Generation 3 --
21Feb12_123456|    -- Crossed 2 individual pairs.
21Feb12_123456|    -- Mutated 32 individuals.
21Feb12_123853|    -- Evaluated 64 individuals.
21Feb12_123853|    Summary of generation 3:
21Feb12_123853| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_123853|-----------  ------------------  --------------------  ----------
21Feb12_123853|    Max            53.04                87.00           0.78400
21Feb12_123853|    Avg            38.55                26.72           0.03507
21Feb12_123853|    Min            24.96                 2.00           0.00000
21Feb12_123853|    Std             3.01                22.50           0.14668
21Feb12_123853|   Best            24.96                14.00           0.69685
21Feb12_123853|-- Generation 4 --
21Feb12_123853|    -- Crossed 2 individual pairs.
21Feb12_123853|    -- Mutated 32 individuals.
21Feb12_124245|    -- Evaluated 64 individuals.
21Feb12_124245|    Summary of generation 4:
21Feb12_124245| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_124245|-----------  ------------------  --------------------  ----------
21Feb12_124245|    Max            39.22                33.00           0.59280
21Feb12_124245|    Avg            38.39                13.11           0.02559
21Feb12_124245|    Min            25.48                 2.00           0.00000
21Feb12_124245|    Std             2.07                 8.70           0.10765
21Feb12_124245|   Best            25.48                16.00           0.57756
21Feb12_124245|-- Generation 5 --
21Feb12_124245|    -- Crossed 3 individual pairs.
21Feb12_124245|    -- Mutated 32 individuals.
21Feb12_124634|    -- Evaluated 64 individuals.
21Feb12_124634|    Summary of generation 5:
21Feb12_124634| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_124634|-----------  ------------------  --------------------  ----------
21Feb12_124634|    Max            56.43                30.00           0.77457
21Feb12_124634|    Avg            38.95                 8.45           0.02414
21Feb12_124634|    Min            28.96                 2.00           0.00000
21Feb12_124634|    Std             2.52                 6.21           0.13439
21Feb12_124634|   Best            28.96                24.00           0.77019
21Feb12_124634|-- Generation 6 --
21Feb12_124634|    -- Crossed 6 individual pairs.
21Feb12_124634|    -- Mutated 32 individuals.
21Feb12_125023|    -- Evaluated 64 individuals.
21Feb12_125023|    Summary of generation 6:
21Feb12_125023| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_125023|-----------  ------------------  --------------------  ----------
21Feb12_125023|    Max            39.22                28.00           0.78328
21Feb12_125023|    Avg            38.08                 7.28           0.03429
21Feb12_125023|    Min            23.39                 2.00           0.00000
21Feb12_125023|    Std             2.96                 6.16           0.13761
21Feb12_125023|   Best            23.39                24.00           0.54120
21Feb12_125023|-- Generation 7 --
21Feb12_125023|    -- Crossed 9 individual pairs.
21Feb12_125023|    -- Mutated 32 individuals.
21Feb12_125410|    -- Evaluated 64 individuals.
21Feb12_125410|    Summary of generation 7:
21Feb12_125410| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_125410|-----------  ------------------  --------------------  ----------
21Feb12_125410|    Max            39.57                44.00           0.69348
21Feb12_125410|    Avg            38.42                 6.92           0.02047
21Feb12_125410|    Min            27.57                 2.00           0.00000
21Feb12_125410|    Std             1.92                 7.30           0.09875
21Feb12_125410|   Best            27.57                10.00           0.39868
21Feb12_125410|-- Generation 8 --
21Feb12_125410|    -- Crossed 7 individual pairs.
21Feb12_125410|    -- Mutated 32 individuals.
21Feb12_125758|    -- Evaluated 64 individuals.
21Feb12_125758|    Summary of generation 8:
21Feb12_125758| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_125758|-----------  ------------------  --------------------  ----------
21Feb12_125758|    Max            59.30                44.00           0.76580
21Feb12_125758|    Avg            38.48                 6.17           0.04406
21Feb12_125758|    Min            24.96                 2.00           0.00000
21Feb12_125758|    Std             3.72                 6.80           0.16090
21Feb12_125758|   Best            24.96                24.00           0.59183
21Feb12_125758|-- Generation 9 --
21Feb12_125758|    -- Crossed 7 individual pairs.
21Feb12_125758|    -- Mutated 32 individuals.
21Feb12_130145|    -- Evaluated 64 individuals.
21Feb12_130145|    Summary of generation 9:
21Feb12_130145| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_130145|-----------  ------------------  --------------------  ----------
21Feb12_130145|    Max            39.30                33.00           0.80733
21Feb12_130145|    Avg            38.17                 6.12           0.04297
21Feb12_130145|    Min            26.35                 2.00           0.00000
21Feb12_130145|    Std             2.49                 6.41           0.15891
21Feb12_130145|   Best            26.35                10.00           0.59629
21Feb12_130145|-- Generation 10 --
21Feb12_130145|    -- Crossed 7 individual pairs.
21Feb12_130145|    -- Mutated 32 individuals.
21Feb12_130536|    -- Evaluated 64 individuals.
21Feb12_130536|    Summary of generation 10:
21Feb12_130536| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_130536|-----------  ------------------  --------------------  ----------
21Feb12_130536|    Max            38.96                33.00           0.74539
21Feb12_130536|    Avg            37.27                 6.50           0.06981
21Feb12_130536|    Min            24.43                 2.00           0.00000
21Feb12_130536|    Std             4.04                 6.49           0.18991
21Feb12_130536|   Best            24.43                10.00           0.50910
21Feb12_130536|-- Generation 11 --
21Feb12_130536|    -- Crossed 7 individual pairs.
21Feb12_130536|    -- Mutated 32 individuals.
21Feb12_130924|    -- Evaluated 64 individuals.
21Feb12_130924|    Summary of generation 11:
21Feb12_130924| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_130924|-----------  ------------------  --------------------  ----------
21Feb12_130924|    Max            39.57                33.00           0.67904
21Feb12_130924|    Avg            37.64                 7.23           0.04905
21Feb12_130924|    Min            23.57                 2.00           0.00000
21Feb12_130924|    Std             3.67                 8.18           0.15505
21Feb12_130924|   Best            23.57                30.00           0.67904
21Feb12_130924|-- Generation 12 --
21Feb12_130924|    -- Crossed 4 individual pairs.
21Feb12_130924|    -- Mutated 32 individuals.
21Feb12_131314|    -- Evaluated 64 individuals.
21Feb12_131314|    Summary of generation 12:
21Feb12_131314| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_131314|-----------  ------------------  --------------------  ----------
21Feb12_131314|    Max            39.13                56.00           0.79431
21Feb12_131314|    Avg            37.18                 5.83           0.07641
21Feb12_131314|    Min            23.74                 2.00           0.00000
21Feb12_131314|    Std             4.28                 8.42           0.20359
21Feb12_131314|   Best            23.74                30.00           0.66849
21Feb12_131314|-- Generation 13 --
21Feb12_131314|    -- Crossed 5 individual pairs.
21Feb12_131314|    -- Mutated 32 individuals.
21Feb12_131704|    -- Evaluated 64 individuals.
21Feb12_131704|    Summary of generation 13:
21Feb12_131704| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_131704|-----------  ------------------  --------------------  ----------
21Feb12_131704|    Max            39.91                56.00           0.73325
21Feb12_131704|    Avg            37.39                 7.72           0.07312
21Feb12_131704|    Min            24.87                 2.00           0.00000
21Feb12_131704|    Std             3.87                11.40           0.19994
21Feb12_131704|   Best            24.87                30.00           0.73325
21Feb12_131704|-- Generation 14 --
21Feb12_131704|    -- Crossed 6 individual pairs.
21Feb12_131704|    -- Mutated 32 individuals.
21Feb12_132055|    -- Evaluated 64 individuals.
21Feb12_132055|    Summary of generation 14:
21Feb12_132055| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_132055|-----------  ------------------  --------------------  ----------
21Feb12_132055|    Max            39.04                56.00           0.71367
21Feb12_132055|    Avg            37.66                 9.52           0.05292
21Feb12_132055|    Min            24.43                 2.00           0.00000
21Feb12_132055|    Std             3.61                14.22           0.16823
21Feb12_132055|   Best            24.43                33.00           0.52849
21Feb12_132055|-- Generation 15 --
21Feb12_132055|    -- Crossed 8 individual pairs.
21Feb12_132055|    -- Mutated 32 individuals.
21Feb12_132443|    -- Evaluated 64 individuals.
21Feb12_132443|    Summary of generation 15:
21Feb12_132443| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_132443|-----------  ------------------  --------------------  ----------
21Feb12_132443|    Max            39.13                33.00           0.77877
21Feb12_132443|    Avg            38.07                 6.41           0.03585
21Feb12_132443|    Min            24.09                 2.00           0.00000
21Feb12_132443|    Std             2.91                 8.26           0.14269
21Feb12_132443|   Best            24.09                10.00           0.55796
21Feb12_132443|-- Generation 16 --
21Feb12_132443|    -- Crossed 6 individual pairs.
21Feb12_132443|    -- Mutated 32 individuals.
21Feb12_132832|    -- Evaluated 64 individuals.
21Feb12_132832|    Summary of generation 16:
21Feb12_132832| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_132832|-----------  ------------------  --------------------  ----------
21Feb12_132832|    Max            40.09                33.00           0.77989
21Feb12_132832|    Avg            38.33                 6.47           0.03177
21Feb12_132832|    Min            23.74                 2.00           0.00000
21Feb12_132832|    Std             2.57                 8.00           0.14480
21Feb12_132832|   Best            23.74                12.00           0.70601
21Feb12_132832|-- Generation 17 --
21Feb12_132832|    -- Crossed 5 individual pairs.
21Feb12_132832|    -- Mutated 32 individuals.
21Feb12_133221|    -- Evaluated 64 individuals.
21Feb12_133221|    Summary of generation 17:
21Feb12_133221| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_133221|-----------  ------------------  --------------------  ----------
21Feb12_133221|    Max            44.00                33.00           0.78958
21Feb12_133221|    Avg            38.73                 5.38           0.01251
21Feb12_133221|    Min            29.83                 2.00           0.00000
21Feb12_133221|    Std             1.30                 7.18           0.09791
21Feb12_133221|   Best            29.83                33.00           0.78958
21Feb12_133221|-- Generation 18 --
21Feb12_133221|    -- Crossed 6 individual pairs.
21Feb12_133221|    -- Mutated 32 individuals.
21Feb12_133607|    -- Evaluated 64 individuals.
21Feb12_133607|    Summary of generation 18:
21Feb12_133607| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_133607|-----------  ------------------  --------------------  ----------
21Feb12_133607|    Max            39.83                36.00           0.45977
21Feb12_133607|    Avg            38.61                 5.30           0.00723
21Feb12_133607|    Min            25.65                 2.00           0.00000
21Feb12_133607|    Std             1.64                 8.06           0.05702
21Feb12_133607|   Best            25.65                33.00           0.45977
21Feb12_133607|-- Generation 19 --
21Feb12_133607|    -- Crossed 8 individual pairs.
21Feb12_133607|    -- Mutated 32 individuals.
21Feb12_133954|    -- Evaluated 64 individuals.
21Feb12_133954|    Summary of generation 19:
21Feb12_133954| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_133954|-----------  ------------------  --------------------  ----------
21Feb12_133954|    Max            39.39                33.00           0.49282
21Feb12_133954|    Avg            38.59                 4.62           0.00770
21Feb12_133954|    Min            24.61                 2.00           0.00000
21Feb12_133954|    Std             1.76                 6.19           0.06112
21Feb12_133954|   Best            24.61                33.00           0.49282
21Feb12_133954|-- Generation 20 --
21Feb12_133954|    -- Crossed 9 individual pairs.
21Feb12_133954|    -- Mutated 32 individuals.
21Feb12_134339|    -- Evaluated 64 individuals.
21Feb12_134339|    Summary of generation 20:
21Feb12_134339| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_134339|-----------  ------------------  --------------------  ----------
21Feb12_134339|    Max            39.04                33.00           0.00000
21Feb12_134339|    Avg            38.80                 4.19           0.00000
21Feb12_134339|    Min            38.78                 2.00           0.00000
21Feb12_134339|    Std             0.05                 6.05           0.00000
21Feb12_134339|   Best            38.78                 2.00           0.00000
21Feb12_134339|-- Generation 21 --
21Feb12_134339|    -- Crossed 10 individual pairs.
21Feb12_134339|    -- Mutated 32 individuals.
21Feb12_134726|    -- Evaluated 64 individuals.
21Feb12_134726|    Summary of generation 21:
21Feb12_134726| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_134726|-----------  ------------------  --------------------  ----------
21Feb12_134726|    Max            38.87                14.00           0.00000
21Feb12_134726|    Avg            38.79                 3.08           0.00000
21Feb12_134726|    Min            38.78                 2.00           0.00000
21Feb12_134726|    Std             0.02                 2.76           0.00000
21Feb12_134726|   Best            38.78                 2.00           0.00000
21Feb12_134726|-- Generation 22 --
21Feb12_134726|    -- Crossed 11 individual pairs.
21Feb12_134726|    -- Mutated 32 individuals.
21Feb12_135113|    -- Evaluated 64 individuals.
21Feb12_135113|    Summary of generation 22:
21Feb12_135113| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_135113|-----------  ------------------  --------------------  ----------
21Feb12_135113|    Max            38.87                14.00           0.67929
21Feb12_135113|    Avg            38.59                 3.70           0.01061
21Feb12_135113|    Min            25.83                 2.00           0.00000
21Feb12_135113|    Std             1.61                 3.64           0.08424
21Feb12_135113|   Best            25.83                10.00           0.67929
21Feb12_135113|-- Generation 23 --
21Feb12_135113|    -- Crossed 8 individual pairs.
21Feb12_135113|    -- Mutated 32 individuals.
21Feb12_135500|    -- Evaluated 64 individuals.
21Feb12_135500|    Summary of generation 23:
21Feb12_135500| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_135500|-----------  ------------------  --------------------  ----------
21Feb12_135500|    Max            39.13                16.00           0.80309
21Feb12_135500|    Avg            38.76                 4.09           0.01255
21Feb12_135500|    Min            36.52                 2.00           0.00000
21Feb12_135500|    Std             0.29                 4.16           0.09960
21Feb12_135500|   Best            36.52                10.00           0.80309
21Feb12_135500|-- Generation 24 --
21Feb12_135500|    -- Crossed 8 individual pairs.
21Feb12_135500|    -- Mutated 32 individuals.
21Feb12_135846|    -- Evaluated 64 individuals.
21Feb12_135846|    Summary of generation 24:
21Feb12_135846| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_135846|-----------  ------------------  --------------------  ----------
21Feb12_135846|    Max            39.04                14.00           0.81466
21Feb12_135846|    Avg            38.46                 3.83           0.02440
21Feb12_135846|    Min            27.57                 2.00           0.00000
21Feb12_135846|    Std             1.87                 3.67           0.13240
21Feb12_135846|   Best            27.57                12.00           0.81466
21Feb12_135846|-- Generation 25 --
21Feb12_135846|    -- Crossed 6 individual pairs.
21Feb12_135846|    -- Mutated 32 individuals.
21Feb12_140235|    -- Evaluated 64 individuals.
21Feb12_140235|    Summary of generation 25:
21Feb12_140235| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_140235|-----------  ------------------  --------------------  ----------
21Feb12_140235|    Max            39.04                21.00           0.00000
21Feb12_140235|    Avg            38.81                 4.20           0.00000
21Feb12_140235|    Min            38.78                 2.00           0.00000
21Feb12_140235|    Std             0.06                 4.48           0.00000
21Feb12_140235|   Best            38.78                 2.00           0.00000
21Feb12_140235|-- Generation 26 --
21Feb12_140235|    -- Crossed 8 individual pairs.
21Feb12_140235|    -- Mutated 32 individuals.
21Feb12_140622|    -- Evaluated 64 individuals.
21Feb12_140622|    Summary of generation 26:
21Feb12_140622| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_140622|-----------  ------------------  --------------------  ----------
21Feb12_140622|    Max            45.91                16.00           0.80733
21Feb12_140622|    Avg            38.91                 4.06           0.01355
21Feb12_140622|    Min            38.78                 2.00           0.00000
21Feb12_140622|    Std             0.88                 4.17           0.10028
21Feb12_140622|   Best            38.78                 2.00           0.00000
21Feb12_140622|-- Generation 27 --
21Feb12_140622|    -- Crossed 8 individual pairs.
21Feb12_140622|    -- Mutated 32 individuals.
21Feb12_141010|    -- Evaluated 64 individuals.
21Feb12_141010|    Summary of generation 27:
21Feb12_141010| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_141010|-----------  ------------------  --------------------  ----------
21Feb12_141010|    Max            39.04                16.00           0.57574
21Feb12_141010|    Avg            38.59                 3.25           0.00900
21Feb12_141010|    Min            25.48                 2.00           0.00000
21Feb12_141010|    Std             1.65                 3.18           0.07140
21Feb12_141010|   Best            25.48                12.00           0.57574
21Feb12_141010|-- Generation 28 --
21Feb12_141010|    -- Crossed 8 individual pairs.
21Feb12_141010|    -- Mutated 32 individuals.
21Feb12_141358|    -- Evaluated 64 individuals.
21Feb12_141358|    Summary of generation 28:
21Feb12_141358| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_141358|-----------  ------------------  --------------------  ----------
21Feb12_141358|    Max            39.04                16.00           0.73959
21Feb12_141358|    Avg            38.53                 3.59           0.01156
21Feb12_141358|    Min            21.91                 2.00           0.00000
21Feb12_141358|    Std             2.09                 3.68           0.09172
21Feb12_141358|   Best            21.91                16.00           0.73959
21Feb12_141358|-- Generation 29 --
21Feb12_141358|    -- Crossed 6 individual pairs.
21Feb12_141358|    -- Mutated 32 individuals.
21Feb12_141746|    -- Evaluated 64 individuals.
21Feb12_141746|    Summary of generation 29:
21Feb12_141746| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_141746|-----------  ------------------  --------------------  ----------
21Feb12_141746|    Max            47.65                16.00           0.80274
21Feb12_141746|    Avg            38.82                 4.06           0.01669
21Feb12_141746|    Min            31.39                 2.00           0.00000
21Feb12_141746|    Std             1.44                 4.28           0.10437
21Feb12_141746|   Best            31.39                 2.00           0.26565
21Feb12_141746|-- Generation 30 --
21Feb12_141747|    -- Crossed 6 individual pairs.
21Feb12_141747|    -- Mutated 32 individuals.
21Feb12_142135|    -- Evaluated 64 individuals.
21Feb12_142135|    Summary of generation 30:
21Feb12_142135| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_142135|-----------  ------------------  --------------------  ----------
21Feb12_142135|    Max            39.04                14.00           0.71803
21Feb12_142135|    Avg            38.43                 3.64           0.01715
21Feb12_142135|    Min            25.65                 2.00           0.00000
21Feb12_142135|    Std             2.07                 3.38           0.10007
21Feb12_142135|   Best            25.65                10.00           0.71803
21Feb12_142135|-- Generation 31 --
21Feb12_142135|    -- Crossed 8 individual pairs.
21Feb12_142135|    -- Mutated 32 individuals.
21Feb12_142524|    -- Evaluated 64 individuals.
21Feb12_142524|    Summary of generation 31:
21Feb12_142524| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_142524|-----------  ------------------  --------------------  ----------
21Feb12_142524|    Max            39.04                21.00           0.80692
21Feb12_142524|    Avg            38.40                 4.08           0.02051
21Feb12_142524|    Min            25.57                 2.00           0.00000
21Feb12_142524|    Std             2.21                 4.13           0.11727
21Feb12_142524|   Best            25.57                14.00           0.50587
21Feb12_142524|-- Generation 32 --
21Feb12_142524|    -- Crossed 7 individual pairs.
21Feb12_142524|    -- Mutated 32 individuals.
21Feb12_142913|    -- Evaluated 64 individuals.
21Feb12_142913|    Summary of generation 32:
21Feb12_142913| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_142913|-----------  ------------------  --------------------  ----------
21Feb12_142913|    Max            39.39                14.00           0.00000
21Feb12_142913|    Avg            38.81                 4.08           0.00000
21Feb12_142913|    Min            38.78                 2.00           0.00000
21Feb12_142913|    Std             0.10                 3.86           0.00000
21Feb12_142913|   Best            38.78                 2.00           0.00000
21Feb12_142913|Best initial individual weights
21Feb12_142913|Individual:
21Feb12_142913|-- Constant hidden layers --
21Feb12_142913|False
21Feb12_142913|Layer 0:
21Feb12_142913|-- Config --
21Feb12_142913|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_142913|-- Weights --
21Feb12_142913|[[-0.95981  0.63808 -0.95380]
21Feb12_142913| [ 0.00520 -0.99353  0.50361]
21Feb12_142913| [-0.11451 -0.83347 -0.55396]
21Feb12_142913| [ 0.35657 -0.33319  0.99061]
21Feb12_142913| [ 0.20904  0.47603  0.54306]
21Feb12_142913| [ 0.86632  0.13678 -0.77041]
21Feb12_142913| [-0.35567 -0.99164  0.62727]
21Feb12_142913| [-0.68497  0.10640 -0.05172]
21Feb12_142913| [-0.59737 -0.00964  0.88158]
21Feb12_142913| [-0.13985 -0.06300 -0.43706]
21Feb12_142913| [ 0.64358  0.92937 -0.73432]
21Feb12_142913| [ 0.23476  0.78313  0.56825]
21Feb12_142913| [-0.54321  0.72471  0.37840]
21Feb12_142913| [-0.42357 -0.01577 -0.17096]
21Feb12_142913| [ 0.72075  0.01528 -0.53335]
21Feb12_142913| [-0.85291 -0.95287  0.91534]
21Feb12_142913| [-0.32401 -0.26906  0.15748]
21Feb12_142913| [-0.40109 -0.17141  0.12077]
21Feb12_142913| [ 0.06946 -0.71844 -0.65437]
21Feb12_142913| [ 0.77536 -0.87117  0.40091]
21Feb12_142913| [ 0.71219 -0.55029 -0.47352]
21Feb12_142913| [-0.48247 -0.59676 -0.13973]
21Feb12_142913| [ 0.29835 -0.64235  0.86195]
21Feb12_142913| [ 0.76225  0.85104  0.00830]
21Feb12_142913| [ 0.47868 -0.29509  0.58927]
21Feb12_142913| [ 0.44057 -0.21842 -0.84593]
21Feb12_142913| [-0.45754  0.53879  0.95554]
21Feb12_142913| [-0.76945 -0.60835  0.71744]
21Feb12_142913| [ 0.53999  0.63134  0.43758]
21Feb12_142913| [-0.19306 -0.59818  0.19108]
21Feb12_142913| [-0.51517  0.85226  0.38538]
21Feb12_142913| [-0.79126 -0.93873  0.01578]
21Feb12_142913| [-0.50150 -0.14594 -0.18067]
21Feb12_142913| [ 0.61416 -0.70576  0.33529]
21Feb12_142913| [ 0.15072  0.89141  0.54784]
21Feb12_142913| [ 0.36697  0.31313 -0.13077]
21Feb12_142913| [ 0.69307 -0.37869  0.20694]
21Feb12_142913| [ 0.03015  0.15728  0.76226]
21Feb12_142913| [ 0.77952 -0.76856 -0.43483]
21Feb12_142913| [-0.61518 -0.05786  0.81156]
21Feb12_142913| [ 0.84017 -0.42741  0.60340]
21Feb12_142913| [ 0.53666 -0.82919  0.07802]
21Feb12_142913| [ 0.47864  0.69058 -0.97920]
21Feb12_142913| [ 0.68760  0.30748  0.39424]
21Feb12_142913| [ 0.18427  0.64362  0.23634]
21Feb12_142913| [-0.94644 -0.07451 -0.16574]
21Feb12_142913| [-0.96084  0.12874 -0.86066]
21Feb12_142913| [-0.56938  0.44358  0.07698]
21Feb12_142913| [-0.21143  0.88977 -0.62804]
21Feb12_142913| [-0.49083  0.36500  0.15463]
21Feb12_142913| [-0.68978  0.96064  0.44141]
21Feb12_142913| [-0.21911  0.93693  0.42766]
21Feb12_142913| [ 0.30992 -0.75633  0.40386]
21Feb12_142913| [-0.38889 -0.87472 -0.60032]
21Feb12_142913| [ 0.63181  0.38743  0.42944]
21Feb12_142913| [-0.36880  0.75866  0.06497]
21Feb12_142913| [ 0.95225  0.89125  0.24472]]
21Feb12_142913|-- Bias --
21Feb12_142913|[-0.87203 -0.18510 -0.82395]
21Feb12_142913|Layer 1:
21Feb12_142913|-- Config --
21Feb12_142913|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 9, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_142913|-- Weights --
21Feb12_142913|[[-0.48876  0.92140 -0.21669  0.72465 -0.25318 -0.77574 -0.72806 -0.41561
21Feb12_142913|   0.09470]
21Feb12_142913| [ 0.16540 -0.74164  0.12712 -0.17055  0.32434  0.08465 -0.18577  0.93967
21Feb12_142913|   0.13630]
21Feb12_142913| [ 0.51611  0.56311  0.06727  0.75197 -0.15192  0.43301 -0.52005  0.07976
21Feb12_142913|  -0.84277]]
21Feb12_142913|-- Bias --
21Feb12_142913|[ 0.32558  0.84726 -0.20681  0.97295  0.68375 -0.70571 -0.86307 -0.88871
21Feb12_142913|  0.55514]
21Feb12_142913|Layer 2:
21Feb12_142913|-- Config --
21Feb12_142913|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 9], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_142913|-- Weights --
21Feb12_142913|[[ 0.76468  0.30035]
21Feb12_142913| [-0.84449  0.54167]
21Feb12_142913| [-0.04649 -0.86516]
21Feb12_142913| [-0.11365 -0.30894]
21Feb12_142913| [ 0.95453  0.69955]
21Feb12_142913| [ 0.56339  0.48813]
21Feb12_142913| [-0.11587 -0.35680]
21Feb12_142913| [ 0.67275  0.94171]
21Feb12_142913| [ 0.44550 -0.58681]]
21Feb12_142913|-- Bias --
21Feb12_142913|[0.41147 0.60365]
21Feb12_142913|Predicting the validation and test data with the Best initial individual.
21Feb12_142921| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_142921|-----------  ------------------  --------------------  ----------
21Feb12_142921|Validation         38.78                  24            0.00000
21Feb12_142921|   Test            39.01                  24            0.00000
21Feb12_142921|-------------------- Test #0 --------------------
21Feb12_142921|Best final individual weights
21Feb12_142921|Individual:
21Feb12_142921|-- Constant hidden layers --
21Feb12_142921|False
21Feb12_142921|Layer 0:
21Feb12_142921|-- Config --
21Feb12_142921|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_142921|-- Weights --
21Feb12_142921|[[ 0.21414  0.52544]
21Feb12_142921| [ 0.05169  0.56268]
21Feb12_142921| [ 0.39643 -0.36944]
21Feb12_142921| [ 0.75139 -0.39262]
21Feb12_142921| [-0.65666 -0.35567]
21Feb12_142921| [ 0.76973 -0.23402]
21Feb12_142921| [ 0.52152  0.55960]
21Feb12_142921| [-0.28808  1.29313]
21Feb12_142921| [ 1.13623 -0.33404]
21Feb12_142921| [ 0.72011  0.57863]
21Feb12_142921| [-0.82677 -0.17911]
21Feb12_142921| [ 0.67247 -0.90114]
21Feb12_142921| [-0.94435 -0.40129]
21Feb12_142921| [ 0.38205 -0.27091]
21Feb12_142921| [ 0.88609 -0.63414]
21Feb12_142921| [ 0.06280 -0.38041]
21Feb12_142921| [-0.55605 -1.10806]
21Feb12_142921| [ 0.05986 -0.90362]
21Feb12_142921| [-1.03054  0.35910]
21Feb12_142921| [ 0.24710  0.65959]
21Feb12_142921| [-0.40237  0.02352]
21Feb12_142921| [ 0.08333  0.13547]
21Feb12_142921| [ 0.61879 -0.90920]
21Feb12_142921| [ 0.67984 -0.25623]
21Feb12_142921| [-0.28837  0.43629]
21Feb12_142921| [-1.08202  0.55318]
21Feb12_142921| [-0.31999  0.11075]
21Feb12_142921| [ 0.20228  0.80637]
21Feb12_142921| [ 1.18759  0.53496]
21Feb12_142921| [ 0.90767 -0.54768]
21Feb12_142921| [-0.04074 -0.34023]
21Feb12_142921| [-0.01048 -0.78582]
21Feb12_142921| [-1.24714  0.33030]
21Feb12_142921| [-0.43642  0.23841]
21Feb12_142921| [-0.71652  0.74987]
21Feb12_142921| [-0.06681  0.69165]
21Feb12_142921| [ 0.67229 -0.62662]
21Feb12_142921| [-0.04327 -0.88245]
21Feb12_142921| [-0.56785  0.43564]
21Feb12_142921| [-1.19669 -0.92456]
21Feb12_142921| [ 0.88074 -0.34189]
21Feb12_142921| [-0.37089  0.37628]
21Feb12_142921| [-0.47467  0.33949]
21Feb12_142921| [-0.85890  0.21259]
21Feb12_142921| [-0.87568 -0.55763]
21Feb12_142921| [-0.13669 -0.06907]
21Feb12_142921| [-0.94063  0.39268]
21Feb12_142921| [ 1.10667 -0.47605]
21Feb12_142921| [ 1.32877  0.84990]
21Feb12_142921| [ 0.88675 -1.37478]
21Feb12_142921| [-0.00196 -0.10654]
21Feb12_142921| [-0.26972  0.42252]
21Feb12_142921| [ 0.46597  0.15688]
21Feb12_142921| [ 0.16470  0.33818]
21Feb12_142921| [-0.83135  0.52175]
21Feb12_142921| [ 0.30230 -0.07531]
21Feb12_142921| [-1.24999  0.25559]]
21Feb12_142921|-- Bias --
21Feb12_142921|[ 0.47675 -0.84795]
21Feb12_142921|Layer 1:
21Feb12_142921|-- Config --
21Feb12_142921|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_142921|-- Weights --
21Feb12_142921|[[-0.16807 -0.20404]
21Feb12_142921| [ 1.14186 -0.87134]]
21Feb12_142921|-- Bias --
21Feb12_142921|[-0.11042  0.35882]
21Feb12_142921|Predicting the validation and test data with the Best final individual.
21Feb12_142928| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_142928|-----------  ------------------  --------------------  ----------
21Feb12_142928|Validation         38.78                  2             0.00000
21Feb12_142928|   Test            39.01                  2             0.00000
21Feb12_142928|-------------------- Test #1 --------------------
21Feb12_142928|Best final individual weights
21Feb12_142928|Individual:
21Feb12_142928|-- Constant hidden layers --
21Feb12_142928|False
21Feb12_142928|Layer 0:
21Feb12_142928|-- Config --
21Feb12_142928|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_142928|-- Weights --
21Feb12_142928|[[ 0.21414  0.52544]
21Feb12_142928| [ 0.05169  0.56268]
21Feb12_142928| [ 0.39643 -0.36944]
21Feb12_142928| [ 0.75139 -0.39262]
21Feb12_142928| [-0.65666 -0.35567]
21Feb12_142928| [ 0.76973 -0.23402]
21Feb12_142928| [ 0.52152  0.55960]
21Feb12_142928| [-0.28808  1.29313]
21Feb12_142928| [ 1.13623 -0.33404]
21Feb12_142928| [ 0.72011  0.57863]
21Feb12_142928| [-0.82677 -0.17911]
21Feb12_142928| [ 0.67247 -0.90114]
21Feb12_142928| [-0.94435 -0.40129]
21Feb12_142928| [ 0.38205 -0.27091]
21Feb12_142928| [ 0.88609 -0.63414]
21Feb12_142928| [ 0.06280 -0.38041]
21Feb12_142928| [-0.55605 -1.10806]
21Feb12_142928| [ 0.05986 -0.90362]
21Feb12_142928| [-1.03054  0.35910]
21Feb12_142928| [ 0.24710  0.65959]
21Feb12_142928| [-0.40237  0.02352]
21Feb12_142928| [ 0.08333  0.13547]
21Feb12_142928| [ 0.61879 -0.90920]
21Feb12_142928| [ 0.67984 -0.25623]
21Feb12_142928| [-0.28837  0.43629]
21Feb12_142928| [-1.08202  0.55318]
21Feb12_142928| [-0.31999  0.11075]
21Feb12_142928| [ 0.20228  0.80637]
21Feb12_142928| [ 1.18759  0.53496]
21Feb12_142928| [ 0.90767 -0.54768]
21Feb12_142928| [-0.04074 -0.34023]
21Feb12_142928| [-0.01048 -0.78582]
21Feb12_142928| [-1.24714  0.33030]
21Feb12_142928| [-0.43642  0.23841]
21Feb12_142928| [-0.71652  0.74987]
21Feb12_142928| [-0.06681  0.69165]
21Feb12_142928| [ 0.67229 -0.62662]
21Feb12_142928| [-0.04327 -0.88245]
21Feb12_142928| [-0.56785  0.43564]
21Feb12_142928| [-1.19669 -0.92456]
21Feb12_142928| [ 0.88074 -0.34189]
21Feb12_142928| [-0.37089  0.37628]
21Feb12_142928| [-0.47467  0.33949]
21Feb12_142928| [-0.85890  0.21259]
21Feb12_142928| [-0.87568 -0.55763]
21Feb12_142928| [-0.13669 -0.06907]
21Feb12_142928| [-0.94063  0.39268]
21Feb12_142928| [ 1.10667 -0.47605]
21Feb12_142928| [ 1.32877  0.84990]
21Feb12_142928| [ 0.88675 -1.37478]
21Feb12_142928| [-0.00196 -0.10654]
21Feb12_142928| [-0.26972  0.42252]
21Feb12_142928| [ 0.46597  0.15688]
21Feb12_142928| [ 0.16470  0.33818]
21Feb12_142928| [-0.83135  0.52175]
21Feb12_142928| [ 0.30230 -0.07531]
21Feb12_142928| [-1.24999  0.25559]]
21Feb12_142928|-- Bias --
21Feb12_142928|[ 0.47675 -0.84795]
21Feb12_142928|Layer 1:
21Feb12_142928|-- Config --
21Feb12_142928|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_142928|-- Weights --
21Feb12_142928|[[-0.16807 -0.20404]
21Feb12_142928| [ 1.14186 -0.87134]]
21Feb12_142928|-- Bias --
21Feb12_142928|[-0.11042  0.35882]
21Feb12_142928|Predicting the validation and test data with the Best final individual.
21Feb12_142935| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_142935|-----------  ------------------  --------------------  ----------
21Feb12_142935|Validation         38.78                  2             0.00000
21Feb12_142935|   Test            39.01                  2             0.00000
21Feb12_142935|-------------------- Test #2 --------------------
21Feb12_142935|Best final individual weights
21Feb12_142935|Individual:
21Feb12_142935|-- Constant hidden layers --
21Feb12_142935|False
21Feb12_142935|Layer 0:
21Feb12_142935|-- Config --
21Feb12_142935|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_142935|-- Weights --
21Feb12_142935|[[ 0.21414  0.52544]
21Feb12_142935| [ 0.05169  0.56268]
21Feb12_142935| [ 0.39643 -0.36944]
21Feb12_142935| [ 0.75139 -0.39262]
21Feb12_142935| [-0.65666 -0.35567]
21Feb12_142935| [ 0.76973 -0.23402]
21Feb12_142935| [ 0.52152  0.55960]
21Feb12_142935| [-0.28808  1.29313]
21Feb12_142935| [ 1.13623 -0.33404]
21Feb12_142935| [ 0.72011  0.57863]
21Feb12_142935| [-0.82677 -0.17911]
21Feb12_142935| [ 0.67247 -0.90114]
21Feb12_142935| [-0.94435 -0.40129]
21Feb12_142935| [ 0.38205 -0.27091]
21Feb12_142935| [ 0.88609 -0.63414]
21Feb12_142935| [ 0.06280 -0.38041]
21Feb12_142935| [-0.55605 -1.10806]
21Feb12_142935| [ 0.05986 -0.90362]
21Feb12_142935| [-1.03054  0.35910]
21Feb12_142935| [ 0.24710  0.65959]
21Feb12_142935| [-0.40237  0.02352]
21Feb12_142935| [ 0.08333  0.13547]
21Feb12_142935| [ 0.61879 -0.90920]
21Feb12_142935| [ 0.67984 -0.25623]
21Feb12_142935| [-0.28837  0.43629]
21Feb12_142935| [-1.08202  0.55318]
21Feb12_142935| [-0.31999  0.11075]
21Feb12_142935| [ 0.20228  0.80637]
21Feb12_142935| [ 1.18759  0.53496]
21Feb12_142935| [ 0.90767 -0.54768]
21Feb12_142935| [-0.04074 -0.34023]
21Feb12_142935| [-0.01048 -0.78582]
21Feb12_142935| [-1.24714  0.33030]
21Feb12_142935| [-0.43642  0.23841]
21Feb12_142935| [-0.71652  0.74987]
21Feb12_142935| [-0.06681  0.69165]
21Feb12_142935| [ 0.67229 -0.62662]
21Feb12_142935| [-0.04327 -0.88245]
21Feb12_142935| [-0.56785  0.43564]
21Feb12_142935| [-1.19669 -0.92456]
21Feb12_142935| [ 0.88074 -0.34189]
21Feb12_142935| [-0.37089  0.37628]
21Feb12_142935| [-0.47467  0.33949]
21Feb12_142935| [-0.85890  0.21259]
21Feb12_142935| [-0.87568 -0.55763]
21Feb12_142935| [-0.13669 -0.06907]
21Feb12_142935| [-0.94063  0.39268]
21Feb12_142935| [ 1.10667 -0.47605]
21Feb12_142935| [ 1.32877  0.84990]
21Feb12_142935| [ 0.88675 -1.37478]
21Feb12_142935| [-0.00196 -0.10654]
21Feb12_142935| [-0.26972  0.42252]
21Feb12_142935| [ 0.46597  0.15688]
21Feb12_142935| [ 0.16470  0.33818]
21Feb12_142935| [-0.83135  0.52175]
21Feb12_142935| [ 0.30230 -0.07531]
21Feb12_142935| [-1.24999  0.25559]]
21Feb12_142935|-- Bias --
21Feb12_142935|[ 0.47675 -0.84795]
21Feb12_142935|Layer 1:
21Feb12_142935|-- Config --
21Feb12_142935|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_142935|-- Weights --
21Feb12_142935|[[-0.16807 -0.20404]
21Feb12_142935| [ 1.14186 -0.87134]]
21Feb12_142935|-- Bias --
21Feb12_142935|[-0.11042  0.35882]
21Feb12_142935|Predicting the validation and test data with the Best final individual.
21Feb12_142942| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_142942|-----------  ------------------  --------------------  ----------
21Feb12_142942|Validation         38.78                  2             0.00000
21Feb12_142942|   Test            39.01                  2             0.00000
21Feb12_142942|-------------------- Test #3 --------------------
21Feb12_142942|Best final individual weights
21Feb12_142942|Individual:
21Feb12_142942|-- Constant hidden layers --
21Feb12_142942|False
21Feb12_142942|Layer 0:
21Feb12_142942|-- Config --
21Feb12_142942|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_142942|-- Weights --
21Feb12_142942|[[ 0.21414  0.52544]
21Feb12_142942| [ 0.05169  0.56268]
21Feb12_142942| [ 0.39643 -0.36944]
21Feb12_142942| [ 0.75139 -0.39262]
21Feb12_142942| [-0.65666 -0.35567]
21Feb12_142942| [ 0.76973 -0.23402]
21Feb12_142942| [ 0.52152  0.55960]
21Feb12_142942| [-0.28808  1.29313]
21Feb12_142942| [ 1.13623 -0.33404]
21Feb12_142942| [ 0.72011  0.57863]
21Feb12_142942| [-0.82677 -0.17911]
21Feb12_142942| [ 0.67247 -0.90114]
21Feb12_142942| [-0.94435 -0.40129]
21Feb12_142942| [ 0.38205 -0.27091]
21Feb12_142942| [ 0.88609 -0.63414]
21Feb12_142942| [ 0.06280 -0.38041]
21Feb12_142942| [-0.55605 -1.10806]
21Feb12_142942| [ 0.05986 -0.90362]
21Feb12_142942| [-1.03054  0.35910]
21Feb12_142942| [ 0.24710  0.65959]
21Feb12_142942| [-0.40237  0.02352]
21Feb12_142942| [ 0.08333  0.13547]
21Feb12_142942| [ 0.61879 -0.90920]
21Feb12_142942| [ 0.67984 -0.25623]
21Feb12_142942| [-0.28837  0.43629]
21Feb12_142942| [-1.08202  0.55318]
21Feb12_142942| [-0.31999  0.11075]
21Feb12_142942| [ 0.20228  0.80637]
21Feb12_142942| [ 1.18759  0.53496]
21Feb12_142942| [ 0.90767 -0.54768]
21Feb12_142942| [-0.04074 -0.34023]
21Feb12_142942| [-0.01048 -0.78582]
21Feb12_142942| [-1.24714  0.33030]
21Feb12_142942| [-0.43642  0.23841]
21Feb12_142942| [-0.71652  0.74987]
21Feb12_142942| [-0.06681  0.69165]
21Feb12_142942| [ 0.67229 -0.62662]
21Feb12_142942| [-0.04327 -0.88245]
21Feb12_142942| [-0.56785  0.43564]
21Feb12_142942| [-1.19669 -0.92456]
21Feb12_142942| [ 0.88074 -0.34189]
21Feb12_142942| [-0.37089  0.37628]
21Feb12_142942| [-0.47467  0.33949]
21Feb12_142942| [-0.85890  0.21259]
21Feb12_142942| [-0.87568 -0.55763]
21Feb12_142942| [-0.13669 -0.06907]
21Feb12_142942| [-0.94063  0.39268]
21Feb12_142942| [ 1.10667 -0.47605]
21Feb12_142942| [ 1.32877  0.84990]
21Feb12_142942| [ 0.88675 -1.37478]
21Feb12_142942| [-0.00196 -0.10654]
21Feb12_142942| [-0.26972  0.42252]
21Feb12_142942| [ 0.46597  0.15688]
21Feb12_142942| [ 0.16470  0.33818]
21Feb12_142942| [-0.83135  0.52175]
21Feb12_142942| [ 0.30230 -0.07531]
21Feb12_142942| [-1.24999  0.25559]]
21Feb12_142942|-- Bias --
21Feb12_142942|[ 0.47675 -0.84795]
21Feb12_142942|Layer 1:
21Feb12_142942|-- Config --
21Feb12_142942|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_142942|-- Weights --
21Feb12_142942|[[-0.16807 -0.20404]
21Feb12_142942| [ 1.14186 -0.87134]]
21Feb12_142942|-- Bias --
21Feb12_142942|[-0.11042  0.35882]
21Feb12_142942|Predicting the validation and test data with the Best final individual.
21Feb12_142949| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_142949|-----------  ------------------  --------------------  ----------
21Feb12_142949|Validation         38.78                  2             0.00000
21Feb12_142949|   Test            39.01                  2             0.00000
21Feb12_142949|-------------------- Test #4 --------------------
21Feb12_142949|Best final individual weights
21Feb12_142949|Individual:
21Feb12_142949|-- Constant hidden layers --
21Feb12_142949|False
21Feb12_142949|Layer 0:
21Feb12_142949|-- Config --
21Feb12_142949|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_142949|-- Weights --
21Feb12_142949|[[ 0.21414  0.52544]
21Feb12_142949| [ 0.05169  0.56268]
21Feb12_142949| [ 0.39643 -0.36944]
21Feb12_142949| [ 0.75139 -0.39262]
21Feb12_142949| [-0.65666 -0.35567]
21Feb12_142949| [ 0.76973 -0.23402]
21Feb12_142949| [ 0.52152  0.55960]
21Feb12_142949| [-0.28808  1.29313]
21Feb12_142949| [ 1.13623 -0.33404]
21Feb12_142949| [ 0.72011  0.57863]
21Feb12_142949| [-0.82677 -0.17911]
21Feb12_142949| [ 0.67247 -0.90114]
21Feb12_142949| [-0.94435 -0.40129]
21Feb12_142949| [ 0.38205 -0.27091]
21Feb12_142949| [ 0.88609 -0.63414]
21Feb12_142949| [ 0.06280 -0.38041]
21Feb12_142949| [-0.55605 -1.10806]
21Feb12_142949| [ 0.05986 -0.90362]
21Feb12_142949| [-1.03054  0.35910]
21Feb12_142949| [ 0.24710  0.65959]
21Feb12_142949| [-0.40237  0.02352]
21Feb12_142949| [ 0.08333  0.13547]
21Feb12_142949| [ 0.61879 -0.90920]
21Feb12_142949| [ 0.67984 -0.25623]
21Feb12_142949| [-0.28837  0.43629]
21Feb12_142949| [-1.08202  0.55318]
21Feb12_142949| [-0.31999  0.11075]
21Feb12_142949| [ 0.20228  0.80637]
21Feb12_142949| [ 1.18759  0.53496]
21Feb12_142949| [ 0.90767 -0.54768]
21Feb12_142949| [-0.04074 -0.34023]
21Feb12_142949| [-0.01048 -0.78582]
21Feb12_142949| [-1.24714  0.33030]
21Feb12_142949| [-0.43642  0.23841]
21Feb12_142949| [-0.71652  0.74987]
21Feb12_142949| [-0.06681  0.69165]
21Feb12_142949| [ 0.67229 -0.62662]
21Feb12_142949| [-0.04327 -0.88245]
21Feb12_142949| [-0.56785  0.43564]
21Feb12_142949| [-1.19669 -0.92456]
21Feb12_142949| [ 0.88074 -0.34189]
21Feb12_142949| [-0.37089  0.37628]
21Feb12_142949| [-0.47467  0.33949]
21Feb12_142949| [-0.85890  0.21259]
21Feb12_142949| [-0.87568 -0.55763]
21Feb12_142949| [-0.13669 -0.06907]
21Feb12_142949| [-0.94063  0.39268]
21Feb12_142949| [ 1.10667 -0.47605]
21Feb12_142949| [ 1.32877  0.84990]
21Feb12_142949| [ 0.88675 -1.37478]
21Feb12_142949| [-0.00196 -0.10654]
21Feb12_142949| [-0.26972  0.42252]
21Feb12_142949| [ 0.46597  0.15688]
21Feb12_142949| [ 0.16470  0.33818]
21Feb12_142949| [-0.83135  0.52175]
21Feb12_142949| [ 0.30230 -0.07531]
21Feb12_142949| [-1.24999  0.25559]]
21Feb12_142949|-- Bias --
21Feb12_142949|[ 0.47675 -0.84795]
21Feb12_142949|Layer 1:
21Feb12_142949|-- Config --
21Feb12_142949|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_142949|-- Weights --
21Feb12_142949|[[-0.16807 -0.20404]
21Feb12_142949| [ 1.14186 -0.87134]]
21Feb12_142949|-- Bias --
21Feb12_142949|[-0.11042  0.35882]
21Feb12_142949|Predicting the validation and test data with the Best final individual.
21Feb12_142956| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_142956|-----------  ------------------  --------------------  ----------
21Feb12_142956|Validation         38.78                  2             0.00000
21Feb12_142956|   Test            39.01                  2             0.00000
21Feb12_142956|-------------------- Test #5 --------------------
21Feb12_142956|Best final individual weights
21Feb12_142956|Individual:
21Feb12_142956|-- Constant hidden layers --
21Feb12_142956|False
21Feb12_142956|Layer 0:
21Feb12_142956|-- Config --
21Feb12_142956|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_142956|-- Weights --
21Feb12_142956|[[ 0.21414  0.52544]
21Feb12_142956| [ 0.05169  0.56268]
21Feb12_142956| [ 0.39643 -0.36944]
21Feb12_142956| [ 0.75139 -0.39262]
21Feb12_142956| [-0.65666 -0.35567]
21Feb12_142956| [ 0.76973 -0.23402]
21Feb12_142956| [ 0.52152  0.55960]
21Feb12_142956| [-0.28808  1.29313]
21Feb12_142956| [ 1.13623 -0.33404]
21Feb12_142956| [ 0.72011  0.57863]
21Feb12_142956| [-0.82677 -0.17911]
21Feb12_142956| [ 0.67247 -0.90114]
21Feb12_142956| [-0.94435 -0.40129]
21Feb12_142956| [ 0.38205 -0.27091]
21Feb12_142956| [ 0.88609 -0.63414]
21Feb12_142956| [ 0.06280 -0.38041]
21Feb12_142956| [-0.55605 -1.10806]
21Feb12_142956| [ 0.05986 -0.90362]
21Feb12_142956| [-1.03054  0.35910]
21Feb12_142956| [ 0.24710  0.65959]
21Feb12_142956| [-0.40237  0.02352]
21Feb12_142956| [ 0.08333  0.13547]
21Feb12_142956| [ 0.61879 -0.90920]
21Feb12_142956| [ 0.67984 -0.25623]
21Feb12_142956| [-0.28837  0.43629]
21Feb12_142956| [-1.08202  0.55318]
21Feb12_142956| [-0.31999  0.11075]
21Feb12_142956| [ 0.20228  0.80637]
21Feb12_142956| [ 1.18759  0.53496]
21Feb12_142956| [ 0.90767 -0.54768]
21Feb12_142956| [-0.04074 -0.34023]
21Feb12_142956| [-0.01048 -0.78582]
21Feb12_142956| [-1.24714  0.33030]
21Feb12_142956| [-0.43642  0.23841]
21Feb12_142956| [-0.71652  0.74987]
21Feb12_142956| [-0.06681  0.69165]
21Feb12_142956| [ 0.67229 -0.62662]
21Feb12_142956| [-0.04327 -0.88245]
21Feb12_142956| [-0.56785  0.43564]
21Feb12_142956| [-1.19669 -0.92456]
21Feb12_142956| [ 0.88074 -0.34189]
21Feb12_142956| [-0.37089  0.37628]
21Feb12_142956| [-0.47467  0.33949]
21Feb12_142956| [-0.85890  0.21259]
21Feb12_142956| [-0.87568 -0.55763]
21Feb12_142956| [-0.13669 -0.06907]
21Feb12_142956| [-0.94063  0.39268]
21Feb12_142956| [ 1.10667 -0.47605]
21Feb12_142956| [ 1.32877  0.84990]
21Feb12_142956| [ 0.88675 -1.37478]
21Feb12_142956| [-0.00196 -0.10654]
21Feb12_142956| [-0.26972  0.42252]
21Feb12_142956| [ 0.46597  0.15688]
21Feb12_142956| [ 0.16470  0.33818]
21Feb12_142956| [-0.83135  0.52175]
21Feb12_142956| [ 0.30230 -0.07531]
21Feb12_142956| [-1.24999  0.25559]]
21Feb12_142956|-- Bias --
21Feb12_142956|[ 0.47675 -0.84795]
21Feb12_142956|Layer 1:
21Feb12_142956|-- Config --
21Feb12_142956|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_142956|-- Weights --
21Feb12_142956|[[-0.16807 -0.20404]
21Feb12_142956| [ 1.14186 -0.87134]]
21Feb12_142956|-- Bias --
21Feb12_142956|[-0.11042  0.35882]
21Feb12_142956|Predicting the validation and test data with the Best final individual.
21Feb12_143003| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_143003|-----------  ------------------  --------------------  ----------
21Feb12_143003|Validation         38.78                  2             0.00000
21Feb12_143003|   Test            39.01                  2             0.00000
21Feb12_143003|-------------------- Test #6 --------------------
21Feb12_143003|Best final individual weights
21Feb12_143003|Individual:
21Feb12_143003|-- Constant hidden layers --
21Feb12_143003|False
21Feb12_143003|Layer 0:
21Feb12_143003|-- Config --
21Feb12_143003|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_143003|-- Weights --
21Feb12_143003|[[ 0.21414  0.52544]
21Feb12_143003| [ 0.05169  0.56268]
21Feb12_143003| [ 0.39643 -0.36944]
21Feb12_143003| [ 0.75139 -0.39262]
21Feb12_143003| [-0.65666 -0.35567]
21Feb12_143003| [ 0.76973 -0.23402]
21Feb12_143003| [ 0.52152  0.55960]
21Feb12_143003| [-0.28808  1.29313]
21Feb12_143003| [ 1.13623 -0.33404]
21Feb12_143003| [ 0.72011  0.57863]
21Feb12_143003| [-0.82677 -0.17911]
21Feb12_143003| [ 0.67247 -0.90114]
21Feb12_143003| [-0.94435 -0.40129]
21Feb12_143003| [ 0.38205 -0.27091]
21Feb12_143003| [ 0.88609 -0.63414]
21Feb12_143003| [ 0.06280 -0.38041]
21Feb12_143003| [-0.55605 -1.10806]
21Feb12_143003| [ 0.05986 -0.90362]
21Feb12_143003| [-1.03054  0.35910]
21Feb12_143003| [ 0.24710  0.65959]
21Feb12_143003| [-0.40237  0.02352]
21Feb12_143003| [ 0.08333  0.13547]
21Feb12_143003| [ 0.61879 -0.90920]
21Feb12_143003| [ 0.67984 -0.25623]
21Feb12_143003| [-0.28837  0.43629]
21Feb12_143003| [-1.08202  0.55318]
21Feb12_143003| [-0.31999  0.11075]
21Feb12_143003| [ 0.20228  0.80637]
21Feb12_143003| [ 1.18759  0.53496]
21Feb12_143003| [ 0.90767 -0.54768]
21Feb12_143003| [-0.04074 -0.34023]
21Feb12_143003| [-0.01048 -0.78582]
21Feb12_143003| [-1.24714  0.33030]
21Feb12_143003| [-0.43642  0.23841]
21Feb12_143003| [-0.71652  0.74987]
21Feb12_143003| [-0.06681  0.69165]
21Feb12_143003| [ 0.67229 -0.62662]
21Feb12_143003| [-0.04327 -0.88245]
21Feb12_143003| [-0.56785  0.43564]
21Feb12_143003| [-1.19669 -0.92456]
21Feb12_143003| [ 0.88074 -0.34189]
21Feb12_143003| [-0.37089  0.37628]
21Feb12_143003| [-0.47467  0.33949]
21Feb12_143003| [-0.85890  0.21259]
21Feb12_143003| [-0.87568 -0.55763]
21Feb12_143003| [-0.13669 -0.06907]
21Feb12_143003| [-0.94063  0.39268]
21Feb12_143003| [ 1.10667 -0.47605]
21Feb12_143003| [ 1.32877  0.84990]
21Feb12_143003| [ 0.88675 -1.37478]
21Feb12_143003| [-0.00196 -0.10654]
21Feb12_143003| [-0.26972  0.42252]
21Feb12_143003| [ 0.46597  0.15688]
21Feb12_143003| [ 0.16470  0.33818]
21Feb12_143003| [-0.83135  0.52175]
21Feb12_143003| [ 0.30230 -0.07531]
21Feb12_143003| [-1.24999  0.25559]]
21Feb12_143003|-- Bias --
21Feb12_143003|[ 0.47675 -0.84795]
21Feb12_143003|Layer 1:
21Feb12_143003|-- Config --
21Feb12_143003|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_143003|-- Weights --
21Feb12_143003|[[-0.16807 -0.20404]
21Feb12_143003| [ 1.14186 -0.87134]]
21Feb12_143003|-- Bias --
21Feb12_143003|[-0.11042  0.35882]
21Feb12_143003|Predicting the validation and test data with the Best final individual.
21Feb12_143010| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_143010|-----------  ------------------  --------------------  ----------
21Feb12_143010|Validation         38.78                  2             0.00000
21Feb12_143010|   Test            39.01                  2             0.00000
21Feb12_143010|-------------------- Test #7 --------------------
21Feb12_143010|Best final individual weights
21Feb12_143010|Individual:
21Feb12_143010|-- Constant hidden layers --
21Feb12_143010|False
21Feb12_143010|Layer 0:
21Feb12_143010|-- Config --
21Feb12_143010|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_143010|-- Weights --
21Feb12_143010|[[ 0.21414  0.52544]
21Feb12_143010| [ 0.05169  0.56268]
21Feb12_143010| [ 0.39643 -0.36944]
21Feb12_143010| [ 0.75139 -0.39262]
21Feb12_143010| [-0.65666 -0.35567]
21Feb12_143010| [ 0.76973 -0.23402]
21Feb12_143010| [ 0.52152  0.55960]
21Feb12_143010| [-0.28808  1.29313]
21Feb12_143010| [ 1.13623 -0.33404]
21Feb12_143010| [ 0.72011  0.57863]
21Feb12_143010| [-0.82677 -0.17911]
21Feb12_143010| [ 0.67247 -0.90114]
21Feb12_143010| [-0.94435 -0.40129]
21Feb12_143010| [ 0.38205 -0.27091]
21Feb12_143010| [ 0.88609 -0.63414]
21Feb12_143010| [ 0.06280 -0.38041]
21Feb12_143010| [-0.55605 -1.10806]
21Feb12_143010| [ 0.05986 -0.90362]
21Feb12_143010| [-1.03054  0.35910]
21Feb12_143010| [ 0.24710  0.65959]
21Feb12_143010| [-0.40237  0.02352]
21Feb12_143010| [ 0.08333  0.13547]
21Feb12_143010| [ 0.61879 -0.90920]
21Feb12_143010| [ 0.67984 -0.25623]
21Feb12_143010| [-0.28837  0.43629]
21Feb12_143010| [-1.08202  0.55318]
21Feb12_143010| [-0.31999  0.11075]
21Feb12_143010| [ 0.20228  0.80637]
21Feb12_143010| [ 1.18759  0.53496]
21Feb12_143010| [ 0.90767 -0.54768]
21Feb12_143010| [-0.04074 -0.34023]
21Feb12_143010| [-0.01048 -0.78582]
21Feb12_143010| [-1.24714  0.33030]
21Feb12_143010| [-0.43642  0.23841]
21Feb12_143010| [-0.71652  0.74987]
21Feb12_143010| [-0.06681  0.69165]
21Feb12_143010| [ 0.67229 -0.62662]
21Feb12_143010| [-0.04327 -0.88245]
21Feb12_143010| [-0.56785  0.43564]
21Feb12_143010| [-1.19669 -0.92456]
21Feb12_143010| [ 0.88074 -0.34189]
21Feb12_143010| [-0.37089  0.37628]
21Feb12_143010| [-0.47467  0.33949]
21Feb12_143010| [-0.85890  0.21259]
21Feb12_143010| [-0.87568 -0.55763]
21Feb12_143010| [-0.13669 -0.06907]
21Feb12_143010| [-0.94063  0.39268]
21Feb12_143010| [ 1.10667 -0.47605]
21Feb12_143010| [ 1.32877  0.84990]
21Feb12_143010| [ 0.88675 -1.37478]
21Feb12_143010| [-0.00196 -0.10654]
21Feb12_143010| [-0.26972  0.42252]
21Feb12_143010| [ 0.46597  0.15688]
21Feb12_143010| [ 0.16470  0.33818]
21Feb12_143010| [-0.83135  0.52175]
21Feb12_143010| [ 0.30230 -0.07531]
21Feb12_143010| [-1.24999  0.25559]]
21Feb12_143010|-- Bias --
21Feb12_143010|[ 0.47675 -0.84795]
21Feb12_143010|Layer 1:
21Feb12_143010|-- Config --
21Feb12_143010|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_143010|-- Weights --
21Feb12_143010|[[-0.16807 -0.20404]
21Feb12_143010| [ 1.14186 -0.87134]]
21Feb12_143010|-- Bias --
21Feb12_143010|[-0.11042  0.35882]
21Feb12_143010|Predicting the validation and test data with the Best final individual.
21Feb12_143017| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_143017|-----------  ------------------  --------------------  ----------
21Feb12_143017|Validation         38.78                  2             0.00000
21Feb12_143017|   Test            39.01                  2             0.00000
21Feb12_143017|-------------------- Test #8 --------------------
21Feb12_143017|Best final individual weights
21Feb12_143017|Individual:
21Feb12_143017|-- Constant hidden layers --
21Feb12_143017|False
21Feb12_143017|Layer 0:
21Feb12_143017|-- Config --
21Feb12_143017|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_143017|-- Weights --
21Feb12_143017|[[ 0.21414  0.52544]
21Feb12_143017| [ 0.05169  0.56268]
21Feb12_143017| [ 0.39643 -0.36944]
21Feb12_143017| [ 0.75139 -0.39262]
21Feb12_143017| [-0.65666 -0.35567]
21Feb12_143017| [ 0.76973 -0.23402]
21Feb12_143017| [ 0.52152  0.55960]
21Feb12_143017| [-0.28808  1.29313]
21Feb12_143017| [ 1.13623 -0.33404]
21Feb12_143017| [ 0.72011  0.57863]
21Feb12_143017| [-0.82677 -0.17911]
21Feb12_143017| [ 0.67247 -0.90114]
21Feb12_143017| [-0.94435 -0.40129]
21Feb12_143017| [ 0.38205 -0.27091]
21Feb12_143017| [ 0.88609 -0.63414]
21Feb12_143017| [ 0.06280 -0.38041]
21Feb12_143017| [-0.55605 -1.10806]
21Feb12_143017| [ 0.05986 -0.90362]
21Feb12_143017| [-1.03054  0.35910]
21Feb12_143017| [ 0.24710  0.65959]
21Feb12_143017| [-0.40237  0.02352]
21Feb12_143017| [ 0.08333  0.13547]
21Feb12_143017| [ 0.61879 -0.90920]
21Feb12_143017| [ 0.67984 -0.25623]
21Feb12_143017| [-0.28837  0.43629]
21Feb12_143017| [-1.08202  0.55318]
21Feb12_143017| [-0.31999  0.11075]
21Feb12_143017| [ 0.20228  0.80637]
21Feb12_143017| [ 1.18759  0.53496]
21Feb12_143017| [ 0.90767 -0.54768]
21Feb12_143017| [-0.04074 -0.34023]
21Feb12_143017| [-0.01048 -0.78582]
21Feb12_143017| [-1.24714  0.33030]
21Feb12_143017| [-0.43642  0.23841]
21Feb12_143017| [-0.71652  0.74987]
21Feb12_143017| [-0.06681  0.69165]
21Feb12_143017| [ 0.67229 -0.62662]
21Feb12_143017| [-0.04327 -0.88245]
21Feb12_143017| [-0.56785  0.43564]
21Feb12_143017| [-1.19669 -0.92456]
21Feb12_143017| [ 0.88074 -0.34189]
21Feb12_143017| [-0.37089  0.37628]
21Feb12_143017| [-0.47467  0.33949]
21Feb12_143017| [-0.85890  0.21259]
21Feb12_143017| [-0.87568 -0.55763]
21Feb12_143017| [-0.13669 -0.06907]
21Feb12_143017| [-0.94063  0.39268]
21Feb12_143017| [ 1.10667 -0.47605]
21Feb12_143017| [ 1.32877  0.84990]
21Feb12_143017| [ 0.88675 -1.37478]
21Feb12_143017| [-0.00196 -0.10654]
21Feb12_143017| [-0.26972  0.42252]
21Feb12_143017| [ 0.46597  0.15688]
21Feb12_143017| [ 0.16470  0.33818]
21Feb12_143017| [-0.83135  0.52175]
21Feb12_143017| [ 0.30230 -0.07531]
21Feb12_143017| [-1.24999  0.25559]]
21Feb12_143017|-- Bias --
21Feb12_143017|[ 0.47675 -0.84795]
21Feb12_143017|Layer 1:
21Feb12_143017|-- Config --
21Feb12_143017|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_143017|-- Weights --
21Feb12_143017|[[-0.16807 -0.20404]
21Feb12_143017| [ 1.14186 -0.87134]]
21Feb12_143017|-- Bias --
21Feb12_143017|[-0.11042  0.35882]
21Feb12_143017|Predicting the validation and test data with the Best final individual.
21Feb12_143025| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_143025|-----------  ------------------  --------------------  ----------
21Feb12_143025|Validation         38.78                  2             0.00000
21Feb12_143025|   Test            39.01                  2             0.00000
21Feb12_143025|-------------------- Test #9 --------------------
21Feb12_143025|Best final individual weights
21Feb12_143025|Individual:
21Feb12_143025|-- Constant hidden layers --
21Feb12_143025|False
21Feb12_143025|Layer 0:
21Feb12_143025|-- Config --
21Feb12_143025|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_143025|-- Weights --
21Feb12_143025|[[ 0.21414  0.52544]
21Feb12_143025| [ 0.05169  0.56268]
21Feb12_143025| [ 0.39643 -0.36944]
21Feb12_143025| [ 0.75139 -0.39262]
21Feb12_143025| [-0.65666 -0.35567]
21Feb12_143025| [ 0.76973 -0.23402]
21Feb12_143025| [ 0.52152  0.55960]
21Feb12_143025| [-0.28808  1.29313]
21Feb12_143025| [ 1.13623 -0.33404]
21Feb12_143025| [ 0.72011  0.57863]
21Feb12_143025| [-0.82677 -0.17911]
21Feb12_143025| [ 0.67247 -0.90114]
21Feb12_143025| [-0.94435 -0.40129]
21Feb12_143025| [ 0.38205 -0.27091]
21Feb12_143025| [ 0.88609 -0.63414]
21Feb12_143025| [ 0.06280 -0.38041]
21Feb12_143025| [-0.55605 -1.10806]
21Feb12_143025| [ 0.05986 -0.90362]
21Feb12_143025| [-1.03054  0.35910]
21Feb12_143025| [ 0.24710  0.65959]
21Feb12_143025| [-0.40237  0.02352]
21Feb12_143025| [ 0.08333  0.13547]
21Feb12_143025| [ 0.61879 -0.90920]
21Feb12_143025| [ 0.67984 -0.25623]
21Feb12_143025| [-0.28837  0.43629]
21Feb12_143025| [-1.08202  0.55318]
21Feb12_143025| [-0.31999  0.11075]
21Feb12_143025| [ 0.20228  0.80637]
21Feb12_143025| [ 1.18759  0.53496]
21Feb12_143025| [ 0.90767 -0.54768]
21Feb12_143025| [-0.04074 -0.34023]
21Feb12_143025| [-0.01048 -0.78582]
21Feb12_143025| [-1.24714  0.33030]
21Feb12_143025| [-0.43642  0.23841]
21Feb12_143025| [-0.71652  0.74987]
21Feb12_143025| [-0.06681  0.69165]
21Feb12_143025| [ 0.67229 -0.62662]
21Feb12_143025| [-0.04327 -0.88245]
21Feb12_143025| [-0.56785  0.43564]
21Feb12_143025| [-1.19669 -0.92456]
21Feb12_143025| [ 0.88074 -0.34189]
21Feb12_143025| [-0.37089  0.37628]
21Feb12_143025| [-0.47467  0.33949]
21Feb12_143025| [-0.85890  0.21259]
21Feb12_143025| [-0.87568 -0.55763]
21Feb12_143025| [-0.13669 -0.06907]
21Feb12_143025| [-0.94063  0.39268]
21Feb12_143025| [ 1.10667 -0.47605]
21Feb12_143025| [ 1.32877  0.84990]
21Feb12_143025| [ 0.88675 -1.37478]
21Feb12_143025| [-0.00196 -0.10654]
21Feb12_143025| [-0.26972  0.42252]
21Feb12_143025| [ 0.46597  0.15688]
21Feb12_143025| [ 0.16470  0.33818]
21Feb12_143025| [-0.83135  0.52175]
21Feb12_143025| [ 0.30230 -0.07531]
21Feb12_143025| [-1.24999  0.25559]]
21Feb12_143025|-- Bias --
21Feb12_143025|[ 0.47675 -0.84795]
21Feb12_143025|Layer 1:
21Feb12_143025|-- Config --
21Feb12_143025|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_143025|-- Weights --
21Feb12_143025|[[-0.16807 -0.20404]
21Feb12_143025| [ 1.14186 -0.87134]]
21Feb12_143025|-- Bias --
21Feb12_143025|[-0.11042  0.35882]
21Feb12_143025|Predicting the validation and test data with the Best final individual.
21Feb12_143032| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_143032|-----------  ------------------  --------------------  ----------
21Feb12_143032|Validation         38.78                  2             0.00000
21Feb12_143032|   Test            39.01                  2             0.00000
21Feb12_143032|-------------------- Test #10 --------------------
21Feb12_143032|Best final individual weights
21Feb12_143032|Individual:
21Feb12_143032|-- Constant hidden layers --
21Feb12_143032|False
21Feb12_143032|Layer 0:
21Feb12_143032|-- Config --
21Feb12_143032|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_143032|-- Weights --
21Feb12_143032|[[ 0.21414  0.52544]
21Feb12_143032| [ 0.05169  0.56268]
21Feb12_143032| [ 0.39643 -0.36944]
21Feb12_143032| [ 0.75139 -0.39262]
21Feb12_143032| [-0.65666 -0.35567]
21Feb12_143032| [ 0.76973 -0.23402]
21Feb12_143032| [ 0.52152  0.55960]
21Feb12_143032| [-0.28808  1.29313]
21Feb12_143032| [ 1.13623 -0.33404]
21Feb12_143032| [ 0.72011  0.57863]
21Feb12_143032| [-0.82677 -0.17911]
21Feb12_143032| [ 0.67247 -0.90114]
21Feb12_143032| [-0.94435 -0.40129]
21Feb12_143032| [ 0.38205 -0.27091]
21Feb12_143032| [ 0.88609 -0.63414]
21Feb12_143032| [ 0.06280 -0.38041]
21Feb12_143032| [-0.55605 -1.10806]
21Feb12_143032| [ 0.05986 -0.90362]
21Feb12_143032| [-1.03054  0.35910]
21Feb12_143032| [ 0.24710  0.65959]
21Feb12_143032| [-0.40237  0.02352]
21Feb12_143032| [ 0.08333  0.13547]
21Feb12_143032| [ 0.61879 -0.90920]
21Feb12_143032| [ 0.67984 -0.25623]
21Feb12_143032| [-0.28837  0.43629]
21Feb12_143032| [-1.08202  0.55318]
21Feb12_143032| [-0.31999  0.11075]
21Feb12_143032| [ 0.20228  0.80637]
21Feb12_143032| [ 1.18759  0.53496]
21Feb12_143032| [ 0.90767 -0.54768]
21Feb12_143032| [-0.04074 -0.34023]
21Feb12_143032| [-0.01048 -0.78582]
21Feb12_143032| [-1.24714  0.33030]
21Feb12_143032| [-0.43642  0.23841]
21Feb12_143032| [-0.71652  0.74987]
21Feb12_143032| [-0.06681  0.69165]
21Feb12_143032| [ 0.67229 -0.62662]
21Feb12_143032| [-0.04327 -0.88245]
21Feb12_143032| [-0.56785  0.43564]
21Feb12_143032| [-1.19669 -0.92456]
21Feb12_143032| [ 0.88074 -0.34189]
21Feb12_143032| [-0.37089  0.37628]
21Feb12_143032| [-0.47467  0.33949]
21Feb12_143032| [-0.85890  0.21259]
21Feb12_143032| [-0.87568 -0.55763]
21Feb12_143032| [-0.13669 -0.06907]
21Feb12_143032| [-0.94063  0.39268]
21Feb12_143032| [ 1.10667 -0.47605]
21Feb12_143032| [ 1.32877  0.84990]
21Feb12_143032| [ 0.88675 -1.37478]
21Feb12_143032| [-0.00196 -0.10654]
21Feb12_143032| [-0.26972  0.42252]
21Feb12_143032| [ 0.46597  0.15688]
21Feb12_143032| [ 0.16470  0.33818]
21Feb12_143032| [-0.83135  0.52175]
21Feb12_143032| [ 0.30230 -0.07531]
21Feb12_143032| [-1.24999  0.25559]]
21Feb12_143032|-- Bias --
21Feb12_143032|[ 0.47675 -0.84795]
21Feb12_143032|Layer 1:
21Feb12_143032|-- Config --
21Feb12_143032|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_143032|-- Weights --
21Feb12_143032|[[-0.16807 -0.20404]
21Feb12_143032| [ 1.14186 -0.87134]]
21Feb12_143032|-- Bias --
21Feb12_143032|[-0.11042  0.35882]
21Feb12_143032|Predicting the validation and test data with the Best final individual.
21Feb12_143039| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_143039|-----------  ------------------  --------------------  ----------
21Feb12_143039|Validation         38.78                  2             0.00000
21Feb12_143039|   Test            39.01                  2             0.00000
21Feb12_143039|-------------------- Test #11 --------------------
21Feb12_143039|Best final individual weights
21Feb12_143039|Individual:
21Feb12_143039|-- Constant hidden layers --
21Feb12_143039|False
21Feb12_143039|Layer 0:
21Feb12_143039|-- Config --
21Feb12_143039|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_143039|-- Weights --
21Feb12_143039|[[ 0.21414  0.52544]
21Feb12_143039| [ 0.05169  0.56268]
21Feb12_143039| [ 0.39643 -0.36944]
21Feb12_143039| [ 0.75139 -0.39262]
21Feb12_143039| [-0.65666 -0.35567]
21Feb12_143039| [ 0.76973 -0.23402]
21Feb12_143039| [ 0.52152  0.55960]
21Feb12_143039| [-0.28808  1.29313]
21Feb12_143039| [ 1.13623 -0.33404]
21Feb12_143039| [ 0.72011  0.57863]
21Feb12_143039| [-0.82677 -0.17911]
21Feb12_143039| [ 0.67247 -0.90114]
21Feb12_143039| [-0.94435 -0.40129]
21Feb12_143039| [ 0.38205 -0.27091]
21Feb12_143039| [ 0.88609 -0.63414]
21Feb12_143039| [ 0.06280 -0.38041]
21Feb12_143039| [-0.55605 -1.10806]
21Feb12_143039| [ 0.05986 -0.90362]
21Feb12_143039| [-1.03054  0.35910]
21Feb12_143039| [ 0.24710  0.65959]
21Feb12_143039| [-0.40237  0.02352]
21Feb12_143039| [ 0.08333  0.13547]
21Feb12_143039| [ 0.61879 -0.90920]
21Feb12_143039| [ 0.67984 -0.25623]
21Feb12_143039| [-0.28837  0.43629]
21Feb12_143039| [-1.08202  0.55318]
21Feb12_143039| [-0.31999  0.11075]
21Feb12_143039| [ 0.20228  0.80637]
21Feb12_143039| [ 1.18759  0.53496]
21Feb12_143039| [ 0.90767 -0.54768]
21Feb12_143039| [-0.04074 -0.34023]
21Feb12_143039| [-0.01048 -0.78582]
21Feb12_143039| [-1.24714  0.33030]
21Feb12_143039| [-0.43642  0.23841]
21Feb12_143039| [-0.71652  0.74987]
21Feb12_143039| [-0.06681  0.69165]
21Feb12_143039| [ 0.67229 -0.62662]
21Feb12_143039| [-0.04327 -0.88245]
21Feb12_143039| [-0.56785  0.43564]
21Feb12_143039| [-1.19669 -0.92456]
21Feb12_143039| [ 0.88074 -0.34189]
21Feb12_143039| [-0.37089  0.37628]
21Feb12_143039| [-0.47467  0.33949]
21Feb12_143039| [-0.85890  0.21259]
21Feb12_143039| [-0.87568 -0.55763]
21Feb12_143039| [-0.13669 -0.06907]
21Feb12_143039| [-0.94063  0.39268]
21Feb12_143039| [ 1.10667 -0.47605]
21Feb12_143039| [ 1.32877  0.84990]
21Feb12_143039| [ 0.88675 -1.37478]
21Feb12_143039| [-0.00196 -0.10654]
21Feb12_143039| [-0.26972  0.42252]
21Feb12_143039| [ 0.46597  0.15688]
21Feb12_143039| [ 0.16470  0.33818]
21Feb12_143039| [-0.83135  0.52175]
21Feb12_143039| [ 0.30230 -0.07531]
21Feb12_143039| [-1.24999  0.25559]]
21Feb12_143039|-- Bias --
21Feb12_143039|[ 0.47675 -0.84795]
21Feb12_143039|Layer 1:
21Feb12_143039|-- Config --
21Feb12_143039|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_143039|-- Weights --
21Feb12_143039|[[-0.16807 -0.20404]
21Feb12_143039| [ 1.14186 -0.87134]]
21Feb12_143039|-- Bias --
21Feb12_143039|[-0.11042  0.35882]
21Feb12_143039|Predicting the validation and test data with the Best final individual.
21Feb12_143046| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_143046|-----------  ------------------  --------------------  ----------
21Feb12_143046|Validation         38.78                  2             0.00000
21Feb12_143046|   Test            39.01                  2             0.00000
21Feb12_143046|-------------------- Test #12 --------------------
21Feb12_143046|Best final individual weights
21Feb12_143046|Individual:
21Feb12_143046|-- Constant hidden layers --
21Feb12_143046|False
21Feb12_143046|Layer 0:
21Feb12_143046|-- Config --
21Feb12_143046|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_143046|-- Weights --
21Feb12_143046|[[ 0.21414  0.52544]
21Feb12_143046| [ 0.05169  0.56268]
21Feb12_143046| [ 0.39643 -0.36944]
21Feb12_143046| [ 0.75139 -0.39262]
21Feb12_143046| [-0.65666 -0.35567]
21Feb12_143046| [ 0.76973 -0.23402]
21Feb12_143046| [ 0.52152  0.55960]
21Feb12_143046| [-0.28808  1.29313]
21Feb12_143046| [ 1.13623 -0.33404]
21Feb12_143046| [ 0.72011  0.57863]
21Feb12_143046| [-0.82677 -0.17911]
21Feb12_143046| [ 0.67247 -0.90114]
21Feb12_143046| [-0.94435 -0.40129]
21Feb12_143046| [ 0.38205 -0.27091]
21Feb12_143046| [ 0.88609 -0.63414]
21Feb12_143046| [ 0.06280 -0.38041]
21Feb12_143046| [-0.55605 -1.10806]
21Feb12_143046| [ 0.05986 -0.90362]
21Feb12_143046| [-1.03054  0.35910]
21Feb12_143046| [ 0.24710  0.65959]
21Feb12_143046| [-0.40237  0.02352]
21Feb12_143046| [ 0.08333  0.13547]
21Feb12_143046| [ 0.61879 -0.90920]
21Feb12_143046| [ 0.67984 -0.25623]
21Feb12_143046| [-0.28837  0.43629]
21Feb12_143046| [-1.08202  0.55318]
21Feb12_143046| [-0.31999  0.11075]
21Feb12_143046| [ 0.20228  0.80637]
21Feb12_143046| [ 1.18759  0.53496]
21Feb12_143046| [ 0.90767 -0.54768]
21Feb12_143046| [-0.04074 -0.34023]
21Feb12_143046| [-0.01048 -0.78582]
21Feb12_143046| [-1.24714  0.33030]
21Feb12_143046| [-0.43642  0.23841]
21Feb12_143046| [-0.71652  0.74987]
21Feb12_143046| [-0.06681  0.69165]
21Feb12_143046| [ 0.67229 -0.62662]
21Feb12_143046| [-0.04327 -0.88245]
21Feb12_143046| [-0.56785  0.43564]
21Feb12_143046| [-1.19669 -0.92456]
21Feb12_143046| [ 0.88074 -0.34189]
21Feb12_143046| [-0.37089  0.37628]
21Feb12_143046| [-0.47467  0.33949]
21Feb12_143046| [-0.85890  0.21259]
21Feb12_143046| [-0.87568 -0.55763]
21Feb12_143046| [-0.13669 -0.06907]
21Feb12_143046| [-0.94063  0.39268]
21Feb12_143046| [ 1.10667 -0.47605]
21Feb12_143046| [ 1.32877  0.84990]
21Feb12_143046| [ 0.88675 -1.37478]
21Feb12_143046| [-0.00196 -0.10654]
21Feb12_143046| [-0.26972  0.42252]
21Feb12_143046| [ 0.46597  0.15688]
21Feb12_143046| [ 0.16470  0.33818]
21Feb12_143046| [-0.83135  0.52175]
21Feb12_143046| [ 0.30230 -0.07531]
21Feb12_143046| [-1.24999  0.25559]]
21Feb12_143046|-- Bias --
21Feb12_143046|[ 0.47675 -0.84795]
21Feb12_143046|Layer 1:
21Feb12_143046|-- Config --
21Feb12_143046|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_143046|-- Weights --
21Feb12_143046|[[-0.16807 -0.20404]
21Feb12_143046| [ 1.14186 -0.87134]]
21Feb12_143046|-- Bias --
21Feb12_143046|[-0.11042  0.35882]
21Feb12_143046|Predicting the validation and test data with the Best final individual.
21Feb12_143053| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_143053|-----------  ------------------  --------------------  ----------
21Feb12_143053|Validation         38.78                  2             0.00000
21Feb12_143053|   Test            39.01                  2             0.00000
21Feb12_143053|-------------------- Test #13 --------------------
21Feb12_143053|Best final individual weights
21Feb12_143053|Individual:
21Feb12_143053|-- Constant hidden layers --
21Feb12_143053|False
21Feb12_143053|Layer 0:
21Feb12_143053|-- Config --
21Feb12_143053|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_143053|-- Weights --
21Feb12_143053|[[ 0.21414  0.52544]
21Feb12_143053| [ 0.05169  0.56268]
21Feb12_143053| [ 0.39643 -0.36944]
21Feb12_143053| [ 0.75139 -0.39262]
21Feb12_143053| [-0.65666 -0.35567]
21Feb12_143053| [ 0.76973 -0.23402]
21Feb12_143053| [ 0.52152  0.55960]
21Feb12_143053| [-0.28808  1.29313]
21Feb12_143053| [ 1.13623 -0.33404]
21Feb12_143053| [ 0.72011  0.57863]
21Feb12_143053| [-0.82677 -0.17911]
21Feb12_143053| [ 0.67247 -0.90114]
21Feb12_143053| [-0.94435 -0.40129]
21Feb12_143053| [ 0.38205 -0.27091]
21Feb12_143053| [ 0.88609 -0.63414]
21Feb12_143053| [ 0.06280 -0.38041]
21Feb12_143053| [-0.55605 -1.10806]
21Feb12_143053| [ 0.05986 -0.90362]
21Feb12_143053| [-1.03054  0.35910]
21Feb12_143053| [ 0.24710  0.65959]
21Feb12_143053| [-0.40237  0.02352]
21Feb12_143053| [ 0.08333  0.13547]
21Feb12_143053| [ 0.61879 -0.90920]
21Feb12_143053| [ 0.67984 -0.25623]
21Feb12_143053| [-0.28837  0.43629]
21Feb12_143053| [-1.08202  0.55318]
21Feb12_143053| [-0.31999  0.11075]
21Feb12_143053| [ 0.20228  0.80637]
21Feb12_143053| [ 1.18759  0.53496]
21Feb12_143053| [ 0.90767 -0.54768]
21Feb12_143053| [-0.04074 -0.34023]
21Feb12_143053| [-0.01048 -0.78582]
21Feb12_143053| [-1.24714  0.33030]
21Feb12_143053| [-0.43642  0.23841]
21Feb12_143053| [-0.71652  0.74987]
21Feb12_143053| [-0.06681  0.69165]
21Feb12_143053| [ 0.67229 -0.62662]
21Feb12_143053| [-0.04327 -0.88245]
21Feb12_143053| [-0.56785  0.43564]
21Feb12_143053| [-1.19669 -0.92456]
21Feb12_143053| [ 0.88074 -0.34189]
21Feb12_143053| [-0.37089  0.37628]
21Feb12_143053| [-0.47467  0.33949]
21Feb12_143053| [-0.85890  0.21259]
21Feb12_143053| [-0.87568 -0.55763]
21Feb12_143053| [-0.13669 -0.06907]
21Feb12_143053| [-0.94063  0.39268]
21Feb12_143053| [ 1.10667 -0.47605]
21Feb12_143053| [ 1.32877  0.84990]
21Feb12_143053| [ 0.88675 -1.37478]
21Feb12_143053| [-0.00196 -0.10654]
21Feb12_143053| [-0.26972  0.42252]
21Feb12_143053| [ 0.46597  0.15688]
21Feb12_143053| [ 0.16470  0.33818]
21Feb12_143053| [-0.83135  0.52175]
21Feb12_143053| [ 0.30230 -0.07531]
21Feb12_143053| [-1.24999  0.25559]]
21Feb12_143053|-- Bias --
21Feb12_143053|[ 0.47675 -0.84795]
21Feb12_143053|Layer 1:
21Feb12_143053|-- Config --
21Feb12_143053|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_143053|-- Weights --
21Feb12_143053|[[-0.16807 -0.20404]
21Feb12_143053| [ 1.14186 -0.87134]]
21Feb12_143053|-- Bias --
21Feb12_143053|[-0.11042  0.35882]
21Feb12_143053|Predicting the validation and test data with the Best final individual.
21Feb12_143100| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_143100|-----------  ------------------  --------------------  ----------
21Feb12_143100|Validation         38.78                  2             0.00000
21Feb12_143100|   Test            39.01                  2             0.00000
21Feb12_143100|-------------------- Test #14 --------------------
21Feb12_143100|Best final individual weights
21Feb12_143100|Individual:
21Feb12_143100|-- Constant hidden layers --
21Feb12_143100|False
21Feb12_143100|Layer 0:
21Feb12_143100|-- Config --
21Feb12_143100|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_143100|-- Weights --
21Feb12_143100|[[ 0.21414  0.52544]
21Feb12_143100| [ 0.05169  0.56268]
21Feb12_143100| [ 0.39643 -0.36944]
21Feb12_143100| [ 0.75139 -0.39262]
21Feb12_143100| [-0.65666 -0.35567]
21Feb12_143100| [ 0.76973 -0.23402]
21Feb12_143100| [ 0.52152  0.55960]
21Feb12_143100| [-0.28808  1.29313]
21Feb12_143100| [ 1.13623 -0.33404]
21Feb12_143100| [ 0.72011  0.57863]
21Feb12_143100| [-0.82677 -0.17911]
21Feb12_143100| [ 0.67247 -0.90114]
21Feb12_143100| [-0.94435 -0.40129]
21Feb12_143100| [ 0.38205 -0.27091]
21Feb12_143100| [ 0.88609 -0.63414]
21Feb12_143100| [ 0.06280 -0.38041]
21Feb12_143100| [-0.55605 -1.10806]
21Feb12_143100| [ 0.05986 -0.90362]
21Feb12_143100| [-1.03054  0.35910]
21Feb12_143100| [ 0.24710  0.65959]
21Feb12_143100| [-0.40237  0.02352]
21Feb12_143100| [ 0.08333  0.13547]
21Feb12_143100| [ 0.61879 -0.90920]
21Feb12_143100| [ 0.67984 -0.25623]
21Feb12_143100| [-0.28837  0.43629]
21Feb12_143100| [-1.08202  0.55318]
21Feb12_143100| [-0.31999  0.11075]
21Feb12_143100| [ 0.20228  0.80637]
21Feb12_143100| [ 1.18759  0.53496]
21Feb12_143100| [ 0.90767 -0.54768]
21Feb12_143100| [-0.04074 -0.34023]
21Feb12_143100| [-0.01048 -0.78582]
21Feb12_143100| [-1.24714  0.33030]
21Feb12_143100| [-0.43642  0.23841]
21Feb12_143100| [-0.71652  0.74987]
21Feb12_143100| [-0.06681  0.69165]
21Feb12_143100| [ 0.67229 -0.62662]
21Feb12_143100| [-0.04327 -0.88245]
21Feb12_143100| [-0.56785  0.43564]
21Feb12_143100| [-1.19669 -0.92456]
21Feb12_143100| [ 0.88074 -0.34189]
21Feb12_143100| [-0.37089  0.37628]
21Feb12_143100| [-0.47467  0.33949]
21Feb12_143100| [-0.85890  0.21259]
21Feb12_143100| [-0.87568 -0.55763]
21Feb12_143100| [-0.13669 -0.06907]
21Feb12_143100| [-0.94063  0.39268]
21Feb12_143100| [ 1.10667 -0.47605]
21Feb12_143100| [ 1.32877  0.84990]
21Feb12_143100| [ 0.88675 -1.37478]
21Feb12_143100| [-0.00196 -0.10654]
21Feb12_143100| [-0.26972  0.42252]
21Feb12_143100| [ 0.46597  0.15688]
21Feb12_143100| [ 0.16470  0.33818]
21Feb12_143100| [-0.83135  0.52175]
21Feb12_143100| [ 0.30230 -0.07531]
21Feb12_143100| [-1.24999  0.25559]]
21Feb12_143100|-- Bias --
21Feb12_143100|[ 0.47675 -0.84795]
21Feb12_143100|Layer 1:
21Feb12_143100|-- Config --
21Feb12_143100|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_143100|-- Weights --
21Feb12_143100|[[-0.16807 -0.20404]
21Feb12_143100| [ 1.14186 -0.87134]]
21Feb12_143100|-- Bias --
21Feb12_143100|[-0.11042  0.35882]
21Feb12_143100|Predicting the validation and test data with the Best final individual.
21Feb12_143107| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_143107|-----------  ------------------  --------------------  ----------
21Feb12_143107|Validation         38.78                  2             0.00000
21Feb12_143107|   Test            39.01                  2             0.00000
2021-02-12 14:31:08.228832: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
21Feb12_143109|Data summary: Train
21Feb12_143109|data.shape = (2300, 57)
21Feb12_143109|labels.shape = (2300,)
21Feb12_143109|Class distribution:
21Feb12_143109|	0 - 1382 (0.60)
21Feb12_143109|	1 - 918 (0.40)
21Feb12_143109|Data summary: Validation
21Feb12_143109|data.shape = (1150, 57)
21Feb12_143109|labels.shape = (1150,)
21Feb12_143109|Class distribution:
21Feb12_143109|	0 - 704 (0.61)
21Feb12_143109|	1 - 446 (0.39)
21Feb12_143109|Data summary: Test
21Feb12_143109|data.shape = (1151, 57)
21Feb12_143109|labels.shape = (1151,)
21Feb12_143109|Class distribution:
21Feb12_143109|	0 - 702 (0.61)
21Feb12_143109|	1 - 449 (0.39)
21Feb12_143109|Selected configuration values
21Feb12_143109|-- Dataset name: spambase1
21Feb12_143109|-- Initial population size: 64
21Feb12_143109|-- Maximun number of generations: 32
21Feb12_143109|-- Neurons per hidden layer range: (2, 20)
21Feb12_143109|-- Hidden layers number range: (1, 3)
21Feb12_143109|-- Crossover probability: 0.5
21Feb12_143109|-- Bias gene mutation probability: 0.2
21Feb12_143109|-- Weights gene mutation probability: 0.75
21Feb12_143109|-- Neuron mutation probability: 0.3
21Feb12_143109|-- Layer mutation probability: 0.3
21Feb12_143109|-- Constant hidden layers: False
21Feb12_143109|-- Seed: 31415
21Feb12_143109|Entering GA
21Feb12_143109|Start the algorithm
2021-02-12 14:31:09.107670: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-12 14:31:09.108248: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-02-12 14:31:09.131317: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-12 14:31:09.131658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.71GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s
2021-02-12 14:31:09.131675: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-02-12 14:31:09.133157: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-02-12 14:31:09.133190: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-02-12 14:31:09.133698: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-02-12 14:31:09.133830: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-02-12 14:31:09.133901: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-12 14:31:09.134379: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-02-12 14:31:09.134426: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-12 14:31:09.134432: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-02-12 14:31:09.134678: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-02-12 14:31:09.135612: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-12 14:31:09.135647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-12 14:31:09.135658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      
2021-02-12 14:31:09.190343: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-02-12 14:31:09.190696: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3493635000 Hz
/home/jmerelo/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype("int32")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn('`model.predict_classes()` is deprecated and '
21Feb12_143515|-- Generation 1 --
21Feb12_143515|    -- Crossed 0 individual pairs.
21Feb12_143515|    -- Mutated 32 individuals.
21Feb12_143920|    -- Evaluated 64 individuals.
21Feb12_143920|    Summary of generation 1:
21Feb12_143920| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_143920|-----------  ------------------  --------------------  ----------
21Feb12_143920|    Max            39.48                144.00          0.55529
21Feb12_143920|    Avg            38.67                50.50           0.00868
21Feb12_143920|    Min            26.17                 3.00           0.00000
21Feb12_143920|    Std             1.58                41.10           0.06887
21Feb12_143920|   Best            26.17                11.00           0.55529
21Feb12_143920|-- Generation 2 --
21Feb12_143920|    -- Crossed 5 individual pairs.
21Feb12_143920|    -- Mutated 32 individuals.
21Feb12_144321|    -- Evaluated 64 individuals.
21Feb12_144321|    Summary of generation 2:
21Feb12_144321| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_144321|-----------  ------------------  --------------------  ----------
21Feb12_144321|    Max            39.57                81.00           0.56291
21Feb12_144321|    Avg            38.57                30.00           0.01371
21Feb12_144321|    Min            26.09                 3.00           0.00000
21Feb12_144321|    Std             1.73                25.94           0.07756
21Feb12_144321|   Best            26.09                12.00           0.56291
21Feb12_144321|-- Generation 3 --
21Feb12_144321|    -- Crossed 3 individual pairs.
21Feb12_144321|    -- Mutated 32 individuals.
21Feb12_144719|    -- Evaluated 64 individuals.
21Feb12_144719|    Summary of generation 3:
21Feb12_144719| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_144719|-----------  ------------------  --------------------  ----------
21Feb12_144719|    Max            39.57                54.00           0.75340
21Feb12_144719|    Avg            37.89                18.52           0.05720
21Feb12_144719|    Min            23.91                 2.00           0.00000
21Feb12_144719|    Std             3.26                15.40           0.18498
21Feb12_144719|   Best            23.91                14.00           0.64256
21Feb12_144719|-- Generation 4 --
21Feb12_144719|    -- Crossed 2 individual pairs.
21Feb12_144719|    -- Mutated 32 individuals.
21Feb12_145115|    -- Evaluated 64 individuals.
21Feb12_145115|    Summary of generation 4:
21Feb12_145115| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_145115|-----------  ------------------  --------------------  ----------
21Feb12_145115|    Max            54.87                45.00           0.77945
21Feb12_145115|    Avg            38.61                11.06           0.03644
21Feb12_145115|    Min            28.43                 2.00           0.00000
21Feb12_145115|    Std             2.79                10.37           0.14109
21Feb12_145115|   Best            28.43                16.00           0.36866
21Feb12_145115|-- Generation 5 --
21Feb12_145115|    -- Crossed 5 individual pairs.
21Feb12_145115|    -- Mutated 32 individuals.
21Feb12_145509|    -- Evaluated 64 individuals.
21Feb12_145509|    Summary of generation 5:
21Feb12_145509| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_145509|-----------  ------------------  --------------------  ----------
21Feb12_145509|    Max            55.39                24.00           0.79216
21Feb12_145509|    Avg            38.46                 8.00           0.04761
21Feb12_145509|    Min            25.22                 2.00           0.00000
21Feb12_145509|    Std             3.11                 5.82           0.15718
21Feb12_145509|   Best            25.22                14.00           0.49705
21Feb12_145509|-- Generation 6 --
21Feb12_145509|    -- Crossed 6 individual pairs.
21Feb12_145509|    -- Mutated 32 individuals.
21Feb12_145903|    -- Evaluated 64 individuals.
21Feb12_145903|    Summary of generation 6:
21Feb12_145903| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_145903|-----------  ------------------  --------------------  ----------
21Feb12_145903|    Max            39.13                36.00           0.66300
21Feb12_145903|    Avg            37.58                 8.19           0.05136
21Feb12_145903|    Min            23.39                 2.00           0.00000
21Feb12_145903|    Std             3.76                 7.36           0.15765
21Feb12_145903|   Best            23.39                14.00           0.55070
21Feb12_145903|-- Generation 7 --
21Feb12_145903|    -- Crossed 7 individual pairs.
21Feb12_145903|    -- Mutated 32 individuals.
21Feb12_150257|    -- Evaluated 64 individuals.
21Feb12_150257|    Summary of generation 7:
21Feb12_150257| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_150257|-----------  ------------------  --------------------  ----------
21Feb12_150257|    Max            53.30                38.00           0.78438
21Feb12_150257|    Avg            38.09                 7.86           0.05705
21Feb12_150257|    Min            24.61                 2.00           0.00000
21Feb12_150257|    Std             3.66                 7.55           0.17045
21Feb12_150257|   Best            24.61                14.00           0.51834
21Feb12_150257|-- Generation 8 --
21Feb12_150257|    -- Crossed 8 individual pairs.
21Feb12_150257|    -- Mutated 32 individuals.
21Feb12_150651|    -- Evaluated 64 individuals.
21Feb12_150651|    Summary of generation 8:
21Feb12_150651| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_150651|-----------  ------------------  --------------------  ----------
21Feb12_150651|    Max            47.22                38.00           0.80296
21Feb12_150651|    Avg            37.73                 7.72           0.06238
21Feb12_150651|    Min            23.83                 2.00           0.00000
21Feb12_150651|    Std             3.93                 7.89           0.17795
21Feb12_150651|   Best            23.83                14.00           0.64114
21Feb12_150651|-- Generation 9 --
21Feb12_150651|    -- Crossed 6 individual pairs.
21Feb12_150651|    -- Mutated 32 individuals.
21Feb12_151045|    -- Evaluated 64 individuals.
21Feb12_151045|    Summary of generation 9:
21Feb12_151045| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_151045|-----------  ------------------  --------------------  ----------
21Feb12_151045|    Max            39.04                42.00           0.69057
21Feb12_151045|    Avg            37.22                 6.67           0.06771
21Feb12_151045|    Min            25.48                 2.00           0.00000
21Feb12_151045|    Std             4.13                 7.12           0.17788
21Feb12_151045|   Best            25.48                14.00           0.55926
21Feb12_151045|-- Generation 10 --
21Feb12_151045|    -- Crossed 7 individual pairs.
21Feb12_151045|    -- Mutated 32 individuals.
21Feb12_151439|    -- Evaluated 64 individuals.
21Feb12_151439|    Summary of generation 10:
21Feb12_151439| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_151439|-----------  ------------------  --------------------  ----------
21Feb12_151439|    Max            56.96                42.00           0.77296
21Feb12_151439|    Avg            37.80                 8.09           0.06276
21Feb12_151439|    Min            23.57                 2.00           0.00000
21Feb12_151439|    Std             4.51                 9.00           0.17560
21Feb12_151439|   Best            23.57                14.00           0.65397
21Feb12_151439|-- Generation 11 --
21Feb12_151439|    -- Crossed 7 individual pairs.
21Feb12_151439|    -- Mutated 32 individuals.
21Feb12_151834|    -- Evaluated 64 individuals.
21Feb12_151834|    Summary of generation 11:
21Feb12_151834| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_151834|-----------  ------------------  --------------------  ----------
21Feb12_151834|    Max            39.22                39.00           0.74937
21Feb12_151834|    Avg            37.92                 7.14           0.04618
21Feb12_151834|    Min            25.48                 2.00           0.00000
21Feb12_151834|    Std             3.04                 7.75           0.16263
21Feb12_151834|   Best            25.48                16.00           0.54811
21Feb12_151834|-- Generation 12 --
21Feb12_151834|    -- Crossed 2 individual pairs.
21Feb12_151834|    -- Mutated 32 individuals.
21Feb12_152227|    -- Evaluated 64 individuals.
21Feb12_152227|    Summary of generation 12:
21Feb12_152227| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_152227|-----------  ------------------  --------------------  ----------
21Feb12_152227|    Max            38.87                42.00           0.80453
21Feb12_152227|    Avg            37.03                 6.44           0.09733
21Feb12_152227|    Min            25.04                 2.00           0.00000
21Feb12_152227|    Std             4.22                 8.15           0.22065
21Feb12_152227|   Best            25.04                14.00           0.52478
21Feb12_152227|-- Generation 13 --
21Feb12_152227|    -- Crossed 7 individual pairs.
21Feb12_152227|    -- Mutated 32 individuals.
21Feb12_152622|    -- Evaluated 64 individuals.
21Feb12_152622|    Summary of generation 13:
21Feb12_152622| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_152622|-----------  ------------------  --------------------  ----------
21Feb12_152622|    Max            39.30                39.00           0.84593
21Feb12_152622|    Avg            37.00                 7.66           0.07632
21Feb12_152622|    Min            24.43                 2.00           0.00000
21Feb12_152622|    Std             4.46                 8.62           0.19077
21Feb12_152622|   Best            24.43                12.00           0.61129
21Feb12_152622|-- Generation 14 --
21Feb12_152622|    -- Crossed 5 individual pairs.
21Feb12_152622|    -- Mutated 32 individuals.
21Feb12_153018|    -- Evaluated 64 individuals.
21Feb12_153018|    Summary of generation 14:
21Feb12_153018| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_153018|-----------  ------------------  --------------------  ----------
21Feb12_153018|    Max            39.04                39.00           0.83960
21Feb12_153018|    Avg            37.15                 8.39           0.06552
21Feb12_153018|    Min            21.91                 2.00           0.00000
21Feb12_153018|    Std             4.38                 9.18           0.17955
21Feb12_153018|   Best            21.91                30.00           0.83960
21Feb12_153018|-- Generation 15 --
21Feb12_153018|    -- Crossed 7 individual pairs.
21Feb12_153018|    -- Mutated 32 individuals.
21Feb12_153414|    -- Evaluated 64 individuals.
21Feb12_153414|    Summary of generation 15:
21Feb12_153414| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_153414|-----------  ------------------  --------------------  ----------
21Feb12_153414|    Max            48.52                56.00           0.79496
21Feb12_153414|    Avg            37.02                 8.27           0.09775
21Feb12_153414|    Min            24.52                 2.00           0.00000
21Feb12_153414|    Std             4.65                10.96           0.21136
21Feb12_153414|   Best            24.52                30.00           0.64560
21Feb12_153414|-- Generation 16 --
21Feb12_153414|    -- Crossed 3 individual pairs.
21Feb12_153414|    -- Mutated 32 individuals.
21Feb12_153811|    -- Evaluated 64 individuals.
21Feb12_153811|    Summary of generation 16:
21Feb12_153811| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_153811|-----------  ------------------  --------------------  ----------
21Feb12_153811|    Max            39.04                60.00           0.82461
21Feb12_153811|    Avg            35.54                11.73           0.15383
21Feb12_153811|    Min            22.61                 2.00           0.00000
21Feb12_153811|    Std             5.75                12.97           0.27447
21Feb12_153811|   Best            22.61                30.00           0.79127
21Feb12_153811|-- Generation 17 --
21Feb12_153811|    -- Crossed 4 individual pairs.
21Feb12_153811|    -- Mutated 32 individuals.
21Feb12_154210|    -- Evaluated 64 individuals.
21Feb12_154210|    Summary of generation 17:
21Feb12_154210| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_154210|-----------  ------------------  --------------------  ----------
21Feb12_154210|    Max            41.74                60.00           0.81676
21Feb12_154210|    Avg            35.21                15.17           0.16519
21Feb12_154210|    Min            20.35                 2.00           0.00000
21Feb12_154210|    Std             5.59                15.99           0.26072
21Feb12_154210|   Best            20.35                33.00           0.72493
21Feb12_154210|-- Generation 18 --
21Feb12_154210|    -- Crossed 1 individual pairs.
21Feb12_154210|    -- Mutated 32 individuals.
21Feb12_154611|    -- Evaluated 64 individuals.
21Feb12_154611|    Summary of generation 18:
21Feb12_154611| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_154611|-----------  ------------------  --------------------  ----------
21Feb12_154611|    Max            44.17                75.00           0.78059
21Feb12_154611|    Avg            35.38                18.05           0.15629
21Feb12_154611|    Min            22.43                 2.00           0.00000
21Feb12_154611|    Std             5.93                17.47           0.26741
21Feb12_154611|   Best            22.43                27.00           0.73919
21Feb12_154611|-- Generation 19 --
21Feb12_154611|    -- Crossed 2 individual pairs.
21Feb12_154611|    -- Mutated 32 individuals.
21Feb12_155012|    -- Evaluated 64 individuals.
21Feb12_155012|    Summary of generation 19:
21Feb12_155012| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_155012|-----------  ------------------  --------------------  ----------
21Feb12_155012|    Max            38.96                60.00           0.77383
21Feb12_155012|    Avg            35.41                15.83           0.16833
21Feb12_155012|    Min            22.87                 2.00           0.00000
21Feb12_155012|    Std             5.69                15.88           0.28570
21Feb12_155012|   Best            22.87                27.00           0.74529
21Feb12_155012|-- Generation 20 --
21Feb12_155012|    -- Crossed 2 individual pairs.
21Feb12_155012|    -- Mutated 32 individuals.
21Feb12_155411|    -- Evaluated 64 individuals.
21Feb12_155411|    Summary of generation 20:
21Feb12_155411| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_155411|-----------  ------------------  --------------------  ----------
21Feb12_155411|    Max            39.22                60.00           0.79910
21Feb12_155411|    Avg            34.67                15.50           0.20107
21Feb12_155411|    Min            23.13                 2.00           0.00000
21Feb12_155411|    Std             6.01                16.12           0.29776
21Feb12_155411|   Best            23.13                27.00           0.70982
21Feb12_155411|-- Generation 21 --
21Feb12_155411|    -- Crossed 3 individual pairs.
21Feb12_155411|    -- Mutated 32 individuals.
21Feb12_155812|    -- Evaluated 64 individuals.
21Feb12_155812|    Summary of generation 21:
21Feb12_155812| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_155812|-----------  ------------------  --------------------  ----------
21Feb12_155812|    Max            40.17                90.00           0.83432
21Feb12_155812|    Avg            34.21                16.70           0.22035
21Feb12_155812|    Min            20.35                 2.00           0.00000
21Feb12_155812|    Std             6.44                16.83           0.30406
21Feb12_155812|   Best            20.35                27.00           0.71688
21Feb12_155812|-- Generation 22 --
21Feb12_155812|    -- Crossed 2 individual pairs.
21Feb12_155812|    -- Mutated 32 individuals.
21Feb12_160214|    -- Evaluated 64 individuals.
21Feb12_160214|    Summary of generation 22:
21Feb12_160214| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_160214|-----------  ------------------  --------------------  ----------
21Feb12_160214|    Max            41.22                60.00           0.81218
21Feb12_160214|    Avg            34.16                17.95           0.21506
21Feb12_160214|    Min            22.43                 2.00           0.00000
21Feb12_160214|    Std             6.29                15.41           0.29360
21Feb12_160214|   Best            22.43                27.00           0.81218
21Feb12_160214|-- Generation 23 --
21Feb12_160214|    -- Crossed 4 individual pairs.
21Feb12_160214|    -- Mutated 32 individuals.
21Feb12_160619|    -- Evaluated 64 individuals.
21Feb12_160619|    Summary of generation 23:
21Feb12_160619| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_160619|-----------  ------------------  --------------------  ----------
21Feb12_160619|    Max            41.65                80.00           0.82195
21Feb12_160619|    Avg            32.78                23.91           0.28896
21Feb12_160619|    Min            20.96                 2.00           0.00000
21Feb12_160619|    Std             6.56                18.75           0.30307
21Feb12_160619|   Best            20.96                60.00           0.75409
21Feb12_160619|-- Generation 24 --
21Feb12_160619|    -- Crossed 1 individual pairs.
21Feb12_160619|    -- Mutated 32 individuals.
21Feb12_161027|    -- Evaluated 64 individuals.
21Feb12_161027|    Summary of generation 24:
21Feb12_161027| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_161027|-----------  ------------------  --------------------  ----------
21Feb12_161027|    Max            39.30                100.00          0.79378
21Feb12_161027|    Avg            31.42                30.45           0.34153
21Feb12_161027|    Min            21.91                 3.00           0.00000
21Feb12_161027|    Std             6.39                23.35           0.30400
21Feb12_161027|   Best            21.91                60.00           0.78071
21Feb12_161027|-- Generation 25 --
21Feb12_161027|    -- Crossed 1 individual pairs.
21Feb12_161027|    -- Mutated 32 individuals.
21Feb12_161437|    -- Evaluated 64 individuals.
21Feb12_161437|    Summary of generation 25:
21Feb12_161437| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_161437|-----------  ------------------  --------------------  ----------
21Feb12_161437|    Max            39.13                85.00           0.77976
21Feb12_161437|    Avg            33.03                32.80           0.28817
21Feb12_161437|    Min            21.39                 3.00           0.00000
21Feb12_161437|    Std             6.48                23.39           0.31908
21Feb12_161437|   Best            21.39                60.00           0.77976
21Feb12_161437|-- Generation 26 --
21Feb12_161437|    -- Crossed 0 individual pairs.
21Feb12_161437|    -- Mutated 32 individuals.
21Feb12_161849|    -- Evaluated 64 individuals.
21Feb12_161849|    Summary of generation 26:
21Feb12_161849| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_161849|-----------  ------------------  --------------------  ----------
21Feb12_161849|    Max            39.74                126.00          0.79433
21Feb12_161849|    Avg            31.85                36.84           0.35422
21Feb12_161849|    Min            21.83                 4.00           0.00000
21Feb12_161849|    Std             6.53                27.88           0.32296
21Feb12_161849|   Best            21.83                64.00           0.71941
21Feb12_161849|-- Generation 27 --
21Feb12_161849|    -- Crossed 0 individual pairs.
21Feb12_161849|    -- Mutated 32 individuals.
21Feb12_162306|    -- Evaluated 64 individuals.
21Feb12_162306|    Summary of generation 27:
21Feb12_162306| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_162306|-----------  ------------------  --------------------  ----------
21Feb12_162306|    Max            38.87                100.00          0.79692
21Feb12_162306|    Avg            32.17                44.66           0.32892
21Feb12_162306|    Min            22.35                10.00           0.00000
21Feb12_162306|    Std             6.41                27.46           0.31649
21Feb12_162306|   Best            22.35                80.00           0.77605
21Feb12_162306|-- Generation 28 --
21Feb12_162306|    -- Crossed 0 individual pairs.
21Feb12_162306|    -- Mutated 32 individuals.
21Feb12_162722|    -- Evaluated 64 individuals.
21Feb12_162722|    Summary of generation 28:
21Feb12_162722| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_162722|-----------  ------------------  --------------------  ----------
21Feb12_162722|    Max            38.96                95.00           0.80577
21Feb12_162722|    Avg            30.90                42.27           0.38962
21Feb12_162722|    Min            22.61                10.00           0.00000
21Feb12_162722|    Std             6.19                24.92           0.30425
21Feb12_162722|   Best            22.61                80.00           0.80577
21Feb12_162722|-- Generation 29 --
21Feb12_162722|    -- Crossed 1 individual pairs.
21Feb12_162722|    -- Mutated 32 individuals.
21Feb12_163139|    -- Evaluated 64 individuals.
21Feb12_163139|    Summary of generation 29:
21Feb12_163139| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_163139|-----------  ------------------  --------------------  ----------
21Feb12_163139|    Max            47.04                108.00          0.79616
21Feb12_163139|    Avg            31.27                46.00           0.37829
21Feb12_163139|    Min            21.48                12.00           0.00000
21Feb12_163139|    Std             6.76                27.48           0.31581
21Feb12_163139|   Best            21.48                108.00          0.74123
21Feb12_163139|-- Generation 30 --
21Feb12_163139|    -- Crossed 0 individual pairs.
21Feb12_163139|    -- Mutated 32 individuals.
21Feb12_163555|    -- Evaluated 64 individuals.
21Feb12_163555|    Summary of generation 30:
21Feb12_163555| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_163555|-----------  ------------------  --------------------  ----------
21Feb12_163555|    Max            39.30                126.00          0.81621
21Feb12_163555|    Avg            31.82                46.45           0.33968
21Feb12_163555|    Min            24.00                 3.00           0.00000
21Feb12_163555|    Std             6.24                30.38           0.30816
21Feb12_163555|   Best            24.00                30.00           0.70347
21Feb12_163555|-- Generation 31 --
21Feb12_163555|    -- Crossed 0 individual pairs.
21Feb12_163555|    -- Mutated 32 individuals.
21Feb12_164013|    -- Evaluated 64 individuals.
21Feb12_164013|    Summary of generation 31:
21Feb12_164013| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_164013|-----------  ------------------  --------------------  ----------
21Feb12_164013|    Max            38.96                161.00          0.78578
21Feb12_164013|    Avg            30.97                53.64           0.35215
21Feb12_164013|    Min            20.78                12.00           0.00000
21Feb12_164013|    Std             6.54                34.79           0.30644
21Feb12_164013|   Best            20.78                80.00           0.69234
21Feb12_164013|-- Generation 32 --
21Feb12_164013|    -- Crossed 0 individual pairs.
21Feb12_164013|    -- Mutated 32 individuals.
21Feb12_164433|    -- Evaluated 64 individuals.
21Feb12_164433|    Summary of generation 32:
21Feb12_164433| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_164433|-----------  ------------------  --------------------  ----------
21Feb12_164433|    Max            38.78                168.00          0.82133
21Feb12_164433|    Avg            29.93                55.88           0.40897
21Feb12_164433|    Min            21.48                12.00           0.00000
21Feb12_164433|    Std             6.34                36.49           0.30017
21Feb12_164433|   Best            21.48                80.00           0.65612
21Feb12_164433|Best initial individual weights
21Feb12_164433|Individual:
21Feb12_164433|-- Constant hidden layers --
21Feb12_164433|False
21Feb12_164433|Layer 0:
21Feb12_164433|-- Config --
21Feb12_164433|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 20, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164433|-- Weights --
21Feb12_164433|[[-0.81530 -0.38125 -0.79998 ... -0.70263 -0.61840  0.66571]
21Feb12_164433| [ 0.65866  0.85470 -0.58802 ... -0.96520  0.62924 -0.99993]
21Feb12_164433| [ 0.82861 -0.31058 -0.15077 ... -0.37206  0.28605  0.29356]
21Feb12_164433| ...
21Feb12_164433| [-0.22356 -0.17240 -0.31428 ... -0.22545  0.94699 -0.71943]
21Feb12_164433| [-0.37773 -0.75933 -0.69490 ... -0.90595 -0.69780 -0.98315]
21Feb12_164433| [ 0.65818 -0.25813 -0.28240 ...  0.35891  0.55911  0.45607]]
21Feb12_164433|-- Bias --
21Feb12_164433|[-0.66607 -0.45412 -0.47565  0.95426  0.37266  0.71643 -0.83233 -0.59141
21Feb12_164433| -0.57925 -0.35895  0.07388  0.17038  0.31672  0.81171  0.30057  0.54611
21Feb12_164433| -0.62651  0.24482  0.64224 -0.28752]
21Feb12_164433|Layer 1:
21Feb12_164433|-- Config --
21Feb12_164433|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 20], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164433|-- Weights --
21Feb12_164433|[[ 0.42040 -0.26492]
21Feb12_164433| [ 0.78679  0.01829]
21Feb12_164433| [ 0.85426  0.35026]
21Feb12_164433| [ 0.63200 -0.62249]
21Feb12_164433| [-0.55346 -0.80586]
21Feb12_164433| [-0.61224  0.86991]
21Feb12_164433| [-0.47486 -0.31648]
21Feb12_164433| [ 0.53818 -0.22812]
21Feb12_164433| [-0.74035 -0.70516]
21Feb12_164433| [-0.47742 -0.04703]
21Feb12_164433| [ 0.68440 -0.93557]
21Feb12_164433| [-0.18841 -0.56741]
21Feb12_164433| [-0.08233  0.51743]
21Feb12_164433| [ 0.43051 -0.46386]
21Feb12_164433| [ 0.67964  0.15665]
21Feb12_164433| [-0.10319 -0.36290]
21Feb12_164433| [-0.23955  0.64790]
21Feb12_164433| [-0.84563 -0.92413]
21Feb12_164433| [ 0.53642 -0.52099]
21Feb12_164433| [ 0.03906 -0.94604]]
21Feb12_164433|-- Bias --
21Feb12_164433|[ 0.50157 -0.93861]
21Feb12_164433|Predicting the validation and test data with the Best initial individual.
21Feb12_164440| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_164440|-----------  ------------------  --------------------  ----------
21Feb12_164440|Validation         38.96                  20            0.00000
21Feb12_164440|   Test            38.66                  20            0.01387
21Feb12_164440|-------------------- Test #0 --------------------
21Feb12_164440|Best final individual weights
21Feb12_164440|Individual:
21Feb12_164440|-- Constant hidden layers --
21Feb12_164440|False
21Feb12_164440|Layer 0:
21Feb12_164440|-- Config --
21Feb12_164440|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164440|-- Weights --
21Feb12_164440|[[-7.91355e-01  2.43120e+00 -8.07061e-01 -3.94286e-01  3.19125e-01]
21Feb12_164440| [ 6.32169e-01  1.11702e+00  4.18321e-01  1.42293e+00 -7.32555e-02]
21Feb12_164440| [-3.48284e-02  1.24559e+00  2.44475e-02  8.48326e-01 -4.64233e-01]
21Feb12_164440| [ 1.17440e+00  3.81583e-01  2.14959e+00  2.13845e-01  1.46366e-01]
21Feb12_164440| [ 4.44159e-01 -1.12940e-02  5.13247e-01 -6.29180e-01 -2.98321e-01]
21Feb12_164440| [ 1.37424e+00 -1.43437e+00 -6.44080e-01  1.41356e+00  2.98025e-01]
21Feb12_164440| [-7.67760e-01  7.93907e-01 -5.67129e-01  1.19634e+00  1.52366e-01]
21Feb12_164440| [-7.08021e-02 -1.80961e+00  1.04882e+00 -1.67209e+00 -2.72411e-01]
21Feb12_164440| [-1.39134e-01 -5.77581e-01  5.25041e-01  1.42652e+00  1.03720e-01]
21Feb12_164440| [-1.07529e+00  3.55062e-02 -2.17335e+00  2.19168e-01  8.29057e-02]
21Feb12_164440| [-4.45037e-01 -4.03228e-01 -2.01532e-01  8.77376e-01  2.81343e-01]
21Feb12_164440| [ 7.19570e-01 -6.79061e-01 -1.60597e-01  8.08258e-01 -3.25257e-01]
21Feb12_164440| [-5.31401e-01  4.04345e-01  1.93758e+00 -4.60418e-01  4.68916e-01]
21Feb12_164440| [-2.13940e-01 -4.75579e-02 -1.36023e+00 -1.19475e-01 -2.31293e-01]
21Feb12_164440| [ 7.36033e-01 -8.15896e-01 -4.37717e-01  1.67296e+00 -1.20651e-01]
21Feb12_164440| [ 7.16388e-01  1.04087e+00 -1.07113e+00  2.07376e+00  1.83025e-01]
21Feb12_164440| [-5.72677e-01 -1.52863e-01  6.40245e-01 -1.37548e-01  2.41768e-01]
21Feb12_164440| [-2.01843e+00 -5.99701e-01 -1.32540e+00  2.25850e-01 -2.56690e-01]
21Feb12_164440| [-4.10261e-01 -8.13422e-01 -4.48009e-01 -3.61940e-01  4.67163e-02]
21Feb12_164440| [ 5.31285e-01  8.03485e-01  4.18423e-01 -2.97820e-01  3.11368e-01]
21Feb12_164440| [ 3.61796e-01 -9.21000e-01 -5.44164e-01 -1.38174e+00  1.80521e-01]
21Feb12_164440| [-4.75496e-01  9.05014e-01  2.36627e+00 -4.94079e-02 -3.36261e-01]
21Feb12_164440| [ 3.71397e-01  4.02431e-01  2.55986e-01  1.78623e-01 -1.70784e-01]
21Feb12_164440| [-3.82692e-01  1.40831e+00  8.55174e-01 -9.90708e-01 -2.96574e-01]
21Feb12_164440| [ 8.55878e-01 -1.28641e+00 -1.27577e-01  1.71285e+00  3.68193e-01]
21Feb12_164440| [-1.38112e-01 -2.03789e+00  1.37740e+00 -1.13825e+00 -1.40275e-01]
21Feb12_164440| [ 1.16784e-01 -1.01605e-01  6.50576e-01 -1.24867e+00  1.59576e-01]
21Feb12_164440| [-6.69357e-02  5.95912e-01  9.10702e-01 -9.96770e-01 -4.54797e-01]
21Feb12_164440| [-3.26068e-01  5.34200e-01  6.46798e-01 -6.85025e-01 -4.96585e-01]
21Feb12_164440| [-5.34229e-01  7.35933e-01 -1.25152e+00 -2.77515e-01 -2.30796e-01]
21Feb12_164440| [ 5.63815e-01  1.25123e-01  3.62872e-01  1.44226e+00  4.48351e-01]
21Feb12_164440| [-4.83407e-01  6.11778e-03 -7.29776e-01  3.97953e-01 -2.35147e-01]
21Feb12_164440| [-4.06974e-01  4.89918e-01 -1.61581e+00 -7.37000e-01  2.22498e-01]
21Feb12_164440| [ 6.06985e-01  1.58098e-01 -1.30279e+00  1.09222e+00  9.42671e-02]
21Feb12_164440| [ 3.00917e-01 -4.38970e-01  6.67241e-01  7.60470e-01  1.72456e-01]
21Feb12_164440| [ 2.61099e-02  8.76452e-02  2.06721e+00 -9.40037e-01  9.36414e-02]
21Feb12_164440| [-5.66141e-01 -1.65301e+00 -8.72837e-02 -1.13373e+00  8.58644e-02]
21Feb12_164440| [-6.85789e-01 -2.27794e+00  2.86336e-01 -9.87500e-01  5.29605e-02]
21Feb12_164440| [ 2.76455e-01 -9.02853e-01 -8.98832e-01  2.10718e+00  2.36407e-01]
21Feb12_164440| [ 2.60908e-01 -2.86778e-01 -1.41586e+00  2.84419e-01 -2.34253e-01]
21Feb12_164440| [ 2.02249e+00 -1.56278e-02 -1.11757e+00  1.13346e+00  1.02623e-01]
21Feb12_164440| [ 1.99017e-02  4.60107e-04 -6.77307e-01 -5.15077e-01  2.53077e-01]
21Feb12_164440| [ 4.24908e-01  5.22426e-01  6.86959e-01  2.52109e+00 -4.59536e-01]
21Feb12_164440| [ 1.02097e+00  4.94626e-01 -3.87759e-01 -3.06730e-01 -4.17139e-01]
21Feb12_164440| [ 8.70831e-01 -4.45426e-02 -1.33056e+00 -5.49784e-01  2.09440e-02]
21Feb12_164440| [ 8.94189e-02 -2.08384e-01  1.21988e+00 -1.03680e+00 -4.09728e-01]
21Feb12_164440| [ 3.67773e-01 -2.38648e-01 -5.69402e-01 -6.91178e-01  3.00814e-01]
21Feb12_164440| [ 1.04658e+00 -8.03105e-01 -6.97413e-01  1.10650e+00 -2.58323e-01]
21Feb12_164440| [ 9.13179e-01  5.52011e-01  7.55601e-01  1.05981e+00  4.83711e-01]
21Feb12_164440| [-1.25875e+00  8.22927e-01  4.69172e-01  1.97213e-01  6.81926e-02]
21Feb12_164440| [ 1.41226e+00  1.40448e+00  2.28829e-01  1.30923e-01  3.23683e-01]
21Feb12_164440| [ 1.04333e+00 -5.42566e-01  1.66765e-01 -3.15393e-01 -2.05789e-02]
21Feb12_164440| [-4.49591e-01 -1.17282e-01 -9.31887e-02  7.86023e-03  2.01356e-01]
21Feb12_164440| [-5.06666e-01  2.51321e-01 -8.58761e-01  5.41108e-01  5.01461e-02]
21Feb12_164440| [-5.11638e-01  1.74281e+00  6.27990e-02  4.80699e-01  3.70887e-01]
21Feb12_164440| [-7.89485e-01  5.47937e-01 -7.29595e-01 -1.69570e-01  3.23468e-01]
21Feb12_164440| [ 5.81765e-01 -1.17246e-01 -3.09404e-02 -2.04408e-01  6.36081e-02]]
21Feb12_164440|-- Bias --
21Feb12_164440|[-0.54319  0.86182 -0.33228  0.44716 -0.38324]
21Feb12_164440|Layer 1:
21Feb12_164440|-- Config --
21Feb12_164440|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164440|-- Weights --
21Feb12_164440|[[-1.46361 -0.19988 -0.22811 -0.32750]
21Feb12_164440| [-0.44277  0.32306  0.33898 -0.11401]
21Feb12_164440| [-1.02744  0.96055  0.41108 -0.17247]
21Feb12_164440| [-0.45828  0.85211 -0.97745  0.52726]
21Feb12_164440| [ 0.04378 -0.23006 -0.08426  0.42305]]
21Feb12_164440|-- Bias --
21Feb12_164440|[-1.73575 -0.27258 -0.42762  0.23958]
21Feb12_164440|Layer 2:
21Feb12_164440|-- Config --
21Feb12_164440|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164440|-- Weights --
21Feb12_164440|[[ 0.52831 -1.83497]
21Feb12_164440| [ 0.77899 -0.32202]
21Feb12_164440| [ 0.58373  0.74305]
21Feb12_164440| [ 0.15087 -0.14917]]
21Feb12_164440|-- Bias --
21Feb12_164440|[0.90094 0.19971]
21Feb12_164440|Layer 3:
21Feb12_164440|-- Config --
21Feb12_164440|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164440|-- Weights --
21Feb12_164440|[[-0.58484 -0.20452  0.13986]
21Feb12_164440| [-1.32761  0.10456  0.03000]]
21Feb12_164440|-- Bias --
21Feb12_164440|[ 0.60328 -0.84742 -0.37995]
21Feb12_164440|Layer 4:
21Feb12_164440|-- Config --
21Feb12_164440|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164440|-- Weights --
21Feb12_164440|[[ 0.76417 -0.21062]
21Feb12_164440| [ 0.49932 -0.62750]
21Feb12_164440| [ 0.28442  0.31657]]
21Feb12_164440|-- Bias --
21Feb12_164440|[ 0.89049 -0.61218]
21Feb12_164440|Layer 5:
21Feb12_164440|-- Config --
21Feb12_164440|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164440|-- Weights --
21Feb12_164440|[[-0.24887  0.29658]
21Feb12_164440| [-0.75856  0.32450]]
21Feb12_164440|-- Bias --
21Feb12_164440|[-0.20865  0.78432]
21Feb12_164440|Predicting the validation and test data with the Best final individual.
21Feb12_164449| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_164449|-----------  ------------------  --------------------  ----------
21Feb12_164449|Validation         22.78                  80            0.58978
21Feb12_164449|   Test            23.46                  80            0.54616
21Feb12_164449|-------------------- Test #1 --------------------
21Feb12_164449|Best final individual weights
21Feb12_164449|Individual:
21Feb12_164449|-- Constant hidden layers --
21Feb12_164449|False
21Feb12_164449|Layer 0:
21Feb12_164449|-- Config --
21Feb12_164449|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164449|-- Weights --
21Feb12_164449|[[-7.91355e-01  2.43120e+00 -8.07061e-01 -3.94286e-01  3.19125e-01]
21Feb12_164449| [ 6.32169e-01  1.11702e+00  4.18321e-01  1.42293e+00 -7.32555e-02]
21Feb12_164449| [-3.48284e-02  1.24559e+00  2.44475e-02  8.48326e-01 -4.64233e-01]
21Feb12_164449| [ 1.17440e+00  3.81583e-01  2.14959e+00  2.13845e-01  1.46366e-01]
21Feb12_164449| [ 4.44159e-01 -1.12940e-02  5.13247e-01 -6.29180e-01 -2.98321e-01]
21Feb12_164449| [ 1.37424e+00 -1.43437e+00 -6.44080e-01  1.41356e+00  2.98025e-01]
21Feb12_164449| [-7.67760e-01  7.93907e-01 -5.67129e-01  1.19634e+00  1.52366e-01]
21Feb12_164449| [-7.08021e-02 -1.80961e+00  1.04882e+00 -1.67209e+00 -2.72411e-01]
21Feb12_164449| [-1.39134e-01 -5.77581e-01  5.25041e-01  1.42652e+00  1.03720e-01]
21Feb12_164449| [-1.07529e+00  3.55062e-02 -2.17335e+00  2.19168e-01  8.29057e-02]
21Feb12_164449| [-4.45037e-01 -4.03228e-01 -2.01532e-01  8.77376e-01  2.81343e-01]
21Feb12_164449| [ 7.19570e-01 -6.79061e-01 -1.60597e-01  8.08258e-01 -3.25257e-01]
21Feb12_164449| [-5.31401e-01  4.04345e-01  1.93758e+00 -4.60418e-01  4.68916e-01]
21Feb12_164449| [-2.13940e-01 -4.75579e-02 -1.36023e+00 -1.19475e-01 -2.31293e-01]
21Feb12_164449| [ 7.36033e-01 -8.15896e-01 -4.37717e-01  1.67296e+00 -1.20651e-01]
21Feb12_164449| [ 7.16388e-01  1.04087e+00 -1.07113e+00  2.07376e+00  1.83025e-01]
21Feb12_164449| [-5.72677e-01 -1.52863e-01  6.40245e-01 -1.37548e-01  2.41768e-01]
21Feb12_164449| [-2.01843e+00 -5.99701e-01 -1.32540e+00  2.25850e-01 -2.56690e-01]
21Feb12_164449| [-4.10261e-01 -8.13422e-01 -4.48009e-01 -3.61940e-01  4.67163e-02]
21Feb12_164449| [ 5.31285e-01  8.03485e-01  4.18423e-01 -2.97820e-01  3.11368e-01]
21Feb12_164449| [ 3.61796e-01 -9.21000e-01 -5.44164e-01 -1.38174e+00  1.80521e-01]
21Feb12_164449| [-4.75496e-01  9.05014e-01  2.36627e+00 -4.94079e-02 -3.36261e-01]
21Feb12_164449| [ 3.71397e-01  4.02431e-01  2.55986e-01  1.78623e-01 -1.70784e-01]
21Feb12_164449| [-3.82692e-01  1.40831e+00  8.55174e-01 -9.90708e-01 -2.96574e-01]
21Feb12_164449| [ 8.55878e-01 -1.28641e+00 -1.27577e-01  1.71285e+00  3.68193e-01]
21Feb12_164449| [-1.38112e-01 -2.03789e+00  1.37740e+00 -1.13825e+00 -1.40275e-01]
21Feb12_164449| [ 1.16784e-01 -1.01605e-01  6.50576e-01 -1.24867e+00  1.59576e-01]
21Feb12_164449| [-6.69357e-02  5.95912e-01  9.10702e-01 -9.96770e-01 -4.54797e-01]
21Feb12_164449| [-3.26068e-01  5.34200e-01  6.46798e-01 -6.85025e-01 -4.96585e-01]
21Feb12_164449| [-5.34229e-01  7.35933e-01 -1.25152e+00 -2.77515e-01 -2.30796e-01]
21Feb12_164449| [ 5.63815e-01  1.25123e-01  3.62872e-01  1.44226e+00  4.48351e-01]
21Feb12_164449| [-4.83407e-01  6.11778e-03 -7.29776e-01  3.97953e-01 -2.35147e-01]
21Feb12_164449| [-4.06974e-01  4.89918e-01 -1.61581e+00 -7.37000e-01  2.22498e-01]
21Feb12_164449| [ 6.06985e-01  1.58098e-01 -1.30279e+00  1.09222e+00  9.42671e-02]
21Feb12_164449| [ 3.00917e-01 -4.38970e-01  6.67241e-01  7.60470e-01  1.72456e-01]
21Feb12_164449| [ 2.61099e-02  8.76452e-02  2.06721e+00 -9.40037e-01  9.36414e-02]
21Feb12_164449| [-5.66141e-01 -1.65301e+00 -8.72837e-02 -1.13373e+00  8.58644e-02]
21Feb12_164449| [-6.85789e-01 -2.27794e+00  2.86336e-01 -9.87500e-01  5.29605e-02]
21Feb12_164449| [ 2.76455e-01 -9.02853e-01 -8.98832e-01  2.10718e+00  2.36407e-01]
21Feb12_164449| [ 2.60908e-01 -2.86778e-01 -1.41586e+00  2.84419e-01 -2.34253e-01]
21Feb12_164449| [ 2.02249e+00 -1.56278e-02 -1.11757e+00  1.13346e+00  1.02623e-01]
21Feb12_164449| [ 1.99017e-02  4.60107e-04 -6.77307e-01 -5.15077e-01  2.53077e-01]
21Feb12_164449| [ 4.24908e-01  5.22426e-01  6.86959e-01  2.52109e+00 -4.59536e-01]
21Feb12_164449| [ 1.02097e+00  4.94626e-01 -3.87759e-01 -3.06730e-01 -4.17139e-01]
21Feb12_164449| [ 8.70831e-01 -4.45426e-02 -1.33056e+00 -5.49784e-01  2.09440e-02]
21Feb12_164449| [ 8.94189e-02 -2.08384e-01  1.21988e+00 -1.03680e+00 -4.09728e-01]
21Feb12_164449| [ 3.67773e-01 -2.38648e-01 -5.69402e-01 -6.91178e-01  3.00814e-01]
21Feb12_164449| [ 1.04658e+00 -8.03105e-01 -6.97413e-01  1.10650e+00 -2.58323e-01]
21Feb12_164449| [ 9.13179e-01  5.52011e-01  7.55601e-01  1.05981e+00  4.83711e-01]
21Feb12_164449| [-1.25875e+00  8.22927e-01  4.69172e-01  1.97213e-01  6.81926e-02]
21Feb12_164449| [ 1.41226e+00  1.40448e+00  2.28829e-01  1.30923e-01  3.23683e-01]
21Feb12_164449| [ 1.04333e+00 -5.42566e-01  1.66765e-01 -3.15393e-01 -2.05789e-02]
21Feb12_164449| [-4.49591e-01 -1.17282e-01 -9.31887e-02  7.86023e-03  2.01356e-01]
21Feb12_164449| [-5.06666e-01  2.51321e-01 -8.58761e-01  5.41108e-01  5.01461e-02]
21Feb12_164449| [-5.11638e-01  1.74281e+00  6.27990e-02  4.80699e-01  3.70887e-01]
21Feb12_164449| [-7.89485e-01  5.47937e-01 -7.29595e-01 -1.69570e-01  3.23468e-01]
21Feb12_164449| [ 5.81765e-01 -1.17246e-01 -3.09404e-02 -2.04408e-01  6.36081e-02]]
21Feb12_164449|-- Bias --
21Feb12_164449|[-0.54319  0.86182 -0.33228  0.44716 -0.38324]
21Feb12_164449|Layer 1:
21Feb12_164449|-- Config --
21Feb12_164449|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164449|-- Weights --
21Feb12_164449|[[-1.46361 -0.19988 -0.22811 -0.32750]
21Feb12_164449| [-0.44277  0.32306  0.33898 -0.11401]
21Feb12_164449| [-1.02744  0.96055  0.41108 -0.17247]
21Feb12_164449| [-0.45828  0.85211 -0.97745  0.52726]
21Feb12_164449| [ 0.04378 -0.23006 -0.08426  0.42305]]
21Feb12_164449|-- Bias --
21Feb12_164449|[-1.73575 -0.27258 -0.42762  0.23958]
21Feb12_164449|Layer 2:
21Feb12_164449|-- Config --
21Feb12_164449|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164449|-- Weights --
21Feb12_164449|[[ 0.52831 -1.83497]
21Feb12_164449| [ 0.77899 -0.32202]
21Feb12_164449| [ 0.58373  0.74305]
21Feb12_164449| [ 0.15087 -0.14917]]
21Feb12_164449|-- Bias --
21Feb12_164449|[0.90094 0.19971]
21Feb12_164449|Layer 3:
21Feb12_164449|-- Config --
21Feb12_164449|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164449|-- Weights --
21Feb12_164449|[[-0.58484 -0.20452  0.13986]
21Feb12_164449| [-1.32761  0.10456  0.03000]]
21Feb12_164449|-- Bias --
21Feb12_164449|[ 0.60328 -0.84742 -0.37995]
21Feb12_164449|Layer 4:
21Feb12_164449|-- Config --
21Feb12_164449|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164449|-- Weights --
21Feb12_164449|[[ 0.76417 -0.21062]
21Feb12_164449| [ 0.49932 -0.62750]
21Feb12_164449| [ 0.28442  0.31657]]
21Feb12_164449|-- Bias --
21Feb12_164449|[ 0.89049 -0.61218]
21Feb12_164449|Layer 5:
21Feb12_164449|-- Config --
21Feb12_164449|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164449|-- Weights --
21Feb12_164449|[[-0.24887  0.29658]
21Feb12_164449| [-0.75856  0.32450]]
21Feb12_164449|-- Bias --
21Feb12_164449|[-0.20865  0.78432]
21Feb12_164449|Predicting the validation and test data with the Best final individual.
21Feb12_164457| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_164457|-----------  ------------------  --------------------  ----------
21Feb12_164457|Validation         22.43                  80            0.63202
21Feb12_164457|   Test            22.33                  80            0.61383
21Feb12_164457|-------------------- Test #2 --------------------
21Feb12_164457|Best final individual weights
21Feb12_164457|Individual:
21Feb12_164457|-- Constant hidden layers --
21Feb12_164457|False
21Feb12_164457|Layer 0:
21Feb12_164457|-- Config --
21Feb12_164457|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164457|-- Weights --
21Feb12_164457|[[-7.91355e-01  2.43120e+00 -8.07061e-01 -3.94286e-01  3.19125e-01]
21Feb12_164457| [ 6.32169e-01  1.11702e+00  4.18321e-01  1.42293e+00 -7.32555e-02]
21Feb12_164457| [-3.48284e-02  1.24559e+00  2.44475e-02  8.48326e-01 -4.64233e-01]
21Feb12_164457| [ 1.17440e+00  3.81583e-01  2.14959e+00  2.13845e-01  1.46366e-01]
21Feb12_164457| [ 4.44159e-01 -1.12940e-02  5.13247e-01 -6.29180e-01 -2.98321e-01]
21Feb12_164457| [ 1.37424e+00 -1.43437e+00 -6.44080e-01  1.41356e+00  2.98025e-01]
21Feb12_164457| [-7.67760e-01  7.93907e-01 -5.67129e-01  1.19634e+00  1.52366e-01]
21Feb12_164457| [-7.08021e-02 -1.80961e+00  1.04882e+00 -1.67209e+00 -2.72411e-01]
21Feb12_164457| [-1.39134e-01 -5.77581e-01  5.25041e-01  1.42652e+00  1.03720e-01]
21Feb12_164457| [-1.07529e+00  3.55062e-02 -2.17335e+00  2.19168e-01  8.29057e-02]
21Feb12_164457| [-4.45037e-01 -4.03228e-01 -2.01532e-01  8.77376e-01  2.81343e-01]
21Feb12_164457| [ 7.19570e-01 -6.79061e-01 -1.60597e-01  8.08258e-01 -3.25257e-01]
21Feb12_164457| [-5.31401e-01  4.04345e-01  1.93758e+00 -4.60418e-01  4.68916e-01]
21Feb12_164457| [-2.13940e-01 -4.75579e-02 -1.36023e+00 -1.19475e-01 -2.31293e-01]
21Feb12_164457| [ 7.36033e-01 -8.15896e-01 -4.37717e-01  1.67296e+00 -1.20651e-01]
21Feb12_164457| [ 7.16388e-01  1.04087e+00 -1.07113e+00  2.07376e+00  1.83025e-01]
21Feb12_164457| [-5.72677e-01 -1.52863e-01  6.40245e-01 -1.37548e-01  2.41768e-01]
21Feb12_164457| [-2.01843e+00 -5.99701e-01 -1.32540e+00  2.25850e-01 -2.56690e-01]
21Feb12_164457| [-4.10261e-01 -8.13422e-01 -4.48009e-01 -3.61940e-01  4.67163e-02]
21Feb12_164457| [ 5.31285e-01  8.03485e-01  4.18423e-01 -2.97820e-01  3.11368e-01]
21Feb12_164457| [ 3.61796e-01 -9.21000e-01 -5.44164e-01 -1.38174e+00  1.80521e-01]
21Feb12_164457| [-4.75496e-01  9.05014e-01  2.36627e+00 -4.94079e-02 -3.36261e-01]
21Feb12_164457| [ 3.71397e-01  4.02431e-01  2.55986e-01  1.78623e-01 -1.70784e-01]
21Feb12_164457| [-3.82692e-01  1.40831e+00  8.55174e-01 -9.90708e-01 -2.96574e-01]
21Feb12_164457| [ 8.55878e-01 -1.28641e+00 -1.27577e-01  1.71285e+00  3.68193e-01]
21Feb12_164457| [-1.38112e-01 -2.03789e+00  1.37740e+00 -1.13825e+00 -1.40275e-01]
21Feb12_164457| [ 1.16784e-01 -1.01605e-01  6.50576e-01 -1.24867e+00  1.59576e-01]
21Feb12_164457| [-6.69357e-02  5.95912e-01  9.10702e-01 -9.96770e-01 -4.54797e-01]
21Feb12_164457| [-3.26068e-01  5.34200e-01  6.46798e-01 -6.85025e-01 -4.96585e-01]
21Feb12_164457| [-5.34229e-01  7.35933e-01 -1.25152e+00 -2.77515e-01 -2.30796e-01]
21Feb12_164457| [ 5.63815e-01  1.25123e-01  3.62872e-01  1.44226e+00  4.48351e-01]
21Feb12_164457| [-4.83407e-01  6.11778e-03 -7.29776e-01  3.97953e-01 -2.35147e-01]
21Feb12_164457| [-4.06974e-01  4.89918e-01 -1.61581e+00 -7.37000e-01  2.22498e-01]
21Feb12_164457| [ 6.06985e-01  1.58098e-01 -1.30279e+00  1.09222e+00  9.42671e-02]
21Feb12_164457| [ 3.00917e-01 -4.38970e-01  6.67241e-01  7.60470e-01  1.72456e-01]
21Feb12_164457| [ 2.61099e-02  8.76452e-02  2.06721e+00 -9.40037e-01  9.36414e-02]
21Feb12_164457| [-5.66141e-01 -1.65301e+00 -8.72837e-02 -1.13373e+00  8.58644e-02]
21Feb12_164457| [-6.85789e-01 -2.27794e+00  2.86336e-01 -9.87500e-01  5.29605e-02]
21Feb12_164457| [ 2.76455e-01 -9.02853e-01 -8.98832e-01  2.10718e+00  2.36407e-01]
21Feb12_164457| [ 2.60908e-01 -2.86778e-01 -1.41586e+00  2.84419e-01 -2.34253e-01]
21Feb12_164457| [ 2.02249e+00 -1.56278e-02 -1.11757e+00  1.13346e+00  1.02623e-01]
21Feb12_164457| [ 1.99017e-02  4.60107e-04 -6.77307e-01 -5.15077e-01  2.53077e-01]
21Feb12_164457| [ 4.24908e-01  5.22426e-01  6.86959e-01  2.52109e+00 -4.59536e-01]
21Feb12_164457| [ 1.02097e+00  4.94626e-01 -3.87759e-01 -3.06730e-01 -4.17139e-01]
21Feb12_164457| [ 8.70831e-01 -4.45426e-02 -1.33056e+00 -5.49784e-01  2.09440e-02]
21Feb12_164457| [ 8.94189e-02 -2.08384e-01  1.21988e+00 -1.03680e+00 -4.09728e-01]
21Feb12_164457| [ 3.67773e-01 -2.38648e-01 -5.69402e-01 -6.91178e-01  3.00814e-01]
21Feb12_164457| [ 1.04658e+00 -8.03105e-01 -6.97413e-01  1.10650e+00 -2.58323e-01]
21Feb12_164457| [ 9.13179e-01  5.52011e-01  7.55601e-01  1.05981e+00  4.83711e-01]
21Feb12_164457| [-1.25875e+00  8.22927e-01  4.69172e-01  1.97213e-01  6.81926e-02]
21Feb12_164457| [ 1.41226e+00  1.40448e+00  2.28829e-01  1.30923e-01  3.23683e-01]
21Feb12_164457| [ 1.04333e+00 -5.42566e-01  1.66765e-01 -3.15393e-01 -2.05789e-02]
21Feb12_164457| [-4.49591e-01 -1.17282e-01 -9.31887e-02  7.86023e-03  2.01356e-01]
21Feb12_164457| [-5.06666e-01  2.51321e-01 -8.58761e-01  5.41108e-01  5.01461e-02]
21Feb12_164457| [-5.11638e-01  1.74281e+00  6.27990e-02  4.80699e-01  3.70887e-01]
21Feb12_164457| [-7.89485e-01  5.47937e-01 -7.29595e-01 -1.69570e-01  3.23468e-01]
21Feb12_164457| [ 5.81765e-01 -1.17246e-01 -3.09404e-02 -2.04408e-01  6.36081e-02]]
21Feb12_164457|-- Bias --
21Feb12_164457|[-0.54319  0.86182 -0.33228  0.44716 -0.38324]
21Feb12_164457|Layer 1:
21Feb12_164457|-- Config --
21Feb12_164457|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164457|-- Weights --
21Feb12_164457|[[-1.46361 -0.19988 -0.22811 -0.32750]
21Feb12_164457| [-0.44277  0.32306  0.33898 -0.11401]
21Feb12_164457| [-1.02744  0.96055  0.41108 -0.17247]
21Feb12_164457| [-0.45828  0.85211 -0.97745  0.52726]
21Feb12_164457| [ 0.04378 -0.23006 -0.08426  0.42305]]
21Feb12_164457|-- Bias --
21Feb12_164457|[-1.73575 -0.27258 -0.42762  0.23958]
21Feb12_164457|Layer 2:
21Feb12_164457|-- Config --
21Feb12_164457|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164457|-- Weights --
21Feb12_164457|[[ 0.52831 -1.83497]
21Feb12_164457| [ 0.77899 -0.32202]
21Feb12_164457| [ 0.58373  0.74305]
21Feb12_164457| [ 0.15087 -0.14917]]
21Feb12_164457|-- Bias --
21Feb12_164457|[0.90094 0.19971]
21Feb12_164457|Layer 3:
21Feb12_164457|-- Config --
21Feb12_164457|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164457|-- Weights --
21Feb12_164457|[[-0.58484 -0.20452  0.13986]
21Feb12_164457| [-1.32761  0.10456  0.03000]]
21Feb12_164457|-- Bias --
21Feb12_164457|[ 0.60328 -0.84742 -0.37995]
21Feb12_164457|Layer 4:
21Feb12_164457|-- Config --
21Feb12_164457|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164457|-- Weights --
21Feb12_164457|[[ 0.76417 -0.21062]
21Feb12_164457| [ 0.49932 -0.62750]
21Feb12_164457| [ 0.28442  0.31657]]
21Feb12_164457|-- Bias --
21Feb12_164457|[ 0.89049 -0.61218]
21Feb12_164457|Layer 5:
21Feb12_164457|-- Config --
21Feb12_164457|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164457|-- Weights --
21Feb12_164457|[[-0.24887  0.29658]
21Feb12_164457| [-0.75856  0.32450]]
21Feb12_164457|-- Bias --
21Feb12_164457|[-0.20865  0.78432]
21Feb12_164457|Predicting the validation and test data with the Best final individual.
21Feb12_164506| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_164506|-----------  ------------------  --------------------  ----------
21Feb12_164506|Validation         23.48                  80            0.72124
21Feb12_164506|   Test            26.67                  80            0.41583
21Feb12_164506|-------------------- Test #3 --------------------
21Feb12_164506|Best final individual weights
21Feb12_164506|Individual:
21Feb12_164506|-- Constant hidden layers --
21Feb12_164506|False
21Feb12_164506|Layer 0:
21Feb12_164506|-- Config --
21Feb12_164506|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164506|-- Weights --
21Feb12_164506|[[-7.91355e-01  2.43120e+00 -8.07061e-01 -3.94286e-01  3.19125e-01]
21Feb12_164506| [ 6.32169e-01  1.11702e+00  4.18321e-01  1.42293e+00 -7.32555e-02]
21Feb12_164506| [-3.48284e-02  1.24559e+00  2.44475e-02  8.48326e-01 -4.64233e-01]
21Feb12_164506| [ 1.17440e+00  3.81583e-01  2.14959e+00  2.13845e-01  1.46366e-01]
21Feb12_164506| [ 4.44159e-01 -1.12940e-02  5.13247e-01 -6.29180e-01 -2.98321e-01]
21Feb12_164506| [ 1.37424e+00 -1.43437e+00 -6.44080e-01  1.41356e+00  2.98025e-01]
21Feb12_164506| [-7.67760e-01  7.93907e-01 -5.67129e-01  1.19634e+00  1.52366e-01]
21Feb12_164506| [-7.08021e-02 -1.80961e+00  1.04882e+00 -1.67209e+00 -2.72411e-01]
21Feb12_164506| [-1.39134e-01 -5.77581e-01  5.25041e-01  1.42652e+00  1.03720e-01]
21Feb12_164506| [-1.07529e+00  3.55062e-02 -2.17335e+00  2.19168e-01  8.29057e-02]
21Feb12_164506| [-4.45037e-01 -4.03228e-01 -2.01532e-01  8.77376e-01  2.81343e-01]
21Feb12_164506| [ 7.19570e-01 -6.79061e-01 -1.60597e-01  8.08258e-01 -3.25257e-01]
21Feb12_164506| [-5.31401e-01  4.04345e-01  1.93758e+00 -4.60418e-01  4.68916e-01]
21Feb12_164506| [-2.13940e-01 -4.75579e-02 -1.36023e+00 -1.19475e-01 -2.31293e-01]
21Feb12_164506| [ 7.36033e-01 -8.15896e-01 -4.37717e-01  1.67296e+00 -1.20651e-01]
21Feb12_164506| [ 7.16388e-01  1.04087e+00 -1.07113e+00  2.07376e+00  1.83025e-01]
21Feb12_164506| [-5.72677e-01 -1.52863e-01  6.40245e-01 -1.37548e-01  2.41768e-01]
21Feb12_164506| [-2.01843e+00 -5.99701e-01 -1.32540e+00  2.25850e-01 -2.56690e-01]
21Feb12_164506| [-4.10261e-01 -8.13422e-01 -4.48009e-01 -3.61940e-01  4.67163e-02]
21Feb12_164506| [ 5.31285e-01  8.03485e-01  4.18423e-01 -2.97820e-01  3.11368e-01]
21Feb12_164506| [ 3.61796e-01 -9.21000e-01 -5.44164e-01 -1.38174e+00  1.80521e-01]
21Feb12_164506| [-4.75496e-01  9.05014e-01  2.36627e+00 -4.94079e-02 -3.36261e-01]
21Feb12_164506| [ 3.71397e-01  4.02431e-01  2.55986e-01  1.78623e-01 -1.70784e-01]
21Feb12_164506| [-3.82692e-01  1.40831e+00  8.55174e-01 -9.90708e-01 -2.96574e-01]
21Feb12_164506| [ 8.55878e-01 -1.28641e+00 -1.27577e-01  1.71285e+00  3.68193e-01]
21Feb12_164506| [-1.38112e-01 -2.03789e+00  1.37740e+00 -1.13825e+00 -1.40275e-01]
21Feb12_164506| [ 1.16784e-01 -1.01605e-01  6.50576e-01 -1.24867e+00  1.59576e-01]
21Feb12_164506| [-6.69357e-02  5.95912e-01  9.10702e-01 -9.96770e-01 -4.54797e-01]
21Feb12_164506| [-3.26068e-01  5.34200e-01  6.46798e-01 -6.85025e-01 -4.96585e-01]
21Feb12_164506| [-5.34229e-01  7.35933e-01 -1.25152e+00 -2.77515e-01 -2.30796e-01]
21Feb12_164506| [ 5.63815e-01  1.25123e-01  3.62872e-01  1.44226e+00  4.48351e-01]
21Feb12_164506| [-4.83407e-01  6.11778e-03 -7.29776e-01  3.97953e-01 -2.35147e-01]
21Feb12_164506| [-4.06974e-01  4.89918e-01 -1.61581e+00 -7.37000e-01  2.22498e-01]
21Feb12_164506| [ 6.06985e-01  1.58098e-01 -1.30279e+00  1.09222e+00  9.42671e-02]
21Feb12_164506| [ 3.00917e-01 -4.38970e-01  6.67241e-01  7.60470e-01  1.72456e-01]
21Feb12_164506| [ 2.61099e-02  8.76452e-02  2.06721e+00 -9.40037e-01  9.36414e-02]
21Feb12_164506| [-5.66141e-01 -1.65301e+00 -8.72837e-02 -1.13373e+00  8.58644e-02]
21Feb12_164506| [-6.85789e-01 -2.27794e+00  2.86336e-01 -9.87500e-01  5.29605e-02]
21Feb12_164506| [ 2.76455e-01 -9.02853e-01 -8.98832e-01  2.10718e+00  2.36407e-01]
21Feb12_164506| [ 2.60908e-01 -2.86778e-01 -1.41586e+00  2.84419e-01 -2.34253e-01]
21Feb12_164506| [ 2.02249e+00 -1.56278e-02 -1.11757e+00  1.13346e+00  1.02623e-01]
21Feb12_164506| [ 1.99017e-02  4.60107e-04 -6.77307e-01 -5.15077e-01  2.53077e-01]
21Feb12_164506| [ 4.24908e-01  5.22426e-01  6.86959e-01  2.52109e+00 -4.59536e-01]
21Feb12_164506| [ 1.02097e+00  4.94626e-01 -3.87759e-01 -3.06730e-01 -4.17139e-01]
21Feb12_164506| [ 8.70831e-01 -4.45426e-02 -1.33056e+00 -5.49784e-01  2.09440e-02]
21Feb12_164506| [ 8.94189e-02 -2.08384e-01  1.21988e+00 -1.03680e+00 -4.09728e-01]
21Feb12_164506| [ 3.67773e-01 -2.38648e-01 -5.69402e-01 -6.91178e-01  3.00814e-01]
21Feb12_164506| [ 1.04658e+00 -8.03105e-01 -6.97413e-01  1.10650e+00 -2.58323e-01]
21Feb12_164506| [ 9.13179e-01  5.52011e-01  7.55601e-01  1.05981e+00  4.83711e-01]
21Feb12_164506| [-1.25875e+00  8.22927e-01  4.69172e-01  1.97213e-01  6.81926e-02]
21Feb12_164506| [ 1.41226e+00  1.40448e+00  2.28829e-01  1.30923e-01  3.23683e-01]
21Feb12_164506| [ 1.04333e+00 -5.42566e-01  1.66765e-01 -3.15393e-01 -2.05789e-02]
21Feb12_164506| [-4.49591e-01 -1.17282e-01 -9.31887e-02  7.86023e-03  2.01356e-01]
21Feb12_164506| [-5.06666e-01  2.51321e-01 -8.58761e-01  5.41108e-01  5.01461e-02]
21Feb12_164506| [-5.11638e-01  1.74281e+00  6.27990e-02  4.80699e-01  3.70887e-01]
21Feb12_164506| [-7.89485e-01  5.47937e-01 -7.29595e-01 -1.69570e-01  3.23468e-01]
21Feb12_164506| [ 5.81765e-01 -1.17246e-01 -3.09404e-02 -2.04408e-01  6.36081e-02]]
21Feb12_164506|-- Bias --
21Feb12_164506|[-0.54319  0.86182 -0.33228  0.44716 -0.38324]
21Feb12_164506|Layer 1:
21Feb12_164506|-- Config --
21Feb12_164506|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164506|-- Weights --
21Feb12_164506|[[-1.46361 -0.19988 -0.22811 -0.32750]
21Feb12_164506| [-0.44277  0.32306  0.33898 -0.11401]
21Feb12_164506| [-1.02744  0.96055  0.41108 -0.17247]
21Feb12_164506| [-0.45828  0.85211 -0.97745  0.52726]
21Feb12_164506| [ 0.04378 -0.23006 -0.08426  0.42305]]
21Feb12_164506|-- Bias --
21Feb12_164506|[-1.73575 -0.27258 -0.42762  0.23958]
21Feb12_164506|Layer 2:
21Feb12_164506|-- Config --
21Feb12_164506|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164506|-- Weights --
21Feb12_164506|[[ 0.52831 -1.83497]
21Feb12_164506| [ 0.77899 -0.32202]
21Feb12_164506| [ 0.58373  0.74305]
21Feb12_164506| [ 0.15087 -0.14917]]
21Feb12_164506|-- Bias --
21Feb12_164506|[0.90094 0.19971]
21Feb12_164506|Layer 3:
21Feb12_164506|-- Config --
21Feb12_164506|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164506|-- Weights --
21Feb12_164506|[[-0.58484 -0.20452  0.13986]
21Feb12_164506| [-1.32761  0.10456  0.03000]]
21Feb12_164506|-- Bias --
21Feb12_164506|[ 0.60328 -0.84742 -0.37995]
21Feb12_164506|Layer 4:
21Feb12_164506|-- Config --
21Feb12_164506|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164506|-- Weights --
21Feb12_164506|[[ 0.76417 -0.21062]
21Feb12_164506| [ 0.49932 -0.62750]
21Feb12_164506| [ 0.28442  0.31657]]
21Feb12_164506|-- Bias --
21Feb12_164506|[ 0.89049 -0.61218]
21Feb12_164506|Layer 5:
21Feb12_164506|-- Config --
21Feb12_164506|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164506|-- Weights --
21Feb12_164506|[[-0.24887  0.29658]
21Feb12_164506| [-0.75856  0.32450]]
21Feb12_164506|-- Bias --
21Feb12_164506|[-0.20865  0.78432]
21Feb12_164506|Predicting the validation and test data with the Best final individual.
21Feb12_164514| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_164514|-----------  ------------------  --------------------  ----------
21Feb12_164514|Validation         22.96                  80            0.56147
21Feb12_164514|   Test            25.63                  80            0.45568
21Feb12_164514|-------------------- Test #4 --------------------
21Feb12_164514|Best final individual weights
21Feb12_164514|Individual:
21Feb12_164514|-- Constant hidden layers --
21Feb12_164514|False
21Feb12_164514|Layer 0:
21Feb12_164514|-- Config --
21Feb12_164514|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164514|-- Weights --
21Feb12_164514|[[-7.91355e-01  2.43120e+00 -8.07061e-01 -3.94286e-01  3.19125e-01]
21Feb12_164514| [ 6.32169e-01  1.11702e+00  4.18321e-01  1.42293e+00 -7.32555e-02]
21Feb12_164514| [-3.48284e-02  1.24559e+00  2.44475e-02  8.48326e-01 -4.64233e-01]
21Feb12_164514| [ 1.17440e+00  3.81583e-01  2.14959e+00  2.13845e-01  1.46366e-01]
21Feb12_164514| [ 4.44159e-01 -1.12940e-02  5.13247e-01 -6.29180e-01 -2.98321e-01]
21Feb12_164514| [ 1.37424e+00 -1.43437e+00 -6.44080e-01  1.41356e+00  2.98025e-01]
21Feb12_164514| [-7.67760e-01  7.93907e-01 -5.67129e-01  1.19634e+00  1.52366e-01]
21Feb12_164514| [-7.08021e-02 -1.80961e+00  1.04882e+00 -1.67209e+00 -2.72411e-01]
21Feb12_164514| [-1.39134e-01 -5.77581e-01  5.25041e-01  1.42652e+00  1.03720e-01]
21Feb12_164514| [-1.07529e+00  3.55062e-02 -2.17335e+00  2.19168e-01  8.29057e-02]
21Feb12_164514| [-4.45037e-01 -4.03228e-01 -2.01532e-01  8.77376e-01  2.81343e-01]
21Feb12_164514| [ 7.19570e-01 -6.79061e-01 -1.60597e-01  8.08258e-01 -3.25257e-01]
21Feb12_164514| [-5.31401e-01  4.04345e-01  1.93758e+00 -4.60418e-01  4.68916e-01]
21Feb12_164514| [-2.13940e-01 -4.75579e-02 -1.36023e+00 -1.19475e-01 -2.31293e-01]
21Feb12_164514| [ 7.36033e-01 -8.15896e-01 -4.37717e-01  1.67296e+00 -1.20651e-01]
21Feb12_164514| [ 7.16388e-01  1.04087e+00 -1.07113e+00  2.07376e+00  1.83025e-01]
21Feb12_164514| [-5.72677e-01 -1.52863e-01  6.40245e-01 -1.37548e-01  2.41768e-01]
21Feb12_164514| [-2.01843e+00 -5.99701e-01 -1.32540e+00  2.25850e-01 -2.56690e-01]
21Feb12_164514| [-4.10261e-01 -8.13422e-01 -4.48009e-01 -3.61940e-01  4.67163e-02]
21Feb12_164514| [ 5.31285e-01  8.03485e-01  4.18423e-01 -2.97820e-01  3.11368e-01]
21Feb12_164514| [ 3.61796e-01 -9.21000e-01 -5.44164e-01 -1.38174e+00  1.80521e-01]
21Feb12_164514| [-4.75496e-01  9.05014e-01  2.36627e+00 -4.94079e-02 -3.36261e-01]
21Feb12_164514| [ 3.71397e-01  4.02431e-01  2.55986e-01  1.78623e-01 -1.70784e-01]
21Feb12_164514| [-3.82692e-01  1.40831e+00  8.55174e-01 -9.90708e-01 -2.96574e-01]
21Feb12_164514| [ 8.55878e-01 -1.28641e+00 -1.27577e-01  1.71285e+00  3.68193e-01]
21Feb12_164514| [-1.38112e-01 -2.03789e+00  1.37740e+00 -1.13825e+00 -1.40275e-01]
21Feb12_164514| [ 1.16784e-01 -1.01605e-01  6.50576e-01 -1.24867e+00  1.59576e-01]
21Feb12_164514| [-6.69357e-02  5.95912e-01  9.10702e-01 -9.96770e-01 -4.54797e-01]
21Feb12_164514| [-3.26068e-01  5.34200e-01  6.46798e-01 -6.85025e-01 -4.96585e-01]
21Feb12_164514| [-5.34229e-01  7.35933e-01 -1.25152e+00 -2.77515e-01 -2.30796e-01]
21Feb12_164514| [ 5.63815e-01  1.25123e-01  3.62872e-01  1.44226e+00  4.48351e-01]
21Feb12_164514| [-4.83407e-01  6.11778e-03 -7.29776e-01  3.97953e-01 -2.35147e-01]
21Feb12_164514| [-4.06974e-01  4.89918e-01 -1.61581e+00 -7.37000e-01  2.22498e-01]
21Feb12_164514| [ 6.06985e-01  1.58098e-01 -1.30279e+00  1.09222e+00  9.42671e-02]
21Feb12_164514| [ 3.00917e-01 -4.38970e-01  6.67241e-01  7.60470e-01  1.72456e-01]
21Feb12_164514| [ 2.61099e-02  8.76452e-02  2.06721e+00 -9.40037e-01  9.36414e-02]
21Feb12_164514| [-5.66141e-01 -1.65301e+00 -8.72837e-02 -1.13373e+00  8.58644e-02]
21Feb12_164514| [-6.85789e-01 -2.27794e+00  2.86336e-01 -9.87500e-01  5.29605e-02]
21Feb12_164514| [ 2.76455e-01 -9.02853e-01 -8.98832e-01  2.10718e+00  2.36407e-01]
21Feb12_164514| [ 2.60908e-01 -2.86778e-01 -1.41586e+00  2.84419e-01 -2.34253e-01]
21Feb12_164514| [ 2.02249e+00 -1.56278e-02 -1.11757e+00  1.13346e+00  1.02623e-01]
21Feb12_164514| [ 1.99017e-02  4.60107e-04 -6.77307e-01 -5.15077e-01  2.53077e-01]
21Feb12_164514| [ 4.24908e-01  5.22426e-01  6.86959e-01  2.52109e+00 -4.59536e-01]
21Feb12_164514| [ 1.02097e+00  4.94626e-01 -3.87759e-01 -3.06730e-01 -4.17139e-01]
21Feb12_164514| [ 8.70831e-01 -4.45426e-02 -1.33056e+00 -5.49784e-01  2.09440e-02]
21Feb12_164514| [ 8.94189e-02 -2.08384e-01  1.21988e+00 -1.03680e+00 -4.09728e-01]
21Feb12_164514| [ 3.67773e-01 -2.38648e-01 -5.69402e-01 -6.91178e-01  3.00814e-01]
21Feb12_164514| [ 1.04658e+00 -8.03105e-01 -6.97413e-01  1.10650e+00 -2.58323e-01]
21Feb12_164514| [ 9.13179e-01  5.52011e-01  7.55601e-01  1.05981e+00  4.83711e-01]
21Feb12_164514| [-1.25875e+00  8.22927e-01  4.69172e-01  1.97213e-01  6.81926e-02]
21Feb12_164514| [ 1.41226e+00  1.40448e+00  2.28829e-01  1.30923e-01  3.23683e-01]
21Feb12_164514| [ 1.04333e+00 -5.42566e-01  1.66765e-01 -3.15393e-01 -2.05789e-02]
21Feb12_164514| [-4.49591e-01 -1.17282e-01 -9.31887e-02  7.86023e-03  2.01356e-01]
21Feb12_164514| [-5.06666e-01  2.51321e-01 -8.58761e-01  5.41108e-01  5.01461e-02]
21Feb12_164514| [-5.11638e-01  1.74281e+00  6.27990e-02  4.80699e-01  3.70887e-01]
21Feb12_164514| [-7.89485e-01  5.47937e-01 -7.29595e-01 -1.69570e-01  3.23468e-01]
21Feb12_164514| [ 5.81765e-01 -1.17246e-01 -3.09404e-02 -2.04408e-01  6.36081e-02]]
21Feb12_164514|-- Bias --
21Feb12_164514|[-0.54319  0.86182 -0.33228  0.44716 -0.38324]
21Feb12_164514|Layer 1:
21Feb12_164514|-- Config --
21Feb12_164514|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164514|-- Weights --
21Feb12_164514|[[-1.46361 -0.19988 -0.22811 -0.32750]
21Feb12_164514| [-0.44277  0.32306  0.33898 -0.11401]
21Feb12_164514| [-1.02744  0.96055  0.41108 -0.17247]
21Feb12_164514| [-0.45828  0.85211 -0.97745  0.52726]
21Feb12_164514| [ 0.04378 -0.23006 -0.08426  0.42305]]
21Feb12_164514|-- Bias --
21Feb12_164514|[-1.73575 -0.27258 -0.42762  0.23958]
21Feb12_164514|Layer 2:
21Feb12_164514|-- Config --
21Feb12_164514|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164514|-- Weights --
21Feb12_164514|[[ 0.52831 -1.83497]
21Feb12_164514| [ 0.77899 -0.32202]
21Feb12_164514| [ 0.58373  0.74305]
21Feb12_164514| [ 0.15087 -0.14917]]
21Feb12_164514|-- Bias --
21Feb12_164514|[0.90094 0.19971]
21Feb12_164514|Layer 3:
21Feb12_164514|-- Config --
21Feb12_164514|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164514|-- Weights --
21Feb12_164514|[[-0.58484 -0.20452  0.13986]
21Feb12_164514| [-1.32761  0.10456  0.03000]]
21Feb12_164514|-- Bias --
21Feb12_164514|[ 0.60328 -0.84742 -0.37995]
21Feb12_164514|Layer 4:
21Feb12_164514|-- Config --
21Feb12_164514|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164514|-- Weights --
21Feb12_164514|[[ 0.76417 -0.21062]
21Feb12_164514| [ 0.49932 -0.62750]
21Feb12_164514| [ 0.28442  0.31657]]
21Feb12_164514|-- Bias --
21Feb12_164514|[ 0.89049 -0.61218]
21Feb12_164514|Layer 5:
21Feb12_164514|-- Config --
21Feb12_164514|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164514|-- Weights --
21Feb12_164514|[[-0.24887  0.29658]
21Feb12_164514| [-0.75856  0.32450]]
21Feb12_164514|-- Bias --
21Feb12_164514|[-0.20865  0.78432]
21Feb12_164514|Predicting the validation and test data with the Best final individual.
21Feb12_164523| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_164523|-----------  ------------------  --------------------  ----------
21Feb12_164523|Validation         24.70                  80            0.48459
21Feb12_164523|   Test            27.28                  80            0.39106
21Feb12_164523|-------------------- Test #5 --------------------
21Feb12_164523|Best final individual weights
21Feb12_164523|Individual:
21Feb12_164523|-- Constant hidden layers --
21Feb12_164523|False
21Feb12_164523|Layer 0:
21Feb12_164523|-- Config --
21Feb12_164523|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164523|-- Weights --
21Feb12_164523|[[-7.91355e-01  2.43120e+00 -8.07061e-01 -3.94286e-01  3.19125e-01]
21Feb12_164523| [ 6.32169e-01  1.11702e+00  4.18321e-01  1.42293e+00 -7.32555e-02]
21Feb12_164523| [-3.48284e-02  1.24559e+00  2.44475e-02  8.48326e-01 -4.64233e-01]
21Feb12_164523| [ 1.17440e+00  3.81583e-01  2.14959e+00  2.13845e-01  1.46366e-01]
21Feb12_164523| [ 4.44159e-01 -1.12940e-02  5.13247e-01 -6.29180e-01 -2.98321e-01]
21Feb12_164523| [ 1.37424e+00 -1.43437e+00 -6.44080e-01  1.41356e+00  2.98025e-01]
21Feb12_164523| [-7.67760e-01  7.93907e-01 -5.67129e-01  1.19634e+00  1.52366e-01]
21Feb12_164523| [-7.08021e-02 -1.80961e+00  1.04882e+00 -1.67209e+00 -2.72411e-01]
21Feb12_164523| [-1.39134e-01 -5.77581e-01  5.25041e-01  1.42652e+00  1.03720e-01]
21Feb12_164523| [-1.07529e+00  3.55062e-02 -2.17335e+00  2.19168e-01  8.29057e-02]
21Feb12_164523| [-4.45037e-01 -4.03228e-01 -2.01532e-01  8.77376e-01  2.81343e-01]
21Feb12_164523| [ 7.19570e-01 -6.79061e-01 -1.60597e-01  8.08258e-01 -3.25257e-01]
21Feb12_164523| [-5.31401e-01  4.04345e-01  1.93758e+00 -4.60418e-01  4.68916e-01]
21Feb12_164523| [-2.13940e-01 -4.75579e-02 -1.36023e+00 -1.19475e-01 -2.31293e-01]
21Feb12_164523| [ 7.36033e-01 -8.15896e-01 -4.37717e-01  1.67296e+00 -1.20651e-01]
21Feb12_164523| [ 7.16388e-01  1.04087e+00 -1.07113e+00  2.07376e+00  1.83025e-01]
21Feb12_164523| [-5.72677e-01 -1.52863e-01  6.40245e-01 -1.37548e-01  2.41768e-01]
21Feb12_164523| [-2.01843e+00 -5.99701e-01 -1.32540e+00  2.25850e-01 -2.56690e-01]
21Feb12_164523| [-4.10261e-01 -8.13422e-01 -4.48009e-01 -3.61940e-01  4.67163e-02]
21Feb12_164523| [ 5.31285e-01  8.03485e-01  4.18423e-01 -2.97820e-01  3.11368e-01]
21Feb12_164523| [ 3.61796e-01 -9.21000e-01 -5.44164e-01 -1.38174e+00  1.80521e-01]
21Feb12_164523| [-4.75496e-01  9.05014e-01  2.36627e+00 -4.94079e-02 -3.36261e-01]
21Feb12_164523| [ 3.71397e-01  4.02431e-01  2.55986e-01  1.78623e-01 -1.70784e-01]
21Feb12_164523| [-3.82692e-01  1.40831e+00  8.55174e-01 -9.90708e-01 -2.96574e-01]
21Feb12_164523| [ 8.55878e-01 -1.28641e+00 -1.27577e-01  1.71285e+00  3.68193e-01]
21Feb12_164523| [-1.38112e-01 -2.03789e+00  1.37740e+00 -1.13825e+00 -1.40275e-01]
21Feb12_164523| [ 1.16784e-01 -1.01605e-01  6.50576e-01 -1.24867e+00  1.59576e-01]
21Feb12_164523| [-6.69357e-02  5.95912e-01  9.10702e-01 -9.96770e-01 -4.54797e-01]
21Feb12_164523| [-3.26068e-01  5.34200e-01  6.46798e-01 -6.85025e-01 -4.96585e-01]
21Feb12_164523| [-5.34229e-01  7.35933e-01 -1.25152e+00 -2.77515e-01 -2.30796e-01]
21Feb12_164523| [ 5.63815e-01  1.25123e-01  3.62872e-01  1.44226e+00  4.48351e-01]
21Feb12_164523| [-4.83407e-01  6.11778e-03 -7.29776e-01  3.97953e-01 -2.35147e-01]
21Feb12_164523| [-4.06974e-01  4.89918e-01 -1.61581e+00 -7.37000e-01  2.22498e-01]
21Feb12_164523| [ 6.06985e-01  1.58098e-01 -1.30279e+00  1.09222e+00  9.42671e-02]
21Feb12_164523| [ 3.00917e-01 -4.38970e-01  6.67241e-01  7.60470e-01  1.72456e-01]
21Feb12_164523| [ 2.61099e-02  8.76452e-02  2.06721e+00 -9.40037e-01  9.36414e-02]
21Feb12_164523| [-5.66141e-01 -1.65301e+00 -8.72837e-02 -1.13373e+00  8.58644e-02]
21Feb12_164523| [-6.85789e-01 -2.27794e+00  2.86336e-01 -9.87500e-01  5.29605e-02]
21Feb12_164523| [ 2.76455e-01 -9.02853e-01 -8.98832e-01  2.10718e+00  2.36407e-01]
21Feb12_164523| [ 2.60908e-01 -2.86778e-01 -1.41586e+00  2.84419e-01 -2.34253e-01]
21Feb12_164523| [ 2.02249e+00 -1.56278e-02 -1.11757e+00  1.13346e+00  1.02623e-01]
21Feb12_164523| [ 1.99017e-02  4.60107e-04 -6.77307e-01 -5.15077e-01  2.53077e-01]
21Feb12_164523| [ 4.24908e-01  5.22426e-01  6.86959e-01  2.52109e+00 -4.59536e-01]
21Feb12_164523| [ 1.02097e+00  4.94626e-01 -3.87759e-01 -3.06730e-01 -4.17139e-01]
21Feb12_164523| [ 8.70831e-01 -4.45426e-02 -1.33056e+00 -5.49784e-01  2.09440e-02]
21Feb12_164523| [ 8.94189e-02 -2.08384e-01  1.21988e+00 -1.03680e+00 -4.09728e-01]
21Feb12_164523| [ 3.67773e-01 -2.38648e-01 -5.69402e-01 -6.91178e-01  3.00814e-01]
21Feb12_164523| [ 1.04658e+00 -8.03105e-01 -6.97413e-01  1.10650e+00 -2.58323e-01]
21Feb12_164523| [ 9.13179e-01  5.52011e-01  7.55601e-01  1.05981e+00  4.83711e-01]
21Feb12_164523| [-1.25875e+00  8.22927e-01  4.69172e-01  1.97213e-01  6.81926e-02]
21Feb12_164523| [ 1.41226e+00  1.40448e+00  2.28829e-01  1.30923e-01  3.23683e-01]
21Feb12_164523| [ 1.04333e+00 -5.42566e-01  1.66765e-01 -3.15393e-01 -2.05789e-02]
21Feb12_164523| [-4.49591e-01 -1.17282e-01 -9.31887e-02  7.86023e-03  2.01356e-01]
21Feb12_164523| [-5.06666e-01  2.51321e-01 -8.58761e-01  5.41108e-01  5.01461e-02]
21Feb12_164523| [-5.11638e-01  1.74281e+00  6.27990e-02  4.80699e-01  3.70887e-01]
21Feb12_164523| [-7.89485e-01  5.47937e-01 -7.29595e-01 -1.69570e-01  3.23468e-01]
21Feb12_164523| [ 5.81765e-01 -1.17246e-01 -3.09404e-02 -2.04408e-01  6.36081e-02]]
21Feb12_164523|-- Bias --
21Feb12_164523|[-0.54319  0.86182 -0.33228  0.44716 -0.38324]
21Feb12_164523|Layer 1:
21Feb12_164523|-- Config --
21Feb12_164523|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164523|-- Weights --
21Feb12_164523|[[-1.46361 -0.19988 -0.22811 -0.32750]
21Feb12_164523| [-0.44277  0.32306  0.33898 -0.11401]
21Feb12_164523| [-1.02744  0.96055  0.41108 -0.17247]
21Feb12_164523| [-0.45828  0.85211 -0.97745  0.52726]
21Feb12_164523| [ 0.04378 -0.23006 -0.08426  0.42305]]
21Feb12_164523|-- Bias --
21Feb12_164523|[-1.73575 -0.27258 -0.42762  0.23958]
21Feb12_164523|Layer 2:
21Feb12_164523|-- Config --
21Feb12_164523|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164523|-- Weights --
21Feb12_164523|[[ 0.52831 -1.83497]
21Feb12_164523| [ 0.77899 -0.32202]
21Feb12_164523| [ 0.58373  0.74305]
21Feb12_164523| [ 0.15087 -0.14917]]
21Feb12_164523|-- Bias --
21Feb12_164523|[0.90094 0.19971]
21Feb12_164523|Layer 3:
21Feb12_164523|-- Config --
21Feb12_164523|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164523|-- Weights --
21Feb12_164523|[[-0.58484 -0.20452  0.13986]
21Feb12_164523| [-1.32761  0.10456  0.03000]]
21Feb12_164523|-- Bias --
21Feb12_164523|[ 0.60328 -0.84742 -0.37995]
21Feb12_164523|Layer 4:
21Feb12_164523|-- Config --
21Feb12_164523|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164523|-- Weights --
21Feb12_164523|[[ 0.76417 -0.21062]
21Feb12_164523| [ 0.49932 -0.62750]
21Feb12_164523| [ 0.28442  0.31657]]
21Feb12_164523|-- Bias --
21Feb12_164523|[ 0.89049 -0.61218]
21Feb12_164523|Layer 5:
21Feb12_164523|-- Config --
21Feb12_164523|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164523|-- Weights --
21Feb12_164523|[[-0.24887  0.29658]
21Feb12_164523| [-0.75856  0.32450]]
21Feb12_164523|-- Bias --
21Feb12_164523|[-0.20865  0.78432]
21Feb12_164523|Predicting the validation and test data with the Best final individual.
21Feb12_164531| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_164531|-----------  ------------------  --------------------  ----------
21Feb12_164531|Validation         26.00                  80            0.46292
21Feb12_164531|   Test            24.33                  80            0.52261
21Feb12_164531|-------------------- Test #6 --------------------
21Feb12_164531|Best final individual weights
21Feb12_164531|Individual:
21Feb12_164531|-- Constant hidden layers --
21Feb12_164531|False
21Feb12_164531|Layer 0:
21Feb12_164531|-- Config --
21Feb12_164531|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164531|-- Weights --
21Feb12_164531|[[-7.91355e-01  2.43120e+00 -8.07061e-01 -3.94286e-01  3.19125e-01]
21Feb12_164531| [ 6.32169e-01  1.11702e+00  4.18321e-01  1.42293e+00 -7.32555e-02]
21Feb12_164531| [-3.48284e-02  1.24559e+00  2.44475e-02  8.48326e-01 -4.64233e-01]
21Feb12_164531| [ 1.17440e+00  3.81583e-01  2.14959e+00  2.13845e-01  1.46366e-01]
21Feb12_164531| [ 4.44159e-01 -1.12940e-02  5.13247e-01 -6.29180e-01 -2.98321e-01]
21Feb12_164531| [ 1.37424e+00 -1.43437e+00 -6.44080e-01  1.41356e+00  2.98025e-01]
21Feb12_164531| [-7.67760e-01  7.93907e-01 -5.67129e-01  1.19634e+00  1.52366e-01]
21Feb12_164531| [-7.08021e-02 -1.80961e+00  1.04882e+00 -1.67209e+00 -2.72411e-01]
21Feb12_164531| [-1.39134e-01 -5.77581e-01  5.25041e-01  1.42652e+00  1.03720e-01]
21Feb12_164531| [-1.07529e+00  3.55062e-02 -2.17335e+00  2.19168e-01  8.29057e-02]
21Feb12_164531| [-4.45037e-01 -4.03228e-01 -2.01532e-01  8.77376e-01  2.81343e-01]
21Feb12_164531| [ 7.19570e-01 -6.79061e-01 -1.60597e-01  8.08258e-01 -3.25257e-01]
21Feb12_164531| [-5.31401e-01  4.04345e-01  1.93758e+00 -4.60418e-01  4.68916e-01]
21Feb12_164531| [-2.13940e-01 -4.75579e-02 -1.36023e+00 -1.19475e-01 -2.31293e-01]
21Feb12_164531| [ 7.36033e-01 -8.15896e-01 -4.37717e-01  1.67296e+00 -1.20651e-01]
21Feb12_164531| [ 7.16388e-01  1.04087e+00 -1.07113e+00  2.07376e+00  1.83025e-01]
21Feb12_164531| [-5.72677e-01 -1.52863e-01  6.40245e-01 -1.37548e-01  2.41768e-01]
21Feb12_164531| [-2.01843e+00 -5.99701e-01 -1.32540e+00  2.25850e-01 -2.56690e-01]
21Feb12_164531| [-4.10261e-01 -8.13422e-01 -4.48009e-01 -3.61940e-01  4.67163e-02]
21Feb12_164531| [ 5.31285e-01  8.03485e-01  4.18423e-01 -2.97820e-01  3.11368e-01]
21Feb12_164531| [ 3.61796e-01 -9.21000e-01 -5.44164e-01 -1.38174e+00  1.80521e-01]
21Feb12_164531| [-4.75496e-01  9.05014e-01  2.36627e+00 -4.94079e-02 -3.36261e-01]
21Feb12_164531| [ 3.71397e-01  4.02431e-01  2.55986e-01  1.78623e-01 -1.70784e-01]
21Feb12_164531| [-3.82692e-01  1.40831e+00  8.55174e-01 -9.90708e-01 -2.96574e-01]
21Feb12_164531| [ 8.55878e-01 -1.28641e+00 -1.27577e-01  1.71285e+00  3.68193e-01]
21Feb12_164531| [-1.38112e-01 -2.03789e+00  1.37740e+00 -1.13825e+00 -1.40275e-01]
21Feb12_164531| [ 1.16784e-01 -1.01605e-01  6.50576e-01 -1.24867e+00  1.59576e-01]
21Feb12_164531| [-6.69357e-02  5.95912e-01  9.10702e-01 -9.96770e-01 -4.54797e-01]
21Feb12_164531| [-3.26068e-01  5.34200e-01  6.46798e-01 -6.85025e-01 -4.96585e-01]
21Feb12_164531| [-5.34229e-01  7.35933e-01 -1.25152e+00 -2.77515e-01 -2.30796e-01]
21Feb12_164531| [ 5.63815e-01  1.25123e-01  3.62872e-01  1.44226e+00  4.48351e-01]
21Feb12_164531| [-4.83407e-01  6.11778e-03 -7.29776e-01  3.97953e-01 -2.35147e-01]
21Feb12_164531| [-4.06974e-01  4.89918e-01 -1.61581e+00 -7.37000e-01  2.22498e-01]
21Feb12_164531| [ 6.06985e-01  1.58098e-01 -1.30279e+00  1.09222e+00  9.42671e-02]
21Feb12_164531| [ 3.00917e-01 -4.38970e-01  6.67241e-01  7.60470e-01  1.72456e-01]
21Feb12_164531| [ 2.61099e-02  8.76452e-02  2.06721e+00 -9.40037e-01  9.36414e-02]
21Feb12_164531| [-5.66141e-01 -1.65301e+00 -8.72837e-02 -1.13373e+00  8.58644e-02]
21Feb12_164531| [-6.85789e-01 -2.27794e+00  2.86336e-01 -9.87500e-01  5.29605e-02]
21Feb12_164531| [ 2.76455e-01 -9.02853e-01 -8.98832e-01  2.10718e+00  2.36407e-01]
21Feb12_164531| [ 2.60908e-01 -2.86778e-01 -1.41586e+00  2.84419e-01 -2.34253e-01]
21Feb12_164531| [ 2.02249e+00 -1.56278e-02 -1.11757e+00  1.13346e+00  1.02623e-01]
21Feb12_164531| [ 1.99017e-02  4.60107e-04 -6.77307e-01 -5.15077e-01  2.53077e-01]
21Feb12_164531| [ 4.24908e-01  5.22426e-01  6.86959e-01  2.52109e+00 -4.59536e-01]
21Feb12_164531| [ 1.02097e+00  4.94626e-01 -3.87759e-01 -3.06730e-01 -4.17139e-01]
21Feb12_164531| [ 8.70831e-01 -4.45426e-02 -1.33056e+00 -5.49784e-01  2.09440e-02]
21Feb12_164531| [ 8.94189e-02 -2.08384e-01  1.21988e+00 -1.03680e+00 -4.09728e-01]
21Feb12_164531| [ 3.67773e-01 -2.38648e-01 -5.69402e-01 -6.91178e-01  3.00814e-01]
21Feb12_164531| [ 1.04658e+00 -8.03105e-01 -6.97413e-01  1.10650e+00 -2.58323e-01]
21Feb12_164531| [ 9.13179e-01  5.52011e-01  7.55601e-01  1.05981e+00  4.83711e-01]
21Feb12_164531| [-1.25875e+00  8.22927e-01  4.69172e-01  1.97213e-01  6.81926e-02]
21Feb12_164531| [ 1.41226e+00  1.40448e+00  2.28829e-01  1.30923e-01  3.23683e-01]
21Feb12_164531| [ 1.04333e+00 -5.42566e-01  1.66765e-01 -3.15393e-01 -2.05789e-02]
21Feb12_164531| [-4.49591e-01 -1.17282e-01 -9.31887e-02  7.86023e-03  2.01356e-01]
21Feb12_164531| [-5.06666e-01  2.51321e-01 -8.58761e-01  5.41108e-01  5.01461e-02]
21Feb12_164531| [-5.11638e-01  1.74281e+00  6.27990e-02  4.80699e-01  3.70887e-01]
21Feb12_164531| [-7.89485e-01  5.47937e-01 -7.29595e-01 -1.69570e-01  3.23468e-01]
21Feb12_164531| [ 5.81765e-01 -1.17246e-01 -3.09404e-02 -2.04408e-01  6.36081e-02]]
21Feb12_164531|-- Bias --
21Feb12_164531|[-0.54319  0.86182 -0.33228  0.44716 -0.38324]
21Feb12_164531|Layer 1:
21Feb12_164531|-- Config --
21Feb12_164531|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164531|-- Weights --
21Feb12_164531|[[-1.46361 -0.19988 -0.22811 -0.32750]
21Feb12_164531| [-0.44277  0.32306  0.33898 -0.11401]
21Feb12_164531| [-1.02744  0.96055  0.41108 -0.17247]
21Feb12_164531| [-0.45828  0.85211 -0.97745  0.52726]
21Feb12_164531| [ 0.04378 -0.23006 -0.08426  0.42305]]
21Feb12_164531|-- Bias --
21Feb12_164531|[-1.73575 -0.27258 -0.42762  0.23958]
21Feb12_164531|Layer 2:
21Feb12_164531|-- Config --
21Feb12_164531|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164531|-- Weights --
21Feb12_164531|[[ 0.52831 -1.83497]
21Feb12_164531| [ 0.77899 -0.32202]
21Feb12_164531| [ 0.58373  0.74305]
21Feb12_164531| [ 0.15087 -0.14917]]
21Feb12_164531|-- Bias --
21Feb12_164531|[0.90094 0.19971]
21Feb12_164531|Layer 3:
21Feb12_164531|-- Config --
21Feb12_164531|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164531|-- Weights --
21Feb12_164531|[[-0.58484 -0.20452  0.13986]
21Feb12_164531| [-1.32761  0.10456  0.03000]]
21Feb12_164531|-- Bias --
21Feb12_164531|[ 0.60328 -0.84742 -0.37995]
21Feb12_164531|Layer 4:
21Feb12_164531|-- Config --
21Feb12_164531|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164531|-- Weights --
21Feb12_164531|[[ 0.76417 -0.21062]
21Feb12_164531| [ 0.49932 -0.62750]
21Feb12_164531| [ 0.28442  0.31657]]
21Feb12_164531|-- Bias --
21Feb12_164531|[ 0.89049 -0.61218]
21Feb12_164531|Layer 5:
21Feb12_164531|-- Config --
21Feb12_164531|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164531|-- Weights --
21Feb12_164531|[[-0.24887  0.29658]
21Feb12_164531| [-0.75856  0.32450]]
21Feb12_164531|-- Bias --
21Feb12_164531|[-0.20865  0.78432]
21Feb12_164531|Predicting the validation and test data with the Best final individual.
21Feb12_164539| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_164539|-----------  ------------------  --------------------  ----------
21Feb12_164539|Validation         26.09                  80            0.44634
21Feb12_164539|   Test            26.32                  80            0.44572
21Feb12_164539|-------------------- Test #7 --------------------
21Feb12_164539|Best final individual weights
21Feb12_164539|Individual:
21Feb12_164539|-- Constant hidden layers --
21Feb12_164539|False
21Feb12_164539|Layer 0:
21Feb12_164539|-- Config --
21Feb12_164539|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164539|-- Weights --
21Feb12_164539|[[-7.91355e-01  2.43120e+00 -8.07061e-01 -3.94286e-01  3.19125e-01]
21Feb12_164539| [ 6.32169e-01  1.11702e+00  4.18321e-01  1.42293e+00 -7.32555e-02]
21Feb12_164539| [-3.48284e-02  1.24559e+00  2.44475e-02  8.48326e-01 -4.64233e-01]
21Feb12_164539| [ 1.17440e+00  3.81583e-01  2.14959e+00  2.13845e-01  1.46366e-01]
21Feb12_164539| [ 4.44159e-01 -1.12940e-02  5.13247e-01 -6.29180e-01 -2.98321e-01]
21Feb12_164539| [ 1.37424e+00 -1.43437e+00 -6.44080e-01  1.41356e+00  2.98025e-01]
21Feb12_164539| [-7.67760e-01  7.93907e-01 -5.67129e-01  1.19634e+00  1.52366e-01]
21Feb12_164539| [-7.08021e-02 -1.80961e+00  1.04882e+00 -1.67209e+00 -2.72411e-01]
21Feb12_164539| [-1.39134e-01 -5.77581e-01  5.25041e-01  1.42652e+00  1.03720e-01]
21Feb12_164539| [-1.07529e+00  3.55062e-02 -2.17335e+00  2.19168e-01  8.29057e-02]
21Feb12_164539| [-4.45037e-01 -4.03228e-01 -2.01532e-01  8.77376e-01  2.81343e-01]
21Feb12_164539| [ 7.19570e-01 -6.79061e-01 -1.60597e-01  8.08258e-01 -3.25257e-01]
21Feb12_164539| [-5.31401e-01  4.04345e-01  1.93758e+00 -4.60418e-01  4.68916e-01]
21Feb12_164539| [-2.13940e-01 -4.75579e-02 -1.36023e+00 -1.19475e-01 -2.31293e-01]
21Feb12_164539| [ 7.36033e-01 -8.15896e-01 -4.37717e-01  1.67296e+00 -1.20651e-01]
21Feb12_164539| [ 7.16388e-01  1.04087e+00 -1.07113e+00  2.07376e+00  1.83025e-01]
21Feb12_164539| [-5.72677e-01 -1.52863e-01  6.40245e-01 -1.37548e-01  2.41768e-01]
21Feb12_164539| [-2.01843e+00 -5.99701e-01 -1.32540e+00  2.25850e-01 -2.56690e-01]
21Feb12_164539| [-4.10261e-01 -8.13422e-01 -4.48009e-01 -3.61940e-01  4.67163e-02]
21Feb12_164539| [ 5.31285e-01  8.03485e-01  4.18423e-01 -2.97820e-01  3.11368e-01]
21Feb12_164539| [ 3.61796e-01 -9.21000e-01 -5.44164e-01 -1.38174e+00  1.80521e-01]
21Feb12_164539| [-4.75496e-01  9.05014e-01  2.36627e+00 -4.94079e-02 -3.36261e-01]
21Feb12_164539| [ 3.71397e-01  4.02431e-01  2.55986e-01  1.78623e-01 -1.70784e-01]
21Feb12_164539| [-3.82692e-01  1.40831e+00  8.55174e-01 -9.90708e-01 -2.96574e-01]
21Feb12_164539| [ 8.55878e-01 -1.28641e+00 -1.27577e-01  1.71285e+00  3.68193e-01]
21Feb12_164539| [-1.38112e-01 -2.03789e+00  1.37740e+00 -1.13825e+00 -1.40275e-01]
21Feb12_164539| [ 1.16784e-01 -1.01605e-01  6.50576e-01 -1.24867e+00  1.59576e-01]
21Feb12_164539| [-6.69357e-02  5.95912e-01  9.10702e-01 -9.96770e-01 -4.54797e-01]
21Feb12_164539| [-3.26068e-01  5.34200e-01  6.46798e-01 -6.85025e-01 -4.96585e-01]
21Feb12_164539| [-5.34229e-01  7.35933e-01 -1.25152e+00 -2.77515e-01 -2.30796e-01]
21Feb12_164539| [ 5.63815e-01  1.25123e-01  3.62872e-01  1.44226e+00  4.48351e-01]
21Feb12_164539| [-4.83407e-01  6.11778e-03 -7.29776e-01  3.97953e-01 -2.35147e-01]
21Feb12_164539| [-4.06974e-01  4.89918e-01 -1.61581e+00 -7.37000e-01  2.22498e-01]
21Feb12_164539| [ 6.06985e-01  1.58098e-01 -1.30279e+00  1.09222e+00  9.42671e-02]
21Feb12_164539| [ 3.00917e-01 -4.38970e-01  6.67241e-01  7.60470e-01  1.72456e-01]
21Feb12_164539| [ 2.61099e-02  8.76452e-02  2.06721e+00 -9.40037e-01  9.36414e-02]
21Feb12_164539| [-5.66141e-01 -1.65301e+00 -8.72837e-02 -1.13373e+00  8.58644e-02]
21Feb12_164539| [-6.85789e-01 -2.27794e+00  2.86336e-01 -9.87500e-01  5.29605e-02]
21Feb12_164539| [ 2.76455e-01 -9.02853e-01 -8.98832e-01  2.10718e+00  2.36407e-01]
21Feb12_164539| [ 2.60908e-01 -2.86778e-01 -1.41586e+00  2.84419e-01 -2.34253e-01]
21Feb12_164539| [ 2.02249e+00 -1.56278e-02 -1.11757e+00  1.13346e+00  1.02623e-01]
21Feb12_164539| [ 1.99017e-02  4.60107e-04 -6.77307e-01 -5.15077e-01  2.53077e-01]
21Feb12_164539| [ 4.24908e-01  5.22426e-01  6.86959e-01  2.52109e+00 -4.59536e-01]
21Feb12_164539| [ 1.02097e+00  4.94626e-01 -3.87759e-01 -3.06730e-01 -4.17139e-01]
21Feb12_164539| [ 8.70831e-01 -4.45426e-02 -1.33056e+00 -5.49784e-01  2.09440e-02]
21Feb12_164539| [ 8.94189e-02 -2.08384e-01  1.21988e+00 -1.03680e+00 -4.09728e-01]
21Feb12_164539| [ 3.67773e-01 -2.38648e-01 -5.69402e-01 -6.91178e-01  3.00814e-01]
21Feb12_164539| [ 1.04658e+00 -8.03105e-01 -6.97413e-01  1.10650e+00 -2.58323e-01]
21Feb12_164539| [ 9.13179e-01  5.52011e-01  7.55601e-01  1.05981e+00  4.83711e-01]
21Feb12_164539| [-1.25875e+00  8.22927e-01  4.69172e-01  1.97213e-01  6.81926e-02]
21Feb12_164539| [ 1.41226e+00  1.40448e+00  2.28829e-01  1.30923e-01  3.23683e-01]
21Feb12_164539| [ 1.04333e+00 -5.42566e-01  1.66765e-01 -3.15393e-01 -2.05789e-02]
21Feb12_164539| [-4.49591e-01 -1.17282e-01 -9.31887e-02  7.86023e-03  2.01356e-01]
21Feb12_164539| [-5.06666e-01  2.51321e-01 -8.58761e-01  5.41108e-01  5.01461e-02]
21Feb12_164539| [-5.11638e-01  1.74281e+00  6.27990e-02  4.80699e-01  3.70887e-01]
21Feb12_164539| [-7.89485e-01  5.47937e-01 -7.29595e-01 -1.69570e-01  3.23468e-01]
21Feb12_164539| [ 5.81765e-01 -1.17246e-01 -3.09404e-02 -2.04408e-01  6.36081e-02]]
21Feb12_164539|-- Bias --
21Feb12_164539|[-0.54319  0.86182 -0.33228  0.44716 -0.38324]
21Feb12_164539|Layer 1:
21Feb12_164539|-- Config --
21Feb12_164539|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164539|-- Weights --
21Feb12_164539|[[-1.46361 -0.19988 -0.22811 -0.32750]
21Feb12_164539| [-0.44277  0.32306  0.33898 -0.11401]
21Feb12_164539| [-1.02744  0.96055  0.41108 -0.17247]
21Feb12_164539| [-0.45828  0.85211 -0.97745  0.52726]
21Feb12_164539| [ 0.04378 -0.23006 -0.08426  0.42305]]
21Feb12_164539|-- Bias --
21Feb12_164539|[-1.73575 -0.27258 -0.42762  0.23958]
21Feb12_164539|Layer 2:
21Feb12_164539|-- Config --
21Feb12_164539|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164539|-- Weights --
21Feb12_164539|[[ 0.52831 -1.83497]
21Feb12_164539| [ 0.77899 -0.32202]
21Feb12_164539| [ 0.58373  0.74305]
21Feb12_164539| [ 0.15087 -0.14917]]
21Feb12_164539|-- Bias --
21Feb12_164539|[0.90094 0.19971]
21Feb12_164539|Layer 3:
21Feb12_164539|-- Config --
21Feb12_164539|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164539|-- Weights --
21Feb12_164539|[[-0.58484 -0.20452  0.13986]
21Feb12_164539| [-1.32761  0.10456  0.03000]]
21Feb12_164539|-- Bias --
21Feb12_164539|[ 0.60328 -0.84742 -0.37995]
21Feb12_164539|Layer 4:
21Feb12_164539|-- Config --
21Feb12_164539|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164539|-- Weights --
21Feb12_164539|[[ 0.76417 -0.21062]
21Feb12_164539| [ 0.49932 -0.62750]
21Feb12_164539| [ 0.28442  0.31657]]
21Feb12_164539|-- Bias --
21Feb12_164539|[ 0.89049 -0.61218]
21Feb12_164539|Layer 5:
21Feb12_164539|-- Config --
21Feb12_164539|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164539|-- Weights --
21Feb12_164539|[[-0.24887  0.29658]
21Feb12_164539| [-0.75856  0.32450]]
21Feb12_164539|-- Bias --
21Feb12_164539|[-0.20865  0.78432]
21Feb12_164539|Predicting the validation and test data with the Best final individual.
21Feb12_164547| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_164547|-----------  ------------------  --------------------  ----------
21Feb12_164547|Validation         22.26                  80            0.60599
21Feb12_164547|   Test            35.19                  80            0.12730
21Feb12_164547|-------------------- Test #8 --------------------
21Feb12_164547|Best final individual weights
21Feb12_164547|Individual:
21Feb12_164547|-- Constant hidden layers --
21Feb12_164547|False
21Feb12_164547|Layer 0:
21Feb12_164547|-- Config --
21Feb12_164547|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164547|-- Weights --
21Feb12_164547|[[-7.91355e-01  2.43120e+00 -8.07061e-01 -3.94286e-01  3.19125e-01]
21Feb12_164547| [ 6.32169e-01  1.11702e+00  4.18321e-01  1.42293e+00 -7.32555e-02]
21Feb12_164547| [-3.48284e-02  1.24559e+00  2.44475e-02  8.48326e-01 -4.64233e-01]
21Feb12_164547| [ 1.17440e+00  3.81583e-01  2.14959e+00  2.13845e-01  1.46366e-01]
21Feb12_164547| [ 4.44159e-01 -1.12940e-02  5.13247e-01 -6.29180e-01 -2.98321e-01]
21Feb12_164547| [ 1.37424e+00 -1.43437e+00 -6.44080e-01  1.41356e+00  2.98025e-01]
21Feb12_164547| [-7.67760e-01  7.93907e-01 -5.67129e-01  1.19634e+00  1.52366e-01]
21Feb12_164547| [-7.08021e-02 -1.80961e+00  1.04882e+00 -1.67209e+00 -2.72411e-01]
21Feb12_164547| [-1.39134e-01 -5.77581e-01  5.25041e-01  1.42652e+00  1.03720e-01]
21Feb12_164547| [-1.07529e+00  3.55062e-02 -2.17335e+00  2.19168e-01  8.29057e-02]
21Feb12_164547| [-4.45037e-01 -4.03228e-01 -2.01532e-01  8.77376e-01  2.81343e-01]
21Feb12_164547| [ 7.19570e-01 -6.79061e-01 -1.60597e-01  8.08258e-01 -3.25257e-01]
21Feb12_164547| [-5.31401e-01  4.04345e-01  1.93758e+00 -4.60418e-01  4.68916e-01]
21Feb12_164547| [-2.13940e-01 -4.75579e-02 -1.36023e+00 -1.19475e-01 -2.31293e-01]
21Feb12_164547| [ 7.36033e-01 -8.15896e-01 -4.37717e-01  1.67296e+00 -1.20651e-01]
21Feb12_164547| [ 7.16388e-01  1.04087e+00 -1.07113e+00  2.07376e+00  1.83025e-01]
21Feb12_164547| [-5.72677e-01 -1.52863e-01  6.40245e-01 -1.37548e-01  2.41768e-01]
21Feb12_164547| [-2.01843e+00 -5.99701e-01 -1.32540e+00  2.25850e-01 -2.56690e-01]
21Feb12_164547| [-4.10261e-01 -8.13422e-01 -4.48009e-01 -3.61940e-01  4.67163e-02]
21Feb12_164547| [ 5.31285e-01  8.03485e-01  4.18423e-01 -2.97820e-01  3.11368e-01]
21Feb12_164547| [ 3.61796e-01 -9.21000e-01 -5.44164e-01 -1.38174e+00  1.80521e-01]
21Feb12_164547| [-4.75496e-01  9.05014e-01  2.36627e+00 -4.94079e-02 -3.36261e-01]
21Feb12_164547| [ 3.71397e-01  4.02431e-01  2.55986e-01  1.78623e-01 -1.70784e-01]
21Feb12_164547| [-3.82692e-01  1.40831e+00  8.55174e-01 -9.90708e-01 -2.96574e-01]
21Feb12_164547| [ 8.55878e-01 -1.28641e+00 -1.27577e-01  1.71285e+00  3.68193e-01]
21Feb12_164547| [-1.38112e-01 -2.03789e+00  1.37740e+00 -1.13825e+00 -1.40275e-01]
21Feb12_164547| [ 1.16784e-01 -1.01605e-01  6.50576e-01 -1.24867e+00  1.59576e-01]
21Feb12_164547| [-6.69357e-02  5.95912e-01  9.10702e-01 -9.96770e-01 -4.54797e-01]
21Feb12_164547| [-3.26068e-01  5.34200e-01  6.46798e-01 -6.85025e-01 -4.96585e-01]
21Feb12_164547| [-5.34229e-01  7.35933e-01 -1.25152e+00 -2.77515e-01 -2.30796e-01]
21Feb12_164547| [ 5.63815e-01  1.25123e-01  3.62872e-01  1.44226e+00  4.48351e-01]
21Feb12_164547| [-4.83407e-01  6.11778e-03 -7.29776e-01  3.97953e-01 -2.35147e-01]
21Feb12_164547| [-4.06974e-01  4.89918e-01 -1.61581e+00 -7.37000e-01  2.22498e-01]
21Feb12_164547| [ 6.06985e-01  1.58098e-01 -1.30279e+00  1.09222e+00  9.42671e-02]
21Feb12_164547| [ 3.00917e-01 -4.38970e-01  6.67241e-01  7.60470e-01  1.72456e-01]
21Feb12_164547| [ 2.61099e-02  8.76452e-02  2.06721e+00 -9.40037e-01  9.36414e-02]
21Feb12_164547| [-5.66141e-01 -1.65301e+00 -8.72837e-02 -1.13373e+00  8.58644e-02]
21Feb12_164547| [-6.85789e-01 -2.27794e+00  2.86336e-01 -9.87500e-01  5.29605e-02]
21Feb12_164547| [ 2.76455e-01 -9.02853e-01 -8.98832e-01  2.10718e+00  2.36407e-01]
21Feb12_164547| [ 2.60908e-01 -2.86778e-01 -1.41586e+00  2.84419e-01 -2.34253e-01]
21Feb12_164547| [ 2.02249e+00 -1.56278e-02 -1.11757e+00  1.13346e+00  1.02623e-01]
21Feb12_164547| [ 1.99017e-02  4.60107e-04 -6.77307e-01 -5.15077e-01  2.53077e-01]
21Feb12_164547| [ 4.24908e-01  5.22426e-01  6.86959e-01  2.52109e+00 -4.59536e-01]
21Feb12_164547| [ 1.02097e+00  4.94626e-01 -3.87759e-01 -3.06730e-01 -4.17139e-01]
21Feb12_164547| [ 8.70831e-01 -4.45426e-02 -1.33056e+00 -5.49784e-01  2.09440e-02]
21Feb12_164547| [ 8.94189e-02 -2.08384e-01  1.21988e+00 -1.03680e+00 -4.09728e-01]
21Feb12_164547| [ 3.67773e-01 -2.38648e-01 -5.69402e-01 -6.91178e-01  3.00814e-01]
21Feb12_164547| [ 1.04658e+00 -8.03105e-01 -6.97413e-01  1.10650e+00 -2.58323e-01]
21Feb12_164547| [ 9.13179e-01  5.52011e-01  7.55601e-01  1.05981e+00  4.83711e-01]
21Feb12_164547| [-1.25875e+00  8.22927e-01  4.69172e-01  1.97213e-01  6.81926e-02]
21Feb12_164547| [ 1.41226e+00  1.40448e+00  2.28829e-01  1.30923e-01  3.23683e-01]
21Feb12_164547| [ 1.04333e+00 -5.42566e-01  1.66765e-01 -3.15393e-01 -2.05789e-02]
21Feb12_164547| [-4.49591e-01 -1.17282e-01 -9.31887e-02  7.86023e-03  2.01356e-01]
21Feb12_164547| [-5.06666e-01  2.51321e-01 -8.58761e-01  5.41108e-01  5.01461e-02]
21Feb12_164547| [-5.11638e-01  1.74281e+00  6.27990e-02  4.80699e-01  3.70887e-01]
21Feb12_164547| [-7.89485e-01  5.47937e-01 -7.29595e-01 -1.69570e-01  3.23468e-01]
21Feb12_164547| [ 5.81765e-01 -1.17246e-01 -3.09404e-02 -2.04408e-01  6.36081e-02]]
21Feb12_164547|-- Bias --
21Feb12_164547|[-0.54319  0.86182 -0.33228  0.44716 -0.38324]
21Feb12_164547|Layer 1:
21Feb12_164547|-- Config --
21Feb12_164547|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164547|-- Weights --
21Feb12_164547|[[-1.46361 -0.19988 -0.22811 -0.32750]
21Feb12_164547| [-0.44277  0.32306  0.33898 -0.11401]
21Feb12_164547| [-1.02744  0.96055  0.41108 -0.17247]
21Feb12_164547| [-0.45828  0.85211 -0.97745  0.52726]
21Feb12_164547| [ 0.04378 -0.23006 -0.08426  0.42305]]
21Feb12_164547|-- Bias --
21Feb12_164547|[-1.73575 -0.27258 -0.42762  0.23958]
21Feb12_164547|Layer 2:
21Feb12_164547|-- Config --
21Feb12_164547|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164547|-- Weights --
21Feb12_164547|[[ 0.52831 -1.83497]
21Feb12_164547| [ 0.77899 -0.32202]
21Feb12_164547| [ 0.58373  0.74305]
21Feb12_164547| [ 0.15087 -0.14917]]
21Feb12_164547|-- Bias --
21Feb12_164547|[0.90094 0.19971]
21Feb12_164547|Layer 3:
21Feb12_164547|-- Config --
21Feb12_164547|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164547|-- Weights --
21Feb12_164547|[[-0.58484 -0.20452  0.13986]
21Feb12_164547| [-1.32761  0.10456  0.03000]]
21Feb12_164547|-- Bias --
21Feb12_164547|[ 0.60328 -0.84742 -0.37995]
21Feb12_164547|Layer 4:
21Feb12_164547|-- Config --
21Feb12_164547|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164547|-- Weights --
21Feb12_164547|[[ 0.76417 -0.21062]
21Feb12_164547| [ 0.49932 -0.62750]
21Feb12_164547| [ 0.28442  0.31657]]
21Feb12_164547|-- Bias --
21Feb12_164547|[ 0.89049 -0.61218]
21Feb12_164547|Layer 5:
21Feb12_164547|-- Config --
21Feb12_164547|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164547|-- Weights --
21Feb12_164547|[[-0.24887  0.29658]
21Feb12_164547| [-0.75856  0.32450]]
21Feb12_164547|-- Bias --
21Feb12_164547|[-0.20865  0.78432]
21Feb12_164547|Predicting the validation and test data with the Best final individual.
21Feb12_164556| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_164556|-----------  ------------------  --------------------  ----------
21Feb12_164556|Validation         22.26                  80            0.61137
21Feb12_164556|   Test            27.80                  80            0.38559
21Feb12_164556|-------------------- Test #9 --------------------
21Feb12_164556|Best final individual weights
21Feb12_164556|Individual:
21Feb12_164556|-- Constant hidden layers --
21Feb12_164556|False
21Feb12_164556|Layer 0:
21Feb12_164556|-- Config --
21Feb12_164556|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164556|-- Weights --
21Feb12_164556|[[-7.91355e-01  2.43120e+00 -8.07061e-01 -3.94286e-01  3.19125e-01]
21Feb12_164556| [ 6.32169e-01  1.11702e+00  4.18321e-01  1.42293e+00 -7.32555e-02]
21Feb12_164556| [-3.48284e-02  1.24559e+00  2.44475e-02  8.48326e-01 -4.64233e-01]
21Feb12_164556| [ 1.17440e+00  3.81583e-01  2.14959e+00  2.13845e-01  1.46366e-01]
21Feb12_164556| [ 4.44159e-01 -1.12940e-02  5.13247e-01 -6.29180e-01 -2.98321e-01]
21Feb12_164556| [ 1.37424e+00 -1.43437e+00 -6.44080e-01  1.41356e+00  2.98025e-01]
21Feb12_164556| [-7.67760e-01  7.93907e-01 -5.67129e-01  1.19634e+00  1.52366e-01]
21Feb12_164556| [-7.08021e-02 -1.80961e+00  1.04882e+00 -1.67209e+00 -2.72411e-01]
21Feb12_164556| [-1.39134e-01 -5.77581e-01  5.25041e-01  1.42652e+00  1.03720e-01]
21Feb12_164556| [-1.07529e+00  3.55062e-02 -2.17335e+00  2.19168e-01  8.29057e-02]
21Feb12_164556| [-4.45037e-01 -4.03228e-01 -2.01532e-01  8.77376e-01  2.81343e-01]
21Feb12_164556| [ 7.19570e-01 -6.79061e-01 -1.60597e-01  8.08258e-01 -3.25257e-01]
21Feb12_164556| [-5.31401e-01  4.04345e-01  1.93758e+00 -4.60418e-01  4.68916e-01]
21Feb12_164556| [-2.13940e-01 -4.75579e-02 -1.36023e+00 -1.19475e-01 -2.31293e-01]
21Feb12_164556| [ 7.36033e-01 -8.15896e-01 -4.37717e-01  1.67296e+00 -1.20651e-01]
21Feb12_164556| [ 7.16388e-01  1.04087e+00 -1.07113e+00  2.07376e+00  1.83025e-01]
21Feb12_164556| [-5.72677e-01 -1.52863e-01  6.40245e-01 -1.37548e-01  2.41768e-01]
21Feb12_164556| [-2.01843e+00 -5.99701e-01 -1.32540e+00  2.25850e-01 -2.56690e-01]
21Feb12_164556| [-4.10261e-01 -8.13422e-01 -4.48009e-01 -3.61940e-01  4.67163e-02]
21Feb12_164556| [ 5.31285e-01  8.03485e-01  4.18423e-01 -2.97820e-01  3.11368e-01]
21Feb12_164556| [ 3.61796e-01 -9.21000e-01 -5.44164e-01 -1.38174e+00  1.80521e-01]
21Feb12_164556| [-4.75496e-01  9.05014e-01  2.36627e+00 -4.94079e-02 -3.36261e-01]
21Feb12_164556| [ 3.71397e-01  4.02431e-01  2.55986e-01  1.78623e-01 -1.70784e-01]
21Feb12_164556| [-3.82692e-01  1.40831e+00  8.55174e-01 -9.90708e-01 -2.96574e-01]
21Feb12_164556| [ 8.55878e-01 -1.28641e+00 -1.27577e-01  1.71285e+00  3.68193e-01]
21Feb12_164556| [-1.38112e-01 -2.03789e+00  1.37740e+00 -1.13825e+00 -1.40275e-01]
21Feb12_164556| [ 1.16784e-01 -1.01605e-01  6.50576e-01 -1.24867e+00  1.59576e-01]
21Feb12_164556| [-6.69357e-02  5.95912e-01  9.10702e-01 -9.96770e-01 -4.54797e-01]
21Feb12_164556| [-3.26068e-01  5.34200e-01  6.46798e-01 -6.85025e-01 -4.96585e-01]
21Feb12_164556| [-5.34229e-01  7.35933e-01 -1.25152e+00 -2.77515e-01 -2.30796e-01]
21Feb12_164556| [ 5.63815e-01  1.25123e-01  3.62872e-01  1.44226e+00  4.48351e-01]
21Feb12_164556| [-4.83407e-01  6.11778e-03 -7.29776e-01  3.97953e-01 -2.35147e-01]
21Feb12_164556| [-4.06974e-01  4.89918e-01 -1.61581e+00 -7.37000e-01  2.22498e-01]
21Feb12_164556| [ 6.06985e-01  1.58098e-01 -1.30279e+00  1.09222e+00  9.42671e-02]
21Feb12_164556| [ 3.00917e-01 -4.38970e-01  6.67241e-01  7.60470e-01  1.72456e-01]
21Feb12_164556| [ 2.61099e-02  8.76452e-02  2.06721e+00 -9.40037e-01  9.36414e-02]
21Feb12_164556| [-5.66141e-01 -1.65301e+00 -8.72837e-02 -1.13373e+00  8.58644e-02]
21Feb12_164556| [-6.85789e-01 -2.27794e+00  2.86336e-01 -9.87500e-01  5.29605e-02]
21Feb12_164556| [ 2.76455e-01 -9.02853e-01 -8.98832e-01  2.10718e+00  2.36407e-01]
21Feb12_164556| [ 2.60908e-01 -2.86778e-01 -1.41586e+00  2.84419e-01 -2.34253e-01]
21Feb12_164556| [ 2.02249e+00 -1.56278e-02 -1.11757e+00  1.13346e+00  1.02623e-01]
21Feb12_164556| [ 1.99017e-02  4.60107e-04 -6.77307e-01 -5.15077e-01  2.53077e-01]
21Feb12_164556| [ 4.24908e-01  5.22426e-01  6.86959e-01  2.52109e+00 -4.59536e-01]
21Feb12_164556| [ 1.02097e+00  4.94626e-01 -3.87759e-01 -3.06730e-01 -4.17139e-01]
21Feb12_164556| [ 8.70831e-01 -4.45426e-02 -1.33056e+00 -5.49784e-01  2.09440e-02]
21Feb12_164556| [ 8.94189e-02 -2.08384e-01  1.21988e+00 -1.03680e+00 -4.09728e-01]
21Feb12_164556| [ 3.67773e-01 -2.38648e-01 -5.69402e-01 -6.91178e-01  3.00814e-01]
21Feb12_164556| [ 1.04658e+00 -8.03105e-01 -6.97413e-01  1.10650e+00 -2.58323e-01]
21Feb12_164556| [ 9.13179e-01  5.52011e-01  7.55601e-01  1.05981e+00  4.83711e-01]
21Feb12_164556| [-1.25875e+00  8.22927e-01  4.69172e-01  1.97213e-01  6.81926e-02]
21Feb12_164556| [ 1.41226e+00  1.40448e+00  2.28829e-01  1.30923e-01  3.23683e-01]
21Feb12_164556| [ 1.04333e+00 -5.42566e-01  1.66765e-01 -3.15393e-01 -2.05789e-02]
21Feb12_164556| [-4.49591e-01 -1.17282e-01 -9.31887e-02  7.86023e-03  2.01356e-01]
21Feb12_164556| [-5.06666e-01  2.51321e-01 -8.58761e-01  5.41108e-01  5.01461e-02]
21Feb12_164556| [-5.11638e-01  1.74281e+00  6.27990e-02  4.80699e-01  3.70887e-01]
21Feb12_164556| [-7.89485e-01  5.47937e-01 -7.29595e-01 -1.69570e-01  3.23468e-01]
21Feb12_164556| [ 5.81765e-01 -1.17246e-01 -3.09404e-02 -2.04408e-01  6.36081e-02]]
21Feb12_164556|-- Bias --
21Feb12_164556|[-0.54319  0.86182 -0.33228  0.44716 -0.38324]
21Feb12_164556|Layer 1:
21Feb12_164556|-- Config --
21Feb12_164556|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164556|-- Weights --
21Feb12_164556|[[-1.46361 -0.19988 -0.22811 -0.32750]
21Feb12_164556| [-0.44277  0.32306  0.33898 -0.11401]
21Feb12_164556| [-1.02744  0.96055  0.41108 -0.17247]
21Feb12_164556| [-0.45828  0.85211 -0.97745  0.52726]
21Feb12_164556| [ 0.04378 -0.23006 -0.08426  0.42305]]
21Feb12_164556|-- Bias --
21Feb12_164556|[-1.73575 -0.27258 -0.42762  0.23958]
21Feb12_164556|Layer 2:
21Feb12_164556|-- Config --
21Feb12_164556|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164556|-- Weights --
21Feb12_164556|[[ 0.52831 -1.83497]
21Feb12_164556| [ 0.77899 -0.32202]
21Feb12_164556| [ 0.58373  0.74305]
21Feb12_164556| [ 0.15087 -0.14917]]
21Feb12_164556|-- Bias --
21Feb12_164556|[0.90094 0.19971]
21Feb12_164556|Layer 3:
21Feb12_164556|-- Config --
21Feb12_164556|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164556|-- Weights --
21Feb12_164556|[[-0.58484 -0.20452  0.13986]
21Feb12_164556| [-1.32761  0.10456  0.03000]]
21Feb12_164556|-- Bias --
21Feb12_164556|[ 0.60328 -0.84742 -0.37995]
21Feb12_164556|Layer 4:
21Feb12_164556|-- Config --
21Feb12_164556|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164556|-- Weights --
21Feb12_164556|[[ 0.76417 -0.21062]
21Feb12_164556| [ 0.49932 -0.62750]
21Feb12_164556| [ 0.28442  0.31657]]
21Feb12_164556|-- Bias --
21Feb12_164556|[ 0.89049 -0.61218]
21Feb12_164556|Layer 5:
21Feb12_164556|-- Config --
21Feb12_164556|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164556|-- Weights --
21Feb12_164556|[[-0.24887  0.29658]
21Feb12_164556| [-0.75856  0.32450]]
21Feb12_164556|-- Bias --
21Feb12_164556|[-0.20865  0.78432]
21Feb12_164556|Predicting the validation and test data with the Best final individual.
21Feb12_164604| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_164604|-----------  ------------------  --------------------  ----------
21Feb12_164604|Validation         31.30                  80            0.25634
21Feb12_164604|   Test            23.72                  80            0.56590
21Feb12_164604|-------------------- Test #10 --------------------
21Feb12_164604|Best final individual weights
21Feb12_164604|Individual:
21Feb12_164604|-- Constant hidden layers --
21Feb12_164604|False
21Feb12_164604|Layer 0:
21Feb12_164604|-- Config --
21Feb12_164604|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164604|-- Weights --
21Feb12_164604|[[-7.91355e-01  2.43120e+00 -8.07061e-01 -3.94286e-01  3.19125e-01]
21Feb12_164604| [ 6.32169e-01  1.11702e+00  4.18321e-01  1.42293e+00 -7.32555e-02]
21Feb12_164604| [-3.48284e-02  1.24559e+00  2.44475e-02  8.48326e-01 -4.64233e-01]
21Feb12_164604| [ 1.17440e+00  3.81583e-01  2.14959e+00  2.13845e-01  1.46366e-01]
21Feb12_164604| [ 4.44159e-01 -1.12940e-02  5.13247e-01 -6.29180e-01 -2.98321e-01]
21Feb12_164604| [ 1.37424e+00 -1.43437e+00 -6.44080e-01  1.41356e+00  2.98025e-01]
21Feb12_164604| [-7.67760e-01  7.93907e-01 -5.67129e-01  1.19634e+00  1.52366e-01]
21Feb12_164604| [-7.08021e-02 -1.80961e+00  1.04882e+00 -1.67209e+00 -2.72411e-01]
21Feb12_164604| [-1.39134e-01 -5.77581e-01  5.25041e-01  1.42652e+00  1.03720e-01]
21Feb12_164604| [-1.07529e+00  3.55062e-02 -2.17335e+00  2.19168e-01  8.29057e-02]
21Feb12_164604| [-4.45037e-01 -4.03228e-01 -2.01532e-01  8.77376e-01  2.81343e-01]
21Feb12_164604| [ 7.19570e-01 -6.79061e-01 -1.60597e-01  8.08258e-01 -3.25257e-01]
21Feb12_164604| [-5.31401e-01  4.04345e-01  1.93758e+00 -4.60418e-01  4.68916e-01]
21Feb12_164604| [-2.13940e-01 -4.75579e-02 -1.36023e+00 -1.19475e-01 -2.31293e-01]
21Feb12_164604| [ 7.36033e-01 -8.15896e-01 -4.37717e-01  1.67296e+00 -1.20651e-01]
21Feb12_164604| [ 7.16388e-01  1.04087e+00 -1.07113e+00  2.07376e+00  1.83025e-01]
21Feb12_164604| [-5.72677e-01 -1.52863e-01  6.40245e-01 -1.37548e-01  2.41768e-01]
21Feb12_164604| [-2.01843e+00 -5.99701e-01 -1.32540e+00  2.25850e-01 -2.56690e-01]
21Feb12_164604| [-4.10261e-01 -8.13422e-01 -4.48009e-01 -3.61940e-01  4.67163e-02]
21Feb12_164604| [ 5.31285e-01  8.03485e-01  4.18423e-01 -2.97820e-01  3.11368e-01]
21Feb12_164604| [ 3.61796e-01 -9.21000e-01 -5.44164e-01 -1.38174e+00  1.80521e-01]
21Feb12_164604| [-4.75496e-01  9.05014e-01  2.36627e+00 -4.94079e-02 -3.36261e-01]
21Feb12_164604| [ 3.71397e-01  4.02431e-01  2.55986e-01  1.78623e-01 -1.70784e-01]
21Feb12_164604| [-3.82692e-01  1.40831e+00  8.55174e-01 -9.90708e-01 -2.96574e-01]
21Feb12_164604| [ 8.55878e-01 -1.28641e+00 -1.27577e-01  1.71285e+00  3.68193e-01]
21Feb12_164604| [-1.38112e-01 -2.03789e+00  1.37740e+00 -1.13825e+00 -1.40275e-01]
21Feb12_164604| [ 1.16784e-01 -1.01605e-01  6.50576e-01 -1.24867e+00  1.59576e-01]
21Feb12_164604| [-6.69357e-02  5.95912e-01  9.10702e-01 -9.96770e-01 -4.54797e-01]
21Feb12_164604| [-3.26068e-01  5.34200e-01  6.46798e-01 -6.85025e-01 -4.96585e-01]
21Feb12_164604| [-5.34229e-01  7.35933e-01 -1.25152e+00 -2.77515e-01 -2.30796e-01]
21Feb12_164604| [ 5.63815e-01  1.25123e-01  3.62872e-01  1.44226e+00  4.48351e-01]
21Feb12_164604| [-4.83407e-01  6.11778e-03 -7.29776e-01  3.97953e-01 -2.35147e-01]
21Feb12_164604| [-4.06974e-01  4.89918e-01 -1.61581e+00 -7.37000e-01  2.22498e-01]
21Feb12_164604| [ 6.06985e-01  1.58098e-01 -1.30279e+00  1.09222e+00  9.42671e-02]
21Feb12_164604| [ 3.00917e-01 -4.38970e-01  6.67241e-01  7.60470e-01  1.72456e-01]
21Feb12_164604| [ 2.61099e-02  8.76452e-02  2.06721e+00 -9.40037e-01  9.36414e-02]
21Feb12_164604| [-5.66141e-01 -1.65301e+00 -8.72837e-02 -1.13373e+00  8.58644e-02]
21Feb12_164604| [-6.85789e-01 -2.27794e+00  2.86336e-01 -9.87500e-01  5.29605e-02]
21Feb12_164604| [ 2.76455e-01 -9.02853e-01 -8.98832e-01  2.10718e+00  2.36407e-01]
21Feb12_164604| [ 2.60908e-01 -2.86778e-01 -1.41586e+00  2.84419e-01 -2.34253e-01]
21Feb12_164604| [ 2.02249e+00 -1.56278e-02 -1.11757e+00  1.13346e+00  1.02623e-01]
21Feb12_164604| [ 1.99017e-02  4.60107e-04 -6.77307e-01 -5.15077e-01  2.53077e-01]
21Feb12_164604| [ 4.24908e-01  5.22426e-01  6.86959e-01  2.52109e+00 -4.59536e-01]
21Feb12_164604| [ 1.02097e+00  4.94626e-01 -3.87759e-01 -3.06730e-01 -4.17139e-01]
21Feb12_164604| [ 8.70831e-01 -4.45426e-02 -1.33056e+00 -5.49784e-01  2.09440e-02]
21Feb12_164604| [ 8.94189e-02 -2.08384e-01  1.21988e+00 -1.03680e+00 -4.09728e-01]
21Feb12_164604| [ 3.67773e-01 -2.38648e-01 -5.69402e-01 -6.91178e-01  3.00814e-01]
21Feb12_164604| [ 1.04658e+00 -8.03105e-01 -6.97413e-01  1.10650e+00 -2.58323e-01]
21Feb12_164604| [ 9.13179e-01  5.52011e-01  7.55601e-01  1.05981e+00  4.83711e-01]
21Feb12_164604| [-1.25875e+00  8.22927e-01  4.69172e-01  1.97213e-01  6.81926e-02]
21Feb12_164604| [ 1.41226e+00  1.40448e+00  2.28829e-01  1.30923e-01  3.23683e-01]
21Feb12_164604| [ 1.04333e+00 -5.42566e-01  1.66765e-01 -3.15393e-01 -2.05789e-02]
21Feb12_164604| [-4.49591e-01 -1.17282e-01 -9.31887e-02  7.86023e-03  2.01356e-01]
21Feb12_164604| [-5.06666e-01  2.51321e-01 -8.58761e-01  5.41108e-01  5.01461e-02]
21Feb12_164604| [-5.11638e-01  1.74281e+00  6.27990e-02  4.80699e-01  3.70887e-01]
21Feb12_164604| [-7.89485e-01  5.47937e-01 -7.29595e-01 -1.69570e-01  3.23468e-01]
21Feb12_164604| [ 5.81765e-01 -1.17246e-01 -3.09404e-02 -2.04408e-01  6.36081e-02]]
21Feb12_164604|-- Bias --
21Feb12_164604|[-0.54319  0.86182 -0.33228  0.44716 -0.38324]
21Feb12_164604|Layer 1:
21Feb12_164604|-- Config --
21Feb12_164604|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164604|-- Weights --
21Feb12_164604|[[-1.46361 -0.19988 -0.22811 -0.32750]
21Feb12_164604| [-0.44277  0.32306  0.33898 -0.11401]
21Feb12_164604| [-1.02744  0.96055  0.41108 -0.17247]
21Feb12_164604| [-0.45828  0.85211 -0.97745  0.52726]
21Feb12_164604| [ 0.04378 -0.23006 -0.08426  0.42305]]
21Feb12_164604|-- Bias --
21Feb12_164604|[-1.73575 -0.27258 -0.42762  0.23958]
21Feb12_164604|Layer 2:
21Feb12_164604|-- Config --
21Feb12_164604|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164604|-- Weights --
21Feb12_164604|[[ 0.52831 -1.83497]
21Feb12_164604| [ 0.77899 -0.32202]
21Feb12_164604| [ 0.58373  0.74305]
21Feb12_164604| [ 0.15087 -0.14917]]
21Feb12_164604|-- Bias --
21Feb12_164604|[0.90094 0.19971]
21Feb12_164604|Layer 3:
21Feb12_164604|-- Config --
21Feb12_164604|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164604|-- Weights --
21Feb12_164604|[[-0.58484 -0.20452  0.13986]
21Feb12_164604| [-1.32761  0.10456  0.03000]]
21Feb12_164604|-- Bias --
21Feb12_164604|[ 0.60328 -0.84742 -0.37995]
21Feb12_164604|Layer 4:
21Feb12_164604|-- Config --
21Feb12_164604|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164604|-- Weights --
21Feb12_164604|[[ 0.76417 -0.21062]
21Feb12_164604| [ 0.49932 -0.62750]
21Feb12_164604| [ 0.28442  0.31657]]
21Feb12_164604|-- Bias --
21Feb12_164604|[ 0.89049 -0.61218]
21Feb12_164604|Layer 5:
21Feb12_164604|-- Config --
21Feb12_164604|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164604|-- Weights --
21Feb12_164604|[[-0.24887  0.29658]
21Feb12_164604| [-0.75856  0.32450]]
21Feb12_164604|-- Bias --
21Feb12_164604|[-0.20865  0.78432]
21Feb12_164604|Predicting the validation and test data with the Best final individual.
21Feb12_164613| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_164613|-----------  ------------------  --------------------  ----------
21Feb12_164613|Validation         32.35                  80            0.22122
21Feb12_164613|   Test            26.50                  80            0.42254
21Feb12_164613|-------------------- Test #11 --------------------
21Feb12_164613|Best final individual weights
21Feb12_164613|Individual:
21Feb12_164613|-- Constant hidden layers --
21Feb12_164613|False
21Feb12_164613|Layer 0:
21Feb12_164613|-- Config --
21Feb12_164613|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164613|-- Weights --
21Feb12_164613|[[-7.91355e-01  2.43120e+00 -8.07061e-01 -3.94286e-01  3.19125e-01]
21Feb12_164613| [ 6.32169e-01  1.11702e+00  4.18321e-01  1.42293e+00 -7.32555e-02]
21Feb12_164613| [-3.48284e-02  1.24559e+00  2.44475e-02  8.48326e-01 -4.64233e-01]
21Feb12_164613| [ 1.17440e+00  3.81583e-01  2.14959e+00  2.13845e-01  1.46366e-01]
21Feb12_164613| [ 4.44159e-01 -1.12940e-02  5.13247e-01 -6.29180e-01 -2.98321e-01]
21Feb12_164613| [ 1.37424e+00 -1.43437e+00 -6.44080e-01  1.41356e+00  2.98025e-01]
21Feb12_164613| [-7.67760e-01  7.93907e-01 -5.67129e-01  1.19634e+00  1.52366e-01]
21Feb12_164613| [-7.08021e-02 -1.80961e+00  1.04882e+00 -1.67209e+00 -2.72411e-01]
21Feb12_164613| [-1.39134e-01 -5.77581e-01  5.25041e-01  1.42652e+00  1.03720e-01]
21Feb12_164613| [-1.07529e+00  3.55062e-02 -2.17335e+00  2.19168e-01  8.29057e-02]
21Feb12_164613| [-4.45037e-01 -4.03228e-01 -2.01532e-01  8.77376e-01  2.81343e-01]
21Feb12_164613| [ 7.19570e-01 -6.79061e-01 -1.60597e-01  8.08258e-01 -3.25257e-01]
21Feb12_164613| [-5.31401e-01  4.04345e-01  1.93758e+00 -4.60418e-01  4.68916e-01]
21Feb12_164613| [-2.13940e-01 -4.75579e-02 -1.36023e+00 -1.19475e-01 -2.31293e-01]
21Feb12_164613| [ 7.36033e-01 -8.15896e-01 -4.37717e-01  1.67296e+00 -1.20651e-01]
21Feb12_164613| [ 7.16388e-01  1.04087e+00 -1.07113e+00  2.07376e+00  1.83025e-01]
21Feb12_164613| [-5.72677e-01 -1.52863e-01  6.40245e-01 -1.37548e-01  2.41768e-01]
21Feb12_164613| [-2.01843e+00 -5.99701e-01 -1.32540e+00  2.25850e-01 -2.56690e-01]
21Feb12_164613| [-4.10261e-01 -8.13422e-01 -4.48009e-01 -3.61940e-01  4.67163e-02]
21Feb12_164613| [ 5.31285e-01  8.03485e-01  4.18423e-01 -2.97820e-01  3.11368e-01]
21Feb12_164613| [ 3.61796e-01 -9.21000e-01 -5.44164e-01 -1.38174e+00  1.80521e-01]
21Feb12_164613| [-4.75496e-01  9.05014e-01  2.36627e+00 -4.94079e-02 -3.36261e-01]
21Feb12_164613| [ 3.71397e-01  4.02431e-01  2.55986e-01  1.78623e-01 -1.70784e-01]
21Feb12_164613| [-3.82692e-01  1.40831e+00  8.55174e-01 -9.90708e-01 -2.96574e-01]
21Feb12_164613| [ 8.55878e-01 -1.28641e+00 -1.27577e-01  1.71285e+00  3.68193e-01]
21Feb12_164613| [-1.38112e-01 -2.03789e+00  1.37740e+00 -1.13825e+00 -1.40275e-01]
21Feb12_164613| [ 1.16784e-01 -1.01605e-01  6.50576e-01 -1.24867e+00  1.59576e-01]
21Feb12_164613| [-6.69357e-02  5.95912e-01  9.10702e-01 -9.96770e-01 -4.54797e-01]
21Feb12_164613| [-3.26068e-01  5.34200e-01  6.46798e-01 -6.85025e-01 -4.96585e-01]
21Feb12_164613| [-5.34229e-01  7.35933e-01 -1.25152e+00 -2.77515e-01 -2.30796e-01]
21Feb12_164613| [ 5.63815e-01  1.25123e-01  3.62872e-01  1.44226e+00  4.48351e-01]
21Feb12_164613| [-4.83407e-01  6.11778e-03 -7.29776e-01  3.97953e-01 -2.35147e-01]
21Feb12_164613| [-4.06974e-01  4.89918e-01 -1.61581e+00 -7.37000e-01  2.22498e-01]
21Feb12_164613| [ 6.06985e-01  1.58098e-01 -1.30279e+00  1.09222e+00  9.42671e-02]
21Feb12_164613| [ 3.00917e-01 -4.38970e-01  6.67241e-01  7.60470e-01  1.72456e-01]
21Feb12_164613| [ 2.61099e-02  8.76452e-02  2.06721e+00 -9.40037e-01  9.36414e-02]
21Feb12_164613| [-5.66141e-01 -1.65301e+00 -8.72837e-02 -1.13373e+00  8.58644e-02]
21Feb12_164613| [-6.85789e-01 -2.27794e+00  2.86336e-01 -9.87500e-01  5.29605e-02]
21Feb12_164613| [ 2.76455e-01 -9.02853e-01 -8.98832e-01  2.10718e+00  2.36407e-01]
21Feb12_164613| [ 2.60908e-01 -2.86778e-01 -1.41586e+00  2.84419e-01 -2.34253e-01]
21Feb12_164613| [ 2.02249e+00 -1.56278e-02 -1.11757e+00  1.13346e+00  1.02623e-01]
21Feb12_164613| [ 1.99017e-02  4.60107e-04 -6.77307e-01 -5.15077e-01  2.53077e-01]
21Feb12_164613| [ 4.24908e-01  5.22426e-01  6.86959e-01  2.52109e+00 -4.59536e-01]
21Feb12_164613| [ 1.02097e+00  4.94626e-01 -3.87759e-01 -3.06730e-01 -4.17139e-01]
21Feb12_164613| [ 8.70831e-01 -4.45426e-02 -1.33056e+00 -5.49784e-01  2.09440e-02]
21Feb12_164613| [ 8.94189e-02 -2.08384e-01  1.21988e+00 -1.03680e+00 -4.09728e-01]
21Feb12_164613| [ 3.67773e-01 -2.38648e-01 -5.69402e-01 -6.91178e-01  3.00814e-01]
21Feb12_164613| [ 1.04658e+00 -8.03105e-01 -6.97413e-01  1.10650e+00 -2.58323e-01]
21Feb12_164613| [ 9.13179e-01  5.52011e-01  7.55601e-01  1.05981e+00  4.83711e-01]
21Feb12_164613| [-1.25875e+00  8.22927e-01  4.69172e-01  1.97213e-01  6.81926e-02]
21Feb12_164613| [ 1.41226e+00  1.40448e+00  2.28829e-01  1.30923e-01  3.23683e-01]
21Feb12_164613| [ 1.04333e+00 -5.42566e-01  1.66765e-01 -3.15393e-01 -2.05789e-02]
21Feb12_164613| [-4.49591e-01 -1.17282e-01 -9.31887e-02  7.86023e-03  2.01356e-01]
21Feb12_164613| [-5.06666e-01  2.51321e-01 -8.58761e-01  5.41108e-01  5.01461e-02]
21Feb12_164613| [-5.11638e-01  1.74281e+00  6.27990e-02  4.80699e-01  3.70887e-01]
21Feb12_164613| [-7.89485e-01  5.47937e-01 -7.29595e-01 -1.69570e-01  3.23468e-01]
21Feb12_164613| [ 5.81765e-01 -1.17246e-01 -3.09404e-02 -2.04408e-01  6.36081e-02]]
21Feb12_164613|-- Bias --
21Feb12_164613|[-0.54319  0.86182 -0.33228  0.44716 -0.38324]
21Feb12_164613|Layer 1:
21Feb12_164613|-- Config --
21Feb12_164613|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164613|-- Weights --
21Feb12_164613|[[-1.46361 -0.19988 -0.22811 -0.32750]
21Feb12_164613| [-0.44277  0.32306  0.33898 -0.11401]
21Feb12_164613| [-1.02744  0.96055  0.41108 -0.17247]
21Feb12_164613| [-0.45828  0.85211 -0.97745  0.52726]
21Feb12_164613| [ 0.04378 -0.23006 -0.08426  0.42305]]
21Feb12_164613|-- Bias --
21Feb12_164613|[-1.73575 -0.27258 -0.42762  0.23958]
21Feb12_164613|Layer 2:
21Feb12_164613|-- Config --
21Feb12_164613|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164613|-- Weights --
21Feb12_164613|[[ 0.52831 -1.83497]
21Feb12_164613| [ 0.77899 -0.32202]
21Feb12_164613| [ 0.58373  0.74305]
21Feb12_164613| [ 0.15087 -0.14917]]
21Feb12_164613|-- Bias --
21Feb12_164613|[0.90094 0.19971]
21Feb12_164613|Layer 3:
21Feb12_164613|-- Config --
21Feb12_164613|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164613|-- Weights --
21Feb12_164613|[[-0.58484 -0.20452  0.13986]
21Feb12_164613| [-1.32761  0.10456  0.03000]]
21Feb12_164613|-- Bias --
21Feb12_164613|[ 0.60328 -0.84742 -0.37995]
21Feb12_164613|Layer 4:
21Feb12_164613|-- Config --
21Feb12_164613|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164613|-- Weights --
21Feb12_164613|[[ 0.76417 -0.21062]
21Feb12_164613| [ 0.49932 -0.62750]
21Feb12_164613| [ 0.28442  0.31657]]
21Feb12_164613|-- Bias --
21Feb12_164613|[ 0.89049 -0.61218]
21Feb12_164613|Layer 5:
21Feb12_164613|-- Config --
21Feb12_164613|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164613|-- Weights --
21Feb12_164613|[[-0.24887  0.29658]
21Feb12_164613| [-0.75856  0.32450]]
21Feb12_164613|-- Bias --
21Feb12_164613|[-0.20865  0.78432]
21Feb12_164613|Predicting the validation and test data with the Best final individual.
21Feb12_164621| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_164621|-----------  ------------------  --------------------  ----------
21Feb12_164621|Validation         29.57                  80            0.32191
21Feb12_164621|   Test            22.94                  80            0.60292
21Feb12_164621|-------------------- Test #12 --------------------
21Feb12_164621|Best final individual weights
21Feb12_164621|Individual:
21Feb12_164621|-- Constant hidden layers --
21Feb12_164621|False
21Feb12_164621|Layer 0:
21Feb12_164621|-- Config --
21Feb12_164621|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164621|-- Weights --
21Feb12_164621|[[-7.91355e-01  2.43120e+00 -8.07061e-01 -3.94286e-01  3.19125e-01]
21Feb12_164621| [ 6.32169e-01  1.11702e+00  4.18321e-01  1.42293e+00 -7.32555e-02]
21Feb12_164621| [-3.48284e-02  1.24559e+00  2.44475e-02  8.48326e-01 -4.64233e-01]
21Feb12_164621| [ 1.17440e+00  3.81583e-01  2.14959e+00  2.13845e-01  1.46366e-01]
21Feb12_164621| [ 4.44159e-01 -1.12940e-02  5.13247e-01 -6.29180e-01 -2.98321e-01]
21Feb12_164621| [ 1.37424e+00 -1.43437e+00 -6.44080e-01  1.41356e+00  2.98025e-01]
21Feb12_164621| [-7.67760e-01  7.93907e-01 -5.67129e-01  1.19634e+00  1.52366e-01]
21Feb12_164621| [-7.08021e-02 -1.80961e+00  1.04882e+00 -1.67209e+00 -2.72411e-01]
21Feb12_164621| [-1.39134e-01 -5.77581e-01  5.25041e-01  1.42652e+00  1.03720e-01]
21Feb12_164621| [-1.07529e+00  3.55062e-02 -2.17335e+00  2.19168e-01  8.29057e-02]
21Feb12_164621| [-4.45037e-01 -4.03228e-01 -2.01532e-01  8.77376e-01  2.81343e-01]
21Feb12_164621| [ 7.19570e-01 -6.79061e-01 -1.60597e-01  8.08258e-01 -3.25257e-01]
21Feb12_164621| [-5.31401e-01  4.04345e-01  1.93758e+00 -4.60418e-01  4.68916e-01]
21Feb12_164621| [-2.13940e-01 -4.75579e-02 -1.36023e+00 -1.19475e-01 -2.31293e-01]
21Feb12_164621| [ 7.36033e-01 -8.15896e-01 -4.37717e-01  1.67296e+00 -1.20651e-01]
21Feb12_164621| [ 7.16388e-01  1.04087e+00 -1.07113e+00  2.07376e+00  1.83025e-01]
21Feb12_164621| [-5.72677e-01 -1.52863e-01  6.40245e-01 -1.37548e-01  2.41768e-01]
21Feb12_164621| [-2.01843e+00 -5.99701e-01 -1.32540e+00  2.25850e-01 -2.56690e-01]
21Feb12_164621| [-4.10261e-01 -8.13422e-01 -4.48009e-01 -3.61940e-01  4.67163e-02]
21Feb12_164621| [ 5.31285e-01  8.03485e-01  4.18423e-01 -2.97820e-01  3.11368e-01]
21Feb12_164621| [ 3.61796e-01 -9.21000e-01 -5.44164e-01 -1.38174e+00  1.80521e-01]
21Feb12_164621| [-4.75496e-01  9.05014e-01  2.36627e+00 -4.94079e-02 -3.36261e-01]
21Feb12_164621| [ 3.71397e-01  4.02431e-01  2.55986e-01  1.78623e-01 -1.70784e-01]
21Feb12_164621| [-3.82692e-01  1.40831e+00  8.55174e-01 -9.90708e-01 -2.96574e-01]
21Feb12_164621| [ 8.55878e-01 -1.28641e+00 -1.27577e-01  1.71285e+00  3.68193e-01]
21Feb12_164621| [-1.38112e-01 -2.03789e+00  1.37740e+00 -1.13825e+00 -1.40275e-01]
21Feb12_164621| [ 1.16784e-01 -1.01605e-01  6.50576e-01 -1.24867e+00  1.59576e-01]
21Feb12_164621| [-6.69357e-02  5.95912e-01  9.10702e-01 -9.96770e-01 -4.54797e-01]
21Feb12_164621| [-3.26068e-01  5.34200e-01  6.46798e-01 -6.85025e-01 -4.96585e-01]
21Feb12_164621| [-5.34229e-01  7.35933e-01 -1.25152e+00 -2.77515e-01 -2.30796e-01]
21Feb12_164621| [ 5.63815e-01  1.25123e-01  3.62872e-01  1.44226e+00  4.48351e-01]
21Feb12_164621| [-4.83407e-01  6.11778e-03 -7.29776e-01  3.97953e-01 -2.35147e-01]
21Feb12_164621| [-4.06974e-01  4.89918e-01 -1.61581e+00 -7.37000e-01  2.22498e-01]
21Feb12_164621| [ 6.06985e-01  1.58098e-01 -1.30279e+00  1.09222e+00  9.42671e-02]
21Feb12_164621| [ 3.00917e-01 -4.38970e-01  6.67241e-01  7.60470e-01  1.72456e-01]
21Feb12_164621| [ 2.61099e-02  8.76452e-02  2.06721e+00 -9.40037e-01  9.36414e-02]
21Feb12_164621| [-5.66141e-01 -1.65301e+00 -8.72837e-02 -1.13373e+00  8.58644e-02]
21Feb12_164621| [-6.85789e-01 -2.27794e+00  2.86336e-01 -9.87500e-01  5.29605e-02]
21Feb12_164621| [ 2.76455e-01 -9.02853e-01 -8.98832e-01  2.10718e+00  2.36407e-01]
21Feb12_164621| [ 2.60908e-01 -2.86778e-01 -1.41586e+00  2.84419e-01 -2.34253e-01]
21Feb12_164621| [ 2.02249e+00 -1.56278e-02 -1.11757e+00  1.13346e+00  1.02623e-01]
21Feb12_164621| [ 1.99017e-02  4.60107e-04 -6.77307e-01 -5.15077e-01  2.53077e-01]
21Feb12_164621| [ 4.24908e-01  5.22426e-01  6.86959e-01  2.52109e+00 -4.59536e-01]
21Feb12_164621| [ 1.02097e+00  4.94626e-01 -3.87759e-01 -3.06730e-01 -4.17139e-01]
21Feb12_164621| [ 8.70831e-01 -4.45426e-02 -1.33056e+00 -5.49784e-01  2.09440e-02]
21Feb12_164621| [ 8.94189e-02 -2.08384e-01  1.21988e+00 -1.03680e+00 -4.09728e-01]
21Feb12_164621| [ 3.67773e-01 -2.38648e-01 -5.69402e-01 -6.91178e-01  3.00814e-01]
21Feb12_164621| [ 1.04658e+00 -8.03105e-01 -6.97413e-01  1.10650e+00 -2.58323e-01]
21Feb12_164621| [ 9.13179e-01  5.52011e-01  7.55601e-01  1.05981e+00  4.83711e-01]
21Feb12_164621| [-1.25875e+00  8.22927e-01  4.69172e-01  1.97213e-01  6.81926e-02]
21Feb12_164621| [ 1.41226e+00  1.40448e+00  2.28829e-01  1.30923e-01  3.23683e-01]
21Feb12_164621| [ 1.04333e+00 -5.42566e-01  1.66765e-01 -3.15393e-01 -2.05789e-02]
21Feb12_164621| [-4.49591e-01 -1.17282e-01 -9.31887e-02  7.86023e-03  2.01356e-01]
21Feb12_164621| [-5.06666e-01  2.51321e-01 -8.58761e-01  5.41108e-01  5.01461e-02]
21Feb12_164621| [-5.11638e-01  1.74281e+00  6.27990e-02  4.80699e-01  3.70887e-01]
21Feb12_164621| [-7.89485e-01  5.47937e-01 -7.29595e-01 -1.69570e-01  3.23468e-01]
21Feb12_164621| [ 5.81765e-01 -1.17246e-01 -3.09404e-02 -2.04408e-01  6.36081e-02]]
21Feb12_164621|-- Bias --
21Feb12_164621|[-0.54319  0.86182 -0.33228  0.44716 -0.38324]
21Feb12_164621|Layer 1:
21Feb12_164621|-- Config --
21Feb12_164621|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164621|-- Weights --
21Feb12_164621|[[-1.46361 -0.19988 -0.22811 -0.32750]
21Feb12_164621| [-0.44277  0.32306  0.33898 -0.11401]
21Feb12_164621| [-1.02744  0.96055  0.41108 -0.17247]
21Feb12_164621| [-0.45828  0.85211 -0.97745  0.52726]
21Feb12_164621| [ 0.04378 -0.23006 -0.08426  0.42305]]
21Feb12_164621|-- Bias --
21Feb12_164621|[-1.73575 -0.27258 -0.42762  0.23958]
21Feb12_164621|Layer 2:
21Feb12_164621|-- Config --
21Feb12_164621|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164621|-- Weights --
21Feb12_164621|[[ 0.52831 -1.83497]
21Feb12_164621| [ 0.77899 -0.32202]
21Feb12_164621| [ 0.58373  0.74305]
21Feb12_164621| [ 0.15087 -0.14917]]
21Feb12_164621|-- Bias --
21Feb12_164621|[0.90094 0.19971]
21Feb12_164621|Layer 3:
21Feb12_164621|-- Config --
21Feb12_164621|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164621|-- Weights --
21Feb12_164621|[[-0.58484 -0.20452  0.13986]
21Feb12_164621| [-1.32761  0.10456  0.03000]]
21Feb12_164621|-- Bias --
21Feb12_164621|[ 0.60328 -0.84742 -0.37995]
21Feb12_164621|Layer 4:
21Feb12_164621|-- Config --
21Feb12_164621|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164621|-- Weights --
21Feb12_164621|[[ 0.76417 -0.21062]
21Feb12_164621| [ 0.49932 -0.62750]
21Feb12_164621| [ 0.28442  0.31657]]
21Feb12_164621|-- Bias --
21Feb12_164621|[ 0.89049 -0.61218]
21Feb12_164621|Layer 5:
21Feb12_164621|-- Config --
21Feb12_164621|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164621|-- Weights --
21Feb12_164621|[[-0.24887  0.29658]
21Feb12_164621| [-0.75856  0.32450]]
21Feb12_164621|-- Bias --
21Feb12_164621|[-0.20865  0.78432]
21Feb12_164621|Predicting the validation and test data with the Best final individual.
21Feb12_164630| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_164630|-----------  ------------------  --------------------  ----------
21Feb12_164630|Validation         25.22                  80            0.49112
21Feb12_164630|   Test            22.42                  80            0.62937
21Feb12_164630|-------------------- Test #13 --------------------
21Feb12_164630|Best final individual weights
21Feb12_164630|Individual:
21Feb12_164630|-- Constant hidden layers --
21Feb12_164630|False
21Feb12_164630|Layer 0:
21Feb12_164630|-- Config --
21Feb12_164630|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164630|-- Weights --
21Feb12_164630|[[-7.91355e-01  2.43120e+00 -8.07061e-01 -3.94286e-01  3.19125e-01]
21Feb12_164630| [ 6.32169e-01  1.11702e+00  4.18321e-01  1.42293e+00 -7.32555e-02]
21Feb12_164630| [-3.48284e-02  1.24559e+00  2.44475e-02  8.48326e-01 -4.64233e-01]
21Feb12_164630| [ 1.17440e+00  3.81583e-01  2.14959e+00  2.13845e-01  1.46366e-01]
21Feb12_164630| [ 4.44159e-01 -1.12940e-02  5.13247e-01 -6.29180e-01 -2.98321e-01]
21Feb12_164630| [ 1.37424e+00 -1.43437e+00 -6.44080e-01  1.41356e+00  2.98025e-01]
21Feb12_164630| [-7.67760e-01  7.93907e-01 -5.67129e-01  1.19634e+00  1.52366e-01]
21Feb12_164630| [-7.08021e-02 -1.80961e+00  1.04882e+00 -1.67209e+00 -2.72411e-01]
21Feb12_164630| [-1.39134e-01 -5.77581e-01  5.25041e-01  1.42652e+00  1.03720e-01]
21Feb12_164630| [-1.07529e+00  3.55062e-02 -2.17335e+00  2.19168e-01  8.29057e-02]
21Feb12_164630| [-4.45037e-01 -4.03228e-01 -2.01532e-01  8.77376e-01  2.81343e-01]
21Feb12_164630| [ 7.19570e-01 -6.79061e-01 -1.60597e-01  8.08258e-01 -3.25257e-01]
21Feb12_164630| [-5.31401e-01  4.04345e-01  1.93758e+00 -4.60418e-01  4.68916e-01]
21Feb12_164630| [-2.13940e-01 -4.75579e-02 -1.36023e+00 -1.19475e-01 -2.31293e-01]
21Feb12_164630| [ 7.36033e-01 -8.15896e-01 -4.37717e-01  1.67296e+00 -1.20651e-01]
21Feb12_164630| [ 7.16388e-01  1.04087e+00 -1.07113e+00  2.07376e+00  1.83025e-01]
21Feb12_164630| [-5.72677e-01 -1.52863e-01  6.40245e-01 -1.37548e-01  2.41768e-01]
21Feb12_164630| [-2.01843e+00 -5.99701e-01 -1.32540e+00  2.25850e-01 -2.56690e-01]
21Feb12_164630| [-4.10261e-01 -8.13422e-01 -4.48009e-01 -3.61940e-01  4.67163e-02]
21Feb12_164630| [ 5.31285e-01  8.03485e-01  4.18423e-01 -2.97820e-01  3.11368e-01]
21Feb12_164630| [ 3.61796e-01 -9.21000e-01 -5.44164e-01 -1.38174e+00  1.80521e-01]
21Feb12_164630| [-4.75496e-01  9.05014e-01  2.36627e+00 -4.94079e-02 -3.36261e-01]
21Feb12_164630| [ 3.71397e-01  4.02431e-01  2.55986e-01  1.78623e-01 -1.70784e-01]
21Feb12_164630| [-3.82692e-01  1.40831e+00  8.55174e-01 -9.90708e-01 -2.96574e-01]
21Feb12_164630| [ 8.55878e-01 -1.28641e+00 -1.27577e-01  1.71285e+00  3.68193e-01]
21Feb12_164630| [-1.38112e-01 -2.03789e+00  1.37740e+00 -1.13825e+00 -1.40275e-01]
21Feb12_164630| [ 1.16784e-01 -1.01605e-01  6.50576e-01 -1.24867e+00  1.59576e-01]
21Feb12_164630| [-6.69357e-02  5.95912e-01  9.10702e-01 -9.96770e-01 -4.54797e-01]
21Feb12_164630| [-3.26068e-01  5.34200e-01  6.46798e-01 -6.85025e-01 -4.96585e-01]
21Feb12_164630| [-5.34229e-01  7.35933e-01 -1.25152e+00 -2.77515e-01 -2.30796e-01]
21Feb12_164630| [ 5.63815e-01  1.25123e-01  3.62872e-01  1.44226e+00  4.48351e-01]
21Feb12_164630| [-4.83407e-01  6.11778e-03 -7.29776e-01  3.97953e-01 -2.35147e-01]
21Feb12_164630| [-4.06974e-01  4.89918e-01 -1.61581e+00 -7.37000e-01  2.22498e-01]
21Feb12_164630| [ 6.06985e-01  1.58098e-01 -1.30279e+00  1.09222e+00  9.42671e-02]
21Feb12_164630| [ 3.00917e-01 -4.38970e-01  6.67241e-01  7.60470e-01  1.72456e-01]
21Feb12_164630| [ 2.61099e-02  8.76452e-02  2.06721e+00 -9.40037e-01  9.36414e-02]
21Feb12_164630| [-5.66141e-01 -1.65301e+00 -8.72837e-02 -1.13373e+00  8.58644e-02]
21Feb12_164630| [-6.85789e-01 -2.27794e+00  2.86336e-01 -9.87500e-01  5.29605e-02]
21Feb12_164630| [ 2.76455e-01 -9.02853e-01 -8.98832e-01  2.10718e+00  2.36407e-01]
21Feb12_164630| [ 2.60908e-01 -2.86778e-01 -1.41586e+00  2.84419e-01 -2.34253e-01]
21Feb12_164630| [ 2.02249e+00 -1.56278e-02 -1.11757e+00  1.13346e+00  1.02623e-01]
21Feb12_164630| [ 1.99017e-02  4.60107e-04 -6.77307e-01 -5.15077e-01  2.53077e-01]
21Feb12_164630| [ 4.24908e-01  5.22426e-01  6.86959e-01  2.52109e+00 -4.59536e-01]
21Feb12_164630| [ 1.02097e+00  4.94626e-01 -3.87759e-01 -3.06730e-01 -4.17139e-01]
21Feb12_164630| [ 8.70831e-01 -4.45426e-02 -1.33056e+00 -5.49784e-01  2.09440e-02]
21Feb12_164630| [ 8.94189e-02 -2.08384e-01  1.21988e+00 -1.03680e+00 -4.09728e-01]
21Feb12_164630| [ 3.67773e-01 -2.38648e-01 -5.69402e-01 -6.91178e-01  3.00814e-01]
21Feb12_164630| [ 1.04658e+00 -8.03105e-01 -6.97413e-01  1.10650e+00 -2.58323e-01]
21Feb12_164630| [ 9.13179e-01  5.52011e-01  7.55601e-01  1.05981e+00  4.83711e-01]
21Feb12_164630| [-1.25875e+00  8.22927e-01  4.69172e-01  1.97213e-01  6.81926e-02]
21Feb12_164630| [ 1.41226e+00  1.40448e+00  2.28829e-01  1.30923e-01  3.23683e-01]
21Feb12_164630| [ 1.04333e+00 -5.42566e-01  1.66765e-01 -3.15393e-01 -2.05789e-02]
21Feb12_164630| [-4.49591e-01 -1.17282e-01 -9.31887e-02  7.86023e-03  2.01356e-01]
21Feb12_164630| [-5.06666e-01  2.51321e-01 -8.58761e-01  5.41108e-01  5.01461e-02]
21Feb12_164630| [-5.11638e-01  1.74281e+00  6.27990e-02  4.80699e-01  3.70887e-01]
21Feb12_164630| [-7.89485e-01  5.47937e-01 -7.29595e-01 -1.69570e-01  3.23468e-01]
21Feb12_164630| [ 5.81765e-01 -1.17246e-01 -3.09404e-02 -2.04408e-01  6.36081e-02]]
21Feb12_164630|-- Bias --
21Feb12_164630|[-0.54319  0.86182 -0.33228  0.44716 -0.38324]
21Feb12_164630|Layer 1:
21Feb12_164630|-- Config --
21Feb12_164630|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164630|-- Weights --
21Feb12_164630|[[-1.46361 -0.19988 -0.22811 -0.32750]
21Feb12_164630| [-0.44277  0.32306  0.33898 -0.11401]
21Feb12_164630| [-1.02744  0.96055  0.41108 -0.17247]
21Feb12_164630| [-0.45828  0.85211 -0.97745  0.52726]
21Feb12_164630| [ 0.04378 -0.23006 -0.08426  0.42305]]
21Feb12_164630|-- Bias --
21Feb12_164630|[-1.73575 -0.27258 -0.42762  0.23958]
21Feb12_164630|Layer 2:
21Feb12_164630|-- Config --
21Feb12_164630|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164630|-- Weights --
21Feb12_164630|[[ 0.52831 -1.83497]
21Feb12_164630| [ 0.77899 -0.32202]
21Feb12_164630| [ 0.58373  0.74305]
21Feb12_164630| [ 0.15087 -0.14917]]
21Feb12_164630|-- Bias --
21Feb12_164630|[0.90094 0.19971]
21Feb12_164630|Layer 3:
21Feb12_164630|-- Config --
21Feb12_164630|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164630|-- Weights --
21Feb12_164630|[[-0.58484 -0.20452  0.13986]
21Feb12_164630| [-1.32761  0.10456  0.03000]]
21Feb12_164630|-- Bias --
21Feb12_164630|[ 0.60328 -0.84742 -0.37995]
21Feb12_164630|Layer 4:
21Feb12_164630|-- Config --
21Feb12_164630|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164630|-- Weights --
21Feb12_164630|[[ 0.76417 -0.21062]
21Feb12_164630| [ 0.49932 -0.62750]
21Feb12_164630| [ 0.28442  0.31657]]
21Feb12_164630|-- Bias --
21Feb12_164630|[ 0.89049 -0.61218]
21Feb12_164630|Layer 5:
21Feb12_164630|-- Config --
21Feb12_164630|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164630|-- Weights --
21Feb12_164630|[[-0.24887  0.29658]
21Feb12_164630| [-0.75856  0.32450]]
21Feb12_164630|-- Bias --
21Feb12_164630|[-0.20865  0.78432]
21Feb12_164630|Predicting the validation and test data with the Best final individual.
21Feb12_164638| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_164638|-----------  ------------------  --------------------  ----------
21Feb12_164638|Validation         20.78                  80            0.68736
21Feb12_164638|   Test            24.67                  80            0.53494
21Feb12_164638|-------------------- Test #14 --------------------
21Feb12_164638|Best final individual weights
21Feb12_164638|Individual:
21Feb12_164638|-- Constant hidden layers --
21Feb12_164638|False
21Feb12_164638|Layer 0:
21Feb12_164638|-- Config --
21Feb12_164638|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164638|-- Weights --
21Feb12_164638|[[-7.91355e-01  2.43120e+00 -8.07061e-01 -3.94286e-01  3.19125e-01]
21Feb12_164638| [ 6.32169e-01  1.11702e+00  4.18321e-01  1.42293e+00 -7.32555e-02]
21Feb12_164638| [-3.48284e-02  1.24559e+00  2.44475e-02  8.48326e-01 -4.64233e-01]
21Feb12_164638| [ 1.17440e+00  3.81583e-01  2.14959e+00  2.13845e-01  1.46366e-01]
21Feb12_164638| [ 4.44159e-01 -1.12940e-02  5.13247e-01 -6.29180e-01 -2.98321e-01]
21Feb12_164638| [ 1.37424e+00 -1.43437e+00 -6.44080e-01  1.41356e+00  2.98025e-01]
21Feb12_164638| [-7.67760e-01  7.93907e-01 -5.67129e-01  1.19634e+00  1.52366e-01]
21Feb12_164638| [-7.08021e-02 -1.80961e+00  1.04882e+00 -1.67209e+00 -2.72411e-01]
21Feb12_164638| [-1.39134e-01 -5.77581e-01  5.25041e-01  1.42652e+00  1.03720e-01]
21Feb12_164638| [-1.07529e+00  3.55062e-02 -2.17335e+00  2.19168e-01  8.29057e-02]
21Feb12_164638| [-4.45037e-01 -4.03228e-01 -2.01532e-01  8.77376e-01  2.81343e-01]
21Feb12_164638| [ 7.19570e-01 -6.79061e-01 -1.60597e-01  8.08258e-01 -3.25257e-01]
21Feb12_164638| [-5.31401e-01  4.04345e-01  1.93758e+00 -4.60418e-01  4.68916e-01]
21Feb12_164638| [-2.13940e-01 -4.75579e-02 -1.36023e+00 -1.19475e-01 -2.31293e-01]
21Feb12_164638| [ 7.36033e-01 -8.15896e-01 -4.37717e-01  1.67296e+00 -1.20651e-01]
21Feb12_164638| [ 7.16388e-01  1.04087e+00 -1.07113e+00  2.07376e+00  1.83025e-01]
21Feb12_164638| [-5.72677e-01 -1.52863e-01  6.40245e-01 -1.37548e-01  2.41768e-01]
21Feb12_164638| [-2.01843e+00 -5.99701e-01 -1.32540e+00  2.25850e-01 -2.56690e-01]
21Feb12_164638| [-4.10261e-01 -8.13422e-01 -4.48009e-01 -3.61940e-01  4.67163e-02]
21Feb12_164638| [ 5.31285e-01  8.03485e-01  4.18423e-01 -2.97820e-01  3.11368e-01]
21Feb12_164638| [ 3.61796e-01 -9.21000e-01 -5.44164e-01 -1.38174e+00  1.80521e-01]
21Feb12_164638| [-4.75496e-01  9.05014e-01  2.36627e+00 -4.94079e-02 -3.36261e-01]
21Feb12_164638| [ 3.71397e-01  4.02431e-01  2.55986e-01  1.78623e-01 -1.70784e-01]
21Feb12_164638| [-3.82692e-01  1.40831e+00  8.55174e-01 -9.90708e-01 -2.96574e-01]
21Feb12_164638| [ 8.55878e-01 -1.28641e+00 -1.27577e-01  1.71285e+00  3.68193e-01]
21Feb12_164638| [-1.38112e-01 -2.03789e+00  1.37740e+00 -1.13825e+00 -1.40275e-01]
21Feb12_164638| [ 1.16784e-01 -1.01605e-01  6.50576e-01 -1.24867e+00  1.59576e-01]
21Feb12_164638| [-6.69357e-02  5.95912e-01  9.10702e-01 -9.96770e-01 -4.54797e-01]
21Feb12_164638| [-3.26068e-01  5.34200e-01  6.46798e-01 -6.85025e-01 -4.96585e-01]
21Feb12_164638| [-5.34229e-01  7.35933e-01 -1.25152e+00 -2.77515e-01 -2.30796e-01]
21Feb12_164638| [ 5.63815e-01  1.25123e-01  3.62872e-01  1.44226e+00  4.48351e-01]
21Feb12_164638| [-4.83407e-01  6.11778e-03 -7.29776e-01  3.97953e-01 -2.35147e-01]
21Feb12_164638| [-4.06974e-01  4.89918e-01 -1.61581e+00 -7.37000e-01  2.22498e-01]
21Feb12_164638| [ 6.06985e-01  1.58098e-01 -1.30279e+00  1.09222e+00  9.42671e-02]
21Feb12_164638| [ 3.00917e-01 -4.38970e-01  6.67241e-01  7.60470e-01  1.72456e-01]
21Feb12_164638| [ 2.61099e-02  8.76452e-02  2.06721e+00 -9.40037e-01  9.36414e-02]
21Feb12_164638| [-5.66141e-01 -1.65301e+00 -8.72837e-02 -1.13373e+00  8.58644e-02]
21Feb12_164638| [-6.85789e-01 -2.27794e+00  2.86336e-01 -9.87500e-01  5.29605e-02]
21Feb12_164638| [ 2.76455e-01 -9.02853e-01 -8.98832e-01  2.10718e+00  2.36407e-01]
21Feb12_164638| [ 2.60908e-01 -2.86778e-01 -1.41586e+00  2.84419e-01 -2.34253e-01]
21Feb12_164638| [ 2.02249e+00 -1.56278e-02 -1.11757e+00  1.13346e+00  1.02623e-01]
21Feb12_164638| [ 1.99017e-02  4.60107e-04 -6.77307e-01 -5.15077e-01  2.53077e-01]
21Feb12_164638| [ 4.24908e-01  5.22426e-01  6.86959e-01  2.52109e+00 -4.59536e-01]
21Feb12_164638| [ 1.02097e+00  4.94626e-01 -3.87759e-01 -3.06730e-01 -4.17139e-01]
21Feb12_164638| [ 8.70831e-01 -4.45426e-02 -1.33056e+00 -5.49784e-01  2.09440e-02]
21Feb12_164638| [ 8.94189e-02 -2.08384e-01  1.21988e+00 -1.03680e+00 -4.09728e-01]
21Feb12_164638| [ 3.67773e-01 -2.38648e-01 -5.69402e-01 -6.91178e-01  3.00814e-01]
21Feb12_164638| [ 1.04658e+00 -8.03105e-01 -6.97413e-01  1.10650e+00 -2.58323e-01]
21Feb12_164638| [ 9.13179e-01  5.52011e-01  7.55601e-01  1.05981e+00  4.83711e-01]
21Feb12_164638| [-1.25875e+00  8.22927e-01  4.69172e-01  1.97213e-01  6.81926e-02]
21Feb12_164638| [ 1.41226e+00  1.40448e+00  2.28829e-01  1.30923e-01  3.23683e-01]
21Feb12_164638| [ 1.04333e+00 -5.42566e-01  1.66765e-01 -3.15393e-01 -2.05789e-02]
21Feb12_164638| [-4.49591e-01 -1.17282e-01 -9.31887e-02  7.86023e-03  2.01356e-01]
21Feb12_164638| [-5.06666e-01  2.51321e-01 -8.58761e-01  5.41108e-01  5.01461e-02]
21Feb12_164638| [-5.11638e-01  1.74281e+00  6.27990e-02  4.80699e-01  3.70887e-01]
21Feb12_164638| [-7.89485e-01  5.47937e-01 -7.29595e-01 -1.69570e-01  3.23468e-01]
21Feb12_164638| [ 5.81765e-01 -1.17246e-01 -3.09404e-02 -2.04408e-01  6.36081e-02]]
21Feb12_164638|-- Bias --
21Feb12_164638|[-0.54319  0.86182 -0.33228  0.44716 -0.38324]
21Feb12_164638|Layer 1:
21Feb12_164638|-- Config --
21Feb12_164638|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164638|-- Weights --
21Feb12_164638|[[-1.46361 -0.19988 -0.22811 -0.32750]
21Feb12_164638| [-0.44277  0.32306  0.33898 -0.11401]
21Feb12_164638| [-1.02744  0.96055  0.41108 -0.17247]
21Feb12_164638| [-0.45828  0.85211 -0.97745  0.52726]
21Feb12_164638| [ 0.04378 -0.23006 -0.08426  0.42305]]
21Feb12_164638|-- Bias --
21Feb12_164638|[-1.73575 -0.27258 -0.42762  0.23958]
21Feb12_164638|Layer 2:
21Feb12_164638|-- Config --
21Feb12_164638|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164638|-- Weights --
21Feb12_164638|[[ 0.52831 -1.83497]
21Feb12_164638| [ 0.77899 -0.32202]
21Feb12_164638| [ 0.58373  0.74305]
21Feb12_164638| [ 0.15087 -0.14917]]
21Feb12_164638|-- Bias --
21Feb12_164638|[0.90094 0.19971]
21Feb12_164638|Layer 3:
21Feb12_164638|-- Config --
21Feb12_164638|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164638|-- Weights --
21Feb12_164638|[[-0.58484 -0.20452  0.13986]
21Feb12_164638| [-1.32761  0.10456  0.03000]]
21Feb12_164638|-- Bias --
21Feb12_164638|[ 0.60328 -0.84742 -0.37995]
21Feb12_164638|Layer 4:
21Feb12_164638|-- Config --
21Feb12_164638|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164638|-- Weights --
21Feb12_164638|[[ 0.76417 -0.21062]
21Feb12_164638| [ 0.49932 -0.62750]
21Feb12_164638| [ 0.28442  0.31657]]
21Feb12_164638|-- Bias --
21Feb12_164638|[ 0.89049 -0.61218]
21Feb12_164638|Layer 5:
21Feb12_164638|-- Config --
21Feb12_164638|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_164638|-- Weights --
21Feb12_164638|[[-0.24887  0.29658]
21Feb12_164638| [-0.75856  0.32450]]
21Feb12_164638|-- Bias --
21Feb12_164638|[-0.20865  0.78432]
21Feb12_164638|Predicting the validation and test data with the Best final individual.
21Feb12_164646| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_164646|-----------  ------------------  --------------------  ----------
21Feb12_164646|Validation         23.57                  80            0.58178
21Feb12_164646|   Test            23.20                  80            0.68733
2021-02-12 16:46:47.615499: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
21Feb12_164648|Data summary: Train
21Feb12_164648|data.shape = (2300, 57)
21Feb12_164648|labels.shape = (2300,)
21Feb12_164648|Class distribution:
21Feb12_164648|	0 - 1382 (0.60)
21Feb12_164648|	1 - 918 (0.40)
21Feb12_164648|Data summary: Validation
21Feb12_164648|data.shape = (1150, 57)
21Feb12_164648|labels.shape = (1150,)
21Feb12_164648|Class distribution:
21Feb12_164648|	0 - 704 (0.61)
21Feb12_164648|	1 - 446 (0.39)
21Feb12_164648|Data summary: Test
21Feb12_164648|data.shape = (1151, 57)
21Feb12_164648|labels.shape = (1151,)
21Feb12_164648|Class distribution:
21Feb12_164648|	0 - 702 (0.61)
21Feb12_164648|	1 - 449 (0.39)
21Feb12_164648|Selected configuration values
21Feb12_164648|-- Dataset name: spambase1
21Feb12_164648|-- Initial population size: 64
21Feb12_164648|-- Maximun number of generations: 32
21Feb12_164648|-- Neurons per hidden layer range: (2, 20)
21Feb12_164648|-- Hidden layers number range: (1, 3)
21Feb12_164648|-- Crossover probability: 0.5
21Feb12_164648|-- Bias gene mutation probability: 0.2
21Feb12_164648|-- Weights gene mutation probability: 0.75
21Feb12_164648|-- Neuron mutation probability: 0.3
21Feb12_164648|-- Layer mutation probability: 0.3
21Feb12_164648|-- Constant hidden layers: False
21Feb12_164648|-- Seed: 31415
21Feb12_164648|Entering GA
21Feb12_164648|Start the algorithm
2021-02-12 16:46:48.509831: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-12 16:46:48.510377: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-02-12 16:46:48.530724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-12 16:46:48.531040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.71GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s
2021-02-12 16:46:48.531054: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-02-12 16:46:48.532515: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-02-12 16:46:48.532547: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-02-12 16:46:48.533040: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-02-12 16:46:48.533182: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-02-12 16:46:48.533253: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-12 16:46:48.533649: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-02-12 16:46:48.533691: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-12 16:46:48.533697: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-02-12 16:46:48.533911: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-02-12 16:46:48.534725: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-12 16:46:48.534741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-12 16:46:48.534745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      
2021-02-12 16:46:48.587933: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-02-12 16:46:48.588269: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3493635000 Hz
/home/jmerelo/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype("int32")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn('`model.predict_classes()` is deprecated and '
21Feb12_165051|-- Generation 1 --
21Feb12_165052|    -- Crossed 1 individual pairs.
21Feb12_165052|    -- Mutated 32 individuals.
21Feb12_165453|    -- Evaluated 64 individuals.
21Feb12_165453|    Summary of generation 1:
21Feb12_165453| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_165453|-----------  ------------------  --------------------  ----------
21Feb12_165453|    Max            39.65                208.00          0.22086
21Feb12_165453|    Avg            38.81                49.92           0.00354
21Feb12_165453|    Min            32.61                 3.00           0.00000
21Feb12_165453|    Std             0.80                46.30           0.02738
21Feb12_165453|   Best            32.61                26.00           0.22086
21Feb12_165453|-- Generation 2 --
21Feb12_165453|    -- Crossed 4 individual pairs.
21Feb12_165453|    -- Mutated 32 individuals.
21Feb12_165855|    -- Evaluated 64 individuals.
21Feb12_165855|    Summary of generation 2:
21Feb12_165855| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_165855|-----------  ------------------  --------------------  ----------
21Feb12_165855|    Max            39.13                124.00          0.02508
21Feb12_165855|    Avg            38.81                44.22           0.00061
21Feb12_165855|    Min            38.09                 2.00           0.00000
21Feb12_165855|    Std             0.14                37.86           0.00354
21Feb12_165855|   Best            38.09                10.00           0.02508
21Feb12_165855|-- Generation 3 --
21Feb12_165855|    -- Crossed 4 individual pairs.
21Feb12_165855|    -- Mutated 32 individuals.
21Feb12_170252|    -- Evaluated 64 individuals.
21Feb12_170252|    Summary of generation 3:
21Feb12_170252| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_170252|-----------  ------------------  --------------------  ----------
21Feb12_170252|    Max            39.13                78.00           0.71523
21Feb12_170252|    Avg            37.96                19.92           0.03477
21Feb12_170252|    Min            24.00                 3.00           0.00000
21Feb12_170252|    Std             3.22                17.22           0.13443
21Feb12_170252|   Best            24.00                10.00           0.57674
21Feb12_170252|-- Generation 4 --
21Feb12_170252|    -- Crossed 3 individual pairs.
21Feb12_170252|    -- Mutated 32 individuals.
21Feb12_170645|    -- Evaluated 64 individuals.
21Feb12_170645|    Summary of generation 4:
21Feb12_170645| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_170645|-----------  ------------------  --------------------  ----------
21Feb12_170645|    Max            39.48                26.00           0.74790
21Feb12_170645|    Avg            38.66                10.20           0.01216
21Feb12_170645|    Min            28.70                 2.00           0.00000
21Feb12_170645|    Std             1.27                 6.24           0.09277
21Feb12_170645|   Best            28.70                16.00           0.74790
21Feb12_170645|-- Generation 5 --
21Feb12_170645|    -- Crossed 3 individual pairs.
21Feb12_170645|    -- Mutated 32 individuals.
21Feb12_171036|    -- Evaluated 64 individuals.
21Feb12_171036|    Summary of generation 5:
21Feb12_171036| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_171036|-----------  ------------------  --------------------  ----------
21Feb12_171036|    Max            39.39                30.00           0.61782
21Feb12_171036|    Avg            38.20                 7.61           0.02689
21Feb12_171036|    Min            25.57                 2.00           0.00000
21Feb12_171036|    Std             2.65                 4.88           0.11509
21Feb12_171036|   Best            25.57                10.00           0.56084
21Feb12_171036|-- Generation 6 --
21Feb12_171036|    -- Crossed 7 individual pairs.
21Feb12_171036|    -- Mutated 32 individuals.
21Feb12_171426|    -- Evaluated 64 individuals.
21Feb12_171426|    Summary of generation 6:
21Feb12_171426| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_171426|-----------  ------------------  --------------------  ----------
21Feb12_171426|    Max            39.30                22.00           0.82398
21Feb12_171426|    Avg            37.54                 6.78           0.05866
21Feb12_171426|    Min            25.13                 2.00           0.00000
21Feb12_171426|    Std             3.68                 4.71           0.17010
21Feb12_171426|   Best            25.13                 8.00           0.52644
21Feb12_171426|-- Generation 7 --
21Feb12_171426|    -- Crossed 6 individual pairs.
21Feb12_171426|    -- Mutated 32 individuals.
21Feb12_171816|    -- Evaluated 64 individuals.
21Feb12_171816|    Summary of generation 7:
21Feb12_171816| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_171816|-----------  ------------------  --------------------  ----------
21Feb12_171816|    Max            39.04                24.00           0.56084
21Feb12_171816|    Avg            38.57                 7.42           0.00985
21Feb12_171816|    Min            25.57                 2.00           0.00000
21Feb12_171816|    Std             1.65                 5.88           0.06968
21Feb12_171816|   Best            25.57                10.00           0.56084
21Feb12_171816|-- Generation 8 --
21Feb12_171816|    -- Crossed 8 individual pairs.
21Feb12_171816|    -- Mutated 32 individuals.
21Feb12_172205|    -- Evaluated 64 individuals.
21Feb12_172205|    Summary of generation 8:
21Feb12_172205| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_172205|-----------  ------------------  --------------------  ----------
21Feb12_172205|    Max            39.30                18.00           0.55345
21Feb12_172205|    Avg            38.59                 5.64           0.01008
21Feb12_172205|    Min            26.78                 2.00           0.00000
21Feb12_172205|    Std             1.50                 4.29           0.06883
21Feb12_172205|   Best            26.78                12.00           0.55345
21Feb12_172205|-- Generation 9 --
21Feb12_172205|    -- Crossed 8 individual pairs.
21Feb12_172205|    -- Mutated 32 individuals.
21Feb12_172554|    -- Evaluated 64 individuals.
21Feb12_172554|    Summary of generation 9:
21Feb12_172554| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_172554|-----------  ------------------  --------------------  ----------
21Feb12_172554|    Max            39.39                18.00           0.52759
21Feb12_172554|    Avg            38.57                 4.97           0.01101
21Feb12_172554|    Min            25.39                 2.00           0.00000
21Feb12_172554|    Std             1.68                 3.77           0.06588
21Feb12_172554|   Best            25.39                14.00           0.52759
21Feb12_172554|-- Generation 10 --
21Feb12_172554|    -- Crossed 9 individual pairs.
21Feb12_172554|    -- Mutated 32 individuals.
21Feb12_172945|    -- Evaluated 64 individuals.
21Feb12_172945|    Summary of generation 10:
21Feb12_172945| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_172945|-----------  ------------------  --------------------  ----------
21Feb12_172945|    Max            49.57                20.00           0.78541
21Feb12_172945|    Avg            38.81                 5.56           0.01870
21Feb12_172945|    Min            27.91                 2.00           0.00000
21Feb12_172945|    Std             1.92                 4.76           0.10753
21Feb12_172945|   Best            27.91                14.00           0.38068
21Feb12_172945|-- Generation 11 --
21Feb12_172945|    -- Crossed 7 individual pairs.
21Feb12_172945|    -- Mutated 32 individuals.
21Feb12_173334|    -- Evaluated 64 individuals.
21Feb12_173334|    Summary of generation 11:
21Feb12_173334| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_173334|-----------  ------------------  --------------------  ----------
21Feb12_173334|    Max            39.39                16.00           0.67909
21Feb12_173334|    Avg            38.48                 4.94           0.01566
21Feb12_173334|    Min            26.35                 2.00           0.00000
21Feb12_173334|    Std             1.95                 4.14           0.09255
21Feb12_173334|   Best            26.35                10.00           0.67909
21Feb12_173334|-- Generation 12 --
21Feb12_173334|    -- Crossed 7 individual pairs.
21Feb12_173334|    -- Mutated 32 individuals.
21Feb12_173724|    -- Evaluated 64 individuals.
21Feb12_173724|    Summary of generation 12:
21Feb12_173724| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_173724|-----------  ------------------  --------------------  ----------
21Feb12_173724|    Max            38.96                36.00           0.77646
21Feb12_173724|    Avg            38.24                 4.47           0.02994
21Feb12_173724|    Min            25.13                 2.00           0.00000
21Feb12_173724|    Std             2.55                 5.28           0.13724
21Feb12_173724|   Best            25.13                14.00           0.49729
21Feb12_173724|-- Generation 13 --
21Feb12_173724|    -- Crossed 5 individual pairs.
21Feb12_173724|    -- Mutated 32 individuals.
21Feb12_174114|    -- Evaluated 64 individuals.
21Feb12_174114|    Summary of generation 13:
21Feb12_174114| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_174114|-----------  ------------------  --------------------  ----------
21Feb12_174114|    Max            55.57                36.00           0.77727
21Feb12_174114|    Avg            38.69                 5.50           0.03134
21Feb12_174114|    Min            25.57                 2.00           0.00000
21Feb12_174114|    Std             3.05                 7.62           0.14423
21Feb12_174114|   Best            25.57                14.00           0.48020
21Feb12_174114|-- Generation 14 --
21Feb12_174114|    -- Crossed 5 individual pairs.
21Feb12_174114|    -- Mutated 32 individuals.
21Feb12_174504|    -- Evaluated 64 individuals.
21Feb12_174504|    Summary of generation 14:
21Feb12_174504| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_174504|-----------  ------------------  --------------------  ----------
21Feb12_174504|    Max            38.96                56.00           0.74344
21Feb12_174504|    Avg            38.04                 5.25           0.04018
21Feb12_174504|    Min            25.22                 2.00           0.00000
21Feb12_174504|    Std             2.99                 8.55           0.15802
21Feb12_174504|   Best            25.22                14.00           0.47714
21Feb12_174504|-- Generation 15 --
21Feb12_174504|    -- Crossed 7 individual pairs.
21Feb12_174504|    -- Mutated 32 individuals.
21Feb12_174854|    -- Evaluated 64 individuals.
21Feb12_174854|    Summary of generation 15:
21Feb12_174854| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_174854|-----------  ------------------  --------------------  ----------
21Feb12_174854|    Max            39.13                36.00           0.81804
21Feb12_174854|    Avg            38.11                 5.12           0.04298
21Feb12_174854|    Min            24.35                 2.00           0.00000
21Feb12_174854|    Std             2.85                 6.74           0.16887
21Feb12_174854|   Best            24.35                36.00           0.66303
21Feb12_174854|-- Generation 16 --
21Feb12_174854|    -- Crossed 5 individual pairs.
21Feb12_174854|    -- Mutated 32 individuals.
21Feb12_175243|    -- Evaluated 64 individuals.
21Feb12_175243|    Summary of generation 16:
21Feb12_175243| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_175243|-----------  ------------------  --------------------  ----------
21Feb12_175243|    Max            38.96                36.00           0.74491
21Feb12_175243|    Avg            38.13                 5.64           0.03659
21Feb12_175243|    Min            24.09                 2.00           0.00000
21Feb12_175243|    Std             2.60                 7.08           0.14445
21Feb12_175243|   Best            24.09                16.00           0.55983
21Feb12_175243|-- Generation 17 --
21Feb12_175243|    -- Crossed 5 individual pairs.
21Feb12_175243|    -- Mutated 32 individuals.
21Feb12_175634|    -- Evaluated 64 individuals.
21Feb12_175634|    Summary of generation 17:
21Feb12_175634| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_175634|-----------  ------------------  --------------------  ----------
21Feb12_175634|    Max            40.26                36.00           0.81772
21Feb12_175634|    Avg            38.75                 6.42           0.01346
21Feb12_175634|    Min            33.57                 2.00           0.00000
21Feb12_175634|    Std             0.68                 8.57           0.10147
21Feb12_175634|   Best            33.57                14.00           0.81772
21Feb12_175634|-- Generation 18 --
21Feb12_175634|    -- Crossed 5 individual pairs.
21Feb12_175634|    -- Mutated 32 individuals.
21Feb12_180022|    -- Evaluated 64 individuals.
21Feb12_180022|    Summary of generation 18:
21Feb12_180022| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_180022|-----------  ------------------  --------------------  ----------
21Feb12_180022|    Max            39.22                14.00           0.00000
21Feb12_180022|    Avg            38.80                 3.64           0.00000
21Feb12_180022|    Min            38.78                 2.00           0.00000
21Feb12_180022|    Std             0.06                 3.66           0.00000
21Feb12_180022|   Best            38.78                 2.00           0.00000
21Feb12_180022|-- Generation 19 --
21Feb12_180022|    -- Crossed 8 individual pairs.
21Feb12_180022|    -- Mutated 32 individuals.
21Feb12_180411|    -- Evaluated 64 individuals.
21Feb12_180411|    Summary of generation 19:
21Feb12_180411| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_180411|-----------  ------------------  --------------------  ----------
21Feb12_180411|    Max            39.22                16.00           0.52747
21Feb12_180411|    Avg            38.57                 3.56           0.00824
21Feb12_180411|    Min            24.78                 2.00           0.00000
21Feb12_180411|    Std             1.74                 3.81           0.06542
21Feb12_180411|   Best            24.78                10.00           0.52747
21Feb12_180411|-- Generation 20 --
21Feb12_180411|    -- Crossed 8 individual pairs.
21Feb12_180411|    -- Mutated 32 individuals.
21Feb12_180759|    -- Evaluated 64 individuals.
21Feb12_180759|    Summary of generation 20:
21Feb12_180759| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_180759|-----------  ------------------  --------------------  ----------
21Feb12_180759|    Max            39.30                14.00           0.00000
21Feb12_180759|    Avg            38.82                 3.25           0.00000
21Feb12_180759|    Min            38.78                 2.00           0.00000
21Feb12_180759|    Std             0.11                 2.94           0.00000
21Feb12_180759|   Best            38.78                 2.00           0.00000
21Feb12_180759|-- Generation 21 --
21Feb12_180759|    -- Crossed 7 individual pairs.
21Feb12_180759|    -- Mutated 32 individuals.
21Feb12_181148|    -- Evaluated 64 individuals.
21Feb12_181148|    Summary of generation 21:
21Feb12_181148| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_181148|-----------  ------------------  --------------------  ----------
21Feb12_181148|    Max            39.13                16.00           0.00000
21Feb12_181148|    Avg            38.79                 3.91           0.00000
21Feb12_181148|    Min            38.78                 2.00           0.00000
21Feb12_181148|    Std             0.05                 3.90           0.00000
21Feb12_181148|   Best            38.78                 2.00           0.00000
21Feb12_181148|-- Generation 22 --
21Feb12_181148|    -- Crossed 10 individual pairs.
21Feb12_181148|    -- Mutated 32 individuals.
21Feb12_181538|    -- Evaluated 64 individuals.
21Feb12_181538|    Summary of generation 22:
21Feb12_181538| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_181538|-----------  ------------------  --------------------  ----------
21Feb12_181538|    Max            38.96                14.00           0.00000
21Feb12_181538|    Avg            38.80                 3.55           0.00000
21Feb12_181538|    Min            38.78                 2.00           0.00000
21Feb12_181538|    Std             0.04                 3.50           0.00000
21Feb12_181538|   Best            38.78                 2.00           0.00000
21Feb12_181538|-- Generation 23 --
21Feb12_181538|    -- Crossed 8 individual pairs.
21Feb12_181538|    -- Mutated 32 individuals.
21Feb12_181928|    -- Evaluated 64 individuals.
21Feb12_181928|    Summary of generation 23:
21Feb12_181928| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_181928|-----------  ------------------  --------------------  ----------
21Feb12_181928|    Max            39.04                16.00           0.31555
21Feb12_181928|    Avg            38.68                 4.00           0.00493
21Feb12_181928|    Min            31.74                 2.00           0.00000
21Feb12_181928|    Std             0.88                 4.23           0.03913
21Feb12_181928|   Best            31.74                16.00           0.31555
21Feb12_181928|-- Generation 24 --
21Feb12_181928|    -- Crossed 5 individual pairs.
21Feb12_181928|    -- Mutated 32 individuals.
21Feb12_182316|    -- Evaluated 64 individuals.
21Feb12_182316|    Summary of generation 24:
21Feb12_182316| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_182316|-----------  ------------------  --------------------  ----------
21Feb12_182316|    Max            40.26                16.00           0.00000
21Feb12_182316|    Avg            38.82                 4.00           0.00000
21Feb12_182316|    Min            38.78                 2.00           0.00000
21Feb12_182316|    Std             0.19                 4.14           0.00000
21Feb12_182316|   Best            38.78                 2.00           0.00000
21Feb12_182316|-- Generation 25 --
21Feb12_182316|    -- Crossed 6 individual pairs.
21Feb12_182316|    -- Mutated 32 individuals.
21Feb12_182705|    -- Evaluated 64 individuals.
21Feb12_182705|    Summary of generation 25:
21Feb12_182705| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_182705|-----------  ------------------  --------------------  ----------
21Feb12_182705|    Max            56.87                16.00           0.77323
21Feb12_182705|    Avg            38.91                 3.67           0.01917
21Feb12_182705|    Min            27.30                 2.00           0.00000
21Feb12_182705|    Std             2.68                 3.69           0.11039
21Feb12_182705|   Best            27.30                12.00           0.45342
21Feb12_182705|-- Generation 26 --
21Feb12_182705|    -- Crossed 2 individual pairs.
21Feb12_182705|    -- Mutated 32 individuals.
21Feb12_183054|    -- Evaluated 64 individuals.
21Feb12_183054|    Summary of generation 26:
21Feb12_183054| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_183054|-----------  ------------------  --------------------  ----------
21Feb12_183054|    Max            53.83                30.00           0.77668
21Feb12_183054|    Avg            38.83                 4.75           0.01997
21Feb12_183054|    Min            25.04                 2.00           0.00000
21Feb12_183054|    Std             2.55                 5.26           0.11382
21Feb12_183054|   Best            25.04                10.00           0.50147
21Feb12_183054|-- Generation 27 --
21Feb12_183054|    -- Crossed 8 individual pairs.
21Feb12_183054|    -- Mutated 32 individuals.
21Feb12_183443|    -- Evaluated 64 individuals.
21Feb12_183443|    Summary of generation 27:
21Feb12_183443| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_183443|-----------  ------------------  --------------------  ----------
21Feb12_183443|    Max            39.13                16.00           0.47690
21Feb12_183443|    Avg            38.57                 4.09           0.00789
21Feb12_183443|    Min            25.30                 2.00           0.00000
21Feb12_183443|    Std             1.67                 4.08           0.05919
21Feb12_183443|   Best            25.30                10.00           0.47690
21Feb12_183443|-- Generation 28 --
21Feb12_183443|    -- Crossed 8 individual pairs.
21Feb12_183443|    -- Mutated 32 individuals.
21Feb12_183833|    -- Evaluated 64 individuals.
21Feb12_183833|    Summary of generation 28:
21Feb12_183833| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_183833|-----------  ------------------  --------------------  ----------
21Feb12_183833|    Max            38.87                16.00           0.81943
21Feb12_183833|    Avg            38.32                 4.02           0.02180
21Feb12_183833|    Min            23.83                 2.00           0.00000
21Feb12_183833|    Std             2.46                 4.11           0.12059
21Feb12_183833|   Best            23.83                 8.00           0.81943
21Feb12_183833|-- Generation 29 --
21Feb12_183833|    -- Crossed 10 individual pairs.
21Feb12_183833|    -- Mutated 32 individuals.
21Feb12_184222|    -- Evaluated 64 individuals.
21Feb12_184222|    Summary of generation 29:
21Feb12_184222| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_184222|-----------  ------------------  --------------------  ----------
21Feb12_184222|    Max            39.04                16.00           0.40102
21Feb12_184222|    Avg            38.59                 3.80           0.00790
21Feb12_184222|    Min            27.48                 2.00           0.00000
21Feb12_184222|    Std             1.41                 3.75           0.05036
21Feb12_184222|   Best            27.48                12.00           0.40102
21Feb12_184222|-- Generation 30 --
21Feb12_184222|    -- Crossed 10 individual pairs.
21Feb12_184222|    -- Mutated 32 individuals.
21Feb12_184612|    -- Evaluated 64 individuals.
21Feb12_184612|    Summary of generation 30:
21Feb12_184612| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_184612|-----------  ------------------  --------------------  ----------
21Feb12_184612|    Max            39.74                36.00           0.00000
21Feb12_184612|    Avg            38.81                 4.55           0.00000
21Feb12_184612|    Min            38.78                 2.00           0.00000
21Feb12_184612|    Std             0.13                 5.67           0.00000
21Feb12_184612|   Best            38.78                 2.00           0.00000
21Feb12_184612|The fitness has not improved in 10 generations:
21Feb12_184612|	Previous best fit: (38.78260869565218, 2.0, 0.0)
21Feb12_184612|	Current best fit: (38.78260869565218, 2.0, 0.0)
21Feb12_184612|Exiting...
21Feb12_184612|Best initial individual weights
21Feb12_184612|Individual:
21Feb12_184612|-- Constant hidden layers --
21Feb12_184612|False
21Feb12_184612|Layer 0:
21Feb12_184612|-- Config --
21Feb12_184612|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 12, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_184612|-- Weights --
21Feb12_184612|[[-0.19605  0.07843 -0.31094 -0.44735  0.88644 -0.41005 -0.92737 -0.51939
21Feb12_184612|   0.90379 -0.86722 -0.58442  0.02119]
21Feb12_184612| [ 0.54780 -0.13999  0.86992  0.67643  0.63457 -0.26414 -0.76365  0.83511
21Feb12_184612|  -0.82664  0.19916 -0.42085  0.14112]
21Feb12_184612| [ 0.92815 -0.99412 -0.30782  0.33834  0.85210 -0.59432 -0.14883 -0.83946
21Feb12_184612|   0.13172 -0.59112 -0.69063  0.18870]
21Feb12_184612| [-0.29746  0.71772 -0.72497 -0.03391 -0.60978  0.53162 -0.51971 -0.07740
21Feb12_184612|   0.00958 -0.35158  0.49349 -0.32340]
21Feb12_184612| [ 0.73546 -0.41176 -0.89296 -0.36846  0.69857 -0.98545 -0.61422 -0.97115
21Feb12_184612|  -0.19382  0.30549 -0.61369 -0.53775]
21Feb12_184612| [-0.51907  0.84979 -0.74659  0.37694  0.20955 -0.42773  0.25342 -0.24185
21Feb12_184612|  -0.58571 -0.54052  0.01641 -0.62195]
21Feb12_184612| [-0.36637 -0.59648  0.90641 -0.32917  0.70252 -0.97759  0.77156 -0.54336
21Feb12_184612|  -0.63097  0.58684  0.56565 -0.38443]
21Feb12_184612| [ 0.47220  0.19322 -0.64569 -0.14107 -0.23431 -0.86701  0.92105  0.34531
21Feb12_184612|   0.09836 -0.70972 -0.53027  0.34415]
21Feb12_184612| [-0.49035 -0.87304 -0.34528 -0.41579 -0.02059  0.39221  0.63551 -0.02803
21Feb12_184612|   0.44723 -0.62434 -0.21190 -0.96922]
21Feb12_184612| [ 0.47460 -0.96286 -0.81731 -0.84472 -0.58155 -0.99043 -0.50158  0.76152
21Feb12_184612|  -0.66560  0.79135  0.71026 -0.67793]
21Feb12_184612| [-0.42166  0.23994 -0.27482  0.14800  0.78420  0.88895  0.05267  0.92468
21Feb12_184612|  -0.37922  0.40907 -0.89761  0.70309]
21Feb12_184612| [ 0.23497  0.83372  0.42807  0.56853  0.54153  0.17151 -0.62377  0.18507
21Feb12_184612|  -0.10411  0.43054  0.67748  0.67758]
21Feb12_184612| [-0.28291  0.67700 -0.98110 -0.29177  0.72729  0.68055 -0.72082  0.09379
21Feb12_184612|   0.96378  0.01188  0.59201  0.76149]
21Feb12_184612| [-0.96321  0.66574  0.54272  0.71254 -0.23570 -0.36536  0.12429  0.62568
21Feb12_184612|  -0.86305  0.27439 -0.72802 -0.24864]
21Feb12_184612| [ 0.25755  0.85144  0.89615  0.36624  0.74994 -0.25647  0.71113 -0.03721
21Feb12_184612|   0.82653  0.37424  0.83053 -0.82677]
21Feb12_184612| [-0.97377  0.78579  0.75967 -0.55092  0.00956  0.04794 -0.65977 -0.97425
21Feb12_184612|   0.96404  0.93558 -0.52538 -0.09205]
21Feb12_184612| [-0.49035  0.28430 -0.55656  0.72426 -0.25637  0.49226 -0.63246  0.93147
21Feb12_184612|  -0.70175  0.24880 -0.85245  0.52518]
21Feb12_184612| [ 0.14856  0.83873  0.91845 -0.63496  0.64931 -0.50770  0.64919 -0.25568
21Feb12_184612|   0.35826 -0.96666  0.00619 -0.18926]
21Feb12_184612| [-0.82902 -0.36322 -0.53492 -0.38547  0.05838  0.84041  0.33463  0.61662
21Feb12_184612|   0.94323  0.95252 -0.95489  0.85206]
21Feb12_184612| [-0.23396  0.06864 -0.59064  0.89709 -0.72366 -0.90802  0.45986  0.53240
21Feb12_184612|  -0.28547 -0.19042  0.64039  0.22830]
21Feb12_184612| [-0.23733  0.69326 -0.74659 -0.32152  0.78239 -0.47993  0.13189 -0.07797
21Feb12_184612|   0.37458  0.71434 -0.06358 -0.49027]
21Feb12_184612| [-0.21645 -0.79396  0.64866  0.23994 -0.60308 -0.64577  0.00575  0.21900
21Feb12_184612|   0.27866 -0.71745  0.57862  0.71158]
21Feb12_184612| [-0.69314 -0.97062  0.69243 -0.56022 -0.09135  0.42521 -0.21484  0.52052
21Feb12_184612|  -0.98040  0.58351  0.94285  0.23907]
21Feb12_184612| [ 0.71315 -0.76245  0.73926 -0.36028  0.14879 -0.28182  0.70512  0.16512
21Feb12_184612|  -0.26497 -0.62287 -0.56888  0.27728]
21Feb12_184612| [-0.14341  0.32688 -0.69707  0.69129  0.06504  0.05570 -0.37368 -0.05829
21Feb12_184612|  -0.87000  0.30138  0.49973  0.47099]
21Feb12_184612| [ 0.28947  0.04095  0.22699 -0.93123 -0.42627 -0.26099 -0.17880 -0.61384
21Feb12_184612|  -0.95795 -0.96474  0.78375  0.48800]
21Feb12_184612| [-0.37158  0.77551  0.61333 -0.88781 -0.60543  0.97582 -0.39711  0.19084
21Feb12_184612|   0.55603  0.03797 -0.29924 -0.13715]
21Feb12_184612| [-0.43702 -0.62190  0.10465 -0.66108 -0.48485  0.78160  0.05362 -0.93961
21Feb12_184612|   0.91432  0.33658  0.49788 -0.84850]
21Feb12_184612| [-0.22827 -0.54119 -0.75249  0.35169  0.86876  0.57233  0.15445 -0.03650
21Feb12_184612|  -0.67703 -0.21074 -0.34815 -0.83224]
21Feb12_184612| [ 0.67886  0.23712 -0.37183 -0.72408  0.88807  0.44770 -0.57875  0.58158
21Feb12_184612|   0.91498 -0.06441 -0.40422 -0.24614]
21Feb12_184612| [ 0.51750  0.72238 -0.00673 -0.64053 -0.28162  0.45487  0.81996 -0.89515
21Feb12_184612|  -0.62003 -0.98783 -0.21311 -0.63064]
21Feb12_184612| [ 0.88583  0.67272  0.01083 -0.82272  0.42140 -0.00875 -0.76958 -0.74108
21Feb12_184612|  -0.39316 -0.60818  0.80695 -0.94411]
21Feb12_184612| [-0.12317  0.22841  0.43555  0.00737  0.08288  0.72114  0.04557 -0.41808
21Feb12_184612|  -0.17800  0.36074 -0.38920 -0.38308]
21Feb12_184612| [ 0.96319 -0.56238 -0.85366  0.42553  0.76722  0.86755  0.31466 -0.97535
21Feb12_184612|  -0.24420 -0.66968 -0.46896  0.01382]
21Feb12_184612| [-0.53134 -0.13708  0.85415 -0.59263 -0.98367 -0.61404 -0.29060 -0.67819
21Feb12_184612|   0.54436 -0.26752 -0.13594 -0.12892]
21Feb12_184612| [-0.56091  0.28911 -0.42022  0.82477 -0.14640 -0.84944  0.35816 -0.57915
21Feb12_184612|  -0.29321  0.02515  0.91416  0.19156]
21Feb12_184612| [ 0.64422  0.21984 -0.15120  0.67097 -0.67070  0.27165  0.42312  0.21395
21Feb12_184612|   0.55535 -0.82562 -0.69462  0.04223]
21Feb12_184612| [-0.37478  0.69891 -0.18261 -0.74082 -0.58298 -0.27973 -0.25535 -0.05790
21Feb12_184612|   0.28104  0.37456 -0.78458  0.98888]
21Feb12_184612| [ 0.79270 -0.20668  0.90887  0.71744 -0.86420 -0.01662 -0.89604 -0.47720
21Feb12_184612|  -0.35188  0.92008 -0.11690  0.90128]
21Feb12_184612| [ 0.88351 -0.61784 -0.81267  0.46418  0.07434  0.20029  0.35680  0.21159
21Feb12_184612|   0.28852  0.24978 -0.79977 -0.75581]
21Feb12_184612| [-0.45852 -0.90347  0.29606  0.97336  0.48387  0.27566 -0.88302  0.10429
21Feb12_184612|  -0.69749  0.08334 -0.12432  0.12389]
21Feb12_184612| [-0.65315 -0.68237 -0.54046 -0.55815  0.71787  0.42769 -0.67949  0.87854
21Feb12_184612|  -0.21407  0.32648  0.43295  0.81105]
21Feb12_184612| [ 0.86888 -0.01829 -0.65935 -0.12922 -0.49685 -0.29120  0.59147  0.05010
21Feb12_184612|   0.99542 -0.69550  0.89021 -0.07593]
21Feb12_184612| [-0.07381  0.01267  0.27307  0.26282  0.55441  0.37188 -0.69164 -0.81718
21Feb12_184612|  -0.58826 -0.69340  0.61993 -0.81237]
21Feb12_184612| [ 0.47530  0.76146 -0.75428  0.29860 -0.70760  0.47941  0.27492 -0.48234
21Feb12_184612|  -0.37542  0.57442  0.75267  0.59246]
21Feb12_184612| [ 0.76064 -0.57826  0.05341  0.87807  0.84498  0.06661  0.90881  0.31908
21Feb12_184612|  -0.21196  0.59415 -0.47988 -0.47217]
21Feb12_184612| [-0.28526 -0.87198 -0.92021 -0.60794  0.14081 -0.02440  0.37672 -0.87611
21Feb12_184612|   0.96127  0.82308 -0.28009  0.40356]
21Feb12_184612| [ 0.47211  0.76738 -0.10357 -0.69428 -0.59205  0.89460  0.26135  0.62380
21Feb12_184612|  -0.73577 -0.11552  0.56692 -0.29719]
21Feb12_184612| [-0.69816 -0.22653  0.52731 -0.85516 -0.04646  0.29010 -0.57031  0.81468
21Feb12_184612|  -0.78263  0.25604 -0.04043  0.48321]
21Feb12_184612| [ 0.61664 -0.79005  0.85570  0.99050 -0.76268 -0.15055 -0.47442  0.92101
21Feb12_184612|   0.33762 -0.47616  0.61102 -0.14568]
21Feb12_184612| [-0.98857  0.41528 -0.03773  0.12596 -0.63205 -0.54454  0.31730 -0.43739
21Feb12_184612|   0.25380 -0.39261 -0.22879 -0.30079]
21Feb12_184612| [ 0.52388 -0.43451 -0.90933  0.29969  0.06616  0.26314 -0.85982  0.84794
21Feb12_184612|  -0.16671  0.35711  0.17694 -0.96064]
21Feb12_184612| [ 0.95040 -0.29663 -0.96590  0.65854  0.39026  0.84997 -0.88826  0.26184
21Feb12_184612|   0.65504  0.17684  0.16152  0.29320]
21Feb12_184612| [ 0.33709  0.64327  0.01201  0.71039  0.75608 -0.49551 -0.27296 -0.06805
21Feb12_184612|   0.77896 -0.94024  0.08091  0.40313]
21Feb12_184612| [-0.92593  0.92289 -0.22076  0.49120  0.27038 -0.14117  0.80761 -0.51965
21Feb12_184612|  -0.10907 -0.80936 -0.08340 -0.79857]
21Feb12_184612| [ 0.27108  0.23921  0.56876 -0.60416 -0.97617 -0.82345 -0.10345  0.54576
21Feb12_184612|  -0.65979 -0.65457 -0.09434 -0.66730]
21Feb12_184612| [ 0.02155 -0.14211 -0.99671 -0.14367 -0.75401  0.02729 -0.58660  0.83371
21Feb12_184612|   0.79378 -0.94277 -0.40400 -0.04899]]
21Feb12_184612|-- Bias --
21Feb12_184612|[-0.06936  0.81912 -0.76323 -0.14845  0.82192 -0.47927  0.18733  0.18279
21Feb12_184612|  0.26160 -0.14867 -0.84828 -0.28023]
21Feb12_184612|Layer 1:
21Feb12_184612|-- Config --
21Feb12_184612|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 12], 'dtype': 'float32', 'units': 13, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_184612|-- Weights --
21Feb12_184612|[[-0.57173  0.45862 -0.93055  0.27222 -0.31226  0.49269  0.89742  0.87860
21Feb12_184612|   0.49316  0.36076 -0.24065  0.45448  0.30401]
21Feb12_184612| [ 0.76531  0.02320 -0.50047 -0.99102  0.48545 -0.77912  0.56844  0.96540
21Feb12_184612|  -0.89874 -0.56777  0.48467 -0.81119 -0.81628]
21Feb12_184612| [-0.64124  0.69401  0.65246 -0.87333  0.42127  0.56195 -0.64966  0.43706
21Feb12_184612|  -0.51348  0.79681  0.30271  0.44589  0.26467]
21Feb12_184612| [ 0.01534  0.05613  0.66673 -0.55747 -0.76006  0.44190 -0.94739 -0.56112
21Feb12_184612|   0.16647 -0.75245  0.47271  0.69006 -0.75609]
21Feb12_184612| [-0.64328  0.42864  0.29471  0.98091  0.98114 -0.01799 -0.96118  0.38420
21Feb12_184612|   0.88607  0.78591 -0.34685  0.27648  0.29606]
21Feb12_184612| [-0.76313 -0.84946  0.54851 -0.95567 -0.68968 -0.57704 -0.48457 -0.90418
21Feb12_184612|  -0.87021  0.31319 -0.90413 -0.84682 -0.45598]
21Feb12_184612| [ 0.72830 -0.26779 -0.48676 -0.67729  0.70218 -0.78320 -0.05996  0.48424
21Feb12_184612|   0.13209 -0.68140 -0.31684 -0.21140  0.64393]
21Feb12_184612| [-0.08896 -0.67439 -0.91435 -0.80077 -0.21941 -0.38012  0.24216  0.22865
21Feb12_184612|   0.50473  0.01475 -0.50273 -0.88155 -0.37004]
21Feb12_184612| [-0.03534  0.29444  0.73037 -0.60714 -0.35843 -0.52162  0.30658 -0.92155
21Feb12_184612|  -0.19878 -0.10421  0.26349  0.23258  0.74541]
21Feb12_184612| [-0.21702 -0.69264 -0.92070  0.55909 -0.12296  0.30133 -0.84777  0.71586
21Feb12_184612|  -0.41361 -0.55813  0.03293  0.17605 -0.13972]
21Feb12_184612| [ 0.70693 -0.83315  0.33310  0.99375 -0.04897 -0.16629  0.70070  0.97647
21Feb12_184612|   0.44050  0.47363  0.75527 -0.22757  0.78307]
21Feb12_184612| [-0.99479 -0.93452  0.11239 -0.37449 -0.77745 -0.08740 -0.27977  0.37414
21Feb12_184612|   0.03453 -0.66167  0.86707  0.44771 -0.85046]]
21Feb12_184612|-- Bias --
21Feb12_184612|[-0.22277  0.83949 -0.70049  0.03933  0.57748  0.71452 -0.29214  0.39634
21Feb12_184612|  0.54944  0.29891 -0.87087 -0.77254 -0.41071]
21Feb12_184612|Layer 2:
21Feb12_184612|-- Config --
21Feb12_184612|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 13], 'dtype': 'float32', 'units': 12, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_184612|-- Weights --
21Feb12_184612|[[-0.75345  0.82041  0.04849 -0.83599 -0.69648 -0.24535 -0.85909 -0.91052
21Feb12_184612|  -0.46901 -0.11820  0.26560  0.42036]
21Feb12_184612| [-0.18624 -0.32704  0.56431  0.55305  0.24353  0.53524  0.11738  0.78421
21Feb12_184612|   0.74729  0.23266  0.53427 -0.75229]
21Feb12_184612| [ 0.13256 -0.31279  0.71021  0.84543 -0.88442 -0.09185  0.82471 -0.90378
21Feb12_184612|  -0.43064 -0.53632  0.31068  0.87027]
21Feb12_184612| [-0.78067 -0.90836  0.45889 -0.90384 -0.69513  0.99596 -0.92463  0.77969
21Feb12_184612|  -0.91035  0.57951 -0.53052  0.96491]
21Feb12_184612| [-0.49284  0.20410 -0.02961  0.26687 -0.55357 -0.18649 -0.70445  0.48148
21Feb12_184612|  -0.68050  0.47158 -0.14382 -0.25341]
21Feb12_184612| [-0.41660 -0.28967 -0.31947  0.69810 -0.60047 -0.66932  0.51894  0.75638
21Feb12_184612|  -0.28920 -0.07668  0.74483  0.35902]
21Feb12_184612| [ 0.30943 -0.29638  0.74220 -0.85318  0.07532  0.99619 -0.96969 -0.83090
21Feb12_184612|  -0.98442  0.96339  0.50345  0.25660]
21Feb12_184612| [-0.86632  0.06937  0.95079  0.44295 -0.88993 -0.45000  0.34496  0.85712
21Feb12_184612|   0.63799 -0.39126  0.84951 -0.73572]
21Feb12_184612| [ 0.86307  0.45271  0.44937  0.82734  0.70615  0.13552 -0.75375  0.09041
21Feb12_184612|  -0.09981 -0.17969  0.47685 -0.31866]
21Feb12_184612| [-0.96734  0.58934 -0.64497  0.27275 -0.98437  0.01854 -0.74254 -0.36858
21Feb12_184612|   0.38864  0.70922 -0.77080 -0.20631]
21Feb12_184612| [ 0.75202  0.63334  0.27752 -0.36737  0.23842  0.26132 -0.66486  0.20808
21Feb12_184612|   0.68710 -0.45993 -0.07293  0.54639]
21Feb12_184612| [-0.91705 -0.64543 -0.39068  0.13141 -0.59270 -0.81381  0.45448 -0.22837
21Feb12_184612|   0.77646 -0.79930  0.84100  0.59053]
21Feb12_184612| [ 0.16885  0.46316  0.25173  0.71703 -0.33081 -0.46487  0.46158 -0.88760
21Feb12_184612|  -0.06960  0.43596  0.01917 -0.52323]]
21Feb12_184612|-- Bias --
21Feb12_184612|[ 0.19064 -0.21748 -0.13248  0.04699  0.78749 -0.15081 -0.13054 -0.40562
21Feb12_184612| -0.24176  0.41348 -0.63690 -0.70923]
21Feb12_184612|Layer 3:
21Feb12_184612|-- Config --
21Feb12_184612|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 12], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_184612|-- Weights --
21Feb12_184612|[[-0.51409  0.33569]
21Feb12_184612| [ 0.07022  0.17244]
21Feb12_184612| [-0.91282  0.47924]
21Feb12_184612| [ 0.62431 -0.00280]
21Feb12_184612| [ 0.72239  0.50121]
21Feb12_184612| [ 0.19713  0.24329]
21Feb12_184612| [-0.60572 -0.15440]
21Feb12_184612| [-0.81091 -0.25537]
21Feb12_184612| [ 0.58884  0.32903]
21Feb12_184612| [-0.80206  0.49467]
21Feb12_184612| [-0.59875  0.90423]
21Feb12_184612| [ 0.14118 -0.50429]]
21Feb12_184612|-- Bias --
21Feb12_184612|[ 0.73243 -0.93830]
21Feb12_184612|Predicting the validation and test data with the Best initial individual.
21Feb12_184619| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_184619|-----------  ------------------  --------------------  ----------
21Feb12_184619|Validation         38.78                 111            0.00000
21Feb12_184619|   Test            39.01                 111            0.00000
21Feb12_184619|-------------------- Test #0 --------------------
21Feb12_184619|Best final individual weights
21Feb12_184619|Individual:
21Feb12_184619|-- Constant hidden layers --
21Feb12_184619|False
21Feb12_184619|Layer 0:
21Feb12_184619|-- Config --
21Feb12_184619|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_184619|-- Weights --
21Feb12_184619|[[-0.22439  0.67798]
21Feb12_184619| [ 0.17502 -0.74040]
21Feb12_184619| [ 1.25096  0.23910]
21Feb12_184619| [ 0.73051 -0.95089]
21Feb12_184619| [-0.43728 -0.45019]
21Feb12_184619| [ 0.56566 -0.81758]
21Feb12_184619| [ 0.41154  1.13685]
21Feb12_184619| [ 0.25057 -0.71133]
21Feb12_184619| [ 0.42515 -1.51557]
21Feb12_184619| [-0.81825  0.70147]
21Feb12_184619| [-0.00593  0.85788]
21Feb12_184619| [-0.41476 -0.79663]
21Feb12_184619| [ 0.81896  0.59360]
21Feb12_184619| [ 0.44951  0.27890]
21Feb12_184619| [-0.45030 -0.49585]
21Feb12_184619| [-0.87356 -0.78499]
21Feb12_184619| [-1.11731 -0.38353]
21Feb12_184619| [ 0.49401 -0.70047]
21Feb12_184619| [-0.72782 -0.03427]
21Feb12_184619| [-0.39432 -0.65564]
21Feb12_184619| [-0.77313  0.22419]
21Feb12_184619| [-0.44810 -0.08650]
21Feb12_184619| [ 0.50671 -0.04631]
21Feb12_184619| [ 0.32901 -0.94198]
21Feb12_184619| [ 0.18140  0.14895]
21Feb12_184619| [-0.74432  0.51297]
21Feb12_184619| [ 0.56722 -0.55062]
21Feb12_184619| [ 1.36718 -0.42863]
21Feb12_184619| [ 0.16677  0.07095]
21Feb12_184619| [ 0.06528 -0.24294]
21Feb12_184619| [-1.03613  1.02094]
21Feb12_184619| [-0.10307  0.94086]
21Feb12_184619| [-0.12384  0.56465]
21Feb12_184619| [ 0.46234 -0.06487]
21Feb12_184619| [-0.53079  0.17866]
21Feb12_184619| [ 0.16999 -0.95302]
21Feb12_184619| [ 0.25867  0.78733]
21Feb12_184619| [ 0.56879  0.55681]
21Feb12_184619| [-0.17964 -0.29500]
21Feb12_184619| [ 0.79841 -0.15416]
21Feb12_184619| [ 0.55438 -0.65300]
21Feb12_184619| [-0.63040  0.74447]
21Feb12_184619| [-0.05612 -0.90323]
21Feb12_184619| [-0.49200 -1.13142]
21Feb12_184619| [ 0.57109  0.69426]
21Feb12_184619| [ 0.33833  1.30358]
21Feb12_184619| [-0.60117  0.21497]
21Feb12_184619| [-0.27104 -0.10814]
21Feb12_184619| [-0.15802  0.91218]
21Feb12_184619| [ 0.54241  0.80802]
21Feb12_184619| [ 0.66569  0.39524]
21Feb12_184619| [-0.13190  1.17715]
21Feb12_184619| [ 0.31978  0.15987]
21Feb12_184619| [-0.12298 -0.57237]
21Feb12_184619| [ 0.17417 -1.12011]
21Feb12_184619| [-0.12555  0.36729]
21Feb12_184619| [ 0.65815 -0.29020]]
21Feb12_184619|-- Bias --
21Feb12_184619|[-0.10678  0.15961]
21Feb12_184619|Layer 1:
21Feb12_184619|-- Config --
21Feb12_184619|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_184619|-- Weights --
21Feb12_184619|[[ 0.41471  1.23384]
21Feb12_184619| [ 0.12533 -0.06534]]
21Feb12_184619|-- Bias --
21Feb12_184619|[-0.37991  0.84672]
21Feb12_184619|Predicting the validation and test data with the Best final individual.
21Feb12_184627| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_184627|-----------  ------------------  --------------------  ----------
21Feb12_184627|Validation         38.78                  2             0.00000
21Feb12_184627|   Test            39.01                  2             0.00000
21Feb12_184627|-------------------- Test #1 --------------------
21Feb12_184627|Best final individual weights
21Feb12_184627|Individual:
21Feb12_184627|-- Constant hidden layers --
21Feb12_184627|False
21Feb12_184627|Layer 0:
21Feb12_184627|-- Config --
21Feb12_184627|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_184627|-- Weights --
21Feb12_184627|[[-0.22439  0.67798]
21Feb12_184627| [ 0.17502 -0.74040]
21Feb12_184627| [ 1.25096  0.23910]
21Feb12_184627| [ 0.73051 -0.95089]
21Feb12_184627| [-0.43728 -0.45019]
21Feb12_184627| [ 0.56566 -0.81758]
21Feb12_184627| [ 0.41154  1.13685]
21Feb12_184627| [ 0.25057 -0.71133]
21Feb12_184627| [ 0.42515 -1.51557]
21Feb12_184627| [-0.81825  0.70147]
21Feb12_184627| [-0.00593  0.85788]
21Feb12_184627| [-0.41476 -0.79663]
21Feb12_184627| [ 0.81896  0.59360]
21Feb12_184627| [ 0.44951  0.27890]
21Feb12_184627| [-0.45030 -0.49585]
21Feb12_184627| [-0.87356 -0.78499]
21Feb12_184627| [-1.11731 -0.38353]
21Feb12_184627| [ 0.49401 -0.70047]
21Feb12_184627| [-0.72782 -0.03427]
21Feb12_184627| [-0.39432 -0.65564]
21Feb12_184627| [-0.77313  0.22419]
21Feb12_184627| [-0.44810 -0.08650]
21Feb12_184627| [ 0.50671 -0.04631]
21Feb12_184627| [ 0.32901 -0.94198]
21Feb12_184627| [ 0.18140  0.14895]
21Feb12_184627| [-0.74432  0.51297]
21Feb12_184627| [ 0.56722 -0.55062]
21Feb12_184627| [ 1.36718 -0.42863]
21Feb12_184627| [ 0.16677  0.07095]
21Feb12_184627| [ 0.06528 -0.24294]
21Feb12_184627| [-1.03613  1.02094]
21Feb12_184627| [-0.10307  0.94086]
21Feb12_184627| [-0.12384  0.56465]
21Feb12_184627| [ 0.46234 -0.06487]
21Feb12_184627| [-0.53079  0.17866]
21Feb12_184627| [ 0.16999 -0.95302]
21Feb12_184627| [ 0.25867  0.78733]
21Feb12_184627| [ 0.56879  0.55681]
21Feb12_184627| [-0.17964 -0.29500]
21Feb12_184627| [ 0.79841 -0.15416]
21Feb12_184627| [ 0.55438 -0.65300]
21Feb12_184627| [-0.63040  0.74447]
21Feb12_184627| [-0.05612 -0.90323]
21Feb12_184627| [-0.49200 -1.13142]
21Feb12_184627| [ 0.57109  0.69426]
21Feb12_184627| [ 0.33833  1.30358]
21Feb12_184627| [-0.60117  0.21497]
21Feb12_184627| [-0.27104 -0.10814]
21Feb12_184627| [-0.15802  0.91218]
21Feb12_184627| [ 0.54241  0.80802]
21Feb12_184627| [ 0.66569  0.39524]
21Feb12_184627| [-0.13190  1.17715]
21Feb12_184627| [ 0.31978  0.15987]
21Feb12_184627| [-0.12298 -0.57237]
21Feb12_184627| [ 0.17417 -1.12011]
21Feb12_184627| [-0.12555  0.36729]
21Feb12_184627| [ 0.65815 -0.29020]]
21Feb12_184627|-- Bias --
21Feb12_184627|[-0.10678  0.15961]
21Feb12_184627|Layer 1:
21Feb12_184627|-- Config --
21Feb12_184627|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_184627|-- Weights --
21Feb12_184627|[[ 0.41471  1.23384]
21Feb12_184627| [ 0.12533 -0.06534]]
21Feb12_184627|-- Bias --
21Feb12_184627|[-0.37991  0.84672]
21Feb12_184627|Predicting the validation and test data with the Best final individual.
21Feb12_184634| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_184634|-----------  ------------------  --------------------  ----------
21Feb12_184634|Validation         38.78                  2             0.00000
21Feb12_184634|   Test            39.01                  2             0.00000
21Feb12_184634|-------------------- Test #2 --------------------
21Feb12_184634|Best final individual weights
21Feb12_184634|Individual:
21Feb12_184634|-- Constant hidden layers --
21Feb12_184634|False
21Feb12_184634|Layer 0:
21Feb12_184634|-- Config --
21Feb12_184634|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_184634|-- Weights --
21Feb12_184634|[[-0.22439  0.67798]
21Feb12_184634| [ 0.17502 -0.74040]
21Feb12_184634| [ 1.25096  0.23910]
21Feb12_184634| [ 0.73051 -0.95089]
21Feb12_184634| [-0.43728 -0.45019]
21Feb12_184634| [ 0.56566 -0.81758]
21Feb12_184634| [ 0.41154  1.13685]
21Feb12_184634| [ 0.25057 -0.71133]
21Feb12_184634| [ 0.42515 -1.51557]
21Feb12_184634| [-0.81825  0.70147]
21Feb12_184634| [-0.00593  0.85788]
21Feb12_184634| [-0.41476 -0.79663]
21Feb12_184634| [ 0.81896  0.59360]
21Feb12_184634| [ 0.44951  0.27890]
21Feb12_184634| [-0.45030 -0.49585]
21Feb12_184634| [-0.87356 -0.78499]
21Feb12_184634| [-1.11731 -0.38353]
21Feb12_184634| [ 0.49401 -0.70047]
21Feb12_184634| [-0.72782 -0.03427]
21Feb12_184634| [-0.39432 -0.65564]
21Feb12_184634| [-0.77313  0.22419]
21Feb12_184634| [-0.44810 -0.08650]
21Feb12_184634| [ 0.50671 -0.04631]
21Feb12_184634| [ 0.32901 -0.94198]
21Feb12_184634| [ 0.18140  0.14895]
21Feb12_184634| [-0.74432  0.51297]
21Feb12_184634| [ 0.56722 -0.55062]
21Feb12_184634| [ 1.36718 -0.42863]
21Feb12_184634| [ 0.16677  0.07095]
21Feb12_184634| [ 0.06528 -0.24294]
21Feb12_184634| [-1.03613  1.02094]
21Feb12_184634| [-0.10307  0.94086]
21Feb12_184634| [-0.12384  0.56465]
21Feb12_184634| [ 0.46234 -0.06487]
21Feb12_184634| [-0.53079  0.17866]
21Feb12_184634| [ 0.16999 -0.95302]
21Feb12_184634| [ 0.25867  0.78733]
21Feb12_184634| [ 0.56879  0.55681]
21Feb12_184634| [-0.17964 -0.29500]
21Feb12_184634| [ 0.79841 -0.15416]
21Feb12_184634| [ 0.55438 -0.65300]
21Feb12_184634| [-0.63040  0.74447]
21Feb12_184634| [-0.05612 -0.90323]
21Feb12_184634| [-0.49200 -1.13142]
21Feb12_184634| [ 0.57109  0.69426]
21Feb12_184634| [ 0.33833  1.30358]
21Feb12_184634| [-0.60117  0.21497]
21Feb12_184634| [-0.27104 -0.10814]
21Feb12_184634| [-0.15802  0.91218]
21Feb12_184634| [ 0.54241  0.80802]
21Feb12_184634| [ 0.66569  0.39524]
21Feb12_184634| [-0.13190  1.17715]
21Feb12_184634| [ 0.31978  0.15987]
21Feb12_184634| [-0.12298 -0.57237]
21Feb12_184634| [ 0.17417 -1.12011]
21Feb12_184634| [-0.12555  0.36729]
21Feb12_184634| [ 0.65815 -0.29020]]
21Feb12_184634|-- Bias --
21Feb12_184634|[-0.10678  0.15961]
21Feb12_184634|Layer 1:
21Feb12_184634|-- Config --
21Feb12_184634|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_184634|-- Weights --
21Feb12_184634|[[ 0.41471  1.23384]
21Feb12_184634| [ 0.12533 -0.06534]]
21Feb12_184634|-- Bias --
21Feb12_184634|[-0.37991  0.84672]
21Feb12_184634|Predicting the validation and test data with the Best final individual.
21Feb12_184641| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_184641|-----------  ------------------  --------------------  ----------
21Feb12_184641|Validation         38.78                  2             0.00000
21Feb12_184641|   Test            39.01                  2             0.00000
21Feb12_184641|-------------------- Test #3 --------------------
21Feb12_184641|Best final individual weights
21Feb12_184641|Individual:
21Feb12_184641|-- Constant hidden layers --
21Feb12_184641|False
21Feb12_184641|Layer 0:
21Feb12_184641|-- Config --
21Feb12_184641|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_184641|-- Weights --
21Feb12_184641|[[-0.22439  0.67798]
21Feb12_184641| [ 0.17502 -0.74040]
21Feb12_184641| [ 1.25096  0.23910]
21Feb12_184641| [ 0.73051 -0.95089]
21Feb12_184641| [-0.43728 -0.45019]
21Feb12_184641| [ 0.56566 -0.81758]
21Feb12_184641| [ 0.41154  1.13685]
21Feb12_184641| [ 0.25057 -0.71133]
21Feb12_184641| [ 0.42515 -1.51557]
21Feb12_184641| [-0.81825  0.70147]
21Feb12_184641| [-0.00593  0.85788]
21Feb12_184641| [-0.41476 -0.79663]
21Feb12_184641| [ 0.81896  0.59360]
21Feb12_184641| [ 0.44951  0.27890]
21Feb12_184641| [-0.45030 -0.49585]
21Feb12_184641| [-0.87356 -0.78499]
21Feb12_184641| [-1.11731 -0.38353]
21Feb12_184641| [ 0.49401 -0.70047]
21Feb12_184641| [-0.72782 -0.03427]
21Feb12_184641| [-0.39432 -0.65564]
21Feb12_184641| [-0.77313  0.22419]
21Feb12_184641| [-0.44810 -0.08650]
21Feb12_184641| [ 0.50671 -0.04631]
21Feb12_184641| [ 0.32901 -0.94198]
21Feb12_184641| [ 0.18140  0.14895]
21Feb12_184641| [-0.74432  0.51297]
21Feb12_184641| [ 0.56722 -0.55062]
21Feb12_184641| [ 1.36718 -0.42863]
21Feb12_184641| [ 0.16677  0.07095]
21Feb12_184641| [ 0.06528 -0.24294]
21Feb12_184641| [-1.03613  1.02094]
21Feb12_184641| [-0.10307  0.94086]
21Feb12_184641| [-0.12384  0.56465]
21Feb12_184641| [ 0.46234 -0.06487]
21Feb12_184641| [-0.53079  0.17866]
21Feb12_184641| [ 0.16999 -0.95302]
21Feb12_184641| [ 0.25867  0.78733]
21Feb12_184641| [ 0.56879  0.55681]
21Feb12_184641| [-0.17964 -0.29500]
21Feb12_184641| [ 0.79841 -0.15416]
21Feb12_184641| [ 0.55438 -0.65300]
21Feb12_184641| [-0.63040  0.74447]
21Feb12_184641| [-0.05612 -0.90323]
21Feb12_184641| [-0.49200 -1.13142]
21Feb12_184641| [ 0.57109  0.69426]
21Feb12_184641| [ 0.33833  1.30358]
21Feb12_184641| [-0.60117  0.21497]
21Feb12_184641| [-0.27104 -0.10814]
21Feb12_184641| [-0.15802  0.91218]
21Feb12_184641| [ 0.54241  0.80802]
21Feb12_184641| [ 0.66569  0.39524]
21Feb12_184641| [-0.13190  1.17715]
21Feb12_184641| [ 0.31978  0.15987]
21Feb12_184641| [-0.12298 -0.57237]
21Feb12_184641| [ 0.17417 -1.12011]
21Feb12_184641| [-0.12555  0.36729]
21Feb12_184641| [ 0.65815 -0.29020]]
21Feb12_184641|-- Bias --
21Feb12_184641|[-0.10678  0.15961]
21Feb12_184641|Layer 1:
21Feb12_184641|-- Config --
21Feb12_184641|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_184641|-- Weights --
21Feb12_184641|[[ 0.41471  1.23384]
21Feb12_184641| [ 0.12533 -0.06534]]
21Feb12_184641|-- Bias --
21Feb12_184641|[-0.37991  0.84672]
21Feb12_184641|Predicting the validation and test data with the Best final individual.
21Feb12_184648| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_184648|-----------  ------------------  --------------------  ----------
21Feb12_184648|Validation         38.87                  2             0.00000
21Feb12_184648|   Test            39.01                  2             0.00000
21Feb12_184648|-------------------- Test #4 --------------------
21Feb12_184648|Best final individual weights
21Feb12_184648|Individual:
21Feb12_184648|-- Constant hidden layers --
21Feb12_184648|False
21Feb12_184648|Layer 0:
21Feb12_184648|-- Config --
21Feb12_184648|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_184648|-- Weights --
21Feb12_184648|[[-0.22439  0.67798]
21Feb12_184648| [ 0.17502 -0.74040]
21Feb12_184648| [ 1.25096  0.23910]
21Feb12_184648| [ 0.73051 -0.95089]
21Feb12_184648| [-0.43728 -0.45019]
21Feb12_184648| [ 0.56566 -0.81758]
21Feb12_184648| [ 0.41154  1.13685]
21Feb12_184648| [ 0.25057 -0.71133]
21Feb12_184648| [ 0.42515 -1.51557]
21Feb12_184648| [-0.81825  0.70147]
21Feb12_184648| [-0.00593  0.85788]
21Feb12_184648| [-0.41476 -0.79663]
21Feb12_184648| [ 0.81896  0.59360]
21Feb12_184648| [ 0.44951  0.27890]
21Feb12_184648| [-0.45030 -0.49585]
21Feb12_184648| [-0.87356 -0.78499]
21Feb12_184648| [-1.11731 -0.38353]
21Feb12_184648| [ 0.49401 -0.70047]
21Feb12_184648| [-0.72782 -0.03427]
21Feb12_184648| [-0.39432 -0.65564]
21Feb12_184648| [-0.77313  0.22419]
21Feb12_184648| [-0.44810 -0.08650]
21Feb12_184648| [ 0.50671 -0.04631]
21Feb12_184648| [ 0.32901 -0.94198]
21Feb12_184648| [ 0.18140  0.14895]
21Feb12_184648| [-0.74432  0.51297]
21Feb12_184648| [ 0.56722 -0.55062]
21Feb12_184648| [ 1.36718 -0.42863]
21Feb12_184648| [ 0.16677  0.07095]
21Feb12_184648| [ 0.06528 -0.24294]
21Feb12_184648| [-1.03613  1.02094]
21Feb12_184648| [-0.10307  0.94086]
21Feb12_184648| [-0.12384  0.56465]
21Feb12_184648| [ 0.46234 -0.06487]
21Feb12_184648| [-0.53079  0.17866]
21Feb12_184648| [ 0.16999 -0.95302]
21Feb12_184648| [ 0.25867  0.78733]
21Feb12_184648| [ 0.56879  0.55681]
21Feb12_184648| [-0.17964 -0.29500]
21Feb12_184648| [ 0.79841 -0.15416]
21Feb12_184648| [ 0.55438 -0.65300]
21Feb12_184648| [-0.63040  0.74447]
21Feb12_184648| [-0.05612 -0.90323]
21Feb12_184648| [-0.49200 -1.13142]
21Feb12_184648| [ 0.57109  0.69426]
21Feb12_184648| [ 0.33833  1.30358]
21Feb12_184648| [-0.60117  0.21497]
21Feb12_184648| [-0.27104 -0.10814]
21Feb12_184648| [-0.15802  0.91218]
21Feb12_184648| [ 0.54241  0.80802]
21Feb12_184648| [ 0.66569  0.39524]
21Feb12_184648| [-0.13190  1.17715]
21Feb12_184648| [ 0.31978  0.15987]
21Feb12_184648| [-0.12298 -0.57237]
21Feb12_184648| [ 0.17417 -1.12011]
21Feb12_184648| [-0.12555  0.36729]
21Feb12_184648| [ 0.65815 -0.29020]]
21Feb12_184648|-- Bias --
21Feb12_184648|[-0.10678  0.15961]
21Feb12_184648|Layer 1:
21Feb12_184648|-- Config --
21Feb12_184648|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_184648|-- Weights --
21Feb12_184648|[[ 0.41471  1.23384]
21Feb12_184648| [ 0.12533 -0.06534]]
21Feb12_184648|-- Bias --
21Feb12_184648|[-0.37991  0.84672]
21Feb12_184648|Predicting the validation and test data with the Best final individual.
21Feb12_184655| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_184655|-----------  ------------------  --------------------  ----------
21Feb12_184655|Validation         38.78                  2             0.00000
21Feb12_184655|   Test            39.01                  2             0.00000
21Feb12_184655|-------------------- Test #5 --------------------
21Feb12_184655|Best final individual weights
21Feb12_184655|Individual:
21Feb12_184655|-- Constant hidden layers --
21Feb12_184655|False
21Feb12_184655|Layer 0:
21Feb12_184655|-- Config --
21Feb12_184655|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_184655|-- Weights --
21Feb12_184655|[[-0.22439  0.67798]
21Feb12_184655| [ 0.17502 -0.74040]
21Feb12_184655| [ 1.25096  0.23910]
21Feb12_184655| [ 0.73051 -0.95089]
21Feb12_184655| [-0.43728 -0.45019]
21Feb12_184655| [ 0.56566 -0.81758]
21Feb12_184655| [ 0.41154  1.13685]
21Feb12_184655| [ 0.25057 -0.71133]
21Feb12_184655| [ 0.42515 -1.51557]
21Feb12_184655| [-0.81825  0.70147]
21Feb12_184655| [-0.00593  0.85788]
21Feb12_184655| [-0.41476 -0.79663]
21Feb12_184655| [ 0.81896  0.59360]
21Feb12_184655| [ 0.44951  0.27890]
21Feb12_184655| [-0.45030 -0.49585]
21Feb12_184655| [-0.87356 -0.78499]
21Feb12_184655| [-1.11731 -0.38353]
21Feb12_184655| [ 0.49401 -0.70047]
21Feb12_184655| [-0.72782 -0.03427]
21Feb12_184655| [-0.39432 -0.65564]
21Feb12_184655| [-0.77313  0.22419]
21Feb12_184655| [-0.44810 -0.08650]
21Feb12_184655| [ 0.50671 -0.04631]
21Feb12_184655| [ 0.32901 -0.94198]
21Feb12_184655| [ 0.18140  0.14895]
21Feb12_184655| [-0.74432  0.51297]
21Feb12_184655| [ 0.56722 -0.55062]
21Feb12_184655| [ 1.36718 -0.42863]
21Feb12_184655| [ 0.16677  0.07095]
21Feb12_184655| [ 0.06528 -0.24294]
21Feb12_184655| [-1.03613  1.02094]
21Feb12_184655| [-0.10307  0.94086]
21Feb12_184655| [-0.12384  0.56465]
21Feb12_184655| [ 0.46234 -0.06487]
21Feb12_184655| [-0.53079  0.17866]
21Feb12_184655| [ 0.16999 -0.95302]
21Feb12_184655| [ 0.25867  0.78733]
21Feb12_184655| [ 0.56879  0.55681]
21Feb12_184655| [-0.17964 -0.29500]
21Feb12_184655| [ 0.79841 -0.15416]
21Feb12_184655| [ 0.55438 -0.65300]
21Feb12_184655| [-0.63040  0.74447]
21Feb12_184655| [-0.05612 -0.90323]
21Feb12_184655| [-0.49200 -1.13142]
21Feb12_184655| [ 0.57109  0.69426]
21Feb12_184655| [ 0.33833  1.30358]
21Feb12_184655| [-0.60117  0.21497]
21Feb12_184655| [-0.27104 -0.10814]
21Feb12_184655| [-0.15802  0.91218]
21Feb12_184655| [ 0.54241  0.80802]
21Feb12_184655| [ 0.66569  0.39524]
21Feb12_184655| [-0.13190  1.17715]
21Feb12_184655| [ 0.31978  0.15987]
21Feb12_184655| [-0.12298 -0.57237]
21Feb12_184655| [ 0.17417 -1.12011]
21Feb12_184655| [-0.12555  0.36729]
21Feb12_184655| [ 0.65815 -0.29020]]
21Feb12_184655|-- Bias --
21Feb12_184655|[-0.10678  0.15961]
21Feb12_184655|Layer 1:
21Feb12_184655|-- Config --
21Feb12_184655|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_184655|-- Weights --
21Feb12_184655|[[ 0.41471  1.23384]
21Feb12_184655| [ 0.12533 -0.06534]]
21Feb12_184655|-- Bias --
21Feb12_184655|[-0.37991  0.84672]
21Feb12_184655|Predicting the validation and test data with the Best final individual.
21Feb12_184702| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_184702|-----------  ------------------  --------------------  ----------
21Feb12_184702|Validation         38.78                  2             0.00000
21Feb12_184702|   Test            39.01                  2             0.00000
21Feb12_184702|-------------------- Test #6 --------------------
21Feb12_184702|Best final individual weights
21Feb12_184702|Individual:
21Feb12_184702|-- Constant hidden layers --
21Feb12_184702|False
21Feb12_184702|Layer 0:
21Feb12_184702|-- Config --
21Feb12_184702|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_184702|-- Weights --
21Feb12_184702|[[-0.22439  0.67798]
21Feb12_184702| [ 0.17502 -0.74040]
21Feb12_184702| [ 1.25096  0.23910]
21Feb12_184702| [ 0.73051 -0.95089]
21Feb12_184702| [-0.43728 -0.45019]
21Feb12_184702| [ 0.56566 -0.81758]
21Feb12_184702| [ 0.41154  1.13685]
21Feb12_184702| [ 0.25057 -0.71133]
21Feb12_184702| [ 0.42515 -1.51557]
21Feb12_184702| [-0.81825  0.70147]
21Feb12_184702| [-0.00593  0.85788]
21Feb12_184702| [-0.41476 -0.79663]
21Feb12_184702| [ 0.81896  0.59360]
21Feb12_184702| [ 0.44951  0.27890]
21Feb12_184702| [-0.45030 -0.49585]
21Feb12_184702| [-0.87356 -0.78499]
21Feb12_184702| [-1.11731 -0.38353]
21Feb12_184702| [ 0.49401 -0.70047]
21Feb12_184702| [-0.72782 -0.03427]
21Feb12_184702| [-0.39432 -0.65564]
21Feb12_184702| [-0.77313  0.22419]
21Feb12_184702| [-0.44810 -0.08650]
21Feb12_184702| [ 0.50671 -0.04631]
21Feb12_184702| [ 0.32901 -0.94198]
21Feb12_184702| [ 0.18140  0.14895]
21Feb12_184702| [-0.74432  0.51297]
21Feb12_184702| [ 0.56722 -0.55062]
21Feb12_184702| [ 1.36718 -0.42863]
21Feb12_184702| [ 0.16677  0.07095]
21Feb12_184702| [ 0.06528 -0.24294]
21Feb12_184702| [-1.03613  1.02094]
21Feb12_184702| [-0.10307  0.94086]
21Feb12_184702| [-0.12384  0.56465]
21Feb12_184702| [ 0.46234 -0.06487]
21Feb12_184702| [-0.53079  0.17866]
21Feb12_184702| [ 0.16999 -0.95302]
21Feb12_184702| [ 0.25867  0.78733]
21Feb12_184702| [ 0.56879  0.55681]
21Feb12_184702| [-0.17964 -0.29500]
21Feb12_184702| [ 0.79841 -0.15416]
21Feb12_184702| [ 0.55438 -0.65300]
21Feb12_184702| [-0.63040  0.74447]
21Feb12_184702| [-0.05612 -0.90323]
21Feb12_184702| [-0.49200 -1.13142]
21Feb12_184702| [ 0.57109  0.69426]
21Feb12_184702| [ 0.33833  1.30358]
21Feb12_184702| [-0.60117  0.21497]
21Feb12_184702| [-0.27104 -0.10814]
21Feb12_184702| [-0.15802  0.91218]
21Feb12_184702| [ 0.54241  0.80802]
21Feb12_184702| [ 0.66569  0.39524]
21Feb12_184702| [-0.13190  1.17715]
21Feb12_184702| [ 0.31978  0.15987]
21Feb12_184702| [-0.12298 -0.57237]
21Feb12_184702| [ 0.17417 -1.12011]
21Feb12_184702| [-0.12555  0.36729]
21Feb12_184702| [ 0.65815 -0.29020]]
21Feb12_184702|-- Bias --
21Feb12_184702|[-0.10678  0.15961]
21Feb12_184702|Layer 1:
21Feb12_184702|-- Config --
21Feb12_184702|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_184702|-- Weights --
21Feb12_184702|[[ 0.41471  1.23384]
21Feb12_184702| [ 0.12533 -0.06534]]
21Feb12_184702|-- Bias --
21Feb12_184702|[-0.37991  0.84672]
21Feb12_184702|Predicting the validation and test data with the Best final individual.
21Feb12_184709| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_184709|-----------  ------------------  --------------------  ----------
21Feb12_184709|Validation         38.78                  2             0.00000
21Feb12_184709|   Test            39.01                  2             0.00000
21Feb12_184709|-------------------- Test #7 --------------------
21Feb12_184709|Best final individual weights
21Feb12_184709|Individual:
21Feb12_184709|-- Constant hidden layers --
21Feb12_184709|False
21Feb12_184709|Layer 0:
21Feb12_184709|-- Config --
21Feb12_184709|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_184709|-- Weights --
21Feb12_184709|[[-0.22439  0.67798]
21Feb12_184709| [ 0.17502 -0.74040]
21Feb12_184709| [ 1.25096  0.23910]
21Feb12_184709| [ 0.73051 -0.95089]
21Feb12_184709| [-0.43728 -0.45019]
21Feb12_184709| [ 0.56566 -0.81758]
21Feb12_184709| [ 0.41154  1.13685]
21Feb12_184709| [ 0.25057 -0.71133]
21Feb12_184709| [ 0.42515 -1.51557]
21Feb12_184709| [-0.81825  0.70147]
21Feb12_184709| [-0.00593  0.85788]
21Feb12_184709| [-0.41476 -0.79663]
21Feb12_184709| [ 0.81896  0.59360]
21Feb12_184709| [ 0.44951  0.27890]
21Feb12_184709| [-0.45030 -0.49585]
21Feb12_184709| [-0.87356 -0.78499]
21Feb12_184709| [-1.11731 -0.38353]
21Feb12_184709| [ 0.49401 -0.70047]
21Feb12_184709| [-0.72782 -0.03427]
21Feb12_184709| [-0.39432 -0.65564]
21Feb12_184709| [-0.77313  0.22419]
21Feb12_184709| [-0.44810 -0.08650]
21Feb12_184709| [ 0.50671 -0.04631]
21Feb12_184709| [ 0.32901 -0.94198]
21Feb12_184709| [ 0.18140  0.14895]
21Feb12_184709| [-0.74432  0.51297]
21Feb12_184709| [ 0.56722 -0.55062]
21Feb12_184709| [ 1.36718 -0.42863]
21Feb12_184709| [ 0.16677  0.07095]
21Feb12_184709| [ 0.06528 -0.24294]
21Feb12_184709| [-1.03613  1.02094]
21Feb12_184709| [-0.10307  0.94086]
21Feb12_184709| [-0.12384  0.56465]
21Feb12_184709| [ 0.46234 -0.06487]
21Feb12_184709| [-0.53079  0.17866]
21Feb12_184709| [ 0.16999 -0.95302]
21Feb12_184709| [ 0.25867  0.78733]
21Feb12_184709| [ 0.56879  0.55681]
21Feb12_184709| [-0.17964 -0.29500]
21Feb12_184709| [ 0.79841 -0.15416]
21Feb12_184709| [ 0.55438 -0.65300]
21Feb12_184709| [-0.63040  0.74447]
21Feb12_184709| [-0.05612 -0.90323]
21Feb12_184709| [-0.49200 -1.13142]
21Feb12_184709| [ 0.57109  0.69426]
21Feb12_184709| [ 0.33833  1.30358]
21Feb12_184709| [-0.60117  0.21497]
21Feb12_184709| [-0.27104 -0.10814]
21Feb12_184709| [-0.15802  0.91218]
21Feb12_184709| [ 0.54241  0.80802]
21Feb12_184709| [ 0.66569  0.39524]
21Feb12_184709| [-0.13190  1.17715]
21Feb12_184709| [ 0.31978  0.15987]
21Feb12_184709| [-0.12298 -0.57237]
21Feb12_184709| [ 0.17417 -1.12011]
21Feb12_184709| [-0.12555  0.36729]
21Feb12_184709| [ 0.65815 -0.29020]]
21Feb12_184709|-- Bias --
21Feb12_184709|[-0.10678  0.15961]
21Feb12_184709|Layer 1:
21Feb12_184709|-- Config --
21Feb12_184709|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_184709|-- Weights --
21Feb12_184709|[[ 0.41471  1.23384]
21Feb12_184709| [ 0.12533 -0.06534]]
21Feb12_184709|-- Bias --
21Feb12_184709|[-0.37991  0.84672]
21Feb12_184709|Predicting the validation and test data with the Best final individual.
21Feb12_184716| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_184716|-----------  ------------------  --------------------  ----------
21Feb12_184716|Validation         38.78                  2             0.00000
21Feb12_184716|   Test            39.01                  2             0.00000
21Feb12_184716|-------------------- Test #8 --------------------
21Feb12_184716|Best final individual weights
21Feb12_184716|Individual:
21Feb12_184716|-- Constant hidden layers --
21Feb12_184716|False
21Feb12_184716|Layer 0:
21Feb12_184716|-- Config --
21Feb12_184716|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_184716|-- Weights --
21Feb12_184716|[[-0.22439  0.67798]
21Feb12_184716| [ 0.17502 -0.74040]
21Feb12_184716| [ 1.25096  0.23910]
21Feb12_184716| [ 0.73051 -0.95089]
21Feb12_184716| [-0.43728 -0.45019]
21Feb12_184716| [ 0.56566 -0.81758]
21Feb12_184716| [ 0.41154  1.13685]
21Feb12_184716| [ 0.25057 -0.71133]
21Feb12_184716| [ 0.42515 -1.51557]
21Feb12_184716| [-0.81825  0.70147]
21Feb12_184716| [-0.00593  0.85788]
21Feb12_184716| [-0.41476 -0.79663]
21Feb12_184716| [ 0.81896  0.59360]
21Feb12_184716| [ 0.44951  0.27890]
21Feb12_184716| [-0.45030 -0.49585]
21Feb12_184716| [-0.87356 -0.78499]
21Feb12_184716| [-1.11731 -0.38353]
21Feb12_184716| [ 0.49401 -0.70047]
21Feb12_184716| [-0.72782 -0.03427]
21Feb12_184716| [-0.39432 -0.65564]
21Feb12_184716| [-0.77313  0.22419]
21Feb12_184716| [-0.44810 -0.08650]
21Feb12_184716| [ 0.50671 -0.04631]
21Feb12_184716| [ 0.32901 -0.94198]
21Feb12_184716| [ 0.18140  0.14895]
21Feb12_184716| [-0.74432  0.51297]
21Feb12_184716| [ 0.56722 -0.55062]
21Feb12_184716| [ 1.36718 -0.42863]
21Feb12_184716| [ 0.16677  0.07095]
21Feb12_184716| [ 0.06528 -0.24294]
21Feb12_184716| [-1.03613  1.02094]
21Feb12_184716| [-0.10307  0.94086]
21Feb12_184716| [-0.12384  0.56465]
21Feb12_184716| [ 0.46234 -0.06487]
21Feb12_184716| [-0.53079  0.17866]
21Feb12_184716| [ 0.16999 -0.95302]
21Feb12_184716| [ 0.25867  0.78733]
21Feb12_184716| [ 0.56879  0.55681]
21Feb12_184716| [-0.17964 -0.29500]
21Feb12_184716| [ 0.79841 -0.15416]
21Feb12_184716| [ 0.55438 -0.65300]
21Feb12_184716| [-0.63040  0.74447]
21Feb12_184716| [-0.05612 -0.90323]
21Feb12_184716| [-0.49200 -1.13142]
21Feb12_184716| [ 0.57109  0.69426]
21Feb12_184716| [ 0.33833  1.30358]
21Feb12_184716| [-0.60117  0.21497]
21Feb12_184716| [-0.27104 -0.10814]
21Feb12_184716| [-0.15802  0.91218]
21Feb12_184716| [ 0.54241  0.80802]
21Feb12_184716| [ 0.66569  0.39524]
21Feb12_184716| [-0.13190  1.17715]
21Feb12_184716| [ 0.31978  0.15987]
21Feb12_184716| [-0.12298 -0.57237]
21Feb12_184716| [ 0.17417 -1.12011]
21Feb12_184716| [-0.12555  0.36729]
21Feb12_184716| [ 0.65815 -0.29020]]
21Feb12_184716|-- Bias --
21Feb12_184716|[-0.10678  0.15961]
21Feb12_184716|Layer 1:
21Feb12_184716|-- Config --
21Feb12_184716|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_184716|-- Weights --
21Feb12_184716|[[ 0.41471  1.23384]
21Feb12_184716| [ 0.12533 -0.06534]]
21Feb12_184716|-- Bias --
21Feb12_184716|[-0.37991  0.84672]
21Feb12_184716|Predicting the validation and test data with the Best final individual.
21Feb12_184723| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_184723|-----------  ------------------  --------------------  ----------
21Feb12_184723|Validation         38.78                  2             0.00000
21Feb12_184723|   Test            39.01                  2             0.00000
21Feb12_184723|-------------------- Test #9 --------------------
21Feb12_184723|Best final individual weights
21Feb12_184723|Individual:
21Feb12_184723|-- Constant hidden layers --
21Feb12_184723|False
21Feb12_184723|Layer 0:
21Feb12_184723|-- Config --
21Feb12_184723|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_184723|-- Weights --
21Feb12_184723|[[-0.22439  0.67798]
21Feb12_184723| [ 0.17502 -0.74040]
21Feb12_184723| [ 1.25096  0.23910]
21Feb12_184723| [ 0.73051 -0.95089]
21Feb12_184723| [-0.43728 -0.45019]
21Feb12_184723| [ 0.56566 -0.81758]
21Feb12_184723| [ 0.41154  1.13685]
21Feb12_184723| [ 0.25057 -0.71133]
21Feb12_184723| [ 0.42515 -1.51557]
21Feb12_184723| [-0.81825  0.70147]
21Feb12_184723| [-0.00593  0.85788]
21Feb12_184723| [-0.41476 -0.79663]
21Feb12_184723| [ 0.81896  0.59360]
21Feb12_184723| [ 0.44951  0.27890]
21Feb12_184723| [-0.45030 -0.49585]
21Feb12_184723| [-0.87356 -0.78499]
21Feb12_184723| [-1.11731 -0.38353]
21Feb12_184723| [ 0.49401 -0.70047]
21Feb12_184723| [-0.72782 -0.03427]
21Feb12_184723| [-0.39432 -0.65564]
21Feb12_184723| [-0.77313  0.22419]
21Feb12_184723| [-0.44810 -0.08650]
21Feb12_184723| [ 0.50671 -0.04631]
21Feb12_184723| [ 0.32901 -0.94198]
21Feb12_184723| [ 0.18140  0.14895]
21Feb12_184723| [-0.74432  0.51297]
21Feb12_184723| [ 0.56722 -0.55062]
21Feb12_184723| [ 1.36718 -0.42863]
21Feb12_184723| [ 0.16677  0.07095]
21Feb12_184723| [ 0.06528 -0.24294]
21Feb12_184723| [-1.03613  1.02094]
21Feb12_184723| [-0.10307  0.94086]
21Feb12_184723| [-0.12384  0.56465]
21Feb12_184723| [ 0.46234 -0.06487]
21Feb12_184723| [-0.53079  0.17866]
21Feb12_184723| [ 0.16999 -0.95302]
21Feb12_184723| [ 0.25867  0.78733]
21Feb12_184723| [ 0.56879  0.55681]
21Feb12_184723| [-0.17964 -0.29500]
21Feb12_184723| [ 0.79841 -0.15416]
21Feb12_184723| [ 0.55438 -0.65300]
21Feb12_184723| [-0.63040  0.74447]
21Feb12_184723| [-0.05612 -0.90323]
21Feb12_184723| [-0.49200 -1.13142]
21Feb12_184723| [ 0.57109  0.69426]
21Feb12_184723| [ 0.33833  1.30358]
21Feb12_184723| [-0.60117  0.21497]
21Feb12_184723| [-0.27104 -0.10814]
21Feb12_184723| [-0.15802  0.91218]
21Feb12_184723| [ 0.54241  0.80802]
21Feb12_184723| [ 0.66569  0.39524]
21Feb12_184723| [-0.13190  1.17715]
21Feb12_184723| [ 0.31978  0.15987]
21Feb12_184723| [-0.12298 -0.57237]
21Feb12_184723| [ 0.17417 -1.12011]
21Feb12_184723| [-0.12555  0.36729]
21Feb12_184723| [ 0.65815 -0.29020]]
21Feb12_184723|-- Bias --
21Feb12_184723|[-0.10678  0.15961]
21Feb12_184723|Layer 1:
21Feb12_184723|-- Config --
21Feb12_184723|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_184723|-- Weights --
21Feb12_184723|[[ 0.41471  1.23384]
21Feb12_184723| [ 0.12533 -0.06534]]
21Feb12_184723|-- Bias --
21Feb12_184723|[-0.37991  0.84672]
21Feb12_184723|Predicting the validation and test data with the Best final individual.
21Feb12_184730| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_184730|-----------  ------------------  --------------------  ----------
21Feb12_184730|Validation         38.78                  2             0.00000
21Feb12_184730|   Test            39.01                  2             0.00000
21Feb12_184730|-------------------- Test #10 --------------------
21Feb12_184730|Best final individual weights
21Feb12_184730|Individual:
21Feb12_184730|-- Constant hidden layers --
21Feb12_184730|False
21Feb12_184730|Layer 0:
21Feb12_184730|-- Config --
21Feb12_184730|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_184730|-- Weights --
21Feb12_184730|[[-0.22439  0.67798]
21Feb12_184730| [ 0.17502 -0.74040]
21Feb12_184730| [ 1.25096  0.23910]
21Feb12_184730| [ 0.73051 -0.95089]
21Feb12_184730| [-0.43728 -0.45019]
21Feb12_184730| [ 0.56566 -0.81758]
21Feb12_184730| [ 0.41154  1.13685]
21Feb12_184730| [ 0.25057 -0.71133]
21Feb12_184730| [ 0.42515 -1.51557]
21Feb12_184730| [-0.81825  0.70147]
21Feb12_184730| [-0.00593  0.85788]
21Feb12_184730| [-0.41476 -0.79663]
21Feb12_184730| [ 0.81896  0.59360]
21Feb12_184730| [ 0.44951  0.27890]
21Feb12_184730| [-0.45030 -0.49585]
21Feb12_184730| [-0.87356 -0.78499]
21Feb12_184730| [-1.11731 -0.38353]
21Feb12_184730| [ 0.49401 -0.70047]
21Feb12_184730| [-0.72782 -0.03427]
21Feb12_184730| [-0.39432 -0.65564]
21Feb12_184730| [-0.77313  0.22419]
21Feb12_184730| [-0.44810 -0.08650]
21Feb12_184730| [ 0.50671 -0.04631]
21Feb12_184730| [ 0.32901 -0.94198]
21Feb12_184730| [ 0.18140  0.14895]
21Feb12_184730| [-0.74432  0.51297]
21Feb12_184730| [ 0.56722 -0.55062]
21Feb12_184730| [ 1.36718 -0.42863]
21Feb12_184730| [ 0.16677  0.07095]
21Feb12_184730| [ 0.06528 -0.24294]
21Feb12_184730| [-1.03613  1.02094]
21Feb12_184730| [-0.10307  0.94086]
21Feb12_184730| [-0.12384  0.56465]
21Feb12_184730| [ 0.46234 -0.06487]
21Feb12_184730| [-0.53079  0.17866]
21Feb12_184730| [ 0.16999 -0.95302]
21Feb12_184730| [ 0.25867  0.78733]
21Feb12_184730| [ 0.56879  0.55681]
21Feb12_184730| [-0.17964 -0.29500]
21Feb12_184730| [ 0.79841 -0.15416]
21Feb12_184730| [ 0.55438 -0.65300]
21Feb12_184730| [-0.63040  0.74447]
21Feb12_184730| [-0.05612 -0.90323]
21Feb12_184730| [-0.49200 -1.13142]
21Feb12_184730| [ 0.57109  0.69426]
21Feb12_184730| [ 0.33833  1.30358]
21Feb12_184730| [-0.60117  0.21497]
21Feb12_184730| [-0.27104 -0.10814]
21Feb12_184730| [-0.15802  0.91218]
21Feb12_184730| [ 0.54241  0.80802]
21Feb12_184730| [ 0.66569  0.39524]
21Feb12_184730| [-0.13190  1.17715]
21Feb12_184730| [ 0.31978  0.15987]
21Feb12_184730| [-0.12298 -0.57237]
21Feb12_184730| [ 0.17417 -1.12011]
21Feb12_184730| [-0.12555  0.36729]
21Feb12_184730| [ 0.65815 -0.29020]]
21Feb12_184730|-- Bias --
21Feb12_184730|[-0.10678  0.15961]
21Feb12_184730|Layer 1:
21Feb12_184730|-- Config --
21Feb12_184730|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_184730|-- Weights --
21Feb12_184730|[[ 0.41471  1.23384]
21Feb12_184730| [ 0.12533 -0.06534]]
21Feb12_184730|-- Bias --
21Feb12_184730|[-0.37991  0.84672]
21Feb12_184730|Predicting the validation and test data with the Best final individual.
21Feb12_184737| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_184737|-----------  ------------------  --------------------  ----------
21Feb12_184737|Validation         38.78                  2             0.00000
21Feb12_184737|   Test            39.01                  2             0.00000
21Feb12_184737|-------------------- Test #11 --------------------
21Feb12_184737|Best final individual weights
21Feb12_184737|Individual:
21Feb12_184737|-- Constant hidden layers --
21Feb12_184737|False
21Feb12_184737|Layer 0:
21Feb12_184737|-- Config --
21Feb12_184737|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_184737|-- Weights --
21Feb12_184737|[[-0.22439  0.67798]
21Feb12_184737| [ 0.17502 -0.74040]
21Feb12_184737| [ 1.25096  0.23910]
21Feb12_184737| [ 0.73051 -0.95089]
21Feb12_184737| [-0.43728 -0.45019]
21Feb12_184737| [ 0.56566 -0.81758]
21Feb12_184737| [ 0.41154  1.13685]
21Feb12_184737| [ 0.25057 -0.71133]
21Feb12_184737| [ 0.42515 -1.51557]
21Feb12_184737| [-0.81825  0.70147]
21Feb12_184737| [-0.00593  0.85788]
21Feb12_184737| [-0.41476 -0.79663]
21Feb12_184737| [ 0.81896  0.59360]
21Feb12_184737| [ 0.44951  0.27890]
21Feb12_184737| [-0.45030 -0.49585]
21Feb12_184737| [-0.87356 -0.78499]
21Feb12_184737| [-1.11731 -0.38353]
21Feb12_184737| [ 0.49401 -0.70047]
21Feb12_184737| [-0.72782 -0.03427]
21Feb12_184737| [-0.39432 -0.65564]
21Feb12_184737| [-0.77313  0.22419]
21Feb12_184737| [-0.44810 -0.08650]
21Feb12_184737| [ 0.50671 -0.04631]
21Feb12_184737| [ 0.32901 -0.94198]
21Feb12_184737| [ 0.18140  0.14895]
21Feb12_184737| [-0.74432  0.51297]
21Feb12_184737| [ 0.56722 -0.55062]
21Feb12_184737| [ 1.36718 -0.42863]
21Feb12_184737| [ 0.16677  0.07095]
21Feb12_184737| [ 0.06528 -0.24294]
21Feb12_184737| [-1.03613  1.02094]
21Feb12_184737| [-0.10307  0.94086]
21Feb12_184737| [-0.12384  0.56465]
21Feb12_184737| [ 0.46234 -0.06487]
21Feb12_184737| [-0.53079  0.17866]
21Feb12_184737| [ 0.16999 -0.95302]
21Feb12_184737| [ 0.25867  0.78733]
21Feb12_184737| [ 0.56879  0.55681]
21Feb12_184737| [-0.17964 -0.29500]
21Feb12_184737| [ 0.79841 -0.15416]
21Feb12_184737| [ 0.55438 -0.65300]
21Feb12_184737| [-0.63040  0.74447]
21Feb12_184737| [-0.05612 -0.90323]
21Feb12_184737| [-0.49200 -1.13142]
21Feb12_184737| [ 0.57109  0.69426]
21Feb12_184737| [ 0.33833  1.30358]
21Feb12_184737| [-0.60117  0.21497]
21Feb12_184737| [-0.27104 -0.10814]
21Feb12_184737| [-0.15802  0.91218]
21Feb12_184737| [ 0.54241  0.80802]
21Feb12_184737| [ 0.66569  0.39524]
21Feb12_184737| [-0.13190  1.17715]
21Feb12_184737| [ 0.31978  0.15987]
21Feb12_184737| [-0.12298 -0.57237]
21Feb12_184737| [ 0.17417 -1.12011]
21Feb12_184737| [-0.12555  0.36729]
21Feb12_184737| [ 0.65815 -0.29020]]
21Feb12_184737|-- Bias --
21Feb12_184737|[-0.10678  0.15961]
21Feb12_184737|Layer 1:
21Feb12_184737|-- Config --
21Feb12_184737|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_184737|-- Weights --
21Feb12_184737|[[ 0.41471  1.23384]
21Feb12_184737| [ 0.12533 -0.06534]]
21Feb12_184737|-- Bias --
21Feb12_184737|[-0.37991  0.84672]
21Feb12_184737|Predicting the validation and test data with the Best final individual.
21Feb12_184744| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_184744|-----------  ------------------  --------------------  ----------
21Feb12_184744|Validation         38.78                  2             0.00000
21Feb12_184744|   Test            39.01                  2             0.00000
21Feb12_184744|-------------------- Test #12 --------------------
21Feb12_184744|Best final individual weights
21Feb12_184744|Individual:
21Feb12_184744|-- Constant hidden layers --
21Feb12_184744|False
21Feb12_184744|Layer 0:
21Feb12_184744|-- Config --
21Feb12_184744|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_184744|-- Weights --
21Feb12_184744|[[-0.22439  0.67798]
21Feb12_184744| [ 0.17502 -0.74040]
21Feb12_184744| [ 1.25096  0.23910]
21Feb12_184744| [ 0.73051 -0.95089]
21Feb12_184744| [-0.43728 -0.45019]
21Feb12_184744| [ 0.56566 -0.81758]
21Feb12_184744| [ 0.41154  1.13685]
21Feb12_184744| [ 0.25057 -0.71133]
21Feb12_184744| [ 0.42515 -1.51557]
21Feb12_184744| [-0.81825  0.70147]
21Feb12_184744| [-0.00593  0.85788]
21Feb12_184744| [-0.41476 -0.79663]
21Feb12_184744| [ 0.81896  0.59360]
21Feb12_184744| [ 0.44951  0.27890]
21Feb12_184744| [-0.45030 -0.49585]
21Feb12_184744| [-0.87356 -0.78499]
21Feb12_184744| [-1.11731 -0.38353]
21Feb12_184744| [ 0.49401 -0.70047]
21Feb12_184744| [-0.72782 -0.03427]
21Feb12_184744| [-0.39432 -0.65564]
21Feb12_184744| [-0.77313  0.22419]
21Feb12_184744| [-0.44810 -0.08650]
21Feb12_184744| [ 0.50671 -0.04631]
21Feb12_184744| [ 0.32901 -0.94198]
21Feb12_184744| [ 0.18140  0.14895]
21Feb12_184744| [-0.74432  0.51297]
21Feb12_184744| [ 0.56722 -0.55062]
21Feb12_184744| [ 1.36718 -0.42863]
21Feb12_184744| [ 0.16677  0.07095]
21Feb12_184744| [ 0.06528 -0.24294]
21Feb12_184744| [-1.03613  1.02094]
21Feb12_184744| [-0.10307  0.94086]
21Feb12_184744| [-0.12384  0.56465]
21Feb12_184744| [ 0.46234 -0.06487]
21Feb12_184744| [-0.53079  0.17866]
21Feb12_184744| [ 0.16999 -0.95302]
21Feb12_184744| [ 0.25867  0.78733]
21Feb12_184744| [ 0.56879  0.55681]
21Feb12_184744| [-0.17964 -0.29500]
21Feb12_184744| [ 0.79841 -0.15416]
21Feb12_184744| [ 0.55438 -0.65300]
21Feb12_184744| [-0.63040  0.74447]
21Feb12_184744| [-0.05612 -0.90323]
21Feb12_184744| [-0.49200 -1.13142]
21Feb12_184744| [ 0.57109  0.69426]
21Feb12_184744| [ 0.33833  1.30358]
21Feb12_184744| [-0.60117  0.21497]
21Feb12_184744| [-0.27104 -0.10814]
21Feb12_184744| [-0.15802  0.91218]
21Feb12_184744| [ 0.54241  0.80802]
21Feb12_184744| [ 0.66569  0.39524]
21Feb12_184744| [-0.13190  1.17715]
21Feb12_184744| [ 0.31978  0.15987]
21Feb12_184744| [-0.12298 -0.57237]
21Feb12_184744| [ 0.17417 -1.12011]
21Feb12_184744| [-0.12555  0.36729]
21Feb12_184744| [ 0.65815 -0.29020]]
21Feb12_184744|-- Bias --
21Feb12_184744|[-0.10678  0.15961]
21Feb12_184744|Layer 1:
21Feb12_184744|-- Config --
21Feb12_184744|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_184744|-- Weights --
21Feb12_184744|[[ 0.41471  1.23384]
21Feb12_184744| [ 0.12533 -0.06534]]
21Feb12_184744|-- Bias --
21Feb12_184744|[-0.37991  0.84672]
21Feb12_184744|Predicting the validation and test data with the Best final individual.
21Feb12_184751| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_184751|-----------  ------------------  --------------------  ----------
21Feb12_184751|Validation         38.78                  2             0.00000
21Feb12_184751|   Test            39.01                  2             0.00000
21Feb12_184751|-------------------- Test #13 --------------------
21Feb12_184751|Best final individual weights
21Feb12_184751|Individual:
21Feb12_184751|-- Constant hidden layers --
21Feb12_184751|False
21Feb12_184751|Layer 0:
21Feb12_184751|-- Config --
21Feb12_184751|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_184751|-- Weights --
21Feb12_184751|[[-0.22439  0.67798]
21Feb12_184751| [ 0.17502 -0.74040]
21Feb12_184751| [ 1.25096  0.23910]
21Feb12_184751| [ 0.73051 -0.95089]
21Feb12_184751| [-0.43728 -0.45019]
21Feb12_184751| [ 0.56566 -0.81758]
21Feb12_184751| [ 0.41154  1.13685]
21Feb12_184751| [ 0.25057 -0.71133]
21Feb12_184751| [ 0.42515 -1.51557]
21Feb12_184751| [-0.81825  0.70147]
21Feb12_184751| [-0.00593  0.85788]
21Feb12_184751| [-0.41476 -0.79663]
21Feb12_184751| [ 0.81896  0.59360]
21Feb12_184751| [ 0.44951  0.27890]
21Feb12_184751| [-0.45030 -0.49585]
21Feb12_184751| [-0.87356 -0.78499]
21Feb12_184751| [-1.11731 -0.38353]
21Feb12_184751| [ 0.49401 -0.70047]
21Feb12_184751| [-0.72782 -0.03427]
21Feb12_184751| [-0.39432 -0.65564]
21Feb12_184751| [-0.77313  0.22419]
21Feb12_184751| [-0.44810 -0.08650]
21Feb12_184751| [ 0.50671 -0.04631]
21Feb12_184751| [ 0.32901 -0.94198]
21Feb12_184751| [ 0.18140  0.14895]
21Feb12_184751| [-0.74432  0.51297]
21Feb12_184751| [ 0.56722 -0.55062]
21Feb12_184751| [ 1.36718 -0.42863]
21Feb12_184751| [ 0.16677  0.07095]
21Feb12_184751| [ 0.06528 -0.24294]
21Feb12_184751| [-1.03613  1.02094]
21Feb12_184751| [-0.10307  0.94086]
21Feb12_184751| [-0.12384  0.56465]
21Feb12_184751| [ 0.46234 -0.06487]
21Feb12_184751| [-0.53079  0.17866]
21Feb12_184751| [ 0.16999 -0.95302]
21Feb12_184751| [ 0.25867  0.78733]
21Feb12_184751| [ 0.56879  0.55681]
21Feb12_184751| [-0.17964 -0.29500]
21Feb12_184751| [ 0.79841 -0.15416]
21Feb12_184751| [ 0.55438 -0.65300]
21Feb12_184751| [-0.63040  0.74447]
21Feb12_184751| [-0.05612 -0.90323]
21Feb12_184751| [-0.49200 -1.13142]
21Feb12_184751| [ 0.57109  0.69426]
21Feb12_184751| [ 0.33833  1.30358]
21Feb12_184751| [-0.60117  0.21497]
21Feb12_184751| [-0.27104 -0.10814]
21Feb12_184751| [-0.15802  0.91218]
21Feb12_184751| [ 0.54241  0.80802]
21Feb12_184751| [ 0.66569  0.39524]
21Feb12_184751| [-0.13190  1.17715]
21Feb12_184751| [ 0.31978  0.15987]
21Feb12_184751| [-0.12298 -0.57237]
21Feb12_184751| [ 0.17417 -1.12011]
21Feb12_184751| [-0.12555  0.36729]
21Feb12_184751| [ 0.65815 -0.29020]]
21Feb12_184751|-- Bias --
21Feb12_184751|[-0.10678  0.15961]
21Feb12_184751|Layer 1:
21Feb12_184751|-- Config --
21Feb12_184751|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_184751|-- Weights --
21Feb12_184751|[[ 0.41471  1.23384]
21Feb12_184751| [ 0.12533 -0.06534]]
21Feb12_184751|-- Bias --
21Feb12_184751|[-0.37991  0.84672]
21Feb12_184751|Predicting the validation and test data with the Best final individual.
21Feb12_184758| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_184758|-----------  ------------------  --------------------  ----------
21Feb12_184758|Validation         38.87                  2             0.00000
21Feb12_184758|   Test            39.01                  2             0.00000
21Feb12_184758|-------------------- Test #14 --------------------
21Feb12_184758|Best final individual weights
21Feb12_184758|Individual:
21Feb12_184758|-- Constant hidden layers --
21Feb12_184758|False
21Feb12_184758|Layer 0:
21Feb12_184758|-- Config --
21Feb12_184758|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_184758|-- Weights --
21Feb12_184758|[[-0.22439  0.67798]
21Feb12_184758| [ 0.17502 -0.74040]
21Feb12_184758| [ 1.25096  0.23910]
21Feb12_184758| [ 0.73051 -0.95089]
21Feb12_184758| [-0.43728 -0.45019]
21Feb12_184758| [ 0.56566 -0.81758]
21Feb12_184758| [ 0.41154  1.13685]
21Feb12_184758| [ 0.25057 -0.71133]
21Feb12_184758| [ 0.42515 -1.51557]
21Feb12_184758| [-0.81825  0.70147]
21Feb12_184758| [-0.00593  0.85788]
21Feb12_184758| [-0.41476 -0.79663]
21Feb12_184758| [ 0.81896  0.59360]
21Feb12_184758| [ 0.44951  0.27890]
21Feb12_184758| [-0.45030 -0.49585]
21Feb12_184758| [-0.87356 -0.78499]
21Feb12_184758| [-1.11731 -0.38353]
21Feb12_184758| [ 0.49401 -0.70047]
21Feb12_184758| [-0.72782 -0.03427]
21Feb12_184758| [-0.39432 -0.65564]
21Feb12_184758| [-0.77313  0.22419]
21Feb12_184758| [-0.44810 -0.08650]
21Feb12_184758| [ 0.50671 -0.04631]
21Feb12_184758| [ 0.32901 -0.94198]
21Feb12_184758| [ 0.18140  0.14895]
21Feb12_184758| [-0.74432  0.51297]
21Feb12_184758| [ 0.56722 -0.55062]
21Feb12_184758| [ 1.36718 -0.42863]
21Feb12_184758| [ 0.16677  0.07095]
21Feb12_184758| [ 0.06528 -0.24294]
21Feb12_184758| [-1.03613  1.02094]
21Feb12_184758| [-0.10307  0.94086]
21Feb12_184758| [-0.12384  0.56465]
21Feb12_184758| [ 0.46234 -0.06487]
21Feb12_184758| [-0.53079  0.17866]
21Feb12_184758| [ 0.16999 -0.95302]
21Feb12_184758| [ 0.25867  0.78733]
21Feb12_184758| [ 0.56879  0.55681]
21Feb12_184758| [-0.17964 -0.29500]
21Feb12_184758| [ 0.79841 -0.15416]
21Feb12_184758| [ 0.55438 -0.65300]
21Feb12_184758| [-0.63040  0.74447]
21Feb12_184758| [-0.05612 -0.90323]
21Feb12_184758| [-0.49200 -1.13142]
21Feb12_184758| [ 0.57109  0.69426]
21Feb12_184758| [ 0.33833  1.30358]
21Feb12_184758| [-0.60117  0.21497]
21Feb12_184758| [-0.27104 -0.10814]
21Feb12_184758| [-0.15802  0.91218]
21Feb12_184758| [ 0.54241  0.80802]
21Feb12_184758| [ 0.66569  0.39524]
21Feb12_184758| [-0.13190  1.17715]
21Feb12_184758| [ 0.31978  0.15987]
21Feb12_184758| [-0.12298 -0.57237]
21Feb12_184758| [ 0.17417 -1.12011]
21Feb12_184758| [-0.12555  0.36729]
21Feb12_184758| [ 0.65815 -0.29020]]
21Feb12_184758|-- Bias --
21Feb12_184758|[-0.10678  0.15961]
21Feb12_184758|Layer 1:
21Feb12_184758|-- Config --
21Feb12_184758|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_184758|-- Weights --
21Feb12_184758|[[ 0.41471  1.23384]
21Feb12_184758| [ 0.12533 -0.06534]]
21Feb12_184758|-- Bias --
21Feb12_184758|[-0.37991  0.84672]
21Feb12_184758|Predicting the validation and test data with the Best final individual.
21Feb12_184805| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_184805|-----------  ------------------  --------------------  ----------
21Feb12_184805|Validation         38.78                  2             0.00000
21Feb12_184805|   Test            39.01                  2             0.00000
2021-02-12 18:48:06.557333: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
21Feb12_184807|Data summary: Train
21Feb12_184807|data.shape = (2300, 57)
21Feb12_184807|labels.shape = (2300,)
21Feb12_184807|Class distribution:
21Feb12_184807|	0 - 1382 (0.60)
21Feb12_184807|	1 - 918 (0.40)
21Feb12_184807|Data summary: Validation
21Feb12_184807|data.shape = (1150, 57)
21Feb12_184807|labels.shape = (1150,)
21Feb12_184807|Class distribution:
21Feb12_184807|	0 - 704 (0.61)
21Feb12_184807|	1 - 446 (0.39)
21Feb12_184807|Data summary: Test
21Feb12_184807|data.shape = (1151, 57)
21Feb12_184807|labels.shape = (1151,)
21Feb12_184807|Class distribution:
21Feb12_184807|	0 - 702 (0.61)
21Feb12_184807|	1 - 449 (0.39)
21Feb12_184807|Selected configuration values
21Feb12_184807|-- Dataset name: spambase1
21Feb12_184807|-- Initial population size: 64
21Feb12_184807|-- Maximun number of generations: 32
21Feb12_184807|-- Neurons per hidden layer range: (2, 20)
21Feb12_184807|-- Hidden layers number range: (1, 3)
21Feb12_184807|-- Crossover probability: 0.5
21Feb12_184807|-- Bias gene mutation probability: 0.2
21Feb12_184807|-- Weights gene mutation probability: 0.75
21Feb12_184807|-- Neuron mutation probability: 0.3
21Feb12_184807|-- Layer mutation probability: 0.3
21Feb12_184807|-- Constant hidden layers: False
21Feb12_184807|-- Seed: 31415
21Feb12_184807|Entering GA
21Feb12_184807|Start the algorithm
2021-02-12 18:48:07.403228: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-12 18:48:07.403771: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-02-12 18:48:07.426834: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-12 18:48:07.427157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.71GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s
2021-02-12 18:48:07.427171: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-02-12 18:48:07.428603: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-02-12 18:48:07.428631: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-02-12 18:48:07.429132: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-02-12 18:48:07.429258: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-02-12 18:48:07.429326: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-12 18:48:07.429726: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-02-12 18:48:07.429766: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-12 18:48:07.429771: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-02-12 18:48:07.429974: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-02-12 18:48:07.430716: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-12 18:48:07.430730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-12 18:48:07.430733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      
2021-02-12 18:48:07.475839: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-02-12 18:48:07.476176: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3493635000 Hz
/home/jmerelo/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype("int32")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn('`model.predict_classes()` is deprecated and '
21Feb12_185211|-- Generation 1 --
21Feb12_185211|    -- Crossed 1 individual pairs.
21Feb12_185211|    -- Mutated 32 individuals.
21Feb12_185616|    -- Evaluated 64 individuals.
21Feb12_185616|    Summary of generation 1:
21Feb12_185616| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_185616|-----------  ------------------  --------------------  ----------
21Feb12_185616|    Max            39.30                216.00          0.45341
21Feb12_185616|    Avg            38.67                58.47           0.00726
21Feb12_185616|    Min            25.74                 2.00           0.00000
21Feb12_185616|    Std             1.64                48.41           0.05623
21Feb12_185616|   Best            25.74                20.00           0.45341
21Feb12_185616|-- Generation 2 --
21Feb12_185616|    -- Crossed 1 individual pairs.
21Feb12_185616|    -- Mutated 32 individuals.
21Feb12_190020|    -- Evaluated 64 individuals.
21Feb12_190020|    Summary of generation 2:
21Feb12_190020| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_190020|-----------  ------------------  --------------------  ----------
21Feb12_190020|    Max            54.00                124.00          0.78218
21Feb12_190020|    Avg            38.49                46.89           0.04170
21Feb12_190020|    Min            26.00                 2.00           0.00000
21Feb12_190020|    Std             3.15                38.64           0.15925
21Feb12_190020|   Best            26.00                27.00           0.53340
21Feb12_190020|-- Generation 3 --
21Feb12_190020|    -- Crossed 2 individual pairs.
21Feb12_190020|    -- Mutated 32 individuals.
21Feb12_190420|    -- Evaluated 64 individuals.
21Feb12_190420|    Summary of generation 3:
21Feb12_190420| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_190420|-----------  ------------------  --------------------  ----------
21Feb12_190420|    Max            39.13                124.00          0.79526
21Feb12_190420|    Avg            38.34                27.12           0.02463
21Feb12_190420|    Min            23.83                 2.00           0.00000
21Feb12_190420|    Std             2.44                25.42           0.12742
21Feb12_190420|   Best            23.83                27.00           0.79526
21Feb12_190420|-- Generation 4 --
21Feb12_190420|    -- Crossed 2 individual pairs.
21Feb12_190420|    -- Mutated 32 individuals.
21Feb12_190815|    -- Evaluated 64 individuals.
21Feb12_190815|    Summary of generation 4:
21Feb12_190815| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_190815|-----------  ------------------  --------------------  ----------
21Feb12_190815|    Max            39.39                36.00           0.39683
21Feb12_190815|    Avg            38.61                13.09           0.00716
21Feb12_190815|    Min            26.52                 2.00           0.00000
21Feb12_190815|    Std             1.53                 9.14           0.04940
21Feb12_190815|   Best            26.52                10.00           0.39683
21Feb12_190815|-- Generation 5 --
21Feb12_190815|    -- Crossed 2 individual pairs.
21Feb12_190815|    -- Mutated 32 individuals.
21Feb12_191208|    -- Evaluated 64 individuals.
21Feb12_191208|    Summary of generation 5:
21Feb12_191208| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_191208|-----------  ------------------  --------------------  ----------
21Feb12_191208|    Max            39.65                30.00           0.82179
21Feb12_191208|    Avg            38.76                 7.77           0.01401
21Feb12_191208|    Min            35.30                 2.00           0.00000
21Feb12_191208|    Std             0.48                 5.81           0.10193
21Feb12_191208|   Best            35.30                 8.00           0.82179
21Feb12_191208|-- Generation 6 --
21Feb12_191208|    -- Crossed 9 individual pairs.
21Feb12_191208|    -- Mutated 32 individuals.
21Feb12_191559|    -- Evaluated 64 individuals.
21Feb12_191559|    Summary of generation 6:
21Feb12_191559| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_191559|-----------  ------------------  --------------------  ----------
21Feb12_191559|    Max            39.22                38.00           0.03330
21Feb12_191559|    Avg            38.79                 7.05           0.00113
21Feb12_191559|    Min            38.26                 2.00           0.00000
21Feb12_191559|    Std             0.14                 6.94           0.00529
21Feb12_191559|   Best            38.26                 4.00           0.01953
21Feb12_191559|-- Generation 7 --
21Feb12_191559|    -- Crossed 8 individual pairs.
21Feb12_191559|    -- Mutated 32 individuals.
21Feb12_191947|    -- Evaluated 64 individuals.
21Feb12_191947|    Summary of generation 7:
21Feb12_191947| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_191947|-----------  ------------------  --------------------  ----------
21Feb12_191947|    Max            39.22                18.00           0.03891
21Feb12_191947|    Avg            38.78                 5.06           0.00122
21Feb12_191947|    Min            37.65                 2.00           0.00000
21Feb12_191947|    Std             0.20                 4.47           0.00677
21Feb12_191947|   Best            37.65                14.00           0.03891
21Feb12_191947|-- Generation 8 --
21Feb12_191947|    -- Crossed 9 individual pairs.
21Feb12_191947|    -- Mutated 32 individuals.
21Feb12_192337|    -- Evaluated 64 individuals.
21Feb12_192337|    Summary of generation 8:
21Feb12_192337| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_192337|-----------  ------------------  --------------------  ----------
21Feb12_192337|    Max            39.13                40.00           0.31153
21Feb12_192337|    Avg            38.69                 5.09           0.00487
21Feb12_192337|    Min            31.48                 2.00           0.00000
21Feb12_192337|    Std             0.91                 6.04           0.03864
21Feb12_192337|   Best            31.48                14.00           0.31153
21Feb12_192337|-- Generation 9 --
21Feb12_192337|    -- Crossed 7 individual pairs.
21Feb12_192337|    -- Mutated 32 individuals.
21Feb12_192727|    -- Evaluated 64 individuals.
21Feb12_192727|    Summary of generation 9:
21Feb12_192727| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_192727|-----------  ------------------  --------------------  ----------
21Feb12_192727|    Max            39.57                16.00           0.49831
21Feb12_192727|    Avg            38.64                 4.33           0.00779
21Feb12_192727|    Min            27.57                 2.00           0.00000
21Feb12_192727|    Std             1.40                 4.16           0.06180
21Feb12_192727|   Best            27.57                10.00           0.49831
21Feb12_192727|-- Generation 10 --
21Feb12_192727|    -- Crossed 9 individual pairs.
21Feb12_192727|    -- Mutated 32 individuals.
21Feb12_193115|    -- Evaluated 64 individuals.
21Feb12_193115|    Summary of generation 10:
21Feb12_193115| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_193115|-----------  ------------------  --------------------  ----------
21Feb12_193115|    Max            39.13                14.00           0.75345
21Feb12_193115|    Avg            38.38                 3.88           0.01969
21Feb12_193115|    Min            24.35                 2.00           0.00000
21Feb12_193115|    Std             2.32                 3.65           0.11177
21Feb12_193115|   Best            24.35                10.00           0.75345
21Feb12_193115|-- Generation 11 --
21Feb12_193115|    -- Crossed 9 individual pairs.
21Feb12_193115|    -- Mutated 32 individuals.
21Feb12_193507|    -- Evaluated 64 individuals.
21Feb12_193507|    Summary of generation 11:
21Feb12_193507| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_193507|-----------  ------------------  --------------------  ----------
21Feb12_193507|    Max            39.04                16.00           0.78698
21Feb12_193507|    Avg            38.28                 4.41           0.02855
21Feb12_193507|    Min            25.74                 2.00           0.00000
21Feb12_193507|    Std             2.33                 4.25           0.13607
21Feb12_193507|   Best            25.74                 8.00           0.71616
21Feb12_193507|-- Generation 12 --
21Feb12_193507|    -- Crossed 6 individual pairs.
21Feb12_193507|    -- Mutated 32 individuals.
21Feb12_193855|    -- Evaluated 64 individuals.
21Feb12_193855|    Summary of generation 12:
21Feb12_193855| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_193855|-----------  ------------------  --------------------  ----------
21Feb12_193855|    Max            39.04                16.00           0.82875
21Feb12_193855|    Avg            38.27                 4.14           0.02813
21Feb12_193855|    Min            25.30                 2.00           0.00000
21Feb12_193855|    Std             2.43                 3.89           0.13161
21Feb12_193855|   Best            25.30                12.00           0.49877
21Feb12_193855|-- Generation 13 --
21Feb12_193855|    -- Crossed 6 individual pairs.
21Feb12_193855|    -- Mutated 32 individuals.
21Feb12_194244|    -- Evaluated 64 individuals.
21Feb12_194244|    Summary of generation 13:
21Feb12_194244| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_194244|-----------  ------------------  --------------------  ----------
21Feb12_194244|    Max            39.04                30.00           0.55163
21Feb12_194244|    Avg            38.05                 4.25           0.02922
21Feb12_194244|    Min            25.74                 2.00           0.00000
21Feb12_194244|    Std             2.90                 4.89           0.11420
21Feb12_194244|   Best            25.74                12.00           0.47170
21Feb12_194244|-- Generation 14 --
21Feb12_194244|    -- Crossed 5 individual pairs.
21Feb12_194244|    -- Mutated 32 individuals.
21Feb12_194634|    -- Evaluated 64 individuals.
21Feb12_194634|    Summary of generation 14:
21Feb12_194634| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_194634|-----------  ------------------  --------------------  ----------
21Feb12_194634|    Max            39.13                24.00           0.50220
21Feb12_194634|    Avg            38.41                 4.94           0.01510
21Feb12_194634|    Min            25.48                 2.00           0.00000
21Feb12_194634|    Std             2.07                 5.04           0.07780
21Feb12_194634|   Best            25.48                12.00           0.50220
21Feb12_194634|-- Generation 15 --
21Feb12_194634|    -- Crossed 7 individual pairs.
21Feb12_194634|    -- Mutated 32 individuals.
21Feb12_195023|    -- Evaluated 64 individuals.
21Feb12_195023|    Summary of generation 15:
21Feb12_195023| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_195023|-----------  ------------------  --------------------  ----------
21Feb12_195023|    Max            40.26                24.00           0.51400
21Feb12_195023|    Avg            38.22                 4.47           0.02526
21Feb12_195023|    Min            26.70                 2.00           0.00000
21Feb12_195023|    Std             2.54                 4.64           0.10255
21Feb12_195023|   Best            26.70                12.00           0.51232
21Feb12_195023|-- Generation 16 --
21Feb12_195023|    -- Crossed 6 individual pairs.
21Feb12_195023|    -- Mutated 32 individuals.
21Feb12_195412|    -- Evaluated 64 individuals.
21Feb12_195412|    Summary of generation 16:
21Feb12_195412| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_195412|-----------  ------------------  --------------------  ----------
21Feb12_195412|    Max            38.96                14.00           0.61078
21Feb12_195412|    Avg            37.81                 4.81           0.03810
21Feb12_195412|    Min            24.78                 2.00           0.00000
21Feb12_195412|    Std             3.38                 4.48           0.13300
21Feb12_195412|   Best            24.78                14.00           0.49827
21Feb12_195412|-- Generation 17 --
21Feb12_195412|    -- Crossed 5 individual pairs.
21Feb12_195412|    -- Mutated 32 individuals.
21Feb12_195802|    -- Evaluated 64 individuals.
21Feb12_195802|    Summary of generation 17:
21Feb12_195802| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_195802|-----------  ------------------  --------------------  ----------
21Feb12_195802|    Max            38.87                24.00           0.56501
21Feb12_195802|    Avg            37.86                 5.12           0.03852
21Feb12_195802|    Min            26.00                 2.00           0.00000
21Feb12_195802|    Std             3.19                 5.02           0.13522
21Feb12_195802|   Best            26.00                12.00           0.54093
21Feb12_195802|-- Generation 18 --
21Feb12_195802|    -- Crossed 6 individual pairs.
21Feb12_195802|    -- Mutated 32 individuals.
21Feb12_200151|    -- Evaluated 64 individuals.
21Feb12_200151|    Summary of generation 18:
21Feb12_200151| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_200151|-----------  ------------------  --------------------  ----------
21Feb12_200151|    Max            39.13                16.00           0.54067
21Feb12_200151|    Avg            37.87                 4.77           0.03758
21Feb12_200151|    Min            25.48                 2.00           0.00000
21Feb12_200151|    Std             3.23                 4.66           0.12869
21Feb12_200151|   Best            25.48                12.00           0.53304
21Feb12_200151|-- Generation 19 --
21Feb12_200151|    -- Crossed 8 individual pairs.
21Feb12_200151|    -- Mutated 32 individuals.
21Feb12_200543|    -- Evaluated 64 individuals.
21Feb12_200543|    Summary of generation 19:
21Feb12_200543| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_200543|-----------  ------------------  --------------------  ----------
21Feb12_200543|    Max            39.22                33.00           0.56448
21Feb12_200543|    Avg            37.87                 5.44           0.03871
21Feb12_200543|    Min            26.00                 2.00           0.00000
21Feb12_200543|    Std             3.26                 5.81           0.13424
21Feb12_200543|   Best            26.00                12.00           0.48697
21Feb12_200543|-- Generation 20 --
21Feb12_200543|    -- Crossed 8 individual pairs.
21Feb12_200543|    -- Mutated 32 individuals.
21Feb12_200933|    -- Evaluated 64 individuals.
21Feb12_200933|    Summary of generation 20:
21Feb12_200933| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_200933|-----------  ------------------  --------------------  ----------
21Feb12_200933|    Max            39.04                18.00           0.55582
21Feb12_200933|    Avg            37.97                 4.88           0.03410
21Feb12_200933|    Min            26.00                 2.00           0.00000
21Feb12_200933|    Std             3.02                 4.63           0.12319
21Feb12_200933|   Best            26.00                12.00           0.55582
21Feb12_200933|-- Generation 21 --
21Feb12_200933|    -- Crossed 10 individual pairs.
21Feb12_200933|    -- Mutated 32 individuals.
21Feb12_201323|    -- Evaluated 64 individuals.
21Feb12_201323|    Summary of generation 21:
21Feb12_201323| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_201323|-----------  ------------------  --------------------  ----------
21Feb12_201323|    Max            39.22                14.00           0.54606
21Feb12_201323|    Avg            38.03                 4.30           0.03103
21Feb12_201323|    Min            26.17                 2.00           0.00000
21Feb12_201323|    Std             2.99                 4.01           0.12045
21Feb12_201323|   Best            26.17                12.00           0.46852
21Feb12_201323|-- Generation 22 --
21Feb12_201323|    -- Crossed 9 individual pairs.
21Feb12_201323|    -- Mutated 32 individuals.
21Feb12_201714|    -- Evaluated 64 individuals.
21Feb12_201714|    Summary of generation 22:
21Feb12_201714| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_201714|-----------  ------------------  --------------------  ----------
21Feb12_201714|    Max            39.13                14.00           0.54363
21Feb12_201714|    Avg            37.87                 4.97           0.03649
21Feb12_201714|    Min            26.35                 2.00           0.00000
21Feb12_201714|    Std             3.17                 4.61           0.12651
21Feb12_201714|   Best            26.35                12.00           0.54363
21Feb12_201714|-- Generation 23 --
21Feb12_201714|    -- Crossed 7 individual pairs.
21Feb12_201714|    -- Mutated 32 individuals.
21Feb12_202105|    -- Evaluated 64 individuals.
21Feb12_202105|    Summary of generation 23:
21Feb12_202105| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_202105|-----------  ------------------  --------------------  ----------
21Feb12_202105|    Max            39.30                33.00           0.56626
21Feb12_202105|    Avg            38.06                 5.91           0.03098
21Feb12_202105|    Min            26.52                 2.00           0.00000
21Feb12_202105|    Std             2.85                 7.05           0.12025
21Feb12_202105|   Best            26.52                14.00           0.44110
21Feb12_202105|-- Generation 24 --
21Feb12_202105|    -- Crossed 8 individual pairs.
21Feb12_202105|    -- Mutated 32 individuals.
21Feb12_202456|    -- Evaluated 64 individuals.
21Feb12_202456|    Summary of generation 24:
21Feb12_202456| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_202456|-----------  ------------------  --------------------  ----------
21Feb12_202456|    Max            38.96                39.00           0.55714
21Feb12_202456|    Avg            38.42                 4.88           0.01501
21Feb12_202456|    Min            26.17                 2.00           0.00000
21Feb12_202456|    Std             2.09                 6.00           0.08466
21Feb12_202456|   Best            26.17                12.00           0.55714
21Feb12_202456|-- Generation 25 --
21Feb12_202456|    -- Crossed 8 individual pairs.
21Feb12_202456|    -- Mutated 32 individuals.
21Feb12_202845|    -- Evaluated 64 individuals.
21Feb12_202845|    Summary of generation 25:
21Feb12_202845| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_202845|-----------  ------------------  --------------------  ----------
21Feb12_202845|    Max            38.96                16.00           0.52987
21Feb12_202845|    Avg            38.16                 3.94           0.02536
21Feb12_202845|    Min            25.91                 2.00           0.00000
21Feb12_202845|    Std             2.64                 3.91           0.10528
21Feb12_202845|   Best            25.91                12.00           0.46720
21Feb12_202845|-- Generation 26 --
21Feb12_202845|    -- Crossed 6 individual pairs.
21Feb12_202845|    -- Mutated 32 individuals.
21Feb12_203235|    -- Evaluated 64 individuals.
21Feb12_203235|    Summary of generation 26:
21Feb12_203235| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_203235|-----------  ------------------  --------------------  ----------
21Feb12_203235|    Max            39.30                27.00           0.51607
21Feb12_203235|    Avg            37.83                 5.05           0.03924
21Feb12_203235|    Min            25.39                 2.00           0.00000
21Feb12_203235|    Std             3.18                 5.24           0.12154
21Feb12_203235|   Best            25.39                12.00           0.51607
21Feb12_203235|-- Generation 27 --
21Feb12_203235|    -- Crossed 8 individual pairs.
21Feb12_203235|    -- Mutated 32 individuals.
21Feb12_203625|    -- Evaluated 64 individuals.
21Feb12_203625|    Summary of generation 27:
21Feb12_203625| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_203625|-----------  ------------------  --------------------  ----------
21Feb12_203625|    Max            39.13                16.00           0.57801
21Feb12_203625|    Avg            38.04                 4.39           0.03150
21Feb12_203625|    Min            25.57                 2.00           0.00000
21Feb12_203625|    Std             2.84                 4.06           0.12108
21Feb12_203625|   Best            25.57                12.00           0.54598
21Feb12_203625|-- Generation 28 --
21Feb12_203625|    -- Crossed 5 individual pairs.
21Feb12_203625|    -- Mutated 32 individuals.
21Feb12_204015|    -- Evaluated 64 individuals.
21Feb12_204015|    Summary of generation 28:
21Feb12_204015| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_204015|-----------  ------------------  --------------------  ----------
21Feb12_204015|    Max            39.04                33.00           0.61111
21Feb12_204015|    Avg            38.01                 4.78           0.03193
21Feb12_204015|    Min            25.57                 2.00           0.00000
21Feb12_204015|    Std             2.94                 5.36           0.12172
21Feb12_204015|   Best            25.57                12.00           0.61111
21Feb12_204015|-- Generation 29 --
21Feb12_204015|    -- Crossed 6 individual pairs.
21Feb12_204015|    -- Mutated 32 individuals.
21Feb12_204405|    -- Evaluated 64 individuals.
21Feb12_204405|    Summary of generation 29:
21Feb12_204405| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_204405|-----------  ------------------  --------------------  ----------
21Feb12_204405|    Max            39.39                16.00           0.54306
21Feb12_204405|    Avg            38.01                 4.42           0.03397
21Feb12_204405|    Min            25.39                 2.00           0.00000
21Feb12_204405|    Std             2.80                 4.30           0.11881
21Feb12_204405|   Best            25.39                12.00           0.52950
21Feb12_204405|-- Generation 30 --
21Feb12_204405|    -- Crossed 5 individual pairs.
21Feb12_204405|    -- Mutated 32 individuals.
21Feb12_204755|    -- Evaluated 64 individuals.
21Feb12_204755|    Summary of generation 30:
21Feb12_204755| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_204755|-----------  ------------------  --------------------  ----------
21Feb12_204755|    Max            39.13                33.00           0.53699
21Feb12_204755|    Avg            38.02                 4.67           0.03163
21Feb12_204755|    Min            26.35                 2.00           0.00000
21Feb12_204755|    Std             2.95                 5.23           0.12004
21Feb12_204755|   Best            26.35                12.00           0.44155
21Feb12_204755|-- Generation 31 --
21Feb12_204755|    -- Crossed 5 individual pairs.
21Feb12_204755|    -- Mutated 32 individuals.
21Feb12_205145|    -- Evaluated 64 individuals.
21Feb12_205145|    Summary of generation 31:
21Feb12_205145| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_205145|-----------  ------------------  --------------------  ----------
21Feb12_205145|    Max            39.30                14.00           0.75707
21Feb12_205145|    Avg            37.67                 4.48           0.05218
21Feb12_205145|    Min            25.13                 2.00           0.00000
21Feb12_205145|    Std             3.52                 4.05           0.16549
21Feb12_205145|   Best            25.13                12.00           0.52453
21Feb12_205145|-- Generation 32 --
21Feb12_205145|    -- Crossed 2 individual pairs.
21Feb12_205145|    -- Mutated 32 individuals.
21Feb12_205534|    -- Evaluated 64 individuals.
21Feb12_205534|    Summary of generation 32:
21Feb12_205534| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_205534|-----------  ------------------  --------------------  ----------
21Feb12_205534|    Max            39.22                14.00           0.69166
21Feb12_205534|    Avg            37.53                 4.58           0.05596
21Feb12_205534|    Min            24.61                 2.00           0.00000
21Feb12_205534|    Std             3.76                 4.23           0.16392
21Feb12_205534|   Best            24.61                10.00           0.69166
21Feb12_205534|Best initial individual weights
21Feb12_205534|Individual:
21Feb12_205534|-- Constant hidden layers --
21Feb12_205534|False
21Feb12_205534|Layer 0:
21Feb12_205534|-- Config --
21Feb12_205534|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 13, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205534|-- Weights --
21Feb12_205534|[[-3.35216e-01  1.77085e-02  6.79611e-01  6.68636e-01 -3.61662e-01
21Feb12_205534|   5.66337e-01 -9.75792e-02 -1.35422e-01 -3.58882e-01  3.66696e-01
21Feb12_205534|  -1.88192e-02  4.76781e-01 -7.09256e-01]
21Feb12_205534| [-9.58712e-02  4.55012e-01  6.14585e-01  8.91791e-02  4.40034e-01
21Feb12_205534|  -2.61391e-01 -4.84596e-01  7.82871e-01  1.87888e-01  3.44537e-01
21Feb12_205534|   5.83634e-01 -1.19899e-01 -4.37449e-01]
21Feb12_205534| [-1.32649e-01 -8.67571e-02  1.25134e-01  1.19478e-01 -5.49504e-01
21Feb12_205534|   6.10219e-01  8.19590e-01 -6.15476e-01 -8.11023e-01  5.32909e-01
21Feb12_205534|  -2.12569e-02 -5.44002e-02 -2.33461e-01]
21Feb12_205534| [-3.45866e-01  1.66123e-01 -7.37427e-01 -5.51962e-01  2.47538e-01
21Feb12_205534|  -6.79750e-01 -6.42964e-01 -9.60408e-01  5.73911e-01 -4.98255e-01
21Feb12_205534|   1.28886e-01  8.88131e-01 -7.05440e-01]
21Feb12_205534| [ 7.22076e-01  8.84720e-01  3.87267e-01  8.64299e-01  3.32696e-01
21Feb12_205534|   6.70985e-01 -6.78471e-01  7.87958e-01  8.62949e-01 -7.50182e-01
21Feb12_205534|   8.55630e-01 -5.47134e-01  2.07222e-01]
21Feb12_205534| [ 3.29988e-01 -3.62330e-01 -3.43756e-01  1.44305e-01 -8.16652e-01
21Feb12_205534|   5.80651e-01  7.29988e-01  7.39789e-01 -3.48876e-02  2.93857e-01
21Feb12_205534|   4.44302e-01  8.87793e-02  2.61327e-01]
21Feb12_205534| [-2.76543e-01 -3.97484e-01  8.73317e-02  8.77409e-01  4.89771e-03
21Feb12_205534|   4.43258e-01 -7.47575e-01 -6.14586e-01 -9.88238e-01  9.49731e-01
21Feb12_205534|   8.95811e-01  8.10143e-01 -7.72138e-01]
21Feb12_205534| [-9.27956e-01  4.00484e-01 -7.47822e-01  2.22792e-01  9.85495e-01
21Feb12_205534|  -3.12237e-01 -8.02710e-01 -5.95312e-01 -4.98626e-01 -1.66344e-01
21Feb12_205534|  -1.57277e-01  9.77154e-01 -1.21622e-01]
21Feb12_205534| [ 6.18732e-01 -8.44337e-01 -7.51044e-01  6.89190e-02  8.78380e-02
21Feb12_205534|  -1.07674e-01 -2.98230e-01 -8.76784e-01 -2.28399e-01 -2.72677e-01
21Feb12_205534|   6.43910e-01 -1.42606e-01 -5.79210e-01]
21Feb12_205534| [-7.11440e-01  3.25965e-01  8.22166e-01  4.59491e-01  2.09940e-01
21Feb12_205534|  -6.31232e-01  8.42649e-01 -9.14417e-01 -9.73984e-01  5.99903e-01
21Feb12_205534|  -8.51707e-01 -5.32403e-01 -3.82747e-01]
21Feb12_205534| [-9.94633e-01 -7.07646e-02 -2.94889e-01 -2.03723e-01  9.62482e-01
21Feb12_205534|   6.42699e-01  5.80090e-01  6.04523e-01 -5.54924e-01  4.79483e-01
21Feb12_205534|   5.68350e-01 -9.22214e-01  5.12824e-01]
21Feb12_205534| [-5.83790e-01 -3.26744e-01  9.55212e-01  4.29883e-01  5.37900e-01
21Feb12_205534|  -9.12688e-01 -4.26381e-02  5.80662e-01 -4.28608e-01 -1.18473e-01
21Feb12_205534|   3.75690e-01 -9.49167e-01 -9.08607e-01]
21Feb12_205534| [-5.46447e-01 -6.77458e-02 -1.44951e-01  5.29709e-01 -1.07834e-01
21Feb12_205534|   4.93564e-01  9.82266e-01 -6.36342e-01  1.97248e-01 -5.71028e-01
21Feb12_205534|  -8.11583e-01  2.92628e-02  4.52940e-01]
21Feb12_205534| [ 9.77814e-01 -7.99617e-01 -5.58166e-01 -1.80095e-01 -8.66635e-01
21Feb12_205534|  -6.80320e-01 -4.74803e-01  2.34608e-02 -9.82075e-01 -2.38111e-01
21Feb12_205534|   2.01833e-01 -8.76299e-01  2.59627e-01]
21Feb12_205534| [ 1.76551e-01 -3.73047e-01  4.35970e-01  5.57839e-02  3.93409e-01
21Feb12_205534|   9.07679e-02  5.05241e-01 -1.09637e-02 -9.21220e-01  2.95212e-01
21Feb12_205534|  -9.49916e-01 -9.57770e-01 -9.31967e-01]
21Feb12_205534| [ 1.83014e-01 -9.36919e-01 -3.17298e-01 -3.47119e-01 -2.63698e-01
21Feb12_205534|  -1.81507e-01  2.73046e-01 -4.59597e-01  4.91071e-01 -6.40921e-01
21Feb12_205534|  -2.73807e-02  5.84633e-01 -2.46656e-01]
21Feb12_205534| [-3.65437e-01  5.89569e-01 -6.75411e-01 -3.01070e-02 -1.27350e-01
21Feb12_205534|  -3.71158e-01  4.84881e-01  4.48336e-01 -6.37471e-01  3.96452e-01
21Feb12_205534|   1.95237e-01  6.60166e-01 -7.83858e-01]
21Feb12_205534| [-6.73724e-01 -5.10809e-01  5.92987e-01  9.16720e-02  7.51109e-01
21Feb12_205534|  -7.52811e-01 -8.20827e-01  5.09835e-01 -9.80894e-01 -5.23721e-01
21Feb12_205534|   4.40847e-01  8.88159e-01  9.59957e-01]
21Feb12_205534| [-3.25186e-01  8.66935e-01  9.52328e-01  2.64629e-01 -6.39066e-01
21Feb12_205534|   8.43060e-01  7.62274e-01 -2.88168e-01 -9.64702e-01  7.47831e-01
21Feb12_205534|  -6.91297e-01  5.99679e-01  3.35403e-01]
21Feb12_205534| [-7.67770e-02 -7.84908e-01 -7.83004e-01  4.21981e-01  7.30720e-01
21Feb12_205534|   6.93636e-01  9.99907e-01  9.95509e-01  1.43034e-01  8.40670e-01
21Feb12_205534|   9.24805e-01  4.06251e-01 -3.57110e-01]
21Feb12_205534| [-3.24114e-01  2.25176e-01  9.68287e-01 -5.66095e-01  8.16438e-01
21Feb12_205534|  -5.31133e-01  4.23432e-01 -8.10889e-01 -3.84444e-03  1.66561e-01
21Feb12_205534|   8.45692e-01 -9.77516e-01  8.43990e-01]
21Feb12_205534| [-3.50839e-01  1.74294e-01 -4.56400e-02  1.78864e-01  6.49254e-01
21Feb12_205534|  -2.90945e-02  6.29257e-01 -7.99652e-01 -5.58575e-01 -1.96274e-01
21Feb12_205534|   7.66505e-01 -1.21990e-01  2.18726e-01]
21Feb12_205534| [-7.32881e-01  1.16489e-01  1.87470e-01 -1.21519e-01 -1.84417e-01
21Feb12_205534|  -9.94493e-01  7.92852e-02  3.53753e-01  9.98931e-01  7.11592e-01
21Feb12_205534|  -5.08161e-01  6.49530e-02 -3.91453e-02]
21Feb12_205534| [ 8.48354e-01 -3.34305e-01 -7.47080e-01  4.93175e-01 -8.65947e-01
21Feb12_205534|   2.05180e-02  7.09667e-01  7.72239e-01  2.15912e-01 -9.78612e-01
21Feb12_205534|  -5.00483e-01 -9.46311e-01 -2.33536e-02]
21Feb12_205534| [ 7.14698e-01  7.79323e-01  4.05848e-01  7.77423e-01  4.50259e-01
21Feb12_205534|  -2.58296e-01 -3.97384e-01  6.61765e-01  6.28629e-01 -8.91316e-01
21Feb12_205534|   6.87779e-01  6.54539e-02 -4.62903e-01]
21Feb12_205534| [-7.52007e-01 -4.59390e-01 -5.98021e-01 -3.65632e-01 -5.21028e-01
21Feb12_205534|   9.46471e-01 -8.71887e-03 -2.49639e-02  4.50431e-01 -1.04025e-01
21Feb12_205534|  -1.65010e-01 -3.83941e-01  5.05423e-01]
21Feb12_205534| [ 2.50451e-01 -8.69370e-01  3.71084e-02  1.78525e-01  5.67997e-01
21Feb12_205534|  -1.97005e-01  2.44287e-01  9.69897e-03 -3.09870e-02  6.74496e-01
21Feb12_205534|  -9.66175e-01  6.27677e-02 -3.06654e-01]
21Feb12_205534| [-7.77649e-01  6.36121e-01 -3.66278e-01  3.34008e-01 -8.51748e-01
21Feb12_205534|   4.38459e-01  4.31986e-01  8.92340e-01  3.69048e-01 -7.07799e-01
21Feb12_205534|   8.03708e-01 -9.75596e-01 -4.33077e-01]
21Feb12_205534| [-9.44069e-01 -4.58312e-01  9.32621e-01  6.80726e-01 -2.97152e-01
21Feb12_205534|   7.40577e-01 -5.18680e-01 -1.78645e-01  4.80035e-01 -1.56707e-01
21Feb12_205534|   7.45548e-01  2.74502e-01 -8.20642e-01]
21Feb12_205534| [ 6.49593e-01 -2.98673e-01  3.73022e-02  7.56753e-01 -1.35669e-01
21Feb12_205534|  -7.57645e-01  9.63181e-01 -5.38087e-01 -8.41132e-01 -2.67909e-01
21Feb12_205534|  -6.66494e-01  1.93293e-02 -8.91503e-01]
21Feb12_205534| [-4.25475e-01  6.01710e-01 -6.80030e-02 -6.98296e-01 -5.55939e-01
21Feb12_205534|  -1.78659e-01 -2.39546e-01 -5.11306e-01 -4.03372e-01 -5.22981e-01
21Feb12_205534|  -1.56524e-01 -2.38902e-01  7.61647e-01]
21Feb12_205534| [ 9.53089e-01 -1.54487e-01  2.01542e-01  1.96710e-01  5.78494e-01
21Feb12_205534|  -4.38912e-01  4.52768e-01 -9.35045e-01 -1.00893e-02 -3.62324e-01
21Feb12_205534|  -4.09252e-01  6.05347e-01  9.51883e-01]
21Feb12_205534| [-9.88679e-01  5.48545e-02  6.76296e-02  4.24200e-01  7.49465e-01
21Feb12_205534|   7.74195e-01  1.60496e-01 -3.62491e-01 -4.78179e-01  9.89412e-01
21Feb12_205534|   8.38722e-01 -6.54862e-01  3.03408e-01]
21Feb12_205534| [-7.53623e-01  2.18981e-01 -9.49430e-01  5.79443e-01  8.59097e-01
21Feb12_205534|   4.86733e-01  2.99617e-01 -9.09526e-01 -2.03969e-01  9.54964e-01
21Feb12_205534|  -8.59950e-01  7.07660e-01 -3.08462e-02]
21Feb12_205534| [ 2.74881e-01  3.80330e-01 -9.68651e-01 -6.10729e-01  3.10904e-01
21Feb12_205534|   9.21590e-01 -9.49651e-01 -5.50235e-01  8.10252e-01 -7.81839e-01
21Feb12_205534|   9.24314e-01  5.86103e-01 -1.54154e-01]
21Feb12_205534| [-5.02576e-01 -2.98235e-01 -2.73364e-01  2.15299e-01 -6.02768e-01
21Feb12_205534|  -5.76591e-01 -4.80649e-01 -1.01036e-01  7.38598e-01  5.07654e-01
21Feb12_205534|  -5.12055e-01 -5.03978e-01  7.29497e-01]
21Feb12_205534| [-1.42784e-01  7.78315e-01 -9.28438e-01 -7.83858e-01 -8.16677e-01
21Feb12_205534|  -4.29997e-02 -5.82463e-01  4.42266e-01  6.03235e-01 -6.08868e-01
21Feb12_205534|  -6.60784e-01 -2.27240e-01 -2.78813e-01]
21Feb12_205534| [ 4.38617e-01 -3.43642e-02 -6.45968e-01  3.62000e-02 -3.98176e-01
21Feb12_205534|  -3.76388e-01  8.35416e-01  3.52542e-01 -1.14950e-01  7.75966e-01
21Feb12_205534|  -5.53691e-01  9.87785e-01  5.42626e-01]
21Feb12_205534| [-8.34990e-01 -4.84977e-01 -9.09943e-01  7.93465e-01  3.32972e-02
21Feb12_205534|  -7.10662e-01  9.31656e-01 -2.15511e-02 -5.22553e-01 -3.13618e-01
21Feb12_205534|   9.22100e-01 -1.64245e-01  9.88653e-01]
21Feb12_205534| [-8.46090e-01 -5.55350e-01 -7.14656e-01  2.46226e-01 -4.79760e-01
21Feb12_205534|  -5.94006e-01  1.01509e-01 -4.82339e-01 -1.42256e-01 -3.75208e-01
21Feb12_205534|  -7.66757e-01  8.50132e-01  2.85013e-01]
21Feb12_205534| [-3.59827e-01  1.39363e-01 -7.17877e-01  8.87613e-01 -2.32150e-01
21Feb12_205534|  -6.87057e-01  6.10625e-01  9.56381e-01  6.58247e-01  3.12955e-01
21Feb12_205534|  -8.80523e-01  4.49070e-01 -6.42939e-01]
21Feb12_205534| [ 2.65487e-01  8.24650e-01 -3.41572e-01 -2.48876e-01  1.70562e-02
21Feb12_205534|  -7.71669e-03 -6.38097e-01 -2.23333e-01 -3.62627e-01  8.21718e-01
21Feb12_205534|   2.00872e-03  1.26525e-01  7.09599e-02]
21Feb12_205534| [ 5.19267e-01  1.31197e-01 -2.41231e-01 -3.87914e-01 -2.18229e-01
21Feb12_205534|   5.73972e-01 -9.60199e-01  9.50486e-01 -3.00428e-01 -7.38959e-01
21Feb12_205534|  -4.49184e-01  7.71433e-01 -9.63563e-01]
21Feb12_205534| [ 8.00110e-01  4.48639e-01 -6.90239e-01  9.55821e-02  6.79646e-01
21Feb12_205534|  -5.14350e-02  4.90053e-01 -6.56391e-01  3.29723e-01  9.00275e-01
21Feb12_205534|  -3.96792e-01  3.56357e-01 -8.00013e-01]
21Feb12_205534| [ 3.25137e-01  5.26828e-01  5.10735e-01 -4.26025e-01  9.81843e-01
21Feb12_205534|   3.55965e-01 -3.90845e-01  5.38692e-01 -1.16433e-01 -2.52418e-01
21Feb12_205534|   9.46756e-01 -8.08352e-01  2.30867e-01]
21Feb12_205534| [-3.96445e-01 -8.03265e-01 -9.17516e-01  9.38920e-01 -7.48120e-02
21Feb12_205534|  -1.85405e-01  6.73338e-01  3.57454e-01  6.97862e-01  8.58625e-01
21Feb12_205534|   4.18734e-01  1.13043e-01  3.33847e-01]
21Feb12_205534| [-7.80470e-01 -3.64632e-02 -4.46042e-01  7.96976e-01 -3.66568e-01
21Feb12_205534|  -7.14404e-01  6.69366e-01 -6.55585e-01 -3.61849e-01 -3.68379e-01
21Feb12_205534|  -4.37108e-01  1.16024e-01 -4.30308e-01]
21Feb12_205534| [ 5.82175e-01 -7.20120e-01  9.06640e-01 -6.77078e-01 -1.72794e-01
21Feb12_205534|   1.40986e-01  2.19744e-01  8.35221e-01 -5.47923e-01 -3.79896e-02
21Feb12_205534|  -6.21995e-01  9.02526e-01  1.55887e-01]
21Feb12_205534| [ 9.08157e-01  7.34370e-01  6.94618e-01  5.68591e-02  5.89644e-01
21Feb12_205534|   1.36860e-01  8.03393e-02  9.10163e-01  8.91741e-01  6.03366e-01
21Feb12_205534|  -2.88164e-01  1.08317e-01  9.52304e-01]
21Feb12_205534| [ 7.36632e-01 -6.30215e-01  9.34561e-01  9.46390e-01 -5.30521e-01
21Feb12_205534|   7.12781e-01  3.23855e-01 -8.37502e-01  1.35794e-01  2.23308e-01
21Feb12_205534|  -1.59215e-01  4.90437e-01  4.46543e-01]
21Feb12_205534| [-6.57299e-01 -1.28478e-02 -7.11023e-01  2.78917e-01 -1.04497e-01
21Feb12_205534|  -2.76062e-02  5.15905e-01 -1.34695e-02 -3.25637e-01  2.84224e-01
21Feb12_205534|  -5.83082e-01  6.78038e-01 -7.43466e-02]
21Feb12_205534| [-2.45709e-01 -4.91273e-01 -7.42669e-02 -4.56918e-01 -4.52283e-01
21Feb12_205534|   1.27291e-01  1.43670e-01 -2.42089e-01 -2.67649e-01  6.44569e-02
21Feb12_205534|  -4.29618e-01  6.26073e-01  4.34533e-01]
21Feb12_205534| [ 5.16492e-01  5.44271e-01  3.73994e-01  1.53139e-01 -5.62854e-01
21Feb12_205534|   7.40829e-01 -5.87725e-01  1.51149e-01  4.36481e-01 -8.84680e-02
21Feb12_205534|  -8.09964e-01  5.25047e-01  8.82817e-01]
21Feb12_205534| [-1.65745e-01  7.02311e-01  5.73706e-01  4.67703e-01  9.46266e-02
21Feb12_205534|   1.30539e-01  9.09564e-01 -4.25101e-01  8.67959e-01  2.44065e-01
21Feb12_205534|  -9.72136e-01 -3.21541e-01  8.30678e-02]
21Feb12_205534| [ 2.26360e-02  2.23294e-01  3.71638e-01  7.25866e-02  1.36455e-01
21Feb12_205534|   7.97139e-01 -2.60035e-01 -7.94375e-01  5.86071e-01  5.69726e-01
21Feb12_205534|   6.21920e-01  8.69922e-01  1.42360e-01]
21Feb12_205534| [ 4.36028e-01  7.56749e-01  9.32476e-01 -4.83169e-01 -7.12290e-01
21Feb12_205534|   3.18660e-02 -6.43899e-01  6.90933e-01 -6.16299e-02  9.24304e-01
21Feb12_205534|   1.50224e-01  3.59796e-01  8.29958e-01]
21Feb12_205534| [ 6.83671e-01  5.10543e-02 -1.57858e-01 -5.64330e-01  8.24621e-02
21Feb12_205534|  -3.68593e-01  7.67558e-01 -9.05650e-01  3.34001e-04 -9.91643e-01
21Feb12_205534|   2.95397e-01  2.55066e-01 -5.17419e-01]]
21Feb12_205534|-- Bias --
21Feb12_205534|[-0.70517 -0.01886 -0.11929  0.64783  0.48281  0.30871  0.84613 -0.02242
21Feb12_205534|  0.53312 -0.14420  0.48094  0.51442  0.50581]
21Feb12_205534|Layer 1:
21Feb12_205534|-- Config --
21Feb12_205534|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 13], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205534|-- Weights --
21Feb12_205534|[[-0.44507  0.91413 -0.11497  0.93905]
21Feb12_205534| [ 0.25796  0.67494 -0.54775 -0.73702]
21Feb12_205534| [-0.27116 -0.77277 -0.19515 -0.13726]
21Feb12_205534| [ 0.80166 -0.32115  0.34523  0.85819]
21Feb12_205534| [-0.32994  0.56359  0.43967  0.86074]
21Feb12_205534| [-0.10119  0.55985  0.80432  0.03107]
21Feb12_205534| [-0.91438  0.67683 -0.21181  0.69223]
21Feb12_205534| [ 0.45769 -0.50244 -0.92505  0.61252]
21Feb12_205534| [-0.95625 -0.86838  0.22496 -0.82488]
21Feb12_205534| [ 0.06234 -0.01083 -0.56257  0.55865]
21Feb12_205534| [ 0.83603 -0.51215  0.26576  0.55736]
21Feb12_205534| [-0.61217 -0.95776  0.82681  0.87634]
21Feb12_205534| [ 0.91154 -0.23553  0.16371 -0.33176]]
21Feb12_205534|-- Bias --
21Feb12_205534|[0.70061 0.66413 0.98309 0.01569]
21Feb12_205534|Layer 2:
21Feb12_205534|-- Config --
21Feb12_205534|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 16, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205534|-- Weights --
21Feb12_205534|[[ 0.00465  0.85080  0.84638  0.70351  0.32222  0.32448 -0.60794  0.66180
21Feb12_205534|  -0.48299 -0.61133  0.78161  0.67968 -0.34614 -0.59312  0.36133  0.96176]
21Feb12_205534| [-0.82663 -0.64514 -0.61359  0.32931 -0.72784 -0.46464  0.08385  0.64909
21Feb12_205534|  -0.15183  0.64171  0.32983 -0.00699 -0.62514  0.38218  0.23054  0.83663]
21Feb12_205534| [ 0.55150  0.21556  0.21944  0.94713 -0.93000 -0.23569  0.39923  0.84815
21Feb12_205534|   0.07815 -0.75462  0.03258  0.13305  0.53376  0.56452 -0.17376 -0.13662]
21Feb12_205534| [-0.65302  0.88041 -0.68880  0.68353 -0.32913 -0.88204 -0.07065 -0.13287
21Feb12_205534|  -0.23846  0.08677  0.22903  0.46418 -0.37024 -0.12520  0.87076 -0.76709]]
21Feb12_205534|-- Bias --
21Feb12_205534|[-0.77935  0.73956  0.45759 -0.58608 -0.45191  0.85618 -0.39266 -0.75230
21Feb12_205534| -0.13304 -0.07502 -0.29174 -0.90958 -0.56025 -0.06425  0.49558  0.00723]
21Feb12_205534|Layer 3:
21Feb12_205534|-- Config --
21Feb12_205534|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 16], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205534|-- Weights --
21Feb12_205534|[[-0.11392 -0.56518]
21Feb12_205534| [ 0.56138 -0.18056]
21Feb12_205534| [ 0.60187 -0.14449]
21Feb12_205534| [-0.67417  0.29692]
21Feb12_205534| [ 0.88924  0.33889]
21Feb12_205534| [-0.07451 -0.09709]
21Feb12_205534| [ 0.32373 -0.00446]
21Feb12_205534| [ 0.70840 -0.75260]
21Feb12_205534| [-0.65738  0.10021]
21Feb12_205534| [ 0.50796 -0.25870]
21Feb12_205534| [ 0.48773 -0.88918]
21Feb12_205534| [-0.76147 -0.85257]
21Feb12_205534| [-0.11458  0.03831]
21Feb12_205534| [-0.11905 -0.84168]
21Feb12_205534| [ 0.35092 -0.91366]
21Feb12_205534| [ 0.84742  0.70400]]
21Feb12_205534|-- Bias --
21Feb12_205534|[0.17159 0.58867]
21Feb12_205534|Predicting the validation and test data with the Best initial individual.
21Feb12_205542| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_205542|-----------  ------------------  --------------------  ----------
21Feb12_205542|Validation         38.87                  99            0.00000
21Feb12_205542|   Test            39.01                  99            0.00000
21Feb12_205542|-------------------- Test #0 --------------------
21Feb12_205542|Best final individual weights
21Feb12_205542|Individual:
21Feb12_205542|-- Constant hidden layers --
21Feb12_205542|False
21Feb12_205542|Layer 0:
21Feb12_205542|-- Config --
21Feb12_205542|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205542|-- Weights --
21Feb12_205542|[[ 1.38403e+00  2.28864e-01]
21Feb12_205542| [ 6.34793e-02  1.17249e+00]
21Feb12_205542| [-5.52130e-01 -1.48663e-01]
21Feb12_205542| [ 2.68391e-01  1.34056e+00]
21Feb12_205542| [ 1.71588e+00  1.54148e-01]
21Feb12_205542| [-6.76487e-01 -8.12632e-01]
21Feb12_205542| [-3.36077e-01  8.37814e-01]
21Feb12_205542| [-2.76932e+00  6.48499e-01]
21Feb12_205542| [ 7.03962e-01  1.39837e+00]
21Feb12_205542| [-7.94729e-01  1.53931e+00]
21Feb12_205542| [ 5.14315e-01 -5.46938e-01]
21Feb12_205542| [ 8.51602e-01 -1.17766e+00]
21Feb12_205542| [-9.85517e-01 -2.02046e-01]
21Feb12_205542| [ 3.57173e-01 -2.36309e-01]
21Feb12_205542| [ 7.72289e-01 -1.26733e-01]
21Feb12_205542| [ 7.81051e-01 -1.61717e-01]
21Feb12_205542| [ 7.70356e-01 -2.27992e-02]
21Feb12_205542| [ 3.25847e-01  8.66593e-01]
21Feb12_205542| [-1.98351e+00  7.29592e-01]
21Feb12_205542| [-1.29020e+00 -6.85880e-01]
21Feb12_205542| [ 4.80697e-01  1.13681e+00]
21Feb12_205542| [ 4.96277e-01 -6.97935e-01]
21Feb12_205542| [ 8.81560e-01  1.50973e+00]
21Feb12_205542| [ 8.05521e-01 -6.06217e-01]
21Feb12_205542| [-1.08425e+00  4.63923e-01]
21Feb12_205542| [ 4.73934e-01 -1.27724e+00]
21Feb12_205542| [-5.07898e-01  1.37824e+00]
21Feb12_205542| [ 4.23982e-01  2.30444e-01]
21Feb12_205542| [ 1.48713e+00 -1.34665e-01]
21Feb12_205542| [ 1.61202e+00 -2.03092e+00]
21Feb12_205542| [-2.30689e-03  9.62640e-01]
21Feb12_205542| [-5.07657e-01 -6.83144e-01]
21Feb12_205542| [ 1.53621e+00  6.19680e-01]
21Feb12_205542| [-9.82751e-02 -1.30833e+00]
21Feb12_205542| [ 1.29116e+00  6.90142e-01]
21Feb12_205542| [ 6.53734e-01 -1.53277e+00]
21Feb12_205542| [-4.15608e-01  3.10879e-01]
21Feb12_205542| [ 1.64881e+00 -1.12810e+00]
21Feb12_205542| [ 1.18432e+00  5.26616e-01]
21Feb12_205542| [ 5.24454e-01  5.80459e-01]
21Feb12_205542| [ 6.90033e-01 -1.87735e+00]
21Feb12_205542| [-3.65241e-01 -2.16301e-02]
21Feb12_205542| [-9.23377e-01  1.18759e+00]
21Feb12_205542| [-2.87730e-01  1.28595e-01]
21Feb12_205542| [ 2.18605e-02  1.06208e+00]
21Feb12_205542| [ 1.25212e+00 -1.86025e+00]
21Feb12_205542| [ 1.38061e+00 -3.03417e-01]
21Feb12_205542| [ 1.83639e-01  9.82415e-01]
21Feb12_205542| [ 1.05313e+00  1.65914e-01]
21Feb12_205542| [-4.71040e-01 -5.76519e-01]
21Feb12_205542| [-1.78462e+00 -7.53291e-01]
21Feb12_205542| [-8.51746e-02 -9.51482e-01]
21Feb12_205542| [-1.92042e+00  5.98504e-01]
21Feb12_205542| [-9.47328e-01  7.62275e-01]
21Feb12_205542| [-3.05419e+00 -2.01332e-01]
21Feb12_205542| [ 9.75110e-01 -8.15757e-01]
21Feb12_205542| [ 5.15170e-01  8.95748e-02]]
21Feb12_205542|-- Bias --
21Feb12_205542|[0.38753 0.10996]
21Feb12_205542|Layer 1:
21Feb12_205542|-- Config --
21Feb12_205542|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205542|-- Weights --
21Feb12_205542|[[-0.50910 -0.17092 -0.38272]
21Feb12_205542| [-0.45768  0.86120 -0.49544]]
21Feb12_205542|-- Bias --
21Feb12_205542|[-0.55242  0.77771  0.12946]
21Feb12_205542|Layer 2:
21Feb12_205542|-- Config --
21Feb12_205542|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205542|-- Weights --
21Feb12_205542|[[-0.57908 -0.77677]
21Feb12_205542| [ 0.69363 -0.30141]
21Feb12_205542| [ 0.01408  0.65954]]
21Feb12_205542|-- Bias --
21Feb12_205542|[ 0.24694 -0.01877]
21Feb12_205542|Predicting the validation and test data with the Best final individual.
21Feb12_205549| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_205549|-----------  ------------------  --------------------  ----------
21Feb12_205549|Validation         38.78                  10            0.00000
21Feb12_205549|   Test            28.32                  10            0.71946
21Feb12_205549|-------------------- Test #1 --------------------
21Feb12_205549|Best final individual weights
21Feb12_205549|Individual:
21Feb12_205549|-- Constant hidden layers --
21Feb12_205549|False
21Feb12_205549|Layer 0:
21Feb12_205549|-- Config --
21Feb12_205549|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205549|-- Weights --
21Feb12_205549|[[ 1.38403e+00  2.28864e-01]
21Feb12_205549| [ 6.34793e-02  1.17249e+00]
21Feb12_205549| [-5.52130e-01 -1.48663e-01]
21Feb12_205549| [ 2.68391e-01  1.34056e+00]
21Feb12_205549| [ 1.71588e+00  1.54148e-01]
21Feb12_205549| [-6.76487e-01 -8.12632e-01]
21Feb12_205549| [-3.36077e-01  8.37814e-01]
21Feb12_205549| [-2.76932e+00  6.48499e-01]
21Feb12_205549| [ 7.03962e-01  1.39837e+00]
21Feb12_205549| [-7.94729e-01  1.53931e+00]
21Feb12_205549| [ 5.14315e-01 -5.46938e-01]
21Feb12_205549| [ 8.51602e-01 -1.17766e+00]
21Feb12_205549| [-9.85517e-01 -2.02046e-01]
21Feb12_205549| [ 3.57173e-01 -2.36309e-01]
21Feb12_205549| [ 7.72289e-01 -1.26733e-01]
21Feb12_205549| [ 7.81051e-01 -1.61717e-01]
21Feb12_205549| [ 7.70356e-01 -2.27992e-02]
21Feb12_205549| [ 3.25847e-01  8.66593e-01]
21Feb12_205549| [-1.98351e+00  7.29592e-01]
21Feb12_205549| [-1.29020e+00 -6.85880e-01]
21Feb12_205549| [ 4.80697e-01  1.13681e+00]
21Feb12_205549| [ 4.96277e-01 -6.97935e-01]
21Feb12_205549| [ 8.81560e-01  1.50973e+00]
21Feb12_205549| [ 8.05521e-01 -6.06217e-01]
21Feb12_205549| [-1.08425e+00  4.63923e-01]
21Feb12_205549| [ 4.73934e-01 -1.27724e+00]
21Feb12_205549| [-5.07898e-01  1.37824e+00]
21Feb12_205549| [ 4.23982e-01  2.30444e-01]
21Feb12_205549| [ 1.48713e+00 -1.34665e-01]
21Feb12_205549| [ 1.61202e+00 -2.03092e+00]
21Feb12_205549| [-2.30689e-03  9.62640e-01]
21Feb12_205549| [-5.07657e-01 -6.83144e-01]
21Feb12_205549| [ 1.53621e+00  6.19680e-01]
21Feb12_205549| [-9.82751e-02 -1.30833e+00]
21Feb12_205549| [ 1.29116e+00  6.90142e-01]
21Feb12_205549| [ 6.53734e-01 -1.53277e+00]
21Feb12_205549| [-4.15608e-01  3.10879e-01]
21Feb12_205549| [ 1.64881e+00 -1.12810e+00]
21Feb12_205549| [ 1.18432e+00  5.26616e-01]
21Feb12_205549| [ 5.24454e-01  5.80459e-01]
21Feb12_205549| [ 6.90033e-01 -1.87735e+00]
21Feb12_205549| [-3.65241e-01 -2.16301e-02]
21Feb12_205549| [-9.23377e-01  1.18759e+00]
21Feb12_205549| [-2.87730e-01  1.28595e-01]
21Feb12_205549| [ 2.18605e-02  1.06208e+00]
21Feb12_205549| [ 1.25212e+00 -1.86025e+00]
21Feb12_205549| [ 1.38061e+00 -3.03417e-01]
21Feb12_205549| [ 1.83639e-01  9.82415e-01]
21Feb12_205549| [ 1.05313e+00  1.65914e-01]
21Feb12_205549| [-4.71040e-01 -5.76519e-01]
21Feb12_205549| [-1.78462e+00 -7.53291e-01]
21Feb12_205549| [-8.51746e-02 -9.51482e-01]
21Feb12_205549| [-1.92042e+00  5.98504e-01]
21Feb12_205549| [-9.47328e-01  7.62275e-01]
21Feb12_205549| [-3.05419e+00 -2.01332e-01]
21Feb12_205549| [ 9.75110e-01 -8.15757e-01]
21Feb12_205549| [ 5.15170e-01  8.95748e-02]]
21Feb12_205549|-- Bias --
21Feb12_205549|[0.38753 0.10996]
21Feb12_205549|Layer 1:
21Feb12_205549|-- Config --
21Feb12_205549|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205549|-- Weights --
21Feb12_205549|[[-0.50910 -0.17092 -0.38272]
21Feb12_205549| [-0.45768  0.86120 -0.49544]]
21Feb12_205549|-- Bias --
21Feb12_205549|[-0.55242  0.77771  0.12946]
21Feb12_205549|Layer 2:
21Feb12_205549|-- Config --
21Feb12_205549|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205549|-- Weights --
21Feb12_205549|[[-0.57908 -0.77677]
21Feb12_205549| [ 0.69363 -0.30141]
21Feb12_205549| [ 0.01408  0.65954]]
21Feb12_205549|-- Bias --
21Feb12_205549|[ 0.24694 -0.01877]
21Feb12_205549|Predicting the validation and test data with the Best final individual.
21Feb12_205556| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_205556|-----------  ------------------  --------------------  ----------
21Feb12_205556|Validation         34.96                  10            0.70545
21Feb12_205556|   Test            39.01                  10            0.00000
21Feb12_205556|-------------------- Test #2 --------------------
21Feb12_205556|Best final individual weights
21Feb12_205556|Individual:
21Feb12_205556|-- Constant hidden layers --
21Feb12_205556|False
21Feb12_205556|Layer 0:
21Feb12_205556|-- Config --
21Feb12_205556|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205556|-- Weights --
21Feb12_205556|[[ 1.38403e+00  2.28864e-01]
21Feb12_205556| [ 6.34793e-02  1.17249e+00]
21Feb12_205556| [-5.52130e-01 -1.48663e-01]
21Feb12_205556| [ 2.68391e-01  1.34056e+00]
21Feb12_205556| [ 1.71588e+00  1.54148e-01]
21Feb12_205556| [-6.76487e-01 -8.12632e-01]
21Feb12_205556| [-3.36077e-01  8.37814e-01]
21Feb12_205556| [-2.76932e+00  6.48499e-01]
21Feb12_205556| [ 7.03962e-01  1.39837e+00]
21Feb12_205556| [-7.94729e-01  1.53931e+00]
21Feb12_205556| [ 5.14315e-01 -5.46938e-01]
21Feb12_205556| [ 8.51602e-01 -1.17766e+00]
21Feb12_205556| [-9.85517e-01 -2.02046e-01]
21Feb12_205556| [ 3.57173e-01 -2.36309e-01]
21Feb12_205556| [ 7.72289e-01 -1.26733e-01]
21Feb12_205556| [ 7.81051e-01 -1.61717e-01]
21Feb12_205556| [ 7.70356e-01 -2.27992e-02]
21Feb12_205556| [ 3.25847e-01  8.66593e-01]
21Feb12_205556| [-1.98351e+00  7.29592e-01]
21Feb12_205556| [-1.29020e+00 -6.85880e-01]
21Feb12_205556| [ 4.80697e-01  1.13681e+00]
21Feb12_205556| [ 4.96277e-01 -6.97935e-01]
21Feb12_205556| [ 8.81560e-01  1.50973e+00]
21Feb12_205556| [ 8.05521e-01 -6.06217e-01]
21Feb12_205556| [-1.08425e+00  4.63923e-01]
21Feb12_205556| [ 4.73934e-01 -1.27724e+00]
21Feb12_205556| [-5.07898e-01  1.37824e+00]
21Feb12_205556| [ 4.23982e-01  2.30444e-01]
21Feb12_205556| [ 1.48713e+00 -1.34665e-01]
21Feb12_205556| [ 1.61202e+00 -2.03092e+00]
21Feb12_205556| [-2.30689e-03  9.62640e-01]
21Feb12_205556| [-5.07657e-01 -6.83144e-01]
21Feb12_205556| [ 1.53621e+00  6.19680e-01]
21Feb12_205556| [-9.82751e-02 -1.30833e+00]
21Feb12_205556| [ 1.29116e+00  6.90142e-01]
21Feb12_205556| [ 6.53734e-01 -1.53277e+00]
21Feb12_205556| [-4.15608e-01  3.10879e-01]
21Feb12_205556| [ 1.64881e+00 -1.12810e+00]
21Feb12_205556| [ 1.18432e+00  5.26616e-01]
21Feb12_205556| [ 5.24454e-01  5.80459e-01]
21Feb12_205556| [ 6.90033e-01 -1.87735e+00]
21Feb12_205556| [-3.65241e-01 -2.16301e-02]
21Feb12_205556| [-9.23377e-01  1.18759e+00]
21Feb12_205556| [-2.87730e-01  1.28595e-01]
21Feb12_205556| [ 2.18605e-02  1.06208e+00]
21Feb12_205556| [ 1.25212e+00 -1.86025e+00]
21Feb12_205556| [ 1.38061e+00 -3.03417e-01]
21Feb12_205556| [ 1.83639e-01  9.82415e-01]
21Feb12_205556| [ 1.05313e+00  1.65914e-01]
21Feb12_205556| [-4.71040e-01 -5.76519e-01]
21Feb12_205556| [-1.78462e+00 -7.53291e-01]
21Feb12_205556| [-8.51746e-02 -9.51482e-01]
21Feb12_205556| [-1.92042e+00  5.98504e-01]
21Feb12_205556| [-9.47328e-01  7.62275e-01]
21Feb12_205556| [-3.05419e+00 -2.01332e-01]
21Feb12_205556| [ 9.75110e-01 -8.15757e-01]
21Feb12_205556| [ 5.15170e-01  8.95748e-02]]
21Feb12_205556|-- Bias --
21Feb12_205556|[0.38753 0.10996]
21Feb12_205556|Layer 1:
21Feb12_205556|-- Config --
21Feb12_205556|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205556|-- Weights --
21Feb12_205556|[[-0.50910 -0.17092 -0.38272]
21Feb12_205556| [-0.45768  0.86120 -0.49544]]
21Feb12_205556|-- Bias --
21Feb12_205556|[-0.55242  0.77771  0.12946]
21Feb12_205556|Layer 2:
21Feb12_205556|-- Config --
21Feb12_205556|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205556|-- Weights --
21Feb12_205556|[[-0.57908 -0.77677]
21Feb12_205556| [ 0.69363 -0.30141]
21Feb12_205556| [ 0.01408  0.65954]]
21Feb12_205556|-- Bias --
21Feb12_205556|[ 0.24694 -0.01877]
21Feb12_205556|Predicting the validation and test data with the Best final individual.
21Feb12_205604| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_205604|-----------  ------------------  --------------------  ----------
21Feb12_205604|Validation         39.39                  10            0.79818
21Feb12_205604|   Test            27.02                  10            0.71028
21Feb12_205604|-------------------- Test #3 --------------------
21Feb12_205604|Best final individual weights
21Feb12_205604|Individual:
21Feb12_205604|-- Constant hidden layers --
21Feb12_205604|False
21Feb12_205604|Layer 0:
21Feb12_205604|-- Config --
21Feb12_205604|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205604|-- Weights --
21Feb12_205604|[[ 1.38403e+00  2.28864e-01]
21Feb12_205604| [ 6.34793e-02  1.17249e+00]
21Feb12_205604| [-5.52130e-01 -1.48663e-01]
21Feb12_205604| [ 2.68391e-01  1.34056e+00]
21Feb12_205604| [ 1.71588e+00  1.54148e-01]
21Feb12_205604| [-6.76487e-01 -8.12632e-01]
21Feb12_205604| [-3.36077e-01  8.37814e-01]
21Feb12_205604| [-2.76932e+00  6.48499e-01]
21Feb12_205604| [ 7.03962e-01  1.39837e+00]
21Feb12_205604| [-7.94729e-01  1.53931e+00]
21Feb12_205604| [ 5.14315e-01 -5.46938e-01]
21Feb12_205604| [ 8.51602e-01 -1.17766e+00]
21Feb12_205604| [-9.85517e-01 -2.02046e-01]
21Feb12_205604| [ 3.57173e-01 -2.36309e-01]
21Feb12_205604| [ 7.72289e-01 -1.26733e-01]
21Feb12_205604| [ 7.81051e-01 -1.61717e-01]
21Feb12_205604| [ 7.70356e-01 -2.27992e-02]
21Feb12_205604| [ 3.25847e-01  8.66593e-01]
21Feb12_205604| [-1.98351e+00  7.29592e-01]
21Feb12_205604| [-1.29020e+00 -6.85880e-01]
21Feb12_205604| [ 4.80697e-01  1.13681e+00]
21Feb12_205604| [ 4.96277e-01 -6.97935e-01]
21Feb12_205604| [ 8.81560e-01  1.50973e+00]
21Feb12_205604| [ 8.05521e-01 -6.06217e-01]
21Feb12_205604| [-1.08425e+00  4.63923e-01]
21Feb12_205604| [ 4.73934e-01 -1.27724e+00]
21Feb12_205604| [-5.07898e-01  1.37824e+00]
21Feb12_205604| [ 4.23982e-01  2.30444e-01]
21Feb12_205604| [ 1.48713e+00 -1.34665e-01]
21Feb12_205604| [ 1.61202e+00 -2.03092e+00]
21Feb12_205604| [-2.30689e-03  9.62640e-01]
21Feb12_205604| [-5.07657e-01 -6.83144e-01]
21Feb12_205604| [ 1.53621e+00  6.19680e-01]
21Feb12_205604| [-9.82751e-02 -1.30833e+00]
21Feb12_205604| [ 1.29116e+00  6.90142e-01]
21Feb12_205604| [ 6.53734e-01 -1.53277e+00]
21Feb12_205604| [-4.15608e-01  3.10879e-01]
21Feb12_205604| [ 1.64881e+00 -1.12810e+00]
21Feb12_205604| [ 1.18432e+00  5.26616e-01]
21Feb12_205604| [ 5.24454e-01  5.80459e-01]
21Feb12_205604| [ 6.90033e-01 -1.87735e+00]
21Feb12_205604| [-3.65241e-01 -2.16301e-02]
21Feb12_205604| [-9.23377e-01  1.18759e+00]
21Feb12_205604| [-2.87730e-01  1.28595e-01]
21Feb12_205604| [ 2.18605e-02  1.06208e+00]
21Feb12_205604| [ 1.25212e+00 -1.86025e+00]
21Feb12_205604| [ 1.38061e+00 -3.03417e-01]
21Feb12_205604| [ 1.83639e-01  9.82415e-01]
21Feb12_205604| [ 1.05313e+00  1.65914e-01]
21Feb12_205604| [-4.71040e-01 -5.76519e-01]
21Feb12_205604| [-1.78462e+00 -7.53291e-01]
21Feb12_205604| [-8.51746e-02 -9.51482e-01]
21Feb12_205604| [-1.92042e+00  5.98504e-01]
21Feb12_205604| [-9.47328e-01  7.62275e-01]
21Feb12_205604| [-3.05419e+00 -2.01332e-01]
21Feb12_205604| [ 9.75110e-01 -8.15757e-01]
21Feb12_205604| [ 5.15170e-01  8.95748e-02]]
21Feb12_205604|-- Bias --
21Feb12_205604|[0.38753 0.10996]
21Feb12_205604|Layer 1:
21Feb12_205604|-- Config --
21Feb12_205604|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205604|-- Weights --
21Feb12_205604|[[-0.50910 -0.17092 -0.38272]
21Feb12_205604| [-0.45768  0.86120 -0.49544]]
21Feb12_205604|-- Bias --
21Feb12_205604|[-0.55242  0.77771  0.12946]
21Feb12_205604|Layer 2:
21Feb12_205604|-- Config --
21Feb12_205604|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205604|-- Weights --
21Feb12_205604|[[-0.57908 -0.77677]
21Feb12_205604| [ 0.69363 -0.30141]
21Feb12_205604| [ 0.01408  0.65954]]
21Feb12_205604|-- Bias --
21Feb12_205604|[ 0.24694 -0.01877]
21Feb12_205604|Predicting the validation and test data with the Best final individual.
21Feb12_205611| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_205611|-----------  ------------------  --------------------  ----------
21Feb12_205611|Validation         38.78                  10            0.00000
21Feb12_205611|   Test            39.01                  10            0.00000
21Feb12_205611|-------------------- Test #4 --------------------
21Feb12_205611|Best final individual weights
21Feb12_205611|Individual:
21Feb12_205611|-- Constant hidden layers --
21Feb12_205611|False
21Feb12_205611|Layer 0:
21Feb12_205611|-- Config --
21Feb12_205611|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205611|-- Weights --
21Feb12_205611|[[ 1.38403e+00  2.28864e-01]
21Feb12_205611| [ 6.34793e-02  1.17249e+00]
21Feb12_205611| [-5.52130e-01 -1.48663e-01]
21Feb12_205611| [ 2.68391e-01  1.34056e+00]
21Feb12_205611| [ 1.71588e+00  1.54148e-01]
21Feb12_205611| [-6.76487e-01 -8.12632e-01]
21Feb12_205611| [-3.36077e-01  8.37814e-01]
21Feb12_205611| [-2.76932e+00  6.48499e-01]
21Feb12_205611| [ 7.03962e-01  1.39837e+00]
21Feb12_205611| [-7.94729e-01  1.53931e+00]
21Feb12_205611| [ 5.14315e-01 -5.46938e-01]
21Feb12_205611| [ 8.51602e-01 -1.17766e+00]
21Feb12_205611| [-9.85517e-01 -2.02046e-01]
21Feb12_205611| [ 3.57173e-01 -2.36309e-01]
21Feb12_205611| [ 7.72289e-01 -1.26733e-01]
21Feb12_205611| [ 7.81051e-01 -1.61717e-01]
21Feb12_205611| [ 7.70356e-01 -2.27992e-02]
21Feb12_205611| [ 3.25847e-01  8.66593e-01]
21Feb12_205611| [-1.98351e+00  7.29592e-01]
21Feb12_205611| [-1.29020e+00 -6.85880e-01]
21Feb12_205611| [ 4.80697e-01  1.13681e+00]
21Feb12_205611| [ 4.96277e-01 -6.97935e-01]
21Feb12_205611| [ 8.81560e-01  1.50973e+00]
21Feb12_205611| [ 8.05521e-01 -6.06217e-01]
21Feb12_205611| [-1.08425e+00  4.63923e-01]
21Feb12_205611| [ 4.73934e-01 -1.27724e+00]
21Feb12_205611| [-5.07898e-01  1.37824e+00]
21Feb12_205611| [ 4.23982e-01  2.30444e-01]
21Feb12_205611| [ 1.48713e+00 -1.34665e-01]
21Feb12_205611| [ 1.61202e+00 -2.03092e+00]
21Feb12_205611| [-2.30689e-03  9.62640e-01]
21Feb12_205611| [-5.07657e-01 -6.83144e-01]
21Feb12_205611| [ 1.53621e+00  6.19680e-01]
21Feb12_205611| [-9.82751e-02 -1.30833e+00]
21Feb12_205611| [ 1.29116e+00  6.90142e-01]
21Feb12_205611| [ 6.53734e-01 -1.53277e+00]
21Feb12_205611| [-4.15608e-01  3.10879e-01]
21Feb12_205611| [ 1.64881e+00 -1.12810e+00]
21Feb12_205611| [ 1.18432e+00  5.26616e-01]
21Feb12_205611| [ 5.24454e-01  5.80459e-01]
21Feb12_205611| [ 6.90033e-01 -1.87735e+00]
21Feb12_205611| [-3.65241e-01 -2.16301e-02]
21Feb12_205611| [-9.23377e-01  1.18759e+00]
21Feb12_205611| [-2.87730e-01  1.28595e-01]
21Feb12_205611| [ 2.18605e-02  1.06208e+00]
21Feb12_205611| [ 1.25212e+00 -1.86025e+00]
21Feb12_205611| [ 1.38061e+00 -3.03417e-01]
21Feb12_205611| [ 1.83639e-01  9.82415e-01]
21Feb12_205611| [ 1.05313e+00  1.65914e-01]
21Feb12_205611| [-4.71040e-01 -5.76519e-01]
21Feb12_205611| [-1.78462e+00 -7.53291e-01]
21Feb12_205611| [-8.51746e-02 -9.51482e-01]
21Feb12_205611| [-1.92042e+00  5.98504e-01]
21Feb12_205611| [-9.47328e-01  7.62275e-01]
21Feb12_205611| [-3.05419e+00 -2.01332e-01]
21Feb12_205611| [ 9.75110e-01 -8.15757e-01]
21Feb12_205611| [ 5.15170e-01  8.95748e-02]]
21Feb12_205611|-- Bias --
21Feb12_205611|[0.38753 0.10996]
21Feb12_205611|Layer 1:
21Feb12_205611|-- Config --
21Feb12_205611|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205611|-- Weights --
21Feb12_205611|[[-0.50910 -0.17092 -0.38272]
21Feb12_205611| [-0.45768  0.86120 -0.49544]]
21Feb12_205611|-- Bias --
21Feb12_205611|[-0.55242  0.77771  0.12946]
21Feb12_205611|Layer 2:
21Feb12_205611|-- Config --
21Feb12_205611|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205611|-- Weights --
21Feb12_205611|[[-0.57908 -0.77677]
21Feb12_205611| [ 0.69363 -0.30141]
21Feb12_205611| [ 0.01408  0.65954]]
21Feb12_205611|-- Bias --
21Feb12_205611|[ 0.24694 -0.01877]
21Feb12_205611|Predicting the validation and test data with the Best final individual.
21Feb12_205619| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_205619|-----------  ------------------  --------------------  ----------
21Feb12_205619|Validation         38.78                  10            0.00000
21Feb12_205619|   Test            27.37                  10            0.51576
21Feb12_205619|-------------------- Test #5 --------------------
21Feb12_205619|Best final individual weights
21Feb12_205619|Individual:
21Feb12_205619|-- Constant hidden layers --
21Feb12_205619|False
21Feb12_205619|Layer 0:
21Feb12_205619|-- Config --
21Feb12_205619|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205619|-- Weights --
21Feb12_205619|[[ 1.38403e+00  2.28864e-01]
21Feb12_205619| [ 6.34793e-02  1.17249e+00]
21Feb12_205619| [-5.52130e-01 -1.48663e-01]
21Feb12_205619| [ 2.68391e-01  1.34056e+00]
21Feb12_205619| [ 1.71588e+00  1.54148e-01]
21Feb12_205619| [-6.76487e-01 -8.12632e-01]
21Feb12_205619| [-3.36077e-01  8.37814e-01]
21Feb12_205619| [-2.76932e+00  6.48499e-01]
21Feb12_205619| [ 7.03962e-01  1.39837e+00]
21Feb12_205619| [-7.94729e-01  1.53931e+00]
21Feb12_205619| [ 5.14315e-01 -5.46938e-01]
21Feb12_205619| [ 8.51602e-01 -1.17766e+00]
21Feb12_205619| [-9.85517e-01 -2.02046e-01]
21Feb12_205619| [ 3.57173e-01 -2.36309e-01]
21Feb12_205619| [ 7.72289e-01 -1.26733e-01]
21Feb12_205619| [ 7.81051e-01 -1.61717e-01]
21Feb12_205619| [ 7.70356e-01 -2.27992e-02]
21Feb12_205619| [ 3.25847e-01  8.66593e-01]
21Feb12_205619| [-1.98351e+00  7.29592e-01]
21Feb12_205619| [-1.29020e+00 -6.85880e-01]
21Feb12_205619| [ 4.80697e-01  1.13681e+00]
21Feb12_205619| [ 4.96277e-01 -6.97935e-01]
21Feb12_205619| [ 8.81560e-01  1.50973e+00]
21Feb12_205619| [ 8.05521e-01 -6.06217e-01]
21Feb12_205619| [-1.08425e+00  4.63923e-01]
21Feb12_205619| [ 4.73934e-01 -1.27724e+00]
21Feb12_205619| [-5.07898e-01  1.37824e+00]
21Feb12_205619| [ 4.23982e-01  2.30444e-01]
21Feb12_205619| [ 1.48713e+00 -1.34665e-01]
21Feb12_205619| [ 1.61202e+00 -2.03092e+00]
21Feb12_205619| [-2.30689e-03  9.62640e-01]
21Feb12_205619| [-5.07657e-01 -6.83144e-01]
21Feb12_205619| [ 1.53621e+00  6.19680e-01]
21Feb12_205619| [-9.82751e-02 -1.30833e+00]
21Feb12_205619| [ 1.29116e+00  6.90142e-01]
21Feb12_205619| [ 6.53734e-01 -1.53277e+00]
21Feb12_205619| [-4.15608e-01  3.10879e-01]
21Feb12_205619| [ 1.64881e+00 -1.12810e+00]
21Feb12_205619| [ 1.18432e+00  5.26616e-01]
21Feb12_205619| [ 5.24454e-01  5.80459e-01]
21Feb12_205619| [ 6.90033e-01 -1.87735e+00]
21Feb12_205619| [-3.65241e-01 -2.16301e-02]
21Feb12_205619| [-9.23377e-01  1.18759e+00]
21Feb12_205619| [-2.87730e-01  1.28595e-01]
21Feb12_205619| [ 2.18605e-02  1.06208e+00]
21Feb12_205619| [ 1.25212e+00 -1.86025e+00]
21Feb12_205619| [ 1.38061e+00 -3.03417e-01]
21Feb12_205619| [ 1.83639e-01  9.82415e-01]
21Feb12_205619| [ 1.05313e+00  1.65914e-01]
21Feb12_205619| [-4.71040e-01 -5.76519e-01]
21Feb12_205619| [-1.78462e+00 -7.53291e-01]
21Feb12_205619| [-8.51746e-02 -9.51482e-01]
21Feb12_205619| [-1.92042e+00  5.98504e-01]
21Feb12_205619| [-9.47328e-01  7.62275e-01]
21Feb12_205619| [-3.05419e+00 -2.01332e-01]
21Feb12_205619| [ 9.75110e-01 -8.15757e-01]
21Feb12_205619| [ 5.15170e-01  8.95748e-02]]
21Feb12_205619|-- Bias --
21Feb12_205619|[0.38753 0.10996]
21Feb12_205619|Layer 1:
21Feb12_205619|-- Config --
21Feb12_205619|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205619|-- Weights --
21Feb12_205619|[[-0.50910 -0.17092 -0.38272]
21Feb12_205619| [-0.45768  0.86120 -0.49544]]
21Feb12_205619|-- Bias --
21Feb12_205619|[-0.55242  0.77771  0.12946]
21Feb12_205619|Layer 2:
21Feb12_205619|-- Config --
21Feb12_205619|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205619|-- Weights --
21Feb12_205619|[[-0.57908 -0.77677]
21Feb12_205619| [ 0.69363 -0.30141]
21Feb12_205619| [ 0.01408  0.65954]]
21Feb12_205619|-- Bias --
21Feb12_205619|[ 0.24694 -0.01877]
21Feb12_205619|Predicting the validation and test data with the Best final individual.
21Feb12_205626| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_205626|-----------  ------------------  --------------------  ----------
21Feb12_205626|Validation         39.83                  10            0.77573
21Feb12_205626|   Test            39.01                  10            0.00000
21Feb12_205626|-------------------- Test #6 --------------------
21Feb12_205626|Best final individual weights
21Feb12_205626|Individual:
21Feb12_205626|-- Constant hidden layers --
21Feb12_205626|False
21Feb12_205626|Layer 0:
21Feb12_205626|-- Config --
21Feb12_205626|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205626|-- Weights --
21Feb12_205626|[[ 1.38403e+00  2.28864e-01]
21Feb12_205626| [ 6.34793e-02  1.17249e+00]
21Feb12_205626| [-5.52130e-01 -1.48663e-01]
21Feb12_205626| [ 2.68391e-01  1.34056e+00]
21Feb12_205626| [ 1.71588e+00  1.54148e-01]
21Feb12_205626| [-6.76487e-01 -8.12632e-01]
21Feb12_205626| [-3.36077e-01  8.37814e-01]
21Feb12_205626| [-2.76932e+00  6.48499e-01]
21Feb12_205626| [ 7.03962e-01  1.39837e+00]
21Feb12_205626| [-7.94729e-01  1.53931e+00]
21Feb12_205626| [ 5.14315e-01 -5.46938e-01]
21Feb12_205626| [ 8.51602e-01 -1.17766e+00]
21Feb12_205626| [-9.85517e-01 -2.02046e-01]
21Feb12_205626| [ 3.57173e-01 -2.36309e-01]
21Feb12_205626| [ 7.72289e-01 -1.26733e-01]
21Feb12_205626| [ 7.81051e-01 -1.61717e-01]
21Feb12_205626| [ 7.70356e-01 -2.27992e-02]
21Feb12_205626| [ 3.25847e-01  8.66593e-01]
21Feb12_205626| [-1.98351e+00  7.29592e-01]
21Feb12_205626| [-1.29020e+00 -6.85880e-01]
21Feb12_205626| [ 4.80697e-01  1.13681e+00]
21Feb12_205626| [ 4.96277e-01 -6.97935e-01]
21Feb12_205626| [ 8.81560e-01  1.50973e+00]
21Feb12_205626| [ 8.05521e-01 -6.06217e-01]
21Feb12_205626| [-1.08425e+00  4.63923e-01]
21Feb12_205626| [ 4.73934e-01 -1.27724e+00]
21Feb12_205626| [-5.07898e-01  1.37824e+00]
21Feb12_205626| [ 4.23982e-01  2.30444e-01]
21Feb12_205626| [ 1.48713e+00 -1.34665e-01]
21Feb12_205626| [ 1.61202e+00 -2.03092e+00]
21Feb12_205626| [-2.30689e-03  9.62640e-01]
21Feb12_205626| [-5.07657e-01 -6.83144e-01]
21Feb12_205626| [ 1.53621e+00  6.19680e-01]
21Feb12_205626| [-9.82751e-02 -1.30833e+00]
21Feb12_205626| [ 1.29116e+00  6.90142e-01]
21Feb12_205626| [ 6.53734e-01 -1.53277e+00]
21Feb12_205626| [-4.15608e-01  3.10879e-01]
21Feb12_205626| [ 1.64881e+00 -1.12810e+00]
21Feb12_205626| [ 1.18432e+00  5.26616e-01]
21Feb12_205626| [ 5.24454e-01  5.80459e-01]
21Feb12_205626| [ 6.90033e-01 -1.87735e+00]
21Feb12_205626| [-3.65241e-01 -2.16301e-02]
21Feb12_205626| [-9.23377e-01  1.18759e+00]
21Feb12_205626| [-2.87730e-01  1.28595e-01]
21Feb12_205626| [ 2.18605e-02  1.06208e+00]
21Feb12_205626| [ 1.25212e+00 -1.86025e+00]
21Feb12_205626| [ 1.38061e+00 -3.03417e-01]
21Feb12_205626| [ 1.83639e-01  9.82415e-01]
21Feb12_205626| [ 1.05313e+00  1.65914e-01]
21Feb12_205626| [-4.71040e-01 -5.76519e-01]
21Feb12_205626| [-1.78462e+00 -7.53291e-01]
21Feb12_205626| [-8.51746e-02 -9.51482e-01]
21Feb12_205626| [-1.92042e+00  5.98504e-01]
21Feb12_205626| [-9.47328e-01  7.62275e-01]
21Feb12_205626| [-3.05419e+00 -2.01332e-01]
21Feb12_205626| [ 9.75110e-01 -8.15757e-01]
21Feb12_205626| [ 5.15170e-01  8.95748e-02]]
21Feb12_205626|-- Bias --
21Feb12_205626|[0.38753 0.10996]
21Feb12_205626|Layer 1:
21Feb12_205626|-- Config --
21Feb12_205626|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205626|-- Weights --
21Feb12_205626|[[-0.50910 -0.17092 -0.38272]
21Feb12_205626| [-0.45768  0.86120 -0.49544]]
21Feb12_205626|-- Bias --
21Feb12_205626|[-0.55242  0.77771  0.12946]
21Feb12_205626|Layer 2:
21Feb12_205626|-- Config --
21Feb12_205626|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205626|-- Weights --
21Feb12_205626|[[-0.57908 -0.77677]
21Feb12_205626| [ 0.69363 -0.30141]
21Feb12_205626| [ 0.01408  0.65954]]
21Feb12_205626|-- Bias --
21Feb12_205626|[ 0.24694 -0.01877]
21Feb12_205626|Predicting the validation and test data with the Best final individual.
21Feb12_205633| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_205633|-----------  ------------------  --------------------  ----------
21Feb12_205633|Validation         43.83                  10            0.79571
21Feb12_205633|   Test            39.01                  10            0.00000
21Feb12_205633|-------------------- Test #7 --------------------
21Feb12_205633|Best final individual weights
21Feb12_205633|Individual:
21Feb12_205633|-- Constant hidden layers --
21Feb12_205633|False
21Feb12_205633|Layer 0:
21Feb12_205633|-- Config --
21Feb12_205633|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205633|-- Weights --
21Feb12_205633|[[ 1.38403e+00  2.28864e-01]
21Feb12_205633| [ 6.34793e-02  1.17249e+00]
21Feb12_205633| [-5.52130e-01 -1.48663e-01]
21Feb12_205633| [ 2.68391e-01  1.34056e+00]
21Feb12_205633| [ 1.71588e+00  1.54148e-01]
21Feb12_205633| [-6.76487e-01 -8.12632e-01]
21Feb12_205633| [-3.36077e-01  8.37814e-01]
21Feb12_205633| [-2.76932e+00  6.48499e-01]
21Feb12_205633| [ 7.03962e-01  1.39837e+00]
21Feb12_205633| [-7.94729e-01  1.53931e+00]
21Feb12_205633| [ 5.14315e-01 -5.46938e-01]
21Feb12_205633| [ 8.51602e-01 -1.17766e+00]
21Feb12_205633| [-9.85517e-01 -2.02046e-01]
21Feb12_205633| [ 3.57173e-01 -2.36309e-01]
21Feb12_205633| [ 7.72289e-01 -1.26733e-01]
21Feb12_205633| [ 7.81051e-01 -1.61717e-01]
21Feb12_205633| [ 7.70356e-01 -2.27992e-02]
21Feb12_205633| [ 3.25847e-01  8.66593e-01]
21Feb12_205633| [-1.98351e+00  7.29592e-01]
21Feb12_205633| [-1.29020e+00 -6.85880e-01]
21Feb12_205633| [ 4.80697e-01  1.13681e+00]
21Feb12_205633| [ 4.96277e-01 -6.97935e-01]
21Feb12_205633| [ 8.81560e-01  1.50973e+00]
21Feb12_205633| [ 8.05521e-01 -6.06217e-01]
21Feb12_205633| [-1.08425e+00  4.63923e-01]
21Feb12_205633| [ 4.73934e-01 -1.27724e+00]
21Feb12_205633| [-5.07898e-01  1.37824e+00]
21Feb12_205633| [ 4.23982e-01  2.30444e-01]
21Feb12_205633| [ 1.48713e+00 -1.34665e-01]
21Feb12_205633| [ 1.61202e+00 -2.03092e+00]
21Feb12_205633| [-2.30689e-03  9.62640e-01]
21Feb12_205633| [-5.07657e-01 -6.83144e-01]
21Feb12_205633| [ 1.53621e+00  6.19680e-01]
21Feb12_205633| [-9.82751e-02 -1.30833e+00]
21Feb12_205633| [ 1.29116e+00  6.90142e-01]
21Feb12_205633| [ 6.53734e-01 -1.53277e+00]
21Feb12_205633| [-4.15608e-01  3.10879e-01]
21Feb12_205633| [ 1.64881e+00 -1.12810e+00]
21Feb12_205633| [ 1.18432e+00  5.26616e-01]
21Feb12_205633| [ 5.24454e-01  5.80459e-01]
21Feb12_205633| [ 6.90033e-01 -1.87735e+00]
21Feb12_205633| [-3.65241e-01 -2.16301e-02]
21Feb12_205633| [-9.23377e-01  1.18759e+00]
21Feb12_205633| [-2.87730e-01  1.28595e-01]
21Feb12_205633| [ 2.18605e-02  1.06208e+00]
21Feb12_205633| [ 1.25212e+00 -1.86025e+00]
21Feb12_205633| [ 1.38061e+00 -3.03417e-01]
21Feb12_205633| [ 1.83639e-01  9.82415e-01]
21Feb12_205633| [ 1.05313e+00  1.65914e-01]
21Feb12_205633| [-4.71040e-01 -5.76519e-01]
21Feb12_205633| [-1.78462e+00 -7.53291e-01]
21Feb12_205633| [-8.51746e-02 -9.51482e-01]
21Feb12_205633| [-1.92042e+00  5.98504e-01]
21Feb12_205633| [-9.47328e-01  7.62275e-01]
21Feb12_205633| [-3.05419e+00 -2.01332e-01]
21Feb12_205633| [ 9.75110e-01 -8.15757e-01]
21Feb12_205633| [ 5.15170e-01  8.95748e-02]]
21Feb12_205633|-- Bias --
21Feb12_205633|[0.38753 0.10996]
21Feb12_205633|Layer 1:
21Feb12_205633|-- Config --
21Feb12_205633|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205633|-- Weights --
21Feb12_205633|[[-0.50910 -0.17092 -0.38272]
21Feb12_205633| [-0.45768  0.86120 -0.49544]]
21Feb12_205633|-- Bias --
21Feb12_205633|[-0.55242  0.77771  0.12946]
21Feb12_205633|Layer 2:
21Feb12_205633|-- Config --
21Feb12_205633|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205633|-- Weights --
21Feb12_205633|[[-0.57908 -0.77677]
21Feb12_205633| [ 0.69363 -0.30141]
21Feb12_205633| [ 0.01408  0.65954]]
21Feb12_205633|-- Bias --
21Feb12_205633|[ 0.24694 -0.01877]
21Feb12_205633|Predicting the validation and test data with the Best final individual.
21Feb12_205641| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_205641|-----------  ------------------  --------------------  ----------
21Feb12_205641|Validation         38.78                  10            0.00000
21Feb12_205641|   Test            26.67                  10            0.65566
21Feb12_205641|-------------------- Test #8 --------------------
21Feb12_205641|Best final individual weights
21Feb12_205641|Individual:
21Feb12_205641|-- Constant hidden layers --
21Feb12_205641|False
21Feb12_205641|Layer 0:
21Feb12_205641|-- Config --
21Feb12_205641|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205641|-- Weights --
21Feb12_205641|[[ 1.38403e+00  2.28864e-01]
21Feb12_205641| [ 6.34793e-02  1.17249e+00]
21Feb12_205641| [-5.52130e-01 -1.48663e-01]
21Feb12_205641| [ 2.68391e-01  1.34056e+00]
21Feb12_205641| [ 1.71588e+00  1.54148e-01]
21Feb12_205641| [-6.76487e-01 -8.12632e-01]
21Feb12_205641| [-3.36077e-01  8.37814e-01]
21Feb12_205641| [-2.76932e+00  6.48499e-01]
21Feb12_205641| [ 7.03962e-01  1.39837e+00]
21Feb12_205641| [-7.94729e-01  1.53931e+00]
21Feb12_205641| [ 5.14315e-01 -5.46938e-01]
21Feb12_205641| [ 8.51602e-01 -1.17766e+00]
21Feb12_205641| [-9.85517e-01 -2.02046e-01]
21Feb12_205641| [ 3.57173e-01 -2.36309e-01]
21Feb12_205641| [ 7.72289e-01 -1.26733e-01]
21Feb12_205641| [ 7.81051e-01 -1.61717e-01]
21Feb12_205641| [ 7.70356e-01 -2.27992e-02]
21Feb12_205641| [ 3.25847e-01  8.66593e-01]
21Feb12_205641| [-1.98351e+00  7.29592e-01]
21Feb12_205641| [-1.29020e+00 -6.85880e-01]
21Feb12_205641| [ 4.80697e-01  1.13681e+00]
21Feb12_205641| [ 4.96277e-01 -6.97935e-01]
21Feb12_205641| [ 8.81560e-01  1.50973e+00]
21Feb12_205641| [ 8.05521e-01 -6.06217e-01]
21Feb12_205641| [-1.08425e+00  4.63923e-01]
21Feb12_205641| [ 4.73934e-01 -1.27724e+00]
21Feb12_205641| [-5.07898e-01  1.37824e+00]
21Feb12_205641| [ 4.23982e-01  2.30444e-01]
21Feb12_205641| [ 1.48713e+00 -1.34665e-01]
21Feb12_205641| [ 1.61202e+00 -2.03092e+00]
21Feb12_205641| [-2.30689e-03  9.62640e-01]
21Feb12_205641| [-5.07657e-01 -6.83144e-01]
21Feb12_205641| [ 1.53621e+00  6.19680e-01]
21Feb12_205641| [-9.82751e-02 -1.30833e+00]
21Feb12_205641| [ 1.29116e+00  6.90142e-01]
21Feb12_205641| [ 6.53734e-01 -1.53277e+00]
21Feb12_205641| [-4.15608e-01  3.10879e-01]
21Feb12_205641| [ 1.64881e+00 -1.12810e+00]
21Feb12_205641| [ 1.18432e+00  5.26616e-01]
21Feb12_205641| [ 5.24454e-01  5.80459e-01]
21Feb12_205641| [ 6.90033e-01 -1.87735e+00]
21Feb12_205641| [-3.65241e-01 -2.16301e-02]
21Feb12_205641| [-9.23377e-01  1.18759e+00]
21Feb12_205641| [-2.87730e-01  1.28595e-01]
21Feb12_205641| [ 2.18605e-02  1.06208e+00]
21Feb12_205641| [ 1.25212e+00 -1.86025e+00]
21Feb12_205641| [ 1.38061e+00 -3.03417e-01]
21Feb12_205641| [ 1.83639e-01  9.82415e-01]
21Feb12_205641| [ 1.05313e+00  1.65914e-01]
21Feb12_205641| [-4.71040e-01 -5.76519e-01]
21Feb12_205641| [-1.78462e+00 -7.53291e-01]
21Feb12_205641| [-8.51746e-02 -9.51482e-01]
21Feb12_205641| [-1.92042e+00  5.98504e-01]
21Feb12_205641| [-9.47328e-01  7.62275e-01]
21Feb12_205641| [-3.05419e+00 -2.01332e-01]
21Feb12_205641| [ 9.75110e-01 -8.15757e-01]
21Feb12_205641| [ 5.15170e-01  8.95748e-02]]
21Feb12_205641|-- Bias --
21Feb12_205641|[0.38753 0.10996]
21Feb12_205641|Layer 1:
21Feb12_205641|-- Config --
21Feb12_205641|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205641|-- Weights --
21Feb12_205641|[[-0.50910 -0.17092 -0.38272]
21Feb12_205641| [-0.45768  0.86120 -0.49544]]
21Feb12_205641|-- Bias --
21Feb12_205641|[-0.55242  0.77771  0.12946]
21Feb12_205641|Layer 2:
21Feb12_205641|-- Config --
21Feb12_205641|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205641|-- Weights --
21Feb12_205641|[[-0.57908 -0.77677]
21Feb12_205641| [ 0.69363 -0.30141]
21Feb12_205641| [ 0.01408  0.65954]]
21Feb12_205641|-- Bias --
21Feb12_205641|[ 0.24694 -0.01877]
21Feb12_205641|Predicting the validation and test data with the Best final individual.
21Feb12_205648| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_205648|-----------  ------------------  --------------------  ----------
21Feb12_205648|Validation         28.35                  10            0.73129
21Feb12_205648|   Test            36.66                  10            0.39705
21Feb12_205648|-------------------- Test #9 --------------------
21Feb12_205648|Best final individual weights
21Feb12_205648|Individual:
21Feb12_205648|-- Constant hidden layers --
21Feb12_205648|False
21Feb12_205648|Layer 0:
21Feb12_205648|-- Config --
21Feb12_205648|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205648|-- Weights --
21Feb12_205648|[[ 1.38403e+00  2.28864e-01]
21Feb12_205648| [ 6.34793e-02  1.17249e+00]
21Feb12_205648| [-5.52130e-01 -1.48663e-01]
21Feb12_205648| [ 2.68391e-01  1.34056e+00]
21Feb12_205648| [ 1.71588e+00  1.54148e-01]
21Feb12_205648| [-6.76487e-01 -8.12632e-01]
21Feb12_205648| [-3.36077e-01  8.37814e-01]
21Feb12_205648| [-2.76932e+00  6.48499e-01]
21Feb12_205648| [ 7.03962e-01  1.39837e+00]
21Feb12_205648| [-7.94729e-01  1.53931e+00]
21Feb12_205648| [ 5.14315e-01 -5.46938e-01]
21Feb12_205648| [ 8.51602e-01 -1.17766e+00]
21Feb12_205648| [-9.85517e-01 -2.02046e-01]
21Feb12_205648| [ 3.57173e-01 -2.36309e-01]
21Feb12_205648| [ 7.72289e-01 -1.26733e-01]
21Feb12_205648| [ 7.81051e-01 -1.61717e-01]
21Feb12_205648| [ 7.70356e-01 -2.27992e-02]
21Feb12_205648| [ 3.25847e-01  8.66593e-01]
21Feb12_205648| [-1.98351e+00  7.29592e-01]
21Feb12_205648| [-1.29020e+00 -6.85880e-01]
21Feb12_205648| [ 4.80697e-01  1.13681e+00]
21Feb12_205648| [ 4.96277e-01 -6.97935e-01]
21Feb12_205648| [ 8.81560e-01  1.50973e+00]
21Feb12_205648| [ 8.05521e-01 -6.06217e-01]
21Feb12_205648| [-1.08425e+00  4.63923e-01]
21Feb12_205648| [ 4.73934e-01 -1.27724e+00]
21Feb12_205648| [-5.07898e-01  1.37824e+00]
21Feb12_205648| [ 4.23982e-01  2.30444e-01]
21Feb12_205648| [ 1.48713e+00 -1.34665e-01]
21Feb12_205648| [ 1.61202e+00 -2.03092e+00]
21Feb12_205648| [-2.30689e-03  9.62640e-01]
21Feb12_205648| [-5.07657e-01 -6.83144e-01]
21Feb12_205648| [ 1.53621e+00  6.19680e-01]
21Feb12_205648| [-9.82751e-02 -1.30833e+00]
21Feb12_205648| [ 1.29116e+00  6.90142e-01]
21Feb12_205648| [ 6.53734e-01 -1.53277e+00]
21Feb12_205648| [-4.15608e-01  3.10879e-01]
21Feb12_205648| [ 1.64881e+00 -1.12810e+00]
21Feb12_205648| [ 1.18432e+00  5.26616e-01]
21Feb12_205648| [ 5.24454e-01  5.80459e-01]
21Feb12_205648| [ 6.90033e-01 -1.87735e+00]
21Feb12_205648| [-3.65241e-01 -2.16301e-02]
21Feb12_205648| [-9.23377e-01  1.18759e+00]
21Feb12_205648| [-2.87730e-01  1.28595e-01]
21Feb12_205648| [ 2.18605e-02  1.06208e+00]
21Feb12_205648| [ 1.25212e+00 -1.86025e+00]
21Feb12_205648| [ 1.38061e+00 -3.03417e-01]
21Feb12_205648| [ 1.83639e-01  9.82415e-01]
21Feb12_205648| [ 1.05313e+00  1.65914e-01]
21Feb12_205648| [-4.71040e-01 -5.76519e-01]
21Feb12_205648| [-1.78462e+00 -7.53291e-01]
21Feb12_205648| [-8.51746e-02 -9.51482e-01]
21Feb12_205648| [-1.92042e+00  5.98504e-01]
21Feb12_205648| [-9.47328e-01  7.62275e-01]
21Feb12_205648| [-3.05419e+00 -2.01332e-01]
21Feb12_205648| [ 9.75110e-01 -8.15757e-01]
21Feb12_205648| [ 5.15170e-01  8.95748e-02]]
21Feb12_205648|-- Bias --
21Feb12_205648|[0.38753 0.10996]
21Feb12_205648|Layer 1:
21Feb12_205648|-- Config --
21Feb12_205648|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205648|-- Weights --
21Feb12_205648|[[-0.50910 -0.17092 -0.38272]
21Feb12_205648| [-0.45768  0.86120 -0.49544]]
21Feb12_205648|-- Bias --
21Feb12_205648|[-0.55242  0.77771  0.12946]
21Feb12_205648|Layer 2:
21Feb12_205648|-- Config --
21Feb12_205648|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205648|-- Weights --
21Feb12_205648|[[-0.57908 -0.77677]
21Feb12_205648| [ 0.69363 -0.30141]
21Feb12_205648| [ 0.01408  0.65954]]
21Feb12_205648|-- Bias --
21Feb12_205648|[ 0.24694 -0.01877]
21Feb12_205648|Predicting the validation and test data with the Best final individual.
21Feb12_205656| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_205656|-----------  ------------------  --------------------  ----------
21Feb12_205656|Validation         27.13                  10            0.64690
21Feb12_205656|   Test            49.00                  10            0.79070
21Feb12_205656|-------------------- Test #10 --------------------
21Feb12_205656|Best final individual weights
21Feb12_205656|Individual:
21Feb12_205656|-- Constant hidden layers --
21Feb12_205656|False
21Feb12_205656|Layer 0:
21Feb12_205656|-- Config --
21Feb12_205656|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205656|-- Weights --
21Feb12_205656|[[ 1.38403e+00  2.28864e-01]
21Feb12_205656| [ 6.34793e-02  1.17249e+00]
21Feb12_205656| [-5.52130e-01 -1.48663e-01]
21Feb12_205656| [ 2.68391e-01  1.34056e+00]
21Feb12_205656| [ 1.71588e+00  1.54148e-01]
21Feb12_205656| [-6.76487e-01 -8.12632e-01]
21Feb12_205656| [-3.36077e-01  8.37814e-01]
21Feb12_205656| [-2.76932e+00  6.48499e-01]
21Feb12_205656| [ 7.03962e-01  1.39837e+00]
21Feb12_205656| [-7.94729e-01  1.53931e+00]
21Feb12_205656| [ 5.14315e-01 -5.46938e-01]
21Feb12_205656| [ 8.51602e-01 -1.17766e+00]
21Feb12_205656| [-9.85517e-01 -2.02046e-01]
21Feb12_205656| [ 3.57173e-01 -2.36309e-01]
21Feb12_205656| [ 7.72289e-01 -1.26733e-01]
21Feb12_205656| [ 7.81051e-01 -1.61717e-01]
21Feb12_205656| [ 7.70356e-01 -2.27992e-02]
21Feb12_205656| [ 3.25847e-01  8.66593e-01]
21Feb12_205656| [-1.98351e+00  7.29592e-01]
21Feb12_205656| [-1.29020e+00 -6.85880e-01]
21Feb12_205656| [ 4.80697e-01  1.13681e+00]
21Feb12_205656| [ 4.96277e-01 -6.97935e-01]
21Feb12_205656| [ 8.81560e-01  1.50973e+00]
21Feb12_205656| [ 8.05521e-01 -6.06217e-01]
21Feb12_205656| [-1.08425e+00  4.63923e-01]
21Feb12_205656| [ 4.73934e-01 -1.27724e+00]
21Feb12_205656| [-5.07898e-01  1.37824e+00]
21Feb12_205656| [ 4.23982e-01  2.30444e-01]
21Feb12_205656| [ 1.48713e+00 -1.34665e-01]
21Feb12_205656| [ 1.61202e+00 -2.03092e+00]
21Feb12_205656| [-2.30689e-03  9.62640e-01]
21Feb12_205656| [-5.07657e-01 -6.83144e-01]
21Feb12_205656| [ 1.53621e+00  6.19680e-01]
21Feb12_205656| [-9.82751e-02 -1.30833e+00]
21Feb12_205656| [ 1.29116e+00  6.90142e-01]
21Feb12_205656| [ 6.53734e-01 -1.53277e+00]
21Feb12_205656| [-4.15608e-01  3.10879e-01]
21Feb12_205656| [ 1.64881e+00 -1.12810e+00]
21Feb12_205656| [ 1.18432e+00  5.26616e-01]
21Feb12_205656| [ 5.24454e-01  5.80459e-01]
21Feb12_205656| [ 6.90033e-01 -1.87735e+00]
21Feb12_205656| [-3.65241e-01 -2.16301e-02]
21Feb12_205656| [-9.23377e-01  1.18759e+00]
21Feb12_205656| [-2.87730e-01  1.28595e-01]
21Feb12_205656| [ 2.18605e-02  1.06208e+00]
21Feb12_205656| [ 1.25212e+00 -1.86025e+00]
21Feb12_205656| [ 1.38061e+00 -3.03417e-01]
21Feb12_205656| [ 1.83639e-01  9.82415e-01]
21Feb12_205656| [ 1.05313e+00  1.65914e-01]
21Feb12_205656| [-4.71040e-01 -5.76519e-01]
21Feb12_205656| [-1.78462e+00 -7.53291e-01]
21Feb12_205656| [-8.51746e-02 -9.51482e-01]
21Feb12_205656| [-1.92042e+00  5.98504e-01]
21Feb12_205656| [-9.47328e-01  7.62275e-01]
21Feb12_205656| [-3.05419e+00 -2.01332e-01]
21Feb12_205656| [ 9.75110e-01 -8.15757e-01]
21Feb12_205656| [ 5.15170e-01  8.95748e-02]]
21Feb12_205656|-- Bias --
21Feb12_205656|[0.38753 0.10996]
21Feb12_205656|Layer 1:
21Feb12_205656|-- Config --
21Feb12_205656|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205656|-- Weights --
21Feb12_205656|[[-0.50910 -0.17092 -0.38272]
21Feb12_205656| [-0.45768  0.86120 -0.49544]]
21Feb12_205656|-- Bias --
21Feb12_205656|[-0.55242  0.77771  0.12946]
21Feb12_205656|Layer 2:
21Feb12_205656|-- Config --
21Feb12_205656|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205656|-- Weights --
21Feb12_205656|[[-0.57908 -0.77677]
21Feb12_205656| [ 0.69363 -0.30141]
21Feb12_205656| [ 0.01408  0.65954]]
21Feb12_205656|-- Bias --
21Feb12_205656|[ 0.24694 -0.01877]
21Feb12_205656|Predicting the validation and test data with the Best final individual.
21Feb12_205703| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_205703|-----------  ------------------  --------------------  ----------
21Feb12_205703|Validation         27.22                  10            0.66637
21Feb12_205703|   Test            43.53                  10            0.79016
21Feb12_205703|-------------------- Test #11 --------------------
21Feb12_205703|Best final individual weights
21Feb12_205703|Individual:
21Feb12_205703|-- Constant hidden layers --
21Feb12_205703|False
21Feb12_205703|Layer 0:
21Feb12_205703|-- Config --
21Feb12_205703|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205703|-- Weights --
21Feb12_205703|[[ 1.38403e+00  2.28864e-01]
21Feb12_205703| [ 6.34793e-02  1.17249e+00]
21Feb12_205703| [-5.52130e-01 -1.48663e-01]
21Feb12_205703| [ 2.68391e-01  1.34056e+00]
21Feb12_205703| [ 1.71588e+00  1.54148e-01]
21Feb12_205703| [-6.76487e-01 -8.12632e-01]
21Feb12_205703| [-3.36077e-01  8.37814e-01]
21Feb12_205703| [-2.76932e+00  6.48499e-01]
21Feb12_205703| [ 7.03962e-01  1.39837e+00]
21Feb12_205703| [-7.94729e-01  1.53931e+00]
21Feb12_205703| [ 5.14315e-01 -5.46938e-01]
21Feb12_205703| [ 8.51602e-01 -1.17766e+00]
21Feb12_205703| [-9.85517e-01 -2.02046e-01]
21Feb12_205703| [ 3.57173e-01 -2.36309e-01]
21Feb12_205703| [ 7.72289e-01 -1.26733e-01]
21Feb12_205703| [ 7.81051e-01 -1.61717e-01]
21Feb12_205703| [ 7.70356e-01 -2.27992e-02]
21Feb12_205703| [ 3.25847e-01  8.66593e-01]
21Feb12_205703| [-1.98351e+00  7.29592e-01]
21Feb12_205703| [-1.29020e+00 -6.85880e-01]
21Feb12_205703| [ 4.80697e-01  1.13681e+00]
21Feb12_205703| [ 4.96277e-01 -6.97935e-01]
21Feb12_205703| [ 8.81560e-01  1.50973e+00]
21Feb12_205703| [ 8.05521e-01 -6.06217e-01]
21Feb12_205703| [-1.08425e+00  4.63923e-01]
21Feb12_205703| [ 4.73934e-01 -1.27724e+00]
21Feb12_205703| [-5.07898e-01  1.37824e+00]
21Feb12_205703| [ 4.23982e-01  2.30444e-01]
21Feb12_205703| [ 1.48713e+00 -1.34665e-01]
21Feb12_205703| [ 1.61202e+00 -2.03092e+00]
21Feb12_205703| [-2.30689e-03  9.62640e-01]
21Feb12_205703| [-5.07657e-01 -6.83144e-01]
21Feb12_205703| [ 1.53621e+00  6.19680e-01]
21Feb12_205703| [-9.82751e-02 -1.30833e+00]
21Feb12_205703| [ 1.29116e+00  6.90142e-01]
21Feb12_205703| [ 6.53734e-01 -1.53277e+00]
21Feb12_205703| [-4.15608e-01  3.10879e-01]
21Feb12_205703| [ 1.64881e+00 -1.12810e+00]
21Feb12_205703| [ 1.18432e+00  5.26616e-01]
21Feb12_205703| [ 5.24454e-01  5.80459e-01]
21Feb12_205703| [ 6.90033e-01 -1.87735e+00]
21Feb12_205703| [-3.65241e-01 -2.16301e-02]
21Feb12_205703| [-9.23377e-01  1.18759e+00]
21Feb12_205703| [-2.87730e-01  1.28595e-01]
21Feb12_205703| [ 2.18605e-02  1.06208e+00]
21Feb12_205703| [ 1.25212e+00 -1.86025e+00]
21Feb12_205703| [ 1.38061e+00 -3.03417e-01]
21Feb12_205703| [ 1.83639e-01  9.82415e-01]
21Feb12_205703| [ 1.05313e+00  1.65914e-01]
21Feb12_205703| [-4.71040e-01 -5.76519e-01]
21Feb12_205703| [-1.78462e+00 -7.53291e-01]
21Feb12_205703| [-8.51746e-02 -9.51482e-01]
21Feb12_205703| [-1.92042e+00  5.98504e-01]
21Feb12_205703| [-9.47328e-01  7.62275e-01]
21Feb12_205703| [-3.05419e+00 -2.01332e-01]
21Feb12_205703| [ 9.75110e-01 -8.15757e-01]
21Feb12_205703| [ 5.15170e-01  8.95748e-02]]
21Feb12_205703|-- Bias --
21Feb12_205703|[0.38753 0.10996]
21Feb12_205703|Layer 1:
21Feb12_205703|-- Config --
21Feb12_205703|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205703|-- Weights --
21Feb12_205703|[[-0.50910 -0.17092 -0.38272]
21Feb12_205703| [-0.45768  0.86120 -0.49544]]
21Feb12_205703|-- Bias --
21Feb12_205703|[-0.55242  0.77771  0.12946]
21Feb12_205703|Layer 2:
21Feb12_205703|-- Config --
21Feb12_205703|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205703|-- Weights --
21Feb12_205703|[[-0.57908 -0.77677]
21Feb12_205703| [ 0.69363 -0.30141]
21Feb12_205703| [ 0.01408  0.65954]]
21Feb12_205703|-- Bias --
21Feb12_205703|[ 0.24694 -0.01877]
21Feb12_205703|Predicting the validation and test data with the Best final individual.
21Feb12_205710| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_205710|-----------  ------------------  --------------------  ----------
21Feb12_205710|Validation         42.17                  10            0.78213
21Feb12_205710|   Test            39.01                  10            0.00000
21Feb12_205710|-------------------- Test #12 --------------------
21Feb12_205710|Best final individual weights
21Feb12_205710|Individual:
21Feb12_205710|-- Constant hidden layers --
21Feb12_205710|False
21Feb12_205710|Layer 0:
21Feb12_205710|-- Config --
21Feb12_205710|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205710|-- Weights --
21Feb12_205710|[[ 1.38403e+00  2.28864e-01]
21Feb12_205710| [ 6.34793e-02  1.17249e+00]
21Feb12_205710| [-5.52130e-01 -1.48663e-01]
21Feb12_205710| [ 2.68391e-01  1.34056e+00]
21Feb12_205710| [ 1.71588e+00  1.54148e-01]
21Feb12_205710| [-6.76487e-01 -8.12632e-01]
21Feb12_205710| [-3.36077e-01  8.37814e-01]
21Feb12_205710| [-2.76932e+00  6.48499e-01]
21Feb12_205710| [ 7.03962e-01  1.39837e+00]
21Feb12_205710| [-7.94729e-01  1.53931e+00]
21Feb12_205710| [ 5.14315e-01 -5.46938e-01]
21Feb12_205710| [ 8.51602e-01 -1.17766e+00]
21Feb12_205710| [-9.85517e-01 -2.02046e-01]
21Feb12_205710| [ 3.57173e-01 -2.36309e-01]
21Feb12_205710| [ 7.72289e-01 -1.26733e-01]
21Feb12_205710| [ 7.81051e-01 -1.61717e-01]
21Feb12_205710| [ 7.70356e-01 -2.27992e-02]
21Feb12_205710| [ 3.25847e-01  8.66593e-01]
21Feb12_205710| [-1.98351e+00  7.29592e-01]
21Feb12_205710| [-1.29020e+00 -6.85880e-01]
21Feb12_205710| [ 4.80697e-01  1.13681e+00]
21Feb12_205710| [ 4.96277e-01 -6.97935e-01]
21Feb12_205710| [ 8.81560e-01  1.50973e+00]
21Feb12_205710| [ 8.05521e-01 -6.06217e-01]
21Feb12_205710| [-1.08425e+00  4.63923e-01]
21Feb12_205710| [ 4.73934e-01 -1.27724e+00]
21Feb12_205710| [-5.07898e-01  1.37824e+00]
21Feb12_205710| [ 4.23982e-01  2.30444e-01]
21Feb12_205710| [ 1.48713e+00 -1.34665e-01]
21Feb12_205710| [ 1.61202e+00 -2.03092e+00]
21Feb12_205710| [-2.30689e-03  9.62640e-01]
21Feb12_205710| [-5.07657e-01 -6.83144e-01]
21Feb12_205710| [ 1.53621e+00  6.19680e-01]
21Feb12_205710| [-9.82751e-02 -1.30833e+00]
21Feb12_205710| [ 1.29116e+00  6.90142e-01]
21Feb12_205710| [ 6.53734e-01 -1.53277e+00]
21Feb12_205710| [-4.15608e-01  3.10879e-01]
21Feb12_205710| [ 1.64881e+00 -1.12810e+00]
21Feb12_205710| [ 1.18432e+00  5.26616e-01]
21Feb12_205710| [ 5.24454e-01  5.80459e-01]
21Feb12_205710| [ 6.90033e-01 -1.87735e+00]
21Feb12_205710| [-3.65241e-01 -2.16301e-02]
21Feb12_205710| [-9.23377e-01  1.18759e+00]
21Feb12_205710| [-2.87730e-01  1.28595e-01]
21Feb12_205710| [ 2.18605e-02  1.06208e+00]
21Feb12_205710| [ 1.25212e+00 -1.86025e+00]
21Feb12_205710| [ 1.38061e+00 -3.03417e-01]
21Feb12_205710| [ 1.83639e-01  9.82415e-01]
21Feb12_205710| [ 1.05313e+00  1.65914e-01]
21Feb12_205710| [-4.71040e-01 -5.76519e-01]
21Feb12_205710| [-1.78462e+00 -7.53291e-01]
21Feb12_205710| [-8.51746e-02 -9.51482e-01]
21Feb12_205710| [-1.92042e+00  5.98504e-01]
21Feb12_205710| [-9.47328e-01  7.62275e-01]
21Feb12_205710| [-3.05419e+00 -2.01332e-01]
21Feb12_205710| [ 9.75110e-01 -8.15757e-01]
21Feb12_205710| [ 5.15170e-01  8.95748e-02]]
21Feb12_205710|-- Bias --
21Feb12_205710|[0.38753 0.10996]
21Feb12_205710|Layer 1:
21Feb12_205710|-- Config --
21Feb12_205710|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205710|-- Weights --
21Feb12_205710|[[-0.50910 -0.17092 -0.38272]
21Feb12_205710| [-0.45768  0.86120 -0.49544]]
21Feb12_205710|-- Bias --
21Feb12_205710|[-0.55242  0.77771  0.12946]
21Feb12_205710|Layer 2:
21Feb12_205710|-- Config --
21Feb12_205710|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205710|-- Weights --
21Feb12_205710|[[-0.57908 -0.77677]
21Feb12_205710| [ 0.69363 -0.30141]
21Feb12_205710| [ 0.01408  0.65954]]
21Feb12_205710|-- Bias --
21Feb12_205710|[ 0.24694 -0.01877]
21Feb12_205710|Predicting the validation and test data with the Best final individual.
21Feb12_205718| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_205718|-----------  ------------------  --------------------  ----------
21Feb12_205718|Validation         51.65                  10            0.78480
21Feb12_205718|   Test            39.01                  10            0.00000
21Feb12_205718|-------------------- Test #13 --------------------
21Feb12_205718|Best final individual weights
21Feb12_205718|Individual:
21Feb12_205718|-- Constant hidden layers --
21Feb12_205718|False
21Feb12_205718|Layer 0:
21Feb12_205718|-- Config --
21Feb12_205718|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205718|-- Weights --
21Feb12_205718|[[ 1.38403e+00  2.28864e-01]
21Feb12_205718| [ 6.34793e-02  1.17249e+00]
21Feb12_205718| [-5.52130e-01 -1.48663e-01]
21Feb12_205718| [ 2.68391e-01  1.34056e+00]
21Feb12_205718| [ 1.71588e+00  1.54148e-01]
21Feb12_205718| [-6.76487e-01 -8.12632e-01]
21Feb12_205718| [-3.36077e-01  8.37814e-01]
21Feb12_205718| [-2.76932e+00  6.48499e-01]
21Feb12_205718| [ 7.03962e-01  1.39837e+00]
21Feb12_205718| [-7.94729e-01  1.53931e+00]
21Feb12_205718| [ 5.14315e-01 -5.46938e-01]
21Feb12_205718| [ 8.51602e-01 -1.17766e+00]
21Feb12_205718| [-9.85517e-01 -2.02046e-01]
21Feb12_205718| [ 3.57173e-01 -2.36309e-01]
21Feb12_205718| [ 7.72289e-01 -1.26733e-01]
21Feb12_205718| [ 7.81051e-01 -1.61717e-01]
21Feb12_205718| [ 7.70356e-01 -2.27992e-02]
21Feb12_205718| [ 3.25847e-01  8.66593e-01]
21Feb12_205718| [-1.98351e+00  7.29592e-01]
21Feb12_205718| [-1.29020e+00 -6.85880e-01]
21Feb12_205718| [ 4.80697e-01  1.13681e+00]
21Feb12_205718| [ 4.96277e-01 -6.97935e-01]
21Feb12_205718| [ 8.81560e-01  1.50973e+00]
21Feb12_205718| [ 8.05521e-01 -6.06217e-01]
21Feb12_205718| [-1.08425e+00  4.63923e-01]
21Feb12_205718| [ 4.73934e-01 -1.27724e+00]
21Feb12_205718| [-5.07898e-01  1.37824e+00]
21Feb12_205718| [ 4.23982e-01  2.30444e-01]
21Feb12_205718| [ 1.48713e+00 -1.34665e-01]
21Feb12_205718| [ 1.61202e+00 -2.03092e+00]
21Feb12_205718| [-2.30689e-03  9.62640e-01]
21Feb12_205718| [-5.07657e-01 -6.83144e-01]
21Feb12_205718| [ 1.53621e+00  6.19680e-01]
21Feb12_205718| [-9.82751e-02 -1.30833e+00]
21Feb12_205718| [ 1.29116e+00  6.90142e-01]
21Feb12_205718| [ 6.53734e-01 -1.53277e+00]
21Feb12_205718| [-4.15608e-01  3.10879e-01]
21Feb12_205718| [ 1.64881e+00 -1.12810e+00]
21Feb12_205718| [ 1.18432e+00  5.26616e-01]
21Feb12_205718| [ 5.24454e-01  5.80459e-01]
21Feb12_205718| [ 6.90033e-01 -1.87735e+00]
21Feb12_205718| [-3.65241e-01 -2.16301e-02]
21Feb12_205718| [-9.23377e-01  1.18759e+00]
21Feb12_205718| [-2.87730e-01  1.28595e-01]
21Feb12_205718| [ 2.18605e-02  1.06208e+00]
21Feb12_205718| [ 1.25212e+00 -1.86025e+00]
21Feb12_205718| [ 1.38061e+00 -3.03417e-01]
21Feb12_205718| [ 1.83639e-01  9.82415e-01]
21Feb12_205718| [ 1.05313e+00  1.65914e-01]
21Feb12_205718| [-4.71040e-01 -5.76519e-01]
21Feb12_205718| [-1.78462e+00 -7.53291e-01]
21Feb12_205718| [-8.51746e-02 -9.51482e-01]
21Feb12_205718| [-1.92042e+00  5.98504e-01]
21Feb12_205718| [-9.47328e-01  7.62275e-01]
21Feb12_205718| [-3.05419e+00 -2.01332e-01]
21Feb12_205718| [ 9.75110e-01 -8.15757e-01]
21Feb12_205718| [ 5.15170e-01  8.95748e-02]]
21Feb12_205718|-- Bias --
21Feb12_205718|[0.38753 0.10996]
21Feb12_205718|Layer 1:
21Feb12_205718|-- Config --
21Feb12_205718|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205718|-- Weights --
21Feb12_205718|[[-0.50910 -0.17092 -0.38272]
21Feb12_205718| [-0.45768  0.86120 -0.49544]]
21Feb12_205718|-- Bias --
21Feb12_205718|[-0.55242  0.77771  0.12946]
21Feb12_205718|Layer 2:
21Feb12_205718|-- Config --
21Feb12_205718|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205718|-- Weights --
21Feb12_205718|[[-0.57908 -0.77677]
21Feb12_205718| [ 0.69363 -0.30141]
21Feb12_205718| [ 0.01408  0.65954]]
21Feb12_205718|-- Bias --
21Feb12_205718|[ 0.24694 -0.01877]
21Feb12_205718|Predicting the validation and test data with the Best final individual.
21Feb12_205725| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_205725|-----------  ------------------  --------------------  ----------
21Feb12_205725|Validation         27.04                  10            0.66533
21Feb12_205725|   Test            39.01                  10            0.00000
21Feb12_205725|-------------------- Test #14 --------------------
21Feb12_205725|Best final individual weights
21Feb12_205725|Individual:
21Feb12_205725|-- Constant hidden layers --
21Feb12_205725|False
21Feb12_205725|Layer 0:
21Feb12_205725|-- Config --
21Feb12_205725|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205725|-- Weights --
21Feb12_205725|[[ 1.38403e+00  2.28864e-01]
21Feb12_205725| [ 6.34793e-02  1.17249e+00]
21Feb12_205725| [-5.52130e-01 -1.48663e-01]
21Feb12_205725| [ 2.68391e-01  1.34056e+00]
21Feb12_205725| [ 1.71588e+00  1.54148e-01]
21Feb12_205725| [-6.76487e-01 -8.12632e-01]
21Feb12_205725| [-3.36077e-01  8.37814e-01]
21Feb12_205725| [-2.76932e+00  6.48499e-01]
21Feb12_205725| [ 7.03962e-01  1.39837e+00]
21Feb12_205725| [-7.94729e-01  1.53931e+00]
21Feb12_205725| [ 5.14315e-01 -5.46938e-01]
21Feb12_205725| [ 8.51602e-01 -1.17766e+00]
21Feb12_205725| [-9.85517e-01 -2.02046e-01]
21Feb12_205725| [ 3.57173e-01 -2.36309e-01]
21Feb12_205725| [ 7.72289e-01 -1.26733e-01]
21Feb12_205725| [ 7.81051e-01 -1.61717e-01]
21Feb12_205725| [ 7.70356e-01 -2.27992e-02]
21Feb12_205725| [ 3.25847e-01  8.66593e-01]
21Feb12_205725| [-1.98351e+00  7.29592e-01]
21Feb12_205725| [-1.29020e+00 -6.85880e-01]
21Feb12_205725| [ 4.80697e-01  1.13681e+00]
21Feb12_205725| [ 4.96277e-01 -6.97935e-01]
21Feb12_205725| [ 8.81560e-01  1.50973e+00]
21Feb12_205725| [ 8.05521e-01 -6.06217e-01]
21Feb12_205725| [-1.08425e+00  4.63923e-01]
21Feb12_205725| [ 4.73934e-01 -1.27724e+00]
21Feb12_205725| [-5.07898e-01  1.37824e+00]
21Feb12_205725| [ 4.23982e-01  2.30444e-01]
21Feb12_205725| [ 1.48713e+00 -1.34665e-01]
21Feb12_205725| [ 1.61202e+00 -2.03092e+00]
21Feb12_205725| [-2.30689e-03  9.62640e-01]
21Feb12_205725| [-5.07657e-01 -6.83144e-01]
21Feb12_205725| [ 1.53621e+00  6.19680e-01]
21Feb12_205725| [-9.82751e-02 -1.30833e+00]
21Feb12_205725| [ 1.29116e+00  6.90142e-01]
21Feb12_205725| [ 6.53734e-01 -1.53277e+00]
21Feb12_205725| [-4.15608e-01  3.10879e-01]
21Feb12_205725| [ 1.64881e+00 -1.12810e+00]
21Feb12_205725| [ 1.18432e+00  5.26616e-01]
21Feb12_205725| [ 5.24454e-01  5.80459e-01]
21Feb12_205725| [ 6.90033e-01 -1.87735e+00]
21Feb12_205725| [-3.65241e-01 -2.16301e-02]
21Feb12_205725| [-9.23377e-01  1.18759e+00]
21Feb12_205725| [-2.87730e-01  1.28595e-01]
21Feb12_205725| [ 2.18605e-02  1.06208e+00]
21Feb12_205725| [ 1.25212e+00 -1.86025e+00]
21Feb12_205725| [ 1.38061e+00 -3.03417e-01]
21Feb12_205725| [ 1.83639e-01  9.82415e-01]
21Feb12_205725| [ 1.05313e+00  1.65914e-01]
21Feb12_205725| [-4.71040e-01 -5.76519e-01]
21Feb12_205725| [-1.78462e+00 -7.53291e-01]
21Feb12_205725| [-8.51746e-02 -9.51482e-01]
21Feb12_205725| [-1.92042e+00  5.98504e-01]
21Feb12_205725| [-9.47328e-01  7.62275e-01]
21Feb12_205725| [-3.05419e+00 -2.01332e-01]
21Feb12_205725| [ 9.75110e-01 -8.15757e-01]
21Feb12_205725| [ 5.15170e-01  8.95748e-02]]
21Feb12_205725|-- Bias --
21Feb12_205725|[0.38753 0.10996]
21Feb12_205725|Layer 1:
21Feb12_205725|-- Config --
21Feb12_205725|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205725|-- Weights --
21Feb12_205725|[[-0.50910 -0.17092 -0.38272]
21Feb12_205725| [-0.45768  0.86120 -0.49544]]
21Feb12_205725|-- Bias --
21Feb12_205725|[-0.55242  0.77771  0.12946]
21Feb12_205725|Layer 2:
21Feb12_205725|-- Config --
21Feb12_205725|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_205725|-- Weights --
21Feb12_205725|[[-0.57908 -0.77677]
21Feb12_205725| [ 0.69363 -0.30141]
21Feb12_205725| [ 0.01408  0.65954]]
21Feb12_205725|-- Bias --
21Feb12_205725|[ 0.24694 -0.01877]
21Feb12_205725|Predicting the validation and test data with the Best final individual.
21Feb12_205733| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_205733|-----------  ------------------  --------------------  ----------
21Feb12_205733|Validation         35.04                  10            0.23661
21Feb12_205733|   Test            35.71                  10            0.34559
2021-02-12 20:57:34.010287: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
21Feb12_205734|Data summary: Train
21Feb12_205734|data.shape = (2300, 57)
21Feb12_205734|labels.shape = (2300,)
21Feb12_205734|Class distribution:
21Feb12_205734|	0 - 1382 (0.60)
21Feb12_205734|	1 - 918 (0.40)
21Feb12_205734|Data summary: Validation
21Feb12_205734|data.shape = (1150, 57)
21Feb12_205734|labels.shape = (1150,)
21Feb12_205734|Class distribution:
21Feb12_205734|	0 - 704 (0.61)
21Feb12_205734|	1 - 446 (0.39)
21Feb12_205734|Data summary: Test
21Feb12_205734|data.shape = (1151, 57)
21Feb12_205734|labels.shape = (1151,)
21Feb12_205734|Class distribution:
21Feb12_205734|	0 - 702 (0.61)
21Feb12_205734|	1 - 449 (0.39)
21Feb12_205734|Selected configuration values
21Feb12_205734|-- Dataset name: spambase1
21Feb12_205734|-- Initial population size: 64
21Feb12_205734|-- Maximun number of generations: 32
21Feb12_205734|-- Neurons per hidden layer range: (2, 20)
21Feb12_205734|-- Hidden layers number range: (1, 3)
21Feb12_205734|-- Crossover probability: 0.5
21Feb12_205734|-- Bias gene mutation probability: 0.2
21Feb12_205734|-- Weights gene mutation probability: 0.75
21Feb12_205734|-- Neuron mutation probability: 0.3
21Feb12_205734|-- Layer mutation probability: 0.3
21Feb12_205734|-- Constant hidden layers: False
21Feb12_205734|-- Seed: 31415
21Feb12_205734|Entering GA
21Feb12_205734|Start the algorithm
2021-02-12 20:57:34.885483: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-12 20:57:34.886051: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-02-12 20:57:34.906922: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-12 20:57:34.907268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.71GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s
2021-02-12 20:57:34.907285: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-02-12 20:57:34.908788: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-02-12 20:57:34.908826: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-02-12 20:57:34.909335: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-02-12 20:57:34.909470: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-02-12 20:57:34.909543: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-12 20:57:34.909962: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-02-12 20:57:34.910006: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-12 20:57:34.910012: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-02-12 20:57:34.910280: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-02-12 20:57:34.911264: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-12 20:57:34.911292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-12 20:57:34.911296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      
2021-02-12 20:57:34.962765: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-02-12 20:57:34.963098: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3493635000 Hz
/home/jmerelo/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype("int32")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn('`model.predict_classes()` is deprecated and '
21Feb12_210140|-- Generation 1 --
21Feb12_210140|    -- Crossed 0 individual pairs.
21Feb12_210140|    -- Mutated 32 individuals.
21Feb12_210545|    -- Evaluated 64 individuals.
21Feb12_210545|    Summary of generation 1:
21Feb12_210545| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_210545|-----------  ------------------  --------------------  ----------
21Feb12_210545|    Max            54.61                180.00          0.77906
21Feb12_210545|    Avg            38.93                47.41           0.02038
21Feb12_210545|    Min            26.09                 3.00           0.00000
21Feb12_210545|    Std             2.54                41.33           0.11569
21Feb12_210545|   Best            26.09                120.00          0.52555
21Feb12_210545|-- Generation 2 --
21Feb12_210545|    -- Crossed 2 individual pairs.
21Feb12_210545|    -- Mutated 32 individuals.
21Feb12_210948|    -- Evaluated 64 individuals.
21Feb12_210948|    Summary of generation 2:
21Feb12_210948| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_210948|-----------  ------------------  --------------------  ----------
21Feb12_210948|    Max            39.57                123.00          0.70496
21Feb12_210948|    Avg            38.28                46.33           0.02751
21Feb12_210948|    Min            25.57                 3.00           0.00000
21Feb12_210948|    Std             2.65                37.75           0.12536
21Feb12_210948|   Best            25.57                54.00           0.51942
21Feb12_210948|-- Generation 3 --
21Feb12_210948|    -- Crossed 2 individual pairs.
21Feb12_210948|    -- Mutated 32 individuals.
21Feb12_211351|    -- Evaluated 64 individuals.
21Feb12_211351|    Summary of generation 3:
21Feb12_211351| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_211351|-----------  ------------------  --------------------  ----------
21Feb12_211351|    Max            39.39                100.00          0.38872
21Feb12_211351|    Avg            38.52                29.75           0.01219
21Feb12_211351|    Min            28.17                 3.00           0.00000
21Feb12_211351|    Std             1.86                23.94           0.06594
21Feb12_211351|   Best            28.17                54.00           0.38872
21Feb12_211351|-- Generation 4 --
21Feb12_211351|    -- Crossed 3 individual pairs.
21Feb12_211351|    -- Mutated 32 individuals.
21Feb12_211749|    -- Evaluated 64 individuals.
21Feb12_211749|    Summary of generation 4:
21Feb12_211749| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_211749|-----------  ------------------  --------------------  ----------
21Feb12_211749|    Max            53.74                54.00           0.78301
21Feb12_211749|    Avg            38.52                16.06           0.04134
21Feb12_211749|    Min            24.52                 2.00           0.00000
21Feb12_211749|    Std             3.15                12.11           0.16194
21Feb12_211749|   Best            24.52                14.00           0.52439
21Feb12_211749|-- Generation 5 --
21Feb12_211749|    -- Crossed 1 individual pairs.
21Feb12_211749|    -- Mutated 32 individuals.
21Feb12_212144|    -- Evaluated 64 individuals.
21Feb12_212144|    Summary of generation 5:
21Feb12_212144| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_212144|-----------  ------------------  --------------------  ----------
21Feb12_212144|    Max            39.30                22.00           0.52797
21Feb12_212144|    Avg            38.25                 9.59           0.02233
21Feb12_212144|    Min            25.91                 2.00           0.00000
21Feb12_212144|    Std             2.53                 5.88           0.09934
21Feb12_212144|   Best            25.91                18.00           0.52797
21Feb12_212144|-- Generation 6 --
21Feb12_212144|    -- Crossed 4 individual pairs.
21Feb12_212144|    -- Mutated 32 individuals.
21Feb12_212538|    -- Evaluated 64 individuals.
21Feb12_212538|    Summary of generation 6:
21Feb12_212538| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_212538|-----------  ------------------  --------------------  ----------
21Feb12_212538|    Max            39.13                36.00           0.66605
21Feb12_212538|    Avg            37.98                 8.05           0.03350
21Feb12_212538|    Min            22.52                 2.00           0.00000
21Feb12_212538|    Std             3.28                 6.96           0.13205
21Feb12_212538|   Best            22.52                36.00           0.66605
21Feb12_212538|-- Generation 7 --
21Feb12_212538|    -- Crossed 9 individual pairs.
21Feb12_212538|    -- Mutated 32 individuals.
21Feb12_212932|    -- Evaluated 64 individuals.
21Feb12_212932|    Summary of generation 7:
21Feb12_212932| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_212932|-----------  ------------------  --------------------  ----------
21Feb12_212932|    Max            39.13                44.00           0.71779
21Feb12_212932|    Avg            38.14                 7.53           0.02678
21Feb12_212932|    Min            22.70                 2.00           0.00000
21Feb12_212932|    Std             3.05                 8.58           0.12270
21Feb12_212932|   Best            22.70                36.00           0.71779
21Feb12_212932|-- Generation 8 --
21Feb12_212932|    -- Crossed 8 individual pairs.
21Feb12_212932|    -- Mutated 32 individuals.
21Feb12_213323|    -- Evaluated 64 individuals.
21Feb12_213323|    Summary of generation 8:
21Feb12_213323| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_213323|-----------  ------------------  --------------------  ----------
21Feb12_213323|    Max            39.22                48.00           0.50608
21Feb12_213323|    Avg            38.40                 6.84           0.01561
21Feb12_213323|    Min            25.30                 2.00           0.00000
21Feb12_213323|    Std             2.28                 9.01           0.08691
21Feb12_213323|   Best            25.30                18.00           0.49285
21Feb12_213323|-- Generation 9 --
21Feb12_213323|    -- Crossed 7 individual pairs.
21Feb12_213323|    -- Mutated 32 individuals.
21Feb12_213715|    -- Evaluated 64 individuals.
21Feb12_213715|    Summary of generation 9:
21Feb12_213715| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_213715|-----------  ------------------  --------------------  ----------
21Feb12_213715|    Max            39.13                21.00           0.55026
21Feb12_213715|    Avg            38.22                 5.39           0.02301
21Feb12_213715|    Min            26.00                 2.00           0.00000
21Feb12_213715|    Std             2.52                 5.09           0.10050
21Feb12_213715|   Best            26.00                18.00           0.55026
21Feb12_213715|-- Generation 10 --
21Feb12_213715|    -- Crossed 9 individual pairs.
21Feb12_213715|    -- Mutated 32 individuals.
21Feb12_214107|    -- Evaluated 64 individuals.
21Feb12_214107|    Summary of generation 10:
21Feb12_214107| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_214107|-----------  ------------------  --------------------  ----------
21Feb12_214107|    Max            39.13                21.00           0.76793
21Feb12_214107|    Avg            38.08                 5.44           0.03244
21Feb12_214107|    Min            24.17                 2.00           0.00000
21Feb12_214107|    Std             2.78                 5.29           0.12835
21Feb12_214107|   Best            24.17                21.00           0.51181
21Feb12_214107|-- Generation 11 --
21Feb12_214107|    -- Crossed 8 individual pairs.
21Feb12_214107|    -- Mutated 32 individuals.
21Feb12_214501|    -- Evaluated 64 individuals.
21Feb12_214501|    Summary of generation 11:
21Feb12_214501| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_214501|-----------  ------------------  --------------------  ----------
21Feb12_214501|    Max            39.22                40.00           0.81540
21Feb12_214501|    Avg            38.07                 6.50           0.04413
21Feb12_214501|    Min            24.70                 2.00           0.00000
21Feb12_214501|    Std             2.88                 7.32           0.15534
21Feb12_214501|   Best            24.70                21.00           0.52388
21Feb12_214501|-- Generation 12 --
21Feb12_214501|    -- Crossed 5 individual pairs.
21Feb12_214501|    -- Mutated 32 individuals.
21Feb12_214853|    -- Evaluated 64 individuals.
21Feb12_214853|    Summary of generation 12:
21Feb12_214853| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_214853|-----------  ------------------  --------------------  ----------
21Feb12_214853|    Max            39.13                48.00           0.59436
21Feb12_214853|    Avg            38.22                 5.28           0.02470
21Feb12_214853|    Min            26.96                 2.00           0.00000
21Feb12_214853|    Std             2.37                 7.47           0.10313
21Feb12_214853|   Best            26.96                21.00           0.59436
21Feb12_214853|-- Generation 13 --
21Feb12_214853|    -- Crossed 7 individual pairs.
21Feb12_214853|    -- Mutated 32 individuals.
21Feb12_215244|    -- Evaluated 64 individuals.
21Feb12_215244|    Summary of generation 13:
21Feb12_215244| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_215244|-----------  ------------------  --------------------  ----------
21Feb12_215244|    Max            39.13                21.00           0.61111
21Feb12_215244|    Avg            38.35                 4.25           0.01866
21Feb12_215244|    Min            25.57                 2.00           0.00000
21Feb12_215244|    Std             2.29                 5.17           0.09443
21Feb12_215244|   Best            25.57                21.00           0.61111
21Feb12_215244|-- Generation 14 --
21Feb12_215244|    -- Crossed 6 individual pairs.
21Feb12_215244|    -- Mutated 32 individuals.
21Feb12_215635|    -- Evaluated 64 individuals.
21Feb12_215635|    Summary of generation 14:
21Feb12_215635| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_215635|-----------  ------------------  --------------------  ----------
21Feb12_215635|    Max            38.96                21.00           0.74882
21Feb12_215635|    Avg            37.77                 4.80           0.04551
21Feb12_215635|    Min            25.13                 2.00           0.00000
21Feb12_215635|    Std             3.52                 5.41           0.15815
21Feb12_215635|   Best            25.13                16.00           0.53217
21Feb12_215635|-- Generation 15 --
21Feb12_215635|    -- Crossed 7 individual pairs.
21Feb12_215635|    -- Mutated 32 individuals.
21Feb12_220028|    -- Evaluated 64 individuals.
21Feb12_220028|    Summary of generation 15:
21Feb12_220028| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_220028|-----------  ------------------  --------------------  ----------
21Feb12_220028|    Max            39.91                21.00           0.54515
21Feb12_220028|    Avg            38.32                 4.95           0.01938
21Feb12_220028|    Min            25.22                 2.00           0.00000
21Feb12_220028|    Std             2.35                 5.13           0.09596
21Feb12_220028|   Best            25.22                21.00           0.54515
21Feb12_220028|-- Generation 16 --
21Feb12_220028|    -- Crossed 6 individual pairs.
21Feb12_220028|    -- Mutated 32 individuals.
21Feb12_220420|    -- Evaluated 64 individuals.
21Feb12_220420|    Summary of generation 16:
21Feb12_220420| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_220420|-----------  ------------------  --------------------  ----------
21Feb12_220420|    Max            51.04                21.00           0.79162
21Feb12_220420|    Avg            37.97                 5.16           0.05294
21Feb12_220420|    Min            23.74                 2.00           0.00000
21Feb12_220420|    Std             3.67                 5.56           0.16216
21Feb12_220420|   Best            23.74                21.00           0.54964
21Feb12_220420|-- Generation 17 --
21Feb12_220420|    -- Crossed 5 individual pairs.
21Feb12_220420|    -- Mutated 32 individuals.
21Feb12_220813|    -- Evaluated 64 individuals.
21Feb12_220813|    Summary of generation 17:
21Feb12_220813| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_220813|-----------  ------------------  --------------------  ----------
21Feb12_220813|    Max            38.96                21.00           0.68658
21Feb12_220813|    Avg            37.60                 5.42           0.05249
21Feb12_220813|    Min            25.13                 2.00           0.00000
21Feb12_220813|    Std             3.69                 5.68           0.16598
21Feb12_220813|   Best            25.13                10.00           0.68658
21Feb12_220813|-- Generation 18 --
21Feb12_220813|    -- Crossed 6 individual pairs.
21Feb12_220813|    -- Mutated 32 individuals.
21Feb12_221205|    -- Evaluated 64 individuals.
21Feb12_221205|    Summary of generation 18:
21Feb12_221205| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_221205|-----------  ------------------  --------------------  ----------
21Feb12_221205|    Max            39.04                24.00           0.77688
21Feb12_221205|    Avg            36.68                 5.12           0.09920
21Feb12_221205|    Min            23.74                 2.00           0.00000
21Feb12_221205|    Std             4.61                 5.30           0.21957
21Feb12_221205|   Best            23.74                10.00           0.71555
21Feb12_221205|-- Generation 19 --
21Feb12_221205|    -- Crossed 7 individual pairs.
21Feb12_221205|    -- Mutated 32 individuals.
21Feb12_221601|    -- Evaluated 64 individuals.
21Feb12_221601|    Summary of generation 19:
21Feb12_221601| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_221601|-----------  ------------------  --------------------  ----------
21Feb12_221601|    Max            44.87                40.00           0.79219
21Feb12_221601|    Avg            37.17                 7.06           0.08901
21Feb12_221601|    Min            23.65                 2.00           0.00000
21Feb12_221601|    Std             4.20                 7.87           0.19634
21Feb12_221601|   Best            23.65                24.00           0.59422
21Feb12_221601|-- Generation 20 --
21Feb12_221601|    -- Crossed 7 individual pairs.
21Feb12_221601|    -- Mutated 32 individuals.
21Feb12_221955|    -- Evaluated 64 individuals.
21Feb12_221955|    Summary of generation 20:
21Feb12_221955| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_221955|-----------  ------------------  --------------------  ----------
21Feb12_221955|    Max            41.13                40.00           0.55660
21Feb12_221955|    Avg            37.57                 7.61           0.05243
21Feb12_221955|    Min            25.48                 2.00           0.00000
21Feb12_221955|    Std             3.74                 8.46           0.15263
21Feb12_221955|   Best            25.48                21.00           0.53494
21Feb12_221955|The fitness has not improved in 10 generations:
21Feb12_221955|	Previous best fit: (25.47826086956522, 21.0, 0.5349397590361445)
21Feb12_221955|	Current best fit: (25.47826086956522, 21.0, 0.5349397590361445)
21Feb12_221955|Exiting...
21Feb12_221955|Best initial individual weights
21Feb12_221955|Individual:
21Feb12_221955|-- Constant hidden layers --
21Feb12_221955|False
21Feb12_221955|Layer 0:
21Feb12_221955|-- Config --
21Feb12_221955|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_221955|-- Weights --
21Feb12_221955|[[ 0.21414  0.89554 -0.09577]
21Feb12_221955| [ 0.29927  0.38469 -0.86620]
21Feb12_221955| [ 0.39643 -0.36944 -0.50463]
21Feb12_221955| [ 0.75139 -0.24290  0.11039]
21Feb12_221955| [-0.65666 -0.57758 -0.34589]
21Feb12_221955| [ 0.76973 -0.59810 -0.93414]
21Feb12_221955| [ 0.52152  0.55960 -0.90126]
21Feb12_221955| [-0.70248  0.97109  0.22446]
21Feb12_221955| [ 0.96280 -0.11996  0.86277]
21Feb12_221955| [ 0.72011  0.75529 -0.82766]
21Feb12_221955| [-0.33660 -0.35476 -0.71476]
21Feb12_221955| [ 0.33438 -0.68141  0.72732]
21Feb12_221955| [-0.61093 -0.40890  0.62660]
21Feb12_221955| [ 0.56744 -0.07154  0.31925]
21Feb12_221955| [ 0.88609 -0.33900  0.61952]
21Feb12_221955| [ 0.49285 -0.33525 -0.90109]
21Feb12_221955| [-0.55605 -0.65017  0.13016]
21Feb12_221955| [ 0.39781 -0.96175 -0.70196]
21Feb12_221955| [-0.87099 -0.13297 -0.41766]
21Feb12_221955| [-0.01994  0.90710 -0.20816]
21Feb12_221955| [-0.81983 -0.31921  0.53962]
21Feb12_221955| [ 0.32674  0.28926  0.54147]
21Feb12_221955| [ 0.31080 -0.89339  0.26998]
21Feb12_221955| [ 0.67984  0.12830  0.06322]
21Feb12_221955| [-0.13356  0.43629 -0.68407]
21Feb12_221955| [-0.92144  0.68797  0.39469]
21Feb12_221955| [-0.31999  0.11075  0.99741]
21Feb12_221955| [-0.13042  0.80637 -0.89303]
21Feb12_221955| [ 0.90765  0.53496  0.68058]
21Feb12_221955| [ 0.90767 -0.54768 -0.23806]
21Feb12_221955| [ 0.31852 -0.38568  0.42940]
21Feb12_221955| [-0.01048 -0.50459  0.84980]
21Feb12_221955| [-0.80539  0.52647 -0.01060]
21Feb12_221955| [-0.43642  0.41663 -0.36429]
21Feb12_221955| [-0.27114  0.87297 -0.95253]
21Feb12_221955| [-0.06681  0.85751  0.09011]
21Feb12_221955| [ 0.65895 -0.76992  0.95635]
21Feb12_221955| [-0.26142 -0.93196 -0.58364]
21Feb12_221955| [-0.68097  0.43564 -0.23982]
21Feb12_221955| [-0.74714 -0.89822  0.22648]
21Feb12_221955| [ 0.75638 -0.34189 -0.16720]
21Feb12_221955| [ 0.07447  0.62611 -0.79106]
21Feb12_221955| [-0.80368  0.35963 -0.14610]
21Feb12_221955| [-0.85890 -0.08560  0.22429]
21Feb12_221955| [-0.73325 -0.89274  0.63033]
21Feb12_221955| [-0.11041 -0.00797  0.04746]
21Feb12_221955| [-0.94063  0.39268 -0.79421]
21Feb12_221955| [ 0.99285 -0.29422  0.43002]
21Feb12_221955| [ 0.89543  0.43777 -0.09217]
21Feb12_221955| [ 0.47514 -0.97677  0.44818]
21Feb12_221955| [-0.47425 -0.17113 -0.65595]
21Feb12_221955| [ 0.16366  0.41159  0.64227]
21Feb12_221955| [ 0.80674 -0.15239  0.66481]
21Feb12_221955| [-0.10308  0.33818 -0.16607]
21Feb12_221955| [-0.83135  0.29243  0.19174]
21Feb12_221955| [ 0.64929  0.29353 -0.55883]
21Feb12_221955| [-0.78685 -0.16958  0.26270]]
21Feb12_221955|-- Bias --
21Feb12_221955|[ 0.47675 -0.84795  0.59239]
21Feb12_221955|Layer 1:
21Feb12_221955|-- Config --
21Feb12_221955|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_221955|-- Weights --
21Feb12_221955|[[-0.56065 -0.46620]
21Feb12_221955| [ 0.81730 -0.87134]
21Feb12_221955| [ 0.01287 -0.44951]]
21Feb12_221955|-- Bias --
21Feb12_221955|[-0.11042  0.35882]
21Feb12_221955|Predicting the validation and test data with the Best initial individual.
21Feb12_222002| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_222002|-----------  ------------------  --------------------  ----------
21Feb12_222002|Validation         38.78                  3             0.00000
21Feb12_222002|   Test            39.01                  3             0.00000
21Feb12_222002|-------------------- Test #0 --------------------
21Feb12_222002|Best final individual weights
21Feb12_222002|Individual:
21Feb12_222002|-- Constant hidden layers --
21Feb12_222002|False
21Feb12_222002|Layer 0:
21Feb12_222002|-- Config --
21Feb12_222002|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222002|-- Weights --
21Feb12_222002|[[-0.54170  0.93401  0.04119]
21Feb12_222002| [-0.77325 -0.24664  0.09186]
21Feb12_222002| [ 0.07303 -0.46735  0.22408]
21Feb12_222002| [-0.09164  0.56787  0.29850]
21Feb12_222002| [-0.58491  0.34197 -0.40097]
21Feb12_222002| [-0.34799 -0.86048  0.28810]
21Feb12_222002| [-1.62035 -0.08828  0.44185]
21Feb12_222002| [-0.53184 -0.76164  0.02387]
21Feb12_222002| [ 0.26800  0.85278  0.17889]
21Feb12_222002| [ 0.79304 -0.21543  0.44742]
21Feb12_222002| [ 1.59144 -0.53244  0.33350]
21Feb12_222002| [ 0.17031 -1.73297 -0.13458]
21Feb12_222002| [ 0.10736 -0.46047  0.40717]
21Feb12_222002| [-0.09455  0.05870 -0.09034]
21Feb12_222002| [ 0.97049 -1.07123  0.11308]
21Feb12_222002| [ 0.91502 -0.32412 -0.27406]
21Feb12_222002| [-0.84725  0.34525 -0.19755]
21Feb12_222002| [-0.48653 -1.15699 -0.31790]
21Feb12_222002| [ 1.14240 -0.55309 -0.20551]
21Feb12_222002| [-0.38509 -0.00396  0.39781]
21Feb12_222002| [-0.74234  0.94452  0.29499]
21Feb12_222002| [ 0.82853 -0.86330  0.20795]
21Feb12_222002| [ 0.44865  1.35322 -0.14925]
21Feb12_222002| [-0.52224 -1.06447  0.25464]
21Feb12_222002| [ 0.25889  0.48368 -0.30267]
21Feb12_222002| [ 0.46850  1.23438 -0.13521]
21Feb12_222002| [ 0.57000  0.79771 -0.29900]
21Feb12_222002| [ 0.78958  0.03141  0.13663]
21Feb12_222002| [-0.67589  0.89571  0.03663]
21Feb12_222002| [ 0.47376 -0.30171  0.38515]
21Feb12_222002| [-0.82374 -0.01550 -0.39589]
21Feb12_222002| [ 0.35163  0.66679 -0.37324]
21Feb12_222002| [-0.33912 -0.42369 -0.21317]
21Feb12_222002| [-0.85759  0.55191 -0.49204]
21Feb12_222002| [ 0.76109 -0.19150  0.06690]
21Feb12_222002| [-0.22136  1.32987  0.09748]
21Feb12_222002| [-0.92539 -0.15925  0.28459]
21Feb12_222002| [ 0.81702 -1.15448 -0.48097]
21Feb12_222002| [ 0.28820 -1.14299  0.48866]
21Feb12_222002| [-0.09292  0.30049 -0.16540]
21Feb12_222002| [ 1.12671 -1.05155 -0.01799]
21Feb12_222002| [-0.42620 -0.90990  0.10208]
21Feb12_222002| [ 0.24989 -0.44552  0.34534]
21Feb12_222002| [ 0.66356  0.18156 -0.16456]
21Feb12_222002| [ 0.09132  0.28170  0.13297]
21Feb12_222002| [ 1.14862 -0.97400  0.20232]
21Feb12_222002| [ 0.21230 -0.51829 -0.20180]
21Feb12_222002| [-0.55656  1.34553 -0.09400]
21Feb12_222002| [-0.18786 -1.06748  0.30449]
21Feb12_222002| [-0.34578 -0.85935  0.46305]
21Feb12_222002| [-0.88531  0.61893  0.01799]
21Feb12_222002| [-0.81618  0.05790 -0.17864]
21Feb12_222002| [-1.35756  0.01771  0.16221]
21Feb12_222002| [-0.69178  0.18287  0.12650]
21Feb12_222002| [ 1.30106 -0.72102  0.24797]
21Feb12_222002| [ 0.67527  0.63348  0.41087]
21Feb12_222002| [-0.49881  0.11802 -0.14302]]
21Feb12_222002|-- Bias --
21Feb12_222002|[-0.63748 -0.26300 -0.28618]
21Feb12_222002|Layer 1:
21Feb12_222002|-- Config --
21Feb12_222002|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222002|-- Weights --
21Feb12_222002|[[-0.08274  0.46780]
21Feb12_222002| [ 0.17995  0.85493]
21Feb12_222002| [-0.45693  0.13859]]
21Feb12_222002|-- Bias --
21Feb12_222002|[-0.62075  0.53538]
21Feb12_222002|Layer 2:
21Feb12_222002|-- Config --
21Feb12_222002|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222002|-- Weights --
21Feb12_222002|[[ 0.54572 -0.88482]
21Feb12_222002| [ 0.72619  0.34039]]
21Feb12_222002|-- Bias --
21Feb12_222002|[-0.40957 -0.73958]
21Feb12_222002|Layer 3:
21Feb12_222002|-- Config --
21Feb12_222002|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222002|-- Weights --
21Feb12_222002|[[-1.36199  0.37967]
21Feb12_222002| [-0.28876  1.07865]]
21Feb12_222002|-- Bias --
21Feb12_222002|[-0.53688 -0.64166]
21Feb12_222002|Predicting the validation and test data with the Best final individual.
21Feb12_222010| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_222010|-----------  ------------------  --------------------  ----------
21Feb12_222010|Validation         25.91                  21            0.44058
21Feb12_222010|   Test            25.46                  21            0.52885
21Feb12_222010|-------------------- Test #1 --------------------
21Feb12_222010|Best final individual weights
21Feb12_222010|Individual:
21Feb12_222010|-- Constant hidden layers --
21Feb12_222010|False
21Feb12_222010|Layer 0:
21Feb12_222010|-- Config --
21Feb12_222010|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222010|-- Weights --
21Feb12_222010|[[-0.54170  0.93401  0.04119]
21Feb12_222010| [-0.77325 -0.24664  0.09186]
21Feb12_222010| [ 0.07303 -0.46735  0.22408]
21Feb12_222010| [-0.09164  0.56787  0.29850]
21Feb12_222010| [-0.58491  0.34197 -0.40097]
21Feb12_222010| [-0.34799 -0.86048  0.28810]
21Feb12_222010| [-1.62035 -0.08828  0.44185]
21Feb12_222010| [-0.53184 -0.76164  0.02387]
21Feb12_222010| [ 0.26800  0.85278  0.17889]
21Feb12_222010| [ 0.79304 -0.21543  0.44742]
21Feb12_222010| [ 1.59144 -0.53244  0.33350]
21Feb12_222010| [ 0.17031 -1.73297 -0.13458]
21Feb12_222010| [ 0.10736 -0.46047  0.40717]
21Feb12_222010| [-0.09455  0.05870 -0.09034]
21Feb12_222010| [ 0.97049 -1.07123  0.11308]
21Feb12_222010| [ 0.91502 -0.32412 -0.27406]
21Feb12_222010| [-0.84725  0.34525 -0.19755]
21Feb12_222010| [-0.48653 -1.15699 -0.31790]
21Feb12_222010| [ 1.14240 -0.55309 -0.20551]
21Feb12_222010| [-0.38509 -0.00396  0.39781]
21Feb12_222010| [-0.74234  0.94452  0.29499]
21Feb12_222010| [ 0.82853 -0.86330  0.20795]
21Feb12_222010| [ 0.44865  1.35322 -0.14925]
21Feb12_222010| [-0.52224 -1.06447  0.25464]
21Feb12_222010| [ 0.25889  0.48368 -0.30267]
21Feb12_222010| [ 0.46850  1.23438 -0.13521]
21Feb12_222010| [ 0.57000  0.79771 -0.29900]
21Feb12_222010| [ 0.78958  0.03141  0.13663]
21Feb12_222010| [-0.67589  0.89571  0.03663]
21Feb12_222010| [ 0.47376 -0.30171  0.38515]
21Feb12_222010| [-0.82374 -0.01550 -0.39589]
21Feb12_222010| [ 0.35163  0.66679 -0.37324]
21Feb12_222010| [-0.33912 -0.42369 -0.21317]
21Feb12_222010| [-0.85759  0.55191 -0.49204]
21Feb12_222010| [ 0.76109 -0.19150  0.06690]
21Feb12_222010| [-0.22136  1.32987  0.09748]
21Feb12_222010| [-0.92539 -0.15925  0.28459]
21Feb12_222010| [ 0.81702 -1.15448 -0.48097]
21Feb12_222010| [ 0.28820 -1.14299  0.48866]
21Feb12_222010| [-0.09292  0.30049 -0.16540]
21Feb12_222010| [ 1.12671 -1.05155 -0.01799]
21Feb12_222010| [-0.42620 -0.90990  0.10208]
21Feb12_222010| [ 0.24989 -0.44552  0.34534]
21Feb12_222010| [ 0.66356  0.18156 -0.16456]
21Feb12_222010| [ 0.09132  0.28170  0.13297]
21Feb12_222010| [ 1.14862 -0.97400  0.20232]
21Feb12_222010| [ 0.21230 -0.51829 -0.20180]
21Feb12_222010| [-0.55656  1.34553 -0.09400]
21Feb12_222010| [-0.18786 -1.06748  0.30449]
21Feb12_222010| [-0.34578 -0.85935  0.46305]
21Feb12_222010| [-0.88531  0.61893  0.01799]
21Feb12_222010| [-0.81618  0.05790 -0.17864]
21Feb12_222010| [-1.35756  0.01771  0.16221]
21Feb12_222010| [-0.69178  0.18287  0.12650]
21Feb12_222010| [ 1.30106 -0.72102  0.24797]
21Feb12_222010| [ 0.67527  0.63348  0.41087]
21Feb12_222010| [-0.49881  0.11802 -0.14302]]
21Feb12_222010|-- Bias --
21Feb12_222010|[-0.63748 -0.26300 -0.28618]
21Feb12_222010|Layer 1:
21Feb12_222010|-- Config --
21Feb12_222010|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222010|-- Weights --
21Feb12_222010|[[-0.08274  0.46780]
21Feb12_222010| [ 0.17995  0.85493]
21Feb12_222010| [-0.45693  0.13859]]
21Feb12_222010|-- Bias --
21Feb12_222010|[-0.62075  0.53538]
21Feb12_222010|Layer 2:
21Feb12_222010|-- Config --
21Feb12_222010|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222010|-- Weights --
21Feb12_222010|[[ 0.54572 -0.88482]
21Feb12_222010| [ 0.72619  0.34039]]
21Feb12_222010|-- Bias --
21Feb12_222010|[-0.40957 -0.73958]
21Feb12_222010|Layer 3:
21Feb12_222010|-- Config --
21Feb12_222010|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222010|-- Weights --
21Feb12_222010|[[-1.36199  0.37967]
21Feb12_222010| [-0.28876  1.07865]]
21Feb12_222010|-- Bias --
21Feb12_222010|[-0.53688 -0.64166]
21Feb12_222010|Predicting the validation and test data with the Best final individual.
21Feb12_222018| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_222018|-----------  ------------------  --------------------  ----------
21Feb12_222018|Validation         29.65                  21            0.32626
21Feb12_222018|   Test            28.84                  21            0.35733
21Feb12_222018|-------------------- Test #2 --------------------
21Feb12_222018|Best final individual weights
21Feb12_222018|Individual:
21Feb12_222018|-- Constant hidden layers --
21Feb12_222018|False
21Feb12_222018|Layer 0:
21Feb12_222018|-- Config --
21Feb12_222018|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222018|-- Weights --
21Feb12_222018|[[-0.54170  0.93401  0.04119]
21Feb12_222018| [-0.77325 -0.24664  0.09186]
21Feb12_222018| [ 0.07303 -0.46735  0.22408]
21Feb12_222018| [-0.09164  0.56787  0.29850]
21Feb12_222018| [-0.58491  0.34197 -0.40097]
21Feb12_222018| [-0.34799 -0.86048  0.28810]
21Feb12_222018| [-1.62035 -0.08828  0.44185]
21Feb12_222018| [-0.53184 -0.76164  0.02387]
21Feb12_222018| [ 0.26800  0.85278  0.17889]
21Feb12_222018| [ 0.79304 -0.21543  0.44742]
21Feb12_222018| [ 1.59144 -0.53244  0.33350]
21Feb12_222018| [ 0.17031 -1.73297 -0.13458]
21Feb12_222018| [ 0.10736 -0.46047  0.40717]
21Feb12_222018| [-0.09455  0.05870 -0.09034]
21Feb12_222018| [ 0.97049 -1.07123  0.11308]
21Feb12_222018| [ 0.91502 -0.32412 -0.27406]
21Feb12_222018| [-0.84725  0.34525 -0.19755]
21Feb12_222018| [-0.48653 -1.15699 -0.31790]
21Feb12_222018| [ 1.14240 -0.55309 -0.20551]
21Feb12_222018| [-0.38509 -0.00396  0.39781]
21Feb12_222018| [-0.74234  0.94452  0.29499]
21Feb12_222018| [ 0.82853 -0.86330  0.20795]
21Feb12_222018| [ 0.44865  1.35322 -0.14925]
21Feb12_222018| [-0.52224 -1.06447  0.25464]
21Feb12_222018| [ 0.25889  0.48368 -0.30267]
21Feb12_222018| [ 0.46850  1.23438 -0.13521]
21Feb12_222018| [ 0.57000  0.79771 -0.29900]
21Feb12_222018| [ 0.78958  0.03141  0.13663]
21Feb12_222018| [-0.67589  0.89571  0.03663]
21Feb12_222018| [ 0.47376 -0.30171  0.38515]
21Feb12_222018| [-0.82374 -0.01550 -0.39589]
21Feb12_222018| [ 0.35163  0.66679 -0.37324]
21Feb12_222018| [-0.33912 -0.42369 -0.21317]
21Feb12_222018| [-0.85759  0.55191 -0.49204]
21Feb12_222018| [ 0.76109 -0.19150  0.06690]
21Feb12_222018| [-0.22136  1.32987  0.09748]
21Feb12_222018| [-0.92539 -0.15925  0.28459]
21Feb12_222018| [ 0.81702 -1.15448 -0.48097]
21Feb12_222018| [ 0.28820 -1.14299  0.48866]
21Feb12_222018| [-0.09292  0.30049 -0.16540]
21Feb12_222018| [ 1.12671 -1.05155 -0.01799]
21Feb12_222018| [-0.42620 -0.90990  0.10208]
21Feb12_222018| [ 0.24989 -0.44552  0.34534]
21Feb12_222018| [ 0.66356  0.18156 -0.16456]
21Feb12_222018| [ 0.09132  0.28170  0.13297]
21Feb12_222018| [ 1.14862 -0.97400  0.20232]
21Feb12_222018| [ 0.21230 -0.51829 -0.20180]
21Feb12_222018| [-0.55656  1.34553 -0.09400]
21Feb12_222018| [-0.18786 -1.06748  0.30449]
21Feb12_222018| [-0.34578 -0.85935  0.46305]
21Feb12_222018| [-0.88531  0.61893  0.01799]
21Feb12_222018| [-0.81618  0.05790 -0.17864]
21Feb12_222018| [-1.35756  0.01771  0.16221]
21Feb12_222018| [-0.69178  0.18287  0.12650]
21Feb12_222018| [ 1.30106 -0.72102  0.24797]
21Feb12_222018| [ 0.67527  0.63348  0.41087]
21Feb12_222018| [-0.49881  0.11802 -0.14302]]
21Feb12_222018|-- Bias --
21Feb12_222018|[-0.63748 -0.26300 -0.28618]
21Feb12_222018|Layer 1:
21Feb12_222018|-- Config --
21Feb12_222018|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222018|-- Weights --
21Feb12_222018|[[-0.08274  0.46780]
21Feb12_222018| [ 0.17995  0.85493]
21Feb12_222018| [-0.45693  0.13859]]
21Feb12_222018|-- Bias --
21Feb12_222018|[-0.62075  0.53538]
21Feb12_222018|Layer 2:
21Feb12_222018|-- Config --
21Feb12_222018|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222018|-- Weights --
21Feb12_222018|[[ 0.54572 -0.88482]
21Feb12_222018| [ 0.72619  0.34039]]
21Feb12_222018|-- Bias --
21Feb12_222018|[-0.40957 -0.73958]
21Feb12_222018|Layer 3:
21Feb12_222018|-- Config --
21Feb12_222018|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222018|-- Weights --
21Feb12_222018|[[-1.36199  0.37967]
21Feb12_222018| [-0.28876  1.07865]]
21Feb12_222018|-- Bias --
21Feb12_222018|[-0.53688 -0.64166]
21Feb12_222018|Predicting the validation and test data with the Best final individual.
21Feb12_222026| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_222026|-----------  ------------------  --------------------  ----------
21Feb12_222026|Validation         25.22                  21            0.54139
21Feb12_222026|   Test            26.85                  21            0.41120
21Feb12_222026|-------------------- Test #3 --------------------
21Feb12_222026|Best final individual weights
21Feb12_222026|Individual:
21Feb12_222026|-- Constant hidden layers --
21Feb12_222026|False
21Feb12_222026|Layer 0:
21Feb12_222026|-- Config --
21Feb12_222026|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222026|-- Weights --
21Feb12_222026|[[-0.54170  0.93401  0.04119]
21Feb12_222026| [-0.77325 -0.24664  0.09186]
21Feb12_222026| [ 0.07303 -0.46735  0.22408]
21Feb12_222026| [-0.09164  0.56787  0.29850]
21Feb12_222026| [-0.58491  0.34197 -0.40097]
21Feb12_222026| [-0.34799 -0.86048  0.28810]
21Feb12_222026| [-1.62035 -0.08828  0.44185]
21Feb12_222026| [-0.53184 -0.76164  0.02387]
21Feb12_222026| [ 0.26800  0.85278  0.17889]
21Feb12_222026| [ 0.79304 -0.21543  0.44742]
21Feb12_222026| [ 1.59144 -0.53244  0.33350]
21Feb12_222026| [ 0.17031 -1.73297 -0.13458]
21Feb12_222026| [ 0.10736 -0.46047  0.40717]
21Feb12_222026| [-0.09455  0.05870 -0.09034]
21Feb12_222026| [ 0.97049 -1.07123  0.11308]
21Feb12_222026| [ 0.91502 -0.32412 -0.27406]
21Feb12_222026| [-0.84725  0.34525 -0.19755]
21Feb12_222026| [-0.48653 -1.15699 -0.31790]
21Feb12_222026| [ 1.14240 -0.55309 -0.20551]
21Feb12_222026| [-0.38509 -0.00396  0.39781]
21Feb12_222026| [-0.74234  0.94452  0.29499]
21Feb12_222026| [ 0.82853 -0.86330  0.20795]
21Feb12_222026| [ 0.44865  1.35322 -0.14925]
21Feb12_222026| [-0.52224 -1.06447  0.25464]
21Feb12_222026| [ 0.25889  0.48368 -0.30267]
21Feb12_222026| [ 0.46850  1.23438 -0.13521]
21Feb12_222026| [ 0.57000  0.79771 -0.29900]
21Feb12_222026| [ 0.78958  0.03141  0.13663]
21Feb12_222026| [-0.67589  0.89571  0.03663]
21Feb12_222026| [ 0.47376 -0.30171  0.38515]
21Feb12_222026| [-0.82374 -0.01550 -0.39589]
21Feb12_222026| [ 0.35163  0.66679 -0.37324]
21Feb12_222026| [-0.33912 -0.42369 -0.21317]
21Feb12_222026| [-0.85759  0.55191 -0.49204]
21Feb12_222026| [ 0.76109 -0.19150  0.06690]
21Feb12_222026| [-0.22136  1.32987  0.09748]
21Feb12_222026| [-0.92539 -0.15925  0.28459]
21Feb12_222026| [ 0.81702 -1.15448 -0.48097]
21Feb12_222026| [ 0.28820 -1.14299  0.48866]
21Feb12_222026| [-0.09292  0.30049 -0.16540]
21Feb12_222026| [ 1.12671 -1.05155 -0.01799]
21Feb12_222026| [-0.42620 -0.90990  0.10208]
21Feb12_222026| [ 0.24989 -0.44552  0.34534]
21Feb12_222026| [ 0.66356  0.18156 -0.16456]
21Feb12_222026| [ 0.09132  0.28170  0.13297]
21Feb12_222026| [ 1.14862 -0.97400  0.20232]
21Feb12_222026| [ 0.21230 -0.51829 -0.20180]
21Feb12_222026| [-0.55656  1.34553 -0.09400]
21Feb12_222026| [-0.18786 -1.06748  0.30449]
21Feb12_222026| [-0.34578 -0.85935  0.46305]
21Feb12_222026| [-0.88531  0.61893  0.01799]
21Feb12_222026| [-0.81618  0.05790 -0.17864]
21Feb12_222026| [-1.35756  0.01771  0.16221]
21Feb12_222026| [-0.69178  0.18287  0.12650]
21Feb12_222026| [ 1.30106 -0.72102  0.24797]
21Feb12_222026| [ 0.67527  0.63348  0.41087]
21Feb12_222026| [-0.49881  0.11802 -0.14302]]
21Feb12_222026|-- Bias --
21Feb12_222026|[-0.63748 -0.26300 -0.28618]
21Feb12_222026|Layer 1:
21Feb12_222026|-- Config --
21Feb12_222026|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222026|-- Weights --
21Feb12_222026|[[-0.08274  0.46780]
21Feb12_222026| [ 0.17995  0.85493]
21Feb12_222026| [-0.45693  0.13859]]
21Feb12_222026|-- Bias --
21Feb12_222026|[-0.62075  0.53538]
21Feb12_222026|Layer 2:
21Feb12_222026|-- Config --
21Feb12_222026|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222026|-- Weights --
21Feb12_222026|[[ 0.54572 -0.88482]
21Feb12_222026| [ 0.72619  0.34039]]
21Feb12_222026|-- Bias --
21Feb12_222026|[-0.40957 -0.73958]
21Feb12_222026|Layer 3:
21Feb12_222026|-- Config --
21Feb12_222026|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222026|-- Weights --
21Feb12_222026|[[-1.36199  0.37967]
21Feb12_222026| [-0.28876  1.07865]]
21Feb12_222026|-- Bias --
21Feb12_222026|[-0.53688 -0.64166]
21Feb12_222026|Predicting the validation and test data with the Best final individual.
21Feb12_222034| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_222034|-----------  ------------------  --------------------  ----------
21Feb12_222034|Validation         28.26                  21            0.37122
21Feb12_222034|   Test            26.59                  21            0.43065
21Feb12_222034|-------------------- Test #4 --------------------
21Feb12_222034|Best final individual weights
21Feb12_222034|Individual:
21Feb12_222034|-- Constant hidden layers --
21Feb12_222034|False
21Feb12_222034|Layer 0:
21Feb12_222034|-- Config --
21Feb12_222034|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222034|-- Weights --
21Feb12_222034|[[-0.54170  0.93401  0.04119]
21Feb12_222034| [-0.77325 -0.24664  0.09186]
21Feb12_222034| [ 0.07303 -0.46735  0.22408]
21Feb12_222034| [-0.09164  0.56787  0.29850]
21Feb12_222034| [-0.58491  0.34197 -0.40097]
21Feb12_222034| [-0.34799 -0.86048  0.28810]
21Feb12_222034| [-1.62035 -0.08828  0.44185]
21Feb12_222034| [-0.53184 -0.76164  0.02387]
21Feb12_222034| [ 0.26800  0.85278  0.17889]
21Feb12_222034| [ 0.79304 -0.21543  0.44742]
21Feb12_222034| [ 1.59144 -0.53244  0.33350]
21Feb12_222034| [ 0.17031 -1.73297 -0.13458]
21Feb12_222034| [ 0.10736 -0.46047  0.40717]
21Feb12_222034| [-0.09455  0.05870 -0.09034]
21Feb12_222034| [ 0.97049 -1.07123  0.11308]
21Feb12_222034| [ 0.91502 -0.32412 -0.27406]
21Feb12_222034| [-0.84725  0.34525 -0.19755]
21Feb12_222034| [-0.48653 -1.15699 -0.31790]
21Feb12_222034| [ 1.14240 -0.55309 -0.20551]
21Feb12_222034| [-0.38509 -0.00396  0.39781]
21Feb12_222034| [-0.74234  0.94452  0.29499]
21Feb12_222034| [ 0.82853 -0.86330  0.20795]
21Feb12_222034| [ 0.44865  1.35322 -0.14925]
21Feb12_222034| [-0.52224 -1.06447  0.25464]
21Feb12_222034| [ 0.25889  0.48368 -0.30267]
21Feb12_222034| [ 0.46850  1.23438 -0.13521]
21Feb12_222034| [ 0.57000  0.79771 -0.29900]
21Feb12_222034| [ 0.78958  0.03141  0.13663]
21Feb12_222034| [-0.67589  0.89571  0.03663]
21Feb12_222034| [ 0.47376 -0.30171  0.38515]
21Feb12_222034| [-0.82374 -0.01550 -0.39589]
21Feb12_222034| [ 0.35163  0.66679 -0.37324]
21Feb12_222034| [-0.33912 -0.42369 -0.21317]
21Feb12_222034| [-0.85759  0.55191 -0.49204]
21Feb12_222034| [ 0.76109 -0.19150  0.06690]
21Feb12_222034| [-0.22136  1.32987  0.09748]
21Feb12_222034| [-0.92539 -0.15925  0.28459]
21Feb12_222034| [ 0.81702 -1.15448 -0.48097]
21Feb12_222034| [ 0.28820 -1.14299  0.48866]
21Feb12_222034| [-0.09292  0.30049 -0.16540]
21Feb12_222034| [ 1.12671 -1.05155 -0.01799]
21Feb12_222034| [-0.42620 -0.90990  0.10208]
21Feb12_222034| [ 0.24989 -0.44552  0.34534]
21Feb12_222034| [ 0.66356  0.18156 -0.16456]
21Feb12_222034| [ 0.09132  0.28170  0.13297]
21Feb12_222034| [ 1.14862 -0.97400  0.20232]
21Feb12_222034| [ 0.21230 -0.51829 -0.20180]
21Feb12_222034| [-0.55656  1.34553 -0.09400]
21Feb12_222034| [-0.18786 -1.06748  0.30449]
21Feb12_222034| [-0.34578 -0.85935  0.46305]
21Feb12_222034| [-0.88531  0.61893  0.01799]
21Feb12_222034| [-0.81618  0.05790 -0.17864]
21Feb12_222034| [-1.35756  0.01771  0.16221]
21Feb12_222034| [-0.69178  0.18287  0.12650]
21Feb12_222034| [ 1.30106 -0.72102  0.24797]
21Feb12_222034| [ 0.67527  0.63348  0.41087]
21Feb12_222034| [-0.49881  0.11802 -0.14302]]
21Feb12_222034|-- Bias --
21Feb12_222034|[-0.63748 -0.26300 -0.28618]
21Feb12_222034|Layer 1:
21Feb12_222034|-- Config --
21Feb12_222034|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222034|-- Weights --
21Feb12_222034|[[-0.08274  0.46780]
21Feb12_222034| [ 0.17995  0.85493]
21Feb12_222034| [-0.45693  0.13859]]
21Feb12_222034|-- Bias --
21Feb12_222034|[-0.62075  0.53538]
21Feb12_222034|Layer 2:
21Feb12_222034|-- Config --
21Feb12_222034|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222034|-- Weights --
21Feb12_222034|[[ 0.54572 -0.88482]
21Feb12_222034| [ 0.72619  0.34039]]
21Feb12_222034|-- Bias --
21Feb12_222034|[-0.40957 -0.73958]
21Feb12_222034|Layer 3:
21Feb12_222034|-- Config --
21Feb12_222034|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222034|-- Weights --
21Feb12_222034|[[-1.36199  0.37967]
21Feb12_222034| [-0.28876  1.07865]]
21Feb12_222034|-- Bias --
21Feb12_222034|[-0.53688 -0.64166]
21Feb12_222034|Predicting the validation and test data with the Best final individual.
21Feb12_222042| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_222042|-----------  ------------------  --------------------  ----------
21Feb12_222042|Validation         25.48                  21            0.55556
21Feb12_222042|   Test            25.98                  21            0.56444
21Feb12_222042|-------------------- Test #5 --------------------
21Feb12_222042|Best final individual weights
21Feb12_222042|Individual:
21Feb12_222042|-- Constant hidden layers --
21Feb12_222042|False
21Feb12_222042|Layer 0:
21Feb12_222042|-- Config --
21Feb12_222042|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222042|-- Weights --
21Feb12_222042|[[-0.54170  0.93401  0.04119]
21Feb12_222042| [-0.77325 -0.24664  0.09186]
21Feb12_222042| [ 0.07303 -0.46735  0.22408]
21Feb12_222042| [-0.09164  0.56787  0.29850]
21Feb12_222042| [-0.58491  0.34197 -0.40097]
21Feb12_222042| [-0.34799 -0.86048  0.28810]
21Feb12_222042| [-1.62035 -0.08828  0.44185]
21Feb12_222042| [-0.53184 -0.76164  0.02387]
21Feb12_222042| [ 0.26800  0.85278  0.17889]
21Feb12_222042| [ 0.79304 -0.21543  0.44742]
21Feb12_222042| [ 1.59144 -0.53244  0.33350]
21Feb12_222042| [ 0.17031 -1.73297 -0.13458]
21Feb12_222042| [ 0.10736 -0.46047  0.40717]
21Feb12_222042| [-0.09455  0.05870 -0.09034]
21Feb12_222042| [ 0.97049 -1.07123  0.11308]
21Feb12_222042| [ 0.91502 -0.32412 -0.27406]
21Feb12_222042| [-0.84725  0.34525 -0.19755]
21Feb12_222042| [-0.48653 -1.15699 -0.31790]
21Feb12_222042| [ 1.14240 -0.55309 -0.20551]
21Feb12_222042| [-0.38509 -0.00396  0.39781]
21Feb12_222042| [-0.74234  0.94452  0.29499]
21Feb12_222042| [ 0.82853 -0.86330  0.20795]
21Feb12_222042| [ 0.44865  1.35322 -0.14925]
21Feb12_222042| [-0.52224 -1.06447  0.25464]
21Feb12_222042| [ 0.25889  0.48368 -0.30267]
21Feb12_222042| [ 0.46850  1.23438 -0.13521]
21Feb12_222042| [ 0.57000  0.79771 -0.29900]
21Feb12_222042| [ 0.78958  0.03141  0.13663]
21Feb12_222042| [-0.67589  0.89571  0.03663]
21Feb12_222042| [ 0.47376 -0.30171  0.38515]
21Feb12_222042| [-0.82374 -0.01550 -0.39589]
21Feb12_222042| [ 0.35163  0.66679 -0.37324]
21Feb12_222042| [-0.33912 -0.42369 -0.21317]
21Feb12_222042| [-0.85759  0.55191 -0.49204]
21Feb12_222042| [ 0.76109 -0.19150  0.06690]
21Feb12_222042| [-0.22136  1.32987  0.09748]
21Feb12_222042| [-0.92539 -0.15925  0.28459]
21Feb12_222042| [ 0.81702 -1.15448 -0.48097]
21Feb12_222042| [ 0.28820 -1.14299  0.48866]
21Feb12_222042| [-0.09292  0.30049 -0.16540]
21Feb12_222042| [ 1.12671 -1.05155 -0.01799]
21Feb12_222042| [-0.42620 -0.90990  0.10208]
21Feb12_222042| [ 0.24989 -0.44552  0.34534]
21Feb12_222042| [ 0.66356  0.18156 -0.16456]
21Feb12_222042| [ 0.09132  0.28170  0.13297]
21Feb12_222042| [ 1.14862 -0.97400  0.20232]
21Feb12_222042| [ 0.21230 -0.51829 -0.20180]
21Feb12_222042| [-0.55656  1.34553 -0.09400]
21Feb12_222042| [-0.18786 -1.06748  0.30449]
21Feb12_222042| [-0.34578 -0.85935  0.46305]
21Feb12_222042| [-0.88531  0.61893  0.01799]
21Feb12_222042| [-0.81618  0.05790 -0.17864]
21Feb12_222042| [-1.35756  0.01771  0.16221]
21Feb12_222042| [-0.69178  0.18287  0.12650]
21Feb12_222042| [ 1.30106 -0.72102  0.24797]
21Feb12_222042| [ 0.67527  0.63348  0.41087]
21Feb12_222042| [-0.49881  0.11802 -0.14302]]
21Feb12_222042|-- Bias --
21Feb12_222042|[-0.63748 -0.26300 -0.28618]
21Feb12_222042|Layer 1:
21Feb12_222042|-- Config --
21Feb12_222042|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222042|-- Weights --
21Feb12_222042|[[-0.08274  0.46780]
21Feb12_222042| [ 0.17995  0.85493]
21Feb12_222042| [-0.45693  0.13859]]
21Feb12_222042|-- Bias --
21Feb12_222042|[-0.62075  0.53538]
21Feb12_222042|Layer 2:
21Feb12_222042|-- Config --
21Feb12_222042|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222042|-- Weights --
21Feb12_222042|[[ 0.54572 -0.88482]
21Feb12_222042| [ 0.72619  0.34039]]
21Feb12_222042|-- Bias --
21Feb12_222042|[-0.40957 -0.73958]
21Feb12_222042|Layer 3:
21Feb12_222042|-- Config --
21Feb12_222042|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222042|-- Weights --
21Feb12_222042|[[-1.36199  0.37967]
21Feb12_222042| [-0.28876  1.07865]]
21Feb12_222042|-- Bias --
21Feb12_222042|[-0.53688 -0.64166]
21Feb12_222042|Predicting the validation and test data with the Best final individual.
21Feb12_222049| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_222049|-----------  ------------------  --------------------  ----------
21Feb12_222049|Validation         24.00                  21            0.52593
21Feb12_222049|   Test            25.72                  21            0.46960
21Feb12_222049|-------------------- Test #6 --------------------
21Feb12_222049|Best final individual weights
21Feb12_222049|Individual:
21Feb12_222049|-- Constant hidden layers --
21Feb12_222049|False
21Feb12_222049|Layer 0:
21Feb12_222049|-- Config --
21Feb12_222049|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222049|-- Weights --
21Feb12_222049|[[-0.54170  0.93401  0.04119]
21Feb12_222049| [-0.77325 -0.24664  0.09186]
21Feb12_222049| [ 0.07303 -0.46735  0.22408]
21Feb12_222049| [-0.09164  0.56787  0.29850]
21Feb12_222049| [-0.58491  0.34197 -0.40097]
21Feb12_222049| [-0.34799 -0.86048  0.28810]
21Feb12_222049| [-1.62035 -0.08828  0.44185]
21Feb12_222049| [-0.53184 -0.76164  0.02387]
21Feb12_222049| [ 0.26800  0.85278  0.17889]
21Feb12_222049| [ 0.79304 -0.21543  0.44742]
21Feb12_222049| [ 1.59144 -0.53244  0.33350]
21Feb12_222049| [ 0.17031 -1.73297 -0.13458]
21Feb12_222049| [ 0.10736 -0.46047  0.40717]
21Feb12_222049| [-0.09455  0.05870 -0.09034]
21Feb12_222049| [ 0.97049 -1.07123  0.11308]
21Feb12_222049| [ 0.91502 -0.32412 -0.27406]
21Feb12_222049| [-0.84725  0.34525 -0.19755]
21Feb12_222049| [-0.48653 -1.15699 -0.31790]
21Feb12_222049| [ 1.14240 -0.55309 -0.20551]
21Feb12_222049| [-0.38509 -0.00396  0.39781]
21Feb12_222049| [-0.74234  0.94452  0.29499]
21Feb12_222049| [ 0.82853 -0.86330  0.20795]
21Feb12_222049| [ 0.44865  1.35322 -0.14925]
21Feb12_222049| [-0.52224 -1.06447  0.25464]
21Feb12_222049| [ 0.25889  0.48368 -0.30267]
21Feb12_222049| [ 0.46850  1.23438 -0.13521]
21Feb12_222049| [ 0.57000  0.79771 -0.29900]
21Feb12_222049| [ 0.78958  0.03141  0.13663]
21Feb12_222049| [-0.67589  0.89571  0.03663]
21Feb12_222049| [ 0.47376 -0.30171  0.38515]
21Feb12_222049| [-0.82374 -0.01550 -0.39589]
21Feb12_222049| [ 0.35163  0.66679 -0.37324]
21Feb12_222049| [-0.33912 -0.42369 -0.21317]
21Feb12_222049| [-0.85759  0.55191 -0.49204]
21Feb12_222049| [ 0.76109 -0.19150  0.06690]
21Feb12_222049| [-0.22136  1.32987  0.09748]
21Feb12_222049| [-0.92539 -0.15925  0.28459]
21Feb12_222049| [ 0.81702 -1.15448 -0.48097]
21Feb12_222049| [ 0.28820 -1.14299  0.48866]
21Feb12_222049| [-0.09292  0.30049 -0.16540]
21Feb12_222049| [ 1.12671 -1.05155 -0.01799]
21Feb12_222049| [-0.42620 -0.90990  0.10208]
21Feb12_222049| [ 0.24989 -0.44552  0.34534]
21Feb12_222049| [ 0.66356  0.18156 -0.16456]
21Feb12_222049| [ 0.09132  0.28170  0.13297]
21Feb12_222049| [ 1.14862 -0.97400  0.20232]
21Feb12_222049| [ 0.21230 -0.51829 -0.20180]
21Feb12_222049| [-0.55656  1.34553 -0.09400]
21Feb12_222049| [-0.18786 -1.06748  0.30449]
21Feb12_222049| [-0.34578 -0.85935  0.46305]
21Feb12_222049| [-0.88531  0.61893  0.01799]
21Feb12_222049| [-0.81618  0.05790 -0.17864]
21Feb12_222049| [-1.35756  0.01771  0.16221]
21Feb12_222049| [-0.69178  0.18287  0.12650]
21Feb12_222049| [ 1.30106 -0.72102  0.24797]
21Feb12_222049| [ 0.67527  0.63348  0.41087]
21Feb12_222049| [-0.49881  0.11802 -0.14302]]
21Feb12_222049|-- Bias --
21Feb12_222049|[-0.63748 -0.26300 -0.28618]
21Feb12_222049|Layer 1:
21Feb12_222049|-- Config --
21Feb12_222049|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222049|-- Weights --
21Feb12_222049|[[-0.08274  0.46780]
21Feb12_222049| [ 0.17995  0.85493]
21Feb12_222049| [-0.45693  0.13859]]
21Feb12_222049|-- Bias --
21Feb12_222049|[-0.62075  0.53538]
21Feb12_222049|Layer 2:
21Feb12_222049|-- Config --
21Feb12_222049|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222049|-- Weights --
21Feb12_222049|[[ 0.54572 -0.88482]
21Feb12_222049| [ 0.72619  0.34039]]
21Feb12_222049|-- Bias --
21Feb12_222049|[-0.40957 -0.73958]
21Feb12_222049|Layer 3:
21Feb12_222049|-- Config --
21Feb12_222049|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222049|-- Weights --
21Feb12_222049|[[-1.36199  0.37967]
21Feb12_222049| [-0.28876  1.07865]]
21Feb12_222049|-- Bias --
21Feb12_222049|[-0.53688 -0.64166]
21Feb12_222049|Predicting the validation and test data with the Best final individual.
21Feb12_222057| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_222057|-----------  ------------------  --------------------  ----------
21Feb12_222057|Validation         27.91                  21            0.38501
21Feb12_222057|   Test            25.63                  21            0.51499
21Feb12_222057|-------------------- Test #7 --------------------
21Feb12_222057|Best final individual weights
21Feb12_222057|Individual:
21Feb12_222057|-- Constant hidden layers --
21Feb12_222057|False
21Feb12_222057|Layer 0:
21Feb12_222057|-- Config --
21Feb12_222057|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222057|-- Weights --
21Feb12_222057|[[-0.54170  0.93401  0.04119]
21Feb12_222057| [-0.77325 -0.24664  0.09186]
21Feb12_222057| [ 0.07303 -0.46735  0.22408]
21Feb12_222057| [-0.09164  0.56787  0.29850]
21Feb12_222057| [-0.58491  0.34197 -0.40097]
21Feb12_222057| [-0.34799 -0.86048  0.28810]
21Feb12_222057| [-1.62035 -0.08828  0.44185]
21Feb12_222057| [-0.53184 -0.76164  0.02387]
21Feb12_222057| [ 0.26800  0.85278  0.17889]
21Feb12_222057| [ 0.79304 -0.21543  0.44742]
21Feb12_222057| [ 1.59144 -0.53244  0.33350]
21Feb12_222057| [ 0.17031 -1.73297 -0.13458]
21Feb12_222057| [ 0.10736 -0.46047  0.40717]
21Feb12_222057| [-0.09455  0.05870 -0.09034]
21Feb12_222057| [ 0.97049 -1.07123  0.11308]
21Feb12_222057| [ 0.91502 -0.32412 -0.27406]
21Feb12_222057| [-0.84725  0.34525 -0.19755]
21Feb12_222057| [-0.48653 -1.15699 -0.31790]
21Feb12_222057| [ 1.14240 -0.55309 -0.20551]
21Feb12_222057| [-0.38509 -0.00396  0.39781]
21Feb12_222057| [-0.74234  0.94452  0.29499]
21Feb12_222057| [ 0.82853 -0.86330  0.20795]
21Feb12_222057| [ 0.44865  1.35322 -0.14925]
21Feb12_222057| [-0.52224 -1.06447  0.25464]
21Feb12_222057| [ 0.25889  0.48368 -0.30267]
21Feb12_222057| [ 0.46850  1.23438 -0.13521]
21Feb12_222057| [ 0.57000  0.79771 -0.29900]
21Feb12_222057| [ 0.78958  0.03141  0.13663]
21Feb12_222057| [-0.67589  0.89571  0.03663]
21Feb12_222057| [ 0.47376 -0.30171  0.38515]
21Feb12_222057| [-0.82374 -0.01550 -0.39589]
21Feb12_222057| [ 0.35163  0.66679 -0.37324]
21Feb12_222057| [-0.33912 -0.42369 -0.21317]
21Feb12_222057| [-0.85759  0.55191 -0.49204]
21Feb12_222057| [ 0.76109 -0.19150  0.06690]
21Feb12_222057| [-0.22136  1.32987  0.09748]
21Feb12_222057| [-0.92539 -0.15925  0.28459]
21Feb12_222057| [ 0.81702 -1.15448 -0.48097]
21Feb12_222057| [ 0.28820 -1.14299  0.48866]
21Feb12_222057| [-0.09292  0.30049 -0.16540]
21Feb12_222057| [ 1.12671 -1.05155 -0.01799]
21Feb12_222057| [-0.42620 -0.90990  0.10208]
21Feb12_222057| [ 0.24989 -0.44552  0.34534]
21Feb12_222057| [ 0.66356  0.18156 -0.16456]
21Feb12_222057| [ 0.09132  0.28170  0.13297]
21Feb12_222057| [ 1.14862 -0.97400  0.20232]
21Feb12_222057| [ 0.21230 -0.51829 -0.20180]
21Feb12_222057| [-0.55656  1.34553 -0.09400]
21Feb12_222057| [-0.18786 -1.06748  0.30449]
21Feb12_222057| [-0.34578 -0.85935  0.46305]
21Feb12_222057| [-0.88531  0.61893  0.01799]
21Feb12_222057| [-0.81618  0.05790 -0.17864]
21Feb12_222057| [-1.35756  0.01771  0.16221]
21Feb12_222057| [-0.69178  0.18287  0.12650]
21Feb12_222057| [ 1.30106 -0.72102  0.24797]
21Feb12_222057| [ 0.67527  0.63348  0.41087]
21Feb12_222057| [-0.49881  0.11802 -0.14302]]
21Feb12_222057|-- Bias --
21Feb12_222057|[-0.63748 -0.26300 -0.28618]
21Feb12_222057|Layer 1:
21Feb12_222057|-- Config --
21Feb12_222057|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222057|-- Weights --
21Feb12_222057|[[-0.08274  0.46780]
21Feb12_222057| [ 0.17995  0.85493]
21Feb12_222057| [-0.45693  0.13859]]
21Feb12_222057|-- Bias --
21Feb12_222057|[-0.62075  0.53538]
21Feb12_222057|Layer 2:
21Feb12_222057|-- Config --
21Feb12_222057|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222057|-- Weights --
21Feb12_222057|[[ 0.54572 -0.88482]
21Feb12_222057| [ 0.72619  0.34039]]
21Feb12_222057|-- Bias --
21Feb12_222057|[-0.40957 -0.73958]
21Feb12_222057|Layer 3:
21Feb12_222057|-- Config --
21Feb12_222057|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222057|-- Weights --
21Feb12_222057|[[-1.36199  0.37967]
21Feb12_222057| [-0.28876  1.07865]]
21Feb12_222057|-- Bias --
21Feb12_222057|[-0.53688 -0.64166]
21Feb12_222057|Predicting the validation and test data with the Best final individual.
21Feb12_222105| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_222105|-----------  ------------------  --------------------  ----------
21Feb12_222105|Validation         25.74                  21            0.60177
21Feb12_222105|   Test            25.63                  21            0.53776
21Feb12_222105|-------------------- Test #8 --------------------
21Feb12_222105|Best final individual weights
21Feb12_222105|Individual:
21Feb12_222105|-- Constant hidden layers --
21Feb12_222105|False
21Feb12_222105|Layer 0:
21Feb12_222105|-- Config --
21Feb12_222105|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222105|-- Weights --
21Feb12_222105|[[-0.54170  0.93401  0.04119]
21Feb12_222105| [-0.77325 -0.24664  0.09186]
21Feb12_222105| [ 0.07303 -0.46735  0.22408]
21Feb12_222105| [-0.09164  0.56787  0.29850]
21Feb12_222105| [-0.58491  0.34197 -0.40097]
21Feb12_222105| [-0.34799 -0.86048  0.28810]
21Feb12_222105| [-1.62035 -0.08828  0.44185]
21Feb12_222105| [-0.53184 -0.76164  0.02387]
21Feb12_222105| [ 0.26800  0.85278  0.17889]
21Feb12_222105| [ 0.79304 -0.21543  0.44742]
21Feb12_222105| [ 1.59144 -0.53244  0.33350]
21Feb12_222105| [ 0.17031 -1.73297 -0.13458]
21Feb12_222105| [ 0.10736 -0.46047  0.40717]
21Feb12_222105| [-0.09455  0.05870 -0.09034]
21Feb12_222105| [ 0.97049 -1.07123  0.11308]
21Feb12_222105| [ 0.91502 -0.32412 -0.27406]
21Feb12_222105| [-0.84725  0.34525 -0.19755]
21Feb12_222105| [-0.48653 -1.15699 -0.31790]
21Feb12_222105| [ 1.14240 -0.55309 -0.20551]
21Feb12_222105| [-0.38509 -0.00396  0.39781]
21Feb12_222105| [-0.74234  0.94452  0.29499]
21Feb12_222105| [ 0.82853 -0.86330  0.20795]
21Feb12_222105| [ 0.44865  1.35322 -0.14925]
21Feb12_222105| [-0.52224 -1.06447  0.25464]
21Feb12_222105| [ 0.25889  0.48368 -0.30267]
21Feb12_222105| [ 0.46850  1.23438 -0.13521]
21Feb12_222105| [ 0.57000  0.79771 -0.29900]
21Feb12_222105| [ 0.78958  0.03141  0.13663]
21Feb12_222105| [-0.67589  0.89571  0.03663]
21Feb12_222105| [ 0.47376 -0.30171  0.38515]
21Feb12_222105| [-0.82374 -0.01550 -0.39589]
21Feb12_222105| [ 0.35163  0.66679 -0.37324]
21Feb12_222105| [-0.33912 -0.42369 -0.21317]
21Feb12_222105| [-0.85759  0.55191 -0.49204]
21Feb12_222105| [ 0.76109 -0.19150  0.06690]
21Feb12_222105| [-0.22136  1.32987  0.09748]
21Feb12_222105| [-0.92539 -0.15925  0.28459]
21Feb12_222105| [ 0.81702 -1.15448 -0.48097]
21Feb12_222105| [ 0.28820 -1.14299  0.48866]
21Feb12_222105| [-0.09292  0.30049 -0.16540]
21Feb12_222105| [ 1.12671 -1.05155 -0.01799]
21Feb12_222105| [-0.42620 -0.90990  0.10208]
21Feb12_222105| [ 0.24989 -0.44552  0.34534]
21Feb12_222105| [ 0.66356  0.18156 -0.16456]
21Feb12_222105| [ 0.09132  0.28170  0.13297]
21Feb12_222105| [ 1.14862 -0.97400  0.20232]
21Feb12_222105| [ 0.21230 -0.51829 -0.20180]
21Feb12_222105| [-0.55656  1.34553 -0.09400]
21Feb12_222105| [-0.18786 -1.06748  0.30449]
21Feb12_222105| [-0.34578 -0.85935  0.46305]
21Feb12_222105| [-0.88531  0.61893  0.01799]
21Feb12_222105| [-0.81618  0.05790 -0.17864]
21Feb12_222105| [-1.35756  0.01771  0.16221]
21Feb12_222105| [-0.69178  0.18287  0.12650]
21Feb12_222105| [ 1.30106 -0.72102  0.24797]
21Feb12_222105| [ 0.67527  0.63348  0.41087]
21Feb12_222105| [-0.49881  0.11802 -0.14302]]
21Feb12_222105|-- Bias --
21Feb12_222105|[-0.63748 -0.26300 -0.28618]
21Feb12_222105|Layer 1:
21Feb12_222105|-- Config --
21Feb12_222105|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222105|-- Weights --
21Feb12_222105|[[-0.08274  0.46780]
21Feb12_222105| [ 0.17995  0.85493]
21Feb12_222105| [-0.45693  0.13859]]
21Feb12_222105|-- Bias --
21Feb12_222105|[-0.62075  0.53538]
21Feb12_222105|Layer 2:
21Feb12_222105|-- Config --
21Feb12_222105|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222105|-- Weights --
21Feb12_222105|[[ 0.54572 -0.88482]
21Feb12_222105| [ 0.72619  0.34039]]
21Feb12_222105|-- Bias --
21Feb12_222105|[-0.40957 -0.73958]
21Feb12_222105|Layer 3:
21Feb12_222105|-- Config --
21Feb12_222105|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222105|-- Weights --
21Feb12_222105|[[-1.36199  0.37967]
21Feb12_222105| [-0.28876  1.07865]]
21Feb12_222105|-- Bias --
21Feb12_222105|[-0.53688 -0.64166]
21Feb12_222105|Predicting the validation and test data with the Best final individual.
21Feb12_222113| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_222113|-----------  ------------------  --------------------  ----------
21Feb12_222113|Validation         25.04                  21            0.47156
21Feb12_222113|   Test            26.15                  21            0.44206
21Feb12_222113|-------------------- Test #9 --------------------
21Feb12_222113|Best final individual weights
21Feb12_222113|Individual:
21Feb12_222113|-- Constant hidden layers --
21Feb12_222113|False
21Feb12_222113|Layer 0:
21Feb12_222113|-- Config --
21Feb12_222113|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222113|-- Weights --
21Feb12_222113|[[-0.54170  0.93401  0.04119]
21Feb12_222113| [-0.77325 -0.24664  0.09186]
21Feb12_222113| [ 0.07303 -0.46735  0.22408]
21Feb12_222113| [-0.09164  0.56787  0.29850]
21Feb12_222113| [-0.58491  0.34197 -0.40097]
21Feb12_222113| [-0.34799 -0.86048  0.28810]
21Feb12_222113| [-1.62035 -0.08828  0.44185]
21Feb12_222113| [-0.53184 -0.76164  0.02387]
21Feb12_222113| [ 0.26800  0.85278  0.17889]
21Feb12_222113| [ 0.79304 -0.21543  0.44742]
21Feb12_222113| [ 1.59144 -0.53244  0.33350]
21Feb12_222113| [ 0.17031 -1.73297 -0.13458]
21Feb12_222113| [ 0.10736 -0.46047  0.40717]
21Feb12_222113| [-0.09455  0.05870 -0.09034]
21Feb12_222113| [ 0.97049 -1.07123  0.11308]
21Feb12_222113| [ 0.91502 -0.32412 -0.27406]
21Feb12_222113| [-0.84725  0.34525 -0.19755]
21Feb12_222113| [-0.48653 -1.15699 -0.31790]
21Feb12_222113| [ 1.14240 -0.55309 -0.20551]
21Feb12_222113| [-0.38509 -0.00396  0.39781]
21Feb12_222113| [-0.74234  0.94452  0.29499]
21Feb12_222113| [ 0.82853 -0.86330  0.20795]
21Feb12_222113| [ 0.44865  1.35322 -0.14925]
21Feb12_222113| [-0.52224 -1.06447  0.25464]
21Feb12_222113| [ 0.25889  0.48368 -0.30267]
21Feb12_222113| [ 0.46850  1.23438 -0.13521]
21Feb12_222113| [ 0.57000  0.79771 -0.29900]
21Feb12_222113| [ 0.78958  0.03141  0.13663]
21Feb12_222113| [-0.67589  0.89571  0.03663]
21Feb12_222113| [ 0.47376 -0.30171  0.38515]
21Feb12_222113| [-0.82374 -0.01550 -0.39589]
21Feb12_222113| [ 0.35163  0.66679 -0.37324]
21Feb12_222113| [-0.33912 -0.42369 -0.21317]
21Feb12_222113| [-0.85759  0.55191 -0.49204]
21Feb12_222113| [ 0.76109 -0.19150  0.06690]
21Feb12_222113| [-0.22136  1.32987  0.09748]
21Feb12_222113| [-0.92539 -0.15925  0.28459]
21Feb12_222113| [ 0.81702 -1.15448 -0.48097]
21Feb12_222113| [ 0.28820 -1.14299  0.48866]
21Feb12_222113| [-0.09292  0.30049 -0.16540]
21Feb12_222113| [ 1.12671 -1.05155 -0.01799]
21Feb12_222113| [-0.42620 -0.90990  0.10208]
21Feb12_222113| [ 0.24989 -0.44552  0.34534]
21Feb12_222113| [ 0.66356  0.18156 -0.16456]
21Feb12_222113| [ 0.09132  0.28170  0.13297]
21Feb12_222113| [ 1.14862 -0.97400  0.20232]
21Feb12_222113| [ 0.21230 -0.51829 -0.20180]
21Feb12_222113| [-0.55656  1.34553 -0.09400]
21Feb12_222113| [-0.18786 -1.06748  0.30449]
21Feb12_222113| [-0.34578 -0.85935  0.46305]
21Feb12_222113| [-0.88531  0.61893  0.01799]
21Feb12_222113| [-0.81618  0.05790 -0.17864]
21Feb12_222113| [-1.35756  0.01771  0.16221]
21Feb12_222113| [-0.69178  0.18287  0.12650]
21Feb12_222113| [ 1.30106 -0.72102  0.24797]
21Feb12_222113| [ 0.67527  0.63348  0.41087]
21Feb12_222113| [-0.49881  0.11802 -0.14302]]
21Feb12_222113|-- Bias --
21Feb12_222113|[-0.63748 -0.26300 -0.28618]
21Feb12_222113|Layer 1:
21Feb12_222113|-- Config --
21Feb12_222113|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222113|-- Weights --
21Feb12_222113|[[-0.08274  0.46780]
21Feb12_222113| [ 0.17995  0.85493]
21Feb12_222113| [-0.45693  0.13859]]
21Feb12_222113|-- Bias --
21Feb12_222113|[-0.62075  0.53538]
21Feb12_222113|Layer 2:
21Feb12_222113|-- Config --
21Feb12_222113|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222113|-- Weights --
21Feb12_222113|[[ 0.54572 -0.88482]
21Feb12_222113| [ 0.72619  0.34039]]
21Feb12_222113|-- Bias --
21Feb12_222113|[-0.40957 -0.73958]
21Feb12_222113|Layer 3:
21Feb12_222113|-- Config --
21Feb12_222113|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222113|-- Weights --
21Feb12_222113|[[-1.36199  0.37967]
21Feb12_222113| [-0.28876  1.07865]]
21Feb12_222113|-- Bias --
21Feb12_222113|[-0.53688 -0.64166]
21Feb12_222113|Predicting the validation and test data with the Best final individual.
21Feb12_222121| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_222121|-----------  ------------------  --------------------  ----------
21Feb12_222121|Validation         25.48                  21            0.54249
21Feb12_222121|   Test            26.15                  21            0.54183
21Feb12_222121|-------------------- Test #10 --------------------
21Feb12_222121|Best final individual weights
21Feb12_222121|Individual:
21Feb12_222121|-- Constant hidden layers --
21Feb12_222121|False
21Feb12_222121|Layer 0:
21Feb12_222121|-- Config --
21Feb12_222121|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222121|-- Weights --
21Feb12_222121|[[-0.54170  0.93401  0.04119]
21Feb12_222121| [-0.77325 -0.24664  0.09186]
21Feb12_222121| [ 0.07303 -0.46735  0.22408]
21Feb12_222121| [-0.09164  0.56787  0.29850]
21Feb12_222121| [-0.58491  0.34197 -0.40097]
21Feb12_222121| [-0.34799 -0.86048  0.28810]
21Feb12_222121| [-1.62035 -0.08828  0.44185]
21Feb12_222121| [-0.53184 -0.76164  0.02387]
21Feb12_222121| [ 0.26800  0.85278  0.17889]
21Feb12_222121| [ 0.79304 -0.21543  0.44742]
21Feb12_222121| [ 1.59144 -0.53244  0.33350]
21Feb12_222121| [ 0.17031 -1.73297 -0.13458]
21Feb12_222121| [ 0.10736 -0.46047  0.40717]
21Feb12_222121| [-0.09455  0.05870 -0.09034]
21Feb12_222121| [ 0.97049 -1.07123  0.11308]
21Feb12_222121| [ 0.91502 -0.32412 -0.27406]
21Feb12_222121| [-0.84725  0.34525 -0.19755]
21Feb12_222121| [-0.48653 -1.15699 -0.31790]
21Feb12_222121| [ 1.14240 -0.55309 -0.20551]
21Feb12_222121| [-0.38509 -0.00396  0.39781]
21Feb12_222121| [-0.74234  0.94452  0.29499]
21Feb12_222121| [ 0.82853 -0.86330  0.20795]
21Feb12_222121| [ 0.44865  1.35322 -0.14925]
21Feb12_222121| [-0.52224 -1.06447  0.25464]
21Feb12_222121| [ 0.25889  0.48368 -0.30267]
21Feb12_222121| [ 0.46850  1.23438 -0.13521]
21Feb12_222121| [ 0.57000  0.79771 -0.29900]
21Feb12_222121| [ 0.78958  0.03141  0.13663]
21Feb12_222121| [-0.67589  0.89571  0.03663]
21Feb12_222121| [ 0.47376 -0.30171  0.38515]
21Feb12_222121| [-0.82374 -0.01550 -0.39589]
21Feb12_222121| [ 0.35163  0.66679 -0.37324]
21Feb12_222121| [-0.33912 -0.42369 -0.21317]
21Feb12_222121| [-0.85759  0.55191 -0.49204]
21Feb12_222121| [ 0.76109 -0.19150  0.06690]
21Feb12_222121| [-0.22136  1.32987  0.09748]
21Feb12_222121| [-0.92539 -0.15925  0.28459]
21Feb12_222121| [ 0.81702 -1.15448 -0.48097]
21Feb12_222121| [ 0.28820 -1.14299  0.48866]
21Feb12_222121| [-0.09292  0.30049 -0.16540]
21Feb12_222121| [ 1.12671 -1.05155 -0.01799]
21Feb12_222121| [-0.42620 -0.90990  0.10208]
21Feb12_222121| [ 0.24989 -0.44552  0.34534]
21Feb12_222121| [ 0.66356  0.18156 -0.16456]
21Feb12_222121| [ 0.09132  0.28170  0.13297]
21Feb12_222121| [ 1.14862 -0.97400  0.20232]
21Feb12_222121| [ 0.21230 -0.51829 -0.20180]
21Feb12_222121| [-0.55656  1.34553 -0.09400]
21Feb12_222121| [-0.18786 -1.06748  0.30449]
21Feb12_222121| [-0.34578 -0.85935  0.46305]
21Feb12_222121| [-0.88531  0.61893  0.01799]
21Feb12_222121| [-0.81618  0.05790 -0.17864]
21Feb12_222121| [-1.35756  0.01771  0.16221]
21Feb12_222121| [-0.69178  0.18287  0.12650]
21Feb12_222121| [ 1.30106 -0.72102  0.24797]
21Feb12_222121| [ 0.67527  0.63348  0.41087]
21Feb12_222121| [-0.49881  0.11802 -0.14302]]
21Feb12_222121|-- Bias --
21Feb12_222121|[-0.63748 -0.26300 -0.28618]
21Feb12_222121|Layer 1:
21Feb12_222121|-- Config --
21Feb12_222121|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222121|-- Weights --
21Feb12_222121|[[-0.08274  0.46780]
21Feb12_222121| [ 0.17995  0.85493]
21Feb12_222121| [-0.45693  0.13859]]
21Feb12_222121|-- Bias --
21Feb12_222121|[-0.62075  0.53538]
21Feb12_222121|Layer 2:
21Feb12_222121|-- Config --
21Feb12_222121|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222121|-- Weights --
21Feb12_222121|[[ 0.54572 -0.88482]
21Feb12_222121| [ 0.72619  0.34039]]
21Feb12_222121|-- Bias --
21Feb12_222121|[-0.40957 -0.73958]
21Feb12_222121|Layer 3:
21Feb12_222121|-- Config --
21Feb12_222121|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222121|-- Weights --
21Feb12_222121|[[-1.36199  0.37967]
21Feb12_222121| [-0.28876  1.07865]]
21Feb12_222121|-- Bias --
21Feb12_222121|[-0.53688 -0.64166]
21Feb12_222121|Predicting the validation and test data with the Best final individual.
21Feb12_222129| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_222129|-----------  ------------------  --------------------  ----------
21Feb12_222129|Validation         25.83                  21            0.44495
21Feb12_222129|   Test            27.89                  21            0.38110
21Feb12_222129|-------------------- Test #11 --------------------
21Feb12_222129|Best final individual weights
21Feb12_222129|Individual:
21Feb12_222129|-- Constant hidden layers --
21Feb12_222129|False
21Feb12_222129|Layer 0:
21Feb12_222129|-- Config --
21Feb12_222129|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222129|-- Weights --
21Feb12_222129|[[-0.54170  0.93401  0.04119]
21Feb12_222129| [-0.77325 -0.24664  0.09186]
21Feb12_222129| [ 0.07303 -0.46735  0.22408]
21Feb12_222129| [-0.09164  0.56787  0.29850]
21Feb12_222129| [-0.58491  0.34197 -0.40097]
21Feb12_222129| [-0.34799 -0.86048  0.28810]
21Feb12_222129| [-1.62035 -0.08828  0.44185]
21Feb12_222129| [-0.53184 -0.76164  0.02387]
21Feb12_222129| [ 0.26800  0.85278  0.17889]
21Feb12_222129| [ 0.79304 -0.21543  0.44742]
21Feb12_222129| [ 1.59144 -0.53244  0.33350]
21Feb12_222129| [ 0.17031 -1.73297 -0.13458]
21Feb12_222129| [ 0.10736 -0.46047  0.40717]
21Feb12_222129| [-0.09455  0.05870 -0.09034]
21Feb12_222129| [ 0.97049 -1.07123  0.11308]
21Feb12_222129| [ 0.91502 -0.32412 -0.27406]
21Feb12_222129| [-0.84725  0.34525 -0.19755]
21Feb12_222129| [-0.48653 -1.15699 -0.31790]
21Feb12_222129| [ 1.14240 -0.55309 -0.20551]
21Feb12_222129| [-0.38509 -0.00396  0.39781]
21Feb12_222129| [-0.74234  0.94452  0.29499]
21Feb12_222129| [ 0.82853 -0.86330  0.20795]
21Feb12_222129| [ 0.44865  1.35322 -0.14925]
21Feb12_222129| [-0.52224 -1.06447  0.25464]
21Feb12_222129| [ 0.25889  0.48368 -0.30267]
21Feb12_222129| [ 0.46850  1.23438 -0.13521]
21Feb12_222129| [ 0.57000  0.79771 -0.29900]
21Feb12_222129| [ 0.78958  0.03141  0.13663]
21Feb12_222129| [-0.67589  0.89571  0.03663]
21Feb12_222129| [ 0.47376 -0.30171  0.38515]
21Feb12_222129| [-0.82374 -0.01550 -0.39589]
21Feb12_222129| [ 0.35163  0.66679 -0.37324]
21Feb12_222129| [-0.33912 -0.42369 -0.21317]
21Feb12_222129| [-0.85759  0.55191 -0.49204]
21Feb12_222129| [ 0.76109 -0.19150  0.06690]
21Feb12_222129| [-0.22136  1.32987  0.09748]
21Feb12_222129| [-0.92539 -0.15925  0.28459]
21Feb12_222129| [ 0.81702 -1.15448 -0.48097]
21Feb12_222129| [ 0.28820 -1.14299  0.48866]
21Feb12_222129| [-0.09292  0.30049 -0.16540]
21Feb12_222129| [ 1.12671 -1.05155 -0.01799]
21Feb12_222129| [-0.42620 -0.90990  0.10208]
21Feb12_222129| [ 0.24989 -0.44552  0.34534]
21Feb12_222129| [ 0.66356  0.18156 -0.16456]
21Feb12_222129| [ 0.09132  0.28170  0.13297]
21Feb12_222129| [ 1.14862 -0.97400  0.20232]
21Feb12_222129| [ 0.21230 -0.51829 -0.20180]
21Feb12_222129| [-0.55656  1.34553 -0.09400]
21Feb12_222129| [-0.18786 -1.06748  0.30449]
21Feb12_222129| [-0.34578 -0.85935  0.46305]
21Feb12_222129| [-0.88531  0.61893  0.01799]
21Feb12_222129| [-0.81618  0.05790 -0.17864]
21Feb12_222129| [-1.35756  0.01771  0.16221]
21Feb12_222129| [-0.69178  0.18287  0.12650]
21Feb12_222129| [ 1.30106 -0.72102  0.24797]
21Feb12_222129| [ 0.67527  0.63348  0.41087]
21Feb12_222129| [-0.49881  0.11802 -0.14302]]
21Feb12_222129|-- Bias --
21Feb12_222129|[-0.63748 -0.26300 -0.28618]
21Feb12_222129|Layer 1:
21Feb12_222129|-- Config --
21Feb12_222129|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222129|-- Weights --
21Feb12_222129|[[-0.08274  0.46780]
21Feb12_222129| [ 0.17995  0.85493]
21Feb12_222129| [-0.45693  0.13859]]
21Feb12_222129|-- Bias --
21Feb12_222129|[-0.62075  0.53538]
21Feb12_222129|Layer 2:
21Feb12_222129|-- Config --
21Feb12_222129|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222129|-- Weights --
21Feb12_222129|[[ 0.54572 -0.88482]
21Feb12_222129| [ 0.72619  0.34039]]
21Feb12_222129|-- Bias --
21Feb12_222129|[-0.40957 -0.73958]
21Feb12_222129|Layer 3:
21Feb12_222129|-- Config --
21Feb12_222129|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222129|-- Weights --
21Feb12_222129|[[-1.36199  0.37967]
21Feb12_222129| [-0.28876  1.07865]]
21Feb12_222129|-- Bias --
21Feb12_222129|[-0.53688 -0.64166]
21Feb12_222129|Predicting the validation and test data with the Best final individual.
21Feb12_222136| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_222136|-----------  ------------------  --------------------  ----------
21Feb12_222136|Validation         25.39                  21            0.53140
21Feb12_222136|   Test            28.50                  21            0.37760
21Feb12_222136|-------------------- Test #12 --------------------
21Feb12_222136|Best final individual weights
21Feb12_222136|Individual:
21Feb12_222136|-- Constant hidden layers --
21Feb12_222136|False
21Feb12_222136|Layer 0:
21Feb12_222136|-- Config --
21Feb12_222136|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222136|-- Weights --
21Feb12_222136|[[-0.54170  0.93401  0.04119]
21Feb12_222136| [-0.77325 -0.24664  0.09186]
21Feb12_222136| [ 0.07303 -0.46735  0.22408]
21Feb12_222136| [-0.09164  0.56787  0.29850]
21Feb12_222136| [-0.58491  0.34197 -0.40097]
21Feb12_222136| [-0.34799 -0.86048  0.28810]
21Feb12_222136| [-1.62035 -0.08828  0.44185]
21Feb12_222136| [-0.53184 -0.76164  0.02387]
21Feb12_222136| [ 0.26800  0.85278  0.17889]
21Feb12_222136| [ 0.79304 -0.21543  0.44742]
21Feb12_222136| [ 1.59144 -0.53244  0.33350]
21Feb12_222136| [ 0.17031 -1.73297 -0.13458]
21Feb12_222136| [ 0.10736 -0.46047  0.40717]
21Feb12_222136| [-0.09455  0.05870 -0.09034]
21Feb12_222136| [ 0.97049 -1.07123  0.11308]
21Feb12_222136| [ 0.91502 -0.32412 -0.27406]
21Feb12_222136| [-0.84725  0.34525 -0.19755]
21Feb12_222136| [-0.48653 -1.15699 -0.31790]
21Feb12_222136| [ 1.14240 -0.55309 -0.20551]
21Feb12_222136| [-0.38509 -0.00396  0.39781]
21Feb12_222136| [-0.74234  0.94452  0.29499]
21Feb12_222136| [ 0.82853 -0.86330  0.20795]
21Feb12_222136| [ 0.44865  1.35322 -0.14925]
21Feb12_222136| [-0.52224 -1.06447  0.25464]
21Feb12_222136| [ 0.25889  0.48368 -0.30267]
21Feb12_222136| [ 0.46850  1.23438 -0.13521]
21Feb12_222136| [ 0.57000  0.79771 -0.29900]
21Feb12_222136| [ 0.78958  0.03141  0.13663]
21Feb12_222136| [-0.67589  0.89571  0.03663]
21Feb12_222136| [ 0.47376 -0.30171  0.38515]
21Feb12_222136| [-0.82374 -0.01550 -0.39589]
21Feb12_222136| [ 0.35163  0.66679 -0.37324]
21Feb12_222136| [-0.33912 -0.42369 -0.21317]
21Feb12_222136| [-0.85759  0.55191 -0.49204]
21Feb12_222136| [ 0.76109 -0.19150  0.06690]
21Feb12_222136| [-0.22136  1.32987  0.09748]
21Feb12_222136| [-0.92539 -0.15925  0.28459]
21Feb12_222136| [ 0.81702 -1.15448 -0.48097]
21Feb12_222136| [ 0.28820 -1.14299  0.48866]
21Feb12_222136| [-0.09292  0.30049 -0.16540]
21Feb12_222136| [ 1.12671 -1.05155 -0.01799]
21Feb12_222136| [-0.42620 -0.90990  0.10208]
21Feb12_222136| [ 0.24989 -0.44552  0.34534]
21Feb12_222136| [ 0.66356  0.18156 -0.16456]
21Feb12_222136| [ 0.09132  0.28170  0.13297]
21Feb12_222136| [ 1.14862 -0.97400  0.20232]
21Feb12_222136| [ 0.21230 -0.51829 -0.20180]
21Feb12_222136| [-0.55656  1.34553 -0.09400]
21Feb12_222136| [-0.18786 -1.06748  0.30449]
21Feb12_222136| [-0.34578 -0.85935  0.46305]
21Feb12_222136| [-0.88531  0.61893  0.01799]
21Feb12_222136| [-0.81618  0.05790 -0.17864]
21Feb12_222136| [-1.35756  0.01771  0.16221]
21Feb12_222136| [-0.69178  0.18287  0.12650]
21Feb12_222136| [ 1.30106 -0.72102  0.24797]
21Feb12_222136| [ 0.67527  0.63348  0.41087]
21Feb12_222136| [-0.49881  0.11802 -0.14302]]
21Feb12_222136|-- Bias --
21Feb12_222136|[-0.63748 -0.26300 -0.28618]
21Feb12_222136|Layer 1:
21Feb12_222136|-- Config --
21Feb12_222136|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222136|-- Weights --
21Feb12_222136|[[-0.08274  0.46780]
21Feb12_222136| [ 0.17995  0.85493]
21Feb12_222136| [-0.45693  0.13859]]
21Feb12_222136|-- Bias --
21Feb12_222136|[-0.62075  0.53538]
21Feb12_222136|Layer 2:
21Feb12_222136|-- Config --
21Feb12_222136|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222136|-- Weights --
21Feb12_222136|[[ 0.54572 -0.88482]
21Feb12_222136| [ 0.72619  0.34039]]
21Feb12_222136|-- Bias --
21Feb12_222136|[-0.40957 -0.73958]
21Feb12_222136|Layer 3:
21Feb12_222136|-- Config --
21Feb12_222136|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222136|-- Weights --
21Feb12_222136|[[-1.36199  0.37967]
21Feb12_222136| [-0.28876  1.07865]]
21Feb12_222136|-- Bias --
21Feb12_222136|[-0.53688 -0.64166]
21Feb12_222136|Predicting the validation and test data with the Best final individual.
21Feb12_222144| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_222144|-----------  ------------------  --------------------  ----------
21Feb12_222144|Validation         25.48                  21            0.58298
21Feb12_222144|   Test            25.72                  21            0.54312
21Feb12_222144|-------------------- Test #13 --------------------
21Feb12_222144|Best final individual weights
21Feb12_222144|Individual:
21Feb12_222144|-- Constant hidden layers --
21Feb12_222144|False
21Feb12_222144|Layer 0:
21Feb12_222144|-- Config --
21Feb12_222144|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222144|-- Weights --
21Feb12_222144|[[-0.54170  0.93401  0.04119]
21Feb12_222144| [-0.77325 -0.24664  0.09186]
21Feb12_222144| [ 0.07303 -0.46735  0.22408]
21Feb12_222144| [-0.09164  0.56787  0.29850]
21Feb12_222144| [-0.58491  0.34197 -0.40097]
21Feb12_222144| [-0.34799 -0.86048  0.28810]
21Feb12_222144| [-1.62035 -0.08828  0.44185]
21Feb12_222144| [-0.53184 -0.76164  0.02387]
21Feb12_222144| [ 0.26800  0.85278  0.17889]
21Feb12_222144| [ 0.79304 -0.21543  0.44742]
21Feb12_222144| [ 1.59144 -0.53244  0.33350]
21Feb12_222144| [ 0.17031 -1.73297 -0.13458]
21Feb12_222144| [ 0.10736 -0.46047  0.40717]
21Feb12_222144| [-0.09455  0.05870 -0.09034]
21Feb12_222144| [ 0.97049 -1.07123  0.11308]
21Feb12_222144| [ 0.91502 -0.32412 -0.27406]
21Feb12_222144| [-0.84725  0.34525 -0.19755]
21Feb12_222144| [-0.48653 -1.15699 -0.31790]
21Feb12_222144| [ 1.14240 -0.55309 -0.20551]
21Feb12_222144| [-0.38509 -0.00396  0.39781]
21Feb12_222144| [-0.74234  0.94452  0.29499]
21Feb12_222144| [ 0.82853 -0.86330  0.20795]
21Feb12_222144| [ 0.44865  1.35322 -0.14925]
21Feb12_222144| [-0.52224 -1.06447  0.25464]
21Feb12_222144| [ 0.25889  0.48368 -0.30267]
21Feb12_222144| [ 0.46850  1.23438 -0.13521]
21Feb12_222144| [ 0.57000  0.79771 -0.29900]
21Feb12_222144| [ 0.78958  0.03141  0.13663]
21Feb12_222144| [-0.67589  0.89571  0.03663]
21Feb12_222144| [ 0.47376 -0.30171  0.38515]
21Feb12_222144| [-0.82374 -0.01550 -0.39589]
21Feb12_222144| [ 0.35163  0.66679 -0.37324]
21Feb12_222144| [-0.33912 -0.42369 -0.21317]
21Feb12_222144| [-0.85759  0.55191 -0.49204]
21Feb12_222144| [ 0.76109 -0.19150  0.06690]
21Feb12_222144| [-0.22136  1.32987  0.09748]
21Feb12_222144| [-0.92539 -0.15925  0.28459]
21Feb12_222144| [ 0.81702 -1.15448 -0.48097]
21Feb12_222144| [ 0.28820 -1.14299  0.48866]
21Feb12_222144| [-0.09292  0.30049 -0.16540]
21Feb12_222144| [ 1.12671 -1.05155 -0.01799]
21Feb12_222144| [-0.42620 -0.90990  0.10208]
21Feb12_222144| [ 0.24989 -0.44552  0.34534]
21Feb12_222144| [ 0.66356  0.18156 -0.16456]
21Feb12_222144| [ 0.09132  0.28170  0.13297]
21Feb12_222144| [ 1.14862 -0.97400  0.20232]
21Feb12_222144| [ 0.21230 -0.51829 -0.20180]
21Feb12_222144| [-0.55656  1.34553 -0.09400]
21Feb12_222144| [-0.18786 -1.06748  0.30449]
21Feb12_222144| [-0.34578 -0.85935  0.46305]
21Feb12_222144| [-0.88531  0.61893  0.01799]
21Feb12_222144| [-0.81618  0.05790 -0.17864]
21Feb12_222144| [-1.35756  0.01771  0.16221]
21Feb12_222144| [-0.69178  0.18287  0.12650]
21Feb12_222144| [ 1.30106 -0.72102  0.24797]
21Feb12_222144| [ 0.67527  0.63348  0.41087]
21Feb12_222144| [-0.49881  0.11802 -0.14302]]
21Feb12_222144|-- Bias --
21Feb12_222144|[-0.63748 -0.26300 -0.28618]
21Feb12_222144|Layer 1:
21Feb12_222144|-- Config --
21Feb12_222144|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222144|-- Weights --
21Feb12_222144|[[-0.08274  0.46780]
21Feb12_222144| [ 0.17995  0.85493]
21Feb12_222144| [-0.45693  0.13859]]
21Feb12_222144|-- Bias --
21Feb12_222144|[-0.62075  0.53538]
21Feb12_222144|Layer 2:
21Feb12_222144|-- Config --
21Feb12_222144|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222144|-- Weights --
21Feb12_222144|[[ 0.54572 -0.88482]
21Feb12_222144| [ 0.72619  0.34039]]
21Feb12_222144|-- Bias --
21Feb12_222144|[-0.40957 -0.73958]
21Feb12_222144|Layer 3:
21Feb12_222144|-- Config --
21Feb12_222144|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222144|-- Weights --
21Feb12_222144|[[-1.36199  0.37967]
21Feb12_222144| [-0.28876  1.07865]]
21Feb12_222144|-- Bias --
21Feb12_222144|[-0.53688 -0.64166]
21Feb12_222144|Predicting the validation and test data with the Best final individual.
21Feb12_222152| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_222152|-----------  ------------------  --------------------  ----------
21Feb12_222152|Validation         25.48                  21            0.49237
21Feb12_222152|   Test            25.80                  21            0.50679
21Feb12_222152|-------------------- Test #14 --------------------
21Feb12_222152|Best final individual weights
21Feb12_222152|Individual:
21Feb12_222152|-- Constant hidden layers --
21Feb12_222152|False
21Feb12_222152|Layer 0:
21Feb12_222152|-- Config --
21Feb12_222152|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222152|-- Weights --
21Feb12_222152|[[-0.54170  0.93401  0.04119]
21Feb12_222152| [-0.77325 -0.24664  0.09186]
21Feb12_222152| [ 0.07303 -0.46735  0.22408]
21Feb12_222152| [-0.09164  0.56787  0.29850]
21Feb12_222152| [-0.58491  0.34197 -0.40097]
21Feb12_222152| [-0.34799 -0.86048  0.28810]
21Feb12_222152| [-1.62035 -0.08828  0.44185]
21Feb12_222152| [-0.53184 -0.76164  0.02387]
21Feb12_222152| [ 0.26800  0.85278  0.17889]
21Feb12_222152| [ 0.79304 -0.21543  0.44742]
21Feb12_222152| [ 1.59144 -0.53244  0.33350]
21Feb12_222152| [ 0.17031 -1.73297 -0.13458]
21Feb12_222152| [ 0.10736 -0.46047  0.40717]
21Feb12_222152| [-0.09455  0.05870 -0.09034]
21Feb12_222152| [ 0.97049 -1.07123  0.11308]
21Feb12_222152| [ 0.91502 -0.32412 -0.27406]
21Feb12_222152| [-0.84725  0.34525 -0.19755]
21Feb12_222152| [-0.48653 -1.15699 -0.31790]
21Feb12_222152| [ 1.14240 -0.55309 -0.20551]
21Feb12_222152| [-0.38509 -0.00396  0.39781]
21Feb12_222152| [-0.74234  0.94452  0.29499]
21Feb12_222152| [ 0.82853 -0.86330  0.20795]
21Feb12_222152| [ 0.44865  1.35322 -0.14925]
21Feb12_222152| [-0.52224 -1.06447  0.25464]
21Feb12_222152| [ 0.25889  0.48368 -0.30267]
21Feb12_222152| [ 0.46850  1.23438 -0.13521]
21Feb12_222152| [ 0.57000  0.79771 -0.29900]
21Feb12_222152| [ 0.78958  0.03141  0.13663]
21Feb12_222152| [-0.67589  0.89571  0.03663]
21Feb12_222152| [ 0.47376 -0.30171  0.38515]
21Feb12_222152| [-0.82374 -0.01550 -0.39589]
21Feb12_222152| [ 0.35163  0.66679 -0.37324]
21Feb12_222152| [-0.33912 -0.42369 -0.21317]
21Feb12_222152| [-0.85759  0.55191 -0.49204]
21Feb12_222152| [ 0.76109 -0.19150  0.06690]
21Feb12_222152| [-0.22136  1.32987  0.09748]
21Feb12_222152| [-0.92539 -0.15925  0.28459]
21Feb12_222152| [ 0.81702 -1.15448 -0.48097]
21Feb12_222152| [ 0.28820 -1.14299  0.48866]
21Feb12_222152| [-0.09292  0.30049 -0.16540]
21Feb12_222152| [ 1.12671 -1.05155 -0.01799]
21Feb12_222152| [-0.42620 -0.90990  0.10208]
21Feb12_222152| [ 0.24989 -0.44552  0.34534]
21Feb12_222152| [ 0.66356  0.18156 -0.16456]
21Feb12_222152| [ 0.09132  0.28170  0.13297]
21Feb12_222152| [ 1.14862 -0.97400  0.20232]
21Feb12_222152| [ 0.21230 -0.51829 -0.20180]
21Feb12_222152| [-0.55656  1.34553 -0.09400]
21Feb12_222152| [-0.18786 -1.06748  0.30449]
21Feb12_222152| [-0.34578 -0.85935  0.46305]
21Feb12_222152| [-0.88531  0.61893  0.01799]
21Feb12_222152| [-0.81618  0.05790 -0.17864]
21Feb12_222152| [-1.35756  0.01771  0.16221]
21Feb12_222152| [-0.69178  0.18287  0.12650]
21Feb12_222152| [ 1.30106 -0.72102  0.24797]
21Feb12_222152| [ 0.67527  0.63348  0.41087]
21Feb12_222152| [-0.49881  0.11802 -0.14302]]
21Feb12_222152|-- Bias --
21Feb12_222152|[-0.63748 -0.26300 -0.28618]
21Feb12_222152|Layer 1:
21Feb12_222152|-- Config --
21Feb12_222152|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222152|-- Weights --
21Feb12_222152|[[-0.08274  0.46780]
21Feb12_222152| [ 0.17995  0.85493]
21Feb12_222152| [-0.45693  0.13859]]
21Feb12_222152|-- Bias --
21Feb12_222152|[-0.62075  0.53538]
21Feb12_222152|Layer 2:
21Feb12_222152|-- Config --
21Feb12_222152|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222152|-- Weights --
21Feb12_222152|[[ 0.54572 -0.88482]
21Feb12_222152| [ 0.72619  0.34039]]
21Feb12_222152|-- Bias --
21Feb12_222152|[-0.40957 -0.73958]
21Feb12_222152|Layer 3:
21Feb12_222152|-- Config --
21Feb12_222152|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_222152|-- Weights --
21Feb12_222152|[[-1.36199  0.37967]
21Feb12_222152| [-0.28876  1.07865]]
21Feb12_222152|-- Bias --
21Feb12_222152|[-0.53688 -0.64166]
21Feb12_222152|Predicting the validation and test data with the Best final individual.
21Feb12_222200| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_222200|-----------  ------------------  --------------------  ----------
21Feb12_222200|Validation         25.65                  21            0.47796
21Feb12_222200|   Test            27.80                  21            0.41937
2021-02-12 22:22:01.073339: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
21Feb12_222201|Data summary: Train
21Feb12_222201|data.shape = (2300, 57)
21Feb12_222201|labels.shape = (2300,)
21Feb12_222201|Class distribution:
21Feb12_222201|	0 - 1382 (0.60)
21Feb12_222201|	1 - 918 (0.40)
21Feb12_222201|Data summary: Validation
21Feb12_222201|data.shape = (1150, 57)
21Feb12_222201|labels.shape = (1150,)
21Feb12_222201|Class distribution:
21Feb12_222201|	0 - 704 (0.61)
21Feb12_222201|	1 - 446 (0.39)
21Feb12_222201|Data summary: Test
21Feb12_222201|data.shape = (1151, 57)
21Feb12_222201|labels.shape = (1151,)
21Feb12_222201|Class distribution:
21Feb12_222201|	0 - 702 (0.61)
21Feb12_222201|	1 - 449 (0.39)
21Feb12_222201|Selected configuration values
21Feb12_222201|-- Dataset name: spambase1
21Feb12_222201|-- Initial population size: 64
21Feb12_222201|-- Maximun number of generations: 32
21Feb12_222201|-- Neurons per hidden layer range: (2, 20)
21Feb12_222201|-- Hidden layers number range: (1, 3)
21Feb12_222201|-- Crossover probability: 0.5
21Feb12_222201|-- Bias gene mutation probability: 0.2
21Feb12_222201|-- Weights gene mutation probability: 0.75
21Feb12_222201|-- Neuron mutation probability: 0.3
21Feb12_222201|-- Layer mutation probability: 0.3
21Feb12_222201|-- Constant hidden layers: False
21Feb12_222201|-- Seed: 31415
21Feb12_222201|Entering GA
21Feb12_222201|Start the algorithm
2021-02-12 22:22:01.945538: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-12 22:22:01.946102: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-02-12 22:22:01.967075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-12 22:22:01.967407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.71GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s
2021-02-12 22:22:01.967422: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-02-12 22:22:01.968915: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-02-12 22:22:01.968951: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-02-12 22:22:01.969468: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-02-12 22:22:01.969602: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-02-12 22:22:01.969674: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-12 22:22:01.970096: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-02-12 22:22:01.970138: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-12 22:22:01.970144: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-02-12 22:22:01.970322: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-02-12 22:22:01.971180: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-12 22:22:01.971207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-12 22:22:01.971210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      
2021-02-12 22:22:02.016926: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-02-12 22:22:02.017236: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3493635000 Hz
/home/jmerelo/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype("int32")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn('`model.predict_classes()` is deprecated and '
21Feb12_222606|-- Generation 1 --
21Feb12_222606|    -- Crossed 2 individual pairs.
21Feb12_222606|    -- Mutated 32 individuals.
21Feb12_223009|    -- Evaluated 64 individuals.
21Feb12_223009|    Summary of generation 1:
21Feb12_223009| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_223009|-----------  ------------------  --------------------  ----------
21Feb12_223009|    Max            39.30                136.00          0.64020
21Feb12_223009|    Avg            38.65                52.38           0.01013
21Feb12_223009|    Min            24.61                 3.00           0.00000
21Feb12_223009|    Std             1.77                43.73           0.07939
21Feb12_223009|   Best            24.61                62.00           0.64020
21Feb12_223009|-- Generation 2 --
21Feb12_223009|    -- Crossed 1 individual pairs.
21Feb12_223009|    -- Mutated 32 individuals.
21Feb12_223413|    -- Evaluated 64 individuals.
21Feb12_223413|    Summary of generation 2:
21Feb12_223413| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_223413|-----------  ------------------  --------------------  ----------
21Feb12_223413|    Max            39.30                124.00          0.60976
21Feb12_223413|    Avg            38.56                46.59           0.01134
21Feb12_223413|    Min            23.83                 3.00           0.00000
21Feb12_223413|    Std             1.87                35.88           0.07608
21Feb12_223413|   Best            23.83                 6.00           0.60976
21Feb12_223413|-- Generation 3 --
21Feb12_223413|    -- Crossed 2 individual pairs.
21Feb12_223413|    -- Mutated 32 individuals.
21Feb12_223815|    -- Evaluated 64 individuals.
21Feb12_223815|    Summary of generation 3:
21Feb12_223815| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_223815|-----------  ------------------  --------------------  ----------
21Feb12_223815|    Max            39.22                88.00           0.70596
21Feb12_223815|    Avg            38.24                28.34           0.02958
21Feb12_223815|    Min            24.35                 2.00           0.00000
21Feb12_223815|    Std             2.68                23.20           0.13034
21Feb12_223815|   Best            24.35                42.00           0.57013
21Feb12_223815|-- Generation 4 --
21Feb12_223815|    -- Crossed 2 individual pairs.
21Feb12_223815|    -- Mutated 32 individuals.
21Feb12_224212|    -- Evaluated 64 individuals.
21Feb12_224212|    Summary of generation 4:
21Feb12_224212| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_224212|-----------  ------------------  --------------------  ----------
21Feb12_224212|    Max            39.04                96.00           0.44907
21Feb12_224212|    Avg            38.52                16.28           0.01082
21Feb12_224212|    Min            25.83                 2.00           0.00000
21Feb12_224212|    Std             1.71                15.82           0.06087
21Feb12_224212|   Best            25.83                10.00           0.44907
21Feb12_224212|-- Generation 5 --
21Feb12_224212|    -- Crossed 4 individual pairs.
21Feb12_224212|    -- Mutated 32 individuals.
21Feb12_224607|    -- Evaluated 64 individuals.
21Feb12_224607|    Summary of generation 5:
21Feb12_224607| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_224607|-----------  ------------------  --------------------  ----------
21Feb12_224607|    Max            39.13                48.00           0.72977
21Feb12_224607|    Avg            38.40                 9.44           0.02270
21Feb12_224607|    Min            22.87                 2.00           0.00000
21Feb12_224607|    Std             2.29                 8.89           0.12350
21Feb12_224607|   Best            22.87                 8.00           0.72977
21Feb12_224607|-- Generation 6 --
21Feb12_224607|    -- Crossed 5 individual pairs.
21Feb12_224607|    -- Mutated 32 individuals.
21Feb12_225000|    -- Evaluated 64 individuals.
21Feb12_225000|    Summary of generation 6:
21Feb12_225000| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_225000|-----------  ------------------  --------------------  ----------
21Feb12_225000|    Max            39.74                48.00           0.84372
21Feb12_225000|    Avg            38.36                 8.23           0.02313
21Feb12_225000|    Min            22.26                 2.00           0.00000
21Feb12_225000|    Std             2.57                 8.92           0.12498
21Feb12_225000|   Best            22.26                48.00           0.84372
21Feb12_225000|-- Generation 7 --
21Feb12_225000|    -- Crossed 6 individual pairs.
21Feb12_225000|    -- Mutated 32 individuals.
21Feb12_225351|    -- Evaluated 64 individuals.
21Feb12_225351|    Summary of generation 7:
21Feb12_225351| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_225351|-----------  ------------------  --------------------  ----------
21Feb12_225351|    Max            38.96                48.00           0.73497
21Feb12_225351|    Avg            38.35                 6.41           0.02026
21Feb12_225351|    Min            23.57                 2.00           0.00000
21Feb12_225351|    Std             2.50                 8.46           0.11382
21Feb12_225351|   Best            23.57                48.00           0.73497
21Feb12_225351|-- Generation 8 --
21Feb12_225351|    -- Crossed 9 individual pairs.
21Feb12_225351|    -- Mutated 32 individuals.
21Feb12_225742|    -- Evaluated 64 individuals.
21Feb12_225742|    Summary of generation 8:
21Feb12_225742| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_225742|-----------  ------------------  --------------------  ----------
21Feb12_225742|    Max            40.17                52.00           0.79382
21Feb12_225742|    Avg            38.36                 6.83           0.02332
21Feb12_225742|    Min            20.09                 2.00           0.00000
21Feb12_225742|    Std             2.69                10.47           0.13009
21Feb12_225742|   Best            20.09                48.00           0.79382
21Feb12_225742|-- Generation 9 --
21Feb12_225742|    -- Crossed 8 individual pairs.
21Feb12_225742|    -- Mutated 32 individuals.
21Feb12_230132|    -- Evaluated 64 individuals.
21Feb12_230132|    Summary of generation 9:
21Feb12_230132| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_230132|-----------  ------------------  --------------------  ----------
21Feb12_230132|    Max            38.96                48.00           0.80400
21Feb12_230132|    Avg            38.33                 5.64           0.02370
21Feb12_230132|    Min            19.39                 2.00           0.00000
21Feb12_230132|    Std             2.69                 8.52           0.13222
21Feb12_230132|   Best            19.39                48.00           0.80400
21Feb12_230132|-- Generation 10 --
21Feb12_230132|    -- Crossed 9 individual pairs.
21Feb12_230132|    -- Mutated 32 individuals.
21Feb12_230524|    -- Evaluated 64 individuals.
21Feb12_230524|    Summary of generation 10:
21Feb12_230524| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_230524|-----------  ------------------  --------------------  ----------
21Feb12_230524|    Max            39.30                80.00           0.80614
21Feb12_230524|    Avg            38.00                 6.98           0.04692
21Feb12_230524|    Min            20.96                 2.00           0.00000
21Feb12_230524|    Std             3.51                13.73           0.18215
21Feb12_230524|   Best            20.96                80.00           0.72903
21Feb12_230524|-- Generation 11 --
21Feb12_230524|    -- Crossed 10 individual pairs.
21Feb12_230524|    -- Mutated 32 individuals.
21Feb12_230918|    -- Evaluated 64 individuals.
21Feb12_230918|    Summary of generation 11:
21Feb12_230918| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_230918|-----------  ------------------  --------------------  ----------
21Feb12_230918|    Max            39.13                80.00           0.85825
21Feb12_230918|    Avg            37.37                10.81           0.08197
21Feb12_230918|    Min            22.78                 2.00           0.00000
21Feb12_230918|    Std             3.95                19.16           0.22383
21Feb12_230918|   Best            22.78                48.00           0.66007
21Feb12_230918|-- Generation 12 --
21Feb12_230918|    -- Crossed 6 individual pairs.
21Feb12_230918|    -- Mutated 32 individuals.
21Feb12_231316|    -- Evaluated 64 individuals.
21Feb12_231316|    Summary of generation 12:
21Feb12_231316| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_231316|-----------  ------------------  --------------------  ----------
21Feb12_231316|    Max            39.04                120.00          0.82502
21Feb12_231316|    Avg            36.66                18.23           0.10441
21Feb12_231316|    Min            19.04                 2.00           0.00000
21Feb12_231316|    Std             5.31                28.37           0.25587
21Feb12_231316|   Best            19.04                48.00           0.79351
21Feb12_231316|-- Generation 13 --
21Feb12_231316|    -- Crossed 6 individual pairs.
21Feb12_231316|    -- Mutated 32 individuals.
21Feb12_231716|    -- Evaluated 64 individuals.
21Feb12_231716|    Summary of generation 13:
21Feb12_231716| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_231716|-----------  ------------------  --------------------  ----------
21Feb12_231716|    Max            39.48                120.00          0.83194
21Feb12_231716|    Avg            36.35                20.94           0.12349
21Feb12_231716|    Min            21.65                 2.00           0.00000
21Feb12_231716|    Std             5.29                31.00           0.26574
21Feb12_231716|   Best            21.65                120.00          0.69905
21Feb12_231716|-- Generation 14 --
21Feb12_231716|    -- Crossed 1 individual pairs.
21Feb12_231716|    -- Mutated 32 individuals.
21Feb12_232118|    -- Evaluated 64 individuals.
21Feb12_232118|    Summary of generation 14:
21Feb12_232118| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_232118|-----------  ------------------  --------------------  ----------
21Feb12_232118|    Max            38.96                120.00          0.85321
21Feb12_232118|    Avg            36.24                25.94           0.14840
21Feb12_232118|    Min            20.78                 2.00           0.00000
21Feb12_232118|    Std             5.35                34.25           0.29604
21Feb12_232118|   Best            20.78                48.00           0.81445
21Feb12_232118|-- Generation 15 --
21Feb12_232118|    -- Crossed 4 individual pairs.
21Feb12_232118|    -- Mutated 32 individuals.
21Feb12_232523|    -- Evaluated 64 individuals.
21Feb12_232523|    Summary of generation 15:
21Feb12_232523| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_232523|-----------  ------------------  --------------------  ----------
21Feb12_232523|    Max            48.43                168.00          0.83881
21Feb12_232523|    Avg            36.46                31.25           0.19892
21Feb12_232523|    Min            23.65                 2.00           0.00000
21Feb12_232523|    Std             4.84                39.99           0.33283
21Feb12_232523|   Best            23.65                48.00           0.83402
21Feb12_232523|-- Generation 16 --
21Feb12_232523|    -- Crossed 4 individual pairs.
21Feb12_232523|    -- Mutated 32 individuals.
21Feb12_232930|    -- Evaluated 64 individuals.
21Feb12_232930|    Summary of generation 16:
21Feb12_232930| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_232930|-----------  ------------------  --------------------  ----------
21Feb12_232930|    Max            43.04                120.00          0.80383
21Feb12_232930|    Avg            35.25                35.33           0.25114
21Feb12_232930|    Min            22.61                 2.00           0.00000
21Feb12_232930|    Std             5.60                37.54           0.34603
21Feb12_232930|   Best            22.61                90.00           0.74164
21Feb12_232930|-- Generation 17 --
21Feb12_232930|    -- Crossed 4 individual pairs.
21Feb12_232930|    -- Mutated 32 individuals.
21Feb12_233344|    -- Evaluated 64 individuals.
21Feb12_233344|    Summary of generation 17:
21Feb12_233344| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_233344|-----------  ------------------  --------------------  ----------
21Feb12_233344|    Max            38.78                126.00          0.83122
21Feb12_233344|    Avg            33.91                45.28           0.32893
21Feb12_233344|    Min            21.22                 2.00           0.00000
21Feb12_233344|    Std             6.17                36.56           0.37500
21Feb12_233344|   Best            21.22                52.00           0.83122
21Feb12_233344|-- Generation 18 --
21Feb12_233344|    -- Crossed 1 individual pairs.
21Feb12_233344|    -- Mutated 32 individuals.
21Feb12_233806|    -- Evaluated 64 individuals.
21Feb12_233806|    Summary of generation 18:
21Feb12_233806| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_233806|-----------  ------------------  --------------------  ----------
21Feb12_233806|    Max            40.70                175.00          0.85419
21Feb12_233806|    Avg            32.75                60.16           0.38857
21Feb12_233806|    Min            18.87                 2.00           0.00000
21Feb12_233806|    Std             6.61                33.53           0.37821
21Feb12_233806|   Best            18.87                48.00           0.77911
21Feb12_233806|-- Generation 19 --
21Feb12_233806|    -- Crossed 3 individual pairs.
21Feb12_233806|    -- Mutated 32 individuals.
21Feb12_234230|    -- Evaluated 64 individuals.
21Feb12_234230|    Summary of generation 19:
21Feb12_234230| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_234230|-----------  ------------------  --------------------  ----------
21Feb12_234230|    Max            48.96                168.00          0.86753
21Feb12_234230|    Avg            32.07                68.42           0.46322
21Feb12_234230|    Min            21.74                21.00           0.00000
21Feb12_234230|    Std             6.49                32.16           0.35961
21Feb12_234230|   Best            21.74                48.00           0.72768
21Feb12_234230|-- Generation 20 --
21Feb12_234230|    -- Crossed 1 individual pairs.
21Feb12_234230|    -- Mutated 32 individuals.
21Feb12_234653|    -- Evaluated 64 individuals.
21Feb12_234653|    Summary of generation 20:
21Feb12_234653| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_234653|-----------  ------------------  --------------------  ----------
21Feb12_234653|    Max            38.87                132.00          0.84316
21Feb12_234653|    Avg            29.80                67.14           0.55237
21Feb12_234653|    Min            18.70                12.00           0.00000
21Feb12_234653|    Std             6.13                29.85           0.32196
21Feb12_234653|   Best            18.70                52.00           0.74401
21Feb12_234653|-- Generation 21 --
21Feb12_234653|    -- Crossed 2 individual pairs.
21Feb12_234653|    -- Mutated 32 individuals.
21Feb12_235118|    -- Evaluated 64 individuals.
21Feb12_235118|    Summary of generation 21:
21Feb12_235118| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_235118|-----------  ------------------  --------------------  ----------
21Feb12_235118|    Max            46.78                132.00          0.84742
21Feb12_235118|    Avg            30.83                67.03           0.51592
21Feb12_235118|    Min            21.57                18.00           0.00000
21Feb12_235118|    Std             6.38                27.55           0.34037
21Feb12_235118|   Best            21.57                85.00           0.83263
21Feb12_235118|-- Generation 22 --
21Feb12_235118|    -- Crossed 3 individual pairs.
21Feb12_235118|    -- Mutated 32 individuals.
21Feb12_235543|    -- Evaluated 64 individuals.
21Feb12_235543|    Summary of generation 22:
21Feb12_235543| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_235543|-----------  ------------------  --------------------  ----------
21Feb12_235543|    Max            38.78                132.00          0.83932
21Feb12_235543|    Avg            29.56                68.42           0.51807
21Feb12_235543|    Min            20.26                18.00           0.00000
21Feb12_235543|    Std             6.09                29.72           0.31571
21Feb12_235543|   Best            20.26                52.00           0.83932
21Feb12_235543|-- Generation 23 --
21Feb12_235543|    -- Crossed 1 individual pairs.
21Feb12_235543|    -- Mutated 32 individuals.
21Feb13_000009|    -- Evaluated 64 individuals.
21Feb13_000009|    Summary of generation 23:
21Feb13_000009| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_000009|-----------  ------------------  --------------------  ----------
21Feb13_000009|    Max            53.04                189.00          0.86256
21Feb13_000009|    Avg            31.43                71.98           0.47258
21Feb13_000009|    Min            21.57                12.00           0.00000
21Feb13_000009|    Std             6.77                31.86           0.34131
21Feb13_000009|   Best            21.57                80.00           0.72357
21Feb13_000009|-- Generation 24 --
21Feb13_000009|    -- Crossed 0 individual pairs.
21Feb13_000009|    -- Mutated 32 individuals.
21Feb13_000436|    -- Evaluated 64 individuals.
21Feb13_000436|    Summary of generation 24:
21Feb13_000436| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_000436|-----------  ------------------  --------------------  ----------
21Feb13_000436|    Max            41.39                182.00          0.81376
21Feb13_000436|    Avg            30.37                76.64           0.49193
21Feb13_000436|    Min            20.87                21.00           0.00000
21Feb13_000436|    Std             6.25                31.76           0.33134
21Feb13_000436|   Best            20.87                80.00           0.77277
21Feb13_000436|-- Generation 25 --
21Feb13_000436|    -- Crossed 0 individual pairs.
21Feb13_000436|    -- Mutated 32 individuals.
21Feb13_000902|    -- Evaluated 64 individuals.
21Feb13_000902|    Summary of generation 25:
21Feb13_000902| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_000902|-----------  ------------------  --------------------  ----------
21Feb13_000902|    Max            39.30                224.00          0.85320
21Feb13_000902|    Avg            29.80                81.34           0.49967
21Feb13_000902|    Min            20.61                10.00           0.00000
21Feb13_000902|    Std             6.32                43.70           0.33654
21Feb13_000902|   Best            20.61                52.00           0.85320
21Feb13_000902|-- Generation 26 --
21Feb13_000902|    -- Crossed 0 individual pairs.
21Feb13_000902|    -- Mutated 32 individuals.
21Feb13_001328|    -- Evaluated 64 individuals.
21Feb13_001328|    Summary of generation 26:
21Feb13_001328| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_001328|-----------  ------------------  --------------------  ----------
21Feb13_001328|    Max            38.87                182.00          0.84204
21Feb13_001328|    Avg            29.27                74.83           0.53406
21Feb13_001328|    Min            21.65                14.00           0.00000
21Feb13_001328|    Std             5.84                40.27           0.30546
21Feb13_001328|   Best            21.65                27.00           0.71846
21Feb13_001328|-- Generation 27 --
21Feb13_001328|    -- Crossed 1 individual pairs.
21Feb13_001328|    -- Mutated 32 individuals.
21Feb13_001755|    -- Evaluated 64 individuals.
21Feb13_001755|    Summary of generation 27:
21Feb13_001755| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_001755|-----------  ------------------  --------------------  ----------
21Feb13_001755|    Max            38.96                196.00          0.81737
21Feb13_001755|    Avg            29.85                81.98           0.47495
21Feb13_001755|    Min            21.13                18.00           0.00000
21Feb13_001755|    Std             6.50                47.01           0.32999
21Feb13_001755|   Best            21.13                85.00           0.81737
21Feb13_001755|-- Generation 28 --
21Feb13_001755|    -- Crossed 1 individual pairs.
21Feb13_001755|    -- Mutated 32 individuals.
21Feb13_002224|    -- Evaluated 64 individuals.
21Feb13_002224|    Summary of generation 28:
21Feb13_002224| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_002224|-----------  ------------------  --------------------  ----------
21Feb13_002224|    Max            38.78                264.00          0.81098
21Feb13_002224|    Avg            29.74                90.08           0.47932
21Feb13_002224|    Min            20.17                10.00           0.00000
21Feb13_002224|    Std             6.09                54.89           0.32057
21Feb13_002224|   Best            20.17                85.00           0.71103
21Feb13_002224|-- Generation 29 --
21Feb13_002224|    -- Crossed 0 individual pairs.
21Feb13_002224|    -- Mutated 32 individuals.
21Feb13_002650|    -- Evaluated 64 individuals.
21Feb13_002650|    Summary of generation 29:
21Feb13_002650| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_002650|-----------  ------------------  --------------------  ----------
21Feb13_002650|    Max            48.70                196.00          0.81590
21Feb13_002650|    Avg            29.87                83.55           0.48158
21Feb13_002650|    Min            21.83                12.00           0.00000
21Feb13_002650|    Std             6.66                50.66           0.32137
21Feb13_002650|   Best            21.83                24.00           0.72260
21Feb13_002650|-- Generation 30 --
21Feb13_002650|    -- Crossed 0 individual pairs.
21Feb13_002650|    -- Mutated 32 individuals.
21Feb13_003118|    -- Evaluated 64 individuals.
21Feb13_003118|    Summary of generation 30:
21Feb13_003118| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_003118|-----------  ------------------  --------------------  ----------
21Feb13_003118|    Max            39.39                232.00          0.82586
21Feb13_003118|    Avg            30.93                87.56           0.37886
21Feb13_003118|    Min            20.35                14.00           0.00000
21Feb13_003118|    Std             6.88                49.98           0.33534
21Feb13_003118|   Best            20.35                44.00           0.75178
21Feb13_003118|-- Generation 31 --
21Feb13_003119|    -- Crossed 1 individual pairs.
21Feb13_003119|    -- Mutated 32 individuals.
21Feb13_003546|    -- Evaluated 64 individuals.
21Feb13_003546|    Summary of generation 31:
21Feb13_003546| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_003546|-----------  ------------------  --------------------  ----------
21Feb13_003546|    Max            38.78                208.00          0.82645
21Feb13_003546|    Avg            29.32                88.55           0.49693
21Feb13_003546|    Min            20.52                14.00           0.00000
21Feb13_003546|    Std             6.18                53.41           0.31827
21Feb13_003546|   Best            20.52                85.00           0.77261
21Feb13_003546|-- Generation 32 --
21Feb13_003546|    -- Crossed 2 individual pairs.
21Feb13_003546|    -- Mutated 32 individuals.
21Feb13_004012|    -- Evaluated 64 individuals.
21Feb13_004012|    Summary of generation 32:
21Feb13_004012| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_004012|-----------  ------------------  --------------------  ----------
21Feb13_004012|    Max            38.87                216.00          0.84955
21Feb13_004012|    Avg            28.62                84.86           0.54341
21Feb13_004012|    Min            20.35                12.00           0.00000
21Feb13_004012|    Std             6.00                52.23           0.31133
21Feb13_004012|   Best            20.35                85.00           0.76260
21Feb13_004012|Best initial individual weights
21Feb13_004012|Individual:
21Feb13_004012|-- Constant hidden layers --
21Feb13_004012|False
21Feb13_004012|Layer 0:
21Feb13_004012|-- Config --
21Feb13_004012|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 14, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004012|-- Weights --
21Feb13_004012|[[-0.75670  0.29871  0.74367  0.45755  0.08378 -0.90696  0.03549 -0.90412
21Feb13_004012|  -0.53729  0.90132  0.03392 -0.44008 -0.51942 -0.58085]
21Feb13_004012| [ 0.76009  0.48203 -0.99647 -0.45525 -0.17065 -0.04635  0.28090  0.96518
21Feb13_004012|   0.67733 -0.97589  0.86349 -0.48367 -0.74170 -0.42889]
21Feb13_004012| [-0.97361  0.10657  0.15641  0.48120 -0.25761  0.24356  0.13170 -0.13518
21Feb13_004012|   0.23765  0.01211 -0.59353 -0.20655  0.39738  0.47359]
21Feb13_004012| [-0.46839 -0.30552  0.81069  0.33490  0.66889  0.47441  0.43325  0.37620
21Feb13_004012|   0.87117  0.15853 -0.46264 -0.82122 -0.23257 -0.06345]
21Feb13_004012| [ 0.03163 -0.60430  0.88694 -0.12364 -0.47165  0.75758 -0.59629 -0.57207
21Feb13_004012|  -0.37716 -0.73908 -0.60843 -0.54767  0.85288  0.82761]
21Feb13_004012| [-0.49980 -0.90747  0.96669 -0.55167 -0.75389 -0.10102  0.04470 -0.09358
21Feb13_004012|   0.70179 -0.91498  0.55672 -0.99924 -0.36845  0.14752]
21Feb13_004012| [ 0.33931  0.11277  0.76350  0.63136  0.98270 -0.42724 -0.08289  0.21179
21Feb13_004012|   0.94143 -0.77971 -0.84383  0.53535  0.41280  0.61677]
21Feb13_004012| [ 0.06427  0.31725 -0.25877  0.96150 -0.67733 -0.08204  0.69496  0.70537
21Feb13_004012|   0.52941  0.38806 -0.30549  0.40936  0.44891  0.26225]
21Feb13_004012| [-0.15068 -0.98438  0.80796 -0.59306  0.30967 -0.82464  0.75113 -0.69313
21Feb13_004012|   0.69463 -0.67058 -0.39739  0.86283  0.13909  0.46960]
21Feb13_004012| [-0.49203  0.50681 -0.72130 -0.36394  0.34368 -0.18489  0.29736  0.53336
21Feb13_004012|  -0.64321  0.82578  0.11252  0.09623  0.29555  0.61368]
21Feb13_004012| [ 0.39746 -0.81034  0.59517  0.72827  0.82092  0.56062 -0.81372 -0.58599
21Feb13_004012|  -0.47920  0.58519 -0.39834  0.34123  0.40037 -0.25907]
21Feb13_004012| [-0.37647  0.54175 -0.73873  0.83602  0.39539 -0.84553 -0.70070  0.31785
21Feb13_004012|  -0.46426  0.71038 -0.69738 -0.89117 -0.47782 -0.14388]
21Feb13_004012| [-0.31786 -0.27473  0.30313  0.27236 -0.79638  0.55763 -0.98113 -0.08304
21Feb13_004012|   0.87479 -0.82718  0.38506  0.52639  0.57862  0.98450]
21Feb13_004012| [ 0.21246 -0.28012  0.34329 -0.71801  0.05596 -0.96595  0.65741 -0.93960
21Feb13_004012|  -0.02532 -0.21506  0.55071 -0.48326 -0.87931  0.60298]
21Feb13_004012| [ 0.05026  0.69755 -0.04463  0.09817  0.62209 -0.27948  0.40675  0.52770
21Feb13_004012|  -0.27998  0.32990 -0.51447 -0.10518 -0.81693  0.34250]
21Feb13_004012| [-0.66708  0.96394 -0.57554 -0.71046 -0.46978  0.34500  0.06566  0.90293
21Feb13_004012|  -0.75856  0.51699 -0.63264  0.54206  0.59623 -0.18843]
21Feb13_004012| [ 0.94678  0.42002 -0.06312 -0.33127  0.76972 -0.07325 -0.81243  0.02734
21Feb13_004012|  -0.77125 -0.48863  0.04721  0.24140 -0.91057 -0.85377]
21Feb13_004012| [-0.56406  0.18375  0.27826 -0.51538  0.27267 -0.75594 -0.63568  0.77797
21Feb13_004012|   0.64038 -0.65061 -0.94470  0.17349 -0.83393 -0.24679]
21Feb13_004012| [ 0.59028 -0.21430  0.61264 -0.77274 -0.75561 -0.99458  0.20343 -0.26229
21Feb13_004012|  -0.45255  0.25161  0.08500 -0.13330  0.91151  0.16477]
21Feb13_004012| [-0.29366  0.00694  0.18224 -0.35074  0.51983  0.27243 -0.00765 -0.06121
21Feb13_004012|   0.75723 -0.89316 -0.52497 -0.89498 -0.05207  0.46331]
21Feb13_004012| [ 0.51083 -0.24956  0.29935 -0.25466 -0.30258  0.85141 -0.91731  0.49698
21Feb13_004012|  -0.69024 -0.88137  0.28808  0.22421 -0.36172 -0.78882]
21Feb13_004012| [-0.57078  0.82142  0.69879 -0.29905  0.54699  0.66486  0.27642 -0.61252
21Feb13_004012|   0.76936  0.77870  0.08857 -0.44903 -0.70288  0.20579]
21Feb13_004012| [ 0.86966 -0.06796 -0.60959  0.15276 -0.42034  0.56430 -0.41750  0.09013
21Feb13_004012|   0.90652  0.63652  0.14660  0.69934 -0.66998 -0.03427]
21Feb13_004012| [ 0.01213  0.92411  0.90096  0.38814 -0.38481  0.05128 -0.81073 -0.91009
21Feb13_004012|   0.06526  0.09645  0.74474  0.49312  0.30922 -0.29548]
21Feb13_004012| [-0.58584  0.10212  0.67615  0.72898 -0.53319 -0.15408 -0.78628 -0.63693
21Feb13_004012|   0.09045 -0.10053 -0.17532  0.25499  0.40299  0.59734]
21Feb13_004012| [-0.72229  0.87681 -0.08413 -0.82145  0.62517  0.63352 -0.10138  0.88730
21Feb13_004012|  -0.13903  0.31718  0.24453  0.27233 -0.53989  0.12477]
21Feb13_004012| [-0.63700  0.67560 -0.76375 -0.93401 -0.92818 -0.37340  0.64492  0.83497
21Feb13_004012|  -0.82894 -0.76380  0.72667  0.87844 -0.95478 -0.57992]
21Feb13_004012| [ 0.93977 -0.95401  0.48504  0.14426  0.36551  0.05814  0.43982 -0.22321
21Feb13_004012|   0.21425  0.82583 -0.03206  0.92117  0.25171  0.64924]
21Feb13_004012| [ 0.98870  0.47932 -0.06973 -0.99486 -0.78595  0.97161  0.82702 -0.13542
21Feb13_004012|   0.02230 -0.24231  0.67756 -0.49211 -0.73191  0.78859]
21Feb13_004012| [-0.16420  0.62310 -0.43918  0.49656 -0.76027 -0.21799  0.76457  0.90149
21Feb13_004012|   0.48926 -0.95857 -0.75473  0.02916  0.49559  0.25066]
21Feb13_004012| [ 0.72572  0.01536  0.06729  0.98882 -0.25487 -0.69352 -0.40743 -0.07047
21Feb13_004012|   0.20078  0.56026  0.66662 -0.11310  0.98139 -0.44622]
21Feb13_004012| [ 0.31631  0.92934 -0.52266  0.34093 -0.60009  0.03235  0.67411  0.91966
21Feb13_004012|   0.73192  0.85623 -0.83599  0.79832  0.11915  0.40904]
21Feb13_004012| [ 0.12019  0.76338  0.19217 -0.48156  0.31820  0.43247  0.30702 -0.73902
21Feb13_004012|  -0.44089  0.34255 -0.49488 -0.81333  0.49664  0.08436]
21Feb13_004012| [ 0.09098 -0.20703 -0.60696  0.06441  0.22841 -0.32381  0.90563 -0.24638
21Feb13_004012|   0.11216 -0.90931 -0.14978 -0.85553  0.14891 -0.57632]
21Feb13_004012| [-0.04342  0.84385  0.39940 -0.74336  0.07538 -0.29719  0.03989 -0.82797
21Feb13_004012|   0.44994  0.39372  0.85450 -0.46476 -0.37510 -0.58204]
21Feb13_004012| [ 0.55210 -0.86040  0.81857 -0.36277 -0.62512 -0.09036 -0.64166 -0.32081
21Feb13_004012|   0.06811 -0.21494 -0.97429  0.28119  0.95872 -0.51193]
21Feb13_004012| [ 0.38149  0.51108 -0.55846  0.08009 -0.32096 -0.56195  0.05056 -0.23043
21Feb13_004012|   0.62340  0.24700  0.59408  0.17231  0.53995  0.40197]
21Feb13_004012| [-0.34439  0.93699 -0.87637  0.34288 -0.42405 -0.87241 -0.08626  0.32107
21Feb13_004012|   0.75541  0.70418 -0.62459  0.06696 -0.38782  0.93216]
21Feb13_004012| [ 0.46713 -0.60430  0.32701 -0.68147  0.38042  0.47619  0.75992  0.63928
21Feb13_004012|  -0.23523  0.18338 -0.86732 -0.46507 -0.69284 -0.43382]
21Feb13_004012| [ 0.88599 -0.97978  0.79867 -0.79714  0.27585 -0.52948 -0.92549  0.53584
21Feb13_004012|  -0.74847 -0.91078 -0.48053  0.12404 -0.71233 -0.38158]
21Feb13_004012| [ 0.61684  0.46758 -0.28863 -0.94009  0.80268  0.99825 -0.15862 -0.76405
21Feb13_004012|   0.66400 -0.12776  0.34975 -0.64131  0.19475  0.56327]
21Feb13_004012| [-0.20653  0.61121 -0.31245 -0.97427 -0.71008 -0.33337  0.49525 -0.18435
21Feb13_004012|   0.78751 -0.51240 -0.85960  0.11472  0.68535  0.72245]
21Feb13_004012| [ 0.63325 -0.34415  0.40714 -0.15677 -0.35908  0.13271  0.58092 -0.10764
21Feb13_004012|  -0.90911 -0.96610  0.96311  0.76031 -0.93270 -0.03221]
21Feb13_004012| [-0.72171 -0.95200 -0.66774  0.57587 -0.52068 -0.69968 -0.39418 -0.48230
21Feb13_004012|   0.33443 -0.56670  0.14768  0.46664 -0.83638  0.71429]
21Feb13_004012| [ 0.09492  0.71062  0.74820  0.69234 -0.48239 -0.67268 -0.63553  0.66965
21Feb13_004012|  -0.34413  0.45765 -0.69526 -0.75477 -0.49130  0.20067]
21Feb13_004012| [ 0.31071  0.76568 -0.22805 -0.79728  0.35458  0.41470 -0.68080 -0.21149
21Feb13_004012|   0.09652 -0.47701 -0.41896  0.13586  0.94266 -0.34626]
21Feb13_004012| [-0.44990  0.69532  0.95065 -0.83172 -0.72093  0.28493  0.23004  0.84693
21Feb13_004012|  -0.59194  0.01498 -0.50101  0.77447 -0.89530  0.58010]
21Feb13_004012| [ 0.20441  0.44410  0.29418 -0.27301  0.76304  0.52721  0.62729 -0.14823
21Feb13_004012|   0.85115  0.48189  0.82008 -0.53310  0.83509 -0.67384]
21Feb13_004012| [-0.51134 -0.74376  0.69561  0.72389 -0.75575 -0.40392  0.14976  0.34566
21Feb13_004012|  -0.78336 -0.29284 -0.16288 -0.18613  0.61455 -0.45062]
21Feb13_004012| [-0.44078  0.16996 -0.10408 -0.01775  0.23327  0.19639  0.75652 -0.08881
21Feb13_004012|  -0.42892 -0.82923  0.61413 -0.79227 -0.97969  0.23826]
21Feb13_004012| [-0.77370 -0.17011 -0.61344 -0.46748 -0.03290  0.45811 -0.91389 -0.30181
21Feb13_004012|  -0.90831  0.33297 -0.02076  0.70651  0.82414 -0.94501]
21Feb13_004012| [ 0.53732  0.58008 -0.73582  0.49481  0.64443  0.09264 -0.16950 -0.37994
21Feb13_004012|  -0.72992  0.88583 -0.72290 -0.51625 -0.92984  0.48119]
21Feb13_004012| [ 0.78589  0.05182 -0.44269 -0.77420 -0.30036  0.62718  0.21837 -0.40883
21Feb13_004012|   0.56074 -0.34557 -0.50461  0.86001  0.61084 -0.93571]
21Feb13_004012| [-0.60259 -0.84504 -0.76480 -0.34047 -0.34801 -0.27669 -0.54341  0.57897
21Feb13_004012|  -0.39427  0.66047 -0.98703  0.21972  0.02776 -0.64340]
21Feb13_004012| [-0.30678  0.00973  0.71451  0.32813  0.30979 -0.64897 -0.52795  0.01095
21Feb13_004012|  -0.25105  0.80006  0.04771 -0.07076 -0.31128 -0.79658]
21Feb13_004012| [-0.42108  0.28696  0.93104 -0.56625  0.88407 -0.94335 -0.28932 -0.04102
21Feb13_004012|  -0.93814 -0.15049 -0.25982  0.39866  0.23867 -0.02475]
21Feb13_004012| [ 0.13794 -0.27147 -0.63842  0.71514 -0.78165  0.17171  0.68861  0.60975
21Feb13_004012|   0.54358  0.41788 -0.68136  0.52820  0.01737 -0.35886]]
21Feb13_004012|-- Bias --
21Feb13_004012|[-0.61007  0.64386 -0.43696 -0.13685 -0.46865 -0.68714  0.62981 -0.27004
21Feb13_004012|  0.84577 -0.13510 -0.87613  0.79408 -0.06580  0.11955]
21Feb13_004012|Layer 1:
21Feb13_004012|-- Config --
21Feb13_004012|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 14], 'dtype': 'float32', 'units': 15, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004012|-- Weights --
21Feb13_004012|[[-4.44537e-01  2.98215e-01 -5.45667e-01 -8.21261e-01  2.37338e-01
21Feb13_004012|  -6.66991e-01 -9.97395e-01  1.03244e-01  5.53519e-01  8.71416e-01
21Feb13_004012|   6.68461e-01 -4.75914e-01 -6.95902e-02 -2.84545e-01  7.31475e-01]
21Feb13_004012| [ 2.88121e-01 -8.76956e-01  1.15903e-01  1.53985e-01 -3.08592e-01
21Feb13_004012|  -8.88431e-01  5.53581e-01  5.11088e-01 -2.82611e-01  4.15705e-01
21Feb13_004012|   4.05110e-01 -1.49712e-01 -3.92652e-01  3.67183e-02  1.81346e-01]
21Feb13_004012| [ 8.91554e-01 -9.11392e-01 -7.36840e-01 -9.62919e-01  9.42758e-01
21Feb13_004012|  -1.17301e-01 -5.76834e-01 -1.26366e-01  1.49094e-01  9.20271e-01
21Feb13_004012|   9.26501e-01 -8.71045e-01 -8.23686e-01  7.54757e-01  3.80548e-01]
21Feb13_004012| [ 2.00818e-01  5.67868e-02 -3.03875e-01  6.32245e-01  3.25711e-01
21Feb13_004012|   8.69330e-01 -4.26698e-01  9.91485e-01  9.89588e-01 -5.98826e-01
21Feb13_004012|   7.31766e-01 -9.37548e-01 -2.78915e-01  8.42235e-01  9.08245e-01]
21Feb13_004012| [-9.17780e-01 -7.39513e-01 -9.72961e-01  7.15850e-01 -9.15256e-01
21Feb13_004012|   2.57581e-02 -7.11064e-01 -3.10103e-01  5.16817e-01  4.22283e-01
21Feb13_004012|  -4.42937e-01 -4.40728e-01 -5.97541e-01  2.39672e-01 -7.35774e-01]
21Feb13_004012| [-1.89526e-03  3.56595e-02  8.97941e-01  2.17211e-01  7.83533e-01
21Feb13_004012|  -7.28842e-01  7.37077e-01 -3.34683e-01 -3.75843e-01  6.20899e-01
21Feb13_004012|   2.37794e-01  4.42948e-01 -4.07523e-01 -8.59128e-01  6.63444e-01]
21Feb13_004012| [-2.34316e-01 -5.44874e-01 -1.91031e-01 -3.72141e-01  8.00935e-01
21Feb13_004012|  -3.44297e-01  9.67431e-01 -3.74071e-01 -5.48191e-02  5.45200e-01
21Feb13_004012|   7.50890e-01  2.31245e-01  3.88952e-01  6.00296e-02 -9.72358e-01]
21Feb13_004012| [-1.50203e-01  6.35125e-01 -4.84727e-01  8.49196e-01 -4.08484e-01
21Feb13_004012|  -8.97271e-01  5.39757e-01  4.35106e-01 -9.25805e-01  7.58537e-01
21Feb13_004012|   7.09786e-01  8.57001e-02  1.03150e-01  6.17059e-01  6.19731e-01]
21Feb13_004012| [ 9.82295e-01 -3.06725e-01  6.75870e-01  7.45805e-01 -4.61457e-01
21Feb13_004012|  -2.06601e-03  9.09827e-01  7.48193e-01  5.32271e-01  2.41798e-01
21Feb13_004012|  -2.52667e-01 -3.45837e-02  4.85799e-02  4.61086e-01  6.53203e-01]
21Feb13_004012| [ 4.42985e-01  4.69929e-01 -7.55656e-01 -4.88852e-01  1.72785e-01
21Feb13_004012|  -2.30531e-01  4.41384e-02 -2.15284e-02 -1.24310e-01  1.05492e-01
21Feb13_004012|  -1.66197e-01  5.91302e-01 -5.48944e-01 -6.19775e-01  1.25038e-01]
21Feb13_004012| [ 5.06871e-02  2.90993e-01  9.50458e-01  2.16131e-01 -3.99997e-01
21Feb13_004012|  -1.21625e-01 -2.31831e-01  1.57385e-02  4.42261e-01  9.23458e-01
21Feb13_004012|   7.19395e-02 -5.45153e-01  8.50891e-01  9.41445e-01 -9.21020e-01]
21Feb13_004012| [ 9.65890e-01  2.91340e-01  4.37191e-01 -4.42659e-01 -4.19737e-01
21Feb13_004012|  -5.73836e-01  8.42757e-01 -3.19215e-01  7.70486e-01 -9.01088e-01
21Feb13_004012|   4.63923e-01 -2.20963e-01 -1.15607e-01  5.39524e-01  5.13690e-01]
21Feb13_004012| [-6.04112e-01 -6.83211e-04 -4.47243e-01 -1.90886e-01 -6.34356e-01
21Feb13_004012|   8.58719e-02 -4.61596e-01  5.07885e-03  8.32116e-01 -2.94871e-01
21Feb13_004012|   4.71619e-02  2.86949e-01  9.74146e-01  1.81634e-01  5.81780e-01]
21Feb13_004012| [ 7.74068e-01  5.46278e-02 -3.90271e-01 -4.20695e-01 -8.82712e-01
21Feb13_004012|  -4.19141e-01 -9.13481e-01  2.39339e-01  8.91210e-02 -4.89770e-01
21Feb13_004012|   9.53936e-01  6.78696e-01 -1.85478e-01 -9.05672e-01 -4.05664e-01]]
21Feb13_004012|-- Bias --
21Feb13_004012|[ 0.28720  0.45428  0.09438  0.32700  0.81161  0.62850 -0.04466 -0.00678
21Feb13_004012|  0.24629 -0.28595 -0.24663 -0.18334  0.64426  0.90999 -0.10464]
21Feb13_004012|Layer 2:
21Feb13_004012|-- Config --
21Feb13_004012|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 15], 'dtype': 'float32', 'units': 11, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004012|-- Weights --
21Feb13_004012|[[ 0.28364  0.15320 -0.19251  0.58839  0.70008 -0.40387  0.10084  0.48862
21Feb13_004012|   0.68986 -0.52713  0.28991]
21Feb13_004012| [ 0.68687  0.22377 -0.35913  0.61329  0.51987 -0.31942  0.05944  0.22969
21Feb13_004012|   0.81802  0.65462  0.82984]
21Feb13_004012| [ 0.01477  0.65854 -0.23562  0.80702  0.64822 -0.20885  0.08882  0.79066
21Feb13_004012|  -0.23288 -0.18492 -0.88343]
21Feb13_004012| [-0.75163 -0.78173  0.21446  0.56948 -0.27602 -0.65911  0.51748 -0.87632
21Feb13_004012|   0.81747  0.36534  0.70251]
21Feb13_004012| [-0.60354 -0.83226  0.08876  0.61026  0.85307  0.94241 -0.66784 -0.99183
21Feb13_004012|   0.03298 -0.75466 -0.09346]
21Feb13_004012| [-0.57320 -0.28101 -0.38067 -0.97423  0.54076  0.18648  0.32370  0.76566
21Feb13_004012|   0.91552  0.95861  0.46650]
21Feb13_004012| [-0.98403 -0.53348 -0.37790  0.42245 -0.47184  0.53961 -0.34002 -0.10006
21Feb13_004012|   0.27291 -0.32518  0.40483]
21Feb13_004012| [-0.55042 -0.67233 -0.69621 -0.58667  0.35264  0.35058 -0.99480 -0.96060
21Feb13_004012|  -0.07876 -0.26093  0.23072]
21Feb13_004012| [ 0.42053  0.66486  0.03877  0.94432 -0.35590  0.55729 -0.44420  0.26567
21Feb13_004012|  -0.23684 -0.94825 -0.61904]
21Feb13_004012| [ 0.58901  0.87539 -0.11385  0.09477 -0.98438  0.56193  0.31884 -0.91744
21Feb13_004012|  -0.41159  0.98918  0.96239]
21Feb13_004012| [-0.55329 -0.39897 -0.29823  0.98382 -0.36887 -0.88324  0.50942  0.05820
21Feb13_004012|   0.03384  0.08312 -0.69379]
21Feb13_004012| [-0.87672 -0.80540  0.74418  0.83622 -0.69817  0.02006  0.58879 -0.76514
21Feb13_004012|  -0.18359 -0.07340 -0.66528]
21Feb13_004012| [ 0.44404  0.77651 -0.88115  0.15876 -0.81337 -0.95520 -0.44630 -0.66951
21Feb13_004012|  -0.71528 -0.94940 -0.05153]
21Feb13_004012| [-0.86968 -0.08923 -0.55744  0.70025 -0.54385  0.50843  0.00926  0.58634
21Feb13_004012|   0.56936  0.60599 -0.79842]
21Feb13_004012| [ 0.68948  0.94597  0.61879 -0.40689 -0.48248 -0.74315 -0.75840 -0.92547
21Feb13_004012|   0.67329 -0.63301 -0.49381]]
21Feb13_004012|-- Bias --
21Feb13_004012|[-0.05134 -0.43349 -0.31320 -0.50645 -0.98021 -0.30436 -0.27416  0.05960
21Feb13_004012| -0.65952 -0.17971  0.24745]
21Feb13_004012|Layer 3:
21Feb13_004012|-- Config --
21Feb13_004012|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 11], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004012|-- Weights --
21Feb13_004012|[[ 0.32420 -0.16935]
21Feb13_004012| [-0.58986 -0.81222]
21Feb13_004012| [-0.42603 -0.60294]
21Feb13_004012| [ 0.90533 -0.77599]
21Feb13_004012| [-0.75774 -0.60030]
21Feb13_004012| [-0.27412  0.74615]
21Feb13_004012| [-0.60255 -0.15669]
21Feb13_004012| [-0.44402 -0.22183]
21Feb13_004012| [ 0.92845 -0.01471]
21Feb13_004012| [-0.12642  0.95427]
21Feb13_004012| [ 0.07937 -0.59080]]
21Feb13_004012|-- Bias --
21Feb13_004012|[-0.34871 -0.89104]
21Feb13_004012|Predicting the validation and test data with the Best initial individual.
21Feb13_004020| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_004020|-----------  ------------------  --------------------  ----------
21Feb13_004020|Validation         38.87                 120            0.00000
21Feb13_004020|   Test            39.10                 120            0.00000
21Feb13_004020|-------------------- Test #0 --------------------
21Feb13_004020|Best final individual weights
21Feb13_004020|Individual:
21Feb13_004020|-- Constant hidden layers --
21Feb13_004020|False
21Feb13_004020|Layer 0:
21Feb13_004020|-- Config --
21Feb13_004020|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004020|-- Weights --
21Feb13_004020|[[-1.11314  0.81946 -0.35142]
21Feb13_004020| [-0.92878 -0.89932  0.40299]
21Feb13_004020| [-1.11044 -0.59735  0.24230]
21Feb13_004020| [ 0.20891 -1.31553 -0.36469]
21Feb13_004020| [ 0.30309 -0.76165 -0.23615]
21Feb13_004020| [ 1.64964  0.04056  0.02223]
21Feb13_004020| [-0.55074 -0.75738  0.46557]
21Feb13_004020| [-1.47927 -0.69261  0.23412]
21Feb13_004020| [-1.33298  1.32978 -0.31259]
21Feb13_004020| [ 0.46752  0.11801 -0.00996]
21Feb13_004020| [ 0.81861 -0.72318 -0.19691]
21Feb13_004020| [-0.47734  1.71184 -0.33536]
21Feb13_004020| [ 0.51477  1.28368  0.35802]
21Feb13_004020| [-0.91466  1.47925 -0.08178]
21Feb13_004020| [ 1.46005  0.67436 -0.12592]
21Feb13_004020| [ 0.70720  0.36657 -0.47678]
21Feb13_004020| [-0.64331  0.43277  0.18878]
21Feb13_004020| [-0.71217 -0.37104 -0.25673]
21Feb13_004020| [ 1.56152  0.98624 -0.05791]
21Feb13_004020| [ 0.52313 -0.57117  0.22682]
21Feb13_004020| [-0.84835  0.24573 -0.44370]
21Feb13_004020| [ 0.07356 -0.62497 -0.32272]
21Feb13_004020| [ 0.70192  0.43981  0.43615]
21Feb13_004020| [-0.58147 -1.09590  0.08919]
21Feb13_004020| [-0.40211 -0.70043  0.47088]
21Feb13_004020| [-0.82276  1.57835  0.07738]
21Feb13_004020| [ 1.34172  0.12865 -0.46300]
21Feb13_004020| [ 1.03792 -0.90825  0.09240]
21Feb13_004020| [-1.42926  1.89750 -0.34475]
21Feb13_004020| [ 1.02414 -0.76343 -0.36258]
21Feb13_004020| [-0.88529 -2.26835 -0.18725]
21Feb13_004020| [ 1.30364  1.13824  0.27483]
21Feb13_004020| [-0.44614 -0.47860 -0.49418]
21Feb13_004020| [-0.03176  1.60744 -0.17383]
21Feb13_004020| [ 1.08822  1.62815  0.36013]
21Feb13_004020| [-0.22818  1.19826  0.49832]
21Feb13_004020| [-0.71528 -0.51704  0.29158]
21Feb13_004020| [-0.00854 -1.77518  0.42051]
21Feb13_004020| [-0.93700 -0.26914 -0.20007]
21Feb13_004020| [ 0.00451 -0.48683 -0.48477]
21Feb13_004020| [ 0.93273 -0.19610 -0.22601]
21Feb13_004020| [-0.93976  0.14014  0.16022]
21Feb13_004020| [ 0.41300  1.39614  0.37801]
21Feb13_004020| [ 0.21004 -0.26822  0.13501]
21Feb13_004020| [ 0.14351 -0.81709 -0.11879]
21Feb13_004020| [ 0.28682 -0.71132  0.21680]
21Feb13_004020| [-1.14313 -0.39791 -0.49363]
21Feb13_004020| [-1.09534  0.74258  0.38014]
21Feb13_004020| [ 1.05762 -1.13060  0.44897]
21Feb13_004020| [-0.37677 -2.47419 -0.38946]
21Feb13_004020| [-0.73548 -0.31637  0.13582]
21Feb13_004020| [ 0.71000  0.24351 -0.03873]
21Feb13_004020| [-1.64987  0.44204  0.11190]
21Feb13_004020| [-0.21109  0.41781  0.05437]
21Feb13_004020| [ 1.64591 -1.72953 -0.32023]
21Feb13_004020| [-0.52154  0.33699 -0.04892]
21Feb13_004020| [ 0.28082 -2.11461 -0.40131]]
21Feb13_004020|-- Bias --
21Feb13_004020|[-0.83006 -0.28814 -0.41742]
21Feb13_004020|Layer 1:
21Feb13_004020|-- Config --
21Feb13_004020|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004020|-- Weights --
21Feb13_004020|[[ 0.34190  0.00494]
21Feb13_004020| [-0.03031  0.70309]
21Feb13_004020| [-0.10300 -0.31124]]
21Feb13_004020|-- Bias --
21Feb13_004020|[-1.08834  0.53538]
21Feb13_004020|Layer 2:
21Feb13_004020|-- Config --
21Feb13_004020|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004020|-- Weights --
21Feb13_004020|[[-1.43216 -0.46999]
21Feb13_004020| [-0.25570  0.29812]]
21Feb13_004020|-- Bias --
21Feb13_004020|[0.53497 0.59206]
21Feb13_004020|Layer 3:
21Feb13_004020|-- Config --
21Feb13_004020|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004020|-- Weights --
21Feb13_004020|[[ 1.26386 -0.57671  0.50937 -0.22036 -0.39070]
21Feb13_004020| [ 0.60509 -1.28500  1.18720  0.13258  0.67850]]
21Feb13_004020|-- Bias --
21Feb13_004020|[ 0.32363 -0.63931 -0.14484  0.01990  0.58968]
21Feb13_004020|Layer 4:
21Feb13_004020|-- Config --
21Feb13_004020|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004020|-- Weights --
21Feb13_004020|[[-0.22550 -0.83751 -0.16810 -0.40779 -0.29968]
21Feb13_004020| [ 0.41990  0.36976  0.32176 -0.72224 -0.36475]
21Feb13_004020| [-0.65415 -0.58004  1.27034 -1.76347  0.96539]
21Feb13_004020| [-0.04734 -0.12159 -0.27842  0.72893  1.45847]
21Feb13_004020| [-0.29575 -0.34150  1.34919  0.46565  1.37439]]
21Feb13_004020|-- Bias --
21Feb13_004020|[-0.86979  0.07658 -0.97912  0.34494  0.63525]
21Feb13_004020|Layer 5:
21Feb13_004020|-- Config --
21Feb13_004020|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004020|-- Weights --
21Feb13_004020|[[-0.69176 -0.64271]
21Feb13_004020| [-0.59285 -0.50468]
21Feb13_004020| [ 0.61725 -1.55259]
21Feb13_004020| [-0.61286 -0.40967]
21Feb13_004020| [ 0.14040 -0.58444]]
21Feb13_004020|-- Bias --
21Feb13_004020|[-0.58506 -0.05294]
21Feb13_004020|Predicting the validation and test data with the Best final individual.
21Feb13_004029| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_004029|-----------  ------------------  --------------------  ----------
21Feb13_004029|Validation         20.78                  85            0.77613
21Feb13_004029|   Test            24.76                  85            0.76972
21Feb13_004029|-------------------- Test #1 --------------------
21Feb13_004029|Best final individual weights
21Feb13_004029|Individual:
21Feb13_004029|-- Constant hidden layers --
21Feb13_004029|False
21Feb13_004029|Layer 0:
21Feb13_004029|-- Config --
21Feb13_004029|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004029|-- Weights --
21Feb13_004029|[[-1.11314  0.81946 -0.35142]
21Feb13_004029| [-0.92878 -0.89932  0.40299]
21Feb13_004029| [-1.11044 -0.59735  0.24230]
21Feb13_004029| [ 0.20891 -1.31553 -0.36469]
21Feb13_004029| [ 0.30309 -0.76165 -0.23615]
21Feb13_004029| [ 1.64964  0.04056  0.02223]
21Feb13_004029| [-0.55074 -0.75738  0.46557]
21Feb13_004029| [-1.47927 -0.69261  0.23412]
21Feb13_004029| [-1.33298  1.32978 -0.31259]
21Feb13_004029| [ 0.46752  0.11801 -0.00996]
21Feb13_004029| [ 0.81861 -0.72318 -0.19691]
21Feb13_004029| [-0.47734  1.71184 -0.33536]
21Feb13_004029| [ 0.51477  1.28368  0.35802]
21Feb13_004029| [-0.91466  1.47925 -0.08178]
21Feb13_004029| [ 1.46005  0.67436 -0.12592]
21Feb13_004029| [ 0.70720  0.36657 -0.47678]
21Feb13_004029| [-0.64331  0.43277  0.18878]
21Feb13_004029| [-0.71217 -0.37104 -0.25673]
21Feb13_004029| [ 1.56152  0.98624 -0.05791]
21Feb13_004029| [ 0.52313 -0.57117  0.22682]
21Feb13_004029| [-0.84835  0.24573 -0.44370]
21Feb13_004029| [ 0.07356 -0.62497 -0.32272]
21Feb13_004029| [ 0.70192  0.43981  0.43615]
21Feb13_004029| [-0.58147 -1.09590  0.08919]
21Feb13_004029| [-0.40211 -0.70043  0.47088]
21Feb13_004029| [-0.82276  1.57835  0.07738]
21Feb13_004029| [ 1.34172  0.12865 -0.46300]
21Feb13_004029| [ 1.03792 -0.90825  0.09240]
21Feb13_004029| [-1.42926  1.89750 -0.34475]
21Feb13_004029| [ 1.02414 -0.76343 -0.36258]
21Feb13_004029| [-0.88529 -2.26835 -0.18725]
21Feb13_004029| [ 1.30364  1.13824  0.27483]
21Feb13_004029| [-0.44614 -0.47860 -0.49418]
21Feb13_004029| [-0.03176  1.60744 -0.17383]
21Feb13_004029| [ 1.08822  1.62815  0.36013]
21Feb13_004029| [-0.22818  1.19826  0.49832]
21Feb13_004029| [-0.71528 -0.51704  0.29158]
21Feb13_004029| [-0.00854 -1.77518  0.42051]
21Feb13_004029| [-0.93700 -0.26914 -0.20007]
21Feb13_004029| [ 0.00451 -0.48683 -0.48477]
21Feb13_004029| [ 0.93273 -0.19610 -0.22601]
21Feb13_004029| [-0.93976  0.14014  0.16022]
21Feb13_004029| [ 0.41300  1.39614  0.37801]
21Feb13_004029| [ 0.21004 -0.26822  0.13501]
21Feb13_004029| [ 0.14351 -0.81709 -0.11879]
21Feb13_004029| [ 0.28682 -0.71132  0.21680]
21Feb13_004029| [-1.14313 -0.39791 -0.49363]
21Feb13_004029| [-1.09534  0.74258  0.38014]
21Feb13_004029| [ 1.05762 -1.13060  0.44897]
21Feb13_004029| [-0.37677 -2.47419 -0.38946]
21Feb13_004029| [-0.73548 -0.31637  0.13582]
21Feb13_004029| [ 0.71000  0.24351 -0.03873]
21Feb13_004029| [-1.64987  0.44204  0.11190]
21Feb13_004029| [-0.21109  0.41781  0.05437]
21Feb13_004029| [ 1.64591 -1.72953 -0.32023]
21Feb13_004029| [-0.52154  0.33699 -0.04892]
21Feb13_004029| [ 0.28082 -2.11461 -0.40131]]
21Feb13_004029|-- Bias --
21Feb13_004029|[-0.83006 -0.28814 -0.41742]
21Feb13_004029|Layer 1:
21Feb13_004029|-- Config --
21Feb13_004029|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004029|-- Weights --
21Feb13_004029|[[ 0.34190  0.00494]
21Feb13_004029| [-0.03031  0.70309]
21Feb13_004029| [-0.10300 -0.31124]]
21Feb13_004029|-- Bias --
21Feb13_004029|[-1.08834  0.53538]
21Feb13_004029|Layer 2:
21Feb13_004029|-- Config --
21Feb13_004029|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004029|-- Weights --
21Feb13_004029|[[-1.43216 -0.46999]
21Feb13_004029| [-0.25570  0.29812]]
21Feb13_004029|-- Bias --
21Feb13_004029|[0.53497 0.59206]
21Feb13_004029|Layer 3:
21Feb13_004029|-- Config --
21Feb13_004029|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004029|-- Weights --
21Feb13_004029|[[ 1.26386 -0.57671  0.50937 -0.22036 -0.39070]
21Feb13_004029| [ 0.60509 -1.28500  1.18720  0.13258  0.67850]]
21Feb13_004029|-- Bias --
21Feb13_004029|[ 0.32363 -0.63931 -0.14484  0.01990  0.58968]
21Feb13_004029|Layer 4:
21Feb13_004029|-- Config --
21Feb13_004029|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004029|-- Weights --
21Feb13_004029|[[-0.22550 -0.83751 -0.16810 -0.40779 -0.29968]
21Feb13_004029| [ 0.41990  0.36976  0.32176 -0.72224 -0.36475]
21Feb13_004029| [-0.65415 -0.58004  1.27034 -1.76347  0.96539]
21Feb13_004029| [-0.04734 -0.12159 -0.27842  0.72893  1.45847]
21Feb13_004029| [-0.29575 -0.34150  1.34919  0.46565  1.37439]]
21Feb13_004029|-- Bias --
21Feb13_004029|[-0.86979  0.07658 -0.97912  0.34494  0.63525]
21Feb13_004029|Layer 5:
21Feb13_004029|-- Config --
21Feb13_004029|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004029|-- Weights --
21Feb13_004029|[[-0.69176 -0.64271]
21Feb13_004029| [-0.59285 -0.50468]
21Feb13_004029| [ 0.61725 -1.55259]
21Feb13_004029| [-0.61286 -0.40967]
21Feb13_004029| [ 0.14040 -0.58444]]
21Feb13_004029|-- Bias --
21Feb13_004029|[-0.58506 -0.05294]
21Feb13_004029|Predicting the validation and test data with the Best final individual.
21Feb13_004037| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_004037|-----------  ------------------  --------------------  ----------
21Feb13_004037|Validation         25.30                  85            0.82338
21Feb13_004037|   Test            22.94                  85            0.71713
21Feb13_004037|-------------------- Test #2 --------------------
21Feb13_004037|Best final individual weights
21Feb13_004037|Individual:
21Feb13_004037|-- Constant hidden layers --
21Feb13_004037|False
21Feb13_004037|Layer 0:
21Feb13_004037|-- Config --
21Feb13_004037|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004037|-- Weights --
21Feb13_004037|[[-1.11314  0.81946 -0.35142]
21Feb13_004037| [-0.92878 -0.89932  0.40299]
21Feb13_004037| [-1.11044 -0.59735  0.24230]
21Feb13_004037| [ 0.20891 -1.31553 -0.36469]
21Feb13_004037| [ 0.30309 -0.76165 -0.23615]
21Feb13_004037| [ 1.64964  0.04056  0.02223]
21Feb13_004037| [-0.55074 -0.75738  0.46557]
21Feb13_004037| [-1.47927 -0.69261  0.23412]
21Feb13_004037| [-1.33298  1.32978 -0.31259]
21Feb13_004037| [ 0.46752  0.11801 -0.00996]
21Feb13_004037| [ 0.81861 -0.72318 -0.19691]
21Feb13_004037| [-0.47734  1.71184 -0.33536]
21Feb13_004037| [ 0.51477  1.28368  0.35802]
21Feb13_004037| [-0.91466  1.47925 -0.08178]
21Feb13_004037| [ 1.46005  0.67436 -0.12592]
21Feb13_004037| [ 0.70720  0.36657 -0.47678]
21Feb13_004037| [-0.64331  0.43277  0.18878]
21Feb13_004037| [-0.71217 -0.37104 -0.25673]
21Feb13_004037| [ 1.56152  0.98624 -0.05791]
21Feb13_004037| [ 0.52313 -0.57117  0.22682]
21Feb13_004037| [-0.84835  0.24573 -0.44370]
21Feb13_004037| [ 0.07356 -0.62497 -0.32272]
21Feb13_004037| [ 0.70192  0.43981  0.43615]
21Feb13_004037| [-0.58147 -1.09590  0.08919]
21Feb13_004037| [-0.40211 -0.70043  0.47088]
21Feb13_004037| [-0.82276  1.57835  0.07738]
21Feb13_004037| [ 1.34172  0.12865 -0.46300]
21Feb13_004037| [ 1.03792 -0.90825  0.09240]
21Feb13_004037| [-1.42926  1.89750 -0.34475]
21Feb13_004037| [ 1.02414 -0.76343 -0.36258]
21Feb13_004037| [-0.88529 -2.26835 -0.18725]
21Feb13_004037| [ 1.30364  1.13824  0.27483]
21Feb13_004037| [-0.44614 -0.47860 -0.49418]
21Feb13_004037| [-0.03176  1.60744 -0.17383]
21Feb13_004037| [ 1.08822  1.62815  0.36013]
21Feb13_004037| [-0.22818  1.19826  0.49832]
21Feb13_004037| [-0.71528 -0.51704  0.29158]
21Feb13_004037| [-0.00854 -1.77518  0.42051]
21Feb13_004037| [-0.93700 -0.26914 -0.20007]
21Feb13_004037| [ 0.00451 -0.48683 -0.48477]
21Feb13_004037| [ 0.93273 -0.19610 -0.22601]
21Feb13_004037| [-0.93976  0.14014  0.16022]
21Feb13_004037| [ 0.41300  1.39614  0.37801]
21Feb13_004037| [ 0.21004 -0.26822  0.13501]
21Feb13_004037| [ 0.14351 -0.81709 -0.11879]
21Feb13_004037| [ 0.28682 -0.71132  0.21680]
21Feb13_004037| [-1.14313 -0.39791 -0.49363]
21Feb13_004037| [-1.09534  0.74258  0.38014]
21Feb13_004037| [ 1.05762 -1.13060  0.44897]
21Feb13_004037| [-0.37677 -2.47419 -0.38946]
21Feb13_004037| [-0.73548 -0.31637  0.13582]
21Feb13_004037| [ 0.71000  0.24351 -0.03873]
21Feb13_004037| [-1.64987  0.44204  0.11190]
21Feb13_004037| [-0.21109  0.41781  0.05437]
21Feb13_004037| [ 1.64591 -1.72953 -0.32023]
21Feb13_004037| [-0.52154  0.33699 -0.04892]
21Feb13_004037| [ 0.28082 -2.11461 -0.40131]]
21Feb13_004037|-- Bias --
21Feb13_004037|[-0.83006 -0.28814 -0.41742]
21Feb13_004037|Layer 1:
21Feb13_004037|-- Config --
21Feb13_004037|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004037|-- Weights --
21Feb13_004037|[[ 0.34190  0.00494]
21Feb13_004037| [-0.03031  0.70309]
21Feb13_004037| [-0.10300 -0.31124]]
21Feb13_004037|-- Bias --
21Feb13_004037|[-1.08834  0.53538]
21Feb13_004037|Layer 2:
21Feb13_004037|-- Config --
21Feb13_004037|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004037|-- Weights --
21Feb13_004037|[[-1.43216 -0.46999]
21Feb13_004037| [-0.25570  0.29812]]
21Feb13_004037|-- Bias --
21Feb13_004037|[0.53497 0.59206]
21Feb13_004037|Layer 3:
21Feb13_004037|-- Config --
21Feb13_004037|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004037|-- Weights --
21Feb13_004037|[[ 1.26386 -0.57671  0.50937 -0.22036 -0.39070]
21Feb13_004037| [ 0.60509 -1.28500  1.18720  0.13258  0.67850]]
21Feb13_004037|-- Bias --
21Feb13_004037|[ 0.32363 -0.63931 -0.14484  0.01990  0.58968]
21Feb13_004037|Layer 4:
21Feb13_004037|-- Config --
21Feb13_004037|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004037|-- Weights --
21Feb13_004037|[[-0.22550 -0.83751 -0.16810 -0.40779 -0.29968]
21Feb13_004037| [ 0.41990  0.36976  0.32176 -0.72224 -0.36475]
21Feb13_004037| [-0.65415 -0.58004  1.27034 -1.76347  0.96539]
21Feb13_004037| [-0.04734 -0.12159 -0.27842  0.72893  1.45847]
21Feb13_004037| [-0.29575 -0.34150  1.34919  0.46565  1.37439]]
21Feb13_004037|-- Bias --
21Feb13_004037|[-0.86979  0.07658 -0.97912  0.34494  0.63525]
21Feb13_004037|Layer 5:
21Feb13_004037|-- Config --
21Feb13_004037|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004037|-- Weights --
21Feb13_004037|[[-0.69176 -0.64271]
21Feb13_004037| [-0.59285 -0.50468]
21Feb13_004037| [ 0.61725 -1.55259]
21Feb13_004037| [-0.61286 -0.40967]
21Feb13_004037| [ 0.14040 -0.58444]]
21Feb13_004037|-- Bias --
21Feb13_004037|[-0.58506 -0.05294]
21Feb13_004037|Predicting the validation and test data with the Best final individual.
21Feb13_004046| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_004046|-----------  ------------------  --------------------  ----------
21Feb13_004046|Validation         27.04                  85            0.73749
21Feb13_004046|   Test            22.50                  85            0.63256
21Feb13_004046|-------------------- Test #3 --------------------
21Feb13_004046|Best final individual weights
21Feb13_004046|Individual:
21Feb13_004046|-- Constant hidden layers --
21Feb13_004046|False
21Feb13_004046|Layer 0:
21Feb13_004046|-- Config --
21Feb13_004046|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004046|-- Weights --
21Feb13_004046|[[-1.11314  0.81946 -0.35142]
21Feb13_004046| [-0.92878 -0.89932  0.40299]
21Feb13_004046| [-1.11044 -0.59735  0.24230]
21Feb13_004046| [ 0.20891 -1.31553 -0.36469]
21Feb13_004046| [ 0.30309 -0.76165 -0.23615]
21Feb13_004046| [ 1.64964  0.04056  0.02223]
21Feb13_004046| [-0.55074 -0.75738  0.46557]
21Feb13_004046| [-1.47927 -0.69261  0.23412]
21Feb13_004046| [-1.33298  1.32978 -0.31259]
21Feb13_004046| [ 0.46752  0.11801 -0.00996]
21Feb13_004046| [ 0.81861 -0.72318 -0.19691]
21Feb13_004046| [-0.47734  1.71184 -0.33536]
21Feb13_004046| [ 0.51477  1.28368  0.35802]
21Feb13_004046| [-0.91466  1.47925 -0.08178]
21Feb13_004046| [ 1.46005  0.67436 -0.12592]
21Feb13_004046| [ 0.70720  0.36657 -0.47678]
21Feb13_004046| [-0.64331  0.43277  0.18878]
21Feb13_004046| [-0.71217 -0.37104 -0.25673]
21Feb13_004046| [ 1.56152  0.98624 -0.05791]
21Feb13_004046| [ 0.52313 -0.57117  0.22682]
21Feb13_004046| [-0.84835  0.24573 -0.44370]
21Feb13_004046| [ 0.07356 -0.62497 -0.32272]
21Feb13_004046| [ 0.70192  0.43981  0.43615]
21Feb13_004046| [-0.58147 -1.09590  0.08919]
21Feb13_004046| [-0.40211 -0.70043  0.47088]
21Feb13_004046| [-0.82276  1.57835  0.07738]
21Feb13_004046| [ 1.34172  0.12865 -0.46300]
21Feb13_004046| [ 1.03792 -0.90825  0.09240]
21Feb13_004046| [-1.42926  1.89750 -0.34475]
21Feb13_004046| [ 1.02414 -0.76343 -0.36258]
21Feb13_004046| [-0.88529 -2.26835 -0.18725]
21Feb13_004046| [ 1.30364  1.13824  0.27483]
21Feb13_004046| [-0.44614 -0.47860 -0.49418]
21Feb13_004046| [-0.03176  1.60744 -0.17383]
21Feb13_004046| [ 1.08822  1.62815  0.36013]
21Feb13_004046| [-0.22818  1.19826  0.49832]
21Feb13_004046| [-0.71528 -0.51704  0.29158]
21Feb13_004046| [-0.00854 -1.77518  0.42051]
21Feb13_004046| [-0.93700 -0.26914 -0.20007]
21Feb13_004046| [ 0.00451 -0.48683 -0.48477]
21Feb13_004046| [ 0.93273 -0.19610 -0.22601]
21Feb13_004046| [-0.93976  0.14014  0.16022]
21Feb13_004046| [ 0.41300  1.39614  0.37801]
21Feb13_004046| [ 0.21004 -0.26822  0.13501]
21Feb13_004046| [ 0.14351 -0.81709 -0.11879]
21Feb13_004046| [ 0.28682 -0.71132  0.21680]
21Feb13_004046| [-1.14313 -0.39791 -0.49363]
21Feb13_004046| [-1.09534  0.74258  0.38014]
21Feb13_004046| [ 1.05762 -1.13060  0.44897]
21Feb13_004046| [-0.37677 -2.47419 -0.38946]
21Feb13_004046| [-0.73548 -0.31637  0.13582]
21Feb13_004046| [ 0.71000  0.24351 -0.03873]
21Feb13_004046| [-1.64987  0.44204  0.11190]
21Feb13_004046| [-0.21109  0.41781  0.05437]
21Feb13_004046| [ 1.64591 -1.72953 -0.32023]
21Feb13_004046| [-0.52154  0.33699 -0.04892]
21Feb13_004046| [ 0.28082 -2.11461 -0.40131]]
21Feb13_004046|-- Bias --
21Feb13_004046|[-0.83006 -0.28814 -0.41742]
21Feb13_004046|Layer 1:
21Feb13_004046|-- Config --
21Feb13_004046|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004046|-- Weights --
21Feb13_004046|[[ 0.34190  0.00494]
21Feb13_004046| [-0.03031  0.70309]
21Feb13_004046| [-0.10300 -0.31124]]
21Feb13_004046|-- Bias --
21Feb13_004046|[-1.08834  0.53538]
21Feb13_004046|Layer 2:
21Feb13_004046|-- Config --
21Feb13_004046|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004046|-- Weights --
21Feb13_004046|[[-1.43216 -0.46999]
21Feb13_004046| [-0.25570  0.29812]]
21Feb13_004046|-- Bias --
21Feb13_004046|[0.53497 0.59206]
21Feb13_004046|Layer 3:
21Feb13_004046|-- Config --
21Feb13_004046|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004046|-- Weights --
21Feb13_004046|[[ 1.26386 -0.57671  0.50937 -0.22036 -0.39070]
21Feb13_004046| [ 0.60509 -1.28500  1.18720  0.13258  0.67850]]
21Feb13_004046|-- Bias --
21Feb13_004046|[ 0.32363 -0.63931 -0.14484  0.01990  0.58968]
21Feb13_004046|Layer 4:
21Feb13_004046|-- Config --
21Feb13_004046|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004046|-- Weights --
21Feb13_004046|[[-0.22550 -0.83751 -0.16810 -0.40779 -0.29968]
21Feb13_004046| [ 0.41990  0.36976  0.32176 -0.72224 -0.36475]
21Feb13_004046| [-0.65415 -0.58004  1.27034 -1.76347  0.96539]
21Feb13_004046| [-0.04734 -0.12159 -0.27842  0.72893  1.45847]
21Feb13_004046| [-0.29575 -0.34150  1.34919  0.46565  1.37439]]
21Feb13_004046|-- Bias --
21Feb13_004046|[-0.86979  0.07658 -0.97912  0.34494  0.63525]
21Feb13_004046|Layer 5:
21Feb13_004046|-- Config --
21Feb13_004046|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004046|-- Weights --
21Feb13_004046|[[-0.69176 -0.64271]
21Feb13_004046| [-0.59285 -0.50468]
21Feb13_004046| [ 0.61725 -1.55259]
21Feb13_004046| [-0.61286 -0.40967]
21Feb13_004046| [ 0.14040 -0.58444]]
21Feb13_004046|-- Bias --
21Feb13_004046|[-0.58506 -0.05294]
21Feb13_004046|Predicting the validation and test data with the Best final individual.
21Feb13_004054| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_004054|-----------  ------------------  --------------------  ----------
21Feb13_004054|Validation         21.74                  85            0.76030
21Feb13_004054|   Test            26.50                  85            0.60376
21Feb13_004054|-------------------- Test #4 --------------------
21Feb13_004054|Best final individual weights
21Feb13_004054|Individual:
21Feb13_004054|-- Constant hidden layers --
21Feb13_004054|False
21Feb13_004054|Layer 0:
21Feb13_004054|-- Config --
21Feb13_004054|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004054|-- Weights --
21Feb13_004054|[[-1.11314  0.81946 -0.35142]
21Feb13_004054| [-0.92878 -0.89932  0.40299]
21Feb13_004054| [-1.11044 -0.59735  0.24230]
21Feb13_004054| [ 0.20891 -1.31553 -0.36469]
21Feb13_004054| [ 0.30309 -0.76165 -0.23615]
21Feb13_004054| [ 1.64964  0.04056  0.02223]
21Feb13_004054| [-0.55074 -0.75738  0.46557]
21Feb13_004054| [-1.47927 -0.69261  0.23412]
21Feb13_004054| [-1.33298  1.32978 -0.31259]
21Feb13_004054| [ 0.46752  0.11801 -0.00996]
21Feb13_004054| [ 0.81861 -0.72318 -0.19691]
21Feb13_004054| [-0.47734  1.71184 -0.33536]
21Feb13_004054| [ 0.51477  1.28368  0.35802]
21Feb13_004054| [-0.91466  1.47925 -0.08178]
21Feb13_004054| [ 1.46005  0.67436 -0.12592]
21Feb13_004054| [ 0.70720  0.36657 -0.47678]
21Feb13_004054| [-0.64331  0.43277  0.18878]
21Feb13_004054| [-0.71217 -0.37104 -0.25673]
21Feb13_004054| [ 1.56152  0.98624 -0.05791]
21Feb13_004054| [ 0.52313 -0.57117  0.22682]
21Feb13_004054| [-0.84835  0.24573 -0.44370]
21Feb13_004054| [ 0.07356 -0.62497 -0.32272]
21Feb13_004054| [ 0.70192  0.43981  0.43615]
21Feb13_004054| [-0.58147 -1.09590  0.08919]
21Feb13_004054| [-0.40211 -0.70043  0.47088]
21Feb13_004054| [-0.82276  1.57835  0.07738]
21Feb13_004054| [ 1.34172  0.12865 -0.46300]
21Feb13_004054| [ 1.03792 -0.90825  0.09240]
21Feb13_004054| [-1.42926  1.89750 -0.34475]
21Feb13_004054| [ 1.02414 -0.76343 -0.36258]
21Feb13_004054| [-0.88529 -2.26835 -0.18725]
21Feb13_004054| [ 1.30364  1.13824  0.27483]
21Feb13_004054| [-0.44614 -0.47860 -0.49418]
21Feb13_004054| [-0.03176  1.60744 -0.17383]
21Feb13_004054| [ 1.08822  1.62815  0.36013]
21Feb13_004054| [-0.22818  1.19826  0.49832]
21Feb13_004054| [-0.71528 -0.51704  0.29158]
21Feb13_004054| [-0.00854 -1.77518  0.42051]
21Feb13_004054| [-0.93700 -0.26914 -0.20007]
21Feb13_004054| [ 0.00451 -0.48683 -0.48477]
21Feb13_004054| [ 0.93273 -0.19610 -0.22601]
21Feb13_004054| [-0.93976  0.14014  0.16022]
21Feb13_004054| [ 0.41300  1.39614  0.37801]
21Feb13_004054| [ 0.21004 -0.26822  0.13501]
21Feb13_004054| [ 0.14351 -0.81709 -0.11879]
21Feb13_004054| [ 0.28682 -0.71132  0.21680]
21Feb13_004054| [-1.14313 -0.39791 -0.49363]
21Feb13_004054| [-1.09534  0.74258  0.38014]
21Feb13_004054| [ 1.05762 -1.13060  0.44897]
21Feb13_004054| [-0.37677 -2.47419 -0.38946]
21Feb13_004054| [-0.73548 -0.31637  0.13582]
21Feb13_004054| [ 0.71000  0.24351 -0.03873]
21Feb13_004054| [-1.64987  0.44204  0.11190]
21Feb13_004054| [-0.21109  0.41781  0.05437]
21Feb13_004054| [ 1.64591 -1.72953 -0.32023]
21Feb13_004054| [-0.52154  0.33699 -0.04892]
21Feb13_004054| [ 0.28082 -2.11461 -0.40131]]
21Feb13_004054|-- Bias --
21Feb13_004054|[-0.83006 -0.28814 -0.41742]
21Feb13_004054|Layer 1:
21Feb13_004054|-- Config --
21Feb13_004054|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004054|-- Weights --
21Feb13_004054|[[ 0.34190  0.00494]
21Feb13_004054| [-0.03031  0.70309]
21Feb13_004054| [-0.10300 -0.31124]]
21Feb13_004054|-- Bias --
21Feb13_004054|[-1.08834  0.53538]
21Feb13_004054|Layer 2:
21Feb13_004054|-- Config --
21Feb13_004054|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004054|-- Weights --
21Feb13_004054|[[-1.43216 -0.46999]
21Feb13_004054| [-0.25570  0.29812]]
21Feb13_004054|-- Bias --
21Feb13_004054|[0.53497 0.59206]
21Feb13_004054|Layer 3:
21Feb13_004054|-- Config --
21Feb13_004054|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004054|-- Weights --
21Feb13_004054|[[ 1.26386 -0.57671  0.50937 -0.22036 -0.39070]
21Feb13_004054| [ 0.60509 -1.28500  1.18720  0.13258  0.67850]]
21Feb13_004054|-- Bias --
21Feb13_004054|[ 0.32363 -0.63931 -0.14484  0.01990  0.58968]
21Feb13_004054|Layer 4:
21Feb13_004054|-- Config --
21Feb13_004054|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004054|-- Weights --
21Feb13_004054|[[-0.22550 -0.83751 -0.16810 -0.40779 -0.29968]
21Feb13_004054| [ 0.41990  0.36976  0.32176 -0.72224 -0.36475]
21Feb13_004054| [-0.65415 -0.58004  1.27034 -1.76347  0.96539]
21Feb13_004054| [-0.04734 -0.12159 -0.27842  0.72893  1.45847]
21Feb13_004054| [-0.29575 -0.34150  1.34919  0.46565  1.37439]]
21Feb13_004054|-- Bias --
21Feb13_004054|[-0.86979  0.07658 -0.97912  0.34494  0.63525]
21Feb13_004054|Layer 5:
21Feb13_004054|-- Config --
21Feb13_004054|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004054|-- Weights --
21Feb13_004054|[[-0.69176 -0.64271]
21Feb13_004054| [-0.59285 -0.50468]
21Feb13_004054| [ 0.61725 -1.55259]
21Feb13_004054| [-0.61286 -0.40967]
21Feb13_004054| [ 0.14040 -0.58444]]
21Feb13_004054|-- Bias --
21Feb13_004054|[-0.58506 -0.05294]
21Feb13_004054|Predicting the validation and test data with the Best final individual.
21Feb13_004102| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_004102|-----------  ------------------  --------------------  ----------
21Feb13_004102|Validation         23.57                  85            0.80203
21Feb13_004102|   Test            39.01                  85            0.00000
21Feb13_004102|-------------------- Test #5 --------------------
21Feb13_004102|Best final individual weights
21Feb13_004102|Individual:
21Feb13_004102|-- Constant hidden layers --
21Feb13_004102|False
21Feb13_004102|Layer 0:
21Feb13_004102|-- Config --
21Feb13_004102|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004102|-- Weights --
21Feb13_004102|[[-1.11314  0.81946 -0.35142]
21Feb13_004102| [-0.92878 -0.89932  0.40299]
21Feb13_004102| [-1.11044 -0.59735  0.24230]
21Feb13_004102| [ 0.20891 -1.31553 -0.36469]
21Feb13_004102| [ 0.30309 -0.76165 -0.23615]
21Feb13_004102| [ 1.64964  0.04056  0.02223]
21Feb13_004102| [-0.55074 -0.75738  0.46557]
21Feb13_004102| [-1.47927 -0.69261  0.23412]
21Feb13_004102| [-1.33298  1.32978 -0.31259]
21Feb13_004102| [ 0.46752  0.11801 -0.00996]
21Feb13_004102| [ 0.81861 -0.72318 -0.19691]
21Feb13_004102| [-0.47734  1.71184 -0.33536]
21Feb13_004102| [ 0.51477  1.28368  0.35802]
21Feb13_004102| [-0.91466  1.47925 -0.08178]
21Feb13_004102| [ 1.46005  0.67436 -0.12592]
21Feb13_004102| [ 0.70720  0.36657 -0.47678]
21Feb13_004102| [-0.64331  0.43277  0.18878]
21Feb13_004102| [-0.71217 -0.37104 -0.25673]
21Feb13_004102| [ 1.56152  0.98624 -0.05791]
21Feb13_004102| [ 0.52313 -0.57117  0.22682]
21Feb13_004102| [-0.84835  0.24573 -0.44370]
21Feb13_004102| [ 0.07356 -0.62497 -0.32272]
21Feb13_004102| [ 0.70192  0.43981  0.43615]
21Feb13_004102| [-0.58147 -1.09590  0.08919]
21Feb13_004102| [-0.40211 -0.70043  0.47088]
21Feb13_004102| [-0.82276  1.57835  0.07738]
21Feb13_004102| [ 1.34172  0.12865 -0.46300]
21Feb13_004102| [ 1.03792 -0.90825  0.09240]
21Feb13_004102| [-1.42926  1.89750 -0.34475]
21Feb13_004102| [ 1.02414 -0.76343 -0.36258]
21Feb13_004102| [-0.88529 -2.26835 -0.18725]
21Feb13_004102| [ 1.30364  1.13824  0.27483]
21Feb13_004102| [-0.44614 -0.47860 -0.49418]
21Feb13_004102| [-0.03176  1.60744 -0.17383]
21Feb13_004102| [ 1.08822  1.62815  0.36013]
21Feb13_004102| [-0.22818  1.19826  0.49832]
21Feb13_004102| [-0.71528 -0.51704  0.29158]
21Feb13_004102| [-0.00854 -1.77518  0.42051]
21Feb13_004102| [-0.93700 -0.26914 -0.20007]
21Feb13_004102| [ 0.00451 -0.48683 -0.48477]
21Feb13_004102| [ 0.93273 -0.19610 -0.22601]
21Feb13_004102| [-0.93976  0.14014  0.16022]
21Feb13_004102| [ 0.41300  1.39614  0.37801]
21Feb13_004102| [ 0.21004 -0.26822  0.13501]
21Feb13_004102| [ 0.14351 -0.81709 -0.11879]
21Feb13_004102| [ 0.28682 -0.71132  0.21680]
21Feb13_004102| [-1.14313 -0.39791 -0.49363]
21Feb13_004102| [-1.09534  0.74258  0.38014]
21Feb13_004102| [ 1.05762 -1.13060  0.44897]
21Feb13_004102| [-0.37677 -2.47419 -0.38946]
21Feb13_004102| [-0.73548 -0.31637  0.13582]
21Feb13_004102| [ 0.71000  0.24351 -0.03873]
21Feb13_004102| [-1.64987  0.44204  0.11190]
21Feb13_004102| [-0.21109  0.41781  0.05437]
21Feb13_004102| [ 1.64591 -1.72953 -0.32023]
21Feb13_004102| [-0.52154  0.33699 -0.04892]
21Feb13_004102| [ 0.28082 -2.11461 -0.40131]]
21Feb13_004102|-- Bias --
21Feb13_004102|[-0.83006 -0.28814 -0.41742]
21Feb13_004102|Layer 1:
21Feb13_004102|-- Config --
21Feb13_004102|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004102|-- Weights --
21Feb13_004102|[[ 0.34190  0.00494]
21Feb13_004102| [-0.03031  0.70309]
21Feb13_004102| [-0.10300 -0.31124]]
21Feb13_004102|-- Bias --
21Feb13_004102|[-1.08834  0.53538]
21Feb13_004102|Layer 2:
21Feb13_004102|-- Config --
21Feb13_004102|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004102|-- Weights --
21Feb13_004102|[[-1.43216 -0.46999]
21Feb13_004102| [-0.25570  0.29812]]
21Feb13_004102|-- Bias --
21Feb13_004102|[0.53497 0.59206]
21Feb13_004102|Layer 3:
21Feb13_004102|-- Config --
21Feb13_004102|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004102|-- Weights --
21Feb13_004102|[[ 1.26386 -0.57671  0.50937 -0.22036 -0.39070]
21Feb13_004102| [ 0.60509 -1.28500  1.18720  0.13258  0.67850]]
21Feb13_004102|-- Bias --
21Feb13_004102|[ 0.32363 -0.63931 -0.14484  0.01990  0.58968]
21Feb13_004102|Layer 4:
21Feb13_004102|-- Config --
21Feb13_004102|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004102|-- Weights --
21Feb13_004102|[[-0.22550 -0.83751 -0.16810 -0.40779 -0.29968]
21Feb13_004102| [ 0.41990  0.36976  0.32176 -0.72224 -0.36475]
21Feb13_004102| [-0.65415 -0.58004  1.27034 -1.76347  0.96539]
21Feb13_004102| [-0.04734 -0.12159 -0.27842  0.72893  1.45847]
21Feb13_004102| [-0.29575 -0.34150  1.34919  0.46565  1.37439]]
21Feb13_004102|-- Bias --
21Feb13_004102|[-0.86979  0.07658 -0.97912  0.34494  0.63525]
21Feb13_004102|Layer 5:
21Feb13_004102|-- Config --
21Feb13_004102|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004102|-- Weights --
21Feb13_004102|[[-0.69176 -0.64271]
21Feb13_004102| [-0.59285 -0.50468]
21Feb13_004102| [ 0.61725 -1.55259]
21Feb13_004102| [-0.61286 -0.40967]
21Feb13_004102| [ 0.14040 -0.58444]]
21Feb13_004102|-- Bias --
21Feb13_004102|[-0.58506 -0.05294]
21Feb13_004102|Predicting the validation and test data with the Best final individual.
21Feb13_004111| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_004111|-----------  ------------------  --------------------  ----------
21Feb13_004111|Validation         21.57                  85            0.69936
21Feb13_004111|   Test            24.76                  85            0.78715
21Feb13_004111|-------------------- Test #6 --------------------
21Feb13_004111|Best final individual weights
21Feb13_004111|Individual:
21Feb13_004111|-- Constant hidden layers --
21Feb13_004111|False
21Feb13_004111|Layer 0:
21Feb13_004111|-- Config --
21Feb13_004111|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004111|-- Weights --
21Feb13_004111|[[-1.11314  0.81946 -0.35142]
21Feb13_004111| [-0.92878 -0.89932  0.40299]
21Feb13_004111| [-1.11044 -0.59735  0.24230]
21Feb13_004111| [ 0.20891 -1.31553 -0.36469]
21Feb13_004111| [ 0.30309 -0.76165 -0.23615]
21Feb13_004111| [ 1.64964  0.04056  0.02223]
21Feb13_004111| [-0.55074 -0.75738  0.46557]
21Feb13_004111| [-1.47927 -0.69261  0.23412]
21Feb13_004111| [-1.33298  1.32978 -0.31259]
21Feb13_004111| [ 0.46752  0.11801 -0.00996]
21Feb13_004111| [ 0.81861 -0.72318 -0.19691]
21Feb13_004111| [-0.47734  1.71184 -0.33536]
21Feb13_004111| [ 0.51477  1.28368  0.35802]
21Feb13_004111| [-0.91466  1.47925 -0.08178]
21Feb13_004111| [ 1.46005  0.67436 -0.12592]
21Feb13_004111| [ 0.70720  0.36657 -0.47678]
21Feb13_004111| [-0.64331  0.43277  0.18878]
21Feb13_004111| [-0.71217 -0.37104 -0.25673]
21Feb13_004111| [ 1.56152  0.98624 -0.05791]
21Feb13_004111| [ 0.52313 -0.57117  0.22682]
21Feb13_004111| [-0.84835  0.24573 -0.44370]
21Feb13_004111| [ 0.07356 -0.62497 -0.32272]
21Feb13_004111| [ 0.70192  0.43981  0.43615]
21Feb13_004111| [-0.58147 -1.09590  0.08919]
21Feb13_004111| [-0.40211 -0.70043  0.47088]
21Feb13_004111| [-0.82276  1.57835  0.07738]
21Feb13_004111| [ 1.34172  0.12865 -0.46300]
21Feb13_004111| [ 1.03792 -0.90825  0.09240]
21Feb13_004111| [-1.42926  1.89750 -0.34475]
21Feb13_004111| [ 1.02414 -0.76343 -0.36258]
21Feb13_004111| [-0.88529 -2.26835 -0.18725]
21Feb13_004111| [ 1.30364  1.13824  0.27483]
21Feb13_004111| [-0.44614 -0.47860 -0.49418]
21Feb13_004111| [-0.03176  1.60744 -0.17383]
21Feb13_004111| [ 1.08822  1.62815  0.36013]
21Feb13_004111| [-0.22818  1.19826  0.49832]
21Feb13_004111| [-0.71528 -0.51704  0.29158]
21Feb13_004111| [-0.00854 -1.77518  0.42051]
21Feb13_004111| [-0.93700 -0.26914 -0.20007]
21Feb13_004111| [ 0.00451 -0.48683 -0.48477]
21Feb13_004111| [ 0.93273 -0.19610 -0.22601]
21Feb13_004111| [-0.93976  0.14014  0.16022]
21Feb13_004111| [ 0.41300  1.39614  0.37801]
21Feb13_004111| [ 0.21004 -0.26822  0.13501]
21Feb13_004111| [ 0.14351 -0.81709 -0.11879]
21Feb13_004111| [ 0.28682 -0.71132  0.21680]
21Feb13_004111| [-1.14313 -0.39791 -0.49363]
21Feb13_004111| [-1.09534  0.74258  0.38014]
21Feb13_004111| [ 1.05762 -1.13060  0.44897]
21Feb13_004111| [-0.37677 -2.47419 -0.38946]
21Feb13_004111| [-0.73548 -0.31637  0.13582]
21Feb13_004111| [ 0.71000  0.24351 -0.03873]
21Feb13_004111| [-1.64987  0.44204  0.11190]
21Feb13_004111| [-0.21109  0.41781  0.05437]
21Feb13_004111| [ 1.64591 -1.72953 -0.32023]
21Feb13_004111| [-0.52154  0.33699 -0.04892]
21Feb13_004111| [ 0.28082 -2.11461 -0.40131]]
21Feb13_004111|-- Bias --
21Feb13_004111|[-0.83006 -0.28814 -0.41742]
21Feb13_004111|Layer 1:
21Feb13_004111|-- Config --
21Feb13_004111|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004111|-- Weights --
21Feb13_004111|[[ 0.34190  0.00494]
21Feb13_004111| [-0.03031  0.70309]
21Feb13_004111| [-0.10300 -0.31124]]
21Feb13_004111|-- Bias --
21Feb13_004111|[-1.08834  0.53538]
21Feb13_004111|Layer 2:
21Feb13_004111|-- Config --
21Feb13_004111|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004111|-- Weights --
21Feb13_004111|[[-1.43216 -0.46999]
21Feb13_004111| [-0.25570  0.29812]]
21Feb13_004111|-- Bias --
21Feb13_004111|[0.53497 0.59206]
21Feb13_004111|Layer 3:
21Feb13_004111|-- Config --
21Feb13_004111|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004111|-- Weights --
21Feb13_004111|[[ 1.26386 -0.57671  0.50937 -0.22036 -0.39070]
21Feb13_004111| [ 0.60509 -1.28500  1.18720  0.13258  0.67850]]
21Feb13_004111|-- Bias --
21Feb13_004111|[ 0.32363 -0.63931 -0.14484  0.01990  0.58968]
21Feb13_004111|Layer 4:
21Feb13_004111|-- Config --
21Feb13_004111|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004111|-- Weights --
21Feb13_004111|[[-0.22550 -0.83751 -0.16810 -0.40779 -0.29968]
21Feb13_004111| [ 0.41990  0.36976  0.32176 -0.72224 -0.36475]
21Feb13_004111| [-0.65415 -0.58004  1.27034 -1.76347  0.96539]
21Feb13_004111| [-0.04734 -0.12159 -0.27842  0.72893  1.45847]
21Feb13_004111| [-0.29575 -0.34150  1.34919  0.46565  1.37439]]
21Feb13_004111|-- Bias --
21Feb13_004111|[-0.86979  0.07658 -0.97912  0.34494  0.63525]
21Feb13_004111|Layer 5:
21Feb13_004111|-- Config --
21Feb13_004111|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004111|-- Weights --
21Feb13_004111|[[-0.69176 -0.64271]
21Feb13_004111| [-0.59285 -0.50468]
21Feb13_004111| [ 0.61725 -1.55259]
21Feb13_004111| [-0.61286 -0.40967]
21Feb13_004111| [ 0.14040 -0.58444]]
21Feb13_004111|-- Bias --
21Feb13_004111|[-0.58506 -0.05294]
21Feb13_004111|Predicting the validation and test data with the Best final individual.
21Feb13_004119| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_004119|-----------  ------------------  --------------------  ----------
21Feb13_004119|Validation         22.87                  85            0.78293
21Feb13_004119|   Test            39.01                  85            0.00000
21Feb13_004119|-------------------- Test #7 --------------------
21Feb13_004119|Best final individual weights
21Feb13_004119|Individual:
21Feb13_004119|-- Constant hidden layers --
21Feb13_004119|False
21Feb13_004119|Layer 0:
21Feb13_004119|-- Config --
21Feb13_004119|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004119|-- Weights --
21Feb13_004119|[[-1.11314  0.81946 -0.35142]
21Feb13_004119| [-0.92878 -0.89932  0.40299]
21Feb13_004119| [-1.11044 -0.59735  0.24230]
21Feb13_004119| [ 0.20891 -1.31553 -0.36469]
21Feb13_004119| [ 0.30309 -0.76165 -0.23615]
21Feb13_004119| [ 1.64964  0.04056  0.02223]
21Feb13_004119| [-0.55074 -0.75738  0.46557]
21Feb13_004119| [-1.47927 -0.69261  0.23412]
21Feb13_004119| [-1.33298  1.32978 -0.31259]
21Feb13_004119| [ 0.46752  0.11801 -0.00996]
21Feb13_004119| [ 0.81861 -0.72318 -0.19691]
21Feb13_004119| [-0.47734  1.71184 -0.33536]
21Feb13_004119| [ 0.51477  1.28368  0.35802]
21Feb13_004119| [-0.91466  1.47925 -0.08178]
21Feb13_004119| [ 1.46005  0.67436 -0.12592]
21Feb13_004119| [ 0.70720  0.36657 -0.47678]
21Feb13_004119| [-0.64331  0.43277  0.18878]
21Feb13_004119| [-0.71217 -0.37104 -0.25673]
21Feb13_004119| [ 1.56152  0.98624 -0.05791]
21Feb13_004119| [ 0.52313 -0.57117  0.22682]
21Feb13_004119| [-0.84835  0.24573 -0.44370]
21Feb13_004119| [ 0.07356 -0.62497 -0.32272]
21Feb13_004119| [ 0.70192  0.43981  0.43615]
21Feb13_004119| [-0.58147 -1.09590  0.08919]
21Feb13_004119| [-0.40211 -0.70043  0.47088]
21Feb13_004119| [-0.82276  1.57835  0.07738]
21Feb13_004119| [ 1.34172  0.12865 -0.46300]
21Feb13_004119| [ 1.03792 -0.90825  0.09240]
21Feb13_004119| [-1.42926  1.89750 -0.34475]
21Feb13_004119| [ 1.02414 -0.76343 -0.36258]
21Feb13_004119| [-0.88529 -2.26835 -0.18725]
21Feb13_004119| [ 1.30364  1.13824  0.27483]
21Feb13_004119| [-0.44614 -0.47860 -0.49418]
21Feb13_004119| [-0.03176  1.60744 -0.17383]
21Feb13_004119| [ 1.08822  1.62815  0.36013]
21Feb13_004119| [-0.22818  1.19826  0.49832]
21Feb13_004119| [-0.71528 -0.51704  0.29158]
21Feb13_004119| [-0.00854 -1.77518  0.42051]
21Feb13_004119| [-0.93700 -0.26914 -0.20007]
21Feb13_004119| [ 0.00451 -0.48683 -0.48477]
21Feb13_004119| [ 0.93273 -0.19610 -0.22601]
21Feb13_004119| [-0.93976  0.14014  0.16022]
21Feb13_004119| [ 0.41300  1.39614  0.37801]
21Feb13_004119| [ 0.21004 -0.26822  0.13501]
21Feb13_004119| [ 0.14351 -0.81709 -0.11879]
21Feb13_004119| [ 0.28682 -0.71132  0.21680]
21Feb13_004119| [-1.14313 -0.39791 -0.49363]
21Feb13_004119| [-1.09534  0.74258  0.38014]
21Feb13_004119| [ 1.05762 -1.13060  0.44897]
21Feb13_004119| [-0.37677 -2.47419 -0.38946]
21Feb13_004119| [-0.73548 -0.31637  0.13582]
21Feb13_004119| [ 0.71000  0.24351 -0.03873]
21Feb13_004119| [-1.64987  0.44204  0.11190]
21Feb13_004119| [-0.21109  0.41781  0.05437]
21Feb13_004119| [ 1.64591 -1.72953 -0.32023]
21Feb13_004119| [-0.52154  0.33699 -0.04892]
21Feb13_004119| [ 0.28082 -2.11461 -0.40131]]
21Feb13_004119|-- Bias --
21Feb13_004119|[-0.83006 -0.28814 -0.41742]
21Feb13_004119|Layer 1:
21Feb13_004119|-- Config --
21Feb13_004119|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004119|-- Weights --
21Feb13_004119|[[ 0.34190  0.00494]
21Feb13_004119| [-0.03031  0.70309]
21Feb13_004119| [-0.10300 -0.31124]]
21Feb13_004119|-- Bias --
21Feb13_004119|[-1.08834  0.53538]
21Feb13_004119|Layer 2:
21Feb13_004119|-- Config --
21Feb13_004119|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004119|-- Weights --
21Feb13_004119|[[-1.43216 -0.46999]
21Feb13_004119| [-0.25570  0.29812]]
21Feb13_004119|-- Bias --
21Feb13_004119|[0.53497 0.59206]
21Feb13_004119|Layer 3:
21Feb13_004119|-- Config --
21Feb13_004119|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004119|-- Weights --
21Feb13_004119|[[ 1.26386 -0.57671  0.50937 -0.22036 -0.39070]
21Feb13_004119| [ 0.60509 -1.28500  1.18720  0.13258  0.67850]]
21Feb13_004119|-- Bias --
21Feb13_004119|[ 0.32363 -0.63931 -0.14484  0.01990  0.58968]
21Feb13_004119|Layer 4:
21Feb13_004119|-- Config --
21Feb13_004119|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004119|-- Weights --
21Feb13_004119|[[-0.22550 -0.83751 -0.16810 -0.40779 -0.29968]
21Feb13_004119| [ 0.41990  0.36976  0.32176 -0.72224 -0.36475]
21Feb13_004119| [-0.65415 -0.58004  1.27034 -1.76347  0.96539]
21Feb13_004119| [-0.04734 -0.12159 -0.27842  0.72893  1.45847]
21Feb13_004119| [-0.29575 -0.34150  1.34919  0.46565  1.37439]]
21Feb13_004119|-- Bias --
21Feb13_004119|[-0.86979  0.07658 -0.97912  0.34494  0.63525]
21Feb13_004119|Layer 5:
21Feb13_004119|-- Config --
21Feb13_004119|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004119|-- Weights --
21Feb13_004119|[[-0.69176 -0.64271]
21Feb13_004119| [-0.59285 -0.50468]
21Feb13_004119| [ 0.61725 -1.55259]
21Feb13_004119| [-0.61286 -0.40967]
21Feb13_004119| [ 0.14040 -0.58444]]
21Feb13_004119|-- Bias --
21Feb13_004119|[-0.58506 -0.05294]
21Feb13_004119|Predicting the validation and test data with the Best final individual.
21Feb13_004128| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_004128|-----------  ------------------  --------------------  ----------
21Feb13_004128|Validation         29.57                  85            0.75208
21Feb13_004128|   Test            25.89                  85            0.83029
21Feb13_004128|-------------------- Test #8 --------------------
21Feb13_004128|Best final individual weights
21Feb13_004128|Individual:
21Feb13_004128|-- Constant hidden layers --
21Feb13_004128|False
21Feb13_004128|Layer 0:
21Feb13_004128|-- Config --
21Feb13_004128|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004128|-- Weights --
21Feb13_004128|[[-1.11314  0.81946 -0.35142]
21Feb13_004128| [-0.92878 -0.89932  0.40299]
21Feb13_004128| [-1.11044 -0.59735  0.24230]
21Feb13_004128| [ 0.20891 -1.31553 -0.36469]
21Feb13_004128| [ 0.30309 -0.76165 -0.23615]
21Feb13_004128| [ 1.64964  0.04056  0.02223]
21Feb13_004128| [-0.55074 -0.75738  0.46557]
21Feb13_004128| [-1.47927 -0.69261  0.23412]
21Feb13_004128| [-1.33298  1.32978 -0.31259]
21Feb13_004128| [ 0.46752  0.11801 -0.00996]
21Feb13_004128| [ 0.81861 -0.72318 -0.19691]
21Feb13_004128| [-0.47734  1.71184 -0.33536]
21Feb13_004128| [ 0.51477  1.28368  0.35802]
21Feb13_004128| [-0.91466  1.47925 -0.08178]
21Feb13_004128| [ 1.46005  0.67436 -0.12592]
21Feb13_004128| [ 0.70720  0.36657 -0.47678]
21Feb13_004128| [-0.64331  0.43277  0.18878]
21Feb13_004128| [-0.71217 -0.37104 -0.25673]
21Feb13_004128| [ 1.56152  0.98624 -0.05791]
21Feb13_004128| [ 0.52313 -0.57117  0.22682]
21Feb13_004128| [-0.84835  0.24573 -0.44370]
21Feb13_004128| [ 0.07356 -0.62497 -0.32272]
21Feb13_004128| [ 0.70192  0.43981  0.43615]
21Feb13_004128| [-0.58147 -1.09590  0.08919]
21Feb13_004128| [-0.40211 -0.70043  0.47088]
21Feb13_004128| [-0.82276  1.57835  0.07738]
21Feb13_004128| [ 1.34172  0.12865 -0.46300]
21Feb13_004128| [ 1.03792 -0.90825  0.09240]
21Feb13_004128| [-1.42926  1.89750 -0.34475]
21Feb13_004128| [ 1.02414 -0.76343 -0.36258]
21Feb13_004128| [-0.88529 -2.26835 -0.18725]
21Feb13_004128| [ 1.30364  1.13824  0.27483]
21Feb13_004128| [-0.44614 -0.47860 -0.49418]
21Feb13_004128| [-0.03176  1.60744 -0.17383]
21Feb13_004128| [ 1.08822  1.62815  0.36013]
21Feb13_004128| [-0.22818  1.19826  0.49832]
21Feb13_004128| [-0.71528 -0.51704  0.29158]
21Feb13_004128| [-0.00854 -1.77518  0.42051]
21Feb13_004128| [-0.93700 -0.26914 -0.20007]
21Feb13_004128| [ 0.00451 -0.48683 -0.48477]
21Feb13_004128| [ 0.93273 -0.19610 -0.22601]
21Feb13_004128| [-0.93976  0.14014  0.16022]
21Feb13_004128| [ 0.41300  1.39614  0.37801]
21Feb13_004128| [ 0.21004 -0.26822  0.13501]
21Feb13_004128| [ 0.14351 -0.81709 -0.11879]
21Feb13_004128| [ 0.28682 -0.71132  0.21680]
21Feb13_004128| [-1.14313 -0.39791 -0.49363]
21Feb13_004128| [-1.09534  0.74258  0.38014]
21Feb13_004128| [ 1.05762 -1.13060  0.44897]
21Feb13_004128| [-0.37677 -2.47419 -0.38946]
21Feb13_004128| [-0.73548 -0.31637  0.13582]
21Feb13_004128| [ 0.71000  0.24351 -0.03873]
21Feb13_004128| [-1.64987  0.44204  0.11190]
21Feb13_004128| [-0.21109  0.41781  0.05437]
21Feb13_004128| [ 1.64591 -1.72953 -0.32023]
21Feb13_004128| [-0.52154  0.33699 -0.04892]
21Feb13_004128| [ 0.28082 -2.11461 -0.40131]]
21Feb13_004128|-- Bias --
21Feb13_004128|[-0.83006 -0.28814 -0.41742]
21Feb13_004128|Layer 1:
21Feb13_004128|-- Config --
21Feb13_004128|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004128|-- Weights --
21Feb13_004128|[[ 0.34190  0.00494]
21Feb13_004128| [-0.03031  0.70309]
21Feb13_004128| [-0.10300 -0.31124]]
21Feb13_004128|-- Bias --
21Feb13_004128|[-1.08834  0.53538]
21Feb13_004128|Layer 2:
21Feb13_004128|-- Config --
21Feb13_004128|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004128|-- Weights --
21Feb13_004128|[[-1.43216 -0.46999]
21Feb13_004128| [-0.25570  0.29812]]
21Feb13_004128|-- Bias --
21Feb13_004128|[0.53497 0.59206]
21Feb13_004128|Layer 3:
21Feb13_004128|-- Config --
21Feb13_004128|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004128|-- Weights --
21Feb13_004128|[[ 1.26386 -0.57671  0.50937 -0.22036 -0.39070]
21Feb13_004128| [ 0.60509 -1.28500  1.18720  0.13258  0.67850]]
21Feb13_004128|-- Bias --
21Feb13_004128|[ 0.32363 -0.63931 -0.14484  0.01990  0.58968]
21Feb13_004128|Layer 4:
21Feb13_004128|-- Config --
21Feb13_004128|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004128|-- Weights --
21Feb13_004128|[[-0.22550 -0.83751 -0.16810 -0.40779 -0.29968]
21Feb13_004128| [ 0.41990  0.36976  0.32176 -0.72224 -0.36475]
21Feb13_004128| [-0.65415 -0.58004  1.27034 -1.76347  0.96539]
21Feb13_004128| [-0.04734 -0.12159 -0.27842  0.72893  1.45847]
21Feb13_004128| [-0.29575 -0.34150  1.34919  0.46565  1.37439]]
21Feb13_004128|-- Bias --
21Feb13_004128|[-0.86979  0.07658 -0.97912  0.34494  0.63525]
21Feb13_004128|Layer 5:
21Feb13_004128|-- Config --
21Feb13_004128|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004128|-- Weights --
21Feb13_004128|[[-0.69176 -0.64271]
21Feb13_004128| [-0.59285 -0.50468]
21Feb13_004128| [ 0.61725 -1.55259]
21Feb13_004128| [-0.61286 -0.40967]
21Feb13_004128| [ 0.14040 -0.58444]]
21Feb13_004128|-- Bias --
21Feb13_004128|[-0.58506 -0.05294]
21Feb13_004128|Predicting the validation and test data with the Best final individual.
21Feb13_004136| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_004136|-----------  ------------------  --------------------  ----------
21Feb13_004136|Validation         31.22                  85            0.83038
21Feb13_004136|   Test            32.32                  85            0.29728
21Feb13_004136|-------------------- Test #9 --------------------
21Feb13_004136|Best final individual weights
21Feb13_004136|Individual:
21Feb13_004136|-- Constant hidden layers --
21Feb13_004136|False
21Feb13_004136|Layer 0:
21Feb13_004136|-- Config --
21Feb13_004136|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004136|-- Weights --
21Feb13_004136|[[-1.11314  0.81946 -0.35142]
21Feb13_004136| [-0.92878 -0.89932  0.40299]
21Feb13_004136| [-1.11044 -0.59735  0.24230]
21Feb13_004136| [ 0.20891 -1.31553 -0.36469]
21Feb13_004136| [ 0.30309 -0.76165 -0.23615]
21Feb13_004136| [ 1.64964  0.04056  0.02223]
21Feb13_004136| [-0.55074 -0.75738  0.46557]
21Feb13_004136| [-1.47927 -0.69261  0.23412]
21Feb13_004136| [-1.33298  1.32978 -0.31259]
21Feb13_004136| [ 0.46752  0.11801 -0.00996]
21Feb13_004136| [ 0.81861 -0.72318 -0.19691]
21Feb13_004136| [-0.47734  1.71184 -0.33536]
21Feb13_004136| [ 0.51477  1.28368  0.35802]
21Feb13_004136| [-0.91466  1.47925 -0.08178]
21Feb13_004136| [ 1.46005  0.67436 -0.12592]
21Feb13_004136| [ 0.70720  0.36657 -0.47678]
21Feb13_004136| [-0.64331  0.43277  0.18878]
21Feb13_004136| [-0.71217 -0.37104 -0.25673]
21Feb13_004136| [ 1.56152  0.98624 -0.05791]
21Feb13_004136| [ 0.52313 -0.57117  0.22682]
21Feb13_004136| [-0.84835  0.24573 -0.44370]
21Feb13_004136| [ 0.07356 -0.62497 -0.32272]
21Feb13_004136| [ 0.70192  0.43981  0.43615]
21Feb13_004136| [-0.58147 -1.09590  0.08919]
21Feb13_004136| [-0.40211 -0.70043  0.47088]
21Feb13_004136| [-0.82276  1.57835  0.07738]
21Feb13_004136| [ 1.34172  0.12865 -0.46300]
21Feb13_004136| [ 1.03792 -0.90825  0.09240]
21Feb13_004136| [-1.42926  1.89750 -0.34475]
21Feb13_004136| [ 1.02414 -0.76343 -0.36258]
21Feb13_004136| [-0.88529 -2.26835 -0.18725]
21Feb13_004136| [ 1.30364  1.13824  0.27483]
21Feb13_004136| [-0.44614 -0.47860 -0.49418]
21Feb13_004136| [-0.03176  1.60744 -0.17383]
21Feb13_004136| [ 1.08822  1.62815  0.36013]
21Feb13_004136| [-0.22818  1.19826  0.49832]
21Feb13_004136| [-0.71528 -0.51704  0.29158]
21Feb13_004136| [-0.00854 -1.77518  0.42051]
21Feb13_004136| [-0.93700 -0.26914 -0.20007]
21Feb13_004136| [ 0.00451 -0.48683 -0.48477]
21Feb13_004136| [ 0.93273 -0.19610 -0.22601]
21Feb13_004136| [-0.93976  0.14014  0.16022]
21Feb13_004136| [ 0.41300  1.39614  0.37801]
21Feb13_004136| [ 0.21004 -0.26822  0.13501]
21Feb13_004136| [ 0.14351 -0.81709 -0.11879]
21Feb13_004136| [ 0.28682 -0.71132  0.21680]
21Feb13_004136| [-1.14313 -0.39791 -0.49363]
21Feb13_004136| [-1.09534  0.74258  0.38014]
21Feb13_004136| [ 1.05762 -1.13060  0.44897]
21Feb13_004136| [-0.37677 -2.47419 -0.38946]
21Feb13_004136| [-0.73548 -0.31637  0.13582]
21Feb13_004136| [ 0.71000  0.24351 -0.03873]
21Feb13_004136| [-1.64987  0.44204  0.11190]
21Feb13_004136| [-0.21109  0.41781  0.05437]
21Feb13_004136| [ 1.64591 -1.72953 -0.32023]
21Feb13_004136| [-0.52154  0.33699 -0.04892]
21Feb13_004136| [ 0.28082 -2.11461 -0.40131]]
21Feb13_004136|-- Bias --
21Feb13_004136|[-0.83006 -0.28814 -0.41742]
21Feb13_004136|Layer 1:
21Feb13_004136|-- Config --
21Feb13_004136|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004136|-- Weights --
21Feb13_004136|[[ 0.34190  0.00494]
21Feb13_004136| [-0.03031  0.70309]
21Feb13_004136| [-0.10300 -0.31124]]
21Feb13_004136|-- Bias --
21Feb13_004136|[-1.08834  0.53538]
21Feb13_004136|Layer 2:
21Feb13_004136|-- Config --
21Feb13_004136|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004136|-- Weights --
21Feb13_004136|[[-1.43216 -0.46999]
21Feb13_004136| [-0.25570  0.29812]]
21Feb13_004136|-- Bias --
21Feb13_004136|[0.53497 0.59206]
21Feb13_004136|Layer 3:
21Feb13_004136|-- Config --
21Feb13_004136|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004136|-- Weights --
21Feb13_004136|[[ 1.26386 -0.57671  0.50937 -0.22036 -0.39070]
21Feb13_004136| [ 0.60509 -1.28500  1.18720  0.13258  0.67850]]
21Feb13_004136|-- Bias --
21Feb13_004136|[ 0.32363 -0.63931 -0.14484  0.01990  0.58968]
21Feb13_004136|Layer 4:
21Feb13_004136|-- Config --
21Feb13_004136|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004136|-- Weights --
21Feb13_004136|[[-0.22550 -0.83751 -0.16810 -0.40779 -0.29968]
21Feb13_004136| [ 0.41990  0.36976  0.32176 -0.72224 -0.36475]
21Feb13_004136| [-0.65415 -0.58004  1.27034 -1.76347  0.96539]
21Feb13_004136| [-0.04734 -0.12159 -0.27842  0.72893  1.45847]
21Feb13_004136| [-0.29575 -0.34150  1.34919  0.46565  1.37439]]
21Feb13_004136|-- Bias --
21Feb13_004136|[-0.86979  0.07658 -0.97912  0.34494  0.63525]
21Feb13_004136|Layer 5:
21Feb13_004136|-- Config --
21Feb13_004136|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004136|-- Weights --
21Feb13_004136|[[-0.69176 -0.64271]
21Feb13_004136| [-0.59285 -0.50468]
21Feb13_004136| [ 0.61725 -1.55259]
21Feb13_004136| [-0.61286 -0.40967]
21Feb13_004136| [ 0.14040 -0.58444]]
21Feb13_004136|-- Bias --
21Feb13_004136|[-0.58506 -0.05294]
21Feb13_004136|Predicting the validation and test data with the Best final individual.
21Feb13_004145| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_004145|-----------  ------------------  --------------------  ----------
21Feb13_004145|Validation         24.70                  85            0.80335
21Feb13_004145|   Test            24.41                  85            0.76661
21Feb13_004145|-------------------- Test #10 --------------------
21Feb13_004145|Best final individual weights
21Feb13_004145|Individual:
21Feb13_004145|-- Constant hidden layers --
21Feb13_004145|False
21Feb13_004145|Layer 0:
21Feb13_004145|-- Config --
21Feb13_004145|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004145|-- Weights --
21Feb13_004145|[[-1.11314  0.81946 -0.35142]
21Feb13_004145| [-0.92878 -0.89932  0.40299]
21Feb13_004145| [-1.11044 -0.59735  0.24230]
21Feb13_004145| [ 0.20891 -1.31553 -0.36469]
21Feb13_004145| [ 0.30309 -0.76165 -0.23615]
21Feb13_004145| [ 1.64964  0.04056  0.02223]
21Feb13_004145| [-0.55074 -0.75738  0.46557]
21Feb13_004145| [-1.47927 -0.69261  0.23412]
21Feb13_004145| [-1.33298  1.32978 -0.31259]
21Feb13_004145| [ 0.46752  0.11801 -0.00996]
21Feb13_004145| [ 0.81861 -0.72318 -0.19691]
21Feb13_004145| [-0.47734  1.71184 -0.33536]
21Feb13_004145| [ 0.51477  1.28368  0.35802]
21Feb13_004145| [-0.91466  1.47925 -0.08178]
21Feb13_004145| [ 1.46005  0.67436 -0.12592]
21Feb13_004145| [ 0.70720  0.36657 -0.47678]
21Feb13_004145| [-0.64331  0.43277  0.18878]
21Feb13_004145| [-0.71217 -0.37104 -0.25673]
21Feb13_004145| [ 1.56152  0.98624 -0.05791]
21Feb13_004145| [ 0.52313 -0.57117  0.22682]
21Feb13_004145| [-0.84835  0.24573 -0.44370]
21Feb13_004145| [ 0.07356 -0.62497 -0.32272]
21Feb13_004145| [ 0.70192  0.43981  0.43615]
21Feb13_004145| [-0.58147 -1.09590  0.08919]
21Feb13_004145| [-0.40211 -0.70043  0.47088]
21Feb13_004145| [-0.82276  1.57835  0.07738]
21Feb13_004145| [ 1.34172  0.12865 -0.46300]
21Feb13_004145| [ 1.03792 -0.90825  0.09240]
21Feb13_004145| [-1.42926  1.89750 -0.34475]
21Feb13_004145| [ 1.02414 -0.76343 -0.36258]
21Feb13_004145| [-0.88529 -2.26835 -0.18725]
21Feb13_004145| [ 1.30364  1.13824  0.27483]
21Feb13_004145| [-0.44614 -0.47860 -0.49418]
21Feb13_004145| [-0.03176  1.60744 -0.17383]
21Feb13_004145| [ 1.08822  1.62815  0.36013]
21Feb13_004145| [-0.22818  1.19826  0.49832]
21Feb13_004145| [-0.71528 -0.51704  0.29158]
21Feb13_004145| [-0.00854 -1.77518  0.42051]
21Feb13_004145| [-0.93700 -0.26914 -0.20007]
21Feb13_004145| [ 0.00451 -0.48683 -0.48477]
21Feb13_004145| [ 0.93273 -0.19610 -0.22601]
21Feb13_004145| [-0.93976  0.14014  0.16022]
21Feb13_004145| [ 0.41300  1.39614  0.37801]
21Feb13_004145| [ 0.21004 -0.26822  0.13501]
21Feb13_004145| [ 0.14351 -0.81709 -0.11879]
21Feb13_004145| [ 0.28682 -0.71132  0.21680]
21Feb13_004145| [-1.14313 -0.39791 -0.49363]
21Feb13_004145| [-1.09534  0.74258  0.38014]
21Feb13_004145| [ 1.05762 -1.13060  0.44897]
21Feb13_004145| [-0.37677 -2.47419 -0.38946]
21Feb13_004145| [-0.73548 -0.31637  0.13582]
21Feb13_004145| [ 0.71000  0.24351 -0.03873]
21Feb13_004145| [-1.64987  0.44204  0.11190]
21Feb13_004145| [-0.21109  0.41781  0.05437]
21Feb13_004145| [ 1.64591 -1.72953 -0.32023]
21Feb13_004145| [-0.52154  0.33699 -0.04892]
21Feb13_004145| [ 0.28082 -2.11461 -0.40131]]
21Feb13_004145|-- Bias --
21Feb13_004145|[-0.83006 -0.28814 -0.41742]
21Feb13_004145|Layer 1:
21Feb13_004145|-- Config --
21Feb13_004145|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004145|-- Weights --
21Feb13_004145|[[ 0.34190  0.00494]
21Feb13_004145| [-0.03031  0.70309]
21Feb13_004145| [-0.10300 -0.31124]]
21Feb13_004145|-- Bias --
21Feb13_004145|[-1.08834  0.53538]
21Feb13_004145|Layer 2:
21Feb13_004145|-- Config --
21Feb13_004145|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004145|-- Weights --
21Feb13_004145|[[-1.43216 -0.46999]
21Feb13_004145| [-0.25570  0.29812]]
21Feb13_004145|-- Bias --
21Feb13_004145|[0.53497 0.59206]
21Feb13_004145|Layer 3:
21Feb13_004145|-- Config --
21Feb13_004145|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004145|-- Weights --
21Feb13_004145|[[ 1.26386 -0.57671  0.50937 -0.22036 -0.39070]
21Feb13_004145| [ 0.60509 -1.28500  1.18720  0.13258  0.67850]]
21Feb13_004145|-- Bias --
21Feb13_004145|[ 0.32363 -0.63931 -0.14484  0.01990  0.58968]
21Feb13_004145|Layer 4:
21Feb13_004145|-- Config --
21Feb13_004145|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004145|-- Weights --
21Feb13_004145|[[-0.22550 -0.83751 -0.16810 -0.40779 -0.29968]
21Feb13_004145| [ 0.41990  0.36976  0.32176 -0.72224 -0.36475]
21Feb13_004145| [-0.65415 -0.58004  1.27034 -1.76347  0.96539]
21Feb13_004145| [-0.04734 -0.12159 -0.27842  0.72893  1.45847]
21Feb13_004145| [-0.29575 -0.34150  1.34919  0.46565  1.37439]]
21Feb13_004145|-- Bias --
21Feb13_004145|[-0.86979  0.07658 -0.97912  0.34494  0.63525]
21Feb13_004145|Layer 5:
21Feb13_004145|-- Config --
21Feb13_004145|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004145|-- Weights --
21Feb13_004145|[[-0.69176 -0.64271]
21Feb13_004145| [-0.59285 -0.50468]
21Feb13_004145| [ 0.61725 -1.55259]
21Feb13_004145| [-0.61286 -0.40967]
21Feb13_004145| [ 0.14040 -0.58444]]
21Feb13_004145|-- Bias --
21Feb13_004145|[-0.58506 -0.05294]
21Feb13_004145|Predicting the validation and test data with the Best final individual.
21Feb13_004153| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_004153|-----------  ------------------  --------------------  ----------
21Feb13_004153|Validation         28.17                  85            0.71674
21Feb13_004153|   Test            22.94                  85            0.62935
21Feb13_004153|-------------------- Test #11 --------------------
21Feb13_004153|Best final individual weights
21Feb13_004153|Individual:
21Feb13_004153|-- Constant hidden layers --
21Feb13_004153|False
21Feb13_004153|Layer 0:
21Feb13_004153|-- Config --
21Feb13_004153|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004153|-- Weights --
21Feb13_004153|[[-1.11314  0.81946 -0.35142]
21Feb13_004153| [-0.92878 -0.89932  0.40299]
21Feb13_004153| [-1.11044 -0.59735  0.24230]
21Feb13_004153| [ 0.20891 -1.31553 -0.36469]
21Feb13_004153| [ 0.30309 -0.76165 -0.23615]
21Feb13_004153| [ 1.64964  0.04056  0.02223]
21Feb13_004153| [-0.55074 -0.75738  0.46557]
21Feb13_004153| [-1.47927 -0.69261  0.23412]
21Feb13_004153| [-1.33298  1.32978 -0.31259]
21Feb13_004153| [ 0.46752  0.11801 -0.00996]
21Feb13_004153| [ 0.81861 -0.72318 -0.19691]
21Feb13_004153| [-0.47734  1.71184 -0.33536]
21Feb13_004153| [ 0.51477  1.28368  0.35802]
21Feb13_004153| [-0.91466  1.47925 -0.08178]
21Feb13_004153| [ 1.46005  0.67436 -0.12592]
21Feb13_004153| [ 0.70720  0.36657 -0.47678]
21Feb13_004153| [-0.64331  0.43277  0.18878]
21Feb13_004153| [-0.71217 -0.37104 -0.25673]
21Feb13_004153| [ 1.56152  0.98624 -0.05791]
21Feb13_004153| [ 0.52313 -0.57117  0.22682]
21Feb13_004153| [-0.84835  0.24573 -0.44370]
21Feb13_004153| [ 0.07356 -0.62497 -0.32272]
21Feb13_004153| [ 0.70192  0.43981  0.43615]
21Feb13_004153| [-0.58147 -1.09590  0.08919]
21Feb13_004153| [-0.40211 -0.70043  0.47088]
21Feb13_004153| [-0.82276  1.57835  0.07738]
21Feb13_004153| [ 1.34172  0.12865 -0.46300]
21Feb13_004153| [ 1.03792 -0.90825  0.09240]
21Feb13_004153| [-1.42926  1.89750 -0.34475]
21Feb13_004153| [ 1.02414 -0.76343 -0.36258]
21Feb13_004153| [-0.88529 -2.26835 -0.18725]
21Feb13_004153| [ 1.30364  1.13824  0.27483]
21Feb13_004153| [-0.44614 -0.47860 -0.49418]
21Feb13_004153| [-0.03176  1.60744 -0.17383]
21Feb13_004153| [ 1.08822  1.62815  0.36013]
21Feb13_004153| [-0.22818  1.19826  0.49832]
21Feb13_004153| [-0.71528 -0.51704  0.29158]
21Feb13_004153| [-0.00854 -1.77518  0.42051]
21Feb13_004153| [-0.93700 -0.26914 -0.20007]
21Feb13_004153| [ 0.00451 -0.48683 -0.48477]
21Feb13_004153| [ 0.93273 -0.19610 -0.22601]
21Feb13_004153| [-0.93976  0.14014  0.16022]
21Feb13_004153| [ 0.41300  1.39614  0.37801]
21Feb13_004153| [ 0.21004 -0.26822  0.13501]
21Feb13_004153| [ 0.14351 -0.81709 -0.11879]
21Feb13_004153| [ 0.28682 -0.71132  0.21680]
21Feb13_004153| [-1.14313 -0.39791 -0.49363]
21Feb13_004153| [-1.09534  0.74258  0.38014]
21Feb13_004153| [ 1.05762 -1.13060  0.44897]
21Feb13_004153| [-0.37677 -2.47419 -0.38946]
21Feb13_004153| [-0.73548 -0.31637  0.13582]
21Feb13_004153| [ 0.71000  0.24351 -0.03873]
21Feb13_004153| [-1.64987  0.44204  0.11190]
21Feb13_004153| [-0.21109  0.41781  0.05437]
21Feb13_004153| [ 1.64591 -1.72953 -0.32023]
21Feb13_004153| [-0.52154  0.33699 -0.04892]
21Feb13_004153| [ 0.28082 -2.11461 -0.40131]]
21Feb13_004153|-- Bias --
21Feb13_004153|[-0.83006 -0.28814 -0.41742]
21Feb13_004153|Layer 1:
21Feb13_004153|-- Config --
21Feb13_004153|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004153|-- Weights --
21Feb13_004153|[[ 0.34190  0.00494]
21Feb13_004153| [-0.03031  0.70309]
21Feb13_004153| [-0.10300 -0.31124]]
21Feb13_004153|-- Bias --
21Feb13_004153|[-1.08834  0.53538]
21Feb13_004153|Layer 2:
21Feb13_004153|-- Config --
21Feb13_004153|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004153|-- Weights --
21Feb13_004153|[[-1.43216 -0.46999]
21Feb13_004153| [-0.25570  0.29812]]
21Feb13_004153|-- Bias --
21Feb13_004153|[0.53497 0.59206]
21Feb13_004153|Layer 3:
21Feb13_004153|-- Config --
21Feb13_004153|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004153|-- Weights --
21Feb13_004153|[[ 1.26386 -0.57671  0.50937 -0.22036 -0.39070]
21Feb13_004153| [ 0.60509 -1.28500  1.18720  0.13258  0.67850]]
21Feb13_004153|-- Bias --
21Feb13_004153|[ 0.32363 -0.63931 -0.14484  0.01990  0.58968]
21Feb13_004153|Layer 4:
21Feb13_004153|-- Config --
21Feb13_004153|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004153|-- Weights --
21Feb13_004153|[[-0.22550 -0.83751 -0.16810 -0.40779 -0.29968]
21Feb13_004153| [ 0.41990  0.36976  0.32176 -0.72224 -0.36475]
21Feb13_004153| [-0.65415 -0.58004  1.27034 -1.76347  0.96539]
21Feb13_004153| [-0.04734 -0.12159 -0.27842  0.72893  1.45847]
21Feb13_004153| [-0.29575 -0.34150  1.34919  0.46565  1.37439]]
21Feb13_004153|-- Bias --
21Feb13_004153|[-0.86979  0.07658 -0.97912  0.34494  0.63525]
21Feb13_004153|Layer 5:
21Feb13_004153|-- Config --
21Feb13_004153|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004153|-- Weights --
21Feb13_004153|[[-0.69176 -0.64271]
21Feb13_004153| [-0.59285 -0.50468]
21Feb13_004153| [ 0.61725 -1.55259]
21Feb13_004153| [-0.61286 -0.40967]
21Feb13_004153| [ 0.14040 -0.58444]]
21Feb13_004153|-- Bias --
21Feb13_004153|[-0.58506 -0.05294]
21Feb13_004153|Predicting the validation and test data with the Best final individual.
21Feb13_004202| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_004202|-----------  ------------------  --------------------  ----------
21Feb13_004202|Validation         28.00                  85            0.74598
21Feb13_004202|   Test            30.23                  85            0.76118
21Feb13_004202|-------------------- Test #12 --------------------
21Feb13_004202|Best final individual weights
21Feb13_004202|Individual:
21Feb13_004202|-- Constant hidden layers --
21Feb13_004202|False
21Feb13_004202|Layer 0:
21Feb13_004202|-- Config --
21Feb13_004202|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004202|-- Weights --
21Feb13_004202|[[-1.11314  0.81946 -0.35142]
21Feb13_004202| [-0.92878 -0.89932  0.40299]
21Feb13_004202| [-1.11044 -0.59735  0.24230]
21Feb13_004202| [ 0.20891 -1.31553 -0.36469]
21Feb13_004202| [ 0.30309 -0.76165 -0.23615]
21Feb13_004202| [ 1.64964  0.04056  0.02223]
21Feb13_004202| [-0.55074 -0.75738  0.46557]
21Feb13_004202| [-1.47927 -0.69261  0.23412]
21Feb13_004202| [-1.33298  1.32978 -0.31259]
21Feb13_004202| [ 0.46752  0.11801 -0.00996]
21Feb13_004202| [ 0.81861 -0.72318 -0.19691]
21Feb13_004202| [-0.47734  1.71184 -0.33536]
21Feb13_004202| [ 0.51477  1.28368  0.35802]
21Feb13_004202| [-0.91466  1.47925 -0.08178]
21Feb13_004202| [ 1.46005  0.67436 -0.12592]
21Feb13_004202| [ 0.70720  0.36657 -0.47678]
21Feb13_004202| [-0.64331  0.43277  0.18878]
21Feb13_004202| [-0.71217 -0.37104 -0.25673]
21Feb13_004202| [ 1.56152  0.98624 -0.05791]
21Feb13_004202| [ 0.52313 -0.57117  0.22682]
21Feb13_004202| [-0.84835  0.24573 -0.44370]
21Feb13_004202| [ 0.07356 -0.62497 -0.32272]
21Feb13_004202| [ 0.70192  0.43981  0.43615]
21Feb13_004202| [-0.58147 -1.09590  0.08919]
21Feb13_004202| [-0.40211 -0.70043  0.47088]
21Feb13_004202| [-0.82276  1.57835  0.07738]
21Feb13_004202| [ 1.34172  0.12865 -0.46300]
21Feb13_004202| [ 1.03792 -0.90825  0.09240]
21Feb13_004202| [-1.42926  1.89750 -0.34475]
21Feb13_004202| [ 1.02414 -0.76343 -0.36258]
21Feb13_004202| [-0.88529 -2.26835 -0.18725]
21Feb13_004202| [ 1.30364  1.13824  0.27483]
21Feb13_004202| [-0.44614 -0.47860 -0.49418]
21Feb13_004202| [-0.03176  1.60744 -0.17383]
21Feb13_004202| [ 1.08822  1.62815  0.36013]
21Feb13_004202| [-0.22818  1.19826  0.49832]
21Feb13_004202| [-0.71528 -0.51704  0.29158]
21Feb13_004202| [-0.00854 -1.77518  0.42051]
21Feb13_004202| [-0.93700 -0.26914 -0.20007]
21Feb13_004202| [ 0.00451 -0.48683 -0.48477]
21Feb13_004202| [ 0.93273 -0.19610 -0.22601]
21Feb13_004202| [-0.93976  0.14014  0.16022]
21Feb13_004202| [ 0.41300  1.39614  0.37801]
21Feb13_004202| [ 0.21004 -0.26822  0.13501]
21Feb13_004202| [ 0.14351 -0.81709 -0.11879]
21Feb13_004202| [ 0.28682 -0.71132  0.21680]
21Feb13_004202| [-1.14313 -0.39791 -0.49363]
21Feb13_004202| [-1.09534  0.74258  0.38014]
21Feb13_004202| [ 1.05762 -1.13060  0.44897]
21Feb13_004202| [-0.37677 -2.47419 -0.38946]
21Feb13_004202| [-0.73548 -0.31637  0.13582]
21Feb13_004202| [ 0.71000  0.24351 -0.03873]
21Feb13_004202| [-1.64987  0.44204  0.11190]
21Feb13_004202| [-0.21109  0.41781  0.05437]
21Feb13_004202| [ 1.64591 -1.72953 -0.32023]
21Feb13_004202| [-0.52154  0.33699 -0.04892]
21Feb13_004202| [ 0.28082 -2.11461 -0.40131]]
21Feb13_004202|-- Bias --
21Feb13_004202|[-0.83006 -0.28814 -0.41742]
21Feb13_004202|Layer 1:
21Feb13_004202|-- Config --
21Feb13_004202|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004202|-- Weights --
21Feb13_004202|[[ 0.34190  0.00494]
21Feb13_004202| [-0.03031  0.70309]
21Feb13_004202| [-0.10300 -0.31124]]
21Feb13_004202|-- Bias --
21Feb13_004202|[-1.08834  0.53538]
21Feb13_004202|Layer 2:
21Feb13_004202|-- Config --
21Feb13_004202|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004202|-- Weights --
21Feb13_004202|[[-1.43216 -0.46999]
21Feb13_004202| [-0.25570  0.29812]]
21Feb13_004202|-- Bias --
21Feb13_004202|[0.53497 0.59206]
21Feb13_004202|Layer 3:
21Feb13_004202|-- Config --
21Feb13_004202|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004202|-- Weights --
21Feb13_004202|[[ 1.26386 -0.57671  0.50937 -0.22036 -0.39070]
21Feb13_004202| [ 0.60509 -1.28500  1.18720  0.13258  0.67850]]
21Feb13_004202|-- Bias --
21Feb13_004202|[ 0.32363 -0.63931 -0.14484  0.01990  0.58968]
21Feb13_004202|Layer 4:
21Feb13_004202|-- Config --
21Feb13_004202|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004202|-- Weights --
21Feb13_004202|[[-0.22550 -0.83751 -0.16810 -0.40779 -0.29968]
21Feb13_004202| [ 0.41990  0.36976  0.32176 -0.72224 -0.36475]
21Feb13_004202| [-0.65415 -0.58004  1.27034 -1.76347  0.96539]
21Feb13_004202| [-0.04734 -0.12159 -0.27842  0.72893  1.45847]
21Feb13_004202| [-0.29575 -0.34150  1.34919  0.46565  1.37439]]
21Feb13_004202|-- Bias --
21Feb13_004202|[-0.86979  0.07658 -0.97912  0.34494  0.63525]
21Feb13_004202|Layer 5:
21Feb13_004202|-- Config --
21Feb13_004202|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004202|-- Weights --
21Feb13_004202|[[-0.69176 -0.64271]
21Feb13_004202| [-0.59285 -0.50468]
21Feb13_004202| [ 0.61725 -1.55259]
21Feb13_004202| [-0.61286 -0.40967]
21Feb13_004202| [ 0.14040 -0.58444]]
21Feb13_004202|-- Bias --
21Feb13_004202|[-0.58506 -0.05294]
21Feb13_004202|Predicting the validation and test data with the Best final individual.
21Feb13_004210| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_004210|-----------  ------------------  --------------------  ----------
21Feb13_004210|Validation         24.09                  85            0.82677
21Feb13_004210|   Test            27.72                  85            0.82999
21Feb13_004210|-------------------- Test #13 --------------------
21Feb13_004210|Best final individual weights
21Feb13_004210|Individual:
21Feb13_004210|-- Constant hidden layers --
21Feb13_004210|False
21Feb13_004210|Layer 0:
21Feb13_004210|-- Config --
21Feb13_004210|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004210|-- Weights --
21Feb13_004210|[[-1.11314  0.81946 -0.35142]
21Feb13_004210| [-0.92878 -0.89932  0.40299]
21Feb13_004210| [-1.11044 -0.59735  0.24230]
21Feb13_004210| [ 0.20891 -1.31553 -0.36469]
21Feb13_004210| [ 0.30309 -0.76165 -0.23615]
21Feb13_004210| [ 1.64964  0.04056  0.02223]
21Feb13_004210| [-0.55074 -0.75738  0.46557]
21Feb13_004210| [-1.47927 -0.69261  0.23412]
21Feb13_004210| [-1.33298  1.32978 -0.31259]
21Feb13_004210| [ 0.46752  0.11801 -0.00996]
21Feb13_004210| [ 0.81861 -0.72318 -0.19691]
21Feb13_004210| [-0.47734  1.71184 -0.33536]
21Feb13_004210| [ 0.51477  1.28368  0.35802]
21Feb13_004210| [-0.91466  1.47925 -0.08178]
21Feb13_004210| [ 1.46005  0.67436 -0.12592]
21Feb13_004210| [ 0.70720  0.36657 -0.47678]
21Feb13_004210| [-0.64331  0.43277  0.18878]
21Feb13_004210| [-0.71217 -0.37104 -0.25673]
21Feb13_004210| [ 1.56152  0.98624 -0.05791]
21Feb13_004210| [ 0.52313 -0.57117  0.22682]
21Feb13_004210| [-0.84835  0.24573 -0.44370]
21Feb13_004210| [ 0.07356 -0.62497 -0.32272]
21Feb13_004210| [ 0.70192  0.43981  0.43615]
21Feb13_004210| [-0.58147 -1.09590  0.08919]
21Feb13_004210| [-0.40211 -0.70043  0.47088]
21Feb13_004210| [-0.82276  1.57835  0.07738]
21Feb13_004210| [ 1.34172  0.12865 -0.46300]
21Feb13_004210| [ 1.03792 -0.90825  0.09240]
21Feb13_004210| [-1.42926  1.89750 -0.34475]
21Feb13_004210| [ 1.02414 -0.76343 -0.36258]
21Feb13_004210| [-0.88529 -2.26835 -0.18725]
21Feb13_004210| [ 1.30364  1.13824  0.27483]
21Feb13_004210| [-0.44614 -0.47860 -0.49418]
21Feb13_004210| [-0.03176  1.60744 -0.17383]
21Feb13_004210| [ 1.08822  1.62815  0.36013]
21Feb13_004210| [-0.22818  1.19826  0.49832]
21Feb13_004210| [-0.71528 -0.51704  0.29158]
21Feb13_004210| [-0.00854 -1.77518  0.42051]
21Feb13_004210| [-0.93700 -0.26914 -0.20007]
21Feb13_004210| [ 0.00451 -0.48683 -0.48477]
21Feb13_004210| [ 0.93273 -0.19610 -0.22601]
21Feb13_004210| [-0.93976  0.14014  0.16022]
21Feb13_004210| [ 0.41300  1.39614  0.37801]
21Feb13_004210| [ 0.21004 -0.26822  0.13501]
21Feb13_004210| [ 0.14351 -0.81709 -0.11879]
21Feb13_004210| [ 0.28682 -0.71132  0.21680]
21Feb13_004210| [-1.14313 -0.39791 -0.49363]
21Feb13_004210| [-1.09534  0.74258  0.38014]
21Feb13_004210| [ 1.05762 -1.13060  0.44897]
21Feb13_004210| [-0.37677 -2.47419 -0.38946]
21Feb13_004210| [-0.73548 -0.31637  0.13582]
21Feb13_004210| [ 0.71000  0.24351 -0.03873]
21Feb13_004210| [-1.64987  0.44204  0.11190]
21Feb13_004210| [-0.21109  0.41781  0.05437]
21Feb13_004210| [ 1.64591 -1.72953 -0.32023]
21Feb13_004210| [-0.52154  0.33699 -0.04892]
21Feb13_004210| [ 0.28082 -2.11461 -0.40131]]
21Feb13_004210|-- Bias --
21Feb13_004210|[-0.83006 -0.28814 -0.41742]
21Feb13_004210|Layer 1:
21Feb13_004210|-- Config --
21Feb13_004210|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004210|-- Weights --
21Feb13_004210|[[ 0.34190  0.00494]
21Feb13_004210| [-0.03031  0.70309]
21Feb13_004210| [-0.10300 -0.31124]]
21Feb13_004210|-- Bias --
21Feb13_004210|[-1.08834  0.53538]
21Feb13_004210|Layer 2:
21Feb13_004210|-- Config --
21Feb13_004210|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004210|-- Weights --
21Feb13_004210|[[-1.43216 -0.46999]
21Feb13_004210| [-0.25570  0.29812]]
21Feb13_004210|-- Bias --
21Feb13_004210|[0.53497 0.59206]
21Feb13_004210|Layer 3:
21Feb13_004210|-- Config --
21Feb13_004210|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004210|-- Weights --
21Feb13_004210|[[ 1.26386 -0.57671  0.50937 -0.22036 -0.39070]
21Feb13_004210| [ 0.60509 -1.28500  1.18720  0.13258  0.67850]]
21Feb13_004210|-- Bias --
21Feb13_004210|[ 0.32363 -0.63931 -0.14484  0.01990  0.58968]
21Feb13_004210|Layer 4:
21Feb13_004210|-- Config --
21Feb13_004210|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004210|-- Weights --
21Feb13_004210|[[-0.22550 -0.83751 -0.16810 -0.40779 -0.29968]
21Feb13_004210| [ 0.41990  0.36976  0.32176 -0.72224 -0.36475]
21Feb13_004210| [-0.65415 -0.58004  1.27034 -1.76347  0.96539]
21Feb13_004210| [-0.04734 -0.12159 -0.27842  0.72893  1.45847]
21Feb13_004210| [-0.29575 -0.34150  1.34919  0.46565  1.37439]]
21Feb13_004210|-- Bias --
21Feb13_004210|[-0.86979  0.07658 -0.97912  0.34494  0.63525]
21Feb13_004210|Layer 5:
21Feb13_004210|-- Config --
21Feb13_004210|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004210|-- Weights --
21Feb13_004210|[[-0.69176 -0.64271]
21Feb13_004210| [-0.59285 -0.50468]
21Feb13_004210| [ 0.61725 -1.55259]
21Feb13_004210| [-0.61286 -0.40967]
21Feb13_004210| [ 0.14040 -0.58444]]
21Feb13_004210|-- Bias --
21Feb13_004210|[-0.58506 -0.05294]
21Feb13_004210|Predicting the validation and test data with the Best final individual.
21Feb13_004218| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_004218|-----------  ------------------  --------------------  ----------
21Feb13_004218|Validation         28.26                  85            0.78273
21Feb13_004218|   Test            21.72                  85            0.71684
21Feb13_004218|-------------------- Test #14 --------------------
21Feb13_004218|Best final individual weights
21Feb13_004218|Individual:
21Feb13_004218|-- Constant hidden layers --
21Feb13_004218|False
21Feb13_004218|Layer 0:
21Feb13_004218|-- Config --
21Feb13_004218|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004218|-- Weights --
21Feb13_004218|[[-1.11314  0.81946 -0.35142]
21Feb13_004218| [-0.92878 -0.89932  0.40299]
21Feb13_004218| [-1.11044 -0.59735  0.24230]
21Feb13_004218| [ 0.20891 -1.31553 -0.36469]
21Feb13_004218| [ 0.30309 -0.76165 -0.23615]
21Feb13_004218| [ 1.64964  0.04056  0.02223]
21Feb13_004218| [-0.55074 -0.75738  0.46557]
21Feb13_004218| [-1.47927 -0.69261  0.23412]
21Feb13_004218| [-1.33298  1.32978 -0.31259]
21Feb13_004218| [ 0.46752  0.11801 -0.00996]
21Feb13_004218| [ 0.81861 -0.72318 -0.19691]
21Feb13_004218| [-0.47734  1.71184 -0.33536]
21Feb13_004218| [ 0.51477  1.28368  0.35802]
21Feb13_004218| [-0.91466  1.47925 -0.08178]
21Feb13_004218| [ 1.46005  0.67436 -0.12592]
21Feb13_004218| [ 0.70720  0.36657 -0.47678]
21Feb13_004218| [-0.64331  0.43277  0.18878]
21Feb13_004218| [-0.71217 -0.37104 -0.25673]
21Feb13_004218| [ 1.56152  0.98624 -0.05791]
21Feb13_004218| [ 0.52313 -0.57117  0.22682]
21Feb13_004218| [-0.84835  0.24573 -0.44370]
21Feb13_004218| [ 0.07356 -0.62497 -0.32272]
21Feb13_004218| [ 0.70192  0.43981  0.43615]
21Feb13_004218| [-0.58147 -1.09590  0.08919]
21Feb13_004218| [-0.40211 -0.70043  0.47088]
21Feb13_004218| [-0.82276  1.57835  0.07738]
21Feb13_004218| [ 1.34172  0.12865 -0.46300]
21Feb13_004218| [ 1.03792 -0.90825  0.09240]
21Feb13_004218| [-1.42926  1.89750 -0.34475]
21Feb13_004218| [ 1.02414 -0.76343 -0.36258]
21Feb13_004218| [-0.88529 -2.26835 -0.18725]
21Feb13_004218| [ 1.30364  1.13824  0.27483]
21Feb13_004218| [-0.44614 -0.47860 -0.49418]
21Feb13_004218| [-0.03176  1.60744 -0.17383]
21Feb13_004218| [ 1.08822  1.62815  0.36013]
21Feb13_004218| [-0.22818  1.19826  0.49832]
21Feb13_004218| [-0.71528 -0.51704  0.29158]
21Feb13_004218| [-0.00854 -1.77518  0.42051]
21Feb13_004218| [-0.93700 -0.26914 -0.20007]
21Feb13_004218| [ 0.00451 -0.48683 -0.48477]
21Feb13_004218| [ 0.93273 -0.19610 -0.22601]
21Feb13_004218| [-0.93976  0.14014  0.16022]
21Feb13_004218| [ 0.41300  1.39614  0.37801]
21Feb13_004218| [ 0.21004 -0.26822  0.13501]
21Feb13_004218| [ 0.14351 -0.81709 -0.11879]
21Feb13_004218| [ 0.28682 -0.71132  0.21680]
21Feb13_004218| [-1.14313 -0.39791 -0.49363]
21Feb13_004218| [-1.09534  0.74258  0.38014]
21Feb13_004218| [ 1.05762 -1.13060  0.44897]
21Feb13_004218| [-0.37677 -2.47419 -0.38946]
21Feb13_004218| [-0.73548 -0.31637  0.13582]
21Feb13_004218| [ 0.71000  0.24351 -0.03873]
21Feb13_004218| [-1.64987  0.44204  0.11190]
21Feb13_004218| [-0.21109  0.41781  0.05437]
21Feb13_004218| [ 1.64591 -1.72953 -0.32023]
21Feb13_004218| [-0.52154  0.33699 -0.04892]
21Feb13_004218| [ 0.28082 -2.11461 -0.40131]]
21Feb13_004218|-- Bias --
21Feb13_004218|[-0.83006 -0.28814 -0.41742]
21Feb13_004218|Layer 1:
21Feb13_004218|-- Config --
21Feb13_004218|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004218|-- Weights --
21Feb13_004218|[[ 0.34190  0.00494]
21Feb13_004218| [-0.03031  0.70309]
21Feb13_004218| [-0.10300 -0.31124]]
21Feb13_004218|-- Bias --
21Feb13_004218|[-1.08834  0.53538]
21Feb13_004218|Layer 2:
21Feb13_004218|-- Config --
21Feb13_004218|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004218|-- Weights --
21Feb13_004218|[[-1.43216 -0.46999]
21Feb13_004218| [-0.25570  0.29812]]
21Feb13_004218|-- Bias --
21Feb13_004218|[0.53497 0.59206]
21Feb13_004218|Layer 3:
21Feb13_004218|-- Config --
21Feb13_004218|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004218|-- Weights --
21Feb13_004218|[[ 1.26386 -0.57671  0.50937 -0.22036 -0.39070]
21Feb13_004218| [ 0.60509 -1.28500  1.18720  0.13258  0.67850]]
21Feb13_004218|-- Bias --
21Feb13_004218|[ 0.32363 -0.63931 -0.14484  0.01990  0.58968]
21Feb13_004218|Layer 4:
21Feb13_004218|-- Config --
21Feb13_004218|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004218|-- Weights --
21Feb13_004218|[[-0.22550 -0.83751 -0.16810 -0.40779 -0.29968]
21Feb13_004218| [ 0.41990  0.36976  0.32176 -0.72224 -0.36475]
21Feb13_004218| [-0.65415 -0.58004  1.27034 -1.76347  0.96539]
21Feb13_004218| [-0.04734 -0.12159 -0.27842  0.72893  1.45847]
21Feb13_004218| [-0.29575 -0.34150  1.34919  0.46565  1.37439]]
21Feb13_004218|-- Bias --
21Feb13_004218|[-0.86979  0.07658 -0.97912  0.34494  0.63525]
21Feb13_004218|Layer 5:
21Feb13_004218|-- Config --
21Feb13_004218|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_004218|-- Weights --
21Feb13_004218|[[-0.69176 -0.64271]
21Feb13_004218| [-0.59285 -0.50468]
21Feb13_004218| [ 0.61725 -1.55259]
21Feb13_004218| [-0.61286 -0.40967]
21Feb13_004218| [ 0.14040 -0.58444]]
21Feb13_004218|-- Bias --
21Feb13_004218|[-0.58506 -0.05294]
21Feb13_004218|Predicting the validation and test data with the Best final individual.
21Feb13_004227| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_004227|-----------  ------------------  --------------------  ----------
21Feb13_004227|Validation         38.78                  85            0.00000
21Feb13_004227|   Test            29.45                  85            0.75970
2021-02-13 00:42:28.148440: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
21Feb13_004228|Data summary: Train
21Feb13_004228|data.shape = (2300, 57)
21Feb13_004228|labels.shape = (2300,)
21Feb13_004228|Class distribution:
21Feb13_004228|	0 - 1382 (0.60)
21Feb13_004228|	1 - 918 (0.40)
21Feb13_004228|Data summary: Validation
21Feb13_004228|data.shape = (1150, 57)
21Feb13_004228|labels.shape = (1150,)
21Feb13_004228|Class distribution:
21Feb13_004228|	0 - 704 (0.61)
21Feb13_004228|	1 - 446 (0.39)
21Feb13_004228|Data summary: Test
21Feb13_004228|data.shape = (1151, 57)
21Feb13_004228|labels.shape = (1151,)
21Feb13_004228|Class distribution:
21Feb13_004228|	0 - 702 (0.61)
21Feb13_004228|	1 - 449 (0.39)
21Feb13_004228|Selected configuration values
21Feb13_004228|-- Dataset name: spambase1
21Feb13_004228|-- Initial population size: 64
21Feb13_004228|-- Maximun number of generations: 32
21Feb13_004228|-- Neurons per hidden layer range: (2, 20)
21Feb13_004228|-- Hidden layers number range: (1, 3)
21Feb13_004228|-- Crossover probability: 0.5
21Feb13_004228|-- Bias gene mutation probability: 0.2
21Feb13_004228|-- Weights gene mutation probability: 0.75
21Feb13_004228|-- Neuron mutation probability: 0.3
21Feb13_004228|-- Layer mutation probability: 0.3
21Feb13_004228|-- Constant hidden layers: False
21Feb13_004228|-- Seed: 31415
21Feb13_004228|Entering GA
21Feb13_004228|Start the algorithm
2021-02-13 00:42:28.999876: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-13 00:42:29.000423: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-02-13 00:42:29.022974: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-13 00:42:29.023302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.71GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s
2021-02-13 00:42:29.023318: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-02-13 00:42:29.024774: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-02-13 00:42:29.024802: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-02-13 00:42:29.025293: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-02-13 00:42:29.025431: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-02-13 00:42:29.025501: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-13 00:42:29.025905: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-02-13 00:42:29.025947: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-13 00:42:29.025953: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-02-13 00:42:29.026173: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-02-13 00:42:29.026932: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-13 00:42:29.026945: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-13 00:42:29.026956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      
2021-02-13 00:42:29.072498: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-02-13 00:42:29.072812: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3493635000 Hz
/home/jmerelo/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype("int32")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn('`model.predict_classes()` is deprecated and '
21Feb13_004632|-- Generation 1 --
21Feb13_004632|    -- Crossed 1 individual pairs.
21Feb13_004632|    -- Mutated 32 individuals.
21Feb13_005035|    -- Evaluated 64 individuals.
21Feb13_005035|    Summary of generation 1:
21Feb13_005035| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_005035|-----------  ------------------  --------------------  ----------
21Feb13_005035|    Max            39.22                153.00          0.30602
21Feb13_005035|    Avg            38.71                52.31           0.00517
21Feb13_005035|    Min            30.78                 3.00           0.00000
21Feb13_005035|    Std             1.01                44.47           0.03798
21Feb13_005035|   Best            30.78                18.00           0.30602
21Feb13_005035|-- Generation 2 --
21Feb13_005035|    -- Crossed 0 individual pairs.
21Feb13_005035|    -- Mutated 32 individuals.
21Feb13_005436|    -- Evaluated 64 individuals.
21Feb13_005436|    Summary of generation 2:
21Feb13_005436| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_005436|-----------  ------------------  --------------------  ----------
21Feb13_005436|    Max            39.30                96.00           0.07928
21Feb13_005436|    Avg            38.83                31.52           0.00180
21Feb13_005436|    Min            37.65                 3.00           0.00000
21Feb13_005436|    Std             0.20                26.36           0.01073
21Feb13_005436|   Best            37.65                14.00           0.07928
21Feb13_005436|-- Generation 3 --
21Feb13_005436|    -- Crossed 4 individual pairs.
21Feb13_005436|    -- Mutated 32 individuals.
21Feb13_005834|    -- Evaluated 64 individuals.
21Feb13_005834|    Summary of generation 3:
21Feb13_005834| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_005834|-----------  ------------------  --------------------  ----------
21Feb13_005834|    Max            39.30                63.00           0.56188
21Feb13_005834|    Avg            38.62                21.45           0.00982
21Feb13_005834|    Min            25.83                 2.00           0.00000
21Feb13_005834|    Std             1.62                15.66           0.06979
21Feb13_005834|   Best            25.83                24.00           0.56188
21Feb13_005834|-- Generation 4 --
21Feb13_005834|    -- Crossed 2 individual pairs.
21Feb13_005834|    -- Mutated 32 individuals.
21Feb13_010229|    -- Evaluated 64 individuals.
21Feb13_010229|    Summary of generation 4:
21Feb13_010229| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_010229|-----------  ------------------  --------------------  ----------
21Feb13_010229|    Max            39.13                51.00           0.01118
21Feb13_010229|    Avg            38.81                12.56           0.00017
21Feb13_010229|    Min            38.52                 2.00           0.00000
21Feb13_010229|    Std             0.09                 9.48           0.00139
21Feb13_010229|   Best            38.52                12.00           0.01118
21Feb13_010229|-- Generation 5 --
21Feb13_010229|    -- Crossed 1 individual pairs.
21Feb13_010229|    -- Mutated 32 individuals.
21Feb13_010620|    -- Evaluated 64 individuals.
21Feb13_010620|    Summary of generation 5:
21Feb13_010620| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_010620|-----------  ------------------  --------------------  ----------
21Feb13_010620|    Max            39.04                27.00           0.64516
21Feb13_010620|    Avg            38.35                 7.42           0.02774
21Feb13_010620|    Min            25.39                 2.00           0.00000
21Feb13_010620|    Std             2.23                 4.90           0.12533
21Feb13_010620|   Best            25.39                10.00           0.60289
21Feb13_010620|-- Generation 6 --
21Feb13_010620|    -- Crossed 5 individual pairs.
21Feb13_010620|    -- Mutated 32 individuals.
21Feb13_011011|    -- Evaluated 64 individuals.
21Feb13_011011|    Summary of generation 6:
21Feb13_011011| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_011011|-----------  ------------------  --------------------  ----------
21Feb13_011011|    Max            39.13                24.00           0.80055
21Feb13_011011|    Avg            38.32                 7.31           0.03014
21Feb13_011011|    Min            24.43                 2.00           0.00000
21Feb13_011011|    Std             2.43                 5.66           0.13814
21Feb13_011011|   Best            24.43                10.00           0.59529
21Feb13_011011|-- Generation 7 --
21Feb13_011011|    -- Crossed 9 individual pairs.
21Feb13_011011|    -- Mutated 32 individuals.
21Feb13_011401|    -- Evaluated 64 individuals.
21Feb13_011401|    Summary of generation 7:
21Feb13_011401| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_011401|-----------  ------------------  --------------------  ----------
21Feb13_011401|    Max            39.04                24.00           0.51816
21Feb13_011401|    Avg            38.47                 5.77           0.01295
21Feb13_011401|    Min            26.00                 2.00           0.00000
21Feb13_011401|    Std             1.70                 4.95           0.06787
21Feb13_011401|   Best            26.00                24.00           0.51816
21Feb13_011401|-- Generation 8 --
21Feb13_011401|    -- Crossed 9 individual pairs.
21Feb13_011401|    -- Mutated 32 individuals.
21Feb13_011750|    -- Evaluated 64 individuals.
21Feb13_011750|    Summary of generation 8:
21Feb13_011750| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_011750|-----------  ------------------  --------------------  ----------
21Feb13_011750|    Max            39.22                24.00           0.55926
21Feb13_011750|    Avg            38.40                 5.05           0.01656
21Feb13_011750|    Min            25.39                 2.00           0.00000
21Feb13_011750|    Std             2.33                 5.12           0.09234
21Feb13_011750|   Best            25.39                18.00           0.50049
21Feb13_011750|-- Generation 9 --
21Feb13_011750|    -- Crossed 9 individual pairs.
21Feb13_011750|    -- Mutated 32 individuals.
21Feb13_012140|    -- Evaluated 64 individuals.
21Feb13_012140|    Summary of generation 9:
21Feb13_012140| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_012140|-----------  ------------------  --------------------  ----------
21Feb13_012140|    Max            39.13                24.00           0.68514
21Feb13_012140|    Avg            38.37                 5.50           0.01978
21Feb13_012140|    Min            24.70                 2.00           0.00000
21Feb13_012140|    Std             2.34                 5.72           0.10595
21Feb13_012140|   Best            24.70                12.00           0.52002
21Feb13_012140|-- Generation 10 --
21Feb13_012140|    -- Crossed 8 individual pairs.
21Feb13_012140|    -- Mutated 32 individuals.
21Feb13_012529|    -- Evaluated 64 individuals.
21Feb13_012529|    Summary of generation 10:
21Feb13_012529| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_012529|-----------  ------------------  --------------------  ----------
21Feb13_012529|    Max            38.96                18.00           0.76556
21Feb13_012529|    Avg            38.25                 4.38           0.02747
21Feb13_012529|    Min            26.26                 2.00           0.00000
21Feb13_012529|    Std             2.46                 4.39           0.12508
21Feb13_012529|   Best            26.26                10.00           0.51357
21Feb13_012529|-- Generation 11 --
21Feb13_012529|    -- Crossed 9 individual pairs.
21Feb13_012529|    -- Mutated 32 individuals.
21Feb13_012919|    -- Evaluated 64 individuals.
21Feb13_012919|    Summary of generation 11:
21Feb13_012919| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_012919|-----------  ------------------  --------------------  ----------
21Feb13_012919|    Max            39.83                30.00           0.59251
21Feb13_012919|    Avg            37.93                 4.83           0.03466
21Feb13_012919|    Min            24.87                 2.00           0.00000
21Feb13_012919|    Std             3.18                 5.27           0.12491
21Feb13_012919|   Best            24.87                10.00           0.58491
21Feb13_012919|-- Generation 12 --
21Feb13_012919|    -- Crossed 7 individual pairs.
21Feb13_012919|    -- Mutated 32 individuals.
21Feb13_013309|    -- Evaluated 64 individuals.
21Feb13_013309|    Summary of generation 12:
21Feb13_013309| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_013309|-----------  ------------------  --------------------  ----------
21Feb13_013309|    Max            39.22                16.00           0.50293
21Feb13_013309|    Avg            38.40                 4.16           0.01510
21Feb13_013309|    Min            25.91                 2.00           0.00000
21Feb13_013309|    Std             2.18                 3.92           0.08075
21Feb13_013309|   Best            25.91                12.00           0.50293
21Feb13_013309|-- Generation 13 --
21Feb13_013309|    -- Crossed 6 individual pairs.
21Feb13_013309|    -- Mutated 32 individuals.
21Feb13_013657|    -- Evaluated 64 individuals.
21Feb13_013657|    Summary of generation 13:
21Feb13_013657| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_013657|-----------  ------------------  --------------------  ----------
21Feb13_013657|    Max            39.39                16.00           0.33178
21Feb13_013657|    Avg            38.52                 3.66           0.01013
21Feb13_013657|    Min            29.13                 2.00           0.00000
21Feb13_013657|    Std             1.60                 3.52           0.05523
21Feb13_013657|   Best            29.13                12.00           0.33178
21Feb13_013657|-- Generation 14 --
21Feb13_013657|    -- Crossed 6 individual pairs.
21Feb13_013657|    -- Mutated 32 individuals.
21Feb13_014047|    -- Evaluated 64 individuals.
21Feb13_014047|    Summary of generation 14:
21Feb13_014047| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_014047|-----------  ------------------  --------------------  ----------
21Feb13_014047|    Max            38.96                16.00           0.62130
21Feb13_014047|    Avg            38.05                 4.00           0.03019
21Feb13_014047|    Min            25.04                 2.00           0.00000
21Feb13_014047|    Std             2.90                 3.91           0.12122
21Feb13_014047|   Best            25.04                10.00           0.55874
21Feb13_014047|-- Generation 15 --
21Feb13_014047|    -- Crossed 9 individual pairs.
21Feb13_014047|    -- Mutated 32 individuals.
21Feb13_014438|    -- Evaluated 64 individuals.
21Feb13_014438|    Summary of generation 15:
21Feb13_014438| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_014438|-----------  ------------------  --------------------  ----------
21Feb13_014438|    Max            39.13                27.00           0.29519
21Feb13_014438|    Avg            38.67                 5.11           0.00483
21Feb13_014438|    Min            30.43                 2.00           0.00000
21Feb13_014438|    Std             1.04                 5.44           0.03662
21Feb13_014438|   Best            30.43                12.00           0.29519
21Feb13_014438|-- Generation 16 --
21Feb13_014438|    -- Crossed 7 individual pairs.
21Feb13_014438|    -- Mutated 32 individuals.
21Feb13_014827|    -- Evaluated 64 individuals.
21Feb13_014827|    Summary of generation 16:
21Feb13_014827| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_014827|-----------  ------------------  --------------------  ----------
21Feb13_014827|    Max            38.87                14.00           0.72174
21Feb13_014827|    Avg            38.41                 4.09           0.01763
21Feb13_014827|    Min            25.91                 2.00           0.00000
21Feb13_014827|    Std             2.05                 3.91           0.10025
21Feb13_014827|   Best            25.91                14.00           0.72174
21Feb13_014827|-- Generation 17 --
21Feb13_014827|    -- Crossed 6 individual pairs.
21Feb13_014827|    -- Mutated 32 individuals.
21Feb13_015216|    -- Evaluated 64 individuals.
21Feb13_015216|    Summary of generation 17:
21Feb13_015216| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_015216|-----------  ------------------  --------------------  ----------
21Feb13_015216|    Max            39.04                16.00           0.56084
21Feb13_015216|    Avg            38.59                 3.81           0.00876
21Feb13_015216|    Min            25.57                 2.00           0.00000
21Feb13_015216|    Std             1.64                 4.01           0.06955
21Feb13_015216|   Best            25.57                12.00           0.56084
21Feb13_015216|-- Generation 18 --
21Feb13_015216|    -- Crossed 6 individual pairs.
21Feb13_015216|    -- Mutated 32 individuals.
21Feb13_015605|    -- Evaluated 64 individuals.
21Feb13_015605|    Summary of generation 18:
21Feb13_015605| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_015605|-----------  ------------------  --------------------  ----------
21Feb13_015605|    Max            39.39                21.00           0.52326
21Feb13_015605|    Avg            38.41                 3.69           0.01474
21Feb13_015605|    Min            25.57                 2.00           0.00000
21Feb13_015605|    Std             2.21                 3.98           0.08255
21Feb13_015605|   Best            25.57                21.00           0.52326
21Feb13_015605|-- Generation 19 --
21Feb13_015605|    -- Crossed 5 individual pairs.
21Feb13_015605|    -- Mutated 32 individuals.
21Feb13_015954|    -- Evaluated 64 individuals.
21Feb13_015954|    Summary of generation 19:
21Feb13_015954| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_015954|-----------  ------------------  --------------------  ----------
21Feb13_015954|    Max            39.04                21.00           0.55529
21Feb13_015954|    Avg            38.44                 3.81           0.01378
21Feb13_015954|    Min            25.57                 2.00           0.00000
21Feb13_015954|    Std             2.01                 4.11           0.07936
21Feb13_015954|   Best            25.57                12.00           0.55529
21Feb13_015954|-- Generation 20 --
21Feb13_015954|    -- Crossed 7 individual pairs.
21Feb13_015954|    -- Mutated 32 individuals.
21Feb13_020343|    -- Evaluated 64 individuals.
21Feb13_020343|    Summary of generation 20:
21Feb13_020343| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_020343|-----------  ------------------  --------------------  ----------
21Feb13_020343|    Max            38.87                14.00           0.53151
21Feb13_020343|    Avg            38.21                 3.73           0.02226
21Feb13_020343|    Min            25.39                 2.00           0.00000
21Feb13_020343|    Std             2.63                 3.80           0.10100
21Feb13_020343|   Best            25.39                12.00           0.48666
21Feb13_020343|-- Generation 21 --
21Feb13_020343|    -- Crossed 8 individual pairs.
21Feb13_020343|    -- Mutated 32 individuals.
21Feb13_020732|    -- Evaluated 64 individuals.
21Feb13_020732|    Summary of generation 21:
21Feb13_020732| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_020732|-----------  ------------------  --------------------  ----------
21Feb13_020732|    Max            39.04                14.00           0.58727
21Feb13_020732|    Avg            38.20                 4.03           0.02501
21Feb13_020732|    Min            25.22                 2.00           0.00000
21Feb13_020732|    Std             2.70                 3.83           0.11328
21Feb13_020732|   Best            25.22                12.00           0.54515
21Feb13_020732|-- Generation 22 --
21Feb13_020732|    -- Crossed 9 individual pairs.
21Feb13_020732|    -- Mutated 32 individuals.
21Feb13_021123|    -- Evaluated 64 individuals.
21Feb13_021123|    Summary of generation 22:
21Feb13_021123| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_021123|-----------  ------------------  --------------------  ----------
21Feb13_021123|    Max            38.96                14.00           0.52326
21Feb13_021123|    Avg            37.76                 4.06           0.03931
21Feb13_021123|    Min            24.87                 2.00           0.00000
21Feb13_021123|    Std             3.53                 3.85           0.13511
21Feb13_021123|   Best            24.87                12.00           0.49803
21Feb13_021123|-- Generation 23 --
21Feb13_021123|    -- Crossed 5 individual pairs.
21Feb13_021123|    -- Mutated 32 individuals.
21Feb13_021513|    -- Evaluated 64 individuals.
21Feb13_021513|    Summary of generation 23:
21Feb13_021513| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_021513|-----------  ------------------  --------------------  ----------
21Feb13_021513|    Max            40.26                16.00           0.58588
21Feb13_021513|    Avg            37.98                 5.22           0.03356
21Feb13_021513|    Min            25.13                 2.00           0.00000
21Feb13_021513|    Std             3.06                 4.96           0.11938
21Feb13_021513|   Best            25.13                10.00           0.58588
21Feb13_021513|-- Generation 24 --
21Feb13_021513|    -- Crossed 6 individual pairs.
21Feb13_021513|    -- Mutated 32 individuals.
21Feb13_021904|    -- Evaluated 64 individuals.
21Feb13_021904|    Summary of generation 24:
21Feb13_021904| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_021904|-----------  ------------------  --------------------  ----------
21Feb13_021904|    Max            39.13                14.00           0.60437
21Feb13_021904|    Avg            37.24                 4.69           0.06125
21Feb13_021904|    Min            25.22                 2.00           0.00000
21Feb13_021904|    Std             4.14                 4.37           0.16471
21Feb13_021904|   Best            25.22                12.00           0.55449
21Feb13_021904|-- Generation 25 --
21Feb13_021904|    -- Crossed 8 individual pairs.
21Feb13_021904|    -- Mutated 32 individuals.
21Feb13_022255|    -- Evaluated 64 individuals.
21Feb13_022255|    Summary of generation 25:
21Feb13_022255| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_022255|-----------  ------------------  --------------------  ----------
21Feb13_022255|    Max            38.96                16.00           0.53931
21Feb13_022255|    Avg            37.62                 5.25           0.04291
21Feb13_022255|    Min            24.70                 2.00           0.00000
21Feb13_022255|    Std             3.67                 4.62           0.13543
21Feb13_022255|   Best            24.70                12.00           0.52195
21Feb13_022255|-- Generation 26 --
21Feb13_022255|    -- Crossed 5 individual pairs.
21Feb13_022255|    -- Mutated 32 individuals.
21Feb13_022647|    -- Evaluated 64 individuals.
21Feb13_022647|    Summary of generation 26:
21Feb13_022647| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_022647|-----------  ------------------  --------------------  ----------
21Feb13_022647|    Max            39.57                36.00           0.54893
21Feb13_022647|    Avg            37.32                 5.70           0.05565
21Feb13_022647|    Min            24.96                 2.00           0.00000
21Feb13_022647|    Std             4.02                 6.50           0.14974
21Feb13_022647|   Best            24.96                12.00           0.51345
21Feb13_022647|-- Generation 27 --
21Feb13_022647|    -- Crossed 7 individual pairs.
21Feb13_022647|    -- Mutated 32 individuals.
21Feb13_023038|    -- Evaluated 64 individuals.
21Feb13_023038|    Summary of generation 27:
21Feb13_023038| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_023038|-----------  ------------------  --------------------  ----------
21Feb13_023038|    Max            39.39                33.00           0.63341
21Feb13_023038|    Avg            36.43                 6.00           0.09028
21Feb13_023038|    Min            23.57                 2.00           0.00000
21Feb13_023038|    Std             4.97                 6.29           0.19070
21Feb13_023038|   Best            23.57                27.00           0.63341
21Feb13_023038|-- Generation 28 --
21Feb13_023038|    -- Crossed 5 individual pairs.
21Feb13_023038|    -- Mutated 32 individuals.
21Feb13_023431|    -- Evaluated 64 individuals.
21Feb13_023431|    Summary of generation 28:
21Feb13_023431| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_023431|-----------  ------------------  --------------------  ----------
21Feb13_023431|    Max            39.13                33.00           0.56872
21Feb13_023431|    Avg            36.35                 8.16           0.09259
21Feb13_023431|    Min            24.70                 2.00           0.00000
21Feb13_023431|    Std             4.90                 8.44           0.18686
21Feb13_023431|   Best            24.70                12.00           0.52772
21Feb13_023431|-- Generation 29 --
21Feb13_023431|    -- Crossed 6 individual pairs.
21Feb13_023431|    -- Mutated 32 individuals.
21Feb13_023824|    -- Evaluated 64 individuals.
21Feb13_023824|    Summary of generation 29:
21Feb13_023824| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_023824|-----------  ------------------  --------------------  ----------
21Feb13_023824|    Max            39.22                48.00           0.68151
21Feb13_023824|    Avg            35.53                 9.14           0.12394
21Feb13_023824|    Min            24.00                 2.00           0.00000
21Feb13_023824|    Std             5.54                10.65           0.21432
21Feb13_023824|   Best            24.00                27.00           0.58222
21Feb13_023824|-- Generation 30 --
21Feb13_023824|    -- Crossed 3 individual pairs.
21Feb13_023824|    -- Mutated 32 individuals.
21Feb13_024219|    -- Evaluated 64 individuals.
21Feb13_024219|    Summary of generation 30:
21Feb13_024219| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_024219|-----------  ------------------  --------------------  ----------
21Feb13_024219|    Max            38.96                52.00           0.57855
21Feb13_024219|    Avg            35.60                11.44           0.12233
21Feb13_024219|    Min            24.78                 2.00           0.00000
21Feb13_024219|    Std             5.36                10.79           0.20751
21Feb13_024219|   Best            24.78                12.00           0.50614
21Feb13_024219|-- Generation 31 --
21Feb13_024219|    -- Crossed 3 individual pairs.
21Feb13_024219|    -- Mutated 32 individuals.
21Feb13_024615|    -- Evaluated 64 individuals.
21Feb13_024615|    Summary of generation 31:
21Feb13_024615| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_024615|-----------  ------------------  --------------------  ----------
21Feb13_024615|    Max            39.04                30.00           0.78331
21Feb13_024615|    Avg            34.33                10.86           0.18128
21Feb13_024615|    Min            24.26                 2.00           0.00000
21Feb13_024615|    Std             6.02                 8.72           0.24888
21Feb13_024615|   Best            24.26                27.00           0.51546
21Feb13_024615|-- Generation 32 --
21Feb13_024615|    -- Crossed 4 individual pairs.
21Feb13_024615|    -- Mutated 32 individuals.
21Feb13_025012|    -- Evaluated 64 individuals.
21Feb13_025012|    Summary of generation 32:
21Feb13_025012| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_025012|-----------  ------------------  --------------------  ----------
21Feb13_025012|    Max            38.87                33.00           0.75377
21Feb13_025012|    Avg            33.20                13.72           0.22221
21Feb13_025012|    Min            24.96                 2.00           0.00000
21Feb13_025012|    Std             6.02                 9.89           0.24582
21Feb13_025012|   Best            24.96                12.00           0.53649
21Feb13_025012|Best initial individual weights
21Feb13_025012|Individual:
21Feb13_025012|-- Constant hidden layers --
21Feb13_025012|False
21Feb13_025012|Layer 0:
21Feb13_025012|-- Config --
21Feb13_025012|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 20, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025012|-- Weights --
21Feb13_025012|[[-0.81530 -0.38125 -0.79998 ... -0.70263 -0.61840  0.66571]
21Feb13_025012| [ 0.65866  0.85470 -0.58802 ... -0.96520  0.62924 -0.99993]
21Feb13_025012| [ 0.82861 -0.31058 -0.15077 ... -0.37206  0.28605  0.29356]
21Feb13_025012| ...
21Feb13_025012| [-0.22356 -0.17240 -0.31428 ... -0.22545  0.94699 -0.71943]
21Feb13_025012| [-0.37773 -0.75933 -0.69490 ... -0.90595 -0.69780 -0.98315]
21Feb13_025012| [ 0.65818 -0.25813 -0.28240 ...  0.35891  0.55911  0.45607]]
21Feb13_025012|-- Bias --
21Feb13_025012|[-0.66607 -0.45412 -0.47565  0.95426  0.37266  0.71643 -0.83233 -0.59141
21Feb13_025012| -0.57925 -0.35895  0.07388  0.17038  0.31672  0.81171  0.30057  0.54611
21Feb13_025012| -0.62651  0.24482  0.64224 -0.28752]
21Feb13_025012|Layer 1:
21Feb13_025012|-- Config --
21Feb13_025012|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 20], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025012|-- Weights --
21Feb13_025012|[[ 0.42040 -0.26492]
21Feb13_025012| [ 0.78679  0.01829]
21Feb13_025012| [ 0.85426  0.35026]
21Feb13_025012| [ 0.63200 -0.62249]
21Feb13_025012| [-0.55346 -0.80586]
21Feb13_025012| [-0.61224  0.86991]
21Feb13_025012| [-0.47486 -0.31648]
21Feb13_025012| [ 0.53818 -0.22812]
21Feb13_025012| [-0.74035 -0.70516]
21Feb13_025012| [-0.47742 -0.04703]
21Feb13_025012| [ 0.68440 -0.93557]
21Feb13_025012| [-0.18841 -0.56741]
21Feb13_025012| [-0.08233  0.51743]
21Feb13_025012| [ 0.43051 -0.46386]
21Feb13_025012| [ 0.67964  0.15665]
21Feb13_025012| [-0.10319 -0.36290]
21Feb13_025012| [-0.23955  0.64790]
21Feb13_025012| [-0.84563 -0.92413]
21Feb13_025012| [ 0.53642 -0.52099]
21Feb13_025012| [ 0.03906 -0.94604]]
21Feb13_025012|-- Bias --
21Feb13_025012|[ 0.50157 -0.93861]
21Feb13_025012|Predicting the validation and test data with the Best initial individual.
21Feb13_025019| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_025019|-----------  ------------------  --------------------  ----------
21Feb13_025019|Validation         38.78                  20            0.00000
21Feb13_025019|   Test            39.10                  20            0.00555
21Feb13_025019|-------------------- Test #0 --------------------
21Feb13_025019|Best final individual weights
21Feb13_025019|Individual:
21Feb13_025019|-- Constant hidden layers --
21Feb13_025019|False
21Feb13_025019|Layer 0:
21Feb13_025019|-- Config --
21Feb13_025019|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025019|-- Weights --
21Feb13_025019|[[-1.69863e+00  5.36868e-01]
21Feb13_025019| [-1.00087e+00 -2.03837e-01]
21Feb13_025019| [-7.82016e-02 -7.26166e-01]
21Feb13_025019| [ 1.09103e-02 -6.64981e-01]
21Feb13_025019| [ 2.61865e-01  1.47874e-01]
21Feb13_025019| [-1.54004e+00 -5.66954e-01]
21Feb13_025019| [-4.36773e-01 -3.87884e-01]
21Feb13_025019| [-3.23971e-01  2.30940e-01]
21Feb13_025019| [ 7.99649e-02  6.22738e-01]
21Feb13_025019| [ 7.41012e-02  3.78434e-01]
21Feb13_025019| [ 4.43657e-01 -2.95091e-01]
21Feb13_025019| [ 1.33195e+00 -3.78631e-01]
21Feb13_025019| [ 9.30112e-01 -1.26126e-01]
21Feb13_025019| [-2.33344e-01  1.72973e-01]
21Feb13_025019| [ 3.16964e-01 -1.95748e+00]
21Feb13_025019| [ 3.66377e-01 -5.84277e-01]
21Feb13_025019| [-9.86139e-01  1.19007e+00]
21Feb13_025019| [-4.06848e-01 -4.14488e-01]
21Feb13_025019| [ 1.22713e-01 -1.42885e-01]
21Feb13_025019| [-6.54057e-01 -8.02956e-01]
21Feb13_025019| [-8.03754e-01  7.47773e-01]
21Feb13_025019| [ 6.51358e-01 -8.13541e-01]
21Feb13_025019| [-1.51428e+00  5.23355e-01]
21Feb13_025019| [-4.32524e-01 -4.36951e-01]
21Feb13_025019| [-1.01652e+00  4.23838e-01]
21Feb13_025019| [ 6.33385e-01  1.47670e+00]
21Feb13_025019| [ 9.44616e-01  7.04149e-01]
21Feb13_025019| [ 2.28886e+00 -1.08929e-01]
21Feb13_025019| [-7.17545e-01  1.10507e+00]
21Feb13_025019| [ 1.18270e-01 -2.13651e-01]
21Feb13_025019| [-3.60633e-01 -8.12025e-01]
21Feb13_025019| [-4.90572e-01  9.26284e-01]
21Feb13_025019| [-6.79514e-01  1.86582e-02]
21Feb13_025019| [-1.04325e+00  6.61269e-01]
21Feb13_025019| [ 1.20725e+00  1.54115e-01]
21Feb13_025019| [-7.02012e-01  1.69880e+00]
21Feb13_025019| [-1.11488e+00 -2.01392e-01]
21Feb13_025019| [ 3.27278e-01 -6.50259e-02]
21Feb13_025019| [-6.20830e-01 -4.76016e-01]
21Feb13_025019| [-2.44251e-02  1.80081e-01]
21Feb13_025019| [ 1.08468e+00 -1.08729e+00]
21Feb13_025019| [-9.04160e-01 -4.80164e-01]
21Feb13_025019| [ 3.01454e-02 -1.07113e+00]
21Feb13_025019| [ 2.19247e+00  1.40439e-01]
21Feb13_025019| [-3.19888e-01  2.09194e-02]
21Feb13_025019| [ 1.89693e+00 -8.41622e-01]
21Feb13_025019| [-1.27969e+00 -6.56352e-01]
21Feb13_025019| [ 1.16580e-02  1.03944e+00]
21Feb13_025019| [-8.20741e-01 -2.24885e-01]
21Feb13_025019| [-1.22052e+00 -1.36352e+00]
21Feb13_025019| [-1.56563e+00 -5.42040e-01]
21Feb13_025019| [-2.80180e-02  7.37459e-01]
21Feb13_025019| [-1.08756e+00 -1.96726e-05]
21Feb13_025019| [-5.52375e-01  1.33786e+00]
21Feb13_025019| [ 4.95950e-01  8.07593e-01]
21Feb13_025019| [ 4.30598e-01  3.46729e-01]
21Feb13_025019| [-5.56634e-01 -1.22269e-01]]
21Feb13_025019|-- Bias --
21Feb13_025019|[-0.70533 -0.26300]
21Feb13_025019|Layer 1:
21Feb13_025019|-- Config --
21Feb13_025019|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025019|-- Weights --
21Feb13_025019|[[-6.94662e-01  3.06303e-01  4.72095e-01  5.73142e-01]
21Feb13_025019| [-4.74827e-04  3.23504e-01 -1.87283e-01 -1.00434e-01]]
21Feb13_025019|-- Bias --
21Feb13_025019|[-0.76799  0.23958  0.20163 -0.17897]
21Feb13_025019|Layer 2:
21Feb13_025019|-- Config --
21Feb13_025019|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025019|-- Weights --
21Feb13_025019|[[-0.00697  1.32245]
21Feb13_025019| [-0.25482  0.09253]
21Feb13_025019| [-0.01568  0.29430]
21Feb13_025019| [ 0.43550 -0.35716]]
21Feb13_025019|-- Bias --
21Feb13_025019|[-0.53688 -0.70488]
21Feb13_025019|Predicting the validation and test data with the Best final individual.
21Feb13_025027| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_025027|-----------  ------------------  --------------------  ----------
21Feb13_025027|Validation         25.39                  12            0.54463
21Feb13_025027|   Test            27.63                  12            0.39454
21Feb13_025027|-------------------- Test #1 --------------------
21Feb13_025027|Best final individual weights
21Feb13_025027|Individual:
21Feb13_025027|-- Constant hidden layers --
21Feb13_025027|False
21Feb13_025027|Layer 0:
21Feb13_025027|-- Config --
21Feb13_025027|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025027|-- Weights --
21Feb13_025027|[[-1.69863e+00  5.36868e-01]
21Feb13_025027| [-1.00087e+00 -2.03837e-01]
21Feb13_025027| [-7.82016e-02 -7.26166e-01]
21Feb13_025027| [ 1.09103e-02 -6.64981e-01]
21Feb13_025027| [ 2.61865e-01  1.47874e-01]
21Feb13_025027| [-1.54004e+00 -5.66954e-01]
21Feb13_025027| [-4.36773e-01 -3.87884e-01]
21Feb13_025027| [-3.23971e-01  2.30940e-01]
21Feb13_025027| [ 7.99649e-02  6.22738e-01]
21Feb13_025027| [ 7.41012e-02  3.78434e-01]
21Feb13_025027| [ 4.43657e-01 -2.95091e-01]
21Feb13_025027| [ 1.33195e+00 -3.78631e-01]
21Feb13_025027| [ 9.30112e-01 -1.26126e-01]
21Feb13_025027| [-2.33344e-01  1.72973e-01]
21Feb13_025027| [ 3.16964e-01 -1.95748e+00]
21Feb13_025027| [ 3.66377e-01 -5.84277e-01]
21Feb13_025027| [-9.86139e-01  1.19007e+00]
21Feb13_025027| [-4.06848e-01 -4.14488e-01]
21Feb13_025027| [ 1.22713e-01 -1.42885e-01]
21Feb13_025027| [-6.54057e-01 -8.02956e-01]
21Feb13_025027| [-8.03754e-01  7.47773e-01]
21Feb13_025027| [ 6.51358e-01 -8.13541e-01]
21Feb13_025027| [-1.51428e+00  5.23355e-01]
21Feb13_025027| [-4.32524e-01 -4.36951e-01]
21Feb13_025027| [-1.01652e+00  4.23838e-01]
21Feb13_025027| [ 6.33385e-01  1.47670e+00]
21Feb13_025027| [ 9.44616e-01  7.04149e-01]
21Feb13_025027| [ 2.28886e+00 -1.08929e-01]
21Feb13_025027| [-7.17545e-01  1.10507e+00]
21Feb13_025027| [ 1.18270e-01 -2.13651e-01]
21Feb13_025027| [-3.60633e-01 -8.12025e-01]
21Feb13_025027| [-4.90572e-01  9.26284e-01]
21Feb13_025027| [-6.79514e-01  1.86582e-02]
21Feb13_025027| [-1.04325e+00  6.61269e-01]
21Feb13_025027| [ 1.20725e+00  1.54115e-01]
21Feb13_025027| [-7.02012e-01  1.69880e+00]
21Feb13_025027| [-1.11488e+00 -2.01392e-01]
21Feb13_025027| [ 3.27278e-01 -6.50259e-02]
21Feb13_025027| [-6.20830e-01 -4.76016e-01]
21Feb13_025027| [-2.44251e-02  1.80081e-01]
21Feb13_025027| [ 1.08468e+00 -1.08729e+00]
21Feb13_025027| [-9.04160e-01 -4.80164e-01]
21Feb13_025027| [ 3.01454e-02 -1.07113e+00]
21Feb13_025027| [ 2.19247e+00  1.40439e-01]
21Feb13_025027| [-3.19888e-01  2.09194e-02]
21Feb13_025027| [ 1.89693e+00 -8.41622e-01]
21Feb13_025027| [-1.27969e+00 -6.56352e-01]
21Feb13_025027| [ 1.16580e-02  1.03944e+00]
21Feb13_025027| [-8.20741e-01 -2.24885e-01]
21Feb13_025027| [-1.22052e+00 -1.36352e+00]
21Feb13_025027| [-1.56563e+00 -5.42040e-01]
21Feb13_025027| [-2.80180e-02  7.37459e-01]
21Feb13_025027| [-1.08756e+00 -1.96726e-05]
21Feb13_025027| [-5.52375e-01  1.33786e+00]
21Feb13_025027| [ 4.95950e-01  8.07593e-01]
21Feb13_025027| [ 4.30598e-01  3.46729e-01]
21Feb13_025027| [-5.56634e-01 -1.22269e-01]]
21Feb13_025027|-- Bias --
21Feb13_025027|[-0.70533 -0.26300]
21Feb13_025027|Layer 1:
21Feb13_025027|-- Config --
21Feb13_025027|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025027|-- Weights --
21Feb13_025027|[[-6.94662e-01  3.06303e-01  4.72095e-01  5.73142e-01]
21Feb13_025027| [-4.74827e-04  3.23504e-01 -1.87283e-01 -1.00434e-01]]
21Feb13_025027|-- Bias --
21Feb13_025027|[-0.76799  0.23958  0.20163 -0.17897]
21Feb13_025027|Layer 2:
21Feb13_025027|-- Config --
21Feb13_025027|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025027|-- Weights --
21Feb13_025027|[[-0.00697  1.32245]
21Feb13_025027| [-0.25482  0.09253]
21Feb13_025027| [-0.01568  0.29430]
21Feb13_025027| [ 0.43550 -0.35716]]
21Feb13_025027|-- Bias --
21Feb13_025027|[-0.53688 -0.70488]
21Feb13_025027|Predicting the validation and test data with the Best final individual.
21Feb13_025034| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_025034|-----------  ------------------  --------------------  ----------
21Feb13_025034|Validation         25.04                  12            0.53243
21Feb13_025034|   Test            25.63                  12            0.52454
21Feb13_025034|-------------------- Test #2 --------------------
21Feb13_025034|Best final individual weights
21Feb13_025034|Individual:
21Feb13_025034|-- Constant hidden layers --
21Feb13_025034|False
21Feb13_025034|Layer 0:
21Feb13_025034|-- Config --
21Feb13_025034|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025034|-- Weights --
21Feb13_025034|[[-1.69863e+00  5.36868e-01]
21Feb13_025034| [-1.00087e+00 -2.03837e-01]
21Feb13_025034| [-7.82016e-02 -7.26166e-01]
21Feb13_025034| [ 1.09103e-02 -6.64981e-01]
21Feb13_025034| [ 2.61865e-01  1.47874e-01]
21Feb13_025034| [-1.54004e+00 -5.66954e-01]
21Feb13_025034| [-4.36773e-01 -3.87884e-01]
21Feb13_025034| [-3.23971e-01  2.30940e-01]
21Feb13_025034| [ 7.99649e-02  6.22738e-01]
21Feb13_025034| [ 7.41012e-02  3.78434e-01]
21Feb13_025034| [ 4.43657e-01 -2.95091e-01]
21Feb13_025034| [ 1.33195e+00 -3.78631e-01]
21Feb13_025034| [ 9.30112e-01 -1.26126e-01]
21Feb13_025034| [-2.33344e-01  1.72973e-01]
21Feb13_025034| [ 3.16964e-01 -1.95748e+00]
21Feb13_025034| [ 3.66377e-01 -5.84277e-01]
21Feb13_025034| [-9.86139e-01  1.19007e+00]
21Feb13_025034| [-4.06848e-01 -4.14488e-01]
21Feb13_025034| [ 1.22713e-01 -1.42885e-01]
21Feb13_025034| [-6.54057e-01 -8.02956e-01]
21Feb13_025034| [-8.03754e-01  7.47773e-01]
21Feb13_025034| [ 6.51358e-01 -8.13541e-01]
21Feb13_025034| [-1.51428e+00  5.23355e-01]
21Feb13_025034| [-4.32524e-01 -4.36951e-01]
21Feb13_025034| [-1.01652e+00  4.23838e-01]
21Feb13_025034| [ 6.33385e-01  1.47670e+00]
21Feb13_025034| [ 9.44616e-01  7.04149e-01]
21Feb13_025034| [ 2.28886e+00 -1.08929e-01]
21Feb13_025034| [-7.17545e-01  1.10507e+00]
21Feb13_025034| [ 1.18270e-01 -2.13651e-01]
21Feb13_025034| [-3.60633e-01 -8.12025e-01]
21Feb13_025034| [-4.90572e-01  9.26284e-01]
21Feb13_025034| [-6.79514e-01  1.86582e-02]
21Feb13_025034| [-1.04325e+00  6.61269e-01]
21Feb13_025034| [ 1.20725e+00  1.54115e-01]
21Feb13_025034| [-7.02012e-01  1.69880e+00]
21Feb13_025034| [-1.11488e+00 -2.01392e-01]
21Feb13_025034| [ 3.27278e-01 -6.50259e-02]
21Feb13_025034| [-6.20830e-01 -4.76016e-01]
21Feb13_025034| [-2.44251e-02  1.80081e-01]
21Feb13_025034| [ 1.08468e+00 -1.08729e+00]
21Feb13_025034| [-9.04160e-01 -4.80164e-01]
21Feb13_025034| [ 3.01454e-02 -1.07113e+00]
21Feb13_025034| [ 2.19247e+00  1.40439e-01]
21Feb13_025034| [-3.19888e-01  2.09194e-02]
21Feb13_025034| [ 1.89693e+00 -8.41622e-01]
21Feb13_025034| [-1.27969e+00 -6.56352e-01]
21Feb13_025034| [ 1.16580e-02  1.03944e+00]
21Feb13_025034| [-8.20741e-01 -2.24885e-01]
21Feb13_025034| [-1.22052e+00 -1.36352e+00]
21Feb13_025034| [-1.56563e+00 -5.42040e-01]
21Feb13_025034| [-2.80180e-02  7.37459e-01]
21Feb13_025034| [-1.08756e+00 -1.96726e-05]
21Feb13_025034| [-5.52375e-01  1.33786e+00]
21Feb13_025034| [ 4.95950e-01  8.07593e-01]
21Feb13_025034| [ 4.30598e-01  3.46729e-01]
21Feb13_025034| [-5.56634e-01 -1.22269e-01]]
21Feb13_025034|-- Bias --
21Feb13_025034|[-0.70533 -0.26300]
21Feb13_025034|Layer 1:
21Feb13_025034|-- Config --
21Feb13_025034|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025034|-- Weights --
21Feb13_025034|[[-6.94662e-01  3.06303e-01  4.72095e-01  5.73142e-01]
21Feb13_025034| [-4.74827e-04  3.23504e-01 -1.87283e-01 -1.00434e-01]]
21Feb13_025034|-- Bias --
21Feb13_025034|[-0.76799  0.23958  0.20163 -0.17897]
21Feb13_025034|Layer 2:
21Feb13_025034|-- Config --
21Feb13_025034|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025034|-- Weights --
21Feb13_025034|[[-0.00697  1.32245]
21Feb13_025034| [-0.25482  0.09253]
21Feb13_025034| [-0.01568  0.29430]
21Feb13_025034| [ 0.43550 -0.35716]]
21Feb13_025034|-- Bias --
21Feb13_025034|[-0.53688 -0.70488]
21Feb13_025034|Predicting the validation and test data with the Best final individual.
21Feb13_025041| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_025041|-----------  ------------------  --------------------  ----------
21Feb13_025041|Validation         26.17                  12            0.55898
21Feb13_025041|   Test            25.46                  12            0.51741
21Feb13_025041|-------------------- Test #3 --------------------
21Feb13_025041|Best final individual weights
21Feb13_025041|Individual:
21Feb13_025041|-- Constant hidden layers --
21Feb13_025041|False
21Feb13_025041|Layer 0:
21Feb13_025041|-- Config --
21Feb13_025041|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025041|-- Weights --
21Feb13_025041|[[-1.69863e+00  5.36868e-01]
21Feb13_025041| [-1.00087e+00 -2.03837e-01]
21Feb13_025041| [-7.82016e-02 -7.26166e-01]
21Feb13_025041| [ 1.09103e-02 -6.64981e-01]
21Feb13_025041| [ 2.61865e-01  1.47874e-01]
21Feb13_025041| [-1.54004e+00 -5.66954e-01]
21Feb13_025041| [-4.36773e-01 -3.87884e-01]
21Feb13_025041| [-3.23971e-01  2.30940e-01]
21Feb13_025041| [ 7.99649e-02  6.22738e-01]
21Feb13_025041| [ 7.41012e-02  3.78434e-01]
21Feb13_025041| [ 4.43657e-01 -2.95091e-01]
21Feb13_025041| [ 1.33195e+00 -3.78631e-01]
21Feb13_025041| [ 9.30112e-01 -1.26126e-01]
21Feb13_025041| [-2.33344e-01  1.72973e-01]
21Feb13_025041| [ 3.16964e-01 -1.95748e+00]
21Feb13_025041| [ 3.66377e-01 -5.84277e-01]
21Feb13_025041| [-9.86139e-01  1.19007e+00]
21Feb13_025041| [-4.06848e-01 -4.14488e-01]
21Feb13_025041| [ 1.22713e-01 -1.42885e-01]
21Feb13_025041| [-6.54057e-01 -8.02956e-01]
21Feb13_025041| [-8.03754e-01  7.47773e-01]
21Feb13_025041| [ 6.51358e-01 -8.13541e-01]
21Feb13_025041| [-1.51428e+00  5.23355e-01]
21Feb13_025041| [-4.32524e-01 -4.36951e-01]
21Feb13_025041| [-1.01652e+00  4.23838e-01]
21Feb13_025041| [ 6.33385e-01  1.47670e+00]
21Feb13_025041| [ 9.44616e-01  7.04149e-01]
21Feb13_025041| [ 2.28886e+00 -1.08929e-01]
21Feb13_025041| [-7.17545e-01  1.10507e+00]
21Feb13_025041| [ 1.18270e-01 -2.13651e-01]
21Feb13_025041| [-3.60633e-01 -8.12025e-01]
21Feb13_025041| [-4.90572e-01  9.26284e-01]
21Feb13_025041| [-6.79514e-01  1.86582e-02]
21Feb13_025041| [-1.04325e+00  6.61269e-01]
21Feb13_025041| [ 1.20725e+00  1.54115e-01]
21Feb13_025041| [-7.02012e-01  1.69880e+00]
21Feb13_025041| [-1.11488e+00 -2.01392e-01]
21Feb13_025041| [ 3.27278e-01 -6.50259e-02]
21Feb13_025041| [-6.20830e-01 -4.76016e-01]
21Feb13_025041| [-2.44251e-02  1.80081e-01]
21Feb13_025041| [ 1.08468e+00 -1.08729e+00]
21Feb13_025041| [-9.04160e-01 -4.80164e-01]
21Feb13_025041| [ 3.01454e-02 -1.07113e+00]
21Feb13_025041| [ 2.19247e+00  1.40439e-01]
21Feb13_025041| [-3.19888e-01  2.09194e-02]
21Feb13_025041| [ 1.89693e+00 -8.41622e-01]
21Feb13_025041| [-1.27969e+00 -6.56352e-01]
21Feb13_025041| [ 1.16580e-02  1.03944e+00]
21Feb13_025041| [-8.20741e-01 -2.24885e-01]
21Feb13_025041| [-1.22052e+00 -1.36352e+00]
21Feb13_025041| [-1.56563e+00 -5.42040e-01]
21Feb13_025041| [-2.80180e-02  7.37459e-01]
21Feb13_025041| [-1.08756e+00 -1.96726e-05]
21Feb13_025041| [-5.52375e-01  1.33786e+00]
21Feb13_025041| [ 4.95950e-01  8.07593e-01]
21Feb13_025041| [ 4.30598e-01  3.46729e-01]
21Feb13_025041| [-5.56634e-01 -1.22269e-01]]
21Feb13_025041|-- Bias --
21Feb13_025041|[-0.70533 -0.26300]
21Feb13_025041|Layer 1:
21Feb13_025041|-- Config --
21Feb13_025041|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025041|-- Weights --
21Feb13_025041|[[-6.94662e-01  3.06303e-01  4.72095e-01  5.73142e-01]
21Feb13_025041| [-4.74827e-04  3.23504e-01 -1.87283e-01 -1.00434e-01]]
21Feb13_025041|-- Bias --
21Feb13_025041|[-0.76799  0.23958  0.20163 -0.17897]
21Feb13_025041|Layer 2:
21Feb13_025041|-- Config --
21Feb13_025041|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025041|-- Weights --
21Feb13_025041|[[-0.00697  1.32245]
21Feb13_025041| [-0.25482  0.09253]
21Feb13_025041| [-0.01568  0.29430]
21Feb13_025041| [ 0.43550 -0.35716]]
21Feb13_025041|-- Bias --
21Feb13_025041|[-0.53688 -0.70488]
21Feb13_025041|Predicting the validation and test data with the Best final individual.
21Feb13_025049| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_025049|-----------  ------------------  --------------------  ----------
21Feb13_025049|Validation         25.30                  12            0.61894
21Feb13_025049|   Test            25.89                  12            0.53512
21Feb13_025049|-------------------- Test #4 --------------------
21Feb13_025049|Best final individual weights
21Feb13_025049|Individual:
21Feb13_025049|-- Constant hidden layers --
21Feb13_025049|False
21Feb13_025049|Layer 0:
21Feb13_025049|-- Config --
21Feb13_025049|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025049|-- Weights --
21Feb13_025049|[[-1.69863e+00  5.36868e-01]
21Feb13_025049| [-1.00087e+00 -2.03837e-01]
21Feb13_025049| [-7.82016e-02 -7.26166e-01]
21Feb13_025049| [ 1.09103e-02 -6.64981e-01]
21Feb13_025049| [ 2.61865e-01  1.47874e-01]
21Feb13_025049| [-1.54004e+00 -5.66954e-01]
21Feb13_025049| [-4.36773e-01 -3.87884e-01]
21Feb13_025049| [-3.23971e-01  2.30940e-01]
21Feb13_025049| [ 7.99649e-02  6.22738e-01]
21Feb13_025049| [ 7.41012e-02  3.78434e-01]
21Feb13_025049| [ 4.43657e-01 -2.95091e-01]
21Feb13_025049| [ 1.33195e+00 -3.78631e-01]
21Feb13_025049| [ 9.30112e-01 -1.26126e-01]
21Feb13_025049| [-2.33344e-01  1.72973e-01]
21Feb13_025049| [ 3.16964e-01 -1.95748e+00]
21Feb13_025049| [ 3.66377e-01 -5.84277e-01]
21Feb13_025049| [-9.86139e-01  1.19007e+00]
21Feb13_025049| [-4.06848e-01 -4.14488e-01]
21Feb13_025049| [ 1.22713e-01 -1.42885e-01]
21Feb13_025049| [-6.54057e-01 -8.02956e-01]
21Feb13_025049| [-8.03754e-01  7.47773e-01]
21Feb13_025049| [ 6.51358e-01 -8.13541e-01]
21Feb13_025049| [-1.51428e+00  5.23355e-01]
21Feb13_025049| [-4.32524e-01 -4.36951e-01]
21Feb13_025049| [-1.01652e+00  4.23838e-01]
21Feb13_025049| [ 6.33385e-01  1.47670e+00]
21Feb13_025049| [ 9.44616e-01  7.04149e-01]
21Feb13_025049| [ 2.28886e+00 -1.08929e-01]
21Feb13_025049| [-7.17545e-01  1.10507e+00]
21Feb13_025049| [ 1.18270e-01 -2.13651e-01]
21Feb13_025049| [-3.60633e-01 -8.12025e-01]
21Feb13_025049| [-4.90572e-01  9.26284e-01]
21Feb13_025049| [-6.79514e-01  1.86582e-02]
21Feb13_025049| [-1.04325e+00  6.61269e-01]
21Feb13_025049| [ 1.20725e+00  1.54115e-01]
21Feb13_025049| [-7.02012e-01  1.69880e+00]
21Feb13_025049| [-1.11488e+00 -2.01392e-01]
21Feb13_025049| [ 3.27278e-01 -6.50259e-02]
21Feb13_025049| [-6.20830e-01 -4.76016e-01]
21Feb13_025049| [-2.44251e-02  1.80081e-01]
21Feb13_025049| [ 1.08468e+00 -1.08729e+00]
21Feb13_025049| [-9.04160e-01 -4.80164e-01]
21Feb13_025049| [ 3.01454e-02 -1.07113e+00]
21Feb13_025049| [ 2.19247e+00  1.40439e-01]
21Feb13_025049| [-3.19888e-01  2.09194e-02]
21Feb13_025049| [ 1.89693e+00 -8.41622e-01]
21Feb13_025049| [-1.27969e+00 -6.56352e-01]
21Feb13_025049| [ 1.16580e-02  1.03944e+00]
21Feb13_025049| [-8.20741e-01 -2.24885e-01]
21Feb13_025049| [-1.22052e+00 -1.36352e+00]
21Feb13_025049| [-1.56563e+00 -5.42040e-01]
21Feb13_025049| [-2.80180e-02  7.37459e-01]
21Feb13_025049| [-1.08756e+00 -1.96726e-05]
21Feb13_025049| [-5.52375e-01  1.33786e+00]
21Feb13_025049| [ 4.95950e-01  8.07593e-01]
21Feb13_025049| [ 4.30598e-01  3.46729e-01]
21Feb13_025049| [-5.56634e-01 -1.22269e-01]]
21Feb13_025049|-- Bias --
21Feb13_025049|[-0.70533 -0.26300]
21Feb13_025049|Layer 1:
21Feb13_025049|-- Config --
21Feb13_025049|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025049|-- Weights --
21Feb13_025049|[[-6.94662e-01  3.06303e-01  4.72095e-01  5.73142e-01]
21Feb13_025049| [-4.74827e-04  3.23504e-01 -1.87283e-01 -1.00434e-01]]
21Feb13_025049|-- Bias --
21Feb13_025049|[-0.76799  0.23958  0.20163 -0.17897]
21Feb13_025049|Layer 2:
21Feb13_025049|-- Config --
21Feb13_025049|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025049|-- Weights --
21Feb13_025049|[[-0.00697  1.32245]
21Feb13_025049| [-0.25482  0.09253]
21Feb13_025049| [-0.01568  0.29430]
21Feb13_025049| [ 0.43550 -0.35716]]
21Feb13_025049|-- Bias --
21Feb13_025049|[-0.53688 -0.70488]
21Feb13_025049|Predicting the validation and test data with the Best final individual.
21Feb13_025056| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_025056|-----------  ------------------  --------------------  ----------
21Feb13_025056|Validation         25.91                  12            0.46517
21Feb13_025056|   Test            26.41                  12            0.47174
21Feb13_025056|-------------------- Test #5 --------------------
21Feb13_025056|Best final individual weights
21Feb13_025056|Individual:
21Feb13_025056|-- Constant hidden layers --
21Feb13_025056|False
21Feb13_025056|Layer 0:
21Feb13_025056|-- Config --
21Feb13_025056|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025056|-- Weights --
21Feb13_025056|[[-1.69863e+00  5.36868e-01]
21Feb13_025056| [-1.00087e+00 -2.03837e-01]
21Feb13_025056| [-7.82016e-02 -7.26166e-01]
21Feb13_025056| [ 1.09103e-02 -6.64981e-01]
21Feb13_025056| [ 2.61865e-01  1.47874e-01]
21Feb13_025056| [-1.54004e+00 -5.66954e-01]
21Feb13_025056| [-4.36773e-01 -3.87884e-01]
21Feb13_025056| [-3.23971e-01  2.30940e-01]
21Feb13_025056| [ 7.99649e-02  6.22738e-01]
21Feb13_025056| [ 7.41012e-02  3.78434e-01]
21Feb13_025056| [ 4.43657e-01 -2.95091e-01]
21Feb13_025056| [ 1.33195e+00 -3.78631e-01]
21Feb13_025056| [ 9.30112e-01 -1.26126e-01]
21Feb13_025056| [-2.33344e-01  1.72973e-01]
21Feb13_025056| [ 3.16964e-01 -1.95748e+00]
21Feb13_025056| [ 3.66377e-01 -5.84277e-01]
21Feb13_025056| [-9.86139e-01  1.19007e+00]
21Feb13_025056| [-4.06848e-01 -4.14488e-01]
21Feb13_025056| [ 1.22713e-01 -1.42885e-01]
21Feb13_025056| [-6.54057e-01 -8.02956e-01]
21Feb13_025056| [-8.03754e-01  7.47773e-01]
21Feb13_025056| [ 6.51358e-01 -8.13541e-01]
21Feb13_025056| [-1.51428e+00  5.23355e-01]
21Feb13_025056| [-4.32524e-01 -4.36951e-01]
21Feb13_025056| [-1.01652e+00  4.23838e-01]
21Feb13_025056| [ 6.33385e-01  1.47670e+00]
21Feb13_025056| [ 9.44616e-01  7.04149e-01]
21Feb13_025056| [ 2.28886e+00 -1.08929e-01]
21Feb13_025056| [-7.17545e-01  1.10507e+00]
21Feb13_025056| [ 1.18270e-01 -2.13651e-01]
21Feb13_025056| [-3.60633e-01 -8.12025e-01]
21Feb13_025056| [-4.90572e-01  9.26284e-01]
21Feb13_025056| [-6.79514e-01  1.86582e-02]
21Feb13_025056| [-1.04325e+00  6.61269e-01]
21Feb13_025056| [ 1.20725e+00  1.54115e-01]
21Feb13_025056| [-7.02012e-01  1.69880e+00]
21Feb13_025056| [-1.11488e+00 -2.01392e-01]
21Feb13_025056| [ 3.27278e-01 -6.50259e-02]
21Feb13_025056| [-6.20830e-01 -4.76016e-01]
21Feb13_025056| [-2.44251e-02  1.80081e-01]
21Feb13_025056| [ 1.08468e+00 -1.08729e+00]
21Feb13_025056| [-9.04160e-01 -4.80164e-01]
21Feb13_025056| [ 3.01454e-02 -1.07113e+00]
21Feb13_025056| [ 2.19247e+00  1.40439e-01]
21Feb13_025056| [-3.19888e-01  2.09194e-02]
21Feb13_025056| [ 1.89693e+00 -8.41622e-01]
21Feb13_025056| [-1.27969e+00 -6.56352e-01]
21Feb13_025056| [ 1.16580e-02  1.03944e+00]
21Feb13_025056| [-8.20741e-01 -2.24885e-01]
21Feb13_025056| [-1.22052e+00 -1.36352e+00]
21Feb13_025056| [-1.56563e+00 -5.42040e-01]
21Feb13_025056| [-2.80180e-02  7.37459e-01]
21Feb13_025056| [-1.08756e+00 -1.96726e-05]
21Feb13_025056| [-5.52375e-01  1.33786e+00]
21Feb13_025056| [ 4.95950e-01  8.07593e-01]
21Feb13_025056| [ 4.30598e-01  3.46729e-01]
21Feb13_025056| [-5.56634e-01 -1.22269e-01]]
21Feb13_025056|-- Bias --
21Feb13_025056|[-0.70533 -0.26300]
21Feb13_025056|Layer 1:
21Feb13_025056|-- Config --
21Feb13_025056|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025056|-- Weights --
21Feb13_025056|[[-6.94662e-01  3.06303e-01  4.72095e-01  5.73142e-01]
21Feb13_025056| [-4.74827e-04  3.23504e-01 -1.87283e-01 -1.00434e-01]]
21Feb13_025056|-- Bias --
21Feb13_025056|[-0.76799  0.23958  0.20163 -0.17897]
21Feb13_025056|Layer 2:
21Feb13_025056|-- Config --
21Feb13_025056|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025056|-- Weights --
21Feb13_025056|[[-0.00697  1.32245]
21Feb13_025056| [-0.25482  0.09253]
21Feb13_025056| [-0.01568  0.29430]
21Feb13_025056| [ 0.43550 -0.35716]]
21Feb13_025056|-- Bias --
21Feb13_025056|[-0.53688 -0.70488]
21Feb13_025056|Predicting the validation and test data with the Best final individual.
21Feb13_025104| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_025104|-----------  ------------------  --------------------  ----------
21Feb13_025104|Validation         25.13                  12            0.53597
21Feb13_025104|   Test            26.24                  12            0.49000
21Feb13_025104|-------------------- Test #6 --------------------
21Feb13_025104|Best final individual weights
21Feb13_025104|Individual:
21Feb13_025104|-- Constant hidden layers --
21Feb13_025104|False
21Feb13_025104|Layer 0:
21Feb13_025104|-- Config --
21Feb13_025104|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025104|-- Weights --
21Feb13_025104|[[-1.69863e+00  5.36868e-01]
21Feb13_025104| [-1.00087e+00 -2.03837e-01]
21Feb13_025104| [-7.82016e-02 -7.26166e-01]
21Feb13_025104| [ 1.09103e-02 -6.64981e-01]
21Feb13_025104| [ 2.61865e-01  1.47874e-01]
21Feb13_025104| [-1.54004e+00 -5.66954e-01]
21Feb13_025104| [-4.36773e-01 -3.87884e-01]
21Feb13_025104| [-3.23971e-01  2.30940e-01]
21Feb13_025104| [ 7.99649e-02  6.22738e-01]
21Feb13_025104| [ 7.41012e-02  3.78434e-01]
21Feb13_025104| [ 4.43657e-01 -2.95091e-01]
21Feb13_025104| [ 1.33195e+00 -3.78631e-01]
21Feb13_025104| [ 9.30112e-01 -1.26126e-01]
21Feb13_025104| [-2.33344e-01  1.72973e-01]
21Feb13_025104| [ 3.16964e-01 -1.95748e+00]
21Feb13_025104| [ 3.66377e-01 -5.84277e-01]
21Feb13_025104| [-9.86139e-01  1.19007e+00]
21Feb13_025104| [-4.06848e-01 -4.14488e-01]
21Feb13_025104| [ 1.22713e-01 -1.42885e-01]
21Feb13_025104| [-6.54057e-01 -8.02956e-01]
21Feb13_025104| [-8.03754e-01  7.47773e-01]
21Feb13_025104| [ 6.51358e-01 -8.13541e-01]
21Feb13_025104| [-1.51428e+00  5.23355e-01]
21Feb13_025104| [-4.32524e-01 -4.36951e-01]
21Feb13_025104| [-1.01652e+00  4.23838e-01]
21Feb13_025104| [ 6.33385e-01  1.47670e+00]
21Feb13_025104| [ 9.44616e-01  7.04149e-01]
21Feb13_025104| [ 2.28886e+00 -1.08929e-01]
21Feb13_025104| [-7.17545e-01  1.10507e+00]
21Feb13_025104| [ 1.18270e-01 -2.13651e-01]
21Feb13_025104| [-3.60633e-01 -8.12025e-01]
21Feb13_025104| [-4.90572e-01  9.26284e-01]
21Feb13_025104| [-6.79514e-01  1.86582e-02]
21Feb13_025104| [-1.04325e+00  6.61269e-01]
21Feb13_025104| [ 1.20725e+00  1.54115e-01]
21Feb13_025104| [-7.02012e-01  1.69880e+00]
21Feb13_025104| [-1.11488e+00 -2.01392e-01]
21Feb13_025104| [ 3.27278e-01 -6.50259e-02]
21Feb13_025104| [-6.20830e-01 -4.76016e-01]
21Feb13_025104| [-2.44251e-02  1.80081e-01]
21Feb13_025104| [ 1.08468e+00 -1.08729e+00]
21Feb13_025104| [-9.04160e-01 -4.80164e-01]
21Feb13_025104| [ 3.01454e-02 -1.07113e+00]
21Feb13_025104| [ 2.19247e+00  1.40439e-01]
21Feb13_025104| [-3.19888e-01  2.09194e-02]
21Feb13_025104| [ 1.89693e+00 -8.41622e-01]
21Feb13_025104| [-1.27969e+00 -6.56352e-01]
21Feb13_025104| [ 1.16580e-02  1.03944e+00]
21Feb13_025104| [-8.20741e-01 -2.24885e-01]
21Feb13_025104| [-1.22052e+00 -1.36352e+00]
21Feb13_025104| [-1.56563e+00 -5.42040e-01]
21Feb13_025104| [-2.80180e-02  7.37459e-01]
21Feb13_025104| [-1.08756e+00 -1.96726e-05]
21Feb13_025104| [-5.52375e-01  1.33786e+00]
21Feb13_025104| [ 4.95950e-01  8.07593e-01]
21Feb13_025104| [ 4.30598e-01  3.46729e-01]
21Feb13_025104| [-5.56634e-01 -1.22269e-01]]
21Feb13_025104|-- Bias --
21Feb13_025104|[-0.70533 -0.26300]
21Feb13_025104|Layer 1:
21Feb13_025104|-- Config --
21Feb13_025104|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025104|-- Weights --
21Feb13_025104|[[-6.94662e-01  3.06303e-01  4.72095e-01  5.73142e-01]
21Feb13_025104| [-4.74827e-04  3.23504e-01 -1.87283e-01 -1.00434e-01]]
21Feb13_025104|-- Bias --
21Feb13_025104|[-0.76799  0.23958  0.20163 -0.17897]
21Feb13_025104|Layer 2:
21Feb13_025104|-- Config --
21Feb13_025104|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025104|-- Weights --
21Feb13_025104|[[-0.00697  1.32245]
21Feb13_025104| [-0.25482  0.09253]
21Feb13_025104| [-0.01568  0.29430]
21Feb13_025104| [ 0.43550 -0.35716]]
21Feb13_025104|-- Bias --
21Feb13_025104|[-0.53688 -0.70488]
21Feb13_025104|Predicting the validation and test data with the Best final individual.
21Feb13_025111| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_025111|-----------  ------------------  --------------------  ----------
21Feb13_025111|Validation         25.83                  12            0.55819
21Feb13_025111|   Test            27.37                  12            0.40996
21Feb13_025111|-------------------- Test #7 --------------------
21Feb13_025111|Best final individual weights
21Feb13_025111|Individual:
21Feb13_025111|-- Constant hidden layers --
21Feb13_025111|False
21Feb13_025111|Layer 0:
21Feb13_025111|-- Config --
21Feb13_025111|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025111|-- Weights --
21Feb13_025111|[[-1.69863e+00  5.36868e-01]
21Feb13_025111| [-1.00087e+00 -2.03837e-01]
21Feb13_025111| [-7.82016e-02 -7.26166e-01]
21Feb13_025111| [ 1.09103e-02 -6.64981e-01]
21Feb13_025111| [ 2.61865e-01  1.47874e-01]
21Feb13_025111| [-1.54004e+00 -5.66954e-01]
21Feb13_025111| [-4.36773e-01 -3.87884e-01]
21Feb13_025111| [-3.23971e-01  2.30940e-01]
21Feb13_025111| [ 7.99649e-02  6.22738e-01]
21Feb13_025111| [ 7.41012e-02  3.78434e-01]
21Feb13_025111| [ 4.43657e-01 -2.95091e-01]
21Feb13_025111| [ 1.33195e+00 -3.78631e-01]
21Feb13_025111| [ 9.30112e-01 -1.26126e-01]
21Feb13_025111| [-2.33344e-01  1.72973e-01]
21Feb13_025111| [ 3.16964e-01 -1.95748e+00]
21Feb13_025111| [ 3.66377e-01 -5.84277e-01]
21Feb13_025111| [-9.86139e-01  1.19007e+00]
21Feb13_025111| [-4.06848e-01 -4.14488e-01]
21Feb13_025111| [ 1.22713e-01 -1.42885e-01]
21Feb13_025111| [-6.54057e-01 -8.02956e-01]
21Feb13_025111| [-8.03754e-01  7.47773e-01]
21Feb13_025111| [ 6.51358e-01 -8.13541e-01]
21Feb13_025111| [-1.51428e+00  5.23355e-01]
21Feb13_025111| [-4.32524e-01 -4.36951e-01]
21Feb13_025111| [-1.01652e+00  4.23838e-01]
21Feb13_025111| [ 6.33385e-01  1.47670e+00]
21Feb13_025111| [ 9.44616e-01  7.04149e-01]
21Feb13_025111| [ 2.28886e+00 -1.08929e-01]
21Feb13_025111| [-7.17545e-01  1.10507e+00]
21Feb13_025111| [ 1.18270e-01 -2.13651e-01]
21Feb13_025111| [-3.60633e-01 -8.12025e-01]
21Feb13_025111| [-4.90572e-01  9.26284e-01]
21Feb13_025111| [-6.79514e-01  1.86582e-02]
21Feb13_025111| [-1.04325e+00  6.61269e-01]
21Feb13_025111| [ 1.20725e+00  1.54115e-01]
21Feb13_025111| [-7.02012e-01  1.69880e+00]
21Feb13_025111| [-1.11488e+00 -2.01392e-01]
21Feb13_025111| [ 3.27278e-01 -6.50259e-02]
21Feb13_025111| [-6.20830e-01 -4.76016e-01]
21Feb13_025111| [-2.44251e-02  1.80081e-01]
21Feb13_025111| [ 1.08468e+00 -1.08729e+00]
21Feb13_025111| [-9.04160e-01 -4.80164e-01]
21Feb13_025111| [ 3.01454e-02 -1.07113e+00]
21Feb13_025111| [ 2.19247e+00  1.40439e-01]
21Feb13_025111| [-3.19888e-01  2.09194e-02]
21Feb13_025111| [ 1.89693e+00 -8.41622e-01]
21Feb13_025111| [-1.27969e+00 -6.56352e-01]
21Feb13_025111| [ 1.16580e-02  1.03944e+00]
21Feb13_025111| [-8.20741e-01 -2.24885e-01]
21Feb13_025111| [-1.22052e+00 -1.36352e+00]
21Feb13_025111| [-1.56563e+00 -5.42040e-01]
21Feb13_025111| [-2.80180e-02  7.37459e-01]
21Feb13_025111| [-1.08756e+00 -1.96726e-05]
21Feb13_025111| [-5.52375e-01  1.33786e+00]
21Feb13_025111| [ 4.95950e-01  8.07593e-01]
21Feb13_025111| [ 4.30598e-01  3.46729e-01]
21Feb13_025111| [-5.56634e-01 -1.22269e-01]]
21Feb13_025111|-- Bias --
21Feb13_025111|[-0.70533 -0.26300]
21Feb13_025111|Layer 1:
21Feb13_025111|-- Config --
21Feb13_025111|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025111|-- Weights --
21Feb13_025111|[[-6.94662e-01  3.06303e-01  4.72095e-01  5.73142e-01]
21Feb13_025111| [-4.74827e-04  3.23504e-01 -1.87283e-01 -1.00434e-01]]
21Feb13_025111|-- Bias --
21Feb13_025111|[-0.76799  0.23958  0.20163 -0.17897]
21Feb13_025111|Layer 2:
21Feb13_025111|-- Config --
21Feb13_025111|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025111|-- Weights --
21Feb13_025111|[[-0.00697  1.32245]
21Feb13_025111| [-0.25482  0.09253]
21Feb13_025111| [-0.01568  0.29430]
21Feb13_025111| [ 0.43550 -0.35716]]
21Feb13_025111|-- Bias --
21Feb13_025111|[-0.53688 -0.70488]
21Feb13_025111|Predicting the validation and test data with the Best final individual.
21Feb13_025119| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_025119|-----------  ------------------  --------------------  ----------
21Feb13_025119|Validation         26.96                  12            0.63067
21Feb13_025119|   Test            26.76                  12            0.45477
21Feb13_025119|-------------------- Test #8 --------------------
21Feb13_025119|Best final individual weights
21Feb13_025119|Individual:
21Feb13_025119|-- Constant hidden layers --
21Feb13_025119|False
21Feb13_025119|Layer 0:
21Feb13_025119|-- Config --
21Feb13_025119|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025119|-- Weights --
21Feb13_025119|[[-1.69863e+00  5.36868e-01]
21Feb13_025119| [-1.00087e+00 -2.03837e-01]
21Feb13_025119| [-7.82016e-02 -7.26166e-01]
21Feb13_025119| [ 1.09103e-02 -6.64981e-01]
21Feb13_025119| [ 2.61865e-01  1.47874e-01]
21Feb13_025119| [-1.54004e+00 -5.66954e-01]
21Feb13_025119| [-4.36773e-01 -3.87884e-01]
21Feb13_025119| [-3.23971e-01  2.30940e-01]
21Feb13_025119| [ 7.99649e-02  6.22738e-01]
21Feb13_025119| [ 7.41012e-02  3.78434e-01]
21Feb13_025119| [ 4.43657e-01 -2.95091e-01]
21Feb13_025119| [ 1.33195e+00 -3.78631e-01]
21Feb13_025119| [ 9.30112e-01 -1.26126e-01]
21Feb13_025119| [-2.33344e-01  1.72973e-01]
21Feb13_025119| [ 3.16964e-01 -1.95748e+00]
21Feb13_025119| [ 3.66377e-01 -5.84277e-01]
21Feb13_025119| [-9.86139e-01  1.19007e+00]
21Feb13_025119| [-4.06848e-01 -4.14488e-01]
21Feb13_025119| [ 1.22713e-01 -1.42885e-01]
21Feb13_025119| [-6.54057e-01 -8.02956e-01]
21Feb13_025119| [-8.03754e-01  7.47773e-01]
21Feb13_025119| [ 6.51358e-01 -8.13541e-01]
21Feb13_025119| [-1.51428e+00  5.23355e-01]
21Feb13_025119| [-4.32524e-01 -4.36951e-01]
21Feb13_025119| [-1.01652e+00  4.23838e-01]
21Feb13_025119| [ 6.33385e-01  1.47670e+00]
21Feb13_025119| [ 9.44616e-01  7.04149e-01]
21Feb13_025119| [ 2.28886e+00 -1.08929e-01]
21Feb13_025119| [-7.17545e-01  1.10507e+00]
21Feb13_025119| [ 1.18270e-01 -2.13651e-01]
21Feb13_025119| [-3.60633e-01 -8.12025e-01]
21Feb13_025119| [-4.90572e-01  9.26284e-01]
21Feb13_025119| [-6.79514e-01  1.86582e-02]
21Feb13_025119| [-1.04325e+00  6.61269e-01]
21Feb13_025119| [ 1.20725e+00  1.54115e-01]
21Feb13_025119| [-7.02012e-01  1.69880e+00]
21Feb13_025119| [-1.11488e+00 -2.01392e-01]
21Feb13_025119| [ 3.27278e-01 -6.50259e-02]
21Feb13_025119| [-6.20830e-01 -4.76016e-01]
21Feb13_025119| [-2.44251e-02  1.80081e-01]
21Feb13_025119| [ 1.08468e+00 -1.08729e+00]
21Feb13_025119| [-9.04160e-01 -4.80164e-01]
21Feb13_025119| [ 3.01454e-02 -1.07113e+00]
21Feb13_025119| [ 2.19247e+00  1.40439e-01]
21Feb13_025119| [-3.19888e-01  2.09194e-02]
21Feb13_025119| [ 1.89693e+00 -8.41622e-01]
21Feb13_025119| [-1.27969e+00 -6.56352e-01]
21Feb13_025119| [ 1.16580e-02  1.03944e+00]
21Feb13_025119| [-8.20741e-01 -2.24885e-01]
21Feb13_025119| [-1.22052e+00 -1.36352e+00]
21Feb13_025119| [-1.56563e+00 -5.42040e-01]
21Feb13_025119| [-2.80180e-02  7.37459e-01]
21Feb13_025119| [-1.08756e+00 -1.96726e-05]
21Feb13_025119| [-5.52375e-01  1.33786e+00]
21Feb13_025119| [ 4.95950e-01  8.07593e-01]
21Feb13_025119| [ 4.30598e-01  3.46729e-01]
21Feb13_025119| [-5.56634e-01 -1.22269e-01]]
21Feb13_025119|-- Bias --
21Feb13_025119|[-0.70533 -0.26300]
21Feb13_025119|Layer 1:
21Feb13_025119|-- Config --
21Feb13_025119|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025119|-- Weights --
21Feb13_025119|[[-6.94662e-01  3.06303e-01  4.72095e-01  5.73142e-01]
21Feb13_025119| [-4.74827e-04  3.23504e-01 -1.87283e-01 -1.00434e-01]]
21Feb13_025119|-- Bias --
21Feb13_025119|[-0.76799  0.23958  0.20163 -0.17897]
21Feb13_025119|Layer 2:
21Feb13_025119|-- Config --
21Feb13_025119|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025119|-- Weights --
21Feb13_025119|[[-0.00697  1.32245]
21Feb13_025119| [-0.25482  0.09253]
21Feb13_025119| [-0.01568  0.29430]
21Feb13_025119| [ 0.43550 -0.35716]]
21Feb13_025119|-- Bias --
21Feb13_025119|[-0.53688 -0.70488]
21Feb13_025119|Predicting the validation and test data with the Best final individual.
21Feb13_025126| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_025126|-----------  ------------------  --------------------  ----------
21Feb13_025126|Validation         24.35                  12            0.51910
21Feb13_025126|   Test            26.06                  12            0.56781
21Feb13_025126|-------------------- Test #9 --------------------
21Feb13_025126|Best final individual weights
21Feb13_025126|Individual:
21Feb13_025126|-- Constant hidden layers --
21Feb13_025126|False
21Feb13_025126|Layer 0:
21Feb13_025126|-- Config --
21Feb13_025126|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025126|-- Weights --
21Feb13_025126|[[-1.69863e+00  5.36868e-01]
21Feb13_025126| [-1.00087e+00 -2.03837e-01]
21Feb13_025126| [-7.82016e-02 -7.26166e-01]
21Feb13_025126| [ 1.09103e-02 -6.64981e-01]
21Feb13_025126| [ 2.61865e-01  1.47874e-01]
21Feb13_025126| [-1.54004e+00 -5.66954e-01]
21Feb13_025126| [-4.36773e-01 -3.87884e-01]
21Feb13_025126| [-3.23971e-01  2.30940e-01]
21Feb13_025126| [ 7.99649e-02  6.22738e-01]
21Feb13_025126| [ 7.41012e-02  3.78434e-01]
21Feb13_025126| [ 4.43657e-01 -2.95091e-01]
21Feb13_025126| [ 1.33195e+00 -3.78631e-01]
21Feb13_025126| [ 9.30112e-01 -1.26126e-01]
21Feb13_025126| [-2.33344e-01  1.72973e-01]
21Feb13_025126| [ 3.16964e-01 -1.95748e+00]
21Feb13_025126| [ 3.66377e-01 -5.84277e-01]
21Feb13_025126| [-9.86139e-01  1.19007e+00]
21Feb13_025126| [-4.06848e-01 -4.14488e-01]
21Feb13_025126| [ 1.22713e-01 -1.42885e-01]
21Feb13_025126| [-6.54057e-01 -8.02956e-01]
21Feb13_025126| [-8.03754e-01  7.47773e-01]
21Feb13_025126| [ 6.51358e-01 -8.13541e-01]
21Feb13_025126| [-1.51428e+00  5.23355e-01]
21Feb13_025126| [-4.32524e-01 -4.36951e-01]
21Feb13_025126| [-1.01652e+00  4.23838e-01]
21Feb13_025126| [ 6.33385e-01  1.47670e+00]
21Feb13_025126| [ 9.44616e-01  7.04149e-01]
21Feb13_025126| [ 2.28886e+00 -1.08929e-01]
21Feb13_025126| [-7.17545e-01  1.10507e+00]
21Feb13_025126| [ 1.18270e-01 -2.13651e-01]
21Feb13_025126| [-3.60633e-01 -8.12025e-01]
21Feb13_025126| [-4.90572e-01  9.26284e-01]
21Feb13_025126| [-6.79514e-01  1.86582e-02]
21Feb13_025126| [-1.04325e+00  6.61269e-01]
21Feb13_025126| [ 1.20725e+00  1.54115e-01]
21Feb13_025126| [-7.02012e-01  1.69880e+00]
21Feb13_025126| [-1.11488e+00 -2.01392e-01]
21Feb13_025126| [ 3.27278e-01 -6.50259e-02]
21Feb13_025126| [-6.20830e-01 -4.76016e-01]
21Feb13_025126| [-2.44251e-02  1.80081e-01]
21Feb13_025126| [ 1.08468e+00 -1.08729e+00]
21Feb13_025126| [-9.04160e-01 -4.80164e-01]
21Feb13_025126| [ 3.01454e-02 -1.07113e+00]
21Feb13_025126| [ 2.19247e+00  1.40439e-01]
21Feb13_025126| [-3.19888e-01  2.09194e-02]
21Feb13_025126| [ 1.89693e+00 -8.41622e-01]
21Feb13_025126| [-1.27969e+00 -6.56352e-01]
21Feb13_025126| [ 1.16580e-02  1.03944e+00]
21Feb13_025126| [-8.20741e-01 -2.24885e-01]
21Feb13_025126| [-1.22052e+00 -1.36352e+00]
21Feb13_025126| [-1.56563e+00 -5.42040e-01]
21Feb13_025126| [-2.80180e-02  7.37459e-01]
21Feb13_025126| [-1.08756e+00 -1.96726e-05]
21Feb13_025126| [-5.52375e-01  1.33786e+00]
21Feb13_025126| [ 4.95950e-01  8.07593e-01]
21Feb13_025126| [ 4.30598e-01  3.46729e-01]
21Feb13_025126| [-5.56634e-01 -1.22269e-01]]
21Feb13_025126|-- Bias --
21Feb13_025126|[-0.70533 -0.26300]
21Feb13_025126|Layer 1:
21Feb13_025126|-- Config --
21Feb13_025126|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025126|-- Weights --
21Feb13_025126|[[-6.94662e-01  3.06303e-01  4.72095e-01  5.73142e-01]
21Feb13_025126| [-4.74827e-04  3.23504e-01 -1.87283e-01 -1.00434e-01]]
21Feb13_025126|-- Bias --
21Feb13_025126|[-0.76799  0.23958  0.20163 -0.17897]
21Feb13_025126|Layer 2:
21Feb13_025126|-- Config --
21Feb13_025126|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025126|-- Weights --
21Feb13_025126|[[-0.00697  1.32245]
21Feb13_025126| [-0.25482  0.09253]
21Feb13_025126| [-0.01568  0.29430]
21Feb13_025126| [ 0.43550 -0.35716]]
21Feb13_025126|-- Bias --
21Feb13_025126|[-0.53688 -0.70488]
21Feb13_025126|Predicting the validation and test data with the Best final individual.
21Feb13_025134| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_025134|-----------  ------------------  --------------------  ----------
21Feb13_025134|Validation         28.61                  12            0.34402
21Feb13_025134|   Test            29.28                  12            0.32990
21Feb13_025134|-------------------- Test #10 --------------------
21Feb13_025134|Best final individual weights
21Feb13_025134|Individual:
21Feb13_025134|-- Constant hidden layers --
21Feb13_025134|False
21Feb13_025134|Layer 0:
21Feb13_025134|-- Config --
21Feb13_025134|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025134|-- Weights --
21Feb13_025134|[[-1.69863e+00  5.36868e-01]
21Feb13_025134| [-1.00087e+00 -2.03837e-01]
21Feb13_025134| [-7.82016e-02 -7.26166e-01]
21Feb13_025134| [ 1.09103e-02 -6.64981e-01]
21Feb13_025134| [ 2.61865e-01  1.47874e-01]
21Feb13_025134| [-1.54004e+00 -5.66954e-01]
21Feb13_025134| [-4.36773e-01 -3.87884e-01]
21Feb13_025134| [-3.23971e-01  2.30940e-01]
21Feb13_025134| [ 7.99649e-02  6.22738e-01]
21Feb13_025134| [ 7.41012e-02  3.78434e-01]
21Feb13_025134| [ 4.43657e-01 -2.95091e-01]
21Feb13_025134| [ 1.33195e+00 -3.78631e-01]
21Feb13_025134| [ 9.30112e-01 -1.26126e-01]
21Feb13_025134| [-2.33344e-01  1.72973e-01]
21Feb13_025134| [ 3.16964e-01 -1.95748e+00]
21Feb13_025134| [ 3.66377e-01 -5.84277e-01]
21Feb13_025134| [-9.86139e-01  1.19007e+00]
21Feb13_025134| [-4.06848e-01 -4.14488e-01]
21Feb13_025134| [ 1.22713e-01 -1.42885e-01]
21Feb13_025134| [-6.54057e-01 -8.02956e-01]
21Feb13_025134| [-8.03754e-01  7.47773e-01]
21Feb13_025134| [ 6.51358e-01 -8.13541e-01]
21Feb13_025134| [-1.51428e+00  5.23355e-01]
21Feb13_025134| [-4.32524e-01 -4.36951e-01]
21Feb13_025134| [-1.01652e+00  4.23838e-01]
21Feb13_025134| [ 6.33385e-01  1.47670e+00]
21Feb13_025134| [ 9.44616e-01  7.04149e-01]
21Feb13_025134| [ 2.28886e+00 -1.08929e-01]
21Feb13_025134| [-7.17545e-01  1.10507e+00]
21Feb13_025134| [ 1.18270e-01 -2.13651e-01]
21Feb13_025134| [-3.60633e-01 -8.12025e-01]
21Feb13_025134| [-4.90572e-01  9.26284e-01]
21Feb13_025134| [-6.79514e-01  1.86582e-02]
21Feb13_025134| [-1.04325e+00  6.61269e-01]
21Feb13_025134| [ 1.20725e+00  1.54115e-01]
21Feb13_025134| [-7.02012e-01  1.69880e+00]
21Feb13_025134| [-1.11488e+00 -2.01392e-01]
21Feb13_025134| [ 3.27278e-01 -6.50259e-02]
21Feb13_025134| [-6.20830e-01 -4.76016e-01]
21Feb13_025134| [-2.44251e-02  1.80081e-01]
21Feb13_025134| [ 1.08468e+00 -1.08729e+00]
21Feb13_025134| [-9.04160e-01 -4.80164e-01]
21Feb13_025134| [ 3.01454e-02 -1.07113e+00]
21Feb13_025134| [ 2.19247e+00  1.40439e-01]
21Feb13_025134| [-3.19888e-01  2.09194e-02]
21Feb13_025134| [ 1.89693e+00 -8.41622e-01]
21Feb13_025134| [-1.27969e+00 -6.56352e-01]
21Feb13_025134| [ 1.16580e-02  1.03944e+00]
21Feb13_025134| [-8.20741e-01 -2.24885e-01]
21Feb13_025134| [-1.22052e+00 -1.36352e+00]
21Feb13_025134| [-1.56563e+00 -5.42040e-01]
21Feb13_025134| [-2.80180e-02  7.37459e-01]
21Feb13_025134| [-1.08756e+00 -1.96726e-05]
21Feb13_025134| [-5.52375e-01  1.33786e+00]
21Feb13_025134| [ 4.95950e-01  8.07593e-01]
21Feb13_025134| [ 4.30598e-01  3.46729e-01]
21Feb13_025134| [-5.56634e-01 -1.22269e-01]]
21Feb13_025134|-- Bias --
21Feb13_025134|[-0.70533 -0.26300]
21Feb13_025134|Layer 1:
21Feb13_025134|-- Config --
21Feb13_025134|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025134|-- Weights --
21Feb13_025134|[[-6.94662e-01  3.06303e-01  4.72095e-01  5.73142e-01]
21Feb13_025134| [-4.74827e-04  3.23504e-01 -1.87283e-01 -1.00434e-01]]
21Feb13_025134|-- Bias --
21Feb13_025134|[-0.76799  0.23958  0.20163 -0.17897]
21Feb13_025134|Layer 2:
21Feb13_025134|-- Config --
21Feb13_025134|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025134|-- Weights --
21Feb13_025134|[[-0.00697  1.32245]
21Feb13_025134| [-0.25482  0.09253]
21Feb13_025134| [-0.01568  0.29430]
21Feb13_025134| [ 0.43550 -0.35716]]
21Feb13_025134|-- Bias --
21Feb13_025134|[-0.53688 -0.70488]
21Feb13_025134|Predicting the validation and test data with the Best final individual.
21Feb13_025141| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_025141|-----------  ------------------  --------------------  ----------
21Feb13_025141|Validation         26.35                  12            0.43741
21Feb13_025141|   Test            27.19                  12            0.55347
21Feb13_025141|-------------------- Test #11 --------------------
21Feb13_025141|Best final individual weights
21Feb13_025141|Individual:
21Feb13_025141|-- Constant hidden layers --
21Feb13_025141|False
21Feb13_025141|Layer 0:
21Feb13_025141|-- Config --
21Feb13_025141|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025141|-- Weights --
21Feb13_025141|[[-1.69863e+00  5.36868e-01]
21Feb13_025141| [-1.00087e+00 -2.03837e-01]
21Feb13_025141| [-7.82016e-02 -7.26166e-01]
21Feb13_025141| [ 1.09103e-02 -6.64981e-01]
21Feb13_025141| [ 2.61865e-01  1.47874e-01]
21Feb13_025141| [-1.54004e+00 -5.66954e-01]
21Feb13_025141| [-4.36773e-01 -3.87884e-01]
21Feb13_025141| [-3.23971e-01  2.30940e-01]
21Feb13_025141| [ 7.99649e-02  6.22738e-01]
21Feb13_025141| [ 7.41012e-02  3.78434e-01]
21Feb13_025141| [ 4.43657e-01 -2.95091e-01]
21Feb13_025141| [ 1.33195e+00 -3.78631e-01]
21Feb13_025141| [ 9.30112e-01 -1.26126e-01]
21Feb13_025141| [-2.33344e-01  1.72973e-01]
21Feb13_025141| [ 3.16964e-01 -1.95748e+00]
21Feb13_025141| [ 3.66377e-01 -5.84277e-01]
21Feb13_025141| [-9.86139e-01  1.19007e+00]
21Feb13_025141| [-4.06848e-01 -4.14488e-01]
21Feb13_025141| [ 1.22713e-01 -1.42885e-01]
21Feb13_025141| [-6.54057e-01 -8.02956e-01]
21Feb13_025141| [-8.03754e-01  7.47773e-01]
21Feb13_025141| [ 6.51358e-01 -8.13541e-01]
21Feb13_025141| [-1.51428e+00  5.23355e-01]
21Feb13_025141| [-4.32524e-01 -4.36951e-01]
21Feb13_025141| [-1.01652e+00  4.23838e-01]
21Feb13_025141| [ 6.33385e-01  1.47670e+00]
21Feb13_025141| [ 9.44616e-01  7.04149e-01]
21Feb13_025141| [ 2.28886e+00 -1.08929e-01]
21Feb13_025141| [-7.17545e-01  1.10507e+00]
21Feb13_025141| [ 1.18270e-01 -2.13651e-01]
21Feb13_025141| [-3.60633e-01 -8.12025e-01]
21Feb13_025141| [-4.90572e-01  9.26284e-01]
21Feb13_025141| [-6.79514e-01  1.86582e-02]
21Feb13_025141| [-1.04325e+00  6.61269e-01]
21Feb13_025141| [ 1.20725e+00  1.54115e-01]
21Feb13_025141| [-7.02012e-01  1.69880e+00]
21Feb13_025141| [-1.11488e+00 -2.01392e-01]
21Feb13_025141| [ 3.27278e-01 -6.50259e-02]
21Feb13_025141| [-6.20830e-01 -4.76016e-01]
21Feb13_025141| [-2.44251e-02  1.80081e-01]
21Feb13_025141| [ 1.08468e+00 -1.08729e+00]
21Feb13_025141| [-9.04160e-01 -4.80164e-01]
21Feb13_025141| [ 3.01454e-02 -1.07113e+00]
21Feb13_025141| [ 2.19247e+00  1.40439e-01]
21Feb13_025141| [-3.19888e-01  2.09194e-02]
21Feb13_025141| [ 1.89693e+00 -8.41622e-01]
21Feb13_025141| [-1.27969e+00 -6.56352e-01]
21Feb13_025141| [ 1.16580e-02  1.03944e+00]
21Feb13_025141| [-8.20741e-01 -2.24885e-01]
21Feb13_025141| [-1.22052e+00 -1.36352e+00]
21Feb13_025141| [-1.56563e+00 -5.42040e-01]
21Feb13_025141| [-2.80180e-02  7.37459e-01]
21Feb13_025141| [-1.08756e+00 -1.96726e-05]
21Feb13_025141| [-5.52375e-01  1.33786e+00]
21Feb13_025141| [ 4.95950e-01  8.07593e-01]
21Feb13_025141| [ 4.30598e-01  3.46729e-01]
21Feb13_025141| [-5.56634e-01 -1.22269e-01]]
21Feb13_025141|-- Bias --
21Feb13_025141|[-0.70533 -0.26300]
21Feb13_025141|Layer 1:
21Feb13_025141|-- Config --
21Feb13_025141|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025141|-- Weights --
21Feb13_025141|[[-6.94662e-01  3.06303e-01  4.72095e-01  5.73142e-01]
21Feb13_025141| [-4.74827e-04  3.23504e-01 -1.87283e-01 -1.00434e-01]]
21Feb13_025141|-- Bias --
21Feb13_025141|[-0.76799  0.23958  0.20163 -0.17897]
21Feb13_025141|Layer 2:
21Feb13_025141|-- Config --
21Feb13_025141|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025141|-- Weights --
21Feb13_025141|[[-0.00697  1.32245]
21Feb13_025141| [-0.25482  0.09253]
21Feb13_025141| [-0.01568  0.29430]
21Feb13_025141| [ 0.43550 -0.35716]]
21Feb13_025141|-- Bias --
21Feb13_025141|[-0.53688 -0.70488]
21Feb13_025141|Predicting the validation and test data with the Best final individual.
21Feb13_025148| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_025148|-----------  ------------------  --------------------  ----------
21Feb13_025148|Validation         25.65                  12            0.49583
21Feb13_025148|   Test            26.76                  12            0.43435
21Feb13_025148|-------------------- Test #12 --------------------
21Feb13_025148|Best final individual weights
21Feb13_025148|Individual:
21Feb13_025148|-- Constant hidden layers --
21Feb13_025148|False
21Feb13_025148|Layer 0:
21Feb13_025148|-- Config --
21Feb13_025148|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025148|-- Weights --
21Feb13_025148|[[-1.69863e+00  5.36868e-01]
21Feb13_025148| [-1.00087e+00 -2.03837e-01]
21Feb13_025148| [-7.82016e-02 -7.26166e-01]
21Feb13_025148| [ 1.09103e-02 -6.64981e-01]
21Feb13_025148| [ 2.61865e-01  1.47874e-01]
21Feb13_025148| [-1.54004e+00 -5.66954e-01]
21Feb13_025148| [-4.36773e-01 -3.87884e-01]
21Feb13_025148| [-3.23971e-01  2.30940e-01]
21Feb13_025148| [ 7.99649e-02  6.22738e-01]
21Feb13_025148| [ 7.41012e-02  3.78434e-01]
21Feb13_025148| [ 4.43657e-01 -2.95091e-01]
21Feb13_025148| [ 1.33195e+00 -3.78631e-01]
21Feb13_025148| [ 9.30112e-01 -1.26126e-01]
21Feb13_025148| [-2.33344e-01  1.72973e-01]
21Feb13_025148| [ 3.16964e-01 -1.95748e+00]
21Feb13_025148| [ 3.66377e-01 -5.84277e-01]
21Feb13_025148| [-9.86139e-01  1.19007e+00]
21Feb13_025148| [-4.06848e-01 -4.14488e-01]
21Feb13_025148| [ 1.22713e-01 -1.42885e-01]
21Feb13_025148| [-6.54057e-01 -8.02956e-01]
21Feb13_025148| [-8.03754e-01  7.47773e-01]
21Feb13_025148| [ 6.51358e-01 -8.13541e-01]
21Feb13_025148| [-1.51428e+00  5.23355e-01]
21Feb13_025148| [-4.32524e-01 -4.36951e-01]
21Feb13_025148| [-1.01652e+00  4.23838e-01]
21Feb13_025148| [ 6.33385e-01  1.47670e+00]
21Feb13_025148| [ 9.44616e-01  7.04149e-01]
21Feb13_025148| [ 2.28886e+00 -1.08929e-01]
21Feb13_025148| [-7.17545e-01  1.10507e+00]
21Feb13_025148| [ 1.18270e-01 -2.13651e-01]
21Feb13_025148| [-3.60633e-01 -8.12025e-01]
21Feb13_025148| [-4.90572e-01  9.26284e-01]
21Feb13_025148| [-6.79514e-01  1.86582e-02]
21Feb13_025148| [-1.04325e+00  6.61269e-01]
21Feb13_025148| [ 1.20725e+00  1.54115e-01]
21Feb13_025148| [-7.02012e-01  1.69880e+00]
21Feb13_025148| [-1.11488e+00 -2.01392e-01]
21Feb13_025148| [ 3.27278e-01 -6.50259e-02]
21Feb13_025148| [-6.20830e-01 -4.76016e-01]
21Feb13_025148| [-2.44251e-02  1.80081e-01]
21Feb13_025148| [ 1.08468e+00 -1.08729e+00]
21Feb13_025148| [-9.04160e-01 -4.80164e-01]
21Feb13_025148| [ 3.01454e-02 -1.07113e+00]
21Feb13_025148| [ 2.19247e+00  1.40439e-01]
21Feb13_025148| [-3.19888e-01  2.09194e-02]
21Feb13_025148| [ 1.89693e+00 -8.41622e-01]
21Feb13_025148| [-1.27969e+00 -6.56352e-01]
21Feb13_025148| [ 1.16580e-02  1.03944e+00]
21Feb13_025148| [-8.20741e-01 -2.24885e-01]
21Feb13_025148| [-1.22052e+00 -1.36352e+00]
21Feb13_025148| [-1.56563e+00 -5.42040e-01]
21Feb13_025148| [-2.80180e-02  7.37459e-01]
21Feb13_025148| [-1.08756e+00 -1.96726e-05]
21Feb13_025148| [-5.52375e-01  1.33786e+00]
21Feb13_025148| [ 4.95950e-01  8.07593e-01]
21Feb13_025148| [ 4.30598e-01  3.46729e-01]
21Feb13_025148| [-5.56634e-01 -1.22269e-01]]
21Feb13_025148|-- Bias --
21Feb13_025148|[-0.70533 -0.26300]
21Feb13_025148|Layer 1:
21Feb13_025148|-- Config --
21Feb13_025148|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025148|-- Weights --
21Feb13_025148|[[-6.94662e-01  3.06303e-01  4.72095e-01  5.73142e-01]
21Feb13_025148| [-4.74827e-04  3.23504e-01 -1.87283e-01 -1.00434e-01]]
21Feb13_025148|-- Bias --
21Feb13_025148|[-0.76799  0.23958  0.20163 -0.17897]
21Feb13_025148|Layer 2:
21Feb13_025148|-- Config --
21Feb13_025148|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025148|-- Weights --
21Feb13_025148|[[-0.00697  1.32245]
21Feb13_025148| [-0.25482  0.09253]
21Feb13_025148| [-0.01568  0.29430]
21Feb13_025148| [ 0.43550 -0.35716]]
21Feb13_025148|-- Bias --
21Feb13_025148|[-0.53688 -0.70488]
21Feb13_025148|Predicting the validation and test data with the Best final individual.
21Feb13_025156| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_025156|-----------  ------------------  --------------------  ----------
21Feb13_025156|Validation         27.83                  12            0.36340
21Feb13_025156|   Test            25.98                  12            0.50823
21Feb13_025156|-------------------- Test #13 --------------------
21Feb13_025156|Best final individual weights
21Feb13_025156|Individual:
21Feb13_025156|-- Constant hidden layers --
21Feb13_025156|False
21Feb13_025156|Layer 0:
21Feb13_025156|-- Config --
21Feb13_025156|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025156|-- Weights --
21Feb13_025156|[[-1.69863e+00  5.36868e-01]
21Feb13_025156| [-1.00087e+00 -2.03837e-01]
21Feb13_025156| [-7.82016e-02 -7.26166e-01]
21Feb13_025156| [ 1.09103e-02 -6.64981e-01]
21Feb13_025156| [ 2.61865e-01  1.47874e-01]
21Feb13_025156| [-1.54004e+00 -5.66954e-01]
21Feb13_025156| [-4.36773e-01 -3.87884e-01]
21Feb13_025156| [-3.23971e-01  2.30940e-01]
21Feb13_025156| [ 7.99649e-02  6.22738e-01]
21Feb13_025156| [ 7.41012e-02  3.78434e-01]
21Feb13_025156| [ 4.43657e-01 -2.95091e-01]
21Feb13_025156| [ 1.33195e+00 -3.78631e-01]
21Feb13_025156| [ 9.30112e-01 -1.26126e-01]
21Feb13_025156| [-2.33344e-01  1.72973e-01]
21Feb13_025156| [ 3.16964e-01 -1.95748e+00]
21Feb13_025156| [ 3.66377e-01 -5.84277e-01]
21Feb13_025156| [-9.86139e-01  1.19007e+00]
21Feb13_025156| [-4.06848e-01 -4.14488e-01]
21Feb13_025156| [ 1.22713e-01 -1.42885e-01]
21Feb13_025156| [-6.54057e-01 -8.02956e-01]
21Feb13_025156| [-8.03754e-01  7.47773e-01]
21Feb13_025156| [ 6.51358e-01 -8.13541e-01]
21Feb13_025156| [-1.51428e+00  5.23355e-01]
21Feb13_025156| [-4.32524e-01 -4.36951e-01]
21Feb13_025156| [-1.01652e+00  4.23838e-01]
21Feb13_025156| [ 6.33385e-01  1.47670e+00]
21Feb13_025156| [ 9.44616e-01  7.04149e-01]
21Feb13_025156| [ 2.28886e+00 -1.08929e-01]
21Feb13_025156| [-7.17545e-01  1.10507e+00]
21Feb13_025156| [ 1.18270e-01 -2.13651e-01]
21Feb13_025156| [-3.60633e-01 -8.12025e-01]
21Feb13_025156| [-4.90572e-01  9.26284e-01]
21Feb13_025156| [-6.79514e-01  1.86582e-02]
21Feb13_025156| [-1.04325e+00  6.61269e-01]
21Feb13_025156| [ 1.20725e+00  1.54115e-01]
21Feb13_025156| [-7.02012e-01  1.69880e+00]
21Feb13_025156| [-1.11488e+00 -2.01392e-01]
21Feb13_025156| [ 3.27278e-01 -6.50259e-02]
21Feb13_025156| [-6.20830e-01 -4.76016e-01]
21Feb13_025156| [-2.44251e-02  1.80081e-01]
21Feb13_025156| [ 1.08468e+00 -1.08729e+00]
21Feb13_025156| [-9.04160e-01 -4.80164e-01]
21Feb13_025156| [ 3.01454e-02 -1.07113e+00]
21Feb13_025156| [ 2.19247e+00  1.40439e-01]
21Feb13_025156| [-3.19888e-01  2.09194e-02]
21Feb13_025156| [ 1.89693e+00 -8.41622e-01]
21Feb13_025156| [-1.27969e+00 -6.56352e-01]
21Feb13_025156| [ 1.16580e-02  1.03944e+00]
21Feb13_025156| [-8.20741e-01 -2.24885e-01]
21Feb13_025156| [-1.22052e+00 -1.36352e+00]
21Feb13_025156| [-1.56563e+00 -5.42040e-01]
21Feb13_025156| [-2.80180e-02  7.37459e-01]
21Feb13_025156| [-1.08756e+00 -1.96726e-05]
21Feb13_025156| [-5.52375e-01  1.33786e+00]
21Feb13_025156| [ 4.95950e-01  8.07593e-01]
21Feb13_025156| [ 4.30598e-01  3.46729e-01]
21Feb13_025156| [-5.56634e-01 -1.22269e-01]]
21Feb13_025156|-- Bias --
21Feb13_025156|[-0.70533 -0.26300]
21Feb13_025156|Layer 1:
21Feb13_025156|-- Config --
21Feb13_025156|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025156|-- Weights --
21Feb13_025156|[[-6.94662e-01  3.06303e-01  4.72095e-01  5.73142e-01]
21Feb13_025156| [-4.74827e-04  3.23504e-01 -1.87283e-01 -1.00434e-01]]
21Feb13_025156|-- Bias --
21Feb13_025156|[-0.76799  0.23958  0.20163 -0.17897]
21Feb13_025156|Layer 2:
21Feb13_025156|-- Config --
21Feb13_025156|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025156|-- Weights --
21Feb13_025156|[[-0.00697  1.32245]
21Feb13_025156| [-0.25482  0.09253]
21Feb13_025156| [-0.01568  0.29430]
21Feb13_025156| [ 0.43550 -0.35716]]
21Feb13_025156|-- Bias --
21Feb13_025156|[-0.53688 -0.70488]
21Feb13_025156|Predicting the validation and test data with the Best final individual.
21Feb13_025203| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_025203|-----------  ------------------  --------------------  ----------
21Feb13_025203|Validation         24.61                  12            0.51834
21Feb13_025203|   Test            25.63                  12            0.52073
21Feb13_025203|-------------------- Test #14 --------------------
21Feb13_025203|Best final individual weights
21Feb13_025203|Individual:
21Feb13_025203|-- Constant hidden layers --
21Feb13_025203|False
21Feb13_025203|Layer 0:
21Feb13_025203|-- Config --
21Feb13_025203|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025203|-- Weights --
21Feb13_025203|[[-1.69863e+00  5.36868e-01]
21Feb13_025203| [-1.00087e+00 -2.03837e-01]
21Feb13_025203| [-7.82016e-02 -7.26166e-01]
21Feb13_025203| [ 1.09103e-02 -6.64981e-01]
21Feb13_025203| [ 2.61865e-01  1.47874e-01]
21Feb13_025203| [-1.54004e+00 -5.66954e-01]
21Feb13_025203| [-4.36773e-01 -3.87884e-01]
21Feb13_025203| [-3.23971e-01  2.30940e-01]
21Feb13_025203| [ 7.99649e-02  6.22738e-01]
21Feb13_025203| [ 7.41012e-02  3.78434e-01]
21Feb13_025203| [ 4.43657e-01 -2.95091e-01]
21Feb13_025203| [ 1.33195e+00 -3.78631e-01]
21Feb13_025203| [ 9.30112e-01 -1.26126e-01]
21Feb13_025203| [-2.33344e-01  1.72973e-01]
21Feb13_025203| [ 3.16964e-01 -1.95748e+00]
21Feb13_025203| [ 3.66377e-01 -5.84277e-01]
21Feb13_025203| [-9.86139e-01  1.19007e+00]
21Feb13_025203| [-4.06848e-01 -4.14488e-01]
21Feb13_025203| [ 1.22713e-01 -1.42885e-01]
21Feb13_025203| [-6.54057e-01 -8.02956e-01]
21Feb13_025203| [-8.03754e-01  7.47773e-01]
21Feb13_025203| [ 6.51358e-01 -8.13541e-01]
21Feb13_025203| [-1.51428e+00  5.23355e-01]
21Feb13_025203| [-4.32524e-01 -4.36951e-01]
21Feb13_025203| [-1.01652e+00  4.23838e-01]
21Feb13_025203| [ 6.33385e-01  1.47670e+00]
21Feb13_025203| [ 9.44616e-01  7.04149e-01]
21Feb13_025203| [ 2.28886e+00 -1.08929e-01]
21Feb13_025203| [-7.17545e-01  1.10507e+00]
21Feb13_025203| [ 1.18270e-01 -2.13651e-01]
21Feb13_025203| [-3.60633e-01 -8.12025e-01]
21Feb13_025203| [-4.90572e-01  9.26284e-01]
21Feb13_025203| [-6.79514e-01  1.86582e-02]
21Feb13_025203| [-1.04325e+00  6.61269e-01]
21Feb13_025203| [ 1.20725e+00  1.54115e-01]
21Feb13_025203| [-7.02012e-01  1.69880e+00]
21Feb13_025203| [-1.11488e+00 -2.01392e-01]
21Feb13_025203| [ 3.27278e-01 -6.50259e-02]
21Feb13_025203| [-6.20830e-01 -4.76016e-01]
21Feb13_025203| [-2.44251e-02  1.80081e-01]
21Feb13_025203| [ 1.08468e+00 -1.08729e+00]
21Feb13_025203| [-9.04160e-01 -4.80164e-01]
21Feb13_025203| [ 3.01454e-02 -1.07113e+00]
21Feb13_025203| [ 2.19247e+00  1.40439e-01]
21Feb13_025203| [-3.19888e-01  2.09194e-02]
21Feb13_025203| [ 1.89693e+00 -8.41622e-01]
21Feb13_025203| [-1.27969e+00 -6.56352e-01]
21Feb13_025203| [ 1.16580e-02  1.03944e+00]
21Feb13_025203| [-8.20741e-01 -2.24885e-01]
21Feb13_025203| [-1.22052e+00 -1.36352e+00]
21Feb13_025203| [-1.56563e+00 -5.42040e-01]
21Feb13_025203| [-2.80180e-02  7.37459e-01]
21Feb13_025203| [-1.08756e+00 -1.96726e-05]
21Feb13_025203| [-5.52375e-01  1.33786e+00]
21Feb13_025203| [ 4.95950e-01  8.07593e-01]
21Feb13_025203| [ 4.30598e-01  3.46729e-01]
21Feb13_025203| [-5.56634e-01 -1.22269e-01]]
21Feb13_025203|-- Bias --
21Feb13_025203|[-0.70533 -0.26300]
21Feb13_025203|Layer 1:
21Feb13_025203|-- Config --
21Feb13_025203|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025203|-- Weights --
21Feb13_025203|[[-6.94662e-01  3.06303e-01  4.72095e-01  5.73142e-01]
21Feb13_025203| [-4.74827e-04  3.23504e-01 -1.87283e-01 -1.00434e-01]]
21Feb13_025203|-- Bias --
21Feb13_025203|[-0.76799  0.23958  0.20163 -0.17897]
21Feb13_025203|Layer 2:
21Feb13_025203|-- Config --
21Feb13_025203|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_025203|-- Weights --
21Feb13_025203|[[-0.00697  1.32245]
21Feb13_025203| [-0.25482  0.09253]
21Feb13_025203| [-0.01568  0.29430]
21Feb13_025203| [ 0.43550 -0.35716]]
21Feb13_025203|-- Bias --
21Feb13_025203|[-0.53688 -0.70488]
21Feb13_025203|Predicting the validation and test data with the Best final individual.
21Feb13_025211| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_025211|-----------  ------------------  --------------------  ----------
21Feb13_025211|Validation         27.13                  12            0.40609
21Feb13_025211|   Test            25.37                  12            0.49241
2021-02-13 02:52:12.010273: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
21Feb13_025212|Data summary: Train
21Feb13_025212|data.shape = (2300, 57)
21Feb13_025212|labels.shape = (2300,)
21Feb13_025212|Class distribution:
21Feb13_025212|	0 - 1382 (0.60)
21Feb13_025212|	1 - 918 (0.40)
21Feb13_025212|Data summary: Validation
21Feb13_025212|data.shape = (1150, 57)
21Feb13_025212|labels.shape = (1150,)
21Feb13_025212|Class distribution:
21Feb13_025212|	0 - 704 (0.61)
21Feb13_025212|	1 - 446 (0.39)
21Feb13_025212|Data summary: Test
21Feb13_025212|data.shape = (1151, 57)
21Feb13_025212|labels.shape = (1151,)
21Feb13_025212|Class distribution:
21Feb13_025212|	0 - 702 (0.61)
21Feb13_025212|	1 - 449 (0.39)
21Feb13_025212|Selected configuration values
21Feb13_025212|-- Dataset name: spambase1
21Feb13_025212|-- Initial population size: 64
21Feb13_025212|-- Maximun number of generations: 32
21Feb13_025212|-- Neurons per hidden layer range: (2, 20)
21Feb13_025212|-- Hidden layers number range: (1, 3)
21Feb13_025212|-- Crossover probability: 0.5
21Feb13_025212|-- Bias gene mutation probability: 0.2
21Feb13_025212|-- Weights gene mutation probability: 0.75
21Feb13_025212|-- Neuron mutation probability: 0.3
21Feb13_025212|-- Layer mutation probability: 0.3
21Feb13_025212|-- Constant hidden layers: False
21Feb13_025212|-- Seed: 31415
21Feb13_025212|Entering GA
21Feb13_025212|Start the algorithm
2021-02-13 02:52:12.925176: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-13 02:52:12.925779: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-02-13 02:52:12.947060: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-13 02:52:12.947423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.71GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s
2021-02-13 02:52:12.947446: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-02-13 02:52:12.949099: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-02-13 02:52:12.949134: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-02-13 02:52:12.949709: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-02-13 02:52:12.949883: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-02-13 02:52:12.949968: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-13 02:52:12.950444: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-02-13 02:52:12.950488: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-13 02:52:12.950494: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-02-13 02:52:12.950713: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-02-13 02:52:12.951579: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-13 02:52:12.951599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-13 02:52:12.951602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      
2021-02-13 02:52:12.998137: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-02-13 02:52:12.998453: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3493635000 Hz
/home/jmerelo/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype("int32")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn('`model.predict_classes()` is deprecated and '
21Feb13_025618|-- Generation 1 --
21Feb13_025618|    -- Crossed 0 individual pairs.
21Feb13_025618|    -- Mutated 32 individuals.
21Feb13_030022|    -- Evaluated 64 individuals.
21Feb13_030022|    Summary of generation 1:
21Feb13_030022| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_030022|-----------  ------------------  --------------------  ----------
21Feb13_030022|    Max            39.48                208.00          0.01953
21Feb13_030022|    Avg            38.90                57.28           0.00048
21Feb13_030022|    Min            38.26                 2.00           0.00000
21Feb13_030022|    Std             0.18                49.64           0.00277
21Feb13_030022|   Best            38.26                20.00           0.01953
21Feb13_030022|-- Generation 2 --
21Feb13_030022|    -- Crossed 1 individual pairs.
21Feb13_030022|    -- Mutated 32 individuals.
21Feb13_030426|    -- Evaluated 64 individuals.
21Feb13_030426|    Summary of generation 2:
21Feb13_030426| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_030426|-----------  ------------------  --------------------  ----------
21Feb13_030426|    Max            39.39                140.00          0.66317
21Feb13_030426|    Avg            38.39                44.69           0.01821
21Feb13_030426|    Min            23.83                 2.00           0.00000
21Feb13_030426|    Std             2.47                38.02           0.10236
21Feb13_030426|   Best            23.83                63.00           0.66317
21Feb13_030426|-- Generation 3 --
21Feb13_030426|    -- Crossed 5 individual pairs.
21Feb13_030426|    -- Mutated 32 individuals.
21Feb13_030825|    -- Evaluated 64 individuals.
21Feb13_030825|    Summary of generation 3:
21Feb13_030825| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_030825|-----------  ------------------  --------------------  ----------
21Feb13_030825|    Max            39.22                69.00           0.73579
21Feb13_030825|    Avg            38.64                21.67           0.01319
21Feb13_030825|    Min            30.43                 2.00           0.00000
21Feb13_030825|    Std             1.06                17.79           0.09139
21Feb13_030825|   Best            30.43                16.00           0.73579
21Feb13_030825|-- Generation 4 --
21Feb13_030825|    -- Crossed 4 individual pairs.
21Feb13_030825|    -- Mutated 32 individuals.
21Feb13_031220|    -- Evaluated 64 individuals.
21Feb13_031220|    Summary of generation 4:
21Feb13_031220| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_031220|-----------  ------------------  --------------------  ----------
21Feb13_031220|    Max            39.30                26.00           0.81595
21Feb13_031220|    Avg            38.14                10.53           0.04648
21Feb13_031220|    Min            26.09                 2.00           0.00000
21Feb13_031220|    Std             2.57                 7.43           0.16956
21Feb13_031220|   Best            26.09                18.00           0.52365
21Feb13_031220|-- Generation 5 --
21Feb13_031220|    -- Crossed 3 individual pairs.
21Feb13_031220|    -- Mutated 32 individuals.
21Feb13_031614|    -- Evaluated 64 individuals.
21Feb13_031614|    Summary of generation 5:
21Feb13_031614| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_031614|-----------  ------------------  --------------------  ----------
21Feb13_031614|    Max            40.78                24.00           0.05782
21Feb13_031614|    Avg            38.84                 7.88           0.00108
21Feb13_031614|    Min            37.91                 2.00           0.00000
21Feb13_031614|    Std             0.28                 6.22           0.00728
21Feb13_031614|   Best            37.91                16.00           0.05782
21Feb13_031614|-- Generation 6 --
21Feb13_031614|    -- Crossed 6 individual pairs.
21Feb13_031614|    -- Mutated 32 individuals.
21Feb13_032005|    -- Evaluated 64 individuals.
21Feb13_032005|    Summary of generation 6:
21Feb13_032005| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_032005|-----------  ------------------  --------------------  ----------
21Feb13_032005|    Max            39.22                24.00           0.52887
21Feb13_032005|    Avg            38.53                 5.53           0.01123
21Feb13_032005|    Min            24.96                 2.00           0.00000
21Feb13_032005|    Std             1.78                 5.20           0.06792
21Feb13_032005|   Best            24.96                 8.00           0.52887
21Feb13_032005|-- Generation 7 --
21Feb13_032005|    -- Crossed 4 individual pairs.
21Feb13_032005|    -- Mutated 32 individuals.
21Feb13_032356|    -- Evaluated 64 individuals.
21Feb13_032356|    Summary of generation 7:
21Feb13_032356| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_032356|-----------  ------------------  --------------------  ----------
21Feb13_032356|    Max            39.13                44.00           0.62383
21Feb13_032356|    Avg            38.55                 4.81           0.01040
21Feb13_032356|    Min            23.30                 2.00           0.00000
21Feb13_032356|    Std             1.92                 6.51           0.07736
21Feb13_032356|   Best            23.30                44.00           0.62383
21Feb13_032356|-- Generation 8 --
21Feb13_032356|    -- Crossed 9 individual pairs.
21Feb13_032356|    -- Mutated 32 individuals.
21Feb13_032748|    -- Evaluated 64 individuals.
21Feb13_032748|    Summary of generation 8:
21Feb13_032748| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_032748|-----------  ------------------  --------------------  ----------
21Feb13_032748|    Max            39.48                44.00           0.03062
21Feb13_032748|    Avg            38.81                 5.88           0.00065
21Feb13_032748|    Min            37.91                 2.00           0.00000
21Feb13_032748|    Std             0.17                 7.71           0.00402
21Feb13_032748|   Best            37.91                24.00           0.03062
21Feb13_032748|-- Generation 9 --
21Feb13_032748|    -- Crossed 9 individual pairs.
21Feb13_032748|    -- Mutated 32 individuals.
21Feb13_033138|    -- Evaluated 64 individuals.
21Feb13_033138|    Summary of generation 9:
21Feb13_033138| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_033138|-----------  ------------------  --------------------  ----------
21Feb13_033138|    Max            38.96                27.00           0.02508
21Feb13_033138|    Avg            38.78                 3.84           0.00039
21Feb13_033138|    Min            38.09                 2.00           0.00000
21Feb13_033138|    Std             0.10                 4.86           0.00311
21Feb13_033138|   Best            38.09                24.00           0.02508
21Feb13_033138|-- Generation 10 --
21Feb13_033138|    -- Crossed 9 individual pairs.
21Feb13_033138|    -- Mutated 32 individuals.
21Feb13_033528|    -- Evaluated 64 individuals.
21Feb13_033528|    Summary of generation 10:
21Feb13_033528| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_033528|-----------  ------------------  --------------------  ----------
21Feb13_033528|    Max            39.48                27.00           0.80025
21Feb13_033528|    Avg            38.61                 4.27           0.01298
21Feb13_033528|    Min            26.61                 2.00           0.00000
21Feb13_033528|    Std             1.52                 5.16           0.09924
21Feb13_033528|   Best            26.61                10.00           0.80025
21Feb13_033528|-- Generation 11 --
21Feb13_033528|    -- Crossed 11 individual pairs.
21Feb13_033528|    -- Mutated 32 individuals.
21Feb13_033920|    -- Evaluated 64 individuals.
21Feb13_033920|    Summary of generation 11:
21Feb13_033920| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_033920|-----------  ------------------  --------------------  ----------
21Feb13_033920|    Max            39.13                27.00           0.02786
21Feb13_033920|    Avg            38.79                 5.11           0.00044
21Feb13_033920|    Min            38.00                 2.00           0.00000
21Feb13_033920|    Std             0.12                 5.56           0.00345
21Feb13_033920|   Best            38.00                24.00           0.02786
21Feb13_033920|-- Generation 12 --
21Feb13_033920|    -- Crossed 5 individual pairs.
21Feb13_033920|    -- Mutated 32 individuals.
21Feb13_034311|    -- Evaluated 64 individuals.
21Feb13_034311|    Summary of generation 12:
21Feb13_034311| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_034311|-----------  ------------------  --------------------  ----------
21Feb13_034311|    Max            38.96                27.00           0.79298
21Feb13_034311|    Avg            38.65                 4.14           0.01283
21Feb13_034311|    Min            30.78                 2.00           0.00000
21Feb13_034311|    Std             1.00                 5.12           0.09835
21Feb13_034311|   Best            30.78                 8.00           0.79298
21Feb13_034311|-- Generation 13 --
21Feb13_034311|    -- Crossed 6 individual pairs.
21Feb13_034311|    -- Mutated 32 individuals.
21Feb13_034703|    -- Evaluated 64 individuals.
21Feb13_034703|    Summary of generation 13:
21Feb13_034703| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_034703|-----------  ------------------  --------------------  ----------
21Feb13_034703|    Max            39.48                24.00           0.00560
21Feb13_034703|    Avg            38.80                 4.02           0.00009
21Feb13_034703|    Min            38.70                 2.00           0.00000
21Feb13_034703|    Std             0.09                 4.84           0.00069
21Feb13_034703|   Best            38.70                24.00           0.00560
21Feb13_034703|-- Generation 14 --
21Feb13_034703|    -- Crossed 7 individual pairs.
21Feb13_034703|    -- Mutated 32 individuals.
21Feb13_035055|    -- Evaluated 64 individuals.
21Feb13_035055|    Summary of generation 14:
21Feb13_035055| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_035055|-----------  ------------------  --------------------  ----------
21Feb13_035055|    Max            39.13                24.00           0.02508
21Feb13_035055|    Avg            38.77                 4.38           0.00078
21Feb13_035055|    Min            38.09                 2.00           0.00000
21Feb13_035055|    Std             0.14                 4.91           0.00436
21Feb13_035055|   Best            38.09                 8.00           0.02508
21Feb13_035055|-- Generation 15 --
21Feb13_035055|    -- Crossed 7 individual pairs.
21Feb13_035055|    -- Mutated 32 individuals.
21Feb13_035446|    -- Evaluated 64 individuals.
21Feb13_035446|    Summary of generation 15:
21Feb13_035446| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_035446|-----------  ------------------  --------------------  ----------
21Feb13_035446|    Max            38.87                40.00           0.02508
21Feb13_035446|    Avg            38.77                 4.59           0.00039
21Feb13_035446|    Min            38.09                 2.00           0.00000
21Feb13_035446|    Std             0.09                 6.20           0.00311
21Feb13_035446|   Best            38.09                24.00           0.02508
21Feb13_035446|-- Generation 16 --
21Feb13_035446|    -- Crossed 6 individual pairs.
21Feb13_035446|    -- Mutated 32 individuals.
21Feb13_035838|    -- Evaluated 64 individuals.
21Feb13_035838|    Summary of generation 16:
21Feb13_035838| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_035838|-----------  ------------------  --------------------  ----------
21Feb13_035838|    Max            39.04                24.00           0.36592
21Feb13_035838|    Avg            38.62                 4.47           0.00611
21Feb13_035838|    Min            28.70                 2.00           0.00000
21Feb13_035838|    Std             1.25                 5.12           0.04544
21Feb13_035838|   Best            28.70                24.00           0.36592
21Feb13_035838|-- Generation 17 --
21Feb13_035838|    -- Crossed 6 individual pairs.
21Feb13_035838|    -- Mutated 32 individuals.
21Feb13_040228|    -- Evaluated 64 individuals.
21Feb13_040228|    Summary of generation 17:
21Feb13_040228| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_040228|-----------  ------------------  --------------------  ----------
21Feb13_040228|    Max            39.39                27.00           0.78244
21Feb13_040228|    Avg            38.35                 4.77           0.02126
21Feb13_040228|    Min            24.52                 2.00           0.00000
21Feb13_040228|    Std             2.35                 5.99           0.11597
21Feb13_040228|   Best            24.52                 8.00           0.78244
21Feb13_040228|-- Generation 18 --
21Feb13_040228|    -- Crossed 6 individual pairs.
21Feb13_040228|    -- Mutated 32 individuals.
21Feb13_040617|    -- Evaluated 64 individuals.
21Feb13_040617|    Summary of generation 18:
21Feb13_040617| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_040617|-----------  ------------------  --------------------  ----------
21Feb13_040617|    Max            38.96                24.00           0.38246
21Feb13_040617|    Avg            38.46                 4.81           0.01194
21Feb13_040617|    Min            28.09                 2.00           0.00000
21Feb13_040617|    Std             1.83                 5.58           0.06459
21Feb13_040617|   Best            28.09                10.00           0.38246
21Feb13_040617|-- Generation 19 --
21Feb13_040617|    -- Crossed 8 individual pairs.
21Feb13_040617|    -- Mutated 32 individuals.
21Feb13_041008|    -- Evaluated 64 individuals.
21Feb13_041008|    Summary of generation 19:
21Feb13_041008| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_041008|-----------  ------------------  --------------------  ----------
21Feb13_041008|    Max            39.13                52.00           0.60409
21Feb13_041008|    Avg            38.41                 4.73           0.01831
21Feb13_041008|    Min            25.57                 2.00           0.00000
21Feb13_041008|    Std             2.15                 7.36           0.09987
21Feb13_041008|   Best            25.57                10.00           0.60409
21Feb13_041008|-- Generation 20 --
21Feb13_041008|    -- Crossed 7 individual pairs.
21Feb13_041008|    -- Mutated 32 individuals.
21Feb13_041359|    -- Evaluated 64 individuals.
21Feb13_041359|    Summary of generation 20:
21Feb13_041359| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_041359|-----------  ------------------  --------------------  ----------
21Feb13_041359|    Max            48.43                27.00           0.79892
21Feb13_041359|    Avg            38.54                 4.28           0.02892
21Feb13_041359|    Min            25.91                 2.00           0.00000
21Feb13_041359|    Std             2.56                 5.03           0.13336
21Feb13_041359|   Best            25.91                10.00           0.54119
21Feb13_041359|-- Generation 21 --
21Feb13_041359|    -- Crossed 9 individual pairs.
21Feb13_041359|    -- Mutated 32 individuals.
21Feb13_041749|    -- Evaluated 64 individuals.
21Feb13_041749|    Summary of generation 21:
21Feb13_041749| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_041749|-----------  ------------------  --------------------  ----------
21Feb13_041749|    Max            39.04                24.00           0.53237
21Feb13_041749|    Avg            38.22                 3.70           0.02216
21Feb13_041749|    Min            25.48                 2.00           0.00000
21Feb13_041749|    Std             2.61                 3.98           0.10045
21Feb13_041749|   Best            25.48                10.00           0.46836
21Feb13_041749|-- Generation 22 --
21Feb13_041749|    -- Crossed 7 individual pairs.
21Feb13_041749|    -- Mutated 32 individuals.
21Feb13_042139|    -- Evaluated 64 individuals.
21Feb13_042139|    Summary of generation 22:
21Feb13_042139| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_042139|-----------  ------------------  --------------------  ----------
21Feb13_042139|    Max            39.04                14.00           0.71738
21Feb13_042139|    Avg            38.06                 4.22           0.03160
21Feb13_042139|    Min            26.09                 2.00           0.00000
21Feb13_042139|    Std             2.83                 3.90           0.12657
21Feb13_042139|   Best            26.09                10.00           0.53125
21Feb13_042139|-- Generation 23 --
21Feb13_042139|    -- Crossed 7 individual pairs.
21Feb13_042139|    -- Mutated 32 individuals.
21Feb13_042530|    -- Evaluated 64 individuals.
21Feb13_042530|    Summary of generation 23:
21Feb13_042530| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_042530|-----------  ------------------  --------------------  ----------
21Feb13_042530|    Max            39.04                30.00           0.75267
21Feb13_042530|    Avg            37.72                 5.12           0.05032
21Feb13_042530|    Min            25.22                 2.00           0.00000
21Feb13_042530|    Std             3.43                 5.37           0.16589
21Feb13_042530|   Best            25.22                 8.00           0.52619
21Feb13_042530|-- Generation 24 --
21Feb13_042530|    -- Crossed 6 individual pairs.
21Feb13_042530|    -- Mutated 32 individuals.
21Feb13_042921|    -- Evaluated 64 individuals.
21Feb13_042921|    Summary of generation 24:
21Feb13_042921| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_042921|-----------  ------------------  --------------------  ----------
21Feb13_042921|    Max            39.04                48.00           0.71366
21Feb13_042921|    Avg            37.66                 6.61           0.05071
21Feb13_042921|    Min            25.39                 2.00           0.00000
21Feb13_042921|    Std             3.56                 8.69           0.16184
21Feb13_042921|   Best            25.39                 8.00           0.52950
21Feb13_042921|-- Generation 25 --
21Feb13_042921|    -- Crossed 3 individual pairs.
21Feb13_042921|    -- Mutated 32 individuals.
21Feb13_043313|    -- Evaluated 64 individuals.
21Feb13_043313|    Summary of generation 25:
21Feb13_043313| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_043313|-----------  ------------------  --------------------  ----------
21Feb13_043313|    Max            39.48                27.00           0.80008
21Feb13_043313|    Avg            37.50                 5.69           0.05535
21Feb13_043313|    Min            22.09                 2.00           0.00000
21Feb13_043313|    Std             4.03                 5.75           0.16845
21Feb13_043313|   Best            22.09                27.00           0.59751
21Feb13_043313|-- Generation 26 --
21Feb13_043313|    -- Crossed 8 individual pairs.
21Feb13_043313|    -- Mutated 32 individuals.
21Feb13_043706|    -- Evaluated 64 individuals.
21Feb13_043706|    Summary of generation 26:
21Feb13_043706| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_043706|-----------  ------------------  --------------------  ----------
21Feb13_043706|    Max            40.26                44.00           0.72731
21Feb13_043706|    Avg            37.47                 6.27           0.05706
21Feb13_043706|    Min            23.74                 2.00           0.00000
21Feb13_043706|    Std             3.93                 7.75           0.16684
21Feb13_043706|   Best            23.74                27.00           0.54585
21Feb13_043706|-- Generation 27 --
21Feb13_043706|    -- Crossed 9 individual pairs.
21Feb13_043706|    -- Mutated 32 individuals.
21Feb13_044059|    -- Evaluated 64 individuals.
21Feb13_044059|    Summary of generation 27:
21Feb13_044059| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_044059|-----------  ------------------  --------------------  ----------
21Feb13_044059|    Max            38.87                44.00           0.54680
21Feb13_044059|    Avg            37.31                 7.42           0.05539
21Feb13_044059|    Min            25.13                 2.00           0.00000
21Feb13_044059|    Std             3.94                 9.66           0.14861
21Feb13_044059|   Best            25.13                27.00           0.46523
21Feb13_044059|-- Generation 28 --
21Feb13_044059|    -- Crossed 5 individual pairs.
21Feb13_044059|    -- Mutated 32 individuals.
21Feb13_044453|    -- Evaluated 64 individuals.
21Feb13_044453|    Summary of generation 28:
21Feb13_044453| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_044453|-----------  ------------------  --------------------  ----------
21Feb13_044453|    Max            39.04                44.00           0.62844
21Feb13_044453|    Avg            36.74                 7.55           0.07961
21Feb13_044453|    Min            23.39                 2.00           0.00000
21Feb13_044453|    Std             4.82                 9.45           0.18761
21Feb13_044453|   Best            23.39                27.00           0.54120
21Feb13_044453|-- Generation 29 --
21Feb13_044453|    -- Crossed 5 individual pairs.
21Feb13_044453|    -- Mutated 32 individuals.
21Feb13_044848|    -- Evaluated 64 individuals.
21Feb13_044848|    Summary of generation 29:
21Feb13_044848| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_044848|-----------  ------------------  --------------------  ----------
21Feb13_044848|    Max            39.83                52.00           0.60556
21Feb13_044848|    Avg            37.13                 9.59           0.06633
21Feb13_044848|    Min            23.48                 2.00           0.00000
21Feb13_044848|    Std             4.33                11.46           0.16913
21Feb13_044848|   Best            23.48                10.00           0.60556
21Feb13_044848|-- Generation 30 --
21Feb13_044848|    -- Crossed 5 individual pairs.
21Feb13_044848|    -- Mutated 32 individuals.
21Feb13_045241|    -- Evaluated 64 individuals.
21Feb13_045241|    Summary of generation 30:
21Feb13_045241| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_045241|-----------  ------------------  --------------------  ----------
21Feb13_045241|    Max            39.04                44.00           0.78592
21Feb13_045241|    Avg            36.42                 8.02           0.09568
21Feb13_045241|    Min            23.65                 2.00           0.00000
21Feb13_045241|    Std             5.00                10.82           0.20555
21Feb13_045241|   Best            23.65                10.00           0.57968
21Feb13_045241|-- Generation 31 --
21Feb13_045241|    -- Crossed 10 individual pairs.
21Feb13_045241|    -- Mutated 32 individuals.
21Feb13_045635|    -- Evaluated 64 individuals.
21Feb13_045635|    Summary of generation 31:
21Feb13_045635| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_045635|-----------  ------------------  --------------------  ----------
21Feb13_045635|    Max            39.13                44.00           0.56214
21Feb13_045635|    Avg            37.25                 8.53           0.05905
21Feb13_045635|    Min            25.13                 2.00           0.00000
21Feb13_045635|    Std             4.13                11.95           0.15808
21Feb13_045635|   Best            25.13                 8.00           0.48738
21Feb13_045635|-- Generation 32 --
21Feb13_045635|    -- Crossed 4 individual pairs.
21Feb13_045635|    -- Mutated 32 individuals.
21Feb13_050029|    -- Evaluated 64 individuals.
21Feb13_050029|    Summary of generation 32:
21Feb13_050029| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_050029|-----------  ------------------  --------------------  ----------
21Feb13_050029|    Max            39.04                44.00           0.58573
21Feb13_050029|    Avg            36.31                 7.84           0.09408
21Feb13_050029|    Min            24.43                 2.00           0.00000
21Feb13_050029|    Std             5.20                12.10           0.19729
21Feb13_050029|   Best            24.43                44.00           0.52272
21Feb13_050029|Best initial individual weights
21Feb13_050029|Individual:
21Feb13_050029|-- Constant hidden layers --
21Feb13_050029|False
21Feb13_050029|Layer 0:
21Feb13_050029|-- Config --
21Feb13_050029|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 15, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050029|-- Weights --
21Feb13_050029|[[ 9.73296e-01 -8.26784e-01 -2.96439e-01 -5.24875e-01 -9.75570e-01
21Feb13_050029|   5.94797e-01  6.56579e-01 -3.55245e-01 -2.06319e-01  7.24525e-02
21Feb13_050029|  -8.18340e-01  3.72301e-01 -8.88903e-01  8.38473e-01 -1.36175e-01]
21Feb13_050029| [ 9.00747e-01 -4.73475e-01 -5.86061e-01 -9.96560e-01 -9.08973e-01
21Feb13_050029|   7.36703e-01 -5.66014e-02 -4.95681e-01 -2.37518e-01  7.36167e-01
21Feb13_050029|   1.18646e-01 -9.34807e-01  1.14774e-01 -1.67031e-01  3.02418e-02]
21Feb13_050029| [-2.75124e-01 -2.99372e-01  2.96611e-03  2.17706e-01  2.22480e-01
21Feb13_050029|   2.85044e-02  3.03819e-01 -3.38706e-02 -2.90173e-01 -2.69699e-01
21Feb13_050029|  -7.85345e-02 -1.49466e-01  3.23384e-01 -1.80370e-01 -2.99972e-01]
21Feb13_050029| [-5.80245e-01  9.85830e-01  1.17641e-03  1.65423e-01 -6.59634e-01
21Feb13_050029|  -3.71185e-01 -7.27571e-01 -1.00209e-01  8.64598e-01 -6.10691e-01
21Feb13_050029|   7.19932e-01  3.21970e-01 -7.00390e-01 -7.10769e-01  2.95705e-01]
21Feb13_050029| [-8.73382e-01  9.76324e-01  8.48430e-02  9.25840e-01 -2.02163e-01
21Feb13_050029|  -1.87887e-01  2.81858e-01  1.43536e-01 -3.05554e-01 -6.69890e-01
21Feb13_050029|   1.58904e-01 -8.97804e-01 -1.32196e-01 -7.37863e-01 -1.90775e-01]
21Feb13_050029| [ 5.44972e-01 -7.61313e-01  4.93506e-01  3.85686e-01 -5.60992e-01
21Feb13_050029|  -4.78222e-01 -5.32042e-01  7.25155e-02 -3.72247e-02  4.27292e-01
21Feb13_050029|   3.62496e-01  2.23487e-01  7.55995e-01  8.53424e-01 -3.57402e-01]
21Feb13_050029| [ 2.69735e-01 -7.35381e-01  8.58039e-01  5.50856e-01 -8.98355e-01
21Feb13_050029|   2.29710e-01 -4.68342e-01  6.32265e-02  1.29601e-02 -8.69018e-01
21Feb13_050029|  -2.73360e-01  2.64992e-01  6.92574e-01 -1.80612e-01 -6.18940e-01]
21Feb13_050029| [ 5.32712e-01 -3.07491e-01 -8.59999e-01 -9.69560e-01  9.74953e-01
21Feb13_050029|   5.11015e-02  4.92610e-01 -7.25292e-01  7.13820e-01 -1.43535e-02
21Feb13_050029|   7.27951e-01  7.71337e-02  8.45383e-01  6.68537e-01 -4.33622e-01]
21Feb13_050029| [-1.09130e-01  5.41333e-01  4.93394e-01  8.63442e-01  8.53343e-01
21Feb13_050029|  -1.12858e-01  7.37356e-01 -4.42087e-02  8.30579e-01  1.38212e-01
21Feb13_050029|   9.88480e-02  7.51784e-01  5.54371e-01  8.47549e-01  8.13372e-02]
21Feb13_050029| [-5.42155e-01 -4.32240e-01 -5.86458e-02 -1.28264e-02  5.78083e-01
21Feb13_050029|   1.68026e-01 -9.11094e-01  4.58106e-01  6.00229e-01  2.17770e-01
21Feb13_050029|   4.34134e-01 -8.53385e-02  4.69495e-01 -2.96878e-01  4.59397e-01]
21Feb13_050029| [-5.68827e-01 -9.10070e-01 -9.04407e-01  7.15505e-01 -1.18063e-01
21Feb13_050029|   2.92277e-03  3.96874e-01 -7.57933e-01  1.39258e-01 -7.48572e-01
21Feb13_050029|   9.76774e-01 -3.96754e-01 -3.75098e-02 -8.37290e-01 -9.68913e-01]
21Feb13_050029| [ 3.85405e-01 -1.66417e-01 -7.72831e-01  5.34828e-01  5.82538e-01
21Feb13_050029|   2.61182e-01 -1.77447e-01 -6.45280e-01 -3.56417e-01 -4.00832e-01
21Feb13_050029|  -9.18095e-01  5.40437e-01  7.49226e-01  3.72730e-01  6.82412e-01]
21Feb13_050029| [-5.90300e-01  5.47573e-01 -2.29506e-02  1.97113e-01 -9.92234e-01
21Feb13_050029|  -4.27465e-01  5.90379e-01  2.70200e-01  3.00202e-01  5.73789e-01
21Feb13_050029|  -2.95641e-01  5.78653e-01 -1.94578e-01  3.61894e-01  6.34740e-02]
21Feb13_050029| [ 2.26425e-01  4.30697e-01 -7.48931e-01  1.34168e-01 -6.17358e-02
21Feb13_050029|   1.86230e-01  7.52588e-01 -3.89451e-01  8.39574e-01  5.82897e-01
21Feb13_050029|  -1.13470e-02 -8.19377e-01 -8.18108e-01  6.24046e-01 -5.54897e-01]
21Feb13_050029| [-5.26836e-01  5.86005e-01 -5.96458e-01 -6.81120e-01  1.84856e-01
21Feb13_050029|   4.96869e-01 -1.31473e-01  4.40657e-01  6.64130e-01  6.22928e-01
21Feb13_050029|  -7.74363e-02 -3.55086e-01 -2.82231e-01  6.46269e-01  1.75388e-01]
21Feb13_050029| [-7.76956e-01 -3.86536e-01  4.36460e-01 -9.92290e-01  7.38722e-02
21Feb13_050029|   7.04992e-01  1.61774e-01 -6.96625e-01 -1.82122e-02  4.77476e-01
21Feb13_050029|   6.36754e-01  1.11465e-01  5.77527e-01  1.58442e-01 -6.62716e-01]
21Feb13_050029| [ 3.47724e-01 -3.90904e-01 -6.29011e-02 -2.04190e-01 -6.92395e-01
21Feb13_050029|  -5.16254e-01  7.11614e-01 -8.77321e-01 -4.47844e-01  7.31159e-01
21Feb13_050029|  -8.28271e-01 -3.51425e-01  6.37538e-01  5.04277e-01  3.92425e-01]
21Feb13_050029| [ 7.75524e-01 -9.01971e-01 -8.17344e-01  9.65231e-01 -2.42290e-01
21Feb13_050029|  -4.48188e-01 -7.58196e-01  1.21021e-01 -4.30787e-01  1.16232e-01
21Feb13_050029|  -1.88406e-01 -3.28890e-01 -8.98977e-01 -3.63500e-02  2.86674e-01]
21Feb13_050029| [-8.40432e-01 -6.71444e-02 -3.73544e-01  1.66693e-01 -8.24864e-01
21Feb13_050029|  -8.87827e-01 -4.18794e-01 -3.81438e-01 -9.71525e-01 -9.80858e-01
21Feb13_050029|   1.13439e-01  2.81032e-01 -4.22822e-01 -2.04687e-01  1.75317e-01]
21Feb13_050029| [-4.20436e-01  2.57572e-01 -3.07821e-01  6.44066e-01  7.91418e-01
21Feb13_050029|  -6.82975e-01  3.42860e-01 -6.44128e-02 -9.34328e-01  7.62391e-02
21Feb13_050029|  -9.59002e-01  8.34106e-02 -8.89504e-01 -1.49882e-01 -1.11396e-01]
21Feb13_050029| [ 6.98833e-01  1.54037e-01  3.14249e-01 -5.01089e-01 -6.44545e-01
21Feb13_050029|   1.55008e-01 -1.94187e-01 -5.94875e-01 -7.36832e-01  8.21613e-02
21Feb13_050029|   3.41441e-02 -4.42761e-02  4.77304e-02 -2.91558e-01  2.88672e-01]
21Feb13_050029| [ 2.48630e-01  5.01011e-01 -6.50631e-01 -6.13626e-02 -9.30021e-01
21Feb13_050029|   5.18612e-01 -4.27695e-01 -5.21728e-01 -2.97082e-01 -9.57096e-01
21Feb13_050029|  -1.21237e-04  6.69464e-01 -6.15966e-01  6.54204e-01  5.66081e-01]
21Feb13_050029| [-9.53841e-01 -8.01340e-01 -9.16434e-01  2.57455e-01 -8.96467e-01
21Feb13_050029|   7.80358e-01  4.63009e-01  5.06015e-01 -3.73053e-01  3.37301e-01
21Feb13_050029|  -2.34600e-01  5.09622e-01 -3.02048e-01 -6.64473e-01 -1.98920e-01]
21Feb13_050029| [-2.18071e-01  2.15106e-01 -9.50319e-01 -9.11332e-01 -9.18482e-01
21Feb13_050029|   1.26622e-01  5.92950e-01  6.93913e-01 -7.25339e-01  2.36405e-01
21Feb13_050029|  -2.83842e-01 -9.08534e-01  2.60791e-01 -4.92172e-01  6.25202e-01]
21Feb13_050029| [ 3.22399e-01  5.30300e-01 -6.82594e-01 -6.29378e-02 -2.78435e-01
21Feb13_050029|   4.91838e-01  2.99825e-02 -8.64897e-01  6.09917e-01  9.09602e-01
21Feb13_050029|   5.44039e-01 -3.00486e-01 -3.32137e-01 -3.21246e-02  8.14287e-01]
21Feb13_050029| [ 9.87171e-01  4.36304e-01  9.80301e-01 -9.56450e-01  5.23598e-01
21Feb13_050029|  -3.00486e-01 -9.81154e-01  6.47157e-01 -6.02031e-01  7.81558e-01
21Feb13_050029|  -2.30610e-01  2.44907e-01  4.19133e-01  2.22724e-01 -8.17960e-01]
21Feb13_050029| [-7.00505e-01  3.02186e-01 -5.61855e-01  6.15549e-01 -4.22791e-01
21Feb13_050029|   3.88411e-01 -5.82917e-01 -7.77882e-01  6.30600e-01 -1.96906e-01
21Feb13_050029|  -3.88054e-02 -5.55807e-01  8.92183e-01  8.21948e-01  1.74197e-01]
21Feb13_050029| [-4.47370e-01  2.05525e-01 -5.62731e-01 -1.98036e-01  2.28871e-01
21Feb13_050029|  -3.83538e-01 -8.13049e-01 -5.91726e-01 -4.19478e-01  7.08680e-01
21Feb13_050029|   2.83808e-01 -7.78897e-01 -5.65193e-01  3.84515e-01 -7.96749e-02]
21Feb13_050029| [-4.81320e-01 -1.73693e-01  3.48146e-01 -9.81670e-01  1.37818e-01
21Feb13_050029|  -2.34945e-01  1.61326e-01 -8.27229e-01 -1.04174e-02 -7.75256e-01
21Feb13_050029|   8.52992e-01 -4.99718e-01 -6.70967e-01 -2.25740e-01 -1.50898e-01]
21Feb13_050029| [ 3.84415e-01 -6.97226e-01 -1.51865e-01  9.18693e-01 -1.77648e-01
21Feb13_050029|   1.22856e-01  8.70082e-01 -6.18862e-01  9.34392e-02 -7.34260e-01
21Feb13_050029|  -5.19661e-01 -9.84020e-01  8.89976e-01 -9.22672e-01 -8.30637e-01]
21Feb13_050029| [-4.54498e-01  9.73784e-01  9.14263e-01 -9.59356e-01  7.62535e-01
21Feb13_050029|   3.81394e-01 -7.75235e-01 -2.75059e-01  7.53859e-01  3.38388e-01
21Feb13_050029|   8.59783e-01  2.10799e-01  3.38360e-01  8.62964e-01 -5.82977e-01]
21Feb13_050029| [ 1.92625e-01 -3.99306e-01  1.07271e-01 -4.51425e-01  4.70392e-01
21Feb13_050029|  -7.65438e-01  6.60993e-01 -8.01258e-01  4.67186e-01 -3.16915e-01
21Feb13_050029|   2.94527e-01 -5.33788e-01 -7.45073e-01 -8.42078e-01 -5.44571e-01]
21Feb13_050029| [-3.62993e-01  1.11266e-01 -5.71362e-01 -3.91574e-01 -9.61148e-01
21Feb13_050029|  -2.90496e-01  8.31183e-01 -3.84938e-01  2.69751e-01 -3.15175e-01
21Feb13_050029|   9.99210e-01 -9.53149e-01 -8.61738e-01  7.70126e-02  5.10691e-01]
21Feb13_050029| [ 8.05352e-01 -4.08977e-01 -9.07560e-01 -8.64653e-01 -1.07789e-01
21Feb13_050029|   2.64140e-01  5.05728e-01  7.48289e-01 -8.65071e-01 -8.18224e-01
21Feb13_050029|   6.78505e-02 -5.06326e-01  1.10690e-01 -8.55440e-01  5.75289e-01]
21Feb13_050029| [ 2.95517e-01 -3.52707e-01 -6.55711e-01  1.07292e-01 -2.91000e-01
21Feb13_050029|  -3.16299e-01  1.98809e-01  5.17179e-01 -9.37755e-01 -6.17104e-01
21Feb13_050029|   7.41318e-01  2.47303e-01  6.90518e-01  3.51857e-01  2.81666e-01]
21Feb13_050029| [ 1.69992e-01  6.04754e-01 -1.32633e-01  6.79534e-01  5.85447e-01
21Feb13_050029|  -6.69632e-01  8.55732e-01 -7.23004e-02  7.71841e-01  5.93699e-01
21Feb13_050029|  -4.01829e-01  2.99000e-01 -2.48420e-01  1.69612e-01  2.61404e-01]
21Feb13_050029| [-4.65263e-01 -5.50757e-01 -2.30908e-02  3.64198e-01  3.79782e-01
21Feb13_050029|  -2.25316e-01  3.04353e-01 -2.00693e-01 -1.18218e-01 -5.52641e-01
21Feb13_050029|   7.10195e-01  8.06878e-01 -5.65174e-01 -4.26162e-01  3.95536e-01]
21Feb13_050029| [-5.61400e-01 -3.19431e-01  2.72779e-01 -1.29018e-01  7.70589e-02
21Feb13_050029|   3.21503e-01 -5.90943e-01  4.24158e-01 -7.05493e-01  5.09745e-01
21Feb13_050029|  -2.41282e-01  4.55611e-01  7.72834e-01 -9.97347e-01 -8.58771e-01]
21Feb13_050029| [-5.46366e-01 -4.86772e-01 -8.62551e-01  7.62475e-01 -1.98789e-03
21Feb13_050029|  -1.56016e-01  3.51919e-01  2.74028e-01 -9.67446e-01  4.31075e-01
21Feb13_050029|  -4.27418e-01 -3.50042e-01 -1.95930e-01 -2.47653e-01  7.98394e-01]
21Feb13_050029| [ 2.03791e-01  9.03027e-01  9.67784e-01 -4.00270e-02 -2.59716e-01
21Feb13_050029|  -7.18872e-01  9.82093e-01  2.10782e-01  9.91966e-01  7.67815e-01
21Feb13_050029|  -3.25024e-01  5.85259e-01 -2.21643e-01 -1.67125e-02  9.36688e-01]
21Feb13_050029| [ 3.16211e-01  9.76470e-01  7.94325e-01 -9.00416e-01  6.98898e-01
21Feb13_050029|  -8.42106e-01  6.75991e-01 -6.32115e-02 -3.58262e-01  2.18246e-01
21Feb13_050029|  -4.13471e-01  9.79392e-02  4.02862e-01  8.14727e-01 -7.43809e-01]
21Feb13_050029| [-4.14597e-01  7.51673e-01  8.43107e-01 -8.56637e-01  2.01330e-01
21Feb13_050029|   5.15009e-01  5.18579e-01  3.77743e-01 -4.70931e-01  8.27614e-01
21Feb13_050029|  -1.84439e-01 -5.43885e-01 -6.03771e-01  1.66381e-01 -2.62433e-01]
21Feb13_050029| [-3.30904e-01 -8.97996e-01  5.59354e-01  9.82660e-01  4.72646e-01
21Feb13_050029|  -3.88086e-01 -3.61082e-01 -3.33936e-01  8.38158e-01  1.00179e-01
21Feb13_050029|   1.36844e-01 -9.95933e-01  6.20488e-01 -6.12446e-01 -2.16831e-01]
21Feb13_050029| [ 9.34249e-01  9.58289e-01 -5.59786e-01  2.63487e-01  3.40624e-01
21Feb13_050029|  -8.82567e-01 -1.87162e-01  9.71567e-01 -1.62228e-01 -5.14816e-02
21Feb13_050029|  -6.15566e-01 -2.21997e-01 -6.32714e-01  3.35681e-01 -7.22899e-01]
21Feb13_050029| [ 1.81650e-01  5.38812e-01 -5.84369e-01  1.83511e-01 -4.73145e-01
21Feb13_050029|   3.69120e-01 -6.10032e-01  5.04085e-01  6.79257e-01  6.97438e-01
21Feb13_050029|   9.97907e-01  3.05666e-01  4.40567e-01  9.43295e-01 -9.02163e-01]
21Feb13_050029| [-1.70947e-01  6.56286e-02 -7.70618e-01  7.44355e-01  6.43106e-01
21Feb13_050029|  -9.22310e-01 -9.79288e-01 -3.81965e-01  3.86344e-01  1.77963e-01
21Feb13_050029|  -3.30390e-01  7.61288e-01  3.33913e-01  5.64535e-01 -5.40325e-01]
21Feb13_050029| [-9.32116e-01  9.90939e-01 -3.30869e-01 -4.27293e-01  7.10723e-01
21Feb13_050029|  -2.31364e-01 -3.76768e-01 -9.93003e-01 -6.60679e-01  8.88879e-01
21Feb13_050029|  -6.39983e-02  1.51892e-01  8.99858e-01  8.00668e-01 -2.98412e-01]
21Feb13_050029| [-2.10118e-01  6.98032e-01  9.37825e-01  8.81575e-01  4.77957e-01
21Feb13_050029|  -9.19276e-01  8.17147e-01  5.26491e-01  4.95066e-01 -8.77804e-01
21Feb13_050029|   1.84540e-01  7.53370e-01 -8.47736e-01 -3.26258e-01  2.71438e-01]
21Feb13_050029| [-7.34106e-01  5.52282e-02  1.81606e-01 -1.03917e-01 -9.16647e-01
21Feb13_050029|  -5.73562e-01  5.39510e-01  1.66977e-01  4.48250e-01 -3.24674e-01
21Feb13_050029|   1.39795e-01  2.34226e-01  4.90799e-01 -7.05583e-01  7.14680e-01]
21Feb13_050029| [-8.37392e-01 -4.18274e-02 -4.14411e-01  4.09715e-01  7.44756e-01
21Feb13_050029|  -7.58552e-01 -8.70333e-01 -6.49756e-01  8.63765e-01 -4.23482e-01
21Feb13_050029|   7.87457e-01 -9.43614e-01  4.77426e-01  6.69989e-01  2.31675e-01]
21Feb13_050029| [-7.69917e-01  2.98477e-01 -9.92047e-01  3.57645e-01  3.18108e-01
21Feb13_050029|   3.05468e-01  5.89527e-01 -1.31507e-01 -8.62127e-01  7.60717e-01
21Feb13_050029|  -5.18226e-01  4.94369e-01 -8.24036e-01 -4.43348e-01 -1.55927e-01]
21Feb13_050029| [ 9.10501e-01 -7.45959e-03 -3.28250e-01 -3.48338e-01  1.64135e-01
21Feb13_050029|  -8.02631e-02  4.22565e-01 -8.42164e-01  3.89676e-01  5.80955e-01
21Feb13_050029|   9.83555e-01  6.38621e-01 -1.00576e-01 -7.42125e-01  7.03190e-01]
21Feb13_050029| [-1.71055e-01  1.25462e-01  3.41395e-01  1.66074e-01 -4.20132e-01
21Feb13_050029|  -7.62667e-01 -6.36091e-01  1.46176e-01 -1.03210e-01 -5.38815e-01
21Feb13_050029|   5.96929e-01 -7.47086e-01  3.78571e-02  4.13885e-01  4.94247e-01]
21Feb13_050029| [-3.35399e-02  9.35145e-01  8.04748e-01 -4.71015e-01  1.19204e-01
21Feb13_050029|  -4.47124e-02  3.23368e-01 -8.61360e-02  9.04695e-03 -2.16230e-01
21Feb13_050029|   9.73383e-03  6.40028e-02 -7.75899e-01  7.42213e-01 -2.41969e-01]
21Feb13_050029| [-4.07810e-01  5.70924e-01 -6.72329e-01 -5.14381e-01 -6.52092e-01
21Feb13_050029|  -7.42952e-01 -3.09589e-01 -9.56182e-01  9.43312e-01  5.64870e-01
21Feb13_050029|   6.42553e-01  7.94006e-01 -3.78536e-01  8.42088e-01 -4.76981e-01]
21Feb13_050029| [ 6.10318e-01 -5.75354e-01  3.73758e-01 -7.73392e-01 -9.60833e-01
21Feb13_050029|   4.27903e-01 -9.41218e-01 -6.94203e-01  6.64921e-01  2.08771e-01
21Feb13_050029|   9.91458e-01 -7.05600e-01 -4.80987e-01 -5.69879e-01 -6.07920e-01]
21Feb13_050029| [ 5.91649e-01 -4.92879e-02 -3.44790e-01 -4.70337e-01  4.26548e-01
21Feb13_050029|  -1.62878e-01 -2.02342e-01  4.02378e-01  6.11021e-01  3.01335e-01
21Feb13_050029|   4.01714e-01 -1.12789e-01  5.33867e-01 -2.31753e-01  7.09983e-01]]
21Feb13_050029|-- Bias --
21Feb13_050029|[-0.78506  0.16228 -0.33422 -0.02819  0.17937  0.59381 -0.35607  0.98170
21Feb13_050029|  0.84415 -0.36809  0.88118  0.00344 -0.36932  0.87305 -0.91166]
21Feb13_050029|Layer 1:
21Feb13_050029|-- Config --
21Feb13_050029|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 15], 'dtype': 'float32', 'units': 10, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050029|-- Weights --
21Feb13_050029|[[ 0.91951  0.13760  0.93226 -0.96100  0.36703 -0.91847  0.02090 -0.91229
21Feb13_050029|  -0.78451  0.42787]
21Feb13_050029| [ 0.18072 -0.99875 -0.90672  0.46909  0.10174 -0.28361 -0.76657 -0.44411
21Feb13_050029|   0.01587 -0.08012]
21Feb13_050029| [-0.52522  0.57842  0.64217 -0.58067  0.73633  0.43445  0.81842  0.10316
21Feb13_050029|   0.96829 -0.65906]
21Feb13_050029| [-0.74083 -0.67462 -0.56811 -0.28798 -0.39432  0.28098  0.72626 -0.36612
21Feb13_050029|  -0.96927 -0.08040]
21Feb13_050029| [ 0.21210 -0.13397 -0.84942  0.54712 -0.03219 -0.92481 -0.98810  0.89079
21Feb13_050029|   0.31637  0.53136]
21Feb13_050029| [-0.18729 -0.69744 -0.16173 -0.93613  0.96262  0.00792 -0.95445  0.32042
21Feb13_050029|  -0.36467 -0.87315]
21Feb13_050029| [-0.04314  0.07497  0.43518 -0.80082  0.93585  0.10181  0.30618  0.41458
21Feb13_050029|   0.98098 -0.73301]
21Feb13_050029| [-0.87685  0.20483  0.84988 -0.51961  0.88167  0.81532 -0.93018  0.13207
21Feb13_050029|   0.15465 -0.81578]
21Feb13_050029| [ 0.09921 -0.76754 -0.49733  0.81089  0.68214 -0.36243  0.59439 -0.15764
21Feb13_050029|  -0.74059 -0.05954]
21Feb13_050029| [-0.07392  0.53340  0.82207 -0.72043  0.38000  0.03960 -0.07042  0.29536
21Feb13_050029|   0.95278 -0.00530]
21Feb13_050029| [ 0.92473 -0.52802 -0.20280 -0.39430  0.48632  0.43274 -0.61715  0.12507
21Feb13_050029|  -0.54846 -0.46933]
21Feb13_050029| [ 0.91914  0.92132 -0.40327  0.08595  0.31134 -0.46791  0.23914  0.06850
21Feb13_050029|   0.84229  0.43934]
21Feb13_050029| [-0.04235  0.97296 -0.83341  0.13476  0.13764  0.94126 -0.34097 -0.51874
21Feb13_050029|  -0.61301  0.79707]
21Feb13_050029| [ 0.04655  0.28131 -0.46598  0.40417  0.08962  0.41710  0.97629 -0.28989
21Feb13_050029|  -0.23680 -0.34164]
21Feb13_050029| [ 0.78000 -0.40552 -0.20550  0.20903  0.41907  0.01739 -0.35840 -0.00938
21Feb13_050029|   0.63674 -0.15946]]
21Feb13_050029|-- Bias --
21Feb13_050029|[-0.79083  0.37148 -0.23368 -0.84856 -0.81550 -0.13297 -0.70006  0.83504
21Feb13_050029|  0.92083 -0.68777]
21Feb13_050029|Layer 2:
21Feb13_050029|-- Config --
21Feb13_050029|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 10], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050029|-- Weights --
21Feb13_050029|[[-0.87117 -0.98023]
21Feb13_050029| [-0.13253  0.72532]
21Feb13_050029| [-0.88656 -0.22166]
21Feb13_050029| [ 0.38520 -0.85873]
21Feb13_050029| [-0.98768 -0.34253]
21Feb13_050029| [-0.45654 -0.72139]
21Feb13_050029| [-0.55069  0.70280]
21Feb13_050029| [ 0.50509  0.57348]
21Feb13_050029| [ 0.16174  0.84480]
21Feb13_050029| [-0.22560 -0.23581]]
21Feb13_050029|-- Bias --
21Feb13_050029|[-0.53578  0.46638]
21Feb13_050029|Predicting the validation and test data with the Best initial individual.
21Feb13_050037| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_050037|-----------  ------------------  --------------------  ----------
21Feb13_050037|Validation         38.78                  50            0.00000
21Feb13_050037|   Test            38.92                  50            0.00278
21Feb13_050037|-------------------- Test #0 --------------------
21Feb13_050037|Best final individual weights
21Feb13_050037|Individual:
21Feb13_050037|-- Constant hidden layers --
21Feb13_050037|False
21Feb13_050037|Layer 0:
21Feb13_050037|-- Config --
21Feb13_050037|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050037|-- Weights --
21Feb13_050037|[[-0.64119  0.41758  0.44403]
21Feb13_050037| [-0.19170 -0.56915 -0.25835]
21Feb13_050037| [ 0.24167 -0.25140  0.76563]
21Feb13_050037| [-0.34028 -0.39268 -0.81387]
21Feb13_050037| [-1.86022 -0.52041 -0.44819]
21Feb13_050037| [ 0.38513  0.25171 -0.11380]
21Feb13_050037| [ 0.22209 -0.92597  0.19546]
21Feb13_050037| [-0.71141 -0.41559  0.24085]
21Feb13_050037| [ 0.05990  1.53864 -0.15835]
21Feb13_050037| [ 0.57521 -0.04311  0.55248]
21Feb13_050037| [ 0.86173  0.05786  0.38030]
21Feb13_050037| [ 0.73310 -0.78236  0.48030]
21Feb13_050037| [ 0.40395 -0.34893 -0.71762]
21Feb13_050037| [ 0.11846 -0.72835  1.43541]
21Feb13_050037| [-0.44861 -0.75277  0.14467]
21Feb13_050037| [ 1.41428  1.05661  0.10286]
21Feb13_050037| [-1.57835 -0.10784  0.05255]
21Feb13_050037| [-0.47421 -0.65751  0.28725]
21Feb13_050037| [ 0.72747  0.12939  0.31006]
21Feb13_050037| [-1.18189  0.27777  0.58656]
21Feb13_050037| [-1.11883 -0.35427 -0.17962]
21Feb13_050037| [ 0.39343 -0.84418 -0.51133]
21Feb13_050037| [ 1.00598  0.61810 -0.21078]
21Feb13_050037| [-0.04015 -0.79351 -0.26753]
21Feb13_050037| [-0.66727  0.28333 -0.43119]
21Feb13_050037| [-0.14585  0.91540  0.81437]
21Feb13_050037| [ 0.13566  0.49138 -0.05944]
21Feb13_050037| [-0.22291  0.86713  1.13344]
21Feb13_050037| [-1.03502  1.56032  0.35828]
21Feb13_050037| [ 0.12223  0.39820  0.44290]
21Feb13_050037| [-1.42658 -0.38599  0.26524]
21Feb13_050037| [-0.52719  1.17703  0.62097]
21Feb13_050037| [ 0.52938  0.21738 -0.06837]
21Feb13_050037| [-0.87508  2.16887  0.32327]
21Feb13_050037| [ 1.35043 -0.65136  0.02642]
21Feb13_050037| [ 1.06028  0.80071 -0.96029]
21Feb13_050037| [-1.86678  0.53951 -0.02691]
21Feb13_050037| [ 1.73320 -1.35784  0.01810]
21Feb13_050037| [-0.03018 -0.70820 -0.34020]
21Feb13_050037| [-0.65415  0.11126 -0.54490]
21Feb13_050037| [ 1.14516 -0.84749  0.70247]
21Feb13_050037| [-0.64028  0.15453 -1.10559]
21Feb13_050037| [-0.18582 -0.94763 -0.78661]
21Feb13_050037| [ 0.90123 -0.72541  1.12612]
21Feb13_050037| [ 0.42551 -0.77656 -0.45109]
21Feb13_050037| [ 0.43603  1.06729  0.60801]
21Feb13_050037| [ 1.36190 -0.56744  0.83111]
21Feb13_050037| [-0.63814  1.07761 -0.29382]
21Feb13_050037| [-2.38452 -1.49477  0.68283]
21Feb13_050037| [-0.75870 -1.11212 -1.75709]
21Feb13_050037| [-0.20420 -1.34511  0.73343]
21Feb13_050037| [-0.20964 -0.04696 -0.11643]
21Feb13_050037| [ 0.02903  1.17196  0.19512]
21Feb13_050037| [ 0.67410  0.98823  0.20455]
21Feb13_050037| [ 1.12898 -0.02920 -0.26203]
21Feb13_050037| [ 0.01925  0.39530  0.50643]
21Feb13_050037| [-0.32905 -1.23882  0.15417]]
21Feb13_050037|-- Bias --
21Feb13_050037|[-0.19062 -0.26300  0.48239]
21Feb13_050037|Layer 1:
21Feb13_050037|-- Config --
21Feb13_050037|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050037|-- Weights --
21Feb13_050037|[[ 0.14457 -0.61956]
21Feb13_050037| [ 1.29113 -0.25904]
21Feb13_050037| [-0.56150  0.30090]]
21Feb13_050037|-- Bias --
21Feb13_050037|[-1.10658  0.88662]
21Feb13_050037|Layer 2:
21Feb13_050037|-- Config --
21Feb13_050037|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050037|-- Weights --
21Feb13_050037|[[ 0.36463 -0.59654  0.07558  1.03681]
21Feb13_050037| [-0.69100  0.65045  0.69266 -0.09649]]
21Feb13_050037|-- Bias --
21Feb13_050037|[-0.34203 -0.15489 -0.67530 -0.34361]
21Feb13_050037|Layer 3:
21Feb13_050037|-- Config --
21Feb13_050037|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050037|-- Weights --
21Feb13_050037|[[ 0.74009  0.50107]
21Feb13_050037| [-0.91862  0.58181]
21Feb13_050037| [-0.52087 -0.10176]
21Feb13_050037| [-0.81097 -0.60657]]
21Feb13_050037|-- Bias --
21Feb13_050037|[-0.72207 -0.14119]
21Feb13_050037|Layer 4:
21Feb13_050037|-- Config --
21Feb13_050037|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050037|-- Weights --
21Feb13_050037|[[-0.36379  0.38387]
21Feb13_050037| [-0.13610  0.43138]]
21Feb13_050037|-- Bias --
21Feb13_050037|[-0.83070 -0.86913]
21Feb13_050037|Predicting the validation and test data with the Best final individual.
21Feb13_050045| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_050045|-----------  ------------------  --------------------  ----------
21Feb13_050045|Validation         26.26                  44            0.45000
21Feb13_050045|   Test            25.63                  44            0.51882
21Feb13_050045|-------------------- Test #1 --------------------
21Feb13_050045|Best final individual weights
21Feb13_050045|Individual:
21Feb13_050045|-- Constant hidden layers --
21Feb13_050045|False
21Feb13_050045|Layer 0:
21Feb13_050045|-- Config --
21Feb13_050045|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050045|-- Weights --
21Feb13_050045|[[-0.64119  0.41758  0.44403]
21Feb13_050045| [-0.19170 -0.56915 -0.25835]
21Feb13_050045| [ 0.24167 -0.25140  0.76563]
21Feb13_050045| [-0.34028 -0.39268 -0.81387]
21Feb13_050045| [-1.86022 -0.52041 -0.44819]
21Feb13_050045| [ 0.38513  0.25171 -0.11380]
21Feb13_050045| [ 0.22209 -0.92597  0.19546]
21Feb13_050045| [-0.71141 -0.41559  0.24085]
21Feb13_050045| [ 0.05990  1.53864 -0.15835]
21Feb13_050045| [ 0.57521 -0.04311  0.55248]
21Feb13_050045| [ 0.86173  0.05786  0.38030]
21Feb13_050045| [ 0.73310 -0.78236  0.48030]
21Feb13_050045| [ 0.40395 -0.34893 -0.71762]
21Feb13_050045| [ 0.11846 -0.72835  1.43541]
21Feb13_050045| [-0.44861 -0.75277  0.14467]
21Feb13_050045| [ 1.41428  1.05661  0.10286]
21Feb13_050045| [-1.57835 -0.10784  0.05255]
21Feb13_050045| [-0.47421 -0.65751  0.28725]
21Feb13_050045| [ 0.72747  0.12939  0.31006]
21Feb13_050045| [-1.18189  0.27777  0.58656]
21Feb13_050045| [-1.11883 -0.35427 -0.17962]
21Feb13_050045| [ 0.39343 -0.84418 -0.51133]
21Feb13_050045| [ 1.00598  0.61810 -0.21078]
21Feb13_050045| [-0.04015 -0.79351 -0.26753]
21Feb13_050045| [-0.66727  0.28333 -0.43119]
21Feb13_050045| [-0.14585  0.91540  0.81437]
21Feb13_050045| [ 0.13566  0.49138 -0.05944]
21Feb13_050045| [-0.22291  0.86713  1.13344]
21Feb13_050045| [-1.03502  1.56032  0.35828]
21Feb13_050045| [ 0.12223  0.39820  0.44290]
21Feb13_050045| [-1.42658 -0.38599  0.26524]
21Feb13_050045| [-0.52719  1.17703  0.62097]
21Feb13_050045| [ 0.52938  0.21738 -0.06837]
21Feb13_050045| [-0.87508  2.16887  0.32327]
21Feb13_050045| [ 1.35043 -0.65136  0.02642]
21Feb13_050045| [ 1.06028  0.80071 -0.96029]
21Feb13_050045| [-1.86678  0.53951 -0.02691]
21Feb13_050045| [ 1.73320 -1.35784  0.01810]
21Feb13_050045| [-0.03018 -0.70820 -0.34020]
21Feb13_050045| [-0.65415  0.11126 -0.54490]
21Feb13_050045| [ 1.14516 -0.84749  0.70247]
21Feb13_050045| [-0.64028  0.15453 -1.10559]
21Feb13_050045| [-0.18582 -0.94763 -0.78661]
21Feb13_050045| [ 0.90123 -0.72541  1.12612]
21Feb13_050045| [ 0.42551 -0.77656 -0.45109]
21Feb13_050045| [ 0.43603  1.06729  0.60801]
21Feb13_050045| [ 1.36190 -0.56744  0.83111]
21Feb13_050045| [-0.63814  1.07761 -0.29382]
21Feb13_050045| [-2.38452 -1.49477  0.68283]
21Feb13_050045| [-0.75870 -1.11212 -1.75709]
21Feb13_050045| [-0.20420 -1.34511  0.73343]
21Feb13_050045| [-0.20964 -0.04696 -0.11643]
21Feb13_050045| [ 0.02903  1.17196  0.19512]
21Feb13_050045| [ 0.67410  0.98823  0.20455]
21Feb13_050045| [ 1.12898 -0.02920 -0.26203]
21Feb13_050045| [ 0.01925  0.39530  0.50643]
21Feb13_050045| [-0.32905 -1.23882  0.15417]]
21Feb13_050045|-- Bias --
21Feb13_050045|[-0.19062 -0.26300  0.48239]
21Feb13_050045|Layer 1:
21Feb13_050045|-- Config --
21Feb13_050045|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050045|-- Weights --
21Feb13_050045|[[ 0.14457 -0.61956]
21Feb13_050045| [ 1.29113 -0.25904]
21Feb13_050045| [-0.56150  0.30090]]
21Feb13_050045|-- Bias --
21Feb13_050045|[-1.10658  0.88662]
21Feb13_050045|Layer 2:
21Feb13_050045|-- Config --
21Feb13_050045|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050045|-- Weights --
21Feb13_050045|[[ 0.36463 -0.59654  0.07558  1.03681]
21Feb13_050045| [-0.69100  0.65045  0.69266 -0.09649]]
21Feb13_050045|-- Bias --
21Feb13_050045|[-0.34203 -0.15489 -0.67530 -0.34361]
21Feb13_050045|Layer 3:
21Feb13_050045|-- Config --
21Feb13_050045|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050045|-- Weights --
21Feb13_050045|[[ 0.74009  0.50107]
21Feb13_050045| [-0.91862  0.58181]
21Feb13_050045| [-0.52087 -0.10176]
21Feb13_050045| [-0.81097 -0.60657]]
21Feb13_050045|-- Bias --
21Feb13_050045|[-0.72207 -0.14119]
21Feb13_050045|Layer 4:
21Feb13_050045|-- Config --
21Feb13_050045|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050045|-- Weights --
21Feb13_050045|[[-0.36379  0.38387]
21Feb13_050045| [-0.13610  0.43138]]
21Feb13_050045|-- Bias --
21Feb13_050045|[-0.83070 -0.86913]
21Feb13_050045|Predicting the validation and test data with the Best final individual.
21Feb13_050053| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_050053|-----------  ------------------  --------------------  ----------
21Feb13_050053|Validation         25.83                  44            0.51481
21Feb13_050053|   Test            25.80                  44            0.50485
21Feb13_050053|-------------------- Test #2 --------------------
21Feb13_050053|Best final individual weights
21Feb13_050053|Individual:
21Feb13_050053|-- Constant hidden layers --
21Feb13_050053|False
21Feb13_050053|Layer 0:
21Feb13_050053|-- Config --
21Feb13_050053|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050053|-- Weights --
21Feb13_050053|[[-0.64119  0.41758  0.44403]
21Feb13_050053| [-0.19170 -0.56915 -0.25835]
21Feb13_050053| [ 0.24167 -0.25140  0.76563]
21Feb13_050053| [-0.34028 -0.39268 -0.81387]
21Feb13_050053| [-1.86022 -0.52041 -0.44819]
21Feb13_050053| [ 0.38513  0.25171 -0.11380]
21Feb13_050053| [ 0.22209 -0.92597  0.19546]
21Feb13_050053| [-0.71141 -0.41559  0.24085]
21Feb13_050053| [ 0.05990  1.53864 -0.15835]
21Feb13_050053| [ 0.57521 -0.04311  0.55248]
21Feb13_050053| [ 0.86173  0.05786  0.38030]
21Feb13_050053| [ 0.73310 -0.78236  0.48030]
21Feb13_050053| [ 0.40395 -0.34893 -0.71762]
21Feb13_050053| [ 0.11846 -0.72835  1.43541]
21Feb13_050053| [-0.44861 -0.75277  0.14467]
21Feb13_050053| [ 1.41428  1.05661  0.10286]
21Feb13_050053| [-1.57835 -0.10784  0.05255]
21Feb13_050053| [-0.47421 -0.65751  0.28725]
21Feb13_050053| [ 0.72747  0.12939  0.31006]
21Feb13_050053| [-1.18189  0.27777  0.58656]
21Feb13_050053| [-1.11883 -0.35427 -0.17962]
21Feb13_050053| [ 0.39343 -0.84418 -0.51133]
21Feb13_050053| [ 1.00598  0.61810 -0.21078]
21Feb13_050053| [-0.04015 -0.79351 -0.26753]
21Feb13_050053| [-0.66727  0.28333 -0.43119]
21Feb13_050053| [-0.14585  0.91540  0.81437]
21Feb13_050053| [ 0.13566  0.49138 -0.05944]
21Feb13_050053| [-0.22291  0.86713  1.13344]
21Feb13_050053| [-1.03502  1.56032  0.35828]
21Feb13_050053| [ 0.12223  0.39820  0.44290]
21Feb13_050053| [-1.42658 -0.38599  0.26524]
21Feb13_050053| [-0.52719  1.17703  0.62097]
21Feb13_050053| [ 0.52938  0.21738 -0.06837]
21Feb13_050053| [-0.87508  2.16887  0.32327]
21Feb13_050053| [ 1.35043 -0.65136  0.02642]
21Feb13_050053| [ 1.06028  0.80071 -0.96029]
21Feb13_050053| [-1.86678  0.53951 -0.02691]
21Feb13_050053| [ 1.73320 -1.35784  0.01810]
21Feb13_050053| [-0.03018 -0.70820 -0.34020]
21Feb13_050053| [-0.65415  0.11126 -0.54490]
21Feb13_050053| [ 1.14516 -0.84749  0.70247]
21Feb13_050053| [-0.64028  0.15453 -1.10559]
21Feb13_050053| [-0.18582 -0.94763 -0.78661]
21Feb13_050053| [ 0.90123 -0.72541  1.12612]
21Feb13_050053| [ 0.42551 -0.77656 -0.45109]
21Feb13_050053| [ 0.43603  1.06729  0.60801]
21Feb13_050053| [ 1.36190 -0.56744  0.83111]
21Feb13_050053| [-0.63814  1.07761 -0.29382]
21Feb13_050053| [-2.38452 -1.49477  0.68283]
21Feb13_050053| [-0.75870 -1.11212 -1.75709]
21Feb13_050053| [-0.20420 -1.34511  0.73343]
21Feb13_050053| [-0.20964 -0.04696 -0.11643]
21Feb13_050053| [ 0.02903  1.17196  0.19512]
21Feb13_050053| [ 0.67410  0.98823  0.20455]
21Feb13_050053| [ 1.12898 -0.02920 -0.26203]
21Feb13_050053| [ 0.01925  0.39530  0.50643]
21Feb13_050053| [-0.32905 -1.23882  0.15417]]
21Feb13_050053|-- Bias --
21Feb13_050053|[-0.19062 -0.26300  0.48239]
21Feb13_050053|Layer 1:
21Feb13_050053|-- Config --
21Feb13_050053|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050053|-- Weights --
21Feb13_050053|[[ 0.14457 -0.61956]
21Feb13_050053| [ 1.29113 -0.25904]
21Feb13_050053| [-0.56150  0.30090]]
21Feb13_050053|-- Bias --
21Feb13_050053|[-1.10658  0.88662]
21Feb13_050053|Layer 2:
21Feb13_050053|-- Config --
21Feb13_050053|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050053|-- Weights --
21Feb13_050053|[[ 0.36463 -0.59654  0.07558  1.03681]
21Feb13_050053| [-0.69100  0.65045  0.69266 -0.09649]]
21Feb13_050053|-- Bias --
21Feb13_050053|[-0.34203 -0.15489 -0.67530 -0.34361]
21Feb13_050053|Layer 3:
21Feb13_050053|-- Config --
21Feb13_050053|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050053|-- Weights --
21Feb13_050053|[[ 0.74009  0.50107]
21Feb13_050053| [-0.91862  0.58181]
21Feb13_050053| [-0.52087 -0.10176]
21Feb13_050053| [-0.81097 -0.60657]]
21Feb13_050053|-- Bias --
21Feb13_050053|[-0.72207 -0.14119]
21Feb13_050053|Layer 4:
21Feb13_050053|-- Config --
21Feb13_050053|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050053|-- Weights --
21Feb13_050053|[[-0.36379  0.38387]
21Feb13_050053| [-0.13610  0.43138]]
21Feb13_050053|-- Bias --
21Feb13_050053|[-0.83070 -0.86913]
21Feb13_050053|Predicting the validation and test data with the Best final individual.
21Feb13_050101| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_050101|-----------  ------------------  --------------------  ----------
21Feb13_050101|Validation         24.61                  44            0.51251
21Feb13_050101|   Test            28.93                  44            0.35276
21Feb13_050101|-------------------- Test #3 --------------------
21Feb13_050101|Best final individual weights
21Feb13_050101|Individual:
21Feb13_050101|-- Constant hidden layers --
21Feb13_050101|False
21Feb13_050101|Layer 0:
21Feb13_050101|-- Config --
21Feb13_050101|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050101|-- Weights --
21Feb13_050101|[[-0.64119  0.41758  0.44403]
21Feb13_050101| [-0.19170 -0.56915 -0.25835]
21Feb13_050101| [ 0.24167 -0.25140  0.76563]
21Feb13_050101| [-0.34028 -0.39268 -0.81387]
21Feb13_050101| [-1.86022 -0.52041 -0.44819]
21Feb13_050101| [ 0.38513  0.25171 -0.11380]
21Feb13_050101| [ 0.22209 -0.92597  0.19546]
21Feb13_050101| [-0.71141 -0.41559  0.24085]
21Feb13_050101| [ 0.05990  1.53864 -0.15835]
21Feb13_050101| [ 0.57521 -0.04311  0.55248]
21Feb13_050101| [ 0.86173  0.05786  0.38030]
21Feb13_050101| [ 0.73310 -0.78236  0.48030]
21Feb13_050101| [ 0.40395 -0.34893 -0.71762]
21Feb13_050101| [ 0.11846 -0.72835  1.43541]
21Feb13_050101| [-0.44861 -0.75277  0.14467]
21Feb13_050101| [ 1.41428  1.05661  0.10286]
21Feb13_050101| [-1.57835 -0.10784  0.05255]
21Feb13_050101| [-0.47421 -0.65751  0.28725]
21Feb13_050101| [ 0.72747  0.12939  0.31006]
21Feb13_050101| [-1.18189  0.27777  0.58656]
21Feb13_050101| [-1.11883 -0.35427 -0.17962]
21Feb13_050101| [ 0.39343 -0.84418 -0.51133]
21Feb13_050101| [ 1.00598  0.61810 -0.21078]
21Feb13_050101| [-0.04015 -0.79351 -0.26753]
21Feb13_050101| [-0.66727  0.28333 -0.43119]
21Feb13_050101| [-0.14585  0.91540  0.81437]
21Feb13_050101| [ 0.13566  0.49138 -0.05944]
21Feb13_050101| [-0.22291  0.86713  1.13344]
21Feb13_050101| [-1.03502  1.56032  0.35828]
21Feb13_050101| [ 0.12223  0.39820  0.44290]
21Feb13_050101| [-1.42658 -0.38599  0.26524]
21Feb13_050101| [-0.52719  1.17703  0.62097]
21Feb13_050101| [ 0.52938  0.21738 -0.06837]
21Feb13_050101| [-0.87508  2.16887  0.32327]
21Feb13_050101| [ 1.35043 -0.65136  0.02642]
21Feb13_050101| [ 1.06028  0.80071 -0.96029]
21Feb13_050101| [-1.86678  0.53951 -0.02691]
21Feb13_050101| [ 1.73320 -1.35784  0.01810]
21Feb13_050101| [-0.03018 -0.70820 -0.34020]
21Feb13_050101| [-0.65415  0.11126 -0.54490]
21Feb13_050101| [ 1.14516 -0.84749  0.70247]
21Feb13_050101| [-0.64028  0.15453 -1.10559]
21Feb13_050101| [-0.18582 -0.94763 -0.78661]
21Feb13_050101| [ 0.90123 -0.72541  1.12612]
21Feb13_050101| [ 0.42551 -0.77656 -0.45109]
21Feb13_050101| [ 0.43603  1.06729  0.60801]
21Feb13_050101| [ 1.36190 -0.56744  0.83111]
21Feb13_050101| [-0.63814  1.07761 -0.29382]
21Feb13_050101| [-2.38452 -1.49477  0.68283]
21Feb13_050101| [-0.75870 -1.11212 -1.75709]
21Feb13_050101| [-0.20420 -1.34511  0.73343]
21Feb13_050101| [-0.20964 -0.04696 -0.11643]
21Feb13_050101| [ 0.02903  1.17196  0.19512]
21Feb13_050101| [ 0.67410  0.98823  0.20455]
21Feb13_050101| [ 1.12898 -0.02920 -0.26203]
21Feb13_050101| [ 0.01925  0.39530  0.50643]
21Feb13_050101| [-0.32905 -1.23882  0.15417]]
21Feb13_050101|-- Bias --
21Feb13_050101|[-0.19062 -0.26300  0.48239]
21Feb13_050101|Layer 1:
21Feb13_050101|-- Config --
21Feb13_050101|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050101|-- Weights --
21Feb13_050101|[[ 0.14457 -0.61956]
21Feb13_050101| [ 1.29113 -0.25904]
21Feb13_050101| [-0.56150  0.30090]]
21Feb13_050101|-- Bias --
21Feb13_050101|[-1.10658  0.88662]
21Feb13_050101|Layer 2:
21Feb13_050101|-- Config --
21Feb13_050101|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050101|-- Weights --
21Feb13_050101|[[ 0.36463 -0.59654  0.07558  1.03681]
21Feb13_050101| [-0.69100  0.65045  0.69266 -0.09649]]
21Feb13_050101|-- Bias --
21Feb13_050101|[-0.34203 -0.15489 -0.67530 -0.34361]
21Feb13_050101|Layer 3:
21Feb13_050101|-- Config --
21Feb13_050101|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050101|-- Weights --
21Feb13_050101|[[ 0.74009  0.50107]
21Feb13_050101| [-0.91862  0.58181]
21Feb13_050101| [-0.52087 -0.10176]
21Feb13_050101| [-0.81097 -0.60657]]
21Feb13_050101|-- Bias --
21Feb13_050101|[-0.72207 -0.14119]
21Feb13_050101|Layer 4:
21Feb13_050101|-- Config --
21Feb13_050101|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050101|-- Weights --
21Feb13_050101|[[-0.36379  0.38387]
21Feb13_050101| [-0.13610  0.43138]]
21Feb13_050101|-- Bias --
21Feb13_050101|[-0.83070 -0.86913]
21Feb13_050101|Predicting the validation and test data with the Best final individual.
21Feb13_050109| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_050109|-----------  ------------------  --------------------  ----------
21Feb13_050109|Validation         25.30                  44            0.46680
21Feb13_050109|   Test            28.24                  44            0.37169
21Feb13_050109|-------------------- Test #4 --------------------
21Feb13_050109|Best final individual weights
21Feb13_050109|Individual:
21Feb13_050109|-- Constant hidden layers --
21Feb13_050109|False
21Feb13_050109|Layer 0:
21Feb13_050109|-- Config --
21Feb13_050109|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050109|-- Weights --
21Feb13_050109|[[-0.64119  0.41758  0.44403]
21Feb13_050109| [-0.19170 -0.56915 -0.25835]
21Feb13_050109| [ 0.24167 -0.25140  0.76563]
21Feb13_050109| [-0.34028 -0.39268 -0.81387]
21Feb13_050109| [-1.86022 -0.52041 -0.44819]
21Feb13_050109| [ 0.38513  0.25171 -0.11380]
21Feb13_050109| [ 0.22209 -0.92597  0.19546]
21Feb13_050109| [-0.71141 -0.41559  0.24085]
21Feb13_050109| [ 0.05990  1.53864 -0.15835]
21Feb13_050109| [ 0.57521 -0.04311  0.55248]
21Feb13_050109| [ 0.86173  0.05786  0.38030]
21Feb13_050109| [ 0.73310 -0.78236  0.48030]
21Feb13_050109| [ 0.40395 -0.34893 -0.71762]
21Feb13_050109| [ 0.11846 -0.72835  1.43541]
21Feb13_050109| [-0.44861 -0.75277  0.14467]
21Feb13_050109| [ 1.41428  1.05661  0.10286]
21Feb13_050109| [-1.57835 -0.10784  0.05255]
21Feb13_050109| [-0.47421 -0.65751  0.28725]
21Feb13_050109| [ 0.72747  0.12939  0.31006]
21Feb13_050109| [-1.18189  0.27777  0.58656]
21Feb13_050109| [-1.11883 -0.35427 -0.17962]
21Feb13_050109| [ 0.39343 -0.84418 -0.51133]
21Feb13_050109| [ 1.00598  0.61810 -0.21078]
21Feb13_050109| [-0.04015 -0.79351 -0.26753]
21Feb13_050109| [-0.66727  0.28333 -0.43119]
21Feb13_050109| [-0.14585  0.91540  0.81437]
21Feb13_050109| [ 0.13566  0.49138 -0.05944]
21Feb13_050109| [-0.22291  0.86713  1.13344]
21Feb13_050109| [-1.03502  1.56032  0.35828]
21Feb13_050109| [ 0.12223  0.39820  0.44290]
21Feb13_050109| [-1.42658 -0.38599  0.26524]
21Feb13_050109| [-0.52719  1.17703  0.62097]
21Feb13_050109| [ 0.52938  0.21738 -0.06837]
21Feb13_050109| [-0.87508  2.16887  0.32327]
21Feb13_050109| [ 1.35043 -0.65136  0.02642]
21Feb13_050109| [ 1.06028  0.80071 -0.96029]
21Feb13_050109| [-1.86678  0.53951 -0.02691]
21Feb13_050109| [ 1.73320 -1.35784  0.01810]
21Feb13_050109| [-0.03018 -0.70820 -0.34020]
21Feb13_050109| [-0.65415  0.11126 -0.54490]
21Feb13_050109| [ 1.14516 -0.84749  0.70247]
21Feb13_050109| [-0.64028  0.15453 -1.10559]
21Feb13_050109| [-0.18582 -0.94763 -0.78661]
21Feb13_050109| [ 0.90123 -0.72541  1.12612]
21Feb13_050109| [ 0.42551 -0.77656 -0.45109]
21Feb13_050109| [ 0.43603  1.06729  0.60801]
21Feb13_050109| [ 1.36190 -0.56744  0.83111]
21Feb13_050109| [-0.63814  1.07761 -0.29382]
21Feb13_050109| [-2.38452 -1.49477  0.68283]
21Feb13_050109| [-0.75870 -1.11212 -1.75709]
21Feb13_050109| [-0.20420 -1.34511  0.73343]
21Feb13_050109| [-0.20964 -0.04696 -0.11643]
21Feb13_050109| [ 0.02903  1.17196  0.19512]
21Feb13_050109| [ 0.67410  0.98823  0.20455]
21Feb13_050109| [ 1.12898 -0.02920 -0.26203]
21Feb13_050109| [ 0.01925  0.39530  0.50643]
21Feb13_050109| [-0.32905 -1.23882  0.15417]]
21Feb13_050109|-- Bias --
21Feb13_050109|[-0.19062 -0.26300  0.48239]
21Feb13_050109|Layer 1:
21Feb13_050109|-- Config --
21Feb13_050109|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050109|-- Weights --
21Feb13_050109|[[ 0.14457 -0.61956]
21Feb13_050109| [ 1.29113 -0.25904]
21Feb13_050109| [-0.56150  0.30090]]
21Feb13_050109|-- Bias --
21Feb13_050109|[-1.10658  0.88662]
21Feb13_050109|Layer 2:
21Feb13_050109|-- Config --
21Feb13_050109|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050109|-- Weights --
21Feb13_050109|[[ 0.36463 -0.59654  0.07558  1.03681]
21Feb13_050109| [-0.69100  0.65045  0.69266 -0.09649]]
21Feb13_050109|-- Bias --
21Feb13_050109|[-0.34203 -0.15489 -0.67530 -0.34361]
21Feb13_050109|Layer 3:
21Feb13_050109|-- Config --
21Feb13_050109|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050109|-- Weights --
21Feb13_050109|[[ 0.74009  0.50107]
21Feb13_050109| [-0.91862  0.58181]
21Feb13_050109| [-0.52087 -0.10176]
21Feb13_050109| [-0.81097 -0.60657]]
21Feb13_050109|-- Bias --
21Feb13_050109|[-0.72207 -0.14119]
21Feb13_050109|Layer 4:
21Feb13_050109|-- Config --
21Feb13_050109|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050109|-- Weights --
21Feb13_050109|[[-0.36379  0.38387]
21Feb13_050109| [-0.13610  0.43138]]
21Feb13_050109|-- Bias --
21Feb13_050109|[-0.83070 -0.86913]
21Feb13_050109|Predicting the validation and test data with the Best final individual.
21Feb13_050117| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_050117|-----------  ------------------  --------------------  ----------
21Feb13_050117|Validation         24.96                  44            0.47785
21Feb13_050117|   Test            25.89                  44            0.51232
21Feb13_050117|-------------------- Test #5 --------------------
21Feb13_050117|Best final individual weights
21Feb13_050117|Individual:
21Feb13_050117|-- Constant hidden layers --
21Feb13_050117|False
21Feb13_050117|Layer 0:
21Feb13_050117|-- Config --
21Feb13_050117|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050117|-- Weights --
21Feb13_050117|[[-0.64119  0.41758  0.44403]
21Feb13_050117| [-0.19170 -0.56915 -0.25835]
21Feb13_050117| [ 0.24167 -0.25140  0.76563]
21Feb13_050117| [-0.34028 -0.39268 -0.81387]
21Feb13_050117| [-1.86022 -0.52041 -0.44819]
21Feb13_050117| [ 0.38513  0.25171 -0.11380]
21Feb13_050117| [ 0.22209 -0.92597  0.19546]
21Feb13_050117| [-0.71141 -0.41559  0.24085]
21Feb13_050117| [ 0.05990  1.53864 -0.15835]
21Feb13_050117| [ 0.57521 -0.04311  0.55248]
21Feb13_050117| [ 0.86173  0.05786  0.38030]
21Feb13_050117| [ 0.73310 -0.78236  0.48030]
21Feb13_050117| [ 0.40395 -0.34893 -0.71762]
21Feb13_050117| [ 0.11846 -0.72835  1.43541]
21Feb13_050117| [-0.44861 -0.75277  0.14467]
21Feb13_050117| [ 1.41428  1.05661  0.10286]
21Feb13_050117| [-1.57835 -0.10784  0.05255]
21Feb13_050117| [-0.47421 -0.65751  0.28725]
21Feb13_050117| [ 0.72747  0.12939  0.31006]
21Feb13_050117| [-1.18189  0.27777  0.58656]
21Feb13_050117| [-1.11883 -0.35427 -0.17962]
21Feb13_050117| [ 0.39343 -0.84418 -0.51133]
21Feb13_050117| [ 1.00598  0.61810 -0.21078]
21Feb13_050117| [-0.04015 -0.79351 -0.26753]
21Feb13_050117| [-0.66727  0.28333 -0.43119]
21Feb13_050117| [-0.14585  0.91540  0.81437]
21Feb13_050117| [ 0.13566  0.49138 -0.05944]
21Feb13_050117| [-0.22291  0.86713  1.13344]
21Feb13_050117| [-1.03502  1.56032  0.35828]
21Feb13_050117| [ 0.12223  0.39820  0.44290]
21Feb13_050117| [-1.42658 -0.38599  0.26524]
21Feb13_050117| [-0.52719  1.17703  0.62097]
21Feb13_050117| [ 0.52938  0.21738 -0.06837]
21Feb13_050117| [-0.87508  2.16887  0.32327]
21Feb13_050117| [ 1.35043 -0.65136  0.02642]
21Feb13_050117| [ 1.06028  0.80071 -0.96029]
21Feb13_050117| [-1.86678  0.53951 -0.02691]
21Feb13_050117| [ 1.73320 -1.35784  0.01810]
21Feb13_050117| [-0.03018 -0.70820 -0.34020]
21Feb13_050117| [-0.65415  0.11126 -0.54490]
21Feb13_050117| [ 1.14516 -0.84749  0.70247]
21Feb13_050117| [-0.64028  0.15453 -1.10559]
21Feb13_050117| [-0.18582 -0.94763 -0.78661]
21Feb13_050117| [ 0.90123 -0.72541  1.12612]
21Feb13_050117| [ 0.42551 -0.77656 -0.45109]
21Feb13_050117| [ 0.43603  1.06729  0.60801]
21Feb13_050117| [ 1.36190 -0.56744  0.83111]
21Feb13_050117| [-0.63814  1.07761 -0.29382]
21Feb13_050117| [-2.38452 -1.49477  0.68283]
21Feb13_050117| [-0.75870 -1.11212 -1.75709]
21Feb13_050117| [-0.20420 -1.34511  0.73343]
21Feb13_050117| [-0.20964 -0.04696 -0.11643]
21Feb13_050117| [ 0.02903  1.17196  0.19512]
21Feb13_050117| [ 0.67410  0.98823  0.20455]
21Feb13_050117| [ 1.12898 -0.02920 -0.26203]
21Feb13_050117| [ 0.01925  0.39530  0.50643]
21Feb13_050117| [-0.32905 -1.23882  0.15417]]
21Feb13_050117|-- Bias --
21Feb13_050117|[-0.19062 -0.26300  0.48239]
21Feb13_050117|Layer 1:
21Feb13_050117|-- Config --
21Feb13_050117|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050117|-- Weights --
21Feb13_050117|[[ 0.14457 -0.61956]
21Feb13_050117| [ 1.29113 -0.25904]
21Feb13_050117| [-0.56150  0.30090]]
21Feb13_050117|-- Bias --
21Feb13_050117|[-1.10658  0.88662]
21Feb13_050117|Layer 2:
21Feb13_050117|-- Config --
21Feb13_050117|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050117|-- Weights --
21Feb13_050117|[[ 0.36463 -0.59654  0.07558  1.03681]
21Feb13_050117| [-0.69100  0.65045  0.69266 -0.09649]]
21Feb13_050117|-- Bias --
21Feb13_050117|[-0.34203 -0.15489 -0.67530 -0.34361]
21Feb13_050117|Layer 3:
21Feb13_050117|-- Config --
21Feb13_050117|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050117|-- Weights --
21Feb13_050117|[[ 0.74009  0.50107]
21Feb13_050117| [-0.91862  0.58181]
21Feb13_050117| [-0.52087 -0.10176]
21Feb13_050117| [-0.81097 -0.60657]]
21Feb13_050117|-- Bias --
21Feb13_050117|[-0.72207 -0.14119]
21Feb13_050117|Layer 4:
21Feb13_050117|-- Config --
21Feb13_050117|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050117|-- Weights --
21Feb13_050117|[[-0.36379  0.38387]
21Feb13_050117| [-0.13610  0.43138]]
21Feb13_050117|-- Bias --
21Feb13_050117|[-0.83070 -0.86913]
21Feb13_050117|Predicting the validation and test data with the Best final individual.
21Feb13_050125| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_050125|-----------  ------------------  --------------------  ----------
21Feb13_050125|Validation         28.96                  44            0.35659
21Feb13_050125|   Test            26.24                  44            0.54713
21Feb13_050125|-------------------- Test #6 --------------------
21Feb13_050125|Best final individual weights
21Feb13_050125|Individual:
21Feb13_050125|-- Constant hidden layers --
21Feb13_050125|False
21Feb13_050125|Layer 0:
21Feb13_050125|-- Config --
21Feb13_050125|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050125|-- Weights --
21Feb13_050125|[[-0.64119  0.41758  0.44403]
21Feb13_050125| [-0.19170 -0.56915 -0.25835]
21Feb13_050125| [ 0.24167 -0.25140  0.76563]
21Feb13_050125| [-0.34028 -0.39268 -0.81387]
21Feb13_050125| [-1.86022 -0.52041 -0.44819]
21Feb13_050125| [ 0.38513  0.25171 -0.11380]
21Feb13_050125| [ 0.22209 -0.92597  0.19546]
21Feb13_050125| [-0.71141 -0.41559  0.24085]
21Feb13_050125| [ 0.05990  1.53864 -0.15835]
21Feb13_050125| [ 0.57521 -0.04311  0.55248]
21Feb13_050125| [ 0.86173  0.05786  0.38030]
21Feb13_050125| [ 0.73310 -0.78236  0.48030]
21Feb13_050125| [ 0.40395 -0.34893 -0.71762]
21Feb13_050125| [ 0.11846 -0.72835  1.43541]
21Feb13_050125| [-0.44861 -0.75277  0.14467]
21Feb13_050125| [ 1.41428  1.05661  0.10286]
21Feb13_050125| [-1.57835 -0.10784  0.05255]
21Feb13_050125| [-0.47421 -0.65751  0.28725]
21Feb13_050125| [ 0.72747  0.12939  0.31006]
21Feb13_050125| [-1.18189  0.27777  0.58656]
21Feb13_050125| [-1.11883 -0.35427 -0.17962]
21Feb13_050125| [ 0.39343 -0.84418 -0.51133]
21Feb13_050125| [ 1.00598  0.61810 -0.21078]
21Feb13_050125| [-0.04015 -0.79351 -0.26753]
21Feb13_050125| [-0.66727  0.28333 -0.43119]
21Feb13_050125| [-0.14585  0.91540  0.81437]
21Feb13_050125| [ 0.13566  0.49138 -0.05944]
21Feb13_050125| [-0.22291  0.86713  1.13344]
21Feb13_050125| [-1.03502  1.56032  0.35828]
21Feb13_050125| [ 0.12223  0.39820  0.44290]
21Feb13_050125| [-1.42658 -0.38599  0.26524]
21Feb13_050125| [-0.52719  1.17703  0.62097]
21Feb13_050125| [ 0.52938  0.21738 -0.06837]
21Feb13_050125| [-0.87508  2.16887  0.32327]
21Feb13_050125| [ 1.35043 -0.65136  0.02642]
21Feb13_050125| [ 1.06028  0.80071 -0.96029]
21Feb13_050125| [-1.86678  0.53951 -0.02691]
21Feb13_050125| [ 1.73320 -1.35784  0.01810]
21Feb13_050125| [-0.03018 -0.70820 -0.34020]
21Feb13_050125| [-0.65415  0.11126 -0.54490]
21Feb13_050125| [ 1.14516 -0.84749  0.70247]
21Feb13_050125| [-0.64028  0.15453 -1.10559]
21Feb13_050125| [-0.18582 -0.94763 -0.78661]
21Feb13_050125| [ 0.90123 -0.72541  1.12612]
21Feb13_050125| [ 0.42551 -0.77656 -0.45109]
21Feb13_050125| [ 0.43603  1.06729  0.60801]
21Feb13_050125| [ 1.36190 -0.56744  0.83111]
21Feb13_050125| [-0.63814  1.07761 -0.29382]
21Feb13_050125| [-2.38452 -1.49477  0.68283]
21Feb13_050125| [-0.75870 -1.11212 -1.75709]
21Feb13_050125| [-0.20420 -1.34511  0.73343]
21Feb13_050125| [-0.20964 -0.04696 -0.11643]
21Feb13_050125| [ 0.02903  1.17196  0.19512]
21Feb13_050125| [ 0.67410  0.98823  0.20455]
21Feb13_050125| [ 1.12898 -0.02920 -0.26203]
21Feb13_050125| [ 0.01925  0.39530  0.50643]
21Feb13_050125| [-0.32905 -1.23882  0.15417]]
21Feb13_050125|-- Bias --
21Feb13_050125|[-0.19062 -0.26300  0.48239]
21Feb13_050125|Layer 1:
21Feb13_050125|-- Config --
21Feb13_050125|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050125|-- Weights --
21Feb13_050125|[[ 0.14457 -0.61956]
21Feb13_050125| [ 1.29113 -0.25904]
21Feb13_050125| [-0.56150  0.30090]]
21Feb13_050125|-- Bias --
21Feb13_050125|[-1.10658  0.88662]
21Feb13_050125|Layer 2:
21Feb13_050125|-- Config --
21Feb13_050125|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050125|-- Weights --
21Feb13_050125|[[ 0.36463 -0.59654  0.07558  1.03681]
21Feb13_050125| [-0.69100  0.65045  0.69266 -0.09649]]
21Feb13_050125|-- Bias --
21Feb13_050125|[-0.34203 -0.15489 -0.67530 -0.34361]
21Feb13_050125|Layer 3:
21Feb13_050125|-- Config --
21Feb13_050125|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050125|-- Weights --
21Feb13_050125|[[ 0.74009  0.50107]
21Feb13_050125| [-0.91862  0.58181]
21Feb13_050125| [-0.52087 -0.10176]
21Feb13_050125| [-0.81097 -0.60657]]
21Feb13_050125|-- Bias --
21Feb13_050125|[-0.72207 -0.14119]
21Feb13_050125|Layer 4:
21Feb13_050125|-- Config --
21Feb13_050125|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050125|-- Weights --
21Feb13_050125|[[-0.36379  0.38387]
21Feb13_050125| [-0.13610  0.43138]]
21Feb13_050125|-- Bias --
21Feb13_050125|[-0.83070 -0.86913]
21Feb13_050125|Predicting the validation and test data with the Best final individual.
21Feb13_050133| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_050133|-----------  ------------------  --------------------  ----------
21Feb13_050133|Validation         25.30                  44            0.53924
21Feb13_050133|   Test            27.02                  44            0.40657
21Feb13_050133|-------------------- Test #7 --------------------
21Feb13_050133|Best final individual weights
21Feb13_050133|Individual:
21Feb13_050133|-- Constant hidden layers --
21Feb13_050133|False
21Feb13_050133|Layer 0:
21Feb13_050133|-- Config --
21Feb13_050133|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050133|-- Weights --
21Feb13_050133|[[-0.64119  0.41758  0.44403]
21Feb13_050133| [-0.19170 -0.56915 -0.25835]
21Feb13_050133| [ 0.24167 -0.25140  0.76563]
21Feb13_050133| [-0.34028 -0.39268 -0.81387]
21Feb13_050133| [-1.86022 -0.52041 -0.44819]
21Feb13_050133| [ 0.38513  0.25171 -0.11380]
21Feb13_050133| [ 0.22209 -0.92597  0.19546]
21Feb13_050133| [-0.71141 -0.41559  0.24085]
21Feb13_050133| [ 0.05990  1.53864 -0.15835]
21Feb13_050133| [ 0.57521 -0.04311  0.55248]
21Feb13_050133| [ 0.86173  0.05786  0.38030]
21Feb13_050133| [ 0.73310 -0.78236  0.48030]
21Feb13_050133| [ 0.40395 -0.34893 -0.71762]
21Feb13_050133| [ 0.11846 -0.72835  1.43541]
21Feb13_050133| [-0.44861 -0.75277  0.14467]
21Feb13_050133| [ 1.41428  1.05661  0.10286]
21Feb13_050133| [-1.57835 -0.10784  0.05255]
21Feb13_050133| [-0.47421 -0.65751  0.28725]
21Feb13_050133| [ 0.72747  0.12939  0.31006]
21Feb13_050133| [-1.18189  0.27777  0.58656]
21Feb13_050133| [-1.11883 -0.35427 -0.17962]
21Feb13_050133| [ 0.39343 -0.84418 -0.51133]
21Feb13_050133| [ 1.00598  0.61810 -0.21078]
21Feb13_050133| [-0.04015 -0.79351 -0.26753]
21Feb13_050133| [-0.66727  0.28333 -0.43119]
21Feb13_050133| [-0.14585  0.91540  0.81437]
21Feb13_050133| [ 0.13566  0.49138 -0.05944]
21Feb13_050133| [-0.22291  0.86713  1.13344]
21Feb13_050133| [-1.03502  1.56032  0.35828]
21Feb13_050133| [ 0.12223  0.39820  0.44290]
21Feb13_050133| [-1.42658 -0.38599  0.26524]
21Feb13_050133| [-0.52719  1.17703  0.62097]
21Feb13_050133| [ 0.52938  0.21738 -0.06837]
21Feb13_050133| [-0.87508  2.16887  0.32327]
21Feb13_050133| [ 1.35043 -0.65136  0.02642]
21Feb13_050133| [ 1.06028  0.80071 -0.96029]
21Feb13_050133| [-1.86678  0.53951 -0.02691]
21Feb13_050133| [ 1.73320 -1.35784  0.01810]
21Feb13_050133| [-0.03018 -0.70820 -0.34020]
21Feb13_050133| [-0.65415  0.11126 -0.54490]
21Feb13_050133| [ 1.14516 -0.84749  0.70247]
21Feb13_050133| [-0.64028  0.15453 -1.10559]
21Feb13_050133| [-0.18582 -0.94763 -0.78661]
21Feb13_050133| [ 0.90123 -0.72541  1.12612]
21Feb13_050133| [ 0.42551 -0.77656 -0.45109]
21Feb13_050133| [ 0.43603  1.06729  0.60801]
21Feb13_050133| [ 1.36190 -0.56744  0.83111]
21Feb13_050133| [-0.63814  1.07761 -0.29382]
21Feb13_050133| [-2.38452 -1.49477  0.68283]
21Feb13_050133| [-0.75870 -1.11212 -1.75709]
21Feb13_050133| [-0.20420 -1.34511  0.73343]
21Feb13_050133| [-0.20964 -0.04696 -0.11643]
21Feb13_050133| [ 0.02903  1.17196  0.19512]
21Feb13_050133| [ 0.67410  0.98823  0.20455]
21Feb13_050133| [ 1.12898 -0.02920 -0.26203]
21Feb13_050133| [ 0.01925  0.39530  0.50643]
21Feb13_050133| [-0.32905 -1.23882  0.15417]]
21Feb13_050133|-- Bias --
21Feb13_050133|[-0.19062 -0.26300  0.48239]
21Feb13_050133|Layer 1:
21Feb13_050133|-- Config --
21Feb13_050133|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050133|-- Weights --
21Feb13_050133|[[ 0.14457 -0.61956]
21Feb13_050133| [ 1.29113 -0.25904]
21Feb13_050133| [-0.56150  0.30090]]
21Feb13_050133|-- Bias --
21Feb13_050133|[-1.10658  0.88662]
21Feb13_050133|Layer 2:
21Feb13_050133|-- Config --
21Feb13_050133|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050133|-- Weights --
21Feb13_050133|[[ 0.36463 -0.59654  0.07558  1.03681]
21Feb13_050133| [-0.69100  0.65045  0.69266 -0.09649]]
21Feb13_050133|-- Bias --
21Feb13_050133|[-0.34203 -0.15489 -0.67530 -0.34361]
21Feb13_050133|Layer 3:
21Feb13_050133|-- Config --
21Feb13_050133|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050133|-- Weights --
21Feb13_050133|[[ 0.74009  0.50107]
21Feb13_050133| [-0.91862  0.58181]
21Feb13_050133| [-0.52087 -0.10176]
21Feb13_050133| [-0.81097 -0.60657]]
21Feb13_050133|-- Bias --
21Feb13_050133|[-0.72207 -0.14119]
21Feb13_050133|Layer 4:
21Feb13_050133|-- Config --
21Feb13_050133|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050133|-- Weights --
21Feb13_050133|[[-0.36379  0.38387]
21Feb13_050133| [-0.13610  0.43138]]
21Feb13_050133|-- Bias --
21Feb13_050133|[-0.83070 -0.86913]
21Feb13_050133|Predicting the validation and test data with the Best final individual.
21Feb13_050141| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_050141|-----------  ------------------  --------------------  ----------
21Feb13_050141|Validation         27.48                  44            0.39888
21Feb13_050141|   Test            26.85                  44            0.44235
21Feb13_050141|-------------------- Test #8 --------------------
21Feb13_050141|Best final individual weights
21Feb13_050141|Individual:
21Feb13_050141|-- Constant hidden layers --
21Feb13_050141|False
21Feb13_050141|Layer 0:
21Feb13_050141|-- Config --
21Feb13_050141|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050141|-- Weights --
21Feb13_050141|[[-0.64119  0.41758  0.44403]
21Feb13_050141| [-0.19170 -0.56915 -0.25835]
21Feb13_050141| [ 0.24167 -0.25140  0.76563]
21Feb13_050141| [-0.34028 -0.39268 -0.81387]
21Feb13_050141| [-1.86022 -0.52041 -0.44819]
21Feb13_050141| [ 0.38513  0.25171 -0.11380]
21Feb13_050141| [ 0.22209 -0.92597  0.19546]
21Feb13_050141| [-0.71141 -0.41559  0.24085]
21Feb13_050141| [ 0.05990  1.53864 -0.15835]
21Feb13_050141| [ 0.57521 -0.04311  0.55248]
21Feb13_050141| [ 0.86173  0.05786  0.38030]
21Feb13_050141| [ 0.73310 -0.78236  0.48030]
21Feb13_050141| [ 0.40395 -0.34893 -0.71762]
21Feb13_050141| [ 0.11846 -0.72835  1.43541]
21Feb13_050141| [-0.44861 -0.75277  0.14467]
21Feb13_050141| [ 1.41428  1.05661  0.10286]
21Feb13_050141| [-1.57835 -0.10784  0.05255]
21Feb13_050141| [-0.47421 -0.65751  0.28725]
21Feb13_050141| [ 0.72747  0.12939  0.31006]
21Feb13_050141| [-1.18189  0.27777  0.58656]
21Feb13_050141| [-1.11883 -0.35427 -0.17962]
21Feb13_050141| [ 0.39343 -0.84418 -0.51133]
21Feb13_050141| [ 1.00598  0.61810 -0.21078]
21Feb13_050141| [-0.04015 -0.79351 -0.26753]
21Feb13_050141| [-0.66727  0.28333 -0.43119]
21Feb13_050141| [-0.14585  0.91540  0.81437]
21Feb13_050141| [ 0.13566  0.49138 -0.05944]
21Feb13_050141| [-0.22291  0.86713  1.13344]
21Feb13_050141| [-1.03502  1.56032  0.35828]
21Feb13_050141| [ 0.12223  0.39820  0.44290]
21Feb13_050141| [-1.42658 -0.38599  0.26524]
21Feb13_050141| [-0.52719  1.17703  0.62097]
21Feb13_050141| [ 0.52938  0.21738 -0.06837]
21Feb13_050141| [-0.87508  2.16887  0.32327]
21Feb13_050141| [ 1.35043 -0.65136  0.02642]
21Feb13_050141| [ 1.06028  0.80071 -0.96029]
21Feb13_050141| [-1.86678  0.53951 -0.02691]
21Feb13_050141| [ 1.73320 -1.35784  0.01810]
21Feb13_050141| [-0.03018 -0.70820 -0.34020]
21Feb13_050141| [-0.65415  0.11126 -0.54490]
21Feb13_050141| [ 1.14516 -0.84749  0.70247]
21Feb13_050141| [-0.64028  0.15453 -1.10559]
21Feb13_050141| [-0.18582 -0.94763 -0.78661]
21Feb13_050141| [ 0.90123 -0.72541  1.12612]
21Feb13_050141| [ 0.42551 -0.77656 -0.45109]
21Feb13_050141| [ 0.43603  1.06729  0.60801]
21Feb13_050141| [ 1.36190 -0.56744  0.83111]
21Feb13_050141| [-0.63814  1.07761 -0.29382]
21Feb13_050141| [-2.38452 -1.49477  0.68283]
21Feb13_050141| [-0.75870 -1.11212 -1.75709]
21Feb13_050141| [-0.20420 -1.34511  0.73343]
21Feb13_050141| [-0.20964 -0.04696 -0.11643]
21Feb13_050141| [ 0.02903  1.17196  0.19512]
21Feb13_050141| [ 0.67410  0.98823  0.20455]
21Feb13_050141| [ 1.12898 -0.02920 -0.26203]
21Feb13_050141| [ 0.01925  0.39530  0.50643]
21Feb13_050141| [-0.32905 -1.23882  0.15417]]
21Feb13_050141|-- Bias --
21Feb13_050141|[-0.19062 -0.26300  0.48239]
21Feb13_050141|Layer 1:
21Feb13_050141|-- Config --
21Feb13_050141|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050141|-- Weights --
21Feb13_050141|[[ 0.14457 -0.61956]
21Feb13_050141| [ 1.29113 -0.25904]
21Feb13_050141| [-0.56150  0.30090]]
21Feb13_050141|-- Bias --
21Feb13_050141|[-1.10658  0.88662]
21Feb13_050141|Layer 2:
21Feb13_050141|-- Config --
21Feb13_050141|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050141|-- Weights --
21Feb13_050141|[[ 0.36463 -0.59654  0.07558  1.03681]
21Feb13_050141| [-0.69100  0.65045  0.69266 -0.09649]]
21Feb13_050141|-- Bias --
21Feb13_050141|[-0.34203 -0.15489 -0.67530 -0.34361]
21Feb13_050141|Layer 3:
21Feb13_050141|-- Config --
21Feb13_050141|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050141|-- Weights --
21Feb13_050141|[[ 0.74009  0.50107]
21Feb13_050141| [-0.91862  0.58181]
21Feb13_050141| [-0.52087 -0.10176]
21Feb13_050141| [-0.81097 -0.60657]]
21Feb13_050141|-- Bias --
21Feb13_050141|[-0.72207 -0.14119]
21Feb13_050141|Layer 4:
21Feb13_050141|-- Config --
21Feb13_050141|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050141|-- Weights --
21Feb13_050141|[[-0.36379  0.38387]
21Feb13_050141| [-0.13610  0.43138]]
21Feb13_050141|-- Bias --
21Feb13_050141|[-0.83070 -0.86913]
21Feb13_050141|Predicting the validation and test data with the Best final individual.
21Feb13_050150| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_050150|-----------  ------------------  --------------------  ----------
21Feb13_050150|Validation         26.26                  44            0.49413
21Feb13_050150|   Test            27.54                  44            0.42622
21Feb13_050150|-------------------- Test #9 --------------------
21Feb13_050150|Best final individual weights
21Feb13_050150|Individual:
21Feb13_050150|-- Constant hidden layers --
21Feb13_050150|False
21Feb13_050150|Layer 0:
21Feb13_050150|-- Config --
21Feb13_050150|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050150|-- Weights --
21Feb13_050150|[[-0.64119  0.41758  0.44403]
21Feb13_050150| [-0.19170 -0.56915 -0.25835]
21Feb13_050150| [ 0.24167 -0.25140  0.76563]
21Feb13_050150| [-0.34028 -0.39268 -0.81387]
21Feb13_050150| [-1.86022 -0.52041 -0.44819]
21Feb13_050150| [ 0.38513  0.25171 -0.11380]
21Feb13_050150| [ 0.22209 -0.92597  0.19546]
21Feb13_050150| [-0.71141 -0.41559  0.24085]
21Feb13_050150| [ 0.05990  1.53864 -0.15835]
21Feb13_050150| [ 0.57521 -0.04311  0.55248]
21Feb13_050150| [ 0.86173  0.05786  0.38030]
21Feb13_050150| [ 0.73310 -0.78236  0.48030]
21Feb13_050150| [ 0.40395 -0.34893 -0.71762]
21Feb13_050150| [ 0.11846 -0.72835  1.43541]
21Feb13_050150| [-0.44861 -0.75277  0.14467]
21Feb13_050150| [ 1.41428  1.05661  0.10286]
21Feb13_050150| [-1.57835 -0.10784  0.05255]
21Feb13_050150| [-0.47421 -0.65751  0.28725]
21Feb13_050150| [ 0.72747  0.12939  0.31006]
21Feb13_050150| [-1.18189  0.27777  0.58656]
21Feb13_050150| [-1.11883 -0.35427 -0.17962]
21Feb13_050150| [ 0.39343 -0.84418 -0.51133]
21Feb13_050150| [ 1.00598  0.61810 -0.21078]
21Feb13_050150| [-0.04015 -0.79351 -0.26753]
21Feb13_050150| [-0.66727  0.28333 -0.43119]
21Feb13_050150| [-0.14585  0.91540  0.81437]
21Feb13_050150| [ 0.13566  0.49138 -0.05944]
21Feb13_050150| [-0.22291  0.86713  1.13344]
21Feb13_050150| [-1.03502  1.56032  0.35828]
21Feb13_050150| [ 0.12223  0.39820  0.44290]
21Feb13_050150| [-1.42658 -0.38599  0.26524]
21Feb13_050150| [-0.52719  1.17703  0.62097]
21Feb13_050150| [ 0.52938  0.21738 -0.06837]
21Feb13_050150| [-0.87508  2.16887  0.32327]
21Feb13_050150| [ 1.35043 -0.65136  0.02642]
21Feb13_050150| [ 1.06028  0.80071 -0.96029]
21Feb13_050150| [-1.86678  0.53951 -0.02691]
21Feb13_050150| [ 1.73320 -1.35784  0.01810]
21Feb13_050150| [-0.03018 -0.70820 -0.34020]
21Feb13_050150| [-0.65415  0.11126 -0.54490]
21Feb13_050150| [ 1.14516 -0.84749  0.70247]
21Feb13_050150| [-0.64028  0.15453 -1.10559]
21Feb13_050150| [-0.18582 -0.94763 -0.78661]
21Feb13_050150| [ 0.90123 -0.72541  1.12612]
21Feb13_050150| [ 0.42551 -0.77656 -0.45109]
21Feb13_050150| [ 0.43603  1.06729  0.60801]
21Feb13_050150| [ 1.36190 -0.56744  0.83111]
21Feb13_050150| [-0.63814  1.07761 -0.29382]
21Feb13_050150| [-2.38452 -1.49477  0.68283]
21Feb13_050150| [-0.75870 -1.11212 -1.75709]
21Feb13_050150| [-0.20420 -1.34511  0.73343]
21Feb13_050150| [-0.20964 -0.04696 -0.11643]
21Feb13_050150| [ 0.02903  1.17196  0.19512]
21Feb13_050150| [ 0.67410  0.98823  0.20455]
21Feb13_050150| [ 1.12898 -0.02920 -0.26203]
21Feb13_050150| [ 0.01925  0.39530  0.50643]
21Feb13_050150| [-0.32905 -1.23882  0.15417]]
21Feb13_050150|-- Bias --
21Feb13_050150|[-0.19062 -0.26300  0.48239]
21Feb13_050150|Layer 1:
21Feb13_050150|-- Config --
21Feb13_050150|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050150|-- Weights --
21Feb13_050150|[[ 0.14457 -0.61956]
21Feb13_050150| [ 1.29113 -0.25904]
21Feb13_050150| [-0.56150  0.30090]]
21Feb13_050150|-- Bias --
21Feb13_050150|[-1.10658  0.88662]
21Feb13_050150|Layer 2:
21Feb13_050150|-- Config --
21Feb13_050150|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050150|-- Weights --
21Feb13_050150|[[ 0.36463 -0.59654  0.07558  1.03681]
21Feb13_050150| [-0.69100  0.65045  0.69266 -0.09649]]
21Feb13_050150|-- Bias --
21Feb13_050150|[-0.34203 -0.15489 -0.67530 -0.34361]
21Feb13_050150|Layer 3:
21Feb13_050150|-- Config --
21Feb13_050150|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050150|-- Weights --
21Feb13_050150|[[ 0.74009  0.50107]
21Feb13_050150| [-0.91862  0.58181]
21Feb13_050150| [-0.52087 -0.10176]
21Feb13_050150| [-0.81097 -0.60657]]
21Feb13_050150|-- Bias --
21Feb13_050150|[-0.72207 -0.14119]
21Feb13_050150|Layer 4:
21Feb13_050150|-- Config --
21Feb13_050150|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050150|-- Weights --
21Feb13_050150|[[-0.36379  0.38387]
21Feb13_050150| [-0.13610  0.43138]]
21Feb13_050150|-- Bias --
21Feb13_050150|[-0.83070 -0.86913]
21Feb13_050150|Predicting the validation and test data with the Best final individual.
21Feb13_050158| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_050158|-----------  ------------------  --------------------  ----------
21Feb13_050158|Validation         25.83                  44            0.55264
21Feb13_050158|   Test            25.54                  44            0.48006
21Feb13_050158|-------------------- Test #10 --------------------
21Feb13_050158|Best final individual weights
21Feb13_050158|Individual:
21Feb13_050158|-- Constant hidden layers --
21Feb13_050158|False
21Feb13_050158|Layer 0:
21Feb13_050158|-- Config --
21Feb13_050158|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050158|-- Weights --
21Feb13_050158|[[-0.64119  0.41758  0.44403]
21Feb13_050158| [-0.19170 -0.56915 -0.25835]
21Feb13_050158| [ 0.24167 -0.25140  0.76563]
21Feb13_050158| [-0.34028 -0.39268 -0.81387]
21Feb13_050158| [-1.86022 -0.52041 -0.44819]
21Feb13_050158| [ 0.38513  0.25171 -0.11380]
21Feb13_050158| [ 0.22209 -0.92597  0.19546]
21Feb13_050158| [-0.71141 -0.41559  0.24085]
21Feb13_050158| [ 0.05990  1.53864 -0.15835]
21Feb13_050158| [ 0.57521 -0.04311  0.55248]
21Feb13_050158| [ 0.86173  0.05786  0.38030]
21Feb13_050158| [ 0.73310 -0.78236  0.48030]
21Feb13_050158| [ 0.40395 -0.34893 -0.71762]
21Feb13_050158| [ 0.11846 -0.72835  1.43541]
21Feb13_050158| [-0.44861 -0.75277  0.14467]
21Feb13_050158| [ 1.41428  1.05661  0.10286]
21Feb13_050158| [-1.57835 -0.10784  0.05255]
21Feb13_050158| [-0.47421 -0.65751  0.28725]
21Feb13_050158| [ 0.72747  0.12939  0.31006]
21Feb13_050158| [-1.18189  0.27777  0.58656]
21Feb13_050158| [-1.11883 -0.35427 -0.17962]
21Feb13_050158| [ 0.39343 -0.84418 -0.51133]
21Feb13_050158| [ 1.00598  0.61810 -0.21078]
21Feb13_050158| [-0.04015 -0.79351 -0.26753]
21Feb13_050158| [-0.66727  0.28333 -0.43119]
21Feb13_050158| [-0.14585  0.91540  0.81437]
21Feb13_050158| [ 0.13566  0.49138 -0.05944]
21Feb13_050158| [-0.22291  0.86713  1.13344]
21Feb13_050158| [-1.03502  1.56032  0.35828]
21Feb13_050158| [ 0.12223  0.39820  0.44290]
21Feb13_050158| [-1.42658 -0.38599  0.26524]
21Feb13_050158| [-0.52719  1.17703  0.62097]
21Feb13_050158| [ 0.52938  0.21738 -0.06837]
21Feb13_050158| [-0.87508  2.16887  0.32327]
21Feb13_050158| [ 1.35043 -0.65136  0.02642]
21Feb13_050158| [ 1.06028  0.80071 -0.96029]
21Feb13_050158| [-1.86678  0.53951 -0.02691]
21Feb13_050158| [ 1.73320 -1.35784  0.01810]
21Feb13_050158| [-0.03018 -0.70820 -0.34020]
21Feb13_050158| [-0.65415  0.11126 -0.54490]
21Feb13_050158| [ 1.14516 -0.84749  0.70247]
21Feb13_050158| [-0.64028  0.15453 -1.10559]
21Feb13_050158| [-0.18582 -0.94763 -0.78661]
21Feb13_050158| [ 0.90123 -0.72541  1.12612]
21Feb13_050158| [ 0.42551 -0.77656 -0.45109]
21Feb13_050158| [ 0.43603  1.06729  0.60801]
21Feb13_050158| [ 1.36190 -0.56744  0.83111]
21Feb13_050158| [-0.63814  1.07761 -0.29382]
21Feb13_050158| [-2.38452 -1.49477  0.68283]
21Feb13_050158| [-0.75870 -1.11212 -1.75709]
21Feb13_050158| [-0.20420 -1.34511  0.73343]
21Feb13_050158| [-0.20964 -0.04696 -0.11643]
21Feb13_050158| [ 0.02903  1.17196  0.19512]
21Feb13_050158| [ 0.67410  0.98823  0.20455]
21Feb13_050158| [ 1.12898 -0.02920 -0.26203]
21Feb13_050158| [ 0.01925  0.39530  0.50643]
21Feb13_050158| [-0.32905 -1.23882  0.15417]]
21Feb13_050158|-- Bias --
21Feb13_050158|[-0.19062 -0.26300  0.48239]
21Feb13_050158|Layer 1:
21Feb13_050158|-- Config --
21Feb13_050158|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050158|-- Weights --
21Feb13_050158|[[ 0.14457 -0.61956]
21Feb13_050158| [ 1.29113 -0.25904]
21Feb13_050158| [-0.56150  0.30090]]
21Feb13_050158|-- Bias --
21Feb13_050158|[-1.10658  0.88662]
21Feb13_050158|Layer 2:
21Feb13_050158|-- Config --
21Feb13_050158|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050158|-- Weights --
21Feb13_050158|[[ 0.36463 -0.59654  0.07558  1.03681]
21Feb13_050158| [-0.69100  0.65045  0.69266 -0.09649]]
21Feb13_050158|-- Bias --
21Feb13_050158|[-0.34203 -0.15489 -0.67530 -0.34361]
21Feb13_050158|Layer 3:
21Feb13_050158|-- Config --
21Feb13_050158|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050158|-- Weights --
21Feb13_050158|[[ 0.74009  0.50107]
21Feb13_050158| [-0.91862  0.58181]
21Feb13_050158| [-0.52087 -0.10176]
21Feb13_050158| [-0.81097 -0.60657]]
21Feb13_050158|-- Bias --
21Feb13_050158|[-0.72207 -0.14119]
21Feb13_050158|Layer 4:
21Feb13_050158|-- Config --
21Feb13_050158|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050158|-- Weights --
21Feb13_050158|[[-0.36379  0.38387]
21Feb13_050158| [-0.13610  0.43138]]
21Feb13_050158|-- Bias --
21Feb13_050158|[-0.83070 -0.86913]
21Feb13_050158|Predicting the validation and test data with the Best final individual.
21Feb13_050206| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_050206|-----------  ------------------  --------------------  ----------
21Feb13_050206|Validation         29.57                  44            0.32417
21Feb13_050206|   Test            26.50                  44            0.51823
21Feb13_050206|-------------------- Test #11 --------------------
21Feb13_050206|Best final individual weights
21Feb13_050206|Individual:
21Feb13_050206|-- Constant hidden layers --
21Feb13_050206|False
21Feb13_050206|Layer 0:
21Feb13_050206|-- Config --
21Feb13_050206|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050206|-- Weights --
21Feb13_050206|[[-0.64119  0.41758  0.44403]
21Feb13_050206| [-0.19170 -0.56915 -0.25835]
21Feb13_050206| [ 0.24167 -0.25140  0.76563]
21Feb13_050206| [-0.34028 -0.39268 -0.81387]
21Feb13_050206| [-1.86022 -0.52041 -0.44819]
21Feb13_050206| [ 0.38513  0.25171 -0.11380]
21Feb13_050206| [ 0.22209 -0.92597  0.19546]
21Feb13_050206| [-0.71141 -0.41559  0.24085]
21Feb13_050206| [ 0.05990  1.53864 -0.15835]
21Feb13_050206| [ 0.57521 -0.04311  0.55248]
21Feb13_050206| [ 0.86173  0.05786  0.38030]
21Feb13_050206| [ 0.73310 -0.78236  0.48030]
21Feb13_050206| [ 0.40395 -0.34893 -0.71762]
21Feb13_050206| [ 0.11846 -0.72835  1.43541]
21Feb13_050206| [-0.44861 -0.75277  0.14467]
21Feb13_050206| [ 1.41428  1.05661  0.10286]
21Feb13_050206| [-1.57835 -0.10784  0.05255]
21Feb13_050206| [-0.47421 -0.65751  0.28725]
21Feb13_050206| [ 0.72747  0.12939  0.31006]
21Feb13_050206| [-1.18189  0.27777  0.58656]
21Feb13_050206| [-1.11883 -0.35427 -0.17962]
21Feb13_050206| [ 0.39343 -0.84418 -0.51133]
21Feb13_050206| [ 1.00598  0.61810 -0.21078]
21Feb13_050206| [-0.04015 -0.79351 -0.26753]
21Feb13_050206| [-0.66727  0.28333 -0.43119]
21Feb13_050206| [-0.14585  0.91540  0.81437]
21Feb13_050206| [ 0.13566  0.49138 -0.05944]
21Feb13_050206| [-0.22291  0.86713  1.13344]
21Feb13_050206| [-1.03502  1.56032  0.35828]
21Feb13_050206| [ 0.12223  0.39820  0.44290]
21Feb13_050206| [-1.42658 -0.38599  0.26524]
21Feb13_050206| [-0.52719  1.17703  0.62097]
21Feb13_050206| [ 0.52938  0.21738 -0.06837]
21Feb13_050206| [-0.87508  2.16887  0.32327]
21Feb13_050206| [ 1.35043 -0.65136  0.02642]
21Feb13_050206| [ 1.06028  0.80071 -0.96029]
21Feb13_050206| [-1.86678  0.53951 -0.02691]
21Feb13_050206| [ 1.73320 -1.35784  0.01810]
21Feb13_050206| [-0.03018 -0.70820 -0.34020]
21Feb13_050206| [-0.65415  0.11126 -0.54490]
21Feb13_050206| [ 1.14516 -0.84749  0.70247]
21Feb13_050206| [-0.64028  0.15453 -1.10559]
21Feb13_050206| [-0.18582 -0.94763 -0.78661]
21Feb13_050206| [ 0.90123 -0.72541  1.12612]
21Feb13_050206| [ 0.42551 -0.77656 -0.45109]
21Feb13_050206| [ 0.43603  1.06729  0.60801]
21Feb13_050206| [ 1.36190 -0.56744  0.83111]
21Feb13_050206| [-0.63814  1.07761 -0.29382]
21Feb13_050206| [-2.38452 -1.49477  0.68283]
21Feb13_050206| [-0.75870 -1.11212 -1.75709]
21Feb13_050206| [-0.20420 -1.34511  0.73343]
21Feb13_050206| [-0.20964 -0.04696 -0.11643]
21Feb13_050206| [ 0.02903  1.17196  0.19512]
21Feb13_050206| [ 0.67410  0.98823  0.20455]
21Feb13_050206| [ 1.12898 -0.02920 -0.26203]
21Feb13_050206| [ 0.01925  0.39530  0.50643]
21Feb13_050206| [-0.32905 -1.23882  0.15417]]
21Feb13_050206|-- Bias --
21Feb13_050206|[-0.19062 -0.26300  0.48239]
21Feb13_050206|Layer 1:
21Feb13_050206|-- Config --
21Feb13_050206|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050206|-- Weights --
21Feb13_050206|[[ 0.14457 -0.61956]
21Feb13_050206| [ 1.29113 -0.25904]
21Feb13_050206| [-0.56150  0.30090]]
21Feb13_050206|-- Bias --
21Feb13_050206|[-1.10658  0.88662]
21Feb13_050206|Layer 2:
21Feb13_050206|-- Config --
21Feb13_050206|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050206|-- Weights --
21Feb13_050206|[[ 0.36463 -0.59654  0.07558  1.03681]
21Feb13_050206| [-0.69100  0.65045  0.69266 -0.09649]]
21Feb13_050206|-- Bias --
21Feb13_050206|[-0.34203 -0.15489 -0.67530 -0.34361]
21Feb13_050206|Layer 3:
21Feb13_050206|-- Config --
21Feb13_050206|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050206|-- Weights --
21Feb13_050206|[[ 0.74009  0.50107]
21Feb13_050206| [-0.91862  0.58181]
21Feb13_050206| [-0.52087 -0.10176]
21Feb13_050206| [-0.81097 -0.60657]]
21Feb13_050206|-- Bias --
21Feb13_050206|[-0.72207 -0.14119]
21Feb13_050206|Layer 4:
21Feb13_050206|-- Config --
21Feb13_050206|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050206|-- Weights --
21Feb13_050206|[[-0.36379  0.38387]
21Feb13_050206| [-0.13610  0.43138]]
21Feb13_050206|-- Bias --
21Feb13_050206|[-0.83070 -0.86913]
21Feb13_050206|Predicting the validation and test data with the Best final individual.
21Feb13_050214| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_050214|-----------  ------------------  --------------------  ----------
21Feb13_050214|Validation         25.65                  44            0.52109
21Feb13_050214|   Test            25.63                  44            0.50728
21Feb13_050214|-------------------- Test #12 --------------------
21Feb13_050214|Best final individual weights
21Feb13_050214|Individual:
21Feb13_050214|-- Constant hidden layers --
21Feb13_050214|False
21Feb13_050214|Layer 0:
21Feb13_050214|-- Config --
21Feb13_050214|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050214|-- Weights --
21Feb13_050214|[[-0.64119  0.41758  0.44403]
21Feb13_050214| [-0.19170 -0.56915 -0.25835]
21Feb13_050214| [ 0.24167 -0.25140  0.76563]
21Feb13_050214| [-0.34028 -0.39268 -0.81387]
21Feb13_050214| [-1.86022 -0.52041 -0.44819]
21Feb13_050214| [ 0.38513  0.25171 -0.11380]
21Feb13_050214| [ 0.22209 -0.92597  0.19546]
21Feb13_050214| [-0.71141 -0.41559  0.24085]
21Feb13_050214| [ 0.05990  1.53864 -0.15835]
21Feb13_050214| [ 0.57521 -0.04311  0.55248]
21Feb13_050214| [ 0.86173  0.05786  0.38030]
21Feb13_050214| [ 0.73310 -0.78236  0.48030]
21Feb13_050214| [ 0.40395 -0.34893 -0.71762]
21Feb13_050214| [ 0.11846 -0.72835  1.43541]
21Feb13_050214| [-0.44861 -0.75277  0.14467]
21Feb13_050214| [ 1.41428  1.05661  0.10286]
21Feb13_050214| [-1.57835 -0.10784  0.05255]
21Feb13_050214| [-0.47421 -0.65751  0.28725]
21Feb13_050214| [ 0.72747  0.12939  0.31006]
21Feb13_050214| [-1.18189  0.27777  0.58656]
21Feb13_050214| [-1.11883 -0.35427 -0.17962]
21Feb13_050214| [ 0.39343 -0.84418 -0.51133]
21Feb13_050214| [ 1.00598  0.61810 -0.21078]
21Feb13_050214| [-0.04015 -0.79351 -0.26753]
21Feb13_050214| [-0.66727  0.28333 -0.43119]
21Feb13_050214| [-0.14585  0.91540  0.81437]
21Feb13_050214| [ 0.13566  0.49138 -0.05944]
21Feb13_050214| [-0.22291  0.86713  1.13344]
21Feb13_050214| [-1.03502  1.56032  0.35828]
21Feb13_050214| [ 0.12223  0.39820  0.44290]
21Feb13_050214| [-1.42658 -0.38599  0.26524]
21Feb13_050214| [-0.52719  1.17703  0.62097]
21Feb13_050214| [ 0.52938  0.21738 -0.06837]
21Feb13_050214| [-0.87508  2.16887  0.32327]
21Feb13_050214| [ 1.35043 -0.65136  0.02642]
21Feb13_050214| [ 1.06028  0.80071 -0.96029]
21Feb13_050214| [-1.86678  0.53951 -0.02691]
21Feb13_050214| [ 1.73320 -1.35784  0.01810]
21Feb13_050214| [-0.03018 -0.70820 -0.34020]
21Feb13_050214| [-0.65415  0.11126 -0.54490]
21Feb13_050214| [ 1.14516 -0.84749  0.70247]
21Feb13_050214| [-0.64028  0.15453 -1.10559]
21Feb13_050214| [-0.18582 -0.94763 -0.78661]
21Feb13_050214| [ 0.90123 -0.72541  1.12612]
21Feb13_050214| [ 0.42551 -0.77656 -0.45109]
21Feb13_050214| [ 0.43603  1.06729  0.60801]
21Feb13_050214| [ 1.36190 -0.56744  0.83111]
21Feb13_050214| [-0.63814  1.07761 -0.29382]
21Feb13_050214| [-2.38452 -1.49477  0.68283]
21Feb13_050214| [-0.75870 -1.11212 -1.75709]
21Feb13_050214| [-0.20420 -1.34511  0.73343]
21Feb13_050214| [-0.20964 -0.04696 -0.11643]
21Feb13_050214| [ 0.02903  1.17196  0.19512]
21Feb13_050214| [ 0.67410  0.98823  0.20455]
21Feb13_050214| [ 1.12898 -0.02920 -0.26203]
21Feb13_050214| [ 0.01925  0.39530  0.50643]
21Feb13_050214| [-0.32905 -1.23882  0.15417]]
21Feb13_050214|-- Bias --
21Feb13_050214|[-0.19062 -0.26300  0.48239]
21Feb13_050214|Layer 1:
21Feb13_050214|-- Config --
21Feb13_050214|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050214|-- Weights --
21Feb13_050214|[[ 0.14457 -0.61956]
21Feb13_050214| [ 1.29113 -0.25904]
21Feb13_050214| [-0.56150  0.30090]]
21Feb13_050214|-- Bias --
21Feb13_050214|[-1.10658  0.88662]
21Feb13_050214|Layer 2:
21Feb13_050214|-- Config --
21Feb13_050214|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050214|-- Weights --
21Feb13_050214|[[ 0.36463 -0.59654  0.07558  1.03681]
21Feb13_050214| [-0.69100  0.65045  0.69266 -0.09649]]
21Feb13_050214|-- Bias --
21Feb13_050214|[-0.34203 -0.15489 -0.67530 -0.34361]
21Feb13_050214|Layer 3:
21Feb13_050214|-- Config --
21Feb13_050214|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050214|-- Weights --
21Feb13_050214|[[ 0.74009  0.50107]
21Feb13_050214| [-0.91862  0.58181]
21Feb13_050214| [-0.52087 -0.10176]
21Feb13_050214| [-0.81097 -0.60657]]
21Feb13_050214|-- Bias --
21Feb13_050214|[-0.72207 -0.14119]
21Feb13_050214|Layer 4:
21Feb13_050214|-- Config --
21Feb13_050214|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050214|-- Weights --
21Feb13_050214|[[-0.36379  0.38387]
21Feb13_050214| [-0.13610  0.43138]]
21Feb13_050214|-- Bias --
21Feb13_050214|[-0.83070 -0.86913]
21Feb13_050214|Predicting the validation and test data with the Best final individual.
21Feb13_050222| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_050222|-----------  ------------------  --------------------  ----------
21Feb13_050222|Validation         27.83                  44            0.38088
21Feb13_050222|   Test            25.63                  44            0.51499
21Feb13_050222|-------------------- Test #13 --------------------
21Feb13_050222|Best final individual weights
21Feb13_050222|Individual:
21Feb13_050222|-- Constant hidden layers --
21Feb13_050222|False
21Feb13_050222|Layer 0:
21Feb13_050222|-- Config --
21Feb13_050222|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050222|-- Weights --
21Feb13_050222|[[-0.64119  0.41758  0.44403]
21Feb13_050222| [-0.19170 -0.56915 -0.25835]
21Feb13_050222| [ 0.24167 -0.25140  0.76563]
21Feb13_050222| [-0.34028 -0.39268 -0.81387]
21Feb13_050222| [-1.86022 -0.52041 -0.44819]
21Feb13_050222| [ 0.38513  0.25171 -0.11380]
21Feb13_050222| [ 0.22209 -0.92597  0.19546]
21Feb13_050222| [-0.71141 -0.41559  0.24085]
21Feb13_050222| [ 0.05990  1.53864 -0.15835]
21Feb13_050222| [ 0.57521 -0.04311  0.55248]
21Feb13_050222| [ 0.86173  0.05786  0.38030]
21Feb13_050222| [ 0.73310 -0.78236  0.48030]
21Feb13_050222| [ 0.40395 -0.34893 -0.71762]
21Feb13_050222| [ 0.11846 -0.72835  1.43541]
21Feb13_050222| [-0.44861 -0.75277  0.14467]
21Feb13_050222| [ 1.41428  1.05661  0.10286]
21Feb13_050222| [-1.57835 -0.10784  0.05255]
21Feb13_050222| [-0.47421 -0.65751  0.28725]
21Feb13_050222| [ 0.72747  0.12939  0.31006]
21Feb13_050222| [-1.18189  0.27777  0.58656]
21Feb13_050222| [-1.11883 -0.35427 -0.17962]
21Feb13_050222| [ 0.39343 -0.84418 -0.51133]
21Feb13_050222| [ 1.00598  0.61810 -0.21078]
21Feb13_050222| [-0.04015 -0.79351 -0.26753]
21Feb13_050222| [-0.66727  0.28333 -0.43119]
21Feb13_050222| [-0.14585  0.91540  0.81437]
21Feb13_050222| [ 0.13566  0.49138 -0.05944]
21Feb13_050222| [-0.22291  0.86713  1.13344]
21Feb13_050222| [-1.03502  1.56032  0.35828]
21Feb13_050222| [ 0.12223  0.39820  0.44290]
21Feb13_050222| [-1.42658 -0.38599  0.26524]
21Feb13_050222| [-0.52719  1.17703  0.62097]
21Feb13_050222| [ 0.52938  0.21738 -0.06837]
21Feb13_050222| [-0.87508  2.16887  0.32327]
21Feb13_050222| [ 1.35043 -0.65136  0.02642]
21Feb13_050222| [ 1.06028  0.80071 -0.96029]
21Feb13_050222| [-1.86678  0.53951 -0.02691]
21Feb13_050222| [ 1.73320 -1.35784  0.01810]
21Feb13_050222| [-0.03018 -0.70820 -0.34020]
21Feb13_050222| [-0.65415  0.11126 -0.54490]
21Feb13_050222| [ 1.14516 -0.84749  0.70247]
21Feb13_050222| [-0.64028  0.15453 -1.10559]
21Feb13_050222| [-0.18582 -0.94763 -0.78661]
21Feb13_050222| [ 0.90123 -0.72541  1.12612]
21Feb13_050222| [ 0.42551 -0.77656 -0.45109]
21Feb13_050222| [ 0.43603  1.06729  0.60801]
21Feb13_050222| [ 1.36190 -0.56744  0.83111]
21Feb13_050222| [-0.63814  1.07761 -0.29382]
21Feb13_050222| [-2.38452 -1.49477  0.68283]
21Feb13_050222| [-0.75870 -1.11212 -1.75709]
21Feb13_050222| [-0.20420 -1.34511  0.73343]
21Feb13_050222| [-0.20964 -0.04696 -0.11643]
21Feb13_050222| [ 0.02903  1.17196  0.19512]
21Feb13_050222| [ 0.67410  0.98823  0.20455]
21Feb13_050222| [ 1.12898 -0.02920 -0.26203]
21Feb13_050222| [ 0.01925  0.39530  0.50643]
21Feb13_050222| [-0.32905 -1.23882  0.15417]]
21Feb13_050222|-- Bias --
21Feb13_050222|[-0.19062 -0.26300  0.48239]
21Feb13_050222|Layer 1:
21Feb13_050222|-- Config --
21Feb13_050222|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050222|-- Weights --
21Feb13_050222|[[ 0.14457 -0.61956]
21Feb13_050222| [ 1.29113 -0.25904]
21Feb13_050222| [-0.56150  0.30090]]
21Feb13_050222|-- Bias --
21Feb13_050222|[-1.10658  0.88662]
21Feb13_050222|Layer 2:
21Feb13_050222|-- Config --
21Feb13_050222|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050222|-- Weights --
21Feb13_050222|[[ 0.36463 -0.59654  0.07558  1.03681]
21Feb13_050222| [-0.69100  0.65045  0.69266 -0.09649]]
21Feb13_050222|-- Bias --
21Feb13_050222|[-0.34203 -0.15489 -0.67530 -0.34361]
21Feb13_050222|Layer 3:
21Feb13_050222|-- Config --
21Feb13_050222|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050222|-- Weights --
21Feb13_050222|[[ 0.74009  0.50107]
21Feb13_050222| [-0.91862  0.58181]
21Feb13_050222| [-0.52087 -0.10176]
21Feb13_050222| [-0.81097 -0.60657]]
21Feb13_050222|-- Bias --
21Feb13_050222|[-0.72207 -0.14119]
21Feb13_050222|Layer 4:
21Feb13_050222|-- Config --
21Feb13_050222|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050222|-- Weights --
21Feb13_050222|[[-0.36379  0.38387]
21Feb13_050222| [-0.13610  0.43138]]
21Feb13_050222|-- Bias --
21Feb13_050222|[-0.83070 -0.86913]
21Feb13_050222|Predicting the validation and test data with the Best final individual.
21Feb13_050230| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_050230|-----------  ------------------  --------------------  ----------
21Feb13_050230|Validation         25.22                  44            0.46703
21Feb13_050230|   Test            26.67                  44            0.42628
21Feb13_050230|-------------------- Test #14 --------------------
21Feb13_050230|Best final individual weights
21Feb13_050230|Individual:
21Feb13_050230|-- Constant hidden layers --
21Feb13_050230|False
21Feb13_050230|Layer 0:
21Feb13_050230|-- Config --
21Feb13_050230|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050230|-- Weights --
21Feb13_050230|[[-0.64119  0.41758  0.44403]
21Feb13_050230| [-0.19170 -0.56915 -0.25835]
21Feb13_050230| [ 0.24167 -0.25140  0.76563]
21Feb13_050230| [-0.34028 -0.39268 -0.81387]
21Feb13_050230| [-1.86022 -0.52041 -0.44819]
21Feb13_050230| [ 0.38513  0.25171 -0.11380]
21Feb13_050230| [ 0.22209 -0.92597  0.19546]
21Feb13_050230| [-0.71141 -0.41559  0.24085]
21Feb13_050230| [ 0.05990  1.53864 -0.15835]
21Feb13_050230| [ 0.57521 -0.04311  0.55248]
21Feb13_050230| [ 0.86173  0.05786  0.38030]
21Feb13_050230| [ 0.73310 -0.78236  0.48030]
21Feb13_050230| [ 0.40395 -0.34893 -0.71762]
21Feb13_050230| [ 0.11846 -0.72835  1.43541]
21Feb13_050230| [-0.44861 -0.75277  0.14467]
21Feb13_050230| [ 1.41428  1.05661  0.10286]
21Feb13_050230| [-1.57835 -0.10784  0.05255]
21Feb13_050230| [-0.47421 -0.65751  0.28725]
21Feb13_050230| [ 0.72747  0.12939  0.31006]
21Feb13_050230| [-1.18189  0.27777  0.58656]
21Feb13_050230| [-1.11883 -0.35427 -0.17962]
21Feb13_050230| [ 0.39343 -0.84418 -0.51133]
21Feb13_050230| [ 1.00598  0.61810 -0.21078]
21Feb13_050230| [-0.04015 -0.79351 -0.26753]
21Feb13_050230| [-0.66727  0.28333 -0.43119]
21Feb13_050230| [-0.14585  0.91540  0.81437]
21Feb13_050230| [ 0.13566  0.49138 -0.05944]
21Feb13_050230| [-0.22291  0.86713  1.13344]
21Feb13_050230| [-1.03502  1.56032  0.35828]
21Feb13_050230| [ 0.12223  0.39820  0.44290]
21Feb13_050230| [-1.42658 -0.38599  0.26524]
21Feb13_050230| [-0.52719  1.17703  0.62097]
21Feb13_050230| [ 0.52938  0.21738 -0.06837]
21Feb13_050230| [-0.87508  2.16887  0.32327]
21Feb13_050230| [ 1.35043 -0.65136  0.02642]
21Feb13_050230| [ 1.06028  0.80071 -0.96029]
21Feb13_050230| [-1.86678  0.53951 -0.02691]
21Feb13_050230| [ 1.73320 -1.35784  0.01810]
21Feb13_050230| [-0.03018 -0.70820 -0.34020]
21Feb13_050230| [-0.65415  0.11126 -0.54490]
21Feb13_050230| [ 1.14516 -0.84749  0.70247]
21Feb13_050230| [-0.64028  0.15453 -1.10559]
21Feb13_050230| [-0.18582 -0.94763 -0.78661]
21Feb13_050230| [ 0.90123 -0.72541  1.12612]
21Feb13_050230| [ 0.42551 -0.77656 -0.45109]
21Feb13_050230| [ 0.43603  1.06729  0.60801]
21Feb13_050230| [ 1.36190 -0.56744  0.83111]
21Feb13_050230| [-0.63814  1.07761 -0.29382]
21Feb13_050230| [-2.38452 -1.49477  0.68283]
21Feb13_050230| [-0.75870 -1.11212 -1.75709]
21Feb13_050230| [-0.20420 -1.34511  0.73343]
21Feb13_050230| [-0.20964 -0.04696 -0.11643]
21Feb13_050230| [ 0.02903  1.17196  0.19512]
21Feb13_050230| [ 0.67410  0.98823  0.20455]
21Feb13_050230| [ 1.12898 -0.02920 -0.26203]
21Feb13_050230| [ 0.01925  0.39530  0.50643]
21Feb13_050230| [-0.32905 -1.23882  0.15417]]
21Feb13_050230|-- Bias --
21Feb13_050230|[-0.19062 -0.26300  0.48239]
21Feb13_050230|Layer 1:
21Feb13_050230|-- Config --
21Feb13_050230|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050230|-- Weights --
21Feb13_050230|[[ 0.14457 -0.61956]
21Feb13_050230| [ 1.29113 -0.25904]
21Feb13_050230| [-0.56150  0.30090]]
21Feb13_050230|-- Bias --
21Feb13_050230|[-1.10658  0.88662]
21Feb13_050230|Layer 2:
21Feb13_050230|-- Config --
21Feb13_050230|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050230|-- Weights --
21Feb13_050230|[[ 0.36463 -0.59654  0.07558  1.03681]
21Feb13_050230| [-0.69100  0.65045  0.69266 -0.09649]]
21Feb13_050230|-- Bias --
21Feb13_050230|[-0.34203 -0.15489 -0.67530 -0.34361]
21Feb13_050230|Layer 3:
21Feb13_050230|-- Config --
21Feb13_050230|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050230|-- Weights --
21Feb13_050230|[[ 0.74009  0.50107]
21Feb13_050230| [-0.91862  0.58181]
21Feb13_050230| [-0.52087 -0.10176]
21Feb13_050230| [-0.81097 -0.60657]]
21Feb13_050230|-- Bias --
21Feb13_050230|[-0.72207 -0.14119]
21Feb13_050230|Layer 4:
21Feb13_050230|-- Config --
21Feb13_050230|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_050230|-- Weights --
21Feb13_050230|[[-0.36379  0.38387]
21Feb13_050230| [-0.13610  0.43138]]
21Feb13_050230|-- Bias --
21Feb13_050230|[-0.83070 -0.86913]
21Feb13_050230|Predicting the validation and test data with the Best final individual.
21Feb13_050238| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_050238|-----------  ------------------  --------------------  ----------
21Feb13_050238|Validation         25.48                  44            0.51774
21Feb13_050238|   Test            26.76                  44            0.45072
2021-02-13 05:02:39.502398: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
21Feb13_050240|Data summary: Train
21Feb13_050240|data.shape = (2300, 57)
21Feb13_050240|labels.shape = (2300,)
21Feb13_050240|Class distribution:
21Feb13_050240|	0 - 1382 (0.60)
21Feb13_050240|	1 - 918 (0.40)
21Feb13_050240|Data summary: Validation
21Feb13_050240|data.shape = (1150, 57)
21Feb13_050240|labels.shape = (1150,)
21Feb13_050240|Class distribution:
21Feb13_050240|	0 - 704 (0.61)
21Feb13_050240|	1 - 446 (0.39)
21Feb13_050240|Data summary: Test
21Feb13_050240|data.shape = (1151, 57)
21Feb13_050240|labels.shape = (1151,)
21Feb13_050240|Class distribution:
21Feb13_050240|	0 - 702 (0.61)
21Feb13_050240|	1 - 449 (0.39)
21Feb13_050240|Selected configuration values
21Feb13_050240|-- Dataset name: spambase1
21Feb13_050240|-- Initial population size: 64
21Feb13_050240|-- Maximun number of generations: 32
21Feb13_050240|-- Neurons per hidden layer range: (2, 20)
21Feb13_050240|-- Hidden layers number range: (1, 3)
21Feb13_050240|-- Crossover probability: 0.5
21Feb13_050240|-- Bias gene mutation probability: 0.2
21Feb13_050240|-- Weights gene mutation probability: 0.75
21Feb13_050240|-- Neuron mutation probability: 0.3
21Feb13_050240|-- Layer mutation probability: 0.3
21Feb13_050240|-- Constant hidden layers: False
21Feb13_050240|-- Seed: 31415
21Feb13_050240|Entering GA
21Feb13_050240|Start the algorithm
2021-02-13 05:02:40.354909: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-13 05:02:40.355481: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-02-13 05:02:40.379027: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-13 05:02:40.379356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.71GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s
2021-02-13 05:02:40.379370: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-02-13 05:02:40.380850: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-02-13 05:02:40.380883: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-02-13 05:02:40.381385: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-02-13 05:02:40.381524: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-02-13 05:02:40.381596: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-13 05:02:40.382008: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-02-13 05:02:40.382048: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-13 05:02:40.382054: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-02-13 05:02:40.382244: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-02-13 05:02:40.383050: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-13 05:02:40.383068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-13 05:02:40.383072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      
2021-02-13 05:02:40.436674: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-02-13 05:02:40.437008: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3493635000 Hz
/home/jmerelo/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype("int32")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn('`model.predict_classes()` is deprecated and '
21Feb13_050640|-- Generation 1 --
21Feb13_050640|    -- Crossed 0 individual pairs.
21Feb13_050640|    -- Mutated 32 individuals.
21Feb13_051039|    -- Evaluated 64 individuals.
21Feb13_051039|    Summary of generation 1:
21Feb13_051039| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_051039|-----------  ------------------  --------------------  ----------
21Feb13_051039|    Max            39.30                180.00          0.80442
21Feb13_051039|    Avg            38.76                49.36           0.01512
21Feb13_051039|    Min            33.22                 3.00           0.00000
21Feb13_051039|    Std             0.78                45.62           0.10068
21Feb13_051039|   Best            33.22                24.00           0.80442
21Feb13_051039|-- Generation 2 --
21Feb13_051039|    -- Crossed 2 individual pairs.
21Feb13_051039|    -- Mutated 32 individuals.
21Feb13_051437|    -- Evaluated 64 individuals.
21Feb13_051437|    Summary of generation 2:
21Feb13_051437| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_051437|-----------  ------------------  --------------------  ----------
21Feb13_051437|    Max            39.30                180.00          0.44263
21Feb13_051437|    Avg            38.55                42.88           0.01204
21Feb13_051437|    Min            28.35                 3.00           0.00000
21Feb13_051437|    Std             1.56                42.87           0.06469
21Feb13_051437|   Best            28.35                36.00           0.44263
21Feb13_051437|-- Generation 3 --
21Feb13_051437|    -- Crossed 2 individual pairs.
21Feb13_051437|    -- Mutated 32 individuals.
21Feb13_051831|    -- Evaluated 64 individuals.
21Feb13_051831|    Summary of generation 3:
21Feb13_051831| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_051831|-----------  ------------------  --------------------  ----------
21Feb13_051831|    Max            39.39                69.00           0.77759
21Feb13_051831|    Avg            38.22                22.84           0.02701
21Feb13_051831|    Min            24.26                 2.00           0.00000
21Feb13_051831|    Std             2.73                19.39           0.12291
21Feb13_051831|   Best            24.26                30.00           0.77759
21Feb13_051831|-- Generation 4 --
21Feb13_051831|    -- Crossed 1 individual pairs.
21Feb13_051831|    -- Mutated 32 individuals.
21Feb13_052224|    -- Evaluated 64 individuals.
21Feb13_052224|    Summary of generation 4:
21Feb13_052224| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_052224|-----------  ------------------  --------------------  ----------
21Feb13_052224|    Max            39.13                60.00           0.79574
21Feb13_052224|    Avg            37.94                17.09           0.04543
21Feb13_052224|    Min            25.57                 2.00           0.00000
21Feb13_052224|    Std             3.06                13.31           0.16478
21Feb13_052224|   Best            25.57                52.00           0.79574
21Feb13_052224|-- Generation 5 --
21Feb13_052224|    -- Crossed 4 individual pairs.
21Feb13_052224|    -- Mutated 32 individuals.
21Feb13_052614|    -- Evaluated 64 individuals.
21Feb13_052614|    Summary of generation 5:
21Feb13_052614| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_052614|-----------  ------------------  --------------------  ----------
21Feb13_052614|    Max            39.30                60.00           0.66593
21Feb13_052614|    Avg            37.71                11.52           0.04840
21Feb13_052614|    Min            23.48                 2.00           0.00000
21Feb13_052614|    Std             3.34                13.75           0.14827
21Feb13_052614|   Best            23.48                52.00           0.64747
21Feb13_052614|-- Generation 6 --
21Feb13_052614|    -- Crossed 5 individual pairs.
21Feb13_052614|    -- Mutated 32 individuals.
21Feb13_053006|    -- Evaluated 64 individuals.
21Feb13_053006|    Summary of generation 6:
21Feb13_053006| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_053006|-----------  ------------------  --------------------  ----------
21Feb13_053006|    Max            39.39                60.00           0.77265
21Feb13_053006|    Avg            37.77                12.62           0.05992
21Feb13_053006|    Min            25.48                 2.00           0.00000
21Feb13_053006|    Std             3.18                15.72           0.17590
21Feb13_053006|   Best            25.48                36.00           0.50611
21Feb13_053006|-- Generation 7 --
21Feb13_053006|    -- Crossed 8 individual pairs.
21Feb13_053006|    -- Mutated 32 individuals.
21Feb13_053356|    -- Evaluated 64 individuals.
21Feb13_053356|    Summary of generation 7:
21Feb13_053356| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_053356|-----------  ------------------  --------------------  ----------
21Feb13_053356|    Max            42.87                56.00           0.77760
21Feb13_053356|    Avg            37.95                11.70           0.05334
21Feb13_053356|    Min            22.26                 2.00           0.00000
21Feb13_053356|    Std             3.24                14.30           0.18140
21Feb13_053356|   Best            22.26                52.00           0.73203
21Feb13_053356|-- Generation 8 --
21Feb13_053356|    -- Crossed 6 individual pairs.
21Feb13_053356|    -- Mutated 32 individuals.
21Feb13_053746|    -- Evaluated 64 individuals.
21Feb13_053746|    Summary of generation 8:
21Feb13_053746| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_053746|-----------  ------------------  --------------------  ----------
21Feb13_053746|    Max            39.13                90.00           0.81409
21Feb13_053746|    Avg            37.70                11.20           0.06300
21Feb13_053746|    Min            24.17                 2.00           0.00000
21Feb13_053746|    Std             3.45                16.96           0.19692
21Feb13_053746|   Best            24.17                36.00           0.56513
21Feb13_053746|-- Generation 9 --
21Feb13_053746|    -- Crossed 9 individual pairs.
21Feb13_053746|    -- Mutated 32 individuals.
21Feb13_054136|    -- Evaluated 64 individuals.
21Feb13_054136|    Summary of generation 9:
21Feb13_054136| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_054136|-----------  ------------------  --------------------  ----------
21Feb13_054136|    Max            39.13                68.00           0.75589
21Feb13_054136|    Avg            37.17                11.61           0.09140
21Feb13_054136|    Min            21.13                 2.00           0.00000
21Feb13_054136|    Std             4.38                17.19           0.23474
21Feb13_054136|   Best            21.13                56.00           0.71719
21Feb13_054136|-- Generation 10 --
21Feb13_054136|    -- Crossed 7 individual pairs.
21Feb13_054136|    -- Mutated 32 individuals.
21Feb13_054530|    -- Evaluated 64 individuals.
21Feb13_054530|    Summary of generation 10:
21Feb13_054530| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_054530|-----------  ------------------  --------------------  ----------
21Feb13_054530|    Max            44.61                90.00           0.79933
21Feb13_054530|    Avg            36.37                17.97           0.14076
21Feb13_054530|    Min            22.00                 2.00           0.00000
21Feb13_054530|    Std             5.34                24.04           0.27690
21Feb13_054530|   Best            22.00                56.00           0.69451
21Feb13_054530|-- Generation 11 --
21Feb13_054530|    -- Crossed 6 individual pairs.
21Feb13_054530|    -- Mutated 32 individuals.
21Feb13_054928|    -- Evaluated 64 individuals.
21Feb13_054928|    Summary of generation 11:
21Feb13_054928| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_054928|-----------  ------------------  --------------------  ----------
21Feb13_054928|    Max            39.30                90.00           0.82485
21Feb13_054928|    Avg            35.97                25.39           0.15278
21Feb13_054928|    Min            22.78                 2.00           0.00000
21Feb13_054928|    Std             5.47                28.25           0.29113
21Feb13_054928|   Best            22.78                60.00           0.69982
21Feb13_054928|-- Generation 12 --
21Feb13_054928|    -- Crossed 3 individual pairs.
21Feb13_054928|    -- Mutated 32 individuals.
21Feb13_055326|    -- Evaluated 64 individuals.
21Feb13_055326|    Summary of generation 12:
21Feb13_055326| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_055326|-----------  ------------------  --------------------  ----------
21Feb13_055326|    Max            39.04                138.00          0.82459
21Feb13_055326|    Avg            34.98                27.52           0.20280
21Feb13_055326|    Min            22.17                 2.00           0.00000
21Feb13_055326|    Std             6.05                30.61           0.31573
21Feb13_055326|   Best            22.17                56.00           0.71812
21Feb13_055326|-- Generation 13 --
21Feb13_055326|    -- Crossed 3 individual pairs.
21Feb13_055327|    -- Mutated 32 individuals.
21Feb13_055730|    -- Evaluated 64 individuals.
21Feb13_055730|    Summary of generation 13:
21Feb13_055730| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_055730|-----------  ------------------  --------------------  ----------
21Feb13_055730|    Max            50.26                144.00          0.79266
21Feb13_055730|    Avg            34.20                38.62           0.25431
21Feb13_055730|    Min            18.87                 2.00           0.00000
21Feb13_055730|    Std             6.87                35.69           0.33016
21Feb13_055730|   Best            18.87                15.00           0.76837
21Feb13_055730|-- Generation 14 --
21Feb13_055730|    -- Crossed 2 individual pairs.
21Feb13_055730|    -- Mutated 32 individuals.
21Feb13_060138|    -- Evaluated 64 individuals.
21Feb13_060138|    Summary of generation 14:
21Feb13_060138| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_060138|-----------  ------------------  --------------------  ----------
21Feb13_060138|    Max            41.39                150.00          0.82046
21Feb13_060138|    Avg            34.01                48.80           0.26010
21Feb13_060138|    Min            22.87                 2.00           0.00000
21Feb13_060138|    Std             6.46                39.36           0.33692
21Feb13_060138|   Best            22.87                56.00           0.75751
21Feb13_060138|-- Generation 15 --
21Feb13_060138|    -- Crossed 1 individual pairs.
21Feb13_060138|    -- Mutated 32 individuals.
21Feb13_060550|    -- Evaluated 64 individuals.
21Feb13_060550|    Summary of generation 15:
21Feb13_060550| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_060550|-----------  ------------------  --------------------  ----------
21Feb13_060550|    Max            39.13                150.00          0.81916
21Feb13_060550|    Avg            32.91                61.80           0.30738
21Feb13_060550|    Min            20.61                 5.00           0.00000
21Feb13_060550|    Std             6.36                37.53           0.33090
21Feb13_060550|   Best            20.61                150.00          0.77378
21Feb13_060550|-- Generation 16 --
21Feb13_060550|    -- Crossed 0 individual pairs.
21Feb13_060550|    -- Mutated 32 individuals.
21Feb13_061009|    -- Evaluated 64 individuals.
21Feb13_061009|    Summary of generation 16:
21Feb13_061009| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_061009|-----------  ------------------  --------------------  ----------
21Feb13_061009|    Max            39.30                196.00          0.82555
21Feb13_061009|    Avg            32.77                75.84           0.35327
21Feb13_061009|    Min            21.48                 4.00           0.00000
21Feb13_061009|    Std             6.31                43.50           0.35890
21Feb13_061009|   Best            21.48                56.00           0.80879
21Feb13_061009|-- Generation 17 --
21Feb13_061009|    -- Crossed 0 individual pairs.
21Feb13_061009|    -- Mutated 32 individuals.
21Feb13_061432|    -- Evaluated 64 individuals.
21Feb13_061432|    Summary of generation 17:
21Feb13_061432| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_061432|-----------  ------------------  --------------------  ----------
21Feb13_061432|    Max            39.39                240.00          0.79878
21Feb13_061432|    Avg            31.33                94.78           0.40152
21Feb13_061432|    Min            21.57                30.00           0.00000
21Feb13_061432|    Std             6.28                47.90           0.33197
21Feb13_061432|   Best            21.57                138.00          0.75022
21Feb13_061432|-- Generation 18 --
21Feb13_061432|    -- Crossed 2 individual pairs.
21Feb13_061432|    -- Mutated 32 individuals.
21Feb13_061856|    -- Evaluated 64 individuals.
21Feb13_061856|    Summary of generation 18:
21Feb13_061856| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_061856|-----------  ------------------  --------------------  ----------
21Feb13_061856|    Max            39.48                196.00          0.81964
21Feb13_061856|    Avg            30.65                92.55           0.43947
21Feb13_061856|    Min            21.39                 8.00           0.00000
21Feb13_061856|    Std             6.56                43.29           0.33852
21Feb13_061856|   Best            21.39                138.00          0.69508
21Feb13_061856|-- Generation 19 --
21Feb13_061856|    -- Crossed 0 individual pairs.
21Feb13_061856|    -- Mutated 32 individuals.
21Feb13_062319|    -- Evaluated 64 individuals.
21Feb13_062319|    Summary of generation 19:
21Feb13_062319| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_062319|-----------  ------------------  --------------------  ----------
21Feb13_062319|    Max            41.83                203.00          0.83651
21Feb13_062319|    Avg            31.88                94.64           0.39633
21Feb13_062319|    Min            20.26                33.00           0.00000
21Feb13_062319|    Std             6.57                41.21           0.33688
21Feb13_062319|   Best            20.26                144.00          0.83651
21Feb13_062319|-- Generation 20 --
21Feb13_062319|    -- Crossed 0 individual pairs.
21Feb13_062319|    -- Mutated 32 individuals.
21Feb13_062742|    -- Evaluated 64 individuals.
21Feb13_062742|    Summary of generation 20:
21Feb13_062742| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_062742|-----------  ------------------  --------------------  ----------
21Feb13_062742|    Max            41.04                240.00          0.83476
21Feb13_062742|    Avg            29.69                92.42           0.48302
21Feb13_062742|    Min            18.52                33.00           0.00000
21Feb13_062742|    Std             6.73                42.37           0.32859
21Feb13_062742|   Best            18.52                144.00          0.73026
21Feb13_062742|-- Generation 21 --
21Feb13_062742|    -- Crossed 1 individual pairs.
21Feb13_062742|    -- Mutated 32 individuals.
21Feb13_063209|    -- Evaluated 64 individuals.
21Feb13_063209|    Summary of generation 21:
21Feb13_063209| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_063209|-----------  ------------------  --------------------  ----------
21Feb13_063209|    Max            39.22                306.00          0.87855
21Feb13_063209|    Avg            29.82                107.73          0.47621
21Feb13_063209|    Min            18.78                39.00           0.00000
21Feb13_063209|    Std             6.44                46.47           0.32399
21Feb13_063209|   Best            18.78                144.00          0.87855
21Feb13_063209|-- Generation 22 --
21Feb13_063209|    -- Crossed 0 individual pairs.
21Feb13_063209|    -- Mutated 32 individuals.
21Feb13_063636|    -- Evaluated 64 individuals.
21Feb13_063636|    Summary of generation 22:
21Feb13_063636| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_063636|-----------  ------------------  --------------------  ----------
21Feb13_063636|    Max            39.83                306.00          0.84465
21Feb13_063636|    Avg            30.05                103.53          0.47152
21Feb13_063636|    Min            20.35                33.00           0.00000
21Feb13_063636|    Std             6.42                50.84           0.33684
21Feb13_063636|   Best            20.35                144.00          0.83333
21Feb13_063636|-- Generation 23 --
21Feb13_063636|    -- Crossed 0 individual pairs.
21Feb13_063636|    -- Mutated 32 individuals.
21Feb13_064059|    -- Evaluated 64 individuals.
21Feb13_064059|    Summary of generation 23:
21Feb13_064059| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_064059|-----------  ------------------  --------------------  ----------
21Feb13_064059|    Max            56.78                196.00          0.85115
21Feb13_064059|    Avg            31.28                95.61           0.43016
21Feb13_064059|    Min            19.83                27.00           0.00000
21Feb13_064059|    Std             7.21                40.96           0.33644
21Feb13_064059|   Best            19.83                90.00           0.74597
21Feb13_064059|-- Generation 24 --
21Feb13_064059|    -- Crossed 0 individual pairs.
21Feb13_064059|    -- Mutated 32 individuals.
21Feb13_064525|    -- Evaluated 64 individuals.
21Feb13_064525|    Summary of generation 24:
21Feb13_064525| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_064525|-----------  ------------------  --------------------  ----------
21Feb13_064525|    Max            57.30                203.00          0.86837
21Feb13_064525|    Avg            29.81                93.55           0.48399
21Feb13_064525|    Min            17.30                27.00           0.00000
21Feb13_064525|    Std             7.20                40.59           0.31851
21Feb13_064525|   Best            17.30                144.00          0.86837
21Feb13_064525|-- Generation 25 --
21Feb13_064525|    -- Crossed 1 individual pairs.
21Feb13_064525|    -- Mutated 32 individuals.
21Feb13_064950|    -- Evaluated 64 individuals.
21Feb13_064950|    Summary of generation 25:
21Feb13_064950| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_064950|-----------  ------------------  --------------------  ----------
21Feb13_064950|    Max            39.04                203.00          0.85142
21Feb13_064950|    Avg            29.97                94.92           0.45224
21Feb13_064950|    Min            20.61                27.00           0.00000
21Feb13_064950|    Std             6.38                41.67           0.32951
21Feb13_064950|   Best            20.61                138.00          0.73668
21Feb13_064950|-- Generation 26 --
21Feb13_064950|    -- Crossed 0 individual pairs.
21Feb13_064950|    -- Mutated 32 individuals.
21Feb13_065413|    -- Evaluated 64 individuals.
21Feb13_065413|    Summary of generation 26:
21Feb13_065413| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_065413|-----------  ------------------  --------------------  ----------
21Feb13_065413|    Max            38.87                240.00          0.85726
21Feb13_065413|    Avg            31.04                90.53           0.42353
21Feb13_065413|    Min            18.96                27.00           0.00000
21Feb13_065413|    Std             6.66                41.87           0.34416
21Feb13_065413|   Best            18.96                56.00           0.85726
21Feb13_065413|-- Generation 27 --
21Feb13_065413|    -- Crossed 0 individual pairs.
21Feb13_065413|    -- Mutated 32 individuals.
21Feb13_065837|    -- Evaluated 64 individuals.
21Feb13_065837|    Summary of generation 27:
21Feb13_065837| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_065837|-----------  ------------------  --------------------  ----------
21Feb13_065837|    Max            39.13                240.00          0.84204
21Feb13_065837|    Avg            29.62                93.86           0.48828
21Feb13_065837|    Min            18.35                 8.00           0.00000
21Feb13_065837|    Std             6.58                47.83           0.31976
21Feb13_065837|   Best            18.35                144.00          0.72118
21Feb13_065837|-- Generation 28 --
21Feb13_065837|    -- Crossed 2 individual pairs.
21Feb13_065837|    -- Mutated 32 individuals.
21Feb13_070303|    -- Evaluated 64 individuals.
21Feb13_070303|    Summary of generation 28:
21Feb13_070303| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_070303|-----------  ------------------  --------------------  ----------
21Feb13_070303|    Max            39.91                240.00          0.84410
21Feb13_070303|    Avg            31.58                104.12          0.40966
21Feb13_070303|    Min            18.70                 8.00           0.00000
21Feb13_070303|    Std             6.29                48.75           0.33388
21Feb13_070303|   Best            18.70                138.00          0.79040
21Feb13_070303|-- Generation 29 --
21Feb13_070303|    -- Crossed 0 individual pairs.
21Feb13_070303|    -- Mutated 32 individuals.
21Feb13_070728|    -- Evaluated 64 individuals.
21Feb13_070728|    Summary of generation 29:
21Feb13_070728| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_070728|-----------  ------------------  --------------------  ----------
21Feb13_070728|    Max            39.22                240.00          0.85111
21Feb13_070728|    Avg            30.84                105.42          0.40320
21Feb13_070728|    Min            18.00                27.00           0.00000
21Feb13_070728|    Std             6.72                51.36           0.33898
21Feb13_070728|   Best            18.00                144.00          0.83009
21Feb13_070728|-- Generation 30 --
21Feb13_070728|    -- Crossed 0 individual pairs.
21Feb13_070728|    -- Mutated 32 individuals.
21Feb13_071151|    -- Evaluated 64 individuals.
21Feb13_071151|    Summary of generation 30:
21Feb13_071151| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_071151|-----------  ------------------  --------------------  ----------
21Feb13_071151|    Max            40.00                240.00          0.84382
21Feb13_071151|    Avg            32.02                95.45           0.36334
21Feb13_071151|    Min            20.61                27.00           0.00000
21Feb13_071151|    Std             6.61                48.42           0.34013
21Feb13_071151|   Best            20.61                85.00           0.81370
21Feb13_071151|-- Generation 31 --
21Feb13_071151|    -- Crossed 0 individual pairs.
21Feb13_071151|    -- Mutated 32 individuals.
21Feb13_071616|    -- Evaluated 64 individuals.
21Feb13_071616|    Summary of generation 31:
21Feb13_071616| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_071616|-----------  ------------------  --------------------  ----------
21Feb13_071616|    Max            39.48                240.00          0.86111
21Feb13_071616|    Avg            30.16                107.47          0.44062
21Feb13_071616|    Min            20.09                27.00           0.00000
21Feb13_071616|    Std             6.40                49.93           0.32493
21Feb13_071616|   Best            20.09                85.00           0.84424
21Feb13_071616|-- Generation 32 --
21Feb13_071616|    -- Crossed 0 individual pairs.
21Feb13_071616|    -- Mutated 32 individuals.
21Feb13_072044|    -- Evaluated 64 individuals.
21Feb13_072044|    Summary of generation 32:
21Feb13_072044| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_072044|-----------  ------------------  --------------------  ----------
21Feb13_072044|    Max            38.96                248.00          0.84023
21Feb13_072044|    Avg            31.65                113.05          0.38248
21Feb13_072044|    Min            21.48                27.00           0.00000
21Feb13_072044|    Std             6.30                57.61           0.33656
21Feb13_072044|   Best            21.48                60.00           0.79570
21Feb13_072044|Best initial individual weights
21Feb13_072044|Individual:
21Feb13_072044|-- Constant hidden layers --
21Feb13_072044|False
21Feb13_072044|Layer 0:
21Feb13_072044|-- Config --
21Feb13_072044|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 10, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072044|-- Weights --
21Feb13_072044|[[ 5.88691e-01  7.34147e-01  8.10367e-01  2.11773e-02 -4.62049e-01
21Feb13_072044|  -7.38458e-01  7.26400e-01  1.68821e-01  4.27604e-01  7.71289e-01]
21Feb13_072044| [ 5.00672e-01  9.43375e-01 -2.13714e-01 -5.02775e-01  4.21756e-01
21Feb13_072044|  -3.11512e-01  9.86832e-01 -3.44580e-01 -7.07002e-01 -7.71608e-01]
21Feb13_072044| [-3.31583e-01  4.10414e-01  3.11327e-01 -9.32762e-01 -6.74456e-01
21Feb13_072044|   7.80288e-01 -6.57899e-01 -6.20230e-01  6.92443e-02 -3.61590e-01]
21Feb13_072044| [-9.04396e-02 -8.19837e-01 -6.88448e-01 -9.62412e-01 -7.58415e-01
21Feb13_072044|  -9.69736e-01  6.19013e-01 -9.10210e-01  5.97962e-02  9.75080e-01]
21Feb13_072044| [-1.68848e-01  1.55578e-01 -3.35445e-01 -4.32001e-01  6.14394e-01
21Feb13_072044|  -9.23878e-01 -1.99060e-01  8.91028e-01 -5.64508e-01  1.19923e-01]
21Feb13_072044| [ 4.93773e-01 -8.24216e-02 -7.56356e-01  8.89522e-01 -8.68267e-01
21Feb13_072044|   7.97026e-01 -4.79894e-01 -3.69296e-01 -3.09683e-01 -1.68745e-01]
21Feb13_072044| [-4.66299e-01  2.17327e-01 -1.45569e-01 -6.41018e-01  8.72142e-01
21Feb13_072044|   5.15854e-01  5.21689e-01 -2.68451e-01 -8.38299e-01  4.82562e-01]
21Feb13_072044| [ 5.57358e-01  8.47613e-01  5.44345e-02 -8.74923e-01  8.54127e-01
21Feb13_072044|  -7.87119e-01 -7.47612e-01  3.34659e-01  1.93653e-01 -7.25571e-01]
21Feb13_072044| [-5.04994e-01  3.13779e-01 -2.74842e-01  7.12119e-01 -8.40114e-01
21Feb13_072044|   2.88567e-01  5.69881e-01  4.92094e-01  4.80434e-01  9.77318e-01]
21Feb13_072044| [ 4.68351e-01 -3.72831e-01  8.55626e-01 -8.79651e-01 -2.33969e-01
21Feb13_072044|   5.98459e-01  2.63593e-01 -3.91403e-01 -6.65983e-01  2.30158e-01]
21Feb13_072044| [-9.89259e-02  3.27688e-01 -7.08383e-01 -2.89411e-01 -2.55774e-01
21Feb13_072044|   7.04638e-01  1.01564e-01 -5.76649e-01  4.70076e-01 -9.95865e-01]
21Feb13_072044| [-1.26307e-01 -4.20269e-01  4.61402e-01  9.81480e-01  5.56598e-01
21Feb13_072044|  -9.65252e-01  8.14121e-02  2.27476e-01 -8.41499e-01  4.20720e-01]
21Feb13_072044| [-1.61331e-01 -2.89443e-01 -8.73690e-01  3.87905e-01 -9.97904e-01
21Feb13_072044|  -9.61631e-01 -7.44421e-01 -2.54994e-01  8.57907e-01 -8.85595e-01]
21Feb13_072044| [-6.77802e-01 -1.05034e-01 -3.87127e-01  5.32446e-03  4.79347e-01
21Feb13_072044|   1.38537e-02 -5.93520e-02 -9.54393e-01 -7.73930e-01  4.41642e-01]
21Feb13_072044| [-6.92501e-01 -9.94134e-01 -7.93645e-01  2.19819e-01 -9.18723e-02
21Feb13_072044|  -5.94588e-01  7.95378e-01 -8.46779e-01  4.50816e-01  7.16356e-01]
21Feb13_072044| [-1.61628e-01  8.66983e-01  6.13211e-01  9.32566e-01  2.71394e-01
21Feb13_072044|   8.84497e-01  4.66395e-01 -5.01253e-03 -8.83523e-01 -3.38501e-01]
21Feb13_072044| [-1.98942e-01 -1.53522e-01 -3.54287e-01  2.96224e-01  1.67320e-02
21Feb13_072044|  -2.56633e-01 -6.58948e-01  6.43574e-01 -1.91386e-01  9.98596e-01]
21Feb13_072044| [-2.02385e-01 -3.42529e-01  8.25586e-01 -5.56719e-01 -9.23610e-02
21Feb13_072044|   9.45777e-01  1.74297e-02 -7.60118e-01 -4.41642e-01  7.11501e-01]
21Feb13_072044| [ 4.38854e-01  8.35297e-01 -8.44456e-01 -2.04286e-01 -1.67918e-01
21Feb13_072044|  -1.57313e-01 -4.98189e-01  2.29870e-01 -9.57882e-01 -7.88812e-01]
21Feb13_072044| [ 9.35869e-01 -4.78536e-01 -9.01026e-01 -7.84669e-01 -1.23863e-01
21Feb13_072044|   2.56095e-01  1.16887e-01 -7.73714e-01 -6.84275e-01  3.22081e-01]
21Feb13_072044| [ 1.95597e-01 -9.03941e-01  1.00917e-01  2.12495e-01 -1.38886e-01
21Feb13_072044|   1.27993e-01 -2.07613e-01  1.17109e-01  5.96296e-01 -7.90501e-02]
21Feb13_072044| [ 2.20625e-01  4.54028e-01  3.27282e-02  7.54794e-01  1.80175e-01
21Feb13_072044|  -6.03194e-01 -9.57194e-01 -8.09770e-01  1.21347e-01  8.83733e-01]
21Feb13_072044| [ 4.49820e-01  3.69144e-01  8.29061e-01 -4.48607e-01 -9.82192e-01
21Feb13_072044|   4.92110e-01  3.57347e-01  5.36846e-01 -6.30739e-02  9.02151e-01]
21Feb13_072044| [-9.69448e-02  2.14567e-01 -4.56073e-01 -1.00257e-01  5.81925e-01
21Feb13_072044|  -2.40685e-01 -5.99891e-01  8.90261e-01  7.48426e-01 -7.60854e-01]
21Feb13_072044| [-8.71451e-01  8.13483e-01 -6.95234e-01  2.58267e-01 -4.77724e-01
21Feb13_072044|  -4.13882e-01  7.20436e-01  7.44498e-01 -8.17985e-01  3.39217e-01]
21Feb13_072044| [-2.03673e-01  8.43336e-01  4.09305e-01 -8.59868e-01  8.01620e-01
21Feb13_072044|   7.98512e-01  2.78738e-01 -4.26665e-01 -1.28989e-02  1.71391e-01]
21Feb13_072044| [ 9.94902e-01 -8.89958e-01  8.58944e-01  1.97706e-01 -4.41080e-01
21Feb13_072044|   9.99900e-01  2.03756e-01  8.73742e-01  9.13034e-03  3.51691e-01]
21Feb13_072044| [ 8.56415e-01  1.09581e-01  2.15394e-01  2.91679e-01  1.02019e-01
21Feb13_072044|   8.95941e-01  8.57483e-01 -1.91964e-01  2.32896e-03 -8.43214e-01]
21Feb13_072044| [ 8.20273e-01  7.20295e-01 -9.69006e-01  3.01361e-01  3.44455e-03
21Feb13_072044|  -9.01219e-02  3.31778e-01  8.13425e-01  9.71212e-01 -8.29976e-01]
21Feb13_072044| [ 3.57910e-01  1.04749e-01 -1.75544e-01 -3.52382e-01 -5.89449e-01
21Feb13_072044|   5.44063e-01 -7.33453e-01 -6.47547e-01  3.19327e-01 -9.89231e-01]
21Feb13_072044| [ 4.71222e-01 -2.71025e-01  3.62167e-01 -9.97391e-01  6.24753e-02
21Feb13_072044|  -9.74511e-01  1.03943e-01 -1.37737e-01 -8.21969e-01 -6.18926e-01]
21Feb13_072044| [-5.72889e-01  4.44510e-01 -4.60464e-01  4.21620e-01 -9.50935e-01
21Feb13_072044|  -5.02365e-01  3.90159e-01 -4.43831e-01 -6.54646e-01 -9.45070e-01]
21Feb13_072044| [-9.90951e-01 -9.84864e-01 -2.05821e-01  7.45200e-01  4.54921e-01
21Feb13_072044|   3.73960e-01  3.58180e-01 -1.33492e-01  3.74532e-01  8.26993e-01]
21Feb13_072044| [ 2.28789e-01 -9.38089e-01 -6.05707e-01 -8.53599e-01 -2.06842e-01
21Feb13_072044|   5.18579e-01  6.44427e-01 -4.57764e-02 -5.21943e-01 -8.94040e-01]
21Feb13_072044| [ 1.20548e-01 -4.09591e-02  4.55860e-01  5.37009e-01 -4.80351e-01
21Feb13_072044|  -5.29837e-01  6.64423e-01  2.06605e-01 -4.07563e-01 -3.79529e-01]
21Feb13_072044| [ 3.68323e-01 -1.04745e-01  9.17144e-01 -9.44134e-01  5.08352e-01
21Feb13_072044|  -3.82612e-01 -6.45528e-01  7.06872e-01  7.73835e-02 -9.65547e-01]
21Feb13_072044| [-1.36106e-01 -5.12596e-01 -6.32027e-01 -6.31918e-02 -5.59999e-01
21Feb13_072044|  -4.21882e-01 -8.13952e-01  9.04074e-01 -3.14950e-04 -3.57557e-01]
21Feb13_072044| [ 9.25971e-01  4.55443e-01 -9.29974e-01  8.48691e-01 -9.34716e-01
21Feb13_072044|   5.05114e-01  2.89824e-01  3.90511e-01  8.53265e-01 -7.66593e-01]
21Feb13_072044| [-2.01611e-01 -5.91456e-01 -3.40856e-01  5.19088e-01 -2.47525e-01
21Feb13_072044|  -5.81275e-01  2.65390e-01 -6.73303e-01  6.99598e-01 -4.95449e-01]
21Feb13_072044| [-3.80707e-01  2.42798e-01 -5.07791e-01 -4.29817e-01 -7.21448e-01
21Feb13_072044|   1.46815e-01 -2.87065e-01 -7.78385e-01 -5.51007e-01  4.87412e-01]
21Feb13_072044| [-6.35758e-01 -5.83164e-01  8.02163e-01  4.54080e-01  4.84620e-01
21Feb13_072044|   6.89271e-01  9.64953e-01 -8.47682e-01  4.30755e-02  6.68325e-01]
21Feb13_072044| [ 4.29025e-01  1.05419e-01 -1.42236e-01 -8.26028e-01 -1.92762e-01
21Feb13_072044|  -9.29279e-01  7.75839e-01 -3.81751e-01  2.25133e-01 -7.85885e-01]
21Feb13_072044| [ 7.68054e-02 -1.62635e-02  6.73712e-01 -3.95508e-01  9.26267e-01
21Feb13_072044|   2.44437e-01 -5.41841e-01  5.89482e-01  4.42732e-01  6.11906e-01]
21Feb13_072044| [-8.53293e-01 -4.11413e-01  8.50931e-01 -1.63866e-01  3.98738e-01
21Feb13_072044|  -8.63514e-01 -9.44856e-01 -7.59112e-01 -5.14321e-01 -2.77357e-01]
21Feb13_072044| [ 7.67790e-02 -2.29706e-01  2.91395e-01  4.76782e-01  5.46709e-01
21Feb13_072044|  -9.24152e-01  3.76650e-01  4.48366e-01  3.81301e-01  1.22584e-01]
21Feb13_072044| [-1.21794e-01 -9.31323e-01 -5.52710e-01  4.58616e-02  9.79322e-01
21Feb13_072044|  -2.02187e-01 -1.84043e-01  6.95449e-01 -6.62945e-01  7.38573e-01]
21Feb13_072044| [ 9.03718e-01 -5.99475e-01 -2.34934e-01 -2.20096e-01 -8.59589e-01
21Feb13_072044|   7.09454e-01 -5.82579e-01  1.48581e-02 -9.52333e-01  6.97731e-01]
21Feb13_072044| [-1.04523e-02  3.43689e-01  5.59886e-01 -6.16761e-01  9.93598e-01
21Feb13_072044|   6.96191e-01 -4.64065e-01 -7.35225e-02  8.24554e-01 -2.89968e-01]
21Feb13_072044| [-4.80958e-01 -1.17974e-01  8.45918e-02  7.89483e-01 -9.16171e-01
21Feb13_072044|  -8.96820e-01 -4.41959e-01  6.97738e-01 -5.73483e-01  8.35166e-01]
21Feb13_072044| [ 4.03425e-01 -2.62952e-01  3.53899e-01 -1.06226e-01  1.18087e-01
21Feb13_072044|   2.10630e-01 -1.79795e-01  5.61830e-01  6.34978e-02 -3.75197e-01]
21Feb13_072044| [-9.05718e-01  1.60680e-01  6.20658e-01 -2.28026e-01  2.46181e-01
21Feb13_072044|  -6.17633e-04 -9.00559e-01 -4.71289e-01  5.22196e-01 -9.55183e-01]
21Feb13_072044| [-4.44125e-01 -6.99492e-02 -8.96307e-01  9.71392e-01  2.95037e-01
21Feb13_072044|  -6.21690e-02  3.74362e-01 -8.99997e-02 -2.50615e-01 -4.80114e-01]
21Feb13_072044| [ 4.57470e-01  4.57003e-01  9.00013e-01  2.25301e-01  6.54005e-01
21Feb13_072044|  -8.58173e-01 -4.32081e-01  1.05686e-01 -2.11761e-01  4.78135e-02]
21Feb13_072044| [ 8.56486e-01 -6.98262e-01 -7.71023e-01  2.59505e-02  8.04203e-02
21Feb13_072044|  -2.78900e-01  4.90797e-02  5.99845e-01  3.42427e-01 -6.75423e-01]
21Feb13_072044| [-6.23465e-01 -7.36419e-01  7.27578e-01  1.80049e-01 -1.76352e-02
21Feb13_072044|  -2.71922e-01  8.61654e-01 -7.54345e-01 -7.15356e-01 -3.73441e-01]
21Feb13_072044| [-5.73488e-01 -8.68197e-02  4.83118e-01 -8.45035e-02 -3.50099e-01
21Feb13_072044|  -2.07869e-01 -1.62978e-01  7.79631e-01  6.88731e-01 -5.49742e-01]
21Feb13_072044| [-8.05512e-01 -6.38555e-01  4.07367e-01  6.60856e-01 -5.28139e-01
21Feb13_072044|  -8.68129e-02  6.54880e-01  7.84686e-01 -6.86646e-01 -3.79099e-01]]
21Feb13_072044|-- Bias --
21Feb13_072044|[ 0.52409 -0.42884 -0.18435  0.35786  0.36295 -0.88238  0.64925 -0.73031
21Feb13_072044|  0.82981 -0.78225]
21Feb13_072044|Layer 1:
21Feb13_072044|-- Config --
21Feb13_072044|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 10], 'dtype': 'float32', 'units': 7, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072044|-- Weights --
21Feb13_072044|[[ 0.89582  0.17284  0.85218 -0.36201  0.67692  0.31055 -0.17052]
21Feb13_072044| [ 0.80971 -0.42599  0.05767  0.13754 -0.80357 -0.72324  0.61202]
21Feb13_072044| [ 0.66688 -0.25801 -0.35937  0.96328  0.37315  0.47132  0.57104]
21Feb13_072044| [-0.23230 -0.90922  0.73938 -0.83932  0.27953  0.81821 -0.40947]
21Feb13_072044| [ 0.22364  0.34601 -0.02206  0.63161  0.26565 -0.36167  0.50290]
21Feb13_072044| [-0.62015 -0.01797 -0.20963  0.69920  0.79305  0.92238 -0.88516]
21Feb13_072044| [ 0.94089 -0.28897 -0.29135  0.32620  0.58539  0.79529  0.65628]
21Feb13_072044| [ 0.75914 -0.77057 -0.92090 -0.64911 -0.63334 -0.85236 -0.36959]
21Feb13_072044| [-0.60479  0.38665 -0.60420  0.86694  0.41259 -0.65755 -0.22577]
21Feb13_072044| [ 0.82894  0.74601  0.24459 -0.17155 -0.12652 -0.23990  0.62730]]
21Feb13_072044|-- Bias --
21Feb13_072044|[ 0.82325  0.44223 -0.35873 -0.19523 -0.55005 -0.18380 -0.88288]
21Feb13_072044|Layer 2:
21Feb13_072044|-- Config --
21Feb13_072044|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 7], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072044|-- Weights --
21Feb13_072044|[[-0.95109 -0.28940]
21Feb13_072044| [-0.55165 -0.49141]
21Feb13_072044| [ 0.41036  0.54736]
21Feb13_072044| [-0.80055  0.86878]
21Feb13_072044| [-0.93782 -0.75027]
21Feb13_072044| [ 0.26380  0.79360]
21Feb13_072044| [ 0.94265 -0.50033]]
21Feb13_072044|-- Bias --
21Feb13_072044|[0.35919 0.40572]
21Feb13_072044|Predicting the validation and test data with the Best initial individual.
21Feb13_072051| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_072051|-----------  ------------------  --------------------  ----------
21Feb13_072051|Validation         38.96                  34            0.00000
21Feb13_072051|   Test            39.01                  34            0.00000
21Feb13_072051|-------------------- Test #0 --------------------
21Feb13_072051|Best final individual weights
21Feb13_072051|Individual:
21Feb13_072051|-- Constant hidden layers --
21Feb13_072051|False
21Feb13_072051|Layer 0:
21Feb13_072051|-- Config --
21Feb13_072051|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072051|-- Weights --
21Feb13_072051|[[ 0.09269  0.48303  0.72927  0.11324]
21Feb13_072051| [-0.81343 -1.95436  1.49446  0.20512]
21Feb13_072051| [ 1.15165 -0.22730  0.75332  1.92231]
21Feb13_072051| [ 0.89415  0.78083 -0.46926  0.25455]
21Feb13_072051| [-0.36531  1.01395 -0.83458  0.35869]
21Feb13_072051| [ 0.41464 -1.66984 -1.43993 -0.44003]
21Feb13_072051| [-0.83228  0.20239  0.76766  0.56882]
21Feb13_072051| [-0.18500  0.34614  1.08102  0.26417]
21Feb13_072051| [-0.42303 -0.00403  0.54872  0.48681]
21Feb13_072051| [-0.67618 -0.49210 -0.42538 -0.20233]
21Feb13_072051| [ 0.37425 -1.99260  0.54239  0.17569]
21Feb13_072051| [ 0.75275 -1.78012 -0.28372  0.43230]
21Feb13_072051| [-0.80620 -0.18828  0.14917 -0.50239]
21Feb13_072051| [ 0.53789  1.24471 -0.50203 -0.41772]
21Feb13_072051| [-0.54895 -0.04226 -0.39663  0.46996]
21Feb13_072051| [ 0.43342 -1.86025  0.42349  0.24957]
21Feb13_072051| [ 1.31029 -0.26223 -1.56812  0.04751]
21Feb13_072051| [-1.92088 -0.26961  0.51447 -0.00805]
21Feb13_072051| [ 0.88215  0.32746 -0.13028 -0.11589]
21Feb13_072051| [ 0.14543 -0.27306 -0.54068 -0.03721]
21Feb13_072051| [-0.26780  1.36653  0.05861 -0.38317]
21Feb13_072051| [ 1.32139 -1.73666 -1.05910  0.19164]
21Feb13_072051| [ 0.62757  1.01460  0.84528  0.10637]
21Feb13_072051| [-1.73185  1.50917  1.20313  0.17788]
21Feb13_072051| [-0.73762  0.52767  0.36189 -0.11175]
21Feb13_072051| [-0.08962  0.68032  0.74072 -0.04362]
21Feb13_072051| [-0.30375 -0.03590 -0.57539 -0.60920]
21Feb13_072051| [ 2.16279 -0.54638 -1.01209  0.49396]
21Feb13_072051| [-0.44346  0.74785 -1.95843  0.05063]
21Feb13_072051| [-1.90054 -0.84287  0.04422  0.27181]
21Feb13_072051| [-0.69009 -0.95128  0.08906  0.71146]
21Feb13_072051| [-2.07506 -0.05557  1.20531 -0.15867]
21Feb13_072051| [ 1.49476 -0.53759  0.73141 -0.50191]
21Feb13_072051| [-1.13549  0.31526  0.67884  0.06683]
21Feb13_072051| [ 1.08905 -0.06987 -0.34082 -0.04126]
21Feb13_072051| [-0.87868  0.53753  0.94409 -1.09155]
21Feb13_072051| [-0.77921 -0.28400  1.38582  0.15721]
21Feb13_072051| [ 0.59576 -1.17047 -0.36122  0.68355]
21Feb13_072051| [ 0.15388 -1.23415  0.57566  0.31033]
21Feb13_072051| [ 0.10572  1.22884 -0.33339  0.52500]
21Feb13_072051| [-0.69911  1.28362 -0.35205 -0.27316]
21Feb13_072051| [-0.54596 -1.29892  0.34388  1.36053]
21Feb13_072051| [ 0.59682 -0.32095 -0.26017 -0.37697]
21Feb13_072051| [-0.12492 -0.96720 -0.37226  1.13062]
21Feb13_072051| [-0.88189 -1.66780 -1.80232 -0.44017]
21Feb13_072051| [ 1.96237 -1.70845  1.33322  0.76020]
21Feb13_072051| [-0.38850 -0.99186  0.23685  1.54881]
21Feb13_072051| [ 0.59635  1.00214 -0.34630  0.65212]
21Feb13_072051| [-0.55835 -1.43523 -0.80696  0.89527]
21Feb13_072051| [-0.85157 -0.88757 -0.48935  0.15119]
21Feb13_072051| [-0.42280 -0.19208  0.72967  0.52976]
21Feb13_072051| [-1.59267  1.29657  0.12161  0.08457]
21Feb13_072051| [-1.77919  0.05853 -0.51608 -0.03135]
21Feb13_072051| [ 1.61866 -1.10419  1.10429  0.33431]
21Feb13_072051| [ 0.81056  0.19812  0.41656  0.05740]
21Feb13_072051| [-0.26445  1.37473 -0.20606 -0.30855]
21Feb13_072051| [ 0.05127 -0.13274 -0.50962 -1.46422]]
21Feb13_072051|-- Bias --
21Feb13_072051|[-0.63748 -0.26300 -0.80266  0.31986]
21Feb13_072051|Layer 1:
21Feb13_072051|-- Config --
21Feb13_072051|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072051|-- Weights --
21Feb13_072051|[[ 0.62773  0.73189 -0.04255]
21Feb13_072051| [ 0.81247 -1.05214  0.43753]
21Feb13_072051| [-0.53275  0.04289 -0.34052]
21Feb13_072051| [ 0.97058  0.02507 -0.57573]]
21Feb13_072051|-- Bias --
21Feb13_072051|[-0.62075  0.53538 -0.45169]
21Feb13_072051|Layer 2:
21Feb13_072051|-- Config --
21Feb13_072051|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072051|-- Weights --
21Feb13_072051|[[-1.11921  0.24347  0.13360  0.22215 -0.22782]
21Feb13_072051| [-0.30547  0.25637  0.68223  1.08533 -0.59880]
21Feb13_072051| [ 0.86558 -0.01238 -0.73882 -0.50169  0.03984]]
21Feb13_072051|-- Bias --
21Feb13_072051|[-0.51021  0.90455 -0.18279 -0.50572  0.35449]
21Feb13_072051|Layer 3:
21Feb13_072051|-- Config --
21Feb13_072051|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072051|-- Weights --
21Feb13_072051|[[-0.39122 -0.59379 -1.27752]
21Feb13_072051| [ 1.30726 -1.42157 -0.56541]
21Feb13_072051| [ 1.19283  1.04866 -0.70498]
21Feb13_072051| [-1.96881  2.06622 -0.66153]
21Feb13_072051| [-2.24836 -1.46952 -0.18691]]
21Feb13_072051|-- Bias --
21Feb13_072051|[0.49160 0.12520 0.53746]
21Feb13_072051|Layer 4:
21Feb13_072051|-- Config --
21Feb13_072051|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072051|-- Weights --
21Feb13_072051|[[-1.83636  1.23796]
21Feb13_072051| [ 0.32710  0.76989]
21Feb13_072051| [ 1.19828  0.18703]]
21Feb13_072051|-- Bias --
21Feb13_072051|[-0.69389  0.00692]
21Feb13_072051|Predicting the validation and test data with the Best final individual.
21Feb13_072059| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_072059|-----------  ------------------  --------------------  ----------
21Feb13_072059|Validation         33.04                  60            0.78474
21Feb13_072059|   Test            26.67                  60            0.77277
21Feb13_072059|-------------------- Test #1 --------------------
21Feb13_072059|Best final individual weights
21Feb13_072059|Individual:
21Feb13_072059|-- Constant hidden layers --
21Feb13_072059|False
21Feb13_072059|Layer 0:
21Feb13_072059|-- Config --
21Feb13_072059|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072059|-- Weights --
21Feb13_072059|[[ 0.09269  0.48303  0.72927  0.11324]
21Feb13_072059| [-0.81343 -1.95436  1.49446  0.20512]
21Feb13_072059| [ 1.15165 -0.22730  0.75332  1.92231]
21Feb13_072059| [ 0.89415  0.78083 -0.46926  0.25455]
21Feb13_072059| [-0.36531  1.01395 -0.83458  0.35869]
21Feb13_072059| [ 0.41464 -1.66984 -1.43993 -0.44003]
21Feb13_072059| [-0.83228  0.20239  0.76766  0.56882]
21Feb13_072059| [-0.18500  0.34614  1.08102  0.26417]
21Feb13_072059| [-0.42303 -0.00403  0.54872  0.48681]
21Feb13_072059| [-0.67618 -0.49210 -0.42538 -0.20233]
21Feb13_072059| [ 0.37425 -1.99260  0.54239  0.17569]
21Feb13_072059| [ 0.75275 -1.78012 -0.28372  0.43230]
21Feb13_072059| [-0.80620 -0.18828  0.14917 -0.50239]
21Feb13_072059| [ 0.53789  1.24471 -0.50203 -0.41772]
21Feb13_072059| [-0.54895 -0.04226 -0.39663  0.46996]
21Feb13_072059| [ 0.43342 -1.86025  0.42349  0.24957]
21Feb13_072059| [ 1.31029 -0.26223 -1.56812  0.04751]
21Feb13_072059| [-1.92088 -0.26961  0.51447 -0.00805]
21Feb13_072059| [ 0.88215  0.32746 -0.13028 -0.11589]
21Feb13_072059| [ 0.14543 -0.27306 -0.54068 -0.03721]
21Feb13_072059| [-0.26780  1.36653  0.05861 -0.38317]
21Feb13_072059| [ 1.32139 -1.73666 -1.05910  0.19164]
21Feb13_072059| [ 0.62757  1.01460  0.84528  0.10637]
21Feb13_072059| [-1.73185  1.50917  1.20313  0.17788]
21Feb13_072059| [-0.73762  0.52767  0.36189 -0.11175]
21Feb13_072059| [-0.08962  0.68032  0.74072 -0.04362]
21Feb13_072059| [-0.30375 -0.03590 -0.57539 -0.60920]
21Feb13_072059| [ 2.16279 -0.54638 -1.01209  0.49396]
21Feb13_072059| [-0.44346  0.74785 -1.95843  0.05063]
21Feb13_072059| [-1.90054 -0.84287  0.04422  0.27181]
21Feb13_072059| [-0.69009 -0.95128  0.08906  0.71146]
21Feb13_072059| [-2.07506 -0.05557  1.20531 -0.15867]
21Feb13_072059| [ 1.49476 -0.53759  0.73141 -0.50191]
21Feb13_072059| [-1.13549  0.31526  0.67884  0.06683]
21Feb13_072059| [ 1.08905 -0.06987 -0.34082 -0.04126]
21Feb13_072059| [-0.87868  0.53753  0.94409 -1.09155]
21Feb13_072059| [-0.77921 -0.28400  1.38582  0.15721]
21Feb13_072059| [ 0.59576 -1.17047 -0.36122  0.68355]
21Feb13_072059| [ 0.15388 -1.23415  0.57566  0.31033]
21Feb13_072059| [ 0.10572  1.22884 -0.33339  0.52500]
21Feb13_072059| [-0.69911  1.28362 -0.35205 -0.27316]
21Feb13_072059| [-0.54596 -1.29892  0.34388  1.36053]
21Feb13_072059| [ 0.59682 -0.32095 -0.26017 -0.37697]
21Feb13_072059| [-0.12492 -0.96720 -0.37226  1.13062]
21Feb13_072059| [-0.88189 -1.66780 -1.80232 -0.44017]
21Feb13_072059| [ 1.96237 -1.70845  1.33322  0.76020]
21Feb13_072059| [-0.38850 -0.99186  0.23685  1.54881]
21Feb13_072059| [ 0.59635  1.00214 -0.34630  0.65212]
21Feb13_072059| [-0.55835 -1.43523 -0.80696  0.89527]
21Feb13_072059| [-0.85157 -0.88757 -0.48935  0.15119]
21Feb13_072059| [-0.42280 -0.19208  0.72967  0.52976]
21Feb13_072059| [-1.59267  1.29657  0.12161  0.08457]
21Feb13_072059| [-1.77919  0.05853 -0.51608 -0.03135]
21Feb13_072059| [ 1.61866 -1.10419  1.10429  0.33431]
21Feb13_072059| [ 0.81056  0.19812  0.41656  0.05740]
21Feb13_072059| [-0.26445  1.37473 -0.20606 -0.30855]
21Feb13_072059| [ 0.05127 -0.13274 -0.50962 -1.46422]]
21Feb13_072059|-- Bias --
21Feb13_072059|[-0.63748 -0.26300 -0.80266  0.31986]
21Feb13_072059|Layer 1:
21Feb13_072059|-- Config --
21Feb13_072059|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072059|-- Weights --
21Feb13_072059|[[ 0.62773  0.73189 -0.04255]
21Feb13_072059| [ 0.81247 -1.05214  0.43753]
21Feb13_072059| [-0.53275  0.04289 -0.34052]
21Feb13_072059| [ 0.97058  0.02507 -0.57573]]
21Feb13_072059|-- Bias --
21Feb13_072059|[-0.62075  0.53538 -0.45169]
21Feb13_072059|Layer 2:
21Feb13_072059|-- Config --
21Feb13_072059|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072059|-- Weights --
21Feb13_072059|[[-1.11921  0.24347  0.13360  0.22215 -0.22782]
21Feb13_072059| [-0.30547  0.25637  0.68223  1.08533 -0.59880]
21Feb13_072059| [ 0.86558 -0.01238 -0.73882 -0.50169  0.03984]]
21Feb13_072059|-- Bias --
21Feb13_072059|[-0.51021  0.90455 -0.18279 -0.50572  0.35449]
21Feb13_072059|Layer 3:
21Feb13_072059|-- Config --
21Feb13_072059|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072059|-- Weights --
21Feb13_072059|[[-0.39122 -0.59379 -1.27752]
21Feb13_072059| [ 1.30726 -1.42157 -0.56541]
21Feb13_072059| [ 1.19283  1.04866 -0.70498]
21Feb13_072059| [-1.96881  2.06622 -0.66153]
21Feb13_072059| [-2.24836 -1.46952 -0.18691]]
21Feb13_072059|-- Bias --
21Feb13_072059|[0.49160 0.12520 0.53746]
21Feb13_072059|Layer 4:
21Feb13_072059|-- Config --
21Feb13_072059|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072059|-- Weights --
21Feb13_072059|[[-1.83636  1.23796]
21Feb13_072059| [ 0.32710  0.76989]
21Feb13_072059| [ 1.19828  0.18703]]
21Feb13_072059|-- Bias --
21Feb13_072059|[-0.69389  0.00692]
21Feb13_072059|Predicting the validation and test data with the Best final individual.
21Feb13_072107| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_072107|-----------  ------------------  --------------------  ----------
21Feb13_072107|Validation         22.26                  60            0.80570
21Feb13_072107|   Test            26.06                  60            0.73963
21Feb13_072107|-------------------- Test #2 --------------------
21Feb13_072107|Best final individual weights
21Feb13_072107|Individual:
21Feb13_072107|-- Constant hidden layers --
21Feb13_072107|False
21Feb13_072107|Layer 0:
21Feb13_072107|-- Config --
21Feb13_072107|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072107|-- Weights --
21Feb13_072107|[[ 0.09269  0.48303  0.72927  0.11324]
21Feb13_072107| [-0.81343 -1.95436  1.49446  0.20512]
21Feb13_072107| [ 1.15165 -0.22730  0.75332  1.92231]
21Feb13_072107| [ 0.89415  0.78083 -0.46926  0.25455]
21Feb13_072107| [-0.36531  1.01395 -0.83458  0.35869]
21Feb13_072107| [ 0.41464 -1.66984 -1.43993 -0.44003]
21Feb13_072107| [-0.83228  0.20239  0.76766  0.56882]
21Feb13_072107| [-0.18500  0.34614  1.08102  0.26417]
21Feb13_072107| [-0.42303 -0.00403  0.54872  0.48681]
21Feb13_072107| [-0.67618 -0.49210 -0.42538 -0.20233]
21Feb13_072107| [ 0.37425 -1.99260  0.54239  0.17569]
21Feb13_072107| [ 0.75275 -1.78012 -0.28372  0.43230]
21Feb13_072107| [-0.80620 -0.18828  0.14917 -0.50239]
21Feb13_072107| [ 0.53789  1.24471 -0.50203 -0.41772]
21Feb13_072107| [-0.54895 -0.04226 -0.39663  0.46996]
21Feb13_072107| [ 0.43342 -1.86025  0.42349  0.24957]
21Feb13_072107| [ 1.31029 -0.26223 -1.56812  0.04751]
21Feb13_072107| [-1.92088 -0.26961  0.51447 -0.00805]
21Feb13_072107| [ 0.88215  0.32746 -0.13028 -0.11589]
21Feb13_072107| [ 0.14543 -0.27306 -0.54068 -0.03721]
21Feb13_072107| [-0.26780  1.36653  0.05861 -0.38317]
21Feb13_072107| [ 1.32139 -1.73666 -1.05910  0.19164]
21Feb13_072107| [ 0.62757  1.01460  0.84528  0.10637]
21Feb13_072107| [-1.73185  1.50917  1.20313  0.17788]
21Feb13_072107| [-0.73762  0.52767  0.36189 -0.11175]
21Feb13_072107| [-0.08962  0.68032  0.74072 -0.04362]
21Feb13_072107| [-0.30375 -0.03590 -0.57539 -0.60920]
21Feb13_072107| [ 2.16279 -0.54638 -1.01209  0.49396]
21Feb13_072107| [-0.44346  0.74785 -1.95843  0.05063]
21Feb13_072107| [-1.90054 -0.84287  0.04422  0.27181]
21Feb13_072107| [-0.69009 -0.95128  0.08906  0.71146]
21Feb13_072107| [-2.07506 -0.05557  1.20531 -0.15867]
21Feb13_072107| [ 1.49476 -0.53759  0.73141 -0.50191]
21Feb13_072107| [-1.13549  0.31526  0.67884  0.06683]
21Feb13_072107| [ 1.08905 -0.06987 -0.34082 -0.04126]
21Feb13_072107| [-0.87868  0.53753  0.94409 -1.09155]
21Feb13_072107| [-0.77921 -0.28400  1.38582  0.15721]
21Feb13_072107| [ 0.59576 -1.17047 -0.36122  0.68355]
21Feb13_072107| [ 0.15388 -1.23415  0.57566  0.31033]
21Feb13_072107| [ 0.10572  1.22884 -0.33339  0.52500]
21Feb13_072107| [-0.69911  1.28362 -0.35205 -0.27316]
21Feb13_072107| [-0.54596 -1.29892  0.34388  1.36053]
21Feb13_072107| [ 0.59682 -0.32095 -0.26017 -0.37697]
21Feb13_072107| [-0.12492 -0.96720 -0.37226  1.13062]
21Feb13_072107| [-0.88189 -1.66780 -1.80232 -0.44017]
21Feb13_072107| [ 1.96237 -1.70845  1.33322  0.76020]
21Feb13_072107| [-0.38850 -0.99186  0.23685  1.54881]
21Feb13_072107| [ 0.59635  1.00214 -0.34630  0.65212]
21Feb13_072107| [-0.55835 -1.43523 -0.80696  0.89527]
21Feb13_072107| [-0.85157 -0.88757 -0.48935  0.15119]
21Feb13_072107| [-0.42280 -0.19208  0.72967  0.52976]
21Feb13_072107| [-1.59267  1.29657  0.12161  0.08457]
21Feb13_072107| [-1.77919  0.05853 -0.51608 -0.03135]
21Feb13_072107| [ 1.61866 -1.10419  1.10429  0.33431]
21Feb13_072107| [ 0.81056  0.19812  0.41656  0.05740]
21Feb13_072107| [-0.26445  1.37473 -0.20606 -0.30855]
21Feb13_072107| [ 0.05127 -0.13274 -0.50962 -1.46422]]
21Feb13_072107|-- Bias --
21Feb13_072107|[-0.63748 -0.26300 -0.80266  0.31986]
21Feb13_072107|Layer 1:
21Feb13_072107|-- Config --
21Feb13_072107|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072107|-- Weights --
21Feb13_072107|[[ 0.62773  0.73189 -0.04255]
21Feb13_072107| [ 0.81247 -1.05214  0.43753]
21Feb13_072107| [-0.53275  0.04289 -0.34052]
21Feb13_072107| [ 0.97058  0.02507 -0.57573]]
21Feb13_072107|-- Bias --
21Feb13_072107|[-0.62075  0.53538 -0.45169]
21Feb13_072107|Layer 2:
21Feb13_072107|-- Config --
21Feb13_072107|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072107|-- Weights --
21Feb13_072107|[[-1.11921  0.24347  0.13360  0.22215 -0.22782]
21Feb13_072107| [-0.30547  0.25637  0.68223  1.08533 -0.59880]
21Feb13_072107| [ 0.86558 -0.01238 -0.73882 -0.50169  0.03984]]
21Feb13_072107|-- Bias --
21Feb13_072107|[-0.51021  0.90455 -0.18279 -0.50572  0.35449]
21Feb13_072107|Layer 3:
21Feb13_072107|-- Config --
21Feb13_072107|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072107|-- Weights --
21Feb13_072107|[[-0.39122 -0.59379 -1.27752]
21Feb13_072107| [ 1.30726 -1.42157 -0.56541]
21Feb13_072107| [ 1.19283  1.04866 -0.70498]
21Feb13_072107| [-1.96881  2.06622 -0.66153]
21Feb13_072107| [-2.24836 -1.46952 -0.18691]]
21Feb13_072107|-- Bias --
21Feb13_072107|[0.49160 0.12520 0.53746]
21Feb13_072107|Layer 4:
21Feb13_072107|-- Config --
21Feb13_072107|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072107|-- Weights --
21Feb13_072107|[[-1.83636  1.23796]
21Feb13_072107| [ 0.32710  0.76989]
21Feb13_072107| [ 1.19828  0.18703]]
21Feb13_072107|-- Bias --
21Feb13_072107|[-0.69389  0.00692]
21Feb13_072107|Predicting the validation and test data with the Best final individual.
21Feb13_072115| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_072115|-----------  ------------------  --------------------  ----------
21Feb13_072115|Validation         23.48                  60            0.83056
21Feb13_072115|   Test            24.33                  60            0.75803
21Feb13_072115|-------------------- Test #3 --------------------
21Feb13_072115|Best final individual weights
21Feb13_072115|Individual:
21Feb13_072115|-- Constant hidden layers --
21Feb13_072115|False
21Feb13_072115|Layer 0:
21Feb13_072115|-- Config --
21Feb13_072115|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072115|-- Weights --
21Feb13_072115|[[ 0.09269  0.48303  0.72927  0.11324]
21Feb13_072115| [-0.81343 -1.95436  1.49446  0.20512]
21Feb13_072115| [ 1.15165 -0.22730  0.75332  1.92231]
21Feb13_072115| [ 0.89415  0.78083 -0.46926  0.25455]
21Feb13_072115| [-0.36531  1.01395 -0.83458  0.35869]
21Feb13_072115| [ 0.41464 -1.66984 -1.43993 -0.44003]
21Feb13_072115| [-0.83228  0.20239  0.76766  0.56882]
21Feb13_072115| [-0.18500  0.34614  1.08102  0.26417]
21Feb13_072115| [-0.42303 -0.00403  0.54872  0.48681]
21Feb13_072115| [-0.67618 -0.49210 -0.42538 -0.20233]
21Feb13_072115| [ 0.37425 -1.99260  0.54239  0.17569]
21Feb13_072115| [ 0.75275 -1.78012 -0.28372  0.43230]
21Feb13_072115| [-0.80620 -0.18828  0.14917 -0.50239]
21Feb13_072115| [ 0.53789  1.24471 -0.50203 -0.41772]
21Feb13_072115| [-0.54895 -0.04226 -0.39663  0.46996]
21Feb13_072115| [ 0.43342 -1.86025  0.42349  0.24957]
21Feb13_072115| [ 1.31029 -0.26223 -1.56812  0.04751]
21Feb13_072115| [-1.92088 -0.26961  0.51447 -0.00805]
21Feb13_072115| [ 0.88215  0.32746 -0.13028 -0.11589]
21Feb13_072115| [ 0.14543 -0.27306 -0.54068 -0.03721]
21Feb13_072115| [-0.26780  1.36653  0.05861 -0.38317]
21Feb13_072115| [ 1.32139 -1.73666 -1.05910  0.19164]
21Feb13_072115| [ 0.62757  1.01460  0.84528  0.10637]
21Feb13_072115| [-1.73185  1.50917  1.20313  0.17788]
21Feb13_072115| [-0.73762  0.52767  0.36189 -0.11175]
21Feb13_072115| [-0.08962  0.68032  0.74072 -0.04362]
21Feb13_072115| [-0.30375 -0.03590 -0.57539 -0.60920]
21Feb13_072115| [ 2.16279 -0.54638 -1.01209  0.49396]
21Feb13_072115| [-0.44346  0.74785 -1.95843  0.05063]
21Feb13_072115| [-1.90054 -0.84287  0.04422  0.27181]
21Feb13_072115| [-0.69009 -0.95128  0.08906  0.71146]
21Feb13_072115| [-2.07506 -0.05557  1.20531 -0.15867]
21Feb13_072115| [ 1.49476 -0.53759  0.73141 -0.50191]
21Feb13_072115| [-1.13549  0.31526  0.67884  0.06683]
21Feb13_072115| [ 1.08905 -0.06987 -0.34082 -0.04126]
21Feb13_072115| [-0.87868  0.53753  0.94409 -1.09155]
21Feb13_072115| [-0.77921 -0.28400  1.38582  0.15721]
21Feb13_072115| [ 0.59576 -1.17047 -0.36122  0.68355]
21Feb13_072115| [ 0.15388 -1.23415  0.57566  0.31033]
21Feb13_072115| [ 0.10572  1.22884 -0.33339  0.52500]
21Feb13_072115| [-0.69911  1.28362 -0.35205 -0.27316]
21Feb13_072115| [-0.54596 -1.29892  0.34388  1.36053]
21Feb13_072115| [ 0.59682 -0.32095 -0.26017 -0.37697]
21Feb13_072115| [-0.12492 -0.96720 -0.37226  1.13062]
21Feb13_072115| [-0.88189 -1.66780 -1.80232 -0.44017]
21Feb13_072115| [ 1.96237 -1.70845  1.33322  0.76020]
21Feb13_072115| [-0.38850 -0.99186  0.23685  1.54881]
21Feb13_072115| [ 0.59635  1.00214 -0.34630  0.65212]
21Feb13_072115| [-0.55835 -1.43523 -0.80696  0.89527]
21Feb13_072115| [-0.85157 -0.88757 -0.48935  0.15119]
21Feb13_072115| [-0.42280 -0.19208  0.72967  0.52976]
21Feb13_072115| [-1.59267  1.29657  0.12161  0.08457]
21Feb13_072115| [-1.77919  0.05853 -0.51608 -0.03135]
21Feb13_072115| [ 1.61866 -1.10419  1.10429  0.33431]
21Feb13_072115| [ 0.81056  0.19812  0.41656  0.05740]
21Feb13_072115| [-0.26445  1.37473 -0.20606 -0.30855]
21Feb13_072115| [ 0.05127 -0.13274 -0.50962 -1.46422]]
21Feb13_072115|-- Bias --
21Feb13_072115|[-0.63748 -0.26300 -0.80266  0.31986]
21Feb13_072115|Layer 1:
21Feb13_072115|-- Config --
21Feb13_072115|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072115|-- Weights --
21Feb13_072115|[[ 0.62773  0.73189 -0.04255]
21Feb13_072115| [ 0.81247 -1.05214  0.43753]
21Feb13_072115| [-0.53275  0.04289 -0.34052]
21Feb13_072115| [ 0.97058  0.02507 -0.57573]]
21Feb13_072115|-- Bias --
21Feb13_072115|[-0.62075  0.53538 -0.45169]
21Feb13_072115|Layer 2:
21Feb13_072115|-- Config --
21Feb13_072115|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072115|-- Weights --
21Feb13_072115|[[-1.11921  0.24347  0.13360  0.22215 -0.22782]
21Feb13_072115| [-0.30547  0.25637  0.68223  1.08533 -0.59880]
21Feb13_072115| [ 0.86558 -0.01238 -0.73882 -0.50169  0.03984]]
21Feb13_072115|-- Bias --
21Feb13_072115|[-0.51021  0.90455 -0.18279 -0.50572  0.35449]
21Feb13_072115|Layer 3:
21Feb13_072115|-- Config --
21Feb13_072115|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072115|-- Weights --
21Feb13_072115|[[-0.39122 -0.59379 -1.27752]
21Feb13_072115| [ 1.30726 -1.42157 -0.56541]
21Feb13_072115| [ 1.19283  1.04866 -0.70498]
21Feb13_072115| [-1.96881  2.06622 -0.66153]
21Feb13_072115| [-2.24836 -1.46952 -0.18691]]
21Feb13_072115|-- Bias --
21Feb13_072115|[0.49160 0.12520 0.53746]
21Feb13_072115|Layer 4:
21Feb13_072115|-- Config --
21Feb13_072115|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072115|-- Weights --
21Feb13_072115|[[-1.83636  1.23796]
21Feb13_072115| [ 0.32710  0.76989]
21Feb13_072115| [ 1.19828  0.18703]]
21Feb13_072115|-- Bias --
21Feb13_072115|[-0.69389  0.00692]
21Feb13_072115|Predicting the validation and test data with the Best final individual.
21Feb13_072123| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_072123|-----------  ------------------  --------------------  ----------
21Feb13_072123|Validation         26.35                  60            0.79983
21Feb13_072123|   Test            27.54                  60            0.68973
21Feb13_072123|-------------------- Test #4 --------------------
21Feb13_072123|Best final individual weights
21Feb13_072123|Individual:
21Feb13_072123|-- Constant hidden layers --
21Feb13_072123|False
21Feb13_072123|Layer 0:
21Feb13_072123|-- Config --
21Feb13_072123|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072123|-- Weights --
21Feb13_072123|[[ 0.09269  0.48303  0.72927  0.11324]
21Feb13_072123| [-0.81343 -1.95436  1.49446  0.20512]
21Feb13_072123| [ 1.15165 -0.22730  0.75332  1.92231]
21Feb13_072123| [ 0.89415  0.78083 -0.46926  0.25455]
21Feb13_072123| [-0.36531  1.01395 -0.83458  0.35869]
21Feb13_072123| [ 0.41464 -1.66984 -1.43993 -0.44003]
21Feb13_072123| [-0.83228  0.20239  0.76766  0.56882]
21Feb13_072123| [-0.18500  0.34614  1.08102  0.26417]
21Feb13_072123| [-0.42303 -0.00403  0.54872  0.48681]
21Feb13_072123| [-0.67618 -0.49210 -0.42538 -0.20233]
21Feb13_072123| [ 0.37425 -1.99260  0.54239  0.17569]
21Feb13_072123| [ 0.75275 -1.78012 -0.28372  0.43230]
21Feb13_072123| [-0.80620 -0.18828  0.14917 -0.50239]
21Feb13_072123| [ 0.53789  1.24471 -0.50203 -0.41772]
21Feb13_072123| [-0.54895 -0.04226 -0.39663  0.46996]
21Feb13_072123| [ 0.43342 -1.86025  0.42349  0.24957]
21Feb13_072123| [ 1.31029 -0.26223 -1.56812  0.04751]
21Feb13_072123| [-1.92088 -0.26961  0.51447 -0.00805]
21Feb13_072123| [ 0.88215  0.32746 -0.13028 -0.11589]
21Feb13_072123| [ 0.14543 -0.27306 -0.54068 -0.03721]
21Feb13_072123| [-0.26780  1.36653  0.05861 -0.38317]
21Feb13_072123| [ 1.32139 -1.73666 -1.05910  0.19164]
21Feb13_072123| [ 0.62757  1.01460  0.84528  0.10637]
21Feb13_072123| [-1.73185  1.50917  1.20313  0.17788]
21Feb13_072123| [-0.73762  0.52767  0.36189 -0.11175]
21Feb13_072123| [-0.08962  0.68032  0.74072 -0.04362]
21Feb13_072123| [-0.30375 -0.03590 -0.57539 -0.60920]
21Feb13_072123| [ 2.16279 -0.54638 -1.01209  0.49396]
21Feb13_072123| [-0.44346  0.74785 -1.95843  0.05063]
21Feb13_072123| [-1.90054 -0.84287  0.04422  0.27181]
21Feb13_072123| [-0.69009 -0.95128  0.08906  0.71146]
21Feb13_072123| [-2.07506 -0.05557  1.20531 -0.15867]
21Feb13_072123| [ 1.49476 -0.53759  0.73141 -0.50191]
21Feb13_072123| [-1.13549  0.31526  0.67884  0.06683]
21Feb13_072123| [ 1.08905 -0.06987 -0.34082 -0.04126]
21Feb13_072123| [-0.87868  0.53753  0.94409 -1.09155]
21Feb13_072123| [-0.77921 -0.28400  1.38582  0.15721]
21Feb13_072123| [ 0.59576 -1.17047 -0.36122  0.68355]
21Feb13_072123| [ 0.15388 -1.23415  0.57566  0.31033]
21Feb13_072123| [ 0.10572  1.22884 -0.33339  0.52500]
21Feb13_072123| [-0.69911  1.28362 -0.35205 -0.27316]
21Feb13_072123| [-0.54596 -1.29892  0.34388  1.36053]
21Feb13_072123| [ 0.59682 -0.32095 -0.26017 -0.37697]
21Feb13_072123| [-0.12492 -0.96720 -0.37226  1.13062]
21Feb13_072123| [-0.88189 -1.66780 -1.80232 -0.44017]
21Feb13_072123| [ 1.96237 -1.70845  1.33322  0.76020]
21Feb13_072123| [-0.38850 -0.99186  0.23685  1.54881]
21Feb13_072123| [ 0.59635  1.00214 -0.34630  0.65212]
21Feb13_072123| [-0.55835 -1.43523 -0.80696  0.89527]
21Feb13_072123| [-0.85157 -0.88757 -0.48935  0.15119]
21Feb13_072123| [-0.42280 -0.19208  0.72967  0.52976]
21Feb13_072123| [-1.59267  1.29657  0.12161  0.08457]
21Feb13_072123| [-1.77919  0.05853 -0.51608 -0.03135]
21Feb13_072123| [ 1.61866 -1.10419  1.10429  0.33431]
21Feb13_072123| [ 0.81056  0.19812  0.41656  0.05740]
21Feb13_072123| [-0.26445  1.37473 -0.20606 -0.30855]
21Feb13_072123| [ 0.05127 -0.13274 -0.50962 -1.46422]]
21Feb13_072123|-- Bias --
21Feb13_072123|[-0.63748 -0.26300 -0.80266  0.31986]
21Feb13_072123|Layer 1:
21Feb13_072123|-- Config --
21Feb13_072123|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072123|-- Weights --
21Feb13_072123|[[ 0.62773  0.73189 -0.04255]
21Feb13_072123| [ 0.81247 -1.05214  0.43753]
21Feb13_072123| [-0.53275  0.04289 -0.34052]
21Feb13_072123| [ 0.97058  0.02507 -0.57573]]
21Feb13_072123|-- Bias --
21Feb13_072123|[-0.62075  0.53538 -0.45169]
21Feb13_072123|Layer 2:
21Feb13_072123|-- Config --
21Feb13_072123|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072123|-- Weights --
21Feb13_072123|[[-1.11921  0.24347  0.13360  0.22215 -0.22782]
21Feb13_072123| [-0.30547  0.25637  0.68223  1.08533 -0.59880]
21Feb13_072123| [ 0.86558 -0.01238 -0.73882 -0.50169  0.03984]]
21Feb13_072123|-- Bias --
21Feb13_072123|[-0.51021  0.90455 -0.18279 -0.50572  0.35449]
21Feb13_072123|Layer 3:
21Feb13_072123|-- Config --
21Feb13_072123|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072123|-- Weights --
21Feb13_072123|[[-0.39122 -0.59379 -1.27752]
21Feb13_072123| [ 1.30726 -1.42157 -0.56541]
21Feb13_072123| [ 1.19283  1.04866 -0.70498]
21Feb13_072123| [-1.96881  2.06622 -0.66153]
21Feb13_072123| [-2.24836 -1.46952 -0.18691]]
21Feb13_072123|-- Bias --
21Feb13_072123|[0.49160 0.12520 0.53746]
21Feb13_072123|Layer 4:
21Feb13_072123|-- Config --
21Feb13_072123|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072123|-- Weights --
21Feb13_072123|[[-1.83636  1.23796]
21Feb13_072123| [ 0.32710  0.76989]
21Feb13_072123| [ 1.19828  0.18703]]
21Feb13_072123|-- Bias --
21Feb13_072123|[-0.69389  0.00692]
21Feb13_072123|Predicting the validation and test data with the Best final individual.
21Feb13_072131| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_072131|-----------  ------------------  --------------------  ----------
21Feb13_072131|Validation         29.57                  60            0.77933
21Feb13_072131|   Test            24.59                  60            0.78638
21Feb13_072131|-------------------- Test #5 --------------------
21Feb13_072131|Best final individual weights
21Feb13_072131|Individual:
21Feb13_072131|-- Constant hidden layers --
21Feb13_072131|False
21Feb13_072131|Layer 0:
21Feb13_072131|-- Config --
21Feb13_072131|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072131|-- Weights --
21Feb13_072131|[[ 0.09269  0.48303  0.72927  0.11324]
21Feb13_072131| [-0.81343 -1.95436  1.49446  0.20512]
21Feb13_072131| [ 1.15165 -0.22730  0.75332  1.92231]
21Feb13_072131| [ 0.89415  0.78083 -0.46926  0.25455]
21Feb13_072131| [-0.36531  1.01395 -0.83458  0.35869]
21Feb13_072131| [ 0.41464 -1.66984 -1.43993 -0.44003]
21Feb13_072131| [-0.83228  0.20239  0.76766  0.56882]
21Feb13_072131| [-0.18500  0.34614  1.08102  0.26417]
21Feb13_072131| [-0.42303 -0.00403  0.54872  0.48681]
21Feb13_072131| [-0.67618 -0.49210 -0.42538 -0.20233]
21Feb13_072131| [ 0.37425 -1.99260  0.54239  0.17569]
21Feb13_072131| [ 0.75275 -1.78012 -0.28372  0.43230]
21Feb13_072131| [-0.80620 -0.18828  0.14917 -0.50239]
21Feb13_072131| [ 0.53789  1.24471 -0.50203 -0.41772]
21Feb13_072131| [-0.54895 -0.04226 -0.39663  0.46996]
21Feb13_072131| [ 0.43342 -1.86025  0.42349  0.24957]
21Feb13_072131| [ 1.31029 -0.26223 -1.56812  0.04751]
21Feb13_072131| [-1.92088 -0.26961  0.51447 -0.00805]
21Feb13_072131| [ 0.88215  0.32746 -0.13028 -0.11589]
21Feb13_072131| [ 0.14543 -0.27306 -0.54068 -0.03721]
21Feb13_072131| [-0.26780  1.36653  0.05861 -0.38317]
21Feb13_072131| [ 1.32139 -1.73666 -1.05910  0.19164]
21Feb13_072131| [ 0.62757  1.01460  0.84528  0.10637]
21Feb13_072131| [-1.73185  1.50917  1.20313  0.17788]
21Feb13_072131| [-0.73762  0.52767  0.36189 -0.11175]
21Feb13_072131| [-0.08962  0.68032  0.74072 -0.04362]
21Feb13_072131| [-0.30375 -0.03590 -0.57539 -0.60920]
21Feb13_072131| [ 2.16279 -0.54638 -1.01209  0.49396]
21Feb13_072131| [-0.44346  0.74785 -1.95843  0.05063]
21Feb13_072131| [-1.90054 -0.84287  0.04422  0.27181]
21Feb13_072131| [-0.69009 -0.95128  0.08906  0.71146]
21Feb13_072131| [-2.07506 -0.05557  1.20531 -0.15867]
21Feb13_072131| [ 1.49476 -0.53759  0.73141 -0.50191]
21Feb13_072131| [-1.13549  0.31526  0.67884  0.06683]
21Feb13_072131| [ 1.08905 -0.06987 -0.34082 -0.04126]
21Feb13_072131| [-0.87868  0.53753  0.94409 -1.09155]
21Feb13_072131| [-0.77921 -0.28400  1.38582  0.15721]
21Feb13_072131| [ 0.59576 -1.17047 -0.36122  0.68355]
21Feb13_072131| [ 0.15388 -1.23415  0.57566  0.31033]
21Feb13_072131| [ 0.10572  1.22884 -0.33339  0.52500]
21Feb13_072131| [-0.69911  1.28362 -0.35205 -0.27316]
21Feb13_072131| [-0.54596 -1.29892  0.34388  1.36053]
21Feb13_072131| [ 0.59682 -0.32095 -0.26017 -0.37697]
21Feb13_072131| [-0.12492 -0.96720 -0.37226  1.13062]
21Feb13_072131| [-0.88189 -1.66780 -1.80232 -0.44017]
21Feb13_072131| [ 1.96237 -1.70845  1.33322  0.76020]
21Feb13_072131| [-0.38850 -0.99186  0.23685  1.54881]
21Feb13_072131| [ 0.59635  1.00214 -0.34630  0.65212]
21Feb13_072131| [-0.55835 -1.43523 -0.80696  0.89527]
21Feb13_072131| [-0.85157 -0.88757 -0.48935  0.15119]
21Feb13_072131| [-0.42280 -0.19208  0.72967  0.52976]
21Feb13_072131| [-1.59267  1.29657  0.12161  0.08457]
21Feb13_072131| [-1.77919  0.05853 -0.51608 -0.03135]
21Feb13_072131| [ 1.61866 -1.10419  1.10429  0.33431]
21Feb13_072131| [ 0.81056  0.19812  0.41656  0.05740]
21Feb13_072131| [-0.26445  1.37473 -0.20606 -0.30855]
21Feb13_072131| [ 0.05127 -0.13274 -0.50962 -1.46422]]
21Feb13_072131|-- Bias --
21Feb13_072131|[-0.63748 -0.26300 -0.80266  0.31986]
21Feb13_072131|Layer 1:
21Feb13_072131|-- Config --
21Feb13_072131|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072131|-- Weights --
21Feb13_072131|[[ 0.62773  0.73189 -0.04255]
21Feb13_072131| [ 0.81247 -1.05214  0.43753]
21Feb13_072131| [-0.53275  0.04289 -0.34052]
21Feb13_072131| [ 0.97058  0.02507 -0.57573]]
21Feb13_072131|-- Bias --
21Feb13_072131|[-0.62075  0.53538 -0.45169]
21Feb13_072131|Layer 2:
21Feb13_072131|-- Config --
21Feb13_072131|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072131|-- Weights --
21Feb13_072131|[[-1.11921  0.24347  0.13360  0.22215 -0.22782]
21Feb13_072131| [-0.30547  0.25637  0.68223  1.08533 -0.59880]
21Feb13_072131| [ 0.86558 -0.01238 -0.73882 -0.50169  0.03984]]
21Feb13_072131|-- Bias --
21Feb13_072131|[-0.51021  0.90455 -0.18279 -0.50572  0.35449]
21Feb13_072131|Layer 3:
21Feb13_072131|-- Config --
21Feb13_072131|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072131|-- Weights --
21Feb13_072131|[[-0.39122 -0.59379 -1.27752]
21Feb13_072131| [ 1.30726 -1.42157 -0.56541]
21Feb13_072131| [ 1.19283  1.04866 -0.70498]
21Feb13_072131| [-1.96881  2.06622 -0.66153]
21Feb13_072131| [-2.24836 -1.46952 -0.18691]]
21Feb13_072131|-- Bias --
21Feb13_072131|[0.49160 0.12520 0.53746]
21Feb13_072131|Layer 4:
21Feb13_072131|-- Config --
21Feb13_072131|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072131|-- Weights --
21Feb13_072131|[[-1.83636  1.23796]
21Feb13_072131| [ 0.32710  0.76989]
21Feb13_072131| [ 1.19828  0.18703]]
21Feb13_072131|-- Bias --
21Feb13_072131|[-0.69389  0.00692]
21Feb13_072131|Predicting the validation and test data with the Best final individual.
21Feb13_072139| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_072139|-----------  ------------------  --------------------  ----------
21Feb13_072139|Validation         20.35                  60            0.73609
21Feb13_072139|   Test            24.15                  60            0.78659
21Feb13_072139|-------------------- Test #6 --------------------
21Feb13_072139|Best final individual weights
21Feb13_072139|Individual:
21Feb13_072139|-- Constant hidden layers --
21Feb13_072139|False
21Feb13_072139|Layer 0:
21Feb13_072139|-- Config --
21Feb13_072139|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072139|-- Weights --
21Feb13_072139|[[ 0.09269  0.48303  0.72927  0.11324]
21Feb13_072139| [-0.81343 -1.95436  1.49446  0.20512]
21Feb13_072139| [ 1.15165 -0.22730  0.75332  1.92231]
21Feb13_072139| [ 0.89415  0.78083 -0.46926  0.25455]
21Feb13_072139| [-0.36531  1.01395 -0.83458  0.35869]
21Feb13_072139| [ 0.41464 -1.66984 -1.43993 -0.44003]
21Feb13_072139| [-0.83228  0.20239  0.76766  0.56882]
21Feb13_072139| [-0.18500  0.34614  1.08102  0.26417]
21Feb13_072139| [-0.42303 -0.00403  0.54872  0.48681]
21Feb13_072139| [-0.67618 -0.49210 -0.42538 -0.20233]
21Feb13_072139| [ 0.37425 -1.99260  0.54239  0.17569]
21Feb13_072139| [ 0.75275 -1.78012 -0.28372  0.43230]
21Feb13_072139| [-0.80620 -0.18828  0.14917 -0.50239]
21Feb13_072139| [ 0.53789  1.24471 -0.50203 -0.41772]
21Feb13_072139| [-0.54895 -0.04226 -0.39663  0.46996]
21Feb13_072139| [ 0.43342 -1.86025  0.42349  0.24957]
21Feb13_072139| [ 1.31029 -0.26223 -1.56812  0.04751]
21Feb13_072139| [-1.92088 -0.26961  0.51447 -0.00805]
21Feb13_072139| [ 0.88215  0.32746 -0.13028 -0.11589]
21Feb13_072139| [ 0.14543 -0.27306 -0.54068 -0.03721]
21Feb13_072139| [-0.26780  1.36653  0.05861 -0.38317]
21Feb13_072139| [ 1.32139 -1.73666 -1.05910  0.19164]
21Feb13_072139| [ 0.62757  1.01460  0.84528  0.10637]
21Feb13_072139| [-1.73185  1.50917  1.20313  0.17788]
21Feb13_072139| [-0.73762  0.52767  0.36189 -0.11175]
21Feb13_072139| [-0.08962  0.68032  0.74072 -0.04362]
21Feb13_072139| [-0.30375 -0.03590 -0.57539 -0.60920]
21Feb13_072139| [ 2.16279 -0.54638 -1.01209  0.49396]
21Feb13_072139| [-0.44346  0.74785 -1.95843  0.05063]
21Feb13_072139| [-1.90054 -0.84287  0.04422  0.27181]
21Feb13_072139| [-0.69009 -0.95128  0.08906  0.71146]
21Feb13_072139| [-2.07506 -0.05557  1.20531 -0.15867]
21Feb13_072139| [ 1.49476 -0.53759  0.73141 -0.50191]
21Feb13_072139| [-1.13549  0.31526  0.67884  0.06683]
21Feb13_072139| [ 1.08905 -0.06987 -0.34082 -0.04126]
21Feb13_072139| [-0.87868  0.53753  0.94409 -1.09155]
21Feb13_072139| [-0.77921 -0.28400  1.38582  0.15721]
21Feb13_072139| [ 0.59576 -1.17047 -0.36122  0.68355]
21Feb13_072139| [ 0.15388 -1.23415  0.57566  0.31033]
21Feb13_072139| [ 0.10572  1.22884 -0.33339  0.52500]
21Feb13_072139| [-0.69911  1.28362 -0.35205 -0.27316]
21Feb13_072139| [-0.54596 -1.29892  0.34388  1.36053]
21Feb13_072139| [ 0.59682 -0.32095 -0.26017 -0.37697]
21Feb13_072139| [-0.12492 -0.96720 -0.37226  1.13062]
21Feb13_072139| [-0.88189 -1.66780 -1.80232 -0.44017]
21Feb13_072139| [ 1.96237 -1.70845  1.33322  0.76020]
21Feb13_072139| [-0.38850 -0.99186  0.23685  1.54881]
21Feb13_072139| [ 0.59635  1.00214 -0.34630  0.65212]
21Feb13_072139| [-0.55835 -1.43523 -0.80696  0.89527]
21Feb13_072139| [-0.85157 -0.88757 -0.48935  0.15119]
21Feb13_072139| [-0.42280 -0.19208  0.72967  0.52976]
21Feb13_072139| [-1.59267  1.29657  0.12161  0.08457]
21Feb13_072139| [-1.77919  0.05853 -0.51608 -0.03135]
21Feb13_072139| [ 1.61866 -1.10419  1.10429  0.33431]
21Feb13_072139| [ 0.81056  0.19812  0.41656  0.05740]
21Feb13_072139| [-0.26445  1.37473 -0.20606 -0.30855]
21Feb13_072139| [ 0.05127 -0.13274 -0.50962 -1.46422]]
21Feb13_072139|-- Bias --
21Feb13_072139|[-0.63748 -0.26300 -0.80266  0.31986]
21Feb13_072139|Layer 1:
21Feb13_072139|-- Config --
21Feb13_072139|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072139|-- Weights --
21Feb13_072139|[[ 0.62773  0.73189 -0.04255]
21Feb13_072139| [ 0.81247 -1.05214  0.43753]
21Feb13_072139| [-0.53275  0.04289 -0.34052]
21Feb13_072139| [ 0.97058  0.02507 -0.57573]]
21Feb13_072139|-- Bias --
21Feb13_072139|[-0.62075  0.53538 -0.45169]
21Feb13_072139|Layer 2:
21Feb13_072139|-- Config --
21Feb13_072139|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072139|-- Weights --
21Feb13_072139|[[-1.11921  0.24347  0.13360  0.22215 -0.22782]
21Feb13_072139| [-0.30547  0.25637  0.68223  1.08533 -0.59880]
21Feb13_072139| [ 0.86558 -0.01238 -0.73882 -0.50169  0.03984]]
21Feb13_072139|-- Bias --
21Feb13_072139|[-0.51021  0.90455 -0.18279 -0.50572  0.35449]
21Feb13_072139|Layer 3:
21Feb13_072139|-- Config --
21Feb13_072139|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072139|-- Weights --
21Feb13_072139|[[-0.39122 -0.59379 -1.27752]
21Feb13_072139| [ 1.30726 -1.42157 -0.56541]
21Feb13_072139| [ 1.19283  1.04866 -0.70498]
21Feb13_072139| [-1.96881  2.06622 -0.66153]
21Feb13_072139| [-2.24836 -1.46952 -0.18691]]
21Feb13_072139|-- Bias --
21Feb13_072139|[0.49160 0.12520 0.53746]
21Feb13_072139|Layer 4:
21Feb13_072139|-- Config --
21Feb13_072139|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072139|-- Weights --
21Feb13_072139|[[-1.83636  1.23796]
21Feb13_072139| [ 0.32710  0.76989]
21Feb13_072139| [ 1.19828  0.18703]]
21Feb13_072139|-- Bias --
21Feb13_072139|[-0.69389  0.00692]
21Feb13_072139|Predicting the validation and test data with the Best final individual.
21Feb13_072147| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_072147|-----------  ------------------  --------------------  ----------
21Feb13_072147|Validation         22.00                  60            0.66112
21Feb13_072147|   Test            25.98                  60            0.78399
21Feb13_072147|-------------------- Test #7 --------------------
21Feb13_072147|Best final individual weights
21Feb13_072147|Individual:
21Feb13_072147|-- Constant hidden layers --
21Feb13_072147|False
21Feb13_072147|Layer 0:
21Feb13_072147|-- Config --
21Feb13_072147|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072147|-- Weights --
21Feb13_072147|[[ 0.09269  0.48303  0.72927  0.11324]
21Feb13_072147| [-0.81343 -1.95436  1.49446  0.20512]
21Feb13_072147| [ 1.15165 -0.22730  0.75332  1.92231]
21Feb13_072147| [ 0.89415  0.78083 -0.46926  0.25455]
21Feb13_072147| [-0.36531  1.01395 -0.83458  0.35869]
21Feb13_072147| [ 0.41464 -1.66984 -1.43993 -0.44003]
21Feb13_072147| [-0.83228  0.20239  0.76766  0.56882]
21Feb13_072147| [-0.18500  0.34614  1.08102  0.26417]
21Feb13_072147| [-0.42303 -0.00403  0.54872  0.48681]
21Feb13_072147| [-0.67618 -0.49210 -0.42538 -0.20233]
21Feb13_072147| [ 0.37425 -1.99260  0.54239  0.17569]
21Feb13_072147| [ 0.75275 -1.78012 -0.28372  0.43230]
21Feb13_072147| [-0.80620 -0.18828  0.14917 -0.50239]
21Feb13_072147| [ 0.53789  1.24471 -0.50203 -0.41772]
21Feb13_072147| [-0.54895 -0.04226 -0.39663  0.46996]
21Feb13_072147| [ 0.43342 -1.86025  0.42349  0.24957]
21Feb13_072147| [ 1.31029 -0.26223 -1.56812  0.04751]
21Feb13_072147| [-1.92088 -0.26961  0.51447 -0.00805]
21Feb13_072147| [ 0.88215  0.32746 -0.13028 -0.11589]
21Feb13_072147| [ 0.14543 -0.27306 -0.54068 -0.03721]
21Feb13_072147| [-0.26780  1.36653  0.05861 -0.38317]
21Feb13_072147| [ 1.32139 -1.73666 -1.05910  0.19164]
21Feb13_072147| [ 0.62757  1.01460  0.84528  0.10637]
21Feb13_072147| [-1.73185  1.50917  1.20313  0.17788]
21Feb13_072147| [-0.73762  0.52767  0.36189 -0.11175]
21Feb13_072147| [-0.08962  0.68032  0.74072 -0.04362]
21Feb13_072147| [-0.30375 -0.03590 -0.57539 -0.60920]
21Feb13_072147| [ 2.16279 -0.54638 -1.01209  0.49396]
21Feb13_072147| [-0.44346  0.74785 -1.95843  0.05063]
21Feb13_072147| [-1.90054 -0.84287  0.04422  0.27181]
21Feb13_072147| [-0.69009 -0.95128  0.08906  0.71146]
21Feb13_072147| [-2.07506 -0.05557  1.20531 -0.15867]
21Feb13_072147| [ 1.49476 -0.53759  0.73141 -0.50191]
21Feb13_072147| [-1.13549  0.31526  0.67884  0.06683]
21Feb13_072147| [ 1.08905 -0.06987 -0.34082 -0.04126]
21Feb13_072147| [-0.87868  0.53753  0.94409 -1.09155]
21Feb13_072147| [-0.77921 -0.28400  1.38582  0.15721]
21Feb13_072147| [ 0.59576 -1.17047 -0.36122  0.68355]
21Feb13_072147| [ 0.15388 -1.23415  0.57566  0.31033]
21Feb13_072147| [ 0.10572  1.22884 -0.33339  0.52500]
21Feb13_072147| [-0.69911  1.28362 -0.35205 -0.27316]
21Feb13_072147| [-0.54596 -1.29892  0.34388  1.36053]
21Feb13_072147| [ 0.59682 -0.32095 -0.26017 -0.37697]
21Feb13_072147| [-0.12492 -0.96720 -0.37226  1.13062]
21Feb13_072147| [-0.88189 -1.66780 -1.80232 -0.44017]
21Feb13_072147| [ 1.96237 -1.70845  1.33322  0.76020]
21Feb13_072147| [-0.38850 -0.99186  0.23685  1.54881]
21Feb13_072147| [ 0.59635  1.00214 -0.34630  0.65212]
21Feb13_072147| [-0.55835 -1.43523 -0.80696  0.89527]
21Feb13_072147| [-0.85157 -0.88757 -0.48935  0.15119]
21Feb13_072147| [-0.42280 -0.19208  0.72967  0.52976]
21Feb13_072147| [-1.59267  1.29657  0.12161  0.08457]
21Feb13_072147| [-1.77919  0.05853 -0.51608 -0.03135]
21Feb13_072147| [ 1.61866 -1.10419  1.10429  0.33431]
21Feb13_072147| [ 0.81056  0.19812  0.41656  0.05740]
21Feb13_072147| [-0.26445  1.37473 -0.20606 -0.30855]
21Feb13_072147| [ 0.05127 -0.13274 -0.50962 -1.46422]]
21Feb13_072147|-- Bias --
21Feb13_072147|[-0.63748 -0.26300 -0.80266  0.31986]
21Feb13_072147|Layer 1:
21Feb13_072147|-- Config --
21Feb13_072147|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072147|-- Weights --
21Feb13_072147|[[ 0.62773  0.73189 -0.04255]
21Feb13_072147| [ 0.81247 -1.05214  0.43753]
21Feb13_072147| [-0.53275  0.04289 -0.34052]
21Feb13_072147| [ 0.97058  0.02507 -0.57573]]
21Feb13_072147|-- Bias --
21Feb13_072147|[-0.62075  0.53538 -0.45169]
21Feb13_072147|Layer 2:
21Feb13_072147|-- Config --
21Feb13_072147|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072147|-- Weights --
21Feb13_072147|[[-1.11921  0.24347  0.13360  0.22215 -0.22782]
21Feb13_072147| [-0.30547  0.25637  0.68223  1.08533 -0.59880]
21Feb13_072147| [ 0.86558 -0.01238 -0.73882 -0.50169  0.03984]]
21Feb13_072147|-- Bias --
21Feb13_072147|[-0.51021  0.90455 -0.18279 -0.50572  0.35449]
21Feb13_072147|Layer 3:
21Feb13_072147|-- Config --
21Feb13_072147|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072147|-- Weights --
21Feb13_072147|[[-0.39122 -0.59379 -1.27752]
21Feb13_072147| [ 1.30726 -1.42157 -0.56541]
21Feb13_072147| [ 1.19283  1.04866 -0.70498]
21Feb13_072147| [-1.96881  2.06622 -0.66153]
21Feb13_072147| [-2.24836 -1.46952 -0.18691]]
21Feb13_072147|-- Bias --
21Feb13_072147|[0.49160 0.12520 0.53746]
21Feb13_072147|Layer 4:
21Feb13_072147|-- Config --
21Feb13_072147|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072147|-- Weights --
21Feb13_072147|[[-1.83636  1.23796]
21Feb13_072147| [ 0.32710  0.76989]
21Feb13_072147| [ 1.19828  0.18703]]
21Feb13_072147|-- Bias --
21Feb13_072147|[-0.69389  0.00692]
21Feb13_072147|Predicting the validation and test data with the Best final individual.
21Feb13_072155| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_072155|-----------  ------------------  --------------------  ----------
21Feb13_072155|Validation         24.52                  60            0.82368
21Feb13_072155|   Test            25.46                  60            0.76418
21Feb13_072155|-------------------- Test #8 --------------------
21Feb13_072155|Best final individual weights
21Feb13_072155|Individual:
21Feb13_072155|-- Constant hidden layers --
21Feb13_072155|False
21Feb13_072155|Layer 0:
21Feb13_072155|-- Config --
21Feb13_072155|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072155|-- Weights --
21Feb13_072155|[[ 0.09269  0.48303  0.72927  0.11324]
21Feb13_072155| [-0.81343 -1.95436  1.49446  0.20512]
21Feb13_072155| [ 1.15165 -0.22730  0.75332  1.92231]
21Feb13_072155| [ 0.89415  0.78083 -0.46926  0.25455]
21Feb13_072155| [-0.36531  1.01395 -0.83458  0.35869]
21Feb13_072155| [ 0.41464 -1.66984 -1.43993 -0.44003]
21Feb13_072155| [-0.83228  0.20239  0.76766  0.56882]
21Feb13_072155| [-0.18500  0.34614  1.08102  0.26417]
21Feb13_072155| [-0.42303 -0.00403  0.54872  0.48681]
21Feb13_072155| [-0.67618 -0.49210 -0.42538 -0.20233]
21Feb13_072155| [ 0.37425 -1.99260  0.54239  0.17569]
21Feb13_072155| [ 0.75275 -1.78012 -0.28372  0.43230]
21Feb13_072155| [-0.80620 -0.18828  0.14917 -0.50239]
21Feb13_072155| [ 0.53789  1.24471 -0.50203 -0.41772]
21Feb13_072155| [-0.54895 -0.04226 -0.39663  0.46996]
21Feb13_072155| [ 0.43342 -1.86025  0.42349  0.24957]
21Feb13_072155| [ 1.31029 -0.26223 -1.56812  0.04751]
21Feb13_072155| [-1.92088 -0.26961  0.51447 -0.00805]
21Feb13_072155| [ 0.88215  0.32746 -0.13028 -0.11589]
21Feb13_072155| [ 0.14543 -0.27306 -0.54068 -0.03721]
21Feb13_072155| [-0.26780  1.36653  0.05861 -0.38317]
21Feb13_072155| [ 1.32139 -1.73666 -1.05910  0.19164]
21Feb13_072155| [ 0.62757  1.01460  0.84528  0.10637]
21Feb13_072155| [-1.73185  1.50917  1.20313  0.17788]
21Feb13_072155| [-0.73762  0.52767  0.36189 -0.11175]
21Feb13_072155| [-0.08962  0.68032  0.74072 -0.04362]
21Feb13_072155| [-0.30375 -0.03590 -0.57539 -0.60920]
21Feb13_072155| [ 2.16279 -0.54638 -1.01209  0.49396]
21Feb13_072155| [-0.44346  0.74785 -1.95843  0.05063]
21Feb13_072155| [-1.90054 -0.84287  0.04422  0.27181]
21Feb13_072155| [-0.69009 -0.95128  0.08906  0.71146]
21Feb13_072155| [-2.07506 -0.05557  1.20531 -0.15867]
21Feb13_072155| [ 1.49476 -0.53759  0.73141 -0.50191]
21Feb13_072155| [-1.13549  0.31526  0.67884  0.06683]
21Feb13_072155| [ 1.08905 -0.06987 -0.34082 -0.04126]
21Feb13_072155| [-0.87868  0.53753  0.94409 -1.09155]
21Feb13_072155| [-0.77921 -0.28400  1.38582  0.15721]
21Feb13_072155| [ 0.59576 -1.17047 -0.36122  0.68355]
21Feb13_072155| [ 0.15388 -1.23415  0.57566  0.31033]
21Feb13_072155| [ 0.10572  1.22884 -0.33339  0.52500]
21Feb13_072155| [-0.69911  1.28362 -0.35205 -0.27316]
21Feb13_072155| [-0.54596 -1.29892  0.34388  1.36053]
21Feb13_072155| [ 0.59682 -0.32095 -0.26017 -0.37697]
21Feb13_072155| [-0.12492 -0.96720 -0.37226  1.13062]
21Feb13_072155| [-0.88189 -1.66780 -1.80232 -0.44017]
21Feb13_072155| [ 1.96237 -1.70845  1.33322  0.76020]
21Feb13_072155| [-0.38850 -0.99186  0.23685  1.54881]
21Feb13_072155| [ 0.59635  1.00214 -0.34630  0.65212]
21Feb13_072155| [-0.55835 -1.43523 -0.80696  0.89527]
21Feb13_072155| [-0.85157 -0.88757 -0.48935  0.15119]
21Feb13_072155| [-0.42280 -0.19208  0.72967  0.52976]
21Feb13_072155| [-1.59267  1.29657  0.12161  0.08457]
21Feb13_072155| [-1.77919  0.05853 -0.51608 -0.03135]
21Feb13_072155| [ 1.61866 -1.10419  1.10429  0.33431]
21Feb13_072155| [ 0.81056  0.19812  0.41656  0.05740]
21Feb13_072155| [-0.26445  1.37473 -0.20606 -0.30855]
21Feb13_072155| [ 0.05127 -0.13274 -0.50962 -1.46422]]
21Feb13_072155|-- Bias --
21Feb13_072155|[-0.63748 -0.26300 -0.80266  0.31986]
21Feb13_072155|Layer 1:
21Feb13_072155|-- Config --
21Feb13_072155|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072155|-- Weights --
21Feb13_072155|[[ 0.62773  0.73189 -0.04255]
21Feb13_072155| [ 0.81247 -1.05214  0.43753]
21Feb13_072155| [-0.53275  0.04289 -0.34052]
21Feb13_072155| [ 0.97058  0.02507 -0.57573]]
21Feb13_072155|-- Bias --
21Feb13_072155|[-0.62075  0.53538 -0.45169]
21Feb13_072155|Layer 2:
21Feb13_072155|-- Config --
21Feb13_072155|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072155|-- Weights --
21Feb13_072155|[[-1.11921  0.24347  0.13360  0.22215 -0.22782]
21Feb13_072155| [-0.30547  0.25637  0.68223  1.08533 -0.59880]
21Feb13_072155| [ 0.86558 -0.01238 -0.73882 -0.50169  0.03984]]
21Feb13_072155|-- Bias --
21Feb13_072155|[-0.51021  0.90455 -0.18279 -0.50572  0.35449]
21Feb13_072155|Layer 3:
21Feb13_072155|-- Config --
21Feb13_072155|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072155|-- Weights --
21Feb13_072155|[[-0.39122 -0.59379 -1.27752]
21Feb13_072155| [ 1.30726 -1.42157 -0.56541]
21Feb13_072155| [ 1.19283  1.04866 -0.70498]
21Feb13_072155| [-1.96881  2.06622 -0.66153]
21Feb13_072155| [-2.24836 -1.46952 -0.18691]]
21Feb13_072155|-- Bias --
21Feb13_072155|[0.49160 0.12520 0.53746]
21Feb13_072155|Layer 4:
21Feb13_072155|-- Config --
21Feb13_072155|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072155|-- Weights --
21Feb13_072155|[[-1.83636  1.23796]
21Feb13_072155| [ 0.32710  0.76989]
21Feb13_072155| [ 1.19828  0.18703]]
21Feb13_072155|-- Bias --
21Feb13_072155|[-0.69389  0.00692]
21Feb13_072155|Predicting the validation and test data with the Best final individual.
21Feb13_072203| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_072203|-----------  ------------------  --------------------  ----------
21Feb13_072203|Validation         21.39                  60            0.81202
21Feb13_072203|   Test            23.54                  60            0.77284
21Feb13_072203|-------------------- Test #9 --------------------
21Feb13_072203|Best final individual weights
21Feb13_072203|Individual:
21Feb13_072203|-- Constant hidden layers --
21Feb13_072203|False
21Feb13_072203|Layer 0:
21Feb13_072203|-- Config --
21Feb13_072203|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072203|-- Weights --
21Feb13_072203|[[ 0.09269  0.48303  0.72927  0.11324]
21Feb13_072203| [-0.81343 -1.95436  1.49446  0.20512]
21Feb13_072203| [ 1.15165 -0.22730  0.75332  1.92231]
21Feb13_072203| [ 0.89415  0.78083 -0.46926  0.25455]
21Feb13_072203| [-0.36531  1.01395 -0.83458  0.35869]
21Feb13_072203| [ 0.41464 -1.66984 -1.43993 -0.44003]
21Feb13_072203| [-0.83228  0.20239  0.76766  0.56882]
21Feb13_072203| [-0.18500  0.34614  1.08102  0.26417]
21Feb13_072203| [-0.42303 -0.00403  0.54872  0.48681]
21Feb13_072203| [-0.67618 -0.49210 -0.42538 -0.20233]
21Feb13_072203| [ 0.37425 -1.99260  0.54239  0.17569]
21Feb13_072203| [ 0.75275 -1.78012 -0.28372  0.43230]
21Feb13_072203| [-0.80620 -0.18828  0.14917 -0.50239]
21Feb13_072203| [ 0.53789  1.24471 -0.50203 -0.41772]
21Feb13_072203| [-0.54895 -0.04226 -0.39663  0.46996]
21Feb13_072203| [ 0.43342 -1.86025  0.42349  0.24957]
21Feb13_072203| [ 1.31029 -0.26223 -1.56812  0.04751]
21Feb13_072203| [-1.92088 -0.26961  0.51447 -0.00805]
21Feb13_072203| [ 0.88215  0.32746 -0.13028 -0.11589]
21Feb13_072203| [ 0.14543 -0.27306 -0.54068 -0.03721]
21Feb13_072203| [-0.26780  1.36653  0.05861 -0.38317]
21Feb13_072203| [ 1.32139 -1.73666 -1.05910  0.19164]
21Feb13_072203| [ 0.62757  1.01460  0.84528  0.10637]
21Feb13_072203| [-1.73185  1.50917  1.20313  0.17788]
21Feb13_072203| [-0.73762  0.52767  0.36189 -0.11175]
21Feb13_072203| [-0.08962  0.68032  0.74072 -0.04362]
21Feb13_072203| [-0.30375 -0.03590 -0.57539 -0.60920]
21Feb13_072203| [ 2.16279 -0.54638 -1.01209  0.49396]
21Feb13_072203| [-0.44346  0.74785 -1.95843  0.05063]
21Feb13_072203| [-1.90054 -0.84287  0.04422  0.27181]
21Feb13_072203| [-0.69009 -0.95128  0.08906  0.71146]
21Feb13_072203| [-2.07506 -0.05557  1.20531 -0.15867]
21Feb13_072203| [ 1.49476 -0.53759  0.73141 -0.50191]
21Feb13_072203| [-1.13549  0.31526  0.67884  0.06683]
21Feb13_072203| [ 1.08905 -0.06987 -0.34082 -0.04126]
21Feb13_072203| [-0.87868  0.53753  0.94409 -1.09155]
21Feb13_072203| [-0.77921 -0.28400  1.38582  0.15721]
21Feb13_072203| [ 0.59576 -1.17047 -0.36122  0.68355]
21Feb13_072203| [ 0.15388 -1.23415  0.57566  0.31033]
21Feb13_072203| [ 0.10572  1.22884 -0.33339  0.52500]
21Feb13_072203| [-0.69911  1.28362 -0.35205 -0.27316]
21Feb13_072203| [-0.54596 -1.29892  0.34388  1.36053]
21Feb13_072203| [ 0.59682 -0.32095 -0.26017 -0.37697]
21Feb13_072203| [-0.12492 -0.96720 -0.37226  1.13062]
21Feb13_072203| [-0.88189 -1.66780 -1.80232 -0.44017]
21Feb13_072203| [ 1.96237 -1.70845  1.33322  0.76020]
21Feb13_072203| [-0.38850 -0.99186  0.23685  1.54881]
21Feb13_072203| [ 0.59635  1.00214 -0.34630  0.65212]
21Feb13_072203| [-0.55835 -1.43523 -0.80696  0.89527]
21Feb13_072203| [-0.85157 -0.88757 -0.48935  0.15119]
21Feb13_072203| [-0.42280 -0.19208  0.72967  0.52976]
21Feb13_072203| [-1.59267  1.29657  0.12161  0.08457]
21Feb13_072203| [-1.77919  0.05853 -0.51608 -0.03135]
21Feb13_072203| [ 1.61866 -1.10419  1.10429  0.33431]
21Feb13_072203| [ 0.81056  0.19812  0.41656  0.05740]
21Feb13_072203| [-0.26445  1.37473 -0.20606 -0.30855]
21Feb13_072203| [ 0.05127 -0.13274 -0.50962 -1.46422]]
21Feb13_072203|-- Bias --
21Feb13_072203|[-0.63748 -0.26300 -0.80266  0.31986]
21Feb13_072203|Layer 1:
21Feb13_072203|-- Config --
21Feb13_072203|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072203|-- Weights --
21Feb13_072203|[[ 0.62773  0.73189 -0.04255]
21Feb13_072203| [ 0.81247 -1.05214  0.43753]
21Feb13_072203| [-0.53275  0.04289 -0.34052]
21Feb13_072203| [ 0.97058  0.02507 -0.57573]]
21Feb13_072203|-- Bias --
21Feb13_072203|[-0.62075  0.53538 -0.45169]
21Feb13_072203|Layer 2:
21Feb13_072203|-- Config --
21Feb13_072203|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072203|-- Weights --
21Feb13_072203|[[-1.11921  0.24347  0.13360  0.22215 -0.22782]
21Feb13_072203| [-0.30547  0.25637  0.68223  1.08533 -0.59880]
21Feb13_072203| [ 0.86558 -0.01238 -0.73882 -0.50169  0.03984]]
21Feb13_072203|-- Bias --
21Feb13_072203|[-0.51021  0.90455 -0.18279 -0.50572  0.35449]
21Feb13_072203|Layer 3:
21Feb13_072203|-- Config --
21Feb13_072203|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072203|-- Weights --
21Feb13_072203|[[-0.39122 -0.59379 -1.27752]
21Feb13_072203| [ 1.30726 -1.42157 -0.56541]
21Feb13_072203| [ 1.19283  1.04866 -0.70498]
21Feb13_072203| [-1.96881  2.06622 -0.66153]
21Feb13_072203| [-2.24836 -1.46952 -0.18691]]
21Feb13_072203|-- Bias --
21Feb13_072203|[0.49160 0.12520 0.53746]
21Feb13_072203|Layer 4:
21Feb13_072203|-- Config --
21Feb13_072203|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072203|-- Weights --
21Feb13_072203|[[-1.83636  1.23796]
21Feb13_072203| [ 0.32710  0.76989]
21Feb13_072203| [ 1.19828  0.18703]]
21Feb13_072203|-- Bias --
21Feb13_072203|[-0.69389  0.00692]
21Feb13_072203|Predicting the validation and test data with the Best final individual.
21Feb13_072211| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_072211|-----------  ------------------  --------------------  ----------
21Feb13_072211|Validation         21.83                  60            0.66343
21Feb13_072211|   Test            24.93                  60            0.82169
21Feb13_072211|-------------------- Test #10 --------------------
21Feb13_072211|Best final individual weights
21Feb13_072211|Individual:
21Feb13_072211|-- Constant hidden layers --
21Feb13_072211|False
21Feb13_072211|Layer 0:
21Feb13_072211|-- Config --
21Feb13_072211|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072211|-- Weights --
21Feb13_072211|[[ 0.09269  0.48303  0.72927  0.11324]
21Feb13_072211| [-0.81343 -1.95436  1.49446  0.20512]
21Feb13_072211| [ 1.15165 -0.22730  0.75332  1.92231]
21Feb13_072211| [ 0.89415  0.78083 -0.46926  0.25455]
21Feb13_072211| [-0.36531  1.01395 -0.83458  0.35869]
21Feb13_072211| [ 0.41464 -1.66984 -1.43993 -0.44003]
21Feb13_072211| [-0.83228  0.20239  0.76766  0.56882]
21Feb13_072211| [-0.18500  0.34614  1.08102  0.26417]
21Feb13_072211| [-0.42303 -0.00403  0.54872  0.48681]
21Feb13_072211| [-0.67618 -0.49210 -0.42538 -0.20233]
21Feb13_072211| [ 0.37425 -1.99260  0.54239  0.17569]
21Feb13_072211| [ 0.75275 -1.78012 -0.28372  0.43230]
21Feb13_072211| [-0.80620 -0.18828  0.14917 -0.50239]
21Feb13_072211| [ 0.53789  1.24471 -0.50203 -0.41772]
21Feb13_072211| [-0.54895 -0.04226 -0.39663  0.46996]
21Feb13_072211| [ 0.43342 -1.86025  0.42349  0.24957]
21Feb13_072211| [ 1.31029 -0.26223 -1.56812  0.04751]
21Feb13_072211| [-1.92088 -0.26961  0.51447 -0.00805]
21Feb13_072211| [ 0.88215  0.32746 -0.13028 -0.11589]
21Feb13_072211| [ 0.14543 -0.27306 -0.54068 -0.03721]
21Feb13_072211| [-0.26780  1.36653  0.05861 -0.38317]
21Feb13_072211| [ 1.32139 -1.73666 -1.05910  0.19164]
21Feb13_072211| [ 0.62757  1.01460  0.84528  0.10637]
21Feb13_072211| [-1.73185  1.50917  1.20313  0.17788]
21Feb13_072211| [-0.73762  0.52767  0.36189 -0.11175]
21Feb13_072211| [-0.08962  0.68032  0.74072 -0.04362]
21Feb13_072211| [-0.30375 -0.03590 -0.57539 -0.60920]
21Feb13_072211| [ 2.16279 -0.54638 -1.01209  0.49396]
21Feb13_072211| [-0.44346  0.74785 -1.95843  0.05063]
21Feb13_072211| [-1.90054 -0.84287  0.04422  0.27181]
21Feb13_072211| [-0.69009 -0.95128  0.08906  0.71146]
21Feb13_072211| [-2.07506 -0.05557  1.20531 -0.15867]
21Feb13_072211| [ 1.49476 -0.53759  0.73141 -0.50191]
21Feb13_072211| [-1.13549  0.31526  0.67884  0.06683]
21Feb13_072211| [ 1.08905 -0.06987 -0.34082 -0.04126]
21Feb13_072211| [-0.87868  0.53753  0.94409 -1.09155]
21Feb13_072211| [-0.77921 -0.28400  1.38582  0.15721]
21Feb13_072211| [ 0.59576 -1.17047 -0.36122  0.68355]
21Feb13_072211| [ 0.15388 -1.23415  0.57566  0.31033]
21Feb13_072211| [ 0.10572  1.22884 -0.33339  0.52500]
21Feb13_072211| [-0.69911  1.28362 -0.35205 -0.27316]
21Feb13_072211| [-0.54596 -1.29892  0.34388  1.36053]
21Feb13_072211| [ 0.59682 -0.32095 -0.26017 -0.37697]
21Feb13_072211| [-0.12492 -0.96720 -0.37226  1.13062]
21Feb13_072211| [-0.88189 -1.66780 -1.80232 -0.44017]
21Feb13_072211| [ 1.96237 -1.70845  1.33322  0.76020]
21Feb13_072211| [-0.38850 -0.99186  0.23685  1.54881]
21Feb13_072211| [ 0.59635  1.00214 -0.34630  0.65212]
21Feb13_072211| [-0.55835 -1.43523 -0.80696  0.89527]
21Feb13_072211| [-0.85157 -0.88757 -0.48935  0.15119]
21Feb13_072211| [-0.42280 -0.19208  0.72967  0.52976]
21Feb13_072211| [-1.59267  1.29657  0.12161  0.08457]
21Feb13_072211| [-1.77919  0.05853 -0.51608 -0.03135]
21Feb13_072211| [ 1.61866 -1.10419  1.10429  0.33431]
21Feb13_072211| [ 0.81056  0.19812  0.41656  0.05740]
21Feb13_072211| [-0.26445  1.37473 -0.20606 -0.30855]
21Feb13_072211| [ 0.05127 -0.13274 -0.50962 -1.46422]]
21Feb13_072211|-- Bias --
21Feb13_072211|[-0.63748 -0.26300 -0.80266  0.31986]
21Feb13_072211|Layer 1:
21Feb13_072211|-- Config --
21Feb13_072211|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072211|-- Weights --
21Feb13_072211|[[ 0.62773  0.73189 -0.04255]
21Feb13_072211| [ 0.81247 -1.05214  0.43753]
21Feb13_072211| [-0.53275  0.04289 -0.34052]
21Feb13_072211| [ 0.97058  0.02507 -0.57573]]
21Feb13_072211|-- Bias --
21Feb13_072211|[-0.62075  0.53538 -0.45169]
21Feb13_072211|Layer 2:
21Feb13_072211|-- Config --
21Feb13_072211|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072211|-- Weights --
21Feb13_072211|[[-1.11921  0.24347  0.13360  0.22215 -0.22782]
21Feb13_072211| [-0.30547  0.25637  0.68223  1.08533 -0.59880]
21Feb13_072211| [ 0.86558 -0.01238 -0.73882 -0.50169  0.03984]]
21Feb13_072211|-- Bias --
21Feb13_072211|[-0.51021  0.90455 -0.18279 -0.50572  0.35449]
21Feb13_072211|Layer 3:
21Feb13_072211|-- Config --
21Feb13_072211|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072211|-- Weights --
21Feb13_072211|[[-0.39122 -0.59379 -1.27752]
21Feb13_072211| [ 1.30726 -1.42157 -0.56541]
21Feb13_072211| [ 1.19283  1.04866 -0.70498]
21Feb13_072211| [-1.96881  2.06622 -0.66153]
21Feb13_072211| [-2.24836 -1.46952 -0.18691]]
21Feb13_072211|-- Bias --
21Feb13_072211|[0.49160 0.12520 0.53746]
21Feb13_072211|Layer 4:
21Feb13_072211|-- Config --
21Feb13_072211|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072211|-- Weights --
21Feb13_072211|[[-1.83636  1.23796]
21Feb13_072211| [ 0.32710  0.76989]
21Feb13_072211| [ 1.19828  0.18703]]
21Feb13_072211|-- Bias --
21Feb13_072211|[-0.69389  0.00692]
21Feb13_072211|Predicting the validation and test data with the Best final individual.
21Feb13_072218| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_072218|-----------  ------------------  --------------------  ----------
21Feb13_072218|Validation         21.91                  60            0.74426
21Feb13_072218|   Test            39.01                  60            0.00000
21Feb13_072218|-------------------- Test #11 --------------------
21Feb13_072218|Best final individual weights
21Feb13_072218|Individual:
21Feb13_072218|-- Constant hidden layers --
21Feb13_072218|False
21Feb13_072218|Layer 0:
21Feb13_072218|-- Config --
21Feb13_072218|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072218|-- Weights --
21Feb13_072218|[[ 0.09269  0.48303  0.72927  0.11324]
21Feb13_072218| [-0.81343 -1.95436  1.49446  0.20512]
21Feb13_072218| [ 1.15165 -0.22730  0.75332  1.92231]
21Feb13_072218| [ 0.89415  0.78083 -0.46926  0.25455]
21Feb13_072218| [-0.36531  1.01395 -0.83458  0.35869]
21Feb13_072218| [ 0.41464 -1.66984 -1.43993 -0.44003]
21Feb13_072218| [-0.83228  0.20239  0.76766  0.56882]
21Feb13_072218| [-0.18500  0.34614  1.08102  0.26417]
21Feb13_072218| [-0.42303 -0.00403  0.54872  0.48681]
21Feb13_072218| [-0.67618 -0.49210 -0.42538 -0.20233]
21Feb13_072218| [ 0.37425 -1.99260  0.54239  0.17569]
21Feb13_072218| [ 0.75275 -1.78012 -0.28372  0.43230]
21Feb13_072218| [-0.80620 -0.18828  0.14917 -0.50239]
21Feb13_072218| [ 0.53789  1.24471 -0.50203 -0.41772]
21Feb13_072218| [-0.54895 -0.04226 -0.39663  0.46996]
21Feb13_072218| [ 0.43342 -1.86025  0.42349  0.24957]
21Feb13_072218| [ 1.31029 -0.26223 -1.56812  0.04751]
21Feb13_072218| [-1.92088 -0.26961  0.51447 -0.00805]
21Feb13_072218| [ 0.88215  0.32746 -0.13028 -0.11589]
21Feb13_072218| [ 0.14543 -0.27306 -0.54068 -0.03721]
21Feb13_072218| [-0.26780  1.36653  0.05861 -0.38317]
21Feb13_072218| [ 1.32139 -1.73666 -1.05910  0.19164]
21Feb13_072218| [ 0.62757  1.01460  0.84528  0.10637]
21Feb13_072218| [-1.73185  1.50917  1.20313  0.17788]
21Feb13_072218| [-0.73762  0.52767  0.36189 -0.11175]
21Feb13_072218| [-0.08962  0.68032  0.74072 -0.04362]
21Feb13_072218| [-0.30375 -0.03590 -0.57539 -0.60920]
21Feb13_072218| [ 2.16279 -0.54638 -1.01209  0.49396]
21Feb13_072218| [-0.44346  0.74785 -1.95843  0.05063]
21Feb13_072218| [-1.90054 -0.84287  0.04422  0.27181]
21Feb13_072218| [-0.69009 -0.95128  0.08906  0.71146]
21Feb13_072218| [-2.07506 -0.05557  1.20531 -0.15867]
21Feb13_072218| [ 1.49476 -0.53759  0.73141 -0.50191]
21Feb13_072218| [-1.13549  0.31526  0.67884  0.06683]
21Feb13_072218| [ 1.08905 -0.06987 -0.34082 -0.04126]
21Feb13_072218| [-0.87868  0.53753  0.94409 -1.09155]
21Feb13_072218| [-0.77921 -0.28400  1.38582  0.15721]
21Feb13_072218| [ 0.59576 -1.17047 -0.36122  0.68355]
21Feb13_072218| [ 0.15388 -1.23415  0.57566  0.31033]
21Feb13_072218| [ 0.10572  1.22884 -0.33339  0.52500]
21Feb13_072218| [-0.69911  1.28362 -0.35205 -0.27316]
21Feb13_072218| [-0.54596 -1.29892  0.34388  1.36053]
21Feb13_072218| [ 0.59682 -0.32095 -0.26017 -0.37697]
21Feb13_072218| [-0.12492 -0.96720 -0.37226  1.13062]
21Feb13_072218| [-0.88189 -1.66780 -1.80232 -0.44017]
21Feb13_072218| [ 1.96237 -1.70845  1.33322  0.76020]
21Feb13_072218| [-0.38850 -0.99186  0.23685  1.54881]
21Feb13_072218| [ 0.59635  1.00214 -0.34630  0.65212]
21Feb13_072218| [-0.55835 -1.43523 -0.80696  0.89527]
21Feb13_072218| [-0.85157 -0.88757 -0.48935  0.15119]
21Feb13_072218| [-0.42280 -0.19208  0.72967  0.52976]
21Feb13_072218| [-1.59267  1.29657  0.12161  0.08457]
21Feb13_072218| [-1.77919  0.05853 -0.51608 -0.03135]
21Feb13_072218| [ 1.61866 -1.10419  1.10429  0.33431]
21Feb13_072218| [ 0.81056  0.19812  0.41656  0.05740]
21Feb13_072218| [-0.26445  1.37473 -0.20606 -0.30855]
21Feb13_072218| [ 0.05127 -0.13274 -0.50962 -1.46422]]
21Feb13_072218|-- Bias --
21Feb13_072218|[-0.63748 -0.26300 -0.80266  0.31986]
21Feb13_072218|Layer 1:
21Feb13_072218|-- Config --
21Feb13_072218|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072218|-- Weights --
21Feb13_072218|[[ 0.62773  0.73189 -0.04255]
21Feb13_072218| [ 0.81247 -1.05214  0.43753]
21Feb13_072218| [-0.53275  0.04289 -0.34052]
21Feb13_072218| [ 0.97058  0.02507 -0.57573]]
21Feb13_072218|-- Bias --
21Feb13_072218|[-0.62075  0.53538 -0.45169]
21Feb13_072218|Layer 2:
21Feb13_072218|-- Config --
21Feb13_072218|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072218|-- Weights --
21Feb13_072218|[[-1.11921  0.24347  0.13360  0.22215 -0.22782]
21Feb13_072218| [-0.30547  0.25637  0.68223  1.08533 -0.59880]
21Feb13_072218| [ 0.86558 -0.01238 -0.73882 -0.50169  0.03984]]
21Feb13_072218|-- Bias --
21Feb13_072218|[-0.51021  0.90455 -0.18279 -0.50572  0.35449]
21Feb13_072218|Layer 3:
21Feb13_072218|-- Config --
21Feb13_072218|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072218|-- Weights --
21Feb13_072218|[[-0.39122 -0.59379 -1.27752]
21Feb13_072218| [ 1.30726 -1.42157 -0.56541]
21Feb13_072218| [ 1.19283  1.04866 -0.70498]
21Feb13_072218| [-1.96881  2.06622 -0.66153]
21Feb13_072218| [-2.24836 -1.46952 -0.18691]]
21Feb13_072218|-- Bias --
21Feb13_072218|[0.49160 0.12520 0.53746]
21Feb13_072218|Layer 4:
21Feb13_072218|-- Config --
21Feb13_072218|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072218|-- Weights --
21Feb13_072218|[[-1.83636  1.23796]
21Feb13_072218| [ 0.32710  0.76989]
21Feb13_072218| [ 1.19828  0.18703]]
21Feb13_072218|-- Bias --
21Feb13_072218|[-0.69389  0.00692]
21Feb13_072218|Predicting the validation and test data with the Best final individual.
21Feb13_072226| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_072226|-----------  ------------------  --------------------  ----------
21Feb13_072226|Validation         38.78                  60            0.00000
21Feb13_072226|   Test            26.67                  60            0.76552
21Feb13_072226|-------------------- Test #12 --------------------
21Feb13_072226|Best final individual weights
21Feb13_072226|Individual:
21Feb13_072226|-- Constant hidden layers --
21Feb13_072226|False
21Feb13_072226|Layer 0:
21Feb13_072226|-- Config --
21Feb13_072226|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072226|-- Weights --
21Feb13_072226|[[ 0.09269  0.48303  0.72927  0.11324]
21Feb13_072226| [-0.81343 -1.95436  1.49446  0.20512]
21Feb13_072226| [ 1.15165 -0.22730  0.75332  1.92231]
21Feb13_072226| [ 0.89415  0.78083 -0.46926  0.25455]
21Feb13_072226| [-0.36531  1.01395 -0.83458  0.35869]
21Feb13_072226| [ 0.41464 -1.66984 -1.43993 -0.44003]
21Feb13_072226| [-0.83228  0.20239  0.76766  0.56882]
21Feb13_072226| [-0.18500  0.34614  1.08102  0.26417]
21Feb13_072226| [-0.42303 -0.00403  0.54872  0.48681]
21Feb13_072226| [-0.67618 -0.49210 -0.42538 -0.20233]
21Feb13_072226| [ 0.37425 -1.99260  0.54239  0.17569]
21Feb13_072226| [ 0.75275 -1.78012 -0.28372  0.43230]
21Feb13_072226| [-0.80620 -0.18828  0.14917 -0.50239]
21Feb13_072226| [ 0.53789  1.24471 -0.50203 -0.41772]
21Feb13_072226| [-0.54895 -0.04226 -0.39663  0.46996]
21Feb13_072226| [ 0.43342 -1.86025  0.42349  0.24957]
21Feb13_072226| [ 1.31029 -0.26223 -1.56812  0.04751]
21Feb13_072226| [-1.92088 -0.26961  0.51447 -0.00805]
21Feb13_072226| [ 0.88215  0.32746 -0.13028 -0.11589]
21Feb13_072226| [ 0.14543 -0.27306 -0.54068 -0.03721]
21Feb13_072226| [-0.26780  1.36653  0.05861 -0.38317]
21Feb13_072226| [ 1.32139 -1.73666 -1.05910  0.19164]
21Feb13_072226| [ 0.62757  1.01460  0.84528  0.10637]
21Feb13_072226| [-1.73185  1.50917  1.20313  0.17788]
21Feb13_072226| [-0.73762  0.52767  0.36189 -0.11175]
21Feb13_072226| [-0.08962  0.68032  0.74072 -0.04362]
21Feb13_072226| [-0.30375 -0.03590 -0.57539 -0.60920]
21Feb13_072226| [ 2.16279 -0.54638 -1.01209  0.49396]
21Feb13_072226| [-0.44346  0.74785 -1.95843  0.05063]
21Feb13_072226| [-1.90054 -0.84287  0.04422  0.27181]
21Feb13_072226| [-0.69009 -0.95128  0.08906  0.71146]
21Feb13_072226| [-2.07506 -0.05557  1.20531 -0.15867]
21Feb13_072226| [ 1.49476 -0.53759  0.73141 -0.50191]
21Feb13_072226| [-1.13549  0.31526  0.67884  0.06683]
21Feb13_072226| [ 1.08905 -0.06987 -0.34082 -0.04126]
21Feb13_072226| [-0.87868  0.53753  0.94409 -1.09155]
21Feb13_072226| [-0.77921 -0.28400  1.38582  0.15721]
21Feb13_072226| [ 0.59576 -1.17047 -0.36122  0.68355]
21Feb13_072226| [ 0.15388 -1.23415  0.57566  0.31033]
21Feb13_072226| [ 0.10572  1.22884 -0.33339  0.52500]
21Feb13_072226| [-0.69911  1.28362 -0.35205 -0.27316]
21Feb13_072226| [-0.54596 -1.29892  0.34388  1.36053]
21Feb13_072226| [ 0.59682 -0.32095 -0.26017 -0.37697]
21Feb13_072226| [-0.12492 -0.96720 -0.37226  1.13062]
21Feb13_072226| [-0.88189 -1.66780 -1.80232 -0.44017]
21Feb13_072226| [ 1.96237 -1.70845  1.33322  0.76020]
21Feb13_072226| [-0.38850 -0.99186  0.23685  1.54881]
21Feb13_072226| [ 0.59635  1.00214 -0.34630  0.65212]
21Feb13_072226| [-0.55835 -1.43523 -0.80696  0.89527]
21Feb13_072226| [-0.85157 -0.88757 -0.48935  0.15119]
21Feb13_072226| [-0.42280 -0.19208  0.72967  0.52976]
21Feb13_072226| [-1.59267  1.29657  0.12161  0.08457]
21Feb13_072226| [-1.77919  0.05853 -0.51608 -0.03135]
21Feb13_072226| [ 1.61866 -1.10419  1.10429  0.33431]
21Feb13_072226| [ 0.81056  0.19812  0.41656  0.05740]
21Feb13_072226| [-0.26445  1.37473 -0.20606 -0.30855]
21Feb13_072226| [ 0.05127 -0.13274 -0.50962 -1.46422]]
21Feb13_072226|-- Bias --
21Feb13_072226|[-0.63748 -0.26300 -0.80266  0.31986]
21Feb13_072226|Layer 1:
21Feb13_072226|-- Config --
21Feb13_072226|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072226|-- Weights --
21Feb13_072226|[[ 0.62773  0.73189 -0.04255]
21Feb13_072226| [ 0.81247 -1.05214  0.43753]
21Feb13_072226| [-0.53275  0.04289 -0.34052]
21Feb13_072226| [ 0.97058  0.02507 -0.57573]]
21Feb13_072226|-- Bias --
21Feb13_072226|[-0.62075  0.53538 -0.45169]
21Feb13_072226|Layer 2:
21Feb13_072226|-- Config --
21Feb13_072226|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072226|-- Weights --
21Feb13_072226|[[-1.11921  0.24347  0.13360  0.22215 -0.22782]
21Feb13_072226| [-0.30547  0.25637  0.68223  1.08533 -0.59880]
21Feb13_072226| [ 0.86558 -0.01238 -0.73882 -0.50169  0.03984]]
21Feb13_072226|-- Bias --
21Feb13_072226|[-0.51021  0.90455 -0.18279 -0.50572  0.35449]
21Feb13_072226|Layer 3:
21Feb13_072226|-- Config --
21Feb13_072226|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072226|-- Weights --
21Feb13_072226|[[-0.39122 -0.59379 -1.27752]
21Feb13_072226| [ 1.30726 -1.42157 -0.56541]
21Feb13_072226| [ 1.19283  1.04866 -0.70498]
21Feb13_072226| [-1.96881  2.06622 -0.66153]
21Feb13_072226| [-2.24836 -1.46952 -0.18691]]
21Feb13_072226|-- Bias --
21Feb13_072226|[0.49160 0.12520 0.53746]
21Feb13_072226|Layer 4:
21Feb13_072226|-- Config --
21Feb13_072226|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072226|-- Weights --
21Feb13_072226|[[-1.83636  1.23796]
21Feb13_072226| [ 0.32710  0.76989]
21Feb13_072226| [ 1.19828  0.18703]]
21Feb13_072226|-- Bias --
21Feb13_072226|[-0.69389  0.00692]
21Feb13_072226|Predicting the validation and test data with the Best final individual.
21Feb13_072234| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_072234|-----------  ------------------  --------------------  ----------
21Feb13_072234|Validation         22.70                  60            0.67882
21Feb13_072234|   Test            25.37                  60            0.55529
21Feb13_072234|-------------------- Test #13 --------------------
21Feb13_072234|Best final individual weights
21Feb13_072234|Individual:
21Feb13_072234|-- Constant hidden layers --
21Feb13_072234|False
21Feb13_072234|Layer 0:
21Feb13_072234|-- Config --
21Feb13_072234|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072234|-- Weights --
21Feb13_072234|[[ 0.09269  0.48303  0.72927  0.11324]
21Feb13_072234| [-0.81343 -1.95436  1.49446  0.20512]
21Feb13_072234| [ 1.15165 -0.22730  0.75332  1.92231]
21Feb13_072234| [ 0.89415  0.78083 -0.46926  0.25455]
21Feb13_072234| [-0.36531  1.01395 -0.83458  0.35869]
21Feb13_072234| [ 0.41464 -1.66984 -1.43993 -0.44003]
21Feb13_072234| [-0.83228  0.20239  0.76766  0.56882]
21Feb13_072234| [-0.18500  0.34614  1.08102  0.26417]
21Feb13_072234| [-0.42303 -0.00403  0.54872  0.48681]
21Feb13_072234| [-0.67618 -0.49210 -0.42538 -0.20233]
21Feb13_072234| [ 0.37425 -1.99260  0.54239  0.17569]
21Feb13_072234| [ 0.75275 -1.78012 -0.28372  0.43230]
21Feb13_072234| [-0.80620 -0.18828  0.14917 -0.50239]
21Feb13_072234| [ 0.53789  1.24471 -0.50203 -0.41772]
21Feb13_072234| [-0.54895 -0.04226 -0.39663  0.46996]
21Feb13_072234| [ 0.43342 -1.86025  0.42349  0.24957]
21Feb13_072234| [ 1.31029 -0.26223 -1.56812  0.04751]
21Feb13_072234| [-1.92088 -0.26961  0.51447 -0.00805]
21Feb13_072234| [ 0.88215  0.32746 -0.13028 -0.11589]
21Feb13_072234| [ 0.14543 -0.27306 -0.54068 -0.03721]
21Feb13_072234| [-0.26780  1.36653  0.05861 -0.38317]
21Feb13_072234| [ 1.32139 -1.73666 -1.05910  0.19164]
21Feb13_072234| [ 0.62757  1.01460  0.84528  0.10637]
21Feb13_072234| [-1.73185  1.50917  1.20313  0.17788]
21Feb13_072234| [-0.73762  0.52767  0.36189 -0.11175]
21Feb13_072234| [-0.08962  0.68032  0.74072 -0.04362]
21Feb13_072234| [-0.30375 -0.03590 -0.57539 -0.60920]
21Feb13_072234| [ 2.16279 -0.54638 -1.01209  0.49396]
21Feb13_072234| [-0.44346  0.74785 -1.95843  0.05063]
21Feb13_072234| [-1.90054 -0.84287  0.04422  0.27181]
21Feb13_072234| [-0.69009 -0.95128  0.08906  0.71146]
21Feb13_072234| [-2.07506 -0.05557  1.20531 -0.15867]
21Feb13_072234| [ 1.49476 -0.53759  0.73141 -0.50191]
21Feb13_072234| [-1.13549  0.31526  0.67884  0.06683]
21Feb13_072234| [ 1.08905 -0.06987 -0.34082 -0.04126]
21Feb13_072234| [-0.87868  0.53753  0.94409 -1.09155]
21Feb13_072234| [-0.77921 -0.28400  1.38582  0.15721]
21Feb13_072234| [ 0.59576 -1.17047 -0.36122  0.68355]
21Feb13_072234| [ 0.15388 -1.23415  0.57566  0.31033]
21Feb13_072234| [ 0.10572  1.22884 -0.33339  0.52500]
21Feb13_072234| [-0.69911  1.28362 -0.35205 -0.27316]
21Feb13_072234| [-0.54596 -1.29892  0.34388  1.36053]
21Feb13_072234| [ 0.59682 -0.32095 -0.26017 -0.37697]
21Feb13_072234| [-0.12492 -0.96720 -0.37226  1.13062]
21Feb13_072234| [-0.88189 -1.66780 -1.80232 -0.44017]
21Feb13_072234| [ 1.96237 -1.70845  1.33322  0.76020]
21Feb13_072234| [-0.38850 -0.99186  0.23685  1.54881]
21Feb13_072234| [ 0.59635  1.00214 -0.34630  0.65212]
21Feb13_072234| [-0.55835 -1.43523 -0.80696  0.89527]
21Feb13_072234| [-0.85157 -0.88757 -0.48935  0.15119]
21Feb13_072234| [-0.42280 -0.19208  0.72967  0.52976]
21Feb13_072234| [-1.59267  1.29657  0.12161  0.08457]
21Feb13_072234| [-1.77919  0.05853 -0.51608 -0.03135]
21Feb13_072234| [ 1.61866 -1.10419  1.10429  0.33431]
21Feb13_072234| [ 0.81056  0.19812  0.41656  0.05740]
21Feb13_072234| [-0.26445  1.37473 -0.20606 -0.30855]
21Feb13_072234| [ 0.05127 -0.13274 -0.50962 -1.46422]]
21Feb13_072234|-- Bias --
21Feb13_072234|[-0.63748 -0.26300 -0.80266  0.31986]
21Feb13_072234|Layer 1:
21Feb13_072234|-- Config --
21Feb13_072234|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072234|-- Weights --
21Feb13_072234|[[ 0.62773  0.73189 -0.04255]
21Feb13_072234| [ 0.81247 -1.05214  0.43753]
21Feb13_072234| [-0.53275  0.04289 -0.34052]
21Feb13_072234| [ 0.97058  0.02507 -0.57573]]
21Feb13_072234|-- Bias --
21Feb13_072234|[-0.62075  0.53538 -0.45169]
21Feb13_072234|Layer 2:
21Feb13_072234|-- Config --
21Feb13_072234|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072234|-- Weights --
21Feb13_072234|[[-1.11921  0.24347  0.13360  0.22215 -0.22782]
21Feb13_072234| [-0.30547  0.25637  0.68223  1.08533 -0.59880]
21Feb13_072234| [ 0.86558 -0.01238 -0.73882 -0.50169  0.03984]]
21Feb13_072234|-- Bias --
21Feb13_072234|[-0.51021  0.90455 -0.18279 -0.50572  0.35449]
21Feb13_072234|Layer 3:
21Feb13_072234|-- Config --
21Feb13_072234|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072234|-- Weights --
21Feb13_072234|[[-0.39122 -0.59379 -1.27752]
21Feb13_072234| [ 1.30726 -1.42157 -0.56541]
21Feb13_072234| [ 1.19283  1.04866 -0.70498]
21Feb13_072234| [-1.96881  2.06622 -0.66153]
21Feb13_072234| [-2.24836 -1.46952 -0.18691]]
21Feb13_072234|-- Bias --
21Feb13_072234|[0.49160 0.12520 0.53746]
21Feb13_072234|Layer 4:
21Feb13_072234|-- Config --
21Feb13_072234|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072234|-- Weights --
21Feb13_072234|[[-1.83636  1.23796]
21Feb13_072234| [ 0.32710  0.76989]
21Feb13_072234| [ 1.19828  0.18703]]
21Feb13_072234|-- Bias --
21Feb13_072234|[-0.69389  0.00692]
21Feb13_072234|Predicting the validation and test data with the Best final individual.
21Feb13_072242| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_072242|-----------  ------------------  --------------------  ----------
21Feb13_072242|Validation         22.26                  60            0.65167
21Feb13_072242|   Test            22.50                  60            0.72972
21Feb13_072242|-------------------- Test #14 --------------------
21Feb13_072242|Best final individual weights
21Feb13_072242|Individual:
21Feb13_072242|-- Constant hidden layers --
21Feb13_072242|False
21Feb13_072242|Layer 0:
21Feb13_072242|-- Config --
21Feb13_072242|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072242|-- Weights --
21Feb13_072242|[[ 0.09269  0.48303  0.72927  0.11324]
21Feb13_072242| [-0.81343 -1.95436  1.49446  0.20512]
21Feb13_072242| [ 1.15165 -0.22730  0.75332  1.92231]
21Feb13_072242| [ 0.89415  0.78083 -0.46926  0.25455]
21Feb13_072242| [-0.36531  1.01395 -0.83458  0.35869]
21Feb13_072242| [ 0.41464 -1.66984 -1.43993 -0.44003]
21Feb13_072242| [-0.83228  0.20239  0.76766  0.56882]
21Feb13_072242| [-0.18500  0.34614  1.08102  0.26417]
21Feb13_072242| [-0.42303 -0.00403  0.54872  0.48681]
21Feb13_072242| [-0.67618 -0.49210 -0.42538 -0.20233]
21Feb13_072242| [ 0.37425 -1.99260  0.54239  0.17569]
21Feb13_072242| [ 0.75275 -1.78012 -0.28372  0.43230]
21Feb13_072242| [-0.80620 -0.18828  0.14917 -0.50239]
21Feb13_072242| [ 0.53789  1.24471 -0.50203 -0.41772]
21Feb13_072242| [-0.54895 -0.04226 -0.39663  0.46996]
21Feb13_072242| [ 0.43342 -1.86025  0.42349  0.24957]
21Feb13_072242| [ 1.31029 -0.26223 -1.56812  0.04751]
21Feb13_072242| [-1.92088 -0.26961  0.51447 -0.00805]
21Feb13_072242| [ 0.88215  0.32746 -0.13028 -0.11589]
21Feb13_072242| [ 0.14543 -0.27306 -0.54068 -0.03721]
21Feb13_072242| [-0.26780  1.36653  0.05861 -0.38317]
21Feb13_072242| [ 1.32139 -1.73666 -1.05910  0.19164]
21Feb13_072242| [ 0.62757  1.01460  0.84528  0.10637]
21Feb13_072242| [-1.73185  1.50917  1.20313  0.17788]
21Feb13_072242| [-0.73762  0.52767  0.36189 -0.11175]
21Feb13_072242| [-0.08962  0.68032  0.74072 -0.04362]
21Feb13_072242| [-0.30375 -0.03590 -0.57539 -0.60920]
21Feb13_072242| [ 2.16279 -0.54638 -1.01209  0.49396]
21Feb13_072242| [-0.44346  0.74785 -1.95843  0.05063]
21Feb13_072242| [-1.90054 -0.84287  0.04422  0.27181]
21Feb13_072242| [-0.69009 -0.95128  0.08906  0.71146]
21Feb13_072242| [-2.07506 -0.05557  1.20531 -0.15867]
21Feb13_072242| [ 1.49476 -0.53759  0.73141 -0.50191]
21Feb13_072242| [-1.13549  0.31526  0.67884  0.06683]
21Feb13_072242| [ 1.08905 -0.06987 -0.34082 -0.04126]
21Feb13_072242| [-0.87868  0.53753  0.94409 -1.09155]
21Feb13_072242| [-0.77921 -0.28400  1.38582  0.15721]
21Feb13_072242| [ 0.59576 -1.17047 -0.36122  0.68355]
21Feb13_072242| [ 0.15388 -1.23415  0.57566  0.31033]
21Feb13_072242| [ 0.10572  1.22884 -0.33339  0.52500]
21Feb13_072242| [-0.69911  1.28362 -0.35205 -0.27316]
21Feb13_072242| [-0.54596 -1.29892  0.34388  1.36053]
21Feb13_072242| [ 0.59682 -0.32095 -0.26017 -0.37697]
21Feb13_072242| [-0.12492 -0.96720 -0.37226  1.13062]
21Feb13_072242| [-0.88189 -1.66780 -1.80232 -0.44017]
21Feb13_072242| [ 1.96237 -1.70845  1.33322  0.76020]
21Feb13_072242| [-0.38850 -0.99186  0.23685  1.54881]
21Feb13_072242| [ 0.59635  1.00214 -0.34630  0.65212]
21Feb13_072242| [-0.55835 -1.43523 -0.80696  0.89527]
21Feb13_072242| [-0.85157 -0.88757 -0.48935  0.15119]
21Feb13_072242| [-0.42280 -0.19208  0.72967  0.52976]
21Feb13_072242| [-1.59267  1.29657  0.12161  0.08457]
21Feb13_072242| [-1.77919  0.05853 -0.51608 -0.03135]
21Feb13_072242| [ 1.61866 -1.10419  1.10429  0.33431]
21Feb13_072242| [ 0.81056  0.19812  0.41656  0.05740]
21Feb13_072242| [-0.26445  1.37473 -0.20606 -0.30855]
21Feb13_072242| [ 0.05127 -0.13274 -0.50962 -1.46422]]
21Feb13_072242|-- Bias --
21Feb13_072242|[-0.63748 -0.26300 -0.80266  0.31986]
21Feb13_072242|Layer 1:
21Feb13_072242|-- Config --
21Feb13_072242|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072242|-- Weights --
21Feb13_072242|[[ 0.62773  0.73189 -0.04255]
21Feb13_072242| [ 0.81247 -1.05214  0.43753]
21Feb13_072242| [-0.53275  0.04289 -0.34052]
21Feb13_072242| [ 0.97058  0.02507 -0.57573]]
21Feb13_072242|-- Bias --
21Feb13_072242|[-0.62075  0.53538 -0.45169]
21Feb13_072242|Layer 2:
21Feb13_072242|-- Config --
21Feb13_072242|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072242|-- Weights --
21Feb13_072242|[[-1.11921  0.24347  0.13360  0.22215 -0.22782]
21Feb13_072242| [-0.30547  0.25637  0.68223  1.08533 -0.59880]
21Feb13_072242| [ 0.86558 -0.01238 -0.73882 -0.50169  0.03984]]
21Feb13_072242|-- Bias --
21Feb13_072242|[-0.51021  0.90455 -0.18279 -0.50572  0.35449]
21Feb13_072242|Layer 3:
21Feb13_072242|-- Config --
21Feb13_072242|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072242|-- Weights --
21Feb13_072242|[[-0.39122 -0.59379 -1.27752]
21Feb13_072242| [ 1.30726 -1.42157 -0.56541]
21Feb13_072242| [ 1.19283  1.04866 -0.70498]
21Feb13_072242| [-1.96881  2.06622 -0.66153]
21Feb13_072242| [-2.24836 -1.46952 -0.18691]]
21Feb13_072242|-- Bias --
21Feb13_072242|[0.49160 0.12520 0.53746]
21Feb13_072242|Layer 4:
21Feb13_072242|-- Config --
21Feb13_072242|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_072242|-- Weights --
21Feb13_072242|[[-1.83636  1.23796]
21Feb13_072242| [ 0.32710  0.76989]
21Feb13_072242| [ 1.19828  0.18703]]
21Feb13_072242|-- Bias --
21Feb13_072242|[-0.69389  0.00692]
21Feb13_072242|Predicting the validation and test data with the Best final individual.
21Feb13_072250| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_072250|-----------  ------------------  --------------------  ----------
21Feb13_072250|Validation         38.78                  60            0.00000
21Feb13_072250|   Test            27.37                  60            0.71827
2021-02-13 07:22:51.330593: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
21Feb13_072252|Data summary: Train
21Feb13_072252|data.shape = (2300, 57)
21Feb13_072252|labels.shape = (2300,)
21Feb13_072252|Class distribution:
21Feb13_072252|	0 - 1382 (0.60)
21Feb13_072252|	1 - 918 (0.40)
21Feb13_072252|Data summary: Validation
21Feb13_072252|data.shape = (1150, 57)
21Feb13_072252|labels.shape = (1150,)
21Feb13_072252|Class distribution:
21Feb13_072252|	0 - 704 (0.61)
21Feb13_072252|	1 - 446 (0.39)
21Feb13_072252|Data summary: Test
21Feb13_072252|data.shape = (1151, 57)
21Feb13_072252|labels.shape = (1151,)
21Feb13_072252|Class distribution:
21Feb13_072252|	0 - 702 (0.61)
21Feb13_072252|	1 - 449 (0.39)
21Feb13_072252|Selected configuration values
21Feb13_072252|-- Dataset name: spambase1
21Feb13_072252|-- Initial population size: 64
21Feb13_072252|-- Maximun number of generations: 32
21Feb13_072252|-- Neurons per hidden layer range: (2, 20)
21Feb13_072252|-- Hidden layers number range: (1, 3)
21Feb13_072252|-- Crossover probability: 0.5
21Feb13_072252|-- Bias gene mutation probability: 0.2
21Feb13_072252|-- Weights gene mutation probability: 0.75
21Feb13_072252|-- Neuron mutation probability: 0.3
21Feb13_072252|-- Layer mutation probability: 0.3
21Feb13_072252|-- Constant hidden layers: False
21Feb13_072252|-- Seed: 31415
21Feb13_072252|Entering GA
21Feb13_072252|Start the algorithm
2021-02-13 07:22:52.176930: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-13 07:22:52.177469: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-02-13 07:22:52.199052: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-13 07:22:52.199384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.71GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s
2021-02-13 07:22:52.199406: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-02-13 07:22:52.200875: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-02-13 07:22:52.200904: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-02-13 07:22:52.201402: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-02-13 07:22:52.201541: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-02-13 07:22:52.201614: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-13 07:22:52.202023: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-02-13 07:22:52.202066: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-13 07:22:52.202072: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-02-13 07:22:52.202279: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-02-13 07:22:52.203087: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-13 07:22:52.203102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-13 07:22:52.203105: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      
2021-02-13 07:22:52.248162: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-02-13 07:22:52.248503: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3493635000 Hz
/home/jmerelo/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype("int32")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn('`model.predict_classes()` is deprecated and '
21Feb13_072653|-- Generation 1 --
21Feb13_072653|    -- Crossed 1 individual pairs.
21Feb13_072653|    -- Mutated 32 individuals.
21Feb13_073052|    -- Evaluated 64 individuals.
21Feb13_073052|    Summary of generation 1:
21Feb13_073052| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_073052|-----------  ------------------  --------------------  ----------
21Feb13_073052|    Max            39.57                208.00          0.41646
21Feb13_073052|    Avg            38.66                52.00           0.00686
21Feb13_073052|    Min            26.35                 3.00           0.00000
21Feb13_073052|    Std             1.56                45.19           0.05168
21Feb13_073052|   Best            26.35                111.00          0.41646
21Feb13_073052|-- Generation 2 --
21Feb13_073052|    -- Crossed 3 individual pairs.
21Feb13_073052|    -- Mutated 32 individuals.
21Feb13_073451|    -- Evaluated 64 individuals.
21Feb13_073451|    Summary of generation 2:
21Feb13_073451| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_073451|-----------  ------------------  --------------------  ----------
21Feb13_073451|    Max            39.39                164.00          0.31299
21Feb13_073451|    Avg            38.67                37.59           0.00952
21Feb13_073451|    Min            29.48                 3.00           0.00000
21Feb13_073451|    Std             1.19                34.38           0.05182
21Feb13_073451|   Best            29.48                10.00           0.31299
21Feb13_073451|-- Generation 3 --
21Feb13_073451|    -- Crossed 2 individual pairs.
21Feb13_073451|    -- Mutated 32 individuals.
21Feb13_073845|    -- Evaluated 64 individuals.
21Feb13_073845|    Summary of generation 3:
21Feb13_073845| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_073845|-----------  ------------------  --------------------  ----------
21Feb13_073845|    Max            39.22                68.00           0.63297
21Feb13_073845|    Avg            38.28                17.03           0.02437
21Feb13_073845|    Min            26.00                 2.00           0.00000
21Feb13_073845|    Std             2.39                14.90           0.11104
21Feb13_073845|   Best            26.00                26.00           0.59563
21Feb13_073845|-- Generation 4 --
21Feb13_073845|    -- Crossed 2 individual pairs.
21Feb13_073845|    -- Mutated 32 individuals.
21Feb13_074235|    -- Evaluated 64 individuals.
21Feb13_074235|    Summary of generation 4:
21Feb13_074235| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_074235|-----------  ------------------  --------------------  ----------
21Feb13_074235|    Max            39.30                34.00           0.49292
21Feb13_074235|    Avg            38.46                 9.36           0.01387
21Feb13_074235|    Min            26.70                 2.00           0.00000
21Feb13_074235|    Std             1.97                 7.33           0.07479
21Feb13_074235|   Best            26.70                10.00           0.49292
21Feb13_074235|-- Generation 5 --
21Feb13_074235|    -- Crossed 6 individual pairs.
21Feb13_074235|    -- Mutated 32 individuals.
21Feb13_074624|    -- Evaluated 64 individuals.
21Feb13_074624|    Summary of generation 5:
21Feb13_074624| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_074624|-----------  ------------------  --------------------  ----------
21Feb13_074624|    Max            39.13                21.00           0.57981
21Feb13_074624|    Avg            38.04                 6.47           0.03084
21Feb13_074624|    Min            25.91                 2.00           0.00000
21Feb13_074624|    Std             2.78                 4.08           0.11160
21Feb13_074624|   Best            25.91                12.00           0.57981
21Feb13_074624|-- Generation 6 --
21Feb13_074624|    -- Crossed 7 individual pairs.
21Feb13_074624|    -- Mutated 32 individuals.
21Feb13_075012|    -- Evaluated 64 individuals.
21Feb13_075012|    Summary of generation 6:
21Feb13_075012| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_075012|-----------  ------------------  --------------------  ----------
21Feb13_075012|    Max            39.04                24.00           0.53983
21Feb13_075012|    Avg            38.21                 5.92           0.02206
21Feb13_075012|    Min            25.65                 2.00           0.00000
21Feb13_075012|    Std             2.69                 4.86           0.09981
21Feb13_075012|   Best            25.65                10.00           0.46587
21Feb13_075012|-- Generation 7 --
21Feb13_075012|    -- Crossed 4 individual pairs.
21Feb13_075012|    -- Mutated 32 individuals.
21Feb13_075359|    -- Evaluated 64 individuals.
21Feb13_075359|    Summary of generation 7:
21Feb13_075359| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_075359|-----------  ------------------  --------------------  ----------
21Feb13_075359|    Max            38.96                16.00           0.74163
21Feb13_075359|    Avg            37.96                 4.61           0.03253
21Feb13_075359|    Min            24.26                 2.00           0.00000
21Feb13_075359|    Std             3.15                 3.75           0.12807
21Feb13_075359|   Best            24.26                12.00           0.74163
21Feb13_075359|-- Generation 8 --
21Feb13_075359|    -- Crossed 9 individual pairs.
21Feb13_075359|    -- Mutated 32 individuals.
21Feb13_075746|    -- Evaluated 64 individuals.
21Feb13_075746|    Summary of generation 8:
21Feb13_075746| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_075746|-----------  ------------------  --------------------  ----------
21Feb13_075746|    Max            39.22                33.00           0.71301
21Feb13_075746|    Avg            37.93                 4.98           0.03478
21Feb13_075746|    Min            22.70                 2.00           0.00000
21Feb13_075746|    Std             3.29                 5.18           0.13309
21Feb13_075746|   Best            22.70                12.00           0.71301
21Feb13_075746|-- Generation 9 --
21Feb13_075746|    -- Crossed 8 individual pairs.
21Feb13_075746|    -- Mutated 32 individuals.
21Feb13_080133|    -- Evaluated 64 individuals.
21Feb13_080133|    Summary of generation 9:
21Feb13_080133| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_080133|-----------  ------------------  --------------------  ----------
21Feb13_080133|    Max            49.04                14.00           0.79570
21Feb13_080133|    Avg            38.15                 4.69           0.04669
21Feb13_080133|    Min            24.96                 2.00           0.00000
21Feb13_080133|    Std             3.43                 4.24           0.16168
21Feb13_080133|   Best            24.96                12.00           0.54969
21Feb13_080133|-- Generation 10 --
21Feb13_080133|    -- Crossed 6 individual pairs.
21Feb13_080133|    -- Mutated 32 individuals.
21Feb13_080521|    -- Evaluated 64 individuals.
21Feb13_080521|    Summary of generation 10:
21Feb13_080521| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_080521|-----------  ------------------  --------------------  ----------
21Feb13_080521|    Max            39.13                16.00           0.80562
21Feb13_080521|    Avg            37.89                 4.78           0.04842
21Feb13_080521|    Min            24.70                 2.00           0.00000
21Feb13_080521|    Std             3.22                 4.28           0.16856
21Feb13_080521|   Best            24.70                12.00           0.49852
21Feb13_080521|-- Generation 11 --
21Feb13_080521|    -- Crossed 9 individual pairs.
21Feb13_080521|    -- Mutated 32 individuals.
21Feb13_080908|    -- Evaluated 64 individuals.
21Feb13_080908|    Summary of generation 11:
21Feb13_080908| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_080908|-----------  ------------------  --------------------  ----------
21Feb13_080908|    Max            54.09                33.00           0.79959
21Feb13_080908|    Avg            37.85                 5.28           0.07240
21Feb13_080908|    Min            23.13                 2.00           0.00000
21Feb13_080908|    Std             4.31                 5.68           0.20962
21Feb13_080908|   Best            23.13                12.00           0.57582
21Feb13_080908|-- Generation 12 --
21Feb13_080908|    -- Crossed 9 individual pairs.
21Feb13_080908|    -- Mutated 32 individuals.
21Feb13_081256|    -- Evaluated 64 individuals.
21Feb13_081256|    Summary of generation 12:
21Feb13_081256| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_081256|-----------  ------------------  --------------------  ----------
21Feb13_081256|    Max            49.74                33.00           0.79098
21Feb13_081256|    Avg            38.12                 5.73           0.04684
21Feb13_081256|    Min            24.61                 2.00           0.00000
21Feb13_081256|    Std             3.54                 7.36           0.16356
21Feb13_081256|   Best            24.61                12.00           0.56563
21Feb13_081256|-- Generation 13 --
21Feb13_081256|    -- Crossed 7 individual pairs.
21Feb13_081256|    -- Mutated 32 individuals.
21Feb13_081644|    -- Evaluated 64 individuals.
21Feb13_081644|    Summary of generation 13:
21Feb13_081644| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_081644|-----------  ------------------  --------------------  ----------
21Feb13_081644|    Max            39.57                33.00           0.79427
21Feb13_081644|    Avg            38.14                 4.92           0.03695
21Feb13_081644|    Min            24.17                 2.00           0.00000
21Feb13_081644|    Std             2.69                 5.53           0.14021
21Feb13_081644|   Best            24.17                12.00           0.59972
21Feb13_081644|-- Generation 14 --
21Feb13_081644|    -- Crossed 5 individual pairs.
21Feb13_081644|    -- Mutated 32 individuals.
21Feb13_082033|    -- Evaluated 64 individuals.
21Feb13_082033|    Summary of generation 14:
21Feb13_082033| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_082033|-----------  ------------------  --------------------  ----------
21Feb13_082033|    Max            39.13                18.00           0.72205
21Feb13_082033|    Avg            38.26                 5.05           0.02363
21Feb13_082033|    Min            25.83                 2.00           0.00000
21Feb13_082033|    Std             2.48                 4.59           0.11191
21Feb13_082033|   Best            25.83                12.00           0.72205
21Feb13_082033|-- Generation 15 --
21Feb13_082033|    -- Crossed 9 individual pairs.
21Feb13_082033|    -- Mutated 32 individuals.
21Feb13_082419|    -- Evaluated 64 individuals.
21Feb13_082419|    Summary of generation 15:
21Feb13_082419| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_082419|-----------  ------------------  --------------------  ----------
21Feb13_082419|    Max            50.87                16.00           0.78975
21Feb13_082419|    Avg            38.76                 4.16           0.02163
21Feb13_082419|    Min            26.17                 2.00           0.00000
21Feb13_082419|    Std             2.19                 4.16           0.11245
21Feb13_082419|   Best            26.17                12.00           0.44199
21Feb13_082419|-- Generation 16 --
21Feb13_082419|    -- Crossed 5 individual pairs.
21Feb13_082419|    -- Mutated 32 individuals.
21Feb13_082805|    -- Evaluated 64 individuals.
21Feb13_082805|    Summary of generation 16:
21Feb13_082805| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_082805|-----------  ------------------  --------------------  ----------
21Feb13_082805|    Max            38.96                14.00           0.75591
21Feb13_082805|    Avg            38.10                 4.70           0.03600
21Feb13_082805|    Min            25.91                 2.00           0.00000
21Feb13_082805|    Std             2.65                 4.22           0.14463
21Feb13_082805|   Best            25.91                14.00           0.45704
21Feb13_082805|-- Generation 17 --
21Feb13_082805|    -- Crossed 6 individual pairs.
21Feb13_082805|    -- Mutated 32 individuals.
21Feb13_083152|    -- Evaluated 64 individuals.
21Feb13_083152|    Summary of generation 17:
21Feb13_083152| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_083152|-----------  ------------------  --------------------  ----------
21Feb13_083152|    Max            41.13                16.00           0.73181
21Feb13_083152|    Avg            38.55                 4.69           0.02029
21Feb13_083152|    Min            26.00                 2.00           0.00000
21Feb13_083152|    Std             1.71                 4.53           0.11223
21Feb13_083152|   Best            26.00                12.00           0.54467
21Feb13_083152|-- Generation 18 --
21Feb13_083152|    -- Crossed 7 individual pairs.
21Feb13_083152|    -- Mutated 32 individuals.
21Feb13_083538|    -- Evaluated 64 individuals.
21Feb13_083538|    Summary of generation 18:
21Feb13_083538| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_083538|-----------  ------------------  --------------------  ----------
21Feb13_083538|    Max            39.04                30.00           0.76845
21Feb13_083538|    Avg            38.48                 4.66           0.02098
21Feb13_083538|    Min            26.00                 2.00           0.00000
21Feb13_083538|    Std             1.82                 5.51           0.11683
21Feb13_083538|   Best            26.00                12.00           0.55766
21Feb13_083538|-- Generation 19 --
21Feb13_083538|    -- Crossed 3 individual pairs.
21Feb13_083538|    -- Mutated 32 individuals.
21Feb13_083923|    -- Evaluated 64 individuals.
21Feb13_083923|    Summary of generation 19:
21Feb13_083923| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_083923|-----------  ------------------  --------------------  ----------
21Feb13_083923|    Max            39.04                16.00           0.71675
21Feb13_083923|    Avg            38.38                 3.70           0.02187
21Feb13_083923|    Min            25.04                 2.00           0.00000
21Feb13_083923|    Std             2.18                 3.60           0.11527
21Feb13_083923|   Best            25.04                12.00           0.60047
21Feb13_083923|-- Generation 20 --
21Feb13_083923|    -- Crossed 5 individual pairs.
21Feb13_083923|    -- Mutated 32 individuals.
21Feb13_084309|    -- Evaluated 64 individuals.
21Feb13_084309|    Summary of generation 20:
21Feb13_084309| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_084309|-----------  ------------------  --------------------  ----------
21Feb13_084309|    Max            38.87                14.00           0.58341
21Feb13_084309|    Avg            38.45                 3.84           0.01384
21Feb13_084309|    Min            25.91                 2.00           0.00000
21Feb13_084309|    Std             1.91                 3.72           0.08033
21Feb13_084309|   Best            25.91                12.00           0.58341
21Feb13_084309|-- Generation 21 --
21Feb13_084309|    -- Crossed 9 individual pairs.
21Feb13_084309|    -- Mutated 32 individuals.
21Feb13_084656|    -- Evaluated 64 individuals.
21Feb13_084656|    Summary of generation 21:
21Feb13_084656| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_084656|-----------  ------------------  --------------------  ----------
21Feb13_084656|    Max            39.04                20.00           0.50630
21Feb13_084656|    Avg            38.60                 3.70           0.00822
21Feb13_084656|    Min            26.78                 2.00           0.00000
21Feb13_084656|    Std             1.49                 3.68           0.06280
21Feb13_084656|   Best            26.78                12.00           0.50630
21Feb13_084656|-- Generation 22 --
21Feb13_084656|    -- Crossed 10 individual pairs.
21Feb13_084656|    -- Mutated 32 individuals.
21Feb13_085043|    -- Evaluated 64 individuals.
21Feb13_085043|    Summary of generation 22:
21Feb13_085043| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_085043|-----------  ------------------  --------------------  ----------
21Feb13_085043|    Max            38.96                27.00           0.53494
21Feb13_085043|    Avg            38.39                 4.09           0.01629
21Feb13_085043|    Min            25.48                 2.00           0.00000
21Feb13_085043|    Std             2.24                 4.54           0.09072
21Feb13_085043|   Best            25.48                12.00           0.53494
21Feb13_085043|-- Generation 23 --
21Feb13_085043|    -- Crossed 5 individual pairs.
21Feb13_085043|    -- Mutated 32 individuals.
21Feb13_085430|    -- Evaluated 64 individuals.
21Feb13_085430|    Summary of generation 23:
21Feb13_085430| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_085430|-----------  ------------------  --------------------  ----------
21Feb13_085430|    Max            39.13                16.00           0.49383
21Feb13_085430|    Avg            38.24                 4.64           0.02062
21Feb13_085430|    Min            24.96                 2.00           0.00000
21Feb13_085430|    Std             2.60                 4.77           0.09336
21Feb13_085430|   Best            24.96                12.00           0.49383
21Feb13_085430|-- Generation 24 --
21Feb13_085430|    -- Crossed 8 individual pairs.
21Feb13_085430|    -- Mutated 32 individuals.
21Feb13_085816|    -- Evaluated 64 individuals.
21Feb13_085816|    Summary of generation 24:
21Feb13_085816| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_085816|-----------  ------------------  --------------------  ----------
21Feb13_085816|    Max            38.96                14.00           0.60133
21Feb13_085816|    Avg            38.13                 3.86           0.02686
21Feb13_085816|    Min            23.13                 2.00           0.00000
21Feb13_085816|    Std             3.00                 3.80           0.12132
21Feb13_085816|   Best            23.13                12.00           0.60133
21Feb13_085816|-- Generation 25 --
21Feb13_085816|    -- Crossed 4 individual pairs.
21Feb13_085816|    -- Mutated 32 individuals.
21Feb13_090202|    -- Evaluated 64 individuals.
21Feb13_090202|    Summary of generation 25:
21Feb13_090202| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_090202|-----------  ------------------  --------------------  ----------
21Feb13_090202|    Max            40.17                16.00           0.58906
21Feb13_090202|    Avg            38.23                 4.09           0.02431
21Feb13_090202|    Min            25.65                 2.00           0.00000
21Feb13_090202|    Std             2.65                 4.05           0.11115
21Feb13_090202|   Best            25.65                12.00           0.56791
21Feb13_090202|-- Generation 26 --
21Feb13_090202|    -- Crossed 8 individual pairs.
21Feb13_090202|    -- Mutated 32 individuals.
21Feb13_090549|    -- Evaluated 64 individuals.
21Feb13_090549|    Summary of generation 26:
21Feb13_090549| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_090549|-----------  ------------------  --------------------  ----------
21Feb13_090549|    Max            53.30                30.00           0.78317
21Feb13_090549|    Avg            38.18                 4.80           0.04443
21Feb13_090549|    Min            24.87                 2.00           0.00000
21Feb13_090549|    Std             3.76                 5.28           0.15529
21Feb13_090549|   Best            24.87                12.00           0.48211
21Feb13_090549|-- Generation 27 --
21Feb13_090549|    -- Crossed 8 individual pairs.
21Feb13_090549|    -- Mutated 32 individuals.
21Feb13_090936|    -- Evaluated 64 individuals.
21Feb13_090936|    Summary of generation 27:
21Feb13_090936| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_090936|-----------  ------------------  --------------------  ----------
21Feb13_090936|    Max            50.78                16.00           0.79125
21Feb13_090936|    Avg            38.20                 4.55           0.04502
21Feb13_090936|    Min            25.48                 2.00           0.00000
21Feb13_090936|    Std             3.49                 4.30           0.15792
21Feb13_090936|   Best            25.48                10.00           0.48443
21Feb13_090936|-- Generation 28 --
21Feb13_090936|    -- Crossed 6 individual pairs.
21Feb13_090936|    -- Mutated 32 individuals.
21Feb13_091323|    -- Evaluated 64 individuals.
21Feb13_091323|    Summary of generation 28:
21Feb13_091323| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_091323|-----------  ------------------  --------------------  ----------
21Feb13_091323|    Max            39.04                30.00           0.56667
21Feb13_091323|    Avg            37.74                 4.78           0.03958
21Feb13_091323|    Min            23.48                 2.00           0.00000
21Feb13_091323|    Std             3.65                 5.13           0.13668
21Feb13_091323|   Best            23.48                12.00           0.55233
21Feb13_091323|-- Generation 29 --
21Feb13_091323|    -- Crossed 8 individual pairs.
21Feb13_091323|    -- Mutated 32 individuals.
21Feb13_091711|    -- Evaluated 64 individuals.
21Feb13_091711|    Summary of generation 29:
21Feb13_091711| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_091711|-----------  ------------------  --------------------  ----------
21Feb13_091711|    Max            39.22                36.00           0.76826
21Feb13_091711|    Avg            37.20                 5.92           0.06713
21Feb13_091711|    Min            23.91                 2.00           0.00000
21Feb13_091711|    Std             4.25                 7.23           0.18392
21Feb13_091711|   Best            23.91                14.00           0.74292
21Feb13_091711|-- Generation 30 --
21Feb13_091711|    -- Crossed 5 individual pairs.
21Feb13_091711|    -- Mutated 32 individuals.
21Feb13_092100|    -- Evaluated 64 individuals.
21Feb13_092100|    Summary of generation 30:
21Feb13_092100| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_092100|-----------  ------------------  --------------------  ----------
21Feb13_092100|    Max            42.35                33.00           0.81081
21Feb13_092100|    Avg            37.68                 6.64           0.06439
21Feb13_092100|    Min            24.00                 2.00           0.00000
21Feb13_092100|    Std             3.78                 7.58           0.18600
21Feb13_092100|   Best            24.00                10.00           0.62674
21Feb13_092100|-- Generation 31 --
21Feb13_092100|    -- Crossed 3 individual pairs.
21Feb13_092100|    -- Mutated 32 individuals.
21Feb13_092446|    -- Evaluated 64 individuals.
21Feb13_092446|    Summary of generation 31:
21Feb13_092446| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_092446|-----------  ------------------  --------------------  ----------
21Feb13_092446|    Max            39.39                30.00           0.69088
21Feb13_092446|    Avg            37.83                 5.83           0.03809
21Feb13_092446|    Min            24.87                 2.00           0.00000
21Feb13_092446|    Std             3.28                 6.60           0.12961
21Feb13_092446|   Best            24.87                30.00           0.49407
21Feb13_092446|-- Generation 32 --
21Feb13_092446|    -- Crossed 2 individual pairs.
21Feb13_092446|    -- Mutated 32 individuals.
21Feb13_092833|    -- Evaluated 64 individuals.
21Feb13_092833|    Summary of generation 32:
21Feb13_092833| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_092833|-----------  ------------------  --------------------  ----------
21Feb13_092833|    Max            40.35                33.00           0.50344
21Feb13_092833|    Avg            37.90                 5.72           0.03398
21Feb13_092833|    Min            25.04                 2.00           0.00000
21Feb13_092833|    Std             3.25                 6.93           0.11669
21Feb13_092833|   Best            25.04                30.00           0.50344
21Feb13_092833|Best initial individual weights
21Feb13_092833|Individual:
21Feb13_092833|-- Constant hidden layers --
21Feb13_092833|False
21Feb13_092833|Layer 0:
21Feb13_092833|-- Config --
21Feb13_092833|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 12, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092833|-- Weights --
21Feb13_092833|[[-0.19605  0.07843 -0.31094 -0.44735  0.88644 -0.41005 -0.92737 -0.51939
21Feb13_092833|   0.90379 -0.86722 -0.58442  0.02119]
21Feb13_092833| [ 0.54780 -0.13999  0.86992  0.67643  0.63457 -0.26414 -0.76365  0.83511
21Feb13_092833|  -0.82664  0.19916 -0.42085  0.14112]
21Feb13_092833| [ 0.92815 -0.99412 -0.30782  0.33834  0.85210 -0.59432 -0.14883 -0.83946
21Feb13_092833|   0.13172 -0.59112 -0.69063  0.18870]
21Feb13_092833| [-0.29746  0.71772 -0.72497 -0.03391 -0.60978  0.53162 -0.51971 -0.07740
21Feb13_092833|   0.00958 -0.35158  0.49349 -0.32340]
21Feb13_092833| [ 0.73546 -0.41176 -0.89296 -0.36846  0.69857 -0.98545 -0.61422 -0.97115
21Feb13_092833|  -0.19382  0.30549 -0.61369 -0.53775]
21Feb13_092833| [-0.51907  0.84979 -0.74659  0.37694  0.20955 -0.42773  0.25342 -0.24185
21Feb13_092833|  -0.58571 -0.54052  0.01641 -0.62195]
21Feb13_092833| [-0.36637 -0.59648  0.90641 -0.32917  0.70252 -0.97759  0.77156 -0.54336
21Feb13_092833|  -0.63097  0.58684  0.56565 -0.38443]
21Feb13_092833| [ 0.47220  0.19322 -0.64569 -0.14107 -0.23431 -0.86701  0.92105  0.34531
21Feb13_092833|   0.09836 -0.70972 -0.53027  0.34415]
21Feb13_092833| [-0.49035 -0.87304 -0.34528 -0.41579 -0.02059  0.39221  0.63551 -0.02803
21Feb13_092833|   0.44723 -0.62434 -0.21190 -0.96922]
21Feb13_092833| [ 0.47460 -0.96286 -0.81731 -0.84472 -0.58155 -0.99043 -0.50158  0.76152
21Feb13_092833|  -0.66560  0.79135  0.71026 -0.67793]
21Feb13_092833| [-0.42166  0.23994 -0.27482  0.14800  0.78420  0.88895  0.05267  0.92468
21Feb13_092833|  -0.37922  0.40907 -0.89761  0.70309]
21Feb13_092833| [ 0.23497  0.83372  0.42807  0.56853  0.54153  0.17151 -0.62377  0.18507
21Feb13_092833|  -0.10411  0.43054  0.67748  0.67758]
21Feb13_092833| [-0.28291  0.67700 -0.98110 -0.29177  0.72729  0.68055 -0.72082  0.09379
21Feb13_092833|   0.96378  0.01188  0.59201  0.76149]
21Feb13_092833| [-0.96321  0.66574  0.54272  0.71254 -0.23570 -0.36536  0.12429  0.62568
21Feb13_092833|  -0.86305  0.27439 -0.72802 -0.24864]
21Feb13_092833| [ 0.25755  0.85144  0.89615  0.36624  0.74994 -0.25647  0.71113 -0.03721
21Feb13_092833|   0.82653  0.37424  0.83053 -0.82677]
21Feb13_092833| [-0.97377  0.78579  0.75967 -0.55092  0.00956  0.04794 -0.65977 -0.97425
21Feb13_092833|   0.96404  0.93558 -0.52538 -0.09205]
21Feb13_092833| [-0.49035  0.28430 -0.55656  0.72426 -0.25637  0.49226 -0.63246  0.93147
21Feb13_092833|  -0.70175  0.24880 -0.85245  0.52518]
21Feb13_092833| [ 0.14856  0.83873  0.91845 -0.63496  0.64931 -0.50770  0.64919 -0.25568
21Feb13_092833|   0.35826 -0.96666  0.00619 -0.18926]
21Feb13_092833| [-0.82902 -0.36322 -0.53492 -0.38547  0.05838  0.84041  0.33463  0.61662
21Feb13_092833|   0.94323  0.95252 -0.95489  0.85206]
21Feb13_092833| [-0.23396  0.06864 -0.59064  0.89709 -0.72366 -0.90802  0.45986  0.53240
21Feb13_092833|  -0.28547 -0.19042  0.64039  0.22830]
21Feb13_092833| [-0.23733  0.69326 -0.74659 -0.32152  0.78239 -0.47993  0.13189 -0.07797
21Feb13_092833|   0.37458  0.71434 -0.06358 -0.49027]
21Feb13_092833| [-0.21645 -0.79396  0.64866  0.23994 -0.60308 -0.64577  0.00575  0.21900
21Feb13_092833|   0.27866 -0.71745  0.57862  0.71158]
21Feb13_092833| [-0.69314 -0.97062  0.69243 -0.56022 -0.09135  0.42521 -0.21484  0.52052
21Feb13_092833|  -0.98040  0.58351  0.94285  0.23907]
21Feb13_092833| [ 0.71315 -0.76245  0.73926 -0.36028  0.14879 -0.28182  0.70512  0.16512
21Feb13_092833|  -0.26497 -0.62287 -0.56888  0.27728]
21Feb13_092833| [-0.14341  0.32688 -0.69707  0.69129  0.06504  0.05570 -0.37368 -0.05829
21Feb13_092833|  -0.87000  0.30138  0.49973  0.47099]
21Feb13_092833| [ 0.28947  0.04095  0.22699 -0.93123 -0.42627 -0.26099 -0.17880 -0.61384
21Feb13_092833|  -0.95795 -0.96474  0.78375  0.48800]
21Feb13_092833| [-0.37158  0.77551  0.61333 -0.88781 -0.60543  0.97582 -0.39711  0.19084
21Feb13_092833|   0.55603  0.03797 -0.29924 -0.13715]
21Feb13_092833| [-0.43702 -0.62190  0.10465 -0.66108 -0.48485  0.78160  0.05362 -0.93961
21Feb13_092833|   0.91432  0.33658  0.49788 -0.84850]
21Feb13_092833| [-0.22827 -0.54119 -0.75249  0.35169  0.86876  0.57233  0.15445 -0.03650
21Feb13_092833|  -0.67703 -0.21074 -0.34815 -0.83224]
21Feb13_092833| [ 0.67886  0.23712 -0.37183 -0.72408  0.88807  0.44770 -0.57875  0.58158
21Feb13_092833|   0.91498 -0.06441 -0.40422 -0.24614]
21Feb13_092833| [ 0.51750  0.72238 -0.00673 -0.64053 -0.28162  0.45487  0.81996 -0.89515
21Feb13_092833|  -0.62003 -0.98783 -0.21311 -0.63064]
21Feb13_092833| [ 0.88583  0.67272  0.01083 -0.82272  0.42140 -0.00875 -0.76958 -0.74108
21Feb13_092833|  -0.39316 -0.60818  0.80695 -0.94411]
21Feb13_092833| [-0.12317  0.22841  0.43555  0.00737  0.08288  0.72114  0.04557 -0.41808
21Feb13_092833|  -0.17800  0.36074 -0.38920 -0.38308]
21Feb13_092833| [ 0.96319 -0.56238 -0.85366  0.42553  0.76722  0.86755  0.31466 -0.97535
21Feb13_092833|  -0.24420 -0.66968 -0.46896  0.01382]
21Feb13_092833| [-0.53134 -0.13708  0.85415 -0.59263 -0.98367 -0.61404 -0.29060 -0.67819
21Feb13_092833|   0.54436 -0.26752 -0.13594 -0.12892]
21Feb13_092833| [-0.56091  0.28911 -0.42022  0.82477 -0.14640 -0.84944  0.35816 -0.57915
21Feb13_092833|  -0.29321  0.02515  0.91416  0.19156]
21Feb13_092833| [ 0.64422  0.21984 -0.15120  0.67097 -0.67070  0.27165  0.42312  0.21395
21Feb13_092833|   0.55535 -0.82562 -0.69462  0.04223]
21Feb13_092833| [-0.37478  0.69891 -0.18261 -0.74082 -0.58298 -0.27973 -0.25535 -0.05790
21Feb13_092833|   0.28104  0.37456 -0.78458  0.98888]
21Feb13_092833| [ 0.79270 -0.20668  0.90887  0.71744 -0.86420 -0.01662 -0.89604 -0.47720
21Feb13_092833|  -0.35188  0.92008 -0.11690  0.90128]
21Feb13_092833| [ 0.88351 -0.61784 -0.81267  0.46418  0.07434  0.20029  0.35680  0.21159
21Feb13_092833|   0.28852  0.24978 -0.79977 -0.75581]
21Feb13_092833| [-0.45852 -0.90347  0.29606  0.97336  0.48387  0.27566 -0.88302  0.10429
21Feb13_092833|  -0.69749  0.08334 -0.12432  0.12389]
21Feb13_092833| [-0.65315 -0.68237 -0.54046 -0.55815  0.71787  0.42769 -0.67949  0.87854
21Feb13_092833|  -0.21407  0.32648  0.43295  0.81105]
21Feb13_092833| [ 0.86888 -0.01829 -0.65935 -0.12922 -0.49685 -0.29120  0.59147  0.05010
21Feb13_092833|   0.99542 -0.69550  0.89021 -0.07593]
21Feb13_092833| [-0.07381  0.01267  0.27307  0.26282  0.55441  0.37188 -0.69164 -0.81718
21Feb13_092833|  -0.58826 -0.69340  0.61993 -0.81237]
21Feb13_092833| [ 0.47530  0.76146 -0.75428  0.29860 -0.70760  0.47941  0.27492 -0.48234
21Feb13_092833|  -0.37542  0.57442  0.75267  0.59246]
21Feb13_092833| [ 0.76064 -0.57826  0.05341  0.87807  0.84498  0.06661  0.90881  0.31908
21Feb13_092833|  -0.21196  0.59415 -0.47988 -0.47217]
21Feb13_092833| [-0.28526 -0.87198 -0.92021 -0.60794  0.14081 -0.02440  0.37672 -0.87611
21Feb13_092833|   0.96127  0.82308 -0.28009  0.40356]
21Feb13_092833| [ 0.47211  0.76738 -0.10357 -0.69428 -0.59205  0.89460  0.26135  0.62380
21Feb13_092833|  -0.73577 -0.11552  0.56692 -0.29719]
21Feb13_092833| [-0.69816 -0.22653  0.52731 -0.85516 -0.04646  0.29010 -0.57031  0.81468
21Feb13_092833|  -0.78263  0.25604 -0.04043  0.48321]
21Feb13_092833| [ 0.61664 -0.79005  0.85570  0.99050 -0.76268 -0.15055 -0.47442  0.92101
21Feb13_092833|   0.33762 -0.47616  0.61102 -0.14568]
21Feb13_092833| [-0.98857  0.41528 -0.03773  0.12596 -0.63205 -0.54454  0.31730 -0.43739
21Feb13_092833|   0.25380 -0.39261 -0.22879 -0.30079]
21Feb13_092833| [ 0.52388 -0.43451 -0.90933  0.29969  0.06616  0.26314 -0.85982  0.84794
21Feb13_092833|  -0.16671  0.35711  0.17694 -0.96064]
21Feb13_092833| [ 0.95040 -0.29663 -0.96590  0.65854  0.39026  0.84997 -0.88826  0.26184
21Feb13_092833|   0.65504  0.17684  0.16152  0.29320]
21Feb13_092833| [ 0.33709  0.64327  0.01201  0.71039  0.75608 -0.49551 -0.27296 -0.06805
21Feb13_092833|   0.77896 -0.94024  0.08091  0.40313]
21Feb13_092833| [-0.92593  0.92289 -0.22076  0.49120  0.27038 -0.14117  0.80761 -0.51965
21Feb13_092833|  -0.10907 -0.80936 -0.08340 -0.79857]
21Feb13_092833| [ 0.27108  0.23921  0.56876 -0.60416 -0.97617 -0.82345 -0.10345  0.54576
21Feb13_092833|  -0.65979 -0.65457 -0.09434 -0.66730]
21Feb13_092833| [ 0.02155 -0.14211 -0.99671 -0.14367 -0.75401  0.02729 -0.58660  0.83371
21Feb13_092833|   0.79378 -0.94277 -0.40400 -0.04899]]
21Feb13_092833|-- Bias --
21Feb13_092833|[-0.06936  0.81912 -0.76323 -0.14845  0.82192 -0.47927  0.18733  0.18279
21Feb13_092833|  0.26160 -0.14867 -0.84828 -0.28023]
21Feb13_092833|Layer 1:
21Feb13_092833|-- Config --
21Feb13_092833|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 12], 'dtype': 'float32', 'units': 13, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092833|-- Weights --
21Feb13_092833|[[-0.57173  0.45862 -0.93055  0.27222 -0.31226  0.49269  0.89742  0.87860
21Feb13_092833|   0.49316  0.36076 -0.24065  0.45448  0.30401]
21Feb13_092833| [ 0.76531  0.02320 -0.50047 -0.99102  0.48545 -0.77912  0.56844  0.96540
21Feb13_092833|  -0.89874 -0.56777  0.48467 -0.81119 -0.81628]
21Feb13_092833| [-0.64124  0.69401  0.65246 -0.87333  0.42127  0.56195 -0.64966  0.43706
21Feb13_092833|  -0.51348  0.79681  0.30271  0.44589  0.26467]
21Feb13_092833| [ 0.01534  0.05613  0.66673 -0.55747 -0.76006  0.44190 -0.94739 -0.56112
21Feb13_092833|   0.16647 -0.75245  0.47271  0.69006 -0.75609]
21Feb13_092833| [-0.64328  0.42864  0.29471  0.98091  0.98114 -0.01799 -0.96118  0.38420
21Feb13_092833|   0.88607  0.78591 -0.34685  0.27648  0.29606]
21Feb13_092833| [-0.76313 -0.84946  0.54851 -0.95567 -0.68968 -0.57704 -0.48457 -0.90418
21Feb13_092833|  -0.87021  0.31319 -0.90413 -0.84682 -0.45598]
21Feb13_092833| [ 0.72830 -0.26779 -0.48676 -0.67729  0.70218 -0.78320 -0.05996  0.48424
21Feb13_092833|   0.13209 -0.68140 -0.31684 -0.21140  0.64393]
21Feb13_092833| [-0.08896 -0.67439 -0.91435 -0.80077 -0.21941 -0.38012  0.24216  0.22865
21Feb13_092833|   0.50473  0.01475 -0.50273 -0.88155 -0.37004]
21Feb13_092833| [-0.03534  0.29444  0.73037 -0.60714 -0.35843 -0.52162  0.30658 -0.92155
21Feb13_092833|  -0.19878 -0.10421  0.26349  0.23258  0.74541]
21Feb13_092833| [-0.21702 -0.69264 -0.92070  0.55909 -0.12296  0.30133 -0.84777  0.71586
21Feb13_092833|  -0.41361 -0.55813  0.03293  0.17605 -0.13972]
21Feb13_092833| [ 0.70693 -0.83315  0.33310  0.99375 -0.04897 -0.16629  0.70070  0.97647
21Feb13_092833|   0.44050  0.47363  0.75527 -0.22757  0.78307]
21Feb13_092833| [-0.99479 -0.93452  0.11239 -0.37449 -0.77745 -0.08740 -0.27977  0.37414
21Feb13_092833|   0.03453 -0.66167  0.86707  0.44771 -0.85046]]
21Feb13_092833|-- Bias --
21Feb13_092833|[-0.22277  0.83949 -0.70049  0.03933  0.57748  0.71452 -0.29214  0.39634
21Feb13_092833|  0.54944  0.29891 -0.87087 -0.77254 -0.41071]
21Feb13_092833|Layer 2:
21Feb13_092833|-- Config --
21Feb13_092833|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 13], 'dtype': 'float32', 'units': 12, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092833|-- Weights --
21Feb13_092833|[[-0.75345  0.82041  0.04849 -0.83599 -0.69648 -0.24535 -0.85909 -0.91052
21Feb13_092833|  -0.46901 -0.11820  0.26560  0.42036]
21Feb13_092833| [-0.18624 -0.32704  0.56431  0.55305  0.24353  0.53524  0.11738  0.78421
21Feb13_092833|   0.74729  0.23266  0.53427 -0.75229]
21Feb13_092833| [ 0.13256 -0.31279  0.71021  0.84543 -0.88442 -0.09185  0.82471 -0.90378
21Feb13_092833|  -0.43064 -0.53632  0.31068  0.87027]
21Feb13_092833| [-0.78067 -0.90836  0.45889 -0.90384 -0.69513  0.99596 -0.92463  0.77969
21Feb13_092833|  -0.91035  0.57951 -0.53052  0.96491]
21Feb13_092833| [-0.49284  0.20410 -0.02961  0.26687 -0.55357 -0.18649 -0.70445  0.48148
21Feb13_092833|  -0.68050  0.47158 -0.14382 -0.25341]
21Feb13_092833| [-0.41660 -0.28967 -0.31947  0.69810 -0.60047 -0.66932  0.51894  0.75638
21Feb13_092833|  -0.28920 -0.07668  0.74483  0.35902]
21Feb13_092833| [ 0.30943 -0.29638  0.74220 -0.85318  0.07532  0.99619 -0.96969 -0.83090
21Feb13_092833|  -0.98442  0.96339  0.50345  0.25660]
21Feb13_092833| [-0.86632  0.06937  0.95079  0.44295 -0.88993 -0.45000  0.34496  0.85712
21Feb13_092833|   0.63799 -0.39126  0.84951 -0.73572]
21Feb13_092833| [ 0.86307  0.45271  0.44937  0.82734  0.70615  0.13552 -0.75375  0.09041
21Feb13_092833|  -0.09981 -0.17969  0.47685 -0.31866]
21Feb13_092833| [-0.96734  0.58934 -0.64497  0.27275 -0.98437  0.01854 -0.74254 -0.36858
21Feb13_092833|   0.38864  0.70922 -0.77080 -0.20631]
21Feb13_092833| [ 0.75202  0.63334  0.27752 -0.36737  0.23842  0.26132 -0.66486  0.20808
21Feb13_092833|   0.68710 -0.45993 -0.07293  0.54639]
21Feb13_092833| [-0.91705 -0.64543 -0.39068  0.13141 -0.59270 -0.81381  0.45448 -0.22837
21Feb13_092833|   0.77646 -0.79930  0.84100  0.59053]
21Feb13_092833| [ 0.16885  0.46316  0.25173  0.71703 -0.33081 -0.46487  0.46158 -0.88760
21Feb13_092833|  -0.06960  0.43596  0.01917 -0.52323]]
21Feb13_092833|-- Bias --
21Feb13_092833|[ 0.19064 -0.21748 -0.13248  0.04699  0.78749 -0.15081 -0.13054 -0.40562
21Feb13_092833| -0.24176  0.41348 -0.63690 -0.70923]
21Feb13_092833|Layer 3:
21Feb13_092833|-- Config --
21Feb13_092833|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 12], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092833|-- Weights --
21Feb13_092833|[[-0.51409  0.33569]
21Feb13_092833| [ 0.07022  0.17244]
21Feb13_092833| [-0.91282  0.47924]
21Feb13_092833| [ 0.62431 -0.00280]
21Feb13_092833| [ 0.72239  0.50121]
21Feb13_092833| [ 0.19713  0.24329]
21Feb13_092833| [-0.60572 -0.15440]
21Feb13_092833| [-0.81091 -0.25537]
21Feb13_092833| [ 0.58884  0.32903]
21Feb13_092833| [-0.80206  0.49467]
21Feb13_092833| [-0.59875  0.90423]
21Feb13_092833| [ 0.14118 -0.50429]]
21Feb13_092833|-- Bias --
21Feb13_092833|[ 0.73243 -0.93830]
21Feb13_092833|Predicting the validation and test data with the Best initial individual.
21Feb13_092841| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_092841|-----------  ------------------  --------------------  ----------
21Feb13_092841|Validation         38.87                 111            0.00000
21Feb13_092841|   Test            39.01                 111            0.00000
21Feb13_092841|-------------------- Test #0 --------------------
21Feb13_092841|Best final individual weights
21Feb13_092841|Individual:
21Feb13_092841|-- Constant hidden layers --
21Feb13_092841|False
21Feb13_092841|Layer 0:
21Feb13_092841|-- Config --
21Feb13_092841|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092841|-- Weights --
21Feb13_092841|[[ 0.40357 -0.18962]
21Feb13_092841| [ 0.63389  0.34346]
21Feb13_092841| [ 1.24534 -0.28953]
21Feb13_092841| [ 0.89656 -0.43923]
21Feb13_092841| [-1.01544 -0.56646]
21Feb13_092841| [ 1.39857 -0.93239]
21Feb13_092841| [-0.11966  0.11335]
21Feb13_092841| [-0.29352  0.85045]
21Feb13_092841| [ 0.70224  0.03044]
21Feb13_092841| [-0.25394  0.94913]
21Feb13_092841| [-0.77606 -0.01962]
21Feb13_092841| [-0.36125 -0.78320]
21Feb13_092841| [-0.60322 -0.36137]
21Feb13_092841| [ 0.97385  0.39888]
21Feb13_092841| [ 1.17820 -0.15125]
21Feb13_092841| [-0.32695 -0.99534]
21Feb13_092841| [ 0.06245 -0.59356]
21Feb13_092841| [ 0.15257  0.02718]
21Feb13_092841| [-1.19350 -0.46384]
21Feb13_092841| [ 0.35488  1.40937]
21Feb13_092841| [-1.06911  0.08581]
21Feb13_092841| [-0.33940 -0.68247]
21Feb13_092841| [ 0.01362 -0.66157]
21Feb13_092841| [ 0.98519 -0.02121]
21Feb13_092841| [-0.32095  0.31924]
21Feb13_092841| [-1.66785  0.35132]
21Feb13_092841| [ 0.26267  1.06776]
21Feb13_092841| [-1.18822  0.59496]
21Feb13_092841| [ 1.86097 -0.18212]
21Feb13_092841| [ 1.21581  0.18210]
21Feb13_092841| [-0.08200 -0.64525]
21Feb13_092841| [ 0.55127 -0.44936]
21Feb13_092841| [-0.48058 -0.02206]
21Feb13_092841| [-1.09558  0.08375]
21Feb13_092841| [ 0.43473  0.15022]
21Feb13_092841| [ 1.17631  0.67575]
21Feb13_092841| [-0.03519 -1.07919]
21Feb13_092841| [-0.91616 -0.50053]
21Feb13_092841| [-1.08606 -0.12496]
21Feb13_092841| [-0.43913 -0.93208]
21Feb13_092841| [ 0.31661 -0.32007]
21Feb13_092841| [-0.26644  1.33806]
21Feb13_092841| [-0.54467  0.47762]
21Feb13_092841| [-0.87403 -0.10565]
21Feb13_092841| [-1.62112 -1.18843]
21Feb13_092841| [ 0.63555  1.34321]
21Feb13_092841| [-1.72218  1.30865]
21Feb13_092841| [ 0.91023 -0.59051]
21Feb13_092841| [ 0.64095  0.95098]
21Feb13_092841| [-0.12341 -1.04846]
21Feb13_092841| [ 0.87908  0.86480]
21Feb13_092841| [-0.68615  0.86004]
21Feb13_092841| [ 1.04177 -0.63106]
21Feb13_092841| [-0.08866 -0.96551]
21Feb13_092841| [-1.54111  0.93125]
21Feb13_092841| [ 0.68548  1.43631]
21Feb13_092841| [-0.33035 -0.38548]]
21Feb13_092841|-- Bias --
21Feb13_092841|[ 0.18556 -0.43358]
21Feb13_092841|Layer 1:
21Feb13_092841|-- Config --
21Feb13_092841|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092841|-- Weights --
21Feb13_092841|[[-0.14008 -1.09501 -0.15226]
21Feb13_092841| [ 0.52818 -0.84946 -0.22217]]
21Feb13_092841|-- Bias --
21Feb13_092841|[-0.06715 -0.34476 -0.15854]
21Feb13_092841|Layer 2:
21Feb13_092841|-- Config --
21Feb13_092841|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092841|-- Weights --
21Feb13_092841|[[-0.51620  0.17635 -0.47447 -0.57139  0.87197]
21Feb13_092841| [ 0.97581 -0.57390 -0.37481 -0.23881 -0.20901]
21Feb13_092841| [ 0.39891  0.42407  0.36421 -0.88927  0.90285]]
21Feb13_092841|-- Bias --
21Feb13_092841|[ 0.28599 -0.00186 -0.15313 -0.80765 -0.59664]
21Feb13_092841|Layer 3:
21Feb13_092841|-- Config --
21Feb13_092841|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092841|-- Weights --
21Feb13_092841|[[-0.49934 -0.31302]
21Feb13_092841| [ 0.15658 -1.30572]
21Feb13_092841| [ 0.66404  0.89534]
21Feb13_092841| [ 1.12580  1.32920]
21Feb13_092841| [-0.56371  1.06147]]
21Feb13_092841|-- Bias --
21Feb13_092841|[-0.12797  0.25323]
21Feb13_092841|Predicting the validation and test data with the Best final individual.
21Feb13_092849| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_092849|-----------  ------------------  --------------------  ----------
21Feb13_092849|Validation         28.87                  30            0.32325
21Feb13_092849|   Test            28.24                  30            0.37386
21Feb13_092849|-------------------- Test #1 --------------------
21Feb13_092849|Best final individual weights
21Feb13_092849|Individual:
21Feb13_092849|-- Constant hidden layers --
21Feb13_092849|False
21Feb13_092849|Layer 0:
21Feb13_092849|-- Config --
21Feb13_092849|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092849|-- Weights --
21Feb13_092849|[[ 0.40357 -0.18962]
21Feb13_092849| [ 0.63389  0.34346]
21Feb13_092849| [ 1.24534 -0.28953]
21Feb13_092849| [ 0.89656 -0.43923]
21Feb13_092849| [-1.01544 -0.56646]
21Feb13_092849| [ 1.39857 -0.93239]
21Feb13_092849| [-0.11966  0.11335]
21Feb13_092849| [-0.29352  0.85045]
21Feb13_092849| [ 0.70224  0.03044]
21Feb13_092849| [-0.25394  0.94913]
21Feb13_092849| [-0.77606 -0.01962]
21Feb13_092849| [-0.36125 -0.78320]
21Feb13_092849| [-0.60322 -0.36137]
21Feb13_092849| [ 0.97385  0.39888]
21Feb13_092849| [ 1.17820 -0.15125]
21Feb13_092849| [-0.32695 -0.99534]
21Feb13_092849| [ 0.06245 -0.59356]
21Feb13_092849| [ 0.15257  0.02718]
21Feb13_092849| [-1.19350 -0.46384]
21Feb13_092849| [ 0.35488  1.40937]
21Feb13_092849| [-1.06911  0.08581]
21Feb13_092849| [-0.33940 -0.68247]
21Feb13_092849| [ 0.01362 -0.66157]
21Feb13_092849| [ 0.98519 -0.02121]
21Feb13_092849| [-0.32095  0.31924]
21Feb13_092849| [-1.66785  0.35132]
21Feb13_092849| [ 0.26267  1.06776]
21Feb13_092849| [-1.18822  0.59496]
21Feb13_092849| [ 1.86097 -0.18212]
21Feb13_092849| [ 1.21581  0.18210]
21Feb13_092849| [-0.08200 -0.64525]
21Feb13_092849| [ 0.55127 -0.44936]
21Feb13_092849| [-0.48058 -0.02206]
21Feb13_092849| [-1.09558  0.08375]
21Feb13_092849| [ 0.43473  0.15022]
21Feb13_092849| [ 1.17631  0.67575]
21Feb13_092849| [-0.03519 -1.07919]
21Feb13_092849| [-0.91616 -0.50053]
21Feb13_092849| [-1.08606 -0.12496]
21Feb13_092849| [-0.43913 -0.93208]
21Feb13_092849| [ 0.31661 -0.32007]
21Feb13_092849| [-0.26644  1.33806]
21Feb13_092849| [-0.54467  0.47762]
21Feb13_092849| [-0.87403 -0.10565]
21Feb13_092849| [-1.62112 -1.18843]
21Feb13_092849| [ 0.63555  1.34321]
21Feb13_092849| [-1.72218  1.30865]
21Feb13_092849| [ 0.91023 -0.59051]
21Feb13_092849| [ 0.64095  0.95098]
21Feb13_092849| [-0.12341 -1.04846]
21Feb13_092849| [ 0.87908  0.86480]
21Feb13_092849| [-0.68615  0.86004]
21Feb13_092849| [ 1.04177 -0.63106]
21Feb13_092849| [-0.08866 -0.96551]
21Feb13_092849| [-1.54111  0.93125]
21Feb13_092849| [ 0.68548  1.43631]
21Feb13_092849| [-0.33035 -0.38548]]
21Feb13_092849|-- Bias --
21Feb13_092849|[ 0.18556 -0.43358]
21Feb13_092849|Layer 1:
21Feb13_092849|-- Config --
21Feb13_092849|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092849|-- Weights --
21Feb13_092849|[[-0.14008 -1.09501 -0.15226]
21Feb13_092849| [ 0.52818 -0.84946 -0.22217]]
21Feb13_092849|-- Bias --
21Feb13_092849|[-0.06715 -0.34476 -0.15854]
21Feb13_092849|Layer 2:
21Feb13_092849|-- Config --
21Feb13_092849|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092849|-- Weights --
21Feb13_092849|[[-0.51620  0.17635 -0.47447 -0.57139  0.87197]
21Feb13_092849| [ 0.97581 -0.57390 -0.37481 -0.23881 -0.20901]
21Feb13_092849| [ 0.39891  0.42407  0.36421 -0.88927  0.90285]]
21Feb13_092849|-- Bias --
21Feb13_092849|[ 0.28599 -0.00186 -0.15313 -0.80765 -0.59664]
21Feb13_092849|Layer 3:
21Feb13_092849|-- Config --
21Feb13_092849|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092849|-- Weights --
21Feb13_092849|[[-0.49934 -0.31302]
21Feb13_092849| [ 0.15658 -1.30572]
21Feb13_092849| [ 0.66404  0.89534]
21Feb13_092849| [ 1.12580  1.32920]
21Feb13_092849| [-0.56371  1.06147]]
21Feb13_092849|-- Bias --
21Feb13_092849|[-0.12797  0.25323]
21Feb13_092849|Predicting the validation and test data with the Best final individual.
21Feb13_092856| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_092856|-----------  ------------------  --------------------  ----------
21Feb13_092856|Validation         31.22                  30            0.25172
21Feb13_092856|   Test            27.37                  30            0.41834
21Feb13_092856|-------------------- Test #2 --------------------
21Feb13_092856|Best final individual weights
21Feb13_092856|Individual:
21Feb13_092856|-- Constant hidden layers --
21Feb13_092856|False
21Feb13_092856|Layer 0:
21Feb13_092856|-- Config --
21Feb13_092856|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092856|-- Weights --
21Feb13_092856|[[ 0.40357 -0.18962]
21Feb13_092856| [ 0.63389  0.34346]
21Feb13_092856| [ 1.24534 -0.28953]
21Feb13_092856| [ 0.89656 -0.43923]
21Feb13_092856| [-1.01544 -0.56646]
21Feb13_092856| [ 1.39857 -0.93239]
21Feb13_092856| [-0.11966  0.11335]
21Feb13_092856| [-0.29352  0.85045]
21Feb13_092856| [ 0.70224  0.03044]
21Feb13_092856| [-0.25394  0.94913]
21Feb13_092856| [-0.77606 -0.01962]
21Feb13_092856| [-0.36125 -0.78320]
21Feb13_092856| [-0.60322 -0.36137]
21Feb13_092856| [ 0.97385  0.39888]
21Feb13_092856| [ 1.17820 -0.15125]
21Feb13_092856| [-0.32695 -0.99534]
21Feb13_092856| [ 0.06245 -0.59356]
21Feb13_092856| [ 0.15257  0.02718]
21Feb13_092856| [-1.19350 -0.46384]
21Feb13_092856| [ 0.35488  1.40937]
21Feb13_092856| [-1.06911  0.08581]
21Feb13_092856| [-0.33940 -0.68247]
21Feb13_092856| [ 0.01362 -0.66157]
21Feb13_092856| [ 0.98519 -0.02121]
21Feb13_092856| [-0.32095  0.31924]
21Feb13_092856| [-1.66785  0.35132]
21Feb13_092856| [ 0.26267  1.06776]
21Feb13_092856| [-1.18822  0.59496]
21Feb13_092856| [ 1.86097 -0.18212]
21Feb13_092856| [ 1.21581  0.18210]
21Feb13_092856| [-0.08200 -0.64525]
21Feb13_092856| [ 0.55127 -0.44936]
21Feb13_092856| [-0.48058 -0.02206]
21Feb13_092856| [-1.09558  0.08375]
21Feb13_092856| [ 0.43473  0.15022]
21Feb13_092856| [ 1.17631  0.67575]
21Feb13_092856| [-0.03519 -1.07919]
21Feb13_092856| [-0.91616 -0.50053]
21Feb13_092856| [-1.08606 -0.12496]
21Feb13_092856| [-0.43913 -0.93208]
21Feb13_092856| [ 0.31661 -0.32007]
21Feb13_092856| [-0.26644  1.33806]
21Feb13_092856| [-0.54467  0.47762]
21Feb13_092856| [-0.87403 -0.10565]
21Feb13_092856| [-1.62112 -1.18843]
21Feb13_092856| [ 0.63555  1.34321]
21Feb13_092856| [-1.72218  1.30865]
21Feb13_092856| [ 0.91023 -0.59051]
21Feb13_092856| [ 0.64095  0.95098]
21Feb13_092856| [-0.12341 -1.04846]
21Feb13_092856| [ 0.87908  0.86480]
21Feb13_092856| [-0.68615  0.86004]
21Feb13_092856| [ 1.04177 -0.63106]
21Feb13_092856| [-0.08866 -0.96551]
21Feb13_092856| [-1.54111  0.93125]
21Feb13_092856| [ 0.68548  1.43631]
21Feb13_092856| [-0.33035 -0.38548]]
21Feb13_092856|-- Bias --
21Feb13_092856|[ 0.18556 -0.43358]
21Feb13_092856|Layer 1:
21Feb13_092856|-- Config --
21Feb13_092856|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092856|-- Weights --
21Feb13_092856|[[-0.14008 -1.09501 -0.15226]
21Feb13_092856| [ 0.52818 -0.84946 -0.22217]]
21Feb13_092856|-- Bias --
21Feb13_092856|[-0.06715 -0.34476 -0.15854]
21Feb13_092856|Layer 2:
21Feb13_092856|-- Config --
21Feb13_092856|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092856|-- Weights --
21Feb13_092856|[[-0.51620  0.17635 -0.47447 -0.57139  0.87197]
21Feb13_092856| [ 0.97581 -0.57390 -0.37481 -0.23881 -0.20901]
21Feb13_092856| [ 0.39891  0.42407  0.36421 -0.88927  0.90285]]
21Feb13_092856|-- Bias --
21Feb13_092856|[ 0.28599 -0.00186 -0.15313 -0.80765 -0.59664]
21Feb13_092856|Layer 3:
21Feb13_092856|-- Config --
21Feb13_092856|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092856|-- Weights --
21Feb13_092856|[[-0.49934 -0.31302]
21Feb13_092856| [ 0.15658 -1.30572]
21Feb13_092856| [ 0.66404  0.89534]
21Feb13_092856| [ 1.12580  1.32920]
21Feb13_092856| [-0.56371  1.06147]]
21Feb13_092856|-- Bias --
21Feb13_092856|[-0.12797  0.25323]
21Feb13_092856|Predicting the validation and test data with the Best final individual.
21Feb13_092904| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_092904|-----------  ------------------  --------------------  ----------
21Feb13_092904|Validation         28.43                  30            0.37084
21Feb13_092904|   Test            28.58                  30            0.36442
21Feb13_092904|-------------------- Test #3 --------------------
21Feb13_092904|Best final individual weights
21Feb13_092904|Individual:
21Feb13_092904|-- Constant hidden layers --
21Feb13_092904|False
21Feb13_092904|Layer 0:
21Feb13_092904|-- Config --
21Feb13_092904|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092904|-- Weights --
21Feb13_092904|[[ 0.40357 -0.18962]
21Feb13_092904| [ 0.63389  0.34346]
21Feb13_092904| [ 1.24534 -0.28953]
21Feb13_092904| [ 0.89656 -0.43923]
21Feb13_092904| [-1.01544 -0.56646]
21Feb13_092904| [ 1.39857 -0.93239]
21Feb13_092904| [-0.11966  0.11335]
21Feb13_092904| [-0.29352  0.85045]
21Feb13_092904| [ 0.70224  0.03044]
21Feb13_092904| [-0.25394  0.94913]
21Feb13_092904| [-0.77606 -0.01962]
21Feb13_092904| [-0.36125 -0.78320]
21Feb13_092904| [-0.60322 -0.36137]
21Feb13_092904| [ 0.97385  0.39888]
21Feb13_092904| [ 1.17820 -0.15125]
21Feb13_092904| [-0.32695 -0.99534]
21Feb13_092904| [ 0.06245 -0.59356]
21Feb13_092904| [ 0.15257  0.02718]
21Feb13_092904| [-1.19350 -0.46384]
21Feb13_092904| [ 0.35488  1.40937]
21Feb13_092904| [-1.06911  0.08581]
21Feb13_092904| [-0.33940 -0.68247]
21Feb13_092904| [ 0.01362 -0.66157]
21Feb13_092904| [ 0.98519 -0.02121]
21Feb13_092904| [-0.32095  0.31924]
21Feb13_092904| [-1.66785  0.35132]
21Feb13_092904| [ 0.26267  1.06776]
21Feb13_092904| [-1.18822  0.59496]
21Feb13_092904| [ 1.86097 -0.18212]
21Feb13_092904| [ 1.21581  0.18210]
21Feb13_092904| [-0.08200 -0.64525]
21Feb13_092904| [ 0.55127 -0.44936]
21Feb13_092904| [-0.48058 -0.02206]
21Feb13_092904| [-1.09558  0.08375]
21Feb13_092904| [ 0.43473  0.15022]
21Feb13_092904| [ 1.17631  0.67575]
21Feb13_092904| [-0.03519 -1.07919]
21Feb13_092904| [-0.91616 -0.50053]
21Feb13_092904| [-1.08606 -0.12496]
21Feb13_092904| [-0.43913 -0.93208]
21Feb13_092904| [ 0.31661 -0.32007]
21Feb13_092904| [-0.26644  1.33806]
21Feb13_092904| [-0.54467  0.47762]
21Feb13_092904| [-0.87403 -0.10565]
21Feb13_092904| [-1.62112 -1.18843]
21Feb13_092904| [ 0.63555  1.34321]
21Feb13_092904| [-1.72218  1.30865]
21Feb13_092904| [ 0.91023 -0.59051]
21Feb13_092904| [ 0.64095  0.95098]
21Feb13_092904| [-0.12341 -1.04846]
21Feb13_092904| [ 0.87908  0.86480]
21Feb13_092904| [-0.68615  0.86004]
21Feb13_092904| [ 1.04177 -0.63106]
21Feb13_092904| [-0.08866 -0.96551]
21Feb13_092904| [-1.54111  0.93125]
21Feb13_092904| [ 0.68548  1.43631]
21Feb13_092904| [-0.33035 -0.38548]]
21Feb13_092904|-- Bias --
21Feb13_092904|[ 0.18556 -0.43358]
21Feb13_092904|Layer 1:
21Feb13_092904|-- Config --
21Feb13_092904|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092904|-- Weights --
21Feb13_092904|[[-0.14008 -1.09501 -0.15226]
21Feb13_092904| [ 0.52818 -0.84946 -0.22217]]
21Feb13_092904|-- Bias --
21Feb13_092904|[-0.06715 -0.34476 -0.15854]
21Feb13_092904|Layer 2:
21Feb13_092904|-- Config --
21Feb13_092904|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092904|-- Weights --
21Feb13_092904|[[-0.51620  0.17635 -0.47447 -0.57139  0.87197]
21Feb13_092904| [ 0.97581 -0.57390 -0.37481 -0.23881 -0.20901]
21Feb13_092904| [ 0.39891  0.42407  0.36421 -0.88927  0.90285]]
21Feb13_092904|-- Bias --
21Feb13_092904|[ 0.28599 -0.00186 -0.15313 -0.80765 -0.59664]
21Feb13_092904|Layer 3:
21Feb13_092904|-- Config --
21Feb13_092904|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092904|-- Weights --
21Feb13_092904|[[-0.49934 -0.31302]
21Feb13_092904| [ 0.15658 -1.30572]
21Feb13_092904| [ 0.66404  0.89534]
21Feb13_092904| [ 1.12580  1.32920]
21Feb13_092904| [-0.56371  1.06147]]
21Feb13_092904|-- Bias --
21Feb13_092904|[-0.12797  0.25323]
21Feb13_092904|Predicting the validation and test data with the Best final individual.
21Feb13_092912| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_092912|-----------  ------------------  --------------------  ----------
21Feb13_092912|Validation         25.13                  30            0.52068
21Feb13_092912|   Test            39.01                  30            0.00000
21Feb13_092912|-------------------- Test #4 --------------------
21Feb13_092912|Best final individual weights
21Feb13_092912|Individual:
21Feb13_092912|-- Constant hidden layers --
21Feb13_092912|False
21Feb13_092912|Layer 0:
21Feb13_092912|-- Config --
21Feb13_092912|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092912|-- Weights --
21Feb13_092912|[[ 0.40357 -0.18962]
21Feb13_092912| [ 0.63389  0.34346]
21Feb13_092912| [ 1.24534 -0.28953]
21Feb13_092912| [ 0.89656 -0.43923]
21Feb13_092912| [-1.01544 -0.56646]
21Feb13_092912| [ 1.39857 -0.93239]
21Feb13_092912| [-0.11966  0.11335]
21Feb13_092912| [-0.29352  0.85045]
21Feb13_092912| [ 0.70224  0.03044]
21Feb13_092912| [-0.25394  0.94913]
21Feb13_092912| [-0.77606 -0.01962]
21Feb13_092912| [-0.36125 -0.78320]
21Feb13_092912| [-0.60322 -0.36137]
21Feb13_092912| [ 0.97385  0.39888]
21Feb13_092912| [ 1.17820 -0.15125]
21Feb13_092912| [-0.32695 -0.99534]
21Feb13_092912| [ 0.06245 -0.59356]
21Feb13_092912| [ 0.15257  0.02718]
21Feb13_092912| [-1.19350 -0.46384]
21Feb13_092912| [ 0.35488  1.40937]
21Feb13_092912| [-1.06911  0.08581]
21Feb13_092912| [-0.33940 -0.68247]
21Feb13_092912| [ 0.01362 -0.66157]
21Feb13_092912| [ 0.98519 -0.02121]
21Feb13_092912| [-0.32095  0.31924]
21Feb13_092912| [-1.66785  0.35132]
21Feb13_092912| [ 0.26267  1.06776]
21Feb13_092912| [-1.18822  0.59496]
21Feb13_092912| [ 1.86097 -0.18212]
21Feb13_092912| [ 1.21581  0.18210]
21Feb13_092912| [-0.08200 -0.64525]
21Feb13_092912| [ 0.55127 -0.44936]
21Feb13_092912| [-0.48058 -0.02206]
21Feb13_092912| [-1.09558  0.08375]
21Feb13_092912| [ 0.43473  0.15022]
21Feb13_092912| [ 1.17631  0.67575]
21Feb13_092912| [-0.03519 -1.07919]
21Feb13_092912| [-0.91616 -0.50053]
21Feb13_092912| [-1.08606 -0.12496]
21Feb13_092912| [-0.43913 -0.93208]
21Feb13_092912| [ 0.31661 -0.32007]
21Feb13_092912| [-0.26644  1.33806]
21Feb13_092912| [-0.54467  0.47762]
21Feb13_092912| [-0.87403 -0.10565]
21Feb13_092912| [-1.62112 -1.18843]
21Feb13_092912| [ 0.63555  1.34321]
21Feb13_092912| [-1.72218  1.30865]
21Feb13_092912| [ 0.91023 -0.59051]
21Feb13_092912| [ 0.64095  0.95098]
21Feb13_092912| [-0.12341 -1.04846]
21Feb13_092912| [ 0.87908  0.86480]
21Feb13_092912| [-0.68615  0.86004]
21Feb13_092912| [ 1.04177 -0.63106]
21Feb13_092912| [-0.08866 -0.96551]
21Feb13_092912| [-1.54111  0.93125]
21Feb13_092912| [ 0.68548  1.43631]
21Feb13_092912| [-0.33035 -0.38548]]
21Feb13_092912|-- Bias --
21Feb13_092912|[ 0.18556 -0.43358]
21Feb13_092912|Layer 1:
21Feb13_092912|-- Config --
21Feb13_092912|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092912|-- Weights --
21Feb13_092912|[[-0.14008 -1.09501 -0.15226]
21Feb13_092912| [ 0.52818 -0.84946 -0.22217]]
21Feb13_092912|-- Bias --
21Feb13_092912|[-0.06715 -0.34476 -0.15854]
21Feb13_092912|Layer 2:
21Feb13_092912|-- Config --
21Feb13_092912|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092912|-- Weights --
21Feb13_092912|[[-0.51620  0.17635 -0.47447 -0.57139  0.87197]
21Feb13_092912| [ 0.97581 -0.57390 -0.37481 -0.23881 -0.20901]
21Feb13_092912| [ 0.39891  0.42407  0.36421 -0.88927  0.90285]]
21Feb13_092912|-- Bias --
21Feb13_092912|[ 0.28599 -0.00186 -0.15313 -0.80765 -0.59664]
21Feb13_092912|Layer 3:
21Feb13_092912|-- Config --
21Feb13_092912|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092912|-- Weights --
21Feb13_092912|[[-0.49934 -0.31302]
21Feb13_092912| [ 0.15658 -1.30572]
21Feb13_092912| [ 0.66404  0.89534]
21Feb13_092912| [ 1.12580  1.32920]
21Feb13_092912| [-0.56371  1.06147]]
21Feb13_092912|-- Bias --
21Feb13_092912|[-0.12797  0.25323]
21Feb13_092912|Predicting the validation and test data with the Best final individual.
21Feb13_092919| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_092919|-----------  ------------------  --------------------  ----------
21Feb13_092919|Validation         38.78                  30            0.00000
21Feb13_092919|   Test            25.80                  30            0.52214
21Feb13_092919|-------------------- Test #5 --------------------
21Feb13_092919|Best final individual weights
21Feb13_092919|Individual:
21Feb13_092919|-- Constant hidden layers --
21Feb13_092919|False
21Feb13_092919|Layer 0:
21Feb13_092919|-- Config --
21Feb13_092919|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092919|-- Weights --
21Feb13_092919|[[ 0.40357 -0.18962]
21Feb13_092919| [ 0.63389  0.34346]
21Feb13_092919| [ 1.24534 -0.28953]
21Feb13_092919| [ 0.89656 -0.43923]
21Feb13_092919| [-1.01544 -0.56646]
21Feb13_092919| [ 1.39857 -0.93239]
21Feb13_092919| [-0.11966  0.11335]
21Feb13_092919| [-0.29352  0.85045]
21Feb13_092919| [ 0.70224  0.03044]
21Feb13_092919| [-0.25394  0.94913]
21Feb13_092919| [-0.77606 -0.01962]
21Feb13_092919| [-0.36125 -0.78320]
21Feb13_092919| [-0.60322 -0.36137]
21Feb13_092919| [ 0.97385  0.39888]
21Feb13_092919| [ 1.17820 -0.15125]
21Feb13_092919| [-0.32695 -0.99534]
21Feb13_092919| [ 0.06245 -0.59356]
21Feb13_092919| [ 0.15257  0.02718]
21Feb13_092919| [-1.19350 -0.46384]
21Feb13_092919| [ 0.35488  1.40937]
21Feb13_092919| [-1.06911  0.08581]
21Feb13_092919| [-0.33940 -0.68247]
21Feb13_092919| [ 0.01362 -0.66157]
21Feb13_092919| [ 0.98519 -0.02121]
21Feb13_092919| [-0.32095  0.31924]
21Feb13_092919| [-1.66785  0.35132]
21Feb13_092919| [ 0.26267  1.06776]
21Feb13_092919| [-1.18822  0.59496]
21Feb13_092919| [ 1.86097 -0.18212]
21Feb13_092919| [ 1.21581  0.18210]
21Feb13_092919| [-0.08200 -0.64525]
21Feb13_092919| [ 0.55127 -0.44936]
21Feb13_092919| [-0.48058 -0.02206]
21Feb13_092919| [-1.09558  0.08375]
21Feb13_092919| [ 0.43473  0.15022]
21Feb13_092919| [ 1.17631  0.67575]
21Feb13_092919| [-0.03519 -1.07919]
21Feb13_092919| [-0.91616 -0.50053]
21Feb13_092919| [-1.08606 -0.12496]
21Feb13_092919| [-0.43913 -0.93208]
21Feb13_092919| [ 0.31661 -0.32007]
21Feb13_092919| [-0.26644  1.33806]
21Feb13_092919| [-0.54467  0.47762]
21Feb13_092919| [-0.87403 -0.10565]
21Feb13_092919| [-1.62112 -1.18843]
21Feb13_092919| [ 0.63555  1.34321]
21Feb13_092919| [-1.72218  1.30865]
21Feb13_092919| [ 0.91023 -0.59051]
21Feb13_092919| [ 0.64095  0.95098]
21Feb13_092919| [-0.12341 -1.04846]
21Feb13_092919| [ 0.87908  0.86480]
21Feb13_092919| [-0.68615  0.86004]
21Feb13_092919| [ 1.04177 -0.63106]
21Feb13_092919| [-0.08866 -0.96551]
21Feb13_092919| [-1.54111  0.93125]
21Feb13_092919| [ 0.68548  1.43631]
21Feb13_092919| [-0.33035 -0.38548]]
21Feb13_092919|-- Bias --
21Feb13_092919|[ 0.18556 -0.43358]
21Feb13_092919|Layer 1:
21Feb13_092919|-- Config --
21Feb13_092919|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092919|-- Weights --
21Feb13_092919|[[-0.14008 -1.09501 -0.15226]
21Feb13_092919| [ 0.52818 -0.84946 -0.22217]]
21Feb13_092919|-- Bias --
21Feb13_092919|[-0.06715 -0.34476 -0.15854]
21Feb13_092919|Layer 2:
21Feb13_092919|-- Config --
21Feb13_092919|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092919|-- Weights --
21Feb13_092919|[[-0.51620  0.17635 -0.47447 -0.57139  0.87197]
21Feb13_092919| [ 0.97581 -0.57390 -0.37481 -0.23881 -0.20901]
21Feb13_092919| [ 0.39891  0.42407  0.36421 -0.88927  0.90285]]
21Feb13_092919|-- Bias --
21Feb13_092919|[ 0.28599 -0.00186 -0.15313 -0.80765 -0.59664]
21Feb13_092919|Layer 3:
21Feb13_092919|-- Config --
21Feb13_092919|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092919|-- Weights --
21Feb13_092919|[[-0.49934 -0.31302]
21Feb13_092919| [ 0.15658 -1.30572]
21Feb13_092919| [ 0.66404  0.89534]
21Feb13_092919| [ 1.12580  1.32920]
21Feb13_092919| [-0.56371  1.06147]]
21Feb13_092919|-- Bias --
21Feb13_092919|[-0.12797  0.25323]
21Feb13_092919|Predicting the validation and test data with the Best final individual.
21Feb13_092927| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_092927|-----------  ------------------  --------------------  ----------
21Feb13_092927|Validation         27.39                  30            0.40547
21Feb13_092927|   Test            27.02                  30            0.57746
21Feb13_092927|-------------------- Test #6 --------------------
21Feb13_092927|Best final individual weights
21Feb13_092927|Individual:
21Feb13_092927|-- Constant hidden layers --
21Feb13_092927|False
21Feb13_092927|Layer 0:
21Feb13_092927|-- Config --
21Feb13_092927|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092927|-- Weights --
21Feb13_092927|[[ 0.40357 -0.18962]
21Feb13_092927| [ 0.63389  0.34346]
21Feb13_092927| [ 1.24534 -0.28953]
21Feb13_092927| [ 0.89656 -0.43923]
21Feb13_092927| [-1.01544 -0.56646]
21Feb13_092927| [ 1.39857 -0.93239]
21Feb13_092927| [-0.11966  0.11335]
21Feb13_092927| [-0.29352  0.85045]
21Feb13_092927| [ 0.70224  0.03044]
21Feb13_092927| [-0.25394  0.94913]
21Feb13_092927| [-0.77606 -0.01962]
21Feb13_092927| [-0.36125 -0.78320]
21Feb13_092927| [-0.60322 -0.36137]
21Feb13_092927| [ 0.97385  0.39888]
21Feb13_092927| [ 1.17820 -0.15125]
21Feb13_092927| [-0.32695 -0.99534]
21Feb13_092927| [ 0.06245 -0.59356]
21Feb13_092927| [ 0.15257  0.02718]
21Feb13_092927| [-1.19350 -0.46384]
21Feb13_092927| [ 0.35488  1.40937]
21Feb13_092927| [-1.06911  0.08581]
21Feb13_092927| [-0.33940 -0.68247]
21Feb13_092927| [ 0.01362 -0.66157]
21Feb13_092927| [ 0.98519 -0.02121]
21Feb13_092927| [-0.32095  0.31924]
21Feb13_092927| [-1.66785  0.35132]
21Feb13_092927| [ 0.26267  1.06776]
21Feb13_092927| [-1.18822  0.59496]
21Feb13_092927| [ 1.86097 -0.18212]
21Feb13_092927| [ 1.21581  0.18210]
21Feb13_092927| [-0.08200 -0.64525]
21Feb13_092927| [ 0.55127 -0.44936]
21Feb13_092927| [-0.48058 -0.02206]
21Feb13_092927| [-1.09558  0.08375]
21Feb13_092927| [ 0.43473  0.15022]
21Feb13_092927| [ 1.17631  0.67575]
21Feb13_092927| [-0.03519 -1.07919]
21Feb13_092927| [-0.91616 -0.50053]
21Feb13_092927| [-1.08606 -0.12496]
21Feb13_092927| [-0.43913 -0.93208]
21Feb13_092927| [ 0.31661 -0.32007]
21Feb13_092927| [-0.26644  1.33806]
21Feb13_092927| [-0.54467  0.47762]
21Feb13_092927| [-0.87403 -0.10565]
21Feb13_092927| [-1.62112 -1.18843]
21Feb13_092927| [ 0.63555  1.34321]
21Feb13_092927| [-1.72218  1.30865]
21Feb13_092927| [ 0.91023 -0.59051]
21Feb13_092927| [ 0.64095  0.95098]
21Feb13_092927| [-0.12341 -1.04846]
21Feb13_092927| [ 0.87908  0.86480]
21Feb13_092927| [-0.68615  0.86004]
21Feb13_092927| [ 1.04177 -0.63106]
21Feb13_092927| [-0.08866 -0.96551]
21Feb13_092927| [-1.54111  0.93125]
21Feb13_092927| [ 0.68548  1.43631]
21Feb13_092927| [-0.33035 -0.38548]]
21Feb13_092927|-- Bias --
21Feb13_092927|[ 0.18556 -0.43358]
21Feb13_092927|Layer 1:
21Feb13_092927|-- Config --
21Feb13_092927|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092927|-- Weights --
21Feb13_092927|[[-0.14008 -1.09501 -0.15226]
21Feb13_092927| [ 0.52818 -0.84946 -0.22217]]
21Feb13_092927|-- Bias --
21Feb13_092927|[-0.06715 -0.34476 -0.15854]
21Feb13_092927|Layer 2:
21Feb13_092927|-- Config --
21Feb13_092927|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092927|-- Weights --
21Feb13_092927|[[-0.51620  0.17635 -0.47447 -0.57139  0.87197]
21Feb13_092927| [ 0.97581 -0.57390 -0.37481 -0.23881 -0.20901]
21Feb13_092927| [ 0.39891  0.42407  0.36421 -0.88927  0.90285]]
21Feb13_092927|-- Bias --
21Feb13_092927|[ 0.28599 -0.00186 -0.15313 -0.80765 -0.59664]
21Feb13_092927|Layer 3:
21Feb13_092927|-- Config --
21Feb13_092927|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092927|-- Weights --
21Feb13_092927|[[-0.49934 -0.31302]
21Feb13_092927| [ 0.15658 -1.30572]
21Feb13_092927| [ 0.66404  0.89534]
21Feb13_092927| [ 1.12580  1.32920]
21Feb13_092927| [-0.56371  1.06147]]
21Feb13_092927|-- Bias --
21Feb13_092927|[-0.12797  0.25323]
21Feb13_092927|Predicting the validation and test data with the Best final individual.
21Feb13_092934| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_092934|-----------  ------------------  --------------------  ----------
21Feb13_092934|Validation         29.74                  30            0.31931
21Feb13_092934|   Test            25.89                  30            0.49488
21Feb13_092934|-------------------- Test #7 --------------------
21Feb13_092934|Best final individual weights
21Feb13_092934|Individual:
21Feb13_092934|-- Constant hidden layers --
21Feb13_092934|False
21Feb13_092934|Layer 0:
21Feb13_092934|-- Config --
21Feb13_092934|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092934|-- Weights --
21Feb13_092934|[[ 0.40357 -0.18962]
21Feb13_092934| [ 0.63389  0.34346]
21Feb13_092934| [ 1.24534 -0.28953]
21Feb13_092934| [ 0.89656 -0.43923]
21Feb13_092934| [-1.01544 -0.56646]
21Feb13_092934| [ 1.39857 -0.93239]
21Feb13_092934| [-0.11966  0.11335]
21Feb13_092934| [-0.29352  0.85045]
21Feb13_092934| [ 0.70224  0.03044]
21Feb13_092934| [-0.25394  0.94913]
21Feb13_092934| [-0.77606 -0.01962]
21Feb13_092934| [-0.36125 -0.78320]
21Feb13_092934| [-0.60322 -0.36137]
21Feb13_092934| [ 0.97385  0.39888]
21Feb13_092934| [ 1.17820 -0.15125]
21Feb13_092934| [-0.32695 -0.99534]
21Feb13_092934| [ 0.06245 -0.59356]
21Feb13_092934| [ 0.15257  0.02718]
21Feb13_092934| [-1.19350 -0.46384]
21Feb13_092934| [ 0.35488  1.40937]
21Feb13_092934| [-1.06911  0.08581]
21Feb13_092934| [-0.33940 -0.68247]
21Feb13_092934| [ 0.01362 -0.66157]
21Feb13_092934| [ 0.98519 -0.02121]
21Feb13_092934| [-0.32095  0.31924]
21Feb13_092934| [-1.66785  0.35132]
21Feb13_092934| [ 0.26267  1.06776]
21Feb13_092934| [-1.18822  0.59496]
21Feb13_092934| [ 1.86097 -0.18212]
21Feb13_092934| [ 1.21581  0.18210]
21Feb13_092934| [-0.08200 -0.64525]
21Feb13_092934| [ 0.55127 -0.44936]
21Feb13_092934| [-0.48058 -0.02206]
21Feb13_092934| [-1.09558  0.08375]
21Feb13_092934| [ 0.43473  0.15022]
21Feb13_092934| [ 1.17631  0.67575]
21Feb13_092934| [-0.03519 -1.07919]
21Feb13_092934| [-0.91616 -0.50053]
21Feb13_092934| [-1.08606 -0.12496]
21Feb13_092934| [-0.43913 -0.93208]
21Feb13_092934| [ 0.31661 -0.32007]
21Feb13_092934| [-0.26644  1.33806]
21Feb13_092934| [-0.54467  0.47762]
21Feb13_092934| [-0.87403 -0.10565]
21Feb13_092934| [-1.62112 -1.18843]
21Feb13_092934| [ 0.63555  1.34321]
21Feb13_092934| [-1.72218  1.30865]
21Feb13_092934| [ 0.91023 -0.59051]
21Feb13_092934| [ 0.64095  0.95098]
21Feb13_092934| [-0.12341 -1.04846]
21Feb13_092934| [ 0.87908  0.86480]
21Feb13_092934| [-0.68615  0.86004]
21Feb13_092934| [ 1.04177 -0.63106]
21Feb13_092934| [-0.08866 -0.96551]
21Feb13_092934| [-1.54111  0.93125]
21Feb13_092934| [ 0.68548  1.43631]
21Feb13_092934| [-0.33035 -0.38548]]
21Feb13_092934|-- Bias --
21Feb13_092934|[ 0.18556 -0.43358]
21Feb13_092934|Layer 1:
21Feb13_092934|-- Config --
21Feb13_092934|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092934|-- Weights --
21Feb13_092934|[[-0.14008 -1.09501 -0.15226]
21Feb13_092934| [ 0.52818 -0.84946 -0.22217]]
21Feb13_092934|-- Bias --
21Feb13_092934|[-0.06715 -0.34476 -0.15854]
21Feb13_092934|Layer 2:
21Feb13_092934|-- Config --
21Feb13_092934|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092934|-- Weights --
21Feb13_092934|[[-0.51620  0.17635 -0.47447 -0.57139  0.87197]
21Feb13_092934| [ 0.97581 -0.57390 -0.37481 -0.23881 -0.20901]
21Feb13_092934| [ 0.39891  0.42407  0.36421 -0.88927  0.90285]]
21Feb13_092934|-- Bias --
21Feb13_092934|[ 0.28599 -0.00186 -0.15313 -0.80765 -0.59664]
21Feb13_092934|Layer 3:
21Feb13_092934|-- Config --
21Feb13_092934|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092934|-- Weights --
21Feb13_092934|[[-0.49934 -0.31302]
21Feb13_092934| [ 0.15658 -1.30572]
21Feb13_092934| [ 0.66404  0.89534]
21Feb13_092934| [ 1.12580  1.32920]
21Feb13_092934| [-0.56371  1.06147]]
21Feb13_092934|-- Bias --
21Feb13_092934|[-0.12797  0.25323]
21Feb13_092934|Predicting the validation and test data with the Best final individual.
21Feb13_092942| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_092942|-----------  ------------------  --------------------  ----------
21Feb13_092942|Validation         30.70                  30            0.26913
21Feb13_092942|   Test            25.89                  30            0.54446
21Feb13_092942|-------------------- Test #8 --------------------
21Feb13_092942|Best final individual weights
21Feb13_092942|Individual:
21Feb13_092942|-- Constant hidden layers --
21Feb13_092942|False
21Feb13_092942|Layer 0:
21Feb13_092942|-- Config --
21Feb13_092942|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092942|-- Weights --
21Feb13_092942|[[ 0.40357 -0.18962]
21Feb13_092942| [ 0.63389  0.34346]
21Feb13_092942| [ 1.24534 -0.28953]
21Feb13_092942| [ 0.89656 -0.43923]
21Feb13_092942| [-1.01544 -0.56646]
21Feb13_092942| [ 1.39857 -0.93239]
21Feb13_092942| [-0.11966  0.11335]
21Feb13_092942| [-0.29352  0.85045]
21Feb13_092942| [ 0.70224  0.03044]
21Feb13_092942| [-0.25394  0.94913]
21Feb13_092942| [-0.77606 -0.01962]
21Feb13_092942| [-0.36125 -0.78320]
21Feb13_092942| [-0.60322 -0.36137]
21Feb13_092942| [ 0.97385  0.39888]
21Feb13_092942| [ 1.17820 -0.15125]
21Feb13_092942| [-0.32695 -0.99534]
21Feb13_092942| [ 0.06245 -0.59356]
21Feb13_092942| [ 0.15257  0.02718]
21Feb13_092942| [-1.19350 -0.46384]
21Feb13_092942| [ 0.35488  1.40937]
21Feb13_092942| [-1.06911  0.08581]
21Feb13_092942| [-0.33940 -0.68247]
21Feb13_092942| [ 0.01362 -0.66157]
21Feb13_092942| [ 0.98519 -0.02121]
21Feb13_092942| [-0.32095  0.31924]
21Feb13_092942| [-1.66785  0.35132]
21Feb13_092942| [ 0.26267  1.06776]
21Feb13_092942| [-1.18822  0.59496]
21Feb13_092942| [ 1.86097 -0.18212]
21Feb13_092942| [ 1.21581  0.18210]
21Feb13_092942| [-0.08200 -0.64525]
21Feb13_092942| [ 0.55127 -0.44936]
21Feb13_092942| [-0.48058 -0.02206]
21Feb13_092942| [-1.09558  0.08375]
21Feb13_092942| [ 0.43473  0.15022]
21Feb13_092942| [ 1.17631  0.67575]
21Feb13_092942| [-0.03519 -1.07919]
21Feb13_092942| [-0.91616 -0.50053]
21Feb13_092942| [-1.08606 -0.12496]
21Feb13_092942| [-0.43913 -0.93208]
21Feb13_092942| [ 0.31661 -0.32007]
21Feb13_092942| [-0.26644  1.33806]
21Feb13_092942| [-0.54467  0.47762]
21Feb13_092942| [-0.87403 -0.10565]
21Feb13_092942| [-1.62112 -1.18843]
21Feb13_092942| [ 0.63555  1.34321]
21Feb13_092942| [-1.72218  1.30865]
21Feb13_092942| [ 0.91023 -0.59051]
21Feb13_092942| [ 0.64095  0.95098]
21Feb13_092942| [-0.12341 -1.04846]
21Feb13_092942| [ 0.87908  0.86480]
21Feb13_092942| [-0.68615  0.86004]
21Feb13_092942| [ 1.04177 -0.63106]
21Feb13_092942| [-0.08866 -0.96551]
21Feb13_092942| [-1.54111  0.93125]
21Feb13_092942| [ 0.68548  1.43631]
21Feb13_092942| [-0.33035 -0.38548]]
21Feb13_092942|-- Bias --
21Feb13_092942|[ 0.18556 -0.43358]
21Feb13_092942|Layer 1:
21Feb13_092942|-- Config --
21Feb13_092942|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092942|-- Weights --
21Feb13_092942|[[-0.14008 -1.09501 -0.15226]
21Feb13_092942| [ 0.52818 -0.84946 -0.22217]]
21Feb13_092942|-- Bias --
21Feb13_092942|[-0.06715 -0.34476 -0.15854]
21Feb13_092942|Layer 2:
21Feb13_092942|-- Config --
21Feb13_092942|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092942|-- Weights --
21Feb13_092942|[[-0.51620  0.17635 -0.47447 -0.57139  0.87197]
21Feb13_092942| [ 0.97581 -0.57390 -0.37481 -0.23881 -0.20901]
21Feb13_092942| [ 0.39891  0.42407  0.36421 -0.88927  0.90285]]
21Feb13_092942|-- Bias --
21Feb13_092942|[ 0.28599 -0.00186 -0.15313 -0.80765 -0.59664]
21Feb13_092942|Layer 3:
21Feb13_092942|-- Config --
21Feb13_092942|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092942|-- Weights --
21Feb13_092942|[[-0.49934 -0.31302]
21Feb13_092942| [ 0.15658 -1.30572]
21Feb13_092942| [ 0.66404  0.89534]
21Feb13_092942| [ 1.12580  1.32920]
21Feb13_092942| [-0.56371  1.06147]]
21Feb13_092942|-- Bias --
21Feb13_092942|[-0.12797  0.25323]
21Feb13_092942|Predicting the validation and test data with the Best final individual.
21Feb13_092949| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_092949|-----------  ------------------  --------------------  ----------
21Feb13_092949|Validation         29.39                  30            0.30628
21Feb13_092949|   Test            27.37                  30            0.40363
21Feb13_092949|-------------------- Test #9 --------------------
21Feb13_092949|Best final individual weights
21Feb13_092949|Individual:
21Feb13_092949|-- Constant hidden layers --
21Feb13_092949|False
21Feb13_092949|Layer 0:
21Feb13_092949|-- Config --
21Feb13_092949|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092949|-- Weights --
21Feb13_092949|[[ 0.40357 -0.18962]
21Feb13_092949| [ 0.63389  0.34346]
21Feb13_092949| [ 1.24534 -0.28953]
21Feb13_092949| [ 0.89656 -0.43923]
21Feb13_092949| [-1.01544 -0.56646]
21Feb13_092949| [ 1.39857 -0.93239]
21Feb13_092949| [-0.11966  0.11335]
21Feb13_092949| [-0.29352  0.85045]
21Feb13_092949| [ 0.70224  0.03044]
21Feb13_092949| [-0.25394  0.94913]
21Feb13_092949| [-0.77606 -0.01962]
21Feb13_092949| [-0.36125 -0.78320]
21Feb13_092949| [-0.60322 -0.36137]
21Feb13_092949| [ 0.97385  0.39888]
21Feb13_092949| [ 1.17820 -0.15125]
21Feb13_092949| [-0.32695 -0.99534]
21Feb13_092949| [ 0.06245 -0.59356]
21Feb13_092949| [ 0.15257  0.02718]
21Feb13_092949| [-1.19350 -0.46384]
21Feb13_092949| [ 0.35488  1.40937]
21Feb13_092949| [-1.06911  0.08581]
21Feb13_092949| [-0.33940 -0.68247]
21Feb13_092949| [ 0.01362 -0.66157]
21Feb13_092949| [ 0.98519 -0.02121]
21Feb13_092949| [-0.32095  0.31924]
21Feb13_092949| [-1.66785  0.35132]
21Feb13_092949| [ 0.26267  1.06776]
21Feb13_092949| [-1.18822  0.59496]
21Feb13_092949| [ 1.86097 -0.18212]
21Feb13_092949| [ 1.21581  0.18210]
21Feb13_092949| [-0.08200 -0.64525]
21Feb13_092949| [ 0.55127 -0.44936]
21Feb13_092949| [-0.48058 -0.02206]
21Feb13_092949| [-1.09558  0.08375]
21Feb13_092949| [ 0.43473  0.15022]
21Feb13_092949| [ 1.17631  0.67575]
21Feb13_092949| [-0.03519 -1.07919]
21Feb13_092949| [-0.91616 -0.50053]
21Feb13_092949| [-1.08606 -0.12496]
21Feb13_092949| [-0.43913 -0.93208]
21Feb13_092949| [ 0.31661 -0.32007]
21Feb13_092949| [-0.26644  1.33806]
21Feb13_092949| [-0.54467  0.47762]
21Feb13_092949| [-0.87403 -0.10565]
21Feb13_092949| [-1.62112 -1.18843]
21Feb13_092949| [ 0.63555  1.34321]
21Feb13_092949| [-1.72218  1.30865]
21Feb13_092949| [ 0.91023 -0.59051]
21Feb13_092949| [ 0.64095  0.95098]
21Feb13_092949| [-0.12341 -1.04846]
21Feb13_092949| [ 0.87908  0.86480]
21Feb13_092949| [-0.68615  0.86004]
21Feb13_092949| [ 1.04177 -0.63106]
21Feb13_092949| [-0.08866 -0.96551]
21Feb13_092949| [-1.54111  0.93125]
21Feb13_092949| [ 0.68548  1.43631]
21Feb13_092949| [-0.33035 -0.38548]]
21Feb13_092949|-- Bias --
21Feb13_092949|[ 0.18556 -0.43358]
21Feb13_092949|Layer 1:
21Feb13_092949|-- Config --
21Feb13_092949|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092949|-- Weights --
21Feb13_092949|[[-0.14008 -1.09501 -0.15226]
21Feb13_092949| [ 0.52818 -0.84946 -0.22217]]
21Feb13_092949|-- Bias --
21Feb13_092949|[-0.06715 -0.34476 -0.15854]
21Feb13_092949|Layer 2:
21Feb13_092949|-- Config --
21Feb13_092949|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092949|-- Weights --
21Feb13_092949|[[-0.51620  0.17635 -0.47447 -0.57139  0.87197]
21Feb13_092949| [ 0.97581 -0.57390 -0.37481 -0.23881 -0.20901]
21Feb13_092949| [ 0.39891  0.42407  0.36421 -0.88927  0.90285]]
21Feb13_092949|-- Bias --
21Feb13_092949|[ 0.28599 -0.00186 -0.15313 -0.80765 -0.59664]
21Feb13_092949|Layer 3:
21Feb13_092949|-- Config --
21Feb13_092949|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092949|-- Weights --
21Feb13_092949|[[-0.49934 -0.31302]
21Feb13_092949| [ 0.15658 -1.30572]
21Feb13_092949| [ 0.66404  0.89534]
21Feb13_092949| [ 1.12580  1.32920]
21Feb13_092949| [-0.56371  1.06147]]
21Feb13_092949|-- Bias --
21Feb13_092949|[-0.12797  0.25323]
21Feb13_092949|Predicting the validation and test data with the Best final individual.
21Feb13_092957| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_092957|-----------  ------------------  --------------------  ----------
21Feb13_092957|Validation         26.17                  30            0.54602
21Feb13_092957|   Test            28.58                  30            0.36442
21Feb13_092957|-------------------- Test #10 --------------------
21Feb13_092957|Best final individual weights
21Feb13_092957|Individual:
21Feb13_092957|-- Constant hidden layers --
21Feb13_092957|False
21Feb13_092957|Layer 0:
21Feb13_092957|-- Config --
21Feb13_092957|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092957|-- Weights --
21Feb13_092957|[[ 0.40357 -0.18962]
21Feb13_092957| [ 0.63389  0.34346]
21Feb13_092957| [ 1.24534 -0.28953]
21Feb13_092957| [ 0.89656 -0.43923]
21Feb13_092957| [-1.01544 -0.56646]
21Feb13_092957| [ 1.39857 -0.93239]
21Feb13_092957| [-0.11966  0.11335]
21Feb13_092957| [-0.29352  0.85045]
21Feb13_092957| [ 0.70224  0.03044]
21Feb13_092957| [-0.25394  0.94913]
21Feb13_092957| [-0.77606 -0.01962]
21Feb13_092957| [-0.36125 -0.78320]
21Feb13_092957| [-0.60322 -0.36137]
21Feb13_092957| [ 0.97385  0.39888]
21Feb13_092957| [ 1.17820 -0.15125]
21Feb13_092957| [-0.32695 -0.99534]
21Feb13_092957| [ 0.06245 -0.59356]
21Feb13_092957| [ 0.15257  0.02718]
21Feb13_092957| [-1.19350 -0.46384]
21Feb13_092957| [ 0.35488  1.40937]
21Feb13_092957| [-1.06911  0.08581]
21Feb13_092957| [-0.33940 -0.68247]
21Feb13_092957| [ 0.01362 -0.66157]
21Feb13_092957| [ 0.98519 -0.02121]
21Feb13_092957| [-0.32095  0.31924]
21Feb13_092957| [-1.66785  0.35132]
21Feb13_092957| [ 0.26267  1.06776]
21Feb13_092957| [-1.18822  0.59496]
21Feb13_092957| [ 1.86097 -0.18212]
21Feb13_092957| [ 1.21581  0.18210]
21Feb13_092957| [-0.08200 -0.64525]
21Feb13_092957| [ 0.55127 -0.44936]
21Feb13_092957| [-0.48058 -0.02206]
21Feb13_092957| [-1.09558  0.08375]
21Feb13_092957| [ 0.43473  0.15022]
21Feb13_092957| [ 1.17631  0.67575]
21Feb13_092957| [-0.03519 -1.07919]
21Feb13_092957| [-0.91616 -0.50053]
21Feb13_092957| [-1.08606 -0.12496]
21Feb13_092957| [-0.43913 -0.93208]
21Feb13_092957| [ 0.31661 -0.32007]
21Feb13_092957| [-0.26644  1.33806]
21Feb13_092957| [-0.54467  0.47762]
21Feb13_092957| [-0.87403 -0.10565]
21Feb13_092957| [-1.62112 -1.18843]
21Feb13_092957| [ 0.63555  1.34321]
21Feb13_092957| [-1.72218  1.30865]
21Feb13_092957| [ 0.91023 -0.59051]
21Feb13_092957| [ 0.64095  0.95098]
21Feb13_092957| [-0.12341 -1.04846]
21Feb13_092957| [ 0.87908  0.86480]
21Feb13_092957| [-0.68615  0.86004]
21Feb13_092957| [ 1.04177 -0.63106]
21Feb13_092957| [-0.08866 -0.96551]
21Feb13_092957| [-1.54111  0.93125]
21Feb13_092957| [ 0.68548  1.43631]
21Feb13_092957| [-0.33035 -0.38548]]
21Feb13_092957|-- Bias --
21Feb13_092957|[ 0.18556 -0.43358]
21Feb13_092957|Layer 1:
21Feb13_092957|-- Config --
21Feb13_092957|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092957|-- Weights --
21Feb13_092957|[[-0.14008 -1.09501 -0.15226]
21Feb13_092957| [ 0.52818 -0.84946 -0.22217]]
21Feb13_092957|-- Bias --
21Feb13_092957|[-0.06715 -0.34476 -0.15854]
21Feb13_092957|Layer 2:
21Feb13_092957|-- Config --
21Feb13_092957|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092957|-- Weights --
21Feb13_092957|[[-0.51620  0.17635 -0.47447 -0.57139  0.87197]
21Feb13_092957| [ 0.97581 -0.57390 -0.37481 -0.23881 -0.20901]
21Feb13_092957| [ 0.39891  0.42407  0.36421 -0.88927  0.90285]]
21Feb13_092957|-- Bias --
21Feb13_092957|[ 0.28599 -0.00186 -0.15313 -0.80765 -0.59664]
21Feb13_092957|Layer 3:
21Feb13_092957|-- Config --
21Feb13_092957|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_092957|-- Weights --
21Feb13_092957|[[-0.49934 -0.31302]
21Feb13_092957| [ 0.15658 -1.30572]
21Feb13_092957| [ 0.66404  0.89534]
21Feb13_092957| [ 1.12580  1.32920]
21Feb13_092957| [-0.56371  1.06147]]
21Feb13_092957|-- Bias --
21Feb13_092957|[-0.12797  0.25323]
21Feb13_092957|Predicting the validation and test data with the Best final individual.
21Feb13_093004| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_093004|-----------  ------------------  --------------------  ----------
21Feb13_093004|Validation         26.09                  30            0.50439
21Feb13_093004|   Test            30.93                  30            0.28371
21Feb13_093004|-------------------- Test #11 --------------------
21Feb13_093004|Best final individual weights
21Feb13_093004|Individual:
21Feb13_093004|-- Constant hidden layers --
21Feb13_093004|False
21Feb13_093004|Layer 0:
21Feb13_093004|-- Config --
21Feb13_093004|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_093004|-- Weights --
21Feb13_093004|[[ 0.40357 -0.18962]
21Feb13_093004| [ 0.63389  0.34346]
21Feb13_093004| [ 1.24534 -0.28953]
21Feb13_093004| [ 0.89656 -0.43923]
21Feb13_093004| [-1.01544 -0.56646]
21Feb13_093004| [ 1.39857 -0.93239]
21Feb13_093004| [-0.11966  0.11335]
21Feb13_093004| [-0.29352  0.85045]
21Feb13_093004| [ 0.70224  0.03044]
21Feb13_093004| [-0.25394  0.94913]
21Feb13_093004| [-0.77606 -0.01962]
21Feb13_093004| [-0.36125 -0.78320]
21Feb13_093004| [-0.60322 -0.36137]
21Feb13_093004| [ 0.97385  0.39888]
21Feb13_093004| [ 1.17820 -0.15125]
21Feb13_093004| [-0.32695 -0.99534]
21Feb13_093004| [ 0.06245 -0.59356]
21Feb13_093004| [ 0.15257  0.02718]
21Feb13_093004| [-1.19350 -0.46384]
21Feb13_093004| [ 0.35488  1.40937]
21Feb13_093004| [-1.06911  0.08581]
21Feb13_093004| [-0.33940 -0.68247]
21Feb13_093004| [ 0.01362 -0.66157]
21Feb13_093004| [ 0.98519 -0.02121]
21Feb13_093004| [-0.32095  0.31924]
21Feb13_093004| [-1.66785  0.35132]
21Feb13_093004| [ 0.26267  1.06776]
21Feb13_093004| [-1.18822  0.59496]
21Feb13_093004| [ 1.86097 -0.18212]
21Feb13_093004| [ 1.21581  0.18210]
21Feb13_093004| [-0.08200 -0.64525]
21Feb13_093004| [ 0.55127 -0.44936]
21Feb13_093004| [-0.48058 -0.02206]
21Feb13_093004| [-1.09558  0.08375]
21Feb13_093004| [ 0.43473  0.15022]
21Feb13_093004| [ 1.17631  0.67575]
21Feb13_093004| [-0.03519 -1.07919]
21Feb13_093004| [-0.91616 -0.50053]
21Feb13_093004| [-1.08606 -0.12496]
21Feb13_093004| [-0.43913 -0.93208]
21Feb13_093004| [ 0.31661 -0.32007]
21Feb13_093004| [-0.26644  1.33806]
21Feb13_093004| [-0.54467  0.47762]
21Feb13_093004| [-0.87403 -0.10565]
21Feb13_093004| [-1.62112 -1.18843]
21Feb13_093004| [ 0.63555  1.34321]
21Feb13_093004| [-1.72218  1.30865]
21Feb13_093004| [ 0.91023 -0.59051]
21Feb13_093004| [ 0.64095  0.95098]
21Feb13_093004| [-0.12341 -1.04846]
21Feb13_093004| [ 0.87908  0.86480]
21Feb13_093004| [-0.68615  0.86004]
21Feb13_093004| [ 1.04177 -0.63106]
21Feb13_093004| [-0.08866 -0.96551]
21Feb13_093004| [-1.54111  0.93125]
21Feb13_093004| [ 0.68548  1.43631]
21Feb13_093004| [-0.33035 -0.38548]]
21Feb13_093004|-- Bias --
21Feb13_093004|[ 0.18556 -0.43358]
21Feb13_093004|Layer 1:
21Feb13_093004|-- Config --
21Feb13_093004|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_093004|-- Weights --
21Feb13_093004|[[-0.14008 -1.09501 -0.15226]
21Feb13_093004| [ 0.52818 -0.84946 -0.22217]]
21Feb13_093004|-- Bias --
21Feb13_093004|[-0.06715 -0.34476 -0.15854]
21Feb13_093004|Layer 2:
21Feb13_093004|-- Config --
21Feb13_093004|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_093004|-- Weights --
21Feb13_093004|[[-0.51620  0.17635 -0.47447 -0.57139  0.87197]
21Feb13_093004| [ 0.97581 -0.57390 -0.37481 -0.23881 -0.20901]
21Feb13_093004| [ 0.39891  0.42407  0.36421 -0.88927  0.90285]]
21Feb13_093004|-- Bias --
21Feb13_093004|[ 0.28599 -0.00186 -0.15313 -0.80765 -0.59664]
21Feb13_093004|Layer 3:
21Feb13_093004|-- Config --
21Feb13_093004|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_093004|-- Weights --
21Feb13_093004|[[-0.49934 -0.31302]
21Feb13_093004| [ 0.15658 -1.30572]
21Feb13_093004| [ 0.66404  0.89534]
21Feb13_093004| [ 1.12580  1.32920]
21Feb13_093004| [-0.56371  1.06147]]
21Feb13_093004|-- Bias --
21Feb13_093004|[-0.12797  0.25323]
21Feb13_093004|Predicting the validation and test data with the Best final individual.
21Feb13_093012| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_093012|-----------  ------------------  --------------------  ----------
21Feb13_093012|Validation         25.30                  30            0.49877
21Feb13_093012|   Test            39.01                  30            0.00000
21Feb13_093012|-------------------- Test #12 --------------------
21Feb13_093012|Best final individual weights
21Feb13_093012|Individual:
21Feb13_093012|-- Constant hidden layers --
21Feb13_093012|False
21Feb13_093012|Layer 0:
21Feb13_093012|-- Config --
21Feb13_093012|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_093012|-- Weights --
21Feb13_093012|[[ 0.40357 -0.18962]
21Feb13_093012| [ 0.63389  0.34346]
21Feb13_093012| [ 1.24534 -0.28953]
21Feb13_093012| [ 0.89656 -0.43923]
21Feb13_093012| [-1.01544 -0.56646]
21Feb13_093012| [ 1.39857 -0.93239]
21Feb13_093012| [-0.11966  0.11335]
21Feb13_093012| [-0.29352  0.85045]
21Feb13_093012| [ 0.70224  0.03044]
21Feb13_093012| [-0.25394  0.94913]
21Feb13_093012| [-0.77606 -0.01962]
21Feb13_093012| [-0.36125 -0.78320]
21Feb13_093012| [-0.60322 -0.36137]
21Feb13_093012| [ 0.97385  0.39888]
21Feb13_093012| [ 1.17820 -0.15125]
21Feb13_093012| [-0.32695 -0.99534]
21Feb13_093012| [ 0.06245 -0.59356]
21Feb13_093012| [ 0.15257  0.02718]
21Feb13_093012| [-1.19350 -0.46384]
21Feb13_093012| [ 0.35488  1.40937]
21Feb13_093012| [-1.06911  0.08581]
21Feb13_093012| [-0.33940 -0.68247]
21Feb13_093012| [ 0.01362 -0.66157]
21Feb13_093012| [ 0.98519 -0.02121]
21Feb13_093012| [-0.32095  0.31924]
21Feb13_093012| [-1.66785  0.35132]
21Feb13_093012| [ 0.26267  1.06776]
21Feb13_093012| [-1.18822  0.59496]
21Feb13_093012| [ 1.86097 -0.18212]
21Feb13_093012| [ 1.21581  0.18210]
21Feb13_093012| [-0.08200 -0.64525]
21Feb13_093012| [ 0.55127 -0.44936]
21Feb13_093012| [-0.48058 -0.02206]
21Feb13_093012| [-1.09558  0.08375]
21Feb13_093012| [ 0.43473  0.15022]
21Feb13_093012| [ 1.17631  0.67575]
21Feb13_093012| [-0.03519 -1.07919]
21Feb13_093012| [-0.91616 -0.50053]
21Feb13_093012| [-1.08606 -0.12496]
21Feb13_093012| [-0.43913 -0.93208]
21Feb13_093012| [ 0.31661 -0.32007]
21Feb13_093012| [-0.26644  1.33806]
21Feb13_093012| [-0.54467  0.47762]
21Feb13_093012| [-0.87403 -0.10565]
21Feb13_093012| [-1.62112 -1.18843]
21Feb13_093012| [ 0.63555  1.34321]
21Feb13_093012| [-1.72218  1.30865]
21Feb13_093012| [ 0.91023 -0.59051]
21Feb13_093012| [ 0.64095  0.95098]
21Feb13_093012| [-0.12341 -1.04846]
21Feb13_093012| [ 0.87908  0.86480]
21Feb13_093012| [-0.68615  0.86004]
21Feb13_093012| [ 1.04177 -0.63106]
21Feb13_093012| [-0.08866 -0.96551]
21Feb13_093012| [-1.54111  0.93125]
21Feb13_093012| [ 0.68548  1.43631]
21Feb13_093012| [-0.33035 -0.38548]]
21Feb13_093012|-- Bias --
21Feb13_093012|[ 0.18556 -0.43358]
21Feb13_093012|Layer 1:
21Feb13_093012|-- Config --
21Feb13_093012|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_093012|-- Weights --
21Feb13_093012|[[-0.14008 -1.09501 -0.15226]
21Feb13_093012| [ 0.52818 -0.84946 -0.22217]]
21Feb13_093012|-- Bias --
21Feb13_093012|[-0.06715 -0.34476 -0.15854]
21Feb13_093012|Layer 2:
21Feb13_093012|-- Config --
21Feb13_093012|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_093012|-- Weights --
21Feb13_093012|[[-0.51620  0.17635 -0.47447 -0.57139  0.87197]
21Feb13_093012| [ 0.97581 -0.57390 -0.37481 -0.23881 -0.20901]
21Feb13_093012| [ 0.39891  0.42407  0.36421 -0.88927  0.90285]]
21Feb13_093012|-- Bias --
21Feb13_093012|[ 0.28599 -0.00186 -0.15313 -0.80765 -0.59664]
21Feb13_093012|Layer 3:
21Feb13_093012|-- Config --
21Feb13_093012|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_093012|-- Weights --
21Feb13_093012|[[-0.49934 -0.31302]
21Feb13_093012| [ 0.15658 -1.30572]
21Feb13_093012| [ 0.66404  0.89534]
21Feb13_093012| [ 1.12580  1.32920]
21Feb13_093012| [-0.56371  1.06147]]
21Feb13_093012|-- Bias --
21Feb13_093012|[-0.12797  0.25323]
21Feb13_093012|Predicting the validation and test data with the Best final individual.
21Feb13_093019| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_093019|-----------  ------------------  --------------------  ----------
21Feb13_093019|Validation         26.00                  30            0.62529
21Feb13_093019|   Test            25.98                  30            0.53486
21Feb13_093019|-------------------- Test #13 --------------------
21Feb13_093019|Best final individual weights
21Feb13_093019|Individual:
21Feb13_093019|-- Constant hidden layers --
21Feb13_093019|False
21Feb13_093019|Layer 0:
21Feb13_093019|-- Config --
21Feb13_093019|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_093019|-- Weights --
21Feb13_093019|[[ 0.40357 -0.18962]
21Feb13_093019| [ 0.63389  0.34346]
21Feb13_093019| [ 1.24534 -0.28953]
21Feb13_093019| [ 0.89656 -0.43923]
21Feb13_093019| [-1.01544 -0.56646]
21Feb13_093019| [ 1.39857 -0.93239]
21Feb13_093019| [-0.11966  0.11335]
21Feb13_093019| [-0.29352  0.85045]
21Feb13_093019| [ 0.70224  0.03044]
21Feb13_093019| [-0.25394  0.94913]
21Feb13_093019| [-0.77606 -0.01962]
21Feb13_093019| [-0.36125 -0.78320]
21Feb13_093019| [-0.60322 -0.36137]
21Feb13_093019| [ 0.97385  0.39888]
21Feb13_093019| [ 1.17820 -0.15125]
21Feb13_093019| [-0.32695 -0.99534]
21Feb13_093019| [ 0.06245 -0.59356]
21Feb13_093019| [ 0.15257  0.02718]
21Feb13_093019| [-1.19350 -0.46384]
21Feb13_093019| [ 0.35488  1.40937]
21Feb13_093019| [-1.06911  0.08581]
21Feb13_093019| [-0.33940 -0.68247]
21Feb13_093019| [ 0.01362 -0.66157]
21Feb13_093019| [ 0.98519 -0.02121]
21Feb13_093019| [-0.32095  0.31924]
21Feb13_093019| [-1.66785  0.35132]
21Feb13_093019| [ 0.26267  1.06776]
21Feb13_093019| [-1.18822  0.59496]
21Feb13_093019| [ 1.86097 -0.18212]
21Feb13_093019| [ 1.21581  0.18210]
21Feb13_093019| [-0.08200 -0.64525]
21Feb13_093019| [ 0.55127 -0.44936]
21Feb13_093019| [-0.48058 -0.02206]
21Feb13_093019| [-1.09558  0.08375]
21Feb13_093019| [ 0.43473  0.15022]
21Feb13_093019| [ 1.17631  0.67575]
21Feb13_093019| [-0.03519 -1.07919]
21Feb13_093019| [-0.91616 -0.50053]
21Feb13_093019| [-1.08606 -0.12496]
21Feb13_093019| [-0.43913 -0.93208]
21Feb13_093019| [ 0.31661 -0.32007]
21Feb13_093019| [-0.26644  1.33806]
21Feb13_093019| [-0.54467  0.47762]
21Feb13_093019| [-0.87403 -0.10565]
21Feb13_093019| [-1.62112 -1.18843]
21Feb13_093019| [ 0.63555  1.34321]
21Feb13_093019| [-1.72218  1.30865]
21Feb13_093019| [ 0.91023 -0.59051]
21Feb13_093019| [ 0.64095  0.95098]
21Feb13_093019| [-0.12341 -1.04846]
21Feb13_093019| [ 0.87908  0.86480]
21Feb13_093019| [-0.68615  0.86004]
21Feb13_093019| [ 1.04177 -0.63106]
21Feb13_093019| [-0.08866 -0.96551]
21Feb13_093019| [-1.54111  0.93125]
21Feb13_093019| [ 0.68548  1.43631]
21Feb13_093019| [-0.33035 -0.38548]]
21Feb13_093019|-- Bias --
21Feb13_093019|[ 0.18556 -0.43358]
21Feb13_093019|Layer 1:
21Feb13_093019|-- Config --
21Feb13_093019|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_093019|-- Weights --
21Feb13_093019|[[-0.14008 -1.09501 -0.15226]
21Feb13_093019| [ 0.52818 -0.84946 -0.22217]]
21Feb13_093019|-- Bias --
21Feb13_093019|[-0.06715 -0.34476 -0.15854]
21Feb13_093019|Layer 2:
21Feb13_093019|-- Config --
21Feb13_093019|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_093019|-- Weights --
21Feb13_093019|[[-0.51620  0.17635 -0.47447 -0.57139  0.87197]
21Feb13_093019| [ 0.97581 -0.57390 -0.37481 -0.23881 -0.20901]
21Feb13_093019| [ 0.39891  0.42407  0.36421 -0.88927  0.90285]]
21Feb13_093019|-- Bias --
21Feb13_093019|[ 0.28599 -0.00186 -0.15313 -0.80765 -0.59664]
21Feb13_093019|Layer 3:
21Feb13_093019|-- Config --
21Feb13_093019|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_093019|-- Weights --
21Feb13_093019|[[-0.49934 -0.31302]
21Feb13_093019| [ 0.15658 -1.30572]
21Feb13_093019| [ 0.66404  0.89534]
21Feb13_093019| [ 1.12580  1.32920]
21Feb13_093019| [-0.56371  1.06147]]
21Feb13_093019|-- Bias --
21Feb13_093019|[-0.12797  0.25323]
21Feb13_093019|Predicting the validation and test data with the Best final individual.
21Feb13_093027| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_093027|-----------  ------------------  --------------------  ----------
21Feb13_093027|Validation         25.48                  30            0.51000
21Feb13_093027|   Test            25.98                  30            0.54420
21Feb13_093027|-------------------- Test #14 --------------------
21Feb13_093027|Best final individual weights
21Feb13_093027|Individual:
21Feb13_093027|-- Constant hidden layers --
21Feb13_093027|False
21Feb13_093027|Layer 0:
21Feb13_093027|-- Config --
21Feb13_093027|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_093027|-- Weights --
21Feb13_093027|[[ 0.40357 -0.18962]
21Feb13_093027| [ 0.63389  0.34346]
21Feb13_093027| [ 1.24534 -0.28953]
21Feb13_093027| [ 0.89656 -0.43923]
21Feb13_093027| [-1.01544 -0.56646]
21Feb13_093027| [ 1.39857 -0.93239]
21Feb13_093027| [-0.11966  0.11335]
21Feb13_093027| [-0.29352  0.85045]
21Feb13_093027| [ 0.70224  0.03044]
21Feb13_093027| [-0.25394  0.94913]
21Feb13_093027| [-0.77606 -0.01962]
21Feb13_093027| [-0.36125 -0.78320]
21Feb13_093027| [-0.60322 -0.36137]
21Feb13_093027| [ 0.97385  0.39888]
21Feb13_093027| [ 1.17820 -0.15125]
21Feb13_093027| [-0.32695 -0.99534]
21Feb13_093027| [ 0.06245 -0.59356]
21Feb13_093027| [ 0.15257  0.02718]
21Feb13_093027| [-1.19350 -0.46384]
21Feb13_093027| [ 0.35488  1.40937]
21Feb13_093027| [-1.06911  0.08581]
21Feb13_093027| [-0.33940 -0.68247]
21Feb13_093027| [ 0.01362 -0.66157]
21Feb13_093027| [ 0.98519 -0.02121]
21Feb13_093027| [-0.32095  0.31924]
21Feb13_093027| [-1.66785  0.35132]
21Feb13_093027| [ 0.26267  1.06776]
21Feb13_093027| [-1.18822  0.59496]
21Feb13_093027| [ 1.86097 -0.18212]
21Feb13_093027| [ 1.21581  0.18210]
21Feb13_093027| [-0.08200 -0.64525]
21Feb13_093027| [ 0.55127 -0.44936]
21Feb13_093027| [-0.48058 -0.02206]
21Feb13_093027| [-1.09558  0.08375]
21Feb13_093027| [ 0.43473  0.15022]
21Feb13_093027| [ 1.17631  0.67575]
21Feb13_093027| [-0.03519 -1.07919]
21Feb13_093027| [-0.91616 -0.50053]
21Feb13_093027| [-1.08606 -0.12496]
21Feb13_093027| [-0.43913 -0.93208]
21Feb13_093027| [ 0.31661 -0.32007]
21Feb13_093027| [-0.26644  1.33806]
21Feb13_093027| [-0.54467  0.47762]
21Feb13_093027| [-0.87403 -0.10565]
21Feb13_093027| [-1.62112 -1.18843]
21Feb13_093027| [ 0.63555  1.34321]
21Feb13_093027| [-1.72218  1.30865]
21Feb13_093027| [ 0.91023 -0.59051]
21Feb13_093027| [ 0.64095  0.95098]
21Feb13_093027| [-0.12341 -1.04846]
21Feb13_093027| [ 0.87908  0.86480]
21Feb13_093027| [-0.68615  0.86004]
21Feb13_093027| [ 1.04177 -0.63106]
21Feb13_093027| [-0.08866 -0.96551]
21Feb13_093027| [-1.54111  0.93125]
21Feb13_093027| [ 0.68548  1.43631]
21Feb13_093027| [-0.33035 -0.38548]]
21Feb13_093027|-- Bias --
21Feb13_093027|[ 0.18556 -0.43358]
21Feb13_093027|Layer 1:
21Feb13_093027|-- Config --
21Feb13_093027|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_093027|-- Weights --
21Feb13_093027|[[-0.14008 -1.09501 -0.15226]
21Feb13_093027| [ 0.52818 -0.84946 -0.22217]]
21Feb13_093027|-- Bias --
21Feb13_093027|[-0.06715 -0.34476 -0.15854]
21Feb13_093027|Layer 2:
21Feb13_093027|-- Config --
21Feb13_093027|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_093027|-- Weights --
21Feb13_093027|[[-0.51620  0.17635 -0.47447 -0.57139  0.87197]
21Feb13_093027| [ 0.97581 -0.57390 -0.37481 -0.23881 -0.20901]
21Feb13_093027| [ 0.39891  0.42407  0.36421 -0.88927  0.90285]]
21Feb13_093027|-- Bias --
21Feb13_093027|[ 0.28599 -0.00186 -0.15313 -0.80765 -0.59664]
21Feb13_093027|Layer 3:
21Feb13_093027|-- Config --
21Feb13_093027|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_093027|-- Weights --
21Feb13_093027|[[-0.49934 -0.31302]
21Feb13_093027| [ 0.15658 -1.30572]
21Feb13_093027| [ 0.66404  0.89534]
21Feb13_093027| [ 1.12580  1.32920]
21Feb13_093027| [-0.56371  1.06147]]
21Feb13_093027|-- Bias --
21Feb13_093027|[-0.12797  0.25323]
21Feb13_093027|Predicting the validation and test data with the Best final individual.
21Feb13_093034| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_093034|-----------  ------------------  --------------------  ----------
21Feb13_093034|Validation         29.04                  30            0.33420
21Feb13_093034|   Test            26.06                  30            0.53648
2021-02-13 09:30:35.640542: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
21Feb13_093036|Data summary: Train
21Feb13_093036|data.shape = (2300, 57)
21Feb13_093036|labels.shape = (2300,)
21Feb13_093036|Class distribution:
21Feb13_093036|	0 - 1382 (0.60)
21Feb13_093036|	1 - 918 (0.40)
21Feb13_093036|Data summary: Validation
21Feb13_093036|data.shape = (1150, 57)
21Feb13_093036|labels.shape = (1150,)
21Feb13_093036|Class distribution:
21Feb13_093036|	0 - 704 (0.61)
21Feb13_093036|	1 - 446 (0.39)
21Feb13_093036|Data summary: Test
21Feb13_093036|data.shape = (1151, 57)
21Feb13_093036|labels.shape = (1151,)
21Feb13_093036|Class distribution:
21Feb13_093036|	0 - 702 (0.61)
21Feb13_093036|	1 - 449 (0.39)
21Feb13_093036|Selected configuration values
21Feb13_093036|-- Dataset name: spambase1
21Feb13_093036|-- Initial population size: 64
21Feb13_093036|-- Maximun number of generations: 32
21Feb13_093036|-- Neurons per hidden layer range: (2, 20)
21Feb13_093036|-- Hidden layers number range: (1, 3)
21Feb13_093036|-- Crossover probability: 0.5
21Feb13_093036|-- Bias gene mutation probability: 0.2
21Feb13_093036|-- Weights gene mutation probability: 0.75
21Feb13_093036|-- Neuron mutation probability: 0.3
21Feb13_093036|-- Layer mutation probability: 0.3
21Feb13_093036|-- Constant hidden layers: False
21Feb13_093036|-- Seed: 31415
21Feb13_093036|Entering GA
21Feb13_093036|Start the algorithm
2021-02-13 09:30:36.499576: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-13 09:30:36.500132: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-02-13 09:30:36.522838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-13 09:30:36.523161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.71GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s
2021-02-13 09:30:36.523183: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-02-13 09:30:36.524658: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-02-13 09:30:36.524693: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-02-13 09:30:36.525186: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-02-13 09:30:36.525334: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-02-13 09:30:36.525407: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-13 09:30:36.525818: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-02-13 09:30:36.525860: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-13 09:30:36.525865: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-02-13 09:30:36.526058: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-02-13 09:30:36.526872: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-13 09:30:36.526889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-13 09:30:36.526893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      
2021-02-13 09:30:36.574010: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-02-13 09:30:36.574348: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3493635000 Hz
/home/jmerelo/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype("int32")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn('`model.predict_classes()` is deprecated and '
21Feb13_093440|-- Generation 1 --
21Feb13_093440|    -- Crossed 1 individual pairs.
21Feb13_093440|    -- Mutated 32 individuals.
21Feb13_093843|    -- Evaluated 64 individuals.
21Feb13_093843|    Summary of generation 1:
21Feb13_093843| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_093843|-----------  ------------------  --------------------  ----------
21Feb13_093843|    Max            39.39                208.00          0.70243
21Feb13_093843|    Avg            38.57                59.47           0.01789
21Feb13_093843|    Min            26.87                 3.00           0.00000
21Feb13_093843|    Std             1.81                50.20           0.10112
21Feb13_093843|   Best            26.87                63.00           0.42569
21Feb13_093843|-- Generation 2 --
21Feb13_093843|    -- Crossed 1 individual pairs.
21Feb13_093843|    -- Mutated 32 individuals.
21Feb13_094245|    -- Evaluated 64 individuals.
21Feb13_094245|    Summary of generation 2:
21Feb13_094245| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_094245|-----------  ------------------  --------------------  ----------
21Feb13_094245|    Max            39.22                132.00          0.73574
21Feb13_094245|    Avg            38.64                40.72           0.01154
21Feb13_094245|    Min            26.70                 2.00           0.00000
21Feb13_094245|    Std             1.51                33.61           0.09124
21Feb13_094245|   Best            26.70                63.00           0.73574
21Feb13_094245|-- Generation 3 --
21Feb13_094245|    -- Crossed 3 individual pairs.
21Feb13_094245|    -- Mutated 32 individuals.
21Feb13_094642|    -- Evaluated 64 individuals.
21Feb13_094642|    Summary of generation 3:
21Feb13_094642| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_094642|-----------  ------------------  --------------------  ----------
21Feb13_094642|    Max            39.22                81.00           0.44728
21Feb13_094642|    Avg            38.44                26.17           0.01411
21Feb13_094642|    Min            26.52                 2.00           0.00000
21Feb13_094642|    Std             2.09                21.37           0.07592
21Feb13_094642|   Best            26.52                18.00           0.44728
21Feb13_094642|-- Generation 4 --
21Feb13_094642|    -- Crossed 2 individual pairs.
21Feb13_094642|    -- Mutated 32 individuals.
21Feb13_095037|    -- Evaluated 64 individuals.
21Feb13_095037|    Summary of generation 4:
21Feb13_095037| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_095037|-----------  ------------------  --------------------  ----------
21Feb13_095037|    Max            39.13                78.00           0.27134
21Feb13_095037|    Avg            38.68                14.58           0.00506
21Feb13_095037|    Min            30.78                 2.00           0.00000
21Feb13_095037|    Std             1.02                12.28           0.03411
21Feb13_095037|   Best            30.78                78.00           0.27134
21Feb13_095037|-- Generation 5 --
21Feb13_095037|    -- Crossed 2 individual pairs.
21Feb13_095037|    -- Mutated 32 individuals.
21Feb13_095430|    -- Evaluated 64 individuals.
21Feb13_095430|    Summary of generation 5:
21Feb13_095430| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_095430|-----------  ------------------  --------------------  ----------
21Feb13_095430|    Max            39.30                78.00           0.74034
21Feb13_095430|    Avg            38.34                10.56           0.02437
21Feb13_095430|    Min            24.61                 2.00           0.00000
21Feb13_095430|    Std             2.44                11.82           0.11548
21Feb13_095430|   Best            24.61                27.00           0.74034
21Feb13_095430|-- Generation 6 --
21Feb13_095430|    -- Crossed 6 individual pairs.
21Feb13_095430|    -- Mutated 32 individuals.
21Feb13_095819|    -- Evaluated 64 individuals.
21Feb13_095819|    Summary of generation 6:
21Feb13_095819| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_095819|-----------  ------------------  --------------------  ----------
21Feb13_095819|    Max            49.30                27.00           0.79362
21Feb13_095819|    Avg            38.54                 7.23           0.03292
21Feb13_095819|    Min            23.91                 2.00           0.00000
21Feb13_095819|    Std             2.78                 6.14           0.14959
21Feb13_095819|   Best            23.91                18.00           0.72435
21Feb13_095819|-- Generation 7 --
21Feb13_095819|    -- Crossed 10 individual pairs.
21Feb13_095819|    -- Mutated 32 individuals.
21Feb13_100205|    -- Evaluated 64 individuals.
21Feb13_100205|    Summary of generation 7:
21Feb13_100205| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_100205|-----------  ------------------  --------------------  ----------
21Feb13_100205|    Max            38.96                20.00           0.45704
21Feb13_100205|    Avg            38.59                 5.19           0.00714
21Feb13_100205|    Min            25.91                 2.00           0.00000
21Feb13_100205|    Std             1.60                 4.29           0.05668
21Feb13_100205|   Best            25.91                18.00           0.45704
21Feb13_100205|-- Generation 8 --
21Feb13_100205|    -- Crossed 6 individual pairs.
21Feb13_100205|    -- Mutated 32 individuals.
21Feb13_100555|    -- Evaluated 64 individuals.
21Feb13_100555|    Summary of generation 8:
21Feb13_100555| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_100555|-----------  ------------------  --------------------  ----------
21Feb13_100555|    Max            39.04                18.00           0.00560
21Feb13_100555|    Avg            38.80                 4.86           0.00017
21Feb13_100555|    Min            38.70                 2.00           0.00000
21Feb13_100555|    Std             0.06                 4.55           0.00097
21Feb13_100555|   Best            38.70                16.00           0.00560
21Feb13_100555|-- Generation 9 --
21Feb13_100555|    -- Crossed 7 individual pairs.
21Feb13_100555|    -- Mutated 32 individuals.
21Feb13_100944|    -- Evaluated 64 individuals.
21Feb13_100944|    Summary of generation 9:
21Feb13_100944| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_100944|-----------  ------------------  --------------------  ----------
21Feb13_100944|    Max            39.13                18.00           0.73836
21Feb13_100944|    Avg            38.54                 5.05           0.01154
21Feb13_100944|    Min            21.83                 2.00           0.00000
21Feb13_100944|    Std             2.11                 4.65           0.09157
21Feb13_100944|   Best            21.83                12.00           0.73836
21Feb13_100944|-- Generation 10 --
21Feb13_100944|    -- Crossed 6 individual pairs.
21Feb13_100944|    -- Mutated 32 individuals.
21Feb13_101332|    -- Evaluated 64 individuals.
21Feb13_101332|    Summary of generation 10:
21Feb13_101332| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_101332|-----------  ------------------  --------------------  ----------
21Feb13_101332|    Max            38.96                16.00           0.60770
21Feb13_101332|    Avg            38.56                 4.30           0.00950
21Feb13_101332|    Min            23.91                 2.00           0.00000
21Feb13_101332|    Std             1.85                 4.08           0.07537
21Feb13_101332|   Best            23.91                14.00           0.60770
21Feb13_101332|-- Generation 11 --
21Feb13_101332|    -- Crossed 11 individual pairs.
21Feb13_101332|    -- Mutated 32 individuals.
21Feb13_101722|    -- Evaluated 64 individuals.
21Feb13_101722|    Summary of generation 11:
21Feb13_101722| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_101722|-----------  ------------------  --------------------  ----------
21Feb13_101722|    Max            56.61                16.00           0.78521
21Feb13_101722|    Avg            39.28                 4.52           0.02574
21Feb13_101722|    Min            37.65                 2.00           0.00000
21Feb13_101722|    Std             2.81                 4.41           0.13563
21Feb13_101722|   Best            37.65                 3.00           0.03891
21Feb13_101722|-- Generation 12 --
21Feb13_101722|    -- Crossed 5 individual pairs.
21Feb13_101722|    -- Mutated 32 individuals.
21Feb13_102110|    -- Evaluated 64 individuals.
21Feb13_102110|    Summary of generation 12:
21Feb13_102110| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_102110|-----------  ------------------  --------------------  ----------
21Feb13_102110|    Max            38.87                16.00           0.04162
21Feb13_102110|    Avg            38.78                 3.31           0.00065
21Feb13_102110|    Min            37.74                 2.00           0.00000
21Feb13_102110|    Std             0.13                 3.21           0.00516
21Feb13_102110|   Best            37.74                 4.00           0.04162
21Feb13_102110|-- Generation 13 --
21Feb13_102110|    -- Crossed 7 individual pairs.
21Feb13_102110|    -- Mutated 32 individuals.
21Feb13_102457|    -- Evaluated 64 individuals.
21Feb13_102457|    Summary of generation 13:
21Feb13_102457| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_102457|-----------  ------------------  --------------------  ----------
21Feb13_102457|    Max            39.04                16.00           0.03889
21Feb13_102457|    Avg            38.79                 3.03           0.00061
21Feb13_102457|    Min            37.74                 2.00           0.00000
21Feb13_102457|    Std             0.14                 2.84           0.00482
21Feb13_102457|   Best            37.74                 4.00           0.03889
21Feb13_102457|-- Generation 14 --
21Feb13_102457|    -- Crossed 6 individual pairs.
21Feb13_102457|    -- Mutated 32 individuals.
21Feb13_102845|    -- Evaluated 64 individuals.
21Feb13_102845|    Summary of generation 14:
21Feb13_102845| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_102845|-----------  ------------------  --------------------  ----------
21Feb13_102845|    Max            40.43                16.00           0.80481
21Feb13_102845|    Avg            38.81                 3.91           0.01258
21Feb13_102845|    Min            38.78                 2.00           0.00000
21Feb13_102845|    Std             0.21                 4.07           0.09981
21Feb13_102845|   Best            38.78                 2.00           0.00000
21Feb13_102845|-- Generation 15 --
21Feb13_102845|    -- Crossed 7 individual pairs.
21Feb13_102845|    -- Mutated 32 individuals.
21Feb13_103233|    -- Evaluated 64 individuals.
21Feb13_103233|    Summary of generation 15:
21Feb13_103233| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_103233|-----------  ------------------  --------------------  ----------
21Feb13_103233|    Max            38.96                14.00           0.00000
21Feb13_103233|    Avg            38.79                 3.73           0.00000
21Feb13_103233|    Min            38.78                 2.00           0.00000
21Feb13_103233|    Std             0.02                 3.62           0.00000
21Feb13_103233|   Best            38.78                 2.00           0.00000
21Feb13_103233|-- Generation 16 --
21Feb13_103233|    -- Crossed 9 individual pairs.
21Feb13_103233|    -- Mutated 32 individuals.
21Feb13_103621|    -- Evaluated 64 individuals.
21Feb13_103621|    Summary of generation 16:
21Feb13_103621| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_103621|-----------  ------------------  --------------------  ----------
21Feb13_103621|    Max            39.30                14.00           0.00000
21Feb13_103621|    Avg            38.80                 3.91           0.00000
21Feb13_103621|    Min            38.78                 2.00           0.00000
21Feb13_103621|    Std             0.08                 3.84           0.00000
21Feb13_103621|   Best            38.78                 2.00           0.00000
21Feb13_103621|-- Generation 17 --
21Feb13_103621|    -- Crossed 8 individual pairs.
21Feb13_103621|    -- Mutated 32 individuals.
21Feb13_104009|    -- Evaluated 64 individuals.
21Feb13_104009|    Summary of generation 17:
21Feb13_104009| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_104009|-----------  ------------------  --------------------  ----------
21Feb13_104009|    Max            39.04                16.00           0.67711
21Feb13_104009|    Avg            38.63                 3.38           0.01058
21Feb13_104009|    Min            27.39                 2.00           0.00000
21Feb13_104009|    Std             1.42                 3.42           0.08397
21Feb13_104009|   Best            27.39                10.00           0.67711
21Feb13_104009|-- Generation 18 --
21Feb13_104009|    -- Crossed 5 individual pairs.
21Feb13_104009|    -- Mutated 32 individuals.
21Feb13_104358|    -- Evaluated 64 individuals.
21Feb13_104358|    Summary of generation 18:
21Feb13_104358| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_104358|-----------  ------------------  --------------------  ----------
21Feb13_104358|    Max            39.04                14.00           0.58563
21Feb13_104358|    Avg            38.60                 3.25           0.00915
21Feb13_104358|    Min            26.35                 2.00           0.00000
21Feb13_104358|    Std             1.54                 3.04           0.07263
21Feb13_104358|   Best            26.35                10.00           0.58563
21Feb13_104358|-- Generation 19 --
21Feb13_104358|    -- Crossed 8 individual pairs.
21Feb13_104358|    -- Mutated 32 individuals.
21Feb13_104746|    -- Evaluated 64 individuals.
21Feb13_104746|    Summary of generation 19:
21Feb13_104746| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_104746|-----------  ------------------  --------------------  ----------
21Feb13_104746|    Max            39.04                16.00           0.00000
21Feb13_104746|    Avg            38.81                 3.47           0.00000
21Feb13_104746|    Min            38.78                 2.00           0.00000
21Feb13_104746|    Std             0.06                 3.41           0.00000
21Feb13_104746|   Best            38.78                 2.00           0.00000
21Feb13_104746|-- Generation 20 --
21Feb13_104746|    -- Crossed 8 individual pairs.
21Feb13_104746|    -- Mutated 32 individuals.
21Feb13_105135|    -- Evaluated 64 individuals.
21Feb13_105135|    Summary of generation 20:
21Feb13_105135| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_105135|-----------  ------------------  --------------------  ----------
21Feb13_105135|    Max            38.87                14.00           0.00000
21Feb13_105135|    Avg            38.79                 3.09           0.00000
21Feb13_105135|    Min            38.78                 2.00           0.00000
21Feb13_105135|    Std             0.02                 3.06           0.00000
21Feb13_105135|   Best            38.78                 2.00           0.00000
21Feb13_105135|-- Generation 21 --
21Feb13_105135|    -- Crossed 10 individual pairs.
21Feb13_105135|    -- Mutated 32 individuals.
21Feb13_105525|    -- Evaluated 64 individuals.
21Feb13_105525|    Summary of generation 21:
21Feb13_105525| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_105525|-----------  ------------------  --------------------  ----------
21Feb13_105525|    Max            38.96                14.00           0.00000
21Feb13_105525|    Avg            38.79                 3.16           0.00000
21Feb13_105525|    Min            38.78                 2.00           0.00000
21Feb13_105525|    Std             0.03                 2.82           0.00000
21Feb13_105525|   Best            38.78                 2.00           0.00000
21Feb13_105525|-- Generation 22 --
21Feb13_105525|    -- Crossed 10 individual pairs.
21Feb13_105525|    -- Mutated 32 individuals.
21Feb13_105914|    -- Evaluated 64 individuals.
21Feb13_105914|    Summary of generation 22:
21Feb13_105914| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_105914|-----------  ------------------  --------------------  ----------
21Feb13_105914|    Max            39.04                14.00           0.52950
21Feb13_105914|    Avg            38.59                 3.86           0.00836
21Feb13_105914|    Min            25.39                 2.00           0.00000
21Feb13_105914|    Std             1.66                 3.88           0.06566
21Feb13_105914|   Best            25.39                 8.00           0.52950
21Feb13_105914|-- Generation 23 --
21Feb13_105914|    -- Crossed 6 individual pairs.
21Feb13_105914|    -- Mutated 32 individuals.
21Feb13_110303|    -- Evaluated 64 individuals.
21Feb13_110303|    Summary of generation 23:
21Feb13_110303| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_110303|-----------  ------------------  --------------------  ----------
21Feb13_110303|    Max            38.96                16.00           0.36027
21Feb13_110303|    Avg            38.63                 3.92           0.00563
21Feb13_110303|    Min            28.26                 2.00           0.00000
21Feb13_110303|    Std             1.31                 4.20           0.04468
21Feb13_110303|   Best            28.26                 8.00           0.36027
21Feb13_110303|-- Generation 24 --
21Feb13_110303|    -- Crossed 11 individual pairs.
21Feb13_110303|    -- Mutated 32 individuals.
21Feb13_110651|    -- Evaluated 64 individuals.
21Feb13_110651|    Summary of generation 24:
21Feb13_110651| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_110651|-----------  ------------------  --------------------  ----------
21Feb13_110651|    Max            39.04                24.00           0.31593
21Feb13_110651|    Avg            38.64                 3.78           0.00494
21Feb13_110651|    Min            29.13                 2.00           0.00000
21Feb13_110651|    Std             1.20                 4.34           0.03918
21Feb13_110651|   Best            29.13                 8.00           0.31593
21Feb13_110651|-- Generation 25 --
21Feb13_110651|    -- Crossed 9 individual pairs.
21Feb13_110651|    -- Mutated 32 individuals.
21Feb13_111038|    -- Evaluated 64 individuals.
21Feb13_111038|    Summary of generation 25:
21Feb13_111038| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_111038|-----------  ------------------  --------------------  ----------
21Feb13_111038|    Max            39.22                16.00           0.51800
21Feb13_111038|    Avg            38.56                 3.42           0.00913
21Feb13_111038|    Min            25.39                 2.00           0.00000
21Feb13_111038|    Std             1.67                 3.24           0.06464
21Feb13_111038|   Best            25.39                 8.00           0.51800
21Feb13_111038|-- Generation 26 --
21Feb13_111038|    -- Crossed 9 individual pairs.
21Feb13_111038|    -- Mutated 32 individuals.
21Feb13_111427|    -- Evaluated 64 individuals.
21Feb13_111427|    Summary of generation 26:
21Feb13_111427| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_111427|-----------  ------------------  --------------------  ----------
21Feb13_111427|    Max            39.04                21.00           0.40527
21Feb13_111427|    Avg            38.62                 4.69           0.00633
21Feb13_111427|    Min            27.48                 2.00           0.00000
21Feb13_111427|    Std             1.40                 4.92           0.05026
21Feb13_111427|   Best            27.48                 8.00           0.40527
21Feb13_111427|-- Generation 27 --
21Feb13_111427|    -- Crossed 7 individual pairs.
21Feb13_111427|    -- Mutated 32 individuals.
21Feb13_111814|    -- Evaluated 64 individuals.
21Feb13_111814|    Summary of generation 27:
21Feb13_111814| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_111814|-----------  ------------------  --------------------  ----------
21Feb13_111814|    Max            38.78                16.00           0.34830
21Feb13_111814|    Avg            38.62                 3.70           0.00544
21Feb13_111814|    Min            28.70                 2.00           0.00000
21Feb13_111814|    Std             1.25                 3.56           0.04320
21Feb13_111814|   Best            28.70                 8.00           0.34830
21Feb13_111814|-- Generation 28 --
21Feb13_111814|    -- Crossed 7 individual pairs.
21Feb13_111814|    -- Mutated 32 individuals.
21Feb13_112202|    -- Evaluated 64 individuals.
21Feb13_112202|    Summary of generation 28:
21Feb13_112202| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_112202|-----------  ------------------  --------------------  ----------
21Feb13_112202|    Max            39.04                16.00           0.57331
21Feb13_112202|    Avg            38.60                 3.41           0.00896
21Feb13_112202|    Min            26.26                 2.00           0.00000
21Feb13_112202|    Std             1.56                 3.27           0.07110
21Feb13_112202|   Best            26.26                 8.00           0.57331
21Feb13_112202|-- Generation 29 --
21Feb13_112202|    -- Crossed 5 individual pairs.
21Feb13_112202|    -- Mutated 32 individuals.
21Feb13_112549|    -- Evaluated 64 individuals.
21Feb13_112549|    Summary of generation 29:
21Feb13_112549| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_112549|-----------  ------------------  --------------------  ----------
21Feb13_112549|    Max            38.87                14.00           0.72835
21Feb13_112549|    Avg            38.04                 3.33           0.03207
21Feb13_112549|    Min            24.52                 2.00           0.00000
21Feb13_112549|    Std             2.94                 3.19           0.12976
21Feb13_112549|   Best            24.52                14.00           0.72835
21Feb13_112549|-- Generation 30 --
21Feb13_112549|    -- Crossed 8 individual pairs.
21Feb13_112549|    -- Mutated 32 individuals.
21Feb13_112938|    -- Evaluated 64 individuals.
21Feb13_112938|    Summary of generation 30:
21Feb13_112938| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_112938|-----------  ------------------  --------------------  ----------
21Feb13_112938|    Max            39.04                14.00           0.55740
21Feb13_112938|    Avg            38.45                 4.38           0.01326
21Feb13_112938|    Min            26.09                 2.00           0.00000
21Feb13_112938|    Std             1.91                 3.95           0.07750
21Feb13_112938|   Best            26.09                 8.00           0.55740
21Feb13_112938|-- Generation 31 --
21Feb13_112938|    -- Crossed 4 individual pairs.
21Feb13_112938|    -- Mutated 32 individuals.
21Feb13_113325|    -- Evaluated 64 individuals.
21Feb13_113325|    Summary of generation 31:
21Feb13_113325| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_113325|-----------  ------------------  --------------------  ----------
21Feb13_113325|    Max            39.30                27.00           0.77513
21Feb13_113325|    Avg            38.39                 3.77           0.02046
21Feb13_113325|    Min            24.52                 2.00           0.00000
21Feb13_113325|    Std             2.34                 4.13           0.11590
21Feb13_113325|   Best            24.52                10.00           0.77513
21Feb13_113325|-- Generation 32 --
21Feb13_113325|    -- Crossed 8 individual pairs.
21Feb13_113325|    -- Mutated 32 individuals.
21Feb13_113714|    -- Evaluated 64 individuals.
21Feb13_113714|    Summary of generation 32:
21Feb13_113714| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_113714|-----------  ------------------  --------------------  ----------
21Feb13_113714|    Max            39.30                21.00           0.54353
21Feb13_113714|    Avg            38.46                 4.08           0.01285
21Feb13_113714|    Min            25.13                 2.00           0.00000
21Feb13_113714|    Std             1.98                 3.98           0.07529
21Feb13_113714|   Best            25.13                 8.00           0.54353
21Feb13_113714|Best initial individual weights
21Feb13_113714|Individual:
21Feb13_113714|-- Constant hidden layers --
21Feb13_113714|False
21Feb13_113714|Layer 0:
21Feb13_113714|-- Config --
21Feb13_113714|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113714|-- Weights --
21Feb13_113714|[[-0.95981  0.63808 -0.95380]
21Feb13_113714| [ 0.00520 -0.99353  0.50361]
21Feb13_113714| [-0.11451 -0.83347 -0.55396]
21Feb13_113714| [ 0.35657 -0.33319  0.99061]
21Feb13_113714| [ 0.20904  0.47603  0.54306]
21Feb13_113714| [ 0.86632  0.13678 -0.77041]
21Feb13_113714| [-0.35567 -0.99164  0.62727]
21Feb13_113714| [-0.68497  0.10640 -0.05172]
21Feb13_113714| [-0.59737 -0.00964  0.88158]
21Feb13_113714| [-0.13985 -0.06300 -0.43706]
21Feb13_113714| [ 0.64358  0.92937 -0.73432]
21Feb13_113714| [ 0.23476  0.78313  0.56825]
21Feb13_113714| [-0.54321  0.72471  0.37840]
21Feb13_113714| [-0.42357 -0.01577 -0.17096]
21Feb13_113714| [ 0.72075  0.01528 -0.53335]
21Feb13_113714| [-0.85291 -0.95287  0.91534]
21Feb13_113714| [-0.32401 -0.26906  0.15748]
21Feb13_113714| [-0.40109 -0.17141  0.12077]
21Feb13_113714| [ 0.06946 -0.71844 -0.65437]
21Feb13_113714| [ 0.77536 -0.87117  0.40091]
21Feb13_113714| [ 0.71219 -0.55029 -0.47352]
21Feb13_113714| [-0.48247 -0.59676 -0.13973]
21Feb13_113714| [ 0.29835 -0.64235  0.86195]
21Feb13_113714| [ 0.76225  0.85104  0.00830]
21Feb13_113714| [ 0.47868 -0.29509  0.58927]
21Feb13_113714| [ 0.44057 -0.21842 -0.84593]
21Feb13_113714| [-0.45754  0.53879  0.95554]
21Feb13_113714| [-0.76945 -0.60835  0.71744]
21Feb13_113714| [ 0.53999  0.63134  0.43758]
21Feb13_113714| [-0.19306 -0.59818  0.19108]
21Feb13_113714| [-0.51517  0.85226  0.38538]
21Feb13_113714| [-0.79126 -0.93873  0.01578]
21Feb13_113714| [-0.50150 -0.14594 -0.18067]
21Feb13_113714| [ 0.61416 -0.70576  0.33529]
21Feb13_113714| [ 0.15072  0.89141  0.54784]
21Feb13_113714| [ 0.36697  0.31313 -0.13077]
21Feb13_113714| [ 0.69307 -0.37869  0.20694]
21Feb13_113714| [ 0.03015  0.15728  0.76226]
21Feb13_113714| [ 0.77952 -0.76856 -0.43483]
21Feb13_113714| [-0.61518 -0.05786  0.81156]
21Feb13_113714| [ 0.84017 -0.42741  0.60340]
21Feb13_113714| [ 0.53666 -0.82919  0.07802]
21Feb13_113714| [ 0.47864  0.69058 -0.97920]
21Feb13_113714| [ 0.68760  0.30748  0.39424]
21Feb13_113714| [ 0.18427  0.64362  0.23634]
21Feb13_113714| [-0.94644 -0.07451 -0.16574]
21Feb13_113714| [-0.96084  0.12874 -0.86066]
21Feb13_113714| [-0.56938  0.44358  0.07698]
21Feb13_113714| [-0.21143  0.88977 -0.62804]
21Feb13_113714| [-0.49083  0.36500  0.15463]
21Feb13_113714| [-0.68978  0.96064  0.44141]
21Feb13_113714| [-0.21911  0.93693  0.42766]
21Feb13_113714| [ 0.30992 -0.75633  0.40386]
21Feb13_113714| [-0.38889 -0.87472 -0.60032]
21Feb13_113714| [ 0.63181  0.38743  0.42944]
21Feb13_113714| [-0.36880  0.75866  0.06497]
21Feb13_113714| [ 0.95225  0.89125  0.24472]]
21Feb13_113714|-- Bias --
21Feb13_113714|[-0.87203 -0.18510 -0.82395]
21Feb13_113714|Layer 1:
21Feb13_113714|-- Config --
21Feb13_113714|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 9, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113714|-- Weights --
21Feb13_113714|[[-0.48876  0.92140 -0.21669  0.72465 -0.25318 -0.77574 -0.72806 -0.41561
21Feb13_113714|   0.09470]
21Feb13_113714| [ 0.16540 -0.74164  0.12712 -0.17055  0.32434  0.08465 -0.18577  0.93967
21Feb13_113714|   0.13630]
21Feb13_113714| [ 0.51611  0.56311  0.06727  0.75197 -0.15192  0.43301 -0.52005  0.07976
21Feb13_113714|  -0.84277]]
21Feb13_113714|-- Bias --
21Feb13_113714|[ 0.32558  0.84726 -0.20681  0.97295  0.68375 -0.70571 -0.86307 -0.88871
21Feb13_113714|  0.55514]
21Feb13_113714|Layer 2:
21Feb13_113714|-- Config --
21Feb13_113714|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 9], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113714|-- Weights --
21Feb13_113714|[[ 0.76468  0.30035]
21Feb13_113714| [-0.84449  0.54167]
21Feb13_113714| [-0.04649 -0.86516]
21Feb13_113714| [-0.11365 -0.30894]
21Feb13_113714| [ 0.95453  0.69955]
21Feb13_113714| [ 0.56339  0.48813]
21Feb13_113714| [-0.11587 -0.35680]
21Feb13_113714| [ 0.67275  0.94171]
21Feb13_113714| [ 0.44550 -0.58681]]
21Feb13_113714|-- Bias --
21Feb13_113714|[0.41147 0.60365]
21Feb13_113714|Predicting the validation and test data with the Best initial individual.
21Feb13_113722| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_113722|-----------  ------------------  --------------------  ----------
21Feb13_113722|Validation         38.78                  24            0.00000
21Feb13_113722|   Test            39.01                  24            0.00000
21Feb13_113722|-------------------- Test #0 --------------------
21Feb13_113722|Best final individual weights
21Feb13_113722|Individual:
21Feb13_113722|-- Constant hidden layers --
21Feb13_113722|False
21Feb13_113722|Layer 0:
21Feb13_113722|-- Config --
21Feb13_113722|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113722|-- Weights --
21Feb13_113722|[[ 1.74276e-01 -2.41590e-01]
21Feb13_113722| [ 1.77129e+00  4.54754e-01]
21Feb13_113722| [-1.87726e-01 -7.08215e-02]
21Feb13_113722| [ 1.67602e+00  1.07538e+00]
21Feb13_113722| [ 4.83300e-01  2.23842e-01]
21Feb13_113722| [ 1.21089e-01  8.43355e-01]
21Feb13_113722| [ 5.58188e-01  6.02878e-01]
21Feb13_113722| [ 9.80989e-01 -1.57022e+00]
21Feb13_113722| [-4.94314e-01  1.03493e-03]
21Feb13_113722| [ 6.50898e-01 -9.91301e-01]
21Feb13_113722| [ 1.21564e-01 -5.16848e-01]
21Feb13_113722| [ 2.05958e-02  7.65841e-01]
21Feb13_113722| [-1.19880e+00 -1.98384e-01]
21Feb13_113722| [ 1.40344e-01 -8.21092e-01]
21Feb13_113722| [ 8.66470e-01  6.10729e-01]
21Feb13_113722| [ 8.12148e-01 -4.05623e-01]
21Feb13_113722| [-1.93100e-01 -8.07256e-01]
21Feb13_113722| [-3.45548e-01 -3.86709e-03]
21Feb13_113722| [ 2.09207e-01 -2.40907e-01]
21Feb13_113722| [ 2.87175e-01 -4.04162e-01]
21Feb13_113722| [ 8.41330e-01  6.62044e-01]
21Feb13_113722| [ 6.85979e-01 -1.49782e+00]
21Feb13_113722| [-8.64047e-01 -4.42409e-01]
21Feb13_113722| [ 3.31760e-01 -3.46622e-01]
21Feb13_113722| [ 1.98449e+00 -1.68578e-01]
21Feb13_113722| [ 1.28383e+00 -5.72640e-01]
21Feb13_113722| [ 5.26745e-01  1.69675e+00]
21Feb13_113722| [ 2.00860e+00  1.52840e+00]
21Feb13_113722| [-1.76176e+00 -3.51036e-01]
21Feb13_113722| [-6.94774e-01  6.57618e-01]
21Feb13_113722| [ 3.70786e-01 -7.10144e-01]
21Feb13_113722| [-1.07489e+00 -2.87213e-01]
21Feb13_113722| [ 1.38837e+00  4.36522e-02]
21Feb13_113722| [-3.09496e-01  4.31557e-01]
21Feb13_113722| [ 1.94421e+00 -3.85891e-01]
21Feb13_113722| [ 1.13461e+00  3.53034e-01]
21Feb13_113722| [ 8.45985e-01  5.29180e-01]
21Feb13_113722| [ 9.77036e-01  9.19790e-02]
21Feb13_113722| [ 4.08182e-01 -2.17468e-01]
21Feb13_113722| [ 5.97516e-02  3.85639e-02]
21Feb13_113722| [-5.72126e-01 -1.12712e+00]
21Feb13_113722| [-6.00429e-02 -7.74199e-01]
21Feb13_113722| [ 1.10419e-01 -3.90905e-01]
21Feb13_113722| [-2.35151e+00 -1.19756e+00]
21Feb13_113722| [-7.19410e-01 -5.15445e-01]
21Feb13_113722| [ 7.11794e-01 -1.63341e-01]
21Feb13_113722| [-7.12856e-01 -1.26040e-01]
21Feb13_113722| [ 1.00583e+00 -4.07499e-01]
21Feb13_113722| [-4.46850e-01 -1.31896e+00]
21Feb13_113722| [ 6.83406e-02  2.95165e-01]
21Feb13_113722| [-7.73834e-01  4.39170e-01]
21Feb13_113722| [ 3.40113e-02 -1.19226e+00]
21Feb13_113722| [-1.90476e-01 -1.30555e+00]
21Feb13_113722| [-8.00537e-01  9.09884e-01]
21Feb13_113722| [ 8.79862e-01  5.55782e-01]
21Feb13_113722| [ 4.30997e-01 -3.58067e-01]
21Feb13_113722| [-6.68257e-01  2.38322e-01]]
21Feb13_113722|-- Bias --
21Feb13_113722|[-0.70906 -0.37669]
21Feb13_113722|Layer 1:
21Feb13_113722|-- Config --
21Feb13_113722|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113722|-- Weights --
21Feb13_113722|[[-0.94561  0.38942]
21Feb13_113722| [ 0.25172 -0.95334]]
21Feb13_113722|-- Bias --
21Feb13_113722|[-0.48591  0.74488]
21Feb13_113722|Layer 2:
21Feb13_113722|-- Config --
21Feb13_113722|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113722|-- Weights --
21Feb13_113722|[[ 1.63570  0.94691]
21Feb13_113722| [-0.10069  0.32775]]
21Feb13_113722|-- Bias --
21Feb13_113722|[0.40880 0.31931]
21Feb13_113722|Predicting the validation and test data with the Best final individual.
21Feb13_113729| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_113729|-----------  ------------------  --------------------  ----------
21Feb13_113729|Validation         29.91                  8             0.29149
21Feb13_113729|   Test            26.59                  8             0.54054
21Feb13_113729|-------------------- Test #1 --------------------
21Feb13_113729|Best final individual weights
21Feb13_113729|Individual:
21Feb13_113729|-- Constant hidden layers --
21Feb13_113729|False
21Feb13_113729|Layer 0:
21Feb13_113729|-- Config --
21Feb13_113729|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113729|-- Weights --
21Feb13_113729|[[ 1.74276e-01 -2.41590e-01]
21Feb13_113729| [ 1.77129e+00  4.54754e-01]
21Feb13_113729| [-1.87726e-01 -7.08215e-02]
21Feb13_113729| [ 1.67602e+00  1.07538e+00]
21Feb13_113729| [ 4.83300e-01  2.23842e-01]
21Feb13_113729| [ 1.21089e-01  8.43355e-01]
21Feb13_113729| [ 5.58188e-01  6.02878e-01]
21Feb13_113729| [ 9.80989e-01 -1.57022e+00]
21Feb13_113729| [-4.94314e-01  1.03493e-03]
21Feb13_113729| [ 6.50898e-01 -9.91301e-01]
21Feb13_113729| [ 1.21564e-01 -5.16848e-01]
21Feb13_113729| [ 2.05958e-02  7.65841e-01]
21Feb13_113729| [-1.19880e+00 -1.98384e-01]
21Feb13_113729| [ 1.40344e-01 -8.21092e-01]
21Feb13_113729| [ 8.66470e-01  6.10729e-01]
21Feb13_113729| [ 8.12148e-01 -4.05623e-01]
21Feb13_113729| [-1.93100e-01 -8.07256e-01]
21Feb13_113729| [-3.45548e-01 -3.86709e-03]
21Feb13_113729| [ 2.09207e-01 -2.40907e-01]
21Feb13_113729| [ 2.87175e-01 -4.04162e-01]
21Feb13_113729| [ 8.41330e-01  6.62044e-01]
21Feb13_113729| [ 6.85979e-01 -1.49782e+00]
21Feb13_113729| [-8.64047e-01 -4.42409e-01]
21Feb13_113729| [ 3.31760e-01 -3.46622e-01]
21Feb13_113729| [ 1.98449e+00 -1.68578e-01]
21Feb13_113729| [ 1.28383e+00 -5.72640e-01]
21Feb13_113729| [ 5.26745e-01  1.69675e+00]
21Feb13_113729| [ 2.00860e+00  1.52840e+00]
21Feb13_113729| [-1.76176e+00 -3.51036e-01]
21Feb13_113729| [-6.94774e-01  6.57618e-01]
21Feb13_113729| [ 3.70786e-01 -7.10144e-01]
21Feb13_113729| [-1.07489e+00 -2.87213e-01]
21Feb13_113729| [ 1.38837e+00  4.36522e-02]
21Feb13_113729| [-3.09496e-01  4.31557e-01]
21Feb13_113729| [ 1.94421e+00 -3.85891e-01]
21Feb13_113729| [ 1.13461e+00  3.53034e-01]
21Feb13_113729| [ 8.45985e-01  5.29180e-01]
21Feb13_113729| [ 9.77036e-01  9.19790e-02]
21Feb13_113729| [ 4.08182e-01 -2.17468e-01]
21Feb13_113729| [ 5.97516e-02  3.85639e-02]
21Feb13_113729| [-5.72126e-01 -1.12712e+00]
21Feb13_113729| [-6.00429e-02 -7.74199e-01]
21Feb13_113729| [ 1.10419e-01 -3.90905e-01]
21Feb13_113729| [-2.35151e+00 -1.19756e+00]
21Feb13_113729| [-7.19410e-01 -5.15445e-01]
21Feb13_113729| [ 7.11794e-01 -1.63341e-01]
21Feb13_113729| [-7.12856e-01 -1.26040e-01]
21Feb13_113729| [ 1.00583e+00 -4.07499e-01]
21Feb13_113729| [-4.46850e-01 -1.31896e+00]
21Feb13_113729| [ 6.83406e-02  2.95165e-01]
21Feb13_113729| [-7.73834e-01  4.39170e-01]
21Feb13_113729| [ 3.40113e-02 -1.19226e+00]
21Feb13_113729| [-1.90476e-01 -1.30555e+00]
21Feb13_113729| [-8.00537e-01  9.09884e-01]
21Feb13_113729| [ 8.79862e-01  5.55782e-01]
21Feb13_113729| [ 4.30997e-01 -3.58067e-01]
21Feb13_113729| [-6.68257e-01  2.38322e-01]]
21Feb13_113729|-- Bias --
21Feb13_113729|[-0.70906 -0.37669]
21Feb13_113729|Layer 1:
21Feb13_113729|-- Config --
21Feb13_113729|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113729|-- Weights --
21Feb13_113729|[[-0.94561  0.38942]
21Feb13_113729| [ 0.25172 -0.95334]]
21Feb13_113729|-- Bias --
21Feb13_113729|[-0.48591  0.74488]
21Feb13_113729|Layer 2:
21Feb13_113729|-- Config --
21Feb13_113729|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113729|-- Weights --
21Feb13_113729|[[ 1.63570  0.94691]
21Feb13_113729| [-0.10069  0.32775]]
21Feb13_113729|-- Bias --
21Feb13_113729|[0.40880 0.31931]
21Feb13_113729|Predicting the validation and test data with the Best final individual.
21Feb13_113736| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_113736|-----------  ------------------  --------------------  ----------
21Feb13_113736|Validation         25.48                  8             0.54811
21Feb13_113736|   Test            28.58                  8             0.35787
21Feb13_113736|-------------------- Test #2 --------------------
21Feb13_113736|Best final individual weights
21Feb13_113736|Individual:
21Feb13_113736|-- Constant hidden layers --
21Feb13_113736|False
21Feb13_113736|Layer 0:
21Feb13_113736|-- Config --
21Feb13_113736|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113736|-- Weights --
21Feb13_113736|[[ 1.74276e-01 -2.41590e-01]
21Feb13_113736| [ 1.77129e+00  4.54754e-01]
21Feb13_113736| [-1.87726e-01 -7.08215e-02]
21Feb13_113736| [ 1.67602e+00  1.07538e+00]
21Feb13_113736| [ 4.83300e-01  2.23842e-01]
21Feb13_113736| [ 1.21089e-01  8.43355e-01]
21Feb13_113736| [ 5.58188e-01  6.02878e-01]
21Feb13_113736| [ 9.80989e-01 -1.57022e+00]
21Feb13_113736| [-4.94314e-01  1.03493e-03]
21Feb13_113736| [ 6.50898e-01 -9.91301e-01]
21Feb13_113736| [ 1.21564e-01 -5.16848e-01]
21Feb13_113736| [ 2.05958e-02  7.65841e-01]
21Feb13_113736| [-1.19880e+00 -1.98384e-01]
21Feb13_113736| [ 1.40344e-01 -8.21092e-01]
21Feb13_113736| [ 8.66470e-01  6.10729e-01]
21Feb13_113736| [ 8.12148e-01 -4.05623e-01]
21Feb13_113736| [-1.93100e-01 -8.07256e-01]
21Feb13_113736| [-3.45548e-01 -3.86709e-03]
21Feb13_113736| [ 2.09207e-01 -2.40907e-01]
21Feb13_113736| [ 2.87175e-01 -4.04162e-01]
21Feb13_113736| [ 8.41330e-01  6.62044e-01]
21Feb13_113736| [ 6.85979e-01 -1.49782e+00]
21Feb13_113736| [-8.64047e-01 -4.42409e-01]
21Feb13_113736| [ 3.31760e-01 -3.46622e-01]
21Feb13_113736| [ 1.98449e+00 -1.68578e-01]
21Feb13_113736| [ 1.28383e+00 -5.72640e-01]
21Feb13_113736| [ 5.26745e-01  1.69675e+00]
21Feb13_113736| [ 2.00860e+00  1.52840e+00]
21Feb13_113736| [-1.76176e+00 -3.51036e-01]
21Feb13_113736| [-6.94774e-01  6.57618e-01]
21Feb13_113736| [ 3.70786e-01 -7.10144e-01]
21Feb13_113736| [-1.07489e+00 -2.87213e-01]
21Feb13_113736| [ 1.38837e+00  4.36522e-02]
21Feb13_113736| [-3.09496e-01  4.31557e-01]
21Feb13_113736| [ 1.94421e+00 -3.85891e-01]
21Feb13_113736| [ 1.13461e+00  3.53034e-01]
21Feb13_113736| [ 8.45985e-01  5.29180e-01]
21Feb13_113736| [ 9.77036e-01  9.19790e-02]
21Feb13_113736| [ 4.08182e-01 -2.17468e-01]
21Feb13_113736| [ 5.97516e-02  3.85639e-02]
21Feb13_113736| [-5.72126e-01 -1.12712e+00]
21Feb13_113736| [-6.00429e-02 -7.74199e-01]
21Feb13_113736| [ 1.10419e-01 -3.90905e-01]
21Feb13_113736| [-2.35151e+00 -1.19756e+00]
21Feb13_113736| [-7.19410e-01 -5.15445e-01]
21Feb13_113736| [ 7.11794e-01 -1.63341e-01]
21Feb13_113736| [-7.12856e-01 -1.26040e-01]
21Feb13_113736| [ 1.00583e+00 -4.07499e-01]
21Feb13_113736| [-4.46850e-01 -1.31896e+00]
21Feb13_113736| [ 6.83406e-02  2.95165e-01]
21Feb13_113736| [-7.73834e-01  4.39170e-01]
21Feb13_113736| [ 3.40113e-02 -1.19226e+00]
21Feb13_113736| [-1.90476e-01 -1.30555e+00]
21Feb13_113736| [-8.00537e-01  9.09884e-01]
21Feb13_113736| [ 8.79862e-01  5.55782e-01]
21Feb13_113736| [ 4.30997e-01 -3.58067e-01]
21Feb13_113736| [-6.68257e-01  2.38322e-01]]
21Feb13_113736|-- Bias --
21Feb13_113736|[-0.70906 -0.37669]
21Feb13_113736|Layer 1:
21Feb13_113736|-- Config --
21Feb13_113736|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113736|-- Weights --
21Feb13_113736|[[-0.94561  0.38942]
21Feb13_113736| [ 0.25172 -0.95334]]
21Feb13_113736|-- Bias --
21Feb13_113736|[-0.48591  0.74488]
21Feb13_113736|Layer 2:
21Feb13_113736|-- Config --
21Feb13_113736|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113736|-- Weights --
21Feb13_113736|[[ 1.63570  0.94691]
21Feb13_113736| [-0.10069  0.32775]]
21Feb13_113736|-- Bias --
21Feb13_113736|[0.40880 0.31931]
21Feb13_113736|Predicting the validation and test data with the Best final individual.
21Feb13_113744| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_113744|-----------  ------------------  --------------------  ----------
21Feb13_113744|Validation         27.13                  8             0.41877
21Feb13_113744|   Test            26.50                  8             0.43912
21Feb13_113744|-------------------- Test #3 --------------------
21Feb13_113744|Best final individual weights
21Feb13_113744|Individual:
21Feb13_113744|-- Constant hidden layers --
21Feb13_113744|False
21Feb13_113744|Layer 0:
21Feb13_113744|-- Config --
21Feb13_113744|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113744|-- Weights --
21Feb13_113744|[[ 1.74276e-01 -2.41590e-01]
21Feb13_113744| [ 1.77129e+00  4.54754e-01]
21Feb13_113744| [-1.87726e-01 -7.08215e-02]
21Feb13_113744| [ 1.67602e+00  1.07538e+00]
21Feb13_113744| [ 4.83300e-01  2.23842e-01]
21Feb13_113744| [ 1.21089e-01  8.43355e-01]
21Feb13_113744| [ 5.58188e-01  6.02878e-01]
21Feb13_113744| [ 9.80989e-01 -1.57022e+00]
21Feb13_113744| [-4.94314e-01  1.03493e-03]
21Feb13_113744| [ 6.50898e-01 -9.91301e-01]
21Feb13_113744| [ 1.21564e-01 -5.16848e-01]
21Feb13_113744| [ 2.05958e-02  7.65841e-01]
21Feb13_113744| [-1.19880e+00 -1.98384e-01]
21Feb13_113744| [ 1.40344e-01 -8.21092e-01]
21Feb13_113744| [ 8.66470e-01  6.10729e-01]
21Feb13_113744| [ 8.12148e-01 -4.05623e-01]
21Feb13_113744| [-1.93100e-01 -8.07256e-01]
21Feb13_113744| [-3.45548e-01 -3.86709e-03]
21Feb13_113744| [ 2.09207e-01 -2.40907e-01]
21Feb13_113744| [ 2.87175e-01 -4.04162e-01]
21Feb13_113744| [ 8.41330e-01  6.62044e-01]
21Feb13_113744| [ 6.85979e-01 -1.49782e+00]
21Feb13_113744| [-8.64047e-01 -4.42409e-01]
21Feb13_113744| [ 3.31760e-01 -3.46622e-01]
21Feb13_113744| [ 1.98449e+00 -1.68578e-01]
21Feb13_113744| [ 1.28383e+00 -5.72640e-01]
21Feb13_113744| [ 5.26745e-01  1.69675e+00]
21Feb13_113744| [ 2.00860e+00  1.52840e+00]
21Feb13_113744| [-1.76176e+00 -3.51036e-01]
21Feb13_113744| [-6.94774e-01  6.57618e-01]
21Feb13_113744| [ 3.70786e-01 -7.10144e-01]
21Feb13_113744| [-1.07489e+00 -2.87213e-01]
21Feb13_113744| [ 1.38837e+00  4.36522e-02]
21Feb13_113744| [-3.09496e-01  4.31557e-01]
21Feb13_113744| [ 1.94421e+00 -3.85891e-01]
21Feb13_113744| [ 1.13461e+00  3.53034e-01]
21Feb13_113744| [ 8.45985e-01  5.29180e-01]
21Feb13_113744| [ 9.77036e-01  9.19790e-02]
21Feb13_113744| [ 4.08182e-01 -2.17468e-01]
21Feb13_113744| [ 5.97516e-02  3.85639e-02]
21Feb13_113744| [-5.72126e-01 -1.12712e+00]
21Feb13_113744| [-6.00429e-02 -7.74199e-01]
21Feb13_113744| [ 1.10419e-01 -3.90905e-01]
21Feb13_113744| [-2.35151e+00 -1.19756e+00]
21Feb13_113744| [-7.19410e-01 -5.15445e-01]
21Feb13_113744| [ 7.11794e-01 -1.63341e-01]
21Feb13_113744| [-7.12856e-01 -1.26040e-01]
21Feb13_113744| [ 1.00583e+00 -4.07499e-01]
21Feb13_113744| [-4.46850e-01 -1.31896e+00]
21Feb13_113744| [ 6.83406e-02  2.95165e-01]
21Feb13_113744| [-7.73834e-01  4.39170e-01]
21Feb13_113744| [ 3.40113e-02 -1.19226e+00]
21Feb13_113744| [-1.90476e-01 -1.30555e+00]
21Feb13_113744| [-8.00537e-01  9.09884e-01]
21Feb13_113744| [ 8.79862e-01  5.55782e-01]
21Feb13_113744| [ 4.30997e-01 -3.58067e-01]
21Feb13_113744| [-6.68257e-01  2.38322e-01]]
21Feb13_113744|-- Bias --
21Feb13_113744|[-0.70906 -0.37669]
21Feb13_113744|Layer 1:
21Feb13_113744|-- Config --
21Feb13_113744|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113744|-- Weights --
21Feb13_113744|[[-0.94561  0.38942]
21Feb13_113744| [ 0.25172 -0.95334]]
21Feb13_113744|-- Bias --
21Feb13_113744|[-0.48591  0.74488]
21Feb13_113744|Layer 2:
21Feb13_113744|-- Config --
21Feb13_113744|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113744|-- Weights --
21Feb13_113744|[[ 1.63570  0.94691]
21Feb13_113744| [-0.10069  0.32775]]
21Feb13_113744|-- Bias --
21Feb13_113744|[0.40880 0.31931]
21Feb13_113744|Predicting the validation and test data with the Best final individual.
21Feb13_113751| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_113751|-----------  ------------------  --------------------  ----------
21Feb13_113751|Validation         30.09                  8             0.28887
21Feb13_113751|   Test            30.41                  8             0.29151
21Feb13_113751|-------------------- Test #4 --------------------
21Feb13_113751|Best final individual weights
21Feb13_113751|Individual:
21Feb13_113751|-- Constant hidden layers --
21Feb13_113751|False
21Feb13_113751|Layer 0:
21Feb13_113751|-- Config --
21Feb13_113751|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113751|-- Weights --
21Feb13_113751|[[ 1.74276e-01 -2.41590e-01]
21Feb13_113751| [ 1.77129e+00  4.54754e-01]
21Feb13_113751| [-1.87726e-01 -7.08215e-02]
21Feb13_113751| [ 1.67602e+00  1.07538e+00]
21Feb13_113751| [ 4.83300e-01  2.23842e-01]
21Feb13_113751| [ 1.21089e-01  8.43355e-01]
21Feb13_113751| [ 5.58188e-01  6.02878e-01]
21Feb13_113751| [ 9.80989e-01 -1.57022e+00]
21Feb13_113751| [-4.94314e-01  1.03493e-03]
21Feb13_113751| [ 6.50898e-01 -9.91301e-01]
21Feb13_113751| [ 1.21564e-01 -5.16848e-01]
21Feb13_113751| [ 2.05958e-02  7.65841e-01]
21Feb13_113751| [-1.19880e+00 -1.98384e-01]
21Feb13_113751| [ 1.40344e-01 -8.21092e-01]
21Feb13_113751| [ 8.66470e-01  6.10729e-01]
21Feb13_113751| [ 8.12148e-01 -4.05623e-01]
21Feb13_113751| [-1.93100e-01 -8.07256e-01]
21Feb13_113751| [-3.45548e-01 -3.86709e-03]
21Feb13_113751| [ 2.09207e-01 -2.40907e-01]
21Feb13_113751| [ 2.87175e-01 -4.04162e-01]
21Feb13_113751| [ 8.41330e-01  6.62044e-01]
21Feb13_113751| [ 6.85979e-01 -1.49782e+00]
21Feb13_113751| [-8.64047e-01 -4.42409e-01]
21Feb13_113751| [ 3.31760e-01 -3.46622e-01]
21Feb13_113751| [ 1.98449e+00 -1.68578e-01]
21Feb13_113751| [ 1.28383e+00 -5.72640e-01]
21Feb13_113751| [ 5.26745e-01  1.69675e+00]
21Feb13_113751| [ 2.00860e+00  1.52840e+00]
21Feb13_113751| [-1.76176e+00 -3.51036e-01]
21Feb13_113751| [-6.94774e-01  6.57618e-01]
21Feb13_113751| [ 3.70786e-01 -7.10144e-01]
21Feb13_113751| [-1.07489e+00 -2.87213e-01]
21Feb13_113751| [ 1.38837e+00  4.36522e-02]
21Feb13_113751| [-3.09496e-01  4.31557e-01]
21Feb13_113751| [ 1.94421e+00 -3.85891e-01]
21Feb13_113751| [ 1.13461e+00  3.53034e-01]
21Feb13_113751| [ 8.45985e-01  5.29180e-01]
21Feb13_113751| [ 9.77036e-01  9.19790e-02]
21Feb13_113751| [ 4.08182e-01 -2.17468e-01]
21Feb13_113751| [ 5.97516e-02  3.85639e-02]
21Feb13_113751| [-5.72126e-01 -1.12712e+00]
21Feb13_113751| [-6.00429e-02 -7.74199e-01]
21Feb13_113751| [ 1.10419e-01 -3.90905e-01]
21Feb13_113751| [-2.35151e+00 -1.19756e+00]
21Feb13_113751| [-7.19410e-01 -5.15445e-01]
21Feb13_113751| [ 7.11794e-01 -1.63341e-01]
21Feb13_113751| [-7.12856e-01 -1.26040e-01]
21Feb13_113751| [ 1.00583e+00 -4.07499e-01]
21Feb13_113751| [-4.46850e-01 -1.31896e+00]
21Feb13_113751| [ 6.83406e-02  2.95165e-01]
21Feb13_113751| [-7.73834e-01  4.39170e-01]
21Feb13_113751| [ 3.40113e-02 -1.19226e+00]
21Feb13_113751| [-1.90476e-01 -1.30555e+00]
21Feb13_113751| [-8.00537e-01  9.09884e-01]
21Feb13_113751| [ 8.79862e-01  5.55782e-01]
21Feb13_113751| [ 4.30997e-01 -3.58067e-01]
21Feb13_113751| [-6.68257e-01  2.38322e-01]]
21Feb13_113751|-- Bias --
21Feb13_113751|[-0.70906 -0.37669]
21Feb13_113751|Layer 1:
21Feb13_113751|-- Config --
21Feb13_113751|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113751|-- Weights --
21Feb13_113751|[[-0.94561  0.38942]
21Feb13_113751| [ 0.25172 -0.95334]]
21Feb13_113751|-- Bias --
21Feb13_113751|[-0.48591  0.74488]
21Feb13_113751|Layer 2:
21Feb13_113751|-- Config --
21Feb13_113751|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113751|-- Weights --
21Feb13_113751|[[ 1.63570  0.94691]
21Feb13_113751| [-0.10069  0.32775]]
21Feb13_113751|-- Bias --
21Feb13_113751|[0.40880 0.31931]
21Feb13_113751|Predicting the validation and test data with the Best final individual.
21Feb13_113759| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_113759|-----------  ------------------  --------------------  ----------
21Feb13_113759|Validation         38.78                  8             0.00000
21Feb13_113759|   Test            30.50                  8             0.29136
21Feb13_113759|-------------------- Test #5 --------------------
21Feb13_113759|Best final individual weights
21Feb13_113759|Individual:
21Feb13_113759|-- Constant hidden layers --
21Feb13_113759|False
21Feb13_113759|Layer 0:
21Feb13_113759|-- Config --
21Feb13_113759|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113759|-- Weights --
21Feb13_113759|[[ 1.74276e-01 -2.41590e-01]
21Feb13_113759| [ 1.77129e+00  4.54754e-01]
21Feb13_113759| [-1.87726e-01 -7.08215e-02]
21Feb13_113759| [ 1.67602e+00  1.07538e+00]
21Feb13_113759| [ 4.83300e-01  2.23842e-01]
21Feb13_113759| [ 1.21089e-01  8.43355e-01]
21Feb13_113759| [ 5.58188e-01  6.02878e-01]
21Feb13_113759| [ 9.80989e-01 -1.57022e+00]
21Feb13_113759| [-4.94314e-01  1.03493e-03]
21Feb13_113759| [ 6.50898e-01 -9.91301e-01]
21Feb13_113759| [ 1.21564e-01 -5.16848e-01]
21Feb13_113759| [ 2.05958e-02  7.65841e-01]
21Feb13_113759| [-1.19880e+00 -1.98384e-01]
21Feb13_113759| [ 1.40344e-01 -8.21092e-01]
21Feb13_113759| [ 8.66470e-01  6.10729e-01]
21Feb13_113759| [ 8.12148e-01 -4.05623e-01]
21Feb13_113759| [-1.93100e-01 -8.07256e-01]
21Feb13_113759| [-3.45548e-01 -3.86709e-03]
21Feb13_113759| [ 2.09207e-01 -2.40907e-01]
21Feb13_113759| [ 2.87175e-01 -4.04162e-01]
21Feb13_113759| [ 8.41330e-01  6.62044e-01]
21Feb13_113759| [ 6.85979e-01 -1.49782e+00]
21Feb13_113759| [-8.64047e-01 -4.42409e-01]
21Feb13_113759| [ 3.31760e-01 -3.46622e-01]
21Feb13_113759| [ 1.98449e+00 -1.68578e-01]
21Feb13_113759| [ 1.28383e+00 -5.72640e-01]
21Feb13_113759| [ 5.26745e-01  1.69675e+00]
21Feb13_113759| [ 2.00860e+00  1.52840e+00]
21Feb13_113759| [-1.76176e+00 -3.51036e-01]
21Feb13_113759| [-6.94774e-01  6.57618e-01]
21Feb13_113759| [ 3.70786e-01 -7.10144e-01]
21Feb13_113759| [-1.07489e+00 -2.87213e-01]
21Feb13_113759| [ 1.38837e+00  4.36522e-02]
21Feb13_113759| [-3.09496e-01  4.31557e-01]
21Feb13_113759| [ 1.94421e+00 -3.85891e-01]
21Feb13_113759| [ 1.13461e+00  3.53034e-01]
21Feb13_113759| [ 8.45985e-01  5.29180e-01]
21Feb13_113759| [ 9.77036e-01  9.19790e-02]
21Feb13_113759| [ 4.08182e-01 -2.17468e-01]
21Feb13_113759| [ 5.97516e-02  3.85639e-02]
21Feb13_113759| [-5.72126e-01 -1.12712e+00]
21Feb13_113759| [-6.00429e-02 -7.74199e-01]
21Feb13_113759| [ 1.10419e-01 -3.90905e-01]
21Feb13_113759| [-2.35151e+00 -1.19756e+00]
21Feb13_113759| [-7.19410e-01 -5.15445e-01]
21Feb13_113759| [ 7.11794e-01 -1.63341e-01]
21Feb13_113759| [-7.12856e-01 -1.26040e-01]
21Feb13_113759| [ 1.00583e+00 -4.07499e-01]
21Feb13_113759| [-4.46850e-01 -1.31896e+00]
21Feb13_113759| [ 6.83406e-02  2.95165e-01]
21Feb13_113759| [-7.73834e-01  4.39170e-01]
21Feb13_113759| [ 3.40113e-02 -1.19226e+00]
21Feb13_113759| [-1.90476e-01 -1.30555e+00]
21Feb13_113759| [-8.00537e-01  9.09884e-01]
21Feb13_113759| [ 8.79862e-01  5.55782e-01]
21Feb13_113759| [ 4.30997e-01 -3.58067e-01]
21Feb13_113759| [-6.68257e-01  2.38322e-01]]
21Feb13_113759|-- Bias --
21Feb13_113759|[-0.70906 -0.37669]
21Feb13_113759|Layer 1:
21Feb13_113759|-- Config --
21Feb13_113759|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113759|-- Weights --
21Feb13_113759|[[-0.94561  0.38942]
21Feb13_113759| [ 0.25172 -0.95334]]
21Feb13_113759|-- Bias --
21Feb13_113759|[-0.48591  0.74488]
21Feb13_113759|Layer 2:
21Feb13_113759|-- Config --
21Feb13_113759|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113759|-- Weights --
21Feb13_113759|[[ 1.63570  0.94691]
21Feb13_113759| [-0.10069  0.32775]]
21Feb13_113759|-- Bias --
21Feb13_113759|[0.40880 0.31931]
21Feb13_113759|Predicting the validation and test data with the Best final individual.
21Feb13_113806| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_113806|-----------  ------------------  --------------------  ----------
21Feb13_113806|Validation         27.30                  8             0.39929
21Feb13_113806|   Test            31.54                  8             0.25000
21Feb13_113806|-------------------- Test #6 --------------------
21Feb13_113806|Best final individual weights
21Feb13_113806|Individual:
21Feb13_113806|-- Constant hidden layers --
21Feb13_113806|False
21Feb13_113806|Layer 0:
21Feb13_113806|-- Config --
21Feb13_113806|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113806|-- Weights --
21Feb13_113806|[[ 1.74276e-01 -2.41590e-01]
21Feb13_113806| [ 1.77129e+00  4.54754e-01]
21Feb13_113806| [-1.87726e-01 -7.08215e-02]
21Feb13_113806| [ 1.67602e+00  1.07538e+00]
21Feb13_113806| [ 4.83300e-01  2.23842e-01]
21Feb13_113806| [ 1.21089e-01  8.43355e-01]
21Feb13_113806| [ 5.58188e-01  6.02878e-01]
21Feb13_113806| [ 9.80989e-01 -1.57022e+00]
21Feb13_113806| [-4.94314e-01  1.03493e-03]
21Feb13_113806| [ 6.50898e-01 -9.91301e-01]
21Feb13_113806| [ 1.21564e-01 -5.16848e-01]
21Feb13_113806| [ 2.05958e-02  7.65841e-01]
21Feb13_113806| [-1.19880e+00 -1.98384e-01]
21Feb13_113806| [ 1.40344e-01 -8.21092e-01]
21Feb13_113806| [ 8.66470e-01  6.10729e-01]
21Feb13_113806| [ 8.12148e-01 -4.05623e-01]
21Feb13_113806| [-1.93100e-01 -8.07256e-01]
21Feb13_113806| [-3.45548e-01 -3.86709e-03]
21Feb13_113806| [ 2.09207e-01 -2.40907e-01]
21Feb13_113806| [ 2.87175e-01 -4.04162e-01]
21Feb13_113806| [ 8.41330e-01  6.62044e-01]
21Feb13_113806| [ 6.85979e-01 -1.49782e+00]
21Feb13_113806| [-8.64047e-01 -4.42409e-01]
21Feb13_113806| [ 3.31760e-01 -3.46622e-01]
21Feb13_113806| [ 1.98449e+00 -1.68578e-01]
21Feb13_113806| [ 1.28383e+00 -5.72640e-01]
21Feb13_113806| [ 5.26745e-01  1.69675e+00]
21Feb13_113806| [ 2.00860e+00  1.52840e+00]
21Feb13_113806| [-1.76176e+00 -3.51036e-01]
21Feb13_113806| [-6.94774e-01  6.57618e-01]
21Feb13_113806| [ 3.70786e-01 -7.10144e-01]
21Feb13_113806| [-1.07489e+00 -2.87213e-01]
21Feb13_113806| [ 1.38837e+00  4.36522e-02]
21Feb13_113806| [-3.09496e-01  4.31557e-01]
21Feb13_113806| [ 1.94421e+00 -3.85891e-01]
21Feb13_113806| [ 1.13461e+00  3.53034e-01]
21Feb13_113806| [ 8.45985e-01  5.29180e-01]
21Feb13_113806| [ 9.77036e-01  9.19790e-02]
21Feb13_113806| [ 4.08182e-01 -2.17468e-01]
21Feb13_113806| [ 5.97516e-02  3.85639e-02]
21Feb13_113806| [-5.72126e-01 -1.12712e+00]
21Feb13_113806| [-6.00429e-02 -7.74199e-01]
21Feb13_113806| [ 1.10419e-01 -3.90905e-01]
21Feb13_113806| [-2.35151e+00 -1.19756e+00]
21Feb13_113806| [-7.19410e-01 -5.15445e-01]
21Feb13_113806| [ 7.11794e-01 -1.63341e-01]
21Feb13_113806| [-7.12856e-01 -1.26040e-01]
21Feb13_113806| [ 1.00583e+00 -4.07499e-01]
21Feb13_113806| [-4.46850e-01 -1.31896e+00]
21Feb13_113806| [ 6.83406e-02  2.95165e-01]
21Feb13_113806| [-7.73834e-01  4.39170e-01]
21Feb13_113806| [ 3.40113e-02 -1.19226e+00]
21Feb13_113806| [-1.90476e-01 -1.30555e+00]
21Feb13_113806| [-8.00537e-01  9.09884e-01]
21Feb13_113806| [ 8.79862e-01  5.55782e-01]
21Feb13_113806| [ 4.30997e-01 -3.58067e-01]
21Feb13_113806| [-6.68257e-01  2.38322e-01]]
21Feb13_113806|-- Bias --
21Feb13_113806|[-0.70906 -0.37669]
21Feb13_113806|Layer 1:
21Feb13_113806|-- Config --
21Feb13_113806|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113806|-- Weights --
21Feb13_113806|[[-0.94561  0.38942]
21Feb13_113806| [ 0.25172 -0.95334]]
21Feb13_113806|-- Bias --
21Feb13_113806|[-0.48591  0.74488]
21Feb13_113806|Layer 2:
21Feb13_113806|-- Config --
21Feb13_113806|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113806|-- Weights --
21Feb13_113806|[[ 1.63570  0.94691]
21Feb13_113806| [-0.10069  0.32775]]
21Feb13_113806|-- Bias --
21Feb13_113806|[0.40880 0.31931]
21Feb13_113806|Predicting the validation and test data with the Best final individual.
21Feb13_113814| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_113814|-----------  ------------------  --------------------  ----------
21Feb13_113814|Validation         26.00                  8             0.56501
21Feb13_113814|   Test            27.63                  8             0.40513
21Feb13_113814|-------------------- Test #7 --------------------
21Feb13_113814|Best final individual weights
21Feb13_113814|Individual:
21Feb13_113814|-- Constant hidden layers --
21Feb13_113814|False
21Feb13_113814|Layer 0:
21Feb13_113814|-- Config --
21Feb13_113814|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113814|-- Weights --
21Feb13_113814|[[ 1.74276e-01 -2.41590e-01]
21Feb13_113814| [ 1.77129e+00  4.54754e-01]
21Feb13_113814| [-1.87726e-01 -7.08215e-02]
21Feb13_113814| [ 1.67602e+00  1.07538e+00]
21Feb13_113814| [ 4.83300e-01  2.23842e-01]
21Feb13_113814| [ 1.21089e-01  8.43355e-01]
21Feb13_113814| [ 5.58188e-01  6.02878e-01]
21Feb13_113814| [ 9.80989e-01 -1.57022e+00]
21Feb13_113814| [-4.94314e-01  1.03493e-03]
21Feb13_113814| [ 6.50898e-01 -9.91301e-01]
21Feb13_113814| [ 1.21564e-01 -5.16848e-01]
21Feb13_113814| [ 2.05958e-02  7.65841e-01]
21Feb13_113814| [-1.19880e+00 -1.98384e-01]
21Feb13_113814| [ 1.40344e-01 -8.21092e-01]
21Feb13_113814| [ 8.66470e-01  6.10729e-01]
21Feb13_113814| [ 8.12148e-01 -4.05623e-01]
21Feb13_113814| [-1.93100e-01 -8.07256e-01]
21Feb13_113814| [-3.45548e-01 -3.86709e-03]
21Feb13_113814| [ 2.09207e-01 -2.40907e-01]
21Feb13_113814| [ 2.87175e-01 -4.04162e-01]
21Feb13_113814| [ 8.41330e-01  6.62044e-01]
21Feb13_113814| [ 6.85979e-01 -1.49782e+00]
21Feb13_113814| [-8.64047e-01 -4.42409e-01]
21Feb13_113814| [ 3.31760e-01 -3.46622e-01]
21Feb13_113814| [ 1.98449e+00 -1.68578e-01]
21Feb13_113814| [ 1.28383e+00 -5.72640e-01]
21Feb13_113814| [ 5.26745e-01  1.69675e+00]
21Feb13_113814| [ 2.00860e+00  1.52840e+00]
21Feb13_113814| [-1.76176e+00 -3.51036e-01]
21Feb13_113814| [-6.94774e-01  6.57618e-01]
21Feb13_113814| [ 3.70786e-01 -7.10144e-01]
21Feb13_113814| [-1.07489e+00 -2.87213e-01]
21Feb13_113814| [ 1.38837e+00  4.36522e-02]
21Feb13_113814| [-3.09496e-01  4.31557e-01]
21Feb13_113814| [ 1.94421e+00 -3.85891e-01]
21Feb13_113814| [ 1.13461e+00  3.53034e-01]
21Feb13_113814| [ 8.45985e-01  5.29180e-01]
21Feb13_113814| [ 9.77036e-01  9.19790e-02]
21Feb13_113814| [ 4.08182e-01 -2.17468e-01]
21Feb13_113814| [ 5.97516e-02  3.85639e-02]
21Feb13_113814| [-5.72126e-01 -1.12712e+00]
21Feb13_113814| [-6.00429e-02 -7.74199e-01]
21Feb13_113814| [ 1.10419e-01 -3.90905e-01]
21Feb13_113814| [-2.35151e+00 -1.19756e+00]
21Feb13_113814| [-7.19410e-01 -5.15445e-01]
21Feb13_113814| [ 7.11794e-01 -1.63341e-01]
21Feb13_113814| [-7.12856e-01 -1.26040e-01]
21Feb13_113814| [ 1.00583e+00 -4.07499e-01]
21Feb13_113814| [-4.46850e-01 -1.31896e+00]
21Feb13_113814| [ 6.83406e-02  2.95165e-01]
21Feb13_113814| [-7.73834e-01  4.39170e-01]
21Feb13_113814| [ 3.40113e-02 -1.19226e+00]
21Feb13_113814| [-1.90476e-01 -1.30555e+00]
21Feb13_113814| [-8.00537e-01  9.09884e-01]
21Feb13_113814| [ 8.79862e-01  5.55782e-01]
21Feb13_113814| [ 4.30997e-01 -3.58067e-01]
21Feb13_113814| [-6.68257e-01  2.38322e-01]]
21Feb13_113814|-- Bias --
21Feb13_113814|[-0.70906 -0.37669]
21Feb13_113814|Layer 1:
21Feb13_113814|-- Config --
21Feb13_113814|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113814|-- Weights --
21Feb13_113814|[[-0.94561  0.38942]
21Feb13_113814| [ 0.25172 -0.95334]]
21Feb13_113814|-- Bias --
21Feb13_113814|[-0.48591  0.74488]
21Feb13_113814|Layer 2:
21Feb13_113814|-- Config --
21Feb13_113814|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113814|-- Weights --
21Feb13_113814|[[ 1.63570  0.94691]
21Feb13_113814| [-0.10069  0.32775]]
21Feb13_113814|-- Bias --
21Feb13_113814|[0.40880 0.31931]
21Feb13_113814|Predicting the validation and test data with the Best final individual.
21Feb13_113821| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_113821|-----------  ------------------  --------------------  ----------
21Feb13_113821|Validation         25.13                  8             0.51100
21Feb13_113821|   Test            30.06                  8             0.31266
21Feb13_113821|-------------------- Test #8 --------------------
21Feb13_113821|Best final individual weights
21Feb13_113821|Individual:
21Feb13_113821|-- Constant hidden layers --
21Feb13_113821|False
21Feb13_113821|Layer 0:
21Feb13_113821|-- Config --
21Feb13_113821|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113821|-- Weights --
21Feb13_113821|[[ 1.74276e-01 -2.41590e-01]
21Feb13_113821| [ 1.77129e+00  4.54754e-01]
21Feb13_113821| [-1.87726e-01 -7.08215e-02]
21Feb13_113821| [ 1.67602e+00  1.07538e+00]
21Feb13_113821| [ 4.83300e-01  2.23842e-01]
21Feb13_113821| [ 1.21089e-01  8.43355e-01]
21Feb13_113821| [ 5.58188e-01  6.02878e-01]
21Feb13_113821| [ 9.80989e-01 -1.57022e+00]
21Feb13_113821| [-4.94314e-01  1.03493e-03]
21Feb13_113821| [ 6.50898e-01 -9.91301e-01]
21Feb13_113821| [ 1.21564e-01 -5.16848e-01]
21Feb13_113821| [ 2.05958e-02  7.65841e-01]
21Feb13_113821| [-1.19880e+00 -1.98384e-01]
21Feb13_113821| [ 1.40344e-01 -8.21092e-01]
21Feb13_113821| [ 8.66470e-01  6.10729e-01]
21Feb13_113821| [ 8.12148e-01 -4.05623e-01]
21Feb13_113821| [-1.93100e-01 -8.07256e-01]
21Feb13_113821| [-3.45548e-01 -3.86709e-03]
21Feb13_113821| [ 2.09207e-01 -2.40907e-01]
21Feb13_113821| [ 2.87175e-01 -4.04162e-01]
21Feb13_113821| [ 8.41330e-01  6.62044e-01]
21Feb13_113821| [ 6.85979e-01 -1.49782e+00]
21Feb13_113821| [-8.64047e-01 -4.42409e-01]
21Feb13_113821| [ 3.31760e-01 -3.46622e-01]
21Feb13_113821| [ 1.98449e+00 -1.68578e-01]
21Feb13_113821| [ 1.28383e+00 -5.72640e-01]
21Feb13_113821| [ 5.26745e-01  1.69675e+00]
21Feb13_113821| [ 2.00860e+00  1.52840e+00]
21Feb13_113821| [-1.76176e+00 -3.51036e-01]
21Feb13_113821| [-6.94774e-01  6.57618e-01]
21Feb13_113821| [ 3.70786e-01 -7.10144e-01]
21Feb13_113821| [-1.07489e+00 -2.87213e-01]
21Feb13_113821| [ 1.38837e+00  4.36522e-02]
21Feb13_113821| [-3.09496e-01  4.31557e-01]
21Feb13_113821| [ 1.94421e+00 -3.85891e-01]
21Feb13_113821| [ 1.13461e+00  3.53034e-01]
21Feb13_113821| [ 8.45985e-01  5.29180e-01]
21Feb13_113821| [ 9.77036e-01  9.19790e-02]
21Feb13_113821| [ 4.08182e-01 -2.17468e-01]
21Feb13_113821| [ 5.97516e-02  3.85639e-02]
21Feb13_113821| [-5.72126e-01 -1.12712e+00]
21Feb13_113821| [-6.00429e-02 -7.74199e-01]
21Feb13_113821| [ 1.10419e-01 -3.90905e-01]
21Feb13_113821| [-2.35151e+00 -1.19756e+00]
21Feb13_113821| [-7.19410e-01 -5.15445e-01]
21Feb13_113821| [ 7.11794e-01 -1.63341e-01]
21Feb13_113821| [-7.12856e-01 -1.26040e-01]
21Feb13_113821| [ 1.00583e+00 -4.07499e-01]
21Feb13_113821| [-4.46850e-01 -1.31896e+00]
21Feb13_113821| [ 6.83406e-02  2.95165e-01]
21Feb13_113821| [-7.73834e-01  4.39170e-01]
21Feb13_113821| [ 3.40113e-02 -1.19226e+00]
21Feb13_113821| [-1.90476e-01 -1.30555e+00]
21Feb13_113821| [-8.00537e-01  9.09884e-01]
21Feb13_113821| [ 8.79862e-01  5.55782e-01]
21Feb13_113821| [ 4.30997e-01 -3.58067e-01]
21Feb13_113821| [-6.68257e-01  2.38322e-01]]
21Feb13_113821|-- Bias --
21Feb13_113821|[-0.70906 -0.37669]
21Feb13_113821|Layer 1:
21Feb13_113821|-- Config --
21Feb13_113821|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113821|-- Weights --
21Feb13_113821|[[-0.94561  0.38942]
21Feb13_113821| [ 0.25172 -0.95334]]
21Feb13_113821|-- Bias --
21Feb13_113821|[-0.48591  0.74488]
21Feb13_113821|Layer 2:
21Feb13_113821|-- Config --
21Feb13_113821|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113821|-- Weights --
21Feb13_113821|[[ 1.63570  0.94691]
21Feb13_113821| [-0.10069  0.32775]]
21Feb13_113821|-- Bias --
21Feb13_113821|[0.40880 0.31931]
21Feb13_113821|Predicting the validation and test data with the Best final individual.
21Feb13_113828| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_113828|-----------  ------------------  --------------------  ----------
21Feb13_113828|Validation         25.30                  8             0.53356
21Feb13_113828|   Test            29.89                  8             0.31750
21Feb13_113828|-------------------- Test #9 --------------------
21Feb13_113828|Best final individual weights
21Feb13_113828|Individual:
21Feb13_113828|-- Constant hidden layers --
21Feb13_113828|False
21Feb13_113828|Layer 0:
21Feb13_113828|-- Config --
21Feb13_113828|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113828|-- Weights --
21Feb13_113828|[[ 1.74276e-01 -2.41590e-01]
21Feb13_113828| [ 1.77129e+00  4.54754e-01]
21Feb13_113828| [-1.87726e-01 -7.08215e-02]
21Feb13_113828| [ 1.67602e+00  1.07538e+00]
21Feb13_113828| [ 4.83300e-01  2.23842e-01]
21Feb13_113828| [ 1.21089e-01  8.43355e-01]
21Feb13_113828| [ 5.58188e-01  6.02878e-01]
21Feb13_113828| [ 9.80989e-01 -1.57022e+00]
21Feb13_113828| [-4.94314e-01  1.03493e-03]
21Feb13_113828| [ 6.50898e-01 -9.91301e-01]
21Feb13_113828| [ 1.21564e-01 -5.16848e-01]
21Feb13_113828| [ 2.05958e-02  7.65841e-01]
21Feb13_113828| [-1.19880e+00 -1.98384e-01]
21Feb13_113828| [ 1.40344e-01 -8.21092e-01]
21Feb13_113828| [ 8.66470e-01  6.10729e-01]
21Feb13_113828| [ 8.12148e-01 -4.05623e-01]
21Feb13_113828| [-1.93100e-01 -8.07256e-01]
21Feb13_113828| [-3.45548e-01 -3.86709e-03]
21Feb13_113828| [ 2.09207e-01 -2.40907e-01]
21Feb13_113828| [ 2.87175e-01 -4.04162e-01]
21Feb13_113828| [ 8.41330e-01  6.62044e-01]
21Feb13_113828| [ 6.85979e-01 -1.49782e+00]
21Feb13_113828| [-8.64047e-01 -4.42409e-01]
21Feb13_113828| [ 3.31760e-01 -3.46622e-01]
21Feb13_113828| [ 1.98449e+00 -1.68578e-01]
21Feb13_113828| [ 1.28383e+00 -5.72640e-01]
21Feb13_113828| [ 5.26745e-01  1.69675e+00]
21Feb13_113828| [ 2.00860e+00  1.52840e+00]
21Feb13_113828| [-1.76176e+00 -3.51036e-01]
21Feb13_113828| [-6.94774e-01  6.57618e-01]
21Feb13_113828| [ 3.70786e-01 -7.10144e-01]
21Feb13_113828| [-1.07489e+00 -2.87213e-01]
21Feb13_113828| [ 1.38837e+00  4.36522e-02]
21Feb13_113828| [-3.09496e-01  4.31557e-01]
21Feb13_113828| [ 1.94421e+00 -3.85891e-01]
21Feb13_113828| [ 1.13461e+00  3.53034e-01]
21Feb13_113828| [ 8.45985e-01  5.29180e-01]
21Feb13_113828| [ 9.77036e-01  9.19790e-02]
21Feb13_113828| [ 4.08182e-01 -2.17468e-01]
21Feb13_113828| [ 5.97516e-02  3.85639e-02]
21Feb13_113828| [-5.72126e-01 -1.12712e+00]
21Feb13_113828| [-6.00429e-02 -7.74199e-01]
21Feb13_113828| [ 1.10419e-01 -3.90905e-01]
21Feb13_113828| [-2.35151e+00 -1.19756e+00]
21Feb13_113828| [-7.19410e-01 -5.15445e-01]
21Feb13_113828| [ 7.11794e-01 -1.63341e-01]
21Feb13_113828| [-7.12856e-01 -1.26040e-01]
21Feb13_113828| [ 1.00583e+00 -4.07499e-01]
21Feb13_113828| [-4.46850e-01 -1.31896e+00]
21Feb13_113828| [ 6.83406e-02  2.95165e-01]
21Feb13_113828| [-7.73834e-01  4.39170e-01]
21Feb13_113828| [ 3.40113e-02 -1.19226e+00]
21Feb13_113828| [-1.90476e-01 -1.30555e+00]
21Feb13_113828| [-8.00537e-01  9.09884e-01]
21Feb13_113828| [ 8.79862e-01  5.55782e-01]
21Feb13_113828| [ 4.30997e-01 -3.58067e-01]
21Feb13_113828| [-6.68257e-01  2.38322e-01]]
21Feb13_113828|-- Bias --
21Feb13_113828|[-0.70906 -0.37669]
21Feb13_113828|Layer 1:
21Feb13_113828|-- Config --
21Feb13_113828|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113828|-- Weights --
21Feb13_113828|[[-0.94561  0.38942]
21Feb13_113828| [ 0.25172 -0.95334]]
21Feb13_113828|-- Bias --
21Feb13_113828|[-0.48591  0.74488]
21Feb13_113828|Layer 2:
21Feb13_113828|-- Config --
21Feb13_113828|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113828|-- Weights --
21Feb13_113828|[[ 1.63570  0.94691]
21Feb13_113828| [-0.10069  0.32775]]
21Feb13_113828|-- Bias --
21Feb13_113828|[0.40880 0.31931]
21Feb13_113828|Predicting the validation and test data with the Best final individual.
21Feb13_113836| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_113836|-----------  ------------------  --------------------  ----------
21Feb13_113836|Validation         29.22                  8             0.31348
21Feb13_113836|   Test            26.85                  8             0.42585
21Feb13_113836|-------------------- Test #10 --------------------
21Feb13_113836|Best final individual weights
21Feb13_113836|Individual:
21Feb13_113836|-- Constant hidden layers --
21Feb13_113836|False
21Feb13_113836|Layer 0:
21Feb13_113836|-- Config --
21Feb13_113836|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113836|-- Weights --
21Feb13_113836|[[ 1.74276e-01 -2.41590e-01]
21Feb13_113836| [ 1.77129e+00  4.54754e-01]
21Feb13_113836| [-1.87726e-01 -7.08215e-02]
21Feb13_113836| [ 1.67602e+00  1.07538e+00]
21Feb13_113836| [ 4.83300e-01  2.23842e-01]
21Feb13_113836| [ 1.21089e-01  8.43355e-01]
21Feb13_113836| [ 5.58188e-01  6.02878e-01]
21Feb13_113836| [ 9.80989e-01 -1.57022e+00]
21Feb13_113836| [-4.94314e-01  1.03493e-03]
21Feb13_113836| [ 6.50898e-01 -9.91301e-01]
21Feb13_113836| [ 1.21564e-01 -5.16848e-01]
21Feb13_113836| [ 2.05958e-02  7.65841e-01]
21Feb13_113836| [-1.19880e+00 -1.98384e-01]
21Feb13_113836| [ 1.40344e-01 -8.21092e-01]
21Feb13_113836| [ 8.66470e-01  6.10729e-01]
21Feb13_113836| [ 8.12148e-01 -4.05623e-01]
21Feb13_113836| [-1.93100e-01 -8.07256e-01]
21Feb13_113836| [-3.45548e-01 -3.86709e-03]
21Feb13_113836| [ 2.09207e-01 -2.40907e-01]
21Feb13_113836| [ 2.87175e-01 -4.04162e-01]
21Feb13_113836| [ 8.41330e-01  6.62044e-01]
21Feb13_113836| [ 6.85979e-01 -1.49782e+00]
21Feb13_113836| [-8.64047e-01 -4.42409e-01]
21Feb13_113836| [ 3.31760e-01 -3.46622e-01]
21Feb13_113836| [ 1.98449e+00 -1.68578e-01]
21Feb13_113836| [ 1.28383e+00 -5.72640e-01]
21Feb13_113836| [ 5.26745e-01  1.69675e+00]
21Feb13_113836| [ 2.00860e+00  1.52840e+00]
21Feb13_113836| [-1.76176e+00 -3.51036e-01]
21Feb13_113836| [-6.94774e-01  6.57618e-01]
21Feb13_113836| [ 3.70786e-01 -7.10144e-01]
21Feb13_113836| [-1.07489e+00 -2.87213e-01]
21Feb13_113836| [ 1.38837e+00  4.36522e-02]
21Feb13_113836| [-3.09496e-01  4.31557e-01]
21Feb13_113836| [ 1.94421e+00 -3.85891e-01]
21Feb13_113836| [ 1.13461e+00  3.53034e-01]
21Feb13_113836| [ 8.45985e-01  5.29180e-01]
21Feb13_113836| [ 9.77036e-01  9.19790e-02]
21Feb13_113836| [ 4.08182e-01 -2.17468e-01]
21Feb13_113836| [ 5.97516e-02  3.85639e-02]
21Feb13_113836| [-5.72126e-01 -1.12712e+00]
21Feb13_113836| [-6.00429e-02 -7.74199e-01]
21Feb13_113836| [ 1.10419e-01 -3.90905e-01]
21Feb13_113836| [-2.35151e+00 -1.19756e+00]
21Feb13_113836| [-7.19410e-01 -5.15445e-01]
21Feb13_113836| [ 7.11794e-01 -1.63341e-01]
21Feb13_113836| [-7.12856e-01 -1.26040e-01]
21Feb13_113836| [ 1.00583e+00 -4.07499e-01]
21Feb13_113836| [-4.46850e-01 -1.31896e+00]
21Feb13_113836| [ 6.83406e-02  2.95165e-01]
21Feb13_113836| [-7.73834e-01  4.39170e-01]
21Feb13_113836| [ 3.40113e-02 -1.19226e+00]
21Feb13_113836| [-1.90476e-01 -1.30555e+00]
21Feb13_113836| [-8.00537e-01  9.09884e-01]
21Feb13_113836| [ 8.79862e-01  5.55782e-01]
21Feb13_113836| [ 4.30997e-01 -3.58067e-01]
21Feb13_113836| [-6.68257e-01  2.38322e-01]]
21Feb13_113836|-- Bias --
21Feb13_113836|[-0.70906 -0.37669]
21Feb13_113836|Layer 1:
21Feb13_113836|-- Config --
21Feb13_113836|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113836|-- Weights --
21Feb13_113836|[[-0.94561  0.38942]
21Feb13_113836| [ 0.25172 -0.95334]]
21Feb13_113836|-- Bias --
21Feb13_113836|[-0.48591  0.74488]
21Feb13_113836|Layer 2:
21Feb13_113836|-- Config --
21Feb13_113836|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113836|-- Weights --
21Feb13_113836|[[ 1.63570  0.94691]
21Feb13_113836| [-0.10069  0.32775]]
21Feb13_113836|-- Bias --
21Feb13_113836|[0.40880 0.31931]
21Feb13_113836|Predicting the validation and test data with the Best final individual.
21Feb13_113844| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_113844|-----------  ------------------  --------------------  ----------
21Feb13_113844|Validation         25.22                  8             0.52619
21Feb13_113844|   Test            25.37                  8             0.50024
21Feb13_113844|-------------------- Test #11 --------------------
21Feb13_113844|Best final individual weights
21Feb13_113844|Individual:
21Feb13_113844|-- Constant hidden layers --
21Feb13_113844|False
21Feb13_113844|Layer 0:
21Feb13_113844|-- Config --
21Feb13_113844|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113844|-- Weights --
21Feb13_113844|[[ 1.74276e-01 -2.41590e-01]
21Feb13_113844| [ 1.77129e+00  4.54754e-01]
21Feb13_113844| [-1.87726e-01 -7.08215e-02]
21Feb13_113844| [ 1.67602e+00  1.07538e+00]
21Feb13_113844| [ 4.83300e-01  2.23842e-01]
21Feb13_113844| [ 1.21089e-01  8.43355e-01]
21Feb13_113844| [ 5.58188e-01  6.02878e-01]
21Feb13_113844| [ 9.80989e-01 -1.57022e+00]
21Feb13_113844| [-4.94314e-01  1.03493e-03]
21Feb13_113844| [ 6.50898e-01 -9.91301e-01]
21Feb13_113844| [ 1.21564e-01 -5.16848e-01]
21Feb13_113844| [ 2.05958e-02  7.65841e-01]
21Feb13_113844| [-1.19880e+00 -1.98384e-01]
21Feb13_113844| [ 1.40344e-01 -8.21092e-01]
21Feb13_113844| [ 8.66470e-01  6.10729e-01]
21Feb13_113844| [ 8.12148e-01 -4.05623e-01]
21Feb13_113844| [-1.93100e-01 -8.07256e-01]
21Feb13_113844| [-3.45548e-01 -3.86709e-03]
21Feb13_113844| [ 2.09207e-01 -2.40907e-01]
21Feb13_113844| [ 2.87175e-01 -4.04162e-01]
21Feb13_113844| [ 8.41330e-01  6.62044e-01]
21Feb13_113844| [ 6.85979e-01 -1.49782e+00]
21Feb13_113844| [-8.64047e-01 -4.42409e-01]
21Feb13_113844| [ 3.31760e-01 -3.46622e-01]
21Feb13_113844| [ 1.98449e+00 -1.68578e-01]
21Feb13_113844| [ 1.28383e+00 -5.72640e-01]
21Feb13_113844| [ 5.26745e-01  1.69675e+00]
21Feb13_113844| [ 2.00860e+00  1.52840e+00]
21Feb13_113844| [-1.76176e+00 -3.51036e-01]
21Feb13_113844| [-6.94774e-01  6.57618e-01]
21Feb13_113844| [ 3.70786e-01 -7.10144e-01]
21Feb13_113844| [-1.07489e+00 -2.87213e-01]
21Feb13_113844| [ 1.38837e+00  4.36522e-02]
21Feb13_113844| [-3.09496e-01  4.31557e-01]
21Feb13_113844| [ 1.94421e+00 -3.85891e-01]
21Feb13_113844| [ 1.13461e+00  3.53034e-01]
21Feb13_113844| [ 8.45985e-01  5.29180e-01]
21Feb13_113844| [ 9.77036e-01  9.19790e-02]
21Feb13_113844| [ 4.08182e-01 -2.17468e-01]
21Feb13_113844| [ 5.97516e-02  3.85639e-02]
21Feb13_113844| [-5.72126e-01 -1.12712e+00]
21Feb13_113844| [-6.00429e-02 -7.74199e-01]
21Feb13_113844| [ 1.10419e-01 -3.90905e-01]
21Feb13_113844| [-2.35151e+00 -1.19756e+00]
21Feb13_113844| [-7.19410e-01 -5.15445e-01]
21Feb13_113844| [ 7.11794e-01 -1.63341e-01]
21Feb13_113844| [-7.12856e-01 -1.26040e-01]
21Feb13_113844| [ 1.00583e+00 -4.07499e-01]
21Feb13_113844| [-4.46850e-01 -1.31896e+00]
21Feb13_113844| [ 6.83406e-02  2.95165e-01]
21Feb13_113844| [-7.73834e-01  4.39170e-01]
21Feb13_113844| [ 3.40113e-02 -1.19226e+00]
21Feb13_113844| [-1.90476e-01 -1.30555e+00]
21Feb13_113844| [-8.00537e-01  9.09884e-01]
21Feb13_113844| [ 8.79862e-01  5.55782e-01]
21Feb13_113844| [ 4.30997e-01 -3.58067e-01]
21Feb13_113844| [-6.68257e-01  2.38322e-01]]
21Feb13_113844|-- Bias --
21Feb13_113844|[-0.70906 -0.37669]
21Feb13_113844|Layer 1:
21Feb13_113844|-- Config --
21Feb13_113844|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113844|-- Weights --
21Feb13_113844|[[-0.94561  0.38942]
21Feb13_113844| [ 0.25172 -0.95334]]
21Feb13_113844|-- Bias --
21Feb13_113844|[-0.48591  0.74488]
21Feb13_113844|Layer 2:
21Feb13_113844|-- Config --
21Feb13_113844|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113844|-- Weights --
21Feb13_113844|[[ 1.63570  0.94691]
21Feb13_113844| [-0.10069  0.32775]]
21Feb13_113844|-- Bias --
21Feb13_113844|[0.40880 0.31931]
21Feb13_113844|Predicting the validation and test data with the Best final individual.
21Feb13_113851| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_113851|-----------  ------------------  --------------------  ----------
21Feb13_113851|Validation         29.04                  8             0.31609
21Feb13_113851|   Test            26.32                  8             0.52632
21Feb13_113851|-------------------- Test #12 --------------------
21Feb13_113851|Best final individual weights
21Feb13_113851|Individual:
21Feb13_113851|-- Constant hidden layers --
21Feb13_113851|False
21Feb13_113851|Layer 0:
21Feb13_113851|-- Config --
21Feb13_113851|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113851|-- Weights --
21Feb13_113851|[[ 1.74276e-01 -2.41590e-01]
21Feb13_113851| [ 1.77129e+00  4.54754e-01]
21Feb13_113851| [-1.87726e-01 -7.08215e-02]
21Feb13_113851| [ 1.67602e+00  1.07538e+00]
21Feb13_113851| [ 4.83300e-01  2.23842e-01]
21Feb13_113851| [ 1.21089e-01  8.43355e-01]
21Feb13_113851| [ 5.58188e-01  6.02878e-01]
21Feb13_113851| [ 9.80989e-01 -1.57022e+00]
21Feb13_113851| [-4.94314e-01  1.03493e-03]
21Feb13_113851| [ 6.50898e-01 -9.91301e-01]
21Feb13_113851| [ 1.21564e-01 -5.16848e-01]
21Feb13_113851| [ 2.05958e-02  7.65841e-01]
21Feb13_113851| [-1.19880e+00 -1.98384e-01]
21Feb13_113851| [ 1.40344e-01 -8.21092e-01]
21Feb13_113851| [ 8.66470e-01  6.10729e-01]
21Feb13_113851| [ 8.12148e-01 -4.05623e-01]
21Feb13_113851| [-1.93100e-01 -8.07256e-01]
21Feb13_113851| [-3.45548e-01 -3.86709e-03]
21Feb13_113851| [ 2.09207e-01 -2.40907e-01]
21Feb13_113851| [ 2.87175e-01 -4.04162e-01]
21Feb13_113851| [ 8.41330e-01  6.62044e-01]
21Feb13_113851| [ 6.85979e-01 -1.49782e+00]
21Feb13_113851| [-8.64047e-01 -4.42409e-01]
21Feb13_113851| [ 3.31760e-01 -3.46622e-01]
21Feb13_113851| [ 1.98449e+00 -1.68578e-01]
21Feb13_113851| [ 1.28383e+00 -5.72640e-01]
21Feb13_113851| [ 5.26745e-01  1.69675e+00]
21Feb13_113851| [ 2.00860e+00  1.52840e+00]
21Feb13_113851| [-1.76176e+00 -3.51036e-01]
21Feb13_113851| [-6.94774e-01  6.57618e-01]
21Feb13_113851| [ 3.70786e-01 -7.10144e-01]
21Feb13_113851| [-1.07489e+00 -2.87213e-01]
21Feb13_113851| [ 1.38837e+00  4.36522e-02]
21Feb13_113851| [-3.09496e-01  4.31557e-01]
21Feb13_113851| [ 1.94421e+00 -3.85891e-01]
21Feb13_113851| [ 1.13461e+00  3.53034e-01]
21Feb13_113851| [ 8.45985e-01  5.29180e-01]
21Feb13_113851| [ 9.77036e-01  9.19790e-02]
21Feb13_113851| [ 4.08182e-01 -2.17468e-01]
21Feb13_113851| [ 5.97516e-02  3.85639e-02]
21Feb13_113851| [-5.72126e-01 -1.12712e+00]
21Feb13_113851| [-6.00429e-02 -7.74199e-01]
21Feb13_113851| [ 1.10419e-01 -3.90905e-01]
21Feb13_113851| [-2.35151e+00 -1.19756e+00]
21Feb13_113851| [-7.19410e-01 -5.15445e-01]
21Feb13_113851| [ 7.11794e-01 -1.63341e-01]
21Feb13_113851| [-7.12856e-01 -1.26040e-01]
21Feb13_113851| [ 1.00583e+00 -4.07499e-01]
21Feb13_113851| [-4.46850e-01 -1.31896e+00]
21Feb13_113851| [ 6.83406e-02  2.95165e-01]
21Feb13_113851| [-7.73834e-01  4.39170e-01]
21Feb13_113851| [ 3.40113e-02 -1.19226e+00]
21Feb13_113851| [-1.90476e-01 -1.30555e+00]
21Feb13_113851| [-8.00537e-01  9.09884e-01]
21Feb13_113851| [ 8.79862e-01  5.55782e-01]
21Feb13_113851| [ 4.30997e-01 -3.58067e-01]
21Feb13_113851| [-6.68257e-01  2.38322e-01]]
21Feb13_113851|-- Bias --
21Feb13_113851|[-0.70906 -0.37669]
21Feb13_113851|Layer 1:
21Feb13_113851|-- Config --
21Feb13_113851|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113851|-- Weights --
21Feb13_113851|[[-0.94561  0.38942]
21Feb13_113851| [ 0.25172 -0.95334]]
21Feb13_113851|-- Bias --
21Feb13_113851|[-0.48591  0.74488]
21Feb13_113851|Layer 2:
21Feb13_113851|-- Config --
21Feb13_113851|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113851|-- Weights --
21Feb13_113851|[[ 1.63570  0.94691]
21Feb13_113851| [-0.10069  0.32775]]
21Feb13_113851|-- Bias --
21Feb13_113851|[0.40880 0.31931]
21Feb13_113851|Predicting the validation and test data with the Best final individual.
21Feb13_113859| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_113859|-----------  ------------------  --------------------  ----------
21Feb13_113859|Validation         26.00                  8             0.45273
21Feb13_113859|   Test            26.67                  8             0.52342
21Feb13_113859|-------------------- Test #13 --------------------
21Feb13_113859|Best final individual weights
21Feb13_113859|Individual:
21Feb13_113859|-- Constant hidden layers --
21Feb13_113859|False
21Feb13_113859|Layer 0:
21Feb13_113859|-- Config --
21Feb13_113859|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113859|-- Weights --
21Feb13_113859|[[ 1.74276e-01 -2.41590e-01]
21Feb13_113859| [ 1.77129e+00  4.54754e-01]
21Feb13_113859| [-1.87726e-01 -7.08215e-02]
21Feb13_113859| [ 1.67602e+00  1.07538e+00]
21Feb13_113859| [ 4.83300e-01  2.23842e-01]
21Feb13_113859| [ 1.21089e-01  8.43355e-01]
21Feb13_113859| [ 5.58188e-01  6.02878e-01]
21Feb13_113859| [ 9.80989e-01 -1.57022e+00]
21Feb13_113859| [-4.94314e-01  1.03493e-03]
21Feb13_113859| [ 6.50898e-01 -9.91301e-01]
21Feb13_113859| [ 1.21564e-01 -5.16848e-01]
21Feb13_113859| [ 2.05958e-02  7.65841e-01]
21Feb13_113859| [-1.19880e+00 -1.98384e-01]
21Feb13_113859| [ 1.40344e-01 -8.21092e-01]
21Feb13_113859| [ 8.66470e-01  6.10729e-01]
21Feb13_113859| [ 8.12148e-01 -4.05623e-01]
21Feb13_113859| [-1.93100e-01 -8.07256e-01]
21Feb13_113859| [-3.45548e-01 -3.86709e-03]
21Feb13_113859| [ 2.09207e-01 -2.40907e-01]
21Feb13_113859| [ 2.87175e-01 -4.04162e-01]
21Feb13_113859| [ 8.41330e-01  6.62044e-01]
21Feb13_113859| [ 6.85979e-01 -1.49782e+00]
21Feb13_113859| [-8.64047e-01 -4.42409e-01]
21Feb13_113859| [ 3.31760e-01 -3.46622e-01]
21Feb13_113859| [ 1.98449e+00 -1.68578e-01]
21Feb13_113859| [ 1.28383e+00 -5.72640e-01]
21Feb13_113859| [ 5.26745e-01  1.69675e+00]
21Feb13_113859| [ 2.00860e+00  1.52840e+00]
21Feb13_113859| [-1.76176e+00 -3.51036e-01]
21Feb13_113859| [-6.94774e-01  6.57618e-01]
21Feb13_113859| [ 3.70786e-01 -7.10144e-01]
21Feb13_113859| [-1.07489e+00 -2.87213e-01]
21Feb13_113859| [ 1.38837e+00  4.36522e-02]
21Feb13_113859| [-3.09496e-01  4.31557e-01]
21Feb13_113859| [ 1.94421e+00 -3.85891e-01]
21Feb13_113859| [ 1.13461e+00  3.53034e-01]
21Feb13_113859| [ 8.45985e-01  5.29180e-01]
21Feb13_113859| [ 9.77036e-01  9.19790e-02]
21Feb13_113859| [ 4.08182e-01 -2.17468e-01]
21Feb13_113859| [ 5.97516e-02  3.85639e-02]
21Feb13_113859| [-5.72126e-01 -1.12712e+00]
21Feb13_113859| [-6.00429e-02 -7.74199e-01]
21Feb13_113859| [ 1.10419e-01 -3.90905e-01]
21Feb13_113859| [-2.35151e+00 -1.19756e+00]
21Feb13_113859| [-7.19410e-01 -5.15445e-01]
21Feb13_113859| [ 7.11794e-01 -1.63341e-01]
21Feb13_113859| [-7.12856e-01 -1.26040e-01]
21Feb13_113859| [ 1.00583e+00 -4.07499e-01]
21Feb13_113859| [-4.46850e-01 -1.31896e+00]
21Feb13_113859| [ 6.83406e-02  2.95165e-01]
21Feb13_113859| [-7.73834e-01  4.39170e-01]
21Feb13_113859| [ 3.40113e-02 -1.19226e+00]
21Feb13_113859| [-1.90476e-01 -1.30555e+00]
21Feb13_113859| [-8.00537e-01  9.09884e-01]
21Feb13_113859| [ 8.79862e-01  5.55782e-01]
21Feb13_113859| [ 4.30997e-01 -3.58067e-01]
21Feb13_113859| [-6.68257e-01  2.38322e-01]]
21Feb13_113859|-- Bias --
21Feb13_113859|[-0.70906 -0.37669]
21Feb13_113859|Layer 1:
21Feb13_113859|-- Config --
21Feb13_113859|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113859|-- Weights --
21Feb13_113859|[[-0.94561  0.38942]
21Feb13_113859| [ 0.25172 -0.95334]]
21Feb13_113859|-- Bias --
21Feb13_113859|[-0.48591  0.74488]
21Feb13_113859|Layer 2:
21Feb13_113859|-- Config --
21Feb13_113859|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113859|-- Weights --
21Feb13_113859|[[ 1.63570  0.94691]
21Feb13_113859| [-0.10069  0.32775]]
21Feb13_113859|-- Bias --
21Feb13_113859|[0.40880 0.31931]
21Feb13_113859|Predicting the validation and test data with the Best final individual.
21Feb13_113906| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_113906|-----------  ------------------  --------------------  ----------
21Feb13_113906|Validation         25.39                  8             0.51992
21Feb13_113906|   Test            28.41                  8             0.41791
21Feb13_113906|-------------------- Test #14 --------------------
21Feb13_113906|Best final individual weights
21Feb13_113906|Individual:
21Feb13_113906|-- Constant hidden layers --
21Feb13_113906|False
21Feb13_113906|Layer 0:
21Feb13_113906|-- Config --
21Feb13_113906|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113906|-- Weights --
21Feb13_113906|[[ 1.74276e-01 -2.41590e-01]
21Feb13_113906| [ 1.77129e+00  4.54754e-01]
21Feb13_113906| [-1.87726e-01 -7.08215e-02]
21Feb13_113906| [ 1.67602e+00  1.07538e+00]
21Feb13_113906| [ 4.83300e-01  2.23842e-01]
21Feb13_113906| [ 1.21089e-01  8.43355e-01]
21Feb13_113906| [ 5.58188e-01  6.02878e-01]
21Feb13_113906| [ 9.80989e-01 -1.57022e+00]
21Feb13_113906| [-4.94314e-01  1.03493e-03]
21Feb13_113906| [ 6.50898e-01 -9.91301e-01]
21Feb13_113906| [ 1.21564e-01 -5.16848e-01]
21Feb13_113906| [ 2.05958e-02  7.65841e-01]
21Feb13_113906| [-1.19880e+00 -1.98384e-01]
21Feb13_113906| [ 1.40344e-01 -8.21092e-01]
21Feb13_113906| [ 8.66470e-01  6.10729e-01]
21Feb13_113906| [ 8.12148e-01 -4.05623e-01]
21Feb13_113906| [-1.93100e-01 -8.07256e-01]
21Feb13_113906| [-3.45548e-01 -3.86709e-03]
21Feb13_113906| [ 2.09207e-01 -2.40907e-01]
21Feb13_113906| [ 2.87175e-01 -4.04162e-01]
21Feb13_113906| [ 8.41330e-01  6.62044e-01]
21Feb13_113906| [ 6.85979e-01 -1.49782e+00]
21Feb13_113906| [-8.64047e-01 -4.42409e-01]
21Feb13_113906| [ 3.31760e-01 -3.46622e-01]
21Feb13_113906| [ 1.98449e+00 -1.68578e-01]
21Feb13_113906| [ 1.28383e+00 -5.72640e-01]
21Feb13_113906| [ 5.26745e-01  1.69675e+00]
21Feb13_113906| [ 2.00860e+00  1.52840e+00]
21Feb13_113906| [-1.76176e+00 -3.51036e-01]
21Feb13_113906| [-6.94774e-01  6.57618e-01]
21Feb13_113906| [ 3.70786e-01 -7.10144e-01]
21Feb13_113906| [-1.07489e+00 -2.87213e-01]
21Feb13_113906| [ 1.38837e+00  4.36522e-02]
21Feb13_113906| [-3.09496e-01  4.31557e-01]
21Feb13_113906| [ 1.94421e+00 -3.85891e-01]
21Feb13_113906| [ 1.13461e+00  3.53034e-01]
21Feb13_113906| [ 8.45985e-01  5.29180e-01]
21Feb13_113906| [ 9.77036e-01  9.19790e-02]
21Feb13_113906| [ 4.08182e-01 -2.17468e-01]
21Feb13_113906| [ 5.97516e-02  3.85639e-02]
21Feb13_113906| [-5.72126e-01 -1.12712e+00]
21Feb13_113906| [-6.00429e-02 -7.74199e-01]
21Feb13_113906| [ 1.10419e-01 -3.90905e-01]
21Feb13_113906| [-2.35151e+00 -1.19756e+00]
21Feb13_113906| [-7.19410e-01 -5.15445e-01]
21Feb13_113906| [ 7.11794e-01 -1.63341e-01]
21Feb13_113906| [-7.12856e-01 -1.26040e-01]
21Feb13_113906| [ 1.00583e+00 -4.07499e-01]
21Feb13_113906| [-4.46850e-01 -1.31896e+00]
21Feb13_113906| [ 6.83406e-02  2.95165e-01]
21Feb13_113906| [-7.73834e-01  4.39170e-01]
21Feb13_113906| [ 3.40113e-02 -1.19226e+00]
21Feb13_113906| [-1.90476e-01 -1.30555e+00]
21Feb13_113906| [-8.00537e-01  9.09884e-01]
21Feb13_113906| [ 8.79862e-01  5.55782e-01]
21Feb13_113906| [ 4.30997e-01 -3.58067e-01]
21Feb13_113906| [-6.68257e-01  2.38322e-01]]
21Feb13_113906|-- Bias --
21Feb13_113906|[-0.70906 -0.37669]
21Feb13_113906|Layer 1:
21Feb13_113906|-- Config --
21Feb13_113906|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113906|-- Weights --
21Feb13_113906|[[-0.94561  0.38942]
21Feb13_113906| [ 0.25172 -0.95334]]
21Feb13_113906|-- Bias --
21Feb13_113906|[-0.48591  0.74488]
21Feb13_113906|Layer 2:
21Feb13_113906|-- Config --
21Feb13_113906|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_113906|-- Weights --
21Feb13_113906|[[ 1.63570  0.94691]
21Feb13_113906| [-0.10069  0.32775]]
21Feb13_113906|-- Bias --
21Feb13_113906|[0.40880 0.31931]
21Feb13_113906|Predicting the validation and test data with the Best final individual.
21Feb13_113913| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_113913|-----------  ------------------  --------------------  ----------
21Feb13_113913|Validation         25.30                  8             0.47287
21Feb13_113913|   Test            27.02                  8             0.46014
2021-02-13 11:39:14.457168: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
21Feb13_113915|Data summary: Train
21Feb13_113915|data.shape = (2300, 57)
21Feb13_113915|labels.shape = (2300,)
21Feb13_113915|Class distribution:
21Feb13_113915|	0 - 1382 (0.60)
21Feb13_113915|	1 - 918 (0.40)
21Feb13_113915|Data summary: Validation
21Feb13_113915|data.shape = (1150, 57)
21Feb13_113915|labels.shape = (1150,)
21Feb13_113915|Class distribution:
21Feb13_113915|	0 - 704 (0.61)
21Feb13_113915|	1 - 446 (0.39)
21Feb13_113915|Data summary: Test
21Feb13_113915|data.shape = (1151, 57)
21Feb13_113915|labels.shape = (1151,)
21Feb13_113915|Class distribution:
21Feb13_113915|	0 - 702 (0.61)
21Feb13_113915|	1 - 449 (0.39)
21Feb13_113915|Selected configuration values
21Feb13_113915|-- Dataset name: spambase1
21Feb13_113915|-- Initial population size: 64
21Feb13_113915|-- Maximun number of generations: 32
21Feb13_113915|-- Neurons per hidden layer range: (2, 20)
21Feb13_113915|-- Hidden layers number range: (1, 3)
21Feb13_113915|-- Crossover probability: 0.5
21Feb13_113915|-- Bias gene mutation probability: 0.2
21Feb13_113915|-- Weights gene mutation probability: 0.75
21Feb13_113915|-- Neuron mutation probability: 0.3
21Feb13_113915|-- Layer mutation probability: 0.3
21Feb13_113915|-- Constant hidden layers: False
21Feb13_113915|-- Seed: 31415
21Feb13_113915|Entering GA
21Feb13_113915|Start the algorithm
2021-02-13 11:39:15.313732: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-13 11:39:15.314273: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-02-13 11:39:15.334676: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-13 11:39:15.334994: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.71GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s
2021-02-13 11:39:15.335008: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-02-13 11:39:15.336462: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-02-13 11:39:15.336491: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-02-13 11:39:15.336999: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-02-13 11:39:15.337128: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-02-13 11:39:15.337198: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-13 11:39:15.337613: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-02-13 11:39:15.337654: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-13 11:39:15.337660: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-02-13 11:39:15.337879: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-02-13 11:39:15.338721: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-13 11:39:15.338735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-13 11:39:15.338739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      
2021-02-13 11:39:15.388154: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-02-13 11:39:15.388534: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3493635000 Hz
/home/jmerelo/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype("int32")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn('`model.predict_classes()` is deprecated and '
21Feb13_114318|-- Generation 1 --
21Feb13_114318|    -- Crossed 0 individual pairs.
21Feb13_114318|    -- Mutated 32 individuals.
21Feb13_114718|    -- Evaluated 64 individuals.
21Feb13_114718|    Summary of generation 1:
21Feb13_114718| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_114718|-----------  ------------------  --------------------  ----------
21Feb13_114718|    Max            39.39                132.00          0.42922
21Feb13_114718|    Avg            38.59                42.11           0.01089
21Feb13_114718|    Min            27.13                 3.00           0.00000
21Feb13_114718|    Std             1.55                36.53           0.05643
21Feb13_114718|   Best            27.13                63.00           0.42922
21Feb13_114718|-- Generation 2 --
21Feb13_114718|    -- Crossed 0 individual pairs.
21Feb13_114718|    -- Mutated 32 individuals.
21Feb13_115118|    -- Evaluated 64 individuals.
21Feb13_115118|    Summary of generation 2:
21Feb13_115118| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_115118|-----------  ------------------  --------------------  ----------
21Feb13_115118|    Max            39.30                99.00           0.61920
21Feb13_115118|    Avg            38.32                34.92           0.02263
21Feb13_115118|    Min            24.70                 3.00           0.00000
21Feb13_115118|    Std             2.42                26.46           0.10433
21Feb13_115118|   Best            24.70                63.00           0.61920
21Feb13_115118|-- Generation 3 --
21Feb13_115118|    -- Crossed 2 individual pairs.
21Feb13_115118|    -- Mutated 32 individuals.
21Feb13_115517|    -- Evaluated 64 individuals.
21Feb13_115517|    Summary of generation 3:
21Feb13_115517| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_115517|-----------  ------------------  --------------------  ----------
21Feb13_115517|    Max            39.22                63.00           0.54223
21Feb13_115517|    Avg            38.56                23.38           0.01154
21Feb13_115517|    Min            25.57                 2.00           0.00000
21Feb13_115517|    Std             1.65                18.84           0.06783
21Feb13_115517|   Best            25.57                39.00           0.54223
21Feb13_115517|-- Generation 4 --
21Feb13_115517|    -- Crossed 2 individual pairs.
21Feb13_115517|    -- Mutated 32 individuals.
21Feb13_115910|    -- Evaluated 64 individuals.
21Feb13_115910|    Summary of generation 4:
21Feb13_115910| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_115910|-----------  ------------------  --------------------  ----------
21Feb13_115910|    Max            39.83                39.00           0.73428
21Feb13_115910|    Avg            38.21                12.58           0.03151
21Feb13_115910|    Min            24.26                 3.00           0.00000
21Feb13_115910|    Std             2.78                 8.77           0.13613
21Feb13_115910|   Best            24.26                14.00           0.56301
21Feb13_115910|-- Generation 5 --
21Feb13_115910|    -- Crossed 3 individual pairs.
21Feb13_115910|    -- Mutated 32 individuals.
21Feb13_120302|    -- Evaluated 64 individuals.
21Feb13_120302|    Summary of generation 5:
21Feb13_120302| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_120302|-----------  ------------------  --------------------  ----------
21Feb13_120302|    Max            39.22                39.00           0.64079
21Feb13_120302|    Avg            38.29                 9.28           0.02391
21Feb13_120302|    Min            24.43                 2.00           0.00000
21Feb13_120302|    Std             2.38                 9.00           0.09840
21Feb13_120302|   Best            24.43                39.00           0.64079
21Feb13_120302|-- Generation 6 --
21Feb13_120302|    -- Crossed 5 individual pairs.
21Feb13_120302|    -- Mutated 32 individuals.
21Feb13_120654|    -- Evaluated 64 individuals.
21Feb13_120654|    Summary of generation 6:
21Feb13_120654| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_120654|-----------  ------------------  --------------------  ----------
21Feb13_120654|    Max            39.13                60.00           0.60734
21Feb13_120654|    Avg            38.06                 9.78           0.02993
21Feb13_120654|    Min            23.48                 2.00           0.00000
21Feb13_120654|    Std             3.00                11.42           0.12040
21Feb13_120654|   Best            23.48                39.00           0.60734
21Feb13_120654|-- Generation 7 --
21Feb13_120654|    -- Crossed 8 individual pairs.
21Feb13_120654|    -- Mutated 32 individuals.
21Feb13_121044|    -- Evaluated 64 individuals.
21Feb13_121044|    Summary of generation 7:
21Feb13_121044| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_121044|-----------  ------------------  --------------------  ----------
21Feb13_121044|    Max            39.48                42.00           0.50914
21Feb13_121044|    Avg            38.26                 7.09           0.01938
21Feb13_121044|    Min            23.74                 2.00           0.00000
21Feb13_121044|    Std             2.61                 8.49           0.08982
21Feb13_121044|   Best            23.74                39.00           0.50914
21Feb13_121044|-- Generation 8 --
21Feb13_121044|    -- Crossed 6 individual pairs.
21Feb13_121044|    -- Mutated 32 individuals.
21Feb13_121433|    -- Evaluated 64 individuals.
21Feb13_121433|    Summary of generation 8:
21Feb13_121433| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_121433|-----------  ------------------  --------------------  ----------
21Feb13_121433|    Max            39.13                42.00           0.67374
21Feb13_121433|    Avg            38.17                 6.80           0.02294
21Feb13_121433|    Min            21.30                 2.00           0.00000
21Feb13_121433|    Std             2.92                 9.40           0.10722
21Feb13_121433|   Best            21.30                39.00           0.67374
21Feb13_121433|-- Generation 9 --
21Feb13_121433|    -- Crossed 6 individual pairs.
21Feb13_121433|    -- Mutated 32 individuals.
21Feb13_121825|    -- Evaluated 64 individuals.
21Feb13_121825|    Summary of generation 9:
21Feb13_121825| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_121825|-----------  ------------------  --------------------  ----------
21Feb13_121825|    Max            38.96                42.00           0.45070
21Feb13_121825|    Avg            38.61                 6.56           0.00704
21Feb13_121825|    Min            26.78                 2.00           0.00000
21Feb13_121825|    Std             1.49                 8.82           0.05590
21Feb13_121825|   Best            26.78                42.00           0.45070
21Feb13_121825|-- Generation 10 --
21Feb13_121825|    -- Crossed 8 individual pairs.
21Feb13_121825|    -- Mutated 32 individuals.
21Feb13_122216|    -- Evaluated 64 individuals.
21Feb13_122216|    Summary of generation 10:
21Feb13_122216| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_122216|-----------  ------------------  --------------------  ----------
21Feb13_122216|    Max            39.22                72.00           0.58090
21Feb13_122216|    Avg            38.61                 5.42           0.00908
21Feb13_122216|    Min            25.57                 2.00           0.00000
21Feb13_122216|    Std             1.65                10.10           0.07204
21Feb13_122216|   Best            25.57                42.00           0.58090
21Feb13_122216|-- Generation 11 --
21Feb13_122216|    -- Crossed 9 individual pairs.
21Feb13_122216|    -- Mutated 32 individuals.
21Feb13_122607|    -- Evaluated 64 individuals.
21Feb13_122607|    Summary of generation 11:
21Feb13_122607| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_122607|-----------  ------------------  --------------------  ----------
21Feb13_122607|    Max            39.13                45.00           0.58533
21Feb13_122607|    Avg            38.39                 6.22           0.01659
21Feb13_122607|    Min            25.30                 2.00           0.00000
21Feb13_122607|    Std             2.27                 7.99           0.09288
21Feb13_122607|   Best            25.30                16.00           0.58533
21Feb13_122607|-- Generation 12 --
21Feb13_122607|    -- Crossed 3 individual pairs.
21Feb13_122607|    -- Mutated 32 individuals.
21Feb13_123001|    -- Evaluated 64 individuals.
21Feb13_123001|    Summary of generation 12:
21Feb13_123001| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_123001|-----------  ------------------  --------------------  ----------
21Feb13_123001|    Max            39.04                72.00           0.49365
21Feb13_123001|    Avg            38.61                 5.80           0.00771
21Feb13_123001|    Min            26.43                 2.00           0.00000
21Feb13_123001|    Std             1.53                10.91           0.06122
21Feb13_123001|   Best            26.43                16.00           0.49365
21Feb13_123001|-- Generation 13 --
21Feb13_123001|    -- Crossed 6 individual pairs.
21Feb13_123001|    -- Mutated 32 individuals.
21Feb13_123351|    -- Evaluated 64 individuals.
21Feb13_123351|    Summary of generation 13:
21Feb13_123351| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_123351|-----------  ------------------  --------------------  ----------
21Feb13_123351|    Max            39.04                16.00           0.36064
21Feb13_123351|    Avg            38.62                 3.52           0.00563
21Feb13_123351|    Min            28.09                 2.00           0.00000
21Feb13_123351|    Std             1.33                 3.76           0.04473
21Feb13_123351|   Best            28.09                16.00           0.36064
21Feb13_123351|-- Generation 14 --
21Feb13_123351|    -- Crossed 8 individual pairs.
21Feb13_123351|    -- Mutated 32 individuals.
21Feb13_123742|    -- Evaluated 64 individuals.
21Feb13_123742|    Summary of generation 14:
21Feb13_123742| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_123742|-----------  ------------------  --------------------  ----------
21Feb13_123742|    Max            48.26                30.00           0.79827
21Feb13_123742|    Avg            38.63                 4.23           0.02740
21Feb13_123742|    Min            22.78                 2.00           0.00000
21Feb13_123742|    Std             2.38                 5.13           0.13593
21Feb13_123742|   Best            22.78                16.00           0.73944
21Feb13_123742|-- Generation 15 --
21Feb13_123742|    -- Crossed 8 individual pairs.
21Feb13_123742|    -- Mutated 32 individuals.
21Feb13_124134|    -- Evaluated 64 individuals.
21Feb13_124134|    Summary of generation 15:
21Feb13_124134| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_124134|-----------  ------------------  --------------------  ----------
21Feb13_124134|    Max            39.30                36.00           0.33522
21Feb13_124134|    Avg            38.67                 5.33           0.00524
21Feb13_124134|    Min            29.65                 2.00           0.00000
21Feb13_124134|    Std             1.14                 7.12           0.04157
21Feb13_124134|   Best            29.65                16.00           0.33522
21Feb13_124134|-- Generation 16 --
21Feb13_124134|    -- Crossed 7 individual pairs.
21Feb13_124134|    -- Mutated 32 individuals.
21Feb13_124525|    -- Evaluated 64 individuals.
21Feb13_124525|    Summary of generation 16:
21Feb13_124525| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_124525|-----------  ------------------  --------------------  ----------
21Feb13_124525|    Max            38.87                16.00           0.00838
21Feb13_124525|    Avg            38.79                 3.88           0.00013
21Feb13_124525|    Min            38.78                 2.00           0.00000
21Feb13_124525|    Std             0.02                 4.02           0.00104
21Feb13_124525|   Best            38.78                 2.00           0.00000
21Feb13_124525|-- Generation 17 --
21Feb13_124525|    -- Crossed 9 individual pairs.
21Feb13_124525|    -- Mutated 32 individuals.
21Feb13_124917|    -- Evaluated 64 individuals.
21Feb13_124917|    Summary of generation 17:
21Feb13_124917| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_124917|-----------  ------------------  --------------------  ----------
21Feb13_124917|    Max            42.78                14.00           0.81305
21Feb13_124917|    Avg            38.86                 3.34           0.01270
21Feb13_124917|    Min            38.78                 2.00           0.00000
21Feb13_124917|    Std             0.50                 3.05           0.10083
21Feb13_124917|   Best            38.78                 2.00           0.00000
21Feb13_124917|-- Generation 18 --
21Feb13_124917|    -- Crossed 7 individual pairs.
21Feb13_124917|    -- Mutated 32 individuals.
21Feb13_125307|    -- Evaluated 64 individuals.
21Feb13_125307|    Summary of generation 18:
21Feb13_125307| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_125307|-----------  ------------------  --------------------  ----------
21Feb13_125307|    Max            39.04                14.00           0.44226
21Feb13_125307|    Avg            38.64                 3.22           0.00691
21Feb13_125307|    Min            29.30                 2.00           0.00000
21Feb13_125307|    Std             1.18                 3.20           0.05485
21Feb13_125307|   Best            29.30                 3.00           0.44226
21Feb13_125307|-- Generation 19 --
21Feb13_125307|    -- Crossed 10 individual pairs.
21Feb13_125307|    -- Mutated 32 individuals.
21Feb13_125657|    -- Evaluated 64 individuals.
21Feb13_125657|    Summary of generation 19:
21Feb13_125657| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_125657|-----------  ------------------  --------------------  ----------
21Feb13_125657|    Max            39.30                16.00           0.00000
21Feb13_125657|    Avg            38.80                 3.25           0.00000
21Feb13_125657|    Min            38.78                 2.00           0.00000
21Feb13_125657|    Std             0.07                 3.23           0.00000
21Feb13_125657|   Best            38.78                 2.00           0.00000
21Feb13_125657|-- Generation 20 --
21Feb13_125657|    -- Crossed 6 individual pairs.
21Feb13_125657|    -- Mutated 32 individuals.
21Feb13_130049|    -- Evaluated 64 individuals.
21Feb13_130049|    Summary of generation 20:
21Feb13_130049| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_130049|-----------  ------------------  --------------------  ----------
21Feb13_130049|    Max            38.96                14.00           0.00000
21Feb13_130049|    Avg            38.79                 3.12           0.00000
21Feb13_130049|    Min            38.78                 2.00           0.00000
21Feb13_130049|    Std             0.02                 2.90           0.00000
21Feb13_130049|   Best            38.78                 2.00           0.00000
21Feb13_130049|-- Generation 21 --
21Feb13_130049|    -- Crossed 7 individual pairs.
21Feb13_130049|    -- Mutated 32 individuals.
21Feb13_130440|    -- Evaluated 64 individuals.
21Feb13_130440|    Summary of generation 21:
21Feb13_130440| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_130440|-----------  ------------------  --------------------  ----------
21Feb13_130440|    Max            38.96                14.00           0.55159
21Feb13_130440|    Avg            38.39                 3.50           0.01589
21Feb13_130440|    Min            25.83                 2.00           0.00000
21Feb13_130440|    Std             2.23                 3.36           0.08880
21Feb13_130440|   Best            25.83                10.00           0.46541
21Feb13_130440|-- Generation 22 --
21Feb13_130440|    -- Crossed 11 individual pairs.
21Feb13_130440|    -- Mutated 32 individuals.
21Feb13_130831|    -- Evaluated 64 individuals.
21Feb13_130831|    Summary of generation 22:
21Feb13_130831| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_130831|-----------  ------------------  --------------------  ----------
21Feb13_130831|    Max            39.83                14.00           0.00000
21Feb13_130831|    Avg            38.81                 4.16           0.00000
21Feb13_130831|    Min            38.78                 2.00           0.00000
21Feb13_130831|    Std             0.13                 4.12           0.00000
21Feb13_130831|   Best            38.78                 2.00           0.00000
21Feb13_130831|-- Generation 23 --
21Feb13_130831|    -- Crossed 9 individual pairs.
21Feb13_130831|    -- Mutated 32 individuals.
21Feb13_131223|    -- Evaluated 64 individuals.
21Feb13_131223|    Summary of generation 23:
21Feb13_131223| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_131223|-----------  ------------------  --------------------  ----------
21Feb13_131223|    Max            38.96                16.00           0.08447
21Feb13_131223|    Avg            38.79                 3.84           0.00132
21Feb13_131223|    Min            37.83                 2.00           0.00000
21Feb13_131223|    Std             0.13                 4.04           0.01048
21Feb13_131223|   Best            37.83                10.00           0.08447
21Feb13_131223|-- Generation 24 --
21Feb13_131223|    -- Crossed 8 individual pairs.
21Feb13_131223|    -- Mutated 32 individuals.
21Feb13_131612|    -- Evaluated 64 individuals.
21Feb13_131612|    Summary of generation 24:
21Feb13_131612| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_131612|-----------  ------------------  --------------------  ----------
21Feb13_131612|    Max            38.96                14.00           0.00000
21Feb13_131612|    Avg            38.79                 3.83           0.00000
21Feb13_131612|    Min            38.78                 2.00           0.00000
21Feb13_131612|    Std             0.03                 3.67           0.00000
21Feb13_131612|   Best            38.78                 2.00           0.00000
21Feb13_131612|-- Generation 25 --
21Feb13_131612|    -- Crossed 6 individual pairs.
21Feb13_131612|    -- Mutated 32 individuals.
21Feb13_132003|    -- Evaluated 64 individuals.
21Feb13_132003|    Summary of generation 25:
21Feb13_132003| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_132003|-----------  ------------------  --------------------  ----------
21Feb13_132003|    Max            39.13                16.00           0.67360
21Feb13_132003|    Avg            38.58                 3.67           0.01052
21Feb13_132003|    Min            24.17                 2.00           0.00000
21Feb13_132003|    Std             1.82                 3.73           0.08354
21Feb13_132003|   Best            24.17                 8.00           0.67360
21Feb13_132003|-- Generation 26 --
21Feb13_132003|    -- Crossed 9 individual pairs.
21Feb13_132003|    -- Mutated 32 individuals.
21Feb13_132354|    -- Evaluated 64 individuals.
21Feb13_132354|    Summary of generation 26:
21Feb13_132354| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_132354|-----------  ------------------  --------------------  ----------
21Feb13_132354|    Max            39.13                16.00           0.61691
21Feb13_132354|    Avg            38.37                 4.20           0.01870
21Feb13_132354|    Min            25.39                 2.00           0.00000
21Feb13_132354|    Std             2.26                 4.09           0.09416
21Feb13_132354|   Best            25.39                12.00           0.61691
21Feb13_132354|-- Generation 27 --
21Feb13_132354|    -- Crossed 8 individual pairs.
21Feb13_132354|    -- Mutated 32 individuals.
21Feb13_132745|    -- Evaluated 64 individuals.
21Feb13_132745|    Summary of generation 27:
21Feb13_132745| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_132745|-----------  ------------------  --------------------  ----------
21Feb13_132745|    Max            39.22                16.00           0.51724
21Feb13_132745|    Avg            38.60                 3.97           0.00808
21Feb13_132745|    Min            25.65                 2.00           0.00000
21Feb13_132745|    Std             1.63                 4.06           0.06415
21Feb13_132745|   Best            25.65                16.00           0.51724
21Feb13_132745|-- Generation 28 --
21Feb13_132745|    -- Crossed 8 individual pairs.
21Feb13_132745|    -- Mutated 32 individuals.
21Feb13_133133|    -- Evaluated 64 individuals.
21Feb13_133133|    Summary of generation 28:
21Feb13_133133| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_133133|-----------  ------------------  --------------------  ----------
21Feb13_133133|    Max            39.13                16.00           0.00000
21Feb13_133133|    Avg            38.80                 3.67           0.00000
21Feb13_133133|    Min            38.78                 2.00           0.00000
21Feb13_133133|    Std             0.06                 3.84           0.00000
21Feb13_133133|   Best            38.78                 2.00           0.00000
21Feb13_133133|-- Generation 29 --
21Feb13_133133|    -- Crossed 7 individual pairs.
21Feb13_133133|    -- Mutated 32 individuals.
21Feb13_133521|    -- Evaluated 64 individuals.
21Feb13_133521|    Summary of generation 29:
21Feb13_133521| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_133521|-----------  ------------------  --------------------  ----------
21Feb13_133521|    Max            39.57                14.00           0.00000
21Feb13_133521|    Avg            38.80                 3.45           0.00000
21Feb13_133521|    Min            38.78                 2.00           0.00000
21Feb13_133521|    Std             0.10                 3.48           0.00000
21Feb13_133521|   Best            38.78                 2.00           0.00000
21Feb13_133521|-- Generation 30 --
21Feb13_133521|    -- Crossed 7 individual pairs.
21Feb13_133521|    -- Mutated 32 individuals.
21Feb13_133911|    -- Evaluated 64 individuals.
21Feb13_133911|    Summary of generation 30:
21Feb13_133911| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_133911|-----------  ------------------  --------------------  ----------
21Feb13_133911|    Max            39.04                14.00           0.00000
21Feb13_133911|    Avg            38.80                 3.50           0.00000
21Feb13_133911|    Min            38.78                 2.00           0.00000
21Feb13_133911|    Std             0.05                 3.22           0.00000
21Feb13_133911|   Best            38.78                 2.00           0.00000
21Feb13_133911|The fitness has not improved in 10 generations:
21Feb13_133911|	Previous best fit: (38.78260869565218, 2.0, 0.0)
21Feb13_133911|	Current best fit: (38.78260869565218, 2.0, 0.0)
21Feb13_133911|Exiting...
21Feb13_133911|Best initial individual weights
21Feb13_133911|Individual:
21Feb13_133911|-- Constant hidden layers --
21Feb13_133911|False
21Feb13_133911|Layer 0:
21Feb13_133911|-- Config --
21Feb13_133911|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 20, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_133911|-- Weights --
21Feb13_133911|[[ 0.16538 -0.77401 -0.00608 ...  0.65170 -0.62891  0.06458]
21Feb13_133911| [-0.68906  0.49124 -0.82875 ...  0.95559 -0.22724  0.37174]
21Feb13_133911| [-0.02459 -0.65663 -0.70183 ...  0.93684 -0.35995  0.08562]
21Feb13_133911| ...
21Feb13_133911| [ 0.14376 -0.58767  0.38143 ...  0.88666 -0.25444  0.24251]
21Feb13_133911| [-0.27631 -0.15933 -0.55384 ...  0.20998 -0.36680 -0.31376]
21Feb13_133911| [ 0.63419 -0.93456 -0.15672 ...  0.23038 -0.88133 -0.63626]]
21Feb13_133911|-- Bias --
21Feb13_133911|[-0.97464 -0.85591 -0.86235 -0.65627 -0.32809 -0.92477  0.19771  0.12766
21Feb13_133911| -0.61142 -0.08191 -0.92249  0.78722 -0.91356 -0.41978  0.73481 -0.07531
21Feb13_133911| -0.13776  0.00316  0.07810  0.98042]
21Feb13_133911|Layer 1:
21Feb13_133911|-- Config --
21Feb13_133911|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 20], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_133911|-- Weights --
21Feb13_133911|[[ 0.17927  0.05059  0.14365 -0.97965]
21Feb13_133911| [-0.72966  0.18465 -0.57958 -0.75661]
21Feb13_133911| [ 0.79160 -0.44957 -0.30703 -0.23486]
21Feb13_133911| [-0.94331 -0.92779  0.16938  0.71109]
21Feb13_133911| [ 0.41752 -0.02958  0.95818  0.85022]
21Feb13_133911| [ 0.98523  0.75232 -0.88204 -0.34763]
21Feb13_133911| [ 0.43929 -0.44193 -0.21478 -0.76798]
21Feb13_133911| [ 0.52274 -0.25374  0.99449  0.65709]
21Feb13_133911| [ 0.99528  0.79914  0.62908 -0.34474]
21Feb13_133911| [-0.76572 -0.83928 -0.43847  0.89005]
21Feb13_133911| [-0.28948  0.48225 -0.04509  0.36951]
21Feb13_133911| [-0.70208  0.36214 -0.68534  0.91435]
21Feb13_133911| [ 0.31676  0.59374 -0.16533 -0.21022]
21Feb13_133911| [ 0.10818 -0.49682  0.95797 -0.21256]
21Feb13_133911| [-0.14358 -0.61799  0.22976 -0.62086]
21Feb13_133911| [ 0.06347  0.37842  0.26411  0.83836]
21Feb13_133911| [-0.97809 -0.90875  0.74790  0.55812]
21Feb13_133911| [ 0.91386 -0.35732  0.47048  0.17558]
21Feb13_133911| [ 0.90609 -0.08591 -0.50923  0.24402]
21Feb13_133911| [ 0.34637 -0.02023  0.98795  0.71753]]
21Feb13_133911|-- Bias --
21Feb13_133911|[ 0.77827 -0.93300 -0.04224  0.08863]
21Feb13_133911|Layer 2:
21Feb13_133911|-- Config --
21Feb13_133911|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 18, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_133911|-- Weights --
21Feb13_133911|[[ 0.38090  0.16612 -0.87717  0.16049  0.05373 -0.15095  0.96084  0.99870
21Feb13_133911|  -0.21572 -0.50778 -0.11916 -0.07972 -0.31260 -0.19441 -0.75699 -0.47510
21Feb13_133911|  -0.07048  0.39064]
21Feb13_133911| [ 0.96786 -0.97945  0.32351  0.31609  0.06547 -0.70443 -0.77079 -0.79363
21Feb13_133911|   0.13246  0.60960  0.14455  0.78804 -0.03175 -0.16979  0.05102  0.15370
21Feb13_133911|   0.34980  0.01450]
21Feb13_133911| [-0.94330  0.20605  0.67576 -0.68437  0.84773 -0.93620  0.40850  0.71162
21Feb13_133911|   0.62654 -0.94535  0.68679 -0.62690  0.12123  0.70189 -0.98775  0.87563
21Feb13_133911|   0.37593 -0.36252]
21Feb13_133911| [ 0.09964  0.65946 -0.07812  0.85653  0.78644  0.33656  0.11319  0.53560
21Feb13_133911|  -0.54287 -0.48351  0.00897  0.78783 -0.57189 -0.85225 -0.78126  0.09783
21Feb13_133911|  -0.70814  0.05556]]
21Feb13_133911|-- Bias --
21Feb13_133911|[-0.80382 -0.52251 -0.43409  0.42023  0.55006 -0.61225 -0.73400  0.48184
21Feb13_133911|  0.81203 -0.35601  0.58294 -0.48240 -0.90354 -0.60396 -0.46119 -0.74489
21Feb13_133911|  0.56448  0.25321]
21Feb13_133911|Layer 3:
21Feb13_133911|-- Config --
21Feb13_133911|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 18], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_133911|-- Weights --
21Feb13_133911|[[ 0.04876 -0.39185]
21Feb13_133911| [-0.55679 -0.06391]
21Feb13_133911| [ 0.01400  0.05819]
21Feb13_133911| [ 0.89548  0.31939]
21Feb13_133911| [-0.33667 -0.63002]
21Feb13_133911| [ 0.37466  0.38304]
21Feb13_133911| [-0.78135 -0.02638]
21Feb13_133911| [ 0.64500  0.58024]
21Feb13_133911| [-0.28350 -0.21430]
21Feb13_133911| [ 0.90758  0.84536]
21Feb13_133911| [ 0.31835 -0.30832]
21Feb13_133911| [-0.57902  0.00787]
21Feb13_133911| [-0.25556 -0.97136]
21Feb13_133911| [-0.41410  0.93435]
21Feb13_133911| [ 0.00794 -0.66137]
21Feb13_133911| [ 0.99846  0.40167]
21Feb13_133911| [ 0.16777  0.38823]
21Feb13_133911| [ 0.52043 -0.12533]]
21Feb13_133911|-- Bias --
21Feb13_133911|[0.75983 0.86308]
21Feb13_133911|Predicting the validation and test data with the Best initial individual.
21Feb13_133919| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_133919|-----------  ------------------  --------------------  ----------
21Feb13_133919|Validation         38.78                 126            0.00000
21Feb13_133919|   Test            39.10                 126            0.00000
21Feb13_133919|-------------------- Test #0 --------------------
21Feb13_133919|Best final individual weights
21Feb13_133919|Individual:
21Feb13_133919|-- Constant hidden layers --
21Feb13_133919|False
21Feb13_133919|Layer 0:
21Feb13_133919|-- Config --
21Feb13_133919|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_133919|-- Weights --
21Feb13_133919|[[ 0.32104  0.61569]
21Feb13_133919| [-0.41279  0.32569]
21Feb13_133919| [ 0.92289  0.54500]
21Feb13_133919| [ 1.79213  0.45034]
21Feb13_133919| [ 0.19404 -0.27829]
21Feb13_133919| [ 1.40124 -0.41596]
21Feb13_133919| [ 0.63246  0.02112]
21Feb13_133919| [-0.89776  1.51786]
21Feb13_133919| [ 1.41674 -0.54312]
21Feb13_133919| [ 0.42736  1.02415]
21Feb13_133919| [-0.01687 -1.42995]
21Feb13_133919| [-0.57162 -0.03201]
21Feb13_133919| [-0.43559 -0.14509]
21Feb13_133919| [ 0.37598  1.10418]
21Feb13_133919| [ 1.83758 -0.24958]
21Feb13_133919| [ 0.31401 -1.31086]
21Feb13_133919| [-1.18647 -0.50781]
21Feb13_133919| [ 0.17264 -1.22236]
21Feb13_133919| [-0.57236 -0.04586]
21Feb13_133919| [ 0.12430  1.26599]
21Feb13_133919| [-0.39206 -0.17742]
21Feb13_133919| [ 0.64517  0.45354]
21Feb13_133919| [-0.27228 -0.70483]
21Feb13_133919| [ 0.69282 -0.41916]
21Feb13_133919| [-0.16537  0.76412]
21Feb13_133919| [-0.63424  0.52767]
21Feb13_133919| [-0.61549  0.26167]
21Feb13_133919| [ 0.27883  0.91609]
21Feb13_133919| [ 0.59316  1.16883]
21Feb13_133919| [ 0.86908 -0.54124]
21Feb13_133919| [-0.95885 -0.56059]
21Feb13_133919| [ 0.30086  0.71889]
21Feb13_133919| [-1.68842  0.72905]
21Feb13_133919| [-0.87035  1.30405]
21Feb13_133919| [-0.04551 -0.13057]
21Feb13_133919| [-0.06314  0.12563]
21Feb13_133919| [ 0.17211 -1.42734]
21Feb13_133919| [-0.12855 -0.95393]
21Feb13_133919| [ 0.22170  0.86302]
21Feb13_133919| [-0.68713 -1.47512]
21Feb13_133919| [ 0.15758 -0.09346]
21Feb13_133919| [-1.18384  0.52780]
21Feb13_133919| [-0.72366  0.15677]
21Feb13_133919| [ 0.30831  0.28092]
21Feb13_133919| [-0.93134 -1.12436]
21Feb13_133919| [-0.45683 -0.14492]
21Feb13_133919| [-0.83521 -0.06431]
21Feb13_133919| [ 1.55615 -0.30180]
21Feb13_133919| [ 0.10461 -0.33054]
21Feb13_133919| [-0.01752 -1.05392]
21Feb13_133919| [-0.47739  0.08643]
21Feb13_133919| [ 0.50720  0.39835]
21Feb13_133919| [ 0.80674 -0.21923]
21Feb13_133919| [-0.30877  0.99188]
21Feb13_133919| [-1.94369 -0.33384]
21Feb13_133919| [ 0.32802  0.48644]
21Feb13_133919| [-0.88146 -0.59046]]
21Feb13_133919|-- Bias --
21Feb13_133919|[ 0.16224 -0.84795]
21Feb13_133919|Layer 1:
21Feb13_133919|-- Config --
21Feb13_133919|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_133919|-- Weights --
21Feb13_133919|[[-0.16795 -0.85647]
21Feb13_133919| [ 0.97061 -0.95915]]
21Feb13_133919|-- Bias --
21Feb13_133919|[-0.09868  0.31871]
21Feb13_133919|Predicting the validation and test data with the Best final individual.
21Feb13_133926| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_133926|-----------  ------------------  --------------------  ----------
21Feb13_133926|Validation         38.78                  2             0.00000
21Feb13_133926|   Test            39.01                  2             0.00000
21Feb13_133926|-------------------- Test #1 --------------------
21Feb13_133926|Best final individual weights
21Feb13_133926|Individual:
21Feb13_133926|-- Constant hidden layers --
21Feb13_133926|False
21Feb13_133926|Layer 0:
21Feb13_133926|-- Config --
21Feb13_133926|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_133926|-- Weights --
21Feb13_133926|[[ 0.32104  0.61569]
21Feb13_133926| [-0.41279  0.32569]
21Feb13_133926| [ 0.92289  0.54500]
21Feb13_133926| [ 1.79213  0.45034]
21Feb13_133926| [ 0.19404 -0.27829]
21Feb13_133926| [ 1.40124 -0.41596]
21Feb13_133926| [ 0.63246  0.02112]
21Feb13_133926| [-0.89776  1.51786]
21Feb13_133926| [ 1.41674 -0.54312]
21Feb13_133926| [ 0.42736  1.02415]
21Feb13_133926| [-0.01687 -1.42995]
21Feb13_133926| [-0.57162 -0.03201]
21Feb13_133926| [-0.43559 -0.14509]
21Feb13_133926| [ 0.37598  1.10418]
21Feb13_133926| [ 1.83758 -0.24958]
21Feb13_133926| [ 0.31401 -1.31086]
21Feb13_133926| [-1.18647 -0.50781]
21Feb13_133926| [ 0.17264 -1.22236]
21Feb13_133926| [-0.57236 -0.04586]
21Feb13_133926| [ 0.12430  1.26599]
21Feb13_133926| [-0.39206 -0.17742]
21Feb13_133926| [ 0.64517  0.45354]
21Feb13_133926| [-0.27228 -0.70483]
21Feb13_133926| [ 0.69282 -0.41916]
21Feb13_133926| [-0.16537  0.76412]
21Feb13_133926| [-0.63424  0.52767]
21Feb13_133926| [-0.61549  0.26167]
21Feb13_133926| [ 0.27883  0.91609]
21Feb13_133926| [ 0.59316  1.16883]
21Feb13_133926| [ 0.86908 -0.54124]
21Feb13_133926| [-0.95885 -0.56059]
21Feb13_133926| [ 0.30086  0.71889]
21Feb13_133926| [-1.68842  0.72905]
21Feb13_133926| [-0.87035  1.30405]
21Feb13_133926| [-0.04551 -0.13057]
21Feb13_133926| [-0.06314  0.12563]
21Feb13_133926| [ 0.17211 -1.42734]
21Feb13_133926| [-0.12855 -0.95393]
21Feb13_133926| [ 0.22170  0.86302]
21Feb13_133926| [-0.68713 -1.47512]
21Feb13_133926| [ 0.15758 -0.09346]
21Feb13_133926| [-1.18384  0.52780]
21Feb13_133926| [-0.72366  0.15677]
21Feb13_133926| [ 0.30831  0.28092]
21Feb13_133926| [-0.93134 -1.12436]
21Feb13_133926| [-0.45683 -0.14492]
21Feb13_133926| [-0.83521 -0.06431]
21Feb13_133926| [ 1.55615 -0.30180]
21Feb13_133926| [ 0.10461 -0.33054]
21Feb13_133926| [-0.01752 -1.05392]
21Feb13_133926| [-0.47739  0.08643]
21Feb13_133926| [ 0.50720  0.39835]
21Feb13_133926| [ 0.80674 -0.21923]
21Feb13_133926| [-0.30877  0.99188]
21Feb13_133926| [-1.94369 -0.33384]
21Feb13_133926| [ 0.32802  0.48644]
21Feb13_133926| [-0.88146 -0.59046]]
21Feb13_133926|-- Bias --
21Feb13_133926|[ 0.16224 -0.84795]
21Feb13_133926|Layer 1:
21Feb13_133926|-- Config --
21Feb13_133926|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_133926|-- Weights --
21Feb13_133926|[[-0.16795 -0.85647]
21Feb13_133926| [ 0.97061 -0.95915]]
21Feb13_133926|-- Bias --
21Feb13_133926|[-0.09868  0.31871]
21Feb13_133926|Predicting the validation and test data with the Best final individual.
21Feb13_133933| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_133933|-----------  ------------------  --------------------  ----------
21Feb13_133933|Validation         38.78                  2             0.00000
21Feb13_133933|   Test            39.01                  2             0.00000
21Feb13_133933|-------------------- Test #2 --------------------
21Feb13_133933|Best final individual weights
21Feb13_133933|Individual:
21Feb13_133933|-- Constant hidden layers --
21Feb13_133933|False
21Feb13_133933|Layer 0:
21Feb13_133933|-- Config --
21Feb13_133933|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_133933|-- Weights --
21Feb13_133933|[[ 0.32104  0.61569]
21Feb13_133933| [-0.41279  0.32569]
21Feb13_133933| [ 0.92289  0.54500]
21Feb13_133933| [ 1.79213  0.45034]
21Feb13_133933| [ 0.19404 -0.27829]
21Feb13_133933| [ 1.40124 -0.41596]
21Feb13_133933| [ 0.63246  0.02112]
21Feb13_133933| [-0.89776  1.51786]
21Feb13_133933| [ 1.41674 -0.54312]
21Feb13_133933| [ 0.42736  1.02415]
21Feb13_133933| [-0.01687 -1.42995]
21Feb13_133933| [-0.57162 -0.03201]
21Feb13_133933| [-0.43559 -0.14509]
21Feb13_133933| [ 0.37598  1.10418]
21Feb13_133933| [ 1.83758 -0.24958]
21Feb13_133933| [ 0.31401 -1.31086]
21Feb13_133933| [-1.18647 -0.50781]
21Feb13_133933| [ 0.17264 -1.22236]
21Feb13_133933| [-0.57236 -0.04586]
21Feb13_133933| [ 0.12430  1.26599]
21Feb13_133933| [-0.39206 -0.17742]
21Feb13_133933| [ 0.64517  0.45354]
21Feb13_133933| [-0.27228 -0.70483]
21Feb13_133933| [ 0.69282 -0.41916]
21Feb13_133933| [-0.16537  0.76412]
21Feb13_133933| [-0.63424  0.52767]
21Feb13_133933| [-0.61549  0.26167]
21Feb13_133933| [ 0.27883  0.91609]
21Feb13_133933| [ 0.59316  1.16883]
21Feb13_133933| [ 0.86908 -0.54124]
21Feb13_133933| [-0.95885 -0.56059]
21Feb13_133933| [ 0.30086  0.71889]
21Feb13_133933| [-1.68842  0.72905]
21Feb13_133933| [-0.87035  1.30405]
21Feb13_133933| [-0.04551 -0.13057]
21Feb13_133933| [-0.06314  0.12563]
21Feb13_133933| [ 0.17211 -1.42734]
21Feb13_133933| [-0.12855 -0.95393]
21Feb13_133933| [ 0.22170  0.86302]
21Feb13_133933| [-0.68713 -1.47512]
21Feb13_133933| [ 0.15758 -0.09346]
21Feb13_133933| [-1.18384  0.52780]
21Feb13_133933| [-0.72366  0.15677]
21Feb13_133933| [ 0.30831  0.28092]
21Feb13_133933| [-0.93134 -1.12436]
21Feb13_133933| [-0.45683 -0.14492]
21Feb13_133933| [-0.83521 -0.06431]
21Feb13_133933| [ 1.55615 -0.30180]
21Feb13_133933| [ 0.10461 -0.33054]
21Feb13_133933| [-0.01752 -1.05392]
21Feb13_133933| [-0.47739  0.08643]
21Feb13_133933| [ 0.50720  0.39835]
21Feb13_133933| [ 0.80674 -0.21923]
21Feb13_133933| [-0.30877  0.99188]
21Feb13_133933| [-1.94369 -0.33384]
21Feb13_133933| [ 0.32802  0.48644]
21Feb13_133933| [-0.88146 -0.59046]]
21Feb13_133933|-- Bias --
21Feb13_133933|[ 0.16224 -0.84795]
21Feb13_133933|Layer 1:
21Feb13_133933|-- Config --
21Feb13_133933|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_133933|-- Weights --
21Feb13_133933|[[-0.16795 -0.85647]
21Feb13_133933| [ 0.97061 -0.95915]]
21Feb13_133933|-- Bias --
21Feb13_133933|[-0.09868  0.31871]
21Feb13_133933|Predicting the validation and test data with the Best final individual.
21Feb13_133940| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_133940|-----------  ------------------  --------------------  ----------
21Feb13_133940|Validation         38.78                  2             0.00000
21Feb13_133940|   Test            39.01                  2             0.00000
21Feb13_133940|-------------------- Test #3 --------------------
21Feb13_133940|Best final individual weights
21Feb13_133940|Individual:
21Feb13_133940|-- Constant hidden layers --
21Feb13_133940|False
21Feb13_133940|Layer 0:
21Feb13_133940|-- Config --
21Feb13_133940|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_133940|-- Weights --
21Feb13_133940|[[ 0.32104  0.61569]
21Feb13_133940| [-0.41279  0.32569]
21Feb13_133940| [ 0.92289  0.54500]
21Feb13_133940| [ 1.79213  0.45034]
21Feb13_133940| [ 0.19404 -0.27829]
21Feb13_133940| [ 1.40124 -0.41596]
21Feb13_133940| [ 0.63246  0.02112]
21Feb13_133940| [-0.89776  1.51786]
21Feb13_133940| [ 1.41674 -0.54312]
21Feb13_133940| [ 0.42736  1.02415]
21Feb13_133940| [-0.01687 -1.42995]
21Feb13_133940| [-0.57162 -0.03201]
21Feb13_133940| [-0.43559 -0.14509]
21Feb13_133940| [ 0.37598  1.10418]
21Feb13_133940| [ 1.83758 -0.24958]
21Feb13_133940| [ 0.31401 -1.31086]
21Feb13_133940| [-1.18647 -0.50781]
21Feb13_133940| [ 0.17264 -1.22236]
21Feb13_133940| [-0.57236 -0.04586]
21Feb13_133940| [ 0.12430  1.26599]
21Feb13_133940| [-0.39206 -0.17742]
21Feb13_133940| [ 0.64517  0.45354]
21Feb13_133940| [-0.27228 -0.70483]
21Feb13_133940| [ 0.69282 -0.41916]
21Feb13_133940| [-0.16537  0.76412]
21Feb13_133940| [-0.63424  0.52767]
21Feb13_133940| [-0.61549  0.26167]
21Feb13_133940| [ 0.27883  0.91609]
21Feb13_133940| [ 0.59316  1.16883]
21Feb13_133940| [ 0.86908 -0.54124]
21Feb13_133940| [-0.95885 -0.56059]
21Feb13_133940| [ 0.30086  0.71889]
21Feb13_133940| [-1.68842  0.72905]
21Feb13_133940| [-0.87035  1.30405]
21Feb13_133940| [-0.04551 -0.13057]
21Feb13_133940| [-0.06314  0.12563]
21Feb13_133940| [ 0.17211 -1.42734]
21Feb13_133940| [-0.12855 -0.95393]
21Feb13_133940| [ 0.22170  0.86302]
21Feb13_133940| [-0.68713 -1.47512]
21Feb13_133940| [ 0.15758 -0.09346]
21Feb13_133940| [-1.18384  0.52780]
21Feb13_133940| [-0.72366  0.15677]
21Feb13_133940| [ 0.30831  0.28092]
21Feb13_133940| [-0.93134 -1.12436]
21Feb13_133940| [-0.45683 -0.14492]
21Feb13_133940| [-0.83521 -0.06431]
21Feb13_133940| [ 1.55615 -0.30180]
21Feb13_133940| [ 0.10461 -0.33054]
21Feb13_133940| [-0.01752 -1.05392]
21Feb13_133940| [-0.47739  0.08643]
21Feb13_133940| [ 0.50720  0.39835]
21Feb13_133940| [ 0.80674 -0.21923]
21Feb13_133940| [-0.30877  0.99188]
21Feb13_133940| [-1.94369 -0.33384]
21Feb13_133940| [ 0.32802  0.48644]
21Feb13_133940| [-0.88146 -0.59046]]
21Feb13_133940|-- Bias --
21Feb13_133940|[ 0.16224 -0.84795]
21Feb13_133940|Layer 1:
21Feb13_133940|-- Config --
21Feb13_133940|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_133940|-- Weights --
21Feb13_133940|[[-0.16795 -0.85647]
21Feb13_133940| [ 0.97061 -0.95915]]
21Feb13_133940|-- Bias --
21Feb13_133940|[-0.09868  0.31871]
21Feb13_133940|Predicting the validation and test data with the Best final individual.
21Feb13_133947| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_133947|-----------  ------------------  --------------------  ----------
21Feb13_133947|Validation         38.78                  2             0.00000
21Feb13_133947|   Test            39.01                  2             0.00000
21Feb13_133947|-------------------- Test #4 --------------------
21Feb13_133947|Best final individual weights
21Feb13_133947|Individual:
21Feb13_133947|-- Constant hidden layers --
21Feb13_133947|False
21Feb13_133947|Layer 0:
21Feb13_133947|-- Config --
21Feb13_133947|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_133947|-- Weights --
21Feb13_133947|[[ 0.32104  0.61569]
21Feb13_133947| [-0.41279  0.32569]
21Feb13_133947| [ 0.92289  0.54500]
21Feb13_133947| [ 1.79213  0.45034]
21Feb13_133947| [ 0.19404 -0.27829]
21Feb13_133947| [ 1.40124 -0.41596]
21Feb13_133947| [ 0.63246  0.02112]
21Feb13_133947| [-0.89776  1.51786]
21Feb13_133947| [ 1.41674 -0.54312]
21Feb13_133947| [ 0.42736  1.02415]
21Feb13_133947| [-0.01687 -1.42995]
21Feb13_133947| [-0.57162 -0.03201]
21Feb13_133947| [-0.43559 -0.14509]
21Feb13_133947| [ 0.37598  1.10418]
21Feb13_133947| [ 1.83758 -0.24958]
21Feb13_133947| [ 0.31401 -1.31086]
21Feb13_133947| [-1.18647 -0.50781]
21Feb13_133947| [ 0.17264 -1.22236]
21Feb13_133947| [-0.57236 -0.04586]
21Feb13_133947| [ 0.12430  1.26599]
21Feb13_133947| [-0.39206 -0.17742]
21Feb13_133947| [ 0.64517  0.45354]
21Feb13_133947| [-0.27228 -0.70483]
21Feb13_133947| [ 0.69282 -0.41916]
21Feb13_133947| [-0.16537  0.76412]
21Feb13_133947| [-0.63424  0.52767]
21Feb13_133947| [-0.61549  0.26167]
21Feb13_133947| [ 0.27883  0.91609]
21Feb13_133947| [ 0.59316  1.16883]
21Feb13_133947| [ 0.86908 -0.54124]
21Feb13_133947| [-0.95885 -0.56059]
21Feb13_133947| [ 0.30086  0.71889]
21Feb13_133947| [-1.68842  0.72905]
21Feb13_133947| [-0.87035  1.30405]
21Feb13_133947| [-0.04551 -0.13057]
21Feb13_133947| [-0.06314  0.12563]
21Feb13_133947| [ 0.17211 -1.42734]
21Feb13_133947| [-0.12855 -0.95393]
21Feb13_133947| [ 0.22170  0.86302]
21Feb13_133947| [-0.68713 -1.47512]
21Feb13_133947| [ 0.15758 -0.09346]
21Feb13_133947| [-1.18384  0.52780]
21Feb13_133947| [-0.72366  0.15677]
21Feb13_133947| [ 0.30831  0.28092]
21Feb13_133947| [-0.93134 -1.12436]
21Feb13_133947| [-0.45683 -0.14492]
21Feb13_133947| [-0.83521 -0.06431]
21Feb13_133947| [ 1.55615 -0.30180]
21Feb13_133947| [ 0.10461 -0.33054]
21Feb13_133947| [-0.01752 -1.05392]
21Feb13_133947| [-0.47739  0.08643]
21Feb13_133947| [ 0.50720  0.39835]
21Feb13_133947| [ 0.80674 -0.21923]
21Feb13_133947| [-0.30877  0.99188]
21Feb13_133947| [-1.94369 -0.33384]
21Feb13_133947| [ 0.32802  0.48644]
21Feb13_133947| [-0.88146 -0.59046]]
21Feb13_133947|-- Bias --
21Feb13_133947|[ 0.16224 -0.84795]
21Feb13_133947|Layer 1:
21Feb13_133947|-- Config --
21Feb13_133947|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_133947|-- Weights --
21Feb13_133947|[[-0.16795 -0.85647]
21Feb13_133947| [ 0.97061 -0.95915]]
21Feb13_133947|-- Bias --
21Feb13_133947|[-0.09868  0.31871]
21Feb13_133947|Predicting the validation and test data with the Best final individual.
21Feb13_133955| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_133955|-----------  ------------------  --------------------  ----------
21Feb13_133955|Validation         38.78                  2             0.00000
21Feb13_133955|   Test            39.01                  2             0.00000
21Feb13_133955|-------------------- Test #5 --------------------
21Feb13_133955|Best final individual weights
21Feb13_133955|Individual:
21Feb13_133955|-- Constant hidden layers --
21Feb13_133955|False
21Feb13_133955|Layer 0:
21Feb13_133955|-- Config --
21Feb13_133955|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_133955|-- Weights --
21Feb13_133955|[[ 0.32104  0.61569]
21Feb13_133955| [-0.41279  0.32569]
21Feb13_133955| [ 0.92289  0.54500]
21Feb13_133955| [ 1.79213  0.45034]
21Feb13_133955| [ 0.19404 -0.27829]
21Feb13_133955| [ 1.40124 -0.41596]
21Feb13_133955| [ 0.63246  0.02112]
21Feb13_133955| [-0.89776  1.51786]
21Feb13_133955| [ 1.41674 -0.54312]
21Feb13_133955| [ 0.42736  1.02415]
21Feb13_133955| [-0.01687 -1.42995]
21Feb13_133955| [-0.57162 -0.03201]
21Feb13_133955| [-0.43559 -0.14509]
21Feb13_133955| [ 0.37598  1.10418]
21Feb13_133955| [ 1.83758 -0.24958]
21Feb13_133955| [ 0.31401 -1.31086]
21Feb13_133955| [-1.18647 -0.50781]
21Feb13_133955| [ 0.17264 -1.22236]
21Feb13_133955| [-0.57236 -0.04586]
21Feb13_133955| [ 0.12430  1.26599]
21Feb13_133955| [-0.39206 -0.17742]
21Feb13_133955| [ 0.64517  0.45354]
21Feb13_133955| [-0.27228 -0.70483]
21Feb13_133955| [ 0.69282 -0.41916]
21Feb13_133955| [-0.16537  0.76412]
21Feb13_133955| [-0.63424  0.52767]
21Feb13_133955| [-0.61549  0.26167]
21Feb13_133955| [ 0.27883  0.91609]
21Feb13_133955| [ 0.59316  1.16883]
21Feb13_133955| [ 0.86908 -0.54124]
21Feb13_133955| [-0.95885 -0.56059]
21Feb13_133955| [ 0.30086  0.71889]
21Feb13_133955| [-1.68842  0.72905]
21Feb13_133955| [-0.87035  1.30405]
21Feb13_133955| [-0.04551 -0.13057]
21Feb13_133955| [-0.06314  0.12563]
21Feb13_133955| [ 0.17211 -1.42734]
21Feb13_133955| [-0.12855 -0.95393]
21Feb13_133955| [ 0.22170  0.86302]
21Feb13_133955| [-0.68713 -1.47512]
21Feb13_133955| [ 0.15758 -0.09346]
21Feb13_133955| [-1.18384  0.52780]
21Feb13_133955| [-0.72366  0.15677]
21Feb13_133955| [ 0.30831  0.28092]
21Feb13_133955| [-0.93134 -1.12436]
21Feb13_133955| [-0.45683 -0.14492]
21Feb13_133955| [-0.83521 -0.06431]
21Feb13_133955| [ 1.55615 -0.30180]
21Feb13_133955| [ 0.10461 -0.33054]
21Feb13_133955| [-0.01752 -1.05392]
21Feb13_133955| [-0.47739  0.08643]
21Feb13_133955| [ 0.50720  0.39835]
21Feb13_133955| [ 0.80674 -0.21923]
21Feb13_133955| [-0.30877  0.99188]
21Feb13_133955| [-1.94369 -0.33384]
21Feb13_133955| [ 0.32802  0.48644]
21Feb13_133955| [-0.88146 -0.59046]]
21Feb13_133955|-- Bias --
21Feb13_133955|[ 0.16224 -0.84795]
21Feb13_133955|Layer 1:
21Feb13_133955|-- Config --
21Feb13_133955|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_133955|-- Weights --
21Feb13_133955|[[-0.16795 -0.85647]
21Feb13_133955| [ 0.97061 -0.95915]]
21Feb13_133955|-- Bias --
21Feb13_133955|[-0.09868  0.31871]
21Feb13_133955|Predicting the validation and test data with the Best final individual.
21Feb13_134002| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_134002|-----------  ------------------  --------------------  ----------
21Feb13_134002|Validation         38.78                  2             0.00000
21Feb13_134002|   Test            39.01                  2             0.00000
21Feb13_134002|-------------------- Test #6 --------------------
21Feb13_134002|Best final individual weights
21Feb13_134002|Individual:
21Feb13_134002|-- Constant hidden layers --
21Feb13_134002|False
21Feb13_134002|Layer 0:
21Feb13_134002|-- Config --
21Feb13_134002|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_134002|-- Weights --
21Feb13_134002|[[ 0.32104  0.61569]
21Feb13_134002| [-0.41279  0.32569]
21Feb13_134002| [ 0.92289  0.54500]
21Feb13_134002| [ 1.79213  0.45034]
21Feb13_134002| [ 0.19404 -0.27829]
21Feb13_134002| [ 1.40124 -0.41596]
21Feb13_134002| [ 0.63246  0.02112]
21Feb13_134002| [-0.89776  1.51786]
21Feb13_134002| [ 1.41674 -0.54312]
21Feb13_134002| [ 0.42736  1.02415]
21Feb13_134002| [-0.01687 -1.42995]
21Feb13_134002| [-0.57162 -0.03201]
21Feb13_134002| [-0.43559 -0.14509]
21Feb13_134002| [ 0.37598  1.10418]
21Feb13_134002| [ 1.83758 -0.24958]
21Feb13_134002| [ 0.31401 -1.31086]
21Feb13_134002| [-1.18647 -0.50781]
21Feb13_134002| [ 0.17264 -1.22236]
21Feb13_134002| [-0.57236 -0.04586]
21Feb13_134002| [ 0.12430  1.26599]
21Feb13_134002| [-0.39206 -0.17742]
21Feb13_134002| [ 0.64517  0.45354]
21Feb13_134002| [-0.27228 -0.70483]
21Feb13_134002| [ 0.69282 -0.41916]
21Feb13_134002| [-0.16537  0.76412]
21Feb13_134002| [-0.63424  0.52767]
21Feb13_134002| [-0.61549  0.26167]
21Feb13_134002| [ 0.27883  0.91609]
21Feb13_134002| [ 0.59316  1.16883]
21Feb13_134002| [ 0.86908 -0.54124]
21Feb13_134002| [-0.95885 -0.56059]
21Feb13_134002| [ 0.30086  0.71889]
21Feb13_134002| [-1.68842  0.72905]
21Feb13_134002| [-0.87035  1.30405]
21Feb13_134002| [-0.04551 -0.13057]
21Feb13_134002| [-0.06314  0.12563]
21Feb13_134002| [ 0.17211 -1.42734]
21Feb13_134002| [-0.12855 -0.95393]
21Feb13_134002| [ 0.22170  0.86302]
21Feb13_134002| [-0.68713 -1.47512]
21Feb13_134002| [ 0.15758 -0.09346]
21Feb13_134002| [-1.18384  0.52780]
21Feb13_134002| [-0.72366  0.15677]
21Feb13_134002| [ 0.30831  0.28092]
21Feb13_134002| [-0.93134 -1.12436]
21Feb13_134002| [-0.45683 -0.14492]
21Feb13_134002| [-0.83521 -0.06431]
21Feb13_134002| [ 1.55615 -0.30180]
21Feb13_134002| [ 0.10461 -0.33054]
21Feb13_134002| [-0.01752 -1.05392]
21Feb13_134002| [-0.47739  0.08643]
21Feb13_134002| [ 0.50720  0.39835]
21Feb13_134002| [ 0.80674 -0.21923]
21Feb13_134002| [-0.30877  0.99188]
21Feb13_134002| [-1.94369 -0.33384]
21Feb13_134002| [ 0.32802  0.48644]
21Feb13_134002| [-0.88146 -0.59046]]
21Feb13_134002|-- Bias --
21Feb13_134002|[ 0.16224 -0.84795]
21Feb13_134002|Layer 1:
21Feb13_134002|-- Config --
21Feb13_134002|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_134002|-- Weights --
21Feb13_134002|[[-0.16795 -0.85647]
21Feb13_134002| [ 0.97061 -0.95915]]
21Feb13_134002|-- Bias --
21Feb13_134002|[-0.09868  0.31871]
21Feb13_134002|Predicting the validation and test data with the Best final individual.
21Feb13_134009| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_134009|-----------  ------------------  --------------------  ----------
21Feb13_134009|Validation         38.78                  2             0.00000
21Feb13_134009|   Test            39.01                  2             0.00000
21Feb13_134009|-------------------- Test #7 --------------------
21Feb13_134009|Best final individual weights
21Feb13_134009|Individual:
21Feb13_134009|-- Constant hidden layers --
21Feb13_134009|False
21Feb13_134009|Layer 0:
21Feb13_134009|-- Config --
21Feb13_134009|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_134009|-- Weights --
21Feb13_134009|[[ 0.32104  0.61569]
21Feb13_134009| [-0.41279  0.32569]
21Feb13_134009| [ 0.92289  0.54500]
21Feb13_134009| [ 1.79213  0.45034]
21Feb13_134009| [ 0.19404 -0.27829]
21Feb13_134009| [ 1.40124 -0.41596]
21Feb13_134009| [ 0.63246  0.02112]
21Feb13_134009| [-0.89776  1.51786]
21Feb13_134009| [ 1.41674 -0.54312]
21Feb13_134009| [ 0.42736  1.02415]
21Feb13_134009| [-0.01687 -1.42995]
21Feb13_134009| [-0.57162 -0.03201]
21Feb13_134009| [-0.43559 -0.14509]
21Feb13_134009| [ 0.37598  1.10418]
21Feb13_134009| [ 1.83758 -0.24958]
21Feb13_134009| [ 0.31401 -1.31086]
21Feb13_134009| [-1.18647 -0.50781]
21Feb13_134009| [ 0.17264 -1.22236]
21Feb13_134009| [-0.57236 -0.04586]
21Feb13_134009| [ 0.12430  1.26599]
21Feb13_134009| [-0.39206 -0.17742]
21Feb13_134009| [ 0.64517  0.45354]
21Feb13_134009| [-0.27228 -0.70483]
21Feb13_134009| [ 0.69282 -0.41916]
21Feb13_134009| [-0.16537  0.76412]
21Feb13_134009| [-0.63424  0.52767]
21Feb13_134009| [-0.61549  0.26167]
21Feb13_134009| [ 0.27883  0.91609]
21Feb13_134009| [ 0.59316  1.16883]
21Feb13_134009| [ 0.86908 -0.54124]
21Feb13_134009| [-0.95885 -0.56059]
21Feb13_134009| [ 0.30086  0.71889]
21Feb13_134009| [-1.68842  0.72905]
21Feb13_134009| [-0.87035  1.30405]
21Feb13_134009| [-0.04551 -0.13057]
21Feb13_134009| [-0.06314  0.12563]
21Feb13_134009| [ 0.17211 -1.42734]
21Feb13_134009| [-0.12855 -0.95393]
21Feb13_134009| [ 0.22170  0.86302]
21Feb13_134009| [-0.68713 -1.47512]
21Feb13_134009| [ 0.15758 -0.09346]
21Feb13_134009| [-1.18384  0.52780]
21Feb13_134009| [-0.72366  0.15677]
21Feb13_134009| [ 0.30831  0.28092]
21Feb13_134009| [-0.93134 -1.12436]
21Feb13_134009| [-0.45683 -0.14492]
21Feb13_134009| [-0.83521 -0.06431]
21Feb13_134009| [ 1.55615 -0.30180]
21Feb13_134009| [ 0.10461 -0.33054]
21Feb13_134009| [-0.01752 -1.05392]
21Feb13_134009| [-0.47739  0.08643]
21Feb13_134009| [ 0.50720  0.39835]
21Feb13_134009| [ 0.80674 -0.21923]
21Feb13_134009| [-0.30877  0.99188]
21Feb13_134009| [-1.94369 -0.33384]
21Feb13_134009| [ 0.32802  0.48644]
21Feb13_134009| [-0.88146 -0.59046]]
21Feb13_134009|-- Bias --
21Feb13_134009|[ 0.16224 -0.84795]
21Feb13_134009|Layer 1:
21Feb13_134009|-- Config --
21Feb13_134009|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_134009|-- Weights --
21Feb13_134009|[[-0.16795 -0.85647]
21Feb13_134009| [ 0.97061 -0.95915]]
21Feb13_134009|-- Bias --
21Feb13_134009|[-0.09868  0.31871]
21Feb13_134009|Predicting the validation and test data with the Best final individual.
21Feb13_134016| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_134016|-----------  ------------------  --------------------  ----------
21Feb13_134016|Validation         38.78                  2             0.00000
21Feb13_134016|   Test            39.01                  2             0.00000
21Feb13_134016|-------------------- Test #8 --------------------
21Feb13_134016|Best final individual weights
21Feb13_134016|Individual:
21Feb13_134016|-- Constant hidden layers --
21Feb13_134016|False
21Feb13_134016|Layer 0:
21Feb13_134016|-- Config --
21Feb13_134016|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_134016|-- Weights --
21Feb13_134016|[[ 0.32104  0.61569]
21Feb13_134016| [-0.41279  0.32569]
21Feb13_134016| [ 0.92289  0.54500]
21Feb13_134016| [ 1.79213  0.45034]
21Feb13_134016| [ 0.19404 -0.27829]
21Feb13_134016| [ 1.40124 -0.41596]
21Feb13_134016| [ 0.63246  0.02112]
21Feb13_134016| [-0.89776  1.51786]
21Feb13_134016| [ 1.41674 -0.54312]
21Feb13_134016| [ 0.42736  1.02415]
21Feb13_134016| [-0.01687 -1.42995]
21Feb13_134016| [-0.57162 -0.03201]
21Feb13_134016| [-0.43559 -0.14509]
21Feb13_134016| [ 0.37598  1.10418]
21Feb13_134016| [ 1.83758 -0.24958]
21Feb13_134016| [ 0.31401 -1.31086]
21Feb13_134016| [-1.18647 -0.50781]
21Feb13_134016| [ 0.17264 -1.22236]
21Feb13_134016| [-0.57236 -0.04586]
21Feb13_134016| [ 0.12430  1.26599]
21Feb13_134016| [-0.39206 -0.17742]
21Feb13_134016| [ 0.64517  0.45354]
21Feb13_134016| [-0.27228 -0.70483]
21Feb13_134016| [ 0.69282 -0.41916]
21Feb13_134016| [-0.16537  0.76412]
21Feb13_134016| [-0.63424  0.52767]
21Feb13_134016| [-0.61549  0.26167]
21Feb13_134016| [ 0.27883  0.91609]
21Feb13_134016| [ 0.59316  1.16883]
21Feb13_134016| [ 0.86908 -0.54124]
21Feb13_134016| [-0.95885 -0.56059]
21Feb13_134016| [ 0.30086  0.71889]
21Feb13_134016| [-1.68842  0.72905]
21Feb13_134016| [-0.87035  1.30405]
21Feb13_134016| [-0.04551 -0.13057]
21Feb13_134016| [-0.06314  0.12563]
21Feb13_134016| [ 0.17211 -1.42734]
21Feb13_134016| [-0.12855 -0.95393]
21Feb13_134016| [ 0.22170  0.86302]
21Feb13_134016| [-0.68713 -1.47512]
21Feb13_134016| [ 0.15758 -0.09346]
21Feb13_134016| [-1.18384  0.52780]
21Feb13_134016| [-0.72366  0.15677]
21Feb13_134016| [ 0.30831  0.28092]
21Feb13_134016| [-0.93134 -1.12436]
21Feb13_134016| [-0.45683 -0.14492]
21Feb13_134016| [-0.83521 -0.06431]
21Feb13_134016| [ 1.55615 -0.30180]
21Feb13_134016| [ 0.10461 -0.33054]
21Feb13_134016| [-0.01752 -1.05392]
21Feb13_134016| [-0.47739  0.08643]
21Feb13_134016| [ 0.50720  0.39835]
21Feb13_134016| [ 0.80674 -0.21923]
21Feb13_134016| [-0.30877  0.99188]
21Feb13_134016| [-1.94369 -0.33384]
21Feb13_134016| [ 0.32802  0.48644]
21Feb13_134016| [-0.88146 -0.59046]]
21Feb13_134016|-- Bias --
21Feb13_134016|[ 0.16224 -0.84795]
21Feb13_134016|Layer 1:
21Feb13_134016|-- Config --
21Feb13_134016|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_134016|-- Weights --
21Feb13_134016|[[-0.16795 -0.85647]
21Feb13_134016| [ 0.97061 -0.95915]]
21Feb13_134016|-- Bias --
21Feb13_134016|[-0.09868  0.31871]
21Feb13_134016|Predicting the validation and test data with the Best final individual.
21Feb13_134023| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_134023|-----------  ------------------  --------------------  ----------
21Feb13_134023|Validation         38.78                  2             0.00000
21Feb13_134023|   Test            39.01                  2             0.00000
21Feb13_134023|-------------------- Test #9 --------------------
21Feb13_134023|Best final individual weights
21Feb13_134023|Individual:
21Feb13_134023|-- Constant hidden layers --
21Feb13_134023|False
21Feb13_134023|Layer 0:
21Feb13_134023|-- Config --
21Feb13_134023|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_134023|-- Weights --
21Feb13_134023|[[ 0.32104  0.61569]
21Feb13_134023| [-0.41279  0.32569]
21Feb13_134023| [ 0.92289  0.54500]
21Feb13_134023| [ 1.79213  0.45034]
21Feb13_134023| [ 0.19404 -0.27829]
21Feb13_134023| [ 1.40124 -0.41596]
21Feb13_134023| [ 0.63246  0.02112]
21Feb13_134023| [-0.89776  1.51786]
21Feb13_134023| [ 1.41674 -0.54312]
21Feb13_134023| [ 0.42736  1.02415]
21Feb13_134023| [-0.01687 -1.42995]
21Feb13_134023| [-0.57162 -0.03201]
21Feb13_134023| [-0.43559 -0.14509]
21Feb13_134023| [ 0.37598  1.10418]
21Feb13_134023| [ 1.83758 -0.24958]
21Feb13_134023| [ 0.31401 -1.31086]
21Feb13_134023| [-1.18647 -0.50781]
21Feb13_134023| [ 0.17264 -1.22236]
21Feb13_134023| [-0.57236 -0.04586]
21Feb13_134023| [ 0.12430  1.26599]
21Feb13_134023| [-0.39206 -0.17742]
21Feb13_134023| [ 0.64517  0.45354]
21Feb13_134023| [-0.27228 -0.70483]
21Feb13_134023| [ 0.69282 -0.41916]
21Feb13_134023| [-0.16537  0.76412]
21Feb13_134023| [-0.63424  0.52767]
21Feb13_134023| [-0.61549  0.26167]
21Feb13_134023| [ 0.27883  0.91609]
21Feb13_134023| [ 0.59316  1.16883]
21Feb13_134023| [ 0.86908 -0.54124]
21Feb13_134023| [-0.95885 -0.56059]
21Feb13_134023| [ 0.30086  0.71889]
21Feb13_134023| [-1.68842  0.72905]
21Feb13_134023| [-0.87035  1.30405]
21Feb13_134023| [-0.04551 -0.13057]
21Feb13_134023| [-0.06314  0.12563]
21Feb13_134023| [ 0.17211 -1.42734]
21Feb13_134023| [-0.12855 -0.95393]
21Feb13_134023| [ 0.22170  0.86302]
21Feb13_134023| [-0.68713 -1.47512]
21Feb13_134023| [ 0.15758 -0.09346]
21Feb13_134023| [-1.18384  0.52780]
21Feb13_134023| [-0.72366  0.15677]
21Feb13_134023| [ 0.30831  0.28092]
21Feb13_134023| [-0.93134 -1.12436]
21Feb13_134023| [-0.45683 -0.14492]
21Feb13_134023| [-0.83521 -0.06431]
21Feb13_134023| [ 1.55615 -0.30180]
21Feb13_134023| [ 0.10461 -0.33054]
21Feb13_134023| [-0.01752 -1.05392]
21Feb13_134023| [-0.47739  0.08643]
21Feb13_134023| [ 0.50720  0.39835]
21Feb13_134023| [ 0.80674 -0.21923]
21Feb13_134023| [-0.30877  0.99188]
21Feb13_134023| [-1.94369 -0.33384]
21Feb13_134023| [ 0.32802  0.48644]
21Feb13_134023| [-0.88146 -0.59046]]
21Feb13_134023|-- Bias --
21Feb13_134023|[ 0.16224 -0.84795]
21Feb13_134023|Layer 1:
21Feb13_134023|-- Config --
21Feb13_134023|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_134023|-- Weights --
21Feb13_134023|[[-0.16795 -0.85647]
21Feb13_134023| [ 0.97061 -0.95915]]
21Feb13_134023|-- Bias --
21Feb13_134023|[-0.09868  0.31871]
21Feb13_134023|Predicting the validation and test data with the Best final individual.
21Feb13_134030| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_134030|-----------  ------------------  --------------------  ----------
21Feb13_134030|Validation         38.78                  2             0.00000
21Feb13_134030|   Test            39.01                  2             0.00000
21Feb13_134030|-------------------- Test #10 --------------------
21Feb13_134030|Best final individual weights
21Feb13_134030|Individual:
21Feb13_134030|-- Constant hidden layers --
21Feb13_134030|False
21Feb13_134030|Layer 0:
21Feb13_134030|-- Config --
21Feb13_134030|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_134030|-- Weights --
21Feb13_134030|[[ 0.32104  0.61569]
21Feb13_134030| [-0.41279  0.32569]
21Feb13_134030| [ 0.92289  0.54500]
21Feb13_134030| [ 1.79213  0.45034]
21Feb13_134030| [ 0.19404 -0.27829]
21Feb13_134030| [ 1.40124 -0.41596]
21Feb13_134030| [ 0.63246  0.02112]
21Feb13_134030| [-0.89776  1.51786]
21Feb13_134030| [ 1.41674 -0.54312]
21Feb13_134030| [ 0.42736  1.02415]
21Feb13_134030| [-0.01687 -1.42995]
21Feb13_134030| [-0.57162 -0.03201]
21Feb13_134030| [-0.43559 -0.14509]
21Feb13_134030| [ 0.37598  1.10418]
21Feb13_134030| [ 1.83758 -0.24958]
21Feb13_134030| [ 0.31401 -1.31086]
21Feb13_134030| [-1.18647 -0.50781]
21Feb13_134030| [ 0.17264 -1.22236]
21Feb13_134030| [-0.57236 -0.04586]
21Feb13_134030| [ 0.12430  1.26599]
21Feb13_134030| [-0.39206 -0.17742]
21Feb13_134030| [ 0.64517  0.45354]
21Feb13_134030| [-0.27228 -0.70483]
21Feb13_134030| [ 0.69282 -0.41916]
21Feb13_134030| [-0.16537  0.76412]
21Feb13_134030| [-0.63424  0.52767]
21Feb13_134030| [-0.61549  0.26167]
21Feb13_134030| [ 0.27883  0.91609]
21Feb13_134030| [ 0.59316  1.16883]
21Feb13_134030| [ 0.86908 -0.54124]
21Feb13_134030| [-0.95885 -0.56059]
21Feb13_134030| [ 0.30086  0.71889]
21Feb13_134030| [-1.68842  0.72905]
21Feb13_134030| [-0.87035  1.30405]
21Feb13_134030| [-0.04551 -0.13057]
21Feb13_134030| [-0.06314  0.12563]
21Feb13_134030| [ 0.17211 -1.42734]
21Feb13_134030| [-0.12855 -0.95393]
21Feb13_134030| [ 0.22170  0.86302]
21Feb13_134030| [-0.68713 -1.47512]
21Feb13_134030| [ 0.15758 -0.09346]
21Feb13_134030| [-1.18384  0.52780]
21Feb13_134030| [-0.72366  0.15677]
21Feb13_134030| [ 0.30831  0.28092]
21Feb13_134030| [-0.93134 -1.12436]
21Feb13_134030| [-0.45683 -0.14492]
21Feb13_134030| [-0.83521 -0.06431]
21Feb13_134030| [ 1.55615 -0.30180]
21Feb13_134030| [ 0.10461 -0.33054]
21Feb13_134030| [-0.01752 -1.05392]
21Feb13_134030| [-0.47739  0.08643]
21Feb13_134030| [ 0.50720  0.39835]
21Feb13_134030| [ 0.80674 -0.21923]
21Feb13_134030| [-0.30877  0.99188]
21Feb13_134030| [-1.94369 -0.33384]
21Feb13_134030| [ 0.32802  0.48644]
21Feb13_134030| [-0.88146 -0.59046]]
21Feb13_134030|-- Bias --
21Feb13_134030|[ 0.16224 -0.84795]
21Feb13_134030|Layer 1:
21Feb13_134030|-- Config --
21Feb13_134030|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_134030|-- Weights --
21Feb13_134030|[[-0.16795 -0.85647]
21Feb13_134030| [ 0.97061 -0.95915]]
21Feb13_134030|-- Bias --
21Feb13_134030|[-0.09868  0.31871]
21Feb13_134030|Predicting the validation and test data with the Best final individual.
21Feb13_134038| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_134038|-----------  ------------------  --------------------  ----------
21Feb13_134038|Validation         38.78                  2             0.00000
21Feb13_134038|   Test            39.01                  2             0.00000
21Feb13_134038|-------------------- Test #11 --------------------
21Feb13_134038|Best final individual weights
21Feb13_134038|Individual:
21Feb13_134038|-- Constant hidden layers --
21Feb13_134038|False
21Feb13_134038|Layer 0:
21Feb13_134038|-- Config --
21Feb13_134038|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_134038|-- Weights --
21Feb13_134038|[[ 0.32104  0.61569]
21Feb13_134038| [-0.41279  0.32569]
21Feb13_134038| [ 0.92289  0.54500]
21Feb13_134038| [ 1.79213  0.45034]
21Feb13_134038| [ 0.19404 -0.27829]
21Feb13_134038| [ 1.40124 -0.41596]
21Feb13_134038| [ 0.63246  0.02112]
21Feb13_134038| [-0.89776  1.51786]
21Feb13_134038| [ 1.41674 -0.54312]
21Feb13_134038| [ 0.42736  1.02415]
21Feb13_134038| [-0.01687 -1.42995]
21Feb13_134038| [-0.57162 -0.03201]
21Feb13_134038| [-0.43559 -0.14509]
21Feb13_134038| [ 0.37598  1.10418]
21Feb13_134038| [ 1.83758 -0.24958]
21Feb13_134038| [ 0.31401 -1.31086]
21Feb13_134038| [-1.18647 -0.50781]
21Feb13_134038| [ 0.17264 -1.22236]
21Feb13_134038| [-0.57236 -0.04586]
21Feb13_134038| [ 0.12430  1.26599]
21Feb13_134038| [-0.39206 -0.17742]
21Feb13_134038| [ 0.64517  0.45354]
21Feb13_134038| [-0.27228 -0.70483]
21Feb13_134038| [ 0.69282 -0.41916]
21Feb13_134038| [-0.16537  0.76412]
21Feb13_134038| [-0.63424  0.52767]
21Feb13_134038| [-0.61549  0.26167]
21Feb13_134038| [ 0.27883  0.91609]
21Feb13_134038| [ 0.59316  1.16883]
21Feb13_134038| [ 0.86908 -0.54124]
21Feb13_134038| [-0.95885 -0.56059]
21Feb13_134038| [ 0.30086  0.71889]
21Feb13_134038| [-1.68842  0.72905]
21Feb13_134038| [-0.87035  1.30405]
21Feb13_134038| [-0.04551 -0.13057]
21Feb13_134038| [-0.06314  0.12563]
21Feb13_134038| [ 0.17211 -1.42734]
21Feb13_134038| [-0.12855 -0.95393]
21Feb13_134038| [ 0.22170  0.86302]
21Feb13_134038| [-0.68713 -1.47512]
21Feb13_134038| [ 0.15758 -0.09346]
21Feb13_134038| [-1.18384  0.52780]
21Feb13_134038| [-0.72366  0.15677]
21Feb13_134038| [ 0.30831  0.28092]
21Feb13_134038| [-0.93134 -1.12436]
21Feb13_134038| [-0.45683 -0.14492]
21Feb13_134038| [-0.83521 -0.06431]
21Feb13_134038| [ 1.55615 -0.30180]
21Feb13_134038| [ 0.10461 -0.33054]
21Feb13_134038| [-0.01752 -1.05392]
21Feb13_134038| [-0.47739  0.08643]
21Feb13_134038| [ 0.50720  0.39835]
21Feb13_134038| [ 0.80674 -0.21923]
21Feb13_134038| [-0.30877  0.99188]
21Feb13_134038| [-1.94369 -0.33384]
21Feb13_134038| [ 0.32802  0.48644]
21Feb13_134038| [-0.88146 -0.59046]]
21Feb13_134038|-- Bias --
21Feb13_134038|[ 0.16224 -0.84795]
21Feb13_134038|Layer 1:
21Feb13_134038|-- Config --
21Feb13_134038|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_134038|-- Weights --
21Feb13_134038|[[-0.16795 -0.85647]
21Feb13_134038| [ 0.97061 -0.95915]]
21Feb13_134038|-- Bias --
21Feb13_134038|[-0.09868  0.31871]
21Feb13_134038|Predicting the validation and test data with the Best final individual.
21Feb13_134045| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_134045|-----------  ------------------  --------------------  ----------
21Feb13_134045|Validation         38.78                  2             0.00000
21Feb13_134045|   Test            39.01                  2             0.00000
21Feb13_134045|-------------------- Test #12 --------------------
21Feb13_134045|Best final individual weights
21Feb13_134045|Individual:
21Feb13_134045|-- Constant hidden layers --
21Feb13_134045|False
21Feb13_134045|Layer 0:
21Feb13_134045|-- Config --
21Feb13_134045|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_134045|-- Weights --
21Feb13_134045|[[ 0.32104  0.61569]
21Feb13_134045| [-0.41279  0.32569]
21Feb13_134045| [ 0.92289  0.54500]
21Feb13_134045| [ 1.79213  0.45034]
21Feb13_134045| [ 0.19404 -0.27829]
21Feb13_134045| [ 1.40124 -0.41596]
21Feb13_134045| [ 0.63246  0.02112]
21Feb13_134045| [-0.89776  1.51786]
21Feb13_134045| [ 1.41674 -0.54312]
21Feb13_134045| [ 0.42736  1.02415]
21Feb13_134045| [-0.01687 -1.42995]
21Feb13_134045| [-0.57162 -0.03201]
21Feb13_134045| [-0.43559 -0.14509]
21Feb13_134045| [ 0.37598  1.10418]
21Feb13_134045| [ 1.83758 -0.24958]
21Feb13_134045| [ 0.31401 -1.31086]
21Feb13_134045| [-1.18647 -0.50781]
21Feb13_134045| [ 0.17264 -1.22236]
21Feb13_134045| [-0.57236 -0.04586]
21Feb13_134045| [ 0.12430  1.26599]
21Feb13_134045| [-0.39206 -0.17742]
21Feb13_134045| [ 0.64517  0.45354]
21Feb13_134045| [-0.27228 -0.70483]
21Feb13_134045| [ 0.69282 -0.41916]
21Feb13_134045| [-0.16537  0.76412]
21Feb13_134045| [-0.63424  0.52767]
21Feb13_134045| [-0.61549  0.26167]
21Feb13_134045| [ 0.27883  0.91609]
21Feb13_134045| [ 0.59316  1.16883]
21Feb13_134045| [ 0.86908 -0.54124]
21Feb13_134045| [-0.95885 -0.56059]
21Feb13_134045| [ 0.30086  0.71889]
21Feb13_134045| [-1.68842  0.72905]
21Feb13_134045| [-0.87035  1.30405]
21Feb13_134045| [-0.04551 -0.13057]
21Feb13_134045| [-0.06314  0.12563]
21Feb13_134045| [ 0.17211 -1.42734]
21Feb13_134045| [-0.12855 -0.95393]
21Feb13_134045| [ 0.22170  0.86302]
21Feb13_134045| [-0.68713 -1.47512]
21Feb13_134045| [ 0.15758 -0.09346]
21Feb13_134045| [-1.18384  0.52780]
21Feb13_134045| [-0.72366  0.15677]
21Feb13_134045| [ 0.30831  0.28092]
21Feb13_134045| [-0.93134 -1.12436]
21Feb13_134045| [-0.45683 -0.14492]
21Feb13_134045| [-0.83521 -0.06431]
21Feb13_134045| [ 1.55615 -0.30180]
21Feb13_134045| [ 0.10461 -0.33054]
21Feb13_134045| [-0.01752 -1.05392]
21Feb13_134045| [-0.47739  0.08643]
21Feb13_134045| [ 0.50720  0.39835]
21Feb13_134045| [ 0.80674 -0.21923]
21Feb13_134045| [-0.30877  0.99188]
21Feb13_134045| [-1.94369 -0.33384]
21Feb13_134045| [ 0.32802  0.48644]
21Feb13_134045| [-0.88146 -0.59046]]
21Feb13_134045|-- Bias --
21Feb13_134045|[ 0.16224 -0.84795]
21Feb13_134045|Layer 1:
21Feb13_134045|-- Config --
21Feb13_134045|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_134045|-- Weights --
21Feb13_134045|[[-0.16795 -0.85647]
21Feb13_134045| [ 0.97061 -0.95915]]
21Feb13_134045|-- Bias --
21Feb13_134045|[-0.09868  0.31871]
21Feb13_134045|Predicting the validation and test data with the Best final individual.
21Feb13_134052| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_134052|-----------  ------------------  --------------------  ----------
21Feb13_134052|Validation         38.78                  2             0.00000
21Feb13_134052|   Test            39.01                  2             0.00000
21Feb13_134052|-------------------- Test #13 --------------------
21Feb13_134052|Best final individual weights
21Feb13_134052|Individual:
21Feb13_134052|-- Constant hidden layers --
21Feb13_134052|False
21Feb13_134052|Layer 0:
21Feb13_134052|-- Config --
21Feb13_134052|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_134052|-- Weights --
21Feb13_134052|[[ 0.32104  0.61569]
21Feb13_134052| [-0.41279  0.32569]
21Feb13_134052| [ 0.92289  0.54500]
21Feb13_134052| [ 1.79213  0.45034]
21Feb13_134052| [ 0.19404 -0.27829]
21Feb13_134052| [ 1.40124 -0.41596]
21Feb13_134052| [ 0.63246  0.02112]
21Feb13_134052| [-0.89776  1.51786]
21Feb13_134052| [ 1.41674 -0.54312]
21Feb13_134052| [ 0.42736  1.02415]
21Feb13_134052| [-0.01687 -1.42995]
21Feb13_134052| [-0.57162 -0.03201]
21Feb13_134052| [-0.43559 -0.14509]
21Feb13_134052| [ 0.37598  1.10418]
21Feb13_134052| [ 1.83758 -0.24958]
21Feb13_134052| [ 0.31401 -1.31086]
21Feb13_134052| [-1.18647 -0.50781]
21Feb13_134052| [ 0.17264 -1.22236]
21Feb13_134052| [-0.57236 -0.04586]
21Feb13_134052| [ 0.12430  1.26599]
21Feb13_134052| [-0.39206 -0.17742]
21Feb13_134052| [ 0.64517  0.45354]
21Feb13_134052| [-0.27228 -0.70483]
21Feb13_134052| [ 0.69282 -0.41916]
21Feb13_134052| [-0.16537  0.76412]
21Feb13_134052| [-0.63424  0.52767]
21Feb13_134052| [-0.61549  0.26167]
21Feb13_134052| [ 0.27883  0.91609]
21Feb13_134052| [ 0.59316  1.16883]
21Feb13_134052| [ 0.86908 -0.54124]
21Feb13_134052| [-0.95885 -0.56059]
21Feb13_134052| [ 0.30086  0.71889]
21Feb13_134052| [-1.68842  0.72905]
21Feb13_134052| [-0.87035  1.30405]
21Feb13_134052| [-0.04551 -0.13057]
21Feb13_134052| [-0.06314  0.12563]
21Feb13_134052| [ 0.17211 -1.42734]
21Feb13_134052| [-0.12855 -0.95393]
21Feb13_134052| [ 0.22170  0.86302]
21Feb13_134052| [-0.68713 -1.47512]
21Feb13_134052| [ 0.15758 -0.09346]
21Feb13_134052| [-1.18384  0.52780]
21Feb13_134052| [-0.72366  0.15677]
21Feb13_134052| [ 0.30831  0.28092]
21Feb13_134052| [-0.93134 -1.12436]
21Feb13_134052| [-0.45683 -0.14492]
21Feb13_134052| [-0.83521 -0.06431]
21Feb13_134052| [ 1.55615 -0.30180]
21Feb13_134052| [ 0.10461 -0.33054]
21Feb13_134052| [-0.01752 -1.05392]
21Feb13_134052| [-0.47739  0.08643]
21Feb13_134052| [ 0.50720  0.39835]
21Feb13_134052| [ 0.80674 -0.21923]
21Feb13_134052| [-0.30877  0.99188]
21Feb13_134052| [-1.94369 -0.33384]
21Feb13_134052| [ 0.32802  0.48644]
21Feb13_134052| [-0.88146 -0.59046]]
21Feb13_134052|-- Bias --
21Feb13_134052|[ 0.16224 -0.84795]
21Feb13_134052|Layer 1:
21Feb13_134052|-- Config --
21Feb13_134052|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_134052|-- Weights --
21Feb13_134052|[[-0.16795 -0.85647]
21Feb13_134052| [ 0.97061 -0.95915]]
21Feb13_134052|-- Bias --
21Feb13_134052|[-0.09868  0.31871]
21Feb13_134052|Predicting the validation and test data with the Best final individual.
21Feb13_134059| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_134059|-----------  ------------------  --------------------  ----------
21Feb13_134059|Validation         38.78                  2             0.00000
21Feb13_134059|   Test            39.01                  2             0.00000
21Feb13_134059|-------------------- Test #14 --------------------
21Feb13_134059|Best final individual weights
21Feb13_134059|Individual:
21Feb13_134059|-- Constant hidden layers --
21Feb13_134059|False
21Feb13_134059|Layer 0:
21Feb13_134059|-- Config --
21Feb13_134059|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_134059|-- Weights --
21Feb13_134059|[[ 0.32104  0.61569]
21Feb13_134059| [-0.41279  0.32569]
21Feb13_134059| [ 0.92289  0.54500]
21Feb13_134059| [ 1.79213  0.45034]
21Feb13_134059| [ 0.19404 -0.27829]
21Feb13_134059| [ 1.40124 -0.41596]
21Feb13_134059| [ 0.63246  0.02112]
21Feb13_134059| [-0.89776  1.51786]
21Feb13_134059| [ 1.41674 -0.54312]
21Feb13_134059| [ 0.42736  1.02415]
21Feb13_134059| [-0.01687 -1.42995]
21Feb13_134059| [-0.57162 -0.03201]
21Feb13_134059| [-0.43559 -0.14509]
21Feb13_134059| [ 0.37598  1.10418]
21Feb13_134059| [ 1.83758 -0.24958]
21Feb13_134059| [ 0.31401 -1.31086]
21Feb13_134059| [-1.18647 -0.50781]
21Feb13_134059| [ 0.17264 -1.22236]
21Feb13_134059| [-0.57236 -0.04586]
21Feb13_134059| [ 0.12430  1.26599]
21Feb13_134059| [-0.39206 -0.17742]
21Feb13_134059| [ 0.64517  0.45354]
21Feb13_134059| [-0.27228 -0.70483]
21Feb13_134059| [ 0.69282 -0.41916]
21Feb13_134059| [-0.16537  0.76412]
21Feb13_134059| [-0.63424  0.52767]
21Feb13_134059| [-0.61549  0.26167]
21Feb13_134059| [ 0.27883  0.91609]
21Feb13_134059| [ 0.59316  1.16883]
21Feb13_134059| [ 0.86908 -0.54124]
21Feb13_134059| [-0.95885 -0.56059]
21Feb13_134059| [ 0.30086  0.71889]
21Feb13_134059| [-1.68842  0.72905]
21Feb13_134059| [-0.87035  1.30405]
21Feb13_134059| [-0.04551 -0.13057]
21Feb13_134059| [-0.06314  0.12563]
21Feb13_134059| [ 0.17211 -1.42734]
21Feb13_134059| [-0.12855 -0.95393]
21Feb13_134059| [ 0.22170  0.86302]
21Feb13_134059| [-0.68713 -1.47512]
21Feb13_134059| [ 0.15758 -0.09346]
21Feb13_134059| [-1.18384  0.52780]
21Feb13_134059| [-0.72366  0.15677]
21Feb13_134059| [ 0.30831  0.28092]
21Feb13_134059| [-0.93134 -1.12436]
21Feb13_134059| [-0.45683 -0.14492]
21Feb13_134059| [-0.83521 -0.06431]
21Feb13_134059| [ 1.55615 -0.30180]
21Feb13_134059| [ 0.10461 -0.33054]
21Feb13_134059| [-0.01752 -1.05392]
21Feb13_134059| [-0.47739  0.08643]
21Feb13_134059| [ 0.50720  0.39835]
21Feb13_134059| [ 0.80674 -0.21923]
21Feb13_134059| [-0.30877  0.99188]
21Feb13_134059| [-1.94369 -0.33384]
21Feb13_134059| [ 0.32802  0.48644]
21Feb13_134059| [-0.88146 -0.59046]]
21Feb13_134059|-- Bias --
21Feb13_134059|[ 0.16224 -0.84795]
21Feb13_134059|Layer 1:
21Feb13_134059|-- Config --
21Feb13_134059|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_134059|-- Weights --
21Feb13_134059|[[-0.16795 -0.85647]
21Feb13_134059| [ 0.97061 -0.95915]]
21Feb13_134059|-- Bias --
21Feb13_134059|[-0.09868  0.31871]
21Feb13_134059|Predicting the validation and test data with the Best final individual.
21Feb13_134106| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_134106|-----------  ------------------  --------------------  ----------
21Feb13_134106|Validation         38.78                  2             0.00000
21Feb13_134106|   Test            39.01                  2             0.00000
2021-02-13 13:41:07.608259: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
21Feb13_134108|Data summary: Train
21Feb13_134108|data.shape = (2300, 57)
21Feb13_134108|labels.shape = (2300,)
21Feb13_134108|Class distribution:
21Feb13_134108|	0 - 1382 (0.60)
21Feb13_134108|	1 - 918 (0.40)
21Feb13_134108|Data summary: Validation
21Feb13_134108|data.shape = (1150, 57)
21Feb13_134108|labels.shape = (1150,)
21Feb13_134108|Class distribution:
21Feb13_134108|	0 - 704 (0.61)
21Feb13_134108|	1 - 446 (0.39)
21Feb13_134108|Data summary: Test
21Feb13_134108|data.shape = (1151, 57)
21Feb13_134108|labels.shape = (1151,)
21Feb13_134108|Class distribution:
21Feb13_134108|	0 - 702 (0.61)
21Feb13_134108|	1 - 449 (0.39)
21Feb13_134108|Selected configuration values
21Feb13_134108|-- Dataset name: spambase1
21Feb13_134108|-- Initial population size: 64
21Feb13_134108|-- Maximun number of generations: 32
21Feb13_134108|-- Neurons per hidden layer range: (2, 20)
21Feb13_134108|-- Hidden layers number range: (1, 3)
21Feb13_134108|-- Crossover probability: 0.5
21Feb13_134108|-- Bias gene mutation probability: 0.2
21Feb13_134108|-- Weights gene mutation probability: 0.75
21Feb13_134108|-- Neuron mutation probability: 0.3
21Feb13_134108|-- Layer mutation probability: 0.3
21Feb13_134108|-- Constant hidden layers: False
21Feb13_134108|-- Seed: 31415
21Feb13_134108|Entering GA
21Feb13_134108|Start the algorithm
2021-02-13 13:41:08.522909: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-13 13:41:08.523500: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-02-13 13:41:08.547100: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-13 13:41:08.547436: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.71GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s
2021-02-13 13:41:08.547453: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-02-13 13:41:08.549015: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-02-13 13:41:08.549060: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-02-13 13:41:08.549657: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-02-13 13:41:08.549793: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-02-13 13:41:08.549870: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-13 13:41:08.550323: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-02-13 13:41:08.550376: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-13 13:41:08.550383: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-02-13 13:41:08.550632: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-02-13 13:41:08.551566: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-13 13:41:08.551587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-13 13:41:08.551591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      
2021-02-13 13:41:08.605346: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-02-13 13:41:08.605694: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3493635000 Hz
/home/jmerelo/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype("int32")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn('`model.predict_classes()` is deprecated and '
21Feb13_134509|-- Generation 1 --
21Feb13_134509|    -- Crossed 1 individual pairs.
21Feb13_134509|    -- Mutated 32 individuals.
21Feb13_134908|    -- Evaluated 64 individuals.
21Feb13_134908|    Summary of generation 1:
21Feb13_134908| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_134908|-----------  ------------------  --------------------  ----------
21Feb13_134908|    Max            40.00                144.00          0.62444
21Feb13_134908|    Avg            38.72                41.77           0.01097
21Feb13_134908|    Min            28.87                 3.00           0.00000
21Feb13_134908|    Std             1.26                39.15           0.07753
21Feb13_134908|   Best            28.87                34.00           0.62444
21Feb13_134908|-- Generation 2 --
21Feb13_134908|    -- Crossed 2 individual pairs.
21Feb13_134908|    -- Mutated 32 individuals.
21Feb13_135306|    -- Evaluated 64 individuals.
21Feb13_135306|    Summary of generation 2:
21Feb13_135306| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_135306|-----------  ------------------  --------------------  ----------
21Feb13_135306|    Max            39.48                111.00          0.52734
21Feb13_135306|    Avg            38.44                35.67           0.01593
21Feb13_135306|    Min            24.17                 3.00           0.00000
21Feb13_135306|    Std             2.39                28.64           0.08875
21Feb13_135306|   Best            24.17                18.00           0.52734
21Feb13_135306|-- Generation 3 --
21Feb13_135306|    -- Crossed 2 individual pairs.
21Feb13_135306|    -- Mutated 32 individuals.
21Feb13_135704|    -- Evaluated 64 individuals.
21Feb13_135704|    Summary of generation 3:
21Feb13_135704| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_135704|-----------  ------------------  --------------------  ----------
21Feb13_135704|    Max            40.43                69.00           0.44933
21Feb13_135704|    Avg            38.68                24.86           0.00702
21Feb13_135704|    Min            26.52                 2.00           0.00000
21Feb13_135704|    Std             1.55                18.68           0.05573
21Feb13_135704|   Best            26.52                18.00           0.44933
21Feb13_135704|-- Generation 4 --
21Feb13_135704|    -- Crossed 4 individual pairs.
21Feb13_135704|    -- Mutated 32 individuals.
21Feb13_140059|    -- Evaluated 64 individuals.
21Feb13_140059|    Summary of generation 4:
21Feb13_140059| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_140059|-----------  ------------------  --------------------  ----------
21Feb13_140059|    Max            39.83                28.00           0.57900
21Feb13_140059|    Avg            37.99                14.06           0.03238
21Feb13_140059|    Min            24.35                 2.00           0.00000
21Feb13_140059|    Std             3.28                 9.00           0.12466
21Feb13_140059|   Best            24.35                18.00           0.53641
21Feb13_140059|-- Generation 5 --
21Feb13_140059|    -- Crossed 2 individual pairs.
21Feb13_140059|    -- Mutated 32 individuals.
21Feb13_140450|    -- Evaluated 64 individuals.
21Feb13_140450|    Summary of generation 5:
21Feb13_140450| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_140450|-----------  ------------------  --------------------  ----------
21Feb13_140450|    Max            39.22                21.00           0.51850
21Feb13_140450|    Avg            38.23                 7.92           0.02051
21Feb13_140450|    Min            25.22                 2.00           0.00000
21Feb13_140450|    Std             2.58                 5.36           0.09243
21Feb13_140450|   Best            25.22                18.00           0.51850
21Feb13_140450|-- Generation 6 --
21Feb13_140450|    -- Crossed 8 individual pairs.
21Feb13_140450|    -- Mutated 32 individuals.
21Feb13_140840|    -- Evaluated 64 individuals.
21Feb13_140840|    Summary of generation 6:
21Feb13_140840| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_140840|-----------  ------------------  --------------------  ----------
21Feb13_140840|    Max            54.61                33.00           0.78027
21Feb13_140840|    Avg            38.21                 6.53           0.04503
21Feb13_140840|    Min            24.96                 2.00           0.00000
21Feb13_140840|    Std             3.83                 5.83           0.15730
21Feb13_140840|   Best            24.96                18.00           0.53459
21Feb13_140840|-- Generation 7 --
21Feb13_140840|    -- Crossed 6 individual pairs.
21Feb13_140840|    -- Mutated 32 individuals.
21Feb13_141229|    -- Evaluated 64 individuals.
21Feb13_141229|    Summary of generation 7:
21Feb13_141229| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_141229|-----------  ------------------  --------------------  ----------
21Feb13_141229|    Max            39.30                21.00           0.59418
21Feb13_141229|    Avg            37.37                 5.27           0.05596
21Feb13_141229|    Min            24.78                 2.00           0.00000
21Feb13_141229|    Std             4.10                 5.02           0.16104
21Feb13_141229|   Best            24.78                12.00           0.59418
21Feb13_141229|-- Generation 8 --
21Feb13_141229|    -- Crossed 7 individual pairs.
21Feb13_141229|    -- Mutated 32 individuals.
21Feb13_141620|    -- Evaluated 64 individuals.
21Feb13_141620|    Summary of generation 8:
21Feb13_141620| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_141620|-----------  ------------------  --------------------  ----------
21Feb13_141620|    Max            39.30                40.00           0.56679
21Feb13_141620|    Avg            37.51                 7.00           0.05014
21Feb13_141620|    Min            24.78                 2.00           0.00000
21Feb13_141620|    Std             3.78                 8.36           0.14621
21Feb13_141620|   Best            24.78                12.00           0.49827
21Feb13_141620|-- Generation 9 --
21Feb13_141620|    -- Crossed 8 individual pairs.
21Feb13_141620|    -- Mutated 32 individuals.
21Feb13_142011|    -- Evaluated 64 individuals.
21Feb13_142011|    Summary of generation 9:
21Feb13_142011| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_142011|-----------  ------------------  --------------------  ----------
21Feb13_142011|    Max            40.09                21.00           0.54706
21Feb13_142011|    Avg            37.40                 5.75           0.05231
21Feb13_142011|    Min            25.22                 2.00           0.00000
21Feb13_142011|    Std             3.80                 5.44           0.14100
21Feb13_142011|   Best            25.22                18.00           0.53191
21Feb13_142011|-- Generation 10 --
21Feb13_142011|    -- Crossed 7 individual pairs.
21Feb13_142011|    -- Mutated 32 individuals.
21Feb13_142401|    -- Evaluated 64 individuals.
21Feb13_142401|    Summary of generation 10:
21Feb13_142401| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_142401|-----------  ------------------  --------------------  ----------
21Feb13_142401|    Max            39.13                30.00           0.76049
21Feb13_142401|    Avg            36.91                 6.88           0.07339
21Feb13_142401|    Min            22.09                 2.00           0.00000
21Feb13_142401|    Std             4.74                 7.27           0.18761
21Feb13_142401|   Best            22.09                30.00           0.76049
21Feb13_142401|-- Generation 11 --
21Feb13_142401|    -- Crossed 7 individual pairs.
21Feb13_142401|    -- Mutated 32 individuals.
21Feb13_142752|    -- Evaluated 64 individuals.
21Feb13_142752|    Summary of generation 11:
21Feb13_142752| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_142752|-----------  ------------------  --------------------  ----------
21Feb13_142752|    Max            39.04                44.00           0.71146
21Feb13_142752|    Avg            37.40                 7.92           0.05439
21Feb13_142752|    Min            24.96                 2.00           0.00000
21Feb13_142752|    Std             4.00                 8.84           0.15824
21Feb13_142752|   Best            24.96                 8.00           0.50760
21Feb13_142752|-- Generation 12 --
21Feb13_142752|    -- Crossed 5 individual pairs.
21Feb13_142752|    -- Mutated 32 individuals.
21Feb13_143143|    -- Evaluated 64 individuals.
21Feb13_143143|    Summary of generation 12:
21Feb13_143143| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_143143|-----------  ------------------  --------------------  ----------
21Feb13_143143|    Max            39.13                75.00           0.78717
21Feb13_143143|    Avg            37.28                 7.97           0.06532
21Feb13_143143|    Min            24.52                 2.00           0.00000
21Feb13_143143|    Std             3.77                12.08           0.16681
21Feb13_143143|   Best            24.52                14.00           0.61978
21Feb13_143143|-- Generation 13 --
21Feb13_143143|    -- Crossed 8 individual pairs.
21Feb13_143143|    -- Mutated 32 individuals.
21Feb13_143533|    -- Evaluated 64 individuals.
21Feb13_143533|    Summary of generation 13:
21Feb13_143533| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_143533|-----------  ------------------  --------------------  ----------
21Feb13_143533|    Max            38.96                44.00           0.80843
21Feb13_143533|    Avg            37.23                 7.53           0.06706
21Feb13_143533|    Min            24.00                 2.00           0.00000
21Feb13_143533|    Std             4.02                 9.91           0.17812
21Feb13_143533|   Best            24.00                12.00           0.59130
21Feb13_143533|-- Generation 14 --
21Feb13_143533|    -- Crossed 8 individual pairs.
21Feb13_143533|    -- Mutated 32 individuals.
21Feb13_143924|    -- Evaluated 64 individuals.
21Feb13_143924|    Summary of generation 14:
21Feb13_143924| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_143924|-----------  ------------------  --------------------  ----------
21Feb13_143924|    Max            39.13                36.00           0.66919
21Feb13_143924|    Avg            37.26                 7.17           0.06361
21Feb13_143924|    Min            24.87                 2.00           0.00000
21Feb13_143924|    Std             3.92                 7.97           0.16350
21Feb13_143924|   Best            24.87                 8.00           0.58671
21Feb13_143924|-- Generation 15 --
21Feb13_143924|    -- Crossed 6 individual pairs.
21Feb13_143924|    -- Mutated 32 individuals.
21Feb13_144316|    -- Evaluated 64 individuals.
21Feb13_144316|    Summary of generation 15:
21Feb13_144316| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_144316|-----------  ------------------  --------------------  ----------
21Feb13_144316|    Max            39.13                39.00           0.77660
21Feb13_144316|    Avg            36.19                 8.97           0.13283
21Feb13_144316|    Min            23.57                 2.00           0.00000
21Feb13_144316|    Std             4.89                10.60           0.23969
21Feb13_144316|   Best            23.57                18.00           0.70504
21Feb13_144316|-- Generation 16 --
21Feb13_144316|    -- Crossed 3 individual pairs.
21Feb13_144316|    -- Mutated 32 individuals.
21Feb13_144712|    -- Evaluated 64 individuals.
21Feb13_144712|    Summary of generation 16:
21Feb13_144712| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_144712|-----------  ------------------  --------------------  ----------
21Feb13_144712|    Max            39.04                60.00           0.80854
21Feb13_144712|    Avg            36.16                13.16           0.12554
21Feb13_144712|    Min            23.83                 2.00           0.00000
21Feb13_144712|    Std             4.89                12.68           0.23535
21Feb13_144712|   Best            23.83                39.00           0.61682
21Feb13_144712|-- Generation 17 --
21Feb13_144712|    -- Crossed 2 individual pairs.
21Feb13_144712|    -- Mutated 32 individuals.
21Feb13_145108|    -- Evaluated 64 individuals.
21Feb13_145108|    Summary of generation 17:
21Feb13_145108| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_145108|-----------  ------------------  --------------------  ----------
21Feb13_145108|    Max            38.87                68.00           0.75357
21Feb13_145108|    Avg            35.61                14.80           0.13385
21Feb13_145108|    Min            23.39                 2.00           0.00000
21Feb13_145108|    Std             5.39                16.94           0.23172
21Feb13_145108|   Best            23.39                36.00           0.70407
21Feb13_145108|-- Generation 18 --
21Feb13_145108|    -- Crossed 3 individual pairs.
21Feb13_145108|    -- Mutated 32 individuals.
21Feb13_145504|    -- Evaluated 64 individuals.
21Feb13_145504|    Summary of generation 18:
21Feb13_145504| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_145504|-----------  ------------------  --------------------  ----------
21Feb13_145504|    Max            51.57                40.00           0.79434
21Feb13_145504|    Avg            35.76                14.64           0.16574
21Feb13_145504|    Min            24.78                 2.00           0.00000
21Feb13_145504|    Std             5.65                12.54           0.26388
21Feb13_145504|   Best            24.78                21.00           0.50418
21Feb13_145504|-- Generation 19 --
21Feb13_145504|    -- Crossed 1 individual pairs.
21Feb13_145504|    -- Mutated 32 individuals.
21Feb13_145902|    -- Evaluated 64 individuals.
21Feb13_145902|    Summary of generation 19:
21Feb13_145902| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_145902|-----------  ------------------  --------------------  ----------
21Feb13_145902|    Max            39.04                52.00           0.74914
21Feb13_145902|    Avg            36.05                17.84           0.11361
21Feb13_145902|    Min            24.43                 2.00           0.00000
21Feb13_145902|    Std             4.98                13.26           0.21328
21Feb13_145902|   Best            24.43                21.00           0.74556
21Feb13_145902|-- Generation 20 --
21Feb13_145902|    -- Crossed 2 individual pairs.
21Feb13_145902|    -- Mutated 32 individuals.
21Feb13_150258|    -- Evaluated 64 individuals.
21Feb13_150258|    Summary of generation 20:
21Feb13_150258| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_150258|-----------  ------------------  --------------------  ----------
21Feb13_150258|    Max            41.39                36.00           0.77806
21Feb13_150258|    Avg            36.42                16.00           0.10733
21Feb13_150258|    Min            24.26                 2.00           0.00000
21Feb13_150258|    Std             4.84                12.63           0.21080
21Feb13_150258|   Best            24.26                14.00           0.63795
21Feb13_150258|-- Generation 21 --
21Feb13_150258|    -- Crossed 1 individual pairs.
21Feb13_150258|    -- Mutated 32 individuals.
21Feb13_150657|    -- Evaluated 64 individuals.
21Feb13_150657|    Summary of generation 21:
21Feb13_150657| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_150657|-----------  ------------------  --------------------  ----------
21Feb13_150657|    Max            39.13                56.00           0.73523
21Feb13_150657|    Avg            35.84                17.72           0.12169
21Feb13_150657|    Min            24.00                 2.00           0.00000
21Feb13_150657|    Std             4.88                12.61           0.20857
21Feb13_150657|   Best            24.00                 8.00           0.64227
21Feb13_150657|-- Generation 22 --
21Feb13_150657|    -- Crossed 0 individual pairs.
21Feb13_150657|    -- Mutated 32 individuals.
21Feb13_151058|    -- Evaluated 64 individuals.
21Feb13_151058|    Summary of generation 22:
21Feb13_151058| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_151058|-----------  ------------------  --------------------  ----------
21Feb13_151058|    Max            40.35                64.00           0.73788
21Feb13_151058|    Avg            33.84                22.30           0.21022
21Feb13_151058|    Min            23.13                 2.00           0.00000
21Feb13_151058|    Std             5.93                13.44           0.25445
21Feb13_151058|   Best            23.13                18.00           0.72566
21Feb13_151058|-- Generation 23 --
21Feb13_151058|    -- Crossed 0 individual pairs.
21Feb13_151058|    -- Mutated 32 individuals.
21Feb13_151501|    -- Evaluated 64 individuals.
21Feb13_151501|    Summary of generation 23:
21Feb13_151501| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_151501|-----------  ------------------  --------------------  ----------
21Feb13_151501|    Max            43.04                64.00           0.73080
21Feb13_151501|    Avg            33.34                24.75           0.23085
21Feb13_151501|    Min            24.26                 3.00           0.00000
21Feb13_151501|    Std             6.14                15.62           0.24434
21Feb13_151501|   Best            24.26                36.00           0.52129
21Feb13_151501|-- Generation 24 --
21Feb13_151501|    -- Crossed 0 individual pairs.
21Feb13_151501|    -- Mutated 32 individuals.
21Feb13_151904|    -- Evaluated 64 individuals.
21Feb13_151904|    Summary of generation 24:
21Feb13_151904| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_151904|-----------  ------------------  --------------------  ----------
21Feb13_151904|    Max            38.96                90.00           0.75460
21Feb13_151904|    Avg            32.76                24.70           0.24452
21Feb13_151904|    Min            23.83                 3.00           0.00000
21Feb13_151904|    Std             6.05                17.56           0.25724
21Feb13_151904|   Best            23.83                36.00           0.64114
21Feb13_151904|-- Generation 25 --
21Feb13_151904|    -- Crossed 1 individual pairs.
21Feb13_151904|    -- Mutated 32 individuals.
21Feb13_152308|    -- Evaluated 64 individuals.
21Feb13_152308|    Summary of generation 25:
21Feb13_152308| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_152308|-----------  ------------------  --------------------  ----------
21Feb13_152308|    Max            39.04                90.00           0.79302
21Feb13_152308|    Avg            31.09                27.73           0.31732
21Feb13_152308|    Min            24.00                 3.00           0.00000
21Feb13_152308|    Std             6.00                20.84           0.25931
21Feb13_152308|   Best            24.00                64.00           0.68570
21Feb13_152308|-- Generation 26 --
21Feb13_152308|    -- Crossed 1 individual pairs.
21Feb13_152308|    -- Mutated 32 individuals.
21Feb13_152715|    -- Evaluated 64 individuals.
21Feb13_152715|    Summary of generation 26:
21Feb13_152715| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_152715|-----------  ------------------  --------------------  ----------
21Feb13_152715|    Max            39.22                90.00           0.71586
21Feb13_152715|    Avg            32.64                34.88           0.25284
21Feb13_152715|    Min            24.00                 2.00           0.00000
21Feb13_152715|    Std             6.15                24.10           0.25911
21Feb13_152715|   Best            24.00                40.00           0.66424
21Feb13_152715|-- Generation 27 --
21Feb13_152715|    -- Crossed 0 individual pairs.
21Feb13_152715|    -- Mutated 32 individuals.
21Feb13_153125|    -- Evaluated 64 individuals.
21Feb13_153125|    Summary of generation 27:
21Feb13_153125| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_153125|-----------  ------------------  --------------------  ----------
21Feb13_153125|    Max            39.57                100.00          0.78569
21Feb13_153125|    Avg            31.54                38.80           0.31701
21Feb13_153125|    Min            23.91                 2.00           0.00000
21Feb13_153125|    Std             5.98                24.34           0.26485
21Feb13_153125|   Best            23.91                18.00           0.69897
21Feb13_153125|-- Generation 28 --
21Feb13_153125|    -- Crossed 0 individual pairs.
21Feb13_153125|    -- Mutated 32 individuals.
21Feb13_153535|    -- Evaluated 64 individuals.
21Feb13_153535|    Summary of generation 28:
21Feb13_153535| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_153535|-----------  ------------------  --------------------  ----------
21Feb13_153535|    Max            38.87                120.00          0.80265
21Feb13_153535|    Avg            31.20                38.25           0.32593
21Feb13_153535|    Min            23.04                 8.00           0.00000
21Feb13_153535|    Std             6.34                27.09           0.28031
21Feb13_153535|   Best            23.04                85.00           0.68747
21Feb13_153535|-- Generation 29 --
21Feb13_153535|    -- Crossed 1 individual pairs.
21Feb13_153535|    -- Mutated 32 individuals.
21Feb13_153946|    -- Evaluated 64 individuals.
21Feb13_153946|    Summary of generation 29:
21Feb13_153946| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_153946|-----------  ------------------  --------------------  ----------
21Feb13_153946|    Max            39.22                144.00          0.72852
21Feb13_153946|    Avg            31.17                38.80           0.32805
21Feb13_153946|    Min            23.57                 3.00           0.00000
21Feb13_153946|    Std             6.27                27.59           0.27396
21Feb13_153946|   Best            23.57                64.00           0.71302
21Feb13_153946|-- Generation 30 --
21Feb13_153946|    -- Crossed 1 individual pairs.
21Feb13_153946|    -- Mutated 32 individuals.
21Feb13_154358|    -- Evaluated 64 individuals.
21Feb13_154358|    Summary of generation 30:
21Feb13_154358| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_154358|-----------  ------------------  --------------------  ----------
21Feb13_154358|    Max            38.96                132.00          0.73806
21Feb13_154358|    Avg            29.97                42.73           0.37277
21Feb13_154358|    Min            23.57                 8.00           0.00000
21Feb13_154358|    Std             5.92                28.67           0.26043
21Feb13_154358|   Best            23.57                56.00           0.73806
21Feb13_154358|-- Generation 31 --
21Feb13_154358|    -- Crossed 0 individual pairs.
21Feb13_154358|    -- Mutated 32 individuals.
21Feb13_154811|    -- Evaluated 64 individuals.
21Feb13_154811|    Summary of generation 31:
21Feb13_154811| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_154811|-----------  ------------------  --------------------  ----------
21Feb13_154811|    Max            38.96                138.00          0.80524
21Feb13_154811|    Avg            30.32                46.66           0.36926
21Feb13_154811|    Min            23.74                 8.00           0.00000
21Feb13_154811|    Std             6.31                28.98           0.28505
21Feb13_154811|   Best            23.74                60.00           0.68499
21Feb13_154811|-- Generation 32 --
21Feb13_154811|    -- Crossed 0 individual pairs.
21Feb13_154811|    -- Mutated 32 individuals.
21Feb13_155226|    -- Evaluated 64 individuals.
21Feb13_155226|    Summary of generation 32:
21Feb13_155226| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_155226|-----------  ------------------  --------------------  ----------
21Feb13_155226|    Max            45.04                105.00          0.78013
21Feb13_155226|    Avg            31.70                48.92           0.32011
21Feb13_155226|    Min            23.65                 8.00           0.00000
21Feb13_155226|    Std             6.68                27.07           0.29123
21Feb13_155226|   Best            23.65                18.00           0.67212
21Feb13_155226|Best initial individual weights
21Feb13_155226|Individual:
21Feb13_155226|-- Constant hidden layers --
21Feb13_155226|False
21Feb13_155226|Layer 0:
21Feb13_155226|-- Config --
21Feb13_155226|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 14, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155226|-- Weights --
21Feb13_155226|[[-0.46755 -0.77923  0.54917 -0.28189 -0.72659 -0.27127 -0.27090 -0.70110
21Feb13_155226|  -0.67504 -0.55383  0.05413 -0.54585  0.33416 -0.40920]
21Feb13_155226| [-0.63500  0.50563  0.57366  0.56179  0.04949  0.13217  0.41463  0.93392
21Feb13_155226|   0.61458  0.96459 -0.18538 -0.13505  0.57914 -0.52395]
21Feb13_155226| [-0.68746 -0.76013 -0.94302  0.63098 -0.51538  0.18933 -0.84177  0.74255
21Feb13_155226|   0.86109 -0.27253 -0.84093 -0.97103 -0.02308  0.93169]
21Feb13_155226| [-0.30389 -0.64730  0.82087 -0.31786 -0.85760 -0.53174 -0.24099  0.67567
21Feb13_155226|   0.06588 -0.45133 -0.21639 -0.44111 -0.61620 -0.17649]
21Feb13_155226| [ 0.48191 -0.65488 -0.21573 -0.77382  0.08877 -0.42943  0.31791  0.19963
21Feb13_155226|   0.68021 -0.01578  0.68440  0.17655 -0.21113  0.67186]
21Feb13_155226| [-0.36815  0.65794 -0.13217 -0.31720  0.76634  0.27196  0.95938  0.33809
21Feb13_155226|   0.19009  0.33029 -0.46957 -0.33031 -0.51404  0.65862]
21Feb13_155226| [-0.65723  0.89409  0.22717  0.66331 -0.65923  0.79128 -0.98129  0.85470
21Feb13_155226|  -0.14172 -0.04193 -0.47613  0.48781  0.68267 -0.66590]
21Feb13_155226| [-0.52649  0.13025 -0.62663 -0.42792  0.22186 -0.95757 -0.54927  0.85846
21Feb13_155226|   0.31648  0.71487 -0.43083  0.44347 -0.23840 -0.29771]
21Feb13_155226| [ 0.66666 -0.29194  0.36156 -0.76444  0.85348 -0.92589 -0.67688 -0.59105
21Feb13_155226|  -0.14206 -0.14664 -0.95610 -0.12937  0.30125 -0.16216]
21Feb13_155226| [ 0.77747  0.46685 -0.71306  0.32989 -0.87164 -0.11013  0.19666  0.73410
21Feb13_155226|  -0.29764  0.99239 -0.68544  0.41165 -0.64248 -0.97687]
21Feb13_155226| [ 0.17007 -0.65841  0.72035  0.09167  0.85914  0.22927 -0.25043 -0.23306
21Feb13_155226|   0.72466  0.74012  0.43476  0.85579 -0.95528 -0.61712]
21Feb13_155226| [-0.09915 -0.54507 -0.26888  0.02218  0.58739 -0.06694  0.07394 -0.71029
21Feb13_155226|  -0.70699 -0.17378 -0.26204 -0.54108  0.87105  0.37003]
21Feb13_155226| [-0.87676  0.79843  0.13830  0.73610 -0.35602  0.07624  0.58797  0.93769
21Feb13_155226|  -0.47112 -0.88784 -0.32329  0.57694  0.54031  0.46209]
21Feb13_155226| [ 0.56833  0.00229 -0.63767 -0.25082  0.87251  0.72852 -0.35706 -0.32574
21Feb13_155226|   0.00338 -0.96495 -0.24423  0.83795  0.17704 -0.52730]
21Feb13_155226| [ 0.57389  0.43306 -0.14668  0.09726 -0.40905  0.48410  0.46706  0.29093
21Feb13_155226|  -0.73066 -0.42228 -0.50998  0.90495  0.38869  0.16695]
21Feb13_155226| [-0.38641 -0.90524 -0.68245 -0.18039  0.28617  0.95451  0.31495  0.98373
21Feb13_155226|   0.03790 -0.42415 -0.77936 -0.83630  0.24380 -0.33397]
21Feb13_155226| [ 0.45738 -0.32376  0.96332 -0.16096  0.31168 -0.94554  0.35925 -0.69530
21Feb13_155226|  -0.03069 -0.91449 -0.94713 -0.87442  0.37907  0.83374]
21Feb13_155226| [ 0.82631 -0.40539  0.37464  0.84534  0.25362 -0.91741 -0.31505  0.86890
21Feb13_155226|  -0.89153 -0.90321  0.55294 -0.19362 -0.49542 -0.19912]
21Feb13_155226| [ 0.45632 -0.68250 -0.38370 -0.52120 -0.03266 -0.74606 -0.97861 -0.15550
21Feb13_155226|  -0.33213  0.11576  0.28994  0.00440  0.65196 -0.58094]
21Feb13_155226| [-0.08531  0.13013 -0.49165  0.13948  0.90958 -0.93520  0.58653 -0.14145
21Feb13_155226|  -0.31804  0.99202 -0.46123 -0.67566  0.72270  0.07720]
21Feb13_155226| [-0.18701  0.84394  0.21217  0.94145 -0.47411  0.61988  0.95344 -0.18707
21Feb13_155226|   0.26361 -0.55127  0.19663  0.91693  0.70662 -0.93054]
21Feb13_155226| [-0.24922 -0.65816  0.12943  0.71089 -0.96074 -0.49543 -0.74916  0.72108
21Feb13_155226|   0.47341 -0.33704  0.60085 -0.79768  0.05831  0.93894]
21Feb13_155226| [-0.56027 -0.07417 -0.59317  0.17038  0.89351 -0.58669  0.76195 -0.97400
21Feb13_155226|  -0.26234  0.01124 -0.37019 -0.07945  0.30678 -0.05190]
21Feb13_155226| [ 0.33030 -0.80606 -0.15583  0.36617  0.51910 -0.23815 -0.41574  0.84538
21Feb13_155226|  -0.24786  0.45644  0.55059  0.62875  0.62044 -0.20357]
21Feb13_155226| [ 0.04941  0.26053 -0.36386 -0.34913  0.91955  0.05273 -0.94165 -0.78189
21Feb13_155226|  -0.57974 -0.22811  0.72354 -0.04255  0.26185  0.37401]
21Feb13_155226| [-0.02059 -0.55773  0.72546 -0.82885 -0.73287  0.45804 -0.78944  0.74713
21Feb13_155226|  -0.89593  0.72724 -0.44896 -0.14313 -0.67643 -0.03675]
21Feb13_155226| [ 0.12220 -0.58125 -0.12500  0.26843  0.12176  0.77053  0.22442 -0.89966
21Feb13_155226|   0.09096 -0.24841 -0.27943  0.37594 -0.79211 -0.43915]
21Feb13_155226| [ 0.13685 -0.46444 -0.80102  0.04904  0.90523 -0.51614 -0.62836 -0.04136
21Feb13_155226|  -0.72900  0.62896 -0.29738  0.27190 -0.76503  0.74540]
21Feb13_155226| [ 0.18538 -0.44490 -0.03086 -0.72017  0.82826  0.04552  0.19502  0.01582
21Feb13_155226|   0.07019  0.26265 -0.61195  0.70762 -0.68833  0.59056]
21Feb13_155226| [-0.19076 -0.40389  0.94951  0.81209 -0.24990 -0.73472  0.35684  0.54594
21Feb13_155226|   0.02705 -0.70092 -0.75131  0.28926 -0.76413  0.90106]
21Feb13_155226| [ 0.89491 -0.44966 -0.07129  0.47477 -0.31786  0.19173  0.56299  0.78493
21Feb13_155226|  -0.85890 -0.80598 -0.03673 -0.18087  0.92364  0.04843]
21Feb13_155226| [ 0.30403  0.77247 -0.84687  0.76203  0.25237  0.62157 -0.18053 -0.91906
21Feb13_155226|  -0.04765  0.20249 -0.65221 -0.05052 -0.41625 -0.65536]
21Feb13_155226| [-0.84187 -0.80188 -0.99497  0.76603 -0.71492 -0.17111 -0.28120  0.80320
21Feb13_155226|  -0.07261  0.71081  0.01508  0.97961 -0.05309  0.42977]
21Feb13_155226| [-0.19072  0.97039 -0.08302 -0.04211 -0.01337 -0.48400 -0.52995  0.19069
21Feb13_155226|   0.01795  0.45507  0.01718 -0.36766 -0.31757  0.80225]
21Feb13_155226| [-0.56903  0.23408  0.70376 -0.67078  0.15573 -0.23159  0.47725  0.93539
21Feb13_155226|  -0.75790  0.53202 -0.84788  0.79902 -0.71951 -0.63768]
21Feb13_155226| [-0.02086  0.23811  0.84799  0.66904  0.62595  0.79239  0.14162 -0.69665
21Feb13_155226|  -0.17673  0.36012 -0.10827 -0.54487 -0.94652  0.64132]
21Feb13_155226| [ 0.54057 -0.52721  0.19858  0.46209  0.25979  0.46581 -0.43188 -0.25092
21Feb13_155226|   0.10142  0.36981  0.29653 -0.60029  0.63754  0.78518]
21Feb13_155226| [-0.73536  0.15757 -0.67765  0.94100  0.55251  0.93236 -0.09504 -0.25668
21Feb13_155226|  -0.49745 -0.08851  0.21545 -0.20070  0.23399  0.94390]
21Feb13_155226| [ 0.40157 -0.64885 -0.99951 -0.73596  0.83216  0.13883 -0.43141 -0.25660
21Feb13_155226|  -0.64869  0.18746 -0.14855 -0.29644 -0.08967  0.09011]
21Feb13_155226| [ 0.24532 -0.25469 -0.27555 -0.26078 -0.06836  0.97940  0.31619 -0.83638
21Feb13_155226|   0.25254 -0.18261  0.58487  0.57371 -0.33039 -0.26035]
21Feb13_155226| [-0.40443 -0.03473  0.67337 -0.52501  0.15891 -0.25029 -0.86421 -0.50345
21Feb13_155226|   0.23077 -0.70594  0.38123 -0.14116  0.24608  0.30380]
21Feb13_155226| [-0.91157 -0.71115 -0.08024  0.43313 -0.66540  0.97313 -0.73091 -0.81121
21Feb13_155226|  -0.12058 -0.15718  0.36369  0.79179  0.96340 -0.40657]
21Feb13_155226| [-0.14059 -0.01148 -0.02677  0.33900 -0.10768 -0.17529 -0.80387 -0.53018
21Feb13_155226|  -0.19863 -0.71902  0.15616  0.81354 -0.49761 -0.06255]
21Feb13_155226| [-0.24706 -0.06008 -0.57834  0.30502 -0.16921 -0.90075  0.78975 -0.91475
21Feb13_155226|   0.17278 -0.06501 -0.82514  0.42792  0.50567  0.31420]
21Feb13_155226| [ 0.19858  0.27139 -0.66526  0.22931 -0.91885 -0.57502  0.66730 -0.08919
21Feb13_155226|   0.48485  0.41713 -0.43555  0.42449 -0.02396  0.92678]
21Feb13_155226| [-0.26449 -0.66167  0.92432 -0.34591 -0.84237 -0.20862 -0.38663  0.70631
21Feb13_155226|  -0.58894  0.28492 -0.75196  0.78287 -0.76882  0.60073]
21Feb13_155226| [-0.90089  0.36008 -0.62836  0.05717  0.16910 -0.42677 -0.29327 -0.07989
21Feb13_155226|   0.83425 -0.46170 -0.83419  0.47481  0.22246  0.00845]
21Feb13_155226| [-0.01303 -0.79612  0.01337  0.96383  0.88888  0.40733  0.52040 -0.78910
21Feb13_155226|   0.54808  0.80667 -0.18360 -0.64126 -0.39695 -0.66319]
21Feb13_155226| [-0.88076  0.98424  0.92610  0.64666 -0.31894 -0.82556 -0.27707  0.04045
21Feb13_155226|   0.66390  0.99121 -0.43994 -0.56351 -0.88577 -0.78906]
21Feb13_155226| [-0.08809 -0.47914  0.74437  0.18616  0.14492  0.91897 -0.78420  0.19567
21Feb13_155226|   0.21651  0.11022 -0.63077  0.25838 -0.62852 -0.54420]
21Feb13_155226| [ 0.83666 -0.13041  0.11889  0.48108 -0.65844 -0.93334 -0.35183 -0.71039
21Feb13_155226|   0.25408  0.40921 -0.96035  0.03882  0.23292 -0.23146]
21Feb13_155226| [-0.42276 -0.88165  0.91051 -0.26078 -0.60459 -0.88375  0.06035  0.28531
21Feb13_155226|  -0.85402  0.32638  0.75647 -0.52785  0.49295  0.07150]
21Feb13_155226| [ 0.41227 -0.53332 -0.86738  0.05626  0.12633 -0.18304  0.78693  0.76589
21Feb13_155226|   0.23618  0.20811  0.34520 -0.59405 -0.24790 -0.64175]
21Feb13_155226| [ 0.16112  0.08361  0.09088  0.19541 -0.26349  0.25044 -0.58915  0.33944
21Feb13_155226|  -0.83164  0.61911  0.32780 -0.96216  0.97785 -0.34160]
21Feb13_155226| [ 0.42787 -0.25634 -0.11060  0.91572  0.65583 -0.19126  0.55396 -0.93986
21Feb13_155226|   0.87875  0.03214 -0.49125 -0.78175 -0.92747  0.36487]
21Feb13_155226| [-0.74605 -0.47039  0.66455 -0.40278 -0.45182 -0.79306 -0.10554 -0.06691
21Feb13_155226|   0.41563 -0.07006  0.15794 -0.88368 -0.54811  0.06069]
21Feb13_155226| [-0.25592 -0.72120 -0.35502 -0.55513  0.21451 -0.66825  0.21368  0.77818
21Feb13_155226|   0.95608 -0.27384 -0.23671 -0.50859 -0.15268  0.22426]]
21Feb13_155226|-- Bias --
21Feb13_155226|[-0.31320 -0.24309  0.70469  0.03150 -0.67450  0.49415  0.71057  0.56074
21Feb13_155226| -0.68882 -0.02550  0.88238 -0.30120  0.61236 -0.98547]
21Feb13_155226|Layer 1:
21Feb13_155226|-- Config --
21Feb13_155226|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 14], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155226|-- Weights --
21Feb13_155226|[[ 0.98573 -0.10612]
21Feb13_155226| [-0.84650 -0.91832]
21Feb13_155226| [-0.43497 -0.92411]
21Feb13_155226| [-0.33475  0.47765]
21Feb13_155226| [ 0.03103 -0.47578]
21Feb13_155226| [-0.40987 -0.23556]
21Feb13_155226| [ 0.94394  0.01566]
21Feb13_155226| [ 0.73003  0.37218]
21Feb13_155226| [ 0.70222 -0.45412]
21Feb13_155226| [-0.23121 -0.00197]
21Feb13_155226| [ 0.27099  0.18396]
21Feb13_155226| [ 0.80007  0.70964]
21Feb13_155226| [-0.41310  0.94902]
21Feb13_155226| [-0.11261 -0.90297]]
21Feb13_155226|-- Bias --
21Feb13_155226|[-0.28704  0.27496]
21Feb13_155226|Predicting the validation and test data with the Best initial individual.
21Feb13_155233| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_155233|-----------  ------------------  --------------------  ----------
21Feb13_155233|Validation         39.04                  14            0.00000
21Feb13_155233|   Test            37.71                  14            0.05760
21Feb13_155233|-------------------- Test #0 --------------------
21Feb13_155233|Best final individual weights
21Feb13_155233|Individual:
21Feb13_155233|-- Constant hidden layers --
21Feb13_155233|False
21Feb13_155233|Layer 0:
21Feb13_155233|-- Config --
21Feb13_155233|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155233|-- Weights --
21Feb13_155233|[[ 4.91885e-01  3.98183e-01]
21Feb13_155233| [-9.54215e-01 -1.24646e+00]
21Feb13_155233| [-1.10574e+00  9.54098e-01]
21Feb13_155233| [-7.23267e-01  5.05588e-01]
21Feb13_155233| [-2.90292e-01 -7.75831e-01]
21Feb13_155233| [ 1.72812e+00  4.07095e-01]
21Feb13_155233| [ 3.55902e-01  1.14081e+00]
21Feb13_155233| [-1.48987e+00  4.85259e-01]
21Feb13_155233| [-5.60401e-01 -3.04522e-01]
21Feb13_155233| [ 6.71669e-01  2.81967e-01]
21Feb13_155233| [-9.29584e-01 -6.42349e-02]
21Feb13_155233| [ 1.03435e+00 -9.55452e-01]
21Feb13_155233| [-1.50000e-01 -3.75330e-01]
21Feb13_155233| [ 3.06193e-01  2.95850e-01]
21Feb13_155233| [-9.42505e-01  2.13800e-01]
21Feb13_155233| [-1.30461e-01  1.64833e+00]
21Feb13_155233| [-6.15155e-01 -3.55179e-01]
21Feb13_155233| [-1.17417e-01 -1.18387e-01]
21Feb13_155233| [-4.01483e-01 -2.19326e-01]
21Feb13_155233| [-1.87883e+00  1.39386e+00]
21Feb13_155233| [ 1.89659e-01  1.45514e-01]
21Feb13_155233| [-5.92524e-01  1.65847e-04]
21Feb13_155233| [ 8.78716e-02  1.46392e+00]
21Feb13_155233| [-1.80890e-01 -2.27272e+00]
21Feb13_155233| [-1.63609e+00 -6.52740e-01]
21Feb13_155233| [ 1.00064e+00  1.46731e+00]
21Feb13_155233| [-3.00436e-01  1.28942e+00]
21Feb13_155233| [ 6.64438e-01 -1.57465e+00]
21Feb13_155233| [ 7.59207e-01 -1.12811e+00]
21Feb13_155233| [ 6.90331e-01 -5.86368e-01]
21Feb13_155233| [-1.06339e+00  4.85698e-01]
21Feb13_155233| [ 5.11252e-01 -3.04713e-01]
21Feb13_155233| [ 4.06633e-01 -9.98990e-01]
21Feb13_155233| [-2.36275e-01  1.06431e+00]
21Feb13_155233| [ 7.76257e-01  4.55359e-02]
21Feb13_155233| [-2.64892e-01 -1.02468e+00]
21Feb13_155233| [-6.04665e-01  2.56693e-02]
21Feb13_155233| [ 1.62444e+00 -6.69185e-02]
21Feb13_155233| [ 2.74037e-01 -4.26530e-01]
21Feb13_155233| [ 3.92490e-01  6.69319e-01]
21Feb13_155233| [ 7.09436e-01  5.26102e-03]
21Feb13_155233| [ 1.61981e+00 -4.23153e-01]
21Feb13_155233| [ 1.53159e+00  9.96100e-01]
21Feb13_155233| [ 1.45073e+00  8.59597e-01]
21Feb13_155233| [-8.01045e-01  1.05088e+00]
21Feb13_155233| [-3.88304e-01 -9.77505e-01]
21Feb13_155233| [ 1.16485e-01 -9.19986e-01]
21Feb13_155233| [ 3.77734e-01  2.48010e-01]
21Feb13_155233| [ 1.41200e+00  1.16799e+00]
21Feb13_155233| [ 1.74979e+00  1.13810e-01]
21Feb13_155233| [-2.67050e-01 -2.95342e-01]
21Feb13_155233| [-2.44769e-01  4.70332e-01]
21Feb13_155233| [-4.69208e-01  7.01631e-01]
21Feb13_155233| [ 2.68463e-01  1.05983e+00]
21Feb13_155233| [-1.24933e+00 -7.63457e-01]
21Feb13_155233| [ 1.72854e+00 -1.64952e+00]
21Feb13_155233| [-4.51831e-01 -1.68902e-01]]
21Feb13_155233|-- Bias --
21Feb13_155233|[0.75810 0.18412]
21Feb13_155233|Layer 1:
21Feb13_155233|-- Config --
21Feb13_155233|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155233|-- Weights --
21Feb13_155233|[[-0.15478  0.26526]
21Feb13_155233| [ 0.85540  0.19795]]
21Feb13_155233|-- Bias --
21Feb13_155233|[-0.13919  0.90108]
21Feb13_155233|Layer 2:
21Feb13_155233|-- Config --
21Feb13_155233|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155233|-- Weights --
21Feb13_155233|[[ 0.81512  0.59188]
21Feb13_155233| [-0.82418 -0.16769]]
21Feb13_155233|-- Bias --
21Feb13_155233|[-0.91892  0.39865]
21Feb13_155233|Layer 3:
21Feb13_155233|-- Config --
21Feb13_155233|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155233|-- Weights --
21Feb13_155233|[[-1.08106 -0.42261]
21Feb13_155233| [-0.08260 -0.34745]]
21Feb13_155233|-- Bias --
21Feb13_155233|[0.09599 0.38712]
21Feb13_155233|Predicting the validation and test data with the Best final individual.
21Feb13_155241| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_155241|-----------  ------------------  --------------------  ----------
21Feb13_155241|Validation         23.57                  18            0.70824
21Feb13_155241|   Test            25.02                  18            0.60325
21Feb13_155241|-------------------- Test #1 --------------------
21Feb13_155241|Best final individual weights
21Feb13_155241|Individual:
21Feb13_155241|-- Constant hidden layers --
21Feb13_155241|False
21Feb13_155241|Layer 0:
21Feb13_155241|-- Config --
21Feb13_155241|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155241|-- Weights --
21Feb13_155241|[[ 4.91885e-01  3.98183e-01]
21Feb13_155241| [-9.54215e-01 -1.24646e+00]
21Feb13_155241| [-1.10574e+00  9.54098e-01]
21Feb13_155241| [-7.23267e-01  5.05588e-01]
21Feb13_155241| [-2.90292e-01 -7.75831e-01]
21Feb13_155241| [ 1.72812e+00  4.07095e-01]
21Feb13_155241| [ 3.55902e-01  1.14081e+00]
21Feb13_155241| [-1.48987e+00  4.85259e-01]
21Feb13_155241| [-5.60401e-01 -3.04522e-01]
21Feb13_155241| [ 6.71669e-01  2.81967e-01]
21Feb13_155241| [-9.29584e-01 -6.42349e-02]
21Feb13_155241| [ 1.03435e+00 -9.55452e-01]
21Feb13_155241| [-1.50000e-01 -3.75330e-01]
21Feb13_155241| [ 3.06193e-01  2.95850e-01]
21Feb13_155241| [-9.42505e-01  2.13800e-01]
21Feb13_155241| [-1.30461e-01  1.64833e+00]
21Feb13_155241| [-6.15155e-01 -3.55179e-01]
21Feb13_155241| [-1.17417e-01 -1.18387e-01]
21Feb13_155241| [-4.01483e-01 -2.19326e-01]
21Feb13_155241| [-1.87883e+00  1.39386e+00]
21Feb13_155241| [ 1.89659e-01  1.45514e-01]
21Feb13_155241| [-5.92524e-01  1.65847e-04]
21Feb13_155241| [ 8.78716e-02  1.46392e+00]
21Feb13_155241| [-1.80890e-01 -2.27272e+00]
21Feb13_155241| [-1.63609e+00 -6.52740e-01]
21Feb13_155241| [ 1.00064e+00  1.46731e+00]
21Feb13_155241| [-3.00436e-01  1.28942e+00]
21Feb13_155241| [ 6.64438e-01 -1.57465e+00]
21Feb13_155241| [ 7.59207e-01 -1.12811e+00]
21Feb13_155241| [ 6.90331e-01 -5.86368e-01]
21Feb13_155241| [-1.06339e+00  4.85698e-01]
21Feb13_155241| [ 5.11252e-01 -3.04713e-01]
21Feb13_155241| [ 4.06633e-01 -9.98990e-01]
21Feb13_155241| [-2.36275e-01  1.06431e+00]
21Feb13_155241| [ 7.76257e-01  4.55359e-02]
21Feb13_155241| [-2.64892e-01 -1.02468e+00]
21Feb13_155241| [-6.04665e-01  2.56693e-02]
21Feb13_155241| [ 1.62444e+00 -6.69185e-02]
21Feb13_155241| [ 2.74037e-01 -4.26530e-01]
21Feb13_155241| [ 3.92490e-01  6.69319e-01]
21Feb13_155241| [ 7.09436e-01  5.26102e-03]
21Feb13_155241| [ 1.61981e+00 -4.23153e-01]
21Feb13_155241| [ 1.53159e+00  9.96100e-01]
21Feb13_155241| [ 1.45073e+00  8.59597e-01]
21Feb13_155241| [-8.01045e-01  1.05088e+00]
21Feb13_155241| [-3.88304e-01 -9.77505e-01]
21Feb13_155241| [ 1.16485e-01 -9.19986e-01]
21Feb13_155241| [ 3.77734e-01  2.48010e-01]
21Feb13_155241| [ 1.41200e+00  1.16799e+00]
21Feb13_155241| [ 1.74979e+00  1.13810e-01]
21Feb13_155241| [-2.67050e-01 -2.95342e-01]
21Feb13_155241| [-2.44769e-01  4.70332e-01]
21Feb13_155241| [-4.69208e-01  7.01631e-01]
21Feb13_155241| [ 2.68463e-01  1.05983e+00]
21Feb13_155241| [-1.24933e+00 -7.63457e-01]
21Feb13_155241| [ 1.72854e+00 -1.64952e+00]
21Feb13_155241| [-4.51831e-01 -1.68902e-01]]
21Feb13_155241|-- Bias --
21Feb13_155241|[0.75810 0.18412]
21Feb13_155241|Layer 1:
21Feb13_155241|-- Config --
21Feb13_155241|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155241|-- Weights --
21Feb13_155241|[[-0.15478  0.26526]
21Feb13_155241| [ 0.85540  0.19795]]
21Feb13_155241|-- Bias --
21Feb13_155241|[-0.13919  0.90108]
21Feb13_155241|Layer 2:
21Feb13_155241|-- Config --
21Feb13_155241|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155241|-- Weights --
21Feb13_155241|[[ 0.81512  0.59188]
21Feb13_155241| [-0.82418 -0.16769]]
21Feb13_155241|-- Bias --
21Feb13_155241|[-0.91892  0.39865]
21Feb13_155241|Layer 3:
21Feb13_155241|-- Config --
21Feb13_155241|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155241|-- Weights --
21Feb13_155241|[[-1.08106 -0.42261]
21Feb13_155241| [-0.08260 -0.34745]]
21Feb13_155241|-- Bias --
21Feb13_155241|[0.09599 0.38712]
21Feb13_155241|Predicting the validation and test data with the Best final individual.
21Feb13_155249| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_155249|-----------  ------------------  --------------------  ----------
21Feb13_155249|Validation         23.39                  18            0.66469
21Feb13_155249|   Test            25.63                  18            0.70586
21Feb13_155249|-------------------- Test #2 --------------------
21Feb13_155249|Best final individual weights
21Feb13_155249|Individual:
21Feb13_155249|-- Constant hidden layers --
21Feb13_155249|False
21Feb13_155249|Layer 0:
21Feb13_155249|-- Config --
21Feb13_155249|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155249|-- Weights --
21Feb13_155249|[[ 4.91885e-01  3.98183e-01]
21Feb13_155249| [-9.54215e-01 -1.24646e+00]
21Feb13_155249| [-1.10574e+00  9.54098e-01]
21Feb13_155249| [-7.23267e-01  5.05588e-01]
21Feb13_155249| [-2.90292e-01 -7.75831e-01]
21Feb13_155249| [ 1.72812e+00  4.07095e-01]
21Feb13_155249| [ 3.55902e-01  1.14081e+00]
21Feb13_155249| [-1.48987e+00  4.85259e-01]
21Feb13_155249| [-5.60401e-01 -3.04522e-01]
21Feb13_155249| [ 6.71669e-01  2.81967e-01]
21Feb13_155249| [-9.29584e-01 -6.42349e-02]
21Feb13_155249| [ 1.03435e+00 -9.55452e-01]
21Feb13_155249| [-1.50000e-01 -3.75330e-01]
21Feb13_155249| [ 3.06193e-01  2.95850e-01]
21Feb13_155249| [-9.42505e-01  2.13800e-01]
21Feb13_155249| [-1.30461e-01  1.64833e+00]
21Feb13_155249| [-6.15155e-01 -3.55179e-01]
21Feb13_155249| [-1.17417e-01 -1.18387e-01]
21Feb13_155249| [-4.01483e-01 -2.19326e-01]
21Feb13_155249| [-1.87883e+00  1.39386e+00]
21Feb13_155249| [ 1.89659e-01  1.45514e-01]
21Feb13_155249| [-5.92524e-01  1.65847e-04]
21Feb13_155249| [ 8.78716e-02  1.46392e+00]
21Feb13_155249| [-1.80890e-01 -2.27272e+00]
21Feb13_155249| [-1.63609e+00 -6.52740e-01]
21Feb13_155249| [ 1.00064e+00  1.46731e+00]
21Feb13_155249| [-3.00436e-01  1.28942e+00]
21Feb13_155249| [ 6.64438e-01 -1.57465e+00]
21Feb13_155249| [ 7.59207e-01 -1.12811e+00]
21Feb13_155249| [ 6.90331e-01 -5.86368e-01]
21Feb13_155249| [-1.06339e+00  4.85698e-01]
21Feb13_155249| [ 5.11252e-01 -3.04713e-01]
21Feb13_155249| [ 4.06633e-01 -9.98990e-01]
21Feb13_155249| [-2.36275e-01  1.06431e+00]
21Feb13_155249| [ 7.76257e-01  4.55359e-02]
21Feb13_155249| [-2.64892e-01 -1.02468e+00]
21Feb13_155249| [-6.04665e-01  2.56693e-02]
21Feb13_155249| [ 1.62444e+00 -6.69185e-02]
21Feb13_155249| [ 2.74037e-01 -4.26530e-01]
21Feb13_155249| [ 3.92490e-01  6.69319e-01]
21Feb13_155249| [ 7.09436e-01  5.26102e-03]
21Feb13_155249| [ 1.61981e+00 -4.23153e-01]
21Feb13_155249| [ 1.53159e+00  9.96100e-01]
21Feb13_155249| [ 1.45073e+00  8.59597e-01]
21Feb13_155249| [-8.01045e-01  1.05088e+00]
21Feb13_155249| [-3.88304e-01 -9.77505e-01]
21Feb13_155249| [ 1.16485e-01 -9.19986e-01]
21Feb13_155249| [ 3.77734e-01  2.48010e-01]
21Feb13_155249| [ 1.41200e+00  1.16799e+00]
21Feb13_155249| [ 1.74979e+00  1.13810e-01]
21Feb13_155249| [-2.67050e-01 -2.95342e-01]
21Feb13_155249| [-2.44769e-01  4.70332e-01]
21Feb13_155249| [-4.69208e-01  7.01631e-01]
21Feb13_155249| [ 2.68463e-01  1.05983e+00]
21Feb13_155249| [-1.24933e+00 -7.63457e-01]
21Feb13_155249| [ 1.72854e+00 -1.64952e+00]
21Feb13_155249| [-4.51831e-01 -1.68902e-01]]
21Feb13_155249|-- Bias --
21Feb13_155249|[0.75810 0.18412]
21Feb13_155249|Layer 1:
21Feb13_155249|-- Config --
21Feb13_155249|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155249|-- Weights --
21Feb13_155249|[[-0.15478  0.26526]
21Feb13_155249| [ 0.85540  0.19795]]
21Feb13_155249|-- Bias --
21Feb13_155249|[-0.13919  0.90108]
21Feb13_155249|Layer 2:
21Feb13_155249|-- Config --
21Feb13_155249|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155249|-- Weights --
21Feb13_155249|[[ 0.81512  0.59188]
21Feb13_155249| [-0.82418 -0.16769]]
21Feb13_155249|-- Bias --
21Feb13_155249|[-0.91892  0.39865]
21Feb13_155249|Layer 3:
21Feb13_155249|-- Config --
21Feb13_155249|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155249|-- Weights --
21Feb13_155249|[[-1.08106 -0.42261]
21Feb13_155249| [-0.08260 -0.34745]]
21Feb13_155249|-- Bias --
21Feb13_155249|[0.09599 0.38712]
21Feb13_155249|Predicting the validation and test data with the Best final individual.
21Feb13_155256| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_155256|-----------  ------------------  --------------------  ----------
21Feb13_155256|Validation         23.83                  18            0.67977
21Feb13_155256|   Test            25.11                  18            0.67736
21Feb13_155256|-------------------- Test #3 --------------------
21Feb13_155256|Best final individual weights
21Feb13_155256|Individual:
21Feb13_155256|-- Constant hidden layers --
21Feb13_155256|False
21Feb13_155256|Layer 0:
21Feb13_155256|-- Config --
21Feb13_155256|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155256|-- Weights --
21Feb13_155256|[[ 4.91885e-01  3.98183e-01]
21Feb13_155256| [-9.54215e-01 -1.24646e+00]
21Feb13_155256| [-1.10574e+00  9.54098e-01]
21Feb13_155256| [-7.23267e-01  5.05588e-01]
21Feb13_155256| [-2.90292e-01 -7.75831e-01]
21Feb13_155256| [ 1.72812e+00  4.07095e-01]
21Feb13_155256| [ 3.55902e-01  1.14081e+00]
21Feb13_155256| [-1.48987e+00  4.85259e-01]
21Feb13_155256| [-5.60401e-01 -3.04522e-01]
21Feb13_155256| [ 6.71669e-01  2.81967e-01]
21Feb13_155256| [-9.29584e-01 -6.42349e-02]
21Feb13_155256| [ 1.03435e+00 -9.55452e-01]
21Feb13_155256| [-1.50000e-01 -3.75330e-01]
21Feb13_155256| [ 3.06193e-01  2.95850e-01]
21Feb13_155256| [-9.42505e-01  2.13800e-01]
21Feb13_155256| [-1.30461e-01  1.64833e+00]
21Feb13_155256| [-6.15155e-01 -3.55179e-01]
21Feb13_155256| [-1.17417e-01 -1.18387e-01]
21Feb13_155256| [-4.01483e-01 -2.19326e-01]
21Feb13_155256| [-1.87883e+00  1.39386e+00]
21Feb13_155256| [ 1.89659e-01  1.45514e-01]
21Feb13_155256| [-5.92524e-01  1.65847e-04]
21Feb13_155256| [ 8.78716e-02  1.46392e+00]
21Feb13_155256| [-1.80890e-01 -2.27272e+00]
21Feb13_155256| [-1.63609e+00 -6.52740e-01]
21Feb13_155256| [ 1.00064e+00  1.46731e+00]
21Feb13_155256| [-3.00436e-01  1.28942e+00]
21Feb13_155256| [ 6.64438e-01 -1.57465e+00]
21Feb13_155256| [ 7.59207e-01 -1.12811e+00]
21Feb13_155256| [ 6.90331e-01 -5.86368e-01]
21Feb13_155256| [-1.06339e+00  4.85698e-01]
21Feb13_155256| [ 5.11252e-01 -3.04713e-01]
21Feb13_155256| [ 4.06633e-01 -9.98990e-01]
21Feb13_155256| [-2.36275e-01  1.06431e+00]
21Feb13_155256| [ 7.76257e-01  4.55359e-02]
21Feb13_155256| [-2.64892e-01 -1.02468e+00]
21Feb13_155256| [-6.04665e-01  2.56693e-02]
21Feb13_155256| [ 1.62444e+00 -6.69185e-02]
21Feb13_155256| [ 2.74037e-01 -4.26530e-01]
21Feb13_155256| [ 3.92490e-01  6.69319e-01]
21Feb13_155256| [ 7.09436e-01  5.26102e-03]
21Feb13_155256| [ 1.61981e+00 -4.23153e-01]
21Feb13_155256| [ 1.53159e+00  9.96100e-01]
21Feb13_155256| [ 1.45073e+00  8.59597e-01]
21Feb13_155256| [-8.01045e-01  1.05088e+00]
21Feb13_155256| [-3.88304e-01 -9.77505e-01]
21Feb13_155256| [ 1.16485e-01 -9.19986e-01]
21Feb13_155256| [ 3.77734e-01  2.48010e-01]
21Feb13_155256| [ 1.41200e+00  1.16799e+00]
21Feb13_155256| [ 1.74979e+00  1.13810e-01]
21Feb13_155256| [-2.67050e-01 -2.95342e-01]
21Feb13_155256| [-2.44769e-01  4.70332e-01]
21Feb13_155256| [-4.69208e-01  7.01631e-01]
21Feb13_155256| [ 2.68463e-01  1.05983e+00]
21Feb13_155256| [-1.24933e+00 -7.63457e-01]
21Feb13_155256| [ 1.72854e+00 -1.64952e+00]
21Feb13_155256| [-4.51831e-01 -1.68902e-01]]
21Feb13_155256|-- Bias --
21Feb13_155256|[0.75810 0.18412]
21Feb13_155256|Layer 1:
21Feb13_155256|-- Config --
21Feb13_155256|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155256|-- Weights --
21Feb13_155256|[[-0.15478  0.26526]
21Feb13_155256| [ 0.85540  0.19795]]
21Feb13_155256|-- Bias --
21Feb13_155256|[-0.13919  0.90108]
21Feb13_155256|Layer 2:
21Feb13_155256|-- Config --
21Feb13_155256|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155256|-- Weights --
21Feb13_155256|[[ 0.81512  0.59188]
21Feb13_155256| [-0.82418 -0.16769]]
21Feb13_155256|-- Bias --
21Feb13_155256|[-0.91892  0.39865]
21Feb13_155256|Layer 3:
21Feb13_155256|-- Config --
21Feb13_155256|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155256|-- Weights --
21Feb13_155256|[[-1.08106 -0.42261]
21Feb13_155256| [-0.08260 -0.34745]]
21Feb13_155256|-- Bias --
21Feb13_155256|[0.09599 0.38712]
21Feb13_155256|Predicting the validation and test data with the Best final individual.
21Feb13_155304| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_155304|-----------  ------------------  --------------------  ----------
21Feb13_155304|Validation         23.39                  18            0.68623
21Feb13_155304|   Test            24.41                  18            0.67652
21Feb13_155304|-------------------- Test #4 --------------------
21Feb13_155304|Best final individual weights
21Feb13_155304|Individual:
21Feb13_155304|-- Constant hidden layers --
21Feb13_155304|False
21Feb13_155304|Layer 0:
21Feb13_155304|-- Config --
21Feb13_155304|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155304|-- Weights --
21Feb13_155304|[[ 4.91885e-01  3.98183e-01]
21Feb13_155304| [-9.54215e-01 -1.24646e+00]
21Feb13_155304| [-1.10574e+00  9.54098e-01]
21Feb13_155304| [-7.23267e-01  5.05588e-01]
21Feb13_155304| [-2.90292e-01 -7.75831e-01]
21Feb13_155304| [ 1.72812e+00  4.07095e-01]
21Feb13_155304| [ 3.55902e-01  1.14081e+00]
21Feb13_155304| [-1.48987e+00  4.85259e-01]
21Feb13_155304| [-5.60401e-01 -3.04522e-01]
21Feb13_155304| [ 6.71669e-01  2.81967e-01]
21Feb13_155304| [-9.29584e-01 -6.42349e-02]
21Feb13_155304| [ 1.03435e+00 -9.55452e-01]
21Feb13_155304| [-1.50000e-01 -3.75330e-01]
21Feb13_155304| [ 3.06193e-01  2.95850e-01]
21Feb13_155304| [-9.42505e-01  2.13800e-01]
21Feb13_155304| [-1.30461e-01  1.64833e+00]
21Feb13_155304| [-6.15155e-01 -3.55179e-01]
21Feb13_155304| [-1.17417e-01 -1.18387e-01]
21Feb13_155304| [-4.01483e-01 -2.19326e-01]
21Feb13_155304| [-1.87883e+00  1.39386e+00]
21Feb13_155304| [ 1.89659e-01  1.45514e-01]
21Feb13_155304| [-5.92524e-01  1.65847e-04]
21Feb13_155304| [ 8.78716e-02  1.46392e+00]
21Feb13_155304| [-1.80890e-01 -2.27272e+00]
21Feb13_155304| [-1.63609e+00 -6.52740e-01]
21Feb13_155304| [ 1.00064e+00  1.46731e+00]
21Feb13_155304| [-3.00436e-01  1.28942e+00]
21Feb13_155304| [ 6.64438e-01 -1.57465e+00]
21Feb13_155304| [ 7.59207e-01 -1.12811e+00]
21Feb13_155304| [ 6.90331e-01 -5.86368e-01]
21Feb13_155304| [-1.06339e+00  4.85698e-01]
21Feb13_155304| [ 5.11252e-01 -3.04713e-01]
21Feb13_155304| [ 4.06633e-01 -9.98990e-01]
21Feb13_155304| [-2.36275e-01  1.06431e+00]
21Feb13_155304| [ 7.76257e-01  4.55359e-02]
21Feb13_155304| [-2.64892e-01 -1.02468e+00]
21Feb13_155304| [-6.04665e-01  2.56693e-02]
21Feb13_155304| [ 1.62444e+00 -6.69185e-02]
21Feb13_155304| [ 2.74037e-01 -4.26530e-01]
21Feb13_155304| [ 3.92490e-01  6.69319e-01]
21Feb13_155304| [ 7.09436e-01  5.26102e-03]
21Feb13_155304| [ 1.61981e+00 -4.23153e-01]
21Feb13_155304| [ 1.53159e+00  9.96100e-01]
21Feb13_155304| [ 1.45073e+00  8.59597e-01]
21Feb13_155304| [-8.01045e-01  1.05088e+00]
21Feb13_155304| [-3.88304e-01 -9.77505e-01]
21Feb13_155304| [ 1.16485e-01 -9.19986e-01]
21Feb13_155304| [ 3.77734e-01  2.48010e-01]
21Feb13_155304| [ 1.41200e+00  1.16799e+00]
21Feb13_155304| [ 1.74979e+00  1.13810e-01]
21Feb13_155304| [-2.67050e-01 -2.95342e-01]
21Feb13_155304| [-2.44769e-01  4.70332e-01]
21Feb13_155304| [-4.69208e-01  7.01631e-01]
21Feb13_155304| [ 2.68463e-01  1.05983e+00]
21Feb13_155304| [-1.24933e+00 -7.63457e-01]
21Feb13_155304| [ 1.72854e+00 -1.64952e+00]
21Feb13_155304| [-4.51831e-01 -1.68902e-01]]
21Feb13_155304|-- Bias --
21Feb13_155304|[0.75810 0.18412]
21Feb13_155304|Layer 1:
21Feb13_155304|-- Config --
21Feb13_155304|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155304|-- Weights --
21Feb13_155304|[[-0.15478  0.26526]
21Feb13_155304| [ 0.85540  0.19795]]
21Feb13_155304|-- Bias --
21Feb13_155304|[-0.13919  0.90108]
21Feb13_155304|Layer 2:
21Feb13_155304|-- Config --
21Feb13_155304|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155304|-- Weights --
21Feb13_155304|[[ 0.81512  0.59188]
21Feb13_155304| [-0.82418 -0.16769]]
21Feb13_155304|-- Bias --
21Feb13_155304|[-0.91892  0.39865]
21Feb13_155304|Layer 3:
21Feb13_155304|-- Config --
21Feb13_155304|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155304|-- Weights --
21Feb13_155304|[[-1.08106 -0.42261]
21Feb13_155304| [-0.08260 -0.34745]]
21Feb13_155304|-- Bias --
21Feb13_155304|[0.09599 0.38712]
21Feb13_155304|Predicting the validation and test data with the Best final individual.
21Feb13_155311| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_155311|-----------  ------------------  --------------------  ----------
21Feb13_155311|Validation         23.30                  18            0.73283
21Feb13_155311|   Test            24.50                  18            0.65974
21Feb13_155311|-------------------- Test #5 --------------------
21Feb13_155311|Best final individual weights
21Feb13_155311|Individual:
21Feb13_155311|-- Constant hidden layers --
21Feb13_155311|False
21Feb13_155311|Layer 0:
21Feb13_155311|-- Config --
21Feb13_155311|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155311|-- Weights --
21Feb13_155311|[[ 4.91885e-01  3.98183e-01]
21Feb13_155311| [-9.54215e-01 -1.24646e+00]
21Feb13_155311| [-1.10574e+00  9.54098e-01]
21Feb13_155311| [-7.23267e-01  5.05588e-01]
21Feb13_155311| [-2.90292e-01 -7.75831e-01]
21Feb13_155311| [ 1.72812e+00  4.07095e-01]
21Feb13_155311| [ 3.55902e-01  1.14081e+00]
21Feb13_155311| [-1.48987e+00  4.85259e-01]
21Feb13_155311| [-5.60401e-01 -3.04522e-01]
21Feb13_155311| [ 6.71669e-01  2.81967e-01]
21Feb13_155311| [-9.29584e-01 -6.42349e-02]
21Feb13_155311| [ 1.03435e+00 -9.55452e-01]
21Feb13_155311| [-1.50000e-01 -3.75330e-01]
21Feb13_155311| [ 3.06193e-01  2.95850e-01]
21Feb13_155311| [-9.42505e-01  2.13800e-01]
21Feb13_155311| [-1.30461e-01  1.64833e+00]
21Feb13_155311| [-6.15155e-01 -3.55179e-01]
21Feb13_155311| [-1.17417e-01 -1.18387e-01]
21Feb13_155311| [-4.01483e-01 -2.19326e-01]
21Feb13_155311| [-1.87883e+00  1.39386e+00]
21Feb13_155311| [ 1.89659e-01  1.45514e-01]
21Feb13_155311| [-5.92524e-01  1.65847e-04]
21Feb13_155311| [ 8.78716e-02  1.46392e+00]
21Feb13_155311| [-1.80890e-01 -2.27272e+00]
21Feb13_155311| [-1.63609e+00 -6.52740e-01]
21Feb13_155311| [ 1.00064e+00  1.46731e+00]
21Feb13_155311| [-3.00436e-01  1.28942e+00]
21Feb13_155311| [ 6.64438e-01 -1.57465e+00]
21Feb13_155311| [ 7.59207e-01 -1.12811e+00]
21Feb13_155311| [ 6.90331e-01 -5.86368e-01]
21Feb13_155311| [-1.06339e+00  4.85698e-01]
21Feb13_155311| [ 5.11252e-01 -3.04713e-01]
21Feb13_155311| [ 4.06633e-01 -9.98990e-01]
21Feb13_155311| [-2.36275e-01  1.06431e+00]
21Feb13_155311| [ 7.76257e-01  4.55359e-02]
21Feb13_155311| [-2.64892e-01 -1.02468e+00]
21Feb13_155311| [-6.04665e-01  2.56693e-02]
21Feb13_155311| [ 1.62444e+00 -6.69185e-02]
21Feb13_155311| [ 2.74037e-01 -4.26530e-01]
21Feb13_155311| [ 3.92490e-01  6.69319e-01]
21Feb13_155311| [ 7.09436e-01  5.26102e-03]
21Feb13_155311| [ 1.61981e+00 -4.23153e-01]
21Feb13_155311| [ 1.53159e+00  9.96100e-01]
21Feb13_155311| [ 1.45073e+00  8.59597e-01]
21Feb13_155311| [-8.01045e-01  1.05088e+00]
21Feb13_155311| [-3.88304e-01 -9.77505e-01]
21Feb13_155311| [ 1.16485e-01 -9.19986e-01]
21Feb13_155311| [ 3.77734e-01  2.48010e-01]
21Feb13_155311| [ 1.41200e+00  1.16799e+00]
21Feb13_155311| [ 1.74979e+00  1.13810e-01]
21Feb13_155311| [-2.67050e-01 -2.95342e-01]
21Feb13_155311| [-2.44769e-01  4.70332e-01]
21Feb13_155311| [-4.69208e-01  7.01631e-01]
21Feb13_155311| [ 2.68463e-01  1.05983e+00]
21Feb13_155311| [-1.24933e+00 -7.63457e-01]
21Feb13_155311| [ 1.72854e+00 -1.64952e+00]
21Feb13_155311| [-4.51831e-01 -1.68902e-01]]
21Feb13_155311|-- Bias --
21Feb13_155311|[0.75810 0.18412]
21Feb13_155311|Layer 1:
21Feb13_155311|-- Config --
21Feb13_155311|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155311|-- Weights --
21Feb13_155311|[[-0.15478  0.26526]
21Feb13_155311| [ 0.85540  0.19795]]
21Feb13_155311|-- Bias --
21Feb13_155311|[-0.13919  0.90108]
21Feb13_155311|Layer 2:
21Feb13_155311|-- Config --
21Feb13_155311|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155311|-- Weights --
21Feb13_155311|[[ 0.81512  0.59188]
21Feb13_155311| [-0.82418 -0.16769]]
21Feb13_155311|-- Bias --
21Feb13_155311|[-0.91892  0.39865]
21Feb13_155311|Layer 3:
21Feb13_155311|-- Config --
21Feb13_155311|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155311|-- Weights --
21Feb13_155311|[[-1.08106 -0.42261]
21Feb13_155311| [-0.08260 -0.34745]]
21Feb13_155311|-- Bias --
21Feb13_155311|[0.09599 0.38712]
21Feb13_155311|Predicting the validation and test data with the Best final individual.
21Feb13_155319| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_155319|-----------  ------------------  --------------------  ----------
21Feb13_155319|Validation         23.91                  18            0.67451
21Feb13_155319|   Test            25.20                  18            0.70426
21Feb13_155319|-------------------- Test #6 --------------------
21Feb13_155319|Best final individual weights
21Feb13_155319|Individual:
21Feb13_155319|-- Constant hidden layers --
21Feb13_155319|False
21Feb13_155319|Layer 0:
21Feb13_155319|-- Config --
21Feb13_155319|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155319|-- Weights --
21Feb13_155319|[[ 4.91885e-01  3.98183e-01]
21Feb13_155319| [-9.54215e-01 -1.24646e+00]
21Feb13_155319| [-1.10574e+00  9.54098e-01]
21Feb13_155319| [-7.23267e-01  5.05588e-01]
21Feb13_155319| [-2.90292e-01 -7.75831e-01]
21Feb13_155319| [ 1.72812e+00  4.07095e-01]
21Feb13_155319| [ 3.55902e-01  1.14081e+00]
21Feb13_155319| [-1.48987e+00  4.85259e-01]
21Feb13_155319| [-5.60401e-01 -3.04522e-01]
21Feb13_155319| [ 6.71669e-01  2.81967e-01]
21Feb13_155319| [-9.29584e-01 -6.42349e-02]
21Feb13_155319| [ 1.03435e+00 -9.55452e-01]
21Feb13_155319| [-1.50000e-01 -3.75330e-01]
21Feb13_155319| [ 3.06193e-01  2.95850e-01]
21Feb13_155319| [-9.42505e-01  2.13800e-01]
21Feb13_155319| [-1.30461e-01  1.64833e+00]
21Feb13_155319| [-6.15155e-01 -3.55179e-01]
21Feb13_155319| [-1.17417e-01 -1.18387e-01]
21Feb13_155319| [-4.01483e-01 -2.19326e-01]
21Feb13_155319| [-1.87883e+00  1.39386e+00]
21Feb13_155319| [ 1.89659e-01  1.45514e-01]
21Feb13_155319| [-5.92524e-01  1.65847e-04]
21Feb13_155319| [ 8.78716e-02  1.46392e+00]
21Feb13_155319| [-1.80890e-01 -2.27272e+00]
21Feb13_155319| [-1.63609e+00 -6.52740e-01]
21Feb13_155319| [ 1.00064e+00  1.46731e+00]
21Feb13_155319| [-3.00436e-01  1.28942e+00]
21Feb13_155319| [ 6.64438e-01 -1.57465e+00]
21Feb13_155319| [ 7.59207e-01 -1.12811e+00]
21Feb13_155319| [ 6.90331e-01 -5.86368e-01]
21Feb13_155319| [-1.06339e+00  4.85698e-01]
21Feb13_155319| [ 5.11252e-01 -3.04713e-01]
21Feb13_155319| [ 4.06633e-01 -9.98990e-01]
21Feb13_155319| [-2.36275e-01  1.06431e+00]
21Feb13_155319| [ 7.76257e-01  4.55359e-02]
21Feb13_155319| [-2.64892e-01 -1.02468e+00]
21Feb13_155319| [-6.04665e-01  2.56693e-02]
21Feb13_155319| [ 1.62444e+00 -6.69185e-02]
21Feb13_155319| [ 2.74037e-01 -4.26530e-01]
21Feb13_155319| [ 3.92490e-01  6.69319e-01]
21Feb13_155319| [ 7.09436e-01  5.26102e-03]
21Feb13_155319| [ 1.61981e+00 -4.23153e-01]
21Feb13_155319| [ 1.53159e+00  9.96100e-01]
21Feb13_155319| [ 1.45073e+00  8.59597e-01]
21Feb13_155319| [-8.01045e-01  1.05088e+00]
21Feb13_155319| [-3.88304e-01 -9.77505e-01]
21Feb13_155319| [ 1.16485e-01 -9.19986e-01]
21Feb13_155319| [ 3.77734e-01  2.48010e-01]
21Feb13_155319| [ 1.41200e+00  1.16799e+00]
21Feb13_155319| [ 1.74979e+00  1.13810e-01]
21Feb13_155319| [-2.67050e-01 -2.95342e-01]
21Feb13_155319| [-2.44769e-01  4.70332e-01]
21Feb13_155319| [-4.69208e-01  7.01631e-01]
21Feb13_155319| [ 2.68463e-01  1.05983e+00]
21Feb13_155319| [-1.24933e+00 -7.63457e-01]
21Feb13_155319| [ 1.72854e+00 -1.64952e+00]
21Feb13_155319| [-4.51831e-01 -1.68902e-01]]
21Feb13_155319|-- Bias --
21Feb13_155319|[0.75810 0.18412]
21Feb13_155319|Layer 1:
21Feb13_155319|-- Config --
21Feb13_155319|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155319|-- Weights --
21Feb13_155319|[[-0.15478  0.26526]
21Feb13_155319| [ 0.85540  0.19795]]
21Feb13_155319|-- Bias --
21Feb13_155319|[-0.13919  0.90108]
21Feb13_155319|Layer 2:
21Feb13_155319|-- Config --
21Feb13_155319|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155319|-- Weights --
21Feb13_155319|[[ 0.81512  0.59188]
21Feb13_155319| [-0.82418 -0.16769]]
21Feb13_155319|-- Bias --
21Feb13_155319|[-0.91892  0.39865]
21Feb13_155319|Layer 3:
21Feb13_155319|-- Config --
21Feb13_155319|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155319|-- Weights --
21Feb13_155319|[[-1.08106 -0.42261]
21Feb13_155319| [-0.08260 -0.34745]]
21Feb13_155319|-- Bias --
21Feb13_155319|[0.09599 0.38712]
21Feb13_155319|Predicting the validation and test data with the Best final individual.
21Feb13_155327| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_155327|-----------  ------------------  --------------------  ----------
21Feb13_155327|Validation         26.35                  18            0.73396
21Feb13_155327|   Test            31.10                  18            0.77499
21Feb13_155327|-------------------- Test #7 --------------------
21Feb13_155327|Best final individual weights
21Feb13_155327|Individual:
21Feb13_155327|-- Constant hidden layers --
21Feb13_155327|False
21Feb13_155327|Layer 0:
21Feb13_155327|-- Config --
21Feb13_155327|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155327|-- Weights --
21Feb13_155327|[[ 4.91885e-01  3.98183e-01]
21Feb13_155327| [-9.54215e-01 -1.24646e+00]
21Feb13_155327| [-1.10574e+00  9.54098e-01]
21Feb13_155327| [-7.23267e-01  5.05588e-01]
21Feb13_155327| [-2.90292e-01 -7.75831e-01]
21Feb13_155327| [ 1.72812e+00  4.07095e-01]
21Feb13_155327| [ 3.55902e-01  1.14081e+00]
21Feb13_155327| [-1.48987e+00  4.85259e-01]
21Feb13_155327| [-5.60401e-01 -3.04522e-01]
21Feb13_155327| [ 6.71669e-01  2.81967e-01]
21Feb13_155327| [-9.29584e-01 -6.42349e-02]
21Feb13_155327| [ 1.03435e+00 -9.55452e-01]
21Feb13_155327| [-1.50000e-01 -3.75330e-01]
21Feb13_155327| [ 3.06193e-01  2.95850e-01]
21Feb13_155327| [-9.42505e-01  2.13800e-01]
21Feb13_155327| [-1.30461e-01  1.64833e+00]
21Feb13_155327| [-6.15155e-01 -3.55179e-01]
21Feb13_155327| [-1.17417e-01 -1.18387e-01]
21Feb13_155327| [-4.01483e-01 -2.19326e-01]
21Feb13_155327| [-1.87883e+00  1.39386e+00]
21Feb13_155327| [ 1.89659e-01  1.45514e-01]
21Feb13_155327| [-5.92524e-01  1.65847e-04]
21Feb13_155327| [ 8.78716e-02  1.46392e+00]
21Feb13_155327| [-1.80890e-01 -2.27272e+00]
21Feb13_155327| [-1.63609e+00 -6.52740e-01]
21Feb13_155327| [ 1.00064e+00  1.46731e+00]
21Feb13_155327| [-3.00436e-01  1.28942e+00]
21Feb13_155327| [ 6.64438e-01 -1.57465e+00]
21Feb13_155327| [ 7.59207e-01 -1.12811e+00]
21Feb13_155327| [ 6.90331e-01 -5.86368e-01]
21Feb13_155327| [-1.06339e+00  4.85698e-01]
21Feb13_155327| [ 5.11252e-01 -3.04713e-01]
21Feb13_155327| [ 4.06633e-01 -9.98990e-01]
21Feb13_155327| [-2.36275e-01  1.06431e+00]
21Feb13_155327| [ 7.76257e-01  4.55359e-02]
21Feb13_155327| [-2.64892e-01 -1.02468e+00]
21Feb13_155327| [-6.04665e-01  2.56693e-02]
21Feb13_155327| [ 1.62444e+00 -6.69185e-02]
21Feb13_155327| [ 2.74037e-01 -4.26530e-01]
21Feb13_155327| [ 3.92490e-01  6.69319e-01]
21Feb13_155327| [ 7.09436e-01  5.26102e-03]
21Feb13_155327| [ 1.61981e+00 -4.23153e-01]
21Feb13_155327| [ 1.53159e+00  9.96100e-01]
21Feb13_155327| [ 1.45073e+00  8.59597e-01]
21Feb13_155327| [-8.01045e-01  1.05088e+00]
21Feb13_155327| [-3.88304e-01 -9.77505e-01]
21Feb13_155327| [ 1.16485e-01 -9.19986e-01]
21Feb13_155327| [ 3.77734e-01  2.48010e-01]
21Feb13_155327| [ 1.41200e+00  1.16799e+00]
21Feb13_155327| [ 1.74979e+00  1.13810e-01]
21Feb13_155327| [-2.67050e-01 -2.95342e-01]
21Feb13_155327| [-2.44769e-01  4.70332e-01]
21Feb13_155327| [-4.69208e-01  7.01631e-01]
21Feb13_155327| [ 2.68463e-01  1.05983e+00]
21Feb13_155327| [-1.24933e+00 -7.63457e-01]
21Feb13_155327| [ 1.72854e+00 -1.64952e+00]
21Feb13_155327| [-4.51831e-01 -1.68902e-01]]
21Feb13_155327|-- Bias --
21Feb13_155327|[0.75810 0.18412]
21Feb13_155327|Layer 1:
21Feb13_155327|-- Config --
21Feb13_155327|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155327|-- Weights --
21Feb13_155327|[[-0.15478  0.26526]
21Feb13_155327| [ 0.85540  0.19795]]
21Feb13_155327|-- Bias --
21Feb13_155327|[-0.13919  0.90108]
21Feb13_155327|Layer 2:
21Feb13_155327|-- Config --
21Feb13_155327|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155327|-- Weights --
21Feb13_155327|[[ 0.81512  0.59188]
21Feb13_155327| [-0.82418 -0.16769]]
21Feb13_155327|-- Bias --
21Feb13_155327|[-0.91892  0.39865]
21Feb13_155327|Layer 3:
21Feb13_155327|-- Config --
21Feb13_155327|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155327|-- Weights --
21Feb13_155327|[[-1.08106 -0.42261]
21Feb13_155327| [-0.08260 -0.34745]]
21Feb13_155327|-- Bias --
21Feb13_155327|[0.09599 0.38712]
21Feb13_155327|Predicting the validation and test data with the Best final individual.
21Feb13_155335| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_155335|-----------  ------------------  --------------------  ----------
21Feb13_155335|Validation         23.57                  18            0.71143
21Feb13_155335|   Test            26.50                  18            0.64798
21Feb13_155335|-------------------- Test #8 --------------------
21Feb13_155335|Best final individual weights
21Feb13_155335|Individual:
21Feb13_155335|-- Constant hidden layers --
21Feb13_155335|False
21Feb13_155335|Layer 0:
21Feb13_155335|-- Config --
21Feb13_155335|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155335|-- Weights --
21Feb13_155335|[[ 4.91885e-01  3.98183e-01]
21Feb13_155335| [-9.54215e-01 -1.24646e+00]
21Feb13_155335| [-1.10574e+00  9.54098e-01]
21Feb13_155335| [-7.23267e-01  5.05588e-01]
21Feb13_155335| [-2.90292e-01 -7.75831e-01]
21Feb13_155335| [ 1.72812e+00  4.07095e-01]
21Feb13_155335| [ 3.55902e-01  1.14081e+00]
21Feb13_155335| [-1.48987e+00  4.85259e-01]
21Feb13_155335| [-5.60401e-01 -3.04522e-01]
21Feb13_155335| [ 6.71669e-01  2.81967e-01]
21Feb13_155335| [-9.29584e-01 -6.42349e-02]
21Feb13_155335| [ 1.03435e+00 -9.55452e-01]
21Feb13_155335| [-1.50000e-01 -3.75330e-01]
21Feb13_155335| [ 3.06193e-01  2.95850e-01]
21Feb13_155335| [-9.42505e-01  2.13800e-01]
21Feb13_155335| [-1.30461e-01  1.64833e+00]
21Feb13_155335| [-6.15155e-01 -3.55179e-01]
21Feb13_155335| [-1.17417e-01 -1.18387e-01]
21Feb13_155335| [-4.01483e-01 -2.19326e-01]
21Feb13_155335| [-1.87883e+00  1.39386e+00]
21Feb13_155335| [ 1.89659e-01  1.45514e-01]
21Feb13_155335| [-5.92524e-01  1.65847e-04]
21Feb13_155335| [ 8.78716e-02  1.46392e+00]
21Feb13_155335| [-1.80890e-01 -2.27272e+00]
21Feb13_155335| [-1.63609e+00 -6.52740e-01]
21Feb13_155335| [ 1.00064e+00  1.46731e+00]
21Feb13_155335| [-3.00436e-01  1.28942e+00]
21Feb13_155335| [ 6.64438e-01 -1.57465e+00]
21Feb13_155335| [ 7.59207e-01 -1.12811e+00]
21Feb13_155335| [ 6.90331e-01 -5.86368e-01]
21Feb13_155335| [-1.06339e+00  4.85698e-01]
21Feb13_155335| [ 5.11252e-01 -3.04713e-01]
21Feb13_155335| [ 4.06633e-01 -9.98990e-01]
21Feb13_155335| [-2.36275e-01  1.06431e+00]
21Feb13_155335| [ 7.76257e-01  4.55359e-02]
21Feb13_155335| [-2.64892e-01 -1.02468e+00]
21Feb13_155335| [-6.04665e-01  2.56693e-02]
21Feb13_155335| [ 1.62444e+00 -6.69185e-02]
21Feb13_155335| [ 2.74037e-01 -4.26530e-01]
21Feb13_155335| [ 3.92490e-01  6.69319e-01]
21Feb13_155335| [ 7.09436e-01  5.26102e-03]
21Feb13_155335| [ 1.61981e+00 -4.23153e-01]
21Feb13_155335| [ 1.53159e+00  9.96100e-01]
21Feb13_155335| [ 1.45073e+00  8.59597e-01]
21Feb13_155335| [-8.01045e-01  1.05088e+00]
21Feb13_155335| [-3.88304e-01 -9.77505e-01]
21Feb13_155335| [ 1.16485e-01 -9.19986e-01]
21Feb13_155335| [ 3.77734e-01  2.48010e-01]
21Feb13_155335| [ 1.41200e+00  1.16799e+00]
21Feb13_155335| [ 1.74979e+00  1.13810e-01]
21Feb13_155335| [-2.67050e-01 -2.95342e-01]
21Feb13_155335| [-2.44769e-01  4.70332e-01]
21Feb13_155335| [-4.69208e-01  7.01631e-01]
21Feb13_155335| [ 2.68463e-01  1.05983e+00]
21Feb13_155335| [-1.24933e+00 -7.63457e-01]
21Feb13_155335| [ 1.72854e+00 -1.64952e+00]
21Feb13_155335| [-4.51831e-01 -1.68902e-01]]
21Feb13_155335|-- Bias --
21Feb13_155335|[0.75810 0.18412]
21Feb13_155335|Layer 1:
21Feb13_155335|-- Config --
21Feb13_155335|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155335|-- Weights --
21Feb13_155335|[[-0.15478  0.26526]
21Feb13_155335| [ 0.85540  0.19795]]
21Feb13_155335|-- Bias --
21Feb13_155335|[-0.13919  0.90108]
21Feb13_155335|Layer 2:
21Feb13_155335|-- Config --
21Feb13_155335|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155335|-- Weights --
21Feb13_155335|[[ 0.81512  0.59188]
21Feb13_155335| [-0.82418 -0.16769]]
21Feb13_155335|-- Bias --
21Feb13_155335|[-0.91892  0.39865]
21Feb13_155335|Layer 3:
21Feb13_155335|-- Config --
21Feb13_155335|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155335|-- Weights --
21Feb13_155335|[[-1.08106 -0.42261]
21Feb13_155335| [-0.08260 -0.34745]]
21Feb13_155335|-- Bias --
21Feb13_155335|[0.09599 0.38712]
21Feb13_155335|Predicting the validation and test data with the Best final individual.
21Feb13_155342| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_155342|-----------  ------------------  --------------------  ----------
21Feb13_155342|Validation         24.61                  18            0.71397
21Feb13_155342|   Test            25.54                  18            0.58025
21Feb13_155342|-------------------- Test #9 --------------------
21Feb13_155342|Best final individual weights
21Feb13_155342|Individual:
21Feb13_155342|-- Constant hidden layers --
21Feb13_155342|False
21Feb13_155342|Layer 0:
21Feb13_155342|-- Config --
21Feb13_155342|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155342|-- Weights --
21Feb13_155342|[[ 4.91885e-01  3.98183e-01]
21Feb13_155342| [-9.54215e-01 -1.24646e+00]
21Feb13_155342| [-1.10574e+00  9.54098e-01]
21Feb13_155342| [-7.23267e-01  5.05588e-01]
21Feb13_155342| [-2.90292e-01 -7.75831e-01]
21Feb13_155342| [ 1.72812e+00  4.07095e-01]
21Feb13_155342| [ 3.55902e-01  1.14081e+00]
21Feb13_155342| [-1.48987e+00  4.85259e-01]
21Feb13_155342| [-5.60401e-01 -3.04522e-01]
21Feb13_155342| [ 6.71669e-01  2.81967e-01]
21Feb13_155342| [-9.29584e-01 -6.42349e-02]
21Feb13_155342| [ 1.03435e+00 -9.55452e-01]
21Feb13_155342| [-1.50000e-01 -3.75330e-01]
21Feb13_155342| [ 3.06193e-01  2.95850e-01]
21Feb13_155342| [-9.42505e-01  2.13800e-01]
21Feb13_155342| [-1.30461e-01  1.64833e+00]
21Feb13_155342| [-6.15155e-01 -3.55179e-01]
21Feb13_155342| [-1.17417e-01 -1.18387e-01]
21Feb13_155342| [-4.01483e-01 -2.19326e-01]
21Feb13_155342| [-1.87883e+00  1.39386e+00]
21Feb13_155342| [ 1.89659e-01  1.45514e-01]
21Feb13_155342| [-5.92524e-01  1.65847e-04]
21Feb13_155342| [ 8.78716e-02  1.46392e+00]
21Feb13_155342| [-1.80890e-01 -2.27272e+00]
21Feb13_155342| [-1.63609e+00 -6.52740e-01]
21Feb13_155342| [ 1.00064e+00  1.46731e+00]
21Feb13_155342| [-3.00436e-01  1.28942e+00]
21Feb13_155342| [ 6.64438e-01 -1.57465e+00]
21Feb13_155342| [ 7.59207e-01 -1.12811e+00]
21Feb13_155342| [ 6.90331e-01 -5.86368e-01]
21Feb13_155342| [-1.06339e+00  4.85698e-01]
21Feb13_155342| [ 5.11252e-01 -3.04713e-01]
21Feb13_155342| [ 4.06633e-01 -9.98990e-01]
21Feb13_155342| [-2.36275e-01  1.06431e+00]
21Feb13_155342| [ 7.76257e-01  4.55359e-02]
21Feb13_155342| [-2.64892e-01 -1.02468e+00]
21Feb13_155342| [-6.04665e-01  2.56693e-02]
21Feb13_155342| [ 1.62444e+00 -6.69185e-02]
21Feb13_155342| [ 2.74037e-01 -4.26530e-01]
21Feb13_155342| [ 3.92490e-01  6.69319e-01]
21Feb13_155342| [ 7.09436e-01  5.26102e-03]
21Feb13_155342| [ 1.61981e+00 -4.23153e-01]
21Feb13_155342| [ 1.53159e+00  9.96100e-01]
21Feb13_155342| [ 1.45073e+00  8.59597e-01]
21Feb13_155342| [-8.01045e-01  1.05088e+00]
21Feb13_155342| [-3.88304e-01 -9.77505e-01]
21Feb13_155342| [ 1.16485e-01 -9.19986e-01]
21Feb13_155342| [ 3.77734e-01  2.48010e-01]
21Feb13_155342| [ 1.41200e+00  1.16799e+00]
21Feb13_155342| [ 1.74979e+00  1.13810e-01]
21Feb13_155342| [-2.67050e-01 -2.95342e-01]
21Feb13_155342| [-2.44769e-01  4.70332e-01]
21Feb13_155342| [-4.69208e-01  7.01631e-01]
21Feb13_155342| [ 2.68463e-01  1.05983e+00]
21Feb13_155342| [-1.24933e+00 -7.63457e-01]
21Feb13_155342| [ 1.72854e+00 -1.64952e+00]
21Feb13_155342| [-4.51831e-01 -1.68902e-01]]
21Feb13_155342|-- Bias --
21Feb13_155342|[0.75810 0.18412]
21Feb13_155342|Layer 1:
21Feb13_155342|-- Config --
21Feb13_155342|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155342|-- Weights --
21Feb13_155342|[[-0.15478  0.26526]
21Feb13_155342| [ 0.85540  0.19795]]
21Feb13_155342|-- Bias --
21Feb13_155342|[-0.13919  0.90108]
21Feb13_155342|Layer 2:
21Feb13_155342|-- Config --
21Feb13_155342|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155342|-- Weights --
21Feb13_155342|[[ 0.81512  0.59188]
21Feb13_155342| [-0.82418 -0.16769]]
21Feb13_155342|-- Bias --
21Feb13_155342|[-0.91892  0.39865]
21Feb13_155342|Layer 3:
21Feb13_155342|-- Config --
21Feb13_155342|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155342|-- Weights --
21Feb13_155342|[[-1.08106 -0.42261]
21Feb13_155342| [-0.08260 -0.34745]]
21Feb13_155342|-- Bias --
21Feb13_155342|[0.09599 0.38712]
21Feb13_155342|Predicting the validation and test data with the Best final individual.
21Feb13_155350| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_155350|-----------  ------------------  --------------------  ----------
21Feb13_155350|Validation         23.74                  18            0.70121
21Feb13_155350|   Test            26.67                  18            0.69904
21Feb13_155350|-------------------- Test #10 --------------------
21Feb13_155350|Best final individual weights
21Feb13_155350|Individual:
21Feb13_155350|-- Constant hidden layers --
21Feb13_155350|False
21Feb13_155350|Layer 0:
21Feb13_155350|-- Config --
21Feb13_155350|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155350|-- Weights --
21Feb13_155350|[[ 4.91885e-01  3.98183e-01]
21Feb13_155350| [-9.54215e-01 -1.24646e+00]
21Feb13_155350| [-1.10574e+00  9.54098e-01]
21Feb13_155350| [-7.23267e-01  5.05588e-01]
21Feb13_155350| [-2.90292e-01 -7.75831e-01]
21Feb13_155350| [ 1.72812e+00  4.07095e-01]
21Feb13_155350| [ 3.55902e-01  1.14081e+00]
21Feb13_155350| [-1.48987e+00  4.85259e-01]
21Feb13_155350| [-5.60401e-01 -3.04522e-01]
21Feb13_155350| [ 6.71669e-01  2.81967e-01]
21Feb13_155350| [-9.29584e-01 -6.42349e-02]
21Feb13_155350| [ 1.03435e+00 -9.55452e-01]
21Feb13_155350| [-1.50000e-01 -3.75330e-01]
21Feb13_155350| [ 3.06193e-01  2.95850e-01]
21Feb13_155350| [-9.42505e-01  2.13800e-01]
21Feb13_155350| [-1.30461e-01  1.64833e+00]
21Feb13_155350| [-6.15155e-01 -3.55179e-01]
21Feb13_155350| [-1.17417e-01 -1.18387e-01]
21Feb13_155350| [-4.01483e-01 -2.19326e-01]
21Feb13_155350| [-1.87883e+00  1.39386e+00]
21Feb13_155350| [ 1.89659e-01  1.45514e-01]
21Feb13_155350| [-5.92524e-01  1.65847e-04]
21Feb13_155350| [ 8.78716e-02  1.46392e+00]
21Feb13_155350| [-1.80890e-01 -2.27272e+00]
21Feb13_155350| [-1.63609e+00 -6.52740e-01]
21Feb13_155350| [ 1.00064e+00  1.46731e+00]
21Feb13_155350| [-3.00436e-01  1.28942e+00]
21Feb13_155350| [ 6.64438e-01 -1.57465e+00]
21Feb13_155350| [ 7.59207e-01 -1.12811e+00]
21Feb13_155350| [ 6.90331e-01 -5.86368e-01]
21Feb13_155350| [-1.06339e+00  4.85698e-01]
21Feb13_155350| [ 5.11252e-01 -3.04713e-01]
21Feb13_155350| [ 4.06633e-01 -9.98990e-01]
21Feb13_155350| [-2.36275e-01  1.06431e+00]
21Feb13_155350| [ 7.76257e-01  4.55359e-02]
21Feb13_155350| [-2.64892e-01 -1.02468e+00]
21Feb13_155350| [-6.04665e-01  2.56693e-02]
21Feb13_155350| [ 1.62444e+00 -6.69185e-02]
21Feb13_155350| [ 2.74037e-01 -4.26530e-01]
21Feb13_155350| [ 3.92490e-01  6.69319e-01]
21Feb13_155350| [ 7.09436e-01  5.26102e-03]
21Feb13_155350| [ 1.61981e+00 -4.23153e-01]
21Feb13_155350| [ 1.53159e+00  9.96100e-01]
21Feb13_155350| [ 1.45073e+00  8.59597e-01]
21Feb13_155350| [-8.01045e-01  1.05088e+00]
21Feb13_155350| [-3.88304e-01 -9.77505e-01]
21Feb13_155350| [ 1.16485e-01 -9.19986e-01]
21Feb13_155350| [ 3.77734e-01  2.48010e-01]
21Feb13_155350| [ 1.41200e+00  1.16799e+00]
21Feb13_155350| [ 1.74979e+00  1.13810e-01]
21Feb13_155350| [-2.67050e-01 -2.95342e-01]
21Feb13_155350| [-2.44769e-01  4.70332e-01]
21Feb13_155350| [-4.69208e-01  7.01631e-01]
21Feb13_155350| [ 2.68463e-01  1.05983e+00]
21Feb13_155350| [-1.24933e+00 -7.63457e-01]
21Feb13_155350| [ 1.72854e+00 -1.64952e+00]
21Feb13_155350| [-4.51831e-01 -1.68902e-01]]
21Feb13_155350|-- Bias --
21Feb13_155350|[0.75810 0.18412]
21Feb13_155350|Layer 1:
21Feb13_155350|-- Config --
21Feb13_155350|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155350|-- Weights --
21Feb13_155350|[[-0.15478  0.26526]
21Feb13_155350| [ 0.85540  0.19795]]
21Feb13_155350|-- Bias --
21Feb13_155350|[-0.13919  0.90108]
21Feb13_155350|Layer 2:
21Feb13_155350|-- Config --
21Feb13_155350|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155350|-- Weights --
21Feb13_155350|[[ 0.81512  0.59188]
21Feb13_155350| [-0.82418 -0.16769]]
21Feb13_155350|-- Bias --
21Feb13_155350|[-0.91892  0.39865]
21Feb13_155350|Layer 3:
21Feb13_155350|-- Config --
21Feb13_155350|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155350|-- Weights --
21Feb13_155350|[[-1.08106 -0.42261]
21Feb13_155350| [-0.08260 -0.34745]]
21Feb13_155350|-- Bias --
21Feb13_155350|[0.09599 0.38712]
21Feb13_155350|Predicting the validation and test data with the Best final individual.
21Feb13_155357| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_155357|-----------  ------------------  --------------------  ----------
21Feb13_155357|Validation         27.30                  18            0.59150
21Feb13_155357|   Test            24.50                  18            0.65641
21Feb13_155357|-------------------- Test #11 --------------------
21Feb13_155357|Best final individual weights
21Feb13_155357|Individual:
21Feb13_155357|-- Constant hidden layers --
21Feb13_155357|False
21Feb13_155357|Layer 0:
21Feb13_155357|-- Config --
21Feb13_155357|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155357|-- Weights --
21Feb13_155357|[[ 4.91885e-01  3.98183e-01]
21Feb13_155357| [-9.54215e-01 -1.24646e+00]
21Feb13_155357| [-1.10574e+00  9.54098e-01]
21Feb13_155357| [-7.23267e-01  5.05588e-01]
21Feb13_155357| [-2.90292e-01 -7.75831e-01]
21Feb13_155357| [ 1.72812e+00  4.07095e-01]
21Feb13_155357| [ 3.55902e-01  1.14081e+00]
21Feb13_155357| [-1.48987e+00  4.85259e-01]
21Feb13_155357| [-5.60401e-01 -3.04522e-01]
21Feb13_155357| [ 6.71669e-01  2.81967e-01]
21Feb13_155357| [-9.29584e-01 -6.42349e-02]
21Feb13_155357| [ 1.03435e+00 -9.55452e-01]
21Feb13_155357| [-1.50000e-01 -3.75330e-01]
21Feb13_155357| [ 3.06193e-01  2.95850e-01]
21Feb13_155357| [-9.42505e-01  2.13800e-01]
21Feb13_155357| [-1.30461e-01  1.64833e+00]
21Feb13_155357| [-6.15155e-01 -3.55179e-01]
21Feb13_155357| [-1.17417e-01 -1.18387e-01]
21Feb13_155357| [-4.01483e-01 -2.19326e-01]
21Feb13_155357| [-1.87883e+00  1.39386e+00]
21Feb13_155357| [ 1.89659e-01  1.45514e-01]
21Feb13_155357| [-5.92524e-01  1.65847e-04]
21Feb13_155357| [ 8.78716e-02  1.46392e+00]
21Feb13_155357| [-1.80890e-01 -2.27272e+00]
21Feb13_155357| [-1.63609e+00 -6.52740e-01]
21Feb13_155357| [ 1.00064e+00  1.46731e+00]
21Feb13_155357| [-3.00436e-01  1.28942e+00]
21Feb13_155357| [ 6.64438e-01 -1.57465e+00]
21Feb13_155357| [ 7.59207e-01 -1.12811e+00]
21Feb13_155357| [ 6.90331e-01 -5.86368e-01]
21Feb13_155357| [-1.06339e+00  4.85698e-01]
21Feb13_155357| [ 5.11252e-01 -3.04713e-01]
21Feb13_155357| [ 4.06633e-01 -9.98990e-01]
21Feb13_155357| [-2.36275e-01  1.06431e+00]
21Feb13_155357| [ 7.76257e-01  4.55359e-02]
21Feb13_155357| [-2.64892e-01 -1.02468e+00]
21Feb13_155357| [-6.04665e-01  2.56693e-02]
21Feb13_155357| [ 1.62444e+00 -6.69185e-02]
21Feb13_155357| [ 2.74037e-01 -4.26530e-01]
21Feb13_155357| [ 3.92490e-01  6.69319e-01]
21Feb13_155357| [ 7.09436e-01  5.26102e-03]
21Feb13_155357| [ 1.61981e+00 -4.23153e-01]
21Feb13_155357| [ 1.53159e+00  9.96100e-01]
21Feb13_155357| [ 1.45073e+00  8.59597e-01]
21Feb13_155357| [-8.01045e-01  1.05088e+00]
21Feb13_155357| [-3.88304e-01 -9.77505e-01]
21Feb13_155357| [ 1.16485e-01 -9.19986e-01]
21Feb13_155357| [ 3.77734e-01  2.48010e-01]
21Feb13_155357| [ 1.41200e+00  1.16799e+00]
21Feb13_155357| [ 1.74979e+00  1.13810e-01]
21Feb13_155357| [-2.67050e-01 -2.95342e-01]
21Feb13_155357| [-2.44769e-01  4.70332e-01]
21Feb13_155357| [-4.69208e-01  7.01631e-01]
21Feb13_155357| [ 2.68463e-01  1.05983e+00]
21Feb13_155357| [-1.24933e+00 -7.63457e-01]
21Feb13_155357| [ 1.72854e+00 -1.64952e+00]
21Feb13_155357| [-4.51831e-01 -1.68902e-01]]
21Feb13_155357|-- Bias --
21Feb13_155357|[0.75810 0.18412]
21Feb13_155357|Layer 1:
21Feb13_155357|-- Config --
21Feb13_155357|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155357|-- Weights --
21Feb13_155357|[[-0.15478  0.26526]
21Feb13_155357| [ 0.85540  0.19795]]
21Feb13_155357|-- Bias --
21Feb13_155357|[-0.13919  0.90108]
21Feb13_155357|Layer 2:
21Feb13_155357|-- Config --
21Feb13_155357|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155357|-- Weights --
21Feb13_155357|[[ 0.81512  0.59188]
21Feb13_155357| [-0.82418 -0.16769]]
21Feb13_155357|-- Bias --
21Feb13_155357|[-0.91892  0.39865]
21Feb13_155357|Layer 3:
21Feb13_155357|-- Config --
21Feb13_155357|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155357|-- Weights --
21Feb13_155357|[[-1.08106 -0.42261]
21Feb13_155357| [-0.08260 -0.34745]]
21Feb13_155357|-- Bias --
21Feb13_155357|[0.09599 0.38712]
21Feb13_155357|Predicting the validation and test data with the Best final individual.
21Feb13_155405| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_155405|-----------  ------------------  --------------------  ----------
21Feb13_155405|Validation         24.52                  18            0.73144
21Feb13_155405|   Test            26.76                  18            0.71583
21Feb13_155405|-------------------- Test #12 --------------------
21Feb13_155405|Best final individual weights
21Feb13_155405|Individual:
21Feb13_155405|-- Constant hidden layers --
21Feb13_155405|False
21Feb13_155405|Layer 0:
21Feb13_155405|-- Config --
21Feb13_155405|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155405|-- Weights --
21Feb13_155405|[[ 4.91885e-01  3.98183e-01]
21Feb13_155405| [-9.54215e-01 -1.24646e+00]
21Feb13_155405| [-1.10574e+00  9.54098e-01]
21Feb13_155405| [-7.23267e-01  5.05588e-01]
21Feb13_155405| [-2.90292e-01 -7.75831e-01]
21Feb13_155405| [ 1.72812e+00  4.07095e-01]
21Feb13_155405| [ 3.55902e-01  1.14081e+00]
21Feb13_155405| [-1.48987e+00  4.85259e-01]
21Feb13_155405| [-5.60401e-01 -3.04522e-01]
21Feb13_155405| [ 6.71669e-01  2.81967e-01]
21Feb13_155405| [-9.29584e-01 -6.42349e-02]
21Feb13_155405| [ 1.03435e+00 -9.55452e-01]
21Feb13_155405| [-1.50000e-01 -3.75330e-01]
21Feb13_155405| [ 3.06193e-01  2.95850e-01]
21Feb13_155405| [-9.42505e-01  2.13800e-01]
21Feb13_155405| [-1.30461e-01  1.64833e+00]
21Feb13_155405| [-6.15155e-01 -3.55179e-01]
21Feb13_155405| [-1.17417e-01 -1.18387e-01]
21Feb13_155405| [-4.01483e-01 -2.19326e-01]
21Feb13_155405| [-1.87883e+00  1.39386e+00]
21Feb13_155405| [ 1.89659e-01  1.45514e-01]
21Feb13_155405| [-5.92524e-01  1.65847e-04]
21Feb13_155405| [ 8.78716e-02  1.46392e+00]
21Feb13_155405| [-1.80890e-01 -2.27272e+00]
21Feb13_155405| [-1.63609e+00 -6.52740e-01]
21Feb13_155405| [ 1.00064e+00  1.46731e+00]
21Feb13_155405| [-3.00436e-01  1.28942e+00]
21Feb13_155405| [ 6.64438e-01 -1.57465e+00]
21Feb13_155405| [ 7.59207e-01 -1.12811e+00]
21Feb13_155405| [ 6.90331e-01 -5.86368e-01]
21Feb13_155405| [-1.06339e+00  4.85698e-01]
21Feb13_155405| [ 5.11252e-01 -3.04713e-01]
21Feb13_155405| [ 4.06633e-01 -9.98990e-01]
21Feb13_155405| [-2.36275e-01  1.06431e+00]
21Feb13_155405| [ 7.76257e-01  4.55359e-02]
21Feb13_155405| [-2.64892e-01 -1.02468e+00]
21Feb13_155405| [-6.04665e-01  2.56693e-02]
21Feb13_155405| [ 1.62444e+00 -6.69185e-02]
21Feb13_155405| [ 2.74037e-01 -4.26530e-01]
21Feb13_155405| [ 3.92490e-01  6.69319e-01]
21Feb13_155405| [ 7.09436e-01  5.26102e-03]
21Feb13_155405| [ 1.61981e+00 -4.23153e-01]
21Feb13_155405| [ 1.53159e+00  9.96100e-01]
21Feb13_155405| [ 1.45073e+00  8.59597e-01]
21Feb13_155405| [-8.01045e-01  1.05088e+00]
21Feb13_155405| [-3.88304e-01 -9.77505e-01]
21Feb13_155405| [ 1.16485e-01 -9.19986e-01]
21Feb13_155405| [ 3.77734e-01  2.48010e-01]
21Feb13_155405| [ 1.41200e+00  1.16799e+00]
21Feb13_155405| [ 1.74979e+00  1.13810e-01]
21Feb13_155405| [-2.67050e-01 -2.95342e-01]
21Feb13_155405| [-2.44769e-01  4.70332e-01]
21Feb13_155405| [-4.69208e-01  7.01631e-01]
21Feb13_155405| [ 2.68463e-01  1.05983e+00]
21Feb13_155405| [-1.24933e+00 -7.63457e-01]
21Feb13_155405| [ 1.72854e+00 -1.64952e+00]
21Feb13_155405| [-4.51831e-01 -1.68902e-01]]
21Feb13_155405|-- Bias --
21Feb13_155405|[0.75810 0.18412]
21Feb13_155405|Layer 1:
21Feb13_155405|-- Config --
21Feb13_155405|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155405|-- Weights --
21Feb13_155405|[[-0.15478  0.26526]
21Feb13_155405| [ 0.85540  0.19795]]
21Feb13_155405|-- Bias --
21Feb13_155405|[-0.13919  0.90108]
21Feb13_155405|Layer 2:
21Feb13_155405|-- Config --
21Feb13_155405|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155405|-- Weights --
21Feb13_155405|[[ 0.81512  0.59188]
21Feb13_155405| [-0.82418 -0.16769]]
21Feb13_155405|-- Bias --
21Feb13_155405|[-0.91892  0.39865]
21Feb13_155405|Layer 3:
21Feb13_155405|-- Config --
21Feb13_155405|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155405|-- Weights --
21Feb13_155405|[[-1.08106 -0.42261]
21Feb13_155405| [-0.08260 -0.34745]]
21Feb13_155405|-- Bias --
21Feb13_155405|[0.09599 0.38712]
21Feb13_155405|Predicting the validation and test data with the Best final individual.
21Feb13_155413| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_155413|-----------  ------------------  --------------------  ----------
21Feb13_155413|Validation         26.35                  18            0.73244
21Feb13_155413|   Test            28.06                  18            0.75606
21Feb13_155413|-------------------- Test #13 --------------------
21Feb13_155413|Best final individual weights
21Feb13_155413|Individual:
21Feb13_155413|-- Constant hidden layers --
21Feb13_155413|False
21Feb13_155413|Layer 0:
21Feb13_155413|-- Config --
21Feb13_155413|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155413|-- Weights --
21Feb13_155413|[[ 4.91885e-01  3.98183e-01]
21Feb13_155413| [-9.54215e-01 -1.24646e+00]
21Feb13_155413| [-1.10574e+00  9.54098e-01]
21Feb13_155413| [-7.23267e-01  5.05588e-01]
21Feb13_155413| [-2.90292e-01 -7.75831e-01]
21Feb13_155413| [ 1.72812e+00  4.07095e-01]
21Feb13_155413| [ 3.55902e-01  1.14081e+00]
21Feb13_155413| [-1.48987e+00  4.85259e-01]
21Feb13_155413| [-5.60401e-01 -3.04522e-01]
21Feb13_155413| [ 6.71669e-01  2.81967e-01]
21Feb13_155413| [-9.29584e-01 -6.42349e-02]
21Feb13_155413| [ 1.03435e+00 -9.55452e-01]
21Feb13_155413| [-1.50000e-01 -3.75330e-01]
21Feb13_155413| [ 3.06193e-01  2.95850e-01]
21Feb13_155413| [-9.42505e-01  2.13800e-01]
21Feb13_155413| [-1.30461e-01  1.64833e+00]
21Feb13_155413| [-6.15155e-01 -3.55179e-01]
21Feb13_155413| [-1.17417e-01 -1.18387e-01]
21Feb13_155413| [-4.01483e-01 -2.19326e-01]
21Feb13_155413| [-1.87883e+00  1.39386e+00]
21Feb13_155413| [ 1.89659e-01  1.45514e-01]
21Feb13_155413| [-5.92524e-01  1.65847e-04]
21Feb13_155413| [ 8.78716e-02  1.46392e+00]
21Feb13_155413| [-1.80890e-01 -2.27272e+00]
21Feb13_155413| [-1.63609e+00 -6.52740e-01]
21Feb13_155413| [ 1.00064e+00  1.46731e+00]
21Feb13_155413| [-3.00436e-01  1.28942e+00]
21Feb13_155413| [ 6.64438e-01 -1.57465e+00]
21Feb13_155413| [ 7.59207e-01 -1.12811e+00]
21Feb13_155413| [ 6.90331e-01 -5.86368e-01]
21Feb13_155413| [-1.06339e+00  4.85698e-01]
21Feb13_155413| [ 5.11252e-01 -3.04713e-01]
21Feb13_155413| [ 4.06633e-01 -9.98990e-01]
21Feb13_155413| [-2.36275e-01  1.06431e+00]
21Feb13_155413| [ 7.76257e-01  4.55359e-02]
21Feb13_155413| [-2.64892e-01 -1.02468e+00]
21Feb13_155413| [-6.04665e-01  2.56693e-02]
21Feb13_155413| [ 1.62444e+00 -6.69185e-02]
21Feb13_155413| [ 2.74037e-01 -4.26530e-01]
21Feb13_155413| [ 3.92490e-01  6.69319e-01]
21Feb13_155413| [ 7.09436e-01  5.26102e-03]
21Feb13_155413| [ 1.61981e+00 -4.23153e-01]
21Feb13_155413| [ 1.53159e+00  9.96100e-01]
21Feb13_155413| [ 1.45073e+00  8.59597e-01]
21Feb13_155413| [-8.01045e-01  1.05088e+00]
21Feb13_155413| [-3.88304e-01 -9.77505e-01]
21Feb13_155413| [ 1.16485e-01 -9.19986e-01]
21Feb13_155413| [ 3.77734e-01  2.48010e-01]
21Feb13_155413| [ 1.41200e+00  1.16799e+00]
21Feb13_155413| [ 1.74979e+00  1.13810e-01]
21Feb13_155413| [-2.67050e-01 -2.95342e-01]
21Feb13_155413| [-2.44769e-01  4.70332e-01]
21Feb13_155413| [-4.69208e-01  7.01631e-01]
21Feb13_155413| [ 2.68463e-01  1.05983e+00]
21Feb13_155413| [-1.24933e+00 -7.63457e-01]
21Feb13_155413| [ 1.72854e+00 -1.64952e+00]
21Feb13_155413| [-4.51831e-01 -1.68902e-01]]
21Feb13_155413|-- Bias --
21Feb13_155413|[0.75810 0.18412]
21Feb13_155413|Layer 1:
21Feb13_155413|-- Config --
21Feb13_155413|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155413|-- Weights --
21Feb13_155413|[[-0.15478  0.26526]
21Feb13_155413| [ 0.85540  0.19795]]
21Feb13_155413|-- Bias --
21Feb13_155413|[-0.13919  0.90108]
21Feb13_155413|Layer 2:
21Feb13_155413|-- Config --
21Feb13_155413|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155413|-- Weights --
21Feb13_155413|[[ 0.81512  0.59188]
21Feb13_155413| [-0.82418 -0.16769]]
21Feb13_155413|-- Bias --
21Feb13_155413|[-0.91892  0.39865]
21Feb13_155413|Layer 3:
21Feb13_155413|-- Config --
21Feb13_155413|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155413|-- Weights --
21Feb13_155413|[[-1.08106 -0.42261]
21Feb13_155413| [-0.08260 -0.34745]]
21Feb13_155413|-- Bias --
21Feb13_155413|[0.09599 0.38712]
21Feb13_155413|Predicting the validation and test data with the Best final individual.
21Feb13_155420| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_155420|-----------  ------------------  --------------------  ----------
21Feb13_155420|Validation         23.83                  18            0.68632
21Feb13_155420|   Test            26.59                  18            0.72411
21Feb13_155420|-------------------- Test #14 --------------------
21Feb13_155420|Best final individual weights
21Feb13_155420|Individual:
21Feb13_155420|-- Constant hidden layers --
21Feb13_155420|False
21Feb13_155420|Layer 0:
21Feb13_155420|-- Config --
21Feb13_155420|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155420|-- Weights --
21Feb13_155420|[[ 4.91885e-01  3.98183e-01]
21Feb13_155420| [-9.54215e-01 -1.24646e+00]
21Feb13_155420| [-1.10574e+00  9.54098e-01]
21Feb13_155420| [-7.23267e-01  5.05588e-01]
21Feb13_155420| [-2.90292e-01 -7.75831e-01]
21Feb13_155420| [ 1.72812e+00  4.07095e-01]
21Feb13_155420| [ 3.55902e-01  1.14081e+00]
21Feb13_155420| [-1.48987e+00  4.85259e-01]
21Feb13_155420| [-5.60401e-01 -3.04522e-01]
21Feb13_155420| [ 6.71669e-01  2.81967e-01]
21Feb13_155420| [-9.29584e-01 -6.42349e-02]
21Feb13_155420| [ 1.03435e+00 -9.55452e-01]
21Feb13_155420| [-1.50000e-01 -3.75330e-01]
21Feb13_155420| [ 3.06193e-01  2.95850e-01]
21Feb13_155420| [-9.42505e-01  2.13800e-01]
21Feb13_155420| [-1.30461e-01  1.64833e+00]
21Feb13_155420| [-6.15155e-01 -3.55179e-01]
21Feb13_155420| [-1.17417e-01 -1.18387e-01]
21Feb13_155420| [-4.01483e-01 -2.19326e-01]
21Feb13_155420| [-1.87883e+00  1.39386e+00]
21Feb13_155420| [ 1.89659e-01  1.45514e-01]
21Feb13_155420| [-5.92524e-01  1.65847e-04]
21Feb13_155420| [ 8.78716e-02  1.46392e+00]
21Feb13_155420| [-1.80890e-01 -2.27272e+00]
21Feb13_155420| [-1.63609e+00 -6.52740e-01]
21Feb13_155420| [ 1.00064e+00  1.46731e+00]
21Feb13_155420| [-3.00436e-01  1.28942e+00]
21Feb13_155420| [ 6.64438e-01 -1.57465e+00]
21Feb13_155420| [ 7.59207e-01 -1.12811e+00]
21Feb13_155420| [ 6.90331e-01 -5.86368e-01]
21Feb13_155420| [-1.06339e+00  4.85698e-01]
21Feb13_155420| [ 5.11252e-01 -3.04713e-01]
21Feb13_155420| [ 4.06633e-01 -9.98990e-01]
21Feb13_155420| [-2.36275e-01  1.06431e+00]
21Feb13_155420| [ 7.76257e-01  4.55359e-02]
21Feb13_155420| [-2.64892e-01 -1.02468e+00]
21Feb13_155420| [-6.04665e-01  2.56693e-02]
21Feb13_155420| [ 1.62444e+00 -6.69185e-02]
21Feb13_155420| [ 2.74037e-01 -4.26530e-01]
21Feb13_155420| [ 3.92490e-01  6.69319e-01]
21Feb13_155420| [ 7.09436e-01  5.26102e-03]
21Feb13_155420| [ 1.61981e+00 -4.23153e-01]
21Feb13_155420| [ 1.53159e+00  9.96100e-01]
21Feb13_155420| [ 1.45073e+00  8.59597e-01]
21Feb13_155420| [-8.01045e-01  1.05088e+00]
21Feb13_155420| [-3.88304e-01 -9.77505e-01]
21Feb13_155420| [ 1.16485e-01 -9.19986e-01]
21Feb13_155420| [ 3.77734e-01  2.48010e-01]
21Feb13_155420| [ 1.41200e+00  1.16799e+00]
21Feb13_155420| [ 1.74979e+00  1.13810e-01]
21Feb13_155420| [-2.67050e-01 -2.95342e-01]
21Feb13_155420| [-2.44769e-01  4.70332e-01]
21Feb13_155420| [-4.69208e-01  7.01631e-01]
21Feb13_155420| [ 2.68463e-01  1.05983e+00]
21Feb13_155420| [-1.24933e+00 -7.63457e-01]
21Feb13_155420| [ 1.72854e+00 -1.64952e+00]
21Feb13_155420| [-4.51831e-01 -1.68902e-01]]
21Feb13_155420|-- Bias --
21Feb13_155420|[0.75810 0.18412]
21Feb13_155420|Layer 1:
21Feb13_155420|-- Config --
21Feb13_155420|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155420|-- Weights --
21Feb13_155420|[[-0.15478  0.26526]
21Feb13_155420| [ 0.85540  0.19795]]
21Feb13_155420|-- Bias --
21Feb13_155420|[-0.13919  0.90108]
21Feb13_155420|Layer 2:
21Feb13_155420|-- Config --
21Feb13_155420|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155420|-- Weights --
21Feb13_155420|[[ 0.81512  0.59188]
21Feb13_155420| [-0.82418 -0.16769]]
21Feb13_155420|-- Bias --
21Feb13_155420|[-0.91892  0.39865]
21Feb13_155420|Layer 3:
21Feb13_155420|-- Config --
21Feb13_155420|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_155420|-- Weights --
21Feb13_155420|[[-1.08106 -0.42261]
21Feb13_155420| [-0.08260 -0.34745]]
21Feb13_155420|-- Bias --
21Feb13_155420|[0.09599 0.38712]
21Feb13_155420|Predicting the validation and test data with the Best final individual.
21Feb13_155428| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_155428|-----------  ------------------  --------------------  ----------
21Feb13_155428|Validation         23.65                  18            0.72687
21Feb13_155428|   Test            27.45                  18            0.70255
2021-02-13 15:54:29.008983: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
21Feb13_155429|Data summary: Train
21Feb13_155429|data.shape = (2300, 57)
21Feb13_155429|labels.shape = (2300,)
21Feb13_155429|Class distribution:
21Feb13_155429|	0 - 1382 (0.60)
21Feb13_155429|	1 - 918 (0.40)
21Feb13_155429|Data summary: Validation
21Feb13_155429|data.shape = (1150, 57)
21Feb13_155429|labels.shape = (1150,)
21Feb13_155429|Class distribution:
21Feb13_155429|	0 - 704 (0.61)
21Feb13_155429|	1 - 446 (0.39)
21Feb13_155429|Data summary: Test
21Feb13_155429|data.shape = (1151, 57)
21Feb13_155429|labels.shape = (1151,)
21Feb13_155429|Class distribution:
21Feb13_155429|	0 - 702 (0.61)
21Feb13_155429|	1 - 449 (0.39)
21Feb13_155429|Selected configuration values
21Feb13_155429|-- Dataset name: spambase1
21Feb13_155429|-- Initial population size: 64
21Feb13_155429|-- Maximun number of generations: 32
21Feb13_155429|-- Neurons per hidden layer range: (2, 20)
21Feb13_155429|-- Hidden layers number range: (1, 3)
21Feb13_155429|-- Crossover probability: 0.5
21Feb13_155429|-- Bias gene mutation probability: 0.2
21Feb13_155429|-- Weights gene mutation probability: 0.75
21Feb13_155429|-- Neuron mutation probability: 0.3
21Feb13_155429|-- Layer mutation probability: 0.3
21Feb13_155429|-- Constant hidden layers: False
21Feb13_155429|-- Seed: 31415
21Feb13_155429|Entering GA
21Feb13_155429|Start the algorithm
2021-02-13 15:54:29.845211: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-13 15:54:29.845748: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-02-13 15:54:29.867012: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-13 15:54:29.867335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.71GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s
2021-02-13 15:54:29.867349: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-02-13 15:54:29.868784: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-02-13 15:54:29.868811: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-02-13 15:54:29.869310: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-02-13 15:54:29.869439: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-02-13 15:54:29.869509: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-13 15:54:29.869917: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-02-13 15:54:29.869958: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-13 15:54:29.869964: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-02-13 15:54:29.870165: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-02-13 15:54:29.870909: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-13 15:54:29.870923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-13 15:54:29.870934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      
2021-02-13 15:54:29.915798: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-02-13 15:54:29.916131: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3493635000 Hz
/home/jmerelo/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype("int32")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn('`model.predict_classes()` is deprecated and '
21Feb13_155829|-- Generation 1 --
21Feb13_155829|    -- Crossed 1 individual pairs.
21Feb13_155829|    -- Mutated 32 individuals.
21Feb13_160229|    -- Evaluated 64 individuals.
21Feb13_160229|    Summary of generation 1:
21Feb13_160229| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_160229|-----------  ------------------  --------------------  ----------
21Feb13_160229|    Max            39.48                216.00          0.67604
21Feb13_160229|    Avg            38.55                57.83           0.01494
21Feb13_160229|    Min            23.48                 3.00           0.00000
21Feb13_160229|    Std             2.10                50.57           0.08997
21Feb13_160229|   Best            23.48                28.00           0.67604
21Feb13_160229|-- Generation 2 --
21Feb13_160229|    -- Crossed 1 individual pairs.
21Feb13_160229|    -- Mutated 32 individuals.
21Feb13_160629|    -- Evaluated 64 individuals.
21Feb13_160629|    Summary of generation 2:
21Feb13_160629| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_160629|-----------  ------------------  --------------------  ----------
21Feb13_160629|    Max            39.30                153.00          0.25146
21Feb13_160629|    Avg            38.64                53.41           0.00691
21Feb13_160629|    Min            31.39                 3.00           0.00000
21Feb13_160629|    Std             1.18                42.49           0.03886
21Feb13_160629|   Best            31.39                24.00           0.25146
21Feb13_160629|-- Generation 3 --
21Feb13_160629|    -- Crossed 3 individual pairs.
21Feb13_160629|    -- Mutated 32 individuals.
21Feb13_161028|    -- Evaluated 64 individuals.
21Feb13_161028|    Summary of generation 3:
21Feb13_161028| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_161028|-----------  ------------------  --------------------  ----------
21Feb13_161028|    Max            39.39                100.00          0.48419
21Feb13_161028|    Avg            38.59                34.50           0.00826
21Feb13_161028|    Min            25.57                 2.00           0.00000
21Feb13_161028|    Std             1.65                26.86           0.06021
21Feb13_161028|   Best            25.57                 8.00           0.48419
21Feb13_161028|-- Generation 4 --
21Feb13_161028|    -- Crossed 3 individual pairs.
21Feb13_161028|    -- Mutated 32 individuals.
21Feb13_161418|    -- Evaluated 64 individuals.
21Feb13_161418|    Summary of generation 4:
21Feb13_161418| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_161418|-----------  ------------------  --------------------  ----------
21Feb13_161418|    Max            40.87                34.00           0.19355
21Feb13_161418|    Avg            38.76                14.61           0.00302
21Feb13_161418|    Min            32.87                 2.00           0.00000
21Feb13_161418|    Std             0.79                10.44           0.02400
21Feb13_161418|   Best            32.87                 8.00           0.19355
21Feb13_161418|-- Generation 5 --
21Feb13_161418|    -- Crossed 6 individual pairs.
21Feb13_161418|    -- Mutated 32 individuals.
21Feb13_161805|    -- Evaluated 64 individuals.
21Feb13_161805|    Summary of generation 5:
21Feb13_161805| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_161805|-----------  ------------------  --------------------  ----------
21Feb13_161805|    Max            39.48                16.00           0.77112
21Feb13_161805|    Avg            38.24                 6.53           0.02856
21Feb13_161805|    Min            23.83                 2.00           0.00000
21Feb13_161805|    Std             2.65                 4.20           0.13173
21Feb13_161805|   Best            23.83                 8.00           0.59726
21Feb13_161805|-- Generation 6 --
21Feb13_161805|    -- Crossed 8 individual pairs.
21Feb13_161806|    -- Mutated 32 individuals.
21Feb13_162151|    -- Evaluated 64 individuals.
21Feb13_162151|    Summary of generation 6:
21Feb13_162151| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_162151|-----------  ------------------  --------------------  ----------
21Feb13_162151|    Max            39.22                20.00           0.59556
21Feb13_162151|    Avg            38.35                 5.75           0.02242
21Feb13_162151|    Min            24.78                 2.00           0.00000
21Feb13_162151|    Std             2.18                 4.63           0.10495
21Feb13_162151|   Best            24.78                 8.00           0.54269
21Feb13_162151|-- Generation 7 --
21Feb13_162151|    -- Crossed 7 individual pairs.
21Feb13_162151|    -- Mutated 32 individuals.
21Feb13_162537|    -- Evaluated 64 individuals.
21Feb13_162537|    Summary of generation 7:
21Feb13_162537| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_162537|-----------  ------------------  --------------------  ----------
21Feb13_162537|    Max            40.35                16.00           0.53683
21Feb13_162537|    Avg            38.13                 4.80           0.02684
21Feb13_162537|    Min            25.48                 2.00           0.00000
21Feb13_162537|    Std             2.79                 3.93           0.10851
21Feb13_162537|   Best            25.48                 8.00           0.53683
21Feb13_162537|-- Generation 8 --
21Feb13_162537|    -- Crossed 8 individual pairs.
21Feb13_162537|    -- Mutated 32 individuals.
21Feb13_162923|    -- Evaluated 64 individuals.
21Feb13_162923|    Summary of generation 8:
21Feb13_162923| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_162923|-----------  ------------------  --------------------  ----------
21Feb13_162923|    Max            39.22                27.00           0.59757
21Feb13_162923|    Avg            38.06                 5.36           0.02813
21Feb13_162923|    Min            25.22                 2.00           0.00000
21Feb13_162923|    Std             2.94                 5.14           0.11285
21Feb13_162923|   Best            25.22                 8.00           0.47915
21Feb13_162923|-- Generation 9 --
21Feb13_162923|    -- Crossed 8 individual pairs.
21Feb13_162923|    -- Mutated 32 individuals.
21Feb13_163309|    -- Evaluated 64 individuals.
21Feb13_163309|    Summary of generation 9:
21Feb13_163309| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_163309|-----------  ------------------  --------------------  ----------
21Feb13_163309|    Max            39.57                16.00           0.58029
21Feb13_163309|    Avg            37.93                 4.52           0.03393
21Feb13_163309|    Min            24.00                 2.00           0.00000
21Feb13_163309|    Std             3.38                 3.77           0.13136
21Feb13_163309|   Best            24.00                10.00           0.53554
21Feb13_163309|-- Generation 10 --
21Feb13_163309|    -- Crossed 9 individual pairs.
21Feb13_163309|    -- Mutated 32 individuals.
21Feb13_163656|    -- Evaluated 64 individuals.
21Feb13_163656|    Summary of generation 10:
21Feb13_163656| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_163656|-----------  ------------------  --------------------  ----------
21Feb13_163656|    Max            39.22                27.00           0.56711
21Feb13_163656|    Avg            37.89                 4.66           0.03760
21Feb13_163656|    Min            25.30                 2.00           0.00000
21Feb13_163656|    Std             3.27                 4.56           0.13216
21Feb13_163656|   Best            25.30                12.00           0.48889
21Feb13_163656|-- Generation 11 --
21Feb13_163656|    -- Crossed 10 individual pairs.
21Feb13_163656|    -- Mutated 32 individuals.
21Feb13_164042|    -- Evaluated 64 individuals.
21Feb13_164042|    Summary of generation 11:
21Feb13_164042| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_164042|-----------  ------------------  --------------------  ----------
21Feb13_164042|    Max            39.30                16.00           0.58036
21Feb13_164042|    Avg            37.81                 4.83           0.04109
21Feb13_164042|    Min            25.48                 2.00           0.00000
21Feb13_164042|    Std             3.38                 4.36           0.14033
21Feb13_164042|   Best            25.48                 8.00           0.56295
21Feb13_164042|-- Generation 12 --
21Feb13_164042|    -- Crossed 5 individual pairs.
21Feb13_164042|    -- Mutated 32 individuals.
21Feb13_164429|    -- Evaluated 64 individuals.
21Feb13_164429|    Summary of generation 12:
21Feb13_164429| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_164429|-----------  ------------------  --------------------  ----------
21Feb13_164429|    Max            40.17                27.00           0.60122
21Feb13_164429|    Avg            37.52                 5.06           0.05075
21Feb13_164429|    Min            24.26                 2.00           0.00000
21Feb13_164429|    Std             3.93                 5.33           0.15508
21Feb13_164429|   Best            24.26                27.00           0.60122
21Feb13_164429|-- Generation 13 --
21Feb13_164429|    -- Crossed 7 individual pairs.
21Feb13_164429|    -- Mutated 32 individuals.
21Feb13_164817|    -- Evaluated 64 individuals.
21Feb13_164817|    Summary of generation 13:
21Feb13_164817| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_164817|-----------  ------------------  --------------------  ----------
21Feb13_164817|    Max            39.04                27.00           0.65018
21Feb13_164817|    Avg            37.26                 5.16           0.05997
21Feb13_164817|    Min            24.17                 2.00           0.00000
21Feb13_164817|    Std             4.13                 5.52           0.16363
21Feb13_164817|   Best            24.17                 8.00           0.65018
21Feb13_164817|-- Generation 14 --
21Feb13_164817|    -- Crossed 3 individual pairs.
21Feb13_164817|    -- Mutated 32 individuals.
21Feb13_165205|    -- Evaluated 64 individuals.
21Feb13_165205|    Summary of generation 14:
21Feb13_165205| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_165205|-----------  ------------------  --------------------  ----------
21Feb13_165205|    Max            39.13                30.00           0.57022
21Feb13_165205|    Avg            37.25                 6.12           0.05936
21Feb13_165205|    Min            23.39                 2.00           0.00000
21Feb13_165205|    Std             4.14                 6.64           0.15993
21Feb13_165205|   Best            23.39                 8.00           0.54501
21Feb13_165205|-- Generation 15 --
21Feb13_165205|    -- Crossed 9 individual pairs.
21Feb13_165205|    -- Mutated 32 individuals.
21Feb13_165552|    -- Evaluated 64 individuals.
21Feb13_165552|    Summary of generation 15:
21Feb13_165552| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_165552|-----------  ------------------  --------------------  ----------
21Feb13_165552|    Max            39.13                56.00           0.56223
21Feb13_165552|    Avg            37.69                 6.73           0.04296
21Feb13_165552|    Min            23.91                 2.00           0.00000
21Feb13_165552|    Std             3.78                 9.43           0.14495
21Feb13_165552|   Best            23.91                 8.00           0.56223
21Feb13_165552|-- Generation 16 --
21Feb13_165552|    -- Crossed 5 individual pairs.
21Feb13_165552|    -- Mutated 32 individuals.
21Feb13_165939|    -- Evaluated 64 individuals.
21Feb13_165939|    Summary of generation 16:
21Feb13_165939| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_165939|-----------  ------------------  --------------------  ----------
21Feb13_165939|    Max            39.13                21.00           0.62905
21Feb13_165939|    Avg            37.61                 4.97           0.04720
21Feb13_165939|    Min            24.35                 2.00           0.00000
21Feb13_165939|    Std             3.68                 5.16           0.14866
21Feb13_165939|   Best            24.35                14.00           0.62905
21Feb13_165939|-- Generation 17 --
21Feb13_165939|    -- Crossed 7 individual pairs.
21Feb13_165939|    -- Mutated 32 individuals.
21Feb13_170325|    -- Evaluated 64 individuals.
21Feb13_170325|    Summary of generation 17:
21Feb13_170325| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_170325|-----------  ------------------  --------------------  ----------
21Feb13_170325|    Max            39.83                33.00           0.54732
21Feb13_170325|    Avg            37.82                 5.34           0.03902
21Feb13_170325|    Min            25.04                 2.00           0.00000
21Feb13_170325|    Std             3.34                 6.55           0.12910
21Feb13_170325|   Best            25.04                 8.00           0.49160
21Feb13_170325|-- Generation 18 --
21Feb13_170325|    -- Crossed 4 individual pairs.
21Feb13_170325|    -- Mutated 32 individuals.
21Feb13_170711|    -- Evaluated 64 individuals.
21Feb13_170711|    Summary of generation 18:
21Feb13_170711| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_170711|-----------  ------------------  --------------------  ----------
21Feb13_170711|    Max            39.22                44.00           0.66331
21Feb13_170711|    Avg            37.25                 5.39           0.06136
21Feb13_170711|    Min            23.30                 2.00           0.00000
21Feb13_170711|    Std             4.20                 7.44           0.16604
21Feb13_170711|   Best            23.30                14.00           0.66331
21Feb13_170711|-- Generation 19 --
21Feb13_170711|    -- Crossed 7 individual pairs.
21Feb13_170711|    -- Mutated 32 individuals.
21Feb13_171100|    -- Evaluated 64 individuals.
21Feb13_171100|    Summary of generation 19:
21Feb13_171100| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_171100|-----------  ------------------  --------------------  ----------
21Feb13_171100|    Max            39.22                48.00           0.71493
21Feb13_171100|    Avg            36.67                 7.03           0.08934
21Feb13_171100|    Min            21.74                 2.00           0.00000
21Feb13_171100|    Std             4.88                 9.70           0.20448
21Feb13_171100|   Best            21.74                48.00           0.71493
21Feb13_171100|-- Generation 20 --
21Feb13_171100|    -- Crossed 3 individual pairs.
21Feb13_171100|    -- Mutated 32 individuals.
21Feb13_171450|    -- Evaluated 64 individuals.
21Feb13_171450|    Summary of generation 20:
21Feb13_171450| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_171450|-----------  ------------------  --------------------  ----------
21Feb13_171450|    Max            39.91                48.00           0.79865
21Feb13_171450|    Avg            36.67                 9.22           0.08508
21Feb13_171450|    Min            24.43                 2.00           0.00000
21Feb13_171450|    Std             4.74                12.38           0.19137
21Feb13_171450|   Best            24.43                48.00           0.79865
21Feb13_171450|-- Generation 21 --
21Feb13_171450|    -- Crossed 4 individual pairs.
21Feb13_171450|    -- Mutated 32 individuals.
21Feb13_171841|    -- Evaluated 64 individuals.
21Feb13_171841|    Summary of generation 21:
21Feb13_171841| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_171841|-----------  ------------------  --------------------  ----------
21Feb13_171841|    Max            39.13                65.00           0.62762
21Feb13_171841|    Avg            36.25                11.11           0.10582
21Feb13_171841|    Min            23.74                 2.00           0.00000
21Feb13_171841|    Std             5.11                15.00           0.21441
21Feb13_171841|   Best            23.74                48.00           0.62762
21Feb13_171841|-- Generation 22 --
21Feb13_171841|    -- Crossed 7 individual pairs.
21Feb13_171841|    -- Mutated 32 individuals.
21Feb13_172233|    -- Evaluated 64 individuals.
21Feb13_172233|    Summary of generation 22:
21Feb13_172233| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_172233|-----------  ------------------  --------------------  ----------
21Feb13_172233|    Max            39.13                85.00           0.65427
21Feb13_172233|    Avg            35.61                11.84           0.12352
21Feb13_172233|    Min            23.48                 2.00           0.00000
21Feb13_172233|    Std             5.59                14.99           0.21923
21Feb13_172233|   Best            23.48                24.00           0.65427
21Feb13_172233|-- Generation 23 --
21Feb13_172233|    -- Crossed 4 individual pairs.
21Feb13_172233|    -- Mutated 32 individuals.
21Feb13_172627|    -- Evaluated 64 individuals.
21Feb13_172627|    Summary of generation 23:
21Feb13_172627| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_172627|-----------  ------------------  --------------------  ----------
21Feb13_172627|    Max            39.22                85.00           0.78537
21Feb13_172627|    Avg            34.69                14.14           0.17565
21Feb13_172627|    Min            24.70                 2.00           0.00000
21Feb13_172627|    Std             5.82                16.17           0.25316
21Feb13_172627|   Best            24.70                24.00           0.54484
21Feb13_172627|-- Generation 24 --
21Feb13_172627|    -- Crossed 2 individual pairs.
21Feb13_172627|    -- Mutated 32 individuals.
21Feb13_173022|    -- Evaluated 64 individuals.
21Feb13_173022|    Summary of generation 24:
21Feb13_173022| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_173022|-----------  ------------------  --------------------  ----------
21Feb13_173022|    Max            44.26                75.00           0.78892
21Feb13_173022|    Avg            34.50                16.38           0.18295
21Feb13_173022|    Min            23.91                 2.00           0.00000
21Feb13_173022|    Std             6.13                16.19           0.25304
21Feb13_173022|   Best            23.91                24.00           0.66287
21Feb13_173022|-- Generation 25 --
21Feb13_173022|    -- Crossed 3 individual pairs.
21Feb13_173022|    -- Mutated 32 individuals.
21Feb13_173420|    -- Evaluated 64 individuals.
21Feb13_173420|    Summary of generation 25:
21Feb13_173420| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_173420|-----------  ------------------  --------------------  ----------
21Feb13_173420|    Max            38.96                75.00           0.58907
21Feb13_173420|    Avg            33.76                18.61           0.19391
21Feb13_173420|    Min            22.87                 2.00           0.00000
21Feb13_173420|    Std             6.36                16.18           0.24563
21Feb13_173420|   Best            22.87                10.00           0.55986
21Feb13_173420|-- Generation 26 --
21Feb13_173420|    -- Crossed 1 individual pairs.
21Feb13_173420|    -- Mutated 32 individuals.
21Feb13_173820|    -- Evaluated 64 individuals.
21Feb13_173820|    Summary of generation 26:
21Feb13_173820| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_173820|-----------  ------------------  --------------------  ----------
21Feb13_173820|    Max            39.13                85.00           0.63908
21Feb13_173820|    Avg            32.36                21.02           0.26036
21Feb13_173820|    Min            23.65                 2.00           0.00000
21Feb13_173820|    Std             6.56                18.06           0.26703
21Feb13_173820|   Best            23.65                10.00           0.53850
21Feb13_173820|-- Generation 27 --
21Feb13_173820|    -- Crossed 1 individual pairs.
21Feb13_173820|    -- Mutated 32 individuals.
21Feb13_174224|    -- Evaluated 64 individuals.
21Feb13_174224|    Summary of generation 27:
21Feb13_174224| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_174224|-----------  ------------------  --------------------  ----------
21Feb13_174224|    Max            39.13                120.00          0.62237
21Feb13_174224|    Avg            30.98                26.95           0.30678
21Feb13_174224|    Min            22.96                 2.00           0.00000
21Feb13_174224|    Std             6.47                21.67           0.25554
21Feb13_174224|   Best            22.96                 8.00           0.57267
21Feb13_174224|-- Generation 28 --
21Feb13_174224|    -- Crossed 1 individual pairs.
21Feb13_174224|    -- Mutated 32 individuals.
21Feb13_174627|    -- Evaluated 64 individuals.
21Feb13_174627|    Summary of generation 28:
21Feb13_174627| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_174627|-----------  ------------------  --------------------  ----------
21Feb13_174627|    Max            39.13                80.00           0.80692
21Feb13_174627|    Avg            30.70                26.70           0.33289
21Feb13_174627|    Min            23.83                 2.00           0.00000
21Feb13_174627|    Std             6.19                18.17           0.26566
21Feb13_174627|   Best            23.83                44.00           0.55314
21Feb13_174627|-- Generation 29 --
21Feb13_174627|    -- Crossed 0 individual pairs.
21Feb13_174627|    -- Mutated 32 individuals.
21Feb13_175033|    -- Evaluated 64 individuals.
21Feb13_175033|    Summary of generation 29:
21Feb13_175033| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_175033|-----------  ------------------  --------------------  ----------
21Feb13_175033|    Max            51.74                108.00          0.81693
21Feb13_175033|    Avg            31.99                31.75           0.30288
21Feb13_175033|    Min            23.39                 2.00           0.00000
21Feb13_175033|    Std             6.75                20.63           0.27583
21Feb13_175033|   Best            23.39                40.00           0.81693
21Feb13_175033|-- Generation 30 --
21Feb13_175033|    -- Crossed 0 individual pairs.
21Feb13_175033|    -- Mutated 32 individuals.
21Feb13_175438|    -- Evaluated 64 individuals.
21Feb13_175438|    Summary of generation 30:
21Feb13_175438| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_175438|-----------  ------------------  --------------------  ----------
21Feb13_175438|    Max            39.39                85.00           0.78285
21Feb13_175438|    Avg            30.39                29.23           0.34302
21Feb13_175438|    Min            22.09                 2.00           0.00000
21Feb13_175438|    Std             6.27                20.40           0.26180
21Feb13_175438|   Best            22.09                65.00           0.75744
21Feb13_175438|-- Generation 31 --
21Feb13_175438|    -- Crossed 0 individual pairs.
21Feb13_175438|    -- Mutated 32 individuals.
21Feb13_175843|    -- Evaluated 64 individuals.
21Feb13_175843|    Summary of generation 31:
21Feb13_175843| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_175843|-----------  ------------------  --------------------  ----------
21Feb13_175843|    Max            39.30                75.00           0.75577
21Feb13_175843|    Avg            31.13                29.64           0.32765
21Feb13_175843|    Min            23.04                 2.00           0.00000
21Feb13_175843|    Std             6.40                19.68           0.27224
21Feb13_175843|   Best            23.04                44.00           0.54798
21Feb13_175843|-- Generation 32 --
21Feb13_175843|    -- Crossed 1 individual pairs.
21Feb13_175843|    -- Mutated 32 individuals.
21Feb13_180250|    -- Evaluated 64 individuals.
21Feb13_180250|    Summary of generation 32:
21Feb13_180250| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_180250|-----------  ------------------  --------------------  ----------
21Feb13_180250|    Max            39.30                80.00           0.79923
21Feb13_180250|    Avg            31.22                32.83           0.30037
21Feb13_180250|    Min            22.35                 2.00           0.00000
21Feb13_180250|    Std             6.39                20.23           0.26074
21Feb13_180250|   Best            22.35                40.00           0.77605
21Feb13_180250|Best initial individual weights
21Feb13_180250|Individual:
21Feb13_180250|-- Constant hidden layers --
21Feb13_180250|False
21Feb13_180250|Layer 0:
21Feb13_180250|-- Config --
21Feb13_180250|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 20, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180250|-- Weights --
21Feb13_180250|[[-0.81530 -0.38125 -0.79998 ... -0.70263 -0.61840  0.66571]
21Feb13_180250| [ 0.65866  0.85470 -0.58802 ... -0.96520  0.62924 -0.99993]
21Feb13_180250| [ 0.82861 -0.31058 -0.15077 ... -0.37206  0.28605  0.29356]
21Feb13_180250| ...
21Feb13_180250| [-0.22356 -0.17240 -0.31428 ... -0.22545  0.94699 -0.71943]
21Feb13_180250| [-0.37773 -0.75933 -0.69490 ... -0.90595 -0.69780 -0.98315]
21Feb13_180250| [ 0.65818 -0.25813 -0.28240 ...  0.35891  0.55911  0.45607]]
21Feb13_180250|-- Bias --
21Feb13_180250|[-0.66607 -0.45412 -0.47565  0.95426  0.37266  0.71643 -0.83233 -0.59141
21Feb13_180250| -0.57925 -0.35895  0.07388  0.17038  0.31672  0.81171  0.30057  0.54611
21Feb13_180250| -0.62651  0.24482  0.64224 -0.28752]
21Feb13_180250|Layer 1:
21Feb13_180250|-- Config --
21Feb13_180250|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 20], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180250|-- Weights --
21Feb13_180250|[[ 0.42040 -0.26492]
21Feb13_180250| [ 0.78679  0.01829]
21Feb13_180250| [ 0.85426  0.35026]
21Feb13_180250| [ 0.63200 -0.62249]
21Feb13_180250| [-0.55346 -0.80586]
21Feb13_180250| [-0.61224  0.86991]
21Feb13_180250| [-0.47486 -0.31648]
21Feb13_180250| [ 0.53818 -0.22812]
21Feb13_180250| [-0.74035 -0.70516]
21Feb13_180250| [-0.47742 -0.04703]
21Feb13_180250| [ 0.68440 -0.93557]
21Feb13_180250| [-0.18841 -0.56741]
21Feb13_180250| [-0.08233  0.51743]
21Feb13_180250| [ 0.43051 -0.46386]
21Feb13_180250| [ 0.67964  0.15665]
21Feb13_180250| [-0.10319 -0.36290]
21Feb13_180250| [-0.23955  0.64790]
21Feb13_180250| [-0.84563 -0.92413]
21Feb13_180250| [ 0.53642 -0.52099]
21Feb13_180250| [ 0.03906 -0.94604]]
21Feb13_180250|-- Bias --
21Feb13_180250|[ 0.50157 -0.93861]
21Feb13_180250|Predicting the validation and test data with the Best initial individual.
21Feb13_180257| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_180257|-----------  ------------------  --------------------  ----------
21Feb13_180257|Validation         39.22                  20            0.00000
21Feb13_180257|   Test            38.75                  20            0.01110
21Feb13_180257|-------------------- Test #0 --------------------
21Feb13_180257|Best final individual weights
21Feb13_180257|Individual:
21Feb13_180257|-- Constant hidden layers --
21Feb13_180257|False
21Feb13_180257|Layer 0:
21Feb13_180257|-- Config --
21Feb13_180257|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180257|-- Weights --
21Feb13_180257|[[-0.52757  0.21411]
21Feb13_180257| [-0.93911 -1.17137]
21Feb13_180257| [-0.61957 -0.66375]
21Feb13_180257| [-0.51664 -2.09212]
21Feb13_180257| [ 1.08829 -0.13413]
21Feb13_180257| [-0.25816  0.27802]
21Feb13_180257| [ 0.66354 -0.52361]
21Feb13_180257| [ 1.01133 -0.15515]
21Feb13_180257| [ 0.01483 -0.14014]
21Feb13_180257| [ 0.22676 -0.27499]
21Feb13_180257| [ 0.43593 -2.14033]
21Feb13_180257| [-0.26769 -0.28757]
21Feb13_180257| [ 0.28306  0.42430]
21Feb13_180257| [-1.86751  0.58942]
21Feb13_180257| [ 0.03955 -0.29203]
21Feb13_180257| [ 0.53856 -1.32664]
21Feb13_180257| [-1.26262  0.12423]
21Feb13_180257| [-0.95736 -0.39002]
21Feb13_180257| [ 0.31148  0.81849]
21Feb13_180257| [-1.20171 -1.16573]
21Feb13_180257| [-0.43995  0.46443]
21Feb13_180257| [ 0.17542 -0.95269]
21Feb13_180257| [ 0.05423  2.54728]
21Feb13_180257| [-0.41660 -0.62510]
21Feb13_180257| [ 0.48650 -0.12177]
21Feb13_180257| [-0.41604 -0.08118]
21Feb13_180257| [-0.16116  0.68089]
21Feb13_180257| [ 0.58706 -1.30828]
21Feb13_180257| [-0.96782  1.51900]
21Feb13_180257| [ 0.08874 -0.67677]
21Feb13_180257| [-0.68590 -1.49289]
21Feb13_180257| [ 1.08065  2.07463]
21Feb13_180257| [-1.05417  0.71235]
21Feb13_180257| [-0.05213 -0.58554]
21Feb13_180257| [-0.12627 -0.31128]
21Feb13_180257| [ 1.34093 -0.18664]
21Feb13_180257| [-1.30497 -0.40435]
21Feb13_180257| [ 0.68676  0.75508]
21Feb13_180257| [-1.59599 -0.71000]
21Feb13_180257| [ 0.79255  0.47768]
21Feb13_180257| [-0.63359 -0.83681]
21Feb13_180257| [-0.54831  0.03451]
21Feb13_180257| [-0.08075  1.16147]
21Feb13_180257| [ 0.82149 -0.24838]
21Feb13_180257| [-0.83911  0.36663]
21Feb13_180257| [-0.40125 -0.23944]
21Feb13_180257| [-1.82054 -0.17440]
21Feb13_180257| [-0.99986  1.60933]
21Feb13_180257| [-1.83158 -2.24240]
21Feb13_180257| [ 0.04873 -1.02073]
21Feb13_180257| [-0.56204 -0.67282]
21Feb13_180257| [-1.61599  0.79008]
21Feb13_180257| [-1.88676  1.24359]
21Feb13_180257| [ 0.28231  0.49092]
21Feb13_180257| [ 1.80131 -0.95736]
21Feb13_180257| [ 1.10036  0.20309]
21Feb13_180257| [ 0.63629 -0.89126]]
21Feb13_180257|-- Bias --
21Feb13_180257|[ 0.05179 -0.09215]
21Feb13_180257|Layer 1:
21Feb13_180257|-- Config --
21Feb13_180257|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180257|-- Weights --
21Feb13_180257|[[ 0.76236  0.77919 -0.54170]
21Feb13_180257| [ 0.72178 -1.22032 -0.56733]]
21Feb13_180257|-- Bias --
21Feb13_180257|[-0.62552  0.86248 -0.09337]
21Feb13_180257|Layer 2:
21Feb13_180257|-- Config --
21Feb13_180257|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180257|-- Weights --
21Feb13_180257|[[ 0.17631  1.22903  0.28211]
21Feb13_180257| [ 0.23756 -0.52210  0.80113]
21Feb13_180257| [-0.53643 -0.29098  0.14483]]
21Feb13_180257|-- Bias --
21Feb13_180257|[-0.75222  0.38335 -0.29971]
21Feb13_180257|Layer 3:
21Feb13_180257|-- Config --
21Feb13_180257|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180257|-- Weights --
21Feb13_180257|[[0.15542 0.28298]
21Feb13_180257| [0.24110 0.49447]
21Feb13_180257| [0.43948 0.55769]]
21Feb13_180257|-- Bias --
21Feb13_180257|[ 0.53898 -0.03614]
21Feb13_180257|Layer 4:
21Feb13_180257|-- Config --
21Feb13_180257|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180257|-- Weights --
21Feb13_180257|[[-0.57811 -0.38365]
21Feb13_180257| [-0.76354  0.47765]]
21Feb13_180257|-- Bias --
21Feb13_180257|[0.19825 0.26873]
21Feb13_180257|Predicting the validation and test data with the Best final individual.
21Feb13_180305| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_180305|-----------  ------------------  --------------------  ----------
21Feb13_180305|Validation         28.96                  40            0.79001
21Feb13_180305|   Test            24.85                  40            0.77524
21Feb13_180305|-------------------- Test #1 --------------------
21Feb13_180305|Best final individual weights
21Feb13_180305|Individual:
21Feb13_180305|-- Constant hidden layers --
21Feb13_180305|False
21Feb13_180305|Layer 0:
21Feb13_180305|-- Config --
21Feb13_180305|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180305|-- Weights --
21Feb13_180305|[[-0.52757  0.21411]
21Feb13_180305| [-0.93911 -1.17137]
21Feb13_180305| [-0.61957 -0.66375]
21Feb13_180305| [-0.51664 -2.09212]
21Feb13_180305| [ 1.08829 -0.13413]
21Feb13_180305| [-0.25816  0.27802]
21Feb13_180305| [ 0.66354 -0.52361]
21Feb13_180305| [ 1.01133 -0.15515]
21Feb13_180305| [ 0.01483 -0.14014]
21Feb13_180305| [ 0.22676 -0.27499]
21Feb13_180305| [ 0.43593 -2.14033]
21Feb13_180305| [-0.26769 -0.28757]
21Feb13_180305| [ 0.28306  0.42430]
21Feb13_180305| [-1.86751  0.58942]
21Feb13_180305| [ 0.03955 -0.29203]
21Feb13_180305| [ 0.53856 -1.32664]
21Feb13_180305| [-1.26262  0.12423]
21Feb13_180305| [-0.95736 -0.39002]
21Feb13_180305| [ 0.31148  0.81849]
21Feb13_180305| [-1.20171 -1.16573]
21Feb13_180305| [-0.43995  0.46443]
21Feb13_180305| [ 0.17542 -0.95269]
21Feb13_180305| [ 0.05423  2.54728]
21Feb13_180305| [-0.41660 -0.62510]
21Feb13_180305| [ 0.48650 -0.12177]
21Feb13_180305| [-0.41604 -0.08118]
21Feb13_180305| [-0.16116  0.68089]
21Feb13_180305| [ 0.58706 -1.30828]
21Feb13_180305| [-0.96782  1.51900]
21Feb13_180305| [ 0.08874 -0.67677]
21Feb13_180305| [-0.68590 -1.49289]
21Feb13_180305| [ 1.08065  2.07463]
21Feb13_180305| [-1.05417  0.71235]
21Feb13_180305| [-0.05213 -0.58554]
21Feb13_180305| [-0.12627 -0.31128]
21Feb13_180305| [ 1.34093 -0.18664]
21Feb13_180305| [-1.30497 -0.40435]
21Feb13_180305| [ 0.68676  0.75508]
21Feb13_180305| [-1.59599 -0.71000]
21Feb13_180305| [ 0.79255  0.47768]
21Feb13_180305| [-0.63359 -0.83681]
21Feb13_180305| [-0.54831  0.03451]
21Feb13_180305| [-0.08075  1.16147]
21Feb13_180305| [ 0.82149 -0.24838]
21Feb13_180305| [-0.83911  0.36663]
21Feb13_180305| [-0.40125 -0.23944]
21Feb13_180305| [-1.82054 -0.17440]
21Feb13_180305| [-0.99986  1.60933]
21Feb13_180305| [-1.83158 -2.24240]
21Feb13_180305| [ 0.04873 -1.02073]
21Feb13_180305| [-0.56204 -0.67282]
21Feb13_180305| [-1.61599  0.79008]
21Feb13_180305| [-1.88676  1.24359]
21Feb13_180305| [ 0.28231  0.49092]
21Feb13_180305| [ 1.80131 -0.95736]
21Feb13_180305| [ 1.10036  0.20309]
21Feb13_180305| [ 0.63629 -0.89126]]
21Feb13_180305|-- Bias --
21Feb13_180305|[ 0.05179 -0.09215]
21Feb13_180305|Layer 1:
21Feb13_180305|-- Config --
21Feb13_180305|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180305|-- Weights --
21Feb13_180305|[[ 0.76236  0.77919 -0.54170]
21Feb13_180305| [ 0.72178 -1.22032 -0.56733]]
21Feb13_180305|-- Bias --
21Feb13_180305|[-0.62552  0.86248 -0.09337]
21Feb13_180305|Layer 2:
21Feb13_180305|-- Config --
21Feb13_180305|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180305|-- Weights --
21Feb13_180305|[[ 0.17631  1.22903  0.28211]
21Feb13_180305| [ 0.23756 -0.52210  0.80113]
21Feb13_180305| [-0.53643 -0.29098  0.14483]]
21Feb13_180305|-- Bias --
21Feb13_180305|[-0.75222  0.38335 -0.29971]
21Feb13_180305|Layer 3:
21Feb13_180305|-- Config --
21Feb13_180305|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180305|-- Weights --
21Feb13_180305|[[0.15542 0.28298]
21Feb13_180305| [0.24110 0.49447]
21Feb13_180305| [0.43948 0.55769]]
21Feb13_180305|-- Bias --
21Feb13_180305|[ 0.53898 -0.03614]
21Feb13_180305|Layer 4:
21Feb13_180305|-- Config --
21Feb13_180305|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180305|-- Weights --
21Feb13_180305|[[-0.57811 -0.38365]
21Feb13_180305| [-0.76354  0.47765]]
21Feb13_180305|-- Bias --
21Feb13_180305|[0.19825 0.26873]
21Feb13_180305|Predicting the validation and test data with the Best final individual.
21Feb13_180313| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_180313|-----------  ------------------  --------------------  ----------
21Feb13_180313|Validation         33.30                  40            0.82783
21Feb13_180313|   Test            27.19                  40            0.51055
21Feb13_180313|-------------------- Test #2 --------------------
21Feb13_180313|Best final individual weights
21Feb13_180313|Individual:
21Feb13_180313|-- Constant hidden layers --
21Feb13_180313|False
21Feb13_180313|Layer 0:
21Feb13_180313|-- Config --
21Feb13_180313|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180313|-- Weights --
21Feb13_180313|[[-0.52757  0.21411]
21Feb13_180313| [-0.93911 -1.17137]
21Feb13_180313| [-0.61957 -0.66375]
21Feb13_180313| [-0.51664 -2.09212]
21Feb13_180313| [ 1.08829 -0.13413]
21Feb13_180313| [-0.25816  0.27802]
21Feb13_180313| [ 0.66354 -0.52361]
21Feb13_180313| [ 1.01133 -0.15515]
21Feb13_180313| [ 0.01483 -0.14014]
21Feb13_180313| [ 0.22676 -0.27499]
21Feb13_180313| [ 0.43593 -2.14033]
21Feb13_180313| [-0.26769 -0.28757]
21Feb13_180313| [ 0.28306  0.42430]
21Feb13_180313| [-1.86751  0.58942]
21Feb13_180313| [ 0.03955 -0.29203]
21Feb13_180313| [ 0.53856 -1.32664]
21Feb13_180313| [-1.26262  0.12423]
21Feb13_180313| [-0.95736 -0.39002]
21Feb13_180313| [ 0.31148  0.81849]
21Feb13_180313| [-1.20171 -1.16573]
21Feb13_180313| [-0.43995  0.46443]
21Feb13_180313| [ 0.17542 -0.95269]
21Feb13_180313| [ 0.05423  2.54728]
21Feb13_180313| [-0.41660 -0.62510]
21Feb13_180313| [ 0.48650 -0.12177]
21Feb13_180313| [-0.41604 -0.08118]
21Feb13_180313| [-0.16116  0.68089]
21Feb13_180313| [ 0.58706 -1.30828]
21Feb13_180313| [-0.96782  1.51900]
21Feb13_180313| [ 0.08874 -0.67677]
21Feb13_180313| [-0.68590 -1.49289]
21Feb13_180313| [ 1.08065  2.07463]
21Feb13_180313| [-1.05417  0.71235]
21Feb13_180313| [-0.05213 -0.58554]
21Feb13_180313| [-0.12627 -0.31128]
21Feb13_180313| [ 1.34093 -0.18664]
21Feb13_180313| [-1.30497 -0.40435]
21Feb13_180313| [ 0.68676  0.75508]
21Feb13_180313| [-1.59599 -0.71000]
21Feb13_180313| [ 0.79255  0.47768]
21Feb13_180313| [-0.63359 -0.83681]
21Feb13_180313| [-0.54831  0.03451]
21Feb13_180313| [-0.08075  1.16147]
21Feb13_180313| [ 0.82149 -0.24838]
21Feb13_180313| [-0.83911  0.36663]
21Feb13_180313| [-0.40125 -0.23944]
21Feb13_180313| [-1.82054 -0.17440]
21Feb13_180313| [-0.99986  1.60933]
21Feb13_180313| [-1.83158 -2.24240]
21Feb13_180313| [ 0.04873 -1.02073]
21Feb13_180313| [-0.56204 -0.67282]
21Feb13_180313| [-1.61599  0.79008]
21Feb13_180313| [-1.88676  1.24359]
21Feb13_180313| [ 0.28231  0.49092]
21Feb13_180313| [ 1.80131 -0.95736]
21Feb13_180313| [ 1.10036  0.20309]
21Feb13_180313| [ 0.63629 -0.89126]]
21Feb13_180313|-- Bias --
21Feb13_180313|[ 0.05179 -0.09215]
21Feb13_180313|Layer 1:
21Feb13_180313|-- Config --
21Feb13_180313|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180313|-- Weights --
21Feb13_180313|[[ 0.76236  0.77919 -0.54170]
21Feb13_180313| [ 0.72178 -1.22032 -0.56733]]
21Feb13_180313|-- Bias --
21Feb13_180313|[-0.62552  0.86248 -0.09337]
21Feb13_180313|Layer 2:
21Feb13_180313|-- Config --
21Feb13_180313|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180313|-- Weights --
21Feb13_180313|[[ 0.17631  1.22903  0.28211]
21Feb13_180313| [ 0.23756 -0.52210  0.80113]
21Feb13_180313| [-0.53643 -0.29098  0.14483]]
21Feb13_180313|-- Bias --
21Feb13_180313|[-0.75222  0.38335 -0.29971]
21Feb13_180313|Layer 3:
21Feb13_180313|-- Config --
21Feb13_180313|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180313|-- Weights --
21Feb13_180313|[[0.15542 0.28298]
21Feb13_180313| [0.24110 0.49447]
21Feb13_180313| [0.43948 0.55769]]
21Feb13_180313|-- Bias --
21Feb13_180313|[ 0.53898 -0.03614]
21Feb13_180313|Layer 4:
21Feb13_180313|-- Config --
21Feb13_180313|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180313|-- Weights --
21Feb13_180313|[[-0.57811 -0.38365]
21Feb13_180313| [-0.76354  0.47765]]
21Feb13_180313|-- Bias --
21Feb13_180313|[0.19825 0.26873]
21Feb13_180313|Predicting the validation and test data with the Best final individual.
21Feb13_180321| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_180321|-----------  ------------------  --------------------  ----------
21Feb13_180321|Validation         28.17                  40            0.74239
21Feb13_180321|   Test            24.76                  40            0.74289
21Feb13_180321|-------------------- Test #3 --------------------
21Feb13_180321|Best final individual weights
21Feb13_180321|Individual:
21Feb13_180321|-- Constant hidden layers --
21Feb13_180321|False
21Feb13_180321|Layer 0:
21Feb13_180321|-- Config --
21Feb13_180321|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180321|-- Weights --
21Feb13_180321|[[-0.52757  0.21411]
21Feb13_180321| [-0.93911 -1.17137]
21Feb13_180321| [-0.61957 -0.66375]
21Feb13_180321| [-0.51664 -2.09212]
21Feb13_180321| [ 1.08829 -0.13413]
21Feb13_180321| [-0.25816  0.27802]
21Feb13_180321| [ 0.66354 -0.52361]
21Feb13_180321| [ 1.01133 -0.15515]
21Feb13_180321| [ 0.01483 -0.14014]
21Feb13_180321| [ 0.22676 -0.27499]
21Feb13_180321| [ 0.43593 -2.14033]
21Feb13_180321| [-0.26769 -0.28757]
21Feb13_180321| [ 0.28306  0.42430]
21Feb13_180321| [-1.86751  0.58942]
21Feb13_180321| [ 0.03955 -0.29203]
21Feb13_180321| [ 0.53856 -1.32664]
21Feb13_180321| [-1.26262  0.12423]
21Feb13_180321| [-0.95736 -0.39002]
21Feb13_180321| [ 0.31148  0.81849]
21Feb13_180321| [-1.20171 -1.16573]
21Feb13_180321| [-0.43995  0.46443]
21Feb13_180321| [ 0.17542 -0.95269]
21Feb13_180321| [ 0.05423  2.54728]
21Feb13_180321| [-0.41660 -0.62510]
21Feb13_180321| [ 0.48650 -0.12177]
21Feb13_180321| [-0.41604 -0.08118]
21Feb13_180321| [-0.16116  0.68089]
21Feb13_180321| [ 0.58706 -1.30828]
21Feb13_180321| [-0.96782  1.51900]
21Feb13_180321| [ 0.08874 -0.67677]
21Feb13_180321| [-0.68590 -1.49289]
21Feb13_180321| [ 1.08065  2.07463]
21Feb13_180321| [-1.05417  0.71235]
21Feb13_180321| [-0.05213 -0.58554]
21Feb13_180321| [-0.12627 -0.31128]
21Feb13_180321| [ 1.34093 -0.18664]
21Feb13_180321| [-1.30497 -0.40435]
21Feb13_180321| [ 0.68676  0.75508]
21Feb13_180321| [-1.59599 -0.71000]
21Feb13_180321| [ 0.79255  0.47768]
21Feb13_180321| [-0.63359 -0.83681]
21Feb13_180321| [-0.54831  0.03451]
21Feb13_180321| [-0.08075  1.16147]
21Feb13_180321| [ 0.82149 -0.24838]
21Feb13_180321| [-0.83911  0.36663]
21Feb13_180321| [-0.40125 -0.23944]
21Feb13_180321| [-1.82054 -0.17440]
21Feb13_180321| [-0.99986  1.60933]
21Feb13_180321| [-1.83158 -2.24240]
21Feb13_180321| [ 0.04873 -1.02073]
21Feb13_180321| [-0.56204 -0.67282]
21Feb13_180321| [-1.61599  0.79008]
21Feb13_180321| [-1.88676  1.24359]
21Feb13_180321| [ 0.28231  0.49092]
21Feb13_180321| [ 1.80131 -0.95736]
21Feb13_180321| [ 1.10036  0.20309]
21Feb13_180321| [ 0.63629 -0.89126]]
21Feb13_180321|-- Bias --
21Feb13_180321|[ 0.05179 -0.09215]
21Feb13_180321|Layer 1:
21Feb13_180321|-- Config --
21Feb13_180321|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180321|-- Weights --
21Feb13_180321|[[ 0.76236  0.77919 -0.54170]
21Feb13_180321| [ 0.72178 -1.22032 -0.56733]]
21Feb13_180321|-- Bias --
21Feb13_180321|[-0.62552  0.86248 -0.09337]
21Feb13_180321|Layer 2:
21Feb13_180321|-- Config --
21Feb13_180321|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180321|-- Weights --
21Feb13_180321|[[ 0.17631  1.22903  0.28211]
21Feb13_180321| [ 0.23756 -0.52210  0.80113]
21Feb13_180321| [-0.53643 -0.29098  0.14483]]
21Feb13_180321|-- Bias --
21Feb13_180321|[-0.75222  0.38335 -0.29971]
21Feb13_180321|Layer 3:
21Feb13_180321|-- Config --
21Feb13_180321|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180321|-- Weights --
21Feb13_180321|[[0.15542 0.28298]
21Feb13_180321| [0.24110 0.49447]
21Feb13_180321| [0.43948 0.55769]]
21Feb13_180321|-- Bias --
21Feb13_180321|[ 0.53898 -0.03614]
21Feb13_180321|Layer 4:
21Feb13_180321|-- Config --
21Feb13_180321|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180321|-- Weights --
21Feb13_180321|[[-0.57811 -0.38365]
21Feb13_180321| [-0.76354  0.47765]]
21Feb13_180321|-- Bias --
21Feb13_180321|[0.19825 0.26873]
21Feb13_180321|Predicting the validation and test data with the Best final individual.
21Feb13_180329| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_180329|-----------  ------------------  --------------------  ----------
21Feb13_180329|Validation         31.22                  40            0.76056
21Feb13_180329|   Test            24.50                  40            0.82200
21Feb13_180329|-------------------- Test #4 --------------------
21Feb13_180329|Best final individual weights
21Feb13_180329|Individual:
21Feb13_180329|-- Constant hidden layers --
21Feb13_180329|False
21Feb13_180329|Layer 0:
21Feb13_180329|-- Config --
21Feb13_180329|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180329|-- Weights --
21Feb13_180329|[[-0.52757  0.21411]
21Feb13_180329| [-0.93911 -1.17137]
21Feb13_180329| [-0.61957 -0.66375]
21Feb13_180329| [-0.51664 -2.09212]
21Feb13_180329| [ 1.08829 -0.13413]
21Feb13_180329| [-0.25816  0.27802]
21Feb13_180329| [ 0.66354 -0.52361]
21Feb13_180329| [ 1.01133 -0.15515]
21Feb13_180329| [ 0.01483 -0.14014]
21Feb13_180329| [ 0.22676 -0.27499]
21Feb13_180329| [ 0.43593 -2.14033]
21Feb13_180329| [-0.26769 -0.28757]
21Feb13_180329| [ 0.28306  0.42430]
21Feb13_180329| [-1.86751  0.58942]
21Feb13_180329| [ 0.03955 -0.29203]
21Feb13_180329| [ 0.53856 -1.32664]
21Feb13_180329| [-1.26262  0.12423]
21Feb13_180329| [-0.95736 -0.39002]
21Feb13_180329| [ 0.31148  0.81849]
21Feb13_180329| [-1.20171 -1.16573]
21Feb13_180329| [-0.43995  0.46443]
21Feb13_180329| [ 0.17542 -0.95269]
21Feb13_180329| [ 0.05423  2.54728]
21Feb13_180329| [-0.41660 -0.62510]
21Feb13_180329| [ 0.48650 -0.12177]
21Feb13_180329| [-0.41604 -0.08118]
21Feb13_180329| [-0.16116  0.68089]
21Feb13_180329| [ 0.58706 -1.30828]
21Feb13_180329| [-0.96782  1.51900]
21Feb13_180329| [ 0.08874 -0.67677]
21Feb13_180329| [-0.68590 -1.49289]
21Feb13_180329| [ 1.08065  2.07463]
21Feb13_180329| [-1.05417  0.71235]
21Feb13_180329| [-0.05213 -0.58554]
21Feb13_180329| [-0.12627 -0.31128]
21Feb13_180329| [ 1.34093 -0.18664]
21Feb13_180329| [-1.30497 -0.40435]
21Feb13_180329| [ 0.68676  0.75508]
21Feb13_180329| [-1.59599 -0.71000]
21Feb13_180329| [ 0.79255  0.47768]
21Feb13_180329| [-0.63359 -0.83681]
21Feb13_180329| [-0.54831  0.03451]
21Feb13_180329| [-0.08075  1.16147]
21Feb13_180329| [ 0.82149 -0.24838]
21Feb13_180329| [-0.83911  0.36663]
21Feb13_180329| [-0.40125 -0.23944]
21Feb13_180329| [-1.82054 -0.17440]
21Feb13_180329| [-0.99986  1.60933]
21Feb13_180329| [-1.83158 -2.24240]
21Feb13_180329| [ 0.04873 -1.02073]
21Feb13_180329| [-0.56204 -0.67282]
21Feb13_180329| [-1.61599  0.79008]
21Feb13_180329| [-1.88676  1.24359]
21Feb13_180329| [ 0.28231  0.49092]
21Feb13_180329| [ 1.80131 -0.95736]
21Feb13_180329| [ 1.10036  0.20309]
21Feb13_180329| [ 0.63629 -0.89126]]
21Feb13_180329|-- Bias --
21Feb13_180329|[ 0.05179 -0.09215]
21Feb13_180329|Layer 1:
21Feb13_180329|-- Config --
21Feb13_180329|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180329|-- Weights --
21Feb13_180329|[[ 0.76236  0.77919 -0.54170]
21Feb13_180329| [ 0.72178 -1.22032 -0.56733]]
21Feb13_180329|-- Bias --
21Feb13_180329|[-0.62552  0.86248 -0.09337]
21Feb13_180329|Layer 2:
21Feb13_180329|-- Config --
21Feb13_180329|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180329|-- Weights --
21Feb13_180329|[[ 0.17631  1.22903  0.28211]
21Feb13_180329| [ 0.23756 -0.52210  0.80113]
21Feb13_180329| [-0.53643 -0.29098  0.14483]]
21Feb13_180329|-- Bias --
21Feb13_180329|[-0.75222  0.38335 -0.29971]
21Feb13_180329|Layer 3:
21Feb13_180329|-- Config --
21Feb13_180329|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180329|-- Weights --
21Feb13_180329|[[0.15542 0.28298]
21Feb13_180329| [0.24110 0.49447]
21Feb13_180329| [0.43948 0.55769]]
21Feb13_180329|-- Bias --
21Feb13_180329|[ 0.53898 -0.03614]
21Feb13_180329|Layer 4:
21Feb13_180329|-- Config --
21Feb13_180329|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180329|-- Weights --
21Feb13_180329|[[-0.57811 -0.38365]
21Feb13_180329| [-0.76354  0.47765]]
21Feb13_180329|-- Bias --
21Feb13_180329|[0.19825 0.26873]
21Feb13_180329|Predicting the validation and test data with the Best final individual.
21Feb13_180337| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_180337|-----------  ------------------  --------------------  ----------
21Feb13_180337|Validation         21.83                  40            0.76906
21Feb13_180337|   Test            29.63                  40            0.80658
21Feb13_180337|-------------------- Test #5 --------------------
21Feb13_180337|Best final individual weights
21Feb13_180337|Individual:
21Feb13_180337|-- Constant hidden layers --
21Feb13_180337|False
21Feb13_180337|Layer 0:
21Feb13_180337|-- Config --
21Feb13_180337|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180337|-- Weights --
21Feb13_180337|[[-0.52757  0.21411]
21Feb13_180337| [-0.93911 -1.17137]
21Feb13_180337| [-0.61957 -0.66375]
21Feb13_180337| [-0.51664 -2.09212]
21Feb13_180337| [ 1.08829 -0.13413]
21Feb13_180337| [-0.25816  0.27802]
21Feb13_180337| [ 0.66354 -0.52361]
21Feb13_180337| [ 1.01133 -0.15515]
21Feb13_180337| [ 0.01483 -0.14014]
21Feb13_180337| [ 0.22676 -0.27499]
21Feb13_180337| [ 0.43593 -2.14033]
21Feb13_180337| [-0.26769 -0.28757]
21Feb13_180337| [ 0.28306  0.42430]
21Feb13_180337| [-1.86751  0.58942]
21Feb13_180337| [ 0.03955 -0.29203]
21Feb13_180337| [ 0.53856 -1.32664]
21Feb13_180337| [-1.26262  0.12423]
21Feb13_180337| [-0.95736 -0.39002]
21Feb13_180337| [ 0.31148  0.81849]
21Feb13_180337| [-1.20171 -1.16573]
21Feb13_180337| [-0.43995  0.46443]
21Feb13_180337| [ 0.17542 -0.95269]
21Feb13_180337| [ 0.05423  2.54728]
21Feb13_180337| [-0.41660 -0.62510]
21Feb13_180337| [ 0.48650 -0.12177]
21Feb13_180337| [-0.41604 -0.08118]
21Feb13_180337| [-0.16116  0.68089]
21Feb13_180337| [ 0.58706 -1.30828]
21Feb13_180337| [-0.96782  1.51900]
21Feb13_180337| [ 0.08874 -0.67677]
21Feb13_180337| [-0.68590 -1.49289]
21Feb13_180337| [ 1.08065  2.07463]
21Feb13_180337| [-1.05417  0.71235]
21Feb13_180337| [-0.05213 -0.58554]
21Feb13_180337| [-0.12627 -0.31128]
21Feb13_180337| [ 1.34093 -0.18664]
21Feb13_180337| [-1.30497 -0.40435]
21Feb13_180337| [ 0.68676  0.75508]
21Feb13_180337| [-1.59599 -0.71000]
21Feb13_180337| [ 0.79255  0.47768]
21Feb13_180337| [-0.63359 -0.83681]
21Feb13_180337| [-0.54831  0.03451]
21Feb13_180337| [-0.08075  1.16147]
21Feb13_180337| [ 0.82149 -0.24838]
21Feb13_180337| [-0.83911  0.36663]
21Feb13_180337| [-0.40125 -0.23944]
21Feb13_180337| [-1.82054 -0.17440]
21Feb13_180337| [-0.99986  1.60933]
21Feb13_180337| [-1.83158 -2.24240]
21Feb13_180337| [ 0.04873 -1.02073]
21Feb13_180337| [-0.56204 -0.67282]
21Feb13_180337| [-1.61599  0.79008]
21Feb13_180337| [-1.88676  1.24359]
21Feb13_180337| [ 0.28231  0.49092]
21Feb13_180337| [ 1.80131 -0.95736]
21Feb13_180337| [ 1.10036  0.20309]
21Feb13_180337| [ 0.63629 -0.89126]]
21Feb13_180337|-- Bias --
21Feb13_180337|[ 0.05179 -0.09215]
21Feb13_180337|Layer 1:
21Feb13_180337|-- Config --
21Feb13_180337|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180337|-- Weights --
21Feb13_180337|[[ 0.76236  0.77919 -0.54170]
21Feb13_180337| [ 0.72178 -1.22032 -0.56733]]
21Feb13_180337|-- Bias --
21Feb13_180337|[-0.62552  0.86248 -0.09337]
21Feb13_180337|Layer 2:
21Feb13_180337|-- Config --
21Feb13_180337|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180337|-- Weights --
21Feb13_180337|[[ 0.17631  1.22903  0.28211]
21Feb13_180337| [ 0.23756 -0.52210  0.80113]
21Feb13_180337| [-0.53643 -0.29098  0.14483]]
21Feb13_180337|-- Bias --
21Feb13_180337|[-0.75222  0.38335 -0.29971]
21Feb13_180337|Layer 3:
21Feb13_180337|-- Config --
21Feb13_180337|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180337|-- Weights --
21Feb13_180337|[[0.15542 0.28298]
21Feb13_180337| [0.24110 0.49447]
21Feb13_180337| [0.43948 0.55769]]
21Feb13_180337|-- Bias --
21Feb13_180337|[ 0.53898 -0.03614]
21Feb13_180337|Layer 4:
21Feb13_180337|-- Config --
21Feb13_180337|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180337|-- Weights --
21Feb13_180337|[[-0.57811 -0.38365]
21Feb13_180337| [-0.76354  0.47765]]
21Feb13_180337|-- Bias --
21Feb13_180337|[0.19825 0.26873]
21Feb13_180337|Predicting the validation and test data with the Best final individual.
21Feb13_180345| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_180345|-----------  ------------------  --------------------  ----------
21Feb13_180345|Validation         27.39                  40            0.81120
21Feb13_180345|   Test            31.45                  40            0.75967
21Feb13_180345|-------------------- Test #6 --------------------
21Feb13_180345|Best final individual weights
21Feb13_180345|Individual:
21Feb13_180345|-- Constant hidden layers --
21Feb13_180345|False
21Feb13_180345|Layer 0:
21Feb13_180345|-- Config --
21Feb13_180345|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180345|-- Weights --
21Feb13_180345|[[-0.52757  0.21411]
21Feb13_180345| [-0.93911 -1.17137]
21Feb13_180345| [-0.61957 -0.66375]
21Feb13_180345| [-0.51664 -2.09212]
21Feb13_180345| [ 1.08829 -0.13413]
21Feb13_180345| [-0.25816  0.27802]
21Feb13_180345| [ 0.66354 -0.52361]
21Feb13_180345| [ 1.01133 -0.15515]
21Feb13_180345| [ 0.01483 -0.14014]
21Feb13_180345| [ 0.22676 -0.27499]
21Feb13_180345| [ 0.43593 -2.14033]
21Feb13_180345| [-0.26769 -0.28757]
21Feb13_180345| [ 0.28306  0.42430]
21Feb13_180345| [-1.86751  0.58942]
21Feb13_180345| [ 0.03955 -0.29203]
21Feb13_180345| [ 0.53856 -1.32664]
21Feb13_180345| [-1.26262  0.12423]
21Feb13_180345| [-0.95736 -0.39002]
21Feb13_180345| [ 0.31148  0.81849]
21Feb13_180345| [-1.20171 -1.16573]
21Feb13_180345| [-0.43995  0.46443]
21Feb13_180345| [ 0.17542 -0.95269]
21Feb13_180345| [ 0.05423  2.54728]
21Feb13_180345| [-0.41660 -0.62510]
21Feb13_180345| [ 0.48650 -0.12177]
21Feb13_180345| [-0.41604 -0.08118]
21Feb13_180345| [-0.16116  0.68089]
21Feb13_180345| [ 0.58706 -1.30828]
21Feb13_180345| [-0.96782  1.51900]
21Feb13_180345| [ 0.08874 -0.67677]
21Feb13_180345| [-0.68590 -1.49289]
21Feb13_180345| [ 1.08065  2.07463]
21Feb13_180345| [-1.05417  0.71235]
21Feb13_180345| [-0.05213 -0.58554]
21Feb13_180345| [-0.12627 -0.31128]
21Feb13_180345| [ 1.34093 -0.18664]
21Feb13_180345| [-1.30497 -0.40435]
21Feb13_180345| [ 0.68676  0.75508]
21Feb13_180345| [-1.59599 -0.71000]
21Feb13_180345| [ 0.79255  0.47768]
21Feb13_180345| [-0.63359 -0.83681]
21Feb13_180345| [-0.54831  0.03451]
21Feb13_180345| [-0.08075  1.16147]
21Feb13_180345| [ 0.82149 -0.24838]
21Feb13_180345| [-0.83911  0.36663]
21Feb13_180345| [-0.40125 -0.23944]
21Feb13_180345| [-1.82054 -0.17440]
21Feb13_180345| [-0.99986  1.60933]
21Feb13_180345| [-1.83158 -2.24240]
21Feb13_180345| [ 0.04873 -1.02073]
21Feb13_180345| [-0.56204 -0.67282]
21Feb13_180345| [-1.61599  0.79008]
21Feb13_180345| [-1.88676  1.24359]
21Feb13_180345| [ 0.28231  0.49092]
21Feb13_180345| [ 1.80131 -0.95736]
21Feb13_180345| [ 1.10036  0.20309]
21Feb13_180345| [ 0.63629 -0.89126]]
21Feb13_180345|-- Bias --
21Feb13_180345|[ 0.05179 -0.09215]
21Feb13_180345|Layer 1:
21Feb13_180345|-- Config --
21Feb13_180345|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180345|-- Weights --
21Feb13_180345|[[ 0.76236  0.77919 -0.54170]
21Feb13_180345| [ 0.72178 -1.22032 -0.56733]]
21Feb13_180345|-- Bias --
21Feb13_180345|[-0.62552  0.86248 -0.09337]
21Feb13_180345|Layer 2:
21Feb13_180345|-- Config --
21Feb13_180345|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180345|-- Weights --
21Feb13_180345|[[ 0.17631  1.22903  0.28211]
21Feb13_180345| [ 0.23756 -0.52210  0.80113]
21Feb13_180345| [-0.53643 -0.29098  0.14483]]
21Feb13_180345|-- Bias --
21Feb13_180345|[-0.75222  0.38335 -0.29971]
21Feb13_180345|Layer 3:
21Feb13_180345|-- Config --
21Feb13_180345|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180345|-- Weights --
21Feb13_180345|[[0.15542 0.28298]
21Feb13_180345| [0.24110 0.49447]
21Feb13_180345| [0.43948 0.55769]]
21Feb13_180345|-- Bias --
21Feb13_180345|[ 0.53898 -0.03614]
21Feb13_180345|Layer 4:
21Feb13_180345|-- Config --
21Feb13_180345|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180345|-- Weights --
21Feb13_180345|[[-0.57811 -0.38365]
21Feb13_180345| [-0.76354  0.47765]]
21Feb13_180345|-- Bias --
21Feb13_180345|[0.19825 0.26873]
21Feb13_180345|Predicting the validation and test data with the Best final individual.
21Feb13_180353| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_180353|-----------  ------------------  --------------------  ----------
21Feb13_180353|Validation         24.52                  40            0.78390
21Feb13_180353|   Test            27.98                  40            0.44559
21Feb13_180353|-------------------- Test #7 --------------------
21Feb13_180353|Best final individual weights
21Feb13_180353|Individual:
21Feb13_180353|-- Constant hidden layers --
21Feb13_180353|False
21Feb13_180353|Layer 0:
21Feb13_180353|-- Config --
21Feb13_180353|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180353|-- Weights --
21Feb13_180353|[[-0.52757  0.21411]
21Feb13_180353| [-0.93911 -1.17137]
21Feb13_180353| [-0.61957 -0.66375]
21Feb13_180353| [-0.51664 -2.09212]
21Feb13_180353| [ 1.08829 -0.13413]
21Feb13_180353| [-0.25816  0.27802]
21Feb13_180353| [ 0.66354 -0.52361]
21Feb13_180353| [ 1.01133 -0.15515]
21Feb13_180353| [ 0.01483 -0.14014]
21Feb13_180353| [ 0.22676 -0.27499]
21Feb13_180353| [ 0.43593 -2.14033]
21Feb13_180353| [-0.26769 -0.28757]
21Feb13_180353| [ 0.28306  0.42430]
21Feb13_180353| [-1.86751  0.58942]
21Feb13_180353| [ 0.03955 -0.29203]
21Feb13_180353| [ 0.53856 -1.32664]
21Feb13_180353| [-1.26262  0.12423]
21Feb13_180353| [-0.95736 -0.39002]
21Feb13_180353| [ 0.31148  0.81849]
21Feb13_180353| [-1.20171 -1.16573]
21Feb13_180353| [-0.43995  0.46443]
21Feb13_180353| [ 0.17542 -0.95269]
21Feb13_180353| [ 0.05423  2.54728]
21Feb13_180353| [-0.41660 -0.62510]
21Feb13_180353| [ 0.48650 -0.12177]
21Feb13_180353| [-0.41604 -0.08118]
21Feb13_180353| [-0.16116  0.68089]
21Feb13_180353| [ 0.58706 -1.30828]
21Feb13_180353| [-0.96782  1.51900]
21Feb13_180353| [ 0.08874 -0.67677]
21Feb13_180353| [-0.68590 -1.49289]
21Feb13_180353| [ 1.08065  2.07463]
21Feb13_180353| [-1.05417  0.71235]
21Feb13_180353| [-0.05213 -0.58554]
21Feb13_180353| [-0.12627 -0.31128]
21Feb13_180353| [ 1.34093 -0.18664]
21Feb13_180353| [-1.30497 -0.40435]
21Feb13_180353| [ 0.68676  0.75508]
21Feb13_180353| [-1.59599 -0.71000]
21Feb13_180353| [ 0.79255  0.47768]
21Feb13_180353| [-0.63359 -0.83681]
21Feb13_180353| [-0.54831  0.03451]
21Feb13_180353| [-0.08075  1.16147]
21Feb13_180353| [ 0.82149 -0.24838]
21Feb13_180353| [-0.83911  0.36663]
21Feb13_180353| [-0.40125 -0.23944]
21Feb13_180353| [-1.82054 -0.17440]
21Feb13_180353| [-0.99986  1.60933]
21Feb13_180353| [-1.83158 -2.24240]
21Feb13_180353| [ 0.04873 -1.02073]
21Feb13_180353| [-0.56204 -0.67282]
21Feb13_180353| [-1.61599  0.79008]
21Feb13_180353| [-1.88676  1.24359]
21Feb13_180353| [ 0.28231  0.49092]
21Feb13_180353| [ 1.80131 -0.95736]
21Feb13_180353| [ 1.10036  0.20309]
21Feb13_180353| [ 0.63629 -0.89126]]
21Feb13_180353|-- Bias --
21Feb13_180353|[ 0.05179 -0.09215]
21Feb13_180353|Layer 1:
21Feb13_180353|-- Config --
21Feb13_180353|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180353|-- Weights --
21Feb13_180353|[[ 0.76236  0.77919 -0.54170]
21Feb13_180353| [ 0.72178 -1.22032 -0.56733]]
21Feb13_180353|-- Bias --
21Feb13_180353|[-0.62552  0.86248 -0.09337]
21Feb13_180353|Layer 2:
21Feb13_180353|-- Config --
21Feb13_180353|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180353|-- Weights --
21Feb13_180353|[[ 0.17631  1.22903  0.28211]
21Feb13_180353| [ 0.23756 -0.52210  0.80113]
21Feb13_180353| [-0.53643 -0.29098  0.14483]]
21Feb13_180353|-- Bias --
21Feb13_180353|[-0.75222  0.38335 -0.29971]
21Feb13_180353|Layer 3:
21Feb13_180353|-- Config --
21Feb13_180353|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180353|-- Weights --
21Feb13_180353|[[0.15542 0.28298]
21Feb13_180353| [0.24110 0.49447]
21Feb13_180353| [0.43948 0.55769]]
21Feb13_180353|-- Bias --
21Feb13_180353|[ 0.53898 -0.03614]
21Feb13_180353|Layer 4:
21Feb13_180353|-- Config --
21Feb13_180353|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180353|-- Weights --
21Feb13_180353|[[-0.57811 -0.38365]
21Feb13_180353| [-0.76354  0.47765]]
21Feb13_180353|-- Bias --
21Feb13_180353|[0.19825 0.26873]
21Feb13_180353|Predicting the validation and test data with the Best final individual.
21Feb13_180401| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_180401|-----------  ------------------  --------------------  ----------
21Feb13_180401|Validation         23.04                  40            0.77783
21Feb13_180401|   Test            26.85                  40            0.79770
21Feb13_180401|-------------------- Test #8 --------------------
21Feb13_180401|Best final individual weights
21Feb13_180401|Individual:
21Feb13_180401|-- Constant hidden layers --
21Feb13_180401|False
21Feb13_180401|Layer 0:
21Feb13_180401|-- Config --
21Feb13_180401|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180401|-- Weights --
21Feb13_180401|[[-0.52757  0.21411]
21Feb13_180401| [-0.93911 -1.17137]
21Feb13_180401| [-0.61957 -0.66375]
21Feb13_180401| [-0.51664 -2.09212]
21Feb13_180401| [ 1.08829 -0.13413]
21Feb13_180401| [-0.25816  0.27802]
21Feb13_180401| [ 0.66354 -0.52361]
21Feb13_180401| [ 1.01133 -0.15515]
21Feb13_180401| [ 0.01483 -0.14014]
21Feb13_180401| [ 0.22676 -0.27499]
21Feb13_180401| [ 0.43593 -2.14033]
21Feb13_180401| [-0.26769 -0.28757]
21Feb13_180401| [ 0.28306  0.42430]
21Feb13_180401| [-1.86751  0.58942]
21Feb13_180401| [ 0.03955 -0.29203]
21Feb13_180401| [ 0.53856 -1.32664]
21Feb13_180401| [-1.26262  0.12423]
21Feb13_180401| [-0.95736 -0.39002]
21Feb13_180401| [ 0.31148  0.81849]
21Feb13_180401| [-1.20171 -1.16573]
21Feb13_180401| [-0.43995  0.46443]
21Feb13_180401| [ 0.17542 -0.95269]
21Feb13_180401| [ 0.05423  2.54728]
21Feb13_180401| [-0.41660 -0.62510]
21Feb13_180401| [ 0.48650 -0.12177]
21Feb13_180401| [-0.41604 -0.08118]
21Feb13_180401| [-0.16116  0.68089]
21Feb13_180401| [ 0.58706 -1.30828]
21Feb13_180401| [-0.96782  1.51900]
21Feb13_180401| [ 0.08874 -0.67677]
21Feb13_180401| [-0.68590 -1.49289]
21Feb13_180401| [ 1.08065  2.07463]
21Feb13_180401| [-1.05417  0.71235]
21Feb13_180401| [-0.05213 -0.58554]
21Feb13_180401| [-0.12627 -0.31128]
21Feb13_180401| [ 1.34093 -0.18664]
21Feb13_180401| [-1.30497 -0.40435]
21Feb13_180401| [ 0.68676  0.75508]
21Feb13_180401| [-1.59599 -0.71000]
21Feb13_180401| [ 0.79255  0.47768]
21Feb13_180401| [-0.63359 -0.83681]
21Feb13_180401| [-0.54831  0.03451]
21Feb13_180401| [-0.08075  1.16147]
21Feb13_180401| [ 0.82149 -0.24838]
21Feb13_180401| [-0.83911  0.36663]
21Feb13_180401| [-0.40125 -0.23944]
21Feb13_180401| [-1.82054 -0.17440]
21Feb13_180401| [-0.99986  1.60933]
21Feb13_180401| [-1.83158 -2.24240]
21Feb13_180401| [ 0.04873 -1.02073]
21Feb13_180401| [-0.56204 -0.67282]
21Feb13_180401| [-1.61599  0.79008]
21Feb13_180401| [-1.88676  1.24359]
21Feb13_180401| [ 0.28231  0.49092]
21Feb13_180401| [ 1.80131 -0.95736]
21Feb13_180401| [ 1.10036  0.20309]
21Feb13_180401| [ 0.63629 -0.89126]]
21Feb13_180401|-- Bias --
21Feb13_180401|[ 0.05179 -0.09215]
21Feb13_180401|Layer 1:
21Feb13_180401|-- Config --
21Feb13_180401|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180401|-- Weights --
21Feb13_180401|[[ 0.76236  0.77919 -0.54170]
21Feb13_180401| [ 0.72178 -1.22032 -0.56733]]
21Feb13_180401|-- Bias --
21Feb13_180401|[-0.62552  0.86248 -0.09337]
21Feb13_180401|Layer 2:
21Feb13_180401|-- Config --
21Feb13_180401|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180401|-- Weights --
21Feb13_180401|[[ 0.17631  1.22903  0.28211]
21Feb13_180401| [ 0.23756 -0.52210  0.80113]
21Feb13_180401| [-0.53643 -0.29098  0.14483]]
21Feb13_180401|-- Bias --
21Feb13_180401|[-0.75222  0.38335 -0.29971]
21Feb13_180401|Layer 3:
21Feb13_180401|-- Config --
21Feb13_180401|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180401|-- Weights --
21Feb13_180401|[[0.15542 0.28298]
21Feb13_180401| [0.24110 0.49447]
21Feb13_180401| [0.43948 0.55769]]
21Feb13_180401|-- Bias --
21Feb13_180401|[ 0.53898 -0.03614]
21Feb13_180401|Layer 4:
21Feb13_180401|-- Config --
21Feb13_180401|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180401|-- Weights --
21Feb13_180401|[[-0.57811 -0.38365]
21Feb13_180401| [-0.76354  0.47765]]
21Feb13_180401|-- Bias --
21Feb13_180401|[0.19825 0.26873]
21Feb13_180401|Predicting the validation and test data with the Best final individual.
21Feb13_180409| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_180409|-----------  ------------------  --------------------  ----------
21Feb13_180409|Validation         38.78                  40            0.00000
21Feb13_180409|   Test            25.63                  40            0.72908
21Feb13_180409|-------------------- Test #9 --------------------
21Feb13_180409|Best final individual weights
21Feb13_180409|Individual:
21Feb13_180409|-- Constant hidden layers --
21Feb13_180409|False
21Feb13_180409|Layer 0:
21Feb13_180409|-- Config --
21Feb13_180409|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180409|-- Weights --
21Feb13_180409|[[-0.52757  0.21411]
21Feb13_180409| [-0.93911 -1.17137]
21Feb13_180409| [-0.61957 -0.66375]
21Feb13_180409| [-0.51664 -2.09212]
21Feb13_180409| [ 1.08829 -0.13413]
21Feb13_180409| [-0.25816  0.27802]
21Feb13_180409| [ 0.66354 -0.52361]
21Feb13_180409| [ 1.01133 -0.15515]
21Feb13_180409| [ 0.01483 -0.14014]
21Feb13_180409| [ 0.22676 -0.27499]
21Feb13_180409| [ 0.43593 -2.14033]
21Feb13_180409| [-0.26769 -0.28757]
21Feb13_180409| [ 0.28306  0.42430]
21Feb13_180409| [-1.86751  0.58942]
21Feb13_180409| [ 0.03955 -0.29203]
21Feb13_180409| [ 0.53856 -1.32664]
21Feb13_180409| [-1.26262  0.12423]
21Feb13_180409| [-0.95736 -0.39002]
21Feb13_180409| [ 0.31148  0.81849]
21Feb13_180409| [-1.20171 -1.16573]
21Feb13_180409| [-0.43995  0.46443]
21Feb13_180409| [ 0.17542 -0.95269]
21Feb13_180409| [ 0.05423  2.54728]
21Feb13_180409| [-0.41660 -0.62510]
21Feb13_180409| [ 0.48650 -0.12177]
21Feb13_180409| [-0.41604 -0.08118]
21Feb13_180409| [-0.16116  0.68089]
21Feb13_180409| [ 0.58706 -1.30828]
21Feb13_180409| [-0.96782  1.51900]
21Feb13_180409| [ 0.08874 -0.67677]
21Feb13_180409| [-0.68590 -1.49289]
21Feb13_180409| [ 1.08065  2.07463]
21Feb13_180409| [-1.05417  0.71235]
21Feb13_180409| [-0.05213 -0.58554]
21Feb13_180409| [-0.12627 -0.31128]
21Feb13_180409| [ 1.34093 -0.18664]
21Feb13_180409| [-1.30497 -0.40435]
21Feb13_180409| [ 0.68676  0.75508]
21Feb13_180409| [-1.59599 -0.71000]
21Feb13_180409| [ 0.79255  0.47768]
21Feb13_180409| [-0.63359 -0.83681]
21Feb13_180409| [-0.54831  0.03451]
21Feb13_180409| [-0.08075  1.16147]
21Feb13_180409| [ 0.82149 -0.24838]
21Feb13_180409| [-0.83911  0.36663]
21Feb13_180409| [-0.40125 -0.23944]
21Feb13_180409| [-1.82054 -0.17440]
21Feb13_180409| [-0.99986  1.60933]
21Feb13_180409| [-1.83158 -2.24240]
21Feb13_180409| [ 0.04873 -1.02073]
21Feb13_180409| [-0.56204 -0.67282]
21Feb13_180409| [-1.61599  0.79008]
21Feb13_180409| [-1.88676  1.24359]
21Feb13_180409| [ 0.28231  0.49092]
21Feb13_180409| [ 1.80131 -0.95736]
21Feb13_180409| [ 1.10036  0.20309]
21Feb13_180409| [ 0.63629 -0.89126]]
21Feb13_180409|-- Bias --
21Feb13_180409|[ 0.05179 -0.09215]
21Feb13_180409|Layer 1:
21Feb13_180409|-- Config --
21Feb13_180409|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180409|-- Weights --
21Feb13_180409|[[ 0.76236  0.77919 -0.54170]
21Feb13_180409| [ 0.72178 -1.22032 -0.56733]]
21Feb13_180409|-- Bias --
21Feb13_180409|[-0.62552  0.86248 -0.09337]
21Feb13_180409|Layer 2:
21Feb13_180409|-- Config --
21Feb13_180409|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180409|-- Weights --
21Feb13_180409|[[ 0.17631  1.22903  0.28211]
21Feb13_180409| [ 0.23756 -0.52210  0.80113]
21Feb13_180409| [-0.53643 -0.29098  0.14483]]
21Feb13_180409|-- Bias --
21Feb13_180409|[-0.75222  0.38335 -0.29971]
21Feb13_180409|Layer 3:
21Feb13_180409|-- Config --
21Feb13_180409|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180409|-- Weights --
21Feb13_180409|[[0.15542 0.28298]
21Feb13_180409| [0.24110 0.49447]
21Feb13_180409| [0.43948 0.55769]]
21Feb13_180409|-- Bias --
21Feb13_180409|[ 0.53898 -0.03614]
21Feb13_180409|Layer 4:
21Feb13_180409|-- Config --
21Feb13_180409|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180409|-- Weights --
21Feb13_180409|[[-0.57811 -0.38365]
21Feb13_180409| [-0.76354  0.47765]]
21Feb13_180409|-- Bias --
21Feb13_180409|[0.19825 0.26873]
21Feb13_180409|Predicting the validation and test data with the Best final individual.
21Feb13_180417| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_180417|-----------  ------------------  --------------------  ----------
21Feb13_180417|Validation         23.48                  40            0.63197
21Feb13_180417|   Test            22.94                  40            0.70281
21Feb13_180417|-------------------- Test #10 --------------------
21Feb13_180417|Best final individual weights
21Feb13_180417|Individual:
21Feb13_180417|-- Constant hidden layers --
21Feb13_180417|False
21Feb13_180417|Layer 0:
21Feb13_180417|-- Config --
21Feb13_180417|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180417|-- Weights --
21Feb13_180417|[[-0.52757  0.21411]
21Feb13_180417| [-0.93911 -1.17137]
21Feb13_180417| [-0.61957 -0.66375]
21Feb13_180417| [-0.51664 -2.09212]
21Feb13_180417| [ 1.08829 -0.13413]
21Feb13_180417| [-0.25816  0.27802]
21Feb13_180417| [ 0.66354 -0.52361]
21Feb13_180417| [ 1.01133 -0.15515]
21Feb13_180417| [ 0.01483 -0.14014]
21Feb13_180417| [ 0.22676 -0.27499]
21Feb13_180417| [ 0.43593 -2.14033]
21Feb13_180417| [-0.26769 -0.28757]
21Feb13_180417| [ 0.28306  0.42430]
21Feb13_180417| [-1.86751  0.58942]
21Feb13_180417| [ 0.03955 -0.29203]
21Feb13_180417| [ 0.53856 -1.32664]
21Feb13_180417| [-1.26262  0.12423]
21Feb13_180417| [-0.95736 -0.39002]
21Feb13_180417| [ 0.31148  0.81849]
21Feb13_180417| [-1.20171 -1.16573]
21Feb13_180417| [-0.43995  0.46443]
21Feb13_180417| [ 0.17542 -0.95269]
21Feb13_180417| [ 0.05423  2.54728]
21Feb13_180417| [-0.41660 -0.62510]
21Feb13_180417| [ 0.48650 -0.12177]
21Feb13_180417| [-0.41604 -0.08118]
21Feb13_180417| [-0.16116  0.68089]
21Feb13_180417| [ 0.58706 -1.30828]
21Feb13_180417| [-0.96782  1.51900]
21Feb13_180417| [ 0.08874 -0.67677]
21Feb13_180417| [-0.68590 -1.49289]
21Feb13_180417| [ 1.08065  2.07463]
21Feb13_180417| [-1.05417  0.71235]
21Feb13_180417| [-0.05213 -0.58554]
21Feb13_180417| [-0.12627 -0.31128]
21Feb13_180417| [ 1.34093 -0.18664]
21Feb13_180417| [-1.30497 -0.40435]
21Feb13_180417| [ 0.68676  0.75508]
21Feb13_180417| [-1.59599 -0.71000]
21Feb13_180417| [ 0.79255  0.47768]
21Feb13_180417| [-0.63359 -0.83681]
21Feb13_180417| [-0.54831  0.03451]
21Feb13_180417| [-0.08075  1.16147]
21Feb13_180417| [ 0.82149 -0.24838]
21Feb13_180417| [-0.83911  0.36663]
21Feb13_180417| [-0.40125 -0.23944]
21Feb13_180417| [-1.82054 -0.17440]
21Feb13_180417| [-0.99986  1.60933]
21Feb13_180417| [-1.83158 -2.24240]
21Feb13_180417| [ 0.04873 -1.02073]
21Feb13_180417| [-0.56204 -0.67282]
21Feb13_180417| [-1.61599  0.79008]
21Feb13_180417| [-1.88676  1.24359]
21Feb13_180417| [ 0.28231  0.49092]
21Feb13_180417| [ 1.80131 -0.95736]
21Feb13_180417| [ 1.10036  0.20309]
21Feb13_180417| [ 0.63629 -0.89126]]
21Feb13_180417|-- Bias --
21Feb13_180417|[ 0.05179 -0.09215]
21Feb13_180417|Layer 1:
21Feb13_180417|-- Config --
21Feb13_180417|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180417|-- Weights --
21Feb13_180417|[[ 0.76236  0.77919 -0.54170]
21Feb13_180417| [ 0.72178 -1.22032 -0.56733]]
21Feb13_180417|-- Bias --
21Feb13_180417|[-0.62552  0.86248 -0.09337]
21Feb13_180417|Layer 2:
21Feb13_180417|-- Config --
21Feb13_180417|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180417|-- Weights --
21Feb13_180417|[[ 0.17631  1.22903  0.28211]
21Feb13_180417| [ 0.23756 -0.52210  0.80113]
21Feb13_180417| [-0.53643 -0.29098  0.14483]]
21Feb13_180417|-- Bias --
21Feb13_180417|[-0.75222  0.38335 -0.29971]
21Feb13_180417|Layer 3:
21Feb13_180417|-- Config --
21Feb13_180417|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180417|-- Weights --
21Feb13_180417|[[0.15542 0.28298]
21Feb13_180417| [0.24110 0.49447]
21Feb13_180417| [0.43948 0.55769]]
21Feb13_180417|-- Bias --
21Feb13_180417|[ 0.53898 -0.03614]
21Feb13_180417|Layer 4:
21Feb13_180417|-- Config --
21Feb13_180417|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180417|-- Weights --
21Feb13_180417|[[-0.57811 -0.38365]
21Feb13_180417| [-0.76354  0.47765]]
21Feb13_180417|-- Bias --
21Feb13_180417|[0.19825 0.26873]
21Feb13_180417|Predicting the validation and test data with the Best final individual.
21Feb13_180425| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_180425|-----------  ------------------  --------------------  ----------
21Feb13_180425|Validation         23.04                  40            0.79250
21Feb13_180425|   Test            23.89                  40            0.75816
21Feb13_180425|-------------------- Test #11 --------------------
21Feb13_180425|Best final individual weights
21Feb13_180425|Individual:
21Feb13_180425|-- Constant hidden layers --
21Feb13_180425|False
21Feb13_180425|Layer 0:
21Feb13_180425|-- Config --
21Feb13_180425|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180425|-- Weights --
21Feb13_180425|[[-0.52757  0.21411]
21Feb13_180425| [-0.93911 -1.17137]
21Feb13_180425| [-0.61957 -0.66375]
21Feb13_180425| [-0.51664 -2.09212]
21Feb13_180425| [ 1.08829 -0.13413]
21Feb13_180425| [-0.25816  0.27802]
21Feb13_180425| [ 0.66354 -0.52361]
21Feb13_180425| [ 1.01133 -0.15515]
21Feb13_180425| [ 0.01483 -0.14014]
21Feb13_180425| [ 0.22676 -0.27499]
21Feb13_180425| [ 0.43593 -2.14033]
21Feb13_180425| [-0.26769 -0.28757]
21Feb13_180425| [ 0.28306  0.42430]
21Feb13_180425| [-1.86751  0.58942]
21Feb13_180425| [ 0.03955 -0.29203]
21Feb13_180425| [ 0.53856 -1.32664]
21Feb13_180425| [-1.26262  0.12423]
21Feb13_180425| [-0.95736 -0.39002]
21Feb13_180425| [ 0.31148  0.81849]
21Feb13_180425| [-1.20171 -1.16573]
21Feb13_180425| [-0.43995  0.46443]
21Feb13_180425| [ 0.17542 -0.95269]
21Feb13_180425| [ 0.05423  2.54728]
21Feb13_180425| [-0.41660 -0.62510]
21Feb13_180425| [ 0.48650 -0.12177]
21Feb13_180425| [-0.41604 -0.08118]
21Feb13_180425| [-0.16116  0.68089]
21Feb13_180425| [ 0.58706 -1.30828]
21Feb13_180425| [-0.96782  1.51900]
21Feb13_180425| [ 0.08874 -0.67677]
21Feb13_180425| [-0.68590 -1.49289]
21Feb13_180425| [ 1.08065  2.07463]
21Feb13_180425| [-1.05417  0.71235]
21Feb13_180425| [-0.05213 -0.58554]
21Feb13_180425| [-0.12627 -0.31128]
21Feb13_180425| [ 1.34093 -0.18664]
21Feb13_180425| [-1.30497 -0.40435]
21Feb13_180425| [ 0.68676  0.75508]
21Feb13_180425| [-1.59599 -0.71000]
21Feb13_180425| [ 0.79255  0.47768]
21Feb13_180425| [-0.63359 -0.83681]
21Feb13_180425| [-0.54831  0.03451]
21Feb13_180425| [-0.08075  1.16147]
21Feb13_180425| [ 0.82149 -0.24838]
21Feb13_180425| [-0.83911  0.36663]
21Feb13_180425| [-0.40125 -0.23944]
21Feb13_180425| [-1.82054 -0.17440]
21Feb13_180425| [-0.99986  1.60933]
21Feb13_180425| [-1.83158 -2.24240]
21Feb13_180425| [ 0.04873 -1.02073]
21Feb13_180425| [-0.56204 -0.67282]
21Feb13_180425| [-1.61599  0.79008]
21Feb13_180425| [-1.88676  1.24359]
21Feb13_180425| [ 0.28231  0.49092]
21Feb13_180425| [ 1.80131 -0.95736]
21Feb13_180425| [ 1.10036  0.20309]
21Feb13_180425| [ 0.63629 -0.89126]]
21Feb13_180425|-- Bias --
21Feb13_180425|[ 0.05179 -0.09215]
21Feb13_180425|Layer 1:
21Feb13_180425|-- Config --
21Feb13_180425|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180425|-- Weights --
21Feb13_180425|[[ 0.76236  0.77919 -0.54170]
21Feb13_180425| [ 0.72178 -1.22032 -0.56733]]
21Feb13_180425|-- Bias --
21Feb13_180425|[-0.62552  0.86248 -0.09337]
21Feb13_180425|Layer 2:
21Feb13_180425|-- Config --
21Feb13_180425|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180425|-- Weights --
21Feb13_180425|[[ 0.17631  1.22903  0.28211]
21Feb13_180425| [ 0.23756 -0.52210  0.80113]
21Feb13_180425| [-0.53643 -0.29098  0.14483]]
21Feb13_180425|-- Bias --
21Feb13_180425|[-0.75222  0.38335 -0.29971]
21Feb13_180425|Layer 3:
21Feb13_180425|-- Config --
21Feb13_180425|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180425|-- Weights --
21Feb13_180425|[[0.15542 0.28298]
21Feb13_180425| [0.24110 0.49447]
21Feb13_180425| [0.43948 0.55769]]
21Feb13_180425|-- Bias --
21Feb13_180425|[ 0.53898 -0.03614]
21Feb13_180425|Layer 4:
21Feb13_180425|-- Config --
21Feb13_180425|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180425|-- Weights --
21Feb13_180425|[[-0.57811 -0.38365]
21Feb13_180425| [-0.76354  0.47765]]
21Feb13_180425|-- Bias --
21Feb13_180425|[0.19825 0.26873]
21Feb13_180425|Predicting the validation and test data with the Best final individual.
21Feb13_180433| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_180433|-----------  ------------------  --------------------  ----------
21Feb13_180433|Validation         27.65                  40            0.74427
21Feb13_180433|   Test            23.37                  40            0.78377
21Feb13_180433|-------------------- Test #12 --------------------
21Feb13_180433|Best final individual weights
21Feb13_180433|Individual:
21Feb13_180433|-- Constant hidden layers --
21Feb13_180433|False
21Feb13_180433|Layer 0:
21Feb13_180433|-- Config --
21Feb13_180433|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180433|-- Weights --
21Feb13_180433|[[-0.52757  0.21411]
21Feb13_180433| [-0.93911 -1.17137]
21Feb13_180433| [-0.61957 -0.66375]
21Feb13_180433| [-0.51664 -2.09212]
21Feb13_180433| [ 1.08829 -0.13413]
21Feb13_180433| [-0.25816  0.27802]
21Feb13_180433| [ 0.66354 -0.52361]
21Feb13_180433| [ 1.01133 -0.15515]
21Feb13_180433| [ 0.01483 -0.14014]
21Feb13_180433| [ 0.22676 -0.27499]
21Feb13_180433| [ 0.43593 -2.14033]
21Feb13_180433| [-0.26769 -0.28757]
21Feb13_180433| [ 0.28306  0.42430]
21Feb13_180433| [-1.86751  0.58942]
21Feb13_180433| [ 0.03955 -0.29203]
21Feb13_180433| [ 0.53856 -1.32664]
21Feb13_180433| [-1.26262  0.12423]
21Feb13_180433| [-0.95736 -0.39002]
21Feb13_180433| [ 0.31148  0.81849]
21Feb13_180433| [-1.20171 -1.16573]
21Feb13_180433| [-0.43995  0.46443]
21Feb13_180433| [ 0.17542 -0.95269]
21Feb13_180433| [ 0.05423  2.54728]
21Feb13_180433| [-0.41660 -0.62510]
21Feb13_180433| [ 0.48650 -0.12177]
21Feb13_180433| [-0.41604 -0.08118]
21Feb13_180433| [-0.16116  0.68089]
21Feb13_180433| [ 0.58706 -1.30828]
21Feb13_180433| [-0.96782  1.51900]
21Feb13_180433| [ 0.08874 -0.67677]
21Feb13_180433| [-0.68590 -1.49289]
21Feb13_180433| [ 1.08065  2.07463]
21Feb13_180433| [-1.05417  0.71235]
21Feb13_180433| [-0.05213 -0.58554]
21Feb13_180433| [-0.12627 -0.31128]
21Feb13_180433| [ 1.34093 -0.18664]
21Feb13_180433| [-1.30497 -0.40435]
21Feb13_180433| [ 0.68676  0.75508]
21Feb13_180433| [-1.59599 -0.71000]
21Feb13_180433| [ 0.79255  0.47768]
21Feb13_180433| [-0.63359 -0.83681]
21Feb13_180433| [-0.54831  0.03451]
21Feb13_180433| [-0.08075  1.16147]
21Feb13_180433| [ 0.82149 -0.24838]
21Feb13_180433| [-0.83911  0.36663]
21Feb13_180433| [-0.40125 -0.23944]
21Feb13_180433| [-1.82054 -0.17440]
21Feb13_180433| [-0.99986  1.60933]
21Feb13_180433| [-1.83158 -2.24240]
21Feb13_180433| [ 0.04873 -1.02073]
21Feb13_180433| [-0.56204 -0.67282]
21Feb13_180433| [-1.61599  0.79008]
21Feb13_180433| [-1.88676  1.24359]
21Feb13_180433| [ 0.28231  0.49092]
21Feb13_180433| [ 1.80131 -0.95736]
21Feb13_180433| [ 1.10036  0.20309]
21Feb13_180433| [ 0.63629 -0.89126]]
21Feb13_180433|-- Bias --
21Feb13_180433|[ 0.05179 -0.09215]
21Feb13_180433|Layer 1:
21Feb13_180433|-- Config --
21Feb13_180433|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180433|-- Weights --
21Feb13_180433|[[ 0.76236  0.77919 -0.54170]
21Feb13_180433| [ 0.72178 -1.22032 -0.56733]]
21Feb13_180433|-- Bias --
21Feb13_180433|[-0.62552  0.86248 -0.09337]
21Feb13_180433|Layer 2:
21Feb13_180433|-- Config --
21Feb13_180433|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180433|-- Weights --
21Feb13_180433|[[ 0.17631  1.22903  0.28211]
21Feb13_180433| [ 0.23756 -0.52210  0.80113]
21Feb13_180433| [-0.53643 -0.29098  0.14483]]
21Feb13_180433|-- Bias --
21Feb13_180433|[-0.75222  0.38335 -0.29971]
21Feb13_180433|Layer 3:
21Feb13_180433|-- Config --
21Feb13_180433|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180433|-- Weights --
21Feb13_180433|[[0.15542 0.28298]
21Feb13_180433| [0.24110 0.49447]
21Feb13_180433| [0.43948 0.55769]]
21Feb13_180433|-- Bias --
21Feb13_180433|[ 0.53898 -0.03614]
21Feb13_180433|Layer 4:
21Feb13_180433|-- Config --
21Feb13_180433|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180433|-- Weights --
21Feb13_180433|[[-0.57811 -0.38365]
21Feb13_180433| [-0.76354  0.47765]]
21Feb13_180433|-- Bias --
21Feb13_180433|[0.19825 0.26873]
21Feb13_180433|Predicting the validation and test data with the Best final individual.
21Feb13_180441| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_180441|-----------  ------------------  --------------------  ----------
21Feb13_180441|Validation         29.48                  40            0.74508
21Feb13_180441|   Test            22.07                  40            0.68151
21Feb13_180441|-------------------- Test #13 --------------------
21Feb13_180441|Best final individual weights
21Feb13_180441|Individual:
21Feb13_180441|-- Constant hidden layers --
21Feb13_180441|False
21Feb13_180441|Layer 0:
21Feb13_180441|-- Config --
21Feb13_180441|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180441|-- Weights --
21Feb13_180441|[[-0.52757  0.21411]
21Feb13_180441| [-0.93911 -1.17137]
21Feb13_180441| [-0.61957 -0.66375]
21Feb13_180441| [-0.51664 -2.09212]
21Feb13_180441| [ 1.08829 -0.13413]
21Feb13_180441| [-0.25816  0.27802]
21Feb13_180441| [ 0.66354 -0.52361]
21Feb13_180441| [ 1.01133 -0.15515]
21Feb13_180441| [ 0.01483 -0.14014]
21Feb13_180441| [ 0.22676 -0.27499]
21Feb13_180441| [ 0.43593 -2.14033]
21Feb13_180441| [-0.26769 -0.28757]
21Feb13_180441| [ 0.28306  0.42430]
21Feb13_180441| [-1.86751  0.58942]
21Feb13_180441| [ 0.03955 -0.29203]
21Feb13_180441| [ 0.53856 -1.32664]
21Feb13_180441| [-1.26262  0.12423]
21Feb13_180441| [-0.95736 -0.39002]
21Feb13_180441| [ 0.31148  0.81849]
21Feb13_180441| [-1.20171 -1.16573]
21Feb13_180441| [-0.43995  0.46443]
21Feb13_180441| [ 0.17542 -0.95269]
21Feb13_180441| [ 0.05423  2.54728]
21Feb13_180441| [-0.41660 -0.62510]
21Feb13_180441| [ 0.48650 -0.12177]
21Feb13_180441| [-0.41604 -0.08118]
21Feb13_180441| [-0.16116  0.68089]
21Feb13_180441| [ 0.58706 -1.30828]
21Feb13_180441| [-0.96782  1.51900]
21Feb13_180441| [ 0.08874 -0.67677]
21Feb13_180441| [-0.68590 -1.49289]
21Feb13_180441| [ 1.08065  2.07463]
21Feb13_180441| [-1.05417  0.71235]
21Feb13_180441| [-0.05213 -0.58554]
21Feb13_180441| [-0.12627 -0.31128]
21Feb13_180441| [ 1.34093 -0.18664]
21Feb13_180441| [-1.30497 -0.40435]
21Feb13_180441| [ 0.68676  0.75508]
21Feb13_180441| [-1.59599 -0.71000]
21Feb13_180441| [ 0.79255  0.47768]
21Feb13_180441| [-0.63359 -0.83681]
21Feb13_180441| [-0.54831  0.03451]
21Feb13_180441| [-0.08075  1.16147]
21Feb13_180441| [ 0.82149 -0.24838]
21Feb13_180441| [-0.83911  0.36663]
21Feb13_180441| [-0.40125 -0.23944]
21Feb13_180441| [-1.82054 -0.17440]
21Feb13_180441| [-0.99986  1.60933]
21Feb13_180441| [-1.83158 -2.24240]
21Feb13_180441| [ 0.04873 -1.02073]
21Feb13_180441| [-0.56204 -0.67282]
21Feb13_180441| [-1.61599  0.79008]
21Feb13_180441| [-1.88676  1.24359]
21Feb13_180441| [ 0.28231  0.49092]
21Feb13_180441| [ 1.80131 -0.95736]
21Feb13_180441| [ 1.10036  0.20309]
21Feb13_180441| [ 0.63629 -0.89126]]
21Feb13_180441|-- Bias --
21Feb13_180441|[ 0.05179 -0.09215]
21Feb13_180441|Layer 1:
21Feb13_180441|-- Config --
21Feb13_180441|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180441|-- Weights --
21Feb13_180441|[[ 0.76236  0.77919 -0.54170]
21Feb13_180441| [ 0.72178 -1.22032 -0.56733]]
21Feb13_180441|-- Bias --
21Feb13_180441|[-0.62552  0.86248 -0.09337]
21Feb13_180441|Layer 2:
21Feb13_180441|-- Config --
21Feb13_180441|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180441|-- Weights --
21Feb13_180441|[[ 0.17631  1.22903  0.28211]
21Feb13_180441| [ 0.23756 -0.52210  0.80113]
21Feb13_180441| [-0.53643 -0.29098  0.14483]]
21Feb13_180441|-- Bias --
21Feb13_180441|[-0.75222  0.38335 -0.29971]
21Feb13_180441|Layer 3:
21Feb13_180441|-- Config --
21Feb13_180441|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180441|-- Weights --
21Feb13_180441|[[0.15542 0.28298]
21Feb13_180441| [0.24110 0.49447]
21Feb13_180441| [0.43948 0.55769]]
21Feb13_180441|-- Bias --
21Feb13_180441|[ 0.53898 -0.03614]
21Feb13_180441|Layer 4:
21Feb13_180441|-- Config --
21Feb13_180441|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180441|-- Weights --
21Feb13_180441|[[-0.57811 -0.38365]
21Feb13_180441| [-0.76354  0.47765]]
21Feb13_180441|-- Bias --
21Feb13_180441|[0.19825 0.26873]
21Feb13_180441|Predicting the validation and test data with the Best final individual.
21Feb13_180448| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_180448|-----------  ------------------  --------------------  ----------
21Feb13_180448|Validation         21.22                  40            0.72007
21Feb13_180448|   Test            23.81                  40            0.78357
21Feb13_180448|-------------------- Test #14 --------------------
21Feb13_180448|Best final individual weights
21Feb13_180448|Individual:
21Feb13_180448|-- Constant hidden layers --
21Feb13_180448|False
21Feb13_180448|Layer 0:
21Feb13_180448|-- Config --
21Feb13_180448|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180448|-- Weights --
21Feb13_180448|[[-0.52757  0.21411]
21Feb13_180448| [-0.93911 -1.17137]
21Feb13_180448| [-0.61957 -0.66375]
21Feb13_180448| [-0.51664 -2.09212]
21Feb13_180448| [ 1.08829 -0.13413]
21Feb13_180448| [-0.25816  0.27802]
21Feb13_180448| [ 0.66354 -0.52361]
21Feb13_180448| [ 1.01133 -0.15515]
21Feb13_180448| [ 0.01483 -0.14014]
21Feb13_180448| [ 0.22676 -0.27499]
21Feb13_180448| [ 0.43593 -2.14033]
21Feb13_180448| [-0.26769 -0.28757]
21Feb13_180448| [ 0.28306  0.42430]
21Feb13_180448| [-1.86751  0.58942]
21Feb13_180448| [ 0.03955 -0.29203]
21Feb13_180448| [ 0.53856 -1.32664]
21Feb13_180448| [-1.26262  0.12423]
21Feb13_180448| [-0.95736 -0.39002]
21Feb13_180448| [ 0.31148  0.81849]
21Feb13_180448| [-1.20171 -1.16573]
21Feb13_180448| [-0.43995  0.46443]
21Feb13_180448| [ 0.17542 -0.95269]
21Feb13_180448| [ 0.05423  2.54728]
21Feb13_180448| [-0.41660 -0.62510]
21Feb13_180448| [ 0.48650 -0.12177]
21Feb13_180448| [-0.41604 -0.08118]
21Feb13_180448| [-0.16116  0.68089]
21Feb13_180448| [ 0.58706 -1.30828]
21Feb13_180448| [-0.96782  1.51900]
21Feb13_180448| [ 0.08874 -0.67677]
21Feb13_180448| [-0.68590 -1.49289]
21Feb13_180448| [ 1.08065  2.07463]
21Feb13_180448| [-1.05417  0.71235]
21Feb13_180448| [-0.05213 -0.58554]
21Feb13_180448| [-0.12627 -0.31128]
21Feb13_180448| [ 1.34093 -0.18664]
21Feb13_180448| [-1.30497 -0.40435]
21Feb13_180448| [ 0.68676  0.75508]
21Feb13_180448| [-1.59599 -0.71000]
21Feb13_180448| [ 0.79255  0.47768]
21Feb13_180448| [-0.63359 -0.83681]
21Feb13_180448| [-0.54831  0.03451]
21Feb13_180448| [-0.08075  1.16147]
21Feb13_180448| [ 0.82149 -0.24838]
21Feb13_180448| [-0.83911  0.36663]
21Feb13_180448| [-0.40125 -0.23944]
21Feb13_180448| [-1.82054 -0.17440]
21Feb13_180448| [-0.99986  1.60933]
21Feb13_180448| [-1.83158 -2.24240]
21Feb13_180448| [ 0.04873 -1.02073]
21Feb13_180448| [-0.56204 -0.67282]
21Feb13_180448| [-1.61599  0.79008]
21Feb13_180448| [-1.88676  1.24359]
21Feb13_180448| [ 0.28231  0.49092]
21Feb13_180448| [ 1.80131 -0.95736]
21Feb13_180448| [ 1.10036  0.20309]
21Feb13_180448| [ 0.63629 -0.89126]]
21Feb13_180448|-- Bias --
21Feb13_180448|[ 0.05179 -0.09215]
21Feb13_180448|Layer 1:
21Feb13_180448|-- Config --
21Feb13_180448|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180448|-- Weights --
21Feb13_180448|[[ 0.76236  0.77919 -0.54170]
21Feb13_180448| [ 0.72178 -1.22032 -0.56733]]
21Feb13_180448|-- Bias --
21Feb13_180448|[-0.62552  0.86248 -0.09337]
21Feb13_180448|Layer 2:
21Feb13_180448|-- Config --
21Feb13_180448|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180448|-- Weights --
21Feb13_180448|[[ 0.17631  1.22903  0.28211]
21Feb13_180448| [ 0.23756 -0.52210  0.80113]
21Feb13_180448| [-0.53643 -0.29098  0.14483]]
21Feb13_180448|-- Bias --
21Feb13_180448|[-0.75222  0.38335 -0.29971]
21Feb13_180448|Layer 3:
21Feb13_180448|-- Config --
21Feb13_180448|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180448|-- Weights --
21Feb13_180448|[[0.15542 0.28298]
21Feb13_180448| [0.24110 0.49447]
21Feb13_180448| [0.43948 0.55769]]
21Feb13_180448|-- Bias --
21Feb13_180448|[ 0.53898 -0.03614]
21Feb13_180448|Layer 4:
21Feb13_180448|-- Config --
21Feb13_180448|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_180448|-- Weights --
21Feb13_180448|[[-0.57811 -0.38365]
21Feb13_180448| [-0.76354  0.47765]]
21Feb13_180448|-- Bias --
21Feb13_180448|[0.19825 0.26873]
21Feb13_180448|Predicting the validation and test data with the Best final individual.
21Feb13_180456| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_180456|-----------  ------------------  --------------------  ----------
21Feb13_180456|Validation         23.65                  40            0.81871
21Feb13_180456|   Test            25.46                  40            0.76271
