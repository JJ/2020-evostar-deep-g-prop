2021-02-13 13:28:24.912625: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
21Feb13_132825|Data summary: Train
21Feb13_132825|data.shape = (2300, 57)
21Feb13_132825|labels.shape = (2300,)
21Feb13_132825|Class distribution:
21Feb13_132825|	0 - 1383 (0.60)
21Feb13_132825|	1 - 917 (0.40)
21Feb13_132825|Data summary: Validation
21Feb13_132825|data.shape = (1150, 57)
21Feb13_132825|labels.shape = (1150,)
21Feb13_132825|Class distribution:
21Feb13_132825|	0 - 708 (0.62)
21Feb13_132825|	1 - 442 (0.38)
21Feb13_132825|Data summary: Test
21Feb13_132825|data.shape = (1151, 57)
21Feb13_132825|labels.shape = (1151,)
21Feb13_132825|Class distribution:
21Feb13_132825|	0 - 697 (0.61)
21Feb13_132825|	1 - 454 (0.39)
21Feb13_132825|Selected configuration values
21Feb13_132825|-- Dataset name: spambase3
21Feb13_132825|-- Initial population size: 64
21Feb13_132825|-- Maximun number of generations: 32
21Feb13_132825|-- Neurons per hidden layer range: (2, 20)
21Feb13_132825|-- Hidden layers number range: (1, 3)
21Feb13_132825|-- Crossover probability: 0.5
21Feb13_132825|-- Bias gene mutation probability: 0.2
21Feb13_132825|-- Weights gene mutation probability: 0.75
21Feb13_132825|-- Neuron mutation probability: 0.3
21Feb13_132825|-- Layer mutation probability: 0.3
21Feb13_132825|-- Constant hidden layers: False
21Feb13_132825|-- Seed: 31415
21Feb13_132825|Entering GA
21Feb13_132825|Start the algorithm
2021-02-13 13:28:25.840150: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-13 13:28:25.840670: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-02-13 13:28:25.862834: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-13 13:28:25.863168: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.71GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s
2021-02-13 13:28:25.863184: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-02-13 13:28:25.864766: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-02-13 13:28:25.864798: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-02-13 13:28:25.865340: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-02-13 13:28:25.865479: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-02-13 13:28:25.865549: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-13 13:28:25.865985: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-02-13 13:28:25.866037: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-13 13:28:25.866045: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-02-13 13:28:25.866289: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-02-13 13:28:25.867089: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-13 13:28:25.867109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-13 13:28:25.867113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      
2021-02-13 13:28:25.920094: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-02-13 13:28:25.920440: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3493635000 Hz
/home/jmerelo/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype("int32")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn('`model.predict_classes()` is deprecated and '
21Feb13_133225|-- Generation 1 --
21Feb13_133225|    -- Crossed 0 individual pairs.
21Feb13_133225|    -- Mutated 32 individuals.
21Feb13_133625|    -- Evaluated 64 individuals.
21Feb13_133625|    Summary of generation 1:
21Feb13_133625| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_133625|-----------  ------------------  --------------------  ----------
21Feb13_133625|    Max            39.13                153.00          0.44817
21Feb13_133625|    Avg            38.29                42.67           0.00937
21Feb13_133625|    Min            27.22                 3.00           0.00000
21Feb13_133625|    Std             1.41                36.20           0.05577
21Feb13_133625|   Best            27.22                30.00           0.44817
21Feb13_133625|-- Generation 2 --
21Feb13_133625|    -- Crossed 1 individual pairs.
21Feb13_133625|    -- Mutated 32 individuals.
21Feb13_134023|    -- Evaluated 64 individuals.
21Feb13_134023|    Summary of generation 2:
21Feb13_134023| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_134023|-----------  ------------------  --------------------  ----------
21Feb13_134023|    Max            39.22                132.00          0.57656
21Feb13_134023|    Avg            37.89                29.78           0.02625
21Feb13_134023|    Min            25.65                 2.00           0.00000
21Feb13_134023|    Std             2.59                23.84           0.11348
21Feb13_134023|   Best            25.65                34.00           0.54699
21Feb13_134023|-- Generation 3 --
21Feb13_134023|    -- Crossed 2 individual pairs.
21Feb13_134023|    -- Mutated 32 individuals.
21Feb13_134417|    -- Evaluated 64 individuals.
21Feb13_134417|    Summary of generation 3:
21Feb13_134417| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_134417|-----------  ------------------  --------------------  ----------
21Feb13_134417|    Max            39.04                132.00          0.58991
21Feb13_134417|    Avg            37.63                18.59           0.03467
21Feb13_134417|    Min            24.35                 2.00           0.00000
21Feb13_134417|    Std             2.77                19.90           0.11461
21Feb13_134417|   Best            24.35                22.00           0.58991
21Feb13_134417|-- Generation 4 --
21Feb13_134417|    -- Crossed 2 individual pairs.
21Feb13_134417|    -- Mutated 32 individuals.
21Feb13_134808|    -- Evaluated 64 individuals.
21Feb13_134808|    Summary of generation 4:
21Feb13_134808| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_134808|-----------  ------------------  --------------------  ----------
21Feb13_134808|    Max            38.87                132.00          0.62242
21Feb13_134808|    Avg            37.26                15.69           0.05286
21Feb13_134808|    Min            25.39                 2.00           0.00000
21Feb13_134808|    Std             3.37                21.57           0.14979
21Feb13_134808|   Best            25.39                 3.00           0.54589
21Feb13_134808|-- Generation 5 --
21Feb13_134808|    -- Crossed 4 individual pairs.
21Feb13_134808|    -- Mutated 32 individuals.
21Feb13_135200|    -- Evaluated 64 individuals.
21Feb13_135200|    Summary of generation 5:
21Feb13_135200| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_135200|-----------  ------------------  --------------------  ----------
21Feb13_135200|    Max            47.83                132.00          0.79206
21Feb13_135200|    Avg            37.63                13.73           0.05784
21Feb13_135200|    Min            24.78                 2.00           0.00000
21Feb13_135200|    Std             3.14                23.14           0.16681
21Feb13_135200|   Best            24.78                 3.00           0.57020
21Feb13_135200|-- Generation 6 --
21Feb13_135200|    -- Crossed 4 individual pairs.
21Feb13_135200|    -- Mutated 32 individuals.
21Feb13_135551|    -- Evaluated 64 individuals.
21Feb13_135551|    Summary of generation 6:
21Feb13_135551| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_135551|-----------  ------------------  --------------------  ----------
21Feb13_135551|    Max            38.70                66.00           0.49015
21Feb13_135551|    Avg            37.61                11.69           0.03765
21Feb13_135551|    Min            26.61                 2.00           0.00000
21Feb13_135551|    Std             2.58                12.41           0.10708
21Feb13_135551|   Best            26.61                36.00           0.49015
21Feb13_135551|-- Generation 7 --
21Feb13_135551|    -- Crossed 4 individual pairs.
21Feb13_135551|    -- Mutated 32 individuals.
21Feb13_135942|    -- Evaluated 64 individuals.
21Feb13_135942|    Summary of generation 7:
21Feb13_135942| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_135942|-----------  ------------------  --------------------  ----------
21Feb13_135942|    Max            38.87                75.00           0.74926
21Feb13_135942|    Avg            37.11                12.56           0.07027
21Feb13_135942|    Min            25.39                 2.00           0.00000
21Feb13_135942|    Std             3.10                13.17           0.17216
21Feb13_135942|   Best            25.39                 6.00           0.64620
21Feb13_135942|-- Generation 8 --
21Feb13_135942|    -- Crossed 1 individual pairs.
21Feb13_135942|    -- Mutated 32 individuals.
21Feb13_140335|    -- Evaluated 64 individuals.
21Feb13_140335|    Summary of generation 8:
21Feb13_140335| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_140335|-----------  ------------------  --------------------  ----------
21Feb13_140335|    Max            38.70                52.00           0.61705
21Feb13_140335|    Avg            37.07                13.55           0.06729
21Feb13_140335|    Min            23.74                 2.00           0.00000
21Feb13_140335|    Std             2.88                12.12           0.13484
21Feb13_140335|   Best            23.74                 3.00           0.61705
21Feb13_140335|-- Generation 9 --
21Feb13_140335|    -- Crossed 1 individual pairs.
21Feb13_140335|    -- Mutated 32 individuals.
21Feb13_140726|    -- Evaluated 64 individuals.
21Feb13_140726|    Summary of generation 9:
21Feb13_140726| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_140726|-----------  ------------------  --------------------  ----------
21Feb13_140726|    Max            39.13                50.00           0.80924
21Feb13_140726|    Avg            36.92                14.72           0.08462
21Feb13_140726|    Min            20.96                 2.00           0.00000
21Feb13_140726|    Std             3.52                11.56           0.18650
21Feb13_140726|   Best            20.96                16.00           0.80924
21Feb13_140726|-- Generation 10 --
21Feb13_140726|    -- Crossed 2 individual pairs.
21Feb13_140726|    -- Mutated 32 individuals.
21Feb13_141117|    -- Evaluated 64 individuals.
21Feb13_141117|    Summary of generation 10:
21Feb13_141117| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_141117|-----------  ------------------  --------------------  ----------
21Feb13_141117|    Max            38.96                50.00           0.74611
21Feb13_141117|    Avg            36.35                16.19           0.09576
21Feb13_141117|    Min            25.04                 2.00           0.00000
21Feb13_141117|    Std             3.69                10.86           0.16832
21Feb13_141117|   Best            25.04                20.00           0.54126
21Feb13_141117|-- Generation 11 --
21Feb13_141117|    -- Crossed 2 individual pairs.
21Feb13_141117|    -- Mutated 32 individuals.
21Feb13_141509|    -- Evaluated 64 individuals.
21Feb13_141509|    Summary of generation 11:
21Feb13_141509| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_141509|-----------  ------------------  --------------------  ----------
21Feb13_141509|    Max            39.13                54.00           0.53545
21Feb13_141509|    Avg            36.59                21.28           0.08086
21Feb13_141509|    Min            24.43                 3.00           0.00000
21Feb13_141509|    Std             3.30                13.66           0.13419
21Feb13_141509|   Best            24.43                21.00           0.53545
21Feb13_141509|-- Generation 12 --
21Feb13_141509|    -- Crossed 2 individual pairs.
21Feb13_141509|    -- Mutated 32 individuals.
21Feb13_141901|    -- Evaluated 64 individuals.
21Feb13_141901|    Summary of generation 12:
21Feb13_141901| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_141901|-----------  ------------------  --------------------  ----------
21Feb13_141901|    Max            38.78                52.00           0.57272
21Feb13_141901|    Avg            36.40                21.36           0.09383
21Feb13_141901|    Min            25.74                 3.00           0.00000
21Feb13_141901|    Std             3.49                11.86           0.14563
21Feb13_141901|   Best            25.74                21.00           0.57272
21Feb13_141901|-- Generation 13 --
21Feb13_141901|    -- Crossed 3 individual pairs.
21Feb13_141901|    -- Mutated 32 individuals.
21Feb13_142252|    -- Evaluated 64 individuals.
21Feb13_142252|    Summary of generation 13:
21Feb13_142252| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_142252|-----------  ------------------  --------------------  ----------
21Feb13_142252|    Max            39.83                54.00           0.68701
21Feb13_142252|    Avg            36.31                21.11           0.09501
21Feb13_142252|    Min            20.09                 3.00           0.00000
21Feb13_142252|    Std             3.76                10.50           0.15240
21Feb13_142252|   Best            20.09                21.00           0.68701
21Feb13_142252|-- Generation 14 --
21Feb13_142252|    -- Crossed 2 individual pairs.
21Feb13_142252|    -- Mutated 32 individuals.
21Feb13_142645|    -- Evaluated 64 individuals.
21Feb13_142645|    Summary of generation 14:
21Feb13_142645| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_142645|-----------  ------------------  --------------------  ----------
21Feb13_142645|    Max            38.96                54.00           0.63571
21Feb13_142645|    Avg            36.17                25.25           0.10467
21Feb13_142645|    Min            26.52                 3.00           0.00000
21Feb13_142645|    Std             3.27                12.84           0.14907
21Feb13_142645|   Best            26.52                14.00           0.47643
21Feb13_142645|-- Generation 15 --
21Feb13_142645|    -- Crossed 2 individual pairs.
21Feb13_142645|    -- Mutated 32 individuals.
21Feb13_143038|    -- Evaluated 64 individuals.
21Feb13_143038|    Summary of generation 15:
21Feb13_143038| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_143038|-----------  ------------------  --------------------  ----------
21Feb13_143038|    Max            39.65                52.00           0.67612
21Feb13_143038|    Avg            36.59                22.22           0.08500
21Feb13_143038|    Min            21.22                 2.00           0.00000
21Feb13_143038|    Std             3.52                10.22           0.14353
21Feb13_143038|   Best            21.22                20.00           0.67612
21Feb13_143038|-- Generation 16 --
21Feb13_143038|    -- Crossed 1 individual pairs.
21Feb13_143038|    -- Mutated 32 individuals.
21Feb13_143430|    -- Evaluated 64 individuals.
21Feb13_143430|    Summary of generation 16:
21Feb13_143430| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_143430|-----------  ------------------  --------------------  ----------
21Feb13_143430|    Max            38.96                56.00           0.61611
21Feb13_143430|    Avg            36.86                24.17           0.07520
21Feb13_143430|    Min            22.96                 2.00           0.00000
21Feb13_143430|    Std             3.23                12.54           0.13098
21Feb13_143430|   Best            22.96                20.00           0.61611
21Feb13_143430|-- Generation 17 --
21Feb13_143431|    -- Crossed 1 individual pairs.
21Feb13_143431|    -- Mutated 32 individuals.
21Feb13_143822|    -- Evaluated 64 individuals.
21Feb13_143822|    Summary of generation 17:
21Feb13_143822| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_143822|-----------  ------------------  --------------------  ----------
21Feb13_143822|    Max            39.39                54.00           0.68973
21Feb13_143822|    Avg            36.64                21.23           0.08699
21Feb13_143822|    Min            22.78                 2.00           0.00000
21Feb13_143822|    Std             2.94                10.55           0.12483
21Feb13_143822|   Best            22.78                20.00           0.59318
21Feb13_143822|-- Generation 18 --
21Feb13_143822|    -- Crossed 3 individual pairs.
21Feb13_143822|    -- Mutated 32 individuals.
21Feb13_144215|    -- Evaluated 64 individuals.
21Feb13_144215|    Summary of generation 18:
21Feb13_144215| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_144215|-----------  ------------------  --------------------  ----------
21Feb13_144215|    Max            39.04                54.00           0.61070
21Feb13_144215|    Avg            36.88                24.02           0.07815
21Feb13_144215|    Min            26.78                 2.00           0.00000
21Feb13_144215|    Std             2.38                12.65           0.11505
21Feb13_144215|   Best            26.78                16.00           0.53606
21Feb13_144215|-- Generation 19 --
21Feb13_144215|    -- Crossed 1 individual pairs.
21Feb13_144215|    -- Mutated 32 individuals.
21Feb13_144607|    -- Evaluated 64 individuals.
21Feb13_144607|    Summary of generation 19:
21Feb13_144607| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_144607|-----------  ------------------  --------------------  ----------
21Feb13_144607|    Max            38.70                54.00           0.67820
21Feb13_144607|    Avg            36.15                23.17           0.10030
21Feb13_144607|    Min            23.91                 2.00           0.00000
21Feb13_144607|    Std             3.46                11.86           0.14630
21Feb13_144607|   Best            23.91                19.00           0.67820
21Feb13_144607|-- Generation 20 --
21Feb13_144607|    -- Crossed 4 individual pairs.
21Feb13_144607|    -- Mutated 32 individuals.
21Feb13_144959|    -- Evaluated 64 individuals.
21Feb13_144959|    Summary of generation 20:
21Feb13_144959| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_144959|-----------  ------------------  --------------------  ----------
21Feb13_144959|    Max            38.87                54.00           0.78189
21Feb13_144959|    Avg            35.45                23.05           0.14188
21Feb13_144959|    Min            24.00                 2.00           0.00000
21Feb13_144959|    Std             3.69                11.89           0.17811
21Feb13_144959|   Best            24.00                18.00           0.74650
21Feb13_144959|-- Generation 21 --
21Feb13_144959|    -- Crossed 1 individual pairs.
21Feb13_144959|    -- Mutated 32 individuals.
21Feb13_145351|    -- Evaluated 64 individuals.
21Feb13_145351|    Summary of generation 21:
21Feb13_145351| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_145351|-----------  ------------------  --------------------  ----------
21Feb13_145351|    Max            38.87                50.00           0.79930
21Feb13_145351|    Avg            35.02                20.38           0.16343
21Feb13_145351|    Min            20.87                 2.00           0.00000
21Feb13_145351|    Std             4.29                10.89           0.20777
21Feb13_145351|   Best            20.87                21.00           0.79930
21Feb13_145351|-- Generation 22 --
21Feb13_145351|    -- Crossed 0 individual pairs.
21Feb13_145351|    -- Mutated 32 individuals.
21Feb13_145743|    -- Evaluated 64 individuals.
21Feb13_145743|    Summary of generation 22:
21Feb13_145743| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_145743|-----------  ------------------  --------------------  ----------
21Feb13_145743|    Max            38.78                54.00           0.77519
21Feb13_145743|    Avg            35.61                18.86           0.12846
21Feb13_145743|    Min            24.00                 2.00           0.00000
21Feb13_145743|    Std             3.97                12.53           0.18486
21Feb13_145743|   Best            24.00                 2.00           0.77519
21Feb13_145743|-- Generation 23 --
21Feb13_145743|    -- Crossed 1 individual pairs.
21Feb13_145743|    -- Mutated 32 individuals.
21Feb13_150134|    -- Evaluated 64 individuals.
21Feb13_150134|    Summary of generation 23:
21Feb13_150134| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_150134|-----------  ------------------  --------------------  ----------
21Feb13_150134|    Max            39.48                50.00           0.79058
21Feb13_150134|    Avg            35.58                17.62           0.14460
21Feb13_150134|    Min            22.43                 2.00           0.00000
21Feb13_150134|    Std             3.86                11.08           0.20346
21Feb13_150134|   Best            22.43                20.00           0.77074
21Feb13_150134|-- Generation 24 --
21Feb13_150134|    -- Crossed 0 individual pairs.
21Feb13_150134|    -- Mutated 32 individuals.
21Feb13_150525|    -- Evaluated 64 individuals.
21Feb13_150525|    Summary of generation 24:
21Feb13_150525| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_150525|-----------  ------------------  --------------------  ----------
21Feb13_150525|    Max            39.13                50.00           0.74147
21Feb13_150525|    Avg            35.25                16.86           0.14435
21Feb13_150525|    Min            24.52                 2.00           0.00000
21Feb13_150525|    Std             4.17                11.46           0.19019
21Feb13_150525|   Best            24.52                22.00           0.74147
21Feb13_150525|-- Generation 25 --
21Feb13_150525|    -- Crossed 2 individual pairs.
21Feb13_150525|    -- Mutated 32 individuals.
21Feb13_150915|    -- Evaluated 64 individuals.
21Feb13_150915|    Summary of generation 25:
21Feb13_150915| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_150915|-----------  ------------------  --------------------  ----------
21Feb13_150915|    Max            56.09                56.00           0.77408
21Feb13_150915|    Avg            36.01                16.23           0.13418
21Feb13_150915|    Min            26.00                 2.00           0.00000
21Feb13_150915|    Std             4.01                12.33           0.15586
21Feb13_150915|   Best            26.00                 2.00           0.51539
21Feb13_150915|-- Generation 26 --
21Feb13_150915|    -- Crossed 2 individual pairs.
21Feb13_150915|    -- Mutated 32 individuals.
21Feb13_151308|    -- Evaluated 64 individuals.
21Feb13_151308|    Summary of generation 26:
21Feb13_151308| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_151308|-----------  ------------------  --------------------  ----------
21Feb13_151308|    Max            39.04                52.00           0.62819
21Feb13_151308|    Avg            35.27                16.19           0.14382
21Feb13_151308|    Min            25.13                 2.00           0.00000
21Feb13_151308|    Std             3.85                11.95           0.17492
21Feb13_151308|   Best            25.13                22.00           0.62819
21Feb13_151308|-- Generation 27 --
21Feb13_151308|    -- Crossed 1 individual pairs.
21Feb13_151308|    -- Mutated 32 individuals.
21Feb13_151659|    -- Evaluated 64 individuals.
21Feb13_151659|    Summary of generation 27:
21Feb13_151659| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_151659|-----------  ------------------  --------------------  ----------
21Feb13_151659|    Max            38.78                50.00           0.69941
21Feb13_151659|    Avg            35.19                15.11           0.14479
21Feb13_151659|    Min            23.04                 2.00           0.00000
21Feb13_151659|    Std             4.47                13.88           0.19438
21Feb13_151659|   Best            23.04                 2.00           0.69941
21Feb13_151659|-- Generation 28 --
21Feb13_151659|    -- Crossed 3 individual pairs.
21Feb13_151659|    -- Mutated 32 individuals.
21Feb13_152050|    -- Evaluated 64 individuals.
21Feb13_152050|    Summary of generation 28:
21Feb13_152050| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_152050|-----------  ------------------  --------------------  ----------
21Feb13_152050|    Max            38.96                52.00           0.59614
21Feb13_152050|    Avg            35.74                13.83           0.11484
21Feb13_152050|    Min            25.22                 2.00           0.00000
21Feb13_152050|    Std             3.74                13.33           0.15628
21Feb13_152050|   Best            25.22                 2.00           0.59614
21Feb13_152050|-- Generation 29 --
21Feb13_152050|    -- Crossed 2 individual pairs.
21Feb13_152050|    -- Mutated 32 individuals.
21Feb13_152441|    -- Evaluated 64 individuals.
21Feb13_152441|    Summary of generation 29:
21Feb13_152441| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_152441|-----------  ------------------  --------------------  ----------
21Feb13_152441|    Max            38.70                54.00           0.79318
21Feb13_152441|    Avg            35.50                13.80           0.13446
21Feb13_152441|    Min            23.91                 2.00           0.00000
21Feb13_152441|    Std             3.93                14.12           0.18925
21Feb13_152441|   Best            23.91                10.00           0.79318
21Feb13_152441|-- Generation 30 --
21Feb13_152441|    -- Crossed 1 individual pairs.
21Feb13_152441|    -- Mutated 32 individuals.
21Feb13_152832|    -- Evaluated 64 individuals.
21Feb13_152832|    Summary of generation 30:
21Feb13_152832| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_152832|-----------  ------------------  --------------------  ----------
21Feb13_152832|    Max            38.70                48.00           0.74779
21Feb13_152832|    Avg            34.95                10.41           0.15159
21Feb13_152832|    Min            22.43                 2.00           0.00000
21Feb13_152832|    Std             4.39                 9.02           0.18771
21Feb13_152832|   Best            22.43                 2.00           0.74779
21Feb13_152832|-- Generation 31 --
21Feb13_152832|    -- Crossed 0 individual pairs.
21Feb13_152832|    -- Mutated 32 individuals.
21Feb13_153223|    -- Evaluated 64 individuals.
21Feb13_153223|    Summary of generation 31:
21Feb13_153223| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_153223|-----------  ------------------  --------------------  ----------
21Feb13_153223|    Max            38.61                52.00           0.71304
21Feb13_153223|    Avg            34.88                10.72           0.15481
21Feb13_153223|    Min            21.39                 2.00           0.00000
21Feb13_153223|    Std             4.49                10.18           0.19206
21Feb13_153223|   Best            21.39                20.00           0.63567
21Feb13_153223|-- Generation 32 --
21Feb13_153223|    -- Crossed 2 individual pairs.
21Feb13_153223|    -- Mutated 32 individuals.
21Feb13_153613|    -- Evaluated 64 individuals.
21Feb13_153613|    Summary of generation 32:
21Feb13_153613| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_153613|-----------  ------------------  --------------------  ----------
21Feb13_153613|    Max            38.61                50.00           0.58325
21Feb13_153613|    Avg            34.88                11.20           0.15399
21Feb13_153613|    Min            25.83                 2.00           0.00000
21Feb13_153613|    Std             3.51                11.40           0.14929
21Feb13_153613|   Best            25.83                12.00           0.47631
21Feb13_153613|Best initial individual weights
21Feb13_153613|Individual:
21Feb13_153613|-- Constant hidden layers --
21Feb13_153613|False
21Feb13_153613|Layer 0:
21Feb13_153613|-- Config --
21Feb13_153613|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 15, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153613|-- Weights --
21Feb13_153613|[[ 9.73296e-01 -8.26784e-01 -2.96439e-01 -5.24875e-01 -9.75570e-01
21Feb13_153613|   5.94797e-01  6.56579e-01 -3.55245e-01 -2.06319e-01  7.24525e-02
21Feb13_153613|  -8.18340e-01  3.72301e-01 -8.88903e-01  8.38473e-01 -1.36175e-01]
21Feb13_153613| [ 9.00747e-01 -4.73475e-01 -5.86061e-01 -9.96560e-01 -9.08973e-01
21Feb13_153613|   7.36703e-01 -5.66014e-02 -4.95681e-01 -2.37518e-01  7.36167e-01
21Feb13_153613|   1.18646e-01 -9.34807e-01  1.14774e-01 -1.67031e-01  3.02418e-02]
21Feb13_153613| [-2.75124e-01 -2.99372e-01  2.96611e-03  2.17706e-01  2.22480e-01
21Feb13_153613|   2.85044e-02  3.03819e-01 -3.38706e-02 -2.90173e-01 -2.69699e-01
21Feb13_153613|  -7.85345e-02 -1.49466e-01  3.23384e-01 -1.80370e-01 -2.99972e-01]
21Feb13_153613| [-5.80245e-01  9.85830e-01  1.17641e-03  1.65423e-01 -6.59634e-01
21Feb13_153613|  -3.71185e-01 -7.27571e-01 -1.00209e-01  8.64598e-01 -6.10691e-01
21Feb13_153613|   7.19932e-01  3.21970e-01 -7.00390e-01 -7.10769e-01  2.95705e-01]
21Feb13_153613| [-8.73382e-01  9.76324e-01  8.48430e-02  9.25840e-01 -2.02163e-01
21Feb13_153613|  -1.87887e-01  2.81858e-01  1.43536e-01 -3.05554e-01 -6.69890e-01
21Feb13_153613|   1.58904e-01 -8.97804e-01 -1.32196e-01 -7.37863e-01 -1.90775e-01]
21Feb13_153613| [ 5.44972e-01 -7.61313e-01  4.93506e-01  3.85686e-01 -5.60992e-01
21Feb13_153613|  -4.78222e-01 -5.32042e-01  7.25155e-02 -3.72247e-02  4.27292e-01
21Feb13_153613|   3.62496e-01  2.23487e-01  7.55995e-01  8.53424e-01 -3.57402e-01]
21Feb13_153613| [ 2.69735e-01 -7.35381e-01  8.58039e-01  5.50856e-01 -8.98355e-01
21Feb13_153613|   2.29710e-01 -4.68342e-01  6.32265e-02  1.29601e-02 -8.69018e-01
21Feb13_153613|  -2.73360e-01  2.64992e-01  6.92574e-01 -1.80612e-01 -6.18940e-01]
21Feb13_153613| [ 5.32712e-01 -3.07491e-01 -8.59999e-01 -9.69560e-01  9.74953e-01
21Feb13_153613|   5.11015e-02  4.92610e-01 -7.25292e-01  7.13820e-01 -1.43535e-02
21Feb13_153613|   7.27951e-01  7.71337e-02  8.45383e-01  6.68537e-01 -4.33622e-01]
21Feb13_153613| [-1.09130e-01  5.41333e-01  4.93394e-01  8.63442e-01  8.53343e-01
21Feb13_153613|  -1.12858e-01  7.37356e-01 -4.42087e-02  8.30579e-01  1.38212e-01
21Feb13_153613|   9.88480e-02  7.51784e-01  5.54371e-01  8.47549e-01  8.13372e-02]
21Feb13_153613| [-5.42155e-01 -4.32240e-01 -5.86458e-02 -1.28264e-02  5.78083e-01
21Feb13_153613|   1.68026e-01 -9.11094e-01  4.58106e-01  6.00229e-01  2.17770e-01
21Feb13_153613|   4.34134e-01 -8.53385e-02  4.69495e-01 -2.96878e-01  4.59397e-01]
21Feb13_153613| [-5.68827e-01 -9.10070e-01 -9.04407e-01  7.15505e-01 -1.18063e-01
21Feb13_153613|   2.92277e-03  3.96874e-01 -7.57933e-01  1.39258e-01 -7.48572e-01
21Feb13_153613|   9.76774e-01 -3.96754e-01 -3.75098e-02 -8.37290e-01 -9.68913e-01]
21Feb13_153613| [ 3.85405e-01 -1.66417e-01 -7.72831e-01  5.34828e-01  5.82538e-01
21Feb13_153613|   2.61182e-01 -1.77447e-01 -6.45280e-01 -3.56417e-01 -4.00832e-01
21Feb13_153613|  -9.18095e-01  5.40437e-01  7.49226e-01  3.72730e-01  6.82412e-01]
21Feb13_153613| [-5.90300e-01  5.47573e-01 -2.29506e-02  1.97113e-01 -9.92234e-01
21Feb13_153613|  -4.27465e-01  5.90379e-01  2.70200e-01  3.00202e-01  5.73789e-01
21Feb13_153613|  -2.95641e-01  5.78653e-01 -1.94578e-01  3.61894e-01  6.34740e-02]
21Feb13_153613| [ 2.26425e-01  4.30697e-01 -7.48931e-01  1.34168e-01 -6.17358e-02
21Feb13_153613|   1.86230e-01  7.52588e-01 -3.89451e-01  8.39574e-01  5.82897e-01
21Feb13_153613|  -1.13470e-02 -8.19377e-01 -8.18108e-01  6.24046e-01 -5.54897e-01]
21Feb13_153613| [-5.26836e-01  5.86005e-01 -5.96458e-01 -6.81120e-01  1.84856e-01
21Feb13_153613|   4.96869e-01 -1.31473e-01  4.40657e-01  6.64130e-01  6.22928e-01
21Feb13_153613|  -7.74363e-02 -3.55086e-01 -2.82231e-01  6.46269e-01  1.75388e-01]
21Feb13_153613| [-7.76956e-01 -3.86536e-01  4.36460e-01 -9.92290e-01  7.38722e-02
21Feb13_153613|   7.04992e-01  1.61774e-01 -6.96625e-01 -1.82122e-02  4.77476e-01
21Feb13_153613|   6.36754e-01  1.11465e-01  5.77527e-01  1.58442e-01 -6.62716e-01]
21Feb13_153613| [ 3.47724e-01 -3.90904e-01 -6.29011e-02 -2.04190e-01 -6.92395e-01
21Feb13_153613|  -5.16254e-01  7.11614e-01 -8.77321e-01 -4.47844e-01  7.31159e-01
21Feb13_153613|  -8.28271e-01 -3.51425e-01  6.37538e-01  5.04277e-01  3.92425e-01]
21Feb13_153613| [ 7.75524e-01 -9.01971e-01 -8.17344e-01  9.65231e-01 -2.42290e-01
21Feb13_153613|  -4.48188e-01 -7.58196e-01  1.21021e-01 -4.30787e-01  1.16232e-01
21Feb13_153613|  -1.88406e-01 -3.28890e-01 -8.98977e-01 -3.63500e-02  2.86674e-01]
21Feb13_153613| [-8.40432e-01 -6.71444e-02 -3.73544e-01  1.66693e-01 -8.24864e-01
21Feb13_153613|  -8.87827e-01 -4.18794e-01 -3.81438e-01 -9.71525e-01 -9.80858e-01
21Feb13_153613|   1.13439e-01  2.81032e-01 -4.22822e-01 -2.04687e-01  1.75317e-01]
21Feb13_153613| [-4.20436e-01  2.57572e-01 -3.07821e-01  6.44066e-01  7.91418e-01
21Feb13_153613|  -6.82975e-01  3.42860e-01 -6.44128e-02 -9.34328e-01  7.62391e-02
21Feb13_153613|  -9.59002e-01  8.34106e-02 -8.89504e-01 -1.49882e-01 -1.11396e-01]
21Feb13_153613| [ 6.98833e-01  1.54037e-01  3.14249e-01 -5.01089e-01 -6.44545e-01
21Feb13_153613|   1.55008e-01 -1.94187e-01 -5.94875e-01 -7.36832e-01  8.21613e-02
21Feb13_153613|   3.41441e-02 -4.42761e-02  4.77304e-02 -2.91558e-01  2.88672e-01]
21Feb13_153613| [ 2.48630e-01  5.01011e-01 -6.50631e-01 -6.13626e-02 -9.30021e-01
21Feb13_153613|   5.18612e-01 -4.27695e-01 -5.21728e-01 -2.97082e-01 -9.57096e-01
21Feb13_153613|  -1.21237e-04  6.69464e-01 -6.15966e-01  6.54204e-01  5.66081e-01]
21Feb13_153613| [-9.53841e-01 -8.01340e-01 -9.16434e-01  2.57455e-01 -8.96467e-01
21Feb13_153613|   7.80358e-01  4.63009e-01  5.06015e-01 -3.73053e-01  3.37301e-01
21Feb13_153613|  -2.34600e-01  5.09622e-01 -3.02048e-01 -6.64473e-01 -1.98920e-01]
21Feb13_153613| [-2.18071e-01  2.15106e-01 -9.50319e-01 -9.11332e-01 -9.18482e-01
21Feb13_153613|   1.26622e-01  5.92950e-01  6.93913e-01 -7.25339e-01  2.36405e-01
21Feb13_153613|  -2.83842e-01 -9.08534e-01  2.60791e-01 -4.92172e-01  6.25202e-01]
21Feb13_153613| [ 3.22399e-01  5.30300e-01 -6.82594e-01 -6.29378e-02 -2.78435e-01
21Feb13_153613|   4.91838e-01  2.99825e-02 -8.64897e-01  6.09917e-01  9.09602e-01
21Feb13_153613|   5.44039e-01 -3.00486e-01 -3.32137e-01 -3.21246e-02  8.14287e-01]
21Feb13_153613| [ 9.87171e-01  4.36304e-01  9.80301e-01 -9.56450e-01  5.23598e-01
21Feb13_153613|  -3.00486e-01 -9.81154e-01  6.47157e-01 -6.02031e-01  7.81558e-01
21Feb13_153613|  -2.30610e-01  2.44907e-01  4.19133e-01  2.22724e-01 -8.17960e-01]
21Feb13_153613| [-7.00505e-01  3.02186e-01 -5.61855e-01  6.15549e-01 -4.22791e-01
21Feb13_153613|   3.88411e-01 -5.82917e-01 -7.77882e-01  6.30600e-01 -1.96906e-01
21Feb13_153613|  -3.88054e-02 -5.55807e-01  8.92183e-01  8.21948e-01  1.74197e-01]
21Feb13_153613| [-4.47370e-01  2.05525e-01 -5.62731e-01 -1.98036e-01  2.28871e-01
21Feb13_153613|  -3.83538e-01 -8.13049e-01 -5.91726e-01 -4.19478e-01  7.08680e-01
21Feb13_153613|   2.83808e-01 -7.78897e-01 -5.65193e-01  3.84515e-01 -7.96749e-02]
21Feb13_153613| [-4.81320e-01 -1.73693e-01  3.48146e-01 -9.81670e-01  1.37818e-01
21Feb13_153613|  -2.34945e-01  1.61326e-01 -8.27229e-01 -1.04174e-02 -7.75256e-01
21Feb13_153613|   8.52992e-01 -4.99718e-01 -6.70967e-01 -2.25740e-01 -1.50898e-01]
21Feb13_153613| [ 3.84415e-01 -6.97226e-01 -1.51865e-01  9.18693e-01 -1.77648e-01
21Feb13_153613|   1.22856e-01  8.70082e-01 -6.18862e-01  9.34392e-02 -7.34260e-01
21Feb13_153613|  -5.19661e-01 -9.84020e-01  8.89976e-01 -9.22672e-01 -8.30637e-01]
21Feb13_153613| [-4.54498e-01  9.73784e-01  9.14263e-01 -9.59356e-01  7.62535e-01
21Feb13_153613|   3.81394e-01 -7.75235e-01 -2.75059e-01  7.53859e-01  3.38388e-01
21Feb13_153613|   8.59783e-01  2.10799e-01  3.38360e-01  8.62964e-01 -5.82977e-01]
21Feb13_153613| [ 1.92625e-01 -3.99306e-01  1.07271e-01 -4.51425e-01  4.70392e-01
21Feb13_153613|  -7.65438e-01  6.60993e-01 -8.01258e-01  4.67186e-01 -3.16915e-01
21Feb13_153613|   2.94527e-01 -5.33788e-01 -7.45073e-01 -8.42078e-01 -5.44571e-01]
21Feb13_153613| [-3.62993e-01  1.11266e-01 -5.71362e-01 -3.91574e-01 -9.61148e-01
21Feb13_153613|  -2.90496e-01  8.31183e-01 -3.84938e-01  2.69751e-01 -3.15175e-01
21Feb13_153613|   9.99210e-01 -9.53149e-01 -8.61738e-01  7.70126e-02  5.10691e-01]
21Feb13_153613| [ 8.05352e-01 -4.08977e-01 -9.07560e-01 -8.64653e-01 -1.07789e-01
21Feb13_153613|   2.64140e-01  5.05728e-01  7.48289e-01 -8.65071e-01 -8.18224e-01
21Feb13_153613|   6.78505e-02 -5.06326e-01  1.10690e-01 -8.55440e-01  5.75289e-01]
21Feb13_153613| [ 2.95517e-01 -3.52707e-01 -6.55711e-01  1.07292e-01 -2.91000e-01
21Feb13_153613|  -3.16299e-01  1.98809e-01  5.17179e-01 -9.37755e-01 -6.17104e-01
21Feb13_153613|   7.41318e-01  2.47303e-01  6.90518e-01  3.51857e-01  2.81666e-01]
21Feb13_153613| [ 1.69992e-01  6.04754e-01 -1.32633e-01  6.79534e-01  5.85447e-01
21Feb13_153613|  -6.69632e-01  8.55732e-01 -7.23004e-02  7.71841e-01  5.93699e-01
21Feb13_153613|  -4.01829e-01  2.99000e-01 -2.48420e-01  1.69612e-01  2.61404e-01]
21Feb13_153613| [-4.65263e-01 -5.50757e-01 -2.30908e-02  3.64198e-01  3.79782e-01
21Feb13_153613|  -2.25316e-01  3.04353e-01 -2.00693e-01 -1.18218e-01 -5.52641e-01
21Feb13_153613|   7.10195e-01  8.06878e-01 -5.65174e-01 -4.26162e-01  3.95536e-01]
21Feb13_153613| [-5.61400e-01 -3.19431e-01  2.72779e-01 -1.29018e-01  7.70589e-02
21Feb13_153613|   3.21503e-01 -5.90943e-01  4.24158e-01 -7.05493e-01  5.09745e-01
21Feb13_153613|  -2.41282e-01  4.55611e-01  7.72834e-01 -9.97347e-01 -8.58771e-01]
21Feb13_153613| [-5.46366e-01 -4.86772e-01 -8.62551e-01  7.62475e-01 -1.98789e-03
21Feb13_153613|  -1.56016e-01  3.51919e-01  2.74028e-01 -9.67446e-01  4.31075e-01
21Feb13_153613|  -4.27418e-01 -3.50042e-01 -1.95930e-01 -2.47653e-01  7.98394e-01]
21Feb13_153613| [ 2.03791e-01  9.03027e-01  9.67784e-01 -4.00270e-02 -2.59716e-01
21Feb13_153613|  -7.18872e-01  9.82093e-01  2.10782e-01  9.91966e-01  7.67815e-01
21Feb13_153613|  -3.25024e-01  5.85259e-01 -2.21643e-01 -1.67125e-02  9.36688e-01]
21Feb13_153613| [ 3.16211e-01  9.76470e-01  7.94325e-01 -9.00416e-01  6.98898e-01
21Feb13_153613|  -8.42106e-01  6.75991e-01 -6.32115e-02 -3.58262e-01  2.18246e-01
21Feb13_153613|  -4.13471e-01  9.79392e-02  4.02862e-01  8.14727e-01 -7.43809e-01]
21Feb13_153613| [-4.14597e-01  7.51673e-01  8.43107e-01 -8.56637e-01  2.01330e-01
21Feb13_153613|   5.15009e-01  5.18579e-01  3.77743e-01 -4.70931e-01  8.27614e-01
21Feb13_153613|  -1.84439e-01 -5.43885e-01 -6.03771e-01  1.66381e-01 -2.62433e-01]
21Feb13_153613| [-3.30904e-01 -8.97996e-01  5.59354e-01  9.82660e-01  4.72646e-01
21Feb13_153613|  -3.88086e-01 -3.61082e-01 -3.33936e-01  8.38158e-01  1.00179e-01
21Feb13_153613|   1.36844e-01 -9.95933e-01  6.20488e-01 -6.12446e-01 -2.16831e-01]
21Feb13_153613| [ 9.34249e-01  9.58289e-01 -5.59786e-01  2.63487e-01  3.40624e-01
21Feb13_153613|  -8.82567e-01 -1.87162e-01  9.71567e-01 -1.62228e-01 -5.14816e-02
21Feb13_153613|  -6.15566e-01 -2.21997e-01 -6.32714e-01  3.35681e-01 -7.22899e-01]
21Feb13_153613| [ 1.81650e-01  5.38812e-01 -5.84369e-01  1.83511e-01 -4.73145e-01
21Feb13_153613|   3.69120e-01 -6.10032e-01  5.04085e-01  6.79257e-01  6.97438e-01
21Feb13_153613|   9.97907e-01  3.05666e-01  4.40567e-01  9.43295e-01 -9.02163e-01]
21Feb13_153613| [-1.70947e-01  6.56286e-02 -7.70618e-01  7.44355e-01  6.43106e-01
21Feb13_153613|  -9.22310e-01 -9.79288e-01 -3.81965e-01  3.86344e-01  1.77963e-01
21Feb13_153613|  -3.30390e-01  7.61288e-01  3.33913e-01  5.64535e-01 -5.40325e-01]
21Feb13_153613| [-9.32116e-01  9.90939e-01 -3.30869e-01 -4.27293e-01  7.10723e-01
21Feb13_153613|  -2.31364e-01 -3.76768e-01 -9.93003e-01 -6.60679e-01  8.88879e-01
21Feb13_153613|  -6.39983e-02  1.51892e-01  8.99858e-01  8.00668e-01 -2.98412e-01]
21Feb13_153613| [-2.10118e-01  6.98032e-01  9.37825e-01  8.81575e-01  4.77957e-01
21Feb13_153613|  -9.19276e-01  8.17147e-01  5.26491e-01  4.95066e-01 -8.77804e-01
21Feb13_153613|   1.84540e-01  7.53370e-01 -8.47736e-01 -3.26258e-01  2.71438e-01]
21Feb13_153613| [-7.34106e-01  5.52282e-02  1.81606e-01 -1.03917e-01 -9.16647e-01
21Feb13_153613|  -5.73562e-01  5.39510e-01  1.66977e-01  4.48250e-01 -3.24674e-01
21Feb13_153613|   1.39795e-01  2.34226e-01  4.90799e-01 -7.05583e-01  7.14680e-01]
21Feb13_153613| [-8.37392e-01 -4.18274e-02 -4.14411e-01  4.09715e-01  7.44756e-01
21Feb13_153613|  -7.58552e-01 -8.70333e-01 -6.49756e-01  8.63765e-01 -4.23482e-01
21Feb13_153613|   7.87457e-01 -9.43614e-01  4.77426e-01  6.69989e-01  2.31675e-01]
21Feb13_153613| [-7.69917e-01  2.98477e-01 -9.92047e-01  3.57645e-01  3.18108e-01
21Feb13_153613|   3.05468e-01  5.89527e-01 -1.31507e-01 -8.62127e-01  7.60717e-01
21Feb13_153613|  -5.18226e-01  4.94369e-01 -8.24036e-01 -4.43348e-01 -1.55927e-01]
21Feb13_153613| [ 9.10501e-01 -7.45959e-03 -3.28250e-01 -3.48338e-01  1.64135e-01
21Feb13_153613|  -8.02631e-02  4.22565e-01 -8.42164e-01  3.89676e-01  5.80955e-01
21Feb13_153613|   9.83555e-01  6.38621e-01 -1.00576e-01 -7.42125e-01  7.03190e-01]
21Feb13_153613| [-1.71055e-01  1.25462e-01  3.41395e-01  1.66074e-01 -4.20132e-01
21Feb13_153613|  -7.62667e-01 -6.36091e-01  1.46176e-01 -1.03210e-01 -5.38815e-01
21Feb13_153613|   5.96929e-01 -7.47086e-01  3.78571e-02  4.13885e-01  4.94247e-01]
21Feb13_153613| [-3.35399e-02  9.35145e-01  8.04748e-01 -4.71015e-01  1.19204e-01
21Feb13_153613|  -4.47124e-02  3.23368e-01 -8.61360e-02  9.04695e-03 -2.16230e-01
21Feb13_153613|   9.73383e-03  6.40028e-02 -7.75899e-01  7.42213e-01 -2.41969e-01]
21Feb13_153613| [-4.07810e-01  5.70924e-01 -6.72329e-01 -5.14381e-01 -6.52092e-01
21Feb13_153613|  -7.42952e-01 -3.09589e-01 -9.56182e-01  9.43312e-01  5.64870e-01
21Feb13_153613|   6.42553e-01  7.94006e-01 -3.78536e-01  8.42088e-01 -4.76981e-01]
21Feb13_153613| [ 6.10318e-01 -5.75354e-01  3.73758e-01 -7.73392e-01 -9.60833e-01
21Feb13_153613|   4.27903e-01 -9.41218e-01 -6.94203e-01  6.64921e-01  2.08771e-01
21Feb13_153613|   9.91458e-01 -7.05600e-01 -4.80987e-01 -5.69879e-01 -6.07920e-01]
21Feb13_153613| [ 5.91649e-01 -4.92879e-02 -3.44790e-01 -4.70337e-01  4.26548e-01
21Feb13_153613|  -1.62878e-01 -2.02342e-01  4.02378e-01  6.11021e-01  3.01335e-01
21Feb13_153613|   4.01714e-01 -1.12789e-01  5.33867e-01 -2.31753e-01  7.09983e-01]]
21Feb13_153613|-- Bias --
21Feb13_153613|[-0.78506  0.16228 -0.33422 -0.02819  0.17937  0.59381 -0.35607  0.98170
21Feb13_153613|  0.84415 -0.36809  0.88118  0.00344 -0.36932  0.87305 -0.91166]
21Feb13_153613|Layer 1:
21Feb13_153613|-- Config --
21Feb13_153613|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 15], 'dtype': 'float32', 'units': 10, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153613|-- Weights --
21Feb13_153613|[[ 0.91951  0.13760  0.93226 -0.96100  0.36703 -0.91847  0.02090 -0.91229
21Feb13_153613|  -0.78451  0.42787]
21Feb13_153613| [ 0.18072 -0.99875 -0.90672  0.46909  0.10174 -0.28361 -0.76657 -0.44411
21Feb13_153613|   0.01587 -0.08012]
21Feb13_153613| [-0.52522  0.57842  0.64217 -0.58067  0.73633  0.43445  0.81842  0.10316
21Feb13_153613|   0.96829 -0.65906]
21Feb13_153613| [-0.74083 -0.67462 -0.56811 -0.28798 -0.39432  0.28098  0.72626 -0.36612
21Feb13_153613|  -0.96927 -0.08040]
21Feb13_153613| [ 0.21210 -0.13397 -0.84942  0.54712 -0.03219 -0.92481 -0.98810  0.89079
21Feb13_153613|   0.31637  0.53136]
21Feb13_153613| [-0.18729 -0.69744 -0.16173 -0.93613  0.96262  0.00792 -0.95445  0.32042
21Feb13_153613|  -0.36467 -0.87315]
21Feb13_153613| [-0.04314  0.07497  0.43518 -0.80082  0.93585  0.10181  0.30618  0.41458
21Feb13_153613|   0.98098 -0.73301]
21Feb13_153613| [-0.87685  0.20483  0.84988 -0.51961  0.88167  0.81532 -0.93018  0.13207
21Feb13_153613|   0.15465 -0.81578]
21Feb13_153613| [ 0.09921 -0.76754 -0.49733  0.81089  0.68214 -0.36243  0.59439 -0.15764
21Feb13_153613|  -0.74059 -0.05954]
21Feb13_153613| [-0.07392  0.53340  0.82207 -0.72043  0.38000  0.03960 -0.07042  0.29536
21Feb13_153613|   0.95278 -0.00530]
21Feb13_153613| [ 0.92473 -0.52802 -0.20280 -0.39430  0.48632  0.43274 -0.61715  0.12507
21Feb13_153613|  -0.54846 -0.46933]
21Feb13_153613| [ 0.91914  0.92132 -0.40327  0.08595  0.31134 -0.46791  0.23914  0.06850
21Feb13_153613|   0.84229  0.43934]
21Feb13_153613| [-0.04235  0.97296 -0.83341  0.13476  0.13764  0.94126 -0.34097 -0.51874
21Feb13_153613|  -0.61301  0.79707]
21Feb13_153613| [ 0.04655  0.28131 -0.46598  0.40417  0.08962  0.41710  0.97629 -0.28989
21Feb13_153613|  -0.23680 -0.34164]
21Feb13_153613| [ 0.78000 -0.40552 -0.20550  0.20903  0.41907  0.01739 -0.35840 -0.00938
21Feb13_153613|   0.63674 -0.15946]]
21Feb13_153613|-- Bias --
21Feb13_153613|[-0.79083  0.37148 -0.23368 -0.84856 -0.81550 -0.13297 -0.70006  0.83504
21Feb13_153613|  0.92083 -0.68777]
21Feb13_153613|Layer 2:
21Feb13_153613|-- Config --
21Feb13_153613|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 10], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153613|-- Weights --
21Feb13_153613|[[-0.87117 -0.98023]
21Feb13_153613| [-0.13253  0.72532]
21Feb13_153613| [-0.88656 -0.22166]
21Feb13_153613| [ 0.38520 -0.85873]
21Feb13_153613| [-0.98768 -0.34253]
21Feb13_153613| [-0.45654 -0.72139]
21Feb13_153613| [-0.55069  0.70280]
21Feb13_153613| [ 0.50509  0.57348]
21Feb13_153613| [ 0.16174  0.84480]
21Feb13_153613| [-0.22560 -0.23581]]
21Feb13_153613|-- Bias --
21Feb13_153613|[-0.53578  0.46638]
21Feb13_153613|Predicting the validation and test data with the Best initial individual.
21Feb13_153621| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_153621|-----------  ------------------  --------------------  ----------
21Feb13_153621|Validation         38.43                  50            0.00000
21Feb13_153621|   Test            39.44                  50            0.00000
21Feb13_153621|-------------------- Test #0 --------------------
21Feb13_153621|Best final individual weights
21Feb13_153621|Individual:
21Feb13_153621|-- Constant hidden layers --
21Feb13_153621|False
21Feb13_153621|Layer 0:
21Feb13_153621|-- Config --
21Feb13_153621|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153621|-- Weights --
21Feb13_153621|[[ 0.38713  2.42063 -0.81233]
21Feb13_153621| [ 0.46584  0.21781 -1.47469]
21Feb13_153621| [ 0.52524  0.25286 -0.75848]
21Feb13_153621| [ 1.05419  0.14503  0.85689]
21Feb13_153621| [-1.80529 -1.45880 -1.06493]
21Feb13_153621| [-0.14918 -1.96139 -1.08659]
21Feb13_153621| [ 1.04503 -0.35673 -0.78110]
21Feb13_153621| [-0.66658  1.37377 -0.34096]
21Feb13_153621| [ 1.52793 -0.71748  1.91379]
21Feb13_153621| [ 0.91559  0.64119  0.67131]
21Feb13_153621| [-0.54570 -1.45433  0.16551]
21Feb13_153621| [ 0.44489 -1.60656  0.63474]
21Feb13_153621| [-0.22650 -0.63288  0.57099]
21Feb13_153621| [ 0.44326  0.45152 -0.51536]
21Feb13_153621| [ 1.40311 -0.66651  0.51698]
21Feb13_153621| [ 1.50925  0.09394  0.01281]
21Feb13_153621| [-1.76743 -1.28362 -0.72095]
21Feb13_153621| [-0.33819 -1.05380 -0.75191]
21Feb13_153621| [-0.40027 -0.59070 -1.35452]
21Feb13_153621| [-0.54297  1.55915  0.23082]
21Feb13_153621| [-0.86819 -1.75993 -1.07029]
21Feb13_153621| [ 1.30716  0.60079  0.37201]
21Feb13_153621| [-1.47537 -2.19202  1.41716]
21Feb13_153621| [ 1.31558 -0.88044  0.04700]
21Feb13_153621| [-2.05456  0.34059 -1.64271]
21Feb13_153621| [-1.97535  1.71428  0.44055]
21Feb13_153621| [ 0.68070  0.31593  0.25745]
21Feb13_153621| [-0.67951  0.91202 -1.61528]
21Feb13_153621| [ 0.96970  0.68426  0.90910]
21Feb13_153621| [ 0.50563 -1.36234 -0.15913]
21Feb13_153621| [-0.18236 -0.09802  0.32229]
21Feb13_153621| [-0.55016 -0.25396  1.79019]
21Feb13_153621| [-1.25899  0.21076  0.55796]
21Feb13_153621| [-1.01640  1.44683 -0.99457]
21Feb13_153621| [-1.00496  1.79390 -0.53071]
21Feb13_153621| [ 0.15909  1.13690 -0.26700]
21Feb13_153621| [ 0.64458  0.48383  0.79797]
21Feb13_153621| [ 0.18767 -1.17443 -1.18586]
21Feb13_153621| [-0.87376 -0.46862 -0.73299]
21Feb13_153621| [-0.76586 -0.54795  1.67859]
21Feb13_153621| [ 0.85147  0.44981 -0.14231]
21Feb13_153621| [ 1.09911  0.31086 -0.91574]
21Feb13_153621| [-1.62543  0.32096  0.91669]
21Feb13_153621| [-1.16200 -0.04002  0.12671]
21Feb13_153621| [-0.35027 -0.61376  0.47083]
21Feb13_153621| [-0.89940  0.17872 -0.52839]
21Feb13_153621| [-1.94942  0.35467 -1.54599]
21Feb13_153621| [ 0.00901  0.85725 -0.40270]
21Feb13_153621| [ 0.56098 -0.26406 -0.53039]
21Feb13_153621| [-0.76616 -1.12136  0.79042]
21Feb13_153621| [-0.13595  0.39278 -1.17800]
21Feb13_153621| [ 0.89288  0.31535 -0.09279]
21Feb13_153621| [ 0.18309 -0.96295 -0.17588]
21Feb13_153621| [ 0.75221  1.37401 -0.89781]
21Feb13_153621| [-0.70757  0.35167 -0.74607]
21Feb13_153621| [ 0.86116  0.60042 -1.51156]
21Feb13_153621| [-0.43082 -1.19351 -0.51187]]
21Feb13_153621|-- Bias --
21Feb13_153621|[ 1.07104 -1.07737  0.83107]
21Feb13_153621|Layer 1:
21Feb13_153621|-- Config --
21Feb13_153621|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153621|-- Weights --
21Feb13_153621|[[ 0.38076 -1.33247  1.12544]
21Feb13_153621| [ 0.73925 -1.15289  0.84060]
21Feb13_153621| [-1.05371 -0.14959  1.24449]]
21Feb13_153621|-- Bias --
21Feb13_153621|[ 0.20502 -0.24416 -0.80573]
21Feb13_153621|Layer 2:
21Feb13_153621|-- Config --
21Feb13_153621|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153621|-- Weights --
21Feb13_153621|[[-1.62327  0.06666]
21Feb13_153621| [ 1.19291 -1.80974]
21Feb13_153621| [ 0.60957 -0.04413]]
21Feb13_153621|-- Bias --
21Feb13_153621|[ 0.14193 -0.78289]
21Feb13_153621|Predicting the validation and test data with the Best final individual.
21Feb13_153628| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_153628|-----------  ------------------  --------------------  ----------
21Feb13_153628|Validation         25.91                  12            0.59568
21Feb13_153628|   Test            30.93                  12            0.31091
21Feb13_153628|-------------------- Test #1 --------------------
21Feb13_153628|Best final individual weights
21Feb13_153628|Individual:
21Feb13_153628|-- Constant hidden layers --
21Feb13_153628|False
21Feb13_153628|Layer 0:
21Feb13_153628|-- Config --
21Feb13_153628|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153628|-- Weights --
21Feb13_153628|[[ 0.38713  2.42063 -0.81233]
21Feb13_153628| [ 0.46584  0.21781 -1.47469]
21Feb13_153628| [ 0.52524  0.25286 -0.75848]
21Feb13_153628| [ 1.05419  0.14503  0.85689]
21Feb13_153628| [-1.80529 -1.45880 -1.06493]
21Feb13_153628| [-0.14918 -1.96139 -1.08659]
21Feb13_153628| [ 1.04503 -0.35673 -0.78110]
21Feb13_153628| [-0.66658  1.37377 -0.34096]
21Feb13_153628| [ 1.52793 -0.71748  1.91379]
21Feb13_153628| [ 0.91559  0.64119  0.67131]
21Feb13_153628| [-0.54570 -1.45433  0.16551]
21Feb13_153628| [ 0.44489 -1.60656  0.63474]
21Feb13_153628| [-0.22650 -0.63288  0.57099]
21Feb13_153628| [ 0.44326  0.45152 -0.51536]
21Feb13_153628| [ 1.40311 -0.66651  0.51698]
21Feb13_153628| [ 1.50925  0.09394  0.01281]
21Feb13_153628| [-1.76743 -1.28362 -0.72095]
21Feb13_153628| [-0.33819 -1.05380 -0.75191]
21Feb13_153628| [-0.40027 -0.59070 -1.35452]
21Feb13_153628| [-0.54297  1.55915  0.23082]
21Feb13_153628| [-0.86819 -1.75993 -1.07029]
21Feb13_153628| [ 1.30716  0.60079  0.37201]
21Feb13_153628| [-1.47537 -2.19202  1.41716]
21Feb13_153628| [ 1.31558 -0.88044  0.04700]
21Feb13_153628| [-2.05456  0.34059 -1.64271]
21Feb13_153628| [-1.97535  1.71428  0.44055]
21Feb13_153628| [ 0.68070  0.31593  0.25745]
21Feb13_153628| [-0.67951  0.91202 -1.61528]
21Feb13_153628| [ 0.96970  0.68426  0.90910]
21Feb13_153628| [ 0.50563 -1.36234 -0.15913]
21Feb13_153628| [-0.18236 -0.09802  0.32229]
21Feb13_153628| [-0.55016 -0.25396  1.79019]
21Feb13_153628| [-1.25899  0.21076  0.55796]
21Feb13_153628| [-1.01640  1.44683 -0.99457]
21Feb13_153628| [-1.00496  1.79390 -0.53071]
21Feb13_153628| [ 0.15909  1.13690 -0.26700]
21Feb13_153628| [ 0.64458  0.48383  0.79797]
21Feb13_153628| [ 0.18767 -1.17443 -1.18586]
21Feb13_153628| [-0.87376 -0.46862 -0.73299]
21Feb13_153628| [-0.76586 -0.54795  1.67859]
21Feb13_153628| [ 0.85147  0.44981 -0.14231]
21Feb13_153628| [ 1.09911  0.31086 -0.91574]
21Feb13_153628| [-1.62543  0.32096  0.91669]
21Feb13_153628| [-1.16200 -0.04002  0.12671]
21Feb13_153628| [-0.35027 -0.61376  0.47083]
21Feb13_153628| [-0.89940  0.17872 -0.52839]
21Feb13_153628| [-1.94942  0.35467 -1.54599]
21Feb13_153628| [ 0.00901  0.85725 -0.40270]
21Feb13_153628| [ 0.56098 -0.26406 -0.53039]
21Feb13_153628| [-0.76616 -1.12136  0.79042]
21Feb13_153628| [-0.13595  0.39278 -1.17800]
21Feb13_153628| [ 0.89288  0.31535 -0.09279]
21Feb13_153628| [ 0.18309 -0.96295 -0.17588]
21Feb13_153628| [ 0.75221  1.37401 -0.89781]
21Feb13_153628| [-0.70757  0.35167 -0.74607]
21Feb13_153628| [ 0.86116  0.60042 -1.51156]
21Feb13_153628| [-0.43082 -1.19351 -0.51187]]
21Feb13_153628|-- Bias --
21Feb13_153628|[ 1.07104 -1.07737  0.83107]
21Feb13_153628|Layer 1:
21Feb13_153628|-- Config --
21Feb13_153628|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153628|-- Weights --
21Feb13_153628|[[ 0.38076 -1.33247  1.12544]
21Feb13_153628| [ 0.73925 -1.15289  0.84060]
21Feb13_153628| [-1.05371 -0.14959  1.24449]]
21Feb13_153628|-- Bias --
21Feb13_153628|[ 0.20502 -0.24416 -0.80573]
21Feb13_153628|Layer 2:
21Feb13_153628|-- Config --
21Feb13_153628|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153628|-- Weights --
21Feb13_153628|[[-1.62327  0.06666]
21Feb13_153628| [ 1.19291 -1.80974]
21Feb13_153628| [ 0.60957 -0.04413]]
21Feb13_153628|-- Bias --
21Feb13_153628|[ 0.14193 -0.78289]
21Feb13_153628|Predicting the validation and test data with the Best final individual.
21Feb13_153636| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_153636|-----------  ------------------  --------------------  ----------
21Feb13_153636|Validation         38.43                  12            0.00000
21Feb13_153636|   Test            39.44                  12            0.00000
21Feb13_153636|-------------------- Test #2 --------------------
21Feb13_153636|Best final individual weights
21Feb13_153636|Individual:
21Feb13_153636|-- Constant hidden layers --
21Feb13_153636|False
21Feb13_153636|Layer 0:
21Feb13_153636|-- Config --
21Feb13_153636|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153636|-- Weights --
21Feb13_153636|[[ 0.38713  2.42063 -0.81233]
21Feb13_153636| [ 0.46584  0.21781 -1.47469]
21Feb13_153636| [ 0.52524  0.25286 -0.75848]
21Feb13_153636| [ 1.05419  0.14503  0.85689]
21Feb13_153636| [-1.80529 -1.45880 -1.06493]
21Feb13_153636| [-0.14918 -1.96139 -1.08659]
21Feb13_153636| [ 1.04503 -0.35673 -0.78110]
21Feb13_153636| [-0.66658  1.37377 -0.34096]
21Feb13_153636| [ 1.52793 -0.71748  1.91379]
21Feb13_153636| [ 0.91559  0.64119  0.67131]
21Feb13_153636| [-0.54570 -1.45433  0.16551]
21Feb13_153636| [ 0.44489 -1.60656  0.63474]
21Feb13_153636| [-0.22650 -0.63288  0.57099]
21Feb13_153636| [ 0.44326  0.45152 -0.51536]
21Feb13_153636| [ 1.40311 -0.66651  0.51698]
21Feb13_153636| [ 1.50925  0.09394  0.01281]
21Feb13_153636| [-1.76743 -1.28362 -0.72095]
21Feb13_153636| [-0.33819 -1.05380 -0.75191]
21Feb13_153636| [-0.40027 -0.59070 -1.35452]
21Feb13_153636| [-0.54297  1.55915  0.23082]
21Feb13_153636| [-0.86819 -1.75993 -1.07029]
21Feb13_153636| [ 1.30716  0.60079  0.37201]
21Feb13_153636| [-1.47537 -2.19202  1.41716]
21Feb13_153636| [ 1.31558 -0.88044  0.04700]
21Feb13_153636| [-2.05456  0.34059 -1.64271]
21Feb13_153636| [-1.97535  1.71428  0.44055]
21Feb13_153636| [ 0.68070  0.31593  0.25745]
21Feb13_153636| [-0.67951  0.91202 -1.61528]
21Feb13_153636| [ 0.96970  0.68426  0.90910]
21Feb13_153636| [ 0.50563 -1.36234 -0.15913]
21Feb13_153636| [-0.18236 -0.09802  0.32229]
21Feb13_153636| [-0.55016 -0.25396  1.79019]
21Feb13_153636| [-1.25899  0.21076  0.55796]
21Feb13_153636| [-1.01640  1.44683 -0.99457]
21Feb13_153636| [-1.00496  1.79390 -0.53071]
21Feb13_153636| [ 0.15909  1.13690 -0.26700]
21Feb13_153636| [ 0.64458  0.48383  0.79797]
21Feb13_153636| [ 0.18767 -1.17443 -1.18586]
21Feb13_153636| [-0.87376 -0.46862 -0.73299]
21Feb13_153636| [-0.76586 -0.54795  1.67859]
21Feb13_153636| [ 0.85147  0.44981 -0.14231]
21Feb13_153636| [ 1.09911  0.31086 -0.91574]
21Feb13_153636| [-1.62543  0.32096  0.91669]
21Feb13_153636| [-1.16200 -0.04002  0.12671]
21Feb13_153636| [-0.35027 -0.61376  0.47083]
21Feb13_153636| [-0.89940  0.17872 -0.52839]
21Feb13_153636| [-1.94942  0.35467 -1.54599]
21Feb13_153636| [ 0.00901  0.85725 -0.40270]
21Feb13_153636| [ 0.56098 -0.26406 -0.53039]
21Feb13_153636| [-0.76616 -1.12136  0.79042]
21Feb13_153636| [-0.13595  0.39278 -1.17800]
21Feb13_153636| [ 0.89288  0.31535 -0.09279]
21Feb13_153636| [ 0.18309 -0.96295 -0.17588]
21Feb13_153636| [ 0.75221  1.37401 -0.89781]
21Feb13_153636| [-0.70757  0.35167 -0.74607]
21Feb13_153636| [ 0.86116  0.60042 -1.51156]
21Feb13_153636| [-0.43082 -1.19351 -0.51187]]
21Feb13_153636|-- Bias --
21Feb13_153636|[ 1.07104 -1.07737  0.83107]
21Feb13_153636|Layer 1:
21Feb13_153636|-- Config --
21Feb13_153636|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153636|-- Weights --
21Feb13_153636|[[ 0.38076 -1.33247  1.12544]
21Feb13_153636| [ 0.73925 -1.15289  0.84060]
21Feb13_153636| [-1.05371 -0.14959  1.24449]]
21Feb13_153636|-- Bias --
21Feb13_153636|[ 0.20502 -0.24416 -0.80573]
21Feb13_153636|Layer 2:
21Feb13_153636|-- Config --
21Feb13_153636|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153636|-- Weights --
21Feb13_153636|[[-1.62327  0.06666]
21Feb13_153636| [ 1.19291 -1.80974]
21Feb13_153636| [ 0.60957 -0.04413]]
21Feb13_153636|-- Bias --
21Feb13_153636|[ 0.14193 -0.78289]
21Feb13_153636|Predicting the validation and test data with the Best final individual.
21Feb13_153643| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_153643|-----------  ------------------  --------------------  ----------
21Feb13_153643|Validation         38.43                  12            0.00000
21Feb13_153643|   Test            39.44                  12            0.00000
21Feb13_153643|-------------------- Test #3 --------------------
21Feb13_153643|Best final individual weights
21Feb13_153643|Individual:
21Feb13_153643|-- Constant hidden layers --
21Feb13_153643|False
21Feb13_153643|Layer 0:
21Feb13_153643|-- Config --
21Feb13_153643|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153643|-- Weights --
21Feb13_153643|[[ 0.38713  2.42063 -0.81233]
21Feb13_153643| [ 0.46584  0.21781 -1.47469]
21Feb13_153643| [ 0.52524  0.25286 -0.75848]
21Feb13_153643| [ 1.05419  0.14503  0.85689]
21Feb13_153643| [-1.80529 -1.45880 -1.06493]
21Feb13_153643| [-0.14918 -1.96139 -1.08659]
21Feb13_153643| [ 1.04503 -0.35673 -0.78110]
21Feb13_153643| [-0.66658  1.37377 -0.34096]
21Feb13_153643| [ 1.52793 -0.71748  1.91379]
21Feb13_153643| [ 0.91559  0.64119  0.67131]
21Feb13_153643| [-0.54570 -1.45433  0.16551]
21Feb13_153643| [ 0.44489 -1.60656  0.63474]
21Feb13_153643| [-0.22650 -0.63288  0.57099]
21Feb13_153643| [ 0.44326  0.45152 -0.51536]
21Feb13_153643| [ 1.40311 -0.66651  0.51698]
21Feb13_153643| [ 1.50925  0.09394  0.01281]
21Feb13_153643| [-1.76743 -1.28362 -0.72095]
21Feb13_153643| [-0.33819 -1.05380 -0.75191]
21Feb13_153643| [-0.40027 -0.59070 -1.35452]
21Feb13_153643| [-0.54297  1.55915  0.23082]
21Feb13_153643| [-0.86819 -1.75993 -1.07029]
21Feb13_153643| [ 1.30716  0.60079  0.37201]
21Feb13_153643| [-1.47537 -2.19202  1.41716]
21Feb13_153643| [ 1.31558 -0.88044  0.04700]
21Feb13_153643| [-2.05456  0.34059 -1.64271]
21Feb13_153643| [-1.97535  1.71428  0.44055]
21Feb13_153643| [ 0.68070  0.31593  0.25745]
21Feb13_153643| [-0.67951  0.91202 -1.61528]
21Feb13_153643| [ 0.96970  0.68426  0.90910]
21Feb13_153643| [ 0.50563 -1.36234 -0.15913]
21Feb13_153643| [-0.18236 -0.09802  0.32229]
21Feb13_153643| [-0.55016 -0.25396  1.79019]
21Feb13_153643| [-1.25899  0.21076  0.55796]
21Feb13_153643| [-1.01640  1.44683 -0.99457]
21Feb13_153643| [-1.00496  1.79390 -0.53071]
21Feb13_153643| [ 0.15909  1.13690 -0.26700]
21Feb13_153643| [ 0.64458  0.48383  0.79797]
21Feb13_153643| [ 0.18767 -1.17443 -1.18586]
21Feb13_153643| [-0.87376 -0.46862 -0.73299]
21Feb13_153643| [-0.76586 -0.54795  1.67859]
21Feb13_153643| [ 0.85147  0.44981 -0.14231]
21Feb13_153643| [ 1.09911  0.31086 -0.91574]
21Feb13_153643| [-1.62543  0.32096  0.91669]
21Feb13_153643| [-1.16200 -0.04002  0.12671]
21Feb13_153643| [-0.35027 -0.61376  0.47083]
21Feb13_153643| [-0.89940  0.17872 -0.52839]
21Feb13_153643| [-1.94942  0.35467 -1.54599]
21Feb13_153643| [ 0.00901  0.85725 -0.40270]
21Feb13_153643| [ 0.56098 -0.26406 -0.53039]
21Feb13_153643| [-0.76616 -1.12136  0.79042]
21Feb13_153643| [-0.13595  0.39278 -1.17800]
21Feb13_153643| [ 0.89288  0.31535 -0.09279]
21Feb13_153643| [ 0.18309 -0.96295 -0.17588]
21Feb13_153643| [ 0.75221  1.37401 -0.89781]
21Feb13_153643| [-0.70757  0.35167 -0.74607]
21Feb13_153643| [ 0.86116  0.60042 -1.51156]
21Feb13_153643| [-0.43082 -1.19351 -0.51187]]
21Feb13_153643|-- Bias --
21Feb13_153643|[ 1.07104 -1.07737  0.83107]
21Feb13_153643|Layer 1:
21Feb13_153643|-- Config --
21Feb13_153643|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153643|-- Weights --
21Feb13_153643|[[ 0.38076 -1.33247  1.12544]
21Feb13_153643| [ 0.73925 -1.15289  0.84060]
21Feb13_153643| [-1.05371 -0.14959  1.24449]]
21Feb13_153643|-- Bias --
21Feb13_153643|[ 0.20502 -0.24416 -0.80573]
21Feb13_153643|Layer 2:
21Feb13_153643|-- Config --
21Feb13_153643|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153643|-- Weights --
21Feb13_153643|[[-1.62327  0.06666]
21Feb13_153643| [ 1.19291 -1.80974]
21Feb13_153643| [ 0.60957 -0.04413]]
21Feb13_153643|-- Bias --
21Feb13_153643|[ 0.14193 -0.78289]
21Feb13_153643|Predicting the validation and test data with the Best final individual.
21Feb13_153651| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_153651|-----------  ------------------  --------------------  ----------
21Feb13_153651|Validation         38.43                  12            0.00000
21Feb13_153651|   Test            39.44                  12            0.00000
21Feb13_153651|-------------------- Test #4 --------------------
21Feb13_153651|Best final individual weights
21Feb13_153651|Individual:
21Feb13_153651|-- Constant hidden layers --
21Feb13_153651|False
21Feb13_153651|Layer 0:
21Feb13_153651|-- Config --
21Feb13_153651|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153651|-- Weights --
21Feb13_153651|[[ 0.38713  2.42063 -0.81233]
21Feb13_153651| [ 0.46584  0.21781 -1.47469]
21Feb13_153651| [ 0.52524  0.25286 -0.75848]
21Feb13_153651| [ 1.05419  0.14503  0.85689]
21Feb13_153651| [-1.80529 -1.45880 -1.06493]
21Feb13_153651| [-0.14918 -1.96139 -1.08659]
21Feb13_153651| [ 1.04503 -0.35673 -0.78110]
21Feb13_153651| [-0.66658  1.37377 -0.34096]
21Feb13_153651| [ 1.52793 -0.71748  1.91379]
21Feb13_153651| [ 0.91559  0.64119  0.67131]
21Feb13_153651| [-0.54570 -1.45433  0.16551]
21Feb13_153651| [ 0.44489 -1.60656  0.63474]
21Feb13_153651| [-0.22650 -0.63288  0.57099]
21Feb13_153651| [ 0.44326  0.45152 -0.51536]
21Feb13_153651| [ 1.40311 -0.66651  0.51698]
21Feb13_153651| [ 1.50925  0.09394  0.01281]
21Feb13_153651| [-1.76743 -1.28362 -0.72095]
21Feb13_153651| [-0.33819 -1.05380 -0.75191]
21Feb13_153651| [-0.40027 -0.59070 -1.35452]
21Feb13_153651| [-0.54297  1.55915  0.23082]
21Feb13_153651| [-0.86819 -1.75993 -1.07029]
21Feb13_153651| [ 1.30716  0.60079  0.37201]
21Feb13_153651| [-1.47537 -2.19202  1.41716]
21Feb13_153651| [ 1.31558 -0.88044  0.04700]
21Feb13_153651| [-2.05456  0.34059 -1.64271]
21Feb13_153651| [-1.97535  1.71428  0.44055]
21Feb13_153651| [ 0.68070  0.31593  0.25745]
21Feb13_153651| [-0.67951  0.91202 -1.61528]
21Feb13_153651| [ 0.96970  0.68426  0.90910]
21Feb13_153651| [ 0.50563 -1.36234 -0.15913]
21Feb13_153651| [-0.18236 -0.09802  0.32229]
21Feb13_153651| [-0.55016 -0.25396  1.79019]
21Feb13_153651| [-1.25899  0.21076  0.55796]
21Feb13_153651| [-1.01640  1.44683 -0.99457]
21Feb13_153651| [-1.00496  1.79390 -0.53071]
21Feb13_153651| [ 0.15909  1.13690 -0.26700]
21Feb13_153651| [ 0.64458  0.48383  0.79797]
21Feb13_153651| [ 0.18767 -1.17443 -1.18586]
21Feb13_153651| [-0.87376 -0.46862 -0.73299]
21Feb13_153651| [-0.76586 -0.54795  1.67859]
21Feb13_153651| [ 0.85147  0.44981 -0.14231]
21Feb13_153651| [ 1.09911  0.31086 -0.91574]
21Feb13_153651| [-1.62543  0.32096  0.91669]
21Feb13_153651| [-1.16200 -0.04002  0.12671]
21Feb13_153651| [-0.35027 -0.61376  0.47083]
21Feb13_153651| [-0.89940  0.17872 -0.52839]
21Feb13_153651| [-1.94942  0.35467 -1.54599]
21Feb13_153651| [ 0.00901  0.85725 -0.40270]
21Feb13_153651| [ 0.56098 -0.26406 -0.53039]
21Feb13_153651| [-0.76616 -1.12136  0.79042]
21Feb13_153651| [-0.13595  0.39278 -1.17800]
21Feb13_153651| [ 0.89288  0.31535 -0.09279]
21Feb13_153651| [ 0.18309 -0.96295 -0.17588]
21Feb13_153651| [ 0.75221  1.37401 -0.89781]
21Feb13_153651| [-0.70757  0.35167 -0.74607]
21Feb13_153651| [ 0.86116  0.60042 -1.51156]
21Feb13_153651| [-0.43082 -1.19351 -0.51187]]
21Feb13_153651|-- Bias --
21Feb13_153651|[ 1.07104 -1.07737  0.83107]
21Feb13_153651|Layer 1:
21Feb13_153651|-- Config --
21Feb13_153651|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153651|-- Weights --
21Feb13_153651|[[ 0.38076 -1.33247  1.12544]
21Feb13_153651| [ 0.73925 -1.15289  0.84060]
21Feb13_153651| [-1.05371 -0.14959  1.24449]]
21Feb13_153651|-- Bias --
21Feb13_153651|[ 0.20502 -0.24416 -0.80573]
21Feb13_153651|Layer 2:
21Feb13_153651|-- Config --
21Feb13_153651|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153651|-- Weights --
21Feb13_153651|[[-1.62327  0.06666]
21Feb13_153651| [ 1.19291 -1.80974]
21Feb13_153651| [ 0.60957 -0.04413]]
21Feb13_153651|-- Bias --
21Feb13_153651|[ 0.14193 -0.78289]
21Feb13_153651|Predicting the validation and test data with the Best final individual.
21Feb13_153658| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_153658|-----------  ------------------  --------------------  ----------
21Feb13_153658|Validation         38.43                  12            0.00000
21Feb13_153658|   Test            39.44                  12            0.00000
21Feb13_153658|-------------------- Test #5 --------------------
21Feb13_153658|Best final individual weights
21Feb13_153658|Individual:
21Feb13_153658|-- Constant hidden layers --
21Feb13_153658|False
21Feb13_153658|Layer 0:
21Feb13_153658|-- Config --
21Feb13_153658|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153658|-- Weights --
21Feb13_153658|[[ 0.38713  2.42063 -0.81233]
21Feb13_153658| [ 0.46584  0.21781 -1.47469]
21Feb13_153658| [ 0.52524  0.25286 -0.75848]
21Feb13_153658| [ 1.05419  0.14503  0.85689]
21Feb13_153658| [-1.80529 -1.45880 -1.06493]
21Feb13_153658| [-0.14918 -1.96139 -1.08659]
21Feb13_153658| [ 1.04503 -0.35673 -0.78110]
21Feb13_153658| [-0.66658  1.37377 -0.34096]
21Feb13_153658| [ 1.52793 -0.71748  1.91379]
21Feb13_153658| [ 0.91559  0.64119  0.67131]
21Feb13_153658| [-0.54570 -1.45433  0.16551]
21Feb13_153658| [ 0.44489 -1.60656  0.63474]
21Feb13_153658| [-0.22650 -0.63288  0.57099]
21Feb13_153658| [ 0.44326  0.45152 -0.51536]
21Feb13_153658| [ 1.40311 -0.66651  0.51698]
21Feb13_153658| [ 1.50925  0.09394  0.01281]
21Feb13_153658| [-1.76743 -1.28362 -0.72095]
21Feb13_153658| [-0.33819 -1.05380 -0.75191]
21Feb13_153658| [-0.40027 -0.59070 -1.35452]
21Feb13_153658| [-0.54297  1.55915  0.23082]
21Feb13_153658| [-0.86819 -1.75993 -1.07029]
21Feb13_153658| [ 1.30716  0.60079  0.37201]
21Feb13_153658| [-1.47537 -2.19202  1.41716]
21Feb13_153658| [ 1.31558 -0.88044  0.04700]
21Feb13_153658| [-2.05456  0.34059 -1.64271]
21Feb13_153658| [-1.97535  1.71428  0.44055]
21Feb13_153658| [ 0.68070  0.31593  0.25745]
21Feb13_153658| [-0.67951  0.91202 -1.61528]
21Feb13_153658| [ 0.96970  0.68426  0.90910]
21Feb13_153658| [ 0.50563 -1.36234 -0.15913]
21Feb13_153658| [-0.18236 -0.09802  0.32229]
21Feb13_153658| [-0.55016 -0.25396  1.79019]
21Feb13_153658| [-1.25899  0.21076  0.55796]
21Feb13_153658| [-1.01640  1.44683 -0.99457]
21Feb13_153658| [-1.00496  1.79390 -0.53071]
21Feb13_153658| [ 0.15909  1.13690 -0.26700]
21Feb13_153658| [ 0.64458  0.48383  0.79797]
21Feb13_153658| [ 0.18767 -1.17443 -1.18586]
21Feb13_153658| [-0.87376 -0.46862 -0.73299]
21Feb13_153658| [-0.76586 -0.54795  1.67859]
21Feb13_153658| [ 0.85147  0.44981 -0.14231]
21Feb13_153658| [ 1.09911  0.31086 -0.91574]
21Feb13_153658| [-1.62543  0.32096  0.91669]
21Feb13_153658| [-1.16200 -0.04002  0.12671]
21Feb13_153658| [-0.35027 -0.61376  0.47083]
21Feb13_153658| [-0.89940  0.17872 -0.52839]
21Feb13_153658| [-1.94942  0.35467 -1.54599]
21Feb13_153658| [ 0.00901  0.85725 -0.40270]
21Feb13_153658| [ 0.56098 -0.26406 -0.53039]
21Feb13_153658| [-0.76616 -1.12136  0.79042]
21Feb13_153658| [-0.13595  0.39278 -1.17800]
21Feb13_153658| [ 0.89288  0.31535 -0.09279]
21Feb13_153658| [ 0.18309 -0.96295 -0.17588]
21Feb13_153658| [ 0.75221  1.37401 -0.89781]
21Feb13_153658| [-0.70757  0.35167 -0.74607]
21Feb13_153658| [ 0.86116  0.60042 -1.51156]
21Feb13_153658| [-0.43082 -1.19351 -0.51187]]
21Feb13_153658|-- Bias --
21Feb13_153658|[ 1.07104 -1.07737  0.83107]
21Feb13_153658|Layer 1:
21Feb13_153658|-- Config --
21Feb13_153658|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153658|-- Weights --
21Feb13_153658|[[ 0.38076 -1.33247  1.12544]
21Feb13_153658| [ 0.73925 -1.15289  0.84060]
21Feb13_153658| [-1.05371 -0.14959  1.24449]]
21Feb13_153658|-- Bias --
21Feb13_153658|[ 0.20502 -0.24416 -0.80573]
21Feb13_153658|Layer 2:
21Feb13_153658|-- Config --
21Feb13_153658|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153658|-- Weights --
21Feb13_153658|[[-1.62327  0.06666]
21Feb13_153658| [ 1.19291 -1.80974]
21Feb13_153658| [ 0.60957 -0.04413]]
21Feb13_153658|-- Bias --
21Feb13_153658|[ 0.14193 -0.78289]
21Feb13_153658|Predicting the validation and test data with the Best final individual.
21Feb13_153705| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_153705|-----------  ------------------  --------------------  ----------
21Feb13_153705|Validation         38.43                  12            0.00000
21Feb13_153705|   Test            39.44                  12            0.00000
21Feb13_153705|-------------------- Test #6 --------------------
21Feb13_153705|Best final individual weights
21Feb13_153705|Individual:
21Feb13_153705|-- Constant hidden layers --
21Feb13_153705|False
21Feb13_153705|Layer 0:
21Feb13_153705|-- Config --
21Feb13_153705|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153705|-- Weights --
21Feb13_153705|[[ 0.38713  2.42063 -0.81233]
21Feb13_153705| [ 0.46584  0.21781 -1.47469]
21Feb13_153705| [ 0.52524  0.25286 -0.75848]
21Feb13_153705| [ 1.05419  0.14503  0.85689]
21Feb13_153705| [-1.80529 -1.45880 -1.06493]
21Feb13_153705| [-0.14918 -1.96139 -1.08659]
21Feb13_153705| [ 1.04503 -0.35673 -0.78110]
21Feb13_153705| [-0.66658  1.37377 -0.34096]
21Feb13_153705| [ 1.52793 -0.71748  1.91379]
21Feb13_153705| [ 0.91559  0.64119  0.67131]
21Feb13_153705| [-0.54570 -1.45433  0.16551]
21Feb13_153705| [ 0.44489 -1.60656  0.63474]
21Feb13_153705| [-0.22650 -0.63288  0.57099]
21Feb13_153705| [ 0.44326  0.45152 -0.51536]
21Feb13_153705| [ 1.40311 -0.66651  0.51698]
21Feb13_153705| [ 1.50925  0.09394  0.01281]
21Feb13_153705| [-1.76743 -1.28362 -0.72095]
21Feb13_153705| [-0.33819 -1.05380 -0.75191]
21Feb13_153705| [-0.40027 -0.59070 -1.35452]
21Feb13_153705| [-0.54297  1.55915  0.23082]
21Feb13_153705| [-0.86819 -1.75993 -1.07029]
21Feb13_153705| [ 1.30716  0.60079  0.37201]
21Feb13_153705| [-1.47537 -2.19202  1.41716]
21Feb13_153705| [ 1.31558 -0.88044  0.04700]
21Feb13_153705| [-2.05456  0.34059 -1.64271]
21Feb13_153705| [-1.97535  1.71428  0.44055]
21Feb13_153705| [ 0.68070  0.31593  0.25745]
21Feb13_153705| [-0.67951  0.91202 -1.61528]
21Feb13_153705| [ 0.96970  0.68426  0.90910]
21Feb13_153705| [ 0.50563 -1.36234 -0.15913]
21Feb13_153705| [-0.18236 -0.09802  0.32229]
21Feb13_153705| [-0.55016 -0.25396  1.79019]
21Feb13_153705| [-1.25899  0.21076  0.55796]
21Feb13_153705| [-1.01640  1.44683 -0.99457]
21Feb13_153705| [-1.00496  1.79390 -0.53071]
21Feb13_153705| [ 0.15909  1.13690 -0.26700]
21Feb13_153705| [ 0.64458  0.48383  0.79797]
21Feb13_153705| [ 0.18767 -1.17443 -1.18586]
21Feb13_153705| [-0.87376 -0.46862 -0.73299]
21Feb13_153705| [-0.76586 -0.54795  1.67859]
21Feb13_153705| [ 0.85147  0.44981 -0.14231]
21Feb13_153705| [ 1.09911  0.31086 -0.91574]
21Feb13_153705| [-1.62543  0.32096  0.91669]
21Feb13_153705| [-1.16200 -0.04002  0.12671]
21Feb13_153705| [-0.35027 -0.61376  0.47083]
21Feb13_153705| [-0.89940  0.17872 -0.52839]
21Feb13_153705| [-1.94942  0.35467 -1.54599]
21Feb13_153705| [ 0.00901  0.85725 -0.40270]
21Feb13_153705| [ 0.56098 -0.26406 -0.53039]
21Feb13_153705| [-0.76616 -1.12136  0.79042]
21Feb13_153705| [-0.13595  0.39278 -1.17800]
21Feb13_153705| [ 0.89288  0.31535 -0.09279]
21Feb13_153705| [ 0.18309 -0.96295 -0.17588]
21Feb13_153705| [ 0.75221  1.37401 -0.89781]
21Feb13_153705| [-0.70757  0.35167 -0.74607]
21Feb13_153705| [ 0.86116  0.60042 -1.51156]
21Feb13_153705| [-0.43082 -1.19351 -0.51187]]
21Feb13_153705|-- Bias --
21Feb13_153705|[ 1.07104 -1.07737  0.83107]
21Feb13_153705|Layer 1:
21Feb13_153705|-- Config --
21Feb13_153705|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153705|-- Weights --
21Feb13_153705|[[ 0.38076 -1.33247  1.12544]
21Feb13_153705| [ 0.73925 -1.15289  0.84060]
21Feb13_153705| [-1.05371 -0.14959  1.24449]]
21Feb13_153705|-- Bias --
21Feb13_153705|[ 0.20502 -0.24416 -0.80573]
21Feb13_153705|Layer 2:
21Feb13_153705|-- Config --
21Feb13_153705|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153705|-- Weights --
21Feb13_153705|[[-1.62327  0.06666]
21Feb13_153705| [ 1.19291 -1.80974]
21Feb13_153705| [ 0.60957 -0.04413]]
21Feb13_153705|-- Bias --
21Feb13_153705|[ 0.14193 -0.78289]
21Feb13_153705|Predicting the validation and test data with the Best final individual.
21Feb13_153713| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_153713|-----------  ------------------  --------------------  ----------
21Feb13_153713|Validation         26.17                  12            0.51489
21Feb13_153713|   Test            39.44                  12            0.00000
21Feb13_153713|-------------------- Test #7 --------------------
21Feb13_153713|Best final individual weights
21Feb13_153713|Individual:
21Feb13_153713|-- Constant hidden layers --
21Feb13_153713|False
21Feb13_153713|Layer 0:
21Feb13_153713|-- Config --
21Feb13_153713|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153713|-- Weights --
21Feb13_153713|[[ 0.38713  2.42063 -0.81233]
21Feb13_153713| [ 0.46584  0.21781 -1.47469]
21Feb13_153713| [ 0.52524  0.25286 -0.75848]
21Feb13_153713| [ 1.05419  0.14503  0.85689]
21Feb13_153713| [-1.80529 -1.45880 -1.06493]
21Feb13_153713| [-0.14918 -1.96139 -1.08659]
21Feb13_153713| [ 1.04503 -0.35673 -0.78110]
21Feb13_153713| [-0.66658  1.37377 -0.34096]
21Feb13_153713| [ 1.52793 -0.71748  1.91379]
21Feb13_153713| [ 0.91559  0.64119  0.67131]
21Feb13_153713| [-0.54570 -1.45433  0.16551]
21Feb13_153713| [ 0.44489 -1.60656  0.63474]
21Feb13_153713| [-0.22650 -0.63288  0.57099]
21Feb13_153713| [ 0.44326  0.45152 -0.51536]
21Feb13_153713| [ 1.40311 -0.66651  0.51698]
21Feb13_153713| [ 1.50925  0.09394  0.01281]
21Feb13_153713| [-1.76743 -1.28362 -0.72095]
21Feb13_153713| [-0.33819 -1.05380 -0.75191]
21Feb13_153713| [-0.40027 -0.59070 -1.35452]
21Feb13_153713| [-0.54297  1.55915  0.23082]
21Feb13_153713| [-0.86819 -1.75993 -1.07029]
21Feb13_153713| [ 1.30716  0.60079  0.37201]
21Feb13_153713| [-1.47537 -2.19202  1.41716]
21Feb13_153713| [ 1.31558 -0.88044  0.04700]
21Feb13_153713| [-2.05456  0.34059 -1.64271]
21Feb13_153713| [-1.97535  1.71428  0.44055]
21Feb13_153713| [ 0.68070  0.31593  0.25745]
21Feb13_153713| [-0.67951  0.91202 -1.61528]
21Feb13_153713| [ 0.96970  0.68426  0.90910]
21Feb13_153713| [ 0.50563 -1.36234 -0.15913]
21Feb13_153713| [-0.18236 -0.09802  0.32229]
21Feb13_153713| [-0.55016 -0.25396  1.79019]
21Feb13_153713| [-1.25899  0.21076  0.55796]
21Feb13_153713| [-1.01640  1.44683 -0.99457]
21Feb13_153713| [-1.00496  1.79390 -0.53071]
21Feb13_153713| [ 0.15909  1.13690 -0.26700]
21Feb13_153713| [ 0.64458  0.48383  0.79797]
21Feb13_153713| [ 0.18767 -1.17443 -1.18586]
21Feb13_153713| [-0.87376 -0.46862 -0.73299]
21Feb13_153713| [-0.76586 -0.54795  1.67859]
21Feb13_153713| [ 0.85147  0.44981 -0.14231]
21Feb13_153713| [ 1.09911  0.31086 -0.91574]
21Feb13_153713| [-1.62543  0.32096  0.91669]
21Feb13_153713| [-1.16200 -0.04002  0.12671]
21Feb13_153713| [-0.35027 -0.61376  0.47083]
21Feb13_153713| [-0.89940  0.17872 -0.52839]
21Feb13_153713| [-1.94942  0.35467 -1.54599]
21Feb13_153713| [ 0.00901  0.85725 -0.40270]
21Feb13_153713| [ 0.56098 -0.26406 -0.53039]
21Feb13_153713| [-0.76616 -1.12136  0.79042]
21Feb13_153713| [-0.13595  0.39278 -1.17800]
21Feb13_153713| [ 0.89288  0.31535 -0.09279]
21Feb13_153713| [ 0.18309 -0.96295 -0.17588]
21Feb13_153713| [ 0.75221  1.37401 -0.89781]
21Feb13_153713| [-0.70757  0.35167 -0.74607]
21Feb13_153713| [ 0.86116  0.60042 -1.51156]
21Feb13_153713| [-0.43082 -1.19351 -0.51187]]
21Feb13_153713|-- Bias --
21Feb13_153713|[ 1.07104 -1.07737  0.83107]
21Feb13_153713|Layer 1:
21Feb13_153713|-- Config --
21Feb13_153713|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153713|-- Weights --
21Feb13_153713|[[ 0.38076 -1.33247  1.12544]
21Feb13_153713| [ 0.73925 -1.15289  0.84060]
21Feb13_153713| [-1.05371 -0.14959  1.24449]]
21Feb13_153713|-- Bias --
21Feb13_153713|[ 0.20502 -0.24416 -0.80573]
21Feb13_153713|Layer 2:
21Feb13_153713|-- Config --
21Feb13_153713|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153713|-- Weights --
21Feb13_153713|[[-1.62327  0.06666]
21Feb13_153713| [ 1.19291 -1.80974]
21Feb13_153713| [ 0.60957 -0.04413]]
21Feb13_153713|-- Bias --
21Feb13_153713|[ 0.14193 -0.78289]
21Feb13_153713|Predicting the validation and test data with the Best final individual.
21Feb13_153720| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_153720|-----------  ------------------  --------------------  ----------
21Feb13_153720|Validation         38.43                  12            0.00000
21Feb13_153720|   Test            39.44                  12            0.00000
21Feb13_153720|-------------------- Test #8 --------------------
21Feb13_153720|Best final individual weights
21Feb13_153720|Individual:
21Feb13_153720|-- Constant hidden layers --
21Feb13_153720|False
21Feb13_153720|Layer 0:
21Feb13_153720|-- Config --
21Feb13_153720|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153720|-- Weights --
21Feb13_153720|[[ 0.38713  2.42063 -0.81233]
21Feb13_153720| [ 0.46584  0.21781 -1.47469]
21Feb13_153720| [ 0.52524  0.25286 -0.75848]
21Feb13_153720| [ 1.05419  0.14503  0.85689]
21Feb13_153720| [-1.80529 -1.45880 -1.06493]
21Feb13_153720| [-0.14918 -1.96139 -1.08659]
21Feb13_153720| [ 1.04503 -0.35673 -0.78110]
21Feb13_153720| [-0.66658  1.37377 -0.34096]
21Feb13_153720| [ 1.52793 -0.71748  1.91379]
21Feb13_153720| [ 0.91559  0.64119  0.67131]
21Feb13_153720| [-0.54570 -1.45433  0.16551]
21Feb13_153720| [ 0.44489 -1.60656  0.63474]
21Feb13_153720| [-0.22650 -0.63288  0.57099]
21Feb13_153720| [ 0.44326  0.45152 -0.51536]
21Feb13_153720| [ 1.40311 -0.66651  0.51698]
21Feb13_153720| [ 1.50925  0.09394  0.01281]
21Feb13_153720| [-1.76743 -1.28362 -0.72095]
21Feb13_153720| [-0.33819 -1.05380 -0.75191]
21Feb13_153720| [-0.40027 -0.59070 -1.35452]
21Feb13_153720| [-0.54297  1.55915  0.23082]
21Feb13_153720| [-0.86819 -1.75993 -1.07029]
21Feb13_153720| [ 1.30716  0.60079  0.37201]
21Feb13_153720| [-1.47537 -2.19202  1.41716]
21Feb13_153720| [ 1.31558 -0.88044  0.04700]
21Feb13_153720| [-2.05456  0.34059 -1.64271]
21Feb13_153720| [-1.97535  1.71428  0.44055]
21Feb13_153720| [ 0.68070  0.31593  0.25745]
21Feb13_153720| [-0.67951  0.91202 -1.61528]
21Feb13_153720| [ 0.96970  0.68426  0.90910]
21Feb13_153720| [ 0.50563 -1.36234 -0.15913]
21Feb13_153720| [-0.18236 -0.09802  0.32229]
21Feb13_153720| [-0.55016 -0.25396  1.79019]
21Feb13_153720| [-1.25899  0.21076  0.55796]
21Feb13_153720| [-1.01640  1.44683 -0.99457]
21Feb13_153720| [-1.00496  1.79390 -0.53071]
21Feb13_153720| [ 0.15909  1.13690 -0.26700]
21Feb13_153720| [ 0.64458  0.48383  0.79797]
21Feb13_153720| [ 0.18767 -1.17443 -1.18586]
21Feb13_153720| [-0.87376 -0.46862 -0.73299]
21Feb13_153720| [-0.76586 -0.54795  1.67859]
21Feb13_153720| [ 0.85147  0.44981 -0.14231]
21Feb13_153720| [ 1.09911  0.31086 -0.91574]
21Feb13_153720| [-1.62543  0.32096  0.91669]
21Feb13_153720| [-1.16200 -0.04002  0.12671]
21Feb13_153720| [-0.35027 -0.61376  0.47083]
21Feb13_153720| [-0.89940  0.17872 -0.52839]
21Feb13_153720| [-1.94942  0.35467 -1.54599]
21Feb13_153720| [ 0.00901  0.85725 -0.40270]
21Feb13_153720| [ 0.56098 -0.26406 -0.53039]
21Feb13_153720| [-0.76616 -1.12136  0.79042]
21Feb13_153720| [-0.13595  0.39278 -1.17800]
21Feb13_153720| [ 0.89288  0.31535 -0.09279]
21Feb13_153720| [ 0.18309 -0.96295 -0.17588]
21Feb13_153720| [ 0.75221  1.37401 -0.89781]
21Feb13_153720| [-0.70757  0.35167 -0.74607]
21Feb13_153720| [ 0.86116  0.60042 -1.51156]
21Feb13_153720| [-0.43082 -1.19351 -0.51187]]
21Feb13_153720|-- Bias --
21Feb13_153720|[ 1.07104 -1.07737  0.83107]
21Feb13_153720|Layer 1:
21Feb13_153720|-- Config --
21Feb13_153720|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153720|-- Weights --
21Feb13_153720|[[ 0.38076 -1.33247  1.12544]
21Feb13_153720| [ 0.73925 -1.15289  0.84060]
21Feb13_153720| [-1.05371 -0.14959  1.24449]]
21Feb13_153720|-- Bias --
21Feb13_153720|[ 0.20502 -0.24416 -0.80573]
21Feb13_153720|Layer 2:
21Feb13_153720|-- Config --
21Feb13_153720|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153720|-- Weights --
21Feb13_153720|[[-1.62327  0.06666]
21Feb13_153720| [ 1.19291 -1.80974]
21Feb13_153720| [ 0.60957 -0.04413]]
21Feb13_153720|-- Bias --
21Feb13_153720|[ 0.14193 -0.78289]
21Feb13_153720|Predicting the validation and test data with the Best final individual.
21Feb13_153728| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_153728|-----------  ------------------  --------------------  ----------
21Feb13_153728|Validation         38.43                  12            0.00000
21Feb13_153728|   Test            39.44                  12            0.00000
21Feb13_153728|-------------------- Test #9 --------------------
21Feb13_153728|Best final individual weights
21Feb13_153728|Individual:
21Feb13_153728|-- Constant hidden layers --
21Feb13_153728|False
21Feb13_153728|Layer 0:
21Feb13_153728|-- Config --
21Feb13_153728|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153728|-- Weights --
21Feb13_153728|[[ 0.38713  2.42063 -0.81233]
21Feb13_153728| [ 0.46584  0.21781 -1.47469]
21Feb13_153728| [ 0.52524  0.25286 -0.75848]
21Feb13_153728| [ 1.05419  0.14503  0.85689]
21Feb13_153728| [-1.80529 -1.45880 -1.06493]
21Feb13_153728| [-0.14918 -1.96139 -1.08659]
21Feb13_153728| [ 1.04503 -0.35673 -0.78110]
21Feb13_153728| [-0.66658  1.37377 -0.34096]
21Feb13_153728| [ 1.52793 -0.71748  1.91379]
21Feb13_153728| [ 0.91559  0.64119  0.67131]
21Feb13_153728| [-0.54570 -1.45433  0.16551]
21Feb13_153728| [ 0.44489 -1.60656  0.63474]
21Feb13_153728| [-0.22650 -0.63288  0.57099]
21Feb13_153728| [ 0.44326  0.45152 -0.51536]
21Feb13_153728| [ 1.40311 -0.66651  0.51698]
21Feb13_153728| [ 1.50925  0.09394  0.01281]
21Feb13_153728| [-1.76743 -1.28362 -0.72095]
21Feb13_153728| [-0.33819 -1.05380 -0.75191]
21Feb13_153728| [-0.40027 -0.59070 -1.35452]
21Feb13_153728| [-0.54297  1.55915  0.23082]
21Feb13_153728| [-0.86819 -1.75993 -1.07029]
21Feb13_153728| [ 1.30716  0.60079  0.37201]
21Feb13_153728| [-1.47537 -2.19202  1.41716]
21Feb13_153728| [ 1.31558 -0.88044  0.04700]
21Feb13_153728| [-2.05456  0.34059 -1.64271]
21Feb13_153728| [-1.97535  1.71428  0.44055]
21Feb13_153728| [ 0.68070  0.31593  0.25745]
21Feb13_153728| [-0.67951  0.91202 -1.61528]
21Feb13_153728| [ 0.96970  0.68426  0.90910]
21Feb13_153728| [ 0.50563 -1.36234 -0.15913]
21Feb13_153728| [-0.18236 -0.09802  0.32229]
21Feb13_153728| [-0.55016 -0.25396  1.79019]
21Feb13_153728| [-1.25899  0.21076  0.55796]
21Feb13_153728| [-1.01640  1.44683 -0.99457]
21Feb13_153728| [-1.00496  1.79390 -0.53071]
21Feb13_153728| [ 0.15909  1.13690 -0.26700]
21Feb13_153728| [ 0.64458  0.48383  0.79797]
21Feb13_153728| [ 0.18767 -1.17443 -1.18586]
21Feb13_153728| [-0.87376 -0.46862 -0.73299]
21Feb13_153728| [-0.76586 -0.54795  1.67859]
21Feb13_153728| [ 0.85147  0.44981 -0.14231]
21Feb13_153728| [ 1.09911  0.31086 -0.91574]
21Feb13_153728| [-1.62543  0.32096  0.91669]
21Feb13_153728| [-1.16200 -0.04002  0.12671]
21Feb13_153728| [-0.35027 -0.61376  0.47083]
21Feb13_153728| [-0.89940  0.17872 -0.52839]
21Feb13_153728| [-1.94942  0.35467 -1.54599]
21Feb13_153728| [ 0.00901  0.85725 -0.40270]
21Feb13_153728| [ 0.56098 -0.26406 -0.53039]
21Feb13_153728| [-0.76616 -1.12136  0.79042]
21Feb13_153728| [-0.13595  0.39278 -1.17800]
21Feb13_153728| [ 0.89288  0.31535 -0.09279]
21Feb13_153728| [ 0.18309 -0.96295 -0.17588]
21Feb13_153728| [ 0.75221  1.37401 -0.89781]
21Feb13_153728| [-0.70757  0.35167 -0.74607]
21Feb13_153728| [ 0.86116  0.60042 -1.51156]
21Feb13_153728| [-0.43082 -1.19351 -0.51187]]
21Feb13_153728|-- Bias --
21Feb13_153728|[ 1.07104 -1.07737  0.83107]
21Feb13_153728|Layer 1:
21Feb13_153728|-- Config --
21Feb13_153728|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153728|-- Weights --
21Feb13_153728|[[ 0.38076 -1.33247  1.12544]
21Feb13_153728| [ 0.73925 -1.15289  0.84060]
21Feb13_153728| [-1.05371 -0.14959  1.24449]]
21Feb13_153728|-- Bias --
21Feb13_153728|[ 0.20502 -0.24416 -0.80573]
21Feb13_153728|Layer 2:
21Feb13_153728|-- Config --
21Feb13_153728|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153728|-- Weights --
21Feb13_153728|[[-1.62327  0.06666]
21Feb13_153728| [ 1.19291 -1.80974]
21Feb13_153728| [ 0.60957 -0.04413]]
21Feb13_153728|-- Bias --
21Feb13_153728|[ 0.14193 -0.78289]
21Feb13_153728|Predicting the validation and test data with the Best final individual.
21Feb13_153735| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_153735|-----------  ------------------  --------------------  ----------
21Feb13_153735|Validation         38.43                  12            0.00000
21Feb13_153735|   Test            39.44                  12            0.00000
21Feb13_153735|-------------------- Test #10 --------------------
21Feb13_153735|Best final individual weights
21Feb13_153735|Individual:
21Feb13_153735|-- Constant hidden layers --
21Feb13_153735|False
21Feb13_153735|Layer 0:
21Feb13_153735|-- Config --
21Feb13_153735|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153735|-- Weights --
21Feb13_153735|[[ 0.38713  2.42063 -0.81233]
21Feb13_153735| [ 0.46584  0.21781 -1.47469]
21Feb13_153735| [ 0.52524  0.25286 -0.75848]
21Feb13_153735| [ 1.05419  0.14503  0.85689]
21Feb13_153735| [-1.80529 -1.45880 -1.06493]
21Feb13_153735| [-0.14918 -1.96139 -1.08659]
21Feb13_153735| [ 1.04503 -0.35673 -0.78110]
21Feb13_153735| [-0.66658  1.37377 -0.34096]
21Feb13_153735| [ 1.52793 -0.71748  1.91379]
21Feb13_153735| [ 0.91559  0.64119  0.67131]
21Feb13_153735| [-0.54570 -1.45433  0.16551]
21Feb13_153735| [ 0.44489 -1.60656  0.63474]
21Feb13_153735| [-0.22650 -0.63288  0.57099]
21Feb13_153735| [ 0.44326  0.45152 -0.51536]
21Feb13_153735| [ 1.40311 -0.66651  0.51698]
21Feb13_153735| [ 1.50925  0.09394  0.01281]
21Feb13_153735| [-1.76743 -1.28362 -0.72095]
21Feb13_153735| [-0.33819 -1.05380 -0.75191]
21Feb13_153735| [-0.40027 -0.59070 -1.35452]
21Feb13_153735| [-0.54297  1.55915  0.23082]
21Feb13_153735| [-0.86819 -1.75993 -1.07029]
21Feb13_153735| [ 1.30716  0.60079  0.37201]
21Feb13_153735| [-1.47537 -2.19202  1.41716]
21Feb13_153735| [ 1.31558 -0.88044  0.04700]
21Feb13_153735| [-2.05456  0.34059 -1.64271]
21Feb13_153735| [-1.97535  1.71428  0.44055]
21Feb13_153735| [ 0.68070  0.31593  0.25745]
21Feb13_153735| [-0.67951  0.91202 -1.61528]
21Feb13_153735| [ 0.96970  0.68426  0.90910]
21Feb13_153735| [ 0.50563 -1.36234 -0.15913]
21Feb13_153735| [-0.18236 -0.09802  0.32229]
21Feb13_153735| [-0.55016 -0.25396  1.79019]
21Feb13_153735| [-1.25899  0.21076  0.55796]
21Feb13_153735| [-1.01640  1.44683 -0.99457]
21Feb13_153735| [-1.00496  1.79390 -0.53071]
21Feb13_153735| [ 0.15909  1.13690 -0.26700]
21Feb13_153735| [ 0.64458  0.48383  0.79797]
21Feb13_153735| [ 0.18767 -1.17443 -1.18586]
21Feb13_153735| [-0.87376 -0.46862 -0.73299]
21Feb13_153735| [-0.76586 -0.54795  1.67859]
21Feb13_153735| [ 0.85147  0.44981 -0.14231]
21Feb13_153735| [ 1.09911  0.31086 -0.91574]
21Feb13_153735| [-1.62543  0.32096  0.91669]
21Feb13_153735| [-1.16200 -0.04002  0.12671]
21Feb13_153735| [-0.35027 -0.61376  0.47083]
21Feb13_153735| [-0.89940  0.17872 -0.52839]
21Feb13_153735| [-1.94942  0.35467 -1.54599]
21Feb13_153735| [ 0.00901  0.85725 -0.40270]
21Feb13_153735| [ 0.56098 -0.26406 -0.53039]
21Feb13_153735| [-0.76616 -1.12136  0.79042]
21Feb13_153735| [-0.13595  0.39278 -1.17800]
21Feb13_153735| [ 0.89288  0.31535 -0.09279]
21Feb13_153735| [ 0.18309 -0.96295 -0.17588]
21Feb13_153735| [ 0.75221  1.37401 -0.89781]
21Feb13_153735| [-0.70757  0.35167 -0.74607]
21Feb13_153735| [ 0.86116  0.60042 -1.51156]
21Feb13_153735| [-0.43082 -1.19351 -0.51187]]
21Feb13_153735|-- Bias --
21Feb13_153735|[ 1.07104 -1.07737  0.83107]
21Feb13_153735|Layer 1:
21Feb13_153735|-- Config --
21Feb13_153735|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153735|-- Weights --
21Feb13_153735|[[ 0.38076 -1.33247  1.12544]
21Feb13_153735| [ 0.73925 -1.15289  0.84060]
21Feb13_153735| [-1.05371 -0.14959  1.24449]]
21Feb13_153735|-- Bias --
21Feb13_153735|[ 0.20502 -0.24416 -0.80573]
21Feb13_153735|Layer 2:
21Feb13_153735|-- Config --
21Feb13_153735|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153735|-- Weights --
21Feb13_153735|[[-1.62327  0.06666]
21Feb13_153735| [ 1.19291 -1.80974]
21Feb13_153735| [ 0.60957 -0.04413]]
21Feb13_153735|-- Bias --
21Feb13_153735|[ 0.14193 -0.78289]
21Feb13_153735|Predicting the validation and test data with the Best final individual.
21Feb13_153742| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_153742|-----------  ------------------  --------------------  ----------
21Feb13_153742|Validation         38.43                  12            0.00000
21Feb13_153742|   Test            39.44                  12            0.00000
21Feb13_153742|-------------------- Test #11 --------------------
21Feb13_153742|Best final individual weights
21Feb13_153742|Individual:
21Feb13_153742|-- Constant hidden layers --
21Feb13_153742|False
21Feb13_153742|Layer 0:
21Feb13_153742|-- Config --
21Feb13_153742|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153742|-- Weights --
21Feb13_153742|[[ 0.38713  2.42063 -0.81233]
21Feb13_153742| [ 0.46584  0.21781 -1.47469]
21Feb13_153742| [ 0.52524  0.25286 -0.75848]
21Feb13_153742| [ 1.05419  0.14503  0.85689]
21Feb13_153742| [-1.80529 -1.45880 -1.06493]
21Feb13_153742| [-0.14918 -1.96139 -1.08659]
21Feb13_153742| [ 1.04503 -0.35673 -0.78110]
21Feb13_153742| [-0.66658  1.37377 -0.34096]
21Feb13_153742| [ 1.52793 -0.71748  1.91379]
21Feb13_153742| [ 0.91559  0.64119  0.67131]
21Feb13_153742| [-0.54570 -1.45433  0.16551]
21Feb13_153742| [ 0.44489 -1.60656  0.63474]
21Feb13_153742| [-0.22650 -0.63288  0.57099]
21Feb13_153742| [ 0.44326  0.45152 -0.51536]
21Feb13_153742| [ 1.40311 -0.66651  0.51698]
21Feb13_153742| [ 1.50925  0.09394  0.01281]
21Feb13_153742| [-1.76743 -1.28362 -0.72095]
21Feb13_153742| [-0.33819 -1.05380 -0.75191]
21Feb13_153742| [-0.40027 -0.59070 -1.35452]
21Feb13_153742| [-0.54297  1.55915  0.23082]
21Feb13_153742| [-0.86819 -1.75993 -1.07029]
21Feb13_153742| [ 1.30716  0.60079  0.37201]
21Feb13_153742| [-1.47537 -2.19202  1.41716]
21Feb13_153742| [ 1.31558 -0.88044  0.04700]
21Feb13_153742| [-2.05456  0.34059 -1.64271]
21Feb13_153742| [-1.97535  1.71428  0.44055]
21Feb13_153742| [ 0.68070  0.31593  0.25745]
21Feb13_153742| [-0.67951  0.91202 -1.61528]
21Feb13_153742| [ 0.96970  0.68426  0.90910]
21Feb13_153742| [ 0.50563 -1.36234 -0.15913]
21Feb13_153742| [-0.18236 -0.09802  0.32229]
21Feb13_153742| [-0.55016 -0.25396  1.79019]
21Feb13_153742| [-1.25899  0.21076  0.55796]
21Feb13_153742| [-1.01640  1.44683 -0.99457]
21Feb13_153742| [-1.00496  1.79390 -0.53071]
21Feb13_153742| [ 0.15909  1.13690 -0.26700]
21Feb13_153742| [ 0.64458  0.48383  0.79797]
21Feb13_153742| [ 0.18767 -1.17443 -1.18586]
21Feb13_153742| [-0.87376 -0.46862 -0.73299]
21Feb13_153742| [-0.76586 -0.54795  1.67859]
21Feb13_153742| [ 0.85147  0.44981 -0.14231]
21Feb13_153742| [ 1.09911  0.31086 -0.91574]
21Feb13_153742| [-1.62543  0.32096  0.91669]
21Feb13_153742| [-1.16200 -0.04002  0.12671]
21Feb13_153742| [-0.35027 -0.61376  0.47083]
21Feb13_153742| [-0.89940  0.17872 -0.52839]
21Feb13_153742| [-1.94942  0.35467 -1.54599]
21Feb13_153742| [ 0.00901  0.85725 -0.40270]
21Feb13_153742| [ 0.56098 -0.26406 -0.53039]
21Feb13_153742| [-0.76616 -1.12136  0.79042]
21Feb13_153742| [-0.13595  0.39278 -1.17800]
21Feb13_153742| [ 0.89288  0.31535 -0.09279]
21Feb13_153742| [ 0.18309 -0.96295 -0.17588]
21Feb13_153742| [ 0.75221  1.37401 -0.89781]
21Feb13_153742| [-0.70757  0.35167 -0.74607]
21Feb13_153742| [ 0.86116  0.60042 -1.51156]
21Feb13_153742| [-0.43082 -1.19351 -0.51187]]
21Feb13_153742|-- Bias --
21Feb13_153742|[ 1.07104 -1.07737  0.83107]
21Feb13_153742|Layer 1:
21Feb13_153742|-- Config --
21Feb13_153742|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153742|-- Weights --
21Feb13_153742|[[ 0.38076 -1.33247  1.12544]
21Feb13_153742| [ 0.73925 -1.15289  0.84060]
21Feb13_153742| [-1.05371 -0.14959  1.24449]]
21Feb13_153742|-- Bias --
21Feb13_153742|[ 0.20502 -0.24416 -0.80573]
21Feb13_153742|Layer 2:
21Feb13_153742|-- Config --
21Feb13_153742|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153742|-- Weights --
21Feb13_153742|[[-1.62327  0.06666]
21Feb13_153742| [ 1.19291 -1.80974]
21Feb13_153742| [ 0.60957 -0.04413]]
21Feb13_153742|-- Bias --
21Feb13_153742|[ 0.14193 -0.78289]
21Feb13_153742|Predicting the validation and test data with the Best final individual.
21Feb13_153750| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_153750|-----------  ------------------  --------------------  ----------
21Feb13_153750|Validation         38.43                  12            0.00000
21Feb13_153750|   Test            27.54                  12            0.57542
21Feb13_153750|-------------------- Test #12 --------------------
21Feb13_153750|Best final individual weights
21Feb13_153750|Individual:
21Feb13_153750|-- Constant hidden layers --
21Feb13_153750|False
21Feb13_153750|Layer 0:
21Feb13_153750|-- Config --
21Feb13_153750|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153750|-- Weights --
21Feb13_153750|[[ 0.38713  2.42063 -0.81233]
21Feb13_153750| [ 0.46584  0.21781 -1.47469]
21Feb13_153750| [ 0.52524  0.25286 -0.75848]
21Feb13_153750| [ 1.05419  0.14503  0.85689]
21Feb13_153750| [-1.80529 -1.45880 -1.06493]
21Feb13_153750| [-0.14918 -1.96139 -1.08659]
21Feb13_153750| [ 1.04503 -0.35673 -0.78110]
21Feb13_153750| [-0.66658  1.37377 -0.34096]
21Feb13_153750| [ 1.52793 -0.71748  1.91379]
21Feb13_153750| [ 0.91559  0.64119  0.67131]
21Feb13_153750| [-0.54570 -1.45433  0.16551]
21Feb13_153750| [ 0.44489 -1.60656  0.63474]
21Feb13_153750| [-0.22650 -0.63288  0.57099]
21Feb13_153750| [ 0.44326  0.45152 -0.51536]
21Feb13_153750| [ 1.40311 -0.66651  0.51698]
21Feb13_153750| [ 1.50925  0.09394  0.01281]
21Feb13_153750| [-1.76743 -1.28362 -0.72095]
21Feb13_153750| [-0.33819 -1.05380 -0.75191]
21Feb13_153750| [-0.40027 -0.59070 -1.35452]
21Feb13_153750| [-0.54297  1.55915  0.23082]
21Feb13_153750| [-0.86819 -1.75993 -1.07029]
21Feb13_153750| [ 1.30716  0.60079  0.37201]
21Feb13_153750| [-1.47537 -2.19202  1.41716]
21Feb13_153750| [ 1.31558 -0.88044  0.04700]
21Feb13_153750| [-2.05456  0.34059 -1.64271]
21Feb13_153750| [-1.97535  1.71428  0.44055]
21Feb13_153750| [ 0.68070  0.31593  0.25745]
21Feb13_153750| [-0.67951  0.91202 -1.61528]
21Feb13_153750| [ 0.96970  0.68426  0.90910]
21Feb13_153750| [ 0.50563 -1.36234 -0.15913]
21Feb13_153750| [-0.18236 -0.09802  0.32229]
21Feb13_153750| [-0.55016 -0.25396  1.79019]
21Feb13_153750| [-1.25899  0.21076  0.55796]
21Feb13_153750| [-1.01640  1.44683 -0.99457]
21Feb13_153750| [-1.00496  1.79390 -0.53071]
21Feb13_153750| [ 0.15909  1.13690 -0.26700]
21Feb13_153750| [ 0.64458  0.48383  0.79797]
21Feb13_153750| [ 0.18767 -1.17443 -1.18586]
21Feb13_153750| [-0.87376 -0.46862 -0.73299]
21Feb13_153750| [-0.76586 -0.54795  1.67859]
21Feb13_153750| [ 0.85147  0.44981 -0.14231]
21Feb13_153750| [ 1.09911  0.31086 -0.91574]
21Feb13_153750| [-1.62543  0.32096  0.91669]
21Feb13_153750| [-1.16200 -0.04002  0.12671]
21Feb13_153750| [-0.35027 -0.61376  0.47083]
21Feb13_153750| [-0.89940  0.17872 -0.52839]
21Feb13_153750| [-1.94942  0.35467 -1.54599]
21Feb13_153750| [ 0.00901  0.85725 -0.40270]
21Feb13_153750| [ 0.56098 -0.26406 -0.53039]
21Feb13_153750| [-0.76616 -1.12136  0.79042]
21Feb13_153750| [-0.13595  0.39278 -1.17800]
21Feb13_153750| [ 0.89288  0.31535 -0.09279]
21Feb13_153750| [ 0.18309 -0.96295 -0.17588]
21Feb13_153750| [ 0.75221  1.37401 -0.89781]
21Feb13_153750| [-0.70757  0.35167 -0.74607]
21Feb13_153750| [ 0.86116  0.60042 -1.51156]
21Feb13_153750| [-0.43082 -1.19351 -0.51187]]
21Feb13_153750|-- Bias --
21Feb13_153750|[ 1.07104 -1.07737  0.83107]
21Feb13_153750|Layer 1:
21Feb13_153750|-- Config --
21Feb13_153750|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153750|-- Weights --
21Feb13_153750|[[ 0.38076 -1.33247  1.12544]
21Feb13_153750| [ 0.73925 -1.15289  0.84060]
21Feb13_153750| [-1.05371 -0.14959  1.24449]]
21Feb13_153750|-- Bias --
21Feb13_153750|[ 0.20502 -0.24416 -0.80573]
21Feb13_153750|Layer 2:
21Feb13_153750|-- Config --
21Feb13_153750|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153750|-- Weights --
21Feb13_153750|[[-1.62327  0.06666]
21Feb13_153750| [ 1.19291 -1.80974]
21Feb13_153750| [ 0.60957 -0.04413]]
21Feb13_153750|-- Bias --
21Feb13_153750|[ 0.14193 -0.78289]
21Feb13_153750|Predicting the validation and test data with the Best final individual.
21Feb13_153757| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_153757|-----------  ------------------  --------------------  ----------
21Feb13_153757|Validation         28.52                  12            0.38599
21Feb13_153757|   Test            29.28                  12            0.51240
21Feb13_153757|-------------------- Test #13 --------------------
21Feb13_153757|Best final individual weights
21Feb13_153757|Individual:
21Feb13_153757|-- Constant hidden layers --
21Feb13_153757|False
21Feb13_153757|Layer 0:
21Feb13_153757|-- Config --
21Feb13_153757|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153757|-- Weights --
21Feb13_153757|[[ 0.38713  2.42063 -0.81233]
21Feb13_153757| [ 0.46584  0.21781 -1.47469]
21Feb13_153757| [ 0.52524  0.25286 -0.75848]
21Feb13_153757| [ 1.05419  0.14503  0.85689]
21Feb13_153757| [-1.80529 -1.45880 -1.06493]
21Feb13_153757| [-0.14918 -1.96139 -1.08659]
21Feb13_153757| [ 1.04503 -0.35673 -0.78110]
21Feb13_153757| [-0.66658  1.37377 -0.34096]
21Feb13_153757| [ 1.52793 -0.71748  1.91379]
21Feb13_153757| [ 0.91559  0.64119  0.67131]
21Feb13_153757| [-0.54570 -1.45433  0.16551]
21Feb13_153757| [ 0.44489 -1.60656  0.63474]
21Feb13_153757| [-0.22650 -0.63288  0.57099]
21Feb13_153757| [ 0.44326  0.45152 -0.51536]
21Feb13_153757| [ 1.40311 -0.66651  0.51698]
21Feb13_153757| [ 1.50925  0.09394  0.01281]
21Feb13_153757| [-1.76743 -1.28362 -0.72095]
21Feb13_153757| [-0.33819 -1.05380 -0.75191]
21Feb13_153757| [-0.40027 -0.59070 -1.35452]
21Feb13_153757| [-0.54297  1.55915  0.23082]
21Feb13_153757| [-0.86819 -1.75993 -1.07029]
21Feb13_153757| [ 1.30716  0.60079  0.37201]
21Feb13_153757| [-1.47537 -2.19202  1.41716]
21Feb13_153757| [ 1.31558 -0.88044  0.04700]
21Feb13_153757| [-2.05456  0.34059 -1.64271]
21Feb13_153757| [-1.97535  1.71428  0.44055]
21Feb13_153757| [ 0.68070  0.31593  0.25745]
21Feb13_153757| [-0.67951  0.91202 -1.61528]
21Feb13_153757| [ 0.96970  0.68426  0.90910]
21Feb13_153757| [ 0.50563 -1.36234 -0.15913]
21Feb13_153757| [-0.18236 -0.09802  0.32229]
21Feb13_153757| [-0.55016 -0.25396  1.79019]
21Feb13_153757| [-1.25899  0.21076  0.55796]
21Feb13_153757| [-1.01640  1.44683 -0.99457]
21Feb13_153757| [-1.00496  1.79390 -0.53071]
21Feb13_153757| [ 0.15909  1.13690 -0.26700]
21Feb13_153757| [ 0.64458  0.48383  0.79797]
21Feb13_153757| [ 0.18767 -1.17443 -1.18586]
21Feb13_153757| [-0.87376 -0.46862 -0.73299]
21Feb13_153757| [-0.76586 -0.54795  1.67859]
21Feb13_153757| [ 0.85147  0.44981 -0.14231]
21Feb13_153757| [ 1.09911  0.31086 -0.91574]
21Feb13_153757| [-1.62543  0.32096  0.91669]
21Feb13_153757| [-1.16200 -0.04002  0.12671]
21Feb13_153757| [-0.35027 -0.61376  0.47083]
21Feb13_153757| [-0.89940  0.17872 -0.52839]
21Feb13_153757| [-1.94942  0.35467 -1.54599]
21Feb13_153757| [ 0.00901  0.85725 -0.40270]
21Feb13_153757| [ 0.56098 -0.26406 -0.53039]
21Feb13_153757| [-0.76616 -1.12136  0.79042]
21Feb13_153757| [-0.13595  0.39278 -1.17800]
21Feb13_153757| [ 0.89288  0.31535 -0.09279]
21Feb13_153757| [ 0.18309 -0.96295 -0.17588]
21Feb13_153757| [ 0.75221  1.37401 -0.89781]
21Feb13_153757| [-0.70757  0.35167 -0.74607]
21Feb13_153757| [ 0.86116  0.60042 -1.51156]
21Feb13_153757| [-0.43082 -1.19351 -0.51187]]
21Feb13_153757|-- Bias --
21Feb13_153757|[ 1.07104 -1.07737  0.83107]
21Feb13_153757|Layer 1:
21Feb13_153757|-- Config --
21Feb13_153757|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153757|-- Weights --
21Feb13_153757|[[ 0.38076 -1.33247  1.12544]
21Feb13_153757| [ 0.73925 -1.15289  0.84060]
21Feb13_153757| [-1.05371 -0.14959  1.24449]]
21Feb13_153757|-- Bias --
21Feb13_153757|[ 0.20502 -0.24416 -0.80573]
21Feb13_153757|Layer 2:
21Feb13_153757|-- Config --
21Feb13_153757|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153757|-- Weights --
21Feb13_153757|[[-1.62327  0.06666]
21Feb13_153757| [ 1.19291 -1.80974]
21Feb13_153757| [ 0.60957 -0.04413]]
21Feb13_153757|-- Bias --
21Feb13_153757|[ 0.14193 -0.78289]
21Feb13_153757|Predicting the validation and test data with the Best final individual.
21Feb13_153805| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_153805|-----------  ------------------  --------------------  ----------
21Feb13_153805|Validation         38.43                  12            0.00000
21Feb13_153805|   Test            30.84                  12            0.36761
21Feb13_153805|-------------------- Test #14 --------------------
21Feb13_153805|Best final individual weights
21Feb13_153805|Individual:
21Feb13_153805|-- Constant hidden layers --
21Feb13_153805|False
21Feb13_153805|Layer 0:
21Feb13_153805|-- Config --
21Feb13_153805|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153805|-- Weights --
21Feb13_153805|[[ 0.38713  2.42063 -0.81233]
21Feb13_153805| [ 0.46584  0.21781 -1.47469]
21Feb13_153805| [ 0.52524  0.25286 -0.75848]
21Feb13_153805| [ 1.05419  0.14503  0.85689]
21Feb13_153805| [-1.80529 -1.45880 -1.06493]
21Feb13_153805| [-0.14918 -1.96139 -1.08659]
21Feb13_153805| [ 1.04503 -0.35673 -0.78110]
21Feb13_153805| [-0.66658  1.37377 -0.34096]
21Feb13_153805| [ 1.52793 -0.71748  1.91379]
21Feb13_153805| [ 0.91559  0.64119  0.67131]
21Feb13_153805| [-0.54570 -1.45433  0.16551]
21Feb13_153805| [ 0.44489 -1.60656  0.63474]
21Feb13_153805| [-0.22650 -0.63288  0.57099]
21Feb13_153805| [ 0.44326  0.45152 -0.51536]
21Feb13_153805| [ 1.40311 -0.66651  0.51698]
21Feb13_153805| [ 1.50925  0.09394  0.01281]
21Feb13_153805| [-1.76743 -1.28362 -0.72095]
21Feb13_153805| [-0.33819 -1.05380 -0.75191]
21Feb13_153805| [-0.40027 -0.59070 -1.35452]
21Feb13_153805| [-0.54297  1.55915  0.23082]
21Feb13_153805| [-0.86819 -1.75993 -1.07029]
21Feb13_153805| [ 1.30716  0.60079  0.37201]
21Feb13_153805| [-1.47537 -2.19202  1.41716]
21Feb13_153805| [ 1.31558 -0.88044  0.04700]
21Feb13_153805| [-2.05456  0.34059 -1.64271]
21Feb13_153805| [-1.97535  1.71428  0.44055]
21Feb13_153805| [ 0.68070  0.31593  0.25745]
21Feb13_153805| [-0.67951  0.91202 -1.61528]
21Feb13_153805| [ 0.96970  0.68426  0.90910]
21Feb13_153805| [ 0.50563 -1.36234 -0.15913]
21Feb13_153805| [-0.18236 -0.09802  0.32229]
21Feb13_153805| [-0.55016 -0.25396  1.79019]
21Feb13_153805| [-1.25899  0.21076  0.55796]
21Feb13_153805| [-1.01640  1.44683 -0.99457]
21Feb13_153805| [-1.00496  1.79390 -0.53071]
21Feb13_153805| [ 0.15909  1.13690 -0.26700]
21Feb13_153805| [ 0.64458  0.48383  0.79797]
21Feb13_153805| [ 0.18767 -1.17443 -1.18586]
21Feb13_153805| [-0.87376 -0.46862 -0.73299]
21Feb13_153805| [-0.76586 -0.54795  1.67859]
21Feb13_153805| [ 0.85147  0.44981 -0.14231]
21Feb13_153805| [ 1.09911  0.31086 -0.91574]
21Feb13_153805| [-1.62543  0.32096  0.91669]
21Feb13_153805| [-1.16200 -0.04002  0.12671]
21Feb13_153805| [-0.35027 -0.61376  0.47083]
21Feb13_153805| [-0.89940  0.17872 -0.52839]
21Feb13_153805| [-1.94942  0.35467 -1.54599]
21Feb13_153805| [ 0.00901  0.85725 -0.40270]
21Feb13_153805| [ 0.56098 -0.26406 -0.53039]
21Feb13_153805| [-0.76616 -1.12136  0.79042]
21Feb13_153805| [-0.13595  0.39278 -1.17800]
21Feb13_153805| [ 0.89288  0.31535 -0.09279]
21Feb13_153805| [ 0.18309 -0.96295 -0.17588]
21Feb13_153805| [ 0.75221  1.37401 -0.89781]
21Feb13_153805| [-0.70757  0.35167 -0.74607]
21Feb13_153805| [ 0.86116  0.60042 -1.51156]
21Feb13_153805| [-0.43082 -1.19351 -0.51187]]
21Feb13_153805|-- Bias --
21Feb13_153805|[ 1.07104 -1.07737  0.83107]
21Feb13_153805|Layer 1:
21Feb13_153805|-- Config --
21Feb13_153805|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153805|-- Weights --
21Feb13_153805|[[ 0.38076 -1.33247  1.12544]
21Feb13_153805| [ 0.73925 -1.15289  0.84060]
21Feb13_153805| [-1.05371 -0.14959  1.24449]]
21Feb13_153805|-- Bias --
21Feb13_153805|[ 0.20502 -0.24416 -0.80573]
21Feb13_153805|Layer 2:
21Feb13_153805|-- Config --
21Feb13_153805|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_153805|-- Weights --
21Feb13_153805|[[-1.62327  0.06666]
21Feb13_153805| [ 1.19291 -1.80974]
21Feb13_153805| [ 0.60957 -0.04413]]
21Feb13_153805|-- Bias --
21Feb13_153805|[ 0.14193 -0.78289]
21Feb13_153805|Predicting the validation and test data with the Best final individual.
21Feb13_153812| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_153812|-----------  ------------------  --------------------  ----------
21Feb13_153812|Validation         38.43                  12            0.00000
21Feb13_153812|   Test            39.44                  12            0.00000
2021-02-13 15:38:13.180730: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
21Feb13_153814|Data summary: Train
21Feb13_153814|data.shape = (2300, 57)
21Feb13_153814|labels.shape = (2300,)
21Feb13_153814|Class distribution:
21Feb13_153814|	0 - 1383 (0.60)
21Feb13_153814|	1 - 917 (0.40)
21Feb13_153814|Data summary: Validation
21Feb13_153814|data.shape = (1150, 57)
21Feb13_153814|labels.shape = (1150,)
21Feb13_153814|Class distribution:
21Feb13_153814|	0 - 708 (0.62)
21Feb13_153814|	1 - 442 (0.38)
21Feb13_153814|Data summary: Test
21Feb13_153814|data.shape = (1151, 57)
21Feb13_153814|labels.shape = (1151,)
21Feb13_153814|Class distribution:
21Feb13_153814|	0 - 697 (0.61)
21Feb13_153814|	1 - 454 (0.39)
21Feb13_153814|Selected configuration values
21Feb13_153814|-- Dataset name: spambase3
21Feb13_153814|-- Initial population size: 64
21Feb13_153814|-- Maximun number of generations: 32
21Feb13_153814|-- Neurons per hidden layer range: (2, 20)
21Feb13_153814|-- Hidden layers number range: (1, 3)
21Feb13_153814|-- Crossover probability: 0.5
21Feb13_153814|-- Bias gene mutation probability: 0.2
21Feb13_153814|-- Weights gene mutation probability: 0.75
21Feb13_153814|-- Neuron mutation probability: 0.3
21Feb13_153814|-- Layer mutation probability: 0.3
21Feb13_153814|-- Constant hidden layers: False
21Feb13_153814|-- Seed: 31415
21Feb13_153814|Entering GA
21Feb13_153814|Start the algorithm
2021-02-13 15:38:14.066215: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-13 15:38:14.066737: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-02-13 15:38:14.086946: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-13 15:38:14.087272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.71GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s
2021-02-13 15:38:14.087286: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-02-13 15:38:14.088716: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-02-13 15:38:14.088744: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-02-13 15:38:14.089231: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-02-13 15:38:14.089363: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-02-13 15:38:14.089434: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-13 15:38:14.089827: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-02-13 15:38:14.089867: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-13 15:38:14.089873: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-02-13 15:38:14.090089: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-02-13 15:38:14.090841: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-13 15:38:14.090857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-13 15:38:14.090860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      
2021-02-13 15:38:14.137076: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-02-13 15:38:14.137399: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3493635000 Hz
/home/jmerelo/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype("int32")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn('`model.predict_classes()` is deprecated and '
21Feb13_154215|-- Generation 1 --
21Feb13_154215|    -- Crossed 0 individual pairs.
21Feb13_154215|    -- Mutated 32 individuals.
21Feb13_154613|    -- Evaluated 64 individuals.
21Feb13_154613|    Summary of generation 1:
21Feb13_154613| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_154613|-----------  ------------------  --------------------  ----------
21Feb13_154613|    Max            38.87                112.00          0.50515
21Feb13_154613|    Avg            37.89                36.86           0.02559
21Feb13_154613|    Min            26.17                 4.00           0.00000
21Feb13_154613|    Std             2.28                27.63           0.09169
21Feb13_154613|   Best            26.17                20.00           0.50515
21Feb13_154613|-- Generation 2 --
21Feb13_154613|    -- Crossed 1 individual pairs.
21Feb13_154613|    -- Mutated 32 individuals.
21Feb13_155010|    -- Evaluated 64 individuals.
21Feb13_155010|    Summary of generation 2:
21Feb13_155010| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_155010|-----------  ------------------  --------------------  ----------
21Feb13_155010|    Max            39.13                78.00           0.46177
21Feb13_155010|    Avg            38.08                30.58           0.01697
21Feb13_155010|    Min            27.48                 4.00           0.00000
21Feb13_155010|    Std             1.82                18.72           0.07203
21Feb13_155010|   Best            27.48                10.00           0.46177
21Feb13_155010|-- Generation 3 --
21Feb13_155010|    -- Crossed 3 individual pairs.
21Feb13_155010|    -- Mutated 32 individuals.
21Feb13_155403|    -- Evaluated 64 individuals.
21Feb13_155403|    Summary of generation 3:
21Feb13_155403| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_155403|-----------  ------------------  --------------------  ----------
21Feb13_155403|    Max            38.87                48.00           0.67979
21Feb13_155403|    Avg            37.37                17.56           0.04453
21Feb13_155403|    Min            19.74                 4.00           0.00000
21Feb13_155403|    Std             3.61                11.00           0.14464
21Feb13_155403|   Best            19.74                 5.00           0.67979
21Feb13_155403|-- Generation 4 --
21Feb13_155403|    -- Crossed 1 individual pairs.
21Feb13_155403|    -- Mutated 32 individuals.
21Feb13_155754|    -- Evaluated 64 individuals.
21Feb13_155754|    Summary of generation 4:
21Feb13_155754| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_155754|-----------  ------------------  --------------------  ----------
21Feb13_155754|    Max            39.04                69.00           0.47277
21Feb13_155754|    Avg            37.97                15.09           0.02012
21Feb13_155754|    Min            27.13                 2.00           0.00000
21Feb13_155754|    Std             1.95                12.71           0.07864
21Feb13_155754|   Best            27.13                24.00           0.47277
21Feb13_155754|-- Generation 5 --
21Feb13_155754|    -- Crossed 2 individual pairs.
21Feb13_155754|    -- Mutated 32 individuals.
21Feb13_160142|    -- Evaluated 64 individuals.
21Feb13_160142|    Summary of generation 5:
21Feb13_160142| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_160142|-----------  ------------------  --------------------  ----------
21Feb13_160142|    Max            39.74                44.00           0.66712
21Feb13_160142|    Avg            37.43                 7.95           0.04425
21Feb13_160142|    Min            25.65                 2.00           0.00000
21Feb13_160142|    Std             3.11                 6.78           0.13268
21Feb13_160142|   Best            25.65                 3.00           0.66712
21Feb13_160142|-- Generation 6 --
21Feb13_160142|    -- Crossed 7 individual pairs.
21Feb13_160142|    -- Mutated 32 individuals.
21Feb13_160531|    -- Evaluated 64 individuals.
21Feb13_160531|    Summary of generation 6:
21Feb13_160531| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_160531|-----------  ------------------  --------------------  ----------
21Feb13_160531|    Max            38.87                44.00           0.80491
21Feb13_160531|    Avg            37.47                 8.80           0.05458
21Feb13_160531|    Min            25.39                 2.00           0.00000
21Feb13_160531|    Std             3.08                 7.41           0.16238
21Feb13_160531|   Best            25.39                16.00           0.56088
21Feb13_160531|-- Generation 7 --
21Feb13_160531|    -- Crossed 4 individual pairs.
21Feb13_160531|    -- Mutated 32 individuals.
21Feb13_160920|    -- Evaluated 64 individuals.
21Feb13_160920|    Summary of generation 7:
21Feb13_160920| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_160920|-----------  ------------------  --------------------  ----------
21Feb13_160920|    Max            38.96                46.00           0.38618
21Feb13_160920|    Avg            38.06                 9.11           0.01821
21Feb13_160920|    Min            29.39                 2.00           0.00000
21Feb13_160920|    Std             1.39                 8.85           0.05922
21Feb13_160920|   Best            29.39                21.00           0.38618
21Feb13_160920|-- Generation 8 --
21Feb13_160920|    -- Crossed 3 individual pairs.
21Feb13_160920|    -- Mutated 32 individuals.
21Feb13_161308|    -- Evaluated 64 individuals.
21Feb13_161308|    Summary of generation 8:
21Feb13_161308| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_161308|-----------  ------------------  --------------------  ----------
21Feb13_161308|    Max            39.04                44.00           0.79584
21Feb13_161308|    Avg            37.88                 7.23           0.03035
21Feb13_161308|    Min            24.35                 2.00           0.00000
21Feb13_161308|    Std             2.29                 7.33           0.11689
21Feb13_161308|   Best            24.35                12.00           0.79584
21Feb13_161308|-- Generation 9 --
21Feb13_161308|    -- Crossed 3 individual pairs.
21Feb13_161308|    -- Mutated 32 individuals.
21Feb13_161655|    -- Evaluated 64 individuals.
21Feb13_161655|    Summary of generation 9:
21Feb13_161655| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_161655|-----------  ------------------  --------------------  ----------
21Feb13_161655|    Max            54.52                48.00           0.77778
21Feb13_161655|    Avg            37.81                 8.91           0.04952
21Feb13_161655|    Min            26.00                 2.00           0.00000
21Feb13_161655|    Std             3.30                 9.15           0.13914
21Feb13_161655|   Best            26.00                14.00           0.55156
21Feb13_161655|-- Generation 10 --
21Feb13_161655|    -- Crossed 2 individual pairs.
21Feb13_161655|    -- Mutated 32 individuals.
21Feb13_162045|    -- Evaluated 64 individuals.
21Feb13_162045|    Summary of generation 10:
21Feb13_162045| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_162045|-----------  ------------------  --------------------  ----------
21Feb13_162045|    Max            39.13                46.00           0.63849
21Feb13_162045|    Avg            37.84                 9.98           0.02795
21Feb13_162045|    Min            25.65                 2.00           0.00000
21Feb13_162045|    Std             2.13                10.91           0.09618
21Feb13_162045|   Best            25.65                21.00           0.63849
21Feb13_162045|-- Generation 11 --
21Feb13_162045|    -- Crossed 2 individual pairs.
21Feb13_162045|    -- Mutated 32 individuals.
21Feb13_162434|    -- Evaluated 64 individuals.
21Feb13_162434|    Summary of generation 11:
21Feb13_162434| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_162434|-----------  ------------------  --------------------  ----------
21Feb13_162434|    Max            38.70                54.00           0.40595
21Feb13_162434|    Avg            37.97                 9.31           0.02122
21Feb13_162434|    Min            29.13                 2.00           0.00000
21Feb13_162434|    Std             1.38                 9.78           0.06047
21Feb13_162434|   Best            29.13                21.00           0.40595
21Feb13_162434|-- Generation 12 --
21Feb13_162434|    -- Crossed 4 individual pairs.
21Feb13_162434|    -- Mutated 32 individuals.
21Feb13_162824|    -- Evaluated 64 individuals.
21Feb13_162824|    Summary of generation 12:
21Feb13_162824| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_162824|-----------  ------------------  --------------------  ----------
21Feb13_162824|    Max            39.13                50.00           0.52027
21Feb13_162824|    Avg            37.56                10.12           0.03981
21Feb13_162824|    Min            25.65                 2.00           0.00000
21Feb13_162824|    Std             2.34                 9.67           0.09894
21Feb13_162824|   Best            25.65                20.00           0.52027
21Feb13_162824|-- Generation 13 --
21Feb13_162824|    -- Crossed 5 individual pairs.
21Feb13_162824|    -- Mutated 32 individuals.
21Feb13_163212|    -- Evaluated 64 individuals.
21Feb13_163212|    Summary of generation 13:
21Feb13_163212| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_163212|-----------  ------------------  --------------------  ----------
21Feb13_163212|    Max            38.70                48.00           0.70787
21Feb13_163212|    Avg            37.28                 9.06           0.04945
21Feb13_163212|    Min            23.39                 2.00           0.00000
21Feb13_163212|    Std             3.09                 9.42           0.13707
21Feb13_163212|   Best            23.39                21.00           0.70787
21Feb13_163212|-- Generation 14 --
21Feb13_163212|    -- Crossed 6 individual pairs.
21Feb13_163212|    -- Mutated 32 individuals.
21Feb13_163603|    -- Evaluated 64 individuals.
21Feb13_163603|    Summary of generation 14:
21Feb13_163603| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_163603|-----------  ------------------  --------------------  ----------
21Feb13_163603|    Max            38.70                42.00           0.59152
21Feb13_163603|    Avg            37.25                11.44           0.05241
21Feb13_163603|    Min            27.22                 2.00           0.00000
21Feb13_163603|    Std             2.57                 9.87           0.11722
21Feb13_163603|   Best            27.22                 6.00           0.59152
21Feb13_163603|-- Generation 15 --
21Feb13_163603|    -- Crossed 4 individual pairs.
21Feb13_163603|    -- Mutated 32 individuals.
21Feb13_163951|    -- Evaluated 64 individuals.
21Feb13_163951|    Summary of generation 15:
21Feb13_163951| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_163951|-----------  ------------------  --------------------  ----------
21Feb13_163951|    Max            45.57                42.00           0.80337
21Feb13_163951|    Avg            37.81                10.34           0.04461
21Feb13_163951|    Min            25.65                 2.00           0.00000
21Feb13_163951|    Std             2.08                 8.34           0.12093
21Feb13_163951|   Best            25.65                22.00           0.51834
21Feb13_163951|-- Generation 16 --
21Feb13_163951|    -- Crossed 2 individual pairs.
21Feb13_163951|    -- Mutated 32 individuals.
21Feb13_164340|    -- Evaluated 64 individuals.
21Feb13_164340|    Summary of generation 16:
21Feb13_164340| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_164340|-----------  ------------------  --------------------  ----------
21Feb13_164340|    Max            38.78                46.00           0.53667
21Feb13_164340|    Avg            37.33                12.78           0.04770
21Feb13_164340|    Min            25.30                 2.00           0.00000
21Feb13_164340|    Std             2.38                 9.99           0.09690
21Feb13_164340|   Best            25.30                 4.00           0.53667
21Feb13_164340|-- Generation 17 --
21Feb13_164340|    -- Crossed 1 individual pairs.
21Feb13_164340|    -- Mutated 32 individuals.
21Feb13_164730|    -- Evaluated 64 individuals.
21Feb13_164730|    Summary of generation 17:
21Feb13_164730| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_164730|-----------  ------------------  --------------------  ----------
21Feb13_164730|    Max            38.70                50.00           0.37991
21Feb13_164730|    Avg            37.53                12.22           0.03936
21Feb13_164730|    Min            29.04                 2.00           0.00000
21Feb13_164730|    Std             1.87                11.41           0.07899
21Feb13_164730|   Best            29.04                20.00           0.34528
21Feb13_164730|-- Generation 18 --
21Feb13_164730|    -- Crossed 2 individual pairs.
21Feb13_164730|    -- Mutated 32 individuals.
21Feb13_165120|    -- Evaluated 64 individuals.
21Feb13_165120|    Summary of generation 18:
21Feb13_165120| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_165120|-----------  ------------------  --------------------  ----------
21Feb13_165120|    Max            38.87                48.00           0.44132
21Feb13_165120|    Avg            37.63                12.58           0.03620
21Feb13_165120|    Min            27.48                 2.00           0.00000
21Feb13_165120|    Std             1.75                10.90           0.07122
21Feb13_165120|   Best            27.48                20.00           0.44132
21Feb13_165120|-- Generation 19 --
21Feb13_165120|    -- Crossed 2 individual pairs.
21Feb13_165120|    -- Mutated 32 individuals.
21Feb13_165509|    -- Evaluated 64 individuals.
21Feb13_165509|    Summary of generation 19:
21Feb13_165509| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_165509|-----------  ------------------  --------------------  ----------
21Feb13_165509|    Max            38.70                48.00           0.77732
21Feb13_165509|    Avg            37.06                11.17           0.06777
21Feb13_165509|    Min            25.65                 3.00           0.00000
21Feb13_165509|    Std             2.46                 8.42           0.13597
21Feb13_165509|   Best            25.65                22.00           0.54132
21Feb13_165509|-- Generation 20 --
21Feb13_165509|    -- Crossed 1 individual pairs.
21Feb13_165509|    -- Mutated 32 individuals.
21Feb13_165900|    -- Evaluated 64 individuals.
21Feb13_165900|    Summary of generation 20:
21Feb13_165900| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_165900|-----------  ------------------  --------------------  ----------
21Feb13_165900|    Max            38.61                48.00           0.59579
21Feb13_165900|    Avg            36.85                13.17           0.07047
21Feb13_165900|    Min            26.26                 4.00           0.00000
21Feb13_165900|    Std             2.67                10.11           0.12102
21Feb13_165900|   Best            26.26                20.00           0.51657
21Feb13_165900|-- Generation 21 --
21Feb13_165900|    -- Crossed 4 individual pairs.
21Feb13_165900|    -- Mutated 32 individuals.
21Feb13_170250|    -- Evaluated 64 individuals.
21Feb13_170250|    Summary of generation 21:
21Feb13_170250| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_170250|-----------  ------------------  --------------------  ----------
21Feb13_170250|    Max            38.87                44.00           0.69300
21Feb13_170250|    Avg            36.52                13.27           0.08616
21Feb13_170250|    Min            23.48                 4.00           0.00000
21Feb13_170250|    Std             3.07                10.98           0.13737
21Feb13_170250|   Best            23.48                 5.00           0.61792
21Feb13_170250|-- Generation 22 --
21Feb13_170250|    -- Crossed 0 individual pairs.
21Feb13_170250|    -- Mutated 32 individuals.
21Feb13_170639|    -- Evaluated 64 individuals.
21Feb13_170639|    Summary of generation 22:
21Feb13_170639| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_170639|-----------  ------------------  --------------------  ----------
21Feb13_170639|    Max            38.61                48.00           0.71334
21Feb13_170639|    Avg            37.00                12.27           0.06565
21Feb13_170639|    Min            25.39                 3.00           0.00000
21Feb13_170639|    Std             2.22                 9.31           0.10884
21Feb13_170639|   Best            25.39                 5.00           0.71334
21Feb13_170639|-- Generation 23 --
21Feb13_170639|    -- Crossed 3 individual pairs.
21Feb13_170639|    -- Mutated 32 individuals.
21Feb13_171028|    -- Evaluated 64 individuals.
21Feb13_171028|    Summary of generation 23:
21Feb13_171028| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_171028|-----------  ------------------  --------------------  ----------
21Feb13_171028|    Max            38.96                44.00           0.53233
21Feb13_171028|    Avg            36.56                11.41           0.08168
21Feb13_171028|    Min            25.48                 4.00           0.00000
21Feb13_171028|    Std             2.71                 8.72           0.10970
21Feb13_171028|   Best            25.48                18.00           0.53233
21Feb13_171028|-- Generation 24 --
21Feb13_171028|    -- Crossed 1 individual pairs.
21Feb13_171028|    -- Mutated 32 individuals.
21Feb13_171418|    -- Evaluated 64 individuals.
21Feb13_171418|    Summary of generation 24:
21Feb13_171418| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_171418|-----------  ------------------  --------------------  ----------
21Feb13_171418|    Max            38.78                48.00           0.65717
21Feb13_171418|    Avg            36.54                12.66           0.08508
21Feb13_171418|    Min            24.17                 3.00           0.00000
21Feb13_171418|    Std             2.82                10.06           0.12986
21Feb13_171418|   Best            24.17                16.00           0.65717
21Feb13_171418|-- Generation 25 --
21Feb13_171418|    -- Crossed 2 individual pairs.
21Feb13_171418|    -- Mutated 32 individuals.
21Feb13_171808|    -- Evaluated 64 individuals.
21Feb13_171808|    Summary of generation 25:
21Feb13_171808| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_171808|-----------  ------------------  --------------------  ----------
21Feb13_171808|    Max            45.83                44.00           0.79750
21Feb13_171808|    Avg            37.13                11.66           0.07505
21Feb13_171808|    Min            24.61                 3.00           0.00000
21Feb13_171808|    Std             2.34                 9.23           0.13553
21Feb13_171808|   Best            24.61                 6.00           0.70664
21Feb13_171808|-- Generation 26 --
21Feb13_171808|    -- Crossed 2 individual pairs.
21Feb13_171808|    -- Mutated 32 individuals.
21Feb13_172156|    -- Evaluated 64 individuals.
21Feb13_172156|    Summary of generation 26:
21Feb13_172156| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_172156|-----------  ------------------  --------------------  ----------
21Feb13_172156|    Max            38.87                40.00           0.62049
21Feb13_172156|    Avg            36.78                 9.83           0.07842
21Feb13_172156|    Min            27.74                 3.00           0.00000
21Feb13_172156|    Std             1.93                 7.33           0.10461
21Feb13_172156|   Best            27.74                18.00           0.39642
21Feb13_172156|-- Generation 27 --
21Feb13_172156|    -- Crossed 1 individual pairs.
21Feb13_172156|    -- Mutated 32 individuals.
21Feb13_172544|    -- Evaluated 64 individuals.
21Feb13_172544|    Summary of generation 27:
21Feb13_172544| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_172544|-----------  ------------------  --------------------  ----------
21Feb13_172544|    Max            38.87                36.00           0.71238
21Feb13_172544|    Avg            36.81                 8.89           0.07588
21Feb13_172544|    Min            24.78                 4.00           0.00000
21Feb13_172544|    Std             1.83                 6.78           0.09734
21Feb13_172544|   Best            24.78                18.00           0.71238
21Feb13_172544|-- Generation 28 --
21Feb13_172544|    -- Crossed 3 individual pairs.
21Feb13_172544|    -- Mutated 32 individuals.
21Feb13_172932|    -- Evaluated 64 individuals.
21Feb13_172932|    Summary of generation 28:
21Feb13_172932| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_172932|-----------  ------------------  --------------------  ----------
21Feb13_172932|    Max            46.26                44.00           0.79353
21Feb13_172932|    Avg            36.96                 9.62           0.08317
21Feb13_172932|    Min            26.43                 3.00           0.00000
21Feb13_172932|    Std             2.09                 9.09           0.12164
21Feb13_172932|   Best            26.43                20.00           0.53140
21Feb13_172932|-- Generation 29 --
21Feb13_172932|    -- Crossed 2 individual pairs.
21Feb13_172932|    -- Mutated 32 individuals.
21Feb13_173321|    -- Evaluated 64 individuals.
21Feb13_173321|    Summary of generation 29:
21Feb13_173321| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_173321|-----------  ------------------  --------------------  ----------
21Feb13_173321|    Max            38.78                39.00           0.52195
21Feb13_173321|    Avg            36.17                 8.48           0.10341
21Feb13_173321|    Min            25.74                 3.00           0.00000
21Feb13_173321|    Std             2.31                 7.41           0.10996
21Feb13_173321|   Best            25.74                12.00           0.52195
21Feb13_173321|-- Generation 30 --
21Feb13_173321|    -- Crossed 3 individual pairs.
21Feb13_173321|    -- Mutated 32 individuals.
21Feb13_173710|    -- Evaluated 64 individuals.
21Feb13_173710|    Summary of generation 30:
21Feb13_173710| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_173710|-----------  ------------------  --------------------  ----------
21Feb13_173710|    Max            38.61                39.00           0.63894
21Feb13_173710|    Avg            36.44                 9.12           0.08758
21Feb13_173710|    Min            24.00                 3.00           0.00000
21Feb13_173710|    Std             2.66                 7.09           0.12038
21Feb13_173710|   Best            24.00                20.00           0.63894
21Feb13_173710|-- Generation 31 --
21Feb13_173710|    -- Crossed 2 individual pairs.
21Feb13_173710|    -- Mutated 32 individuals.
21Feb13_174100|    -- Evaluated 64 individuals.
21Feb13_174100|    Summary of generation 31:
21Feb13_174100| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_174100|-----------  ------------------  --------------------  ----------
21Feb13_174100|    Max            55.30                22.00           0.77532
21Feb13_174100|    Avg            36.45                 8.70           0.11695
21Feb13_174100|    Min            21.65                 4.00           0.00000
21Feb13_174100|    Std             3.75                 5.82           0.15852
21Feb13_174100|   Best            21.65                 5.00           0.73510
21Feb13_174100|-- Generation 32 --
21Feb13_174100|    -- Crossed 1 individual pairs.
21Feb13_174100|    -- Mutated 32 individuals.
21Feb13_174448|    -- Evaluated 64 individuals.
21Feb13_174448|    Summary of generation 32:
21Feb13_174448| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_174448|-----------  ------------------  --------------------  ----------
21Feb13_174448|    Max            39.04                48.00           0.52098
21Feb13_174448|    Avg            36.33                 9.02           0.08829
21Feb13_174448|    Min            26.52                 4.00           0.00000
21Feb13_174448|    Std             2.04                 8.64           0.08696
21Feb13_174448|   Best            26.52                20.00           0.47038
21Feb13_174448|Best initial individual weights
21Feb13_174448|Individual:
21Feb13_174448|-- Constant hidden layers --
21Feb13_174448|False
21Feb13_174448|Layer 0:
21Feb13_174448|-- Config --
21Feb13_174448|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 15, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174448|-- Weights --
21Feb13_174448|[[ 9.73296e-01 -8.26784e-01 -2.96439e-01 -5.24875e-01 -9.75570e-01
21Feb13_174448|   5.94797e-01  6.56579e-01 -3.55245e-01 -2.06319e-01  7.24525e-02
21Feb13_174448|  -8.18340e-01  3.72301e-01 -8.88903e-01  8.38473e-01 -1.36175e-01]
21Feb13_174448| [ 9.00747e-01 -4.73475e-01 -5.86061e-01 -9.96560e-01 -9.08973e-01
21Feb13_174448|   7.36703e-01 -5.66014e-02 -4.95681e-01 -2.37518e-01  7.36167e-01
21Feb13_174448|   1.18646e-01 -9.34807e-01  1.14774e-01 -1.67031e-01  3.02418e-02]
21Feb13_174448| [-2.75124e-01 -2.99372e-01  2.96611e-03  2.17706e-01  2.22480e-01
21Feb13_174448|   2.85044e-02  3.03819e-01 -3.38706e-02 -2.90173e-01 -2.69699e-01
21Feb13_174448|  -7.85345e-02 -1.49466e-01  3.23384e-01 -1.80370e-01 -2.99972e-01]
21Feb13_174448| [-5.80245e-01  9.85830e-01  1.17641e-03  1.65423e-01 -6.59634e-01
21Feb13_174448|  -3.71185e-01 -7.27571e-01 -1.00209e-01  8.64598e-01 -6.10691e-01
21Feb13_174448|   7.19932e-01  3.21970e-01 -7.00390e-01 -7.10769e-01  2.95705e-01]
21Feb13_174448| [-8.73382e-01  9.76324e-01  8.48430e-02  9.25840e-01 -2.02163e-01
21Feb13_174448|  -1.87887e-01  2.81858e-01  1.43536e-01 -3.05554e-01 -6.69890e-01
21Feb13_174448|   1.58904e-01 -8.97804e-01 -1.32196e-01 -7.37863e-01 -1.90775e-01]
21Feb13_174448| [ 5.44972e-01 -7.61313e-01  4.93506e-01  3.85686e-01 -5.60992e-01
21Feb13_174448|  -4.78222e-01 -5.32042e-01  7.25155e-02 -3.72247e-02  4.27292e-01
21Feb13_174448|   3.62496e-01  2.23487e-01  7.55995e-01  8.53424e-01 -3.57402e-01]
21Feb13_174448| [ 2.69735e-01 -7.35381e-01  8.58039e-01  5.50856e-01 -8.98355e-01
21Feb13_174448|   2.29710e-01 -4.68342e-01  6.32265e-02  1.29601e-02 -8.69018e-01
21Feb13_174448|  -2.73360e-01  2.64992e-01  6.92574e-01 -1.80612e-01 -6.18940e-01]
21Feb13_174448| [ 5.32712e-01 -3.07491e-01 -8.59999e-01 -9.69560e-01  9.74953e-01
21Feb13_174448|   5.11015e-02  4.92610e-01 -7.25292e-01  7.13820e-01 -1.43535e-02
21Feb13_174448|   7.27951e-01  7.71337e-02  8.45383e-01  6.68537e-01 -4.33622e-01]
21Feb13_174448| [-1.09130e-01  5.41333e-01  4.93394e-01  8.63442e-01  8.53343e-01
21Feb13_174448|  -1.12858e-01  7.37356e-01 -4.42087e-02  8.30579e-01  1.38212e-01
21Feb13_174448|   9.88480e-02  7.51784e-01  5.54371e-01  8.47549e-01  8.13372e-02]
21Feb13_174448| [-5.42155e-01 -4.32240e-01 -5.86458e-02 -1.28264e-02  5.78083e-01
21Feb13_174448|   1.68026e-01 -9.11094e-01  4.58106e-01  6.00229e-01  2.17770e-01
21Feb13_174448|   4.34134e-01 -8.53385e-02  4.69495e-01 -2.96878e-01  4.59397e-01]
21Feb13_174448| [-5.68827e-01 -9.10070e-01 -9.04407e-01  7.15505e-01 -1.18063e-01
21Feb13_174448|   2.92277e-03  3.96874e-01 -7.57933e-01  1.39258e-01 -7.48572e-01
21Feb13_174448|   9.76774e-01 -3.96754e-01 -3.75098e-02 -8.37290e-01 -9.68913e-01]
21Feb13_174448| [ 3.85405e-01 -1.66417e-01 -7.72831e-01  5.34828e-01  5.82538e-01
21Feb13_174448|   2.61182e-01 -1.77447e-01 -6.45280e-01 -3.56417e-01 -4.00832e-01
21Feb13_174448|  -9.18095e-01  5.40437e-01  7.49226e-01  3.72730e-01  6.82412e-01]
21Feb13_174448| [-5.90300e-01  5.47573e-01 -2.29506e-02  1.97113e-01 -9.92234e-01
21Feb13_174448|  -4.27465e-01  5.90379e-01  2.70200e-01  3.00202e-01  5.73789e-01
21Feb13_174448|  -2.95641e-01  5.78653e-01 -1.94578e-01  3.61894e-01  6.34740e-02]
21Feb13_174448| [ 2.26425e-01  4.30697e-01 -7.48931e-01  1.34168e-01 -6.17358e-02
21Feb13_174448|   1.86230e-01  7.52588e-01 -3.89451e-01  8.39574e-01  5.82897e-01
21Feb13_174448|  -1.13470e-02 -8.19377e-01 -8.18108e-01  6.24046e-01 -5.54897e-01]
21Feb13_174448| [-5.26836e-01  5.86005e-01 -5.96458e-01 -6.81120e-01  1.84856e-01
21Feb13_174448|   4.96869e-01 -1.31473e-01  4.40657e-01  6.64130e-01  6.22928e-01
21Feb13_174448|  -7.74363e-02 -3.55086e-01 -2.82231e-01  6.46269e-01  1.75388e-01]
21Feb13_174448| [-7.76956e-01 -3.86536e-01  4.36460e-01 -9.92290e-01  7.38722e-02
21Feb13_174448|   7.04992e-01  1.61774e-01 -6.96625e-01 -1.82122e-02  4.77476e-01
21Feb13_174448|   6.36754e-01  1.11465e-01  5.77527e-01  1.58442e-01 -6.62716e-01]
21Feb13_174448| [ 3.47724e-01 -3.90904e-01 -6.29011e-02 -2.04190e-01 -6.92395e-01
21Feb13_174448|  -5.16254e-01  7.11614e-01 -8.77321e-01 -4.47844e-01  7.31159e-01
21Feb13_174448|  -8.28271e-01 -3.51425e-01  6.37538e-01  5.04277e-01  3.92425e-01]
21Feb13_174448| [ 7.75524e-01 -9.01971e-01 -8.17344e-01  9.65231e-01 -2.42290e-01
21Feb13_174448|  -4.48188e-01 -7.58196e-01  1.21021e-01 -4.30787e-01  1.16232e-01
21Feb13_174448|  -1.88406e-01 -3.28890e-01 -8.98977e-01 -3.63500e-02  2.86674e-01]
21Feb13_174448| [-8.40432e-01 -6.71444e-02 -3.73544e-01  1.66693e-01 -8.24864e-01
21Feb13_174448|  -8.87827e-01 -4.18794e-01 -3.81438e-01 -9.71525e-01 -9.80858e-01
21Feb13_174448|   1.13439e-01  2.81032e-01 -4.22822e-01 -2.04687e-01  1.75317e-01]
21Feb13_174448| [-4.20436e-01  2.57572e-01 -3.07821e-01  6.44066e-01  7.91418e-01
21Feb13_174448|  -6.82975e-01  3.42860e-01 -6.44128e-02 -9.34328e-01  7.62391e-02
21Feb13_174448|  -9.59002e-01  8.34106e-02 -8.89504e-01 -1.49882e-01 -1.11396e-01]
21Feb13_174448| [ 6.98833e-01  1.54037e-01  3.14249e-01 -5.01089e-01 -6.44545e-01
21Feb13_174448|   1.55008e-01 -1.94187e-01 -5.94875e-01 -7.36832e-01  8.21613e-02
21Feb13_174448|   3.41441e-02 -4.42761e-02  4.77304e-02 -2.91558e-01  2.88672e-01]
21Feb13_174448| [ 2.48630e-01  5.01011e-01 -6.50631e-01 -6.13626e-02 -9.30021e-01
21Feb13_174448|   5.18612e-01 -4.27695e-01 -5.21728e-01 -2.97082e-01 -9.57096e-01
21Feb13_174448|  -1.21237e-04  6.69464e-01 -6.15966e-01  6.54204e-01  5.66081e-01]
21Feb13_174448| [-9.53841e-01 -8.01340e-01 -9.16434e-01  2.57455e-01 -8.96467e-01
21Feb13_174448|   7.80358e-01  4.63009e-01  5.06015e-01 -3.73053e-01  3.37301e-01
21Feb13_174448|  -2.34600e-01  5.09622e-01 -3.02048e-01 -6.64473e-01 -1.98920e-01]
21Feb13_174448| [-2.18071e-01  2.15106e-01 -9.50319e-01 -9.11332e-01 -9.18482e-01
21Feb13_174448|   1.26622e-01  5.92950e-01  6.93913e-01 -7.25339e-01  2.36405e-01
21Feb13_174448|  -2.83842e-01 -9.08534e-01  2.60791e-01 -4.92172e-01  6.25202e-01]
21Feb13_174448| [ 3.22399e-01  5.30300e-01 -6.82594e-01 -6.29378e-02 -2.78435e-01
21Feb13_174448|   4.91838e-01  2.99825e-02 -8.64897e-01  6.09917e-01  9.09602e-01
21Feb13_174448|   5.44039e-01 -3.00486e-01 -3.32137e-01 -3.21246e-02  8.14287e-01]
21Feb13_174448| [ 9.87171e-01  4.36304e-01  9.80301e-01 -9.56450e-01  5.23598e-01
21Feb13_174448|  -3.00486e-01 -9.81154e-01  6.47157e-01 -6.02031e-01  7.81558e-01
21Feb13_174448|  -2.30610e-01  2.44907e-01  4.19133e-01  2.22724e-01 -8.17960e-01]
21Feb13_174448| [-7.00505e-01  3.02186e-01 -5.61855e-01  6.15549e-01 -4.22791e-01
21Feb13_174448|   3.88411e-01 -5.82917e-01 -7.77882e-01  6.30600e-01 -1.96906e-01
21Feb13_174448|  -3.88054e-02 -5.55807e-01  8.92183e-01  8.21948e-01  1.74197e-01]
21Feb13_174448| [-4.47370e-01  2.05525e-01 -5.62731e-01 -1.98036e-01  2.28871e-01
21Feb13_174448|  -3.83538e-01 -8.13049e-01 -5.91726e-01 -4.19478e-01  7.08680e-01
21Feb13_174448|   2.83808e-01 -7.78897e-01 -5.65193e-01  3.84515e-01 -7.96749e-02]
21Feb13_174448| [-4.81320e-01 -1.73693e-01  3.48146e-01 -9.81670e-01  1.37818e-01
21Feb13_174448|  -2.34945e-01  1.61326e-01 -8.27229e-01 -1.04174e-02 -7.75256e-01
21Feb13_174448|   8.52992e-01 -4.99718e-01 -6.70967e-01 -2.25740e-01 -1.50898e-01]
21Feb13_174448| [ 3.84415e-01 -6.97226e-01 -1.51865e-01  9.18693e-01 -1.77648e-01
21Feb13_174448|   1.22856e-01  8.70082e-01 -6.18862e-01  9.34392e-02 -7.34260e-01
21Feb13_174448|  -5.19661e-01 -9.84020e-01  8.89976e-01 -9.22672e-01 -8.30637e-01]
21Feb13_174448| [-4.54498e-01  9.73784e-01  9.14263e-01 -9.59356e-01  7.62535e-01
21Feb13_174448|   3.81394e-01 -7.75235e-01 -2.75059e-01  7.53859e-01  3.38388e-01
21Feb13_174448|   8.59783e-01  2.10799e-01  3.38360e-01  8.62964e-01 -5.82977e-01]
21Feb13_174448| [ 1.92625e-01 -3.99306e-01  1.07271e-01 -4.51425e-01  4.70392e-01
21Feb13_174448|  -7.65438e-01  6.60993e-01 -8.01258e-01  4.67186e-01 -3.16915e-01
21Feb13_174448|   2.94527e-01 -5.33788e-01 -7.45073e-01 -8.42078e-01 -5.44571e-01]
21Feb13_174448| [-3.62993e-01  1.11266e-01 -5.71362e-01 -3.91574e-01 -9.61148e-01
21Feb13_174448|  -2.90496e-01  8.31183e-01 -3.84938e-01  2.69751e-01 -3.15175e-01
21Feb13_174448|   9.99210e-01 -9.53149e-01 -8.61738e-01  7.70126e-02  5.10691e-01]
21Feb13_174448| [ 8.05352e-01 -4.08977e-01 -9.07560e-01 -8.64653e-01 -1.07789e-01
21Feb13_174448|   2.64140e-01  5.05728e-01  7.48289e-01 -8.65071e-01 -8.18224e-01
21Feb13_174448|   6.78505e-02 -5.06326e-01  1.10690e-01 -8.55440e-01  5.75289e-01]
21Feb13_174448| [ 2.95517e-01 -3.52707e-01 -6.55711e-01  1.07292e-01 -2.91000e-01
21Feb13_174448|  -3.16299e-01  1.98809e-01  5.17179e-01 -9.37755e-01 -6.17104e-01
21Feb13_174448|   7.41318e-01  2.47303e-01  6.90518e-01  3.51857e-01  2.81666e-01]
21Feb13_174448| [ 1.69992e-01  6.04754e-01 -1.32633e-01  6.79534e-01  5.85447e-01
21Feb13_174448|  -6.69632e-01  8.55732e-01 -7.23004e-02  7.71841e-01  5.93699e-01
21Feb13_174448|  -4.01829e-01  2.99000e-01 -2.48420e-01  1.69612e-01  2.61404e-01]
21Feb13_174448| [-4.65263e-01 -5.50757e-01 -2.30908e-02  3.64198e-01  3.79782e-01
21Feb13_174448|  -2.25316e-01  3.04353e-01 -2.00693e-01 -1.18218e-01 -5.52641e-01
21Feb13_174448|   7.10195e-01  8.06878e-01 -5.65174e-01 -4.26162e-01  3.95536e-01]
21Feb13_174448| [-5.61400e-01 -3.19431e-01  2.72779e-01 -1.29018e-01  7.70589e-02
21Feb13_174448|   3.21503e-01 -5.90943e-01  4.24158e-01 -7.05493e-01  5.09745e-01
21Feb13_174448|  -2.41282e-01  4.55611e-01  7.72834e-01 -9.97347e-01 -8.58771e-01]
21Feb13_174448| [-5.46366e-01 -4.86772e-01 -8.62551e-01  7.62475e-01 -1.98789e-03
21Feb13_174448|  -1.56016e-01  3.51919e-01  2.74028e-01 -9.67446e-01  4.31075e-01
21Feb13_174448|  -4.27418e-01 -3.50042e-01 -1.95930e-01 -2.47653e-01  7.98394e-01]
21Feb13_174448| [ 2.03791e-01  9.03027e-01  9.67784e-01 -4.00270e-02 -2.59716e-01
21Feb13_174448|  -7.18872e-01  9.82093e-01  2.10782e-01  9.91966e-01  7.67815e-01
21Feb13_174448|  -3.25024e-01  5.85259e-01 -2.21643e-01 -1.67125e-02  9.36688e-01]
21Feb13_174448| [ 3.16211e-01  9.76470e-01  7.94325e-01 -9.00416e-01  6.98898e-01
21Feb13_174448|  -8.42106e-01  6.75991e-01 -6.32115e-02 -3.58262e-01  2.18246e-01
21Feb13_174448|  -4.13471e-01  9.79392e-02  4.02862e-01  8.14727e-01 -7.43809e-01]
21Feb13_174448| [-4.14597e-01  7.51673e-01  8.43107e-01 -8.56637e-01  2.01330e-01
21Feb13_174448|   5.15009e-01  5.18579e-01  3.77743e-01 -4.70931e-01  8.27614e-01
21Feb13_174448|  -1.84439e-01 -5.43885e-01 -6.03771e-01  1.66381e-01 -2.62433e-01]
21Feb13_174448| [-3.30904e-01 -8.97996e-01  5.59354e-01  9.82660e-01  4.72646e-01
21Feb13_174448|  -3.88086e-01 -3.61082e-01 -3.33936e-01  8.38158e-01  1.00179e-01
21Feb13_174448|   1.36844e-01 -9.95933e-01  6.20488e-01 -6.12446e-01 -2.16831e-01]
21Feb13_174448| [ 9.34249e-01  9.58289e-01 -5.59786e-01  2.63487e-01  3.40624e-01
21Feb13_174448|  -8.82567e-01 -1.87162e-01  9.71567e-01 -1.62228e-01 -5.14816e-02
21Feb13_174448|  -6.15566e-01 -2.21997e-01 -6.32714e-01  3.35681e-01 -7.22899e-01]
21Feb13_174448| [ 1.81650e-01  5.38812e-01 -5.84369e-01  1.83511e-01 -4.73145e-01
21Feb13_174448|   3.69120e-01 -6.10032e-01  5.04085e-01  6.79257e-01  6.97438e-01
21Feb13_174448|   9.97907e-01  3.05666e-01  4.40567e-01  9.43295e-01 -9.02163e-01]
21Feb13_174448| [-1.70947e-01  6.56286e-02 -7.70618e-01  7.44355e-01  6.43106e-01
21Feb13_174448|  -9.22310e-01 -9.79288e-01 -3.81965e-01  3.86344e-01  1.77963e-01
21Feb13_174448|  -3.30390e-01  7.61288e-01  3.33913e-01  5.64535e-01 -5.40325e-01]
21Feb13_174448| [-9.32116e-01  9.90939e-01 -3.30869e-01 -4.27293e-01  7.10723e-01
21Feb13_174448|  -2.31364e-01 -3.76768e-01 -9.93003e-01 -6.60679e-01  8.88879e-01
21Feb13_174448|  -6.39983e-02  1.51892e-01  8.99858e-01  8.00668e-01 -2.98412e-01]
21Feb13_174448| [-2.10118e-01  6.98032e-01  9.37825e-01  8.81575e-01  4.77957e-01
21Feb13_174448|  -9.19276e-01  8.17147e-01  5.26491e-01  4.95066e-01 -8.77804e-01
21Feb13_174448|   1.84540e-01  7.53370e-01 -8.47736e-01 -3.26258e-01  2.71438e-01]
21Feb13_174448| [-7.34106e-01  5.52282e-02  1.81606e-01 -1.03917e-01 -9.16647e-01
21Feb13_174448|  -5.73562e-01  5.39510e-01  1.66977e-01  4.48250e-01 -3.24674e-01
21Feb13_174448|   1.39795e-01  2.34226e-01  4.90799e-01 -7.05583e-01  7.14680e-01]
21Feb13_174448| [-8.37392e-01 -4.18274e-02 -4.14411e-01  4.09715e-01  7.44756e-01
21Feb13_174448|  -7.58552e-01 -8.70333e-01 -6.49756e-01  8.63765e-01 -4.23482e-01
21Feb13_174448|   7.87457e-01 -9.43614e-01  4.77426e-01  6.69989e-01  2.31675e-01]
21Feb13_174448| [-7.69917e-01  2.98477e-01 -9.92047e-01  3.57645e-01  3.18108e-01
21Feb13_174448|   3.05468e-01  5.89527e-01 -1.31507e-01 -8.62127e-01  7.60717e-01
21Feb13_174448|  -5.18226e-01  4.94369e-01 -8.24036e-01 -4.43348e-01 -1.55927e-01]
21Feb13_174448| [ 9.10501e-01 -7.45959e-03 -3.28250e-01 -3.48338e-01  1.64135e-01
21Feb13_174448|  -8.02631e-02  4.22565e-01 -8.42164e-01  3.89676e-01  5.80955e-01
21Feb13_174448|   9.83555e-01  6.38621e-01 -1.00576e-01 -7.42125e-01  7.03190e-01]
21Feb13_174448| [-1.71055e-01  1.25462e-01  3.41395e-01  1.66074e-01 -4.20132e-01
21Feb13_174448|  -7.62667e-01 -6.36091e-01  1.46176e-01 -1.03210e-01 -5.38815e-01
21Feb13_174448|   5.96929e-01 -7.47086e-01  3.78571e-02  4.13885e-01  4.94247e-01]
21Feb13_174448| [-3.35399e-02  9.35145e-01  8.04748e-01 -4.71015e-01  1.19204e-01
21Feb13_174448|  -4.47124e-02  3.23368e-01 -8.61360e-02  9.04695e-03 -2.16230e-01
21Feb13_174448|   9.73383e-03  6.40028e-02 -7.75899e-01  7.42213e-01 -2.41969e-01]
21Feb13_174448| [-4.07810e-01  5.70924e-01 -6.72329e-01 -5.14381e-01 -6.52092e-01
21Feb13_174448|  -7.42952e-01 -3.09589e-01 -9.56182e-01  9.43312e-01  5.64870e-01
21Feb13_174448|   6.42553e-01  7.94006e-01 -3.78536e-01  8.42088e-01 -4.76981e-01]
21Feb13_174448| [ 6.10318e-01 -5.75354e-01  3.73758e-01 -7.73392e-01 -9.60833e-01
21Feb13_174448|   4.27903e-01 -9.41218e-01 -6.94203e-01  6.64921e-01  2.08771e-01
21Feb13_174448|   9.91458e-01 -7.05600e-01 -4.80987e-01 -5.69879e-01 -6.07920e-01]
21Feb13_174448| [ 5.91649e-01 -4.92879e-02 -3.44790e-01 -4.70337e-01  4.26548e-01
21Feb13_174448|  -1.62878e-01 -2.02342e-01  4.02378e-01  6.11021e-01  3.01335e-01
21Feb13_174448|   4.01714e-01 -1.12789e-01  5.33867e-01 -2.31753e-01  7.09983e-01]]
21Feb13_174448|-- Bias --
21Feb13_174448|[-0.78506  0.16228 -0.33422 -0.02819  0.17937  0.59381 -0.35607  0.98170
21Feb13_174448|  0.84415 -0.36809  0.88118  0.00344 -0.36932  0.87305 -0.91166]
21Feb13_174448|Layer 1:
21Feb13_174448|-- Config --
21Feb13_174448|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 15], 'dtype': 'float32', 'units': 10, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174448|-- Weights --
21Feb13_174448|[[ 0.91951  0.13760  0.93226 -0.96100  0.36703 -0.91847  0.02090 -0.91229
21Feb13_174448|  -0.78451  0.42787]
21Feb13_174448| [ 0.18072 -0.99875 -0.90672  0.46909  0.10174 -0.28361 -0.76657 -0.44411
21Feb13_174448|   0.01587 -0.08012]
21Feb13_174448| [-0.52522  0.57842  0.64217 -0.58067  0.73633  0.43445  0.81842  0.10316
21Feb13_174448|   0.96829 -0.65906]
21Feb13_174448| [-0.74083 -0.67462 -0.56811 -0.28798 -0.39432  0.28098  0.72626 -0.36612
21Feb13_174448|  -0.96927 -0.08040]
21Feb13_174448| [ 0.21210 -0.13397 -0.84942  0.54712 -0.03219 -0.92481 -0.98810  0.89079
21Feb13_174448|   0.31637  0.53136]
21Feb13_174448| [-0.18729 -0.69744 -0.16173 -0.93613  0.96262  0.00792 -0.95445  0.32042
21Feb13_174448|  -0.36467 -0.87315]
21Feb13_174448| [-0.04314  0.07497  0.43518 -0.80082  0.93585  0.10181  0.30618  0.41458
21Feb13_174448|   0.98098 -0.73301]
21Feb13_174448| [-0.87685  0.20483  0.84988 -0.51961  0.88167  0.81532 -0.93018  0.13207
21Feb13_174448|   0.15465 -0.81578]
21Feb13_174448| [ 0.09921 -0.76754 -0.49733  0.81089  0.68214 -0.36243  0.59439 -0.15764
21Feb13_174448|  -0.74059 -0.05954]
21Feb13_174448| [-0.07392  0.53340  0.82207 -0.72043  0.38000  0.03960 -0.07042  0.29536
21Feb13_174448|   0.95278 -0.00530]
21Feb13_174448| [ 0.92473 -0.52802 -0.20280 -0.39430  0.48632  0.43274 -0.61715  0.12507
21Feb13_174448|  -0.54846 -0.46933]
21Feb13_174448| [ 0.91914  0.92132 -0.40327  0.08595  0.31134 -0.46791  0.23914  0.06850
21Feb13_174448|   0.84229  0.43934]
21Feb13_174448| [-0.04235  0.97296 -0.83341  0.13476  0.13764  0.94126 -0.34097 -0.51874
21Feb13_174448|  -0.61301  0.79707]
21Feb13_174448| [ 0.04655  0.28131 -0.46598  0.40417  0.08962  0.41710  0.97629 -0.28989
21Feb13_174448|  -0.23680 -0.34164]
21Feb13_174448| [ 0.78000 -0.40552 -0.20550  0.20903  0.41907  0.01739 -0.35840 -0.00938
21Feb13_174448|   0.63674 -0.15946]]
21Feb13_174448|-- Bias --
21Feb13_174448|[-0.79083  0.37148 -0.23368 -0.84856 -0.81550 -0.13297 -0.70006  0.83504
21Feb13_174448|  0.92083 -0.68777]
21Feb13_174448|Layer 2:
21Feb13_174448|-- Config --
21Feb13_174448|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 10], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174448|-- Weights --
21Feb13_174448|[[-0.87117 -0.98023]
21Feb13_174448| [-0.13253  0.72532]
21Feb13_174448| [-0.88656 -0.22166]
21Feb13_174448| [ 0.38520 -0.85873]
21Feb13_174448| [-0.98768 -0.34253]
21Feb13_174448| [-0.45654 -0.72139]
21Feb13_174448| [-0.55069  0.70280]
21Feb13_174448| [ 0.50509  0.57348]
21Feb13_174448| [ 0.16174  0.84480]
21Feb13_174448| [-0.22560 -0.23581]]
21Feb13_174448|-- Bias --
21Feb13_174448|[-0.53578  0.46638]
21Feb13_174448|Predicting the validation and test data with the Best initial individual.
21Feb13_174456| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_174456|-----------  ------------------  --------------------  ----------
21Feb13_174456|Validation         37.65                  50            0.04192
21Feb13_174456|   Test            39.53                  50            0.00000
21Feb13_174456|-------------------- Test #0 --------------------
21Feb13_174456|Best final individual weights
21Feb13_174456|Individual:
21Feb13_174456|-- Constant hidden layers --
21Feb13_174456|False
21Feb13_174456|Layer 0:
21Feb13_174456|-- Config --
21Feb13_174456|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174456|-- Weights --
21Feb13_174456|[[ 1.13034e+00 -5.53286e-01  1.06969e+00  6.04800e-01 -1.80344e+00
21Feb13_174456|   1.87998e-01]
21Feb13_174456| [-2.06086e-01 -1.17561e+00 -3.88209e-01 -1.23630e+00 -1.70580e-01
21Feb13_174456|  -4.93509e-01]
21Feb13_174456| [ 8.62255e-01  1.17018e+00 -1.49746e+00 -2.74330e-01 -9.97699e-01
21Feb13_174456|   1.06762e+00]
21Feb13_174456| [ 1.05284e+00 -1.09601e+00  2.23484e+00 -1.58443e+00 -7.08990e-01
21Feb13_174456|  -2.24847e-02]
21Feb13_174456| [-1.85392e-01  3.74849e-01 -9.28314e-01 -5.05116e-01  9.75807e-01
21Feb13_174456|   2.26265e-02]
21Feb13_174456| [ 5.53864e-01 -1.44701e-01 -2.78496e-01 -9.65915e-02 -4.66222e-01
21Feb13_174456|  -4.82200e-01]
21Feb13_174456| [-2.83744e-01  1.05014e+00  6.84434e-01  1.96472e-01  1.51780e+00
21Feb13_174456|  -1.43357e+00]
21Feb13_174456| [ 2.51787e-01  2.82378e+00  3.38266e-02  7.75067e-01 -7.71118e-01
21Feb13_174456|   1.01245e+00]
21Feb13_174456| [ 6.35048e-01 -1.31302e+00  1.58172e+00 -7.59300e-01  7.75194e-01
21Feb13_174456|   3.57667e-01]
21Feb13_174456| [ 1.55833e-02 -1.52513e-01  1.14441e+00  1.21641e+00  1.46095e+00
21Feb13_174456|  -1.97462e-01]
21Feb13_174456| [ 8.82940e-01  4.70981e-01  8.94543e-03  2.12770e+00 -4.73172e-02
21Feb13_174456|   2.49972e-01]
21Feb13_174456| [ 2.02733e+00 -5.44623e-01  5.59001e-03 -5.46488e-01 -2.93472e-01
21Feb13_174456|   7.41024e-02]
21Feb13_174456| [ 4.30996e-01 -3.44291e-01  5.03869e-01 -1.70903e-01  2.02710e+00
21Feb13_174456|   7.40481e-01]
21Feb13_174456| [-5.79992e-02 -3.52174e-02  6.19134e-01  6.75090e-01  5.62871e-03
21Feb13_174456|   4.08582e-01]
21Feb13_174456| [ 2.11756e+00 -1.41866e+00 -4.73399e-01 -8.55975e-01  2.50962e-01
21Feb13_174456|   3.88174e-01]
21Feb13_174456| [ 1.08338e+00  7.28871e-01 -8.79437e-01  3.81938e-01 -1.04980e-01
21Feb13_174456|   3.81630e-01]
21Feb13_174456| [ 3.05477e-01  2.96671e-01 -3.34109e-02  9.81726e-01  7.50611e-01
21Feb13_174456|   1.53923e-03]
21Feb13_174456| [-1.97136e+00  4.35535e-01 -3.41613e-01 -1.14664e+00  2.60336e+00
21Feb13_174456|   1.22123e-01]
21Feb13_174456| [-9.72294e-01 -1.31051e+00 -6.25687e-01 -1.01171e+00  3.20799e-01
21Feb13_174456|  -6.29617e-01]
21Feb13_174456| [ 3.89268e-01 -3.12905e-01 -3.24592e+00  3.19579e-01 -9.28448e-01
21Feb13_174456|  -4.49606e-01]
21Feb13_174456| [-1.23874e-01  2.54123e-01  1.52446e-01  2.93099e+00 -8.96749e-01
21Feb13_174456|  -6.47971e-01]
21Feb13_174456| [-1.80957e-01  6.75851e-01 -7.40387e-01 -2.44728e-01 -9.53669e-01
21Feb13_174456|   5.04709e-01]
21Feb13_174456| [ 4.18558e-01  8.80843e-01  1.64533e+00  4.24741e-02 -3.58074e-01
21Feb13_174456|   7.98441e-02]
21Feb13_174456| [-3.98428e-01 -1.79152e+00 -2.41090e+00 -1.41339e+00  7.43891e-01
21Feb13_174456|   3.09447e-01]
21Feb13_174456| [ 3.44250e-01 -1.54741e+00 -4.11403e-01  4.49406e-01 -2.66079e-01
21Feb13_174456|  -2.31925e-01]
21Feb13_174456| [ 2.23338e-02 -2.24281e-01  1.92970e+00 -1.50261e+00  1.34918e+00
21Feb13_174456|  -3.39176e-01]
21Feb13_174456| [ 8.00847e-01  1.20519e+00  1.69998e+00 -1.46682e+00  7.53415e-01
21Feb13_174456|  -3.78005e-01]
21Feb13_174456| [-1.15511e-01  3.70614e-01  5.57123e-01  2.68691e-01 -1.42742e+00
21Feb13_174456|  -1.93233e-01]
21Feb13_174456| [-6.62414e-01  1.08008e-01  7.05660e-01 -4.59772e-02 -1.30027e+00
21Feb13_174456|  -5.21610e-01]
21Feb13_174456| [ 1.66346e+00  5.86243e-01 -1.51876e-01  2.30012e-01 -3.58419e-01
21Feb13_174456|  -1.23990e-01]
21Feb13_174456| [ 1.61966e+00 -6.43844e-02 -5.68742e-01 -9.25386e-01  6.79694e-01
21Feb13_174456|  -2.93331e-01]
21Feb13_174456| [ 7.10363e-01 -1.44787e+00 -2.34484e-01 -4.37677e-01 -1.22538e+00
21Feb13_174456|   1.83002e-01]
21Feb13_174456| [ 2.14622e-01 -1.12925e+00 -5.15099e-01  9.37440e-01  5.26126e-01
21Feb13_174456|   5.19098e-01]
21Feb13_174456| [ 5.67954e-01  1.43059e-01 -1.06384e+00  9.05593e-01 -2.00117e+00
21Feb13_174456|   1.80507e+00]
21Feb13_174456| [ 7.80472e-01 -3.54113e-01 -1.20890e+00  2.77431e+00 -9.37215e-01
21Feb13_174456|   3.77714e-01]
21Feb13_174456| [ 9.01572e-01 -4.56129e-01  1.15429e+00 -1.66769e-01  8.62034e-01
21Feb13_174456|   4.58879e-01]
21Feb13_174456| [ 2.91961e+00 -2.86061e+00 -2.01106e-01 -1.16509e+00 -7.08412e-01
21Feb13_174456|   1.11489e-01]
21Feb13_174456| [ 1.72952e+00  1.57028e+00 -2.07455e+00  8.60966e-01  1.09806e-01
21Feb13_174456|  -1.87101e-01]
21Feb13_174456| [-1.26201e+00  1.05169e+00  5.94851e-01  1.01150e-01 -1.38611e+00
21Feb13_174456|   1.02119e-01]
21Feb13_174456| [-1.07746e-02  3.08677e-01  1.45140e+00  3.07728e-01 -3.03820e-01
21Feb13_174456|  -1.89218e-01]
21Feb13_174456| [ 2.88911e-01  6.61534e-01 -5.08244e-01 -1.42714e-01  8.10001e-02
21Feb13_174456|   1.24332e-01]
21Feb13_174456| [-1.32570e+00  1.66273e-01  1.53351e+00  1.48902e+00  1.52882e+00
21Feb13_174456|   5.31791e-01]
21Feb13_174456| [ 2.18605e+00  7.69662e-01 -5.86388e-01  5.94944e-01  3.36219e-01
21Feb13_174456|   1.04673e-01]
21Feb13_174456| [-1.26380e-01  5.38904e-02 -7.81064e-01 -5.99197e-01  1.32875e-01
21Feb13_174456|  -5.29580e-01]
21Feb13_174456| [-4.18577e-01 -3.05427e-01 -2.87218e-02  2.30080e-01 -4.63573e-01
21Feb13_174456|   1.02996e+00]
21Feb13_174456| [-7.58159e-02 -7.34967e-01 -2.89689e-01 -6.13321e-01  1.19156e+00
21Feb13_174456|   6.56374e-01]
21Feb13_174456| [ 4.42022e-02 -1.91843e-01  9.05626e-01 -7.47534e-01  1.88839e-01
21Feb13_174456|  -2.99682e-01]
21Feb13_174456| [ 9.98249e-01  7.67460e-01  5.60854e-01  1.00827e+00 -5.46571e-01
21Feb13_174456|   2.12347e-01]
21Feb13_174456| [-3.93190e-01 -5.15195e-01  2.43161e-01  1.08610e+00 -1.18163e+00
21Feb13_174456|   5.27352e-01]
21Feb13_174456| [-2.10995e+00 -4.58607e-01  1.02182e+00 -9.34708e-01 -1.61474e-01
21Feb13_174456|   5.21834e-01]
21Feb13_174456| [ 2.71710e-01  6.30733e-01 -2.12292e+00  2.44596e-02  2.19986e-01
21Feb13_174456|   2.64510e-01]
21Feb13_174456| [ 2.73506e+00 -1.68607e+00 -3.43628e-01  7.61628e-02 -2.26828e-01
21Feb13_174456|  -3.81731e-01]
21Feb13_174456| [ 5.23338e-02 -7.03002e-01 -1.03161e-01  9.49301e-01  1.27202e-01
21Feb13_174456|   6.50503e-01]
21Feb13_174456| [-1.12324e-01  1.94323e-01 -1.49900e+00  1.41035e-01 -1.16220e+00
21Feb13_174456|  -3.35985e-01]
21Feb13_174456| [ 8.70873e-01  7.43781e-01 -1.46105e+00  4.68759e-01 -6.68305e-01
21Feb13_174456|  -1.71642e-01]
21Feb13_174456| [-8.00266e-01 -1.06325e-01  7.65769e-01  1.72880e+00  1.90866e+00
21Feb13_174456|   1.16830e+00]
21Feb13_174456| [-3.71919e-01  1.04334e+00 -1.67330e+00 -5.96497e-01 -3.52827e-01
21Feb13_174456|  -7.28103e-03]]
21Feb13_174456|-- Bias --
21Feb13_174456|[ 1.71352  0.90911  0.47256 -0.01331  0.42218 -0.02646]
21Feb13_174456|Layer 1:
21Feb13_174456|-- Config --
21Feb13_174456|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174456|-- Weights --
21Feb13_174456|[[-0.99267 -0.97274  0.82405 -0.16977]
21Feb13_174456| [ 0.60239 -0.10238 -0.00496 -0.14288]
21Feb13_174456| [-0.11020  0.99493  0.79092 -0.16312]
21Feb13_174456| [ 0.55308 -0.37597 -1.28077 -0.67794]
21Feb13_174456| [ 0.99539  0.72798  0.47591  0.49305]
21Feb13_174456| [ 0.83623 -0.20924  0.30390  0.06038]]
21Feb13_174456|-- Bias --
21Feb13_174456|[-0.44854  0.57814 -0.25511  0.43911]
21Feb13_174456|Layer 2:
21Feb13_174456|-- Config --
21Feb13_174456|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174456|-- Weights --
21Feb13_174456|[[ 0.33441  0.48577]
21Feb13_174456| [-0.92058 -1.06244]
21Feb13_174456| [-0.40205  1.58320]
21Feb13_174456| [-0.58076 -0.11565]]
21Feb13_174456|-- Bias --
21Feb13_174456|[0.09744 0.58731]
21Feb13_174456|Predicting the validation and test data with the Best final individual.
21Feb13_174503| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_174503|-----------  ------------------  --------------------  ----------
21Feb13_174503|Validation         26.17                  20            0.53976
21Feb13_174503|   Test            27.37                  20            0.55091
21Feb13_174503|-------------------- Test #1 --------------------
21Feb13_174503|Best final individual weights
21Feb13_174503|Individual:
21Feb13_174503|-- Constant hidden layers --
21Feb13_174503|False
21Feb13_174503|Layer 0:
21Feb13_174503|-- Config --
21Feb13_174503|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174503|-- Weights --
21Feb13_174503|[[ 1.13034e+00 -5.53286e-01  1.06969e+00  6.04800e-01 -1.80344e+00
21Feb13_174503|   1.87998e-01]
21Feb13_174503| [-2.06086e-01 -1.17561e+00 -3.88209e-01 -1.23630e+00 -1.70580e-01
21Feb13_174503|  -4.93509e-01]
21Feb13_174503| [ 8.62255e-01  1.17018e+00 -1.49746e+00 -2.74330e-01 -9.97699e-01
21Feb13_174503|   1.06762e+00]
21Feb13_174503| [ 1.05284e+00 -1.09601e+00  2.23484e+00 -1.58443e+00 -7.08990e-01
21Feb13_174503|  -2.24847e-02]
21Feb13_174503| [-1.85392e-01  3.74849e-01 -9.28314e-01 -5.05116e-01  9.75807e-01
21Feb13_174503|   2.26265e-02]
21Feb13_174503| [ 5.53864e-01 -1.44701e-01 -2.78496e-01 -9.65915e-02 -4.66222e-01
21Feb13_174503|  -4.82200e-01]
21Feb13_174503| [-2.83744e-01  1.05014e+00  6.84434e-01  1.96472e-01  1.51780e+00
21Feb13_174503|  -1.43357e+00]
21Feb13_174503| [ 2.51787e-01  2.82378e+00  3.38266e-02  7.75067e-01 -7.71118e-01
21Feb13_174503|   1.01245e+00]
21Feb13_174503| [ 6.35048e-01 -1.31302e+00  1.58172e+00 -7.59300e-01  7.75194e-01
21Feb13_174503|   3.57667e-01]
21Feb13_174503| [ 1.55833e-02 -1.52513e-01  1.14441e+00  1.21641e+00  1.46095e+00
21Feb13_174503|  -1.97462e-01]
21Feb13_174503| [ 8.82940e-01  4.70981e-01  8.94543e-03  2.12770e+00 -4.73172e-02
21Feb13_174503|   2.49972e-01]
21Feb13_174503| [ 2.02733e+00 -5.44623e-01  5.59001e-03 -5.46488e-01 -2.93472e-01
21Feb13_174503|   7.41024e-02]
21Feb13_174503| [ 4.30996e-01 -3.44291e-01  5.03869e-01 -1.70903e-01  2.02710e+00
21Feb13_174503|   7.40481e-01]
21Feb13_174503| [-5.79992e-02 -3.52174e-02  6.19134e-01  6.75090e-01  5.62871e-03
21Feb13_174503|   4.08582e-01]
21Feb13_174503| [ 2.11756e+00 -1.41866e+00 -4.73399e-01 -8.55975e-01  2.50962e-01
21Feb13_174503|   3.88174e-01]
21Feb13_174503| [ 1.08338e+00  7.28871e-01 -8.79437e-01  3.81938e-01 -1.04980e-01
21Feb13_174503|   3.81630e-01]
21Feb13_174503| [ 3.05477e-01  2.96671e-01 -3.34109e-02  9.81726e-01  7.50611e-01
21Feb13_174503|   1.53923e-03]
21Feb13_174503| [-1.97136e+00  4.35535e-01 -3.41613e-01 -1.14664e+00  2.60336e+00
21Feb13_174503|   1.22123e-01]
21Feb13_174503| [-9.72294e-01 -1.31051e+00 -6.25687e-01 -1.01171e+00  3.20799e-01
21Feb13_174503|  -6.29617e-01]
21Feb13_174503| [ 3.89268e-01 -3.12905e-01 -3.24592e+00  3.19579e-01 -9.28448e-01
21Feb13_174503|  -4.49606e-01]
21Feb13_174503| [-1.23874e-01  2.54123e-01  1.52446e-01  2.93099e+00 -8.96749e-01
21Feb13_174503|  -6.47971e-01]
21Feb13_174503| [-1.80957e-01  6.75851e-01 -7.40387e-01 -2.44728e-01 -9.53669e-01
21Feb13_174503|   5.04709e-01]
21Feb13_174503| [ 4.18558e-01  8.80843e-01  1.64533e+00  4.24741e-02 -3.58074e-01
21Feb13_174503|   7.98441e-02]
21Feb13_174503| [-3.98428e-01 -1.79152e+00 -2.41090e+00 -1.41339e+00  7.43891e-01
21Feb13_174503|   3.09447e-01]
21Feb13_174503| [ 3.44250e-01 -1.54741e+00 -4.11403e-01  4.49406e-01 -2.66079e-01
21Feb13_174503|  -2.31925e-01]
21Feb13_174503| [ 2.23338e-02 -2.24281e-01  1.92970e+00 -1.50261e+00  1.34918e+00
21Feb13_174503|  -3.39176e-01]
21Feb13_174503| [ 8.00847e-01  1.20519e+00  1.69998e+00 -1.46682e+00  7.53415e-01
21Feb13_174503|  -3.78005e-01]
21Feb13_174503| [-1.15511e-01  3.70614e-01  5.57123e-01  2.68691e-01 -1.42742e+00
21Feb13_174503|  -1.93233e-01]
21Feb13_174503| [-6.62414e-01  1.08008e-01  7.05660e-01 -4.59772e-02 -1.30027e+00
21Feb13_174503|  -5.21610e-01]
21Feb13_174503| [ 1.66346e+00  5.86243e-01 -1.51876e-01  2.30012e-01 -3.58419e-01
21Feb13_174503|  -1.23990e-01]
21Feb13_174503| [ 1.61966e+00 -6.43844e-02 -5.68742e-01 -9.25386e-01  6.79694e-01
21Feb13_174503|  -2.93331e-01]
21Feb13_174503| [ 7.10363e-01 -1.44787e+00 -2.34484e-01 -4.37677e-01 -1.22538e+00
21Feb13_174503|   1.83002e-01]
21Feb13_174503| [ 2.14622e-01 -1.12925e+00 -5.15099e-01  9.37440e-01  5.26126e-01
21Feb13_174503|   5.19098e-01]
21Feb13_174503| [ 5.67954e-01  1.43059e-01 -1.06384e+00  9.05593e-01 -2.00117e+00
21Feb13_174503|   1.80507e+00]
21Feb13_174503| [ 7.80472e-01 -3.54113e-01 -1.20890e+00  2.77431e+00 -9.37215e-01
21Feb13_174503|   3.77714e-01]
21Feb13_174503| [ 9.01572e-01 -4.56129e-01  1.15429e+00 -1.66769e-01  8.62034e-01
21Feb13_174503|   4.58879e-01]
21Feb13_174503| [ 2.91961e+00 -2.86061e+00 -2.01106e-01 -1.16509e+00 -7.08412e-01
21Feb13_174503|   1.11489e-01]
21Feb13_174503| [ 1.72952e+00  1.57028e+00 -2.07455e+00  8.60966e-01  1.09806e-01
21Feb13_174503|  -1.87101e-01]
21Feb13_174503| [-1.26201e+00  1.05169e+00  5.94851e-01  1.01150e-01 -1.38611e+00
21Feb13_174503|   1.02119e-01]
21Feb13_174503| [-1.07746e-02  3.08677e-01  1.45140e+00  3.07728e-01 -3.03820e-01
21Feb13_174503|  -1.89218e-01]
21Feb13_174503| [ 2.88911e-01  6.61534e-01 -5.08244e-01 -1.42714e-01  8.10001e-02
21Feb13_174503|   1.24332e-01]
21Feb13_174503| [-1.32570e+00  1.66273e-01  1.53351e+00  1.48902e+00  1.52882e+00
21Feb13_174503|   5.31791e-01]
21Feb13_174503| [ 2.18605e+00  7.69662e-01 -5.86388e-01  5.94944e-01  3.36219e-01
21Feb13_174503|   1.04673e-01]
21Feb13_174503| [-1.26380e-01  5.38904e-02 -7.81064e-01 -5.99197e-01  1.32875e-01
21Feb13_174503|  -5.29580e-01]
21Feb13_174503| [-4.18577e-01 -3.05427e-01 -2.87218e-02  2.30080e-01 -4.63573e-01
21Feb13_174503|   1.02996e+00]
21Feb13_174503| [-7.58159e-02 -7.34967e-01 -2.89689e-01 -6.13321e-01  1.19156e+00
21Feb13_174503|   6.56374e-01]
21Feb13_174503| [ 4.42022e-02 -1.91843e-01  9.05626e-01 -7.47534e-01  1.88839e-01
21Feb13_174503|  -2.99682e-01]
21Feb13_174503| [ 9.98249e-01  7.67460e-01  5.60854e-01  1.00827e+00 -5.46571e-01
21Feb13_174503|   2.12347e-01]
21Feb13_174503| [-3.93190e-01 -5.15195e-01  2.43161e-01  1.08610e+00 -1.18163e+00
21Feb13_174503|   5.27352e-01]
21Feb13_174503| [-2.10995e+00 -4.58607e-01  1.02182e+00 -9.34708e-01 -1.61474e-01
21Feb13_174503|   5.21834e-01]
21Feb13_174503| [ 2.71710e-01  6.30733e-01 -2.12292e+00  2.44596e-02  2.19986e-01
21Feb13_174503|   2.64510e-01]
21Feb13_174503| [ 2.73506e+00 -1.68607e+00 -3.43628e-01  7.61628e-02 -2.26828e-01
21Feb13_174503|  -3.81731e-01]
21Feb13_174503| [ 5.23338e-02 -7.03002e-01 -1.03161e-01  9.49301e-01  1.27202e-01
21Feb13_174503|   6.50503e-01]
21Feb13_174503| [-1.12324e-01  1.94323e-01 -1.49900e+00  1.41035e-01 -1.16220e+00
21Feb13_174503|  -3.35985e-01]
21Feb13_174503| [ 8.70873e-01  7.43781e-01 -1.46105e+00  4.68759e-01 -6.68305e-01
21Feb13_174503|  -1.71642e-01]
21Feb13_174503| [-8.00266e-01 -1.06325e-01  7.65769e-01  1.72880e+00  1.90866e+00
21Feb13_174503|   1.16830e+00]
21Feb13_174503| [-3.71919e-01  1.04334e+00 -1.67330e+00 -5.96497e-01 -3.52827e-01
21Feb13_174503|  -7.28103e-03]]
21Feb13_174503|-- Bias --
21Feb13_174503|[ 1.71352  0.90911  0.47256 -0.01331  0.42218 -0.02646]
21Feb13_174503|Layer 1:
21Feb13_174503|-- Config --
21Feb13_174503|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174503|-- Weights --
21Feb13_174503|[[-0.99267 -0.97274  0.82405 -0.16977]
21Feb13_174503| [ 0.60239 -0.10238 -0.00496 -0.14288]
21Feb13_174503| [-0.11020  0.99493  0.79092 -0.16312]
21Feb13_174503| [ 0.55308 -0.37597 -1.28077 -0.67794]
21Feb13_174503| [ 0.99539  0.72798  0.47591  0.49305]
21Feb13_174503| [ 0.83623 -0.20924  0.30390  0.06038]]
21Feb13_174503|-- Bias --
21Feb13_174503|[-0.44854  0.57814 -0.25511  0.43911]
21Feb13_174503|Layer 2:
21Feb13_174503|-- Config --
21Feb13_174503|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174503|-- Weights --
21Feb13_174503|[[ 0.33441  0.48577]
21Feb13_174503| [-0.92058 -1.06244]
21Feb13_174503| [-0.40205  1.58320]
21Feb13_174503| [-0.58076 -0.11565]]
21Feb13_174503|-- Bias --
21Feb13_174503|[0.09744 0.58731]
21Feb13_174503|Predicting the validation and test data with the Best final individual.
21Feb13_174510| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_174510|-----------  ------------------  --------------------  ----------
21Feb13_174510|Validation         38.52                  20            0.00000
21Feb13_174510|   Test            36.23                  20            0.12800
21Feb13_174510|-------------------- Test #2 --------------------
21Feb13_174510|Best final individual weights
21Feb13_174510|Individual:
21Feb13_174510|-- Constant hidden layers --
21Feb13_174510|False
21Feb13_174510|Layer 0:
21Feb13_174510|-- Config --
21Feb13_174510|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174510|-- Weights --
21Feb13_174510|[[ 1.13034e+00 -5.53286e-01  1.06969e+00  6.04800e-01 -1.80344e+00
21Feb13_174510|   1.87998e-01]
21Feb13_174510| [-2.06086e-01 -1.17561e+00 -3.88209e-01 -1.23630e+00 -1.70580e-01
21Feb13_174510|  -4.93509e-01]
21Feb13_174510| [ 8.62255e-01  1.17018e+00 -1.49746e+00 -2.74330e-01 -9.97699e-01
21Feb13_174510|   1.06762e+00]
21Feb13_174510| [ 1.05284e+00 -1.09601e+00  2.23484e+00 -1.58443e+00 -7.08990e-01
21Feb13_174510|  -2.24847e-02]
21Feb13_174510| [-1.85392e-01  3.74849e-01 -9.28314e-01 -5.05116e-01  9.75807e-01
21Feb13_174510|   2.26265e-02]
21Feb13_174510| [ 5.53864e-01 -1.44701e-01 -2.78496e-01 -9.65915e-02 -4.66222e-01
21Feb13_174510|  -4.82200e-01]
21Feb13_174510| [-2.83744e-01  1.05014e+00  6.84434e-01  1.96472e-01  1.51780e+00
21Feb13_174510|  -1.43357e+00]
21Feb13_174510| [ 2.51787e-01  2.82378e+00  3.38266e-02  7.75067e-01 -7.71118e-01
21Feb13_174510|   1.01245e+00]
21Feb13_174510| [ 6.35048e-01 -1.31302e+00  1.58172e+00 -7.59300e-01  7.75194e-01
21Feb13_174510|   3.57667e-01]
21Feb13_174510| [ 1.55833e-02 -1.52513e-01  1.14441e+00  1.21641e+00  1.46095e+00
21Feb13_174510|  -1.97462e-01]
21Feb13_174510| [ 8.82940e-01  4.70981e-01  8.94543e-03  2.12770e+00 -4.73172e-02
21Feb13_174510|   2.49972e-01]
21Feb13_174510| [ 2.02733e+00 -5.44623e-01  5.59001e-03 -5.46488e-01 -2.93472e-01
21Feb13_174510|   7.41024e-02]
21Feb13_174510| [ 4.30996e-01 -3.44291e-01  5.03869e-01 -1.70903e-01  2.02710e+00
21Feb13_174510|   7.40481e-01]
21Feb13_174510| [-5.79992e-02 -3.52174e-02  6.19134e-01  6.75090e-01  5.62871e-03
21Feb13_174510|   4.08582e-01]
21Feb13_174510| [ 2.11756e+00 -1.41866e+00 -4.73399e-01 -8.55975e-01  2.50962e-01
21Feb13_174510|   3.88174e-01]
21Feb13_174510| [ 1.08338e+00  7.28871e-01 -8.79437e-01  3.81938e-01 -1.04980e-01
21Feb13_174510|   3.81630e-01]
21Feb13_174510| [ 3.05477e-01  2.96671e-01 -3.34109e-02  9.81726e-01  7.50611e-01
21Feb13_174510|   1.53923e-03]
21Feb13_174510| [-1.97136e+00  4.35535e-01 -3.41613e-01 -1.14664e+00  2.60336e+00
21Feb13_174510|   1.22123e-01]
21Feb13_174510| [-9.72294e-01 -1.31051e+00 -6.25687e-01 -1.01171e+00  3.20799e-01
21Feb13_174510|  -6.29617e-01]
21Feb13_174510| [ 3.89268e-01 -3.12905e-01 -3.24592e+00  3.19579e-01 -9.28448e-01
21Feb13_174510|  -4.49606e-01]
21Feb13_174510| [-1.23874e-01  2.54123e-01  1.52446e-01  2.93099e+00 -8.96749e-01
21Feb13_174510|  -6.47971e-01]
21Feb13_174510| [-1.80957e-01  6.75851e-01 -7.40387e-01 -2.44728e-01 -9.53669e-01
21Feb13_174510|   5.04709e-01]
21Feb13_174510| [ 4.18558e-01  8.80843e-01  1.64533e+00  4.24741e-02 -3.58074e-01
21Feb13_174510|   7.98441e-02]
21Feb13_174510| [-3.98428e-01 -1.79152e+00 -2.41090e+00 -1.41339e+00  7.43891e-01
21Feb13_174510|   3.09447e-01]
21Feb13_174510| [ 3.44250e-01 -1.54741e+00 -4.11403e-01  4.49406e-01 -2.66079e-01
21Feb13_174510|  -2.31925e-01]
21Feb13_174510| [ 2.23338e-02 -2.24281e-01  1.92970e+00 -1.50261e+00  1.34918e+00
21Feb13_174510|  -3.39176e-01]
21Feb13_174510| [ 8.00847e-01  1.20519e+00  1.69998e+00 -1.46682e+00  7.53415e-01
21Feb13_174510|  -3.78005e-01]
21Feb13_174510| [-1.15511e-01  3.70614e-01  5.57123e-01  2.68691e-01 -1.42742e+00
21Feb13_174510|  -1.93233e-01]
21Feb13_174510| [-6.62414e-01  1.08008e-01  7.05660e-01 -4.59772e-02 -1.30027e+00
21Feb13_174510|  -5.21610e-01]
21Feb13_174510| [ 1.66346e+00  5.86243e-01 -1.51876e-01  2.30012e-01 -3.58419e-01
21Feb13_174510|  -1.23990e-01]
21Feb13_174510| [ 1.61966e+00 -6.43844e-02 -5.68742e-01 -9.25386e-01  6.79694e-01
21Feb13_174510|  -2.93331e-01]
21Feb13_174510| [ 7.10363e-01 -1.44787e+00 -2.34484e-01 -4.37677e-01 -1.22538e+00
21Feb13_174510|   1.83002e-01]
21Feb13_174510| [ 2.14622e-01 -1.12925e+00 -5.15099e-01  9.37440e-01  5.26126e-01
21Feb13_174510|   5.19098e-01]
21Feb13_174510| [ 5.67954e-01  1.43059e-01 -1.06384e+00  9.05593e-01 -2.00117e+00
21Feb13_174510|   1.80507e+00]
21Feb13_174510| [ 7.80472e-01 -3.54113e-01 -1.20890e+00  2.77431e+00 -9.37215e-01
21Feb13_174510|   3.77714e-01]
21Feb13_174510| [ 9.01572e-01 -4.56129e-01  1.15429e+00 -1.66769e-01  8.62034e-01
21Feb13_174510|   4.58879e-01]
21Feb13_174510| [ 2.91961e+00 -2.86061e+00 -2.01106e-01 -1.16509e+00 -7.08412e-01
21Feb13_174510|   1.11489e-01]
21Feb13_174510| [ 1.72952e+00  1.57028e+00 -2.07455e+00  8.60966e-01  1.09806e-01
21Feb13_174510|  -1.87101e-01]
21Feb13_174510| [-1.26201e+00  1.05169e+00  5.94851e-01  1.01150e-01 -1.38611e+00
21Feb13_174510|   1.02119e-01]
21Feb13_174510| [-1.07746e-02  3.08677e-01  1.45140e+00  3.07728e-01 -3.03820e-01
21Feb13_174510|  -1.89218e-01]
21Feb13_174510| [ 2.88911e-01  6.61534e-01 -5.08244e-01 -1.42714e-01  8.10001e-02
21Feb13_174510|   1.24332e-01]
21Feb13_174510| [-1.32570e+00  1.66273e-01  1.53351e+00  1.48902e+00  1.52882e+00
21Feb13_174510|   5.31791e-01]
21Feb13_174510| [ 2.18605e+00  7.69662e-01 -5.86388e-01  5.94944e-01  3.36219e-01
21Feb13_174510|   1.04673e-01]
21Feb13_174510| [-1.26380e-01  5.38904e-02 -7.81064e-01 -5.99197e-01  1.32875e-01
21Feb13_174510|  -5.29580e-01]
21Feb13_174510| [-4.18577e-01 -3.05427e-01 -2.87218e-02  2.30080e-01 -4.63573e-01
21Feb13_174510|   1.02996e+00]
21Feb13_174510| [-7.58159e-02 -7.34967e-01 -2.89689e-01 -6.13321e-01  1.19156e+00
21Feb13_174510|   6.56374e-01]
21Feb13_174510| [ 4.42022e-02 -1.91843e-01  9.05626e-01 -7.47534e-01  1.88839e-01
21Feb13_174510|  -2.99682e-01]
21Feb13_174510| [ 9.98249e-01  7.67460e-01  5.60854e-01  1.00827e+00 -5.46571e-01
21Feb13_174510|   2.12347e-01]
21Feb13_174510| [-3.93190e-01 -5.15195e-01  2.43161e-01  1.08610e+00 -1.18163e+00
21Feb13_174510|   5.27352e-01]
21Feb13_174510| [-2.10995e+00 -4.58607e-01  1.02182e+00 -9.34708e-01 -1.61474e-01
21Feb13_174510|   5.21834e-01]
21Feb13_174510| [ 2.71710e-01  6.30733e-01 -2.12292e+00  2.44596e-02  2.19986e-01
21Feb13_174510|   2.64510e-01]
21Feb13_174510| [ 2.73506e+00 -1.68607e+00 -3.43628e-01  7.61628e-02 -2.26828e-01
21Feb13_174510|  -3.81731e-01]
21Feb13_174510| [ 5.23338e-02 -7.03002e-01 -1.03161e-01  9.49301e-01  1.27202e-01
21Feb13_174510|   6.50503e-01]
21Feb13_174510| [-1.12324e-01  1.94323e-01 -1.49900e+00  1.41035e-01 -1.16220e+00
21Feb13_174510|  -3.35985e-01]
21Feb13_174510| [ 8.70873e-01  7.43781e-01 -1.46105e+00  4.68759e-01 -6.68305e-01
21Feb13_174510|  -1.71642e-01]
21Feb13_174510| [-8.00266e-01 -1.06325e-01  7.65769e-01  1.72880e+00  1.90866e+00
21Feb13_174510|   1.16830e+00]
21Feb13_174510| [-3.71919e-01  1.04334e+00 -1.67330e+00 -5.96497e-01 -3.52827e-01
21Feb13_174510|  -7.28103e-03]]
21Feb13_174510|-- Bias --
21Feb13_174510|[ 1.71352  0.90911  0.47256 -0.01331  0.42218 -0.02646]
21Feb13_174510|Layer 1:
21Feb13_174510|-- Config --
21Feb13_174510|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174510|-- Weights --
21Feb13_174510|[[-0.99267 -0.97274  0.82405 -0.16977]
21Feb13_174510| [ 0.60239 -0.10238 -0.00496 -0.14288]
21Feb13_174510| [-0.11020  0.99493  0.79092 -0.16312]
21Feb13_174510| [ 0.55308 -0.37597 -1.28077 -0.67794]
21Feb13_174510| [ 0.99539  0.72798  0.47591  0.49305]
21Feb13_174510| [ 0.83623 -0.20924  0.30390  0.06038]]
21Feb13_174510|-- Bias --
21Feb13_174510|[-0.44854  0.57814 -0.25511  0.43911]
21Feb13_174510|Layer 2:
21Feb13_174510|-- Config --
21Feb13_174510|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174510|-- Weights --
21Feb13_174510|[[ 0.33441  0.48577]
21Feb13_174510| [-0.92058 -1.06244]
21Feb13_174510| [-0.40205  1.58320]
21Feb13_174510| [-0.58076 -0.11565]]
21Feb13_174510|-- Bias --
21Feb13_174510|[0.09744 0.58731]
21Feb13_174510|Predicting the validation and test data with the Best final individual.
21Feb13_174518| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_174518|-----------  ------------------  --------------------  ----------
21Feb13_174518|Validation         36.17                  20            0.48006
21Feb13_174518|   Test            39.53                  20            0.00275
21Feb13_174518|-------------------- Test #3 --------------------
21Feb13_174518|Best final individual weights
21Feb13_174518|Individual:
21Feb13_174518|-- Constant hidden layers --
21Feb13_174518|False
21Feb13_174518|Layer 0:
21Feb13_174518|-- Config --
21Feb13_174518|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174518|-- Weights --
21Feb13_174518|[[ 1.13034e+00 -5.53286e-01  1.06969e+00  6.04800e-01 -1.80344e+00
21Feb13_174518|   1.87998e-01]
21Feb13_174518| [-2.06086e-01 -1.17561e+00 -3.88209e-01 -1.23630e+00 -1.70580e-01
21Feb13_174518|  -4.93509e-01]
21Feb13_174518| [ 8.62255e-01  1.17018e+00 -1.49746e+00 -2.74330e-01 -9.97699e-01
21Feb13_174518|   1.06762e+00]
21Feb13_174518| [ 1.05284e+00 -1.09601e+00  2.23484e+00 -1.58443e+00 -7.08990e-01
21Feb13_174518|  -2.24847e-02]
21Feb13_174518| [-1.85392e-01  3.74849e-01 -9.28314e-01 -5.05116e-01  9.75807e-01
21Feb13_174518|   2.26265e-02]
21Feb13_174518| [ 5.53864e-01 -1.44701e-01 -2.78496e-01 -9.65915e-02 -4.66222e-01
21Feb13_174518|  -4.82200e-01]
21Feb13_174518| [-2.83744e-01  1.05014e+00  6.84434e-01  1.96472e-01  1.51780e+00
21Feb13_174518|  -1.43357e+00]
21Feb13_174518| [ 2.51787e-01  2.82378e+00  3.38266e-02  7.75067e-01 -7.71118e-01
21Feb13_174518|   1.01245e+00]
21Feb13_174518| [ 6.35048e-01 -1.31302e+00  1.58172e+00 -7.59300e-01  7.75194e-01
21Feb13_174518|   3.57667e-01]
21Feb13_174518| [ 1.55833e-02 -1.52513e-01  1.14441e+00  1.21641e+00  1.46095e+00
21Feb13_174518|  -1.97462e-01]
21Feb13_174518| [ 8.82940e-01  4.70981e-01  8.94543e-03  2.12770e+00 -4.73172e-02
21Feb13_174518|   2.49972e-01]
21Feb13_174518| [ 2.02733e+00 -5.44623e-01  5.59001e-03 -5.46488e-01 -2.93472e-01
21Feb13_174518|   7.41024e-02]
21Feb13_174518| [ 4.30996e-01 -3.44291e-01  5.03869e-01 -1.70903e-01  2.02710e+00
21Feb13_174518|   7.40481e-01]
21Feb13_174518| [-5.79992e-02 -3.52174e-02  6.19134e-01  6.75090e-01  5.62871e-03
21Feb13_174518|   4.08582e-01]
21Feb13_174518| [ 2.11756e+00 -1.41866e+00 -4.73399e-01 -8.55975e-01  2.50962e-01
21Feb13_174518|   3.88174e-01]
21Feb13_174518| [ 1.08338e+00  7.28871e-01 -8.79437e-01  3.81938e-01 -1.04980e-01
21Feb13_174518|   3.81630e-01]
21Feb13_174518| [ 3.05477e-01  2.96671e-01 -3.34109e-02  9.81726e-01  7.50611e-01
21Feb13_174518|   1.53923e-03]
21Feb13_174518| [-1.97136e+00  4.35535e-01 -3.41613e-01 -1.14664e+00  2.60336e+00
21Feb13_174518|   1.22123e-01]
21Feb13_174518| [-9.72294e-01 -1.31051e+00 -6.25687e-01 -1.01171e+00  3.20799e-01
21Feb13_174518|  -6.29617e-01]
21Feb13_174518| [ 3.89268e-01 -3.12905e-01 -3.24592e+00  3.19579e-01 -9.28448e-01
21Feb13_174518|  -4.49606e-01]
21Feb13_174518| [-1.23874e-01  2.54123e-01  1.52446e-01  2.93099e+00 -8.96749e-01
21Feb13_174518|  -6.47971e-01]
21Feb13_174518| [-1.80957e-01  6.75851e-01 -7.40387e-01 -2.44728e-01 -9.53669e-01
21Feb13_174518|   5.04709e-01]
21Feb13_174518| [ 4.18558e-01  8.80843e-01  1.64533e+00  4.24741e-02 -3.58074e-01
21Feb13_174518|   7.98441e-02]
21Feb13_174518| [-3.98428e-01 -1.79152e+00 -2.41090e+00 -1.41339e+00  7.43891e-01
21Feb13_174518|   3.09447e-01]
21Feb13_174518| [ 3.44250e-01 -1.54741e+00 -4.11403e-01  4.49406e-01 -2.66079e-01
21Feb13_174518|  -2.31925e-01]
21Feb13_174518| [ 2.23338e-02 -2.24281e-01  1.92970e+00 -1.50261e+00  1.34918e+00
21Feb13_174518|  -3.39176e-01]
21Feb13_174518| [ 8.00847e-01  1.20519e+00  1.69998e+00 -1.46682e+00  7.53415e-01
21Feb13_174518|  -3.78005e-01]
21Feb13_174518| [-1.15511e-01  3.70614e-01  5.57123e-01  2.68691e-01 -1.42742e+00
21Feb13_174518|  -1.93233e-01]
21Feb13_174518| [-6.62414e-01  1.08008e-01  7.05660e-01 -4.59772e-02 -1.30027e+00
21Feb13_174518|  -5.21610e-01]
21Feb13_174518| [ 1.66346e+00  5.86243e-01 -1.51876e-01  2.30012e-01 -3.58419e-01
21Feb13_174518|  -1.23990e-01]
21Feb13_174518| [ 1.61966e+00 -6.43844e-02 -5.68742e-01 -9.25386e-01  6.79694e-01
21Feb13_174518|  -2.93331e-01]
21Feb13_174518| [ 7.10363e-01 -1.44787e+00 -2.34484e-01 -4.37677e-01 -1.22538e+00
21Feb13_174518|   1.83002e-01]
21Feb13_174518| [ 2.14622e-01 -1.12925e+00 -5.15099e-01  9.37440e-01  5.26126e-01
21Feb13_174518|   5.19098e-01]
21Feb13_174518| [ 5.67954e-01  1.43059e-01 -1.06384e+00  9.05593e-01 -2.00117e+00
21Feb13_174518|   1.80507e+00]
21Feb13_174518| [ 7.80472e-01 -3.54113e-01 -1.20890e+00  2.77431e+00 -9.37215e-01
21Feb13_174518|   3.77714e-01]
21Feb13_174518| [ 9.01572e-01 -4.56129e-01  1.15429e+00 -1.66769e-01  8.62034e-01
21Feb13_174518|   4.58879e-01]
21Feb13_174518| [ 2.91961e+00 -2.86061e+00 -2.01106e-01 -1.16509e+00 -7.08412e-01
21Feb13_174518|   1.11489e-01]
21Feb13_174518| [ 1.72952e+00  1.57028e+00 -2.07455e+00  8.60966e-01  1.09806e-01
21Feb13_174518|  -1.87101e-01]
21Feb13_174518| [-1.26201e+00  1.05169e+00  5.94851e-01  1.01150e-01 -1.38611e+00
21Feb13_174518|   1.02119e-01]
21Feb13_174518| [-1.07746e-02  3.08677e-01  1.45140e+00  3.07728e-01 -3.03820e-01
21Feb13_174518|  -1.89218e-01]
21Feb13_174518| [ 2.88911e-01  6.61534e-01 -5.08244e-01 -1.42714e-01  8.10001e-02
21Feb13_174518|   1.24332e-01]
21Feb13_174518| [-1.32570e+00  1.66273e-01  1.53351e+00  1.48902e+00  1.52882e+00
21Feb13_174518|   5.31791e-01]
21Feb13_174518| [ 2.18605e+00  7.69662e-01 -5.86388e-01  5.94944e-01  3.36219e-01
21Feb13_174518|   1.04673e-01]
21Feb13_174518| [-1.26380e-01  5.38904e-02 -7.81064e-01 -5.99197e-01  1.32875e-01
21Feb13_174518|  -5.29580e-01]
21Feb13_174518| [-4.18577e-01 -3.05427e-01 -2.87218e-02  2.30080e-01 -4.63573e-01
21Feb13_174518|   1.02996e+00]
21Feb13_174518| [-7.58159e-02 -7.34967e-01 -2.89689e-01 -6.13321e-01  1.19156e+00
21Feb13_174518|   6.56374e-01]
21Feb13_174518| [ 4.42022e-02 -1.91843e-01  9.05626e-01 -7.47534e-01  1.88839e-01
21Feb13_174518|  -2.99682e-01]
21Feb13_174518| [ 9.98249e-01  7.67460e-01  5.60854e-01  1.00827e+00 -5.46571e-01
21Feb13_174518|   2.12347e-01]
21Feb13_174518| [-3.93190e-01 -5.15195e-01  2.43161e-01  1.08610e+00 -1.18163e+00
21Feb13_174518|   5.27352e-01]
21Feb13_174518| [-2.10995e+00 -4.58607e-01  1.02182e+00 -9.34708e-01 -1.61474e-01
21Feb13_174518|   5.21834e-01]
21Feb13_174518| [ 2.71710e-01  6.30733e-01 -2.12292e+00  2.44596e-02  2.19986e-01
21Feb13_174518|   2.64510e-01]
21Feb13_174518| [ 2.73506e+00 -1.68607e+00 -3.43628e-01  7.61628e-02 -2.26828e-01
21Feb13_174518|  -3.81731e-01]
21Feb13_174518| [ 5.23338e-02 -7.03002e-01 -1.03161e-01  9.49301e-01  1.27202e-01
21Feb13_174518|   6.50503e-01]
21Feb13_174518| [-1.12324e-01  1.94323e-01 -1.49900e+00  1.41035e-01 -1.16220e+00
21Feb13_174518|  -3.35985e-01]
21Feb13_174518| [ 8.70873e-01  7.43781e-01 -1.46105e+00  4.68759e-01 -6.68305e-01
21Feb13_174518|  -1.71642e-01]
21Feb13_174518| [-8.00266e-01 -1.06325e-01  7.65769e-01  1.72880e+00  1.90866e+00
21Feb13_174518|   1.16830e+00]
21Feb13_174518| [-3.71919e-01  1.04334e+00 -1.67330e+00 -5.96497e-01 -3.52827e-01
21Feb13_174518|  -7.28103e-03]]
21Feb13_174518|-- Bias --
21Feb13_174518|[ 1.71352  0.90911  0.47256 -0.01331  0.42218 -0.02646]
21Feb13_174518|Layer 1:
21Feb13_174518|-- Config --
21Feb13_174518|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174518|-- Weights --
21Feb13_174518|[[-0.99267 -0.97274  0.82405 -0.16977]
21Feb13_174518| [ 0.60239 -0.10238 -0.00496 -0.14288]
21Feb13_174518| [-0.11020  0.99493  0.79092 -0.16312]
21Feb13_174518| [ 0.55308 -0.37597 -1.28077 -0.67794]
21Feb13_174518| [ 0.99539  0.72798  0.47591  0.49305]
21Feb13_174518| [ 0.83623 -0.20924  0.30390  0.06038]]
21Feb13_174518|-- Bias --
21Feb13_174518|[-0.44854  0.57814 -0.25511  0.43911]
21Feb13_174518|Layer 2:
21Feb13_174518|-- Config --
21Feb13_174518|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174518|-- Weights --
21Feb13_174518|[[ 0.33441  0.48577]
21Feb13_174518| [-0.92058 -1.06244]
21Feb13_174518| [-0.40205  1.58320]
21Feb13_174518| [-0.58076 -0.11565]]
21Feb13_174518|-- Bias --
21Feb13_174518|[0.09744 0.58731]
21Feb13_174518|Predicting the validation and test data with the Best final individual.
21Feb13_174525| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_174525|-----------  ------------------  --------------------  ----------
21Feb13_174525|Validation         38.43                  20            0.00282
21Feb13_174525|   Test            39.53                  20            0.00000
21Feb13_174525|-------------------- Test #4 --------------------
21Feb13_174525|Best final individual weights
21Feb13_174525|Individual:
21Feb13_174525|-- Constant hidden layers --
21Feb13_174525|False
21Feb13_174525|Layer 0:
21Feb13_174525|-- Config --
21Feb13_174525|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174525|-- Weights --
21Feb13_174525|[[ 1.13034e+00 -5.53286e-01  1.06969e+00  6.04800e-01 -1.80344e+00
21Feb13_174525|   1.87998e-01]
21Feb13_174525| [-2.06086e-01 -1.17561e+00 -3.88209e-01 -1.23630e+00 -1.70580e-01
21Feb13_174525|  -4.93509e-01]
21Feb13_174525| [ 8.62255e-01  1.17018e+00 -1.49746e+00 -2.74330e-01 -9.97699e-01
21Feb13_174525|   1.06762e+00]
21Feb13_174525| [ 1.05284e+00 -1.09601e+00  2.23484e+00 -1.58443e+00 -7.08990e-01
21Feb13_174525|  -2.24847e-02]
21Feb13_174525| [-1.85392e-01  3.74849e-01 -9.28314e-01 -5.05116e-01  9.75807e-01
21Feb13_174525|   2.26265e-02]
21Feb13_174525| [ 5.53864e-01 -1.44701e-01 -2.78496e-01 -9.65915e-02 -4.66222e-01
21Feb13_174525|  -4.82200e-01]
21Feb13_174525| [-2.83744e-01  1.05014e+00  6.84434e-01  1.96472e-01  1.51780e+00
21Feb13_174525|  -1.43357e+00]
21Feb13_174525| [ 2.51787e-01  2.82378e+00  3.38266e-02  7.75067e-01 -7.71118e-01
21Feb13_174525|   1.01245e+00]
21Feb13_174525| [ 6.35048e-01 -1.31302e+00  1.58172e+00 -7.59300e-01  7.75194e-01
21Feb13_174525|   3.57667e-01]
21Feb13_174525| [ 1.55833e-02 -1.52513e-01  1.14441e+00  1.21641e+00  1.46095e+00
21Feb13_174525|  -1.97462e-01]
21Feb13_174525| [ 8.82940e-01  4.70981e-01  8.94543e-03  2.12770e+00 -4.73172e-02
21Feb13_174525|   2.49972e-01]
21Feb13_174525| [ 2.02733e+00 -5.44623e-01  5.59001e-03 -5.46488e-01 -2.93472e-01
21Feb13_174525|   7.41024e-02]
21Feb13_174525| [ 4.30996e-01 -3.44291e-01  5.03869e-01 -1.70903e-01  2.02710e+00
21Feb13_174525|   7.40481e-01]
21Feb13_174525| [-5.79992e-02 -3.52174e-02  6.19134e-01  6.75090e-01  5.62871e-03
21Feb13_174525|   4.08582e-01]
21Feb13_174525| [ 2.11756e+00 -1.41866e+00 -4.73399e-01 -8.55975e-01  2.50962e-01
21Feb13_174525|   3.88174e-01]
21Feb13_174525| [ 1.08338e+00  7.28871e-01 -8.79437e-01  3.81938e-01 -1.04980e-01
21Feb13_174525|   3.81630e-01]
21Feb13_174525| [ 3.05477e-01  2.96671e-01 -3.34109e-02  9.81726e-01  7.50611e-01
21Feb13_174525|   1.53923e-03]
21Feb13_174525| [-1.97136e+00  4.35535e-01 -3.41613e-01 -1.14664e+00  2.60336e+00
21Feb13_174525|   1.22123e-01]
21Feb13_174525| [-9.72294e-01 -1.31051e+00 -6.25687e-01 -1.01171e+00  3.20799e-01
21Feb13_174525|  -6.29617e-01]
21Feb13_174525| [ 3.89268e-01 -3.12905e-01 -3.24592e+00  3.19579e-01 -9.28448e-01
21Feb13_174525|  -4.49606e-01]
21Feb13_174525| [-1.23874e-01  2.54123e-01  1.52446e-01  2.93099e+00 -8.96749e-01
21Feb13_174525|  -6.47971e-01]
21Feb13_174525| [-1.80957e-01  6.75851e-01 -7.40387e-01 -2.44728e-01 -9.53669e-01
21Feb13_174525|   5.04709e-01]
21Feb13_174525| [ 4.18558e-01  8.80843e-01  1.64533e+00  4.24741e-02 -3.58074e-01
21Feb13_174525|   7.98441e-02]
21Feb13_174525| [-3.98428e-01 -1.79152e+00 -2.41090e+00 -1.41339e+00  7.43891e-01
21Feb13_174525|   3.09447e-01]
21Feb13_174525| [ 3.44250e-01 -1.54741e+00 -4.11403e-01  4.49406e-01 -2.66079e-01
21Feb13_174525|  -2.31925e-01]
21Feb13_174525| [ 2.23338e-02 -2.24281e-01  1.92970e+00 -1.50261e+00  1.34918e+00
21Feb13_174525|  -3.39176e-01]
21Feb13_174525| [ 8.00847e-01  1.20519e+00  1.69998e+00 -1.46682e+00  7.53415e-01
21Feb13_174525|  -3.78005e-01]
21Feb13_174525| [-1.15511e-01  3.70614e-01  5.57123e-01  2.68691e-01 -1.42742e+00
21Feb13_174525|  -1.93233e-01]
21Feb13_174525| [-6.62414e-01  1.08008e-01  7.05660e-01 -4.59772e-02 -1.30027e+00
21Feb13_174525|  -5.21610e-01]
21Feb13_174525| [ 1.66346e+00  5.86243e-01 -1.51876e-01  2.30012e-01 -3.58419e-01
21Feb13_174525|  -1.23990e-01]
21Feb13_174525| [ 1.61966e+00 -6.43844e-02 -5.68742e-01 -9.25386e-01  6.79694e-01
21Feb13_174525|  -2.93331e-01]
21Feb13_174525| [ 7.10363e-01 -1.44787e+00 -2.34484e-01 -4.37677e-01 -1.22538e+00
21Feb13_174525|   1.83002e-01]
21Feb13_174525| [ 2.14622e-01 -1.12925e+00 -5.15099e-01  9.37440e-01  5.26126e-01
21Feb13_174525|   5.19098e-01]
21Feb13_174525| [ 5.67954e-01  1.43059e-01 -1.06384e+00  9.05593e-01 -2.00117e+00
21Feb13_174525|   1.80507e+00]
21Feb13_174525| [ 7.80472e-01 -3.54113e-01 -1.20890e+00  2.77431e+00 -9.37215e-01
21Feb13_174525|   3.77714e-01]
21Feb13_174525| [ 9.01572e-01 -4.56129e-01  1.15429e+00 -1.66769e-01  8.62034e-01
21Feb13_174525|   4.58879e-01]
21Feb13_174525| [ 2.91961e+00 -2.86061e+00 -2.01106e-01 -1.16509e+00 -7.08412e-01
21Feb13_174525|   1.11489e-01]
21Feb13_174525| [ 1.72952e+00  1.57028e+00 -2.07455e+00  8.60966e-01  1.09806e-01
21Feb13_174525|  -1.87101e-01]
21Feb13_174525| [-1.26201e+00  1.05169e+00  5.94851e-01  1.01150e-01 -1.38611e+00
21Feb13_174525|   1.02119e-01]
21Feb13_174525| [-1.07746e-02  3.08677e-01  1.45140e+00  3.07728e-01 -3.03820e-01
21Feb13_174525|  -1.89218e-01]
21Feb13_174525| [ 2.88911e-01  6.61534e-01 -5.08244e-01 -1.42714e-01  8.10001e-02
21Feb13_174525|   1.24332e-01]
21Feb13_174525| [-1.32570e+00  1.66273e-01  1.53351e+00  1.48902e+00  1.52882e+00
21Feb13_174525|   5.31791e-01]
21Feb13_174525| [ 2.18605e+00  7.69662e-01 -5.86388e-01  5.94944e-01  3.36219e-01
21Feb13_174525|   1.04673e-01]
21Feb13_174525| [-1.26380e-01  5.38904e-02 -7.81064e-01 -5.99197e-01  1.32875e-01
21Feb13_174525|  -5.29580e-01]
21Feb13_174525| [-4.18577e-01 -3.05427e-01 -2.87218e-02  2.30080e-01 -4.63573e-01
21Feb13_174525|   1.02996e+00]
21Feb13_174525| [-7.58159e-02 -7.34967e-01 -2.89689e-01 -6.13321e-01  1.19156e+00
21Feb13_174525|   6.56374e-01]
21Feb13_174525| [ 4.42022e-02 -1.91843e-01  9.05626e-01 -7.47534e-01  1.88839e-01
21Feb13_174525|  -2.99682e-01]
21Feb13_174525| [ 9.98249e-01  7.67460e-01  5.60854e-01  1.00827e+00 -5.46571e-01
21Feb13_174525|   2.12347e-01]
21Feb13_174525| [-3.93190e-01 -5.15195e-01  2.43161e-01  1.08610e+00 -1.18163e+00
21Feb13_174525|   5.27352e-01]
21Feb13_174525| [-2.10995e+00 -4.58607e-01  1.02182e+00 -9.34708e-01 -1.61474e-01
21Feb13_174525|   5.21834e-01]
21Feb13_174525| [ 2.71710e-01  6.30733e-01 -2.12292e+00  2.44596e-02  2.19986e-01
21Feb13_174525|   2.64510e-01]
21Feb13_174525| [ 2.73506e+00 -1.68607e+00 -3.43628e-01  7.61628e-02 -2.26828e-01
21Feb13_174525|  -3.81731e-01]
21Feb13_174525| [ 5.23338e-02 -7.03002e-01 -1.03161e-01  9.49301e-01  1.27202e-01
21Feb13_174525|   6.50503e-01]
21Feb13_174525| [-1.12324e-01  1.94323e-01 -1.49900e+00  1.41035e-01 -1.16220e+00
21Feb13_174525|  -3.35985e-01]
21Feb13_174525| [ 8.70873e-01  7.43781e-01 -1.46105e+00  4.68759e-01 -6.68305e-01
21Feb13_174525|  -1.71642e-01]
21Feb13_174525| [-8.00266e-01 -1.06325e-01  7.65769e-01  1.72880e+00  1.90866e+00
21Feb13_174525|   1.16830e+00]
21Feb13_174525| [-3.71919e-01  1.04334e+00 -1.67330e+00 -5.96497e-01 -3.52827e-01
21Feb13_174525|  -7.28103e-03]]
21Feb13_174525|-- Bias --
21Feb13_174525|[ 1.71352  0.90911  0.47256 -0.01331  0.42218 -0.02646]
21Feb13_174525|Layer 1:
21Feb13_174525|-- Config --
21Feb13_174525|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174525|-- Weights --
21Feb13_174525|[[-0.99267 -0.97274  0.82405 -0.16977]
21Feb13_174525| [ 0.60239 -0.10238 -0.00496 -0.14288]
21Feb13_174525| [-0.11020  0.99493  0.79092 -0.16312]
21Feb13_174525| [ 0.55308 -0.37597 -1.28077 -0.67794]
21Feb13_174525| [ 0.99539  0.72798  0.47591  0.49305]
21Feb13_174525| [ 0.83623 -0.20924  0.30390  0.06038]]
21Feb13_174525|-- Bias --
21Feb13_174525|[-0.44854  0.57814 -0.25511  0.43911]
21Feb13_174525|Layer 2:
21Feb13_174525|-- Config --
21Feb13_174525|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174525|-- Weights --
21Feb13_174525|[[ 0.33441  0.48577]
21Feb13_174525| [-0.92058 -1.06244]
21Feb13_174525| [-0.40205  1.58320]
21Feb13_174525| [-0.58076 -0.11565]]
21Feb13_174525|-- Bias --
21Feb13_174525|[0.09744 0.58731]
21Feb13_174525|Predicting the validation and test data with the Best final individual.
21Feb13_174533| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_174533|-----------  ------------------  --------------------  ----------
21Feb13_174533|Validation         28.43                  20            0.36655
21Feb13_174533|   Test            28.32                  20            0.51692
21Feb13_174533|-------------------- Test #5 --------------------
21Feb13_174533|Best final individual weights
21Feb13_174533|Individual:
21Feb13_174533|-- Constant hidden layers --
21Feb13_174533|False
21Feb13_174533|Layer 0:
21Feb13_174533|-- Config --
21Feb13_174533|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174533|-- Weights --
21Feb13_174533|[[ 1.13034e+00 -5.53286e-01  1.06969e+00  6.04800e-01 -1.80344e+00
21Feb13_174533|   1.87998e-01]
21Feb13_174533| [-2.06086e-01 -1.17561e+00 -3.88209e-01 -1.23630e+00 -1.70580e-01
21Feb13_174533|  -4.93509e-01]
21Feb13_174533| [ 8.62255e-01  1.17018e+00 -1.49746e+00 -2.74330e-01 -9.97699e-01
21Feb13_174533|   1.06762e+00]
21Feb13_174533| [ 1.05284e+00 -1.09601e+00  2.23484e+00 -1.58443e+00 -7.08990e-01
21Feb13_174533|  -2.24847e-02]
21Feb13_174533| [-1.85392e-01  3.74849e-01 -9.28314e-01 -5.05116e-01  9.75807e-01
21Feb13_174533|   2.26265e-02]
21Feb13_174533| [ 5.53864e-01 -1.44701e-01 -2.78496e-01 -9.65915e-02 -4.66222e-01
21Feb13_174533|  -4.82200e-01]
21Feb13_174533| [-2.83744e-01  1.05014e+00  6.84434e-01  1.96472e-01  1.51780e+00
21Feb13_174533|  -1.43357e+00]
21Feb13_174533| [ 2.51787e-01  2.82378e+00  3.38266e-02  7.75067e-01 -7.71118e-01
21Feb13_174533|   1.01245e+00]
21Feb13_174533| [ 6.35048e-01 -1.31302e+00  1.58172e+00 -7.59300e-01  7.75194e-01
21Feb13_174533|   3.57667e-01]
21Feb13_174533| [ 1.55833e-02 -1.52513e-01  1.14441e+00  1.21641e+00  1.46095e+00
21Feb13_174533|  -1.97462e-01]
21Feb13_174533| [ 8.82940e-01  4.70981e-01  8.94543e-03  2.12770e+00 -4.73172e-02
21Feb13_174533|   2.49972e-01]
21Feb13_174533| [ 2.02733e+00 -5.44623e-01  5.59001e-03 -5.46488e-01 -2.93472e-01
21Feb13_174533|   7.41024e-02]
21Feb13_174533| [ 4.30996e-01 -3.44291e-01  5.03869e-01 -1.70903e-01  2.02710e+00
21Feb13_174533|   7.40481e-01]
21Feb13_174533| [-5.79992e-02 -3.52174e-02  6.19134e-01  6.75090e-01  5.62871e-03
21Feb13_174533|   4.08582e-01]
21Feb13_174533| [ 2.11756e+00 -1.41866e+00 -4.73399e-01 -8.55975e-01  2.50962e-01
21Feb13_174533|   3.88174e-01]
21Feb13_174533| [ 1.08338e+00  7.28871e-01 -8.79437e-01  3.81938e-01 -1.04980e-01
21Feb13_174533|   3.81630e-01]
21Feb13_174533| [ 3.05477e-01  2.96671e-01 -3.34109e-02  9.81726e-01  7.50611e-01
21Feb13_174533|   1.53923e-03]
21Feb13_174533| [-1.97136e+00  4.35535e-01 -3.41613e-01 -1.14664e+00  2.60336e+00
21Feb13_174533|   1.22123e-01]
21Feb13_174533| [-9.72294e-01 -1.31051e+00 -6.25687e-01 -1.01171e+00  3.20799e-01
21Feb13_174533|  -6.29617e-01]
21Feb13_174533| [ 3.89268e-01 -3.12905e-01 -3.24592e+00  3.19579e-01 -9.28448e-01
21Feb13_174533|  -4.49606e-01]
21Feb13_174533| [-1.23874e-01  2.54123e-01  1.52446e-01  2.93099e+00 -8.96749e-01
21Feb13_174533|  -6.47971e-01]
21Feb13_174533| [-1.80957e-01  6.75851e-01 -7.40387e-01 -2.44728e-01 -9.53669e-01
21Feb13_174533|   5.04709e-01]
21Feb13_174533| [ 4.18558e-01  8.80843e-01  1.64533e+00  4.24741e-02 -3.58074e-01
21Feb13_174533|   7.98441e-02]
21Feb13_174533| [-3.98428e-01 -1.79152e+00 -2.41090e+00 -1.41339e+00  7.43891e-01
21Feb13_174533|   3.09447e-01]
21Feb13_174533| [ 3.44250e-01 -1.54741e+00 -4.11403e-01  4.49406e-01 -2.66079e-01
21Feb13_174533|  -2.31925e-01]
21Feb13_174533| [ 2.23338e-02 -2.24281e-01  1.92970e+00 -1.50261e+00  1.34918e+00
21Feb13_174533|  -3.39176e-01]
21Feb13_174533| [ 8.00847e-01  1.20519e+00  1.69998e+00 -1.46682e+00  7.53415e-01
21Feb13_174533|  -3.78005e-01]
21Feb13_174533| [-1.15511e-01  3.70614e-01  5.57123e-01  2.68691e-01 -1.42742e+00
21Feb13_174533|  -1.93233e-01]
21Feb13_174533| [-6.62414e-01  1.08008e-01  7.05660e-01 -4.59772e-02 -1.30027e+00
21Feb13_174533|  -5.21610e-01]
21Feb13_174533| [ 1.66346e+00  5.86243e-01 -1.51876e-01  2.30012e-01 -3.58419e-01
21Feb13_174533|  -1.23990e-01]
21Feb13_174533| [ 1.61966e+00 -6.43844e-02 -5.68742e-01 -9.25386e-01  6.79694e-01
21Feb13_174533|  -2.93331e-01]
21Feb13_174533| [ 7.10363e-01 -1.44787e+00 -2.34484e-01 -4.37677e-01 -1.22538e+00
21Feb13_174533|   1.83002e-01]
21Feb13_174533| [ 2.14622e-01 -1.12925e+00 -5.15099e-01  9.37440e-01  5.26126e-01
21Feb13_174533|   5.19098e-01]
21Feb13_174533| [ 5.67954e-01  1.43059e-01 -1.06384e+00  9.05593e-01 -2.00117e+00
21Feb13_174533|   1.80507e+00]
21Feb13_174533| [ 7.80472e-01 -3.54113e-01 -1.20890e+00  2.77431e+00 -9.37215e-01
21Feb13_174533|   3.77714e-01]
21Feb13_174533| [ 9.01572e-01 -4.56129e-01  1.15429e+00 -1.66769e-01  8.62034e-01
21Feb13_174533|   4.58879e-01]
21Feb13_174533| [ 2.91961e+00 -2.86061e+00 -2.01106e-01 -1.16509e+00 -7.08412e-01
21Feb13_174533|   1.11489e-01]
21Feb13_174533| [ 1.72952e+00  1.57028e+00 -2.07455e+00  8.60966e-01  1.09806e-01
21Feb13_174533|  -1.87101e-01]
21Feb13_174533| [-1.26201e+00  1.05169e+00  5.94851e-01  1.01150e-01 -1.38611e+00
21Feb13_174533|   1.02119e-01]
21Feb13_174533| [-1.07746e-02  3.08677e-01  1.45140e+00  3.07728e-01 -3.03820e-01
21Feb13_174533|  -1.89218e-01]
21Feb13_174533| [ 2.88911e-01  6.61534e-01 -5.08244e-01 -1.42714e-01  8.10001e-02
21Feb13_174533|   1.24332e-01]
21Feb13_174533| [-1.32570e+00  1.66273e-01  1.53351e+00  1.48902e+00  1.52882e+00
21Feb13_174533|   5.31791e-01]
21Feb13_174533| [ 2.18605e+00  7.69662e-01 -5.86388e-01  5.94944e-01  3.36219e-01
21Feb13_174533|   1.04673e-01]
21Feb13_174533| [-1.26380e-01  5.38904e-02 -7.81064e-01 -5.99197e-01  1.32875e-01
21Feb13_174533|  -5.29580e-01]
21Feb13_174533| [-4.18577e-01 -3.05427e-01 -2.87218e-02  2.30080e-01 -4.63573e-01
21Feb13_174533|   1.02996e+00]
21Feb13_174533| [-7.58159e-02 -7.34967e-01 -2.89689e-01 -6.13321e-01  1.19156e+00
21Feb13_174533|   6.56374e-01]
21Feb13_174533| [ 4.42022e-02 -1.91843e-01  9.05626e-01 -7.47534e-01  1.88839e-01
21Feb13_174533|  -2.99682e-01]
21Feb13_174533| [ 9.98249e-01  7.67460e-01  5.60854e-01  1.00827e+00 -5.46571e-01
21Feb13_174533|   2.12347e-01]
21Feb13_174533| [-3.93190e-01 -5.15195e-01  2.43161e-01  1.08610e+00 -1.18163e+00
21Feb13_174533|   5.27352e-01]
21Feb13_174533| [-2.10995e+00 -4.58607e-01  1.02182e+00 -9.34708e-01 -1.61474e-01
21Feb13_174533|   5.21834e-01]
21Feb13_174533| [ 2.71710e-01  6.30733e-01 -2.12292e+00  2.44596e-02  2.19986e-01
21Feb13_174533|   2.64510e-01]
21Feb13_174533| [ 2.73506e+00 -1.68607e+00 -3.43628e-01  7.61628e-02 -2.26828e-01
21Feb13_174533|  -3.81731e-01]
21Feb13_174533| [ 5.23338e-02 -7.03002e-01 -1.03161e-01  9.49301e-01  1.27202e-01
21Feb13_174533|   6.50503e-01]
21Feb13_174533| [-1.12324e-01  1.94323e-01 -1.49900e+00  1.41035e-01 -1.16220e+00
21Feb13_174533|  -3.35985e-01]
21Feb13_174533| [ 8.70873e-01  7.43781e-01 -1.46105e+00  4.68759e-01 -6.68305e-01
21Feb13_174533|  -1.71642e-01]
21Feb13_174533| [-8.00266e-01 -1.06325e-01  7.65769e-01  1.72880e+00  1.90866e+00
21Feb13_174533|   1.16830e+00]
21Feb13_174533| [-3.71919e-01  1.04334e+00 -1.67330e+00 -5.96497e-01 -3.52827e-01
21Feb13_174533|  -7.28103e-03]]
21Feb13_174533|-- Bias --
21Feb13_174533|[ 1.71352  0.90911  0.47256 -0.01331  0.42218 -0.02646]
21Feb13_174533|Layer 1:
21Feb13_174533|-- Config --
21Feb13_174533|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174533|-- Weights --
21Feb13_174533|[[-0.99267 -0.97274  0.82405 -0.16977]
21Feb13_174533| [ 0.60239 -0.10238 -0.00496 -0.14288]
21Feb13_174533| [-0.11020  0.99493  0.79092 -0.16312]
21Feb13_174533| [ 0.55308 -0.37597 -1.28077 -0.67794]
21Feb13_174533| [ 0.99539  0.72798  0.47591  0.49305]
21Feb13_174533| [ 0.83623 -0.20924  0.30390  0.06038]]
21Feb13_174533|-- Bias --
21Feb13_174533|[-0.44854  0.57814 -0.25511  0.43911]
21Feb13_174533|Layer 2:
21Feb13_174533|-- Config --
21Feb13_174533|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174533|-- Weights --
21Feb13_174533|[[ 0.33441  0.48577]
21Feb13_174533| [-0.92058 -1.06244]
21Feb13_174533| [-0.40205  1.58320]
21Feb13_174533| [-0.58076 -0.11565]]
21Feb13_174533|-- Bias --
21Feb13_174533|[0.09744 0.58731]
21Feb13_174533|Predicting the validation and test data with the Best final individual.
21Feb13_174540| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_174540|-----------  ------------------  --------------------  ----------
21Feb13_174540|Validation         28.26                  20            0.74287
21Feb13_174540|   Test            39.53                  20            0.00000
21Feb13_174540|-------------------- Test #6 --------------------
21Feb13_174540|Best final individual weights
21Feb13_174540|Individual:
21Feb13_174540|-- Constant hidden layers --
21Feb13_174540|False
21Feb13_174540|Layer 0:
21Feb13_174540|-- Config --
21Feb13_174540|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174540|-- Weights --
21Feb13_174540|[[ 1.13034e+00 -5.53286e-01  1.06969e+00  6.04800e-01 -1.80344e+00
21Feb13_174540|   1.87998e-01]
21Feb13_174540| [-2.06086e-01 -1.17561e+00 -3.88209e-01 -1.23630e+00 -1.70580e-01
21Feb13_174540|  -4.93509e-01]
21Feb13_174540| [ 8.62255e-01  1.17018e+00 -1.49746e+00 -2.74330e-01 -9.97699e-01
21Feb13_174540|   1.06762e+00]
21Feb13_174540| [ 1.05284e+00 -1.09601e+00  2.23484e+00 -1.58443e+00 -7.08990e-01
21Feb13_174540|  -2.24847e-02]
21Feb13_174540| [-1.85392e-01  3.74849e-01 -9.28314e-01 -5.05116e-01  9.75807e-01
21Feb13_174540|   2.26265e-02]
21Feb13_174540| [ 5.53864e-01 -1.44701e-01 -2.78496e-01 -9.65915e-02 -4.66222e-01
21Feb13_174540|  -4.82200e-01]
21Feb13_174540| [-2.83744e-01  1.05014e+00  6.84434e-01  1.96472e-01  1.51780e+00
21Feb13_174540|  -1.43357e+00]
21Feb13_174540| [ 2.51787e-01  2.82378e+00  3.38266e-02  7.75067e-01 -7.71118e-01
21Feb13_174540|   1.01245e+00]
21Feb13_174540| [ 6.35048e-01 -1.31302e+00  1.58172e+00 -7.59300e-01  7.75194e-01
21Feb13_174540|   3.57667e-01]
21Feb13_174540| [ 1.55833e-02 -1.52513e-01  1.14441e+00  1.21641e+00  1.46095e+00
21Feb13_174540|  -1.97462e-01]
21Feb13_174540| [ 8.82940e-01  4.70981e-01  8.94543e-03  2.12770e+00 -4.73172e-02
21Feb13_174540|   2.49972e-01]
21Feb13_174540| [ 2.02733e+00 -5.44623e-01  5.59001e-03 -5.46488e-01 -2.93472e-01
21Feb13_174540|   7.41024e-02]
21Feb13_174540| [ 4.30996e-01 -3.44291e-01  5.03869e-01 -1.70903e-01  2.02710e+00
21Feb13_174540|   7.40481e-01]
21Feb13_174540| [-5.79992e-02 -3.52174e-02  6.19134e-01  6.75090e-01  5.62871e-03
21Feb13_174540|   4.08582e-01]
21Feb13_174540| [ 2.11756e+00 -1.41866e+00 -4.73399e-01 -8.55975e-01  2.50962e-01
21Feb13_174540|   3.88174e-01]
21Feb13_174540| [ 1.08338e+00  7.28871e-01 -8.79437e-01  3.81938e-01 -1.04980e-01
21Feb13_174540|   3.81630e-01]
21Feb13_174540| [ 3.05477e-01  2.96671e-01 -3.34109e-02  9.81726e-01  7.50611e-01
21Feb13_174540|   1.53923e-03]
21Feb13_174540| [-1.97136e+00  4.35535e-01 -3.41613e-01 -1.14664e+00  2.60336e+00
21Feb13_174540|   1.22123e-01]
21Feb13_174540| [-9.72294e-01 -1.31051e+00 -6.25687e-01 -1.01171e+00  3.20799e-01
21Feb13_174540|  -6.29617e-01]
21Feb13_174540| [ 3.89268e-01 -3.12905e-01 -3.24592e+00  3.19579e-01 -9.28448e-01
21Feb13_174540|  -4.49606e-01]
21Feb13_174540| [-1.23874e-01  2.54123e-01  1.52446e-01  2.93099e+00 -8.96749e-01
21Feb13_174540|  -6.47971e-01]
21Feb13_174540| [-1.80957e-01  6.75851e-01 -7.40387e-01 -2.44728e-01 -9.53669e-01
21Feb13_174540|   5.04709e-01]
21Feb13_174540| [ 4.18558e-01  8.80843e-01  1.64533e+00  4.24741e-02 -3.58074e-01
21Feb13_174540|   7.98441e-02]
21Feb13_174540| [-3.98428e-01 -1.79152e+00 -2.41090e+00 -1.41339e+00  7.43891e-01
21Feb13_174540|   3.09447e-01]
21Feb13_174540| [ 3.44250e-01 -1.54741e+00 -4.11403e-01  4.49406e-01 -2.66079e-01
21Feb13_174540|  -2.31925e-01]
21Feb13_174540| [ 2.23338e-02 -2.24281e-01  1.92970e+00 -1.50261e+00  1.34918e+00
21Feb13_174540|  -3.39176e-01]
21Feb13_174540| [ 8.00847e-01  1.20519e+00  1.69998e+00 -1.46682e+00  7.53415e-01
21Feb13_174540|  -3.78005e-01]
21Feb13_174540| [-1.15511e-01  3.70614e-01  5.57123e-01  2.68691e-01 -1.42742e+00
21Feb13_174540|  -1.93233e-01]
21Feb13_174540| [-6.62414e-01  1.08008e-01  7.05660e-01 -4.59772e-02 -1.30027e+00
21Feb13_174540|  -5.21610e-01]
21Feb13_174540| [ 1.66346e+00  5.86243e-01 -1.51876e-01  2.30012e-01 -3.58419e-01
21Feb13_174540|  -1.23990e-01]
21Feb13_174540| [ 1.61966e+00 -6.43844e-02 -5.68742e-01 -9.25386e-01  6.79694e-01
21Feb13_174540|  -2.93331e-01]
21Feb13_174540| [ 7.10363e-01 -1.44787e+00 -2.34484e-01 -4.37677e-01 -1.22538e+00
21Feb13_174540|   1.83002e-01]
21Feb13_174540| [ 2.14622e-01 -1.12925e+00 -5.15099e-01  9.37440e-01  5.26126e-01
21Feb13_174540|   5.19098e-01]
21Feb13_174540| [ 5.67954e-01  1.43059e-01 -1.06384e+00  9.05593e-01 -2.00117e+00
21Feb13_174540|   1.80507e+00]
21Feb13_174540| [ 7.80472e-01 -3.54113e-01 -1.20890e+00  2.77431e+00 -9.37215e-01
21Feb13_174540|   3.77714e-01]
21Feb13_174540| [ 9.01572e-01 -4.56129e-01  1.15429e+00 -1.66769e-01  8.62034e-01
21Feb13_174540|   4.58879e-01]
21Feb13_174540| [ 2.91961e+00 -2.86061e+00 -2.01106e-01 -1.16509e+00 -7.08412e-01
21Feb13_174540|   1.11489e-01]
21Feb13_174540| [ 1.72952e+00  1.57028e+00 -2.07455e+00  8.60966e-01  1.09806e-01
21Feb13_174540|  -1.87101e-01]
21Feb13_174540| [-1.26201e+00  1.05169e+00  5.94851e-01  1.01150e-01 -1.38611e+00
21Feb13_174540|   1.02119e-01]
21Feb13_174540| [-1.07746e-02  3.08677e-01  1.45140e+00  3.07728e-01 -3.03820e-01
21Feb13_174540|  -1.89218e-01]
21Feb13_174540| [ 2.88911e-01  6.61534e-01 -5.08244e-01 -1.42714e-01  8.10001e-02
21Feb13_174540|   1.24332e-01]
21Feb13_174540| [-1.32570e+00  1.66273e-01  1.53351e+00  1.48902e+00  1.52882e+00
21Feb13_174540|   5.31791e-01]
21Feb13_174540| [ 2.18605e+00  7.69662e-01 -5.86388e-01  5.94944e-01  3.36219e-01
21Feb13_174540|   1.04673e-01]
21Feb13_174540| [-1.26380e-01  5.38904e-02 -7.81064e-01 -5.99197e-01  1.32875e-01
21Feb13_174540|  -5.29580e-01]
21Feb13_174540| [-4.18577e-01 -3.05427e-01 -2.87218e-02  2.30080e-01 -4.63573e-01
21Feb13_174540|   1.02996e+00]
21Feb13_174540| [-7.58159e-02 -7.34967e-01 -2.89689e-01 -6.13321e-01  1.19156e+00
21Feb13_174540|   6.56374e-01]
21Feb13_174540| [ 4.42022e-02 -1.91843e-01  9.05626e-01 -7.47534e-01  1.88839e-01
21Feb13_174540|  -2.99682e-01]
21Feb13_174540| [ 9.98249e-01  7.67460e-01  5.60854e-01  1.00827e+00 -5.46571e-01
21Feb13_174540|   2.12347e-01]
21Feb13_174540| [-3.93190e-01 -5.15195e-01  2.43161e-01  1.08610e+00 -1.18163e+00
21Feb13_174540|   5.27352e-01]
21Feb13_174540| [-2.10995e+00 -4.58607e-01  1.02182e+00 -9.34708e-01 -1.61474e-01
21Feb13_174540|   5.21834e-01]
21Feb13_174540| [ 2.71710e-01  6.30733e-01 -2.12292e+00  2.44596e-02  2.19986e-01
21Feb13_174540|   2.64510e-01]
21Feb13_174540| [ 2.73506e+00 -1.68607e+00 -3.43628e-01  7.61628e-02 -2.26828e-01
21Feb13_174540|  -3.81731e-01]
21Feb13_174540| [ 5.23338e-02 -7.03002e-01 -1.03161e-01  9.49301e-01  1.27202e-01
21Feb13_174540|   6.50503e-01]
21Feb13_174540| [-1.12324e-01  1.94323e-01 -1.49900e+00  1.41035e-01 -1.16220e+00
21Feb13_174540|  -3.35985e-01]
21Feb13_174540| [ 8.70873e-01  7.43781e-01 -1.46105e+00  4.68759e-01 -6.68305e-01
21Feb13_174540|  -1.71642e-01]
21Feb13_174540| [-8.00266e-01 -1.06325e-01  7.65769e-01  1.72880e+00  1.90866e+00
21Feb13_174540|   1.16830e+00]
21Feb13_174540| [-3.71919e-01  1.04334e+00 -1.67330e+00 -5.96497e-01 -3.52827e-01
21Feb13_174540|  -7.28103e-03]]
21Feb13_174540|-- Bias --
21Feb13_174540|[ 1.71352  0.90911  0.47256 -0.01331  0.42218 -0.02646]
21Feb13_174540|Layer 1:
21Feb13_174540|-- Config --
21Feb13_174540|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174540|-- Weights --
21Feb13_174540|[[-0.99267 -0.97274  0.82405 -0.16977]
21Feb13_174540| [ 0.60239 -0.10238 -0.00496 -0.14288]
21Feb13_174540| [-0.11020  0.99493  0.79092 -0.16312]
21Feb13_174540| [ 0.55308 -0.37597 -1.28077 -0.67794]
21Feb13_174540| [ 0.99539  0.72798  0.47591  0.49305]
21Feb13_174540| [ 0.83623 -0.20924  0.30390  0.06038]]
21Feb13_174540|-- Bias --
21Feb13_174540|[-0.44854  0.57814 -0.25511  0.43911]
21Feb13_174540|Layer 2:
21Feb13_174540|-- Config --
21Feb13_174540|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174540|-- Weights --
21Feb13_174540|[[ 0.33441  0.48577]
21Feb13_174540| [-0.92058 -1.06244]
21Feb13_174540| [-0.40205  1.58320]
21Feb13_174540| [-0.58076 -0.11565]]
21Feb13_174540|-- Bias --
21Feb13_174540|[0.09744 0.58731]
21Feb13_174540|Predicting the validation and test data with the Best final individual.
21Feb13_174547| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_174547|-----------  ------------------  --------------------  ----------
21Feb13_174547|Validation         38.43                  20            0.00000
21Feb13_174547|   Test            27.63                  20            0.56630
21Feb13_174547|-------------------- Test #7 --------------------
21Feb13_174547|Best final individual weights
21Feb13_174547|Individual:
21Feb13_174547|-- Constant hidden layers --
21Feb13_174547|False
21Feb13_174547|Layer 0:
21Feb13_174547|-- Config --
21Feb13_174547|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174547|-- Weights --
21Feb13_174547|[[ 1.13034e+00 -5.53286e-01  1.06969e+00  6.04800e-01 -1.80344e+00
21Feb13_174547|   1.87998e-01]
21Feb13_174547| [-2.06086e-01 -1.17561e+00 -3.88209e-01 -1.23630e+00 -1.70580e-01
21Feb13_174547|  -4.93509e-01]
21Feb13_174547| [ 8.62255e-01  1.17018e+00 -1.49746e+00 -2.74330e-01 -9.97699e-01
21Feb13_174547|   1.06762e+00]
21Feb13_174547| [ 1.05284e+00 -1.09601e+00  2.23484e+00 -1.58443e+00 -7.08990e-01
21Feb13_174547|  -2.24847e-02]
21Feb13_174547| [-1.85392e-01  3.74849e-01 -9.28314e-01 -5.05116e-01  9.75807e-01
21Feb13_174547|   2.26265e-02]
21Feb13_174547| [ 5.53864e-01 -1.44701e-01 -2.78496e-01 -9.65915e-02 -4.66222e-01
21Feb13_174547|  -4.82200e-01]
21Feb13_174547| [-2.83744e-01  1.05014e+00  6.84434e-01  1.96472e-01  1.51780e+00
21Feb13_174547|  -1.43357e+00]
21Feb13_174547| [ 2.51787e-01  2.82378e+00  3.38266e-02  7.75067e-01 -7.71118e-01
21Feb13_174547|   1.01245e+00]
21Feb13_174547| [ 6.35048e-01 -1.31302e+00  1.58172e+00 -7.59300e-01  7.75194e-01
21Feb13_174547|   3.57667e-01]
21Feb13_174547| [ 1.55833e-02 -1.52513e-01  1.14441e+00  1.21641e+00  1.46095e+00
21Feb13_174547|  -1.97462e-01]
21Feb13_174547| [ 8.82940e-01  4.70981e-01  8.94543e-03  2.12770e+00 -4.73172e-02
21Feb13_174547|   2.49972e-01]
21Feb13_174547| [ 2.02733e+00 -5.44623e-01  5.59001e-03 -5.46488e-01 -2.93472e-01
21Feb13_174547|   7.41024e-02]
21Feb13_174547| [ 4.30996e-01 -3.44291e-01  5.03869e-01 -1.70903e-01  2.02710e+00
21Feb13_174547|   7.40481e-01]
21Feb13_174547| [-5.79992e-02 -3.52174e-02  6.19134e-01  6.75090e-01  5.62871e-03
21Feb13_174547|   4.08582e-01]
21Feb13_174547| [ 2.11756e+00 -1.41866e+00 -4.73399e-01 -8.55975e-01  2.50962e-01
21Feb13_174547|   3.88174e-01]
21Feb13_174547| [ 1.08338e+00  7.28871e-01 -8.79437e-01  3.81938e-01 -1.04980e-01
21Feb13_174547|   3.81630e-01]
21Feb13_174547| [ 3.05477e-01  2.96671e-01 -3.34109e-02  9.81726e-01  7.50611e-01
21Feb13_174547|   1.53923e-03]
21Feb13_174547| [-1.97136e+00  4.35535e-01 -3.41613e-01 -1.14664e+00  2.60336e+00
21Feb13_174547|   1.22123e-01]
21Feb13_174547| [-9.72294e-01 -1.31051e+00 -6.25687e-01 -1.01171e+00  3.20799e-01
21Feb13_174547|  -6.29617e-01]
21Feb13_174547| [ 3.89268e-01 -3.12905e-01 -3.24592e+00  3.19579e-01 -9.28448e-01
21Feb13_174547|  -4.49606e-01]
21Feb13_174547| [-1.23874e-01  2.54123e-01  1.52446e-01  2.93099e+00 -8.96749e-01
21Feb13_174547|  -6.47971e-01]
21Feb13_174547| [-1.80957e-01  6.75851e-01 -7.40387e-01 -2.44728e-01 -9.53669e-01
21Feb13_174547|   5.04709e-01]
21Feb13_174547| [ 4.18558e-01  8.80843e-01  1.64533e+00  4.24741e-02 -3.58074e-01
21Feb13_174547|   7.98441e-02]
21Feb13_174547| [-3.98428e-01 -1.79152e+00 -2.41090e+00 -1.41339e+00  7.43891e-01
21Feb13_174547|   3.09447e-01]
21Feb13_174547| [ 3.44250e-01 -1.54741e+00 -4.11403e-01  4.49406e-01 -2.66079e-01
21Feb13_174547|  -2.31925e-01]
21Feb13_174547| [ 2.23338e-02 -2.24281e-01  1.92970e+00 -1.50261e+00  1.34918e+00
21Feb13_174547|  -3.39176e-01]
21Feb13_174547| [ 8.00847e-01  1.20519e+00  1.69998e+00 -1.46682e+00  7.53415e-01
21Feb13_174547|  -3.78005e-01]
21Feb13_174547| [-1.15511e-01  3.70614e-01  5.57123e-01  2.68691e-01 -1.42742e+00
21Feb13_174547|  -1.93233e-01]
21Feb13_174547| [-6.62414e-01  1.08008e-01  7.05660e-01 -4.59772e-02 -1.30027e+00
21Feb13_174547|  -5.21610e-01]
21Feb13_174547| [ 1.66346e+00  5.86243e-01 -1.51876e-01  2.30012e-01 -3.58419e-01
21Feb13_174547|  -1.23990e-01]
21Feb13_174547| [ 1.61966e+00 -6.43844e-02 -5.68742e-01 -9.25386e-01  6.79694e-01
21Feb13_174547|  -2.93331e-01]
21Feb13_174547| [ 7.10363e-01 -1.44787e+00 -2.34484e-01 -4.37677e-01 -1.22538e+00
21Feb13_174547|   1.83002e-01]
21Feb13_174547| [ 2.14622e-01 -1.12925e+00 -5.15099e-01  9.37440e-01  5.26126e-01
21Feb13_174547|   5.19098e-01]
21Feb13_174547| [ 5.67954e-01  1.43059e-01 -1.06384e+00  9.05593e-01 -2.00117e+00
21Feb13_174547|   1.80507e+00]
21Feb13_174547| [ 7.80472e-01 -3.54113e-01 -1.20890e+00  2.77431e+00 -9.37215e-01
21Feb13_174547|   3.77714e-01]
21Feb13_174547| [ 9.01572e-01 -4.56129e-01  1.15429e+00 -1.66769e-01  8.62034e-01
21Feb13_174547|   4.58879e-01]
21Feb13_174547| [ 2.91961e+00 -2.86061e+00 -2.01106e-01 -1.16509e+00 -7.08412e-01
21Feb13_174547|   1.11489e-01]
21Feb13_174547| [ 1.72952e+00  1.57028e+00 -2.07455e+00  8.60966e-01  1.09806e-01
21Feb13_174547|  -1.87101e-01]
21Feb13_174547| [-1.26201e+00  1.05169e+00  5.94851e-01  1.01150e-01 -1.38611e+00
21Feb13_174547|   1.02119e-01]
21Feb13_174547| [-1.07746e-02  3.08677e-01  1.45140e+00  3.07728e-01 -3.03820e-01
21Feb13_174547|  -1.89218e-01]
21Feb13_174547| [ 2.88911e-01  6.61534e-01 -5.08244e-01 -1.42714e-01  8.10001e-02
21Feb13_174547|   1.24332e-01]
21Feb13_174547| [-1.32570e+00  1.66273e-01  1.53351e+00  1.48902e+00  1.52882e+00
21Feb13_174547|   5.31791e-01]
21Feb13_174547| [ 2.18605e+00  7.69662e-01 -5.86388e-01  5.94944e-01  3.36219e-01
21Feb13_174547|   1.04673e-01]
21Feb13_174547| [-1.26380e-01  5.38904e-02 -7.81064e-01 -5.99197e-01  1.32875e-01
21Feb13_174547|  -5.29580e-01]
21Feb13_174547| [-4.18577e-01 -3.05427e-01 -2.87218e-02  2.30080e-01 -4.63573e-01
21Feb13_174547|   1.02996e+00]
21Feb13_174547| [-7.58159e-02 -7.34967e-01 -2.89689e-01 -6.13321e-01  1.19156e+00
21Feb13_174547|   6.56374e-01]
21Feb13_174547| [ 4.42022e-02 -1.91843e-01  9.05626e-01 -7.47534e-01  1.88839e-01
21Feb13_174547|  -2.99682e-01]
21Feb13_174547| [ 9.98249e-01  7.67460e-01  5.60854e-01  1.00827e+00 -5.46571e-01
21Feb13_174547|   2.12347e-01]
21Feb13_174547| [-3.93190e-01 -5.15195e-01  2.43161e-01  1.08610e+00 -1.18163e+00
21Feb13_174547|   5.27352e-01]
21Feb13_174547| [-2.10995e+00 -4.58607e-01  1.02182e+00 -9.34708e-01 -1.61474e-01
21Feb13_174547|   5.21834e-01]
21Feb13_174547| [ 2.71710e-01  6.30733e-01 -2.12292e+00  2.44596e-02  2.19986e-01
21Feb13_174547|   2.64510e-01]
21Feb13_174547| [ 2.73506e+00 -1.68607e+00 -3.43628e-01  7.61628e-02 -2.26828e-01
21Feb13_174547|  -3.81731e-01]
21Feb13_174547| [ 5.23338e-02 -7.03002e-01 -1.03161e-01  9.49301e-01  1.27202e-01
21Feb13_174547|   6.50503e-01]
21Feb13_174547| [-1.12324e-01  1.94323e-01 -1.49900e+00  1.41035e-01 -1.16220e+00
21Feb13_174547|  -3.35985e-01]
21Feb13_174547| [ 8.70873e-01  7.43781e-01 -1.46105e+00  4.68759e-01 -6.68305e-01
21Feb13_174547|  -1.71642e-01]
21Feb13_174547| [-8.00266e-01 -1.06325e-01  7.65769e-01  1.72880e+00  1.90866e+00
21Feb13_174547|   1.16830e+00]
21Feb13_174547| [-3.71919e-01  1.04334e+00 -1.67330e+00 -5.96497e-01 -3.52827e-01
21Feb13_174547|  -7.28103e-03]]
21Feb13_174547|-- Bias --
21Feb13_174547|[ 1.71352  0.90911  0.47256 -0.01331  0.42218 -0.02646]
21Feb13_174547|Layer 1:
21Feb13_174547|-- Config --
21Feb13_174547|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174547|-- Weights --
21Feb13_174547|[[-0.99267 -0.97274  0.82405 -0.16977]
21Feb13_174547| [ 0.60239 -0.10238 -0.00496 -0.14288]
21Feb13_174547| [-0.11020  0.99493  0.79092 -0.16312]
21Feb13_174547| [ 0.55308 -0.37597 -1.28077 -0.67794]
21Feb13_174547| [ 0.99539  0.72798  0.47591  0.49305]
21Feb13_174547| [ 0.83623 -0.20924  0.30390  0.06038]]
21Feb13_174547|-- Bias --
21Feb13_174547|[-0.44854  0.57814 -0.25511  0.43911]
21Feb13_174547|Layer 2:
21Feb13_174547|-- Config --
21Feb13_174547|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174547|-- Weights --
21Feb13_174547|[[ 0.33441  0.48577]
21Feb13_174547| [-0.92058 -1.06244]
21Feb13_174547| [-0.40205  1.58320]
21Feb13_174547| [-0.58076 -0.11565]]
21Feb13_174547|-- Bias --
21Feb13_174547|[0.09744 0.58731]
21Feb13_174547|Predicting the validation and test data with the Best final individual.
21Feb13_174555| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_174555|-----------  ------------------  --------------------  ----------
21Feb13_174555|Validation         38.35                  20            0.00283
21Feb13_174555|   Test            39.53                  20            0.00000
21Feb13_174555|-------------------- Test #8 --------------------
21Feb13_174555|Best final individual weights
21Feb13_174555|Individual:
21Feb13_174555|-- Constant hidden layers --
21Feb13_174555|False
21Feb13_174555|Layer 0:
21Feb13_174555|-- Config --
21Feb13_174555|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174555|-- Weights --
21Feb13_174555|[[ 1.13034e+00 -5.53286e-01  1.06969e+00  6.04800e-01 -1.80344e+00
21Feb13_174555|   1.87998e-01]
21Feb13_174555| [-2.06086e-01 -1.17561e+00 -3.88209e-01 -1.23630e+00 -1.70580e-01
21Feb13_174555|  -4.93509e-01]
21Feb13_174555| [ 8.62255e-01  1.17018e+00 -1.49746e+00 -2.74330e-01 -9.97699e-01
21Feb13_174555|   1.06762e+00]
21Feb13_174555| [ 1.05284e+00 -1.09601e+00  2.23484e+00 -1.58443e+00 -7.08990e-01
21Feb13_174555|  -2.24847e-02]
21Feb13_174555| [-1.85392e-01  3.74849e-01 -9.28314e-01 -5.05116e-01  9.75807e-01
21Feb13_174555|   2.26265e-02]
21Feb13_174555| [ 5.53864e-01 -1.44701e-01 -2.78496e-01 -9.65915e-02 -4.66222e-01
21Feb13_174555|  -4.82200e-01]
21Feb13_174555| [-2.83744e-01  1.05014e+00  6.84434e-01  1.96472e-01  1.51780e+00
21Feb13_174555|  -1.43357e+00]
21Feb13_174555| [ 2.51787e-01  2.82378e+00  3.38266e-02  7.75067e-01 -7.71118e-01
21Feb13_174555|   1.01245e+00]
21Feb13_174555| [ 6.35048e-01 -1.31302e+00  1.58172e+00 -7.59300e-01  7.75194e-01
21Feb13_174555|   3.57667e-01]
21Feb13_174555| [ 1.55833e-02 -1.52513e-01  1.14441e+00  1.21641e+00  1.46095e+00
21Feb13_174555|  -1.97462e-01]
21Feb13_174555| [ 8.82940e-01  4.70981e-01  8.94543e-03  2.12770e+00 -4.73172e-02
21Feb13_174555|   2.49972e-01]
21Feb13_174555| [ 2.02733e+00 -5.44623e-01  5.59001e-03 -5.46488e-01 -2.93472e-01
21Feb13_174555|   7.41024e-02]
21Feb13_174555| [ 4.30996e-01 -3.44291e-01  5.03869e-01 -1.70903e-01  2.02710e+00
21Feb13_174555|   7.40481e-01]
21Feb13_174555| [-5.79992e-02 -3.52174e-02  6.19134e-01  6.75090e-01  5.62871e-03
21Feb13_174555|   4.08582e-01]
21Feb13_174555| [ 2.11756e+00 -1.41866e+00 -4.73399e-01 -8.55975e-01  2.50962e-01
21Feb13_174555|   3.88174e-01]
21Feb13_174555| [ 1.08338e+00  7.28871e-01 -8.79437e-01  3.81938e-01 -1.04980e-01
21Feb13_174555|   3.81630e-01]
21Feb13_174555| [ 3.05477e-01  2.96671e-01 -3.34109e-02  9.81726e-01  7.50611e-01
21Feb13_174555|   1.53923e-03]
21Feb13_174555| [-1.97136e+00  4.35535e-01 -3.41613e-01 -1.14664e+00  2.60336e+00
21Feb13_174555|   1.22123e-01]
21Feb13_174555| [-9.72294e-01 -1.31051e+00 -6.25687e-01 -1.01171e+00  3.20799e-01
21Feb13_174555|  -6.29617e-01]
21Feb13_174555| [ 3.89268e-01 -3.12905e-01 -3.24592e+00  3.19579e-01 -9.28448e-01
21Feb13_174555|  -4.49606e-01]
21Feb13_174555| [-1.23874e-01  2.54123e-01  1.52446e-01  2.93099e+00 -8.96749e-01
21Feb13_174555|  -6.47971e-01]
21Feb13_174555| [-1.80957e-01  6.75851e-01 -7.40387e-01 -2.44728e-01 -9.53669e-01
21Feb13_174555|   5.04709e-01]
21Feb13_174555| [ 4.18558e-01  8.80843e-01  1.64533e+00  4.24741e-02 -3.58074e-01
21Feb13_174555|   7.98441e-02]
21Feb13_174555| [-3.98428e-01 -1.79152e+00 -2.41090e+00 -1.41339e+00  7.43891e-01
21Feb13_174555|   3.09447e-01]
21Feb13_174555| [ 3.44250e-01 -1.54741e+00 -4.11403e-01  4.49406e-01 -2.66079e-01
21Feb13_174555|  -2.31925e-01]
21Feb13_174555| [ 2.23338e-02 -2.24281e-01  1.92970e+00 -1.50261e+00  1.34918e+00
21Feb13_174555|  -3.39176e-01]
21Feb13_174555| [ 8.00847e-01  1.20519e+00  1.69998e+00 -1.46682e+00  7.53415e-01
21Feb13_174555|  -3.78005e-01]
21Feb13_174555| [-1.15511e-01  3.70614e-01  5.57123e-01  2.68691e-01 -1.42742e+00
21Feb13_174555|  -1.93233e-01]
21Feb13_174555| [-6.62414e-01  1.08008e-01  7.05660e-01 -4.59772e-02 -1.30027e+00
21Feb13_174555|  -5.21610e-01]
21Feb13_174555| [ 1.66346e+00  5.86243e-01 -1.51876e-01  2.30012e-01 -3.58419e-01
21Feb13_174555|  -1.23990e-01]
21Feb13_174555| [ 1.61966e+00 -6.43844e-02 -5.68742e-01 -9.25386e-01  6.79694e-01
21Feb13_174555|  -2.93331e-01]
21Feb13_174555| [ 7.10363e-01 -1.44787e+00 -2.34484e-01 -4.37677e-01 -1.22538e+00
21Feb13_174555|   1.83002e-01]
21Feb13_174555| [ 2.14622e-01 -1.12925e+00 -5.15099e-01  9.37440e-01  5.26126e-01
21Feb13_174555|   5.19098e-01]
21Feb13_174555| [ 5.67954e-01  1.43059e-01 -1.06384e+00  9.05593e-01 -2.00117e+00
21Feb13_174555|   1.80507e+00]
21Feb13_174555| [ 7.80472e-01 -3.54113e-01 -1.20890e+00  2.77431e+00 -9.37215e-01
21Feb13_174555|   3.77714e-01]
21Feb13_174555| [ 9.01572e-01 -4.56129e-01  1.15429e+00 -1.66769e-01  8.62034e-01
21Feb13_174555|   4.58879e-01]
21Feb13_174555| [ 2.91961e+00 -2.86061e+00 -2.01106e-01 -1.16509e+00 -7.08412e-01
21Feb13_174555|   1.11489e-01]
21Feb13_174555| [ 1.72952e+00  1.57028e+00 -2.07455e+00  8.60966e-01  1.09806e-01
21Feb13_174555|  -1.87101e-01]
21Feb13_174555| [-1.26201e+00  1.05169e+00  5.94851e-01  1.01150e-01 -1.38611e+00
21Feb13_174555|   1.02119e-01]
21Feb13_174555| [-1.07746e-02  3.08677e-01  1.45140e+00  3.07728e-01 -3.03820e-01
21Feb13_174555|  -1.89218e-01]
21Feb13_174555| [ 2.88911e-01  6.61534e-01 -5.08244e-01 -1.42714e-01  8.10001e-02
21Feb13_174555|   1.24332e-01]
21Feb13_174555| [-1.32570e+00  1.66273e-01  1.53351e+00  1.48902e+00  1.52882e+00
21Feb13_174555|   5.31791e-01]
21Feb13_174555| [ 2.18605e+00  7.69662e-01 -5.86388e-01  5.94944e-01  3.36219e-01
21Feb13_174555|   1.04673e-01]
21Feb13_174555| [-1.26380e-01  5.38904e-02 -7.81064e-01 -5.99197e-01  1.32875e-01
21Feb13_174555|  -5.29580e-01]
21Feb13_174555| [-4.18577e-01 -3.05427e-01 -2.87218e-02  2.30080e-01 -4.63573e-01
21Feb13_174555|   1.02996e+00]
21Feb13_174555| [-7.58159e-02 -7.34967e-01 -2.89689e-01 -6.13321e-01  1.19156e+00
21Feb13_174555|   6.56374e-01]
21Feb13_174555| [ 4.42022e-02 -1.91843e-01  9.05626e-01 -7.47534e-01  1.88839e-01
21Feb13_174555|  -2.99682e-01]
21Feb13_174555| [ 9.98249e-01  7.67460e-01  5.60854e-01  1.00827e+00 -5.46571e-01
21Feb13_174555|   2.12347e-01]
21Feb13_174555| [-3.93190e-01 -5.15195e-01  2.43161e-01  1.08610e+00 -1.18163e+00
21Feb13_174555|   5.27352e-01]
21Feb13_174555| [-2.10995e+00 -4.58607e-01  1.02182e+00 -9.34708e-01 -1.61474e-01
21Feb13_174555|   5.21834e-01]
21Feb13_174555| [ 2.71710e-01  6.30733e-01 -2.12292e+00  2.44596e-02  2.19986e-01
21Feb13_174555|   2.64510e-01]
21Feb13_174555| [ 2.73506e+00 -1.68607e+00 -3.43628e-01  7.61628e-02 -2.26828e-01
21Feb13_174555|  -3.81731e-01]
21Feb13_174555| [ 5.23338e-02 -7.03002e-01 -1.03161e-01  9.49301e-01  1.27202e-01
21Feb13_174555|   6.50503e-01]
21Feb13_174555| [-1.12324e-01  1.94323e-01 -1.49900e+00  1.41035e-01 -1.16220e+00
21Feb13_174555|  -3.35985e-01]
21Feb13_174555| [ 8.70873e-01  7.43781e-01 -1.46105e+00  4.68759e-01 -6.68305e-01
21Feb13_174555|  -1.71642e-01]
21Feb13_174555| [-8.00266e-01 -1.06325e-01  7.65769e-01  1.72880e+00  1.90866e+00
21Feb13_174555|   1.16830e+00]
21Feb13_174555| [-3.71919e-01  1.04334e+00 -1.67330e+00 -5.96497e-01 -3.52827e-01
21Feb13_174555|  -7.28103e-03]]
21Feb13_174555|-- Bias --
21Feb13_174555|[ 1.71352  0.90911  0.47256 -0.01331  0.42218 -0.02646]
21Feb13_174555|Layer 1:
21Feb13_174555|-- Config --
21Feb13_174555|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174555|-- Weights --
21Feb13_174555|[[-0.99267 -0.97274  0.82405 -0.16977]
21Feb13_174555| [ 0.60239 -0.10238 -0.00496 -0.14288]
21Feb13_174555| [-0.11020  0.99493  0.79092 -0.16312]
21Feb13_174555| [ 0.55308 -0.37597 -1.28077 -0.67794]
21Feb13_174555| [ 0.99539  0.72798  0.47591  0.49305]
21Feb13_174555| [ 0.83623 -0.20924  0.30390  0.06038]]
21Feb13_174555|-- Bias --
21Feb13_174555|[-0.44854  0.57814 -0.25511  0.43911]
21Feb13_174555|Layer 2:
21Feb13_174555|-- Config --
21Feb13_174555|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174555|-- Weights --
21Feb13_174555|[[ 0.33441  0.48577]
21Feb13_174555| [-0.92058 -1.06244]
21Feb13_174555| [-0.40205  1.58320]
21Feb13_174555| [-0.58076 -0.11565]]
21Feb13_174555|-- Bias --
21Feb13_174555|[0.09744 0.58731]
21Feb13_174555|Predicting the validation and test data with the Best final individual.
21Feb13_174602| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_174602|-----------  ------------------  --------------------  ----------
21Feb13_174602|Validation         38.52                  20            0.00000
21Feb13_174602|   Test            27.98                  20            0.46225
21Feb13_174602|-------------------- Test #9 --------------------
21Feb13_174602|Best final individual weights
21Feb13_174602|Individual:
21Feb13_174602|-- Constant hidden layers --
21Feb13_174602|False
21Feb13_174602|Layer 0:
21Feb13_174602|-- Config --
21Feb13_174602|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174602|-- Weights --
21Feb13_174602|[[ 1.13034e+00 -5.53286e-01  1.06969e+00  6.04800e-01 -1.80344e+00
21Feb13_174602|   1.87998e-01]
21Feb13_174602| [-2.06086e-01 -1.17561e+00 -3.88209e-01 -1.23630e+00 -1.70580e-01
21Feb13_174602|  -4.93509e-01]
21Feb13_174602| [ 8.62255e-01  1.17018e+00 -1.49746e+00 -2.74330e-01 -9.97699e-01
21Feb13_174602|   1.06762e+00]
21Feb13_174602| [ 1.05284e+00 -1.09601e+00  2.23484e+00 -1.58443e+00 -7.08990e-01
21Feb13_174602|  -2.24847e-02]
21Feb13_174602| [-1.85392e-01  3.74849e-01 -9.28314e-01 -5.05116e-01  9.75807e-01
21Feb13_174602|   2.26265e-02]
21Feb13_174602| [ 5.53864e-01 -1.44701e-01 -2.78496e-01 -9.65915e-02 -4.66222e-01
21Feb13_174602|  -4.82200e-01]
21Feb13_174602| [-2.83744e-01  1.05014e+00  6.84434e-01  1.96472e-01  1.51780e+00
21Feb13_174602|  -1.43357e+00]
21Feb13_174602| [ 2.51787e-01  2.82378e+00  3.38266e-02  7.75067e-01 -7.71118e-01
21Feb13_174602|   1.01245e+00]
21Feb13_174602| [ 6.35048e-01 -1.31302e+00  1.58172e+00 -7.59300e-01  7.75194e-01
21Feb13_174602|   3.57667e-01]
21Feb13_174602| [ 1.55833e-02 -1.52513e-01  1.14441e+00  1.21641e+00  1.46095e+00
21Feb13_174602|  -1.97462e-01]
21Feb13_174602| [ 8.82940e-01  4.70981e-01  8.94543e-03  2.12770e+00 -4.73172e-02
21Feb13_174602|   2.49972e-01]
21Feb13_174602| [ 2.02733e+00 -5.44623e-01  5.59001e-03 -5.46488e-01 -2.93472e-01
21Feb13_174602|   7.41024e-02]
21Feb13_174602| [ 4.30996e-01 -3.44291e-01  5.03869e-01 -1.70903e-01  2.02710e+00
21Feb13_174602|   7.40481e-01]
21Feb13_174602| [-5.79992e-02 -3.52174e-02  6.19134e-01  6.75090e-01  5.62871e-03
21Feb13_174602|   4.08582e-01]
21Feb13_174602| [ 2.11756e+00 -1.41866e+00 -4.73399e-01 -8.55975e-01  2.50962e-01
21Feb13_174602|   3.88174e-01]
21Feb13_174602| [ 1.08338e+00  7.28871e-01 -8.79437e-01  3.81938e-01 -1.04980e-01
21Feb13_174602|   3.81630e-01]
21Feb13_174602| [ 3.05477e-01  2.96671e-01 -3.34109e-02  9.81726e-01  7.50611e-01
21Feb13_174602|   1.53923e-03]
21Feb13_174602| [-1.97136e+00  4.35535e-01 -3.41613e-01 -1.14664e+00  2.60336e+00
21Feb13_174602|   1.22123e-01]
21Feb13_174602| [-9.72294e-01 -1.31051e+00 -6.25687e-01 -1.01171e+00  3.20799e-01
21Feb13_174602|  -6.29617e-01]
21Feb13_174602| [ 3.89268e-01 -3.12905e-01 -3.24592e+00  3.19579e-01 -9.28448e-01
21Feb13_174602|  -4.49606e-01]
21Feb13_174602| [-1.23874e-01  2.54123e-01  1.52446e-01  2.93099e+00 -8.96749e-01
21Feb13_174602|  -6.47971e-01]
21Feb13_174602| [-1.80957e-01  6.75851e-01 -7.40387e-01 -2.44728e-01 -9.53669e-01
21Feb13_174602|   5.04709e-01]
21Feb13_174602| [ 4.18558e-01  8.80843e-01  1.64533e+00  4.24741e-02 -3.58074e-01
21Feb13_174602|   7.98441e-02]
21Feb13_174602| [-3.98428e-01 -1.79152e+00 -2.41090e+00 -1.41339e+00  7.43891e-01
21Feb13_174602|   3.09447e-01]
21Feb13_174602| [ 3.44250e-01 -1.54741e+00 -4.11403e-01  4.49406e-01 -2.66079e-01
21Feb13_174602|  -2.31925e-01]
21Feb13_174602| [ 2.23338e-02 -2.24281e-01  1.92970e+00 -1.50261e+00  1.34918e+00
21Feb13_174602|  -3.39176e-01]
21Feb13_174602| [ 8.00847e-01  1.20519e+00  1.69998e+00 -1.46682e+00  7.53415e-01
21Feb13_174602|  -3.78005e-01]
21Feb13_174602| [-1.15511e-01  3.70614e-01  5.57123e-01  2.68691e-01 -1.42742e+00
21Feb13_174602|  -1.93233e-01]
21Feb13_174602| [-6.62414e-01  1.08008e-01  7.05660e-01 -4.59772e-02 -1.30027e+00
21Feb13_174602|  -5.21610e-01]
21Feb13_174602| [ 1.66346e+00  5.86243e-01 -1.51876e-01  2.30012e-01 -3.58419e-01
21Feb13_174602|  -1.23990e-01]
21Feb13_174602| [ 1.61966e+00 -6.43844e-02 -5.68742e-01 -9.25386e-01  6.79694e-01
21Feb13_174602|  -2.93331e-01]
21Feb13_174602| [ 7.10363e-01 -1.44787e+00 -2.34484e-01 -4.37677e-01 -1.22538e+00
21Feb13_174602|   1.83002e-01]
21Feb13_174602| [ 2.14622e-01 -1.12925e+00 -5.15099e-01  9.37440e-01  5.26126e-01
21Feb13_174602|   5.19098e-01]
21Feb13_174602| [ 5.67954e-01  1.43059e-01 -1.06384e+00  9.05593e-01 -2.00117e+00
21Feb13_174602|   1.80507e+00]
21Feb13_174602| [ 7.80472e-01 -3.54113e-01 -1.20890e+00  2.77431e+00 -9.37215e-01
21Feb13_174602|   3.77714e-01]
21Feb13_174602| [ 9.01572e-01 -4.56129e-01  1.15429e+00 -1.66769e-01  8.62034e-01
21Feb13_174602|   4.58879e-01]
21Feb13_174602| [ 2.91961e+00 -2.86061e+00 -2.01106e-01 -1.16509e+00 -7.08412e-01
21Feb13_174602|   1.11489e-01]
21Feb13_174602| [ 1.72952e+00  1.57028e+00 -2.07455e+00  8.60966e-01  1.09806e-01
21Feb13_174602|  -1.87101e-01]
21Feb13_174602| [-1.26201e+00  1.05169e+00  5.94851e-01  1.01150e-01 -1.38611e+00
21Feb13_174602|   1.02119e-01]
21Feb13_174602| [-1.07746e-02  3.08677e-01  1.45140e+00  3.07728e-01 -3.03820e-01
21Feb13_174602|  -1.89218e-01]
21Feb13_174602| [ 2.88911e-01  6.61534e-01 -5.08244e-01 -1.42714e-01  8.10001e-02
21Feb13_174602|   1.24332e-01]
21Feb13_174602| [-1.32570e+00  1.66273e-01  1.53351e+00  1.48902e+00  1.52882e+00
21Feb13_174602|   5.31791e-01]
21Feb13_174602| [ 2.18605e+00  7.69662e-01 -5.86388e-01  5.94944e-01  3.36219e-01
21Feb13_174602|   1.04673e-01]
21Feb13_174602| [-1.26380e-01  5.38904e-02 -7.81064e-01 -5.99197e-01  1.32875e-01
21Feb13_174602|  -5.29580e-01]
21Feb13_174602| [-4.18577e-01 -3.05427e-01 -2.87218e-02  2.30080e-01 -4.63573e-01
21Feb13_174602|   1.02996e+00]
21Feb13_174602| [-7.58159e-02 -7.34967e-01 -2.89689e-01 -6.13321e-01  1.19156e+00
21Feb13_174602|   6.56374e-01]
21Feb13_174602| [ 4.42022e-02 -1.91843e-01  9.05626e-01 -7.47534e-01  1.88839e-01
21Feb13_174602|  -2.99682e-01]
21Feb13_174602| [ 9.98249e-01  7.67460e-01  5.60854e-01  1.00827e+00 -5.46571e-01
21Feb13_174602|   2.12347e-01]
21Feb13_174602| [-3.93190e-01 -5.15195e-01  2.43161e-01  1.08610e+00 -1.18163e+00
21Feb13_174602|   5.27352e-01]
21Feb13_174602| [-2.10995e+00 -4.58607e-01  1.02182e+00 -9.34708e-01 -1.61474e-01
21Feb13_174602|   5.21834e-01]
21Feb13_174602| [ 2.71710e-01  6.30733e-01 -2.12292e+00  2.44596e-02  2.19986e-01
21Feb13_174602|   2.64510e-01]
21Feb13_174602| [ 2.73506e+00 -1.68607e+00 -3.43628e-01  7.61628e-02 -2.26828e-01
21Feb13_174602|  -3.81731e-01]
21Feb13_174602| [ 5.23338e-02 -7.03002e-01 -1.03161e-01  9.49301e-01  1.27202e-01
21Feb13_174602|   6.50503e-01]
21Feb13_174602| [-1.12324e-01  1.94323e-01 -1.49900e+00  1.41035e-01 -1.16220e+00
21Feb13_174602|  -3.35985e-01]
21Feb13_174602| [ 8.70873e-01  7.43781e-01 -1.46105e+00  4.68759e-01 -6.68305e-01
21Feb13_174602|  -1.71642e-01]
21Feb13_174602| [-8.00266e-01 -1.06325e-01  7.65769e-01  1.72880e+00  1.90866e+00
21Feb13_174602|   1.16830e+00]
21Feb13_174602| [-3.71919e-01  1.04334e+00 -1.67330e+00 -5.96497e-01 -3.52827e-01
21Feb13_174602|  -7.28103e-03]]
21Feb13_174602|-- Bias --
21Feb13_174602|[ 1.71352  0.90911  0.47256 -0.01331  0.42218 -0.02646]
21Feb13_174602|Layer 1:
21Feb13_174602|-- Config --
21Feb13_174602|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174602|-- Weights --
21Feb13_174602|[[-0.99267 -0.97274  0.82405 -0.16977]
21Feb13_174602| [ 0.60239 -0.10238 -0.00496 -0.14288]
21Feb13_174602| [-0.11020  0.99493  0.79092 -0.16312]
21Feb13_174602| [ 0.55308 -0.37597 -1.28077 -0.67794]
21Feb13_174602| [ 0.99539  0.72798  0.47591  0.49305]
21Feb13_174602| [ 0.83623 -0.20924  0.30390  0.06038]]
21Feb13_174602|-- Bias --
21Feb13_174602|[-0.44854  0.57814 -0.25511  0.43911]
21Feb13_174602|Layer 2:
21Feb13_174602|-- Config --
21Feb13_174602|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174602|-- Weights --
21Feb13_174602|[[ 0.33441  0.48577]
21Feb13_174602| [-0.92058 -1.06244]
21Feb13_174602| [-0.40205  1.58320]
21Feb13_174602| [-0.58076 -0.11565]]
21Feb13_174602|-- Bias --
21Feb13_174602|[0.09744 0.58731]
21Feb13_174602|Predicting the validation and test data with the Best final individual.
21Feb13_174610| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_174610|-----------  ------------------  --------------------  ----------
21Feb13_174610|Validation         26.43                  20            0.57055
21Feb13_174610|   Test            29.97                  20            0.37792
21Feb13_174610|-------------------- Test #10 --------------------
21Feb13_174610|Best final individual weights
21Feb13_174610|Individual:
21Feb13_174610|-- Constant hidden layers --
21Feb13_174610|False
21Feb13_174610|Layer 0:
21Feb13_174610|-- Config --
21Feb13_174610|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174610|-- Weights --
21Feb13_174610|[[ 1.13034e+00 -5.53286e-01  1.06969e+00  6.04800e-01 -1.80344e+00
21Feb13_174610|   1.87998e-01]
21Feb13_174610| [-2.06086e-01 -1.17561e+00 -3.88209e-01 -1.23630e+00 -1.70580e-01
21Feb13_174610|  -4.93509e-01]
21Feb13_174610| [ 8.62255e-01  1.17018e+00 -1.49746e+00 -2.74330e-01 -9.97699e-01
21Feb13_174610|   1.06762e+00]
21Feb13_174610| [ 1.05284e+00 -1.09601e+00  2.23484e+00 -1.58443e+00 -7.08990e-01
21Feb13_174610|  -2.24847e-02]
21Feb13_174610| [-1.85392e-01  3.74849e-01 -9.28314e-01 -5.05116e-01  9.75807e-01
21Feb13_174610|   2.26265e-02]
21Feb13_174610| [ 5.53864e-01 -1.44701e-01 -2.78496e-01 -9.65915e-02 -4.66222e-01
21Feb13_174610|  -4.82200e-01]
21Feb13_174610| [-2.83744e-01  1.05014e+00  6.84434e-01  1.96472e-01  1.51780e+00
21Feb13_174610|  -1.43357e+00]
21Feb13_174610| [ 2.51787e-01  2.82378e+00  3.38266e-02  7.75067e-01 -7.71118e-01
21Feb13_174610|   1.01245e+00]
21Feb13_174610| [ 6.35048e-01 -1.31302e+00  1.58172e+00 -7.59300e-01  7.75194e-01
21Feb13_174610|   3.57667e-01]
21Feb13_174610| [ 1.55833e-02 -1.52513e-01  1.14441e+00  1.21641e+00  1.46095e+00
21Feb13_174610|  -1.97462e-01]
21Feb13_174610| [ 8.82940e-01  4.70981e-01  8.94543e-03  2.12770e+00 -4.73172e-02
21Feb13_174610|   2.49972e-01]
21Feb13_174610| [ 2.02733e+00 -5.44623e-01  5.59001e-03 -5.46488e-01 -2.93472e-01
21Feb13_174610|   7.41024e-02]
21Feb13_174610| [ 4.30996e-01 -3.44291e-01  5.03869e-01 -1.70903e-01  2.02710e+00
21Feb13_174610|   7.40481e-01]
21Feb13_174610| [-5.79992e-02 -3.52174e-02  6.19134e-01  6.75090e-01  5.62871e-03
21Feb13_174610|   4.08582e-01]
21Feb13_174610| [ 2.11756e+00 -1.41866e+00 -4.73399e-01 -8.55975e-01  2.50962e-01
21Feb13_174610|   3.88174e-01]
21Feb13_174610| [ 1.08338e+00  7.28871e-01 -8.79437e-01  3.81938e-01 -1.04980e-01
21Feb13_174610|   3.81630e-01]
21Feb13_174610| [ 3.05477e-01  2.96671e-01 -3.34109e-02  9.81726e-01  7.50611e-01
21Feb13_174610|   1.53923e-03]
21Feb13_174610| [-1.97136e+00  4.35535e-01 -3.41613e-01 -1.14664e+00  2.60336e+00
21Feb13_174610|   1.22123e-01]
21Feb13_174610| [-9.72294e-01 -1.31051e+00 -6.25687e-01 -1.01171e+00  3.20799e-01
21Feb13_174610|  -6.29617e-01]
21Feb13_174610| [ 3.89268e-01 -3.12905e-01 -3.24592e+00  3.19579e-01 -9.28448e-01
21Feb13_174610|  -4.49606e-01]
21Feb13_174610| [-1.23874e-01  2.54123e-01  1.52446e-01  2.93099e+00 -8.96749e-01
21Feb13_174610|  -6.47971e-01]
21Feb13_174610| [-1.80957e-01  6.75851e-01 -7.40387e-01 -2.44728e-01 -9.53669e-01
21Feb13_174610|   5.04709e-01]
21Feb13_174610| [ 4.18558e-01  8.80843e-01  1.64533e+00  4.24741e-02 -3.58074e-01
21Feb13_174610|   7.98441e-02]
21Feb13_174610| [-3.98428e-01 -1.79152e+00 -2.41090e+00 -1.41339e+00  7.43891e-01
21Feb13_174610|   3.09447e-01]
21Feb13_174610| [ 3.44250e-01 -1.54741e+00 -4.11403e-01  4.49406e-01 -2.66079e-01
21Feb13_174610|  -2.31925e-01]
21Feb13_174610| [ 2.23338e-02 -2.24281e-01  1.92970e+00 -1.50261e+00  1.34918e+00
21Feb13_174610|  -3.39176e-01]
21Feb13_174610| [ 8.00847e-01  1.20519e+00  1.69998e+00 -1.46682e+00  7.53415e-01
21Feb13_174610|  -3.78005e-01]
21Feb13_174610| [-1.15511e-01  3.70614e-01  5.57123e-01  2.68691e-01 -1.42742e+00
21Feb13_174610|  -1.93233e-01]
21Feb13_174610| [-6.62414e-01  1.08008e-01  7.05660e-01 -4.59772e-02 -1.30027e+00
21Feb13_174610|  -5.21610e-01]
21Feb13_174610| [ 1.66346e+00  5.86243e-01 -1.51876e-01  2.30012e-01 -3.58419e-01
21Feb13_174610|  -1.23990e-01]
21Feb13_174610| [ 1.61966e+00 -6.43844e-02 -5.68742e-01 -9.25386e-01  6.79694e-01
21Feb13_174610|  -2.93331e-01]
21Feb13_174610| [ 7.10363e-01 -1.44787e+00 -2.34484e-01 -4.37677e-01 -1.22538e+00
21Feb13_174610|   1.83002e-01]
21Feb13_174610| [ 2.14622e-01 -1.12925e+00 -5.15099e-01  9.37440e-01  5.26126e-01
21Feb13_174610|   5.19098e-01]
21Feb13_174610| [ 5.67954e-01  1.43059e-01 -1.06384e+00  9.05593e-01 -2.00117e+00
21Feb13_174610|   1.80507e+00]
21Feb13_174610| [ 7.80472e-01 -3.54113e-01 -1.20890e+00  2.77431e+00 -9.37215e-01
21Feb13_174610|   3.77714e-01]
21Feb13_174610| [ 9.01572e-01 -4.56129e-01  1.15429e+00 -1.66769e-01  8.62034e-01
21Feb13_174610|   4.58879e-01]
21Feb13_174610| [ 2.91961e+00 -2.86061e+00 -2.01106e-01 -1.16509e+00 -7.08412e-01
21Feb13_174610|   1.11489e-01]
21Feb13_174610| [ 1.72952e+00  1.57028e+00 -2.07455e+00  8.60966e-01  1.09806e-01
21Feb13_174610|  -1.87101e-01]
21Feb13_174610| [-1.26201e+00  1.05169e+00  5.94851e-01  1.01150e-01 -1.38611e+00
21Feb13_174610|   1.02119e-01]
21Feb13_174610| [-1.07746e-02  3.08677e-01  1.45140e+00  3.07728e-01 -3.03820e-01
21Feb13_174610|  -1.89218e-01]
21Feb13_174610| [ 2.88911e-01  6.61534e-01 -5.08244e-01 -1.42714e-01  8.10001e-02
21Feb13_174610|   1.24332e-01]
21Feb13_174610| [-1.32570e+00  1.66273e-01  1.53351e+00  1.48902e+00  1.52882e+00
21Feb13_174610|   5.31791e-01]
21Feb13_174610| [ 2.18605e+00  7.69662e-01 -5.86388e-01  5.94944e-01  3.36219e-01
21Feb13_174610|   1.04673e-01]
21Feb13_174610| [-1.26380e-01  5.38904e-02 -7.81064e-01 -5.99197e-01  1.32875e-01
21Feb13_174610|  -5.29580e-01]
21Feb13_174610| [-4.18577e-01 -3.05427e-01 -2.87218e-02  2.30080e-01 -4.63573e-01
21Feb13_174610|   1.02996e+00]
21Feb13_174610| [-7.58159e-02 -7.34967e-01 -2.89689e-01 -6.13321e-01  1.19156e+00
21Feb13_174610|   6.56374e-01]
21Feb13_174610| [ 4.42022e-02 -1.91843e-01  9.05626e-01 -7.47534e-01  1.88839e-01
21Feb13_174610|  -2.99682e-01]
21Feb13_174610| [ 9.98249e-01  7.67460e-01  5.60854e-01  1.00827e+00 -5.46571e-01
21Feb13_174610|   2.12347e-01]
21Feb13_174610| [-3.93190e-01 -5.15195e-01  2.43161e-01  1.08610e+00 -1.18163e+00
21Feb13_174610|   5.27352e-01]
21Feb13_174610| [-2.10995e+00 -4.58607e-01  1.02182e+00 -9.34708e-01 -1.61474e-01
21Feb13_174610|   5.21834e-01]
21Feb13_174610| [ 2.71710e-01  6.30733e-01 -2.12292e+00  2.44596e-02  2.19986e-01
21Feb13_174610|   2.64510e-01]
21Feb13_174610| [ 2.73506e+00 -1.68607e+00 -3.43628e-01  7.61628e-02 -2.26828e-01
21Feb13_174610|  -3.81731e-01]
21Feb13_174610| [ 5.23338e-02 -7.03002e-01 -1.03161e-01  9.49301e-01  1.27202e-01
21Feb13_174610|   6.50503e-01]
21Feb13_174610| [-1.12324e-01  1.94323e-01 -1.49900e+00  1.41035e-01 -1.16220e+00
21Feb13_174610|  -3.35985e-01]
21Feb13_174610| [ 8.70873e-01  7.43781e-01 -1.46105e+00  4.68759e-01 -6.68305e-01
21Feb13_174610|  -1.71642e-01]
21Feb13_174610| [-8.00266e-01 -1.06325e-01  7.65769e-01  1.72880e+00  1.90866e+00
21Feb13_174610|   1.16830e+00]
21Feb13_174610| [-3.71919e-01  1.04334e+00 -1.67330e+00 -5.96497e-01 -3.52827e-01
21Feb13_174610|  -7.28103e-03]]
21Feb13_174610|-- Bias --
21Feb13_174610|[ 1.71352  0.90911  0.47256 -0.01331  0.42218 -0.02646]
21Feb13_174610|Layer 1:
21Feb13_174610|-- Config --
21Feb13_174610|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174610|-- Weights --
21Feb13_174610|[[-0.99267 -0.97274  0.82405 -0.16977]
21Feb13_174610| [ 0.60239 -0.10238 -0.00496 -0.14288]
21Feb13_174610| [-0.11020  0.99493  0.79092 -0.16312]
21Feb13_174610| [ 0.55308 -0.37597 -1.28077 -0.67794]
21Feb13_174610| [ 0.99539  0.72798  0.47591  0.49305]
21Feb13_174610| [ 0.83623 -0.20924  0.30390  0.06038]]
21Feb13_174610|-- Bias --
21Feb13_174610|[-0.44854  0.57814 -0.25511  0.43911]
21Feb13_174610|Layer 2:
21Feb13_174610|-- Config --
21Feb13_174610|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174610|-- Weights --
21Feb13_174610|[[ 0.33441  0.48577]
21Feb13_174610| [-0.92058 -1.06244]
21Feb13_174610| [-0.40205  1.58320]
21Feb13_174610| [-0.58076 -0.11565]]
21Feb13_174610|-- Bias --
21Feb13_174610|[0.09744 0.58731]
21Feb13_174610|Predicting the validation and test data with the Best final individual.
21Feb13_174617| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_174617|-----------  ------------------  --------------------  ----------
21Feb13_174617|Validation         38.43                  20            0.00000
21Feb13_174617|   Test            39.44                  20            0.00000
21Feb13_174617|-------------------- Test #11 --------------------
21Feb13_174617|Best final individual weights
21Feb13_174617|Individual:
21Feb13_174617|-- Constant hidden layers --
21Feb13_174617|False
21Feb13_174617|Layer 0:
21Feb13_174617|-- Config --
21Feb13_174617|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174617|-- Weights --
21Feb13_174617|[[ 1.13034e+00 -5.53286e-01  1.06969e+00  6.04800e-01 -1.80344e+00
21Feb13_174617|   1.87998e-01]
21Feb13_174617| [-2.06086e-01 -1.17561e+00 -3.88209e-01 -1.23630e+00 -1.70580e-01
21Feb13_174617|  -4.93509e-01]
21Feb13_174617| [ 8.62255e-01  1.17018e+00 -1.49746e+00 -2.74330e-01 -9.97699e-01
21Feb13_174617|   1.06762e+00]
21Feb13_174617| [ 1.05284e+00 -1.09601e+00  2.23484e+00 -1.58443e+00 -7.08990e-01
21Feb13_174617|  -2.24847e-02]
21Feb13_174617| [-1.85392e-01  3.74849e-01 -9.28314e-01 -5.05116e-01  9.75807e-01
21Feb13_174617|   2.26265e-02]
21Feb13_174617| [ 5.53864e-01 -1.44701e-01 -2.78496e-01 -9.65915e-02 -4.66222e-01
21Feb13_174617|  -4.82200e-01]
21Feb13_174617| [-2.83744e-01  1.05014e+00  6.84434e-01  1.96472e-01  1.51780e+00
21Feb13_174617|  -1.43357e+00]
21Feb13_174617| [ 2.51787e-01  2.82378e+00  3.38266e-02  7.75067e-01 -7.71118e-01
21Feb13_174617|   1.01245e+00]
21Feb13_174617| [ 6.35048e-01 -1.31302e+00  1.58172e+00 -7.59300e-01  7.75194e-01
21Feb13_174617|   3.57667e-01]
21Feb13_174617| [ 1.55833e-02 -1.52513e-01  1.14441e+00  1.21641e+00  1.46095e+00
21Feb13_174617|  -1.97462e-01]
21Feb13_174617| [ 8.82940e-01  4.70981e-01  8.94543e-03  2.12770e+00 -4.73172e-02
21Feb13_174617|   2.49972e-01]
21Feb13_174617| [ 2.02733e+00 -5.44623e-01  5.59001e-03 -5.46488e-01 -2.93472e-01
21Feb13_174617|   7.41024e-02]
21Feb13_174617| [ 4.30996e-01 -3.44291e-01  5.03869e-01 -1.70903e-01  2.02710e+00
21Feb13_174617|   7.40481e-01]
21Feb13_174617| [-5.79992e-02 -3.52174e-02  6.19134e-01  6.75090e-01  5.62871e-03
21Feb13_174617|   4.08582e-01]
21Feb13_174617| [ 2.11756e+00 -1.41866e+00 -4.73399e-01 -8.55975e-01  2.50962e-01
21Feb13_174617|   3.88174e-01]
21Feb13_174617| [ 1.08338e+00  7.28871e-01 -8.79437e-01  3.81938e-01 -1.04980e-01
21Feb13_174617|   3.81630e-01]
21Feb13_174617| [ 3.05477e-01  2.96671e-01 -3.34109e-02  9.81726e-01  7.50611e-01
21Feb13_174617|   1.53923e-03]
21Feb13_174617| [-1.97136e+00  4.35535e-01 -3.41613e-01 -1.14664e+00  2.60336e+00
21Feb13_174617|   1.22123e-01]
21Feb13_174617| [-9.72294e-01 -1.31051e+00 -6.25687e-01 -1.01171e+00  3.20799e-01
21Feb13_174617|  -6.29617e-01]
21Feb13_174617| [ 3.89268e-01 -3.12905e-01 -3.24592e+00  3.19579e-01 -9.28448e-01
21Feb13_174617|  -4.49606e-01]
21Feb13_174617| [-1.23874e-01  2.54123e-01  1.52446e-01  2.93099e+00 -8.96749e-01
21Feb13_174617|  -6.47971e-01]
21Feb13_174617| [-1.80957e-01  6.75851e-01 -7.40387e-01 -2.44728e-01 -9.53669e-01
21Feb13_174617|   5.04709e-01]
21Feb13_174617| [ 4.18558e-01  8.80843e-01  1.64533e+00  4.24741e-02 -3.58074e-01
21Feb13_174617|   7.98441e-02]
21Feb13_174617| [-3.98428e-01 -1.79152e+00 -2.41090e+00 -1.41339e+00  7.43891e-01
21Feb13_174617|   3.09447e-01]
21Feb13_174617| [ 3.44250e-01 -1.54741e+00 -4.11403e-01  4.49406e-01 -2.66079e-01
21Feb13_174617|  -2.31925e-01]
21Feb13_174617| [ 2.23338e-02 -2.24281e-01  1.92970e+00 -1.50261e+00  1.34918e+00
21Feb13_174617|  -3.39176e-01]
21Feb13_174617| [ 8.00847e-01  1.20519e+00  1.69998e+00 -1.46682e+00  7.53415e-01
21Feb13_174617|  -3.78005e-01]
21Feb13_174617| [-1.15511e-01  3.70614e-01  5.57123e-01  2.68691e-01 -1.42742e+00
21Feb13_174617|  -1.93233e-01]
21Feb13_174617| [-6.62414e-01  1.08008e-01  7.05660e-01 -4.59772e-02 -1.30027e+00
21Feb13_174617|  -5.21610e-01]
21Feb13_174617| [ 1.66346e+00  5.86243e-01 -1.51876e-01  2.30012e-01 -3.58419e-01
21Feb13_174617|  -1.23990e-01]
21Feb13_174617| [ 1.61966e+00 -6.43844e-02 -5.68742e-01 -9.25386e-01  6.79694e-01
21Feb13_174617|  -2.93331e-01]
21Feb13_174617| [ 7.10363e-01 -1.44787e+00 -2.34484e-01 -4.37677e-01 -1.22538e+00
21Feb13_174617|   1.83002e-01]
21Feb13_174617| [ 2.14622e-01 -1.12925e+00 -5.15099e-01  9.37440e-01  5.26126e-01
21Feb13_174617|   5.19098e-01]
21Feb13_174617| [ 5.67954e-01  1.43059e-01 -1.06384e+00  9.05593e-01 -2.00117e+00
21Feb13_174617|   1.80507e+00]
21Feb13_174617| [ 7.80472e-01 -3.54113e-01 -1.20890e+00  2.77431e+00 -9.37215e-01
21Feb13_174617|   3.77714e-01]
21Feb13_174617| [ 9.01572e-01 -4.56129e-01  1.15429e+00 -1.66769e-01  8.62034e-01
21Feb13_174617|   4.58879e-01]
21Feb13_174617| [ 2.91961e+00 -2.86061e+00 -2.01106e-01 -1.16509e+00 -7.08412e-01
21Feb13_174617|   1.11489e-01]
21Feb13_174617| [ 1.72952e+00  1.57028e+00 -2.07455e+00  8.60966e-01  1.09806e-01
21Feb13_174617|  -1.87101e-01]
21Feb13_174617| [-1.26201e+00  1.05169e+00  5.94851e-01  1.01150e-01 -1.38611e+00
21Feb13_174617|   1.02119e-01]
21Feb13_174617| [-1.07746e-02  3.08677e-01  1.45140e+00  3.07728e-01 -3.03820e-01
21Feb13_174617|  -1.89218e-01]
21Feb13_174617| [ 2.88911e-01  6.61534e-01 -5.08244e-01 -1.42714e-01  8.10001e-02
21Feb13_174617|   1.24332e-01]
21Feb13_174617| [-1.32570e+00  1.66273e-01  1.53351e+00  1.48902e+00  1.52882e+00
21Feb13_174617|   5.31791e-01]
21Feb13_174617| [ 2.18605e+00  7.69662e-01 -5.86388e-01  5.94944e-01  3.36219e-01
21Feb13_174617|   1.04673e-01]
21Feb13_174617| [-1.26380e-01  5.38904e-02 -7.81064e-01 -5.99197e-01  1.32875e-01
21Feb13_174617|  -5.29580e-01]
21Feb13_174617| [-4.18577e-01 -3.05427e-01 -2.87218e-02  2.30080e-01 -4.63573e-01
21Feb13_174617|   1.02996e+00]
21Feb13_174617| [-7.58159e-02 -7.34967e-01 -2.89689e-01 -6.13321e-01  1.19156e+00
21Feb13_174617|   6.56374e-01]
21Feb13_174617| [ 4.42022e-02 -1.91843e-01  9.05626e-01 -7.47534e-01  1.88839e-01
21Feb13_174617|  -2.99682e-01]
21Feb13_174617| [ 9.98249e-01  7.67460e-01  5.60854e-01  1.00827e+00 -5.46571e-01
21Feb13_174617|   2.12347e-01]
21Feb13_174617| [-3.93190e-01 -5.15195e-01  2.43161e-01  1.08610e+00 -1.18163e+00
21Feb13_174617|   5.27352e-01]
21Feb13_174617| [-2.10995e+00 -4.58607e-01  1.02182e+00 -9.34708e-01 -1.61474e-01
21Feb13_174617|   5.21834e-01]
21Feb13_174617| [ 2.71710e-01  6.30733e-01 -2.12292e+00  2.44596e-02  2.19986e-01
21Feb13_174617|   2.64510e-01]
21Feb13_174617| [ 2.73506e+00 -1.68607e+00 -3.43628e-01  7.61628e-02 -2.26828e-01
21Feb13_174617|  -3.81731e-01]
21Feb13_174617| [ 5.23338e-02 -7.03002e-01 -1.03161e-01  9.49301e-01  1.27202e-01
21Feb13_174617|   6.50503e-01]
21Feb13_174617| [-1.12324e-01  1.94323e-01 -1.49900e+00  1.41035e-01 -1.16220e+00
21Feb13_174617|  -3.35985e-01]
21Feb13_174617| [ 8.70873e-01  7.43781e-01 -1.46105e+00  4.68759e-01 -6.68305e-01
21Feb13_174617|  -1.71642e-01]
21Feb13_174617| [-8.00266e-01 -1.06325e-01  7.65769e-01  1.72880e+00  1.90866e+00
21Feb13_174617|   1.16830e+00]
21Feb13_174617| [-3.71919e-01  1.04334e+00 -1.67330e+00 -5.96497e-01 -3.52827e-01
21Feb13_174617|  -7.28103e-03]]
21Feb13_174617|-- Bias --
21Feb13_174617|[ 1.71352  0.90911  0.47256 -0.01331  0.42218 -0.02646]
21Feb13_174617|Layer 1:
21Feb13_174617|-- Config --
21Feb13_174617|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174617|-- Weights --
21Feb13_174617|[[-0.99267 -0.97274  0.82405 -0.16977]
21Feb13_174617| [ 0.60239 -0.10238 -0.00496 -0.14288]
21Feb13_174617| [-0.11020  0.99493  0.79092 -0.16312]
21Feb13_174617| [ 0.55308 -0.37597 -1.28077 -0.67794]
21Feb13_174617| [ 0.99539  0.72798  0.47591  0.49305]
21Feb13_174617| [ 0.83623 -0.20924  0.30390  0.06038]]
21Feb13_174617|-- Bias --
21Feb13_174617|[-0.44854  0.57814 -0.25511  0.43911]
21Feb13_174617|Layer 2:
21Feb13_174617|-- Config --
21Feb13_174617|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174617|-- Weights --
21Feb13_174617|[[ 0.33441  0.48577]
21Feb13_174617| [-0.92058 -1.06244]
21Feb13_174617| [-0.40205  1.58320]
21Feb13_174617| [-0.58076 -0.11565]]
21Feb13_174617|-- Bias --
21Feb13_174617|[0.09744 0.58731]
21Feb13_174617|Predicting the validation and test data with the Best final individual.
21Feb13_174625| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_174625|-----------  ------------------  --------------------  ----------
21Feb13_174625|Validation         38.43                  20            0.00282
21Feb13_174625|   Test            39.53                  20            0.00000
21Feb13_174625|-------------------- Test #12 --------------------
21Feb13_174625|Best final individual weights
21Feb13_174625|Individual:
21Feb13_174625|-- Constant hidden layers --
21Feb13_174625|False
21Feb13_174625|Layer 0:
21Feb13_174625|-- Config --
21Feb13_174625|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174625|-- Weights --
21Feb13_174625|[[ 1.13034e+00 -5.53286e-01  1.06969e+00  6.04800e-01 -1.80344e+00
21Feb13_174625|   1.87998e-01]
21Feb13_174625| [-2.06086e-01 -1.17561e+00 -3.88209e-01 -1.23630e+00 -1.70580e-01
21Feb13_174625|  -4.93509e-01]
21Feb13_174625| [ 8.62255e-01  1.17018e+00 -1.49746e+00 -2.74330e-01 -9.97699e-01
21Feb13_174625|   1.06762e+00]
21Feb13_174625| [ 1.05284e+00 -1.09601e+00  2.23484e+00 -1.58443e+00 -7.08990e-01
21Feb13_174625|  -2.24847e-02]
21Feb13_174625| [-1.85392e-01  3.74849e-01 -9.28314e-01 -5.05116e-01  9.75807e-01
21Feb13_174625|   2.26265e-02]
21Feb13_174625| [ 5.53864e-01 -1.44701e-01 -2.78496e-01 -9.65915e-02 -4.66222e-01
21Feb13_174625|  -4.82200e-01]
21Feb13_174625| [-2.83744e-01  1.05014e+00  6.84434e-01  1.96472e-01  1.51780e+00
21Feb13_174625|  -1.43357e+00]
21Feb13_174625| [ 2.51787e-01  2.82378e+00  3.38266e-02  7.75067e-01 -7.71118e-01
21Feb13_174625|   1.01245e+00]
21Feb13_174625| [ 6.35048e-01 -1.31302e+00  1.58172e+00 -7.59300e-01  7.75194e-01
21Feb13_174625|   3.57667e-01]
21Feb13_174625| [ 1.55833e-02 -1.52513e-01  1.14441e+00  1.21641e+00  1.46095e+00
21Feb13_174625|  -1.97462e-01]
21Feb13_174625| [ 8.82940e-01  4.70981e-01  8.94543e-03  2.12770e+00 -4.73172e-02
21Feb13_174625|   2.49972e-01]
21Feb13_174625| [ 2.02733e+00 -5.44623e-01  5.59001e-03 -5.46488e-01 -2.93472e-01
21Feb13_174625|   7.41024e-02]
21Feb13_174625| [ 4.30996e-01 -3.44291e-01  5.03869e-01 -1.70903e-01  2.02710e+00
21Feb13_174625|   7.40481e-01]
21Feb13_174625| [-5.79992e-02 -3.52174e-02  6.19134e-01  6.75090e-01  5.62871e-03
21Feb13_174625|   4.08582e-01]
21Feb13_174625| [ 2.11756e+00 -1.41866e+00 -4.73399e-01 -8.55975e-01  2.50962e-01
21Feb13_174625|   3.88174e-01]
21Feb13_174625| [ 1.08338e+00  7.28871e-01 -8.79437e-01  3.81938e-01 -1.04980e-01
21Feb13_174625|   3.81630e-01]
21Feb13_174625| [ 3.05477e-01  2.96671e-01 -3.34109e-02  9.81726e-01  7.50611e-01
21Feb13_174625|   1.53923e-03]
21Feb13_174625| [-1.97136e+00  4.35535e-01 -3.41613e-01 -1.14664e+00  2.60336e+00
21Feb13_174625|   1.22123e-01]
21Feb13_174625| [-9.72294e-01 -1.31051e+00 -6.25687e-01 -1.01171e+00  3.20799e-01
21Feb13_174625|  -6.29617e-01]
21Feb13_174625| [ 3.89268e-01 -3.12905e-01 -3.24592e+00  3.19579e-01 -9.28448e-01
21Feb13_174625|  -4.49606e-01]
21Feb13_174625| [-1.23874e-01  2.54123e-01  1.52446e-01  2.93099e+00 -8.96749e-01
21Feb13_174625|  -6.47971e-01]
21Feb13_174625| [-1.80957e-01  6.75851e-01 -7.40387e-01 -2.44728e-01 -9.53669e-01
21Feb13_174625|   5.04709e-01]
21Feb13_174625| [ 4.18558e-01  8.80843e-01  1.64533e+00  4.24741e-02 -3.58074e-01
21Feb13_174625|   7.98441e-02]
21Feb13_174625| [-3.98428e-01 -1.79152e+00 -2.41090e+00 -1.41339e+00  7.43891e-01
21Feb13_174625|   3.09447e-01]
21Feb13_174625| [ 3.44250e-01 -1.54741e+00 -4.11403e-01  4.49406e-01 -2.66079e-01
21Feb13_174625|  -2.31925e-01]
21Feb13_174625| [ 2.23338e-02 -2.24281e-01  1.92970e+00 -1.50261e+00  1.34918e+00
21Feb13_174625|  -3.39176e-01]
21Feb13_174625| [ 8.00847e-01  1.20519e+00  1.69998e+00 -1.46682e+00  7.53415e-01
21Feb13_174625|  -3.78005e-01]
21Feb13_174625| [-1.15511e-01  3.70614e-01  5.57123e-01  2.68691e-01 -1.42742e+00
21Feb13_174625|  -1.93233e-01]
21Feb13_174625| [-6.62414e-01  1.08008e-01  7.05660e-01 -4.59772e-02 -1.30027e+00
21Feb13_174625|  -5.21610e-01]
21Feb13_174625| [ 1.66346e+00  5.86243e-01 -1.51876e-01  2.30012e-01 -3.58419e-01
21Feb13_174625|  -1.23990e-01]
21Feb13_174625| [ 1.61966e+00 -6.43844e-02 -5.68742e-01 -9.25386e-01  6.79694e-01
21Feb13_174625|  -2.93331e-01]
21Feb13_174625| [ 7.10363e-01 -1.44787e+00 -2.34484e-01 -4.37677e-01 -1.22538e+00
21Feb13_174625|   1.83002e-01]
21Feb13_174625| [ 2.14622e-01 -1.12925e+00 -5.15099e-01  9.37440e-01  5.26126e-01
21Feb13_174625|   5.19098e-01]
21Feb13_174625| [ 5.67954e-01  1.43059e-01 -1.06384e+00  9.05593e-01 -2.00117e+00
21Feb13_174625|   1.80507e+00]
21Feb13_174625| [ 7.80472e-01 -3.54113e-01 -1.20890e+00  2.77431e+00 -9.37215e-01
21Feb13_174625|   3.77714e-01]
21Feb13_174625| [ 9.01572e-01 -4.56129e-01  1.15429e+00 -1.66769e-01  8.62034e-01
21Feb13_174625|   4.58879e-01]
21Feb13_174625| [ 2.91961e+00 -2.86061e+00 -2.01106e-01 -1.16509e+00 -7.08412e-01
21Feb13_174625|   1.11489e-01]
21Feb13_174625| [ 1.72952e+00  1.57028e+00 -2.07455e+00  8.60966e-01  1.09806e-01
21Feb13_174625|  -1.87101e-01]
21Feb13_174625| [-1.26201e+00  1.05169e+00  5.94851e-01  1.01150e-01 -1.38611e+00
21Feb13_174625|   1.02119e-01]
21Feb13_174625| [-1.07746e-02  3.08677e-01  1.45140e+00  3.07728e-01 -3.03820e-01
21Feb13_174625|  -1.89218e-01]
21Feb13_174625| [ 2.88911e-01  6.61534e-01 -5.08244e-01 -1.42714e-01  8.10001e-02
21Feb13_174625|   1.24332e-01]
21Feb13_174625| [-1.32570e+00  1.66273e-01  1.53351e+00  1.48902e+00  1.52882e+00
21Feb13_174625|   5.31791e-01]
21Feb13_174625| [ 2.18605e+00  7.69662e-01 -5.86388e-01  5.94944e-01  3.36219e-01
21Feb13_174625|   1.04673e-01]
21Feb13_174625| [-1.26380e-01  5.38904e-02 -7.81064e-01 -5.99197e-01  1.32875e-01
21Feb13_174625|  -5.29580e-01]
21Feb13_174625| [-4.18577e-01 -3.05427e-01 -2.87218e-02  2.30080e-01 -4.63573e-01
21Feb13_174625|   1.02996e+00]
21Feb13_174625| [-7.58159e-02 -7.34967e-01 -2.89689e-01 -6.13321e-01  1.19156e+00
21Feb13_174625|   6.56374e-01]
21Feb13_174625| [ 4.42022e-02 -1.91843e-01  9.05626e-01 -7.47534e-01  1.88839e-01
21Feb13_174625|  -2.99682e-01]
21Feb13_174625| [ 9.98249e-01  7.67460e-01  5.60854e-01  1.00827e+00 -5.46571e-01
21Feb13_174625|   2.12347e-01]
21Feb13_174625| [-3.93190e-01 -5.15195e-01  2.43161e-01  1.08610e+00 -1.18163e+00
21Feb13_174625|   5.27352e-01]
21Feb13_174625| [-2.10995e+00 -4.58607e-01  1.02182e+00 -9.34708e-01 -1.61474e-01
21Feb13_174625|   5.21834e-01]
21Feb13_174625| [ 2.71710e-01  6.30733e-01 -2.12292e+00  2.44596e-02  2.19986e-01
21Feb13_174625|   2.64510e-01]
21Feb13_174625| [ 2.73506e+00 -1.68607e+00 -3.43628e-01  7.61628e-02 -2.26828e-01
21Feb13_174625|  -3.81731e-01]
21Feb13_174625| [ 5.23338e-02 -7.03002e-01 -1.03161e-01  9.49301e-01  1.27202e-01
21Feb13_174625|   6.50503e-01]
21Feb13_174625| [-1.12324e-01  1.94323e-01 -1.49900e+00  1.41035e-01 -1.16220e+00
21Feb13_174625|  -3.35985e-01]
21Feb13_174625| [ 8.70873e-01  7.43781e-01 -1.46105e+00  4.68759e-01 -6.68305e-01
21Feb13_174625|  -1.71642e-01]
21Feb13_174625| [-8.00266e-01 -1.06325e-01  7.65769e-01  1.72880e+00  1.90866e+00
21Feb13_174625|   1.16830e+00]
21Feb13_174625| [-3.71919e-01  1.04334e+00 -1.67330e+00 -5.96497e-01 -3.52827e-01
21Feb13_174625|  -7.28103e-03]]
21Feb13_174625|-- Bias --
21Feb13_174625|[ 1.71352  0.90911  0.47256 -0.01331  0.42218 -0.02646]
21Feb13_174625|Layer 1:
21Feb13_174625|-- Config --
21Feb13_174625|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174625|-- Weights --
21Feb13_174625|[[-0.99267 -0.97274  0.82405 -0.16977]
21Feb13_174625| [ 0.60239 -0.10238 -0.00496 -0.14288]
21Feb13_174625| [-0.11020  0.99493  0.79092 -0.16312]
21Feb13_174625| [ 0.55308 -0.37597 -1.28077 -0.67794]
21Feb13_174625| [ 0.99539  0.72798  0.47591  0.49305]
21Feb13_174625| [ 0.83623 -0.20924  0.30390  0.06038]]
21Feb13_174625|-- Bias --
21Feb13_174625|[-0.44854  0.57814 -0.25511  0.43911]
21Feb13_174625|Layer 2:
21Feb13_174625|-- Config --
21Feb13_174625|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174625|-- Weights --
21Feb13_174625|[[ 0.33441  0.48577]
21Feb13_174625| [-0.92058 -1.06244]
21Feb13_174625| [-0.40205  1.58320]
21Feb13_174625| [-0.58076 -0.11565]]
21Feb13_174625|-- Bias --
21Feb13_174625|[0.09744 0.58731]
21Feb13_174625|Predicting the validation and test data with the Best final individual.
21Feb13_174632| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_174632|-----------  ------------------  --------------------  ----------
21Feb13_174632|Validation         38.35                  20            0.00565
21Feb13_174632|   Test            30.58                  20            0.34890
21Feb13_174632|-------------------- Test #13 --------------------
21Feb13_174632|Best final individual weights
21Feb13_174632|Individual:
21Feb13_174632|-- Constant hidden layers --
21Feb13_174632|False
21Feb13_174632|Layer 0:
21Feb13_174632|-- Config --
21Feb13_174632|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174632|-- Weights --
21Feb13_174632|[[ 1.13034e+00 -5.53286e-01  1.06969e+00  6.04800e-01 -1.80344e+00
21Feb13_174632|   1.87998e-01]
21Feb13_174632| [-2.06086e-01 -1.17561e+00 -3.88209e-01 -1.23630e+00 -1.70580e-01
21Feb13_174632|  -4.93509e-01]
21Feb13_174632| [ 8.62255e-01  1.17018e+00 -1.49746e+00 -2.74330e-01 -9.97699e-01
21Feb13_174632|   1.06762e+00]
21Feb13_174632| [ 1.05284e+00 -1.09601e+00  2.23484e+00 -1.58443e+00 -7.08990e-01
21Feb13_174632|  -2.24847e-02]
21Feb13_174632| [-1.85392e-01  3.74849e-01 -9.28314e-01 -5.05116e-01  9.75807e-01
21Feb13_174632|   2.26265e-02]
21Feb13_174632| [ 5.53864e-01 -1.44701e-01 -2.78496e-01 -9.65915e-02 -4.66222e-01
21Feb13_174632|  -4.82200e-01]
21Feb13_174632| [-2.83744e-01  1.05014e+00  6.84434e-01  1.96472e-01  1.51780e+00
21Feb13_174632|  -1.43357e+00]
21Feb13_174632| [ 2.51787e-01  2.82378e+00  3.38266e-02  7.75067e-01 -7.71118e-01
21Feb13_174632|   1.01245e+00]
21Feb13_174632| [ 6.35048e-01 -1.31302e+00  1.58172e+00 -7.59300e-01  7.75194e-01
21Feb13_174632|   3.57667e-01]
21Feb13_174632| [ 1.55833e-02 -1.52513e-01  1.14441e+00  1.21641e+00  1.46095e+00
21Feb13_174632|  -1.97462e-01]
21Feb13_174632| [ 8.82940e-01  4.70981e-01  8.94543e-03  2.12770e+00 -4.73172e-02
21Feb13_174632|   2.49972e-01]
21Feb13_174632| [ 2.02733e+00 -5.44623e-01  5.59001e-03 -5.46488e-01 -2.93472e-01
21Feb13_174632|   7.41024e-02]
21Feb13_174632| [ 4.30996e-01 -3.44291e-01  5.03869e-01 -1.70903e-01  2.02710e+00
21Feb13_174632|   7.40481e-01]
21Feb13_174632| [-5.79992e-02 -3.52174e-02  6.19134e-01  6.75090e-01  5.62871e-03
21Feb13_174632|   4.08582e-01]
21Feb13_174632| [ 2.11756e+00 -1.41866e+00 -4.73399e-01 -8.55975e-01  2.50962e-01
21Feb13_174632|   3.88174e-01]
21Feb13_174632| [ 1.08338e+00  7.28871e-01 -8.79437e-01  3.81938e-01 -1.04980e-01
21Feb13_174632|   3.81630e-01]
21Feb13_174632| [ 3.05477e-01  2.96671e-01 -3.34109e-02  9.81726e-01  7.50611e-01
21Feb13_174632|   1.53923e-03]
21Feb13_174632| [-1.97136e+00  4.35535e-01 -3.41613e-01 -1.14664e+00  2.60336e+00
21Feb13_174632|   1.22123e-01]
21Feb13_174632| [-9.72294e-01 -1.31051e+00 -6.25687e-01 -1.01171e+00  3.20799e-01
21Feb13_174632|  -6.29617e-01]
21Feb13_174632| [ 3.89268e-01 -3.12905e-01 -3.24592e+00  3.19579e-01 -9.28448e-01
21Feb13_174632|  -4.49606e-01]
21Feb13_174632| [-1.23874e-01  2.54123e-01  1.52446e-01  2.93099e+00 -8.96749e-01
21Feb13_174632|  -6.47971e-01]
21Feb13_174632| [-1.80957e-01  6.75851e-01 -7.40387e-01 -2.44728e-01 -9.53669e-01
21Feb13_174632|   5.04709e-01]
21Feb13_174632| [ 4.18558e-01  8.80843e-01  1.64533e+00  4.24741e-02 -3.58074e-01
21Feb13_174632|   7.98441e-02]
21Feb13_174632| [-3.98428e-01 -1.79152e+00 -2.41090e+00 -1.41339e+00  7.43891e-01
21Feb13_174632|   3.09447e-01]
21Feb13_174632| [ 3.44250e-01 -1.54741e+00 -4.11403e-01  4.49406e-01 -2.66079e-01
21Feb13_174632|  -2.31925e-01]
21Feb13_174632| [ 2.23338e-02 -2.24281e-01  1.92970e+00 -1.50261e+00  1.34918e+00
21Feb13_174632|  -3.39176e-01]
21Feb13_174632| [ 8.00847e-01  1.20519e+00  1.69998e+00 -1.46682e+00  7.53415e-01
21Feb13_174632|  -3.78005e-01]
21Feb13_174632| [-1.15511e-01  3.70614e-01  5.57123e-01  2.68691e-01 -1.42742e+00
21Feb13_174632|  -1.93233e-01]
21Feb13_174632| [-6.62414e-01  1.08008e-01  7.05660e-01 -4.59772e-02 -1.30027e+00
21Feb13_174632|  -5.21610e-01]
21Feb13_174632| [ 1.66346e+00  5.86243e-01 -1.51876e-01  2.30012e-01 -3.58419e-01
21Feb13_174632|  -1.23990e-01]
21Feb13_174632| [ 1.61966e+00 -6.43844e-02 -5.68742e-01 -9.25386e-01  6.79694e-01
21Feb13_174632|  -2.93331e-01]
21Feb13_174632| [ 7.10363e-01 -1.44787e+00 -2.34484e-01 -4.37677e-01 -1.22538e+00
21Feb13_174632|   1.83002e-01]
21Feb13_174632| [ 2.14622e-01 -1.12925e+00 -5.15099e-01  9.37440e-01  5.26126e-01
21Feb13_174632|   5.19098e-01]
21Feb13_174632| [ 5.67954e-01  1.43059e-01 -1.06384e+00  9.05593e-01 -2.00117e+00
21Feb13_174632|   1.80507e+00]
21Feb13_174632| [ 7.80472e-01 -3.54113e-01 -1.20890e+00  2.77431e+00 -9.37215e-01
21Feb13_174632|   3.77714e-01]
21Feb13_174632| [ 9.01572e-01 -4.56129e-01  1.15429e+00 -1.66769e-01  8.62034e-01
21Feb13_174632|   4.58879e-01]
21Feb13_174632| [ 2.91961e+00 -2.86061e+00 -2.01106e-01 -1.16509e+00 -7.08412e-01
21Feb13_174632|   1.11489e-01]
21Feb13_174632| [ 1.72952e+00  1.57028e+00 -2.07455e+00  8.60966e-01  1.09806e-01
21Feb13_174632|  -1.87101e-01]
21Feb13_174632| [-1.26201e+00  1.05169e+00  5.94851e-01  1.01150e-01 -1.38611e+00
21Feb13_174632|   1.02119e-01]
21Feb13_174632| [-1.07746e-02  3.08677e-01  1.45140e+00  3.07728e-01 -3.03820e-01
21Feb13_174632|  -1.89218e-01]
21Feb13_174632| [ 2.88911e-01  6.61534e-01 -5.08244e-01 -1.42714e-01  8.10001e-02
21Feb13_174632|   1.24332e-01]
21Feb13_174632| [-1.32570e+00  1.66273e-01  1.53351e+00  1.48902e+00  1.52882e+00
21Feb13_174632|   5.31791e-01]
21Feb13_174632| [ 2.18605e+00  7.69662e-01 -5.86388e-01  5.94944e-01  3.36219e-01
21Feb13_174632|   1.04673e-01]
21Feb13_174632| [-1.26380e-01  5.38904e-02 -7.81064e-01 -5.99197e-01  1.32875e-01
21Feb13_174632|  -5.29580e-01]
21Feb13_174632| [-4.18577e-01 -3.05427e-01 -2.87218e-02  2.30080e-01 -4.63573e-01
21Feb13_174632|   1.02996e+00]
21Feb13_174632| [-7.58159e-02 -7.34967e-01 -2.89689e-01 -6.13321e-01  1.19156e+00
21Feb13_174632|   6.56374e-01]
21Feb13_174632| [ 4.42022e-02 -1.91843e-01  9.05626e-01 -7.47534e-01  1.88839e-01
21Feb13_174632|  -2.99682e-01]
21Feb13_174632| [ 9.98249e-01  7.67460e-01  5.60854e-01  1.00827e+00 -5.46571e-01
21Feb13_174632|   2.12347e-01]
21Feb13_174632| [-3.93190e-01 -5.15195e-01  2.43161e-01  1.08610e+00 -1.18163e+00
21Feb13_174632|   5.27352e-01]
21Feb13_174632| [-2.10995e+00 -4.58607e-01  1.02182e+00 -9.34708e-01 -1.61474e-01
21Feb13_174632|   5.21834e-01]
21Feb13_174632| [ 2.71710e-01  6.30733e-01 -2.12292e+00  2.44596e-02  2.19986e-01
21Feb13_174632|   2.64510e-01]
21Feb13_174632| [ 2.73506e+00 -1.68607e+00 -3.43628e-01  7.61628e-02 -2.26828e-01
21Feb13_174632|  -3.81731e-01]
21Feb13_174632| [ 5.23338e-02 -7.03002e-01 -1.03161e-01  9.49301e-01  1.27202e-01
21Feb13_174632|   6.50503e-01]
21Feb13_174632| [-1.12324e-01  1.94323e-01 -1.49900e+00  1.41035e-01 -1.16220e+00
21Feb13_174632|  -3.35985e-01]
21Feb13_174632| [ 8.70873e-01  7.43781e-01 -1.46105e+00  4.68759e-01 -6.68305e-01
21Feb13_174632|  -1.71642e-01]
21Feb13_174632| [-8.00266e-01 -1.06325e-01  7.65769e-01  1.72880e+00  1.90866e+00
21Feb13_174632|   1.16830e+00]
21Feb13_174632| [-3.71919e-01  1.04334e+00 -1.67330e+00 -5.96497e-01 -3.52827e-01
21Feb13_174632|  -7.28103e-03]]
21Feb13_174632|-- Bias --
21Feb13_174632|[ 1.71352  0.90911  0.47256 -0.01331  0.42218 -0.02646]
21Feb13_174632|Layer 1:
21Feb13_174632|-- Config --
21Feb13_174632|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174632|-- Weights --
21Feb13_174632|[[-0.99267 -0.97274  0.82405 -0.16977]
21Feb13_174632| [ 0.60239 -0.10238 -0.00496 -0.14288]
21Feb13_174632| [-0.11020  0.99493  0.79092 -0.16312]
21Feb13_174632| [ 0.55308 -0.37597 -1.28077 -0.67794]
21Feb13_174632| [ 0.99539  0.72798  0.47591  0.49305]
21Feb13_174632| [ 0.83623 -0.20924  0.30390  0.06038]]
21Feb13_174632|-- Bias --
21Feb13_174632|[-0.44854  0.57814 -0.25511  0.43911]
21Feb13_174632|Layer 2:
21Feb13_174632|-- Config --
21Feb13_174632|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174632|-- Weights --
21Feb13_174632|[[ 0.33441  0.48577]
21Feb13_174632| [-0.92058 -1.06244]
21Feb13_174632| [-0.40205  1.58320]
21Feb13_174632| [-0.58076 -0.11565]]
21Feb13_174632|-- Bias --
21Feb13_174632|[0.09744 0.58731]
21Feb13_174632|Predicting the validation and test data with the Best final individual.
21Feb13_174640| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_174640|-----------  ------------------  --------------------  ----------
21Feb13_174640|Validation         38.52                  20            0.00000
21Feb13_174640|   Test            29.97                  20            0.35229
21Feb13_174640|-------------------- Test #14 --------------------
21Feb13_174640|Best final individual weights
21Feb13_174640|Individual:
21Feb13_174640|-- Constant hidden layers --
21Feb13_174640|False
21Feb13_174640|Layer 0:
21Feb13_174640|-- Config --
21Feb13_174640|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174640|-- Weights --
21Feb13_174640|[[ 1.13034e+00 -5.53286e-01  1.06969e+00  6.04800e-01 -1.80344e+00
21Feb13_174640|   1.87998e-01]
21Feb13_174640| [-2.06086e-01 -1.17561e+00 -3.88209e-01 -1.23630e+00 -1.70580e-01
21Feb13_174640|  -4.93509e-01]
21Feb13_174640| [ 8.62255e-01  1.17018e+00 -1.49746e+00 -2.74330e-01 -9.97699e-01
21Feb13_174640|   1.06762e+00]
21Feb13_174640| [ 1.05284e+00 -1.09601e+00  2.23484e+00 -1.58443e+00 -7.08990e-01
21Feb13_174640|  -2.24847e-02]
21Feb13_174640| [-1.85392e-01  3.74849e-01 -9.28314e-01 -5.05116e-01  9.75807e-01
21Feb13_174640|   2.26265e-02]
21Feb13_174640| [ 5.53864e-01 -1.44701e-01 -2.78496e-01 -9.65915e-02 -4.66222e-01
21Feb13_174640|  -4.82200e-01]
21Feb13_174640| [-2.83744e-01  1.05014e+00  6.84434e-01  1.96472e-01  1.51780e+00
21Feb13_174640|  -1.43357e+00]
21Feb13_174640| [ 2.51787e-01  2.82378e+00  3.38266e-02  7.75067e-01 -7.71118e-01
21Feb13_174640|   1.01245e+00]
21Feb13_174640| [ 6.35048e-01 -1.31302e+00  1.58172e+00 -7.59300e-01  7.75194e-01
21Feb13_174640|   3.57667e-01]
21Feb13_174640| [ 1.55833e-02 -1.52513e-01  1.14441e+00  1.21641e+00  1.46095e+00
21Feb13_174640|  -1.97462e-01]
21Feb13_174640| [ 8.82940e-01  4.70981e-01  8.94543e-03  2.12770e+00 -4.73172e-02
21Feb13_174640|   2.49972e-01]
21Feb13_174640| [ 2.02733e+00 -5.44623e-01  5.59001e-03 -5.46488e-01 -2.93472e-01
21Feb13_174640|   7.41024e-02]
21Feb13_174640| [ 4.30996e-01 -3.44291e-01  5.03869e-01 -1.70903e-01  2.02710e+00
21Feb13_174640|   7.40481e-01]
21Feb13_174640| [-5.79992e-02 -3.52174e-02  6.19134e-01  6.75090e-01  5.62871e-03
21Feb13_174640|   4.08582e-01]
21Feb13_174640| [ 2.11756e+00 -1.41866e+00 -4.73399e-01 -8.55975e-01  2.50962e-01
21Feb13_174640|   3.88174e-01]
21Feb13_174640| [ 1.08338e+00  7.28871e-01 -8.79437e-01  3.81938e-01 -1.04980e-01
21Feb13_174640|   3.81630e-01]
21Feb13_174640| [ 3.05477e-01  2.96671e-01 -3.34109e-02  9.81726e-01  7.50611e-01
21Feb13_174640|   1.53923e-03]
21Feb13_174640| [-1.97136e+00  4.35535e-01 -3.41613e-01 -1.14664e+00  2.60336e+00
21Feb13_174640|   1.22123e-01]
21Feb13_174640| [-9.72294e-01 -1.31051e+00 -6.25687e-01 -1.01171e+00  3.20799e-01
21Feb13_174640|  -6.29617e-01]
21Feb13_174640| [ 3.89268e-01 -3.12905e-01 -3.24592e+00  3.19579e-01 -9.28448e-01
21Feb13_174640|  -4.49606e-01]
21Feb13_174640| [-1.23874e-01  2.54123e-01  1.52446e-01  2.93099e+00 -8.96749e-01
21Feb13_174640|  -6.47971e-01]
21Feb13_174640| [-1.80957e-01  6.75851e-01 -7.40387e-01 -2.44728e-01 -9.53669e-01
21Feb13_174640|   5.04709e-01]
21Feb13_174640| [ 4.18558e-01  8.80843e-01  1.64533e+00  4.24741e-02 -3.58074e-01
21Feb13_174640|   7.98441e-02]
21Feb13_174640| [-3.98428e-01 -1.79152e+00 -2.41090e+00 -1.41339e+00  7.43891e-01
21Feb13_174640|   3.09447e-01]
21Feb13_174640| [ 3.44250e-01 -1.54741e+00 -4.11403e-01  4.49406e-01 -2.66079e-01
21Feb13_174640|  -2.31925e-01]
21Feb13_174640| [ 2.23338e-02 -2.24281e-01  1.92970e+00 -1.50261e+00  1.34918e+00
21Feb13_174640|  -3.39176e-01]
21Feb13_174640| [ 8.00847e-01  1.20519e+00  1.69998e+00 -1.46682e+00  7.53415e-01
21Feb13_174640|  -3.78005e-01]
21Feb13_174640| [-1.15511e-01  3.70614e-01  5.57123e-01  2.68691e-01 -1.42742e+00
21Feb13_174640|  -1.93233e-01]
21Feb13_174640| [-6.62414e-01  1.08008e-01  7.05660e-01 -4.59772e-02 -1.30027e+00
21Feb13_174640|  -5.21610e-01]
21Feb13_174640| [ 1.66346e+00  5.86243e-01 -1.51876e-01  2.30012e-01 -3.58419e-01
21Feb13_174640|  -1.23990e-01]
21Feb13_174640| [ 1.61966e+00 -6.43844e-02 -5.68742e-01 -9.25386e-01  6.79694e-01
21Feb13_174640|  -2.93331e-01]
21Feb13_174640| [ 7.10363e-01 -1.44787e+00 -2.34484e-01 -4.37677e-01 -1.22538e+00
21Feb13_174640|   1.83002e-01]
21Feb13_174640| [ 2.14622e-01 -1.12925e+00 -5.15099e-01  9.37440e-01  5.26126e-01
21Feb13_174640|   5.19098e-01]
21Feb13_174640| [ 5.67954e-01  1.43059e-01 -1.06384e+00  9.05593e-01 -2.00117e+00
21Feb13_174640|   1.80507e+00]
21Feb13_174640| [ 7.80472e-01 -3.54113e-01 -1.20890e+00  2.77431e+00 -9.37215e-01
21Feb13_174640|   3.77714e-01]
21Feb13_174640| [ 9.01572e-01 -4.56129e-01  1.15429e+00 -1.66769e-01  8.62034e-01
21Feb13_174640|   4.58879e-01]
21Feb13_174640| [ 2.91961e+00 -2.86061e+00 -2.01106e-01 -1.16509e+00 -7.08412e-01
21Feb13_174640|   1.11489e-01]
21Feb13_174640| [ 1.72952e+00  1.57028e+00 -2.07455e+00  8.60966e-01  1.09806e-01
21Feb13_174640|  -1.87101e-01]
21Feb13_174640| [-1.26201e+00  1.05169e+00  5.94851e-01  1.01150e-01 -1.38611e+00
21Feb13_174640|   1.02119e-01]
21Feb13_174640| [-1.07746e-02  3.08677e-01  1.45140e+00  3.07728e-01 -3.03820e-01
21Feb13_174640|  -1.89218e-01]
21Feb13_174640| [ 2.88911e-01  6.61534e-01 -5.08244e-01 -1.42714e-01  8.10001e-02
21Feb13_174640|   1.24332e-01]
21Feb13_174640| [-1.32570e+00  1.66273e-01  1.53351e+00  1.48902e+00  1.52882e+00
21Feb13_174640|   5.31791e-01]
21Feb13_174640| [ 2.18605e+00  7.69662e-01 -5.86388e-01  5.94944e-01  3.36219e-01
21Feb13_174640|   1.04673e-01]
21Feb13_174640| [-1.26380e-01  5.38904e-02 -7.81064e-01 -5.99197e-01  1.32875e-01
21Feb13_174640|  -5.29580e-01]
21Feb13_174640| [-4.18577e-01 -3.05427e-01 -2.87218e-02  2.30080e-01 -4.63573e-01
21Feb13_174640|   1.02996e+00]
21Feb13_174640| [-7.58159e-02 -7.34967e-01 -2.89689e-01 -6.13321e-01  1.19156e+00
21Feb13_174640|   6.56374e-01]
21Feb13_174640| [ 4.42022e-02 -1.91843e-01  9.05626e-01 -7.47534e-01  1.88839e-01
21Feb13_174640|  -2.99682e-01]
21Feb13_174640| [ 9.98249e-01  7.67460e-01  5.60854e-01  1.00827e+00 -5.46571e-01
21Feb13_174640|   2.12347e-01]
21Feb13_174640| [-3.93190e-01 -5.15195e-01  2.43161e-01  1.08610e+00 -1.18163e+00
21Feb13_174640|   5.27352e-01]
21Feb13_174640| [-2.10995e+00 -4.58607e-01  1.02182e+00 -9.34708e-01 -1.61474e-01
21Feb13_174640|   5.21834e-01]
21Feb13_174640| [ 2.71710e-01  6.30733e-01 -2.12292e+00  2.44596e-02  2.19986e-01
21Feb13_174640|   2.64510e-01]
21Feb13_174640| [ 2.73506e+00 -1.68607e+00 -3.43628e-01  7.61628e-02 -2.26828e-01
21Feb13_174640|  -3.81731e-01]
21Feb13_174640| [ 5.23338e-02 -7.03002e-01 -1.03161e-01  9.49301e-01  1.27202e-01
21Feb13_174640|   6.50503e-01]
21Feb13_174640| [-1.12324e-01  1.94323e-01 -1.49900e+00  1.41035e-01 -1.16220e+00
21Feb13_174640|  -3.35985e-01]
21Feb13_174640| [ 8.70873e-01  7.43781e-01 -1.46105e+00  4.68759e-01 -6.68305e-01
21Feb13_174640|  -1.71642e-01]
21Feb13_174640| [-8.00266e-01 -1.06325e-01  7.65769e-01  1.72880e+00  1.90866e+00
21Feb13_174640|   1.16830e+00]
21Feb13_174640| [-3.71919e-01  1.04334e+00 -1.67330e+00 -5.96497e-01 -3.52827e-01
21Feb13_174640|  -7.28103e-03]]
21Feb13_174640|-- Bias --
21Feb13_174640|[ 1.71352  0.90911  0.47256 -0.01331  0.42218 -0.02646]
21Feb13_174640|Layer 1:
21Feb13_174640|-- Config --
21Feb13_174640|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174640|-- Weights --
21Feb13_174640|[[-0.99267 -0.97274  0.82405 -0.16977]
21Feb13_174640| [ 0.60239 -0.10238 -0.00496 -0.14288]
21Feb13_174640| [-0.11020  0.99493  0.79092 -0.16312]
21Feb13_174640| [ 0.55308 -0.37597 -1.28077 -0.67794]
21Feb13_174640| [ 0.99539  0.72798  0.47591  0.49305]
21Feb13_174640| [ 0.83623 -0.20924  0.30390  0.06038]]
21Feb13_174640|-- Bias --
21Feb13_174640|[-0.44854  0.57814 -0.25511  0.43911]
21Feb13_174640|Layer 2:
21Feb13_174640|-- Config --
21Feb13_174640|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_174640|-- Weights --
21Feb13_174640|[[ 0.33441  0.48577]
21Feb13_174640| [-0.92058 -1.06244]
21Feb13_174640| [-0.40205  1.58320]
21Feb13_174640| [-0.58076 -0.11565]]
21Feb13_174640|-- Bias --
21Feb13_174640|[0.09744 0.58731]
21Feb13_174640|Predicting the validation and test data with the Best final individual.
21Feb13_174647| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_174647|-----------  ------------------  --------------------  ----------
21Feb13_174647|Validation         38.43                  20            0.00282
21Feb13_174647|   Test            39.62                  20            0.00000
2021-02-13 17:46:48.079772: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
21Feb13_174648|Data summary: Train
21Feb13_174648|data.shape = (2300, 57)
21Feb13_174648|labels.shape = (2300,)
21Feb13_174648|Class distribution:
21Feb13_174648|	0 - 1383 (0.60)
21Feb13_174648|	1 - 917 (0.40)
21Feb13_174648|Data summary: Validation
21Feb13_174648|data.shape = (1150, 57)
21Feb13_174648|labels.shape = (1150,)
21Feb13_174648|Class distribution:
21Feb13_174648|	0 - 708 (0.62)
21Feb13_174648|	1 - 442 (0.38)
21Feb13_174648|Data summary: Test
21Feb13_174648|data.shape = (1151, 57)
21Feb13_174648|labels.shape = (1151,)
21Feb13_174648|Class distribution:
21Feb13_174648|	0 - 697 (0.61)
21Feb13_174648|	1 - 454 (0.39)
21Feb13_174648|Selected configuration values
21Feb13_174648|-- Dataset name: spambase3
21Feb13_174648|-- Initial population size: 64
21Feb13_174648|-- Maximun number of generations: 32
21Feb13_174648|-- Neurons per hidden layer range: (2, 20)
21Feb13_174648|-- Hidden layers number range: (1, 3)
21Feb13_174648|-- Crossover probability: 0.5
21Feb13_174648|-- Bias gene mutation probability: 0.2
21Feb13_174648|-- Weights gene mutation probability: 0.75
21Feb13_174648|-- Neuron mutation probability: 0.3
21Feb13_174648|-- Layer mutation probability: 0.3
21Feb13_174648|-- Constant hidden layers: False
21Feb13_174648|-- Seed: 31415
21Feb13_174648|Entering GA
21Feb13_174648|Start the algorithm
2021-02-13 17:46:48.916811: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-13 17:46:48.917341: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-02-13 17:46:48.939063: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-13 17:46:48.939386: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.71GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s
2021-02-13 17:46:48.939399: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-02-13 17:46:48.940849: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-02-13 17:46:48.940875: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-02-13 17:46:48.941376: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-02-13 17:46:48.941513: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-02-13 17:46:48.941583: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-13 17:46:48.941985: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-02-13 17:46:48.942025: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-13 17:46:48.942031: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-02-13 17:46:48.942233: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-02-13 17:46:48.943017: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-13 17:46:48.943031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-13 17:46:48.943035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      
2021-02-13 17:46:48.987651: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-02-13 17:46:48.987987: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3493635000 Hz
/home/jmerelo/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype("int32")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn('`model.predict_classes()` is deprecated and '
21Feb13_175050|-- Generation 1 --
21Feb13_175050|    -- Crossed 0 individual pairs.
21Feb13_175050|    -- Mutated 32 individuals.
21Feb13_175452|    -- Evaluated 64 individuals.
21Feb13_175452|    Summary of generation 1:
21Feb13_175452| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_175452|-----------  ------------------  --------------------  ----------
21Feb13_175452|    Max            38.70                184.00          0.61612
21Feb13_175452|    Avg            38.00                55.12           0.02358
21Feb13_175452|    Min            26.35                 2.00           0.00000
21Feb13_175452|    Std             2.20                43.08           0.10467
21Feb13_175452|   Best            26.35                24.00           0.49087
21Feb13_175452|-- Generation 2 --
21Feb13_175452|    -- Crossed 2 individual pairs.
21Feb13_175452|    -- Mutated 32 individuals.
21Feb13_175849|    -- Evaluated 64 individuals.
21Feb13_175849|    Summary of generation 2:
21Feb13_175849| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_175849|-----------  ------------------  --------------------  ----------
21Feb13_175849|    Max            39.22                102.00          0.56941
21Feb13_175849|    Avg            38.18                32.66           0.01388
21Feb13_175849|    Min            27.39                 3.00           0.00000
21Feb13_175849|    Std             1.49                26.23           0.07381
21Feb13_175849|   Best            27.39                22.00           0.56941
21Feb13_175849|-- Generation 3 --
21Feb13_175849|    -- Crossed 0 individual pairs.
21Feb13_175849|    -- Mutated 32 individuals.
21Feb13_180244|    -- Evaluated 64 individuals.
21Feb13_180244|    Summary of generation 3:
21Feb13_180244| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_180244|-----------  ------------------  --------------------  ----------
21Feb13_180244|    Max            38.96                76.00           0.72985
21Feb13_180244|    Avg            37.37                23.30           0.05586
21Feb13_180244|    Min            23.39                 3.00           0.00000
21Feb13_180244|    Std             3.39                17.36           0.16386
21Feb13_180244|   Best            23.39                 7.00           0.58753
21Feb13_180244|-- Generation 4 --
21Feb13_180244|    -- Crossed 3 individual pairs.
21Feb13_180244|    -- Mutated 32 individuals.
21Feb13_180638|    -- Evaluated 64 individuals.
21Feb13_180638|    Summary of generation 4:
21Feb13_180638| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_180638|-----------  ------------------  --------------------  ----------
21Feb13_180638|    Max            38.70                76.00           0.71239
21Feb13_180638|    Avg            37.22                17.77           0.05603
21Feb13_180638|    Min            25.22                 4.00           0.00000
21Feb13_180638|    Std             3.25                13.23           0.14861
21Feb13_180638|   Best            25.22                10.00           0.71239
21Feb13_180638|-- Generation 5 --
21Feb13_180638|    -- Crossed 0 individual pairs.
21Feb13_180638|    -- Mutated 32 individuals.
21Feb13_181032|    -- Evaluated 64 individuals.
21Feb13_181032|    Summary of generation 5:
21Feb13_181032| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_181032|-----------  ------------------  --------------------  ----------
21Feb13_181032|    Max            38.78                48.00           0.68435
21Feb13_181032|    Avg            37.75                12.30           0.03331
21Feb13_181032|    Min            25.65                 2.00           0.00000
21Feb13_181032|    Std             2.59                 8.88           0.11884
21Feb13_181032|   Best            25.65                42.00           0.45638
21Feb13_181032|-- Generation 6 --
21Feb13_181032|    -- Crossed 3 individual pairs.
21Feb13_181032|    -- Mutated 32 individuals.
21Feb13_181422|    -- Evaluated 64 individuals.
21Feb13_181422|    Summary of generation 6:
21Feb13_181422| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_181422|-----------  ------------------  --------------------  ----------
21Feb13_181422|    Max            53.22                42.00           0.77947
21Feb13_181422|    Avg            37.90                 9.92           0.04394
21Feb13_181422|    Min            21.91                 2.00           0.00000
21Feb13_181422|    Std             3.42                 7.96           0.14489
21Feb13_181422|   Best            21.91                42.00           0.64440
21Feb13_181422|-- Generation 7 --
21Feb13_181422|    -- Crossed 6 individual pairs.
21Feb13_181422|    -- Mutated 32 individuals.
21Feb13_181809|    -- Evaluated 64 individuals.
21Feb13_181809|    Summary of generation 7:
21Feb13_181809| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_181809|-----------  ------------------  --------------------  ----------
21Feb13_181809|    Max            38.87                45.00           0.59906
21Feb13_181809|    Avg            37.31                 9.09           0.04871
21Feb13_181809|    Min            24.43                 2.00           0.00000
21Feb13_181809|    Std             3.40                 8.72           0.14007
21Feb13_181809|   Best            24.43                18.00           0.56386
21Feb13_181809|-- Generation 8 --
21Feb13_181809|    -- Crossed 3 individual pairs.
21Feb13_181809|    -- Mutated 32 individuals.
21Feb13_182156|    -- Evaluated 64 individuals.
21Feb13_182156|    Summary of generation 8:
21Feb13_182156| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_182156|-----------  ------------------  --------------------  ----------
21Feb13_182156|    Max            38.78                28.00           0.56608
21Feb13_182156|    Avg            37.51                 7.09           0.04286
21Feb13_182156|    Min            26.35                 2.00           0.00000
21Feb13_182156|    Std             2.88                 5.58           0.12664
21Feb13_182156|   Best            26.35                12.00           0.47085
21Feb13_182156|-- Generation 9 --
21Feb13_182156|    -- Crossed 3 individual pairs.
21Feb13_182156|    -- Mutated 32 individuals.
21Feb13_182545|    -- Evaluated 64 individuals.
21Feb13_182545|    Summary of generation 9:
21Feb13_182545| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_182545|-----------  ------------------  --------------------  ----------
21Feb13_182545|    Max            39.48                39.00           0.76890
21Feb13_182545|    Avg            37.23                 8.73           0.05722
21Feb13_182545|    Min            24.87                 2.00           0.00000
21Feb13_182545|    Std             3.27                 7.12           0.15701
21Feb13_182545|   Best            24.87                24.00           0.76890
21Feb13_182545|-- Generation 10 --
21Feb13_182545|    -- Crossed 2 individual pairs.
21Feb13_182545|    -- Mutated 32 individuals.
21Feb13_182933|    -- Evaluated 64 individuals.
21Feb13_182933|    Summary of generation 10:
21Feb13_182933| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_182933|-----------  ------------------  --------------------  ----------
21Feb13_182933|    Max            48.87                64.00           0.79480
21Feb13_182933|    Avg            37.52                 9.69           0.06645
21Feb13_182933|    Min            24.87                 2.00           0.00000
21Feb13_182933|    Std             3.40                10.30           0.18067
21Feb13_182933|   Best            24.87                 6.00           0.66150
21Feb13_182933|-- Generation 11 --
21Feb13_182933|    -- Crossed 2 individual pairs.
21Feb13_182933|    -- Mutated 32 individuals.
21Feb13_183322|    -- Evaluated 64 individuals.
21Feb13_183322|    Summary of generation 11:
21Feb13_183322| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_183322|-----------  ------------------  --------------------  ----------
21Feb13_183322|    Max            38.70                32.00           0.69902
21Feb13_183322|    Avg            37.43                 8.81           0.04748
21Feb13_183322|    Min            25.39                 2.00           0.00000
21Feb13_183322|    Std             2.75                 7.24           0.13867
21Feb13_183322|   Best            25.39                 6.00           0.69902
21Feb13_183322|-- Generation 12 --
21Feb13_183322|    -- Crossed 1 individual pairs.
21Feb13_183322|    -- Mutated 32 individuals.
21Feb13_183712|    -- Evaluated 64 individuals.
21Feb13_183712|    Summary of generation 12:
21Feb13_183712| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_183712|-----------  ------------------  --------------------  ----------
21Feb13_183712|    Max            39.22                36.00           0.73718
21Feb13_183712|    Avg            36.75                 8.77           0.07914
21Feb13_183712|    Min            23.04                 2.00           0.00000
21Feb13_183712|    Std             4.05                 7.25           0.18958
21Feb13_183712|   Best            23.04                11.00           0.69451
21Feb13_183712|-- Generation 13 --
21Feb13_183712|    -- Crossed 3 individual pairs.
21Feb13_183712|    -- Mutated 32 individuals.
21Feb13_184102|    -- Evaluated 64 individuals.
21Feb13_184102|    Summary of generation 13:
21Feb13_184102| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_184102|-----------  ------------------  --------------------  ----------
21Feb13_184102|    Max            38.70                56.00           0.78151
21Feb13_184102|    Avg            36.21                 8.70           0.09492
21Feb13_184102|    Min            22.87                 2.00           0.00000
21Feb13_184102|    Std             4.42                 9.36           0.19094
21Feb13_184102|   Best            22.87                27.00           0.54983
21Feb13_184102|-- Generation 14 --
21Feb13_184102|    -- Crossed 3 individual pairs.
21Feb13_184102|    -- Mutated 32 individuals.
21Feb13_184454|    -- Evaluated 64 individuals.
21Feb13_184454|    Summary of generation 14:
21Feb13_184454| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_184454|-----------  ------------------  --------------------  ----------
21Feb13_184454|    Max            38.70                56.00           0.69088
21Feb13_184454|    Avg            36.31                14.06           0.09620
21Feb13_184454|    Min            25.74                 2.00           0.00000
21Feb13_184454|    Std             3.96                12.93           0.18259
21Feb13_184454|   Best            25.74                44.00           0.52002
21Feb13_184454|-- Generation 15 --
21Feb13_184454|    -- Crossed 1 individual pairs.
21Feb13_184454|    -- Mutated 32 individuals.
21Feb13_184846|    -- Evaluated 64 individuals.
21Feb13_184846|    Summary of generation 15:
21Feb13_184846| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_184846|-----------  ------------------  --------------------  ----------
21Feb13_184846|    Max            38.70                90.00           0.75294
21Feb13_184846|    Avg            36.25                14.30           0.10327
21Feb13_184846|    Min            23.13                 2.00           0.00000
21Feb13_184846|    Std             4.30                15.59           0.20511
21Feb13_184846|   Best            23.13                27.00           0.57915
21Feb13_184846|-- Generation 16 --
21Feb13_184846|    -- Crossed 3 individual pairs.
21Feb13_184846|    -- Mutated 32 individuals.
21Feb13_185241|    -- Evaluated 64 individuals.
21Feb13_185241|    Summary of generation 16:
21Feb13_185241| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_185241|-----------  ------------------  --------------------  ----------
21Feb13_185241|    Max            39.57                90.00           0.76984
21Feb13_185241|    Avg            36.01                17.97           0.11935
21Feb13_185241|    Min            22.00                 2.00           0.00000
21Feb13_185241|    Std             4.52                19.62           0.21680
21Feb13_185241|   Best            22.00                27.00           0.58652
21Feb13_185241|-- Generation 17 --
21Feb13_185241|    -- Crossed 3 individual pairs.
21Feb13_185241|    -- Mutated 32 individuals.
21Feb13_185636|    -- Evaluated 64 individuals.
21Feb13_185636|    Summary of generation 17:
21Feb13_185636| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_185636|-----------  ------------------  --------------------  ----------
21Feb13_185636|    Max            38.70                90.00           0.76908
21Feb13_185636|    Avg            34.92                18.91           0.17374
21Feb13_185636|    Min            23.57                 2.00           0.00000
21Feb13_185636|    Std             5.10                19.74           0.25349
21Feb13_185636|   Best            23.57                27.00           0.60692
21Feb13_185636|-- Generation 18 --
21Feb13_185636|    -- Crossed 3 individual pairs.
21Feb13_185636|    -- Mutated 32 individuals.
21Feb13_190034|    -- Evaluated 64 individuals.
21Feb13_190034|    Summary of generation 18:
21Feb13_190034| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_190034|-----------  ------------------  --------------------  ----------
21Feb13_190034|    Max            38.70                80.00           0.76078
21Feb13_190034|    Avg            34.28                21.88           0.20398
21Feb13_190034|    Min            22.96                 3.00           0.00000
21Feb13_190034|    Std             5.11                15.87           0.25843
21Feb13_190034|   Best            22.96                27.00           0.56475
21Feb13_190034|-- Generation 19 --
21Feb13_190034|    -- Crossed 3 individual pairs.
21Feb13_190034|    -- Mutated 32 individuals.
21Feb13_190435|    -- Evaluated 64 individuals.
21Feb13_190435|    Summary of generation 19:
21Feb13_190435| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_190435|-----------  ------------------  --------------------  ----------
21Feb13_190435|    Max            38.70                90.00           0.76500
21Feb13_190435|    Avg            34.02                26.81           0.21204
21Feb13_190435|    Min            24.96                 6.00           0.00000
21Feb13_190435|    Std             5.23                17.17           0.25306
21Feb13_190435|   Best            24.96                27.00           0.65277
21Feb13_190435|-- Generation 20 --
21Feb13_190435|    -- Crossed 2 individual pairs.
21Feb13_190435|    -- Mutated 32 individuals.
21Feb13_190837|    -- Evaluated 64 individuals.
21Feb13_190837|    Summary of generation 20:
21Feb13_190837| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_190837|-----------  ------------------  --------------------  ----------
21Feb13_190837|    Max            38.78                100.00          0.72688
21Feb13_190837|    Avg            32.08                30.98           0.27953
21Feb13_190837|    Min            21.65                 9.00           0.00000
21Feb13_190837|    Std             5.50                19.47           0.24772
21Feb13_190837|   Best            21.65                27.00           0.66091
21Feb13_190837|-- Generation 21 --
21Feb13_190837|    -- Crossed 0 individual pairs.
21Feb13_190837|    -- Mutated 32 individuals.
21Feb13_191245|    -- Evaluated 64 individuals.
21Feb13_191245|    Summary of generation 21:
21Feb13_191245| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_191245|-----------  ------------------  --------------------  ----------
21Feb13_191245|    Max            38.52                100.00          0.79322
21Feb13_191245|    Avg            31.30                34.14           0.34328
21Feb13_191245|    Min            22.87                 2.00           0.00000
21Feb13_191245|    Std             5.64                19.92           0.27821
21Feb13_191245|   Best            22.87                24.00           0.60382
21Feb13_191245|-- Generation 22 --
21Feb13_191245|    -- Crossed 1 individual pairs.
21Feb13_191245|    -- Mutated 32 individuals.
21Feb13_191652|    -- Evaluated 64 individuals.
21Feb13_191652|    Summary of generation 22:
21Feb13_191652| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_191652|-----------  ------------------  --------------------  ----------
21Feb13_191652|    Max            39.65                70.00           0.76791
21Feb13_191652|    Avg            31.35                32.34           0.34260
21Feb13_191652|    Min            21.74                12.00           0.00000
21Feb13_191652|    Std             5.86                13.19           0.28353
21Feb13_191652|   Best            21.74                12.00           0.60759
21Feb13_191652|-- Generation 23 --
21Feb13_191652|    -- Crossed 0 individual pairs.
21Feb13_191652|    -- Mutated 32 individuals.
21Feb13_192100|    -- Evaluated 64 individuals.
21Feb13_192100|    Summary of generation 23:
21Feb13_192100| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_192100|-----------  ------------------  --------------------  ----------
21Feb13_192100|    Max            50.00                80.00           0.80749
21Feb13_192100|    Avg            31.16                33.38           0.34662
21Feb13_192100|    Min            20.78                 4.00           0.00000
21Feb13_192100|    Std             6.23                16.71           0.26900
21Feb13_192100|   Best            20.78                14.00           0.80701
21Feb13_192100|-- Generation 24 --
21Feb13_192100|    -- Crossed 1 individual pairs.
21Feb13_192100|    -- Mutated 32 individuals.
21Feb13_192510|    -- Evaluated 64 individuals.
21Feb13_192510|    Summary of generation 24:
21Feb13_192510| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_192510|-----------  ------------------  --------------------  ----------
21Feb13_192510|    Max            38.52                85.00           0.78216
21Feb13_192510|    Avg            31.22                35.23           0.32099
21Feb13_192510|    Min            21.83                12.00           0.00000
21Feb13_192510|    Std             5.58                16.53           0.26104
21Feb13_192510|   Best            21.83                24.00           0.58151
21Feb13_192510|-- Generation 25 --
21Feb13_192510|    -- Crossed 0 individual pairs.
21Feb13_192510|    -- Mutated 32 individuals.
21Feb13_192923|    -- Evaluated 64 individuals.
21Feb13_192923|    Summary of generation 25:
21Feb13_192923| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_192923|-----------  ------------------  --------------------  ----------
21Feb13_192923|    Max            38.43                75.00           0.78192
21Feb13_192923|    Avg            30.30                39.97           0.38320
21Feb13_192923|    Min            22.00                12.00           0.00000
21Feb13_192923|    Std             5.50                16.53           0.26807
21Feb13_192923|   Best            22.00                24.00           0.58467
21Feb13_192923|-- Generation 26 --
21Feb13_192923|    -- Crossed 0 individual pairs.
21Feb13_192923|    -- Mutated 32 individuals.
21Feb13_193336|    -- Evaluated 64 individuals.
21Feb13_193336|    Summary of generation 26:
21Feb13_193336| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_193336|-----------  ------------------  --------------------  ----------
21Feb13_193336|    Max            56.52                96.00           0.80099
21Feb13_193336|    Avg            30.75                38.62           0.38240
21Feb13_193336|    Min            22.26                12.00           0.00000
21Feb13_193336|    Std             6.70                17.15           0.27361
21Feb13_193336|   Best            22.26                24.00           0.58567
21Feb13_193336|-- Generation 27 --
21Feb13_193336|    -- Crossed 1 individual pairs.
21Feb13_193336|    -- Mutated 32 individuals.
21Feb13_193749|    -- Evaluated 64 individuals.
21Feb13_193749|    Summary of generation 27:
21Feb13_193749| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_193749|-----------  ------------------  --------------------  ----------
21Feb13_193749|    Max            42.26                102.00          0.74978
21Feb13_193749|    Avg            30.51                41.27           0.35527
21Feb13_193749|    Min            23.13                 5.00           0.00000
21Feb13_193749|    Std             5.90                19.82           0.25678
21Feb13_193749|   Best            23.13                24.00           0.55093
21Feb13_193749|-- Generation 28 --
21Feb13_193749|    -- Crossed 1 individual pairs.
21Feb13_193749|    -- Mutated 32 individuals.
21Feb13_194203|    -- Evaluated 64 individuals.
21Feb13_194203|    Summary of generation 28:
21Feb13_194203| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_194203|-----------  ------------------  --------------------  ----------
21Feb13_194203|    Max            48.52                154.00          0.79224
21Feb13_194203|    Avg            30.29                41.59           0.36969
21Feb13_194203|    Min            22.09                12.00           0.00000
21Feb13_194203|    Std             5.99                22.75           0.25069
21Feb13_194203|   Best            22.09                24.00           0.62084
21Feb13_194203|-- Generation 29 --
21Feb13_194203|    -- Crossed 0 individual pairs.
21Feb13_194203|    -- Mutated 32 individuals.
21Feb13_194619|    -- Evaluated 64 individuals.
21Feb13_194619|    Summary of generation 29:
21Feb13_194619| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_194619|-----------  ------------------  --------------------  ----------
21Feb13_194619|    Max            47.22                102.00          0.78532
21Feb13_194619|    Avg            30.81                46.00           0.37621
21Feb13_194619|    Min            22.61                 3.00           0.00000
21Feb13_194619|    Std             5.93                20.50           0.27605
21Feb13_194619|   Best            22.61                24.00           0.57337
21Feb13_194619|-- Generation 30 --
21Feb13_194619|    -- Crossed 1 individual pairs.
21Feb13_194619|    -- Mutated 32 individuals.
21Feb13_195036|    -- Evaluated 64 individuals.
21Feb13_195036|    Summary of generation 30:
21Feb13_195036| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_195036|-----------  ------------------  --------------------  ----------
21Feb13_195036|    Max            38.87                102.00          0.78270
21Feb13_195036|    Avg            31.74                48.11           0.29195
21Feb13_195036|    Min            21.57                12.00           0.00000
21Feb13_195036|    Std             6.37                21.81           0.28212
21Feb13_195036|   Best            21.57                24.00           0.58609
21Feb13_195036|-- Generation 31 --
21Feb13_195036|    -- Crossed 0 individual pairs.
21Feb13_195036|    -- Mutated 32 individuals.
21Feb13_195453|    -- Evaluated 64 individuals.
21Feb13_195453|    Summary of generation 31:
21Feb13_195453| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_195453|-----------  ------------------  --------------------  ----------
21Feb13_195453|    Max            38.78                120.00          0.79014
21Feb13_195453|    Avg            31.30                52.27           0.32553
21Feb13_195453|    Min            23.39                12.00           0.00000
21Feb13_195453|    Std             6.08                26.61           0.28801
21Feb13_195453|   Best            23.39                27.00           0.59119
21Feb13_195453|-- Generation 32 --
21Feb13_195453|    -- Crossed 1 individual pairs.
21Feb13_195453|    -- Mutated 32 individuals.
21Feb13_195912|    -- Evaluated 64 individuals.
21Feb13_195912|    Summary of generation 32:
21Feb13_195912| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_195912|-----------  ------------------  --------------------  ----------
21Feb13_195912|    Max            39.65                138.00          0.77906
21Feb13_195912|    Avg            30.94                54.86           0.35162
21Feb13_195912|    Min            21.22                12.00           0.00000
21Feb13_195912|    Std             6.03                26.84           0.28947
21Feb13_195912|   Best            21.22                52.00           0.70119
21Feb13_195912|Best initial individual weights
21Feb13_195912|Individual:
21Feb13_195912|-- Constant hidden layers --
21Feb13_195912|False
21Feb13_195912|Layer 0:
21Feb13_195912|-- Config --
21Feb13_195912|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_195912|-- Weights --
21Feb13_195912|[[-5.38414e-01 -1.11941e-01  4.59687e-01  9.30600e-01 -7.26034e-01
21Feb13_195912|   3.72001e-01]
21Feb13_195912| [ 3.60602e-01  5.53284e-01  5.84148e-02  9.30504e-01 -7.82688e-01
21Feb13_195912|  -9.31075e-01]
21Feb13_195912| [ 1.11869e-01  6.63120e-01 -9.03340e-01  8.20675e-01 -2.05381e-01
21Feb13_195912|  -8.87143e-01]
21Feb13_195912| [-7.09603e-01 -7.06799e-01 -8.03514e-01  4.32426e-01 -9.16816e-01
21Feb13_195912|  -9.72913e-01]
21Feb13_195912| [ 9.25116e-01 -6.50738e-01  2.10477e-01 -2.26129e-01  1.76222e-01
21Feb13_195912|  -5.03244e-01]
21Feb13_195912| [-5.30949e-01  3.01577e-01  3.46549e-01  5.11452e-01 -8.98169e-01
21Feb13_195912|   9.06618e-01]
21Feb13_195912| [ 3.21726e-01  8.55196e-01 -9.46055e-01 -3.04463e-01  2.78888e-01
21Feb13_195912|  -4.99565e-01]
21Feb13_195912| [-6.48728e-01 -7.84529e-01  9.69338e-01  6.39180e-01 -5.43770e-01
21Feb13_195912|   1.34397e-01]
21Feb13_195912| [-9.70870e-01 -6.54822e-01  5.37514e-02  9.87488e-01 -4.86301e-02
21Feb13_195912|  -5.40641e-01]
21Feb13_195912| [ 5.83103e-01 -5.82018e-01 -3.87978e-01  9.40017e-01 -4.76074e-01
21Feb13_195912|  -5.91012e-01]
21Feb13_195912| [-1.91912e-03  6.52106e-01  1.57526e-01 -3.89327e-02  6.27661e-01
21Feb13_195912|   6.90774e-01]
21Feb13_195912| [ 3.95897e-01  3.26236e-01  1.50670e-01 -2.32047e-01 -5.79411e-01
21Feb13_195912|   9.88567e-01]
21Feb13_195912| [ 1.50419e-01  3.70015e-01  1.60860e-01 -9.20774e-01 -1.87420e-01
21Feb13_195912|  -2.19623e-01]
21Feb13_195912| [ 9.57987e-01 -4.99330e-01  5.73294e-01 -5.93520e-02 -8.63942e-01
21Feb13_195912|   5.42727e-01]
21Feb13_195912| [ 6.33214e-01  9.14423e-01 -6.96776e-01  6.77153e-01 -8.80782e-01
21Feb13_195912|  -9.24147e-01]
21Feb13_195912| [ 7.04217e-01 -9.34760e-01 -9.92798e-02 -2.19116e-01  3.13541e-01
21Feb13_195912|  -1.46124e-01]
21Feb13_195912| [ 7.28719e-01  3.25631e-01  2.76086e-01  6.84535e-01 -8.19422e-01
21Feb13_195912|   2.50781e-01]
21Feb13_195912| [ 6.80315e-01  5.66422e-01  6.79806e-03 -7.05925e-01 -3.31549e-01
21Feb13_195912|  -2.10219e-01]
21Feb13_195912| [ 6.61774e-01  4.67895e-01  5.06009e-01  1.37143e-01  1.86678e-01
21Feb13_195912|  -1.54636e-01]
21Feb13_195912| [ 6.87290e-01 -8.04588e-01  3.83299e-01  3.42730e-01 -2.97817e-01
21Feb13_195912|  -5.03462e-01]
21Feb13_195912| [ 9.96164e-01 -6.46923e-01 -7.78171e-01 -5.61654e-01 -3.70504e-01
21Feb13_195912|  -8.34454e-01]
21Feb13_195912| [-7.20312e-01 -7.35783e-01  6.90976e-01  4.72736e-01  6.50778e-01
21Feb13_195912|  -2.45008e-01]
21Feb13_195912| [-4.40759e-01  4.34247e-01  5.07729e-01 -3.24154e-01  5.25949e-01
21Feb13_195912|   3.98492e-01]
21Feb13_195912| [-6.45654e-01 -3.56834e-01 -4.72648e-01  7.46373e-01  4.83143e-01
21Feb13_195912|   9.81922e-01]
21Feb13_195912| [-8.81085e-01 -2.25511e-01 -5.67638e-01 -2.54381e-01  4.94019e-01
21Feb13_195912|   7.51894e-01]
21Feb13_195912| [-3.24442e-03 -3.40707e-01 -6.27731e-02  3.88478e-01 -7.35648e-01
21Feb13_195912|   5.75421e-01]
21Feb13_195912| [ 4.00171e-01 -1.10654e-01  4.87811e-01 -1.06929e-01  9.90155e-01
21Feb13_195912|   7.63739e-01]
21Feb13_195912| [-6.57928e-01  1.76071e-01 -5.75769e-01 -1.74657e-02  3.64947e-02
21Feb13_195912|   7.34770e-05]
21Feb13_195912| [ 2.87981e-02 -7.24736e-02 -6.12689e-01 -7.59073e-01 -2.82026e-01
21Feb13_195912|   3.01483e-01]
21Feb13_195912| [-6.37720e-02  1.58742e-01 -7.89464e-01  3.09770e-01 -5.40136e-01
21Feb13_195912|  -9.52794e-01]
21Feb13_195912| [ 2.52189e-01  1.19322e-01  5.60726e-01 -6.49547e-03  7.84271e-01
21Feb13_195912|   1.83244e-01]
21Feb13_195912| [-2.06608e-01 -9.85389e-01  6.95458e-01 -4.27583e-01  6.90101e-01
21Feb13_195912|  -8.75413e-02]
21Feb13_195912| [ 5.75377e-01 -5.97830e-01 -5.48820e-01  5.12034e-01 -8.58947e-01
21Feb13_195912|   6.18673e-02]
21Feb13_195912| [ 2.11372e-01  3.60965e-01 -3.58364e-01 -8.05964e-01  2.86475e-01
21Feb13_195912|  -3.14446e-01]
21Feb13_195912| [-5.96829e-01  6.98452e-01  1.32086e-01 -8.18678e-01 -1.44609e-01
21Feb13_195912|   8.48112e-01]
21Feb13_195912| [ 1.14109e-01 -9.13741e-01 -4.21725e-01 -9.38720e-01 -3.58322e-01
21Feb13_195912|  -6.51011e-01]
21Feb13_195912| [-4.94378e-02  1.20415e-01 -1.75446e-01  2.32402e-01 -8.13887e-01
21Feb13_195912|  -7.36999e-01]
21Feb13_195912| [-3.99135e-01  3.03573e-01  3.08043e-03 -6.13878e-01  8.42504e-01
21Feb13_195912|  -6.91215e-01]
21Feb13_195912| [-1.80775e-01  1.09100e-01 -8.17880e-01 -5.98349e-01 -7.78075e-01
21Feb13_195912|   4.63807e-01]
21Feb13_195912| [-3.79292e-01  5.45740e-01 -2.83088e-01  5.59926e-01  7.03895e-01
21Feb13_195912|   4.36480e-01]
21Feb13_195912| [-8.92759e-02  4.10473e-01 -2.29113e-01  7.70840e-01 -1.48559e-01
21Feb13_195912|  -2.53774e-01]
21Feb13_195912| [-4.36372e-01  6.10836e-01 -8.34882e-01  1.51849e-01  2.70480e-01
21Feb13_195912|   5.21678e-01]
21Feb13_195912| [-3.89315e-01 -3.97914e-01  6.43415e-01  2.53974e-01  1.49145e-01
21Feb13_195912|   5.93488e-01]
21Feb13_195912| [ 8.96330e-01 -7.04667e-01  9.17003e-01  4.15152e-01 -7.17592e-01
21Feb13_195912|  -2.50562e-01]
21Feb13_195912| [ 9.67896e-01 -6.51170e-01 -7.78860e-01 -7.96559e-02 -9.54845e-01
21Feb13_195912|   6.44993e-01]
21Feb13_195912| [ 1.00276e-01  1.83205e-01  2.10153e-01 -4.35853e-01 -2.61470e-01
21Feb13_195912|  -2.74774e-01]
21Feb13_195912| [-7.85781e-01  9.24978e-01 -7.46751e-01  6.44773e-01  4.96564e-02
21Feb13_195912|  -1.25046e-01]
21Feb13_195912| [ 5.22784e-01 -9.80250e-01 -3.25439e-01 -4.64498e-01 -9.51071e-01
21Feb13_195912|   7.75711e-01]
21Feb13_195912| [ 8.56376e-01  7.14107e-01  6.60668e-01 -5.69235e-01  9.60393e-01
21Feb13_195912|   4.11440e-01]
21Feb13_195912| [-8.12929e-01  2.43167e-01  7.85767e-01  7.11152e-01  7.36495e-01
21Feb13_195912|   8.96444e-02]
21Feb13_195912| [-1.52651e-01  2.52419e-01  4.91317e-01 -1.13850e-02 -4.18982e-01
21Feb13_195912|  -3.70351e-01]
21Feb13_195912| [-7.90272e-02 -2.53430e-01  9.39604e-01 -8.75452e-01  2.58826e-01
21Feb13_195912|  -1.02071e-01]
21Feb13_195912| [-4.89616e-01 -5.74736e-01  3.54268e-01  9.88502e-04 -3.51688e-01
21Feb13_195912|   6.99329e-01]
21Feb13_195912| [ 5.47316e-01  2.29557e-01 -4.97133e-01 -6.94224e-01 -3.60223e-01
21Feb13_195912|   4.54396e-01]
21Feb13_195912| [-1.37010e-01  9.44196e-01  7.38532e-01  9.90601e-01 -6.51859e-01
21Feb13_195912|  -7.82265e-01]
21Feb13_195912| [ 7.92089e-01 -2.55769e-01  1.43900e-01 -8.54367e-01  4.30294e-01
21Feb13_195912|  -9.92344e-01]
21Feb13_195912| [-3.26732e-01  4.47087e-02  3.12938e-01  9.16935e-01  1.96683e-01
21Feb13_195912|  -8.94111e-02]]
21Feb13_195912|-- Bias --
21Feb13_195912|[-0.59136  0.98022 -0.97673  0.61339  0.56791  0.94975]
21Feb13_195912|Layer 1:
21Feb13_195912|-- Config --
21Feb13_195912|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_195912|-- Weights --
21Feb13_195912|[[ 0.91069 -0.80478  0.56169  0.60899 -0.29517]
21Feb13_195912| [ 0.56889 -0.71434 -0.75554  0.66084  0.42575]
21Feb13_195912| [ 0.78835 -0.35372 -0.80997  0.51990  0.17042]
21Feb13_195912| [-0.30603 -0.77033  0.16272 -0.83770  0.88477]
21Feb13_195912| [-0.71988  0.76294 -0.81182  0.31364  0.69726]
21Feb13_195912| [ 0.15635 -0.83677  0.90955 -0.26461 -0.57742]]
21Feb13_195912|-- Bias --
21Feb13_195912|[ 0.55087  0.13665  0.06276 -0.24419 -0.58009]
21Feb13_195912|Layer 2:
21Feb13_195912|-- Config --
21Feb13_195912|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_195912|-- Weights --
21Feb13_195912|[[ 0.15322  0.65446]
21Feb13_195912| [ 0.67064  0.32184]
21Feb13_195912| [-0.17492  0.43632]
21Feb13_195912| [ 0.57016  0.44698]
21Feb13_195912| [ 0.46848  0.11977]]
21Feb13_195912|-- Bias --
21Feb13_195912|[-0.61426 -0.19964]
21Feb13_195912|Predicting the validation and test data with the Best initial individual.
21Feb13_195919| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_195919|-----------  ------------------  --------------------  ----------
21Feb13_195919|Validation         38.43                  22            0.00000
21Feb13_195919|   Test            39.44                  22            0.00000
21Feb13_195919|-------------------- Test #0 --------------------
21Feb13_195919|Best final individual weights
21Feb13_195919|Individual:
21Feb13_195919|-- Constant hidden layers --
21Feb13_195919|False
21Feb13_195919|Layer 0:
21Feb13_195919|-- Config --
21Feb13_195919|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_195919|-- Weights --
21Feb13_195919|[[-0.70147  1.81898 -1.19811 -0.98702]
21Feb13_195919| [ 0.12854  0.81408  0.25514  0.23353]
21Feb13_195919| [-0.76378 -0.76500  0.35248  0.26890]
21Feb13_195919| [ 1.64341  1.67169  0.03518 -0.20378]
21Feb13_195919| [ 0.22157 -0.61019  0.79588 -0.27345]
21Feb13_195919| [-1.23822 -1.86764 -1.85666  0.33678]
21Feb13_195919| [-0.97692  0.15098  0.30715  1.75219]
21Feb13_195919| [ 0.20395 -0.35022 -1.69279 -0.34243]
21Feb13_195919| [-0.24159 -0.14268  2.25383  0.68550]
21Feb13_195919| [-0.55194 -0.68549  0.80280 -0.60941]
21Feb13_195919| [-0.63201  0.46144  0.24282  2.20161]
21Feb13_195919| [-1.18622 -0.60422  0.26610 -0.70285]
21Feb13_195919| [ 0.60333  0.16633 -0.65080  0.11363]
21Feb13_195919| [ 0.36873  0.18594  0.36549  0.22051]
21Feb13_195919| [ 1.04502  0.19518 -0.43040  1.07351]
21Feb13_195919| [ 0.96694  0.14477 -1.02896  0.89242]
21Feb13_195919| [ 1.27167  0.01653  0.96997 -1.61365]
21Feb13_195919| [-1.59173 -0.22669 -1.11659  0.59352]
21Feb13_195919| [ 0.87703 -1.31311 -1.04639  0.94319]
21Feb13_195919| [ 0.87336  0.01591  0.70213 -1.77416]
21Feb13_195919| [ 2.19503 -1.36122 -1.48883  0.00411]
21Feb13_195919| [-0.85040  0.98617  2.14218 -0.12991]
21Feb13_195919| [ 1.25178 -0.36561  0.06305 -0.36145]
21Feb13_195919| [-2.58965  1.31141  1.10693 -0.55231]
21Feb13_195919| [ 0.59457  1.69880 -1.10262  1.36493]
21Feb13_195919| [-0.28694 -0.91882  0.92790 -0.77578]
21Feb13_195919| [ 0.55829  0.46047  0.83314 -0.61592]
21Feb13_195919| [ 0.34349  1.22218 -0.85430 -1.79906]
21Feb13_195919| [-0.28156 -0.80385  0.47478  0.95791]
21Feb13_195919| [ 0.89316  1.14094  0.47921  0.22448]
21Feb13_195919| [ 0.02193 -0.43600  0.87852  2.16496]
21Feb13_195919| [-1.31579  1.36006  0.18801  0.76711]
21Feb13_195919| [-0.00297  0.12555 -0.92105 -1.78211]
21Feb13_195919| [ 0.57371 -0.19964 -0.75235  0.20121]
21Feb13_195919| [-0.07073  1.32002 -0.15200  0.74027]
21Feb13_195919| [ 1.03756 -0.91348  0.02172  1.94365]
21Feb13_195919| [ 0.90723 -1.45536  0.11866 -1.84272]
21Feb13_195919| [-0.50110 -1.18639  1.25970 -0.55013]
21Feb13_195919| [ 0.98329 -0.40237 -0.83564  0.39022]
21Feb13_195919| [ 0.18550  0.63159 -0.20666 -1.04919]
21Feb13_195919| [ 0.92871 -1.14096 -1.51486  1.62599]
21Feb13_195919| [ 2.21129 -0.75264  1.54338 -0.82534]
21Feb13_195919| [-2.56190  0.75152  0.14857  1.17383]
21Feb13_195919| [ 1.03770  0.01148  0.25022 -1.28659]
21Feb13_195919| [ 2.16183  0.47029  0.01741 -0.98632]
21Feb13_195919| [-0.08188 -0.86313  2.36805 -1.03742]
21Feb13_195919| [-0.08347  1.55004  0.04645 -2.86549]
21Feb13_195919| [-0.70867 -0.69114 -0.70866 -0.67093]
21Feb13_195919| [-0.14483  0.37071  0.04424  2.13613]
21Feb13_195919| [-0.14117  0.20703 -0.41044  1.72514]
21Feb13_195919| [ 0.84550  0.84911  0.28784 -2.20851]
21Feb13_195919| [ 0.10779 -2.36073 -0.21111  2.16331]
21Feb13_195919| [ 0.56615 -0.57729  1.36509  1.07720]
21Feb13_195919| [ 0.58032 -0.61085 -0.68982  0.73322]
21Feb13_195919| [-0.89739  0.52350 -0.68521 -0.63787]
21Feb13_195919| [-0.74391 -0.23943  0.66873  0.46393]
21Feb13_195919| [ 0.65107 -0.95629 -0.15588  0.30563]]
21Feb13_195919|-- Bias --
21Feb13_195919|[-1.06816  1.50470  0.19707 -0.34618]
21Feb13_195919|Layer 1:
21Feb13_195919|-- Config --
21Feb13_195919|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_195919|-- Weights --
21Feb13_195919|[[-0.44514 -0.08425 -0.25456]
21Feb13_195919| [-1.05359 -0.95623  0.08659]
21Feb13_195919| [ 0.56276 -1.30721 -0.31449]
21Feb13_195919| [ 0.86216 -0.92706 -0.16242]]
21Feb13_195919|-- Bias --
21Feb13_195919|[ 0.84774 -1.12624  0.30544]
21Feb13_195919|Layer 2:
21Feb13_195919|-- Config --
21Feb13_195919|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_195919|-- Weights --
21Feb13_195919|[[ 0.45569 -0.38708]
21Feb13_195919| [-0.65573 -0.58254]
21Feb13_195919| [-0.23855 -0.05677]]
21Feb13_195919|-- Bias --
21Feb13_195919|[ 0.84507 -0.46860]
21Feb13_195919|Layer 3:
21Feb13_195919|-- Config --
21Feb13_195919|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_195919|-- Weights --
21Feb13_195919|[[ 0.73429  0.34384  0.35353 -0.30287]
21Feb13_195919| [-0.75329 -1.27485 -0.41900  0.22601]]
21Feb13_195919|-- Bias --
21Feb13_195919|[-0.95448  0.13450 -0.29140 -0.48520]
21Feb13_195919|Layer 4:
21Feb13_195919|-- Config --
21Feb13_195919|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_195919|-- Weights --
21Feb13_195919|[[-0.73824  0.43630]
21Feb13_195919| [-0.01328  0.34065]
21Feb13_195919| [ 0.22924 -0.30811]
21Feb13_195919| [-0.13534 -0.31318]]
21Feb13_195919|-- Bias --
21Feb13_195919|[-0.51373  0.76130]
21Feb13_195919|Predicting the validation and test data with the Best final individual.
21Feb13_195927| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_195927|-----------  ------------------  --------------------  ----------
21Feb13_195927|Validation         22.52                  52            0.65612
21Feb13_195927|   Test            27.45                  52            0.49666
21Feb13_195927|-------------------- Test #1 --------------------
21Feb13_195927|Best final individual weights
21Feb13_195927|Individual:
21Feb13_195927|-- Constant hidden layers --
21Feb13_195927|False
21Feb13_195927|Layer 0:
21Feb13_195927|-- Config --
21Feb13_195927|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_195927|-- Weights --
21Feb13_195927|[[-0.70147  1.81898 -1.19811 -0.98702]
21Feb13_195927| [ 0.12854  0.81408  0.25514  0.23353]
21Feb13_195927| [-0.76378 -0.76500  0.35248  0.26890]
21Feb13_195927| [ 1.64341  1.67169  0.03518 -0.20378]
21Feb13_195927| [ 0.22157 -0.61019  0.79588 -0.27345]
21Feb13_195927| [-1.23822 -1.86764 -1.85666  0.33678]
21Feb13_195927| [-0.97692  0.15098  0.30715  1.75219]
21Feb13_195927| [ 0.20395 -0.35022 -1.69279 -0.34243]
21Feb13_195927| [-0.24159 -0.14268  2.25383  0.68550]
21Feb13_195927| [-0.55194 -0.68549  0.80280 -0.60941]
21Feb13_195927| [-0.63201  0.46144  0.24282  2.20161]
21Feb13_195927| [-1.18622 -0.60422  0.26610 -0.70285]
21Feb13_195927| [ 0.60333  0.16633 -0.65080  0.11363]
21Feb13_195927| [ 0.36873  0.18594  0.36549  0.22051]
21Feb13_195927| [ 1.04502  0.19518 -0.43040  1.07351]
21Feb13_195927| [ 0.96694  0.14477 -1.02896  0.89242]
21Feb13_195927| [ 1.27167  0.01653  0.96997 -1.61365]
21Feb13_195927| [-1.59173 -0.22669 -1.11659  0.59352]
21Feb13_195927| [ 0.87703 -1.31311 -1.04639  0.94319]
21Feb13_195927| [ 0.87336  0.01591  0.70213 -1.77416]
21Feb13_195927| [ 2.19503 -1.36122 -1.48883  0.00411]
21Feb13_195927| [-0.85040  0.98617  2.14218 -0.12991]
21Feb13_195927| [ 1.25178 -0.36561  0.06305 -0.36145]
21Feb13_195927| [-2.58965  1.31141  1.10693 -0.55231]
21Feb13_195927| [ 0.59457  1.69880 -1.10262  1.36493]
21Feb13_195927| [-0.28694 -0.91882  0.92790 -0.77578]
21Feb13_195927| [ 0.55829  0.46047  0.83314 -0.61592]
21Feb13_195927| [ 0.34349  1.22218 -0.85430 -1.79906]
21Feb13_195927| [-0.28156 -0.80385  0.47478  0.95791]
21Feb13_195927| [ 0.89316  1.14094  0.47921  0.22448]
21Feb13_195927| [ 0.02193 -0.43600  0.87852  2.16496]
21Feb13_195927| [-1.31579  1.36006  0.18801  0.76711]
21Feb13_195927| [-0.00297  0.12555 -0.92105 -1.78211]
21Feb13_195927| [ 0.57371 -0.19964 -0.75235  0.20121]
21Feb13_195927| [-0.07073  1.32002 -0.15200  0.74027]
21Feb13_195927| [ 1.03756 -0.91348  0.02172  1.94365]
21Feb13_195927| [ 0.90723 -1.45536  0.11866 -1.84272]
21Feb13_195927| [-0.50110 -1.18639  1.25970 -0.55013]
21Feb13_195927| [ 0.98329 -0.40237 -0.83564  0.39022]
21Feb13_195927| [ 0.18550  0.63159 -0.20666 -1.04919]
21Feb13_195927| [ 0.92871 -1.14096 -1.51486  1.62599]
21Feb13_195927| [ 2.21129 -0.75264  1.54338 -0.82534]
21Feb13_195927| [-2.56190  0.75152  0.14857  1.17383]
21Feb13_195927| [ 1.03770  0.01148  0.25022 -1.28659]
21Feb13_195927| [ 2.16183  0.47029  0.01741 -0.98632]
21Feb13_195927| [-0.08188 -0.86313  2.36805 -1.03742]
21Feb13_195927| [-0.08347  1.55004  0.04645 -2.86549]
21Feb13_195927| [-0.70867 -0.69114 -0.70866 -0.67093]
21Feb13_195927| [-0.14483  0.37071  0.04424  2.13613]
21Feb13_195927| [-0.14117  0.20703 -0.41044  1.72514]
21Feb13_195927| [ 0.84550  0.84911  0.28784 -2.20851]
21Feb13_195927| [ 0.10779 -2.36073 -0.21111  2.16331]
21Feb13_195927| [ 0.56615 -0.57729  1.36509  1.07720]
21Feb13_195927| [ 0.58032 -0.61085 -0.68982  0.73322]
21Feb13_195927| [-0.89739  0.52350 -0.68521 -0.63787]
21Feb13_195927| [-0.74391 -0.23943  0.66873  0.46393]
21Feb13_195927| [ 0.65107 -0.95629 -0.15588  0.30563]]
21Feb13_195927|-- Bias --
21Feb13_195927|[-1.06816  1.50470  0.19707 -0.34618]
21Feb13_195927|Layer 1:
21Feb13_195927|-- Config --
21Feb13_195927|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_195927|-- Weights --
21Feb13_195927|[[-0.44514 -0.08425 -0.25456]
21Feb13_195927| [-1.05359 -0.95623  0.08659]
21Feb13_195927| [ 0.56276 -1.30721 -0.31449]
21Feb13_195927| [ 0.86216 -0.92706 -0.16242]]
21Feb13_195927|-- Bias --
21Feb13_195927|[ 0.84774 -1.12624  0.30544]
21Feb13_195927|Layer 2:
21Feb13_195927|-- Config --
21Feb13_195927|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_195927|-- Weights --
21Feb13_195927|[[ 0.45569 -0.38708]
21Feb13_195927| [-0.65573 -0.58254]
21Feb13_195927| [-0.23855 -0.05677]]
21Feb13_195927|-- Bias --
21Feb13_195927|[ 0.84507 -0.46860]
21Feb13_195927|Layer 3:
21Feb13_195927|-- Config --
21Feb13_195927|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_195927|-- Weights --
21Feb13_195927|[[ 0.73429  0.34384  0.35353 -0.30287]
21Feb13_195927| [-0.75329 -1.27485 -0.41900  0.22601]]
21Feb13_195927|-- Bias --
21Feb13_195927|[-0.95448  0.13450 -0.29140 -0.48520]
21Feb13_195927|Layer 4:
21Feb13_195927|-- Config --
21Feb13_195927|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_195927|-- Weights --
21Feb13_195927|[[-0.73824  0.43630]
21Feb13_195927| [-0.01328  0.34065]
21Feb13_195927| [ 0.22924 -0.30811]
21Feb13_195927| [-0.13534 -0.31318]]
21Feb13_195927|-- Bias --
21Feb13_195927|[-0.51373  0.76130]
21Feb13_195927|Predicting the validation and test data with the Best final individual.
21Feb13_195935| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_195935|-----------  ------------------  --------------------  ----------
21Feb13_195935|Validation         25.39                  52            0.55529
21Feb13_195935|   Test            24.59                  52            0.53135
21Feb13_195935|-------------------- Test #2 --------------------
21Feb13_195935|Best final individual weights
21Feb13_195935|Individual:
21Feb13_195935|-- Constant hidden layers --
21Feb13_195935|False
21Feb13_195935|Layer 0:
21Feb13_195935|-- Config --
21Feb13_195935|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_195935|-- Weights --
21Feb13_195935|[[-0.70147  1.81898 -1.19811 -0.98702]
21Feb13_195935| [ 0.12854  0.81408  0.25514  0.23353]
21Feb13_195935| [-0.76378 -0.76500  0.35248  0.26890]
21Feb13_195935| [ 1.64341  1.67169  0.03518 -0.20378]
21Feb13_195935| [ 0.22157 -0.61019  0.79588 -0.27345]
21Feb13_195935| [-1.23822 -1.86764 -1.85666  0.33678]
21Feb13_195935| [-0.97692  0.15098  0.30715  1.75219]
21Feb13_195935| [ 0.20395 -0.35022 -1.69279 -0.34243]
21Feb13_195935| [-0.24159 -0.14268  2.25383  0.68550]
21Feb13_195935| [-0.55194 -0.68549  0.80280 -0.60941]
21Feb13_195935| [-0.63201  0.46144  0.24282  2.20161]
21Feb13_195935| [-1.18622 -0.60422  0.26610 -0.70285]
21Feb13_195935| [ 0.60333  0.16633 -0.65080  0.11363]
21Feb13_195935| [ 0.36873  0.18594  0.36549  0.22051]
21Feb13_195935| [ 1.04502  0.19518 -0.43040  1.07351]
21Feb13_195935| [ 0.96694  0.14477 -1.02896  0.89242]
21Feb13_195935| [ 1.27167  0.01653  0.96997 -1.61365]
21Feb13_195935| [-1.59173 -0.22669 -1.11659  0.59352]
21Feb13_195935| [ 0.87703 -1.31311 -1.04639  0.94319]
21Feb13_195935| [ 0.87336  0.01591  0.70213 -1.77416]
21Feb13_195935| [ 2.19503 -1.36122 -1.48883  0.00411]
21Feb13_195935| [-0.85040  0.98617  2.14218 -0.12991]
21Feb13_195935| [ 1.25178 -0.36561  0.06305 -0.36145]
21Feb13_195935| [-2.58965  1.31141  1.10693 -0.55231]
21Feb13_195935| [ 0.59457  1.69880 -1.10262  1.36493]
21Feb13_195935| [-0.28694 -0.91882  0.92790 -0.77578]
21Feb13_195935| [ 0.55829  0.46047  0.83314 -0.61592]
21Feb13_195935| [ 0.34349  1.22218 -0.85430 -1.79906]
21Feb13_195935| [-0.28156 -0.80385  0.47478  0.95791]
21Feb13_195935| [ 0.89316  1.14094  0.47921  0.22448]
21Feb13_195935| [ 0.02193 -0.43600  0.87852  2.16496]
21Feb13_195935| [-1.31579  1.36006  0.18801  0.76711]
21Feb13_195935| [-0.00297  0.12555 -0.92105 -1.78211]
21Feb13_195935| [ 0.57371 -0.19964 -0.75235  0.20121]
21Feb13_195935| [-0.07073  1.32002 -0.15200  0.74027]
21Feb13_195935| [ 1.03756 -0.91348  0.02172  1.94365]
21Feb13_195935| [ 0.90723 -1.45536  0.11866 -1.84272]
21Feb13_195935| [-0.50110 -1.18639  1.25970 -0.55013]
21Feb13_195935| [ 0.98329 -0.40237 -0.83564  0.39022]
21Feb13_195935| [ 0.18550  0.63159 -0.20666 -1.04919]
21Feb13_195935| [ 0.92871 -1.14096 -1.51486  1.62599]
21Feb13_195935| [ 2.21129 -0.75264  1.54338 -0.82534]
21Feb13_195935| [-2.56190  0.75152  0.14857  1.17383]
21Feb13_195935| [ 1.03770  0.01148  0.25022 -1.28659]
21Feb13_195935| [ 2.16183  0.47029  0.01741 -0.98632]
21Feb13_195935| [-0.08188 -0.86313  2.36805 -1.03742]
21Feb13_195935| [-0.08347  1.55004  0.04645 -2.86549]
21Feb13_195935| [-0.70867 -0.69114 -0.70866 -0.67093]
21Feb13_195935| [-0.14483  0.37071  0.04424  2.13613]
21Feb13_195935| [-0.14117  0.20703 -0.41044  1.72514]
21Feb13_195935| [ 0.84550  0.84911  0.28784 -2.20851]
21Feb13_195935| [ 0.10779 -2.36073 -0.21111  2.16331]
21Feb13_195935| [ 0.56615 -0.57729  1.36509  1.07720]
21Feb13_195935| [ 0.58032 -0.61085 -0.68982  0.73322]
21Feb13_195935| [-0.89739  0.52350 -0.68521 -0.63787]
21Feb13_195935| [-0.74391 -0.23943  0.66873  0.46393]
21Feb13_195935| [ 0.65107 -0.95629 -0.15588  0.30563]]
21Feb13_195935|-- Bias --
21Feb13_195935|[-1.06816  1.50470  0.19707 -0.34618]
21Feb13_195935|Layer 1:
21Feb13_195935|-- Config --
21Feb13_195935|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_195935|-- Weights --
21Feb13_195935|[[-0.44514 -0.08425 -0.25456]
21Feb13_195935| [-1.05359 -0.95623  0.08659]
21Feb13_195935| [ 0.56276 -1.30721 -0.31449]
21Feb13_195935| [ 0.86216 -0.92706 -0.16242]]
21Feb13_195935|-- Bias --
21Feb13_195935|[ 0.84774 -1.12624  0.30544]
21Feb13_195935|Layer 2:
21Feb13_195935|-- Config --
21Feb13_195935|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_195935|-- Weights --
21Feb13_195935|[[ 0.45569 -0.38708]
21Feb13_195935| [-0.65573 -0.58254]
21Feb13_195935| [-0.23855 -0.05677]]
21Feb13_195935|-- Bias --
21Feb13_195935|[ 0.84507 -0.46860]
21Feb13_195935|Layer 3:
21Feb13_195935|-- Config --
21Feb13_195935|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_195935|-- Weights --
21Feb13_195935|[[ 0.73429  0.34384  0.35353 -0.30287]
21Feb13_195935| [-0.75329 -1.27485 -0.41900  0.22601]]
21Feb13_195935|-- Bias --
21Feb13_195935|[-0.95448  0.13450 -0.29140 -0.48520]
21Feb13_195935|Layer 4:
21Feb13_195935|-- Config --
21Feb13_195935|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_195935|-- Weights --
21Feb13_195935|[[-0.73824  0.43630]
21Feb13_195935| [-0.01328  0.34065]
21Feb13_195935| [ 0.22924 -0.30811]
21Feb13_195935| [-0.13534 -0.31318]]
21Feb13_195935|-- Bias --
21Feb13_195935|[-0.51373  0.76130]
21Feb13_195935|Predicting the validation and test data with the Best final individual.
21Feb13_195943| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_195943|-----------  ------------------  --------------------  ----------
21Feb13_195943|Validation         21.22                  52            0.71103
21Feb13_195943|   Test            25.02                  52            0.81081
21Feb13_195943|-------------------- Test #3 --------------------
21Feb13_195943|Best final individual weights
21Feb13_195943|Individual:
21Feb13_195943|-- Constant hidden layers --
21Feb13_195943|False
21Feb13_195943|Layer 0:
21Feb13_195943|-- Config --
21Feb13_195943|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_195943|-- Weights --
21Feb13_195943|[[-0.70147  1.81898 -1.19811 -0.98702]
21Feb13_195943| [ 0.12854  0.81408  0.25514  0.23353]
21Feb13_195943| [-0.76378 -0.76500  0.35248  0.26890]
21Feb13_195943| [ 1.64341  1.67169  0.03518 -0.20378]
21Feb13_195943| [ 0.22157 -0.61019  0.79588 -0.27345]
21Feb13_195943| [-1.23822 -1.86764 -1.85666  0.33678]
21Feb13_195943| [-0.97692  0.15098  0.30715  1.75219]
21Feb13_195943| [ 0.20395 -0.35022 -1.69279 -0.34243]
21Feb13_195943| [-0.24159 -0.14268  2.25383  0.68550]
21Feb13_195943| [-0.55194 -0.68549  0.80280 -0.60941]
21Feb13_195943| [-0.63201  0.46144  0.24282  2.20161]
21Feb13_195943| [-1.18622 -0.60422  0.26610 -0.70285]
21Feb13_195943| [ 0.60333  0.16633 -0.65080  0.11363]
21Feb13_195943| [ 0.36873  0.18594  0.36549  0.22051]
21Feb13_195943| [ 1.04502  0.19518 -0.43040  1.07351]
21Feb13_195943| [ 0.96694  0.14477 -1.02896  0.89242]
21Feb13_195943| [ 1.27167  0.01653  0.96997 -1.61365]
21Feb13_195943| [-1.59173 -0.22669 -1.11659  0.59352]
21Feb13_195943| [ 0.87703 -1.31311 -1.04639  0.94319]
21Feb13_195943| [ 0.87336  0.01591  0.70213 -1.77416]
21Feb13_195943| [ 2.19503 -1.36122 -1.48883  0.00411]
21Feb13_195943| [-0.85040  0.98617  2.14218 -0.12991]
21Feb13_195943| [ 1.25178 -0.36561  0.06305 -0.36145]
21Feb13_195943| [-2.58965  1.31141  1.10693 -0.55231]
21Feb13_195943| [ 0.59457  1.69880 -1.10262  1.36493]
21Feb13_195943| [-0.28694 -0.91882  0.92790 -0.77578]
21Feb13_195943| [ 0.55829  0.46047  0.83314 -0.61592]
21Feb13_195943| [ 0.34349  1.22218 -0.85430 -1.79906]
21Feb13_195943| [-0.28156 -0.80385  0.47478  0.95791]
21Feb13_195943| [ 0.89316  1.14094  0.47921  0.22448]
21Feb13_195943| [ 0.02193 -0.43600  0.87852  2.16496]
21Feb13_195943| [-1.31579  1.36006  0.18801  0.76711]
21Feb13_195943| [-0.00297  0.12555 -0.92105 -1.78211]
21Feb13_195943| [ 0.57371 -0.19964 -0.75235  0.20121]
21Feb13_195943| [-0.07073  1.32002 -0.15200  0.74027]
21Feb13_195943| [ 1.03756 -0.91348  0.02172  1.94365]
21Feb13_195943| [ 0.90723 -1.45536  0.11866 -1.84272]
21Feb13_195943| [-0.50110 -1.18639  1.25970 -0.55013]
21Feb13_195943| [ 0.98329 -0.40237 -0.83564  0.39022]
21Feb13_195943| [ 0.18550  0.63159 -0.20666 -1.04919]
21Feb13_195943| [ 0.92871 -1.14096 -1.51486  1.62599]
21Feb13_195943| [ 2.21129 -0.75264  1.54338 -0.82534]
21Feb13_195943| [-2.56190  0.75152  0.14857  1.17383]
21Feb13_195943| [ 1.03770  0.01148  0.25022 -1.28659]
21Feb13_195943| [ 2.16183  0.47029  0.01741 -0.98632]
21Feb13_195943| [-0.08188 -0.86313  2.36805 -1.03742]
21Feb13_195943| [-0.08347  1.55004  0.04645 -2.86549]
21Feb13_195943| [-0.70867 -0.69114 -0.70866 -0.67093]
21Feb13_195944| [-0.14483  0.37071  0.04424  2.13613]
21Feb13_195944| [-0.14117  0.20703 -0.41044  1.72514]
21Feb13_195944| [ 0.84550  0.84911  0.28784 -2.20851]
21Feb13_195944| [ 0.10779 -2.36073 -0.21111  2.16331]
21Feb13_195944| [ 0.56615 -0.57729  1.36509  1.07720]
21Feb13_195944| [ 0.58032 -0.61085 -0.68982  0.73322]
21Feb13_195944| [-0.89739  0.52350 -0.68521 -0.63787]
21Feb13_195944| [-0.74391 -0.23943  0.66873  0.46393]
21Feb13_195944| [ 0.65107 -0.95629 -0.15588  0.30563]]
21Feb13_195944|-- Bias --
21Feb13_195944|[-1.06816  1.50470  0.19707 -0.34618]
21Feb13_195944|Layer 1:
21Feb13_195944|-- Config --
21Feb13_195944|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_195944|-- Weights --
21Feb13_195944|[[-0.44514 -0.08425 -0.25456]
21Feb13_195944| [-1.05359 -0.95623  0.08659]
21Feb13_195944| [ 0.56276 -1.30721 -0.31449]
21Feb13_195944| [ 0.86216 -0.92706 -0.16242]]
21Feb13_195944|-- Bias --
21Feb13_195944|[ 0.84774 -1.12624  0.30544]
21Feb13_195944|Layer 2:
21Feb13_195944|-- Config --
21Feb13_195944|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_195944|-- Weights --
21Feb13_195944|[[ 0.45569 -0.38708]
21Feb13_195944| [-0.65573 -0.58254]
21Feb13_195944| [-0.23855 -0.05677]]
21Feb13_195944|-- Bias --
21Feb13_195944|[ 0.84507 -0.46860]
21Feb13_195944|Layer 3:
21Feb13_195944|-- Config --
21Feb13_195944|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_195944|-- Weights --
21Feb13_195944|[[ 0.73429  0.34384  0.35353 -0.30287]
21Feb13_195944| [-0.75329 -1.27485 -0.41900  0.22601]]
21Feb13_195944|-- Bias --
21Feb13_195944|[-0.95448  0.13450 -0.29140 -0.48520]
21Feb13_195944|Layer 4:
21Feb13_195944|-- Config --
21Feb13_195944|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_195944|-- Weights --
21Feb13_195944|[[-0.73824  0.43630]
21Feb13_195944| [-0.01328  0.34065]
21Feb13_195944| [ 0.22924 -0.30811]
21Feb13_195944| [-0.13534 -0.31318]]
21Feb13_195944|-- Bias --
21Feb13_195944|[-0.51373  0.76130]
21Feb13_195944|Predicting the validation and test data with the Best final individual.
21Feb13_195952| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_195952|-----------  ------------------  --------------------  ----------
21Feb13_195952|Validation         37.83                  52            0.81515
21Feb13_195952|   Test            27.28                  52            0.47193
21Feb13_195952|-------------------- Test #4 --------------------
21Feb13_195952|Best final individual weights
21Feb13_195952|Individual:
21Feb13_195952|-- Constant hidden layers --
21Feb13_195952|False
21Feb13_195952|Layer 0:
21Feb13_195952|-- Config --
21Feb13_195952|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_195952|-- Weights --
21Feb13_195952|[[-0.70147  1.81898 -1.19811 -0.98702]
21Feb13_195952| [ 0.12854  0.81408  0.25514  0.23353]
21Feb13_195952| [-0.76378 -0.76500  0.35248  0.26890]
21Feb13_195952| [ 1.64341  1.67169  0.03518 -0.20378]
21Feb13_195952| [ 0.22157 -0.61019  0.79588 -0.27345]
21Feb13_195952| [-1.23822 -1.86764 -1.85666  0.33678]
21Feb13_195952| [-0.97692  0.15098  0.30715  1.75219]
21Feb13_195952| [ 0.20395 -0.35022 -1.69279 -0.34243]
21Feb13_195952| [-0.24159 -0.14268  2.25383  0.68550]
21Feb13_195952| [-0.55194 -0.68549  0.80280 -0.60941]
21Feb13_195952| [-0.63201  0.46144  0.24282  2.20161]
21Feb13_195952| [-1.18622 -0.60422  0.26610 -0.70285]
21Feb13_195952| [ 0.60333  0.16633 -0.65080  0.11363]
21Feb13_195952| [ 0.36873  0.18594  0.36549  0.22051]
21Feb13_195952| [ 1.04502  0.19518 -0.43040  1.07351]
21Feb13_195952| [ 0.96694  0.14477 -1.02896  0.89242]
21Feb13_195952| [ 1.27167  0.01653  0.96997 -1.61365]
21Feb13_195952| [-1.59173 -0.22669 -1.11659  0.59352]
21Feb13_195952| [ 0.87703 -1.31311 -1.04639  0.94319]
21Feb13_195952| [ 0.87336  0.01591  0.70213 -1.77416]
21Feb13_195952| [ 2.19503 -1.36122 -1.48883  0.00411]
21Feb13_195952| [-0.85040  0.98617  2.14218 -0.12991]
21Feb13_195952| [ 1.25178 -0.36561  0.06305 -0.36145]
21Feb13_195952| [-2.58965  1.31141  1.10693 -0.55231]
21Feb13_195952| [ 0.59457  1.69880 -1.10262  1.36493]
21Feb13_195952| [-0.28694 -0.91882  0.92790 -0.77578]
21Feb13_195952| [ 0.55829  0.46047  0.83314 -0.61592]
21Feb13_195952| [ 0.34349  1.22218 -0.85430 -1.79906]
21Feb13_195952| [-0.28156 -0.80385  0.47478  0.95791]
21Feb13_195952| [ 0.89316  1.14094  0.47921  0.22448]
21Feb13_195952| [ 0.02193 -0.43600  0.87852  2.16496]
21Feb13_195952| [-1.31579  1.36006  0.18801  0.76711]
21Feb13_195952| [-0.00297  0.12555 -0.92105 -1.78211]
21Feb13_195952| [ 0.57371 -0.19964 -0.75235  0.20121]
21Feb13_195952| [-0.07073  1.32002 -0.15200  0.74027]
21Feb13_195952| [ 1.03756 -0.91348  0.02172  1.94365]
21Feb13_195952| [ 0.90723 -1.45536  0.11866 -1.84272]
21Feb13_195952| [-0.50110 -1.18639  1.25970 -0.55013]
21Feb13_195952| [ 0.98329 -0.40237 -0.83564  0.39022]
21Feb13_195952| [ 0.18550  0.63159 -0.20666 -1.04919]
21Feb13_195952| [ 0.92871 -1.14096 -1.51486  1.62599]
21Feb13_195952| [ 2.21129 -0.75264  1.54338 -0.82534]
21Feb13_195952| [-2.56190  0.75152  0.14857  1.17383]
21Feb13_195952| [ 1.03770  0.01148  0.25022 -1.28659]
21Feb13_195952| [ 2.16183  0.47029  0.01741 -0.98632]
21Feb13_195952| [-0.08188 -0.86313  2.36805 -1.03742]
21Feb13_195952| [-0.08347  1.55004  0.04645 -2.86549]
21Feb13_195952| [-0.70867 -0.69114 -0.70866 -0.67093]
21Feb13_195952| [-0.14483  0.37071  0.04424  2.13613]
21Feb13_195952| [-0.14117  0.20703 -0.41044  1.72514]
21Feb13_195952| [ 0.84550  0.84911  0.28784 -2.20851]
21Feb13_195952| [ 0.10779 -2.36073 -0.21111  2.16331]
21Feb13_195952| [ 0.56615 -0.57729  1.36509  1.07720]
21Feb13_195952| [ 0.58032 -0.61085 -0.68982  0.73322]
21Feb13_195952| [-0.89739  0.52350 -0.68521 -0.63787]
21Feb13_195952| [-0.74391 -0.23943  0.66873  0.46393]
21Feb13_195952| [ 0.65107 -0.95629 -0.15588  0.30563]]
21Feb13_195952|-- Bias --
21Feb13_195952|[-1.06816  1.50470  0.19707 -0.34618]
21Feb13_195952|Layer 1:
21Feb13_195952|-- Config --
21Feb13_195952|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_195952|-- Weights --
21Feb13_195952|[[-0.44514 -0.08425 -0.25456]
21Feb13_195952| [-1.05359 -0.95623  0.08659]
21Feb13_195952| [ 0.56276 -1.30721 -0.31449]
21Feb13_195952| [ 0.86216 -0.92706 -0.16242]]
21Feb13_195952|-- Bias --
21Feb13_195952|[ 0.84774 -1.12624  0.30544]
21Feb13_195952|Layer 2:
21Feb13_195952|-- Config --
21Feb13_195952|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_195952|-- Weights --
21Feb13_195952|[[ 0.45569 -0.38708]
21Feb13_195952| [-0.65573 -0.58254]
21Feb13_195952| [-0.23855 -0.05677]]
21Feb13_195952|-- Bias --
21Feb13_195952|[ 0.84507 -0.46860]
21Feb13_195952|Layer 3:
21Feb13_195952|-- Config --
21Feb13_195952|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_195952|-- Weights --
21Feb13_195952|[[ 0.73429  0.34384  0.35353 -0.30287]
21Feb13_195952| [-0.75329 -1.27485 -0.41900  0.22601]]
21Feb13_195952|-- Bias --
21Feb13_195952|[-0.95448  0.13450 -0.29140 -0.48520]
21Feb13_195952|Layer 4:
21Feb13_195952|-- Config --
21Feb13_195952|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_195952|-- Weights --
21Feb13_195952|[[-0.73824  0.43630]
21Feb13_195952| [-0.01328  0.34065]
21Feb13_195952| [ 0.22924 -0.30811]
21Feb13_195952| [-0.13534 -0.31318]]
21Feb13_195952|-- Bias --
21Feb13_195952|[-0.51373  0.76130]
21Feb13_195952|Predicting the validation and test data with the Best final individual.
21Feb13_200000| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_200000|-----------  ------------------  --------------------  ----------
21Feb13_200000|Validation         21.74                  52            0.65716
21Feb13_200000|   Test            27.80                  52            0.48225
21Feb13_200000|-------------------- Test #5 --------------------
21Feb13_200000|Best final individual weights
21Feb13_200000|Individual:
21Feb13_200000|-- Constant hidden layers --
21Feb13_200000|False
21Feb13_200000|Layer 0:
21Feb13_200000|-- Config --
21Feb13_200000|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200000|-- Weights --
21Feb13_200000|[[-0.70147  1.81898 -1.19811 -0.98702]
21Feb13_200000| [ 0.12854  0.81408  0.25514  0.23353]
21Feb13_200000| [-0.76378 -0.76500  0.35248  0.26890]
21Feb13_200000| [ 1.64341  1.67169  0.03518 -0.20378]
21Feb13_200000| [ 0.22157 -0.61019  0.79588 -0.27345]
21Feb13_200000| [-1.23822 -1.86764 -1.85666  0.33678]
21Feb13_200000| [-0.97692  0.15098  0.30715  1.75219]
21Feb13_200000| [ 0.20395 -0.35022 -1.69279 -0.34243]
21Feb13_200000| [-0.24159 -0.14268  2.25383  0.68550]
21Feb13_200000| [-0.55194 -0.68549  0.80280 -0.60941]
21Feb13_200000| [-0.63201  0.46144  0.24282  2.20161]
21Feb13_200000| [-1.18622 -0.60422  0.26610 -0.70285]
21Feb13_200000| [ 0.60333  0.16633 -0.65080  0.11363]
21Feb13_200000| [ 0.36873  0.18594  0.36549  0.22051]
21Feb13_200000| [ 1.04502  0.19518 -0.43040  1.07351]
21Feb13_200000| [ 0.96694  0.14477 -1.02896  0.89242]
21Feb13_200000| [ 1.27167  0.01653  0.96997 -1.61365]
21Feb13_200000| [-1.59173 -0.22669 -1.11659  0.59352]
21Feb13_200000| [ 0.87703 -1.31311 -1.04639  0.94319]
21Feb13_200000| [ 0.87336  0.01591  0.70213 -1.77416]
21Feb13_200000| [ 2.19503 -1.36122 -1.48883  0.00411]
21Feb13_200000| [-0.85040  0.98617  2.14218 -0.12991]
21Feb13_200000| [ 1.25178 -0.36561  0.06305 -0.36145]
21Feb13_200000| [-2.58965  1.31141  1.10693 -0.55231]
21Feb13_200000| [ 0.59457  1.69880 -1.10262  1.36493]
21Feb13_200000| [-0.28694 -0.91882  0.92790 -0.77578]
21Feb13_200000| [ 0.55829  0.46047  0.83314 -0.61592]
21Feb13_200000| [ 0.34349  1.22218 -0.85430 -1.79906]
21Feb13_200000| [-0.28156 -0.80385  0.47478  0.95791]
21Feb13_200000| [ 0.89316  1.14094  0.47921  0.22448]
21Feb13_200000| [ 0.02193 -0.43600  0.87852  2.16496]
21Feb13_200000| [-1.31579  1.36006  0.18801  0.76711]
21Feb13_200000| [-0.00297  0.12555 -0.92105 -1.78211]
21Feb13_200000| [ 0.57371 -0.19964 -0.75235  0.20121]
21Feb13_200000| [-0.07073  1.32002 -0.15200  0.74027]
21Feb13_200000| [ 1.03756 -0.91348  0.02172  1.94365]
21Feb13_200000| [ 0.90723 -1.45536  0.11866 -1.84272]
21Feb13_200000| [-0.50110 -1.18639  1.25970 -0.55013]
21Feb13_200000| [ 0.98329 -0.40237 -0.83564  0.39022]
21Feb13_200000| [ 0.18550  0.63159 -0.20666 -1.04919]
21Feb13_200000| [ 0.92871 -1.14096 -1.51486  1.62599]
21Feb13_200000| [ 2.21129 -0.75264  1.54338 -0.82534]
21Feb13_200000| [-2.56190  0.75152  0.14857  1.17383]
21Feb13_200000| [ 1.03770  0.01148  0.25022 -1.28659]
21Feb13_200000| [ 2.16183  0.47029  0.01741 -0.98632]
21Feb13_200000| [-0.08188 -0.86313  2.36805 -1.03742]
21Feb13_200000| [-0.08347  1.55004  0.04645 -2.86549]
21Feb13_200000| [-0.70867 -0.69114 -0.70866 -0.67093]
21Feb13_200000| [-0.14483  0.37071  0.04424  2.13613]
21Feb13_200000| [-0.14117  0.20703 -0.41044  1.72514]
21Feb13_200000| [ 0.84550  0.84911  0.28784 -2.20851]
21Feb13_200000| [ 0.10779 -2.36073 -0.21111  2.16331]
21Feb13_200000| [ 0.56615 -0.57729  1.36509  1.07720]
21Feb13_200000| [ 0.58032 -0.61085 -0.68982  0.73322]
21Feb13_200000| [-0.89739  0.52350 -0.68521 -0.63787]
21Feb13_200000| [-0.74391 -0.23943  0.66873  0.46393]
21Feb13_200000| [ 0.65107 -0.95629 -0.15588  0.30563]]
21Feb13_200000|-- Bias --
21Feb13_200000|[-1.06816  1.50470  0.19707 -0.34618]
21Feb13_200000|Layer 1:
21Feb13_200000|-- Config --
21Feb13_200000|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200000|-- Weights --
21Feb13_200000|[[-0.44514 -0.08425 -0.25456]
21Feb13_200000| [-1.05359 -0.95623  0.08659]
21Feb13_200000| [ 0.56276 -1.30721 -0.31449]
21Feb13_200000| [ 0.86216 -0.92706 -0.16242]]
21Feb13_200000|-- Bias --
21Feb13_200000|[ 0.84774 -1.12624  0.30544]
21Feb13_200000|Layer 2:
21Feb13_200000|-- Config --
21Feb13_200000|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200000|-- Weights --
21Feb13_200000|[[ 0.45569 -0.38708]
21Feb13_200000| [-0.65573 -0.58254]
21Feb13_200000| [-0.23855 -0.05677]]
21Feb13_200000|-- Bias --
21Feb13_200000|[ 0.84507 -0.46860]
21Feb13_200000|Layer 3:
21Feb13_200000|-- Config --
21Feb13_200000|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200000|-- Weights --
21Feb13_200000|[[ 0.73429  0.34384  0.35353 -0.30287]
21Feb13_200000| [-0.75329 -1.27485 -0.41900  0.22601]]
21Feb13_200000|-- Bias --
21Feb13_200000|[-0.95448  0.13450 -0.29140 -0.48520]
21Feb13_200000|Layer 4:
21Feb13_200000|-- Config --
21Feb13_200000|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200000|-- Weights --
21Feb13_200000|[[-0.73824  0.43630]
21Feb13_200000| [-0.01328  0.34065]
21Feb13_200000| [ 0.22924 -0.30811]
21Feb13_200000| [-0.13534 -0.31318]]
21Feb13_200000|-- Bias --
21Feb13_200000|[-0.51373  0.76130]
21Feb13_200000|Predicting the validation and test data with the Best final individual.
21Feb13_200008| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_200008|-----------  ------------------  --------------------  ----------
21Feb13_200008|Validation         31.30                  52            0.25320
21Feb13_200008|   Test            28.50                  52            0.53488
21Feb13_200008|-------------------- Test #6 --------------------
21Feb13_200008|Best final individual weights
21Feb13_200008|Individual:
21Feb13_200008|-- Constant hidden layers --
21Feb13_200008|False
21Feb13_200008|Layer 0:
21Feb13_200008|-- Config --
21Feb13_200008|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200008|-- Weights --
21Feb13_200008|[[-0.70147  1.81898 -1.19811 -0.98702]
21Feb13_200008| [ 0.12854  0.81408  0.25514  0.23353]
21Feb13_200008| [-0.76378 -0.76500  0.35248  0.26890]
21Feb13_200008| [ 1.64341  1.67169  0.03518 -0.20378]
21Feb13_200008| [ 0.22157 -0.61019  0.79588 -0.27345]
21Feb13_200008| [-1.23822 -1.86764 -1.85666  0.33678]
21Feb13_200008| [-0.97692  0.15098  0.30715  1.75219]
21Feb13_200008| [ 0.20395 -0.35022 -1.69279 -0.34243]
21Feb13_200008| [-0.24159 -0.14268  2.25383  0.68550]
21Feb13_200008| [-0.55194 -0.68549  0.80280 -0.60941]
21Feb13_200008| [-0.63201  0.46144  0.24282  2.20161]
21Feb13_200008| [-1.18622 -0.60422  0.26610 -0.70285]
21Feb13_200008| [ 0.60333  0.16633 -0.65080  0.11363]
21Feb13_200008| [ 0.36873  0.18594  0.36549  0.22051]
21Feb13_200008| [ 1.04502  0.19518 -0.43040  1.07351]
21Feb13_200008| [ 0.96694  0.14477 -1.02896  0.89242]
21Feb13_200008| [ 1.27167  0.01653  0.96997 -1.61365]
21Feb13_200008| [-1.59173 -0.22669 -1.11659  0.59352]
21Feb13_200008| [ 0.87703 -1.31311 -1.04639  0.94319]
21Feb13_200008| [ 0.87336  0.01591  0.70213 -1.77416]
21Feb13_200008| [ 2.19503 -1.36122 -1.48883  0.00411]
21Feb13_200008| [-0.85040  0.98617  2.14218 -0.12991]
21Feb13_200008| [ 1.25178 -0.36561  0.06305 -0.36145]
21Feb13_200008| [-2.58965  1.31141  1.10693 -0.55231]
21Feb13_200008| [ 0.59457  1.69880 -1.10262  1.36493]
21Feb13_200008| [-0.28694 -0.91882  0.92790 -0.77578]
21Feb13_200008| [ 0.55829  0.46047  0.83314 -0.61592]
21Feb13_200008| [ 0.34349  1.22218 -0.85430 -1.79906]
21Feb13_200008| [-0.28156 -0.80385  0.47478  0.95791]
21Feb13_200008| [ 0.89316  1.14094  0.47921  0.22448]
21Feb13_200008| [ 0.02193 -0.43600  0.87852  2.16496]
21Feb13_200008| [-1.31579  1.36006  0.18801  0.76711]
21Feb13_200008| [-0.00297  0.12555 -0.92105 -1.78211]
21Feb13_200008| [ 0.57371 -0.19964 -0.75235  0.20121]
21Feb13_200008| [-0.07073  1.32002 -0.15200  0.74027]
21Feb13_200008| [ 1.03756 -0.91348  0.02172  1.94365]
21Feb13_200008| [ 0.90723 -1.45536  0.11866 -1.84272]
21Feb13_200008| [-0.50110 -1.18639  1.25970 -0.55013]
21Feb13_200008| [ 0.98329 -0.40237 -0.83564  0.39022]
21Feb13_200008| [ 0.18550  0.63159 -0.20666 -1.04919]
21Feb13_200008| [ 0.92871 -1.14096 -1.51486  1.62599]
21Feb13_200008| [ 2.21129 -0.75264  1.54338 -0.82534]
21Feb13_200008| [-2.56190  0.75152  0.14857  1.17383]
21Feb13_200008| [ 1.03770  0.01148  0.25022 -1.28659]
21Feb13_200008| [ 2.16183  0.47029  0.01741 -0.98632]
21Feb13_200008| [-0.08188 -0.86313  2.36805 -1.03742]
21Feb13_200008| [-0.08347  1.55004  0.04645 -2.86549]
21Feb13_200008| [-0.70867 -0.69114 -0.70866 -0.67093]
21Feb13_200008| [-0.14483  0.37071  0.04424  2.13613]
21Feb13_200008| [-0.14117  0.20703 -0.41044  1.72514]
21Feb13_200008| [ 0.84550  0.84911  0.28784 -2.20851]
21Feb13_200008| [ 0.10779 -2.36073 -0.21111  2.16331]
21Feb13_200008| [ 0.56615 -0.57729  1.36509  1.07720]
21Feb13_200008| [ 0.58032 -0.61085 -0.68982  0.73322]
21Feb13_200008| [-0.89739  0.52350 -0.68521 -0.63787]
21Feb13_200008| [-0.74391 -0.23943  0.66873  0.46393]
21Feb13_200008| [ 0.65107 -0.95629 -0.15588  0.30563]]
21Feb13_200008|-- Bias --
21Feb13_200008|[-1.06816  1.50470  0.19707 -0.34618]
21Feb13_200008|Layer 1:
21Feb13_200008|-- Config --
21Feb13_200008|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200008|-- Weights --
21Feb13_200008|[[-0.44514 -0.08425 -0.25456]
21Feb13_200008| [-1.05359 -0.95623  0.08659]
21Feb13_200008| [ 0.56276 -1.30721 -0.31449]
21Feb13_200008| [ 0.86216 -0.92706 -0.16242]]
21Feb13_200008|-- Bias --
21Feb13_200008|[ 0.84774 -1.12624  0.30544]
21Feb13_200008|Layer 2:
21Feb13_200008|-- Config --
21Feb13_200008|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200008|-- Weights --
21Feb13_200008|[[ 0.45569 -0.38708]
21Feb13_200008| [-0.65573 -0.58254]
21Feb13_200008| [-0.23855 -0.05677]]
21Feb13_200008|-- Bias --
21Feb13_200008|[ 0.84507 -0.46860]
21Feb13_200008|Layer 3:
21Feb13_200008|-- Config --
21Feb13_200008|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200008|-- Weights --
21Feb13_200008|[[ 0.73429  0.34384  0.35353 -0.30287]
21Feb13_200008| [-0.75329 -1.27485 -0.41900  0.22601]]
21Feb13_200008|-- Bias --
21Feb13_200008|[-0.95448  0.13450 -0.29140 -0.48520]
21Feb13_200008|Layer 4:
21Feb13_200008|-- Config --
21Feb13_200008|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200008|-- Weights --
21Feb13_200008|[[-0.73824  0.43630]
21Feb13_200008| [-0.01328  0.34065]
21Feb13_200008| [ 0.22924 -0.30811]
21Feb13_200008| [-0.13534 -0.31318]]
21Feb13_200008|-- Bias --
21Feb13_200008|[-0.51373  0.76130]
21Feb13_200008|Predicting the validation and test data with the Best final individual.
21Feb13_200016| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_200016|-----------  ------------------  --------------------  ----------
21Feb13_200016|Validation         21.22                  52            0.70612
21Feb13_200016|   Test            27.28                  52            0.50476
21Feb13_200016|-------------------- Test #7 --------------------
21Feb13_200016|Best final individual weights
21Feb13_200016|Individual:
21Feb13_200016|-- Constant hidden layers --
21Feb13_200016|False
21Feb13_200016|Layer 0:
21Feb13_200016|-- Config --
21Feb13_200016|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200016|-- Weights --
21Feb13_200016|[[-0.70147  1.81898 -1.19811 -0.98702]
21Feb13_200016| [ 0.12854  0.81408  0.25514  0.23353]
21Feb13_200016| [-0.76378 -0.76500  0.35248  0.26890]
21Feb13_200016| [ 1.64341  1.67169  0.03518 -0.20378]
21Feb13_200016| [ 0.22157 -0.61019  0.79588 -0.27345]
21Feb13_200016| [-1.23822 -1.86764 -1.85666  0.33678]
21Feb13_200016| [-0.97692  0.15098  0.30715  1.75219]
21Feb13_200016| [ 0.20395 -0.35022 -1.69279 -0.34243]
21Feb13_200016| [-0.24159 -0.14268  2.25383  0.68550]
21Feb13_200016| [-0.55194 -0.68549  0.80280 -0.60941]
21Feb13_200016| [-0.63201  0.46144  0.24282  2.20161]
21Feb13_200016| [-1.18622 -0.60422  0.26610 -0.70285]
21Feb13_200016| [ 0.60333  0.16633 -0.65080  0.11363]
21Feb13_200016| [ 0.36873  0.18594  0.36549  0.22051]
21Feb13_200016| [ 1.04502  0.19518 -0.43040  1.07351]
21Feb13_200016| [ 0.96694  0.14477 -1.02896  0.89242]
21Feb13_200016| [ 1.27167  0.01653  0.96997 -1.61365]
21Feb13_200016| [-1.59173 -0.22669 -1.11659  0.59352]
21Feb13_200016| [ 0.87703 -1.31311 -1.04639  0.94319]
21Feb13_200016| [ 0.87336  0.01591  0.70213 -1.77416]
21Feb13_200016| [ 2.19503 -1.36122 -1.48883  0.00411]
21Feb13_200016| [-0.85040  0.98617  2.14218 -0.12991]
21Feb13_200016| [ 1.25178 -0.36561  0.06305 -0.36145]
21Feb13_200016| [-2.58965  1.31141  1.10693 -0.55231]
21Feb13_200016| [ 0.59457  1.69880 -1.10262  1.36493]
21Feb13_200016| [-0.28694 -0.91882  0.92790 -0.77578]
21Feb13_200016| [ 0.55829  0.46047  0.83314 -0.61592]
21Feb13_200016| [ 0.34349  1.22218 -0.85430 -1.79906]
21Feb13_200016| [-0.28156 -0.80385  0.47478  0.95791]
21Feb13_200016| [ 0.89316  1.14094  0.47921  0.22448]
21Feb13_200016| [ 0.02193 -0.43600  0.87852  2.16496]
21Feb13_200016| [-1.31579  1.36006  0.18801  0.76711]
21Feb13_200016| [-0.00297  0.12555 -0.92105 -1.78211]
21Feb13_200016| [ 0.57371 -0.19964 -0.75235  0.20121]
21Feb13_200016| [-0.07073  1.32002 -0.15200  0.74027]
21Feb13_200016| [ 1.03756 -0.91348  0.02172  1.94365]
21Feb13_200016| [ 0.90723 -1.45536  0.11866 -1.84272]
21Feb13_200016| [-0.50110 -1.18639  1.25970 -0.55013]
21Feb13_200016| [ 0.98329 -0.40237 -0.83564  0.39022]
21Feb13_200016| [ 0.18550  0.63159 -0.20666 -1.04919]
21Feb13_200016| [ 0.92871 -1.14096 -1.51486  1.62599]
21Feb13_200016| [ 2.21129 -0.75264  1.54338 -0.82534]
21Feb13_200016| [-2.56190  0.75152  0.14857  1.17383]
21Feb13_200016| [ 1.03770  0.01148  0.25022 -1.28659]
21Feb13_200016| [ 2.16183  0.47029  0.01741 -0.98632]
21Feb13_200016| [-0.08188 -0.86313  2.36805 -1.03742]
21Feb13_200016| [-0.08347  1.55004  0.04645 -2.86549]
21Feb13_200016| [-0.70867 -0.69114 -0.70866 -0.67093]
21Feb13_200016| [-0.14483  0.37071  0.04424  2.13613]
21Feb13_200016| [-0.14117  0.20703 -0.41044  1.72514]
21Feb13_200016| [ 0.84550  0.84911  0.28784 -2.20851]
21Feb13_200016| [ 0.10779 -2.36073 -0.21111  2.16331]
21Feb13_200016| [ 0.56615 -0.57729  1.36509  1.07720]
21Feb13_200016| [ 0.58032 -0.61085 -0.68982  0.73322]
21Feb13_200016| [-0.89739  0.52350 -0.68521 -0.63787]
21Feb13_200016| [-0.74391 -0.23943  0.66873  0.46393]
21Feb13_200016| [ 0.65107 -0.95629 -0.15588  0.30563]]
21Feb13_200016|-- Bias --
21Feb13_200016|[-1.06816  1.50470  0.19707 -0.34618]
21Feb13_200016|Layer 1:
21Feb13_200016|-- Config --
21Feb13_200016|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200016|-- Weights --
21Feb13_200016|[[-0.44514 -0.08425 -0.25456]
21Feb13_200016| [-1.05359 -0.95623  0.08659]
21Feb13_200016| [ 0.56276 -1.30721 -0.31449]
21Feb13_200016| [ 0.86216 -0.92706 -0.16242]]
21Feb13_200016|-- Bias --
21Feb13_200016|[ 0.84774 -1.12624  0.30544]
21Feb13_200016|Layer 2:
21Feb13_200016|-- Config --
21Feb13_200016|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200016|-- Weights --
21Feb13_200016|[[ 0.45569 -0.38708]
21Feb13_200016| [-0.65573 -0.58254]
21Feb13_200016| [-0.23855 -0.05677]]
21Feb13_200016|-- Bias --
21Feb13_200016|[ 0.84507 -0.46860]
21Feb13_200016|Layer 3:
21Feb13_200016|-- Config --
21Feb13_200016|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200016|-- Weights --
21Feb13_200016|[[ 0.73429  0.34384  0.35353 -0.30287]
21Feb13_200016| [-0.75329 -1.27485 -0.41900  0.22601]]
21Feb13_200016|-- Bias --
21Feb13_200016|[-0.95448  0.13450 -0.29140 -0.48520]
21Feb13_200016|Layer 4:
21Feb13_200016|-- Config --
21Feb13_200016|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200016|-- Weights --
21Feb13_200016|[[-0.73824  0.43630]
21Feb13_200016| [-0.01328  0.34065]
21Feb13_200016| [ 0.22924 -0.30811]
21Feb13_200016| [-0.13534 -0.31318]]
21Feb13_200016|-- Bias --
21Feb13_200016|[-0.51373  0.76130]
21Feb13_200016|Predicting the validation and test data with the Best final individual.
21Feb13_200024| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_200024|-----------  ------------------  --------------------  ----------
21Feb13_200024|Validation         24.87                  52            0.69444
21Feb13_200024|   Test            27.63                  52            0.44118
21Feb13_200024|-------------------- Test #8 --------------------
21Feb13_200024|Best final individual weights
21Feb13_200024|Individual:
21Feb13_200024|-- Constant hidden layers --
21Feb13_200024|False
21Feb13_200024|Layer 0:
21Feb13_200024|-- Config --
21Feb13_200024|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200024|-- Weights --
21Feb13_200024|[[-0.70147  1.81898 -1.19811 -0.98702]
21Feb13_200024| [ 0.12854  0.81408  0.25514  0.23353]
21Feb13_200024| [-0.76378 -0.76500  0.35248  0.26890]
21Feb13_200024| [ 1.64341  1.67169  0.03518 -0.20378]
21Feb13_200024| [ 0.22157 -0.61019  0.79588 -0.27345]
21Feb13_200024| [-1.23822 -1.86764 -1.85666  0.33678]
21Feb13_200024| [-0.97692  0.15098  0.30715  1.75219]
21Feb13_200024| [ 0.20395 -0.35022 -1.69279 -0.34243]
21Feb13_200024| [-0.24159 -0.14268  2.25383  0.68550]
21Feb13_200024| [-0.55194 -0.68549  0.80280 -0.60941]
21Feb13_200024| [-0.63201  0.46144  0.24282  2.20161]
21Feb13_200024| [-1.18622 -0.60422  0.26610 -0.70285]
21Feb13_200024| [ 0.60333  0.16633 -0.65080  0.11363]
21Feb13_200024| [ 0.36873  0.18594  0.36549  0.22051]
21Feb13_200024| [ 1.04502  0.19518 -0.43040  1.07351]
21Feb13_200024| [ 0.96694  0.14477 -1.02896  0.89242]
21Feb13_200024| [ 1.27167  0.01653  0.96997 -1.61365]
21Feb13_200024| [-1.59173 -0.22669 -1.11659  0.59352]
21Feb13_200024| [ 0.87703 -1.31311 -1.04639  0.94319]
21Feb13_200024| [ 0.87336  0.01591  0.70213 -1.77416]
21Feb13_200024| [ 2.19503 -1.36122 -1.48883  0.00411]
21Feb13_200024| [-0.85040  0.98617  2.14218 -0.12991]
21Feb13_200024| [ 1.25178 -0.36561  0.06305 -0.36145]
21Feb13_200024| [-2.58965  1.31141  1.10693 -0.55231]
21Feb13_200024| [ 0.59457  1.69880 -1.10262  1.36493]
21Feb13_200024| [-0.28694 -0.91882  0.92790 -0.77578]
21Feb13_200024| [ 0.55829  0.46047  0.83314 -0.61592]
21Feb13_200024| [ 0.34349  1.22218 -0.85430 -1.79906]
21Feb13_200024| [-0.28156 -0.80385  0.47478  0.95791]
21Feb13_200024| [ 0.89316  1.14094  0.47921  0.22448]
21Feb13_200024| [ 0.02193 -0.43600  0.87852  2.16496]
21Feb13_200024| [-1.31579  1.36006  0.18801  0.76711]
21Feb13_200024| [-0.00297  0.12555 -0.92105 -1.78211]
21Feb13_200024| [ 0.57371 -0.19964 -0.75235  0.20121]
21Feb13_200024| [-0.07073  1.32002 -0.15200  0.74027]
21Feb13_200024| [ 1.03756 -0.91348  0.02172  1.94365]
21Feb13_200024| [ 0.90723 -1.45536  0.11866 -1.84272]
21Feb13_200024| [-0.50110 -1.18639  1.25970 -0.55013]
21Feb13_200024| [ 0.98329 -0.40237 -0.83564  0.39022]
21Feb13_200024| [ 0.18550  0.63159 -0.20666 -1.04919]
21Feb13_200024| [ 0.92871 -1.14096 -1.51486  1.62599]
21Feb13_200024| [ 2.21129 -0.75264  1.54338 -0.82534]
21Feb13_200024| [-2.56190  0.75152  0.14857  1.17383]
21Feb13_200024| [ 1.03770  0.01148  0.25022 -1.28659]
21Feb13_200024| [ 2.16183  0.47029  0.01741 -0.98632]
21Feb13_200024| [-0.08188 -0.86313  2.36805 -1.03742]
21Feb13_200024| [-0.08347  1.55004  0.04645 -2.86549]
21Feb13_200024| [-0.70867 -0.69114 -0.70866 -0.67093]
21Feb13_200024| [-0.14483  0.37071  0.04424  2.13613]
21Feb13_200024| [-0.14117  0.20703 -0.41044  1.72514]
21Feb13_200024| [ 0.84550  0.84911  0.28784 -2.20851]
21Feb13_200024| [ 0.10779 -2.36073 -0.21111  2.16331]
21Feb13_200024| [ 0.56615 -0.57729  1.36509  1.07720]
21Feb13_200024| [ 0.58032 -0.61085 -0.68982  0.73322]
21Feb13_200024| [-0.89739  0.52350 -0.68521 -0.63787]
21Feb13_200024| [-0.74391 -0.23943  0.66873  0.46393]
21Feb13_200024| [ 0.65107 -0.95629 -0.15588  0.30563]]
21Feb13_200024|-- Bias --
21Feb13_200024|[-1.06816  1.50470  0.19707 -0.34618]
21Feb13_200024|Layer 1:
21Feb13_200024|-- Config --
21Feb13_200024|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200024|-- Weights --
21Feb13_200024|[[-0.44514 -0.08425 -0.25456]
21Feb13_200024| [-1.05359 -0.95623  0.08659]
21Feb13_200024| [ 0.56276 -1.30721 -0.31449]
21Feb13_200024| [ 0.86216 -0.92706 -0.16242]]
21Feb13_200024|-- Bias --
21Feb13_200024|[ 0.84774 -1.12624  0.30544]
21Feb13_200024|Layer 2:
21Feb13_200024|-- Config --
21Feb13_200024|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200024|-- Weights --
21Feb13_200024|[[ 0.45569 -0.38708]
21Feb13_200024| [-0.65573 -0.58254]
21Feb13_200024| [-0.23855 -0.05677]]
21Feb13_200024|-- Bias --
21Feb13_200024|[ 0.84507 -0.46860]
21Feb13_200024|Layer 3:
21Feb13_200024|-- Config --
21Feb13_200024|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200024|-- Weights --
21Feb13_200024|[[ 0.73429  0.34384  0.35353 -0.30287]
21Feb13_200024| [-0.75329 -1.27485 -0.41900  0.22601]]
21Feb13_200024|-- Bias --
21Feb13_200024|[-0.95448  0.13450 -0.29140 -0.48520]
21Feb13_200024|Layer 4:
21Feb13_200024|-- Config --
21Feb13_200024|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200024|-- Weights --
21Feb13_200024|[[-0.73824  0.43630]
21Feb13_200024| [-0.01328  0.34065]
21Feb13_200024| [ 0.22924 -0.30811]
21Feb13_200024| [-0.13534 -0.31318]]
21Feb13_200024|-- Bias --
21Feb13_200024|[-0.51373  0.76130]
21Feb13_200024|Predicting the validation and test data with the Best final individual.
21Feb13_200032| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_200032|-----------  ------------------  --------------------  ----------
21Feb13_200032|Validation         25.39                  52            0.61334
21Feb13_200032|   Test            25.89                  52            0.47758
21Feb13_200032|-------------------- Test #9 --------------------
21Feb13_200032|Best final individual weights
21Feb13_200032|Individual:
21Feb13_200032|-- Constant hidden layers --
21Feb13_200032|False
21Feb13_200032|Layer 0:
21Feb13_200032|-- Config --
21Feb13_200032|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200032|-- Weights --
21Feb13_200032|[[-0.70147  1.81898 -1.19811 -0.98702]
21Feb13_200032| [ 0.12854  0.81408  0.25514  0.23353]
21Feb13_200032| [-0.76378 -0.76500  0.35248  0.26890]
21Feb13_200032| [ 1.64341  1.67169  0.03518 -0.20378]
21Feb13_200032| [ 0.22157 -0.61019  0.79588 -0.27345]
21Feb13_200032| [-1.23822 -1.86764 -1.85666  0.33678]
21Feb13_200032| [-0.97692  0.15098  0.30715  1.75219]
21Feb13_200032| [ 0.20395 -0.35022 -1.69279 -0.34243]
21Feb13_200032| [-0.24159 -0.14268  2.25383  0.68550]
21Feb13_200032| [-0.55194 -0.68549  0.80280 -0.60941]
21Feb13_200032| [-0.63201  0.46144  0.24282  2.20161]
21Feb13_200032| [-1.18622 -0.60422  0.26610 -0.70285]
21Feb13_200032| [ 0.60333  0.16633 -0.65080  0.11363]
21Feb13_200032| [ 0.36873  0.18594  0.36549  0.22051]
21Feb13_200032| [ 1.04502  0.19518 -0.43040  1.07351]
21Feb13_200032| [ 0.96694  0.14477 -1.02896  0.89242]
21Feb13_200032| [ 1.27167  0.01653  0.96997 -1.61365]
21Feb13_200032| [-1.59173 -0.22669 -1.11659  0.59352]
21Feb13_200032| [ 0.87703 -1.31311 -1.04639  0.94319]
21Feb13_200032| [ 0.87336  0.01591  0.70213 -1.77416]
21Feb13_200032| [ 2.19503 -1.36122 -1.48883  0.00411]
21Feb13_200032| [-0.85040  0.98617  2.14218 -0.12991]
21Feb13_200032| [ 1.25178 -0.36561  0.06305 -0.36145]
21Feb13_200032| [-2.58965  1.31141  1.10693 -0.55231]
21Feb13_200032| [ 0.59457  1.69880 -1.10262  1.36493]
21Feb13_200032| [-0.28694 -0.91882  0.92790 -0.77578]
21Feb13_200032| [ 0.55829  0.46047  0.83314 -0.61592]
21Feb13_200032| [ 0.34349  1.22218 -0.85430 -1.79906]
21Feb13_200032| [-0.28156 -0.80385  0.47478  0.95791]
21Feb13_200032| [ 0.89316  1.14094  0.47921  0.22448]
21Feb13_200032| [ 0.02193 -0.43600  0.87852  2.16496]
21Feb13_200032| [-1.31579  1.36006  0.18801  0.76711]
21Feb13_200032| [-0.00297  0.12555 -0.92105 -1.78211]
21Feb13_200032| [ 0.57371 -0.19964 -0.75235  0.20121]
21Feb13_200032| [-0.07073  1.32002 -0.15200  0.74027]
21Feb13_200032| [ 1.03756 -0.91348  0.02172  1.94365]
21Feb13_200032| [ 0.90723 -1.45536  0.11866 -1.84272]
21Feb13_200032| [-0.50110 -1.18639  1.25970 -0.55013]
21Feb13_200032| [ 0.98329 -0.40237 -0.83564  0.39022]
21Feb13_200032| [ 0.18550  0.63159 -0.20666 -1.04919]
21Feb13_200032| [ 0.92871 -1.14096 -1.51486  1.62599]
21Feb13_200032| [ 2.21129 -0.75264  1.54338 -0.82534]
21Feb13_200032| [-2.56190  0.75152  0.14857  1.17383]
21Feb13_200032| [ 1.03770  0.01148  0.25022 -1.28659]
21Feb13_200032| [ 2.16183  0.47029  0.01741 -0.98632]
21Feb13_200032| [-0.08188 -0.86313  2.36805 -1.03742]
21Feb13_200032| [-0.08347  1.55004  0.04645 -2.86549]
21Feb13_200032| [-0.70867 -0.69114 -0.70866 -0.67093]
21Feb13_200032| [-0.14483  0.37071  0.04424  2.13613]
21Feb13_200032| [-0.14117  0.20703 -0.41044  1.72514]
21Feb13_200032| [ 0.84550  0.84911  0.28784 -2.20851]
21Feb13_200032| [ 0.10779 -2.36073 -0.21111  2.16331]
21Feb13_200032| [ 0.56615 -0.57729  1.36509  1.07720]
21Feb13_200032| [ 0.58032 -0.61085 -0.68982  0.73322]
21Feb13_200032| [-0.89739  0.52350 -0.68521 -0.63787]
21Feb13_200032| [-0.74391 -0.23943  0.66873  0.46393]
21Feb13_200032| [ 0.65107 -0.95629 -0.15588  0.30563]]
21Feb13_200032|-- Bias --
21Feb13_200032|[-1.06816  1.50470  0.19707 -0.34618]
21Feb13_200032|Layer 1:
21Feb13_200032|-- Config --
21Feb13_200032|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200032|-- Weights --
21Feb13_200032|[[-0.44514 -0.08425 -0.25456]
21Feb13_200032| [-1.05359 -0.95623  0.08659]
21Feb13_200032| [ 0.56276 -1.30721 -0.31449]
21Feb13_200032| [ 0.86216 -0.92706 -0.16242]]
21Feb13_200032|-- Bias --
21Feb13_200032|[ 0.84774 -1.12624  0.30544]
21Feb13_200032|Layer 2:
21Feb13_200032|-- Config --
21Feb13_200032|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200032|-- Weights --
21Feb13_200032|[[ 0.45569 -0.38708]
21Feb13_200032| [-0.65573 -0.58254]
21Feb13_200032| [-0.23855 -0.05677]]
21Feb13_200032|-- Bias --
21Feb13_200032|[ 0.84507 -0.46860]
21Feb13_200032|Layer 3:
21Feb13_200032|-- Config --
21Feb13_200032|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200032|-- Weights --
21Feb13_200032|[[ 0.73429  0.34384  0.35353 -0.30287]
21Feb13_200032| [-0.75329 -1.27485 -0.41900  0.22601]]
21Feb13_200032|-- Bias --
21Feb13_200032|[-0.95448  0.13450 -0.29140 -0.48520]
21Feb13_200032|Layer 4:
21Feb13_200032|-- Config --
21Feb13_200032|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200032|-- Weights --
21Feb13_200032|[[-0.73824  0.43630]
21Feb13_200032| [-0.01328  0.34065]
21Feb13_200032| [ 0.22924 -0.30811]
21Feb13_200032| [-0.13534 -0.31318]]
21Feb13_200032|-- Bias --
21Feb13_200032|[-0.51373  0.76130]
21Feb13_200032|Predicting the validation and test data with the Best final individual.
21Feb13_200040| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_200040|-----------  ------------------  --------------------  ----------
21Feb13_200040|Validation         22.43                  52            0.61787
21Feb13_200040|   Test            31.89                  52            0.27763
21Feb13_200040|-------------------- Test #10 --------------------
21Feb13_200040|Best final individual weights
21Feb13_200040|Individual:
21Feb13_200040|-- Constant hidden layers --
21Feb13_200040|False
21Feb13_200040|Layer 0:
21Feb13_200040|-- Config --
21Feb13_200040|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200040|-- Weights --
21Feb13_200040|[[-0.70147  1.81898 -1.19811 -0.98702]
21Feb13_200040| [ 0.12854  0.81408  0.25514  0.23353]
21Feb13_200040| [-0.76378 -0.76500  0.35248  0.26890]
21Feb13_200040| [ 1.64341  1.67169  0.03518 -0.20378]
21Feb13_200040| [ 0.22157 -0.61019  0.79588 -0.27345]
21Feb13_200040| [-1.23822 -1.86764 -1.85666  0.33678]
21Feb13_200040| [-0.97692  0.15098  0.30715  1.75219]
21Feb13_200040| [ 0.20395 -0.35022 -1.69279 -0.34243]
21Feb13_200040| [-0.24159 -0.14268  2.25383  0.68550]
21Feb13_200040| [-0.55194 -0.68549  0.80280 -0.60941]
21Feb13_200040| [-0.63201  0.46144  0.24282  2.20161]
21Feb13_200040| [-1.18622 -0.60422  0.26610 -0.70285]
21Feb13_200040| [ 0.60333  0.16633 -0.65080  0.11363]
21Feb13_200040| [ 0.36873  0.18594  0.36549  0.22051]
21Feb13_200040| [ 1.04502  0.19518 -0.43040  1.07351]
21Feb13_200040| [ 0.96694  0.14477 -1.02896  0.89242]
21Feb13_200040| [ 1.27167  0.01653  0.96997 -1.61365]
21Feb13_200040| [-1.59173 -0.22669 -1.11659  0.59352]
21Feb13_200040| [ 0.87703 -1.31311 -1.04639  0.94319]
21Feb13_200040| [ 0.87336  0.01591  0.70213 -1.77416]
21Feb13_200040| [ 2.19503 -1.36122 -1.48883  0.00411]
21Feb13_200040| [-0.85040  0.98617  2.14218 -0.12991]
21Feb13_200040| [ 1.25178 -0.36561  0.06305 -0.36145]
21Feb13_200040| [-2.58965  1.31141  1.10693 -0.55231]
21Feb13_200040| [ 0.59457  1.69880 -1.10262  1.36493]
21Feb13_200040| [-0.28694 -0.91882  0.92790 -0.77578]
21Feb13_200040| [ 0.55829  0.46047  0.83314 -0.61592]
21Feb13_200041| [ 0.34349  1.22218 -0.85430 -1.79906]
21Feb13_200041| [-0.28156 -0.80385  0.47478  0.95791]
21Feb13_200041| [ 0.89316  1.14094  0.47921  0.22448]
21Feb13_200041| [ 0.02193 -0.43600  0.87852  2.16496]
21Feb13_200041| [-1.31579  1.36006  0.18801  0.76711]
21Feb13_200041| [-0.00297  0.12555 -0.92105 -1.78211]
21Feb13_200041| [ 0.57371 -0.19964 -0.75235  0.20121]
21Feb13_200041| [-0.07073  1.32002 -0.15200  0.74027]
21Feb13_200041| [ 1.03756 -0.91348  0.02172  1.94365]
21Feb13_200041| [ 0.90723 -1.45536  0.11866 -1.84272]
21Feb13_200041| [-0.50110 -1.18639  1.25970 -0.55013]
21Feb13_200041| [ 0.98329 -0.40237 -0.83564  0.39022]
21Feb13_200041| [ 0.18550  0.63159 -0.20666 -1.04919]
21Feb13_200041| [ 0.92871 -1.14096 -1.51486  1.62599]
21Feb13_200041| [ 2.21129 -0.75264  1.54338 -0.82534]
21Feb13_200041| [-2.56190  0.75152  0.14857  1.17383]
21Feb13_200041| [ 1.03770  0.01148  0.25022 -1.28659]
21Feb13_200041| [ 2.16183  0.47029  0.01741 -0.98632]
21Feb13_200041| [-0.08188 -0.86313  2.36805 -1.03742]
21Feb13_200041| [-0.08347  1.55004  0.04645 -2.86549]
21Feb13_200041| [-0.70867 -0.69114 -0.70866 -0.67093]
21Feb13_200041| [-0.14483  0.37071  0.04424  2.13613]
21Feb13_200041| [-0.14117  0.20703 -0.41044  1.72514]
21Feb13_200041| [ 0.84550  0.84911  0.28784 -2.20851]
21Feb13_200041| [ 0.10779 -2.36073 -0.21111  2.16331]
21Feb13_200041| [ 0.56615 -0.57729  1.36509  1.07720]
21Feb13_200041| [ 0.58032 -0.61085 -0.68982  0.73322]
21Feb13_200041| [-0.89739  0.52350 -0.68521 -0.63787]
21Feb13_200041| [-0.74391 -0.23943  0.66873  0.46393]
21Feb13_200041| [ 0.65107 -0.95629 -0.15588  0.30563]]
21Feb13_200041|-- Bias --
21Feb13_200041|[-1.06816  1.50470  0.19707 -0.34618]
21Feb13_200041|Layer 1:
21Feb13_200041|-- Config --
21Feb13_200041|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200041|-- Weights --
21Feb13_200041|[[-0.44514 -0.08425 -0.25456]
21Feb13_200041| [-1.05359 -0.95623  0.08659]
21Feb13_200041| [ 0.56276 -1.30721 -0.31449]
21Feb13_200041| [ 0.86216 -0.92706 -0.16242]]
21Feb13_200041|-- Bias --
21Feb13_200041|[ 0.84774 -1.12624  0.30544]
21Feb13_200041|Layer 2:
21Feb13_200041|-- Config --
21Feb13_200041|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200041|-- Weights --
21Feb13_200041|[[ 0.45569 -0.38708]
21Feb13_200041| [-0.65573 -0.58254]
21Feb13_200041| [-0.23855 -0.05677]]
21Feb13_200041|-- Bias --
21Feb13_200041|[ 0.84507 -0.46860]
21Feb13_200041|Layer 3:
21Feb13_200041|-- Config --
21Feb13_200041|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200041|-- Weights --
21Feb13_200041|[[ 0.73429  0.34384  0.35353 -0.30287]
21Feb13_200041| [-0.75329 -1.27485 -0.41900  0.22601]]
21Feb13_200041|-- Bias --
21Feb13_200041|[-0.95448  0.13450 -0.29140 -0.48520]
21Feb13_200041|Layer 4:
21Feb13_200041|-- Config --
21Feb13_200041|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200041|-- Weights --
21Feb13_200041|[[-0.73824  0.43630]
21Feb13_200041| [-0.01328  0.34065]
21Feb13_200041| [ 0.22924 -0.30811]
21Feb13_200041| [-0.13534 -0.31318]]
21Feb13_200041|-- Bias --
21Feb13_200041|[-0.51373  0.76130]
21Feb13_200041|Predicting the validation and test data with the Best final individual.
21Feb13_200049| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_200049|-----------  ------------------  --------------------  ----------
21Feb13_200049|Validation         47.13                  52            0.79934
21Feb13_200049|   Test            28.93                  52            0.53910
21Feb13_200049|-------------------- Test #11 --------------------
21Feb13_200049|Best final individual weights
21Feb13_200049|Individual:
21Feb13_200049|-- Constant hidden layers --
21Feb13_200049|False
21Feb13_200049|Layer 0:
21Feb13_200049|-- Config --
21Feb13_200049|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200049|-- Weights --
21Feb13_200049|[[-0.70147  1.81898 -1.19811 -0.98702]
21Feb13_200049| [ 0.12854  0.81408  0.25514  0.23353]
21Feb13_200049| [-0.76378 -0.76500  0.35248  0.26890]
21Feb13_200049| [ 1.64341  1.67169  0.03518 -0.20378]
21Feb13_200049| [ 0.22157 -0.61019  0.79588 -0.27345]
21Feb13_200049| [-1.23822 -1.86764 -1.85666  0.33678]
21Feb13_200049| [-0.97692  0.15098  0.30715  1.75219]
21Feb13_200049| [ 0.20395 -0.35022 -1.69279 -0.34243]
21Feb13_200049| [-0.24159 -0.14268  2.25383  0.68550]
21Feb13_200049| [-0.55194 -0.68549  0.80280 -0.60941]
21Feb13_200049| [-0.63201  0.46144  0.24282  2.20161]
21Feb13_200049| [-1.18622 -0.60422  0.26610 -0.70285]
21Feb13_200049| [ 0.60333  0.16633 -0.65080  0.11363]
21Feb13_200049| [ 0.36873  0.18594  0.36549  0.22051]
21Feb13_200049| [ 1.04502  0.19518 -0.43040  1.07351]
21Feb13_200049| [ 0.96694  0.14477 -1.02896  0.89242]
21Feb13_200049| [ 1.27167  0.01653  0.96997 -1.61365]
21Feb13_200049| [-1.59173 -0.22669 -1.11659  0.59352]
21Feb13_200049| [ 0.87703 -1.31311 -1.04639  0.94319]
21Feb13_200049| [ 0.87336  0.01591  0.70213 -1.77416]
21Feb13_200049| [ 2.19503 -1.36122 -1.48883  0.00411]
21Feb13_200049| [-0.85040  0.98617  2.14218 -0.12991]
21Feb13_200049| [ 1.25178 -0.36561  0.06305 -0.36145]
21Feb13_200049| [-2.58965  1.31141  1.10693 -0.55231]
21Feb13_200049| [ 0.59457  1.69880 -1.10262  1.36493]
21Feb13_200049| [-0.28694 -0.91882  0.92790 -0.77578]
21Feb13_200049| [ 0.55829  0.46047  0.83314 -0.61592]
21Feb13_200049| [ 0.34349  1.22218 -0.85430 -1.79906]
21Feb13_200049| [-0.28156 -0.80385  0.47478  0.95791]
21Feb13_200049| [ 0.89316  1.14094  0.47921  0.22448]
21Feb13_200049| [ 0.02193 -0.43600  0.87852  2.16496]
21Feb13_200049| [-1.31579  1.36006  0.18801  0.76711]
21Feb13_200049| [-0.00297  0.12555 -0.92105 -1.78211]
21Feb13_200049| [ 0.57371 -0.19964 -0.75235  0.20121]
21Feb13_200049| [-0.07073  1.32002 -0.15200  0.74027]
21Feb13_200049| [ 1.03756 -0.91348  0.02172  1.94365]
21Feb13_200049| [ 0.90723 -1.45536  0.11866 -1.84272]
21Feb13_200049| [-0.50110 -1.18639  1.25970 -0.55013]
21Feb13_200049| [ 0.98329 -0.40237 -0.83564  0.39022]
21Feb13_200049| [ 0.18550  0.63159 -0.20666 -1.04919]
21Feb13_200049| [ 0.92871 -1.14096 -1.51486  1.62599]
21Feb13_200049| [ 2.21129 -0.75264  1.54338 -0.82534]
21Feb13_200049| [-2.56190  0.75152  0.14857  1.17383]
21Feb13_200049| [ 1.03770  0.01148  0.25022 -1.28659]
21Feb13_200049| [ 2.16183  0.47029  0.01741 -0.98632]
21Feb13_200049| [-0.08188 -0.86313  2.36805 -1.03742]
21Feb13_200049| [-0.08347  1.55004  0.04645 -2.86549]
21Feb13_200049| [-0.70867 -0.69114 -0.70866 -0.67093]
21Feb13_200049| [-0.14483  0.37071  0.04424  2.13613]
21Feb13_200049| [-0.14117  0.20703 -0.41044  1.72514]
21Feb13_200049| [ 0.84550  0.84911  0.28784 -2.20851]
21Feb13_200049| [ 0.10779 -2.36073 -0.21111  2.16331]
21Feb13_200049| [ 0.56615 -0.57729  1.36509  1.07720]
21Feb13_200049| [ 0.58032 -0.61085 -0.68982  0.73322]
21Feb13_200049| [-0.89739  0.52350 -0.68521 -0.63787]
21Feb13_200049| [-0.74391 -0.23943  0.66873  0.46393]
21Feb13_200049| [ 0.65107 -0.95629 -0.15588  0.30563]]
21Feb13_200049|-- Bias --
21Feb13_200049|[-1.06816  1.50470  0.19707 -0.34618]
21Feb13_200049|Layer 1:
21Feb13_200049|-- Config --
21Feb13_200049|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200049|-- Weights --
21Feb13_200049|[[-0.44514 -0.08425 -0.25456]
21Feb13_200049| [-1.05359 -0.95623  0.08659]
21Feb13_200049| [ 0.56276 -1.30721 -0.31449]
21Feb13_200049| [ 0.86216 -0.92706 -0.16242]]
21Feb13_200049|-- Bias --
21Feb13_200049|[ 0.84774 -1.12624  0.30544]
21Feb13_200049|Layer 2:
21Feb13_200049|-- Config --
21Feb13_200049|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200049|-- Weights --
21Feb13_200049|[[ 0.45569 -0.38708]
21Feb13_200049| [-0.65573 -0.58254]
21Feb13_200049| [-0.23855 -0.05677]]
21Feb13_200049|-- Bias --
21Feb13_200049|[ 0.84507 -0.46860]
21Feb13_200049|Layer 3:
21Feb13_200049|-- Config --
21Feb13_200049|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200049|-- Weights --
21Feb13_200049|[[ 0.73429  0.34384  0.35353 -0.30287]
21Feb13_200049| [-0.75329 -1.27485 -0.41900  0.22601]]
21Feb13_200049|-- Bias --
21Feb13_200049|[-0.95448  0.13450 -0.29140 -0.48520]
21Feb13_200049|Layer 4:
21Feb13_200049|-- Config --
21Feb13_200049|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200049|-- Weights --
21Feb13_200049|[[-0.73824  0.43630]
21Feb13_200049| [-0.01328  0.34065]
21Feb13_200049| [ 0.22924 -0.30811]
21Feb13_200049| [-0.13534 -0.31318]]
21Feb13_200049|-- Bias --
21Feb13_200049|[-0.51373  0.76130]
21Feb13_200049|Predicting the validation and test data with the Best final individual.
21Feb13_200057| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_200057|-----------  ------------------  --------------------  ----------
21Feb13_200057|Validation         25.22                  52            0.60150
21Feb13_200057|   Test            28.06                  52            0.44211
21Feb13_200057|-------------------- Test #12 --------------------
21Feb13_200057|Best final individual weights
21Feb13_200057|Individual:
21Feb13_200057|-- Constant hidden layers --
21Feb13_200057|False
21Feb13_200057|Layer 0:
21Feb13_200057|-- Config --
21Feb13_200057|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200057|-- Weights --
21Feb13_200057|[[-0.70147  1.81898 -1.19811 -0.98702]
21Feb13_200057| [ 0.12854  0.81408  0.25514  0.23353]
21Feb13_200057| [-0.76378 -0.76500  0.35248  0.26890]
21Feb13_200057| [ 1.64341  1.67169  0.03518 -0.20378]
21Feb13_200057| [ 0.22157 -0.61019  0.79588 -0.27345]
21Feb13_200057| [-1.23822 -1.86764 -1.85666  0.33678]
21Feb13_200057| [-0.97692  0.15098  0.30715  1.75219]
21Feb13_200057| [ 0.20395 -0.35022 -1.69279 -0.34243]
21Feb13_200057| [-0.24159 -0.14268  2.25383  0.68550]
21Feb13_200057| [-0.55194 -0.68549  0.80280 -0.60941]
21Feb13_200057| [-0.63201  0.46144  0.24282  2.20161]
21Feb13_200057| [-1.18622 -0.60422  0.26610 -0.70285]
21Feb13_200057| [ 0.60333  0.16633 -0.65080  0.11363]
21Feb13_200057| [ 0.36873  0.18594  0.36549  0.22051]
21Feb13_200057| [ 1.04502  0.19518 -0.43040  1.07351]
21Feb13_200057| [ 0.96694  0.14477 -1.02896  0.89242]
21Feb13_200057| [ 1.27167  0.01653  0.96997 -1.61365]
21Feb13_200057| [-1.59173 -0.22669 -1.11659  0.59352]
21Feb13_200057| [ 0.87703 -1.31311 -1.04639  0.94319]
21Feb13_200057| [ 0.87336  0.01591  0.70213 -1.77416]
21Feb13_200057| [ 2.19503 -1.36122 -1.48883  0.00411]
21Feb13_200057| [-0.85040  0.98617  2.14218 -0.12991]
21Feb13_200057| [ 1.25178 -0.36561  0.06305 -0.36145]
21Feb13_200057| [-2.58965  1.31141  1.10693 -0.55231]
21Feb13_200057| [ 0.59457  1.69880 -1.10262  1.36493]
21Feb13_200057| [-0.28694 -0.91882  0.92790 -0.77578]
21Feb13_200057| [ 0.55829  0.46047  0.83314 -0.61592]
21Feb13_200057| [ 0.34349  1.22218 -0.85430 -1.79906]
21Feb13_200057| [-0.28156 -0.80385  0.47478  0.95791]
21Feb13_200057| [ 0.89316  1.14094  0.47921  0.22448]
21Feb13_200057| [ 0.02193 -0.43600  0.87852  2.16496]
21Feb13_200057| [-1.31579  1.36006  0.18801  0.76711]
21Feb13_200057| [-0.00297  0.12555 -0.92105 -1.78211]
21Feb13_200057| [ 0.57371 -0.19964 -0.75235  0.20121]
21Feb13_200057| [-0.07073  1.32002 -0.15200  0.74027]
21Feb13_200057| [ 1.03756 -0.91348  0.02172  1.94365]
21Feb13_200057| [ 0.90723 -1.45536  0.11866 -1.84272]
21Feb13_200057| [-0.50110 -1.18639  1.25970 -0.55013]
21Feb13_200057| [ 0.98329 -0.40237 -0.83564  0.39022]
21Feb13_200057| [ 0.18550  0.63159 -0.20666 -1.04919]
21Feb13_200057| [ 0.92871 -1.14096 -1.51486  1.62599]
21Feb13_200057| [ 2.21129 -0.75264  1.54338 -0.82534]
21Feb13_200057| [-2.56190  0.75152  0.14857  1.17383]
21Feb13_200057| [ 1.03770  0.01148  0.25022 -1.28659]
21Feb13_200057| [ 2.16183  0.47029  0.01741 -0.98632]
21Feb13_200057| [-0.08188 -0.86313  2.36805 -1.03742]
21Feb13_200057| [-0.08347  1.55004  0.04645 -2.86549]
21Feb13_200057| [-0.70867 -0.69114 -0.70866 -0.67093]
21Feb13_200057| [-0.14483  0.37071  0.04424  2.13613]
21Feb13_200057| [-0.14117  0.20703 -0.41044  1.72514]
21Feb13_200057| [ 0.84550  0.84911  0.28784 -2.20851]
21Feb13_200057| [ 0.10779 -2.36073 -0.21111  2.16331]
21Feb13_200057| [ 0.56615 -0.57729  1.36509  1.07720]
21Feb13_200057| [ 0.58032 -0.61085 -0.68982  0.73322]
21Feb13_200057| [-0.89739  0.52350 -0.68521 -0.63787]
21Feb13_200057| [-0.74391 -0.23943  0.66873  0.46393]
21Feb13_200057| [ 0.65107 -0.95629 -0.15588  0.30563]]
21Feb13_200057|-- Bias --
21Feb13_200057|[-1.06816  1.50470  0.19707 -0.34618]
21Feb13_200057|Layer 1:
21Feb13_200057|-- Config --
21Feb13_200057|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200057|-- Weights --
21Feb13_200057|[[-0.44514 -0.08425 -0.25456]
21Feb13_200057| [-1.05359 -0.95623  0.08659]
21Feb13_200057| [ 0.56276 -1.30721 -0.31449]
21Feb13_200057| [ 0.86216 -0.92706 -0.16242]]
21Feb13_200057|-- Bias --
21Feb13_200057|[ 0.84774 -1.12624  0.30544]
21Feb13_200057|Layer 2:
21Feb13_200057|-- Config --
21Feb13_200057|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200057|-- Weights --
21Feb13_200057|[[ 0.45569 -0.38708]
21Feb13_200057| [-0.65573 -0.58254]
21Feb13_200057| [-0.23855 -0.05677]]
21Feb13_200057|-- Bias --
21Feb13_200057|[ 0.84507 -0.46860]
21Feb13_200057|Layer 3:
21Feb13_200057|-- Config --
21Feb13_200057|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200057|-- Weights --
21Feb13_200057|[[ 0.73429  0.34384  0.35353 -0.30287]
21Feb13_200057| [-0.75329 -1.27485 -0.41900  0.22601]]
21Feb13_200057|-- Bias --
21Feb13_200057|[-0.95448  0.13450 -0.29140 -0.48520]
21Feb13_200057|Layer 4:
21Feb13_200057|-- Config --
21Feb13_200057|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200057|-- Weights --
21Feb13_200057|[[-0.73824  0.43630]
21Feb13_200057| [-0.01328  0.34065]
21Feb13_200057| [ 0.22924 -0.30811]
21Feb13_200057| [-0.13534 -0.31318]]
21Feb13_200057|-- Bias --
21Feb13_200057|[-0.51373  0.76130]
21Feb13_200057|Predicting the validation and test data with the Best final individual.
21Feb13_200105| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_200105|-----------  ------------------  --------------------  ----------
21Feb13_200105|Validation         31.57                  52            0.24800
21Feb13_200105|   Test            24.24                  52            0.55292
21Feb13_200105|-------------------- Test #13 --------------------
21Feb13_200105|Best final individual weights
21Feb13_200105|Individual:
21Feb13_200105|-- Constant hidden layers --
21Feb13_200105|False
21Feb13_200105|Layer 0:
21Feb13_200105|-- Config --
21Feb13_200105|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200105|-- Weights --
21Feb13_200105|[[-0.70147  1.81898 -1.19811 -0.98702]
21Feb13_200105| [ 0.12854  0.81408  0.25514  0.23353]
21Feb13_200105| [-0.76378 -0.76500  0.35248  0.26890]
21Feb13_200105| [ 1.64341  1.67169  0.03518 -0.20378]
21Feb13_200105| [ 0.22157 -0.61019  0.79588 -0.27345]
21Feb13_200105| [-1.23822 -1.86764 -1.85666  0.33678]
21Feb13_200105| [-0.97692  0.15098  0.30715  1.75219]
21Feb13_200105| [ 0.20395 -0.35022 -1.69279 -0.34243]
21Feb13_200105| [-0.24159 -0.14268  2.25383  0.68550]
21Feb13_200105| [-0.55194 -0.68549  0.80280 -0.60941]
21Feb13_200105| [-0.63201  0.46144  0.24282  2.20161]
21Feb13_200105| [-1.18622 -0.60422  0.26610 -0.70285]
21Feb13_200105| [ 0.60333  0.16633 -0.65080  0.11363]
21Feb13_200105| [ 0.36873  0.18594  0.36549  0.22051]
21Feb13_200105| [ 1.04502  0.19518 -0.43040  1.07351]
21Feb13_200105| [ 0.96694  0.14477 -1.02896  0.89242]
21Feb13_200105| [ 1.27167  0.01653  0.96997 -1.61365]
21Feb13_200105| [-1.59173 -0.22669 -1.11659  0.59352]
21Feb13_200105| [ 0.87703 -1.31311 -1.04639  0.94319]
21Feb13_200105| [ 0.87336  0.01591  0.70213 -1.77416]
21Feb13_200105| [ 2.19503 -1.36122 -1.48883  0.00411]
21Feb13_200105| [-0.85040  0.98617  2.14218 -0.12991]
21Feb13_200105| [ 1.25178 -0.36561  0.06305 -0.36145]
21Feb13_200105| [-2.58965  1.31141  1.10693 -0.55231]
21Feb13_200105| [ 0.59457  1.69880 -1.10262  1.36493]
21Feb13_200105| [-0.28694 -0.91882  0.92790 -0.77578]
21Feb13_200105| [ 0.55829  0.46047  0.83314 -0.61592]
21Feb13_200105| [ 0.34349  1.22218 -0.85430 -1.79906]
21Feb13_200105| [-0.28156 -0.80385  0.47478  0.95791]
21Feb13_200105| [ 0.89316  1.14094  0.47921  0.22448]
21Feb13_200105| [ 0.02193 -0.43600  0.87852  2.16496]
21Feb13_200105| [-1.31579  1.36006  0.18801  0.76711]
21Feb13_200105| [-0.00297  0.12555 -0.92105 -1.78211]
21Feb13_200105| [ 0.57371 -0.19964 -0.75235  0.20121]
21Feb13_200105| [-0.07073  1.32002 -0.15200  0.74027]
21Feb13_200105| [ 1.03756 -0.91348  0.02172  1.94365]
21Feb13_200105| [ 0.90723 -1.45536  0.11866 -1.84272]
21Feb13_200105| [-0.50110 -1.18639  1.25970 -0.55013]
21Feb13_200105| [ 0.98329 -0.40237 -0.83564  0.39022]
21Feb13_200105| [ 0.18550  0.63159 -0.20666 -1.04919]
21Feb13_200105| [ 0.92871 -1.14096 -1.51486  1.62599]
21Feb13_200105| [ 2.21129 -0.75264  1.54338 -0.82534]
21Feb13_200105| [-2.56190  0.75152  0.14857  1.17383]
21Feb13_200105| [ 1.03770  0.01148  0.25022 -1.28659]
21Feb13_200105| [ 2.16183  0.47029  0.01741 -0.98632]
21Feb13_200105| [-0.08188 -0.86313  2.36805 -1.03742]
21Feb13_200105| [-0.08347  1.55004  0.04645 -2.86549]
21Feb13_200105| [-0.70867 -0.69114 -0.70866 -0.67093]
21Feb13_200105| [-0.14483  0.37071  0.04424  2.13613]
21Feb13_200105| [-0.14117  0.20703 -0.41044  1.72514]
21Feb13_200105| [ 0.84550  0.84911  0.28784 -2.20851]
21Feb13_200105| [ 0.10779 -2.36073 -0.21111  2.16331]
21Feb13_200105| [ 0.56615 -0.57729  1.36509  1.07720]
21Feb13_200105| [ 0.58032 -0.61085 -0.68982  0.73322]
21Feb13_200105| [-0.89739  0.52350 -0.68521 -0.63787]
21Feb13_200105| [-0.74391 -0.23943  0.66873  0.46393]
21Feb13_200105| [ 0.65107 -0.95629 -0.15588  0.30563]]
21Feb13_200105|-- Bias --
21Feb13_200105|[-1.06816  1.50470  0.19707 -0.34618]
21Feb13_200105|Layer 1:
21Feb13_200105|-- Config --
21Feb13_200105|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200105|-- Weights --
21Feb13_200105|[[-0.44514 -0.08425 -0.25456]
21Feb13_200105| [-1.05359 -0.95623  0.08659]
21Feb13_200105| [ 0.56276 -1.30721 -0.31449]
21Feb13_200105| [ 0.86216 -0.92706 -0.16242]]
21Feb13_200105|-- Bias --
21Feb13_200105|[ 0.84774 -1.12624  0.30544]
21Feb13_200105|Layer 2:
21Feb13_200105|-- Config --
21Feb13_200105|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200105|-- Weights --
21Feb13_200105|[[ 0.45569 -0.38708]
21Feb13_200105| [-0.65573 -0.58254]
21Feb13_200105| [-0.23855 -0.05677]]
21Feb13_200105|-- Bias --
21Feb13_200105|[ 0.84507 -0.46860]
21Feb13_200105|Layer 3:
21Feb13_200105|-- Config --
21Feb13_200105|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200105|-- Weights --
21Feb13_200105|[[ 0.73429  0.34384  0.35353 -0.30287]
21Feb13_200105| [-0.75329 -1.27485 -0.41900  0.22601]]
21Feb13_200105|-- Bias --
21Feb13_200105|[-0.95448  0.13450 -0.29140 -0.48520]
21Feb13_200105|Layer 4:
21Feb13_200105|-- Config --
21Feb13_200105|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200105|-- Weights --
21Feb13_200105|[[-0.73824  0.43630]
21Feb13_200105| [-0.01328  0.34065]
21Feb13_200105| [ 0.22924 -0.30811]
21Feb13_200105| [-0.13534 -0.31318]]
21Feb13_200105|-- Bias --
21Feb13_200105|[-0.51373  0.76130]
21Feb13_200105|Predicting the validation and test data with the Best final individual.
21Feb13_200113| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_200113|-----------  ------------------  --------------------  ----------
21Feb13_200113|Validation         38.43                  52            0.00000
21Feb13_200113|   Test            26.41                  52            0.71704
21Feb13_200113|-------------------- Test #14 --------------------
21Feb13_200113|Best final individual weights
21Feb13_200113|Individual:
21Feb13_200113|-- Constant hidden layers --
21Feb13_200113|False
21Feb13_200113|Layer 0:
21Feb13_200113|-- Config --
21Feb13_200113|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200113|-- Weights --
21Feb13_200113|[[-0.70147  1.81898 -1.19811 -0.98702]
21Feb13_200113| [ 0.12854  0.81408  0.25514  0.23353]
21Feb13_200113| [-0.76378 -0.76500  0.35248  0.26890]
21Feb13_200113| [ 1.64341  1.67169  0.03518 -0.20378]
21Feb13_200113| [ 0.22157 -0.61019  0.79588 -0.27345]
21Feb13_200113| [-1.23822 -1.86764 -1.85666  0.33678]
21Feb13_200113| [-0.97692  0.15098  0.30715  1.75219]
21Feb13_200113| [ 0.20395 -0.35022 -1.69279 -0.34243]
21Feb13_200113| [-0.24159 -0.14268  2.25383  0.68550]
21Feb13_200113| [-0.55194 -0.68549  0.80280 -0.60941]
21Feb13_200113| [-0.63201  0.46144  0.24282  2.20161]
21Feb13_200113| [-1.18622 -0.60422  0.26610 -0.70285]
21Feb13_200113| [ 0.60333  0.16633 -0.65080  0.11363]
21Feb13_200113| [ 0.36873  0.18594  0.36549  0.22051]
21Feb13_200113| [ 1.04502  0.19518 -0.43040  1.07351]
21Feb13_200113| [ 0.96694  0.14477 -1.02896  0.89242]
21Feb13_200113| [ 1.27167  0.01653  0.96997 -1.61365]
21Feb13_200113| [-1.59173 -0.22669 -1.11659  0.59352]
21Feb13_200113| [ 0.87703 -1.31311 -1.04639  0.94319]
21Feb13_200113| [ 0.87336  0.01591  0.70213 -1.77416]
21Feb13_200113| [ 2.19503 -1.36122 -1.48883  0.00411]
21Feb13_200113| [-0.85040  0.98617  2.14218 -0.12991]
21Feb13_200113| [ 1.25178 -0.36561  0.06305 -0.36145]
21Feb13_200113| [-2.58965  1.31141  1.10693 -0.55231]
21Feb13_200113| [ 0.59457  1.69880 -1.10262  1.36493]
21Feb13_200113| [-0.28694 -0.91882  0.92790 -0.77578]
21Feb13_200113| [ 0.55829  0.46047  0.83314 -0.61592]
21Feb13_200113| [ 0.34349  1.22218 -0.85430 -1.79906]
21Feb13_200113| [-0.28156 -0.80385  0.47478  0.95791]
21Feb13_200113| [ 0.89316  1.14094  0.47921  0.22448]
21Feb13_200113| [ 0.02193 -0.43600  0.87852  2.16496]
21Feb13_200113| [-1.31579  1.36006  0.18801  0.76711]
21Feb13_200113| [-0.00297  0.12555 -0.92105 -1.78211]
21Feb13_200113| [ 0.57371 -0.19964 -0.75235  0.20121]
21Feb13_200113| [-0.07073  1.32002 -0.15200  0.74027]
21Feb13_200113| [ 1.03756 -0.91348  0.02172  1.94365]
21Feb13_200113| [ 0.90723 -1.45536  0.11866 -1.84272]
21Feb13_200113| [-0.50110 -1.18639  1.25970 -0.55013]
21Feb13_200113| [ 0.98329 -0.40237 -0.83564  0.39022]
21Feb13_200113| [ 0.18550  0.63159 -0.20666 -1.04919]
21Feb13_200113| [ 0.92871 -1.14096 -1.51486  1.62599]
21Feb13_200113| [ 2.21129 -0.75264  1.54338 -0.82534]
21Feb13_200113| [-2.56190  0.75152  0.14857  1.17383]
21Feb13_200113| [ 1.03770  0.01148  0.25022 -1.28659]
21Feb13_200113| [ 2.16183  0.47029  0.01741 -0.98632]
21Feb13_200113| [-0.08188 -0.86313  2.36805 -1.03742]
21Feb13_200113| [-0.08347  1.55004  0.04645 -2.86549]
21Feb13_200113| [-0.70867 -0.69114 -0.70866 -0.67093]
21Feb13_200113| [-0.14483  0.37071  0.04424  2.13613]
21Feb13_200113| [-0.14117  0.20703 -0.41044  1.72514]
21Feb13_200113| [ 0.84550  0.84911  0.28784 -2.20851]
21Feb13_200113| [ 0.10779 -2.36073 -0.21111  2.16331]
21Feb13_200113| [ 0.56615 -0.57729  1.36509  1.07720]
21Feb13_200113| [ 0.58032 -0.61085 -0.68982  0.73322]
21Feb13_200113| [-0.89739  0.52350 -0.68521 -0.63787]
21Feb13_200113| [-0.74391 -0.23943  0.66873  0.46393]
21Feb13_200113| [ 0.65107 -0.95629 -0.15588  0.30563]]
21Feb13_200113|-- Bias --
21Feb13_200113|[-1.06816  1.50470  0.19707 -0.34618]
21Feb13_200113|Layer 1:
21Feb13_200113|-- Config --
21Feb13_200113|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200113|-- Weights --
21Feb13_200113|[[-0.44514 -0.08425 -0.25456]
21Feb13_200113| [-1.05359 -0.95623  0.08659]
21Feb13_200113| [ 0.56276 -1.30721 -0.31449]
21Feb13_200113| [ 0.86216 -0.92706 -0.16242]]
21Feb13_200113|-- Bias --
21Feb13_200113|[ 0.84774 -1.12624  0.30544]
21Feb13_200113|Layer 2:
21Feb13_200113|-- Config --
21Feb13_200113|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200113|-- Weights --
21Feb13_200113|[[ 0.45569 -0.38708]
21Feb13_200113| [-0.65573 -0.58254]
21Feb13_200113| [-0.23855 -0.05677]]
21Feb13_200113|-- Bias --
21Feb13_200113|[ 0.84507 -0.46860]
21Feb13_200113|Layer 3:
21Feb13_200113|-- Config --
21Feb13_200113|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200113|-- Weights --
21Feb13_200113|[[ 0.73429  0.34384  0.35353 -0.30287]
21Feb13_200113| [-0.75329 -1.27485 -0.41900  0.22601]]
21Feb13_200113|-- Bias --
21Feb13_200113|[-0.95448  0.13450 -0.29140 -0.48520]
21Feb13_200113|Layer 4:
21Feb13_200113|-- Config --
21Feb13_200113|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_200113|-- Weights --
21Feb13_200113|[[-0.73824  0.43630]
21Feb13_200113| [-0.01328  0.34065]
21Feb13_200113| [ 0.22924 -0.30811]
21Feb13_200113| [-0.13534 -0.31318]]
21Feb13_200113|-- Bias --
21Feb13_200113|[-0.51373  0.76130]
21Feb13_200113|Predicting the validation and test data with the Best final individual.
21Feb13_200121| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_200121|-----------  ------------------  --------------------  ----------
21Feb13_200121|Validation         38.35                  52            0.00565
21Feb13_200121|   Test            24.41                  52            0.56706
2021-02-13 20:01:22.388283: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
21Feb13_200123|Data summary: Train
21Feb13_200123|data.shape = (2300, 57)
21Feb13_200123|labels.shape = (2300,)
21Feb13_200123|Class distribution:
21Feb13_200123|	0 - 1383 (0.60)
21Feb13_200123|	1 - 917 (0.40)
21Feb13_200123|Data summary: Validation
21Feb13_200123|data.shape = (1150, 57)
21Feb13_200123|labels.shape = (1150,)
21Feb13_200123|Class distribution:
21Feb13_200123|	0 - 708 (0.62)
21Feb13_200123|	1 - 442 (0.38)
21Feb13_200123|Data summary: Test
21Feb13_200123|data.shape = (1151, 57)
21Feb13_200123|labels.shape = (1151,)
21Feb13_200123|Class distribution:
21Feb13_200123|	0 - 697 (0.61)
21Feb13_200123|	1 - 454 (0.39)
21Feb13_200123|Selected configuration values
21Feb13_200123|-- Dataset name: spambase3
21Feb13_200123|-- Initial population size: 64
21Feb13_200123|-- Maximun number of generations: 32
21Feb13_200123|-- Neurons per hidden layer range: (2, 20)
21Feb13_200123|-- Hidden layers number range: (1, 3)
21Feb13_200123|-- Crossover probability: 0.5
21Feb13_200123|-- Bias gene mutation probability: 0.2
21Feb13_200123|-- Weights gene mutation probability: 0.75
21Feb13_200123|-- Neuron mutation probability: 0.3
21Feb13_200123|-- Layer mutation probability: 0.3
21Feb13_200123|-- Constant hidden layers: False
21Feb13_200123|-- Seed: 31415
21Feb13_200123|Entering GA
21Feb13_200123|Start the algorithm
2021-02-13 20:01:23.221504: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-13 20:01:23.222038: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-02-13 20:01:23.253308: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-13 20:01:23.253639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.71GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s
2021-02-13 20:01:23.253656: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-02-13 20:01:23.255194: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-02-13 20:01:23.255225: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-02-13 20:01:23.255728: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-02-13 20:01:23.255855: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-02-13 20:01:23.255928: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-13 20:01:23.256335: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-02-13 20:01:23.256379: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-13 20:01:23.256385: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-02-13 20:01:23.256614: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-02-13 20:01:23.257428: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-13 20:01:23.257443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-13 20:01:23.257447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      
2021-02-13 20:01:23.301720: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-02-13 20:01:23.302120: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3493635000 Hz
/home/jmerelo/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype("int32")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn('`model.predict_classes()` is deprecated and '
21Feb13_200524|-- Generation 1 --
21Feb13_200524|    -- Crossed 0 individual pairs.
21Feb13_200524|    -- Mutated 32 individuals.
21Feb13_200924|    -- Evaluated 64 individuals.
21Feb13_200924|    Summary of generation 1:
21Feb13_200924| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_200924|-----------  ------------------  --------------------  ----------
21Feb13_200924|    Max            39.48                120.00          0.69982
21Feb13_200924|    Avg            37.90                40.69           0.02725
21Feb13_200924|    Min            23.83                 3.00           0.00000
21Feb13_200924|    Std             2.36                28.82           0.10611
21Feb13_200924|   Best            23.83                 4.00           0.69982
21Feb13_200924|-- Generation 2 --
21Feb13_200924|    -- Crossed 2 individual pairs.
21Feb13_200924|    -- Mutated 32 individuals.
21Feb13_201320|    -- Evaluated 64 individuals.
21Feb13_201320|    Summary of generation 2:
21Feb13_201320| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_201320|-----------  ------------------  --------------------  ----------
21Feb13_201320|    Max            38.78                104.00          0.75402
21Feb13_201320|    Avg            37.20                25.69           0.05889
21Feb13_201320|    Min            24.00                 4.00           0.00000
21Feb13_201320|    Std             3.64                20.25           0.17120
21Feb13_201320|   Best            24.00                16.00           0.58739
21Feb13_201320|-- Generation 3 --
21Feb13_201320|    -- Crossed 2 individual pairs.
21Feb13_201320|    -- Mutated 32 individuals.
21Feb13_201712|    -- Evaluated 64 individuals.
21Feb13_201712|    Summary of generation 3:
21Feb13_201712| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_201712|-----------  ------------------  --------------------  ----------
21Feb13_201712|    Max            38.87                42.00           0.50342
21Feb13_201712|    Avg            37.32                14.69           0.04677
21Feb13_201712|    Min            26.26                 2.00           0.00000
21Feb13_201712|    Std             3.24                10.48           0.12927
21Feb13_201712|   Best            26.26                 5.00           0.48515
21Feb13_201712|-- Generation 4 --
21Feb13_201712|    -- Crossed 4 individual pairs.
21Feb13_201712|    -- Mutated 32 individuals.
21Feb13_202101|    -- Evaluated 64 individuals.
21Feb13_202101|    Summary of generation 4:
21Feb13_202101| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_202101|-----------  ------------------  --------------------  ----------
21Feb13_202101|    Max            39.04                42.00           0.82234
21Feb13_202101|    Avg            37.54                11.00           0.04382
21Feb13_202101|    Min            26.26                 2.00           0.00000
21Feb13_202101|    Std             2.79                 9.86           0.13844
21Feb13_202101|   Best            26.26                 4.00           0.82234
21Feb13_202101|-- Generation 5 --
21Feb13_202101|    -- Crossed 4 individual pairs.
21Feb13_202101|    -- Mutated 32 individuals.
21Feb13_202448|    -- Evaluated 64 individuals.
21Feb13_202448|    Summary of generation 5:
21Feb13_202448| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_202448|-----------  ------------------  --------------------  ----------
21Feb13_202448|    Max            38.70                18.00           0.67087
21Feb13_202448|    Avg            37.28                 7.31           0.05321
21Feb13_202448|    Min            25.65                 2.00           0.00000
21Feb13_202448|    Std             3.19                 4.30           0.14764
21Feb13_202448|   Best            25.65                17.00           0.61424
21Feb13_202448|-- Generation 6 --
21Feb13_202448|    -- Crossed 3 individual pairs.
21Feb13_202448|    -- Mutated 32 individuals.
21Feb13_202836|    -- Evaluated 64 individuals.
21Feb13_202836|    Summary of generation 6:
21Feb13_202836| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_202836|-----------  ------------------  --------------------  ----------
21Feb13_202836|    Max            38.78                30.00           0.73504
21Feb13_202836|    Avg            37.00                 8.44           0.06639
21Feb13_202836|    Min            22.26                 2.00           0.00000
21Feb13_202836|    Std             3.89                 6.55           0.17944
21Feb13_202836|   Best            22.26                 5.00           0.67068
21Feb13_202836|-- Generation 7 --
21Feb13_202836|    -- Crossed 7 individual pairs.
21Feb13_202836|    -- Mutated 32 individuals.
21Feb13_203224|    -- Evaluated 64 individuals.
21Feb13_203224|    Summary of generation 7:
21Feb13_203224| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_203224|-----------  ------------------  --------------------  ----------
21Feb13_203224|    Max            38.78                30.00           0.62917
21Feb13_203224|    Avg            37.68                 7.66           0.03802
21Feb13_203224|    Min            24.96                 2.00           0.00000
21Feb13_203224|    Std             2.60                 5.32           0.12540
21Feb13_203224|   Best            24.96                 2.00           0.56037
21Feb13_203224|-- Generation 8 --
21Feb13_203224|    -- Crossed 3 individual pairs.
21Feb13_203224|    -- Mutated 32 individuals.
21Feb13_203614|    -- Evaluated 64 individuals.
21Feb13_203614|    Summary of generation 8:
21Feb13_203614| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_203614|-----------  ------------------  --------------------  ----------
21Feb13_203614|    Max            38.96                33.00           0.53349
21Feb13_203614|    Avg            37.24                 7.48           0.05129
21Feb13_203614|    Min            24.96                 2.00           0.00000
21Feb13_203614|    Std             3.26                 6.00           0.13481
21Feb13_203614|   Best            24.96                 8.00           0.53197
21Feb13_203614|-- Generation 9 --
21Feb13_203614|    -- Crossed 4 individual pairs.
21Feb13_203614|    -- Mutated 32 individuals.
21Feb13_204003|    -- Evaluated 64 individuals.
21Feb13_204003|    Summary of generation 9:
21Feb13_204003| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_204003|-----------  ------------------  --------------------  ----------
21Feb13_204003|    Max            39.39                20.00           0.50465
21Feb13_204003|    Avg            37.68                 7.61           0.03172
21Feb13_204003|    Min            26.35                 2.00           0.00000
21Feb13_204003|    Std             2.26                 5.15           0.08931
21Feb13_204003|   Best            26.35                14.00           0.50465
21Feb13_204003|-- Generation 10 --
21Feb13_204003|    -- Crossed 3 individual pairs.
21Feb13_204003|    -- Mutated 32 individuals.
21Feb13_204353|    -- Evaluated 64 individuals.
21Feb13_204353|    Summary of generation 10:
21Feb13_204353| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_204353|-----------  ------------------  --------------------  ----------
21Feb13_204353|    Max            39.04                39.00           0.68068
21Feb13_204353|    Avg            37.36                 7.58           0.04904
21Feb13_204353|    Min            23.22                 2.00           0.00000
21Feb13_204353|    Std             3.08                 6.57           0.14022
21Feb13_204353|   Best            23.22                 4.00           0.68068
21Feb13_204353|-- Generation 11 --
21Feb13_204353|    -- Crossed 1 individual pairs.
21Feb13_204353|    -- Mutated 32 individuals.
21Feb13_204742|    -- Evaluated 64 individuals.
21Feb13_204742|    Summary of generation 11:
21Feb13_204742| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_204742|-----------  ------------------  --------------------  ----------
21Feb13_204742|    Max            47.39                30.00           0.79847
21Feb13_204742|    Avg            37.45                 9.17           0.05680
21Feb13_204742|    Min            25.57                 2.00           0.00000
21Feb13_204742|    Std             2.90                 7.29           0.13536
21Feb13_204742|   Best            25.57                18.00           0.47094
21Feb13_204742|-- Generation 12 --
21Feb13_204742|    -- Crossed 1 individual pairs.
21Feb13_204742|    -- Mutated 32 individuals.
21Feb13_205133|    -- Evaluated 64 individuals.
21Feb13_205133|    Summary of generation 12:
21Feb13_205133| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_205133|-----------  ------------------  --------------------  ----------
21Feb13_205133|    Max            38.78                39.00           0.76224
21Feb13_205133|    Avg            37.22                10.00           0.06242
21Feb13_205133|    Min            25.13                 2.00           0.00000
21Feb13_205133|    Std             2.61                 7.72           0.13717
21Feb13_205133|   Best            25.13                16.00           0.56540
21Feb13_205133|-- Generation 13 --
21Feb13_205133|    -- Crossed 2 individual pairs.
21Feb13_205133|    -- Mutated 32 individuals.
21Feb13_205524|    -- Evaluated 64 individuals.
21Feb13_205524|    Summary of generation 13:
21Feb13_205524| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_205524|-----------  ------------------  --------------------  ----------
21Feb13_205524|    Max            38.78                39.00           0.65460
21Feb13_205524|    Avg            36.98                10.27           0.06558
21Feb13_205524|    Min            22.96                 2.00           0.00000
21Feb13_205524|    Std             3.08                 8.10           0.13927
21Feb13_205524|   Best            22.96                 7.00           0.65460
21Feb13_205524|-- Generation 14 --
21Feb13_205524|    -- Crossed 4 individual pairs.
21Feb13_205524|    -- Mutated 32 individuals.
21Feb13_205914|    -- Evaluated 64 individuals.
21Feb13_205914|    Summary of generation 14:
21Feb13_205914| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_205914|-----------  ------------------  --------------------  ----------
21Feb13_205914|    Max            39.13                42.00           0.55767
21Feb13_205914|    Avg            37.13                10.17           0.06228
21Feb13_205914|    Min            26.43                 2.00           0.00000
21Feb13_205914|    Std             2.59                 7.91           0.11774
21Feb13_205914|   Best            26.43                24.00           0.55767
21Feb13_205914|-- Generation 15 --
21Feb13_205914|    -- Crossed 1 individual pairs.
21Feb13_205914|    -- Mutated 32 individuals.
21Feb13_210304|    -- Evaluated 64 individuals.
21Feb13_210304|    Summary of generation 15:
21Feb13_210304| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_210304|-----------  ------------------  --------------------  ----------
21Feb13_210304|    Max            48.78                42.00           0.79138
21Feb13_210304|    Avg            36.81                10.31           0.10002
21Feb13_210304|    Min            26.43                 2.00           0.00000
21Feb13_210304|    Std             3.49                 7.38           0.18416
21Feb13_210304|   Best            26.43                20.00           0.49853
21Feb13_210304|-- Generation 16 --
21Feb13_210304|    -- Crossed 3 individual pairs.
21Feb13_210304|    -- Mutated 32 individuals.
21Feb13_210655|    -- Evaluated 64 individuals.
21Feb13_210655|    Summary of generation 16:
21Feb13_210655| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_210655|-----------  ------------------  --------------------  ----------
21Feb13_210655|    Max            38.87                26.00           0.77362
21Feb13_210655|    Avg            36.26                10.59           0.09835
21Feb13_210655|    Min            21.74                 4.00           0.00000
21Feb13_210655|    Std             3.53                 6.73           0.16575
21Feb13_210655|   Best            21.74                18.00           0.63093
21Feb13_210655|-- Generation 17 --
21Feb13_210655|    -- Crossed 1 individual pairs.
21Feb13_210655|    -- Mutated 32 individuals.
21Feb13_211044|    -- Evaluated 64 individuals.
21Feb13_211044|    Summary of generation 17:
21Feb13_211044| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_211044|-----------  ------------------  --------------------  ----------
21Feb13_211044|    Max            38.96                24.00           0.71867
21Feb13_211044|    Avg            36.11                 9.70           0.10177
21Feb13_211044|    Min            24.35                 4.00           0.00000
21Feb13_211044|    Std             3.64                 5.77           0.16931
21Feb13_211044|   Best            24.35                24.00           0.61856
21Feb13_211044|-- Generation 18 --
21Feb13_211044|    -- Crossed 4 individual pairs.
21Feb13_211044|    -- Mutated 32 individuals.
21Feb13_211434|    -- Evaluated 64 individuals.
21Feb13_211434|    Summary of generation 18:
21Feb13_211434| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_211434|-----------  ------------------  --------------------  ----------
21Feb13_211434|    Max            38.70                42.00           0.77293
21Feb13_211434|    Avg            36.20                 9.72           0.09772
21Feb13_211434|    Min            22.26                 4.00           0.00000
21Feb13_211434|    Std             3.47                 7.19           0.15954
21Feb13_211434|   Best            22.26                 7.00           0.77293
21Feb13_211434|-- Generation 19 --
21Feb13_211434|    -- Crossed 2 individual pairs.
21Feb13_211434|    -- Mutated 32 individuals.
21Feb13_211825|    -- Evaluated 64 individuals.
21Feb13_211825|    Summary of generation 19:
21Feb13_211825| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_211825|-----------  ------------------  --------------------  ----------
21Feb13_211825|    Max            38.61                33.00           0.75826
21Feb13_211825|    Avg            36.33                10.64           0.09834
21Feb13_211825|    Min            28.61                 4.00           0.00000
21Feb13_211825|    Std             2.32                 7.20           0.14332
21Feb13_211825|   Best            28.61                33.00           0.70965
21Feb13_211825|-- Generation 20 --
21Feb13_211825|    -- Crossed 3 individual pairs.
21Feb13_211825|    -- Mutated 32 individuals.
21Feb13_212214|    -- Evaluated 64 individuals.
21Feb13_212214|    Summary of generation 20:
21Feb13_212214| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_212214|-----------  ------------------  --------------------  ----------
21Feb13_212214|    Max            38.70                45.00           0.59896
21Feb13_212214|    Avg            36.62                10.41           0.07449
21Feb13_212214|    Min            24.35                 4.00           0.00000
21Feb13_212214|    Std             2.45                 8.22           0.10160
21Feb13_212214|   Best            24.35                33.00           0.59896
21Feb13_212214|-- Generation 21 --
21Feb13_212214|    -- Crossed 4 individual pairs.
21Feb13_212214|    -- Mutated 32 individuals.
21Feb13_212601|    -- Evaluated 64 individuals.
21Feb13_212601|    Summary of generation 21:
21Feb13_212601| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_212601|-----------  ------------------  --------------------  ----------
21Feb13_212601|    Max            38.61                36.00           0.75387
21Feb13_212601|    Avg            35.44                 9.53           0.12674
21Feb13_212601|    Min            23.74                 4.00           0.00000
21Feb13_212601|    Std             3.46                 6.62           0.16428
21Feb13_212601|   Best            23.74                 6.00           0.73666
21Feb13_212601|-- Generation 22 --
21Feb13_212601|    -- Crossed 1 individual pairs.
21Feb13_212601|    -- Mutated 32 individuals.
21Feb13_212952|    -- Evaluated 64 individuals.
21Feb13_212952|    Summary of generation 22:
21Feb13_212952| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_212952|-----------  ------------------  --------------------  ----------
21Feb13_212952|    Max            38.70                56.00           0.84890
21Feb13_212952|    Avg            36.15                11.11           0.10685
21Feb13_212952|    Min            23.04                 4.00           0.00000
21Feb13_212952|    Std             2.91                 9.71           0.16672
21Feb13_212952|   Best            23.04                56.00           0.84890
21Feb13_212952|-- Generation 23 --
21Feb13_212952|    -- Crossed 3 individual pairs.
21Feb13_212952|    -- Mutated 32 individuals.
21Feb13_213343|    -- Evaluated 64 individuals.
21Feb13_213343|    Summary of generation 23:
21Feb13_213343| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_213343|-----------  ------------------  --------------------  ----------
21Feb13_213343|    Max            38.61                56.00           0.74843
21Feb13_213343|    Avg            35.44                12.23           0.13825
21Feb13_213343|    Min            20.78                 3.00           0.00000
21Feb13_213343|    Std             3.71                11.18           0.18980
21Feb13_213343|   Best            20.78                56.00           0.70115
21Feb13_213343|-- Generation 24 --
21Feb13_213343|    -- Crossed 1 individual pairs.
21Feb13_213343|    -- Mutated 32 individuals.
21Feb13_213734|    -- Evaluated 64 individuals.
21Feb13_213734|    Summary of generation 24:
21Feb13_213734| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_213734|-----------  ------------------  --------------------  ----------
21Feb13_213734|    Max            38.61                56.00           0.83968
21Feb13_213734|    Avg            34.96                13.20           0.16758
21Feb13_213734|    Min            21.30                 3.00           0.00000
21Feb13_213734|    Std             4.05                12.33           0.21913
21Feb13_213734|   Best            21.30                 7.00           0.69093
21Feb13_213734|-- Generation 25 --
21Feb13_213734|    -- Crossed 1 individual pairs.
21Feb13_213734|    -- Mutated 32 individuals.
21Feb13_214127|    -- Evaluated 64 individuals.
21Feb13_214127|    Summary of generation 25:
21Feb13_214127| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_214127|-----------  ------------------  --------------------  ----------
21Feb13_214127|    Max            38.52                60.00           0.85027
21Feb13_214127|    Avg            34.57                13.50           0.18210
21Feb13_214127|    Min            23.04                 2.00           0.00000
21Feb13_214127|    Std             4.42                12.74           0.23311
21Feb13_214127|   Best            23.04                56.00           0.85027
21Feb13_214127|-- Generation 26 --
21Feb13_214127|    -- Crossed 3 individual pairs.
21Feb13_214127|    -- Mutated 32 individuals.
21Feb13_214520|    -- Evaluated 64 individuals.
21Feb13_214520|    Summary of generation 26:
21Feb13_214520| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_214520|-----------  ------------------  --------------------  ----------
21Feb13_214520|    Max            39.22                60.00           0.81708
21Feb13_214520|    Avg            34.44                15.16           0.18796
21Feb13_214520|    Min            19.74                 3.00           0.00000
21Feb13_214520|    Std             4.90                13.35           0.24007
21Feb13_214520|   Best            19.74                56.00           0.81708
21Feb13_214520|-- Generation 27 --
21Feb13_214520|    -- Crossed 3 individual pairs.
21Feb13_214520|    -- Mutated 32 individuals.
21Feb13_214914|    -- Evaluated 64 individuals.
21Feb13_214914|    Summary of generation 27:
21Feb13_214914| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_214914|-----------  ------------------  --------------------  ----------
21Feb13_214914|    Max            41.65                95.00           0.80530
21Feb13_214914|    Avg            34.95                16.45           0.17725
21Feb13_214914|    Min            20.26                 3.00           0.00000
21Feb13_214914|    Std             4.61                14.91           0.22772
21Feb13_214914|   Best            20.26                56.00           0.70309
21Feb13_214914|-- Generation 28 --
21Feb13_214914|    -- Crossed 0 individual pairs.
21Feb13_214914|    -- Mutated 32 individuals.
21Feb13_215306|    -- Evaluated 64 individuals.
21Feb13_215306|    Summary of generation 28:
21Feb13_215306| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_215306|-----------  ------------------  --------------------  ----------
21Feb13_215306|    Max            38.61                60.00           0.74821
21Feb13_215306|    Avg            35.29                15.06           0.13465
21Feb13_215306|    Min            20.70                 3.00           0.00000
21Feb13_215306|    Std             3.97                13.40           0.17860
21Feb13_215306|   Best            20.70                33.00           0.74821
21Feb13_215306|-- Generation 29 --
21Feb13_215306|    -- Crossed 2 individual pairs.
21Feb13_215306|    -- Mutated 32 individuals.
21Feb13_215658|    -- Evaluated 64 individuals.
21Feb13_215658|    Summary of generation 29:
21Feb13_215658| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_215658|-----------  ------------------  --------------------  ----------
21Feb13_215658|    Max            56.09                52.00           0.78739
21Feb13_215658|    Avg            36.30                12.91           0.12111
21Feb13_215658|    Min            27.30                 3.00           0.00000
21Feb13_215658|    Std             3.74                10.97           0.16555
21Feb13_215658|   Best            27.30                33.00           0.78739
21Feb13_215658|-- Generation 30 --
21Feb13_215658|    -- Crossed 2 individual pairs.
21Feb13_215658|    -- Mutated 32 individuals.
21Feb13_220048|    -- Evaluated 64 individuals.
21Feb13_220048|    Summary of generation 30:
21Feb13_220048| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_220048|-----------  ------------------  --------------------  ----------
21Feb13_220048|    Max            38.87                33.00           0.81009
21Feb13_220048|    Avg            35.43                10.89           0.14027
21Feb13_220048|    Min            21.91                 5.00           0.00000
21Feb13_220048|    Std             3.51                 7.69           0.18728
21Feb13_220048|   Best            21.91                33.00           0.80687
21Feb13_220048|-- Generation 31 --
21Feb13_220048|    -- Crossed 6 individual pairs.
21Feb13_220048|    -- Mutated 32 individuals.
21Feb13_220438|    -- Evaluated 64 individuals.
21Feb13_220438|    Summary of generation 31:
21Feb13_220438| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_220438|-----------  ------------------  --------------------  ----------
21Feb13_220438|    Max            38.52                36.00           0.77715
21Feb13_220438|    Avg            35.02                10.42           0.15204
21Feb13_220438|    Min            17.13                 5.00           0.00000
21Feb13_220438|    Std             3.74                 6.89           0.18029
21Feb13_220438|   Best            17.13                36.00           0.76379
21Feb13_220438|-- Generation 32 --
21Feb13_220438|    -- Crossed 2 individual pairs.
21Feb13_220438|    -- Mutated 32 individuals.
21Feb13_220829|    -- Evaluated 64 individuals.
21Feb13_220829|    Summary of generation 32:
21Feb13_220829| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_220829|-----------  ------------------  --------------------  ----------
21Feb13_220829|    Max            56.52                51.00           0.86228
21Feb13_220829|    Avg            34.38                13.02           0.21444
21Feb13_220829|    Min            22.43                 5.00           0.00000
21Feb13_220829|    Std             4.88                 9.93           0.22902
21Feb13_220829|   Best            22.43                36.00           0.86228
21Feb13_220829|Best initial individual weights
21Feb13_220829|Individual:
21Feb13_220829|-- Constant hidden layers --
21Feb13_220829|False
21Feb13_220829|Layer 0:
21Feb13_220829|-- Config --
21Feb13_220829|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 11, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220829|-- Weights --
21Feb13_220829|[[ 0.46156 -0.84277 -0.22568 -0.50996 -0.18647  0.74122  0.12973  0.16913
21Feb13_220829|  -0.21673 -0.59271  0.73136]
21Feb13_220829| [-0.34142 -0.49046  0.95750 -0.97233  0.07730  0.23974  0.01821 -0.55712
21Feb13_220829|   0.29515 -0.88897 -0.11559]
21Feb13_220829| [ 0.19671 -0.15301 -0.09018 -0.24452 -0.41953  0.15258  0.70736  0.22475
21Feb13_220829|  -0.18941  0.63199 -0.53833]
21Feb13_220829| [-0.75876 -0.94729  0.39322  0.76233 -0.72082  0.78982 -0.99506 -0.09535
21Feb13_220829|   0.18006  0.81908 -0.40380]
21Feb13_220829| [ 0.67659  0.67803  0.32462  0.17474  0.87408 -0.29092  0.50592  0.72894
21Feb13_220829|  -0.19482  0.72472  0.11818]
21Feb13_220829| [-0.66955 -0.73584  0.53480  0.49365 -0.07939 -0.35309 -0.73923 -0.49602
21Feb13_220829|  -0.22049 -0.14190  0.71721]
21Feb13_220829| [-0.79263  0.67121 -0.16223 -0.37137 -0.51415 -0.25089  0.94908 -0.21636
21Feb13_220829|   0.89535  0.30128 -0.93309]
21Feb13_220829| [-0.64648 -0.77753  0.21308 -0.62218 -0.24603 -0.51568  0.48051  0.53451
21Feb13_220829|   0.69055 -0.17948  0.21615]
21Feb13_220829| [ 0.19212  0.19034  0.62794 -0.69032 -0.88218 -0.87517  0.83172 -0.10710
21Feb13_220829|  -0.34197 -0.16423  0.85052]
21Feb13_220829| [ 0.58053 -0.47927 -0.57968 -0.53076  0.56056  0.56318 -0.78047 -0.67923
21Feb13_220829|  -0.99355 -0.43780  0.24345]
21Feb13_220829| [ 0.34856 -0.89892  0.72957 -0.88989 -0.64530  0.02886  0.37805  0.04132
21Feb13_220829|  -0.85562 -0.35674  0.15408]
21Feb13_220829| [ 0.63328  0.90154 -0.76917  0.96275  0.39363 -0.02203  0.70402 -0.77667
21Feb13_220829|  -0.62533  0.24145 -0.33060]
21Feb13_220829| [-0.15913 -0.98060  0.58153  0.18921 -0.97892 -0.66739 -0.92320  0.18200
21Feb13_220829|   0.63483 -0.61560  0.45894]
21Feb13_220829| [ 0.26317 -0.46409 -0.39611 -0.34134 -0.44145 -0.22776 -0.71825 -0.02512
21Feb13_220829|   0.82600 -0.22713  0.14618]
21Feb13_220829| [ 0.82930 -0.28286  0.51722 -0.61681  0.90021  0.76276 -0.91303  0.41267
21Feb13_220829|  -0.72574 -0.87163 -0.12995]
21Feb13_220829| [-0.51736  0.84213  0.99320  0.19479  0.79148 -0.00868 -0.87948  0.08187
21Feb13_220829|  -0.53860 -0.41084  0.61311]
21Feb13_220829| [-0.31297  0.59008  0.99296  0.31656  0.06285  0.64120 -0.31099  0.51513
21Feb13_220829|  -0.43232 -0.58976  0.23846]
21Feb13_220829| [ 0.65579 -0.89609  0.19396 -0.58527  0.69232 -0.88414 -0.09072 -0.68932
21Feb13_220829|  -0.69171 -0.21130  0.44286]
21Feb13_220829| [ 0.49749 -0.53324  0.56851  0.09048 -0.86033 -0.18757 -0.40228 -0.87280
21Feb13_220829|   0.58916  0.77012 -0.63919]
21Feb13_220829| [ 0.12018 -0.95411 -0.72984  0.53219 -0.34616 -0.32513  0.71577  0.31407
21Feb13_220829|  -0.27608  0.31351 -0.35381]
21Feb13_220829| [-0.92506  0.30790 -0.58125  0.16272 -0.23022 -0.80441 -0.30016  0.93635
21Feb13_220829|   0.72339  0.90620  0.67251]
21Feb13_220829| [ 0.95530  0.63710 -0.80814 -0.89797  0.28457  0.04758 -0.65087 -0.49658
21Feb13_220829|  -0.77933 -0.89945 -0.33491]
21Feb13_220829| [-0.73198 -0.32008  0.30035  0.94852  0.60335  0.09708  0.22408  0.03524
21Feb13_220829|   0.26623  0.15536 -0.49701]
21Feb13_220829| [-0.15413  0.34885 -0.72261 -0.45820 -0.69063 -0.42229 -0.00118 -0.21610
21Feb13_220829|   0.97891 -0.88030  0.47623]
21Feb13_220829| [-0.02087 -0.72000  0.30120 -0.80775  0.78944 -0.01415 -0.92439  0.23635
21Feb13_220829|   0.18041 -0.73091 -0.24119]
21Feb13_220829| [-0.18178 -0.72110  0.80020 -0.86084  0.80111  0.04660 -0.25789 -0.77162
21Feb13_220829|   0.30131 -0.04128  0.86601]
21Feb13_220829| [ 0.74938  0.24531  0.49469  0.65306 -0.64403 -0.50531  0.67535  0.42567
21Feb13_220829|  -0.88681  0.88365  0.57275]
21Feb13_220829| [ 0.61793 -0.60591 -0.95873  0.82733  0.20855  0.63858  0.11719 -0.70281
21Feb13_220829|   0.90278 -0.73134 -0.27009]
21Feb13_220829| [ 0.68615 -0.66283  0.04250 -0.63324  0.81231 -0.03717  0.03130 -0.94612
21Feb13_220829|   0.50452 -0.57023  0.52201]
21Feb13_220829| [ 0.07436 -0.49388  0.09451  0.46407  0.81160  0.01747 -0.74353 -0.81128
21Feb13_220829|  -0.40479  0.82579  0.99725]
21Feb13_220829| [-0.08100  0.07427  0.89833 -0.82119  0.69745  0.13422  0.36783 -0.73814
21Feb13_220829|   0.27100 -0.45010 -0.11706]
21Feb13_220829| [-0.12450  0.38075  0.95939 -0.75603  0.62593  0.48885  0.80826 -0.77832
21Feb13_220829|  -0.08250  0.65245 -0.98096]
21Feb13_220829| [ 0.36840  0.93952 -0.62803 -0.20614  0.79480  0.91722 -0.90007  0.81492
21Feb13_220829|  -0.60906 -0.13822 -0.42728]
21Feb13_220829| [-0.64488 -0.43686 -0.79983  0.48295  0.01275  0.05227 -0.90070  0.06205
21Feb13_220829|   0.73141 -0.88780 -0.68008]
21Feb13_220829| [-0.35766 -0.94308  0.20279 -0.01764 -0.34853 -0.56298 -0.70361 -0.28824
21Feb13_220829|   0.71152 -0.01610 -0.76744]
21Feb13_220829| [-0.52639  0.50210  0.65861  0.44058  0.87250 -0.36064  0.04803 -0.82127
21Feb13_220829|  -0.15983 -0.54440  0.85838]
21Feb13_220829| [ 0.62030 -0.24830 -0.49870  0.58496 -0.58340  0.41398 -0.83676  0.18844
21Feb13_220829|   0.13032  0.54927 -0.54255]
21Feb13_220829| [-0.53953  0.70914 -0.38719  0.74898 -0.83592  0.26169  0.99023  0.99936
21Feb13_220829|   0.75254 -0.28578 -0.22916]
21Feb13_220829| [ 0.23337 -0.36826 -0.84238  0.41740  0.29491 -0.72677 -0.07455  0.86715
21Feb13_220829|   0.88307 -0.74167 -0.27355]
21Feb13_220829| [ 0.04816  0.48525 -0.74426 -0.61987  0.58929  0.18628  0.95215  0.97644
21Feb13_220829|   0.52484  0.38709 -0.89610]
21Feb13_220829| [ 0.55206 -0.91608 -0.05119  0.78188  0.62319 -0.89453  0.86896  0.80890
21Feb13_220829|  -0.29647  0.01872  0.17831]
21Feb13_220829| [ 0.42220 -0.07057 -0.84375 -0.52242  0.57595 -0.16678 -0.30945 -0.78803
21Feb13_220829|  -0.96702 -0.57209  0.28572]
21Feb13_220829| [ 0.44938  0.62285  0.34202  0.75939  0.27177 -0.80879 -0.17292 -0.14618
21Feb13_220829|   0.99636 -0.35621 -0.34148]
21Feb13_220829| [ 0.44383  0.33111 -0.19249  0.25318  0.28964 -0.08683 -0.70032  0.29827
21Feb13_220829|  -0.61222 -0.08441 -0.74944]
21Feb13_220829| [-0.51631 -0.67304  0.07716  0.25530  0.43512  0.99840 -0.11257  0.36044
21Feb13_220829|   0.26019  0.26291  0.88620]
21Feb13_220829| [-0.97805 -0.13415  0.25268 -0.19824  0.35973  0.92227 -0.02086 -0.09807
21Feb13_220829|   0.44180 -0.62591 -0.82882]
21Feb13_220829| [ 0.59917 -0.94368  0.11743  0.27201  0.45839 -0.33014 -0.33718 -0.72683
21Feb13_220829|   0.26701 -0.13187  0.16695]
21Feb13_220829| [-0.21617  0.59286 -0.52080  0.45399  0.58378  0.62486  0.99748  0.74203
21Feb13_220829|  -0.37741 -0.78882 -0.06936]
21Feb13_220829| [-0.61019 -0.19669 -0.34611  0.66314 -0.51139  0.48959  0.42887  0.55545
21Feb13_220829|   0.06698  0.04537 -0.87143]
21Feb13_220829| [ 0.03769  0.33448 -0.83834  0.22264 -0.20081 -0.37369 -0.01191 -0.02856
21Feb13_220829|  -0.18197 -0.46795  0.15897]
21Feb13_220829| [-0.25895 -0.39593 -0.62962 -0.40587 -0.30512  0.58183  0.71841 -0.10650
21Feb13_220829|  -0.34730  0.72074 -0.41597]
21Feb13_220829| [-0.30888  0.83513 -0.94608  0.15732  0.66184 -0.59164  0.88078 -0.35222
21Feb13_220829|   0.03447 -0.88073 -0.15461]
21Feb13_220829| [ 0.65528 -0.10935 -0.17975 -0.44352 -0.37960 -0.70180 -0.75068  0.74882
21Feb13_220829|  -0.89516 -0.78717 -0.31925]
21Feb13_220829| [-0.04084 -0.63857 -0.60833 -0.86044 -0.36060  0.35863 -0.21565 -0.54523
21Feb13_220829|  -0.53325  0.17239  0.69990]
21Feb13_220829| [ 0.97885 -0.12170 -0.71989 -0.75297  0.21089  0.94010 -0.95947 -0.33500
21Feb13_220829|  -0.18277 -0.93301  0.59758]
21Feb13_220829| [ 0.85027  0.94989 -0.61888  0.00132  0.03665  0.85438  0.91330  0.03308
21Feb13_220829|  -0.82748  0.07924 -0.91554]
21Feb13_220829| [-0.03278 -0.48901 -0.33692 -0.80823  0.70334  0.75718  0.56360  0.29023
21Feb13_220829|  -0.90300 -0.50756  0.04004]]
21Feb13_220829|-- Bias --
21Feb13_220829|[ 0.96354  0.94829 -0.94615  0.29592 -0.49326 -0.95263  0.20334  0.89945
21Feb13_220829|  0.04192 -0.20826 -0.05801]
21Feb13_220829|Layer 1:
21Feb13_220829|-- Config --
21Feb13_220829|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 11], 'dtype': 'float32', 'units': 15, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220829|-- Weights --
21Feb13_220829|[[ 0.12624  0.83147 -0.61486 -0.37490  0.90546  0.71530 -0.88079 -0.94587
21Feb13_220829|  -0.28561  0.45546 -0.10789  0.83522 -0.84093  0.39527  0.83301]
21Feb13_220829| [ 0.98951 -0.97384 -0.22760 -0.31419  0.03143 -0.86785 -0.04479 -0.08200
21Feb13_220829|  -0.15940  0.40006 -0.13946  0.64945  0.54932 -0.76136  0.30777]
21Feb13_220829| [ 0.67211  0.03789 -0.11624  0.80009 -0.71290 -0.44615 -0.07116 -0.72539
21Feb13_220829|   0.75729  0.00954  0.08530 -0.06510 -0.81471 -0.78039  0.08806]
21Feb13_220829| [-0.88356 -0.58102  0.58349  0.50216  0.80266  0.93345 -0.85666  0.33087
21Feb13_220829|   0.48417  0.17860 -0.57177  0.27292  0.46198 -0.86291  0.76472]
21Feb13_220829| [ 0.55151  0.10339  0.22808 -0.63447 -0.79835 -0.98564  0.63205 -0.84692
21Feb13_220829|   0.97242 -0.50414  0.67677 -0.02345 -0.75943 -0.90298 -0.45389]
21Feb13_220829| [-0.36861  0.55729 -0.20262  0.83045 -0.87171 -0.89379  0.00633 -0.23091
21Feb13_220829|  -0.95829 -0.46448 -0.47024  0.70013 -0.38917  0.82132  0.90858]
21Feb13_220829| [-0.05771 -0.77098  0.81138 -0.59784  0.35023 -0.78897  0.00675 -0.40607
21Feb13_220829|   0.32760  0.49983 -0.25636 -0.95494 -0.58504 -0.03358 -0.40552]
21Feb13_220829| [-0.97284 -0.98973 -0.51763  0.70790  0.27199  0.74072  0.14217 -0.31149
21Feb13_220829|  -0.41738 -0.61039  0.99634  0.86640 -0.53771 -0.89706  0.63251]
21Feb13_220829| [ 0.60212  0.52405  0.81437  0.22913 -0.91098 -0.66411 -0.36272  0.76208
21Feb13_220829|  -0.51770  0.70485 -0.14646  0.21942  0.30804  0.65676  0.67761]
21Feb13_220829| [ 0.39245  0.38645  0.19223 -0.00366  0.23057 -0.12726 -0.51919  0.03560
21Feb13_220829|  -0.62945 -0.60461 -0.14267  0.49378 -0.66295  0.15394 -0.32695]
21Feb13_220829| [ 0.64896 -0.83386 -0.54453  0.17384 -0.25507 -0.56471 -0.55835  0.28651
21Feb13_220829|  -0.63933 -0.03990  0.69226 -0.30216  0.25120  0.63246  0.48033]]
21Feb13_220829|-- Bias --
21Feb13_220829|[ 0.64416 -0.88121  0.91364 -0.46742  0.65875 -0.90983 -0.38207  0.13445
21Feb13_220829| -0.87588 -0.83549  0.17215  0.92650 -0.81040  0.10950 -0.61825]
21Feb13_220829|Layer 2:
21Feb13_220829|-- Config --
21Feb13_220829|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 15], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220829|-- Weights --
21Feb13_220829|[[ 0.37134  0.55222]
21Feb13_220829| [-0.18791  0.99596]
21Feb13_220829| [-0.95839 -0.63762]
21Feb13_220829| [ 0.10111  0.87081]
21Feb13_220829| [ 0.32555 -0.66393]
21Feb13_220829| [ 0.14939  0.95956]
21Feb13_220829| [ 0.38854 -0.36554]
21Feb13_220829| [-0.18303  0.26304]
21Feb13_220829| [ 0.06022 -0.78830]
21Feb13_220829| [-0.39990  0.72124]
21Feb13_220829| [-0.29330  0.09230]
21Feb13_220829| [-0.29557  0.45368]
21Feb13_220829| [ 0.42856  0.21717]
21Feb13_220829| [-0.65774 -0.15569]
21Feb13_220829| [ 0.99461  0.17483]]
21Feb13_220829|-- Bias --
21Feb13_220829|[-0.96451  0.08640]
21Feb13_220829|Predicting the validation and test data with the Best initial individual.
21Feb13_220837| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_220837|-----------  ------------------  --------------------  ----------
21Feb13_220837|Validation         38.35                  52            0.00283
21Feb13_220837|   Test            39.44                  52            0.00275
21Feb13_220837|-------------------- Test #0 --------------------
21Feb13_220837|Best final individual weights
21Feb13_220837|Individual:
21Feb13_220837|-- Constant hidden layers --
21Feb13_220837|False
21Feb13_220837|Layer 0:
21Feb13_220837|-- Config --
21Feb13_220837|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220837|-- Weights --
21Feb13_220837|[[-0.40915  0.29174 -0.34361  0.14991  0.48013  0.43962]
21Feb13_220837| [-0.03889 -2.58918  1.23726 -0.94545  0.31112 -0.33123]
21Feb13_220837| [-0.20635  0.94283  0.91953  0.65409  0.05057 -0.26007]
21Feb13_220837| [ 0.43641 -0.76635  0.05389  1.13480  0.41780  0.46235]
21Feb13_220837| [ 1.82634  0.72047  0.74041 -0.14215 -0.12675 -0.24346]
21Feb13_220837| [ 0.28127  0.08807 -1.98005  0.01426  0.26090 -0.14537]
21Feb13_220837| [-1.25185  0.82655  0.46228 -0.55060  0.10941 -0.15674]
21Feb13_220837| [ 0.91445  1.72888 -0.21980  0.73581 -0.72850  0.14657]
21Feb13_220837| [-0.57907 -0.24880  1.15136  0.39596  0.74559  0.44478]
21Feb13_220837| [-1.70002 -0.70915 -2.56272  1.01268  0.12472  0.33916]
21Feb13_220837| [ 0.41868 -1.77356 -1.11896 -0.73114  0.06927  0.26964]
21Feb13_220837| [-1.09531  0.14368 -0.26154 -0.23597  0.45805  0.03320]
21Feb13_220837| [-0.50566 -0.11825  2.29879 -0.11187  0.83873 -0.31067]
21Feb13_220837| [ 0.41226 -2.16123  1.56164  0.08939 -0.72259  0.31162]
21Feb13_220837| [-1.24419  0.81010 -1.10440 -0.20148  0.35840 -0.33718]
21Feb13_220837| [-0.12460  0.61383 -0.45420  0.83739  0.56627 -0.42802]
21Feb13_220837| [-0.39166 -2.48851  1.52386 -1.32659  0.30787  0.13333]
21Feb13_220837| [-0.93483  0.69438 -0.95500  1.27853  0.05581  0.28043]
21Feb13_220837| [ 0.56230 -0.94056  0.46910  0.10418 -0.19409 -0.47523]
21Feb13_220837| [-2.07937  0.22698  1.42960  0.92495  0.47285  0.03640]
21Feb13_220837| [-0.37785  0.95082  1.95371 -0.51694 -0.55583 -0.47787]
21Feb13_220837| [-0.55685  0.99330 -2.63246  1.05090 -0.43896  0.28635]
21Feb13_220837| [ 1.18738  0.35601  1.18799  0.87220 -0.10480  0.27707]
21Feb13_220837| [-0.86533 -1.24460  0.85164  0.74349  0.54417  0.29889]
21Feb13_220837| [-0.24069 -1.24668  0.16743  0.84590  0.21360  0.29043]
21Feb13_220837| [ 0.63554  0.81106 -0.00390  1.39866  0.46540  0.17208]
21Feb13_220837| [ 0.30270  1.13969 -0.75028 -0.78198 -1.02639  0.05785]
21Feb13_220837| [-0.96730  0.20619 -1.16463  1.39466  0.57145  0.19332]
21Feb13_220837| [ 0.96709 -2.84136  0.18157 -0.77198  0.68265 -0.43429]
21Feb13_220837| [-1.15123 -0.32784 -1.75614  1.26760  0.32257 -0.39679]
21Feb13_220837| [ 1.65321 -0.51426  3.04899 -1.65205 -1.16383  0.16424]
21Feb13_220837| [-1.04445  1.98716 -1.72225 -1.62612 -0.39208  0.05691]
21Feb13_220837| [-0.03870  3.82088  0.10601 -1.50340  0.64469 -0.18022]
21Feb13_220837| [ 0.70423 -0.51765 -0.97406 -0.13983  0.39618 -0.43729]
21Feb13_220837| [ 0.11732 -1.38663 -1.62332 -1.08766 -0.63584 -0.02089]
21Feb13_220837| [-0.69095 -1.90050  0.56484  1.12305  0.68882 -0.42906]
21Feb13_220837| [ 1.84548  0.44085  0.64487 -0.70848 -0.82392 -0.36589]
21Feb13_220837| [ 0.09851  2.13277  0.57030 -0.79303  0.48128 -0.42670]
21Feb13_220837| [ 0.11840 -0.81597 -0.12555  0.58548  0.52800  0.32666]
21Feb13_220837| [-0.21547  1.51130 -1.44840 -0.95307  0.80526  0.45558]
21Feb13_220837| [ 0.65240  0.91420 -1.25405 -1.21548 -0.15191  0.32359]
21Feb13_220837| [-0.09876 -0.42450 -0.24028 -0.61702 -0.04275  0.08542]
21Feb13_220837| [-0.70354  1.07974 -0.49390  0.67614 -0.00435  0.12051]
21Feb13_220837| [-1.81032 -0.94975 -0.34274  0.23071  0.39457  0.45390]
21Feb13_220837| [-0.23721  0.17217 -0.42835 -1.68301 -0.30137  0.06268]
21Feb13_220837| [ 0.35544 -2.92353  1.61345 -1.99230 -0.39892  0.40786]
21Feb13_220837| [ 0.92536  0.52707  0.67114 -0.82958 -0.71602  0.46510]
21Feb13_220837| [-0.92465 -2.10152 -0.00460 -0.06597  0.49376 -0.49032]
21Feb13_220837| [ 0.45803  1.52102  0.44313 -0.89222  0.25115  0.38088]
21Feb13_220837| [-0.55595 -1.75173 -0.51886 -0.83852  0.43962 -0.35753]
21Feb13_220837| [ 1.05043  0.13022  0.50909  1.35826  0.06262  0.37678]
21Feb13_220837| [-0.73516 -1.66793 -1.03505 -0.32304  0.29883 -0.45118]
21Feb13_220837| [-0.98587 -1.27575  1.32223  1.83009 -0.24774 -0.02303]
21Feb13_220837| [ 0.62667  1.15369  1.08062 -0.95194 -0.33125  0.49280]
21Feb13_220837| [ 0.29335  0.50911 -0.31591 -0.47999 -0.68764  0.21059]
21Feb13_220837| [-0.57894  0.76114 -0.65343  0.71286  0.78908  0.25605]
21Feb13_220837| [-0.31510 -0.63291  0.15396 -1.15177 -0.27702  0.28602]]
21Feb13_220837|-- Bias --
21Feb13_220837|[ 0.33651 -0.10761 -0.53450  0.36499 -0.01881  0.10157]
21Feb13_220837|Layer 1:
21Feb13_220837|-- Config --
21Feb13_220837|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220837|-- Weights --
21Feb13_220837|[[-0.31032 -1.54200  0.38873  1.86483]
21Feb13_220837| [ 0.27827  0.68678 -0.04542  0.33503]
21Feb13_220837| [-0.12370 -2.00154  0.33123 -1.03780]
21Feb13_220837| [ 1.24947 -0.59883  0.08929  0.18047]
21Feb13_220837| [-0.12048 -0.19640  0.34362 -0.41276]
21Feb13_220837| [ 0.22336  0.35012  0.14086 -0.40865]]
21Feb13_220837|-- Bias --
21Feb13_220837|[-0.44268  0.22631 -0.39436 -0.21581]
21Feb13_220837|Layer 2:
21Feb13_220837|-- Config --
21Feb13_220837|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220837|-- Weights --
21Feb13_220837|[[-0.26912 -0.04537]
21Feb13_220837| [-0.13112  0.23976]
21Feb13_220837| [-0.33179 -0.13228]
21Feb13_220837| [-0.22655  0.49163]]
21Feb13_220837|-- Bias --
21Feb13_220837|[ 1.26151 -0.75338]
21Feb13_220837|Layer 3:
21Feb13_220837|-- Config --
21Feb13_220837|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220837|-- Weights --
21Feb13_220837|[[ 0.40923 -1.00526]
21Feb13_220837| [ 0.41626 -0.24565]]
21Feb13_220837|-- Bias --
21Feb13_220837|[-1.04567 -0.78011]
21Feb13_220837|Predicting the validation and test data with the Best final individual.
21Feb13_220845| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_220845|-----------  ------------------  --------------------  ----------
21Feb13_220845|Validation         18.61                  36            0.84480
21Feb13_220845|   Test            22.59                  36            0.84219
21Feb13_220845|-------------------- Test #1 --------------------
21Feb13_220845|Best final individual weights
21Feb13_220845|Individual:
21Feb13_220845|-- Constant hidden layers --
21Feb13_220845|False
21Feb13_220845|Layer 0:
21Feb13_220845|-- Config --
21Feb13_220845|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220845|-- Weights --
21Feb13_220845|[[-0.40915  0.29174 -0.34361  0.14991  0.48013  0.43962]
21Feb13_220845| [-0.03889 -2.58918  1.23726 -0.94545  0.31112 -0.33123]
21Feb13_220845| [-0.20635  0.94283  0.91953  0.65409  0.05057 -0.26007]
21Feb13_220845| [ 0.43641 -0.76635  0.05389  1.13480  0.41780  0.46235]
21Feb13_220845| [ 1.82634  0.72047  0.74041 -0.14215 -0.12675 -0.24346]
21Feb13_220845| [ 0.28127  0.08807 -1.98005  0.01426  0.26090 -0.14537]
21Feb13_220845| [-1.25185  0.82655  0.46228 -0.55060  0.10941 -0.15674]
21Feb13_220845| [ 0.91445  1.72888 -0.21980  0.73581 -0.72850  0.14657]
21Feb13_220845| [-0.57907 -0.24880  1.15136  0.39596  0.74559  0.44478]
21Feb13_220845| [-1.70002 -0.70915 -2.56272  1.01268  0.12472  0.33916]
21Feb13_220845| [ 0.41868 -1.77356 -1.11896 -0.73114  0.06927  0.26964]
21Feb13_220845| [-1.09531  0.14368 -0.26154 -0.23597  0.45805  0.03320]
21Feb13_220845| [-0.50566 -0.11825  2.29879 -0.11187  0.83873 -0.31067]
21Feb13_220845| [ 0.41226 -2.16123  1.56164  0.08939 -0.72259  0.31162]
21Feb13_220845| [-1.24419  0.81010 -1.10440 -0.20148  0.35840 -0.33718]
21Feb13_220845| [-0.12460  0.61383 -0.45420  0.83739  0.56627 -0.42802]
21Feb13_220845| [-0.39166 -2.48851  1.52386 -1.32659  0.30787  0.13333]
21Feb13_220845| [-0.93483  0.69438 -0.95500  1.27853  0.05581  0.28043]
21Feb13_220845| [ 0.56230 -0.94056  0.46910  0.10418 -0.19409 -0.47523]
21Feb13_220845| [-2.07937  0.22698  1.42960  0.92495  0.47285  0.03640]
21Feb13_220845| [-0.37785  0.95082  1.95371 -0.51694 -0.55583 -0.47787]
21Feb13_220845| [-0.55685  0.99330 -2.63246  1.05090 -0.43896  0.28635]
21Feb13_220845| [ 1.18738  0.35601  1.18799  0.87220 -0.10480  0.27707]
21Feb13_220845| [-0.86533 -1.24460  0.85164  0.74349  0.54417  0.29889]
21Feb13_220845| [-0.24069 -1.24668  0.16743  0.84590  0.21360  0.29043]
21Feb13_220845| [ 0.63554  0.81106 -0.00390  1.39866  0.46540  0.17208]
21Feb13_220845| [ 0.30270  1.13969 -0.75028 -0.78198 -1.02639  0.05785]
21Feb13_220845| [-0.96730  0.20619 -1.16463  1.39466  0.57145  0.19332]
21Feb13_220845| [ 0.96709 -2.84136  0.18157 -0.77198  0.68265 -0.43429]
21Feb13_220845| [-1.15123 -0.32784 -1.75614  1.26760  0.32257 -0.39679]
21Feb13_220845| [ 1.65321 -0.51426  3.04899 -1.65205 -1.16383  0.16424]
21Feb13_220845| [-1.04445  1.98716 -1.72225 -1.62612 -0.39208  0.05691]
21Feb13_220845| [-0.03870  3.82088  0.10601 -1.50340  0.64469 -0.18022]
21Feb13_220845| [ 0.70423 -0.51765 -0.97406 -0.13983  0.39618 -0.43729]
21Feb13_220845| [ 0.11732 -1.38663 -1.62332 -1.08766 -0.63584 -0.02089]
21Feb13_220845| [-0.69095 -1.90050  0.56484  1.12305  0.68882 -0.42906]
21Feb13_220845| [ 1.84548  0.44085  0.64487 -0.70848 -0.82392 -0.36589]
21Feb13_220845| [ 0.09851  2.13277  0.57030 -0.79303  0.48128 -0.42670]
21Feb13_220845| [ 0.11840 -0.81597 -0.12555  0.58548  0.52800  0.32666]
21Feb13_220845| [-0.21547  1.51130 -1.44840 -0.95307  0.80526  0.45558]
21Feb13_220845| [ 0.65240  0.91420 -1.25405 -1.21548 -0.15191  0.32359]
21Feb13_220845| [-0.09876 -0.42450 -0.24028 -0.61702 -0.04275  0.08542]
21Feb13_220845| [-0.70354  1.07974 -0.49390  0.67614 -0.00435  0.12051]
21Feb13_220845| [-1.81032 -0.94975 -0.34274  0.23071  0.39457  0.45390]
21Feb13_220845| [-0.23721  0.17217 -0.42835 -1.68301 -0.30137  0.06268]
21Feb13_220845| [ 0.35544 -2.92353  1.61345 -1.99230 -0.39892  0.40786]
21Feb13_220845| [ 0.92536  0.52707  0.67114 -0.82958 -0.71602  0.46510]
21Feb13_220845| [-0.92465 -2.10152 -0.00460 -0.06597  0.49376 -0.49032]
21Feb13_220845| [ 0.45803  1.52102  0.44313 -0.89222  0.25115  0.38088]
21Feb13_220845| [-0.55595 -1.75173 -0.51886 -0.83852  0.43962 -0.35753]
21Feb13_220845| [ 1.05043  0.13022  0.50909  1.35826  0.06262  0.37678]
21Feb13_220845| [-0.73516 -1.66793 -1.03505 -0.32304  0.29883 -0.45118]
21Feb13_220845| [-0.98587 -1.27575  1.32223  1.83009 -0.24774 -0.02303]
21Feb13_220845| [ 0.62667  1.15369  1.08062 -0.95194 -0.33125  0.49280]
21Feb13_220845| [ 0.29335  0.50911 -0.31591 -0.47999 -0.68764  0.21059]
21Feb13_220845| [-0.57894  0.76114 -0.65343  0.71286  0.78908  0.25605]
21Feb13_220845| [-0.31510 -0.63291  0.15396 -1.15177 -0.27702  0.28602]]
21Feb13_220845|-- Bias --
21Feb13_220845|[ 0.33651 -0.10761 -0.53450  0.36499 -0.01881  0.10157]
21Feb13_220845|Layer 1:
21Feb13_220845|-- Config --
21Feb13_220845|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220845|-- Weights --
21Feb13_220845|[[-0.31032 -1.54200  0.38873  1.86483]
21Feb13_220845| [ 0.27827  0.68678 -0.04542  0.33503]
21Feb13_220845| [-0.12370 -2.00154  0.33123 -1.03780]
21Feb13_220845| [ 1.24947 -0.59883  0.08929  0.18047]
21Feb13_220845| [-0.12048 -0.19640  0.34362 -0.41276]
21Feb13_220845| [ 0.22336  0.35012  0.14086 -0.40865]]
21Feb13_220845|-- Bias --
21Feb13_220845|[-0.44268  0.22631 -0.39436 -0.21581]
21Feb13_220845|Layer 2:
21Feb13_220845|-- Config --
21Feb13_220845|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220845|-- Weights --
21Feb13_220845|[[-0.26912 -0.04537]
21Feb13_220845| [-0.13112  0.23976]
21Feb13_220845| [-0.33179 -0.13228]
21Feb13_220845| [-0.22655  0.49163]]
21Feb13_220845|-- Bias --
21Feb13_220845|[ 1.26151 -0.75338]
21Feb13_220845|Layer 3:
21Feb13_220845|-- Config --
21Feb13_220845|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220845|-- Weights --
21Feb13_220845|[[ 0.40923 -1.00526]
21Feb13_220845| [ 0.41626 -0.24565]]
21Feb13_220845|-- Bias --
21Feb13_220845|[-1.04567 -0.78011]
21Feb13_220845|Predicting the validation and test data with the Best final individual.
21Feb13_220852| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_220852|-----------  ------------------  --------------------  ----------
21Feb13_220852|Validation         18.52                  36            0.77079
21Feb13_220852|   Test            19.90                  36            0.75472
21Feb13_220852|-------------------- Test #2 --------------------
21Feb13_220852|Best final individual weights
21Feb13_220852|Individual:
21Feb13_220852|-- Constant hidden layers --
21Feb13_220852|False
21Feb13_220852|Layer 0:
21Feb13_220852|-- Config --
21Feb13_220852|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220852|-- Weights --
21Feb13_220852|[[-0.40915  0.29174 -0.34361  0.14991  0.48013  0.43962]
21Feb13_220852| [-0.03889 -2.58918  1.23726 -0.94545  0.31112 -0.33123]
21Feb13_220852| [-0.20635  0.94283  0.91953  0.65409  0.05057 -0.26007]
21Feb13_220852| [ 0.43641 -0.76635  0.05389  1.13480  0.41780  0.46235]
21Feb13_220852| [ 1.82634  0.72047  0.74041 -0.14215 -0.12675 -0.24346]
21Feb13_220852| [ 0.28127  0.08807 -1.98005  0.01426  0.26090 -0.14537]
21Feb13_220852| [-1.25185  0.82655  0.46228 -0.55060  0.10941 -0.15674]
21Feb13_220852| [ 0.91445  1.72888 -0.21980  0.73581 -0.72850  0.14657]
21Feb13_220852| [-0.57907 -0.24880  1.15136  0.39596  0.74559  0.44478]
21Feb13_220852| [-1.70002 -0.70915 -2.56272  1.01268  0.12472  0.33916]
21Feb13_220852| [ 0.41868 -1.77356 -1.11896 -0.73114  0.06927  0.26964]
21Feb13_220852| [-1.09531  0.14368 -0.26154 -0.23597  0.45805  0.03320]
21Feb13_220852| [-0.50566 -0.11825  2.29879 -0.11187  0.83873 -0.31067]
21Feb13_220852| [ 0.41226 -2.16123  1.56164  0.08939 -0.72259  0.31162]
21Feb13_220852| [-1.24419  0.81010 -1.10440 -0.20148  0.35840 -0.33718]
21Feb13_220852| [-0.12460  0.61383 -0.45420  0.83739  0.56627 -0.42802]
21Feb13_220852| [-0.39166 -2.48851  1.52386 -1.32659  0.30787  0.13333]
21Feb13_220852| [-0.93483  0.69438 -0.95500  1.27853  0.05581  0.28043]
21Feb13_220852| [ 0.56230 -0.94056  0.46910  0.10418 -0.19409 -0.47523]
21Feb13_220852| [-2.07937  0.22698  1.42960  0.92495  0.47285  0.03640]
21Feb13_220852| [-0.37785  0.95082  1.95371 -0.51694 -0.55583 -0.47787]
21Feb13_220852| [-0.55685  0.99330 -2.63246  1.05090 -0.43896  0.28635]
21Feb13_220852| [ 1.18738  0.35601  1.18799  0.87220 -0.10480  0.27707]
21Feb13_220852| [-0.86533 -1.24460  0.85164  0.74349  0.54417  0.29889]
21Feb13_220852| [-0.24069 -1.24668  0.16743  0.84590  0.21360  0.29043]
21Feb13_220852| [ 0.63554  0.81106 -0.00390  1.39866  0.46540  0.17208]
21Feb13_220852| [ 0.30270  1.13969 -0.75028 -0.78198 -1.02639  0.05785]
21Feb13_220852| [-0.96730  0.20619 -1.16463  1.39466  0.57145  0.19332]
21Feb13_220852| [ 0.96709 -2.84136  0.18157 -0.77198  0.68265 -0.43429]
21Feb13_220852| [-1.15123 -0.32784 -1.75614  1.26760  0.32257 -0.39679]
21Feb13_220852| [ 1.65321 -0.51426  3.04899 -1.65205 -1.16383  0.16424]
21Feb13_220852| [-1.04445  1.98716 -1.72225 -1.62612 -0.39208  0.05691]
21Feb13_220852| [-0.03870  3.82088  0.10601 -1.50340  0.64469 -0.18022]
21Feb13_220852| [ 0.70423 -0.51765 -0.97406 -0.13983  0.39618 -0.43729]
21Feb13_220852| [ 0.11732 -1.38663 -1.62332 -1.08766 -0.63584 -0.02089]
21Feb13_220852| [-0.69095 -1.90050  0.56484  1.12305  0.68882 -0.42906]
21Feb13_220852| [ 1.84548  0.44085  0.64487 -0.70848 -0.82392 -0.36589]
21Feb13_220852| [ 0.09851  2.13277  0.57030 -0.79303  0.48128 -0.42670]
21Feb13_220852| [ 0.11840 -0.81597 -0.12555  0.58548  0.52800  0.32666]
21Feb13_220852| [-0.21547  1.51130 -1.44840 -0.95307  0.80526  0.45558]
21Feb13_220852| [ 0.65240  0.91420 -1.25405 -1.21548 -0.15191  0.32359]
21Feb13_220852| [-0.09876 -0.42450 -0.24028 -0.61702 -0.04275  0.08542]
21Feb13_220852| [-0.70354  1.07974 -0.49390  0.67614 -0.00435  0.12051]
21Feb13_220852| [-1.81032 -0.94975 -0.34274  0.23071  0.39457  0.45390]
21Feb13_220852| [-0.23721  0.17217 -0.42835 -1.68301 -0.30137  0.06268]
21Feb13_220852| [ 0.35544 -2.92353  1.61345 -1.99230 -0.39892  0.40786]
21Feb13_220852| [ 0.92536  0.52707  0.67114 -0.82958 -0.71602  0.46510]
21Feb13_220852| [-0.92465 -2.10152 -0.00460 -0.06597  0.49376 -0.49032]
21Feb13_220852| [ 0.45803  1.52102  0.44313 -0.89222  0.25115  0.38088]
21Feb13_220852| [-0.55595 -1.75173 -0.51886 -0.83852  0.43962 -0.35753]
21Feb13_220852| [ 1.05043  0.13022  0.50909  1.35826  0.06262  0.37678]
21Feb13_220852| [-0.73516 -1.66793 -1.03505 -0.32304  0.29883 -0.45118]
21Feb13_220852| [-0.98587 -1.27575  1.32223  1.83009 -0.24774 -0.02303]
21Feb13_220852| [ 0.62667  1.15369  1.08062 -0.95194 -0.33125  0.49280]
21Feb13_220852| [ 0.29335  0.50911 -0.31591 -0.47999 -0.68764  0.21059]
21Feb13_220852| [-0.57894  0.76114 -0.65343  0.71286  0.78908  0.25605]
21Feb13_220852| [-0.31510 -0.63291  0.15396 -1.15177 -0.27702  0.28602]]
21Feb13_220852|-- Bias --
21Feb13_220852|[ 0.33651 -0.10761 -0.53450  0.36499 -0.01881  0.10157]
21Feb13_220852|Layer 1:
21Feb13_220852|-- Config --
21Feb13_220852|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220852|-- Weights --
21Feb13_220852|[[-0.31032 -1.54200  0.38873  1.86483]
21Feb13_220852| [ 0.27827  0.68678 -0.04542  0.33503]
21Feb13_220852| [-0.12370 -2.00154  0.33123 -1.03780]
21Feb13_220852| [ 1.24947 -0.59883  0.08929  0.18047]
21Feb13_220852| [-0.12048 -0.19640  0.34362 -0.41276]
21Feb13_220852| [ 0.22336  0.35012  0.14086 -0.40865]]
21Feb13_220852|-- Bias --
21Feb13_220852|[-0.44268  0.22631 -0.39436 -0.21581]
21Feb13_220852|Layer 2:
21Feb13_220852|-- Config --
21Feb13_220852|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220852|-- Weights --
21Feb13_220852|[[-0.26912 -0.04537]
21Feb13_220852| [-0.13112  0.23976]
21Feb13_220852| [-0.33179 -0.13228]
21Feb13_220852| [-0.22655  0.49163]]
21Feb13_220852|-- Bias --
21Feb13_220852|[ 1.26151 -0.75338]
21Feb13_220852|Layer 3:
21Feb13_220852|-- Config --
21Feb13_220852|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220852|-- Weights --
21Feb13_220852|[[ 0.40923 -1.00526]
21Feb13_220852| [ 0.41626 -0.24565]]
21Feb13_220852|-- Bias --
21Feb13_220852|[-1.04567 -0.78011]
21Feb13_220852|Predicting the validation and test data with the Best final individual.
21Feb13_220900| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_220900|-----------  ------------------  --------------------  ----------
21Feb13_220900|Validation         33.13                  36            0.78683
21Feb13_220900|   Test            19.81                  36            0.80128
21Feb13_220900|-------------------- Test #3 --------------------
21Feb13_220900|Best final individual weights
21Feb13_220900|Individual:
21Feb13_220900|-- Constant hidden layers --
21Feb13_220900|False
21Feb13_220900|Layer 0:
21Feb13_220900|-- Config --
21Feb13_220900|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220900|-- Weights --
21Feb13_220900|[[-0.40915  0.29174 -0.34361  0.14991  0.48013  0.43962]
21Feb13_220900| [-0.03889 -2.58918  1.23726 -0.94545  0.31112 -0.33123]
21Feb13_220900| [-0.20635  0.94283  0.91953  0.65409  0.05057 -0.26007]
21Feb13_220900| [ 0.43641 -0.76635  0.05389  1.13480  0.41780  0.46235]
21Feb13_220900| [ 1.82634  0.72047  0.74041 -0.14215 -0.12675 -0.24346]
21Feb13_220900| [ 0.28127  0.08807 -1.98005  0.01426  0.26090 -0.14537]
21Feb13_220900| [-1.25185  0.82655  0.46228 -0.55060  0.10941 -0.15674]
21Feb13_220900| [ 0.91445  1.72888 -0.21980  0.73581 -0.72850  0.14657]
21Feb13_220900| [-0.57907 -0.24880  1.15136  0.39596  0.74559  0.44478]
21Feb13_220900| [-1.70002 -0.70915 -2.56272  1.01268  0.12472  0.33916]
21Feb13_220900| [ 0.41868 -1.77356 -1.11896 -0.73114  0.06927  0.26964]
21Feb13_220900| [-1.09531  0.14368 -0.26154 -0.23597  0.45805  0.03320]
21Feb13_220900| [-0.50566 -0.11825  2.29879 -0.11187  0.83873 -0.31067]
21Feb13_220900| [ 0.41226 -2.16123  1.56164  0.08939 -0.72259  0.31162]
21Feb13_220900| [-1.24419  0.81010 -1.10440 -0.20148  0.35840 -0.33718]
21Feb13_220900| [-0.12460  0.61383 -0.45420  0.83739  0.56627 -0.42802]
21Feb13_220900| [-0.39166 -2.48851  1.52386 -1.32659  0.30787  0.13333]
21Feb13_220900| [-0.93483  0.69438 -0.95500  1.27853  0.05581  0.28043]
21Feb13_220900| [ 0.56230 -0.94056  0.46910  0.10418 -0.19409 -0.47523]
21Feb13_220900| [-2.07937  0.22698  1.42960  0.92495  0.47285  0.03640]
21Feb13_220900| [-0.37785  0.95082  1.95371 -0.51694 -0.55583 -0.47787]
21Feb13_220900| [-0.55685  0.99330 -2.63246  1.05090 -0.43896  0.28635]
21Feb13_220900| [ 1.18738  0.35601  1.18799  0.87220 -0.10480  0.27707]
21Feb13_220900| [-0.86533 -1.24460  0.85164  0.74349  0.54417  0.29889]
21Feb13_220900| [-0.24069 -1.24668  0.16743  0.84590  0.21360  0.29043]
21Feb13_220900| [ 0.63554  0.81106 -0.00390  1.39866  0.46540  0.17208]
21Feb13_220900| [ 0.30270  1.13969 -0.75028 -0.78198 -1.02639  0.05785]
21Feb13_220900| [-0.96730  0.20619 -1.16463  1.39466  0.57145  0.19332]
21Feb13_220900| [ 0.96709 -2.84136  0.18157 -0.77198  0.68265 -0.43429]
21Feb13_220900| [-1.15123 -0.32784 -1.75614  1.26760  0.32257 -0.39679]
21Feb13_220900| [ 1.65321 -0.51426  3.04899 -1.65205 -1.16383  0.16424]
21Feb13_220900| [-1.04445  1.98716 -1.72225 -1.62612 -0.39208  0.05691]
21Feb13_220900| [-0.03870  3.82088  0.10601 -1.50340  0.64469 -0.18022]
21Feb13_220900| [ 0.70423 -0.51765 -0.97406 -0.13983  0.39618 -0.43729]
21Feb13_220900| [ 0.11732 -1.38663 -1.62332 -1.08766 -0.63584 -0.02089]
21Feb13_220900| [-0.69095 -1.90050  0.56484  1.12305  0.68882 -0.42906]
21Feb13_220900| [ 1.84548  0.44085  0.64487 -0.70848 -0.82392 -0.36589]
21Feb13_220900| [ 0.09851  2.13277  0.57030 -0.79303  0.48128 -0.42670]
21Feb13_220900| [ 0.11840 -0.81597 -0.12555  0.58548  0.52800  0.32666]
21Feb13_220900| [-0.21547  1.51130 -1.44840 -0.95307  0.80526  0.45558]
21Feb13_220900| [ 0.65240  0.91420 -1.25405 -1.21548 -0.15191  0.32359]
21Feb13_220900| [-0.09876 -0.42450 -0.24028 -0.61702 -0.04275  0.08542]
21Feb13_220900| [-0.70354  1.07974 -0.49390  0.67614 -0.00435  0.12051]
21Feb13_220900| [-1.81032 -0.94975 -0.34274  0.23071  0.39457  0.45390]
21Feb13_220900| [-0.23721  0.17217 -0.42835 -1.68301 -0.30137  0.06268]
21Feb13_220900| [ 0.35544 -2.92353  1.61345 -1.99230 -0.39892  0.40786]
21Feb13_220900| [ 0.92536  0.52707  0.67114 -0.82958 -0.71602  0.46510]
21Feb13_220900| [-0.92465 -2.10152 -0.00460 -0.06597  0.49376 -0.49032]
21Feb13_220900| [ 0.45803  1.52102  0.44313 -0.89222  0.25115  0.38088]
21Feb13_220900| [-0.55595 -1.75173 -0.51886 -0.83852  0.43962 -0.35753]
21Feb13_220900| [ 1.05043  0.13022  0.50909  1.35826  0.06262  0.37678]
21Feb13_220900| [-0.73516 -1.66793 -1.03505 -0.32304  0.29883 -0.45118]
21Feb13_220900| [-0.98587 -1.27575  1.32223  1.83009 -0.24774 -0.02303]
21Feb13_220900| [ 0.62667  1.15369  1.08062 -0.95194 -0.33125  0.49280]
21Feb13_220900| [ 0.29335  0.50911 -0.31591 -0.47999 -0.68764  0.21059]
21Feb13_220900| [-0.57894  0.76114 -0.65343  0.71286  0.78908  0.25605]
21Feb13_220900| [-0.31510 -0.63291  0.15396 -1.15177 -0.27702  0.28602]]
21Feb13_220900|-- Bias --
21Feb13_220900|[ 0.33651 -0.10761 -0.53450  0.36499 -0.01881  0.10157]
21Feb13_220900|Layer 1:
21Feb13_220900|-- Config --
21Feb13_220900|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220900|-- Weights --
21Feb13_220900|[[-0.31032 -1.54200  0.38873  1.86483]
21Feb13_220900| [ 0.27827  0.68678 -0.04542  0.33503]
21Feb13_220900| [-0.12370 -2.00154  0.33123 -1.03780]
21Feb13_220900| [ 1.24947 -0.59883  0.08929  0.18047]
21Feb13_220900| [-0.12048 -0.19640  0.34362 -0.41276]
21Feb13_220900| [ 0.22336  0.35012  0.14086 -0.40865]]
21Feb13_220900|-- Bias --
21Feb13_220900|[-0.44268  0.22631 -0.39436 -0.21581]
21Feb13_220900|Layer 2:
21Feb13_220900|-- Config --
21Feb13_220900|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220900|-- Weights --
21Feb13_220900|[[-0.26912 -0.04537]
21Feb13_220900| [-0.13112  0.23976]
21Feb13_220900| [-0.33179 -0.13228]
21Feb13_220900| [-0.22655  0.49163]]
21Feb13_220900|-- Bias --
21Feb13_220900|[ 1.26151 -0.75338]
21Feb13_220900|Layer 3:
21Feb13_220900|-- Config --
21Feb13_220900|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220900|-- Weights --
21Feb13_220900|[[ 0.40923 -1.00526]
21Feb13_220900| [ 0.41626 -0.24565]]
21Feb13_220900|-- Bias --
21Feb13_220900|[-1.04567 -0.78011]
21Feb13_220900|Predicting the validation and test data with the Best final individual.
21Feb13_220908| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_220908|-----------  ------------------  --------------------  ----------
21Feb13_220908|Validation         23.74                  36            0.77768
21Feb13_220908|   Test            26.59                  36            0.85047
21Feb13_220908|-------------------- Test #4 --------------------
21Feb13_220908|Best final individual weights
21Feb13_220908|Individual:
21Feb13_220908|-- Constant hidden layers --
21Feb13_220908|False
21Feb13_220908|Layer 0:
21Feb13_220908|-- Config --
21Feb13_220908|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220908|-- Weights --
21Feb13_220908|[[-0.40915  0.29174 -0.34361  0.14991  0.48013  0.43962]
21Feb13_220908| [-0.03889 -2.58918  1.23726 -0.94545  0.31112 -0.33123]
21Feb13_220908| [-0.20635  0.94283  0.91953  0.65409  0.05057 -0.26007]
21Feb13_220908| [ 0.43641 -0.76635  0.05389  1.13480  0.41780  0.46235]
21Feb13_220908| [ 1.82634  0.72047  0.74041 -0.14215 -0.12675 -0.24346]
21Feb13_220908| [ 0.28127  0.08807 -1.98005  0.01426  0.26090 -0.14537]
21Feb13_220908| [-1.25185  0.82655  0.46228 -0.55060  0.10941 -0.15674]
21Feb13_220908| [ 0.91445  1.72888 -0.21980  0.73581 -0.72850  0.14657]
21Feb13_220908| [-0.57907 -0.24880  1.15136  0.39596  0.74559  0.44478]
21Feb13_220908| [-1.70002 -0.70915 -2.56272  1.01268  0.12472  0.33916]
21Feb13_220908| [ 0.41868 -1.77356 -1.11896 -0.73114  0.06927  0.26964]
21Feb13_220908| [-1.09531  0.14368 -0.26154 -0.23597  0.45805  0.03320]
21Feb13_220908| [-0.50566 -0.11825  2.29879 -0.11187  0.83873 -0.31067]
21Feb13_220908| [ 0.41226 -2.16123  1.56164  0.08939 -0.72259  0.31162]
21Feb13_220908| [-1.24419  0.81010 -1.10440 -0.20148  0.35840 -0.33718]
21Feb13_220908| [-0.12460  0.61383 -0.45420  0.83739  0.56627 -0.42802]
21Feb13_220908| [-0.39166 -2.48851  1.52386 -1.32659  0.30787  0.13333]
21Feb13_220908| [-0.93483  0.69438 -0.95500  1.27853  0.05581  0.28043]
21Feb13_220908| [ 0.56230 -0.94056  0.46910  0.10418 -0.19409 -0.47523]
21Feb13_220908| [-2.07937  0.22698  1.42960  0.92495  0.47285  0.03640]
21Feb13_220908| [-0.37785  0.95082  1.95371 -0.51694 -0.55583 -0.47787]
21Feb13_220908| [-0.55685  0.99330 -2.63246  1.05090 -0.43896  0.28635]
21Feb13_220908| [ 1.18738  0.35601  1.18799  0.87220 -0.10480  0.27707]
21Feb13_220908| [-0.86533 -1.24460  0.85164  0.74349  0.54417  0.29889]
21Feb13_220908| [-0.24069 -1.24668  0.16743  0.84590  0.21360  0.29043]
21Feb13_220908| [ 0.63554  0.81106 -0.00390  1.39866  0.46540  0.17208]
21Feb13_220908| [ 0.30270  1.13969 -0.75028 -0.78198 -1.02639  0.05785]
21Feb13_220908| [-0.96730  0.20619 -1.16463  1.39466  0.57145  0.19332]
21Feb13_220908| [ 0.96709 -2.84136  0.18157 -0.77198  0.68265 -0.43429]
21Feb13_220908| [-1.15123 -0.32784 -1.75614  1.26760  0.32257 -0.39679]
21Feb13_220908| [ 1.65321 -0.51426  3.04899 -1.65205 -1.16383  0.16424]
21Feb13_220908| [-1.04445  1.98716 -1.72225 -1.62612 -0.39208  0.05691]
21Feb13_220908| [-0.03870  3.82088  0.10601 -1.50340  0.64469 -0.18022]
21Feb13_220908| [ 0.70423 -0.51765 -0.97406 -0.13983  0.39618 -0.43729]
21Feb13_220908| [ 0.11732 -1.38663 -1.62332 -1.08766 -0.63584 -0.02089]
21Feb13_220908| [-0.69095 -1.90050  0.56484  1.12305  0.68882 -0.42906]
21Feb13_220908| [ 1.84548  0.44085  0.64487 -0.70848 -0.82392 -0.36589]
21Feb13_220908| [ 0.09851  2.13277  0.57030 -0.79303  0.48128 -0.42670]
21Feb13_220908| [ 0.11840 -0.81597 -0.12555  0.58548  0.52800  0.32666]
21Feb13_220908| [-0.21547  1.51130 -1.44840 -0.95307  0.80526  0.45558]
21Feb13_220908| [ 0.65240  0.91420 -1.25405 -1.21548 -0.15191  0.32359]
21Feb13_220908| [-0.09876 -0.42450 -0.24028 -0.61702 -0.04275  0.08542]
21Feb13_220908| [-0.70354  1.07974 -0.49390  0.67614 -0.00435  0.12051]
21Feb13_220908| [-1.81032 -0.94975 -0.34274  0.23071  0.39457  0.45390]
21Feb13_220908| [-0.23721  0.17217 -0.42835 -1.68301 -0.30137  0.06268]
21Feb13_220908| [ 0.35544 -2.92353  1.61345 -1.99230 -0.39892  0.40786]
21Feb13_220908| [ 0.92536  0.52707  0.67114 -0.82958 -0.71602  0.46510]
21Feb13_220908| [-0.92465 -2.10152 -0.00460 -0.06597  0.49376 -0.49032]
21Feb13_220908| [ 0.45803  1.52102  0.44313 -0.89222  0.25115  0.38088]
21Feb13_220908| [-0.55595 -1.75173 -0.51886 -0.83852  0.43962 -0.35753]
21Feb13_220908| [ 1.05043  0.13022  0.50909  1.35826  0.06262  0.37678]
21Feb13_220908| [-0.73516 -1.66793 -1.03505 -0.32304  0.29883 -0.45118]
21Feb13_220908| [-0.98587 -1.27575  1.32223  1.83009 -0.24774 -0.02303]
21Feb13_220908| [ 0.62667  1.15369  1.08062 -0.95194 -0.33125  0.49280]
21Feb13_220908| [ 0.29335  0.50911 -0.31591 -0.47999 -0.68764  0.21059]
21Feb13_220908| [-0.57894  0.76114 -0.65343  0.71286  0.78908  0.25605]
21Feb13_220908| [-0.31510 -0.63291  0.15396 -1.15177 -0.27702  0.28602]]
21Feb13_220908|-- Bias --
21Feb13_220908|[ 0.33651 -0.10761 -0.53450  0.36499 -0.01881  0.10157]
21Feb13_220908|Layer 1:
21Feb13_220908|-- Config --
21Feb13_220908|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220908|-- Weights --
21Feb13_220908|[[-0.31032 -1.54200  0.38873  1.86483]
21Feb13_220908| [ 0.27827  0.68678 -0.04542  0.33503]
21Feb13_220908| [-0.12370 -2.00154  0.33123 -1.03780]
21Feb13_220908| [ 1.24947 -0.59883  0.08929  0.18047]
21Feb13_220908| [-0.12048 -0.19640  0.34362 -0.41276]
21Feb13_220908| [ 0.22336  0.35012  0.14086 -0.40865]]
21Feb13_220908|-- Bias --
21Feb13_220908|[-0.44268  0.22631 -0.39436 -0.21581]
21Feb13_220908|Layer 2:
21Feb13_220908|-- Config --
21Feb13_220908|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220908|-- Weights --
21Feb13_220908|[[-0.26912 -0.04537]
21Feb13_220908| [-0.13112  0.23976]
21Feb13_220908| [-0.33179 -0.13228]
21Feb13_220908| [-0.22655  0.49163]]
21Feb13_220908|-- Bias --
21Feb13_220908|[ 1.26151 -0.75338]
21Feb13_220908|Layer 3:
21Feb13_220908|-- Config --
21Feb13_220908|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220908|-- Weights --
21Feb13_220908|[[ 0.40923 -1.00526]
21Feb13_220908| [ 0.41626 -0.24565]]
21Feb13_220908|-- Bias --
21Feb13_220908|[-1.04567 -0.78011]
21Feb13_220908|Predicting the validation and test data with the Best final individual.
21Feb13_220916| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_220916|-----------  ------------------  --------------------  ----------
21Feb13_220916|Validation         38.43                  36            0.00000
21Feb13_220916|   Test            21.89                  36            0.78152
21Feb13_220916|-------------------- Test #5 --------------------
21Feb13_220916|Best final individual weights
21Feb13_220916|Individual:
21Feb13_220916|-- Constant hidden layers --
21Feb13_220916|False
21Feb13_220916|Layer 0:
21Feb13_220916|-- Config --
21Feb13_220916|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220916|-- Weights --
21Feb13_220916|[[-0.40915  0.29174 -0.34361  0.14991  0.48013  0.43962]
21Feb13_220916| [-0.03889 -2.58918  1.23726 -0.94545  0.31112 -0.33123]
21Feb13_220916| [-0.20635  0.94283  0.91953  0.65409  0.05057 -0.26007]
21Feb13_220916| [ 0.43641 -0.76635  0.05389  1.13480  0.41780  0.46235]
21Feb13_220916| [ 1.82634  0.72047  0.74041 -0.14215 -0.12675 -0.24346]
21Feb13_220916| [ 0.28127  0.08807 -1.98005  0.01426  0.26090 -0.14537]
21Feb13_220916| [-1.25185  0.82655  0.46228 -0.55060  0.10941 -0.15674]
21Feb13_220916| [ 0.91445  1.72888 -0.21980  0.73581 -0.72850  0.14657]
21Feb13_220916| [-0.57907 -0.24880  1.15136  0.39596  0.74559  0.44478]
21Feb13_220916| [-1.70002 -0.70915 -2.56272  1.01268  0.12472  0.33916]
21Feb13_220916| [ 0.41868 -1.77356 -1.11896 -0.73114  0.06927  0.26964]
21Feb13_220916| [-1.09531  0.14368 -0.26154 -0.23597  0.45805  0.03320]
21Feb13_220916| [-0.50566 -0.11825  2.29879 -0.11187  0.83873 -0.31067]
21Feb13_220916| [ 0.41226 -2.16123  1.56164  0.08939 -0.72259  0.31162]
21Feb13_220916| [-1.24419  0.81010 -1.10440 -0.20148  0.35840 -0.33718]
21Feb13_220916| [-0.12460  0.61383 -0.45420  0.83739  0.56627 -0.42802]
21Feb13_220916| [-0.39166 -2.48851  1.52386 -1.32659  0.30787  0.13333]
21Feb13_220916| [-0.93483  0.69438 -0.95500  1.27853  0.05581  0.28043]
21Feb13_220916| [ 0.56230 -0.94056  0.46910  0.10418 -0.19409 -0.47523]
21Feb13_220916| [-2.07937  0.22698  1.42960  0.92495  0.47285  0.03640]
21Feb13_220916| [-0.37785  0.95082  1.95371 -0.51694 -0.55583 -0.47787]
21Feb13_220916| [-0.55685  0.99330 -2.63246  1.05090 -0.43896  0.28635]
21Feb13_220916| [ 1.18738  0.35601  1.18799  0.87220 -0.10480  0.27707]
21Feb13_220916| [-0.86533 -1.24460  0.85164  0.74349  0.54417  0.29889]
21Feb13_220916| [-0.24069 -1.24668  0.16743  0.84590  0.21360  0.29043]
21Feb13_220916| [ 0.63554  0.81106 -0.00390  1.39866  0.46540  0.17208]
21Feb13_220916| [ 0.30270  1.13969 -0.75028 -0.78198 -1.02639  0.05785]
21Feb13_220916| [-0.96730  0.20619 -1.16463  1.39466  0.57145  0.19332]
21Feb13_220916| [ 0.96709 -2.84136  0.18157 -0.77198  0.68265 -0.43429]
21Feb13_220916| [-1.15123 -0.32784 -1.75614  1.26760  0.32257 -0.39679]
21Feb13_220916| [ 1.65321 -0.51426  3.04899 -1.65205 -1.16383  0.16424]
21Feb13_220916| [-1.04445  1.98716 -1.72225 -1.62612 -0.39208  0.05691]
21Feb13_220916| [-0.03870  3.82088  0.10601 -1.50340  0.64469 -0.18022]
21Feb13_220916| [ 0.70423 -0.51765 -0.97406 -0.13983  0.39618 -0.43729]
21Feb13_220916| [ 0.11732 -1.38663 -1.62332 -1.08766 -0.63584 -0.02089]
21Feb13_220916| [-0.69095 -1.90050  0.56484  1.12305  0.68882 -0.42906]
21Feb13_220916| [ 1.84548  0.44085  0.64487 -0.70848 -0.82392 -0.36589]
21Feb13_220916| [ 0.09851  2.13277  0.57030 -0.79303  0.48128 -0.42670]
21Feb13_220916| [ 0.11840 -0.81597 -0.12555  0.58548  0.52800  0.32666]
21Feb13_220916| [-0.21547  1.51130 -1.44840 -0.95307  0.80526  0.45558]
21Feb13_220916| [ 0.65240  0.91420 -1.25405 -1.21548 -0.15191  0.32359]
21Feb13_220916| [-0.09876 -0.42450 -0.24028 -0.61702 -0.04275  0.08542]
21Feb13_220916| [-0.70354  1.07974 -0.49390  0.67614 -0.00435  0.12051]
21Feb13_220916| [-1.81032 -0.94975 -0.34274  0.23071  0.39457  0.45390]
21Feb13_220916| [-0.23721  0.17217 -0.42835 -1.68301 -0.30137  0.06268]
21Feb13_220916| [ 0.35544 -2.92353  1.61345 -1.99230 -0.39892  0.40786]
21Feb13_220916| [ 0.92536  0.52707  0.67114 -0.82958 -0.71602  0.46510]
21Feb13_220916| [-0.92465 -2.10152 -0.00460 -0.06597  0.49376 -0.49032]
21Feb13_220916| [ 0.45803  1.52102  0.44313 -0.89222  0.25115  0.38088]
21Feb13_220916| [-0.55595 -1.75173 -0.51886 -0.83852  0.43962 -0.35753]
21Feb13_220916| [ 1.05043  0.13022  0.50909  1.35826  0.06262  0.37678]
21Feb13_220916| [-0.73516 -1.66793 -1.03505 -0.32304  0.29883 -0.45118]
21Feb13_220916| [-0.98587 -1.27575  1.32223  1.83009 -0.24774 -0.02303]
21Feb13_220916| [ 0.62667  1.15369  1.08062 -0.95194 -0.33125  0.49280]
21Feb13_220916| [ 0.29335  0.50911 -0.31591 -0.47999 -0.68764  0.21059]
21Feb13_220916| [-0.57894  0.76114 -0.65343  0.71286  0.78908  0.25605]
21Feb13_220916| [-0.31510 -0.63291  0.15396 -1.15177 -0.27702  0.28602]]
21Feb13_220916|-- Bias --
21Feb13_220916|[ 0.33651 -0.10761 -0.53450  0.36499 -0.01881  0.10157]
21Feb13_220916|Layer 1:
21Feb13_220916|-- Config --
21Feb13_220916|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220916|-- Weights --
21Feb13_220916|[[-0.31032 -1.54200  0.38873  1.86483]
21Feb13_220916| [ 0.27827  0.68678 -0.04542  0.33503]
21Feb13_220916| [-0.12370 -2.00154  0.33123 -1.03780]
21Feb13_220916| [ 1.24947 -0.59883  0.08929  0.18047]
21Feb13_220916| [-0.12048 -0.19640  0.34362 -0.41276]
21Feb13_220916| [ 0.22336  0.35012  0.14086 -0.40865]]
21Feb13_220916|-- Bias --
21Feb13_220916|[-0.44268  0.22631 -0.39436 -0.21581]
21Feb13_220916|Layer 2:
21Feb13_220916|-- Config --
21Feb13_220916|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220916|-- Weights --
21Feb13_220916|[[-0.26912 -0.04537]
21Feb13_220916| [-0.13112  0.23976]
21Feb13_220916| [-0.33179 -0.13228]
21Feb13_220916| [-0.22655  0.49163]]
21Feb13_220916|-- Bias --
21Feb13_220916|[ 1.26151 -0.75338]
21Feb13_220916|Layer 3:
21Feb13_220916|-- Config --
21Feb13_220916|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220916|-- Weights --
21Feb13_220916|[[ 0.40923 -1.00526]
21Feb13_220916| [ 0.41626 -0.24565]]
21Feb13_220916|-- Bias --
21Feb13_220916|[-1.04567 -0.78011]
21Feb13_220916|Predicting the validation and test data with the Best final individual.
21Feb13_220923| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_220923|-----------  ------------------  --------------------  ----------
21Feb13_220923|Validation         25.39                  36            0.80611
21Feb13_220923|   Test            27.19                  36            0.70817
21Feb13_220923|-------------------- Test #6 --------------------
21Feb13_220923|Best final individual weights
21Feb13_220923|Individual:
21Feb13_220923|-- Constant hidden layers --
21Feb13_220923|False
21Feb13_220923|Layer 0:
21Feb13_220923|-- Config --
21Feb13_220923|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220923|-- Weights --
21Feb13_220923|[[-0.40915  0.29174 -0.34361  0.14991  0.48013  0.43962]
21Feb13_220923| [-0.03889 -2.58918  1.23726 -0.94545  0.31112 -0.33123]
21Feb13_220923| [-0.20635  0.94283  0.91953  0.65409  0.05057 -0.26007]
21Feb13_220923| [ 0.43641 -0.76635  0.05389  1.13480  0.41780  0.46235]
21Feb13_220923| [ 1.82634  0.72047  0.74041 -0.14215 -0.12675 -0.24346]
21Feb13_220923| [ 0.28127  0.08807 -1.98005  0.01426  0.26090 -0.14537]
21Feb13_220923| [-1.25185  0.82655  0.46228 -0.55060  0.10941 -0.15674]
21Feb13_220923| [ 0.91445  1.72888 -0.21980  0.73581 -0.72850  0.14657]
21Feb13_220923| [-0.57907 -0.24880  1.15136  0.39596  0.74559  0.44478]
21Feb13_220923| [-1.70002 -0.70915 -2.56272  1.01268  0.12472  0.33916]
21Feb13_220923| [ 0.41868 -1.77356 -1.11896 -0.73114  0.06927  0.26964]
21Feb13_220923| [-1.09531  0.14368 -0.26154 -0.23597  0.45805  0.03320]
21Feb13_220923| [-0.50566 -0.11825  2.29879 -0.11187  0.83873 -0.31067]
21Feb13_220923| [ 0.41226 -2.16123  1.56164  0.08939 -0.72259  0.31162]
21Feb13_220923| [-1.24419  0.81010 -1.10440 -0.20148  0.35840 -0.33718]
21Feb13_220923| [-0.12460  0.61383 -0.45420  0.83739  0.56627 -0.42802]
21Feb13_220923| [-0.39166 -2.48851  1.52386 -1.32659  0.30787  0.13333]
21Feb13_220923| [-0.93483  0.69438 -0.95500  1.27853  0.05581  0.28043]
21Feb13_220923| [ 0.56230 -0.94056  0.46910  0.10418 -0.19409 -0.47523]
21Feb13_220923| [-2.07937  0.22698  1.42960  0.92495  0.47285  0.03640]
21Feb13_220923| [-0.37785  0.95082  1.95371 -0.51694 -0.55583 -0.47787]
21Feb13_220923| [-0.55685  0.99330 -2.63246  1.05090 -0.43896  0.28635]
21Feb13_220923| [ 1.18738  0.35601  1.18799  0.87220 -0.10480  0.27707]
21Feb13_220923| [-0.86533 -1.24460  0.85164  0.74349  0.54417  0.29889]
21Feb13_220923| [-0.24069 -1.24668  0.16743  0.84590  0.21360  0.29043]
21Feb13_220923| [ 0.63554  0.81106 -0.00390  1.39866  0.46540  0.17208]
21Feb13_220923| [ 0.30270  1.13969 -0.75028 -0.78198 -1.02639  0.05785]
21Feb13_220923| [-0.96730  0.20619 -1.16463  1.39466  0.57145  0.19332]
21Feb13_220923| [ 0.96709 -2.84136  0.18157 -0.77198  0.68265 -0.43429]
21Feb13_220923| [-1.15123 -0.32784 -1.75614  1.26760  0.32257 -0.39679]
21Feb13_220923| [ 1.65321 -0.51426  3.04899 -1.65205 -1.16383  0.16424]
21Feb13_220923| [-1.04445  1.98716 -1.72225 -1.62612 -0.39208  0.05691]
21Feb13_220923| [-0.03870  3.82088  0.10601 -1.50340  0.64469 -0.18022]
21Feb13_220923| [ 0.70423 -0.51765 -0.97406 -0.13983  0.39618 -0.43729]
21Feb13_220923| [ 0.11732 -1.38663 -1.62332 -1.08766 -0.63584 -0.02089]
21Feb13_220923| [-0.69095 -1.90050  0.56484  1.12305  0.68882 -0.42906]
21Feb13_220923| [ 1.84548  0.44085  0.64487 -0.70848 -0.82392 -0.36589]
21Feb13_220923| [ 0.09851  2.13277  0.57030 -0.79303  0.48128 -0.42670]
21Feb13_220923| [ 0.11840 -0.81597 -0.12555  0.58548  0.52800  0.32666]
21Feb13_220923| [-0.21547  1.51130 -1.44840 -0.95307  0.80526  0.45558]
21Feb13_220923| [ 0.65240  0.91420 -1.25405 -1.21548 -0.15191  0.32359]
21Feb13_220923| [-0.09876 -0.42450 -0.24028 -0.61702 -0.04275  0.08542]
21Feb13_220923| [-0.70354  1.07974 -0.49390  0.67614 -0.00435  0.12051]
21Feb13_220923| [-1.81032 -0.94975 -0.34274  0.23071  0.39457  0.45390]
21Feb13_220923| [-0.23721  0.17217 -0.42835 -1.68301 -0.30137  0.06268]
21Feb13_220923| [ 0.35544 -2.92353  1.61345 -1.99230 -0.39892  0.40786]
21Feb13_220923| [ 0.92536  0.52707  0.67114 -0.82958 -0.71602  0.46510]
21Feb13_220923| [-0.92465 -2.10152 -0.00460 -0.06597  0.49376 -0.49032]
21Feb13_220923| [ 0.45803  1.52102  0.44313 -0.89222  0.25115  0.38088]
21Feb13_220923| [-0.55595 -1.75173 -0.51886 -0.83852  0.43962 -0.35753]
21Feb13_220923| [ 1.05043  0.13022  0.50909  1.35826  0.06262  0.37678]
21Feb13_220923| [-0.73516 -1.66793 -1.03505 -0.32304  0.29883 -0.45118]
21Feb13_220923| [-0.98587 -1.27575  1.32223  1.83009 -0.24774 -0.02303]
21Feb13_220923| [ 0.62667  1.15369  1.08062 -0.95194 -0.33125  0.49280]
21Feb13_220923| [ 0.29335  0.50911 -0.31591 -0.47999 -0.68764  0.21059]
21Feb13_220923| [-0.57894  0.76114 -0.65343  0.71286  0.78908  0.25605]
21Feb13_220923| [-0.31510 -0.63291  0.15396 -1.15177 -0.27702  0.28602]]
21Feb13_220923|-- Bias --
21Feb13_220923|[ 0.33651 -0.10761 -0.53450  0.36499 -0.01881  0.10157]
21Feb13_220923|Layer 1:
21Feb13_220923|-- Config --
21Feb13_220923|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220923|-- Weights --
21Feb13_220923|[[-0.31032 -1.54200  0.38873  1.86483]
21Feb13_220923| [ 0.27827  0.68678 -0.04542  0.33503]
21Feb13_220923| [-0.12370 -2.00154  0.33123 -1.03780]
21Feb13_220923| [ 1.24947 -0.59883  0.08929  0.18047]
21Feb13_220923| [-0.12048 -0.19640  0.34362 -0.41276]
21Feb13_220923| [ 0.22336  0.35012  0.14086 -0.40865]]
21Feb13_220923|-- Bias --
21Feb13_220923|[-0.44268  0.22631 -0.39436 -0.21581]
21Feb13_220923|Layer 2:
21Feb13_220923|-- Config --
21Feb13_220923|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220923|-- Weights --
21Feb13_220923|[[-0.26912 -0.04537]
21Feb13_220923| [-0.13112  0.23976]
21Feb13_220923| [-0.33179 -0.13228]
21Feb13_220923| [-0.22655  0.49163]]
21Feb13_220923|-- Bias --
21Feb13_220923|[ 1.26151 -0.75338]
21Feb13_220923|Layer 3:
21Feb13_220923|-- Config --
21Feb13_220923|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220923|-- Weights --
21Feb13_220923|[[ 0.40923 -1.00526]
21Feb13_220923| [ 0.41626 -0.24565]]
21Feb13_220923|-- Bias --
21Feb13_220923|[-1.04567 -0.78011]
21Feb13_220923|Predicting the validation and test data with the Best final individual.
21Feb13_220931| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_220931|-----------  ------------------  --------------------  ----------
21Feb13_220931|Validation         23.30                  36            0.57115
21Feb13_220931|   Test            22.50                  36            0.81637
21Feb13_220931|-------------------- Test #7 --------------------
21Feb13_220931|Best final individual weights
21Feb13_220931|Individual:
21Feb13_220931|-- Constant hidden layers --
21Feb13_220931|False
21Feb13_220931|Layer 0:
21Feb13_220931|-- Config --
21Feb13_220931|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220931|-- Weights --
21Feb13_220931|[[-0.40915  0.29174 -0.34361  0.14991  0.48013  0.43962]
21Feb13_220931| [-0.03889 -2.58918  1.23726 -0.94545  0.31112 -0.33123]
21Feb13_220931| [-0.20635  0.94283  0.91953  0.65409  0.05057 -0.26007]
21Feb13_220931| [ 0.43641 -0.76635  0.05389  1.13480  0.41780  0.46235]
21Feb13_220931| [ 1.82634  0.72047  0.74041 -0.14215 -0.12675 -0.24346]
21Feb13_220931| [ 0.28127  0.08807 -1.98005  0.01426  0.26090 -0.14537]
21Feb13_220931| [-1.25185  0.82655  0.46228 -0.55060  0.10941 -0.15674]
21Feb13_220931| [ 0.91445  1.72888 -0.21980  0.73581 -0.72850  0.14657]
21Feb13_220931| [-0.57907 -0.24880  1.15136  0.39596  0.74559  0.44478]
21Feb13_220931| [-1.70002 -0.70915 -2.56272  1.01268  0.12472  0.33916]
21Feb13_220931| [ 0.41868 -1.77356 -1.11896 -0.73114  0.06927  0.26964]
21Feb13_220931| [-1.09531  0.14368 -0.26154 -0.23597  0.45805  0.03320]
21Feb13_220931| [-0.50566 -0.11825  2.29879 -0.11187  0.83873 -0.31067]
21Feb13_220931| [ 0.41226 -2.16123  1.56164  0.08939 -0.72259  0.31162]
21Feb13_220931| [-1.24419  0.81010 -1.10440 -0.20148  0.35840 -0.33718]
21Feb13_220931| [-0.12460  0.61383 -0.45420  0.83739  0.56627 -0.42802]
21Feb13_220931| [-0.39166 -2.48851  1.52386 -1.32659  0.30787  0.13333]
21Feb13_220931| [-0.93483  0.69438 -0.95500  1.27853  0.05581  0.28043]
21Feb13_220931| [ 0.56230 -0.94056  0.46910  0.10418 -0.19409 -0.47523]
21Feb13_220931| [-2.07937  0.22698  1.42960  0.92495  0.47285  0.03640]
21Feb13_220931| [-0.37785  0.95082  1.95371 -0.51694 -0.55583 -0.47787]
21Feb13_220931| [-0.55685  0.99330 -2.63246  1.05090 -0.43896  0.28635]
21Feb13_220931| [ 1.18738  0.35601  1.18799  0.87220 -0.10480  0.27707]
21Feb13_220931| [-0.86533 -1.24460  0.85164  0.74349  0.54417  0.29889]
21Feb13_220931| [-0.24069 -1.24668  0.16743  0.84590  0.21360  0.29043]
21Feb13_220931| [ 0.63554  0.81106 -0.00390  1.39866  0.46540  0.17208]
21Feb13_220931| [ 0.30270  1.13969 -0.75028 -0.78198 -1.02639  0.05785]
21Feb13_220931| [-0.96730  0.20619 -1.16463  1.39466  0.57145  0.19332]
21Feb13_220931| [ 0.96709 -2.84136  0.18157 -0.77198  0.68265 -0.43429]
21Feb13_220931| [-1.15123 -0.32784 -1.75614  1.26760  0.32257 -0.39679]
21Feb13_220931| [ 1.65321 -0.51426  3.04899 -1.65205 -1.16383  0.16424]
21Feb13_220931| [-1.04445  1.98716 -1.72225 -1.62612 -0.39208  0.05691]
21Feb13_220931| [-0.03870  3.82088  0.10601 -1.50340  0.64469 -0.18022]
21Feb13_220931| [ 0.70423 -0.51765 -0.97406 -0.13983  0.39618 -0.43729]
21Feb13_220931| [ 0.11732 -1.38663 -1.62332 -1.08766 -0.63584 -0.02089]
21Feb13_220931| [-0.69095 -1.90050  0.56484  1.12305  0.68882 -0.42906]
21Feb13_220931| [ 1.84548  0.44085  0.64487 -0.70848 -0.82392 -0.36589]
21Feb13_220931| [ 0.09851  2.13277  0.57030 -0.79303  0.48128 -0.42670]
21Feb13_220931| [ 0.11840 -0.81597 -0.12555  0.58548  0.52800  0.32666]
21Feb13_220931| [-0.21547  1.51130 -1.44840 -0.95307  0.80526  0.45558]
21Feb13_220931| [ 0.65240  0.91420 -1.25405 -1.21548 -0.15191  0.32359]
21Feb13_220931| [-0.09876 -0.42450 -0.24028 -0.61702 -0.04275  0.08542]
21Feb13_220931| [-0.70354  1.07974 -0.49390  0.67614 -0.00435  0.12051]
21Feb13_220931| [-1.81032 -0.94975 -0.34274  0.23071  0.39457  0.45390]
21Feb13_220931| [-0.23721  0.17217 -0.42835 -1.68301 -0.30137  0.06268]
21Feb13_220931| [ 0.35544 -2.92353  1.61345 -1.99230 -0.39892  0.40786]
21Feb13_220931| [ 0.92536  0.52707  0.67114 -0.82958 -0.71602  0.46510]
21Feb13_220931| [-0.92465 -2.10152 -0.00460 -0.06597  0.49376 -0.49032]
21Feb13_220931| [ 0.45803  1.52102  0.44313 -0.89222  0.25115  0.38088]
21Feb13_220931| [-0.55595 -1.75173 -0.51886 -0.83852  0.43962 -0.35753]
21Feb13_220931| [ 1.05043  0.13022  0.50909  1.35826  0.06262  0.37678]
21Feb13_220931| [-0.73516 -1.66793 -1.03505 -0.32304  0.29883 -0.45118]
21Feb13_220931| [-0.98587 -1.27575  1.32223  1.83009 -0.24774 -0.02303]
21Feb13_220931| [ 0.62667  1.15369  1.08062 -0.95194 -0.33125  0.49280]
21Feb13_220931| [ 0.29335  0.50911 -0.31591 -0.47999 -0.68764  0.21059]
21Feb13_220931| [-0.57894  0.76114 -0.65343  0.71286  0.78908  0.25605]
21Feb13_220931| [-0.31510 -0.63291  0.15396 -1.15177 -0.27702  0.28602]]
21Feb13_220931|-- Bias --
21Feb13_220931|[ 0.33651 -0.10761 -0.53450  0.36499 -0.01881  0.10157]
21Feb13_220931|Layer 1:
21Feb13_220931|-- Config --
21Feb13_220931|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220931|-- Weights --
21Feb13_220931|[[-0.31032 -1.54200  0.38873  1.86483]
21Feb13_220931| [ 0.27827  0.68678 -0.04542  0.33503]
21Feb13_220931| [-0.12370 -2.00154  0.33123 -1.03780]
21Feb13_220931| [ 1.24947 -0.59883  0.08929  0.18047]
21Feb13_220931| [-0.12048 -0.19640  0.34362 -0.41276]
21Feb13_220931| [ 0.22336  0.35012  0.14086 -0.40865]]
21Feb13_220931|-- Bias --
21Feb13_220931|[-0.44268  0.22631 -0.39436 -0.21581]
21Feb13_220931|Layer 2:
21Feb13_220931|-- Config --
21Feb13_220931|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220931|-- Weights --
21Feb13_220931|[[-0.26912 -0.04537]
21Feb13_220931| [-0.13112  0.23976]
21Feb13_220931| [-0.33179 -0.13228]
21Feb13_220931| [-0.22655  0.49163]]
21Feb13_220931|-- Bias --
21Feb13_220931|[ 1.26151 -0.75338]
21Feb13_220931|Layer 3:
21Feb13_220931|-- Config --
21Feb13_220931|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220931|-- Weights --
21Feb13_220931|[[ 0.40923 -1.00526]
21Feb13_220931| [ 0.41626 -0.24565]]
21Feb13_220931|-- Bias --
21Feb13_220931|[-1.04567 -0.78011]
21Feb13_220931|Predicting the validation and test data with the Best final individual.
21Feb13_220939| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_220939|-----------  ------------------  --------------------  ----------
21Feb13_220939|Validation         23.48                  36            0.73607
21Feb13_220939|   Test            27.72                  36            0.49212
21Feb13_220939|-------------------- Test #8 --------------------
21Feb13_220939|Best final individual weights
21Feb13_220939|Individual:
21Feb13_220939|-- Constant hidden layers --
21Feb13_220939|False
21Feb13_220939|Layer 0:
21Feb13_220939|-- Config --
21Feb13_220939|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220939|-- Weights --
21Feb13_220939|[[-0.40915  0.29174 -0.34361  0.14991  0.48013  0.43962]
21Feb13_220939| [-0.03889 -2.58918  1.23726 -0.94545  0.31112 -0.33123]
21Feb13_220939| [-0.20635  0.94283  0.91953  0.65409  0.05057 -0.26007]
21Feb13_220939| [ 0.43641 -0.76635  0.05389  1.13480  0.41780  0.46235]
21Feb13_220939| [ 1.82634  0.72047  0.74041 -0.14215 -0.12675 -0.24346]
21Feb13_220939| [ 0.28127  0.08807 -1.98005  0.01426  0.26090 -0.14537]
21Feb13_220939| [-1.25185  0.82655  0.46228 -0.55060  0.10941 -0.15674]
21Feb13_220939| [ 0.91445  1.72888 -0.21980  0.73581 -0.72850  0.14657]
21Feb13_220939| [-0.57907 -0.24880  1.15136  0.39596  0.74559  0.44478]
21Feb13_220939| [-1.70002 -0.70915 -2.56272  1.01268  0.12472  0.33916]
21Feb13_220939| [ 0.41868 -1.77356 -1.11896 -0.73114  0.06927  0.26964]
21Feb13_220939| [-1.09531  0.14368 -0.26154 -0.23597  0.45805  0.03320]
21Feb13_220939| [-0.50566 -0.11825  2.29879 -0.11187  0.83873 -0.31067]
21Feb13_220939| [ 0.41226 -2.16123  1.56164  0.08939 -0.72259  0.31162]
21Feb13_220939| [-1.24419  0.81010 -1.10440 -0.20148  0.35840 -0.33718]
21Feb13_220939| [-0.12460  0.61383 -0.45420  0.83739  0.56627 -0.42802]
21Feb13_220939| [-0.39166 -2.48851  1.52386 -1.32659  0.30787  0.13333]
21Feb13_220939| [-0.93483  0.69438 -0.95500  1.27853  0.05581  0.28043]
21Feb13_220939| [ 0.56230 -0.94056  0.46910  0.10418 -0.19409 -0.47523]
21Feb13_220939| [-2.07937  0.22698  1.42960  0.92495  0.47285  0.03640]
21Feb13_220939| [-0.37785  0.95082  1.95371 -0.51694 -0.55583 -0.47787]
21Feb13_220939| [-0.55685  0.99330 -2.63246  1.05090 -0.43896  0.28635]
21Feb13_220939| [ 1.18738  0.35601  1.18799  0.87220 -0.10480  0.27707]
21Feb13_220939| [-0.86533 -1.24460  0.85164  0.74349  0.54417  0.29889]
21Feb13_220939| [-0.24069 -1.24668  0.16743  0.84590  0.21360  0.29043]
21Feb13_220939| [ 0.63554  0.81106 -0.00390  1.39866  0.46540  0.17208]
21Feb13_220939| [ 0.30270  1.13969 -0.75028 -0.78198 -1.02639  0.05785]
21Feb13_220939| [-0.96730  0.20619 -1.16463  1.39466  0.57145  0.19332]
21Feb13_220939| [ 0.96709 -2.84136  0.18157 -0.77198  0.68265 -0.43429]
21Feb13_220939| [-1.15123 -0.32784 -1.75614  1.26760  0.32257 -0.39679]
21Feb13_220939| [ 1.65321 -0.51426  3.04899 -1.65205 -1.16383  0.16424]
21Feb13_220939| [-1.04445  1.98716 -1.72225 -1.62612 -0.39208  0.05691]
21Feb13_220939| [-0.03870  3.82088  0.10601 -1.50340  0.64469 -0.18022]
21Feb13_220939| [ 0.70423 -0.51765 -0.97406 -0.13983  0.39618 -0.43729]
21Feb13_220939| [ 0.11732 -1.38663 -1.62332 -1.08766 -0.63584 -0.02089]
21Feb13_220939| [-0.69095 -1.90050  0.56484  1.12305  0.68882 -0.42906]
21Feb13_220939| [ 1.84548  0.44085  0.64487 -0.70848 -0.82392 -0.36589]
21Feb13_220939| [ 0.09851  2.13277  0.57030 -0.79303  0.48128 -0.42670]
21Feb13_220939| [ 0.11840 -0.81597 -0.12555  0.58548  0.52800  0.32666]
21Feb13_220939| [-0.21547  1.51130 -1.44840 -0.95307  0.80526  0.45558]
21Feb13_220939| [ 0.65240  0.91420 -1.25405 -1.21548 -0.15191  0.32359]
21Feb13_220939| [-0.09876 -0.42450 -0.24028 -0.61702 -0.04275  0.08542]
21Feb13_220939| [-0.70354  1.07974 -0.49390  0.67614 -0.00435  0.12051]
21Feb13_220939| [-1.81032 -0.94975 -0.34274  0.23071  0.39457  0.45390]
21Feb13_220939| [-0.23721  0.17217 -0.42835 -1.68301 -0.30137  0.06268]
21Feb13_220939| [ 0.35544 -2.92353  1.61345 -1.99230 -0.39892  0.40786]
21Feb13_220939| [ 0.92536  0.52707  0.67114 -0.82958 -0.71602  0.46510]
21Feb13_220939| [-0.92465 -2.10152 -0.00460 -0.06597  0.49376 -0.49032]
21Feb13_220939| [ 0.45803  1.52102  0.44313 -0.89222  0.25115  0.38088]
21Feb13_220939| [-0.55595 -1.75173 -0.51886 -0.83852  0.43962 -0.35753]
21Feb13_220939| [ 1.05043  0.13022  0.50909  1.35826  0.06262  0.37678]
21Feb13_220939| [-0.73516 -1.66793 -1.03505 -0.32304  0.29883 -0.45118]
21Feb13_220939| [-0.98587 -1.27575  1.32223  1.83009 -0.24774 -0.02303]
21Feb13_220939| [ 0.62667  1.15369  1.08062 -0.95194 -0.33125  0.49280]
21Feb13_220939| [ 0.29335  0.50911 -0.31591 -0.47999 -0.68764  0.21059]
21Feb13_220939| [-0.57894  0.76114 -0.65343  0.71286  0.78908  0.25605]
21Feb13_220939| [-0.31510 -0.63291  0.15396 -1.15177 -0.27702  0.28602]]
21Feb13_220939|-- Bias --
21Feb13_220939|[ 0.33651 -0.10761 -0.53450  0.36499 -0.01881  0.10157]
21Feb13_220939|Layer 1:
21Feb13_220939|-- Config --
21Feb13_220939|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220939|-- Weights --
21Feb13_220939|[[-0.31032 -1.54200  0.38873  1.86483]
21Feb13_220939| [ 0.27827  0.68678 -0.04542  0.33503]
21Feb13_220939| [-0.12370 -2.00154  0.33123 -1.03780]
21Feb13_220939| [ 1.24947 -0.59883  0.08929  0.18047]
21Feb13_220939| [-0.12048 -0.19640  0.34362 -0.41276]
21Feb13_220939| [ 0.22336  0.35012  0.14086 -0.40865]]
21Feb13_220939|-- Bias --
21Feb13_220939|[-0.44268  0.22631 -0.39436 -0.21581]
21Feb13_220939|Layer 2:
21Feb13_220939|-- Config --
21Feb13_220939|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220939|-- Weights --
21Feb13_220939|[[-0.26912 -0.04537]
21Feb13_220939| [-0.13112  0.23976]
21Feb13_220939| [-0.33179 -0.13228]
21Feb13_220939| [-0.22655  0.49163]]
21Feb13_220939|-- Bias --
21Feb13_220939|[ 1.26151 -0.75338]
21Feb13_220939|Layer 3:
21Feb13_220939|-- Config --
21Feb13_220939|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220939|-- Weights --
21Feb13_220939|[[ 0.40923 -1.00526]
21Feb13_220939| [ 0.41626 -0.24565]]
21Feb13_220939|-- Bias --
21Feb13_220939|[-1.04567 -0.78011]
21Feb13_220939|Predicting the validation and test data with the Best final individual.
21Feb13_220946| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_220946|-----------  ------------------  --------------------  ----------
21Feb13_220946|Validation         19.57                  36            0.73349
21Feb13_220946|   Test            22.85                  36            0.82888
21Feb13_220946|-------------------- Test #9 --------------------
21Feb13_220946|Best final individual weights
21Feb13_220946|Individual:
21Feb13_220946|-- Constant hidden layers --
21Feb13_220946|False
21Feb13_220946|Layer 0:
21Feb13_220946|-- Config --
21Feb13_220946|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220946|-- Weights --
21Feb13_220946|[[-0.40915  0.29174 -0.34361  0.14991  0.48013  0.43962]
21Feb13_220946| [-0.03889 -2.58918  1.23726 -0.94545  0.31112 -0.33123]
21Feb13_220946| [-0.20635  0.94283  0.91953  0.65409  0.05057 -0.26007]
21Feb13_220946| [ 0.43641 -0.76635  0.05389  1.13480  0.41780  0.46235]
21Feb13_220946| [ 1.82634  0.72047  0.74041 -0.14215 -0.12675 -0.24346]
21Feb13_220946| [ 0.28127  0.08807 -1.98005  0.01426  0.26090 -0.14537]
21Feb13_220946| [-1.25185  0.82655  0.46228 -0.55060  0.10941 -0.15674]
21Feb13_220946| [ 0.91445  1.72888 -0.21980  0.73581 -0.72850  0.14657]
21Feb13_220946| [-0.57907 -0.24880  1.15136  0.39596  0.74559  0.44478]
21Feb13_220946| [-1.70002 -0.70915 -2.56272  1.01268  0.12472  0.33916]
21Feb13_220946| [ 0.41868 -1.77356 -1.11896 -0.73114  0.06927  0.26964]
21Feb13_220946| [-1.09531  0.14368 -0.26154 -0.23597  0.45805  0.03320]
21Feb13_220946| [-0.50566 -0.11825  2.29879 -0.11187  0.83873 -0.31067]
21Feb13_220946| [ 0.41226 -2.16123  1.56164  0.08939 -0.72259  0.31162]
21Feb13_220946| [-1.24419  0.81010 -1.10440 -0.20148  0.35840 -0.33718]
21Feb13_220946| [-0.12460  0.61383 -0.45420  0.83739  0.56627 -0.42802]
21Feb13_220946| [-0.39166 -2.48851  1.52386 -1.32659  0.30787  0.13333]
21Feb13_220946| [-0.93483  0.69438 -0.95500  1.27853  0.05581  0.28043]
21Feb13_220946| [ 0.56230 -0.94056  0.46910  0.10418 -0.19409 -0.47523]
21Feb13_220946| [-2.07937  0.22698  1.42960  0.92495  0.47285  0.03640]
21Feb13_220946| [-0.37785  0.95082  1.95371 -0.51694 -0.55583 -0.47787]
21Feb13_220946| [-0.55685  0.99330 -2.63246  1.05090 -0.43896  0.28635]
21Feb13_220946| [ 1.18738  0.35601  1.18799  0.87220 -0.10480  0.27707]
21Feb13_220946| [-0.86533 -1.24460  0.85164  0.74349  0.54417  0.29889]
21Feb13_220946| [-0.24069 -1.24668  0.16743  0.84590  0.21360  0.29043]
21Feb13_220946| [ 0.63554  0.81106 -0.00390  1.39866  0.46540  0.17208]
21Feb13_220946| [ 0.30270  1.13969 -0.75028 -0.78198 -1.02639  0.05785]
21Feb13_220946| [-0.96730  0.20619 -1.16463  1.39466  0.57145  0.19332]
21Feb13_220946| [ 0.96709 -2.84136  0.18157 -0.77198  0.68265 -0.43429]
21Feb13_220946| [-1.15123 -0.32784 -1.75614  1.26760  0.32257 -0.39679]
21Feb13_220946| [ 1.65321 -0.51426  3.04899 -1.65205 -1.16383  0.16424]
21Feb13_220946| [-1.04445  1.98716 -1.72225 -1.62612 -0.39208  0.05691]
21Feb13_220946| [-0.03870  3.82088  0.10601 -1.50340  0.64469 -0.18022]
21Feb13_220946| [ 0.70423 -0.51765 -0.97406 -0.13983  0.39618 -0.43729]
21Feb13_220946| [ 0.11732 -1.38663 -1.62332 -1.08766 -0.63584 -0.02089]
21Feb13_220946| [-0.69095 -1.90050  0.56484  1.12305  0.68882 -0.42906]
21Feb13_220946| [ 1.84548  0.44085  0.64487 -0.70848 -0.82392 -0.36589]
21Feb13_220946| [ 0.09851  2.13277  0.57030 -0.79303  0.48128 -0.42670]
21Feb13_220946| [ 0.11840 -0.81597 -0.12555  0.58548  0.52800  0.32666]
21Feb13_220946| [-0.21547  1.51130 -1.44840 -0.95307  0.80526  0.45558]
21Feb13_220946| [ 0.65240  0.91420 -1.25405 -1.21548 -0.15191  0.32359]
21Feb13_220946| [-0.09876 -0.42450 -0.24028 -0.61702 -0.04275  0.08542]
21Feb13_220946| [-0.70354  1.07974 -0.49390  0.67614 -0.00435  0.12051]
21Feb13_220946| [-1.81032 -0.94975 -0.34274  0.23071  0.39457  0.45390]
21Feb13_220946| [-0.23721  0.17217 -0.42835 -1.68301 -0.30137  0.06268]
21Feb13_220946| [ 0.35544 -2.92353  1.61345 -1.99230 -0.39892  0.40786]
21Feb13_220946| [ 0.92536  0.52707  0.67114 -0.82958 -0.71602  0.46510]
21Feb13_220946| [-0.92465 -2.10152 -0.00460 -0.06597  0.49376 -0.49032]
21Feb13_220946| [ 0.45803  1.52102  0.44313 -0.89222  0.25115  0.38088]
21Feb13_220946| [-0.55595 -1.75173 -0.51886 -0.83852  0.43962 -0.35753]
21Feb13_220946| [ 1.05043  0.13022  0.50909  1.35826  0.06262  0.37678]
21Feb13_220946| [-0.73516 -1.66793 -1.03505 -0.32304  0.29883 -0.45118]
21Feb13_220946| [-0.98587 -1.27575  1.32223  1.83009 -0.24774 -0.02303]
21Feb13_220946| [ 0.62667  1.15369  1.08062 -0.95194 -0.33125  0.49280]
21Feb13_220946| [ 0.29335  0.50911 -0.31591 -0.47999 -0.68764  0.21059]
21Feb13_220946| [-0.57894  0.76114 -0.65343  0.71286  0.78908  0.25605]
21Feb13_220946| [-0.31510 -0.63291  0.15396 -1.15177 -0.27702  0.28602]]
21Feb13_220946|-- Bias --
21Feb13_220946|[ 0.33651 -0.10761 -0.53450  0.36499 -0.01881  0.10157]
21Feb13_220946|Layer 1:
21Feb13_220946|-- Config --
21Feb13_220946|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220946|-- Weights --
21Feb13_220946|[[-0.31032 -1.54200  0.38873  1.86483]
21Feb13_220946| [ 0.27827  0.68678 -0.04542  0.33503]
21Feb13_220946| [-0.12370 -2.00154  0.33123 -1.03780]
21Feb13_220946| [ 1.24947 -0.59883  0.08929  0.18047]
21Feb13_220946| [-0.12048 -0.19640  0.34362 -0.41276]
21Feb13_220946| [ 0.22336  0.35012  0.14086 -0.40865]]
21Feb13_220946|-- Bias --
21Feb13_220946|[-0.44268  0.22631 -0.39436 -0.21581]
21Feb13_220946|Layer 2:
21Feb13_220946|-- Config --
21Feb13_220946|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220946|-- Weights --
21Feb13_220946|[[-0.26912 -0.04537]
21Feb13_220946| [-0.13112  0.23976]
21Feb13_220946| [-0.33179 -0.13228]
21Feb13_220946| [-0.22655  0.49163]]
21Feb13_220946|-- Bias --
21Feb13_220946|[ 1.26151 -0.75338]
21Feb13_220946|Layer 3:
21Feb13_220946|-- Config --
21Feb13_220946|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220946|-- Weights --
21Feb13_220946|[[ 0.40923 -1.00526]
21Feb13_220946| [ 0.41626 -0.24565]]
21Feb13_220946|-- Bias --
21Feb13_220946|[-1.04567 -0.78011]
21Feb13_220946|Predicting the validation and test data with the Best final individual.
21Feb13_220954| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_220954|-----------  ------------------  --------------------  ----------
21Feb13_220954|Validation         20.00                  36            0.85448
21Feb13_220954|   Test            29.54                  36            0.68007
21Feb13_220954|-------------------- Test #10 --------------------
21Feb13_220954|Best final individual weights
21Feb13_220954|Individual:
21Feb13_220954|-- Constant hidden layers --
21Feb13_220954|False
21Feb13_220954|Layer 0:
21Feb13_220954|-- Config --
21Feb13_220954|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220954|-- Weights --
21Feb13_220954|[[-0.40915  0.29174 -0.34361  0.14991  0.48013  0.43962]
21Feb13_220954| [-0.03889 -2.58918  1.23726 -0.94545  0.31112 -0.33123]
21Feb13_220954| [-0.20635  0.94283  0.91953  0.65409  0.05057 -0.26007]
21Feb13_220954| [ 0.43641 -0.76635  0.05389  1.13480  0.41780  0.46235]
21Feb13_220954| [ 1.82634  0.72047  0.74041 -0.14215 -0.12675 -0.24346]
21Feb13_220954| [ 0.28127  0.08807 -1.98005  0.01426  0.26090 -0.14537]
21Feb13_220954| [-1.25185  0.82655  0.46228 -0.55060  0.10941 -0.15674]
21Feb13_220954| [ 0.91445  1.72888 -0.21980  0.73581 -0.72850  0.14657]
21Feb13_220954| [-0.57907 -0.24880  1.15136  0.39596  0.74559  0.44478]
21Feb13_220954| [-1.70002 -0.70915 -2.56272  1.01268  0.12472  0.33916]
21Feb13_220954| [ 0.41868 -1.77356 -1.11896 -0.73114  0.06927  0.26964]
21Feb13_220954| [-1.09531  0.14368 -0.26154 -0.23597  0.45805  0.03320]
21Feb13_220954| [-0.50566 -0.11825  2.29879 -0.11187  0.83873 -0.31067]
21Feb13_220954| [ 0.41226 -2.16123  1.56164  0.08939 -0.72259  0.31162]
21Feb13_220954| [-1.24419  0.81010 -1.10440 -0.20148  0.35840 -0.33718]
21Feb13_220954| [-0.12460  0.61383 -0.45420  0.83739  0.56627 -0.42802]
21Feb13_220954| [-0.39166 -2.48851  1.52386 -1.32659  0.30787  0.13333]
21Feb13_220954| [-0.93483  0.69438 -0.95500  1.27853  0.05581  0.28043]
21Feb13_220954| [ 0.56230 -0.94056  0.46910  0.10418 -0.19409 -0.47523]
21Feb13_220954| [-2.07937  0.22698  1.42960  0.92495  0.47285  0.03640]
21Feb13_220954| [-0.37785  0.95082  1.95371 -0.51694 -0.55583 -0.47787]
21Feb13_220954| [-0.55685  0.99330 -2.63246  1.05090 -0.43896  0.28635]
21Feb13_220954| [ 1.18738  0.35601  1.18799  0.87220 -0.10480  0.27707]
21Feb13_220954| [-0.86533 -1.24460  0.85164  0.74349  0.54417  0.29889]
21Feb13_220954| [-0.24069 -1.24668  0.16743  0.84590  0.21360  0.29043]
21Feb13_220954| [ 0.63554  0.81106 -0.00390  1.39866  0.46540  0.17208]
21Feb13_220954| [ 0.30270  1.13969 -0.75028 -0.78198 -1.02639  0.05785]
21Feb13_220954| [-0.96730  0.20619 -1.16463  1.39466  0.57145  0.19332]
21Feb13_220954| [ 0.96709 -2.84136  0.18157 -0.77198  0.68265 -0.43429]
21Feb13_220954| [-1.15123 -0.32784 -1.75614  1.26760  0.32257 -0.39679]
21Feb13_220954| [ 1.65321 -0.51426  3.04899 -1.65205 -1.16383  0.16424]
21Feb13_220954| [-1.04445  1.98716 -1.72225 -1.62612 -0.39208  0.05691]
21Feb13_220954| [-0.03870  3.82088  0.10601 -1.50340  0.64469 -0.18022]
21Feb13_220954| [ 0.70423 -0.51765 -0.97406 -0.13983  0.39618 -0.43729]
21Feb13_220954| [ 0.11732 -1.38663 -1.62332 -1.08766 -0.63584 -0.02089]
21Feb13_220954| [-0.69095 -1.90050  0.56484  1.12305  0.68882 -0.42906]
21Feb13_220954| [ 1.84548  0.44085  0.64487 -0.70848 -0.82392 -0.36589]
21Feb13_220954| [ 0.09851  2.13277  0.57030 -0.79303  0.48128 -0.42670]
21Feb13_220954| [ 0.11840 -0.81597 -0.12555  0.58548  0.52800  0.32666]
21Feb13_220954| [-0.21547  1.51130 -1.44840 -0.95307  0.80526  0.45558]
21Feb13_220954| [ 0.65240  0.91420 -1.25405 -1.21548 -0.15191  0.32359]
21Feb13_220954| [-0.09876 -0.42450 -0.24028 -0.61702 -0.04275  0.08542]
21Feb13_220954| [-0.70354  1.07974 -0.49390  0.67614 -0.00435  0.12051]
21Feb13_220954| [-1.81032 -0.94975 -0.34274  0.23071  0.39457  0.45390]
21Feb13_220954| [-0.23721  0.17217 -0.42835 -1.68301 -0.30137  0.06268]
21Feb13_220954| [ 0.35544 -2.92353  1.61345 -1.99230 -0.39892  0.40786]
21Feb13_220954| [ 0.92536  0.52707  0.67114 -0.82958 -0.71602  0.46510]
21Feb13_220954| [-0.92465 -2.10152 -0.00460 -0.06597  0.49376 -0.49032]
21Feb13_220954| [ 0.45803  1.52102  0.44313 -0.89222  0.25115  0.38088]
21Feb13_220954| [-0.55595 -1.75173 -0.51886 -0.83852  0.43962 -0.35753]
21Feb13_220954| [ 1.05043  0.13022  0.50909  1.35826  0.06262  0.37678]
21Feb13_220954| [-0.73516 -1.66793 -1.03505 -0.32304  0.29883 -0.45118]
21Feb13_220954| [-0.98587 -1.27575  1.32223  1.83009 -0.24774 -0.02303]
21Feb13_220954| [ 0.62667  1.15369  1.08062 -0.95194 -0.33125  0.49280]
21Feb13_220954| [ 0.29335  0.50911 -0.31591 -0.47999 -0.68764  0.21059]
21Feb13_220954| [-0.57894  0.76114 -0.65343  0.71286  0.78908  0.25605]
21Feb13_220954| [-0.31510 -0.63291  0.15396 -1.15177 -0.27702  0.28602]]
21Feb13_220954|-- Bias --
21Feb13_220954|[ 0.33651 -0.10761 -0.53450  0.36499 -0.01881  0.10157]
21Feb13_220954|Layer 1:
21Feb13_220954|-- Config --
21Feb13_220954|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220954|-- Weights --
21Feb13_220954|[[-0.31032 -1.54200  0.38873  1.86483]
21Feb13_220954| [ 0.27827  0.68678 -0.04542  0.33503]
21Feb13_220954| [-0.12370 -2.00154  0.33123 -1.03780]
21Feb13_220954| [ 1.24947 -0.59883  0.08929  0.18047]
21Feb13_220954| [-0.12048 -0.19640  0.34362 -0.41276]
21Feb13_220954| [ 0.22336  0.35012  0.14086 -0.40865]]
21Feb13_220954|-- Bias --
21Feb13_220954|[-0.44268  0.22631 -0.39436 -0.21581]
21Feb13_220954|Layer 2:
21Feb13_220954|-- Config --
21Feb13_220954|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220954|-- Weights --
21Feb13_220954|[[-0.26912 -0.04537]
21Feb13_220954| [-0.13112  0.23976]
21Feb13_220954| [-0.33179 -0.13228]
21Feb13_220954| [-0.22655  0.49163]]
21Feb13_220954|-- Bias --
21Feb13_220954|[ 1.26151 -0.75338]
21Feb13_220954|Layer 3:
21Feb13_220954|-- Config --
21Feb13_220954|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_220954|-- Weights --
21Feb13_220954|[[ 0.40923 -1.00526]
21Feb13_220954| [ 0.41626 -0.24565]]
21Feb13_220954|-- Bias --
21Feb13_220954|[-1.04567 -0.78011]
21Feb13_220954|Predicting the validation and test data with the Best final individual.
21Feb13_221002| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_221002|-----------  ------------------  --------------------  ----------
21Feb13_221002|Validation         20.87                  36            0.86466
21Feb13_221002|   Test            21.11                  36            0.71746
21Feb13_221002|-------------------- Test #11 --------------------
21Feb13_221002|Best final individual weights
21Feb13_221002|Individual:
21Feb13_221002|-- Constant hidden layers --
21Feb13_221002|False
21Feb13_221002|Layer 0:
21Feb13_221002|-- Config --
21Feb13_221002|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_221002|-- Weights --
21Feb13_221002|[[-0.40915  0.29174 -0.34361  0.14991  0.48013  0.43962]
21Feb13_221002| [-0.03889 -2.58918  1.23726 -0.94545  0.31112 -0.33123]
21Feb13_221002| [-0.20635  0.94283  0.91953  0.65409  0.05057 -0.26007]
21Feb13_221002| [ 0.43641 -0.76635  0.05389  1.13480  0.41780  0.46235]
21Feb13_221002| [ 1.82634  0.72047  0.74041 -0.14215 -0.12675 -0.24346]
21Feb13_221002| [ 0.28127  0.08807 -1.98005  0.01426  0.26090 -0.14537]
21Feb13_221002| [-1.25185  0.82655  0.46228 -0.55060  0.10941 -0.15674]
21Feb13_221002| [ 0.91445  1.72888 -0.21980  0.73581 -0.72850  0.14657]
21Feb13_221002| [-0.57907 -0.24880  1.15136  0.39596  0.74559  0.44478]
21Feb13_221002| [-1.70002 -0.70915 -2.56272  1.01268  0.12472  0.33916]
21Feb13_221002| [ 0.41868 -1.77356 -1.11896 -0.73114  0.06927  0.26964]
21Feb13_221002| [-1.09531  0.14368 -0.26154 -0.23597  0.45805  0.03320]
21Feb13_221002| [-0.50566 -0.11825  2.29879 -0.11187  0.83873 -0.31067]
21Feb13_221002| [ 0.41226 -2.16123  1.56164  0.08939 -0.72259  0.31162]
21Feb13_221002| [-1.24419  0.81010 -1.10440 -0.20148  0.35840 -0.33718]
21Feb13_221002| [-0.12460  0.61383 -0.45420  0.83739  0.56627 -0.42802]
21Feb13_221002| [-0.39166 -2.48851  1.52386 -1.32659  0.30787  0.13333]
21Feb13_221002| [-0.93483  0.69438 -0.95500  1.27853  0.05581  0.28043]
21Feb13_221002| [ 0.56230 -0.94056  0.46910  0.10418 -0.19409 -0.47523]
21Feb13_221002| [-2.07937  0.22698  1.42960  0.92495  0.47285  0.03640]
21Feb13_221002| [-0.37785  0.95082  1.95371 -0.51694 -0.55583 -0.47787]
21Feb13_221002| [-0.55685  0.99330 -2.63246  1.05090 -0.43896  0.28635]
21Feb13_221002| [ 1.18738  0.35601  1.18799  0.87220 -0.10480  0.27707]
21Feb13_221002| [-0.86533 -1.24460  0.85164  0.74349  0.54417  0.29889]
21Feb13_221002| [-0.24069 -1.24668  0.16743  0.84590  0.21360  0.29043]
21Feb13_221002| [ 0.63554  0.81106 -0.00390  1.39866  0.46540  0.17208]
21Feb13_221002| [ 0.30270  1.13969 -0.75028 -0.78198 -1.02639  0.05785]
21Feb13_221002| [-0.96730  0.20619 -1.16463  1.39466  0.57145  0.19332]
21Feb13_221002| [ 0.96709 -2.84136  0.18157 -0.77198  0.68265 -0.43429]
21Feb13_221002| [-1.15123 -0.32784 -1.75614  1.26760  0.32257 -0.39679]
21Feb13_221002| [ 1.65321 -0.51426  3.04899 -1.65205 -1.16383  0.16424]
21Feb13_221002| [-1.04445  1.98716 -1.72225 -1.62612 -0.39208  0.05691]
21Feb13_221002| [-0.03870  3.82088  0.10601 -1.50340  0.64469 -0.18022]
21Feb13_221002| [ 0.70423 -0.51765 -0.97406 -0.13983  0.39618 -0.43729]
21Feb13_221002| [ 0.11732 -1.38663 -1.62332 -1.08766 -0.63584 -0.02089]
21Feb13_221002| [-0.69095 -1.90050  0.56484  1.12305  0.68882 -0.42906]
21Feb13_221002| [ 1.84548  0.44085  0.64487 -0.70848 -0.82392 -0.36589]
21Feb13_221002| [ 0.09851  2.13277  0.57030 -0.79303  0.48128 -0.42670]
21Feb13_221002| [ 0.11840 -0.81597 -0.12555  0.58548  0.52800  0.32666]
21Feb13_221002| [-0.21547  1.51130 -1.44840 -0.95307  0.80526  0.45558]
21Feb13_221002| [ 0.65240  0.91420 -1.25405 -1.21548 -0.15191  0.32359]
21Feb13_221002| [-0.09876 -0.42450 -0.24028 -0.61702 -0.04275  0.08542]
21Feb13_221002| [-0.70354  1.07974 -0.49390  0.67614 -0.00435  0.12051]
21Feb13_221002| [-1.81032 -0.94975 -0.34274  0.23071  0.39457  0.45390]
21Feb13_221002| [-0.23721  0.17217 -0.42835 -1.68301 -0.30137  0.06268]
21Feb13_221002| [ 0.35544 -2.92353  1.61345 -1.99230 -0.39892  0.40786]
21Feb13_221002| [ 0.92536  0.52707  0.67114 -0.82958 -0.71602  0.46510]
21Feb13_221002| [-0.92465 -2.10152 -0.00460 -0.06597  0.49376 -0.49032]
21Feb13_221002| [ 0.45803  1.52102  0.44313 -0.89222  0.25115  0.38088]
21Feb13_221002| [-0.55595 -1.75173 -0.51886 -0.83852  0.43962 -0.35753]
21Feb13_221002| [ 1.05043  0.13022  0.50909  1.35826  0.06262  0.37678]
21Feb13_221002| [-0.73516 -1.66793 -1.03505 -0.32304  0.29883 -0.45118]
21Feb13_221002| [-0.98587 -1.27575  1.32223  1.83009 -0.24774 -0.02303]
21Feb13_221002| [ 0.62667  1.15369  1.08062 -0.95194 -0.33125  0.49280]
21Feb13_221002| [ 0.29335  0.50911 -0.31591 -0.47999 -0.68764  0.21059]
21Feb13_221002| [-0.57894  0.76114 -0.65343  0.71286  0.78908  0.25605]
21Feb13_221002| [-0.31510 -0.63291  0.15396 -1.15177 -0.27702  0.28602]]
21Feb13_221002|-- Bias --
21Feb13_221002|[ 0.33651 -0.10761 -0.53450  0.36499 -0.01881  0.10157]
21Feb13_221002|Layer 1:
21Feb13_221002|-- Config --
21Feb13_221002|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_221002|-- Weights --
21Feb13_221002|[[-0.31032 -1.54200  0.38873  1.86483]
21Feb13_221002| [ 0.27827  0.68678 -0.04542  0.33503]
21Feb13_221002| [-0.12370 -2.00154  0.33123 -1.03780]
21Feb13_221002| [ 1.24947 -0.59883  0.08929  0.18047]
21Feb13_221002| [-0.12048 -0.19640  0.34362 -0.41276]
21Feb13_221002| [ 0.22336  0.35012  0.14086 -0.40865]]
21Feb13_221002|-- Bias --
21Feb13_221002|[-0.44268  0.22631 -0.39436 -0.21581]
21Feb13_221002|Layer 2:
21Feb13_221002|-- Config --
21Feb13_221002|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_221002|-- Weights --
21Feb13_221002|[[-0.26912 -0.04537]
21Feb13_221002| [-0.13112  0.23976]
21Feb13_221002| [-0.33179 -0.13228]
21Feb13_221002| [-0.22655  0.49163]]
21Feb13_221002|-- Bias --
21Feb13_221002|[ 1.26151 -0.75338]
21Feb13_221002|Layer 3:
21Feb13_221002|-- Config --
21Feb13_221002|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_221002|-- Weights --
21Feb13_221002|[[ 0.40923 -1.00526]
21Feb13_221002| [ 0.41626 -0.24565]]
21Feb13_221002|-- Bias --
21Feb13_221002|[-1.04567 -0.78011]
21Feb13_221002|Predicting the validation and test data with the Best final individual.
21Feb13_221010| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_221010|-----------  ------------------  --------------------  ----------
21Feb13_221010|Validation         38.43                  36            0.00000
21Feb13_221010|   Test            29.45                  36            0.78182
21Feb13_221010|-------------------- Test #12 --------------------
21Feb13_221010|Best final individual weights
21Feb13_221010|Individual:
21Feb13_221010|-- Constant hidden layers --
21Feb13_221010|False
21Feb13_221010|Layer 0:
21Feb13_221010|-- Config --
21Feb13_221010|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_221010|-- Weights --
21Feb13_221010|[[-0.40915  0.29174 -0.34361  0.14991  0.48013  0.43962]
21Feb13_221010| [-0.03889 -2.58918  1.23726 -0.94545  0.31112 -0.33123]
21Feb13_221010| [-0.20635  0.94283  0.91953  0.65409  0.05057 -0.26007]
21Feb13_221010| [ 0.43641 -0.76635  0.05389  1.13480  0.41780  0.46235]
21Feb13_221010| [ 1.82634  0.72047  0.74041 -0.14215 -0.12675 -0.24346]
21Feb13_221010| [ 0.28127  0.08807 -1.98005  0.01426  0.26090 -0.14537]
21Feb13_221010| [-1.25185  0.82655  0.46228 -0.55060  0.10941 -0.15674]
21Feb13_221010| [ 0.91445  1.72888 -0.21980  0.73581 -0.72850  0.14657]
21Feb13_221010| [-0.57907 -0.24880  1.15136  0.39596  0.74559  0.44478]
21Feb13_221010| [-1.70002 -0.70915 -2.56272  1.01268  0.12472  0.33916]
21Feb13_221010| [ 0.41868 -1.77356 -1.11896 -0.73114  0.06927  0.26964]
21Feb13_221010| [-1.09531  0.14368 -0.26154 -0.23597  0.45805  0.03320]
21Feb13_221010| [-0.50566 -0.11825  2.29879 -0.11187  0.83873 -0.31067]
21Feb13_221010| [ 0.41226 -2.16123  1.56164  0.08939 -0.72259  0.31162]
21Feb13_221010| [-1.24419  0.81010 -1.10440 -0.20148  0.35840 -0.33718]
21Feb13_221010| [-0.12460  0.61383 -0.45420  0.83739  0.56627 -0.42802]
21Feb13_221010| [-0.39166 -2.48851  1.52386 -1.32659  0.30787  0.13333]
21Feb13_221010| [-0.93483  0.69438 -0.95500  1.27853  0.05581  0.28043]
21Feb13_221010| [ 0.56230 -0.94056  0.46910  0.10418 -0.19409 -0.47523]
21Feb13_221010| [-2.07937  0.22698  1.42960  0.92495  0.47285  0.03640]
21Feb13_221010| [-0.37785  0.95082  1.95371 -0.51694 -0.55583 -0.47787]
21Feb13_221010| [-0.55685  0.99330 -2.63246  1.05090 -0.43896  0.28635]
21Feb13_221010| [ 1.18738  0.35601  1.18799  0.87220 -0.10480  0.27707]
21Feb13_221010| [-0.86533 -1.24460  0.85164  0.74349  0.54417  0.29889]
21Feb13_221010| [-0.24069 -1.24668  0.16743  0.84590  0.21360  0.29043]
21Feb13_221010| [ 0.63554  0.81106 -0.00390  1.39866  0.46540  0.17208]
21Feb13_221010| [ 0.30270  1.13969 -0.75028 -0.78198 -1.02639  0.05785]
21Feb13_221010| [-0.96730  0.20619 -1.16463  1.39466  0.57145  0.19332]
21Feb13_221010| [ 0.96709 -2.84136  0.18157 -0.77198  0.68265 -0.43429]
21Feb13_221010| [-1.15123 -0.32784 -1.75614  1.26760  0.32257 -0.39679]
21Feb13_221010| [ 1.65321 -0.51426  3.04899 -1.65205 -1.16383  0.16424]
21Feb13_221010| [-1.04445  1.98716 -1.72225 -1.62612 -0.39208  0.05691]
21Feb13_221010| [-0.03870  3.82088  0.10601 -1.50340  0.64469 -0.18022]
21Feb13_221010| [ 0.70423 -0.51765 -0.97406 -0.13983  0.39618 -0.43729]
21Feb13_221010| [ 0.11732 -1.38663 -1.62332 -1.08766 -0.63584 -0.02089]
21Feb13_221010| [-0.69095 -1.90050  0.56484  1.12305  0.68882 -0.42906]
21Feb13_221010| [ 1.84548  0.44085  0.64487 -0.70848 -0.82392 -0.36589]
21Feb13_221010| [ 0.09851  2.13277  0.57030 -0.79303  0.48128 -0.42670]
21Feb13_221010| [ 0.11840 -0.81597 -0.12555  0.58548  0.52800  0.32666]
21Feb13_221010| [-0.21547  1.51130 -1.44840 -0.95307  0.80526  0.45558]
21Feb13_221010| [ 0.65240  0.91420 -1.25405 -1.21548 -0.15191  0.32359]
21Feb13_221010| [-0.09876 -0.42450 -0.24028 -0.61702 -0.04275  0.08542]
21Feb13_221010| [-0.70354  1.07974 -0.49390  0.67614 -0.00435  0.12051]
21Feb13_221010| [-1.81032 -0.94975 -0.34274  0.23071  0.39457  0.45390]
21Feb13_221010| [-0.23721  0.17217 -0.42835 -1.68301 -0.30137  0.06268]
21Feb13_221010| [ 0.35544 -2.92353  1.61345 -1.99230 -0.39892  0.40786]
21Feb13_221010| [ 0.92536  0.52707  0.67114 -0.82958 -0.71602  0.46510]
21Feb13_221010| [-0.92465 -2.10152 -0.00460 -0.06597  0.49376 -0.49032]
21Feb13_221010| [ 0.45803  1.52102  0.44313 -0.89222  0.25115  0.38088]
21Feb13_221010| [-0.55595 -1.75173 -0.51886 -0.83852  0.43962 -0.35753]
21Feb13_221010| [ 1.05043  0.13022  0.50909  1.35826  0.06262  0.37678]
21Feb13_221010| [-0.73516 -1.66793 -1.03505 -0.32304  0.29883 -0.45118]
21Feb13_221010| [-0.98587 -1.27575  1.32223  1.83009 -0.24774 -0.02303]
21Feb13_221010| [ 0.62667  1.15369  1.08062 -0.95194 -0.33125  0.49280]
21Feb13_221010| [ 0.29335  0.50911 -0.31591 -0.47999 -0.68764  0.21059]
21Feb13_221010| [-0.57894  0.76114 -0.65343  0.71286  0.78908  0.25605]
21Feb13_221010| [-0.31510 -0.63291  0.15396 -1.15177 -0.27702  0.28602]]
21Feb13_221010|-- Bias --
21Feb13_221010|[ 0.33651 -0.10761 -0.53450  0.36499 -0.01881  0.10157]
21Feb13_221010|Layer 1:
21Feb13_221010|-- Config --
21Feb13_221010|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_221010|-- Weights --
21Feb13_221010|[[-0.31032 -1.54200  0.38873  1.86483]
21Feb13_221010| [ 0.27827  0.68678 -0.04542  0.33503]
21Feb13_221010| [-0.12370 -2.00154  0.33123 -1.03780]
21Feb13_221010| [ 1.24947 -0.59883  0.08929  0.18047]
21Feb13_221010| [-0.12048 -0.19640  0.34362 -0.41276]
21Feb13_221010| [ 0.22336  0.35012  0.14086 -0.40865]]
21Feb13_221010|-- Bias --
21Feb13_221010|[-0.44268  0.22631 -0.39436 -0.21581]
21Feb13_221010|Layer 2:
21Feb13_221010|-- Config --
21Feb13_221010|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_221010|-- Weights --
21Feb13_221010|[[-0.26912 -0.04537]
21Feb13_221010| [-0.13112  0.23976]
21Feb13_221010| [-0.33179 -0.13228]
21Feb13_221010| [-0.22655  0.49163]]
21Feb13_221010|-- Bias --
21Feb13_221010|[ 1.26151 -0.75338]
21Feb13_221010|Layer 3:
21Feb13_221010|-- Config --
21Feb13_221010|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_221010|-- Weights --
21Feb13_221010|[[ 0.40923 -1.00526]
21Feb13_221010| [ 0.41626 -0.24565]]
21Feb13_221010|-- Bias --
21Feb13_221010|[-1.04567 -0.78011]
21Feb13_221010|Predicting the validation and test data with the Best final individual.
21Feb13_221017| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_221017|-----------  ------------------  --------------------  ----------
21Feb13_221017|Validation         27.13                  36            0.78086
21Feb13_221017|   Test            21.20                  36            0.72030
21Feb13_221017|-------------------- Test #13 --------------------
21Feb13_221017|Best final individual weights
21Feb13_221017|Individual:
21Feb13_221017|-- Constant hidden layers --
21Feb13_221017|False
21Feb13_221017|Layer 0:
21Feb13_221017|-- Config --
21Feb13_221017|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_221017|-- Weights --
21Feb13_221017|[[-0.40915  0.29174 -0.34361  0.14991  0.48013  0.43962]
21Feb13_221017| [-0.03889 -2.58918  1.23726 -0.94545  0.31112 -0.33123]
21Feb13_221017| [-0.20635  0.94283  0.91953  0.65409  0.05057 -0.26007]
21Feb13_221017| [ 0.43641 -0.76635  0.05389  1.13480  0.41780  0.46235]
21Feb13_221017| [ 1.82634  0.72047  0.74041 -0.14215 -0.12675 -0.24346]
21Feb13_221017| [ 0.28127  0.08807 -1.98005  0.01426  0.26090 -0.14537]
21Feb13_221017| [-1.25185  0.82655  0.46228 -0.55060  0.10941 -0.15674]
21Feb13_221017| [ 0.91445  1.72888 -0.21980  0.73581 -0.72850  0.14657]
21Feb13_221017| [-0.57907 -0.24880  1.15136  0.39596  0.74559  0.44478]
21Feb13_221017| [-1.70002 -0.70915 -2.56272  1.01268  0.12472  0.33916]
21Feb13_221017| [ 0.41868 -1.77356 -1.11896 -0.73114  0.06927  0.26964]
21Feb13_221017| [-1.09531  0.14368 -0.26154 -0.23597  0.45805  0.03320]
21Feb13_221017| [-0.50566 -0.11825  2.29879 -0.11187  0.83873 -0.31067]
21Feb13_221017| [ 0.41226 -2.16123  1.56164  0.08939 -0.72259  0.31162]
21Feb13_221017| [-1.24419  0.81010 -1.10440 -0.20148  0.35840 -0.33718]
21Feb13_221017| [-0.12460  0.61383 -0.45420  0.83739  0.56627 -0.42802]
21Feb13_221017| [-0.39166 -2.48851  1.52386 -1.32659  0.30787  0.13333]
21Feb13_221017| [-0.93483  0.69438 -0.95500  1.27853  0.05581  0.28043]
21Feb13_221017| [ 0.56230 -0.94056  0.46910  0.10418 -0.19409 -0.47523]
21Feb13_221017| [-2.07937  0.22698  1.42960  0.92495  0.47285  0.03640]
21Feb13_221017| [-0.37785  0.95082  1.95371 -0.51694 -0.55583 -0.47787]
21Feb13_221017| [-0.55685  0.99330 -2.63246  1.05090 -0.43896  0.28635]
21Feb13_221017| [ 1.18738  0.35601  1.18799  0.87220 -0.10480  0.27707]
21Feb13_221017| [-0.86533 -1.24460  0.85164  0.74349  0.54417  0.29889]
21Feb13_221017| [-0.24069 -1.24668  0.16743  0.84590  0.21360  0.29043]
21Feb13_221017| [ 0.63554  0.81106 -0.00390  1.39866  0.46540  0.17208]
21Feb13_221017| [ 0.30270  1.13969 -0.75028 -0.78198 -1.02639  0.05785]
21Feb13_221017| [-0.96730  0.20619 -1.16463  1.39466  0.57145  0.19332]
21Feb13_221017| [ 0.96709 -2.84136  0.18157 -0.77198  0.68265 -0.43429]
21Feb13_221017| [-1.15123 -0.32784 -1.75614  1.26760  0.32257 -0.39679]
21Feb13_221017| [ 1.65321 -0.51426  3.04899 -1.65205 -1.16383  0.16424]
21Feb13_221017| [-1.04445  1.98716 -1.72225 -1.62612 -0.39208  0.05691]
21Feb13_221017| [-0.03870  3.82088  0.10601 -1.50340  0.64469 -0.18022]
21Feb13_221017| [ 0.70423 -0.51765 -0.97406 -0.13983  0.39618 -0.43729]
21Feb13_221017| [ 0.11732 -1.38663 -1.62332 -1.08766 -0.63584 -0.02089]
21Feb13_221017| [-0.69095 -1.90050  0.56484  1.12305  0.68882 -0.42906]
21Feb13_221017| [ 1.84548  0.44085  0.64487 -0.70848 -0.82392 -0.36589]
21Feb13_221017| [ 0.09851  2.13277  0.57030 -0.79303  0.48128 -0.42670]
21Feb13_221017| [ 0.11840 -0.81597 -0.12555  0.58548  0.52800  0.32666]
21Feb13_221017| [-0.21547  1.51130 -1.44840 -0.95307  0.80526  0.45558]
21Feb13_221017| [ 0.65240  0.91420 -1.25405 -1.21548 -0.15191  0.32359]
21Feb13_221017| [-0.09876 -0.42450 -0.24028 -0.61702 -0.04275  0.08542]
21Feb13_221017| [-0.70354  1.07974 -0.49390  0.67614 -0.00435  0.12051]
21Feb13_221017| [-1.81032 -0.94975 -0.34274  0.23071  0.39457  0.45390]
21Feb13_221017| [-0.23721  0.17217 -0.42835 -1.68301 -0.30137  0.06268]
21Feb13_221017| [ 0.35544 -2.92353  1.61345 -1.99230 -0.39892  0.40786]
21Feb13_221017| [ 0.92536  0.52707  0.67114 -0.82958 -0.71602  0.46510]
21Feb13_221017| [-0.92465 -2.10152 -0.00460 -0.06597  0.49376 -0.49032]
21Feb13_221017| [ 0.45803  1.52102  0.44313 -0.89222  0.25115  0.38088]
21Feb13_221017| [-0.55595 -1.75173 -0.51886 -0.83852  0.43962 -0.35753]
21Feb13_221017| [ 1.05043  0.13022  0.50909  1.35826  0.06262  0.37678]
21Feb13_221017| [-0.73516 -1.66793 -1.03505 -0.32304  0.29883 -0.45118]
21Feb13_221017| [-0.98587 -1.27575  1.32223  1.83009 -0.24774 -0.02303]
21Feb13_221017| [ 0.62667  1.15369  1.08062 -0.95194 -0.33125  0.49280]
21Feb13_221017| [ 0.29335  0.50911 -0.31591 -0.47999 -0.68764  0.21059]
21Feb13_221017| [-0.57894  0.76114 -0.65343  0.71286  0.78908  0.25605]
21Feb13_221017| [-0.31510 -0.63291  0.15396 -1.15177 -0.27702  0.28602]]
21Feb13_221017|-- Bias --
21Feb13_221017|[ 0.33651 -0.10761 -0.53450  0.36499 -0.01881  0.10157]
21Feb13_221017|Layer 1:
21Feb13_221017|-- Config --
21Feb13_221017|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_221017|-- Weights --
21Feb13_221017|[[-0.31032 -1.54200  0.38873  1.86483]
21Feb13_221017| [ 0.27827  0.68678 -0.04542  0.33503]
21Feb13_221017| [-0.12370 -2.00154  0.33123 -1.03780]
21Feb13_221017| [ 1.24947 -0.59883  0.08929  0.18047]
21Feb13_221017| [-0.12048 -0.19640  0.34362 -0.41276]
21Feb13_221017| [ 0.22336  0.35012  0.14086 -0.40865]]
21Feb13_221017|-- Bias --
21Feb13_221017|[-0.44268  0.22631 -0.39436 -0.21581]
21Feb13_221017|Layer 2:
21Feb13_221017|-- Config --
21Feb13_221017|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_221017|-- Weights --
21Feb13_221017|[[-0.26912 -0.04537]
21Feb13_221017| [-0.13112  0.23976]
21Feb13_221017| [-0.33179 -0.13228]
21Feb13_221017| [-0.22655  0.49163]]
21Feb13_221017|-- Bias --
21Feb13_221017|[ 1.26151 -0.75338]
21Feb13_221017|Layer 3:
21Feb13_221017|-- Config --
21Feb13_221017|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_221017|-- Weights --
21Feb13_221017|[[ 0.40923 -1.00526]
21Feb13_221017| [ 0.41626 -0.24565]]
21Feb13_221017|-- Bias --
21Feb13_221017|[-1.04567 -0.78011]
21Feb13_221017|Predicting the validation and test data with the Best final individual.
21Feb13_221025| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_221025|-----------  ------------------  --------------------  ----------
21Feb13_221025|Validation         34.52                  36            0.84008
21Feb13_221025|   Test            24.50                  36            0.61813
21Feb13_221025|-------------------- Test #14 --------------------
21Feb13_221025|Best final individual weights
21Feb13_221025|Individual:
21Feb13_221025|-- Constant hidden layers --
21Feb13_221025|False
21Feb13_221025|Layer 0:
21Feb13_221025|-- Config --
21Feb13_221025|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_221025|-- Weights --
21Feb13_221025|[[-0.40915  0.29174 -0.34361  0.14991  0.48013  0.43962]
21Feb13_221025| [-0.03889 -2.58918  1.23726 -0.94545  0.31112 -0.33123]
21Feb13_221025| [-0.20635  0.94283  0.91953  0.65409  0.05057 -0.26007]
21Feb13_221025| [ 0.43641 -0.76635  0.05389  1.13480  0.41780  0.46235]
21Feb13_221025| [ 1.82634  0.72047  0.74041 -0.14215 -0.12675 -0.24346]
21Feb13_221025| [ 0.28127  0.08807 -1.98005  0.01426  0.26090 -0.14537]
21Feb13_221025| [-1.25185  0.82655  0.46228 -0.55060  0.10941 -0.15674]
21Feb13_221025| [ 0.91445  1.72888 -0.21980  0.73581 -0.72850  0.14657]
21Feb13_221025| [-0.57907 -0.24880  1.15136  0.39596  0.74559  0.44478]
21Feb13_221025| [-1.70002 -0.70915 -2.56272  1.01268  0.12472  0.33916]
21Feb13_221025| [ 0.41868 -1.77356 -1.11896 -0.73114  0.06927  0.26964]
21Feb13_221025| [-1.09531  0.14368 -0.26154 -0.23597  0.45805  0.03320]
21Feb13_221025| [-0.50566 -0.11825  2.29879 -0.11187  0.83873 -0.31067]
21Feb13_221025| [ 0.41226 -2.16123  1.56164  0.08939 -0.72259  0.31162]
21Feb13_221025| [-1.24419  0.81010 -1.10440 -0.20148  0.35840 -0.33718]
21Feb13_221025| [-0.12460  0.61383 -0.45420  0.83739  0.56627 -0.42802]
21Feb13_221025| [-0.39166 -2.48851  1.52386 -1.32659  0.30787  0.13333]
21Feb13_221025| [-0.93483  0.69438 -0.95500  1.27853  0.05581  0.28043]
21Feb13_221025| [ 0.56230 -0.94056  0.46910  0.10418 -0.19409 -0.47523]
21Feb13_221025| [-2.07937  0.22698  1.42960  0.92495  0.47285  0.03640]
21Feb13_221025| [-0.37785  0.95082  1.95371 -0.51694 -0.55583 -0.47787]
21Feb13_221025| [-0.55685  0.99330 -2.63246  1.05090 -0.43896  0.28635]
21Feb13_221025| [ 1.18738  0.35601  1.18799  0.87220 -0.10480  0.27707]
21Feb13_221025| [-0.86533 -1.24460  0.85164  0.74349  0.54417  0.29889]
21Feb13_221025| [-0.24069 -1.24668  0.16743  0.84590  0.21360  0.29043]
21Feb13_221025| [ 0.63554  0.81106 -0.00390  1.39866  0.46540  0.17208]
21Feb13_221025| [ 0.30270  1.13969 -0.75028 -0.78198 -1.02639  0.05785]
21Feb13_221025| [-0.96730  0.20619 -1.16463  1.39466  0.57145  0.19332]
21Feb13_221025| [ 0.96709 -2.84136  0.18157 -0.77198  0.68265 -0.43429]
21Feb13_221025| [-1.15123 -0.32784 -1.75614  1.26760  0.32257 -0.39679]
21Feb13_221025| [ 1.65321 -0.51426  3.04899 -1.65205 -1.16383  0.16424]
21Feb13_221025| [-1.04445  1.98716 -1.72225 -1.62612 -0.39208  0.05691]
21Feb13_221025| [-0.03870  3.82088  0.10601 -1.50340  0.64469 -0.18022]
21Feb13_221025| [ 0.70423 -0.51765 -0.97406 -0.13983  0.39618 -0.43729]
21Feb13_221025| [ 0.11732 -1.38663 -1.62332 -1.08766 -0.63584 -0.02089]
21Feb13_221025| [-0.69095 -1.90050  0.56484  1.12305  0.68882 -0.42906]
21Feb13_221025| [ 1.84548  0.44085  0.64487 -0.70848 -0.82392 -0.36589]
21Feb13_221025| [ 0.09851  2.13277  0.57030 -0.79303  0.48128 -0.42670]
21Feb13_221025| [ 0.11840 -0.81597 -0.12555  0.58548  0.52800  0.32666]
21Feb13_221025| [-0.21547  1.51130 -1.44840 -0.95307  0.80526  0.45558]
21Feb13_221025| [ 0.65240  0.91420 -1.25405 -1.21548 -0.15191  0.32359]
21Feb13_221025| [-0.09876 -0.42450 -0.24028 -0.61702 -0.04275  0.08542]
21Feb13_221025| [-0.70354  1.07974 -0.49390  0.67614 -0.00435  0.12051]
21Feb13_221025| [-1.81032 -0.94975 -0.34274  0.23071  0.39457  0.45390]
21Feb13_221025| [-0.23721  0.17217 -0.42835 -1.68301 -0.30137  0.06268]
21Feb13_221025| [ 0.35544 -2.92353  1.61345 -1.99230 -0.39892  0.40786]
21Feb13_221025| [ 0.92536  0.52707  0.67114 -0.82958 -0.71602  0.46510]
21Feb13_221025| [-0.92465 -2.10152 -0.00460 -0.06597  0.49376 -0.49032]
21Feb13_221025| [ 0.45803  1.52102  0.44313 -0.89222  0.25115  0.38088]
21Feb13_221025| [-0.55595 -1.75173 -0.51886 -0.83852  0.43962 -0.35753]
21Feb13_221025| [ 1.05043  0.13022  0.50909  1.35826  0.06262  0.37678]
21Feb13_221025| [-0.73516 -1.66793 -1.03505 -0.32304  0.29883 -0.45118]
21Feb13_221025| [-0.98587 -1.27575  1.32223  1.83009 -0.24774 -0.02303]
21Feb13_221025| [ 0.62667  1.15369  1.08062 -0.95194 -0.33125  0.49280]
21Feb13_221025| [ 0.29335  0.50911 -0.31591 -0.47999 -0.68764  0.21059]
21Feb13_221025| [-0.57894  0.76114 -0.65343  0.71286  0.78908  0.25605]
21Feb13_221025| [-0.31510 -0.63291  0.15396 -1.15177 -0.27702  0.28602]]
21Feb13_221025|-- Bias --
21Feb13_221025|[ 0.33651 -0.10761 -0.53450  0.36499 -0.01881  0.10157]
21Feb13_221025|Layer 1:
21Feb13_221025|-- Config --
21Feb13_221025|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_221025|-- Weights --
21Feb13_221025|[[-0.31032 -1.54200  0.38873  1.86483]
21Feb13_221025| [ 0.27827  0.68678 -0.04542  0.33503]
21Feb13_221025| [-0.12370 -2.00154  0.33123 -1.03780]
21Feb13_221025| [ 1.24947 -0.59883  0.08929  0.18047]
21Feb13_221025| [-0.12048 -0.19640  0.34362 -0.41276]
21Feb13_221025| [ 0.22336  0.35012  0.14086 -0.40865]]
21Feb13_221025|-- Bias --
21Feb13_221025|[-0.44268  0.22631 -0.39436 -0.21581]
21Feb13_221025|Layer 2:
21Feb13_221025|-- Config --
21Feb13_221025|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_221025|-- Weights --
21Feb13_221025|[[-0.26912 -0.04537]
21Feb13_221025| [-0.13112  0.23976]
21Feb13_221025| [-0.33179 -0.13228]
21Feb13_221025| [-0.22655  0.49163]]
21Feb13_221025|-- Bias --
21Feb13_221025|[ 1.26151 -0.75338]
21Feb13_221025|Layer 3:
21Feb13_221025|-- Config --
21Feb13_221025|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_221025|-- Weights --
21Feb13_221025|[[ 0.40923 -1.00526]
21Feb13_221025| [ 0.41626 -0.24565]]
21Feb13_221025|-- Bias --
21Feb13_221025|[-1.04567 -0.78011]
21Feb13_221025|Predicting the validation and test data with the Best final individual.
21Feb13_221033| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_221033|-----------  ------------------  --------------------  ----------
21Feb13_221033|Validation         19.13                  36            0.73998
21Feb13_221033|   Test            39.62                  36            0.00000
