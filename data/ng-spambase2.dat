2021-02-12 10:15:25.135832: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
21Feb12_101526|Data summary: Train
21Feb12_101526|data.shape = (2300, 57)
21Feb12_101526|labels.shape = (2300,)
21Feb12_101526|Class distribution:
21Feb12_101526|	0 - 1389 (0.60)
21Feb12_101526|	1 - 911 (0.40)
21Feb12_101526|Data summary: Validation
21Feb12_101526|data.shape = (1150, 57)
21Feb12_101526|labels.shape = (1150,)
21Feb12_101526|Class distribution:
21Feb12_101526|	0 - 667 (0.58)
21Feb12_101526|	1 - 483 (0.42)
21Feb12_101526|Data summary: Test
21Feb12_101526|data.shape = (1151, 57)
21Feb12_101526|labels.shape = (1151,)
21Feb12_101526|Class distribution:
21Feb12_101526|	0 - 732 (0.64)
21Feb12_101526|	1 - 419 (0.36)
21Feb12_101526|Selected configuration values
21Feb12_101526|-- Dataset name: spambase2
21Feb12_101526|-- Initial population size: 64
21Feb12_101526|-- Maximun number of generations: 32
21Feb12_101526|-- Neurons per hidden layer range: (2, 20)
21Feb12_101526|-- Hidden layers number range: (1, 3)
21Feb12_101526|-- Crossover probability: 0.5
21Feb12_101526|-- Bias gene mutation probability: 0.2
21Feb12_101526|-- Weights gene mutation probability: 0.75
21Feb12_101526|-- Neuron mutation probability: 0.3
21Feb12_101526|-- Layer mutation probability: 0.3
21Feb12_101526|-- Constant hidden layers: False
21Feb12_101526|-- Seed: 31415
21Feb12_101526|Entering GA
21Feb12_101526|Start the algorithm
2021-02-12 10:15:26.011497: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-12 10:15:26.012004: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-02-12 10:15:26.035089: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-12 10:15:26.035415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.71GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s
2021-02-12 10:15:26.035431: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-02-12 10:15:26.036864: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-02-12 10:15:26.036896: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-02-12 10:15:26.037389: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-02-12 10:15:26.037523: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-02-12 10:15:26.037597: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-12 10:15:26.037985: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-02-12 10:15:26.038036: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-12 10:15:26.038043: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-02-12 10:15:26.038272: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-02-12 10:15:26.039030: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-12 10:15:26.039046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-12 10:15:26.039051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      
2021-02-12 10:15:26.087097: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-02-12 10:15:26.087418: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3493635000 Hz
/home/jmerelo/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype("int32")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn('`model.predict_classes()` is deprecated and '
21Feb12_101928|-- Generation 1 --
21Feb12_101928|    -- Crossed 0 individual pairs.
21Feb12_101928|    -- Mutated 32 individuals.
21Feb12_102326|    -- Evaluated 64 individuals.
21Feb12_102326|    Summary of generation 1:
21Feb12_102326| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_102326|-----------  ------------------  --------------------  ----------
21Feb12_102326|    Max            42.35                120.00          0.02572
21Feb12_102326|    Avg            41.99                38.77           0.00145
21Feb12_102326|    Min            41.30                 3.00           0.00000
21Feb12_102326|    Std             0.12                31.35           0.00361
21Feb12_102326|   Best            41.30                20.00           0.02572
21Feb12_102326|-- Generation 2 --
21Feb12_102326|    -- Crossed 3 individual pairs.
21Feb12_102326|    -- Mutated 32 individuals.
21Feb12_102720|    -- Evaluated 64 individuals.
21Feb12_102720|    Summary of generation 2:
21Feb12_102720| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_102720|-----------  ------------------  --------------------  ----------
21Feb12_102720|    Max            42.17                120.00          0.73848
21Feb12_102720|    Avg            41.79                21.98           0.01319
21Feb12_102720|    Min            29.57                 3.00           0.00000
21Feb12_102720|    Std             1.55                23.47           0.09146
21Feb12_102720|   Best            29.57                62.00           0.73848
21Feb12_102720|-- Generation 3 --
21Feb12_102720|    -- Crossed 1 individual pairs.
21Feb12_102720|    -- Mutated 32 individuals.
21Feb12_103112|    -- Evaluated 64 individuals.
21Feb12_103112|    Summary of generation 3:
21Feb12_103112| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_103112|-----------  ------------------  --------------------  ----------
21Feb12_103112|    Max            43.83                62.00           0.69694
21Feb12_103112|    Avg            41.73                14.39           0.01242
21Feb12_103112|    Min            23.83                 3.00           0.00000
21Feb12_103112|    Std             2.27                14.67           0.08631
21Feb12_103112|   Best            23.83                20.00           0.69694
21Feb12_103112|-- Generation 4 --
21Feb12_103112|    -- Crossed 6 individual pairs.
21Feb12_103112|    -- Mutated 32 individuals.
21Feb12_103503|    -- Evaluated 64 individuals.
21Feb12_103503|    Summary of generation 4:
21Feb12_103503| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_103503|-----------  ------------------  --------------------  ----------
21Feb12_103503|    Max            42.26                108.00          0.70835
21Feb12_103503|    Avg            41.44                10.59           0.02341
21Feb12_103503|    Min            24.00                 2.00           0.00000
21Feb12_103503|    Std             3.03                15.33           0.12205
21Feb12_103503|   Best            24.00                20.00           0.70835
21Feb12_103503|-- Generation 5 --
21Feb12_103503|    -- Crossed 6 individual pairs.
21Feb12_103503|    -- Mutated 32 individuals.
21Feb12_103853|    -- Evaluated 64 individuals.
21Feb12_103853|    Summary of generation 5:
21Feb12_103853| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_103853|-----------  ------------------  --------------------  ----------
21Feb12_103853|    Max            42.17                45.00           0.66611
21Feb12_103853|    Avg            41.74                 8.42           0.01206
21Feb12_103853|    Min            27.22                 2.00           0.00000
21Feb12_103853|    Std             1.83                 7.82           0.08250
21Feb12_103853|   Best            27.22                24.00           0.66611
21Feb12_103853|-- Generation 6 --
21Feb12_103853|    -- Crossed 6 individual pairs.
21Feb12_103853|    -- Mutated 32 individuals.
21Feb12_104242|    -- Evaluated 64 individuals.
21Feb12_104242|    Summary of generation 6:
21Feb12_104242| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_104242|-----------  ------------------  --------------------  ----------
21Feb12_104242|    Max            42.26                46.00           0.53239
21Feb12_104242|    Avg            41.77                 8.89           0.00961
21Feb12_104242|    Min            28.26                 2.00           0.00000
21Feb12_104242|    Std             1.70                 8.40           0.06595
21Feb12_104242|   Best            28.26                14.00           0.53239
21Feb12_104242|-- Generation 7 --
21Feb12_104242|    -- Crossed 5 individual pairs.
21Feb12_104242|    -- Mutated 32 individuals.
21Feb12_104631|    -- Evaluated 64 individuals.
21Feb12_104631|    Summary of generation 7:
21Feb12_104631| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_104631|-----------  ------------------  --------------------  ----------
21Feb12_104631|    Max            42.17                44.00           0.55186
21Feb12_104631|    Avg            41.76                 8.02           0.01015
21Feb12_104631|    Min            26.87                 2.00           0.00000
21Feb12_104631|    Std             1.88                 8.32           0.06837
21Feb12_104631|   Best            26.87                14.00           0.55186
21Feb12_104631|-- Generation 8 --
21Feb12_104631|    -- Crossed 7 individual pairs.
21Feb12_104631|    -- Mutated 32 individuals.
21Feb12_105021|    -- Evaluated 64 individuals.
21Feb12_105021|    Summary of generation 8:
21Feb12_105021| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_105021|-----------  ------------------  --------------------  ----------
21Feb12_105021|    Max            42.35                48.00           0.45661
21Feb12_105021|    Avg            41.67                 7.20           0.01369
21Feb12_105021|    Min            30.43                 2.00           0.00000
21Feb12_105021|    Std             1.87                 8.09           0.07069
21Feb12_105021|   Best            30.43                16.00           0.45661
21Feb12_105021|-- Generation 9 --
21Feb12_105021|    -- Crossed 7 individual pairs.
21Feb12_105021|    -- Mutated 32 individuals.
21Feb12_105412|    -- Evaluated 64 individuals.
21Feb12_105412|    Summary of generation 9:
21Feb12_105412| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_105412|-----------  ------------------  --------------------  ----------
21Feb12_105412|    Max            42.00                20.00           0.82254
21Feb12_105412|    Avg            41.73                 5.22           0.02180
21Feb12_105412|    Min            27.30                 2.00           0.00000
21Feb12_105412|    Std             1.83                 4.98           0.11977
21Feb12_105412|   Best            27.30                14.00           0.52088
21Feb12_105412|-- Generation 10 --
21Feb12_105412|    -- Crossed 6 individual pairs.
21Feb12_105412|    -- Mutated 32 individuals.
21Feb12_105803|    -- Evaluated 64 individuals.
21Feb12_105803|    Summary of generation 10:
21Feb12_105803| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_105803|-----------  ------------------  --------------------  ----------
21Feb12_105803|    Max            42.17                16.00           0.81836
21Feb12_105803|    Avg            41.39                 5.30           0.03393
21Feb12_105803|    Min            26.96                 2.00           0.00000
21Feb12_105803|    Std             2.69                 4.77           0.15070
21Feb12_105803|   Best            26.96                10.00           0.81836
21Feb12_105803|-- Generation 11 --
21Feb12_105803|    -- Crossed 7 individual pairs.
21Feb12_105803|    -- Mutated 32 individuals.
21Feb12_110155|    -- Evaluated 64 individuals.
21Feb12_110155|    Summary of generation 11:
21Feb12_110155| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_110155|-----------  ------------------  --------------------  ----------
21Feb12_110155|    Max            42.09                16.00           0.54723
21Feb12_110155|    Avg            41.92                 5.44           0.00904
21Feb12_110155|    Min            37.22                 2.00           0.00000
21Feb12_110155|    Std             0.59                 4.87           0.06782
21Feb12_110155|   Best            37.22                10.00           0.54723
21Feb12_110155|-- Generation 12 --
21Feb12_110155|    -- Crossed 9 individual pairs.
21Feb12_110155|    -- Mutated 32 individuals.
21Feb12_110547|    -- Evaluated 64 individuals.
21Feb12_110547|    Summary of generation 12:
21Feb12_110547| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_110547|-----------  ------------------  --------------------  ----------
21Feb12_110547|    Max            42.09                30.00           0.78394
21Feb12_110547|    Avg            41.56                 4.55           0.02489
21Feb12_110547|    Min            28.17                 2.00           0.00000
21Feb12_110547|    Std             2.25                 5.54           0.13052
21Feb12_110547|   Best            28.17                10.00           0.71630
21Feb12_110547|-- Generation 13 --
21Feb12_110547|    -- Crossed 7 individual pairs.
21Feb12_110547|    -- Mutated 32 individuals.
21Feb12_110939|    -- Evaluated 64 individuals.
21Feb12_110939|    Summary of generation 13:
21Feb12_110939| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_110939|-----------  ------------------  --------------------  ----------
21Feb12_110939|    Max            42.00                24.00           0.81559
21Feb12_110939|    Avg            41.67                 4.59           0.02502
21Feb12_110939|    Min            28.35                 2.00           0.00000
21Feb12_110939|    Std             1.82                 4.80           0.13336
21Feb12_110939|   Best            28.35                10.00           0.71572
21Feb12_110939|-- Generation 14 --
21Feb12_110939|    -- Crossed 7 individual pairs.
21Feb12_110939|    -- Mutated 32 individuals.
21Feb12_111330|    -- Evaluated 64 individuals.
21Feb12_111330|    Summary of generation 14:
21Feb12_111330| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_111330|-----------  ------------------  --------------------  ----------
21Feb12_111330|    Max            47.74                16.00           0.80678
21Feb12_111330|    Avg            42.05                 4.38           0.01847
21Feb12_111330|    Min            40.96                 2.00           0.00000
21Feb12_111330|    Std             0.73                 4.18           0.10605
21Feb12_111330|   Best            40.96                10.00           0.30018
21Feb12_111330|-- Generation 15 --
21Feb12_111330|    -- Crossed 4 individual pairs.
21Feb12_111330|    -- Mutated 32 individuals.
21Feb12_111721|    -- Evaluated 64 individuals.
21Feb12_111721|    Summary of generation 15:
21Feb12_111721| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_111721|-----------  ------------------  --------------------  ----------
21Feb12_111721|    Max            42.17                14.00           0.67349
21Feb12_111721|    Avg            41.70                 4.58           0.02106
21Feb12_111721|    Min            29.30                 2.00           0.00000
21Feb12_111721|    Std             1.62                 3.87           0.10554
21Feb12_111721|   Best            29.30                10.00           0.53477
21Feb12_111721|-- Generation 16 --
21Feb12_111721|    -- Crossed 2 individual pairs.
21Feb12_111721|    -- Mutated 32 individuals.
21Feb12_112112|    -- Evaluated 64 individuals.
21Feb12_112112|    Summary of generation 16:
21Feb12_112112| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_112112|-----------  ------------------  --------------------  ----------
21Feb12_112112|    Max            42.09                27.00           0.72600
21Feb12_112112|    Avg            41.52                 5.11           0.02401
21Feb12_112112|    Min            28.17                 2.00           0.00000
21Feb12_112112|    Std             2.39                 4.98           0.11998
21Feb12_112112|   Best            28.17                27.00           0.65543
21Feb12_112112|-- Generation 17 --
21Feb12_112112|    -- Crossed 3 individual pairs.
21Feb12_112112|    -- Mutated 32 individuals.
21Feb12_112502|    -- Evaluated 64 individuals.
21Feb12_112502|    Summary of generation 17:
21Feb12_112502| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_112502|-----------  ------------------  --------------------  ----------
21Feb12_112502|    Max            42.26                30.00           0.73132
21Feb12_112502|    Avg            41.73                 6.33           0.01425
21Feb12_112502|    Min            28.78                 2.00           0.00000
21Feb12_112502|    Std             1.64                 7.03           0.09044
21Feb12_112502|   Best            28.78                10.00           0.73132
21Feb12_112502|-- Generation 18 --
21Feb12_112502|    -- Crossed 3 individual pairs.
21Feb12_112502|    -- Mutated 32 individuals.
21Feb12_112852|    -- Evaluated 64 individuals.
21Feb12_112852|    Summary of generation 18:
21Feb12_112852| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_112852|-----------  ------------------  --------------------  ----------
21Feb12_112852|    Max            42.17                30.00           0.01805
21Feb12_112852|    Avg            41.93                 5.98           0.00323
21Feb12_112852|    Min            41.39                 2.00           0.00000
21Feb12_112852|    Std             0.17                 5.88           0.00514
21Feb12_112852|   Best            41.39                 2.00           0.01805
21Feb12_112852|-- Generation 19 --
21Feb12_112852|    -- Crossed 6 individual pairs.
21Feb12_112852|    -- Mutated 32 individuals.
21Feb12_113243|    -- Evaluated 64 individuals.
21Feb12_113243|    Summary of generation 19:
21Feb12_113243| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_113243|-----------  ------------------  --------------------  ----------
21Feb12_113243|    Max            42.17                27.00           0.02059
21Feb12_113243|    Avg            41.92                 6.02           0.00363
21Feb12_113243|    Min            41.39                 2.00           0.00000
21Feb12_113243|    Std             0.15                 5.73           0.00466
21Feb12_113243|   Best            41.39                 2.00           0.01805
21Feb12_113243|-- Generation 20 --
21Feb12_113243|    -- Crossed 3 individual pairs.
21Feb12_113243|    -- Mutated 32 individuals.
21Feb12_113634|    -- Evaluated 64 individuals.
21Feb12_113634|    Summary of generation 20:
21Feb12_113634| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_113634|-----------  ------------------  --------------------  ----------
21Feb12_113634|    Max            42.09                27.00           0.02060
21Feb12_113634|    Avg            41.91                 6.94           0.00363
21Feb12_113634|    Min            41.39                 2.00           0.00000
21Feb12_113634|    Std             0.15                 5.67           0.00439
21Feb12_113634|   Best            41.39                 2.00           0.01805
21Feb12_113634|-- Generation 21 --
21Feb12_113634|    -- Crossed 3 individual pairs.
21Feb12_113634|    -- Mutated 32 individuals.
21Feb12_114025|    -- Evaluated 64 individuals.
21Feb12_114025|    Summary of generation 21:
21Feb12_114025| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_114025|-----------  ------------------  --------------------  ----------
21Feb12_114025|    Max            43.48                30.00           0.01805
21Feb12_114025|    Avg            41.93                 6.19           0.00379
21Feb12_114025|    Min            41.39                 2.00           0.00000
21Feb12_114025|    Std             0.24                 6.28           0.00405
21Feb12_114025|   Best            41.39                 2.00           0.01805
21Feb12_114025|-- Generation 22 --
21Feb12_114025|    -- Crossed 6 individual pairs.
21Feb12_114025|    -- Mutated 32 individuals.
21Feb12_114415|    -- Evaluated 64 individuals.
21Feb12_114415|    Summary of generation 22:
21Feb12_114415| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_114415|-----------  ------------------  --------------------  ----------
21Feb12_114415|    Max            42.09                27.00           0.02062
21Feb12_114415|    Avg            41.88                 5.02           0.00416
21Feb12_114415|    Min            41.30                 2.00           0.00000
21Feb12_114415|    Std             0.16                 4.67           0.00500
21Feb12_114415|   Best            41.30                 3.00           0.02062
21Feb12_114415|-- Generation 23 --
21Feb12_114415|    -- Crossed 6 individual pairs.
21Feb12_114415|    -- Mutated 32 individuals.
21Feb12_114807|    -- Evaluated 64 individuals.
21Feb12_114807|    Summary of generation 23:
21Feb12_114807| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_114807|-----------  ------------------  --------------------  ----------
21Feb12_114807|    Max            43.13                16.00           0.02317
21Feb12_114807|    Avg            41.93                 6.14           0.00359
21Feb12_114807|    Min            41.30                 2.00           0.00000
21Feb12_114807|    Std             0.19                 4.52           0.00380
21Feb12_114807|   Best            41.30                 3.00           0.02317
21Feb12_114807|-- Generation 24 --
21Feb12_114807|    -- Crossed 4 individual pairs.
21Feb12_114807|    -- Mutated 32 individuals.
21Feb12_115158|    -- Evaluated 64 individuals.
21Feb12_115158|    Summary of generation 24:
21Feb12_115158| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_115158|-----------  ------------------  --------------------  ----------
21Feb12_115158|    Max            42.26                27.00           0.05333
21Feb12_115158|    Avg            41.90                 6.81           0.00467
21Feb12_115158|    Min            41.48                 2.00           0.00000
21Feb12_115158|    Std             0.14                 5.58           0.00725
21Feb12_115158|   Best            41.48                 3.00           0.01804
21Feb12_115158|-- Generation 25 --
21Feb12_115158|    -- Crossed 4 individual pairs.
21Feb12_115158|    -- Mutated 32 individuals.
21Feb12_115551|    -- Evaluated 64 individuals.
21Feb12_115551|    Summary of generation 25:
21Feb12_115551| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_115551|-----------  ------------------  --------------------  ----------
21Feb12_115551|    Max            42.00                33.00           0.76706
21Feb12_115551|    Avg            41.60                 7.86           0.01570
21Feb12_115551|    Min            23.30                 2.00           0.00000
21Feb12_115551|    Std             2.31                 7.30           0.09474
21Feb12_115551|   Best            23.30                16.00           0.76706
21Feb12_115551|-- Generation 26 --
21Feb12_115551|    -- Crossed 4 individual pairs.
21Feb12_115551|    -- Mutated 32 individuals.
21Feb12_115943|    -- Evaluated 64 individuals.
21Feb12_115943|    Summary of generation 26:
21Feb12_115943| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_115943|-----------  ------------------  --------------------  ----------
21Feb12_115943|    Max            42.17                33.00           0.72142
21Feb12_115943|    Avg            41.71                 7.69           0.01499
21Feb12_115943|    Min            28.78                 2.00           0.00000
21Feb12_115943|    Std             1.63                 7.34           0.08907
21Feb12_115943|   Best            28.78                27.00           0.72142
21Feb12_115943|-- Generation 27 --
21Feb12_115943|    -- Crossed 2 individual pairs.
21Feb12_115943|    -- Mutated 32 individuals.
21Feb12_120334|    -- Evaluated 64 individuals.
21Feb12_120334|    Summary of generation 27:
21Feb12_120334| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_120334|-----------  ------------------  --------------------  ----------
21Feb12_120334|    Max            42.17                52.00           0.77703
21Feb12_120334|    Avg            41.37                 7.88           0.02772
21Feb12_120334|    Min            24.78                 2.00           0.00000
21Feb12_120334|    Std             2.92                 8.69           0.13166
21Feb12_120334|   Best            24.78                24.00           0.77703
21Feb12_120334|-- Generation 28 --
21Feb12_120334|    -- Crossed 6 individual pairs.
21Feb12_120334|    -- Mutated 32 individuals.
21Feb12_120728|    -- Evaluated 64 individuals.
21Feb12_120728|    Summary of generation 28:
21Feb12_120728| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_120728|-----------  ------------------  --------------------  ----------
21Feb12_120728|    Max            42.09                30.00           0.75684
21Feb12_120728|    Avg            41.00                 9.20           0.04287
21Feb12_120728|    Min            23.13                 2.00           0.00000
21Feb12_120728|    Std             3.69                 8.61           0.15240
21Feb12_120728|   Best            23.13                24.00           0.71131
21Feb12_120728|-- Generation 29 --
21Feb12_120728|    -- Crossed 7 individual pairs.
21Feb12_120728|    -- Mutated 32 individuals.
21Feb12_121121|    -- Evaluated 64 individuals.
21Feb12_121121|    Summary of generation 29:
21Feb12_121121| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_121121|-----------  ------------------  --------------------  ----------
21Feb12_121121|    Max            42.09                30.00           0.80958
21Feb12_121121|    Avg            40.64                 9.44           0.07227
21Feb12_121121|    Min            24.70                 2.00           0.00000
21Feb12_121121|    Std             4.03                 8.36           0.21307
21Feb12_121121|   Best            24.70                24.00           0.74666
21Feb12_121121|-- Generation 30 --
21Feb12_121121|    -- Crossed 6 individual pairs.
21Feb12_121121|    -- Mutated 32 individuals.
21Feb12_121516|    -- Evaluated 64 individuals.
21Feb12_121516|    Summary of generation 30:
21Feb12_121516| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_121516|-----------  ------------------  --------------------  ----------
21Feb12_121516|    Max            42.00                33.00           0.83995
21Feb12_121516|    Avg            40.83                10.44           0.05825
21Feb12_121516|    Min            26.52                 2.00           0.00000
21Feb12_121516|    Std             3.63                 8.82           0.18182
21Feb12_121516|   Best            26.52                24.00           0.60828
21Feb12_121516|-- Generation 31 --
21Feb12_121516|    -- Crossed 5 individual pairs.
21Feb12_121516|    -- Mutated 32 individuals.
21Feb12_121912|    -- Evaluated 64 individuals.
21Feb12_121912|    Summary of generation 31:
21Feb12_121912| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_121912|-----------  ------------------  --------------------  ----------
21Feb12_121912|    Max            42.09                56.00           0.83645
21Feb12_121912|    Avg            40.33                11.91           0.07410
21Feb12_121912|    Min            21.83                 2.00           0.00000
21Feb12_121912|    Std             4.90                11.48           0.21932
21Feb12_121912|   Best            21.83                56.00           0.77516
21Feb12_121912|-- Generation 32 --
21Feb12_121912|    -- Crossed 7 individual pairs.
21Feb12_121912|    -- Mutated 32 individuals.
21Feb12_122307|    -- Evaluated 64 individuals.
21Feb12_122307|    Summary of generation 32:
21Feb12_122307| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_122307|-----------  ------------------  --------------------  ----------
21Feb12_122307|    Max            42.09                56.00           0.80554
21Feb12_122307|    Avg            40.25                11.73           0.07277
21Feb12_122307|    Min            20.70                 2.00           0.00000
21Feb12_122307|    Std             5.12                11.62           0.21493
21Feb12_122307|   Best            20.70                33.00           0.80554
21Feb12_122307|Best initial individual weights
21Feb12_122307|Individual:
21Feb12_122307|-- Constant hidden layers --
21Feb12_122307|False
21Feb12_122307|Layer 0:
21Feb12_122307|-- Config --
21Feb12_122307|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122307|-- Weights --
21Feb12_122307|[[-0.27202 -0.86357 -0.55480 -0.23305 -0.86065  0.00935]
21Feb12_122307| [ 0.79962  0.37670  0.29685  0.27749  0.49011 -0.69201]
21Feb12_122307| [ 0.14479  0.91685 -0.48781  0.43998  0.63560 -0.30697]
21Feb12_122307| [ 0.38698  0.86287 -0.71294  0.64752 -0.03047 -0.77785]
21Feb12_122307| [ 0.48209  0.66076  0.64751  0.81042 -0.07483  0.42515]
21Feb12_122307| [ 0.55955 -0.47655 -0.07712 -0.63479 -0.35794  0.52636]
21Feb12_122307| [ 0.38576  0.23223  0.25353  0.73450 -0.90178 -0.96369]
21Feb12_122307| [ 0.11039  0.36714  0.33686  0.01774  0.45868  0.81669]
21Feb12_122307| [-0.79637  0.26224 -0.03232  0.48232 -0.15309  0.61156]
21Feb12_122307| [-0.88621  0.90413  0.87744 -0.64355 -0.40369 -0.97981]
21Feb12_122307| [-0.68940  0.06179 -0.18424  0.08150 -0.45878  0.41370]
21Feb12_122307| [-0.36044 -0.13559  0.65226 -0.07204  0.54308  0.16062]
21Feb12_122307| [ 0.11714  0.93671 -0.29633  0.99754  0.45369 -0.70753]
21Feb12_122307| [ 0.64728 -0.33413 -0.57208 -0.73568  0.75425 -0.55104]
21Feb12_122307| [-0.99999 -0.96058  0.33387  0.28233 -0.17633  0.03884]
21Feb12_122307| [-0.31698 -0.57029  0.10048  0.21559 -0.52309  0.33687]
21Feb12_122307| [ 0.61192 -0.96178 -0.06414 -0.36741  0.15685  0.02906]
21Feb12_122307| [-0.75997 -0.73378  0.49810  0.83880 -0.83756 -0.54574]
21Feb12_122307| [ 0.84699 -0.24948  0.54050  0.73535 -0.06642 -0.14727]
21Feb12_122307| [-0.94868 -0.55371 -0.60216  0.40726 -0.98034 -0.48830]
21Feb12_122307| [ 0.83709 -0.79262  0.03398 -0.48243 -0.43785 -0.35972]
21Feb12_122307| [-0.44328  0.52441 -0.25583  0.35182 -0.83091 -0.39106]
21Feb12_122307| [-0.15833  0.20269  0.54130 -0.37920  0.09680  0.17172]
21Feb12_122307| [ 0.39523 -0.09539 -0.94133 -0.81601 -0.29414  0.09808]
21Feb12_122307| [ 0.86566 -0.82514  0.72303  0.62921 -0.61237  0.81126]
21Feb12_122307| [ 0.76870  0.06416 -0.11886 -0.75631 -0.12365 -0.72666]
21Feb12_122307| [ 0.89288  0.41306 -0.54112  0.04405 -0.79963  0.73224]
21Feb12_122307| [ 0.93553  0.89126 -0.61857  0.87545 -0.23947  0.75701]
21Feb12_122307| [-0.82086  0.81521  0.86256 -0.74272 -0.12443 -0.22844]
21Feb12_122307| [ 0.97160  0.41439 -0.41378 -0.28541  0.97440  0.41257]
21Feb12_122307| [ 0.70964  0.93589  0.10477  0.43589 -0.53252 -0.32168]
21Feb12_122307| [ 0.78787 -0.33435  0.99010 -0.65538  0.82368  0.49009]
21Feb12_122307| [ 0.22751  0.13008 -0.77326 -0.52830  0.50907  0.36905]
21Feb12_122307| [-0.27162 -0.36135  0.67608 -0.27532  0.90150  0.01127]
21Feb12_122307| [ 0.32844  0.99962 -0.09280  0.45964  0.99188 -0.46898]
21Feb12_122307| [-0.18508  0.43122 -0.20933  0.22437 -0.38523 -0.93105]
21Feb12_122307| [-0.71925  0.06113  0.19689 -0.43143 -0.18550 -0.84294]
21Feb12_122307| [-0.26779 -0.36079  0.46561  0.91330  0.52255 -0.08778]
21Feb12_122307| [-0.77037  0.39767  0.64833 -0.98560  0.46858  0.31212]
21Feb12_122307| [-0.85160 -0.84100 -0.57533 -0.89125 -0.26714 -0.03784]
21Feb12_122307| [-0.45978 -0.09001 -0.25873 -0.50100  0.50007  0.36246]
21Feb12_122307| [ 0.24085  0.09905  0.63589  0.41544  0.94690 -0.17740]
21Feb12_122307| [ 0.37276 -0.55653  0.03085 -0.57053  0.64921  0.77760]
21Feb12_122307| [-0.15149  0.70665 -0.89632  0.21282 -0.46831 -0.02174]
21Feb12_122307| [-0.90518 -0.77970  0.95331  0.59768  0.52171 -0.16887]
21Feb12_122307| [-0.91831  0.02967 -0.06979  0.13512 -0.23631 -0.64488]
21Feb12_122307| [ 0.97479 -0.94377  0.06324  0.51263  0.92015  0.33195]
21Feb12_122307| [-0.23392  0.17446 -0.00269  0.39550  0.16762  0.49246]
21Feb12_122307| [-0.38197 -0.12955 -0.15881  0.40103 -0.44224  0.28044]
21Feb12_122307| [-0.18428 -0.43672  0.17268 -0.61813  0.37910  0.10582]
21Feb12_122307| [-0.90436 -0.34919  0.78535  0.66625 -0.73042 -0.71018]
21Feb12_122307| [ 0.51032 -0.77746 -0.44325  0.84430 -0.30217 -0.29958]
21Feb12_122307| [ 0.68940  0.61874 -0.16478 -0.15758 -0.13000  0.90632]
21Feb12_122307| [ 0.03548 -0.47831  0.42708 -0.16343 -0.95208  0.69563]
21Feb12_122307| [-0.01411  0.20035  0.12539 -0.96161  0.92710 -0.77067]
21Feb12_122307| [ 0.81703  0.44147  0.72058 -0.81223 -0.67418 -0.85267]
21Feb12_122307| [-0.26530  0.72399 -0.58999 -0.15740  0.39892 -0.58918]]
21Feb12_122307|-- Bias --
21Feb12_122307|[ 0.23050  0.64820 -0.64277 -0.41900 -0.54681  0.15437]
21Feb12_122307|Layer 1:
21Feb12_122307|-- Config --
21Feb12_122307|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 7, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122307|-- Weights --
21Feb12_122307|[[-0.50321 -0.80875 -0.60144 -0.65045  0.61886 -0.77767  0.32772]
21Feb12_122307| [-0.04845 -0.89529  0.64487 -0.62765 -0.63134  0.05243 -0.44669]
21Feb12_122307| [-0.43718  0.21711  0.81639 -0.51368 -0.99854 -0.22537  0.94769]
21Feb12_122307| [-0.24806 -0.09443  0.39011  0.48081 -0.14372 -0.70297 -0.89667]
21Feb12_122307| [ 0.70687  0.42155  0.18340 -0.17501  0.52040  0.16771  0.10606]
21Feb12_122307| [ 0.44794  0.33101  0.53886 -0.17021  0.78118 -0.81555  0.43746]]
21Feb12_122307|-- Bias --
21Feb12_122307|[-0.73477  0.09614 -0.39402 -0.10087  0.57570 -0.12327  0.59815]
21Feb12_122307|Layer 2:
21Feb12_122307|-- Config --
21Feb12_122307|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 7], 'dtype': 'float32', 'units': 10, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122307|-- Weights --
21Feb12_122307|[[ 0.31908 -0.68092  0.42155  0.77600 -0.73710 -0.39887 -0.07843  0.23743
21Feb12_122307|   0.15714 -0.76581]
21Feb12_122307| [ 0.86369 -0.12993 -0.24148  0.53900  0.76709  0.96250 -0.56779 -0.90161
21Feb12_122307|  -0.05478 -0.07884]
21Feb12_122307| [ 0.55244  0.08052  0.06876 -0.21762  0.03301  0.12657 -0.10267 -0.45140
21Feb12_122307|   0.74279 -0.68060]
21Feb12_122307| [-0.82927  0.38658 -0.24283 -0.60293  0.98747 -0.55144  0.76581  0.09305
21Feb12_122307|   0.25851  0.32179]
21Feb12_122307| [ 0.50403 -0.55046  0.84432 -0.88204 -0.35981  0.51384 -0.70348  0.60683
21Feb12_122307|  -0.43326  0.96808]
21Feb12_122307| [-0.55850  0.68494  0.22628  0.92543 -0.20070  0.79557  0.78836  0.80610
21Feb12_122307|   0.78859 -0.65676]
21Feb12_122307| [-0.65413 -0.45252 -0.64423  0.93837  0.67689 -0.63509 -0.98556 -0.70209
21Feb12_122307|   0.15696  0.38727]]
21Feb12_122307|-- Bias --
21Feb12_122307|[ 0.74117  0.06232 -0.97740  0.25194  0.96653  0.46481  0.25293  0.37737
21Feb12_122307| -0.98026 -0.39274]
21Feb12_122307|Layer 3:
21Feb12_122307|-- Config --
21Feb12_122307|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 10], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122307|-- Weights --
21Feb12_122307|[[ 0.00457 -0.86221]
21Feb12_122307| [ 0.78832  0.80619]
21Feb12_122307| [ 0.15057 -0.18753]
21Feb12_122307| [ 0.89929 -0.85656]
21Feb12_122307| [ 0.75527  0.29249]
21Feb12_122307| [-0.45525  0.95025]
21Feb12_122307| [ 0.35702  0.60776]
21Feb12_122307| [ 0.11856 -0.18745]
21Feb12_122307| [-0.97968 -0.74320]
21Feb12_122307| [-0.86733  0.80774]]
21Feb12_122307|-- Bias --
21Feb12_122307|[ 0.82786 -0.37827]
21Feb12_122307|Predicting the validation and test data with the Best initial individual.
21Feb12_122314| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_122314|-----------  ------------------  --------------------  ----------
21Feb12_122314|Validation         42.00                  69            0.00000
21Feb12_122314|   Test            36.40                  69            0.00000
21Feb12_122314|-------------------- Test #0 --------------------
21Feb12_122314|Best final individual weights
21Feb12_122314|Individual:
21Feb12_122314|-- Constant hidden layers --
21Feb12_122314|False
21Feb12_122314|Layer 0:
21Feb12_122314|-- Config --
21Feb12_122314|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122314|-- Weights --
21Feb12_122314|[[-2.04393  0.94448]
21Feb12_122314| [ 0.11948  0.70709]
21Feb12_122314| [ 1.25419  0.09249]
21Feb12_122314| [ 1.30503 -0.61550]
21Feb12_122314| [-0.60509  0.24396]
21Feb12_122314| [ 1.12806 -0.70806]
21Feb12_122314| [ 1.44704 -0.48686]
21Feb12_122314| [-0.27510  2.36693]
21Feb12_122314| [ 1.03325 -1.38632]
21Feb12_122314| [ 0.75283 -0.37118]
21Feb12_122314| [-1.37344 -2.38437]
21Feb12_122314| [ 0.29599 -2.82818]
21Feb12_122314| [-0.08697 -0.51462]
21Feb12_122314| [ 0.22779 -0.03188]
21Feb12_122314| [ 1.10192  0.34059]
21Feb12_122314| [ 0.00737 -1.13053]
21Feb12_122314| [-0.38697 -0.78166]
21Feb12_122314| [ 1.11279 -0.70794]
21Feb12_122314| [-1.57859  0.13758]
21Feb12_122314| [ 0.57509  1.71894]
21Feb12_122314| [-0.22878 -0.16188]
21Feb12_122314| [ 0.02918 -0.37772]
21Feb12_122314| [ 0.48940 -0.96049]
21Feb12_122314| [ 0.70215  0.28465]
21Feb12_122314| [-0.13129  0.68326]
21Feb12_122314| [-1.52609  0.60254]
21Feb12_122314| [-1.29880  0.49477]
21Feb12_122314| [-1.07047  0.74063]
21Feb12_122314| [ 1.73937  0.57457]
21Feb12_122314| [ 0.47201 -0.06445]
21Feb12_122314| [-0.35947 -0.63247]
21Feb12_122314| [-1.27315 -0.85671]
21Feb12_122314| [-1.77157 -0.04656]
21Feb12_122314| [-0.36294  0.69560]
21Feb12_122314| [-1.29108  1.39541]
21Feb12_122314| [ 0.29550 -1.02032]
21Feb12_122314| [ 0.73382  0.17714]
21Feb12_122314| [ 0.36856  0.70171]
21Feb12_122314| [-0.61639  1.22436]
21Feb12_122314| [-1.64172 -2.25179]
21Feb12_122314| [ 0.09914  0.44019]
21Feb12_122314| [-1.25653  0.25848]
21Feb12_122314| [-0.54212  0.01596]
21Feb12_122314| [-1.34511  0.02169]
21Feb12_122314| [-0.16047 -1.27696]
21Feb12_122314| [-0.80058 -0.48952]
21Feb12_122314| [-0.95582  0.95487]
21Feb12_122314| [ 1.78352  0.09199]
21Feb12_122314| [ 1.37699  0.47338]
21Feb12_122314| [-0.61417 -2.56181]
21Feb12_122314| [-0.93012  1.04286]
21Feb12_122314| [ 1.35669  0.00900]
21Feb12_122314| [ 1.14910  1.09033]
21Feb12_122314| [-0.27953 -0.04201]
21Feb12_122314| [ 0.25632  0.02874]
21Feb12_122314| [ 1.23722  0.82313]
21Feb12_122314| [-0.48085 -0.49832]]
21Feb12_122314|-- Bias --
21Feb12_122314|[ 0.47675 -0.76660]
21Feb12_122314|Layer 1:
21Feb12_122314|-- Config --
21Feb12_122314|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122314|-- Weights --
21Feb12_122314|[[ 0.82049 -0.64190  0.15905  0.29356]
21Feb12_122314| [ 1.28383 -1.58235 -0.26631 -0.46335]]
21Feb12_122314|-- Bias --
21Feb12_122314|[ 0.02519 -0.46145  0.26882 -0.17956]
21Feb12_122314|Layer 2:
21Feb12_122314|-- Config --
21Feb12_122314|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122314|-- Weights --
21Feb12_122314|[[ 0.12590 -1.10838 -0.22227 -0.11569  0.19880]
21Feb12_122314| [ 0.02297  0.49371 -0.09440  0.49582 -0.82915]
21Feb12_122314| [ 0.14673 -0.43178  0.32269 -0.30475  0.51259]
21Feb12_122314| [ 0.25636 -0.34216 -0.13513  0.13946  0.30263]]
21Feb12_122314|-- Bias --
21Feb12_122314|[-0.85246 -0.21497  0.14004 -0.81699  0.14464]
21Feb12_122314|Layer 3:
21Feb12_122314|-- Config --
21Feb12_122314|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122314|-- Weights --
21Feb12_122314|[[-1.95210 -1.00039]
21Feb12_122314| [ 0.89031 -1.13606]
21Feb12_122314| [ 1.00561 -0.84721]
21Feb12_122314| [-0.98758  0.54903]
21Feb12_122314| [ 0.17707  0.27421]]
21Feb12_122314|-- Bias --
21Feb12_122314|[-0.58068  0.83748]
21Feb12_122314|Predicting the validation and test data with the Best final individual.
21Feb12_122322| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_122322|-----------  ------------------  --------------------  ----------
21Feb12_122322|Validation         24.70                  33            0.85828
21Feb12_122322|   Test            36.49                  33            0.00000
21Feb12_122322|-------------------- Test #1 --------------------
21Feb12_122322|Best final individual weights
21Feb12_122322|Individual:
21Feb12_122322|-- Constant hidden layers --
21Feb12_122322|False
21Feb12_122322|Layer 0:
21Feb12_122322|-- Config --
21Feb12_122322|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122322|-- Weights --
21Feb12_122322|[[-2.04393  0.94448]
21Feb12_122322| [ 0.11948  0.70709]
21Feb12_122322| [ 1.25419  0.09249]
21Feb12_122322| [ 1.30503 -0.61550]
21Feb12_122322| [-0.60509  0.24396]
21Feb12_122322| [ 1.12806 -0.70806]
21Feb12_122322| [ 1.44704 -0.48686]
21Feb12_122322| [-0.27510  2.36693]
21Feb12_122322| [ 1.03325 -1.38632]
21Feb12_122322| [ 0.75283 -0.37118]
21Feb12_122322| [-1.37344 -2.38437]
21Feb12_122322| [ 0.29599 -2.82818]
21Feb12_122322| [-0.08697 -0.51462]
21Feb12_122322| [ 0.22779 -0.03188]
21Feb12_122322| [ 1.10192  0.34059]
21Feb12_122322| [ 0.00737 -1.13053]
21Feb12_122322| [-0.38697 -0.78166]
21Feb12_122322| [ 1.11279 -0.70794]
21Feb12_122322| [-1.57859  0.13758]
21Feb12_122322| [ 0.57509  1.71894]
21Feb12_122322| [-0.22878 -0.16188]
21Feb12_122322| [ 0.02918 -0.37772]
21Feb12_122322| [ 0.48940 -0.96049]
21Feb12_122322| [ 0.70215  0.28465]
21Feb12_122322| [-0.13129  0.68326]
21Feb12_122322| [-1.52609  0.60254]
21Feb12_122322| [-1.29880  0.49477]
21Feb12_122322| [-1.07047  0.74063]
21Feb12_122322| [ 1.73937  0.57457]
21Feb12_122322| [ 0.47201 -0.06445]
21Feb12_122322| [-0.35947 -0.63247]
21Feb12_122322| [-1.27315 -0.85671]
21Feb12_122322| [-1.77157 -0.04656]
21Feb12_122322| [-0.36294  0.69560]
21Feb12_122322| [-1.29108  1.39541]
21Feb12_122322| [ 0.29550 -1.02032]
21Feb12_122322| [ 0.73382  0.17714]
21Feb12_122322| [ 0.36856  0.70171]
21Feb12_122322| [-0.61639  1.22436]
21Feb12_122322| [-1.64172 -2.25179]
21Feb12_122322| [ 0.09914  0.44019]
21Feb12_122322| [-1.25653  0.25848]
21Feb12_122322| [-0.54212  0.01596]
21Feb12_122322| [-1.34511  0.02169]
21Feb12_122322| [-0.16047 -1.27696]
21Feb12_122322| [-0.80058 -0.48952]
21Feb12_122322| [-0.95582  0.95487]
21Feb12_122322| [ 1.78352  0.09199]
21Feb12_122322| [ 1.37699  0.47338]
21Feb12_122322| [-0.61417 -2.56181]
21Feb12_122322| [-0.93012  1.04286]
21Feb12_122322| [ 1.35669  0.00900]
21Feb12_122322| [ 1.14910  1.09033]
21Feb12_122322| [-0.27953 -0.04201]
21Feb12_122322| [ 0.25632  0.02874]
21Feb12_122322| [ 1.23722  0.82313]
21Feb12_122322| [-0.48085 -0.49832]]
21Feb12_122322|-- Bias --
21Feb12_122322|[ 0.47675 -0.76660]
21Feb12_122322|Layer 1:
21Feb12_122322|-- Config --
21Feb12_122322|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122322|-- Weights --
21Feb12_122322|[[ 0.82049 -0.64190  0.15905  0.29356]
21Feb12_122322| [ 1.28383 -1.58235 -0.26631 -0.46335]]
21Feb12_122322|-- Bias --
21Feb12_122322|[ 0.02519 -0.46145  0.26882 -0.17956]
21Feb12_122322|Layer 2:
21Feb12_122322|-- Config --
21Feb12_122322|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122322|-- Weights --
21Feb12_122322|[[ 0.12590 -1.10838 -0.22227 -0.11569  0.19880]
21Feb12_122322| [ 0.02297  0.49371 -0.09440  0.49582 -0.82915]
21Feb12_122322| [ 0.14673 -0.43178  0.32269 -0.30475  0.51259]
21Feb12_122322| [ 0.25636 -0.34216 -0.13513  0.13946  0.30263]]
21Feb12_122322|-- Bias --
21Feb12_122322|[-0.85246 -0.21497  0.14004 -0.81699  0.14464]
21Feb12_122322|Layer 3:
21Feb12_122322|-- Config --
21Feb12_122322|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122322|-- Weights --
21Feb12_122322|[[-1.95210 -1.00039]
21Feb12_122322| [ 0.89031 -1.13606]
21Feb12_122322| [ 1.00561 -0.84721]
21Feb12_122322| [-0.98758  0.54903]
21Feb12_122322| [ 0.17707  0.27421]]
21Feb12_122322|-- Bias --
21Feb12_122322|[-0.58068  0.83748]
21Feb12_122322|Predicting the validation and test data with the Best final individual.
21Feb12_122330| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_122330|-----------  ------------------  --------------------  ----------
21Feb12_122330|Validation         42.00                  33            0.00000
21Feb12_122330|   Test            36.40                  33            0.00000
21Feb12_122330|-------------------- Test #2 --------------------
21Feb12_122330|Best final individual weights
21Feb12_122330|Individual:
21Feb12_122330|-- Constant hidden layers --
21Feb12_122330|False
21Feb12_122330|Layer 0:
21Feb12_122330|-- Config --
21Feb12_122330|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122330|-- Weights --
21Feb12_122330|[[-2.04393  0.94448]
21Feb12_122330| [ 0.11948  0.70709]
21Feb12_122330| [ 1.25419  0.09249]
21Feb12_122330| [ 1.30503 -0.61550]
21Feb12_122330| [-0.60509  0.24396]
21Feb12_122330| [ 1.12806 -0.70806]
21Feb12_122330| [ 1.44704 -0.48686]
21Feb12_122330| [-0.27510  2.36693]
21Feb12_122330| [ 1.03325 -1.38632]
21Feb12_122330| [ 0.75283 -0.37118]
21Feb12_122330| [-1.37344 -2.38437]
21Feb12_122330| [ 0.29599 -2.82818]
21Feb12_122330| [-0.08697 -0.51462]
21Feb12_122330| [ 0.22779 -0.03188]
21Feb12_122330| [ 1.10192  0.34059]
21Feb12_122330| [ 0.00737 -1.13053]
21Feb12_122330| [-0.38697 -0.78166]
21Feb12_122330| [ 1.11279 -0.70794]
21Feb12_122330| [-1.57859  0.13758]
21Feb12_122330| [ 0.57509  1.71894]
21Feb12_122330| [-0.22878 -0.16188]
21Feb12_122330| [ 0.02918 -0.37772]
21Feb12_122330| [ 0.48940 -0.96049]
21Feb12_122330| [ 0.70215  0.28465]
21Feb12_122330| [-0.13129  0.68326]
21Feb12_122330| [-1.52609  0.60254]
21Feb12_122330| [-1.29880  0.49477]
21Feb12_122330| [-1.07047  0.74063]
21Feb12_122330| [ 1.73937  0.57457]
21Feb12_122330| [ 0.47201 -0.06445]
21Feb12_122330| [-0.35947 -0.63247]
21Feb12_122330| [-1.27315 -0.85671]
21Feb12_122330| [-1.77157 -0.04656]
21Feb12_122330| [-0.36294  0.69560]
21Feb12_122330| [-1.29108  1.39541]
21Feb12_122330| [ 0.29550 -1.02032]
21Feb12_122330| [ 0.73382  0.17714]
21Feb12_122330| [ 0.36856  0.70171]
21Feb12_122330| [-0.61639  1.22436]
21Feb12_122330| [-1.64172 -2.25179]
21Feb12_122330| [ 0.09914  0.44019]
21Feb12_122330| [-1.25653  0.25848]
21Feb12_122330| [-0.54212  0.01596]
21Feb12_122330| [-1.34511  0.02169]
21Feb12_122330| [-0.16047 -1.27696]
21Feb12_122330| [-0.80058 -0.48952]
21Feb12_122330| [-0.95582  0.95487]
21Feb12_122330| [ 1.78352  0.09199]
21Feb12_122330| [ 1.37699  0.47338]
21Feb12_122330| [-0.61417 -2.56181]
21Feb12_122330| [-0.93012  1.04286]
21Feb12_122330| [ 1.35669  0.00900]
21Feb12_122330| [ 1.14910  1.09033]
21Feb12_122330| [-0.27953 -0.04201]
21Feb12_122330| [ 0.25632  0.02874]
21Feb12_122330| [ 1.23722  0.82313]
21Feb12_122330| [-0.48085 -0.49832]]
21Feb12_122330|-- Bias --
21Feb12_122330|[ 0.47675 -0.76660]
21Feb12_122330|Layer 1:
21Feb12_122330|-- Config --
21Feb12_122330|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122330|-- Weights --
21Feb12_122330|[[ 0.82049 -0.64190  0.15905  0.29356]
21Feb12_122330| [ 1.28383 -1.58235 -0.26631 -0.46335]]
21Feb12_122330|-- Bias --
21Feb12_122330|[ 0.02519 -0.46145  0.26882 -0.17956]
21Feb12_122330|Layer 2:
21Feb12_122330|-- Config --
21Feb12_122330|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122330|-- Weights --
21Feb12_122330|[[ 0.12590 -1.10838 -0.22227 -0.11569  0.19880]
21Feb12_122330| [ 0.02297  0.49371 -0.09440  0.49582 -0.82915]
21Feb12_122330| [ 0.14673 -0.43178  0.32269 -0.30475  0.51259]
21Feb12_122330| [ 0.25636 -0.34216 -0.13513  0.13946  0.30263]]
21Feb12_122330|-- Bias --
21Feb12_122330|[-0.85246 -0.21497  0.14004 -0.81699  0.14464]
21Feb12_122330|Layer 3:
21Feb12_122330|-- Config --
21Feb12_122330|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122330|-- Weights --
21Feb12_122330|[[-1.95210 -1.00039]
21Feb12_122330| [ 0.89031 -1.13606]
21Feb12_122330| [ 1.00561 -0.84721]
21Feb12_122330| [-0.98758  0.54903]
21Feb12_122330| [ 0.17707  0.27421]]
21Feb12_122330|-- Bias --
21Feb12_122330|[-0.58068  0.83748]
21Feb12_122330|Predicting the validation and test data with the Best final individual.
21Feb12_122338| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_122338|-----------  ------------------  --------------------  ----------
21Feb12_122338|Validation         22.09                  33            0.70283
21Feb12_122338|   Test            24.85                  33            0.76785
21Feb12_122338|-------------------- Test #3 --------------------
21Feb12_122338|Best final individual weights
21Feb12_122338|Individual:
21Feb12_122338|-- Constant hidden layers --
21Feb12_122338|False
21Feb12_122338|Layer 0:
21Feb12_122338|-- Config --
21Feb12_122338|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122338|-- Weights --
21Feb12_122338|[[-2.04393  0.94448]
21Feb12_122338| [ 0.11948  0.70709]
21Feb12_122338| [ 1.25419  0.09249]
21Feb12_122338| [ 1.30503 -0.61550]
21Feb12_122338| [-0.60509  0.24396]
21Feb12_122338| [ 1.12806 -0.70806]
21Feb12_122338| [ 1.44704 -0.48686]
21Feb12_122338| [-0.27510  2.36693]
21Feb12_122338| [ 1.03325 -1.38632]
21Feb12_122338| [ 0.75283 -0.37118]
21Feb12_122338| [-1.37344 -2.38437]
21Feb12_122338| [ 0.29599 -2.82818]
21Feb12_122338| [-0.08697 -0.51462]
21Feb12_122338| [ 0.22779 -0.03188]
21Feb12_122338| [ 1.10192  0.34059]
21Feb12_122338| [ 0.00737 -1.13053]
21Feb12_122338| [-0.38697 -0.78166]
21Feb12_122338| [ 1.11279 -0.70794]
21Feb12_122338| [-1.57859  0.13758]
21Feb12_122338| [ 0.57509  1.71894]
21Feb12_122338| [-0.22878 -0.16188]
21Feb12_122338| [ 0.02918 -0.37772]
21Feb12_122338| [ 0.48940 -0.96049]
21Feb12_122338| [ 0.70215  0.28465]
21Feb12_122338| [-0.13129  0.68326]
21Feb12_122338| [-1.52609  0.60254]
21Feb12_122338| [-1.29880  0.49477]
21Feb12_122338| [-1.07047  0.74063]
21Feb12_122338| [ 1.73937  0.57457]
21Feb12_122338| [ 0.47201 -0.06445]
21Feb12_122338| [-0.35947 -0.63247]
21Feb12_122338| [-1.27315 -0.85671]
21Feb12_122338| [-1.77157 -0.04656]
21Feb12_122338| [-0.36294  0.69560]
21Feb12_122338| [-1.29108  1.39541]
21Feb12_122338| [ 0.29550 -1.02032]
21Feb12_122338| [ 0.73382  0.17714]
21Feb12_122338| [ 0.36856  0.70171]
21Feb12_122338| [-0.61639  1.22436]
21Feb12_122338| [-1.64172 -2.25179]
21Feb12_122338| [ 0.09914  0.44019]
21Feb12_122338| [-1.25653  0.25848]
21Feb12_122338| [-0.54212  0.01596]
21Feb12_122338| [-1.34511  0.02169]
21Feb12_122338| [-0.16047 -1.27696]
21Feb12_122338| [-0.80058 -0.48952]
21Feb12_122338| [-0.95582  0.95487]
21Feb12_122338| [ 1.78352  0.09199]
21Feb12_122338| [ 1.37699  0.47338]
21Feb12_122338| [-0.61417 -2.56181]
21Feb12_122338| [-0.93012  1.04286]
21Feb12_122338| [ 1.35669  0.00900]
21Feb12_122338| [ 1.14910  1.09033]
21Feb12_122338| [-0.27953 -0.04201]
21Feb12_122338| [ 0.25632  0.02874]
21Feb12_122338| [ 1.23722  0.82313]
21Feb12_122338| [-0.48085 -0.49832]]
21Feb12_122338|-- Bias --
21Feb12_122338|[ 0.47675 -0.76660]
21Feb12_122338|Layer 1:
21Feb12_122338|-- Config --
21Feb12_122338|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122338|-- Weights --
21Feb12_122338|[[ 0.82049 -0.64190  0.15905  0.29356]
21Feb12_122338| [ 1.28383 -1.58235 -0.26631 -0.46335]]
21Feb12_122338|-- Bias --
21Feb12_122338|[ 0.02519 -0.46145  0.26882 -0.17956]
21Feb12_122338|Layer 2:
21Feb12_122338|-- Config --
21Feb12_122338|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122338|-- Weights --
21Feb12_122338|[[ 0.12590 -1.10838 -0.22227 -0.11569  0.19880]
21Feb12_122338| [ 0.02297  0.49371 -0.09440  0.49582 -0.82915]
21Feb12_122338| [ 0.14673 -0.43178  0.32269 -0.30475  0.51259]
21Feb12_122338| [ 0.25636 -0.34216 -0.13513  0.13946  0.30263]]
21Feb12_122338|-- Bias --
21Feb12_122338|[-0.85246 -0.21497  0.14004 -0.81699  0.14464]
21Feb12_122338|Layer 3:
21Feb12_122338|-- Config --
21Feb12_122338|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122338|-- Weights --
21Feb12_122338|[[-1.95210 -1.00039]
21Feb12_122338| [ 0.89031 -1.13606]
21Feb12_122338| [ 1.00561 -0.84721]
21Feb12_122338| [-0.98758  0.54903]
21Feb12_122338| [ 0.17707  0.27421]]
21Feb12_122338|-- Bias --
21Feb12_122338|[-0.58068  0.83748]
21Feb12_122338|Predicting the validation and test data with the Best final individual.
21Feb12_122345| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_122345|-----------  ------------------  --------------------  ----------
21Feb12_122345|Validation         22.52                  33            0.82680
21Feb12_122345|   Test            26.50                  33            0.62079
21Feb12_122345|-------------------- Test #4 --------------------
21Feb12_122345|Best final individual weights
21Feb12_122345|Individual:
21Feb12_122345|-- Constant hidden layers --
21Feb12_122345|False
21Feb12_122345|Layer 0:
21Feb12_122345|-- Config --
21Feb12_122345|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122345|-- Weights --
21Feb12_122345|[[-2.04393  0.94448]
21Feb12_122345| [ 0.11948  0.70709]
21Feb12_122345| [ 1.25419  0.09249]
21Feb12_122345| [ 1.30503 -0.61550]
21Feb12_122345| [-0.60509  0.24396]
21Feb12_122345| [ 1.12806 -0.70806]
21Feb12_122345| [ 1.44704 -0.48686]
21Feb12_122345| [-0.27510  2.36693]
21Feb12_122345| [ 1.03325 -1.38632]
21Feb12_122345| [ 0.75283 -0.37118]
21Feb12_122345| [-1.37344 -2.38437]
21Feb12_122345| [ 0.29599 -2.82818]
21Feb12_122345| [-0.08697 -0.51462]
21Feb12_122345| [ 0.22779 -0.03188]
21Feb12_122345| [ 1.10192  0.34059]
21Feb12_122345| [ 0.00737 -1.13053]
21Feb12_122345| [-0.38697 -0.78166]
21Feb12_122345| [ 1.11279 -0.70794]
21Feb12_122345| [-1.57859  0.13758]
21Feb12_122345| [ 0.57509  1.71894]
21Feb12_122345| [-0.22878 -0.16188]
21Feb12_122345| [ 0.02918 -0.37772]
21Feb12_122345| [ 0.48940 -0.96049]
21Feb12_122345| [ 0.70215  0.28465]
21Feb12_122345| [-0.13129  0.68326]
21Feb12_122345| [-1.52609  0.60254]
21Feb12_122345| [-1.29880  0.49477]
21Feb12_122345| [-1.07047  0.74063]
21Feb12_122345| [ 1.73937  0.57457]
21Feb12_122345| [ 0.47201 -0.06445]
21Feb12_122345| [-0.35947 -0.63247]
21Feb12_122345| [-1.27315 -0.85671]
21Feb12_122345| [-1.77157 -0.04656]
21Feb12_122345| [-0.36294  0.69560]
21Feb12_122345| [-1.29108  1.39541]
21Feb12_122345| [ 0.29550 -1.02032]
21Feb12_122345| [ 0.73382  0.17714]
21Feb12_122345| [ 0.36856  0.70171]
21Feb12_122345| [-0.61639  1.22436]
21Feb12_122345| [-1.64172 -2.25179]
21Feb12_122345| [ 0.09914  0.44019]
21Feb12_122345| [-1.25653  0.25848]
21Feb12_122345| [-0.54212  0.01596]
21Feb12_122345| [-1.34511  0.02169]
21Feb12_122345| [-0.16047 -1.27696]
21Feb12_122345| [-0.80058 -0.48952]
21Feb12_122345| [-0.95582  0.95487]
21Feb12_122345| [ 1.78352  0.09199]
21Feb12_122345| [ 1.37699  0.47338]
21Feb12_122345| [-0.61417 -2.56181]
21Feb12_122345| [-0.93012  1.04286]
21Feb12_122345| [ 1.35669  0.00900]
21Feb12_122345| [ 1.14910  1.09033]
21Feb12_122345| [-0.27953 -0.04201]
21Feb12_122345| [ 0.25632  0.02874]
21Feb12_122345| [ 1.23722  0.82313]
21Feb12_122345| [-0.48085 -0.49832]]
21Feb12_122345|-- Bias --
21Feb12_122345|[ 0.47675 -0.76660]
21Feb12_122345|Layer 1:
21Feb12_122345|-- Config --
21Feb12_122345|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122345|-- Weights --
21Feb12_122345|[[ 0.82049 -0.64190  0.15905  0.29356]
21Feb12_122345| [ 1.28383 -1.58235 -0.26631 -0.46335]]
21Feb12_122345|-- Bias --
21Feb12_122345|[ 0.02519 -0.46145  0.26882 -0.17956]
21Feb12_122345|Layer 2:
21Feb12_122345|-- Config --
21Feb12_122345|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122345|-- Weights --
21Feb12_122345|[[ 0.12590 -1.10838 -0.22227 -0.11569  0.19880]
21Feb12_122345| [ 0.02297  0.49371 -0.09440  0.49582 -0.82915]
21Feb12_122345| [ 0.14673 -0.43178  0.32269 -0.30475  0.51259]
21Feb12_122345| [ 0.25636 -0.34216 -0.13513  0.13946  0.30263]]
21Feb12_122345|-- Bias --
21Feb12_122345|[-0.85246 -0.21497  0.14004 -0.81699  0.14464]
21Feb12_122345|Layer 3:
21Feb12_122345|-- Config --
21Feb12_122345|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122345|-- Weights --
21Feb12_122345|[[-1.95210 -1.00039]
21Feb12_122345| [ 0.89031 -1.13606]
21Feb12_122345| [ 1.00561 -0.84721]
21Feb12_122345| [-0.98758  0.54903]
21Feb12_122345| [ 0.17707  0.27421]]
21Feb12_122345|-- Bias --
21Feb12_122345|[-0.58068  0.83748]
21Feb12_122345|Predicting the validation and test data with the Best final individual.
21Feb12_122353| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_122353|-----------  ------------------  --------------------  ----------
21Feb12_122353|Validation         41.74                  33            0.00775
21Feb12_122353|   Test            36.40                  33            0.00000
21Feb12_122353|-------------------- Test #5 --------------------
21Feb12_122353|Best final individual weights
21Feb12_122353|Individual:
21Feb12_122353|-- Constant hidden layers --
21Feb12_122353|False
21Feb12_122353|Layer 0:
21Feb12_122353|-- Config --
21Feb12_122353|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122353|-- Weights --
21Feb12_122353|[[-2.04393  0.94448]
21Feb12_122353| [ 0.11948  0.70709]
21Feb12_122353| [ 1.25419  0.09249]
21Feb12_122353| [ 1.30503 -0.61550]
21Feb12_122353| [-0.60509  0.24396]
21Feb12_122353| [ 1.12806 -0.70806]
21Feb12_122353| [ 1.44704 -0.48686]
21Feb12_122353| [-0.27510  2.36693]
21Feb12_122353| [ 1.03325 -1.38632]
21Feb12_122353| [ 0.75283 -0.37118]
21Feb12_122353| [-1.37344 -2.38437]
21Feb12_122353| [ 0.29599 -2.82818]
21Feb12_122353| [-0.08697 -0.51462]
21Feb12_122353| [ 0.22779 -0.03188]
21Feb12_122353| [ 1.10192  0.34059]
21Feb12_122353| [ 0.00737 -1.13053]
21Feb12_122353| [-0.38697 -0.78166]
21Feb12_122353| [ 1.11279 -0.70794]
21Feb12_122353| [-1.57859  0.13758]
21Feb12_122353| [ 0.57509  1.71894]
21Feb12_122353| [-0.22878 -0.16188]
21Feb12_122353| [ 0.02918 -0.37772]
21Feb12_122353| [ 0.48940 -0.96049]
21Feb12_122353| [ 0.70215  0.28465]
21Feb12_122353| [-0.13129  0.68326]
21Feb12_122353| [-1.52609  0.60254]
21Feb12_122353| [-1.29880  0.49477]
21Feb12_122353| [-1.07047  0.74063]
21Feb12_122353| [ 1.73937  0.57457]
21Feb12_122353| [ 0.47201 -0.06445]
21Feb12_122353| [-0.35947 -0.63247]
21Feb12_122353| [-1.27315 -0.85671]
21Feb12_122353| [-1.77157 -0.04656]
21Feb12_122353| [-0.36294  0.69560]
21Feb12_122353| [-1.29108  1.39541]
21Feb12_122353| [ 0.29550 -1.02032]
21Feb12_122353| [ 0.73382  0.17714]
21Feb12_122353| [ 0.36856  0.70171]
21Feb12_122353| [-0.61639  1.22436]
21Feb12_122353| [-1.64172 -2.25179]
21Feb12_122353| [ 0.09914  0.44019]
21Feb12_122353| [-1.25653  0.25848]
21Feb12_122353| [-0.54212  0.01596]
21Feb12_122353| [-1.34511  0.02169]
21Feb12_122353| [-0.16047 -1.27696]
21Feb12_122353| [-0.80058 -0.48952]
21Feb12_122353| [-0.95582  0.95487]
21Feb12_122353| [ 1.78352  0.09199]
21Feb12_122353| [ 1.37699  0.47338]
21Feb12_122353| [-0.61417 -2.56181]
21Feb12_122353| [-0.93012  1.04286]
21Feb12_122353| [ 1.35669  0.00900]
21Feb12_122353| [ 1.14910  1.09033]
21Feb12_122353| [-0.27953 -0.04201]
21Feb12_122353| [ 0.25632  0.02874]
21Feb12_122353| [ 1.23722  0.82313]
21Feb12_122353| [-0.48085 -0.49832]]
21Feb12_122353|-- Bias --
21Feb12_122353|[ 0.47675 -0.76660]
21Feb12_122353|Layer 1:
21Feb12_122353|-- Config --
21Feb12_122353|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122353|-- Weights --
21Feb12_122353|[[ 0.82049 -0.64190  0.15905  0.29356]
21Feb12_122353| [ 1.28383 -1.58235 -0.26631 -0.46335]]
21Feb12_122353|-- Bias --
21Feb12_122353|[ 0.02519 -0.46145  0.26882 -0.17956]
21Feb12_122353|Layer 2:
21Feb12_122353|-- Config --
21Feb12_122353|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122353|-- Weights --
21Feb12_122353|[[ 0.12590 -1.10838 -0.22227 -0.11569  0.19880]
21Feb12_122353| [ 0.02297  0.49371 -0.09440  0.49582 -0.82915]
21Feb12_122353| [ 0.14673 -0.43178  0.32269 -0.30475  0.51259]
21Feb12_122353| [ 0.25636 -0.34216 -0.13513  0.13946  0.30263]]
21Feb12_122353|-- Bias --
21Feb12_122353|[-0.85246 -0.21497  0.14004 -0.81699  0.14464]
21Feb12_122353|Layer 3:
21Feb12_122353|-- Config --
21Feb12_122353|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122353|-- Weights --
21Feb12_122353|[[-1.95210 -1.00039]
21Feb12_122353| [ 0.89031 -1.13606]
21Feb12_122353| [ 1.00561 -0.84721]
21Feb12_122353| [-0.98758  0.54903]
21Feb12_122353| [ 0.17707  0.27421]]
21Feb12_122353|-- Bias --
21Feb12_122353|[-0.58068  0.83748]
21Feb12_122353|Predicting the validation and test data with the Best final individual.
21Feb12_122400| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_122400|-----------  ------------------  --------------------  ----------
21Feb12_122400|Validation         27.04                  33            0.76361
21Feb12_122400|   Test            36.40                  33            0.00000
21Feb12_122400|-------------------- Test #6 --------------------
21Feb12_122400|Best final individual weights
21Feb12_122400|Individual:
21Feb12_122400|-- Constant hidden layers --
21Feb12_122400|False
21Feb12_122400|Layer 0:
21Feb12_122400|-- Config --
21Feb12_122400|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122400|-- Weights --
21Feb12_122400|[[-2.04393  0.94448]
21Feb12_122400| [ 0.11948  0.70709]
21Feb12_122400| [ 1.25419  0.09249]
21Feb12_122400| [ 1.30503 -0.61550]
21Feb12_122400| [-0.60509  0.24396]
21Feb12_122400| [ 1.12806 -0.70806]
21Feb12_122400| [ 1.44704 -0.48686]
21Feb12_122400| [-0.27510  2.36693]
21Feb12_122400| [ 1.03325 -1.38632]
21Feb12_122400| [ 0.75283 -0.37118]
21Feb12_122400| [-1.37344 -2.38437]
21Feb12_122400| [ 0.29599 -2.82818]
21Feb12_122400| [-0.08697 -0.51462]
21Feb12_122400| [ 0.22779 -0.03188]
21Feb12_122400| [ 1.10192  0.34059]
21Feb12_122400| [ 0.00737 -1.13053]
21Feb12_122400| [-0.38697 -0.78166]
21Feb12_122400| [ 1.11279 -0.70794]
21Feb12_122400| [-1.57859  0.13758]
21Feb12_122400| [ 0.57509  1.71894]
21Feb12_122400| [-0.22878 -0.16188]
21Feb12_122400| [ 0.02918 -0.37772]
21Feb12_122400| [ 0.48940 -0.96049]
21Feb12_122400| [ 0.70215  0.28465]
21Feb12_122400| [-0.13129  0.68326]
21Feb12_122400| [-1.52609  0.60254]
21Feb12_122400| [-1.29880  0.49477]
21Feb12_122400| [-1.07047  0.74063]
21Feb12_122400| [ 1.73937  0.57457]
21Feb12_122400| [ 0.47201 -0.06445]
21Feb12_122400| [-0.35947 -0.63247]
21Feb12_122400| [-1.27315 -0.85671]
21Feb12_122400| [-1.77157 -0.04656]
21Feb12_122400| [-0.36294  0.69560]
21Feb12_122400| [-1.29108  1.39541]
21Feb12_122400| [ 0.29550 -1.02032]
21Feb12_122400| [ 0.73382  0.17714]
21Feb12_122400| [ 0.36856  0.70171]
21Feb12_122400| [-0.61639  1.22436]
21Feb12_122400| [-1.64172 -2.25179]
21Feb12_122400| [ 0.09914  0.44019]
21Feb12_122400| [-1.25653  0.25848]
21Feb12_122400| [-0.54212  0.01596]
21Feb12_122400| [-1.34511  0.02169]
21Feb12_122400| [-0.16047 -1.27696]
21Feb12_122400| [-0.80058 -0.48952]
21Feb12_122400| [-0.95582  0.95487]
21Feb12_122400| [ 1.78352  0.09199]
21Feb12_122400| [ 1.37699  0.47338]
21Feb12_122400| [-0.61417 -2.56181]
21Feb12_122400| [-0.93012  1.04286]
21Feb12_122400| [ 1.35669  0.00900]
21Feb12_122400| [ 1.14910  1.09033]
21Feb12_122400| [-0.27953 -0.04201]
21Feb12_122400| [ 0.25632  0.02874]
21Feb12_122400| [ 1.23722  0.82313]
21Feb12_122400| [-0.48085 -0.49832]]
21Feb12_122400|-- Bias --
21Feb12_122400|[ 0.47675 -0.76660]
21Feb12_122400|Layer 1:
21Feb12_122400|-- Config --
21Feb12_122400|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122400|-- Weights --
21Feb12_122400|[[ 0.82049 -0.64190  0.15905  0.29356]
21Feb12_122400| [ 1.28383 -1.58235 -0.26631 -0.46335]]
21Feb12_122400|-- Bias --
21Feb12_122400|[ 0.02519 -0.46145  0.26882 -0.17956]
21Feb12_122400|Layer 2:
21Feb12_122400|-- Config --
21Feb12_122400|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122400|-- Weights --
21Feb12_122400|[[ 0.12590 -1.10838 -0.22227 -0.11569  0.19880]
21Feb12_122400| [ 0.02297  0.49371 -0.09440  0.49582 -0.82915]
21Feb12_122400| [ 0.14673 -0.43178  0.32269 -0.30475  0.51259]
21Feb12_122400| [ 0.25636 -0.34216 -0.13513  0.13946  0.30263]]
21Feb12_122400|-- Bias --
21Feb12_122400|[-0.85246 -0.21497  0.14004 -0.81699  0.14464]
21Feb12_122400|Layer 3:
21Feb12_122400|-- Config --
21Feb12_122400|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122400|-- Weights --
21Feb12_122400|[[-1.95210 -1.00039]
21Feb12_122400| [ 0.89031 -1.13606]
21Feb12_122400| [ 1.00561 -0.84721]
21Feb12_122400| [-0.98758  0.54903]
21Feb12_122400| [ 0.17707  0.27421]]
21Feb12_122400|-- Bias --
21Feb12_122400|[-0.58068  0.83748]
21Feb12_122400|Predicting the validation and test data with the Best final individual.
21Feb12_122408| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_122408|-----------  ------------------  --------------------  ----------
21Feb12_122408|Validation         42.00                  33            0.00000
21Feb12_122408|   Test            36.40                  33            0.00000
21Feb12_122408|-------------------- Test #7 --------------------
21Feb12_122408|Best final individual weights
21Feb12_122408|Individual:
21Feb12_122408|-- Constant hidden layers --
21Feb12_122408|False
21Feb12_122408|Layer 0:
21Feb12_122408|-- Config --
21Feb12_122408|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122408|-- Weights --
21Feb12_122408|[[-2.04393  0.94448]
21Feb12_122408| [ 0.11948  0.70709]
21Feb12_122408| [ 1.25419  0.09249]
21Feb12_122408| [ 1.30503 -0.61550]
21Feb12_122408| [-0.60509  0.24396]
21Feb12_122408| [ 1.12806 -0.70806]
21Feb12_122408| [ 1.44704 -0.48686]
21Feb12_122408| [-0.27510  2.36693]
21Feb12_122408| [ 1.03325 -1.38632]
21Feb12_122408| [ 0.75283 -0.37118]
21Feb12_122408| [-1.37344 -2.38437]
21Feb12_122408| [ 0.29599 -2.82818]
21Feb12_122408| [-0.08697 -0.51462]
21Feb12_122408| [ 0.22779 -0.03188]
21Feb12_122408| [ 1.10192  0.34059]
21Feb12_122408| [ 0.00737 -1.13053]
21Feb12_122408| [-0.38697 -0.78166]
21Feb12_122408| [ 1.11279 -0.70794]
21Feb12_122408| [-1.57859  0.13758]
21Feb12_122408| [ 0.57509  1.71894]
21Feb12_122408| [-0.22878 -0.16188]
21Feb12_122408| [ 0.02918 -0.37772]
21Feb12_122408| [ 0.48940 -0.96049]
21Feb12_122408| [ 0.70215  0.28465]
21Feb12_122408| [-0.13129  0.68326]
21Feb12_122408| [-1.52609  0.60254]
21Feb12_122408| [-1.29880  0.49477]
21Feb12_122408| [-1.07047  0.74063]
21Feb12_122408| [ 1.73937  0.57457]
21Feb12_122408| [ 0.47201 -0.06445]
21Feb12_122408| [-0.35947 -0.63247]
21Feb12_122408| [-1.27315 -0.85671]
21Feb12_122408| [-1.77157 -0.04656]
21Feb12_122408| [-0.36294  0.69560]
21Feb12_122408| [-1.29108  1.39541]
21Feb12_122408| [ 0.29550 -1.02032]
21Feb12_122408| [ 0.73382  0.17714]
21Feb12_122408| [ 0.36856  0.70171]
21Feb12_122408| [-0.61639  1.22436]
21Feb12_122408| [-1.64172 -2.25179]
21Feb12_122408| [ 0.09914  0.44019]
21Feb12_122408| [-1.25653  0.25848]
21Feb12_122408| [-0.54212  0.01596]
21Feb12_122408| [-1.34511  0.02169]
21Feb12_122408| [-0.16047 -1.27696]
21Feb12_122408| [-0.80058 -0.48952]
21Feb12_122408| [-0.95582  0.95487]
21Feb12_122408| [ 1.78352  0.09199]
21Feb12_122408| [ 1.37699  0.47338]
21Feb12_122408| [-0.61417 -2.56181]
21Feb12_122408| [-0.93012  1.04286]
21Feb12_122408| [ 1.35669  0.00900]
21Feb12_122408| [ 1.14910  1.09033]
21Feb12_122408| [-0.27953 -0.04201]
21Feb12_122408| [ 0.25632  0.02874]
21Feb12_122408| [ 1.23722  0.82313]
21Feb12_122408| [-0.48085 -0.49832]]
21Feb12_122408|-- Bias --
21Feb12_122408|[ 0.47675 -0.76660]
21Feb12_122408|Layer 1:
21Feb12_122408|-- Config --
21Feb12_122408|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122408|-- Weights --
21Feb12_122408|[[ 0.82049 -0.64190  0.15905  0.29356]
21Feb12_122408| [ 1.28383 -1.58235 -0.26631 -0.46335]]
21Feb12_122408|-- Bias --
21Feb12_122408|[ 0.02519 -0.46145  0.26882 -0.17956]
21Feb12_122408|Layer 2:
21Feb12_122408|-- Config --
21Feb12_122408|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122408|-- Weights --
21Feb12_122408|[[ 0.12590 -1.10838 -0.22227 -0.11569  0.19880]
21Feb12_122408| [ 0.02297  0.49371 -0.09440  0.49582 -0.82915]
21Feb12_122408| [ 0.14673 -0.43178  0.32269 -0.30475  0.51259]
21Feb12_122408| [ 0.25636 -0.34216 -0.13513  0.13946  0.30263]]
21Feb12_122408|-- Bias --
21Feb12_122408|[-0.85246 -0.21497  0.14004 -0.81699  0.14464]
21Feb12_122408|Layer 3:
21Feb12_122408|-- Config --
21Feb12_122408|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122408|-- Weights --
21Feb12_122408|[[-1.95210 -1.00039]
21Feb12_122408| [ 0.89031 -1.13606]
21Feb12_122408| [ 1.00561 -0.84721]
21Feb12_122408| [-0.98758  0.54903]
21Feb12_122408| [ 0.17707  0.27421]]
21Feb12_122408|-- Bias --
21Feb12_122408|[-0.58068  0.83748]
21Feb12_122408|Predicting the validation and test data with the Best final individual.
21Feb12_122416| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_122416|-----------  ------------------  --------------------  ----------
21Feb12_122416|Validation         33.22                  33            0.82387
21Feb12_122416|   Test            24.15                  33            0.53708
21Feb12_122416|-------------------- Test #8 --------------------
21Feb12_122416|Best final individual weights
21Feb12_122416|Individual:
21Feb12_122416|-- Constant hidden layers --
21Feb12_122416|False
21Feb12_122416|Layer 0:
21Feb12_122416|-- Config --
21Feb12_122416|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122416|-- Weights --
21Feb12_122416|[[-2.04393  0.94448]
21Feb12_122416| [ 0.11948  0.70709]
21Feb12_122416| [ 1.25419  0.09249]
21Feb12_122416| [ 1.30503 -0.61550]
21Feb12_122416| [-0.60509  0.24396]
21Feb12_122416| [ 1.12806 -0.70806]
21Feb12_122416| [ 1.44704 -0.48686]
21Feb12_122416| [-0.27510  2.36693]
21Feb12_122416| [ 1.03325 -1.38632]
21Feb12_122416| [ 0.75283 -0.37118]
21Feb12_122416| [-1.37344 -2.38437]
21Feb12_122416| [ 0.29599 -2.82818]
21Feb12_122416| [-0.08697 -0.51462]
21Feb12_122416| [ 0.22779 -0.03188]
21Feb12_122416| [ 1.10192  0.34059]
21Feb12_122416| [ 0.00737 -1.13053]
21Feb12_122416| [-0.38697 -0.78166]
21Feb12_122416| [ 1.11279 -0.70794]
21Feb12_122416| [-1.57859  0.13758]
21Feb12_122416| [ 0.57509  1.71894]
21Feb12_122416| [-0.22878 -0.16188]
21Feb12_122416| [ 0.02918 -0.37772]
21Feb12_122416| [ 0.48940 -0.96049]
21Feb12_122416| [ 0.70215  0.28465]
21Feb12_122416| [-0.13129  0.68326]
21Feb12_122416| [-1.52609  0.60254]
21Feb12_122416| [-1.29880  0.49477]
21Feb12_122416| [-1.07047  0.74063]
21Feb12_122416| [ 1.73937  0.57457]
21Feb12_122416| [ 0.47201 -0.06445]
21Feb12_122416| [-0.35947 -0.63247]
21Feb12_122416| [-1.27315 -0.85671]
21Feb12_122416| [-1.77157 -0.04656]
21Feb12_122416| [-0.36294  0.69560]
21Feb12_122416| [-1.29108  1.39541]
21Feb12_122416| [ 0.29550 -1.02032]
21Feb12_122416| [ 0.73382  0.17714]
21Feb12_122416| [ 0.36856  0.70171]
21Feb12_122416| [-0.61639  1.22436]
21Feb12_122416| [-1.64172 -2.25179]
21Feb12_122416| [ 0.09914  0.44019]
21Feb12_122416| [-1.25653  0.25848]
21Feb12_122416| [-0.54212  0.01596]
21Feb12_122416| [-1.34511  0.02169]
21Feb12_122416| [-0.16047 -1.27696]
21Feb12_122416| [-0.80058 -0.48952]
21Feb12_122416| [-0.95582  0.95487]
21Feb12_122416| [ 1.78352  0.09199]
21Feb12_122416| [ 1.37699  0.47338]
21Feb12_122416| [-0.61417 -2.56181]
21Feb12_122416| [-0.93012  1.04286]
21Feb12_122416| [ 1.35669  0.00900]
21Feb12_122416| [ 1.14910  1.09033]
21Feb12_122416| [-0.27953 -0.04201]
21Feb12_122416| [ 0.25632  0.02874]
21Feb12_122416| [ 1.23722  0.82313]
21Feb12_122416| [-0.48085 -0.49832]]
21Feb12_122416|-- Bias --
21Feb12_122416|[ 0.47675 -0.76660]
21Feb12_122416|Layer 1:
21Feb12_122416|-- Config --
21Feb12_122416|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122416|-- Weights --
21Feb12_122416|[[ 0.82049 -0.64190  0.15905  0.29356]
21Feb12_122416| [ 1.28383 -1.58235 -0.26631 -0.46335]]
21Feb12_122416|-- Bias --
21Feb12_122416|[ 0.02519 -0.46145  0.26882 -0.17956]
21Feb12_122416|Layer 2:
21Feb12_122416|-- Config --
21Feb12_122416|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122416|-- Weights --
21Feb12_122416|[[ 0.12590 -1.10838 -0.22227 -0.11569  0.19880]
21Feb12_122416| [ 0.02297  0.49371 -0.09440  0.49582 -0.82915]
21Feb12_122416| [ 0.14673 -0.43178  0.32269 -0.30475  0.51259]
21Feb12_122416| [ 0.25636 -0.34216 -0.13513  0.13946  0.30263]]
21Feb12_122416|-- Bias --
21Feb12_122416|[-0.85246 -0.21497  0.14004 -0.81699  0.14464]
21Feb12_122416|Layer 3:
21Feb12_122416|-- Config --
21Feb12_122416|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122416|-- Weights --
21Feb12_122416|[[-1.95210 -1.00039]
21Feb12_122416| [ 0.89031 -1.13606]
21Feb12_122416| [ 1.00561 -0.84721]
21Feb12_122416| [-0.98758  0.54903]
21Feb12_122416| [ 0.17707  0.27421]]
21Feb12_122416|-- Bias --
21Feb12_122416|[-0.58068  0.83748]
21Feb12_122416|Predicting the validation and test data with the Best final individual.
21Feb12_122423| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_122423|-----------  ------------------  --------------------  ----------
21Feb12_122423|Validation         42.00                  33            0.00000
21Feb12_122423|   Test            36.40                  33            0.00000
21Feb12_122423|-------------------- Test #9 --------------------
21Feb12_122423|Best final individual weights
21Feb12_122423|Individual:
21Feb12_122423|-- Constant hidden layers --
21Feb12_122423|False
21Feb12_122423|Layer 0:
21Feb12_122423|-- Config --
21Feb12_122423|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122423|-- Weights --
21Feb12_122423|[[-2.04393  0.94448]
21Feb12_122423| [ 0.11948  0.70709]
21Feb12_122423| [ 1.25419  0.09249]
21Feb12_122423| [ 1.30503 -0.61550]
21Feb12_122423| [-0.60509  0.24396]
21Feb12_122423| [ 1.12806 -0.70806]
21Feb12_122423| [ 1.44704 -0.48686]
21Feb12_122423| [-0.27510  2.36693]
21Feb12_122423| [ 1.03325 -1.38632]
21Feb12_122423| [ 0.75283 -0.37118]
21Feb12_122423| [-1.37344 -2.38437]
21Feb12_122423| [ 0.29599 -2.82818]
21Feb12_122423| [-0.08697 -0.51462]
21Feb12_122423| [ 0.22779 -0.03188]
21Feb12_122423| [ 1.10192  0.34059]
21Feb12_122423| [ 0.00737 -1.13053]
21Feb12_122423| [-0.38697 -0.78166]
21Feb12_122423| [ 1.11279 -0.70794]
21Feb12_122423| [-1.57859  0.13758]
21Feb12_122423| [ 0.57509  1.71894]
21Feb12_122423| [-0.22878 -0.16188]
21Feb12_122423| [ 0.02918 -0.37772]
21Feb12_122423| [ 0.48940 -0.96049]
21Feb12_122423| [ 0.70215  0.28465]
21Feb12_122423| [-0.13129  0.68326]
21Feb12_122423| [-1.52609  0.60254]
21Feb12_122423| [-1.29880  0.49477]
21Feb12_122423| [-1.07047  0.74063]
21Feb12_122423| [ 1.73937  0.57457]
21Feb12_122423| [ 0.47201 -0.06445]
21Feb12_122423| [-0.35947 -0.63247]
21Feb12_122423| [-1.27315 -0.85671]
21Feb12_122423| [-1.77157 -0.04656]
21Feb12_122423| [-0.36294  0.69560]
21Feb12_122423| [-1.29108  1.39541]
21Feb12_122423| [ 0.29550 -1.02032]
21Feb12_122423| [ 0.73382  0.17714]
21Feb12_122423| [ 0.36856  0.70171]
21Feb12_122423| [-0.61639  1.22436]
21Feb12_122423| [-1.64172 -2.25179]
21Feb12_122423| [ 0.09914  0.44019]
21Feb12_122423| [-1.25653  0.25848]
21Feb12_122423| [-0.54212  0.01596]
21Feb12_122423| [-1.34511  0.02169]
21Feb12_122423| [-0.16047 -1.27696]
21Feb12_122423| [-0.80058 -0.48952]
21Feb12_122423| [-0.95582  0.95487]
21Feb12_122423| [ 1.78352  0.09199]
21Feb12_122423| [ 1.37699  0.47338]
21Feb12_122423| [-0.61417 -2.56181]
21Feb12_122423| [-0.93012  1.04286]
21Feb12_122423| [ 1.35669  0.00900]
21Feb12_122423| [ 1.14910  1.09033]
21Feb12_122423| [-0.27953 -0.04201]
21Feb12_122423| [ 0.25632  0.02874]
21Feb12_122423| [ 1.23722  0.82313]
21Feb12_122423| [-0.48085 -0.49832]]
21Feb12_122423|-- Bias --
21Feb12_122423|[ 0.47675 -0.76660]
21Feb12_122423|Layer 1:
21Feb12_122423|-- Config --
21Feb12_122423|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122423|-- Weights --
21Feb12_122423|[[ 0.82049 -0.64190  0.15905  0.29356]
21Feb12_122423| [ 1.28383 -1.58235 -0.26631 -0.46335]]
21Feb12_122423|-- Bias --
21Feb12_122423|[ 0.02519 -0.46145  0.26882 -0.17956]
21Feb12_122423|Layer 2:
21Feb12_122423|-- Config --
21Feb12_122423|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122423|-- Weights --
21Feb12_122423|[[ 0.12590 -1.10838 -0.22227 -0.11569  0.19880]
21Feb12_122423| [ 0.02297  0.49371 -0.09440  0.49582 -0.82915]
21Feb12_122423| [ 0.14673 -0.43178  0.32269 -0.30475  0.51259]
21Feb12_122423| [ 0.25636 -0.34216 -0.13513  0.13946  0.30263]]
21Feb12_122423|-- Bias --
21Feb12_122423|[-0.85246 -0.21497  0.14004 -0.81699  0.14464]
21Feb12_122423|Layer 3:
21Feb12_122423|-- Config --
21Feb12_122423|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122423|-- Weights --
21Feb12_122423|[[-1.95210 -1.00039]
21Feb12_122423| [ 0.89031 -1.13606]
21Feb12_122423| [ 1.00561 -0.84721]
21Feb12_122423| [-0.98758  0.54903]
21Feb12_122423| [ 0.17707  0.27421]]
21Feb12_122423|-- Bias --
21Feb12_122423|[-0.58068  0.83748]
21Feb12_122423|Predicting the validation and test data with the Best final individual.
21Feb12_122431| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_122431|-----------  ------------------  --------------------  ----------
21Feb12_122431|Validation         24.78                  33            0.80532
21Feb12_122431|   Test            21.63                  33            0.82369
21Feb12_122431|-------------------- Test #10 --------------------
21Feb12_122431|Best final individual weights
21Feb12_122431|Individual:
21Feb12_122431|-- Constant hidden layers --
21Feb12_122431|False
21Feb12_122431|Layer 0:
21Feb12_122431|-- Config --
21Feb12_122431|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122431|-- Weights --
21Feb12_122431|[[-2.04393  0.94448]
21Feb12_122431| [ 0.11948  0.70709]
21Feb12_122431| [ 1.25419  0.09249]
21Feb12_122431| [ 1.30503 -0.61550]
21Feb12_122431| [-0.60509  0.24396]
21Feb12_122431| [ 1.12806 -0.70806]
21Feb12_122431| [ 1.44704 -0.48686]
21Feb12_122431| [-0.27510  2.36693]
21Feb12_122431| [ 1.03325 -1.38632]
21Feb12_122431| [ 0.75283 -0.37118]
21Feb12_122431| [-1.37344 -2.38437]
21Feb12_122431| [ 0.29599 -2.82818]
21Feb12_122431| [-0.08697 -0.51462]
21Feb12_122431| [ 0.22779 -0.03188]
21Feb12_122431| [ 1.10192  0.34059]
21Feb12_122431| [ 0.00737 -1.13053]
21Feb12_122431| [-0.38697 -0.78166]
21Feb12_122431| [ 1.11279 -0.70794]
21Feb12_122431| [-1.57859  0.13758]
21Feb12_122431| [ 0.57509  1.71894]
21Feb12_122431| [-0.22878 -0.16188]
21Feb12_122431| [ 0.02918 -0.37772]
21Feb12_122431| [ 0.48940 -0.96049]
21Feb12_122431| [ 0.70215  0.28465]
21Feb12_122431| [-0.13129  0.68326]
21Feb12_122431| [-1.52609  0.60254]
21Feb12_122431| [-1.29880  0.49477]
21Feb12_122431| [-1.07047  0.74063]
21Feb12_122431| [ 1.73937  0.57457]
21Feb12_122431| [ 0.47201 -0.06445]
21Feb12_122431| [-0.35947 -0.63247]
21Feb12_122431| [-1.27315 -0.85671]
21Feb12_122431| [-1.77157 -0.04656]
21Feb12_122431| [-0.36294  0.69560]
21Feb12_122431| [-1.29108  1.39541]
21Feb12_122431| [ 0.29550 -1.02032]
21Feb12_122431| [ 0.73382  0.17714]
21Feb12_122431| [ 0.36856  0.70171]
21Feb12_122431| [-0.61639  1.22436]
21Feb12_122431| [-1.64172 -2.25179]
21Feb12_122431| [ 0.09914  0.44019]
21Feb12_122431| [-1.25653  0.25848]
21Feb12_122431| [-0.54212  0.01596]
21Feb12_122431| [-1.34511  0.02169]
21Feb12_122431| [-0.16047 -1.27696]
21Feb12_122431| [-0.80058 -0.48952]
21Feb12_122431| [-0.95582  0.95487]
21Feb12_122431| [ 1.78352  0.09199]
21Feb12_122431| [ 1.37699  0.47338]
21Feb12_122431| [-0.61417 -2.56181]
21Feb12_122431| [-0.93012  1.04286]
21Feb12_122431| [ 1.35669  0.00900]
21Feb12_122431| [ 1.14910  1.09033]
21Feb12_122431| [-0.27953 -0.04201]
21Feb12_122431| [ 0.25632  0.02874]
21Feb12_122431| [ 1.23722  0.82313]
21Feb12_122431| [-0.48085 -0.49832]]
21Feb12_122431|-- Bias --
21Feb12_122431|[ 0.47675 -0.76660]
21Feb12_122431|Layer 1:
21Feb12_122431|-- Config --
21Feb12_122431|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122431|-- Weights --
21Feb12_122431|[[ 0.82049 -0.64190  0.15905  0.29356]
21Feb12_122431| [ 1.28383 -1.58235 -0.26631 -0.46335]]
21Feb12_122431|-- Bias --
21Feb12_122431|[ 0.02519 -0.46145  0.26882 -0.17956]
21Feb12_122431|Layer 2:
21Feb12_122431|-- Config --
21Feb12_122431|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122431|-- Weights --
21Feb12_122431|[[ 0.12590 -1.10838 -0.22227 -0.11569  0.19880]
21Feb12_122431| [ 0.02297  0.49371 -0.09440  0.49582 -0.82915]
21Feb12_122431| [ 0.14673 -0.43178  0.32269 -0.30475  0.51259]
21Feb12_122431| [ 0.25636 -0.34216 -0.13513  0.13946  0.30263]]
21Feb12_122431|-- Bias --
21Feb12_122431|[-0.85246 -0.21497  0.14004 -0.81699  0.14464]
21Feb12_122431|Layer 3:
21Feb12_122431|-- Config --
21Feb12_122431|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122431|-- Weights --
21Feb12_122431|[[-1.95210 -1.00039]
21Feb12_122431| [ 0.89031 -1.13606]
21Feb12_122431| [ 1.00561 -0.84721]
21Feb12_122431| [-0.98758  0.54903]
21Feb12_122431| [ 0.17707  0.27421]]
21Feb12_122431|-- Bias --
21Feb12_122431|[-0.58068  0.83748]
21Feb12_122431|Predicting the validation and test data with the Best final individual.
21Feb12_122439| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_122439|-----------  ------------------  --------------------  ----------
21Feb12_122439|Validation         42.00                  33            0.00000
21Feb12_122439|   Test            36.40                  33            0.00000
21Feb12_122439|-------------------- Test #11 --------------------
21Feb12_122439|Best final individual weights
21Feb12_122439|Individual:
21Feb12_122439|-- Constant hidden layers --
21Feb12_122439|False
21Feb12_122439|Layer 0:
21Feb12_122439|-- Config --
21Feb12_122439|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122439|-- Weights --
21Feb12_122439|[[-2.04393  0.94448]
21Feb12_122439| [ 0.11948  0.70709]
21Feb12_122439| [ 1.25419  0.09249]
21Feb12_122439| [ 1.30503 -0.61550]
21Feb12_122439| [-0.60509  0.24396]
21Feb12_122439| [ 1.12806 -0.70806]
21Feb12_122439| [ 1.44704 -0.48686]
21Feb12_122439| [-0.27510  2.36693]
21Feb12_122439| [ 1.03325 -1.38632]
21Feb12_122439| [ 0.75283 -0.37118]
21Feb12_122439| [-1.37344 -2.38437]
21Feb12_122439| [ 0.29599 -2.82818]
21Feb12_122439| [-0.08697 -0.51462]
21Feb12_122439| [ 0.22779 -0.03188]
21Feb12_122439| [ 1.10192  0.34059]
21Feb12_122439| [ 0.00737 -1.13053]
21Feb12_122439| [-0.38697 -0.78166]
21Feb12_122439| [ 1.11279 -0.70794]
21Feb12_122439| [-1.57859  0.13758]
21Feb12_122439| [ 0.57509  1.71894]
21Feb12_122439| [-0.22878 -0.16188]
21Feb12_122439| [ 0.02918 -0.37772]
21Feb12_122439| [ 0.48940 -0.96049]
21Feb12_122439| [ 0.70215  0.28465]
21Feb12_122439| [-0.13129  0.68326]
21Feb12_122439| [-1.52609  0.60254]
21Feb12_122439| [-1.29880  0.49477]
21Feb12_122439| [-1.07047  0.74063]
21Feb12_122439| [ 1.73937  0.57457]
21Feb12_122439| [ 0.47201 -0.06445]
21Feb12_122439| [-0.35947 -0.63247]
21Feb12_122439| [-1.27315 -0.85671]
21Feb12_122439| [-1.77157 -0.04656]
21Feb12_122439| [-0.36294  0.69560]
21Feb12_122439| [-1.29108  1.39541]
21Feb12_122439| [ 0.29550 -1.02032]
21Feb12_122439| [ 0.73382  0.17714]
21Feb12_122439| [ 0.36856  0.70171]
21Feb12_122439| [-0.61639  1.22436]
21Feb12_122439| [-1.64172 -2.25179]
21Feb12_122439| [ 0.09914  0.44019]
21Feb12_122439| [-1.25653  0.25848]
21Feb12_122439| [-0.54212  0.01596]
21Feb12_122439| [-1.34511  0.02169]
21Feb12_122439| [-0.16047 -1.27696]
21Feb12_122439| [-0.80058 -0.48952]
21Feb12_122439| [-0.95582  0.95487]
21Feb12_122439| [ 1.78352  0.09199]
21Feb12_122439| [ 1.37699  0.47338]
21Feb12_122439| [-0.61417 -2.56181]
21Feb12_122439| [-0.93012  1.04286]
21Feb12_122439| [ 1.35669  0.00900]
21Feb12_122439| [ 1.14910  1.09033]
21Feb12_122439| [-0.27953 -0.04201]
21Feb12_122439| [ 0.25632  0.02874]
21Feb12_122439| [ 1.23722  0.82313]
21Feb12_122439| [-0.48085 -0.49832]]
21Feb12_122439|-- Bias --
21Feb12_122439|[ 0.47675 -0.76660]
21Feb12_122439|Layer 1:
21Feb12_122439|-- Config --
21Feb12_122439|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122439|-- Weights --
21Feb12_122439|[[ 0.82049 -0.64190  0.15905  0.29356]
21Feb12_122439| [ 1.28383 -1.58235 -0.26631 -0.46335]]
21Feb12_122439|-- Bias --
21Feb12_122439|[ 0.02519 -0.46145  0.26882 -0.17956]
21Feb12_122439|Layer 2:
21Feb12_122439|-- Config --
21Feb12_122439|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122439|-- Weights --
21Feb12_122439|[[ 0.12590 -1.10838 -0.22227 -0.11569  0.19880]
21Feb12_122439| [ 0.02297  0.49371 -0.09440  0.49582 -0.82915]
21Feb12_122439| [ 0.14673 -0.43178  0.32269 -0.30475  0.51259]
21Feb12_122439| [ 0.25636 -0.34216 -0.13513  0.13946  0.30263]]
21Feb12_122439|-- Bias --
21Feb12_122439|[-0.85246 -0.21497  0.14004 -0.81699  0.14464]
21Feb12_122439|Layer 3:
21Feb12_122439|-- Config --
21Feb12_122439|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122439|-- Weights --
21Feb12_122439|[[-1.95210 -1.00039]
21Feb12_122439| [ 0.89031 -1.13606]
21Feb12_122439| [ 1.00561 -0.84721]
21Feb12_122439| [-0.98758  0.54903]
21Feb12_122439| [ 0.17707  0.27421]]
21Feb12_122439|-- Bias --
21Feb12_122439|[-0.58068  0.83748]
21Feb12_122439|Predicting the validation and test data with the Best final individual.
21Feb12_122446| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_122446|-----------  ------------------  --------------------  ----------
21Feb12_122446|Validation         20.52                  33            0.83564
21Feb12_122446|   Test            36.40                  33            0.00000
21Feb12_122446|-------------------- Test #12 --------------------
21Feb12_122446|Best final individual weights
21Feb12_122446|Individual:
21Feb12_122446|-- Constant hidden layers --
21Feb12_122446|False
21Feb12_122446|Layer 0:
21Feb12_122446|-- Config --
21Feb12_122446|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122446|-- Weights --
21Feb12_122446|[[-2.04393  0.94448]
21Feb12_122446| [ 0.11948  0.70709]
21Feb12_122446| [ 1.25419  0.09249]
21Feb12_122446| [ 1.30503 -0.61550]
21Feb12_122446| [-0.60509  0.24396]
21Feb12_122446| [ 1.12806 -0.70806]
21Feb12_122446| [ 1.44704 -0.48686]
21Feb12_122446| [-0.27510  2.36693]
21Feb12_122446| [ 1.03325 -1.38632]
21Feb12_122446| [ 0.75283 -0.37118]
21Feb12_122446| [-1.37344 -2.38437]
21Feb12_122446| [ 0.29599 -2.82818]
21Feb12_122446| [-0.08697 -0.51462]
21Feb12_122446| [ 0.22779 -0.03188]
21Feb12_122446| [ 1.10192  0.34059]
21Feb12_122446| [ 0.00737 -1.13053]
21Feb12_122446| [-0.38697 -0.78166]
21Feb12_122446| [ 1.11279 -0.70794]
21Feb12_122446| [-1.57859  0.13758]
21Feb12_122446| [ 0.57509  1.71894]
21Feb12_122446| [-0.22878 -0.16188]
21Feb12_122446| [ 0.02918 -0.37772]
21Feb12_122446| [ 0.48940 -0.96049]
21Feb12_122446| [ 0.70215  0.28465]
21Feb12_122446| [-0.13129  0.68326]
21Feb12_122446| [-1.52609  0.60254]
21Feb12_122446| [-1.29880  0.49477]
21Feb12_122446| [-1.07047  0.74063]
21Feb12_122446| [ 1.73937  0.57457]
21Feb12_122446| [ 0.47201 -0.06445]
21Feb12_122446| [-0.35947 -0.63247]
21Feb12_122446| [-1.27315 -0.85671]
21Feb12_122446| [-1.77157 -0.04656]
21Feb12_122446| [-0.36294  0.69560]
21Feb12_122446| [-1.29108  1.39541]
21Feb12_122446| [ 0.29550 -1.02032]
21Feb12_122446| [ 0.73382  0.17714]
21Feb12_122446| [ 0.36856  0.70171]
21Feb12_122446| [-0.61639  1.22436]
21Feb12_122446| [-1.64172 -2.25179]
21Feb12_122446| [ 0.09914  0.44019]
21Feb12_122446| [-1.25653  0.25848]
21Feb12_122446| [-0.54212  0.01596]
21Feb12_122446| [-1.34511  0.02169]
21Feb12_122446| [-0.16047 -1.27696]
21Feb12_122446| [-0.80058 -0.48952]
21Feb12_122446| [-0.95582  0.95487]
21Feb12_122446| [ 1.78352  0.09199]
21Feb12_122446| [ 1.37699  0.47338]
21Feb12_122446| [-0.61417 -2.56181]
21Feb12_122446| [-0.93012  1.04286]
21Feb12_122446| [ 1.35669  0.00900]
21Feb12_122446| [ 1.14910  1.09033]
21Feb12_122446| [-0.27953 -0.04201]
21Feb12_122446| [ 0.25632  0.02874]
21Feb12_122446| [ 1.23722  0.82313]
21Feb12_122446| [-0.48085 -0.49832]]
21Feb12_122446|-- Bias --
21Feb12_122446|[ 0.47675 -0.76660]
21Feb12_122446|Layer 1:
21Feb12_122446|-- Config --
21Feb12_122446|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122446|-- Weights --
21Feb12_122446|[[ 0.82049 -0.64190  0.15905  0.29356]
21Feb12_122446| [ 1.28383 -1.58235 -0.26631 -0.46335]]
21Feb12_122446|-- Bias --
21Feb12_122446|[ 0.02519 -0.46145  0.26882 -0.17956]
21Feb12_122446|Layer 2:
21Feb12_122446|-- Config --
21Feb12_122446|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122446|-- Weights --
21Feb12_122446|[[ 0.12590 -1.10838 -0.22227 -0.11569  0.19880]
21Feb12_122446| [ 0.02297  0.49371 -0.09440  0.49582 -0.82915]
21Feb12_122446| [ 0.14673 -0.43178  0.32269 -0.30475  0.51259]
21Feb12_122446| [ 0.25636 -0.34216 -0.13513  0.13946  0.30263]]
21Feb12_122446|-- Bias --
21Feb12_122446|[-0.85246 -0.21497  0.14004 -0.81699  0.14464]
21Feb12_122446|Layer 3:
21Feb12_122446|-- Config --
21Feb12_122446|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122446|-- Weights --
21Feb12_122446|[[-1.95210 -1.00039]
21Feb12_122446| [ 0.89031 -1.13606]
21Feb12_122446| [ 1.00561 -0.84721]
21Feb12_122446| [-0.98758  0.54903]
21Feb12_122446| [ 0.17707  0.27421]]
21Feb12_122446|-- Bias --
21Feb12_122446|[-0.58068  0.83748]
21Feb12_122446|Predicting the validation and test data with the Best final individual.
21Feb12_122454| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_122454|-----------  ------------------  --------------------  ----------
21Feb12_122454|Validation         41.91                  33            0.00774
21Feb12_122454|   Test            26.50                  33            0.65628
21Feb12_122454|-------------------- Test #13 --------------------
21Feb12_122454|Best final individual weights
21Feb12_122454|Individual:
21Feb12_122454|-- Constant hidden layers --
21Feb12_122454|False
21Feb12_122454|Layer 0:
21Feb12_122454|-- Config --
21Feb12_122454|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122454|-- Weights --
21Feb12_122454|[[-2.04393  0.94448]
21Feb12_122454| [ 0.11948  0.70709]
21Feb12_122454| [ 1.25419  0.09249]
21Feb12_122454| [ 1.30503 -0.61550]
21Feb12_122454| [-0.60509  0.24396]
21Feb12_122454| [ 1.12806 -0.70806]
21Feb12_122454| [ 1.44704 -0.48686]
21Feb12_122454| [-0.27510  2.36693]
21Feb12_122454| [ 1.03325 -1.38632]
21Feb12_122454| [ 0.75283 -0.37118]
21Feb12_122454| [-1.37344 -2.38437]
21Feb12_122454| [ 0.29599 -2.82818]
21Feb12_122454| [-0.08697 -0.51462]
21Feb12_122454| [ 0.22779 -0.03188]
21Feb12_122454| [ 1.10192  0.34059]
21Feb12_122454| [ 0.00737 -1.13053]
21Feb12_122454| [-0.38697 -0.78166]
21Feb12_122454| [ 1.11279 -0.70794]
21Feb12_122454| [-1.57859  0.13758]
21Feb12_122454| [ 0.57509  1.71894]
21Feb12_122454| [-0.22878 -0.16188]
21Feb12_122454| [ 0.02918 -0.37772]
21Feb12_122454| [ 0.48940 -0.96049]
21Feb12_122454| [ 0.70215  0.28465]
21Feb12_122454| [-0.13129  0.68326]
21Feb12_122454| [-1.52609  0.60254]
21Feb12_122454| [-1.29880  0.49477]
21Feb12_122454| [-1.07047  0.74063]
21Feb12_122454| [ 1.73937  0.57457]
21Feb12_122454| [ 0.47201 -0.06445]
21Feb12_122454| [-0.35947 -0.63247]
21Feb12_122454| [-1.27315 -0.85671]
21Feb12_122454| [-1.77157 -0.04656]
21Feb12_122454| [-0.36294  0.69560]
21Feb12_122454| [-1.29108  1.39541]
21Feb12_122454| [ 0.29550 -1.02032]
21Feb12_122454| [ 0.73382  0.17714]
21Feb12_122454| [ 0.36856  0.70171]
21Feb12_122454| [-0.61639  1.22436]
21Feb12_122454| [-1.64172 -2.25179]
21Feb12_122454| [ 0.09914  0.44019]
21Feb12_122454| [-1.25653  0.25848]
21Feb12_122454| [-0.54212  0.01596]
21Feb12_122454| [-1.34511  0.02169]
21Feb12_122454| [-0.16047 -1.27696]
21Feb12_122454| [-0.80058 -0.48952]
21Feb12_122454| [-0.95582  0.95487]
21Feb12_122454| [ 1.78352  0.09199]
21Feb12_122454| [ 1.37699  0.47338]
21Feb12_122454| [-0.61417 -2.56181]
21Feb12_122454| [-0.93012  1.04286]
21Feb12_122454| [ 1.35669  0.00900]
21Feb12_122454| [ 1.14910  1.09033]
21Feb12_122454| [-0.27953 -0.04201]
21Feb12_122454| [ 0.25632  0.02874]
21Feb12_122454| [ 1.23722  0.82313]
21Feb12_122454| [-0.48085 -0.49832]]
21Feb12_122454|-- Bias --
21Feb12_122454|[ 0.47675 -0.76660]
21Feb12_122454|Layer 1:
21Feb12_122454|-- Config --
21Feb12_122454|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122454|-- Weights --
21Feb12_122454|[[ 0.82049 -0.64190  0.15905  0.29356]
21Feb12_122454| [ 1.28383 -1.58235 -0.26631 -0.46335]]
21Feb12_122454|-- Bias --
21Feb12_122454|[ 0.02519 -0.46145  0.26882 -0.17956]
21Feb12_122454|Layer 2:
21Feb12_122454|-- Config --
21Feb12_122454|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122454|-- Weights --
21Feb12_122454|[[ 0.12590 -1.10838 -0.22227 -0.11569  0.19880]
21Feb12_122454| [ 0.02297  0.49371 -0.09440  0.49582 -0.82915]
21Feb12_122454| [ 0.14673 -0.43178  0.32269 -0.30475  0.51259]
21Feb12_122454| [ 0.25636 -0.34216 -0.13513  0.13946  0.30263]]
21Feb12_122454|-- Bias --
21Feb12_122454|[-0.85246 -0.21497  0.14004 -0.81699  0.14464]
21Feb12_122454|Layer 3:
21Feb12_122454|-- Config --
21Feb12_122454|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122454|-- Weights --
21Feb12_122454|[[-1.95210 -1.00039]
21Feb12_122454| [ 0.89031 -1.13606]
21Feb12_122454| [ 1.00561 -0.84721]
21Feb12_122454| [-0.98758  0.54903]
21Feb12_122454| [ 0.17707  0.27421]]
21Feb12_122454|-- Bias --
21Feb12_122454|[-0.58068  0.83748]
21Feb12_122454|Predicting the validation and test data with the Best final individual.
21Feb12_122502| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_122502|-----------  ------------------  --------------------  ----------
21Feb12_122502|Validation         27.83                  33            0.70297
21Feb12_122502|   Test            33.19                  33            0.33086
21Feb12_122502|-------------------- Test #14 --------------------
21Feb12_122502|Best final individual weights
21Feb12_122502|Individual:
21Feb12_122502|-- Constant hidden layers --
21Feb12_122502|False
21Feb12_122502|Layer 0:
21Feb12_122502|-- Config --
21Feb12_122502|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122502|-- Weights --
21Feb12_122502|[[-2.04393  0.94448]
21Feb12_122502| [ 0.11948  0.70709]
21Feb12_122502| [ 1.25419  0.09249]
21Feb12_122502| [ 1.30503 -0.61550]
21Feb12_122502| [-0.60509  0.24396]
21Feb12_122502| [ 1.12806 -0.70806]
21Feb12_122502| [ 1.44704 -0.48686]
21Feb12_122502| [-0.27510  2.36693]
21Feb12_122502| [ 1.03325 -1.38632]
21Feb12_122502| [ 0.75283 -0.37118]
21Feb12_122502| [-1.37344 -2.38437]
21Feb12_122502| [ 0.29599 -2.82818]
21Feb12_122502| [-0.08697 -0.51462]
21Feb12_122502| [ 0.22779 -0.03188]
21Feb12_122502| [ 1.10192  0.34059]
21Feb12_122502| [ 0.00737 -1.13053]
21Feb12_122502| [-0.38697 -0.78166]
21Feb12_122502| [ 1.11279 -0.70794]
21Feb12_122502| [-1.57859  0.13758]
21Feb12_122502| [ 0.57509  1.71894]
21Feb12_122502| [-0.22878 -0.16188]
21Feb12_122502| [ 0.02918 -0.37772]
21Feb12_122502| [ 0.48940 -0.96049]
21Feb12_122502| [ 0.70215  0.28465]
21Feb12_122502| [-0.13129  0.68326]
21Feb12_122502| [-1.52609  0.60254]
21Feb12_122502| [-1.29880  0.49477]
21Feb12_122502| [-1.07047  0.74063]
21Feb12_122502| [ 1.73937  0.57457]
21Feb12_122502| [ 0.47201 -0.06445]
21Feb12_122502| [-0.35947 -0.63247]
21Feb12_122502| [-1.27315 -0.85671]
21Feb12_122502| [-1.77157 -0.04656]
21Feb12_122502| [-0.36294  0.69560]
21Feb12_122502| [-1.29108  1.39541]
21Feb12_122502| [ 0.29550 -1.02032]
21Feb12_122502| [ 0.73382  0.17714]
21Feb12_122502| [ 0.36856  0.70171]
21Feb12_122502| [-0.61639  1.22436]
21Feb12_122502| [-1.64172 -2.25179]
21Feb12_122502| [ 0.09914  0.44019]
21Feb12_122502| [-1.25653  0.25848]
21Feb12_122502| [-0.54212  0.01596]
21Feb12_122502| [-1.34511  0.02169]
21Feb12_122502| [-0.16047 -1.27696]
21Feb12_122502| [-0.80058 -0.48952]
21Feb12_122502| [-0.95582  0.95487]
21Feb12_122502| [ 1.78352  0.09199]
21Feb12_122502| [ 1.37699  0.47338]
21Feb12_122502| [-0.61417 -2.56181]
21Feb12_122502| [-0.93012  1.04286]
21Feb12_122502| [ 1.35669  0.00900]
21Feb12_122502| [ 1.14910  1.09033]
21Feb12_122502| [-0.27953 -0.04201]
21Feb12_122502| [ 0.25632  0.02874]
21Feb12_122502| [ 1.23722  0.82313]
21Feb12_122502| [-0.48085 -0.49832]]
21Feb12_122502|-- Bias --
21Feb12_122502|[ 0.47675 -0.76660]
21Feb12_122502|Layer 1:
21Feb12_122502|-- Config --
21Feb12_122502|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122502|-- Weights --
21Feb12_122502|[[ 0.82049 -0.64190  0.15905  0.29356]
21Feb12_122502| [ 1.28383 -1.58235 -0.26631 -0.46335]]
21Feb12_122502|-- Bias --
21Feb12_122502|[ 0.02519 -0.46145  0.26882 -0.17956]
21Feb12_122502|Layer 2:
21Feb12_122502|-- Config --
21Feb12_122502|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122502|-- Weights --
21Feb12_122502|[[ 0.12590 -1.10838 -0.22227 -0.11569  0.19880]
21Feb12_122502| [ 0.02297  0.49371 -0.09440  0.49582 -0.82915]
21Feb12_122502| [ 0.14673 -0.43178  0.32269 -0.30475  0.51259]
21Feb12_122502| [ 0.25636 -0.34216 -0.13513  0.13946  0.30263]]
21Feb12_122502|-- Bias --
21Feb12_122502|[-0.85246 -0.21497  0.14004 -0.81699  0.14464]
21Feb12_122502|Layer 3:
21Feb12_122502|-- Config --
21Feb12_122502|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_122502|-- Weights --
21Feb12_122502|[[-1.95210 -1.00039]
21Feb12_122502| [ 0.89031 -1.13606]
21Feb12_122502| [ 1.00561 -0.84721]
21Feb12_122502| [-0.98758  0.54903]
21Feb12_122502| [ 0.17707  0.27421]]
21Feb12_122502|-- Bias --
21Feb12_122502|[-0.58068  0.83748]
21Feb12_122502|Predicting the validation and test data with the Best final individual.
21Feb12_122509| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_122509|-----------  ------------------  --------------------  ----------
21Feb12_122509|Validation         23.83                  33            0.75254
21Feb12_122509|   Test            36.40                  33            0.00000
2021-02-12 12:25:10.409876: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
21Feb12_122511|Data summary: Train
21Feb12_122511|data.shape = (2300, 57)
21Feb12_122511|labels.shape = (2300,)
21Feb12_122511|Class distribution:
21Feb12_122511|	0 - 1389 (0.60)
21Feb12_122511|	1 - 911 (0.40)
21Feb12_122511|Data summary: Validation
21Feb12_122511|data.shape = (1150, 57)
21Feb12_122511|labels.shape = (1150,)
21Feb12_122511|Class distribution:
21Feb12_122511|	0 - 667 (0.58)
21Feb12_122511|	1 - 483 (0.42)
21Feb12_122511|Data summary: Test
21Feb12_122511|data.shape = (1151, 57)
21Feb12_122511|labels.shape = (1151,)
21Feb12_122511|Class distribution:
21Feb12_122511|	0 - 732 (0.64)
21Feb12_122511|	1 - 419 (0.36)
21Feb12_122511|Selected configuration values
21Feb12_122511|-- Dataset name: spambase2
21Feb12_122511|-- Initial population size: 64
21Feb12_122511|-- Maximun number of generations: 32
21Feb12_122511|-- Neurons per hidden layer range: (2, 20)
21Feb12_122511|-- Hidden layers number range: (1, 3)
21Feb12_122511|-- Crossover probability: 0.5
21Feb12_122511|-- Bias gene mutation probability: 0.2
21Feb12_122511|-- Weights gene mutation probability: 0.75
21Feb12_122511|-- Neuron mutation probability: 0.3
21Feb12_122511|-- Layer mutation probability: 0.3
21Feb12_122511|-- Constant hidden layers: False
21Feb12_122511|-- Seed: 31415
21Feb12_122511|Entering GA
21Feb12_122511|Start the algorithm
2021-02-12 12:25:11.341153: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-12 12:25:11.341659: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-02-12 12:25:11.362806: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-12 12:25:11.363143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.71GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s
2021-02-12 12:25:11.363158: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-02-12 12:25:11.364583: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-02-12 12:25:11.364612: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-02-12 12:25:11.365093: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-02-12 12:25:11.365224: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-02-12 12:25:11.365296: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-12 12:25:11.365688: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-02-12 12:25:11.365728: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-12 12:25:11.365735: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-02-12 12:25:11.365968: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-02-12 12:25:11.366715: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-12 12:25:11.366731: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-12 12:25:11.366735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      
2021-02-12 12:25:11.415232: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-02-12 12:25:11.415542: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3493635000 Hz
/home/jmerelo/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype("int32")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn('`model.predict_classes()` is deprecated and '
21Feb12_122911|-- Generation 1 --
21Feb12_122911|    -- Crossed 1 individual pairs.
21Feb12_122911|    -- Mutated 32 individuals.
21Feb12_123305|    -- Evaluated 64 individuals.
21Feb12_123305|    Summary of generation 1:
21Feb12_123305| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_123305|-----------  ------------------  --------------------  ----------
21Feb12_123305|    Max            42.52                132.00          0.61233
21Feb12_123305|    Avg            41.75                33.92           0.01118
21Feb12_123305|    Min            26.26                 2.00           0.00000
21Feb12_123305|    Std             1.96                31.23           0.07579
21Feb12_123305|   Best            26.26                39.00           0.61233
21Feb12_123305|-- Generation 2 --
21Feb12_123305|    -- Crossed 0 individual pairs.
21Feb12_123305|    -- Mutated 32 individuals.
21Feb12_123657|    -- Evaluated 64 individuals.
21Feb12_123657|    Summary of generation 2:
21Feb12_123657| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_123657|-----------  ------------------  --------------------  ----------
21Feb12_123657|    Max            42.17                69.00           0.77448
21Feb12_123657|    Avg            41.42                19.09           0.02444
21Feb12_123657|    Min            23.57                 2.00           0.00000
21Feb12_123657|    Std             2.98                15.32           0.12124
21Feb12_123657|   Best            23.57                39.00           0.77448
21Feb12_123657|-- Generation 3 --
21Feb12_123657|    -- Crossed 0 individual pairs.
21Feb12_123657|    -- Mutated 32 individuals.
21Feb12_124048|    -- Evaluated 64 individuals.
21Feb12_124048|    Summary of generation 3:
21Feb12_124048| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_124048|-----------  ------------------  --------------------  ----------
21Feb12_124048|    Max            47.13                81.00           0.80640
21Feb12_124048|    Avg            41.02                18.70           0.05562
21Feb12_124048|    Min            23.30                 2.00           0.00000
21Feb12_124048|    Std             4.02                17.53           0.18571
21Feb12_124048|   Best            23.30                39.00           0.73861
21Feb12_124048|-- Generation 4 --
21Feb12_124048|    -- Crossed 3 individual pairs.
21Feb12_124048|    -- Mutated 32 individuals.
21Feb12_124438|    -- Evaluated 64 individuals.
21Feb12_124438|    Summary of generation 4:
21Feb12_124438| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_124438|-----------  ------------------  --------------------  ----------
21Feb12_124438|    Max            42.26                69.00           0.56244
21Feb12_124438|    Avg            41.37                16.39           0.02299
21Feb12_124438|    Min            26.17                 2.00           0.00000
21Feb12_124438|    Std             2.82                16.75           0.09852
21Feb12_124438|   Best            26.17                16.00           0.56244
21Feb12_124438|-- Generation 5 --
21Feb12_124438|    -- Crossed 2 individual pairs.
21Feb12_124438|    -- Mutated 32 individuals.
21Feb12_124828|    -- Evaluated 64 individuals.
21Feb12_124828|    Summary of generation 5:
21Feb12_124828| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_124828|-----------  ------------------  --------------------  ----------
21Feb12_124828|    Max            42.17                69.00           0.83333
21Feb12_124828|    Avg            41.01                13.59           0.05085
21Feb12_124828|    Min            22.87                 2.00           0.00000
21Feb12_124828|    Std             3.68                15.07           0.17747
21Feb12_124828|   Best            22.87                39.00           0.83073
21Feb12_124828|-- Generation 6 --
21Feb12_124828|    -- Crossed 2 individual pairs.
21Feb12_124828|    -- Mutated 32 individuals.
21Feb12_125217|    -- Evaluated 64 individuals.
21Feb12_125217|    Summary of generation 6:
21Feb12_125217| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_125217|-----------  ------------------  --------------------  ----------
21Feb12_125217|    Max            42.17                84.00           0.78759
21Feb12_125217|    Avg            40.48                14.56           0.05948
21Feb12_125217|    Min            23.74                 2.00           0.00000
21Feb12_125217|    Std             4.53                16.75           0.17376
21Feb12_125217|   Best            23.74                36.00           0.78759
21Feb12_125217|-- Generation 7 --
21Feb12_125217|    -- Crossed 4 individual pairs.
21Feb12_125217|    -- Mutated 32 individuals.
21Feb12_125606|    -- Evaluated 64 individuals.
21Feb12_125606|    Summary of generation 7:
21Feb12_125606| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_125606|-----------  ------------------  --------------------  ----------
21Feb12_125606|    Max            42.70                69.00           0.63652
21Feb12_125606|    Avg            40.95                14.59           0.03847
21Feb12_125606|    Min            25.22                 2.00           0.00000
21Feb12_125606|    Std             3.61                15.07           0.13030
21Feb12_125606|   Best            25.22                16.00           0.63652
21Feb12_125606|-- Generation 8 --
21Feb12_125606|    -- Crossed 4 individual pairs.
21Feb12_125606|    -- Mutated 32 individuals.
21Feb12_125956|    -- Evaluated 64 individuals.
21Feb12_125956|    Summary of generation 8:
21Feb12_125956| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_125956|-----------  ------------------  --------------------  ----------
21Feb12_125956|    Max            42.35                69.00           0.61002
21Feb12_125956|    Avg            40.90                14.89           0.03990
21Feb12_125956|    Min            24.87                 2.00           0.00000
21Feb12_125956|    Std             3.76                17.31           0.13434
21Feb12_125956|   Best            24.87                16.00           0.61002
21Feb12_125956|-- Generation 9 --
21Feb12_125956|    -- Crossed 0 individual pairs.
21Feb12_125956|    -- Mutated 32 individuals.
21Feb12_130346|    -- Evaluated 64 individuals.
21Feb12_130346|    Summary of generation 9:
21Feb12_130346| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_130346|-----------  ------------------  --------------------  ----------
21Feb12_130346|    Max            42.26                69.00           0.64606
21Feb12_130346|    Avg            40.35                13.11           0.06302
21Feb12_130346|    Min            25.22                 2.00           0.00000
21Feb12_130346|    Std             4.55                16.08           0.16969
21Feb12_130346|   Best            25.22                16.00           0.64606
21Feb12_130346|-- Generation 10 --
21Feb12_130346|    -- Crossed 4 individual pairs.
21Feb12_130346|    -- Mutated 32 individuals.
21Feb12_130736|    -- Evaluated 64 individuals.
21Feb12_130736|    Summary of generation 10:
21Feb12_130736| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_130736|-----------  ------------------  --------------------  ----------
21Feb12_130736|    Max            42.17                69.00           0.80716
21Feb12_130736|    Avg            39.99                13.47           0.08716
21Feb12_130736|    Min            24.70                 2.00           0.00000
21Feb12_130736|    Std             4.64                15.52           0.19730
21Feb12_130736|   Best            24.70                16.00           0.68800
21Feb12_130736|-- Generation 11 --
21Feb12_130736|    -- Crossed 3 individual pairs.
21Feb12_130736|    -- Mutated 32 individuals.
21Feb12_131131|    -- Evaluated 64 individuals.
21Feb12_131131|    Summary of generation 11:
21Feb12_131131| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_131131|-----------  ------------------  --------------------  ----------
21Feb12_131131|    Max            42.96                72.00           0.79737
21Feb12_131131|    Avg            38.85                18.91           0.13601
21Feb12_131131|    Min            25.22                 3.00           0.00000
21Feb12_131131|    Std             5.72                18.16           0.24832
21Feb12_131131|   Best            25.22                16.00           0.61552
21Feb12_131131|-- Generation 12 --
21Feb12_131131|    -- Crossed 2 individual pairs.
21Feb12_131131|    -- Mutated 32 individuals.
21Feb12_131526|    -- Evaluated 64 individuals.
21Feb12_131526|    Summary of generation 12:
21Feb12_131526| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_131526|-----------  ------------------  --------------------  ----------
21Feb12_131526|    Max            48.61                69.00           0.82301
21Feb12_131526|    Avg            39.49                17.89           0.13345
21Feb12_131526|    Min            24.35                 3.00           0.00000
21Feb12_131526|    Std             5.49                17.85           0.24811
21Feb12_131526|   Best            24.35                18.00           0.66298
21Feb12_131526|-- Generation 13 --
21Feb12_131526|    -- Crossed 4 individual pairs.
21Feb12_131526|    -- Mutated 32 individuals.
21Feb12_131919|    -- Evaluated 64 individuals.
21Feb12_131919|    Summary of generation 13:
21Feb12_131919| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_131919|-----------  ------------------  --------------------  ----------
21Feb12_131919|    Max            42.00                100.00          0.83722
21Feb12_131919|    Avg            39.04                18.58           0.11797
21Feb12_131919|    Min            22.52                 2.00           0.00000
21Feb12_131919|    Std             5.64                20.95           0.22776
21Feb12_131919|   Best            22.52                16.00           0.66107
21Feb12_131919|-- Generation 14 --
21Feb12_131919|    -- Crossed 6 individual pairs.
21Feb12_131919|    -- Mutated 32 individuals.
21Feb12_132311|    -- Evaluated 64 individuals.
21Feb12_132311|    Summary of generation 14:
21Feb12_132311| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_132311|-----------  ------------------  --------------------  ----------
21Feb12_132311|    Max            42.17                69.00           0.84746
21Feb12_132311|    Avg            37.94                16.86           0.15684
21Feb12_132311|    Min            22.96                 2.00           0.00000
21Feb12_132311|    Std             6.46                17.04           0.25696
21Feb12_132311|   Best            22.96                16.00           0.81597
21Feb12_132311|-- Generation 15 --
21Feb12_132311|    -- Crossed 5 individual pairs.
21Feb12_132311|    -- Mutated 32 individuals.
21Feb12_132708|    -- Evaluated 64 individuals.
21Feb12_132708|    Summary of generation 15:
21Feb12_132708| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_132708|-----------  ------------------  --------------------  ----------
21Feb12_132708|    Max            42.26                100.00          0.77014
21Feb12_132708|    Avg            37.31                21.56           0.17726
21Feb12_132708|    Min            20.35                 2.00           0.00000
21Feb12_132708|    Std             6.67                19.86           0.25490
21Feb12_132708|   Best            20.35                100.00          0.72693
21Feb12_132708|-- Generation 16 --
21Feb12_132708|    -- Crossed 1 individual pairs.
21Feb12_132708|    -- Mutated 32 individuals.
21Feb12_133108|    -- Evaluated 64 individuals.
21Feb12_133108|    Summary of generation 16:
21Feb12_133108| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_133108|-----------  ------------------  --------------------  ----------
21Feb12_133108|    Max            42.26                100.00          0.81746
21Feb12_133108|    Avg            35.95                29.59           0.22709
21Feb12_133108|    Min            20.61                 2.00           0.00000
21Feb12_133108|    Std             7.42                23.78           0.27775
21Feb12_133108|   Best            20.61                60.00           0.79075
21Feb12_133108|-- Generation 17 --
21Feb12_133108|    -- Crossed 2 individual pairs.
21Feb12_133108|    -- Mutated 32 individuals.
21Feb12_133510|    -- Evaluated 64 individuals.
21Feb12_133510|    Summary of generation 17:
21Feb12_133510| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_133510|-----------  ------------------  --------------------  ----------
21Feb12_133510|    Max            42.26                100.00          0.82125
21Feb12_133510|    Avg            34.36                37.55           0.30199
21Feb12_133510|    Min            20.17                 6.00           0.00000
21Feb12_133510|    Std             7.33                26.03           0.29436
21Feb12_133510|   Best            20.17                100.00          0.77696
21Feb12_133510|-- Generation 18 --
21Feb12_133510|    -- Crossed 0 individual pairs.
21Feb12_133510|    -- Mutated 32 individuals.
21Feb12_133915|    -- Evaluated 64 individuals.
21Feb12_133915|    Summary of generation 18:
21Feb12_133915| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_133915|-----------  ------------------  --------------------  ----------
21Feb12_133915|    Max            42.61                100.00          0.85747
21Feb12_133915|    Avg            33.54                38.75           0.34647
21Feb12_133915|    Min            21.91                 6.00           0.00000
21Feb12_133915|    Std             7.32                25.72           0.30626
21Feb12_133915|   Best            21.91                60.00           0.85747
21Feb12_133915|-- Generation 19 --
21Feb12_133915|    -- Crossed 2 individual pairs.
21Feb12_133915|    -- Mutated 32 individuals.
21Feb12_134320|    -- Evaluated 64 individuals.
21Feb12_134320|    Summary of generation 19:
21Feb12_134320| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_134320|-----------  ------------------  --------------------  ----------
21Feb12_134320|    Max            42.17                105.00          0.83987
21Feb12_134320|    Avg            32.64                45.22           0.38888
21Feb12_134320|    Min            21.13                 6.00           0.00000
21Feb12_134320|    Std             7.53                26.15           0.31329
21Feb12_134320|   Best            21.13                100.00          0.83987
21Feb12_134320|-- Generation 20 --
21Feb12_134320|    -- Crossed 1 individual pairs.
21Feb12_134320|    -- Mutated 32 individuals.
21Feb12_134729|    -- Evaluated 64 individuals.
21Feb12_134729|    Summary of generation 20:
21Feb12_134729| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_134729|-----------  ------------------  --------------------  ----------
21Feb12_134729|    Max            42.09                105.00          0.85815
21Feb12_134729|    Avg            32.12                48.23           0.41789
21Feb12_134729|    Min            21.13                 6.00           0.00000
21Feb12_134729|    Std             7.44                25.59           0.32446
21Feb12_134729|   Best            21.13                60.00           0.79984
21Feb12_134729|-- Generation 21 --
21Feb12_134729|    -- Crossed 1 individual pairs.
21Feb12_134729|    -- Mutated 32 individuals.
21Feb12_135140|    -- Evaluated 64 individuals.
21Feb12_135140|    Summary of generation 21:
21Feb12_135140| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_135140|-----------  ------------------  --------------------  ----------
21Feb12_135140|    Max            42.26                132.00          0.84496
21Feb12_135140|    Avg            34.69                52.94           0.31010
21Feb12_135140|    Min            22.17                 6.00           0.00000
21Feb12_135140|    Std             7.72                29.75           0.33481
21Feb12_135140|   Best            22.17                60.00           0.80279
21Feb12_135140|-- Generation 22 --
21Feb12_135140|    -- Crossed 0 individual pairs.
21Feb12_135140|    -- Mutated 32 individuals.
21Feb12_135551|    -- Evaluated 64 individuals.
21Feb12_135551|    Summary of generation 22:
21Feb12_135551| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_135551|-----------  ------------------  --------------------  ----------
21Feb12_135551|    Max            42.35                132.00          0.83965
21Feb12_135551|    Avg            33.49                52.17           0.35805
21Feb12_135551|    Min            22.70                16.00           0.00000
21Feb12_135551|    Std             7.75                29.32           0.33553
21Feb12_135551|   Best            22.70                56.00           0.75368
21Feb12_135551|-- Generation 23 --
21Feb12_135551|    -- Crossed 1 individual pairs.
21Feb12_135551|    -- Mutated 32 individuals.
21Feb12_140004|    -- Evaluated 64 individuals.
21Feb12_140004|    Summary of generation 23:
21Feb12_140004| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_140004|-----------  ------------------  --------------------  ----------
21Feb12_140004|    Max            53.22                105.00          0.85496
21Feb12_140004|    Avg            32.50                60.30           0.41965
21Feb12_140004|    Min            22.09                16.00           0.00000
21Feb12_140004|    Std             8.24                26.92           0.33748
21Feb12_140004|   Best            22.09                105.00          0.73998
21Feb12_140004|-- Generation 24 --
21Feb12_140004|    -- Crossed 0 individual pairs.
21Feb12_140004|    -- Mutated 32 individuals.
21Feb12_140423|    -- Evaluated 64 individuals.
21Feb12_140423|    Summary of generation 24:
21Feb12_140423| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_140423|-----------  ------------------  --------------------  ----------
21Feb12_140423|    Max            44.09                144.00          0.83750
21Feb12_140423|    Avg            29.85                70.61           0.54612
21Feb12_140423|    Min            19.83                16.00           0.00000
21Feb12_140423|    Std             7.86                25.22           0.32475
21Feb12_140423|   Best            19.83                105.00          0.82233
21Feb12_140423|-- Generation 25 --
21Feb12_140423|    -- Crossed 1 individual pairs.
21Feb12_140423|    -- Mutated 32 individuals.
21Feb12_140846|    -- Evaluated 64 individuals.
21Feb12_140846|    Summary of generation 25:
21Feb12_140846| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_140846|-----------  ------------------  --------------------  ----------
21Feb12_140846|    Max            42.00                150.00          0.83173
21Feb12_140846|    Avg            31.06                78.98           0.46278
21Feb12_140846|    Min            20.52                30.00           0.00000
21Feb12_140846|    Std             8.36                25.87           0.34525
21Feb12_140846|   Best            20.52                60.00           0.79108
21Feb12_140846|-- Generation 26 --
21Feb12_140846|    -- Crossed 0 individual pairs.
21Feb12_140846|    -- Mutated 32 individuals.
21Feb12_141309|    -- Evaluated 64 individuals.
21Feb12_141309|    Summary of generation 26:
21Feb12_141309| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_141309|-----------  ------------------  --------------------  ----------
21Feb12_141309|    Max            42.52                156.00          0.83811
21Feb12_141309|    Avg            30.60                79.92           0.48856
21Feb12_141309|    Min            20.78                33.00           0.00000
21Feb12_141309|    Std             8.11                27.05           0.34749
21Feb12_141309|   Best            20.78                56.00           0.82540
21Feb12_141309|-- Generation 27 --
21Feb12_141309|    -- Crossed 1 individual pairs.
21Feb12_141309|    -- Mutated 32 individuals.
21Feb12_141731|    -- Evaluated 64 individuals.
21Feb12_141731|    Summary of generation 27:
21Feb12_141731| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_141731|-----------  ------------------  --------------------  ----------
21Feb12_141731|    Max            42.09                150.00          0.85078
21Feb12_141731|    Avg            31.55                82.88           0.45977
21Feb12_141731|    Min            19.83                33.00           0.00000
21Feb12_141731|    Std             8.34                27.96           0.36107
21Feb12_141731|   Best            19.83                100.00          0.75240
21Feb12_141731|-- Generation 28 --
21Feb12_141731|    -- Crossed 2 individual pairs.
21Feb12_141731|    -- Mutated 32 individuals.
21Feb12_142156|    -- Evaluated 64 individuals.
21Feb12_142156|    Summary of generation 28:
21Feb12_142156| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_142156|-----------  ------------------  --------------------  ----------
21Feb12_142156|    Max            43.22                156.00          0.86466
21Feb12_142156|    Avg            28.73                85.92           0.57443
21Feb12_142156|    Min            20.43                30.00           0.00000
21Feb12_142156|    Std             7.40                30.22           0.31376
21Feb12_142156|   Best            20.43                144.00          0.81059
21Feb12_142156|-- Generation 29 --
21Feb12_142156|    -- Crossed 1 individual pairs.
21Feb12_142156|    -- Mutated 32 individuals.
21Feb12_142619|    -- Evaluated 64 individuals.
21Feb12_142619|    Summary of generation 29:
21Feb12_142619| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_142619|-----------  ------------------  --------------------  ----------
21Feb12_142619|    Max            42.00                156.00          0.85180
21Feb12_142619|    Avg            30.14                86.36           0.51283
21Feb12_142619|    Min            22.09                14.00           0.00000
21Feb12_142619|    Std             7.90                32.18           0.34219
21Feb12_142619|   Best            22.09                105.00          0.72678
21Feb12_142619|-- Generation 30 --
21Feb12_142619|    -- Crossed 0 individual pairs.
21Feb12_142619|    -- Mutated 32 individuals.
21Feb12_143043|    -- Evaluated 64 individuals.
21Feb12_143043|    Summary of generation 30:
21Feb12_143043| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_143043|-----------  ------------------  --------------------  ----------
21Feb12_143043|    Max            42.17                162.00          0.84952
21Feb12_143043|    Avg            31.55                90.19           0.48011
21Feb12_143043|    Min            20.09                30.00           0.00000
21Feb12_143043|    Std             8.15                35.03           0.35609
21Feb12_143043|   Best            20.09                100.00          0.81865
21Feb12_143043|-- Generation 31 --
21Feb12_143043|    -- Crossed 1 individual pairs.
21Feb12_143043|    -- Mutated 32 individuals.
21Feb12_143510|    -- Evaluated 64 individuals.
21Feb12_143510|    Summary of generation 31:
21Feb12_143510| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_143510|-----------  ------------------  --------------------  ----------
21Feb12_143510|    Max            42.09                196.00          0.84130
21Feb12_143510|    Avg            30.23                96.41           0.49318
21Feb12_143510|    Min            21.04                30.00           0.00000
21Feb12_143510|    Std             8.07                34.03           0.34097
21Feb12_143510|   Best            21.04                60.00           0.78081
21Feb12_143510|-- Generation 32 --
21Feb12_143510|    -- Crossed 1 individual pairs.
21Feb12_143510|    -- Mutated 32 individuals.
21Feb12_143936|    -- Evaluated 64 individuals.
21Feb12_143936|    Summary of generation 32:
21Feb12_143936| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_143936|-----------  ------------------  --------------------  ----------
21Feb12_143936|    Max            42.00                161.00          0.82494
21Feb12_143936|    Avg            30.43                97.69           0.50259
21Feb12_143936|    Min            20.00                36.00           0.00000
21Feb12_143936|    Std             8.38                32.89           0.34659
21Feb12_143936|   Best            20.00                156.00          0.70849
21Feb12_143936|Best initial individual weights
21Feb12_143936|Individual:
21Feb12_143936|-- Constant hidden layers --
21Feb12_143936|False
21Feb12_143936|Layer 0:
21Feb12_143936|-- Config --
21Feb12_143936|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_143936|-- Weights --
21Feb12_143936|[[-0.95981  0.63808 -0.95380]
21Feb12_143936| [ 0.00520 -0.99353  0.50361]
21Feb12_143936| [-0.11451 -0.83347 -0.55396]
21Feb12_143936| [ 0.35657 -0.33319  0.99061]
21Feb12_143936| [ 0.20904  0.47603  0.54306]
21Feb12_143936| [ 0.86632  0.13678 -0.77041]
21Feb12_143936| [-0.35567 -0.99164  0.62727]
21Feb12_143936| [-0.68497  0.10640 -0.05172]
21Feb12_143936| [-0.59737 -0.00964  0.88158]
21Feb12_143936| [-0.13985 -0.06300 -0.43706]
21Feb12_143936| [ 0.64358  0.92937 -0.73432]
21Feb12_143936| [ 0.23476  0.78313  0.56825]
21Feb12_143936| [-0.54321  0.72471  0.37840]
21Feb12_143936| [-0.42357 -0.01577 -0.17096]
21Feb12_143936| [ 0.72075  0.01528 -0.53335]
21Feb12_143936| [-0.85291 -0.95287  0.91534]
21Feb12_143936| [-0.32401 -0.26906  0.15748]
21Feb12_143936| [-0.40109 -0.17141  0.12077]
21Feb12_143936| [ 0.06946 -0.71844 -0.65437]
21Feb12_143936| [ 0.77536 -0.87117  0.40091]
21Feb12_143936| [ 0.71219 -0.55029 -0.47352]
21Feb12_143936| [-0.48247 -0.59676 -0.13973]
21Feb12_143936| [ 0.29835 -0.64235  0.86195]
21Feb12_143936| [ 0.76225  0.85104  0.00830]
21Feb12_143936| [ 0.47868 -0.29509  0.58927]
21Feb12_143936| [ 0.44057 -0.21842 -0.84593]
21Feb12_143936| [-0.45754  0.53879  0.95554]
21Feb12_143936| [-0.76945 -0.60835  0.71744]
21Feb12_143936| [ 0.53999  0.63134  0.43758]
21Feb12_143936| [-0.19306 -0.59818  0.19108]
21Feb12_143936| [-0.51517  0.85226  0.38538]
21Feb12_143936| [-0.79126 -0.93873  0.01578]
21Feb12_143936| [-0.50150 -0.14594 -0.18067]
21Feb12_143936| [ 0.61416 -0.70576  0.33529]
21Feb12_143936| [ 0.15072  0.89141  0.54784]
21Feb12_143936| [ 0.36697  0.31313 -0.13077]
21Feb12_143936| [ 0.69307 -0.37869  0.20694]
21Feb12_143936| [ 0.03015  0.15728  0.76226]
21Feb12_143936| [ 0.77952 -0.76856 -0.43483]
21Feb12_143936| [-0.61518 -0.05786  0.81156]
21Feb12_143936| [ 0.84017 -0.42741  0.60340]
21Feb12_143936| [ 0.53666 -0.82919  0.07802]
21Feb12_143936| [ 0.47864  0.69058 -0.97920]
21Feb12_143936| [ 0.68760  0.30748  0.39424]
21Feb12_143936| [ 0.18427  0.64362  0.23634]
21Feb12_143936| [-0.94644 -0.07451 -0.16574]
21Feb12_143936| [-0.96084  0.12874 -0.86066]
21Feb12_143936| [-0.56938  0.44358  0.07698]
21Feb12_143936| [-0.21143  0.88977 -0.62804]
21Feb12_143936| [-0.49083  0.36500  0.15463]
21Feb12_143936| [-0.68978  0.96064  0.44141]
21Feb12_143936| [-0.21911  0.93693  0.42766]
21Feb12_143936| [ 0.30992 -0.75633  0.40386]
21Feb12_143936| [-0.38889 -0.87472 -0.60032]
21Feb12_143936| [ 0.63181  0.38743  0.42944]
21Feb12_143936| [-0.36880  0.75866  0.06497]
21Feb12_143936| [ 0.95225  0.89125  0.24472]]
21Feb12_143936|-- Bias --
21Feb12_143936|[-0.87203 -0.18510 -0.82395]
21Feb12_143936|Layer 1:
21Feb12_143936|-- Config --
21Feb12_143936|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 9, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_143936|-- Weights --
21Feb12_143936|[[-0.48876  0.92140 -0.21669  0.72465 -0.25318 -0.77574 -0.72806 -0.41561
21Feb12_143936|   0.09470]
21Feb12_143936| [ 0.16540 -0.74164  0.12712 -0.17055  0.32434  0.08465 -0.18577  0.93967
21Feb12_143936|   0.13630]
21Feb12_143936| [ 0.51611  0.56311  0.06727  0.75197 -0.15192  0.43301 -0.52005  0.07976
21Feb12_143936|  -0.84277]]
21Feb12_143936|-- Bias --
21Feb12_143936|[ 0.32558  0.84726 -0.20681  0.97295  0.68375 -0.70571 -0.86307 -0.88871
21Feb12_143936|  0.55514]
21Feb12_143936|Layer 2:
21Feb12_143936|-- Config --
21Feb12_143936|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 9], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_143936|-- Weights --
21Feb12_143936|[[ 0.76468  0.30035]
21Feb12_143936| [-0.84449  0.54167]
21Feb12_143936| [-0.04649 -0.86516]
21Feb12_143936| [-0.11365 -0.30894]
21Feb12_143936| [ 0.95453  0.69955]
21Feb12_143936| [ 0.56339  0.48813]
21Feb12_143936| [-0.11587 -0.35680]
21Feb12_143936| [ 0.67275  0.94171]
21Feb12_143936| [ 0.44550 -0.58681]]
21Feb12_143936|-- Bias --
21Feb12_143936|[0.41147 0.60365]
21Feb12_143936|Predicting the validation and test data with the Best initial individual.
21Feb12_143943| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_143943|-----------  ------------------  --------------------  ----------
21Feb12_143943|Validation         42.17                  24            0.00000
21Feb12_143943|   Test            36.40                  24            0.00000
21Feb12_143943|-------------------- Test #0 --------------------
21Feb12_143943|Best final individual weights
21Feb12_143943|Individual:
21Feb12_143943|-- Constant hidden layers --
21Feb12_143943|False
21Feb12_143943|Layer 0:
21Feb12_143943|-- Config --
21Feb12_143943|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_143943|-- Weights --
21Feb12_143943|[[-1.00900  0.18252  1.10044  0.29024  1.31204 -1.15151]
21Feb12_143943| [-2.44628 -0.37596 -1.43390 -1.12203 -0.04904  0.52843]
21Feb12_143943| [ 1.20049  0.03592 -0.21372  1.81446  0.86713  1.56757]
21Feb12_143943| [ 2.10403  1.12072  0.35379  0.07725 -1.49841  0.84359]
21Feb12_143943| [ 0.66667 -0.28431  0.74459  0.61496  0.80113  0.30739]
21Feb12_143943| [-0.96340  1.34729 -0.21719 -0.66682 -2.03598  0.40019]
21Feb12_143943| [-0.52124  0.08105  1.42824  0.49110 -0.04806 -0.23947]
21Feb12_143943| [ 1.14738 -0.76638  1.01210  0.27597 -0.71484  1.35432]
21Feb12_143943| [ 0.02902  1.74896 -0.19677  0.12664 -0.39990 -1.36148]
21Feb12_143943| [ 1.24576  0.19537 -0.64164  0.34542  0.54807  0.55545]
21Feb12_143943| [ 0.66620 -0.26547 -0.83577 -1.26238  0.37798 -0.27613]
21Feb12_143943| [-0.78657  0.83312 -0.98676  1.20478  0.21291 -0.93913]
21Feb12_143943| [-1.37418  0.82481 -0.15928 -1.80645  1.44130  0.21421]
21Feb12_143943| [-0.02044  0.93685  1.06133  0.15770 -0.50533 -1.09024]
21Feb12_143943| [-0.04234  1.30144  0.06884 -0.63179 -0.33612  0.07686]
21Feb12_143943| [-0.33875 -0.07463 -0.14142  1.60381 -1.09643 -1.40030]
21Feb12_143943| [ 1.53350  0.61559  0.86519 -0.23458  0.86752 -0.45258]
21Feb12_143943| [-0.21733 -0.94093  0.35488 -0.63081  1.23490 -0.10059]
21Feb12_143943| [ 1.10482 -0.54999  0.06361 -0.98467  0.98841  1.10716]
21Feb12_143943| [ 0.48921  0.35977 -0.87615  1.31654  1.70644 -0.91750]
21Feb12_143943| [ 2.72869 -0.10064  1.03767 -0.61647  1.42380  1.84019]
21Feb12_143943| [-0.53304  0.42354  1.13694 -2.14180 -0.47781  0.29236]
21Feb12_143943| [-0.33778 -0.39475  0.16332 -0.15763 -0.49919 -0.89460]
21Feb12_143943| [-1.04280 -1.56283  0.36626 -0.25201 -0.28858 -1.36344]
21Feb12_143943| [-1.08871 -1.64602  0.54402  0.43907 -2.00973 -1.48787]
21Feb12_143943| [-0.21181 -0.73556 -1.98945  1.41692  0.93706 -0.25636]
21Feb12_143943| [-1.55542  0.40630  0.31652 -1.02046 -0.27004  0.19632]
21Feb12_143943| [ 1.39783 -0.54885  0.68391  1.57307 -1.07495  1.12532]
21Feb12_143943| [-0.76201 -0.04218 -0.57011 -0.52083  0.43830  2.59180]
21Feb12_143943| [-0.21753  0.04696  2.21389  2.09894 -0.29473  0.68414]
21Feb12_143943| [ 0.01575 -1.03633 -0.32878  0.69735  1.18392  0.72893]
21Feb12_143943| [-0.19264 -1.26455 -0.63480  0.76464  0.89465 -1.71142]
21Feb12_143943| [ 0.02632 -1.91608  1.58659 -0.29071  2.02573  0.03414]
21Feb12_143943| [ 1.65020 -1.27293  0.34686 -1.19815 -1.32648 -1.26882]
21Feb12_143943| [ 2.69540 -0.32808  0.31202  0.80343 -0.95016  0.44790]
21Feb12_143943| [ 0.77228  0.03163 -1.91777  0.35090 -0.34457 -1.97053]
21Feb12_143943| [ 0.56983  0.05254  1.79141  1.05885  0.24739  0.36784]
21Feb12_143943| [ 0.68847 -0.90965  0.74557 -0.99403 -1.26981 -0.61634]
21Feb12_143943| [ 0.70687  0.84294  0.57884  0.20303 -1.08778  2.00826]
21Feb12_143943| [-0.88282  0.60747 -0.54714  1.12710  0.50134  0.57920]
21Feb12_143943| [ 1.36840  0.32126 -1.29974 -0.51943 -0.41930  0.67669]
21Feb12_143943| [-0.04632 -1.30195  0.14846 -0.10446 -1.10160 -0.09529]
21Feb12_143943| [ 0.65238  0.67989 -1.96791 -1.53567 -0.85830  0.09371]
21Feb12_143943| [-0.06946  1.00221  0.03059 -0.89911 -0.41538  0.81783]
21Feb12_143943| [ 0.93359 -0.22642 -2.16799 -0.16258 -0.33185 -0.54353]
21Feb12_143943| [-0.73116  0.05803 -0.19415 -2.32698 -0.07218  0.41897]
21Feb12_143943| [ 0.01372 -1.72754  0.13547 -0.00512  0.42455 -0.36913]
21Feb12_143943| [ 1.66177  0.06579 -0.91003 -1.96934 -0.23352  1.08777]
21Feb12_143943| [ 0.09289 -1.82141 -0.78890 -2.16661  0.40321 -1.07977]
21Feb12_143943| [ 0.03205  1.35989 -0.58023  0.87747  0.15330  0.70902]
21Feb12_143943| [-0.88917 -0.10020  0.33811 -0.64537  1.24566  0.38907]
21Feb12_143943| [ 0.62530 -0.80583 -0.72489  0.51594 -1.46419 -0.95670]
21Feb12_143943| [ 0.84186  1.56276 -0.63387 -0.77819  0.18843  1.33647]
21Feb12_143943| [ 0.48085  1.19299  0.22441 -0.65616  1.25472  0.11685]
21Feb12_143943| [ 1.05217  0.40591 -1.84754 -2.43144  0.60234 -0.12202]
21Feb12_143943| [-0.00812 -1.37629  1.18334  0.13408  3.24150  0.05204]
21Feb12_143943| [ 0.28646 -0.47090 -1.33980 -0.75876 -0.74237  0.09620]]
21Feb12_143943|-- Bias --
21Feb12_143943|[-0.99248 -0.71563 -0.78878  0.27988  0.06431 -0.58382]
21Feb12_143943|Layer 1:
21Feb12_143943|-- Config --
21Feb12_143943|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_143943|-- Weights --
21Feb12_143943|[[-0.74764  0.04173]
21Feb12_143943| [-0.52868  0.77131]
21Feb12_143943| [ 0.33829  0.18324]
21Feb12_143943| [ 0.05913 -2.08317]
21Feb12_143943| [ 0.46104  0.18919]
21Feb12_143943| [-1.26997 -1.60808]]
21Feb12_143943|-- Bias --
21Feb12_143943|[-0.91535  0.55242]
21Feb12_143943|Layer 2:
21Feb12_143943|-- Config --
21Feb12_143943|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_143943|-- Weights --
21Feb12_143943|[[-0.54781  0.50280 -0.20410]
21Feb12_143943| [ 0.61976 -0.03473 -0.21993]]
21Feb12_143943|-- Bias --
21Feb12_143943|[ 0.80186 -1.14980 -0.80324]
21Feb12_143943|Layer 3:
21Feb12_143943|-- Config --
21Feb12_143943|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_143943|-- Weights --
21Feb12_143943|[[-0.23693 -0.18694 -0.06836 -0.38083]
21Feb12_143943| [-0.18482 -0.74519  1.01192 -0.73306]
21Feb12_143943| [-1.34032 -1.90482  0.21049 -0.84424]]
21Feb12_143943|-- Bias --
21Feb12_143943|[-0.45480  0.22554  1.34863 -0.53238]
21Feb12_143943|Layer 4:
21Feb12_143943|-- Config --
21Feb12_143943|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_143943|-- Weights --
21Feb12_143943|[[ 1.38774  1.08699 -0.77759  0.56311 -1.77299]
21Feb12_143943| [ 0.28391 -0.10364 -1.12276 -0.52361  0.09630]
21Feb12_143943| [-0.52512 -0.16867 -1.87508  0.57790 -1.21581]
21Feb12_143943| [ 0.13746  0.45911 -0.92657  0.25726 -0.74730]]
21Feb12_143943|-- Bias --
21Feb12_143943|[-0.14276  0.44395 -0.44961  0.47833 -0.07693]
21Feb12_143943|Layer 5:
21Feb12_143943|-- Config --
21Feb12_143943|{'name': 'Hidden6', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_143943|-- Weights --
21Feb12_143943|[[-0.96618  0.96909 -0.48297 -1.11889  0.70384  0.27997]
21Feb12_143943| [-1.09513 -0.74822  0.54830  0.05093  1.12909  0.21934]
21Feb12_143943| [-0.21483 -0.43027  0.98052 -0.42408 -0.95917 -0.04963]
21Feb12_143943| [ 0.14881 -0.12743 -1.24908 -0.70705 -0.62287  0.12561]
21Feb12_143943| [-0.36569  1.22889 -0.25290  0.99234 -0.08906 -0.31559]]
21Feb12_143943|-- Bias --
21Feb12_143943|[ 0.67994  0.31382 -0.21719  0.20593  0.86896 -0.11833]
21Feb12_143943|Layer 6:
21Feb12_143943|-- Config --
21Feb12_143943|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_143943|-- Weights --
21Feb12_143943|[[ 0.53450  0.24174]
21Feb12_143943| [-0.24442 -0.59403]
21Feb12_143943| [ 2.07751  0.11893]
21Feb12_143943| [-1.08995 -1.42727]
21Feb12_143943| [-0.71218  1.91415]
21Feb12_143943| [-0.32732 -0.06770]]
21Feb12_143943|-- Bias --
21Feb12_143943|[ 1.42761 -1.28538]
21Feb12_143943|Predicting the validation and test data with the Best final individual.
21Feb12_143952| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_143952|-----------  ------------------  --------------------  ----------
21Feb12_143952|Validation         26.78                 156            0.56071
21Feb12_143952|   Test            22.50                 156            0.55041
21Feb12_143952|-------------------- Test #1 --------------------
21Feb12_143952|Best final individual weights
21Feb12_143952|Individual:
21Feb12_143952|-- Constant hidden layers --
21Feb12_143952|False
21Feb12_143952|Layer 0:
21Feb12_143952|-- Config --
21Feb12_143952|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_143952|-- Weights --
21Feb12_143952|[[-1.00900  0.18252  1.10044  0.29024  1.31204 -1.15151]
21Feb12_143952| [-2.44628 -0.37596 -1.43390 -1.12203 -0.04904  0.52843]
21Feb12_143952| [ 1.20049  0.03592 -0.21372  1.81446  0.86713  1.56757]
21Feb12_143952| [ 2.10403  1.12072  0.35379  0.07725 -1.49841  0.84359]
21Feb12_143952| [ 0.66667 -0.28431  0.74459  0.61496  0.80113  0.30739]
21Feb12_143952| [-0.96340  1.34729 -0.21719 -0.66682 -2.03598  0.40019]
21Feb12_143952| [-0.52124  0.08105  1.42824  0.49110 -0.04806 -0.23947]
21Feb12_143952| [ 1.14738 -0.76638  1.01210  0.27597 -0.71484  1.35432]
21Feb12_143952| [ 0.02902  1.74896 -0.19677  0.12664 -0.39990 -1.36148]
21Feb12_143952| [ 1.24576  0.19537 -0.64164  0.34542  0.54807  0.55545]
21Feb12_143952| [ 0.66620 -0.26547 -0.83577 -1.26238  0.37798 -0.27613]
21Feb12_143952| [-0.78657  0.83312 -0.98676  1.20478  0.21291 -0.93913]
21Feb12_143952| [-1.37418  0.82481 -0.15928 -1.80645  1.44130  0.21421]
21Feb12_143952| [-0.02044  0.93685  1.06133  0.15770 -0.50533 -1.09024]
21Feb12_143952| [-0.04234  1.30144  0.06884 -0.63179 -0.33612  0.07686]
21Feb12_143952| [-0.33875 -0.07463 -0.14142  1.60381 -1.09643 -1.40030]
21Feb12_143952| [ 1.53350  0.61559  0.86519 -0.23458  0.86752 -0.45258]
21Feb12_143952| [-0.21733 -0.94093  0.35488 -0.63081  1.23490 -0.10059]
21Feb12_143952| [ 1.10482 -0.54999  0.06361 -0.98467  0.98841  1.10716]
21Feb12_143952| [ 0.48921  0.35977 -0.87615  1.31654  1.70644 -0.91750]
21Feb12_143952| [ 2.72869 -0.10064  1.03767 -0.61647  1.42380  1.84019]
21Feb12_143952| [-0.53304  0.42354  1.13694 -2.14180 -0.47781  0.29236]
21Feb12_143952| [-0.33778 -0.39475  0.16332 -0.15763 -0.49919 -0.89460]
21Feb12_143952| [-1.04280 -1.56283  0.36626 -0.25201 -0.28858 -1.36344]
21Feb12_143952| [-1.08871 -1.64602  0.54402  0.43907 -2.00973 -1.48787]
21Feb12_143952| [-0.21181 -0.73556 -1.98945  1.41692  0.93706 -0.25636]
21Feb12_143952| [-1.55542  0.40630  0.31652 -1.02046 -0.27004  0.19632]
21Feb12_143952| [ 1.39783 -0.54885  0.68391  1.57307 -1.07495  1.12532]
21Feb12_143952| [-0.76201 -0.04218 -0.57011 -0.52083  0.43830  2.59180]
21Feb12_143952| [-0.21753  0.04696  2.21389  2.09894 -0.29473  0.68414]
21Feb12_143952| [ 0.01575 -1.03633 -0.32878  0.69735  1.18392  0.72893]
21Feb12_143952| [-0.19264 -1.26455 -0.63480  0.76464  0.89465 -1.71142]
21Feb12_143952| [ 0.02632 -1.91608  1.58659 -0.29071  2.02573  0.03414]
21Feb12_143952| [ 1.65020 -1.27293  0.34686 -1.19815 -1.32648 -1.26882]
21Feb12_143952| [ 2.69540 -0.32808  0.31202  0.80343 -0.95016  0.44790]
21Feb12_143952| [ 0.77228  0.03163 -1.91777  0.35090 -0.34457 -1.97053]
21Feb12_143952| [ 0.56983  0.05254  1.79141  1.05885  0.24739  0.36784]
21Feb12_143952| [ 0.68847 -0.90965  0.74557 -0.99403 -1.26981 -0.61634]
21Feb12_143952| [ 0.70687  0.84294  0.57884  0.20303 -1.08778  2.00826]
21Feb12_143952| [-0.88282  0.60747 -0.54714  1.12710  0.50134  0.57920]
21Feb12_143952| [ 1.36840  0.32126 -1.29974 -0.51943 -0.41930  0.67669]
21Feb12_143952| [-0.04632 -1.30195  0.14846 -0.10446 -1.10160 -0.09529]
21Feb12_143952| [ 0.65238  0.67989 -1.96791 -1.53567 -0.85830  0.09371]
21Feb12_143952| [-0.06946  1.00221  0.03059 -0.89911 -0.41538  0.81783]
21Feb12_143952| [ 0.93359 -0.22642 -2.16799 -0.16258 -0.33185 -0.54353]
21Feb12_143952| [-0.73116  0.05803 -0.19415 -2.32698 -0.07218  0.41897]
21Feb12_143952| [ 0.01372 -1.72754  0.13547 -0.00512  0.42455 -0.36913]
21Feb12_143952| [ 1.66177  0.06579 -0.91003 -1.96934 -0.23352  1.08777]
21Feb12_143952| [ 0.09289 -1.82141 -0.78890 -2.16661  0.40321 -1.07977]
21Feb12_143952| [ 0.03205  1.35989 -0.58023  0.87747  0.15330  0.70902]
21Feb12_143952| [-0.88917 -0.10020  0.33811 -0.64537  1.24566  0.38907]
21Feb12_143952| [ 0.62530 -0.80583 -0.72489  0.51594 -1.46419 -0.95670]
21Feb12_143952| [ 0.84186  1.56276 -0.63387 -0.77819  0.18843  1.33647]
21Feb12_143952| [ 0.48085  1.19299  0.22441 -0.65616  1.25472  0.11685]
21Feb12_143952| [ 1.05217  0.40591 -1.84754 -2.43144  0.60234 -0.12202]
21Feb12_143952| [-0.00812 -1.37629  1.18334  0.13408  3.24150  0.05204]
21Feb12_143952| [ 0.28646 -0.47090 -1.33980 -0.75876 -0.74237  0.09620]]
21Feb12_143952|-- Bias --
21Feb12_143952|[-0.99248 -0.71563 -0.78878  0.27988  0.06431 -0.58382]
21Feb12_143952|Layer 1:
21Feb12_143952|-- Config --
21Feb12_143952|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_143952|-- Weights --
21Feb12_143952|[[-0.74764  0.04173]
21Feb12_143952| [-0.52868  0.77131]
21Feb12_143952| [ 0.33829  0.18324]
21Feb12_143952| [ 0.05913 -2.08317]
21Feb12_143952| [ 0.46104  0.18919]
21Feb12_143952| [-1.26997 -1.60808]]
21Feb12_143952|-- Bias --
21Feb12_143952|[-0.91535  0.55242]
21Feb12_143952|Layer 2:
21Feb12_143952|-- Config --
21Feb12_143952|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_143952|-- Weights --
21Feb12_143952|[[-0.54781  0.50280 -0.20410]
21Feb12_143952| [ 0.61976 -0.03473 -0.21993]]
21Feb12_143952|-- Bias --
21Feb12_143952|[ 0.80186 -1.14980 -0.80324]
21Feb12_143952|Layer 3:
21Feb12_143952|-- Config --
21Feb12_143952|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_143952|-- Weights --
21Feb12_143952|[[-0.23693 -0.18694 -0.06836 -0.38083]
21Feb12_143952| [-0.18482 -0.74519  1.01192 -0.73306]
21Feb12_143952| [-1.34032 -1.90482  0.21049 -0.84424]]
21Feb12_143952|-- Bias --
21Feb12_143952|[-0.45480  0.22554  1.34863 -0.53238]
21Feb12_143952|Layer 4:
21Feb12_143952|-- Config --
21Feb12_143952|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_143952|-- Weights --
21Feb12_143952|[[ 1.38774  1.08699 -0.77759  0.56311 -1.77299]
21Feb12_143952| [ 0.28391 -0.10364 -1.12276 -0.52361  0.09630]
21Feb12_143952| [-0.52512 -0.16867 -1.87508  0.57790 -1.21581]
21Feb12_143952| [ 0.13746  0.45911 -0.92657  0.25726 -0.74730]]
21Feb12_143952|-- Bias --
21Feb12_143952|[-0.14276  0.44395 -0.44961  0.47833 -0.07693]
21Feb12_143952|Layer 5:
21Feb12_143952|-- Config --
21Feb12_143952|{'name': 'Hidden6', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_143952|-- Weights --
21Feb12_143952|[[-0.96618  0.96909 -0.48297 -1.11889  0.70384  0.27997]
21Feb12_143952| [-1.09513 -0.74822  0.54830  0.05093  1.12909  0.21934]
21Feb12_143952| [-0.21483 -0.43027  0.98052 -0.42408 -0.95917 -0.04963]
21Feb12_143952| [ 0.14881 -0.12743 -1.24908 -0.70705 -0.62287  0.12561]
21Feb12_143952| [-0.36569  1.22889 -0.25290  0.99234 -0.08906 -0.31559]]
21Feb12_143952|-- Bias --
21Feb12_143952|[ 0.67994  0.31382 -0.21719  0.20593  0.86896 -0.11833]
21Feb12_143952|Layer 6:
21Feb12_143952|-- Config --
21Feb12_143952|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_143952|-- Weights --
21Feb12_143952|[[ 0.53450  0.24174]
21Feb12_143952| [-0.24442 -0.59403]
21Feb12_143952| [ 2.07751  0.11893]
21Feb12_143952| [-1.08995 -1.42727]
21Feb12_143952| [-0.71218  1.91415]
21Feb12_143952| [-0.32732 -0.06770]]
21Feb12_143952|-- Bias --
21Feb12_143952|[ 1.42761 -1.28538]
21Feb12_143952|Predicting the validation and test data with the Best final individual.
21Feb12_144000| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_144000|-----------  ------------------  --------------------  ----------
21Feb12_144000|Validation         20.96                 156            0.71126
21Feb12_144000|   Test            36.40                 156            0.00000
21Feb12_144000|-------------------- Test #2 --------------------
21Feb12_144000|Best final individual weights
21Feb12_144000|Individual:
21Feb12_144000|-- Constant hidden layers --
21Feb12_144000|False
21Feb12_144000|Layer 0:
21Feb12_144000|-- Config --
21Feb12_144000|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144000|-- Weights --
21Feb12_144000|[[-1.00900  0.18252  1.10044  0.29024  1.31204 -1.15151]
21Feb12_144000| [-2.44628 -0.37596 -1.43390 -1.12203 -0.04904  0.52843]
21Feb12_144000| [ 1.20049  0.03592 -0.21372  1.81446  0.86713  1.56757]
21Feb12_144000| [ 2.10403  1.12072  0.35379  0.07725 -1.49841  0.84359]
21Feb12_144000| [ 0.66667 -0.28431  0.74459  0.61496  0.80113  0.30739]
21Feb12_144000| [-0.96340  1.34729 -0.21719 -0.66682 -2.03598  0.40019]
21Feb12_144000| [-0.52124  0.08105  1.42824  0.49110 -0.04806 -0.23947]
21Feb12_144000| [ 1.14738 -0.76638  1.01210  0.27597 -0.71484  1.35432]
21Feb12_144000| [ 0.02902  1.74896 -0.19677  0.12664 -0.39990 -1.36148]
21Feb12_144000| [ 1.24576  0.19537 -0.64164  0.34542  0.54807  0.55545]
21Feb12_144000| [ 0.66620 -0.26547 -0.83577 -1.26238  0.37798 -0.27613]
21Feb12_144000| [-0.78657  0.83312 -0.98676  1.20478  0.21291 -0.93913]
21Feb12_144000| [-1.37418  0.82481 -0.15928 -1.80645  1.44130  0.21421]
21Feb12_144000| [-0.02044  0.93685  1.06133  0.15770 -0.50533 -1.09024]
21Feb12_144000| [-0.04234  1.30144  0.06884 -0.63179 -0.33612  0.07686]
21Feb12_144000| [-0.33875 -0.07463 -0.14142  1.60381 -1.09643 -1.40030]
21Feb12_144000| [ 1.53350  0.61559  0.86519 -0.23458  0.86752 -0.45258]
21Feb12_144000| [-0.21733 -0.94093  0.35488 -0.63081  1.23490 -0.10059]
21Feb12_144000| [ 1.10482 -0.54999  0.06361 -0.98467  0.98841  1.10716]
21Feb12_144000| [ 0.48921  0.35977 -0.87615  1.31654  1.70644 -0.91750]
21Feb12_144000| [ 2.72869 -0.10064  1.03767 -0.61647  1.42380  1.84019]
21Feb12_144000| [-0.53304  0.42354  1.13694 -2.14180 -0.47781  0.29236]
21Feb12_144000| [-0.33778 -0.39475  0.16332 -0.15763 -0.49919 -0.89460]
21Feb12_144000| [-1.04280 -1.56283  0.36626 -0.25201 -0.28858 -1.36344]
21Feb12_144000| [-1.08871 -1.64602  0.54402  0.43907 -2.00973 -1.48787]
21Feb12_144000| [-0.21181 -0.73556 -1.98945  1.41692  0.93706 -0.25636]
21Feb12_144000| [-1.55542  0.40630  0.31652 -1.02046 -0.27004  0.19632]
21Feb12_144000| [ 1.39783 -0.54885  0.68391  1.57307 -1.07495  1.12532]
21Feb12_144000| [-0.76201 -0.04218 -0.57011 -0.52083  0.43830  2.59180]
21Feb12_144000| [-0.21753  0.04696  2.21389  2.09894 -0.29473  0.68414]
21Feb12_144000| [ 0.01575 -1.03633 -0.32878  0.69735  1.18392  0.72893]
21Feb12_144000| [-0.19264 -1.26455 -0.63480  0.76464  0.89465 -1.71142]
21Feb12_144000| [ 0.02632 -1.91608  1.58659 -0.29071  2.02573  0.03414]
21Feb12_144000| [ 1.65020 -1.27293  0.34686 -1.19815 -1.32648 -1.26882]
21Feb12_144000| [ 2.69540 -0.32808  0.31202  0.80343 -0.95016  0.44790]
21Feb12_144000| [ 0.77228  0.03163 -1.91777  0.35090 -0.34457 -1.97053]
21Feb12_144000| [ 0.56983  0.05254  1.79141  1.05885  0.24739  0.36784]
21Feb12_144000| [ 0.68847 -0.90965  0.74557 -0.99403 -1.26981 -0.61634]
21Feb12_144000| [ 0.70687  0.84294  0.57884  0.20303 -1.08778  2.00826]
21Feb12_144000| [-0.88282  0.60747 -0.54714  1.12710  0.50134  0.57920]
21Feb12_144000| [ 1.36840  0.32126 -1.29974 -0.51943 -0.41930  0.67669]
21Feb12_144000| [-0.04632 -1.30195  0.14846 -0.10446 -1.10160 -0.09529]
21Feb12_144000| [ 0.65238  0.67989 -1.96791 -1.53567 -0.85830  0.09371]
21Feb12_144000| [-0.06946  1.00221  0.03059 -0.89911 -0.41538  0.81783]
21Feb12_144000| [ 0.93359 -0.22642 -2.16799 -0.16258 -0.33185 -0.54353]
21Feb12_144000| [-0.73116  0.05803 -0.19415 -2.32698 -0.07218  0.41897]
21Feb12_144000| [ 0.01372 -1.72754  0.13547 -0.00512  0.42455 -0.36913]
21Feb12_144000| [ 1.66177  0.06579 -0.91003 -1.96934 -0.23352  1.08777]
21Feb12_144000| [ 0.09289 -1.82141 -0.78890 -2.16661  0.40321 -1.07977]
21Feb12_144000| [ 0.03205  1.35989 -0.58023  0.87747  0.15330  0.70902]
21Feb12_144000| [-0.88917 -0.10020  0.33811 -0.64537  1.24566  0.38907]
21Feb12_144000| [ 0.62530 -0.80583 -0.72489  0.51594 -1.46419 -0.95670]
21Feb12_144000| [ 0.84186  1.56276 -0.63387 -0.77819  0.18843  1.33647]
21Feb12_144000| [ 0.48085  1.19299  0.22441 -0.65616  1.25472  0.11685]
21Feb12_144000| [ 1.05217  0.40591 -1.84754 -2.43144  0.60234 -0.12202]
21Feb12_144000| [-0.00812 -1.37629  1.18334  0.13408  3.24150  0.05204]
21Feb12_144000| [ 0.28646 -0.47090 -1.33980 -0.75876 -0.74237  0.09620]]
21Feb12_144000|-- Bias --
21Feb12_144000|[-0.99248 -0.71563 -0.78878  0.27988  0.06431 -0.58382]
21Feb12_144000|Layer 1:
21Feb12_144000|-- Config --
21Feb12_144000|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144000|-- Weights --
21Feb12_144000|[[-0.74764  0.04173]
21Feb12_144000| [-0.52868  0.77131]
21Feb12_144000| [ 0.33829  0.18324]
21Feb12_144000| [ 0.05913 -2.08317]
21Feb12_144000| [ 0.46104  0.18919]
21Feb12_144000| [-1.26997 -1.60808]]
21Feb12_144000|-- Bias --
21Feb12_144000|[-0.91535  0.55242]
21Feb12_144000|Layer 2:
21Feb12_144000|-- Config --
21Feb12_144000|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144000|-- Weights --
21Feb12_144000|[[-0.54781  0.50280 -0.20410]
21Feb12_144000| [ 0.61976 -0.03473 -0.21993]]
21Feb12_144000|-- Bias --
21Feb12_144000|[ 0.80186 -1.14980 -0.80324]
21Feb12_144000|Layer 3:
21Feb12_144000|-- Config --
21Feb12_144000|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144000|-- Weights --
21Feb12_144000|[[-0.23693 -0.18694 -0.06836 -0.38083]
21Feb12_144000| [-0.18482 -0.74519  1.01192 -0.73306]
21Feb12_144000| [-1.34032 -1.90482  0.21049 -0.84424]]
21Feb12_144000|-- Bias --
21Feb12_144000|[-0.45480  0.22554  1.34863 -0.53238]
21Feb12_144000|Layer 4:
21Feb12_144000|-- Config --
21Feb12_144000|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144000|-- Weights --
21Feb12_144000|[[ 1.38774  1.08699 -0.77759  0.56311 -1.77299]
21Feb12_144000| [ 0.28391 -0.10364 -1.12276 -0.52361  0.09630]
21Feb12_144000| [-0.52512 -0.16867 -1.87508  0.57790 -1.21581]
21Feb12_144000| [ 0.13746  0.45911 -0.92657  0.25726 -0.74730]]
21Feb12_144000|-- Bias --
21Feb12_144000|[-0.14276  0.44395 -0.44961  0.47833 -0.07693]
21Feb12_144000|Layer 5:
21Feb12_144000|-- Config --
21Feb12_144000|{'name': 'Hidden6', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144000|-- Weights --
21Feb12_144000|[[-0.96618  0.96909 -0.48297 -1.11889  0.70384  0.27997]
21Feb12_144000| [-1.09513 -0.74822  0.54830  0.05093  1.12909  0.21934]
21Feb12_144000| [-0.21483 -0.43027  0.98052 -0.42408 -0.95917 -0.04963]
21Feb12_144000| [ 0.14881 -0.12743 -1.24908 -0.70705 -0.62287  0.12561]
21Feb12_144000| [-0.36569  1.22889 -0.25290  0.99234 -0.08906 -0.31559]]
21Feb12_144000|-- Bias --
21Feb12_144000|[ 0.67994  0.31382 -0.21719  0.20593  0.86896 -0.11833]
21Feb12_144000|Layer 6:
21Feb12_144000|-- Config --
21Feb12_144000|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144000|-- Weights --
21Feb12_144000|[[ 0.53450  0.24174]
21Feb12_144000| [-0.24442 -0.59403]
21Feb12_144000| [ 2.07751  0.11893]
21Feb12_144000| [-1.08995 -1.42727]
21Feb12_144000| [-0.71218  1.91415]
21Feb12_144000| [-0.32732 -0.06770]]
21Feb12_144000|-- Bias --
21Feb12_144000|[ 1.42761 -1.28538]
21Feb12_144000|Predicting the validation and test data with the Best final individual.
21Feb12_144009| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_144009|-----------  ------------------  --------------------  ----------
21Feb12_144009|Validation         42.00                 156            0.00000
21Feb12_144009|   Test            25.98                 156            0.65640
21Feb12_144009|-------------------- Test #3 --------------------
21Feb12_144009|Best final individual weights
21Feb12_144009|Individual:
21Feb12_144009|-- Constant hidden layers --
21Feb12_144009|False
21Feb12_144009|Layer 0:
21Feb12_144009|-- Config --
21Feb12_144009|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144009|-- Weights --
21Feb12_144009|[[-1.00900  0.18252  1.10044  0.29024  1.31204 -1.15151]
21Feb12_144009| [-2.44628 -0.37596 -1.43390 -1.12203 -0.04904  0.52843]
21Feb12_144009| [ 1.20049  0.03592 -0.21372  1.81446  0.86713  1.56757]
21Feb12_144009| [ 2.10403  1.12072  0.35379  0.07725 -1.49841  0.84359]
21Feb12_144009| [ 0.66667 -0.28431  0.74459  0.61496  0.80113  0.30739]
21Feb12_144009| [-0.96340  1.34729 -0.21719 -0.66682 -2.03598  0.40019]
21Feb12_144009| [-0.52124  0.08105  1.42824  0.49110 -0.04806 -0.23947]
21Feb12_144009| [ 1.14738 -0.76638  1.01210  0.27597 -0.71484  1.35432]
21Feb12_144009| [ 0.02902  1.74896 -0.19677  0.12664 -0.39990 -1.36148]
21Feb12_144009| [ 1.24576  0.19537 -0.64164  0.34542  0.54807  0.55545]
21Feb12_144009| [ 0.66620 -0.26547 -0.83577 -1.26238  0.37798 -0.27613]
21Feb12_144009| [-0.78657  0.83312 -0.98676  1.20478  0.21291 -0.93913]
21Feb12_144009| [-1.37418  0.82481 -0.15928 -1.80645  1.44130  0.21421]
21Feb12_144009| [-0.02044  0.93685  1.06133  0.15770 -0.50533 -1.09024]
21Feb12_144009| [-0.04234  1.30144  0.06884 -0.63179 -0.33612  0.07686]
21Feb12_144009| [-0.33875 -0.07463 -0.14142  1.60381 -1.09643 -1.40030]
21Feb12_144009| [ 1.53350  0.61559  0.86519 -0.23458  0.86752 -0.45258]
21Feb12_144009| [-0.21733 -0.94093  0.35488 -0.63081  1.23490 -0.10059]
21Feb12_144009| [ 1.10482 -0.54999  0.06361 -0.98467  0.98841  1.10716]
21Feb12_144009| [ 0.48921  0.35977 -0.87615  1.31654  1.70644 -0.91750]
21Feb12_144009| [ 2.72869 -0.10064  1.03767 -0.61647  1.42380  1.84019]
21Feb12_144009| [-0.53304  0.42354  1.13694 -2.14180 -0.47781  0.29236]
21Feb12_144009| [-0.33778 -0.39475  0.16332 -0.15763 -0.49919 -0.89460]
21Feb12_144009| [-1.04280 -1.56283  0.36626 -0.25201 -0.28858 -1.36344]
21Feb12_144009| [-1.08871 -1.64602  0.54402  0.43907 -2.00973 -1.48787]
21Feb12_144009| [-0.21181 -0.73556 -1.98945  1.41692  0.93706 -0.25636]
21Feb12_144009| [-1.55542  0.40630  0.31652 -1.02046 -0.27004  0.19632]
21Feb12_144009| [ 1.39783 -0.54885  0.68391  1.57307 -1.07495  1.12532]
21Feb12_144009| [-0.76201 -0.04218 -0.57011 -0.52083  0.43830  2.59180]
21Feb12_144009| [-0.21753  0.04696  2.21389  2.09894 -0.29473  0.68414]
21Feb12_144009| [ 0.01575 -1.03633 -0.32878  0.69735  1.18392  0.72893]
21Feb12_144009| [-0.19264 -1.26455 -0.63480  0.76464  0.89465 -1.71142]
21Feb12_144009| [ 0.02632 -1.91608  1.58659 -0.29071  2.02573  0.03414]
21Feb12_144009| [ 1.65020 -1.27293  0.34686 -1.19815 -1.32648 -1.26882]
21Feb12_144009| [ 2.69540 -0.32808  0.31202  0.80343 -0.95016  0.44790]
21Feb12_144009| [ 0.77228  0.03163 -1.91777  0.35090 -0.34457 -1.97053]
21Feb12_144009| [ 0.56983  0.05254  1.79141  1.05885  0.24739  0.36784]
21Feb12_144009| [ 0.68847 -0.90965  0.74557 -0.99403 -1.26981 -0.61634]
21Feb12_144009| [ 0.70687  0.84294  0.57884  0.20303 -1.08778  2.00826]
21Feb12_144009| [-0.88282  0.60747 -0.54714  1.12710  0.50134  0.57920]
21Feb12_144009| [ 1.36840  0.32126 -1.29974 -0.51943 -0.41930  0.67669]
21Feb12_144009| [-0.04632 -1.30195  0.14846 -0.10446 -1.10160 -0.09529]
21Feb12_144009| [ 0.65238  0.67989 -1.96791 -1.53567 -0.85830  0.09371]
21Feb12_144009| [-0.06946  1.00221  0.03059 -0.89911 -0.41538  0.81783]
21Feb12_144009| [ 0.93359 -0.22642 -2.16799 -0.16258 -0.33185 -0.54353]
21Feb12_144009| [-0.73116  0.05803 -0.19415 -2.32698 -0.07218  0.41897]
21Feb12_144009| [ 0.01372 -1.72754  0.13547 -0.00512  0.42455 -0.36913]
21Feb12_144009| [ 1.66177  0.06579 -0.91003 -1.96934 -0.23352  1.08777]
21Feb12_144009| [ 0.09289 -1.82141 -0.78890 -2.16661  0.40321 -1.07977]
21Feb12_144009| [ 0.03205  1.35989 -0.58023  0.87747  0.15330  0.70902]
21Feb12_144009| [-0.88917 -0.10020  0.33811 -0.64537  1.24566  0.38907]
21Feb12_144009| [ 0.62530 -0.80583 -0.72489  0.51594 -1.46419 -0.95670]
21Feb12_144009| [ 0.84186  1.56276 -0.63387 -0.77819  0.18843  1.33647]
21Feb12_144009| [ 0.48085  1.19299  0.22441 -0.65616  1.25472  0.11685]
21Feb12_144009| [ 1.05217  0.40591 -1.84754 -2.43144  0.60234 -0.12202]
21Feb12_144009| [-0.00812 -1.37629  1.18334  0.13408  3.24150  0.05204]
21Feb12_144009| [ 0.28646 -0.47090 -1.33980 -0.75876 -0.74237  0.09620]]
21Feb12_144009|-- Bias --
21Feb12_144009|[-0.99248 -0.71563 -0.78878  0.27988  0.06431 -0.58382]
21Feb12_144009|Layer 1:
21Feb12_144009|-- Config --
21Feb12_144009|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144009|-- Weights --
21Feb12_144009|[[-0.74764  0.04173]
21Feb12_144009| [-0.52868  0.77131]
21Feb12_144009| [ 0.33829  0.18324]
21Feb12_144009| [ 0.05913 -2.08317]
21Feb12_144009| [ 0.46104  0.18919]
21Feb12_144009| [-1.26997 -1.60808]]
21Feb12_144009|-- Bias --
21Feb12_144009|[-0.91535  0.55242]
21Feb12_144009|Layer 2:
21Feb12_144009|-- Config --
21Feb12_144009|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144009|-- Weights --
21Feb12_144009|[[-0.54781  0.50280 -0.20410]
21Feb12_144009| [ 0.61976 -0.03473 -0.21993]]
21Feb12_144009|-- Bias --
21Feb12_144009|[ 0.80186 -1.14980 -0.80324]
21Feb12_144009|Layer 3:
21Feb12_144009|-- Config --
21Feb12_144009|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144009|-- Weights --
21Feb12_144009|[[-0.23693 -0.18694 -0.06836 -0.38083]
21Feb12_144009| [-0.18482 -0.74519  1.01192 -0.73306]
21Feb12_144009| [-1.34032 -1.90482  0.21049 -0.84424]]
21Feb12_144009|-- Bias --
21Feb12_144009|[-0.45480  0.22554  1.34863 -0.53238]
21Feb12_144009|Layer 4:
21Feb12_144009|-- Config --
21Feb12_144009|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144009|-- Weights --
21Feb12_144009|[[ 1.38774  1.08699 -0.77759  0.56311 -1.77299]
21Feb12_144009| [ 0.28391 -0.10364 -1.12276 -0.52361  0.09630]
21Feb12_144009| [-0.52512 -0.16867 -1.87508  0.57790 -1.21581]
21Feb12_144009| [ 0.13746  0.45911 -0.92657  0.25726 -0.74730]]
21Feb12_144009|-- Bias --
21Feb12_144009|[-0.14276  0.44395 -0.44961  0.47833 -0.07693]
21Feb12_144009|Layer 5:
21Feb12_144009|-- Config --
21Feb12_144009|{'name': 'Hidden6', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144009|-- Weights --
21Feb12_144009|[[-0.96618  0.96909 -0.48297 -1.11889  0.70384  0.27997]
21Feb12_144009| [-1.09513 -0.74822  0.54830  0.05093  1.12909  0.21934]
21Feb12_144009| [-0.21483 -0.43027  0.98052 -0.42408 -0.95917 -0.04963]
21Feb12_144009| [ 0.14881 -0.12743 -1.24908 -0.70705 -0.62287  0.12561]
21Feb12_144009| [-0.36569  1.22889 -0.25290  0.99234 -0.08906 -0.31559]]
21Feb12_144009|-- Bias --
21Feb12_144009|[ 0.67994  0.31382 -0.21719  0.20593  0.86896 -0.11833]
21Feb12_144009|Layer 6:
21Feb12_144009|-- Config --
21Feb12_144009|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144009|-- Weights --
21Feb12_144009|[[ 0.53450  0.24174]
21Feb12_144009| [-0.24442 -0.59403]
21Feb12_144009| [ 2.07751  0.11893]
21Feb12_144009| [-1.08995 -1.42727]
21Feb12_144009| [-0.71218  1.91415]
21Feb12_144009| [-0.32732 -0.06770]]
21Feb12_144009|-- Bias --
21Feb12_144009|[ 1.42761 -1.28538]
21Feb12_144009|Predicting the validation and test data with the Best final individual.
21Feb12_144018| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_144018|-----------  ------------------  --------------------  ----------
21Feb12_144018|Validation         24.52                 156            0.62093
21Feb12_144018|   Test            25.63                 156            0.47706
21Feb12_144018|-------------------- Test #4 --------------------
21Feb12_144018|Best final individual weights
21Feb12_144018|Individual:
21Feb12_144018|-- Constant hidden layers --
21Feb12_144018|False
21Feb12_144018|Layer 0:
21Feb12_144018|-- Config --
21Feb12_144018|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144018|-- Weights --
21Feb12_144018|[[-1.00900  0.18252  1.10044  0.29024  1.31204 -1.15151]
21Feb12_144018| [-2.44628 -0.37596 -1.43390 -1.12203 -0.04904  0.52843]
21Feb12_144018| [ 1.20049  0.03592 -0.21372  1.81446  0.86713  1.56757]
21Feb12_144018| [ 2.10403  1.12072  0.35379  0.07725 -1.49841  0.84359]
21Feb12_144018| [ 0.66667 -0.28431  0.74459  0.61496  0.80113  0.30739]
21Feb12_144018| [-0.96340  1.34729 -0.21719 -0.66682 -2.03598  0.40019]
21Feb12_144018| [-0.52124  0.08105  1.42824  0.49110 -0.04806 -0.23947]
21Feb12_144018| [ 1.14738 -0.76638  1.01210  0.27597 -0.71484  1.35432]
21Feb12_144018| [ 0.02902  1.74896 -0.19677  0.12664 -0.39990 -1.36148]
21Feb12_144018| [ 1.24576  0.19537 -0.64164  0.34542  0.54807  0.55545]
21Feb12_144018| [ 0.66620 -0.26547 -0.83577 -1.26238  0.37798 -0.27613]
21Feb12_144018| [-0.78657  0.83312 -0.98676  1.20478  0.21291 -0.93913]
21Feb12_144018| [-1.37418  0.82481 -0.15928 -1.80645  1.44130  0.21421]
21Feb12_144018| [-0.02044  0.93685  1.06133  0.15770 -0.50533 -1.09024]
21Feb12_144018| [-0.04234  1.30144  0.06884 -0.63179 -0.33612  0.07686]
21Feb12_144018| [-0.33875 -0.07463 -0.14142  1.60381 -1.09643 -1.40030]
21Feb12_144018| [ 1.53350  0.61559  0.86519 -0.23458  0.86752 -0.45258]
21Feb12_144018| [-0.21733 -0.94093  0.35488 -0.63081  1.23490 -0.10059]
21Feb12_144018| [ 1.10482 -0.54999  0.06361 -0.98467  0.98841  1.10716]
21Feb12_144018| [ 0.48921  0.35977 -0.87615  1.31654  1.70644 -0.91750]
21Feb12_144018| [ 2.72869 -0.10064  1.03767 -0.61647  1.42380  1.84019]
21Feb12_144018| [-0.53304  0.42354  1.13694 -2.14180 -0.47781  0.29236]
21Feb12_144018| [-0.33778 -0.39475  0.16332 -0.15763 -0.49919 -0.89460]
21Feb12_144018| [-1.04280 -1.56283  0.36626 -0.25201 -0.28858 -1.36344]
21Feb12_144018| [-1.08871 -1.64602  0.54402  0.43907 -2.00973 -1.48787]
21Feb12_144018| [-0.21181 -0.73556 -1.98945  1.41692  0.93706 -0.25636]
21Feb12_144018| [-1.55542  0.40630  0.31652 -1.02046 -0.27004  0.19632]
21Feb12_144018| [ 1.39783 -0.54885  0.68391  1.57307 -1.07495  1.12532]
21Feb12_144018| [-0.76201 -0.04218 -0.57011 -0.52083  0.43830  2.59180]
21Feb12_144018| [-0.21753  0.04696  2.21389  2.09894 -0.29473  0.68414]
21Feb12_144018| [ 0.01575 -1.03633 -0.32878  0.69735  1.18392  0.72893]
21Feb12_144018| [-0.19264 -1.26455 -0.63480  0.76464  0.89465 -1.71142]
21Feb12_144018| [ 0.02632 -1.91608  1.58659 -0.29071  2.02573  0.03414]
21Feb12_144018| [ 1.65020 -1.27293  0.34686 -1.19815 -1.32648 -1.26882]
21Feb12_144018| [ 2.69540 -0.32808  0.31202  0.80343 -0.95016  0.44790]
21Feb12_144018| [ 0.77228  0.03163 -1.91777  0.35090 -0.34457 -1.97053]
21Feb12_144018| [ 0.56983  0.05254  1.79141  1.05885  0.24739  0.36784]
21Feb12_144018| [ 0.68847 -0.90965  0.74557 -0.99403 -1.26981 -0.61634]
21Feb12_144018| [ 0.70687  0.84294  0.57884  0.20303 -1.08778  2.00826]
21Feb12_144018| [-0.88282  0.60747 -0.54714  1.12710  0.50134  0.57920]
21Feb12_144018| [ 1.36840  0.32126 -1.29974 -0.51943 -0.41930  0.67669]
21Feb12_144018| [-0.04632 -1.30195  0.14846 -0.10446 -1.10160 -0.09529]
21Feb12_144018| [ 0.65238  0.67989 -1.96791 -1.53567 -0.85830  0.09371]
21Feb12_144018| [-0.06946  1.00221  0.03059 -0.89911 -0.41538  0.81783]
21Feb12_144018| [ 0.93359 -0.22642 -2.16799 -0.16258 -0.33185 -0.54353]
21Feb12_144018| [-0.73116  0.05803 -0.19415 -2.32698 -0.07218  0.41897]
21Feb12_144018| [ 0.01372 -1.72754  0.13547 -0.00512  0.42455 -0.36913]
21Feb12_144018| [ 1.66177  0.06579 -0.91003 -1.96934 -0.23352  1.08777]
21Feb12_144018| [ 0.09289 -1.82141 -0.78890 -2.16661  0.40321 -1.07977]
21Feb12_144018| [ 0.03205  1.35989 -0.58023  0.87747  0.15330  0.70902]
21Feb12_144018| [-0.88917 -0.10020  0.33811 -0.64537  1.24566  0.38907]
21Feb12_144018| [ 0.62530 -0.80583 -0.72489  0.51594 -1.46419 -0.95670]
21Feb12_144018| [ 0.84186  1.56276 -0.63387 -0.77819  0.18843  1.33647]
21Feb12_144018| [ 0.48085  1.19299  0.22441 -0.65616  1.25472  0.11685]
21Feb12_144018| [ 1.05217  0.40591 -1.84754 -2.43144  0.60234 -0.12202]
21Feb12_144018| [-0.00812 -1.37629  1.18334  0.13408  3.24150  0.05204]
21Feb12_144018| [ 0.28646 -0.47090 -1.33980 -0.75876 -0.74237  0.09620]]
21Feb12_144018|-- Bias --
21Feb12_144018|[-0.99248 -0.71563 -0.78878  0.27988  0.06431 -0.58382]
21Feb12_144018|Layer 1:
21Feb12_144018|-- Config --
21Feb12_144018|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144018|-- Weights --
21Feb12_144018|[[-0.74764  0.04173]
21Feb12_144018| [-0.52868  0.77131]
21Feb12_144018| [ 0.33829  0.18324]
21Feb12_144018| [ 0.05913 -2.08317]
21Feb12_144018| [ 0.46104  0.18919]
21Feb12_144018| [-1.26997 -1.60808]]
21Feb12_144018|-- Bias --
21Feb12_144018|[-0.91535  0.55242]
21Feb12_144018|Layer 2:
21Feb12_144018|-- Config --
21Feb12_144018|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144018|-- Weights --
21Feb12_144018|[[-0.54781  0.50280 -0.20410]
21Feb12_144018| [ 0.61976 -0.03473 -0.21993]]
21Feb12_144018|-- Bias --
21Feb12_144018|[ 0.80186 -1.14980 -0.80324]
21Feb12_144018|Layer 3:
21Feb12_144018|-- Config --
21Feb12_144018|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144018|-- Weights --
21Feb12_144018|[[-0.23693 -0.18694 -0.06836 -0.38083]
21Feb12_144018| [-0.18482 -0.74519  1.01192 -0.73306]
21Feb12_144018| [-1.34032 -1.90482  0.21049 -0.84424]]
21Feb12_144018|-- Bias --
21Feb12_144018|[-0.45480  0.22554  1.34863 -0.53238]
21Feb12_144018|Layer 4:
21Feb12_144018|-- Config --
21Feb12_144018|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144018|-- Weights --
21Feb12_144018|[[ 1.38774  1.08699 -0.77759  0.56311 -1.77299]
21Feb12_144018| [ 0.28391 -0.10364 -1.12276 -0.52361  0.09630]
21Feb12_144018| [-0.52512 -0.16867 -1.87508  0.57790 -1.21581]
21Feb12_144018| [ 0.13746  0.45911 -0.92657  0.25726 -0.74730]]
21Feb12_144018|-- Bias --
21Feb12_144018|[-0.14276  0.44395 -0.44961  0.47833 -0.07693]
21Feb12_144018|Layer 5:
21Feb12_144018|-- Config --
21Feb12_144018|{'name': 'Hidden6', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144018|-- Weights --
21Feb12_144018|[[-0.96618  0.96909 -0.48297 -1.11889  0.70384  0.27997]
21Feb12_144018| [-1.09513 -0.74822  0.54830  0.05093  1.12909  0.21934]
21Feb12_144018| [-0.21483 -0.43027  0.98052 -0.42408 -0.95917 -0.04963]
21Feb12_144018| [ 0.14881 -0.12743 -1.24908 -0.70705 -0.62287  0.12561]
21Feb12_144018| [-0.36569  1.22889 -0.25290  0.99234 -0.08906 -0.31559]]
21Feb12_144018|-- Bias --
21Feb12_144018|[ 0.67994  0.31382 -0.21719  0.20593  0.86896 -0.11833]
21Feb12_144018|Layer 6:
21Feb12_144018|-- Config --
21Feb12_144018|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144018|-- Weights --
21Feb12_144018|[[ 0.53450  0.24174]
21Feb12_144018| [-0.24442 -0.59403]
21Feb12_144018| [ 2.07751  0.11893]
21Feb12_144018| [-1.08995 -1.42727]
21Feb12_144018| [-0.71218  1.91415]
21Feb12_144018| [-0.32732 -0.06770]]
21Feb12_144018|-- Bias --
21Feb12_144018|[ 1.42761 -1.28538]
21Feb12_144018|Predicting the validation and test data with the Best final individual.
21Feb12_144026| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_144026|-----------  ------------------  --------------------  ----------
21Feb12_144026|Validation         26.43                 156            0.61991
21Feb12_144026|   Test            16.42                 156            0.75531
21Feb12_144026|-------------------- Test #5 --------------------
21Feb12_144026|Best final individual weights
21Feb12_144026|Individual:
21Feb12_144026|-- Constant hidden layers --
21Feb12_144026|False
21Feb12_144026|Layer 0:
21Feb12_144026|-- Config --
21Feb12_144026|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144026|-- Weights --
21Feb12_144026|[[-1.00900  0.18252  1.10044  0.29024  1.31204 -1.15151]
21Feb12_144026| [-2.44628 -0.37596 -1.43390 -1.12203 -0.04904  0.52843]
21Feb12_144026| [ 1.20049  0.03592 -0.21372  1.81446  0.86713  1.56757]
21Feb12_144026| [ 2.10403  1.12072  0.35379  0.07725 -1.49841  0.84359]
21Feb12_144026| [ 0.66667 -0.28431  0.74459  0.61496  0.80113  0.30739]
21Feb12_144026| [-0.96340  1.34729 -0.21719 -0.66682 -2.03598  0.40019]
21Feb12_144026| [-0.52124  0.08105  1.42824  0.49110 -0.04806 -0.23947]
21Feb12_144026| [ 1.14738 -0.76638  1.01210  0.27597 -0.71484  1.35432]
21Feb12_144026| [ 0.02902  1.74896 -0.19677  0.12664 -0.39990 -1.36148]
21Feb12_144026| [ 1.24576  0.19537 -0.64164  0.34542  0.54807  0.55545]
21Feb12_144026| [ 0.66620 -0.26547 -0.83577 -1.26238  0.37798 -0.27613]
21Feb12_144026| [-0.78657  0.83312 -0.98676  1.20478  0.21291 -0.93913]
21Feb12_144026| [-1.37418  0.82481 -0.15928 -1.80645  1.44130  0.21421]
21Feb12_144026| [-0.02044  0.93685  1.06133  0.15770 -0.50533 -1.09024]
21Feb12_144026| [-0.04234  1.30144  0.06884 -0.63179 -0.33612  0.07686]
21Feb12_144026| [-0.33875 -0.07463 -0.14142  1.60381 -1.09643 -1.40030]
21Feb12_144026| [ 1.53350  0.61559  0.86519 -0.23458  0.86752 -0.45258]
21Feb12_144026| [-0.21733 -0.94093  0.35488 -0.63081  1.23490 -0.10059]
21Feb12_144026| [ 1.10482 -0.54999  0.06361 -0.98467  0.98841  1.10716]
21Feb12_144026| [ 0.48921  0.35977 -0.87615  1.31654  1.70644 -0.91750]
21Feb12_144026| [ 2.72869 -0.10064  1.03767 -0.61647  1.42380  1.84019]
21Feb12_144026| [-0.53304  0.42354  1.13694 -2.14180 -0.47781  0.29236]
21Feb12_144026| [-0.33778 -0.39475  0.16332 -0.15763 -0.49919 -0.89460]
21Feb12_144026| [-1.04280 -1.56283  0.36626 -0.25201 -0.28858 -1.36344]
21Feb12_144026| [-1.08871 -1.64602  0.54402  0.43907 -2.00973 -1.48787]
21Feb12_144026| [-0.21181 -0.73556 -1.98945  1.41692  0.93706 -0.25636]
21Feb12_144026| [-1.55542  0.40630  0.31652 -1.02046 -0.27004  0.19632]
21Feb12_144026| [ 1.39783 -0.54885  0.68391  1.57307 -1.07495  1.12532]
21Feb12_144026| [-0.76201 -0.04218 -0.57011 -0.52083  0.43830  2.59180]
21Feb12_144026| [-0.21753  0.04696  2.21389  2.09894 -0.29473  0.68414]
21Feb12_144026| [ 0.01575 -1.03633 -0.32878  0.69735  1.18392  0.72893]
21Feb12_144026| [-0.19264 -1.26455 -0.63480  0.76464  0.89465 -1.71142]
21Feb12_144026| [ 0.02632 -1.91608  1.58659 -0.29071  2.02573  0.03414]
21Feb12_144026| [ 1.65020 -1.27293  0.34686 -1.19815 -1.32648 -1.26882]
21Feb12_144026| [ 2.69540 -0.32808  0.31202  0.80343 -0.95016  0.44790]
21Feb12_144026| [ 0.77228  0.03163 -1.91777  0.35090 -0.34457 -1.97053]
21Feb12_144026| [ 0.56983  0.05254  1.79141  1.05885  0.24739  0.36784]
21Feb12_144026| [ 0.68847 -0.90965  0.74557 -0.99403 -1.26981 -0.61634]
21Feb12_144026| [ 0.70687  0.84294  0.57884  0.20303 -1.08778  2.00826]
21Feb12_144026| [-0.88282  0.60747 -0.54714  1.12710  0.50134  0.57920]
21Feb12_144026| [ 1.36840  0.32126 -1.29974 -0.51943 -0.41930  0.67669]
21Feb12_144026| [-0.04632 -1.30195  0.14846 -0.10446 -1.10160 -0.09529]
21Feb12_144026| [ 0.65238  0.67989 -1.96791 -1.53567 -0.85830  0.09371]
21Feb12_144026| [-0.06946  1.00221  0.03059 -0.89911 -0.41538  0.81783]
21Feb12_144026| [ 0.93359 -0.22642 -2.16799 -0.16258 -0.33185 -0.54353]
21Feb12_144026| [-0.73116  0.05803 -0.19415 -2.32698 -0.07218  0.41897]
21Feb12_144026| [ 0.01372 -1.72754  0.13547 -0.00512  0.42455 -0.36913]
21Feb12_144026| [ 1.66177  0.06579 -0.91003 -1.96934 -0.23352  1.08777]
21Feb12_144026| [ 0.09289 -1.82141 -0.78890 -2.16661  0.40321 -1.07977]
21Feb12_144026| [ 0.03205  1.35989 -0.58023  0.87747  0.15330  0.70902]
21Feb12_144026| [-0.88917 -0.10020  0.33811 -0.64537  1.24566  0.38907]
21Feb12_144026| [ 0.62530 -0.80583 -0.72489  0.51594 -1.46419 -0.95670]
21Feb12_144026| [ 0.84186  1.56276 -0.63387 -0.77819  0.18843  1.33647]
21Feb12_144026| [ 0.48085  1.19299  0.22441 -0.65616  1.25472  0.11685]
21Feb12_144026| [ 1.05217  0.40591 -1.84754 -2.43144  0.60234 -0.12202]
21Feb12_144026| [-0.00812 -1.37629  1.18334  0.13408  3.24150  0.05204]
21Feb12_144026| [ 0.28646 -0.47090 -1.33980 -0.75876 -0.74237  0.09620]]
21Feb12_144026|-- Bias --
21Feb12_144026|[-0.99248 -0.71563 -0.78878  0.27988  0.06431 -0.58382]
21Feb12_144026|Layer 1:
21Feb12_144026|-- Config --
21Feb12_144026|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144026|-- Weights --
21Feb12_144026|[[-0.74764  0.04173]
21Feb12_144026| [-0.52868  0.77131]
21Feb12_144026| [ 0.33829  0.18324]
21Feb12_144026| [ 0.05913 -2.08317]
21Feb12_144026| [ 0.46104  0.18919]
21Feb12_144026| [-1.26997 -1.60808]]
21Feb12_144026|-- Bias --
21Feb12_144026|[-0.91535  0.55242]
21Feb12_144026|Layer 2:
21Feb12_144026|-- Config --
21Feb12_144026|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144026|-- Weights --
21Feb12_144026|[[-0.54781  0.50280 -0.20410]
21Feb12_144026| [ 0.61976 -0.03473 -0.21993]]
21Feb12_144026|-- Bias --
21Feb12_144026|[ 0.80186 -1.14980 -0.80324]
21Feb12_144026|Layer 3:
21Feb12_144026|-- Config --
21Feb12_144026|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144026|-- Weights --
21Feb12_144026|[[-0.23693 -0.18694 -0.06836 -0.38083]
21Feb12_144026| [-0.18482 -0.74519  1.01192 -0.73306]
21Feb12_144026| [-1.34032 -1.90482  0.21049 -0.84424]]
21Feb12_144026|-- Bias --
21Feb12_144026|[-0.45480  0.22554  1.34863 -0.53238]
21Feb12_144026|Layer 4:
21Feb12_144026|-- Config --
21Feb12_144026|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144026|-- Weights --
21Feb12_144026|[[ 1.38774  1.08699 -0.77759  0.56311 -1.77299]
21Feb12_144026| [ 0.28391 -0.10364 -1.12276 -0.52361  0.09630]
21Feb12_144026| [-0.52512 -0.16867 -1.87508  0.57790 -1.21581]
21Feb12_144026| [ 0.13746  0.45911 -0.92657  0.25726 -0.74730]]
21Feb12_144026|-- Bias --
21Feb12_144026|[-0.14276  0.44395 -0.44961  0.47833 -0.07693]
21Feb12_144026|Layer 5:
21Feb12_144026|-- Config --
21Feb12_144026|{'name': 'Hidden6', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144026|-- Weights --
21Feb12_144026|[[-0.96618  0.96909 -0.48297 -1.11889  0.70384  0.27997]
21Feb12_144026| [-1.09513 -0.74822  0.54830  0.05093  1.12909  0.21934]
21Feb12_144026| [-0.21483 -0.43027  0.98052 -0.42408 -0.95917 -0.04963]
21Feb12_144026| [ 0.14881 -0.12743 -1.24908 -0.70705 -0.62287  0.12561]
21Feb12_144026| [-0.36569  1.22889 -0.25290  0.99234 -0.08906 -0.31559]]
21Feb12_144026|-- Bias --
21Feb12_144026|[ 0.67994  0.31382 -0.21719  0.20593  0.86896 -0.11833]
21Feb12_144026|Layer 6:
21Feb12_144026|-- Config --
21Feb12_144026|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144026|-- Weights --
21Feb12_144026|[[ 0.53450  0.24174]
21Feb12_144026| [-0.24442 -0.59403]
21Feb12_144026| [ 2.07751  0.11893]
21Feb12_144026| [-1.08995 -1.42727]
21Feb12_144026| [-0.71218  1.91415]
21Feb12_144026| [-0.32732 -0.06770]]
21Feb12_144026|-- Bias --
21Feb12_144026|[ 1.42761 -1.28538]
21Feb12_144026|Predicting the validation and test data with the Best final individual.
21Feb12_144035| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_144035|-----------  ------------------  --------------------  ----------
21Feb12_144035|Validation         27.04                 156            0.54444
21Feb12_144035|   Test            25.63                 156            0.48964
21Feb12_144035|-------------------- Test #6 --------------------
21Feb12_144035|Best final individual weights
21Feb12_144035|Individual:
21Feb12_144035|-- Constant hidden layers --
21Feb12_144035|False
21Feb12_144035|Layer 0:
21Feb12_144035|-- Config --
21Feb12_144035|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144035|-- Weights --
21Feb12_144035|[[-1.00900  0.18252  1.10044  0.29024  1.31204 -1.15151]
21Feb12_144035| [-2.44628 -0.37596 -1.43390 -1.12203 -0.04904  0.52843]
21Feb12_144035| [ 1.20049  0.03592 -0.21372  1.81446  0.86713  1.56757]
21Feb12_144035| [ 2.10403  1.12072  0.35379  0.07725 -1.49841  0.84359]
21Feb12_144035| [ 0.66667 -0.28431  0.74459  0.61496  0.80113  0.30739]
21Feb12_144035| [-0.96340  1.34729 -0.21719 -0.66682 -2.03598  0.40019]
21Feb12_144035| [-0.52124  0.08105  1.42824  0.49110 -0.04806 -0.23947]
21Feb12_144035| [ 1.14738 -0.76638  1.01210  0.27597 -0.71484  1.35432]
21Feb12_144035| [ 0.02902  1.74896 -0.19677  0.12664 -0.39990 -1.36148]
21Feb12_144035| [ 1.24576  0.19537 -0.64164  0.34542  0.54807  0.55545]
21Feb12_144035| [ 0.66620 -0.26547 -0.83577 -1.26238  0.37798 -0.27613]
21Feb12_144035| [-0.78657  0.83312 -0.98676  1.20478  0.21291 -0.93913]
21Feb12_144035| [-1.37418  0.82481 -0.15928 -1.80645  1.44130  0.21421]
21Feb12_144035| [-0.02044  0.93685  1.06133  0.15770 -0.50533 -1.09024]
21Feb12_144035| [-0.04234  1.30144  0.06884 -0.63179 -0.33612  0.07686]
21Feb12_144035| [-0.33875 -0.07463 -0.14142  1.60381 -1.09643 -1.40030]
21Feb12_144035| [ 1.53350  0.61559  0.86519 -0.23458  0.86752 -0.45258]
21Feb12_144035| [-0.21733 -0.94093  0.35488 -0.63081  1.23490 -0.10059]
21Feb12_144035| [ 1.10482 -0.54999  0.06361 -0.98467  0.98841  1.10716]
21Feb12_144035| [ 0.48921  0.35977 -0.87615  1.31654  1.70644 -0.91750]
21Feb12_144035| [ 2.72869 -0.10064  1.03767 -0.61647  1.42380  1.84019]
21Feb12_144035| [-0.53304  0.42354  1.13694 -2.14180 -0.47781  0.29236]
21Feb12_144035| [-0.33778 -0.39475  0.16332 -0.15763 -0.49919 -0.89460]
21Feb12_144035| [-1.04280 -1.56283  0.36626 -0.25201 -0.28858 -1.36344]
21Feb12_144035| [-1.08871 -1.64602  0.54402  0.43907 -2.00973 -1.48787]
21Feb12_144035| [-0.21181 -0.73556 -1.98945  1.41692  0.93706 -0.25636]
21Feb12_144035| [-1.55542  0.40630  0.31652 -1.02046 -0.27004  0.19632]
21Feb12_144035| [ 1.39783 -0.54885  0.68391  1.57307 -1.07495  1.12532]
21Feb12_144035| [-0.76201 -0.04218 -0.57011 -0.52083  0.43830  2.59180]
21Feb12_144035| [-0.21753  0.04696  2.21389  2.09894 -0.29473  0.68414]
21Feb12_144035| [ 0.01575 -1.03633 -0.32878  0.69735  1.18392  0.72893]
21Feb12_144035| [-0.19264 -1.26455 -0.63480  0.76464  0.89465 -1.71142]
21Feb12_144035| [ 0.02632 -1.91608  1.58659 -0.29071  2.02573  0.03414]
21Feb12_144035| [ 1.65020 -1.27293  0.34686 -1.19815 -1.32648 -1.26882]
21Feb12_144035| [ 2.69540 -0.32808  0.31202  0.80343 -0.95016  0.44790]
21Feb12_144035| [ 0.77228  0.03163 -1.91777  0.35090 -0.34457 -1.97053]
21Feb12_144035| [ 0.56983  0.05254  1.79141  1.05885  0.24739  0.36784]
21Feb12_144035| [ 0.68847 -0.90965  0.74557 -0.99403 -1.26981 -0.61634]
21Feb12_144035| [ 0.70687  0.84294  0.57884  0.20303 -1.08778  2.00826]
21Feb12_144035| [-0.88282  0.60747 -0.54714  1.12710  0.50134  0.57920]
21Feb12_144035| [ 1.36840  0.32126 -1.29974 -0.51943 -0.41930  0.67669]
21Feb12_144035| [-0.04632 -1.30195  0.14846 -0.10446 -1.10160 -0.09529]
21Feb12_144035| [ 0.65238  0.67989 -1.96791 -1.53567 -0.85830  0.09371]
21Feb12_144035| [-0.06946  1.00221  0.03059 -0.89911 -0.41538  0.81783]
21Feb12_144035| [ 0.93359 -0.22642 -2.16799 -0.16258 -0.33185 -0.54353]
21Feb12_144035| [-0.73116  0.05803 -0.19415 -2.32698 -0.07218  0.41897]
21Feb12_144035| [ 0.01372 -1.72754  0.13547 -0.00512  0.42455 -0.36913]
21Feb12_144035| [ 1.66177  0.06579 -0.91003 -1.96934 -0.23352  1.08777]
21Feb12_144035| [ 0.09289 -1.82141 -0.78890 -2.16661  0.40321 -1.07977]
21Feb12_144035| [ 0.03205  1.35989 -0.58023  0.87747  0.15330  0.70902]
21Feb12_144035| [-0.88917 -0.10020  0.33811 -0.64537  1.24566  0.38907]
21Feb12_144035| [ 0.62530 -0.80583 -0.72489  0.51594 -1.46419 -0.95670]
21Feb12_144035| [ 0.84186  1.56276 -0.63387 -0.77819  0.18843  1.33647]
21Feb12_144035| [ 0.48085  1.19299  0.22441 -0.65616  1.25472  0.11685]
21Feb12_144035| [ 1.05217  0.40591 -1.84754 -2.43144  0.60234 -0.12202]
21Feb12_144035| [-0.00812 -1.37629  1.18334  0.13408  3.24150  0.05204]
21Feb12_144035| [ 0.28646 -0.47090 -1.33980 -0.75876 -0.74237  0.09620]]
21Feb12_144035|-- Bias --
21Feb12_144035|[-0.99248 -0.71563 -0.78878  0.27988  0.06431 -0.58382]
21Feb12_144035|Layer 1:
21Feb12_144035|-- Config --
21Feb12_144035|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144035|-- Weights --
21Feb12_144035|[[-0.74764  0.04173]
21Feb12_144035| [-0.52868  0.77131]
21Feb12_144035| [ 0.33829  0.18324]
21Feb12_144035| [ 0.05913 -2.08317]
21Feb12_144035| [ 0.46104  0.18919]
21Feb12_144035| [-1.26997 -1.60808]]
21Feb12_144035|-- Bias --
21Feb12_144035|[-0.91535  0.55242]
21Feb12_144035|Layer 2:
21Feb12_144035|-- Config --
21Feb12_144035|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144035|-- Weights --
21Feb12_144035|[[-0.54781  0.50280 -0.20410]
21Feb12_144035| [ 0.61976 -0.03473 -0.21993]]
21Feb12_144035|-- Bias --
21Feb12_144035|[ 0.80186 -1.14980 -0.80324]
21Feb12_144035|Layer 3:
21Feb12_144035|-- Config --
21Feb12_144035|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144035|-- Weights --
21Feb12_144035|[[-0.23693 -0.18694 -0.06836 -0.38083]
21Feb12_144035| [-0.18482 -0.74519  1.01192 -0.73306]
21Feb12_144035| [-1.34032 -1.90482  0.21049 -0.84424]]
21Feb12_144035|-- Bias --
21Feb12_144035|[-0.45480  0.22554  1.34863 -0.53238]
21Feb12_144035|Layer 4:
21Feb12_144035|-- Config --
21Feb12_144035|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144035|-- Weights --
21Feb12_144035|[[ 1.38774  1.08699 -0.77759  0.56311 -1.77299]
21Feb12_144035| [ 0.28391 -0.10364 -1.12276 -0.52361  0.09630]
21Feb12_144035| [-0.52512 -0.16867 -1.87508  0.57790 -1.21581]
21Feb12_144035| [ 0.13746  0.45911 -0.92657  0.25726 -0.74730]]
21Feb12_144035|-- Bias --
21Feb12_144035|[-0.14276  0.44395 -0.44961  0.47833 -0.07693]
21Feb12_144035|Layer 5:
21Feb12_144035|-- Config --
21Feb12_144035|{'name': 'Hidden6', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144035|-- Weights --
21Feb12_144035|[[-0.96618  0.96909 -0.48297 -1.11889  0.70384  0.27997]
21Feb12_144035| [-1.09513 -0.74822  0.54830  0.05093  1.12909  0.21934]
21Feb12_144035| [-0.21483 -0.43027  0.98052 -0.42408 -0.95917 -0.04963]
21Feb12_144035| [ 0.14881 -0.12743 -1.24908 -0.70705 -0.62287  0.12561]
21Feb12_144035| [-0.36569  1.22889 -0.25290  0.99234 -0.08906 -0.31559]]
21Feb12_144035|-- Bias --
21Feb12_144035|[ 0.67994  0.31382 -0.21719  0.20593  0.86896 -0.11833]
21Feb12_144035|Layer 6:
21Feb12_144035|-- Config --
21Feb12_144035|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144035|-- Weights --
21Feb12_144035|[[ 0.53450  0.24174]
21Feb12_144035| [-0.24442 -0.59403]
21Feb12_144035| [ 2.07751  0.11893]
21Feb12_144035| [-1.08995 -1.42727]
21Feb12_144035| [-0.71218  1.91415]
21Feb12_144035| [-0.32732 -0.06770]]
21Feb12_144035|-- Bias --
21Feb12_144035|[ 1.42761 -1.28538]
21Feb12_144035|Predicting the validation and test data with the Best final individual.
21Feb12_144044| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_144044|-----------  ------------------  --------------------  ----------
21Feb12_144044|Validation         42.00                 156            0.00000
21Feb12_144044|   Test            23.81                 156            0.68171
21Feb12_144044|-------------------- Test #7 --------------------
21Feb12_144044|Best final individual weights
21Feb12_144044|Individual:
21Feb12_144044|-- Constant hidden layers --
21Feb12_144044|False
21Feb12_144044|Layer 0:
21Feb12_144044|-- Config --
21Feb12_144044|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144044|-- Weights --
21Feb12_144044|[[-1.00900  0.18252  1.10044  0.29024  1.31204 -1.15151]
21Feb12_144044| [-2.44628 -0.37596 -1.43390 -1.12203 -0.04904  0.52843]
21Feb12_144044| [ 1.20049  0.03592 -0.21372  1.81446  0.86713  1.56757]
21Feb12_144044| [ 2.10403  1.12072  0.35379  0.07725 -1.49841  0.84359]
21Feb12_144044| [ 0.66667 -0.28431  0.74459  0.61496  0.80113  0.30739]
21Feb12_144044| [-0.96340  1.34729 -0.21719 -0.66682 -2.03598  0.40019]
21Feb12_144044| [-0.52124  0.08105  1.42824  0.49110 -0.04806 -0.23947]
21Feb12_144044| [ 1.14738 -0.76638  1.01210  0.27597 -0.71484  1.35432]
21Feb12_144044| [ 0.02902  1.74896 -0.19677  0.12664 -0.39990 -1.36148]
21Feb12_144044| [ 1.24576  0.19537 -0.64164  0.34542  0.54807  0.55545]
21Feb12_144044| [ 0.66620 -0.26547 -0.83577 -1.26238  0.37798 -0.27613]
21Feb12_144044| [-0.78657  0.83312 -0.98676  1.20478  0.21291 -0.93913]
21Feb12_144044| [-1.37418  0.82481 -0.15928 -1.80645  1.44130  0.21421]
21Feb12_144044| [-0.02044  0.93685  1.06133  0.15770 -0.50533 -1.09024]
21Feb12_144044| [-0.04234  1.30144  0.06884 -0.63179 -0.33612  0.07686]
21Feb12_144044| [-0.33875 -0.07463 -0.14142  1.60381 -1.09643 -1.40030]
21Feb12_144044| [ 1.53350  0.61559  0.86519 -0.23458  0.86752 -0.45258]
21Feb12_144044| [-0.21733 -0.94093  0.35488 -0.63081  1.23490 -0.10059]
21Feb12_144044| [ 1.10482 -0.54999  0.06361 -0.98467  0.98841  1.10716]
21Feb12_144044| [ 0.48921  0.35977 -0.87615  1.31654  1.70644 -0.91750]
21Feb12_144044| [ 2.72869 -0.10064  1.03767 -0.61647  1.42380  1.84019]
21Feb12_144044| [-0.53304  0.42354  1.13694 -2.14180 -0.47781  0.29236]
21Feb12_144044| [-0.33778 -0.39475  0.16332 -0.15763 -0.49919 -0.89460]
21Feb12_144044| [-1.04280 -1.56283  0.36626 -0.25201 -0.28858 -1.36344]
21Feb12_144044| [-1.08871 -1.64602  0.54402  0.43907 -2.00973 -1.48787]
21Feb12_144044| [-0.21181 -0.73556 -1.98945  1.41692  0.93706 -0.25636]
21Feb12_144044| [-1.55542  0.40630  0.31652 -1.02046 -0.27004  0.19632]
21Feb12_144044| [ 1.39783 -0.54885  0.68391  1.57307 -1.07495  1.12532]
21Feb12_144044| [-0.76201 -0.04218 -0.57011 -0.52083  0.43830  2.59180]
21Feb12_144044| [-0.21753  0.04696  2.21389  2.09894 -0.29473  0.68414]
21Feb12_144044| [ 0.01575 -1.03633 -0.32878  0.69735  1.18392  0.72893]
21Feb12_144044| [-0.19264 -1.26455 -0.63480  0.76464  0.89465 -1.71142]
21Feb12_144044| [ 0.02632 -1.91608  1.58659 -0.29071  2.02573  0.03414]
21Feb12_144044| [ 1.65020 -1.27293  0.34686 -1.19815 -1.32648 -1.26882]
21Feb12_144044| [ 2.69540 -0.32808  0.31202  0.80343 -0.95016  0.44790]
21Feb12_144044| [ 0.77228  0.03163 -1.91777  0.35090 -0.34457 -1.97053]
21Feb12_144044| [ 0.56983  0.05254  1.79141  1.05885  0.24739  0.36784]
21Feb12_144044| [ 0.68847 -0.90965  0.74557 -0.99403 -1.26981 -0.61634]
21Feb12_144044| [ 0.70687  0.84294  0.57884  0.20303 -1.08778  2.00826]
21Feb12_144044| [-0.88282  0.60747 -0.54714  1.12710  0.50134  0.57920]
21Feb12_144044| [ 1.36840  0.32126 -1.29974 -0.51943 -0.41930  0.67669]
21Feb12_144044| [-0.04632 -1.30195  0.14846 -0.10446 -1.10160 -0.09529]
21Feb12_144044| [ 0.65238  0.67989 -1.96791 -1.53567 -0.85830  0.09371]
21Feb12_144044| [-0.06946  1.00221  0.03059 -0.89911 -0.41538  0.81783]
21Feb12_144044| [ 0.93359 -0.22642 -2.16799 -0.16258 -0.33185 -0.54353]
21Feb12_144044| [-0.73116  0.05803 -0.19415 -2.32698 -0.07218  0.41897]
21Feb12_144044| [ 0.01372 -1.72754  0.13547 -0.00512  0.42455 -0.36913]
21Feb12_144044| [ 1.66177  0.06579 -0.91003 -1.96934 -0.23352  1.08777]
21Feb12_144044| [ 0.09289 -1.82141 -0.78890 -2.16661  0.40321 -1.07977]
21Feb12_144044| [ 0.03205  1.35989 -0.58023  0.87747  0.15330  0.70902]
21Feb12_144044| [-0.88917 -0.10020  0.33811 -0.64537  1.24566  0.38907]
21Feb12_144044| [ 0.62530 -0.80583 -0.72489  0.51594 -1.46419 -0.95670]
21Feb12_144044| [ 0.84186  1.56276 -0.63387 -0.77819  0.18843  1.33647]
21Feb12_144044| [ 0.48085  1.19299  0.22441 -0.65616  1.25472  0.11685]
21Feb12_144044| [ 1.05217  0.40591 -1.84754 -2.43144  0.60234 -0.12202]
21Feb12_144044| [-0.00812 -1.37629  1.18334  0.13408  3.24150  0.05204]
21Feb12_144044| [ 0.28646 -0.47090 -1.33980 -0.75876 -0.74237  0.09620]]
21Feb12_144044|-- Bias --
21Feb12_144044|[-0.99248 -0.71563 -0.78878  0.27988  0.06431 -0.58382]
21Feb12_144044|Layer 1:
21Feb12_144044|-- Config --
21Feb12_144044|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144044|-- Weights --
21Feb12_144044|[[-0.74764  0.04173]
21Feb12_144044| [-0.52868  0.77131]
21Feb12_144044| [ 0.33829  0.18324]
21Feb12_144044| [ 0.05913 -2.08317]
21Feb12_144044| [ 0.46104  0.18919]
21Feb12_144044| [-1.26997 -1.60808]]
21Feb12_144044|-- Bias --
21Feb12_144044|[-0.91535  0.55242]
21Feb12_144044|Layer 2:
21Feb12_144044|-- Config --
21Feb12_144044|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144044|-- Weights --
21Feb12_144044|[[-0.54781  0.50280 -0.20410]
21Feb12_144044| [ 0.61976 -0.03473 -0.21993]]
21Feb12_144044|-- Bias --
21Feb12_144044|[ 0.80186 -1.14980 -0.80324]
21Feb12_144044|Layer 3:
21Feb12_144044|-- Config --
21Feb12_144044|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144044|-- Weights --
21Feb12_144044|[[-0.23693 -0.18694 -0.06836 -0.38083]
21Feb12_144044| [-0.18482 -0.74519  1.01192 -0.73306]
21Feb12_144044| [-1.34032 -1.90482  0.21049 -0.84424]]
21Feb12_144044|-- Bias --
21Feb12_144044|[-0.45480  0.22554  1.34863 -0.53238]
21Feb12_144044|Layer 4:
21Feb12_144044|-- Config --
21Feb12_144044|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144044|-- Weights --
21Feb12_144044|[[ 1.38774  1.08699 -0.77759  0.56311 -1.77299]
21Feb12_144044| [ 0.28391 -0.10364 -1.12276 -0.52361  0.09630]
21Feb12_144044| [-0.52512 -0.16867 -1.87508  0.57790 -1.21581]
21Feb12_144044| [ 0.13746  0.45911 -0.92657  0.25726 -0.74730]]
21Feb12_144044|-- Bias --
21Feb12_144044|[-0.14276  0.44395 -0.44961  0.47833 -0.07693]
21Feb12_144044|Layer 5:
21Feb12_144044|-- Config --
21Feb12_144044|{'name': 'Hidden6', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144044|-- Weights --
21Feb12_144044|[[-0.96618  0.96909 -0.48297 -1.11889  0.70384  0.27997]
21Feb12_144044| [-1.09513 -0.74822  0.54830  0.05093  1.12909  0.21934]
21Feb12_144044| [-0.21483 -0.43027  0.98052 -0.42408 -0.95917 -0.04963]
21Feb12_144044| [ 0.14881 -0.12743 -1.24908 -0.70705 -0.62287  0.12561]
21Feb12_144044| [-0.36569  1.22889 -0.25290  0.99234 -0.08906 -0.31559]]
21Feb12_144044|-- Bias --
21Feb12_144044|[ 0.67994  0.31382 -0.21719  0.20593  0.86896 -0.11833]
21Feb12_144044|Layer 6:
21Feb12_144044|-- Config --
21Feb12_144044|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144044|-- Weights --
21Feb12_144044|[[ 0.53450  0.24174]
21Feb12_144044| [-0.24442 -0.59403]
21Feb12_144044| [ 2.07751  0.11893]
21Feb12_144044| [-1.08995 -1.42727]
21Feb12_144044| [-0.71218  1.91415]
21Feb12_144044| [-0.32732 -0.06770]]
21Feb12_144044|-- Bias --
21Feb12_144044|[ 1.42761 -1.28538]
21Feb12_144044|Predicting the validation and test data with the Best final individual.
21Feb12_144053| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_144053|-----------  ------------------  --------------------  ----------
21Feb12_144053|Validation         24.78                 156            0.74209
21Feb12_144053|   Test            26.06                 156            0.42621
21Feb12_144053|-------------------- Test #8 --------------------
21Feb12_144053|Best final individual weights
21Feb12_144053|Individual:
21Feb12_144053|-- Constant hidden layers --
21Feb12_144053|False
21Feb12_144053|Layer 0:
21Feb12_144053|-- Config --
21Feb12_144053|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144053|-- Weights --
21Feb12_144053|[[-1.00900  0.18252  1.10044  0.29024  1.31204 -1.15151]
21Feb12_144053| [-2.44628 -0.37596 -1.43390 -1.12203 -0.04904  0.52843]
21Feb12_144053| [ 1.20049  0.03592 -0.21372  1.81446  0.86713  1.56757]
21Feb12_144053| [ 2.10403  1.12072  0.35379  0.07725 -1.49841  0.84359]
21Feb12_144053| [ 0.66667 -0.28431  0.74459  0.61496  0.80113  0.30739]
21Feb12_144053| [-0.96340  1.34729 -0.21719 -0.66682 -2.03598  0.40019]
21Feb12_144053| [-0.52124  0.08105  1.42824  0.49110 -0.04806 -0.23947]
21Feb12_144053| [ 1.14738 -0.76638  1.01210  0.27597 -0.71484  1.35432]
21Feb12_144053| [ 0.02902  1.74896 -0.19677  0.12664 -0.39990 -1.36148]
21Feb12_144053| [ 1.24576  0.19537 -0.64164  0.34542  0.54807  0.55545]
21Feb12_144053| [ 0.66620 -0.26547 -0.83577 -1.26238  0.37798 -0.27613]
21Feb12_144053| [-0.78657  0.83312 -0.98676  1.20478  0.21291 -0.93913]
21Feb12_144053| [-1.37418  0.82481 -0.15928 -1.80645  1.44130  0.21421]
21Feb12_144053| [-0.02044  0.93685  1.06133  0.15770 -0.50533 -1.09024]
21Feb12_144053| [-0.04234  1.30144  0.06884 -0.63179 -0.33612  0.07686]
21Feb12_144053| [-0.33875 -0.07463 -0.14142  1.60381 -1.09643 -1.40030]
21Feb12_144053| [ 1.53350  0.61559  0.86519 -0.23458  0.86752 -0.45258]
21Feb12_144053| [-0.21733 -0.94093  0.35488 -0.63081  1.23490 -0.10059]
21Feb12_144053| [ 1.10482 -0.54999  0.06361 -0.98467  0.98841  1.10716]
21Feb12_144053| [ 0.48921  0.35977 -0.87615  1.31654  1.70644 -0.91750]
21Feb12_144053| [ 2.72869 -0.10064  1.03767 -0.61647  1.42380  1.84019]
21Feb12_144053| [-0.53304  0.42354  1.13694 -2.14180 -0.47781  0.29236]
21Feb12_144053| [-0.33778 -0.39475  0.16332 -0.15763 -0.49919 -0.89460]
21Feb12_144053| [-1.04280 -1.56283  0.36626 -0.25201 -0.28858 -1.36344]
21Feb12_144053| [-1.08871 -1.64602  0.54402  0.43907 -2.00973 -1.48787]
21Feb12_144053| [-0.21181 -0.73556 -1.98945  1.41692  0.93706 -0.25636]
21Feb12_144053| [-1.55542  0.40630  0.31652 -1.02046 -0.27004  0.19632]
21Feb12_144053| [ 1.39783 -0.54885  0.68391  1.57307 -1.07495  1.12532]
21Feb12_144053| [-0.76201 -0.04218 -0.57011 -0.52083  0.43830  2.59180]
21Feb12_144053| [-0.21753  0.04696  2.21389  2.09894 -0.29473  0.68414]
21Feb12_144053| [ 0.01575 -1.03633 -0.32878  0.69735  1.18392  0.72893]
21Feb12_144053| [-0.19264 -1.26455 -0.63480  0.76464  0.89465 -1.71142]
21Feb12_144053| [ 0.02632 -1.91608  1.58659 -0.29071  2.02573  0.03414]
21Feb12_144053| [ 1.65020 -1.27293  0.34686 -1.19815 -1.32648 -1.26882]
21Feb12_144053| [ 2.69540 -0.32808  0.31202  0.80343 -0.95016  0.44790]
21Feb12_144053| [ 0.77228  0.03163 -1.91777  0.35090 -0.34457 -1.97053]
21Feb12_144053| [ 0.56983  0.05254  1.79141  1.05885  0.24739  0.36784]
21Feb12_144053| [ 0.68847 -0.90965  0.74557 -0.99403 -1.26981 -0.61634]
21Feb12_144053| [ 0.70687  0.84294  0.57884  0.20303 -1.08778  2.00826]
21Feb12_144053| [-0.88282  0.60747 -0.54714  1.12710  0.50134  0.57920]
21Feb12_144053| [ 1.36840  0.32126 -1.29974 -0.51943 -0.41930  0.67669]
21Feb12_144053| [-0.04632 -1.30195  0.14846 -0.10446 -1.10160 -0.09529]
21Feb12_144053| [ 0.65238  0.67989 -1.96791 -1.53567 -0.85830  0.09371]
21Feb12_144053| [-0.06946  1.00221  0.03059 -0.89911 -0.41538  0.81783]
21Feb12_144053| [ 0.93359 -0.22642 -2.16799 -0.16258 -0.33185 -0.54353]
21Feb12_144053| [-0.73116  0.05803 -0.19415 -2.32698 -0.07218  0.41897]
21Feb12_144053| [ 0.01372 -1.72754  0.13547 -0.00512  0.42455 -0.36913]
21Feb12_144053| [ 1.66177  0.06579 -0.91003 -1.96934 -0.23352  1.08777]
21Feb12_144053| [ 0.09289 -1.82141 -0.78890 -2.16661  0.40321 -1.07977]
21Feb12_144053| [ 0.03205  1.35989 -0.58023  0.87747  0.15330  0.70902]
21Feb12_144053| [-0.88917 -0.10020  0.33811 -0.64537  1.24566  0.38907]
21Feb12_144053| [ 0.62530 -0.80583 -0.72489  0.51594 -1.46419 -0.95670]
21Feb12_144053| [ 0.84186  1.56276 -0.63387 -0.77819  0.18843  1.33647]
21Feb12_144053| [ 0.48085  1.19299  0.22441 -0.65616  1.25472  0.11685]
21Feb12_144053| [ 1.05217  0.40591 -1.84754 -2.43144  0.60234 -0.12202]
21Feb12_144053| [-0.00812 -1.37629  1.18334  0.13408  3.24150  0.05204]
21Feb12_144053| [ 0.28646 -0.47090 -1.33980 -0.75876 -0.74237  0.09620]]
21Feb12_144053|-- Bias --
21Feb12_144053|[-0.99248 -0.71563 -0.78878  0.27988  0.06431 -0.58382]
21Feb12_144053|Layer 1:
21Feb12_144053|-- Config --
21Feb12_144053|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144053|-- Weights --
21Feb12_144053|[[-0.74764  0.04173]
21Feb12_144053| [-0.52868  0.77131]
21Feb12_144053| [ 0.33829  0.18324]
21Feb12_144053| [ 0.05913 -2.08317]
21Feb12_144053| [ 0.46104  0.18919]
21Feb12_144053| [-1.26997 -1.60808]]
21Feb12_144053|-- Bias --
21Feb12_144053|[-0.91535  0.55242]
21Feb12_144053|Layer 2:
21Feb12_144053|-- Config --
21Feb12_144053|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144053|-- Weights --
21Feb12_144053|[[-0.54781  0.50280 -0.20410]
21Feb12_144053| [ 0.61976 -0.03473 -0.21993]]
21Feb12_144053|-- Bias --
21Feb12_144053|[ 0.80186 -1.14980 -0.80324]
21Feb12_144053|Layer 3:
21Feb12_144053|-- Config --
21Feb12_144053|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144053|-- Weights --
21Feb12_144053|[[-0.23693 -0.18694 -0.06836 -0.38083]
21Feb12_144053| [-0.18482 -0.74519  1.01192 -0.73306]
21Feb12_144053| [-1.34032 -1.90482  0.21049 -0.84424]]
21Feb12_144053|-- Bias --
21Feb12_144053|[-0.45480  0.22554  1.34863 -0.53238]
21Feb12_144053|Layer 4:
21Feb12_144053|-- Config --
21Feb12_144053|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144053|-- Weights --
21Feb12_144053|[[ 1.38774  1.08699 -0.77759  0.56311 -1.77299]
21Feb12_144053| [ 0.28391 -0.10364 -1.12276 -0.52361  0.09630]
21Feb12_144053| [-0.52512 -0.16867 -1.87508  0.57790 -1.21581]
21Feb12_144053| [ 0.13746  0.45911 -0.92657  0.25726 -0.74730]]
21Feb12_144053|-- Bias --
21Feb12_144053|[-0.14276  0.44395 -0.44961  0.47833 -0.07693]
21Feb12_144053|Layer 5:
21Feb12_144053|-- Config --
21Feb12_144053|{'name': 'Hidden6', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144053|-- Weights --
21Feb12_144053|[[-0.96618  0.96909 -0.48297 -1.11889  0.70384  0.27997]
21Feb12_144053| [-1.09513 -0.74822  0.54830  0.05093  1.12909  0.21934]
21Feb12_144053| [-0.21483 -0.43027  0.98052 -0.42408 -0.95917 -0.04963]
21Feb12_144053| [ 0.14881 -0.12743 -1.24908 -0.70705 -0.62287  0.12561]
21Feb12_144053| [-0.36569  1.22889 -0.25290  0.99234 -0.08906 -0.31559]]
21Feb12_144053|-- Bias --
21Feb12_144053|[ 0.67994  0.31382 -0.21719  0.20593  0.86896 -0.11833]
21Feb12_144053|Layer 6:
21Feb12_144053|-- Config --
21Feb12_144053|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144053|-- Weights --
21Feb12_144053|[[ 0.53450  0.24174]
21Feb12_144053| [-0.24442 -0.59403]
21Feb12_144053| [ 2.07751  0.11893]
21Feb12_144053| [-1.08995 -1.42727]
21Feb12_144053| [-0.71218  1.91415]
21Feb12_144053| [-0.32732 -0.06770]]
21Feb12_144053|-- Bias --
21Feb12_144053|[ 1.42761 -1.28538]
21Feb12_144053|Predicting the validation and test data with the Best final individual.
21Feb12_144102| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_144102|-----------  ------------------  --------------------  ----------
21Feb12_144102|Validation         42.00                 156            0.00000
21Feb12_144102|   Test            25.54                 156            0.72540
21Feb12_144102|-------------------- Test #9 --------------------
21Feb12_144102|Best final individual weights
21Feb12_144102|Individual:
21Feb12_144102|-- Constant hidden layers --
21Feb12_144102|False
21Feb12_144102|Layer 0:
21Feb12_144102|-- Config --
21Feb12_144102|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144102|-- Weights --
21Feb12_144102|[[-1.00900  0.18252  1.10044  0.29024  1.31204 -1.15151]
21Feb12_144102| [-2.44628 -0.37596 -1.43390 -1.12203 -0.04904  0.52843]
21Feb12_144102| [ 1.20049  0.03592 -0.21372  1.81446  0.86713  1.56757]
21Feb12_144102| [ 2.10403  1.12072  0.35379  0.07725 -1.49841  0.84359]
21Feb12_144102| [ 0.66667 -0.28431  0.74459  0.61496  0.80113  0.30739]
21Feb12_144102| [-0.96340  1.34729 -0.21719 -0.66682 -2.03598  0.40019]
21Feb12_144102| [-0.52124  0.08105  1.42824  0.49110 -0.04806 -0.23947]
21Feb12_144102| [ 1.14738 -0.76638  1.01210  0.27597 -0.71484  1.35432]
21Feb12_144102| [ 0.02902  1.74896 -0.19677  0.12664 -0.39990 -1.36148]
21Feb12_144102| [ 1.24576  0.19537 -0.64164  0.34542  0.54807  0.55545]
21Feb12_144102| [ 0.66620 -0.26547 -0.83577 -1.26238  0.37798 -0.27613]
21Feb12_144102| [-0.78657  0.83312 -0.98676  1.20478  0.21291 -0.93913]
21Feb12_144102| [-1.37418  0.82481 -0.15928 -1.80645  1.44130  0.21421]
21Feb12_144102| [-0.02044  0.93685  1.06133  0.15770 -0.50533 -1.09024]
21Feb12_144102| [-0.04234  1.30144  0.06884 -0.63179 -0.33612  0.07686]
21Feb12_144102| [-0.33875 -0.07463 -0.14142  1.60381 -1.09643 -1.40030]
21Feb12_144102| [ 1.53350  0.61559  0.86519 -0.23458  0.86752 -0.45258]
21Feb12_144102| [-0.21733 -0.94093  0.35488 -0.63081  1.23490 -0.10059]
21Feb12_144102| [ 1.10482 -0.54999  0.06361 -0.98467  0.98841  1.10716]
21Feb12_144102| [ 0.48921  0.35977 -0.87615  1.31654  1.70644 -0.91750]
21Feb12_144102| [ 2.72869 -0.10064  1.03767 -0.61647  1.42380  1.84019]
21Feb12_144102| [-0.53304  0.42354  1.13694 -2.14180 -0.47781  0.29236]
21Feb12_144102| [-0.33778 -0.39475  0.16332 -0.15763 -0.49919 -0.89460]
21Feb12_144102| [-1.04280 -1.56283  0.36626 -0.25201 -0.28858 -1.36344]
21Feb12_144102| [-1.08871 -1.64602  0.54402  0.43907 -2.00973 -1.48787]
21Feb12_144102| [-0.21181 -0.73556 -1.98945  1.41692  0.93706 -0.25636]
21Feb12_144102| [-1.55542  0.40630  0.31652 -1.02046 -0.27004  0.19632]
21Feb12_144102| [ 1.39783 -0.54885  0.68391  1.57307 -1.07495  1.12532]
21Feb12_144102| [-0.76201 -0.04218 -0.57011 -0.52083  0.43830  2.59180]
21Feb12_144102| [-0.21753  0.04696  2.21389  2.09894 -0.29473  0.68414]
21Feb12_144102| [ 0.01575 -1.03633 -0.32878  0.69735  1.18392  0.72893]
21Feb12_144102| [-0.19264 -1.26455 -0.63480  0.76464  0.89465 -1.71142]
21Feb12_144102| [ 0.02632 -1.91608  1.58659 -0.29071  2.02573  0.03414]
21Feb12_144102| [ 1.65020 -1.27293  0.34686 -1.19815 -1.32648 -1.26882]
21Feb12_144102| [ 2.69540 -0.32808  0.31202  0.80343 -0.95016  0.44790]
21Feb12_144102| [ 0.77228  0.03163 -1.91777  0.35090 -0.34457 -1.97053]
21Feb12_144102| [ 0.56983  0.05254  1.79141  1.05885  0.24739  0.36784]
21Feb12_144102| [ 0.68847 -0.90965  0.74557 -0.99403 -1.26981 -0.61634]
21Feb12_144102| [ 0.70687  0.84294  0.57884  0.20303 -1.08778  2.00826]
21Feb12_144102| [-0.88282  0.60747 -0.54714  1.12710  0.50134  0.57920]
21Feb12_144102| [ 1.36840  0.32126 -1.29974 -0.51943 -0.41930  0.67669]
21Feb12_144102| [-0.04632 -1.30195  0.14846 -0.10446 -1.10160 -0.09529]
21Feb12_144102| [ 0.65238  0.67989 -1.96791 -1.53567 -0.85830  0.09371]
21Feb12_144102| [-0.06946  1.00221  0.03059 -0.89911 -0.41538  0.81783]
21Feb12_144102| [ 0.93359 -0.22642 -2.16799 -0.16258 -0.33185 -0.54353]
21Feb12_144102| [-0.73116  0.05803 -0.19415 -2.32698 -0.07218  0.41897]
21Feb12_144102| [ 0.01372 -1.72754  0.13547 -0.00512  0.42455 -0.36913]
21Feb12_144102| [ 1.66177  0.06579 -0.91003 -1.96934 -0.23352  1.08777]
21Feb12_144102| [ 0.09289 -1.82141 -0.78890 -2.16661  0.40321 -1.07977]
21Feb12_144102| [ 0.03205  1.35989 -0.58023  0.87747  0.15330  0.70902]
21Feb12_144102| [-0.88917 -0.10020  0.33811 -0.64537  1.24566  0.38907]
21Feb12_144102| [ 0.62530 -0.80583 -0.72489  0.51594 -1.46419 -0.95670]
21Feb12_144102| [ 0.84186  1.56276 -0.63387 -0.77819  0.18843  1.33647]
21Feb12_144102| [ 0.48085  1.19299  0.22441 -0.65616  1.25472  0.11685]
21Feb12_144102| [ 1.05217  0.40591 -1.84754 -2.43144  0.60234 -0.12202]
21Feb12_144102| [-0.00812 -1.37629  1.18334  0.13408  3.24150  0.05204]
21Feb12_144102| [ 0.28646 -0.47090 -1.33980 -0.75876 -0.74237  0.09620]]
21Feb12_144102|-- Bias --
21Feb12_144102|[-0.99248 -0.71563 -0.78878  0.27988  0.06431 -0.58382]
21Feb12_144102|Layer 1:
21Feb12_144102|-- Config --
21Feb12_144102|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144102|-- Weights --
21Feb12_144102|[[-0.74764  0.04173]
21Feb12_144102| [-0.52868  0.77131]
21Feb12_144102| [ 0.33829  0.18324]
21Feb12_144102| [ 0.05913 -2.08317]
21Feb12_144102| [ 0.46104  0.18919]
21Feb12_144102| [-1.26997 -1.60808]]
21Feb12_144102|-- Bias --
21Feb12_144102|[-0.91535  0.55242]
21Feb12_144102|Layer 2:
21Feb12_144102|-- Config --
21Feb12_144102|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144102|-- Weights --
21Feb12_144102|[[-0.54781  0.50280 -0.20410]
21Feb12_144102| [ 0.61976 -0.03473 -0.21993]]
21Feb12_144102|-- Bias --
21Feb12_144102|[ 0.80186 -1.14980 -0.80324]
21Feb12_144102|Layer 3:
21Feb12_144102|-- Config --
21Feb12_144102|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144102|-- Weights --
21Feb12_144102|[[-0.23693 -0.18694 -0.06836 -0.38083]
21Feb12_144102| [-0.18482 -0.74519  1.01192 -0.73306]
21Feb12_144102| [-1.34032 -1.90482  0.21049 -0.84424]]
21Feb12_144102|-- Bias --
21Feb12_144102|[-0.45480  0.22554  1.34863 -0.53238]
21Feb12_144102|Layer 4:
21Feb12_144102|-- Config --
21Feb12_144102|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144102|-- Weights --
21Feb12_144102|[[ 1.38774  1.08699 -0.77759  0.56311 -1.77299]
21Feb12_144102| [ 0.28391 -0.10364 -1.12276 -0.52361  0.09630]
21Feb12_144102| [-0.52512 -0.16867 -1.87508  0.57790 -1.21581]
21Feb12_144102| [ 0.13746  0.45911 -0.92657  0.25726 -0.74730]]
21Feb12_144102|-- Bias --
21Feb12_144102|[-0.14276  0.44395 -0.44961  0.47833 -0.07693]
21Feb12_144102|Layer 5:
21Feb12_144102|-- Config --
21Feb12_144102|{'name': 'Hidden6', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144102|-- Weights --
21Feb12_144102|[[-0.96618  0.96909 -0.48297 -1.11889  0.70384  0.27997]
21Feb12_144102| [-1.09513 -0.74822  0.54830  0.05093  1.12909  0.21934]
21Feb12_144102| [-0.21483 -0.43027  0.98052 -0.42408 -0.95917 -0.04963]
21Feb12_144102| [ 0.14881 -0.12743 -1.24908 -0.70705 -0.62287  0.12561]
21Feb12_144102| [-0.36569  1.22889 -0.25290  0.99234 -0.08906 -0.31559]]
21Feb12_144102|-- Bias --
21Feb12_144102|[ 0.67994  0.31382 -0.21719  0.20593  0.86896 -0.11833]
21Feb12_144102|Layer 6:
21Feb12_144102|-- Config --
21Feb12_144102|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144102|-- Weights --
21Feb12_144102|[[ 0.53450  0.24174]
21Feb12_144102| [-0.24442 -0.59403]
21Feb12_144102| [ 2.07751  0.11893]
21Feb12_144102| [-1.08995 -1.42727]
21Feb12_144102| [-0.71218  1.91415]
21Feb12_144102| [-0.32732 -0.06770]]
21Feb12_144102|-- Bias --
21Feb12_144102|[ 1.42761 -1.28538]
21Feb12_144102|Predicting the validation and test data with the Best final individual.
21Feb12_144110| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_144110|-----------  ------------------  --------------------  ----------
21Feb12_144110|Validation         24.52                 156            0.71399
21Feb12_144110|   Test            25.98                 156            0.67542
21Feb12_144110|-------------------- Test #10 --------------------
21Feb12_144110|Best final individual weights
21Feb12_144110|Individual:
21Feb12_144110|-- Constant hidden layers --
21Feb12_144110|False
21Feb12_144110|Layer 0:
21Feb12_144110|-- Config --
21Feb12_144110|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144110|-- Weights --
21Feb12_144110|[[-1.00900  0.18252  1.10044  0.29024  1.31204 -1.15151]
21Feb12_144110| [-2.44628 -0.37596 -1.43390 -1.12203 -0.04904  0.52843]
21Feb12_144110| [ 1.20049  0.03592 -0.21372  1.81446  0.86713  1.56757]
21Feb12_144110| [ 2.10403  1.12072  0.35379  0.07725 -1.49841  0.84359]
21Feb12_144110| [ 0.66667 -0.28431  0.74459  0.61496  0.80113  0.30739]
21Feb12_144110| [-0.96340  1.34729 -0.21719 -0.66682 -2.03598  0.40019]
21Feb12_144110| [-0.52124  0.08105  1.42824  0.49110 -0.04806 -0.23947]
21Feb12_144110| [ 1.14738 -0.76638  1.01210  0.27597 -0.71484  1.35432]
21Feb12_144110| [ 0.02902  1.74896 -0.19677  0.12664 -0.39990 -1.36148]
21Feb12_144110| [ 1.24576  0.19537 -0.64164  0.34542  0.54807  0.55545]
21Feb12_144110| [ 0.66620 -0.26547 -0.83577 -1.26238  0.37798 -0.27613]
21Feb12_144110| [-0.78657  0.83312 -0.98676  1.20478  0.21291 -0.93913]
21Feb12_144110| [-1.37418  0.82481 -0.15928 -1.80645  1.44130  0.21421]
21Feb12_144110| [-0.02044  0.93685  1.06133  0.15770 -0.50533 -1.09024]
21Feb12_144110| [-0.04234  1.30144  0.06884 -0.63179 -0.33612  0.07686]
21Feb12_144110| [-0.33875 -0.07463 -0.14142  1.60381 -1.09643 -1.40030]
21Feb12_144110| [ 1.53350  0.61559  0.86519 -0.23458  0.86752 -0.45258]
21Feb12_144110| [-0.21733 -0.94093  0.35488 -0.63081  1.23490 -0.10059]
21Feb12_144110| [ 1.10482 -0.54999  0.06361 -0.98467  0.98841  1.10716]
21Feb12_144110| [ 0.48921  0.35977 -0.87615  1.31654  1.70644 -0.91750]
21Feb12_144110| [ 2.72869 -0.10064  1.03767 -0.61647  1.42380  1.84019]
21Feb12_144110| [-0.53304  0.42354  1.13694 -2.14180 -0.47781  0.29236]
21Feb12_144110| [-0.33778 -0.39475  0.16332 -0.15763 -0.49919 -0.89460]
21Feb12_144110| [-1.04280 -1.56283  0.36626 -0.25201 -0.28858 -1.36344]
21Feb12_144110| [-1.08871 -1.64602  0.54402  0.43907 -2.00973 -1.48787]
21Feb12_144110| [-0.21181 -0.73556 -1.98945  1.41692  0.93706 -0.25636]
21Feb12_144110| [-1.55542  0.40630  0.31652 -1.02046 -0.27004  0.19632]
21Feb12_144110| [ 1.39783 -0.54885  0.68391  1.57307 -1.07495  1.12532]
21Feb12_144110| [-0.76201 -0.04218 -0.57011 -0.52083  0.43830  2.59180]
21Feb12_144110| [-0.21753  0.04696  2.21389  2.09894 -0.29473  0.68414]
21Feb12_144110| [ 0.01575 -1.03633 -0.32878  0.69735  1.18392  0.72893]
21Feb12_144110| [-0.19264 -1.26455 -0.63480  0.76464  0.89465 -1.71142]
21Feb12_144110| [ 0.02632 -1.91608  1.58659 -0.29071  2.02573  0.03414]
21Feb12_144110| [ 1.65020 -1.27293  0.34686 -1.19815 -1.32648 -1.26882]
21Feb12_144110| [ 2.69540 -0.32808  0.31202  0.80343 -0.95016  0.44790]
21Feb12_144110| [ 0.77228  0.03163 -1.91777  0.35090 -0.34457 -1.97053]
21Feb12_144110| [ 0.56983  0.05254  1.79141  1.05885  0.24739  0.36784]
21Feb12_144110| [ 0.68847 -0.90965  0.74557 -0.99403 -1.26981 -0.61634]
21Feb12_144110| [ 0.70687  0.84294  0.57884  0.20303 -1.08778  2.00826]
21Feb12_144110| [-0.88282  0.60747 -0.54714  1.12710  0.50134  0.57920]
21Feb12_144110| [ 1.36840  0.32126 -1.29974 -0.51943 -0.41930  0.67669]
21Feb12_144110| [-0.04632 -1.30195  0.14846 -0.10446 -1.10160 -0.09529]
21Feb12_144110| [ 0.65238  0.67989 -1.96791 -1.53567 -0.85830  0.09371]
21Feb12_144110| [-0.06946  1.00221  0.03059 -0.89911 -0.41538  0.81783]
21Feb12_144110| [ 0.93359 -0.22642 -2.16799 -0.16258 -0.33185 -0.54353]
21Feb12_144110| [-0.73116  0.05803 -0.19415 -2.32698 -0.07218  0.41897]
21Feb12_144110| [ 0.01372 -1.72754  0.13547 -0.00512  0.42455 -0.36913]
21Feb12_144110| [ 1.66177  0.06579 -0.91003 -1.96934 -0.23352  1.08777]
21Feb12_144110| [ 0.09289 -1.82141 -0.78890 -2.16661  0.40321 -1.07977]
21Feb12_144110| [ 0.03205  1.35989 -0.58023  0.87747  0.15330  0.70902]
21Feb12_144110| [-0.88917 -0.10020  0.33811 -0.64537  1.24566  0.38907]
21Feb12_144110| [ 0.62530 -0.80583 -0.72489  0.51594 -1.46419 -0.95670]
21Feb12_144110| [ 0.84186  1.56276 -0.63387 -0.77819  0.18843  1.33647]
21Feb12_144110| [ 0.48085  1.19299  0.22441 -0.65616  1.25472  0.11685]
21Feb12_144110| [ 1.05217  0.40591 -1.84754 -2.43144  0.60234 -0.12202]
21Feb12_144110| [-0.00812 -1.37629  1.18334  0.13408  3.24150  0.05204]
21Feb12_144110| [ 0.28646 -0.47090 -1.33980 -0.75876 -0.74237  0.09620]]
21Feb12_144110|-- Bias --
21Feb12_144110|[-0.99248 -0.71563 -0.78878  0.27988  0.06431 -0.58382]
21Feb12_144110|Layer 1:
21Feb12_144110|-- Config --
21Feb12_144110|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144110|-- Weights --
21Feb12_144110|[[-0.74764  0.04173]
21Feb12_144110| [-0.52868  0.77131]
21Feb12_144110| [ 0.33829  0.18324]
21Feb12_144110| [ 0.05913 -2.08317]
21Feb12_144110| [ 0.46104  0.18919]
21Feb12_144110| [-1.26997 -1.60808]]
21Feb12_144110|-- Bias --
21Feb12_144110|[-0.91535  0.55242]
21Feb12_144110|Layer 2:
21Feb12_144110|-- Config --
21Feb12_144110|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144110|-- Weights --
21Feb12_144110|[[-0.54781  0.50280 -0.20410]
21Feb12_144110| [ 0.61976 -0.03473 -0.21993]]
21Feb12_144110|-- Bias --
21Feb12_144110|[ 0.80186 -1.14980 -0.80324]
21Feb12_144110|Layer 3:
21Feb12_144110|-- Config --
21Feb12_144110|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144110|-- Weights --
21Feb12_144110|[[-0.23693 -0.18694 -0.06836 -0.38083]
21Feb12_144110| [-0.18482 -0.74519  1.01192 -0.73306]
21Feb12_144110| [-1.34032 -1.90482  0.21049 -0.84424]]
21Feb12_144110|-- Bias --
21Feb12_144110|[-0.45480  0.22554  1.34863 -0.53238]
21Feb12_144110|Layer 4:
21Feb12_144110|-- Config --
21Feb12_144110|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144110|-- Weights --
21Feb12_144110|[[ 1.38774  1.08699 -0.77759  0.56311 -1.77299]
21Feb12_144110| [ 0.28391 -0.10364 -1.12276 -0.52361  0.09630]
21Feb12_144110| [-0.52512 -0.16867 -1.87508  0.57790 -1.21581]
21Feb12_144110| [ 0.13746  0.45911 -0.92657  0.25726 -0.74730]]
21Feb12_144110|-- Bias --
21Feb12_144110|[-0.14276  0.44395 -0.44961  0.47833 -0.07693]
21Feb12_144110|Layer 5:
21Feb12_144110|-- Config --
21Feb12_144110|{'name': 'Hidden6', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144110|-- Weights --
21Feb12_144110|[[-0.96618  0.96909 -0.48297 -1.11889  0.70384  0.27997]
21Feb12_144110| [-1.09513 -0.74822  0.54830  0.05093  1.12909  0.21934]
21Feb12_144110| [-0.21483 -0.43027  0.98052 -0.42408 -0.95917 -0.04963]
21Feb12_144110| [ 0.14881 -0.12743 -1.24908 -0.70705 -0.62287  0.12561]
21Feb12_144110| [-0.36569  1.22889 -0.25290  0.99234 -0.08906 -0.31559]]
21Feb12_144110|-- Bias --
21Feb12_144110|[ 0.67994  0.31382 -0.21719  0.20593  0.86896 -0.11833]
21Feb12_144110|Layer 6:
21Feb12_144110|-- Config --
21Feb12_144110|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144110|-- Weights --
21Feb12_144110|[[ 0.53450  0.24174]
21Feb12_144110| [-0.24442 -0.59403]
21Feb12_144110| [ 2.07751  0.11893]
21Feb12_144110| [-1.08995 -1.42727]
21Feb12_144110| [-0.71218  1.91415]
21Feb12_144110| [-0.32732 -0.06770]]
21Feb12_144110|-- Bias --
21Feb12_144110|[ 1.42761 -1.28538]
21Feb12_144110|Predicting the validation and test data with the Best final individual.
21Feb12_144119| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_144119|-----------  ------------------  --------------------  ----------
21Feb12_144119|Validation         42.00                 156            0.00000
21Feb12_144119|   Test            37.19                 156            0.02352
21Feb12_144119|-------------------- Test #11 --------------------
21Feb12_144119|Best final individual weights
21Feb12_144119|Individual:
21Feb12_144119|-- Constant hidden layers --
21Feb12_144119|False
21Feb12_144119|Layer 0:
21Feb12_144119|-- Config --
21Feb12_144119|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144119|-- Weights --
21Feb12_144119|[[-1.00900  0.18252  1.10044  0.29024  1.31204 -1.15151]
21Feb12_144119| [-2.44628 -0.37596 -1.43390 -1.12203 -0.04904  0.52843]
21Feb12_144119| [ 1.20049  0.03592 -0.21372  1.81446  0.86713  1.56757]
21Feb12_144119| [ 2.10403  1.12072  0.35379  0.07725 -1.49841  0.84359]
21Feb12_144119| [ 0.66667 -0.28431  0.74459  0.61496  0.80113  0.30739]
21Feb12_144119| [-0.96340  1.34729 -0.21719 -0.66682 -2.03598  0.40019]
21Feb12_144119| [-0.52124  0.08105  1.42824  0.49110 -0.04806 -0.23947]
21Feb12_144119| [ 1.14738 -0.76638  1.01210  0.27597 -0.71484  1.35432]
21Feb12_144119| [ 0.02902  1.74896 -0.19677  0.12664 -0.39990 -1.36148]
21Feb12_144119| [ 1.24576  0.19537 -0.64164  0.34542  0.54807  0.55545]
21Feb12_144119| [ 0.66620 -0.26547 -0.83577 -1.26238  0.37798 -0.27613]
21Feb12_144119| [-0.78657  0.83312 -0.98676  1.20478  0.21291 -0.93913]
21Feb12_144119| [-1.37418  0.82481 -0.15928 -1.80645  1.44130  0.21421]
21Feb12_144119| [-0.02044  0.93685  1.06133  0.15770 -0.50533 -1.09024]
21Feb12_144119| [-0.04234  1.30144  0.06884 -0.63179 -0.33612  0.07686]
21Feb12_144119| [-0.33875 -0.07463 -0.14142  1.60381 -1.09643 -1.40030]
21Feb12_144119| [ 1.53350  0.61559  0.86519 -0.23458  0.86752 -0.45258]
21Feb12_144119| [-0.21733 -0.94093  0.35488 -0.63081  1.23490 -0.10059]
21Feb12_144119| [ 1.10482 -0.54999  0.06361 -0.98467  0.98841  1.10716]
21Feb12_144119| [ 0.48921  0.35977 -0.87615  1.31654  1.70644 -0.91750]
21Feb12_144119| [ 2.72869 -0.10064  1.03767 -0.61647  1.42380  1.84019]
21Feb12_144119| [-0.53304  0.42354  1.13694 -2.14180 -0.47781  0.29236]
21Feb12_144119| [-0.33778 -0.39475  0.16332 -0.15763 -0.49919 -0.89460]
21Feb12_144119| [-1.04280 -1.56283  0.36626 -0.25201 -0.28858 -1.36344]
21Feb12_144119| [-1.08871 -1.64602  0.54402  0.43907 -2.00973 -1.48787]
21Feb12_144119| [-0.21181 -0.73556 -1.98945  1.41692  0.93706 -0.25636]
21Feb12_144119| [-1.55542  0.40630  0.31652 -1.02046 -0.27004  0.19632]
21Feb12_144119| [ 1.39783 -0.54885  0.68391  1.57307 -1.07495  1.12532]
21Feb12_144119| [-0.76201 -0.04218 -0.57011 -0.52083  0.43830  2.59180]
21Feb12_144119| [-0.21753  0.04696  2.21389  2.09894 -0.29473  0.68414]
21Feb12_144119| [ 0.01575 -1.03633 -0.32878  0.69735  1.18392  0.72893]
21Feb12_144119| [-0.19264 -1.26455 -0.63480  0.76464  0.89465 -1.71142]
21Feb12_144119| [ 0.02632 -1.91608  1.58659 -0.29071  2.02573  0.03414]
21Feb12_144119| [ 1.65020 -1.27293  0.34686 -1.19815 -1.32648 -1.26882]
21Feb12_144119| [ 2.69540 -0.32808  0.31202  0.80343 -0.95016  0.44790]
21Feb12_144119| [ 0.77228  0.03163 -1.91777  0.35090 -0.34457 -1.97053]
21Feb12_144119| [ 0.56983  0.05254  1.79141  1.05885  0.24739  0.36784]
21Feb12_144119| [ 0.68847 -0.90965  0.74557 -0.99403 -1.26981 -0.61634]
21Feb12_144119| [ 0.70687  0.84294  0.57884  0.20303 -1.08778  2.00826]
21Feb12_144119| [-0.88282  0.60747 -0.54714  1.12710  0.50134  0.57920]
21Feb12_144119| [ 1.36840  0.32126 -1.29974 -0.51943 -0.41930  0.67669]
21Feb12_144119| [-0.04632 -1.30195  0.14846 -0.10446 -1.10160 -0.09529]
21Feb12_144119| [ 0.65238  0.67989 -1.96791 -1.53567 -0.85830  0.09371]
21Feb12_144119| [-0.06946  1.00221  0.03059 -0.89911 -0.41538  0.81783]
21Feb12_144119| [ 0.93359 -0.22642 -2.16799 -0.16258 -0.33185 -0.54353]
21Feb12_144119| [-0.73116  0.05803 -0.19415 -2.32698 -0.07218  0.41897]
21Feb12_144119| [ 0.01372 -1.72754  0.13547 -0.00512  0.42455 -0.36913]
21Feb12_144119| [ 1.66177  0.06579 -0.91003 -1.96934 -0.23352  1.08777]
21Feb12_144119| [ 0.09289 -1.82141 -0.78890 -2.16661  0.40321 -1.07977]
21Feb12_144119| [ 0.03205  1.35989 -0.58023  0.87747  0.15330  0.70902]
21Feb12_144119| [-0.88917 -0.10020  0.33811 -0.64537  1.24566  0.38907]
21Feb12_144119| [ 0.62530 -0.80583 -0.72489  0.51594 -1.46419 -0.95670]
21Feb12_144119| [ 0.84186  1.56276 -0.63387 -0.77819  0.18843  1.33647]
21Feb12_144119| [ 0.48085  1.19299  0.22441 -0.65616  1.25472  0.11685]
21Feb12_144119| [ 1.05217  0.40591 -1.84754 -2.43144  0.60234 -0.12202]
21Feb12_144119| [-0.00812 -1.37629  1.18334  0.13408  3.24150  0.05204]
21Feb12_144119| [ 0.28646 -0.47090 -1.33980 -0.75876 -0.74237  0.09620]]
21Feb12_144119|-- Bias --
21Feb12_144119|[-0.99248 -0.71563 -0.78878  0.27988  0.06431 -0.58382]
21Feb12_144119|Layer 1:
21Feb12_144119|-- Config --
21Feb12_144119|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144119|-- Weights --
21Feb12_144119|[[-0.74764  0.04173]
21Feb12_144119| [-0.52868  0.77131]
21Feb12_144119| [ 0.33829  0.18324]
21Feb12_144119| [ 0.05913 -2.08317]
21Feb12_144119| [ 0.46104  0.18919]
21Feb12_144119| [-1.26997 -1.60808]]
21Feb12_144119|-- Bias --
21Feb12_144119|[-0.91535  0.55242]
21Feb12_144119|Layer 2:
21Feb12_144119|-- Config --
21Feb12_144119|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144119|-- Weights --
21Feb12_144119|[[-0.54781  0.50280 -0.20410]
21Feb12_144119| [ 0.61976 -0.03473 -0.21993]]
21Feb12_144119|-- Bias --
21Feb12_144119|[ 0.80186 -1.14980 -0.80324]
21Feb12_144119|Layer 3:
21Feb12_144119|-- Config --
21Feb12_144119|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144119|-- Weights --
21Feb12_144119|[[-0.23693 -0.18694 -0.06836 -0.38083]
21Feb12_144119| [-0.18482 -0.74519  1.01192 -0.73306]
21Feb12_144119| [-1.34032 -1.90482  0.21049 -0.84424]]
21Feb12_144119|-- Bias --
21Feb12_144119|[-0.45480  0.22554  1.34863 -0.53238]
21Feb12_144119|Layer 4:
21Feb12_144119|-- Config --
21Feb12_144119|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144119|-- Weights --
21Feb12_144119|[[ 1.38774  1.08699 -0.77759  0.56311 -1.77299]
21Feb12_144119| [ 0.28391 -0.10364 -1.12276 -0.52361  0.09630]
21Feb12_144119| [-0.52512 -0.16867 -1.87508  0.57790 -1.21581]
21Feb12_144119| [ 0.13746  0.45911 -0.92657  0.25726 -0.74730]]
21Feb12_144119|-- Bias --
21Feb12_144119|[-0.14276  0.44395 -0.44961  0.47833 -0.07693]
21Feb12_144119|Layer 5:
21Feb12_144119|-- Config --
21Feb12_144119|{'name': 'Hidden6', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144119|-- Weights --
21Feb12_144119|[[-0.96618  0.96909 -0.48297 -1.11889  0.70384  0.27997]
21Feb12_144119| [-1.09513 -0.74822  0.54830  0.05093  1.12909  0.21934]
21Feb12_144119| [-0.21483 -0.43027  0.98052 -0.42408 -0.95917 -0.04963]
21Feb12_144119| [ 0.14881 -0.12743 -1.24908 -0.70705 -0.62287  0.12561]
21Feb12_144119| [-0.36569  1.22889 -0.25290  0.99234 -0.08906 -0.31559]]
21Feb12_144119|-- Bias --
21Feb12_144119|[ 0.67994  0.31382 -0.21719  0.20593  0.86896 -0.11833]
21Feb12_144119|Layer 6:
21Feb12_144119|-- Config --
21Feb12_144119|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144119|-- Weights --
21Feb12_144119|[[ 0.53450  0.24174]
21Feb12_144119| [-0.24442 -0.59403]
21Feb12_144119| [ 2.07751  0.11893]
21Feb12_144119| [-1.08995 -1.42727]
21Feb12_144119| [-0.71218  1.91415]
21Feb12_144119| [-0.32732 -0.06770]]
21Feb12_144119|-- Bias --
21Feb12_144119|[ 1.42761 -1.28538]
21Feb12_144119|Predicting the validation and test data with the Best final individual.
21Feb12_144128| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_144128|-----------  ------------------  --------------------  ----------
21Feb12_144128|Validation         21.83                 156            0.83203
21Feb12_144128|   Test            21.55                 156            0.74592
21Feb12_144128|-------------------- Test #12 --------------------
21Feb12_144128|Best final individual weights
21Feb12_144128|Individual:
21Feb12_144128|-- Constant hidden layers --
21Feb12_144128|False
21Feb12_144128|Layer 0:
21Feb12_144128|-- Config --
21Feb12_144128|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144128|-- Weights --
21Feb12_144128|[[-1.00900  0.18252  1.10044  0.29024  1.31204 -1.15151]
21Feb12_144128| [-2.44628 -0.37596 -1.43390 -1.12203 -0.04904  0.52843]
21Feb12_144128| [ 1.20049  0.03592 -0.21372  1.81446  0.86713  1.56757]
21Feb12_144128| [ 2.10403  1.12072  0.35379  0.07725 -1.49841  0.84359]
21Feb12_144128| [ 0.66667 -0.28431  0.74459  0.61496  0.80113  0.30739]
21Feb12_144128| [-0.96340  1.34729 -0.21719 -0.66682 -2.03598  0.40019]
21Feb12_144128| [-0.52124  0.08105  1.42824  0.49110 -0.04806 -0.23947]
21Feb12_144128| [ 1.14738 -0.76638  1.01210  0.27597 -0.71484  1.35432]
21Feb12_144128| [ 0.02902  1.74896 -0.19677  0.12664 -0.39990 -1.36148]
21Feb12_144128| [ 1.24576  0.19537 -0.64164  0.34542  0.54807  0.55545]
21Feb12_144128| [ 0.66620 -0.26547 -0.83577 -1.26238  0.37798 -0.27613]
21Feb12_144128| [-0.78657  0.83312 -0.98676  1.20478  0.21291 -0.93913]
21Feb12_144128| [-1.37418  0.82481 -0.15928 -1.80645  1.44130  0.21421]
21Feb12_144128| [-0.02044  0.93685  1.06133  0.15770 -0.50533 -1.09024]
21Feb12_144128| [-0.04234  1.30144  0.06884 -0.63179 -0.33612  0.07686]
21Feb12_144128| [-0.33875 -0.07463 -0.14142  1.60381 -1.09643 -1.40030]
21Feb12_144128| [ 1.53350  0.61559  0.86519 -0.23458  0.86752 -0.45258]
21Feb12_144128| [-0.21733 -0.94093  0.35488 -0.63081  1.23490 -0.10059]
21Feb12_144128| [ 1.10482 -0.54999  0.06361 -0.98467  0.98841  1.10716]
21Feb12_144128| [ 0.48921  0.35977 -0.87615  1.31654  1.70644 -0.91750]
21Feb12_144128| [ 2.72869 -0.10064  1.03767 -0.61647  1.42380  1.84019]
21Feb12_144128| [-0.53304  0.42354  1.13694 -2.14180 -0.47781  0.29236]
21Feb12_144128| [-0.33778 -0.39475  0.16332 -0.15763 -0.49919 -0.89460]
21Feb12_144128| [-1.04280 -1.56283  0.36626 -0.25201 -0.28858 -1.36344]
21Feb12_144128| [-1.08871 -1.64602  0.54402  0.43907 -2.00973 -1.48787]
21Feb12_144128| [-0.21181 -0.73556 -1.98945  1.41692  0.93706 -0.25636]
21Feb12_144128| [-1.55542  0.40630  0.31652 -1.02046 -0.27004  0.19632]
21Feb12_144128| [ 1.39783 -0.54885  0.68391  1.57307 -1.07495  1.12532]
21Feb12_144128| [-0.76201 -0.04218 -0.57011 -0.52083  0.43830  2.59180]
21Feb12_144128| [-0.21753  0.04696  2.21389  2.09894 -0.29473  0.68414]
21Feb12_144128| [ 0.01575 -1.03633 -0.32878  0.69735  1.18392  0.72893]
21Feb12_144128| [-0.19264 -1.26455 -0.63480  0.76464  0.89465 -1.71142]
21Feb12_144128| [ 0.02632 -1.91608  1.58659 -0.29071  2.02573  0.03414]
21Feb12_144128| [ 1.65020 -1.27293  0.34686 -1.19815 -1.32648 -1.26882]
21Feb12_144128| [ 2.69540 -0.32808  0.31202  0.80343 -0.95016  0.44790]
21Feb12_144128| [ 0.77228  0.03163 -1.91777  0.35090 -0.34457 -1.97053]
21Feb12_144128| [ 0.56983  0.05254  1.79141  1.05885  0.24739  0.36784]
21Feb12_144128| [ 0.68847 -0.90965  0.74557 -0.99403 -1.26981 -0.61634]
21Feb12_144128| [ 0.70687  0.84294  0.57884  0.20303 -1.08778  2.00826]
21Feb12_144128| [-0.88282  0.60747 -0.54714  1.12710  0.50134  0.57920]
21Feb12_144128| [ 1.36840  0.32126 -1.29974 -0.51943 -0.41930  0.67669]
21Feb12_144128| [-0.04632 -1.30195  0.14846 -0.10446 -1.10160 -0.09529]
21Feb12_144128| [ 0.65238  0.67989 -1.96791 -1.53567 -0.85830  0.09371]
21Feb12_144128| [-0.06946  1.00221  0.03059 -0.89911 -0.41538  0.81783]
21Feb12_144128| [ 0.93359 -0.22642 -2.16799 -0.16258 -0.33185 -0.54353]
21Feb12_144128| [-0.73116  0.05803 -0.19415 -2.32698 -0.07218  0.41897]
21Feb12_144128| [ 0.01372 -1.72754  0.13547 -0.00512  0.42455 -0.36913]
21Feb12_144128| [ 1.66177  0.06579 -0.91003 -1.96934 -0.23352  1.08777]
21Feb12_144128| [ 0.09289 -1.82141 -0.78890 -2.16661  0.40321 -1.07977]
21Feb12_144128| [ 0.03205  1.35989 -0.58023  0.87747  0.15330  0.70902]
21Feb12_144128| [-0.88917 -0.10020  0.33811 -0.64537  1.24566  0.38907]
21Feb12_144128| [ 0.62530 -0.80583 -0.72489  0.51594 -1.46419 -0.95670]
21Feb12_144128| [ 0.84186  1.56276 -0.63387 -0.77819  0.18843  1.33647]
21Feb12_144128| [ 0.48085  1.19299  0.22441 -0.65616  1.25472  0.11685]
21Feb12_144128| [ 1.05217  0.40591 -1.84754 -2.43144  0.60234 -0.12202]
21Feb12_144128| [-0.00812 -1.37629  1.18334  0.13408  3.24150  0.05204]
21Feb12_144128| [ 0.28646 -0.47090 -1.33980 -0.75876 -0.74237  0.09620]]
21Feb12_144128|-- Bias --
21Feb12_144128|[-0.99248 -0.71563 -0.78878  0.27988  0.06431 -0.58382]
21Feb12_144128|Layer 1:
21Feb12_144128|-- Config --
21Feb12_144128|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144128|-- Weights --
21Feb12_144128|[[-0.74764  0.04173]
21Feb12_144128| [-0.52868  0.77131]
21Feb12_144128| [ 0.33829  0.18324]
21Feb12_144128| [ 0.05913 -2.08317]
21Feb12_144128| [ 0.46104  0.18919]
21Feb12_144128| [-1.26997 -1.60808]]
21Feb12_144128|-- Bias --
21Feb12_144128|[-0.91535  0.55242]
21Feb12_144128|Layer 2:
21Feb12_144128|-- Config --
21Feb12_144128|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144128|-- Weights --
21Feb12_144128|[[-0.54781  0.50280 -0.20410]
21Feb12_144128| [ 0.61976 -0.03473 -0.21993]]
21Feb12_144128|-- Bias --
21Feb12_144128|[ 0.80186 -1.14980 -0.80324]
21Feb12_144128|Layer 3:
21Feb12_144128|-- Config --
21Feb12_144128|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144128|-- Weights --
21Feb12_144128|[[-0.23693 -0.18694 -0.06836 -0.38083]
21Feb12_144128| [-0.18482 -0.74519  1.01192 -0.73306]
21Feb12_144128| [-1.34032 -1.90482  0.21049 -0.84424]]
21Feb12_144128|-- Bias --
21Feb12_144128|[-0.45480  0.22554  1.34863 -0.53238]
21Feb12_144128|Layer 4:
21Feb12_144128|-- Config --
21Feb12_144128|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144128|-- Weights --
21Feb12_144128|[[ 1.38774  1.08699 -0.77759  0.56311 -1.77299]
21Feb12_144128| [ 0.28391 -0.10364 -1.12276 -0.52361  0.09630]
21Feb12_144128| [-0.52512 -0.16867 -1.87508  0.57790 -1.21581]
21Feb12_144128| [ 0.13746  0.45911 -0.92657  0.25726 -0.74730]]
21Feb12_144128|-- Bias --
21Feb12_144128|[-0.14276  0.44395 -0.44961  0.47833 -0.07693]
21Feb12_144128|Layer 5:
21Feb12_144128|-- Config --
21Feb12_144128|{'name': 'Hidden6', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144128|-- Weights --
21Feb12_144128|[[-0.96618  0.96909 -0.48297 -1.11889  0.70384  0.27997]
21Feb12_144128| [-1.09513 -0.74822  0.54830  0.05093  1.12909  0.21934]
21Feb12_144128| [-0.21483 -0.43027  0.98052 -0.42408 -0.95917 -0.04963]
21Feb12_144128| [ 0.14881 -0.12743 -1.24908 -0.70705 -0.62287  0.12561]
21Feb12_144128| [-0.36569  1.22889 -0.25290  0.99234 -0.08906 -0.31559]]
21Feb12_144128|-- Bias --
21Feb12_144128|[ 0.67994  0.31382 -0.21719  0.20593  0.86896 -0.11833]
21Feb12_144128|Layer 6:
21Feb12_144128|-- Config --
21Feb12_144128|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144128|-- Weights --
21Feb12_144128|[[ 0.53450  0.24174]
21Feb12_144128| [-0.24442 -0.59403]
21Feb12_144128| [ 2.07751  0.11893]
21Feb12_144128| [-1.08995 -1.42727]
21Feb12_144128| [-0.71218  1.91415]
21Feb12_144128| [-0.32732 -0.06770]]
21Feb12_144128|-- Bias --
21Feb12_144128|[ 1.42761 -1.28538]
21Feb12_144128|Predicting the validation and test data with the Best final individual.
21Feb12_144136| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_144136|-----------  ------------------  --------------------  ----------
21Feb12_144136|Validation         27.22                 156            0.53699
21Feb12_144136|   Test            33.01                 156            0.80538
21Feb12_144136|-------------------- Test #13 --------------------
21Feb12_144136|Best final individual weights
21Feb12_144136|Individual:
21Feb12_144136|-- Constant hidden layers --
21Feb12_144136|False
21Feb12_144136|Layer 0:
21Feb12_144136|-- Config --
21Feb12_144136|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144136|-- Weights --
21Feb12_144136|[[-1.00900  0.18252  1.10044  0.29024  1.31204 -1.15151]
21Feb12_144136| [-2.44628 -0.37596 -1.43390 -1.12203 -0.04904  0.52843]
21Feb12_144136| [ 1.20049  0.03592 -0.21372  1.81446  0.86713  1.56757]
21Feb12_144136| [ 2.10403  1.12072  0.35379  0.07725 -1.49841  0.84359]
21Feb12_144136| [ 0.66667 -0.28431  0.74459  0.61496  0.80113  0.30739]
21Feb12_144136| [-0.96340  1.34729 -0.21719 -0.66682 -2.03598  0.40019]
21Feb12_144136| [-0.52124  0.08105  1.42824  0.49110 -0.04806 -0.23947]
21Feb12_144136| [ 1.14738 -0.76638  1.01210  0.27597 -0.71484  1.35432]
21Feb12_144136| [ 0.02902  1.74896 -0.19677  0.12664 -0.39990 -1.36148]
21Feb12_144136| [ 1.24576  0.19537 -0.64164  0.34542  0.54807  0.55545]
21Feb12_144136| [ 0.66620 -0.26547 -0.83577 -1.26238  0.37798 -0.27613]
21Feb12_144136| [-0.78657  0.83312 -0.98676  1.20478  0.21291 -0.93913]
21Feb12_144136| [-1.37418  0.82481 -0.15928 -1.80645  1.44130  0.21421]
21Feb12_144136| [-0.02044  0.93685  1.06133  0.15770 -0.50533 -1.09024]
21Feb12_144136| [-0.04234  1.30144  0.06884 -0.63179 -0.33612  0.07686]
21Feb12_144136| [-0.33875 -0.07463 -0.14142  1.60381 -1.09643 -1.40030]
21Feb12_144136| [ 1.53350  0.61559  0.86519 -0.23458  0.86752 -0.45258]
21Feb12_144136| [-0.21733 -0.94093  0.35488 -0.63081  1.23490 -0.10059]
21Feb12_144136| [ 1.10482 -0.54999  0.06361 -0.98467  0.98841  1.10716]
21Feb12_144136| [ 0.48921  0.35977 -0.87615  1.31654  1.70644 -0.91750]
21Feb12_144136| [ 2.72869 -0.10064  1.03767 -0.61647  1.42380  1.84019]
21Feb12_144136| [-0.53304  0.42354  1.13694 -2.14180 -0.47781  0.29236]
21Feb12_144136| [-0.33778 -0.39475  0.16332 -0.15763 -0.49919 -0.89460]
21Feb12_144136| [-1.04280 -1.56283  0.36626 -0.25201 -0.28858 -1.36344]
21Feb12_144136| [-1.08871 -1.64602  0.54402  0.43907 -2.00973 -1.48787]
21Feb12_144136| [-0.21181 -0.73556 -1.98945  1.41692  0.93706 -0.25636]
21Feb12_144136| [-1.55542  0.40630  0.31652 -1.02046 -0.27004  0.19632]
21Feb12_144136| [ 1.39783 -0.54885  0.68391  1.57307 -1.07495  1.12532]
21Feb12_144136| [-0.76201 -0.04218 -0.57011 -0.52083  0.43830  2.59180]
21Feb12_144136| [-0.21753  0.04696  2.21389  2.09894 -0.29473  0.68414]
21Feb12_144136| [ 0.01575 -1.03633 -0.32878  0.69735  1.18392  0.72893]
21Feb12_144136| [-0.19264 -1.26455 -0.63480  0.76464  0.89465 -1.71142]
21Feb12_144136| [ 0.02632 -1.91608  1.58659 -0.29071  2.02573  0.03414]
21Feb12_144136| [ 1.65020 -1.27293  0.34686 -1.19815 -1.32648 -1.26882]
21Feb12_144136| [ 2.69540 -0.32808  0.31202  0.80343 -0.95016  0.44790]
21Feb12_144136| [ 0.77228  0.03163 -1.91777  0.35090 -0.34457 -1.97053]
21Feb12_144136| [ 0.56983  0.05254  1.79141  1.05885  0.24739  0.36784]
21Feb12_144136| [ 0.68847 -0.90965  0.74557 -0.99403 -1.26981 -0.61634]
21Feb12_144136| [ 0.70687  0.84294  0.57884  0.20303 -1.08778  2.00826]
21Feb12_144136| [-0.88282  0.60747 -0.54714  1.12710  0.50134  0.57920]
21Feb12_144136| [ 1.36840  0.32126 -1.29974 -0.51943 -0.41930  0.67669]
21Feb12_144136| [-0.04632 -1.30195  0.14846 -0.10446 -1.10160 -0.09529]
21Feb12_144136| [ 0.65238  0.67989 -1.96791 -1.53567 -0.85830  0.09371]
21Feb12_144136| [-0.06946  1.00221  0.03059 -0.89911 -0.41538  0.81783]
21Feb12_144136| [ 0.93359 -0.22642 -2.16799 -0.16258 -0.33185 -0.54353]
21Feb12_144136| [-0.73116  0.05803 -0.19415 -2.32698 -0.07218  0.41897]
21Feb12_144136| [ 0.01372 -1.72754  0.13547 -0.00512  0.42455 -0.36913]
21Feb12_144136| [ 1.66177  0.06579 -0.91003 -1.96934 -0.23352  1.08777]
21Feb12_144136| [ 0.09289 -1.82141 -0.78890 -2.16661  0.40321 -1.07977]
21Feb12_144136| [ 0.03205  1.35989 -0.58023  0.87747  0.15330  0.70902]
21Feb12_144136| [-0.88917 -0.10020  0.33811 -0.64537  1.24566  0.38907]
21Feb12_144136| [ 0.62530 -0.80583 -0.72489  0.51594 -1.46419 -0.95670]
21Feb12_144136| [ 0.84186  1.56276 -0.63387 -0.77819  0.18843  1.33647]
21Feb12_144136| [ 0.48085  1.19299  0.22441 -0.65616  1.25472  0.11685]
21Feb12_144136| [ 1.05217  0.40591 -1.84754 -2.43144  0.60234 -0.12202]
21Feb12_144136| [-0.00812 -1.37629  1.18334  0.13408  3.24150  0.05204]
21Feb12_144136| [ 0.28646 -0.47090 -1.33980 -0.75876 -0.74237  0.09620]]
21Feb12_144136|-- Bias --
21Feb12_144136|[-0.99248 -0.71563 -0.78878  0.27988  0.06431 -0.58382]
21Feb12_144136|Layer 1:
21Feb12_144136|-- Config --
21Feb12_144136|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144136|-- Weights --
21Feb12_144136|[[-0.74764  0.04173]
21Feb12_144136| [-0.52868  0.77131]
21Feb12_144136| [ 0.33829  0.18324]
21Feb12_144136| [ 0.05913 -2.08317]
21Feb12_144136| [ 0.46104  0.18919]
21Feb12_144136| [-1.26997 -1.60808]]
21Feb12_144136|-- Bias --
21Feb12_144136|[-0.91535  0.55242]
21Feb12_144136|Layer 2:
21Feb12_144136|-- Config --
21Feb12_144136|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144136|-- Weights --
21Feb12_144136|[[-0.54781  0.50280 -0.20410]
21Feb12_144136| [ 0.61976 -0.03473 -0.21993]]
21Feb12_144136|-- Bias --
21Feb12_144136|[ 0.80186 -1.14980 -0.80324]
21Feb12_144136|Layer 3:
21Feb12_144136|-- Config --
21Feb12_144136|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144136|-- Weights --
21Feb12_144136|[[-0.23693 -0.18694 -0.06836 -0.38083]
21Feb12_144136| [-0.18482 -0.74519  1.01192 -0.73306]
21Feb12_144136| [-1.34032 -1.90482  0.21049 -0.84424]]
21Feb12_144136|-- Bias --
21Feb12_144136|[-0.45480  0.22554  1.34863 -0.53238]
21Feb12_144136|Layer 4:
21Feb12_144136|-- Config --
21Feb12_144136|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144136|-- Weights --
21Feb12_144136|[[ 1.38774  1.08699 -0.77759  0.56311 -1.77299]
21Feb12_144136| [ 0.28391 -0.10364 -1.12276 -0.52361  0.09630]
21Feb12_144136| [-0.52512 -0.16867 -1.87508  0.57790 -1.21581]
21Feb12_144136| [ 0.13746  0.45911 -0.92657  0.25726 -0.74730]]
21Feb12_144136|-- Bias --
21Feb12_144136|[-0.14276  0.44395 -0.44961  0.47833 -0.07693]
21Feb12_144136|Layer 5:
21Feb12_144136|-- Config --
21Feb12_144136|{'name': 'Hidden6', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144136|-- Weights --
21Feb12_144136|[[-0.96618  0.96909 -0.48297 -1.11889  0.70384  0.27997]
21Feb12_144136| [-1.09513 -0.74822  0.54830  0.05093  1.12909  0.21934]
21Feb12_144136| [-0.21483 -0.43027  0.98052 -0.42408 -0.95917 -0.04963]
21Feb12_144136| [ 0.14881 -0.12743 -1.24908 -0.70705 -0.62287  0.12561]
21Feb12_144136| [-0.36569  1.22889 -0.25290  0.99234 -0.08906 -0.31559]]
21Feb12_144136|-- Bias --
21Feb12_144136|[ 0.67994  0.31382 -0.21719  0.20593  0.86896 -0.11833]
21Feb12_144136|Layer 6:
21Feb12_144136|-- Config --
21Feb12_144136|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144136|-- Weights --
21Feb12_144136|[[ 0.53450  0.24174]
21Feb12_144136| [-0.24442 -0.59403]
21Feb12_144136| [ 2.07751  0.11893]
21Feb12_144136| [-1.08995 -1.42727]
21Feb12_144136| [-0.71218  1.91415]
21Feb12_144136| [-0.32732 -0.06770]]
21Feb12_144136|-- Bias --
21Feb12_144136|[ 1.42761 -1.28538]
21Feb12_144136|Predicting the validation and test data with the Best final individual.
21Feb12_144145| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_144145|-----------  ------------------  --------------------  ----------
21Feb12_144145|Validation         26.87                 156            0.67786
21Feb12_144145|   Test            36.40                 156            0.00000
21Feb12_144145|-------------------- Test #14 --------------------
21Feb12_144145|Best final individual weights
21Feb12_144145|Individual:
21Feb12_144145|-- Constant hidden layers --
21Feb12_144145|False
21Feb12_144145|Layer 0:
21Feb12_144145|-- Config --
21Feb12_144145|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144145|-- Weights --
21Feb12_144145|[[-1.00900  0.18252  1.10044  0.29024  1.31204 -1.15151]
21Feb12_144145| [-2.44628 -0.37596 -1.43390 -1.12203 -0.04904  0.52843]
21Feb12_144145| [ 1.20049  0.03592 -0.21372  1.81446  0.86713  1.56757]
21Feb12_144145| [ 2.10403  1.12072  0.35379  0.07725 -1.49841  0.84359]
21Feb12_144145| [ 0.66667 -0.28431  0.74459  0.61496  0.80113  0.30739]
21Feb12_144145| [-0.96340  1.34729 -0.21719 -0.66682 -2.03598  0.40019]
21Feb12_144145| [-0.52124  0.08105  1.42824  0.49110 -0.04806 -0.23947]
21Feb12_144145| [ 1.14738 -0.76638  1.01210  0.27597 -0.71484  1.35432]
21Feb12_144145| [ 0.02902  1.74896 -0.19677  0.12664 -0.39990 -1.36148]
21Feb12_144145| [ 1.24576  0.19537 -0.64164  0.34542  0.54807  0.55545]
21Feb12_144145| [ 0.66620 -0.26547 -0.83577 -1.26238  0.37798 -0.27613]
21Feb12_144145| [-0.78657  0.83312 -0.98676  1.20478  0.21291 -0.93913]
21Feb12_144145| [-1.37418  0.82481 -0.15928 -1.80645  1.44130  0.21421]
21Feb12_144145| [-0.02044  0.93685  1.06133  0.15770 -0.50533 -1.09024]
21Feb12_144145| [-0.04234  1.30144  0.06884 -0.63179 -0.33612  0.07686]
21Feb12_144145| [-0.33875 -0.07463 -0.14142  1.60381 -1.09643 -1.40030]
21Feb12_144145| [ 1.53350  0.61559  0.86519 -0.23458  0.86752 -0.45258]
21Feb12_144145| [-0.21733 -0.94093  0.35488 -0.63081  1.23490 -0.10059]
21Feb12_144145| [ 1.10482 -0.54999  0.06361 -0.98467  0.98841  1.10716]
21Feb12_144145| [ 0.48921  0.35977 -0.87615  1.31654  1.70644 -0.91750]
21Feb12_144145| [ 2.72869 -0.10064  1.03767 -0.61647  1.42380  1.84019]
21Feb12_144145| [-0.53304  0.42354  1.13694 -2.14180 -0.47781  0.29236]
21Feb12_144145| [-0.33778 -0.39475  0.16332 -0.15763 -0.49919 -0.89460]
21Feb12_144145| [-1.04280 -1.56283  0.36626 -0.25201 -0.28858 -1.36344]
21Feb12_144145| [-1.08871 -1.64602  0.54402  0.43907 -2.00973 -1.48787]
21Feb12_144145| [-0.21181 -0.73556 -1.98945  1.41692  0.93706 -0.25636]
21Feb12_144145| [-1.55542  0.40630  0.31652 -1.02046 -0.27004  0.19632]
21Feb12_144145| [ 1.39783 -0.54885  0.68391  1.57307 -1.07495  1.12532]
21Feb12_144145| [-0.76201 -0.04218 -0.57011 -0.52083  0.43830  2.59180]
21Feb12_144145| [-0.21753  0.04696  2.21389  2.09894 -0.29473  0.68414]
21Feb12_144145| [ 0.01575 -1.03633 -0.32878  0.69735  1.18392  0.72893]
21Feb12_144145| [-0.19264 -1.26455 -0.63480  0.76464  0.89465 -1.71142]
21Feb12_144145| [ 0.02632 -1.91608  1.58659 -0.29071  2.02573  0.03414]
21Feb12_144145| [ 1.65020 -1.27293  0.34686 -1.19815 -1.32648 -1.26882]
21Feb12_144145| [ 2.69540 -0.32808  0.31202  0.80343 -0.95016  0.44790]
21Feb12_144145| [ 0.77228  0.03163 -1.91777  0.35090 -0.34457 -1.97053]
21Feb12_144145| [ 0.56983  0.05254  1.79141  1.05885  0.24739  0.36784]
21Feb12_144145| [ 0.68847 -0.90965  0.74557 -0.99403 -1.26981 -0.61634]
21Feb12_144145| [ 0.70687  0.84294  0.57884  0.20303 -1.08778  2.00826]
21Feb12_144145| [-0.88282  0.60747 -0.54714  1.12710  0.50134  0.57920]
21Feb12_144145| [ 1.36840  0.32126 -1.29974 -0.51943 -0.41930  0.67669]
21Feb12_144145| [-0.04632 -1.30195  0.14846 -0.10446 -1.10160 -0.09529]
21Feb12_144145| [ 0.65238  0.67989 -1.96791 -1.53567 -0.85830  0.09371]
21Feb12_144145| [-0.06946  1.00221  0.03059 -0.89911 -0.41538  0.81783]
21Feb12_144145| [ 0.93359 -0.22642 -2.16799 -0.16258 -0.33185 -0.54353]
21Feb12_144145| [-0.73116  0.05803 -0.19415 -2.32698 -0.07218  0.41897]
21Feb12_144145| [ 0.01372 -1.72754  0.13547 -0.00512  0.42455 -0.36913]
21Feb12_144145| [ 1.66177  0.06579 -0.91003 -1.96934 -0.23352  1.08777]
21Feb12_144145| [ 0.09289 -1.82141 -0.78890 -2.16661  0.40321 -1.07977]
21Feb12_144145| [ 0.03205  1.35989 -0.58023  0.87747  0.15330  0.70902]
21Feb12_144145| [-0.88917 -0.10020  0.33811 -0.64537  1.24566  0.38907]
21Feb12_144145| [ 0.62530 -0.80583 -0.72489  0.51594 -1.46419 -0.95670]
21Feb12_144145| [ 0.84186  1.56276 -0.63387 -0.77819  0.18843  1.33647]
21Feb12_144145| [ 0.48085  1.19299  0.22441 -0.65616  1.25472  0.11685]
21Feb12_144145| [ 1.05217  0.40591 -1.84754 -2.43144  0.60234 -0.12202]
21Feb12_144145| [-0.00812 -1.37629  1.18334  0.13408  3.24150  0.05204]
21Feb12_144145| [ 0.28646 -0.47090 -1.33980 -0.75876 -0.74237  0.09620]]
21Feb12_144145|-- Bias --
21Feb12_144145|[-0.99248 -0.71563 -0.78878  0.27988  0.06431 -0.58382]
21Feb12_144145|Layer 1:
21Feb12_144145|-- Config --
21Feb12_144145|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144145|-- Weights --
21Feb12_144145|[[-0.74764  0.04173]
21Feb12_144145| [-0.52868  0.77131]
21Feb12_144145| [ 0.33829  0.18324]
21Feb12_144145| [ 0.05913 -2.08317]
21Feb12_144145| [ 0.46104  0.18919]
21Feb12_144145| [-1.26997 -1.60808]]
21Feb12_144145|-- Bias --
21Feb12_144145|[-0.91535  0.55242]
21Feb12_144145|Layer 2:
21Feb12_144145|-- Config --
21Feb12_144145|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144145|-- Weights --
21Feb12_144145|[[-0.54781  0.50280 -0.20410]
21Feb12_144145| [ 0.61976 -0.03473 -0.21993]]
21Feb12_144145|-- Bias --
21Feb12_144145|[ 0.80186 -1.14980 -0.80324]
21Feb12_144145|Layer 3:
21Feb12_144145|-- Config --
21Feb12_144145|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144145|-- Weights --
21Feb12_144145|[[-0.23693 -0.18694 -0.06836 -0.38083]
21Feb12_144145| [-0.18482 -0.74519  1.01192 -0.73306]
21Feb12_144145| [-1.34032 -1.90482  0.21049 -0.84424]]
21Feb12_144145|-- Bias --
21Feb12_144145|[-0.45480  0.22554  1.34863 -0.53238]
21Feb12_144145|Layer 4:
21Feb12_144145|-- Config --
21Feb12_144145|{'name': 'Hidden5', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144145|-- Weights --
21Feb12_144145|[[ 1.38774  1.08699 -0.77759  0.56311 -1.77299]
21Feb12_144145| [ 0.28391 -0.10364 -1.12276 -0.52361  0.09630]
21Feb12_144145| [-0.52512 -0.16867 -1.87508  0.57790 -1.21581]
21Feb12_144145| [ 0.13746  0.45911 -0.92657  0.25726 -0.74730]]
21Feb12_144145|-- Bias --
21Feb12_144145|[-0.14276  0.44395 -0.44961  0.47833 -0.07693]
21Feb12_144145|Layer 5:
21Feb12_144145|-- Config --
21Feb12_144145|{'name': 'Hidden6', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144145|-- Weights --
21Feb12_144145|[[-0.96618  0.96909 -0.48297 -1.11889  0.70384  0.27997]
21Feb12_144145| [-1.09513 -0.74822  0.54830  0.05093  1.12909  0.21934]
21Feb12_144145| [-0.21483 -0.43027  0.98052 -0.42408 -0.95917 -0.04963]
21Feb12_144145| [ 0.14881 -0.12743 -1.24908 -0.70705 -0.62287  0.12561]
21Feb12_144145| [-0.36569  1.22889 -0.25290  0.99234 -0.08906 -0.31559]]
21Feb12_144145|-- Bias --
21Feb12_144145|[ 0.67994  0.31382 -0.21719  0.20593  0.86896 -0.11833]
21Feb12_144145|Layer 6:
21Feb12_144145|-- Config --
21Feb12_144145|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_144145|-- Weights --
21Feb12_144145|[[ 0.53450  0.24174]
21Feb12_144145| [-0.24442 -0.59403]
21Feb12_144145| [ 2.07751  0.11893]
21Feb12_144145| [-1.08995 -1.42727]
21Feb12_144145| [-0.71218  1.91415]
21Feb12_144145| [-0.32732 -0.06770]]
21Feb12_144145|-- Bias --
21Feb12_144145|[ 1.42761 -1.28538]
21Feb12_144145|Predicting the validation and test data with the Best final individual.
21Feb12_144153| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_144153|-----------  ------------------  --------------------  ----------
21Feb12_144153|Validation         24.43                 156            0.69792
21Feb12_144153|   Test            28.32                 156            0.85035
2021-02-12 14:41:54.658629: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
21Feb12_144155|Data summary: Train
21Feb12_144155|data.shape = (2300, 57)
21Feb12_144155|labels.shape = (2300,)
21Feb12_144155|Class distribution:
21Feb12_144155|	0 - 1389 (0.60)
21Feb12_144155|	1 - 911 (0.40)
21Feb12_144155|Data summary: Validation
21Feb12_144155|data.shape = (1150, 57)
21Feb12_144155|labels.shape = (1150,)
21Feb12_144155|Class distribution:
21Feb12_144155|	0 - 667 (0.58)
21Feb12_144155|	1 - 483 (0.42)
21Feb12_144155|Data summary: Test
21Feb12_144155|data.shape = (1151, 57)
21Feb12_144155|labels.shape = (1151,)
21Feb12_144155|Class distribution:
21Feb12_144155|	0 - 732 (0.64)
21Feb12_144155|	1 - 419 (0.36)
21Feb12_144155|Selected configuration values
21Feb12_144155|-- Dataset name: spambase2
21Feb12_144155|-- Initial population size: 64
21Feb12_144155|-- Maximun number of generations: 32
21Feb12_144155|-- Neurons per hidden layer range: (2, 20)
21Feb12_144155|-- Hidden layers number range: (1, 3)
21Feb12_144155|-- Crossover probability: 0.5
21Feb12_144155|-- Bias gene mutation probability: 0.2
21Feb12_144155|-- Weights gene mutation probability: 0.75
21Feb12_144155|-- Neuron mutation probability: 0.3
21Feb12_144155|-- Layer mutation probability: 0.3
21Feb12_144155|-- Constant hidden layers: False
21Feb12_144155|-- Seed: 31415
21Feb12_144155|Entering GA
21Feb12_144155|Start the algorithm
2021-02-12 14:41:55.498639: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-12 14:41:55.499160: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-02-12 14:41:55.522904: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-12 14:41:55.523227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.71GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s
2021-02-12 14:41:55.523240: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-02-12 14:41:55.524657: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-02-12 14:41:55.524686: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-02-12 14:41:55.525182: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-02-12 14:41:55.525316: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-02-12 14:41:55.525386: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-12 14:41:55.525786: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-02-12 14:41:55.525825: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-12 14:41:55.525831: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-02-12 14:41:55.526036: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-02-12 14:41:55.526761: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-12 14:41:55.526775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-12 14:41:55.526779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      
2021-02-12 14:41:55.572474: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-02-12 14:41:55.572791: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3493635000 Hz
/home/jmerelo/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype("int32")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn('`model.predict_classes()` is deprecated and '
21Feb12_144559|-- Generation 1 --
21Feb12_144559|    -- Crossed 1 individual pairs.
21Feb12_144559|    -- Mutated 32 individuals.
21Feb12_144956|    -- Evaluated 64 individuals.
21Feb12_144956|    Summary of generation 1:
21Feb12_144956| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_144956|-----------  ------------------  --------------------  ----------
21Feb12_144956|    Max            42.26                123.00          0.51385
21Feb12_144956|    Avg            41.77                33.09           0.01298
21Feb12_144956|    Min            28.61                 3.00           0.00000
21Feb12_144956|    Std             1.66                28.86           0.06761
21Feb12_144956|   Best            28.61                50.00           0.51385
21Feb12_144956|-- Generation 2 --
21Feb12_144956|    -- Crossed 4 individual pairs.
21Feb12_144956|    -- Mutated 32 individuals.
21Feb12_145349|    -- Evaluated 64 individuals.
21Feb12_145349|    Summary of generation 2:
21Feb12_145349| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_145349|-----------  ------------------  --------------------  ----------
21Feb12_145349|    Max            42.61                87.00           0.72775
21Feb12_145349|    Avg            41.60                18.42           0.02146
21Feb12_145349|    Min            27.74                 3.00           0.00000
21Feb12_145349|    Std             1.99                17.66           0.09730
21Feb12_145349|   Best            27.74                20.00           0.72775
21Feb12_145349|-- Generation 3 --
21Feb12_145349|    -- Crossed 1 individual pairs.
21Feb12_145349|    -- Mutated 32 individuals.
21Feb12_145741|    -- Evaluated 64 individuals.
21Feb12_145741|    Summary of generation 3:
21Feb12_145741| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_145741|-----------  ------------------  --------------------  ----------
21Feb12_145741|    Max            42.43                64.00           0.43199
21Feb12_145741|    Avg            41.80                15.84           0.00873
21Feb12_145741|    Min            30.52                 2.00           0.00000
21Feb12_145741|    Std             1.43                13.41           0.05347
21Feb12_145741|   Best            30.52                14.00           0.43199
21Feb12_145741|-- Generation 4 --
21Feb12_145741|    -- Crossed 4 individual pairs.
21Feb12_145741|    -- Mutated 32 individuals.
21Feb12_150132|    -- Evaluated 64 individuals.
21Feb12_150132|    Summary of generation 4:
21Feb12_150132| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_150132|-----------  ------------------  --------------------  ----------
21Feb12_150132|    Max            42.17                50.00           0.79194
21Feb12_150132|    Avg            41.50                12.23           0.02220
21Feb12_150132|    Min            25.91                 2.00           0.00000
21Feb12_150132|    Std             2.50                11.10           0.11193
21Feb12_150132|   Best            25.91                14.00           0.79194
21Feb12_150132|-- Generation 5 --
21Feb12_150132|    -- Crossed 2 individual pairs.
21Feb12_150132|    -- Mutated 32 individuals.
21Feb12_150523|    -- Evaluated 64 individuals.
21Feb12_150523|    Summary of generation 5:
21Feb12_150523| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_150523|-----------  ------------------  --------------------  ----------
21Feb12_150523|    Max            42.35                64.00           0.76315
21Feb12_150523|    Avg            41.70                12.83           0.01563
21Feb12_150523|    Min            26.78                 2.00           0.00000
21Feb12_150523|    Std             1.89                11.10           0.09439
21Feb12_150523|   Best            26.78                33.00           0.76315
21Feb12_150523|-- Generation 6 --
21Feb12_150523|    -- Crossed 4 individual pairs.
21Feb12_150523|    -- Mutated 32 individuals.
21Feb12_150916|    -- Evaluated 64 individuals.
21Feb12_150916|    Summary of generation 6:
21Feb12_150916| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_150916|-----------  ------------------  --------------------  ----------
21Feb12_150916|    Max            42.43                64.00           0.76816
21Feb12_150916|    Avg            41.68                15.77           0.01585
21Feb12_150916|    Min            25.74                 2.00           0.00000
21Feb12_150916|    Std             2.03                13.48           0.09532
21Feb12_150916|   Best            25.74                16.00           0.76816
21Feb12_150916|-- Generation 7 --
21Feb12_150916|    -- Crossed 4 individual pairs.
21Feb12_150916|    -- Mutated 32 individuals.
21Feb12_151306|    -- Evaluated 64 individuals.
21Feb12_151306|    Summary of generation 7:
21Feb12_151306| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_151306|-----------  ------------------  --------------------  ----------
21Feb12_151306|    Max            47.91                42.00           0.80738
21Feb12_151306|    Avg            41.83                13.17           0.03002
21Feb12_151306|    Min            29.04                 2.00           0.00000
21Feb12_151306|    Std             1.79                11.02           0.13807
21Feb12_151306|   Best            29.04                36.00           0.76624
21Feb12_151306|-- Generation 8 --
21Feb12_151306|    -- Crossed 1 individual pairs.
21Feb12_151306|    -- Mutated 32 individuals.
21Feb12_151659|    -- Evaluated 64 individuals.
21Feb12_151659|    Summary of generation 8:
21Feb12_151659| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_151659|-----------  ------------------  --------------------  ----------
21Feb12_151659|    Max            42.17                50.00           0.81892
21Feb12_151659|    Avg            41.61                14.88           0.02827
21Feb12_151659|    Min            30.70                 2.00           0.00000
21Feb12_151659|    Std             1.78                12.05           0.13815
21Feb12_151659|   Best            30.70                 8.00           0.77395
21Feb12_151659|-- Generation 9 --
21Feb12_151659|    -- Crossed 2 individual pairs.
21Feb12_151659|    -- Mutated 32 individuals.
21Feb12_152052|    -- Evaluated 64 individuals.
21Feb12_152052|    Summary of generation 9:
21Feb12_152052| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_152052|-----------  ------------------  --------------------  ----------
21Feb12_152052|    Max            42.17                50.00           0.55964
21Feb12_152052|    Avg            41.38                16.36           0.02674
21Feb12_152052|    Min            29.57                 2.00           0.00000
21Feb12_152052|    Std             2.56                12.69           0.10724
21Feb12_152052|   Best            29.57                19.00           0.51311
21Feb12_152052|-- Generation 10 --
21Feb12_152052|    -- Crossed 2 individual pairs.
21Feb12_152052|    -- Mutated 32 individuals.
21Feb12_152446|    -- Evaluated 64 individuals.
21Feb12_152446|    Summary of generation 10:
21Feb12_152446| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_152446|-----------  ------------------  --------------------  ----------
21Feb12_152446|    Max            42.26                44.00           0.69563
21Feb12_152446|    Avg            41.65                17.72           0.01691
21Feb12_152446|    Min            27.83                 2.00           0.00000
21Feb12_152446|    Std             1.76                11.86           0.08587
21Feb12_152446|   Best            27.83                 8.00           0.69563
21Feb12_152446|-- Generation 11 --
21Feb12_152446|    -- Crossed 1 individual pairs.
21Feb12_152446|    -- Mutated 32 individuals.
21Feb12_152840|    -- Evaluated 64 individuals.
21Feb12_152840|    Summary of generation 11:
21Feb12_152840| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_152840|-----------  ------------------  --------------------  ----------
21Feb12_152840|    Max            42.35                52.00           0.66119
21Feb12_152840|    Avg            41.69                21.98           0.01734
21Feb12_152840|    Min            29.74                 2.00           0.00000
21Feb12_152840|    Std             1.53                12.03           0.08147
21Feb12_152840|   Best            29.74                18.00           0.66119
21Feb12_152840|-- Generation 12 --
21Feb12_152840|    -- Crossed 3 individual pairs.
21Feb12_152840|    -- Mutated 32 individuals.
21Feb12_153234|    -- Evaluated 64 individuals.
21Feb12_153234|    Summary of generation 12:
21Feb12_153234| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_153234|-----------  ------------------  --------------------  ----------
21Feb12_153234|    Max            46.61                48.00           0.81035
21Feb12_153234|    Avg            41.93                22.02           0.02043
21Feb12_153234|    Min            41.30                 4.00           0.00000
21Feb12_153234|    Std             0.64                11.20           0.09982
21Feb12_153234|   Best            41.30                17.00           0.02317
21Feb12_153234|-- Generation 13 --
21Feb12_153234|    -- Crossed 0 individual pairs.
21Feb12_153234|    -- Mutated 32 individuals.
21Feb12_153626|    -- Evaluated 64 individuals.
21Feb12_153626|    Summary of generation 13:
21Feb12_153626| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_153626|-----------  ------------------  --------------------  ----------
21Feb12_153626|    Max            42.26                48.00           0.59247
21Feb12_153626|    Avg            41.62                18.83           0.01796
21Feb12_153626|    Min            30.78                 3.00           0.00000
21Feb12_153626|    Std             1.39                 8.89           0.07284
21Feb12_153626|   Best            30.78                14.00           0.59247
21Feb12_153626|-- Generation 14 --
21Feb12_153626|    -- Crossed 4 individual pairs.
21Feb12_153626|    -- Mutated 32 individuals.
21Feb12_154019|    -- Evaluated 64 individuals.
21Feb12_154019|    Summary of generation 14:
21Feb12_154019| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_154019|-----------  ------------------  --------------------  ----------
21Feb12_154019|    Max            43.39                50.00           0.02569
21Feb12_154019|    Avg            41.91                21.94           0.00673
21Feb12_154019|    Min            41.22                 4.00           0.00000
21Feb12_154019|    Std             0.28                 9.79           0.00657
21Feb12_154019|   Best            41.22                15.00           0.02318
21Feb12_154019|-- Generation 15 --
21Feb12_154019|    -- Crossed 5 individual pairs.
21Feb12_154019|    -- Mutated 32 individuals.
21Feb12_154412|    -- Evaluated 64 individuals.
21Feb12_154412|    Summary of generation 15:
21Feb12_154412| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_154412|-----------  ------------------  --------------------  ----------
21Feb12_154412|    Max            42.17                54.00           0.03332
21Feb12_154412|    Avg            41.82                21.48           0.00921
21Feb12_154412|    Min            41.22                15.00           0.00000
21Feb12_154412|    Std             0.23                 8.95           0.00897
21Feb12_154412|   Best            41.22                17.00           0.03082
21Feb12_154412|-- Generation 16 --
21Feb12_154412|    -- Crossed 3 individual pairs.
21Feb12_154412|    -- Mutated 32 individuals.
21Feb12_154806|    -- Evaluated 64 individuals.
21Feb12_154806|    Summary of generation 16:
21Feb12_154806| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_154806|-----------  ------------------  --------------------  ----------
21Feb12_154806|    Max            42.35                48.00           0.02829
21Feb12_154806|    Avg            41.83                23.91           0.00826
21Feb12_154806|    Min            41.13                15.00           0.00000
21Feb12_154806|    Std             0.24                10.91           0.00749
21Feb12_154806|   Best            41.13                19.00           0.02829
21Feb12_154806|-- Generation 17 --
21Feb12_154806|    -- Crossed 6 individual pairs.
21Feb12_154806|    -- Mutated 32 individuals.
21Feb12_155159|    -- Evaluated 64 individuals.
21Feb12_155159|    Summary of generation 17:
21Feb12_155159| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_155159|-----------  ------------------  --------------------  ----------
21Feb12_155159|    Max            42.35                48.00           0.04080
21Feb12_155159|    Avg            41.82                20.41           0.01022
21Feb12_155159|    Min            41.13                14.00           0.00000
21Feb12_155159|    Std             0.25                 8.26           0.00842
21Feb12_155159|   Best            41.13                15.00           0.02575
21Feb12_155159|-- Generation 18 --
21Feb12_155159|    -- Crossed 2 individual pairs.
21Feb12_155159|    -- Mutated 32 individuals.
21Feb12_155553|    -- Evaluated 64 individuals.
21Feb12_155553|    Summary of generation 18:
21Feb12_155553| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_155553|-----------  ------------------  --------------------  ----------
21Feb12_155553|    Max            42.52                54.00           0.02822
21Feb12_155553|    Avg            41.84                21.91           0.00793
21Feb12_155553|    Min            41.30                14.00           0.00000
21Feb12_155553|    Std             0.24                 9.88           0.00809
21Feb12_155553|   Best            41.30                14.00           0.02317
21Feb12_155553|-- Generation 19 --
21Feb12_155553|    -- Crossed 3 individual pairs.
21Feb12_155553|    -- Mutated 32 individuals.
21Feb12_155946|    -- Evaluated 64 individuals.
21Feb12_155946|    Summary of generation 19:
21Feb12_155946| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_155946|-----------  ------------------  --------------------  ----------
21Feb12_155946|    Max            42.35                48.00           0.03080
21Feb12_155946|    Avg            41.82                21.88           0.00910
21Feb12_155946|    Min            41.22                14.00           0.00000
21Feb12_155946|    Std             0.24                10.54           0.00825
21Feb12_155946|   Best            41.22                18.00           0.02318
21Feb12_155946|-- Generation 20 --
21Feb12_155946|    -- Crossed 4 individual pairs.
21Feb12_155946|    -- Mutated 32 individuals.
21Feb12_160340|    -- Evaluated 64 individuals.
21Feb12_160340|    Summary of generation 20:
21Feb12_160340| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_160340|-----------  ------------------  --------------------  ----------
21Feb12_160340|    Max            42.70                48.00           0.02318
21Feb12_160340|    Avg            41.82                20.77           0.00898
21Feb12_160340|    Min            41.22                14.00           0.00000
21Feb12_160340|    Std             0.25                10.29           0.00693
21Feb12_160340|   Best            41.22                15.00           0.02318
21Feb12_160340|-- Generation 21 --
21Feb12_160340|    -- Crossed 0 individual pairs.
21Feb12_160340|    -- Mutated 32 individuals.
21Feb12_160732|    -- Evaluated 64 individuals.
21Feb12_160732|    Summary of generation 21:
21Feb12_160732| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_160732|-----------  ------------------  --------------------  ----------
21Feb12_160732|    Max            42.35                46.00           0.02823
21Feb12_160732|    Avg            41.78                18.78           0.00995
21Feb12_160732|    Min            41.22                13.00           0.00000
21Feb12_160732|    Std             0.27                 7.54           0.00827
21Feb12_160732|   Best            41.22                15.00           0.02318
21Feb12_160732|-- Generation 22 --
21Feb12_160732|    -- Crossed 2 individual pairs.
21Feb12_160732|    -- Mutated 32 individuals.
21Feb12_161125|    -- Evaluated 64 individuals.
21Feb12_161125|    Summary of generation 22:
21Feb12_161125| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_161125|-----------  ------------------  --------------------  ----------
21Feb12_161125|    Max            42.78                44.00           0.02568
21Feb12_161125|    Avg            41.84                18.72           0.00898
21Feb12_161125|    Min            41.22                14.00           0.00000
21Feb12_161125|    Std             0.28                 7.89           0.00748
21Feb12_161125|   Best            41.22                15.00           0.02318
21Feb12_161125|-- Generation 23 --
21Feb12_161125|    -- Crossed 4 individual pairs.
21Feb12_161125|    -- Mutated 32 individuals.
21Feb12_161517|    -- Evaluated 64 individuals.
21Feb12_161517|    Summary of generation 23:
21Feb12_161517| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_161517|-----------  ------------------  --------------------  ----------
21Feb12_161517|    Max            42.17                46.00           0.02572
21Feb12_161517|    Avg            41.80                19.06           0.00866
21Feb12_161517|    Min            41.22                14.00           0.00000
21Feb12_161517|    Std             0.24                 8.14           0.00755
21Feb12_161517|   Best            41.22                14.00           0.02318
21Feb12_161517|-- Generation 24 --
21Feb12_161517|    -- Crossed 2 individual pairs.
21Feb12_161517|    -- Mutated 32 individuals.
21Feb12_161909|    -- Evaluated 64 individuals.
21Feb12_161909|    Summary of generation 24:
21Feb12_161909| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_161909|-----------  ------------------  --------------------  ----------
21Feb12_161909|    Max            42.52                48.00           0.02828
21Feb12_161909|    Avg            41.82                19.48           0.00850
21Feb12_161909|    Min            41.22                13.00           0.00000
21Feb12_161909|    Std             0.23                 9.26           0.00695
21Feb12_161909|   Best            41.22                15.00           0.02828
21Feb12_161909|-- Generation 25 --
21Feb12_161909|    -- Crossed 4 individual pairs.
21Feb12_161909|    -- Mutated 32 individuals.
21Feb12_162302|    -- Evaluated 64 individuals.
21Feb12_162302|    Summary of generation 25:
21Feb12_162302| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_162302|-----------  ------------------  --------------------  ----------
21Feb12_162302|    Max            42.26                42.00           0.02318
21Feb12_162302|    Avg            41.76                17.30           0.00987
21Feb12_162302|    Min            41.22                13.00           0.00000
21Feb12_162302|    Std             0.25                 6.62           0.00673
21Feb12_162302|   Best            41.22                15.00           0.02318
21Feb12_162302|-- Generation 26 --
21Feb12_162302|    -- Crossed 3 individual pairs.
21Feb12_162302|    -- Mutated 32 individuals.
21Feb12_162656|    -- Evaluated 64 individuals.
21Feb12_162656|    Summary of generation 26:
21Feb12_162656| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_162656|-----------  ------------------  --------------------  ----------
21Feb12_162656|    Max            42.26                42.00           0.02575
21Feb12_162656|    Avg            41.77                19.88           0.00987
21Feb12_162656|    Min            41.13                13.00           0.00000
21Feb12_162656|    Std             0.27                 9.00           0.00754
21Feb12_162656|   Best            41.13                18.00           0.02575
21Feb12_162656|-- Generation 27 --
21Feb12_162656|    -- Crossed 3 individual pairs.
21Feb12_162656|    -- Mutated 32 individuals.
21Feb12_163050|    -- Evaluated 64 individuals.
21Feb12_163050|    Summary of generation 27:
21Feb12_163050| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_163050|-----------  ------------------  --------------------  ----------
21Feb12_163050|    Max            42.09                44.00           0.02318
21Feb12_163050|    Avg            41.73                20.30           0.01015
21Feb12_163050|    Min            41.22                14.00           0.00000
21Feb12_163050|    Std             0.26                 9.68           0.00793
21Feb12_163050|   Best            41.22                15.00           0.02318
21Feb12_163050|-- Generation 28 --
21Feb12_163050|    -- Crossed 9 individual pairs.
21Feb12_163050|    -- Mutated 32 individuals.
21Feb12_163443|    -- Evaluated 64 individuals.
21Feb12_163443|    Summary of generation 28:
21Feb12_163443| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_163443|-----------  ------------------  --------------------  ----------
21Feb12_163443|    Max            54.78                40.00           0.78861
21Feb12_163443|    Avg            41.98                18.56           0.02155
21Feb12_163443|    Min            41.22                13.00           0.00000
21Feb12_163443|    Std             1.63                 8.19           0.09695
21Feb12_163443|   Best            41.22                15.00           0.02318
21Feb12_163443|-- Generation 29 --
21Feb12_163443|    -- Crossed 4 individual pairs.
21Feb12_163443|    -- Mutated 32 individuals.
21Feb12_163835|    -- Evaluated 64 individuals.
21Feb12_163835|    Summary of generation 29:
21Feb12_163835| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_163835|-----------  ------------------  --------------------  ----------
21Feb12_163835|    Max            42.09                46.00           0.02573
21Feb12_163835|    Avg            41.69                18.25           0.01212
21Feb12_163835|    Min            41.22                12.00           0.00000
21Feb12_163835|    Std             0.27                 8.27           0.00862
21Feb12_163835|   Best            41.22                14.00           0.02573
21Feb12_163835|-- Generation 30 --
21Feb12_163835|    -- Crossed 3 individual pairs.
21Feb12_163835|    -- Mutated 32 individuals.
21Feb12_164227|    -- Evaluated 64 individuals.
21Feb12_164227|    Summary of generation 30:
21Feb12_164227| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_164227|-----------  ------------------  --------------------  ----------
21Feb12_164227|    Max            42.17                40.00           0.02317
21Feb12_164227|    Avg            41.78                18.81           0.00927
21Feb12_164227|    Min            41.30                12.00           0.00000
21Feb12_164227|    Std             0.24                 8.21           0.00747
21Feb12_164227|   Best            41.30                14.00           0.02317
21Feb12_164227|-- Generation 31 --
21Feb12_164227|    -- Crossed 1 individual pairs.
21Feb12_164227|    -- Mutated 32 individuals.
21Feb12_164619|    -- Evaluated 64 individuals.
21Feb12_164619|    Summary of generation 31:
21Feb12_164619| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_164619|-----------  ------------------  --------------------  ----------
21Feb12_164619|    Max            42.43                40.00           0.02318
21Feb12_164619|    Avg            41.74                18.41           0.00967
21Feb12_164619|    Min            41.22                13.00           0.00000
21Feb12_164619|    Std             0.28                 7.94           0.00807
21Feb12_164619|   Best            41.22                16.00           0.02318
21Feb12_164619|-- Generation 32 --
21Feb12_164619|    -- Crossed 5 individual pairs.
21Feb12_164619|    -- Mutated 32 individuals.
21Feb12_165011|    -- Evaluated 64 individuals.
21Feb12_165011|    Summary of generation 32:
21Feb12_165011| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_165011|-----------  ------------------  --------------------  ----------
21Feb12_165011|    Max            42.52                38.00           0.02572
21Feb12_165011|    Avg            41.76                17.30           0.01031
21Feb12_165011|    Min            41.30                13.00           0.00000
21Feb12_165011|    Std             0.29                 7.00           0.00860
21Feb12_165011|   Best            41.30                15.00           0.02572
21Feb12_165011|Best initial individual weights
21Feb12_165011|Individual:
21Feb12_165011|-- Constant hidden layers --
21Feb12_165011|False
21Feb12_165011|Layer 0:
21Feb12_165011|-- Config --
21Feb12_165011|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 10, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_165011|-- Weights --
21Feb12_165011|[[ 0.66647  0.02142 -0.84385 -0.84703  0.10970  0.47046  0.54749 -0.06375
21Feb12_165011|  -0.82625 -0.73536]
21Feb12_165011| [ 0.19547  0.93181  0.02920 -0.93083 -0.67027 -0.01003 -0.59957 -0.08630
21Feb12_165011|  -0.26622  0.43995]
21Feb12_165011| [-0.91775  0.18325  0.33384 -0.35255 -0.00946 -0.79938  0.37764 -0.12132
21Feb12_165011|   0.00321  0.56101]
21Feb12_165011| [ 0.95786 -0.92620 -0.06458  0.75542  0.50879 -0.85339  0.25497  0.29354
21Feb12_165011|  -0.11051 -0.09120]
21Feb12_165011| [-0.84576 -0.49279  0.30186 -0.47307  0.08938 -0.29780 -0.19361 -0.61463
21Feb12_165011|  -0.45975 -0.20043]
21Feb12_165011| [-0.37422  0.08348 -0.44596  0.91542 -0.13046  0.58543  0.09429  0.07371
21Feb12_165011|   0.97275  0.87626]
21Feb12_165011| [-0.80835 -0.60625  0.11952  0.79077 -0.15738  0.40057  0.79644 -0.73711
21Feb12_165011|  -0.12740 -0.38600]
21Feb12_165011| [-0.97639 -0.61633 -0.10484 -0.93055 -0.34165 -0.16126 -0.04257 -0.42578
21Feb12_165011|  -0.67986  0.84859]
21Feb12_165011| [ 0.71717 -0.75767  0.84995 -0.58620 -0.04667  0.86954  0.60594 -0.58579
21Feb12_165011|   0.53431  0.28181]
21Feb12_165011| [-0.26952 -0.68674  0.49036 -0.21551  0.39158  0.37250  0.16152 -0.91202
21Feb12_165011|   0.24849 -0.36130]
21Feb12_165011| [ 0.91720  0.92990 -0.75998  0.72682 -0.62054  0.30298  0.60105 -0.66843
21Feb12_165011|  -0.88323 -0.44212]
21Feb12_165011| [ 0.77923 -0.24669 -0.08619 -0.46393 -0.22745 -0.14447 -0.36035  0.64308
21Feb12_165011|   0.06765 -0.91598]
21Feb12_165011| [-0.16567 -0.35744  0.80297 -0.48077 -0.50812  0.69829 -0.06925  0.40060
21Feb12_165011|   0.33729 -0.31944]
21Feb12_165011| [-0.55780 -0.16889 -0.47538 -0.69457 -0.49224  0.24134  0.47374  0.30493
21Feb12_165011|  -0.27066  0.64589]
21Feb12_165011| [-0.14048  0.79683 -0.78410  0.41868  0.06357  0.87763  0.07928  0.39293
21Feb12_165011|  -0.90446 -0.44431]
21Feb12_165011| [-0.46684  0.99641 -0.09247  0.90746 -0.97814  0.82526 -0.92914 -0.41245
21Feb12_165011|   0.05528 -0.27921]
21Feb12_165011| [ 0.42903 -0.50996  0.46436  0.50584 -0.48798 -0.90329  0.55029 -0.55034
21Feb12_165011|   0.17022 -0.48617]
21Feb12_165011| [ 0.97182  0.46311  0.86652 -0.36705 -0.60447 -0.46466 -0.48757  0.48022
21Feb12_165011|   0.90806 -0.11829]
21Feb12_165011| [ 0.15779 -0.56748  0.24584  0.00805 -0.16111  0.03003 -0.56439  0.15011
21Feb12_165011|   0.75082  0.30266]
21Feb12_165011| [ 0.09708  0.29615 -0.86451 -0.24118 -0.89659 -0.76265  0.39938 -0.48087
21Feb12_165011|  -0.92500  0.15597]
21Feb12_165011| [ 0.53206  0.10004 -0.94896 -0.99133  0.43705 -0.13793  0.16334  0.79462
21Feb12_165011|   0.33977 -0.36052]
21Feb12_165011| [-0.45525 -0.70521  0.70165  0.88469  0.22148 -0.52491 -0.15339 -0.83649
21Feb12_165011|  -0.75994  0.00536]
21Feb12_165011| [ 0.92662 -0.64054  0.40569 -0.51946 -0.39784  0.70701 -0.97712  0.42155
21Feb12_165011|   0.40859  0.27092]
21Feb12_165011| [ 0.34186  0.32927 -0.49974  0.50417  0.69820 -0.40136 -0.30591  0.22597
21Feb12_165011|   0.86256 -0.24976]
21Feb12_165011| [ 0.71345 -0.64275  0.51054 -0.47925  0.71698  0.34387  0.14394 -0.56967
21Feb12_165011|  -0.77596  0.99421]
21Feb12_165011| [-0.04421  0.17996 -0.74492  0.74250  0.30735 -0.19794  0.86244 -0.43620
21Feb12_165011|   0.73598 -0.73770]
21Feb12_165011| [-0.63512  0.68833 -0.41430  0.71971 -0.26561  0.72136 -0.87425  0.92870
21Feb12_165011|   0.30657 -0.95296]
21Feb12_165011| [-0.12425  0.55884 -0.84870  0.16483  0.78384 -0.32080  0.20151  0.28749
21Feb12_165011|  -0.32547 -0.04779]
21Feb12_165011| [ 0.46094  0.59604  0.97506 -0.67373 -0.35774  0.14162 -0.95359  0.99371
21Feb12_165011|  -0.52479  0.51429]
21Feb12_165011| [-0.16029  0.54548  0.88359  0.16461  0.69812  0.41192  0.04135 -0.96647
21Feb12_165011|  -0.01990  0.89125]
21Feb12_165011| [ 0.65181 -0.09006  0.05152  0.54478 -0.03151 -0.41389  0.70744 -0.42901
21Feb12_165011|   0.91851 -0.86395]
21Feb12_165011| [-0.41906 -0.42648  0.32104  0.04279  0.54728 -0.72161 -0.72705  0.57628
21Feb12_165011|  -0.94585 -0.26312]
21Feb12_165011| [ 0.34809  0.72501 -0.07299  0.75575 -0.47970 -0.90437  0.23058 -0.25174
21Feb12_165011|   0.00370 -0.77075]
21Feb12_165011| [ 0.65391 -0.52919 -0.24682 -0.38985 -0.20329 -0.90630  0.56458 -0.35651
21Feb12_165011|   0.76773 -0.09309]
21Feb12_165011| [-0.21846 -0.13982  0.89691  0.83484 -0.57978  0.80949  0.95859 -0.45877
21Feb12_165011|   0.15435  0.90391]
21Feb12_165011| [-0.90779  0.90431  0.64253  0.90921  0.86889  0.62600  0.11771  0.20348
21Feb12_165011|  -0.04171  0.60311]
21Feb12_165011| [-0.68090 -0.21867  0.48169 -0.46248  0.13623  0.28640 -0.59450  0.42491
21Feb12_165011|   0.81438 -0.68730]
21Feb12_165011| [ 0.52596  0.17121 -0.70047  0.13703  0.00308 -0.42753 -0.60221  0.84393
21Feb12_165011|  -0.56795  0.87546]
21Feb12_165011| [ 0.56634 -0.19813 -0.08565  0.31141  0.85166  0.73311  0.15341  0.94347
21Feb12_165011|   0.36316  0.31268]
21Feb12_165011| [ 0.27873  0.17469  0.48142  0.45959  0.33427  0.97525 -0.83454  0.67069
21Feb12_165011|   0.95624  0.83303]
21Feb12_165011| [-0.63097 -0.90686  0.51713 -0.88020  0.21054 -0.95289 -0.30139  0.32388
21Feb12_165011|  -0.47575  0.97368]
21Feb12_165011| [-0.48967  0.73175 -0.61005  0.70686 -0.07136 -0.80564  0.75565  0.40105
21Feb12_165011|   0.19633  0.04665]
21Feb12_165011| [ 0.04521  0.03271  0.58169 -0.18601 -0.23567 -0.06072  0.81628  0.07653
21Feb12_165011|   0.84919  0.20131]
21Feb12_165011| [-0.46092 -0.33739  0.19616 -0.63836 -0.38679  0.20543  0.31448  0.87379
21Feb12_165011|  -0.95412 -0.02667]
21Feb12_165011| [ 0.65901 -0.66184  0.53793  0.07134 -0.09234 -0.31336 -0.35733  0.73626
21Feb12_165011|   0.97033  0.93229]
21Feb12_165011| [ 0.71857  0.38884  0.55595 -0.21988  0.05904  0.12778  0.79028 -0.66774
21Feb12_165011|   0.53933  0.03376]
21Feb12_165011| [-0.21152  0.93407  0.98556  0.81964  0.71960  0.95032 -0.69688  0.79286
21Feb12_165011|  -0.99521 -0.99683]
21Feb12_165011| [ 0.96960  0.32712  0.88530 -0.37650  0.48826  0.80815 -0.88029  0.28570
21Feb12_165011|  -0.27308  0.47931]
21Feb12_165011| [-0.33682 -0.56152 -0.91974 -0.56808  0.64164 -0.42615  0.50801 -0.50218
21Feb12_165011|  -0.79043  0.50648]
21Feb12_165011| [-0.76170 -0.11038  0.52954  0.36762  0.40345  0.75203  0.05521 -0.50957
21Feb12_165011|  -0.18692 -0.31639]
21Feb12_165011| [ 0.86957  0.51190  0.30396  0.68131 -0.58434  0.47203  0.33759 -0.30342
21Feb12_165011|   0.79632 -0.53897]
21Feb12_165011| [-0.69499  0.01500  0.91349  0.16063 -0.01097  0.46602  0.70153  0.42842
21Feb12_165011|  -0.34091 -0.54618]
21Feb12_165011| [ 0.30692 -0.94409 -0.19468  0.81675 -0.98158 -0.58214 -0.98632  0.47607
21Feb12_165011|   0.14024  0.03175]
21Feb12_165011| [ 0.52664 -0.19594 -0.40466  0.79251 -0.37232 -0.47426  0.81031  0.28276
21Feb12_165011|  -0.35580 -0.35212]
21Feb12_165011| [ 0.97612 -0.78367  0.93323  0.84804  0.21607 -0.19064 -0.54599 -0.51258
21Feb12_165011|   0.93530 -0.89108]
21Feb12_165011| [ 0.35552  0.35734 -0.88698 -0.05943  0.04736  0.39575 -0.67236 -0.92867
21Feb12_165011|   0.17839  0.64416]
21Feb12_165011| [-0.54587 -0.42681  0.53761  0.12972  0.69473 -0.42679 -0.34045  0.42295
21Feb12_165011|  -0.43438  0.47465]]
21Feb12_165011|-- Bias --
21Feb12_165011|[ 0.06657  0.82493  0.66750 -0.54352  0.04675  0.32456  0.17751 -0.37449
21Feb12_165011|  0.01920  0.30685]
21Feb12_165011|Layer 1:
21Feb12_165011|-- Config --
21Feb12_165011|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 10], 'dtype': 'float32', 'units': 13, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_165011|-- Weights --
21Feb12_165011|[[-0.55579  0.48236  0.13101 -0.58886  0.35644  0.13507  0.47338 -0.05173
21Feb12_165011|   0.10118  0.83719 -0.11309  0.12287 -0.16824]
21Feb12_165011| [-0.30631  0.87728 -0.09973  0.13424  0.77393  0.29855  0.89472  0.31443
21Feb12_165011|   0.46786  0.71644 -0.42228 -0.46391  0.87550]
21Feb12_165011| [ 0.79789 -0.74265  0.48429 -0.73094  0.92952  0.41460 -0.40947  0.89764
21Feb12_165011|   0.16504  0.94929  0.90305 -0.04601  0.88684]
21Feb12_165011| [ 0.71707 -0.13537 -0.64980 -0.79781 -0.14364  0.84492 -0.64219 -0.23368
21Feb12_165011|  -0.58005  0.10443 -0.81587  0.84968 -0.84460]
21Feb12_165011| [-0.87952  0.79869  0.99941 -0.44260 -0.20721  0.27584 -0.06725  0.57355
21Feb12_165011|   0.43331 -0.83402 -0.02971 -0.05526  0.01931]
21Feb12_165011| [-0.53836  0.59482 -0.73384  0.88578  0.84579  0.65189  0.88273  0.80591
21Feb12_165011|   0.43338 -0.32958  0.93748  0.24770  0.72812]
21Feb12_165011| [ 0.29581 -0.60279  0.63894  0.35096 -0.37078 -0.96416  0.24207  0.87081
21Feb12_165011|   0.46742 -0.68542 -0.68426 -0.57002  0.45502]
21Feb12_165011| [-0.31696 -0.18045 -0.31169  0.41994 -0.95692  0.91904 -0.93749 -0.24986
21Feb12_165011|  -0.06083  0.30145 -0.42730 -0.33354 -0.91126]
21Feb12_165011| [-0.75428  0.01778 -0.01513 -0.04954  0.06473  0.09639  0.42520 -0.63236
21Feb12_165011|  -0.14124 -0.25333 -0.93919  0.22265 -0.36096]
21Feb12_165011| [-0.19415 -0.60267 -0.55209  0.49432  0.49812  0.55505  0.22043  0.27430
21Feb12_165011|   0.06421  0.28408 -0.21710 -0.60417  0.55838]]
21Feb12_165011|-- Bias --
21Feb12_165011|[ 0.93890 -0.49377 -0.94368  0.53136  0.52792 -0.07235  0.49121  0.96158
21Feb12_165011|  0.60908  0.49093 -0.10645  0.70663  0.92398]
21Feb12_165011|Layer 2:
21Feb12_165011|-- Config --
21Feb12_165011|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 13], 'dtype': 'float32', 'units': 13, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_165011|-- Weights --
21Feb12_165011|[[-9.62782e-01 -4.28171e-04 -7.86487e-01 -3.40810e-01 -6.07153e-01
21Feb12_165011|  -9.22632e-01 -1.12072e-01 -5.69210e-01 -6.42428e-01  9.33352e-01
21Feb12_165011|   2.64563e-01 -8.73753e-01 -5.29076e-01]
21Feb12_165011| [-4.06816e-02  2.83796e-01 -9.54118e-01  7.98096e-01 -9.07534e-01
21Feb12_165011|   3.16628e-02  3.25231e-01 -1.82745e-01 -1.66803e-01 -1.05200e-01
21Feb12_165011|   3.71002e-01 -8.01364e-01  1.69211e-01]
21Feb12_165011| [ 5.28537e-01  7.87447e-01 -8.15523e-02  9.32615e-01 -5.87328e-01
21Feb12_165011|   5.54006e-01  9.95338e-01  4.99963e-02 -9.47909e-01  1.77103e-01
21Feb12_165011|   4.81787e-01 -7.20366e-01 -8.71499e-02]
21Feb12_165011| [-3.41464e-01 -5.13775e-01 -9.58942e-01 -3.12698e-01 -2.48140e-01
21Feb12_165011|  -4.91777e-01 -7.99721e-01  7.44343e-01  3.72897e-01  8.14923e-01
21Feb12_165011|  -5.67620e-01  4.77155e-01 -3.62034e-01]
21Feb12_165011| [-3.06999e-01 -8.34290e-01  4.21797e-01 -7.49380e-01 -7.33278e-01
21Feb12_165011|   6.33720e-01  9.34691e-01  1.02629e-03  7.50914e-01  9.20277e-01
21Feb12_165011|  -8.96753e-01 -1.72377e-01  1.38331e-01]
21Feb12_165011| [ 9.10254e-01 -2.20874e-01  3.18942e-01  9.18945e-01  3.91403e-02
21Feb12_165011|  -3.48962e-01  6.17648e-01 -2.11893e-01  6.48227e-01  8.02889e-01
21Feb12_165011|  -3.18258e-01 -7.93726e-01  9.32795e-01]
21Feb12_165011| [-3.23747e-02  9.25937e-01  9.98565e-02  1.21683e-01  4.04212e-01
21Feb12_165011|   2.66679e-01  1.59881e-01  9.46816e-01 -6.63580e-01 -6.18931e-01
21Feb12_165011|   4.58254e-03 -4.49294e-01  8.46336e-02]
21Feb12_165011| [ 3.63358e-02  9.23936e-01 -8.51338e-01 -3.33519e-01  5.20690e-01
21Feb12_165011|   8.21382e-01  4.54260e-01 -3.63021e-01  3.78782e-01 -3.99692e-01
21Feb12_165011|   5.48701e-01  3.93344e-01  8.72601e-01]
21Feb12_165011| [ 2.50583e-01  8.63997e-01  4.46105e-01 -3.80671e-01 -3.40642e-01
21Feb12_165011|   2.91525e-01 -4.20983e-01 -6.34830e-01  2.88427e-01 -3.32622e-01
21Feb12_165011|   7.72444e-01 -2.38269e-01  4.52549e-01]
21Feb12_165011| [-5.63272e-01  3.04826e-01 -2.39729e-01 -9.31123e-01 -6.87987e-01
21Feb12_165011|   5.55435e-01 -3.77278e-01 -3.85725e-01 -6.27124e-01 -2.82796e-02
21Feb12_165011|  -5.55430e-01 -1.09994e-01  7.99970e-01]
21Feb12_165011| [ 7.80859e-02  8.21368e-01  1.21854e-01  8.16475e-01 -1.27449e-01
21Feb12_165011|  -1.79959e-01  4.75948e-02 -6.99426e-01  7.14669e-01  5.73969e-01
21Feb12_165011|   4.37627e-01 -9.14016e-01 -8.68136e-01]
21Feb12_165011| [-3.27575e-01 -7.92627e-01  4.83385e-01  2.52347e-01  5.53948e-01
21Feb12_165011|   6.70885e-01 -9.54491e-03 -1.32047e-01  3.12701e-01  9.08946e-01
21Feb12_165011|  -9.39021e-03 -2.46808e-01  6.97142e-01]
21Feb12_165011| [-5.48774e-01 -1.65990e-01 -9.87376e-01  9.28071e-01  2.84990e-01
21Feb12_165011|  -1.61427e-01  8.70161e-02  5.01921e-01 -8.08083e-01  8.49112e-01
21Feb12_165011|  -6.52733e-01  2.37170e-01  3.13547e-01]]
21Feb12_165011|-- Bias --
21Feb12_165011|[ 0.24662  0.44736 -0.32858  0.33637 -0.46731  0.72607 -0.05204 -0.19373
21Feb12_165011|  0.48862  0.63189 -0.90691  0.81971 -0.51735]
21Feb12_165011|Layer 3:
21Feb12_165011|-- Config --
21Feb12_165011|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 13], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_165011|-- Weights --
21Feb12_165011|[[-0.71914  0.31285]
21Feb12_165011| [ 0.02323 -0.73840]
21Feb12_165011| [ 0.11675  0.74639]
21Feb12_165011| [ 0.56855 -0.17893]
21Feb12_165011| [ 0.74842  0.44150]
21Feb12_165011| [-0.52274 -0.37478]
21Feb12_165011| [-0.96763  0.94704]
21Feb12_165011| [ 0.24247  0.28835]
21Feb12_165011| [ 0.53177  0.52031]
21Feb12_165011| [-0.89662  0.37878]
21Feb12_165011| [ 0.70936 -0.82609]
21Feb12_165011| [ 0.55012 -0.55237]
21Feb12_165011| [ 0.94722 -0.49675]]
21Feb12_165011|-- Bias --
21Feb12_165011|[-0.41345 -0.68809]
21Feb12_165011|Predicting the validation and test data with the Best initial individual.
21Feb12_165019| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_165019|-----------  ------------------  --------------------  ----------
21Feb12_165019|Validation         42.00                 108            0.00000
21Feb12_165019|   Test            36.32                 108            0.00298
21Feb12_165019|-------------------- Test #0 --------------------
21Feb12_165019|Best final individual weights
21Feb12_165019|Individual:
21Feb12_165019|-- Constant hidden layers --
21Feb12_165019|False
21Feb12_165019|Layer 0:
21Feb12_165019|-- Config --
21Feb12_165019|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 15, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_165019|-- Weights --
21Feb12_165019|[[ 5.09617e-01  8.20902e-01 -3.02367e-01 -9.64837e-01 -4.33824e-01
21Feb12_165019|  -2.42034e-01 -5.04343e-01  1.31689e+00  9.21850e-01  5.13818e-01
21Feb12_165019|  -3.49854e-01  2.15852e-01 -1.04928e+00  7.68905e-01 -1.88324e+00]
21Feb12_165019| [-7.50915e-01 -2.52628e+00  3.69383e-01  1.39331e-01 -4.71230e-01
21Feb12_165019|   2.50267e+00 -2.55477e-01 -5.15419e-01 -2.31831e-01 -1.16548e+00
21Feb12_165019|  -8.22133e-01  4.82232e-01 -1.26500e+00  7.69663e-01  1.16647e+00]
21Feb12_165019| [ 4.01389e-03  9.01850e-01 -4.38696e-01 -7.91041e-01 -3.45664e-01
21Feb12_165019|  -1.66871e+00  1.65396e+00  7.90223e-01  5.51123e-01  1.67606e-01
21Feb12_165019|   2.12442e-01  1.14271e+00  6.42674e-01  2.00899e-01 -2.05944e-01]
21Feb12_165019| [ 1.80619e-01 -2.50060e-01 -1.12859e+00  1.83522e+00  1.81374e+00
21Feb12_165019|  -1.42416e+00  5.22823e-01 -7.02013e-01  1.84516e+00  1.90809e+00
21Feb12_165019|   1.37151e+00  4.03871e-02  4.29238e-01 -2.37117e-01 -1.00132e+00]
21Feb12_165019| [ 4.39871e-01  3.98574e-01 -3.75109e-01 -8.64825e-01  4.06425e-01
21Feb12_165019|   5.56500e-01  1.44148e+00 -5.22177e-01 -7.21740e-01  3.07682e-01
21Feb12_165019|  -9.52454e-01  8.44086e-01  1.09295e+00 -3.90444e-01  1.33545e+00]
21Feb12_165019| [-1.42180e+00  3.85641e-01 -8.43471e-02  1.81738e-02 -1.14521e+00
21Feb12_165019|  -8.06111e-01 -8.15090e-01  7.76165e-02  1.02784e+00  1.02123e-01
21Feb12_165019|   7.08213e-01  9.96943e-01 -7.79890e-01  1.66778e+00 -6.05761e-01]
21Feb12_165019| [-2.52774e-01 -9.61820e-01  3.02997e+00 -4.75355e-02  9.27908e-01
21Feb12_165019|   6.12327e-01 -4.65796e-01  8.85447e-01 -9.19731e-02  5.35502e-02
21Feb12_165019|  -5.61515e-01  1.22163e+00 -6.55581e-02 -4.23284e-01  6.78889e-01]
21Feb12_165019| [-4.07954e-01  7.89564e-01 -1.02275e+00 -1.42852e-01 -1.21182e-01
21Feb12_165019|   2.60288e+00  1.31219e+00 -1.05105e+00 -7.28076e-01  7.37981e-01
21Feb12_165019|   1.07877e+00  4.12772e-01  3.20972e-01 -1.42903e+00  5.49771e-01]
21Feb12_165019| [-1.06598e+00  4.11763e-01 -5.98736e-01 -1.02922e+00  1.44690e+00
21Feb12_165019|   1.61847e+00  7.86271e-01 -1.04439e+00 -1.22083e+00 -5.20594e-01
21Feb12_165019|   1.50709e+00 -2.76750e-01 -9.31489e-01  1.18032e+00 -1.34476e+00]
21Feb12_165019| [-9.84737e-01 -5.97909e-01 -5.05735e-01  1.21453e+00  2.04300e+00
21Feb12_165019|  -1.80226e+00  2.27960e-01  2.48235e-01 -9.14083e-01 -8.19925e-01
21Feb12_165019|   8.79325e-03  1.89321e+00 -2.33314e+00  3.64489e-01 -8.65853e-01]
21Feb12_165019| [-5.52147e-01 -1.09026e+00 -6.31263e-01 -9.85456e-02 -1.26793e+00
21Feb12_165019|   6.92239e-01  4.07591e-03  8.28704e-02 -4.61769e-01  1.47380e+00
21Feb12_165019|  -8.25050e-01  1.85307e+00 -7.02559e-01  4.42800e-01 -5.09351e-01]
21Feb12_165019| [-1.22241e+00 -2.82164e+00 -3.49419e-01  2.35780e-01 -3.06882e-01
21Feb12_165019|   4.97633e-01 -8.59745e-01  1.41005e+00  4.44223e-01  4.80295e-01
21Feb12_165019|   5.28514e-01 -8.52095e-01  7.93638e-01 -1.18061e+00  3.77575e-01]
21Feb12_165019| [ 1.83848e+00  1.86747e+00 -6.09064e-01 -1.29117e-01  8.20239e-01
21Feb12_165019|  -8.41223e-01 -4.91994e-01 -4.35134e-02 -3.10526e-01  8.12742e-01
21Feb12_165019|  -2.48499e+00  6.10492e-01  2.59825e-01  1.10740e+00  2.25110e-01]
21Feb12_165019| [-9.61110e-02  1.17814e+00  1.12148e-01 -3.49813e-01  2.43858e+00
21Feb12_165019|  -1.38613e+00 -3.82927e-01  1.52932e+00  8.48623e-01 -1.99483e+00
21Feb12_165019|  -2.12240e+00  1.06312e+00 -3.90781e-02  1.49640e+00  1.12926e+00]
21Feb12_165019| [-4.30616e-01  2.39031e-01 -7.23476e-01  1.25568e+00 -2.14845e-01
21Feb12_165019|  -5.53173e-01 -2.65699e+00  2.69230e-02 -1.00392e+00  1.32765e-01
21Feb12_165019|  -5.64005e-01  1.22524e+00  1.24383e+00 -1.09592e+00 -1.41796e+00]
21Feb12_165019| [-2.39791e-01  1.53064e+00  3.01720e-01  2.78106e-01 -1.84792e-01
21Feb12_165019|   1.56208e+00  9.94463e-01 -1.63904e+00  6.63295e-01 -1.85188e+00
21Feb12_165019|  -7.33287e-01 -1.62705e-01 -9.61094e-01  4.14256e-01 -1.81088e+00]
21Feb12_165019| [ 2.83794e-01  7.82624e-01  8.22930e-01  1.38834e+00  1.35777e+00
21Feb12_165019|   1.13137e+00 -4.51094e-01 -9.14736e-02 -4.29153e-01 -1.32003e-01
21Feb12_165019|  -1.06833e+00 -3.60741e-02 -1.72337e+00 -9.36812e-02 -1.50919e-01]
21Feb12_165019| [ 4.60832e-01 -6.41447e-01  7.19778e-01  1.43690e+00 -5.39012e-01
21Feb12_165019|   2.73839e+00  4.18203e-02  1.12728e+00 -1.96359e+00  5.08015e-01
21Feb12_165019|  -3.94637e-02  1.21425e+00  7.81562e-01  1.21240e+00  8.71932e-02]
21Feb12_165019| [ 7.21067e-01 -4.05470e-01  4.30706e-01 -1.12406e+00 -1.66416e-01
21Feb12_165019|  -1.74613e-01 -2.82475e+00  7.83187e-01 -1.70599e+00 -4.53800e-01
21Feb12_165019|   7.68700e-02  1.38626e+00  4.71260e-01 -1.20854e-01 -3.85957e-01]
21Feb12_165019| [-1.45393e+00 -4.35386e-01  7.35002e-01 -1.05813e+00 -6.41567e-01
21Feb12_165019|  -1.23953e+00 -1.11174e+00 -4.33161e-01  1.71285e+00 -1.69152e+00
21Feb12_165019|  -3.94477e-01 -9.64481e-01  2.12241e-01 -4.51296e-01  6.12573e-01]
21Feb12_165019| [ 1.91178e+00 -7.20020e-01 -1.43347e+00  6.16597e-01 -1.40631e-01
21Feb12_165019|   9.60419e-01 -2.94601e-01 -3.70235e-01  1.68500e-03 -7.06077e-02
21Feb12_165019|  -2.63686e+00 -7.93469e-01  3.46275e-01  2.04211e+00  9.19580e-01]
21Feb12_165019| [ 2.28690e-01 -1.52406e-01 -4.49362e-01 -7.32180e-01  7.99781e-01
21Feb12_165019|   4.88373e-01 -9.34696e-01 -5.02242e-01  9.68074e-01 -3.07760e-01
21Feb12_165019|  -3.49720e-01 -2.00695e+00 -4.45838e-01  2.62312e-01  3.38818e-01]
21Feb12_165019| [-1.98557e-01  8.34883e-01 -1.61905e-01  1.28379e+00  1.04073e+00
21Feb12_165019|   1.45833e+00  4.77341e-01  9.87420e-01 -3.08856e-01 -1.55031e+00
21Feb12_165019|   1.38023e+00 -4.42201e-01  1.78369e+00  8.01018e-01  1.52483e+00]
21Feb12_165019| [ 1.12967e+00 -8.45423e-01  1.52345e+00  1.08801e+00 -4.32434e-01
21Feb12_165019|  -3.16741e-01 -7.17985e-02  1.09877e+00 -7.90690e-01  1.36084e+00
21Feb12_165019|  -5.66120e-01 -1.70432e+00 -2.12910e+00 -2.41374e-01  1.33636e+00]
21Feb12_165019| [-4.08205e-01 -8.03871e-01  9.13990e-01  5.00916e-01 -1.81059e-01
21Feb12_165019|   2.42621e-01 -9.57869e-01  6.74094e-01  6.52179e-01  2.77279e-01
21Feb12_165019|  -3.91051e-01 -9.05321e-02  6.86316e-01 -3.54594e-01  5.83144e-01]
21Feb12_165019| [-3.98308e-01 -4.48018e-03  1.11987e+00  1.50374e+00 -9.18129e-01
21Feb12_165019|  -1.81690e+00 -1.38223e+00 -2.74481e-01 -8.24843e-01 -7.05820e-01
21Feb12_165019|   1.50584e+00 -4.21386e-01  4.00084e-01 -7.61841e-02 -7.41767e-01]
21Feb12_165019| [ 5.51762e-01 -1.04904e+00  5.21335e-01  2.14684e-01 -8.21795e-02
21Feb12_165019|   3.68556e-01  1.01222e+00 -1.30634e+00 -1.52652e+00  9.98379e-01
21Feb12_165019|   8.51997e-01 -9.42775e-01 -1.16577e-01  3.64988e-01 -1.27419e+00]
21Feb12_165019| [ 1.67425e+00 -1.27190e-01  2.44775e+00  1.44302e+00 -4.43112e-01
21Feb12_165019|  -4.07317e-02  1.33875e-01  4.92876e-01  1.36327e+00  3.41424e-01
21Feb12_165019|   1.70937e+00 -2.26414e+00  5.48087e-01 -2.49869e-01 -1.95666e+00]
21Feb12_165019| [-7.77069e-01  1.76839e+00 -5.99460e-01 -2.13769e+00  1.38006e+00
21Feb12_165019|   1.30623e+00 -1.06865e+00 -1.16462e+00  8.02528e-01 -3.99780e-01
21Feb12_165019|   8.20611e-01 -1.64613e-01  3.17174e-01  1.50755e+00  1.82851e-01]
21Feb12_165019| [-1.02989e+00 -1.07499e+00 -1.93091e+00  4.66271e-01 -8.74190e-01
21Feb12_165019|  -1.32185e+00 -9.08286e-01 -8.46363e-01  2.03651e-01 -2.52017e-01
21Feb12_165019|   1.15748e+00 -3.29038e-01 -5.53034e-01  6.31862e-01 -9.38469e-02]
21Feb12_165019| [-1.07650e+00  2.26383e-01  1.43406e-01 -1.04859e+00 -1.13255e+00
21Feb12_165019|   5.32942e-01 -2.81361e-01  1.06039e+00 -4.84886e-01  1.81779e+00
21Feb12_165019|   4.45898e-01  1.15599e-01  2.22637e+00 -1.10477e+00 -7.41273e-01]
21Feb12_165019| [ 5.36190e-01  1.36053e+00  1.86442e-01  1.76821e-01  1.73842e+00
21Feb12_165019|   1.33653e-01 -2.69435e-01  1.42842e+00 -6.67924e-01  8.34192e-01
21Feb12_165019|  -4.93949e-01  2.55190e-01  8.44813e-02  1.07023e+00  3.32795e-01]
21Feb12_165019| [-7.77858e-01  6.91255e-01 -2.00094e-01 -3.47804e-02  1.25963e+00
21Feb12_165019|   2.88406e-01  1.11181e-02 -1.72072e-01  1.74171e-01  1.07767e+00
21Feb12_165019|  -7.57539e-01 -1.51881e+00  1.13432e+00 -8.19687e-01  2.51036e-01]
21Feb12_165019| [ 1.17877e+00  8.51361e-01  5.34249e-01 -3.85201e-01  1.62741e+00
21Feb12_165019|   7.14108e-01 -2.49586e-01 -1.51061e+00 -5.78471e-01 -1.53573e+00
21Feb12_165019|  -6.82580e-01 -1.03046e+00  2.14369e+00 -2.12686e+00  2.93875e-01]
21Feb12_165019| [-5.46699e-01 -1.24367e-01  1.50400e+00  5.24570e-01  1.32199e-01
21Feb12_165019|  -1.11873e+00 -1.21781e-01  1.60716e+00  7.94494e-01  4.12000e-02
21Feb12_165019|  -1.45629e-01 -1.67069e+00  1.55359e+00  1.27490e+00  3.78250e-01]
21Feb12_165019| [-1.65770e+00  7.63010e-01 -1.07032e-01 -1.29077e+00 -2.72523e-01
21Feb12_165019|   8.86152e-01  2.03137e-02  1.07244e+00 -2.07611e+00  1.79718e-01
21Feb12_165019|   1.81554e-01 -6.15758e-01 -9.51774e-01  1.02939e+00  8.17973e-01]
21Feb12_165019| [ 9.21545e-01 -8.71244e-02 -1.53454e+00 -1.66686e+00  9.25583e-02
21Feb12_165019|   5.45788e-01  9.00588e-01  5.39148e-01  1.73423e+00  5.95858e-01
21Feb12_165019|   7.60598e-01  7.10163e-01 -1.92447e-01 -2.18648e-01 -1.06613e-01]
21Feb12_165019| [-1.27156e+00  1.50471e-01 -1.51367e+00  2.43159e-01  1.45374e+00
21Feb12_165019|   1.39069e-01  1.63857e+00  7.76127e-01  1.22775e-01 -9.15383e-01
21Feb12_165019|  -7.88206e-01 -1.88443e-01  5.88849e-01 -1.15889e+00  1.57532e+00]
21Feb12_165019| [-7.87307e-01  7.90368e-01 -8.23463e-01 -7.31497e-01 -1.23567e+00
21Feb12_165019|   4.22757e-01  3.63316e-02  6.01964e-01  1.96999e+00 -1.17414e+00
21Feb12_165019|   3.97797e-01 -1.08808e+00 -5.94358e-01 -2.83672e-01  8.50566e-01]
21Feb12_165019| [ 5.30769e-01 -1.84801e+00 -5.66134e-01  6.76585e-02  1.10136e-01
21Feb12_165019|   4.92367e-01 -4.90997e-01  6.06677e-01  2.28381e+00 -4.07746e-02
21Feb12_165019|   1.15850e+00 -5.98080e-01 -7.01578e-01  1.01957e+00  2.49859e-01]
21Feb12_165019| [-8.63352e-01  1.10102e+00 -1.35284e+00  7.44546e-01  1.23832e+00
21Feb12_165019|  -5.46095e-01 -7.14545e-01  6.39714e-01 -1.05446e-01 -8.88602e-01
21Feb12_165019|   9.93232e-01  1.94862e+00 -4.16105e-01  1.03489e-01  1.11977e+00]
21Feb12_165019| [ 1.19516e+00 -1.76346e-01  1.04128e-01  1.20697e+00 -9.23981e-01
21Feb12_165019|  -1.33787e+00 -2.81645e-01  4.54001e-01  1.13838e-01  7.67530e-01
21Feb12_165019|  -1.19224e+00 -1.30105e-01 -1.91934e-01  4.19944e-01  1.69825e-01]
21Feb12_165019| [ 7.65088e-01 -1.94246e+00 -7.11338e-01  4.53958e-01  1.94201e+00
21Feb12_165019|   1.31030e+00 -2.96434e-02 -1.76407e+00  5.53828e-01  6.85560e-01
21Feb12_165019|   7.66333e-01  3.82096e-02 -8.16458e-01 -6.24116e-02  2.64193e-01]
21Feb12_165019| [ 3.18200e-01  2.29948e+00  1.64715e+00  1.62897e+00 -7.51376e-02
21Feb12_165019|  -1.28841e+00 -6.20669e-01 -1.11166e-01  8.60402e-01 -1.33019e+00
21Feb12_165019|  -5.96012e-01  1.43903e+00  4.95090e-01 -5.77593e-01  1.44906e+00]
21Feb12_165019| [ 4.11040e-01  7.04946e-01 -5.20407e-01  1.19926e-01 -2.14187e-01
21Feb12_165019|   2.61836e-01 -2.06690e-01 -5.23044e-01 -2.21768e+00 -1.84159e+00
21Feb12_165019|   1.07890e-01 -1.21571e+00  1.41906e-02 -1.18878e+00 -1.10586e+00]
21Feb12_165019| [ 7.47110e-04 -2.19367e-01  1.24132e+00  2.42981e-01  1.64975e+00
21Feb12_165019|  -7.56681e-01  2.05047e+00  1.41699e+00  2.11413e-01  2.05856e-01
21Feb12_165019|  -1.19536e+00 -1.17721e+00 -5.74572e-02 -9.88771e-01 -5.21745e-02]
21Feb12_165019| [ 8.41039e-01 -7.80210e-01  1.63153e-01  9.11562e-01  1.96584e+00
21Feb12_165019|   1.78291e+00  1.27725e-01  9.24125e-01  8.89095e-01  8.02583e-01
21Feb12_165019|  -1.84072e-01 -1.83956e+00 -1.02407e+00  6.97260e-01  2.04119e+00]
21Feb12_165019| [ 1.02325e+00 -1.14512e+00  1.53735e+00 -1.20875e+00  2.40349e-01
21Feb12_165019|   3.65149e-01 -8.45853e-01 -9.53877e-01  1.08881e+00  1.31369e+00
21Feb12_165019|  -8.73629e-01  3.54768e-01 -1.44120e+00  3.00774e+00  5.37138e-01]
21Feb12_165019| [ 1.21153e+00  1.33780e+00  2.37346e-01  1.10192e+00 -7.71109e-01
21Feb12_165019|  -1.67297e+00 -9.85041e-01 -9.67469e-02  1.35584e-01  1.43828e+00
21Feb12_165019|  -5.37772e-01  6.81867e-01  8.99423e-02 -3.00140e-01  7.40803e-01]
21Feb12_165019| [-1.53912e-01 -1.45545e+00 -8.51719e-01 -3.24207e-01 -1.85297e+00
21Feb12_165019|  -1.37632e+00  2.56265e+00 -1.51591e+00 -7.70917e-01  1.60742e+00
21Feb12_165019|   8.19418e-01  1.51279e+00 -7.75504e-01 -4.56317e-01  7.93313e-01]
21Feb12_165019| [ 1.79234e+00  5.37534e-01 -1.64985e-01  1.12594e+00  4.19165e-01
21Feb12_165019|   1.00815e+00 -1.24029e+00  8.99015e-02  5.04534e-01  1.04688e+00
21Feb12_165019|  -1.85983e+00 -6.28367e-01  1.44747e+00 -7.70927e-01 -6.80962e-02]
21Feb12_165019| [-6.11685e-01  5.81244e-01 -2.00813e+00  4.40980e-01  1.17081e+00
21Feb12_165019|   4.53617e-02 -1.02732e-01 -5.30344e-01 -2.30272e-01 -2.75712e-01
21Feb12_165019|  -1.35628e+00  6.77073e-01  1.18206e+00 -9.68516e-01  8.88227e-01]
21Feb12_165019| [ 3.39330e-01  1.85906e-01  3.17199e+00 -1.14941e+00  8.41043e-01
21Feb12_165019|   1.43171e+00  2.91815e-01  9.90040e-01  2.43151e-01 -4.20123e-01
21Feb12_165019|  -7.71009e-01  8.26689e-01 -2.38729e-01  2.25124e-01  4.71938e-02]
21Feb12_165019| [-1.24769e+00 -1.74352e-01  1.33159e+00  6.31103e-01  1.39801e-01
21Feb12_165019|  -1.97232e-01  1.00881e+00 -1.05164e+00 -1.26316e-01 -6.77330e-01
21Feb12_165019|   6.93223e-01  3.09964e-01  4.46448e-01  3.28001e-01 -7.51083e-01]
21Feb12_165019| [-7.55157e-01 -1.20070e+00  1.18128e+00  2.31557e-01 -5.77142e-01
21Feb12_165019|   8.50621e-01 -6.80691e-01  1.14562e+00  6.53826e-01 -1.28380e+00
21Feb12_165019|   4.15503e-02  9.67591e-01 -3.56690e+00 -2.80446e-01 -2.39691e-01]
21Feb12_165019| [ 1.43065e+00  4.89999e-01  7.08940e-01  9.80815e-01 -5.25905e-01
21Feb12_165019|   8.92854e-01 -1.47577e+00 -9.27641e-02 -3.34619e-01 -1.41270e+00
21Feb12_165019|  -1.10591e+00  1.59163e+00  2.61333e-01 -1.48185e+00 -2.14182e+00]
21Feb12_165019| [ 8.38600e-01 -8.88508e-01 -4.12187e-01 -1.04812e-01  3.26908e-01
21Feb12_165019|  -9.83693e-01  1.67864e+00  7.72612e-01  1.95026e+00  9.57917e-01
21Feb12_165019|  -1.48928e+00 -1.99797e-01 -3.05136e-01 -1.14633e-01 -1.04672e+00]]
21Feb12_165019|-- Bias --
21Feb12_165019|[ 0.73695 -0.51772  1.29843 -0.86449  0.54318  0.17660 -0.21569  0.35471
21Feb12_165019| -0.23531 -0.15791  1.04286  0.77391 -0.11794  1.01790  0.50375]
21Feb12_165019|Layer 1:
21Feb12_165019|-- Config --
21Feb12_165019|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 15], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_165019|-- Weights --
21Feb12_165019|[[ 0.70443 -1.08724]
21Feb12_165019| [-0.44561 -1.05050]
21Feb12_165019| [ 0.25488  0.31427]
21Feb12_165019| [-1.40193  0.84859]
21Feb12_165019| [ 0.27127 -0.15942]
21Feb12_165019| [-0.18528 -0.14003]
21Feb12_165019| [ 1.68717  0.30442]
21Feb12_165019| [-0.01440  0.47743]
21Feb12_165019| [ 0.46612  0.57491]
21Feb12_165019| [-1.91613 -0.31596]
21Feb12_165019| [ 1.38318 -0.97860]
21Feb12_165019| [-0.49568  0.13334]
21Feb12_165019| [ 0.67487 -1.08400]
21Feb12_165019| [ 1.22898  1.13422]
21Feb12_165019| [ 0.14442 -0.69100]]
21Feb12_165019|-- Bias --
21Feb12_165019|[ 1.12271 -0.02168]
21Feb12_165019|Predicting the validation and test data with the Best final individual.
21Feb12_165027| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_165027|-----------  ------------------  --------------------  ----------
21Feb12_165027|Validation         41.83                  15            0.00517
21Feb12_165027|   Test            36.40                  15            0.00595
21Feb12_165027|-------------------- Test #1 --------------------
21Feb12_165027|Best final individual weights
21Feb12_165027|Individual:
21Feb12_165027|-- Constant hidden layers --
21Feb12_165027|False
21Feb12_165027|Layer 0:
21Feb12_165027|-- Config --
21Feb12_165027|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 15, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_165027|-- Weights --
21Feb12_165027|[[ 5.09617e-01  8.20902e-01 -3.02367e-01 -9.64837e-01 -4.33824e-01
21Feb12_165027|  -2.42034e-01 -5.04343e-01  1.31689e+00  9.21850e-01  5.13818e-01
21Feb12_165027|  -3.49854e-01  2.15852e-01 -1.04928e+00  7.68905e-01 -1.88324e+00]
21Feb12_165027| [-7.50915e-01 -2.52628e+00  3.69383e-01  1.39331e-01 -4.71230e-01
21Feb12_165027|   2.50267e+00 -2.55477e-01 -5.15419e-01 -2.31831e-01 -1.16548e+00
21Feb12_165027|  -8.22133e-01  4.82232e-01 -1.26500e+00  7.69663e-01  1.16647e+00]
21Feb12_165027| [ 4.01389e-03  9.01850e-01 -4.38696e-01 -7.91041e-01 -3.45664e-01
21Feb12_165027|  -1.66871e+00  1.65396e+00  7.90223e-01  5.51123e-01  1.67606e-01
21Feb12_165027|   2.12442e-01  1.14271e+00  6.42674e-01  2.00899e-01 -2.05944e-01]
21Feb12_165027| [ 1.80619e-01 -2.50060e-01 -1.12859e+00  1.83522e+00  1.81374e+00
21Feb12_165027|  -1.42416e+00  5.22823e-01 -7.02013e-01  1.84516e+00  1.90809e+00
21Feb12_165027|   1.37151e+00  4.03871e-02  4.29238e-01 -2.37117e-01 -1.00132e+00]
21Feb12_165027| [ 4.39871e-01  3.98574e-01 -3.75109e-01 -8.64825e-01  4.06425e-01
21Feb12_165027|   5.56500e-01  1.44148e+00 -5.22177e-01 -7.21740e-01  3.07682e-01
21Feb12_165027|  -9.52454e-01  8.44086e-01  1.09295e+00 -3.90444e-01  1.33545e+00]
21Feb12_165027| [-1.42180e+00  3.85641e-01 -8.43471e-02  1.81738e-02 -1.14521e+00
21Feb12_165027|  -8.06111e-01 -8.15090e-01  7.76165e-02  1.02784e+00  1.02123e-01
21Feb12_165027|   7.08213e-01  9.96943e-01 -7.79890e-01  1.66778e+00 -6.05761e-01]
21Feb12_165027| [-2.52774e-01 -9.61820e-01  3.02997e+00 -4.75355e-02  9.27908e-01
21Feb12_165027|   6.12327e-01 -4.65796e-01  8.85447e-01 -9.19731e-02  5.35502e-02
21Feb12_165027|  -5.61515e-01  1.22163e+00 -6.55581e-02 -4.23284e-01  6.78889e-01]
21Feb12_165027| [-4.07954e-01  7.89564e-01 -1.02275e+00 -1.42852e-01 -1.21182e-01
21Feb12_165027|   2.60288e+00  1.31219e+00 -1.05105e+00 -7.28076e-01  7.37981e-01
21Feb12_165027|   1.07877e+00  4.12772e-01  3.20972e-01 -1.42903e+00  5.49771e-01]
21Feb12_165027| [-1.06598e+00  4.11763e-01 -5.98736e-01 -1.02922e+00  1.44690e+00
21Feb12_165027|   1.61847e+00  7.86271e-01 -1.04439e+00 -1.22083e+00 -5.20594e-01
21Feb12_165027|   1.50709e+00 -2.76750e-01 -9.31489e-01  1.18032e+00 -1.34476e+00]
21Feb12_165027| [-9.84737e-01 -5.97909e-01 -5.05735e-01  1.21453e+00  2.04300e+00
21Feb12_165027|  -1.80226e+00  2.27960e-01  2.48235e-01 -9.14083e-01 -8.19925e-01
21Feb12_165027|   8.79325e-03  1.89321e+00 -2.33314e+00  3.64489e-01 -8.65853e-01]
21Feb12_165027| [-5.52147e-01 -1.09026e+00 -6.31263e-01 -9.85456e-02 -1.26793e+00
21Feb12_165027|   6.92239e-01  4.07591e-03  8.28704e-02 -4.61769e-01  1.47380e+00
21Feb12_165027|  -8.25050e-01  1.85307e+00 -7.02559e-01  4.42800e-01 -5.09351e-01]
21Feb12_165027| [-1.22241e+00 -2.82164e+00 -3.49419e-01  2.35780e-01 -3.06882e-01
21Feb12_165027|   4.97633e-01 -8.59745e-01  1.41005e+00  4.44223e-01  4.80295e-01
21Feb12_165027|   5.28514e-01 -8.52095e-01  7.93638e-01 -1.18061e+00  3.77575e-01]
21Feb12_165027| [ 1.83848e+00  1.86747e+00 -6.09064e-01 -1.29117e-01  8.20239e-01
21Feb12_165027|  -8.41223e-01 -4.91994e-01 -4.35134e-02 -3.10526e-01  8.12742e-01
21Feb12_165027|  -2.48499e+00  6.10492e-01  2.59825e-01  1.10740e+00  2.25110e-01]
21Feb12_165027| [-9.61110e-02  1.17814e+00  1.12148e-01 -3.49813e-01  2.43858e+00
21Feb12_165027|  -1.38613e+00 -3.82927e-01  1.52932e+00  8.48623e-01 -1.99483e+00
21Feb12_165027|  -2.12240e+00  1.06312e+00 -3.90781e-02  1.49640e+00  1.12926e+00]
21Feb12_165027| [-4.30616e-01  2.39031e-01 -7.23476e-01  1.25568e+00 -2.14845e-01
21Feb12_165027|  -5.53173e-01 -2.65699e+00  2.69230e-02 -1.00392e+00  1.32765e-01
21Feb12_165027|  -5.64005e-01  1.22524e+00  1.24383e+00 -1.09592e+00 -1.41796e+00]
21Feb12_165027| [-2.39791e-01  1.53064e+00  3.01720e-01  2.78106e-01 -1.84792e-01
21Feb12_165027|   1.56208e+00  9.94463e-01 -1.63904e+00  6.63295e-01 -1.85188e+00
21Feb12_165027|  -7.33287e-01 -1.62705e-01 -9.61094e-01  4.14256e-01 -1.81088e+00]
21Feb12_165027| [ 2.83794e-01  7.82624e-01  8.22930e-01  1.38834e+00  1.35777e+00
21Feb12_165027|   1.13137e+00 -4.51094e-01 -9.14736e-02 -4.29153e-01 -1.32003e-01
21Feb12_165027|  -1.06833e+00 -3.60741e-02 -1.72337e+00 -9.36812e-02 -1.50919e-01]
21Feb12_165027| [ 4.60832e-01 -6.41447e-01  7.19778e-01  1.43690e+00 -5.39012e-01
21Feb12_165027|   2.73839e+00  4.18203e-02  1.12728e+00 -1.96359e+00  5.08015e-01
21Feb12_165027|  -3.94637e-02  1.21425e+00  7.81562e-01  1.21240e+00  8.71932e-02]
21Feb12_165027| [ 7.21067e-01 -4.05470e-01  4.30706e-01 -1.12406e+00 -1.66416e-01
21Feb12_165027|  -1.74613e-01 -2.82475e+00  7.83187e-01 -1.70599e+00 -4.53800e-01
21Feb12_165027|   7.68700e-02  1.38626e+00  4.71260e-01 -1.20854e-01 -3.85957e-01]
21Feb12_165027| [-1.45393e+00 -4.35386e-01  7.35002e-01 -1.05813e+00 -6.41567e-01
21Feb12_165027|  -1.23953e+00 -1.11174e+00 -4.33161e-01  1.71285e+00 -1.69152e+00
21Feb12_165027|  -3.94477e-01 -9.64481e-01  2.12241e-01 -4.51296e-01  6.12573e-01]
21Feb12_165027| [ 1.91178e+00 -7.20020e-01 -1.43347e+00  6.16597e-01 -1.40631e-01
21Feb12_165027|   9.60419e-01 -2.94601e-01 -3.70235e-01  1.68500e-03 -7.06077e-02
21Feb12_165027|  -2.63686e+00 -7.93469e-01  3.46275e-01  2.04211e+00  9.19580e-01]
21Feb12_165027| [ 2.28690e-01 -1.52406e-01 -4.49362e-01 -7.32180e-01  7.99781e-01
21Feb12_165027|   4.88373e-01 -9.34696e-01 -5.02242e-01  9.68074e-01 -3.07760e-01
21Feb12_165027|  -3.49720e-01 -2.00695e+00 -4.45838e-01  2.62312e-01  3.38818e-01]
21Feb12_165027| [-1.98557e-01  8.34883e-01 -1.61905e-01  1.28379e+00  1.04073e+00
21Feb12_165027|   1.45833e+00  4.77341e-01  9.87420e-01 -3.08856e-01 -1.55031e+00
21Feb12_165027|   1.38023e+00 -4.42201e-01  1.78369e+00  8.01018e-01  1.52483e+00]
21Feb12_165027| [ 1.12967e+00 -8.45423e-01  1.52345e+00  1.08801e+00 -4.32434e-01
21Feb12_165027|  -3.16741e-01 -7.17985e-02  1.09877e+00 -7.90690e-01  1.36084e+00
21Feb12_165027|  -5.66120e-01 -1.70432e+00 -2.12910e+00 -2.41374e-01  1.33636e+00]
21Feb12_165027| [-4.08205e-01 -8.03871e-01  9.13990e-01  5.00916e-01 -1.81059e-01
21Feb12_165027|   2.42621e-01 -9.57869e-01  6.74094e-01  6.52179e-01  2.77279e-01
21Feb12_165027|  -3.91051e-01 -9.05321e-02  6.86316e-01 -3.54594e-01  5.83144e-01]
21Feb12_165027| [-3.98308e-01 -4.48018e-03  1.11987e+00  1.50374e+00 -9.18129e-01
21Feb12_165027|  -1.81690e+00 -1.38223e+00 -2.74481e-01 -8.24843e-01 -7.05820e-01
21Feb12_165027|   1.50584e+00 -4.21386e-01  4.00084e-01 -7.61841e-02 -7.41767e-01]
21Feb12_165027| [ 5.51762e-01 -1.04904e+00  5.21335e-01  2.14684e-01 -8.21795e-02
21Feb12_165027|   3.68556e-01  1.01222e+00 -1.30634e+00 -1.52652e+00  9.98379e-01
21Feb12_165027|   8.51997e-01 -9.42775e-01 -1.16577e-01  3.64988e-01 -1.27419e+00]
21Feb12_165027| [ 1.67425e+00 -1.27190e-01  2.44775e+00  1.44302e+00 -4.43112e-01
21Feb12_165027|  -4.07317e-02  1.33875e-01  4.92876e-01  1.36327e+00  3.41424e-01
21Feb12_165027|   1.70937e+00 -2.26414e+00  5.48087e-01 -2.49869e-01 -1.95666e+00]
21Feb12_165027| [-7.77069e-01  1.76839e+00 -5.99460e-01 -2.13769e+00  1.38006e+00
21Feb12_165027|   1.30623e+00 -1.06865e+00 -1.16462e+00  8.02528e-01 -3.99780e-01
21Feb12_165027|   8.20611e-01 -1.64613e-01  3.17174e-01  1.50755e+00  1.82851e-01]
21Feb12_165027| [-1.02989e+00 -1.07499e+00 -1.93091e+00  4.66271e-01 -8.74190e-01
21Feb12_165027|  -1.32185e+00 -9.08286e-01 -8.46363e-01  2.03651e-01 -2.52017e-01
21Feb12_165027|   1.15748e+00 -3.29038e-01 -5.53034e-01  6.31862e-01 -9.38469e-02]
21Feb12_165027| [-1.07650e+00  2.26383e-01  1.43406e-01 -1.04859e+00 -1.13255e+00
21Feb12_165027|   5.32942e-01 -2.81361e-01  1.06039e+00 -4.84886e-01  1.81779e+00
21Feb12_165027|   4.45898e-01  1.15599e-01  2.22637e+00 -1.10477e+00 -7.41273e-01]
21Feb12_165027| [ 5.36190e-01  1.36053e+00  1.86442e-01  1.76821e-01  1.73842e+00
21Feb12_165027|   1.33653e-01 -2.69435e-01  1.42842e+00 -6.67924e-01  8.34192e-01
21Feb12_165027|  -4.93949e-01  2.55190e-01  8.44813e-02  1.07023e+00  3.32795e-01]
21Feb12_165027| [-7.77858e-01  6.91255e-01 -2.00094e-01 -3.47804e-02  1.25963e+00
21Feb12_165027|   2.88406e-01  1.11181e-02 -1.72072e-01  1.74171e-01  1.07767e+00
21Feb12_165027|  -7.57539e-01 -1.51881e+00  1.13432e+00 -8.19687e-01  2.51036e-01]
21Feb12_165027| [ 1.17877e+00  8.51361e-01  5.34249e-01 -3.85201e-01  1.62741e+00
21Feb12_165027|   7.14108e-01 -2.49586e-01 -1.51061e+00 -5.78471e-01 -1.53573e+00
21Feb12_165027|  -6.82580e-01 -1.03046e+00  2.14369e+00 -2.12686e+00  2.93875e-01]
21Feb12_165027| [-5.46699e-01 -1.24367e-01  1.50400e+00  5.24570e-01  1.32199e-01
21Feb12_165027|  -1.11873e+00 -1.21781e-01  1.60716e+00  7.94494e-01  4.12000e-02
21Feb12_165027|  -1.45629e-01 -1.67069e+00  1.55359e+00  1.27490e+00  3.78250e-01]
21Feb12_165027| [-1.65770e+00  7.63010e-01 -1.07032e-01 -1.29077e+00 -2.72523e-01
21Feb12_165027|   8.86152e-01  2.03137e-02  1.07244e+00 -2.07611e+00  1.79718e-01
21Feb12_165027|   1.81554e-01 -6.15758e-01 -9.51774e-01  1.02939e+00  8.17973e-01]
21Feb12_165027| [ 9.21545e-01 -8.71244e-02 -1.53454e+00 -1.66686e+00  9.25583e-02
21Feb12_165027|   5.45788e-01  9.00588e-01  5.39148e-01  1.73423e+00  5.95858e-01
21Feb12_165027|   7.60598e-01  7.10163e-01 -1.92447e-01 -2.18648e-01 -1.06613e-01]
21Feb12_165027| [-1.27156e+00  1.50471e-01 -1.51367e+00  2.43159e-01  1.45374e+00
21Feb12_165027|   1.39069e-01  1.63857e+00  7.76127e-01  1.22775e-01 -9.15383e-01
21Feb12_165027|  -7.88206e-01 -1.88443e-01  5.88849e-01 -1.15889e+00  1.57532e+00]
21Feb12_165027| [-7.87307e-01  7.90368e-01 -8.23463e-01 -7.31497e-01 -1.23567e+00
21Feb12_165027|   4.22757e-01  3.63316e-02  6.01964e-01  1.96999e+00 -1.17414e+00
21Feb12_165027|   3.97797e-01 -1.08808e+00 -5.94358e-01 -2.83672e-01  8.50566e-01]
21Feb12_165027| [ 5.30769e-01 -1.84801e+00 -5.66134e-01  6.76585e-02  1.10136e-01
21Feb12_165027|   4.92367e-01 -4.90997e-01  6.06677e-01  2.28381e+00 -4.07746e-02
21Feb12_165027|   1.15850e+00 -5.98080e-01 -7.01578e-01  1.01957e+00  2.49859e-01]
21Feb12_165027| [-8.63352e-01  1.10102e+00 -1.35284e+00  7.44546e-01  1.23832e+00
21Feb12_165027|  -5.46095e-01 -7.14545e-01  6.39714e-01 -1.05446e-01 -8.88602e-01
21Feb12_165027|   9.93232e-01  1.94862e+00 -4.16105e-01  1.03489e-01  1.11977e+00]
21Feb12_165027| [ 1.19516e+00 -1.76346e-01  1.04128e-01  1.20697e+00 -9.23981e-01
21Feb12_165027|  -1.33787e+00 -2.81645e-01  4.54001e-01  1.13838e-01  7.67530e-01
21Feb12_165027|  -1.19224e+00 -1.30105e-01 -1.91934e-01  4.19944e-01  1.69825e-01]
21Feb12_165027| [ 7.65088e-01 -1.94246e+00 -7.11338e-01  4.53958e-01  1.94201e+00
21Feb12_165027|   1.31030e+00 -2.96434e-02 -1.76407e+00  5.53828e-01  6.85560e-01
21Feb12_165027|   7.66333e-01  3.82096e-02 -8.16458e-01 -6.24116e-02  2.64193e-01]
21Feb12_165027| [ 3.18200e-01  2.29948e+00  1.64715e+00  1.62897e+00 -7.51376e-02
21Feb12_165027|  -1.28841e+00 -6.20669e-01 -1.11166e-01  8.60402e-01 -1.33019e+00
21Feb12_165027|  -5.96012e-01  1.43903e+00  4.95090e-01 -5.77593e-01  1.44906e+00]
21Feb12_165027| [ 4.11040e-01  7.04946e-01 -5.20407e-01  1.19926e-01 -2.14187e-01
21Feb12_165027|   2.61836e-01 -2.06690e-01 -5.23044e-01 -2.21768e+00 -1.84159e+00
21Feb12_165027|   1.07890e-01 -1.21571e+00  1.41906e-02 -1.18878e+00 -1.10586e+00]
21Feb12_165027| [ 7.47110e-04 -2.19367e-01  1.24132e+00  2.42981e-01  1.64975e+00
21Feb12_165027|  -7.56681e-01  2.05047e+00  1.41699e+00  2.11413e-01  2.05856e-01
21Feb12_165027|  -1.19536e+00 -1.17721e+00 -5.74572e-02 -9.88771e-01 -5.21745e-02]
21Feb12_165027| [ 8.41039e-01 -7.80210e-01  1.63153e-01  9.11562e-01  1.96584e+00
21Feb12_165027|   1.78291e+00  1.27725e-01  9.24125e-01  8.89095e-01  8.02583e-01
21Feb12_165027|  -1.84072e-01 -1.83956e+00 -1.02407e+00  6.97260e-01  2.04119e+00]
21Feb12_165027| [ 1.02325e+00 -1.14512e+00  1.53735e+00 -1.20875e+00  2.40349e-01
21Feb12_165027|   3.65149e-01 -8.45853e-01 -9.53877e-01  1.08881e+00  1.31369e+00
21Feb12_165027|  -8.73629e-01  3.54768e-01 -1.44120e+00  3.00774e+00  5.37138e-01]
21Feb12_165027| [ 1.21153e+00  1.33780e+00  2.37346e-01  1.10192e+00 -7.71109e-01
21Feb12_165027|  -1.67297e+00 -9.85041e-01 -9.67469e-02  1.35584e-01  1.43828e+00
21Feb12_165027|  -5.37772e-01  6.81867e-01  8.99423e-02 -3.00140e-01  7.40803e-01]
21Feb12_165027| [-1.53912e-01 -1.45545e+00 -8.51719e-01 -3.24207e-01 -1.85297e+00
21Feb12_165027|  -1.37632e+00  2.56265e+00 -1.51591e+00 -7.70917e-01  1.60742e+00
21Feb12_165027|   8.19418e-01  1.51279e+00 -7.75504e-01 -4.56317e-01  7.93313e-01]
21Feb12_165027| [ 1.79234e+00  5.37534e-01 -1.64985e-01  1.12594e+00  4.19165e-01
21Feb12_165027|   1.00815e+00 -1.24029e+00  8.99015e-02  5.04534e-01  1.04688e+00
21Feb12_165027|  -1.85983e+00 -6.28367e-01  1.44747e+00 -7.70927e-01 -6.80962e-02]
21Feb12_165027| [-6.11685e-01  5.81244e-01 -2.00813e+00  4.40980e-01  1.17081e+00
21Feb12_165027|   4.53617e-02 -1.02732e-01 -5.30344e-01 -2.30272e-01 -2.75712e-01
21Feb12_165027|  -1.35628e+00  6.77073e-01  1.18206e+00 -9.68516e-01  8.88227e-01]
21Feb12_165027| [ 3.39330e-01  1.85906e-01  3.17199e+00 -1.14941e+00  8.41043e-01
21Feb12_165027|   1.43171e+00  2.91815e-01  9.90040e-01  2.43151e-01 -4.20123e-01
21Feb12_165027|  -7.71009e-01  8.26689e-01 -2.38729e-01  2.25124e-01  4.71938e-02]
21Feb12_165027| [-1.24769e+00 -1.74352e-01  1.33159e+00  6.31103e-01  1.39801e-01
21Feb12_165027|  -1.97232e-01  1.00881e+00 -1.05164e+00 -1.26316e-01 -6.77330e-01
21Feb12_165027|   6.93223e-01  3.09964e-01  4.46448e-01  3.28001e-01 -7.51083e-01]
21Feb12_165027| [-7.55157e-01 -1.20070e+00  1.18128e+00  2.31557e-01 -5.77142e-01
21Feb12_165027|   8.50621e-01 -6.80691e-01  1.14562e+00  6.53826e-01 -1.28380e+00
21Feb12_165027|   4.15503e-02  9.67591e-01 -3.56690e+00 -2.80446e-01 -2.39691e-01]
21Feb12_165027| [ 1.43065e+00  4.89999e-01  7.08940e-01  9.80815e-01 -5.25905e-01
21Feb12_165027|   8.92854e-01 -1.47577e+00 -9.27641e-02 -3.34619e-01 -1.41270e+00
21Feb12_165027|  -1.10591e+00  1.59163e+00  2.61333e-01 -1.48185e+00 -2.14182e+00]
21Feb12_165027| [ 8.38600e-01 -8.88508e-01 -4.12187e-01 -1.04812e-01  3.26908e-01
21Feb12_165027|  -9.83693e-01  1.67864e+00  7.72612e-01  1.95026e+00  9.57917e-01
21Feb12_165027|  -1.48928e+00 -1.99797e-01 -3.05136e-01 -1.14633e-01 -1.04672e+00]]
21Feb12_165027|-- Bias --
21Feb12_165027|[ 0.73695 -0.51772  1.29843 -0.86449  0.54318  0.17660 -0.21569  0.35471
21Feb12_165027| -0.23531 -0.15791  1.04286  0.77391 -0.11794  1.01790  0.50375]
21Feb12_165027|Layer 1:
21Feb12_165027|-- Config --
21Feb12_165027|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 15], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_165027|-- Weights --
21Feb12_165027|[[ 0.70443 -1.08724]
21Feb12_165027| [-0.44561 -1.05050]
21Feb12_165027| [ 0.25488  0.31427]
21Feb12_165027| [-1.40193  0.84859]
21Feb12_165027| [ 0.27127 -0.15942]
21Feb12_165027| [-0.18528 -0.14003]
21Feb12_165027| [ 1.68717  0.30442]
21Feb12_165027| [-0.01440  0.47743]
21Feb12_165027| [ 0.46612  0.57491]
21Feb12_165027| [-1.91613 -0.31596]
21Feb12_165027| [ 1.38318 -0.97860]
21Feb12_165027| [-0.49568  0.13334]
21Feb12_165027| [ 0.67487 -1.08400]
21Feb12_165027| [ 1.22898  1.13422]
21Feb12_165027| [ 0.14442 -0.69100]]
21Feb12_165027|-- Bias --
21Feb12_165027|[ 1.12271 -0.02168]
21Feb12_165027|Predicting the validation and test data with the Best final individual.
21Feb12_165034| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_165034|-----------  ------------------  --------------------  ----------
21Feb12_165034|Validation         41.91                  15            0.00517
21Feb12_165034|   Test            36.66                  15            0.00297
21Feb12_165034|-------------------- Test #2 --------------------
21Feb12_165034|Best final individual weights
21Feb12_165034|Individual:
21Feb12_165034|-- Constant hidden layers --
21Feb12_165034|False
21Feb12_165034|Layer 0:
21Feb12_165034|-- Config --
21Feb12_165034|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 15, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_165034|-- Weights --
21Feb12_165034|[[ 5.09617e-01  8.20902e-01 -3.02367e-01 -9.64837e-01 -4.33824e-01
21Feb12_165034|  -2.42034e-01 -5.04343e-01  1.31689e+00  9.21850e-01  5.13818e-01
21Feb12_165034|  -3.49854e-01  2.15852e-01 -1.04928e+00  7.68905e-01 -1.88324e+00]
21Feb12_165034| [-7.50915e-01 -2.52628e+00  3.69383e-01  1.39331e-01 -4.71230e-01
21Feb12_165034|   2.50267e+00 -2.55477e-01 -5.15419e-01 -2.31831e-01 -1.16548e+00
21Feb12_165034|  -8.22133e-01  4.82232e-01 -1.26500e+00  7.69663e-01  1.16647e+00]
21Feb12_165034| [ 4.01389e-03  9.01850e-01 -4.38696e-01 -7.91041e-01 -3.45664e-01
21Feb12_165034|  -1.66871e+00  1.65396e+00  7.90223e-01  5.51123e-01  1.67606e-01
21Feb12_165034|   2.12442e-01  1.14271e+00  6.42674e-01  2.00899e-01 -2.05944e-01]
21Feb12_165034| [ 1.80619e-01 -2.50060e-01 -1.12859e+00  1.83522e+00  1.81374e+00
21Feb12_165034|  -1.42416e+00  5.22823e-01 -7.02013e-01  1.84516e+00  1.90809e+00
21Feb12_165034|   1.37151e+00  4.03871e-02  4.29238e-01 -2.37117e-01 -1.00132e+00]
21Feb12_165034| [ 4.39871e-01  3.98574e-01 -3.75109e-01 -8.64825e-01  4.06425e-01
21Feb12_165034|   5.56500e-01  1.44148e+00 -5.22177e-01 -7.21740e-01  3.07682e-01
21Feb12_165034|  -9.52454e-01  8.44086e-01  1.09295e+00 -3.90444e-01  1.33545e+00]
21Feb12_165034| [-1.42180e+00  3.85641e-01 -8.43471e-02  1.81738e-02 -1.14521e+00
21Feb12_165034|  -8.06111e-01 -8.15090e-01  7.76165e-02  1.02784e+00  1.02123e-01
21Feb12_165034|   7.08213e-01  9.96943e-01 -7.79890e-01  1.66778e+00 -6.05761e-01]
21Feb12_165034| [-2.52774e-01 -9.61820e-01  3.02997e+00 -4.75355e-02  9.27908e-01
21Feb12_165034|   6.12327e-01 -4.65796e-01  8.85447e-01 -9.19731e-02  5.35502e-02
21Feb12_165034|  -5.61515e-01  1.22163e+00 -6.55581e-02 -4.23284e-01  6.78889e-01]
21Feb12_165034| [-4.07954e-01  7.89564e-01 -1.02275e+00 -1.42852e-01 -1.21182e-01
21Feb12_165034|   2.60288e+00  1.31219e+00 -1.05105e+00 -7.28076e-01  7.37981e-01
21Feb12_165034|   1.07877e+00  4.12772e-01  3.20972e-01 -1.42903e+00  5.49771e-01]
21Feb12_165034| [-1.06598e+00  4.11763e-01 -5.98736e-01 -1.02922e+00  1.44690e+00
21Feb12_165034|   1.61847e+00  7.86271e-01 -1.04439e+00 -1.22083e+00 -5.20594e-01
21Feb12_165034|   1.50709e+00 -2.76750e-01 -9.31489e-01  1.18032e+00 -1.34476e+00]
21Feb12_165034| [-9.84737e-01 -5.97909e-01 -5.05735e-01  1.21453e+00  2.04300e+00
21Feb12_165034|  -1.80226e+00  2.27960e-01  2.48235e-01 -9.14083e-01 -8.19925e-01
21Feb12_165034|   8.79325e-03  1.89321e+00 -2.33314e+00  3.64489e-01 -8.65853e-01]
21Feb12_165034| [-5.52147e-01 -1.09026e+00 -6.31263e-01 -9.85456e-02 -1.26793e+00
21Feb12_165034|   6.92239e-01  4.07591e-03  8.28704e-02 -4.61769e-01  1.47380e+00
21Feb12_165034|  -8.25050e-01  1.85307e+00 -7.02559e-01  4.42800e-01 -5.09351e-01]
21Feb12_165034| [-1.22241e+00 -2.82164e+00 -3.49419e-01  2.35780e-01 -3.06882e-01
21Feb12_165034|   4.97633e-01 -8.59745e-01  1.41005e+00  4.44223e-01  4.80295e-01
21Feb12_165034|   5.28514e-01 -8.52095e-01  7.93638e-01 -1.18061e+00  3.77575e-01]
21Feb12_165034| [ 1.83848e+00  1.86747e+00 -6.09064e-01 -1.29117e-01  8.20239e-01
21Feb12_165034|  -8.41223e-01 -4.91994e-01 -4.35134e-02 -3.10526e-01  8.12742e-01
21Feb12_165034|  -2.48499e+00  6.10492e-01  2.59825e-01  1.10740e+00  2.25110e-01]
21Feb12_165034| [-9.61110e-02  1.17814e+00  1.12148e-01 -3.49813e-01  2.43858e+00
21Feb12_165034|  -1.38613e+00 -3.82927e-01  1.52932e+00  8.48623e-01 -1.99483e+00
21Feb12_165034|  -2.12240e+00  1.06312e+00 -3.90781e-02  1.49640e+00  1.12926e+00]
21Feb12_165034| [-4.30616e-01  2.39031e-01 -7.23476e-01  1.25568e+00 -2.14845e-01
21Feb12_165034|  -5.53173e-01 -2.65699e+00  2.69230e-02 -1.00392e+00  1.32765e-01
21Feb12_165034|  -5.64005e-01  1.22524e+00  1.24383e+00 -1.09592e+00 -1.41796e+00]
21Feb12_165034| [-2.39791e-01  1.53064e+00  3.01720e-01  2.78106e-01 -1.84792e-01
21Feb12_165034|   1.56208e+00  9.94463e-01 -1.63904e+00  6.63295e-01 -1.85188e+00
21Feb12_165034|  -7.33287e-01 -1.62705e-01 -9.61094e-01  4.14256e-01 -1.81088e+00]
21Feb12_165034| [ 2.83794e-01  7.82624e-01  8.22930e-01  1.38834e+00  1.35777e+00
21Feb12_165034|   1.13137e+00 -4.51094e-01 -9.14736e-02 -4.29153e-01 -1.32003e-01
21Feb12_165034|  -1.06833e+00 -3.60741e-02 -1.72337e+00 -9.36812e-02 -1.50919e-01]
21Feb12_165034| [ 4.60832e-01 -6.41447e-01  7.19778e-01  1.43690e+00 -5.39012e-01
21Feb12_165034|   2.73839e+00  4.18203e-02  1.12728e+00 -1.96359e+00  5.08015e-01
21Feb12_165034|  -3.94637e-02  1.21425e+00  7.81562e-01  1.21240e+00  8.71932e-02]
21Feb12_165034| [ 7.21067e-01 -4.05470e-01  4.30706e-01 -1.12406e+00 -1.66416e-01
21Feb12_165034|  -1.74613e-01 -2.82475e+00  7.83187e-01 -1.70599e+00 -4.53800e-01
21Feb12_165034|   7.68700e-02  1.38626e+00  4.71260e-01 -1.20854e-01 -3.85957e-01]
21Feb12_165034| [-1.45393e+00 -4.35386e-01  7.35002e-01 -1.05813e+00 -6.41567e-01
21Feb12_165034|  -1.23953e+00 -1.11174e+00 -4.33161e-01  1.71285e+00 -1.69152e+00
21Feb12_165034|  -3.94477e-01 -9.64481e-01  2.12241e-01 -4.51296e-01  6.12573e-01]
21Feb12_165034| [ 1.91178e+00 -7.20020e-01 -1.43347e+00  6.16597e-01 -1.40631e-01
21Feb12_165034|   9.60419e-01 -2.94601e-01 -3.70235e-01  1.68500e-03 -7.06077e-02
21Feb12_165034|  -2.63686e+00 -7.93469e-01  3.46275e-01  2.04211e+00  9.19580e-01]
21Feb12_165034| [ 2.28690e-01 -1.52406e-01 -4.49362e-01 -7.32180e-01  7.99781e-01
21Feb12_165034|   4.88373e-01 -9.34696e-01 -5.02242e-01  9.68074e-01 -3.07760e-01
21Feb12_165034|  -3.49720e-01 -2.00695e+00 -4.45838e-01  2.62312e-01  3.38818e-01]
21Feb12_165034| [-1.98557e-01  8.34883e-01 -1.61905e-01  1.28379e+00  1.04073e+00
21Feb12_165034|   1.45833e+00  4.77341e-01  9.87420e-01 -3.08856e-01 -1.55031e+00
21Feb12_165034|   1.38023e+00 -4.42201e-01  1.78369e+00  8.01018e-01  1.52483e+00]
21Feb12_165034| [ 1.12967e+00 -8.45423e-01  1.52345e+00  1.08801e+00 -4.32434e-01
21Feb12_165034|  -3.16741e-01 -7.17985e-02  1.09877e+00 -7.90690e-01  1.36084e+00
21Feb12_165034|  -5.66120e-01 -1.70432e+00 -2.12910e+00 -2.41374e-01  1.33636e+00]
21Feb12_165034| [-4.08205e-01 -8.03871e-01  9.13990e-01  5.00916e-01 -1.81059e-01
21Feb12_165034|   2.42621e-01 -9.57869e-01  6.74094e-01  6.52179e-01  2.77279e-01
21Feb12_165034|  -3.91051e-01 -9.05321e-02  6.86316e-01 -3.54594e-01  5.83144e-01]
21Feb12_165034| [-3.98308e-01 -4.48018e-03  1.11987e+00  1.50374e+00 -9.18129e-01
21Feb12_165034|  -1.81690e+00 -1.38223e+00 -2.74481e-01 -8.24843e-01 -7.05820e-01
21Feb12_165034|   1.50584e+00 -4.21386e-01  4.00084e-01 -7.61841e-02 -7.41767e-01]
21Feb12_165034| [ 5.51762e-01 -1.04904e+00  5.21335e-01  2.14684e-01 -8.21795e-02
21Feb12_165034|   3.68556e-01  1.01222e+00 -1.30634e+00 -1.52652e+00  9.98379e-01
21Feb12_165034|   8.51997e-01 -9.42775e-01 -1.16577e-01  3.64988e-01 -1.27419e+00]
21Feb12_165034| [ 1.67425e+00 -1.27190e-01  2.44775e+00  1.44302e+00 -4.43112e-01
21Feb12_165034|  -4.07317e-02  1.33875e-01  4.92876e-01  1.36327e+00  3.41424e-01
21Feb12_165034|   1.70937e+00 -2.26414e+00  5.48087e-01 -2.49869e-01 -1.95666e+00]
21Feb12_165034| [-7.77069e-01  1.76839e+00 -5.99460e-01 -2.13769e+00  1.38006e+00
21Feb12_165034|   1.30623e+00 -1.06865e+00 -1.16462e+00  8.02528e-01 -3.99780e-01
21Feb12_165034|   8.20611e-01 -1.64613e-01  3.17174e-01  1.50755e+00  1.82851e-01]
21Feb12_165034| [-1.02989e+00 -1.07499e+00 -1.93091e+00  4.66271e-01 -8.74190e-01
21Feb12_165034|  -1.32185e+00 -9.08286e-01 -8.46363e-01  2.03651e-01 -2.52017e-01
21Feb12_165034|   1.15748e+00 -3.29038e-01 -5.53034e-01  6.31862e-01 -9.38469e-02]
21Feb12_165034| [-1.07650e+00  2.26383e-01  1.43406e-01 -1.04859e+00 -1.13255e+00
21Feb12_165034|   5.32942e-01 -2.81361e-01  1.06039e+00 -4.84886e-01  1.81779e+00
21Feb12_165034|   4.45898e-01  1.15599e-01  2.22637e+00 -1.10477e+00 -7.41273e-01]
21Feb12_165034| [ 5.36190e-01  1.36053e+00  1.86442e-01  1.76821e-01  1.73842e+00
21Feb12_165034|   1.33653e-01 -2.69435e-01  1.42842e+00 -6.67924e-01  8.34192e-01
21Feb12_165034|  -4.93949e-01  2.55190e-01  8.44813e-02  1.07023e+00  3.32795e-01]
21Feb12_165034| [-7.77858e-01  6.91255e-01 -2.00094e-01 -3.47804e-02  1.25963e+00
21Feb12_165034|   2.88406e-01  1.11181e-02 -1.72072e-01  1.74171e-01  1.07767e+00
21Feb12_165034|  -7.57539e-01 -1.51881e+00  1.13432e+00 -8.19687e-01  2.51036e-01]
21Feb12_165034| [ 1.17877e+00  8.51361e-01  5.34249e-01 -3.85201e-01  1.62741e+00
21Feb12_165034|   7.14108e-01 -2.49586e-01 -1.51061e+00 -5.78471e-01 -1.53573e+00
21Feb12_165034|  -6.82580e-01 -1.03046e+00  2.14369e+00 -2.12686e+00  2.93875e-01]
21Feb12_165034| [-5.46699e-01 -1.24367e-01  1.50400e+00  5.24570e-01  1.32199e-01
21Feb12_165034|  -1.11873e+00 -1.21781e-01  1.60716e+00  7.94494e-01  4.12000e-02
21Feb12_165034|  -1.45629e-01 -1.67069e+00  1.55359e+00  1.27490e+00  3.78250e-01]
21Feb12_165034| [-1.65770e+00  7.63010e-01 -1.07032e-01 -1.29077e+00 -2.72523e-01
21Feb12_165034|   8.86152e-01  2.03137e-02  1.07244e+00 -2.07611e+00  1.79718e-01
21Feb12_165034|   1.81554e-01 -6.15758e-01 -9.51774e-01  1.02939e+00  8.17973e-01]
21Feb12_165034| [ 9.21545e-01 -8.71244e-02 -1.53454e+00 -1.66686e+00  9.25583e-02
21Feb12_165034|   5.45788e-01  9.00588e-01  5.39148e-01  1.73423e+00  5.95858e-01
21Feb12_165034|   7.60598e-01  7.10163e-01 -1.92447e-01 -2.18648e-01 -1.06613e-01]
21Feb12_165034| [-1.27156e+00  1.50471e-01 -1.51367e+00  2.43159e-01  1.45374e+00
21Feb12_165034|   1.39069e-01  1.63857e+00  7.76127e-01  1.22775e-01 -9.15383e-01
21Feb12_165034|  -7.88206e-01 -1.88443e-01  5.88849e-01 -1.15889e+00  1.57532e+00]
21Feb12_165034| [-7.87307e-01  7.90368e-01 -8.23463e-01 -7.31497e-01 -1.23567e+00
21Feb12_165034|   4.22757e-01  3.63316e-02  6.01964e-01  1.96999e+00 -1.17414e+00
21Feb12_165034|   3.97797e-01 -1.08808e+00 -5.94358e-01 -2.83672e-01  8.50566e-01]
21Feb12_165034| [ 5.30769e-01 -1.84801e+00 -5.66134e-01  6.76585e-02  1.10136e-01
21Feb12_165034|   4.92367e-01 -4.90997e-01  6.06677e-01  2.28381e+00 -4.07746e-02
21Feb12_165034|   1.15850e+00 -5.98080e-01 -7.01578e-01  1.01957e+00  2.49859e-01]
21Feb12_165034| [-8.63352e-01  1.10102e+00 -1.35284e+00  7.44546e-01  1.23832e+00
21Feb12_165034|  -5.46095e-01 -7.14545e-01  6.39714e-01 -1.05446e-01 -8.88602e-01
21Feb12_165034|   9.93232e-01  1.94862e+00 -4.16105e-01  1.03489e-01  1.11977e+00]
21Feb12_165034| [ 1.19516e+00 -1.76346e-01  1.04128e-01  1.20697e+00 -9.23981e-01
21Feb12_165034|  -1.33787e+00 -2.81645e-01  4.54001e-01  1.13838e-01  7.67530e-01
21Feb12_165034|  -1.19224e+00 -1.30105e-01 -1.91934e-01  4.19944e-01  1.69825e-01]
21Feb12_165034| [ 7.65088e-01 -1.94246e+00 -7.11338e-01  4.53958e-01  1.94201e+00
21Feb12_165034|   1.31030e+00 -2.96434e-02 -1.76407e+00  5.53828e-01  6.85560e-01
21Feb12_165034|   7.66333e-01  3.82096e-02 -8.16458e-01 -6.24116e-02  2.64193e-01]
21Feb12_165034| [ 3.18200e-01  2.29948e+00  1.64715e+00  1.62897e+00 -7.51376e-02
21Feb12_165034|  -1.28841e+00 -6.20669e-01 -1.11166e-01  8.60402e-01 -1.33019e+00
21Feb12_165034|  -5.96012e-01  1.43903e+00  4.95090e-01 -5.77593e-01  1.44906e+00]
21Feb12_165034| [ 4.11040e-01  7.04946e-01 -5.20407e-01  1.19926e-01 -2.14187e-01
21Feb12_165034|   2.61836e-01 -2.06690e-01 -5.23044e-01 -2.21768e+00 -1.84159e+00
21Feb12_165034|   1.07890e-01 -1.21571e+00  1.41906e-02 -1.18878e+00 -1.10586e+00]
21Feb12_165034| [ 7.47110e-04 -2.19367e-01  1.24132e+00  2.42981e-01  1.64975e+00
21Feb12_165034|  -7.56681e-01  2.05047e+00  1.41699e+00  2.11413e-01  2.05856e-01
21Feb12_165034|  -1.19536e+00 -1.17721e+00 -5.74572e-02 -9.88771e-01 -5.21745e-02]
21Feb12_165034| [ 8.41039e-01 -7.80210e-01  1.63153e-01  9.11562e-01  1.96584e+00
21Feb12_165034|   1.78291e+00  1.27725e-01  9.24125e-01  8.89095e-01  8.02583e-01
21Feb12_165034|  -1.84072e-01 -1.83956e+00 -1.02407e+00  6.97260e-01  2.04119e+00]
21Feb12_165034| [ 1.02325e+00 -1.14512e+00  1.53735e+00 -1.20875e+00  2.40349e-01
21Feb12_165034|   3.65149e-01 -8.45853e-01 -9.53877e-01  1.08881e+00  1.31369e+00
21Feb12_165034|  -8.73629e-01  3.54768e-01 -1.44120e+00  3.00774e+00  5.37138e-01]
21Feb12_165034| [ 1.21153e+00  1.33780e+00  2.37346e-01  1.10192e+00 -7.71109e-01
21Feb12_165034|  -1.67297e+00 -9.85041e-01 -9.67469e-02  1.35584e-01  1.43828e+00
21Feb12_165034|  -5.37772e-01  6.81867e-01  8.99423e-02 -3.00140e-01  7.40803e-01]
21Feb12_165034| [-1.53912e-01 -1.45545e+00 -8.51719e-01 -3.24207e-01 -1.85297e+00
21Feb12_165034|  -1.37632e+00  2.56265e+00 -1.51591e+00 -7.70917e-01  1.60742e+00
21Feb12_165034|   8.19418e-01  1.51279e+00 -7.75504e-01 -4.56317e-01  7.93313e-01]
21Feb12_165034| [ 1.79234e+00  5.37534e-01 -1.64985e-01  1.12594e+00  4.19165e-01
21Feb12_165034|   1.00815e+00 -1.24029e+00  8.99015e-02  5.04534e-01  1.04688e+00
21Feb12_165034|  -1.85983e+00 -6.28367e-01  1.44747e+00 -7.70927e-01 -6.80962e-02]
21Feb12_165034| [-6.11685e-01  5.81244e-01 -2.00813e+00  4.40980e-01  1.17081e+00
21Feb12_165034|   4.53617e-02 -1.02732e-01 -5.30344e-01 -2.30272e-01 -2.75712e-01
21Feb12_165034|  -1.35628e+00  6.77073e-01  1.18206e+00 -9.68516e-01  8.88227e-01]
21Feb12_165034| [ 3.39330e-01  1.85906e-01  3.17199e+00 -1.14941e+00  8.41043e-01
21Feb12_165034|   1.43171e+00  2.91815e-01  9.90040e-01  2.43151e-01 -4.20123e-01
21Feb12_165034|  -7.71009e-01  8.26689e-01 -2.38729e-01  2.25124e-01  4.71938e-02]
21Feb12_165034| [-1.24769e+00 -1.74352e-01  1.33159e+00  6.31103e-01  1.39801e-01
21Feb12_165034|  -1.97232e-01  1.00881e+00 -1.05164e+00 -1.26316e-01 -6.77330e-01
21Feb12_165034|   6.93223e-01  3.09964e-01  4.46448e-01  3.28001e-01 -7.51083e-01]
21Feb12_165034| [-7.55157e-01 -1.20070e+00  1.18128e+00  2.31557e-01 -5.77142e-01
21Feb12_165034|   8.50621e-01 -6.80691e-01  1.14562e+00  6.53826e-01 -1.28380e+00
21Feb12_165034|   4.15503e-02  9.67591e-01 -3.56690e+00 -2.80446e-01 -2.39691e-01]
21Feb12_165034| [ 1.43065e+00  4.89999e-01  7.08940e-01  9.80815e-01 -5.25905e-01
21Feb12_165034|   8.92854e-01 -1.47577e+00 -9.27641e-02 -3.34619e-01 -1.41270e+00
21Feb12_165034|  -1.10591e+00  1.59163e+00  2.61333e-01 -1.48185e+00 -2.14182e+00]
21Feb12_165034| [ 8.38600e-01 -8.88508e-01 -4.12187e-01 -1.04812e-01  3.26908e-01
21Feb12_165034|  -9.83693e-01  1.67864e+00  7.72612e-01  1.95026e+00  9.57917e-01
21Feb12_165034|  -1.48928e+00 -1.99797e-01 -3.05136e-01 -1.14633e-01 -1.04672e+00]]
21Feb12_165034|-- Bias --
21Feb12_165034|[ 0.73695 -0.51772  1.29843 -0.86449  0.54318  0.17660 -0.21569  0.35471
21Feb12_165034| -0.23531 -0.15791  1.04286  0.77391 -0.11794  1.01790  0.50375]
21Feb12_165034|Layer 1:
21Feb12_165034|-- Config --
21Feb12_165034|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 15], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_165034|-- Weights --
21Feb12_165034|[[ 0.70443 -1.08724]
21Feb12_165034| [-0.44561 -1.05050]
21Feb12_165034| [ 0.25488  0.31427]
21Feb12_165034| [-1.40193  0.84859]
21Feb12_165034| [ 0.27127 -0.15942]
21Feb12_165034| [-0.18528 -0.14003]
21Feb12_165034| [ 1.68717  0.30442]
21Feb12_165034| [-0.01440  0.47743]
21Feb12_165034| [ 0.46612  0.57491]
21Feb12_165034| [-1.91613 -0.31596]
21Feb12_165034| [ 1.38318 -0.97860]
21Feb12_165034| [-0.49568  0.13334]
21Feb12_165034| [ 0.67487 -1.08400]
21Feb12_165034| [ 1.22898  1.13422]
21Feb12_165034| [ 0.14442 -0.69100]]
21Feb12_165034|-- Bias --
21Feb12_165034|[ 1.12271 -0.02168]
21Feb12_165034|Predicting the validation and test data with the Best final individual.
21Feb12_165041| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_165041|-----------  ------------------  --------------------  ----------
21Feb12_165041|Validation         41.39                  15            0.02571
21Feb12_165041|   Test            36.75                  15            0.00297
21Feb12_165041|-------------------- Test #3 --------------------
21Feb12_165041|Best final individual weights
21Feb12_165041|Individual:
21Feb12_165041|-- Constant hidden layers --
21Feb12_165041|False
21Feb12_165041|Layer 0:
21Feb12_165041|-- Config --
21Feb12_165041|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 15, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_165041|-- Weights --
21Feb12_165041|[[ 5.09617e-01  8.20902e-01 -3.02367e-01 -9.64837e-01 -4.33824e-01
21Feb12_165041|  -2.42034e-01 -5.04343e-01  1.31689e+00  9.21850e-01  5.13818e-01
21Feb12_165041|  -3.49854e-01  2.15852e-01 -1.04928e+00  7.68905e-01 -1.88324e+00]
21Feb12_165041| [-7.50915e-01 -2.52628e+00  3.69383e-01  1.39331e-01 -4.71230e-01
21Feb12_165041|   2.50267e+00 -2.55477e-01 -5.15419e-01 -2.31831e-01 -1.16548e+00
21Feb12_165041|  -8.22133e-01  4.82232e-01 -1.26500e+00  7.69663e-01  1.16647e+00]
21Feb12_165041| [ 4.01389e-03  9.01850e-01 -4.38696e-01 -7.91041e-01 -3.45664e-01
21Feb12_165041|  -1.66871e+00  1.65396e+00  7.90223e-01  5.51123e-01  1.67606e-01
21Feb12_165041|   2.12442e-01  1.14271e+00  6.42674e-01  2.00899e-01 -2.05944e-01]
21Feb12_165041| [ 1.80619e-01 -2.50060e-01 -1.12859e+00  1.83522e+00  1.81374e+00
21Feb12_165041|  -1.42416e+00  5.22823e-01 -7.02013e-01  1.84516e+00  1.90809e+00
21Feb12_165041|   1.37151e+00  4.03871e-02  4.29238e-01 -2.37117e-01 -1.00132e+00]
21Feb12_165041| [ 4.39871e-01  3.98574e-01 -3.75109e-01 -8.64825e-01  4.06425e-01
21Feb12_165041|   5.56500e-01  1.44148e+00 -5.22177e-01 -7.21740e-01  3.07682e-01
21Feb12_165041|  -9.52454e-01  8.44086e-01  1.09295e+00 -3.90444e-01  1.33545e+00]
21Feb12_165041| [-1.42180e+00  3.85641e-01 -8.43471e-02  1.81738e-02 -1.14521e+00
21Feb12_165041|  -8.06111e-01 -8.15090e-01  7.76165e-02  1.02784e+00  1.02123e-01
21Feb12_165041|   7.08213e-01  9.96943e-01 -7.79890e-01  1.66778e+00 -6.05761e-01]
21Feb12_165041| [-2.52774e-01 -9.61820e-01  3.02997e+00 -4.75355e-02  9.27908e-01
21Feb12_165041|   6.12327e-01 -4.65796e-01  8.85447e-01 -9.19731e-02  5.35502e-02
21Feb12_165041|  -5.61515e-01  1.22163e+00 -6.55581e-02 -4.23284e-01  6.78889e-01]
21Feb12_165041| [-4.07954e-01  7.89564e-01 -1.02275e+00 -1.42852e-01 -1.21182e-01
21Feb12_165041|   2.60288e+00  1.31219e+00 -1.05105e+00 -7.28076e-01  7.37981e-01
21Feb12_165041|   1.07877e+00  4.12772e-01  3.20972e-01 -1.42903e+00  5.49771e-01]
21Feb12_165041| [-1.06598e+00  4.11763e-01 -5.98736e-01 -1.02922e+00  1.44690e+00
21Feb12_165041|   1.61847e+00  7.86271e-01 -1.04439e+00 -1.22083e+00 -5.20594e-01
21Feb12_165041|   1.50709e+00 -2.76750e-01 -9.31489e-01  1.18032e+00 -1.34476e+00]
21Feb12_165041| [-9.84737e-01 -5.97909e-01 -5.05735e-01  1.21453e+00  2.04300e+00
21Feb12_165041|  -1.80226e+00  2.27960e-01  2.48235e-01 -9.14083e-01 -8.19925e-01
21Feb12_165041|   8.79325e-03  1.89321e+00 -2.33314e+00  3.64489e-01 -8.65853e-01]
21Feb12_165041| [-5.52147e-01 -1.09026e+00 -6.31263e-01 -9.85456e-02 -1.26793e+00
21Feb12_165041|   6.92239e-01  4.07591e-03  8.28704e-02 -4.61769e-01  1.47380e+00
21Feb12_165041|  -8.25050e-01  1.85307e+00 -7.02559e-01  4.42800e-01 -5.09351e-01]
21Feb12_165041| [-1.22241e+00 -2.82164e+00 -3.49419e-01  2.35780e-01 -3.06882e-01
21Feb12_165041|   4.97633e-01 -8.59745e-01  1.41005e+00  4.44223e-01  4.80295e-01
21Feb12_165041|   5.28514e-01 -8.52095e-01  7.93638e-01 -1.18061e+00  3.77575e-01]
21Feb12_165041| [ 1.83848e+00  1.86747e+00 -6.09064e-01 -1.29117e-01  8.20239e-01
21Feb12_165041|  -8.41223e-01 -4.91994e-01 -4.35134e-02 -3.10526e-01  8.12742e-01
21Feb12_165041|  -2.48499e+00  6.10492e-01  2.59825e-01  1.10740e+00  2.25110e-01]
21Feb12_165041| [-9.61110e-02  1.17814e+00  1.12148e-01 -3.49813e-01  2.43858e+00
21Feb12_165041|  -1.38613e+00 -3.82927e-01  1.52932e+00  8.48623e-01 -1.99483e+00
21Feb12_165041|  -2.12240e+00  1.06312e+00 -3.90781e-02  1.49640e+00  1.12926e+00]
21Feb12_165041| [-4.30616e-01  2.39031e-01 -7.23476e-01  1.25568e+00 -2.14845e-01
21Feb12_165041|  -5.53173e-01 -2.65699e+00  2.69230e-02 -1.00392e+00  1.32765e-01
21Feb12_165041|  -5.64005e-01  1.22524e+00  1.24383e+00 -1.09592e+00 -1.41796e+00]
21Feb12_165041| [-2.39791e-01  1.53064e+00  3.01720e-01  2.78106e-01 -1.84792e-01
21Feb12_165041|   1.56208e+00  9.94463e-01 -1.63904e+00  6.63295e-01 -1.85188e+00
21Feb12_165041|  -7.33287e-01 -1.62705e-01 -9.61094e-01  4.14256e-01 -1.81088e+00]
21Feb12_165041| [ 2.83794e-01  7.82624e-01  8.22930e-01  1.38834e+00  1.35777e+00
21Feb12_165041|   1.13137e+00 -4.51094e-01 -9.14736e-02 -4.29153e-01 -1.32003e-01
21Feb12_165041|  -1.06833e+00 -3.60741e-02 -1.72337e+00 -9.36812e-02 -1.50919e-01]
21Feb12_165041| [ 4.60832e-01 -6.41447e-01  7.19778e-01  1.43690e+00 -5.39012e-01
21Feb12_165041|   2.73839e+00  4.18203e-02  1.12728e+00 -1.96359e+00  5.08015e-01
21Feb12_165041|  -3.94637e-02  1.21425e+00  7.81562e-01  1.21240e+00  8.71932e-02]
21Feb12_165041| [ 7.21067e-01 -4.05470e-01  4.30706e-01 -1.12406e+00 -1.66416e-01
21Feb12_165041|  -1.74613e-01 -2.82475e+00  7.83187e-01 -1.70599e+00 -4.53800e-01
21Feb12_165041|   7.68700e-02  1.38626e+00  4.71260e-01 -1.20854e-01 -3.85957e-01]
21Feb12_165041| [-1.45393e+00 -4.35386e-01  7.35002e-01 -1.05813e+00 -6.41567e-01
21Feb12_165041|  -1.23953e+00 -1.11174e+00 -4.33161e-01  1.71285e+00 -1.69152e+00
21Feb12_165041|  -3.94477e-01 -9.64481e-01  2.12241e-01 -4.51296e-01  6.12573e-01]
21Feb12_165041| [ 1.91178e+00 -7.20020e-01 -1.43347e+00  6.16597e-01 -1.40631e-01
21Feb12_165041|   9.60419e-01 -2.94601e-01 -3.70235e-01  1.68500e-03 -7.06077e-02
21Feb12_165041|  -2.63686e+00 -7.93469e-01  3.46275e-01  2.04211e+00  9.19580e-01]
21Feb12_165041| [ 2.28690e-01 -1.52406e-01 -4.49362e-01 -7.32180e-01  7.99781e-01
21Feb12_165041|   4.88373e-01 -9.34696e-01 -5.02242e-01  9.68074e-01 -3.07760e-01
21Feb12_165041|  -3.49720e-01 -2.00695e+00 -4.45838e-01  2.62312e-01  3.38818e-01]
21Feb12_165041| [-1.98557e-01  8.34883e-01 -1.61905e-01  1.28379e+00  1.04073e+00
21Feb12_165041|   1.45833e+00  4.77341e-01  9.87420e-01 -3.08856e-01 -1.55031e+00
21Feb12_165041|   1.38023e+00 -4.42201e-01  1.78369e+00  8.01018e-01  1.52483e+00]
21Feb12_165041| [ 1.12967e+00 -8.45423e-01  1.52345e+00  1.08801e+00 -4.32434e-01
21Feb12_165041|  -3.16741e-01 -7.17985e-02  1.09877e+00 -7.90690e-01  1.36084e+00
21Feb12_165041|  -5.66120e-01 -1.70432e+00 -2.12910e+00 -2.41374e-01  1.33636e+00]
21Feb12_165041| [-4.08205e-01 -8.03871e-01  9.13990e-01  5.00916e-01 -1.81059e-01
21Feb12_165041|   2.42621e-01 -9.57869e-01  6.74094e-01  6.52179e-01  2.77279e-01
21Feb12_165041|  -3.91051e-01 -9.05321e-02  6.86316e-01 -3.54594e-01  5.83144e-01]
21Feb12_165041| [-3.98308e-01 -4.48018e-03  1.11987e+00  1.50374e+00 -9.18129e-01
21Feb12_165041|  -1.81690e+00 -1.38223e+00 -2.74481e-01 -8.24843e-01 -7.05820e-01
21Feb12_165041|   1.50584e+00 -4.21386e-01  4.00084e-01 -7.61841e-02 -7.41767e-01]
21Feb12_165041| [ 5.51762e-01 -1.04904e+00  5.21335e-01  2.14684e-01 -8.21795e-02
21Feb12_165041|   3.68556e-01  1.01222e+00 -1.30634e+00 -1.52652e+00  9.98379e-01
21Feb12_165041|   8.51997e-01 -9.42775e-01 -1.16577e-01  3.64988e-01 -1.27419e+00]
21Feb12_165041| [ 1.67425e+00 -1.27190e-01  2.44775e+00  1.44302e+00 -4.43112e-01
21Feb12_165041|  -4.07317e-02  1.33875e-01  4.92876e-01  1.36327e+00  3.41424e-01
21Feb12_165041|   1.70937e+00 -2.26414e+00  5.48087e-01 -2.49869e-01 -1.95666e+00]
21Feb12_165041| [-7.77069e-01  1.76839e+00 -5.99460e-01 -2.13769e+00  1.38006e+00
21Feb12_165041|   1.30623e+00 -1.06865e+00 -1.16462e+00  8.02528e-01 -3.99780e-01
21Feb12_165041|   8.20611e-01 -1.64613e-01  3.17174e-01  1.50755e+00  1.82851e-01]
21Feb12_165041| [-1.02989e+00 -1.07499e+00 -1.93091e+00  4.66271e-01 -8.74190e-01
21Feb12_165041|  -1.32185e+00 -9.08286e-01 -8.46363e-01  2.03651e-01 -2.52017e-01
21Feb12_165041|   1.15748e+00 -3.29038e-01 -5.53034e-01  6.31862e-01 -9.38469e-02]
21Feb12_165041| [-1.07650e+00  2.26383e-01  1.43406e-01 -1.04859e+00 -1.13255e+00
21Feb12_165041|   5.32942e-01 -2.81361e-01  1.06039e+00 -4.84886e-01  1.81779e+00
21Feb12_165041|   4.45898e-01  1.15599e-01  2.22637e+00 -1.10477e+00 -7.41273e-01]
21Feb12_165041| [ 5.36190e-01  1.36053e+00  1.86442e-01  1.76821e-01  1.73842e+00
21Feb12_165041|   1.33653e-01 -2.69435e-01  1.42842e+00 -6.67924e-01  8.34192e-01
21Feb12_165041|  -4.93949e-01  2.55190e-01  8.44813e-02  1.07023e+00  3.32795e-01]
21Feb12_165041| [-7.77858e-01  6.91255e-01 -2.00094e-01 -3.47804e-02  1.25963e+00
21Feb12_165041|   2.88406e-01  1.11181e-02 -1.72072e-01  1.74171e-01  1.07767e+00
21Feb12_165041|  -7.57539e-01 -1.51881e+00  1.13432e+00 -8.19687e-01  2.51036e-01]
21Feb12_165041| [ 1.17877e+00  8.51361e-01  5.34249e-01 -3.85201e-01  1.62741e+00
21Feb12_165041|   7.14108e-01 -2.49586e-01 -1.51061e+00 -5.78471e-01 -1.53573e+00
21Feb12_165041|  -6.82580e-01 -1.03046e+00  2.14369e+00 -2.12686e+00  2.93875e-01]
21Feb12_165041| [-5.46699e-01 -1.24367e-01  1.50400e+00  5.24570e-01  1.32199e-01
21Feb12_165041|  -1.11873e+00 -1.21781e-01  1.60716e+00  7.94494e-01  4.12000e-02
21Feb12_165041|  -1.45629e-01 -1.67069e+00  1.55359e+00  1.27490e+00  3.78250e-01]
21Feb12_165041| [-1.65770e+00  7.63010e-01 -1.07032e-01 -1.29077e+00 -2.72523e-01
21Feb12_165041|   8.86152e-01  2.03137e-02  1.07244e+00 -2.07611e+00  1.79718e-01
21Feb12_165041|   1.81554e-01 -6.15758e-01 -9.51774e-01  1.02939e+00  8.17973e-01]
21Feb12_165041| [ 9.21545e-01 -8.71244e-02 -1.53454e+00 -1.66686e+00  9.25583e-02
21Feb12_165041|   5.45788e-01  9.00588e-01  5.39148e-01  1.73423e+00  5.95858e-01
21Feb12_165041|   7.60598e-01  7.10163e-01 -1.92447e-01 -2.18648e-01 -1.06613e-01]
21Feb12_165041| [-1.27156e+00  1.50471e-01 -1.51367e+00  2.43159e-01  1.45374e+00
21Feb12_165041|   1.39069e-01  1.63857e+00  7.76127e-01  1.22775e-01 -9.15383e-01
21Feb12_165041|  -7.88206e-01 -1.88443e-01  5.88849e-01 -1.15889e+00  1.57532e+00]
21Feb12_165041| [-7.87307e-01  7.90368e-01 -8.23463e-01 -7.31497e-01 -1.23567e+00
21Feb12_165041|   4.22757e-01  3.63316e-02  6.01964e-01  1.96999e+00 -1.17414e+00
21Feb12_165041|   3.97797e-01 -1.08808e+00 -5.94358e-01 -2.83672e-01  8.50566e-01]
21Feb12_165041| [ 5.30769e-01 -1.84801e+00 -5.66134e-01  6.76585e-02  1.10136e-01
21Feb12_165041|   4.92367e-01 -4.90997e-01  6.06677e-01  2.28381e+00 -4.07746e-02
21Feb12_165041|   1.15850e+00 -5.98080e-01 -7.01578e-01  1.01957e+00  2.49859e-01]
21Feb12_165041| [-8.63352e-01  1.10102e+00 -1.35284e+00  7.44546e-01  1.23832e+00
21Feb12_165041|  -5.46095e-01 -7.14545e-01  6.39714e-01 -1.05446e-01 -8.88602e-01
21Feb12_165041|   9.93232e-01  1.94862e+00 -4.16105e-01  1.03489e-01  1.11977e+00]
21Feb12_165041| [ 1.19516e+00 -1.76346e-01  1.04128e-01  1.20697e+00 -9.23981e-01
21Feb12_165041|  -1.33787e+00 -2.81645e-01  4.54001e-01  1.13838e-01  7.67530e-01
21Feb12_165041|  -1.19224e+00 -1.30105e-01 -1.91934e-01  4.19944e-01  1.69825e-01]
21Feb12_165041| [ 7.65088e-01 -1.94246e+00 -7.11338e-01  4.53958e-01  1.94201e+00
21Feb12_165041|   1.31030e+00 -2.96434e-02 -1.76407e+00  5.53828e-01  6.85560e-01
21Feb12_165041|   7.66333e-01  3.82096e-02 -8.16458e-01 -6.24116e-02  2.64193e-01]
21Feb12_165041| [ 3.18200e-01  2.29948e+00  1.64715e+00  1.62897e+00 -7.51376e-02
21Feb12_165041|  -1.28841e+00 -6.20669e-01 -1.11166e-01  8.60402e-01 -1.33019e+00
21Feb12_165041|  -5.96012e-01  1.43903e+00  4.95090e-01 -5.77593e-01  1.44906e+00]
21Feb12_165041| [ 4.11040e-01  7.04946e-01 -5.20407e-01  1.19926e-01 -2.14187e-01
21Feb12_165041|   2.61836e-01 -2.06690e-01 -5.23044e-01 -2.21768e+00 -1.84159e+00
21Feb12_165041|   1.07890e-01 -1.21571e+00  1.41906e-02 -1.18878e+00 -1.10586e+00]
21Feb12_165041| [ 7.47110e-04 -2.19367e-01  1.24132e+00  2.42981e-01  1.64975e+00
21Feb12_165041|  -7.56681e-01  2.05047e+00  1.41699e+00  2.11413e-01  2.05856e-01
21Feb12_165041|  -1.19536e+00 -1.17721e+00 -5.74572e-02 -9.88771e-01 -5.21745e-02]
21Feb12_165041| [ 8.41039e-01 -7.80210e-01  1.63153e-01  9.11562e-01  1.96584e+00
21Feb12_165041|   1.78291e+00  1.27725e-01  9.24125e-01  8.89095e-01  8.02583e-01
21Feb12_165041|  -1.84072e-01 -1.83956e+00 -1.02407e+00  6.97260e-01  2.04119e+00]
21Feb12_165041| [ 1.02325e+00 -1.14512e+00  1.53735e+00 -1.20875e+00  2.40349e-01
21Feb12_165041|   3.65149e-01 -8.45853e-01 -9.53877e-01  1.08881e+00  1.31369e+00
21Feb12_165041|  -8.73629e-01  3.54768e-01 -1.44120e+00  3.00774e+00  5.37138e-01]
21Feb12_165041| [ 1.21153e+00  1.33780e+00  2.37346e-01  1.10192e+00 -7.71109e-01
21Feb12_165041|  -1.67297e+00 -9.85041e-01 -9.67469e-02  1.35584e-01  1.43828e+00
21Feb12_165041|  -5.37772e-01  6.81867e-01  8.99423e-02 -3.00140e-01  7.40803e-01]
21Feb12_165041| [-1.53912e-01 -1.45545e+00 -8.51719e-01 -3.24207e-01 -1.85297e+00
21Feb12_165041|  -1.37632e+00  2.56265e+00 -1.51591e+00 -7.70917e-01  1.60742e+00
21Feb12_165041|   8.19418e-01  1.51279e+00 -7.75504e-01 -4.56317e-01  7.93313e-01]
21Feb12_165041| [ 1.79234e+00  5.37534e-01 -1.64985e-01  1.12594e+00  4.19165e-01
21Feb12_165041|   1.00815e+00 -1.24029e+00  8.99015e-02  5.04534e-01  1.04688e+00
21Feb12_165041|  -1.85983e+00 -6.28367e-01  1.44747e+00 -7.70927e-01 -6.80962e-02]
21Feb12_165041| [-6.11685e-01  5.81244e-01 -2.00813e+00  4.40980e-01  1.17081e+00
21Feb12_165041|   4.53617e-02 -1.02732e-01 -5.30344e-01 -2.30272e-01 -2.75712e-01
21Feb12_165041|  -1.35628e+00  6.77073e-01  1.18206e+00 -9.68516e-01  8.88227e-01]
21Feb12_165041| [ 3.39330e-01  1.85906e-01  3.17199e+00 -1.14941e+00  8.41043e-01
21Feb12_165041|   1.43171e+00  2.91815e-01  9.90040e-01  2.43151e-01 -4.20123e-01
21Feb12_165041|  -7.71009e-01  8.26689e-01 -2.38729e-01  2.25124e-01  4.71938e-02]
21Feb12_165041| [-1.24769e+00 -1.74352e-01  1.33159e+00  6.31103e-01  1.39801e-01
21Feb12_165041|  -1.97232e-01  1.00881e+00 -1.05164e+00 -1.26316e-01 -6.77330e-01
21Feb12_165041|   6.93223e-01  3.09964e-01  4.46448e-01  3.28001e-01 -7.51083e-01]
21Feb12_165041| [-7.55157e-01 -1.20070e+00  1.18128e+00  2.31557e-01 -5.77142e-01
21Feb12_165041|   8.50621e-01 -6.80691e-01  1.14562e+00  6.53826e-01 -1.28380e+00
21Feb12_165041|   4.15503e-02  9.67591e-01 -3.56690e+00 -2.80446e-01 -2.39691e-01]
21Feb12_165041| [ 1.43065e+00  4.89999e-01  7.08940e-01  9.80815e-01 -5.25905e-01
21Feb12_165041|   8.92854e-01 -1.47577e+00 -9.27641e-02 -3.34619e-01 -1.41270e+00
21Feb12_165041|  -1.10591e+00  1.59163e+00  2.61333e-01 -1.48185e+00 -2.14182e+00]
21Feb12_165041| [ 8.38600e-01 -8.88508e-01 -4.12187e-01 -1.04812e-01  3.26908e-01
21Feb12_165041|  -9.83693e-01  1.67864e+00  7.72612e-01  1.95026e+00  9.57917e-01
21Feb12_165041|  -1.48928e+00 -1.99797e-01 -3.05136e-01 -1.14633e-01 -1.04672e+00]]
21Feb12_165041|-- Bias --
21Feb12_165041|[ 0.73695 -0.51772  1.29843 -0.86449  0.54318  0.17660 -0.21569  0.35471
21Feb12_165041| -0.23531 -0.15791  1.04286  0.77391 -0.11794  1.01790  0.50375]
21Feb12_165041|Layer 1:
21Feb12_165041|-- Config --
21Feb12_165041|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 15], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_165041|-- Weights --
21Feb12_165041|[[ 0.70443 -1.08724]
21Feb12_165041| [-0.44561 -1.05050]
21Feb12_165041| [ 0.25488  0.31427]
21Feb12_165041| [-1.40193  0.84859]
21Feb12_165041| [ 0.27127 -0.15942]
21Feb12_165041| [-0.18528 -0.14003]
21Feb12_165041| [ 1.68717  0.30442]
21Feb12_165041| [-0.01440  0.47743]
21Feb12_165041| [ 0.46612  0.57491]
21Feb12_165041| [-1.91613 -0.31596]
21Feb12_165041| [ 1.38318 -0.97860]
21Feb12_165041| [-0.49568  0.13334]
21Feb12_165041| [ 0.67487 -1.08400]
21Feb12_165041| [ 1.22898  1.13422]
21Feb12_165041| [ 0.14442 -0.69100]]
21Feb12_165041|-- Bias --
21Feb12_165041|[ 1.12271 -0.02168]
21Feb12_165041|Predicting the validation and test data with the Best final individual.
21Feb12_165048| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_165048|-----------  ------------------  --------------------  ----------
21Feb12_165048|Validation         41.91                  15            0.00774
21Feb12_165048|   Test            36.58                  15            0.00891
21Feb12_165048|-------------------- Test #4 --------------------
21Feb12_165048|Best final individual weights
21Feb12_165048|Individual:
21Feb12_165048|-- Constant hidden layers --
21Feb12_165048|False
21Feb12_165048|Layer 0:
21Feb12_165048|-- Config --
21Feb12_165048|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 15, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_165048|-- Weights --
21Feb12_165048|[[ 5.09617e-01  8.20902e-01 -3.02367e-01 -9.64837e-01 -4.33824e-01
21Feb12_165048|  -2.42034e-01 -5.04343e-01  1.31689e+00  9.21850e-01  5.13818e-01
21Feb12_165048|  -3.49854e-01  2.15852e-01 -1.04928e+00  7.68905e-01 -1.88324e+00]
21Feb12_165048| [-7.50915e-01 -2.52628e+00  3.69383e-01  1.39331e-01 -4.71230e-01
21Feb12_165048|   2.50267e+00 -2.55477e-01 -5.15419e-01 -2.31831e-01 -1.16548e+00
21Feb12_165048|  -8.22133e-01  4.82232e-01 -1.26500e+00  7.69663e-01  1.16647e+00]
21Feb12_165048| [ 4.01389e-03  9.01850e-01 -4.38696e-01 -7.91041e-01 -3.45664e-01
21Feb12_165048|  -1.66871e+00  1.65396e+00  7.90223e-01  5.51123e-01  1.67606e-01
21Feb12_165048|   2.12442e-01  1.14271e+00  6.42674e-01  2.00899e-01 -2.05944e-01]
21Feb12_165048| [ 1.80619e-01 -2.50060e-01 -1.12859e+00  1.83522e+00  1.81374e+00
21Feb12_165048|  -1.42416e+00  5.22823e-01 -7.02013e-01  1.84516e+00  1.90809e+00
21Feb12_165048|   1.37151e+00  4.03871e-02  4.29238e-01 -2.37117e-01 -1.00132e+00]
21Feb12_165048| [ 4.39871e-01  3.98574e-01 -3.75109e-01 -8.64825e-01  4.06425e-01
21Feb12_165048|   5.56500e-01  1.44148e+00 -5.22177e-01 -7.21740e-01  3.07682e-01
21Feb12_165048|  -9.52454e-01  8.44086e-01  1.09295e+00 -3.90444e-01  1.33545e+00]
21Feb12_165048| [-1.42180e+00  3.85641e-01 -8.43471e-02  1.81738e-02 -1.14521e+00
21Feb12_165048|  -8.06111e-01 -8.15090e-01  7.76165e-02  1.02784e+00  1.02123e-01
21Feb12_165048|   7.08213e-01  9.96943e-01 -7.79890e-01  1.66778e+00 -6.05761e-01]
21Feb12_165048| [-2.52774e-01 -9.61820e-01  3.02997e+00 -4.75355e-02  9.27908e-01
21Feb12_165048|   6.12327e-01 -4.65796e-01  8.85447e-01 -9.19731e-02  5.35502e-02
21Feb12_165048|  -5.61515e-01  1.22163e+00 -6.55581e-02 -4.23284e-01  6.78889e-01]
21Feb12_165048| [-4.07954e-01  7.89564e-01 -1.02275e+00 -1.42852e-01 -1.21182e-01
21Feb12_165048|   2.60288e+00  1.31219e+00 -1.05105e+00 -7.28076e-01  7.37981e-01
21Feb12_165048|   1.07877e+00  4.12772e-01  3.20972e-01 -1.42903e+00  5.49771e-01]
21Feb12_165048| [-1.06598e+00  4.11763e-01 -5.98736e-01 -1.02922e+00  1.44690e+00
21Feb12_165048|   1.61847e+00  7.86271e-01 -1.04439e+00 -1.22083e+00 -5.20594e-01
21Feb12_165048|   1.50709e+00 -2.76750e-01 -9.31489e-01  1.18032e+00 -1.34476e+00]
21Feb12_165048| [-9.84737e-01 -5.97909e-01 -5.05735e-01  1.21453e+00  2.04300e+00
21Feb12_165048|  -1.80226e+00  2.27960e-01  2.48235e-01 -9.14083e-01 -8.19925e-01
21Feb12_165048|   8.79325e-03  1.89321e+00 -2.33314e+00  3.64489e-01 -8.65853e-01]
21Feb12_165048| [-5.52147e-01 -1.09026e+00 -6.31263e-01 -9.85456e-02 -1.26793e+00
21Feb12_165048|   6.92239e-01  4.07591e-03  8.28704e-02 -4.61769e-01  1.47380e+00
21Feb12_165048|  -8.25050e-01  1.85307e+00 -7.02559e-01  4.42800e-01 -5.09351e-01]
21Feb12_165048| [-1.22241e+00 -2.82164e+00 -3.49419e-01  2.35780e-01 -3.06882e-01
21Feb12_165048|   4.97633e-01 -8.59745e-01  1.41005e+00  4.44223e-01  4.80295e-01
21Feb12_165048|   5.28514e-01 -8.52095e-01  7.93638e-01 -1.18061e+00  3.77575e-01]
21Feb12_165048| [ 1.83848e+00  1.86747e+00 -6.09064e-01 -1.29117e-01  8.20239e-01
21Feb12_165048|  -8.41223e-01 -4.91994e-01 -4.35134e-02 -3.10526e-01  8.12742e-01
21Feb12_165048|  -2.48499e+00  6.10492e-01  2.59825e-01  1.10740e+00  2.25110e-01]
21Feb12_165048| [-9.61110e-02  1.17814e+00  1.12148e-01 -3.49813e-01  2.43858e+00
21Feb12_165048|  -1.38613e+00 -3.82927e-01  1.52932e+00  8.48623e-01 -1.99483e+00
21Feb12_165048|  -2.12240e+00  1.06312e+00 -3.90781e-02  1.49640e+00  1.12926e+00]
21Feb12_165048| [-4.30616e-01  2.39031e-01 -7.23476e-01  1.25568e+00 -2.14845e-01
21Feb12_165048|  -5.53173e-01 -2.65699e+00  2.69230e-02 -1.00392e+00  1.32765e-01
21Feb12_165048|  -5.64005e-01  1.22524e+00  1.24383e+00 -1.09592e+00 -1.41796e+00]
21Feb12_165048| [-2.39791e-01  1.53064e+00  3.01720e-01  2.78106e-01 -1.84792e-01
21Feb12_165048|   1.56208e+00  9.94463e-01 -1.63904e+00  6.63295e-01 -1.85188e+00
21Feb12_165048|  -7.33287e-01 -1.62705e-01 -9.61094e-01  4.14256e-01 -1.81088e+00]
21Feb12_165048| [ 2.83794e-01  7.82624e-01  8.22930e-01  1.38834e+00  1.35777e+00
21Feb12_165048|   1.13137e+00 -4.51094e-01 -9.14736e-02 -4.29153e-01 -1.32003e-01
21Feb12_165048|  -1.06833e+00 -3.60741e-02 -1.72337e+00 -9.36812e-02 -1.50919e-01]
21Feb12_165048| [ 4.60832e-01 -6.41447e-01  7.19778e-01  1.43690e+00 -5.39012e-01
21Feb12_165048|   2.73839e+00  4.18203e-02  1.12728e+00 -1.96359e+00  5.08015e-01
21Feb12_165048|  -3.94637e-02  1.21425e+00  7.81562e-01  1.21240e+00  8.71932e-02]
21Feb12_165048| [ 7.21067e-01 -4.05470e-01  4.30706e-01 -1.12406e+00 -1.66416e-01
21Feb12_165048|  -1.74613e-01 -2.82475e+00  7.83187e-01 -1.70599e+00 -4.53800e-01
21Feb12_165048|   7.68700e-02  1.38626e+00  4.71260e-01 -1.20854e-01 -3.85957e-01]
21Feb12_165048| [-1.45393e+00 -4.35386e-01  7.35002e-01 -1.05813e+00 -6.41567e-01
21Feb12_165048|  -1.23953e+00 -1.11174e+00 -4.33161e-01  1.71285e+00 -1.69152e+00
21Feb12_165048|  -3.94477e-01 -9.64481e-01  2.12241e-01 -4.51296e-01  6.12573e-01]
21Feb12_165048| [ 1.91178e+00 -7.20020e-01 -1.43347e+00  6.16597e-01 -1.40631e-01
21Feb12_165048|   9.60419e-01 -2.94601e-01 -3.70235e-01  1.68500e-03 -7.06077e-02
21Feb12_165048|  -2.63686e+00 -7.93469e-01  3.46275e-01  2.04211e+00  9.19580e-01]
21Feb12_165048| [ 2.28690e-01 -1.52406e-01 -4.49362e-01 -7.32180e-01  7.99781e-01
21Feb12_165048|   4.88373e-01 -9.34696e-01 -5.02242e-01  9.68074e-01 -3.07760e-01
21Feb12_165048|  -3.49720e-01 -2.00695e+00 -4.45838e-01  2.62312e-01  3.38818e-01]
21Feb12_165048| [-1.98557e-01  8.34883e-01 -1.61905e-01  1.28379e+00  1.04073e+00
21Feb12_165048|   1.45833e+00  4.77341e-01  9.87420e-01 -3.08856e-01 -1.55031e+00
21Feb12_165048|   1.38023e+00 -4.42201e-01  1.78369e+00  8.01018e-01  1.52483e+00]
21Feb12_165048| [ 1.12967e+00 -8.45423e-01  1.52345e+00  1.08801e+00 -4.32434e-01
21Feb12_165048|  -3.16741e-01 -7.17985e-02  1.09877e+00 -7.90690e-01  1.36084e+00
21Feb12_165048|  -5.66120e-01 -1.70432e+00 -2.12910e+00 -2.41374e-01  1.33636e+00]
21Feb12_165048| [-4.08205e-01 -8.03871e-01  9.13990e-01  5.00916e-01 -1.81059e-01
21Feb12_165048|   2.42621e-01 -9.57869e-01  6.74094e-01  6.52179e-01  2.77279e-01
21Feb12_165048|  -3.91051e-01 -9.05321e-02  6.86316e-01 -3.54594e-01  5.83144e-01]
21Feb12_165048| [-3.98308e-01 -4.48018e-03  1.11987e+00  1.50374e+00 -9.18129e-01
21Feb12_165048|  -1.81690e+00 -1.38223e+00 -2.74481e-01 -8.24843e-01 -7.05820e-01
21Feb12_165048|   1.50584e+00 -4.21386e-01  4.00084e-01 -7.61841e-02 -7.41767e-01]
21Feb12_165048| [ 5.51762e-01 -1.04904e+00  5.21335e-01  2.14684e-01 -8.21795e-02
21Feb12_165048|   3.68556e-01  1.01222e+00 -1.30634e+00 -1.52652e+00  9.98379e-01
21Feb12_165048|   8.51997e-01 -9.42775e-01 -1.16577e-01  3.64988e-01 -1.27419e+00]
21Feb12_165048| [ 1.67425e+00 -1.27190e-01  2.44775e+00  1.44302e+00 -4.43112e-01
21Feb12_165048|  -4.07317e-02  1.33875e-01  4.92876e-01  1.36327e+00  3.41424e-01
21Feb12_165048|   1.70937e+00 -2.26414e+00  5.48087e-01 -2.49869e-01 -1.95666e+00]
21Feb12_165048| [-7.77069e-01  1.76839e+00 -5.99460e-01 -2.13769e+00  1.38006e+00
21Feb12_165048|   1.30623e+00 -1.06865e+00 -1.16462e+00  8.02528e-01 -3.99780e-01
21Feb12_165048|   8.20611e-01 -1.64613e-01  3.17174e-01  1.50755e+00  1.82851e-01]
21Feb12_165048| [-1.02989e+00 -1.07499e+00 -1.93091e+00  4.66271e-01 -8.74190e-01
21Feb12_165048|  -1.32185e+00 -9.08286e-01 -8.46363e-01  2.03651e-01 -2.52017e-01
21Feb12_165048|   1.15748e+00 -3.29038e-01 -5.53034e-01  6.31862e-01 -9.38469e-02]
21Feb12_165048| [-1.07650e+00  2.26383e-01  1.43406e-01 -1.04859e+00 -1.13255e+00
21Feb12_165048|   5.32942e-01 -2.81361e-01  1.06039e+00 -4.84886e-01  1.81779e+00
21Feb12_165048|   4.45898e-01  1.15599e-01  2.22637e+00 -1.10477e+00 -7.41273e-01]
21Feb12_165048| [ 5.36190e-01  1.36053e+00  1.86442e-01  1.76821e-01  1.73842e+00
21Feb12_165048|   1.33653e-01 -2.69435e-01  1.42842e+00 -6.67924e-01  8.34192e-01
21Feb12_165048|  -4.93949e-01  2.55190e-01  8.44813e-02  1.07023e+00  3.32795e-01]
21Feb12_165048| [-7.77858e-01  6.91255e-01 -2.00094e-01 -3.47804e-02  1.25963e+00
21Feb12_165048|   2.88406e-01  1.11181e-02 -1.72072e-01  1.74171e-01  1.07767e+00
21Feb12_165048|  -7.57539e-01 -1.51881e+00  1.13432e+00 -8.19687e-01  2.51036e-01]
21Feb12_165048| [ 1.17877e+00  8.51361e-01  5.34249e-01 -3.85201e-01  1.62741e+00
21Feb12_165048|   7.14108e-01 -2.49586e-01 -1.51061e+00 -5.78471e-01 -1.53573e+00
21Feb12_165048|  -6.82580e-01 -1.03046e+00  2.14369e+00 -2.12686e+00  2.93875e-01]
21Feb12_165048| [-5.46699e-01 -1.24367e-01  1.50400e+00  5.24570e-01  1.32199e-01
21Feb12_165048|  -1.11873e+00 -1.21781e-01  1.60716e+00  7.94494e-01  4.12000e-02
21Feb12_165048|  -1.45629e-01 -1.67069e+00  1.55359e+00  1.27490e+00  3.78250e-01]
21Feb12_165048| [-1.65770e+00  7.63010e-01 -1.07032e-01 -1.29077e+00 -2.72523e-01
21Feb12_165048|   8.86152e-01  2.03137e-02  1.07244e+00 -2.07611e+00  1.79718e-01
21Feb12_165048|   1.81554e-01 -6.15758e-01 -9.51774e-01  1.02939e+00  8.17973e-01]
21Feb12_165048| [ 9.21545e-01 -8.71244e-02 -1.53454e+00 -1.66686e+00  9.25583e-02
21Feb12_165048|   5.45788e-01  9.00588e-01  5.39148e-01  1.73423e+00  5.95858e-01
21Feb12_165048|   7.60598e-01  7.10163e-01 -1.92447e-01 -2.18648e-01 -1.06613e-01]
21Feb12_165048| [-1.27156e+00  1.50471e-01 -1.51367e+00  2.43159e-01  1.45374e+00
21Feb12_165048|   1.39069e-01  1.63857e+00  7.76127e-01  1.22775e-01 -9.15383e-01
21Feb12_165048|  -7.88206e-01 -1.88443e-01  5.88849e-01 -1.15889e+00  1.57532e+00]
21Feb12_165048| [-7.87307e-01  7.90368e-01 -8.23463e-01 -7.31497e-01 -1.23567e+00
21Feb12_165048|   4.22757e-01  3.63316e-02  6.01964e-01  1.96999e+00 -1.17414e+00
21Feb12_165048|   3.97797e-01 -1.08808e+00 -5.94358e-01 -2.83672e-01  8.50566e-01]
21Feb12_165048| [ 5.30769e-01 -1.84801e+00 -5.66134e-01  6.76585e-02  1.10136e-01
21Feb12_165048|   4.92367e-01 -4.90997e-01  6.06677e-01  2.28381e+00 -4.07746e-02
21Feb12_165048|   1.15850e+00 -5.98080e-01 -7.01578e-01  1.01957e+00  2.49859e-01]
21Feb12_165048| [-8.63352e-01  1.10102e+00 -1.35284e+00  7.44546e-01  1.23832e+00
21Feb12_165048|  -5.46095e-01 -7.14545e-01  6.39714e-01 -1.05446e-01 -8.88602e-01
21Feb12_165048|   9.93232e-01  1.94862e+00 -4.16105e-01  1.03489e-01  1.11977e+00]
21Feb12_165048| [ 1.19516e+00 -1.76346e-01  1.04128e-01  1.20697e+00 -9.23981e-01
21Feb12_165048|  -1.33787e+00 -2.81645e-01  4.54001e-01  1.13838e-01  7.67530e-01
21Feb12_165048|  -1.19224e+00 -1.30105e-01 -1.91934e-01  4.19944e-01  1.69825e-01]
21Feb12_165048| [ 7.65088e-01 -1.94246e+00 -7.11338e-01  4.53958e-01  1.94201e+00
21Feb12_165048|   1.31030e+00 -2.96434e-02 -1.76407e+00  5.53828e-01  6.85560e-01
21Feb12_165048|   7.66333e-01  3.82096e-02 -8.16458e-01 -6.24116e-02  2.64193e-01]
21Feb12_165048| [ 3.18200e-01  2.29948e+00  1.64715e+00  1.62897e+00 -7.51376e-02
21Feb12_165048|  -1.28841e+00 -6.20669e-01 -1.11166e-01  8.60402e-01 -1.33019e+00
21Feb12_165048|  -5.96012e-01  1.43903e+00  4.95090e-01 -5.77593e-01  1.44906e+00]
21Feb12_165048| [ 4.11040e-01  7.04946e-01 -5.20407e-01  1.19926e-01 -2.14187e-01
21Feb12_165048|   2.61836e-01 -2.06690e-01 -5.23044e-01 -2.21768e+00 -1.84159e+00
21Feb12_165048|   1.07890e-01 -1.21571e+00  1.41906e-02 -1.18878e+00 -1.10586e+00]
21Feb12_165048| [ 7.47110e-04 -2.19367e-01  1.24132e+00  2.42981e-01  1.64975e+00
21Feb12_165048|  -7.56681e-01  2.05047e+00  1.41699e+00  2.11413e-01  2.05856e-01
21Feb12_165048|  -1.19536e+00 -1.17721e+00 -5.74572e-02 -9.88771e-01 -5.21745e-02]
21Feb12_165048| [ 8.41039e-01 -7.80210e-01  1.63153e-01  9.11562e-01  1.96584e+00
21Feb12_165048|   1.78291e+00  1.27725e-01  9.24125e-01  8.89095e-01  8.02583e-01
21Feb12_165048|  -1.84072e-01 -1.83956e+00 -1.02407e+00  6.97260e-01  2.04119e+00]
21Feb12_165048| [ 1.02325e+00 -1.14512e+00  1.53735e+00 -1.20875e+00  2.40349e-01
21Feb12_165048|   3.65149e-01 -8.45853e-01 -9.53877e-01  1.08881e+00  1.31369e+00
21Feb12_165048|  -8.73629e-01  3.54768e-01 -1.44120e+00  3.00774e+00  5.37138e-01]
21Feb12_165048| [ 1.21153e+00  1.33780e+00  2.37346e-01  1.10192e+00 -7.71109e-01
21Feb12_165048|  -1.67297e+00 -9.85041e-01 -9.67469e-02  1.35584e-01  1.43828e+00
21Feb12_165048|  -5.37772e-01  6.81867e-01  8.99423e-02 -3.00140e-01  7.40803e-01]
21Feb12_165048| [-1.53912e-01 -1.45545e+00 -8.51719e-01 -3.24207e-01 -1.85297e+00
21Feb12_165048|  -1.37632e+00  2.56265e+00 -1.51591e+00 -7.70917e-01  1.60742e+00
21Feb12_165048|   8.19418e-01  1.51279e+00 -7.75504e-01 -4.56317e-01  7.93313e-01]
21Feb12_165048| [ 1.79234e+00  5.37534e-01 -1.64985e-01  1.12594e+00  4.19165e-01
21Feb12_165048|   1.00815e+00 -1.24029e+00  8.99015e-02  5.04534e-01  1.04688e+00
21Feb12_165048|  -1.85983e+00 -6.28367e-01  1.44747e+00 -7.70927e-01 -6.80962e-02]
21Feb12_165048| [-6.11685e-01  5.81244e-01 -2.00813e+00  4.40980e-01  1.17081e+00
21Feb12_165048|   4.53617e-02 -1.02732e-01 -5.30344e-01 -2.30272e-01 -2.75712e-01
21Feb12_165048|  -1.35628e+00  6.77073e-01  1.18206e+00 -9.68516e-01  8.88227e-01]
21Feb12_165048| [ 3.39330e-01  1.85906e-01  3.17199e+00 -1.14941e+00  8.41043e-01
21Feb12_165048|   1.43171e+00  2.91815e-01  9.90040e-01  2.43151e-01 -4.20123e-01
21Feb12_165048|  -7.71009e-01  8.26689e-01 -2.38729e-01  2.25124e-01  4.71938e-02]
21Feb12_165048| [-1.24769e+00 -1.74352e-01  1.33159e+00  6.31103e-01  1.39801e-01
21Feb12_165048|  -1.97232e-01  1.00881e+00 -1.05164e+00 -1.26316e-01 -6.77330e-01
21Feb12_165048|   6.93223e-01  3.09964e-01  4.46448e-01  3.28001e-01 -7.51083e-01]
21Feb12_165048| [-7.55157e-01 -1.20070e+00  1.18128e+00  2.31557e-01 -5.77142e-01
21Feb12_165048|   8.50621e-01 -6.80691e-01  1.14562e+00  6.53826e-01 -1.28380e+00
21Feb12_165048|   4.15503e-02  9.67591e-01 -3.56690e+00 -2.80446e-01 -2.39691e-01]
21Feb12_165048| [ 1.43065e+00  4.89999e-01  7.08940e-01  9.80815e-01 -5.25905e-01
21Feb12_165048|   8.92854e-01 -1.47577e+00 -9.27641e-02 -3.34619e-01 -1.41270e+00
21Feb12_165048|  -1.10591e+00  1.59163e+00  2.61333e-01 -1.48185e+00 -2.14182e+00]
21Feb12_165048| [ 8.38600e-01 -8.88508e-01 -4.12187e-01 -1.04812e-01  3.26908e-01
21Feb12_165048|  -9.83693e-01  1.67864e+00  7.72612e-01  1.95026e+00  9.57917e-01
21Feb12_165048|  -1.48928e+00 -1.99797e-01 -3.05136e-01 -1.14633e-01 -1.04672e+00]]
21Feb12_165048|-- Bias --
21Feb12_165048|[ 0.73695 -0.51772  1.29843 -0.86449  0.54318  0.17660 -0.21569  0.35471
21Feb12_165048| -0.23531 -0.15791  1.04286  0.77391 -0.11794  1.01790  0.50375]
21Feb12_165048|Layer 1:
21Feb12_165048|-- Config --
21Feb12_165048|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 15], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_165048|-- Weights --
21Feb12_165048|[[ 0.70443 -1.08724]
21Feb12_165048| [-0.44561 -1.05050]
21Feb12_165048| [ 0.25488  0.31427]
21Feb12_165048| [-1.40193  0.84859]
21Feb12_165048| [ 0.27127 -0.15942]
21Feb12_165048| [-0.18528 -0.14003]
21Feb12_165048| [ 1.68717  0.30442]
21Feb12_165048| [-0.01440  0.47743]
21Feb12_165048| [ 0.46612  0.57491]
21Feb12_165048| [-1.91613 -0.31596]
21Feb12_165048| [ 1.38318 -0.97860]
21Feb12_165048| [-0.49568  0.13334]
21Feb12_165048| [ 0.67487 -1.08400]
21Feb12_165048| [ 1.22898  1.13422]
21Feb12_165048| [ 0.14442 -0.69100]]
21Feb12_165048|-- Bias --
21Feb12_165048|[ 1.12271 -0.02168]
21Feb12_165048|Predicting the validation and test data with the Best final individual.
21Feb12_165056| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_165056|-----------  ------------------  --------------------  ----------
21Feb12_165056|Validation         41.83                  15            0.00775
21Feb12_165056|   Test            36.58                  15            0.00000
21Feb12_165056|-------------------- Test #5 --------------------
21Feb12_165056|Best final individual weights
21Feb12_165056|Individual:
21Feb12_165056|-- Constant hidden layers --
21Feb12_165056|False
21Feb12_165056|Layer 0:
21Feb12_165056|-- Config --
21Feb12_165056|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 15, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_165056|-- Weights --
21Feb12_165056|[[ 5.09617e-01  8.20902e-01 -3.02367e-01 -9.64837e-01 -4.33824e-01
21Feb12_165056|  -2.42034e-01 -5.04343e-01  1.31689e+00  9.21850e-01  5.13818e-01
21Feb12_165056|  -3.49854e-01  2.15852e-01 -1.04928e+00  7.68905e-01 -1.88324e+00]
21Feb12_165056| [-7.50915e-01 -2.52628e+00  3.69383e-01  1.39331e-01 -4.71230e-01
21Feb12_165056|   2.50267e+00 -2.55477e-01 -5.15419e-01 -2.31831e-01 -1.16548e+00
21Feb12_165056|  -8.22133e-01  4.82232e-01 -1.26500e+00  7.69663e-01  1.16647e+00]
21Feb12_165056| [ 4.01389e-03  9.01850e-01 -4.38696e-01 -7.91041e-01 -3.45664e-01
21Feb12_165056|  -1.66871e+00  1.65396e+00  7.90223e-01  5.51123e-01  1.67606e-01
21Feb12_165056|   2.12442e-01  1.14271e+00  6.42674e-01  2.00899e-01 -2.05944e-01]
21Feb12_165056| [ 1.80619e-01 -2.50060e-01 -1.12859e+00  1.83522e+00  1.81374e+00
21Feb12_165056|  -1.42416e+00  5.22823e-01 -7.02013e-01  1.84516e+00  1.90809e+00
21Feb12_165056|   1.37151e+00  4.03871e-02  4.29238e-01 -2.37117e-01 -1.00132e+00]
21Feb12_165056| [ 4.39871e-01  3.98574e-01 -3.75109e-01 -8.64825e-01  4.06425e-01
21Feb12_165056|   5.56500e-01  1.44148e+00 -5.22177e-01 -7.21740e-01  3.07682e-01
21Feb12_165056|  -9.52454e-01  8.44086e-01  1.09295e+00 -3.90444e-01  1.33545e+00]
21Feb12_165056| [-1.42180e+00  3.85641e-01 -8.43471e-02  1.81738e-02 -1.14521e+00
21Feb12_165056|  -8.06111e-01 -8.15090e-01  7.76165e-02  1.02784e+00  1.02123e-01
21Feb12_165056|   7.08213e-01  9.96943e-01 -7.79890e-01  1.66778e+00 -6.05761e-01]
21Feb12_165056| [-2.52774e-01 -9.61820e-01  3.02997e+00 -4.75355e-02  9.27908e-01
21Feb12_165056|   6.12327e-01 -4.65796e-01  8.85447e-01 -9.19731e-02  5.35502e-02
21Feb12_165056|  -5.61515e-01  1.22163e+00 -6.55581e-02 -4.23284e-01  6.78889e-01]
21Feb12_165056| [-4.07954e-01  7.89564e-01 -1.02275e+00 -1.42852e-01 -1.21182e-01
21Feb12_165056|   2.60288e+00  1.31219e+00 -1.05105e+00 -7.28076e-01  7.37981e-01
21Feb12_165056|   1.07877e+00  4.12772e-01  3.20972e-01 -1.42903e+00  5.49771e-01]
21Feb12_165056| [-1.06598e+00  4.11763e-01 -5.98736e-01 -1.02922e+00  1.44690e+00
21Feb12_165056|   1.61847e+00  7.86271e-01 -1.04439e+00 -1.22083e+00 -5.20594e-01
21Feb12_165056|   1.50709e+00 -2.76750e-01 -9.31489e-01  1.18032e+00 -1.34476e+00]
21Feb12_165056| [-9.84737e-01 -5.97909e-01 -5.05735e-01  1.21453e+00  2.04300e+00
21Feb12_165056|  -1.80226e+00  2.27960e-01  2.48235e-01 -9.14083e-01 -8.19925e-01
21Feb12_165056|   8.79325e-03  1.89321e+00 -2.33314e+00  3.64489e-01 -8.65853e-01]
21Feb12_165056| [-5.52147e-01 -1.09026e+00 -6.31263e-01 -9.85456e-02 -1.26793e+00
21Feb12_165056|   6.92239e-01  4.07591e-03  8.28704e-02 -4.61769e-01  1.47380e+00
21Feb12_165056|  -8.25050e-01  1.85307e+00 -7.02559e-01  4.42800e-01 -5.09351e-01]
21Feb12_165056| [-1.22241e+00 -2.82164e+00 -3.49419e-01  2.35780e-01 -3.06882e-01
21Feb12_165056|   4.97633e-01 -8.59745e-01  1.41005e+00  4.44223e-01  4.80295e-01
21Feb12_165056|   5.28514e-01 -8.52095e-01  7.93638e-01 -1.18061e+00  3.77575e-01]
21Feb12_165056| [ 1.83848e+00  1.86747e+00 -6.09064e-01 -1.29117e-01  8.20239e-01
21Feb12_165056|  -8.41223e-01 -4.91994e-01 -4.35134e-02 -3.10526e-01  8.12742e-01
21Feb12_165056|  -2.48499e+00  6.10492e-01  2.59825e-01  1.10740e+00  2.25110e-01]
21Feb12_165056| [-9.61110e-02  1.17814e+00  1.12148e-01 -3.49813e-01  2.43858e+00
21Feb12_165056|  -1.38613e+00 -3.82927e-01  1.52932e+00  8.48623e-01 -1.99483e+00
21Feb12_165056|  -2.12240e+00  1.06312e+00 -3.90781e-02  1.49640e+00  1.12926e+00]
21Feb12_165056| [-4.30616e-01  2.39031e-01 -7.23476e-01  1.25568e+00 -2.14845e-01
21Feb12_165056|  -5.53173e-01 -2.65699e+00  2.69230e-02 -1.00392e+00  1.32765e-01
21Feb12_165056|  -5.64005e-01  1.22524e+00  1.24383e+00 -1.09592e+00 -1.41796e+00]
21Feb12_165056| [-2.39791e-01  1.53064e+00  3.01720e-01  2.78106e-01 -1.84792e-01
21Feb12_165056|   1.56208e+00  9.94463e-01 -1.63904e+00  6.63295e-01 -1.85188e+00
21Feb12_165056|  -7.33287e-01 -1.62705e-01 -9.61094e-01  4.14256e-01 -1.81088e+00]
21Feb12_165056| [ 2.83794e-01  7.82624e-01  8.22930e-01  1.38834e+00  1.35777e+00
21Feb12_165056|   1.13137e+00 -4.51094e-01 -9.14736e-02 -4.29153e-01 -1.32003e-01
21Feb12_165056|  -1.06833e+00 -3.60741e-02 -1.72337e+00 -9.36812e-02 -1.50919e-01]
21Feb12_165056| [ 4.60832e-01 -6.41447e-01  7.19778e-01  1.43690e+00 -5.39012e-01
21Feb12_165056|   2.73839e+00  4.18203e-02  1.12728e+00 -1.96359e+00  5.08015e-01
21Feb12_165056|  -3.94637e-02  1.21425e+00  7.81562e-01  1.21240e+00  8.71932e-02]
21Feb12_165056| [ 7.21067e-01 -4.05470e-01  4.30706e-01 -1.12406e+00 -1.66416e-01
21Feb12_165056|  -1.74613e-01 -2.82475e+00  7.83187e-01 -1.70599e+00 -4.53800e-01
21Feb12_165056|   7.68700e-02  1.38626e+00  4.71260e-01 -1.20854e-01 -3.85957e-01]
21Feb12_165056| [-1.45393e+00 -4.35386e-01  7.35002e-01 -1.05813e+00 -6.41567e-01
21Feb12_165056|  -1.23953e+00 -1.11174e+00 -4.33161e-01  1.71285e+00 -1.69152e+00
21Feb12_165056|  -3.94477e-01 -9.64481e-01  2.12241e-01 -4.51296e-01  6.12573e-01]
21Feb12_165056| [ 1.91178e+00 -7.20020e-01 -1.43347e+00  6.16597e-01 -1.40631e-01
21Feb12_165056|   9.60419e-01 -2.94601e-01 -3.70235e-01  1.68500e-03 -7.06077e-02
21Feb12_165056|  -2.63686e+00 -7.93469e-01  3.46275e-01  2.04211e+00  9.19580e-01]
21Feb12_165056| [ 2.28690e-01 -1.52406e-01 -4.49362e-01 -7.32180e-01  7.99781e-01
21Feb12_165056|   4.88373e-01 -9.34696e-01 -5.02242e-01  9.68074e-01 -3.07760e-01
21Feb12_165056|  -3.49720e-01 -2.00695e+00 -4.45838e-01  2.62312e-01  3.38818e-01]
21Feb12_165056| [-1.98557e-01  8.34883e-01 -1.61905e-01  1.28379e+00  1.04073e+00
21Feb12_165056|   1.45833e+00  4.77341e-01  9.87420e-01 -3.08856e-01 -1.55031e+00
21Feb12_165056|   1.38023e+00 -4.42201e-01  1.78369e+00  8.01018e-01  1.52483e+00]
21Feb12_165056| [ 1.12967e+00 -8.45423e-01  1.52345e+00  1.08801e+00 -4.32434e-01
21Feb12_165056|  -3.16741e-01 -7.17985e-02  1.09877e+00 -7.90690e-01  1.36084e+00
21Feb12_165056|  -5.66120e-01 -1.70432e+00 -2.12910e+00 -2.41374e-01  1.33636e+00]
21Feb12_165056| [-4.08205e-01 -8.03871e-01  9.13990e-01  5.00916e-01 -1.81059e-01
21Feb12_165056|   2.42621e-01 -9.57869e-01  6.74094e-01  6.52179e-01  2.77279e-01
21Feb12_165056|  -3.91051e-01 -9.05321e-02  6.86316e-01 -3.54594e-01  5.83144e-01]
21Feb12_165056| [-3.98308e-01 -4.48018e-03  1.11987e+00  1.50374e+00 -9.18129e-01
21Feb12_165056|  -1.81690e+00 -1.38223e+00 -2.74481e-01 -8.24843e-01 -7.05820e-01
21Feb12_165056|   1.50584e+00 -4.21386e-01  4.00084e-01 -7.61841e-02 -7.41767e-01]
21Feb12_165056| [ 5.51762e-01 -1.04904e+00  5.21335e-01  2.14684e-01 -8.21795e-02
21Feb12_165056|   3.68556e-01  1.01222e+00 -1.30634e+00 -1.52652e+00  9.98379e-01
21Feb12_165056|   8.51997e-01 -9.42775e-01 -1.16577e-01  3.64988e-01 -1.27419e+00]
21Feb12_165056| [ 1.67425e+00 -1.27190e-01  2.44775e+00  1.44302e+00 -4.43112e-01
21Feb12_165056|  -4.07317e-02  1.33875e-01  4.92876e-01  1.36327e+00  3.41424e-01
21Feb12_165056|   1.70937e+00 -2.26414e+00  5.48087e-01 -2.49869e-01 -1.95666e+00]
21Feb12_165056| [-7.77069e-01  1.76839e+00 -5.99460e-01 -2.13769e+00  1.38006e+00
21Feb12_165056|   1.30623e+00 -1.06865e+00 -1.16462e+00  8.02528e-01 -3.99780e-01
21Feb12_165056|   8.20611e-01 -1.64613e-01  3.17174e-01  1.50755e+00  1.82851e-01]
21Feb12_165056| [-1.02989e+00 -1.07499e+00 -1.93091e+00  4.66271e-01 -8.74190e-01
21Feb12_165056|  -1.32185e+00 -9.08286e-01 -8.46363e-01  2.03651e-01 -2.52017e-01
21Feb12_165056|   1.15748e+00 -3.29038e-01 -5.53034e-01  6.31862e-01 -9.38469e-02]
21Feb12_165056| [-1.07650e+00  2.26383e-01  1.43406e-01 -1.04859e+00 -1.13255e+00
21Feb12_165056|   5.32942e-01 -2.81361e-01  1.06039e+00 -4.84886e-01  1.81779e+00
21Feb12_165056|   4.45898e-01  1.15599e-01  2.22637e+00 -1.10477e+00 -7.41273e-01]
21Feb12_165056| [ 5.36190e-01  1.36053e+00  1.86442e-01  1.76821e-01  1.73842e+00
21Feb12_165056|   1.33653e-01 -2.69435e-01  1.42842e+00 -6.67924e-01  8.34192e-01
21Feb12_165056|  -4.93949e-01  2.55190e-01  8.44813e-02  1.07023e+00  3.32795e-01]
21Feb12_165056| [-7.77858e-01  6.91255e-01 -2.00094e-01 -3.47804e-02  1.25963e+00
21Feb12_165056|   2.88406e-01  1.11181e-02 -1.72072e-01  1.74171e-01  1.07767e+00
21Feb12_165056|  -7.57539e-01 -1.51881e+00  1.13432e+00 -8.19687e-01  2.51036e-01]
21Feb12_165056| [ 1.17877e+00  8.51361e-01  5.34249e-01 -3.85201e-01  1.62741e+00
21Feb12_165056|   7.14108e-01 -2.49586e-01 -1.51061e+00 -5.78471e-01 -1.53573e+00
21Feb12_165056|  -6.82580e-01 -1.03046e+00  2.14369e+00 -2.12686e+00  2.93875e-01]
21Feb12_165056| [-5.46699e-01 -1.24367e-01  1.50400e+00  5.24570e-01  1.32199e-01
21Feb12_165056|  -1.11873e+00 -1.21781e-01  1.60716e+00  7.94494e-01  4.12000e-02
21Feb12_165056|  -1.45629e-01 -1.67069e+00  1.55359e+00  1.27490e+00  3.78250e-01]
21Feb12_165056| [-1.65770e+00  7.63010e-01 -1.07032e-01 -1.29077e+00 -2.72523e-01
21Feb12_165056|   8.86152e-01  2.03137e-02  1.07244e+00 -2.07611e+00  1.79718e-01
21Feb12_165056|   1.81554e-01 -6.15758e-01 -9.51774e-01  1.02939e+00  8.17973e-01]
21Feb12_165056| [ 9.21545e-01 -8.71244e-02 -1.53454e+00 -1.66686e+00  9.25583e-02
21Feb12_165056|   5.45788e-01  9.00588e-01  5.39148e-01  1.73423e+00  5.95858e-01
21Feb12_165056|   7.60598e-01  7.10163e-01 -1.92447e-01 -2.18648e-01 -1.06613e-01]
21Feb12_165056| [-1.27156e+00  1.50471e-01 -1.51367e+00  2.43159e-01  1.45374e+00
21Feb12_165056|   1.39069e-01  1.63857e+00  7.76127e-01  1.22775e-01 -9.15383e-01
21Feb12_165056|  -7.88206e-01 -1.88443e-01  5.88849e-01 -1.15889e+00  1.57532e+00]
21Feb12_165056| [-7.87307e-01  7.90368e-01 -8.23463e-01 -7.31497e-01 -1.23567e+00
21Feb12_165056|   4.22757e-01  3.63316e-02  6.01964e-01  1.96999e+00 -1.17414e+00
21Feb12_165056|   3.97797e-01 -1.08808e+00 -5.94358e-01 -2.83672e-01  8.50566e-01]
21Feb12_165056| [ 5.30769e-01 -1.84801e+00 -5.66134e-01  6.76585e-02  1.10136e-01
21Feb12_165056|   4.92367e-01 -4.90997e-01  6.06677e-01  2.28381e+00 -4.07746e-02
21Feb12_165056|   1.15850e+00 -5.98080e-01 -7.01578e-01  1.01957e+00  2.49859e-01]
21Feb12_165056| [-8.63352e-01  1.10102e+00 -1.35284e+00  7.44546e-01  1.23832e+00
21Feb12_165056|  -5.46095e-01 -7.14545e-01  6.39714e-01 -1.05446e-01 -8.88602e-01
21Feb12_165056|   9.93232e-01  1.94862e+00 -4.16105e-01  1.03489e-01  1.11977e+00]
21Feb12_165056| [ 1.19516e+00 -1.76346e-01  1.04128e-01  1.20697e+00 -9.23981e-01
21Feb12_165056|  -1.33787e+00 -2.81645e-01  4.54001e-01  1.13838e-01  7.67530e-01
21Feb12_165056|  -1.19224e+00 -1.30105e-01 -1.91934e-01  4.19944e-01  1.69825e-01]
21Feb12_165056| [ 7.65088e-01 -1.94246e+00 -7.11338e-01  4.53958e-01  1.94201e+00
21Feb12_165056|   1.31030e+00 -2.96434e-02 -1.76407e+00  5.53828e-01  6.85560e-01
21Feb12_165056|   7.66333e-01  3.82096e-02 -8.16458e-01 -6.24116e-02  2.64193e-01]
21Feb12_165056| [ 3.18200e-01  2.29948e+00  1.64715e+00  1.62897e+00 -7.51376e-02
21Feb12_165056|  -1.28841e+00 -6.20669e-01 -1.11166e-01  8.60402e-01 -1.33019e+00
21Feb12_165056|  -5.96012e-01  1.43903e+00  4.95090e-01 -5.77593e-01  1.44906e+00]
21Feb12_165056| [ 4.11040e-01  7.04946e-01 -5.20407e-01  1.19926e-01 -2.14187e-01
21Feb12_165056|   2.61836e-01 -2.06690e-01 -5.23044e-01 -2.21768e+00 -1.84159e+00
21Feb12_165056|   1.07890e-01 -1.21571e+00  1.41906e-02 -1.18878e+00 -1.10586e+00]
21Feb12_165056| [ 7.47110e-04 -2.19367e-01  1.24132e+00  2.42981e-01  1.64975e+00
21Feb12_165056|  -7.56681e-01  2.05047e+00  1.41699e+00  2.11413e-01  2.05856e-01
21Feb12_165056|  -1.19536e+00 -1.17721e+00 -5.74572e-02 -9.88771e-01 -5.21745e-02]
21Feb12_165056| [ 8.41039e-01 -7.80210e-01  1.63153e-01  9.11562e-01  1.96584e+00
21Feb12_165056|   1.78291e+00  1.27725e-01  9.24125e-01  8.89095e-01  8.02583e-01
21Feb12_165056|  -1.84072e-01 -1.83956e+00 -1.02407e+00  6.97260e-01  2.04119e+00]
21Feb12_165056| [ 1.02325e+00 -1.14512e+00  1.53735e+00 -1.20875e+00  2.40349e-01
21Feb12_165056|   3.65149e-01 -8.45853e-01 -9.53877e-01  1.08881e+00  1.31369e+00
21Feb12_165056|  -8.73629e-01  3.54768e-01 -1.44120e+00  3.00774e+00  5.37138e-01]
21Feb12_165056| [ 1.21153e+00  1.33780e+00  2.37346e-01  1.10192e+00 -7.71109e-01
21Feb12_165056|  -1.67297e+00 -9.85041e-01 -9.67469e-02  1.35584e-01  1.43828e+00
21Feb12_165056|  -5.37772e-01  6.81867e-01  8.99423e-02 -3.00140e-01  7.40803e-01]
21Feb12_165056| [-1.53912e-01 -1.45545e+00 -8.51719e-01 -3.24207e-01 -1.85297e+00
21Feb12_165056|  -1.37632e+00  2.56265e+00 -1.51591e+00 -7.70917e-01  1.60742e+00
21Feb12_165056|   8.19418e-01  1.51279e+00 -7.75504e-01 -4.56317e-01  7.93313e-01]
21Feb12_165056| [ 1.79234e+00  5.37534e-01 -1.64985e-01  1.12594e+00  4.19165e-01
21Feb12_165056|   1.00815e+00 -1.24029e+00  8.99015e-02  5.04534e-01  1.04688e+00
21Feb12_165056|  -1.85983e+00 -6.28367e-01  1.44747e+00 -7.70927e-01 -6.80962e-02]
21Feb12_165056| [-6.11685e-01  5.81244e-01 -2.00813e+00  4.40980e-01  1.17081e+00
21Feb12_165056|   4.53617e-02 -1.02732e-01 -5.30344e-01 -2.30272e-01 -2.75712e-01
21Feb12_165056|  -1.35628e+00  6.77073e-01  1.18206e+00 -9.68516e-01  8.88227e-01]
21Feb12_165056| [ 3.39330e-01  1.85906e-01  3.17199e+00 -1.14941e+00  8.41043e-01
21Feb12_165056|   1.43171e+00  2.91815e-01  9.90040e-01  2.43151e-01 -4.20123e-01
21Feb12_165056|  -7.71009e-01  8.26689e-01 -2.38729e-01  2.25124e-01  4.71938e-02]
21Feb12_165056| [-1.24769e+00 -1.74352e-01  1.33159e+00  6.31103e-01  1.39801e-01
21Feb12_165056|  -1.97232e-01  1.00881e+00 -1.05164e+00 -1.26316e-01 -6.77330e-01
21Feb12_165056|   6.93223e-01  3.09964e-01  4.46448e-01  3.28001e-01 -7.51083e-01]
21Feb12_165056| [-7.55157e-01 -1.20070e+00  1.18128e+00  2.31557e-01 -5.77142e-01
21Feb12_165056|   8.50621e-01 -6.80691e-01  1.14562e+00  6.53826e-01 -1.28380e+00
21Feb12_165056|   4.15503e-02  9.67591e-01 -3.56690e+00 -2.80446e-01 -2.39691e-01]
21Feb12_165056| [ 1.43065e+00  4.89999e-01  7.08940e-01  9.80815e-01 -5.25905e-01
21Feb12_165056|   8.92854e-01 -1.47577e+00 -9.27641e-02 -3.34619e-01 -1.41270e+00
21Feb12_165056|  -1.10591e+00  1.59163e+00  2.61333e-01 -1.48185e+00 -2.14182e+00]
21Feb12_165056| [ 8.38600e-01 -8.88508e-01 -4.12187e-01 -1.04812e-01  3.26908e-01
21Feb12_165056|  -9.83693e-01  1.67864e+00  7.72612e-01  1.95026e+00  9.57917e-01
21Feb12_165056|  -1.48928e+00 -1.99797e-01 -3.05136e-01 -1.14633e-01 -1.04672e+00]]
21Feb12_165056|-- Bias --
21Feb12_165056|[ 0.73695 -0.51772  1.29843 -0.86449  0.54318  0.17660 -0.21569  0.35471
21Feb12_165056| -0.23531 -0.15791  1.04286  0.77391 -0.11794  1.01790  0.50375]
21Feb12_165056|Layer 1:
21Feb12_165056|-- Config --
21Feb12_165056|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 15], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_165056|-- Weights --
21Feb12_165056|[[ 0.70443 -1.08724]
21Feb12_165056| [-0.44561 -1.05050]
21Feb12_165056| [ 0.25488  0.31427]
21Feb12_165056| [-1.40193  0.84859]
21Feb12_165056| [ 0.27127 -0.15942]
21Feb12_165056| [-0.18528 -0.14003]
21Feb12_165056| [ 1.68717  0.30442]
21Feb12_165056| [-0.01440  0.47743]
21Feb12_165056| [ 0.46612  0.57491]
21Feb12_165056| [-1.91613 -0.31596]
21Feb12_165056| [ 1.38318 -0.97860]
21Feb12_165056| [-0.49568  0.13334]
21Feb12_165056| [ 0.67487 -1.08400]
21Feb12_165056| [ 1.22898  1.13422]
21Feb12_165056| [ 0.14442 -0.69100]]
21Feb12_165056|-- Bias --
21Feb12_165056|[ 1.12271 -0.02168]
21Feb12_165056|Predicting the validation and test data with the Best final individual.
21Feb12_165103| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_165103|-----------  ------------------  --------------------  ----------
21Feb12_165103|Validation         42.17                  15            0.00258
21Feb12_165103|   Test            36.49                  15            0.00000
21Feb12_165103|-------------------- Test #6 --------------------
21Feb12_165103|Best final individual weights
21Feb12_165103|Individual:
21Feb12_165103|-- Constant hidden layers --
21Feb12_165103|False
21Feb12_165103|Layer 0:
21Feb12_165103|-- Config --
21Feb12_165103|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 15, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_165103|-- Weights --
21Feb12_165103|[[ 5.09617e-01  8.20902e-01 -3.02367e-01 -9.64837e-01 -4.33824e-01
21Feb12_165103|  -2.42034e-01 -5.04343e-01  1.31689e+00  9.21850e-01  5.13818e-01
21Feb12_165103|  -3.49854e-01  2.15852e-01 -1.04928e+00  7.68905e-01 -1.88324e+00]
21Feb12_165103| [-7.50915e-01 -2.52628e+00  3.69383e-01  1.39331e-01 -4.71230e-01
21Feb12_165103|   2.50267e+00 -2.55477e-01 -5.15419e-01 -2.31831e-01 -1.16548e+00
21Feb12_165103|  -8.22133e-01  4.82232e-01 -1.26500e+00  7.69663e-01  1.16647e+00]
21Feb12_165103| [ 4.01389e-03  9.01850e-01 -4.38696e-01 -7.91041e-01 -3.45664e-01
21Feb12_165103|  -1.66871e+00  1.65396e+00  7.90223e-01  5.51123e-01  1.67606e-01
21Feb12_165103|   2.12442e-01  1.14271e+00  6.42674e-01  2.00899e-01 -2.05944e-01]
21Feb12_165103| [ 1.80619e-01 -2.50060e-01 -1.12859e+00  1.83522e+00  1.81374e+00
21Feb12_165103|  -1.42416e+00  5.22823e-01 -7.02013e-01  1.84516e+00  1.90809e+00
21Feb12_165103|   1.37151e+00  4.03871e-02  4.29238e-01 -2.37117e-01 -1.00132e+00]
21Feb12_165103| [ 4.39871e-01  3.98574e-01 -3.75109e-01 -8.64825e-01  4.06425e-01
21Feb12_165103|   5.56500e-01  1.44148e+00 -5.22177e-01 -7.21740e-01  3.07682e-01
21Feb12_165103|  -9.52454e-01  8.44086e-01  1.09295e+00 -3.90444e-01  1.33545e+00]
21Feb12_165103| [-1.42180e+00  3.85641e-01 -8.43471e-02  1.81738e-02 -1.14521e+00
21Feb12_165103|  -8.06111e-01 -8.15090e-01  7.76165e-02  1.02784e+00  1.02123e-01
21Feb12_165103|   7.08213e-01  9.96943e-01 -7.79890e-01  1.66778e+00 -6.05761e-01]
21Feb12_165103| [-2.52774e-01 -9.61820e-01  3.02997e+00 -4.75355e-02  9.27908e-01
21Feb12_165103|   6.12327e-01 -4.65796e-01  8.85447e-01 -9.19731e-02  5.35502e-02
21Feb12_165103|  -5.61515e-01  1.22163e+00 -6.55581e-02 -4.23284e-01  6.78889e-01]
21Feb12_165103| [-4.07954e-01  7.89564e-01 -1.02275e+00 -1.42852e-01 -1.21182e-01
21Feb12_165103|   2.60288e+00  1.31219e+00 -1.05105e+00 -7.28076e-01  7.37981e-01
21Feb12_165103|   1.07877e+00  4.12772e-01  3.20972e-01 -1.42903e+00  5.49771e-01]
21Feb12_165103| [-1.06598e+00  4.11763e-01 -5.98736e-01 -1.02922e+00  1.44690e+00
21Feb12_165103|   1.61847e+00  7.86271e-01 -1.04439e+00 -1.22083e+00 -5.20594e-01
21Feb12_165103|   1.50709e+00 -2.76750e-01 -9.31489e-01  1.18032e+00 -1.34476e+00]
21Feb12_165103| [-9.84737e-01 -5.97909e-01 -5.05735e-01  1.21453e+00  2.04300e+00
21Feb12_165103|  -1.80226e+00  2.27960e-01  2.48235e-01 -9.14083e-01 -8.19925e-01
21Feb12_165103|   8.79325e-03  1.89321e+00 -2.33314e+00  3.64489e-01 -8.65853e-01]
21Feb12_165103| [-5.52147e-01 -1.09026e+00 -6.31263e-01 -9.85456e-02 -1.26793e+00
21Feb12_165103|   6.92239e-01  4.07591e-03  8.28704e-02 -4.61769e-01  1.47380e+00
21Feb12_165103|  -8.25050e-01  1.85307e+00 -7.02559e-01  4.42800e-01 -5.09351e-01]
21Feb12_165103| [-1.22241e+00 -2.82164e+00 -3.49419e-01  2.35780e-01 -3.06882e-01
21Feb12_165103|   4.97633e-01 -8.59745e-01  1.41005e+00  4.44223e-01  4.80295e-01
21Feb12_165103|   5.28514e-01 -8.52095e-01  7.93638e-01 -1.18061e+00  3.77575e-01]
21Feb12_165103| [ 1.83848e+00  1.86747e+00 -6.09064e-01 -1.29117e-01  8.20239e-01
21Feb12_165103|  -8.41223e-01 -4.91994e-01 -4.35134e-02 -3.10526e-01  8.12742e-01
21Feb12_165103|  -2.48499e+00  6.10492e-01  2.59825e-01  1.10740e+00  2.25110e-01]
21Feb12_165103| [-9.61110e-02  1.17814e+00  1.12148e-01 -3.49813e-01  2.43858e+00
21Feb12_165103|  -1.38613e+00 -3.82927e-01  1.52932e+00  8.48623e-01 -1.99483e+00
21Feb12_165103|  -2.12240e+00  1.06312e+00 -3.90781e-02  1.49640e+00  1.12926e+00]
21Feb12_165103| [-4.30616e-01  2.39031e-01 -7.23476e-01  1.25568e+00 -2.14845e-01
21Feb12_165103|  -5.53173e-01 -2.65699e+00  2.69230e-02 -1.00392e+00  1.32765e-01
21Feb12_165103|  -5.64005e-01  1.22524e+00  1.24383e+00 -1.09592e+00 -1.41796e+00]
21Feb12_165103| [-2.39791e-01  1.53064e+00  3.01720e-01  2.78106e-01 -1.84792e-01
21Feb12_165103|   1.56208e+00  9.94463e-01 -1.63904e+00  6.63295e-01 -1.85188e+00
21Feb12_165103|  -7.33287e-01 -1.62705e-01 -9.61094e-01  4.14256e-01 -1.81088e+00]
21Feb12_165103| [ 2.83794e-01  7.82624e-01  8.22930e-01  1.38834e+00  1.35777e+00
21Feb12_165103|   1.13137e+00 -4.51094e-01 -9.14736e-02 -4.29153e-01 -1.32003e-01
21Feb12_165103|  -1.06833e+00 -3.60741e-02 -1.72337e+00 -9.36812e-02 -1.50919e-01]
21Feb12_165103| [ 4.60832e-01 -6.41447e-01  7.19778e-01  1.43690e+00 -5.39012e-01
21Feb12_165103|   2.73839e+00  4.18203e-02  1.12728e+00 -1.96359e+00  5.08015e-01
21Feb12_165103|  -3.94637e-02  1.21425e+00  7.81562e-01  1.21240e+00  8.71932e-02]
21Feb12_165103| [ 7.21067e-01 -4.05470e-01  4.30706e-01 -1.12406e+00 -1.66416e-01
21Feb12_165103|  -1.74613e-01 -2.82475e+00  7.83187e-01 -1.70599e+00 -4.53800e-01
21Feb12_165103|   7.68700e-02  1.38626e+00  4.71260e-01 -1.20854e-01 -3.85957e-01]
21Feb12_165103| [-1.45393e+00 -4.35386e-01  7.35002e-01 -1.05813e+00 -6.41567e-01
21Feb12_165103|  -1.23953e+00 -1.11174e+00 -4.33161e-01  1.71285e+00 -1.69152e+00
21Feb12_165103|  -3.94477e-01 -9.64481e-01  2.12241e-01 -4.51296e-01  6.12573e-01]
21Feb12_165103| [ 1.91178e+00 -7.20020e-01 -1.43347e+00  6.16597e-01 -1.40631e-01
21Feb12_165103|   9.60419e-01 -2.94601e-01 -3.70235e-01  1.68500e-03 -7.06077e-02
21Feb12_165103|  -2.63686e+00 -7.93469e-01  3.46275e-01  2.04211e+00  9.19580e-01]
21Feb12_165103| [ 2.28690e-01 -1.52406e-01 -4.49362e-01 -7.32180e-01  7.99781e-01
21Feb12_165103|   4.88373e-01 -9.34696e-01 -5.02242e-01  9.68074e-01 -3.07760e-01
21Feb12_165103|  -3.49720e-01 -2.00695e+00 -4.45838e-01  2.62312e-01  3.38818e-01]
21Feb12_165103| [-1.98557e-01  8.34883e-01 -1.61905e-01  1.28379e+00  1.04073e+00
21Feb12_165103|   1.45833e+00  4.77341e-01  9.87420e-01 -3.08856e-01 -1.55031e+00
21Feb12_165103|   1.38023e+00 -4.42201e-01  1.78369e+00  8.01018e-01  1.52483e+00]
21Feb12_165103| [ 1.12967e+00 -8.45423e-01  1.52345e+00  1.08801e+00 -4.32434e-01
21Feb12_165103|  -3.16741e-01 -7.17985e-02  1.09877e+00 -7.90690e-01  1.36084e+00
21Feb12_165103|  -5.66120e-01 -1.70432e+00 -2.12910e+00 -2.41374e-01  1.33636e+00]
21Feb12_165103| [-4.08205e-01 -8.03871e-01  9.13990e-01  5.00916e-01 -1.81059e-01
21Feb12_165103|   2.42621e-01 -9.57869e-01  6.74094e-01  6.52179e-01  2.77279e-01
21Feb12_165103|  -3.91051e-01 -9.05321e-02  6.86316e-01 -3.54594e-01  5.83144e-01]
21Feb12_165103| [-3.98308e-01 -4.48018e-03  1.11987e+00  1.50374e+00 -9.18129e-01
21Feb12_165103|  -1.81690e+00 -1.38223e+00 -2.74481e-01 -8.24843e-01 -7.05820e-01
21Feb12_165103|   1.50584e+00 -4.21386e-01  4.00084e-01 -7.61841e-02 -7.41767e-01]
21Feb12_165103| [ 5.51762e-01 -1.04904e+00  5.21335e-01  2.14684e-01 -8.21795e-02
21Feb12_165103|   3.68556e-01  1.01222e+00 -1.30634e+00 -1.52652e+00  9.98379e-01
21Feb12_165103|   8.51997e-01 -9.42775e-01 -1.16577e-01  3.64988e-01 -1.27419e+00]
21Feb12_165103| [ 1.67425e+00 -1.27190e-01  2.44775e+00  1.44302e+00 -4.43112e-01
21Feb12_165103|  -4.07317e-02  1.33875e-01  4.92876e-01  1.36327e+00  3.41424e-01
21Feb12_165103|   1.70937e+00 -2.26414e+00  5.48087e-01 -2.49869e-01 -1.95666e+00]
21Feb12_165103| [-7.77069e-01  1.76839e+00 -5.99460e-01 -2.13769e+00  1.38006e+00
21Feb12_165103|   1.30623e+00 -1.06865e+00 -1.16462e+00  8.02528e-01 -3.99780e-01
21Feb12_165103|   8.20611e-01 -1.64613e-01  3.17174e-01  1.50755e+00  1.82851e-01]
21Feb12_165103| [-1.02989e+00 -1.07499e+00 -1.93091e+00  4.66271e-01 -8.74190e-01
21Feb12_165103|  -1.32185e+00 -9.08286e-01 -8.46363e-01  2.03651e-01 -2.52017e-01
21Feb12_165103|   1.15748e+00 -3.29038e-01 -5.53034e-01  6.31862e-01 -9.38469e-02]
21Feb12_165103| [-1.07650e+00  2.26383e-01  1.43406e-01 -1.04859e+00 -1.13255e+00
21Feb12_165103|   5.32942e-01 -2.81361e-01  1.06039e+00 -4.84886e-01  1.81779e+00
21Feb12_165103|   4.45898e-01  1.15599e-01  2.22637e+00 -1.10477e+00 -7.41273e-01]
21Feb12_165103| [ 5.36190e-01  1.36053e+00  1.86442e-01  1.76821e-01  1.73842e+00
21Feb12_165103|   1.33653e-01 -2.69435e-01  1.42842e+00 -6.67924e-01  8.34192e-01
21Feb12_165103|  -4.93949e-01  2.55190e-01  8.44813e-02  1.07023e+00  3.32795e-01]
21Feb12_165103| [-7.77858e-01  6.91255e-01 -2.00094e-01 -3.47804e-02  1.25963e+00
21Feb12_165103|   2.88406e-01  1.11181e-02 -1.72072e-01  1.74171e-01  1.07767e+00
21Feb12_165103|  -7.57539e-01 -1.51881e+00  1.13432e+00 -8.19687e-01  2.51036e-01]
21Feb12_165103| [ 1.17877e+00  8.51361e-01  5.34249e-01 -3.85201e-01  1.62741e+00
21Feb12_165103|   7.14108e-01 -2.49586e-01 -1.51061e+00 -5.78471e-01 -1.53573e+00
21Feb12_165103|  -6.82580e-01 -1.03046e+00  2.14369e+00 -2.12686e+00  2.93875e-01]
21Feb12_165103| [-5.46699e-01 -1.24367e-01  1.50400e+00  5.24570e-01  1.32199e-01
21Feb12_165103|  -1.11873e+00 -1.21781e-01  1.60716e+00  7.94494e-01  4.12000e-02
21Feb12_165103|  -1.45629e-01 -1.67069e+00  1.55359e+00  1.27490e+00  3.78250e-01]
21Feb12_165103| [-1.65770e+00  7.63010e-01 -1.07032e-01 -1.29077e+00 -2.72523e-01
21Feb12_165103|   8.86152e-01  2.03137e-02  1.07244e+00 -2.07611e+00  1.79718e-01
21Feb12_165103|   1.81554e-01 -6.15758e-01 -9.51774e-01  1.02939e+00  8.17973e-01]
21Feb12_165103| [ 9.21545e-01 -8.71244e-02 -1.53454e+00 -1.66686e+00  9.25583e-02
21Feb12_165103|   5.45788e-01  9.00588e-01  5.39148e-01  1.73423e+00  5.95858e-01
21Feb12_165103|   7.60598e-01  7.10163e-01 -1.92447e-01 -2.18648e-01 -1.06613e-01]
21Feb12_165103| [-1.27156e+00  1.50471e-01 -1.51367e+00  2.43159e-01  1.45374e+00
21Feb12_165103|   1.39069e-01  1.63857e+00  7.76127e-01  1.22775e-01 -9.15383e-01
21Feb12_165103|  -7.88206e-01 -1.88443e-01  5.88849e-01 -1.15889e+00  1.57532e+00]
21Feb12_165103| [-7.87307e-01  7.90368e-01 -8.23463e-01 -7.31497e-01 -1.23567e+00
21Feb12_165103|   4.22757e-01  3.63316e-02  6.01964e-01  1.96999e+00 -1.17414e+00
21Feb12_165103|   3.97797e-01 -1.08808e+00 -5.94358e-01 -2.83672e-01  8.50566e-01]
21Feb12_165103| [ 5.30769e-01 -1.84801e+00 -5.66134e-01  6.76585e-02  1.10136e-01
21Feb12_165103|   4.92367e-01 -4.90997e-01  6.06677e-01  2.28381e+00 -4.07746e-02
21Feb12_165103|   1.15850e+00 -5.98080e-01 -7.01578e-01  1.01957e+00  2.49859e-01]
21Feb12_165103| [-8.63352e-01  1.10102e+00 -1.35284e+00  7.44546e-01  1.23832e+00
21Feb12_165103|  -5.46095e-01 -7.14545e-01  6.39714e-01 -1.05446e-01 -8.88602e-01
21Feb12_165103|   9.93232e-01  1.94862e+00 -4.16105e-01  1.03489e-01  1.11977e+00]
21Feb12_165103| [ 1.19516e+00 -1.76346e-01  1.04128e-01  1.20697e+00 -9.23981e-01
21Feb12_165103|  -1.33787e+00 -2.81645e-01  4.54001e-01  1.13838e-01  7.67530e-01
21Feb12_165103|  -1.19224e+00 -1.30105e-01 -1.91934e-01  4.19944e-01  1.69825e-01]
21Feb12_165103| [ 7.65088e-01 -1.94246e+00 -7.11338e-01  4.53958e-01  1.94201e+00
21Feb12_165103|   1.31030e+00 -2.96434e-02 -1.76407e+00  5.53828e-01  6.85560e-01
21Feb12_165103|   7.66333e-01  3.82096e-02 -8.16458e-01 -6.24116e-02  2.64193e-01]
21Feb12_165103| [ 3.18200e-01  2.29948e+00  1.64715e+00  1.62897e+00 -7.51376e-02
21Feb12_165103|  -1.28841e+00 -6.20669e-01 -1.11166e-01  8.60402e-01 -1.33019e+00
21Feb12_165103|  -5.96012e-01  1.43903e+00  4.95090e-01 -5.77593e-01  1.44906e+00]
21Feb12_165103| [ 4.11040e-01  7.04946e-01 -5.20407e-01  1.19926e-01 -2.14187e-01
21Feb12_165103|   2.61836e-01 -2.06690e-01 -5.23044e-01 -2.21768e+00 -1.84159e+00
21Feb12_165103|   1.07890e-01 -1.21571e+00  1.41906e-02 -1.18878e+00 -1.10586e+00]
21Feb12_165103| [ 7.47110e-04 -2.19367e-01  1.24132e+00  2.42981e-01  1.64975e+00
21Feb12_165103|  -7.56681e-01  2.05047e+00  1.41699e+00  2.11413e-01  2.05856e-01
21Feb12_165103|  -1.19536e+00 -1.17721e+00 -5.74572e-02 -9.88771e-01 -5.21745e-02]
21Feb12_165103| [ 8.41039e-01 -7.80210e-01  1.63153e-01  9.11562e-01  1.96584e+00
21Feb12_165103|   1.78291e+00  1.27725e-01  9.24125e-01  8.89095e-01  8.02583e-01
21Feb12_165103|  -1.84072e-01 -1.83956e+00 -1.02407e+00  6.97260e-01  2.04119e+00]
21Feb12_165103| [ 1.02325e+00 -1.14512e+00  1.53735e+00 -1.20875e+00  2.40349e-01
21Feb12_165103|   3.65149e-01 -8.45853e-01 -9.53877e-01  1.08881e+00  1.31369e+00
21Feb12_165103|  -8.73629e-01  3.54768e-01 -1.44120e+00  3.00774e+00  5.37138e-01]
21Feb12_165103| [ 1.21153e+00  1.33780e+00  2.37346e-01  1.10192e+00 -7.71109e-01
21Feb12_165103|  -1.67297e+00 -9.85041e-01 -9.67469e-02  1.35584e-01  1.43828e+00
21Feb12_165103|  -5.37772e-01  6.81867e-01  8.99423e-02 -3.00140e-01  7.40803e-01]
21Feb12_165103| [-1.53912e-01 -1.45545e+00 -8.51719e-01 -3.24207e-01 -1.85297e+00
21Feb12_165103|  -1.37632e+00  2.56265e+00 -1.51591e+00 -7.70917e-01  1.60742e+00
21Feb12_165103|   8.19418e-01  1.51279e+00 -7.75504e-01 -4.56317e-01  7.93313e-01]
21Feb12_165103| [ 1.79234e+00  5.37534e-01 -1.64985e-01  1.12594e+00  4.19165e-01
21Feb12_165103|   1.00815e+00 -1.24029e+00  8.99015e-02  5.04534e-01  1.04688e+00
21Feb12_165103|  -1.85983e+00 -6.28367e-01  1.44747e+00 -7.70927e-01 -6.80962e-02]
21Feb12_165103| [-6.11685e-01  5.81244e-01 -2.00813e+00  4.40980e-01  1.17081e+00
21Feb12_165103|   4.53617e-02 -1.02732e-01 -5.30344e-01 -2.30272e-01 -2.75712e-01
21Feb12_165103|  -1.35628e+00  6.77073e-01  1.18206e+00 -9.68516e-01  8.88227e-01]
21Feb12_165103| [ 3.39330e-01  1.85906e-01  3.17199e+00 -1.14941e+00  8.41043e-01
21Feb12_165103|   1.43171e+00  2.91815e-01  9.90040e-01  2.43151e-01 -4.20123e-01
21Feb12_165103|  -7.71009e-01  8.26689e-01 -2.38729e-01  2.25124e-01  4.71938e-02]
21Feb12_165103| [-1.24769e+00 -1.74352e-01  1.33159e+00  6.31103e-01  1.39801e-01
21Feb12_165103|  -1.97232e-01  1.00881e+00 -1.05164e+00 -1.26316e-01 -6.77330e-01
21Feb12_165103|   6.93223e-01  3.09964e-01  4.46448e-01  3.28001e-01 -7.51083e-01]
21Feb12_165103| [-7.55157e-01 -1.20070e+00  1.18128e+00  2.31557e-01 -5.77142e-01
21Feb12_165103|   8.50621e-01 -6.80691e-01  1.14562e+00  6.53826e-01 -1.28380e+00
21Feb12_165103|   4.15503e-02  9.67591e-01 -3.56690e+00 -2.80446e-01 -2.39691e-01]
21Feb12_165103| [ 1.43065e+00  4.89999e-01  7.08940e-01  9.80815e-01 -5.25905e-01
21Feb12_165103|   8.92854e-01 -1.47577e+00 -9.27641e-02 -3.34619e-01 -1.41270e+00
21Feb12_165103|  -1.10591e+00  1.59163e+00  2.61333e-01 -1.48185e+00 -2.14182e+00]
21Feb12_165103| [ 8.38600e-01 -8.88508e-01 -4.12187e-01 -1.04812e-01  3.26908e-01
21Feb12_165103|  -9.83693e-01  1.67864e+00  7.72612e-01  1.95026e+00  9.57917e-01
21Feb12_165103|  -1.48928e+00 -1.99797e-01 -3.05136e-01 -1.14633e-01 -1.04672e+00]]
21Feb12_165103|-- Bias --
21Feb12_165103|[ 0.73695 -0.51772  1.29843 -0.86449  0.54318  0.17660 -0.21569  0.35471
21Feb12_165103| -0.23531 -0.15791  1.04286  0.77391 -0.11794  1.01790  0.50375]
21Feb12_165103|Layer 1:
21Feb12_165103|-- Config --
21Feb12_165103|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 15], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_165103|-- Weights --
21Feb12_165103|[[ 0.70443 -1.08724]
21Feb12_165103| [-0.44561 -1.05050]
21Feb12_165103| [ 0.25488  0.31427]
21Feb12_165103| [-1.40193  0.84859]
21Feb12_165103| [ 0.27127 -0.15942]
21Feb12_165103| [-0.18528 -0.14003]
21Feb12_165103| [ 1.68717  0.30442]
21Feb12_165103| [-0.01440  0.47743]
21Feb12_165103| [ 0.46612  0.57491]
21Feb12_165103| [-1.91613 -0.31596]
21Feb12_165103| [ 1.38318 -0.97860]
21Feb12_165103| [-0.49568  0.13334]
21Feb12_165103| [ 0.67487 -1.08400]
21Feb12_165103| [ 1.22898  1.13422]
21Feb12_165103| [ 0.14442 -0.69100]]
21Feb12_165103|-- Bias --
21Feb12_165103|[ 1.12271 -0.02168]
21Feb12_165103|Predicting the validation and test data with the Best final individual.
21Feb12_165110| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_165110|-----------  ------------------  --------------------  ----------
21Feb12_165110|Validation         41.91                  15            0.00259
21Feb12_165110|   Test            36.49                  15            0.00595
21Feb12_165110|-------------------- Test #7 --------------------
21Feb12_165110|Best final individual weights
21Feb12_165110|Individual:
21Feb12_165110|-- Constant hidden layers --
21Feb12_165110|False
21Feb12_165110|Layer 0:
21Feb12_165110|-- Config --
21Feb12_165110|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 15, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_165110|-- Weights --
21Feb12_165110|[[ 5.09617e-01  8.20902e-01 -3.02367e-01 -9.64837e-01 -4.33824e-01
21Feb12_165110|  -2.42034e-01 -5.04343e-01  1.31689e+00  9.21850e-01  5.13818e-01
21Feb12_165110|  -3.49854e-01  2.15852e-01 -1.04928e+00  7.68905e-01 -1.88324e+00]
21Feb12_165110| [-7.50915e-01 -2.52628e+00  3.69383e-01  1.39331e-01 -4.71230e-01
21Feb12_165110|   2.50267e+00 -2.55477e-01 -5.15419e-01 -2.31831e-01 -1.16548e+00
21Feb12_165110|  -8.22133e-01  4.82232e-01 -1.26500e+00  7.69663e-01  1.16647e+00]
21Feb12_165110| [ 4.01389e-03  9.01850e-01 -4.38696e-01 -7.91041e-01 -3.45664e-01
21Feb12_165110|  -1.66871e+00  1.65396e+00  7.90223e-01  5.51123e-01  1.67606e-01
21Feb12_165110|   2.12442e-01  1.14271e+00  6.42674e-01  2.00899e-01 -2.05944e-01]
21Feb12_165110| [ 1.80619e-01 -2.50060e-01 -1.12859e+00  1.83522e+00  1.81374e+00
21Feb12_165110|  -1.42416e+00  5.22823e-01 -7.02013e-01  1.84516e+00  1.90809e+00
21Feb12_165110|   1.37151e+00  4.03871e-02  4.29238e-01 -2.37117e-01 -1.00132e+00]
21Feb12_165110| [ 4.39871e-01  3.98574e-01 -3.75109e-01 -8.64825e-01  4.06425e-01
21Feb12_165110|   5.56500e-01  1.44148e+00 -5.22177e-01 -7.21740e-01  3.07682e-01
21Feb12_165110|  -9.52454e-01  8.44086e-01  1.09295e+00 -3.90444e-01  1.33545e+00]
21Feb12_165110| [-1.42180e+00  3.85641e-01 -8.43471e-02  1.81738e-02 -1.14521e+00
21Feb12_165110|  -8.06111e-01 -8.15090e-01  7.76165e-02  1.02784e+00  1.02123e-01
21Feb12_165110|   7.08213e-01  9.96943e-01 -7.79890e-01  1.66778e+00 -6.05761e-01]
21Feb12_165110| [-2.52774e-01 -9.61820e-01  3.02997e+00 -4.75355e-02  9.27908e-01
21Feb12_165110|   6.12327e-01 -4.65796e-01  8.85447e-01 -9.19731e-02  5.35502e-02
21Feb12_165110|  -5.61515e-01  1.22163e+00 -6.55581e-02 -4.23284e-01  6.78889e-01]
21Feb12_165110| [-4.07954e-01  7.89564e-01 -1.02275e+00 -1.42852e-01 -1.21182e-01
21Feb12_165110|   2.60288e+00  1.31219e+00 -1.05105e+00 -7.28076e-01  7.37981e-01
21Feb12_165110|   1.07877e+00  4.12772e-01  3.20972e-01 -1.42903e+00  5.49771e-01]
21Feb12_165110| [-1.06598e+00  4.11763e-01 -5.98736e-01 -1.02922e+00  1.44690e+00
21Feb12_165110|   1.61847e+00  7.86271e-01 -1.04439e+00 -1.22083e+00 -5.20594e-01
21Feb12_165110|   1.50709e+00 -2.76750e-01 -9.31489e-01  1.18032e+00 -1.34476e+00]
21Feb12_165110| [-9.84737e-01 -5.97909e-01 -5.05735e-01  1.21453e+00  2.04300e+00
21Feb12_165110|  -1.80226e+00  2.27960e-01  2.48235e-01 -9.14083e-01 -8.19925e-01
21Feb12_165110|   8.79325e-03  1.89321e+00 -2.33314e+00  3.64489e-01 -8.65853e-01]
21Feb12_165110| [-5.52147e-01 -1.09026e+00 -6.31263e-01 -9.85456e-02 -1.26793e+00
21Feb12_165110|   6.92239e-01  4.07591e-03  8.28704e-02 -4.61769e-01  1.47380e+00
21Feb12_165110|  -8.25050e-01  1.85307e+00 -7.02559e-01  4.42800e-01 -5.09351e-01]
21Feb12_165110| [-1.22241e+00 -2.82164e+00 -3.49419e-01  2.35780e-01 -3.06882e-01
21Feb12_165110|   4.97633e-01 -8.59745e-01  1.41005e+00  4.44223e-01  4.80295e-01
21Feb12_165110|   5.28514e-01 -8.52095e-01  7.93638e-01 -1.18061e+00  3.77575e-01]
21Feb12_165110| [ 1.83848e+00  1.86747e+00 -6.09064e-01 -1.29117e-01  8.20239e-01
21Feb12_165110|  -8.41223e-01 -4.91994e-01 -4.35134e-02 -3.10526e-01  8.12742e-01
21Feb12_165110|  -2.48499e+00  6.10492e-01  2.59825e-01  1.10740e+00  2.25110e-01]
21Feb12_165110| [-9.61110e-02  1.17814e+00  1.12148e-01 -3.49813e-01  2.43858e+00
21Feb12_165110|  -1.38613e+00 -3.82927e-01  1.52932e+00  8.48623e-01 -1.99483e+00
21Feb12_165110|  -2.12240e+00  1.06312e+00 -3.90781e-02  1.49640e+00  1.12926e+00]
21Feb12_165110| [-4.30616e-01  2.39031e-01 -7.23476e-01  1.25568e+00 -2.14845e-01
21Feb12_165110|  -5.53173e-01 -2.65699e+00  2.69230e-02 -1.00392e+00  1.32765e-01
21Feb12_165110|  -5.64005e-01  1.22524e+00  1.24383e+00 -1.09592e+00 -1.41796e+00]
21Feb12_165110| [-2.39791e-01  1.53064e+00  3.01720e-01  2.78106e-01 -1.84792e-01
21Feb12_165110|   1.56208e+00  9.94463e-01 -1.63904e+00  6.63295e-01 -1.85188e+00
21Feb12_165110|  -7.33287e-01 -1.62705e-01 -9.61094e-01  4.14256e-01 -1.81088e+00]
21Feb12_165110| [ 2.83794e-01  7.82624e-01  8.22930e-01  1.38834e+00  1.35777e+00
21Feb12_165110|   1.13137e+00 -4.51094e-01 -9.14736e-02 -4.29153e-01 -1.32003e-01
21Feb12_165110|  -1.06833e+00 -3.60741e-02 -1.72337e+00 -9.36812e-02 -1.50919e-01]
21Feb12_165110| [ 4.60832e-01 -6.41447e-01  7.19778e-01  1.43690e+00 -5.39012e-01
21Feb12_165110|   2.73839e+00  4.18203e-02  1.12728e+00 -1.96359e+00  5.08015e-01
21Feb12_165110|  -3.94637e-02  1.21425e+00  7.81562e-01  1.21240e+00  8.71932e-02]
21Feb12_165110| [ 7.21067e-01 -4.05470e-01  4.30706e-01 -1.12406e+00 -1.66416e-01
21Feb12_165110|  -1.74613e-01 -2.82475e+00  7.83187e-01 -1.70599e+00 -4.53800e-01
21Feb12_165110|   7.68700e-02  1.38626e+00  4.71260e-01 -1.20854e-01 -3.85957e-01]
21Feb12_165110| [-1.45393e+00 -4.35386e-01  7.35002e-01 -1.05813e+00 -6.41567e-01
21Feb12_165110|  -1.23953e+00 -1.11174e+00 -4.33161e-01  1.71285e+00 -1.69152e+00
21Feb12_165110|  -3.94477e-01 -9.64481e-01  2.12241e-01 -4.51296e-01  6.12573e-01]
21Feb12_165110| [ 1.91178e+00 -7.20020e-01 -1.43347e+00  6.16597e-01 -1.40631e-01
21Feb12_165110|   9.60419e-01 -2.94601e-01 -3.70235e-01  1.68500e-03 -7.06077e-02
21Feb12_165110|  -2.63686e+00 -7.93469e-01  3.46275e-01  2.04211e+00  9.19580e-01]
21Feb12_165110| [ 2.28690e-01 -1.52406e-01 -4.49362e-01 -7.32180e-01  7.99781e-01
21Feb12_165110|   4.88373e-01 -9.34696e-01 -5.02242e-01  9.68074e-01 -3.07760e-01
21Feb12_165110|  -3.49720e-01 -2.00695e+00 -4.45838e-01  2.62312e-01  3.38818e-01]
21Feb12_165110| [-1.98557e-01  8.34883e-01 -1.61905e-01  1.28379e+00  1.04073e+00
21Feb12_165110|   1.45833e+00  4.77341e-01  9.87420e-01 -3.08856e-01 -1.55031e+00
21Feb12_165110|   1.38023e+00 -4.42201e-01  1.78369e+00  8.01018e-01  1.52483e+00]
21Feb12_165110| [ 1.12967e+00 -8.45423e-01  1.52345e+00  1.08801e+00 -4.32434e-01
21Feb12_165110|  -3.16741e-01 -7.17985e-02  1.09877e+00 -7.90690e-01  1.36084e+00
21Feb12_165110|  -5.66120e-01 -1.70432e+00 -2.12910e+00 -2.41374e-01  1.33636e+00]
21Feb12_165110| [-4.08205e-01 -8.03871e-01  9.13990e-01  5.00916e-01 -1.81059e-01
21Feb12_165110|   2.42621e-01 -9.57869e-01  6.74094e-01  6.52179e-01  2.77279e-01
21Feb12_165110|  -3.91051e-01 -9.05321e-02  6.86316e-01 -3.54594e-01  5.83144e-01]
21Feb12_165110| [-3.98308e-01 -4.48018e-03  1.11987e+00  1.50374e+00 -9.18129e-01
21Feb12_165110|  -1.81690e+00 -1.38223e+00 -2.74481e-01 -8.24843e-01 -7.05820e-01
21Feb12_165110|   1.50584e+00 -4.21386e-01  4.00084e-01 -7.61841e-02 -7.41767e-01]
21Feb12_165110| [ 5.51762e-01 -1.04904e+00  5.21335e-01  2.14684e-01 -8.21795e-02
21Feb12_165110|   3.68556e-01  1.01222e+00 -1.30634e+00 -1.52652e+00  9.98379e-01
21Feb12_165110|   8.51997e-01 -9.42775e-01 -1.16577e-01  3.64988e-01 -1.27419e+00]
21Feb12_165110| [ 1.67425e+00 -1.27190e-01  2.44775e+00  1.44302e+00 -4.43112e-01
21Feb12_165110|  -4.07317e-02  1.33875e-01  4.92876e-01  1.36327e+00  3.41424e-01
21Feb12_165110|   1.70937e+00 -2.26414e+00  5.48087e-01 -2.49869e-01 -1.95666e+00]
21Feb12_165110| [-7.77069e-01  1.76839e+00 -5.99460e-01 -2.13769e+00  1.38006e+00
21Feb12_165110|   1.30623e+00 -1.06865e+00 -1.16462e+00  8.02528e-01 -3.99780e-01
21Feb12_165110|   8.20611e-01 -1.64613e-01  3.17174e-01  1.50755e+00  1.82851e-01]
21Feb12_165110| [-1.02989e+00 -1.07499e+00 -1.93091e+00  4.66271e-01 -8.74190e-01
21Feb12_165110|  -1.32185e+00 -9.08286e-01 -8.46363e-01  2.03651e-01 -2.52017e-01
21Feb12_165110|   1.15748e+00 -3.29038e-01 -5.53034e-01  6.31862e-01 -9.38469e-02]
21Feb12_165110| [-1.07650e+00  2.26383e-01  1.43406e-01 -1.04859e+00 -1.13255e+00
21Feb12_165110|   5.32942e-01 -2.81361e-01  1.06039e+00 -4.84886e-01  1.81779e+00
21Feb12_165110|   4.45898e-01  1.15599e-01  2.22637e+00 -1.10477e+00 -7.41273e-01]
21Feb12_165110| [ 5.36190e-01  1.36053e+00  1.86442e-01  1.76821e-01  1.73842e+00
21Feb12_165110|   1.33653e-01 -2.69435e-01  1.42842e+00 -6.67924e-01  8.34192e-01
21Feb12_165110|  -4.93949e-01  2.55190e-01  8.44813e-02  1.07023e+00  3.32795e-01]
21Feb12_165110| [-7.77858e-01  6.91255e-01 -2.00094e-01 -3.47804e-02  1.25963e+00
21Feb12_165110|   2.88406e-01  1.11181e-02 -1.72072e-01  1.74171e-01  1.07767e+00
21Feb12_165110|  -7.57539e-01 -1.51881e+00  1.13432e+00 -8.19687e-01  2.51036e-01]
21Feb12_165110| [ 1.17877e+00  8.51361e-01  5.34249e-01 -3.85201e-01  1.62741e+00
21Feb12_165110|   7.14108e-01 -2.49586e-01 -1.51061e+00 -5.78471e-01 -1.53573e+00
21Feb12_165110|  -6.82580e-01 -1.03046e+00  2.14369e+00 -2.12686e+00  2.93875e-01]
21Feb12_165110| [-5.46699e-01 -1.24367e-01  1.50400e+00  5.24570e-01  1.32199e-01
21Feb12_165110|  -1.11873e+00 -1.21781e-01  1.60716e+00  7.94494e-01  4.12000e-02
21Feb12_165110|  -1.45629e-01 -1.67069e+00  1.55359e+00  1.27490e+00  3.78250e-01]
21Feb12_165110| [-1.65770e+00  7.63010e-01 -1.07032e-01 -1.29077e+00 -2.72523e-01
21Feb12_165110|   8.86152e-01  2.03137e-02  1.07244e+00 -2.07611e+00  1.79718e-01
21Feb12_165110|   1.81554e-01 -6.15758e-01 -9.51774e-01  1.02939e+00  8.17973e-01]
21Feb12_165110| [ 9.21545e-01 -8.71244e-02 -1.53454e+00 -1.66686e+00  9.25583e-02
21Feb12_165110|   5.45788e-01  9.00588e-01  5.39148e-01  1.73423e+00  5.95858e-01
21Feb12_165110|   7.60598e-01  7.10163e-01 -1.92447e-01 -2.18648e-01 -1.06613e-01]
21Feb12_165110| [-1.27156e+00  1.50471e-01 -1.51367e+00  2.43159e-01  1.45374e+00
21Feb12_165110|   1.39069e-01  1.63857e+00  7.76127e-01  1.22775e-01 -9.15383e-01
21Feb12_165110|  -7.88206e-01 -1.88443e-01  5.88849e-01 -1.15889e+00  1.57532e+00]
21Feb12_165110| [-7.87307e-01  7.90368e-01 -8.23463e-01 -7.31497e-01 -1.23567e+00
21Feb12_165110|   4.22757e-01  3.63316e-02  6.01964e-01  1.96999e+00 -1.17414e+00
21Feb12_165110|   3.97797e-01 -1.08808e+00 -5.94358e-01 -2.83672e-01  8.50566e-01]
21Feb12_165110| [ 5.30769e-01 -1.84801e+00 -5.66134e-01  6.76585e-02  1.10136e-01
21Feb12_165110|   4.92367e-01 -4.90997e-01  6.06677e-01  2.28381e+00 -4.07746e-02
21Feb12_165110|   1.15850e+00 -5.98080e-01 -7.01578e-01  1.01957e+00  2.49859e-01]
21Feb12_165110| [-8.63352e-01  1.10102e+00 -1.35284e+00  7.44546e-01  1.23832e+00
21Feb12_165110|  -5.46095e-01 -7.14545e-01  6.39714e-01 -1.05446e-01 -8.88602e-01
21Feb12_165110|   9.93232e-01  1.94862e+00 -4.16105e-01  1.03489e-01  1.11977e+00]
21Feb12_165110| [ 1.19516e+00 -1.76346e-01  1.04128e-01  1.20697e+00 -9.23981e-01
21Feb12_165110|  -1.33787e+00 -2.81645e-01  4.54001e-01  1.13838e-01  7.67530e-01
21Feb12_165110|  -1.19224e+00 -1.30105e-01 -1.91934e-01  4.19944e-01  1.69825e-01]
21Feb12_165110| [ 7.65088e-01 -1.94246e+00 -7.11338e-01  4.53958e-01  1.94201e+00
21Feb12_165110|   1.31030e+00 -2.96434e-02 -1.76407e+00  5.53828e-01  6.85560e-01
21Feb12_165110|   7.66333e-01  3.82096e-02 -8.16458e-01 -6.24116e-02  2.64193e-01]
21Feb12_165110| [ 3.18200e-01  2.29948e+00  1.64715e+00  1.62897e+00 -7.51376e-02
21Feb12_165110|  -1.28841e+00 -6.20669e-01 -1.11166e-01  8.60402e-01 -1.33019e+00
21Feb12_165110|  -5.96012e-01  1.43903e+00  4.95090e-01 -5.77593e-01  1.44906e+00]
21Feb12_165110| [ 4.11040e-01  7.04946e-01 -5.20407e-01  1.19926e-01 -2.14187e-01
21Feb12_165110|   2.61836e-01 -2.06690e-01 -5.23044e-01 -2.21768e+00 -1.84159e+00
21Feb12_165110|   1.07890e-01 -1.21571e+00  1.41906e-02 -1.18878e+00 -1.10586e+00]
21Feb12_165110| [ 7.47110e-04 -2.19367e-01  1.24132e+00  2.42981e-01  1.64975e+00
21Feb12_165110|  -7.56681e-01  2.05047e+00  1.41699e+00  2.11413e-01  2.05856e-01
21Feb12_165110|  -1.19536e+00 -1.17721e+00 -5.74572e-02 -9.88771e-01 -5.21745e-02]
21Feb12_165110| [ 8.41039e-01 -7.80210e-01  1.63153e-01  9.11562e-01  1.96584e+00
21Feb12_165110|   1.78291e+00  1.27725e-01  9.24125e-01  8.89095e-01  8.02583e-01
21Feb12_165110|  -1.84072e-01 -1.83956e+00 -1.02407e+00  6.97260e-01  2.04119e+00]
21Feb12_165110| [ 1.02325e+00 -1.14512e+00  1.53735e+00 -1.20875e+00  2.40349e-01
21Feb12_165110|   3.65149e-01 -8.45853e-01 -9.53877e-01  1.08881e+00  1.31369e+00
21Feb12_165110|  -8.73629e-01  3.54768e-01 -1.44120e+00  3.00774e+00  5.37138e-01]
21Feb12_165110| [ 1.21153e+00  1.33780e+00  2.37346e-01  1.10192e+00 -7.71109e-01
21Feb12_165110|  -1.67297e+00 -9.85041e-01 -9.67469e-02  1.35584e-01  1.43828e+00
21Feb12_165110|  -5.37772e-01  6.81867e-01  8.99423e-02 -3.00140e-01  7.40803e-01]
21Feb12_165110| [-1.53912e-01 -1.45545e+00 -8.51719e-01 -3.24207e-01 -1.85297e+00
21Feb12_165110|  -1.37632e+00  2.56265e+00 -1.51591e+00 -7.70917e-01  1.60742e+00
21Feb12_165110|   8.19418e-01  1.51279e+00 -7.75504e-01 -4.56317e-01  7.93313e-01]
21Feb12_165110| [ 1.79234e+00  5.37534e-01 -1.64985e-01  1.12594e+00  4.19165e-01
21Feb12_165110|   1.00815e+00 -1.24029e+00  8.99015e-02  5.04534e-01  1.04688e+00
21Feb12_165110|  -1.85983e+00 -6.28367e-01  1.44747e+00 -7.70927e-01 -6.80962e-02]
21Feb12_165110| [-6.11685e-01  5.81244e-01 -2.00813e+00  4.40980e-01  1.17081e+00
21Feb12_165110|   4.53617e-02 -1.02732e-01 -5.30344e-01 -2.30272e-01 -2.75712e-01
21Feb12_165110|  -1.35628e+00  6.77073e-01  1.18206e+00 -9.68516e-01  8.88227e-01]
21Feb12_165110| [ 3.39330e-01  1.85906e-01  3.17199e+00 -1.14941e+00  8.41043e-01
21Feb12_165110|   1.43171e+00  2.91815e-01  9.90040e-01  2.43151e-01 -4.20123e-01
21Feb12_165110|  -7.71009e-01  8.26689e-01 -2.38729e-01  2.25124e-01  4.71938e-02]
21Feb12_165110| [-1.24769e+00 -1.74352e-01  1.33159e+00  6.31103e-01  1.39801e-01
21Feb12_165110|  -1.97232e-01  1.00881e+00 -1.05164e+00 -1.26316e-01 -6.77330e-01
21Feb12_165110|   6.93223e-01  3.09964e-01  4.46448e-01  3.28001e-01 -7.51083e-01]
21Feb12_165110| [-7.55157e-01 -1.20070e+00  1.18128e+00  2.31557e-01 -5.77142e-01
21Feb12_165110|   8.50621e-01 -6.80691e-01  1.14562e+00  6.53826e-01 -1.28380e+00
21Feb12_165110|   4.15503e-02  9.67591e-01 -3.56690e+00 -2.80446e-01 -2.39691e-01]
21Feb12_165110| [ 1.43065e+00  4.89999e-01  7.08940e-01  9.80815e-01 -5.25905e-01
21Feb12_165110|   8.92854e-01 -1.47577e+00 -9.27641e-02 -3.34619e-01 -1.41270e+00
21Feb12_165110|  -1.10591e+00  1.59163e+00  2.61333e-01 -1.48185e+00 -2.14182e+00]
21Feb12_165110| [ 8.38600e-01 -8.88508e-01 -4.12187e-01 -1.04812e-01  3.26908e-01
21Feb12_165110|  -9.83693e-01  1.67864e+00  7.72612e-01  1.95026e+00  9.57917e-01
21Feb12_165110|  -1.48928e+00 -1.99797e-01 -3.05136e-01 -1.14633e-01 -1.04672e+00]]
21Feb12_165110|-- Bias --
21Feb12_165110|[ 0.73695 -0.51772  1.29843 -0.86449  0.54318  0.17660 -0.21569  0.35471
21Feb12_165110| -0.23531 -0.15791  1.04286  0.77391 -0.11794  1.01790  0.50375]
21Feb12_165110|Layer 1:
21Feb12_165110|-- Config --
21Feb12_165110|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 15], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_165110|-- Weights --
21Feb12_165110|[[ 0.70443 -1.08724]
21Feb12_165110| [-0.44561 -1.05050]
21Feb12_165110| [ 0.25488  0.31427]
21Feb12_165110| [-1.40193  0.84859]
21Feb12_165110| [ 0.27127 -0.15942]
21Feb12_165110| [-0.18528 -0.14003]
21Feb12_165110| [ 1.68717  0.30442]
21Feb12_165110| [-0.01440  0.47743]
21Feb12_165110| [ 0.46612  0.57491]
21Feb12_165110| [-1.91613 -0.31596]
21Feb12_165110| [ 1.38318 -0.97860]
21Feb12_165110| [-0.49568  0.13334]
21Feb12_165110| [ 0.67487 -1.08400]
21Feb12_165110| [ 1.22898  1.13422]
21Feb12_165110| [ 0.14442 -0.69100]]
21Feb12_165110|-- Bias --
21Feb12_165110|[ 1.12271 -0.02168]
21Feb12_165110|Predicting the validation and test data with the Best final individual.
21Feb12_165117| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_165117|-----------  ------------------  --------------------  ----------
21Feb12_165117|Validation         41.39                  15            0.02061
21Feb12_165117|   Test            36.66                  15            0.00000
21Feb12_165117|-------------------- Test #8 --------------------
21Feb12_165117|Best final individual weights
21Feb12_165117|Individual:
21Feb12_165117|-- Constant hidden layers --
21Feb12_165117|False
21Feb12_165117|Layer 0:
21Feb12_165117|-- Config --
21Feb12_165117|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 15, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_165117|-- Weights --
21Feb12_165117|[[ 5.09617e-01  8.20902e-01 -3.02367e-01 -9.64837e-01 -4.33824e-01
21Feb12_165117|  -2.42034e-01 -5.04343e-01  1.31689e+00  9.21850e-01  5.13818e-01
21Feb12_165117|  -3.49854e-01  2.15852e-01 -1.04928e+00  7.68905e-01 -1.88324e+00]
21Feb12_165117| [-7.50915e-01 -2.52628e+00  3.69383e-01  1.39331e-01 -4.71230e-01
21Feb12_165117|   2.50267e+00 -2.55477e-01 -5.15419e-01 -2.31831e-01 -1.16548e+00
21Feb12_165117|  -8.22133e-01  4.82232e-01 -1.26500e+00  7.69663e-01  1.16647e+00]
21Feb12_165117| [ 4.01389e-03  9.01850e-01 -4.38696e-01 -7.91041e-01 -3.45664e-01
21Feb12_165117|  -1.66871e+00  1.65396e+00  7.90223e-01  5.51123e-01  1.67606e-01
21Feb12_165117|   2.12442e-01  1.14271e+00  6.42674e-01  2.00899e-01 -2.05944e-01]
21Feb12_165117| [ 1.80619e-01 -2.50060e-01 -1.12859e+00  1.83522e+00  1.81374e+00
21Feb12_165117|  -1.42416e+00  5.22823e-01 -7.02013e-01  1.84516e+00  1.90809e+00
21Feb12_165117|   1.37151e+00  4.03871e-02  4.29238e-01 -2.37117e-01 -1.00132e+00]
21Feb12_165117| [ 4.39871e-01  3.98574e-01 -3.75109e-01 -8.64825e-01  4.06425e-01
21Feb12_165117|   5.56500e-01  1.44148e+00 -5.22177e-01 -7.21740e-01  3.07682e-01
21Feb12_165117|  -9.52454e-01  8.44086e-01  1.09295e+00 -3.90444e-01  1.33545e+00]
21Feb12_165117| [-1.42180e+00  3.85641e-01 -8.43471e-02  1.81738e-02 -1.14521e+00
21Feb12_165117|  -8.06111e-01 -8.15090e-01  7.76165e-02  1.02784e+00  1.02123e-01
21Feb12_165117|   7.08213e-01  9.96943e-01 -7.79890e-01  1.66778e+00 -6.05761e-01]
21Feb12_165117| [-2.52774e-01 -9.61820e-01  3.02997e+00 -4.75355e-02  9.27908e-01
21Feb12_165117|   6.12327e-01 -4.65796e-01  8.85447e-01 -9.19731e-02  5.35502e-02
21Feb12_165117|  -5.61515e-01  1.22163e+00 -6.55581e-02 -4.23284e-01  6.78889e-01]
21Feb12_165117| [-4.07954e-01  7.89564e-01 -1.02275e+00 -1.42852e-01 -1.21182e-01
21Feb12_165117|   2.60288e+00  1.31219e+00 -1.05105e+00 -7.28076e-01  7.37981e-01
21Feb12_165117|   1.07877e+00  4.12772e-01  3.20972e-01 -1.42903e+00  5.49771e-01]
21Feb12_165117| [-1.06598e+00  4.11763e-01 -5.98736e-01 -1.02922e+00  1.44690e+00
21Feb12_165117|   1.61847e+00  7.86271e-01 -1.04439e+00 -1.22083e+00 -5.20594e-01
21Feb12_165117|   1.50709e+00 -2.76750e-01 -9.31489e-01  1.18032e+00 -1.34476e+00]
21Feb12_165117| [-9.84737e-01 -5.97909e-01 -5.05735e-01  1.21453e+00  2.04300e+00
21Feb12_165117|  -1.80226e+00  2.27960e-01  2.48235e-01 -9.14083e-01 -8.19925e-01
21Feb12_165117|   8.79325e-03  1.89321e+00 -2.33314e+00  3.64489e-01 -8.65853e-01]
21Feb12_165117| [-5.52147e-01 -1.09026e+00 -6.31263e-01 -9.85456e-02 -1.26793e+00
21Feb12_165117|   6.92239e-01  4.07591e-03  8.28704e-02 -4.61769e-01  1.47380e+00
21Feb12_165117|  -8.25050e-01  1.85307e+00 -7.02559e-01  4.42800e-01 -5.09351e-01]
21Feb12_165117| [-1.22241e+00 -2.82164e+00 -3.49419e-01  2.35780e-01 -3.06882e-01
21Feb12_165117|   4.97633e-01 -8.59745e-01  1.41005e+00  4.44223e-01  4.80295e-01
21Feb12_165117|   5.28514e-01 -8.52095e-01  7.93638e-01 -1.18061e+00  3.77575e-01]
21Feb12_165117| [ 1.83848e+00  1.86747e+00 -6.09064e-01 -1.29117e-01  8.20239e-01
21Feb12_165117|  -8.41223e-01 -4.91994e-01 -4.35134e-02 -3.10526e-01  8.12742e-01
21Feb12_165117|  -2.48499e+00  6.10492e-01  2.59825e-01  1.10740e+00  2.25110e-01]
21Feb12_165117| [-9.61110e-02  1.17814e+00  1.12148e-01 -3.49813e-01  2.43858e+00
21Feb12_165117|  -1.38613e+00 -3.82927e-01  1.52932e+00  8.48623e-01 -1.99483e+00
21Feb12_165117|  -2.12240e+00  1.06312e+00 -3.90781e-02  1.49640e+00  1.12926e+00]
21Feb12_165117| [-4.30616e-01  2.39031e-01 -7.23476e-01  1.25568e+00 -2.14845e-01
21Feb12_165117|  -5.53173e-01 -2.65699e+00  2.69230e-02 -1.00392e+00  1.32765e-01
21Feb12_165117|  -5.64005e-01  1.22524e+00  1.24383e+00 -1.09592e+00 -1.41796e+00]
21Feb12_165117| [-2.39791e-01  1.53064e+00  3.01720e-01  2.78106e-01 -1.84792e-01
21Feb12_165117|   1.56208e+00  9.94463e-01 -1.63904e+00  6.63295e-01 -1.85188e+00
21Feb12_165117|  -7.33287e-01 -1.62705e-01 -9.61094e-01  4.14256e-01 -1.81088e+00]
21Feb12_165117| [ 2.83794e-01  7.82624e-01  8.22930e-01  1.38834e+00  1.35777e+00
21Feb12_165117|   1.13137e+00 -4.51094e-01 -9.14736e-02 -4.29153e-01 -1.32003e-01
21Feb12_165117|  -1.06833e+00 -3.60741e-02 -1.72337e+00 -9.36812e-02 -1.50919e-01]
21Feb12_165117| [ 4.60832e-01 -6.41447e-01  7.19778e-01  1.43690e+00 -5.39012e-01
21Feb12_165117|   2.73839e+00  4.18203e-02  1.12728e+00 -1.96359e+00  5.08015e-01
21Feb12_165117|  -3.94637e-02  1.21425e+00  7.81562e-01  1.21240e+00  8.71932e-02]
21Feb12_165117| [ 7.21067e-01 -4.05470e-01  4.30706e-01 -1.12406e+00 -1.66416e-01
21Feb12_165117|  -1.74613e-01 -2.82475e+00  7.83187e-01 -1.70599e+00 -4.53800e-01
21Feb12_165117|   7.68700e-02  1.38626e+00  4.71260e-01 -1.20854e-01 -3.85957e-01]
21Feb12_165117| [-1.45393e+00 -4.35386e-01  7.35002e-01 -1.05813e+00 -6.41567e-01
21Feb12_165117|  -1.23953e+00 -1.11174e+00 -4.33161e-01  1.71285e+00 -1.69152e+00
21Feb12_165117|  -3.94477e-01 -9.64481e-01  2.12241e-01 -4.51296e-01  6.12573e-01]
21Feb12_165117| [ 1.91178e+00 -7.20020e-01 -1.43347e+00  6.16597e-01 -1.40631e-01
21Feb12_165117|   9.60419e-01 -2.94601e-01 -3.70235e-01  1.68500e-03 -7.06077e-02
21Feb12_165117|  -2.63686e+00 -7.93469e-01  3.46275e-01  2.04211e+00  9.19580e-01]
21Feb12_165117| [ 2.28690e-01 -1.52406e-01 -4.49362e-01 -7.32180e-01  7.99781e-01
21Feb12_165117|   4.88373e-01 -9.34696e-01 -5.02242e-01  9.68074e-01 -3.07760e-01
21Feb12_165117|  -3.49720e-01 -2.00695e+00 -4.45838e-01  2.62312e-01  3.38818e-01]
21Feb12_165117| [-1.98557e-01  8.34883e-01 -1.61905e-01  1.28379e+00  1.04073e+00
21Feb12_165117|   1.45833e+00  4.77341e-01  9.87420e-01 -3.08856e-01 -1.55031e+00
21Feb12_165117|   1.38023e+00 -4.42201e-01  1.78369e+00  8.01018e-01  1.52483e+00]
21Feb12_165117| [ 1.12967e+00 -8.45423e-01  1.52345e+00  1.08801e+00 -4.32434e-01
21Feb12_165117|  -3.16741e-01 -7.17985e-02  1.09877e+00 -7.90690e-01  1.36084e+00
21Feb12_165117|  -5.66120e-01 -1.70432e+00 -2.12910e+00 -2.41374e-01  1.33636e+00]
21Feb12_165117| [-4.08205e-01 -8.03871e-01  9.13990e-01  5.00916e-01 -1.81059e-01
21Feb12_165117|   2.42621e-01 -9.57869e-01  6.74094e-01  6.52179e-01  2.77279e-01
21Feb12_165117|  -3.91051e-01 -9.05321e-02  6.86316e-01 -3.54594e-01  5.83144e-01]
21Feb12_165117| [-3.98308e-01 -4.48018e-03  1.11987e+00  1.50374e+00 -9.18129e-01
21Feb12_165117|  -1.81690e+00 -1.38223e+00 -2.74481e-01 -8.24843e-01 -7.05820e-01
21Feb12_165117|   1.50584e+00 -4.21386e-01  4.00084e-01 -7.61841e-02 -7.41767e-01]
21Feb12_165117| [ 5.51762e-01 -1.04904e+00  5.21335e-01  2.14684e-01 -8.21795e-02
21Feb12_165117|   3.68556e-01  1.01222e+00 -1.30634e+00 -1.52652e+00  9.98379e-01
21Feb12_165117|   8.51997e-01 -9.42775e-01 -1.16577e-01  3.64988e-01 -1.27419e+00]
21Feb12_165117| [ 1.67425e+00 -1.27190e-01  2.44775e+00  1.44302e+00 -4.43112e-01
21Feb12_165117|  -4.07317e-02  1.33875e-01  4.92876e-01  1.36327e+00  3.41424e-01
21Feb12_165117|   1.70937e+00 -2.26414e+00  5.48087e-01 -2.49869e-01 -1.95666e+00]
21Feb12_165117| [-7.77069e-01  1.76839e+00 -5.99460e-01 -2.13769e+00  1.38006e+00
21Feb12_165117|   1.30623e+00 -1.06865e+00 -1.16462e+00  8.02528e-01 -3.99780e-01
21Feb12_165117|   8.20611e-01 -1.64613e-01  3.17174e-01  1.50755e+00  1.82851e-01]
21Feb12_165117| [-1.02989e+00 -1.07499e+00 -1.93091e+00  4.66271e-01 -8.74190e-01
21Feb12_165117|  -1.32185e+00 -9.08286e-01 -8.46363e-01  2.03651e-01 -2.52017e-01
21Feb12_165117|   1.15748e+00 -3.29038e-01 -5.53034e-01  6.31862e-01 -9.38469e-02]
21Feb12_165117| [-1.07650e+00  2.26383e-01  1.43406e-01 -1.04859e+00 -1.13255e+00
21Feb12_165117|   5.32942e-01 -2.81361e-01  1.06039e+00 -4.84886e-01  1.81779e+00
21Feb12_165117|   4.45898e-01  1.15599e-01  2.22637e+00 -1.10477e+00 -7.41273e-01]
21Feb12_165117| [ 5.36190e-01  1.36053e+00  1.86442e-01  1.76821e-01  1.73842e+00
21Feb12_165117|   1.33653e-01 -2.69435e-01  1.42842e+00 -6.67924e-01  8.34192e-01
21Feb12_165117|  -4.93949e-01  2.55190e-01  8.44813e-02  1.07023e+00  3.32795e-01]
21Feb12_165117| [-7.77858e-01  6.91255e-01 -2.00094e-01 -3.47804e-02  1.25963e+00
21Feb12_165117|   2.88406e-01  1.11181e-02 -1.72072e-01  1.74171e-01  1.07767e+00
21Feb12_165117|  -7.57539e-01 -1.51881e+00  1.13432e+00 -8.19687e-01  2.51036e-01]
21Feb12_165117| [ 1.17877e+00  8.51361e-01  5.34249e-01 -3.85201e-01  1.62741e+00
21Feb12_165117|   7.14108e-01 -2.49586e-01 -1.51061e+00 -5.78471e-01 -1.53573e+00
21Feb12_165117|  -6.82580e-01 -1.03046e+00  2.14369e+00 -2.12686e+00  2.93875e-01]
21Feb12_165117| [-5.46699e-01 -1.24367e-01  1.50400e+00  5.24570e-01  1.32199e-01
21Feb12_165117|  -1.11873e+00 -1.21781e-01  1.60716e+00  7.94494e-01  4.12000e-02
21Feb12_165117|  -1.45629e-01 -1.67069e+00  1.55359e+00  1.27490e+00  3.78250e-01]
21Feb12_165117| [-1.65770e+00  7.63010e-01 -1.07032e-01 -1.29077e+00 -2.72523e-01
21Feb12_165117|   8.86152e-01  2.03137e-02  1.07244e+00 -2.07611e+00  1.79718e-01
21Feb12_165117|   1.81554e-01 -6.15758e-01 -9.51774e-01  1.02939e+00  8.17973e-01]
21Feb12_165117| [ 9.21545e-01 -8.71244e-02 -1.53454e+00 -1.66686e+00  9.25583e-02
21Feb12_165117|   5.45788e-01  9.00588e-01  5.39148e-01  1.73423e+00  5.95858e-01
21Feb12_165117|   7.60598e-01  7.10163e-01 -1.92447e-01 -2.18648e-01 -1.06613e-01]
21Feb12_165117| [-1.27156e+00  1.50471e-01 -1.51367e+00  2.43159e-01  1.45374e+00
21Feb12_165117|   1.39069e-01  1.63857e+00  7.76127e-01  1.22775e-01 -9.15383e-01
21Feb12_165117|  -7.88206e-01 -1.88443e-01  5.88849e-01 -1.15889e+00  1.57532e+00]
21Feb12_165117| [-7.87307e-01  7.90368e-01 -8.23463e-01 -7.31497e-01 -1.23567e+00
21Feb12_165117|   4.22757e-01  3.63316e-02  6.01964e-01  1.96999e+00 -1.17414e+00
21Feb12_165117|   3.97797e-01 -1.08808e+00 -5.94358e-01 -2.83672e-01  8.50566e-01]
21Feb12_165117| [ 5.30769e-01 -1.84801e+00 -5.66134e-01  6.76585e-02  1.10136e-01
21Feb12_165117|   4.92367e-01 -4.90997e-01  6.06677e-01  2.28381e+00 -4.07746e-02
21Feb12_165117|   1.15850e+00 -5.98080e-01 -7.01578e-01  1.01957e+00  2.49859e-01]
21Feb12_165117| [-8.63352e-01  1.10102e+00 -1.35284e+00  7.44546e-01  1.23832e+00
21Feb12_165117|  -5.46095e-01 -7.14545e-01  6.39714e-01 -1.05446e-01 -8.88602e-01
21Feb12_165117|   9.93232e-01  1.94862e+00 -4.16105e-01  1.03489e-01  1.11977e+00]
21Feb12_165117| [ 1.19516e+00 -1.76346e-01  1.04128e-01  1.20697e+00 -9.23981e-01
21Feb12_165117|  -1.33787e+00 -2.81645e-01  4.54001e-01  1.13838e-01  7.67530e-01
21Feb12_165117|  -1.19224e+00 -1.30105e-01 -1.91934e-01  4.19944e-01  1.69825e-01]
21Feb12_165117| [ 7.65088e-01 -1.94246e+00 -7.11338e-01  4.53958e-01  1.94201e+00
21Feb12_165117|   1.31030e+00 -2.96434e-02 -1.76407e+00  5.53828e-01  6.85560e-01
21Feb12_165117|   7.66333e-01  3.82096e-02 -8.16458e-01 -6.24116e-02  2.64193e-01]
21Feb12_165117| [ 3.18200e-01  2.29948e+00  1.64715e+00  1.62897e+00 -7.51376e-02
21Feb12_165117|  -1.28841e+00 -6.20669e-01 -1.11166e-01  8.60402e-01 -1.33019e+00
21Feb12_165117|  -5.96012e-01  1.43903e+00  4.95090e-01 -5.77593e-01  1.44906e+00]
21Feb12_165117| [ 4.11040e-01  7.04946e-01 -5.20407e-01  1.19926e-01 -2.14187e-01
21Feb12_165117|   2.61836e-01 -2.06690e-01 -5.23044e-01 -2.21768e+00 -1.84159e+00
21Feb12_165117|   1.07890e-01 -1.21571e+00  1.41906e-02 -1.18878e+00 -1.10586e+00]
21Feb12_165117| [ 7.47110e-04 -2.19367e-01  1.24132e+00  2.42981e-01  1.64975e+00
21Feb12_165117|  -7.56681e-01  2.05047e+00  1.41699e+00  2.11413e-01  2.05856e-01
21Feb12_165117|  -1.19536e+00 -1.17721e+00 -5.74572e-02 -9.88771e-01 -5.21745e-02]
21Feb12_165117| [ 8.41039e-01 -7.80210e-01  1.63153e-01  9.11562e-01  1.96584e+00
21Feb12_165117|   1.78291e+00  1.27725e-01  9.24125e-01  8.89095e-01  8.02583e-01
21Feb12_165117|  -1.84072e-01 -1.83956e+00 -1.02407e+00  6.97260e-01  2.04119e+00]
21Feb12_165117| [ 1.02325e+00 -1.14512e+00  1.53735e+00 -1.20875e+00  2.40349e-01
21Feb12_165117|   3.65149e-01 -8.45853e-01 -9.53877e-01  1.08881e+00  1.31369e+00
21Feb12_165117|  -8.73629e-01  3.54768e-01 -1.44120e+00  3.00774e+00  5.37138e-01]
21Feb12_165117| [ 1.21153e+00  1.33780e+00  2.37346e-01  1.10192e+00 -7.71109e-01
21Feb12_165117|  -1.67297e+00 -9.85041e-01 -9.67469e-02  1.35584e-01  1.43828e+00
21Feb12_165117|  -5.37772e-01  6.81867e-01  8.99423e-02 -3.00140e-01  7.40803e-01]
21Feb12_165117| [-1.53912e-01 -1.45545e+00 -8.51719e-01 -3.24207e-01 -1.85297e+00
21Feb12_165117|  -1.37632e+00  2.56265e+00 -1.51591e+00 -7.70917e-01  1.60742e+00
21Feb12_165117|   8.19418e-01  1.51279e+00 -7.75504e-01 -4.56317e-01  7.93313e-01]
21Feb12_165117| [ 1.79234e+00  5.37534e-01 -1.64985e-01  1.12594e+00  4.19165e-01
21Feb12_165117|   1.00815e+00 -1.24029e+00  8.99015e-02  5.04534e-01  1.04688e+00
21Feb12_165117|  -1.85983e+00 -6.28367e-01  1.44747e+00 -7.70927e-01 -6.80962e-02]
21Feb12_165117| [-6.11685e-01  5.81244e-01 -2.00813e+00  4.40980e-01  1.17081e+00
21Feb12_165117|   4.53617e-02 -1.02732e-01 -5.30344e-01 -2.30272e-01 -2.75712e-01
21Feb12_165117|  -1.35628e+00  6.77073e-01  1.18206e+00 -9.68516e-01  8.88227e-01]
21Feb12_165117| [ 3.39330e-01  1.85906e-01  3.17199e+00 -1.14941e+00  8.41043e-01
21Feb12_165117|   1.43171e+00  2.91815e-01  9.90040e-01  2.43151e-01 -4.20123e-01
21Feb12_165117|  -7.71009e-01  8.26689e-01 -2.38729e-01  2.25124e-01  4.71938e-02]
21Feb12_165117| [-1.24769e+00 -1.74352e-01  1.33159e+00  6.31103e-01  1.39801e-01
21Feb12_165117|  -1.97232e-01  1.00881e+00 -1.05164e+00 -1.26316e-01 -6.77330e-01
21Feb12_165117|   6.93223e-01  3.09964e-01  4.46448e-01  3.28001e-01 -7.51083e-01]
21Feb12_165117| [-7.55157e-01 -1.20070e+00  1.18128e+00  2.31557e-01 -5.77142e-01
21Feb12_165117|   8.50621e-01 -6.80691e-01  1.14562e+00  6.53826e-01 -1.28380e+00
21Feb12_165117|   4.15503e-02  9.67591e-01 -3.56690e+00 -2.80446e-01 -2.39691e-01]
21Feb12_165117| [ 1.43065e+00  4.89999e-01  7.08940e-01  9.80815e-01 -5.25905e-01
21Feb12_165117|   8.92854e-01 -1.47577e+00 -9.27641e-02 -3.34619e-01 -1.41270e+00
21Feb12_165117|  -1.10591e+00  1.59163e+00  2.61333e-01 -1.48185e+00 -2.14182e+00]
21Feb12_165117| [ 8.38600e-01 -8.88508e-01 -4.12187e-01 -1.04812e-01  3.26908e-01
21Feb12_165117|  -9.83693e-01  1.67864e+00  7.72612e-01  1.95026e+00  9.57917e-01
21Feb12_165117|  -1.48928e+00 -1.99797e-01 -3.05136e-01 -1.14633e-01 -1.04672e+00]]
21Feb12_165117|-- Bias --
21Feb12_165117|[ 0.73695 -0.51772  1.29843 -0.86449  0.54318  0.17660 -0.21569  0.35471
21Feb12_165117| -0.23531 -0.15791  1.04286  0.77391 -0.11794  1.01790  0.50375]
21Feb12_165117|Layer 1:
21Feb12_165117|-- Config --
21Feb12_165117|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 15], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_165117|-- Weights --
21Feb12_165117|[[ 0.70443 -1.08724]
21Feb12_165117| [-0.44561 -1.05050]
21Feb12_165117| [ 0.25488  0.31427]
21Feb12_165117| [-1.40193  0.84859]
21Feb12_165117| [ 0.27127 -0.15942]
21Feb12_165117| [-0.18528 -0.14003]
21Feb12_165117| [ 1.68717  0.30442]
21Feb12_165117| [-0.01440  0.47743]
21Feb12_165117| [ 0.46612  0.57491]
21Feb12_165117| [-1.91613 -0.31596]
21Feb12_165117| [ 1.38318 -0.97860]
21Feb12_165117| [-0.49568  0.13334]
21Feb12_165117| [ 0.67487 -1.08400]
21Feb12_165117| [ 1.22898  1.13422]
21Feb12_165117| [ 0.14442 -0.69100]]
21Feb12_165117|-- Bias --
21Feb12_165117|[ 1.12271 -0.02168]
21Feb12_165117|Predicting the validation and test data with the Best final individual.
21Feb12_165125| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_165125|-----------  ------------------  --------------------  ----------
21Feb12_165125|Validation         42.00                  15            0.00259
21Feb12_165125|   Test            36.58                  15            0.00595
21Feb12_165125|-------------------- Test #9 --------------------
21Feb12_165125|Best final individual weights
21Feb12_165125|Individual:
21Feb12_165125|-- Constant hidden layers --
21Feb12_165125|False
21Feb12_165125|Layer 0:
21Feb12_165125|-- Config --
21Feb12_165125|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 15, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_165125|-- Weights --
21Feb12_165125|[[ 5.09617e-01  8.20902e-01 -3.02367e-01 -9.64837e-01 -4.33824e-01
21Feb12_165125|  -2.42034e-01 -5.04343e-01  1.31689e+00  9.21850e-01  5.13818e-01
21Feb12_165125|  -3.49854e-01  2.15852e-01 -1.04928e+00  7.68905e-01 -1.88324e+00]
21Feb12_165125| [-7.50915e-01 -2.52628e+00  3.69383e-01  1.39331e-01 -4.71230e-01
21Feb12_165125|   2.50267e+00 -2.55477e-01 -5.15419e-01 -2.31831e-01 -1.16548e+00
21Feb12_165125|  -8.22133e-01  4.82232e-01 -1.26500e+00  7.69663e-01  1.16647e+00]
21Feb12_165125| [ 4.01389e-03  9.01850e-01 -4.38696e-01 -7.91041e-01 -3.45664e-01
21Feb12_165125|  -1.66871e+00  1.65396e+00  7.90223e-01  5.51123e-01  1.67606e-01
21Feb12_165125|   2.12442e-01  1.14271e+00  6.42674e-01  2.00899e-01 -2.05944e-01]
21Feb12_165125| [ 1.80619e-01 -2.50060e-01 -1.12859e+00  1.83522e+00  1.81374e+00
21Feb12_165125|  -1.42416e+00  5.22823e-01 -7.02013e-01  1.84516e+00  1.90809e+00
21Feb12_165125|   1.37151e+00  4.03871e-02  4.29238e-01 -2.37117e-01 -1.00132e+00]
21Feb12_165125| [ 4.39871e-01  3.98574e-01 -3.75109e-01 -8.64825e-01  4.06425e-01
21Feb12_165125|   5.56500e-01  1.44148e+00 -5.22177e-01 -7.21740e-01  3.07682e-01
21Feb12_165125|  -9.52454e-01  8.44086e-01  1.09295e+00 -3.90444e-01  1.33545e+00]
21Feb12_165125| [-1.42180e+00  3.85641e-01 -8.43471e-02  1.81738e-02 -1.14521e+00
21Feb12_165125|  -8.06111e-01 -8.15090e-01  7.76165e-02  1.02784e+00  1.02123e-01
21Feb12_165125|   7.08213e-01  9.96943e-01 -7.79890e-01  1.66778e+00 -6.05761e-01]
21Feb12_165125| [-2.52774e-01 -9.61820e-01  3.02997e+00 -4.75355e-02  9.27908e-01
21Feb12_165125|   6.12327e-01 -4.65796e-01  8.85447e-01 -9.19731e-02  5.35502e-02
21Feb12_165125|  -5.61515e-01  1.22163e+00 -6.55581e-02 -4.23284e-01  6.78889e-01]
21Feb12_165125| [-4.07954e-01  7.89564e-01 -1.02275e+00 -1.42852e-01 -1.21182e-01
21Feb12_165125|   2.60288e+00  1.31219e+00 -1.05105e+00 -7.28076e-01  7.37981e-01
21Feb12_165125|   1.07877e+00  4.12772e-01  3.20972e-01 -1.42903e+00  5.49771e-01]
21Feb12_165125| [-1.06598e+00  4.11763e-01 -5.98736e-01 -1.02922e+00  1.44690e+00
21Feb12_165125|   1.61847e+00  7.86271e-01 -1.04439e+00 -1.22083e+00 -5.20594e-01
21Feb12_165125|   1.50709e+00 -2.76750e-01 -9.31489e-01  1.18032e+00 -1.34476e+00]
21Feb12_165125| [-9.84737e-01 -5.97909e-01 -5.05735e-01  1.21453e+00  2.04300e+00
21Feb12_165125|  -1.80226e+00  2.27960e-01  2.48235e-01 -9.14083e-01 -8.19925e-01
21Feb12_165125|   8.79325e-03  1.89321e+00 -2.33314e+00  3.64489e-01 -8.65853e-01]
21Feb12_165125| [-5.52147e-01 -1.09026e+00 -6.31263e-01 -9.85456e-02 -1.26793e+00
21Feb12_165125|   6.92239e-01  4.07591e-03  8.28704e-02 -4.61769e-01  1.47380e+00
21Feb12_165125|  -8.25050e-01  1.85307e+00 -7.02559e-01  4.42800e-01 -5.09351e-01]
21Feb12_165125| [-1.22241e+00 -2.82164e+00 -3.49419e-01  2.35780e-01 -3.06882e-01
21Feb12_165125|   4.97633e-01 -8.59745e-01  1.41005e+00  4.44223e-01  4.80295e-01
21Feb12_165125|   5.28514e-01 -8.52095e-01  7.93638e-01 -1.18061e+00  3.77575e-01]
21Feb12_165125| [ 1.83848e+00  1.86747e+00 -6.09064e-01 -1.29117e-01  8.20239e-01
21Feb12_165125|  -8.41223e-01 -4.91994e-01 -4.35134e-02 -3.10526e-01  8.12742e-01
21Feb12_165125|  -2.48499e+00  6.10492e-01  2.59825e-01  1.10740e+00  2.25110e-01]
21Feb12_165125| [-9.61110e-02  1.17814e+00  1.12148e-01 -3.49813e-01  2.43858e+00
21Feb12_165125|  -1.38613e+00 -3.82927e-01  1.52932e+00  8.48623e-01 -1.99483e+00
21Feb12_165125|  -2.12240e+00  1.06312e+00 -3.90781e-02  1.49640e+00  1.12926e+00]
21Feb12_165125| [-4.30616e-01  2.39031e-01 -7.23476e-01  1.25568e+00 -2.14845e-01
21Feb12_165125|  -5.53173e-01 -2.65699e+00  2.69230e-02 -1.00392e+00  1.32765e-01
21Feb12_165125|  -5.64005e-01  1.22524e+00  1.24383e+00 -1.09592e+00 -1.41796e+00]
21Feb12_165125| [-2.39791e-01  1.53064e+00  3.01720e-01  2.78106e-01 -1.84792e-01
21Feb12_165125|   1.56208e+00  9.94463e-01 -1.63904e+00  6.63295e-01 -1.85188e+00
21Feb12_165125|  -7.33287e-01 -1.62705e-01 -9.61094e-01  4.14256e-01 -1.81088e+00]
21Feb12_165125| [ 2.83794e-01  7.82624e-01  8.22930e-01  1.38834e+00  1.35777e+00
21Feb12_165125|   1.13137e+00 -4.51094e-01 -9.14736e-02 -4.29153e-01 -1.32003e-01
21Feb12_165125|  -1.06833e+00 -3.60741e-02 -1.72337e+00 -9.36812e-02 -1.50919e-01]
21Feb12_165125| [ 4.60832e-01 -6.41447e-01  7.19778e-01  1.43690e+00 -5.39012e-01
21Feb12_165125|   2.73839e+00  4.18203e-02  1.12728e+00 -1.96359e+00  5.08015e-01
21Feb12_165125|  -3.94637e-02  1.21425e+00  7.81562e-01  1.21240e+00  8.71932e-02]
21Feb12_165125| [ 7.21067e-01 -4.05470e-01  4.30706e-01 -1.12406e+00 -1.66416e-01
21Feb12_165125|  -1.74613e-01 -2.82475e+00  7.83187e-01 -1.70599e+00 -4.53800e-01
21Feb12_165125|   7.68700e-02  1.38626e+00  4.71260e-01 -1.20854e-01 -3.85957e-01]
21Feb12_165125| [-1.45393e+00 -4.35386e-01  7.35002e-01 -1.05813e+00 -6.41567e-01
21Feb12_165125|  -1.23953e+00 -1.11174e+00 -4.33161e-01  1.71285e+00 -1.69152e+00
21Feb12_165125|  -3.94477e-01 -9.64481e-01  2.12241e-01 -4.51296e-01  6.12573e-01]
21Feb12_165125| [ 1.91178e+00 -7.20020e-01 -1.43347e+00  6.16597e-01 -1.40631e-01
21Feb12_165125|   9.60419e-01 -2.94601e-01 -3.70235e-01  1.68500e-03 -7.06077e-02
21Feb12_165125|  -2.63686e+00 -7.93469e-01  3.46275e-01  2.04211e+00  9.19580e-01]
21Feb12_165125| [ 2.28690e-01 -1.52406e-01 -4.49362e-01 -7.32180e-01  7.99781e-01
21Feb12_165125|   4.88373e-01 -9.34696e-01 -5.02242e-01  9.68074e-01 -3.07760e-01
21Feb12_165125|  -3.49720e-01 -2.00695e+00 -4.45838e-01  2.62312e-01  3.38818e-01]
21Feb12_165125| [-1.98557e-01  8.34883e-01 -1.61905e-01  1.28379e+00  1.04073e+00
21Feb12_165125|   1.45833e+00  4.77341e-01  9.87420e-01 -3.08856e-01 -1.55031e+00
21Feb12_165125|   1.38023e+00 -4.42201e-01  1.78369e+00  8.01018e-01  1.52483e+00]
21Feb12_165125| [ 1.12967e+00 -8.45423e-01  1.52345e+00  1.08801e+00 -4.32434e-01
21Feb12_165125|  -3.16741e-01 -7.17985e-02  1.09877e+00 -7.90690e-01  1.36084e+00
21Feb12_165125|  -5.66120e-01 -1.70432e+00 -2.12910e+00 -2.41374e-01  1.33636e+00]
21Feb12_165125| [-4.08205e-01 -8.03871e-01  9.13990e-01  5.00916e-01 -1.81059e-01
21Feb12_165125|   2.42621e-01 -9.57869e-01  6.74094e-01  6.52179e-01  2.77279e-01
21Feb12_165125|  -3.91051e-01 -9.05321e-02  6.86316e-01 -3.54594e-01  5.83144e-01]
21Feb12_165125| [-3.98308e-01 -4.48018e-03  1.11987e+00  1.50374e+00 -9.18129e-01
21Feb12_165125|  -1.81690e+00 -1.38223e+00 -2.74481e-01 -8.24843e-01 -7.05820e-01
21Feb12_165125|   1.50584e+00 -4.21386e-01  4.00084e-01 -7.61841e-02 -7.41767e-01]
21Feb12_165125| [ 5.51762e-01 -1.04904e+00  5.21335e-01  2.14684e-01 -8.21795e-02
21Feb12_165125|   3.68556e-01  1.01222e+00 -1.30634e+00 -1.52652e+00  9.98379e-01
21Feb12_165125|   8.51997e-01 -9.42775e-01 -1.16577e-01  3.64988e-01 -1.27419e+00]
21Feb12_165125| [ 1.67425e+00 -1.27190e-01  2.44775e+00  1.44302e+00 -4.43112e-01
21Feb12_165125|  -4.07317e-02  1.33875e-01  4.92876e-01  1.36327e+00  3.41424e-01
21Feb12_165125|   1.70937e+00 -2.26414e+00  5.48087e-01 -2.49869e-01 -1.95666e+00]
21Feb12_165125| [-7.77069e-01  1.76839e+00 -5.99460e-01 -2.13769e+00  1.38006e+00
21Feb12_165125|   1.30623e+00 -1.06865e+00 -1.16462e+00  8.02528e-01 -3.99780e-01
21Feb12_165125|   8.20611e-01 -1.64613e-01  3.17174e-01  1.50755e+00  1.82851e-01]
21Feb12_165125| [-1.02989e+00 -1.07499e+00 -1.93091e+00  4.66271e-01 -8.74190e-01
21Feb12_165125|  -1.32185e+00 -9.08286e-01 -8.46363e-01  2.03651e-01 -2.52017e-01
21Feb12_165125|   1.15748e+00 -3.29038e-01 -5.53034e-01  6.31862e-01 -9.38469e-02]
21Feb12_165125| [-1.07650e+00  2.26383e-01  1.43406e-01 -1.04859e+00 -1.13255e+00
21Feb12_165125|   5.32942e-01 -2.81361e-01  1.06039e+00 -4.84886e-01  1.81779e+00
21Feb12_165125|   4.45898e-01  1.15599e-01  2.22637e+00 -1.10477e+00 -7.41273e-01]
21Feb12_165125| [ 5.36190e-01  1.36053e+00  1.86442e-01  1.76821e-01  1.73842e+00
21Feb12_165125|   1.33653e-01 -2.69435e-01  1.42842e+00 -6.67924e-01  8.34192e-01
21Feb12_165125|  -4.93949e-01  2.55190e-01  8.44813e-02  1.07023e+00  3.32795e-01]
21Feb12_165125| [-7.77858e-01  6.91255e-01 -2.00094e-01 -3.47804e-02  1.25963e+00
21Feb12_165125|   2.88406e-01  1.11181e-02 -1.72072e-01  1.74171e-01  1.07767e+00
21Feb12_165125|  -7.57539e-01 -1.51881e+00  1.13432e+00 -8.19687e-01  2.51036e-01]
21Feb12_165125| [ 1.17877e+00  8.51361e-01  5.34249e-01 -3.85201e-01  1.62741e+00
21Feb12_165125|   7.14108e-01 -2.49586e-01 -1.51061e+00 -5.78471e-01 -1.53573e+00
21Feb12_165125|  -6.82580e-01 -1.03046e+00  2.14369e+00 -2.12686e+00  2.93875e-01]
21Feb12_165125| [-5.46699e-01 -1.24367e-01  1.50400e+00  5.24570e-01  1.32199e-01
21Feb12_165125|  -1.11873e+00 -1.21781e-01  1.60716e+00  7.94494e-01  4.12000e-02
21Feb12_165125|  -1.45629e-01 -1.67069e+00  1.55359e+00  1.27490e+00  3.78250e-01]
21Feb12_165125| [-1.65770e+00  7.63010e-01 -1.07032e-01 -1.29077e+00 -2.72523e-01
21Feb12_165125|   8.86152e-01  2.03137e-02  1.07244e+00 -2.07611e+00  1.79718e-01
21Feb12_165125|   1.81554e-01 -6.15758e-01 -9.51774e-01  1.02939e+00  8.17973e-01]
21Feb12_165125| [ 9.21545e-01 -8.71244e-02 -1.53454e+00 -1.66686e+00  9.25583e-02
21Feb12_165125|   5.45788e-01  9.00588e-01  5.39148e-01  1.73423e+00  5.95858e-01
21Feb12_165125|   7.60598e-01  7.10163e-01 -1.92447e-01 -2.18648e-01 -1.06613e-01]
21Feb12_165125| [-1.27156e+00  1.50471e-01 -1.51367e+00  2.43159e-01  1.45374e+00
21Feb12_165125|   1.39069e-01  1.63857e+00  7.76127e-01  1.22775e-01 -9.15383e-01
21Feb12_165125|  -7.88206e-01 -1.88443e-01  5.88849e-01 -1.15889e+00  1.57532e+00]
21Feb12_165125| [-7.87307e-01  7.90368e-01 -8.23463e-01 -7.31497e-01 -1.23567e+00
21Feb12_165125|   4.22757e-01  3.63316e-02  6.01964e-01  1.96999e+00 -1.17414e+00
21Feb12_165125|   3.97797e-01 -1.08808e+00 -5.94358e-01 -2.83672e-01  8.50566e-01]
21Feb12_165125| [ 5.30769e-01 -1.84801e+00 -5.66134e-01  6.76585e-02  1.10136e-01
21Feb12_165125|   4.92367e-01 -4.90997e-01  6.06677e-01  2.28381e+00 -4.07746e-02
21Feb12_165125|   1.15850e+00 -5.98080e-01 -7.01578e-01  1.01957e+00  2.49859e-01]
21Feb12_165125| [-8.63352e-01  1.10102e+00 -1.35284e+00  7.44546e-01  1.23832e+00
21Feb12_165125|  -5.46095e-01 -7.14545e-01  6.39714e-01 -1.05446e-01 -8.88602e-01
21Feb12_165125|   9.93232e-01  1.94862e+00 -4.16105e-01  1.03489e-01  1.11977e+00]
21Feb12_165125| [ 1.19516e+00 -1.76346e-01  1.04128e-01  1.20697e+00 -9.23981e-01
21Feb12_165125|  -1.33787e+00 -2.81645e-01  4.54001e-01  1.13838e-01  7.67530e-01
21Feb12_165125|  -1.19224e+00 -1.30105e-01 -1.91934e-01  4.19944e-01  1.69825e-01]
21Feb12_165125| [ 7.65088e-01 -1.94246e+00 -7.11338e-01  4.53958e-01  1.94201e+00
21Feb12_165125|   1.31030e+00 -2.96434e-02 -1.76407e+00  5.53828e-01  6.85560e-01
21Feb12_165125|   7.66333e-01  3.82096e-02 -8.16458e-01 -6.24116e-02  2.64193e-01]
21Feb12_165125| [ 3.18200e-01  2.29948e+00  1.64715e+00  1.62897e+00 -7.51376e-02
21Feb12_165125|  -1.28841e+00 -6.20669e-01 -1.11166e-01  8.60402e-01 -1.33019e+00
21Feb12_165125|  -5.96012e-01  1.43903e+00  4.95090e-01 -5.77593e-01  1.44906e+00]
21Feb12_165125| [ 4.11040e-01  7.04946e-01 -5.20407e-01  1.19926e-01 -2.14187e-01
21Feb12_165125|   2.61836e-01 -2.06690e-01 -5.23044e-01 -2.21768e+00 -1.84159e+00
21Feb12_165125|   1.07890e-01 -1.21571e+00  1.41906e-02 -1.18878e+00 -1.10586e+00]
21Feb12_165125| [ 7.47110e-04 -2.19367e-01  1.24132e+00  2.42981e-01  1.64975e+00
21Feb12_165125|  -7.56681e-01  2.05047e+00  1.41699e+00  2.11413e-01  2.05856e-01
21Feb12_165125|  -1.19536e+00 -1.17721e+00 -5.74572e-02 -9.88771e-01 -5.21745e-02]
21Feb12_165125| [ 8.41039e-01 -7.80210e-01  1.63153e-01  9.11562e-01  1.96584e+00
21Feb12_165125|   1.78291e+00  1.27725e-01  9.24125e-01  8.89095e-01  8.02583e-01
21Feb12_165125|  -1.84072e-01 -1.83956e+00 -1.02407e+00  6.97260e-01  2.04119e+00]
21Feb12_165125| [ 1.02325e+00 -1.14512e+00  1.53735e+00 -1.20875e+00  2.40349e-01
21Feb12_165125|   3.65149e-01 -8.45853e-01 -9.53877e-01  1.08881e+00  1.31369e+00
21Feb12_165125|  -8.73629e-01  3.54768e-01 -1.44120e+00  3.00774e+00  5.37138e-01]
21Feb12_165125| [ 1.21153e+00  1.33780e+00  2.37346e-01  1.10192e+00 -7.71109e-01
21Feb12_165125|  -1.67297e+00 -9.85041e-01 -9.67469e-02  1.35584e-01  1.43828e+00
21Feb12_165125|  -5.37772e-01  6.81867e-01  8.99423e-02 -3.00140e-01  7.40803e-01]
21Feb12_165125| [-1.53912e-01 -1.45545e+00 -8.51719e-01 -3.24207e-01 -1.85297e+00
21Feb12_165125|  -1.37632e+00  2.56265e+00 -1.51591e+00 -7.70917e-01  1.60742e+00
21Feb12_165125|   8.19418e-01  1.51279e+00 -7.75504e-01 -4.56317e-01  7.93313e-01]
21Feb12_165125| [ 1.79234e+00  5.37534e-01 -1.64985e-01  1.12594e+00  4.19165e-01
21Feb12_165125|   1.00815e+00 -1.24029e+00  8.99015e-02  5.04534e-01  1.04688e+00
21Feb12_165125|  -1.85983e+00 -6.28367e-01  1.44747e+00 -7.70927e-01 -6.80962e-02]
21Feb12_165125| [-6.11685e-01  5.81244e-01 -2.00813e+00  4.40980e-01  1.17081e+00
21Feb12_165125|   4.53617e-02 -1.02732e-01 -5.30344e-01 -2.30272e-01 -2.75712e-01
21Feb12_165125|  -1.35628e+00  6.77073e-01  1.18206e+00 -9.68516e-01  8.88227e-01]
21Feb12_165125| [ 3.39330e-01  1.85906e-01  3.17199e+00 -1.14941e+00  8.41043e-01
21Feb12_165125|   1.43171e+00  2.91815e-01  9.90040e-01  2.43151e-01 -4.20123e-01
21Feb12_165125|  -7.71009e-01  8.26689e-01 -2.38729e-01  2.25124e-01  4.71938e-02]
21Feb12_165125| [-1.24769e+00 -1.74352e-01  1.33159e+00  6.31103e-01  1.39801e-01
21Feb12_165125|  -1.97232e-01  1.00881e+00 -1.05164e+00 -1.26316e-01 -6.77330e-01
21Feb12_165125|   6.93223e-01  3.09964e-01  4.46448e-01  3.28001e-01 -7.51083e-01]
21Feb12_165125| [-7.55157e-01 -1.20070e+00  1.18128e+00  2.31557e-01 -5.77142e-01
21Feb12_165125|   8.50621e-01 -6.80691e-01  1.14562e+00  6.53826e-01 -1.28380e+00
21Feb12_165125|   4.15503e-02  9.67591e-01 -3.56690e+00 -2.80446e-01 -2.39691e-01]
21Feb12_165125| [ 1.43065e+00  4.89999e-01  7.08940e-01  9.80815e-01 -5.25905e-01
21Feb12_165125|   8.92854e-01 -1.47577e+00 -9.27641e-02 -3.34619e-01 -1.41270e+00
21Feb12_165125|  -1.10591e+00  1.59163e+00  2.61333e-01 -1.48185e+00 -2.14182e+00]
21Feb12_165125| [ 8.38600e-01 -8.88508e-01 -4.12187e-01 -1.04812e-01  3.26908e-01
21Feb12_165125|  -9.83693e-01  1.67864e+00  7.72612e-01  1.95026e+00  9.57917e-01
21Feb12_165125|  -1.48928e+00 -1.99797e-01 -3.05136e-01 -1.14633e-01 -1.04672e+00]]
21Feb12_165125|-- Bias --
21Feb12_165125|[ 0.73695 -0.51772  1.29843 -0.86449  0.54318  0.17660 -0.21569  0.35471
21Feb12_165125| -0.23531 -0.15791  1.04286  0.77391 -0.11794  1.01790  0.50375]
21Feb12_165125|Layer 1:
21Feb12_165125|-- Config --
21Feb12_165125|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 15], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_165125|-- Weights --
21Feb12_165125|[[ 0.70443 -1.08724]
21Feb12_165125| [-0.44561 -1.05050]
21Feb12_165125| [ 0.25488  0.31427]
21Feb12_165125| [-1.40193  0.84859]
21Feb12_165125| [ 0.27127 -0.15942]
21Feb12_165125| [-0.18528 -0.14003]
21Feb12_165125| [ 1.68717  0.30442]
21Feb12_165125| [-0.01440  0.47743]
21Feb12_165125| [ 0.46612  0.57491]
21Feb12_165125| [-1.91613 -0.31596]
21Feb12_165125| [ 1.38318 -0.97860]
21Feb12_165125| [-0.49568  0.13334]
21Feb12_165125| [ 0.67487 -1.08400]
21Feb12_165125| [ 1.22898  1.13422]
21Feb12_165125| [ 0.14442 -0.69100]]
21Feb12_165125|-- Bias --
21Feb12_165125|[ 1.12271 -0.02168]
21Feb12_165125|Predicting the validation and test data with the Best final individual.
21Feb12_165132| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_165132|-----------  ------------------  --------------------  ----------
21Feb12_165132|Validation         41.39                  15            0.02061
21Feb12_165132|   Test            36.58                  15            0.00298
21Feb12_165132|-------------------- Test #10 --------------------
21Feb12_165132|Best final individual weights
21Feb12_165132|Individual:
21Feb12_165132|-- Constant hidden layers --
21Feb12_165132|False
21Feb12_165132|Layer 0:
21Feb12_165132|-- Config --
21Feb12_165132|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 15, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_165132|-- Weights --
21Feb12_165132|[[ 5.09617e-01  8.20902e-01 -3.02367e-01 -9.64837e-01 -4.33824e-01
21Feb12_165132|  -2.42034e-01 -5.04343e-01  1.31689e+00  9.21850e-01  5.13818e-01
21Feb12_165132|  -3.49854e-01  2.15852e-01 -1.04928e+00  7.68905e-01 -1.88324e+00]
21Feb12_165132| [-7.50915e-01 -2.52628e+00  3.69383e-01  1.39331e-01 -4.71230e-01
21Feb12_165132|   2.50267e+00 -2.55477e-01 -5.15419e-01 -2.31831e-01 -1.16548e+00
21Feb12_165132|  -8.22133e-01  4.82232e-01 -1.26500e+00  7.69663e-01  1.16647e+00]
21Feb12_165132| [ 4.01389e-03  9.01850e-01 -4.38696e-01 -7.91041e-01 -3.45664e-01
21Feb12_165132|  -1.66871e+00  1.65396e+00  7.90223e-01  5.51123e-01  1.67606e-01
21Feb12_165132|   2.12442e-01  1.14271e+00  6.42674e-01  2.00899e-01 -2.05944e-01]
21Feb12_165132| [ 1.80619e-01 -2.50060e-01 -1.12859e+00  1.83522e+00  1.81374e+00
21Feb12_165132|  -1.42416e+00  5.22823e-01 -7.02013e-01  1.84516e+00  1.90809e+00
21Feb12_165132|   1.37151e+00  4.03871e-02  4.29238e-01 -2.37117e-01 -1.00132e+00]
21Feb12_165132| [ 4.39871e-01  3.98574e-01 -3.75109e-01 -8.64825e-01  4.06425e-01
21Feb12_165132|   5.56500e-01  1.44148e+00 -5.22177e-01 -7.21740e-01  3.07682e-01
21Feb12_165132|  -9.52454e-01  8.44086e-01  1.09295e+00 -3.90444e-01  1.33545e+00]
21Feb12_165132| [-1.42180e+00  3.85641e-01 -8.43471e-02  1.81738e-02 -1.14521e+00
21Feb12_165132|  -8.06111e-01 -8.15090e-01  7.76165e-02  1.02784e+00  1.02123e-01
21Feb12_165132|   7.08213e-01  9.96943e-01 -7.79890e-01  1.66778e+00 -6.05761e-01]
21Feb12_165132| [-2.52774e-01 -9.61820e-01  3.02997e+00 -4.75355e-02  9.27908e-01
21Feb12_165132|   6.12327e-01 -4.65796e-01  8.85447e-01 -9.19731e-02  5.35502e-02
21Feb12_165132|  -5.61515e-01  1.22163e+00 -6.55581e-02 -4.23284e-01  6.78889e-01]
21Feb12_165132| [-4.07954e-01  7.89564e-01 -1.02275e+00 -1.42852e-01 -1.21182e-01
21Feb12_165132|   2.60288e+00  1.31219e+00 -1.05105e+00 -7.28076e-01  7.37981e-01
21Feb12_165132|   1.07877e+00  4.12772e-01  3.20972e-01 -1.42903e+00  5.49771e-01]
21Feb12_165132| [-1.06598e+00  4.11763e-01 -5.98736e-01 -1.02922e+00  1.44690e+00
21Feb12_165132|   1.61847e+00  7.86271e-01 -1.04439e+00 -1.22083e+00 -5.20594e-01
21Feb12_165132|   1.50709e+00 -2.76750e-01 -9.31489e-01  1.18032e+00 -1.34476e+00]
21Feb12_165132| [-9.84737e-01 -5.97909e-01 -5.05735e-01  1.21453e+00  2.04300e+00
21Feb12_165132|  -1.80226e+00  2.27960e-01  2.48235e-01 -9.14083e-01 -8.19925e-01
21Feb12_165132|   8.79325e-03  1.89321e+00 -2.33314e+00  3.64489e-01 -8.65853e-01]
21Feb12_165132| [-5.52147e-01 -1.09026e+00 -6.31263e-01 -9.85456e-02 -1.26793e+00
21Feb12_165132|   6.92239e-01  4.07591e-03  8.28704e-02 -4.61769e-01  1.47380e+00
21Feb12_165132|  -8.25050e-01  1.85307e+00 -7.02559e-01  4.42800e-01 -5.09351e-01]
21Feb12_165132| [-1.22241e+00 -2.82164e+00 -3.49419e-01  2.35780e-01 -3.06882e-01
21Feb12_165132|   4.97633e-01 -8.59745e-01  1.41005e+00  4.44223e-01  4.80295e-01
21Feb12_165132|   5.28514e-01 -8.52095e-01  7.93638e-01 -1.18061e+00  3.77575e-01]
21Feb12_165132| [ 1.83848e+00  1.86747e+00 -6.09064e-01 -1.29117e-01  8.20239e-01
21Feb12_165132|  -8.41223e-01 -4.91994e-01 -4.35134e-02 -3.10526e-01  8.12742e-01
21Feb12_165132|  -2.48499e+00  6.10492e-01  2.59825e-01  1.10740e+00  2.25110e-01]
21Feb12_165132| [-9.61110e-02  1.17814e+00  1.12148e-01 -3.49813e-01  2.43858e+00
21Feb12_165132|  -1.38613e+00 -3.82927e-01  1.52932e+00  8.48623e-01 -1.99483e+00
21Feb12_165132|  -2.12240e+00  1.06312e+00 -3.90781e-02  1.49640e+00  1.12926e+00]
21Feb12_165132| [-4.30616e-01  2.39031e-01 -7.23476e-01  1.25568e+00 -2.14845e-01
21Feb12_165132|  -5.53173e-01 -2.65699e+00  2.69230e-02 -1.00392e+00  1.32765e-01
21Feb12_165132|  -5.64005e-01  1.22524e+00  1.24383e+00 -1.09592e+00 -1.41796e+00]
21Feb12_165132| [-2.39791e-01  1.53064e+00  3.01720e-01  2.78106e-01 -1.84792e-01
21Feb12_165132|   1.56208e+00  9.94463e-01 -1.63904e+00  6.63295e-01 -1.85188e+00
21Feb12_165132|  -7.33287e-01 -1.62705e-01 -9.61094e-01  4.14256e-01 -1.81088e+00]
21Feb12_165132| [ 2.83794e-01  7.82624e-01  8.22930e-01  1.38834e+00  1.35777e+00
21Feb12_165132|   1.13137e+00 -4.51094e-01 -9.14736e-02 -4.29153e-01 -1.32003e-01
21Feb12_165132|  -1.06833e+00 -3.60741e-02 -1.72337e+00 -9.36812e-02 -1.50919e-01]
21Feb12_165132| [ 4.60832e-01 -6.41447e-01  7.19778e-01  1.43690e+00 -5.39012e-01
21Feb12_165132|   2.73839e+00  4.18203e-02  1.12728e+00 -1.96359e+00  5.08015e-01
21Feb12_165132|  -3.94637e-02  1.21425e+00  7.81562e-01  1.21240e+00  8.71932e-02]
21Feb12_165132| [ 7.21067e-01 -4.05470e-01  4.30706e-01 -1.12406e+00 -1.66416e-01
21Feb12_165132|  -1.74613e-01 -2.82475e+00  7.83187e-01 -1.70599e+00 -4.53800e-01
21Feb12_165132|   7.68700e-02  1.38626e+00  4.71260e-01 -1.20854e-01 -3.85957e-01]
21Feb12_165132| [-1.45393e+00 -4.35386e-01  7.35002e-01 -1.05813e+00 -6.41567e-01
21Feb12_165132|  -1.23953e+00 -1.11174e+00 -4.33161e-01  1.71285e+00 -1.69152e+00
21Feb12_165132|  -3.94477e-01 -9.64481e-01  2.12241e-01 -4.51296e-01  6.12573e-01]
21Feb12_165132| [ 1.91178e+00 -7.20020e-01 -1.43347e+00  6.16597e-01 -1.40631e-01
21Feb12_165132|   9.60419e-01 -2.94601e-01 -3.70235e-01  1.68500e-03 -7.06077e-02
21Feb12_165132|  -2.63686e+00 -7.93469e-01  3.46275e-01  2.04211e+00  9.19580e-01]
21Feb12_165132| [ 2.28690e-01 -1.52406e-01 -4.49362e-01 -7.32180e-01  7.99781e-01
21Feb12_165132|   4.88373e-01 -9.34696e-01 -5.02242e-01  9.68074e-01 -3.07760e-01
21Feb12_165132|  -3.49720e-01 -2.00695e+00 -4.45838e-01  2.62312e-01  3.38818e-01]
21Feb12_165132| [-1.98557e-01  8.34883e-01 -1.61905e-01  1.28379e+00  1.04073e+00
21Feb12_165132|   1.45833e+00  4.77341e-01  9.87420e-01 -3.08856e-01 -1.55031e+00
21Feb12_165132|   1.38023e+00 -4.42201e-01  1.78369e+00  8.01018e-01  1.52483e+00]
21Feb12_165132| [ 1.12967e+00 -8.45423e-01  1.52345e+00  1.08801e+00 -4.32434e-01
21Feb12_165132|  -3.16741e-01 -7.17985e-02  1.09877e+00 -7.90690e-01  1.36084e+00
21Feb12_165132|  -5.66120e-01 -1.70432e+00 -2.12910e+00 -2.41374e-01  1.33636e+00]
21Feb12_165132| [-4.08205e-01 -8.03871e-01  9.13990e-01  5.00916e-01 -1.81059e-01
21Feb12_165132|   2.42621e-01 -9.57869e-01  6.74094e-01  6.52179e-01  2.77279e-01
21Feb12_165132|  -3.91051e-01 -9.05321e-02  6.86316e-01 -3.54594e-01  5.83144e-01]
21Feb12_165132| [-3.98308e-01 -4.48018e-03  1.11987e+00  1.50374e+00 -9.18129e-01
21Feb12_165132|  -1.81690e+00 -1.38223e+00 -2.74481e-01 -8.24843e-01 -7.05820e-01
21Feb12_165132|   1.50584e+00 -4.21386e-01  4.00084e-01 -7.61841e-02 -7.41767e-01]
21Feb12_165132| [ 5.51762e-01 -1.04904e+00  5.21335e-01  2.14684e-01 -8.21795e-02
21Feb12_165132|   3.68556e-01  1.01222e+00 -1.30634e+00 -1.52652e+00  9.98379e-01
21Feb12_165132|   8.51997e-01 -9.42775e-01 -1.16577e-01  3.64988e-01 -1.27419e+00]
21Feb12_165132| [ 1.67425e+00 -1.27190e-01  2.44775e+00  1.44302e+00 -4.43112e-01
21Feb12_165132|  -4.07317e-02  1.33875e-01  4.92876e-01  1.36327e+00  3.41424e-01
21Feb12_165132|   1.70937e+00 -2.26414e+00  5.48087e-01 -2.49869e-01 -1.95666e+00]
21Feb12_165132| [-7.77069e-01  1.76839e+00 -5.99460e-01 -2.13769e+00  1.38006e+00
21Feb12_165132|   1.30623e+00 -1.06865e+00 -1.16462e+00  8.02528e-01 -3.99780e-01
21Feb12_165132|   8.20611e-01 -1.64613e-01  3.17174e-01  1.50755e+00  1.82851e-01]
21Feb12_165132| [-1.02989e+00 -1.07499e+00 -1.93091e+00  4.66271e-01 -8.74190e-01
21Feb12_165132|  -1.32185e+00 -9.08286e-01 -8.46363e-01  2.03651e-01 -2.52017e-01
21Feb12_165132|   1.15748e+00 -3.29038e-01 -5.53034e-01  6.31862e-01 -9.38469e-02]
21Feb12_165132| [-1.07650e+00  2.26383e-01  1.43406e-01 -1.04859e+00 -1.13255e+00
21Feb12_165132|   5.32942e-01 -2.81361e-01  1.06039e+00 -4.84886e-01  1.81779e+00
21Feb12_165132|   4.45898e-01  1.15599e-01  2.22637e+00 -1.10477e+00 -7.41273e-01]
21Feb12_165132| [ 5.36190e-01  1.36053e+00  1.86442e-01  1.76821e-01  1.73842e+00
21Feb12_165132|   1.33653e-01 -2.69435e-01  1.42842e+00 -6.67924e-01  8.34192e-01
21Feb12_165132|  -4.93949e-01  2.55190e-01  8.44813e-02  1.07023e+00  3.32795e-01]
21Feb12_165132| [-7.77858e-01  6.91255e-01 -2.00094e-01 -3.47804e-02  1.25963e+00
21Feb12_165132|   2.88406e-01  1.11181e-02 -1.72072e-01  1.74171e-01  1.07767e+00
21Feb12_165132|  -7.57539e-01 -1.51881e+00  1.13432e+00 -8.19687e-01  2.51036e-01]
21Feb12_165132| [ 1.17877e+00  8.51361e-01  5.34249e-01 -3.85201e-01  1.62741e+00
21Feb12_165132|   7.14108e-01 -2.49586e-01 -1.51061e+00 -5.78471e-01 -1.53573e+00
21Feb12_165132|  -6.82580e-01 -1.03046e+00  2.14369e+00 -2.12686e+00  2.93875e-01]
21Feb12_165132| [-5.46699e-01 -1.24367e-01  1.50400e+00  5.24570e-01  1.32199e-01
21Feb12_165132|  -1.11873e+00 -1.21781e-01  1.60716e+00  7.94494e-01  4.12000e-02
21Feb12_165132|  -1.45629e-01 -1.67069e+00  1.55359e+00  1.27490e+00  3.78250e-01]
21Feb12_165132| [-1.65770e+00  7.63010e-01 -1.07032e-01 -1.29077e+00 -2.72523e-01
21Feb12_165132|   8.86152e-01  2.03137e-02  1.07244e+00 -2.07611e+00  1.79718e-01
21Feb12_165132|   1.81554e-01 -6.15758e-01 -9.51774e-01  1.02939e+00  8.17973e-01]
21Feb12_165132| [ 9.21545e-01 -8.71244e-02 -1.53454e+00 -1.66686e+00  9.25583e-02
21Feb12_165132|   5.45788e-01  9.00588e-01  5.39148e-01  1.73423e+00  5.95858e-01
21Feb12_165132|   7.60598e-01  7.10163e-01 -1.92447e-01 -2.18648e-01 -1.06613e-01]
21Feb12_165132| [-1.27156e+00  1.50471e-01 -1.51367e+00  2.43159e-01  1.45374e+00
21Feb12_165132|   1.39069e-01  1.63857e+00  7.76127e-01  1.22775e-01 -9.15383e-01
21Feb12_165132|  -7.88206e-01 -1.88443e-01  5.88849e-01 -1.15889e+00  1.57532e+00]
21Feb12_165132| [-7.87307e-01  7.90368e-01 -8.23463e-01 -7.31497e-01 -1.23567e+00
21Feb12_165132|   4.22757e-01  3.63316e-02  6.01964e-01  1.96999e+00 -1.17414e+00
21Feb12_165132|   3.97797e-01 -1.08808e+00 -5.94358e-01 -2.83672e-01  8.50566e-01]
21Feb12_165132| [ 5.30769e-01 -1.84801e+00 -5.66134e-01  6.76585e-02  1.10136e-01
21Feb12_165132|   4.92367e-01 -4.90997e-01  6.06677e-01  2.28381e+00 -4.07746e-02
21Feb12_165132|   1.15850e+00 -5.98080e-01 -7.01578e-01  1.01957e+00  2.49859e-01]
21Feb12_165132| [-8.63352e-01  1.10102e+00 -1.35284e+00  7.44546e-01  1.23832e+00
21Feb12_165132|  -5.46095e-01 -7.14545e-01  6.39714e-01 -1.05446e-01 -8.88602e-01
21Feb12_165132|   9.93232e-01  1.94862e+00 -4.16105e-01  1.03489e-01  1.11977e+00]
21Feb12_165132| [ 1.19516e+00 -1.76346e-01  1.04128e-01  1.20697e+00 -9.23981e-01
21Feb12_165132|  -1.33787e+00 -2.81645e-01  4.54001e-01  1.13838e-01  7.67530e-01
21Feb12_165132|  -1.19224e+00 -1.30105e-01 -1.91934e-01  4.19944e-01  1.69825e-01]
21Feb12_165132| [ 7.65088e-01 -1.94246e+00 -7.11338e-01  4.53958e-01  1.94201e+00
21Feb12_165132|   1.31030e+00 -2.96434e-02 -1.76407e+00  5.53828e-01  6.85560e-01
21Feb12_165132|   7.66333e-01  3.82096e-02 -8.16458e-01 -6.24116e-02  2.64193e-01]
21Feb12_165132| [ 3.18200e-01  2.29948e+00  1.64715e+00  1.62897e+00 -7.51376e-02
21Feb12_165132|  -1.28841e+00 -6.20669e-01 -1.11166e-01  8.60402e-01 -1.33019e+00
21Feb12_165132|  -5.96012e-01  1.43903e+00  4.95090e-01 -5.77593e-01  1.44906e+00]
21Feb12_165132| [ 4.11040e-01  7.04946e-01 -5.20407e-01  1.19926e-01 -2.14187e-01
21Feb12_165132|   2.61836e-01 -2.06690e-01 -5.23044e-01 -2.21768e+00 -1.84159e+00
21Feb12_165132|   1.07890e-01 -1.21571e+00  1.41906e-02 -1.18878e+00 -1.10586e+00]
21Feb12_165132| [ 7.47110e-04 -2.19367e-01  1.24132e+00  2.42981e-01  1.64975e+00
21Feb12_165132|  -7.56681e-01  2.05047e+00  1.41699e+00  2.11413e-01  2.05856e-01
21Feb12_165132|  -1.19536e+00 -1.17721e+00 -5.74572e-02 -9.88771e-01 -5.21745e-02]
21Feb12_165132| [ 8.41039e-01 -7.80210e-01  1.63153e-01  9.11562e-01  1.96584e+00
21Feb12_165132|   1.78291e+00  1.27725e-01  9.24125e-01  8.89095e-01  8.02583e-01
21Feb12_165132|  -1.84072e-01 -1.83956e+00 -1.02407e+00  6.97260e-01  2.04119e+00]
21Feb12_165132| [ 1.02325e+00 -1.14512e+00  1.53735e+00 -1.20875e+00  2.40349e-01
21Feb12_165132|   3.65149e-01 -8.45853e-01 -9.53877e-01  1.08881e+00  1.31369e+00
21Feb12_165132|  -8.73629e-01  3.54768e-01 -1.44120e+00  3.00774e+00  5.37138e-01]
21Feb12_165132| [ 1.21153e+00  1.33780e+00  2.37346e-01  1.10192e+00 -7.71109e-01
21Feb12_165132|  -1.67297e+00 -9.85041e-01 -9.67469e-02  1.35584e-01  1.43828e+00
21Feb12_165132|  -5.37772e-01  6.81867e-01  8.99423e-02 -3.00140e-01  7.40803e-01]
21Feb12_165132| [-1.53912e-01 -1.45545e+00 -8.51719e-01 -3.24207e-01 -1.85297e+00
21Feb12_165132|  -1.37632e+00  2.56265e+00 -1.51591e+00 -7.70917e-01  1.60742e+00
21Feb12_165132|   8.19418e-01  1.51279e+00 -7.75504e-01 -4.56317e-01  7.93313e-01]
21Feb12_165132| [ 1.79234e+00  5.37534e-01 -1.64985e-01  1.12594e+00  4.19165e-01
21Feb12_165132|   1.00815e+00 -1.24029e+00  8.99015e-02  5.04534e-01  1.04688e+00
21Feb12_165132|  -1.85983e+00 -6.28367e-01  1.44747e+00 -7.70927e-01 -6.80962e-02]
21Feb12_165132| [-6.11685e-01  5.81244e-01 -2.00813e+00  4.40980e-01  1.17081e+00
21Feb12_165132|   4.53617e-02 -1.02732e-01 -5.30344e-01 -2.30272e-01 -2.75712e-01
21Feb12_165132|  -1.35628e+00  6.77073e-01  1.18206e+00 -9.68516e-01  8.88227e-01]
21Feb12_165132| [ 3.39330e-01  1.85906e-01  3.17199e+00 -1.14941e+00  8.41043e-01
21Feb12_165132|   1.43171e+00  2.91815e-01  9.90040e-01  2.43151e-01 -4.20123e-01
21Feb12_165132|  -7.71009e-01  8.26689e-01 -2.38729e-01  2.25124e-01  4.71938e-02]
21Feb12_165132| [-1.24769e+00 -1.74352e-01  1.33159e+00  6.31103e-01  1.39801e-01
21Feb12_165132|  -1.97232e-01  1.00881e+00 -1.05164e+00 -1.26316e-01 -6.77330e-01
21Feb12_165132|   6.93223e-01  3.09964e-01  4.46448e-01  3.28001e-01 -7.51083e-01]
21Feb12_165132| [-7.55157e-01 -1.20070e+00  1.18128e+00  2.31557e-01 -5.77142e-01
21Feb12_165132|   8.50621e-01 -6.80691e-01  1.14562e+00  6.53826e-01 -1.28380e+00
21Feb12_165132|   4.15503e-02  9.67591e-01 -3.56690e+00 -2.80446e-01 -2.39691e-01]
21Feb12_165132| [ 1.43065e+00  4.89999e-01  7.08940e-01  9.80815e-01 -5.25905e-01
21Feb12_165132|   8.92854e-01 -1.47577e+00 -9.27641e-02 -3.34619e-01 -1.41270e+00
21Feb12_165132|  -1.10591e+00  1.59163e+00  2.61333e-01 -1.48185e+00 -2.14182e+00]
21Feb12_165132| [ 8.38600e-01 -8.88508e-01 -4.12187e-01 -1.04812e-01  3.26908e-01
21Feb12_165132|  -9.83693e-01  1.67864e+00  7.72612e-01  1.95026e+00  9.57917e-01
21Feb12_165132|  -1.48928e+00 -1.99797e-01 -3.05136e-01 -1.14633e-01 -1.04672e+00]]
21Feb12_165132|-- Bias --
21Feb12_165132|[ 0.73695 -0.51772  1.29843 -0.86449  0.54318  0.17660 -0.21569  0.35471
21Feb12_165132| -0.23531 -0.15791  1.04286  0.77391 -0.11794  1.01790  0.50375]
21Feb12_165132|Layer 1:
21Feb12_165132|-- Config --
21Feb12_165132|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 15], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_165132|-- Weights --
21Feb12_165132|[[ 0.70443 -1.08724]
21Feb12_165132| [-0.44561 -1.05050]
21Feb12_165132| [ 0.25488  0.31427]
21Feb12_165132| [-1.40193  0.84859]
21Feb12_165132| [ 0.27127 -0.15942]
21Feb12_165132| [-0.18528 -0.14003]
21Feb12_165132| [ 1.68717  0.30442]
21Feb12_165132| [-0.01440  0.47743]
21Feb12_165132| [ 0.46612  0.57491]
21Feb12_165132| [-1.91613 -0.31596]
21Feb12_165132| [ 1.38318 -0.97860]
21Feb12_165132| [-0.49568  0.13334]
21Feb12_165132| [ 0.67487 -1.08400]
21Feb12_165132| [ 1.22898  1.13422]
21Feb12_165132| [ 0.14442 -0.69100]]
21Feb12_165132|-- Bias --
21Feb12_165132|[ 1.12271 -0.02168]
21Feb12_165132|Predicting the validation and test data with the Best final individual.
21Feb12_165139| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_165139|-----------  ------------------  --------------------  ----------
21Feb12_165139|Validation         41.74                  15            0.00775
21Feb12_165139|   Test            36.66                  15            0.00594
21Feb12_165139|-------------------- Test #11 --------------------
21Feb12_165139|Best final individual weights
21Feb12_165139|Individual:
21Feb12_165139|-- Constant hidden layers --
21Feb12_165139|False
21Feb12_165139|Layer 0:
21Feb12_165139|-- Config --
21Feb12_165139|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 15, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_165139|-- Weights --
21Feb12_165139|[[ 5.09617e-01  8.20902e-01 -3.02367e-01 -9.64837e-01 -4.33824e-01
21Feb12_165139|  -2.42034e-01 -5.04343e-01  1.31689e+00  9.21850e-01  5.13818e-01
21Feb12_165139|  -3.49854e-01  2.15852e-01 -1.04928e+00  7.68905e-01 -1.88324e+00]
21Feb12_165139| [-7.50915e-01 -2.52628e+00  3.69383e-01  1.39331e-01 -4.71230e-01
21Feb12_165139|   2.50267e+00 -2.55477e-01 -5.15419e-01 -2.31831e-01 -1.16548e+00
21Feb12_165139|  -8.22133e-01  4.82232e-01 -1.26500e+00  7.69663e-01  1.16647e+00]
21Feb12_165139| [ 4.01389e-03  9.01850e-01 -4.38696e-01 -7.91041e-01 -3.45664e-01
21Feb12_165139|  -1.66871e+00  1.65396e+00  7.90223e-01  5.51123e-01  1.67606e-01
21Feb12_165139|   2.12442e-01  1.14271e+00  6.42674e-01  2.00899e-01 -2.05944e-01]
21Feb12_165139| [ 1.80619e-01 -2.50060e-01 -1.12859e+00  1.83522e+00  1.81374e+00
21Feb12_165139|  -1.42416e+00  5.22823e-01 -7.02013e-01  1.84516e+00  1.90809e+00
21Feb12_165139|   1.37151e+00  4.03871e-02  4.29238e-01 -2.37117e-01 -1.00132e+00]
21Feb12_165139| [ 4.39871e-01  3.98574e-01 -3.75109e-01 -8.64825e-01  4.06425e-01
21Feb12_165139|   5.56500e-01  1.44148e+00 -5.22177e-01 -7.21740e-01  3.07682e-01
21Feb12_165139|  -9.52454e-01  8.44086e-01  1.09295e+00 -3.90444e-01  1.33545e+00]
21Feb12_165139| [-1.42180e+00  3.85641e-01 -8.43471e-02  1.81738e-02 -1.14521e+00
21Feb12_165139|  -8.06111e-01 -8.15090e-01  7.76165e-02  1.02784e+00  1.02123e-01
21Feb12_165139|   7.08213e-01  9.96943e-01 -7.79890e-01  1.66778e+00 -6.05761e-01]
21Feb12_165139| [-2.52774e-01 -9.61820e-01  3.02997e+00 -4.75355e-02  9.27908e-01
21Feb12_165139|   6.12327e-01 -4.65796e-01  8.85447e-01 -9.19731e-02  5.35502e-02
21Feb12_165139|  -5.61515e-01  1.22163e+00 -6.55581e-02 -4.23284e-01  6.78889e-01]
21Feb12_165139| [-4.07954e-01  7.89564e-01 -1.02275e+00 -1.42852e-01 -1.21182e-01
21Feb12_165139|   2.60288e+00  1.31219e+00 -1.05105e+00 -7.28076e-01  7.37981e-01
21Feb12_165139|   1.07877e+00  4.12772e-01  3.20972e-01 -1.42903e+00  5.49771e-01]
21Feb12_165139| [-1.06598e+00  4.11763e-01 -5.98736e-01 -1.02922e+00  1.44690e+00
21Feb12_165139|   1.61847e+00  7.86271e-01 -1.04439e+00 -1.22083e+00 -5.20594e-01
21Feb12_165139|   1.50709e+00 -2.76750e-01 -9.31489e-01  1.18032e+00 -1.34476e+00]
21Feb12_165139| [-9.84737e-01 -5.97909e-01 -5.05735e-01  1.21453e+00  2.04300e+00
21Feb12_165139|  -1.80226e+00  2.27960e-01  2.48235e-01 -9.14083e-01 -8.19925e-01
21Feb12_165139|   8.79325e-03  1.89321e+00 -2.33314e+00  3.64489e-01 -8.65853e-01]
21Feb12_165139| [-5.52147e-01 -1.09026e+00 -6.31263e-01 -9.85456e-02 -1.26793e+00
21Feb12_165139|   6.92239e-01  4.07591e-03  8.28704e-02 -4.61769e-01  1.47380e+00
21Feb12_165139|  -8.25050e-01  1.85307e+00 -7.02559e-01  4.42800e-01 -5.09351e-01]
21Feb12_165139| [-1.22241e+00 -2.82164e+00 -3.49419e-01  2.35780e-01 -3.06882e-01
21Feb12_165139|   4.97633e-01 -8.59745e-01  1.41005e+00  4.44223e-01  4.80295e-01
21Feb12_165139|   5.28514e-01 -8.52095e-01  7.93638e-01 -1.18061e+00  3.77575e-01]
21Feb12_165139| [ 1.83848e+00  1.86747e+00 -6.09064e-01 -1.29117e-01  8.20239e-01
21Feb12_165139|  -8.41223e-01 -4.91994e-01 -4.35134e-02 -3.10526e-01  8.12742e-01
21Feb12_165139|  -2.48499e+00  6.10492e-01  2.59825e-01  1.10740e+00  2.25110e-01]
21Feb12_165139| [-9.61110e-02  1.17814e+00  1.12148e-01 -3.49813e-01  2.43858e+00
21Feb12_165139|  -1.38613e+00 -3.82927e-01  1.52932e+00  8.48623e-01 -1.99483e+00
21Feb12_165139|  -2.12240e+00  1.06312e+00 -3.90781e-02  1.49640e+00  1.12926e+00]
21Feb12_165139| [-4.30616e-01  2.39031e-01 -7.23476e-01  1.25568e+00 -2.14845e-01
21Feb12_165139|  -5.53173e-01 -2.65699e+00  2.69230e-02 -1.00392e+00  1.32765e-01
21Feb12_165139|  -5.64005e-01  1.22524e+00  1.24383e+00 -1.09592e+00 -1.41796e+00]
21Feb12_165139| [-2.39791e-01  1.53064e+00  3.01720e-01  2.78106e-01 -1.84792e-01
21Feb12_165139|   1.56208e+00  9.94463e-01 -1.63904e+00  6.63295e-01 -1.85188e+00
21Feb12_165139|  -7.33287e-01 -1.62705e-01 -9.61094e-01  4.14256e-01 -1.81088e+00]
21Feb12_165139| [ 2.83794e-01  7.82624e-01  8.22930e-01  1.38834e+00  1.35777e+00
21Feb12_165139|   1.13137e+00 -4.51094e-01 -9.14736e-02 -4.29153e-01 -1.32003e-01
21Feb12_165139|  -1.06833e+00 -3.60741e-02 -1.72337e+00 -9.36812e-02 -1.50919e-01]
21Feb12_165139| [ 4.60832e-01 -6.41447e-01  7.19778e-01  1.43690e+00 -5.39012e-01
21Feb12_165139|   2.73839e+00  4.18203e-02  1.12728e+00 -1.96359e+00  5.08015e-01
21Feb12_165139|  -3.94637e-02  1.21425e+00  7.81562e-01  1.21240e+00  8.71932e-02]
21Feb12_165139| [ 7.21067e-01 -4.05470e-01  4.30706e-01 -1.12406e+00 -1.66416e-01
21Feb12_165139|  -1.74613e-01 -2.82475e+00  7.83187e-01 -1.70599e+00 -4.53800e-01
21Feb12_165139|   7.68700e-02  1.38626e+00  4.71260e-01 -1.20854e-01 -3.85957e-01]
21Feb12_165139| [-1.45393e+00 -4.35386e-01  7.35002e-01 -1.05813e+00 -6.41567e-01
21Feb12_165139|  -1.23953e+00 -1.11174e+00 -4.33161e-01  1.71285e+00 -1.69152e+00
21Feb12_165139|  -3.94477e-01 -9.64481e-01  2.12241e-01 -4.51296e-01  6.12573e-01]
21Feb12_165139| [ 1.91178e+00 -7.20020e-01 -1.43347e+00  6.16597e-01 -1.40631e-01
21Feb12_165139|   9.60419e-01 -2.94601e-01 -3.70235e-01  1.68500e-03 -7.06077e-02
21Feb12_165139|  -2.63686e+00 -7.93469e-01  3.46275e-01  2.04211e+00  9.19580e-01]
21Feb12_165139| [ 2.28690e-01 -1.52406e-01 -4.49362e-01 -7.32180e-01  7.99781e-01
21Feb12_165139|   4.88373e-01 -9.34696e-01 -5.02242e-01  9.68074e-01 -3.07760e-01
21Feb12_165139|  -3.49720e-01 -2.00695e+00 -4.45838e-01  2.62312e-01  3.38818e-01]
21Feb12_165139| [-1.98557e-01  8.34883e-01 -1.61905e-01  1.28379e+00  1.04073e+00
21Feb12_165139|   1.45833e+00  4.77341e-01  9.87420e-01 -3.08856e-01 -1.55031e+00
21Feb12_165139|   1.38023e+00 -4.42201e-01  1.78369e+00  8.01018e-01  1.52483e+00]
21Feb12_165139| [ 1.12967e+00 -8.45423e-01  1.52345e+00  1.08801e+00 -4.32434e-01
21Feb12_165139|  -3.16741e-01 -7.17985e-02  1.09877e+00 -7.90690e-01  1.36084e+00
21Feb12_165139|  -5.66120e-01 -1.70432e+00 -2.12910e+00 -2.41374e-01  1.33636e+00]
21Feb12_165139| [-4.08205e-01 -8.03871e-01  9.13990e-01  5.00916e-01 -1.81059e-01
21Feb12_165139|   2.42621e-01 -9.57869e-01  6.74094e-01  6.52179e-01  2.77279e-01
21Feb12_165139|  -3.91051e-01 -9.05321e-02  6.86316e-01 -3.54594e-01  5.83144e-01]
21Feb12_165139| [-3.98308e-01 -4.48018e-03  1.11987e+00  1.50374e+00 -9.18129e-01
21Feb12_165139|  -1.81690e+00 -1.38223e+00 -2.74481e-01 -8.24843e-01 -7.05820e-01
21Feb12_165139|   1.50584e+00 -4.21386e-01  4.00084e-01 -7.61841e-02 -7.41767e-01]
21Feb12_165139| [ 5.51762e-01 -1.04904e+00  5.21335e-01  2.14684e-01 -8.21795e-02
21Feb12_165139|   3.68556e-01  1.01222e+00 -1.30634e+00 -1.52652e+00  9.98379e-01
21Feb12_165139|   8.51997e-01 -9.42775e-01 -1.16577e-01  3.64988e-01 -1.27419e+00]
21Feb12_165139| [ 1.67425e+00 -1.27190e-01  2.44775e+00  1.44302e+00 -4.43112e-01
21Feb12_165139|  -4.07317e-02  1.33875e-01  4.92876e-01  1.36327e+00  3.41424e-01
21Feb12_165139|   1.70937e+00 -2.26414e+00  5.48087e-01 -2.49869e-01 -1.95666e+00]
21Feb12_165139| [-7.77069e-01  1.76839e+00 -5.99460e-01 -2.13769e+00  1.38006e+00
21Feb12_165139|   1.30623e+00 -1.06865e+00 -1.16462e+00  8.02528e-01 -3.99780e-01
21Feb12_165139|   8.20611e-01 -1.64613e-01  3.17174e-01  1.50755e+00  1.82851e-01]
21Feb12_165139| [-1.02989e+00 -1.07499e+00 -1.93091e+00  4.66271e-01 -8.74190e-01
21Feb12_165139|  -1.32185e+00 -9.08286e-01 -8.46363e-01  2.03651e-01 -2.52017e-01
21Feb12_165139|   1.15748e+00 -3.29038e-01 -5.53034e-01  6.31862e-01 -9.38469e-02]
21Feb12_165139| [-1.07650e+00  2.26383e-01  1.43406e-01 -1.04859e+00 -1.13255e+00
21Feb12_165139|   5.32942e-01 -2.81361e-01  1.06039e+00 -4.84886e-01  1.81779e+00
21Feb12_165139|   4.45898e-01  1.15599e-01  2.22637e+00 -1.10477e+00 -7.41273e-01]
21Feb12_165139| [ 5.36190e-01  1.36053e+00  1.86442e-01  1.76821e-01  1.73842e+00
21Feb12_165139|   1.33653e-01 -2.69435e-01  1.42842e+00 -6.67924e-01  8.34192e-01
21Feb12_165139|  -4.93949e-01  2.55190e-01  8.44813e-02  1.07023e+00  3.32795e-01]
21Feb12_165139| [-7.77858e-01  6.91255e-01 -2.00094e-01 -3.47804e-02  1.25963e+00
21Feb12_165139|   2.88406e-01  1.11181e-02 -1.72072e-01  1.74171e-01  1.07767e+00
21Feb12_165139|  -7.57539e-01 -1.51881e+00  1.13432e+00 -8.19687e-01  2.51036e-01]
21Feb12_165139| [ 1.17877e+00  8.51361e-01  5.34249e-01 -3.85201e-01  1.62741e+00
21Feb12_165139|   7.14108e-01 -2.49586e-01 -1.51061e+00 -5.78471e-01 -1.53573e+00
21Feb12_165139|  -6.82580e-01 -1.03046e+00  2.14369e+00 -2.12686e+00  2.93875e-01]
21Feb12_165139| [-5.46699e-01 -1.24367e-01  1.50400e+00  5.24570e-01  1.32199e-01
21Feb12_165139|  -1.11873e+00 -1.21781e-01  1.60716e+00  7.94494e-01  4.12000e-02
21Feb12_165139|  -1.45629e-01 -1.67069e+00  1.55359e+00  1.27490e+00  3.78250e-01]
21Feb12_165139| [-1.65770e+00  7.63010e-01 -1.07032e-01 -1.29077e+00 -2.72523e-01
21Feb12_165139|   8.86152e-01  2.03137e-02  1.07244e+00 -2.07611e+00  1.79718e-01
21Feb12_165139|   1.81554e-01 -6.15758e-01 -9.51774e-01  1.02939e+00  8.17973e-01]
21Feb12_165139| [ 9.21545e-01 -8.71244e-02 -1.53454e+00 -1.66686e+00  9.25583e-02
21Feb12_165139|   5.45788e-01  9.00588e-01  5.39148e-01  1.73423e+00  5.95858e-01
21Feb12_165139|   7.60598e-01  7.10163e-01 -1.92447e-01 -2.18648e-01 -1.06613e-01]
21Feb12_165139| [-1.27156e+00  1.50471e-01 -1.51367e+00  2.43159e-01  1.45374e+00
21Feb12_165139|   1.39069e-01  1.63857e+00  7.76127e-01  1.22775e-01 -9.15383e-01
21Feb12_165139|  -7.88206e-01 -1.88443e-01  5.88849e-01 -1.15889e+00  1.57532e+00]
21Feb12_165139| [-7.87307e-01  7.90368e-01 -8.23463e-01 -7.31497e-01 -1.23567e+00
21Feb12_165139|   4.22757e-01  3.63316e-02  6.01964e-01  1.96999e+00 -1.17414e+00
21Feb12_165139|   3.97797e-01 -1.08808e+00 -5.94358e-01 -2.83672e-01  8.50566e-01]
21Feb12_165139| [ 5.30769e-01 -1.84801e+00 -5.66134e-01  6.76585e-02  1.10136e-01
21Feb12_165139|   4.92367e-01 -4.90997e-01  6.06677e-01  2.28381e+00 -4.07746e-02
21Feb12_165139|   1.15850e+00 -5.98080e-01 -7.01578e-01  1.01957e+00  2.49859e-01]
21Feb12_165139| [-8.63352e-01  1.10102e+00 -1.35284e+00  7.44546e-01  1.23832e+00
21Feb12_165139|  -5.46095e-01 -7.14545e-01  6.39714e-01 -1.05446e-01 -8.88602e-01
21Feb12_165139|   9.93232e-01  1.94862e+00 -4.16105e-01  1.03489e-01  1.11977e+00]
21Feb12_165139| [ 1.19516e+00 -1.76346e-01  1.04128e-01  1.20697e+00 -9.23981e-01
21Feb12_165139|  -1.33787e+00 -2.81645e-01  4.54001e-01  1.13838e-01  7.67530e-01
21Feb12_165139|  -1.19224e+00 -1.30105e-01 -1.91934e-01  4.19944e-01  1.69825e-01]
21Feb12_165139| [ 7.65088e-01 -1.94246e+00 -7.11338e-01  4.53958e-01  1.94201e+00
21Feb12_165139|   1.31030e+00 -2.96434e-02 -1.76407e+00  5.53828e-01  6.85560e-01
21Feb12_165139|   7.66333e-01  3.82096e-02 -8.16458e-01 -6.24116e-02  2.64193e-01]
21Feb12_165139| [ 3.18200e-01  2.29948e+00  1.64715e+00  1.62897e+00 -7.51376e-02
21Feb12_165139|  -1.28841e+00 -6.20669e-01 -1.11166e-01  8.60402e-01 -1.33019e+00
21Feb12_165139|  -5.96012e-01  1.43903e+00  4.95090e-01 -5.77593e-01  1.44906e+00]
21Feb12_165139| [ 4.11040e-01  7.04946e-01 -5.20407e-01  1.19926e-01 -2.14187e-01
21Feb12_165139|   2.61836e-01 -2.06690e-01 -5.23044e-01 -2.21768e+00 -1.84159e+00
21Feb12_165139|   1.07890e-01 -1.21571e+00  1.41906e-02 -1.18878e+00 -1.10586e+00]
21Feb12_165139| [ 7.47110e-04 -2.19367e-01  1.24132e+00  2.42981e-01  1.64975e+00
21Feb12_165139|  -7.56681e-01  2.05047e+00  1.41699e+00  2.11413e-01  2.05856e-01
21Feb12_165139|  -1.19536e+00 -1.17721e+00 -5.74572e-02 -9.88771e-01 -5.21745e-02]
21Feb12_165139| [ 8.41039e-01 -7.80210e-01  1.63153e-01  9.11562e-01  1.96584e+00
21Feb12_165139|   1.78291e+00  1.27725e-01  9.24125e-01  8.89095e-01  8.02583e-01
21Feb12_165139|  -1.84072e-01 -1.83956e+00 -1.02407e+00  6.97260e-01  2.04119e+00]
21Feb12_165139| [ 1.02325e+00 -1.14512e+00  1.53735e+00 -1.20875e+00  2.40349e-01
21Feb12_165139|   3.65149e-01 -8.45853e-01 -9.53877e-01  1.08881e+00  1.31369e+00
21Feb12_165139|  -8.73629e-01  3.54768e-01 -1.44120e+00  3.00774e+00  5.37138e-01]
21Feb12_165139| [ 1.21153e+00  1.33780e+00  2.37346e-01  1.10192e+00 -7.71109e-01
21Feb12_165139|  -1.67297e+00 -9.85041e-01 -9.67469e-02  1.35584e-01  1.43828e+00
21Feb12_165139|  -5.37772e-01  6.81867e-01  8.99423e-02 -3.00140e-01  7.40803e-01]
21Feb12_165139| [-1.53912e-01 -1.45545e+00 -8.51719e-01 -3.24207e-01 -1.85297e+00
21Feb12_165139|  -1.37632e+00  2.56265e+00 -1.51591e+00 -7.70917e-01  1.60742e+00
21Feb12_165139|   8.19418e-01  1.51279e+00 -7.75504e-01 -4.56317e-01  7.93313e-01]
21Feb12_165139| [ 1.79234e+00  5.37534e-01 -1.64985e-01  1.12594e+00  4.19165e-01
21Feb12_165139|   1.00815e+00 -1.24029e+00  8.99015e-02  5.04534e-01  1.04688e+00
21Feb12_165139|  -1.85983e+00 -6.28367e-01  1.44747e+00 -7.70927e-01 -6.80962e-02]
21Feb12_165139| [-6.11685e-01  5.81244e-01 -2.00813e+00  4.40980e-01  1.17081e+00
21Feb12_165139|   4.53617e-02 -1.02732e-01 -5.30344e-01 -2.30272e-01 -2.75712e-01
21Feb12_165139|  -1.35628e+00  6.77073e-01  1.18206e+00 -9.68516e-01  8.88227e-01]
21Feb12_165139| [ 3.39330e-01  1.85906e-01  3.17199e+00 -1.14941e+00  8.41043e-01
21Feb12_165139|   1.43171e+00  2.91815e-01  9.90040e-01  2.43151e-01 -4.20123e-01
21Feb12_165139|  -7.71009e-01  8.26689e-01 -2.38729e-01  2.25124e-01  4.71938e-02]
21Feb12_165139| [-1.24769e+00 -1.74352e-01  1.33159e+00  6.31103e-01  1.39801e-01
21Feb12_165139|  -1.97232e-01  1.00881e+00 -1.05164e+00 -1.26316e-01 -6.77330e-01
21Feb12_165139|   6.93223e-01  3.09964e-01  4.46448e-01  3.28001e-01 -7.51083e-01]
21Feb12_165139| [-7.55157e-01 -1.20070e+00  1.18128e+00  2.31557e-01 -5.77142e-01
21Feb12_165139|   8.50621e-01 -6.80691e-01  1.14562e+00  6.53826e-01 -1.28380e+00
21Feb12_165139|   4.15503e-02  9.67591e-01 -3.56690e+00 -2.80446e-01 -2.39691e-01]
21Feb12_165139| [ 1.43065e+00  4.89999e-01  7.08940e-01  9.80815e-01 -5.25905e-01
21Feb12_165139|   8.92854e-01 -1.47577e+00 -9.27641e-02 -3.34619e-01 -1.41270e+00
21Feb12_165139|  -1.10591e+00  1.59163e+00  2.61333e-01 -1.48185e+00 -2.14182e+00]
21Feb12_165139| [ 8.38600e-01 -8.88508e-01 -4.12187e-01 -1.04812e-01  3.26908e-01
21Feb12_165139|  -9.83693e-01  1.67864e+00  7.72612e-01  1.95026e+00  9.57917e-01
21Feb12_165139|  -1.48928e+00 -1.99797e-01 -3.05136e-01 -1.14633e-01 -1.04672e+00]]
21Feb12_165139|-- Bias --
21Feb12_165139|[ 0.73695 -0.51772  1.29843 -0.86449  0.54318  0.17660 -0.21569  0.35471
21Feb12_165139| -0.23531 -0.15791  1.04286  0.77391 -0.11794  1.01790  0.50375]
21Feb12_165139|Layer 1:
21Feb12_165139|-- Config --
21Feb12_165139|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 15], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_165139|-- Weights --
21Feb12_165139|[[ 0.70443 -1.08724]
21Feb12_165139| [-0.44561 -1.05050]
21Feb12_165139| [ 0.25488  0.31427]
21Feb12_165139| [-1.40193  0.84859]
21Feb12_165139| [ 0.27127 -0.15942]
21Feb12_165139| [-0.18528 -0.14003]
21Feb12_165139| [ 1.68717  0.30442]
21Feb12_165139| [-0.01440  0.47743]
21Feb12_165139| [ 0.46612  0.57491]
21Feb12_165139| [-1.91613 -0.31596]
21Feb12_165139| [ 1.38318 -0.97860]
21Feb12_165139| [-0.49568  0.13334]
21Feb12_165139| [ 0.67487 -1.08400]
21Feb12_165139| [ 1.22898  1.13422]
21Feb12_165139| [ 0.14442 -0.69100]]
21Feb12_165139|-- Bias --
21Feb12_165139|[ 1.12271 -0.02168]
21Feb12_165139|Predicting the validation and test data with the Best final individual.
21Feb12_165147| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_165147|-----------  ------------------  --------------------  ----------
21Feb12_165147|Validation         41.91                  15            0.00259
21Feb12_165147|   Test            36.40                  15            0.00595
21Feb12_165147|-------------------- Test #12 --------------------
21Feb12_165147|Best final individual weights
21Feb12_165147|Individual:
21Feb12_165147|-- Constant hidden layers --
21Feb12_165147|False
21Feb12_165147|Layer 0:
21Feb12_165147|-- Config --
21Feb12_165147|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 15, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_165147|-- Weights --
21Feb12_165147|[[ 5.09617e-01  8.20902e-01 -3.02367e-01 -9.64837e-01 -4.33824e-01
21Feb12_165147|  -2.42034e-01 -5.04343e-01  1.31689e+00  9.21850e-01  5.13818e-01
21Feb12_165147|  -3.49854e-01  2.15852e-01 -1.04928e+00  7.68905e-01 -1.88324e+00]
21Feb12_165147| [-7.50915e-01 -2.52628e+00  3.69383e-01  1.39331e-01 -4.71230e-01
21Feb12_165147|   2.50267e+00 -2.55477e-01 -5.15419e-01 -2.31831e-01 -1.16548e+00
21Feb12_165147|  -8.22133e-01  4.82232e-01 -1.26500e+00  7.69663e-01  1.16647e+00]
21Feb12_165147| [ 4.01389e-03  9.01850e-01 -4.38696e-01 -7.91041e-01 -3.45664e-01
21Feb12_165147|  -1.66871e+00  1.65396e+00  7.90223e-01  5.51123e-01  1.67606e-01
21Feb12_165147|   2.12442e-01  1.14271e+00  6.42674e-01  2.00899e-01 -2.05944e-01]
21Feb12_165147| [ 1.80619e-01 -2.50060e-01 -1.12859e+00  1.83522e+00  1.81374e+00
21Feb12_165147|  -1.42416e+00  5.22823e-01 -7.02013e-01  1.84516e+00  1.90809e+00
21Feb12_165147|   1.37151e+00  4.03871e-02  4.29238e-01 -2.37117e-01 -1.00132e+00]
21Feb12_165147| [ 4.39871e-01  3.98574e-01 -3.75109e-01 -8.64825e-01  4.06425e-01
21Feb12_165147|   5.56500e-01  1.44148e+00 -5.22177e-01 -7.21740e-01  3.07682e-01
21Feb12_165147|  -9.52454e-01  8.44086e-01  1.09295e+00 -3.90444e-01  1.33545e+00]
21Feb12_165147| [-1.42180e+00  3.85641e-01 -8.43471e-02  1.81738e-02 -1.14521e+00
21Feb12_165147|  -8.06111e-01 -8.15090e-01  7.76165e-02  1.02784e+00  1.02123e-01
21Feb12_165147|   7.08213e-01  9.96943e-01 -7.79890e-01  1.66778e+00 -6.05761e-01]
21Feb12_165147| [-2.52774e-01 -9.61820e-01  3.02997e+00 -4.75355e-02  9.27908e-01
21Feb12_165147|   6.12327e-01 -4.65796e-01  8.85447e-01 -9.19731e-02  5.35502e-02
21Feb12_165147|  -5.61515e-01  1.22163e+00 -6.55581e-02 -4.23284e-01  6.78889e-01]
21Feb12_165147| [-4.07954e-01  7.89564e-01 -1.02275e+00 -1.42852e-01 -1.21182e-01
21Feb12_165147|   2.60288e+00  1.31219e+00 -1.05105e+00 -7.28076e-01  7.37981e-01
21Feb12_165147|   1.07877e+00  4.12772e-01  3.20972e-01 -1.42903e+00  5.49771e-01]
21Feb12_165147| [-1.06598e+00  4.11763e-01 -5.98736e-01 -1.02922e+00  1.44690e+00
21Feb12_165147|   1.61847e+00  7.86271e-01 -1.04439e+00 -1.22083e+00 -5.20594e-01
21Feb12_165147|   1.50709e+00 -2.76750e-01 -9.31489e-01  1.18032e+00 -1.34476e+00]
21Feb12_165147| [-9.84737e-01 -5.97909e-01 -5.05735e-01  1.21453e+00  2.04300e+00
21Feb12_165147|  -1.80226e+00  2.27960e-01  2.48235e-01 -9.14083e-01 -8.19925e-01
21Feb12_165147|   8.79325e-03  1.89321e+00 -2.33314e+00  3.64489e-01 -8.65853e-01]
21Feb12_165147| [-5.52147e-01 -1.09026e+00 -6.31263e-01 -9.85456e-02 -1.26793e+00
21Feb12_165147|   6.92239e-01  4.07591e-03  8.28704e-02 -4.61769e-01  1.47380e+00
21Feb12_165147|  -8.25050e-01  1.85307e+00 -7.02559e-01  4.42800e-01 -5.09351e-01]
21Feb12_165147| [-1.22241e+00 -2.82164e+00 -3.49419e-01  2.35780e-01 -3.06882e-01
21Feb12_165147|   4.97633e-01 -8.59745e-01  1.41005e+00  4.44223e-01  4.80295e-01
21Feb12_165147|   5.28514e-01 -8.52095e-01  7.93638e-01 -1.18061e+00  3.77575e-01]
21Feb12_165147| [ 1.83848e+00  1.86747e+00 -6.09064e-01 -1.29117e-01  8.20239e-01
21Feb12_165147|  -8.41223e-01 -4.91994e-01 -4.35134e-02 -3.10526e-01  8.12742e-01
21Feb12_165147|  -2.48499e+00  6.10492e-01  2.59825e-01  1.10740e+00  2.25110e-01]
21Feb12_165147| [-9.61110e-02  1.17814e+00  1.12148e-01 -3.49813e-01  2.43858e+00
21Feb12_165147|  -1.38613e+00 -3.82927e-01  1.52932e+00  8.48623e-01 -1.99483e+00
21Feb12_165147|  -2.12240e+00  1.06312e+00 -3.90781e-02  1.49640e+00  1.12926e+00]
21Feb12_165147| [-4.30616e-01  2.39031e-01 -7.23476e-01  1.25568e+00 -2.14845e-01
21Feb12_165147|  -5.53173e-01 -2.65699e+00  2.69230e-02 -1.00392e+00  1.32765e-01
21Feb12_165147|  -5.64005e-01  1.22524e+00  1.24383e+00 -1.09592e+00 -1.41796e+00]
21Feb12_165147| [-2.39791e-01  1.53064e+00  3.01720e-01  2.78106e-01 -1.84792e-01
21Feb12_165147|   1.56208e+00  9.94463e-01 -1.63904e+00  6.63295e-01 -1.85188e+00
21Feb12_165147|  -7.33287e-01 -1.62705e-01 -9.61094e-01  4.14256e-01 -1.81088e+00]
21Feb12_165147| [ 2.83794e-01  7.82624e-01  8.22930e-01  1.38834e+00  1.35777e+00
21Feb12_165147|   1.13137e+00 -4.51094e-01 -9.14736e-02 -4.29153e-01 -1.32003e-01
21Feb12_165147|  -1.06833e+00 -3.60741e-02 -1.72337e+00 -9.36812e-02 -1.50919e-01]
21Feb12_165147| [ 4.60832e-01 -6.41447e-01  7.19778e-01  1.43690e+00 -5.39012e-01
21Feb12_165147|   2.73839e+00  4.18203e-02  1.12728e+00 -1.96359e+00  5.08015e-01
21Feb12_165147|  -3.94637e-02  1.21425e+00  7.81562e-01  1.21240e+00  8.71932e-02]
21Feb12_165147| [ 7.21067e-01 -4.05470e-01  4.30706e-01 -1.12406e+00 -1.66416e-01
21Feb12_165147|  -1.74613e-01 -2.82475e+00  7.83187e-01 -1.70599e+00 -4.53800e-01
21Feb12_165147|   7.68700e-02  1.38626e+00  4.71260e-01 -1.20854e-01 -3.85957e-01]
21Feb12_165147| [-1.45393e+00 -4.35386e-01  7.35002e-01 -1.05813e+00 -6.41567e-01
21Feb12_165147|  -1.23953e+00 -1.11174e+00 -4.33161e-01  1.71285e+00 -1.69152e+00
21Feb12_165147|  -3.94477e-01 -9.64481e-01  2.12241e-01 -4.51296e-01  6.12573e-01]
21Feb12_165147| [ 1.91178e+00 -7.20020e-01 -1.43347e+00  6.16597e-01 -1.40631e-01
21Feb12_165147|   9.60419e-01 -2.94601e-01 -3.70235e-01  1.68500e-03 -7.06077e-02
21Feb12_165147|  -2.63686e+00 -7.93469e-01  3.46275e-01  2.04211e+00  9.19580e-01]
21Feb12_165147| [ 2.28690e-01 -1.52406e-01 -4.49362e-01 -7.32180e-01  7.99781e-01
21Feb12_165147|   4.88373e-01 -9.34696e-01 -5.02242e-01  9.68074e-01 -3.07760e-01
21Feb12_165147|  -3.49720e-01 -2.00695e+00 -4.45838e-01  2.62312e-01  3.38818e-01]
21Feb12_165147| [-1.98557e-01  8.34883e-01 -1.61905e-01  1.28379e+00  1.04073e+00
21Feb12_165147|   1.45833e+00  4.77341e-01  9.87420e-01 -3.08856e-01 -1.55031e+00
21Feb12_165147|   1.38023e+00 -4.42201e-01  1.78369e+00  8.01018e-01  1.52483e+00]
21Feb12_165147| [ 1.12967e+00 -8.45423e-01  1.52345e+00  1.08801e+00 -4.32434e-01
21Feb12_165147|  -3.16741e-01 -7.17985e-02  1.09877e+00 -7.90690e-01  1.36084e+00
21Feb12_165147|  -5.66120e-01 -1.70432e+00 -2.12910e+00 -2.41374e-01  1.33636e+00]
21Feb12_165147| [-4.08205e-01 -8.03871e-01  9.13990e-01  5.00916e-01 -1.81059e-01
21Feb12_165147|   2.42621e-01 -9.57869e-01  6.74094e-01  6.52179e-01  2.77279e-01
21Feb12_165147|  -3.91051e-01 -9.05321e-02  6.86316e-01 -3.54594e-01  5.83144e-01]
21Feb12_165147| [-3.98308e-01 -4.48018e-03  1.11987e+00  1.50374e+00 -9.18129e-01
21Feb12_165147|  -1.81690e+00 -1.38223e+00 -2.74481e-01 -8.24843e-01 -7.05820e-01
21Feb12_165147|   1.50584e+00 -4.21386e-01  4.00084e-01 -7.61841e-02 -7.41767e-01]
21Feb12_165147| [ 5.51762e-01 -1.04904e+00  5.21335e-01  2.14684e-01 -8.21795e-02
21Feb12_165147|   3.68556e-01  1.01222e+00 -1.30634e+00 -1.52652e+00  9.98379e-01
21Feb12_165147|   8.51997e-01 -9.42775e-01 -1.16577e-01  3.64988e-01 -1.27419e+00]
21Feb12_165147| [ 1.67425e+00 -1.27190e-01  2.44775e+00  1.44302e+00 -4.43112e-01
21Feb12_165147|  -4.07317e-02  1.33875e-01  4.92876e-01  1.36327e+00  3.41424e-01
21Feb12_165147|   1.70937e+00 -2.26414e+00  5.48087e-01 -2.49869e-01 -1.95666e+00]
21Feb12_165147| [-7.77069e-01  1.76839e+00 -5.99460e-01 -2.13769e+00  1.38006e+00
21Feb12_165147|   1.30623e+00 -1.06865e+00 -1.16462e+00  8.02528e-01 -3.99780e-01
21Feb12_165147|   8.20611e-01 -1.64613e-01  3.17174e-01  1.50755e+00  1.82851e-01]
21Feb12_165147| [-1.02989e+00 -1.07499e+00 -1.93091e+00  4.66271e-01 -8.74190e-01
21Feb12_165147|  -1.32185e+00 -9.08286e-01 -8.46363e-01  2.03651e-01 -2.52017e-01
21Feb12_165147|   1.15748e+00 -3.29038e-01 -5.53034e-01  6.31862e-01 -9.38469e-02]
21Feb12_165147| [-1.07650e+00  2.26383e-01  1.43406e-01 -1.04859e+00 -1.13255e+00
21Feb12_165147|   5.32942e-01 -2.81361e-01  1.06039e+00 -4.84886e-01  1.81779e+00
21Feb12_165147|   4.45898e-01  1.15599e-01  2.22637e+00 -1.10477e+00 -7.41273e-01]
21Feb12_165147| [ 5.36190e-01  1.36053e+00  1.86442e-01  1.76821e-01  1.73842e+00
21Feb12_165147|   1.33653e-01 -2.69435e-01  1.42842e+00 -6.67924e-01  8.34192e-01
21Feb12_165147|  -4.93949e-01  2.55190e-01  8.44813e-02  1.07023e+00  3.32795e-01]
21Feb12_165147| [-7.77858e-01  6.91255e-01 -2.00094e-01 -3.47804e-02  1.25963e+00
21Feb12_165147|   2.88406e-01  1.11181e-02 -1.72072e-01  1.74171e-01  1.07767e+00
21Feb12_165147|  -7.57539e-01 -1.51881e+00  1.13432e+00 -8.19687e-01  2.51036e-01]
21Feb12_165147| [ 1.17877e+00  8.51361e-01  5.34249e-01 -3.85201e-01  1.62741e+00
21Feb12_165147|   7.14108e-01 -2.49586e-01 -1.51061e+00 -5.78471e-01 -1.53573e+00
21Feb12_165147|  -6.82580e-01 -1.03046e+00  2.14369e+00 -2.12686e+00  2.93875e-01]
21Feb12_165147| [-5.46699e-01 -1.24367e-01  1.50400e+00  5.24570e-01  1.32199e-01
21Feb12_165147|  -1.11873e+00 -1.21781e-01  1.60716e+00  7.94494e-01  4.12000e-02
21Feb12_165147|  -1.45629e-01 -1.67069e+00  1.55359e+00  1.27490e+00  3.78250e-01]
21Feb12_165147| [-1.65770e+00  7.63010e-01 -1.07032e-01 -1.29077e+00 -2.72523e-01
21Feb12_165147|   8.86152e-01  2.03137e-02  1.07244e+00 -2.07611e+00  1.79718e-01
21Feb12_165147|   1.81554e-01 -6.15758e-01 -9.51774e-01  1.02939e+00  8.17973e-01]
21Feb12_165147| [ 9.21545e-01 -8.71244e-02 -1.53454e+00 -1.66686e+00  9.25583e-02
21Feb12_165147|   5.45788e-01  9.00588e-01  5.39148e-01  1.73423e+00  5.95858e-01
21Feb12_165147|   7.60598e-01  7.10163e-01 -1.92447e-01 -2.18648e-01 -1.06613e-01]
21Feb12_165147| [-1.27156e+00  1.50471e-01 -1.51367e+00  2.43159e-01  1.45374e+00
21Feb12_165147|   1.39069e-01  1.63857e+00  7.76127e-01  1.22775e-01 -9.15383e-01
21Feb12_165147|  -7.88206e-01 -1.88443e-01  5.88849e-01 -1.15889e+00  1.57532e+00]
21Feb12_165147| [-7.87307e-01  7.90368e-01 -8.23463e-01 -7.31497e-01 -1.23567e+00
21Feb12_165147|   4.22757e-01  3.63316e-02  6.01964e-01  1.96999e+00 -1.17414e+00
21Feb12_165147|   3.97797e-01 -1.08808e+00 -5.94358e-01 -2.83672e-01  8.50566e-01]
21Feb12_165147| [ 5.30769e-01 -1.84801e+00 -5.66134e-01  6.76585e-02  1.10136e-01
21Feb12_165147|   4.92367e-01 -4.90997e-01  6.06677e-01  2.28381e+00 -4.07746e-02
21Feb12_165147|   1.15850e+00 -5.98080e-01 -7.01578e-01  1.01957e+00  2.49859e-01]
21Feb12_165147| [-8.63352e-01  1.10102e+00 -1.35284e+00  7.44546e-01  1.23832e+00
21Feb12_165147|  -5.46095e-01 -7.14545e-01  6.39714e-01 -1.05446e-01 -8.88602e-01
21Feb12_165147|   9.93232e-01  1.94862e+00 -4.16105e-01  1.03489e-01  1.11977e+00]
21Feb12_165147| [ 1.19516e+00 -1.76346e-01  1.04128e-01  1.20697e+00 -9.23981e-01
21Feb12_165147|  -1.33787e+00 -2.81645e-01  4.54001e-01  1.13838e-01  7.67530e-01
21Feb12_165147|  -1.19224e+00 -1.30105e-01 -1.91934e-01  4.19944e-01  1.69825e-01]
21Feb12_165147| [ 7.65088e-01 -1.94246e+00 -7.11338e-01  4.53958e-01  1.94201e+00
21Feb12_165147|   1.31030e+00 -2.96434e-02 -1.76407e+00  5.53828e-01  6.85560e-01
21Feb12_165147|   7.66333e-01  3.82096e-02 -8.16458e-01 -6.24116e-02  2.64193e-01]
21Feb12_165147| [ 3.18200e-01  2.29948e+00  1.64715e+00  1.62897e+00 -7.51376e-02
21Feb12_165147|  -1.28841e+00 -6.20669e-01 -1.11166e-01  8.60402e-01 -1.33019e+00
21Feb12_165147|  -5.96012e-01  1.43903e+00  4.95090e-01 -5.77593e-01  1.44906e+00]
21Feb12_165147| [ 4.11040e-01  7.04946e-01 -5.20407e-01  1.19926e-01 -2.14187e-01
21Feb12_165147|   2.61836e-01 -2.06690e-01 -5.23044e-01 -2.21768e+00 -1.84159e+00
21Feb12_165147|   1.07890e-01 -1.21571e+00  1.41906e-02 -1.18878e+00 -1.10586e+00]
21Feb12_165147| [ 7.47110e-04 -2.19367e-01  1.24132e+00  2.42981e-01  1.64975e+00
21Feb12_165147|  -7.56681e-01  2.05047e+00  1.41699e+00  2.11413e-01  2.05856e-01
21Feb12_165147|  -1.19536e+00 -1.17721e+00 -5.74572e-02 -9.88771e-01 -5.21745e-02]
21Feb12_165147| [ 8.41039e-01 -7.80210e-01  1.63153e-01  9.11562e-01  1.96584e+00
21Feb12_165147|   1.78291e+00  1.27725e-01  9.24125e-01  8.89095e-01  8.02583e-01
21Feb12_165147|  -1.84072e-01 -1.83956e+00 -1.02407e+00  6.97260e-01  2.04119e+00]
21Feb12_165147| [ 1.02325e+00 -1.14512e+00  1.53735e+00 -1.20875e+00  2.40349e-01
21Feb12_165147|   3.65149e-01 -8.45853e-01 -9.53877e-01  1.08881e+00  1.31369e+00
21Feb12_165147|  -8.73629e-01  3.54768e-01 -1.44120e+00  3.00774e+00  5.37138e-01]
21Feb12_165147| [ 1.21153e+00  1.33780e+00  2.37346e-01  1.10192e+00 -7.71109e-01
21Feb12_165147|  -1.67297e+00 -9.85041e-01 -9.67469e-02  1.35584e-01  1.43828e+00
21Feb12_165147|  -5.37772e-01  6.81867e-01  8.99423e-02 -3.00140e-01  7.40803e-01]
21Feb12_165147| [-1.53912e-01 -1.45545e+00 -8.51719e-01 -3.24207e-01 -1.85297e+00
21Feb12_165147|  -1.37632e+00  2.56265e+00 -1.51591e+00 -7.70917e-01  1.60742e+00
21Feb12_165147|   8.19418e-01  1.51279e+00 -7.75504e-01 -4.56317e-01  7.93313e-01]
21Feb12_165147| [ 1.79234e+00  5.37534e-01 -1.64985e-01  1.12594e+00  4.19165e-01
21Feb12_165147|   1.00815e+00 -1.24029e+00  8.99015e-02  5.04534e-01  1.04688e+00
21Feb12_165147|  -1.85983e+00 -6.28367e-01  1.44747e+00 -7.70927e-01 -6.80962e-02]
21Feb12_165147| [-6.11685e-01  5.81244e-01 -2.00813e+00  4.40980e-01  1.17081e+00
21Feb12_165147|   4.53617e-02 -1.02732e-01 -5.30344e-01 -2.30272e-01 -2.75712e-01
21Feb12_165147|  -1.35628e+00  6.77073e-01  1.18206e+00 -9.68516e-01  8.88227e-01]
21Feb12_165147| [ 3.39330e-01  1.85906e-01  3.17199e+00 -1.14941e+00  8.41043e-01
21Feb12_165147|   1.43171e+00  2.91815e-01  9.90040e-01  2.43151e-01 -4.20123e-01
21Feb12_165147|  -7.71009e-01  8.26689e-01 -2.38729e-01  2.25124e-01  4.71938e-02]
21Feb12_165147| [-1.24769e+00 -1.74352e-01  1.33159e+00  6.31103e-01  1.39801e-01
21Feb12_165147|  -1.97232e-01  1.00881e+00 -1.05164e+00 -1.26316e-01 -6.77330e-01
21Feb12_165147|   6.93223e-01  3.09964e-01  4.46448e-01  3.28001e-01 -7.51083e-01]
21Feb12_165147| [-7.55157e-01 -1.20070e+00  1.18128e+00  2.31557e-01 -5.77142e-01
21Feb12_165147|   8.50621e-01 -6.80691e-01  1.14562e+00  6.53826e-01 -1.28380e+00
21Feb12_165147|   4.15503e-02  9.67591e-01 -3.56690e+00 -2.80446e-01 -2.39691e-01]
21Feb12_165147| [ 1.43065e+00  4.89999e-01  7.08940e-01  9.80815e-01 -5.25905e-01
21Feb12_165147|   8.92854e-01 -1.47577e+00 -9.27641e-02 -3.34619e-01 -1.41270e+00
21Feb12_165147|  -1.10591e+00  1.59163e+00  2.61333e-01 -1.48185e+00 -2.14182e+00]
21Feb12_165147| [ 8.38600e-01 -8.88508e-01 -4.12187e-01 -1.04812e-01  3.26908e-01
21Feb12_165147|  -9.83693e-01  1.67864e+00  7.72612e-01  1.95026e+00  9.57917e-01
21Feb12_165147|  -1.48928e+00 -1.99797e-01 -3.05136e-01 -1.14633e-01 -1.04672e+00]]
21Feb12_165147|-- Bias --
21Feb12_165147|[ 0.73695 -0.51772  1.29843 -0.86449  0.54318  0.17660 -0.21569  0.35471
21Feb12_165147| -0.23531 -0.15791  1.04286  0.77391 -0.11794  1.01790  0.50375]
21Feb12_165147|Layer 1:
21Feb12_165147|-- Config --
21Feb12_165147|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 15], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_165147|-- Weights --
21Feb12_165147|[[ 0.70443 -1.08724]
21Feb12_165147| [-0.44561 -1.05050]
21Feb12_165147| [ 0.25488  0.31427]
21Feb12_165147| [-1.40193  0.84859]
21Feb12_165147| [ 0.27127 -0.15942]
21Feb12_165147| [-0.18528 -0.14003]
21Feb12_165147| [ 1.68717  0.30442]
21Feb12_165147| [-0.01440  0.47743]
21Feb12_165147| [ 0.46612  0.57491]
21Feb12_165147| [-1.91613 -0.31596]
21Feb12_165147| [ 1.38318 -0.97860]
21Feb12_165147| [-0.49568  0.13334]
21Feb12_165147| [ 0.67487 -1.08400]
21Feb12_165147| [ 1.22898  1.13422]
21Feb12_165147| [ 0.14442 -0.69100]]
21Feb12_165147|-- Bias --
21Feb12_165147|[ 1.12271 -0.02168]
21Feb12_165147|Predicting the validation and test data with the Best final individual.
21Feb12_165154| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_165154|-----------  ------------------  --------------------  ----------
21Feb12_165154|Validation         42.00                  15            0.00000
21Feb12_165154|   Test            36.49                  15            0.00000
21Feb12_165154|-------------------- Test #13 --------------------
21Feb12_165154|Best final individual weights
21Feb12_165154|Individual:
21Feb12_165154|-- Constant hidden layers --
21Feb12_165154|False
21Feb12_165154|Layer 0:
21Feb12_165154|-- Config --
21Feb12_165154|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 15, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_165154|-- Weights --
21Feb12_165154|[[ 5.09617e-01  8.20902e-01 -3.02367e-01 -9.64837e-01 -4.33824e-01
21Feb12_165154|  -2.42034e-01 -5.04343e-01  1.31689e+00  9.21850e-01  5.13818e-01
21Feb12_165154|  -3.49854e-01  2.15852e-01 -1.04928e+00  7.68905e-01 -1.88324e+00]
21Feb12_165154| [-7.50915e-01 -2.52628e+00  3.69383e-01  1.39331e-01 -4.71230e-01
21Feb12_165154|   2.50267e+00 -2.55477e-01 -5.15419e-01 -2.31831e-01 -1.16548e+00
21Feb12_165154|  -8.22133e-01  4.82232e-01 -1.26500e+00  7.69663e-01  1.16647e+00]
21Feb12_165154| [ 4.01389e-03  9.01850e-01 -4.38696e-01 -7.91041e-01 -3.45664e-01
21Feb12_165154|  -1.66871e+00  1.65396e+00  7.90223e-01  5.51123e-01  1.67606e-01
21Feb12_165154|   2.12442e-01  1.14271e+00  6.42674e-01  2.00899e-01 -2.05944e-01]
21Feb12_165154| [ 1.80619e-01 -2.50060e-01 -1.12859e+00  1.83522e+00  1.81374e+00
21Feb12_165154|  -1.42416e+00  5.22823e-01 -7.02013e-01  1.84516e+00  1.90809e+00
21Feb12_165154|   1.37151e+00  4.03871e-02  4.29238e-01 -2.37117e-01 -1.00132e+00]
21Feb12_165154| [ 4.39871e-01  3.98574e-01 -3.75109e-01 -8.64825e-01  4.06425e-01
21Feb12_165154|   5.56500e-01  1.44148e+00 -5.22177e-01 -7.21740e-01  3.07682e-01
21Feb12_165154|  -9.52454e-01  8.44086e-01  1.09295e+00 -3.90444e-01  1.33545e+00]
21Feb12_165154| [-1.42180e+00  3.85641e-01 -8.43471e-02  1.81738e-02 -1.14521e+00
21Feb12_165154|  -8.06111e-01 -8.15090e-01  7.76165e-02  1.02784e+00  1.02123e-01
21Feb12_165154|   7.08213e-01  9.96943e-01 -7.79890e-01  1.66778e+00 -6.05761e-01]
21Feb12_165154| [-2.52774e-01 -9.61820e-01  3.02997e+00 -4.75355e-02  9.27908e-01
21Feb12_165154|   6.12327e-01 -4.65796e-01  8.85447e-01 -9.19731e-02  5.35502e-02
21Feb12_165154|  -5.61515e-01  1.22163e+00 -6.55581e-02 -4.23284e-01  6.78889e-01]
21Feb12_165154| [-4.07954e-01  7.89564e-01 -1.02275e+00 -1.42852e-01 -1.21182e-01
21Feb12_165154|   2.60288e+00  1.31219e+00 -1.05105e+00 -7.28076e-01  7.37981e-01
21Feb12_165154|   1.07877e+00  4.12772e-01  3.20972e-01 -1.42903e+00  5.49771e-01]
21Feb12_165154| [-1.06598e+00  4.11763e-01 -5.98736e-01 -1.02922e+00  1.44690e+00
21Feb12_165154|   1.61847e+00  7.86271e-01 -1.04439e+00 -1.22083e+00 -5.20594e-01
21Feb12_165154|   1.50709e+00 -2.76750e-01 -9.31489e-01  1.18032e+00 -1.34476e+00]
21Feb12_165154| [-9.84737e-01 -5.97909e-01 -5.05735e-01  1.21453e+00  2.04300e+00
21Feb12_165154|  -1.80226e+00  2.27960e-01  2.48235e-01 -9.14083e-01 -8.19925e-01
21Feb12_165154|   8.79325e-03  1.89321e+00 -2.33314e+00  3.64489e-01 -8.65853e-01]
21Feb12_165154| [-5.52147e-01 -1.09026e+00 -6.31263e-01 -9.85456e-02 -1.26793e+00
21Feb12_165154|   6.92239e-01  4.07591e-03  8.28704e-02 -4.61769e-01  1.47380e+00
21Feb12_165154|  -8.25050e-01  1.85307e+00 -7.02559e-01  4.42800e-01 -5.09351e-01]
21Feb12_165154| [-1.22241e+00 -2.82164e+00 -3.49419e-01  2.35780e-01 -3.06882e-01
21Feb12_165154|   4.97633e-01 -8.59745e-01  1.41005e+00  4.44223e-01  4.80295e-01
21Feb12_165154|   5.28514e-01 -8.52095e-01  7.93638e-01 -1.18061e+00  3.77575e-01]
21Feb12_165154| [ 1.83848e+00  1.86747e+00 -6.09064e-01 -1.29117e-01  8.20239e-01
21Feb12_165154|  -8.41223e-01 -4.91994e-01 -4.35134e-02 -3.10526e-01  8.12742e-01
21Feb12_165154|  -2.48499e+00  6.10492e-01  2.59825e-01  1.10740e+00  2.25110e-01]
21Feb12_165154| [-9.61110e-02  1.17814e+00  1.12148e-01 -3.49813e-01  2.43858e+00
21Feb12_165154|  -1.38613e+00 -3.82927e-01  1.52932e+00  8.48623e-01 -1.99483e+00
21Feb12_165154|  -2.12240e+00  1.06312e+00 -3.90781e-02  1.49640e+00  1.12926e+00]
21Feb12_165154| [-4.30616e-01  2.39031e-01 -7.23476e-01  1.25568e+00 -2.14845e-01
21Feb12_165154|  -5.53173e-01 -2.65699e+00  2.69230e-02 -1.00392e+00  1.32765e-01
21Feb12_165154|  -5.64005e-01  1.22524e+00  1.24383e+00 -1.09592e+00 -1.41796e+00]
21Feb12_165154| [-2.39791e-01  1.53064e+00  3.01720e-01  2.78106e-01 -1.84792e-01
21Feb12_165154|   1.56208e+00  9.94463e-01 -1.63904e+00  6.63295e-01 -1.85188e+00
21Feb12_165154|  -7.33287e-01 -1.62705e-01 -9.61094e-01  4.14256e-01 -1.81088e+00]
21Feb12_165154| [ 2.83794e-01  7.82624e-01  8.22930e-01  1.38834e+00  1.35777e+00
21Feb12_165154|   1.13137e+00 -4.51094e-01 -9.14736e-02 -4.29153e-01 -1.32003e-01
21Feb12_165154|  -1.06833e+00 -3.60741e-02 -1.72337e+00 -9.36812e-02 -1.50919e-01]
21Feb12_165154| [ 4.60832e-01 -6.41447e-01  7.19778e-01  1.43690e+00 -5.39012e-01
21Feb12_165154|   2.73839e+00  4.18203e-02  1.12728e+00 -1.96359e+00  5.08015e-01
21Feb12_165154|  -3.94637e-02  1.21425e+00  7.81562e-01  1.21240e+00  8.71932e-02]
21Feb12_165154| [ 7.21067e-01 -4.05470e-01  4.30706e-01 -1.12406e+00 -1.66416e-01
21Feb12_165154|  -1.74613e-01 -2.82475e+00  7.83187e-01 -1.70599e+00 -4.53800e-01
21Feb12_165154|   7.68700e-02  1.38626e+00  4.71260e-01 -1.20854e-01 -3.85957e-01]
21Feb12_165154| [-1.45393e+00 -4.35386e-01  7.35002e-01 -1.05813e+00 -6.41567e-01
21Feb12_165154|  -1.23953e+00 -1.11174e+00 -4.33161e-01  1.71285e+00 -1.69152e+00
21Feb12_165154|  -3.94477e-01 -9.64481e-01  2.12241e-01 -4.51296e-01  6.12573e-01]
21Feb12_165154| [ 1.91178e+00 -7.20020e-01 -1.43347e+00  6.16597e-01 -1.40631e-01
21Feb12_165154|   9.60419e-01 -2.94601e-01 -3.70235e-01  1.68500e-03 -7.06077e-02
21Feb12_165154|  -2.63686e+00 -7.93469e-01  3.46275e-01  2.04211e+00  9.19580e-01]
21Feb12_165154| [ 2.28690e-01 -1.52406e-01 -4.49362e-01 -7.32180e-01  7.99781e-01
21Feb12_165154|   4.88373e-01 -9.34696e-01 -5.02242e-01  9.68074e-01 -3.07760e-01
21Feb12_165154|  -3.49720e-01 -2.00695e+00 -4.45838e-01  2.62312e-01  3.38818e-01]
21Feb12_165154| [-1.98557e-01  8.34883e-01 -1.61905e-01  1.28379e+00  1.04073e+00
21Feb12_165154|   1.45833e+00  4.77341e-01  9.87420e-01 -3.08856e-01 -1.55031e+00
21Feb12_165154|   1.38023e+00 -4.42201e-01  1.78369e+00  8.01018e-01  1.52483e+00]
21Feb12_165154| [ 1.12967e+00 -8.45423e-01  1.52345e+00  1.08801e+00 -4.32434e-01
21Feb12_165154|  -3.16741e-01 -7.17985e-02  1.09877e+00 -7.90690e-01  1.36084e+00
21Feb12_165154|  -5.66120e-01 -1.70432e+00 -2.12910e+00 -2.41374e-01  1.33636e+00]
21Feb12_165154| [-4.08205e-01 -8.03871e-01  9.13990e-01  5.00916e-01 -1.81059e-01
21Feb12_165154|   2.42621e-01 -9.57869e-01  6.74094e-01  6.52179e-01  2.77279e-01
21Feb12_165154|  -3.91051e-01 -9.05321e-02  6.86316e-01 -3.54594e-01  5.83144e-01]
21Feb12_165154| [-3.98308e-01 -4.48018e-03  1.11987e+00  1.50374e+00 -9.18129e-01
21Feb12_165154|  -1.81690e+00 -1.38223e+00 -2.74481e-01 -8.24843e-01 -7.05820e-01
21Feb12_165154|   1.50584e+00 -4.21386e-01  4.00084e-01 -7.61841e-02 -7.41767e-01]
21Feb12_165154| [ 5.51762e-01 -1.04904e+00  5.21335e-01  2.14684e-01 -8.21795e-02
21Feb12_165154|   3.68556e-01  1.01222e+00 -1.30634e+00 -1.52652e+00  9.98379e-01
21Feb12_165154|   8.51997e-01 -9.42775e-01 -1.16577e-01  3.64988e-01 -1.27419e+00]
21Feb12_165154| [ 1.67425e+00 -1.27190e-01  2.44775e+00  1.44302e+00 -4.43112e-01
21Feb12_165154|  -4.07317e-02  1.33875e-01  4.92876e-01  1.36327e+00  3.41424e-01
21Feb12_165154|   1.70937e+00 -2.26414e+00  5.48087e-01 -2.49869e-01 -1.95666e+00]
21Feb12_165154| [-7.77069e-01  1.76839e+00 -5.99460e-01 -2.13769e+00  1.38006e+00
21Feb12_165154|   1.30623e+00 -1.06865e+00 -1.16462e+00  8.02528e-01 -3.99780e-01
21Feb12_165154|   8.20611e-01 -1.64613e-01  3.17174e-01  1.50755e+00  1.82851e-01]
21Feb12_165154| [-1.02989e+00 -1.07499e+00 -1.93091e+00  4.66271e-01 -8.74190e-01
21Feb12_165154|  -1.32185e+00 -9.08286e-01 -8.46363e-01  2.03651e-01 -2.52017e-01
21Feb12_165154|   1.15748e+00 -3.29038e-01 -5.53034e-01  6.31862e-01 -9.38469e-02]
21Feb12_165154| [-1.07650e+00  2.26383e-01  1.43406e-01 -1.04859e+00 -1.13255e+00
21Feb12_165154|   5.32942e-01 -2.81361e-01  1.06039e+00 -4.84886e-01  1.81779e+00
21Feb12_165154|   4.45898e-01  1.15599e-01  2.22637e+00 -1.10477e+00 -7.41273e-01]
21Feb12_165154| [ 5.36190e-01  1.36053e+00  1.86442e-01  1.76821e-01  1.73842e+00
21Feb12_165154|   1.33653e-01 -2.69435e-01  1.42842e+00 -6.67924e-01  8.34192e-01
21Feb12_165154|  -4.93949e-01  2.55190e-01  8.44813e-02  1.07023e+00  3.32795e-01]
21Feb12_165154| [-7.77858e-01  6.91255e-01 -2.00094e-01 -3.47804e-02  1.25963e+00
21Feb12_165154|   2.88406e-01  1.11181e-02 -1.72072e-01  1.74171e-01  1.07767e+00
21Feb12_165154|  -7.57539e-01 -1.51881e+00  1.13432e+00 -8.19687e-01  2.51036e-01]
21Feb12_165154| [ 1.17877e+00  8.51361e-01  5.34249e-01 -3.85201e-01  1.62741e+00
21Feb12_165154|   7.14108e-01 -2.49586e-01 -1.51061e+00 -5.78471e-01 -1.53573e+00
21Feb12_165154|  -6.82580e-01 -1.03046e+00  2.14369e+00 -2.12686e+00  2.93875e-01]
21Feb12_165154| [-5.46699e-01 -1.24367e-01  1.50400e+00  5.24570e-01  1.32199e-01
21Feb12_165154|  -1.11873e+00 -1.21781e-01  1.60716e+00  7.94494e-01  4.12000e-02
21Feb12_165154|  -1.45629e-01 -1.67069e+00  1.55359e+00  1.27490e+00  3.78250e-01]
21Feb12_165154| [-1.65770e+00  7.63010e-01 -1.07032e-01 -1.29077e+00 -2.72523e-01
21Feb12_165154|   8.86152e-01  2.03137e-02  1.07244e+00 -2.07611e+00  1.79718e-01
21Feb12_165154|   1.81554e-01 -6.15758e-01 -9.51774e-01  1.02939e+00  8.17973e-01]
21Feb12_165154| [ 9.21545e-01 -8.71244e-02 -1.53454e+00 -1.66686e+00  9.25583e-02
21Feb12_165154|   5.45788e-01  9.00588e-01  5.39148e-01  1.73423e+00  5.95858e-01
21Feb12_165154|   7.60598e-01  7.10163e-01 -1.92447e-01 -2.18648e-01 -1.06613e-01]
21Feb12_165154| [-1.27156e+00  1.50471e-01 -1.51367e+00  2.43159e-01  1.45374e+00
21Feb12_165154|   1.39069e-01  1.63857e+00  7.76127e-01  1.22775e-01 -9.15383e-01
21Feb12_165154|  -7.88206e-01 -1.88443e-01  5.88849e-01 -1.15889e+00  1.57532e+00]
21Feb12_165154| [-7.87307e-01  7.90368e-01 -8.23463e-01 -7.31497e-01 -1.23567e+00
21Feb12_165154|   4.22757e-01  3.63316e-02  6.01964e-01  1.96999e+00 -1.17414e+00
21Feb12_165154|   3.97797e-01 -1.08808e+00 -5.94358e-01 -2.83672e-01  8.50566e-01]
21Feb12_165154| [ 5.30769e-01 -1.84801e+00 -5.66134e-01  6.76585e-02  1.10136e-01
21Feb12_165154|   4.92367e-01 -4.90997e-01  6.06677e-01  2.28381e+00 -4.07746e-02
21Feb12_165154|   1.15850e+00 -5.98080e-01 -7.01578e-01  1.01957e+00  2.49859e-01]
21Feb12_165154| [-8.63352e-01  1.10102e+00 -1.35284e+00  7.44546e-01  1.23832e+00
21Feb12_165154|  -5.46095e-01 -7.14545e-01  6.39714e-01 -1.05446e-01 -8.88602e-01
21Feb12_165154|   9.93232e-01  1.94862e+00 -4.16105e-01  1.03489e-01  1.11977e+00]
21Feb12_165154| [ 1.19516e+00 -1.76346e-01  1.04128e-01  1.20697e+00 -9.23981e-01
21Feb12_165154|  -1.33787e+00 -2.81645e-01  4.54001e-01  1.13838e-01  7.67530e-01
21Feb12_165154|  -1.19224e+00 -1.30105e-01 -1.91934e-01  4.19944e-01  1.69825e-01]
21Feb12_165154| [ 7.65088e-01 -1.94246e+00 -7.11338e-01  4.53958e-01  1.94201e+00
21Feb12_165154|   1.31030e+00 -2.96434e-02 -1.76407e+00  5.53828e-01  6.85560e-01
21Feb12_165154|   7.66333e-01  3.82096e-02 -8.16458e-01 -6.24116e-02  2.64193e-01]
21Feb12_165154| [ 3.18200e-01  2.29948e+00  1.64715e+00  1.62897e+00 -7.51376e-02
21Feb12_165154|  -1.28841e+00 -6.20669e-01 -1.11166e-01  8.60402e-01 -1.33019e+00
21Feb12_165154|  -5.96012e-01  1.43903e+00  4.95090e-01 -5.77593e-01  1.44906e+00]
21Feb12_165154| [ 4.11040e-01  7.04946e-01 -5.20407e-01  1.19926e-01 -2.14187e-01
21Feb12_165154|   2.61836e-01 -2.06690e-01 -5.23044e-01 -2.21768e+00 -1.84159e+00
21Feb12_165154|   1.07890e-01 -1.21571e+00  1.41906e-02 -1.18878e+00 -1.10586e+00]
21Feb12_165154| [ 7.47110e-04 -2.19367e-01  1.24132e+00  2.42981e-01  1.64975e+00
21Feb12_165154|  -7.56681e-01  2.05047e+00  1.41699e+00  2.11413e-01  2.05856e-01
21Feb12_165154|  -1.19536e+00 -1.17721e+00 -5.74572e-02 -9.88771e-01 -5.21745e-02]
21Feb12_165154| [ 8.41039e-01 -7.80210e-01  1.63153e-01  9.11562e-01  1.96584e+00
21Feb12_165154|   1.78291e+00  1.27725e-01  9.24125e-01  8.89095e-01  8.02583e-01
21Feb12_165154|  -1.84072e-01 -1.83956e+00 -1.02407e+00  6.97260e-01  2.04119e+00]
21Feb12_165154| [ 1.02325e+00 -1.14512e+00  1.53735e+00 -1.20875e+00  2.40349e-01
21Feb12_165154|   3.65149e-01 -8.45853e-01 -9.53877e-01  1.08881e+00  1.31369e+00
21Feb12_165154|  -8.73629e-01  3.54768e-01 -1.44120e+00  3.00774e+00  5.37138e-01]
21Feb12_165154| [ 1.21153e+00  1.33780e+00  2.37346e-01  1.10192e+00 -7.71109e-01
21Feb12_165154|  -1.67297e+00 -9.85041e-01 -9.67469e-02  1.35584e-01  1.43828e+00
21Feb12_165154|  -5.37772e-01  6.81867e-01  8.99423e-02 -3.00140e-01  7.40803e-01]
21Feb12_165154| [-1.53912e-01 -1.45545e+00 -8.51719e-01 -3.24207e-01 -1.85297e+00
21Feb12_165154|  -1.37632e+00  2.56265e+00 -1.51591e+00 -7.70917e-01  1.60742e+00
21Feb12_165154|   8.19418e-01  1.51279e+00 -7.75504e-01 -4.56317e-01  7.93313e-01]
21Feb12_165154| [ 1.79234e+00  5.37534e-01 -1.64985e-01  1.12594e+00  4.19165e-01
21Feb12_165154|   1.00815e+00 -1.24029e+00  8.99015e-02  5.04534e-01  1.04688e+00
21Feb12_165154|  -1.85983e+00 -6.28367e-01  1.44747e+00 -7.70927e-01 -6.80962e-02]
21Feb12_165154| [-6.11685e-01  5.81244e-01 -2.00813e+00  4.40980e-01  1.17081e+00
21Feb12_165154|   4.53617e-02 -1.02732e-01 -5.30344e-01 -2.30272e-01 -2.75712e-01
21Feb12_165154|  -1.35628e+00  6.77073e-01  1.18206e+00 -9.68516e-01  8.88227e-01]
21Feb12_165154| [ 3.39330e-01  1.85906e-01  3.17199e+00 -1.14941e+00  8.41043e-01
21Feb12_165154|   1.43171e+00  2.91815e-01  9.90040e-01  2.43151e-01 -4.20123e-01
21Feb12_165154|  -7.71009e-01  8.26689e-01 -2.38729e-01  2.25124e-01  4.71938e-02]
21Feb12_165154| [-1.24769e+00 -1.74352e-01  1.33159e+00  6.31103e-01  1.39801e-01
21Feb12_165154|  -1.97232e-01  1.00881e+00 -1.05164e+00 -1.26316e-01 -6.77330e-01
21Feb12_165154|   6.93223e-01  3.09964e-01  4.46448e-01  3.28001e-01 -7.51083e-01]
21Feb12_165154| [-7.55157e-01 -1.20070e+00  1.18128e+00  2.31557e-01 -5.77142e-01
21Feb12_165154|   8.50621e-01 -6.80691e-01  1.14562e+00  6.53826e-01 -1.28380e+00
21Feb12_165154|   4.15503e-02  9.67591e-01 -3.56690e+00 -2.80446e-01 -2.39691e-01]
21Feb12_165154| [ 1.43065e+00  4.89999e-01  7.08940e-01  9.80815e-01 -5.25905e-01
21Feb12_165154|   8.92854e-01 -1.47577e+00 -9.27641e-02 -3.34619e-01 -1.41270e+00
21Feb12_165154|  -1.10591e+00  1.59163e+00  2.61333e-01 -1.48185e+00 -2.14182e+00]
21Feb12_165154| [ 8.38600e-01 -8.88508e-01 -4.12187e-01 -1.04812e-01  3.26908e-01
21Feb12_165154|  -9.83693e-01  1.67864e+00  7.72612e-01  1.95026e+00  9.57917e-01
21Feb12_165154|  -1.48928e+00 -1.99797e-01 -3.05136e-01 -1.14633e-01 -1.04672e+00]]
21Feb12_165154|-- Bias --
21Feb12_165154|[ 0.73695 -0.51772  1.29843 -0.86449  0.54318  0.17660 -0.21569  0.35471
21Feb12_165154| -0.23531 -0.15791  1.04286  0.77391 -0.11794  1.01790  0.50375]
21Feb12_165154|Layer 1:
21Feb12_165154|-- Config --
21Feb12_165154|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 15], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_165154|-- Weights --
21Feb12_165154|[[ 0.70443 -1.08724]
21Feb12_165154| [-0.44561 -1.05050]
21Feb12_165154| [ 0.25488  0.31427]
21Feb12_165154| [-1.40193  0.84859]
21Feb12_165154| [ 0.27127 -0.15942]
21Feb12_165154| [-0.18528 -0.14003]
21Feb12_165154| [ 1.68717  0.30442]
21Feb12_165154| [-0.01440  0.47743]
21Feb12_165154| [ 0.46612  0.57491]
21Feb12_165154| [-1.91613 -0.31596]
21Feb12_165154| [ 1.38318 -0.97860]
21Feb12_165154| [-0.49568  0.13334]
21Feb12_165154| [ 0.67487 -1.08400]
21Feb12_165154| [ 1.22898  1.13422]
21Feb12_165154| [ 0.14442 -0.69100]]
21Feb12_165154|-- Bias --
21Feb12_165154|[ 1.12271 -0.02168]
21Feb12_165154|Predicting the validation and test data with the Best final individual.
21Feb12_165201| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_165201|-----------  ------------------  --------------------  ----------
21Feb12_165201|Validation         42.17                  15            0.00258
21Feb12_165201|   Test            36.58                  15            0.00000
21Feb12_165201|-------------------- Test #14 --------------------
21Feb12_165201|Best final individual weights
21Feb12_165201|Individual:
21Feb12_165201|-- Constant hidden layers --
21Feb12_165201|False
21Feb12_165201|Layer 0:
21Feb12_165201|-- Config --
21Feb12_165201|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 15, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_165201|-- Weights --
21Feb12_165201|[[ 5.09617e-01  8.20902e-01 -3.02367e-01 -9.64837e-01 -4.33824e-01
21Feb12_165201|  -2.42034e-01 -5.04343e-01  1.31689e+00  9.21850e-01  5.13818e-01
21Feb12_165201|  -3.49854e-01  2.15852e-01 -1.04928e+00  7.68905e-01 -1.88324e+00]
21Feb12_165201| [-7.50915e-01 -2.52628e+00  3.69383e-01  1.39331e-01 -4.71230e-01
21Feb12_165201|   2.50267e+00 -2.55477e-01 -5.15419e-01 -2.31831e-01 -1.16548e+00
21Feb12_165201|  -8.22133e-01  4.82232e-01 -1.26500e+00  7.69663e-01  1.16647e+00]
21Feb12_165201| [ 4.01389e-03  9.01850e-01 -4.38696e-01 -7.91041e-01 -3.45664e-01
21Feb12_165201|  -1.66871e+00  1.65396e+00  7.90223e-01  5.51123e-01  1.67606e-01
21Feb12_165201|   2.12442e-01  1.14271e+00  6.42674e-01  2.00899e-01 -2.05944e-01]
21Feb12_165201| [ 1.80619e-01 -2.50060e-01 -1.12859e+00  1.83522e+00  1.81374e+00
21Feb12_165201|  -1.42416e+00  5.22823e-01 -7.02013e-01  1.84516e+00  1.90809e+00
21Feb12_165201|   1.37151e+00  4.03871e-02  4.29238e-01 -2.37117e-01 -1.00132e+00]
21Feb12_165201| [ 4.39871e-01  3.98574e-01 -3.75109e-01 -8.64825e-01  4.06425e-01
21Feb12_165201|   5.56500e-01  1.44148e+00 -5.22177e-01 -7.21740e-01  3.07682e-01
21Feb12_165201|  -9.52454e-01  8.44086e-01  1.09295e+00 -3.90444e-01  1.33545e+00]
21Feb12_165201| [-1.42180e+00  3.85641e-01 -8.43471e-02  1.81738e-02 -1.14521e+00
21Feb12_165201|  -8.06111e-01 -8.15090e-01  7.76165e-02  1.02784e+00  1.02123e-01
21Feb12_165201|   7.08213e-01  9.96943e-01 -7.79890e-01  1.66778e+00 -6.05761e-01]
21Feb12_165201| [-2.52774e-01 -9.61820e-01  3.02997e+00 -4.75355e-02  9.27908e-01
21Feb12_165201|   6.12327e-01 -4.65796e-01  8.85447e-01 -9.19731e-02  5.35502e-02
21Feb12_165201|  -5.61515e-01  1.22163e+00 -6.55581e-02 -4.23284e-01  6.78889e-01]
21Feb12_165201| [-4.07954e-01  7.89564e-01 -1.02275e+00 -1.42852e-01 -1.21182e-01
21Feb12_165201|   2.60288e+00  1.31219e+00 -1.05105e+00 -7.28076e-01  7.37981e-01
21Feb12_165201|   1.07877e+00  4.12772e-01  3.20972e-01 -1.42903e+00  5.49771e-01]
21Feb12_165201| [-1.06598e+00  4.11763e-01 -5.98736e-01 -1.02922e+00  1.44690e+00
21Feb12_165201|   1.61847e+00  7.86271e-01 -1.04439e+00 -1.22083e+00 -5.20594e-01
21Feb12_165201|   1.50709e+00 -2.76750e-01 -9.31489e-01  1.18032e+00 -1.34476e+00]
21Feb12_165201| [-9.84737e-01 -5.97909e-01 -5.05735e-01  1.21453e+00  2.04300e+00
21Feb12_165201|  -1.80226e+00  2.27960e-01  2.48235e-01 -9.14083e-01 -8.19925e-01
21Feb12_165201|   8.79325e-03  1.89321e+00 -2.33314e+00  3.64489e-01 -8.65853e-01]
21Feb12_165201| [-5.52147e-01 -1.09026e+00 -6.31263e-01 -9.85456e-02 -1.26793e+00
21Feb12_165201|   6.92239e-01  4.07591e-03  8.28704e-02 -4.61769e-01  1.47380e+00
21Feb12_165201|  -8.25050e-01  1.85307e+00 -7.02559e-01  4.42800e-01 -5.09351e-01]
21Feb12_165201| [-1.22241e+00 -2.82164e+00 -3.49419e-01  2.35780e-01 -3.06882e-01
21Feb12_165201|   4.97633e-01 -8.59745e-01  1.41005e+00  4.44223e-01  4.80295e-01
21Feb12_165201|   5.28514e-01 -8.52095e-01  7.93638e-01 -1.18061e+00  3.77575e-01]
21Feb12_165201| [ 1.83848e+00  1.86747e+00 -6.09064e-01 -1.29117e-01  8.20239e-01
21Feb12_165201|  -8.41223e-01 -4.91994e-01 -4.35134e-02 -3.10526e-01  8.12742e-01
21Feb12_165201|  -2.48499e+00  6.10492e-01  2.59825e-01  1.10740e+00  2.25110e-01]
21Feb12_165201| [-9.61110e-02  1.17814e+00  1.12148e-01 -3.49813e-01  2.43858e+00
21Feb12_165201|  -1.38613e+00 -3.82927e-01  1.52932e+00  8.48623e-01 -1.99483e+00
21Feb12_165201|  -2.12240e+00  1.06312e+00 -3.90781e-02  1.49640e+00  1.12926e+00]
21Feb12_165201| [-4.30616e-01  2.39031e-01 -7.23476e-01  1.25568e+00 -2.14845e-01
21Feb12_165201|  -5.53173e-01 -2.65699e+00  2.69230e-02 -1.00392e+00  1.32765e-01
21Feb12_165201|  -5.64005e-01  1.22524e+00  1.24383e+00 -1.09592e+00 -1.41796e+00]
21Feb12_165201| [-2.39791e-01  1.53064e+00  3.01720e-01  2.78106e-01 -1.84792e-01
21Feb12_165201|   1.56208e+00  9.94463e-01 -1.63904e+00  6.63295e-01 -1.85188e+00
21Feb12_165201|  -7.33287e-01 -1.62705e-01 -9.61094e-01  4.14256e-01 -1.81088e+00]
21Feb12_165201| [ 2.83794e-01  7.82624e-01  8.22930e-01  1.38834e+00  1.35777e+00
21Feb12_165201|   1.13137e+00 -4.51094e-01 -9.14736e-02 -4.29153e-01 -1.32003e-01
21Feb12_165201|  -1.06833e+00 -3.60741e-02 -1.72337e+00 -9.36812e-02 -1.50919e-01]
21Feb12_165201| [ 4.60832e-01 -6.41447e-01  7.19778e-01  1.43690e+00 -5.39012e-01
21Feb12_165201|   2.73839e+00  4.18203e-02  1.12728e+00 -1.96359e+00  5.08015e-01
21Feb12_165201|  -3.94637e-02  1.21425e+00  7.81562e-01  1.21240e+00  8.71932e-02]
21Feb12_165201| [ 7.21067e-01 -4.05470e-01  4.30706e-01 -1.12406e+00 -1.66416e-01
21Feb12_165201|  -1.74613e-01 -2.82475e+00  7.83187e-01 -1.70599e+00 -4.53800e-01
21Feb12_165201|   7.68700e-02  1.38626e+00  4.71260e-01 -1.20854e-01 -3.85957e-01]
21Feb12_165201| [-1.45393e+00 -4.35386e-01  7.35002e-01 -1.05813e+00 -6.41567e-01
21Feb12_165201|  -1.23953e+00 -1.11174e+00 -4.33161e-01  1.71285e+00 -1.69152e+00
21Feb12_165201|  -3.94477e-01 -9.64481e-01  2.12241e-01 -4.51296e-01  6.12573e-01]
21Feb12_165201| [ 1.91178e+00 -7.20020e-01 -1.43347e+00  6.16597e-01 -1.40631e-01
21Feb12_165201|   9.60419e-01 -2.94601e-01 -3.70235e-01  1.68500e-03 -7.06077e-02
21Feb12_165201|  -2.63686e+00 -7.93469e-01  3.46275e-01  2.04211e+00  9.19580e-01]
21Feb12_165201| [ 2.28690e-01 -1.52406e-01 -4.49362e-01 -7.32180e-01  7.99781e-01
21Feb12_165201|   4.88373e-01 -9.34696e-01 -5.02242e-01  9.68074e-01 -3.07760e-01
21Feb12_165201|  -3.49720e-01 -2.00695e+00 -4.45838e-01  2.62312e-01  3.38818e-01]
21Feb12_165201| [-1.98557e-01  8.34883e-01 -1.61905e-01  1.28379e+00  1.04073e+00
21Feb12_165201|   1.45833e+00  4.77341e-01  9.87420e-01 -3.08856e-01 -1.55031e+00
21Feb12_165201|   1.38023e+00 -4.42201e-01  1.78369e+00  8.01018e-01  1.52483e+00]
21Feb12_165201| [ 1.12967e+00 -8.45423e-01  1.52345e+00  1.08801e+00 -4.32434e-01
21Feb12_165201|  -3.16741e-01 -7.17985e-02  1.09877e+00 -7.90690e-01  1.36084e+00
21Feb12_165201|  -5.66120e-01 -1.70432e+00 -2.12910e+00 -2.41374e-01  1.33636e+00]
21Feb12_165201| [-4.08205e-01 -8.03871e-01  9.13990e-01  5.00916e-01 -1.81059e-01
21Feb12_165201|   2.42621e-01 -9.57869e-01  6.74094e-01  6.52179e-01  2.77279e-01
21Feb12_165201|  -3.91051e-01 -9.05321e-02  6.86316e-01 -3.54594e-01  5.83144e-01]
21Feb12_165201| [-3.98308e-01 -4.48018e-03  1.11987e+00  1.50374e+00 -9.18129e-01
21Feb12_165201|  -1.81690e+00 -1.38223e+00 -2.74481e-01 -8.24843e-01 -7.05820e-01
21Feb12_165201|   1.50584e+00 -4.21386e-01  4.00084e-01 -7.61841e-02 -7.41767e-01]
21Feb12_165201| [ 5.51762e-01 -1.04904e+00  5.21335e-01  2.14684e-01 -8.21795e-02
21Feb12_165201|   3.68556e-01  1.01222e+00 -1.30634e+00 -1.52652e+00  9.98379e-01
21Feb12_165201|   8.51997e-01 -9.42775e-01 -1.16577e-01  3.64988e-01 -1.27419e+00]
21Feb12_165201| [ 1.67425e+00 -1.27190e-01  2.44775e+00  1.44302e+00 -4.43112e-01
21Feb12_165201|  -4.07317e-02  1.33875e-01  4.92876e-01  1.36327e+00  3.41424e-01
21Feb12_165201|   1.70937e+00 -2.26414e+00  5.48087e-01 -2.49869e-01 -1.95666e+00]
21Feb12_165201| [-7.77069e-01  1.76839e+00 -5.99460e-01 -2.13769e+00  1.38006e+00
21Feb12_165201|   1.30623e+00 -1.06865e+00 -1.16462e+00  8.02528e-01 -3.99780e-01
21Feb12_165201|   8.20611e-01 -1.64613e-01  3.17174e-01  1.50755e+00  1.82851e-01]
21Feb12_165201| [-1.02989e+00 -1.07499e+00 -1.93091e+00  4.66271e-01 -8.74190e-01
21Feb12_165201|  -1.32185e+00 -9.08286e-01 -8.46363e-01  2.03651e-01 -2.52017e-01
21Feb12_165201|   1.15748e+00 -3.29038e-01 -5.53034e-01  6.31862e-01 -9.38469e-02]
21Feb12_165201| [-1.07650e+00  2.26383e-01  1.43406e-01 -1.04859e+00 -1.13255e+00
21Feb12_165201|   5.32942e-01 -2.81361e-01  1.06039e+00 -4.84886e-01  1.81779e+00
21Feb12_165201|   4.45898e-01  1.15599e-01  2.22637e+00 -1.10477e+00 -7.41273e-01]
21Feb12_165201| [ 5.36190e-01  1.36053e+00  1.86442e-01  1.76821e-01  1.73842e+00
21Feb12_165201|   1.33653e-01 -2.69435e-01  1.42842e+00 -6.67924e-01  8.34192e-01
21Feb12_165201|  -4.93949e-01  2.55190e-01  8.44813e-02  1.07023e+00  3.32795e-01]
21Feb12_165201| [-7.77858e-01  6.91255e-01 -2.00094e-01 -3.47804e-02  1.25963e+00
21Feb12_165201|   2.88406e-01  1.11181e-02 -1.72072e-01  1.74171e-01  1.07767e+00
21Feb12_165201|  -7.57539e-01 -1.51881e+00  1.13432e+00 -8.19687e-01  2.51036e-01]
21Feb12_165201| [ 1.17877e+00  8.51361e-01  5.34249e-01 -3.85201e-01  1.62741e+00
21Feb12_165201|   7.14108e-01 -2.49586e-01 -1.51061e+00 -5.78471e-01 -1.53573e+00
21Feb12_165201|  -6.82580e-01 -1.03046e+00  2.14369e+00 -2.12686e+00  2.93875e-01]
21Feb12_165201| [-5.46699e-01 -1.24367e-01  1.50400e+00  5.24570e-01  1.32199e-01
21Feb12_165201|  -1.11873e+00 -1.21781e-01  1.60716e+00  7.94494e-01  4.12000e-02
21Feb12_165201|  -1.45629e-01 -1.67069e+00  1.55359e+00  1.27490e+00  3.78250e-01]
21Feb12_165201| [-1.65770e+00  7.63010e-01 -1.07032e-01 -1.29077e+00 -2.72523e-01
21Feb12_165201|   8.86152e-01  2.03137e-02  1.07244e+00 -2.07611e+00  1.79718e-01
21Feb12_165201|   1.81554e-01 -6.15758e-01 -9.51774e-01  1.02939e+00  8.17973e-01]
21Feb12_165201| [ 9.21545e-01 -8.71244e-02 -1.53454e+00 -1.66686e+00  9.25583e-02
21Feb12_165201|   5.45788e-01  9.00588e-01  5.39148e-01  1.73423e+00  5.95858e-01
21Feb12_165201|   7.60598e-01  7.10163e-01 -1.92447e-01 -2.18648e-01 -1.06613e-01]
21Feb12_165201| [-1.27156e+00  1.50471e-01 -1.51367e+00  2.43159e-01  1.45374e+00
21Feb12_165201|   1.39069e-01  1.63857e+00  7.76127e-01  1.22775e-01 -9.15383e-01
21Feb12_165201|  -7.88206e-01 -1.88443e-01  5.88849e-01 -1.15889e+00  1.57532e+00]
21Feb12_165201| [-7.87307e-01  7.90368e-01 -8.23463e-01 -7.31497e-01 -1.23567e+00
21Feb12_165201|   4.22757e-01  3.63316e-02  6.01964e-01  1.96999e+00 -1.17414e+00
21Feb12_165201|   3.97797e-01 -1.08808e+00 -5.94358e-01 -2.83672e-01  8.50566e-01]
21Feb12_165201| [ 5.30769e-01 -1.84801e+00 -5.66134e-01  6.76585e-02  1.10136e-01
21Feb12_165201|   4.92367e-01 -4.90997e-01  6.06677e-01  2.28381e+00 -4.07746e-02
21Feb12_165201|   1.15850e+00 -5.98080e-01 -7.01578e-01  1.01957e+00  2.49859e-01]
21Feb12_165201| [-8.63352e-01  1.10102e+00 -1.35284e+00  7.44546e-01  1.23832e+00
21Feb12_165201|  -5.46095e-01 -7.14545e-01  6.39714e-01 -1.05446e-01 -8.88602e-01
21Feb12_165201|   9.93232e-01  1.94862e+00 -4.16105e-01  1.03489e-01  1.11977e+00]
21Feb12_165201| [ 1.19516e+00 -1.76346e-01  1.04128e-01  1.20697e+00 -9.23981e-01
21Feb12_165201|  -1.33787e+00 -2.81645e-01  4.54001e-01  1.13838e-01  7.67530e-01
21Feb12_165201|  -1.19224e+00 -1.30105e-01 -1.91934e-01  4.19944e-01  1.69825e-01]
21Feb12_165201| [ 7.65088e-01 -1.94246e+00 -7.11338e-01  4.53958e-01  1.94201e+00
21Feb12_165201|   1.31030e+00 -2.96434e-02 -1.76407e+00  5.53828e-01  6.85560e-01
21Feb12_165201|   7.66333e-01  3.82096e-02 -8.16458e-01 -6.24116e-02  2.64193e-01]
21Feb12_165201| [ 3.18200e-01  2.29948e+00  1.64715e+00  1.62897e+00 -7.51376e-02
21Feb12_165201|  -1.28841e+00 -6.20669e-01 -1.11166e-01  8.60402e-01 -1.33019e+00
21Feb12_165201|  -5.96012e-01  1.43903e+00  4.95090e-01 -5.77593e-01  1.44906e+00]
21Feb12_165201| [ 4.11040e-01  7.04946e-01 -5.20407e-01  1.19926e-01 -2.14187e-01
21Feb12_165201|   2.61836e-01 -2.06690e-01 -5.23044e-01 -2.21768e+00 -1.84159e+00
21Feb12_165201|   1.07890e-01 -1.21571e+00  1.41906e-02 -1.18878e+00 -1.10586e+00]
21Feb12_165201| [ 7.47110e-04 -2.19367e-01  1.24132e+00  2.42981e-01  1.64975e+00
21Feb12_165201|  -7.56681e-01  2.05047e+00  1.41699e+00  2.11413e-01  2.05856e-01
21Feb12_165201|  -1.19536e+00 -1.17721e+00 -5.74572e-02 -9.88771e-01 -5.21745e-02]
21Feb12_165201| [ 8.41039e-01 -7.80210e-01  1.63153e-01  9.11562e-01  1.96584e+00
21Feb12_165201|   1.78291e+00  1.27725e-01  9.24125e-01  8.89095e-01  8.02583e-01
21Feb12_165201|  -1.84072e-01 -1.83956e+00 -1.02407e+00  6.97260e-01  2.04119e+00]
21Feb12_165201| [ 1.02325e+00 -1.14512e+00  1.53735e+00 -1.20875e+00  2.40349e-01
21Feb12_165201|   3.65149e-01 -8.45853e-01 -9.53877e-01  1.08881e+00  1.31369e+00
21Feb12_165201|  -8.73629e-01  3.54768e-01 -1.44120e+00  3.00774e+00  5.37138e-01]
21Feb12_165201| [ 1.21153e+00  1.33780e+00  2.37346e-01  1.10192e+00 -7.71109e-01
21Feb12_165201|  -1.67297e+00 -9.85041e-01 -9.67469e-02  1.35584e-01  1.43828e+00
21Feb12_165201|  -5.37772e-01  6.81867e-01  8.99423e-02 -3.00140e-01  7.40803e-01]
21Feb12_165201| [-1.53912e-01 -1.45545e+00 -8.51719e-01 -3.24207e-01 -1.85297e+00
21Feb12_165201|  -1.37632e+00  2.56265e+00 -1.51591e+00 -7.70917e-01  1.60742e+00
21Feb12_165201|   8.19418e-01  1.51279e+00 -7.75504e-01 -4.56317e-01  7.93313e-01]
21Feb12_165201| [ 1.79234e+00  5.37534e-01 -1.64985e-01  1.12594e+00  4.19165e-01
21Feb12_165201|   1.00815e+00 -1.24029e+00  8.99015e-02  5.04534e-01  1.04688e+00
21Feb12_165201|  -1.85983e+00 -6.28367e-01  1.44747e+00 -7.70927e-01 -6.80962e-02]
21Feb12_165201| [-6.11685e-01  5.81244e-01 -2.00813e+00  4.40980e-01  1.17081e+00
21Feb12_165201|   4.53617e-02 -1.02732e-01 -5.30344e-01 -2.30272e-01 -2.75712e-01
21Feb12_165201|  -1.35628e+00  6.77073e-01  1.18206e+00 -9.68516e-01  8.88227e-01]
21Feb12_165201| [ 3.39330e-01  1.85906e-01  3.17199e+00 -1.14941e+00  8.41043e-01
21Feb12_165201|   1.43171e+00  2.91815e-01  9.90040e-01  2.43151e-01 -4.20123e-01
21Feb12_165201|  -7.71009e-01  8.26689e-01 -2.38729e-01  2.25124e-01  4.71938e-02]
21Feb12_165201| [-1.24769e+00 -1.74352e-01  1.33159e+00  6.31103e-01  1.39801e-01
21Feb12_165201|  -1.97232e-01  1.00881e+00 -1.05164e+00 -1.26316e-01 -6.77330e-01
21Feb12_165201|   6.93223e-01  3.09964e-01  4.46448e-01  3.28001e-01 -7.51083e-01]
21Feb12_165201| [-7.55157e-01 -1.20070e+00  1.18128e+00  2.31557e-01 -5.77142e-01
21Feb12_165201|   8.50621e-01 -6.80691e-01  1.14562e+00  6.53826e-01 -1.28380e+00
21Feb12_165201|   4.15503e-02  9.67591e-01 -3.56690e+00 -2.80446e-01 -2.39691e-01]
21Feb12_165201| [ 1.43065e+00  4.89999e-01  7.08940e-01  9.80815e-01 -5.25905e-01
21Feb12_165201|   8.92854e-01 -1.47577e+00 -9.27641e-02 -3.34619e-01 -1.41270e+00
21Feb12_165201|  -1.10591e+00  1.59163e+00  2.61333e-01 -1.48185e+00 -2.14182e+00]
21Feb12_165201| [ 8.38600e-01 -8.88508e-01 -4.12187e-01 -1.04812e-01  3.26908e-01
21Feb12_165201|  -9.83693e-01  1.67864e+00  7.72612e-01  1.95026e+00  9.57917e-01
21Feb12_165201|  -1.48928e+00 -1.99797e-01 -3.05136e-01 -1.14633e-01 -1.04672e+00]]
21Feb12_165201|-- Bias --
21Feb12_165201|[ 0.73695 -0.51772  1.29843 -0.86449  0.54318  0.17660 -0.21569  0.35471
21Feb12_165201| -0.23531 -0.15791  1.04286  0.77391 -0.11794  1.01790  0.50375]
21Feb12_165201|Layer 1:
21Feb12_165201|-- Config --
21Feb12_165201|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 15], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_165201|-- Weights --
21Feb12_165201|[[ 0.70443 -1.08724]
21Feb12_165201| [-0.44561 -1.05050]
21Feb12_165201| [ 0.25488  0.31427]
21Feb12_165201| [-1.40193  0.84859]
21Feb12_165201| [ 0.27127 -0.15942]
21Feb12_165201| [-0.18528 -0.14003]
21Feb12_165201| [ 1.68717  0.30442]
21Feb12_165201| [-0.01440  0.47743]
21Feb12_165201| [ 0.46612  0.57491]
21Feb12_165201| [-1.91613 -0.31596]
21Feb12_165201| [ 1.38318 -0.97860]
21Feb12_165201| [-0.49568  0.13334]
21Feb12_165201| [ 0.67487 -1.08400]
21Feb12_165201| [ 1.22898  1.13422]
21Feb12_165201| [ 0.14442 -0.69100]]
21Feb12_165201|-- Bias --
21Feb12_165201|[ 1.12271 -0.02168]
21Feb12_165201|Predicting the validation and test data with the Best final individual.
21Feb12_165208| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_165208|-----------  ------------------  --------------------  ----------
21Feb12_165208|Validation         42.00                  15            0.00259
21Feb12_165208|   Test            36.49                  15            0.00000
2021-02-12 16:52:09.303586: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
21Feb12_165210|Data summary: Train
21Feb12_165210|data.shape = (2300, 57)
21Feb12_165210|labels.shape = (2300,)
21Feb12_165210|Class distribution:
21Feb12_165210|	0 - 1389 (0.60)
21Feb12_165210|	1 - 911 (0.40)
21Feb12_165210|Data summary: Validation
21Feb12_165210|data.shape = (1150, 57)
21Feb12_165210|labels.shape = (1150,)
21Feb12_165210|Class distribution:
21Feb12_165210|	0 - 667 (0.58)
21Feb12_165210|	1 - 483 (0.42)
21Feb12_165210|Data summary: Test
21Feb12_165210|data.shape = (1151, 57)
21Feb12_165210|labels.shape = (1151,)
21Feb12_165210|Class distribution:
21Feb12_165210|	0 - 732 (0.64)
21Feb12_165210|	1 - 419 (0.36)
21Feb12_165210|Selected configuration values
21Feb12_165210|-- Dataset name: spambase2
21Feb12_165210|-- Initial population size: 64
21Feb12_165210|-- Maximun number of generations: 32
21Feb12_165210|-- Neurons per hidden layer range: (2, 20)
21Feb12_165210|-- Hidden layers number range: (1, 3)
21Feb12_165210|-- Crossover probability: 0.5
21Feb12_165210|-- Bias gene mutation probability: 0.2
21Feb12_165210|-- Weights gene mutation probability: 0.75
21Feb12_165210|-- Neuron mutation probability: 0.3
21Feb12_165210|-- Layer mutation probability: 0.3
21Feb12_165210|-- Constant hidden layers: False
21Feb12_165210|-- Seed: 31415
21Feb12_165210|Entering GA
21Feb12_165210|Start the algorithm
2021-02-12 16:52:10.166364: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-12 16:52:10.166914: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-02-12 16:52:10.170874: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-12 16:52:10.171195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.71GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s
2021-02-12 16:52:10.171209: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-02-12 16:52:10.172681: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-02-12 16:52:10.172714: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-02-12 16:52:10.173219: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-02-12 16:52:10.173348: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-02-12 16:52:10.173419: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-12 16:52:10.173829: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-02-12 16:52:10.173871: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-12 16:52:10.173877: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-02-12 16:52:10.174066: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-02-12 16:52:10.174934: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-12 16:52:10.174953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-12 16:52:10.174965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      
2021-02-12 16:52:10.228399: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-02-12 16:52:10.228751: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3493635000 Hz
/home/jmerelo/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype("int32")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn('`model.predict_classes()` is deprecated and '
21Feb12_165615|-- Generation 1 --
21Feb12_165615|    -- Crossed 0 individual pairs.
21Feb12_165615|    -- Mutated 32 individuals.
21Feb12_170015|    -- Evaluated 64 individuals.
21Feb12_170015|    Summary of generation 1:
21Feb12_170015| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_170015|-----------  ------------------  --------------------  ----------
21Feb12_170015|    Max            42.43                153.00          0.78021
21Feb12_170015|    Avg            41.54                34.89           0.02353
21Feb12_170015|    Min            26.96                 3.00           0.00000
21Feb12_170015|    Std             2.54                30.24           0.11903
21Feb12_170015|   Best            26.96                26.00           0.78021
21Feb12_170015|-- Generation 2 --
21Feb12_170015|    -- Crossed 1 individual pairs.
21Feb12_170015|    -- Mutated 32 individuals.
21Feb12_170413|    -- Evaluated 64 individuals.
21Feb12_170413|    Summary of generation 2:
21Feb12_170413| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_170413|-----------  ------------------  --------------------  ----------
21Feb12_170413|    Max            42.17                120.00          0.59213
21Feb12_170413|    Avg            41.75                21.77           0.01552
21Feb12_170413|    Min            29.22                 3.00           0.00000
21Feb12_170413|    Std             1.59                23.40           0.08049
21Feb12_170413|   Best            29.22                10.00           0.59213
21Feb12_170413|-- Generation 3 --
21Feb12_170413|    -- Crossed 2 individual pairs.
21Feb12_170413|    -- Mutated 32 individuals.
21Feb12_170807|    -- Evaluated 64 individuals.
21Feb12_170807|    Summary of generation 3:
21Feb12_170807| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_170807|-----------  ------------------  --------------------  ----------
21Feb12_170807|    Max            42.35                52.00           0.57081
21Feb12_170807|    Avg            41.45                12.50           0.02158
21Feb12_170807|    Min            28.00                 3.00           0.00000
21Feb12_170807|    Std             2.41                11.47           0.09265
21Feb12_170807|   Best            28.00                10.00           0.57081
21Feb12_170807|-- Generation 4 --
21Feb12_170807|    -- Crossed 2 individual pairs.
21Feb12_170807|    -- Mutated 32 individuals.
21Feb12_171203|    -- Evaluated 64 individuals.
21Feb12_171203|    Summary of generation 4:
21Feb12_171203| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_171203|-----------  ------------------  --------------------  ----------
21Feb12_171203|    Max            42.43                50.00           0.73604
21Feb12_171203|    Avg            40.91                14.03           0.04906
21Feb12_171203|    Min            26.61                 3.00           0.00000
21Feb12_171203|    Std             3.68                12.98           0.16491
21Feb12_171203|   Best            26.61                10.00           0.58490
21Feb12_171203|-- Generation 5 --
21Feb12_171203|    -- Crossed 1 individual pairs.
21Feb12_171203|    -- Mutated 32 individuals.
21Feb12_171557|    -- Evaluated 64 individuals.
21Feb12_171557|    Summary of generation 5:
21Feb12_171557| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_171557|-----------  ------------------  --------------------  ----------
21Feb12_171557|    Max            42.00                87.00           0.58645
21Feb12_171557|    Avg            41.40                11.06           0.02243
21Feb12_171557|    Min            27.22                 2.00           0.00000
21Feb12_171557|    Std             2.50                14.42           0.09508
21Feb12_171557|   Best            27.22                10.00           0.58645
21Feb12_171557|-- Generation 6 --
21Feb12_171557|    -- Crossed 1 individual pairs.
21Feb12_171557|    -- Mutated 32 individuals.
21Feb12_171952|    -- Evaluated 64 individuals.
21Feb12_171952|    Summary of generation 6:
21Feb12_171952| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_171952|-----------  ------------------  --------------------  ----------
21Feb12_171952|    Max            42.17                87.00           0.48315
21Feb12_171952|    Avg            41.76                14.61           0.01075
21Feb12_171952|    Min            30.09                 2.00           0.00000
21Feb12_171952|    Std             1.48                16.14           0.06024
21Feb12_171952|   Best            30.09                16.00           0.48315
21Feb12_171952|-- Generation 7 --
21Feb12_171952|    -- Crossed 4 individual pairs.
21Feb12_171952|    -- Mutated 32 individuals.
21Feb12_172346|    -- Evaluated 64 individuals.
21Feb12_172346|    Summary of generation 7:
21Feb12_172346| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_172346|-----------  ------------------  --------------------  ----------
21Feb12_172346|    Max            42.35                87.00           0.60142
21Feb12_172346|    Avg            41.96                17.47           0.01153
21Feb12_172346|    Min            41.30                 2.00           0.00000
21Feb12_172346|    Std             0.13                20.88           0.07442
21Feb12_172346|   Best            41.30                 8.00           0.02317
21Feb12_172346|-- Generation 8 --
21Feb12_172346|    -- Crossed 2 individual pairs.
21Feb12_172346|    -- Mutated 32 individuals.
21Feb12_172740|    -- Evaluated 64 individuals.
21Feb12_172740|    Summary of generation 8:
21Feb12_172740| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_172740|-----------  ------------------  --------------------  ----------
21Feb12_172740|    Max            42.26                63.00           0.02318
21Feb12_172740|    Avg            41.96                11.36           0.00198
21Feb12_172740|    Min            41.22                 2.00           0.00000
21Feb12_172740|    Std             0.12                12.84           0.00346
21Feb12_172740|   Best            41.22                 8.00           0.02318
21Feb12_172740|-- Generation 9 --
21Feb12_172740|    -- Crossed 4 individual pairs.
21Feb12_172740|    -- Mutated 32 individuals.
21Feb12_173135|    -- Evaluated 64 individuals.
21Feb12_173135|    Summary of generation 9:
21Feb12_173135| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_173135|-----------  ------------------  --------------------  ----------
21Feb12_173135|    Max            42.17                57.00           0.02831
21Feb12_173135|    Avg            41.91                11.08           0.00331
21Feb12_173135|    Min            41.04                 2.00           0.00000
21Feb12_173135|    Std             0.17                10.58           0.00556
21Feb12_173135|   Best            41.04                 8.00           0.02831
21Feb12_173135|-- Generation 10 --
21Feb12_173135|    -- Crossed 5 individual pairs.
21Feb12_173135|    -- Mutated 32 individuals.
21Feb12_173529|    -- Evaluated 64 individuals.
21Feb12_173529|    Summary of generation 10:
21Feb12_173529| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_173529|-----------  ------------------  --------------------  ----------
21Feb12_173529|    Max            42.09                34.00           0.02318
21Feb12_173529|    Avg            41.90                10.81           0.00408
21Feb12_173529|    Min            41.22                 2.00           0.00000
21Feb12_173529|    Std             0.12                 7.36           0.00429
21Feb12_173529|   Best            41.22                 8.00           0.02318
21Feb12_173529|-- Generation 11 --
21Feb12_173529|    -- Crossed 2 individual pairs.
21Feb12_173529|    -- Mutated 32 individuals.
21Feb12_173924|    -- Evaluated 64 individuals.
21Feb12_173924|    Summary of generation 11:
21Feb12_173924| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_173924|-----------  ------------------  --------------------  ----------
21Feb12_173924|    Max            42.35                54.00           0.79914
21Feb12_173924|    Avg            41.88                12.89           0.01596
21Feb12_173924|    Min            39.83                 3.00           0.00000
21Feb12_173924|    Std             0.29                10.43           0.09877
21Feb12_173924|   Best            39.83                18.00           0.79914
21Feb12_173924|-- Generation 12 --
21Feb12_173924|    -- Crossed 5 individual pairs.
21Feb12_173924|    -- Mutated 32 individuals.
21Feb12_174318|    -- Evaluated 64 individuals.
21Feb12_174318|    Summary of generation 12:
21Feb12_174318| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_174318|-----------  ------------------  --------------------  ----------
21Feb12_174318|    Max            42.17                36.00           0.48292
21Feb12_174318|    Avg            41.65                10.70           0.01259
21Feb12_174318|    Min            28.00                 3.00           0.00000
21Feb12_174318|    Std             1.73                 8.20           0.05949
21Feb12_174318|   Best            28.00                36.00           0.48292
21Feb12_174318|-- Generation 13 --
21Feb12_174318|    -- Crossed 4 individual pairs.
21Feb12_174318|    -- Mutated 32 individuals.
21Feb12_174711|    -- Evaluated 64 individuals.
21Feb12_174711|    Summary of generation 13:
21Feb12_174711| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_174711|-----------  ------------------  --------------------  ----------
21Feb12_174711|    Max            42.43                60.00           0.59889
21Feb12_174711|    Avg            41.63                12.56           0.01584
21Feb12_174711|    Min            29.13                 2.00           0.00000
21Feb12_174711|    Std             1.59                11.65           0.07385
21Feb12_174711|   Best            29.13                36.00           0.59889
21Feb12_174711|-- Generation 14 --
21Feb12_174711|    -- Crossed 2 individual pairs.
21Feb12_174711|    -- Mutated 32 individuals.
21Feb12_175107|    -- Evaluated 64 individuals.
21Feb12_175107|    Summary of generation 14:
21Feb12_175107| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_175107|-----------  ------------------  --------------------  ----------
21Feb12_175107|    Max            42.70                64.00           0.09132
21Feb12_175107|    Avg            41.84                15.06           0.00699
21Feb12_175107|    Min            39.13                 3.00           0.00000
21Feb12_175107|    Std             0.40                12.33           0.01205
21Feb12_175107|   Best            39.13                13.00           0.09132
21Feb12_175107|-- Generation 15 --
21Feb12_175107|    -- Crossed 2 individual pairs.
21Feb12_175107|    -- Mutated 32 individuals.
21Feb12_175501|    -- Evaluated 64 individuals.
21Feb12_175501|    Summary of generation 15:
21Feb12_175501| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_175501|-----------  ------------------  --------------------  ----------
21Feb12_175501|    Max            42.17                34.00           0.05624
21Feb12_175501|    Avg            41.83                12.44           0.00624
21Feb12_175501|    Min            40.26                 3.00           0.00000
21Feb12_175501|    Std             0.26                 9.28           0.00820
21Feb12_175501|   Best            40.26                14.00           0.05624
21Feb12_175501|-- Generation 16 --
21Feb12_175501|    -- Crossed 4 individual pairs.
21Feb12_175501|    -- Mutated 32 individuals.
21Feb12_175854|    -- Evaluated 64 individuals.
21Feb12_175854|    Summary of generation 16:
21Feb12_175854| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_175854|-----------  ------------------  --------------------  ----------
21Feb12_175854|    Max            42.26                42.00           0.02317
21Feb12_175854|    Avg            41.87                11.16           0.00569
21Feb12_175854|    Min            41.30                 3.00           0.00000
21Feb12_175854|    Std             0.16                 9.03           0.00531
21Feb12_175854|   Best            41.30                14.00           0.02317
21Feb12_175854|-- Generation 17 --
21Feb12_175854|    -- Crossed 2 individual pairs.
21Feb12_175854|    -- Mutated 32 individuals.
21Feb12_180246|    -- Evaluated 64 individuals.
21Feb12_180246|    Summary of generation 17:
21Feb12_180246| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_180246|-----------  ------------------  --------------------  ----------
21Feb12_180246|    Max            42.17                38.00           0.02317
21Feb12_180246|    Avg            41.84                 8.97           0.00589
21Feb12_180246|    Min            41.30                 3.00           0.00000
21Feb12_180246|    Std             0.17                 7.54           0.00556
21Feb12_180246|   Best            41.30                 6.00           0.02317
21Feb12_180246|-- Generation 18 --
21Feb12_180246|    -- Crossed 6 individual pairs.
21Feb12_180246|    -- Mutated 32 individuals.
21Feb12_180638|    -- Evaluated 64 individuals.
21Feb12_180638|    Summary of generation 18:
21Feb12_180638| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_180638|-----------  ------------------  --------------------  ----------
21Feb12_180638|    Max            42.17                34.00           0.02062
21Feb12_180638|    Avg            41.85                 7.94           0.00541
21Feb12_180638|    Min            41.30                 2.00           0.00000
21Feb12_180638|    Std             0.15                 6.04           0.00466
21Feb12_180638|   Best            41.30                14.00           0.02062
21Feb12_180638|-- Generation 19 --
21Feb12_180638|    -- Crossed 2 individual pairs.
21Feb12_180638|    -- Mutated 32 individuals.
21Feb12_181030|    -- Evaluated 64 individuals.
21Feb12_181030|    Summary of generation 19:
21Feb12_181030| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_181030|-----------  ------------------  --------------------  ----------
21Feb12_181030|    Max            42.09                36.00           0.02062
21Feb12_181030|    Avg            41.86                 8.64           0.00520
21Feb12_181030|    Min            41.30                 2.00           0.00000
21Feb12_181030|    Std             0.14                 7.58           0.00457
21Feb12_181030|   Best            41.30                14.00           0.02062
21Feb12_181030|-- Generation 20 --
21Feb12_181030|    -- Crossed 6 individual pairs.
21Feb12_181030|    -- Mutated 32 individuals.
21Feb12_181424|    -- Evaluated 64 individuals.
21Feb12_181424|    Summary of generation 20:
21Feb12_181424| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_181424|-----------  ------------------  --------------------  ----------
21Feb12_181424|    Max            42.35                38.00           0.47684
21Feb12_181424|    Avg            41.68                 7.67           0.01181
21Feb12_181424|    Min            28.96                 2.00           0.00000
21Feb12_181424|    Std             1.61                 6.96           0.05870
21Feb12_181424|   Best            28.96                27.00           0.47684
21Feb12_181424|-- Generation 21 --
21Feb12_181424|    -- Crossed 4 individual pairs.
21Feb12_181424|    -- Mutated 32 individuals.
21Feb12_181817|    -- Evaluated 64 individuals.
21Feb12_181817|    Summary of generation 21:
21Feb12_181817| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_181817|-----------  ------------------  --------------------  ----------
21Feb12_181817|    Max            42.00                30.00           0.03852
21Feb12_181817|    Avg            41.83                 7.09           0.00561
21Feb12_181817|    Min            40.70                 2.00           0.00000
21Feb12_181817|    Std             0.20                 5.54           0.00621
21Feb12_181817|   Best            40.70                12.00           0.03852
21Feb12_181817|-- Generation 22 --
21Feb12_181817|    -- Crossed 7 individual pairs.
21Feb12_181817|    -- Mutated 32 individuals.
21Feb12_182210|    -- Evaluated 64 individuals.
21Feb12_182210|    Summary of generation 22:
21Feb12_182210| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_182210|-----------  ------------------  --------------------  ----------
21Feb12_182210|    Max            42.00                36.00           0.78917
21Feb12_182210|    Avg            41.61                 7.02           0.01726
21Feb12_182210|    Min            26.70                 2.00           0.00000
21Feb12_182210|    Std             1.88                 5.97           0.09732
21Feb12_182210|   Best            26.70                12.00           0.78917
21Feb12_182210|-- Generation 23 --
21Feb12_182210|    -- Crossed 8 individual pairs.
21Feb12_182210|    -- Mutated 32 individuals.
21Feb12_182602|    -- Evaluated 64 individuals.
21Feb12_182602|    Summary of generation 23:
21Feb12_182602| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_182602|-----------  ------------------  --------------------  ----------
21Feb12_182602|    Max            42.17                36.00           0.01803
21Feb12_182602|    Avg            41.88                 5.92           0.00400
21Feb12_182602|    Min            41.57                 2.00           0.00000
21Feb12_182602|    Std             0.10                 5.68           0.00299
21Feb12_182602|   Best            41.57                 4.00           0.01803
21Feb12_182602|-- Generation 24 --
21Feb12_182602|    -- Crossed 6 individual pairs.
21Feb12_182602|    -- Mutated 32 individuals.
21Feb12_182954|    -- Evaluated 64 individuals.
21Feb12_182954|    Summary of generation 24:
21Feb12_182954| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_182954|-----------  ------------------  --------------------  ----------
21Feb12_182954|    Max            42.00                18.00           0.05118
21Feb12_182954|    Avg            41.83                 4.16           0.00560
21Feb12_182954|    Min            40.43                 2.00           0.00000
21Feb12_182954|    Std             0.21                 3.64           0.00670
21Feb12_182954|   Best            40.43                16.00           0.05118
21Feb12_182954|-- Generation 25 --
21Feb12_182954|    -- Crossed 7 individual pairs.
21Feb12_182954|    -- Mutated 32 individuals.
21Feb12_183344|    -- Evaluated 64 individuals.
21Feb12_183344|    Summary of generation 25:
21Feb12_183344| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_183344|-----------  ------------------  --------------------  ----------
21Feb12_183344|    Max            42.00                16.00           0.33123
21Feb12_183344|    Avg            41.85                 4.94           0.00961
21Feb12_183344|    Min            40.78                 2.00           0.00000
21Feb12_183344|    Std             0.17                 4.20           0.04088
21Feb12_183344|   Best            40.78                16.00           0.04355
21Feb12_183344|-- Generation 26 --
21Feb12_183344|    -- Crossed 8 individual pairs.
21Feb12_183344|    -- Mutated 32 individuals.
21Feb12_183737|    -- Evaluated 64 individuals.
21Feb12_183737|    Summary of generation 26:
21Feb12_183737| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_183737|-----------  ------------------  --------------------  ----------
21Feb12_183737|    Max            42.09                18.00           0.37955
21Feb12_183737|    Avg            41.71                 5.16           0.02032
21Feb12_183737|    Min            36.26                 2.00           0.00000
21Feb12_183737|    Std             0.82                 4.70           0.07407
21Feb12_183737|   Best            36.26                16.00           0.37955
21Feb12_183737|-- Generation 27 --
21Feb12_183737|    -- Crossed 4 individual pairs.
21Feb12_183737|    -- Mutated 32 individuals.
21Feb12_184129|    -- Evaluated 64 individuals.
21Feb12_184129|    Summary of generation 27:
21Feb12_184129| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_184129|-----------  ------------------  --------------------  ----------
21Feb12_184129|    Max            45.04                36.00           0.63942
21Feb12_184129|    Avg            41.89                 5.61           0.01757
21Feb12_184129|    Min            40.52                 2.00           0.00000
21Feb12_184129|    Std             0.46                 6.84           0.07983
21Feb12_184129|   Best            40.52                16.00           0.04864
21Feb12_184129|-- Generation 28 --
21Feb12_184129|    -- Crossed 6 individual pairs.
21Feb12_184129|    -- Mutated 32 individuals.
21Feb12_184522|    -- Evaluated 64 individuals.
21Feb12_184522|    Summary of generation 28:
21Feb12_184522| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_184522|-----------  ------------------  --------------------  ----------
21Feb12_184522|    Max            42.09                16.00           0.33726
21Feb12_184522|    Avg            41.85                 4.77           0.01021
21Feb12_184522|    Min            40.17                 2.00           0.00000
21Feb12_184522|    Std             0.23                 4.50           0.04197
21Feb12_184522|   Best            40.17                12.00           0.33726
21Feb12_184522|-- Generation 29 --
21Feb12_184522|    -- Crossed 8 individual pairs.
21Feb12_184522|    -- Mutated 32 individuals.
21Feb12_184913|    -- Evaluated 64 individuals.
21Feb12_184913|    Summary of generation 29:
21Feb12_184913| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_184913|-----------  ------------------  --------------------  ----------
21Feb12_184913|    Max            42.09                16.00           0.36303
21Feb12_184913|    Avg            41.79                 4.16           0.01871
21Feb12_184913|    Min            40.09                 2.00           0.00000
21Feb12_184913|    Std             0.31                 4.24           0.06179
21Feb12_184913|   Best            40.09                12.00           0.34132
21Feb12_184913|-- Generation 30 --
21Feb12_184913|    -- Crossed 9 individual pairs.
21Feb12_184913|    -- Mutated 32 individuals.
21Feb12_185306|    -- Evaluated 64 individuals.
21Feb12_185306|    Summary of generation 30:
21Feb12_185306| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_185306|-----------  ------------------  --------------------  ----------
21Feb12_185306|    Max            42.00                16.00           0.35828
21Feb12_185306|    Avg            41.74                 4.69           0.01683
21Feb12_185306|    Min            38.26                 2.00           0.00000
21Feb12_185306|    Std             0.50                 4.83           0.05358
21Feb12_185306|   Best            38.26                16.00           0.35828
21Feb12_185306|-- Generation 31 --
21Feb12_185306|    -- Crossed 11 individual pairs.
21Feb12_185306|    -- Mutated 32 individuals.
21Feb12_185659|    -- Evaluated 64 individuals.
21Feb12_185659|    Summary of generation 31:
21Feb12_185659| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_185659|-----------  ------------------  --------------------  ----------
21Feb12_185659|    Max            42.26                39.00           0.09472
21Feb12_185659|    Avg            41.86                 6.19           0.00690
21Feb12_185659|    Min            40.52                 2.00           0.00000
21Feb12_185659|    Std             0.21                 7.34           0.01529
21Feb12_185659|   Best            40.52                16.00           0.04613
21Feb12_185659|-- Generation 32 --
21Feb12_185659|    -- Crossed 10 individual pairs.
21Feb12_185659|    -- Mutated 32 individuals.
21Feb12_190050|    -- Evaluated 64 individuals.
21Feb12_190050|    Summary of generation 32:
21Feb12_190050| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_190050|-----------  ------------------  --------------------  ----------
21Feb12_190050|    Max            42.09                16.00           0.76604
21Feb12_190050|    Avg            41.71                 3.86           0.02090
21Feb12_190050|    Min            33.83                 2.00           0.00000
21Feb12_190050|    Std             1.02                 3.70           0.09877
21Feb12_190050|   Best            33.83                12.00           0.76604
21Feb12_190050|Best initial individual weights
21Feb12_190050|Individual:
21Feb12_190050|-- Constant hidden layers --
21Feb12_190050|False
21Feb12_190050|Layer 0:
21Feb12_190050|-- Config --
21Feb12_190050|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 11, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190050|-- Weights --
21Feb12_190050|[[-0.29576  0.44171  0.90013 -0.67922 -0.39729 -0.40263 -0.04202  0.08496
21Feb12_190050|   0.19256  0.41763 -0.24910]
21Feb12_190050| [ 0.47493 -0.67691  0.52223  0.92034  0.93101 -0.85934  0.61073  0.49136
21Feb12_190050|  -0.57326 -0.74076 -0.79649]
21Feb12_190050| [-0.19879  0.46529  0.21105  0.45887 -0.72253  0.41490  0.79793 -0.30828
21Feb12_190050|   0.25210 -0.63916 -0.53387]
21Feb12_190050| [ 0.14632  0.09562  0.13535  0.51707 -0.55555  0.15363  0.01683 -0.13500
21Feb12_190050|   0.87463 -0.63349  0.73259]
21Feb12_190050| [ 0.18647 -0.51428 -0.93035 -0.97888 -0.81124  0.42160 -0.76787  0.54877
21Feb12_190050|   0.74036 -0.67404 -0.66504]
21Feb12_190050| [-0.67870  0.45223 -0.37491  0.59901 -0.51989  0.22216  0.49236  0.56033
21Feb12_190050|  -0.35836  0.35994  0.55326]
21Feb12_190050| [-0.85862 -0.64388  0.59068 -0.99511  0.96639  0.45897 -0.97818 -0.61082
21Feb12_190050|   0.59509 -0.58225 -0.78013]
21Feb12_190050| [-0.41616  0.48318 -0.47935  0.60946  0.21410 -0.08904 -0.96585 -0.04995
21Feb12_190050|   0.62368 -0.73073  0.97219]
21Feb12_190050| [-0.17193  0.50680 -0.14093  0.74261 -0.92535 -0.16094 -0.84764  0.01603
21Feb12_190050|  -0.35258 -0.11580  0.13854]
21Feb12_190050| [ 0.77768  0.99810  0.06076 -0.64347 -0.54477 -0.14330 -0.06569  0.86989
21Feb12_190050|  -0.11544  0.54092  0.53981]
21Feb12_190050| [ 0.65170 -0.92989 -0.19214  0.96298  0.81013 -0.67034  0.82829 -0.33340
21Feb12_190050|  -0.11748 -0.37341  0.32247]
21Feb12_190050| [-0.24216  0.09957  0.72394 -0.06990 -0.34305  0.05443 -0.33588  0.47261
21Feb12_190050|  -0.75247  0.95147 -0.61440]
21Feb12_190050| [-0.89314 -0.84457 -0.28706 -0.46024  0.04331  0.42584  0.87819 -0.17375
21Feb12_190050|  -0.45340  0.34670  0.63683]
21Feb12_190050| [-0.05969  0.05102  0.03684 -0.81817  0.19725 -0.57510  0.42830  0.11246
21Feb12_190050|   0.94414 -0.24328  0.08999]
21Feb12_190050| [-0.40440 -0.67323  0.44669 -0.52153 -0.76404  0.28184  0.14262 -0.84181
21Feb12_190050|  -0.72081 -0.78985 -0.29508]
21Feb12_190050| [ 0.92388  0.99360  0.85258 -0.63939 -0.03349  0.40591 -0.37523 -0.27652
21Feb12_190050|  -0.49979  0.62500  0.59817]
21Feb12_190050| [ 0.62915  0.72273  0.79188  0.03677  0.82216 -0.69465  0.68928  0.66152
21Feb12_190050|   0.36424 -0.45319  0.83669]
21Feb12_190050| [ 0.03153 -0.48924 -0.64073  0.37862 -0.24840  0.44365 -0.19640  0.54182
21Feb12_190050|  -0.67521  0.36251 -0.89945]
21Feb12_190050| [-0.79120  0.82310 -0.05409  0.54136  0.77593 -0.71341 -0.36023 -0.84678
21Feb12_190050|   0.26197  0.35918 -0.83492]
21Feb12_190050| [-0.28186  0.99550  0.62717  0.80755 -0.56914  0.91476  0.28779 -0.78664
21Feb12_190050|  -0.27508 -0.01966 -0.48291]
21Feb12_190050| [ 0.88834  0.53014  0.35742  0.94366  0.65878  0.38323 -0.96544  0.93123
21Feb12_190050|   0.63960  0.63535 -0.46926]
21Feb12_190050| [ 0.45002  0.67483 -0.96693 -0.69815  0.02970 -0.61388 -0.81626  0.43638
21Feb12_190050|   0.29674 -0.56912  0.08677]
21Feb12_190050| [-0.13865  0.23134  0.65175  0.02864  0.32709 -0.42827 -0.25479 -0.61408
21Feb12_190050|   0.02793 -0.91917 -0.54231]
21Feb12_190050| [-0.99842 -0.11173  0.73087  0.94943 -0.01869 -0.01638 -0.46550  0.30141
21Feb12_190050|  -0.05369 -0.87358  0.39794]
21Feb12_190050| [ 0.78462  0.27529  0.79753  0.45045 -0.76238  0.32652 -0.79247 -0.23391
21Feb12_190050|   0.19755 -0.20175 -0.26996]
21Feb12_190050| [-0.00426 -0.70702 -0.27396 -0.47884  0.02352 -0.76399 -0.42811  0.44411
21Feb12_190050|  -0.35013 -0.28976 -0.31532]
21Feb12_190050| [ 0.36183  0.14226 -0.04661  0.31445 -0.42451 -0.84823 -0.88133 -0.96984
21Feb12_190050|  -0.81685  0.81182  0.13656]
21Feb12_190050| [-0.60907  0.42451  0.29491 -0.46852  0.78885  0.20030 -0.38119 -0.54307
21Feb12_190050|  -0.78533  0.03419 -0.48764]
21Feb12_190050| [ 0.22941  0.92714 -0.74982  0.58576 -0.64095  0.31465  0.14736  0.37728
21Feb12_190050|  -0.88395  0.01660 -0.48622]
21Feb12_190050| [ 0.11337  0.23404 -0.06600  0.27416 -0.01675 -0.15693  0.48697  0.28708
21Feb12_190050|   0.68547 -0.18628 -0.33336]
21Feb12_190050| [-0.68801  0.12030  0.52869  0.03536 -0.66741  0.36721  0.05309 -0.56489
21Feb12_190050|  -0.15327 -0.85319 -0.74260]
21Feb12_190050| [-0.10616 -0.41975 -0.05051  0.17304 -0.87530 -0.19831  0.83959 -0.71838
21Feb12_190050|   0.42196 -0.55286 -0.92074]
21Feb12_190050| [-0.14150 -0.87233 -0.29700  0.48172  0.27235  0.00437 -0.06600 -0.85195
21Feb12_190050|  -0.13544 -0.44674 -0.53926]
21Feb12_190050| [-0.94904 -0.21754 -0.06643 -0.41229  0.84909 -0.86020 -0.11523  0.49364
21Feb12_190050|   0.87791  0.59266 -0.01598]
21Feb12_190050| [ 0.43678 -0.97180 -0.91202 -0.32709 -0.40804 -0.38986 -0.80275 -0.12827
21Feb12_190050|  -0.14983  0.78031  0.94472]
21Feb12_190050| [ 0.09362  0.12280  0.44496  0.81658  0.23281  0.75600  0.43491  0.09108
21Feb12_190050|   0.70670 -0.31504 -0.14322]
21Feb12_190050| [-0.55823 -0.59812 -0.21541  0.32501  0.25693 -0.67641  0.74696 -0.97160
21Feb12_190050|  -0.23376  0.70688 -0.79409]
21Feb12_190050| [ 0.04609 -0.20207 -0.77610  0.53143  0.95253  0.65050  0.54157 -0.24706
21Feb12_190050|   0.79107  0.55921 -0.11719]
21Feb12_190050| [-0.67773  0.95721 -0.84428 -0.88051 -0.93167  0.42388 -0.43337 -0.83657
21Feb12_190050|  -0.25593  0.43029  0.79844]
21Feb12_190050| [ 0.77510  0.02649 -0.94974 -0.19331 -0.99427 -0.46967 -0.58294 -0.35727
21Feb12_190050|   0.92875  0.37809  0.76197]
21Feb12_190050| [-0.52250 -0.62252  0.61463  0.75560  0.12808  0.47657  0.20933 -0.68188
21Feb12_190050|   0.95615 -0.85965 -0.58901]
21Feb12_190050| [-0.29330  0.97664  0.63705  0.49555  0.13610 -0.07304  0.95707  0.32469
21Feb12_190050|   0.14671  0.59363 -0.49901]
21Feb12_190050| [ 0.73249 -0.18657  0.83322 -0.28426  0.24491  0.19713  0.48414  0.15126
21Feb12_190050|   0.45775 -0.12371  0.50424]
21Feb12_190050| [-0.49974 -0.24168 -0.48402  0.73610 -0.04308 -0.79545 -0.27158  0.11203
21Feb12_190050|   0.48799 -0.26679  0.36018]
21Feb12_190050| [ 0.45858 -0.85714  0.92189 -0.16526  0.71189 -0.25251 -0.02545  0.39237
21Feb12_190050|  -0.48677 -0.69279 -0.58604]
21Feb12_190050| [-0.20202  0.65799  0.46645  0.38929 -0.68372  0.84869 -0.12614 -0.50276
21Feb12_190050|   0.08758 -0.76666  0.84266]
21Feb12_190050| [-0.45524  0.04646  0.67728  0.59735 -0.54596  0.38150 -0.66395  0.02403
21Feb12_190050|  -0.98324  0.08609  0.79063]
21Feb12_190050| [ 0.15928  0.64826 -0.21082 -0.68342  0.67169  0.23875  0.29847  0.00488
21Feb12_190050|   0.48168  0.28575 -0.95257]
21Feb12_190050| [-0.77984 -0.11936 -0.90815  0.86596  0.77760 -0.74816 -0.88634 -0.99337
21Feb12_190050|  -0.34641 -0.64570  0.12533]
21Feb12_190050| [-0.72284  0.20483 -0.48588 -0.00654  0.36727  0.29562 -0.62051 -0.76325
21Feb12_190050|   0.17198  0.58959 -0.17821]
21Feb12_190050| [-0.93115 -0.10329 -0.56331  0.04189  0.59153  0.50150 -0.81420  0.71884
21Feb12_190050|  -0.27439 -0.99572 -0.37961]
21Feb12_190050| [-0.90947 -0.24039  0.51574  0.18926  0.88074  0.79405  0.33308 -0.75612
21Feb12_190050|   0.49840 -0.49200 -0.11378]
21Feb12_190050| [-0.31649 -0.57316 -0.76818 -0.95569  0.77239  0.48581  0.78517 -0.76635
21Feb12_190050|  -0.45484 -0.14335  0.10823]
21Feb12_190050| [ 0.81253  0.35428  0.22109  0.73372 -0.91041 -0.74838 -0.35725 -0.81841
21Feb12_190050|   0.21316  0.32486  0.40128]
21Feb12_190050| [-0.81834  0.57764  0.92182  0.33726 -0.30333 -0.04800  0.83304  0.43958
21Feb12_190050|  -0.64812  0.94559  0.01033]
21Feb12_190050| [ 0.48196  0.26653  0.77869 -0.47694 -0.85232  0.49088  0.09418  0.53945
21Feb12_190050|  -0.64240 -0.48429  0.71164]
21Feb12_190050| [-0.49896  0.76619  0.19463  0.49981  0.34442 -0.19091  0.93672  0.00971
21Feb12_190050|   0.74970  0.01320 -0.97981]]
21Feb12_190050|-- Bias --
21Feb12_190050|[-0.52460  0.52210  0.23662 -0.54722 -0.16964  0.21425 -0.28974 -0.66275
21Feb12_190050|  0.37977  0.92358  0.49915]
21Feb12_190050|Layer 1:
21Feb12_190050|-- Config --
21Feb12_190050|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 11], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190050|-- Weights --
21Feb12_190050|[[ 0.16314  0.83166]
21Feb12_190050| [ 0.31256 -0.10962]
21Feb12_190050| [-0.58012 -0.50993]
21Feb12_190050| [-0.77112 -0.63298]
21Feb12_190050| [-0.92198  0.22610]
21Feb12_190050| [ 0.06620 -0.58917]
21Feb12_190050| [ 0.89231  0.75125]
21Feb12_190050| [-0.93385  0.54358]
21Feb12_190050| [ 0.59636  0.12484]
21Feb12_190050| [ 0.67557 -0.43479]
21Feb12_190050| [-0.49289 -0.00622]]
21Feb12_190050|-- Bias --
21Feb12_190050|[-0.35739 -0.71180]
21Feb12_190050|Predicting the validation and test data with the Best initial individual.
21Feb12_190057| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_190057|-----------  ------------------  --------------------  ----------
21Feb12_190057|Validation         41.83                  11            0.00517
21Feb12_190057|   Test            36.49                  11            0.00000
21Feb12_190057|-------------------- Test #0 --------------------
21Feb12_190057|Best final individual weights
21Feb12_190057|Individual:
21Feb12_190057|-- Constant hidden layers --
21Feb12_190057|False
21Feb12_190057|Layer 0:
21Feb12_190057|-- Config --
21Feb12_190057|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190057|-- Weights --
21Feb12_190057|[[ 8.10203e-01  1.99129e-01]
21Feb12_190057| [-6.84952e-02  9.83400e-01]
21Feb12_190057| [-5.01340e-01  1.00868e+00]
21Feb12_190057| [ 2.40662e-01 -1.64043e+00]
21Feb12_190057| [-1.21490e-03  2.84203e-01]
21Feb12_190057| [ 6.44481e-02  9.35729e-01]
21Feb12_190057| [-3.89721e-01  4.44481e-01]
21Feb12_190057| [ 2.26160e-02  2.08558e+00]
21Feb12_190057| [ 1.52323e+00 -3.73645e-02]
21Feb12_190057| [ 9.95079e-01 -1.19442e+00]
21Feb12_190057| [ 2.32017e+00  2.47772e+00]
21Feb12_190057| [ 1.39694e+00  2.00685e+00]
21Feb12_190057| [ 1.60315e+00  2.62051e-01]
21Feb12_190057| [-1.99992e-01 -7.39963e-01]
21Feb12_190057| [ 6.47605e-01  7.20793e-02]
21Feb12_190057| [ 1.10277e+00  2.23991e-01]
21Feb12_190057| [-9.47393e-01 -1.66714e+00]
21Feb12_190057| [-2.57348e+00  2.41281e-01]
21Feb12_190057| [-4.87500e-01 -1.66269e+00]
21Feb12_190057| [ 2.64955e-01  1.70976e+00]
21Feb12_190057| [-6.83241e-01  8.97158e-02]
21Feb12_190057| [-6.78085e-02  7.86602e-01]
21Feb12_190057| [-5.49131e-01  5.31253e-02]
21Feb12_190057| [ 7.03601e-01 -1.02610e+00]
21Feb12_190057| [ 1.85455e+00  1.12002e+00]
21Feb12_190057| [ 3.52295e-01  3.10293e-01]
21Feb12_190057| [ 1.94962e-01  3.45131e-01]
21Feb12_190057| [ 1.70639e+00 -7.49769e-01]
21Feb12_190057| [-1.52947e+00 -9.79587e-02]
21Feb12_190057| [ 1.17446e+00 -1.52283e+00]
21Feb12_190057| [ 7.02147e-02  9.39315e-03]
21Feb12_190057| [-6.24043e-01 -3.22238e-01]
21Feb12_190057| [ 4.20892e-01 -6.45196e-01]
21Feb12_190057| [ 2.85730e-02 -5.92999e-01]
21Feb12_190057| [ 1.00154e+00 -6.72183e-01]
21Feb12_190057| [ 1.50337e+00  9.23464e-01]
21Feb12_190057| [ 7.19733e-01  5.94171e-01]
21Feb12_190057| [ 1.07145e+00  5.55464e-01]
21Feb12_190057| [-8.40764e-01  7.68126e-01]
21Feb12_190057| [ 1.23893e+00  9.22462e-01]
21Feb12_190057| [-9.13895e-02  9.23047e-01]
21Feb12_190057| [-3.22161e-01 -6.34520e-01]
21Feb12_190057| [ 1.51205e-01 -6.43524e-01]
21Feb12_190057| [-6.58346e-01  9.89111e-01]
21Feb12_190057| [-2.29255e+00 -7.15652e-01]
21Feb12_190057| [-8.19109e-01 -8.88308e-01]
21Feb12_190057| [ 5.36962e-01 -3.15096e+00]
21Feb12_190057| [-2.03141e+00  7.69575e-01]
21Feb12_190057| [ 2.14540e+00 -8.85673e-01]
21Feb12_190057| [-1.09594e+00 -8.25339e-01]
21Feb12_190057| [ 1.30855e-01 -1.79813e+00]
21Feb12_190057| [ 2.57514e+00  1.18195e+00]
21Feb12_190057| [ 1.79697e+00 -4.44049e-01]
21Feb12_190057| [-8.11073e-01 -9.58804e-02]
21Feb12_190057| [ 6.97402e-01 -3.52362e-01]
21Feb12_190057| [ 1.31588e+00 -1.06488e+00]
21Feb12_190057| [-1.13318e-01  8.95197e-01]]
21Feb12_190057|-- Bias --
21Feb12_190057|[-0.74250  0.42025]
21Feb12_190057|Layer 1:
21Feb12_190057|-- Config --
21Feb12_190057|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190057|-- Weights --
21Feb12_190057|[[ 0.13109 -0.79243  0.39897 -0.74131]
21Feb12_190057| [-0.93057 -0.81797 -0.74571  0.03946]]
21Feb12_190057|-- Bias --
21Feb12_190057|[ 0.52923  0.95311  0.78114 -0.93265]
21Feb12_190057|Layer 2:
21Feb12_190057|-- Config --
21Feb12_190057|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190057|-- Weights --
21Feb12_190057|[[ 0.84055  0.52233]
21Feb12_190057| [-1.37734 -0.30154]
21Feb12_190057| [ 0.54593 -0.67204]
21Feb12_190057| [-0.73794 -0.33974]]
21Feb12_190057|-- Bias --
21Feb12_190057|[0.06722 0.06699]
21Feb12_190057|Predicting the validation and test data with the Best final individual.
21Feb12_190105| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_190105|-----------  ------------------  --------------------  ----------
21Feb12_190105|Validation         42.00                  12            0.00000
21Feb12_190105|   Test            36.40                  12            0.00000
21Feb12_190105|-------------------- Test #1 --------------------
21Feb12_190105|Best final individual weights
21Feb12_190105|Individual:
21Feb12_190105|-- Constant hidden layers --
21Feb12_190105|False
21Feb12_190105|Layer 0:
21Feb12_190105|-- Config --
21Feb12_190105|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190105|-- Weights --
21Feb12_190105|[[ 8.10203e-01  1.99129e-01]
21Feb12_190105| [-6.84952e-02  9.83400e-01]
21Feb12_190105| [-5.01340e-01  1.00868e+00]
21Feb12_190105| [ 2.40662e-01 -1.64043e+00]
21Feb12_190105| [-1.21490e-03  2.84203e-01]
21Feb12_190105| [ 6.44481e-02  9.35729e-01]
21Feb12_190105| [-3.89721e-01  4.44481e-01]
21Feb12_190105| [ 2.26160e-02  2.08558e+00]
21Feb12_190105| [ 1.52323e+00 -3.73645e-02]
21Feb12_190105| [ 9.95079e-01 -1.19442e+00]
21Feb12_190105| [ 2.32017e+00  2.47772e+00]
21Feb12_190105| [ 1.39694e+00  2.00685e+00]
21Feb12_190105| [ 1.60315e+00  2.62051e-01]
21Feb12_190105| [-1.99992e-01 -7.39963e-01]
21Feb12_190105| [ 6.47605e-01  7.20793e-02]
21Feb12_190105| [ 1.10277e+00  2.23991e-01]
21Feb12_190105| [-9.47393e-01 -1.66714e+00]
21Feb12_190105| [-2.57348e+00  2.41281e-01]
21Feb12_190105| [-4.87500e-01 -1.66269e+00]
21Feb12_190105| [ 2.64955e-01  1.70976e+00]
21Feb12_190105| [-6.83241e-01  8.97158e-02]
21Feb12_190105| [-6.78085e-02  7.86602e-01]
21Feb12_190105| [-5.49131e-01  5.31253e-02]
21Feb12_190105| [ 7.03601e-01 -1.02610e+00]
21Feb12_190105| [ 1.85455e+00  1.12002e+00]
21Feb12_190105| [ 3.52295e-01  3.10293e-01]
21Feb12_190105| [ 1.94962e-01  3.45131e-01]
21Feb12_190105| [ 1.70639e+00 -7.49769e-01]
21Feb12_190105| [-1.52947e+00 -9.79587e-02]
21Feb12_190105| [ 1.17446e+00 -1.52283e+00]
21Feb12_190105| [ 7.02147e-02  9.39315e-03]
21Feb12_190105| [-6.24043e-01 -3.22238e-01]
21Feb12_190105| [ 4.20892e-01 -6.45196e-01]
21Feb12_190105| [ 2.85730e-02 -5.92999e-01]
21Feb12_190105| [ 1.00154e+00 -6.72183e-01]
21Feb12_190105| [ 1.50337e+00  9.23464e-01]
21Feb12_190105| [ 7.19733e-01  5.94171e-01]
21Feb12_190105| [ 1.07145e+00  5.55464e-01]
21Feb12_190105| [-8.40764e-01  7.68126e-01]
21Feb12_190105| [ 1.23893e+00  9.22462e-01]
21Feb12_190105| [-9.13895e-02  9.23047e-01]
21Feb12_190105| [-3.22161e-01 -6.34520e-01]
21Feb12_190105| [ 1.51205e-01 -6.43524e-01]
21Feb12_190105| [-6.58346e-01  9.89111e-01]
21Feb12_190105| [-2.29255e+00 -7.15652e-01]
21Feb12_190105| [-8.19109e-01 -8.88308e-01]
21Feb12_190105| [ 5.36962e-01 -3.15096e+00]
21Feb12_190105| [-2.03141e+00  7.69575e-01]
21Feb12_190105| [ 2.14540e+00 -8.85673e-01]
21Feb12_190105| [-1.09594e+00 -8.25339e-01]
21Feb12_190105| [ 1.30855e-01 -1.79813e+00]
21Feb12_190105| [ 2.57514e+00  1.18195e+00]
21Feb12_190105| [ 1.79697e+00 -4.44049e-01]
21Feb12_190105| [-8.11073e-01 -9.58804e-02]
21Feb12_190105| [ 6.97402e-01 -3.52362e-01]
21Feb12_190105| [ 1.31588e+00 -1.06488e+00]
21Feb12_190105| [-1.13318e-01  8.95197e-01]]
21Feb12_190105|-- Bias --
21Feb12_190105|[-0.74250  0.42025]
21Feb12_190105|Layer 1:
21Feb12_190105|-- Config --
21Feb12_190105|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190105|-- Weights --
21Feb12_190105|[[ 0.13109 -0.79243  0.39897 -0.74131]
21Feb12_190105| [-0.93057 -0.81797 -0.74571  0.03946]]
21Feb12_190105|-- Bias --
21Feb12_190105|[ 0.52923  0.95311  0.78114 -0.93265]
21Feb12_190105|Layer 2:
21Feb12_190105|-- Config --
21Feb12_190105|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190105|-- Weights --
21Feb12_190105|[[ 0.84055  0.52233]
21Feb12_190105| [-1.37734 -0.30154]
21Feb12_190105| [ 0.54593 -0.67204]
21Feb12_190105| [-0.73794 -0.33974]]
21Feb12_190105|-- Bias --
21Feb12_190105|[0.06722 0.06699]
21Feb12_190105|Predicting the validation and test data with the Best final individual.
21Feb12_190113| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_190113|-----------  ------------------  --------------------  ----------
21Feb12_190113|Validation         42.00                  12            0.00000
21Feb12_190113|   Test            36.40                  12            0.00000
21Feb12_190113|-------------------- Test #2 --------------------
21Feb12_190113|Best final individual weights
21Feb12_190113|Individual:
21Feb12_190113|-- Constant hidden layers --
21Feb12_190113|False
21Feb12_190113|Layer 0:
21Feb12_190113|-- Config --
21Feb12_190113|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190113|-- Weights --
21Feb12_190113|[[ 8.10203e-01  1.99129e-01]
21Feb12_190113| [-6.84952e-02  9.83400e-01]
21Feb12_190113| [-5.01340e-01  1.00868e+00]
21Feb12_190113| [ 2.40662e-01 -1.64043e+00]
21Feb12_190113| [-1.21490e-03  2.84203e-01]
21Feb12_190113| [ 6.44481e-02  9.35729e-01]
21Feb12_190113| [-3.89721e-01  4.44481e-01]
21Feb12_190113| [ 2.26160e-02  2.08558e+00]
21Feb12_190113| [ 1.52323e+00 -3.73645e-02]
21Feb12_190113| [ 9.95079e-01 -1.19442e+00]
21Feb12_190113| [ 2.32017e+00  2.47772e+00]
21Feb12_190113| [ 1.39694e+00  2.00685e+00]
21Feb12_190113| [ 1.60315e+00  2.62051e-01]
21Feb12_190113| [-1.99992e-01 -7.39963e-01]
21Feb12_190113| [ 6.47605e-01  7.20793e-02]
21Feb12_190113| [ 1.10277e+00  2.23991e-01]
21Feb12_190113| [-9.47393e-01 -1.66714e+00]
21Feb12_190113| [-2.57348e+00  2.41281e-01]
21Feb12_190113| [-4.87500e-01 -1.66269e+00]
21Feb12_190113| [ 2.64955e-01  1.70976e+00]
21Feb12_190113| [-6.83241e-01  8.97158e-02]
21Feb12_190113| [-6.78085e-02  7.86602e-01]
21Feb12_190113| [-5.49131e-01  5.31253e-02]
21Feb12_190113| [ 7.03601e-01 -1.02610e+00]
21Feb12_190113| [ 1.85455e+00  1.12002e+00]
21Feb12_190113| [ 3.52295e-01  3.10293e-01]
21Feb12_190113| [ 1.94962e-01  3.45131e-01]
21Feb12_190113| [ 1.70639e+00 -7.49769e-01]
21Feb12_190113| [-1.52947e+00 -9.79587e-02]
21Feb12_190113| [ 1.17446e+00 -1.52283e+00]
21Feb12_190113| [ 7.02147e-02  9.39315e-03]
21Feb12_190113| [-6.24043e-01 -3.22238e-01]
21Feb12_190113| [ 4.20892e-01 -6.45196e-01]
21Feb12_190113| [ 2.85730e-02 -5.92999e-01]
21Feb12_190113| [ 1.00154e+00 -6.72183e-01]
21Feb12_190113| [ 1.50337e+00  9.23464e-01]
21Feb12_190113| [ 7.19733e-01  5.94171e-01]
21Feb12_190113| [ 1.07145e+00  5.55464e-01]
21Feb12_190113| [-8.40764e-01  7.68126e-01]
21Feb12_190113| [ 1.23893e+00  9.22462e-01]
21Feb12_190113| [-9.13895e-02  9.23047e-01]
21Feb12_190113| [-3.22161e-01 -6.34520e-01]
21Feb12_190113| [ 1.51205e-01 -6.43524e-01]
21Feb12_190113| [-6.58346e-01  9.89111e-01]
21Feb12_190113| [-2.29255e+00 -7.15652e-01]
21Feb12_190113| [-8.19109e-01 -8.88308e-01]
21Feb12_190113| [ 5.36962e-01 -3.15096e+00]
21Feb12_190113| [-2.03141e+00  7.69575e-01]
21Feb12_190113| [ 2.14540e+00 -8.85673e-01]
21Feb12_190113| [-1.09594e+00 -8.25339e-01]
21Feb12_190113| [ 1.30855e-01 -1.79813e+00]
21Feb12_190113| [ 2.57514e+00  1.18195e+00]
21Feb12_190113| [ 1.79697e+00 -4.44049e-01]
21Feb12_190113| [-8.11073e-01 -9.58804e-02]
21Feb12_190113| [ 6.97402e-01 -3.52362e-01]
21Feb12_190113| [ 1.31588e+00 -1.06488e+00]
21Feb12_190113| [-1.13318e-01  8.95197e-01]]
21Feb12_190113|-- Bias --
21Feb12_190113|[-0.74250  0.42025]
21Feb12_190113|Layer 1:
21Feb12_190113|-- Config --
21Feb12_190113|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190113|-- Weights --
21Feb12_190113|[[ 0.13109 -0.79243  0.39897 -0.74131]
21Feb12_190113| [-0.93057 -0.81797 -0.74571  0.03946]]
21Feb12_190113|-- Bias --
21Feb12_190113|[ 0.52923  0.95311  0.78114 -0.93265]
21Feb12_190113|Layer 2:
21Feb12_190113|-- Config --
21Feb12_190113|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190113|-- Weights --
21Feb12_190113|[[ 0.84055  0.52233]
21Feb12_190113| [-1.37734 -0.30154]
21Feb12_190113| [ 0.54593 -0.67204]
21Feb12_190113| [-0.73794 -0.33974]]
21Feb12_190113|-- Bias --
21Feb12_190113|[0.06722 0.06699]
21Feb12_190113|Predicting the validation and test data with the Best final individual.
21Feb12_190120| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_190120|-----------  ------------------  --------------------  ----------
21Feb12_190120|Validation         42.00                  12            0.00000
21Feb12_190120|   Test            36.40                  12            0.00000
21Feb12_190120|-------------------- Test #3 --------------------
21Feb12_190120|Best final individual weights
21Feb12_190120|Individual:
21Feb12_190120|-- Constant hidden layers --
21Feb12_190120|False
21Feb12_190120|Layer 0:
21Feb12_190120|-- Config --
21Feb12_190120|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190120|-- Weights --
21Feb12_190120|[[ 8.10203e-01  1.99129e-01]
21Feb12_190120| [-6.84952e-02  9.83400e-01]
21Feb12_190120| [-5.01340e-01  1.00868e+00]
21Feb12_190120| [ 2.40662e-01 -1.64043e+00]
21Feb12_190120| [-1.21490e-03  2.84203e-01]
21Feb12_190120| [ 6.44481e-02  9.35729e-01]
21Feb12_190120| [-3.89721e-01  4.44481e-01]
21Feb12_190120| [ 2.26160e-02  2.08558e+00]
21Feb12_190120| [ 1.52323e+00 -3.73645e-02]
21Feb12_190120| [ 9.95079e-01 -1.19442e+00]
21Feb12_190120| [ 2.32017e+00  2.47772e+00]
21Feb12_190120| [ 1.39694e+00  2.00685e+00]
21Feb12_190120| [ 1.60315e+00  2.62051e-01]
21Feb12_190120| [-1.99992e-01 -7.39963e-01]
21Feb12_190120| [ 6.47605e-01  7.20793e-02]
21Feb12_190120| [ 1.10277e+00  2.23991e-01]
21Feb12_190120| [-9.47393e-01 -1.66714e+00]
21Feb12_190120| [-2.57348e+00  2.41281e-01]
21Feb12_190120| [-4.87500e-01 -1.66269e+00]
21Feb12_190120| [ 2.64955e-01  1.70976e+00]
21Feb12_190120| [-6.83241e-01  8.97158e-02]
21Feb12_190120| [-6.78085e-02  7.86602e-01]
21Feb12_190120| [-5.49131e-01  5.31253e-02]
21Feb12_190120| [ 7.03601e-01 -1.02610e+00]
21Feb12_190120| [ 1.85455e+00  1.12002e+00]
21Feb12_190120| [ 3.52295e-01  3.10293e-01]
21Feb12_190120| [ 1.94962e-01  3.45131e-01]
21Feb12_190120| [ 1.70639e+00 -7.49769e-01]
21Feb12_190120| [-1.52947e+00 -9.79587e-02]
21Feb12_190120| [ 1.17446e+00 -1.52283e+00]
21Feb12_190120| [ 7.02147e-02  9.39315e-03]
21Feb12_190120| [-6.24043e-01 -3.22238e-01]
21Feb12_190120| [ 4.20892e-01 -6.45196e-01]
21Feb12_190120| [ 2.85730e-02 -5.92999e-01]
21Feb12_190120| [ 1.00154e+00 -6.72183e-01]
21Feb12_190120| [ 1.50337e+00  9.23464e-01]
21Feb12_190120| [ 7.19733e-01  5.94171e-01]
21Feb12_190120| [ 1.07145e+00  5.55464e-01]
21Feb12_190120| [-8.40764e-01  7.68126e-01]
21Feb12_190120| [ 1.23893e+00  9.22462e-01]
21Feb12_190120| [-9.13895e-02  9.23047e-01]
21Feb12_190120| [-3.22161e-01 -6.34520e-01]
21Feb12_190120| [ 1.51205e-01 -6.43524e-01]
21Feb12_190120| [-6.58346e-01  9.89111e-01]
21Feb12_190120| [-2.29255e+00 -7.15652e-01]
21Feb12_190120| [-8.19109e-01 -8.88308e-01]
21Feb12_190120| [ 5.36962e-01 -3.15096e+00]
21Feb12_190120| [-2.03141e+00  7.69575e-01]
21Feb12_190120| [ 2.14540e+00 -8.85673e-01]
21Feb12_190120| [-1.09594e+00 -8.25339e-01]
21Feb12_190120| [ 1.30855e-01 -1.79813e+00]
21Feb12_190120| [ 2.57514e+00  1.18195e+00]
21Feb12_190120| [ 1.79697e+00 -4.44049e-01]
21Feb12_190120| [-8.11073e-01 -9.58804e-02]
21Feb12_190120| [ 6.97402e-01 -3.52362e-01]
21Feb12_190120| [ 1.31588e+00 -1.06488e+00]
21Feb12_190120| [-1.13318e-01  8.95197e-01]]
21Feb12_190120|-- Bias --
21Feb12_190120|[-0.74250  0.42025]
21Feb12_190120|Layer 1:
21Feb12_190120|-- Config --
21Feb12_190120|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190120|-- Weights --
21Feb12_190120|[[ 0.13109 -0.79243  0.39897 -0.74131]
21Feb12_190120| [-0.93057 -0.81797 -0.74571  0.03946]]
21Feb12_190120|-- Bias --
21Feb12_190120|[ 0.52923  0.95311  0.78114 -0.93265]
21Feb12_190120|Layer 2:
21Feb12_190120|-- Config --
21Feb12_190120|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190120|-- Weights --
21Feb12_190120|[[ 0.84055  0.52233]
21Feb12_190120| [-1.37734 -0.30154]
21Feb12_190120| [ 0.54593 -0.67204]
21Feb12_190120| [-0.73794 -0.33974]]
21Feb12_190120|-- Bias --
21Feb12_190120|[0.06722 0.06699]
21Feb12_190120|Predicting the validation and test data with the Best final individual.
21Feb12_190128| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_190128|-----------  ------------------  --------------------  ----------
21Feb12_190128|Validation         42.00                  12            0.00000
21Feb12_190128|   Test            36.40                  12            0.00000
21Feb12_190128|-------------------- Test #4 --------------------
21Feb12_190128|Best final individual weights
21Feb12_190128|Individual:
21Feb12_190128|-- Constant hidden layers --
21Feb12_190128|False
21Feb12_190128|Layer 0:
21Feb12_190128|-- Config --
21Feb12_190128|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190128|-- Weights --
21Feb12_190128|[[ 8.10203e-01  1.99129e-01]
21Feb12_190128| [-6.84952e-02  9.83400e-01]
21Feb12_190128| [-5.01340e-01  1.00868e+00]
21Feb12_190128| [ 2.40662e-01 -1.64043e+00]
21Feb12_190128| [-1.21490e-03  2.84203e-01]
21Feb12_190128| [ 6.44481e-02  9.35729e-01]
21Feb12_190128| [-3.89721e-01  4.44481e-01]
21Feb12_190128| [ 2.26160e-02  2.08558e+00]
21Feb12_190128| [ 1.52323e+00 -3.73645e-02]
21Feb12_190128| [ 9.95079e-01 -1.19442e+00]
21Feb12_190128| [ 2.32017e+00  2.47772e+00]
21Feb12_190128| [ 1.39694e+00  2.00685e+00]
21Feb12_190128| [ 1.60315e+00  2.62051e-01]
21Feb12_190128| [-1.99992e-01 -7.39963e-01]
21Feb12_190128| [ 6.47605e-01  7.20793e-02]
21Feb12_190128| [ 1.10277e+00  2.23991e-01]
21Feb12_190128| [-9.47393e-01 -1.66714e+00]
21Feb12_190128| [-2.57348e+00  2.41281e-01]
21Feb12_190128| [-4.87500e-01 -1.66269e+00]
21Feb12_190128| [ 2.64955e-01  1.70976e+00]
21Feb12_190128| [-6.83241e-01  8.97158e-02]
21Feb12_190128| [-6.78085e-02  7.86602e-01]
21Feb12_190128| [-5.49131e-01  5.31253e-02]
21Feb12_190128| [ 7.03601e-01 -1.02610e+00]
21Feb12_190128| [ 1.85455e+00  1.12002e+00]
21Feb12_190128| [ 3.52295e-01  3.10293e-01]
21Feb12_190128| [ 1.94962e-01  3.45131e-01]
21Feb12_190128| [ 1.70639e+00 -7.49769e-01]
21Feb12_190128| [-1.52947e+00 -9.79587e-02]
21Feb12_190128| [ 1.17446e+00 -1.52283e+00]
21Feb12_190128| [ 7.02147e-02  9.39315e-03]
21Feb12_190128| [-6.24043e-01 -3.22238e-01]
21Feb12_190128| [ 4.20892e-01 -6.45196e-01]
21Feb12_190128| [ 2.85730e-02 -5.92999e-01]
21Feb12_190128| [ 1.00154e+00 -6.72183e-01]
21Feb12_190128| [ 1.50337e+00  9.23464e-01]
21Feb12_190128| [ 7.19733e-01  5.94171e-01]
21Feb12_190128| [ 1.07145e+00  5.55464e-01]
21Feb12_190128| [-8.40764e-01  7.68126e-01]
21Feb12_190128| [ 1.23893e+00  9.22462e-01]
21Feb12_190128| [-9.13895e-02  9.23047e-01]
21Feb12_190128| [-3.22161e-01 -6.34520e-01]
21Feb12_190128| [ 1.51205e-01 -6.43524e-01]
21Feb12_190128| [-6.58346e-01  9.89111e-01]
21Feb12_190128| [-2.29255e+00 -7.15652e-01]
21Feb12_190128| [-8.19109e-01 -8.88308e-01]
21Feb12_190128| [ 5.36962e-01 -3.15096e+00]
21Feb12_190128| [-2.03141e+00  7.69575e-01]
21Feb12_190128| [ 2.14540e+00 -8.85673e-01]
21Feb12_190128| [-1.09594e+00 -8.25339e-01]
21Feb12_190128| [ 1.30855e-01 -1.79813e+00]
21Feb12_190128| [ 2.57514e+00  1.18195e+00]
21Feb12_190128| [ 1.79697e+00 -4.44049e-01]
21Feb12_190128| [-8.11073e-01 -9.58804e-02]
21Feb12_190128| [ 6.97402e-01 -3.52362e-01]
21Feb12_190128| [ 1.31588e+00 -1.06488e+00]
21Feb12_190128| [-1.13318e-01  8.95197e-01]]
21Feb12_190128|-- Bias --
21Feb12_190128|[-0.74250  0.42025]
21Feb12_190128|Layer 1:
21Feb12_190128|-- Config --
21Feb12_190128|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190128|-- Weights --
21Feb12_190128|[[ 0.13109 -0.79243  0.39897 -0.74131]
21Feb12_190128| [-0.93057 -0.81797 -0.74571  0.03946]]
21Feb12_190128|-- Bias --
21Feb12_190128|[ 0.52923  0.95311  0.78114 -0.93265]
21Feb12_190128|Layer 2:
21Feb12_190128|-- Config --
21Feb12_190128|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190128|-- Weights --
21Feb12_190128|[[ 0.84055  0.52233]
21Feb12_190128| [-1.37734 -0.30154]
21Feb12_190128| [ 0.54593 -0.67204]
21Feb12_190128| [-0.73794 -0.33974]]
21Feb12_190128|-- Bias --
21Feb12_190128|[0.06722 0.06699]
21Feb12_190128|Predicting the validation and test data with the Best final individual.
21Feb12_190135| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_190135|-----------  ------------------  --------------------  ----------
21Feb12_190135|Validation         42.00                  12            0.00000
21Feb12_190135|   Test            36.40                  12            0.00000
21Feb12_190135|-------------------- Test #5 --------------------
21Feb12_190135|Best final individual weights
21Feb12_190135|Individual:
21Feb12_190135|-- Constant hidden layers --
21Feb12_190135|False
21Feb12_190135|Layer 0:
21Feb12_190135|-- Config --
21Feb12_190135|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190135|-- Weights --
21Feb12_190135|[[ 8.10203e-01  1.99129e-01]
21Feb12_190135| [-6.84952e-02  9.83400e-01]
21Feb12_190135| [-5.01340e-01  1.00868e+00]
21Feb12_190135| [ 2.40662e-01 -1.64043e+00]
21Feb12_190135| [-1.21490e-03  2.84203e-01]
21Feb12_190135| [ 6.44481e-02  9.35729e-01]
21Feb12_190135| [-3.89721e-01  4.44481e-01]
21Feb12_190135| [ 2.26160e-02  2.08558e+00]
21Feb12_190135| [ 1.52323e+00 -3.73645e-02]
21Feb12_190135| [ 9.95079e-01 -1.19442e+00]
21Feb12_190135| [ 2.32017e+00  2.47772e+00]
21Feb12_190135| [ 1.39694e+00  2.00685e+00]
21Feb12_190135| [ 1.60315e+00  2.62051e-01]
21Feb12_190135| [-1.99992e-01 -7.39963e-01]
21Feb12_190135| [ 6.47605e-01  7.20793e-02]
21Feb12_190135| [ 1.10277e+00  2.23991e-01]
21Feb12_190135| [-9.47393e-01 -1.66714e+00]
21Feb12_190135| [-2.57348e+00  2.41281e-01]
21Feb12_190135| [-4.87500e-01 -1.66269e+00]
21Feb12_190135| [ 2.64955e-01  1.70976e+00]
21Feb12_190135| [-6.83241e-01  8.97158e-02]
21Feb12_190135| [-6.78085e-02  7.86602e-01]
21Feb12_190135| [-5.49131e-01  5.31253e-02]
21Feb12_190135| [ 7.03601e-01 -1.02610e+00]
21Feb12_190135| [ 1.85455e+00  1.12002e+00]
21Feb12_190135| [ 3.52295e-01  3.10293e-01]
21Feb12_190135| [ 1.94962e-01  3.45131e-01]
21Feb12_190135| [ 1.70639e+00 -7.49769e-01]
21Feb12_190135| [-1.52947e+00 -9.79587e-02]
21Feb12_190135| [ 1.17446e+00 -1.52283e+00]
21Feb12_190135| [ 7.02147e-02  9.39315e-03]
21Feb12_190135| [-6.24043e-01 -3.22238e-01]
21Feb12_190135| [ 4.20892e-01 -6.45196e-01]
21Feb12_190135| [ 2.85730e-02 -5.92999e-01]
21Feb12_190135| [ 1.00154e+00 -6.72183e-01]
21Feb12_190135| [ 1.50337e+00  9.23464e-01]
21Feb12_190135| [ 7.19733e-01  5.94171e-01]
21Feb12_190135| [ 1.07145e+00  5.55464e-01]
21Feb12_190135| [-8.40764e-01  7.68126e-01]
21Feb12_190135| [ 1.23893e+00  9.22462e-01]
21Feb12_190135| [-9.13895e-02  9.23047e-01]
21Feb12_190135| [-3.22161e-01 -6.34520e-01]
21Feb12_190135| [ 1.51205e-01 -6.43524e-01]
21Feb12_190135| [-6.58346e-01  9.89111e-01]
21Feb12_190135| [-2.29255e+00 -7.15652e-01]
21Feb12_190135| [-8.19109e-01 -8.88308e-01]
21Feb12_190135| [ 5.36962e-01 -3.15096e+00]
21Feb12_190135| [-2.03141e+00  7.69575e-01]
21Feb12_190135| [ 2.14540e+00 -8.85673e-01]
21Feb12_190135| [-1.09594e+00 -8.25339e-01]
21Feb12_190135| [ 1.30855e-01 -1.79813e+00]
21Feb12_190135| [ 2.57514e+00  1.18195e+00]
21Feb12_190135| [ 1.79697e+00 -4.44049e-01]
21Feb12_190135| [-8.11073e-01 -9.58804e-02]
21Feb12_190135| [ 6.97402e-01 -3.52362e-01]
21Feb12_190135| [ 1.31588e+00 -1.06488e+00]
21Feb12_190135| [-1.13318e-01  8.95197e-01]]
21Feb12_190135|-- Bias --
21Feb12_190135|[-0.74250  0.42025]
21Feb12_190135|Layer 1:
21Feb12_190135|-- Config --
21Feb12_190135|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190135|-- Weights --
21Feb12_190135|[[ 0.13109 -0.79243  0.39897 -0.74131]
21Feb12_190135| [-0.93057 -0.81797 -0.74571  0.03946]]
21Feb12_190135|-- Bias --
21Feb12_190135|[ 0.52923  0.95311  0.78114 -0.93265]
21Feb12_190135|Layer 2:
21Feb12_190135|-- Config --
21Feb12_190135|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190135|-- Weights --
21Feb12_190135|[[ 0.84055  0.52233]
21Feb12_190135| [-1.37734 -0.30154]
21Feb12_190135| [ 0.54593 -0.67204]
21Feb12_190135| [-0.73794 -0.33974]]
21Feb12_190135|-- Bias --
21Feb12_190135|[0.06722 0.06699]
21Feb12_190135|Predicting the validation and test data with the Best final individual.
21Feb12_190143| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_190143|-----------  ------------------  --------------------  ----------
21Feb12_190143|Validation         42.00                  12            0.00000
21Feb12_190143|   Test            36.40                  12            0.00000
21Feb12_190143|-------------------- Test #6 --------------------
21Feb12_190143|Best final individual weights
21Feb12_190143|Individual:
21Feb12_190143|-- Constant hidden layers --
21Feb12_190143|False
21Feb12_190143|Layer 0:
21Feb12_190143|-- Config --
21Feb12_190143|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190143|-- Weights --
21Feb12_190143|[[ 8.10203e-01  1.99129e-01]
21Feb12_190143| [-6.84952e-02  9.83400e-01]
21Feb12_190143| [-5.01340e-01  1.00868e+00]
21Feb12_190143| [ 2.40662e-01 -1.64043e+00]
21Feb12_190143| [-1.21490e-03  2.84203e-01]
21Feb12_190143| [ 6.44481e-02  9.35729e-01]
21Feb12_190143| [-3.89721e-01  4.44481e-01]
21Feb12_190143| [ 2.26160e-02  2.08558e+00]
21Feb12_190143| [ 1.52323e+00 -3.73645e-02]
21Feb12_190143| [ 9.95079e-01 -1.19442e+00]
21Feb12_190143| [ 2.32017e+00  2.47772e+00]
21Feb12_190143| [ 1.39694e+00  2.00685e+00]
21Feb12_190143| [ 1.60315e+00  2.62051e-01]
21Feb12_190143| [-1.99992e-01 -7.39963e-01]
21Feb12_190143| [ 6.47605e-01  7.20793e-02]
21Feb12_190143| [ 1.10277e+00  2.23991e-01]
21Feb12_190143| [-9.47393e-01 -1.66714e+00]
21Feb12_190143| [-2.57348e+00  2.41281e-01]
21Feb12_190143| [-4.87500e-01 -1.66269e+00]
21Feb12_190143| [ 2.64955e-01  1.70976e+00]
21Feb12_190143| [-6.83241e-01  8.97158e-02]
21Feb12_190143| [-6.78085e-02  7.86602e-01]
21Feb12_190143| [-5.49131e-01  5.31253e-02]
21Feb12_190143| [ 7.03601e-01 -1.02610e+00]
21Feb12_190143| [ 1.85455e+00  1.12002e+00]
21Feb12_190143| [ 3.52295e-01  3.10293e-01]
21Feb12_190143| [ 1.94962e-01  3.45131e-01]
21Feb12_190143| [ 1.70639e+00 -7.49769e-01]
21Feb12_190143| [-1.52947e+00 -9.79587e-02]
21Feb12_190143| [ 1.17446e+00 -1.52283e+00]
21Feb12_190143| [ 7.02147e-02  9.39315e-03]
21Feb12_190143| [-6.24043e-01 -3.22238e-01]
21Feb12_190143| [ 4.20892e-01 -6.45196e-01]
21Feb12_190143| [ 2.85730e-02 -5.92999e-01]
21Feb12_190143| [ 1.00154e+00 -6.72183e-01]
21Feb12_190143| [ 1.50337e+00  9.23464e-01]
21Feb12_190143| [ 7.19733e-01  5.94171e-01]
21Feb12_190143| [ 1.07145e+00  5.55464e-01]
21Feb12_190143| [-8.40764e-01  7.68126e-01]
21Feb12_190143| [ 1.23893e+00  9.22462e-01]
21Feb12_190143| [-9.13895e-02  9.23047e-01]
21Feb12_190143| [-3.22161e-01 -6.34520e-01]
21Feb12_190143| [ 1.51205e-01 -6.43524e-01]
21Feb12_190143| [-6.58346e-01  9.89111e-01]
21Feb12_190143| [-2.29255e+00 -7.15652e-01]
21Feb12_190143| [-8.19109e-01 -8.88308e-01]
21Feb12_190143| [ 5.36962e-01 -3.15096e+00]
21Feb12_190143| [-2.03141e+00  7.69575e-01]
21Feb12_190143| [ 2.14540e+00 -8.85673e-01]
21Feb12_190143| [-1.09594e+00 -8.25339e-01]
21Feb12_190143| [ 1.30855e-01 -1.79813e+00]
21Feb12_190143| [ 2.57514e+00  1.18195e+00]
21Feb12_190143| [ 1.79697e+00 -4.44049e-01]
21Feb12_190143| [-8.11073e-01 -9.58804e-02]
21Feb12_190143| [ 6.97402e-01 -3.52362e-01]
21Feb12_190143| [ 1.31588e+00 -1.06488e+00]
21Feb12_190143| [-1.13318e-01  8.95197e-01]]
21Feb12_190143|-- Bias --
21Feb12_190143|[-0.74250  0.42025]
21Feb12_190143|Layer 1:
21Feb12_190143|-- Config --
21Feb12_190143|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190143|-- Weights --
21Feb12_190143|[[ 0.13109 -0.79243  0.39897 -0.74131]
21Feb12_190143| [-0.93057 -0.81797 -0.74571  0.03946]]
21Feb12_190143|-- Bias --
21Feb12_190143|[ 0.52923  0.95311  0.78114 -0.93265]
21Feb12_190143|Layer 2:
21Feb12_190143|-- Config --
21Feb12_190143|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190143|-- Weights --
21Feb12_190143|[[ 0.84055  0.52233]
21Feb12_190143| [-1.37734 -0.30154]
21Feb12_190143| [ 0.54593 -0.67204]
21Feb12_190143| [-0.73794 -0.33974]]
21Feb12_190143|-- Bias --
21Feb12_190143|[0.06722 0.06699]
21Feb12_190143|Predicting the validation and test data with the Best final individual.
21Feb12_190151| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_190151|-----------  ------------------  --------------------  ----------
21Feb12_190151|Validation         42.00                  12            0.00000
21Feb12_190151|   Test            36.40                  12            0.00000
21Feb12_190151|-------------------- Test #7 --------------------
21Feb12_190151|Best final individual weights
21Feb12_190151|Individual:
21Feb12_190151|-- Constant hidden layers --
21Feb12_190151|False
21Feb12_190151|Layer 0:
21Feb12_190151|-- Config --
21Feb12_190151|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190151|-- Weights --
21Feb12_190151|[[ 8.10203e-01  1.99129e-01]
21Feb12_190151| [-6.84952e-02  9.83400e-01]
21Feb12_190151| [-5.01340e-01  1.00868e+00]
21Feb12_190151| [ 2.40662e-01 -1.64043e+00]
21Feb12_190151| [-1.21490e-03  2.84203e-01]
21Feb12_190151| [ 6.44481e-02  9.35729e-01]
21Feb12_190151| [-3.89721e-01  4.44481e-01]
21Feb12_190151| [ 2.26160e-02  2.08558e+00]
21Feb12_190151| [ 1.52323e+00 -3.73645e-02]
21Feb12_190151| [ 9.95079e-01 -1.19442e+00]
21Feb12_190151| [ 2.32017e+00  2.47772e+00]
21Feb12_190151| [ 1.39694e+00  2.00685e+00]
21Feb12_190151| [ 1.60315e+00  2.62051e-01]
21Feb12_190151| [-1.99992e-01 -7.39963e-01]
21Feb12_190151| [ 6.47605e-01  7.20793e-02]
21Feb12_190151| [ 1.10277e+00  2.23991e-01]
21Feb12_190151| [-9.47393e-01 -1.66714e+00]
21Feb12_190151| [-2.57348e+00  2.41281e-01]
21Feb12_190151| [-4.87500e-01 -1.66269e+00]
21Feb12_190151| [ 2.64955e-01  1.70976e+00]
21Feb12_190151| [-6.83241e-01  8.97158e-02]
21Feb12_190151| [-6.78085e-02  7.86602e-01]
21Feb12_190151| [-5.49131e-01  5.31253e-02]
21Feb12_190151| [ 7.03601e-01 -1.02610e+00]
21Feb12_190151| [ 1.85455e+00  1.12002e+00]
21Feb12_190151| [ 3.52295e-01  3.10293e-01]
21Feb12_190151| [ 1.94962e-01  3.45131e-01]
21Feb12_190151| [ 1.70639e+00 -7.49769e-01]
21Feb12_190151| [-1.52947e+00 -9.79587e-02]
21Feb12_190151| [ 1.17446e+00 -1.52283e+00]
21Feb12_190151| [ 7.02147e-02  9.39315e-03]
21Feb12_190151| [-6.24043e-01 -3.22238e-01]
21Feb12_190151| [ 4.20892e-01 -6.45196e-01]
21Feb12_190151| [ 2.85730e-02 -5.92999e-01]
21Feb12_190151| [ 1.00154e+00 -6.72183e-01]
21Feb12_190151| [ 1.50337e+00  9.23464e-01]
21Feb12_190151| [ 7.19733e-01  5.94171e-01]
21Feb12_190151| [ 1.07145e+00  5.55464e-01]
21Feb12_190151| [-8.40764e-01  7.68126e-01]
21Feb12_190151| [ 1.23893e+00  9.22462e-01]
21Feb12_190151| [-9.13895e-02  9.23047e-01]
21Feb12_190151| [-3.22161e-01 -6.34520e-01]
21Feb12_190151| [ 1.51205e-01 -6.43524e-01]
21Feb12_190151| [-6.58346e-01  9.89111e-01]
21Feb12_190151| [-2.29255e+00 -7.15652e-01]
21Feb12_190151| [-8.19109e-01 -8.88308e-01]
21Feb12_190151| [ 5.36962e-01 -3.15096e+00]
21Feb12_190151| [-2.03141e+00  7.69575e-01]
21Feb12_190151| [ 2.14540e+00 -8.85673e-01]
21Feb12_190151| [-1.09594e+00 -8.25339e-01]
21Feb12_190151| [ 1.30855e-01 -1.79813e+00]
21Feb12_190151| [ 2.57514e+00  1.18195e+00]
21Feb12_190151| [ 1.79697e+00 -4.44049e-01]
21Feb12_190151| [-8.11073e-01 -9.58804e-02]
21Feb12_190151| [ 6.97402e-01 -3.52362e-01]
21Feb12_190151| [ 1.31588e+00 -1.06488e+00]
21Feb12_190151| [-1.13318e-01  8.95197e-01]]
21Feb12_190151|-- Bias --
21Feb12_190151|[-0.74250  0.42025]
21Feb12_190151|Layer 1:
21Feb12_190151|-- Config --
21Feb12_190151|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190151|-- Weights --
21Feb12_190151|[[ 0.13109 -0.79243  0.39897 -0.74131]
21Feb12_190151| [-0.93057 -0.81797 -0.74571  0.03946]]
21Feb12_190151|-- Bias --
21Feb12_190151|[ 0.52923  0.95311  0.78114 -0.93265]
21Feb12_190151|Layer 2:
21Feb12_190151|-- Config --
21Feb12_190151|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190151|-- Weights --
21Feb12_190151|[[ 0.84055  0.52233]
21Feb12_190151| [-1.37734 -0.30154]
21Feb12_190151| [ 0.54593 -0.67204]
21Feb12_190151| [-0.73794 -0.33974]]
21Feb12_190151|-- Bias --
21Feb12_190151|[0.06722 0.06699]
21Feb12_190151|Predicting the validation and test data with the Best final individual.
21Feb12_190158| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_190158|-----------  ------------------  --------------------  ----------
21Feb12_190158|Validation         42.00                  12            0.00000
21Feb12_190158|   Test            36.40                  12            0.00000
21Feb12_190158|-------------------- Test #8 --------------------
21Feb12_190158|Best final individual weights
21Feb12_190158|Individual:
21Feb12_190158|-- Constant hidden layers --
21Feb12_190158|False
21Feb12_190158|Layer 0:
21Feb12_190158|-- Config --
21Feb12_190158|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190158|-- Weights --
21Feb12_190158|[[ 8.10203e-01  1.99129e-01]
21Feb12_190158| [-6.84952e-02  9.83400e-01]
21Feb12_190158| [-5.01340e-01  1.00868e+00]
21Feb12_190158| [ 2.40662e-01 -1.64043e+00]
21Feb12_190158| [-1.21490e-03  2.84203e-01]
21Feb12_190158| [ 6.44481e-02  9.35729e-01]
21Feb12_190158| [-3.89721e-01  4.44481e-01]
21Feb12_190158| [ 2.26160e-02  2.08558e+00]
21Feb12_190158| [ 1.52323e+00 -3.73645e-02]
21Feb12_190158| [ 9.95079e-01 -1.19442e+00]
21Feb12_190158| [ 2.32017e+00  2.47772e+00]
21Feb12_190158| [ 1.39694e+00  2.00685e+00]
21Feb12_190158| [ 1.60315e+00  2.62051e-01]
21Feb12_190158| [-1.99992e-01 -7.39963e-01]
21Feb12_190158| [ 6.47605e-01  7.20793e-02]
21Feb12_190158| [ 1.10277e+00  2.23991e-01]
21Feb12_190158| [-9.47393e-01 -1.66714e+00]
21Feb12_190158| [-2.57348e+00  2.41281e-01]
21Feb12_190158| [-4.87500e-01 -1.66269e+00]
21Feb12_190158| [ 2.64955e-01  1.70976e+00]
21Feb12_190158| [-6.83241e-01  8.97158e-02]
21Feb12_190158| [-6.78085e-02  7.86602e-01]
21Feb12_190158| [-5.49131e-01  5.31253e-02]
21Feb12_190158| [ 7.03601e-01 -1.02610e+00]
21Feb12_190158| [ 1.85455e+00  1.12002e+00]
21Feb12_190158| [ 3.52295e-01  3.10293e-01]
21Feb12_190158| [ 1.94962e-01  3.45131e-01]
21Feb12_190158| [ 1.70639e+00 -7.49769e-01]
21Feb12_190158| [-1.52947e+00 -9.79587e-02]
21Feb12_190158| [ 1.17446e+00 -1.52283e+00]
21Feb12_190158| [ 7.02147e-02  9.39315e-03]
21Feb12_190158| [-6.24043e-01 -3.22238e-01]
21Feb12_190158| [ 4.20892e-01 -6.45196e-01]
21Feb12_190158| [ 2.85730e-02 -5.92999e-01]
21Feb12_190158| [ 1.00154e+00 -6.72183e-01]
21Feb12_190158| [ 1.50337e+00  9.23464e-01]
21Feb12_190158| [ 7.19733e-01  5.94171e-01]
21Feb12_190158| [ 1.07145e+00  5.55464e-01]
21Feb12_190158| [-8.40764e-01  7.68126e-01]
21Feb12_190158| [ 1.23893e+00  9.22462e-01]
21Feb12_190158| [-9.13895e-02  9.23047e-01]
21Feb12_190158| [-3.22161e-01 -6.34520e-01]
21Feb12_190158| [ 1.51205e-01 -6.43524e-01]
21Feb12_190158| [-6.58346e-01  9.89111e-01]
21Feb12_190158| [-2.29255e+00 -7.15652e-01]
21Feb12_190158| [-8.19109e-01 -8.88308e-01]
21Feb12_190158| [ 5.36962e-01 -3.15096e+00]
21Feb12_190158| [-2.03141e+00  7.69575e-01]
21Feb12_190158| [ 2.14540e+00 -8.85673e-01]
21Feb12_190158| [-1.09594e+00 -8.25339e-01]
21Feb12_190158| [ 1.30855e-01 -1.79813e+00]
21Feb12_190158| [ 2.57514e+00  1.18195e+00]
21Feb12_190158| [ 1.79697e+00 -4.44049e-01]
21Feb12_190158| [-8.11073e-01 -9.58804e-02]
21Feb12_190158| [ 6.97402e-01 -3.52362e-01]
21Feb12_190158| [ 1.31588e+00 -1.06488e+00]
21Feb12_190158| [-1.13318e-01  8.95197e-01]]
21Feb12_190158|-- Bias --
21Feb12_190158|[-0.74250  0.42025]
21Feb12_190158|Layer 1:
21Feb12_190158|-- Config --
21Feb12_190158|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190158|-- Weights --
21Feb12_190158|[[ 0.13109 -0.79243  0.39897 -0.74131]
21Feb12_190158| [-0.93057 -0.81797 -0.74571  0.03946]]
21Feb12_190158|-- Bias --
21Feb12_190158|[ 0.52923  0.95311  0.78114 -0.93265]
21Feb12_190158|Layer 2:
21Feb12_190158|-- Config --
21Feb12_190158|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190158|-- Weights --
21Feb12_190158|[[ 0.84055  0.52233]
21Feb12_190158| [-1.37734 -0.30154]
21Feb12_190158| [ 0.54593 -0.67204]
21Feb12_190158| [-0.73794 -0.33974]]
21Feb12_190158|-- Bias --
21Feb12_190158|[0.06722 0.06699]
21Feb12_190158|Predicting the validation and test data with the Best final individual.
21Feb12_190205| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_190205|-----------  ------------------  --------------------  ----------
21Feb12_190205|Validation         42.00                  12            0.00000
21Feb12_190205|   Test            36.40                  12            0.00000
21Feb12_190205|-------------------- Test #9 --------------------
21Feb12_190205|Best final individual weights
21Feb12_190205|Individual:
21Feb12_190205|-- Constant hidden layers --
21Feb12_190205|False
21Feb12_190205|Layer 0:
21Feb12_190205|-- Config --
21Feb12_190205|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190205|-- Weights --
21Feb12_190205|[[ 8.10203e-01  1.99129e-01]
21Feb12_190205| [-6.84952e-02  9.83400e-01]
21Feb12_190205| [-5.01340e-01  1.00868e+00]
21Feb12_190205| [ 2.40662e-01 -1.64043e+00]
21Feb12_190205| [-1.21490e-03  2.84203e-01]
21Feb12_190205| [ 6.44481e-02  9.35729e-01]
21Feb12_190205| [-3.89721e-01  4.44481e-01]
21Feb12_190205| [ 2.26160e-02  2.08558e+00]
21Feb12_190205| [ 1.52323e+00 -3.73645e-02]
21Feb12_190205| [ 9.95079e-01 -1.19442e+00]
21Feb12_190205| [ 2.32017e+00  2.47772e+00]
21Feb12_190205| [ 1.39694e+00  2.00685e+00]
21Feb12_190205| [ 1.60315e+00  2.62051e-01]
21Feb12_190205| [-1.99992e-01 -7.39963e-01]
21Feb12_190205| [ 6.47605e-01  7.20793e-02]
21Feb12_190205| [ 1.10277e+00  2.23991e-01]
21Feb12_190205| [-9.47393e-01 -1.66714e+00]
21Feb12_190205| [-2.57348e+00  2.41281e-01]
21Feb12_190205| [-4.87500e-01 -1.66269e+00]
21Feb12_190205| [ 2.64955e-01  1.70976e+00]
21Feb12_190205| [-6.83241e-01  8.97158e-02]
21Feb12_190205| [-6.78085e-02  7.86602e-01]
21Feb12_190205| [-5.49131e-01  5.31253e-02]
21Feb12_190205| [ 7.03601e-01 -1.02610e+00]
21Feb12_190205| [ 1.85455e+00  1.12002e+00]
21Feb12_190205| [ 3.52295e-01  3.10293e-01]
21Feb12_190205| [ 1.94962e-01  3.45131e-01]
21Feb12_190205| [ 1.70639e+00 -7.49769e-01]
21Feb12_190205| [-1.52947e+00 -9.79587e-02]
21Feb12_190205| [ 1.17446e+00 -1.52283e+00]
21Feb12_190205| [ 7.02147e-02  9.39315e-03]
21Feb12_190205| [-6.24043e-01 -3.22238e-01]
21Feb12_190205| [ 4.20892e-01 -6.45196e-01]
21Feb12_190205| [ 2.85730e-02 -5.92999e-01]
21Feb12_190205| [ 1.00154e+00 -6.72183e-01]
21Feb12_190205| [ 1.50337e+00  9.23464e-01]
21Feb12_190205| [ 7.19733e-01  5.94171e-01]
21Feb12_190205| [ 1.07145e+00  5.55464e-01]
21Feb12_190205| [-8.40764e-01  7.68126e-01]
21Feb12_190205| [ 1.23893e+00  9.22462e-01]
21Feb12_190205| [-9.13895e-02  9.23047e-01]
21Feb12_190205| [-3.22161e-01 -6.34520e-01]
21Feb12_190205| [ 1.51205e-01 -6.43524e-01]
21Feb12_190205| [-6.58346e-01  9.89111e-01]
21Feb12_190205| [-2.29255e+00 -7.15652e-01]
21Feb12_190205| [-8.19109e-01 -8.88308e-01]
21Feb12_190205| [ 5.36962e-01 -3.15096e+00]
21Feb12_190205| [-2.03141e+00  7.69575e-01]
21Feb12_190205| [ 2.14540e+00 -8.85673e-01]
21Feb12_190205| [-1.09594e+00 -8.25339e-01]
21Feb12_190205| [ 1.30855e-01 -1.79813e+00]
21Feb12_190205| [ 2.57514e+00  1.18195e+00]
21Feb12_190205| [ 1.79697e+00 -4.44049e-01]
21Feb12_190205| [-8.11073e-01 -9.58804e-02]
21Feb12_190205| [ 6.97402e-01 -3.52362e-01]
21Feb12_190205| [ 1.31588e+00 -1.06488e+00]
21Feb12_190205| [-1.13318e-01  8.95197e-01]]
21Feb12_190205|-- Bias --
21Feb12_190205|[-0.74250  0.42025]
21Feb12_190205|Layer 1:
21Feb12_190205|-- Config --
21Feb12_190205|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190205|-- Weights --
21Feb12_190205|[[ 0.13109 -0.79243  0.39897 -0.74131]
21Feb12_190205| [-0.93057 -0.81797 -0.74571  0.03946]]
21Feb12_190205|-- Bias --
21Feb12_190205|[ 0.52923  0.95311  0.78114 -0.93265]
21Feb12_190205|Layer 2:
21Feb12_190205|-- Config --
21Feb12_190205|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190205|-- Weights --
21Feb12_190205|[[ 0.84055  0.52233]
21Feb12_190205| [-1.37734 -0.30154]
21Feb12_190205| [ 0.54593 -0.67204]
21Feb12_190205| [-0.73794 -0.33974]]
21Feb12_190205|-- Bias --
21Feb12_190205|[0.06722 0.06699]
21Feb12_190205|Predicting the validation and test data with the Best final individual.
21Feb12_190213| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_190213|-----------  ------------------  --------------------  ----------
21Feb12_190213|Validation         42.00                  12            0.00000
21Feb12_190213|   Test            30.58                  12            0.65904
21Feb12_190213|-------------------- Test #10 --------------------
21Feb12_190213|Best final individual weights
21Feb12_190213|Individual:
21Feb12_190213|-- Constant hidden layers --
21Feb12_190213|False
21Feb12_190213|Layer 0:
21Feb12_190213|-- Config --
21Feb12_190213|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190213|-- Weights --
21Feb12_190213|[[ 8.10203e-01  1.99129e-01]
21Feb12_190213| [-6.84952e-02  9.83400e-01]
21Feb12_190213| [-5.01340e-01  1.00868e+00]
21Feb12_190213| [ 2.40662e-01 -1.64043e+00]
21Feb12_190213| [-1.21490e-03  2.84203e-01]
21Feb12_190213| [ 6.44481e-02  9.35729e-01]
21Feb12_190213| [-3.89721e-01  4.44481e-01]
21Feb12_190213| [ 2.26160e-02  2.08558e+00]
21Feb12_190213| [ 1.52323e+00 -3.73645e-02]
21Feb12_190213| [ 9.95079e-01 -1.19442e+00]
21Feb12_190213| [ 2.32017e+00  2.47772e+00]
21Feb12_190213| [ 1.39694e+00  2.00685e+00]
21Feb12_190213| [ 1.60315e+00  2.62051e-01]
21Feb12_190213| [-1.99992e-01 -7.39963e-01]
21Feb12_190213| [ 6.47605e-01  7.20793e-02]
21Feb12_190213| [ 1.10277e+00  2.23991e-01]
21Feb12_190213| [-9.47393e-01 -1.66714e+00]
21Feb12_190213| [-2.57348e+00  2.41281e-01]
21Feb12_190213| [-4.87500e-01 -1.66269e+00]
21Feb12_190213| [ 2.64955e-01  1.70976e+00]
21Feb12_190213| [-6.83241e-01  8.97158e-02]
21Feb12_190213| [-6.78085e-02  7.86602e-01]
21Feb12_190213| [-5.49131e-01  5.31253e-02]
21Feb12_190213| [ 7.03601e-01 -1.02610e+00]
21Feb12_190213| [ 1.85455e+00  1.12002e+00]
21Feb12_190213| [ 3.52295e-01  3.10293e-01]
21Feb12_190213| [ 1.94962e-01  3.45131e-01]
21Feb12_190213| [ 1.70639e+00 -7.49769e-01]
21Feb12_190213| [-1.52947e+00 -9.79587e-02]
21Feb12_190213| [ 1.17446e+00 -1.52283e+00]
21Feb12_190213| [ 7.02147e-02  9.39315e-03]
21Feb12_190213| [-6.24043e-01 -3.22238e-01]
21Feb12_190213| [ 4.20892e-01 -6.45196e-01]
21Feb12_190213| [ 2.85730e-02 -5.92999e-01]
21Feb12_190213| [ 1.00154e+00 -6.72183e-01]
21Feb12_190213| [ 1.50337e+00  9.23464e-01]
21Feb12_190213| [ 7.19733e-01  5.94171e-01]
21Feb12_190213| [ 1.07145e+00  5.55464e-01]
21Feb12_190213| [-8.40764e-01  7.68126e-01]
21Feb12_190213| [ 1.23893e+00  9.22462e-01]
21Feb12_190213| [-9.13895e-02  9.23047e-01]
21Feb12_190213| [-3.22161e-01 -6.34520e-01]
21Feb12_190213| [ 1.51205e-01 -6.43524e-01]
21Feb12_190213| [-6.58346e-01  9.89111e-01]
21Feb12_190213| [-2.29255e+00 -7.15652e-01]
21Feb12_190213| [-8.19109e-01 -8.88308e-01]
21Feb12_190213| [ 5.36962e-01 -3.15096e+00]
21Feb12_190213| [-2.03141e+00  7.69575e-01]
21Feb12_190213| [ 2.14540e+00 -8.85673e-01]
21Feb12_190213| [-1.09594e+00 -8.25339e-01]
21Feb12_190213| [ 1.30855e-01 -1.79813e+00]
21Feb12_190213| [ 2.57514e+00  1.18195e+00]
21Feb12_190213| [ 1.79697e+00 -4.44049e-01]
21Feb12_190213| [-8.11073e-01 -9.58804e-02]
21Feb12_190213| [ 6.97402e-01 -3.52362e-01]
21Feb12_190213| [ 1.31588e+00 -1.06488e+00]
21Feb12_190213| [-1.13318e-01  8.95197e-01]]
21Feb12_190213|-- Bias --
21Feb12_190213|[-0.74250  0.42025]
21Feb12_190213|Layer 1:
21Feb12_190213|-- Config --
21Feb12_190213|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190213|-- Weights --
21Feb12_190213|[[ 0.13109 -0.79243  0.39897 -0.74131]
21Feb12_190213| [-0.93057 -0.81797 -0.74571  0.03946]]
21Feb12_190213|-- Bias --
21Feb12_190213|[ 0.52923  0.95311  0.78114 -0.93265]
21Feb12_190213|Layer 2:
21Feb12_190213|-- Config --
21Feb12_190213|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190213|-- Weights --
21Feb12_190213|[[ 0.84055  0.52233]
21Feb12_190213| [-1.37734 -0.30154]
21Feb12_190213| [ 0.54593 -0.67204]
21Feb12_190213| [-0.73794 -0.33974]]
21Feb12_190213|-- Bias --
21Feb12_190213|[0.06722 0.06699]
21Feb12_190213|Predicting the validation and test data with the Best final individual.
21Feb12_190220| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_190220|-----------  ------------------  --------------------  ----------
21Feb12_190220|Validation         42.00                  12            0.00000
21Feb12_190220|   Test            36.40                  12            0.00000
21Feb12_190220|-------------------- Test #11 --------------------
21Feb12_190220|Best final individual weights
21Feb12_190220|Individual:
21Feb12_190220|-- Constant hidden layers --
21Feb12_190220|False
21Feb12_190220|Layer 0:
21Feb12_190220|-- Config --
21Feb12_190220|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190220|-- Weights --
21Feb12_190220|[[ 8.10203e-01  1.99129e-01]
21Feb12_190220| [-6.84952e-02  9.83400e-01]
21Feb12_190220| [-5.01340e-01  1.00868e+00]
21Feb12_190220| [ 2.40662e-01 -1.64043e+00]
21Feb12_190220| [-1.21490e-03  2.84203e-01]
21Feb12_190220| [ 6.44481e-02  9.35729e-01]
21Feb12_190220| [-3.89721e-01  4.44481e-01]
21Feb12_190220| [ 2.26160e-02  2.08558e+00]
21Feb12_190220| [ 1.52323e+00 -3.73645e-02]
21Feb12_190220| [ 9.95079e-01 -1.19442e+00]
21Feb12_190220| [ 2.32017e+00  2.47772e+00]
21Feb12_190220| [ 1.39694e+00  2.00685e+00]
21Feb12_190220| [ 1.60315e+00  2.62051e-01]
21Feb12_190220| [-1.99992e-01 -7.39963e-01]
21Feb12_190220| [ 6.47605e-01  7.20793e-02]
21Feb12_190220| [ 1.10277e+00  2.23991e-01]
21Feb12_190220| [-9.47393e-01 -1.66714e+00]
21Feb12_190220| [-2.57348e+00  2.41281e-01]
21Feb12_190220| [-4.87500e-01 -1.66269e+00]
21Feb12_190220| [ 2.64955e-01  1.70976e+00]
21Feb12_190220| [-6.83241e-01  8.97158e-02]
21Feb12_190220| [-6.78085e-02  7.86602e-01]
21Feb12_190220| [-5.49131e-01  5.31253e-02]
21Feb12_190220| [ 7.03601e-01 -1.02610e+00]
21Feb12_190220| [ 1.85455e+00  1.12002e+00]
21Feb12_190220| [ 3.52295e-01  3.10293e-01]
21Feb12_190220| [ 1.94962e-01  3.45131e-01]
21Feb12_190220| [ 1.70639e+00 -7.49769e-01]
21Feb12_190220| [-1.52947e+00 -9.79587e-02]
21Feb12_190220| [ 1.17446e+00 -1.52283e+00]
21Feb12_190220| [ 7.02147e-02  9.39315e-03]
21Feb12_190220| [-6.24043e-01 -3.22238e-01]
21Feb12_190220| [ 4.20892e-01 -6.45196e-01]
21Feb12_190220| [ 2.85730e-02 -5.92999e-01]
21Feb12_190220| [ 1.00154e+00 -6.72183e-01]
21Feb12_190220| [ 1.50337e+00  9.23464e-01]
21Feb12_190220| [ 7.19733e-01  5.94171e-01]
21Feb12_190220| [ 1.07145e+00  5.55464e-01]
21Feb12_190220| [-8.40764e-01  7.68126e-01]
21Feb12_190220| [ 1.23893e+00  9.22462e-01]
21Feb12_190220| [-9.13895e-02  9.23047e-01]
21Feb12_190220| [-3.22161e-01 -6.34520e-01]
21Feb12_190220| [ 1.51205e-01 -6.43524e-01]
21Feb12_190220| [-6.58346e-01  9.89111e-01]
21Feb12_190220| [-2.29255e+00 -7.15652e-01]
21Feb12_190220| [-8.19109e-01 -8.88308e-01]
21Feb12_190220| [ 5.36962e-01 -3.15096e+00]
21Feb12_190220| [-2.03141e+00  7.69575e-01]
21Feb12_190220| [ 2.14540e+00 -8.85673e-01]
21Feb12_190220| [-1.09594e+00 -8.25339e-01]
21Feb12_190220| [ 1.30855e-01 -1.79813e+00]
21Feb12_190220| [ 2.57514e+00  1.18195e+00]
21Feb12_190220| [ 1.79697e+00 -4.44049e-01]
21Feb12_190220| [-8.11073e-01 -9.58804e-02]
21Feb12_190220| [ 6.97402e-01 -3.52362e-01]
21Feb12_190220| [ 1.31588e+00 -1.06488e+00]
21Feb12_190220| [-1.13318e-01  8.95197e-01]]
21Feb12_190220|-- Bias --
21Feb12_190220|[-0.74250  0.42025]
21Feb12_190220|Layer 1:
21Feb12_190220|-- Config --
21Feb12_190220|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190220|-- Weights --
21Feb12_190220|[[ 0.13109 -0.79243  0.39897 -0.74131]
21Feb12_190220| [-0.93057 -0.81797 -0.74571  0.03946]]
21Feb12_190220|-- Bias --
21Feb12_190220|[ 0.52923  0.95311  0.78114 -0.93265]
21Feb12_190220|Layer 2:
21Feb12_190220|-- Config --
21Feb12_190220|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190220|-- Weights --
21Feb12_190220|[[ 0.84055  0.52233]
21Feb12_190220| [-1.37734 -0.30154]
21Feb12_190220| [ 0.54593 -0.67204]
21Feb12_190220| [-0.73794 -0.33974]]
21Feb12_190220|-- Bias --
21Feb12_190220|[0.06722 0.06699]
21Feb12_190220|Predicting the validation and test data with the Best final individual.
21Feb12_190228| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_190228|-----------  ------------------  --------------------  ----------
21Feb12_190228|Validation         42.00                  12            0.00000
21Feb12_190228|   Test            36.40                  12            0.00000
21Feb12_190228|-------------------- Test #12 --------------------
21Feb12_190228|Best final individual weights
21Feb12_190228|Individual:
21Feb12_190228|-- Constant hidden layers --
21Feb12_190228|False
21Feb12_190228|Layer 0:
21Feb12_190228|-- Config --
21Feb12_190228|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190228|-- Weights --
21Feb12_190228|[[ 8.10203e-01  1.99129e-01]
21Feb12_190228| [-6.84952e-02  9.83400e-01]
21Feb12_190228| [-5.01340e-01  1.00868e+00]
21Feb12_190228| [ 2.40662e-01 -1.64043e+00]
21Feb12_190228| [-1.21490e-03  2.84203e-01]
21Feb12_190228| [ 6.44481e-02  9.35729e-01]
21Feb12_190228| [-3.89721e-01  4.44481e-01]
21Feb12_190228| [ 2.26160e-02  2.08558e+00]
21Feb12_190228| [ 1.52323e+00 -3.73645e-02]
21Feb12_190228| [ 9.95079e-01 -1.19442e+00]
21Feb12_190228| [ 2.32017e+00  2.47772e+00]
21Feb12_190228| [ 1.39694e+00  2.00685e+00]
21Feb12_190228| [ 1.60315e+00  2.62051e-01]
21Feb12_190228| [-1.99992e-01 -7.39963e-01]
21Feb12_190228| [ 6.47605e-01  7.20793e-02]
21Feb12_190228| [ 1.10277e+00  2.23991e-01]
21Feb12_190228| [-9.47393e-01 -1.66714e+00]
21Feb12_190228| [-2.57348e+00  2.41281e-01]
21Feb12_190228| [-4.87500e-01 -1.66269e+00]
21Feb12_190228| [ 2.64955e-01  1.70976e+00]
21Feb12_190228| [-6.83241e-01  8.97158e-02]
21Feb12_190228| [-6.78085e-02  7.86602e-01]
21Feb12_190228| [-5.49131e-01  5.31253e-02]
21Feb12_190228| [ 7.03601e-01 -1.02610e+00]
21Feb12_190228| [ 1.85455e+00  1.12002e+00]
21Feb12_190228| [ 3.52295e-01  3.10293e-01]
21Feb12_190228| [ 1.94962e-01  3.45131e-01]
21Feb12_190228| [ 1.70639e+00 -7.49769e-01]
21Feb12_190228| [-1.52947e+00 -9.79587e-02]
21Feb12_190228| [ 1.17446e+00 -1.52283e+00]
21Feb12_190228| [ 7.02147e-02  9.39315e-03]
21Feb12_190228| [-6.24043e-01 -3.22238e-01]
21Feb12_190228| [ 4.20892e-01 -6.45196e-01]
21Feb12_190228| [ 2.85730e-02 -5.92999e-01]
21Feb12_190228| [ 1.00154e+00 -6.72183e-01]
21Feb12_190228| [ 1.50337e+00  9.23464e-01]
21Feb12_190228| [ 7.19733e-01  5.94171e-01]
21Feb12_190228| [ 1.07145e+00  5.55464e-01]
21Feb12_190228| [-8.40764e-01  7.68126e-01]
21Feb12_190228| [ 1.23893e+00  9.22462e-01]
21Feb12_190228| [-9.13895e-02  9.23047e-01]
21Feb12_190228| [-3.22161e-01 -6.34520e-01]
21Feb12_190228| [ 1.51205e-01 -6.43524e-01]
21Feb12_190228| [-6.58346e-01  9.89111e-01]
21Feb12_190228| [-2.29255e+00 -7.15652e-01]
21Feb12_190228| [-8.19109e-01 -8.88308e-01]
21Feb12_190228| [ 5.36962e-01 -3.15096e+00]
21Feb12_190228| [-2.03141e+00  7.69575e-01]
21Feb12_190228| [ 2.14540e+00 -8.85673e-01]
21Feb12_190228| [-1.09594e+00 -8.25339e-01]
21Feb12_190228| [ 1.30855e-01 -1.79813e+00]
21Feb12_190228| [ 2.57514e+00  1.18195e+00]
21Feb12_190228| [ 1.79697e+00 -4.44049e-01]
21Feb12_190228| [-8.11073e-01 -9.58804e-02]
21Feb12_190228| [ 6.97402e-01 -3.52362e-01]
21Feb12_190228| [ 1.31588e+00 -1.06488e+00]
21Feb12_190228| [-1.13318e-01  8.95197e-01]]
21Feb12_190228|-- Bias --
21Feb12_190228|[-0.74250  0.42025]
21Feb12_190228|Layer 1:
21Feb12_190228|-- Config --
21Feb12_190228|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190228|-- Weights --
21Feb12_190228|[[ 0.13109 -0.79243  0.39897 -0.74131]
21Feb12_190228| [-0.93057 -0.81797 -0.74571  0.03946]]
21Feb12_190228|-- Bias --
21Feb12_190228|[ 0.52923  0.95311  0.78114 -0.93265]
21Feb12_190228|Layer 2:
21Feb12_190228|-- Config --
21Feb12_190228|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190228|-- Weights --
21Feb12_190228|[[ 0.84055  0.52233]
21Feb12_190228| [-1.37734 -0.30154]
21Feb12_190228| [ 0.54593 -0.67204]
21Feb12_190228| [-0.73794 -0.33974]]
21Feb12_190228|-- Bias --
21Feb12_190228|[0.06722 0.06699]
21Feb12_190228|Predicting the validation and test data with the Best final individual.
21Feb12_190236| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_190236|-----------  ------------------  --------------------  ----------
21Feb12_190236|Validation         42.00                  12            0.00000
21Feb12_190236|   Test            36.40                  12            0.00000
21Feb12_190236|-------------------- Test #13 --------------------
21Feb12_190236|Best final individual weights
21Feb12_190236|Individual:
21Feb12_190236|-- Constant hidden layers --
21Feb12_190236|False
21Feb12_190236|Layer 0:
21Feb12_190236|-- Config --
21Feb12_190236|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190236|-- Weights --
21Feb12_190236|[[ 8.10203e-01  1.99129e-01]
21Feb12_190236| [-6.84952e-02  9.83400e-01]
21Feb12_190236| [-5.01340e-01  1.00868e+00]
21Feb12_190236| [ 2.40662e-01 -1.64043e+00]
21Feb12_190236| [-1.21490e-03  2.84203e-01]
21Feb12_190236| [ 6.44481e-02  9.35729e-01]
21Feb12_190236| [-3.89721e-01  4.44481e-01]
21Feb12_190236| [ 2.26160e-02  2.08558e+00]
21Feb12_190236| [ 1.52323e+00 -3.73645e-02]
21Feb12_190236| [ 9.95079e-01 -1.19442e+00]
21Feb12_190236| [ 2.32017e+00  2.47772e+00]
21Feb12_190236| [ 1.39694e+00  2.00685e+00]
21Feb12_190236| [ 1.60315e+00  2.62051e-01]
21Feb12_190236| [-1.99992e-01 -7.39963e-01]
21Feb12_190236| [ 6.47605e-01  7.20793e-02]
21Feb12_190236| [ 1.10277e+00  2.23991e-01]
21Feb12_190236| [-9.47393e-01 -1.66714e+00]
21Feb12_190236| [-2.57348e+00  2.41281e-01]
21Feb12_190236| [-4.87500e-01 -1.66269e+00]
21Feb12_190236| [ 2.64955e-01  1.70976e+00]
21Feb12_190236| [-6.83241e-01  8.97158e-02]
21Feb12_190236| [-6.78085e-02  7.86602e-01]
21Feb12_190236| [-5.49131e-01  5.31253e-02]
21Feb12_190236| [ 7.03601e-01 -1.02610e+00]
21Feb12_190236| [ 1.85455e+00  1.12002e+00]
21Feb12_190236| [ 3.52295e-01  3.10293e-01]
21Feb12_190236| [ 1.94962e-01  3.45131e-01]
21Feb12_190236| [ 1.70639e+00 -7.49769e-01]
21Feb12_190236| [-1.52947e+00 -9.79587e-02]
21Feb12_190236| [ 1.17446e+00 -1.52283e+00]
21Feb12_190236| [ 7.02147e-02  9.39315e-03]
21Feb12_190236| [-6.24043e-01 -3.22238e-01]
21Feb12_190236| [ 4.20892e-01 -6.45196e-01]
21Feb12_190236| [ 2.85730e-02 -5.92999e-01]
21Feb12_190236| [ 1.00154e+00 -6.72183e-01]
21Feb12_190236| [ 1.50337e+00  9.23464e-01]
21Feb12_190236| [ 7.19733e-01  5.94171e-01]
21Feb12_190236| [ 1.07145e+00  5.55464e-01]
21Feb12_190236| [-8.40764e-01  7.68126e-01]
21Feb12_190236| [ 1.23893e+00  9.22462e-01]
21Feb12_190236| [-9.13895e-02  9.23047e-01]
21Feb12_190236| [-3.22161e-01 -6.34520e-01]
21Feb12_190236| [ 1.51205e-01 -6.43524e-01]
21Feb12_190236| [-6.58346e-01  9.89111e-01]
21Feb12_190236| [-2.29255e+00 -7.15652e-01]
21Feb12_190236| [-8.19109e-01 -8.88308e-01]
21Feb12_190236| [ 5.36962e-01 -3.15096e+00]
21Feb12_190236| [-2.03141e+00  7.69575e-01]
21Feb12_190236| [ 2.14540e+00 -8.85673e-01]
21Feb12_190236| [-1.09594e+00 -8.25339e-01]
21Feb12_190236| [ 1.30855e-01 -1.79813e+00]
21Feb12_190236| [ 2.57514e+00  1.18195e+00]
21Feb12_190236| [ 1.79697e+00 -4.44049e-01]
21Feb12_190236| [-8.11073e-01 -9.58804e-02]
21Feb12_190236| [ 6.97402e-01 -3.52362e-01]
21Feb12_190236| [ 1.31588e+00 -1.06488e+00]
21Feb12_190236| [-1.13318e-01  8.95197e-01]]
21Feb12_190236|-- Bias --
21Feb12_190236|[-0.74250  0.42025]
21Feb12_190236|Layer 1:
21Feb12_190236|-- Config --
21Feb12_190236|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190236|-- Weights --
21Feb12_190236|[[ 0.13109 -0.79243  0.39897 -0.74131]
21Feb12_190236| [-0.93057 -0.81797 -0.74571  0.03946]]
21Feb12_190236|-- Bias --
21Feb12_190236|[ 0.52923  0.95311  0.78114 -0.93265]
21Feb12_190236|Layer 2:
21Feb12_190236|-- Config --
21Feb12_190236|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190236|-- Weights --
21Feb12_190236|[[ 0.84055  0.52233]
21Feb12_190236| [-1.37734 -0.30154]
21Feb12_190236| [ 0.54593 -0.67204]
21Feb12_190236| [-0.73794 -0.33974]]
21Feb12_190236|-- Bias --
21Feb12_190236|[0.06722 0.06699]
21Feb12_190236|Predicting the validation and test data with the Best final individual.
21Feb12_190243| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_190243|-----------  ------------------  --------------------  ----------
21Feb12_190243|Validation         42.00                  12            0.00000
21Feb12_190243|   Test            36.40                  12            0.00000
21Feb12_190243|-------------------- Test #14 --------------------
21Feb12_190243|Best final individual weights
21Feb12_190243|Individual:
21Feb12_190243|-- Constant hidden layers --
21Feb12_190243|False
21Feb12_190243|Layer 0:
21Feb12_190243|-- Config --
21Feb12_190243|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190243|-- Weights --
21Feb12_190243|[[ 8.10203e-01  1.99129e-01]
21Feb12_190243| [-6.84952e-02  9.83400e-01]
21Feb12_190243| [-5.01340e-01  1.00868e+00]
21Feb12_190243| [ 2.40662e-01 -1.64043e+00]
21Feb12_190243| [-1.21490e-03  2.84203e-01]
21Feb12_190243| [ 6.44481e-02  9.35729e-01]
21Feb12_190243| [-3.89721e-01  4.44481e-01]
21Feb12_190243| [ 2.26160e-02  2.08558e+00]
21Feb12_190243| [ 1.52323e+00 -3.73645e-02]
21Feb12_190243| [ 9.95079e-01 -1.19442e+00]
21Feb12_190243| [ 2.32017e+00  2.47772e+00]
21Feb12_190243| [ 1.39694e+00  2.00685e+00]
21Feb12_190243| [ 1.60315e+00  2.62051e-01]
21Feb12_190243| [-1.99992e-01 -7.39963e-01]
21Feb12_190243| [ 6.47605e-01  7.20793e-02]
21Feb12_190243| [ 1.10277e+00  2.23991e-01]
21Feb12_190243| [-9.47393e-01 -1.66714e+00]
21Feb12_190243| [-2.57348e+00  2.41281e-01]
21Feb12_190243| [-4.87500e-01 -1.66269e+00]
21Feb12_190243| [ 2.64955e-01  1.70976e+00]
21Feb12_190243| [-6.83241e-01  8.97158e-02]
21Feb12_190243| [-6.78085e-02  7.86602e-01]
21Feb12_190243| [-5.49131e-01  5.31253e-02]
21Feb12_190243| [ 7.03601e-01 -1.02610e+00]
21Feb12_190243| [ 1.85455e+00  1.12002e+00]
21Feb12_190243| [ 3.52295e-01  3.10293e-01]
21Feb12_190243| [ 1.94962e-01  3.45131e-01]
21Feb12_190243| [ 1.70639e+00 -7.49769e-01]
21Feb12_190243| [-1.52947e+00 -9.79587e-02]
21Feb12_190243| [ 1.17446e+00 -1.52283e+00]
21Feb12_190243| [ 7.02147e-02  9.39315e-03]
21Feb12_190243| [-6.24043e-01 -3.22238e-01]
21Feb12_190243| [ 4.20892e-01 -6.45196e-01]
21Feb12_190243| [ 2.85730e-02 -5.92999e-01]
21Feb12_190243| [ 1.00154e+00 -6.72183e-01]
21Feb12_190243| [ 1.50337e+00  9.23464e-01]
21Feb12_190243| [ 7.19733e-01  5.94171e-01]
21Feb12_190243| [ 1.07145e+00  5.55464e-01]
21Feb12_190243| [-8.40764e-01  7.68126e-01]
21Feb12_190243| [ 1.23893e+00  9.22462e-01]
21Feb12_190243| [-9.13895e-02  9.23047e-01]
21Feb12_190243| [-3.22161e-01 -6.34520e-01]
21Feb12_190243| [ 1.51205e-01 -6.43524e-01]
21Feb12_190243| [-6.58346e-01  9.89111e-01]
21Feb12_190243| [-2.29255e+00 -7.15652e-01]
21Feb12_190243| [-8.19109e-01 -8.88308e-01]
21Feb12_190243| [ 5.36962e-01 -3.15096e+00]
21Feb12_190243| [-2.03141e+00  7.69575e-01]
21Feb12_190243| [ 2.14540e+00 -8.85673e-01]
21Feb12_190243| [-1.09594e+00 -8.25339e-01]
21Feb12_190243| [ 1.30855e-01 -1.79813e+00]
21Feb12_190243| [ 2.57514e+00  1.18195e+00]
21Feb12_190243| [ 1.79697e+00 -4.44049e-01]
21Feb12_190243| [-8.11073e-01 -9.58804e-02]
21Feb12_190243| [ 6.97402e-01 -3.52362e-01]
21Feb12_190243| [ 1.31588e+00 -1.06488e+00]
21Feb12_190243| [-1.13318e-01  8.95197e-01]]
21Feb12_190243|-- Bias --
21Feb12_190243|[-0.74250  0.42025]
21Feb12_190243|Layer 1:
21Feb12_190243|-- Config --
21Feb12_190243|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190243|-- Weights --
21Feb12_190243|[[ 0.13109 -0.79243  0.39897 -0.74131]
21Feb12_190243| [-0.93057 -0.81797 -0.74571  0.03946]]
21Feb12_190243|-- Bias --
21Feb12_190243|[ 0.52923  0.95311  0.78114 -0.93265]
21Feb12_190243|Layer 2:
21Feb12_190243|-- Config --
21Feb12_190243|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_190243|-- Weights --
21Feb12_190243|[[ 0.84055  0.52233]
21Feb12_190243| [-1.37734 -0.30154]
21Feb12_190243| [ 0.54593 -0.67204]
21Feb12_190243| [-0.73794 -0.33974]]
21Feb12_190243|-- Bias --
21Feb12_190243|[0.06722 0.06699]
21Feb12_190243|Predicting the validation and test data with the Best final individual.
21Feb12_190251| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_190251|-----------  ------------------  --------------------  ----------
21Feb12_190251|Validation         42.00                  12            0.00000
21Feb12_190251|   Test            36.40                  12            0.00000
2021-02-12 19:02:51.744400: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
21Feb12_190252|Data summary: Train
21Feb12_190252|data.shape = (2300, 57)
21Feb12_190252|labels.shape = (2300,)
21Feb12_190252|Class distribution:
21Feb12_190252|	0 - 1389 (0.60)
21Feb12_190252|	1 - 911 (0.40)
21Feb12_190252|Data summary: Validation
21Feb12_190252|data.shape = (1150, 57)
21Feb12_190252|labels.shape = (1150,)
21Feb12_190252|Class distribution:
21Feb12_190252|	0 - 667 (0.58)
21Feb12_190252|	1 - 483 (0.42)
21Feb12_190252|Data summary: Test
21Feb12_190252|data.shape = (1151, 57)
21Feb12_190252|labels.shape = (1151,)
21Feb12_190252|Class distribution:
21Feb12_190252|	0 - 732 (0.64)
21Feb12_190252|	1 - 419 (0.36)
21Feb12_190252|Selected configuration values
21Feb12_190252|-- Dataset name: spambase2
21Feb12_190252|-- Initial population size: 64
21Feb12_190252|-- Maximun number of generations: 32
21Feb12_190252|-- Neurons per hidden layer range: (2, 20)
21Feb12_190252|-- Hidden layers number range: (1, 3)
21Feb12_190252|-- Crossover probability: 0.5
21Feb12_190252|-- Bias gene mutation probability: 0.2
21Feb12_190252|-- Weights gene mutation probability: 0.75
21Feb12_190252|-- Neuron mutation probability: 0.3
21Feb12_190252|-- Layer mutation probability: 0.3
21Feb12_190252|-- Constant hidden layers: False
21Feb12_190252|-- Seed: 31415
21Feb12_190252|Entering GA
21Feb12_190252|Start the algorithm
2021-02-12 19:02:52.585116: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-12 19:02:52.585648: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-02-12 19:02:52.607012: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-12 19:02:52.607343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.71GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s
2021-02-12 19:02:52.607358: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-02-12 19:02:52.608808: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-02-12 19:02:52.608837: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-02-12 19:02:52.609335: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-02-12 19:02:52.609467: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-02-12 19:02:52.609537: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-12 19:02:52.609955: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-02-12 19:02:52.609997: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-12 19:02:52.610003: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-02-12 19:02:52.610216: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-02-12 19:02:52.611034: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-12 19:02:52.611049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-12 19:02:52.611052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      
2021-02-12 19:02:52.656355: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-02-12 19:02:52.656702: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3493635000 Hz
/home/jmerelo/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype("int32")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn('`model.predict_classes()` is deprecated and '
21Feb12_190656|-- Generation 1 --
21Feb12_190656|    -- Crossed 0 individual pairs.
21Feb12_190656|    -- Mutated 32 individuals.
21Feb12_191058|    -- Evaluated 64 individuals.
21Feb12_191058|    Summary of generation 1:
21Feb12_191058| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_191058|-----------  ------------------  --------------------  ----------
21Feb12_191058|    Max            42.26                156.00          0.62316
21Feb12_191058|    Avg            41.78                41.06           0.01167
21Feb12_191058|    Min            29.04                 3.00           0.00000
21Feb12_191058|    Std             1.61                33.65           0.07712
21Feb12_191058|   Best            29.04                26.00           0.62316
21Feb12_191058|-- Generation 2 --
21Feb12_191058|    -- Crossed 3 individual pairs.
21Feb12_191058|    -- Mutated 32 individuals.
21Feb12_191452|    -- Evaluated 64 individuals.
21Feb12_191452|    Summary of generation 2:
21Feb12_191452| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_191452|-----------  ------------------  --------------------  ----------
21Feb12_191452|    Max            42.26                108.00          0.66766
21Feb12_191452|    Avg            41.61                21.31           0.01580
21Feb12_191452|    Min            24.35                 3.00           0.00000
21Feb12_191452|    Std             2.35                17.64           0.08703
21Feb12_191452|   Best            24.35                39.00           0.66766
21Feb12_191452|-- Generation 3 --
21Feb12_191452|    -- Crossed 0 individual pairs.
21Feb12_191452|    -- Mutated 32 individuals.
21Feb12_191844|    -- Evaluated 64 individuals.
21Feb12_191844|    Summary of generation 3:
21Feb12_191844| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_191844|-----------  ------------------  --------------------  ----------
21Feb12_191844|    Max            42.26                48.00           0.13930
21Feb12_191844|    Avg            41.93                14.48           0.00411
21Feb12_191844|    Min            39.04                 3.00           0.00000
21Feb12_191844|    Std             0.39                10.42           0.01769
21Feb12_191844|   Best            39.04                14.00           0.13930
21Feb12_191844|-- Generation 4 --
21Feb12_191844|    -- Crossed 2 individual pairs.
21Feb12_191844|    -- Mutated 32 individuals.
21Feb12_192234|    -- Evaluated 64 individuals.
21Feb12_192234|    Summary of generation 4:
21Feb12_192234| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_192234|-----------  ------------------  --------------------  ----------
21Feb12_192234|    Max            42.78                54.00           0.02058
21Feb12_192234|    Avg            41.99                11.09           0.00177
21Feb12_192234|    Min            41.57                 2.00           0.00000
21Feb12_192234|    Std             0.14                 9.53           0.00352
21Feb12_192234|   Best            41.57                12.00           0.01547
21Feb12_192234|-- Generation 5 --
21Feb12_192234|    -- Crossed 3 individual pairs.
21Feb12_192234|    -- Mutated 32 individuals.
21Feb12_192625|    -- Evaluated 64 individuals.
21Feb12_192625|    Summary of generation 5:
21Feb12_192625| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_192625|-----------  ------------------  --------------------  ----------
21Feb12_192625|    Max            42.17                30.00           0.51391
21Feb12_192625|    Avg            41.74                 7.36           0.01013
21Feb12_192625|    Min            27.91                 2.00           0.00000
21Feb12_192625|    Std             1.75                 5.20           0.06360
21Feb12_192625|   Best            27.91                16.00           0.51391
21Feb12_192625|-- Generation 6 --
21Feb12_192625|    -- Crossed 5 individual pairs.
21Feb12_192625|    -- Mutated 32 individuals.
21Feb12_193016|    -- Evaluated 64 individuals.
21Feb12_193016|    Summary of generation 6:
21Feb12_193016| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_193016|-----------  ------------------  --------------------  ----------
21Feb12_193016|    Max            48.61                34.00           0.80520
21Feb12_193016|    Avg            42.02                 9.25           0.01577
21Feb12_193016|    Min            41.30                 2.00           0.00000
21Feb12_193016|    Std             0.85                 6.75           0.09963
21Feb12_193016|   Best            41.30                 7.00           0.02062
21Feb12_193016|-- Generation 7 --
21Feb12_193016|    -- Crossed 2 individual pairs.
21Feb12_193016|    -- Mutated 32 individuals.
21Feb12_193407|    -- Evaluated 64 individuals.
21Feb12_193407|    Summary of generation 7:
21Feb12_193407| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_193407|-----------  ------------------  --------------------  ----------
21Feb12_193407|    Max            42.17                36.00           0.70943
21Feb12_193407|    Avg            41.74                 9.20           0.01395
21Feb12_193407|    Min            29.83                 2.00           0.00000
21Feb12_193407|    Std             1.51                 7.12           0.08775
21Feb12_193407|   Best            29.83                36.00           0.70943
21Feb12_193407|-- Generation 8 --
21Feb12_193407|    -- Crossed 2 individual pairs.
21Feb12_193407|    -- Mutated 32 individuals.
21Feb12_193758|    -- Evaluated 64 individuals.
21Feb12_193758|    Summary of generation 8:
21Feb12_193758| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_193758|-----------  ------------------  --------------------  ----------
21Feb12_193758|    Max            42.09                40.00           0.49206
21Feb12_193758|    Avg            41.72                11.03           0.01019
21Feb12_193758|    Min            28.00                 2.00           0.00000
21Feb12_193758|    Std             1.73                 8.98           0.06082
21Feb12_193758|   Best            28.00                30.00           0.49206
21Feb12_193758|-- Generation 9 --
21Feb12_193758|    -- Crossed 3 individual pairs.
21Feb12_193758|    -- Mutated 32 individuals.
21Feb12_194149|    -- Evaluated 64 individuals.
21Feb12_194149|    Summary of generation 9:
21Feb12_194149| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_194149|-----------  ------------------  --------------------  ----------
21Feb12_194149|    Max            42.17                40.00           0.02062
21Feb12_194149|    Avg            41.92                11.16           0.00311
21Feb12_194149|    Min            41.30                 2.00           0.00000
21Feb12_194149|    Std             0.14                 8.04           0.00465
21Feb12_194149|   Best            41.30                15.00           0.02062
21Feb12_194149|-- Generation 10 --
21Feb12_194149|    -- Crossed 3 individual pairs.
21Feb12_194149|    -- Mutated 32 individuals.
21Feb12_194540|    -- Evaluated 64 individuals.
21Feb12_194540|    Summary of generation 10:
21Feb12_194540| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_194540|-----------  ------------------  --------------------  ----------
21Feb12_194540|    Max            42.17                38.00           0.02062
21Feb12_194540|    Avg            41.92                11.34           0.00299
21Feb12_194540|    Min            41.30                 2.00           0.00000
21Feb12_194540|    Std             0.11                 7.95           0.00342
21Feb12_194540|   Best            41.30                13.00           0.02062
21Feb12_194540|-- Generation 11 --
21Feb12_194540|    -- Crossed 2 individual pairs.
21Feb12_194540|    -- Mutated 32 individuals.
21Feb12_194931|    -- Evaluated 64 individuals.
21Feb12_194931|    Summary of generation 11:
21Feb12_194931| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_194931|-----------  ------------------  --------------------  ----------
21Feb12_194931|    Max            42.17                36.00           0.58531
21Feb12_194931|    Avg            41.69                12.12           0.01298
21Feb12_194931|    Min            28.17                 3.00           0.00000
21Feb12_194931|    Std             1.71                 7.84           0.07228
21Feb12_194931|   Best            28.17                16.00           0.58531
21Feb12_194931|-- Generation 12 --
21Feb12_194931|    -- Crossed 5 individual pairs.
21Feb12_194931|    -- Mutated 32 individuals.
21Feb12_195322|    -- Evaluated 64 individuals.
21Feb12_195322|    Summary of generation 12:
21Feb12_195322| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_195322|-----------  ------------------  --------------------  ----------
21Feb12_195322|    Max            42.09                40.00           0.02316
21Feb12_195322|    Avg            41.89                11.50           0.00452
21Feb12_195322|    Min            41.39                 3.00           0.00000
21Feb12_195322|    Std             0.15                 7.91           0.00572
21Feb12_195322|   Best            41.39                 3.00           0.02316
21Feb12_195322|-- Generation 13 --
21Feb12_195322|    -- Crossed 4 individual pairs.
21Feb12_195322|    -- Mutated 32 individuals.
21Feb12_195712|    -- Evaluated 64 individuals.
21Feb12_195712|    Summary of generation 13:
21Feb12_195712| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_195712|-----------  ------------------  --------------------  ----------
21Feb12_195712|    Max            42.26                30.00           0.02318
21Feb12_195712|    Avg            41.90                 8.86           0.00440
21Feb12_195712|    Min            41.22                 2.00           0.00000
21Feb12_195712|    Std             0.17                 6.06           0.00538
21Feb12_195712|   Best            41.22                11.00           0.02318
21Feb12_195712|-- Generation 14 --
21Feb12_195712|    -- Crossed 2 individual pairs.
21Feb12_195712|    -- Mutated 32 individuals.
21Feb12_200103|    -- Evaluated 64 individuals.
21Feb12_200103|    Summary of generation 14:
21Feb12_200103| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_200103|-----------  ------------------  --------------------  ----------
21Feb12_200103|    Max            42.17                32.00           0.24757
21Feb12_200103|    Avg            41.80                10.08           0.00863
21Feb12_200103|    Min            35.39                 2.00           0.00000
21Feb12_200103|    Std             0.83                 7.44           0.03055
21Feb12_200103|   Best            35.39                12.00           0.24757
21Feb12_200103|-- Generation 15 --
21Feb12_200103|    -- Crossed 6 individual pairs.
21Feb12_200103|    -- Mutated 32 individuals.
21Feb12_200454|    -- Evaluated 64 individuals.
21Feb12_200454|    Summary of generation 15:
21Feb12_200454| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_200454|-----------  ------------------  --------------------  ----------
21Feb12_200454|    Max            42.17                32.00           0.01803
21Feb12_200454|    Avg            41.92                 8.17           0.00420
21Feb12_200454|    Min            41.48                 2.00           0.00000
21Feb12_200454|    Std             0.12                 5.19           0.00383
21Feb12_200454|   Best            41.48                10.00           0.01548
21Feb12_200454|-- Generation 16 --
21Feb12_200454|    -- Crossed 3 individual pairs.
21Feb12_200454|    -- Mutated 32 individuals.
21Feb12_200845|    -- Evaluated 64 individuals.
21Feb12_200845|    Summary of generation 16:
21Feb12_200845| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_200845|-----------  ------------------  --------------------  ----------
21Feb12_200845|    Max            42.35                32.00           0.02575
21Feb12_200845|    Avg            41.88                 9.28           0.00484
21Feb12_200845|    Min            41.13                 2.00           0.00000
21Feb12_200845|    Std             0.20                 7.01           0.00549
21Feb12_200845|   Best            41.13                12.00           0.02575
21Feb12_200845|-- Generation 17 --
21Feb12_200845|    -- Crossed 2 individual pairs.
21Feb12_200845|    -- Mutated 32 individuals.
21Feb12_201236|    -- Evaluated 64 individuals.
21Feb12_201236|    Summary of generation 17:
21Feb12_201236| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_201236|-----------  ------------------  --------------------  ----------
21Feb12_201236|    Max            42.17                34.00           0.02316
21Feb12_201236|    Avg            41.88                 9.12           0.00460
21Feb12_201236|    Min            41.39                 2.00           0.00000
21Feb12_201236|    Std             0.15                 5.97           0.00447
21Feb12_201236|   Best            41.39                12.00           0.02316
21Feb12_201236|-- Generation 18 --
21Feb12_201236|    -- Crossed 6 individual pairs.
21Feb12_201236|    -- Mutated 32 individuals.
21Feb12_201626|    -- Evaluated 64 individuals.
21Feb12_201626|    Summary of generation 18:
21Feb12_201626| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_201626|-----------  ------------------  --------------------  ----------
21Feb12_201626|    Max            42.00                30.00           0.02062
21Feb12_201626|    Avg            41.86                 8.08           0.00468
21Feb12_201626|    Min            41.30                 2.00           0.00000
21Feb12_201626|    Std             0.14                 6.58           0.00400
21Feb12_201626|   Best            41.30                 3.00           0.02062
21Feb12_201626|-- Generation 19 --
21Feb12_201626|    -- Crossed 5 individual pairs.
21Feb12_201626|    -- Mutated 32 individuals.
21Feb12_202018|    -- Evaluated 64 individuals.
21Feb12_202018|    Summary of generation 19:
21Feb12_202018| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_202018|-----------  ------------------  --------------------  ----------
21Feb12_202018|    Max            42.17                39.00           0.84723
21Feb12_202018|    Avg            41.39                 8.89           0.02464
21Feb12_202018|    Min            22.26                 2.00           0.00000
21Feb12_202018|    Std             2.74                 7.06           0.11425
21Feb12_202018|   Best            22.26                39.00           0.84723
21Feb12_202018|-- Generation 20 --
21Feb12_202018|    -- Crossed 6 individual pairs.
21Feb12_202018|    -- Mutated 32 individuals.
21Feb12_202409|    -- Evaluated 64 individuals.
21Feb12_202409|    Summary of generation 20:
21Feb12_202409| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_202409|-----------  ------------------  --------------------  ----------
21Feb12_202409|    Max            42.17                39.00           0.71862
21Feb12_202409|    Avg            41.36                 9.30           0.02620
21Feb12_202409|    Min            24.78                 2.00           0.00000
21Feb12_202409|    Std             2.78                 9.00           0.11809
21Feb12_202409|   Best            24.78                 8.00           0.64585
21Feb12_202409|-- Generation 21 --
21Feb12_202409|    -- Crossed 4 individual pairs.
21Feb12_202409|    -- Mutated 32 individuals.
21Feb12_202801|    -- Evaluated 64 individuals.
21Feb12_202801|    Summary of generation 21:
21Feb12_202801| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_202801|-----------  ------------------  --------------------  ----------
21Feb12_202801|    Max            42.35                39.00           0.84015
21Feb12_202801|    Avg            41.67                 7.23           0.01841
21Feb12_202801|    Min            29.30                 2.00           0.00000
21Feb12_202801|    Std             1.56                 6.33           0.10360
21Feb12_202801|   Best            29.30                 8.00           0.84015
21Feb12_202801|-- Generation 22 --
21Feb12_202801|    -- Crossed 7 individual pairs.
21Feb12_202801|    -- Mutated 32 individuals.
21Feb12_203150|    -- Evaluated 64 individuals.
21Feb12_203150|    Summary of generation 22:
21Feb12_203150| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_203150|-----------  ------------------  --------------------  ----------
21Feb12_203150|    Max            42.09                32.00           0.77523
21Feb12_203150|    Avg            41.50                 7.25           0.01748
21Feb12_203150|    Min            20.26                 2.00           0.00000
21Feb12_203150|    Std             2.68                 6.11           0.09557
21Feb12_203150|   Best            20.26                 8.00           0.77523
21Feb12_203150|-- Generation 23 --
21Feb12_203150|    -- Crossed 8 individual pairs.
21Feb12_203150|    -- Mutated 32 individuals.
21Feb12_203539|    -- Evaluated 64 individuals.
21Feb12_203539|    Summary of generation 23:
21Feb12_203539| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_203539|-----------  ------------------  --------------------  ----------
21Feb12_203539|    Max            42.43                30.00           0.82950
21Feb12_203539|    Avg            41.73                 6.91           0.03032
21Feb12_203539|    Min            35.65                 2.00           0.00000
21Feb12_203539|    Std             0.90                 5.93           0.14310
21Feb12_203539|   Best            35.65                 8.00           0.82402
21Feb12_203539|-- Generation 24 --
21Feb12_203539|    -- Crossed 5 individual pairs.
21Feb12_203539|    -- Mutated 32 individuals.
21Feb12_203929|    -- Evaluated 64 individuals.
21Feb12_203929|    Summary of generation 24:
21Feb12_203929| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_203929|-----------  ------------------  --------------------  ----------
21Feb12_203929|    Max            51.22                32.00           0.79940
21Feb12_203929|    Avg            41.32                 7.41           0.04338
21Feb12_203929|    Min            22.09                 2.00           0.00000
21Feb12_203929|    Std             3.46                 7.34           0.15692
21Feb12_203929|   Best            22.09                 8.00           0.79495
21Feb12_203929|-- Generation 25 --
21Feb12_203929|    -- Crossed 5 individual pairs.
21Feb12_203929|    -- Mutated 32 individuals.
21Feb12_204320|    -- Evaluated 64 individuals.
21Feb12_204320|    Summary of generation 25:
21Feb12_204320| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_204320|-----------  ------------------  --------------------  ----------
21Feb12_204320|    Max            42.09                36.00           0.49436
21Feb12_204320|    Avg            41.66                 7.55           0.01236
21Feb12_204320|    Min            28.52                 2.00           0.00000
21Feb12_204320|    Std             1.66                 7.36           0.06094
21Feb12_204320|   Best            28.52                22.00           0.49436
21Feb12_204320|-- Generation 26 --
21Feb12_204320|    -- Crossed 2 individual pairs.
21Feb12_204320|    -- Mutated 32 individuals.
21Feb12_204712|    -- Evaluated 64 individuals.
21Feb12_204712|    Summary of generation 26:
21Feb12_204712| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_204712|-----------  ------------------  --------------------  ----------
21Feb12_204712|    Max            42.09                39.00           0.83044
21Feb12_204712|    Avg            41.60                 6.89           0.01749
21Feb12_204712|    Min            24.70                 2.00           0.00000
21Feb12_204712|    Std             2.13                 7.09           0.10250
21Feb12_204712|   Best            24.70                 8.00           0.83044
21Feb12_204712|-- Generation 27 --
21Feb12_204712|    -- Crossed 6 individual pairs.
21Feb12_204712|    -- Mutated 32 individuals.
21Feb12_205102|    -- Evaluated 64 individuals.
21Feb12_205102|    Summary of generation 27:
21Feb12_205102| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_205102|-----------  ------------------  --------------------  ----------
21Feb12_205102|    Max            42.17                30.00           0.82353
21Feb12_205102|    Avg            41.80                 6.47           0.01727
21Feb12_205102|    Min            37.57                 2.00           0.00000
21Feb12_205102|    Std             0.55                 5.86           0.10165
21Feb12_205102|   Best            37.57                 8.00           0.82353
21Feb12_205102|-- Generation 28 --
21Feb12_205102|    -- Crossed 3 individual pairs.
21Feb12_205102|    -- Mutated 32 individuals.
21Feb12_205453|    -- Evaluated 64 individuals.
21Feb12_205453|    Summary of generation 28:
21Feb12_205453| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_205453|-----------  ------------------  --------------------  ----------
21Feb12_205453|    Max            42.09                20.00           0.80408
21Feb12_205453|    Avg            41.68                 5.80           0.01696
21Feb12_205453|    Min            30.26                 2.00           0.00000
21Feb12_205453|    Std             1.44                 5.37           0.09924
21Feb12_205453|   Best            30.26                 8.00           0.80408
21Feb12_205453|-- Generation 29 --
21Feb12_205453|    -- Crossed 6 individual pairs.
21Feb12_205453|    -- Mutated 32 individuals.
21Feb12_205844|    -- Evaluated 64 individuals.
21Feb12_205844|    Summary of generation 29:
21Feb12_205844| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_205844|-----------  ------------------  --------------------  ----------
21Feb12_205844|    Max            42.17                20.00           0.02062
21Feb12_205844|    Avg            41.88                 5.64           0.00428
21Feb12_205844|    Min            41.30                 2.00           0.00000
21Feb12_205844|    Std             0.13                 5.27           0.00395
21Feb12_205844|   Best            41.30                20.00           0.02062
21Feb12_205844|-- Generation 30 --
21Feb12_205844|    -- Crossed 6 individual pairs.
21Feb12_205844|    -- Mutated 32 individuals.
21Feb12_210234|    -- Evaluated 64 individuals.
21Feb12_210234|    Summary of generation 30:
21Feb12_210234| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_210234|-----------  ------------------  --------------------  ----------
21Feb12_210234|    Max            42.00                22.00           0.01805
21Feb12_210234|    Avg            41.86                 5.08           0.00440
21Feb12_210234|    Min            41.39                 2.00           0.00000
21Feb12_210234|    Std             0.10                 5.24           0.00311
21Feb12_210234|   Best            41.39                14.00           0.01805
21Feb12_210234|-- Generation 31 --
21Feb12_210234|    -- Crossed 5 individual pairs.
21Feb12_210234|    -- Mutated 32 individuals.
21Feb12_210623|    -- Evaluated 64 individuals.
21Feb12_210623|    Summary of generation 31:
21Feb12_210623| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_210623|-----------  ------------------  --------------------  ----------
21Feb12_210623|    Max            42.61                16.00           0.01805
21Feb12_210623|    Avg            41.86                 3.31           0.00444
21Feb12_210623|    Min            41.39                 2.00           0.00000
21Feb12_210623|    Std             0.14                 2.99           0.00304
21Feb12_210623|   Best            41.39                 5.00           0.01805
21Feb12_210623|-- Generation 32 --
21Feb12_210623|    -- Crossed 11 individual pairs.
21Feb12_210623|    -- Mutated 32 individuals.
21Feb12_211012|    -- Evaluated 64 individuals.
21Feb12_211012|    Summary of generation 32:
21Feb12_211012| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_211012|-----------  ------------------  --------------------  ----------
21Feb12_211012|    Max            42.00                16.00           0.01805
21Feb12_211012|    Avg            41.84                 4.14           0.00505
21Feb12_211012|    Min            41.39                 2.00           0.00000
21Feb12_211012|    Std             0.12                 3.79           0.00383
21Feb12_211012|   Best            41.39                12.00           0.01805
21Feb12_211012|Best initial individual weights
21Feb12_211012|Individual:
21Feb12_211012|-- Constant hidden layers --
21Feb12_211012|False
21Feb12_211012|Layer 0:
21Feb12_211012|-- Config --
21Feb12_211012|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 20, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211012|-- Weights --
21Feb12_211012|[[ 0.16538 -0.77401 -0.00608 ...  0.65170 -0.62891  0.06458]
21Feb12_211012| [-0.68906  0.49124 -0.82875 ...  0.95559 -0.22724  0.37174]
21Feb12_211012| [-0.02459 -0.65663 -0.70183 ...  0.93684 -0.35995  0.08562]
21Feb12_211012| ...
21Feb12_211012| [ 0.14376 -0.58767  0.38143 ...  0.88666 -0.25444  0.24251]
21Feb12_211012| [-0.27631 -0.15933 -0.55384 ...  0.20998 -0.36680 -0.31376]
21Feb12_211012| [ 0.63419 -0.93456 -0.15672 ...  0.23038 -0.88133 -0.63626]]
21Feb12_211012|-- Bias --
21Feb12_211012|[-0.97464 -0.85591 -0.86235 -0.65627 -0.32809 -0.92477  0.19771  0.12766
21Feb12_211012| -0.61142 -0.08191 -0.92249  0.78722 -0.91356 -0.41978  0.73481 -0.07531
21Feb12_211012| -0.13776  0.00316  0.07810  0.98042]
21Feb12_211012|Layer 1:
21Feb12_211012|-- Config --
21Feb12_211012|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 20], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211012|-- Weights --
21Feb12_211012|[[ 0.17927  0.05059  0.14365 -0.97965]
21Feb12_211012| [-0.72966  0.18465 -0.57958 -0.75661]
21Feb12_211012| [ 0.79160 -0.44957 -0.30703 -0.23486]
21Feb12_211012| [-0.94331 -0.92779  0.16938  0.71109]
21Feb12_211012| [ 0.41752 -0.02958  0.95818  0.85022]
21Feb12_211012| [ 0.98523  0.75232 -0.88204 -0.34763]
21Feb12_211012| [ 0.43929 -0.44193 -0.21478 -0.76798]
21Feb12_211012| [ 0.52274 -0.25374  0.99449  0.65709]
21Feb12_211012| [ 0.99528  0.79914  0.62908 -0.34474]
21Feb12_211012| [-0.76572 -0.83928 -0.43847  0.89005]
21Feb12_211012| [-0.28948  0.48225 -0.04509  0.36951]
21Feb12_211012| [-0.70208  0.36214 -0.68534  0.91435]
21Feb12_211012| [ 0.31676  0.59374 -0.16533 -0.21022]
21Feb12_211012| [ 0.10818 -0.49682  0.95797 -0.21256]
21Feb12_211012| [-0.14358 -0.61799  0.22976 -0.62086]
21Feb12_211012| [ 0.06347  0.37842  0.26411  0.83836]
21Feb12_211012| [-0.97809 -0.90875  0.74790  0.55812]
21Feb12_211012| [ 0.91386 -0.35732  0.47048  0.17558]
21Feb12_211012| [ 0.90609 -0.08591 -0.50923  0.24402]
21Feb12_211012| [ 0.34637 -0.02023  0.98795  0.71753]]
21Feb12_211012|-- Bias --
21Feb12_211012|[ 0.77827 -0.93300 -0.04224  0.08863]
21Feb12_211012|Layer 2:
21Feb12_211012|-- Config --
21Feb12_211012|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 18, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211012|-- Weights --
21Feb12_211012|[[ 0.38090  0.16612 -0.87717  0.16049  0.05373 -0.15095  0.96084  0.99870
21Feb12_211012|  -0.21572 -0.50778 -0.11916 -0.07972 -0.31260 -0.19441 -0.75699 -0.47510
21Feb12_211012|  -0.07048  0.39064]
21Feb12_211012| [ 0.96786 -0.97945  0.32351  0.31609  0.06547 -0.70443 -0.77079 -0.79363
21Feb12_211012|   0.13246  0.60960  0.14455  0.78804 -0.03175 -0.16979  0.05102  0.15370
21Feb12_211012|   0.34980  0.01450]
21Feb12_211012| [-0.94330  0.20605  0.67576 -0.68437  0.84773 -0.93620  0.40850  0.71162
21Feb12_211012|   0.62654 -0.94535  0.68679 -0.62690  0.12123  0.70189 -0.98775  0.87563
21Feb12_211012|   0.37593 -0.36252]
21Feb12_211012| [ 0.09964  0.65946 -0.07812  0.85653  0.78644  0.33656  0.11319  0.53560
21Feb12_211012|  -0.54287 -0.48351  0.00897  0.78783 -0.57189 -0.85225 -0.78126  0.09783
21Feb12_211012|  -0.70814  0.05556]]
21Feb12_211012|-- Bias --
21Feb12_211012|[-0.80382 -0.52251 -0.43409  0.42023  0.55006 -0.61225 -0.73400  0.48184
21Feb12_211012|  0.81203 -0.35601  0.58294 -0.48240 -0.90354 -0.60396 -0.46119 -0.74489
21Feb12_211012|  0.56448  0.25321]
21Feb12_211012|Layer 3:
21Feb12_211012|-- Config --
21Feb12_211012|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 18], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211012|-- Weights --
21Feb12_211012|[[ 0.04876 -0.39185]
21Feb12_211012| [-0.55679 -0.06391]
21Feb12_211012| [ 0.01400  0.05819]
21Feb12_211012| [ 0.89548  0.31939]
21Feb12_211012| [-0.33667 -0.63002]
21Feb12_211012| [ 0.37466  0.38304]
21Feb12_211012| [-0.78135 -0.02638]
21Feb12_211012| [ 0.64500  0.58024]
21Feb12_211012| [-0.28350 -0.21430]
21Feb12_211012| [ 0.90758  0.84536]
21Feb12_211012| [ 0.31835 -0.30832]
21Feb12_211012| [-0.57902  0.00787]
21Feb12_211012| [-0.25556 -0.97136]
21Feb12_211012| [-0.41410  0.93435]
21Feb12_211012| [ 0.00794 -0.66137]
21Feb12_211012| [ 0.99846  0.40167]
21Feb12_211012| [ 0.16777  0.38823]
21Feb12_211012| [ 0.52043 -0.12533]]
21Feb12_211012|-- Bias --
21Feb12_211012|[0.75983 0.86308]
21Feb12_211012|Predicting the validation and test data with the Best initial individual.
21Feb12_211021| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_211021|-----------  ------------------  --------------------  ----------
21Feb12_211021|Validation         42.00                 126            0.00000
21Feb12_211021|   Test            36.49                 126            0.00000
21Feb12_211021|-------------------- Test #0 --------------------
21Feb12_211021|Best final individual weights
21Feb12_211021|Individual:
21Feb12_211021|-- Constant hidden layers --
21Feb12_211021|False
21Feb12_211021|Layer 0:
21Feb12_211021|-- Config --
21Feb12_211021|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211021|-- Weights --
21Feb12_211021|[[ 0.48141  1.08053]
21Feb12_211021| [-0.62108  0.02214]
21Feb12_211021| [-0.65483  0.88968]
21Feb12_211021| [-0.91839 -0.30848]
21Feb12_211021| [ 0.08504  0.90277]
21Feb12_211021| [ 0.37053  0.38479]
21Feb12_211021| [ 0.40871  1.23967]
21Feb12_211021| [-0.48711  0.45785]
21Feb12_211021| [ 0.96174 -1.07439]
21Feb12_211021| [ 0.06805  0.37322]
21Feb12_211021| [-0.22538  0.98785]
21Feb12_211021| [ 0.28474  0.11466]
21Feb12_211021| [ 0.95618 -1.73991]
21Feb12_211021| [ 0.23280  0.70700]
21Feb12_211021| [ 0.67583  0.28878]
21Feb12_211021| [ 1.10819  0.60307]
21Feb12_211021| [-0.19711 -1.04827]
21Feb12_211021| [-1.50344  1.92408]
21Feb12_211021| [ 0.13970  0.27654]
21Feb12_211021| [-1.13489  1.43482]
21Feb12_211021| [ 0.90793  0.09290]
21Feb12_211021| [ 0.28340 -0.20824]
21Feb12_211021| [-0.31490 -0.27430]
21Feb12_211021| [-0.04291 -0.55918]
21Feb12_211021| [-0.57216 -0.33220]
21Feb12_211021| [-0.18320 -2.15242]
21Feb12_211021| [ 1.41196  0.46552]
21Feb12_211021| [ 1.35793  0.32961]
21Feb12_211021| [-1.10509 -0.07299]
21Feb12_211021| [ 1.66389 -0.38715]
21Feb12_211021| [ 0.41781 -1.07053]
21Feb12_211021| [-0.07102 -0.59571]
21Feb12_211021| [-1.06163  0.25294]
21Feb12_211021| [-0.05236 -0.29352]
21Feb12_211021| [-0.07774  2.36904]
21Feb12_211021| [ 0.69814 -0.02507]
21Feb12_211021| [ 1.73983 -1.31095]
21Feb12_211021| [ 1.30637  1.52494]
21Feb12_211021| [-0.50587 -0.07929]
21Feb12_211021| [ 0.19700 -0.02597]
21Feb12_211021| [ 0.74440  0.98723]
21Feb12_211021| [ 0.01100 -0.67337]
21Feb12_211021| [ 0.06204  0.35817]
21Feb12_211021| [ 0.26726  0.48263]
21Feb12_211021| [-0.88494 -0.70844]
21Feb12_211021| [-0.84413 -0.69285]
21Feb12_211021| [ 0.45345 -2.08209]
21Feb12_211021| [-0.40021 -0.10894]
21Feb12_211021| [ 2.73392 -0.61867]
21Feb12_211021| [ 1.24710  0.98537]
21Feb12_211021| [ 0.82300  0.72555]
21Feb12_211021| [ 2.06057 -0.06460]
21Feb12_211021| [ 1.26673 -1.23461]
21Feb12_211021| [ 0.42018 -0.49554]
21Feb12_211021| [ 2.61792  1.45873]
21Feb12_211021| [ 0.59144 -1.10854]
21Feb12_211021| [-0.97707  1.48165]]
21Feb12_211021|-- Bias --
21Feb12_211021|[ 0.38902 -0.39861]
21Feb12_211021|Layer 1:
21Feb12_211021|-- Config --
21Feb12_211021|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211021|-- Weights --
21Feb12_211021|[[-0.32012 -0.65699  0.76440  0.52560]
21Feb12_211021| [ 0.44064  0.51440 -0.76282  0.19969]]
21Feb12_211021|-- Bias --
21Feb12_211021|[ 0.04015  0.29509  0.93883 -0.02209]
21Feb12_211021|Layer 2:
21Feb12_211021|-- Config --
21Feb12_211021|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211021|-- Weights --
21Feb12_211021|[[ 2.71531 -0.86969]
21Feb12_211021| [-0.96223  1.09854]
21Feb12_211021| [-0.40245  0.31843]
21Feb12_211021| [-0.02201 -0.31563]]
21Feb12_211021|-- Bias --
21Feb12_211021|[0.38755 0.47351]
21Feb12_211021|Predicting the validation and test data with the Best final individual.
21Feb12_211028| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_211028|-----------  ------------------  --------------------  ----------
21Feb12_211028|Validation         41.39                  12            0.01805
21Feb12_211028|   Test            36.32                  12            0.00298
21Feb12_211028|-------------------- Test #1 --------------------
21Feb12_211028|Best final individual weights
21Feb12_211028|Individual:
21Feb12_211028|-- Constant hidden layers --
21Feb12_211028|False
21Feb12_211028|Layer 0:
21Feb12_211028|-- Config --
21Feb12_211028|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211028|-- Weights --
21Feb12_211028|[[ 0.48141  1.08053]
21Feb12_211028| [-0.62108  0.02214]
21Feb12_211028| [-0.65483  0.88968]
21Feb12_211028| [-0.91839 -0.30848]
21Feb12_211028| [ 0.08504  0.90277]
21Feb12_211028| [ 0.37053  0.38479]
21Feb12_211028| [ 0.40871  1.23967]
21Feb12_211028| [-0.48711  0.45785]
21Feb12_211028| [ 0.96174 -1.07439]
21Feb12_211028| [ 0.06805  0.37322]
21Feb12_211028| [-0.22538  0.98785]
21Feb12_211028| [ 0.28474  0.11466]
21Feb12_211028| [ 0.95618 -1.73991]
21Feb12_211028| [ 0.23280  0.70700]
21Feb12_211028| [ 0.67583  0.28878]
21Feb12_211028| [ 1.10819  0.60307]
21Feb12_211028| [-0.19711 -1.04827]
21Feb12_211028| [-1.50344  1.92408]
21Feb12_211028| [ 0.13970  0.27654]
21Feb12_211028| [-1.13489  1.43482]
21Feb12_211028| [ 0.90793  0.09290]
21Feb12_211028| [ 0.28340 -0.20824]
21Feb12_211028| [-0.31490 -0.27430]
21Feb12_211028| [-0.04291 -0.55918]
21Feb12_211028| [-0.57216 -0.33220]
21Feb12_211028| [-0.18320 -2.15242]
21Feb12_211028| [ 1.41196  0.46552]
21Feb12_211028| [ 1.35793  0.32961]
21Feb12_211028| [-1.10509 -0.07299]
21Feb12_211028| [ 1.66389 -0.38715]
21Feb12_211028| [ 0.41781 -1.07053]
21Feb12_211028| [-0.07102 -0.59571]
21Feb12_211028| [-1.06163  0.25294]
21Feb12_211028| [-0.05236 -0.29352]
21Feb12_211028| [-0.07774  2.36904]
21Feb12_211028| [ 0.69814 -0.02507]
21Feb12_211028| [ 1.73983 -1.31095]
21Feb12_211028| [ 1.30637  1.52494]
21Feb12_211028| [-0.50587 -0.07929]
21Feb12_211028| [ 0.19700 -0.02597]
21Feb12_211028| [ 0.74440  0.98723]
21Feb12_211028| [ 0.01100 -0.67337]
21Feb12_211028| [ 0.06204  0.35817]
21Feb12_211028| [ 0.26726  0.48263]
21Feb12_211028| [-0.88494 -0.70844]
21Feb12_211028| [-0.84413 -0.69285]
21Feb12_211028| [ 0.45345 -2.08209]
21Feb12_211028| [-0.40021 -0.10894]
21Feb12_211028| [ 2.73392 -0.61867]
21Feb12_211028| [ 1.24710  0.98537]
21Feb12_211028| [ 0.82300  0.72555]
21Feb12_211028| [ 2.06057 -0.06460]
21Feb12_211028| [ 1.26673 -1.23461]
21Feb12_211028| [ 0.42018 -0.49554]
21Feb12_211028| [ 2.61792  1.45873]
21Feb12_211028| [ 0.59144 -1.10854]
21Feb12_211028| [-0.97707  1.48165]]
21Feb12_211028|-- Bias --
21Feb12_211028|[ 0.38902 -0.39861]
21Feb12_211028|Layer 1:
21Feb12_211028|-- Config --
21Feb12_211028|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211028|-- Weights --
21Feb12_211028|[[-0.32012 -0.65699  0.76440  0.52560]
21Feb12_211028| [ 0.44064  0.51440 -0.76282  0.19969]]
21Feb12_211028|-- Bias --
21Feb12_211028|[ 0.04015  0.29509  0.93883 -0.02209]
21Feb12_211028|Layer 2:
21Feb12_211028|-- Config --
21Feb12_211028|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211028|-- Weights --
21Feb12_211028|[[ 2.71531 -0.86969]
21Feb12_211028| [-0.96223  1.09854]
21Feb12_211028| [-0.40245  0.31843]
21Feb12_211028| [-0.02201 -0.31563]]
21Feb12_211028|-- Bias --
21Feb12_211028|[0.38755 0.47351]
21Feb12_211028|Predicting the validation and test data with the Best final individual.
21Feb12_211035| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_211035|-----------  ------------------  --------------------  ----------
21Feb12_211035|Validation         41.91                  12            0.00259
21Feb12_211035|   Test            36.49                  12            0.19263
21Feb12_211035|-------------------- Test #2 --------------------
21Feb12_211035|Best final individual weights
21Feb12_211035|Individual:
21Feb12_211035|-- Constant hidden layers --
21Feb12_211035|False
21Feb12_211035|Layer 0:
21Feb12_211035|-- Config --
21Feb12_211035|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211035|-- Weights --
21Feb12_211035|[[ 0.48141  1.08053]
21Feb12_211035| [-0.62108  0.02214]
21Feb12_211035| [-0.65483  0.88968]
21Feb12_211035| [-0.91839 -0.30848]
21Feb12_211035| [ 0.08504  0.90277]
21Feb12_211035| [ 0.37053  0.38479]
21Feb12_211035| [ 0.40871  1.23967]
21Feb12_211035| [-0.48711  0.45785]
21Feb12_211035| [ 0.96174 -1.07439]
21Feb12_211035| [ 0.06805  0.37322]
21Feb12_211035| [-0.22538  0.98785]
21Feb12_211035| [ 0.28474  0.11466]
21Feb12_211035| [ 0.95618 -1.73991]
21Feb12_211035| [ 0.23280  0.70700]
21Feb12_211035| [ 0.67583  0.28878]
21Feb12_211035| [ 1.10819  0.60307]
21Feb12_211035| [-0.19711 -1.04827]
21Feb12_211035| [-1.50344  1.92408]
21Feb12_211035| [ 0.13970  0.27654]
21Feb12_211035| [-1.13489  1.43482]
21Feb12_211035| [ 0.90793  0.09290]
21Feb12_211035| [ 0.28340 -0.20824]
21Feb12_211035| [-0.31490 -0.27430]
21Feb12_211035| [-0.04291 -0.55918]
21Feb12_211035| [-0.57216 -0.33220]
21Feb12_211035| [-0.18320 -2.15242]
21Feb12_211035| [ 1.41196  0.46552]
21Feb12_211035| [ 1.35793  0.32961]
21Feb12_211035| [-1.10509 -0.07299]
21Feb12_211035| [ 1.66389 -0.38715]
21Feb12_211035| [ 0.41781 -1.07053]
21Feb12_211035| [-0.07102 -0.59571]
21Feb12_211035| [-1.06163  0.25294]
21Feb12_211035| [-0.05236 -0.29352]
21Feb12_211035| [-0.07774  2.36904]
21Feb12_211035| [ 0.69814 -0.02507]
21Feb12_211035| [ 1.73983 -1.31095]
21Feb12_211035| [ 1.30637  1.52494]
21Feb12_211035| [-0.50587 -0.07929]
21Feb12_211035| [ 0.19700 -0.02597]
21Feb12_211035| [ 0.74440  0.98723]
21Feb12_211035| [ 0.01100 -0.67337]
21Feb12_211035| [ 0.06204  0.35817]
21Feb12_211035| [ 0.26726  0.48263]
21Feb12_211035| [-0.88494 -0.70844]
21Feb12_211035| [-0.84413 -0.69285]
21Feb12_211035| [ 0.45345 -2.08209]
21Feb12_211035| [-0.40021 -0.10894]
21Feb12_211035| [ 2.73392 -0.61867]
21Feb12_211035| [ 1.24710  0.98537]
21Feb12_211035| [ 0.82300  0.72555]
21Feb12_211035| [ 2.06057 -0.06460]
21Feb12_211035| [ 1.26673 -1.23461]
21Feb12_211035| [ 0.42018 -0.49554]
21Feb12_211035| [ 2.61792  1.45873]
21Feb12_211035| [ 0.59144 -1.10854]
21Feb12_211035| [-0.97707  1.48165]]
21Feb12_211035|-- Bias --
21Feb12_211035|[ 0.38902 -0.39861]
21Feb12_211035|Layer 1:
21Feb12_211035|-- Config --
21Feb12_211035|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211035|-- Weights --
21Feb12_211035|[[-0.32012 -0.65699  0.76440  0.52560]
21Feb12_211035| [ 0.44064  0.51440 -0.76282  0.19969]]
21Feb12_211035|-- Bias --
21Feb12_211035|[ 0.04015  0.29509  0.93883 -0.02209]
21Feb12_211035|Layer 2:
21Feb12_211035|-- Config --
21Feb12_211035|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211035|-- Weights --
21Feb12_211035|[[ 2.71531 -0.86969]
21Feb12_211035| [-0.96223  1.09854]
21Feb12_211035| [-0.40245  0.31843]
21Feb12_211035| [-0.02201 -0.31563]]
21Feb12_211035|-- Bias --
21Feb12_211035|[0.38755 0.47351]
21Feb12_211035|Predicting the validation and test data with the Best final individual.
21Feb12_211043| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_211043|-----------  ------------------  --------------------  ----------
21Feb12_211043|Validation         41.39                  12            0.01805
21Feb12_211043|   Test            36.49                  12            0.01187
21Feb12_211043|-------------------- Test #3 --------------------
21Feb12_211043|Best final individual weights
21Feb12_211043|Individual:
21Feb12_211043|-- Constant hidden layers --
21Feb12_211043|False
21Feb12_211043|Layer 0:
21Feb12_211043|-- Config --
21Feb12_211043|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211043|-- Weights --
21Feb12_211043|[[ 0.48141  1.08053]
21Feb12_211043| [-0.62108  0.02214]
21Feb12_211043| [-0.65483  0.88968]
21Feb12_211043| [-0.91839 -0.30848]
21Feb12_211043| [ 0.08504  0.90277]
21Feb12_211043| [ 0.37053  0.38479]
21Feb12_211043| [ 0.40871  1.23967]
21Feb12_211043| [-0.48711  0.45785]
21Feb12_211043| [ 0.96174 -1.07439]
21Feb12_211043| [ 0.06805  0.37322]
21Feb12_211043| [-0.22538  0.98785]
21Feb12_211043| [ 0.28474  0.11466]
21Feb12_211043| [ 0.95618 -1.73991]
21Feb12_211043| [ 0.23280  0.70700]
21Feb12_211043| [ 0.67583  0.28878]
21Feb12_211043| [ 1.10819  0.60307]
21Feb12_211043| [-0.19711 -1.04827]
21Feb12_211043| [-1.50344  1.92408]
21Feb12_211043| [ 0.13970  0.27654]
21Feb12_211043| [-1.13489  1.43482]
21Feb12_211043| [ 0.90793  0.09290]
21Feb12_211043| [ 0.28340 -0.20824]
21Feb12_211043| [-0.31490 -0.27430]
21Feb12_211043| [-0.04291 -0.55918]
21Feb12_211043| [-0.57216 -0.33220]
21Feb12_211043| [-0.18320 -2.15242]
21Feb12_211043| [ 1.41196  0.46552]
21Feb12_211043| [ 1.35793  0.32961]
21Feb12_211043| [-1.10509 -0.07299]
21Feb12_211043| [ 1.66389 -0.38715]
21Feb12_211043| [ 0.41781 -1.07053]
21Feb12_211043| [-0.07102 -0.59571]
21Feb12_211043| [-1.06163  0.25294]
21Feb12_211043| [-0.05236 -0.29352]
21Feb12_211043| [-0.07774  2.36904]
21Feb12_211043| [ 0.69814 -0.02507]
21Feb12_211043| [ 1.73983 -1.31095]
21Feb12_211043| [ 1.30637  1.52494]
21Feb12_211043| [-0.50587 -0.07929]
21Feb12_211043| [ 0.19700 -0.02597]
21Feb12_211043| [ 0.74440  0.98723]
21Feb12_211043| [ 0.01100 -0.67337]
21Feb12_211043| [ 0.06204  0.35817]
21Feb12_211043| [ 0.26726  0.48263]
21Feb12_211043| [-0.88494 -0.70844]
21Feb12_211043| [-0.84413 -0.69285]
21Feb12_211043| [ 0.45345 -2.08209]
21Feb12_211043| [-0.40021 -0.10894]
21Feb12_211043| [ 2.73392 -0.61867]
21Feb12_211043| [ 1.24710  0.98537]
21Feb12_211043| [ 0.82300  0.72555]
21Feb12_211043| [ 2.06057 -0.06460]
21Feb12_211043| [ 1.26673 -1.23461]
21Feb12_211043| [ 0.42018 -0.49554]
21Feb12_211043| [ 2.61792  1.45873]
21Feb12_211043| [ 0.59144 -1.10854]
21Feb12_211043| [-0.97707  1.48165]]
21Feb12_211043|-- Bias --
21Feb12_211043|[ 0.38902 -0.39861]
21Feb12_211043|Layer 1:
21Feb12_211043|-- Config --
21Feb12_211043|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211043|-- Weights --
21Feb12_211043|[[-0.32012 -0.65699  0.76440  0.52560]
21Feb12_211043| [ 0.44064  0.51440 -0.76282  0.19969]]
21Feb12_211043|-- Bias --
21Feb12_211043|[ 0.04015  0.29509  0.93883 -0.02209]
21Feb12_211043|Layer 2:
21Feb12_211043|-- Config --
21Feb12_211043|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211043|-- Weights --
21Feb12_211043|[[ 2.71531 -0.86969]
21Feb12_211043| [-0.96223  1.09854]
21Feb12_211043| [-0.40245  0.31843]
21Feb12_211043| [-0.02201 -0.31563]]
21Feb12_211043|-- Bias --
21Feb12_211043|[0.38755 0.47351]
21Feb12_211043|Predicting the validation and test data with the Best final individual.
21Feb12_211050| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_211050|-----------  ------------------  --------------------  ----------
21Feb12_211050|Validation         41.22                  12            0.02318
21Feb12_211050|   Test            36.14                  12            0.01485
21Feb12_211050|-------------------- Test #4 --------------------
21Feb12_211050|Best final individual weights
21Feb12_211050|Individual:
21Feb12_211050|-- Constant hidden layers --
21Feb12_211050|False
21Feb12_211050|Layer 0:
21Feb12_211050|-- Config --
21Feb12_211050|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211050|-- Weights --
21Feb12_211050|[[ 0.48141  1.08053]
21Feb12_211050| [-0.62108  0.02214]
21Feb12_211050| [-0.65483  0.88968]
21Feb12_211050| [-0.91839 -0.30848]
21Feb12_211050| [ 0.08504  0.90277]
21Feb12_211050| [ 0.37053  0.38479]
21Feb12_211050| [ 0.40871  1.23967]
21Feb12_211050| [-0.48711  0.45785]
21Feb12_211050| [ 0.96174 -1.07439]
21Feb12_211050| [ 0.06805  0.37322]
21Feb12_211050| [-0.22538  0.98785]
21Feb12_211050| [ 0.28474  0.11466]
21Feb12_211050| [ 0.95618 -1.73991]
21Feb12_211050| [ 0.23280  0.70700]
21Feb12_211050| [ 0.67583  0.28878]
21Feb12_211050| [ 1.10819  0.60307]
21Feb12_211050| [-0.19711 -1.04827]
21Feb12_211050| [-1.50344  1.92408]
21Feb12_211050| [ 0.13970  0.27654]
21Feb12_211050| [-1.13489  1.43482]
21Feb12_211050| [ 0.90793  0.09290]
21Feb12_211050| [ 0.28340 -0.20824]
21Feb12_211050| [-0.31490 -0.27430]
21Feb12_211050| [-0.04291 -0.55918]
21Feb12_211050| [-0.57216 -0.33220]
21Feb12_211050| [-0.18320 -2.15242]
21Feb12_211050| [ 1.41196  0.46552]
21Feb12_211050| [ 1.35793  0.32961]
21Feb12_211050| [-1.10509 -0.07299]
21Feb12_211050| [ 1.66389 -0.38715]
21Feb12_211050| [ 0.41781 -1.07053]
21Feb12_211050| [-0.07102 -0.59571]
21Feb12_211050| [-1.06163  0.25294]
21Feb12_211050| [-0.05236 -0.29352]
21Feb12_211050| [-0.07774  2.36904]
21Feb12_211050| [ 0.69814 -0.02507]
21Feb12_211050| [ 1.73983 -1.31095]
21Feb12_211050| [ 1.30637  1.52494]
21Feb12_211050| [-0.50587 -0.07929]
21Feb12_211050| [ 0.19700 -0.02597]
21Feb12_211050| [ 0.74440  0.98723]
21Feb12_211050| [ 0.01100 -0.67337]
21Feb12_211050| [ 0.06204  0.35817]
21Feb12_211050| [ 0.26726  0.48263]
21Feb12_211050| [-0.88494 -0.70844]
21Feb12_211050| [-0.84413 -0.69285]
21Feb12_211050| [ 0.45345 -2.08209]
21Feb12_211050| [-0.40021 -0.10894]
21Feb12_211050| [ 2.73392 -0.61867]
21Feb12_211050| [ 1.24710  0.98537]
21Feb12_211050| [ 0.82300  0.72555]
21Feb12_211050| [ 2.06057 -0.06460]
21Feb12_211050| [ 1.26673 -1.23461]
21Feb12_211050| [ 0.42018 -0.49554]
21Feb12_211050| [ 2.61792  1.45873]
21Feb12_211050| [ 0.59144 -1.10854]
21Feb12_211050| [-0.97707  1.48165]]
21Feb12_211050|-- Bias --
21Feb12_211050|[ 0.38902 -0.39861]
21Feb12_211050|Layer 1:
21Feb12_211050|-- Config --
21Feb12_211050|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211050|-- Weights --
21Feb12_211050|[[-0.32012 -0.65699  0.76440  0.52560]
21Feb12_211050| [ 0.44064  0.51440 -0.76282  0.19969]]
21Feb12_211050|-- Bias --
21Feb12_211050|[ 0.04015  0.29509  0.93883 -0.02209]
21Feb12_211050|Layer 2:
21Feb12_211050|-- Config --
21Feb12_211050|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211050|-- Weights --
21Feb12_211050|[[ 2.71531 -0.86969]
21Feb12_211050| [-0.96223  1.09854]
21Feb12_211050| [-0.40245  0.31843]
21Feb12_211050| [-0.02201 -0.31563]]
21Feb12_211050|-- Bias --
21Feb12_211050|[0.38755 0.47351]
21Feb12_211050|Predicting the validation and test data with the Best final individual.
21Feb12_211058| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_211058|-----------  ------------------  --------------------  ----------
21Feb12_211058|Validation         41.22                  12            0.02318
21Feb12_211058|   Test            36.40                  12            0.00000
21Feb12_211058|-------------------- Test #5 --------------------
21Feb12_211058|Best final individual weights
21Feb12_211058|Individual:
21Feb12_211058|-- Constant hidden layers --
21Feb12_211058|False
21Feb12_211058|Layer 0:
21Feb12_211058|-- Config --
21Feb12_211058|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211058|-- Weights --
21Feb12_211058|[[ 0.48141  1.08053]
21Feb12_211058| [-0.62108  0.02214]
21Feb12_211058| [-0.65483  0.88968]
21Feb12_211058| [-0.91839 -0.30848]
21Feb12_211058| [ 0.08504  0.90277]
21Feb12_211058| [ 0.37053  0.38479]
21Feb12_211058| [ 0.40871  1.23967]
21Feb12_211058| [-0.48711  0.45785]
21Feb12_211058| [ 0.96174 -1.07439]
21Feb12_211058| [ 0.06805  0.37322]
21Feb12_211058| [-0.22538  0.98785]
21Feb12_211058| [ 0.28474  0.11466]
21Feb12_211058| [ 0.95618 -1.73991]
21Feb12_211058| [ 0.23280  0.70700]
21Feb12_211058| [ 0.67583  0.28878]
21Feb12_211058| [ 1.10819  0.60307]
21Feb12_211058| [-0.19711 -1.04827]
21Feb12_211058| [-1.50344  1.92408]
21Feb12_211058| [ 0.13970  0.27654]
21Feb12_211058| [-1.13489  1.43482]
21Feb12_211058| [ 0.90793  0.09290]
21Feb12_211058| [ 0.28340 -0.20824]
21Feb12_211058| [-0.31490 -0.27430]
21Feb12_211058| [-0.04291 -0.55918]
21Feb12_211058| [-0.57216 -0.33220]
21Feb12_211058| [-0.18320 -2.15242]
21Feb12_211058| [ 1.41196  0.46552]
21Feb12_211058| [ 1.35793  0.32961]
21Feb12_211058| [-1.10509 -0.07299]
21Feb12_211058| [ 1.66389 -0.38715]
21Feb12_211058| [ 0.41781 -1.07053]
21Feb12_211058| [-0.07102 -0.59571]
21Feb12_211058| [-1.06163  0.25294]
21Feb12_211058| [-0.05236 -0.29352]
21Feb12_211058| [-0.07774  2.36904]
21Feb12_211058| [ 0.69814 -0.02507]
21Feb12_211058| [ 1.73983 -1.31095]
21Feb12_211058| [ 1.30637  1.52494]
21Feb12_211058| [-0.50587 -0.07929]
21Feb12_211058| [ 0.19700 -0.02597]
21Feb12_211058| [ 0.74440  0.98723]
21Feb12_211058| [ 0.01100 -0.67337]
21Feb12_211058| [ 0.06204  0.35817]
21Feb12_211058| [ 0.26726  0.48263]
21Feb12_211058| [-0.88494 -0.70844]
21Feb12_211058| [-0.84413 -0.69285]
21Feb12_211058| [ 0.45345 -2.08209]
21Feb12_211058| [-0.40021 -0.10894]
21Feb12_211058| [ 2.73392 -0.61867]
21Feb12_211058| [ 1.24710  0.98537]
21Feb12_211058| [ 0.82300  0.72555]
21Feb12_211058| [ 2.06057 -0.06460]
21Feb12_211058| [ 1.26673 -1.23461]
21Feb12_211058| [ 0.42018 -0.49554]
21Feb12_211058| [ 2.61792  1.45873]
21Feb12_211058| [ 0.59144 -1.10854]
21Feb12_211058| [-0.97707  1.48165]]
21Feb12_211058|-- Bias --
21Feb12_211058|[ 0.38902 -0.39861]
21Feb12_211058|Layer 1:
21Feb12_211058|-- Config --
21Feb12_211058|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211058|-- Weights --
21Feb12_211058|[[-0.32012 -0.65699  0.76440  0.52560]
21Feb12_211058| [ 0.44064  0.51440 -0.76282  0.19969]]
21Feb12_211058|-- Bias --
21Feb12_211058|[ 0.04015  0.29509  0.93883 -0.02209]
21Feb12_211058|Layer 2:
21Feb12_211058|-- Config --
21Feb12_211058|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211058|-- Weights --
21Feb12_211058|[[ 2.71531 -0.86969]
21Feb12_211058| [-0.96223  1.09854]
21Feb12_211058| [-0.40245  0.31843]
21Feb12_211058| [-0.02201 -0.31563]]
21Feb12_211058|-- Bias --
21Feb12_211058|[0.38755 0.47351]
21Feb12_211058|Predicting the validation and test data with the Best final individual.
21Feb12_211105| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_211105|-----------  ------------------  --------------------  ----------
21Feb12_211105|Validation         41.83                  12            0.00775
21Feb12_211105|   Test            36.32                  12            0.01188
21Feb12_211105|-------------------- Test #6 --------------------
21Feb12_211105|Best final individual weights
21Feb12_211105|Individual:
21Feb12_211105|-- Constant hidden layers --
21Feb12_211105|False
21Feb12_211105|Layer 0:
21Feb12_211105|-- Config --
21Feb12_211105|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211105|-- Weights --
21Feb12_211105|[[ 0.48141  1.08053]
21Feb12_211105| [-0.62108  0.02214]
21Feb12_211105| [-0.65483  0.88968]
21Feb12_211105| [-0.91839 -0.30848]
21Feb12_211105| [ 0.08504  0.90277]
21Feb12_211105| [ 0.37053  0.38479]
21Feb12_211105| [ 0.40871  1.23967]
21Feb12_211105| [-0.48711  0.45785]
21Feb12_211105| [ 0.96174 -1.07439]
21Feb12_211105| [ 0.06805  0.37322]
21Feb12_211105| [-0.22538  0.98785]
21Feb12_211105| [ 0.28474  0.11466]
21Feb12_211105| [ 0.95618 -1.73991]
21Feb12_211105| [ 0.23280  0.70700]
21Feb12_211105| [ 0.67583  0.28878]
21Feb12_211105| [ 1.10819  0.60307]
21Feb12_211105| [-0.19711 -1.04827]
21Feb12_211105| [-1.50344  1.92408]
21Feb12_211105| [ 0.13970  0.27654]
21Feb12_211105| [-1.13489  1.43482]
21Feb12_211105| [ 0.90793  0.09290]
21Feb12_211105| [ 0.28340 -0.20824]
21Feb12_211105| [-0.31490 -0.27430]
21Feb12_211105| [-0.04291 -0.55918]
21Feb12_211105| [-0.57216 -0.33220]
21Feb12_211105| [-0.18320 -2.15242]
21Feb12_211105| [ 1.41196  0.46552]
21Feb12_211105| [ 1.35793  0.32961]
21Feb12_211105| [-1.10509 -0.07299]
21Feb12_211105| [ 1.66389 -0.38715]
21Feb12_211105| [ 0.41781 -1.07053]
21Feb12_211105| [-0.07102 -0.59571]
21Feb12_211105| [-1.06163  0.25294]
21Feb12_211105| [-0.05236 -0.29352]
21Feb12_211105| [-0.07774  2.36904]
21Feb12_211105| [ 0.69814 -0.02507]
21Feb12_211105| [ 1.73983 -1.31095]
21Feb12_211105| [ 1.30637  1.52494]
21Feb12_211105| [-0.50587 -0.07929]
21Feb12_211105| [ 0.19700 -0.02597]
21Feb12_211105| [ 0.74440  0.98723]
21Feb12_211105| [ 0.01100 -0.67337]
21Feb12_211105| [ 0.06204  0.35817]
21Feb12_211105| [ 0.26726  0.48263]
21Feb12_211105| [-0.88494 -0.70844]
21Feb12_211105| [-0.84413 -0.69285]
21Feb12_211105| [ 0.45345 -2.08209]
21Feb12_211105| [-0.40021 -0.10894]
21Feb12_211105| [ 2.73392 -0.61867]
21Feb12_211105| [ 1.24710  0.98537]
21Feb12_211105| [ 0.82300  0.72555]
21Feb12_211105| [ 2.06057 -0.06460]
21Feb12_211105| [ 1.26673 -1.23461]
21Feb12_211105| [ 0.42018 -0.49554]
21Feb12_211105| [ 2.61792  1.45873]
21Feb12_211105| [ 0.59144 -1.10854]
21Feb12_211105| [-0.97707  1.48165]]
21Feb12_211105|-- Bias --
21Feb12_211105|[ 0.38902 -0.39861]
21Feb12_211105|Layer 1:
21Feb12_211105|-- Config --
21Feb12_211105|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211105|-- Weights --
21Feb12_211105|[[-0.32012 -0.65699  0.76440  0.52560]
21Feb12_211105| [ 0.44064  0.51440 -0.76282  0.19969]]
21Feb12_211105|-- Bias --
21Feb12_211105|[ 0.04015  0.29509  0.93883 -0.02209]
21Feb12_211105|Layer 2:
21Feb12_211105|-- Config --
21Feb12_211105|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211105|-- Weights --
21Feb12_211105|[[ 2.71531 -0.86969]
21Feb12_211105| [-0.96223  1.09854]
21Feb12_211105| [-0.40245  0.31843]
21Feb12_211105| [-0.02201 -0.31563]]
21Feb12_211105|-- Bias --
21Feb12_211105|[0.38755 0.47351]
21Feb12_211105|Predicting the validation and test data with the Best final individual.
21Feb12_211112| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_211112|-----------  ------------------  --------------------  ----------
21Feb12_211112|Validation         41.83                  12            0.00517
21Feb12_211112|   Test            36.40                  12            0.00892
21Feb12_211112|-------------------- Test #7 --------------------
21Feb12_211112|Best final individual weights
21Feb12_211112|Individual:
21Feb12_211112|-- Constant hidden layers --
21Feb12_211112|False
21Feb12_211112|Layer 0:
21Feb12_211112|-- Config --
21Feb12_211112|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211112|-- Weights --
21Feb12_211112|[[ 0.48141  1.08053]
21Feb12_211112| [-0.62108  0.02214]
21Feb12_211112| [-0.65483  0.88968]
21Feb12_211112| [-0.91839 -0.30848]
21Feb12_211112| [ 0.08504  0.90277]
21Feb12_211112| [ 0.37053  0.38479]
21Feb12_211112| [ 0.40871  1.23967]
21Feb12_211112| [-0.48711  0.45785]
21Feb12_211112| [ 0.96174 -1.07439]
21Feb12_211112| [ 0.06805  0.37322]
21Feb12_211112| [-0.22538  0.98785]
21Feb12_211112| [ 0.28474  0.11466]
21Feb12_211112| [ 0.95618 -1.73991]
21Feb12_211112| [ 0.23280  0.70700]
21Feb12_211112| [ 0.67583  0.28878]
21Feb12_211112| [ 1.10819  0.60307]
21Feb12_211112| [-0.19711 -1.04827]
21Feb12_211112| [-1.50344  1.92408]
21Feb12_211112| [ 0.13970  0.27654]
21Feb12_211112| [-1.13489  1.43482]
21Feb12_211112| [ 0.90793  0.09290]
21Feb12_211112| [ 0.28340 -0.20824]
21Feb12_211112| [-0.31490 -0.27430]
21Feb12_211112| [-0.04291 -0.55918]
21Feb12_211112| [-0.57216 -0.33220]
21Feb12_211112| [-0.18320 -2.15242]
21Feb12_211112| [ 1.41196  0.46552]
21Feb12_211112| [ 1.35793  0.32961]
21Feb12_211112| [-1.10509 -0.07299]
21Feb12_211112| [ 1.66389 -0.38715]
21Feb12_211112| [ 0.41781 -1.07053]
21Feb12_211112| [-0.07102 -0.59571]
21Feb12_211112| [-1.06163  0.25294]
21Feb12_211112| [-0.05236 -0.29352]
21Feb12_211112| [-0.07774  2.36904]
21Feb12_211112| [ 0.69814 -0.02507]
21Feb12_211112| [ 1.73983 -1.31095]
21Feb12_211112| [ 1.30637  1.52494]
21Feb12_211112| [-0.50587 -0.07929]
21Feb12_211112| [ 0.19700 -0.02597]
21Feb12_211112| [ 0.74440  0.98723]
21Feb12_211112| [ 0.01100 -0.67337]
21Feb12_211112| [ 0.06204  0.35817]
21Feb12_211112| [ 0.26726  0.48263]
21Feb12_211112| [-0.88494 -0.70844]
21Feb12_211112| [-0.84413 -0.69285]
21Feb12_211112| [ 0.45345 -2.08209]
21Feb12_211112| [-0.40021 -0.10894]
21Feb12_211112| [ 2.73392 -0.61867]
21Feb12_211112| [ 1.24710  0.98537]
21Feb12_211112| [ 0.82300  0.72555]
21Feb12_211112| [ 2.06057 -0.06460]
21Feb12_211112| [ 1.26673 -1.23461]
21Feb12_211112| [ 0.42018 -0.49554]
21Feb12_211112| [ 2.61792  1.45873]
21Feb12_211112| [ 0.59144 -1.10854]
21Feb12_211112| [-0.97707  1.48165]]
21Feb12_211112|-- Bias --
21Feb12_211112|[ 0.38902 -0.39861]
21Feb12_211112|Layer 1:
21Feb12_211112|-- Config --
21Feb12_211112|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211112|-- Weights --
21Feb12_211112|[[-0.32012 -0.65699  0.76440  0.52560]
21Feb12_211112| [ 0.44064  0.51440 -0.76282  0.19969]]
21Feb12_211112|-- Bias --
21Feb12_211112|[ 0.04015  0.29509  0.93883 -0.02209]
21Feb12_211112|Layer 2:
21Feb12_211112|-- Config --
21Feb12_211112|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211112|-- Weights --
21Feb12_211112|[[ 2.71531 -0.86969]
21Feb12_211112| [-0.96223  1.09854]
21Feb12_211112| [-0.40245  0.31843]
21Feb12_211112| [-0.02201 -0.31563]]
21Feb12_211112|-- Bias --
21Feb12_211112|[0.38755 0.47351]
21Feb12_211112|Predicting the validation and test data with the Best final individual.
21Feb12_211120| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_211120|-----------  ------------------  --------------------  ----------
21Feb12_211120|Validation         41.39                  12            0.01805
21Feb12_211120|   Test            36.40                  12            0.00892
21Feb12_211120|-------------------- Test #8 --------------------
21Feb12_211120|Best final individual weights
21Feb12_211120|Individual:
21Feb12_211120|-- Constant hidden layers --
21Feb12_211120|False
21Feb12_211120|Layer 0:
21Feb12_211120|-- Config --
21Feb12_211120|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211120|-- Weights --
21Feb12_211120|[[ 0.48141  1.08053]
21Feb12_211120| [-0.62108  0.02214]
21Feb12_211120| [-0.65483  0.88968]
21Feb12_211120| [-0.91839 -0.30848]
21Feb12_211120| [ 0.08504  0.90277]
21Feb12_211120| [ 0.37053  0.38479]
21Feb12_211120| [ 0.40871  1.23967]
21Feb12_211120| [-0.48711  0.45785]
21Feb12_211120| [ 0.96174 -1.07439]
21Feb12_211120| [ 0.06805  0.37322]
21Feb12_211120| [-0.22538  0.98785]
21Feb12_211120| [ 0.28474  0.11466]
21Feb12_211120| [ 0.95618 -1.73991]
21Feb12_211120| [ 0.23280  0.70700]
21Feb12_211120| [ 0.67583  0.28878]
21Feb12_211120| [ 1.10819  0.60307]
21Feb12_211120| [-0.19711 -1.04827]
21Feb12_211120| [-1.50344  1.92408]
21Feb12_211120| [ 0.13970  0.27654]
21Feb12_211120| [-1.13489  1.43482]
21Feb12_211120| [ 0.90793  0.09290]
21Feb12_211120| [ 0.28340 -0.20824]
21Feb12_211120| [-0.31490 -0.27430]
21Feb12_211120| [-0.04291 -0.55918]
21Feb12_211120| [-0.57216 -0.33220]
21Feb12_211120| [-0.18320 -2.15242]
21Feb12_211120| [ 1.41196  0.46552]
21Feb12_211120| [ 1.35793  0.32961]
21Feb12_211120| [-1.10509 -0.07299]
21Feb12_211120| [ 1.66389 -0.38715]
21Feb12_211120| [ 0.41781 -1.07053]
21Feb12_211120| [-0.07102 -0.59571]
21Feb12_211120| [-1.06163  0.25294]
21Feb12_211120| [-0.05236 -0.29352]
21Feb12_211120| [-0.07774  2.36904]
21Feb12_211120| [ 0.69814 -0.02507]
21Feb12_211120| [ 1.73983 -1.31095]
21Feb12_211120| [ 1.30637  1.52494]
21Feb12_211120| [-0.50587 -0.07929]
21Feb12_211120| [ 0.19700 -0.02597]
21Feb12_211120| [ 0.74440  0.98723]
21Feb12_211120| [ 0.01100 -0.67337]
21Feb12_211120| [ 0.06204  0.35817]
21Feb12_211120| [ 0.26726  0.48263]
21Feb12_211120| [-0.88494 -0.70844]
21Feb12_211120| [-0.84413 -0.69285]
21Feb12_211120| [ 0.45345 -2.08209]
21Feb12_211120| [-0.40021 -0.10894]
21Feb12_211120| [ 2.73392 -0.61867]
21Feb12_211120| [ 1.24710  0.98537]
21Feb12_211120| [ 0.82300  0.72555]
21Feb12_211120| [ 2.06057 -0.06460]
21Feb12_211120| [ 1.26673 -1.23461]
21Feb12_211120| [ 0.42018 -0.49554]
21Feb12_211120| [ 2.61792  1.45873]
21Feb12_211120| [ 0.59144 -1.10854]
21Feb12_211120| [-0.97707  1.48165]]
21Feb12_211120|-- Bias --
21Feb12_211120|[ 0.38902 -0.39861]
21Feb12_211120|Layer 1:
21Feb12_211120|-- Config --
21Feb12_211120|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211120|-- Weights --
21Feb12_211120|[[-0.32012 -0.65699  0.76440  0.52560]
21Feb12_211120| [ 0.44064  0.51440 -0.76282  0.19969]]
21Feb12_211120|-- Bias --
21Feb12_211120|[ 0.04015  0.29509  0.93883 -0.02209]
21Feb12_211120|Layer 2:
21Feb12_211120|-- Config --
21Feb12_211120|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211120|-- Weights --
21Feb12_211120|[[ 2.71531 -0.86969]
21Feb12_211120| [-0.96223  1.09854]
21Feb12_211120| [-0.40245  0.31843]
21Feb12_211120| [-0.02201 -0.31563]]
21Feb12_211120|-- Bias --
21Feb12_211120|[0.38755 0.47351]
21Feb12_211120|Predicting the validation and test data with the Best final individual.
21Feb12_211127| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_211127|-----------  ------------------  --------------------  ----------
21Feb12_211127|Validation         41.39                  12            0.01805
21Feb12_211127|   Test            36.75                  12            0.00000
21Feb12_211127|-------------------- Test #9 --------------------
21Feb12_211127|Best final individual weights
21Feb12_211127|Individual:
21Feb12_211127|-- Constant hidden layers --
21Feb12_211127|False
21Feb12_211127|Layer 0:
21Feb12_211127|-- Config --
21Feb12_211127|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211127|-- Weights --
21Feb12_211127|[[ 0.48141  1.08053]
21Feb12_211127| [-0.62108  0.02214]
21Feb12_211127| [-0.65483  0.88968]
21Feb12_211127| [-0.91839 -0.30848]
21Feb12_211127| [ 0.08504  0.90277]
21Feb12_211127| [ 0.37053  0.38479]
21Feb12_211127| [ 0.40871  1.23967]
21Feb12_211127| [-0.48711  0.45785]
21Feb12_211127| [ 0.96174 -1.07439]
21Feb12_211127| [ 0.06805  0.37322]
21Feb12_211127| [-0.22538  0.98785]
21Feb12_211127| [ 0.28474  0.11466]
21Feb12_211127| [ 0.95618 -1.73991]
21Feb12_211127| [ 0.23280  0.70700]
21Feb12_211127| [ 0.67583  0.28878]
21Feb12_211127| [ 1.10819  0.60307]
21Feb12_211127| [-0.19711 -1.04827]
21Feb12_211127| [-1.50344  1.92408]
21Feb12_211127| [ 0.13970  0.27654]
21Feb12_211127| [-1.13489  1.43482]
21Feb12_211127| [ 0.90793  0.09290]
21Feb12_211127| [ 0.28340 -0.20824]
21Feb12_211127| [-0.31490 -0.27430]
21Feb12_211127| [-0.04291 -0.55918]
21Feb12_211127| [-0.57216 -0.33220]
21Feb12_211127| [-0.18320 -2.15242]
21Feb12_211127| [ 1.41196  0.46552]
21Feb12_211127| [ 1.35793  0.32961]
21Feb12_211127| [-1.10509 -0.07299]
21Feb12_211127| [ 1.66389 -0.38715]
21Feb12_211127| [ 0.41781 -1.07053]
21Feb12_211127| [-0.07102 -0.59571]
21Feb12_211127| [-1.06163  0.25294]
21Feb12_211127| [-0.05236 -0.29352]
21Feb12_211127| [-0.07774  2.36904]
21Feb12_211127| [ 0.69814 -0.02507]
21Feb12_211127| [ 1.73983 -1.31095]
21Feb12_211127| [ 1.30637  1.52494]
21Feb12_211127| [-0.50587 -0.07929]
21Feb12_211127| [ 0.19700 -0.02597]
21Feb12_211127| [ 0.74440  0.98723]
21Feb12_211127| [ 0.01100 -0.67337]
21Feb12_211127| [ 0.06204  0.35817]
21Feb12_211127| [ 0.26726  0.48263]
21Feb12_211127| [-0.88494 -0.70844]
21Feb12_211127| [-0.84413 -0.69285]
21Feb12_211127| [ 0.45345 -2.08209]
21Feb12_211127| [-0.40021 -0.10894]
21Feb12_211127| [ 2.73392 -0.61867]
21Feb12_211127| [ 1.24710  0.98537]
21Feb12_211127| [ 0.82300  0.72555]
21Feb12_211127| [ 2.06057 -0.06460]
21Feb12_211127| [ 1.26673 -1.23461]
21Feb12_211127| [ 0.42018 -0.49554]
21Feb12_211127| [ 2.61792  1.45873]
21Feb12_211127| [ 0.59144 -1.10854]
21Feb12_211127| [-0.97707  1.48165]]
21Feb12_211127|-- Bias --
21Feb12_211127|[ 0.38902 -0.39861]
21Feb12_211127|Layer 1:
21Feb12_211127|-- Config --
21Feb12_211127|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211127|-- Weights --
21Feb12_211127|[[-0.32012 -0.65699  0.76440  0.52560]
21Feb12_211127| [ 0.44064  0.51440 -0.76282  0.19969]]
21Feb12_211127|-- Bias --
21Feb12_211127|[ 0.04015  0.29509  0.93883 -0.02209]
21Feb12_211127|Layer 2:
21Feb12_211127|-- Config --
21Feb12_211127|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211127|-- Weights --
21Feb12_211127|[[ 2.71531 -0.86969]
21Feb12_211127| [-0.96223  1.09854]
21Feb12_211127| [-0.40245  0.31843]
21Feb12_211127| [-0.02201 -0.31563]]
21Feb12_211127|-- Bias --
21Feb12_211127|[0.38755 0.47351]
21Feb12_211127|Predicting the validation and test data with the Best final individual.
21Feb12_211135| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_211135|-----------  ------------------  --------------------  ----------
21Feb12_211135|Validation         41.74                  12            0.00775
21Feb12_211135|   Test            36.49                  12            0.01187
21Feb12_211135|-------------------- Test #10 --------------------
21Feb12_211135|Best final individual weights
21Feb12_211135|Individual:
21Feb12_211135|-- Constant hidden layers --
21Feb12_211135|False
21Feb12_211135|Layer 0:
21Feb12_211135|-- Config --
21Feb12_211135|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211135|-- Weights --
21Feb12_211135|[[ 0.48141  1.08053]
21Feb12_211135| [-0.62108  0.02214]
21Feb12_211135| [-0.65483  0.88968]
21Feb12_211135| [-0.91839 -0.30848]
21Feb12_211135| [ 0.08504  0.90277]
21Feb12_211135| [ 0.37053  0.38479]
21Feb12_211135| [ 0.40871  1.23967]
21Feb12_211135| [-0.48711  0.45785]
21Feb12_211135| [ 0.96174 -1.07439]
21Feb12_211135| [ 0.06805  0.37322]
21Feb12_211135| [-0.22538  0.98785]
21Feb12_211135| [ 0.28474  0.11466]
21Feb12_211135| [ 0.95618 -1.73991]
21Feb12_211135| [ 0.23280  0.70700]
21Feb12_211135| [ 0.67583  0.28878]
21Feb12_211135| [ 1.10819  0.60307]
21Feb12_211135| [-0.19711 -1.04827]
21Feb12_211135| [-1.50344  1.92408]
21Feb12_211135| [ 0.13970  0.27654]
21Feb12_211135| [-1.13489  1.43482]
21Feb12_211135| [ 0.90793  0.09290]
21Feb12_211135| [ 0.28340 -0.20824]
21Feb12_211135| [-0.31490 -0.27430]
21Feb12_211135| [-0.04291 -0.55918]
21Feb12_211135| [-0.57216 -0.33220]
21Feb12_211135| [-0.18320 -2.15242]
21Feb12_211135| [ 1.41196  0.46552]
21Feb12_211135| [ 1.35793  0.32961]
21Feb12_211135| [-1.10509 -0.07299]
21Feb12_211135| [ 1.66389 -0.38715]
21Feb12_211135| [ 0.41781 -1.07053]
21Feb12_211135| [-0.07102 -0.59571]
21Feb12_211135| [-1.06163  0.25294]
21Feb12_211135| [-0.05236 -0.29352]
21Feb12_211135| [-0.07774  2.36904]
21Feb12_211135| [ 0.69814 -0.02507]
21Feb12_211135| [ 1.73983 -1.31095]
21Feb12_211135| [ 1.30637  1.52494]
21Feb12_211135| [-0.50587 -0.07929]
21Feb12_211135| [ 0.19700 -0.02597]
21Feb12_211135| [ 0.74440  0.98723]
21Feb12_211135| [ 0.01100 -0.67337]
21Feb12_211135| [ 0.06204  0.35817]
21Feb12_211135| [ 0.26726  0.48263]
21Feb12_211135| [-0.88494 -0.70844]
21Feb12_211135| [-0.84413 -0.69285]
21Feb12_211135| [ 0.45345 -2.08209]
21Feb12_211135| [-0.40021 -0.10894]
21Feb12_211135| [ 2.73392 -0.61867]
21Feb12_211135| [ 1.24710  0.98537]
21Feb12_211135| [ 0.82300  0.72555]
21Feb12_211135| [ 2.06057 -0.06460]
21Feb12_211135| [ 1.26673 -1.23461]
21Feb12_211135| [ 0.42018 -0.49554]
21Feb12_211135| [ 2.61792  1.45873]
21Feb12_211135| [ 0.59144 -1.10854]
21Feb12_211135| [-0.97707  1.48165]]
21Feb12_211135|-- Bias --
21Feb12_211135|[ 0.38902 -0.39861]
21Feb12_211135|Layer 1:
21Feb12_211135|-- Config --
21Feb12_211135|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211135|-- Weights --
21Feb12_211135|[[-0.32012 -0.65699  0.76440  0.52560]
21Feb12_211135| [ 0.44064  0.51440 -0.76282  0.19969]]
21Feb12_211135|-- Bias --
21Feb12_211135|[ 0.04015  0.29509  0.93883 -0.02209]
21Feb12_211135|Layer 2:
21Feb12_211135|-- Config --
21Feb12_211135|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211135|-- Weights --
21Feb12_211135|[[ 2.71531 -0.86969]
21Feb12_211135| [-0.96223  1.09854]
21Feb12_211135| [-0.40245  0.31843]
21Feb12_211135| [-0.02201 -0.31563]]
21Feb12_211135|-- Bias --
21Feb12_211135|[0.38755 0.47351]
21Feb12_211135|Predicting the validation and test data with the Best final individual.
21Feb12_211142| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_211142|-----------  ------------------  --------------------  ----------
21Feb12_211142|Validation         42.00                  12            0.00000
21Feb12_211142|   Test            36.49                  12            0.01187
21Feb12_211142|-------------------- Test #11 --------------------
21Feb12_211142|Best final individual weights
21Feb12_211142|Individual:
21Feb12_211142|-- Constant hidden layers --
21Feb12_211142|False
21Feb12_211142|Layer 0:
21Feb12_211142|-- Config --
21Feb12_211142|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211142|-- Weights --
21Feb12_211142|[[ 0.48141  1.08053]
21Feb12_211142| [-0.62108  0.02214]
21Feb12_211142| [-0.65483  0.88968]
21Feb12_211142| [-0.91839 -0.30848]
21Feb12_211142| [ 0.08504  0.90277]
21Feb12_211142| [ 0.37053  0.38479]
21Feb12_211142| [ 0.40871  1.23967]
21Feb12_211142| [-0.48711  0.45785]
21Feb12_211142| [ 0.96174 -1.07439]
21Feb12_211142| [ 0.06805  0.37322]
21Feb12_211142| [-0.22538  0.98785]
21Feb12_211142| [ 0.28474  0.11466]
21Feb12_211142| [ 0.95618 -1.73991]
21Feb12_211142| [ 0.23280  0.70700]
21Feb12_211142| [ 0.67583  0.28878]
21Feb12_211142| [ 1.10819  0.60307]
21Feb12_211142| [-0.19711 -1.04827]
21Feb12_211142| [-1.50344  1.92408]
21Feb12_211142| [ 0.13970  0.27654]
21Feb12_211142| [-1.13489  1.43482]
21Feb12_211142| [ 0.90793  0.09290]
21Feb12_211142| [ 0.28340 -0.20824]
21Feb12_211142| [-0.31490 -0.27430]
21Feb12_211142| [-0.04291 -0.55918]
21Feb12_211142| [-0.57216 -0.33220]
21Feb12_211142| [-0.18320 -2.15242]
21Feb12_211142| [ 1.41196  0.46552]
21Feb12_211142| [ 1.35793  0.32961]
21Feb12_211142| [-1.10509 -0.07299]
21Feb12_211142| [ 1.66389 -0.38715]
21Feb12_211142| [ 0.41781 -1.07053]
21Feb12_211142| [-0.07102 -0.59571]
21Feb12_211142| [-1.06163  0.25294]
21Feb12_211142| [-0.05236 -0.29352]
21Feb12_211142| [-0.07774  2.36904]
21Feb12_211142| [ 0.69814 -0.02507]
21Feb12_211142| [ 1.73983 -1.31095]
21Feb12_211142| [ 1.30637  1.52494]
21Feb12_211142| [-0.50587 -0.07929]
21Feb12_211142| [ 0.19700 -0.02597]
21Feb12_211142| [ 0.74440  0.98723]
21Feb12_211142| [ 0.01100 -0.67337]
21Feb12_211142| [ 0.06204  0.35817]
21Feb12_211142| [ 0.26726  0.48263]
21Feb12_211142| [-0.88494 -0.70844]
21Feb12_211142| [-0.84413 -0.69285]
21Feb12_211142| [ 0.45345 -2.08209]
21Feb12_211142| [-0.40021 -0.10894]
21Feb12_211142| [ 2.73392 -0.61867]
21Feb12_211142| [ 1.24710  0.98537]
21Feb12_211142| [ 0.82300  0.72555]
21Feb12_211142| [ 2.06057 -0.06460]
21Feb12_211142| [ 1.26673 -1.23461]
21Feb12_211142| [ 0.42018 -0.49554]
21Feb12_211142| [ 2.61792  1.45873]
21Feb12_211142| [ 0.59144 -1.10854]
21Feb12_211142| [-0.97707  1.48165]]
21Feb12_211142|-- Bias --
21Feb12_211142|[ 0.38902 -0.39861]
21Feb12_211142|Layer 1:
21Feb12_211142|-- Config --
21Feb12_211142|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211142|-- Weights --
21Feb12_211142|[[-0.32012 -0.65699  0.76440  0.52560]
21Feb12_211142| [ 0.44064  0.51440 -0.76282  0.19969]]
21Feb12_211142|-- Bias --
21Feb12_211142|[ 0.04015  0.29509  0.93883 -0.02209]
21Feb12_211142|Layer 2:
21Feb12_211142|-- Config --
21Feb12_211142|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211142|-- Weights --
21Feb12_211142|[[ 2.71531 -0.86969]
21Feb12_211142| [-0.96223  1.09854]
21Feb12_211142| [-0.40245  0.31843]
21Feb12_211142| [-0.02201 -0.31563]]
21Feb12_211142|-- Bias --
21Feb12_211142|[0.38755 0.47351]
21Feb12_211142|Predicting the validation and test data with the Best final individual.
21Feb12_211150| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_211150|-----------  ------------------  --------------------  ----------
21Feb12_211150|Validation         41.39                  12            0.02061
21Feb12_211150|   Test            36.14                  12            0.01190
21Feb12_211150|-------------------- Test #12 --------------------
21Feb12_211150|Best final individual weights
21Feb12_211150|Individual:
21Feb12_211150|-- Constant hidden layers --
21Feb12_211150|False
21Feb12_211150|Layer 0:
21Feb12_211150|-- Config --
21Feb12_211150|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211150|-- Weights --
21Feb12_211150|[[ 0.48141  1.08053]
21Feb12_211150| [-0.62108  0.02214]
21Feb12_211150| [-0.65483  0.88968]
21Feb12_211150| [-0.91839 -0.30848]
21Feb12_211150| [ 0.08504  0.90277]
21Feb12_211150| [ 0.37053  0.38479]
21Feb12_211150| [ 0.40871  1.23967]
21Feb12_211150| [-0.48711  0.45785]
21Feb12_211150| [ 0.96174 -1.07439]
21Feb12_211150| [ 0.06805  0.37322]
21Feb12_211150| [-0.22538  0.98785]
21Feb12_211150| [ 0.28474  0.11466]
21Feb12_211150| [ 0.95618 -1.73991]
21Feb12_211150| [ 0.23280  0.70700]
21Feb12_211150| [ 0.67583  0.28878]
21Feb12_211150| [ 1.10819  0.60307]
21Feb12_211150| [-0.19711 -1.04827]
21Feb12_211150| [-1.50344  1.92408]
21Feb12_211150| [ 0.13970  0.27654]
21Feb12_211150| [-1.13489  1.43482]
21Feb12_211150| [ 0.90793  0.09290]
21Feb12_211150| [ 0.28340 -0.20824]
21Feb12_211150| [-0.31490 -0.27430]
21Feb12_211150| [-0.04291 -0.55918]
21Feb12_211150| [-0.57216 -0.33220]
21Feb12_211150| [-0.18320 -2.15242]
21Feb12_211150| [ 1.41196  0.46552]
21Feb12_211150| [ 1.35793  0.32961]
21Feb12_211150| [-1.10509 -0.07299]
21Feb12_211150| [ 1.66389 -0.38715]
21Feb12_211150| [ 0.41781 -1.07053]
21Feb12_211150| [-0.07102 -0.59571]
21Feb12_211150| [-1.06163  0.25294]
21Feb12_211150| [-0.05236 -0.29352]
21Feb12_211150| [-0.07774  2.36904]
21Feb12_211150| [ 0.69814 -0.02507]
21Feb12_211150| [ 1.73983 -1.31095]
21Feb12_211150| [ 1.30637  1.52494]
21Feb12_211150| [-0.50587 -0.07929]
21Feb12_211150| [ 0.19700 -0.02597]
21Feb12_211150| [ 0.74440  0.98723]
21Feb12_211150| [ 0.01100 -0.67337]
21Feb12_211150| [ 0.06204  0.35817]
21Feb12_211150| [ 0.26726  0.48263]
21Feb12_211150| [-0.88494 -0.70844]
21Feb12_211150| [-0.84413 -0.69285]
21Feb12_211150| [ 0.45345 -2.08209]
21Feb12_211150| [-0.40021 -0.10894]
21Feb12_211150| [ 2.73392 -0.61867]
21Feb12_211150| [ 1.24710  0.98537]
21Feb12_211150| [ 0.82300  0.72555]
21Feb12_211150| [ 2.06057 -0.06460]
21Feb12_211150| [ 1.26673 -1.23461]
21Feb12_211150| [ 0.42018 -0.49554]
21Feb12_211150| [ 2.61792  1.45873]
21Feb12_211150| [ 0.59144 -1.10854]
21Feb12_211150| [-0.97707  1.48165]]
21Feb12_211150|-- Bias --
21Feb12_211150|[ 0.38902 -0.39861]
21Feb12_211150|Layer 1:
21Feb12_211150|-- Config --
21Feb12_211150|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211150|-- Weights --
21Feb12_211150|[[-0.32012 -0.65699  0.76440  0.52560]
21Feb12_211150| [ 0.44064  0.51440 -0.76282  0.19969]]
21Feb12_211150|-- Bias --
21Feb12_211150|[ 0.04015  0.29509  0.93883 -0.02209]
21Feb12_211150|Layer 2:
21Feb12_211150|-- Config --
21Feb12_211150|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211150|-- Weights --
21Feb12_211150|[[ 2.71531 -0.86969]
21Feb12_211150| [-0.96223  1.09854]
21Feb12_211150| [-0.40245  0.31843]
21Feb12_211150| [-0.02201 -0.31563]]
21Feb12_211150|-- Bias --
21Feb12_211150|[0.38755 0.47351]
21Feb12_211150|Predicting the validation and test data with the Best final individual.
21Feb12_211157| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_211157|-----------  ------------------  --------------------  ----------
21Feb12_211157|Validation         41.30                  12            0.02062
21Feb12_211157|   Test            36.14                  12            0.01190
21Feb12_211157|-------------------- Test #13 --------------------
21Feb12_211157|Best final individual weights
21Feb12_211157|Individual:
21Feb12_211157|-- Constant hidden layers --
21Feb12_211157|False
21Feb12_211157|Layer 0:
21Feb12_211157|-- Config --
21Feb12_211157|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211157|-- Weights --
21Feb12_211157|[[ 0.48141  1.08053]
21Feb12_211157| [-0.62108  0.02214]
21Feb12_211157| [-0.65483  0.88968]
21Feb12_211157| [-0.91839 -0.30848]
21Feb12_211157| [ 0.08504  0.90277]
21Feb12_211157| [ 0.37053  0.38479]
21Feb12_211157| [ 0.40871  1.23967]
21Feb12_211157| [-0.48711  0.45785]
21Feb12_211157| [ 0.96174 -1.07439]
21Feb12_211157| [ 0.06805  0.37322]
21Feb12_211157| [-0.22538  0.98785]
21Feb12_211157| [ 0.28474  0.11466]
21Feb12_211157| [ 0.95618 -1.73991]
21Feb12_211157| [ 0.23280  0.70700]
21Feb12_211157| [ 0.67583  0.28878]
21Feb12_211157| [ 1.10819  0.60307]
21Feb12_211157| [-0.19711 -1.04827]
21Feb12_211157| [-1.50344  1.92408]
21Feb12_211157| [ 0.13970  0.27654]
21Feb12_211157| [-1.13489  1.43482]
21Feb12_211157| [ 0.90793  0.09290]
21Feb12_211157| [ 0.28340 -0.20824]
21Feb12_211157| [-0.31490 -0.27430]
21Feb12_211157| [-0.04291 -0.55918]
21Feb12_211157| [-0.57216 -0.33220]
21Feb12_211157| [-0.18320 -2.15242]
21Feb12_211157| [ 1.41196  0.46552]
21Feb12_211157| [ 1.35793  0.32961]
21Feb12_211157| [-1.10509 -0.07299]
21Feb12_211157| [ 1.66389 -0.38715]
21Feb12_211157| [ 0.41781 -1.07053]
21Feb12_211157| [-0.07102 -0.59571]
21Feb12_211157| [-1.06163  0.25294]
21Feb12_211157| [-0.05236 -0.29352]
21Feb12_211157| [-0.07774  2.36904]
21Feb12_211157| [ 0.69814 -0.02507]
21Feb12_211157| [ 1.73983 -1.31095]
21Feb12_211157| [ 1.30637  1.52494]
21Feb12_211157| [-0.50587 -0.07929]
21Feb12_211157| [ 0.19700 -0.02597]
21Feb12_211157| [ 0.74440  0.98723]
21Feb12_211157| [ 0.01100 -0.67337]
21Feb12_211157| [ 0.06204  0.35817]
21Feb12_211157| [ 0.26726  0.48263]
21Feb12_211157| [-0.88494 -0.70844]
21Feb12_211157| [-0.84413 -0.69285]
21Feb12_211157| [ 0.45345 -2.08209]
21Feb12_211157| [-0.40021 -0.10894]
21Feb12_211157| [ 2.73392 -0.61867]
21Feb12_211157| [ 1.24710  0.98537]
21Feb12_211157| [ 0.82300  0.72555]
21Feb12_211157| [ 2.06057 -0.06460]
21Feb12_211157| [ 1.26673 -1.23461]
21Feb12_211157| [ 0.42018 -0.49554]
21Feb12_211157| [ 2.61792  1.45873]
21Feb12_211157| [ 0.59144 -1.10854]
21Feb12_211157| [-0.97707  1.48165]]
21Feb12_211157|-- Bias --
21Feb12_211157|[ 0.38902 -0.39861]
21Feb12_211157|Layer 1:
21Feb12_211157|-- Config --
21Feb12_211157|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211157|-- Weights --
21Feb12_211157|[[-0.32012 -0.65699  0.76440  0.52560]
21Feb12_211157| [ 0.44064  0.51440 -0.76282  0.19969]]
21Feb12_211157|-- Bias --
21Feb12_211157|[ 0.04015  0.29509  0.93883 -0.02209]
21Feb12_211157|Layer 2:
21Feb12_211157|-- Config --
21Feb12_211157|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211157|-- Weights --
21Feb12_211157|[[ 2.71531 -0.86969]
21Feb12_211157| [-0.96223  1.09854]
21Feb12_211157| [-0.40245  0.31843]
21Feb12_211157| [-0.02201 -0.31563]]
21Feb12_211157|-- Bias --
21Feb12_211157|[0.38755 0.47351]
21Feb12_211157|Predicting the validation and test data with the Best final individual.
21Feb12_211204| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_211204|-----------  ------------------  --------------------  ----------
21Feb12_211204|Validation         41.74                  12            0.00775
21Feb12_211204|   Test            36.14                  12            0.01190
21Feb12_211204|-------------------- Test #14 --------------------
21Feb12_211204|Best final individual weights
21Feb12_211204|Individual:
21Feb12_211204|-- Constant hidden layers --
21Feb12_211204|False
21Feb12_211204|Layer 0:
21Feb12_211204|-- Config --
21Feb12_211204|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211204|-- Weights --
21Feb12_211204|[[ 0.48141  1.08053]
21Feb12_211204| [-0.62108  0.02214]
21Feb12_211204| [-0.65483  0.88968]
21Feb12_211204| [-0.91839 -0.30848]
21Feb12_211204| [ 0.08504  0.90277]
21Feb12_211204| [ 0.37053  0.38479]
21Feb12_211204| [ 0.40871  1.23967]
21Feb12_211204| [-0.48711  0.45785]
21Feb12_211204| [ 0.96174 -1.07439]
21Feb12_211204| [ 0.06805  0.37322]
21Feb12_211204| [-0.22538  0.98785]
21Feb12_211204| [ 0.28474  0.11466]
21Feb12_211204| [ 0.95618 -1.73991]
21Feb12_211204| [ 0.23280  0.70700]
21Feb12_211204| [ 0.67583  0.28878]
21Feb12_211204| [ 1.10819  0.60307]
21Feb12_211204| [-0.19711 -1.04827]
21Feb12_211204| [-1.50344  1.92408]
21Feb12_211204| [ 0.13970  0.27654]
21Feb12_211204| [-1.13489  1.43482]
21Feb12_211204| [ 0.90793  0.09290]
21Feb12_211204| [ 0.28340 -0.20824]
21Feb12_211204| [-0.31490 -0.27430]
21Feb12_211204| [-0.04291 -0.55918]
21Feb12_211204| [-0.57216 -0.33220]
21Feb12_211204| [-0.18320 -2.15242]
21Feb12_211204| [ 1.41196  0.46552]
21Feb12_211204| [ 1.35793  0.32961]
21Feb12_211204| [-1.10509 -0.07299]
21Feb12_211204| [ 1.66389 -0.38715]
21Feb12_211204| [ 0.41781 -1.07053]
21Feb12_211204| [-0.07102 -0.59571]
21Feb12_211204| [-1.06163  0.25294]
21Feb12_211204| [-0.05236 -0.29352]
21Feb12_211204| [-0.07774  2.36904]
21Feb12_211204| [ 0.69814 -0.02507]
21Feb12_211204| [ 1.73983 -1.31095]
21Feb12_211204| [ 1.30637  1.52494]
21Feb12_211204| [-0.50587 -0.07929]
21Feb12_211204| [ 0.19700 -0.02597]
21Feb12_211204| [ 0.74440  0.98723]
21Feb12_211204| [ 0.01100 -0.67337]
21Feb12_211204| [ 0.06204  0.35817]
21Feb12_211204| [ 0.26726  0.48263]
21Feb12_211204| [-0.88494 -0.70844]
21Feb12_211204| [-0.84413 -0.69285]
21Feb12_211204| [ 0.45345 -2.08209]
21Feb12_211204| [-0.40021 -0.10894]
21Feb12_211204| [ 2.73392 -0.61867]
21Feb12_211204| [ 1.24710  0.98537]
21Feb12_211204| [ 0.82300  0.72555]
21Feb12_211204| [ 2.06057 -0.06460]
21Feb12_211204| [ 1.26673 -1.23461]
21Feb12_211204| [ 0.42018 -0.49554]
21Feb12_211204| [ 2.61792  1.45873]
21Feb12_211204| [ 0.59144 -1.10854]
21Feb12_211204| [-0.97707  1.48165]]
21Feb12_211204|-- Bias --
21Feb12_211204|[ 0.38902 -0.39861]
21Feb12_211204|Layer 1:
21Feb12_211204|-- Config --
21Feb12_211204|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211204|-- Weights --
21Feb12_211204|[[-0.32012 -0.65699  0.76440  0.52560]
21Feb12_211204| [ 0.44064  0.51440 -0.76282  0.19969]]
21Feb12_211204|-- Bias --
21Feb12_211204|[ 0.04015  0.29509  0.93883 -0.02209]
21Feb12_211204|Layer 2:
21Feb12_211204|-- Config --
21Feb12_211204|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_211204|-- Weights --
21Feb12_211204|[[ 2.71531 -0.86969]
21Feb12_211204| [-0.96223  1.09854]
21Feb12_211204| [-0.40245  0.31843]
21Feb12_211204| [-0.02201 -0.31563]]
21Feb12_211204|-- Bias --
21Feb12_211204|[0.38755 0.47351]
21Feb12_211204|Predicting the validation and test data with the Best final individual.
21Feb12_211212| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_211212|-----------  ------------------  --------------------  ----------
21Feb12_211212|Validation         41.65                  12            0.01546
21Feb12_211212|   Test            36.23                  12            0.01189
2021-02-12 21:12:13.369188: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
21Feb12_211214|Data summary: Train
21Feb12_211214|data.shape = (2300, 57)
21Feb12_211214|labels.shape = (2300,)
21Feb12_211214|Class distribution:
21Feb12_211214|	0 - 1389 (0.60)
21Feb12_211214|	1 - 911 (0.40)
21Feb12_211214|Data summary: Validation
21Feb12_211214|data.shape = (1150, 57)
21Feb12_211214|labels.shape = (1150,)
21Feb12_211214|Class distribution:
21Feb12_211214|	0 - 667 (0.58)
21Feb12_211214|	1 - 483 (0.42)
21Feb12_211214|Data summary: Test
21Feb12_211214|data.shape = (1151, 57)
21Feb12_211214|labels.shape = (1151,)
21Feb12_211214|Class distribution:
21Feb12_211214|	0 - 732 (0.64)
21Feb12_211214|	1 - 419 (0.36)
21Feb12_211214|Selected configuration values
21Feb12_211214|-- Dataset name: spambase2
21Feb12_211214|-- Initial population size: 64
21Feb12_211214|-- Maximun number of generations: 32
21Feb12_211214|-- Neurons per hidden layer range: (2, 20)
21Feb12_211214|-- Hidden layers number range: (1, 3)
21Feb12_211214|-- Crossover probability: 0.5
21Feb12_211214|-- Bias gene mutation probability: 0.2
21Feb12_211214|-- Weights gene mutation probability: 0.75
21Feb12_211214|-- Neuron mutation probability: 0.3
21Feb12_211214|-- Layer mutation probability: 0.3
21Feb12_211214|-- Constant hidden layers: False
21Feb12_211214|-- Seed: 31415
21Feb12_211214|Entering GA
21Feb12_211214|Start the algorithm
2021-02-12 21:12:14.269055: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-12 21:12:14.269590: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-02-12 21:12:14.291134: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-12 21:12:14.291452: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.71GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s
2021-02-12 21:12:14.291465: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-02-12 21:12:14.292913: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-02-12 21:12:14.292941: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-02-12 21:12:14.293437: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-02-12 21:12:14.293565: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-02-12 21:12:14.293635: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-12 21:12:14.294043: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-02-12 21:12:14.294084: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-12 21:12:14.294098: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-02-12 21:12:14.294314: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-02-12 21:12:14.295116: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-12 21:12:14.295130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-12 21:12:14.295134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      
2021-02-12 21:12:14.340622: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-02-12 21:12:14.340960: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3493635000 Hz
/home/jmerelo/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype("int32")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn('`model.predict_classes()` is deprecated and '
21Feb12_211620|-- Generation 1 --
21Feb12_211620|    -- Crossed 2 individual pairs.
21Feb12_211620|    -- Mutated 32 individuals.
21Feb12_212022|    -- Evaluated 64 individuals.
21Feb12_212022|    Summary of generation 1:
21Feb12_212022| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_212022|-----------  ------------------  --------------------  ----------
21Feb12_212022|    Max            42.26                120.00          0.77904
21Feb12_212022|    Avg            41.66                37.80           0.02011
21Feb12_212022|    Min            26.52                 3.00           0.00000
21Feb12_212022|    Std             2.01                30.23           0.10764
21Feb12_212022|   Best            26.52                54.00           0.77904
21Feb12_212022|-- Generation 2 --
21Feb12_212022|    -- Crossed 1 individual pairs.
21Feb12_212022|    -- Mutated 32 individuals.
21Feb12_212419|    -- Evaluated 64 individuals.
21Feb12_212419|    Summary of generation 2:
21Feb12_212419| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_212419|-----------  ------------------  --------------------  ----------
21Feb12_212419|    Max            42.43                62.00           0.42326
21Feb12_212419|    Avg            41.79                22.41           0.00871
21Feb12_212419|    Min            29.30                 3.00           0.00000
21Feb12_212419|    Std             1.58                19.52           0.05241
21Feb12_212419|   Best            29.30                14.00           0.42326
21Feb12_212419|-- Generation 3 --
21Feb12_212419|    -- Crossed 2 individual pairs.
21Feb12_212419|    -- Mutated 32 individuals.
21Feb12_212811|    -- Evaluated 64 individuals.
21Feb12_212811|    Summary of generation 3:
21Feb12_212811| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_212811|-----------  ------------------  --------------------  ----------
21Feb12_212811|    Max            42.17                105.00          0.47641
21Feb12_212811|    Avg            41.76                10.64           0.00926
21Feb12_212811|    Min            29.13                 2.00           0.00000
21Feb12_212811|    Std             1.60                14.51           0.05899
21Feb12_212811|   Best            29.13                14.00           0.47641
21Feb12_212811|-- Generation 4 --
21Feb12_212811|    -- Crossed 4 individual pairs.
21Feb12_212811|    -- Mutated 32 individuals.
21Feb12_213202|    -- Evaluated 64 individuals.
21Feb12_213202|    Summary of generation 4:
21Feb12_213202| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_213202|-----------  ------------------  --------------------  ----------
21Feb12_213202|    Max            42.26                48.00           0.38985
21Feb12_213202|    Avg            41.78                 8.73           0.00779
21Feb12_213202|    Min            30.26                 2.00           0.00000
21Feb12_213202|    Std             1.46                 8.69           0.04832
21Feb12_213202|   Best            30.26                24.00           0.38985
21Feb12_213202|-- Generation 5 --
21Feb12_213202|    -- Crossed 6 individual pairs.
21Feb12_213202|    -- Mutated 32 individuals.
21Feb12_213553|    -- Evaluated 64 individuals.
21Feb12_213553|    Summary of generation 5:
21Feb12_213553| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_213553|-----------  ------------------  --------------------  ----------
21Feb12_213553|    Max            42.17                28.00           0.02060
21Feb12_213553|    Avg            41.96                 6.48           0.00173
21Feb12_213553|    Min            41.48                 2.00           0.00000
21Feb12_213553|    Std             0.11                 5.74           0.00379
21Feb12_213553|   Best            41.48                11.00           0.02060
21Feb12_213553|-- Generation 6 --
21Feb12_213553|    -- Crossed 6 individual pairs.
21Feb12_213553|    -- Mutated 32 individuals.
21Feb12_213944|    -- Evaluated 64 individuals.
21Feb12_213944|    Summary of generation 6:
21Feb12_213944| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_213944|-----------  ------------------  --------------------  ----------
21Feb12_213944|    Max            42.17                34.00           0.02061
21Feb12_213944|    Avg            41.95                 7.30           0.00238
21Feb12_213944|    Min            41.39                 2.00           0.00000
21Feb12_213944|    Std             0.15                 6.26           0.00474
21Feb12_213944|   Best            41.39                 8.00           0.02061
21Feb12_213944|-- Generation 7 --
21Feb12_213944|    -- Crossed 6 individual pairs.
21Feb12_213944|    -- Mutated 32 individuals.
21Feb12_214335|    -- Evaluated 64 individuals.
21Feb12_214335|    Summary of generation 7:
21Feb12_214335| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_214335|-----------  ------------------  --------------------  ----------
21Feb12_214335|    Max            42.17                30.00           0.02061
21Feb12_214335|    Avg            41.95                 6.30           0.00202
21Feb12_214335|    Min            41.39                 2.00           0.00000
21Feb12_214335|    Std             0.12                 5.53           0.00404
21Feb12_214335|   Best            41.39                11.00           0.02061
21Feb12_214335|-- Generation 8 --
21Feb12_214335|    -- Crossed 6 individual pairs.
21Feb12_214335|    -- Mutated 32 individuals.
21Feb12_214727|    -- Evaluated 64 individuals.
21Feb12_214727|    Summary of generation 8:
21Feb12_214727| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_214727|-----------  ------------------  --------------------  ----------
21Feb12_214727|    Max            42.17                34.00           0.02061
21Feb12_214727|    Avg            41.95                 6.28           0.00206
21Feb12_214727|    Min            41.39                 2.00           0.00000
21Feb12_214727|    Std             0.11                 5.63           0.00342
21Feb12_214727|   Best            41.39                 3.00           0.02061
21Feb12_214727|-- Generation 9 --
21Feb12_214727|    -- Crossed 8 individual pairs.
21Feb12_214727|    -- Mutated 32 individuals.
21Feb12_215118|    -- Evaluated 64 individuals.
21Feb12_215118|    Summary of generation 9:
21Feb12_215118| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_215118|-----------  ------------------  --------------------  ----------
21Feb12_215118|    Max            42.09                30.00           0.02061
21Feb12_215118|    Avg            41.94                 6.17           0.00218
21Feb12_215118|    Min            41.39                 2.00           0.00000
21Feb12_215118|    Std             0.11                 5.50           0.00374
21Feb12_215118|   Best            41.39                 2.00           0.02061
21Feb12_215118|-- Generation 10 --
21Feb12_215118|    -- Crossed 3 individual pairs.
21Feb12_215118|    -- Mutated 32 individuals.
21Feb12_215510|    -- Evaluated 64 individuals.
21Feb12_215510|    Summary of generation 10:
21Feb12_215510| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_215510|-----------  ------------------  --------------------  ----------
21Feb12_215510|    Max            42.26                30.00           0.76034
21Feb12_215510|    Avg            41.64                 6.72           0.01475
21Feb12_215510|    Min            23.22                 2.00           0.00000
21Feb12_215510|    Std             2.33                 6.14           0.09403
21Feb12_215510|   Best            23.22                12.00           0.76034
21Feb12_215510|-- Generation 11 --
21Feb12_215510|    -- Crossed 3 individual pairs.
21Feb12_215510|    -- Mutated 32 individuals.
21Feb12_215904|    -- Evaluated 64 individuals.
21Feb12_215904|    Summary of generation 11:
21Feb12_215904| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_215904|-----------  ------------------  --------------------  ----------
21Feb12_215904|    Max            54.70                54.00           0.79224
21Feb12_215904|    Avg            41.92                 9.00           0.02300
21Feb12_215904|    Min            30.09                 2.00           0.00000
21Feb12_215904|    Std             2.18                 8.64           0.11218
21Feb12_215904|   Best            30.09                24.00           0.45744
21Feb12_215904|-- Generation 12 --
21Feb12_215904|    -- Crossed 6 individual pairs.
21Feb12_215904|    -- Mutated 32 individuals.
21Feb12_220256|    -- Evaluated 64 individuals.
21Feb12_220256|    Summary of generation 12:
21Feb12_220256| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_220256|-----------  ------------------  --------------------  ----------
21Feb12_220256|    Max            42.17                27.00           0.55457
21Feb12_220256|    Avg            41.54                 5.78           0.01687
21Feb12_220256|    Min            26.52                 2.00           0.00000
21Feb12_220256|    Std             2.15                 5.18           0.07754
21Feb12_220256|   Best            26.52                27.00           0.55457
21Feb12_220256|-- Generation 13 --
21Feb12_220256|    -- Crossed 5 individual pairs.
21Feb12_220256|    -- Mutated 32 individuals.
21Feb12_220649|    -- Evaluated 64 individuals.
21Feb12_220649|    Summary of generation 13:
21Feb12_220649| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_220649|-----------  ------------------  --------------------  ----------
21Feb12_220649|    Max            42.09                30.00           0.63763
21Feb12_220649|    Avg            41.38                 6.00           0.02482
21Feb12_220649|    Min            27.91                 2.00           0.00000
21Feb12_220649|    Std             2.49                 5.90           0.10298
21Feb12_220649|   Best            27.91                30.00           0.63763
21Feb12_220649|-- Generation 14 --
21Feb12_220649|    -- Crossed 6 individual pairs.
21Feb12_220649|    -- Mutated 32 individuals.
21Feb12_221040|    -- Evaluated 64 individuals.
21Feb12_221040|    Summary of generation 14:
21Feb12_221040| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_221040|-----------  ------------------  --------------------  ----------
21Feb12_221040|    Max            42.09                32.00           0.57048
21Feb12_221040|    Avg            41.17                 6.70           0.03043
21Feb12_221040|    Min            26.35                 2.00           0.00000
21Feb12_221040|    Std             3.22                 8.09           0.11878
21Feb12_221040|   Best            26.35                10.00           0.57048
21Feb12_221040|-- Generation 15 --
21Feb12_221040|    -- Crossed 3 individual pairs.
21Feb12_221040|    -- Mutated 32 individuals.
21Feb12_221434|    -- Evaluated 64 individuals.
21Feb12_221434|    Summary of generation 15:
21Feb12_221434| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_221434|-----------  ------------------  --------------------  ----------
21Feb12_221434|    Max            42.09                30.00           0.80337
21Feb12_221434|    Avg            41.29                 7.66           0.03558
21Feb12_221434|    Min            26.52                 2.00           0.00000
21Feb12_221434|    Std             2.74                 7.73           0.14168
21Feb12_221434|   Best            26.52                10.00           0.56316
21Feb12_221434|-- Generation 16 --
21Feb12_221434|    -- Crossed 4 individual pairs.
21Feb12_221434|    -- Mutated 32 individuals.
21Feb12_221826|    -- Evaluated 64 individuals.
21Feb12_221826|    Summary of generation 16:
21Feb12_221826| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_221826|-----------  ------------------  --------------------  ----------
21Feb12_221826|    Max            42.17                48.00           0.50471
21Feb12_221826|    Avg            41.30                 6.52           0.02614
21Feb12_221826|    Min            28.70                 2.00           0.00000
21Feb12_221826|    Std             2.54                 8.68           0.09485
21Feb12_221826|   Best            28.70                30.00           0.50471
21Feb12_221826|-- Generation 17 --
21Feb12_221826|    -- Crossed 5 individual pairs.
21Feb12_221826|    -- Mutated 32 individuals.
21Feb12_222220|    -- Evaluated 64 individuals.
21Feb12_222220|    Summary of generation 17:
21Feb12_222220| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_222220|-----------  ------------------  --------------------  ----------
21Feb12_222220|    Max            42.17                30.00           0.71429
21Feb12_222220|    Avg            40.93                 6.91           0.04453
21Feb12_222220|    Min            27.04                 2.00           0.00000
21Feb12_222220|    Std             3.54                 7.02           0.15068
21Feb12_222220|   Best            27.04                12.00           0.71429
21Feb12_222220|-- Generation 18 --
21Feb12_222220|    -- Crossed 4 individual pairs.
21Feb12_222220|    -- Mutated 32 individuals.
21Feb12_222614|    -- Evaluated 64 individuals.
21Feb12_222614|    Summary of generation 18:
21Feb12_222614| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_222614|-----------  ------------------  --------------------  ----------
21Feb12_222614|    Max            56.09                60.00           0.78698
21Feb12_222614|    Avg            41.17                 8.58           0.06059
21Feb12_222614|    Min            26.61                 2.00           0.00000
21Feb12_222614|    Std             3.78                10.55           0.18034
21Feb12_222614|   Best            26.61                27.00           0.56633
21Feb12_222614|-- Generation 19 --
21Feb12_222614|    -- Crossed 4 individual pairs.
21Feb12_222614|    -- Mutated 32 individuals.
21Feb12_223009|    -- Evaluated 64 individuals.
21Feb12_223009|    Summary of generation 19:
21Feb12_223009| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_223009|-----------  ------------------  --------------------  ----------
21Feb12_223009|    Max            42.09                60.00           0.78498
21Feb12_223009|    Avg            40.57                11.12           0.05593
21Feb12_223009|    Min            24.09                 2.00           0.00000
21Feb12_223009|    Std             3.95                14.81           0.16051
21Feb12_223009|   Best            24.09                24.00           0.78498
21Feb12_223009|-- Generation 20 --
21Feb12_223009|    -- Crossed 1 individual pairs.
21Feb12_223009|    -- Mutated 32 individuals.
21Feb12_223406|    -- Evaluated 64 individuals.
21Feb12_223406|    Summary of generation 20:
21Feb12_223406| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_223406|-----------  ------------------  --------------------  ----------
21Feb12_223406|    Max            44.00                60.00           0.80472
21Feb12_223406|    Avg            40.74                12.86           0.06150
21Feb12_223406|    Min            23.48                 2.00           0.00000
21Feb12_223406|    Std             3.93                13.94           0.17872
21Feb12_223406|   Best            23.48                27.00           0.78717
21Feb12_223406|-- Generation 21 --
21Feb12_223406|    -- Crossed 2 individual pairs.
21Feb12_223406|    -- Mutated 32 individuals.
21Feb12_223801|    -- Evaluated 64 individuals.
21Feb12_223801|    Summary of generation 21:
21Feb12_223801| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_223801|-----------  ------------------  --------------------  ----------
21Feb12_223801|    Max            42.17                33.00           0.77358
21Feb12_223801|    Avg            40.74                 9.16           0.05000
21Feb12_223801|    Min            25.74                 2.00           0.00000
21Feb12_223801|    Std             3.57                10.29           0.14790
21Feb12_223801|   Best            25.74                27.00           0.59581
21Feb12_223801|-- Generation 22 --
21Feb12_223801|    -- Crossed 6 individual pairs.
21Feb12_223801|    -- Mutated 32 individuals.
21Feb12_224156|    -- Evaluated 64 individuals.
21Feb12_224156|    Summary of generation 22:
21Feb12_224156| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_224156|-----------  ------------------  --------------------  ----------
21Feb12_224156|    Max            45.57                33.00           0.81021
21Feb12_224156|    Avg            41.05                 8.73           0.05130
21Feb12_224156|    Min            27.13                 2.00           0.00000
21Feb12_224156|    Std             3.26                 9.37           0.16102
21Feb12_224156|   Best            27.13                30.00           0.55457
21Feb12_224156|-- Generation 23 --
21Feb12_224156|    -- Crossed 1 individual pairs.
21Feb12_224156|    -- Mutated 32 individuals.
21Feb12_224550|    -- Evaluated 64 individuals.
21Feb12_224550|    Summary of generation 23:
21Feb12_224550| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_224550|-----------  ------------------  --------------------  ----------
21Feb12_224550|    Max            42.09                33.00           0.69406
21Feb12_224550|    Avg            41.03                 7.56           0.04115
21Feb12_224550|    Min            26.52                 2.00           0.00000
21Feb12_224550|    Std             3.03                 8.37           0.13337
21Feb12_224550|   Best            26.52                10.00           0.58682
21Feb12_224550|-- Generation 24 --
21Feb12_224550|    -- Crossed 1 individual pairs.
21Feb12_224550|    -- Mutated 32 individuals.
21Feb12_224944|    -- Evaluated 64 individuals.
21Feb12_224944|    Summary of generation 24:
21Feb12_224944| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_224944|-----------  ------------------  --------------------  ----------
21Feb12_224944|    Max            42.09                33.00           0.56683
21Feb12_224944|    Avg            40.77                 8.33           0.04477
21Feb12_224944|    Min            26.43                 2.00           0.00000
21Feb12_224944|    Std             3.54                 8.48           0.13114
21Feb12_224944|   Best            26.43                10.00           0.56683
21Feb12_224944|-- Generation 25 --
21Feb12_224944|    -- Crossed 1 individual pairs.
21Feb12_224944|    -- Mutated 32 individuals.
21Feb12_225339|    -- Evaluated 64 individuals.
21Feb12_225339|    Summary of generation 25:
21Feb12_225339| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_225339|-----------  ------------------  --------------------  ----------
21Feb12_225339|    Max            42.00                64.00           0.81472
21Feb12_225339|    Avg            40.71                10.33           0.05705
21Feb12_225339|    Min            26.26                 2.00           0.00000
21Feb12_225339|    Std             3.68                12.00           0.17070
21Feb12_225339|   Best            26.26                10.00           0.56562
21Feb12_225339|-- Generation 26 --
21Feb12_225339|    -- Crossed 4 individual pairs.
21Feb12_225339|    -- Mutated 32 individuals.
21Feb12_225733|    -- Evaluated 64 individuals.
21Feb12_225733|    Summary of generation 26:
21Feb12_225733| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_225733|-----------  ------------------  --------------------  ----------
21Feb12_225733|    Max            43.04                33.00           0.59669
21Feb12_225733|    Avg            40.84                 8.97           0.04504
21Feb12_225733|    Min            26.00                 2.00           0.00000
21Feb12_225733|    Std             3.44                 9.42           0.13634
21Feb12_225733|   Best            26.00                10.00           0.59669
21Feb12_225733|-- Generation 27 --
21Feb12_225733|    -- Crossed 3 individual pairs.
21Feb12_225733|    -- Mutated 32 individuals.
21Feb12_230129|    -- Evaluated 64 individuals.
21Feb12_230129|    Summary of generation 27:
21Feb12_230129| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_230129|-----------  ------------------  --------------------  ----------
21Feb12_230129|    Max            42.17                60.00           0.51334
21Feb12_230129|    Avg            40.37                11.06           0.05649
21Feb12_230129|    Min            26.78                 2.00           0.00000
21Feb12_230129|    Std             3.95                11.81           0.13773
21Feb12_230129|   Best            26.78                21.00           0.51334
21Feb12_230129|-- Generation 28 --
21Feb12_230129|    -- Crossed 2 individual pairs.
21Feb12_230129|    -- Mutated 32 individuals.
21Feb12_230529|    -- Evaluated 64 individuals.
21Feb12_230529|    Summary of generation 28:
21Feb12_230529| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_230529|-----------  ------------------  --------------------  ----------
21Feb12_230529|    Max            42.09                60.00           0.77710
21Feb12_230529|    Avg            39.60                14.62           0.09682
21Feb12_230529|    Min            24.09                 2.00           0.00000
21Feb12_230529|    Std             5.13                14.11           0.21152
21Feb12_230529|   Best            24.09                60.00           0.71988
21Feb12_230529|-- Generation 29 --
21Feb12_230529|    -- Crossed 3 individual pairs.
21Feb12_230529|    -- Mutated 32 individuals.
21Feb12_230928|    -- Evaluated 64 individuals.
21Feb12_230928|    Summary of generation 29:
21Feb12_230928| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_230928|-----------  ------------------  --------------------  ----------
21Feb12_230928|    Max            42.26                64.00           0.79993
21Feb12_230928|    Avg            38.97                16.81           0.12267
21Feb12_230928|    Min            21.39                 2.00           0.00000
21Feb12_230928|    Std             5.87                15.96           0.24216
21Feb12_230928|   Best            21.39                21.00           0.77534
21Feb12_230928|-- Generation 30 --
21Feb12_230928|    -- Crossed 2 individual pairs.
21Feb12_230928|    -- Mutated 32 individuals.
21Feb12_231332|    -- Evaluated 64 individuals.
21Feb12_231332|    Summary of generation 30:
21Feb12_231332| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_231332|-----------  ------------------  --------------------  ----------
21Feb12_231332|    Max            42.09                60.00           0.81399
21Feb12_231332|    Avg            40.29                20.95           0.07449
21Feb12_231332|    Min            21.65                 2.00           0.00000
21Feb12_231332|    Std             4.27                16.72           0.18576
21Feb12_231332|   Best            21.65                21.00           0.77158
21Feb12_231332|-- Generation 31 --
21Feb12_231332|    -- Crossed 3 individual pairs.
21Feb12_231332|    -- Mutated 32 individuals.
21Feb12_231731|    -- Evaluated 64 individuals.
21Feb12_231731|    Summary of generation 31:
21Feb12_231731| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_231731|-----------  ------------------  --------------------  ----------
21Feb12_231731|    Max            42.70                56.00           0.80544
21Feb12_231731|    Avg            39.76                16.45           0.08656
21Feb12_231731|    Min            23.22                 2.00           0.00000
21Feb12_231731|    Std             5.09                14.15           0.20354
21Feb12_231731|   Best            23.22                21.00           0.68528
21Feb12_231731|-- Generation 32 --
21Feb12_231731|    -- Crossed 4 individual pairs.
21Feb12_231731|    -- Mutated 32 individuals.
21Feb12_232132|    -- Evaluated 64 individuals.
21Feb12_232132|    Summary of generation 32:
21Feb12_232132| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_232132|-----------  ------------------  --------------------  ----------
21Feb12_232132|    Max            42.09                56.00           0.81970
21Feb12_232132|    Avg            38.86                18.42           0.13240
21Feb12_232132|    Min            22.96                 2.00           0.00000
21Feb12_232132|    Std             5.75                14.35           0.25036
21Feb12_232132|   Best            22.96                24.00           0.78905
21Feb12_232132|Best initial individual weights
21Feb12_232132|Individual:
21Feb12_232132|-- Constant hidden layers --
21Feb12_232132|False
21Feb12_232132|Layer 0:
21Feb12_232132|-- Config --
21Feb12_232132|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 20, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232132|-- Weights --
21Feb12_232132|[[-0.81530 -0.38125 -0.79998 ... -0.70263 -0.61840  0.66571]
21Feb12_232132| [ 0.65866  0.85470 -0.58802 ... -0.96520  0.62924 -0.99993]
21Feb12_232132| [ 0.82861 -0.31058 -0.15077 ... -0.37206  0.28605  0.29356]
21Feb12_232132| ...
21Feb12_232132| [-0.22356 -0.17240 -0.31428 ... -0.22545  0.94699 -0.71943]
21Feb12_232132| [-0.37773 -0.75933 -0.69490 ... -0.90595 -0.69780 -0.98315]
21Feb12_232132| [ 0.65818 -0.25813 -0.28240 ...  0.35891  0.55911  0.45607]]
21Feb12_232132|-- Bias --
21Feb12_232132|[-0.66607 -0.45412 -0.47565  0.95426  0.37266  0.71643 -0.83233 -0.59141
21Feb12_232132| -0.57925 -0.35895  0.07388  0.17038  0.31672  0.81171  0.30057  0.54611
21Feb12_232132| -0.62651  0.24482  0.64224 -0.28752]
21Feb12_232132|Layer 1:
21Feb12_232132|-- Config --
21Feb12_232132|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 20], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232132|-- Weights --
21Feb12_232132|[[ 0.42040 -0.26492]
21Feb12_232132| [ 0.78679  0.01829]
21Feb12_232132| [ 0.85426  0.35026]
21Feb12_232132| [ 0.63200 -0.62249]
21Feb12_232132| [-0.55346 -0.80586]
21Feb12_232132| [-0.61224  0.86991]
21Feb12_232132| [-0.47486 -0.31648]
21Feb12_232132| [ 0.53818 -0.22812]
21Feb12_232132| [-0.74035 -0.70516]
21Feb12_232132| [-0.47742 -0.04703]
21Feb12_232132| [ 0.68440 -0.93557]
21Feb12_232132| [-0.18841 -0.56741]
21Feb12_232132| [-0.08233  0.51743]
21Feb12_232132| [ 0.43051 -0.46386]
21Feb12_232132| [ 0.67964  0.15665]
21Feb12_232132| [-0.10319 -0.36290]
21Feb12_232132| [-0.23955  0.64790]
21Feb12_232132| [-0.84563 -0.92413]
21Feb12_232132| [ 0.53642 -0.52099]
21Feb12_232132| [ 0.03906 -0.94604]]
21Feb12_232132|-- Bias --
21Feb12_232132|[ 0.50157 -0.93861]
21Feb12_232132|Predicting the validation and test data with the Best initial individual.
21Feb12_232140| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_232140|-----------  ------------------  --------------------  ----------
21Feb12_232140|Validation         42.00                  20            0.00259
21Feb12_232140|   Test            36.49                  20            0.00000
21Feb12_232140|-------------------- Test #0 --------------------
21Feb12_232140|Best final individual weights
21Feb12_232140|Individual:
21Feb12_232140|-- Constant hidden layers --
21Feb12_232140|False
21Feb12_232140|Layer 0:
21Feb12_232140|-- Config --
21Feb12_232140|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232140|-- Weights --
21Feb12_232140|[[-0.88430  0.38744  0.30429 -0.19493]
21Feb12_232140| [-0.07106  0.05862  1.34480 -0.46391]
21Feb12_232140| [ 0.06174 -1.01753  0.91730  0.44578]
21Feb12_232140| [ 0.65403 -0.46094 -0.43710  0.06277]
21Feb12_232140| [ 0.26691  0.05663  1.01849  0.33034]
21Feb12_232140| [ 0.62238 -1.16873 -1.03042  0.43068]
21Feb12_232140| [ 0.61110 -1.46840  0.44994 -0.28322]
21Feb12_232140| [-0.82124  1.02884 -0.40450  0.40306]
21Feb12_232140| [-0.56817  1.43936 -0.79233 -0.31949]
21Feb12_232140| [-0.11266  1.07052 -0.57275  0.01036]
21Feb12_232140| [ 0.32740 -1.66256 -1.22600  0.11828]
21Feb12_232140| [-0.70810 -2.31320 -1.10761 -0.40808]
21Feb12_232140| [ 0.93245  0.36786 -0.79838 -0.10952]
21Feb12_232140| [-1.07525 -0.60551 -0.66128  0.02992]
21Feb12_232140| [-0.94245 -0.40706 -0.82415  0.29567]
21Feb12_232140| [ 0.71756 -0.08265  0.79341  0.29860]
21Feb12_232140| [-1.59746  1.81339  1.55303 -0.37562]
21Feb12_232140| [-0.36642 -1.51142 -1.06142 -0.09675]
21Feb12_232140| [-1.24167 -0.48675  1.07870 -0.49966]
21Feb12_232140| [-0.37284 -1.07562  0.98240  0.46102]
21Feb12_232140| [-1.56216  0.77984 -0.56551  0.16250]
21Feb12_232140| [ 1.07349 -1.90915  0.46168 -0.11103]
21Feb12_232140| [-1.33189  0.95651 -0.22357  0.49323]
21Feb12_232140| [-1.12687 -0.77820  0.21195 -0.33038]
21Feb12_232140| [ 0.65272  0.18763 -0.05432  0.13593]
21Feb12_232140| [ 0.55334  0.94725  0.25358 -0.43635]
21Feb12_232140| [-1.07432  0.56233 -0.92488  0.49818]
21Feb12_232140| [ 0.54917  0.47714 -0.71581  0.28568]
21Feb12_232140| [ 0.74296  1.21411 -0.25897 -0.06134]
21Feb12_232140| [-2.26559 -1.44219 -0.35266  0.02409]
21Feb12_232140| [-1.56621 -1.96934  0.04624 -0.05266]
21Feb12_232140| [-0.32211  2.53154 -0.19339 -0.01619]
21Feb12_232140| [-1.62310  0.86832 -1.59048 -0.25297]
21Feb12_232140| [ 0.01383  1.33516 -0.97640  0.42359]
21Feb12_232140| [ 0.60856 -1.04358  0.50439 -0.42649]
21Feb12_232140| [ 1.38760  1.47011 -0.82651  0.27243]
21Feb12_232140| [-0.78439  0.61616  1.12318  0.46024]
21Feb12_232140| [ 1.01039 -1.11643 -0.10615  0.16438]
21Feb12_232140| [-0.60194  0.16256  0.69794  0.42338]
21Feb12_232140| [ 1.29789 -0.66201 -0.54308 -0.41395]
21Feb12_232140| [ 1.27111 -0.80429 -0.45608  0.43618]
21Feb12_232140| [-0.30043 -0.17224  0.73640  0.39627]
21Feb12_232140| [ 1.06895 -0.11087 -0.49826  0.03048]
21Feb12_232140| [-0.24413  0.52260  0.19550 -0.28699]
21Feb12_232140| [ 0.28284  0.77646 -0.25399 -0.07475]
21Feb12_232140| [-0.55158 -0.29051 -0.23798  0.46269]
21Feb12_232140| [-0.38260 -1.40522  0.63413 -0.29225]
21Feb12_232140| [ 0.03139  0.20183 -0.08841  0.37224]
21Feb12_232140| [-1.48545 -0.91705 -0.13515 -0.46855]
21Feb12_232140| [ 0.47649 -0.27177  0.82744  0.39112]
21Feb12_232140| [-1.87642 -0.32403 -0.23635  0.30883]
21Feb12_232140| [-1.23419 -0.11716  0.28717  0.04225]
21Feb12_232140| [-2.71438 -0.35530  0.90248 -0.14798]
21Feb12_232140| [ 1.26386 -0.32541 -0.00451  0.09379]
21Feb12_232140| [ 2.19550  0.91671 -0.98338 -0.43225]
21Feb12_232140| [ 0.48682 -0.34951  0.40278  0.32559]
21Feb12_232140| [ 0.87740 -0.34327  0.09753 -0.43035]]
21Feb12_232140|-- Bias --
21Feb12_232140|[-1.61088 -0.25085  0.53274  0.21367]
21Feb12_232140|Layer 1:
21Feb12_232140|-- Config --
21Feb12_232140|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232140|-- Weights --
21Feb12_232140|[[ 0.85045  0.02234]
21Feb12_232140| [ 0.15146  0.55865]
21Feb12_232140| [-0.04185  0.06756]
21Feb12_232140| [-0.47434  0.49266]]
21Feb12_232140|-- Bias --
21Feb12_232140|[-1.03310 -1.04658]
21Feb12_232140|Layer 2:
21Feb12_232140|-- Config --
21Feb12_232140|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232140|-- Weights --
21Feb12_232140|[[ 0.71153 -0.44529]
21Feb12_232140| [-0.44942 -0.32761]]
21Feb12_232140|-- Bias --
21Feb12_232140|[ 0.85309 -0.84290]
21Feb12_232140|Layer 3:
21Feb12_232140|-- Config --
21Feb12_232140|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232140|-- Weights --
21Feb12_232140|[[1.27656 0.06911]
21Feb12_232140| [0.53547 2.59670]]
21Feb12_232140|-- Bias --
21Feb12_232140|[-0.73581 -0.51354]
21Feb12_232140|Predicting the validation and test data with the Best final individual.
21Feb12_232147| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_232147|-----------  ------------------  --------------------  ----------
21Feb12_232147|Validation         24.26                  24            0.71340
21Feb12_232147|   Test            23.81                  24            0.83079
21Feb12_232147|-------------------- Test #1 --------------------
21Feb12_232147|Best final individual weights
21Feb12_232147|Individual:
21Feb12_232147|-- Constant hidden layers --
21Feb12_232147|False
21Feb12_232147|Layer 0:
21Feb12_232147|-- Config --
21Feb12_232147|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232147|-- Weights --
21Feb12_232147|[[-0.88430  0.38744  0.30429 -0.19493]
21Feb12_232147| [-0.07106  0.05862  1.34480 -0.46391]
21Feb12_232147| [ 0.06174 -1.01753  0.91730  0.44578]
21Feb12_232147| [ 0.65403 -0.46094 -0.43710  0.06277]
21Feb12_232147| [ 0.26691  0.05663  1.01849  0.33034]
21Feb12_232147| [ 0.62238 -1.16873 -1.03042  0.43068]
21Feb12_232147| [ 0.61110 -1.46840  0.44994 -0.28322]
21Feb12_232147| [-0.82124  1.02884 -0.40450  0.40306]
21Feb12_232147| [-0.56817  1.43936 -0.79233 -0.31949]
21Feb12_232147| [-0.11266  1.07052 -0.57275  0.01036]
21Feb12_232147| [ 0.32740 -1.66256 -1.22600  0.11828]
21Feb12_232147| [-0.70810 -2.31320 -1.10761 -0.40808]
21Feb12_232147| [ 0.93245  0.36786 -0.79838 -0.10952]
21Feb12_232147| [-1.07525 -0.60551 -0.66128  0.02992]
21Feb12_232147| [-0.94245 -0.40706 -0.82415  0.29567]
21Feb12_232147| [ 0.71756 -0.08265  0.79341  0.29860]
21Feb12_232147| [-1.59746  1.81339  1.55303 -0.37562]
21Feb12_232147| [-0.36642 -1.51142 -1.06142 -0.09675]
21Feb12_232147| [-1.24167 -0.48675  1.07870 -0.49966]
21Feb12_232147| [-0.37284 -1.07562  0.98240  0.46102]
21Feb12_232147| [-1.56216  0.77984 -0.56551  0.16250]
21Feb12_232147| [ 1.07349 -1.90915  0.46168 -0.11103]
21Feb12_232147| [-1.33189  0.95651 -0.22357  0.49323]
21Feb12_232147| [-1.12687 -0.77820  0.21195 -0.33038]
21Feb12_232147| [ 0.65272  0.18763 -0.05432  0.13593]
21Feb12_232147| [ 0.55334  0.94725  0.25358 -0.43635]
21Feb12_232147| [-1.07432  0.56233 -0.92488  0.49818]
21Feb12_232147| [ 0.54917  0.47714 -0.71581  0.28568]
21Feb12_232147| [ 0.74296  1.21411 -0.25897 -0.06134]
21Feb12_232147| [-2.26559 -1.44219 -0.35266  0.02409]
21Feb12_232147| [-1.56621 -1.96934  0.04624 -0.05266]
21Feb12_232147| [-0.32211  2.53154 -0.19339 -0.01619]
21Feb12_232147| [-1.62310  0.86832 -1.59048 -0.25297]
21Feb12_232147| [ 0.01383  1.33516 -0.97640  0.42359]
21Feb12_232147| [ 0.60856 -1.04358  0.50439 -0.42649]
21Feb12_232147| [ 1.38760  1.47011 -0.82651  0.27243]
21Feb12_232147| [-0.78439  0.61616  1.12318  0.46024]
21Feb12_232147| [ 1.01039 -1.11643 -0.10615  0.16438]
21Feb12_232147| [-0.60194  0.16256  0.69794  0.42338]
21Feb12_232147| [ 1.29789 -0.66201 -0.54308 -0.41395]
21Feb12_232147| [ 1.27111 -0.80429 -0.45608  0.43618]
21Feb12_232147| [-0.30043 -0.17224  0.73640  0.39627]
21Feb12_232147| [ 1.06895 -0.11087 -0.49826  0.03048]
21Feb12_232147| [-0.24413  0.52260  0.19550 -0.28699]
21Feb12_232147| [ 0.28284  0.77646 -0.25399 -0.07475]
21Feb12_232147| [-0.55158 -0.29051 -0.23798  0.46269]
21Feb12_232147| [-0.38260 -1.40522  0.63413 -0.29225]
21Feb12_232147| [ 0.03139  0.20183 -0.08841  0.37224]
21Feb12_232147| [-1.48545 -0.91705 -0.13515 -0.46855]
21Feb12_232147| [ 0.47649 -0.27177  0.82744  0.39112]
21Feb12_232147| [-1.87642 -0.32403 -0.23635  0.30883]
21Feb12_232147| [-1.23419 -0.11716  0.28717  0.04225]
21Feb12_232147| [-2.71438 -0.35530  0.90248 -0.14798]
21Feb12_232147| [ 1.26386 -0.32541 -0.00451  0.09379]
21Feb12_232147| [ 2.19550  0.91671 -0.98338 -0.43225]
21Feb12_232147| [ 0.48682 -0.34951  0.40278  0.32559]
21Feb12_232147| [ 0.87740 -0.34327  0.09753 -0.43035]]
21Feb12_232147|-- Bias --
21Feb12_232147|[-1.61088 -0.25085  0.53274  0.21367]
21Feb12_232147|Layer 1:
21Feb12_232147|-- Config --
21Feb12_232147|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232147|-- Weights --
21Feb12_232147|[[ 0.85045  0.02234]
21Feb12_232147| [ 0.15146  0.55865]
21Feb12_232147| [-0.04185  0.06756]
21Feb12_232147| [-0.47434  0.49266]]
21Feb12_232147|-- Bias --
21Feb12_232147|[-1.03310 -1.04658]
21Feb12_232147|Layer 2:
21Feb12_232147|-- Config --
21Feb12_232147|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232147|-- Weights --
21Feb12_232147|[[ 0.71153 -0.44529]
21Feb12_232147| [-0.44942 -0.32761]]
21Feb12_232147|-- Bias --
21Feb12_232147|[ 0.85309 -0.84290]
21Feb12_232147|Layer 3:
21Feb12_232147|-- Config --
21Feb12_232147|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232147|-- Weights --
21Feb12_232147|[[1.27656 0.06911]
21Feb12_232147| [0.53547 2.59670]]
21Feb12_232147|-- Bias --
21Feb12_232147|[-0.73581 -0.51354]
21Feb12_232147|Predicting the validation and test data with the Best final individual.
21Feb12_232156| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_232156|-----------  ------------------  --------------------  ----------
21Feb12_232156|Validation         42.09                  24            0.00258
21Feb12_232156|   Test            36.40                  24            0.00000
21Feb12_232156|-------------------- Test #2 --------------------
21Feb12_232156|Best final individual weights
21Feb12_232156|Individual:
21Feb12_232156|-- Constant hidden layers --
21Feb12_232156|False
21Feb12_232156|Layer 0:
21Feb12_232156|-- Config --
21Feb12_232156|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232156|-- Weights --
21Feb12_232156|[[-0.88430  0.38744  0.30429 -0.19493]
21Feb12_232156| [-0.07106  0.05862  1.34480 -0.46391]
21Feb12_232156| [ 0.06174 -1.01753  0.91730  0.44578]
21Feb12_232156| [ 0.65403 -0.46094 -0.43710  0.06277]
21Feb12_232156| [ 0.26691  0.05663  1.01849  0.33034]
21Feb12_232156| [ 0.62238 -1.16873 -1.03042  0.43068]
21Feb12_232156| [ 0.61110 -1.46840  0.44994 -0.28322]
21Feb12_232156| [-0.82124  1.02884 -0.40450  0.40306]
21Feb12_232156| [-0.56817  1.43936 -0.79233 -0.31949]
21Feb12_232156| [-0.11266  1.07052 -0.57275  0.01036]
21Feb12_232156| [ 0.32740 -1.66256 -1.22600  0.11828]
21Feb12_232156| [-0.70810 -2.31320 -1.10761 -0.40808]
21Feb12_232156| [ 0.93245  0.36786 -0.79838 -0.10952]
21Feb12_232156| [-1.07525 -0.60551 -0.66128  0.02992]
21Feb12_232156| [-0.94245 -0.40706 -0.82415  0.29567]
21Feb12_232156| [ 0.71756 -0.08265  0.79341  0.29860]
21Feb12_232156| [-1.59746  1.81339  1.55303 -0.37562]
21Feb12_232156| [-0.36642 -1.51142 -1.06142 -0.09675]
21Feb12_232156| [-1.24167 -0.48675  1.07870 -0.49966]
21Feb12_232156| [-0.37284 -1.07562  0.98240  0.46102]
21Feb12_232156| [-1.56216  0.77984 -0.56551  0.16250]
21Feb12_232156| [ 1.07349 -1.90915  0.46168 -0.11103]
21Feb12_232156| [-1.33189  0.95651 -0.22357  0.49323]
21Feb12_232156| [-1.12687 -0.77820  0.21195 -0.33038]
21Feb12_232156| [ 0.65272  0.18763 -0.05432  0.13593]
21Feb12_232156| [ 0.55334  0.94725  0.25358 -0.43635]
21Feb12_232156| [-1.07432  0.56233 -0.92488  0.49818]
21Feb12_232156| [ 0.54917  0.47714 -0.71581  0.28568]
21Feb12_232156| [ 0.74296  1.21411 -0.25897 -0.06134]
21Feb12_232156| [-2.26559 -1.44219 -0.35266  0.02409]
21Feb12_232156| [-1.56621 -1.96934  0.04624 -0.05266]
21Feb12_232156| [-0.32211  2.53154 -0.19339 -0.01619]
21Feb12_232156| [-1.62310  0.86832 -1.59048 -0.25297]
21Feb12_232156| [ 0.01383  1.33516 -0.97640  0.42359]
21Feb12_232156| [ 0.60856 -1.04358  0.50439 -0.42649]
21Feb12_232156| [ 1.38760  1.47011 -0.82651  0.27243]
21Feb12_232156| [-0.78439  0.61616  1.12318  0.46024]
21Feb12_232156| [ 1.01039 -1.11643 -0.10615  0.16438]
21Feb12_232156| [-0.60194  0.16256  0.69794  0.42338]
21Feb12_232156| [ 1.29789 -0.66201 -0.54308 -0.41395]
21Feb12_232156| [ 1.27111 -0.80429 -0.45608  0.43618]
21Feb12_232156| [-0.30043 -0.17224  0.73640  0.39627]
21Feb12_232156| [ 1.06895 -0.11087 -0.49826  0.03048]
21Feb12_232156| [-0.24413  0.52260  0.19550 -0.28699]
21Feb12_232156| [ 0.28284  0.77646 -0.25399 -0.07475]
21Feb12_232156| [-0.55158 -0.29051 -0.23798  0.46269]
21Feb12_232156| [-0.38260 -1.40522  0.63413 -0.29225]
21Feb12_232156| [ 0.03139  0.20183 -0.08841  0.37224]
21Feb12_232156| [-1.48545 -0.91705 -0.13515 -0.46855]
21Feb12_232156| [ 0.47649 -0.27177  0.82744  0.39112]
21Feb12_232156| [-1.87642 -0.32403 -0.23635  0.30883]
21Feb12_232156| [-1.23419 -0.11716  0.28717  0.04225]
21Feb12_232156| [-2.71438 -0.35530  0.90248 -0.14798]
21Feb12_232156| [ 1.26386 -0.32541 -0.00451  0.09379]
21Feb12_232156| [ 2.19550  0.91671 -0.98338 -0.43225]
21Feb12_232156| [ 0.48682 -0.34951  0.40278  0.32559]
21Feb12_232156| [ 0.87740 -0.34327  0.09753 -0.43035]]
21Feb12_232156|-- Bias --
21Feb12_232156|[-1.61088 -0.25085  0.53274  0.21367]
21Feb12_232156|Layer 1:
21Feb12_232156|-- Config --
21Feb12_232156|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232156|-- Weights --
21Feb12_232156|[[ 0.85045  0.02234]
21Feb12_232156| [ 0.15146  0.55865]
21Feb12_232156| [-0.04185  0.06756]
21Feb12_232156| [-0.47434  0.49266]]
21Feb12_232156|-- Bias --
21Feb12_232156|[-1.03310 -1.04658]
21Feb12_232156|Layer 2:
21Feb12_232156|-- Config --
21Feb12_232156|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232156|-- Weights --
21Feb12_232156|[[ 0.71153 -0.44529]
21Feb12_232156| [-0.44942 -0.32761]]
21Feb12_232156|-- Bias --
21Feb12_232156|[ 0.85309 -0.84290]
21Feb12_232156|Layer 3:
21Feb12_232156|-- Config --
21Feb12_232156|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232156|-- Weights --
21Feb12_232156|[[1.27656 0.06911]
21Feb12_232156| [0.53547 2.59670]]
21Feb12_232156|-- Bias --
21Feb12_232156|[-0.73581 -0.51354]
21Feb12_232156|Predicting the validation and test data with the Best final individual.
21Feb12_232203| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_232203|-----------  ------------------  --------------------  ----------
21Feb12_232203|Validation         25.13                  24            0.68656
21Feb12_232203|   Test            51.17                  24            0.77670
21Feb12_232203|-------------------- Test #3 --------------------
21Feb12_232203|Best final individual weights
21Feb12_232203|Individual:
21Feb12_232203|-- Constant hidden layers --
21Feb12_232203|False
21Feb12_232203|Layer 0:
21Feb12_232203|-- Config --
21Feb12_232203|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232203|-- Weights --
21Feb12_232203|[[-0.88430  0.38744  0.30429 -0.19493]
21Feb12_232203| [-0.07106  0.05862  1.34480 -0.46391]
21Feb12_232203| [ 0.06174 -1.01753  0.91730  0.44578]
21Feb12_232203| [ 0.65403 -0.46094 -0.43710  0.06277]
21Feb12_232203| [ 0.26691  0.05663  1.01849  0.33034]
21Feb12_232203| [ 0.62238 -1.16873 -1.03042  0.43068]
21Feb12_232203| [ 0.61110 -1.46840  0.44994 -0.28322]
21Feb12_232203| [-0.82124  1.02884 -0.40450  0.40306]
21Feb12_232203| [-0.56817  1.43936 -0.79233 -0.31949]
21Feb12_232203| [-0.11266  1.07052 -0.57275  0.01036]
21Feb12_232203| [ 0.32740 -1.66256 -1.22600  0.11828]
21Feb12_232203| [-0.70810 -2.31320 -1.10761 -0.40808]
21Feb12_232203| [ 0.93245  0.36786 -0.79838 -0.10952]
21Feb12_232203| [-1.07525 -0.60551 -0.66128  0.02992]
21Feb12_232203| [-0.94245 -0.40706 -0.82415  0.29567]
21Feb12_232203| [ 0.71756 -0.08265  0.79341  0.29860]
21Feb12_232203| [-1.59746  1.81339  1.55303 -0.37562]
21Feb12_232203| [-0.36642 -1.51142 -1.06142 -0.09675]
21Feb12_232203| [-1.24167 -0.48675  1.07870 -0.49966]
21Feb12_232203| [-0.37284 -1.07562  0.98240  0.46102]
21Feb12_232203| [-1.56216  0.77984 -0.56551  0.16250]
21Feb12_232203| [ 1.07349 -1.90915  0.46168 -0.11103]
21Feb12_232203| [-1.33189  0.95651 -0.22357  0.49323]
21Feb12_232203| [-1.12687 -0.77820  0.21195 -0.33038]
21Feb12_232203| [ 0.65272  0.18763 -0.05432  0.13593]
21Feb12_232203| [ 0.55334  0.94725  0.25358 -0.43635]
21Feb12_232203| [-1.07432  0.56233 -0.92488  0.49818]
21Feb12_232203| [ 0.54917  0.47714 -0.71581  0.28568]
21Feb12_232203| [ 0.74296  1.21411 -0.25897 -0.06134]
21Feb12_232203| [-2.26559 -1.44219 -0.35266  0.02409]
21Feb12_232203| [-1.56621 -1.96934  0.04624 -0.05266]
21Feb12_232203| [-0.32211  2.53154 -0.19339 -0.01619]
21Feb12_232203| [-1.62310  0.86832 -1.59048 -0.25297]
21Feb12_232203| [ 0.01383  1.33516 -0.97640  0.42359]
21Feb12_232203| [ 0.60856 -1.04358  0.50439 -0.42649]
21Feb12_232203| [ 1.38760  1.47011 -0.82651  0.27243]
21Feb12_232203| [-0.78439  0.61616  1.12318  0.46024]
21Feb12_232203| [ 1.01039 -1.11643 -0.10615  0.16438]
21Feb12_232203| [-0.60194  0.16256  0.69794  0.42338]
21Feb12_232203| [ 1.29789 -0.66201 -0.54308 -0.41395]
21Feb12_232203| [ 1.27111 -0.80429 -0.45608  0.43618]
21Feb12_232203| [-0.30043 -0.17224  0.73640  0.39627]
21Feb12_232203| [ 1.06895 -0.11087 -0.49826  0.03048]
21Feb12_232203| [-0.24413  0.52260  0.19550 -0.28699]
21Feb12_232203| [ 0.28284  0.77646 -0.25399 -0.07475]
21Feb12_232203| [-0.55158 -0.29051 -0.23798  0.46269]
21Feb12_232203| [-0.38260 -1.40522  0.63413 -0.29225]
21Feb12_232203| [ 0.03139  0.20183 -0.08841  0.37224]
21Feb12_232203| [-1.48545 -0.91705 -0.13515 -0.46855]
21Feb12_232203| [ 0.47649 -0.27177  0.82744  0.39112]
21Feb12_232203| [-1.87642 -0.32403 -0.23635  0.30883]
21Feb12_232203| [-1.23419 -0.11716  0.28717  0.04225]
21Feb12_232203| [-2.71438 -0.35530  0.90248 -0.14798]
21Feb12_232203| [ 1.26386 -0.32541 -0.00451  0.09379]
21Feb12_232203| [ 2.19550  0.91671 -0.98338 -0.43225]
21Feb12_232203| [ 0.48682 -0.34951  0.40278  0.32559]
21Feb12_232203| [ 0.87740 -0.34327  0.09753 -0.43035]]
21Feb12_232203|-- Bias --
21Feb12_232203|[-1.61088 -0.25085  0.53274  0.21367]
21Feb12_232203|Layer 1:
21Feb12_232203|-- Config --
21Feb12_232203|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232203|-- Weights --
21Feb12_232203|[[ 0.85045  0.02234]
21Feb12_232203| [ 0.15146  0.55865]
21Feb12_232203| [-0.04185  0.06756]
21Feb12_232203| [-0.47434  0.49266]]
21Feb12_232203|-- Bias --
21Feb12_232203|[-1.03310 -1.04658]
21Feb12_232203|Layer 2:
21Feb12_232203|-- Config --
21Feb12_232203|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232203|-- Weights --
21Feb12_232203|[[ 0.71153 -0.44529]
21Feb12_232203| [-0.44942 -0.32761]]
21Feb12_232203|-- Bias --
21Feb12_232203|[ 0.85309 -0.84290]
21Feb12_232203|Layer 3:
21Feb12_232203|-- Config --
21Feb12_232203|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232203|-- Weights --
21Feb12_232203|[[1.27656 0.06911]
21Feb12_232203| [0.53547 2.59670]]
21Feb12_232203|-- Bias --
21Feb12_232203|[-0.73581 -0.51354]
21Feb12_232203|Predicting the validation and test data with the Best final individual.
21Feb12_232211| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_232211|-----------  ------------------  --------------------  ----------
21Feb12_232211|Validation         23.30                  24            0.78369
21Feb12_232211|   Test            23.89                  24            0.82605
21Feb12_232211|-------------------- Test #4 --------------------
21Feb12_232211|Best final individual weights
21Feb12_232211|Individual:
21Feb12_232211|-- Constant hidden layers --
21Feb12_232211|False
21Feb12_232211|Layer 0:
21Feb12_232211|-- Config --
21Feb12_232211|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232211|-- Weights --
21Feb12_232211|[[-0.88430  0.38744  0.30429 -0.19493]
21Feb12_232211| [-0.07106  0.05862  1.34480 -0.46391]
21Feb12_232211| [ 0.06174 -1.01753  0.91730  0.44578]
21Feb12_232211| [ 0.65403 -0.46094 -0.43710  0.06277]
21Feb12_232211| [ 0.26691  0.05663  1.01849  0.33034]
21Feb12_232211| [ 0.62238 -1.16873 -1.03042  0.43068]
21Feb12_232211| [ 0.61110 -1.46840  0.44994 -0.28322]
21Feb12_232211| [-0.82124  1.02884 -0.40450  0.40306]
21Feb12_232211| [-0.56817  1.43936 -0.79233 -0.31949]
21Feb12_232211| [-0.11266  1.07052 -0.57275  0.01036]
21Feb12_232211| [ 0.32740 -1.66256 -1.22600  0.11828]
21Feb12_232211| [-0.70810 -2.31320 -1.10761 -0.40808]
21Feb12_232211| [ 0.93245  0.36786 -0.79838 -0.10952]
21Feb12_232211| [-1.07525 -0.60551 -0.66128  0.02992]
21Feb12_232211| [-0.94245 -0.40706 -0.82415  0.29567]
21Feb12_232211| [ 0.71756 -0.08265  0.79341  0.29860]
21Feb12_232211| [-1.59746  1.81339  1.55303 -0.37562]
21Feb12_232211| [-0.36642 -1.51142 -1.06142 -0.09675]
21Feb12_232211| [-1.24167 -0.48675  1.07870 -0.49966]
21Feb12_232211| [-0.37284 -1.07562  0.98240  0.46102]
21Feb12_232211| [-1.56216  0.77984 -0.56551  0.16250]
21Feb12_232211| [ 1.07349 -1.90915  0.46168 -0.11103]
21Feb12_232211| [-1.33189  0.95651 -0.22357  0.49323]
21Feb12_232211| [-1.12687 -0.77820  0.21195 -0.33038]
21Feb12_232211| [ 0.65272  0.18763 -0.05432  0.13593]
21Feb12_232211| [ 0.55334  0.94725  0.25358 -0.43635]
21Feb12_232211| [-1.07432  0.56233 -0.92488  0.49818]
21Feb12_232211| [ 0.54917  0.47714 -0.71581  0.28568]
21Feb12_232211| [ 0.74296  1.21411 -0.25897 -0.06134]
21Feb12_232211| [-2.26559 -1.44219 -0.35266  0.02409]
21Feb12_232211| [-1.56621 -1.96934  0.04624 -0.05266]
21Feb12_232211| [-0.32211  2.53154 -0.19339 -0.01619]
21Feb12_232211| [-1.62310  0.86832 -1.59048 -0.25297]
21Feb12_232211| [ 0.01383  1.33516 -0.97640  0.42359]
21Feb12_232211| [ 0.60856 -1.04358  0.50439 -0.42649]
21Feb12_232211| [ 1.38760  1.47011 -0.82651  0.27243]
21Feb12_232211| [-0.78439  0.61616  1.12318  0.46024]
21Feb12_232211| [ 1.01039 -1.11643 -0.10615  0.16438]
21Feb12_232211| [-0.60194  0.16256  0.69794  0.42338]
21Feb12_232211| [ 1.29789 -0.66201 -0.54308 -0.41395]
21Feb12_232211| [ 1.27111 -0.80429 -0.45608  0.43618]
21Feb12_232211| [-0.30043 -0.17224  0.73640  0.39627]
21Feb12_232211| [ 1.06895 -0.11087 -0.49826  0.03048]
21Feb12_232211| [-0.24413  0.52260  0.19550 -0.28699]
21Feb12_232211| [ 0.28284  0.77646 -0.25399 -0.07475]
21Feb12_232211| [-0.55158 -0.29051 -0.23798  0.46269]
21Feb12_232211| [-0.38260 -1.40522  0.63413 -0.29225]
21Feb12_232211| [ 0.03139  0.20183 -0.08841  0.37224]
21Feb12_232211| [-1.48545 -0.91705 -0.13515 -0.46855]
21Feb12_232211| [ 0.47649 -0.27177  0.82744  0.39112]
21Feb12_232211| [-1.87642 -0.32403 -0.23635  0.30883]
21Feb12_232211| [-1.23419 -0.11716  0.28717  0.04225]
21Feb12_232211| [-2.71438 -0.35530  0.90248 -0.14798]
21Feb12_232211| [ 1.26386 -0.32541 -0.00451  0.09379]
21Feb12_232211| [ 2.19550  0.91671 -0.98338 -0.43225]
21Feb12_232211| [ 0.48682 -0.34951  0.40278  0.32559]
21Feb12_232211| [ 0.87740 -0.34327  0.09753 -0.43035]]
21Feb12_232211|-- Bias --
21Feb12_232211|[-1.61088 -0.25085  0.53274  0.21367]
21Feb12_232211|Layer 1:
21Feb12_232211|-- Config --
21Feb12_232211|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232211|-- Weights --
21Feb12_232211|[[ 0.85045  0.02234]
21Feb12_232211| [ 0.15146  0.55865]
21Feb12_232211| [-0.04185  0.06756]
21Feb12_232211| [-0.47434  0.49266]]
21Feb12_232211|-- Bias --
21Feb12_232211|[-1.03310 -1.04658]
21Feb12_232211|Layer 2:
21Feb12_232211|-- Config --
21Feb12_232211|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232211|-- Weights --
21Feb12_232211|[[ 0.71153 -0.44529]
21Feb12_232211| [-0.44942 -0.32761]]
21Feb12_232211|-- Bias --
21Feb12_232211|[ 0.85309 -0.84290]
21Feb12_232211|Layer 3:
21Feb12_232211|-- Config --
21Feb12_232211|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232211|-- Weights --
21Feb12_232211|[[1.27656 0.06911]
21Feb12_232211| [0.53547 2.59670]]
21Feb12_232211|-- Bias --
21Feb12_232211|[-0.73581 -0.51354]
21Feb12_232211|Predicting the validation and test data with the Best final individual.
21Feb12_232219| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_232219|-----------  ------------------  --------------------  ----------
21Feb12_232219|Validation         22.52                  24            0.74713
21Feb12_232219|   Test            36.40                  24            0.00000
21Feb12_232219|-------------------- Test #5 --------------------
21Feb12_232219|Best final individual weights
21Feb12_232219|Individual:
21Feb12_232219|-- Constant hidden layers --
21Feb12_232219|False
21Feb12_232219|Layer 0:
21Feb12_232219|-- Config --
21Feb12_232219|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232219|-- Weights --
21Feb12_232219|[[-0.88430  0.38744  0.30429 -0.19493]
21Feb12_232219| [-0.07106  0.05862  1.34480 -0.46391]
21Feb12_232219| [ 0.06174 -1.01753  0.91730  0.44578]
21Feb12_232219| [ 0.65403 -0.46094 -0.43710  0.06277]
21Feb12_232219| [ 0.26691  0.05663  1.01849  0.33034]
21Feb12_232219| [ 0.62238 -1.16873 -1.03042  0.43068]
21Feb12_232219| [ 0.61110 -1.46840  0.44994 -0.28322]
21Feb12_232219| [-0.82124  1.02884 -0.40450  0.40306]
21Feb12_232219| [-0.56817  1.43936 -0.79233 -0.31949]
21Feb12_232219| [-0.11266  1.07052 -0.57275  0.01036]
21Feb12_232219| [ 0.32740 -1.66256 -1.22600  0.11828]
21Feb12_232219| [-0.70810 -2.31320 -1.10761 -0.40808]
21Feb12_232219| [ 0.93245  0.36786 -0.79838 -0.10952]
21Feb12_232219| [-1.07525 -0.60551 -0.66128  0.02992]
21Feb12_232219| [-0.94245 -0.40706 -0.82415  0.29567]
21Feb12_232219| [ 0.71756 -0.08265  0.79341  0.29860]
21Feb12_232219| [-1.59746  1.81339  1.55303 -0.37562]
21Feb12_232219| [-0.36642 -1.51142 -1.06142 -0.09675]
21Feb12_232219| [-1.24167 -0.48675  1.07870 -0.49966]
21Feb12_232219| [-0.37284 -1.07562  0.98240  0.46102]
21Feb12_232219| [-1.56216  0.77984 -0.56551  0.16250]
21Feb12_232219| [ 1.07349 -1.90915  0.46168 -0.11103]
21Feb12_232219| [-1.33189  0.95651 -0.22357  0.49323]
21Feb12_232219| [-1.12687 -0.77820  0.21195 -0.33038]
21Feb12_232219| [ 0.65272  0.18763 -0.05432  0.13593]
21Feb12_232219| [ 0.55334  0.94725  0.25358 -0.43635]
21Feb12_232219| [-1.07432  0.56233 -0.92488  0.49818]
21Feb12_232219| [ 0.54917  0.47714 -0.71581  0.28568]
21Feb12_232219| [ 0.74296  1.21411 -0.25897 -0.06134]
21Feb12_232219| [-2.26559 -1.44219 -0.35266  0.02409]
21Feb12_232219| [-1.56621 -1.96934  0.04624 -0.05266]
21Feb12_232219| [-0.32211  2.53154 -0.19339 -0.01619]
21Feb12_232219| [-1.62310  0.86832 -1.59048 -0.25297]
21Feb12_232219| [ 0.01383  1.33516 -0.97640  0.42359]
21Feb12_232219| [ 0.60856 -1.04358  0.50439 -0.42649]
21Feb12_232219| [ 1.38760  1.47011 -0.82651  0.27243]
21Feb12_232219| [-0.78439  0.61616  1.12318  0.46024]
21Feb12_232219| [ 1.01039 -1.11643 -0.10615  0.16438]
21Feb12_232219| [-0.60194  0.16256  0.69794  0.42338]
21Feb12_232219| [ 1.29789 -0.66201 -0.54308 -0.41395]
21Feb12_232219| [ 1.27111 -0.80429 -0.45608  0.43618]
21Feb12_232219| [-0.30043 -0.17224  0.73640  0.39627]
21Feb12_232219| [ 1.06895 -0.11087 -0.49826  0.03048]
21Feb12_232219| [-0.24413  0.52260  0.19550 -0.28699]
21Feb12_232219| [ 0.28284  0.77646 -0.25399 -0.07475]
21Feb12_232219| [-0.55158 -0.29051 -0.23798  0.46269]
21Feb12_232219| [-0.38260 -1.40522  0.63413 -0.29225]
21Feb12_232219| [ 0.03139  0.20183 -0.08841  0.37224]
21Feb12_232219| [-1.48545 -0.91705 -0.13515 -0.46855]
21Feb12_232219| [ 0.47649 -0.27177  0.82744  0.39112]
21Feb12_232219| [-1.87642 -0.32403 -0.23635  0.30883]
21Feb12_232219| [-1.23419 -0.11716  0.28717  0.04225]
21Feb12_232219| [-2.71438 -0.35530  0.90248 -0.14798]
21Feb12_232219| [ 1.26386 -0.32541 -0.00451  0.09379]
21Feb12_232219| [ 2.19550  0.91671 -0.98338 -0.43225]
21Feb12_232219| [ 0.48682 -0.34951  0.40278  0.32559]
21Feb12_232219| [ 0.87740 -0.34327  0.09753 -0.43035]]
21Feb12_232219|-- Bias --
21Feb12_232219|[-1.61088 -0.25085  0.53274  0.21367]
21Feb12_232219|Layer 1:
21Feb12_232219|-- Config --
21Feb12_232219|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232219|-- Weights --
21Feb12_232219|[[ 0.85045  0.02234]
21Feb12_232219| [ 0.15146  0.55865]
21Feb12_232219| [-0.04185  0.06756]
21Feb12_232219| [-0.47434  0.49266]]
21Feb12_232219|-- Bias --
21Feb12_232219|[-1.03310 -1.04658]
21Feb12_232219|Layer 2:
21Feb12_232219|-- Config --
21Feb12_232219|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232219|-- Weights --
21Feb12_232219|[[ 0.71153 -0.44529]
21Feb12_232219| [-0.44942 -0.32761]]
21Feb12_232219|-- Bias --
21Feb12_232219|[ 0.85309 -0.84290]
21Feb12_232219|Layer 3:
21Feb12_232219|-- Config --
21Feb12_232219|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232219|-- Weights --
21Feb12_232219|[[1.27656 0.06911]
21Feb12_232219| [0.53547 2.59670]]
21Feb12_232219|-- Bias --
21Feb12_232219|[-0.73581 -0.51354]
21Feb12_232219|Predicting the validation and test data with the Best final individual.
21Feb12_232227| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_232227|-----------  ------------------  --------------------  ----------
21Feb12_232227|Validation         42.17                  24            0.00258
21Feb12_232227|   Test            32.32                  24            0.77656
21Feb12_232227|-------------------- Test #6 --------------------
21Feb12_232227|Best final individual weights
21Feb12_232227|Individual:
21Feb12_232227|-- Constant hidden layers --
21Feb12_232227|False
21Feb12_232227|Layer 0:
21Feb12_232227|-- Config --
21Feb12_232227|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232227|-- Weights --
21Feb12_232227|[[-0.88430  0.38744  0.30429 -0.19493]
21Feb12_232227| [-0.07106  0.05862  1.34480 -0.46391]
21Feb12_232227| [ 0.06174 -1.01753  0.91730  0.44578]
21Feb12_232227| [ 0.65403 -0.46094 -0.43710  0.06277]
21Feb12_232227| [ 0.26691  0.05663  1.01849  0.33034]
21Feb12_232227| [ 0.62238 -1.16873 -1.03042  0.43068]
21Feb12_232227| [ 0.61110 -1.46840  0.44994 -0.28322]
21Feb12_232227| [-0.82124  1.02884 -0.40450  0.40306]
21Feb12_232227| [-0.56817  1.43936 -0.79233 -0.31949]
21Feb12_232227| [-0.11266  1.07052 -0.57275  0.01036]
21Feb12_232227| [ 0.32740 -1.66256 -1.22600  0.11828]
21Feb12_232227| [-0.70810 -2.31320 -1.10761 -0.40808]
21Feb12_232227| [ 0.93245  0.36786 -0.79838 -0.10952]
21Feb12_232227| [-1.07525 -0.60551 -0.66128  0.02992]
21Feb12_232227| [-0.94245 -0.40706 -0.82415  0.29567]
21Feb12_232227| [ 0.71756 -0.08265  0.79341  0.29860]
21Feb12_232227| [-1.59746  1.81339  1.55303 -0.37562]
21Feb12_232227| [-0.36642 -1.51142 -1.06142 -0.09675]
21Feb12_232227| [-1.24167 -0.48675  1.07870 -0.49966]
21Feb12_232227| [-0.37284 -1.07562  0.98240  0.46102]
21Feb12_232227| [-1.56216  0.77984 -0.56551  0.16250]
21Feb12_232227| [ 1.07349 -1.90915  0.46168 -0.11103]
21Feb12_232227| [-1.33189  0.95651 -0.22357  0.49323]
21Feb12_232227| [-1.12687 -0.77820  0.21195 -0.33038]
21Feb12_232227| [ 0.65272  0.18763 -0.05432  0.13593]
21Feb12_232227| [ 0.55334  0.94725  0.25358 -0.43635]
21Feb12_232227| [-1.07432  0.56233 -0.92488  0.49818]
21Feb12_232227| [ 0.54917  0.47714 -0.71581  0.28568]
21Feb12_232227| [ 0.74296  1.21411 -0.25897 -0.06134]
21Feb12_232227| [-2.26559 -1.44219 -0.35266  0.02409]
21Feb12_232227| [-1.56621 -1.96934  0.04624 -0.05266]
21Feb12_232227| [-0.32211  2.53154 -0.19339 -0.01619]
21Feb12_232227| [-1.62310  0.86832 -1.59048 -0.25297]
21Feb12_232227| [ 0.01383  1.33516 -0.97640  0.42359]
21Feb12_232227| [ 0.60856 -1.04358  0.50439 -0.42649]
21Feb12_232227| [ 1.38760  1.47011 -0.82651  0.27243]
21Feb12_232227| [-0.78439  0.61616  1.12318  0.46024]
21Feb12_232227| [ 1.01039 -1.11643 -0.10615  0.16438]
21Feb12_232227| [-0.60194  0.16256  0.69794  0.42338]
21Feb12_232227| [ 1.29789 -0.66201 -0.54308 -0.41395]
21Feb12_232227| [ 1.27111 -0.80429 -0.45608  0.43618]
21Feb12_232227| [-0.30043 -0.17224  0.73640  0.39627]
21Feb12_232227| [ 1.06895 -0.11087 -0.49826  0.03048]
21Feb12_232227| [-0.24413  0.52260  0.19550 -0.28699]
21Feb12_232227| [ 0.28284  0.77646 -0.25399 -0.07475]
21Feb12_232227| [-0.55158 -0.29051 -0.23798  0.46269]
21Feb12_232227| [-0.38260 -1.40522  0.63413 -0.29225]
21Feb12_232227| [ 0.03139  0.20183 -0.08841  0.37224]
21Feb12_232227| [-1.48545 -0.91705 -0.13515 -0.46855]
21Feb12_232227| [ 0.47649 -0.27177  0.82744  0.39112]
21Feb12_232227| [-1.87642 -0.32403 -0.23635  0.30883]
21Feb12_232227| [-1.23419 -0.11716  0.28717  0.04225]
21Feb12_232227| [-2.71438 -0.35530  0.90248 -0.14798]
21Feb12_232227| [ 1.26386 -0.32541 -0.00451  0.09379]
21Feb12_232227| [ 2.19550  0.91671 -0.98338 -0.43225]
21Feb12_232227| [ 0.48682 -0.34951  0.40278  0.32559]
21Feb12_232227| [ 0.87740 -0.34327  0.09753 -0.43035]]
21Feb12_232227|-- Bias --
21Feb12_232227|[-1.61088 -0.25085  0.53274  0.21367]
21Feb12_232227|Layer 1:
21Feb12_232227|-- Config --
21Feb12_232227|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232227|-- Weights --
21Feb12_232227|[[ 0.85045  0.02234]
21Feb12_232227| [ 0.15146  0.55865]
21Feb12_232227| [-0.04185  0.06756]
21Feb12_232227| [-0.47434  0.49266]]
21Feb12_232227|-- Bias --
21Feb12_232227|[-1.03310 -1.04658]
21Feb12_232227|Layer 2:
21Feb12_232227|-- Config --
21Feb12_232227|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232227|-- Weights --
21Feb12_232227|[[ 0.71153 -0.44529]
21Feb12_232227| [-0.44942 -0.32761]]
21Feb12_232227|-- Bias --
21Feb12_232227|[ 0.85309 -0.84290]
21Feb12_232227|Layer 3:
21Feb12_232227|-- Config --
21Feb12_232227|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232227|-- Weights --
21Feb12_232227|[[1.27656 0.06911]
21Feb12_232227| [0.53547 2.59670]]
21Feb12_232227|-- Bias --
21Feb12_232227|[-0.73581 -0.51354]
21Feb12_232227|Predicting the validation and test data with the Best final individual.
21Feb12_232235| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_232235|-----------  ------------------  --------------------  ----------
21Feb12_232235|Validation         25.39                  24            0.83556
21Feb12_232235|   Test            36.49                  24            0.00000
21Feb12_232235|-------------------- Test #7 --------------------
21Feb12_232235|Best final individual weights
21Feb12_232235|Individual:
21Feb12_232235|-- Constant hidden layers --
21Feb12_232235|False
21Feb12_232235|Layer 0:
21Feb12_232235|-- Config --
21Feb12_232235|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232235|-- Weights --
21Feb12_232235|[[-0.88430  0.38744  0.30429 -0.19493]
21Feb12_232235| [-0.07106  0.05862  1.34480 -0.46391]
21Feb12_232235| [ 0.06174 -1.01753  0.91730  0.44578]
21Feb12_232235| [ 0.65403 -0.46094 -0.43710  0.06277]
21Feb12_232235| [ 0.26691  0.05663  1.01849  0.33034]
21Feb12_232235| [ 0.62238 -1.16873 -1.03042  0.43068]
21Feb12_232235| [ 0.61110 -1.46840  0.44994 -0.28322]
21Feb12_232235| [-0.82124  1.02884 -0.40450  0.40306]
21Feb12_232235| [-0.56817  1.43936 -0.79233 -0.31949]
21Feb12_232235| [-0.11266  1.07052 -0.57275  0.01036]
21Feb12_232235| [ 0.32740 -1.66256 -1.22600  0.11828]
21Feb12_232235| [-0.70810 -2.31320 -1.10761 -0.40808]
21Feb12_232235| [ 0.93245  0.36786 -0.79838 -0.10952]
21Feb12_232235| [-1.07525 -0.60551 -0.66128  0.02992]
21Feb12_232235| [-0.94245 -0.40706 -0.82415  0.29567]
21Feb12_232235| [ 0.71756 -0.08265  0.79341  0.29860]
21Feb12_232235| [-1.59746  1.81339  1.55303 -0.37562]
21Feb12_232235| [-0.36642 -1.51142 -1.06142 -0.09675]
21Feb12_232235| [-1.24167 -0.48675  1.07870 -0.49966]
21Feb12_232235| [-0.37284 -1.07562  0.98240  0.46102]
21Feb12_232235| [-1.56216  0.77984 -0.56551  0.16250]
21Feb12_232235| [ 1.07349 -1.90915  0.46168 -0.11103]
21Feb12_232235| [-1.33189  0.95651 -0.22357  0.49323]
21Feb12_232235| [-1.12687 -0.77820  0.21195 -0.33038]
21Feb12_232235| [ 0.65272  0.18763 -0.05432  0.13593]
21Feb12_232235| [ 0.55334  0.94725  0.25358 -0.43635]
21Feb12_232235| [-1.07432  0.56233 -0.92488  0.49818]
21Feb12_232235| [ 0.54917  0.47714 -0.71581  0.28568]
21Feb12_232235| [ 0.74296  1.21411 -0.25897 -0.06134]
21Feb12_232235| [-2.26559 -1.44219 -0.35266  0.02409]
21Feb12_232235| [-1.56621 -1.96934  0.04624 -0.05266]
21Feb12_232235| [-0.32211  2.53154 -0.19339 -0.01619]
21Feb12_232235| [-1.62310  0.86832 -1.59048 -0.25297]
21Feb12_232235| [ 0.01383  1.33516 -0.97640  0.42359]
21Feb12_232235| [ 0.60856 -1.04358  0.50439 -0.42649]
21Feb12_232235| [ 1.38760  1.47011 -0.82651  0.27243]
21Feb12_232235| [-0.78439  0.61616  1.12318  0.46024]
21Feb12_232235| [ 1.01039 -1.11643 -0.10615  0.16438]
21Feb12_232235| [-0.60194  0.16256  0.69794  0.42338]
21Feb12_232235| [ 1.29789 -0.66201 -0.54308 -0.41395]
21Feb12_232235| [ 1.27111 -0.80429 -0.45608  0.43618]
21Feb12_232235| [-0.30043 -0.17224  0.73640  0.39627]
21Feb12_232235| [ 1.06895 -0.11087 -0.49826  0.03048]
21Feb12_232235| [-0.24413  0.52260  0.19550 -0.28699]
21Feb12_232235| [ 0.28284  0.77646 -0.25399 -0.07475]
21Feb12_232235| [-0.55158 -0.29051 -0.23798  0.46269]
21Feb12_232235| [-0.38260 -1.40522  0.63413 -0.29225]
21Feb12_232235| [ 0.03139  0.20183 -0.08841  0.37224]
21Feb12_232235| [-1.48545 -0.91705 -0.13515 -0.46855]
21Feb12_232235| [ 0.47649 -0.27177  0.82744  0.39112]
21Feb12_232235| [-1.87642 -0.32403 -0.23635  0.30883]
21Feb12_232235| [-1.23419 -0.11716  0.28717  0.04225]
21Feb12_232235| [-2.71438 -0.35530  0.90248 -0.14798]
21Feb12_232235| [ 1.26386 -0.32541 -0.00451  0.09379]
21Feb12_232235| [ 2.19550  0.91671 -0.98338 -0.43225]
21Feb12_232235| [ 0.48682 -0.34951  0.40278  0.32559]
21Feb12_232235| [ 0.87740 -0.34327  0.09753 -0.43035]]
21Feb12_232235|-- Bias --
21Feb12_232235|[-1.61088 -0.25085  0.53274  0.21367]
21Feb12_232235|Layer 1:
21Feb12_232235|-- Config --
21Feb12_232235|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232235|-- Weights --
21Feb12_232235|[[ 0.85045  0.02234]
21Feb12_232235| [ 0.15146  0.55865]
21Feb12_232235| [-0.04185  0.06756]
21Feb12_232235| [-0.47434  0.49266]]
21Feb12_232235|-- Bias --
21Feb12_232235|[-1.03310 -1.04658]
21Feb12_232235|Layer 2:
21Feb12_232235|-- Config --
21Feb12_232235|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232235|-- Weights --
21Feb12_232235|[[ 0.71153 -0.44529]
21Feb12_232235| [-0.44942 -0.32761]]
21Feb12_232235|-- Bias --
21Feb12_232235|[ 0.85309 -0.84290]
21Feb12_232235|Layer 3:
21Feb12_232235|-- Config --
21Feb12_232235|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232235|-- Weights --
21Feb12_232235|[[1.27656 0.06911]
21Feb12_232235| [0.53547 2.59670]]
21Feb12_232235|-- Bias --
21Feb12_232235|[-0.73581 -0.51354]
21Feb12_232235|Predicting the validation and test data with the Best final individual.
21Feb12_232242| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_232242|-----------  ------------------  --------------------  ----------
21Feb12_232242|Validation         24.43                  24            0.77000
21Feb12_232242|   Test            33.28                  24            0.81553
21Feb12_232242|-------------------- Test #8 --------------------
21Feb12_232242|Best final individual weights
21Feb12_232242|Individual:
21Feb12_232242|-- Constant hidden layers --
21Feb12_232242|False
21Feb12_232242|Layer 0:
21Feb12_232242|-- Config --
21Feb12_232242|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232242|-- Weights --
21Feb12_232242|[[-0.88430  0.38744  0.30429 -0.19493]
21Feb12_232242| [-0.07106  0.05862  1.34480 -0.46391]
21Feb12_232242| [ 0.06174 -1.01753  0.91730  0.44578]
21Feb12_232242| [ 0.65403 -0.46094 -0.43710  0.06277]
21Feb12_232242| [ 0.26691  0.05663  1.01849  0.33034]
21Feb12_232242| [ 0.62238 -1.16873 -1.03042  0.43068]
21Feb12_232242| [ 0.61110 -1.46840  0.44994 -0.28322]
21Feb12_232242| [-0.82124  1.02884 -0.40450  0.40306]
21Feb12_232242| [-0.56817  1.43936 -0.79233 -0.31949]
21Feb12_232242| [-0.11266  1.07052 -0.57275  0.01036]
21Feb12_232242| [ 0.32740 -1.66256 -1.22600  0.11828]
21Feb12_232242| [-0.70810 -2.31320 -1.10761 -0.40808]
21Feb12_232242| [ 0.93245  0.36786 -0.79838 -0.10952]
21Feb12_232242| [-1.07525 -0.60551 -0.66128  0.02992]
21Feb12_232242| [-0.94245 -0.40706 -0.82415  0.29567]
21Feb12_232242| [ 0.71756 -0.08265  0.79341  0.29860]
21Feb12_232242| [-1.59746  1.81339  1.55303 -0.37562]
21Feb12_232242| [-0.36642 -1.51142 -1.06142 -0.09675]
21Feb12_232242| [-1.24167 -0.48675  1.07870 -0.49966]
21Feb12_232242| [-0.37284 -1.07562  0.98240  0.46102]
21Feb12_232242| [-1.56216  0.77984 -0.56551  0.16250]
21Feb12_232242| [ 1.07349 -1.90915  0.46168 -0.11103]
21Feb12_232242| [-1.33189  0.95651 -0.22357  0.49323]
21Feb12_232242| [-1.12687 -0.77820  0.21195 -0.33038]
21Feb12_232242| [ 0.65272  0.18763 -0.05432  0.13593]
21Feb12_232242| [ 0.55334  0.94725  0.25358 -0.43635]
21Feb12_232242| [-1.07432  0.56233 -0.92488  0.49818]
21Feb12_232242| [ 0.54917  0.47714 -0.71581  0.28568]
21Feb12_232242| [ 0.74296  1.21411 -0.25897 -0.06134]
21Feb12_232242| [-2.26559 -1.44219 -0.35266  0.02409]
21Feb12_232242| [-1.56621 -1.96934  0.04624 -0.05266]
21Feb12_232242| [-0.32211  2.53154 -0.19339 -0.01619]
21Feb12_232242| [-1.62310  0.86832 -1.59048 -0.25297]
21Feb12_232242| [ 0.01383  1.33516 -0.97640  0.42359]
21Feb12_232242| [ 0.60856 -1.04358  0.50439 -0.42649]
21Feb12_232242| [ 1.38760  1.47011 -0.82651  0.27243]
21Feb12_232242| [-0.78439  0.61616  1.12318  0.46024]
21Feb12_232242| [ 1.01039 -1.11643 -0.10615  0.16438]
21Feb12_232242| [-0.60194  0.16256  0.69794  0.42338]
21Feb12_232242| [ 1.29789 -0.66201 -0.54308 -0.41395]
21Feb12_232242| [ 1.27111 -0.80429 -0.45608  0.43618]
21Feb12_232242| [-0.30043 -0.17224  0.73640  0.39627]
21Feb12_232242| [ 1.06895 -0.11087 -0.49826  0.03048]
21Feb12_232242| [-0.24413  0.52260  0.19550 -0.28699]
21Feb12_232242| [ 0.28284  0.77646 -0.25399 -0.07475]
21Feb12_232242| [-0.55158 -0.29051 -0.23798  0.46269]
21Feb12_232242| [-0.38260 -1.40522  0.63413 -0.29225]
21Feb12_232242| [ 0.03139  0.20183 -0.08841  0.37224]
21Feb12_232242| [-1.48545 -0.91705 -0.13515 -0.46855]
21Feb12_232242| [ 0.47649 -0.27177  0.82744  0.39112]
21Feb12_232242| [-1.87642 -0.32403 -0.23635  0.30883]
21Feb12_232242| [-1.23419 -0.11716  0.28717  0.04225]
21Feb12_232242| [-2.71438 -0.35530  0.90248 -0.14798]
21Feb12_232242| [ 1.26386 -0.32541 -0.00451  0.09379]
21Feb12_232242| [ 2.19550  0.91671 -0.98338 -0.43225]
21Feb12_232242| [ 0.48682 -0.34951  0.40278  0.32559]
21Feb12_232242| [ 0.87740 -0.34327  0.09753 -0.43035]]
21Feb12_232242|-- Bias --
21Feb12_232242|[-1.61088 -0.25085  0.53274  0.21367]
21Feb12_232242|Layer 1:
21Feb12_232242|-- Config --
21Feb12_232242|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232242|-- Weights --
21Feb12_232242|[[ 0.85045  0.02234]
21Feb12_232242| [ 0.15146  0.55865]
21Feb12_232242| [-0.04185  0.06756]
21Feb12_232242| [-0.47434  0.49266]]
21Feb12_232242|-- Bias --
21Feb12_232242|[-1.03310 -1.04658]
21Feb12_232242|Layer 2:
21Feb12_232242|-- Config --
21Feb12_232242|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232242|-- Weights --
21Feb12_232242|[[ 0.71153 -0.44529]
21Feb12_232242| [-0.44942 -0.32761]]
21Feb12_232242|-- Bias --
21Feb12_232242|[ 0.85309 -0.84290]
21Feb12_232242|Layer 3:
21Feb12_232242|-- Config --
21Feb12_232242|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232242|-- Weights --
21Feb12_232242|[[1.27656 0.06911]
21Feb12_232242| [0.53547 2.59670]]
21Feb12_232242|-- Bias --
21Feb12_232242|[-0.73581 -0.51354]
21Feb12_232242|Predicting the validation and test data with the Best final individual.
21Feb12_232250| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_232250|-----------  ------------------  --------------------  ----------
21Feb12_232250|Validation         24.87                  24            0.79568
21Feb12_232250|   Test            24.93                  24            0.77370
21Feb12_232250|-------------------- Test #9 --------------------
21Feb12_232250|Best final individual weights
21Feb12_232250|Individual:
21Feb12_232250|-- Constant hidden layers --
21Feb12_232250|False
21Feb12_232250|Layer 0:
21Feb12_232250|-- Config --
21Feb12_232250|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232250|-- Weights --
21Feb12_232250|[[-0.88430  0.38744  0.30429 -0.19493]
21Feb12_232250| [-0.07106  0.05862  1.34480 -0.46391]
21Feb12_232250| [ 0.06174 -1.01753  0.91730  0.44578]
21Feb12_232250| [ 0.65403 -0.46094 -0.43710  0.06277]
21Feb12_232250| [ 0.26691  0.05663  1.01849  0.33034]
21Feb12_232250| [ 0.62238 -1.16873 -1.03042  0.43068]
21Feb12_232250| [ 0.61110 -1.46840  0.44994 -0.28322]
21Feb12_232250| [-0.82124  1.02884 -0.40450  0.40306]
21Feb12_232250| [-0.56817  1.43936 -0.79233 -0.31949]
21Feb12_232250| [-0.11266  1.07052 -0.57275  0.01036]
21Feb12_232250| [ 0.32740 -1.66256 -1.22600  0.11828]
21Feb12_232250| [-0.70810 -2.31320 -1.10761 -0.40808]
21Feb12_232250| [ 0.93245  0.36786 -0.79838 -0.10952]
21Feb12_232250| [-1.07525 -0.60551 -0.66128  0.02992]
21Feb12_232250| [-0.94245 -0.40706 -0.82415  0.29567]
21Feb12_232250| [ 0.71756 -0.08265  0.79341  0.29860]
21Feb12_232250| [-1.59746  1.81339  1.55303 -0.37562]
21Feb12_232250| [-0.36642 -1.51142 -1.06142 -0.09675]
21Feb12_232250| [-1.24167 -0.48675  1.07870 -0.49966]
21Feb12_232250| [-0.37284 -1.07562  0.98240  0.46102]
21Feb12_232250| [-1.56216  0.77984 -0.56551  0.16250]
21Feb12_232250| [ 1.07349 -1.90915  0.46168 -0.11103]
21Feb12_232250| [-1.33189  0.95651 -0.22357  0.49323]
21Feb12_232250| [-1.12687 -0.77820  0.21195 -0.33038]
21Feb12_232250| [ 0.65272  0.18763 -0.05432  0.13593]
21Feb12_232250| [ 0.55334  0.94725  0.25358 -0.43635]
21Feb12_232250| [-1.07432  0.56233 -0.92488  0.49818]
21Feb12_232250| [ 0.54917  0.47714 -0.71581  0.28568]
21Feb12_232250| [ 0.74296  1.21411 -0.25897 -0.06134]
21Feb12_232250| [-2.26559 -1.44219 -0.35266  0.02409]
21Feb12_232250| [-1.56621 -1.96934  0.04624 -0.05266]
21Feb12_232250| [-0.32211  2.53154 -0.19339 -0.01619]
21Feb12_232250| [-1.62310  0.86832 -1.59048 -0.25297]
21Feb12_232250| [ 0.01383  1.33516 -0.97640  0.42359]
21Feb12_232250| [ 0.60856 -1.04358  0.50439 -0.42649]
21Feb12_232250| [ 1.38760  1.47011 -0.82651  0.27243]
21Feb12_232250| [-0.78439  0.61616  1.12318  0.46024]
21Feb12_232250| [ 1.01039 -1.11643 -0.10615  0.16438]
21Feb12_232250| [-0.60194  0.16256  0.69794  0.42338]
21Feb12_232250| [ 1.29789 -0.66201 -0.54308 -0.41395]
21Feb12_232250| [ 1.27111 -0.80429 -0.45608  0.43618]
21Feb12_232250| [-0.30043 -0.17224  0.73640  0.39627]
21Feb12_232250| [ 1.06895 -0.11087 -0.49826  0.03048]
21Feb12_232250| [-0.24413  0.52260  0.19550 -0.28699]
21Feb12_232250| [ 0.28284  0.77646 -0.25399 -0.07475]
21Feb12_232250| [-0.55158 -0.29051 -0.23798  0.46269]
21Feb12_232250| [-0.38260 -1.40522  0.63413 -0.29225]
21Feb12_232250| [ 0.03139  0.20183 -0.08841  0.37224]
21Feb12_232250| [-1.48545 -0.91705 -0.13515 -0.46855]
21Feb12_232250| [ 0.47649 -0.27177  0.82744  0.39112]
21Feb12_232250| [-1.87642 -0.32403 -0.23635  0.30883]
21Feb12_232250| [-1.23419 -0.11716  0.28717  0.04225]
21Feb12_232250| [-2.71438 -0.35530  0.90248 -0.14798]
21Feb12_232250| [ 1.26386 -0.32541 -0.00451  0.09379]
21Feb12_232250| [ 2.19550  0.91671 -0.98338 -0.43225]
21Feb12_232250| [ 0.48682 -0.34951  0.40278  0.32559]
21Feb12_232250| [ 0.87740 -0.34327  0.09753 -0.43035]]
21Feb12_232250|-- Bias --
21Feb12_232250|[-1.61088 -0.25085  0.53274  0.21367]
21Feb12_232250|Layer 1:
21Feb12_232250|-- Config --
21Feb12_232250|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232250|-- Weights --
21Feb12_232250|[[ 0.85045  0.02234]
21Feb12_232250| [ 0.15146  0.55865]
21Feb12_232250| [-0.04185  0.06756]
21Feb12_232250| [-0.47434  0.49266]]
21Feb12_232250|-- Bias --
21Feb12_232250|[-1.03310 -1.04658]
21Feb12_232250|Layer 2:
21Feb12_232250|-- Config --
21Feb12_232250|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232250|-- Weights --
21Feb12_232250|[[ 0.71153 -0.44529]
21Feb12_232250| [-0.44942 -0.32761]]
21Feb12_232250|-- Bias --
21Feb12_232250|[ 0.85309 -0.84290]
21Feb12_232250|Layer 3:
21Feb12_232250|-- Config --
21Feb12_232250|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232250|-- Weights --
21Feb12_232250|[[1.27656 0.06911]
21Feb12_232250| [0.53547 2.59670]]
21Feb12_232250|-- Bias --
21Feb12_232250|[-0.73581 -0.51354]
21Feb12_232250|Predicting the validation and test data with the Best final individual.
21Feb12_232258| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_232258|-----------  ------------------  --------------------  ----------
21Feb12_232258|Validation         23.83                  24            0.69089
21Feb12_232258|   Test            22.94                  24            0.75012
21Feb12_232258|-------------------- Test #10 --------------------
21Feb12_232258|Best final individual weights
21Feb12_232258|Individual:
21Feb12_232258|-- Constant hidden layers --
21Feb12_232258|False
21Feb12_232258|Layer 0:
21Feb12_232258|-- Config --
21Feb12_232258|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232258|-- Weights --
21Feb12_232258|[[-0.88430  0.38744  0.30429 -0.19493]
21Feb12_232258| [-0.07106  0.05862  1.34480 -0.46391]
21Feb12_232258| [ 0.06174 -1.01753  0.91730  0.44578]
21Feb12_232258| [ 0.65403 -0.46094 -0.43710  0.06277]
21Feb12_232258| [ 0.26691  0.05663  1.01849  0.33034]
21Feb12_232258| [ 0.62238 -1.16873 -1.03042  0.43068]
21Feb12_232258| [ 0.61110 -1.46840  0.44994 -0.28322]
21Feb12_232258| [-0.82124  1.02884 -0.40450  0.40306]
21Feb12_232258| [-0.56817  1.43936 -0.79233 -0.31949]
21Feb12_232258| [-0.11266  1.07052 -0.57275  0.01036]
21Feb12_232258| [ 0.32740 -1.66256 -1.22600  0.11828]
21Feb12_232258| [-0.70810 -2.31320 -1.10761 -0.40808]
21Feb12_232258| [ 0.93245  0.36786 -0.79838 -0.10952]
21Feb12_232258| [-1.07525 -0.60551 -0.66128  0.02992]
21Feb12_232258| [-0.94245 -0.40706 -0.82415  0.29567]
21Feb12_232258| [ 0.71756 -0.08265  0.79341  0.29860]
21Feb12_232258| [-1.59746  1.81339  1.55303 -0.37562]
21Feb12_232258| [-0.36642 -1.51142 -1.06142 -0.09675]
21Feb12_232258| [-1.24167 -0.48675  1.07870 -0.49966]
21Feb12_232258| [-0.37284 -1.07562  0.98240  0.46102]
21Feb12_232258| [-1.56216  0.77984 -0.56551  0.16250]
21Feb12_232258| [ 1.07349 -1.90915  0.46168 -0.11103]
21Feb12_232258| [-1.33189  0.95651 -0.22357  0.49323]
21Feb12_232258| [-1.12687 -0.77820  0.21195 -0.33038]
21Feb12_232258| [ 0.65272  0.18763 -0.05432  0.13593]
21Feb12_232258| [ 0.55334  0.94725  0.25358 -0.43635]
21Feb12_232258| [-1.07432  0.56233 -0.92488  0.49818]
21Feb12_232258| [ 0.54917  0.47714 -0.71581  0.28568]
21Feb12_232258| [ 0.74296  1.21411 -0.25897 -0.06134]
21Feb12_232258| [-2.26559 -1.44219 -0.35266  0.02409]
21Feb12_232258| [-1.56621 -1.96934  0.04624 -0.05266]
21Feb12_232258| [-0.32211  2.53154 -0.19339 -0.01619]
21Feb12_232258| [-1.62310  0.86832 -1.59048 -0.25297]
21Feb12_232258| [ 0.01383  1.33516 -0.97640  0.42359]
21Feb12_232258| [ 0.60856 -1.04358  0.50439 -0.42649]
21Feb12_232258| [ 1.38760  1.47011 -0.82651  0.27243]
21Feb12_232258| [-0.78439  0.61616  1.12318  0.46024]
21Feb12_232258| [ 1.01039 -1.11643 -0.10615  0.16438]
21Feb12_232258| [-0.60194  0.16256  0.69794  0.42338]
21Feb12_232258| [ 1.29789 -0.66201 -0.54308 -0.41395]
21Feb12_232258| [ 1.27111 -0.80429 -0.45608  0.43618]
21Feb12_232258| [-0.30043 -0.17224  0.73640  0.39627]
21Feb12_232258| [ 1.06895 -0.11087 -0.49826  0.03048]
21Feb12_232258| [-0.24413  0.52260  0.19550 -0.28699]
21Feb12_232258| [ 0.28284  0.77646 -0.25399 -0.07475]
21Feb12_232258| [-0.55158 -0.29051 -0.23798  0.46269]
21Feb12_232258| [-0.38260 -1.40522  0.63413 -0.29225]
21Feb12_232258| [ 0.03139  0.20183 -0.08841  0.37224]
21Feb12_232258| [-1.48545 -0.91705 -0.13515 -0.46855]
21Feb12_232258| [ 0.47649 -0.27177  0.82744  0.39112]
21Feb12_232258| [-1.87642 -0.32403 -0.23635  0.30883]
21Feb12_232258| [-1.23419 -0.11716  0.28717  0.04225]
21Feb12_232258| [-2.71438 -0.35530  0.90248 -0.14798]
21Feb12_232258| [ 1.26386 -0.32541 -0.00451  0.09379]
21Feb12_232258| [ 2.19550  0.91671 -0.98338 -0.43225]
21Feb12_232258| [ 0.48682 -0.34951  0.40278  0.32559]
21Feb12_232258| [ 0.87740 -0.34327  0.09753 -0.43035]]
21Feb12_232258|-- Bias --
21Feb12_232258|[-1.61088 -0.25085  0.53274  0.21367]
21Feb12_232258|Layer 1:
21Feb12_232258|-- Config --
21Feb12_232258|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232258|-- Weights --
21Feb12_232258|[[ 0.85045  0.02234]
21Feb12_232258| [ 0.15146  0.55865]
21Feb12_232258| [-0.04185  0.06756]
21Feb12_232258| [-0.47434  0.49266]]
21Feb12_232258|-- Bias --
21Feb12_232258|[-1.03310 -1.04658]
21Feb12_232258|Layer 2:
21Feb12_232258|-- Config --
21Feb12_232258|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232258|-- Weights --
21Feb12_232258|[[ 0.71153 -0.44529]
21Feb12_232258| [-0.44942 -0.32761]]
21Feb12_232258|-- Bias --
21Feb12_232258|[ 0.85309 -0.84290]
21Feb12_232258|Layer 3:
21Feb12_232258|-- Config --
21Feb12_232258|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232258|-- Weights --
21Feb12_232258|[[1.27656 0.06911]
21Feb12_232258| [0.53547 2.59670]]
21Feb12_232258|-- Bias --
21Feb12_232258|[-0.73581 -0.51354]
21Feb12_232258|Predicting the validation and test data with the Best final individual.
21Feb12_232306| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_232306|-----------  ------------------  --------------------  ----------
21Feb12_232306|Validation         22.96                  24            0.68922
21Feb12_232306|   Test            36.40                  24            0.00000
21Feb12_232306|-------------------- Test #11 --------------------
21Feb12_232306|Best final individual weights
21Feb12_232306|Individual:
21Feb12_232306|-- Constant hidden layers --
21Feb12_232306|False
21Feb12_232306|Layer 0:
21Feb12_232306|-- Config --
21Feb12_232306|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232306|-- Weights --
21Feb12_232306|[[-0.88430  0.38744  0.30429 -0.19493]
21Feb12_232306| [-0.07106  0.05862  1.34480 -0.46391]
21Feb12_232306| [ 0.06174 -1.01753  0.91730  0.44578]
21Feb12_232306| [ 0.65403 -0.46094 -0.43710  0.06277]
21Feb12_232306| [ 0.26691  0.05663  1.01849  0.33034]
21Feb12_232306| [ 0.62238 -1.16873 -1.03042  0.43068]
21Feb12_232306| [ 0.61110 -1.46840  0.44994 -0.28322]
21Feb12_232306| [-0.82124  1.02884 -0.40450  0.40306]
21Feb12_232306| [-0.56817  1.43936 -0.79233 -0.31949]
21Feb12_232306| [-0.11266  1.07052 -0.57275  0.01036]
21Feb12_232306| [ 0.32740 -1.66256 -1.22600  0.11828]
21Feb12_232306| [-0.70810 -2.31320 -1.10761 -0.40808]
21Feb12_232306| [ 0.93245  0.36786 -0.79838 -0.10952]
21Feb12_232306| [-1.07525 -0.60551 -0.66128  0.02992]
21Feb12_232306| [-0.94245 -0.40706 -0.82415  0.29567]
21Feb12_232306| [ 0.71756 -0.08265  0.79341  0.29860]
21Feb12_232306| [-1.59746  1.81339  1.55303 -0.37562]
21Feb12_232306| [-0.36642 -1.51142 -1.06142 -0.09675]
21Feb12_232306| [-1.24167 -0.48675  1.07870 -0.49966]
21Feb12_232306| [-0.37284 -1.07562  0.98240  0.46102]
21Feb12_232306| [-1.56216  0.77984 -0.56551  0.16250]
21Feb12_232306| [ 1.07349 -1.90915  0.46168 -0.11103]
21Feb12_232306| [-1.33189  0.95651 -0.22357  0.49323]
21Feb12_232306| [-1.12687 -0.77820  0.21195 -0.33038]
21Feb12_232306| [ 0.65272  0.18763 -0.05432  0.13593]
21Feb12_232306| [ 0.55334  0.94725  0.25358 -0.43635]
21Feb12_232306| [-1.07432  0.56233 -0.92488  0.49818]
21Feb12_232306| [ 0.54917  0.47714 -0.71581  0.28568]
21Feb12_232306| [ 0.74296  1.21411 -0.25897 -0.06134]
21Feb12_232306| [-2.26559 -1.44219 -0.35266  0.02409]
21Feb12_232306| [-1.56621 -1.96934  0.04624 -0.05266]
21Feb12_232306| [-0.32211  2.53154 -0.19339 -0.01619]
21Feb12_232306| [-1.62310  0.86832 -1.59048 -0.25297]
21Feb12_232306| [ 0.01383  1.33516 -0.97640  0.42359]
21Feb12_232306| [ 0.60856 -1.04358  0.50439 -0.42649]
21Feb12_232306| [ 1.38760  1.47011 -0.82651  0.27243]
21Feb12_232306| [-0.78439  0.61616  1.12318  0.46024]
21Feb12_232306| [ 1.01039 -1.11643 -0.10615  0.16438]
21Feb12_232306| [-0.60194  0.16256  0.69794  0.42338]
21Feb12_232306| [ 1.29789 -0.66201 -0.54308 -0.41395]
21Feb12_232306| [ 1.27111 -0.80429 -0.45608  0.43618]
21Feb12_232306| [-0.30043 -0.17224  0.73640  0.39627]
21Feb12_232306| [ 1.06895 -0.11087 -0.49826  0.03048]
21Feb12_232306| [-0.24413  0.52260  0.19550 -0.28699]
21Feb12_232306| [ 0.28284  0.77646 -0.25399 -0.07475]
21Feb12_232306| [-0.55158 -0.29051 -0.23798  0.46269]
21Feb12_232306| [-0.38260 -1.40522  0.63413 -0.29225]
21Feb12_232306| [ 0.03139  0.20183 -0.08841  0.37224]
21Feb12_232306| [-1.48545 -0.91705 -0.13515 -0.46855]
21Feb12_232306| [ 0.47649 -0.27177  0.82744  0.39112]
21Feb12_232306| [-1.87642 -0.32403 -0.23635  0.30883]
21Feb12_232306| [-1.23419 -0.11716  0.28717  0.04225]
21Feb12_232306| [-2.71438 -0.35530  0.90248 -0.14798]
21Feb12_232306| [ 1.26386 -0.32541 -0.00451  0.09379]
21Feb12_232306| [ 2.19550  0.91671 -0.98338 -0.43225]
21Feb12_232306| [ 0.48682 -0.34951  0.40278  0.32559]
21Feb12_232306| [ 0.87740 -0.34327  0.09753 -0.43035]]
21Feb12_232306|-- Bias --
21Feb12_232306|[-1.61088 -0.25085  0.53274  0.21367]
21Feb12_232306|Layer 1:
21Feb12_232306|-- Config --
21Feb12_232306|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232306|-- Weights --
21Feb12_232306|[[ 0.85045  0.02234]
21Feb12_232306| [ 0.15146  0.55865]
21Feb12_232306| [-0.04185  0.06756]
21Feb12_232306| [-0.47434  0.49266]]
21Feb12_232306|-- Bias --
21Feb12_232306|[-1.03310 -1.04658]
21Feb12_232306|Layer 2:
21Feb12_232306|-- Config --
21Feb12_232306|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232306|-- Weights --
21Feb12_232306|[[ 0.71153 -0.44529]
21Feb12_232306| [-0.44942 -0.32761]]
21Feb12_232306|-- Bias --
21Feb12_232306|[ 0.85309 -0.84290]
21Feb12_232306|Layer 3:
21Feb12_232306|-- Config --
21Feb12_232306|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232306|-- Weights --
21Feb12_232306|[[1.27656 0.06911]
21Feb12_232306| [0.53547 2.59670]]
21Feb12_232306|-- Bias --
21Feb12_232306|[-0.73581 -0.51354]
21Feb12_232306|Predicting the validation and test data with the Best final individual.
21Feb12_232314| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_232314|-----------  ------------------  --------------------  ----------
21Feb12_232314|Validation         43.91                  24            0.81552
21Feb12_232314|   Test            22.68                  24            0.69629
21Feb12_232314|-------------------- Test #12 --------------------
21Feb12_232314|Best final individual weights
21Feb12_232314|Individual:
21Feb12_232314|-- Constant hidden layers --
21Feb12_232314|False
21Feb12_232314|Layer 0:
21Feb12_232314|-- Config --
21Feb12_232314|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232314|-- Weights --
21Feb12_232314|[[-0.88430  0.38744  0.30429 -0.19493]
21Feb12_232314| [-0.07106  0.05862  1.34480 -0.46391]
21Feb12_232314| [ 0.06174 -1.01753  0.91730  0.44578]
21Feb12_232314| [ 0.65403 -0.46094 -0.43710  0.06277]
21Feb12_232314| [ 0.26691  0.05663  1.01849  0.33034]
21Feb12_232314| [ 0.62238 -1.16873 -1.03042  0.43068]
21Feb12_232314| [ 0.61110 -1.46840  0.44994 -0.28322]
21Feb12_232314| [-0.82124  1.02884 -0.40450  0.40306]
21Feb12_232314| [-0.56817  1.43936 -0.79233 -0.31949]
21Feb12_232314| [-0.11266  1.07052 -0.57275  0.01036]
21Feb12_232314| [ 0.32740 -1.66256 -1.22600  0.11828]
21Feb12_232314| [-0.70810 -2.31320 -1.10761 -0.40808]
21Feb12_232314| [ 0.93245  0.36786 -0.79838 -0.10952]
21Feb12_232314| [-1.07525 -0.60551 -0.66128  0.02992]
21Feb12_232314| [-0.94245 -0.40706 -0.82415  0.29567]
21Feb12_232314| [ 0.71756 -0.08265  0.79341  0.29860]
21Feb12_232314| [-1.59746  1.81339  1.55303 -0.37562]
21Feb12_232314| [-0.36642 -1.51142 -1.06142 -0.09675]
21Feb12_232314| [-1.24167 -0.48675  1.07870 -0.49966]
21Feb12_232314| [-0.37284 -1.07562  0.98240  0.46102]
21Feb12_232314| [-1.56216  0.77984 -0.56551  0.16250]
21Feb12_232314| [ 1.07349 -1.90915  0.46168 -0.11103]
21Feb12_232314| [-1.33189  0.95651 -0.22357  0.49323]
21Feb12_232314| [-1.12687 -0.77820  0.21195 -0.33038]
21Feb12_232314| [ 0.65272  0.18763 -0.05432  0.13593]
21Feb12_232314| [ 0.55334  0.94725  0.25358 -0.43635]
21Feb12_232314| [-1.07432  0.56233 -0.92488  0.49818]
21Feb12_232314| [ 0.54917  0.47714 -0.71581  0.28568]
21Feb12_232314| [ 0.74296  1.21411 -0.25897 -0.06134]
21Feb12_232314| [-2.26559 -1.44219 -0.35266  0.02409]
21Feb12_232314| [-1.56621 -1.96934  0.04624 -0.05266]
21Feb12_232314| [-0.32211  2.53154 -0.19339 -0.01619]
21Feb12_232314| [-1.62310  0.86832 -1.59048 -0.25297]
21Feb12_232314| [ 0.01383  1.33516 -0.97640  0.42359]
21Feb12_232314| [ 0.60856 -1.04358  0.50439 -0.42649]
21Feb12_232314| [ 1.38760  1.47011 -0.82651  0.27243]
21Feb12_232314| [-0.78439  0.61616  1.12318  0.46024]
21Feb12_232314| [ 1.01039 -1.11643 -0.10615  0.16438]
21Feb12_232314| [-0.60194  0.16256  0.69794  0.42338]
21Feb12_232314| [ 1.29789 -0.66201 -0.54308 -0.41395]
21Feb12_232314| [ 1.27111 -0.80429 -0.45608  0.43618]
21Feb12_232314| [-0.30043 -0.17224  0.73640  0.39627]
21Feb12_232314| [ 1.06895 -0.11087 -0.49826  0.03048]
21Feb12_232314| [-0.24413  0.52260  0.19550 -0.28699]
21Feb12_232314| [ 0.28284  0.77646 -0.25399 -0.07475]
21Feb12_232314| [-0.55158 -0.29051 -0.23798  0.46269]
21Feb12_232314| [-0.38260 -1.40522  0.63413 -0.29225]
21Feb12_232314| [ 0.03139  0.20183 -0.08841  0.37224]
21Feb12_232314| [-1.48545 -0.91705 -0.13515 -0.46855]
21Feb12_232314| [ 0.47649 -0.27177  0.82744  0.39112]
21Feb12_232314| [-1.87642 -0.32403 -0.23635  0.30883]
21Feb12_232314| [-1.23419 -0.11716  0.28717  0.04225]
21Feb12_232314| [-2.71438 -0.35530  0.90248 -0.14798]
21Feb12_232314| [ 1.26386 -0.32541 -0.00451  0.09379]
21Feb12_232314| [ 2.19550  0.91671 -0.98338 -0.43225]
21Feb12_232314| [ 0.48682 -0.34951  0.40278  0.32559]
21Feb12_232314| [ 0.87740 -0.34327  0.09753 -0.43035]]
21Feb12_232314|-- Bias --
21Feb12_232314|[-1.61088 -0.25085  0.53274  0.21367]
21Feb12_232314|Layer 1:
21Feb12_232314|-- Config --
21Feb12_232314|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232314|-- Weights --
21Feb12_232314|[[ 0.85045  0.02234]
21Feb12_232314| [ 0.15146  0.55865]
21Feb12_232314| [-0.04185  0.06756]
21Feb12_232314| [-0.47434  0.49266]]
21Feb12_232314|-- Bias --
21Feb12_232314|[-1.03310 -1.04658]
21Feb12_232314|Layer 2:
21Feb12_232314|-- Config --
21Feb12_232314|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232314|-- Weights --
21Feb12_232314|[[ 0.71153 -0.44529]
21Feb12_232314| [-0.44942 -0.32761]]
21Feb12_232314|-- Bias --
21Feb12_232314|[ 0.85309 -0.84290]
21Feb12_232314|Layer 3:
21Feb12_232314|-- Config --
21Feb12_232314|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232314|-- Weights --
21Feb12_232314|[[1.27656 0.06911]
21Feb12_232314| [0.53547 2.59670]]
21Feb12_232314|-- Bias --
21Feb12_232314|[-0.73581 -0.51354]
21Feb12_232314|Predicting the validation and test data with the Best final individual.
21Feb12_232322| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_232322|-----------  ------------------  --------------------  ----------
21Feb12_232322|Validation         22.00                  24            0.79936
21Feb12_232322|   Test            25.28                  24            0.76768
21Feb12_232322|-------------------- Test #13 --------------------
21Feb12_232322|Best final individual weights
21Feb12_232322|Individual:
21Feb12_232322|-- Constant hidden layers --
21Feb12_232322|False
21Feb12_232322|Layer 0:
21Feb12_232322|-- Config --
21Feb12_232322|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232322|-- Weights --
21Feb12_232322|[[-0.88430  0.38744  0.30429 -0.19493]
21Feb12_232322| [-0.07106  0.05862  1.34480 -0.46391]
21Feb12_232322| [ 0.06174 -1.01753  0.91730  0.44578]
21Feb12_232322| [ 0.65403 -0.46094 -0.43710  0.06277]
21Feb12_232322| [ 0.26691  0.05663  1.01849  0.33034]
21Feb12_232322| [ 0.62238 -1.16873 -1.03042  0.43068]
21Feb12_232322| [ 0.61110 -1.46840  0.44994 -0.28322]
21Feb12_232322| [-0.82124  1.02884 -0.40450  0.40306]
21Feb12_232322| [-0.56817  1.43936 -0.79233 -0.31949]
21Feb12_232322| [-0.11266  1.07052 -0.57275  0.01036]
21Feb12_232322| [ 0.32740 -1.66256 -1.22600  0.11828]
21Feb12_232322| [-0.70810 -2.31320 -1.10761 -0.40808]
21Feb12_232322| [ 0.93245  0.36786 -0.79838 -0.10952]
21Feb12_232322| [-1.07525 -0.60551 -0.66128  0.02992]
21Feb12_232322| [-0.94245 -0.40706 -0.82415  0.29567]
21Feb12_232322| [ 0.71756 -0.08265  0.79341  0.29860]
21Feb12_232322| [-1.59746  1.81339  1.55303 -0.37562]
21Feb12_232322| [-0.36642 -1.51142 -1.06142 -0.09675]
21Feb12_232322| [-1.24167 -0.48675  1.07870 -0.49966]
21Feb12_232322| [-0.37284 -1.07562  0.98240  0.46102]
21Feb12_232322| [-1.56216  0.77984 -0.56551  0.16250]
21Feb12_232322| [ 1.07349 -1.90915  0.46168 -0.11103]
21Feb12_232322| [-1.33189  0.95651 -0.22357  0.49323]
21Feb12_232322| [-1.12687 -0.77820  0.21195 -0.33038]
21Feb12_232322| [ 0.65272  0.18763 -0.05432  0.13593]
21Feb12_232322| [ 0.55334  0.94725  0.25358 -0.43635]
21Feb12_232322| [-1.07432  0.56233 -0.92488  0.49818]
21Feb12_232322| [ 0.54917  0.47714 -0.71581  0.28568]
21Feb12_232322| [ 0.74296  1.21411 -0.25897 -0.06134]
21Feb12_232322| [-2.26559 -1.44219 -0.35266  0.02409]
21Feb12_232322| [-1.56621 -1.96934  0.04624 -0.05266]
21Feb12_232322| [-0.32211  2.53154 -0.19339 -0.01619]
21Feb12_232322| [-1.62310  0.86832 -1.59048 -0.25297]
21Feb12_232322| [ 0.01383  1.33516 -0.97640  0.42359]
21Feb12_232322| [ 0.60856 -1.04358  0.50439 -0.42649]
21Feb12_232322| [ 1.38760  1.47011 -0.82651  0.27243]
21Feb12_232322| [-0.78439  0.61616  1.12318  0.46024]
21Feb12_232322| [ 1.01039 -1.11643 -0.10615  0.16438]
21Feb12_232322| [-0.60194  0.16256  0.69794  0.42338]
21Feb12_232322| [ 1.29789 -0.66201 -0.54308 -0.41395]
21Feb12_232322| [ 1.27111 -0.80429 -0.45608  0.43618]
21Feb12_232322| [-0.30043 -0.17224  0.73640  0.39627]
21Feb12_232322| [ 1.06895 -0.11087 -0.49826  0.03048]
21Feb12_232322| [-0.24413  0.52260  0.19550 -0.28699]
21Feb12_232322| [ 0.28284  0.77646 -0.25399 -0.07475]
21Feb12_232322| [-0.55158 -0.29051 -0.23798  0.46269]
21Feb12_232322| [-0.38260 -1.40522  0.63413 -0.29225]
21Feb12_232322| [ 0.03139  0.20183 -0.08841  0.37224]
21Feb12_232322| [-1.48545 -0.91705 -0.13515 -0.46855]
21Feb12_232322| [ 0.47649 -0.27177  0.82744  0.39112]
21Feb12_232322| [-1.87642 -0.32403 -0.23635  0.30883]
21Feb12_232322| [-1.23419 -0.11716  0.28717  0.04225]
21Feb12_232322| [-2.71438 -0.35530  0.90248 -0.14798]
21Feb12_232322| [ 1.26386 -0.32541 -0.00451  0.09379]
21Feb12_232322| [ 2.19550  0.91671 -0.98338 -0.43225]
21Feb12_232322| [ 0.48682 -0.34951  0.40278  0.32559]
21Feb12_232322| [ 0.87740 -0.34327  0.09753 -0.43035]]
21Feb12_232322|-- Bias --
21Feb12_232322|[-1.61088 -0.25085  0.53274  0.21367]
21Feb12_232322|Layer 1:
21Feb12_232322|-- Config --
21Feb12_232322|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232322|-- Weights --
21Feb12_232322|[[ 0.85045  0.02234]
21Feb12_232322| [ 0.15146  0.55865]
21Feb12_232322| [-0.04185  0.06756]
21Feb12_232322| [-0.47434  0.49266]]
21Feb12_232322|-- Bias --
21Feb12_232322|[-1.03310 -1.04658]
21Feb12_232322|Layer 2:
21Feb12_232322|-- Config --
21Feb12_232322|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232322|-- Weights --
21Feb12_232322|[[ 0.71153 -0.44529]
21Feb12_232322| [-0.44942 -0.32761]]
21Feb12_232322|-- Bias --
21Feb12_232322|[ 0.85309 -0.84290]
21Feb12_232322|Layer 3:
21Feb12_232322|-- Config --
21Feb12_232322|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232322|-- Weights --
21Feb12_232322|[[1.27656 0.06911]
21Feb12_232322| [0.53547 2.59670]]
21Feb12_232322|-- Bias --
21Feb12_232322|[-0.73581 -0.51354]
21Feb12_232322|Predicting the validation and test data with the Best final individual.
21Feb12_232329| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_232329|-----------  ------------------  --------------------  ----------
21Feb12_232329|Validation         25.91                  24            0.79194
21Feb12_232329|   Test            22.24                  24            0.66294
21Feb12_232329|-------------------- Test #14 --------------------
21Feb12_232329|Best final individual weights
21Feb12_232329|Individual:
21Feb12_232329|-- Constant hidden layers --
21Feb12_232329|False
21Feb12_232329|Layer 0:
21Feb12_232329|-- Config --
21Feb12_232329|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232329|-- Weights --
21Feb12_232329|[[-0.88430  0.38744  0.30429 -0.19493]
21Feb12_232329| [-0.07106  0.05862  1.34480 -0.46391]
21Feb12_232329| [ 0.06174 -1.01753  0.91730  0.44578]
21Feb12_232329| [ 0.65403 -0.46094 -0.43710  0.06277]
21Feb12_232329| [ 0.26691  0.05663  1.01849  0.33034]
21Feb12_232329| [ 0.62238 -1.16873 -1.03042  0.43068]
21Feb12_232329| [ 0.61110 -1.46840  0.44994 -0.28322]
21Feb12_232329| [-0.82124  1.02884 -0.40450  0.40306]
21Feb12_232329| [-0.56817  1.43936 -0.79233 -0.31949]
21Feb12_232329| [-0.11266  1.07052 -0.57275  0.01036]
21Feb12_232329| [ 0.32740 -1.66256 -1.22600  0.11828]
21Feb12_232329| [-0.70810 -2.31320 -1.10761 -0.40808]
21Feb12_232329| [ 0.93245  0.36786 -0.79838 -0.10952]
21Feb12_232329| [-1.07525 -0.60551 -0.66128  0.02992]
21Feb12_232329| [-0.94245 -0.40706 -0.82415  0.29567]
21Feb12_232329| [ 0.71756 -0.08265  0.79341  0.29860]
21Feb12_232329| [-1.59746  1.81339  1.55303 -0.37562]
21Feb12_232329| [-0.36642 -1.51142 -1.06142 -0.09675]
21Feb12_232329| [-1.24167 -0.48675  1.07870 -0.49966]
21Feb12_232329| [-0.37284 -1.07562  0.98240  0.46102]
21Feb12_232329| [-1.56216  0.77984 -0.56551  0.16250]
21Feb12_232329| [ 1.07349 -1.90915  0.46168 -0.11103]
21Feb12_232329| [-1.33189  0.95651 -0.22357  0.49323]
21Feb12_232329| [-1.12687 -0.77820  0.21195 -0.33038]
21Feb12_232329| [ 0.65272  0.18763 -0.05432  0.13593]
21Feb12_232329| [ 0.55334  0.94725  0.25358 -0.43635]
21Feb12_232329| [-1.07432  0.56233 -0.92488  0.49818]
21Feb12_232329| [ 0.54917  0.47714 -0.71581  0.28568]
21Feb12_232329| [ 0.74296  1.21411 -0.25897 -0.06134]
21Feb12_232329| [-2.26559 -1.44219 -0.35266  0.02409]
21Feb12_232329| [-1.56621 -1.96934  0.04624 -0.05266]
21Feb12_232329| [-0.32211  2.53154 -0.19339 -0.01619]
21Feb12_232329| [-1.62310  0.86832 -1.59048 -0.25297]
21Feb12_232329| [ 0.01383  1.33516 -0.97640  0.42359]
21Feb12_232329| [ 0.60856 -1.04358  0.50439 -0.42649]
21Feb12_232329| [ 1.38760  1.47011 -0.82651  0.27243]
21Feb12_232329| [-0.78439  0.61616  1.12318  0.46024]
21Feb12_232329| [ 1.01039 -1.11643 -0.10615  0.16438]
21Feb12_232329| [-0.60194  0.16256  0.69794  0.42338]
21Feb12_232329| [ 1.29789 -0.66201 -0.54308 -0.41395]
21Feb12_232329| [ 1.27111 -0.80429 -0.45608  0.43618]
21Feb12_232329| [-0.30043 -0.17224  0.73640  0.39627]
21Feb12_232329| [ 1.06895 -0.11087 -0.49826  0.03048]
21Feb12_232329| [-0.24413  0.52260  0.19550 -0.28699]
21Feb12_232329| [ 0.28284  0.77646 -0.25399 -0.07475]
21Feb12_232329| [-0.55158 -0.29051 -0.23798  0.46269]
21Feb12_232329| [-0.38260 -1.40522  0.63413 -0.29225]
21Feb12_232329| [ 0.03139  0.20183 -0.08841  0.37224]
21Feb12_232329| [-1.48545 -0.91705 -0.13515 -0.46855]
21Feb12_232329| [ 0.47649 -0.27177  0.82744  0.39112]
21Feb12_232329| [-1.87642 -0.32403 -0.23635  0.30883]
21Feb12_232329| [-1.23419 -0.11716  0.28717  0.04225]
21Feb12_232329| [-2.71438 -0.35530  0.90248 -0.14798]
21Feb12_232329| [ 1.26386 -0.32541 -0.00451  0.09379]
21Feb12_232329| [ 2.19550  0.91671 -0.98338 -0.43225]
21Feb12_232329| [ 0.48682 -0.34951  0.40278  0.32559]
21Feb12_232329| [ 0.87740 -0.34327  0.09753 -0.43035]]
21Feb12_232329|-- Bias --
21Feb12_232329|[-1.61088 -0.25085  0.53274  0.21367]
21Feb12_232329|Layer 1:
21Feb12_232329|-- Config --
21Feb12_232329|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232329|-- Weights --
21Feb12_232329|[[ 0.85045  0.02234]
21Feb12_232329| [ 0.15146  0.55865]
21Feb12_232329| [-0.04185  0.06756]
21Feb12_232329| [-0.47434  0.49266]]
21Feb12_232329|-- Bias --
21Feb12_232329|[-1.03310 -1.04658]
21Feb12_232329|Layer 2:
21Feb12_232329|-- Config --
21Feb12_232329|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232329|-- Weights --
21Feb12_232329|[[ 0.71153 -0.44529]
21Feb12_232329| [-0.44942 -0.32761]]
21Feb12_232329|-- Bias --
21Feb12_232329|[ 0.85309 -0.84290]
21Feb12_232329|Layer 3:
21Feb12_232329|-- Config --
21Feb12_232329|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb12_232329|-- Weights --
21Feb12_232329|[[1.27656 0.06911]
21Feb12_232329| [0.53547 2.59670]]
21Feb12_232329|-- Bias --
21Feb12_232329|[-0.73581 -0.51354]
21Feb12_232329|Predicting the validation and test data with the Best final individual.
21Feb12_232337| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb12_232337|-----------  ------------------  --------------------  ----------
21Feb12_232337|Validation         41.91                  24            0.00259
21Feb12_232337|   Test            32.32                  24            0.77363
2021-02-12 23:23:38.451242: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
21Feb12_232339|Data summary: Train
21Feb12_232339|data.shape = (2300, 57)
21Feb12_232339|labels.shape = (2300,)
21Feb12_232339|Class distribution:
21Feb12_232339|	0 - 1389 (0.60)
21Feb12_232339|	1 - 911 (0.40)
21Feb12_232339|Data summary: Validation
21Feb12_232339|data.shape = (1150, 57)
21Feb12_232339|labels.shape = (1150,)
21Feb12_232339|Class distribution:
21Feb12_232339|	0 - 667 (0.58)
21Feb12_232339|	1 - 483 (0.42)
21Feb12_232339|Data summary: Test
21Feb12_232339|data.shape = (1151, 57)
21Feb12_232339|labels.shape = (1151,)
21Feb12_232339|Class distribution:
21Feb12_232339|	0 - 732 (0.64)
21Feb12_232339|	1 - 419 (0.36)
21Feb12_232339|Selected configuration values
21Feb12_232339|-- Dataset name: spambase2
21Feb12_232339|-- Initial population size: 64
21Feb12_232339|-- Maximun number of generations: 32
21Feb12_232339|-- Neurons per hidden layer range: (2, 20)
21Feb12_232339|-- Hidden layers number range: (1, 3)
21Feb12_232339|-- Crossover probability: 0.5
21Feb12_232339|-- Bias gene mutation probability: 0.2
21Feb12_232339|-- Weights gene mutation probability: 0.75
21Feb12_232339|-- Neuron mutation probability: 0.3
21Feb12_232339|-- Layer mutation probability: 0.3
21Feb12_232339|-- Constant hidden layers: False
21Feb12_232339|-- Seed: 31415
21Feb12_232339|Entering GA
21Feb12_232339|Start the algorithm
2021-02-12 23:23:39.323899: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-12 23:23:39.324459: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-02-12 23:23:39.347024: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-12 23:23:39.347352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.71GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s
2021-02-12 23:23:39.347367: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-02-12 23:23:39.348845: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-02-12 23:23:39.348882: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-02-12 23:23:39.349385: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-02-12 23:23:39.349524: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-02-12 23:23:39.349595: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-12 23:23:39.350006: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-02-12 23:23:39.350054: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-12 23:23:39.350060: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-02-12 23:23:39.350252: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-02-12 23:23:39.351100: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-12 23:23:39.351117: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-12 23:23:39.351121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      
2021-02-12 23:23:39.405754: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-02-12 23:23:39.406098: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3493635000 Hz
/home/jmerelo/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype("int32")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn('`model.predict_classes()` is deprecated and '
21Feb12_232741|-- Generation 1 --
21Feb12_232741|    -- Crossed 2 individual pairs.
21Feb12_232741|    -- Mutated 32 individuals.
21Feb12_233139|    -- Evaluated 64 individuals.
21Feb12_233139|    Summary of generation 1:
21Feb12_233139| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_233139|-----------  ------------------  --------------------  ----------
21Feb12_233139|    Max            42.70                108.00          0.73424
21Feb12_233139|    Avg            41.79                34.23           0.01321
21Feb12_233139|    Min            27.91                 3.00           0.00000
21Feb12_233139|    Std             1.76                26.63           0.09089
21Feb12_233139|   Best            27.91                22.00           0.73424
21Feb12_233139|-- Generation 2 --
21Feb12_233139|    -- Crossed 2 individual pairs.
21Feb12_233139|    -- Mutated 32 individuals.
21Feb12_233531|    -- Evaluated 64 individuals.
21Feb12_233531|    Summary of generation 2:
21Feb12_233531| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_233531|-----------  ------------------  --------------------  ----------
21Feb12_233531|    Max            42.26                62.00           0.01805
21Feb12_233531|    Avg            41.99                20.70           0.00129
21Feb12_233531|    Min            41.39                 3.00           0.00000
21Feb12_233531|    Std             0.10                14.44           0.00277
21Feb12_233531|   Best            41.39                 8.00           0.01805
21Feb12_233531|-- Generation 3 --
21Feb12_233531|    -- Crossed 0 individual pairs.
21Feb12_233531|    -- Mutated 32 individuals.
21Feb12_233922|    -- Evaluated 64 individuals.
21Feb12_233922|    Summary of generation 3:
21Feb12_233922| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_233922|-----------  ------------------  --------------------  ----------
21Feb12_233922|    Max            42.17                57.00           0.66554
21Feb12_233922|    Avg            41.72                13.92           0.01201
21Feb12_233922|    Min            25.48                 3.00           0.00000
21Feb12_233922|    Std             2.05                11.34           0.08242
21Feb12_233922|   Best            25.48                36.00           0.66554
21Feb12_233922|-- Generation 4 --
21Feb12_233922|    -- Crossed 4 individual pairs.
21Feb12_233922|    -- Mutated 32 individuals.
21Feb12_234312|    -- Evaluated 64 individuals.
21Feb12_234312|    Summary of generation 4:
21Feb12_234312| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_234312|-----------  ------------------  --------------------  ----------
21Feb12_234312|    Max            42.17                57.00           0.02060
21Feb12_234312|    Avg            41.95                11.84           0.00238
21Feb12_234312|    Min            41.39                 3.00           0.00000
21Feb12_234312|    Std             0.14                13.62           0.00426
21Feb12_234312|   Best            41.39                 5.00           0.01805
21Feb12_234312|-- Generation 5 --
21Feb12_234312|    -- Crossed 3 individual pairs.
21Feb12_234312|    -- Mutated 32 individuals.
21Feb12_234702|    -- Evaluated 64 individuals.
21Feb12_234702|    Summary of generation 5:
21Feb12_234702| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_234702|-----------  ------------------  --------------------  ----------
21Feb12_234702|    Max            42.09                57.00           0.82115
21Feb12_234702|    Avg            41.76                12.91           0.01501
21Feb12_234702|    Min            29.74                 3.00           0.00000
21Feb12_234702|    Std             1.52                14.97           0.10162
21Feb12_234702|   Best            29.74                34.00           0.82115
21Feb12_234702|-- Generation 6 --
21Feb12_234702|    -- Crossed 4 individual pairs.
21Feb12_234702|    -- Mutated 32 individuals.
21Feb12_235054|    -- Evaluated 64 individuals.
21Feb12_235054|    Summary of generation 6:
21Feb12_235054| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_235054|-----------  ------------------  --------------------  ----------
21Feb12_235054|    Max            42.26                75.00           0.77107
21Feb12_235054|    Avg            41.69                18.14           0.01447
21Feb12_235054|    Min            25.30                 2.00           0.00000
21Feb12_235054|    Std             2.07                18.53           0.09538
21Feb12_235054|   Best            25.30                14.00           0.77107
21Feb12_235054|-- Generation 7 --
21Feb12_235054|    -- Crossed 3 individual pairs.
21Feb12_235054|    -- Mutated 32 individuals.
21Feb12_235448|    -- Evaluated 64 individuals.
21Feb12_235448|    Summary of generation 7:
21Feb12_235448| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_235448|-----------  ------------------  --------------------  ----------
21Feb12_235448|    Max            42.26                96.00           0.02318
21Feb12_235448|    Avg            41.92                23.08           0.00347
21Feb12_235448|    Min            41.22                 2.00           0.00000
21Feb12_235448|    Std             0.17                22.10           0.00449
21Feb12_235448|   Best            41.22                 8.00           0.02318
21Feb12_235448|-- Generation 8 --
21Feb12_235448|    -- Crossed 4 individual pairs.
21Feb12_235448|    -- Mutated 32 individuals.
21Feb12_235840|    -- Evaluated 64 individuals.
21Feb12_235840|    Summary of generation 8:
21Feb12_235840| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb12_235840|-----------  ------------------  --------------------  ----------
21Feb12_235840|    Max            42.87                57.00           0.81072
21Feb12_235840|    Avg            41.70                17.17           0.02568
21Feb12_235840|    Min            26.70                 4.00           0.00000
21Feb12_235840|    Std             1.90                14.97           0.12673
21Feb12_235840|   Best            26.70                14.00           0.64141
21Feb12_235840|-- Generation 9 --
21Feb12_235840|    -- Crossed 1 individual pairs.
21Feb12_235840|    -- Mutated 32 individuals.
21Feb13_000229|    -- Evaluated 64 individuals.
21Feb13_000229|    Summary of generation 9:
21Feb13_000229| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_000229|-----------  ------------------  --------------------  ----------
21Feb13_000229|    Max            42.35                36.00           0.02318
21Feb13_000229|    Avg            41.88                12.02           0.00484
21Feb13_000229|    Min            41.22                 3.00           0.00000
21Feb13_000229|    Std             0.20                 8.26           0.00575
21Feb13_000229|   Best            41.22                 9.00           0.02318
21Feb13_000229|-- Generation 10 --
21Feb13_000229|    -- Crossed 3 individual pairs.
21Feb13_000229|    -- Mutated 32 individuals.
21Feb13_000617|    -- Evaluated 64 individuals.
21Feb13_000617|    Summary of generation 10:
21Feb13_000617| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_000617|-----------  ------------------  --------------------  ----------
21Feb13_000617|    Max            42.35                34.00           0.01805
21Feb13_000617|    Avg            41.94                 9.84           0.00295
21Feb13_000617|    Min            41.39                 3.00           0.00000
21Feb13_000617|    Std             0.12                 6.73           0.00302
21Feb13_000617|   Best            41.39                 4.00           0.01805
21Feb13_000617|-- Generation 11 --
21Feb13_000617|    -- Crossed 4 individual pairs.
21Feb13_000617|    -- Mutated 32 individuals.
21Feb13_001006|    -- Evaluated 64 individuals.
21Feb13_001006|    Summary of generation 11:
21Feb13_001006| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_001006|-----------  ------------------  --------------------  ----------
21Feb13_001006|    Max            42.70                34.00           0.75472
21Feb13_001006|    Avg            41.72                 9.59           0.01454
21Feb13_001006|    Min            28.43                 3.00           0.00000
21Feb13_001006|    Std             1.68                 6.88           0.09329
21Feb13_001006|   Best            28.43                14.00           0.75472
21Feb13_001006|-- Generation 12 --
21Feb13_001006|    -- Crossed 6 individual pairs.
21Feb13_001006|    -- Mutated 32 individuals.
21Feb13_001354|    -- Evaluated 64 individuals.
21Feb13_001354|    Summary of generation 12:
21Feb13_001354| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_001354|-----------  ------------------  --------------------  ----------
21Feb13_001354|    Max            42.09                34.00           0.02062
21Feb13_001354|    Avg            41.91                 8.59           0.00319
21Feb13_001354|    Min            41.30                 3.00           0.00000
21Feb13_001354|    Std             0.12                 6.52           0.00355
21Feb13_001354|   Best            41.30                13.00           0.02062
21Feb13_001354|-- Generation 13 --
21Feb13_001354|    -- Crossed 6 individual pairs.
21Feb13_001354|    -- Mutated 32 individuals.
21Feb13_001740|    -- Evaluated 64 individuals.
21Feb13_001740|    Summary of generation 13:
21Feb13_001740| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_001740|-----------  ------------------  --------------------  ----------
21Feb13_001740|    Max            42.09                16.00           0.01805
21Feb13_001740|    Avg            41.90                 6.38           0.00363
21Feb13_001740|    Min            41.39                 3.00           0.00000
21Feb13_001740|    Std             0.12                 4.14           0.00349
21Feb13_001740|   Best            41.39                 8.00           0.01805
21Feb13_001740|-- Generation 14 --
21Feb13_001740|    -- Crossed 6 individual pairs.
21Feb13_001740|    -- Mutated 32 individuals.
21Feb13_002129|    -- Evaluated 64 individuals.
21Feb13_002129|    Summary of generation 14:
21Feb13_002129| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_002129|-----------  ------------------  --------------------  ----------
21Feb13_002129|    Max            42.96                36.00           0.74849
21Feb13_002129|    Avg            41.66                 8.41           0.01569
21Feb13_002129|    Min            25.39                 3.00           0.00000
21Feb13_002129|    Std             2.06                 6.54           0.09245
21Feb13_002129|   Best            25.39                16.00           0.74849
21Feb13_002129|-- Generation 15 --
21Feb13_002129|    -- Crossed 5 individual pairs.
21Feb13_002129|    -- Mutated 32 individuals.
21Feb13_002518|    -- Evaluated 64 individuals.
21Feb13_002518|    Summary of generation 15:
21Feb13_002518| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_002518|-----------  ------------------  --------------------  ----------
21Feb13_002518|    Max            42.26                34.00           0.24158
21Feb13_002518|    Avg            41.77                 8.27           0.00785
21Feb13_002518|    Min            34.96                 2.00           0.00000
21Feb13_002518|    Std             0.87                 6.18           0.02975
21Feb13_002518|   Best            34.96                34.00           0.24158
21Feb13_002518|-- Generation 16 --
21Feb13_002518|    -- Crossed 5 individual pairs.
21Feb13_002518|    -- Mutated 32 individuals.
21Feb13_002907|    -- Evaluated 64 individuals.
21Feb13_002907|    Summary of generation 16:
21Feb13_002907| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_002907|-----------  ------------------  --------------------  ----------
21Feb13_002907|    Max            42.09                40.00           0.57549
21Feb13_002907|    Avg            41.66                 9.66           0.01279
21Feb13_002907|    Min            26.96                 2.00           0.00000
21Feb13_002907|    Std             1.86                 8.72           0.07098
21Feb13_002907|   Best            26.96                20.00           0.57549
21Feb13_002907|-- Generation 17 --
21Feb13_002907|    -- Crossed 5 individual pairs.
21Feb13_002907|    -- Mutated 32 individuals.
21Feb13_003256|    -- Evaluated 64 individuals.
21Feb13_003256|    Summary of generation 17:
21Feb13_003256| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_003256|-----------  ------------------  --------------------  ----------
21Feb13_003256|    Max            42.52                32.00           0.02062
21Feb13_003256|    Avg            41.90                 8.12           0.00404
21Feb13_003256|    Min            41.30                 2.00           0.00000
21Feb13_003256|    Std             0.15                 6.22           0.00384
21Feb13_003256|   Best            41.30                 8.00           0.02062
21Feb13_003256|-- Generation 18 --
21Feb13_003256|    -- Crossed 6 individual pairs.
21Feb13_003256|    -- Mutated 32 individuals.
21Feb13_003644|    -- Evaluated 64 individuals.
21Feb13_003644|    Summary of generation 18:
21Feb13_003644| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_003644|-----------  ------------------  --------------------  ----------
21Feb13_003644|    Max            42.17                36.00           0.01805
21Feb13_003644|    Avg            41.89                 7.70           0.00444
21Feb13_003644|    Min            41.39                 2.00           0.00000
21Feb13_003644|    Std             0.14                 6.75           0.00409
21Feb13_003644|   Best            41.39                 8.00           0.01805
21Feb13_003644|-- Generation 19 --
21Feb13_003644|    -- Crossed 9 individual pairs.
21Feb13_003644|    -- Mutated 32 individuals.
21Feb13_004032|    -- Evaluated 64 individuals.
21Feb13_004032|    Summary of generation 19:
21Feb13_004032| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_004032|-----------  ------------------  --------------------  ----------
21Feb13_004032|    Max            42.26                24.00           0.00775
21Feb13_004032|    Avg            41.90                 6.67           0.00384
21Feb13_004032|    Min            41.74                 2.00           0.00000
21Feb13_004032|    Std             0.09                 4.67           0.00242
21Feb13_004032|   Best            41.74                 3.00           0.00775
21Feb13_004032|-- Generation 20 --
21Feb13_004032|    -- Crossed 2 individual pairs.
21Feb13_004032|    -- Mutated 32 individuals.
21Feb13_004419|    -- Evaluated 64 individuals.
21Feb13_004419|    Summary of generation 20:
21Feb13_004419| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_004419|-----------  ------------------  --------------------  ----------
21Feb13_004419|    Max            42.00                32.00           0.01548
21Feb13_004419|    Avg            41.87                 6.48           0.00432
21Feb13_004419|    Min            41.48                 2.00           0.00000
21Feb13_004419|    Std             0.09                 6.29           0.00285
21Feb13_004419|   Best            41.48                10.00           0.01548
21Feb13_004419|-- Generation 21 --
21Feb13_004419|    -- Crossed 5 individual pairs.
21Feb13_004419|    -- Mutated 32 individuals.
21Feb13_004807|    -- Evaluated 64 individuals.
21Feb13_004807|    Summary of generation 21:
21Feb13_004807| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_004807|-----------  ------------------  --------------------  ----------
21Feb13_004807|    Max            42.09                32.00           0.02317
21Feb13_004807|    Avg            41.85                 5.98           0.00484
21Feb13_004807|    Min            41.30                 2.00           0.00000
21Feb13_004807|    Std             0.11                 5.32           0.00343
21Feb13_004807|   Best            41.30                 9.00           0.02317
21Feb13_004807|-- Generation 22 --
21Feb13_004807|    -- Crossed 11 individual pairs.
21Feb13_004807|    -- Mutated 32 individuals.
21Feb13_005155|    -- Evaluated 64 individuals.
21Feb13_005155|    Summary of generation 22:
21Feb13_005155| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_005155|-----------  ------------------  --------------------  ----------
21Feb13_005155|    Max            42.17                22.00           0.01805
21Feb13_005155|    Avg            41.87                 6.27           0.00448
21Feb13_005155|    Min            41.39                 2.00           0.00000
21Feb13_005155|    Std             0.12                 5.15           0.00320
21Feb13_005155|   Best            41.39                10.00           0.01805
21Feb13_005155|-- Generation 23 --
21Feb13_005155|    -- Crossed 8 individual pairs.
21Feb13_005155|    -- Mutated 32 individuals.
21Feb13_005544|    -- Evaluated 64 individuals.
21Feb13_005544|    Summary of generation 23:
21Feb13_005544| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_005544|-----------  ------------------  --------------------  ----------
21Feb13_005544|    Max            42.17                26.00           0.52699
21Feb13_005544|    Avg            41.74                 6.39           0.01320
21Feb13_005544|    Min            34.17                 2.00           0.00000
21Feb13_005544|    Std             0.96                 5.67           0.06484
21Feb13_005544|   Best            34.17                14.00           0.52699
21Feb13_005544|-- Generation 24 --
21Feb13_005544|    -- Crossed 5 individual pairs.
21Feb13_005544|    -- Mutated 32 individuals.
21Feb13_005932|    -- Evaluated 64 individuals.
21Feb13_005932|    Summary of generation 24:
21Feb13_005932| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_005932|-----------  ------------------  --------------------  ----------
21Feb13_005932|    Max            42.26                26.00           0.80916
21Feb13_005932|    Avg            41.85                 6.72           0.03034
21Feb13_005932|    Min            41.22                 2.00           0.00000
21Feb13_005932|    Std             0.15                 5.93           0.13951
21Feb13_005932|   Best            41.22                 9.00           0.02318
21Feb13_005932|-- Generation 25 --
21Feb13_005932|    -- Crossed 5 individual pairs.
21Feb13_005932|    -- Mutated 32 individuals.
21Feb13_010320|    -- Evaluated 64 individuals.
21Feb13_010320|    Summary of generation 25:
21Feb13_010320| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_010320|-----------  ------------------  --------------------  ----------
21Feb13_010320|    Max            42.09                28.00           0.02318
21Feb13_010320|    Avg            41.82                 6.27           0.00617
21Feb13_010320|    Min            41.22                 2.00           0.00000
21Feb13_010320|    Std             0.15                 5.05           0.00500
21Feb13_010320|   Best            41.22                 8.00           0.02318
21Feb13_010320|-- Generation 26 --
21Feb13_010320|    -- Crossed 6 individual pairs.
21Feb13_010320|    -- Mutated 32 individuals.
21Feb13_010708|    -- Evaluated 64 individuals.
21Feb13_010708|    Summary of generation 26:
21Feb13_010708| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_010708|-----------  ------------------  --------------------  ----------
21Feb13_010708|    Max            42.26                26.00           0.02061
21Feb13_010708|    Avg            41.86                 7.08           0.00464
21Feb13_010708|    Min            41.39                 2.00           0.00000
21Feb13_010708|    Std             0.14                 5.83           0.00428
21Feb13_010708|   Best            41.39                 8.00           0.02061
21Feb13_010708|-- Generation 27 --
21Feb13_010708|    -- Crossed 4 individual pairs.
21Feb13_010708|    -- Mutated 32 individuals.
21Feb13_011057|    -- Evaluated 64 individuals.
21Feb13_011057|    Summary of generation 27:
21Feb13_011057| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_011057|-----------  ------------------  --------------------  ----------
21Feb13_011057|    Max            48.35                30.00           0.80027
21Feb13_011057|    Avg            41.88                 7.17           0.02241
21Feb13_011057|    Min            38.96                 2.00           0.00000
21Feb13_011057|    Std             0.90                 6.80           0.10402
21Feb13_011057|   Best            38.96                26.00           0.28491
21Feb13_011057|-- Generation 28 --
21Feb13_011057|    -- Crossed 6 individual pairs.
21Feb13_011057|    -- Mutated 32 individuals.
21Feb13_011445|    -- Evaluated 64 individuals.
21Feb13_011445|    Summary of generation 28:
21Feb13_011445| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_011445|-----------  ------------------  --------------------  ----------
21Feb13_011445|    Max            42.52                48.00           0.43066
21Feb13_011445|    Avg            41.83                 6.25           0.01214
21Feb13_011445|    Min            41.13                 2.00           0.00000
21Feb13_011445|    Std             0.18                 7.14           0.05288
21Feb13_011445|   Best            41.13                26.00           0.43066
21Feb13_011445|-- Generation 29 --
21Feb13_011445|    -- Crossed 7 individual pairs.
21Feb13_011445|    -- Mutated 32 individuals.
21Feb13_011833|    -- Evaluated 64 individuals.
21Feb13_011833|    Summary of generation 29:
21Feb13_011833| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_011833|-----------  ------------------  --------------------  ----------
21Feb13_011833|    Max            43.04                54.00           0.21617
21Feb13_011833|    Avg            41.85                 6.73           0.00863
21Feb13_011833|    Min            41.22                 2.00           0.00000
21Feb13_011833|    Std             0.20                 8.55           0.02644
21Feb13_011833|   Best            41.22                 3.00           0.02318
21Feb13_011833|-- Generation 30 --
21Feb13_011833|    -- Crossed 4 individual pairs.
21Feb13_011833|    -- Mutated 32 individuals.
21Feb13_012221|    -- Evaluated 64 individuals.
21Feb13_012221|    Summary of generation 30:
21Feb13_012221| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_012221|-----------  ------------------  --------------------  ----------
21Feb13_012221|    Max            42.09                30.00           0.01804
21Feb13_012221|    Avg            41.83                 5.20           0.00589
21Feb13_012221|    Min            41.48                 2.00           0.00000
21Feb13_012221|    Std             0.11                 5.69           0.00333
21Feb13_012221|   Best            41.48                 9.00           0.01804
21Feb13_012221|-- Generation 31 --
21Feb13_012221|    -- Crossed 6 individual pairs.
21Feb13_012221|    -- Mutated 32 individuals.
21Feb13_012609|    -- Evaluated 64 individuals.
21Feb13_012609|    Summary of generation 31:
21Feb13_012609| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_012609|-----------  ------------------  --------------------  ----------
21Feb13_012609|    Max            42.09                30.00           0.01805
21Feb13_012609|    Avg            41.85                 6.00           0.00468
21Feb13_012609|    Min            41.39                 2.00           0.00000
21Feb13_012609|    Std             0.13                 5.58           0.00381
21Feb13_012609|   Best            41.39                 9.00           0.01805
21Feb13_012609|-- Generation 32 --
21Feb13_012609|    -- Crossed 7 individual pairs.
21Feb13_012609|    -- Mutated 32 individuals.
21Feb13_012957|    -- Evaluated 64 individuals.
21Feb13_012957|    Summary of generation 32:
21Feb13_012957| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_012957|-----------  ------------------  --------------------  ----------
21Feb13_012957|    Max            42.00                28.00           0.01805
21Feb13_012957|    Avg            41.85                 4.48           0.00468
21Feb13_012957|    Min            41.39                 2.00           0.00000
21Feb13_012957|    Std             0.10                 4.59           0.00302
21Feb13_012957|   Best            41.39                 9.00           0.01805
21Feb13_012957|Best initial individual weights
21Feb13_012957|Individual:
21Feb13_012957|-- Constant hidden layers --
21Feb13_012957|False
21Feb13_012957|Layer 0:
21Feb13_012957|-- Config --
21Feb13_012957|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_012957|-- Weights --
21Feb13_012957|[[-0.20147 -0.10000  0.36916]
21Feb13_012957| [-0.98466 -0.97465 -0.42522]
21Feb13_012957| [ 0.02860 -0.87960 -0.08339]
21Feb13_012957| [ 0.54065  0.61634 -0.25743]
21Feb13_012957| [-0.67115 -0.90213  0.51125]
21Feb13_012957| [ 0.36672 -0.31849  0.78281]
21Feb13_012957| [-0.02977  0.40650 -0.39509]
21Feb13_012957| [ 0.13197  0.05056  0.43756]
21Feb13_012957| [ 0.24648 -0.03781  0.50723]
21Feb13_012957| [-0.78189  0.24337 -0.42283]
21Feb13_012957| [-0.75710  0.15705 -0.33207]
21Feb13_012957| [ 0.21836 -0.93446 -0.80759]
21Feb13_012957| [-0.89659 -0.10006 -0.20240]
21Feb13_012957| [ 0.17940  0.01905 -0.34669]
21Feb13_012957| [-0.08809 -0.89081 -0.34430]
21Feb13_012957| [ 0.78698 -0.63316  0.04749]
21Feb13_012957| [ 0.63161  0.38405 -0.84337]
21Feb13_012957| [-0.43487  0.47611 -0.15985]
21Feb13_012957| [-0.82812  0.90566 -0.34478]
21Feb13_012957| [-0.32337  0.30159  0.44135]
21Feb13_012957| [-0.48392 -0.99624 -0.80574]
21Feb13_012957| [-0.13933 -0.77432 -0.52091]
21Feb13_012957| [ 0.74558 -0.04882  0.75363]
21Feb13_012957| [-0.22524  0.78680  0.38545]
21Feb13_012957| [ 0.06639  0.90256  0.59544]
21Feb13_012957| [-0.25961  0.39173 -0.20881]
21Feb13_012957| [-0.86264  0.46922 -0.71829]
21Feb13_012957| [-0.45601 -0.18610 -0.58252]
21Feb13_012957| [ 0.47791 -0.36073  0.30983]
21Feb13_012957| [-0.79854 -0.59747 -0.50139]
21Feb13_012957| [ 0.98230 -0.15342  0.04506]
21Feb13_012957| [ 0.34751 -0.20263 -0.66275]
21Feb13_012957| [ 0.28409 -0.75795  0.17536]
21Feb13_012957| [-0.25719  0.67593 -0.32643]
21Feb13_012957| [ 0.79541 -0.21197  0.20002]
21Feb13_012957| [ 0.77924  0.51748  0.76229]
21Feb13_012957| [ 0.67889 -0.53028  0.99005]
21Feb13_012957| [-0.23285 -0.89452  0.29765]
21Feb13_012957| [ 0.20403 -0.25551  0.64244]
21Feb13_012957| [-0.72035 -0.28428 -0.81373]
21Feb13_012957| [-0.70936 -0.48694  0.83553]
21Feb13_012957| [ 0.50595  0.27522 -0.35960]
21Feb13_012957| [-0.14349 -0.17269 -0.58115]
21Feb13_012957| [ 0.27525 -0.60894  0.24367]
21Feb13_012957| [ 0.63260 -0.35043 -0.29433]
21Feb13_012957| [ 0.58467 -0.93911 -0.18214]
21Feb13_012957| [-0.68006 -0.14885 -0.15339]
21Feb13_012957| [-0.13424  0.38953  0.97675]
21Feb13_012957| [ 0.25016 -0.88760  0.17332]
21Feb13_012957| [ 0.99492  0.40810 -0.24760]
21Feb13_012957| [ 0.94283  0.15323 -0.11306]
21Feb13_012957| [-0.85658  0.97405  0.33098]
21Feb13_012957| [-0.08409 -0.11024 -0.25619]
21Feb13_012957| [ 0.49800 -0.13837  0.80873]
21Feb13_012957| [ 0.16878 -0.70408  0.63834]
21Feb13_012957| [ 0.58052 -0.98587  0.90110]
21Feb13_012957| [ 0.02173  0.73264  0.90788]]
21Feb13_012957|-- Bias --
21Feb13_012957|[0.64187 0.90341 0.24914]
21Feb13_012957|Layer 1:
21Feb13_012957|-- Config --
21Feb13_012957|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_012957|-- Weights --
21Feb13_012957|[[-0.57418  0.86563 -0.11996  0.71118 -0.41107 -0.91742]
21Feb13_012957| [-0.99969  0.23304 -0.90593  0.43362 -0.50845  0.95250]
21Feb13_012957| [ 0.97763  0.13846 -0.08530 -0.93497  0.08212  0.55395]]
21Feb13_012957|-- Bias --
21Feb13_012957|[ 0.65976  0.01239 -0.78454  0.72648 -0.07840  0.13113]
21Feb13_012957|Layer 2:
21Feb13_012957|-- Config --
21Feb13_012957|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 12, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_012957|-- Weights --
21Feb13_012957|[[ 0.17359 -0.62023 -0.58093  0.68233 -0.98519  0.52207 -0.05723  0.68314
21Feb13_012957|  -0.18134  0.08329  0.82794  0.17370]
21Feb13_012957| [-0.94520  0.13184 -0.88330  0.62061  0.84151 -0.43238  0.32085 -0.56612
21Feb13_012957|  -0.33852  0.22221  0.70764  0.24166]
21Feb13_012957| [ 0.85096 -0.18177  0.97990 -0.73866  0.71122 -0.02317  0.56691 -0.86830
21Feb13_012957|  -0.79065 -0.12907  0.23339 -0.04503]
21Feb13_012957| [ 0.75508 -0.87096 -0.51212  0.98152  0.12000  0.94519  0.30853 -0.02625
21Feb13_012957|   0.65462  0.56159 -0.17856  0.37439]
21Feb13_012957| [-0.04915 -0.57060  0.92704  0.62123 -0.03339 -0.31789 -0.29493  0.14151
21Feb13_012957|  -0.15907  0.41830 -0.93252  0.53936]
21Feb13_012957| [ 0.57080 -0.05835  0.36780 -0.31237  0.70189 -0.01198 -0.05906 -0.46018
21Feb13_012957|   0.16024  0.91169  0.99233 -0.33891]]
21Feb13_012957|-- Bias --
21Feb13_012957|[-0.44069 -0.81586 -0.64885 -0.86397  0.66034 -0.74043  0.66751 -0.06974
21Feb13_012957|  0.70710  0.50280  0.32419 -0.28059]
21Feb13_012957|Layer 3:
21Feb13_012957|-- Config --
21Feb13_012957|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 12], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_012957|-- Weights --
21Feb13_012957|[[-0.15834 -0.25206]
21Feb13_012957| [ 0.09453 -0.79022]
21Feb13_012957| [ 0.76024 -0.45239]
21Feb13_012957| [-0.95585 -0.26779]
21Feb13_012957| [-0.14879  0.04867]
21Feb13_012957| [ 0.48596  0.65506]
21Feb13_012957| [ 0.61715  0.34001]
21Feb13_012957| [-0.47268 -0.28024]
21Feb13_012957| [-0.11491  0.43343]
21Feb13_012957| [ 0.41451 -0.85454]
21Feb13_012957| [-0.87217 -0.05289]
21Feb13_012957| [ 0.49829  0.32235]]
21Feb13_012957|-- Bias --
21Feb13_012957|[0.96776 0.99897]
21Feb13_012957|Predicting the validation and test data with the Best initial individual.
21Feb13_013005| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_013005|-----------  ------------------  --------------------  ----------
21Feb13_013005|Validation         42.00                  63            0.00000
21Feb13_013005|   Test            36.40                  63            0.00000
21Feb13_013005|-------------------- Test #0 --------------------
21Feb13_013005|Best final individual weights
21Feb13_013005|Individual:
21Feb13_013005|-- Constant hidden layers --
21Feb13_013005|False
21Feb13_013005|Layer 0:
21Feb13_013005|-- Config --
21Feb13_013005|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 9, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_013005|-- Weights --
21Feb13_013005|[[-4.61006e-01  6.85931e-01 -1.53413e+00  3.18540e-01  1.65279e+00
21Feb13_013005|  -3.98052e-01  4.33508e-01 -6.92513e-01  3.42704e-01]
21Feb13_013005| [-1.09470e+00  9.32382e-01  7.25102e-01 -4.91678e-01  1.53894e+00
21Feb13_013005|   6.32892e-01  1.66659e+00 -1.21771e+00 -3.90783e-01]
21Feb13_013005| [ 9.03759e-01 -9.77900e-01  1.77765e+00 -2.07879e-01 -3.69959e-01
21Feb13_013005|   2.57340e-02  9.32038e-01  1.80456e+00  3.87273e-01]
21Feb13_013005| [-3.49696e-01 -3.58058e-03 -6.07396e-01 -1.37181e+00 -1.10504e+00
21Feb13_013005|  -1.11474e+00 -1.03332e+00  2.23341e-01 -4.72876e-01]
21Feb13_013005| [ 2.32707e-01 -1.07579e+00 -5.40875e-01  1.42954e+00  6.10975e-01
21Feb13_013005|   5.59004e-01 -5.83178e-01  1.52584e+00 -2.61616e-02]
21Feb13_013005| [ 2.60802e-01  1.01484e+00 -3.13035e-03  3.59113e-01 -5.42962e-02
21Feb13_013005|   1.30419e-01 -1.43042e+00  3.06781e-01  4.02528e-01]
21Feb13_013005| [ 3.31900e-01 -7.68883e-01  2.16435e+00  5.44727e-01 -7.94370e-01
21Feb13_013005|   4.13300e-01  8.17497e-01  8.49172e-01  3.89172e-01]
21Feb13_013005| [-1.74100e+00 -1.34439e+00 -1.72034e-01  5.54274e-01  4.11878e-03
21Feb13_013005|  -1.72138e+00  1.21996e+00 -2.14134e-01 -1.29167e-01]
21Feb13_013005| [ 1.02404e+00  6.15020e-02 -2.14163e-01  3.45452e-02  5.64308e-01
21Feb13_013005|   1.23836e-01 -7.85150e-01 -2.34675e-01 -6.19357e-01]
21Feb13_013005| [ 3.39580e-01 -9.02752e-01 -1.40731e+00  1.01083e+00 -1.27692e+00
21Feb13_013005|  -3.87978e-01  2.91565e-01  7.80658e-01 -4.54186e-01]
21Feb13_013005| [-6.53637e-01  3.40165e-01  6.43150e-01 -4.23568e-01 -2.78934e-01
21Feb13_013005|  -9.34614e-02 -6.67337e-01  4.52195e-01  1.32123e+00]
21Feb13_013005| [-1.27502e+00  1.02666e+00 -4.87675e-01  8.02112e-01  2.39068e-01
21Feb13_013005|  -4.86850e-01  1.73530e+00 -1.15809e-01 -3.03472e-02]
21Feb13_013005| [-5.53044e-01  4.66997e-01  8.50262e-01 -9.72246e-01  5.75977e-01
21Feb13_013005|  -8.30986e-01  6.72198e-01 -1.48566e+00 -4.40186e-01]
21Feb13_013005| [ 1.56239e+00  4.89175e-02  3.52725e-01 -5.84369e-01  3.78056e-01
21Feb13_013005|  -1.08095e+00  2.25579e-01  1.36469e+00  1.05927e-01]
21Feb13_013005| [ 5.87912e-01 -6.66494e-01  7.79087e-01 -1.37734e+00 -5.68017e-02
21Feb13_013005|  -5.28526e-01 -2.16139e-01 -1.39364e-01 -1.22582e-01]
21Feb13_013005| [-3.25557e-01  7.27112e-02 -9.80921e-01  1.85031e-02 -2.87431e-01
21Feb13_013005|   1.76187e+00  1.29272e+00 -2.15986e+00 -3.48111e-02]
21Feb13_013005| [ 2.43878e-01  5.55203e-02  1.46280e+00 -6.81342e-01  6.28102e-01
21Feb13_013005|   7.31779e-01 -1.31015e+00  8.71093e-01 -4.54700e-01]
21Feb13_013005| [ 4.93144e-01  7.54375e-02 -1.20005e+00  6.27631e-02  7.82145e-01
21Feb13_013005|   5.33649e-01 -1.13427e+00  8.26364e-01 -1.48796e-01]
21Feb13_013005| [-4.21426e-01 -1.29212e-01 -8.75548e-01 -7.62601e-01 -5.40266e-01
21Feb13_013005|   1.80516e+00 -1.24863e+00  1.35354e+00 -3.30202e-02]
21Feb13_013005| [ 3.22391e-01 -5.16648e-01  1.97275e+00  3.26675e-01 -1.58735e-01
21Feb13_013005|  -1.86724e-01  3.96522e-01  6.89546e-01 -9.39432e-01]
21Feb13_013005| [-4.67129e-01  2.15586e+00 -5.38287e-01  2.78568e-01  9.42587e-01
21Feb13_013005|  -2.77032e-01  1.25393e+00  3.81716e-01  8.82734e-01]
21Feb13_013005| [-1.41583e+00 -1.45012e-01 -7.99630e-01 -5.31952e-01 -1.19693e+00
21Feb13_013005|   7.92286e-01  1.30639e-01 -2.37138e-01 -1.58410e+00]
21Feb13_013005| [-1.16444e+00 -5.22290e-01  1.02540e+00  3.99299e-01 -9.33985e-01
21Feb13_013005|   2.16709e+00  3.01229e-01 -7.56401e-01  1.21738e+00]
21Feb13_013005| [-4.96242e-01  1.99264e+00  1.72242e+00 -7.33992e-01  1.79053e+00
21Feb13_013005|   7.69467e-01  4.32490e-01  8.00370e-02 -1.48974e-01]
21Feb13_013005| [ 9.93945e-02 -1.39770e+00  2.13769e-01  1.86767e+00  1.11288e+00
21Feb13_013005|   6.22801e-01  3.99123e-01  6.84795e-01  2.17178e-01]
21Feb13_013005| [ 1.35578e+00  8.00580e-01  3.99488e-01  4.40513e-01  1.93473e-02
21Feb13_013005|  -4.51602e-01  2.87170e-01  3.29084e-02 -1.36035e+00]
21Feb13_013005| [-1.09101e+00  2.48048e+00  5.80244e-01 -1.33268e-01 -5.28168e-01
21Feb13_013005|   8.09824e-01 -4.30853e-01 -2.55311e-02  1.50016e+00]
21Feb13_013005| [ 5.18298e-02 -2.30052e-01  1.28184e+00 -2.64124e+00  3.01962e-01
21Feb13_013005|   1.55697e+00 -1.20762e+00  6.34586e-01 -1.58188e-01]
21Feb13_013005| [-1.72551e+00  1.63754e+00 -4.70755e-01 -1.15326e+00 -8.33712e-01
21Feb13_013005|   1.31472e+00  2.01820e-01 -2.33652e-01  2.10201e-01]
21Feb13_013005| [ 1.47803e-01  1.06813e-01 -7.00830e-02 -1.17159e+00 -1.10268e+00
21Feb13_013005|  -8.43557e-01  4.82005e-01  1.25841e+00  4.90572e-02]
21Feb13_013005| [-4.14468e-01 -9.13217e-01  1.43297e+00 -2.20598e-01 -5.00413e-02
21Feb13_013005|   1.00790e+00 -1.44685e+00  1.08882e-02  4.97447e-02]
21Feb13_013005| [ 8.57554e-01  1.16591e+00 -1.34007e-01  1.71257e+00 -1.12961e+00
21Feb13_013005|   1.37418e+00 -1.22028e+00 -6.84918e-01  7.78660e-01]
21Feb13_013005| [-7.13839e-01  1.40966e+00 -4.77517e-01 -1.19630e+00 -1.15371e+00
21Feb13_013005|  -3.93636e-01  3.23964e-01 -6.64234e-01  1.21979e+00]
21Feb13_013005| [ 1.74382e+00  1.33485e+00  1.78034e-01  9.41668e-02  2.62732e-01
21Feb13_013005|   8.78408e-01  2.48648e-01  1.21791e+00  4.85344e-01]
21Feb13_013005| [-5.31246e-01 -1.52761e-01  2.84841e-01 -2.19881e-01 -5.37130e-01
21Feb13_013005|  -5.76407e-01  9.54226e-01  4.85366e-01 -9.77571e-01]
21Feb13_013005| [-1.35084e+00  1.09906e+00 -6.32061e-01  1.77342e-01 -6.40846e-01
21Feb13_013005|  -3.03854e-02  1.66807e+00  3.12194e-02 -3.53426e-01]
21Feb13_013005| [ 9.50869e-01 -3.62129e-01  2.98314e-01  4.91118e-01 -1.57990e+00
21Feb13_013005|  -2.44973e+00  8.00915e-01  7.10599e-04  8.10353e-01]
21Feb13_013005| [ 1.78432e+00 -9.71843e-01 -1.97505e+00 -1.18986e+00 -2.70454e-01
21Feb13_013005|  -1.30340e+00  7.99598e-01 -2.84399e-01  2.78754e-01]
21Feb13_013005| [-6.25690e-01 -1.36899e+00 -1.69985e-01 -6.67490e-01 -1.83927e+00
21Feb13_013005|   7.29422e-01 -1.91879e+00  9.93721e-01  1.24720e-01]
21Feb13_013005| [-6.63423e-02 -1.59385e+00  1.31061e+00 -5.23944e-01 -9.22575e-01
21Feb13_013005|   1.02268e-01  4.40389e-01  7.93366e-01  8.34624e-01]
21Feb13_013005| [-3.15115e-01 -8.73738e-01  2.06436e-01 -4.60182e-01  3.67394e-01
21Feb13_013005|   8.74019e-01 -1.00027e+00 -7.35157e-01 -6.67303e-01]
21Feb13_013005| [ 2.59118e-01  1.24828e+00 -4.10084e-01  3.25478e-01 -1.34056e+00
21Feb13_013005|  -2.04943e+00 -8.99572e-02  1.63028e+00  5.09953e-01]
21Feb13_013005| [ 1.17609e-02 -8.36465e-01 -8.15524e-02  3.43689e-01 -9.21088e-01
21Feb13_013005|  -1.89687e+00 -1.24788e+00  1.11545e+00  9.05282e-01]
21Feb13_013005| [-1.50660e+00  6.36055e-01 -3.71286e-02  4.62230e-01  8.44458e-01
21Feb13_013005|  -1.52079e+00 -7.16504e-01  7.07441e-02 -1.03582e+00]
21Feb13_013005| [-3.32525e-02 -5.49366e-01  7.30336e-01  1.55130e+00  1.87862e+00
21Feb13_013005|   5.59851e-01  1.58186e+00  4.62385e-01  7.76501e-01]
21Feb13_013005| [-2.09596e+00  1.33953e+00 -1.51561e+00 -1.25216e+00 -1.00343e+00
21Feb13_013005|  -5.75715e-01  8.79691e-01 -1.53243e+00 -3.80041e-01]
21Feb13_013005| [ 1.61185e-01  5.12300e-01  1.59935e+00  1.06339e+00  7.93391e-01
21Feb13_013005|   2.53927e+00 -1.61466e+00 -1.69022e+00 -2.02367e-01]
21Feb13_013005| [-1.25470e+00 -2.58098e-01  5.92567e-01  3.37381e-01 -6.99700e-01
21Feb13_013005|   9.24420e-01  9.48337e-01 -8.98604e-01  9.35058e-01]
21Feb13_013005| [ 1.43861e+00  1.42065e+00 -9.84910e-01 -8.21470e-01 -5.79001e-02
21Feb13_013005|   6.47525e-01  8.65842e-01 -1.50544e-01 -5.53358e-01]
21Feb13_013005| [-6.20387e-01 -2.38812e-02 -1.35219e-01 -2.58836e-01 -1.37737e+00
21Feb13_013005|   5.90991e-01 -2.13963e-01 -1.42807e+00 -1.91510e-01]
21Feb13_013005| [-9.48377e-01  1.45005e+00  6.23528e-01  9.24684e-01  8.68100e-01
21Feb13_013005|  -1.99460e+00  4.72527e-01  1.81921e+00 -1.50210e-01]
21Feb13_013005| [ 5.42301e-01  2.45411e-01  1.22571e+00 -1.22660e+00  2.00326e+00
21Feb13_013005|   1.28311e+00 -4.79063e-01 -1.26853e+00  3.54082e-01]
21Feb13_013005| [-9.68448e-02 -9.53055e-01 -6.39710e-01  7.39744e-02 -3.14837e-01
21Feb13_013005|  -4.64567e-01  8.27918e-01 -1.06114e+00 -5.10970e-01]
21Feb13_013005| [ 2.33279e-01  7.22497e-01  9.49373e-01 -1.20131e+00 -8.38683e-01
21Feb13_013005|  -5.38987e-01 -2.01753e+00  1.18580e+00 -7.12282e-01]
21Feb13_013005| [ 1.38078e+00 -3.07472e-01 -9.41548e-01  2.12287e+00  7.20946e-01
21Feb13_013005|   4.38905e-01  1.23216e+00  1.01939e+00  1.80698e-01]
21Feb13_013005| [-1.45026e-01  1.94626e+00 -1.81820e+00  1.49784e+00  7.71685e-01
21Feb13_013005|   1.57506e-01 -7.09054e-01 -3.76284e-02 -6.77940e-01]
21Feb13_013005| [-8.93030e-01  4.45952e-01 -5.02934e-01 -1.64437e+00  2.79315e-01
21Feb13_013005|  -1.03096e+00 -1.36068e+00 -4.50048e-01  2.88074e-01]]
21Feb13_013005|-- Bias --
21Feb13_013005|[ 0.37717  0.47788 -0.06014 -0.50820  0.52122 -0.91124 -1.67126 -0.64210
21Feb13_013005| -0.07185]
21Feb13_013005|Layer 1:
21Feb13_013005|-- Config --
21Feb13_013005|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 9], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_013005|-- Weights --
21Feb13_013005|[[ 0.68231 -0.74250]
21Feb13_013005| [ 0.62314  1.42898]
21Feb13_013005| [ 2.01695  1.97734]
21Feb13_013005| [-0.39663 -0.22189]
21Feb13_013005| [ 0.44922  0.41110]
21Feb13_013005| [ 0.33786  0.12545]
21Feb13_013005| [ 0.50773  1.87586]
21Feb13_013005| [-1.32230 -0.68529]
21Feb13_013005| [-0.06485  1.23686]]
21Feb13_013005|-- Bias --
21Feb13_013005|[-0.71772 -0.40861]
21Feb13_013005|Predicting the validation and test data with the Best final individual.
21Feb13_013012| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_013012|-----------  ------------------  --------------------  ----------
21Feb13_013012|Validation         41.74                  9             0.00775
21Feb13_013012|   Test            36.40                  9             0.00298
21Feb13_013012|-------------------- Test #1 --------------------
21Feb13_013012|Best final individual weights
21Feb13_013012|Individual:
21Feb13_013012|-- Constant hidden layers --
21Feb13_013012|False
21Feb13_013012|Layer 0:
21Feb13_013012|-- Config --
21Feb13_013012|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 9, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_013012|-- Weights --
21Feb13_013012|[[-4.61006e-01  6.85931e-01 -1.53413e+00  3.18540e-01  1.65279e+00
21Feb13_013012|  -3.98052e-01  4.33508e-01 -6.92513e-01  3.42704e-01]
21Feb13_013012| [-1.09470e+00  9.32382e-01  7.25102e-01 -4.91678e-01  1.53894e+00
21Feb13_013012|   6.32892e-01  1.66659e+00 -1.21771e+00 -3.90783e-01]
21Feb13_013012| [ 9.03759e-01 -9.77900e-01  1.77765e+00 -2.07879e-01 -3.69959e-01
21Feb13_013012|   2.57340e-02  9.32038e-01  1.80456e+00  3.87273e-01]
21Feb13_013012| [-3.49696e-01 -3.58058e-03 -6.07396e-01 -1.37181e+00 -1.10504e+00
21Feb13_013012|  -1.11474e+00 -1.03332e+00  2.23341e-01 -4.72876e-01]
21Feb13_013012| [ 2.32707e-01 -1.07579e+00 -5.40875e-01  1.42954e+00  6.10975e-01
21Feb13_013012|   5.59004e-01 -5.83178e-01  1.52584e+00 -2.61616e-02]
21Feb13_013012| [ 2.60802e-01  1.01484e+00 -3.13035e-03  3.59113e-01 -5.42962e-02
21Feb13_013012|   1.30419e-01 -1.43042e+00  3.06781e-01  4.02528e-01]
21Feb13_013012| [ 3.31900e-01 -7.68883e-01  2.16435e+00  5.44727e-01 -7.94370e-01
21Feb13_013012|   4.13300e-01  8.17497e-01  8.49172e-01  3.89172e-01]
21Feb13_013012| [-1.74100e+00 -1.34439e+00 -1.72034e-01  5.54274e-01  4.11878e-03
21Feb13_013012|  -1.72138e+00  1.21996e+00 -2.14134e-01 -1.29167e-01]
21Feb13_013012| [ 1.02404e+00  6.15020e-02 -2.14163e-01  3.45452e-02  5.64308e-01
21Feb13_013012|   1.23836e-01 -7.85150e-01 -2.34675e-01 -6.19357e-01]
21Feb13_013012| [ 3.39580e-01 -9.02752e-01 -1.40731e+00  1.01083e+00 -1.27692e+00
21Feb13_013012|  -3.87978e-01  2.91565e-01  7.80658e-01 -4.54186e-01]
21Feb13_013012| [-6.53637e-01  3.40165e-01  6.43150e-01 -4.23568e-01 -2.78934e-01
21Feb13_013012|  -9.34614e-02 -6.67337e-01  4.52195e-01  1.32123e+00]
21Feb13_013012| [-1.27502e+00  1.02666e+00 -4.87675e-01  8.02112e-01  2.39068e-01
21Feb13_013012|  -4.86850e-01  1.73530e+00 -1.15809e-01 -3.03472e-02]
21Feb13_013012| [-5.53044e-01  4.66997e-01  8.50262e-01 -9.72246e-01  5.75977e-01
21Feb13_013012|  -8.30986e-01  6.72198e-01 -1.48566e+00 -4.40186e-01]
21Feb13_013012| [ 1.56239e+00  4.89175e-02  3.52725e-01 -5.84369e-01  3.78056e-01
21Feb13_013012|  -1.08095e+00  2.25579e-01  1.36469e+00  1.05927e-01]
21Feb13_013012| [ 5.87912e-01 -6.66494e-01  7.79087e-01 -1.37734e+00 -5.68017e-02
21Feb13_013012|  -5.28526e-01 -2.16139e-01 -1.39364e-01 -1.22582e-01]
21Feb13_013012| [-3.25557e-01  7.27112e-02 -9.80921e-01  1.85031e-02 -2.87431e-01
21Feb13_013012|   1.76187e+00  1.29272e+00 -2.15986e+00 -3.48111e-02]
21Feb13_013012| [ 2.43878e-01  5.55203e-02  1.46280e+00 -6.81342e-01  6.28102e-01
21Feb13_013012|   7.31779e-01 -1.31015e+00  8.71093e-01 -4.54700e-01]
21Feb13_013012| [ 4.93144e-01  7.54375e-02 -1.20005e+00  6.27631e-02  7.82145e-01
21Feb13_013012|   5.33649e-01 -1.13427e+00  8.26364e-01 -1.48796e-01]
21Feb13_013012| [-4.21426e-01 -1.29212e-01 -8.75548e-01 -7.62601e-01 -5.40266e-01
21Feb13_013012|   1.80516e+00 -1.24863e+00  1.35354e+00 -3.30202e-02]
21Feb13_013012| [ 3.22391e-01 -5.16648e-01  1.97275e+00  3.26675e-01 -1.58735e-01
21Feb13_013012|  -1.86724e-01  3.96522e-01  6.89546e-01 -9.39432e-01]
21Feb13_013012| [-4.67129e-01  2.15586e+00 -5.38287e-01  2.78568e-01  9.42587e-01
21Feb13_013012|  -2.77032e-01  1.25393e+00  3.81716e-01  8.82734e-01]
21Feb13_013012| [-1.41583e+00 -1.45012e-01 -7.99630e-01 -5.31952e-01 -1.19693e+00
21Feb13_013012|   7.92286e-01  1.30639e-01 -2.37138e-01 -1.58410e+00]
21Feb13_013012| [-1.16444e+00 -5.22290e-01  1.02540e+00  3.99299e-01 -9.33985e-01
21Feb13_013012|   2.16709e+00  3.01229e-01 -7.56401e-01  1.21738e+00]
21Feb13_013012| [-4.96242e-01  1.99264e+00  1.72242e+00 -7.33992e-01  1.79053e+00
21Feb13_013012|   7.69467e-01  4.32490e-01  8.00370e-02 -1.48974e-01]
21Feb13_013012| [ 9.93945e-02 -1.39770e+00  2.13769e-01  1.86767e+00  1.11288e+00
21Feb13_013012|   6.22801e-01  3.99123e-01  6.84795e-01  2.17178e-01]
21Feb13_013012| [ 1.35578e+00  8.00580e-01  3.99488e-01  4.40513e-01  1.93473e-02
21Feb13_013012|  -4.51602e-01  2.87170e-01  3.29084e-02 -1.36035e+00]
21Feb13_013012| [-1.09101e+00  2.48048e+00  5.80244e-01 -1.33268e-01 -5.28168e-01
21Feb13_013012|   8.09824e-01 -4.30853e-01 -2.55311e-02  1.50016e+00]
21Feb13_013012| [ 5.18298e-02 -2.30052e-01  1.28184e+00 -2.64124e+00  3.01962e-01
21Feb13_013012|   1.55697e+00 -1.20762e+00  6.34586e-01 -1.58188e-01]
21Feb13_013012| [-1.72551e+00  1.63754e+00 -4.70755e-01 -1.15326e+00 -8.33712e-01
21Feb13_013012|   1.31472e+00  2.01820e-01 -2.33652e-01  2.10201e-01]
21Feb13_013012| [ 1.47803e-01  1.06813e-01 -7.00830e-02 -1.17159e+00 -1.10268e+00
21Feb13_013012|  -8.43557e-01  4.82005e-01  1.25841e+00  4.90572e-02]
21Feb13_013012| [-4.14468e-01 -9.13217e-01  1.43297e+00 -2.20598e-01 -5.00413e-02
21Feb13_013012|   1.00790e+00 -1.44685e+00  1.08882e-02  4.97447e-02]
21Feb13_013012| [ 8.57554e-01  1.16591e+00 -1.34007e-01  1.71257e+00 -1.12961e+00
21Feb13_013012|   1.37418e+00 -1.22028e+00 -6.84918e-01  7.78660e-01]
21Feb13_013012| [-7.13839e-01  1.40966e+00 -4.77517e-01 -1.19630e+00 -1.15371e+00
21Feb13_013012|  -3.93636e-01  3.23964e-01 -6.64234e-01  1.21979e+00]
21Feb13_013012| [ 1.74382e+00  1.33485e+00  1.78034e-01  9.41668e-02  2.62732e-01
21Feb13_013012|   8.78408e-01  2.48648e-01  1.21791e+00  4.85344e-01]
21Feb13_013012| [-5.31246e-01 -1.52761e-01  2.84841e-01 -2.19881e-01 -5.37130e-01
21Feb13_013012|  -5.76407e-01  9.54226e-01  4.85366e-01 -9.77571e-01]
21Feb13_013012| [-1.35084e+00  1.09906e+00 -6.32061e-01  1.77342e-01 -6.40846e-01
21Feb13_013012|  -3.03854e-02  1.66807e+00  3.12194e-02 -3.53426e-01]
21Feb13_013012| [ 9.50869e-01 -3.62129e-01  2.98314e-01  4.91118e-01 -1.57990e+00
21Feb13_013012|  -2.44973e+00  8.00915e-01  7.10599e-04  8.10353e-01]
21Feb13_013012| [ 1.78432e+00 -9.71843e-01 -1.97505e+00 -1.18986e+00 -2.70454e-01
21Feb13_013012|  -1.30340e+00  7.99598e-01 -2.84399e-01  2.78754e-01]
21Feb13_013012| [-6.25690e-01 -1.36899e+00 -1.69985e-01 -6.67490e-01 -1.83927e+00
21Feb13_013012|   7.29422e-01 -1.91879e+00  9.93721e-01  1.24720e-01]
21Feb13_013012| [-6.63423e-02 -1.59385e+00  1.31061e+00 -5.23944e-01 -9.22575e-01
21Feb13_013012|   1.02268e-01  4.40389e-01  7.93366e-01  8.34624e-01]
21Feb13_013012| [-3.15115e-01 -8.73738e-01  2.06436e-01 -4.60182e-01  3.67394e-01
21Feb13_013012|   8.74019e-01 -1.00027e+00 -7.35157e-01 -6.67303e-01]
21Feb13_013012| [ 2.59118e-01  1.24828e+00 -4.10084e-01  3.25478e-01 -1.34056e+00
21Feb13_013012|  -2.04943e+00 -8.99572e-02  1.63028e+00  5.09953e-01]
21Feb13_013012| [ 1.17609e-02 -8.36465e-01 -8.15524e-02  3.43689e-01 -9.21088e-01
21Feb13_013012|  -1.89687e+00 -1.24788e+00  1.11545e+00  9.05282e-01]
21Feb13_013012| [-1.50660e+00  6.36055e-01 -3.71286e-02  4.62230e-01  8.44458e-01
21Feb13_013012|  -1.52079e+00 -7.16504e-01  7.07441e-02 -1.03582e+00]
21Feb13_013012| [-3.32525e-02 -5.49366e-01  7.30336e-01  1.55130e+00  1.87862e+00
21Feb13_013012|   5.59851e-01  1.58186e+00  4.62385e-01  7.76501e-01]
21Feb13_013012| [-2.09596e+00  1.33953e+00 -1.51561e+00 -1.25216e+00 -1.00343e+00
21Feb13_013012|  -5.75715e-01  8.79691e-01 -1.53243e+00 -3.80041e-01]
21Feb13_013012| [ 1.61185e-01  5.12300e-01  1.59935e+00  1.06339e+00  7.93391e-01
21Feb13_013012|   2.53927e+00 -1.61466e+00 -1.69022e+00 -2.02367e-01]
21Feb13_013012| [-1.25470e+00 -2.58098e-01  5.92567e-01  3.37381e-01 -6.99700e-01
21Feb13_013012|   9.24420e-01  9.48337e-01 -8.98604e-01  9.35058e-01]
21Feb13_013012| [ 1.43861e+00  1.42065e+00 -9.84910e-01 -8.21470e-01 -5.79001e-02
21Feb13_013012|   6.47525e-01  8.65842e-01 -1.50544e-01 -5.53358e-01]
21Feb13_013012| [-6.20387e-01 -2.38812e-02 -1.35219e-01 -2.58836e-01 -1.37737e+00
21Feb13_013012|   5.90991e-01 -2.13963e-01 -1.42807e+00 -1.91510e-01]
21Feb13_013012| [-9.48377e-01  1.45005e+00  6.23528e-01  9.24684e-01  8.68100e-01
21Feb13_013012|  -1.99460e+00  4.72527e-01  1.81921e+00 -1.50210e-01]
21Feb13_013012| [ 5.42301e-01  2.45411e-01  1.22571e+00 -1.22660e+00  2.00326e+00
21Feb13_013012|   1.28311e+00 -4.79063e-01 -1.26853e+00  3.54082e-01]
21Feb13_013012| [-9.68448e-02 -9.53055e-01 -6.39710e-01  7.39744e-02 -3.14837e-01
21Feb13_013012|  -4.64567e-01  8.27918e-01 -1.06114e+00 -5.10970e-01]
21Feb13_013012| [ 2.33279e-01  7.22497e-01  9.49373e-01 -1.20131e+00 -8.38683e-01
21Feb13_013012|  -5.38987e-01 -2.01753e+00  1.18580e+00 -7.12282e-01]
21Feb13_013012| [ 1.38078e+00 -3.07472e-01 -9.41548e-01  2.12287e+00  7.20946e-01
21Feb13_013012|   4.38905e-01  1.23216e+00  1.01939e+00  1.80698e-01]
21Feb13_013012| [-1.45026e-01  1.94626e+00 -1.81820e+00  1.49784e+00  7.71685e-01
21Feb13_013012|   1.57506e-01 -7.09054e-01 -3.76284e-02 -6.77940e-01]
21Feb13_013012| [-8.93030e-01  4.45952e-01 -5.02934e-01 -1.64437e+00  2.79315e-01
21Feb13_013012|  -1.03096e+00 -1.36068e+00 -4.50048e-01  2.88074e-01]]
21Feb13_013012|-- Bias --
21Feb13_013012|[ 0.37717  0.47788 -0.06014 -0.50820  0.52122 -0.91124 -1.67126 -0.64210
21Feb13_013012| -0.07185]
21Feb13_013012|Layer 1:
21Feb13_013012|-- Config --
21Feb13_013012|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 9], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_013012|-- Weights --
21Feb13_013012|[[ 0.68231 -0.74250]
21Feb13_013012| [ 0.62314  1.42898]
21Feb13_013012| [ 2.01695  1.97734]
21Feb13_013012| [-0.39663 -0.22189]
21Feb13_013012| [ 0.44922  0.41110]
21Feb13_013012| [ 0.33786  0.12545]
21Feb13_013012| [ 0.50773  1.87586]
21Feb13_013012| [-1.32230 -0.68529]
21Feb13_013012| [-0.06485  1.23686]]
21Feb13_013012|-- Bias --
21Feb13_013012|[-0.71772 -0.40861]
21Feb13_013012|Predicting the validation and test data with the Best final individual.
21Feb13_013019| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_013019|-----------  ------------------  --------------------  ----------
21Feb13_013019|Validation         41.65                  9             0.01033
21Feb13_013019|   Test            36.32                  9             0.00596
21Feb13_013019|-------------------- Test #2 --------------------
21Feb13_013019|Best final individual weights
21Feb13_013019|Individual:
21Feb13_013019|-- Constant hidden layers --
21Feb13_013019|False
21Feb13_013019|Layer 0:
21Feb13_013019|-- Config --
21Feb13_013019|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 9, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_013019|-- Weights --
21Feb13_013019|[[-4.61006e-01  6.85931e-01 -1.53413e+00  3.18540e-01  1.65279e+00
21Feb13_013019|  -3.98052e-01  4.33508e-01 -6.92513e-01  3.42704e-01]
21Feb13_013019| [-1.09470e+00  9.32382e-01  7.25102e-01 -4.91678e-01  1.53894e+00
21Feb13_013019|   6.32892e-01  1.66659e+00 -1.21771e+00 -3.90783e-01]
21Feb13_013019| [ 9.03759e-01 -9.77900e-01  1.77765e+00 -2.07879e-01 -3.69959e-01
21Feb13_013019|   2.57340e-02  9.32038e-01  1.80456e+00  3.87273e-01]
21Feb13_013019| [-3.49696e-01 -3.58058e-03 -6.07396e-01 -1.37181e+00 -1.10504e+00
21Feb13_013019|  -1.11474e+00 -1.03332e+00  2.23341e-01 -4.72876e-01]
21Feb13_013019| [ 2.32707e-01 -1.07579e+00 -5.40875e-01  1.42954e+00  6.10975e-01
21Feb13_013019|   5.59004e-01 -5.83178e-01  1.52584e+00 -2.61616e-02]
21Feb13_013019| [ 2.60802e-01  1.01484e+00 -3.13035e-03  3.59113e-01 -5.42962e-02
21Feb13_013019|   1.30419e-01 -1.43042e+00  3.06781e-01  4.02528e-01]
21Feb13_013019| [ 3.31900e-01 -7.68883e-01  2.16435e+00  5.44727e-01 -7.94370e-01
21Feb13_013019|   4.13300e-01  8.17497e-01  8.49172e-01  3.89172e-01]
21Feb13_013019| [-1.74100e+00 -1.34439e+00 -1.72034e-01  5.54274e-01  4.11878e-03
21Feb13_013019|  -1.72138e+00  1.21996e+00 -2.14134e-01 -1.29167e-01]
21Feb13_013019| [ 1.02404e+00  6.15020e-02 -2.14163e-01  3.45452e-02  5.64308e-01
21Feb13_013019|   1.23836e-01 -7.85150e-01 -2.34675e-01 -6.19357e-01]
21Feb13_013019| [ 3.39580e-01 -9.02752e-01 -1.40731e+00  1.01083e+00 -1.27692e+00
21Feb13_013019|  -3.87978e-01  2.91565e-01  7.80658e-01 -4.54186e-01]
21Feb13_013019| [-6.53637e-01  3.40165e-01  6.43150e-01 -4.23568e-01 -2.78934e-01
21Feb13_013019|  -9.34614e-02 -6.67337e-01  4.52195e-01  1.32123e+00]
21Feb13_013019| [-1.27502e+00  1.02666e+00 -4.87675e-01  8.02112e-01  2.39068e-01
21Feb13_013019|  -4.86850e-01  1.73530e+00 -1.15809e-01 -3.03472e-02]
21Feb13_013019| [-5.53044e-01  4.66997e-01  8.50262e-01 -9.72246e-01  5.75977e-01
21Feb13_013019|  -8.30986e-01  6.72198e-01 -1.48566e+00 -4.40186e-01]
21Feb13_013019| [ 1.56239e+00  4.89175e-02  3.52725e-01 -5.84369e-01  3.78056e-01
21Feb13_013019|  -1.08095e+00  2.25579e-01  1.36469e+00  1.05927e-01]
21Feb13_013019| [ 5.87912e-01 -6.66494e-01  7.79087e-01 -1.37734e+00 -5.68017e-02
21Feb13_013019|  -5.28526e-01 -2.16139e-01 -1.39364e-01 -1.22582e-01]
21Feb13_013019| [-3.25557e-01  7.27112e-02 -9.80921e-01  1.85031e-02 -2.87431e-01
21Feb13_013019|   1.76187e+00  1.29272e+00 -2.15986e+00 -3.48111e-02]
21Feb13_013019| [ 2.43878e-01  5.55203e-02  1.46280e+00 -6.81342e-01  6.28102e-01
21Feb13_013019|   7.31779e-01 -1.31015e+00  8.71093e-01 -4.54700e-01]
21Feb13_013019| [ 4.93144e-01  7.54375e-02 -1.20005e+00  6.27631e-02  7.82145e-01
21Feb13_013019|   5.33649e-01 -1.13427e+00  8.26364e-01 -1.48796e-01]
21Feb13_013019| [-4.21426e-01 -1.29212e-01 -8.75548e-01 -7.62601e-01 -5.40266e-01
21Feb13_013019|   1.80516e+00 -1.24863e+00  1.35354e+00 -3.30202e-02]
21Feb13_013019| [ 3.22391e-01 -5.16648e-01  1.97275e+00  3.26675e-01 -1.58735e-01
21Feb13_013019|  -1.86724e-01  3.96522e-01  6.89546e-01 -9.39432e-01]
21Feb13_013019| [-4.67129e-01  2.15586e+00 -5.38287e-01  2.78568e-01  9.42587e-01
21Feb13_013019|  -2.77032e-01  1.25393e+00  3.81716e-01  8.82734e-01]
21Feb13_013019| [-1.41583e+00 -1.45012e-01 -7.99630e-01 -5.31952e-01 -1.19693e+00
21Feb13_013019|   7.92286e-01  1.30639e-01 -2.37138e-01 -1.58410e+00]
21Feb13_013019| [-1.16444e+00 -5.22290e-01  1.02540e+00  3.99299e-01 -9.33985e-01
21Feb13_013019|   2.16709e+00  3.01229e-01 -7.56401e-01  1.21738e+00]
21Feb13_013019| [-4.96242e-01  1.99264e+00  1.72242e+00 -7.33992e-01  1.79053e+00
21Feb13_013019|   7.69467e-01  4.32490e-01  8.00370e-02 -1.48974e-01]
21Feb13_013019| [ 9.93945e-02 -1.39770e+00  2.13769e-01  1.86767e+00  1.11288e+00
21Feb13_013019|   6.22801e-01  3.99123e-01  6.84795e-01  2.17178e-01]
21Feb13_013019| [ 1.35578e+00  8.00580e-01  3.99488e-01  4.40513e-01  1.93473e-02
21Feb13_013019|  -4.51602e-01  2.87170e-01  3.29084e-02 -1.36035e+00]
21Feb13_013019| [-1.09101e+00  2.48048e+00  5.80244e-01 -1.33268e-01 -5.28168e-01
21Feb13_013019|   8.09824e-01 -4.30853e-01 -2.55311e-02  1.50016e+00]
21Feb13_013019| [ 5.18298e-02 -2.30052e-01  1.28184e+00 -2.64124e+00  3.01962e-01
21Feb13_013019|   1.55697e+00 -1.20762e+00  6.34586e-01 -1.58188e-01]
21Feb13_013019| [-1.72551e+00  1.63754e+00 -4.70755e-01 -1.15326e+00 -8.33712e-01
21Feb13_013019|   1.31472e+00  2.01820e-01 -2.33652e-01  2.10201e-01]
21Feb13_013019| [ 1.47803e-01  1.06813e-01 -7.00830e-02 -1.17159e+00 -1.10268e+00
21Feb13_013019|  -8.43557e-01  4.82005e-01  1.25841e+00  4.90572e-02]
21Feb13_013019| [-4.14468e-01 -9.13217e-01  1.43297e+00 -2.20598e-01 -5.00413e-02
21Feb13_013019|   1.00790e+00 -1.44685e+00  1.08882e-02  4.97447e-02]
21Feb13_013019| [ 8.57554e-01  1.16591e+00 -1.34007e-01  1.71257e+00 -1.12961e+00
21Feb13_013019|   1.37418e+00 -1.22028e+00 -6.84918e-01  7.78660e-01]
21Feb13_013019| [-7.13839e-01  1.40966e+00 -4.77517e-01 -1.19630e+00 -1.15371e+00
21Feb13_013019|  -3.93636e-01  3.23964e-01 -6.64234e-01  1.21979e+00]
21Feb13_013019| [ 1.74382e+00  1.33485e+00  1.78034e-01  9.41668e-02  2.62732e-01
21Feb13_013019|   8.78408e-01  2.48648e-01  1.21791e+00  4.85344e-01]
21Feb13_013019| [-5.31246e-01 -1.52761e-01  2.84841e-01 -2.19881e-01 -5.37130e-01
21Feb13_013019|  -5.76407e-01  9.54226e-01  4.85366e-01 -9.77571e-01]
21Feb13_013019| [-1.35084e+00  1.09906e+00 -6.32061e-01  1.77342e-01 -6.40846e-01
21Feb13_013019|  -3.03854e-02  1.66807e+00  3.12194e-02 -3.53426e-01]
21Feb13_013019| [ 9.50869e-01 -3.62129e-01  2.98314e-01  4.91118e-01 -1.57990e+00
21Feb13_013019|  -2.44973e+00  8.00915e-01  7.10599e-04  8.10353e-01]
21Feb13_013019| [ 1.78432e+00 -9.71843e-01 -1.97505e+00 -1.18986e+00 -2.70454e-01
21Feb13_013019|  -1.30340e+00  7.99598e-01 -2.84399e-01  2.78754e-01]
21Feb13_013019| [-6.25690e-01 -1.36899e+00 -1.69985e-01 -6.67490e-01 -1.83927e+00
21Feb13_013019|   7.29422e-01 -1.91879e+00  9.93721e-01  1.24720e-01]
21Feb13_013019| [-6.63423e-02 -1.59385e+00  1.31061e+00 -5.23944e-01 -9.22575e-01
21Feb13_013019|   1.02268e-01  4.40389e-01  7.93366e-01  8.34624e-01]
21Feb13_013019| [-3.15115e-01 -8.73738e-01  2.06436e-01 -4.60182e-01  3.67394e-01
21Feb13_013019|   8.74019e-01 -1.00027e+00 -7.35157e-01 -6.67303e-01]
21Feb13_013019| [ 2.59118e-01  1.24828e+00 -4.10084e-01  3.25478e-01 -1.34056e+00
21Feb13_013019|  -2.04943e+00 -8.99572e-02  1.63028e+00  5.09953e-01]
21Feb13_013019| [ 1.17609e-02 -8.36465e-01 -8.15524e-02  3.43689e-01 -9.21088e-01
21Feb13_013019|  -1.89687e+00 -1.24788e+00  1.11545e+00  9.05282e-01]
21Feb13_013019| [-1.50660e+00  6.36055e-01 -3.71286e-02  4.62230e-01  8.44458e-01
21Feb13_013019|  -1.52079e+00 -7.16504e-01  7.07441e-02 -1.03582e+00]
21Feb13_013019| [-3.32525e-02 -5.49366e-01  7.30336e-01  1.55130e+00  1.87862e+00
21Feb13_013019|   5.59851e-01  1.58186e+00  4.62385e-01  7.76501e-01]
21Feb13_013019| [-2.09596e+00  1.33953e+00 -1.51561e+00 -1.25216e+00 -1.00343e+00
21Feb13_013019|  -5.75715e-01  8.79691e-01 -1.53243e+00 -3.80041e-01]
21Feb13_013019| [ 1.61185e-01  5.12300e-01  1.59935e+00  1.06339e+00  7.93391e-01
21Feb13_013019|   2.53927e+00 -1.61466e+00 -1.69022e+00 -2.02367e-01]
21Feb13_013019| [-1.25470e+00 -2.58098e-01  5.92567e-01  3.37381e-01 -6.99700e-01
21Feb13_013019|   9.24420e-01  9.48337e-01 -8.98604e-01  9.35058e-01]
21Feb13_013019| [ 1.43861e+00  1.42065e+00 -9.84910e-01 -8.21470e-01 -5.79001e-02
21Feb13_013019|   6.47525e-01  8.65842e-01 -1.50544e-01 -5.53358e-01]
21Feb13_013019| [-6.20387e-01 -2.38812e-02 -1.35219e-01 -2.58836e-01 -1.37737e+00
21Feb13_013019|   5.90991e-01 -2.13963e-01 -1.42807e+00 -1.91510e-01]
21Feb13_013019| [-9.48377e-01  1.45005e+00  6.23528e-01  9.24684e-01  8.68100e-01
21Feb13_013019|  -1.99460e+00  4.72527e-01  1.81921e+00 -1.50210e-01]
21Feb13_013019| [ 5.42301e-01  2.45411e-01  1.22571e+00 -1.22660e+00  2.00326e+00
21Feb13_013019|   1.28311e+00 -4.79063e-01 -1.26853e+00  3.54082e-01]
21Feb13_013019| [-9.68448e-02 -9.53055e-01 -6.39710e-01  7.39744e-02 -3.14837e-01
21Feb13_013019|  -4.64567e-01  8.27918e-01 -1.06114e+00 -5.10970e-01]
21Feb13_013019| [ 2.33279e-01  7.22497e-01  9.49373e-01 -1.20131e+00 -8.38683e-01
21Feb13_013019|  -5.38987e-01 -2.01753e+00  1.18580e+00 -7.12282e-01]
21Feb13_013019| [ 1.38078e+00 -3.07472e-01 -9.41548e-01  2.12287e+00  7.20946e-01
21Feb13_013019|   4.38905e-01  1.23216e+00  1.01939e+00  1.80698e-01]
21Feb13_013019| [-1.45026e-01  1.94626e+00 -1.81820e+00  1.49784e+00  7.71685e-01
21Feb13_013019|   1.57506e-01 -7.09054e-01 -3.76284e-02 -6.77940e-01]
21Feb13_013019| [-8.93030e-01  4.45952e-01 -5.02934e-01 -1.64437e+00  2.79315e-01
21Feb13_013019|  -1.03096e+00 -1.36068e+00 -4.50048e-01  2.88074e-01]]
21Feb13_013019|-- Bias --
21Feb13_013019|[ 0.37717  0.47788 -0.06014 -0.50820  0.52122 -0.91124 -1.67126 -0.64210
21Feb13_013019| -0.07185]
21Feb13_013019|Layer 1:
21Feb13_013019|-- Config --
21Feb13_013019|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 9], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_013019|-- Weights --
21Feb13_013019|[[ 0.68231 -0.74250]
21Feb13_013019| [ 0.62314  1.42898]
21Feb13_013019| [ 2.01695  1.97734]
21Feb13_013019| [-0.39663 -0.22189]
21Feb13_013019| [ 0.44922  0.41110]
21Feb13_013019| [ 0.33786  0.12545]
21Feb13_013019| [ 0.50773  1.87586]
21Feb13_013019| [-1.32230 -0.68529]
21Feb13_013019| [-0.06485  1.23686]]
21Feb13_013019|-- Bias --
21Feb13_013019|[-0.71772 -0.40861]
21Feb13_013019|Predicting the validation and test data with the Best final individual.
21Feb13_013026| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_013026|-----------  ------------------  --------------------  ----------
21Feb13_013026|Validation         41.74                  9             0.01033
21Feb13_013026|   Test            36.49                  9             0.00595
21Feb13_013026|-------------------- Test #3 --------------------
21Feb13_013026|Best final individual weights
21Feb13_013026|Individual:
21Feb13_013026|-- Constant hidden layers --
21Feb13_013026|False
21Feb13_013026|Layer 0:
21Feb13_013026|-- Config --
21Feb13_013026|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 9, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_013026|-- Weights --
21Feb13_013026|[[-4.61006e-01  6.85931e-01 -1.53413e+00  3.18540e-01  1.65279e+00
21Feb13_013026|  -3.98052e-01  4.33508e-01 -6.92513e-01  3.42704e-01]
21Feb13_013026| [-1.09470e+00  9.32382e-01  7.25102e-01 -4.91678e-01  1.53894e+00
21Feb13_013026|   6.32892e-01  1.66659e+00 -1.21771e+00 -3.90783e-01]
21Feb13_013026| [ 9.03759e-01 -9.77900e-01  1.77765e+00 -2.07879e-01 -3.69959e-01
21Feb13_013026|   2.57340e-02  9.32038e-01  1.80456e+00  3.87273e-01]
21Feb13_013026| [-3.49696e-01 -3.58058e-03 -6.07396e-01 -1.37181e+00 -1.10504e+00
21Feb13_013026|  -1.11474e+00 -1.03332e+00  2.23341e-01 -4.72876e-01]
21Feb13_013026| [ 2.32707e-01 -1.07579e+00 -5.40875e-01  1.42954e+00  6.10975e-01
21Feb13_013026|   5.59004e-01 -5.83178e-01  1.52584e+00 -2.61616e-02]
21Feb13_013026| [ 2.60802e-01  1.01484e+00 -3.13035e-03  3.59113e-01 -5.42962e-02
21Feb13_013026|   1.30419e-01 -1.43042e+00  3.06781e-01  4.02528e-01]
21Feb13_013026| [ 3.31900e-01 -7.68883e-01  2.16435e+00  5.44727e-01 -7.94370e-01
21Feb13_013026|   4.13300e-01  8.17497e-01  8.49172e-01  3.89172e-01]
21Feb13_013026| [-1.74100e+00 -1.34439e+00 -1.72034e-01  5.54274e-01  4.11878e-03
21Feb13_013026|  -1.72138e+00  1.21996e+00 -2.14134e-01 -1.29167e-01]
21Feb13_013026| [ 1.02404e+00  6.15020e-02 -2.14163e-01  3.45452e-02  5.64308e-01
21Feb13_013026|   1.23836e-01 -7.85150e-01 -2.34675e-01 -6.19357e-01]
21Feb13_013026| [ 3.39580e-01 -9.02752e-01 -1.40731e+00  1.01083e+00 -1.27692e+00
21Feb13_013026|  -3.87978e-01  2.91565e-01  7.80658e-01 -4.54186e-01]
21Feb13_013026| [-6.53637e-01  3.40165e-01  6.43150e-01 -4.23568e-01 -2.78934e-01
21Feb13_013026|  -9.34614e-02 -6.67337e-01  4.52195e-01  1.32123e+00]
21Feb13_013026| [-1.27502e+00  1.02666e+00 -4.87675e-01  8.02112e-01  2.39068e-01
21Feb13_013026|  -4.86850e-01  1.73530e+00 -1.15809e-01 -3.03472e-02]
21Feb13_013026| [-5.53044e-01  4.66997e-01  8.50262e-01 -9.72246e-01  5.75977e-01
21Feb13_013026|  -8.30986e-01  6.72198e-01 -1.48566e+00 -4.40186e-01]
21Feb13_013026| [ 1.56239e+00  4.89175e-02  3.52725e-01 -5.84369e-01  3.78056e-01
21Feb13_013026|  -1.08095e+00  2.25579e-01  1.36469e+00  1.05927e-01]
21Feb13_013026| [ 5.87912e-01 -6.66494e-01  7.79087e-01 -1.37734e+00 -5.68017e-02
21Feb13_013026|  -5.28526e-01 -2.16139e-01 -1.39364e-01 -1.22582e-01]
21Feb13_013026| [-3.25557e-01  7.27112e-02 -9.80921e-01  1.85031e-02 -2.87431e-01
21Feb13_013026|   1.76187e+00  1.29272e+00 -2.15986e+00 -3.48111e-02]
21Feb13_013026| [ 2.43878e-01  5.55203e-02  1.46280e+00 -6.81342e-01  6.28102e-01
21Feb13_013026|   7.31779e-01 -1.31015e+00  8.71093e-01 -4.54700e-01]
21Feb13_013026| [ 4.93144e-01  7.54375e-02 -1.20005e+00  6.27631e-02  7.82145e-01
21Feb13_013026|   5.33649e-01 -1.13427e+00  8.26364e-01 -1.48796e-01]
21Feb13_013026| [-4.21426e-01 -1.29212e-01 -8.75548e-01 -7.62601e-01 -5.40266e-01
21Feb13_013026|   1.80516e+00 -1.24863e+00  1.35354e+00 -3.30202e-02]
21Feb13_013026| [ 3.22391e-01 -5.16648e-01  1.97275e+00  3.26675e-01 -1.58735e-01
21Feb13_013026|  -1.86724e-01  3.96522e-01  6.89546e-01 -9.39432e-01]
21Feb13_013026| [-4.67129e-01  2.15586e+00 -5.38287e-01  2.78568e-01  9.42587e-01
21Feb13_013026|  -2.77032e-01  1.25393e+00  3.81716e-01  8.82734e-01]
21Feb13_013026| [-1.41583e+00 -1.45012e-01 -7.99630e-01 -5.31952e-01 -1.19693e+00
21Feb13_013026|   7.92286e-01  1.30639e-01 -2.37138e-01 -1.58410e+00]
21Feb13_013026| [-1.16444e+00 -5.22290e-01  1.02540e+00  3.99299e-01 -9.33985e-01
21Feb13_013026|   2.16709e+00  3.01229e-01 -7.56401e-01  1.21738e+00]
21Feb13_013026| [-4.96242e-01  1.99264e+00  1.72242e+00 -7.33992e-01  1.79053e+00
21Feb13_013026|   7.69467e-01  4.32490e-01  8.00370e-02 -1.48974e-01]
21Feb13_013026| [ 9.93945e-02 -1.39770e+00  2.13769e-01  1.86767e+00  1.11288e+00
21Feb13_013026|   6.22801e-01  3.99123e-01  6.84795e-01  2.17178e-01]
21Feb13_013026| [ 1.35578e+00  8.00580e-01  3.99488e-01  4.40513e-01  1.93473e-02
21Feb13_013026|  -4.51602e-01  2.87170e-01  3.29084e-02 -1.36035e+00]
21Feb13_013026| [-1.09101e+00  2.48048e+00  5.80244e-01 -1.33268e-01 -5.28168e-01
21Feb13_013026|   8.09824e-01 -4.30853e-01 -2.55311e-02  1.50016e+00]
21Feb13_013026| [ 5.18298e-02 -2.30052e-01  1.28184e+00 -2.64124e+00  3.01962e-01
21Feb13_013026|   1.55697e+00 -1.20762e+00  6.34586e-01 -1.58188e-01]
21Feb13_013026| [-1.72551e+00  1.63754e+00 -4.70755e-01 -1.15326e+00 -8.33712e-01
21Feb13_013026|   1.31472e+00  2.01820e-01 -2.33652e-01  2.10201e-01]
21Feb13_013026| [ 1.47803e-01  1.06813e-01 -7.00830e-02 -1.17159e+00 -1.10268e+00
21Feb13_013026|  -8.43557e-01  4.82005e-01  1.25841e+00  4.90572e-02]
21Feb13_013026| [-4.14468e-01 -9.13217e-01  1.43297e+00 -2.20598e-01 -5.00413e-02
21Feb13_013026|   1.00790e+00 -1.44685e+00  1.08882e-02  4.97447e-02]
21Feb13_013026| [ 8.57554e-01  1.16591e+00 -1.34007e-01  1.71257e+00 -1.12961e+00
21Feb13_013026|   1.37418e+00 -1.22028e+00 -6.84918e-01  7.78660e-01]
21Feb13_013026| [-7.13839e-01  1.40966e+00 -4.77517e-01 -1.19630e+00 -1.15371e+00
21Feb13_013026|  -3.93636e-01  3.23964e-01 -6.64234e-01  1.21979e+00]
21Feb13_013026| [ 1.74382e+00  1.33485e+00  1.78034e-01  9.41668e-02  2.62732e-01
21Feb13_013026|   8.78408e-01  2.48648e-01  1.21791e+00  4.85344e-01]
21Feb13_013026| [-5.31246e-01 -1.52761e-01  2.84841e-01 -2.19881e-01 -5.37130e-01
21Feb13_013026|  -5.76407e-01  9.54226e-01  4.85366e-01 -9.77571e-01]
21Feb13_013026| [-1.35084e+00  1.09906e+00 -6.32061e-01  1.77342e-01 -6.40846e-01
21Feb13_013026|  -3.03854e-02  1.66807e+00  3.12194e-02 -3.53426e-01]
21Feb13_013026| [ 9.50869e-01 -3.62129e-01  2.98314e-01  4.91118e-01 -1.57990e+00
21Feb13_013026|  -2.44973e+00  8.00915e-01  7.10599e-04  8.10353e-01]
21Feb13_013026| [ 1.78432e+00 -9.71843e-01 -1.97505e+00 -1.18986e+00 -2.70454e-01
21Feb13_013026|  -1.30340e+00  7.99598e-01 -2.84399e-01  2.78754e-01]
21Feb13_013026| [-6.25690e-01 -1.36899e+00 -1.69985e-01 -6.67490e-01 -1.83927e+00
21Feb13_013026|   7.29422e-01 -1.91879e+00  9.93721e-01  1.24720e-01]
21Feb13_013026| [-6.63423e-02 -1.59385e+00  1.31061e+00 -5.23944e-01 -9.22575e-01
21Feb13_013026|   1.02268e-01  4.40389e-01  7.93366e-01  8.34624e-01]
21Feb13_013026| [-3.15115e-01 -8.73738e-01  2.06436e-01 -4.60182e-01  3.67394e-01
21Feb13_013026|   8.74019e-01 -1.00027e+00 -7.35157e-01 -6.67303e-01]
21Feb13_013026| [ 2.59118e-01  1.24828e+00 -4.10084e-01  3.25478e-01 -1.34056e+00
21Feb13_013026|  -2.04943e+00 -8.99572e-02  1.63028e+00  5.09953e-01]
21Feb13_013026| [ 1.17609e-02 -8.36465e-01 -8.15524e-02  3.43689e-01 -9.21088e-01
21Feb13_013026|  -1.89687e+00 -1.24788e+00  1.11545e+00  9.05282e-01]
21Feb13_013026| [-1.50660e+00  6.36055e-01 -3.71286e-02  4.62230e-01  8.44458e-01
21Feb13_013026|  -1.52079e+00 -7.16504e-01  7.07441e-02 -1.03582e+00]
21Feb13_013026| [-3.32525e-02 -5.49366e-01  7.30336e-01  1.55130e+00  1.87862e+00
21Feb13_013026|   5.59851e-01  1.58186e+00  4.62385e-01  7.76501e-01]
21Feb13_013026| [-2.09596e+00  1.33953e+00 -1.51561e+00 -1.25216e+00 -1.00343e+00
21Feb13_013026|  -5.75715e-01  8.79691e-01 -1.53243e+00 -3.80041e-01]
21Feb13_013026| [ 1.61185e-01  5.12300e-01  1.59935e+00  1.06339e+00  7.93391e-01
21Feb13_013026|   2.53927e+00 -1.61466e+00 -1.69022e+00 -2.02367e-01]
21Feb13_013026| [-1.25470e+00 -2.58098e-01  5.92567e-01  3.37381e-01 -6.99700e-01
21Feb13_013026|   9.24420e-01  9.48337e-01 -8.98604e-01  9.35058e-01]
21Feb13_013026| [ 1.43861e+00  1.42065e+00 -9.84910e-01 -8.21470e-01 -5.79001e-02
21Feb13_013026|   6.47525e-01  8.65842e-01 -1.50544e-01 -5.53358e-01]
21Feb13_013026| [-6.20387e-01 -2.38812e-02 -1.35219e-01 -2.58836e-01 -1.37737e+00
21Feb13_013026|   5.90991e-01 -2.13963e-01 -1.42807e+00 -1.91510e-01]
21Feb13_013026| [-9.48377e-01  1.45005e+00  6.23528e-01  9.24684e-01  8.68100e-01
21Feb13_013026|  -1.99460e+00  4.72527e-01  1.81921e+00 -1.50210e-01]
21Feb13_013026| [ 5.42301e-01  2.45411e-01  1.22571e+00 -1.22660e+00  2.00326e+00
21Feb13_013026|   1.28311e+00 -4.79063e-01 -1.26853e+00  3.54082e-01]
21Feb13_013026| [-9.68448e-02 -9.53055e-01 -6.39710e-01  7.39744e-02 -3.14837e-01
21Feb13_013026|  -4.64567e-01  8.27918e-01 -1.06114e+00 -5.10970e-01]
21Feb13_013026| [ 2.33279e-01  7.22497e-01  9.49373e-01 -1.20131e+00 -8.38683e-01
21Feb13_013026|  -5.38987e-01 -2.01753e+00  1.18580e+00 -7.12282e-01]
21Feb13_013026| [ 1.38078e+00 -3.07472e-01 -9.41548e-01  2.12287e+00  7.20946e-01
21Feb13_013026|   4.38905e-01  1.23216e+00  1.01939e+00  1.80698e-01]
21Feb13_013026| [-1.45026e-01  1.94626e+00 -1.81820e+00  1.49784e+00  7.71685e-01
21Feb13_013026|   1.57506e-01 -7.09054e-01 -3.76284e-02 -6.77940e-01]
21Feb13_013026| [-8.93030e-01  4.45952e-01 -5.02934e-01 -1.64437e+00  2.79315e-01
21Feb13_013026|  -1.03096e+00 -1.36068e+00 -4.50048e-01  2.88074e-01]]
21Feb13_013026|-- Bias --
21Feb13_013026|[ 0.37717  0.47788 -0.06014 -0.50820  0.52122 -0.91124 -1.67126 -0.64210
21Feb13_013026| -0.07185]
21Feb13_013026|Layer 1:
21Feb13_013026|-- Config --
21Feb13_013026|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 9], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_013026|-- Weights --
21Feb13_013026|[[ 0.68231 -0.74250]
21Feb13_013026| [ 0.62314  1.42898]
21Feb13_013026| [ 2.01695  1.97734]
21Feb13_013026| [-0.39663 -0.22189]
21Feb13_013026| [ 0.44922  0.41110]
21Feb13_013026| [ 0.33786  0.12545]
21Feb13_013026| [ 0.50773  1.87586]
21Feb13_013026| [-1.32230 -0.68529]
21Feb13_013026| [-0.06485  1.23686]]
21Feb13_013026|-- Bias --
21Feb13_013026|[-0.71772 -0.40861]
21Feb13_013026|Predicting the validation and test data with the Best final individual.
21Feb13_013033| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_013033|-----------  ------------------  --------------------  ----------
21Feb13_013033|Validation         41.39                  9             0.01805
21Feb13_013033|   Test            36.40                  9             0.00298
21Feb13_013033|-------------------- Test #4 --------------------
21Feb13_013033|Best final individual weights
21Feb13_013033|Individual:
21Feb13_013033|-- Constant hidden layers --
21Feb13_013033|False
21Feb13_013033|Layer 0:
21Feb13_013033|-- Config --
21Feb13_013033|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 9, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_013033|-- Weights --
21Feb13_013033|[[-4.61006e-01  6.85931e-01 -1.53413e+00  3.18540e-01  1.65279e+00
21Feb13_013033|  -3.98052e-01  4.33508e-01 -6.92513e-01  3.42704e-01]
21Feb13_013033| [-1.09470e+00  9.32382e-01  7.25102e-01 -4.91678e-01  1.53894e+00
21Feb13_013033|   6.32892e-01  1.66659e+00 -1.21771e+00 -3.90783e-01]
21Feb13_013033| [ 9.03759e-01 -9.77900e-01  1.77765e+00 -2.07879e-01 -3.69959e-01
21Feb13_013033|   2.57340e-02  9.32038e-01  1.80456e+00  3.87273e-01]
21Feb13_013033| [-3.49696e-01 -3.58058e-03 -6.07396e-01 -1.37181e+00 -1.10504e+00
21Feb13_013033|  -1.11474e+00 -1.03332e+00  2.23341e-01 -4.72876e-01]
21Feb13_013033| [ 2.32707e-01 -1.07579e+00 -5.40875e-01  1.42954e+00  6.10975e-01
21Feb13_013033|   5.59004e-01 -5.83178e-01  1.52584e+00 -2.61616e-02]
21Feb13_013033| [ 2.60802e-01  1.01484e+00 -3.13035e-03  3.59113e-01 -5.42962e-02
21Feb13_013033|   1.30419e-01 -1.43042e+00  3.06781e-01  4.02528e-01]
21Feb13_013033| [ 3.31900e-01 -7.68883e-01  2.16435e+00  5.44727e-01 -7.94370e-01
21Feb13_013033|   4.13300e-01  8.17497e-01  8.49172e-01  3.89172e-01]
21Feb13_013033| [-1.74100e+00 -1.34439e+00 -1.72034e-01  5.54274e-01  4.11878e-03
21Feb13_013033|  -1.72138e+00  1.21996e+00 -2.14134e-01 -1.29167e-01]
21Feb13_013033| [ 1.02404e+00  6.15020e-02 -2.14163e-01  3.45452e-02  5.64308e-01
21Feb13_013033|   1.23836e-01 -7.85150e-01 -2.34675e-01 -6.19357e-01]
21Feb13_013033| [ 3.39580e-01 -9.02752e-01 -1.40731e+00  1.01083e+00 -1.27692e+00
21Feb13_013033|  -3.87978e-01  2.91565e-01  7.80658e-01 -4.54186e-01]
21Feb13_013033| [-6.53637e-01  3.40165e-01  6.43150e-01 -4.23568e-01 -2.78934e-01
21Feb13_013033|  -9.34614e-02 -6.67337e-01  4.52195e-01  1.32123e+00]
21Feb13_013033| [-1.27502e+00  1.02666e+00 -4.87675e-01  8.02112e-01  2.39068e-01
21Feb13_013033|  -4.86850e-01  1.73530e+00 -1.15809e-01 -3.03472e-02]
21Feb13_013033| [-5.53044e-01  4.66997e-01  8.50262e-01 -9.72246e-01  5.75977e-01
21Feb13_013033|  -8.30986e-01  6.72198e-01 -1.48566e+00 -4.40186e-01]
21Feb13_013033| [ 1.56239e+00  4.89175e-02  3.52725e-01 -5.84369e-01  3.78056e-01
21Feb13_013033|  -1.08095e+00  2.25579e-01  1.36469e+00  1.05927e-01]
21Feb13_013033| [ 5.87912e-01 -6.66494e-01  7.79087e-01 -1.37734e+00 -5.68017e-02
21Feb13_013033|  -5.28526e-01 -2.16139e-01 -1.39364e-01 -1.22582e-01]
21Feb13_013033| [-3.25557e-01  7.27112e-02 -9.80921e-01  1.85031e-02 -2.87431e-01
21Feb13_013033|   1.76187e+00  1.29272e+00 -2.15986e+00 -3.48111e-02]
21Feb13_013033| [ 2.43878e-01  5.55203e-02  1.46280e+00 -6.81342e-01  6.28102e-01
21Feb13_013033|   7.31779e-01 -1.31015e+00  8.71093e-01 -4.54700e-01]
21Feb13_013033| [ 4.93144e-01  7.54375e-02 -1.20005e+00  6.27631e-02  7.82145e-01
21Feb13_013033|   5.33649e-01 -1.13427e+00  8.26364e-01 -1.48796e-01]
21Feb13_013033| [-4.21426e-01 -1.29212e-01 -8.75548e-01 -7.62601e-01 -5.40266e-01
21Feb13_013033|   1.80516e+00 -1.24863e+00  1.35354e+00 -3.30202e-02]
21Feb13_013033| [ 3.22391e-01 -5.16648e-01  1.97275e+00  3.26675e-01 -1.58735e-01
21Feb13_013033|  -1.86724e-01  3.96522e-01  6.89546e-01 -9.39432e-01]
21Feb13_013033| [-4.67129e-01  2.15586e+00 -5.38287e-01  2.78568e-01  9.42587e-01
21Feb13_013033|  -2.77032e-01  1.25393e+00  3.81716e-01  8.82734e-01]
21Feb13_013033| [-1.41583e+00 -1.45012e-01 -7.99630e-01 -5.31952e-01 -1.19693e+00
21Feb13_013033|   7.92286e-01  1.30639e-01 -2.37138e-01 -1.58410e+00]
21Feb13_013033| [-1.16444e+00 -5.22290e-01  1.02540e+00  3.99299e-01 -9.33985e-01
21Feb13_013033|   2.16709e+00  3.01229e-01 -7.56401e-01  1.21738e+00]
21Feb13_013033| [-4.96242e-01  1.99264e+00  1.72242e+00 -7.33992e-01  1.79053e+00
21Feb13_013033|   7.69467e-01  4.32490e-01  8.00370e-02 -1.48974e-01]
21Feb13_013033| [ 9.93945e-02 -1.39770e+00  2.13769e-01  1.86767e+00  1.11288e+00
21Feb13_013033|   6.22801e-01  3.99123e-01  6.84795e-01  2.17178e-01]
21Feb13_013033| [ 1.35578e+00  8.00580e-01  3.99488e-01  4.40513e-01  1.93473e-02
21Feb13_013033|  -4.51602e-01  2.87170e-01  3.29084e-02 -1.36035e+00]
21Feb13_013033| [-1.09101e+00  2.48048e+00  5.80244e-01 -1.33268e-01 -5.28168e-01
21Feb13_013033|   8.09824e-01 -4.30853e-01 -2.55311e-02  1.50016e+00]
21Feb13_013033| [ 5.18298e-02 -2.30052e-01  1.28184e+00 -2.64124e+00  3.01962e-01
21Feb13_013033|   1.55697e+00 -1.20762e+00  6.34586e-01 -1.58188e-01]
21Feb13_013033| [-1.72551e+00  1.63754e+00 -4.70755e-01 -1.15326e+00 -8.33712e-01
21Feb13_013033|   1.31472e+00  2.01820e-01 -2.33652e-01  2.10201e-01]
21Feb13_013033| [ 1.47803e-01  1.06813e-01 -7.00830e-02 -1.17159e+00 -1.10268e+00
21Feb13_013033|  -8.43557e-01  4.82005e-01  1.25841e+00  4.90572e-02]
21Feb13_013033| [-4.14468e-01 -9.13217e-01  1.43297e+00 -2.20598e-01 -5.00413e-02
21Feb13_013033|   1.00790e+00 -1.44685e+00  1.08882e-02  4.97447e-02]
21Feb13_013033| [ 8.57554e-01  1.16591e+00 -1.34007e-01  1.71257e+00 -1.12961e+00
21Feb13_013033|   1.37418e+00 -1.22028e+00 -6.84918e-01  7.78660e-01]
21Feb13_013033| [-7.13839e-01  1.40966e+00 -4.77517e-01 -1.19630e+00 -1.15371e+00
21Feb13_013033|  -3.93636e-01  3.23964e-01 -6.64234e-01  1.21979e+00]
21Feb13_013033| [ 1.74382e+00  1.33485e+00  1.78034e-01  9.41668e-02  2.62732e-01
21Feb13_013033|   8.78408e-01  2.48648e-01  1.21791e+00  4.85344e-01]
21Feb13_013033| [-5.31246e-01 -1.52761e-01  2.84841e-01 -2.19881e-01 -5.37130e-01
21Feb13_013033|  -5.76407e-01  9.54226e-01  4.85366e-01 -9.77571e-01]
21Feb13_013033| [-1.35084e+00  1.09906e+00 -6.32061e-01  1.77342e-01 -6.40846e-01
21Feb13_013033|  -3.03854e-02  1.66807e+00  3.12194e-02 -3.53426e-01]
21Feb13_013033| [ 9.50869e-01 -3.62129e-01  2.98314e-01  4.91118e-01 -1.57990e+00
21Feb13_013033|  -2.44973e+00  8.00915e-01  7.10599e-04  8.10353e-01]
21Feb13_013033| [ 1.78432e+00 -9.71843e-01 -1.97505e+00 -1.18986e+00 -2.70454e-01
21Feb13_013033|  -1.30340e+00  7.99598e-01 -2.84399e-01  2.78754e-01]
21Feb13_013033| [-6.25690e-01 -1.36899e+00 -1.69985e-01 -6.67490e-01 -1.83927e+00
21Feb13_013033|   7.29422e-01 -1.91879e+00  9.93721e-01  1.24720e-01]
21Feb13_013033| [-6.63423e-02 -1.59385e+00  1.31061e+00 -5.23944e-01 -9.22575e-01
21Feb13_013033|   1.02268e-01  4.40389e-01  7.93366e-01  8.34624e-01]
21Feb13_013033| [-3.15115e-01 -8.73738e-01  2.06436e-01 -4.60182e-01  3.67394e-01
21Feb13_013033|   8.74019e-01 -1.00027e+00 -7.35157e-01 -6.67303e-01]
21Feb13_013033| [ 2.59118e-01  1.24828e+00 -4.10084e-01  3.25478e-01 -1.34056e+00
21Feb13_013033|  -2.04943e+00 -8.99572e-02  1.63028e+00  5.09953e-01]
21Feb13_013033| [ 1.17609e-02 -8.36465e-01 -8.15524e-02  3.43689e-01 -9.21088e-01
21Feb13_013033|  -1.89687e+00 -1.24788e+00  1.11545e+00  9.05282e-01]
21Feb13_013033| [-1.50660e+00  6.36055e-01 -3.71286e-02  4.62230e-01  8.44458e-01
21Feb13_013033|  -1.52079e+00 -7.16504e-01  7.07441e-02 -1.03582e+00]
21Feb13_013033| [-3.32525e-02 -5.49366e-01  7.30336e-01  1.55130e+00  1.87862e+00
21Feb13_013033|   5.59851e-01  1.58186e+00  4.62385e-01  7.76501e-01]
21Feb13_013033| [-2.09596e+00  1.33953e+00 -1.51561e+00 -1.25216e+00 -1.00343e+00
21Feb13_013033|  -5.75715e-01  8.79691e-01 -1.53243e+00 -3.80041e-01]
21Feb13_013033| [ 1.61185e-01  5.12300e-01  1.59935e+00  1.06339e+00  7.93391e-01
21Feb13_013033|   2.53927e+00 -1.61466e+00 -1.69022e+00 -2.02367e-01]
21Feb13_013033| [-1.25470e+00 -2.58098e-01  5.92567e-01  3.37381e-01 -6.99700e-01
21Feb13_013033|   9.24420e-01  9.48337e-01 -8.98604e-01  9.35058e-01]
21Feb13_013033| [ 1.43861e+00  1.42065e+00 -9.84910e-01 -8.21470e-01 -5.79001e-02
21Feb13_013033|   6.47525e-01  8.65842e-01 -1.50544e-01 -5.53358e-01]
21Feb13_013033| [-6.20387e-01 -2.38812e-02 -1.35219e-01 -2.58836e-01 -1.37737e+00
21Feb13_013033|   5.90991e-01 -2.13963e-01 -1.42807e+00 -1.91510e-01]
21Feb13_013033| [-9.48377e-01  1.45005e+00  6.23528e-01  9.24684e-01  8.68100e-01
21Feb13_013033|  -1.99460e+00  4.72527e-01  1.81921e+00 -1.50210e-01]
21Feb13_013033| [ 5.42301e-01  2.45411e-01  1.22571e+00 -1.22660e+00  2.00326e+00
21Feb13_013033|   1.28311e+00 -4.79063e-01 -1.26853e+00  3.54082e-01]
21Feb13_013033| [-9.68448e-02 -9.53055e-01 -6.39710e-01  7.39744e-02 -3.14837e-01
21Feb13_013033|  -4.64567e-01  8.27918e-01 -1.06114e+00 -5.10970e-01]
21Feb13_013033| [ 2.33279e-01  7.22497e-01  9.49373e-01 -1.20131e+00 -8.38683e-01
21Feb13_013033|  -5.38987e-01 -2.01753e+00  1.18580e+00 -7.12282e-01]
21Feb13_013033| [ 1.38078e+00 -3.07472e-01 -9.41548e-01  2.12287e+00  7.20946e-01
21Feb13_013033|   4.38905e-01  1.23216e+00  1.01939e+00  1.80698e-01]
21Feb13_013033| [-1.45026e-01  1.94626e+00 -1.81820e+00  1.49784e+00  7.71685e-01
21Feb13_013033|   1.57506e-01 -7.09054e-01 -3.76284e-02 -6.77940e-01]
21Feb13_013033| [-8.93030e-01  4.45952e-01 -5.02934e-01 -1.64437e+00  2.79315e-01
21Feb13_013033|  -1.03096e+00 -1.36068e+00 -4.50048e-01  2.88074e-01]]
21Feb13_013033|-- Bias --
21Feb13_013033|[ 0.37717  0.47788 -0.06014 -0.50820  0.52122 -0.91124 -1.67126 -0.64210
21Feb13_013033| -0.07185]
21Feb13_013033|Layer 1:
21Feb13_013033|-- Config --
21Feb13_013033|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 9], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_013033|-- Weights --
21Feb13_013033|[[ 0.68231 -0.74250]
21Feb13_013033| [ 0.62314  1.42898]
21Feb13_013033| [ 2.01695  1.97734]
21Feb13_013033| [-0.39663 -0.22189]
21Feb13_013033| [ 0.44922  0.41110]
21Feb13_013033| [ 0.33786  0.12545]
21Feb13_013033| [ 0.50773  1.87586]
21Feb13_013033| [-1.32230 -0.68529]
21Feb13_013033| [-0.06485  1.23686]]
21Feb13_013033|-- Bias --
21Feb13_013033|[-0.71772 -0.40861]
21Feb13_013033|Predicting the validation and test data with the Best final individual.
21Feb13_013040| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_013040|-----------  ------------------  --------------------  ----------
21Feb13_013040|Validation         41.48                  9             0.01804
21Feb13_013040|   Test            36.40                  9             0.00298
21Feb13_013040|-------------------- Test #5 --------------------
21Feb13_013040|Best final individual weights
21Feb13_013040|Individual:
21Feb13_013040|-- Constant hidden layers --
21Feb13_013040|False
21Feb13_013040|Layer 0:
21Feb13_013040|-- Config --
21Feb13_013040|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 9, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_013040|-- Weights --
21Feb13_013040|[[-4.61006e-01  6.85931e-01 -1.53413e+00  3.18540e-01  1.65279e+00
21Feb13_013040|  -3.98052e-01  4.33508e-01 -6.92513e-01  3.42704e-01]
21Feb13_013040| [-1.09470e+00  9.32382e-01  7.25102e-01 -4.91678e-01  1.53894e+00
21Feb13_013040|   6.32892e-01  1.66659e+00 -1.21771e+00 -3.90783e-01]
21Feb13_013040| [ 9.03759e-01 -9.77900e-01  1.77765e+00 -2.07879e-01 -3.69959e-01
21Feb13_013040|   2.57340e-02  9.32038e-01  1.80456e+00  3.87273e-01]
21Feb13_013040| [-3.49696e-01 -3.58058e-03 -6.07396e-01 -1.37181e+00 -1.10504e+00
21Feb13_013040|  -1.11474e+00 -1.03332e+00  2.23341e-01 -4.72876e-01]
21Feb13_013040| [ 2.32707e-01 -1.07579e+00 -5.40875e-01  1.42954e+00  6.10975e-01
21Feb13_013040|   5.59004e-01 -5.83178e-01  1.52584e+00 -2.61616e-02]
21Feb13_013040| [ 2.60802e-01  1.01484e+00 -3.13035e-03  3.59113e-01 -5.42962e-02
21Feb13_013040|   1.30419e-01 -1.43042e+00  3.06781e-01  4.02528e-01]
21Feb13_013040| [ 3.31900e-01 -7.68883e-01  2.16435e+00  5.44727e-01 -7.94370e-01
21Feb13_013040|   4.13300e-01  8.17497e-01  8.49172e-01  3.89172e-01]
21Feb13_013040| [-1.74100e+00 -1.34439e+00 -1.72034e-01  5.54274e-01  4.11878e-03
21Feb13_013040|  -1.72138e+00  1.21996e+00 -2.14134e-01 -1.29167e-01]
21Feb13_013040| [ 1.02404e+00  6.15020e-02 -2.14163e-01  3.45452e-02  5.64308e-01
21Feb13_013040|   1.23836e-01 -7.85150e-01 -2.34675e-01 -6.19357e-01]
21Feb13_013040| [ 3.39580e-01 -9.02752e-01 -1.40731e+00  1.01083e+00 -1.27692e+00
21Feb13_013040|  -3.87978e-01  2.91565e-01  7.80658e-01 -4.54186e-01]
21Feb13_013040| [-6.53637e-01  3.40165e-01  6.43150e-01 -4.23568e-01 -2.78934e-01
21Feb13_013040|  -9.34614e-02 -6.67337e-01  4.52195e-01  1.32123e+00]
21Feb13_013040| [-1.27502e+00  1.02666e+00 -4.87675e-01  8.02112e-01  2.39068e-01
21Feb13_013040|  -4.86850e-01  1.73530e+00 -1.15809e-01 -3.03472e-02]
21Feb13_013040| [-5.53044e-01  4.66997e-01  8.50262e-01 -9.72246e-01  5.75977e-01
21Feb13_013040|  -8.30986e-01  6.72198e-01 -1.48566e+00 -4.40186e-01]
21Feb13_013040| [ 1.56239e+00  4.89175e-02  3.52725e-01 -5.84369e-01  3.78056e-01
21Feb13_013040|  -1.08095e+00  2.25579e-01  1.36469e+00  1.05927e-01]
21Feb13_013040| [ 5.87912e-01 -6.66494e-01  7.79087e-01 -1.37734e+00 -5.68017e-02
21Feb13_013040|  -5.28526e-01 -2.16139e-01 -1.39364e-01 -1.22582e-01]
21Feb13_013040| [-3.25557e-01  7.27112e-02 -9.80921e-01  1.85031e-02 -2.87431e-01
21Feb13_013040|   1.76187e+00  1.29272e+00 -2.15986e+00 -3.48111e-02]
21Feb13_013040| [ 2.43878e-01  5.55203e-02  1.46280e+00 -6.81342e-01  6.28102e-01
21Feb13_013040|   7.31779e-01 -1.31015e+00  8.71093e-01 -4.54700e-01]
21Feb13_013040| [ 4.93144e-01  7.54375e-02 -1.20005e+00  6.27631e-02  7.82145e-01
21Feb13_013040|   5.33649e-01 -1.13427e+00  8.26364e-01 -1.48796e-01]
21Feb13_013040| [-4.21426e-01 -1.29212e-01 -8.75548e-01 -7.62601e-01 -5.40266e-01
21Feb13_013040|   1.80516e+00 -1.24863e+00  1.35354e+00 -3.30202e-02]
21Feb13_013040| [ 3.22391e-01 -5.16648e-01  1.97275e+00  3.26675e-01 -1.58735e-01
21Feb13_013040|  -1.86724e-01  3.96522e-01  6.89546e-01 -9.39432e-01]
21Feb13_013040| [-4.67129e-01  2.15586e+00 -5.38287e-01  2.78568e-01  9.42587e-01
21Feb13_013040|  -2.77032e-01  1.25393e+00  3.81716e-01  8.82734e-01]
21Feb13_013040| [-1.41583e+00 -1.45012e-01 -7.99630e-01 -5.31952e-01 -1.19693e+00
21Feb13_013040|   7.92286e-01  1.30639e-01 -2.37138e-01 -1.58410e+00]
21Feb13_013040| [-1.16444e+00 -5.22290e-01  1.02540e+00  3.99299e-01 -9.33985e-01
21Feb13_013040|   2.16709e+00  3.01229e-01 -7.56401e-01  1.21738e+00]
21Feb13_013040| [-4.96242e-01  1.99264e+00  1.72242e+00 -7.33992e-01  1.79053e+00
21Feb13_013040|   7.69467e-01  4.32490e-01  8.00370e-02 -1.48974e-01]
21Feb13_013040| [ 9.93945e-02 -1.39770e+00  2.13769e-01  1.86767e+00  1.11288e+00
21Feb13_013040|   6.22801e-01  3.99123e-01  6.84795e-01  2.17178e-01]
21Feb13_013040| [ 1.35578e+00  8.00580e-01  3.99488e-01  4.40513e-01  1.93473e-02
21Feb13_013040|  -4.51602e-01  2.87170e-01  3.29084e-02 -1.36035e+00]
21Feb13_013040| [-1.09101e+00  2.48048e+00  5.80244e-01 -1.33268e-01 -5.28168e-01
21Feb13_013040|   8.09824e-01 -4.30853e-01 -2.55311e-02  1.50016e+00]
21Feb13_013040| [ 5.18298e-02 -2.30052e-01  1.28184e+00 -2.64124e+00  3.01962e-01
21Feb13_013040|   1.55697e+00 -1.20762e+00  6.34586e-01 -1.58188e-01]
21Feb13_013040| [-1.72551e+00  1.63754e+00 -4.70755e-01 -1.15326e+00 -8.33712e-01
21Feb13_013040|   1.31472e+00  2.01820e-01 -2.33652e-01  2.10201e-01]
21Feb13_013040| [ 1.47803e-01  1.06813e-01 -7.00830e-02 -1.17159e+00 -1.10268e+00
21Feb13_013040|  -8.43557e-01  4.82005e-01  1.25841e+00  4.90572e-02]
21Feb13_013040| [-4.14468e-01 -9.13217e-01  1.43297e+00 -2.20598e-01 -5.00413e-02
21Feb13_013040|   1.00790e+00 -1.44685e+00  1.08882e-02  4.97447e-02]
21Feb13_013040| [ 8.57554e-01  1.16591e+00 -1.34007e-01  1.71257e+00 -1.12961e+00
21Feb13_013040|   1.37418e+00 -1.22028e+00 -6.84918e-01  7.78660e-01]
21Feb13_013040| [-7.13839e-01  1.40966e+00 -4.77517e-01 -1.19630e+00 -1.15371e+00
21Feb13_013040|  -3.93636e-01  3.23964e-01 -6.64234e-01  1.21979e+00]
21Feb13_013040| [ 1.74382e+00  1.33485e+00  1.78034e-01  9.41668e-02  2.62732e-01
21Feb13_013040|   8.78408e-01  2.48648e-01  1.21791e+00  4.85344e-01]
21Feb13_013040| [-5.31246e-01 -1.52761e-01  2.84841e-01 -2.19881e-01 -5.37130e-01
21Feb13_013040|  -5.76407e-01  9.54226e-01  4.85366e-01 -9.77571e-01]
21Feb13_013040| [-1.35084e+00  1.09906e+00 -6.32061e-01  1.77342e-01 -6.40846e-01
21Feb13_013040|  -3.03854e-02  1.66807e+00  3.12194e-02 -3.53426e-01]
21Feb13_013040| [ 9.50869e-01 -3.62129e-01  2.98314e-01  4.91118e-01 -1.57990e+00
21Feb13_013040|  -2.44973e+00  8.00915e-01  7.10599e-04  8.10353e-01]
21Feb13_013040| [ 1.78432e+00 -9.71843e-01 -1.97505e+00 -1.18986e+00 -2.70454e-01
21Feb13_013040|  -1.30340e+00  7.99598e-01 -2.84399e-01  2.78754e-01]
21Feb13_013040| [-6.25690e-01 -1.36899e+00 -1.69985e-01 -6.67490e-01 -1.83927e+00
21Feb13_013040|   7.29422e-01 -1.91879e+00  9.93721e-01  1.24720e-01]
21Feb13_013040| [-6.63423e-02 -1.59385e+00  1.31061e+00 -5.23944e-01 -9.22575e-01
21Feb13_013040|   1.02268e-01  4.40389e-01  7.93366e-01  8.34624e-01]
21Feb13_013040| [-3.15115e-01 -8.73738e-01  2.06436e-01 -4.60182e-01  3.67394e-01
21Feb13_013040|   8.74019e-01 -1.00027e+00 -7.35157e-01 -6.67303e-01]
21Feb13_013040| [ 2.59118e-01  1.24828e+00 -4.10084e-01  3.25478e-01 -1.34056e+00
21Feb13_013040|  -2.04943e+00 -8.99572e-02  1.63028e+00  5.09953e-01]
21Feb13_013040| [ 1.17609e-02 -8.36465e-01 -8.15524e-02  3.43689e-01 -9.21088e-01
21Feb13_013040|  -1.89687e+00 -1.24788e+00  1.11545e+00  9.05282e-01]
21Feb13_013040| [-1.50660e+00  6.36055e-01 -3.71286e-02  4.62230e-01  8.44458e-01
21Feb13_013040|  -1.52079e+00 -7.16504e-01  7.07441e-02 -1.03582e+00]
21Feb13_013040| [-3.32525e-02 -5.49366e-01  7.30336e-01  1.55130e+00  1.87862e+00
21Feb13_013040|   5.59851e-01  1.58186e+00  4.62385e-01  7.76501e-01]
21Feb13_013040| [-2.09596e+00  1.33953e+00 -1.51561e+00 -1.25216e+00 -1.00343e+00
21Feb13_013040|  -5.75715e-01  8.79691e-01 -1.53243e+00 -3.80041e-01]
21Feb13_013040| [ 1.61185e-01  5.12300e-01  1.59935e+00  1.06339e+00  7.93391e-01
21Feb13_013040|   2.53927e+00 -1.61466e+00 -1.69022e+00 -2.02367e-01]
21Feb13_013040| [-1.25470e+00 -2.58098e-01  5.92567e-01  3.37381e-01 -6.99700e-01
21Feb13_013040|   9.24420e-01  9.48337e-01 -8.98604e-01  9.35058e-01]
21Feb13_013040| [ 1.43861e+00  1.42065e+00 -9.84910e-01 -8.21470e-01 -5.79001e-02
21Feb13_013040|   6.47525e-01  8.65842e-01 -1.50544e-01 -5.53358e-01]
21Feb13_013040| [-6.20387e-01 -2.38812e-02 -1.35219e-01 -2.58836e-01 -1.37737e+00
21Feb13_013040|   5.90991e-01 -2.13963e-01 -1.42807e+00 -1.91510e-01]
21Feb13_013040| [-9.48377e-01  1.45005e+00  6.23528e-01  9.24684e-01  8.68100e-01
21Feb13_013040|  -1.99460e+00  4.72527e-01  1.81921e+00 -1.50210e-01]
21Feb13_013040| [ 5.42301e-01  2.45411e-01  1.22571e+00 -1.22660e+00  2.00326e+00
21Feb13_013040|   1.28311e+00 -4.79063e-01 -1.26853e+00  3.54082e-01]
21Feb13_013040| [-9.68448e-02 -9.53055e-01 -6.39710e-01  7.39744e-02 -3.14837e-01
21Feb13_013040|  -4.64567e-01  8.27918e-01 -1.06114e+00 -5.10970e-01]
21Feb13_013040| [ 2.33279e-01  7.22497e-01  9.49373e-01 -1.20131e+00 -8.38683e-01
21Feb13_013040|  -5.38987e-01 -2.01753e+00  1.18580e+00 -7.12282e-01]
21Feb13_013040| [ 1.38078e+00 -3.07472e-01 -9.41548e-01  2.12287e+00  7.20946e-01
21Feb13_013040|   4.38905e-01  1.23216e+00  1.01939e+00  1.80698e-01]
21Feb13_013040| [-1.45026e-01  1.94626e+00 -1.81820e+00  1.49784e+00  7.71685e-01
21Feb13_013040|   1.57506e-01 -7.09054e-01 -3.76284e-02 -6.77940e-01]
21Feb13_013040| [-8.93030e-01  4.45952e-01 -5.02934e-01 -1.64437e+00  2.79315e-01
21Feb13_013040|  -1.03096e+00 -1.36068e+00 -4.50048e-01  2.88074e-01]]
21Feb13_013040|-- Bias --
21Feb13_013040|[ 0.37717  0.47788 -0.06014 -0.50820  0.52122 -0.91124 -1.67126 -0.64210
21Feb13_013040| -0.07185]
21Feb13_013040|Layer 1:
21Feb13_013040|-- Config --
21Feb13_013040|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 9], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_013040|-- Weights --
21Feb13_013040|[[ 0.68231 -0.74250]
21Feb13_013040| [ 0.62314  1.42898]
21Feb13_013040| [ 2.01695  1.97734]
21Feb13_013040| [-0.39663 -0.22189]
21Feb13_013040| [ 0.44922  0.41110]
21Feb13_013040| [ 0.33786  0.12545]
21Feb13_013040| [ 0.50773  1.87586]
21Feb13_013040| [-1.32230 -0.68529]
21Feb13_013040| [-0.06485  1.23686]]
21Feb13_013040|-- Bias --
21Feb13_013040|[-0.71772 -0.40861]
21Feb13_013040|Predicting the validation and test data with the Best final individual.
21Feb13_013047| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_013047|-----------  ------------------  --------------------  ----------
21Feb13_013047|Validation         41.39                  9             0.01805
21Feb13_013047|   Test            36.40                  9             0.00298
21Feb13_013047|-------------------- Test #6 --------------------
21Feb13_013047|Best final individual weights
21Feb13_013047|Individual:
21Feb13_013047|-- Constant hidden layers --
21Feb13_013047|False
21Feb13_013047|Layer 0:
21Feb13_013047|-- Config --
21Feb13_013047|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 9, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_013047|-- Weights --
21Feb13_013047|[[-4.61006e-01  6.85931e-01 -1.53413e+00  3.18540e-01  1.65279e+00
21Feb13_013047|  -3.98052e-01  4.33508e-01 -6.92513e-01  3.42704e-01]
21Feb13_013047| [-1.09470e+00  9.32382e-01  7.25102e-01 -4.91678e-01  1.53894e+00
21Feb13_013047|   6.32892e-01  1.66659e+00 -1.21771e+00 -3.90783e-01]
21Feb13_013047| [ 9.03759e-01 -9.77900e-01  1.77765e+00 -2.07879e-01 -3.69959e-01
21Feb13_013047|   2.57340e-02  9.32038e-01  1.80456e+00  3.87273e-01]
21Feb13_013047| [-3.49696e-01 -3.58058e-03 -6.07396e-01 -1.37181e+00 -1.10504e+00
21Feb13_013047|  -1.11474e+00 -1.03332e+00  2.23341e-01 -4.72876e-01]
21Feb13_013047| [ 2.32707e-01 -1.07579e+00 -5.40875e-01  1.42954e+00  6.10975e-01
21Feb13_013047|   5.59004e-01 -5.83178e-01  1.52584e+00 -2.61616e-02]
21Feb13_013047| [ 2.60802e-01  1.01484e+00 -3.13035e-03  3.59113e-01 -5.42962e-02
21Feb13_013047|   1.30419e-01 -1.43042e+00  3.06781e-01  4.02528e-01]
21Feb13_013047| [ 3.31900e-01 -7.68883e-01  2.16435e+00  5.44727e-01 -7.94370e-01
21Feb13_013047|   4.13300e-01  8.17497e-01  8.49172e-01  3.89172e-01]
21Feb13_013047| [-1.74100e+00 -1.34439e+00 -1.72034e-01  5.54274e-01  4.11878e-03
21Feb13_013047|  -1.72138e+00  1.21996e+00 -2.14134e-01 -1.29167e-01]
21Feb13_013047| [ 1.02404e+00  6.15020e-02 -2.14163e-01  3.45452e-02  5.64308e-01
21Feb13_013047|   1.23836e-01 -7.85150e-01 -2.34675e-01 -6.19357e-01]
21Feb13_013047| [ 3.39580e-01 -9.02752e-01 -1.40731e+00  1.01083e+00 -1.27692e+00
21Feb13_013047|  -3.87978e-01  2.91565e-01  7.80658e-01 -4.54186e-01]
21Feb13_013047| [-6.53637e-01  3.40165e-01  6.43150e-01 -4.23568e-01 -2.78934e-01
21Feb13_013047|  -9.34614e-02 -6.67337e-01  4.52195e-01  1.32123e+00]
21Feb13_013047| [-1.27502e+00  1.02666e+00 -4.87675e-01  8.02112e-01  2.39068e-01
21Feb13_013047|  -4.86850e-01  1.73530e+00 -1.15809e-01 -3.03472e-02]
21Feb13_013047| [-5.53044e-01  4.66997e-01  8.50262e-01 -9.72246e-01  5.75977e-01
21Feb13_013047|  -8.30986e-01  6.72198e-01 -1.48566e+00 -4.40186e-01]
21Feb13_013047| [ 1.56239e+00  4.89175e-02  3.52725e-01 -5.84369e-01  3.78056e-01
21Feb13_013047|  -1.08095e+00  2.25579e-01  1.36469e+00  1.05927e-01]
21Feb13_013047| [ 5.87912e-01 -6.66494e-01  7.79087e-01 -1.37734e+00 -5.68017e-02
21Feb13_013047|  -5.28526e-01 -2.16139e-01 -1.39364e-01 -1.22582e-01]
21Feb13_013047| [-3.25557e-01  7.27112e-02 -9.80921e-01  1.85031e-02 -2.87431e-01
21Feb13_013047|   1.76187e+00  1.29272e+00 -2.15986e+00 -3.48111e-02]
21Feb13_013047| [ 2.43878e-01  5.55203e-02  1.46280e+00 -6.81342e-01  6.28102e-01
21Feb13_013047|   7.31779e-01 -1.31015e+00  8.71093e-01 -4.54700e-01]
21Feb13_013047| [ 4.93144e-01  7.54375e-02 -1.20005e+00  6.27631e-02  7.82145e-01
21Feb13_013047|   5.33649e-01 -1.13427e+00  8.26364e-01 -1.48796e-01]
21Feb13_013047| [-4.21426e-01 -1.29212e-01 -8.75548e-01 -7.62601e-01 -5.40266e-01
21Feb13_013047|   1.80516e+00 -1.24863e+00  1.35354e+00 -3.30202e-02]
21Feb13_013047| [ 3.22391e-01 -5.16648e-01  1.97275e+00  3.26675e-01 -1.58735e-01
21Feb13_013047|  -1.86724e-01  3.96522e-01  6.89546e-01 -9.39432e-01]
21Feb13_013047| [-4.67129e-01  2.15586e+00 -5.38287e-01  2.78568e-01  9.42587e-01
21Feb13_013047|  -2.77032e-01  1.25393e+00  3.81716e-01  8.82734e-01]
21Feb13_013047| [-1.41583e+00 -1.45012e-01 -7.99630e-01 -5.31952e-01 -1.19693e+00
21Feb13_013047|   7.92286e-01  1.30639e-01 -2.37138e-01 -1.58410e+00]
21Feb13_013047| [-1.16444e+00 -5.22290e-01  1.02540e+00  3.99299e-01 -9.33985e-01
21Feb13_013047|   2.16709e+00  3.01229e-01 -7.56401e-01  1.21738e+00]
21Feb13_013047| [-4.96242e-01  1.99264e+00  1.72242e+00 -7.33992e-01  1.79053e+00
21Feb13_013047|   7.69467e-01  4.32490e-01  8.00370e-02 -1.48974e-01]
21Feb13_013047| [ 9.93945e-02 -1.39770e+00  2.13769e-01  1.86767e+00  1.11288e+00
21Feb13_013047|   6.22801e-01  3.99123e-01  6.84795e-01  2.17178e-01]
21Feb13_013047| [ 1.35578e+00  8.00580e-01  3.99488e-01  4.40513e-01  1.93473e-02
21Feb13_013047|  -4.51602e-01  2.87170e-01  3.29084e-02 -1.36035e+00]
21Feb13_013047| [-1.09101e+00  2.48048e+00  5.80244e-01 -1.33268e-01 -5.28168e-01
21Feb13_013047|   8.09824e-01 -4.30853e-01 -2.55311e-02  1.50016e+00]
21Feb13_013047| [ 5.18298e-02 -2.30052e-01  1.28184e+00 -2.64124e+00  3.01962e-01
21Feb13_013047|   1.55697e+00 -1.20762e+00  6.34586e-01 -1.58188e-01]
21Feb13_013047| [-1.72551e+00  1.63754e+00 -4.70755e-01 -1.15326e+00 -8.33712e-01
21Feb13_013047|   1.31472e+00  2.01820e-01 -2.33652e-01  2.10201e-01]
21Feb13_013047| [ 1.47803e-01  1.06813e-01 -7.00830e-02 -1.17159e+00 -1.10268e+00
21Feb13_013047|  -8.43557e-01  4.82005e-01  1.25841e+00  4.90572e-02]
21Feb13_013047| [-4.14468e-01 -9.13217e-01  1.43297e+00 -2.20598e-01 -5.00413e-02
21Feb13_013047|   1.00790e+00 -1.44685e+00  1.08882e-02  4.97447e-02]
21Feb13_013047| [ 8.57554e-01  1.16591e+00 -1.34007e-01  1.71257e+00 -1.12961e+00
21Feb13_013047|   1.37418e+00 -1.22028e+00 -6.84918e-01  7.78660e-01]
21Feb13_013047| [-7.13839e-01  1.40966e+00 -4.77517e-01 -1.19630e+00 -1.15371e+00
21Feb13_013047|  -3.93636e-01  3.23964e-01 -6.64234e-01  1.21979e+00]
21Feb13_013047| [ 1.74382e+00  1.33485e+00  1.78034e-01  9.41668e-02  2.62732e-01
21Feb13_013047|   8.78408e-01  2.48648e-01  1.21791e+00  4.85344e-01]
21Feb13_013047| [-5.31246e-01 -1.52761e-01  2.84841e-01 -2.19881e-01 -5.37130e-01
21Feb13_013047|  -5.76407e-01  9.54226e-01  4.85366e-01 -9.77571e-01]
21Feb13_013047| [-1.35084e+00  1.09906e+00 -6.32061e-01  1.77342e-01 -6.40846e-01
21Feb13_013047|  -3.03854e-02  1.66807e+00  3.12194e-02 -3.53426e-01]
21Feb13_013047| [ 9.50869e-01 -3.62129e-01  2.98314e-01  4.91118e-01 -1.57990e+00
21Feb13_013047|  -2.44973e+00  8.00915e-01  7.10599e-04  8.10353e-01]
21Feb13_013047| [ 1.78432e+00 -9.71843e-01 -1.97505e+00 -1.18986e+00 -2.70454e-01
21Feb13_013047|  -1.30340e+00  7.99598e-01 -2.84399e-01  2.78754e-01]
21Feb13_013047| [-6.25690e-01 -1.36899e+00 -1.69985e-01 -6.67490e-01 -1.83927e+00
21Feb13_013047|   7.29422e-01 -1.91879e+00  9.93721e-01  1.24720e-01]
21Feb13_013047| [-6.63423e-02 -1.59385e+00  1.31061e+00 -5.23944e-01 -9.22575e-01
21Feb13_013047|   1.02268e-01  4.40389e-01  7.93366e-01  8.34624e-01]
21Feb13_013047| [-3.15115e-01 -8.73738e-01  2.06436e-01 -4.60182e-01  3.67394e-01
21Feb13_013047|   8.74019e-01 -1.00027e+00 -7.35157e-01 -6.67303e-01]
21Feb13_013047| [ 2.59118e-01  1.24828e+00 -4.10084e-01  3.25478e-01 -1.34056e+00
21Feb13_013047|  -2.04943e+00 -8.99572e-02  1.63028e+00  5.09953e-01]
21Feb13_013047| [ 1.17609e-02 -8.36465e-01 -8.15524e-02  3.43689e-01 -9.21088e-01
21Feb13_013047|  -1.89687e+00 -1.24788e+00  1.11545e+00  9.05282e-01]
21Feb13_013047| [-1.50660e+00  6.36055e-01 -3.71286e-02  4.62230e-01  8.44458e-01
21Feb13_013047|  -1.52079e+00 -7.16504e-01  7.07441e-02 -1.03582e+00]
21Feb13_013047| [-3.32525e-02 -5.49366e-01  7.30336e-01  1.55130e+00  1.87862e+00
21Feb13_013047|   5.59851e-01  1.58186e+00  4.62385e-01  7.76501e-01]
21Feb13_013047| [-2.09596e+00  1.33953e+00 -1.51561e+00 -1.25216e+00 -1.00343e+00
21Feb13_013047|  -5.75715e-01  8.79691e-01 -1.53243e+00 -3.80041e-01]
21Feb13_013047| [ 1.61185e-01  5.12300e-01  1.59935e+00  1.06339e+00  7.93391e-01
21Feb13_013047|   2.53927e+00 -1.61466e+00 -1.69022e+00 -2.02367e-01]
21Feb13_013047| [-1.25470e+00 -2.58098e-01  5.92567e-01  3.37381e-01 -6.99700e-01
21Feb13_013047|   9.24420e-01  9.48337e-01 -8.98604e-01  9.35058e-01]
21Feb13_013047| [ 1.43861e+00  1.42065e+00 -9.84910e-01 -8.21470e-01 -5.79001e-02
21Feb13_013047|   6.47525e-01  8.65842e-01 -1.50544e-01 -5.53358e-01]
21Feb13_013047| [-6.20387e-01 -2.38812e-02 -1.35219e-01 -2.58836e-01 -1.37737e+00
21Feb13_013047|   5.90991e-01 -2.13963e-01 -1.42807e+00 -1.91510e-01]
21Feb13_013047| [-9.48377e-01  1.45005e+00  6.23528e-01  9.24684e-01  8.68100e-01
21Feb13_013047|  -1.99460e+00  4.72527e-01  1.81921e+00 -1.50210e-01]
21Feb13_013047| [ 5.42301e-01  2.45411e-01  1.22571e+00 -1.22660e+00  2.00326e+00
21Feb13_013047|   1.28311e+00 -4.79063e-01 -1.26853e+00  3.54082e-01]
21Feb13_013047| [-9.68448e-02 -9.53055e-01 -6.39710e-01  7.39744e-02 -3.14837e-01
21Feb13_013047|  -4.64567e-01  8.27918e-01 -1.06114e+00 -5.10970e-01]
21Feb13_013047| [ 2.33279e-01  7.22497e-01  9.49373e-01 -1.20131e+00 -8.38683e-01
21Feb13_013047|  -5.38987e-01 -2.01753e+00  1.18580e+00 -7.12282e-01]
21Feb13_013047| [ 1.38078e+00 -3.07472e-01 -9.41548e-01  2.12287e+00  7.20946e-01
21Feb13_013047|   4.38905e-01  1.23216e+00  1.01939e+00  1.80698e-01]
21Feb13_013047| [-1.45026e-01  1.94626e+00 -1.81820e+00  1.49784e+00  7.71685e-01
21Feb13_013047|   1.57506e-01 -7.09054e-01 -3.76284e-02 -6.77940e-01]
21Feb13_013047| [-8.93030e-01  4.45952e-01 -5.02934e-01 -1.64437e+00  2.79315e-01
21Feb13_013047|  -1.03096e+00 -1.36068e+00 -4.50048e-01  2.88074e-01]]
21Feb13_013047|-- Bias --
21Feb13_013047|[ 0.37717  0.47788 -0.06014 -0.50820  0.52122 -0.91124 -1.67126 -0.64210
21Feb13_013047| -0.07185]
21Feb13_013047|Layer 1:
21Feb13_013047|-- Config --
21Feb13_013047|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 9], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_013047|-- Weights --
21Feb13_013047|[[ 0.68231 -0.74250]
21Feb13_013047| [ 0.62314  1.42898]
21Feb13_013047| [ 2.01695  1.97734]
21Feb13_013047| [-0.39663 -0.22189]
21Feb13_013047| [ 0.44922  0.41110]
21Feb13_013047| [ 0.33786  0.12545]
21Feb13_013047| [ 0.50773  1.87586]
21Feb13_013047| [-1.32230 -0.68529]
21Feb13_013047| [-0.06485  1.23686]]
21Feb13_013047|-- Bias --
21Feb13_013047|[-0.71772 -0.40861]
21Feb13_013047|Predicting the validation and test data with the Best final individual.
21Feb13_013054| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_013054|-----------  ------------------  --------------------  ----------
21Feb13_013054|Validation         41.39                  9             0.01805
21Feb13_013054|   Test            36.40                  9             0.00298
21Feb13_013054|-------------------- Test #7 --------------------
21Feb13_013054|Best final individual weights
21Feb13_013054|Individual:
21Feb13_013054|-- Constant hidden layers --
21Feb13_013054|False
21Feb13_013054|Layer 0:
21Feb13_013054|-- Config --
21Feb13_013054|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 9, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_013054|-- Weights --
21Feb13_013054|[[-4.61006e-01  6.85931e-01 -1.53413e+00  3.18540e-01  1.65279e+00
21Feb13_013054|  -3.98052e-01  4.33508e-01 -6.92513e-01  3.42704e-01]
21Feb13_013054| [-1.09470e+00  9.32382e-01  7.25102e-01 -4.91678e-01  1.53894e+00
21Feb13_013054|   6.32892e-01  1.66659e+00 -1.21771e+00 -3.90783e-01]
21Feb13_013054| [ 9.03759e-01 -9.77900e-01  1.77765e+00 -2.07879e-01 -3.69959e-01
21Feb13_013054|   2.57340e-02  9.32038e-01  1.80456e+00  3.87273e-01]
21Feb13_013054| [-3.49696e-01 -3.58058e-03 -6.07396e-01 -1.37181e+00 -1.10504e+00
21Feb13_013054|  -1.11474e+00 -1.03332e+00  2.23341e-01 -4.72876e-01]
21Feb13_013054| [ 2.32707e-01 -1.07579e+00 -5.40875e-01  1.42954e+00  6.10975e-01
21Feb13_013054|   5.59004e-01 -5.83178e-01  1.52584e+00 -2.61616e-02]
21Feb13_013054| [ 2.60802e-01  1.01484e+00 -3.13035e-03  3.59113e-01 -5.42962e-02
21Feb13_013054|   1.30419e-01 -1.43042e+00  3.06781e-01  4.02528e-01]
21Feb13_013054| [ 3.31900e-01 -7.68883e-01  2.16435e+00  5.44727e-01 -7.94370e-01
21Feb13_013054|   4.13300e-01  8.17497e-01  8.49172e-01  3.89172e-01]
21Feb13_013054| [-1.74100e+00 -1.34439e+00 -1.72034e-01  5.54274e-01  4.11878e-03
21Feb13_013054|  -1.72138e+00  1.21996e+00 -2.14134e-01 -1.29167e-01]
21Feb13_013054| [ 1.02404e+00  6.15020e-02 -2.14163e-01  3.45452e-02  5.64308e-01
21Feb13_013054|   1.23836e-01 -7.85150e-01 -2.34675e-01 -6.19357e-01]
21Feb13_013054| [ 3.39580e-01 -9.02752e-01 -1.40731e+00  1.01083e+00 -1.27692e+00
21Feb13_013054|  -3.87978e-01  2.91565e-01  7.80658e-01 -4.54186e-01]
21Feb13_013054| [-6.53637e-01  3.40165e-01  6.43150e-01 -4.23568e-01 -2.78934e-01
21Feb13_013054|  -9.34614e-02 -6.67337e-01  4.52195e-01  1.32123e+00]
21Feb13_013054| [-1.27502e+00  1.02666e+00 -4.87675e-01  8.02112e-01  2.39068e-01
21Feb13_013054|  -4.86850e-01  1.73530e+00 -1.15809e-01 -3.03472e-02]
21Feb13_013054| [-5.53044e-01  4.66997e-01  8.50262e-01 -9.72246e-01  5.75977e-01
21Feb13_013054|  -8.30986e-01  6.72198e-01 -1.48566e+00 -4.40186e-01]
21Feb13_013054| [ 1.56239e+00  4.89175e-02  3.52725e-01 -5.84369e-01  3.78056e-01
21Feb13_013054|  -1.08095e+00  2.25579e-01  1.36469e+00  1.05927e-01]
21Feb13_013054| [ 5.87912e-01 -6.66494e-01  7.79087e-01 -1.37734e+00 -5.68017e-02
21Feb13_013054|  -5.28526e-01 -2.16139e-01 -1.39364e-01 -1.22582e-01]
21Feb13_013054| [-3.25557e-01  7.27112e-02 -9.80921e-01  1.85031e-02 -2.87431e-01
21Feb13_013054|   1.76187e+00  1.29272e+00 -2.15986e+00 -3.48111e-02]
21Feb13_013054| [ 2.43878e-01  5.55203e-02  1.46280e+00 -6.81342e-01  6.28102e-01
21Feb13_013054|   7.31779e-01 -1.31015e+00  8.71093e-01 -4.54700e-01]
21Feb13_013054| [ 4.93144e-01  7.54375e-02 -1.20005e+00  6.27631e-02  7.82145e-01
21Feb13_013054|   5.33649e-01 -1.13427e+00  8.26364e-01 -1.48796e-01]
21Feb13_013054| [-4.21426e-01 -1.29212e-01 -8.75548e-01 -7.62601e-01 -5.40266e-01
21Feb13_013054|   1.80516e+00 -1.24863e+00  1.35354e+00 -3.30202e-02]
21Feb13_013054| [ 3.22391e-01 -5.16648e-01  1.97275e+00  3.26675e-01 -1.58735e-01
21Feb13_013054|  -1.86724e-01  3.96522e-01  6.89546e-01 -9.39432e-01]
21Feb13_013054| [-4.67129e-01  2.15586e+00 -5.38287e-01  2.78568e-01  9.42587e-01
21Feb13_013054|  -2.77032e-01  1.25393e+00  3.81716e-01  8.82734e-01]
21Feb13_013054| [-1.41583e+00 -1.45012e-01 -7.99630e-01 -5.31952e-01 -1.19693e+00
21Feb13_013054|   7.92286e-01  1.30639e-01 -2.37138e-01 -1.58410e+00]
21Feb13_013054| [-1.16444e+00 -5.22290e-01  1.02540e+00  3.99299e-01 -9.33985e-01
21Feb13_013054|   2.16709e+00  3.01229e-01 -7.56401e-01  1.21738e+00]
21Feb13_013054| [-4.96242e-01  1.99264e+00  1.72242e+00 -7.33992e-01  1.79053e+00
21Feb13_013054|   7.69467e-01  4.32490e-01  8.00370e-02 -1.48974e-01]
21Feb13_013054| [ 9.93945e-02 -1.39770e+00  2.13769e-01  1.86767e+00  1.11288e+00
21Feb13_013054|   6.22801e-01  3.99123e-01  6.84795e-01  2.17178e-01]
21Feb13_013054| [ 1.35578e+00  8.00580e-01  3.99488e-01  4.40513e-01  1.93473e-02
21Feb13_013054|  -4.51602e-01  2.87170e-01  3.29084e-02 -1.36035e+00]
21Feb13_013054| [-1.09101e+00  2.48048e+00  5.80244e-01 -1.33268e-01 -5.28168e-01
21Feb13_013054|   8.09824e-01 -4.30853e-01 -2.55311e-02  1.50016e+00]
21Feb13_013054| [ 5.18298e-02 -2.30052e-01  1.28184e+00 -2.64124e+00  3.01962e-01
21Feb13_013054|   1.55697e+00 -1.20762e+00  6.34586e-01 -1.58188e-01]
21Feb13_013054| [-1.72551e+00  1.63754e+00 -4.70755e-01 -1.15326e+00 -8.33712e-01
21Feb13_013054|   1.31472e+00  2.01820e-01 -2.33652e-01  2.10201e-01]
21Feb13_013054| [ 1.47803e-01  1.06813e-01 -7.00830e-02 -1.17159e+00 -1.10268e+00
21Feb13_013054|  -8.43557e-01  4.82005e-01  1.25841e+00  4.90572e-02]
21Feb13_013054| [-4.14468e-01 -9.13217e-01  1.43297e+00 -2.20598e-01 -5.00413e-02
21Feb13_013054|   1.00790e+00 -1.44685e+00  1.08882e-02  4.97447e-02]
21Feb13_013054| [ 8.57554e-01  1.16591e+00 -1.34007e-01  1.71257e+00 -1.12961e+00
21Feb13_013054|   1.37418e+00 -1.22028e+00 -6.84918e-01  7.78660e-01]
21Feb13_013054| [-7.13839e-01  1.40966e+00 -4.77517e-01 -1.19630e+00 -1.15371e+00
21Feb13_013054|  -3.93636e-01  3.23964e-01 -6.64234e-01  1.21979e+00]
21Feb13_013054| [ 1.74382e+00  1.33485e+00  1.78034e-01  9.41668e-02  2.62732e-01
21Feb13_013054|   8.78408e-01  2.48648e-01  1.21791e+00  4.85344e-01]
21Feb13_013054| [-5.31246e-01 -1.52761e-01  2.84841e-01 -2.19881e-01 -5.37130e-01
21Feb13_013054|  -5.76407e-01  9.54226e-01  4.85366e-01 -9.77571e-01]
21Feb13_013054| [-1.35084e+00  1.09906e+00 -6.32061e-01  1.77342e-01 -6.40846e-01
21Feb13_013054|  -3.03854e-02  1.66807e+00  3.12194e-02 -3.53426e-01]
21Feb13_013054| [ 9.50869e-01 -3.62129e-01  2.98314e-01  4.91118e-01 -1.57990e+00
21Feb13_013054|  -2.44973e+00  8.00915e-01  7.10599e-04  8.10353e-01]
21Feb13_013054| [ 1.78432e+00 -9.71843e-01 -1.97505e+00 -1.18986e+00 -2.70454e-01
21Feb13_013054|  -1.30340e+00  7.99598e-01 -2.84399e-01  2.78754e-01]
21Feb13_013054| [-6.25690e-01 -1.36899e+00 -1.69985e-01 -6.67490e-01 -1.83927e+00
21Feb13_013054|   7.29422e-01 -1.91879e+00  9.93721e-01  1.24720e-01]
21Feb13_013054| [-6.63423e-02 -1.59385e+00  1.31061e+00 -5.23944e-01 -9.22575e-01
21Feb13_013054|   1.02268e-01  4.40389e-01  7.93366e-01  8.34624e-01]
21Feb13_013054| [-3.15115e-01 -8.73738e-01  2.06436e-01 -4.60182e-01  3.67394e-01
21Feb13_013054|   8.74019e-01 -1.00027e+00 -7.35157e-01 -6.67303e-01]
21Feb13_013054| [ 2.59118e-01  1.24828e+00 -4.10084e-01  3.25478e-01 -1.34056e+00
21Feb13_013054|  -2.04943e+00 -8.99572e-02  1.63028e+00  5.09953e-01]
21Feb13_013054| [ 1.17609e-02 -8.36465e-01 -8.15524e-02  3.43689e-01 -9.21088e-01
21Feb13_013054|  -1.89687e+00 -1.24788e+00  1.11545e+00  9.05282e-01]
21Feb13_013054| [-1.50660e+00  6.36055e-01 -3.71286e-02  4.62230e-01  8.44458e-01
21Feb13_013054|  -1.52079e+00 -7.16504e-01  7.07441e-02 -1.03582e+00]
21Feb13_013054| [-3.32525e-02 -5.49366e-01  7.30336e-01  1.55130e+00  1.87862e+00
21Feb13_013054|   5.59851e-01  1.58186e+00  4.62385e-01  7.76501e-01]
21Feb13_013054| [-2.09596e+00  1.33953e+00 -1.51561e+00 -1.25216e+00 -1.00343e+00
21Feb13_013054|  -5.75715e-01  8.79691e-01 -1.53243e+00 -3.80041e-01]
21Feb13_013054| [ 1.61185e-01  5.12300e-01  1.59935e+00  1.06339e+00  7.93391e-01
21Feb13_013054|   2.53927e+00 -1.61466e+00 -1.69022e+00 -2.02367e-01]
21Feb13_013054| [-1.25470e+00 -2.58098e-01  5.92567e-01  3.37381e-01 -6.99700e-01
21Feb13_013054|   9.24420e-01  9.48337e-01 -8.98604e-01  9.35058e-01]
21Feb13_013054| [ 1.43861e+00  1.42065e+00 -9.84910e-01 -8.21470e-01 -5.79001e-02
21Feb13_013054|   6.47525e-01  8.65842e-01 -1.50544e-01 -5.53358e-01]
21Feb13_013054| [-6.20387e-01 -2.38812e-02 -1.35219e-01 -2.58836e-01 -1.37737e+00
21Feb13_013054|   5.90991e-01 -2.13963e-01 -1.42807e+00 -1.91510e-01]
21Feb13_013054| [-9.48377e-01  1.45005e+00  6.23528e-01  9.24684e-01  8.68100e-01
21Feb13_013054|  -1.99460e+00  4.72527e-01  1.81921e+00 -1.50210e-01]
21Feb13_013054| [ 5.42301e-01  2.45411e-01  1.22571e+00 -1.22660e+00  2.00326e+00
21Feb13_013054|   1.28311e+00 -4.79063e-01 -1.26853e+00  3.54082e-01]
21Feb13_013054| [-9.68448e-02 -9.53055e-01 -6.39710e-01  7.39744e-02 -3.14837e-01
21Feb13_013054|  -4.64567e-01  8.27918e-01 -1.06114e+00 -5.10970e-01]
21Feb13_013054| [ 2.33279e-01  7.22497e-01  9.49373e-01 -1.20131e+00 -8.38683e-01
21Feb13_013054|  -5.38987e-01 -2.01753e+00  1.18580e+00 -7.12282e-01]
21Feb13_013054| [ 1.38078e+00 -3.07472e-01 -9.41548e-01  2.12287e+00  7.20946e-01
21Feb13_013054|   4.38905e-01  1.23216e+00  1.01939e+00  1.80698e-01]
21Feb13_013054| [-1.45026e-01  1.94626e+00 -1.81820e+00  1.49784e+00  7.71685e-01
21Feb13_013054|   1.57506e-01 -7.09054e-01 -3.76284e-02 -6.77940e-01]
21Feb13_013054| [-8.93030e-01  4.45952e-01 -5.02934e-01 -1.64437e+00  2.79315e-01
21Feb13_013054|  -1.03096e+00 -1.36068e+00 -4.50048e-01  2.88074e-01]]
21Feb13_013054|-- Bias --
21Feb13_013054|[ 0.37717  0.47788 -0.06014 -0.50820  0.52122 -0.91124 -1.67126 -0.64210
21Feb13_013054| -0.07185]
21Feb13_013054|Layer 1:
21Feb13_013054|-- Config --
21Feb13_013054|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 9], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_013054|-- Weights --
21Feb13_013054|[[ 0.68231 -0.74250]
21Feb13_013054| [ 0.62314  1.42898]
21Feb13_013054| [ 2.01695  1.97734]
21Feb13_013054| [-0.39663 -0.22189]
21Feb13_013054| [ 0.44922  0.41110]
21Feb13_013054| [ 0.33786  0.12545]
21Feb13_013054| [ 0.50773  1.87586]
21Feb13_013054| [-1.32230 -0.68529]
21Feb13_013054| [-0.06485  1.23686]]
21Feb13_013054|-- Bias --
21Feb13_013054|[-0.71772 -0.40861]
21Feb13_013054|Predicting the validation and test data with the Best final individual.
21Feb13_013101| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_013101|-----------  ------------------  --------------------  ----------
21Feb13_013101|Validation         41.83                  9             0.01032
21Feb13_013101|   Test            36.32                  9             0.00596
21Feb13_013101|-------------------- Test #8 --------------------
21Feb13_013101|Best final individual weights
21Feb13_013101|Individual:
21Feb13_013101|-- Constant hidden layers --
21Feb13_013101|False
21Feb13_013101|Layer 0:
21Feb13_013101|-- Config --
21Feb13_013101|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 9, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_013101|-- Weights --
21Feb13_013101|[[-4.61006e-01  6.85931e-01 -1.53413e+00  3.18540e-01  1.65279e+00
21Feb13_013101|  -3.98052e-01  4.33508e-01 -6.92513e-01  3.42704e-01]
21Feb13_013101| [-1.09470e+00  9.32382e-01  7.25102e-01 -4.91678e-01  1.53894e+00
21Feb13_013101|   6.32892e-01  1.66659e+00 -1.21771e+00 -3.90783e-01]
21Feb13_013101| [ 9.03759e-01 -9.77900e-01  1.77765e+00 -2.07879e-01 -3.69959e-01
21Feb13_013101|   2.57340e-02  9.32038e-01  1.80456e+00  3.87273e-01]
21Feb13_013101| [-3.49696e-01 -3.58058e-03 -6.07396e-01 -1.37181e+00 -1.10504e+00
21Feb13_013101|  -1.11474e+00 -1.03332e+00  2.23341e-01 -4.72876e-01]
21Feb13_013101| [ 2.32707e-01 -1.07579e+00 -5.40875e-01  1.42954e+00  6.10975e-01
21Feb13_013101|   5.59004e-01 -5.83178e-01  1.52584e+00 -2.61616e-02]
21Feb13_013101| [ 2.60802e-01  1.01484e+00 -3.13035e-03  3.59113e-01 -5.42962e-02
21Feb13_013101|   1.30419e-01 -1.43042e+00  3.06781e-01  4.02528e-01]
21Feb13_013101| [ 3.31900e-01 -7.68883e-01  2.16435e+00  5.44727e-01 -7.94370e-01
21Feb13_013101|   4.13300e-01  8.17497e-01  8.49172e-01  3.89172e-01]
21Feb13_013101| [-1.74100e+00 -1.34439e+00 -1.72034e-01  5.54274e-01  4.11878e-03
21Feb13_013101|  -1.72138e+00  1.21996e+00 -2.14134e-01 -1.29167e-01]
21Feb13_013101| [ 1.02404e+00  6.15020e-02 -2.14163e-01  3.45452e-02  5.64308e-01
21Feb13_013101|   1.23836e-01 -7.85150e-01 -2.34675e-01 -6.19357e-01]
21Feb13_013101| [ 3.39580e-01 -9.02752e-01 -1.40731e+00  1.01083e+00 -1.27692e+00
21Feb13_013101|  -3.87978e-01  2.91565e-01  7.80658e-01 -4.54186e-01]
21Feb13_013101| [-6.53637e-01  3.40165e-01  6.43150e-01 -4.23568e-01 -2.78934e-01
21Feb13_013101|  -9.34614e-02 -6.67337e-01  4.52195e-01  1.32123e+00]
21Feb13_013101| [-1.27502e+00  1.02666e+00 -4.87675e-01  8.02112e-01  2.39068e-01
21Feb13_013101|  -4.86850e-01  1.73530e+00 -1.15809e-01 -3.03472e-02]
21Feb13_013101| [-5.53044e-01  4.66997e-01  8.50262e-01 -9.72246e-01  5.75977e-01
21Feb13_013101|  -8.30986e-01  6.72198e-01 -1.48566e+00 -4.40186e-01]
21Feb13_013101| [ 1.56239e+00  4.89175e-02  3.52725e-01 -5.84369e-01  3.78056e-01
21Feb13_013101|  -1.08095e+00  2.25579e-01  1.36469e+00  1.05927e-01]
21Feb13_013101| [ 5.87912e-01 -6.66494e-01  7.79087e-01 -1.37734e+00 -5.68017e-02
21Feb13_013101|  -5.28526e-01 -2.16139e-01 -1.39364e-01 -1.22582e-01]
21Feb13_013101| [-3.25557e-01  7.27112e-02 -9.80921e-01  1.85031e-02 -2.87431e-01
21Feb13_013101|   1.76187e+00  1.29272e+00 -2.15986e+00 -3.48111e-02]
21Feb13_013101| [ 2.43878e-01  5.55203e-02  1.46280e+00 -6.81342e-01  6.28102e-01
21Feb13_013101|   7.31779e-01 -1.31015e+00  8.71093e-01 -4.54700e-01]
21Feb13_013101| [ 4.93144e-01  7.54375e-02 -1.20005e+00  6.27631e-02  7.82145e-01
21Feb13_013101|   5.33649e-01 -1.13427e+00  8.26364e-01 -1.48796e-01]
21Feb13_013101| [-4.21426e-01 -1.29212e-01 -8.75548e-01 -7.62601e-01 -5.40266e-01
21Feb13_013101|   1.80516e+00 -1.24863e+00  1.35354e+00 -3.30202e-02]
21Feb13_013101| [ 3.22391e-01 -5.16648e-01  1.97275e+00  3.26675e-01 -1.58735e-01
21Feb13_013101|  -1.86724e-01  3.96522e-01  6.89546e-01 -9.39432e-01]
21Feb13_013101| [-4.67129e-01  2.15586e+00 -5.38287e-01  2.78568e-01  9.42587e-01
21Feb13_013101|  -2.77032e-01  1.25393e+00  3.81716e-01  8.82734e-01]
21Feb13_013101| [-1.41583e+00 -1.45012e-01 -7.99630e-01 -5.31952e-01 -1.19693e+00
21Feb13_013101|   7.92286e-01  1.30639e-01 -2.37138e-01 -1.58410e+00]
21Feb13_013101| [-1.16444e+00 -5.22290e-01  1.02540e+00  3.99299e-01 -9.33985e-01
21Feb13_013101|   2.16709e+00  3.01229e-01 -7.56401e-01  1.21738e+00]
21Feb13_013101| [-4.96242e-01  1.99264e+00  1.72242e+00 -7.33992e-01  1.79053e+00
21Feb13_013101|   7.69467e-01  4.32490e-01  8.00370e-02 -1.48974e-01]
21Feb13_013101| [ 9.93945e-02 -1.39770e+00  2.13769e-01  1.86767e+00  1.11288e+00
21Feb13_013101|   6.22801e-01  3.99123e-01  6.84795e-01  2.17178e-01]
21Feb13_013101| [ 1.35578e+00  8.00580e-01  3.99488e-01  4.40513e-01  1.93473e-02
21Feb13_013101|  -4.51602e-01  2.87170e-01  3.29084e-02 -1.36035e+00]
21Feb13_013101| [-1.09101e+00  2.48048e+00  5.80244e-01 -1.33268e-01 -5.28168e-01
21Feb13_013101|   8.09824e-01 -4.30853e-01 -2.55311e-02  1.50016e+00]
21Feb13_013101| [ 5.18298e-02 -2.30052e-01  1.28184e+00 -2.64124e+00  3.01962e-01
21Feb13_013101|   1.55697e+00 -1.20762e+00  6.34586e-01 -1.58188e-01]
21Feb13_013101| [-1.72551e+00  1.63754e+00 -4.70755e-01 -1.15326e+00 -8.33712e-01
21Feb13_013101|   1.31472e+00  2.01820e-01 -2.33652e-01  2.10201e-01]
21Feb13_013101| [ 1.47803e-01  1.06813e-01 -7.00830e-02 -1.17159e+00 -1.10268e+00
21Feb13_013101|  -8.43557e-01  4.82005e-01  1.25841e+00  4.90572e-02]
21Feb13_013101| [-4.14468e-01 -9.13217e-01  1.43297e+00 -2.20598e-01 -5.00413e-02
21Feb13_013101|   1.00790e+00 -1.44685e+00  1.08882e-02  4.97447e-02]
21Feb13_013101| [ 8.57554e-01  1.16591e+00 -1.34007e-01  1.71257e+00 -1.12961e+00
21Feb13_013101|   1.37418e+00 -1.22028e+00 -6.84918e-01  7.78660e-01]
21Feb13_013101| [-7.13839e-01  1.40966e+00 -4.77517e-01 -1.19630e+00 -1.15371e+00
21Feb13_013101|  -3.93636e-01  3.23964e-01 -6.64234e-01  1.21979e+00]
21Feb13_013101| [ 1.74382e+00  1.33485e+00  1.78034e-01  9.41668e-02  2.62732e-01
21Feb13_013101|   8.78408e-01  2.48648e-01  1.21791e+00  4.85344e-01]
21Feb13_013101| [-5.31246e-01 -1.52761e-01  2.84841e-01 -2.19881e-01 -5.37130e-01
21Feb13_013101|  -5.76407e-01  9.54226e-01  4.85366e-01 -9.77571e-01]
21Feb13_013101| [-1.35084e+00  1.09906e+00 -6.32061e-01  1.77342e-01 -6.40846e-01
21Feb13_013101|  -3.03854e-02  1.66807e+00  3.12194e-02 -3.53426e-01]
21Feb13_013101| [ 9.50869e-01 -3.62129e-01  2.98314e-01  4.91118e-01 -1.57990e+00
21Feb13_013101|  -2.44973e+00  8.00915e-01  7.10599e-04  8.10353e-01]
21Feb13_013101| [ 1.78432e+00 -9.71843e-01 -1.97505e+00 -1.18986e+00 -2.70454e-01
21Feb13_013101|  -1.30340e+00  7.99598e-01 -2.84399e-01  2.78754e-01]
21Feb13_013101| [-6.25690e-01 -1.36899e+00 -1.69985e-01 -6.67490e-01 -1.83927e+00
21Feb13_013101|   7.29422e-01 -1.91879e+00  9.93721e-01  1.24720e-01]
21Feb13_013101| [-6.63423e-02 -1.59385e+00  1.31061e+00 -5.23944e-01 -9.22575e-01
21Feb13_013101|   1.02268e-01  4.40389e-01  7.93366e-01  8.34624e-01]
21Feb13_013101| [-3.15115e-01 -8.73738e-01  2.06436e-01 -4.60182e-01  3.67394e-01
21Feb13_013101|   8.74019e-01 -1.00027e+00 -7.35157e-01 -6.67303e-01]
21Feb13_013101| [ 2.59118e-01  1.24828e+00 -4.10084e-01  3.25478e-01 -1.34056e+00
21Feb13_013101|  -2.04943e+00 -8.99572e-02  1.63028e+00  5.09953e-01]
21Feb13_013101| [ 1.17609e-02 -8.36465e-01 -8.15524e-02  3.43689e-01 -9.21088e-01
21Feb13_013101|  -1.89687e+00 -1.24788e+00  1.11545e+00  9.05282e-01]
21Feb13_013101| [-1.50660e+00  6.36055e-01 -3.71286e-02  4.62230e-01  8.44458e-01
21Feb13_013101|  -1.52079e+00 -7.16504e-01  7.07441e-02 -1.03582e+00]
21Feb13_013101| [-3.32525e-02 -5.49366e-01  7.30336e-01  1.55130e+00  1.87862e+00
21Feb13_013101|   5.59851e-01  1.58186e+00  4.62385e-01  7.76501e-01]
21Feb13_013101| [-2.09596e+00  1.33953e+00 -1.51561e+00 -1.25216e+00 -1.00343e+00
21Feb13_013101|  -5.75715e-01  8.79691e-01 -1.53243e+00 -3.80041e-01]
21Feb13_013101| [ 1.61185e-01  5.12300e-01  1.59935e+00  1.06339e+00  7.93391e-01
21Feb13_013101|   2.53927e+00 -1.61466e+00 -1.69022e+00 -2.02367e-01]
21Feb13_013101| [-1.25470e+00 -2.58098e-01  5.92567e-01  3.37381e-01 -6.99700e-01
21Feb13_013101|   9.24420e-01  9.48337e-01 -8.98604e-01  9.35058e-01]
21Feb13_013101| [ 1.43861e+00  1.42065e+00 -9.84910e-01 -8.21470e-01 -5.79001e-02
21Feb13_013101|   6.47525e-01  8.65842e-01 -1.50544e-01 -5.53358e-01]
21Feb13_013101| [-6.20387e-01 -2.38812e-02 -1.35219e-01 -2.58836e-01 -1.37737e+00
21Feb13_013101|   5.90991e-01 -2.13963e-01 -1.42807e+00 -1.91510e-01]
21Feb13_013101| [-9.48377e-01  1.45005e+00  6.23528e-01  9.24684e-01  8.68100e-01
21Feb13_013101|  -1.99460e+00  4.72527e-01  1.81921e+00 -1.50210e-01]
21Feb13_013101| [ 5.42301e-01  2.45411e-01  1.22571e+00 -1.22660e+00  2.00326e+00
21Feb13_013101|   1.28311e+00 -4.79063e-01 -1.26853e+00  3.54082e-01]
21Feb13_013101| [-9.68448e-02 -9.53055e-01 -6.39710e-01  7.39744e-02 -3.14837e-01
21Feb13_013101|  -4.64567e-01  8.27918e-01 -1.06114e+00 -5.10970e-01]
21Feb13_013101| [ 2.33279e-01  7.22497e-01  9.49373e-01 -1.20131e+00 -8.38683e-01
21Feb13_013101|  -5.38987e-01 -2.01753e+00  1.18580e+00 -7.12282e-01]
21Feb13_013101| [ 1.38078e+00 -3.07472e-01 -9.41548e-01  2.12287e+00  7.20946e-01
21Feb13_013101|   4.38905e-01  1.23216e+00  1.01939e+00  1.80698e-01]
21Feb13_013101| [-1.45026e-01  1.94626e+00 -1.81820e+00  1.49784e+00  7.71685e-01
21Feb13_013101|   1.57506e-01 -7.09054e-01 -3.76284e-02 -6.77940e-01]
21Feb13_013101| [-8.93030e-01  4.45952e-01 -5.02934e-01 -1.64437e+00  2.79315e-01
21Feb13_013101|  -1.03096e+00 -1.36068e+00 -4.50048e-01  2.88074e-01]]
21Feb13_013101|-- Bias --
21Feb13_013101|[ 0.37717  0.47788 -0.06014 -0.50820  0.52122 -0.91124 -1.67126 -0.64210
21Feb13_013101| -0.07185]
21Feb13_013101|Layer 1:
21Feb13_013101|-- Config --
21Feb13_013101|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 9], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_013101|-- Weights --
21Feb13_013101|[[ 0.68231 -0.74250]
21Feb13_013101| [ 0.62314  1.42898]
21Feb13_013101| [ 2.01695  1.97734]
21Feb13_013101| [-0.39663 -0.22189]
21Feb13_013101| [ 0.44922  0.41110]
21Feb13_013101| [ 0.33786  0.12545]
21Feb13_013101| [ 0.50773  1.87586]
21Feb13_013101| [-1.32230 -0.68529]
21Feb13_013101| [-0.06485  1.23686]]
21Feb13_013101|-- Bias --
21Feb13_013101|[-0.71772 -0.40861]
21Feb13_013101|Predicting the validation and test data with the Best final individual.
21Feb13_013108| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_013108|-----------  ------------------  --------------------  ----------
21Feb13_013108|Validation         41.39                  9             0.01805
21Feb13_013108|   Test            36.40                  9             0.00298
21Feb13_013108|-------------------- Test #9 --------------------
21Feb13_013108|Best final individual weights
21Feb13_013108|Individual:
21Feb13_013108|-- Constant hidden layers --
21Feb13_013108|False
21Feb13_013108|Layer 0:
21Feb13_013108|-- Config --
21Feb13_013108|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 9, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_013108|-- Weights --
21Feb13_013108|[[-4.61006e-01  6.85931e-01 -1.53413e+00  3.18540e-01  1.65279e+00
21Feb13_013108|  -3.98052e-01  4.33508e-01 -6.92513e-01  3.42704e-01]
21Feb13_013108| [-1.09470e+00  9.32382e-01  7.25102e-01 -4.91678e-01  1.53894e+00
21Feb13_013108|   6.32892e-01  1.66659e+00 -1.21771e+00 -3.90783e-01]
21Feb13_013108| [ 9.03759e-01 -9.77900e-01  1.77765e+00 -2.07879e-01 -3.69959e-01
21Feb13_013108|   2.57340e-02  9.32038e-01  1.80456e+00  3.87273e-01]
21Feb13_013108| [-3.49696e-01 -3.58058e-03 -6.07396e-01 -1.37181e+00 -1.10504e+00
21Feb13_013108|  -1.11474e+00 -1.03332e+00  2.23341e-01 -4.72876e-01]
21Feb13_013108| [ 2.32707e-01 -1.07579e+00 -5.40875e-01  1.42954e+00  6.10975e-01
21Feb13_013108|   5.59004e-01 -5.83178e-01  1.52584e+00 -2.61616e-02]
21Feb13_013108| [ 2.60802e-01  1.01484e+00 -3.13035e-03  3.59113e-01 -5.42962e-02
21Feb13_013108|   1.30419e-01 -1.43042e+00  3.06781e-01  4.02528e-01]
21Feb13_013108| [ 3.31900e-01 -7.68883e-01  2.16435e+00  5.44727e-01 -7.94370e-01
21Feb13_013108|   4.13300e-01  8.17497e-01  8.49172e-01  3.89172e-01]
21Feb13_013108| [-1.74100e+00 -1.34439e+00 -1.72034e-01  5.54274e-01  4.11878e-03
21Feb13_013108|  -1.72138e+00  1.21996e+00 -2.14134e-01 -1.29167e-01]
21Feb13_013108| [ 1.02404e+00  6.15020e-02 -2.14163e-01  3.45452e-02  5.64308e-01
21Feb13_013108|   1.23836e-01 -7.85150e-01 -2.34675e-01 -6.19357e-01]
21Feb13_013108| [ 3.39580e-01 -9.02752e-01 -1.40731e+00  1.01083e+00 -1.27692e+00
21Feb13_013108|  -3.87978e-01  2.91565e-01  7.80658e-01 -4.54186e-01]
21Feb13_013108| [-6.53637e-01  3.40165e-01  6.43150e-01 -4.23568e-01 -2.78934e-01
21Feb13_013108|  -9.34614e-02 -6.67337e-01  4.52195e-01  1.32123e+00]
21Feb13_013108| [-1.27502e+00  1.02666e+00 -4.87675e-01  8.02112e-01  2.39068e-01
21Feb13_013108|  -4.86850e-01  1.73530e+00 -1.15809e-01 -3.03472e-02]
21Feb13_013108| [-5.53044e-01  4.66997e-01  8.50262e-01 -9.72246e-01  5.75977e-01
21Feb13_013108|  -8.30986e-01  6.72198e-01 -1.48566e+00 -4.40186e-01]
21Feb13_013108| [ 1.56239e+00  4.89175e-02  3.52725e-01 -5.84369e-01  3.78056e-01
21Feb13_013108|  -1.08095e+00  2.25579e-01  1.36469e+00  1.05927e-01]
21Feb13_013108| [ 5.87912e-01 -6.66494e-01  7.79087e-01 -1.37734e+00 -5.68017e-02
21Feb13_013108|  -5.28526e-01 -2.16139e-01 -1.39364e-01 -1.22582e-01]
21Feb13_013108| [-3.25557e-01  7.27112e-02 -9.80921e-01  1.85031e-02 -2.87431e-01
21Feb13_013108|   1.76187e+00  1.29272e+00 -2.15986e+00 -3.48111e-02]
21Feb13_013108| [ 2.43878e-01  5.55203e-02  1.46280e+00 -6.81342e-01  6.28102e-01
21Feb13_013108|   7.31779e-01 -1.31015e+00  8.71093e-01 -4.54700e-01]
21Feb13_013108| [ 4.93144e-01  7.54375e-02 -1.20005e+00  6.27631e-02  7.82145e-01
21Feb13_013108|   5.33649e-01 -1.13427e+00  8.26364e-01 -1.48796e-01]
21Feb13_013108| [-4.21426e-01 -1.29212e-01 -8.75548e-01 -7.62601e-01 -5.40266e-01
21Feb13_013108|   1.80516e+00 -1.24863e+00  1.35354e+00 -3.30202e-02]
21Feb13_013108| [ 3.22391e-01 -5.16648e-01  1.97275e+00  3.26675e-01 -1.58735e-01
21Feb13_013108|  -1.86724e-01  3.96522e-01  6.89546e-01 -9.39432e-01]
21Feb13_013108| [-4.67129e-01  2.15586e+00 -5.38287e-01  2.78568e-01  9.42587e-01
21Feb13_013108|  -2.77032e-01  1.25393e+00  3.81716e-01  8.82734e-01]
21Feb13_013108| [-1.41583e+00 -1.45012e-01 -7.99630e-01 -5.31952e-01 -1.19693e+00
21Feb13_013108|   7.92286e-01  1.30639e-01 -2.37138e-01 -1.58410e+00]
21Feb13_013108| [-1.16444e+00 -5.22290e-01  1.02540e+00  3.99299e-01 -9.33985e-01
21Feb13_013108|   2.16709e+00  3.01229e-01 -7.56401e-01  1.21738e+00]
21Feb13_013108| [-4.96242e-01  1.99264e+00  1.72242e+00 -7.33992e-01  1.79053e+00
21Feb13_013108|   7.69467e-01  4.32490e-01  8.00370e-02 -1.48974e-01]
21Feb13_013108| [ 9.93945e-02 -1.39770e+00  2.13769e-01  1.86767e+00  1.11288e+00
21Feb13_013108|   6.22801e-01  3.99123e-01  6.84795e-01  2.17178e-01]
21Feb13_013108| [ 1.35578e+00  8.00580e-01  3.99488e-01  4.40513e-01  1.93473e-02
21Feb13_013108|  -4.51602e-01  2.87170e-01  3.29084e-02 -1.36035e+00]
21Feb13_013108| [-1.09101e+00  2.48048e+00  5.80244e-01 -1.33268e-01 -5.28168e-01
21Feb13_013108|   8.09824e-01 -4.30853e-01 -2.55311e-02  1.50016e+00]
21Feb13_013108| [ 5.18298e-02 -2.30052e-01  1.28184e+00 -2.64124e+00  3.01962e-01
21Feb13_013108|   1.55697e+00 -1.20762e+00  6.34586e-01 -1.58188e-01]
21Feb13_013108| [-1.72551e+00  1.63754e+00 -4.70755e-01 -1.15326e+00 -8.33712e-01
21Feb13_013108|   1.31472e+00  2.01820e-01 -2.33652e-01  2.10201e-01]
21Feb13_013108| [ 1.47803e-01  1.06813e-01 -7.00830e-02 -1.17159e+00 -1.10268e+00
21Feb13_013108|  -8.43557e-01  4.82005e-01  1.25841e+00  4.90572e-02]
21Feb13_013108| [-4.14468e-01 -9.13217e-01  1.43297e+00 -2.20598e-01 -5.00413e-02
21Feb13_013108|   1.00790e+00 -1.44685e+00  1.08882e-02  4.97447e-02]
21Feb13_013108| [ 8.57554e-01  1.16591e+00 -1.34007e-01  1.71257e+00 -1.12961e+00
21Feb13_013108|   1.37418e+00 -1.22028e+00 -6.84918e-01  7.78660e-01]
21Feb13_013108| [-7.13839e-01  1.40966e+00 -4.77517e-01 -1.19630e+00 -1.15371e+00
21Feb13_013108|  -3.93636e-01  3.23964e-01 -6.64234e-01  1.21979e+00]
21Feb13_013108| [ 1.74382e+00  1.33485e+00  1.78034e-01  9.41668e-02  2.62732e-01
21Feb13_013108|   8.78408e-01  2.48648e-01  1.21791e+00  4.85344e-01]
21Feb13_013108| [-5.31246e-01 -1.52761e-01  2.84841e-01 -2.19881e-01 -5.37130e-01
21Feb13_013108|  -5.76407e-01  9.54226e-01  4.85366e-01 -9.77571e-01]
21Feb13_013108| [-1.35084e+00  1.09906e+00 -6.32061e-01  1.77342e-01 -6.40846e-01
21Feb13_013108|  -3.03854e-02  1.66807e+00  3.12194e-02 -3.53426e-01]
21Feb13_013108| [ 9.50869e-01 -3.62129e-01  2.98314e-01  4.91118e-01 -1.57990e+00
21Feb13_013108|  -2.44973e+00  8.00915e-01  7.10599e-04  8.10353e-01]
21Feb13_013108| [ 1.78432e+00 -9.71843e-01 -1.97505e+00 -1.18986e+00 -2.70454e-01
21Feb13_013108|  -1.30340e+00  7.99598e-01 -2.84399e-01  2.78754e-01]
21Feb13_013108| [-6.25690e-01 -1.36899e+00 -1.69985e-01 -6.67490e-01 -1.83927e+00
21Feb13_013108|   7.29422e-01 -1.91879e+00  9.93721e-01  1.24720e-01]
21Feb13_013108| [-6.63423e-02 -1.59385e+00  1.31061e+00 -5.23944e-01 -9.22575e-01
21Feb13_013108|   1.02268e-01  4.40389e-01  7.93366e-01  8.34624e-01]
21Feb13_013108| [-3.15115e-01 -8.73738e-01  2.06436e-01 -4.60182e-01  3.67394e-01
21Feb13_013108|   8.74019e-01 -1.00027e+00 -7.35157e-01 -6.67303e-01]
21Feb13_013108| [ 2.59118e-01  1.24828e+00 -4.10084e-01  3.25478e-01 -1.34056e+00
21Feb13_013108|  -2.04943e+00 -8.99572e-02  1.63028e+00  5.09953e-01]
21Feb13_013108| [ 1.17609e-02 -8.36465e-01 -8.15524e-02  3.43689e-01 -9.21088e-01
21Feb13_013108|  -1.89687e+00 -1.24788e+00  1.11545e+00  9.05282e-01]
21Feb13_013108| [-1.50660e+00  6.36055e-01 -3.71286e-02  4.62230e-01  8.44458e-01
21Feb13_013108|  -1.52079e+00 -7.16504e-01  7.07441e-02 -1.03582e+00]
21Feb13_013108| [-3.32525e-02 -5.49366e-01  7.30336e-01  1.55130e+00  1.87862e+00
21Feb13_013108|   5.59851e-01  1.58186e+00  4.62385e-01  7.76501e-01]
21Feb13_013108| [-2.09596e+00  1.33953e+00 -1.51561e+00 -1.25216e+00 -1.00343e+00
21Feb13_013108|  -5.75715e-01  8.79691e-01 -1.53243e+00 -3.80041e-01]
21Feb13_013108| [ 1.61185e-01  5.12300e-01  1.59935e+00  1.06339e+00  7.93391e-01
21Feb13_013108|   2.53927e+00 -1.61466e+00 -1.69022e+00 -2.02367e-01]
21Feb13_013108| [-1.25470e+00 -2.58098e-01  5.92567e-01  3.37381e-01 -6.99700e-01
21Feb13_013108|   9.24420e-01  9.48337e-01 -8.98604e-01  9.35058e-01]
21Feb13_013108| [ 1.43861e+00  1.42065e+00 -9.84910e-01 -8.21470e-01 -5.79001e-02
21Feb13_013108|   6.47525e-01  8.65842e-01 -1.50544e-01 -5.53358e-01]
21Feb13_013108| [-6.20387e-01 -2.38812e-02 -1.35219e-01 -2.58836e-01 -1.37737e+00
21Feb13_013108|   5.90991e-01 -2.13963e-01 -1.42807e+00 -1.91510e-01]
21Feb13_013108| [-9.48377e-01  1.45005e+00  6.23528e-01  9.24684e-01  8.68100e-01
21Feb13_013108|  -1.99460e+00  4.72527e-01  1.81921e+00 -1.50210e-01]
21Feb13_013108| [ 5.42301e-01  2.45411e-01  1.22571e+00 -1.22660e+00  2.00326e+00
21Feb13_013108|   1.28311e+00 -4.79063e-01 -1.26853e+00  3.54082e-01]
21Feb13_013108| [-9.68448e-02 -9.53055e-01 -6.39710e-01  7.39744e-02 -3.14837e-01
21Feb13_013108|  -4.64567e-01  8.27918e-01 -1.06114e+00 -5.10970e-01]
21Feb13_013108| [ 2.33279e-01  7.22497e-01  9.49373e-01 -1.20131e+00 -8.38683e-01
21Feb13_013108|  -5.38987e-01 -2.01753e+00  1.18580e+00 -7.12282e-01]
21Feb13_013108| [ 1.38078e+00 -3.07472e-01 -9.41548e-01  2.12287e+00  7.20946e-01
21Feb13_013108|   4.38905e-01  1.23216e+00  1.01939e+00  1.80698e-01]
21Feb13_013108| [-1.45026e-01  1.94626e+00 -1.81820e+00  1.49784e+00  7.71685e-01
21Feb13_013108|   1.57506e-01 -7.09054e-01 -3.76284e-02 -6.77940e-01]
21Feb13_013108| [-8.93030e-01  4.45952e-01 -5.02934e-01 -1.64437e+00  2.79315e-01
21Feb13_013108|  -1.03096e+00 -1.36068e+00 -4.50048e-01  2.88074e-01]]
21Feb13_013108|-- Bias --
21Feb13_013108|[ 0.37717  0.47788 -0.06014 -0.50820  0.52122 -0.91124 -1.67126 -0.64210
21Feb13_013108| -0.07185]
21Feb13_013108|Layer 1:
21Feb13_013108|-- Config --
21Feb13_013108|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 9], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_013108|-- Weights --
21Feb13_013108|[[ 0.68231 -0.74250]
21Feb13_013108| [ 0.62314  1.42898]
21Feb13_013108| [ 2.01695  1.97734]
21Feb13_013108| [-0.39663 -0.22189]
21Feb13_013108| [ 0.44922  0.41110]
21Feb13_013108| [ 0.33786  0.12545]
21Feb13_013108| [ 0.50773  1.87586]
21Feb13_013108| [-1.32230 -0.68529]
21Feb13_013108| [-0.06485  1.23686]]
21Feb13_013108|-- Bias --
21Feb13_013108|[-0.71772 -0.40861]
21Feb13_013108|Predicting the validation and test data with the Best final individual.
21Feb13_013115| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_013115|-----------  ------------------  --------------------  ----------
21Feb13_013115|Validation         41.74                  9             0.00775
21Feb13_013115|   Test            36.32                  9             0.00596
21Feb13_013115|-------------------- Test #10 --------------------
21Feb13_013115|Best final individual weights
21Feb13_013115|Individual:
21Feb13_013115|-- Constant hidden layers --
21Feb13_013115|False
21Feb13_013115|Layer 0:
21Feb13_013115|-- Config --
21Feb13_013115|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 9, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_013115|-- Weights --
21Feb13_013115|[[-4.61006e-01  6.85931e-01 -1.53413e+00  3.18540e-01  1.65279e+00
21Feb13_013115|  -3.98052e-01  4.33508e-01 -6.92513e-01  3.42704e-01]
21Feb13_013115| [-1.09470e+00  9.32382e-01  7.25102e-01 -4.91678e-01  1.53894e+00
21Feb13_013115|   6.32892e-01  1.66659e+00 -1.21771e+00 -3.90783e-01]
21Feb13_013115| [ 9.03759e-01 -9.77900e-01  1.77765e+00 -2.07879e-01 -3.69959e-01
21Feb13_013115|   2.57340e-02  9.32038e-01  1.80456e+00  3.87273e-01]
21Feb13_013115| [-3.49696e-01 -3.58058e-03 -6.07396e-01 -1.37181e+00 -1.10504e+00
21Feb13_013115|  -1.11474e+00 -1.03332e+00  2.23341e-01 -4.72876e-01]
21Feb13_013115| [ 2.32707e-01 -1.07579e+00 -5.40875e-01  1.42954e+00  6.10975e-01
21Feb13_013115|   5.59004e-01 -5.83178e-01  1.52584e+00 -2.61616e-02]
21Feb13_013115| [ 2.60802e-01  1.01484e+00 -3.13035e-03  3.59113e-01 -5.42962e-02
21Feb13_013115|   1.30419e-01 -1.43042e+00  3.06781e-01  4.02528e-01]
21Feb13_013115| [ 3.31900e-01 -7.68883e-01  2.16435e+00  5.44727e-01 -7.94370e-01
21Feb13_013115|   4.13300e-01  8.17497e-01  8.49172e-01  3.89172e-01]
21Feb13_013115| [-1.74100e+00 -1.34439e+00 -1.72034e-01  5.54274e-01  4.11878e-03
21Feb13_013115|  -1.72138e+00  1.21996e+00 -2.14134e-01 -1.29167e-01]
21Feb13_013115| [ 1.02404e+00  6.15020e-02 -2.14163e-01  3.45452e-02  5.64308e-01
21Feb13_013115|   1.23836e-01 -7.85150e-01 -2.34675e-01 -6.19357e-01]
21Feb13_013115| [ 3.39580e-01 -9.02752e-01 -1.40731e+00  1.01083e+00 -1.27692e+00
21Feb13_013115|  -3.87978e-01  2.91565e-01  7.80658e-01 -4.54186e-01]
21Feb13_013115| [-6.53637e-01  3.40165e-01  6.43150e-01 -4.23568e-01 -2.78934e-01
21Feb13_013115|  -9.34614e-02 -6.67337e-01  4.52195e-01  1.32123e+00]
21Feb13_013115| [-1.27502e+00  1.02666e+00 -4.87675e-01  8.02112e-01  2.39068e-01
21Feb13_013115|  -4.86850e-01  1.73530e+00 -1.15809e-01 -3.03472e-02]
21Feb13_013115| [-5.53044e-01  4.66997e-01  8.50262e-01 -9.72246e-01  5.75977e-01
21Feb13_013115|  -8.30986e-01  6.72198e-01 -1.48566e+00 -4.40186e-01]
21Feb13_013115| [ 1.56239e+00  4.89175e-02  3.52725e-01 -5.84369e-01  3.78056e-01
21Feb13_013115|  -1.08095e+00  2.25579e-01  1.36469e+00  1.05927e-01]
21Feb13_013115| [ 5.87912e-01 -6.66494e-01  7.79087e-01 -1.37734e+00 -5.68017e-02
21Feb13_013115|  -5.28526e-01 -2.16139e-01 -1.39364e-01 -1.22582e-01]
21Feb13_013115| [-3.25557e-01  7.27112e-02 -9.80921e-01  1.85031e-02 -2.87431e-01
21Feb13_013115|   1.76187e+00  1.29272e+00 -2.15986e+00 -3.48111e-02]
21Feb13_013115| [ 2.43878e-01  5.55203e-02  1.46280e+00 -6.81342e-01  6.28102e-01
21Feb13_013115|   7.31779e-01 -1.31015e+00  8.71093e-01 -4.54700e-01]
21Feb13_013115| [ 4.93144e-01  7.54375e-02 -1.20005e+00  6.27631e-02  7.82145e-01
21Feb13_013115|   5.33649e-01 -1.13427e+00  8.26364e-01 -1.48796e-01]
21Feb13_013115| [-4.21426e-01 -1.29212e-01 -8.75548e-01 -7.62601e-01 -5.40266e-01
21Feb13_013115|   1.80516e+00 -1.24863e+00  1.35354e+00 -3.30202e-02]
21Feb13_013115| [ 3.22391e-01 -5.16648e-01  1.97275e+00  3.26675e-01 -1.58735e-01
21Feb13_013115|  -1.86724e-01  3.96522e-01  6.89546e-01 -9.39432e-01]
21Feb13_013115| [-4.67129e-01  2.15586e+00 -5.38287e-01  2.78568e-01  9.42587e-01
21Feb13_013115|  -2.77032e-01  1.25393e+00  3.81716e-01  8.82734e-01]
21Feb13_013115| [-1.41583e+00 -1.45012e-01 -7.99630e-01 -5.31952e-01 -1.19693e+00
21Feb13_013115|   7.92286e-01  1.30639e-01 -2.37138e-01 -1.58410e+00]
21Feb13_013115| [-1.16444e+00 -5.22290e-01  1.02540e+00  3.99299e-01 -9.33985e-01
21Feb13_013115|   2.16709e+00  3.01229e-01 -7.56401e-01  1.21738e+00]
21Feb13_013115| [-4.96242e-01  1.99264e+00  1.72242e+00 -7.33992e-01  1.79053e+00
21Feb13_013115|   7.69467e-01  4.32490e-01  8.00370e-02 -1.48974e-01]
21Feb13_013115| [ 9.93945e-02 -1.39770e+00  2.13769e-01  1.86767e+00  1.11288e+00
21Feb13_013115|   6.22801e-01  3.99123e-01  6.84795e-01  2.17178e-01]
21Feb13_013115| [ 1.35578e+00  8.00580e-01  3.99488e-01  4.40513e-01  1.93473e-02
21Feb13_013115|  -4.51602e-01  2.87170e-01  3.29084e-02 -1.36035e+00]
21Feb13_013115| [-1.09101e+00  2.48048e+00  5.80244e-01 -1.33268e-01 -5.28168e-01
21Feb13_013115|   8.09824e-01 -4.30853e-01 -2.55311e-02  1.50016e+00]
21Feb13_013115| [ 5.18298e-02 -2.30052e-01  1.28184e+00 -2.64124e+00  3.01962e-01
21Feb13_013115|   1.55697e+00 -1.20762e+00  6.34586e-01 -1.58188e-01]
21Feb13_013115| [-1.72551e+00  1.63754e+00 -4.70755e-01 -1.15326e+00 -8.33712e-01
21Feb13_013115|   1.31472e+00  2.01820e-01 -2.33652e-01  2.10201e-01]
21Feb13_013115| [ 1.47803e-01  1.06813e-01 -7.00830e-02 -1.17159e+00 -1.10268e+00
21Feb13_013115|  -8.43557e-01  4.82005e-01  1.25841e+00  4.90572e-02]
21Feb13_013115| [-4.14468e-01 -9.13217e-01  1.43297e+00 -2.20598e-01 -5.00413e-02
21Feb13_013115|   1.00790e+00 -1.44685e+00  1.08882e-02  4.97447e-02]
21Feb13_013115| [ 8.57554e-01  1.16591e+00 -1.34007e-01  1.71257e+00 -1.12961e+00
21Feb13_013115|   1.37418e+00 -1.22028e+00 -6.84918e-01  7.78660e-01]
21Feb13_013115| [-7.13839e-01  1.40966e+00 -4.77517e-01 -1.19630e+00 -1.15371e+00
21Feb13_013115|  -3.93636e-01  3.23964e-01 -6.64234e-01  1.21979e+00]
21Feb13_013115| [ 1.74382e+00  1.33485e+00  1.78034e-01  9.41668e-02  2.62732e-01
21Feb13_013115|   8.78408e-01  2.48648e-01  1.21791e+00  4.85344e-01]
21Feb13_013115| [-5.31246e-01 -1.52761e-01  2.84841e-01 -2.19881e-01 -5.37130e-01
21Feb13_013115|  -5.76407e-01  9.54226e-01  4.85366e-01 -9.77571e-01]
21Feb13_013115| [-1.35084e+00  1.09906e+00 -6.32061e-01  1.77342e-01 -6.40846e-01
21Feb13_013115|  -3.03854e-02  1.66807e+00  3.12194e-02 -3.53426e-01]
21Feb13_013115| [ 9.50869e-01 -3.62129e-01  2.98314e-01  4.91118e-01 -1.57990e+00
21Feb13_013115|  -2.44973e+00  8.00915e-01  7.10599e-04  8.10353e-01]
21Feb13_013115| [ 1.78432e+00 -9.71843e-01 -1.97505e+00 -1.18986e+00 -2.70454e-01
21Feb13_013115|  -1.30340e+00  7.99598e-01 -2.84399e-01  2.78754e-01]
21Feb13_013115| [-6.25690e-01 -1.36899e+00 -1.69985e-01 -6.67490e-01 -1.83927e+00
21Feb13_013115|   7.29422e-01 -1.91879e+00  9.93721e-01  1.24720e-01]
21Feb13_013115| [-6.63423e-02 -1.59385e+00  1.31061e+00 -5.23944e-01 -9.22575e-01
21Feb13_013115|   1.02268e-01  4.40389e-01  7.93366e-01  8.34624e-01]
21Feb13_013115| [-3.15115e-01 -8.73738e-01  2.06436e-01 -4.60182e-01  3.67394e-01
21Feb13_013115|   8.74019e-01 -1.00027e+00 -7.35157e-01 -6.67303e-01]
21Feb13_013115| [ 2.59118e-01  1.24828e+00 -4.10084e-01  3.25478e-01 -1.34056e+00
21Feb13_013115|  -2.04943e+00 -8.99572e-02  1.63028e+00  5.09953e-01]
21Feb13_013115| [ 1.17609e-02 -8.36465e-01 -8.15524e-02  3.43689e-01 -9.21088e-01
21Feb13_013115|  -1.89687e+00 -1.24788e+00  1.11545e+00  9.05282e-01]
21Feb13_013115| [-1.50660e+00  6.36055e-01 -3.71286e-02  4.62230e-01  8.44458e-01
21Feb13_013115|  -1.52079e+00 -7.16504e-01  7.07441e-02 -1.03582e+00]
21Feb13_013115| [-3.32525e-02 -5.49366e-01  7.30336e-01  1.55130e+00  1.87862e+00
21Feb13_013115|   5.59851e-01  1.58186e+00  4.62385e-01  7.76501e-01]
21Feb13_013115| [-2.09596e+00  1.33953e+00 -1.51561e+00 -1.25216e+00 -1.00343e+00
21Feb13_013115|  -5.75715e-01  8.79691e-01 -1.53243e+00 -3.80041e-01]
21Feb13_013115| [ 1.61185e-01  5.12300e-01  1.59935e+00  1.06339e+00  7.93391e-01
21Feb13_013115|   2.53927e+00 -1.61466e+00 -1.69022e+00 -2.02367e-01]
21Feb13_013115| [-1.25470e+00 -2.58098e-01  5.92567e-01  3.37381e-01 -6.99700e-01
21Feb13_013115|   9.24420e-01  9.48337e-01 -8.98604e-01  9.35058e-01]
21Feb13_013115| [ 1.43861e+00  1.42065e+00 -9.84910e-01 -8.21470e-01 -5.79001e-02
21Feb13_013115|   6.47525e-01  8.65842e-01 -1.50544e-01 -5.53358e-01]
21Feb13_013115| [-6.20387e-01 -2.38812e-02 -1.35219e-01 -2.58836e-01 -1.37737e+00
21Feb13_013115|   5.90991e-01 -2.13963e-01 -1.42807e+00 -1.91510e-01]
21Feb13_013115| [-9.48377e-01  1.45005e+00  6.23528e-01  9.24684e-01  8.68100e-01
21Feb13_013115|  -1.99460e+00  4.72527e-01  1.81921e+00 -1.50210e-01]
21Feb13_013115| [ 5.42301e-01  2.45411e-01  1.22571e+00 -1.22660e+00  2.00326e+00
21Feb13_013115|   1.28311e+00 -4.79063e-01 -1.26853e+00  3.54082e-01]
21Feb13_013115| [-9.68448e-02 -9.53055e-01 -6.39710e-01  7.39744e-02 -3.14837e-01
21Feb13_013115|  -4.64567e-01  8.27918e-01 -1.06114e+00 -5.10970e-01]
21Feb13_013115| [ 2.33279e-01  7.22497e-01  9.49373e-01 -1.20131e+00 -8.38683e-01
21Feb13_013115|  -5.38987e-01 -2.01753e+00  1.18580e+00 -7.12282e-01]
21Feb13_013115| [ 1.38078e+00 -3.07472e-01 -9.41548e-01  2.12287e+00  7.20946e-01
21Feb13_013115|   4.38905e-01  1.23216e+00  1.01939e+00  1.80698e-01]
21Feb13_013115| [-1.45026e-01  1.94626e+00 -1.81820e+00  1.49784e+00  7.71685e-01
21Feb13_013115|   1.57506e-01 -7.09054e-01 -3.76284e-02 -6.77940e-01]
21Feb13_013115| [-8.93030e-01  4.45952e-01 -5.02934e-01 -1.64437e+00  2.79315e-01
21Feb13_013115|  -1.03096e+00 -1.36068e+00 -4.50048e-01  2.88074e-01]]
21Feb13_013115|-- Bias --
21Feb13_013115|[ 0.37717  0.47788 -0.06014 -0.50820  0.52122 -0.91124 -1.67126 -0.64210
21Feb13_013115| -0.07185]
21Feb13_013115|Layer 1:
21Feb13_013115|-- Config --
21Feb13_013115|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 9], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_013115|-- Weights --
21Feb13_013115|[[ 0.68231 -0.74250]
21Feb13_013115| [ 0.62314  1.42898]
21Feb13_013115| [ 2.01695  1.97734]
21Feb13_013115| [-0.39663 -0.22189]
21Feb13_013115| [ 0.44922  0.41110]
21Feb13_013115| [ 0.33786  0.12545]
21Feb13_013115| [ 0.50773  1.87586]
21Feb13_013115| [-1.32230 -0.68529]
21Feb13_013115| [-0.06485  1.23686]]
21Feb13_013115|-- Bias --
21Feb13_013115|[-0.71772 -0.40861]
21Feb13_013115|Predicting the validation and test data with the Best final individual.
21Feb13_013122| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_013122|-----------  ------------------  --------------------  ----------
21Feb13_013122|Validation         41.74                  9             0.00775
21Feb13_013122|   Test            36.32                  9             0.00596
21Feb13_013122|-------------------- Test #11 --------------------
21Feb13_013122|Best final individual weights
21Feb13_013122|Individual:
21Feb13_013122|-- Constant hidden layers --
21Feb13_013122|False
21Feb13_013122|Layer 0:
21Feb13_013122|-- Config --
21Feb13_013122|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 9, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_013122|-- Weights --
21Feb13_013122|[[-4.61006e-01  6.85931e-01 -1.53413e+00  3.18540e-01  1.65279e+00
21Feb13_013122|  -3.98052e-01  4.33508e-01 -6.92513e-01  3.42704e-01]
21Feb13_013122| [-1.09470e+00  9.32382e-01  7.25102e-01 -4.91678e-01  1.53894e+00
21Feb13_013122|   6.32892e-01  1.66659e+00 -1.21771e+00 -3.90783e-01]
21Feb13_013122| [ 9.03759e-01 -9.77900e-01  1.77765e+00 -2.07879e-01 -3.69959e-01
21Feb13_013122|   2.57340e-02  9.32038e-01  1.80456e+00  3.87273e-01]
21Feb13_013122| [-3.49696e-01 -3.58058e-03 -6.07396e-01 -1.37181e+00 -1.10504e+00
21Feb13_013122|  -1.11474e+00 -1.03332e+00  2.23341e-01 -4.72876e-01]
21Feb13_013122| [ 2.32707e-01 -1.07579e+00 -5.40875e-01  1.42954e+00  6.10975e-01
21Feb13_013122|   5.59004e-01 -5.83178e-01  1.52584e+00 -2.61616e-02]
21Feb13_013122| [ 2.60802e-01  1.01484e+00 -3.13035e-03  3.59113e-01 -5.42962e-02
21Feb13_013122|   1.30419e-01 -1.43042e+00  3.06781e-01  4.02528e-01]
21Feb13_013122| [ 3.31900e-01 -7.68883e-01  2.16435e+00  5.44727e-01 -7.94370e-01
21Feb13_013122|   4.13300e-01  8.17497e-01  8.49172e-01  3.89172e-01]
21Feb13_013122| [-1.74100e+00 -1.34439e+00 -1.72034e-01  5.54274e-01  4.11878e-03
21Feb13_013122|  -1.72138e+00  1.21996e+00 -2.14134e-01 -1.29167e-01]
21Feb13_013122| [ 1.02404e+00  6.15020e-02 -2.14163e-01  3.45452e-02  5.64308e-01
21Feb13_013122|   1.23836e-01 -7.85150e-01 -2.34675e-01 -6.19357e-01]
21Feb13_013122| [ 3.39580e-01 -9.02752e-01 -1.40731e+00  1.01083e+00 -1.27692e+00
21Feb13_013122|  -3.87978e-01  2.91565e-01  7.80658e-01 -4.54186e-01]
21Feb13_013122| [-6.53637e-01  3.40165e-01  6.43150e-01 -4.23568e-01 -2.78934e-01
21Feb13_013122|  -9.34614e-02 -6.67337e-01  4.52195e-01  1.32123e+00]
21Feb13_013122| [-1.27502e+00  1.02666e+00 -4.87675e-01  8.02112e-01  2.39068e-01
21Feb13_013122|  -4.86850e-01  1.73530e+00 -1.15809e-01 -3.03472e-02]
21Feb13_013122| [-5.53044e-01  4.66997e-01  8.50262e-01 -9.72246e-01  5.75977e-01
21Feb13_013122|  -8.30986e-01  6.72198e-01 -1.48566e+00 -4.40186e-01]
21Feb13_013122| [ 1.56239e+00  4.89175e-02  3.52725e-01 -5.84369e-01  3.78056e-01
21Feb13_013122|  -1.08095e+00  2.25579e-01  1.36469e+00  1.05927e-01]
21Feb13_013122| [ 5.87912e-01 -6.66494e-01  7.79087e-01 -1.37734e+00 -5.68017e-02
21Feb13_013122|  -5.28526e-01 -2.16139e-01 -1.39364e-01 -1.22582e-01]
21Feb13_013122| [-3.25557e-01  7.27112e-02 -9.80921e-01  1.85031e-02 -2.87431e-01
21Feb13_013122|   1.76187e+00  1.29272e+00 -2.15986e+00 -3.48111e-02]
21Feb13_013122| [ 2.43878e-01  5.55203e-02  1.46280e+00 -6.81342e-01  6.28102e-01
21Feb13_013122|   7.31779e-01 -1.31015e+00  8.71093e-01 -4.54700e-01]
21Feb13_013122| [ 4.93144e-01  7.54375e-02 -1.20005e+00  6.27631e-02  7.82145e-01
21Feb13_013122|   5.33649e-01 -1.13427e+00  8.26364e-01 -1.48796e-01]
21Feb13_013122| [-4.21426e-01 -1.29212e-01 -8.75548e-01 -7.62601e-01 -5.40266e-01
21Feb13_013122|   1.80516e+00 -1.24863e+00  1.35354e+00 -3.30202e-02]
21Feb13_013122| [ 3.22391e-01 -5.16648e-01  1.97275e+00  3.26675e-01 -1.58735e-01
21Feb13_013122|  -1.86724e-01  3.96522e-01  6.89546e-01 -9.39432e-01]
21Feb13_013122| [-4.67129e-01  2.15586e+00 -5.38287e-01  2.78568e-01  9.42587e-01
21Feb13_013122|  -2.77032e-01  1.25393e+00  3.81716e-01  8.82734e-01]
21Feb13_013122| [-1.41583e+00 -1.45012e-01 -7.99630e-01 -5.31952e-01 -1.19693e+00
21Feb13_013122|   7.92286e-01  1.30639e-01 -2.37138e-01 -1.58410e+00]
21Feb13_013122| [-1.16444e+00 -5.22290e-01  1.02540e+00  3.99299e-01 -9.33985e-01
21Feb13_013122|   2.16709e+00  3.01229e-01 -7.56401e-01  1.21738e+00]
21Feb13_013122| [-4.96242e-01  1.99264e+00  1.72242e+00 -7.33992e-01  1.79053e+00
21Feb13_013122|   7.69467e-01  4.32490e-01  8.00370e-02 -1.48974e-01]
21Feb13_013122| [ 9.93945e-02 -1.39770e+00  2.13769e-01  1.86767e+00  1.11288e+00
21Feb13_013122|   6.22801e-01  3.99123e-01  6.84795e-01  2.17178e-01]
21Feb13_013122| [ 1.35578e+00  8.00580e-01  3.99488e-01  4.40513e-01  1.93473e-02
21Feb13_013122|  -4.51602e-01  2.87170e-01  3.29084e-02 -1.36035e+00]
21Feb13_013122| [-1.09101e+00  2.48048e+00  5.80244e-01 -1.33268e-01 -5.28168e-01
21Feb13_013122|   8.09824e-01 -4.30853e-01 -2.55311e-02  1.50016e+00]
21Feb13_013122| [ 5.18298e-02 -2.30052e-01  1.28184e+00 -2.64124e+00  3.01962e-01
21Feb13_013122|   1.55697e+00 -1.20762e+00  6.34586e-01 -1.58188e-01]
21Feb13_013122| [-1.72551e+00  1.63754e+00 -4.70755e-01 -1.15326e+00 -8.33712e-01
21Feb13_013122|   1.31472e+00  2.01820e-01 -2.33652e-01  2.10201e-01]
21Feb13_013122| [ 1.47803e-01  1.06813e-01 -7.00830e-02 -1.17159e+00 -1.10268e+00
21Feb13_013122|  -8.43557e-01  4.82005e-01  1.25841e+00  4.90572e-02]
21Feb13_013122| [-4.14468e-01 -9.13217e-01  1.43297e+00 -2.20598e-01 -5.00413e-02
21Feb13_013122|   1.00790e+00 -1.44685e+00  1.08882e-02  4.97447e-02]
21Feb13_013122| [ 8.57554e-01  1.16591e+00 -1.34007e-01  1.71257e+00 -1.12961e+00
21Feb13_013122|   1.37418e+00 -1.22028e+00 -6.84918e-01  7.78660e-01]
21Feb13_013122| [-7.13839e-01  1.40966e+00 -4.77517e-01 -1.19630e+00 -1.15371e+00
21Feb13_013122|  -3.93636e-01  3.23964e-01 -6.64234e-01  1.21979e+00]
21Feb13_013122| [ 1.74382e+00  1.33485e+00  1.78034e-01  9.41668e-02  2.62732e-01
21Feb13_013122|   8.78408e-01  2.48648e-01  1.21791e+00  4.85344e-01]
21Feb13_013122| [-5.31246e-01 -1.52761e-01  2.84841e-01 -2.19881e-01 -5.37130e-01
21Feb13_013122|  -5.76407e-01  9.54226e-01  4.85366e-01 -9.77571e-01]
21Feb13_013122| [-1.35084e+00  1.09906e+00 -6.32061e-01  1.77342e-01 -6.40846e-01
21Feb13_013122|  -3.03854e-02  1.66807e+00  3.12194e-02 -3.53426e-01]
21Feb13_013122| [ 9.50869e-01 -3.62129e-01  2.98314e-01  4.91118e-01 -1.57990e+00
21Feb13_013122|  -2.44973e+00  8.00915e-01  7.10599e-04  8.10353e-01]
21Feb13_013122| [ 1.78432e+00 -9.71843e-01 -1.97505e+00 -1.18986e+00 -2.70454e-01
21Feb13_013122|  -1.30340e+00  7.99598e-01 -2.84399e-01  2.78754e-01]
21Feb13_013122| [-6.25690e-01 -1.36899e+00 -1.69985e-01 -6.67490e-01 -1.83927e+00
21Feb13_013122|   7.29422e-01 -1.91879e+00  9.93721e-01  1.24720e-01]
21Feb13_013122| [-6.63423e-02 -1.59385e+00  1.31061e+00 -5.23944e-01 -9.22575e-01
21Feb13_013122|   1.02268e-01  4.40389e-01  7.93366e-01  8.34624e-01]
21Feb13_013122| [-3.15115e-01 -8.73738e-01  2.06436e-01 -4.60182e-01  3.67394e-01
21Feb13_013122|   8.74019e-01 -1.00027e+00 -7.35157e-01 -6.67303e-01]
21Feb13_013122| [ 2.59118e-01  1.24828e+00 -4.10084e-01  3.25478e-01 -1.34056e+00
21Feb13_013122|  -2.04943e+00 -8.99572e-02  1.63028e+00  5.09953e-01]
21Feb13_013122| [ 1.17609e-02 -8.36465e-01 -8.15524e-02  3.43689e-01 -9.21088e-01
21Feb13_013122|  -1.89687e+00 -1.24788e+00  1.11545e+00  9.05282e-01]
21Feb13_013122| [-1.50660e+00  6.36055e-01 -3.71286e-02  4.62230e-01  8.44458e-01
21Feb13_013122|  -1.52079e+00 -7.16504e-01  7.07441e-02 -1.03582e+00]
21Feb13_013122| [-3.32525e-02 -5.49366e-01  7.30336e-01  1.55130e+00  1.87862e+00
21Feb13_013122|   5.59851e-01  1.58186e+00  4.62385e-01  7.76501e-01]
21Feb13_013122| [-2.09596e+00  1.33953e+00 -1.51561e+00 -1.25216e+00 -1.00343e+00
21Feb13_013122|  -5.75715e-01  8.79691e-01 -1.53243e+00 -3.80041e-01]
21Feb13_013122| [ 1.61185e-01  5.12300e-01  1.59935e+00  1.06339e+00  7.93391e-01
21Feb13_013122|   2.53927e+00 -1.61466e+00 -1.69022e+00 -2.02367e-01]
21Feb13_013122| [-1.25470e+00 -2.58098e-01  5.92567e-01  3.37381e-01 -6.99700e-01
21Feb13_013122|   9.24420e-01  9.48337e-01 -8.98604e-01  9.35058e-01]
21Feb13_013122| [ 1.43861e+00  1.42065e+00 -9.84910e-01 -8.21470e-01 -5.79001e-02
21Feb13_013122|   6.47525e-01  8.65842e-01 -1.50544e-01 -5.53358e-01]
21Feb13_013122| [-6.20387e-01 -2.38812e-02 -1.35219e-01 -2.58836e-01 -1.37737e+00
21Feb13_013122|   5.90991e-01 -2.13963e-01 -1.42807e+00 -1.91510e-01]
21Feb13_013122| [-9.48377e-01  1.45005e+00  6.23528e-01  9.24684e-01  8.68100e-01
21Feb13_013122|  -1.99460e+00  4.72527e-01  1.81921e+00 -1.50210e-01]
21Feb13_013122| [ 5.42301e-01  2.45411e-01  1.22571e+00 -1.22660e+00  2.00326e+00
21Feb13_013122|   1.28311e+00 -4.79063e-01 -1.26853e+00  3.54082e-01]
21Feb13_013122| [-9.68448e-02 -9.53055e-01 -6.39710e-01  7.39744e-02 -3.14837e-01
21Feb13_013122|  -4.64567e-01  8.27918e-01 -1.06114e+00 -5.10970e-01]
21Feb13_013122| [ 2.33279e-01  7.22497e-01  9.49373e-01 -1.20131e+00 -8.38683e-01
21Feb13_013122|  -5.38987e-01 -2.01753e+00  1.18580e+00 -7.12282e-01]
21Feb13_013122| [ 1.38078e+00 -3.07472e-01 -9.41548e-01  2.12287e+00  7.20946e-01
21Feb13_013122|   4.38905e-01  1.23216e+00  1.01939e+00  1.80698e-01]
21Feb13_013122| [-1.45026e-01  1.94626e+00 -1.81820e+00  1.49784e+00  7.71685e-01
21Feb13_013122|   1.57506e-01 -7.09054e-01 -3.76284e-02 -6.77940e-01]
21Feb13_013122| [-8.93030e-01  4.45952e-01 -5.02934e-01 -1.64437e+00  2.79315e-01
21Feb13_013122|  -1.03096e+00 -1.36068e+00 -4.50048e-01  2.88074e-01]]
21Feb13_013122|-- Bias --
21Feb13_013122|[ 0.37717  0.47788 -0.06014 -0.50820  0.52122 -0.91124 -1.67126 -0.64210
21Feb13_013122| -0.07185]
21Feb13_013122|Layer 1:
21Feb13_013122|-- Config --
21Feb13_013122|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 9], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_013122|-- Weights --
21Feb13_013122|[[ 0.68231 -0.74250]
21Feb13_013122| [ 0.62314  1.42898]
21Feb13_013122| [ 2.01695  1.97734]
21Feb13_013122| [-0.39663 -0.22189]
21Feb13_013122| [ 0.44922  0.41110]
21Feb13_013122| [ 0.33786  0.12545]
21Feb13_013122| [ 0.50773  1.87586]
21Feb13_013122| [-1.32230 -0.68529]
21Feb13_013122| [-0.06485  1.23686]]
21Feb13_013122|-- Bias --
21Feb13_013122|[-0.71772 -0.40861]
21Feb13_013122|Predicting the validation and test data with the Best final individual.
21Feb13_013129| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_013129|-----------  ------------------  --------------------  ----------
21Feb13_013129|Validation         41.83                  9             0.00775
21Feb13_013129|   Test            36.32                  9             0.00596
21Feb13_013129|-------------------- Test #12 --------------------
21Feb13_013129|Best final individual weights
21Feb13_013129|Individual:
21Feb13_013129|-- Constant hidden layers --
21Feb13_013129|False
21Feb13_013129|Layer 0:
21Feb13_013129|-- Config --
21Feb13_013129|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 9, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_013129|-- Weights --
21Feb13_013129|[[-4.61006e-01  6.85931e-01 -1.53413e+00  3.18540e-01  1.65279e+00
21Feb13_013129|  -3.98052e-01  4.33508e-01 -6.92513e-01  3.42704e-01]
21Feb13_013129| [-1.09470e+00  9.32382e-01  7.25102e-01 -4.91678e-01  1.53894e+00
21Feb13_013129|   6.32892e-01  1.66659e+00 -1.21771e+00 -3.90783e-01]
21Feb13_013129| [ 9.03759e-01 -9.77900e-01  1.77765e+00 -2.07879e-01 -3.69959e-01
21Feb13_013129|   2.57340e-02  9.32038e-01  1.80456e+00  3.87273e-01]
21Feb13_013129| [-3.49696e-01 -3.58058e-03 -6.07396e-01 -1.37181e+00 -1.10504e+00
21Feb13_013129|  -1.11474e+00 -1.03332e+00  2.23341e-01 -4.72876e-01]
21Feb13_013129| [ 2.32707e-01 -1.07579e+00 -5.40875e-01  1.42954e+00  6.10975e-01
21Feb13_013129|   5.59004e-01 -5.83178e-01  1.52584e+00 -2.61616e-02]
21Feb13_013129| [ 2.60802e-01  1.01484e+00 -3.13035e-03  3.59113e-01 -5.42962e-02
21Feb13_013129|   1.30419e-01 -1.43042e+00  3.06781e-01  4.02528e-01]
21Feb13_013129| [ 3.31900e-01 -7.68883e-01  2.16435e+00  5.44727e-01 -7.94370e-01
21Feb13_013129|   4.13300e-01  8.17497e-01  8.49172e-01  3.89172e-01]
21Feb13_013129| [-1.74100e+00 -1.34439e+00 -1.72034e-01  5.54274e-01  4.11878e-03
21Feb13_013129|  -1.72138e+00  1.21996e+00 -2.14134e-01 -1.29167e-01]
21Feb13_013129| [ 1.02404e+00  6.15020e-02 -2.14163e-01  3.45452e-02  5.64308e-01
21Feb13_013129|   1.23836e-01 -7.85150e-01 -2.34675e-01 -6.19357e-01]
21Feb13_013129| [ 3.39580e-01 -9.02752e-01 -1.40731e+00  1.01083e+00 -1.27692e+00
21Feb13_013129|  -3.87978e-01  2.91565e-01  7.80658e-01 -4.54186e-01]
21Feb13_013129| [-6.53637e-01  3.40165e-01  6.43150e-01 -4.23568e-01 -2.78934e-01
21Feb13_013129|  -9.34614e-02 -6.67337e-01  4.52195e-01  1.32123e+00]
21Feb13_013129| [-1.27502e+00  1.02666e+00 -4.87675e-01  8.02112e-01  2.39068e-01
21Feb13_013129|  -4.86850e-01  1.73530e+00 -1.15809e-01 -3.03472e-02]
21Feb13_013129| [-5.53044e-01  4.66997e-01  8.50262e-01 -9.72246e-01  5.75977e-01
21Feb13_013129|  -8.30986e-01  6.72198e-01 -1.48566e+00 -4.40186e-01]
21Feb13_013129| [ 1.56239e+00  4.89175e-02  3.52725e-01 -5.84369e-01  3.78056e-01
21Feb13_013129|  -1.08095e+00  2.25579e-01  1.36469e+00  1.05927e-01]
21Feb13_013129| [ 5.87912e-01 -6.66494e-01  7.79087e-01 -1.37734e+00 -5.68017e-02
21Feb13_013129|  -5.28526e-01 -2.16139e-01 -1.39364e-01 -1.22582e-01]
21Feb13_013129| [-3.25557e-01  7.27112e-02 -9.80921e-01  1.85031e-02 -2.87431e-01
21Feb13_013129|   1.76187e+00  1.29272e+00 -2.15986e+00 -3.48111e-02]
21Feb13_013129| [ 2.43878e-01  5.55203e-02  1.46280e+00 -6.81342e-01  6.28102e-01
21Feb13_013129|   7.31779e-01 -1.31015e+00  8.71093e-01 -4.54700e-01]
21Feb13_013129| [ 4.93144e-01  7.54375e-02 -1.20005e+00  6.27631e-02  7.82145e-01
21Feb13_013129|   5.33649e-01 -1.13427e+00  8.26364e-01 -1.48796e-01]
21Feb13_013129| [-4.21426e-01 -1.29212e-01 -8.75548e-01 -7.62601e-01 -5.40266e-01
21Feb13_013129|   1.80516e+00 -1.24863e+00  1.35354e+00 -3.30202e-02]
21Feb13_013129| [ 3.22391e-01 -5.16648e-01  1.97275e+00  3.26675e-01 -1.58735e-01
21Feb13_013129|  -1.86724e-01  3.96522e-01  6.89546e-01 -9.39432e-01]
21Feb13_013129| [-4.67129e-01  2.15586e+00 -5.38287e-01  2.78568e-01  9.42587e-01
21Feb13_013129|  -2.77032e-01  1.25393e+00  3.81716e-01  8.82734e-01]
21Feb13_013129| [-1.41583e+00 -1.45012e-01 -7.99630e-01 -5.31952e-01 -1.19693e+00
21Feb13_013129|   7.92286e-01  1.30639e-01 -2.37138e-01 -1.58410e+00]
21Feb13_013129| [-1.16444e+00 -5.22290e-01  1.02540e+00  3.99299e-01 -9.33985e-01
21Feb13_013129|   2.16709e+00  3.01229e-01 -7.56401e-01  1.21738e+00]
21Feb13_013129| [-4.96242e-01  1.99264e+00  1.72242e+00 -7.33992e-01  1.79053e+00
21Feb13_013129|   7.69467e-01  4.32490e-01  8.00370e-02 -1.48974e-01]
21Feb13_013129| [ 9.93945e-02 -1.39770e+00  2.13769e-01  1.86767e+00  1.11288e+00
21Feb13_013129|   6.22801e-01  3.99123e-01  6.84795e-01  2.17178e-01]
21Feb13_013129| [ 1.35578e+00  8.00580e-01  3.99488e-01  4.40513e-01  1.93473e-02
21Feb13_013129|  -4.51602e-01  2.87170e-01  3.29084e-02 -1.36035e+00]
21Feb13_013129| [-1.09101e+00  2.48048e+00  5.80244e-01 -1.33268e-01 -5.28168e-01
21Feb13_013129|   8.09824e-01 -4.30853e-01 -2.55311e-02  1.50016e+00]
21Feb13_013129| [ 5.18298e-02 -2.30052e-01  1.28184e+00 -2.64124e+00  3.01962e-01
21Feb13_013129|   1.55697e+00 -1.20762e+00  6.34586e-01 -1.58188e-01]
21Feb13_013129| [-1.72551e+00  1.63754e+00 -4.70755e-01 -1.15326e+00 -8.33712e-01
21Feb13_013129|   1.31472e+00  2.01820e-01 -2.33652e-01  2.10201e-01]
21Feb13_013129| [ 1.47803e-01  1.06813e-01 -7.00830e-02 -1.17159e+00 -1.10268e+00
21Feb13_013129|  -8.43557e-01  4.82005e-01  1.25841e+00  4.90572e-02]
21Feb13_013129| [-4.14468e-01 -9.13217e-01  1.43297e+00 -2.20598e-01 -5.00413e-02
21Feb13_013129|   1.00790e+00 -1.44685e+00  1.08882e-02  4.97447e-02]
21Feb13_013129| [ 8.57554e-01  1.16591e+00 -1.34007e-01  1.71257e+00 -1.12961e+00
21Feb13_013129|   1.37418e+00 -1.22028e+00 -6.84918e-01  7.78660e-01]
21Feb13_013129| [-7.13839e-01  1.40966e+00 -4.77517e-01 -1.19630e+00 -1.15371e+00
21Feb13_013129|  -3.93636e-01  3.23964e-01 -6.64234e-01  1.21979e+00]
21Feb13_013129| [ 1.74382e+00  1.33485e+00  1.78034e-01  9.41668e-02  2.62732e-01
21Feb13_013129|   8.78408e-01  2.48648e-01  1.21791e+00  4.85344e-01]
21Feb13_013129| [-5.31246e-01 -1.52761e-01  2.84841e-01 -2.19881e-01 -5.37130e-01
21Feb13_013129|  -5.76407e-01  9.54226e-01  4.85366e-01 -9.77571e-01]
21Feb13_013129| [-1.35084e+00  1.09906e+00 -6.32061e-01  1.77342e-01 -6.40846e-01
21Feb13_013129|  -3.03854e-02  1.66807e+00  3.12194e-02 -3.53426e-01]
21Feb13_013129| [ 9.50869e-01 -3.62129e-01  2.98314e-01  4.91118e-01 -1.57990e+00
21Feb13_013129|  -2.44973e+00  8.00915e-01  7.10599e-04  8.10353e-01]
21Feb13_013129| [ 1.78432e+00 -9.71843e-01 -1.97505e+00 -1.18986e+00 -2.70454e-01
21Feb13_013129|  -1.30340e+00  7.99598e-01 -2.84399e-01  2.78754e-01]
21Feb13_013129| [-6.25690e-01 -1.36899e+00 -1.69985e-01 -6.67490e-01 -1.83927e+00
21Feb13_013129|   7.29422e-01 -1.91879e+00  9.93721e-01  1.24720e-01]
21Feb13_013129| [-6.63423e-02 -1.59385e+00  1.31061e+00 -5.23944e-01 -9.22575e-01
21Feb13_013129|   1.02268e-01  4.40389e-01  7.93366e-01  8.34624e-01]
21Feb13_013129| [-3.15115e-01 -8.73738e-01  2.06436e-01 -4.60182e-01  3.67394e-01
21Feb13_013129|   8.74019e-01 -1.00027e+00 -7.35157e-01 -6.67303e-01]
21Feb13_013129| [ 2.59118e-01  1.24828e+00 -4.10084e-01  3.25478e-01 -1.34056e+00
21Feb13_013129|  -2.04943e+00 -8.99572e-02  1.63028e+00  5.09953e-01]
21Feb13_013129| [ 1.17609e-02 -8.36465e-01 -8.15524e-02  3.43689e-01 -9.21088e-01
21Feb13_013129|  -1.89687e+00 -1.24788e+00  1.11545e+00  9.05282e-01]
21Feb13_013129| [-1.50660e+00  6.36055e-01 -3.71286e-02  4.62230e-01  8.44458e-01
21Feb13_013129|  -1.52079e+00 -7.16504e-01  7.07441e-02 -1.03582e+00]
21Feb13_013129| [-3.32525e-02 -5.49366e-01  7.30336e-01  1.55130e+00  1.87862e+00
21Feb13_013129|   5.59851e-01  1.58186e+00  4.62385e-01  7.76501e-01]
21Feb13_013129| [-2.09596e+00  1.33953e+00 -1.51561e+00 -1.25216e+00 -1.00343e+00
21Feb13_013129|  -5.75715e-01  8.79691e-01 -1.53243e+00 -3.80041e-01]
21Feb13_013129| [ 1.61185e-01  5.12300e-01  1.59935e+00  1.06339e+00  7.93391e-01
21Feb13_013129|   2.53927e+00 -1.61466e+00 -1.69022e+00 -2.02367e-01]
21Feb13_013129| [-1.25470e+00 -2.58098e-01  5.92567e-01  3.37381e-01 -6.99700e-01
21Feb13_013129|   9.24420e-01  9.48337e-01 -8.98604e-01  9.35058e-01]
21Feb13_013129| [ 1.43861e+00  1.42065e+00 -9.84910e-01 -8.21470e-01 -5.79001e-02
21Feb13_013129|   6.47525e-01  8.65842e-01 -1.50544e-01 -5.53358e-01]
21Feb13_013129| [-6.20387e-01 -2.38812e-02 -1.35219e-01 -2.58836e-01 -1.37737e+00
21Feb13_013129|   5.90991e-01 -2.13963e-01 -1.42807e+00 -1.91510e-01]
21Feb13_013129| [-9.48377e-01  1.45005e+00  6.23528e-01  9.24684e-01  8.68100e-01
21Feb13_013129|  -1.99460e+00  4.72527e-01  1.81921e+00 -1.50210e-01]
21Feb13_013129| [ 5.42301e-01  2.45411e-01  1.22571e+00 -1.22660e+00  2.00326e+00
21Feb13_013129|   1.28311e+00 -4.79063e-01 -1.26853e+00  3.54082e-01]
21Feb13_013129| [-9.68448e-02 -9.53055e-01 -6.39710e-01  7.39744e-02 -3.14837e-01
21Feb13_013129|  -4.64567e-01  8.27918e-01 -1.06114e+00 -5.10970e-01]
21Feb13_013129| [ 2.33279e-01  7.22497e-01  9.49373e-01 -1.20131e+00 -8.38683e-01
21Feb13_013129|  -5.38987e-01 -2.01753e+00  1.18580e+00 -7.12282e-01]
21Feb13_013129| [ 1.38078e+00 -3.07472e-01 -9.41548e-01  2.12287e+00  7.20946e-01
21Feb13_013129|   4.38905e-01  1.23216e+00  1.01939e+00  1.80698e-01]
21Feb13_013129| [-1.45026e-01  1.94626e+00 -1.81820e+00  1.49784e+00  7.71685e-01
21Feb13_013129|   1.57506e-01 -7.09054e-01 -3.76284e-02 -6.77940e-01]
21Feb13_013129| [-8.93030e-01  4.45952e-01 -5.02934e-01 -1.64437e+00  2.79315e-01
21Feb13_013129|  -1.03096e+00 -1.36068e+00 -4.50048e-01  2.88074e-01]]
21Feb13_013129|-- Bias --
21Feb13_013129|[ 0.37717  0.47788 -0.06014 -0.50820  0.52122 -0.91124 -1.67126 -0.64210
21Feb13_013129| -0.07185]
21Feb13_013129|Layer 1:
21Feb13_013129|-- Config --
21Feb13_013129|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 9], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_013129|-- Weights --
21Feb13_013129|[[ 0.68231 -0.74250]
21Feb13_013129| [ 0.62314  1.42898]
21Feb13_013129| [ 2.01695  1.97734]
21Feb13_013129| [-0.39663 -0.22189]
21Feb13_013129| [ 0.44922  0.41110]
21Feb13_013129| [ 0.33786  0.12545]
21Feb13_013129| [ 0.50773  1.87586]
21Feb13_013129| [-1.32230 -0.68529]
21Feb13_013129| [-0.06485  1.23686]]
21Feb13_013129|-- Bias --
21Feb13_013129|[-0.71772 -0.40861]
21Feb13_013129|Predicting the validation and test data with the Best final individual.
21Feb13_013136| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_013136|-----------  ------------------  --------------------  ----------
21Feb13_013136|Validation         41.74                  9             0.00775
21Feb13_013136|   Test            36.40                  9             0.00298
21Feb13_013136|-------------------- Test #13 --------------------
21Feb13_013136|Best final individual weights
21Feb13_013136|Individual:
21Feb13_013136|-- Constant hidden layers --
21Feb13_013136|False
21Feb13_013136|Layer 0:
21Feb13_013136|-- Config --
21Feb13_013136|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 9, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_013136|-- Weights --
21Feb13_013136|[[-4.61006e-01  6.85931e-01 -1.53413e+00  3.18540e-01  1.65279e+00
21Feb13_013136|  -3.98052e-01  4.33508e-01 -6.92513e-01  3.42704e-01]
21Feb13_013136| [-1.09470e+00  9.32382e-01  7.25102e-01 -4.91678e-01  1.53894e+00
21Feb13_013136|   6.32892e-01  1.66659e+00 -1.21771e+00 -3.90783e-01]
21Feb13_013136| [ 9.03759e-01 -9.77900e-01  1.77765e+00 -2.07879e-01 -3.69959e-01
21Feb13_013136|   2.57340e-02  9.32038e-01  1.80456e+00  3.87273e-01]
21Feb13_013136| [-3.49696e-01 -3.58058e-03 -6.07396e-01 -1.37181e+00 -1.10504e+00
21Feb13_013136|  -1.11474e+00 -1.03332e+00  2.23341e-01 -4.72876e-01]
21Feb13_013136| [ 2.32707e-01 -1.07579e+00 -5.40875e-01  1.42954e+00  6.10975e-01
21Feb13_013136|   5.59004e-01 -5.83178e-01  1.52584e+00 -2.61616e-02]
21Feb13_013136| [ 2.60802e-01  1.01484e+00 -3.13035e-03  3.59113e-01 -5.42962e-02
21Feb13_013136|   1.30419e-01 -1.43042e+00  3.06781e-01  4.02528e-01]
21Feb13_013136| [ 3.31900e-01 -7.68883e-01  2.16435e+00  5.44727e-01 -7.94370e-01
21Feb13_013136|   4.13300e-01  8.17497e-01  8.49172e-01  3.89172e-01]
21Feb13_013136| [-1.74100e+00 -1.34439e+00 -1.72034e-01  5.54274e-01  4.11878e-03
21Feb13_013136|  -1.72138e+00  1.21996e+00 -2.14134e-01 -1.29167e-01]
21Feb13_013136| [ 1.02404e+00  6.15020e-02 -2.14163e-01  3.45452e-02  5.64308e-01
21Feb13_013136|   1.23836e-01 -7.85150e-01 -2.34675e-01 -6.19357e-01]
21Feb13_013136| [ 3.39580e-01 -9.02752e-01 -1.40731e+00  1.01083e+00 -1.27692e+00
21Feb13_013136|  -3.87978e-01  2.91565e-01  7.80658e-01 -4.54186e-01]
21Feb13_013136| [-6.53637e-01  3.40165e-01  6.43150e-01 -4.23568e-01 -2.78934e-01
21Feb13_013136|  -9.34614e-02 -6.67337e-01  4.52195e-01  1.32123e+00]
21Feb13_013136| [-1.27502e+00  1.02666e+00 -4.87675e-01  8.02112e-01  2.39068e-01
21Feb13_013136|  -4.86850e-01  1.73530e+00 -1.15809e-01 -3.03472e-02]
21Feb13_013136| [-5.53044e-01  4.66997e-01  8.50262e-01 -9.72246e-01  5.75977e-01
21Feb13_013136|  -8.30986e-01  6.72198e-01 -1.48566e+00 -4.40186e-01]
21Feb13_013136| [ 1.56239e+00  4.89175e-02  3.52725e-01 -5.84369e-01  3.78056e-01
21Feb13_013136|  -1.08095e+00  2.25579e-01  1.36469e+00  1.05927e-01]
21Feb13_013136| [ 5.87912e-01 -6.66494e-01  7.79087e-01 -1.37734e+00 -5.68017e-02
21Feb13_013136|  -5.28526e-01 -2.16139e-01 -1.39364e-01 -1.22582e-01]
21Feb13_013136| [-3.25557e-01  7.27112e-02 -9.80921e-01  1.85031e-02 -2.87431e-01
21Feb13_013136|   1.76187e+00  1.29272e+00 -2.15986e+00 -3.48111e-02]
21Feb13_013136| [ 2.43878e-01  5.55203e-02  1.46280e+00 -6.81342e-01  6.28102e-01
21Feb13_013136|   7.31779e-01 -1.31015e+00  8.71093e-01 -4.54700e-01]
21Feb13_013136| [ 4.93144e-01  7.54375e-02 -1.20005e+00  6.27631e-02  7.82145e-01
21Feb13_013136|   5.33649e-01 -1.13427e+00  8.26364e-01 -1.48796e-01]
21Feb13_013136| [-4.21426e-01 -1.29212e-01 -8.75548e-01 -7.62601e-01 -5.40266e-01
21Feb13_013136|   1.80516e+00 -1.24863e+00  1.35354e+00 -3.30202e-02]
21Feb13_013136| [ 3.22391e-01 -5.16648e-01  1.97275e+00  3.26675e-01 -1.58735e-01
21Feb13_013136|  -1.86724e-01  3.96522e-01  6.89546e-01 -9.39432e-01]
21Feb13_013136| [-4.67129e-01  2.15586e+00 -5.38287e-01  2.78568e-01  9.42587e-01
21Feb13_013136|  -2.77032e-01  1.25393e+00  3.81716e-01  8.82734e-01]
21Feb13_013136| [-1.41583e+00 -1.45012e-01 -7.99630e-01 -5.31952e-01 -1.19693e+00
21Feb13_013136|   7.92286e-01  1.30639e-01 -2.37138e-01 -1.58410e+00]
21Feb13_013136| [-1.16444e+00 -5.22290e-01  1.02540e+00  3.99299e-01 -9.33985e-01
21Feb13_013136|   2.16709e+00  3.01229e-01 -7.56401e-01  1.21738e+00]
21Feb13_013136| [-4.96242e-01  1.99264e+00  1.72242e+00 -7.33992e-01  1.79053e+00
21Feb13_013136|   7.69467e-01  4.32490e-01  8.00370e-02 -1.48974e-01]
21Feb13_013136| [ 9.93945e-02 -1.39770e+00  2.13769e-01  1.86767e+00  1.11288e+00
21Feb13_013136|   6.22801e-01  3.99123e-01  6.84795e-01  2.17178e-01]
21Feb13_013136| [ 1.35578e+00  8.00580e-01  3.99488e-01  4.40513e-01  1.93473e-02
21Feb13_013136|  -4.51602e-01  2.87170e-01  3.29084e-02 -1.36035e+00]
21Feb13_013136| [-1.09101e+00  2.48048e+00  5.80244e-01 -1.33268e-01 -5.28168e-01
21Feb13_013136|   8.09824e-01 -4.30853e-01 -2.55311e-02  1.50016e+00]
21Feb13_013136| [ 5.18298e-02 -2.30052e-01  1.28184e+00 -2.64124e+00  3.01962e-01
21Feb13_013136|   1.55697e+00 -1.20762e+00  6.34586e-01 -1.58188e-01]
21Feb13_013136| [-1.72551e+00  1.63754e+00 -4.70755e-01 -1.15326e+00 -8.33712e-01
21Feb13_013136|   1.31472e+00  2.01820e-01 -2.33652e-01  2.10201e-01]
21Feb13_013136| [ 1.47803e-01  1.06813e-01 -7.00830e-02 -1.17159e+00 -1.10268e+00
21Feb13_013136|  -8.43557e-01  4.82005e-01  1.25841e+00  4.90572e-02]
21Feb13_013136| [-4.14468e-01 -9.13217e-01  1.43297e+00 -2.20598e-01 -5.00413e-02
21Feb13_013136|   1.00790e+00 -1.44685e+00  1.08882e-02  4.97447e-02]
21Feb13_013136| [ 8.57554e-01  1.16591e+00 -1.34007e-01  1.71257e+00 -1.12961e+00
21Feb13_013136|   1.37418e+00 -1.22028e+00 -6.84918e-01  7.78660e-01]
21Feb13_013136| [-7.13839e-01  1.40966e+00 -4.77517e-01 -1.19630e+00 -1.15371e+00
21Feb13_013136|  -3.93636e-01  3.23964e-01 -6.64234e-01  1.21979e+00]
21Feb13_013136| [ 1.74382e+00  1.33485e+00  1.78034e-01  9.41668e-02  2.62732e-01
21Feb13_013136|   8.78408e-01  2.48648e-01  1.21791e+00  4.85344e-01]
21Feb13_013136| [-5.31246e-01 -1.52761e-01  2.84841e-01 -2.19881e-01 -5.37130e-01
21Feb13_013136|  -5.76407e-01  9.54226e-01  4.85366e-01 -9.77571e-01]
21Feb13_013136| [-1.35084e+00  1.09906e+00 -6.32061e-01  1.77342e-01 -6.40846e-01
21Feb13_013136|  -3.03854e-02  1.66807e+00  3.12194e-02 -3.53426e-01]
21Feb13_013136| [ 9.50869e-01 -3.62129e-01  2.98314e-01  4.91118e-01 -1.57990e+00
21Feb13_013136|  -2.44973e+00  8.00915e-01  7.10599e-04  8.10353e-01]
21Feb13_013136| [ 1.78432e+00 -9.71843e-01 -1.97505e+00 -1.18986e+00 -2.70454e-01
21Feb13_013136|  -1.30340e+00  7.99598e-01 -2.84399e-01  2.78754e-01]
21Feb13_013136| [-6.25690e-01 -1.36899e+00 -1.69985e-01 -6.67490e-01 -1.83927e+00
21Feb13_013136|   7.29422e-01 -1.91879e+00  9.93721e-01  1.24720e-01]
21Feb13_013136| [-6.63423e-02 -1.59385e+00  1.31061e+00 -5.23944e-01 -9.22575e-01
21Feb13_013136|   1.02268e-01  4.40389e-01  7.93366e-01  8.34624e-01]
21Feb13_013136| [-3.15115e-01 -8.73738e-01  2.06436e-01 -4.60182e-01  3.67394e-01
21Feb13_013136|   8.74019e-01 -1.00027e+00 -7.35157e-01 -6.67303e-01]
21Feb13_013136| [ 2.59118e-01  1.24828e+00 -4.10084e-01  3.25478e-01 -1.34056e+00
21Feb13_013136|  -2.04943e+00 -8.99572e-02  1.63028e+00  5.09953e-01]
21Feb13_013136| [ 1.17609e-02 -8.36465e-01 -8.15524e-02  3.43689e-01 -9.21088e-01
21Feb13_013136|  -1.89687e+00 -1.24788e+00  1.11545e+00  9.05282e-01]
21Feb13_013136| [-1.50660e+00  6.36055e-01 -3.71286e-02  4.62230e-01  8.44458e-01
21Feb13_013136|  -1.52079e+00 -7.16504e-01  7.07441e-02 -1.03582e+00]
21Feb13_013136| [-3.32525e-02 -5.49366e-01  7.30336e-01  1.55130e+00  1.87862e+00
21Feb13_013136|   5.59851e-01  1.58186e+00  4.62385e-01  7.76501e-01]
21Feb13_013136| [-2.09596e+00  1.33953e+00 -1.51561e+00 -1.25216e+00 -1.00343e+00
21Feb13_013136|  -5.75715e-01  8.79691e-01 -1.53243e+00 -3.80041e-01]
21Feb13_013136| [ 1.61185e-01  5.12300e-01  1.59935e+00  1.06339e+00  7.93391e-01
21Feb13_013136|   2.53927e+00 -1.61466e+00 -1.69022e+00 -2.02367e-01]
21Feb13_013136| [-1.25470e+00 -2.58098e-01  5.92567e-01  3.37381e-01 -6.99700e-01
21Feb13_013136|   9.24420e-01  9.48337e-01 -8.98604e-01  9.35058e-01]
21Feb13_013136| [ 1.43861e+00  1.42065e+00 -9.84910e-01 -8.21470e-01 -5.79001e-02
21Feb13_013136|   6.47525e-01  8.65842e-01 -1.50544e-01 -5.53358e-01]
21Feb13_013136| [-6.20387e-01 -2.38812e-02 -1.35219e-01 -2.58836e-01 -1.37737e+00
21Feb13_013136|   5.90991e-01 -2.13963e-01 -1.42807e+00 -1.91510e-01]
21Feb13_013136| [-9.48377e-01  1.45005e+00  6.23528e-01  9.24684e-01  8.68100e-01
21Feb13_013136|  -1.99460e+00  4.72527e-01  1.81921e+00 -1.50210e-01]
21Feb13_013136| [ 5.42301e-01  2.45411e-01  1.22571e+00 -1.22660e+00  2.00326e+00
21Feb13_013136|   1.28311e+00 -4.79063e-01 -1.26853e+00  3.54082e-01]
21Feb13_013136| [-9.68448e-02 -9.53055e-01 -6.39710e-01  7.39744e-02 -3.14837e-01
21Feb13_013136|  -4.64567e-01  8.27918e-01 -1.06114e+00 -5.10970e-01]
21Feb13_013136| [ 2.33279e-01  7.22497e-01  9.49373e-01 -1.20131e+00 -8.38683e-01
21Feb13_013136|  -5.38987e-01 -2.01753e+00  1.18580e+00 -7.12282e-01]
21Feb13_013136| [ 1.38078e+00 -3.07472e-01 -9.41548e-01  2.12287e+00  7.20946e-01
21Feb13_013136|   4.38905e-01  1.23216e+00  1.01939e+00  1.80698e-01]
21Feb13_013136| [-1.45026e-01  1.94626e+00 -1.81820e+00  1.49784e+00  7.71685e-01
21Feb13_013136|   1.57506e-01 -7.09054e-01 -3.76284e-02 -6.77940e-01]
21Feb13_013136| [-8.93030e-01  4.45952e-01 -5.02934e-01 -1.64437e+00  2.79315e-01
21Feb13_013136|  -1.03096e+00 -1.36068e+00 -4.50048e-01  2.88074e-01]]
21Feb13_013136|-- Bias --
21Feb13_013136|[ 0.37717  0.47788 -0.06014 -0.50820  0.52122 -0.91124 -1.67126 -0.64210
21Feb13_013136| -0.07185]
21Feb13_013136|Layer 1:
21Feb13_013136|-- Config --
21Feb13_013136|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 9], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_013136|-- Weights --
21Feb13_013136|[[ 0.68231 -0.74250]
21Feb13_013136| [ 0.62314  1.42898]
21Feb13_013136| [ 2.01695  1.97734]
21Feb13_013136| [-0.39663 -0.22189]
21Feb13_013136| [ 0.44922  0.41110]
21Feb13_013136| [ 0.33786  0.12545]
21Feb13_013136| [ 0.50773  1.87586]
21Feb13_013136| [-1.32230 -0.68529]
21Feb13_013136| [-0.06485  1.23686]]
21Feb13_013136|-- Bias --
21Feb13_013136|[-0.71772 -0.40861]
21Feb13_013136|Predicting the validation and test data with the Best final individual.
21Feb13_013144| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_013144|-----------  ------------------  --------------------  ----------
21Feb13_013144|Validation         41.74                  9             0.00775
21Feb13_013144|   Test            36.32                  9             0.00596
21Feb13_013144|-------------------- Test #14 --------------------
21Feb13_013144|Best final individual weights
21Feb13_013144|Individual:
21Feb13_013144|-- Constant hidden layers --
21Feb13_013144|False
21Feb13_013144|Layer 0:
21Feb13_013144|-- Config --
21Feb13_013144|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 9, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_013144|-- Weights --
21Feb13_013144|[[-4.61006e-01  6.85931e-01 -1.53413e+00  3.18540e-01  1.65279e+00
21Feb13_013144|  -3.98052e-01  4.33508e-01 -6.92513e-01  3.42704e-01]
21Feb13_013144| [-1.09470e+00  9.32382e-01  7.25102e-01 -4.91678e-01  1.53894e+00
21Feb13_013144|   6.32892e-01  1.66659e+00 -1.21771e+00 -3.90783e-01]
21Feb13_013144| [ 9.03759e-01 -9.77900e-01  1.77765e+00 -2.07879e-01 -3.69959e-01
21Feb13_013144|   2.57340e-02  9.32038e-01  1.80456e+00  3.87273e-01]
21Feb13_013144| [-3.49696e-01 -3.58058e-03 -6.07396e-01 -1.37181e+00 -1.10504e+00
21Feb13_013144|  -1.11474e+00 -1.03332e+00  2.23341e-01 -4.72876e-01]
21Feb13_013144| [ 2.32707e-01 -1.07579e+00 -5.40875e-01  1.42954e+00  6.10975e-01
21Feb13_013144|   5.59004e-01 -5.83178e-01  1.52584e+00 -2.61616e-02]
21Feb13_013144| [ 2.60802e-01  1.01484e+00 -3.13035e-03  3.59113e-01 -5.42962e-02
21Feb13_013144|   1.30419e-01 -1.43042e+00  3.06781e-01  4.02528e-01]
21Feb13_013144| [ 3.31900e-01 -7.68883e-01  2.16435e+00  5.44727e-01 -7.94370e-01
21Feb13_013144|   4.13300e-01  8.17497e-01  8.49172e-01  3.89172e-01]
21Feb13_013144| [-1.74100e+00 -1.34439e+00 -1.72034e-01  5.54274e-01  4.11878e-03
21Feb13_013144|  -1.72138e+00  1.21996e+00 -2.14134e-01 -1.29167e-01]
21Feb13_013144| [ 1.02404e+00  6.15020e-02 -2.14163e-01  3.45452e-02  5.64308e-01
21Feb13_013144|   1.23836e-01 -7.85150e-01 -2.34675e-01 -6.19357e-01]
21Feb13_013144| [ 3.39580e-01 -9.02752e-01 -1.40731e+00  1.01083e+00 -1.27692e+00
21Feb13_013144|  -3.87978e-01  2.91565e-01  7.80658e-01 -4.54186e-01]
21Feb13_013144| [-6.53637e-01  3.40165e-01  6.43150e-01 -4.23568e-01 -2.78934e-01
21Feb13_013144|  -9.34614e-02 -6.67337e-01  4.52195e-01  1.32123e+00]
21Feb13_013144| [-1.27502e+00  1.02666e+00 -4.87675e-01  8.02112e-01  2.39068e-01
21Feb13_013144|  -4.86850e-01  1.73530e+00 -1.15809e-01 -3.03472e-02]
21Feb13_013144| [-5.53044e-01  4.66997e-01  8.50262e-01 -9.72246e-01  5.75977e-01
21Feb13_013144|  -8.30986e-01  6.72198e-01 -1.48566e+00 -4.40186e-01]
21Feb13_013144| [ 1.56239e+00  4.89175e-02  3.52725e-01 -5.84369e-01  3.78056e-01
21Feb13_013144|  -1.08095e+00  2.25579e-01  1.36469e+00  1.05927e-01]
21Feb13_013144| [ 5.87912e-01 -6.66494e-01  7.79087e-01 -1.37734e+00 -5.68017e-02
21Feb13_013144|  -5.28526e-01 -2.16139e-01 -1.39364e-01 -1.22582e-01]
21Feb13_013144| [-3.25557e-01  7.27112e-02 -9.80921e-01  1.85031e-02 -2.87431e-01
21Feb13_013144|   1.76187e+00  1.29272e+00 -2.15986e+00 -3.48111e-02]
21Feb13_013144| [ 2.43878e-01  5.55203e-02  1.46280e+00 -6.81342e-01  6.28102e-01
21Feb13_013144|   7.31779e-01 -1.31015e+00  8.71093e-01 -4.54700e-01]
21Feb13_013144| [ 4.93144e-01  7.54375e-02 -1.20005e+00  6.27631e-02  7.82145e-01
21Feb13_013144|   5.33649e-01 -1.13427e+00  8.26364e-01 -1.48796e-01]
21Feb13_013144| [-4.21426e-01 -1.29212e-01 -8.75548e-01 -7.62601e-01 -5.40266e-01
21Feb13_013144|   1.80516e+00 -1.24863e+00  1.35354e+00 -3.30202e-02]
21Feb13_013144| [ 3.22391e-01 -5.16648e-01  1.97275e+00  3.26675e-01 -1.58735e-01
21Feb13_013144|  -1.86724e-01  3.96522e-01  6.89546e-01 -9.39432e-01]
21Feb13_013144| [-4.67129e-01  2.15586e+00 -5.38287e-01  2.78568e-01  9.42587e-01
21Feb13_013144|  -2.77032e-01  1.25393e+00  3.81716e-01  8.82734e-01]
21Feb13_013144| [-1.41583e+00 -1.45012e-01 -7.99630e-01 -5.31952e-01 -1.19693e+00
21Feb13_013144|   7.92286e-01  1.30639e-01 -2.37138e-01 -1.58410e+00]
21Feb13_013144| [-1.16444e+00 -5.22290e-01  1.02540e+00  3.99299e-01 -9.33985e-01
21Feb13_013144|   2.16709e+00  3.01229e-01 -7.56401e-01  1.21738e+00]
21Feb13_013144| [-4.96242e-01  1.99264e+00  1.72242e+00 -7.33992e-01  1.79053e+00
21Feb13_013144|   7.69467e-01  4.32490e-01  8.00370e-02 -1.48974e-01]
21Feb13_013144| [ 9.93945e-02 -1.39770e+00  2.13769e-01  1.86767e+00  1.11288e+00
21Feb13_013144|   6.22801e-01  3.99123e-01  6.84795e-01  2.17178e-01]
21Feb13_013144| [ 1.35578e+00  8.00580e-01  3.99488e-01  4.40513e-01  1.93473e-02
21Feb13_013144|  -4.51602e-01  2.87170e-01  3.29084e-02 -1.36035e+00]
21Feb13_013144| [-1.09101e+00  2.48048e+00  5.80244e-01 -1.33268e-01 -5.28168e-01
21Feb13_013144|   8.09824e-01 -4.30853e-01 -2.55311e-02  1.50016e+00]
21Feb13_013144| [ 5.18298e-02 -2.30052e-01  1.28184e+00 -2.64124e+00  3.01962e-01
21Feb13_013144|   1.55697e+00 -1.20762e+00  6.34586e-01 -1.58188e-01]
21Feb13_013144| [-1.72551e+00  1.63754e+00 -4.70755e-01 -1.15326e+00 -8.33712e-01
21Feb13_013144|   1.31472e+00  2.01820e-01 -2.33652e-01  2.10201e-01]
21Feb13_013144| [ 1.47803e-01  1.06813e-01 -7.00830e-02 -1.17159e+00 -1.10268e+00
21Feb13_013144|  -8.43557e-01  4.82005e-01  1.25841e+00  4.90572e-02]
21Feb13_013144| [-4.14468e-01 -9.13217e-01  1.43297e+00 -2.20598e-01 -5.00413e-02
21Feb13_013144|   1.00790e+00 -1.44685e+00  1.08882e-02  4.97447e-02]
21Feb13_013144| [ 8.57554e-01  1.16591e+00 -1.34007e-01  1.71257e+00 -1.12961e+00
21Feb13_013144|   1.37418e+00 -1.22028e+00 -6.84918e-01  7.78660e-01]
21Feb13_013144| [-7.13839e-01  1.40966e+00 -4.77517e-01 -1.19630e+00 -1.15371e+00
21Feb13_013144|  -3.93636e-01  3.23964e-01 -6.64234e-01  1.21979e+00]
21Feb13_013144| [ 1.74382e+00  1.33485e+00  1.78034e-01  9.41668e-02  2.62732e-01
21Feb13_013144|   8.78408e-01  2.48648e-01  1.21791e+00  4.85344e-01]
21Feb13_013144| [-5.31246e-01 -1.52761e-01  2.84841e-01 -2.19881e-01 -5.37130e-01
21Feb13_013144|  -5.76407e-01  9.54226e-01  4.85366e-01 -9.77571e-01]
21Feb13_013144| [-1.35084e+00  1.09906e+00 -6.32061e-01  1.77342e-01 -6.40846e-01
21Feb13_013144|  -3.03854e-02  1.66807e+00  3.12194e-02 -3.53426e-01]
21Feb13_013144| [ 9.50869e-01 -3.62129e-01  2.98314e-01  4.91118e-01 -1.57990e+00
21Feb13_013144|  -2.44973e+00  8.00915e-01  7.10599e-04  8.10353e-01]
21Feb13_013144| [ 1.78432e+00 -9.71843e-01 -1.97505e+00 -1.18986e+00 -2.70454e-01
21Feb13_013144|  -1.30340e+00  7.99598e-01 -2.84399e-01  2.78754e-01]
21Feb13_013144| [-6.25690e-01 -1.36899e+00 -1.69985e-01 -6.67490e-01 -1.83927e+00
21Feb13_013144|   7.29422e-01 -1.91879e+00  9.93721e-01  1.24720e-01]
21Feb13_013144| [-6.63423e-02 -1.59385e+00  1.31061e+00 -5.23944e-01 -9.22575e-01
21Feb13_013144|   1.02268e-01  4.40389e-01  7.93366e-01  8.34624e-01]
21Feb13_013144| [-3.15115e-01 -8.73738e-01  2.06436e-01 -4.60182e-01  3.67394e-01
21Feb13_013144|   8.74019e-01 -1.00027e+00 -7.35157e-01 -6.67303e-01]
21Feb13_013144| [ 2.59118e-01  1.24828e+00 -4.10084e-01  3.25478e-01 -1.34056e+00
21Feb13_013144|  -2.04943e+00 -8.99572e-02  1.63028e+00  5.09953e-01]
21Feb13_013144| [ 1.17609e-02 -8.36465e-01 -8.15524e-02  3.43689e-01 -9.21088e-01
21Feb13_013144|  -1.89687e+00 -1.24788e+00  1.11545e+00  9.05282e-01]
21Feb13_013144| [-1.50660e+00  6.36055e-01 -3.71286e-02  4.62230e-01  8.44458e-01
21Feb13_013144|  -1.52079e+00 -7.16504e-01  7.07441e-02 -1.03582e+00]
21Feb13_013144| [-3.32525e-02 -5.49366e-01  7.30336e-01  1.55130e+00  1.87862e+00
21Feb13_013144|   5.59851e-01  1.58186e+00  4.62385e-01  7.76501e-01]
21Feb13_013144| [-2.09596e+00  1.33953e+00 -1.51561e+00 -1.25216e+00 -1.00343e+00
21Feb13_013144|  -5.75715e-01  8.79691e-01 -1.53243e+00 -3.80041e-01]
21Feb13_013144| [ 1.61185e-01  5.12300e-01  1.59935e+00  1.06339e+00  7.93391e-01
21Feb13_013144|   2.53927e+00 -1.61466e+00 -1.69022e+00 -2.02367e-01]
21Feb13_013144| [-1.25470e+00 -2.58098e-01  5.92567e-01  3.37381e-01 -6.99700e-01
21Feb13_013144|   9.24420e-01  9.48337e-01 -8.98604e-01  9.35058e-01]
21Feb13_013144| [ 1.43861e+00  1.42065e+00 -9.84910e-01 -8.21470e-01 -5.79001e-02
21Feb13_013144|   6.47525e-01  8.65842e-01 -1.50544e-01 -5.53358e-01]
21Feb13_013144| [-6.20387e-01 -2.38812e-02 -1.35219e-01 -2.58836e-01 -1.37737e+00
21Feb13_013144|   5.90991e-01 -2.13963e-01 -1.42807e+00 -1.91510e-01]
21Feb13_013144| [-9.48377e-01  1.45005e+00  6.23528e-01  9.24684e-01  8.68100e-01
21Feb13_013144|  -1.99460e+00  4.72527e-01  1.81921e+00 -1.50210e-01]
21Feb13_013144| [ 5.42301e-01  2.45411e-01  1.22571e+00 -1.22660e+00  2.00326e+00
21Feb13_013144|   1.28311e+00 -4.79063e-01 -1.26853e+00  3.54082e-01]
21Feb13_013144| [-9.68448e-02 -9.53055e-01 -6.39710e-01  7.39744e-02 -3.14837e-01
21Feb13_013144|  -4.64567e-01  8.27918e-01 -1.06114e+00 -5.10970e-01]
21Feb13_013144| [ 2.33279e-01  7.22497e-01  9.49373e-01 -1.20131e+00 -8.38683e-01
21Feb13_013144|  -5.38987e-01 -2.01753e+00  1.18580e+00 -7.12282e-01]
21Feb13_013144| [ 1.38078e+00 -3.07472e-01 -9.41548e-01  2.12287e+00  7.20946e-01
21Feb13_013144|   4.38905e-01  1.23216e+00  1.01939e+00  1.80698e-01]
21Feb13_013144| [-1.45026e-01  1.94626e+00 -1.81820e+00  1.49784e+00  7.71685e-01
21Feb13_013144|   1.57506e-01 -7.09054e-01 -3.76284e-02 -6.77940e-01]
21Feb13_013144| [-8.93030e-01  4.45952e-01 -5.02934e-01 -1.64437e+00  2.79315e-01
21Feb13_013144|  -1.03096e+00 -1.36068e+00 -4.50048e-01  2.88074e-01]]
21Feb13_013144|-- Bias --
21Feb13_013144|[ 0.37717  0.47788 -0.06014 -0.50820  0.52122 -0.91124 -1.67126 -0.64210
21Feb13_013144| -0.07185]
21Feb13_013144|Layer 1:
21Feb13_013144|-- Config --
21Feb13_013144|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 9], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_013144|-- Weights --
21Feb13_013144|[[ 0.68231 -0.74250]
21Feb13_013144| [ 0.62314  1.42898]
21Feb13_013144| [ 2.01695  1.97734]
21Feb13_013144| [-0.39663 -0.22189]
21Feb13_013144| [ 0.44922  0.41110]
21Feb13_013144| [ 0.33786  0.12545]
21Feb13_013144| [ 0.50773  1.87586]
21Feb13_013144| [-1.32230 -0.68529]
21Feb13_013144| [-0.06485  1.23686]]
21Feb13_013144|-- Bias --
21Feb13_013144|[-0.71772 -0.40861]
21Feb13_013144|Predicting the validation and test data with the Best final individual.
21Feb13_013151| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_013151|-----------  ------------------  --------------------  ----------
21Feb13_013151|Validation         42.00                  9             0.00259
21Feb13_013151|   Test            36.32                  9             0.00596
2021-02-13 01:31:51.833182: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
21Feb13_013152|Data summary: Train
21Feb13_013152|data.shape = (2300, 57)
21Feb13_013152|labels.shape = (2300,)
21Feb13_013152|Class distribution:
21Feb13_013152|	0 - 1389 (0.60)
21Feb13_013152|	1 - 911 (0.40)
21Feb13_013152|Data summary: Validation
21Feb13_013152|data.shape = (1150, 57)
21Feb13_013152|labels.shape = (1150,)
21Feb13_013152|Class distribution:
21Feb13_013152|	0 - 667 (0.58)
21Feb13_013152|	1 - 483 (0.42)
21Feb13_013152|Data summary: Test
21Feb13_013152|data.shape = (1151, 57)
21Feb13_013152|labels.shape = (1151,)
21Feb13_013152|Class distribution:
21Feb13_013152|	0 - 732 (0.64)
21Feb13_013152|	1 - 419 (0.36)
21Feb13_013152|Selected configuration values
21Feb13_013152|-- Dataset name: spambase2
21Feb13_013152|-- Initial population size: 64
21Feb13_013152|-- Maximun number of generations: 32
21Feb13_013152|-- Neurons per hidden layer range: (2, 20)
21Feb13_013152|-- Hidden layers number range: (1, 3)
21Feb13_013152|-- Crossover probability: 0.5
21Feb13_013152|-- Bias gene mutation probability: 0.2
21Feb13_013152|-- Weights gene mutation probability: 0.75
21Feb13_013152|-- Neuron mutation probability: 0.3
21Feb13_013152|-- Layer mutation probability: 0.3
21Feb13_013152|-- Constant hidden layers: False
21Feb13_013152|-- Seed: 31415
21Feb13_013152|Entering GA
21Feb13_013152|Start the algorithm
2021-02-13 01:31:52.689878: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-13 01:31:52.690476: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-02-13 01:31:52.711314: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-13 01:31:52.711644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.71GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s
2021-02-13 01:31:52.711662: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-02-13 01:31:52.713279: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-02-13 01:31:52.713312: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-02-13 01:31:52.713878: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-02-13 01:31:52.714013: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-02-13 01:31:52.714084: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-13 01:31:52.714507: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-02-13 01:31:52.714549: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-13 01:31:52.714555: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-02-13 01:31:52.714756: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-02-13 01:31:52.715637: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-13 01:31:52.715659: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-13 01:31:52.715666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      
2021-02-13 01:31:52.768065: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-02-13 01:31:52.768386: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3493635000 Hz
/home/jmerelo/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype("int32")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn('`model.predict_classes()` is deprecated and '
21Feb13_013555|-- Generation 1 --
21Feb13_013555|    -- Crossed 0 individual pairs.
21Feb13_013555|    -- Mutated 32 individuals.
21Feb13_013953|    -- Evaluated 64 individuals.
21Feb13_013953|    Summary of generation 1:
21Feb13_013953| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_013953|-----------  ------------------  --------------------  ----------
21Feb13_013953|    Max            55.04                126.00          0.79120
21Feb13_013953|    Avg            42.18                34.72           0.01422
21Feb13_013953|    Min            41.39                 2.00           0.00000
21Feb13_013953|    Std             1.63                31.54           0.09797
21Feb13_013953|   Best            41.39                 8.00           0.01805
21Feb13_013953|-- Generation 2 --
21Feb13_013953|    -- Crossed 1 individual pairs.
21Feb13_013953|    -- Mutated 32 individuals.
21Feb13_014343|    -- Evaluated 64 individuals.
21Feb13_014343|    Summary of generation 2:
21Feb13_014343| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_014343|-----------  ------------------  --------------------  ----------
21Feb13_014343|    Max            42.78                60.00           0.42739
21Feb13_014343|    Avg            41.81                16.45           0.00821
21Feb13_014343|    Min            30.87                 2.00           0.00000
21Feb13_014343|    Std             1.39                13.99           0.05290
21Feb13_014343|   Best            30.87                26.00           0.42739
21Feb13_014343|-- Generation 3 --
21Feb13_014343|    -- Crossed 1 individual pairs.
21Feb13_014343|    -- Mutated 32 individuals.
21Feb13_014732|    -- Evaluated 64 individuals.
21Feb13_014732|    Summary of generation 3:
21Feb13_014732| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_014732|-----------  ------------------  --------------------  ----------
21Feb13_014732|    Max            42.17                60.00           0.06304
21Feb13_014732|    Avg            41.96                12.08           0.00288
21Feb13_014732|    Min            41.39                 2.00           0.00000
21Feb13_014732|    Std             0.12                13.46           0.00834
21Feb13_014732|   Best            41.39                 8.00           0.01805
21Feb13_014732|-- Generation 4 --
21Feb13_014732|    -- Crossed 3 individual pairs.
21Feb13_014732|    -- Mutated 32 individuals.
21Feb13_015121|    -- Evaluated 64 individuals.
21Feb13_015121|    Summary of generation 4:
21Feb13_015121| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_015121|-----------  ------------------  --------------------  ----------
21Feb13_015121|    Max            42.61                48.00           0.02061
21Feb13_015121|    Avg            41.97                 9.52           0.00214
21Feb13_015121|    Min            41.39                 2.00           0.00000
21Feb13_015121|    Std             0.17                 9.20           0.00424
21Feb13_015121|   Best            41.39                 8.00           0.01805
21Feb13_015121|-- Generation 5 --
21Feb13_015121|    -- Crossed 2 individual pairs.
21Feb13_015121|    -- Mutated 32 individuals.
21Feb13_015509|    -- Evaluated 64 individuals.
21Feb13_015509|    Summary of generation 5:
21Feb13_015509| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_015509|-----------  ------------------  --------------------  ----------
21Feb13_015509|    Max            42.09                34.00           0.45310
21Feb13_015509|    Avg            41.76                 9.47           0.00974
21Feb13_015509|    Min            30.35                 2.00           0.00000
21Feb13_015509|    Std             1.45                 9.50           0.05613
21Feb13_015509|   Best            30.35                14.00           0.45310
21Feb13_015509|-- Generation 6 --
21Feb13_015509|    -- Crossed 5 individual pairs.
21Feb13_015509|    -- Mutated 32 individuals.
21Feb13_015858|    -- Evaluated 64 individuals.
21Feb13_015858|    Summary of generation 6:
21Feb13_015858| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_015858|-----------  ------------------  --------------------  ----------
21Feb13_015858|    Max            43.04                36.00           0.46119
21Feb13_015858|    Avg            41.79                 7.52           0.00974
21Feb13_015858|    Min            29.30                 2.00           0.00000
21Feb13_015858|    Std             1.59                 6.55           0.05718
21Feb13_015858|   Best            29.30                14.00           0.46119
21Feb13_015858|-- Generation 7 --
21Feb13_015858|    -- Crossed 8 individual pairs.
21Feb13_015858|    -- Mutated 32 individuals.
21Feb13_020247|    -- Evaluated 64 individuals.
21Feb13_020247|    Summary of generation 7:
21Feb13_020247| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_020247|-----------  ------------------  --------------------  ----------
21Feb13_020247|    Max            42.26                24.00           0.00517
21Feb13_020247|    Avg            41.99                 6.03           0.00105
21Feb13_020247|    Min            41.83                 2.00           0.00000
21Feb13_020247|    Std             0.08                 5.57           0.00169
21Feb13_020247|   Best            41.83                10.00           0.00517
21Feb13_020247|-- Generation 8 --
21Feb13_020247|    -- Crossed 8 individual pairs.
21Feb13_020247|    -- Mutated 32 individuals.
21Feb13_020634|    -- Evaluated 64 individuals.
21Feb13_020634|    Summary of generation 8:
21Feb13_020634| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_020634|-----------  ------------------  --------------------  ----------
21Feb13_020634|    Max            42.09                18.00           0.02062
21Feb13_020634|    Avg            41.96                 5.67           0.00194
21Feb13_020634|    Min            41.30                 2.00           0.00000
21Feb13_020634|    Std             0.10                 4.39           0.00322
21Feb13_020634|   Best            41.30                 3.00           0.02062
21Feb13_020634|-- Generation 9 --
21Feb13_020634|    -- Crossed 4 individual pairs.
21Feb13_020634|    -- Mutated 32 individuals.
21Feb13_021023|    -- Evaluated 64 individuals.
21Feb13_021023|    Summary of generation 9:
21Feb13_021023| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_021023|-----------  ------------------  --------------------  ----------
21Feb13_021023|    Max            42.09                32.00           0.02061
21Feb13_021023|    Avg            41.96                 8.36           0.00238
21Feb13_021023|    Min            41.39                 2.00           0.00000
21Feb13_021023|    Std             0.11                 6.88           0.00406
21Feb13_021023|   Best            41.39                11.00           0.02061
21Feb13_021023|-- Generation 10 --
21Feb13_021023|    -- Crossed 2 individual pairs.
21Feb13_021023|    -- Mutated 32 individuals.
21Feb13_021410|    -- Evaluated 64 individuals.
21Feb13_021410|    Summary of generation 10:
21Feb13_021410| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_021410|-----------  ------------------  --------------------  ----------
21Feb13_021410|    Max            42.26                30.00           0.82084
21Feb13_021410|    Avg            41.96                 6.59           0.01549
21Feb13_021410|    Min            41.57                 2.00           0.00000
21Feb13_021410|    Std             0.10                 5.42           0.10152
21Feb13_021410|   Best            41.57                14.00           0.82084
21Feb13_021410|-- Generation 11 --
21Feb13_021410|    -- Crossed 4 individual pairs.
21Feb13_021410|    -- Mutated 32 individuals.
21Feb13_021759|    -- Evaluated 64 individuals.
21Feb13_021759|    Summary of generation 11:
21Feb13_021759| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_021759|-----------  ------------------  --------------------  ----------
21Feb13_021759|    Max            54.61                30.00           0.82955
21Feb13_021759|    Avg            42.13                 9.70           0.02805
21Feb13_021759|    Min            40.35                 2.00           0.00000
21Feb13_021759|    Std             1.59                 7.71           0.14072
21Feb13_021759|   Best            40.35                14.00           0.82955
21Feb13_021759|-- Generation 12 --
21Feb13_021759|    -- Crossed 4 individual pairs.
21Feb13_021759|    -- Mutated 32 individuals.
21Feb13_022148|    -- Evaluated 64 individuals.
21Feb13_022148|    Summary of generation 12:
21Feb13_022148| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_022148|-----------  ------------------  --------------------  ----------
21Feb13_022148|    Max            50.43                33.00           0.80181
21Feb13_022148|    Avg            41.88                 9.75           0.02706
21Feb13_022148|    Min            27.83                 2.00           0.00000
21Feb13_022148|    Std             2.06                 7.87           0.13387
21Feb13_022148|   Best            27.83                16.00           0.74155
21Feb13_022148|-- Generation 13 --
21Feb13_022148|    -- Crossed 3 individual pairs.
21Feb13_022148|    -- Mutated 32 individuals.
21Feb13_022536|    -- Evaluated 64 individuals.
21Feb13_022536|    Summary of generation 13:
21Feb13_022536| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_022536|-----------  ------------------  --------------------  ----------
21Feb13_022536|    Max            42.09                32.00           0.04105
21Feb13_022536|    Avg            41.90                10.09           0.00387
21Feb13_022536|    Min            40.70                 2.00           0.00000
21Feb13_022536|    Std             0.17                 7.90           0.00531
21Feb13_022536|   Best            40.70                14.00           0.04105
21Feb13_022536|-- Generation 14 --
21Feb13_022536|    -- Crossed 5 individual pairs.
21Feb13_022536|    -- Mutated 32 individuals.
21Feb13_022924|    -- Evaluated 64 individuals.
21Feb13_022924|    Summary of generation 14:
21Feb13_022924| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_022924|-----------  ------------------  --------------------  ----------
21Feb13_022924|    Max            42.87                32.00           0.03082
21Feb13_022924|    Avg            41.94                 7.92           0.00331
21Feb13_022924|    Min            41.22                 2.00           0.00000
21Feb13_022924|    Std             0.17                 6.01           0.00446
21Feb13_022924|   Best            41.22                 9.00           0.03082
21Feb13_022924|-- Generation 15 --
21Feb13_022924|    -- Crossed 6 individual pairs.
21Feb13_022924|    -- Mutated 32 individuals.
21Feb13_023313|    -- Evaluated 64 individuals.
21Feb13_023313|    Summary of generation 15:
21Feb13_023313| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_023313|-----------  ------------------  --------------------  ----------
21Feb13_023313|    Max            42.09                42.00           0.02062
21Feb13_023313|    Avg            41.91                 8.66           0.00399
21Feb13_023313|    Min            41.30                 2.00           0.00000
21Feb13_023313|    Std             0.12                 7.67           0.00439
21Feb13_023313|   Best            41.30                11.00           0.02062
21Feb13_023313|-- Generation 16 --
21Feb13_023313|    -- Crossed 4 individual pairs.
21Feb13_023313|    -- Mutated 32 individuals.
21Feb13_023702|    -- Evaluated 64 individuals.
21Feb13_023702|    Summary of generation 16:
21Feb13_023702| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_023702|-----------  ------------------  --------------------  ----------
21Feb13_023702|    Max            42.17                68.00           0.01800
21Feb13_023702|    Avg            41.94                10.17           0.00311
21Feb13_023702|    Min            41.74                 2.00           0.00000
21Feb13_023702|    Std             0.09                10.74           0.00316
21Feb13_023702|   Best            41.74                 8.00           0.00775
21Feb13_023702|-- Generation 17 --
21Feb13_023702|    -- Crossed 3 individual pairs.
21Feb13_023702|    -- Mutated 32 individuals.
21Feb13_024052|    -- Evaluated 64 individuals.
21Feb13_024052|    Summary of generation 17:
21Feb13_024052| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_024052|-----------  ------------------  --------------------  ----------
21Feb13_024052|    Max            42.26                76.00           0.67512
21Feb13_024052|    Avg            41.74                 9.08           0.01382
21Feb13_024052|    Min            29.13                 2.00           0.00000
21Feb13_024052|    Std             1.59                11.06           0.08337
21Feb13_024052|   Best            29.13                76.00           0.67512
21Feb13_024052|-- Generation 18 --
21Feb13_024052|    -- Crossed 4 individual pairs.
21Feb13_024052|    -- Mutated 32 individuals.
21Feb13_024441|    -- Evaluated 64 individuals.
21Feb13_024441|    Summary of generation 18:
21Feb13_024441| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_024441|-----------  ------------------  --------------------  ----------
21Feb13_024441|    Max            42.09                76.00           0.78302
21Feb13_024441|    Avg            41.68                 9.34           0.01575
21Feb13_024441|    Min            27.30                 2.00           0.00000
21Feb13_024441|    Std             1.81                13.08           0.09671
21Feb13_024441|   Best            27.30                16.00           0.78302
21Feb13_024441|-- Generation 19 --
21Feb13_024441|    -- Crossed 6 individual pairs.
21Feb13_024441|    -- Mutated 32 individuals.
21Feb13_024828|    -- Evaluated 64 individuals.
21Feb13_024828|    Summary of generation 19:
21Feb13_024828| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_024828|-----------  ------------------  --------------------  ----------
21Feb13_024828|    Max            42.26                30.00           0.01033
21Feb13_024828|    Avg            41.91                 8.36           0.00384
21Feb13_024828|    Min            41.65                 2.00           0.00000
21Feb13_024828|    Std             0.09                 6.66           0.00266
21Feb13_024828|   Best            41.65                 8.00           0.01033
21Feb13_024828|-- Generation 20 --
21Feb13_024828|    -- Crossed 4 individual pairs.
21Feb13_024828|    -- Mutated 32 individuals.
21Feb13_025217|    -- Evaluated 64 individuals.
21Feb13_025217|    Summary of generation 20:
21Feb13_025217| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_025217|-----------  ------------------  --------------------  ----------
21Feb13_025217|    Max            42.17                30.00           0.56466
21Feb13_025217|    Avg            41.72                 7.50           0.01310
21Feb13_025217|    Min            30.17                 2.00           0.00000
21Feb13_025217|    Std             1.46                 6.19           0.06963
21Feb13_025217|   Best            30.17                12.00           0.56466
21Feb13_025217|-- Generation 21 --
21Feb13_025217|    -- Crossed 5 individual pairs.
21Feb13_025217|    -- Mutated 32 individuals.
21Feb13_025604|    -- Evaluated 64 individuals.
21Feb13_025604|    Summary of generation 21:
21Feb13_025604| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_025604|-----------  ------------------  --------------------  ----------
21Feb13_025604|    Max            42.17                30.00           0.79718
21Feb13_025604|    Avg            41.90                 7.58           0.01677
21Feb13_025604|    Min            41.30                 2.00           0.00000
21Feb13_025604|    Std             0.13                 6.12           0.09839
21Feb13_025604|   Best            41.30                 8.00           0.02062
21Feb13_025604|-- Generation 22 --
21Feb13_025604|    -- Crossed 6 individual pairs.
21Feb13_025604|    -- Mutated 32 individuals.
21Feb13_025953|    -- Evaluated 64 individuals.
21Feb13_025953|    Summary of generation 22:
21Feb13_025953| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_025953|-----------  ------------------  --------------------  ----------
21Feb13_025953|    Max            42.26                30.00           0.01033
21Feb13_025953|    Avg            41.90                 9.19           0.00428
21Feb13_025953|    Min            41.65                 2.00           0.00000
21Feb13_025953|    Std             0.11                 7.39           0.00300
21Feb13_025953|   Best            41.65                 8.00           0.01033
21Feb13_025953|-- Generation 23 --
21Feb13_025953|    -- Crossed 3 individual pairs.
21Feb13_025953|    -- Mutated 32 individuals.
21Feb13_030341|    -- Evaluated 64 individuals.
21Feb13_030341|    Summary of generation 23:
21Feb13_030341| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_030341|-----------  ------------------  --------------------  ----------
21Feb13_030341|    Max            42.09                30.00           0.01803
21Feb13_030341|    Avg            41.89                 8.22           0.00480
21Feb13_030341|    Min            41.57                 2.00           0.00000
21Feb13_030341|    Std             0.10                 6.71           0.00305
21Feb13_030341|   Best            41.57                 4.00           0.01803
21Feb13_030341|-- Generation 24 --
21Feb13_030341|    -- Crossed 9 individual pairs.
21Feb13_030341|    -- Mutated 32 individuals.
21Feb13_030729|    -- Evaluated 64 individuals.
21Feb13_030729|    Summary of generation 24:
21Feb13_030729| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_030729|-----------  ------------------  --------------------  ----------
21Feb13_030729|    Max            42.17                51.00           0.01805
21Feb13_030729|    Avg            41.87                 9.02           0.00521
21Feb13_030729|    Min            41.39                 2.00           0.00000
21Feb13_030729|    Std             0.12                 8.43           0.00330
21Feb13_030729|   Best            41.39                 8.00           0.01805
21Feb13_030729|-- Generation 25 --
21Feb13_030729|    -- Crossed 3 individual pairs.
21Feb13_030729|    -- Mutated 32 individuals.
21Feb13_031118|    -- Evaluated 64 individuals.
21Feb13_031118|    Summary of generation 25:
21Feb13_031118| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_031118|-----------  ------------------  --------------------  ----------
21Feb13_031118|    Max            42.17                51.00           0.01804
21Feb13_031118|    Avg            41.87                10.39           0.00529
21Feb13_031118|    Min            41.48                 2.00           0.00000
21Feb13_031118|    Std             0.13                 8.50           0.00349
21Feb13_031118|   Best            41.48                10.00           0.01804
21Feb13_031118|-- Generation 26 --
21Feb13_031118|    -- Crossed 3 individual pairs.
21Feb13_031118|    -- Mutated 32 individuals.
21Feb13_031507|    -- Evaluated 64 individuals.
21Feb13_031507|    Summary of generation 26:
21Feb13_031507| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_031507|-----------  ------------------  --------------------  ----------
21Feb13_031507|    Max            42.09                32.00           0.02317
21Feb13_031507|    Avg            41.87                10.52           0.00553
21Feb13_031507|    Min            41.30                 2.00           0.00000
21Feb13_031507|    Std             0.13                 7.24           0.00400
21Feb13_031507|   Best            41.30                10.00           0.02317
21Feb13_031507|-- Generation 27 --
21Feb13_031507|    -- Crossed 3 individual pairs.
21Feb13_031507|    -- Mutated 32 individuals.
21Feb13_031857|    -- Evaluated 64 individuals.
21Feb13_031857|    Summary of generation 27:
21Feb13_031857| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_031857|-----------  ------------------  --------------------  ----------
21Feb13_031857|    Max            42.17                30.00           0.01033
21Feb13_031857|    Avg            41.87                 9.88           0.00561
21Feb13_031857|    Min            41.65                 3.00           0.00000
21Feb13_031857|    Std             0.11                 6.66           0.00283
21Feb13_031857|   Best            41.65                 7.00           0.01033
21Feb13_031857|-- Generation 28 --
21Feb13_031857|    -- Crossed 7 individual pairs.
21Feb13_031857|    -- Mutated 32 individuals.
21Feb13_032244|    -- Evaluated 64 individuals.
21Feb13_032244|    Summary of generation 28:
21Feb13_032244| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_032244|-----------  ------------------  --------------------  ----------
21Feb13_032244|    Max            42.17                36.00           0.01291
21Feb13_032244|    Avg            41.82                 8.72           0.00642
21Feb13_032244|    Min            41.57                 4.00           0.00000
21Feb13_032244|    Std             0.11                 5.52           0.00313
21Feb13_032244|   Best            41.57                12.00           0.01291
21Feb13_032244|-- Generation 29 --
21Feb13_032244|    -- Crossed 7 individual pairs.
21Feb13_032244|    -- Mutated 32 individuals.
21Feb13_032633|    -- Evaluated 64 individuals.
21Feb13_032633|    Summary of generation 29:
21Feb13_032633| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_032633|-----------  ------------------  --------------------  ----------
21Feb13_032633|    Max            42.09                26.00           0.05333
21Feb13_032633|    Avg            41.83                 9.00           0.00697
21Feb13_032633|    Min            41.57                 3.00           0.00000
21Feb13_032633|    Std             0.13                 5.23           0.00682
21Feb13_032633|   Best            41.57                12.00           0.01547
21Feb13_032633|-- Generation 30 --
21Feb13_032633|    -- Crossed 4 individual pairs.
21Feb13_032633|    -- Mutated 32 individuals.
21Feb13_033021|    -- Evaluated 64 individuals.
21Feb13_033021|    Summary of generation 30:
21Feb13_033021| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_033021|-----------  ------------------  --------------------  ----------
21Feb13_033021|    Max            42.17                32.00           0.63410
21Feb13_033021|    Avg            41.57                 9.58           0.01660
21Feb13_033021|    Min            25.48                 4.00           0.00000
21Feb13_033021|    Std             2.03                 6.09           0.07791
21Feb13_033021|   Best            25.48                24.00           0.63410
21Feb13_033021|-- Generation 31 --
21Feb13_033021|    -- Crossed 5 individual pairs.
21Feb13_033021|    -- Mutated 32 individuals.
21Feb13_033410|    -- Evaluated 64 individuals.
21Feb13_033410|    Summary of generation 31:
21Feb13_033410| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_033410|-----------  ------------------  --------------------  ----------
21Feb13_033410|    Max            42.26                45.00           0.02316
21Feb13_033410|    Avg            41.81                 9.58           0.00678
21Feb13_033410|    Min            41.39                 3.00           0.00000
21Feb13_033410|    Std             0.15                 7.33           0.00409
21Feb13_033410|   Best            41.39                 6.00           0.02316
21Feb13_033410|-- Generation 32 --
21Feb13_033410|    -- Crossed 7 individual pairs.
21Feb13_033410|    -- Mutated 32 individuals.
21Feb13_033800|    -- Evaluated 64 individuals.
21Feb13_033800|    Summary of generation 32:
21Feb13_033800| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_033800|-----------  ------------------  --------------------  ----------
21Feb13_033800|    Max            42.26                28.00           0.02318
21Feb13_033800|    Avg            41.80                10.34           0.00730
21Feb13_033800|    Min            41.22                 4.00           0.00000
21Feb13_033800|    Std             0.17                 5.92           0.00470
21Feb13_033800|   Best            41.22                 6.00           0.02318
21Feb13_033800|Best initial individual weights
21Feb13_033800|Individual:
21Feb13_033800|-- Constant hidden layers --
21Feb13_033800|False
21Feb13_033800|Layer 0:
21Feb13_033800|-- Config --
21Feb13_033800|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_033800|-- Weights --
21Feb13_033800|[[-0.27202 -0.86357 -0.55480 -0.23305 -0.86065  0.00935]
21Feb13_033800| [ 0.79962  0.37670  0.29685  0.27749  0.49011 -0.69201]
21Feb13_033800| [ 0.14479  0.91685 -0.48781  0.43998  0.63560 -0.30697]
21Feb13_033800| [ 0.38698  0.86287 -0.71294  0.64752 -0.03047 -0.77785]
21Feb13_033800| [ 0.48209  0.66076  0.64751  0.81042 -0.07483  0.42515]
21Feb13_033800| [ 0.55955 -0.47655 -0.07712 -0.63479 -0.35794  0.52636]
21Feb13_033800| [ 0.38576  0.23223  0.25353  0.73450 -0.90178 -0.96369]
21Feb13_033800| [ 0.11039  0.36714  0.33686  0.01774  0.45868  0.81669]
21Feb13_033800| [-0.79637  0.26224 -0.03232  0.48232 -0.15309  0.61156]
21Feb13_033800| [-0.88621  0.90413  0.87744 -0.64355 -0.40369 -0.97981]
21Feb13_033800| [-0.68940  0.06179 -0.18424  0.08150 -0.45878  0.41370]
21Feb13_033800| [-0.36044 -0.13559  0.65226 -0.07204  0.54308  0.16062]
21Feb13_033800| [ 0.11714  0.93671 -0.29633  0.99754  0.45369 -0.70753]
21Feb13_033800| [ 0.64728 -0.33413 -0.57208 -0.73568  0.75425 -0.55104]
21Feb13_033800| [-0.99999 -0.96058  0.33387  0.28233 -0.17633  0.03884]
21Feb13_033800| [-0.31698 -0.57029  0.10048  0.21559 -0.52309  0.33687]
21Feb13_033800| [ 0.61192 -0.96178 -0.06414 -0.36741  0.15685  0.02906]
21Feb13_033800| [-0.75997 -0.73378  0.49810  0.83880 -0.83756 -0.54574]
21Feb13_033800| [ 0.84699 -0.24948  0.54050  0.73535 -0.06642 -0.14727]
21Feb13_033800| [-0.94868 -0.55371 -0.60216  0.40726 -0.98034 -0.48830]
21Feb13_033800| [ 0.83709 -0.79262  0.03398 -0.48243 -0.43785 -0.35972]
21Feb13_033800| [-0.44328  0.52441 -0.25583  0.35182 -0.83091 -0.39106]
21Feb13_033800| [-0.15833  0.20269  0.54130 -0.37920  0.09680  0.17172]
21Feb13_033800| [ 0.39523 -0.09539 -0.94133 -0.81601 -0.29414  0.09808]
21Feb13_033800| [ 0.86566 -0.82514  0.72303  0.62921 -0.61237  0.81126]
21Feb13_033800| [ 0.76870  0.06416 -0.11886 -0.75631 -0.12365 -0.72666]
21Feb13_033800| [ 0.89288  0.41306 -0.54112  0.04405 -0.79963  0.73224]
21Feb13_033800| [ 0.93553  0.89126 -0.61857  0.87545 -0.23947  0.75701]
21Feb13_033800| [-0.82086  0.81521  0.86256 -0.74272 -0.12443 -0.22844]
21Feb13_033800| [ 0.97160  0.41439 -0.41378 -0.28541  0.97440  0.41257]
21Feb13_033800| [ 0.70964  0.93589  0.10477  0.43589 -0.53252 -0.32168]
21Feb13_033800| [ 0.78787 -0.33435  0.99010 -0.65538  0.82368  0.49009]
21Feb13_033800| [ 0.22751  0.13008 -0.77326 -0.52830  0.50907  0.36905]
21Feb13_033800| [-0.27162 -0.36135  0.67608 -0.27532  0.90150  0.01127]
21Feb13_033800| [ 0.32844  0.99962 -0.09280  0.45964  0.99188 -0.46898]
21Feb13_033800| [-0.18508  0.43122 -0.20933  0.22437 -0.38523 -0.93105]
21Feb13_033800| [-0.71925  0.06113  0.19689 -0.43143 -0.18550 -0.84294]
21Feb13_033800| [-0.26779 -0.36079  0.46561  0.91330  0.52255 -0.08778]
21Feb13_033800| [-0.77037  0.39767  0.64833 -0.98560  0.46858  0.31212]
21Feb13_033800| [-0.85160 -0.84100 -0.57533 -0.89125 -0.26714 -0.03784]
21Feb13_033800| [-0.45978 -0.09001 -0.25873 -0.50100  0.50007  0.36246]
21Feb13_033800| [ 0.24085  0.09905  0.63589  0.41544  0.94690 -0.17740]
21Feb13_033800| [ 0.37276 -0.55653  0.03085 -0.57053  0.64921  0.77760]
21Feb13_033800| [-0.15149  0.70665 -0.89632  0.21282 -0.46831 -0.02174]
21Feb13_033800| [-0.90518 -0.77970  0.95331  0.59768  0.52171 -0.16887]
21Feb13_033800| [-0.91831  0.02967 -0.06979  0.13512 -0.23631 -0.64488]
21Feb13_033800| [ 0.97479 -0.94377  0.06324  0.51263  0.92015  0.33195]
21Feb13_033800| [-0.23392  0.17446 -0.00269  0.39550  0.16762  0.49246]
21Feb13_033800| [-0.38197 -0.12955 -0.15881  0.40103 -0.44224  0.28044]
21Feb13_033800| [-0.18428 -0.43672  0.17268 -0.61813  0.37910  0.10582]
21Feb13_033800| [-0.90436 -0.34919  0.78535  0.66625 -0.73042 -0.71018]
21Feb13_033800| [ 0.51032 -0.77746 -0.44325  0.84430 -0.30217 -0.29958]
21Feb13_033800| [ 0.68940  0.61874 -0.16478 -0.15758 -0.13000  0.90632]
21Feb13_033800| [ 0.03548 -0.47831  0.42708 -0.16343 -0.95208  0.69563]
21Feb13_033800| [-0.01411  0.20035  0.12539 -0.96161  0.92710 -0.77067]
21Feb13_033800| [ 0.81703  0.44147  0.72058 -0.81223 -0.67418 -0.85267]
21Feb13_033800| [-0.26530  0.72399 -0.58999 -0.15740  0.39892 -0.58918]]
21Feb13_033800|-- Bias --
21Feb13_033800|[ 0.23050  0.64820 -0.64277 -0.41900 -0.54681  0.15437]
21Feb13_033800|Layer 1:
21Feb13_033800|-- Config --
21Feb13_033800|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 7, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_033800|-- Weights --
21Feb13_033800|[[-0.50321 -0.80875 -0.60144 -0.65045  0.61886 -0.77767  0.32772]
21Feb13_033800| [-0.04845 -0.89529  0.64487 -0.62765 -0.63134  0.05243 -0.44669]
21Feb13_033800| [-0.43718  0.21711  0.81639 -0.51368 -0.99854 -0.22537  0.94769]
21Feb13_033800| [-0.24806 -0.09443  0.39011  0.48081 -0.14372 -0.70297 -0.89667]
21Feb13_033800| [ 0.70687  0.42155  0.18340 -0.17501  0.52040  0.16771  0.10606]
21Feb13_033800| [ 0.44794  0.33101  0.53886 -0.17021  0.78118 -0.81555  0.43746]]
21Feb13_033800|-- Bias --
21Feb13_033800|[-0.73477  0.09614 -0.39402 -0.10087  0.57570 -0.12327  0.59815]
21Feb13_033800|Layer 2:
21Feb13_033800|-- Config --
21Feb13_033800|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 7], 'dtype': 'float32', 'units': 10, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_033800|-- Weights --
21Feb13_033800|[[ 0.31908 -0.68092  0.42155  0.77600 -0.73710 -0.39887 -0.07843  0.23743
21Feb13_033800|   0.15714 -0.76581]
21Feb13_033800| [ 0.86369 -0.12993 -0.24148  0.53900  0.76709  0.96250 -0.56779 -0.90161
21Feb13_033800|  -0.05478 -0.07884]
21Feb13_033800| [ 0.55244  0.08052  0.06876 -0.21762  0.03301  0.12657 -0.10267 -0.45140
21Feb13_033800|   0.74279 -0.68060]
21Feb13_033800| [-0.82927  0.38658 -0.24283 -0.60293  0.98747 -0.55144  0.76581  0.09305
21Feb13_033800|   0.25851  0.32179]
21Feb13_033800| [ 0.50403 -0.55046  0.84432 -0.88204 -0.35981  0.51384 -0.70348  0.60683
21Feb13_033800|  -0.43326  0.96808]
21Feb13_033800| [-0.55850  0.68494  0.22628  0.92543 -0.20070  0.79557  0.78836  0.80610
21Feb13_033800|   0.78859 -0.65676]
21Feb13_033800| [-0.65413 -0.45252 -0.64423  0.93837  0.67689 -0.63509 -0.98556 -0.70209
21Feb13_033800|   0.15696  0.38727]]
21Feb13_033800|-- Bias --
21Feb13_033800|[ 0.74117  0.06232 -0.97740  0.25194  0.96653  0.46481  0.25293  0.37737
21Feb13_033800| -0.98026 -0.39274]
21Feb13_033800|Layer 3:
21Feb13_033800|-- Config --
21Feb13_033800|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 10], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_033800|-- Weights --
21Feb13_033800|[[ 0.00457 -0.86221]
21Feb13_033800| [ 0.78832  0.80619]
21Feb13_033800| [ 0.15057 -0.18753]
21Feb13_033800| [ 0.89929 -0.85656]
21Feb13_033800| [ 0.75527  0.29249]
21Feb13_033800| [-0.45525  0.95025]
21Feb13_033800| [ 0.35702  0.60776]
21Feb13_033800| [ 0.11856 -0.18745]
21Feb13_033800| [-0.97968 -0.74320]
21Feb13_033800| [-0.86733  0.80774]]
21Feb13_033800|-- Bias --
21Feb13_033800|[ 0.82786 -0.37827]
21Feb13_033800|Predicting the validation and test data with the Best initial individual.
21Feb13_033808| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_033808|-----------  ------------------  --------------------  ----------
21Feb13_033808|Validation         42.09                  69            0.00000
21Feb13_033808|   Test            36.49                  69            0.00000
21Feb13_033808|-------------------- Test #0 --------------------
21Feb13_033808|Best final individual weights
21Feb13_033808|Individual:
21Feb13_033808|-- Constant hidden layers --
21Feb13_033808|False
21Feb13_033808|Layer 0:
21Feb13_033808|-- Config --
21Feb13_033808|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_033808|-- Weights --
21Feb13_033808|[[-3.22596e+00  8.15030e-02 -6.01515e-01 -4.22099e-01  1.44663e+00
21Feb13_033808|  -1.61649e+00]
21Feb13_033808| [-1.50985e+00 -8.80248e-01  4.97777e-01 -1.13432e+00 -2.07553e-01
21Feb13_033808|  -1.33127e-01]
21Feb13_033808| [-4.93230e-01  9.20894e-01 -6.80714e-01 -2.06675e-01 -1.67587e+00
21Feb13_033808|  -6.52652e-01]
21Feb13_033808| [-2.05655e+00 -1.26240e-01  1.02608e+00  3.31071e-01  2.72223e+00
21Feb13_033808|  -1.74184e-01]
21Feb13_033808| [-3.69830e-01  6.68594e-01  2.26357e-01  2.51533e-01 -6.70313e-01
21Feb13_033808|   2.55592e-01]
21Feb13_033808| [-2.36286e+00  3.86648e-01 -2.15750e+00  1.36469e-02 -1.48716e-01
21Feb13_033808|   1.85106e-02]
21Feb13_033808| [-1.32345e+00  1.17064e-01  4.67906e-01  1.18407e+00 -3.34708e-01
21Feb13_033808|   1.09335e+00]
21Feb13_033808| [ 4.64573e-02 -4.21817e-01 -2.00697e-02  6.73155e-01  2.22709e+00
21Feb13_033808|   1.05368e+00]
21Feb13_033808| [ 1.09741e+00 -4.08370e-01  1.22170e-01  1.54974e+00 -1.16833e-01
21Feb13_033808|   7.13909e-01]
21Feb13_033808| [ 5.46404e-01  2.46330e-01 -1.10982e+00  1.25920e+00 -3.52503e-01
21Feb13_033808|  -1.05035e+00]
21Feb13_033808| [ 3.91003e-01 -4.99730e-01 -1.00691e+00  1.39055e-01  1.92670e-01
21Feb13_033808|  -2.41086e+00]
21Feb13_033808| [-2.87157e-01  2.24456e+00  3.52979e-01  7.50725e-01  3.94071e-01
21Feb13_033808|   1.45677e+00]
21Feb13_033808| [ 1.91678e-02  1.30795e+00  1.99890e+00  2.12176e-01 -1.05133e+00
21Feb13_033808|  -1.54555e+00]
21Feb13_033808| [-1.57311e+00 -1.51965e+00 -1.47786e+00  8.92305e-01 -1.53035e+00
21Feb13_033808|   3.74029e-01]
21Feb13_033808| [-6.10475e-01  7.15578e-01  9.61852e-01  1.61375e+00 -1.90442e+00
21Feb13_033808|  -2.29618e-01]
21Feb13_033808| [ 8.88482e-01  5.42253e-01  1.36180e+00  1.49804e+00 -3.01915e-01
21Feb13_033808|  -1.64657e+00]
21Feb13_033808| [-7.72804e-01 -7.88868e-01 -1.51732e+00  2.67411e+00  4.06295e-01
21Feb13_033808|  -8.92510e-01]
21Feb13_033808| [ 6.46004e-01  5.12295e-01  7.01179e-01 -4.54621e-01  3.75918e-01
21Feb13_033808|   1.49924e+00]
21Feb13_033808| [ 1.52278e+00  1.92058e+00 -9.65125e-01 -4.80307e-01  5.46888e-01
21Feb13_033808|   2.24850e+00]
21Feb13_033808| [ 4.66992e-01  7.44738e-01  2.04032e+00 -7.52850e-01  4.39795e-01
21Feb13_033808|  -1.30633e+00]
21Feb13_033808| [ 5.36590e-03  2.71827e-01 -9.00687e-01 -1.69175e+00  2.60630e-01
21Feb13_033808|  -1.17641e-01]
21Feb13_033808| [-1.89419e+00  5.86120e-01  3.17287e-01  1.23132e+00  8.29902e-01
21Feb13_033808|  -2.27367e-01]
21Feb13_033808| [-9.93682e-01 -4.88945e-01  1.53959e+00 -2.17389e+00  4.91149e-01
21Feb13_033808|  -1.53693e-01]
21Feb13_033808| [-2.37496e+00  1.80554e+00  8.46161e-01 -8.02585e-02 -4.71501e-01
21Feb13_033808|   9.27510e-01]
21Feb13_033808| [ 6.71329e-01  7.64780e-01  1.79372e+00  1.27631e+00  2.45948e-01
21Feb13_033808|  -3.84121e-01]
21Feb13_033808| [ 1.38052e-03  1.00208e-01 -7.26106e-01  2.08987e+00  6.05057e-01
21Feb13_033808|  -3.44705e-01]
21Feb13_033808| [-6.40448e-01 -1.25756e+00 -6.91855e-01 -6.60281e-01 -5.32415e-01
21Feb13_033808|   4.82907e-01]
21Feb13_033808| [-8.29951e-01 -1.45360e-02 -5.18103e-01 -6.96224e-01  9.92941e-01
21Feb13_033808|  -3.74757e-01]
21Feb13_033808| [ 5.04431e-01  1.30316e+00 -7.61889e-01 -5.64505e-01 -1.86976e+00
21Feb13_033808|  -1.65515e+00]
21Feb13_033808| [ 1.80792e+00  9.99541e-01 -7.60678e-01  5.74908e-01 -1.53949e-01
21Feb13_033808|  -5.10970e-01]
21Feb13_033808| [ 5.74980e-01 -2.02913e+00 -5.90122e-04  2.24040e-01  2.40596e+00
21Feb13_033808|   1.13780e+00]
21Feb13_033808| [ 5.37268e-01 -1.13424e+00 -1.13375e+00  9.51094e-01 -2.61279e+00
21Feb13_033808|   3.09503e+00]
21Feb13_033808| [-7.43876e-01 -7.91567e-01 -1.42315e-01 -5.44246e-01 -1.31291e+00
21Feb13_033808|   8.00366e-01]
21Feb13_033808| [-4.43500e-01  5.01447e-01  7.37639e-01 -8.86292e-01 -1.43796e-01
21Feb13_033808|  -4.43199e-01]
21Feb13_033808| [-8.09815e-01 -5.40442e-01 -8.18936e-01 -2.62253e-01  1.23623e+00
21Feb13_033808|  -1.68396e-01]
21Feb13_033808| [-1.41040e+00 -1.68646e+00  6.51829e-01  1.33127e+00 -3.55390e-01
21Feb13_033808|  -6.44956e-01]
21Feb13_033808| [ 1.02374e+00  1.38475e+00 -1.60690e+00  1.39313e+00  1.52072e-01
21Feb13_033808|   1.78248e+00]
21Feb13_033808| [ 5.73046e-01 -1.24317e-01 -9.46218e-01 -9.92492e-01  7.18726e-01
21Feb13_033808|  -1.17057e+00]
21Feb13_033808| [ 7.12853e-01 -2.02767e+00  9.54969e-01  2.94993e-01  3.47986e-01
21Feb13_033808|   6.63350e-01]
21Feb13_033808| [-1.54972e-01 -2.25426e-02 -6.84809e-01  1.52444e+00 -3.08307e-01
21Feb13_033808|   6.16589e-01]
21Feb13_033808| [-2.68374e+00 -4.22414e-01 -8.89236e-01 -1.93846e+00 -6.21410e-03
21Feb13_033808|   2.43379e-02]
21Feb13_033808| [ 1.09577e+00 -1.55455e+00 -6.10941e-02  1.52828e-01 -7.03620e-01
21Feb13_033808|   1.09147e-01]
21Feb13_033808| [-7.87936e-01  6.89893e-01  9.67818e-03 -1.11178e+00 -9.82087e-01
21Feb13_033808|  -2.04381e-02]
21Feb13_033808| [-2.17261e+00 -1.22041e-01 -2.73620e-01 -8.36236e-01 -1.38438e+00
21Feb13_033808|  -2.87446e+00]
21Feb13_033808| [-1.27789e+00 -2.22055e+00  8.59278e-01  1.76093e+00  1.70142e+00
21Feb13_033808|  -3.61876e-01]
21Feb13_033808| [-1.67503e-01 -1.63536e-01 -9.50598e-01  4.35036e-01  5.75847e-01
21Feb13_033808|  -8.25957e-01]
21Feb13_033808| [ 2.38600e-01  6.87028e-01 -1.93100e-01 -1.37955e+00 -1.44922e+00
21Feb13_033808|  -5.58933e-01]
21Feb13_033808| [ 1.39524e+00 -1.73409e+00  5.43499e-01  4.06335e-01  1.47732e+00
21Feb13_033808|  -1.58348e+00]
21Feb13_033808| [ 2.93958e-01 -1.60558e-01 -6.19102e-01  2.12392e+00 -5.84554e-01
21Feb13_033808|  -1.08076e+00]
21Feb13_033808| [-1.03545e+00 -5.95621e-01 -4.88036e-01  2.22136e+00  1.27135e+00
21Feb13_033808|   1.21194e+00]
21Feb13_033808| [ 4.53245e-01 -4.35898e-01  9.15575e-01  5.54548e-01  2.31589e+00
21Feb13_033808|  -1.49880e-01]
21Feb13_033808| [ 1.95697e-01 -7.10320e-01  2.11797e+00  2.19429e-01 -8.34045e-01
21Feb13_033808|   6.75304e-01]
21Feb13_033808| [-1.09139e+00 -4.01523e-01  1.57825e+00 -3.63577e-01  1.27839e+00
21Feb13_033808|  -1.36927e+00]
21Feb13_033808| [-1.11411e+00  8.48703e-01 -1.23858e+00  6.59452e-02  6.16666e-01
21Feb13_033808|  -1.01983e+00]
21Feb13_033808| [ 8.64455e-01 -9.64796e-01  1.83325e+00  7.13131e-01 -1.19417e-01
21Feb13_033808|   1.24116e+00]
21Feb13_033808| [ 8.48703e-01 -1.26355e+00  1.89405e-01 -3.56211e-01  1.75192e+00
21Feb13_033808|  -9.35049e-01]
21Feb13_033808| [-6.05565e-01  1.49776e-01 -5.52038e-01  7.30625e-01  7.54976e-01
21Feb13_033808|  -1.13010e-01]]
21Feb13_033808|-- Bias --
21Feb13_033808|[-0.96395 -1.81574  0.59648 -0.89546  0.53643 -0.54271]
21Feb13_033808|Layer 1:
21Feb13_033808|-- Config --
21Feb13_033808|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_033808|-- Weights --
21Feb13_033808|[[-0.15615 -0.20495]
21Feb13_033808| [-0.32598  1.06694]
21Feb13_033808| [-1.47486  2.25005]
21Feb13_033808| [ 0.99958 -0.64832]
21Feb13_033808| [-0.41273 -1.27368]
21Feb13_033808| [-0.24560 -0.41985]]
21Feb13_033808|-- Bias --
21Feb13_033808|[0.71852 0.71224]
21Feb13_033808|Predicting the validation and test data with the Best final individual.
21Feb13_033815| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_033815|-----------  ------------------  --------------------  ----------
21Feb13_033815|Validation         41.57                  6             0.01803
21Feb13_033815|   Test            36.49                  6             0.00298
21Feb13_033815|-------------------- Test #1 --------------------
21Feb13_033815|Best final individual weights
21Feb13_033815|Individual:
21Feb13_033815|-- Constant hidden layers --
21Feb13_033815|False
21Feb13_033815|Layer 0:
21Feb13_033815|-- Config --
21Feb13_033815|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_033815|-- Weights --
21Feb13_033815|[[-3.22596e+00  8.15030e-02 -6.01515e-01 -4.22099e-01  1.44663e+00
21Feb13_033815|  -1.61649e+00]
21Feb13_033815| [-1.50985e+00 -8.80248e-01  4.97777e-01 -1.13432e+00 -2.07553e-01
21Feb13_033815|  -1.33127e-01]
21Feb13_033815| [-4.93230e-01  9.20894e-01 -6.80714e-01 -2.06675e-01 -1.67587e+00
21Feb13_033815|  -6.52652e-01]
21Feb13_033815| [-2.05655e+00 -1.26240e-01  1.02608e+00  3.31071e-01  2.72223e+00
21Feb13_033815|  -1.74184e-01]
21Feb13_033815| [-3.69830e-01  6.68594e-01  2.26357e-01  2.51533e-01 -6.70313e-01
21Feb13_033815|   2.55592e-01]
21Feb13_033815| [-2.36286e+00  3.86648e-01 -2.15750e+00  1.36469e-02 -1.48716e-01
21Feb13_033815|   1.85106e-02]
21Feb13_033815| [-1.32345e+00  1.17064e-01  4.67906e-01  1.18407e+00 -3.34708e-01
21Feb13_033815|   1.09335e+00]
21Feb13_033815| [ 4.64573e-02 -4.21817e-01 -2.00697e-02  6.73155e-01  2.22709e+00
21Feb13_033815|   1.05368e+00]
21Feb13_033815| [ 1.09741e+00 -4.08370e-01  1.22170e-01  1.54974e+00 -1.16833e-01
21Feb13_033815|   7.13909e-01]
21Feb13_033815| [ 5.46404e-01  2.46330e-01 -1.10982e+00  1.25920e+00 -3.52503e-01
21Feb13_033815|  -1.05035e+00]
21Feb13_033815| [ 3.91003e-01 -4.99730e-01 -1.00691e+00  1.39055e-01  1.92670e-01
21Feb13_033815|  -2.41086e+00]
21Feb13_033815| [-2.87157e-01  2.24456e+00  3.52979e-01  7.50725e-01  3.94071e-01
21Feb13_033815|   1.45677e+00]
21Feb13_033815| [ 1.91678e-02  1.30795e+00  1.99890e+00  2.12176e-01 -1.05133e+00
21Feb13_033815|  -1.54555e+00]
21Feb13_033815| [-1.57311e+00 -1.51965e+00 -1.47786e+00  8.92305e-01 -1.53035e+00
21Feb13_033815|   3.74029e-01]
21Feb13_033815| [-6.10475e-01  7.15578e-01  9.61852e-01  1.61375e+00 -1.90442e+00
21Feb13_033815|  -2.29618e-01]
21Feb13_033815| [ 8.88482e-01  5.42253e-01  1.36180e+00  1.49804e+00 -3.01915e-01
21Feb13_033815|  -1.64657e+00]
21Feb13_033815| [-7.72804e-01 -7.88868e-01 -1.51732e+00  2.67411e+00  4.06295e-01
21Feb13_033815|  -8.92510e-01]
21Feb13_033815| [ 6.46004e-01  5.12295e-01  7.01179e-01 -4.54621e-01  3.75918e-01
21Feb13_033815|   1.49924e+00]
21Feb13_033815| [ 1.52278e+00  1.92058e+00 -9.65125e-01 -4.80307e-01  5.46888e-01
21Feb13_033815|   2.24850e+00]
21Feb13_033815| [ 4.66992e-01  7.44738e-01  2.04032e+00 -7.52850e-01  4.39795e-01
21Feb13_033815|  -1.30633e+00]
21Feb13_033815| [ 5.36590e-03  2.71827e-01 -9.00687e-01 -1.69175e+00  2.60630e-01
21Feb13_033815|  -1.17641e-01]
21Feb13_033815| [-1.89419e+00  5.86120e-01  3.17287e-01  1.23132e+00  8.29902e-01
21Feb13_033815|  -2.27367e-01]
21Feb13_033815| [-9.93682e-01 -4.88945e-01  1.53959e+00 -2.17389e+00  4.91149e-01
21Feb13_033815|  -1.53693e-01]
21Feb13_033815| [-2.37496e+00  1.80554e+00  8.46161e-01 -8.02585e-02 -4.71501e-01
21Feb13_033815|   9.27510e-01]
21Feb13_033815| [ 6.71329e-01  7.64780e-01  1.79372e+00  1.27631e+00  2.45948e-01
21Feb13_033815|  -3.84121e-01]
21Feb13_033815| [ 1.38052e-03  1.00208e-01 -7.26106e-01  2.08987e+00  6.05057e-01
21Feb13_033815|  -3.44705e-01]
21Feb13_033815| [-6.40448e-01 -1.25756e+00 -6.91855e-01 -6.60281e-01 -5.32415e-01
21Feb13_033815|   4.82907e-01]
21Feb13_033815| [-8.29951e-01 -1.45360e-02 -5.18103e-01 -6.96224e-01  9.92941e-01
21Feb13_033815|  -3.74757e-01]
21Feb13_033815| [ 5.04431e-01  1.30316e+00 -7.61889e-01 -5.64505e-01 -1.86976e+00
21Feb13_033815|  -1.65515e+00]
21Feb13_033815| [ 1.80792e+00  9.99541e-01 -7.60678e-01  5.74908e-01 -1.53949e-01
21Feb13_033815|  -5.10970e-01]
21Feb13_033815| [ 5.74980e-01 -2.02913e+00 -5.90122e-04  2.24040e-01  2.40596e+00
21Feb13_033815|   1.13780e+00]
21Feb13_033815| [ 5.37268e-01 -1.13424e+00 -1.13375e+00  9.51094e-01 -2.61279e+00
21Feb13_033815|   3.09503e+00]
21Feb13_033815| [-7.43876e-01 -7.91567e-01 -1.42315e-01 -5.44246e-01 -1.31291e+00
21Feb13_033815|   8.00366e-01]
21Feb13_033815| [-4.43500e-01  5.01447e-01  7.37639e-01 -8.86292e-01 -1.43796e-01
21Feb13_033815|  -4.43199e-01]
21Feb13_033815| [-8.09815e-01 -5.40442e-01 -8.18936e-01 -2.62253e-01  1.23623e+00
21Feb13_033815|  -1.68396e-01]
21Feb13_033815| [-1.41040e+00 -1.68646e+00  6.51829e-01  1.33127e+00 -3.55390e-01
21Feb13_033815|  -6.44956e-01]
21Feb13_033815| [ 1.02374e+00  1.38475e+00 -1.60690e+00  1.39313e+00  1.52072e-01
21Feb13_033815|   1.78248e+00]
21Feb13_033815| [ 5.73046e-01 -1.24317e-01 -9.46218e-01 -9.92492e-01  7.18726e-01
21Feb13_033815|  -1.17057e+00]
21Feb13_033815| [ 7.12853e-01 -2.02767e+00  9.54969e-01  2.94993e-01  3.47986e-01
21Feb13_033815|   6.63350e-01]
21Feb13_033815| [-1.54972e-01 -2.25426e-02 -6.84809e-01  1.52444e+00 -3.08307e-01
21Feb13_033815|   6.16589e-01]
21Feb13_033815| [-2.68374e+00 -4.22414e-01 -8.89236e-01 -1.93846e+00 -6.21410e-03
21Feb13_033815|   2.43379e-02]
21Feb13_033815| [ 1.09577e+00 -1.55455e+00 -6.10941e-02  1.52828e-01 -7.03620e-01
21Feb13_033815|   1.09147e-01]
21Feb13_033815| [-7.87936e-01  6.89893e-01  9.67818e-03 -1.11178e+00 -9.82087e-01
21Feb13_033815|  -2.04381e-02]
21Feb13_033815| [-2.17261e+00 -1.22041e-01 -2.73620e-01 -8.36236e-01 -1.38438e+00
21Feb13_033815|  -2.87446e+00]
21Feb13_033815| [-1.27789e+00 -2.22055e+00  8.59278e-01  1.76093e+00  1.70142e+00
21Feb13_033815|  -3.61876e-01]
21Feb13_033815| [-1.67503e-01 -1.63536e-01 -9.50598e-01  4.35036e-01  5.75847e-01
21Feb13_033815|  -8.25957e-01]
21Feb13_033815| [ 2.38600e-01  6.87028e-01 -1.93100e-01 -1.37955e+00 -1.44922e+00
21Feb13_033815|  -5.58933e-01]
21Feb13_033815| [ 1.39524e+00 -1.73409e+00  5.43499e-01  4.06335e-01  1.47732e+00
21Feb13_033815|  -1.58348e+00]
21Feb13_033815| [ 2.93958e-01 -1.60558e-01 -6.19102e-01  2.12392e+00 -5.84554e-01
21Feb13_033815|  -1.08076e+00]
21Feb13_033815| [-1.03545e+00 -5.95621e-01 -4.88036e-01  2.22136e+00  1.27135e+00
21Feb13_033815|   1.21194e+00]
21Feb13_033815| [ 4.53245e-01 -4.35898e-01  9.15575e-01  5.54548e-01  2.31589e+00
21Feb13_033815|  -1.49880e-01]
21Feb13_033815| [ 1.95697e-01 -7.10320e-01  2.11797e+00  2.19429e-01 -8.34045e-01
21Feb13_033815|   6.75304e-01]
21Feb13_033815| [-1.09139e+00 -4.01523e-01  1.57825e+00 -3.63577e-01  1.27839e+00
21Feb13_033815|  -1.36927e+00]
21Feb13_033815| [-1.11411e+00  8.48703e-01 -1.23858e+00  6.59452e-02  6.16666e-01
21Feb13_033815|  -1.01983e+00]
21Feb13_033815| [ 8.64455e-01 -9.64796e-01  1.83325e+00  7.13131e-01 -1.19417e-01
21Feb13_033815|   1.24116e+00]
21Feb13_033815| [ 8.48703e-01 -1.26355e+00  1.89405e-01 -3.56211e-01  1.75192e+00
21Feb13_033815|  -9.35049e-01]
21Feb13_033815| [-6.05565e-01  1.49776e-01 -5.52038e-01  7.30625e-01  7.54976e-01
21Feb13_033815|  -1.13010e-01]]
21Feb13_033815|-- Bias --
21Feb13_033815|[-0.96395 -1.81574  0.59648 -0.89546  0.53643 -0.54271]
21Feb13_033815|Layer 1:
21Feb13_033815|-- Config --
21Feb13_033815|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_033815|-- Weights --
21Feb13_033815|[[-0.15615 -0.20495]
21Feb13_033815| [-0.32598  1.06694]
21Feb13_033815| [-1.47486  2.25005]
21Feb13_033815| [ 0.99958 -0.64832]
21Feb13_033815| [-0.41273 -1.27368]
21Feb13_033815| [-0.24560 -0.41985]]
21Feb13_033815|-- Bias --
21Feb13_033815|[0.71852 0.71224]
21Feb13_033815|Predicting the validation and test data with the Best final individual.
21Feb13_033822| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_033822|-----------  ------------------  --------------------  ----------
21Feb13_033822|Validation         41.22                  6             0.02318
21Feb13_033822|   Test            36.23                  6             0.01189
21Feb13_033822|-------------------- Test #2 --------------------
21Feb13_033822|Best final individual weights
21Feb13_033822|Individual:
21Feb13_033822|-- Constant hidden layers --
21Feb13_033822|False
21Feb13_033822|Layer 0:
21Feb13_033822|-- Config --
21Feb13_033822|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_033822|-- Weights --
21Feb13_033822|[[-3.22596e+00  8.15030e-02 -6.01515e-01 -4.22099e-01  1.44663e+00
21Feb13_033822|  -1.61649e+00]
21Feb13_033822| [-1.50985e+00 -8.80248e-01  4.97777e-01 -1.13432e+00 -2.07553e-01
21Feb13_033822|  -1.33127e-01]
21Feb13_033822| [-4.93230e-01  9.20894e-01 -6.80714e-01 -2.06675e-01 -1.67587e+00
21Feb13_033822|  -6.52652e-01]
21Feb13_033822| [-2.05655e+00 -1.26240e-01  1.02608e+00  3.31071e-01  2.72223e+00
21Feb13_033822|  -1.74184e-01]
21Feb13_033822| [-3.69830e-01  6.68594e-01  2.26357e-01  2.51533e-01 -6.70313e-01
21Feb13_033822|   2.55592e-01]
21Feb13_033822| [-2.36286e+00  3.86648e-01 -2.15750e+00  1.36469e-02 -1.48716e-01
21Feb13_033822|   1.85106e-02]
21Feb13_033822| [-1.32345e+00  1.17064e-01  4.67906e-01  1.18407e+00 -3.34708e-01
21Feb13_033822|   1.09335e+00]
21Feb13_033822| [ 4.64573e-02 -4.21817e-01 -2.00697e-02  6.73155e-01  2.22709e+00
21Feb13_033822|   1.05368e+00]
21Feb13_033822| [ 1.09741e+00 -4.08370e-01  1.22170e-01  1.54974e+00 -1.16833e-01
21Feb13_033822|   7.13909e-01]
21Feb13_033822| [ 5.46404e-01  2.46330e-01 -1.10982e+00  1.25920e+00 -3.52503e-01
21Feb13_033822|  -1.05035e+00]
21Feb13_033822| [ 3.91003e-01 -4.99730e-01 -1.00691e+00  1.39055e-01  1.92670e-01
21Feb13_033822|  -2.41086e+00]
21Feb13_033822| [-2.87157e-01  2.24456e+00  3.52979e-01  7.50725e-01  3.94071e-01
21Feb13_033822|   1.45677e+00]
21Feb13_033822| [ 1.91678e-02  1.30795e+00  1.99890e+00  2.12176e-01 -1.05133e+00
21Feb13_033822|  -1.54555e+00]
21Feb13_033822| [-1.57311e+00 -1.51965e+00 -1.47786e+00  8.92305e-01 -1.53035e+00
21Feb13_033822|   3.74029e-01]
21Feb13_033822| [-6.10475e-01  7.15578e-01  9.61852e-01  1.61375e+00 -1.90442e+00
21Feb13_033822|  -2.29618e-01]
21Feb13_033822| [ 8.88482e-01  5.42253e-01  1.36180e+00  1.49804e+00 -3.01915e-01
21Feb13_033822|  -1.64657e+00]
21Feb13_033822| [-7.72804e-01 -7.88868e-01 -1.51732e+00  2.67411e+00  4.06295e-01
21Feb13_033822|  -8.92510e-01]
21Feb13_033822| [ 6.46004e-01  5.12295e-01  7.01179e-01 -4.54621e-01  3.75918e-01
21Feb13_033822|   1.49924e+00]
21Feb13_033822| [ 1.52278e+00  1.92058e+00 -9.65125e-01 -4.80307e-01  5.46888e-01
21Feb13_033822|   2.24850e+00]
21Feb13_033822| [ 4.66992e-01  7.44738e-01  2.04032e+00 -7.52850e-01  4.39795e-01
21Feb13_033822|  -1.30633e+00]
21Feb13_033822| [ 5.36590e-03  2.71827e-01 -9.00687e-01 -1.69175e+00  2.60630e-01
21Feb13_033822|  -1.17641e-01]
21Feb13_033822| [-1.89419e+00  5.86120e-01  3.17287e-01  1.23132e+00  8.29902e-01
21Feb13_033822|  -2.27367e-01]
21Feb13_033822| [-9.93682e-01 -4.88945e-01  1.53959e+00 -2.17389e+00  4.91149e-01
21Feb13_033822|  -1.53693e-01]
21Feb13_033822| [-2.37496e+00  1.80554e+00  8.46161e-01 -8.02585e-02 -4.71501e-01
21Feb13_033822|   9.27510e-01]
21Feb13_033822| [ 6.71329e-01  7.64780e-01  1.79372e+00  1.27631e+00  2.45948e-01
21Feb13_033822|  -3.84121e-01]
21Feb13_033822| [ 1.38052e-03  1.00208e-01 -7.26106e-01  2.08987e+00  6.05057e-01
21Feb13_033822|  -3.44705e-01]
21Feb13_033822| [-6.40448e-01 -1.25756e+00 -6.91855e-01 -6.60281e-01 -5.32415e-01
21Feb13_033822|   4.82907e-01]
21Feb13_033822| [-8.29951e-01 -1.45360e-02 -5.18103e-01 -6.96224e-01  9.92941e-01
21Feb13_033822|  -3.74757e-01]
21Feb13_033822| [ 5.04431e-01  1.30316e+00 -7.61889e-01 -5.64505e-01 -1.86976e+00
21Feb13_033822|  -1.65515e+00]
21Feb13_033822| [ 1.80792e+00  9.99541e-01 -7.60678e-01  5.74908e-01 -1.53949e-01
21Feb13_033822|  -5.10970e-01]
21Feb13_033822| [ 5.74980e-01 -2.02913e+00 -5.90122e-04  2.24040e-01  2.40596e+00
21Feb13_033822|   1.13780e+00]
21Feb13_033822| [ 5.37268e-01 -1.13424e+00 -1.13375e+00  9.51094e-01 -2.61279e+00
21Feb13_033822|   3.09503e+00]
21Feb13_033822| [-7.43876e-01 -7.91567e-01 -1.42315e-01 -5.44246e-01 -1.31291e+00
21Feb13_033822|   8.00366e-01]
21Feb13_033822| [-4.43500e-01  5.01447e-01  7.37639e-01 -8.86292e-01 -1.43796e-01
21Feb13_033822|  -4.43199e-01]
21Feb13_033822| [-8.09815e-01 -5.40442e-01 -8.18936e-01 -2.62253e-01  1.23623e+00
21Feb13_033822|  -1.68396e-01]
21Feb13_033822| [-1.41040e+00 -1.68646e+00  6.51829e-01  1.33127e+00 -3.55390e-01
21Feb13_033822|  -6.44956e-01]
21Feb13_033822| [ 1.02374e+00  1.38475e+00 -1.60690e+00  1.39313e+00  1.52072e-01
21Feb13_033822|   1.78248e+00]
21Feb13_033822| [ 5.73046e-01 -1.24317e-01 -9.46218e-01 -9.92492e-01  7.18726e-01
21Feb13_033822|  -1.17057e+00]
21Feb13_033822| [ 7.12853e-01 -2.02767e+00  9.54969e-01  2.94993e-01  3.47986e-01
21Feb13_033822|   6.63350e-01]
21Feb13_033822| [-1.54972e-01 -2.25426e-02 -6.84809e-01  1.52444e+00 -3.08307e-01
21Feb13_033822|   6.16589e-01]
21Feb13_033822| [-2.68374e+00 -4.22414e-01 -8.89236e-01 -1.93846e+00 -6.21410e-03
21Feb13_033822|   2.43379e-02]
21Feb13_033822| [ 1.09577e+00 -1.55455e+00 -6.10941e-02  1.52828e-01 -7.03620e-01
21Feb13_033822|   1.09147e-01]
21Feb13_033822| [-7.87936e-01  6.89893e-01  9.67818e-03 -1.11178e+00 -9.82087e-01
21Feb13_033822|  -2.04381e-02]
21Feb13_033822| [-2.17261e+00 -1.22041e-01 -2.73620e-01 -8.36236e-01 -1.38438e+00
21Feb13_033822|  -2.87446e+00]
21Feb13_033822| [-1.27789e+00 -2.22055e+00  8.59278e-01  1.76093e+00  1.70142e+00
21Feb13_033822|  -3.61876e-01]
21Feb13_033822| [-1.67503e-01 -1.63536e-01 -9.50598e-01  4.35036e-01  5.75847e-01
21Feb13_033822|  -8.25957e-01]
21Feb13_033822| [ 2.38600e-01  6.87028e-01 -1.93100e-01 -1.37955e+00 -1.44922e+00
21Feb13_033822|  -5.58933e-01]
21Feb13_033822| [ 1.39524e+00 -1.73409e+00  5.43499e-01  4.06335e-01  1.47732e+00
21Feb13_033822|  -1.58348e+00]
21Feb13_033822| [ 2.93958e-01 -1.60558e-01 -6.19102e-01  2.12392e+00 -5.84554e-01
21Feb13_033822|  -1.08076e+00]
21Feb13_033822| [-1.03545e+00 -5.95621e-01 -4.88036e-01  2.22136e+00  1.27135e+00
21Feb13_033822|   1.21194e+00]
21Feb13_033822| [ 4.53245e-01 -4.35898e-01  9.15575e-01  5.54548e-01  2.31589e+00
21Feb13_033822|  -1.49880e-01]
21Feb13_033822| [ 1.95697e-01 -7.10320e-01  2.11797e+00  2.19429e-01 -8.34045e-01
21Feb13_033822|   6.75304e-01]
21Feb13_033822| [-1.09139e+00 -4.01523e-01  1.57825e+00 -3.63577e-01  1.27839e+00
21Feb13_033822|  -1.36927e+00]
21Feb13_033822| [-1.11411e+00  8.48703e-01 -1.23858e+00  6.59452e-02  6.16666e-01
21Feb13_033822|  -1.01983e+00]
21Feb13_033822| [ 8.64455e-01 -9.64796e-01  1.83325e+00  7.13131e-01 -1.19417e-01
21Feb13_033822|   1.24116e+00]
21Feb13_033822| [ 8.48703e-01 -1.26355e+00  1.89405e-01 -3.56211e-01  1.75192e+00
21Feb13_033822|  -9.35049e-01]
21Feb13_033822| [-6.05565e-01  1.49776e-01 -5.52038e-01  7.30625e-01  7.54976e-01
21Feb13_033822|  -1.13010e-01]]
21Feb13_033822|-- Bias --
21Feb13_033822|[-0.96395 -1.81574  0.59648 -0.89546  0.53643 -0.54271]
21Feb13_033822|Layer 1:
21Feb13_033822|-- Config --
21Feb13_033822|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_033822|-- Weights --
21Feb13_033822|[[-0.15615 -0.20495]
21Feb13_033822| [-0.32598  1.06694]
21Feb13_033822| [-1.47486  2.25005]
21Feb13_033822| [ 0.99958 -0.64832]
21Feb13_033822| [-0.41273 -1.27368]
21Feb13_033822| [-0.24560 -0.41985]]
21Feb13_033822|-- Bias --
21Feb13_033822|[0.71852 0.71224]
21Feb13_033822|Predicting the validation and test data with the Best final individual.
21Feb13_033829| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_033829|-----------  ------------------  --------------------  ----------
21Feb13_033829|Validation         41.39                  6             0.02061
21Feb13_033829|   Test            36.32                  6             0.00892
21Feb13_033829|-------------------- Test #3 --------------------
21Feb13_033829|Best final individual weights
21Feb13_033829|Individual:
21Feb13_033829|-- Constant hidden layers --
21Feb13_033829|False
21Feb13_033829|Layer 0:
21Feb13_033829|-- Config --
21Feb13_033829|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_033829|-- Weights --
21Feb13_033829|[[-3.22596e+00  8.15030e-02 -6.01515e-01 -4.22099e-01  1.44663e+00
21Feb13_033829|  -1.61649e+00]
21Feb13_033829| [-1.50985e+00 -8.80248e-01  4.97777e-01 -1.13432e+00 -2.07553e-01
21Feb13_033829|  -1.33127e-01]
21Feb13_033829| [-4.93230e-01  9.20894e-01 -6.80714e-01 -2.06675e-01 -1.67587e+00
21Feb13_033829|  -6.52652e-01]
21Feb13_033829| [-2.05655e+00 -1.26240e-01  1.02608e+00  3.31071e-01  2.72223e+00
21Feb13_033829|  -1.74184e-01]
21Feb13_033829| [-3.69830e-01  6.68594e-01  2.26357e-01  2.51533e-01 -6.70313e-01
21Feb13_033829|   2.55592e-01]
21Feb13_033829| [-2.36286e+00  3.86648e-01 -2.15750e+00  1.36469e-02 -1.48716e-01
21Feb13_033829|   1.85106e-02]
21Feb13_033829| [-1.32345e+00  1.17064e-01  4.67906e-01  1.18407e+00 -3.34708e-01
21Feb13_033829|   1.09335e+00]
21Feb13_033829| [ 4.64573e-02 -4.21817e-01 -2.00697e-02  6.73155e-01  2.22709e+00
21Feb13_033829|   1.05368e+00]
21Feb13_033829| [ 1.09741e+00 -4.08370e-01  1.22170e-01  1.54974e+00 -1.16833e-01
21Feb13_033829|   7.13909e-01]
21Feb13_033829| [ 5.46404e-01  2.46330e-01 -1.10982e+00  1.25920e+00 -3.52503e-01
21Feb13_033829|  -1.05035e+00]
21Feb13_033829| [ 3.91003e-01 -4.99730e-01 -1.00691e+00  1.39055e-01  1.92670e-01
21Feb13_033829|  -2.41086e+00]
21Feb13_033829| [-2.87157e-01  2.24456e+00  3.52979e-01  7.50725e-01  3.94071e-01
21Feb13_033829|   1.45677e+00]
21Feb13_033829| [ 1.91678e-02  1.30795e+00  1.99890e+00  2.12176e-01 -1.05133e+00
21Feb13_033829|  -1.54555e+00]
21Feb13_033829| [-1.57311e+00 -1.51965e+00 -1.47786e+00  8.92305e-01 -1.53035e+00
21Feb13_033829|   3.74029e-01]
21Feb13_033829| [-6.10475e-01  7.15578e-01  9.61852e-01  1.61375e+00 -1.90442e+00
21Feb13_033829|  -2.29618e-01]
21Feb13_033829| [ 8.88482e-01  5.42253e-01  1.36180e+00  1.49804e+00 -3.01915e-01
21Feb13_033829|  -1.64657e+00]
21Feb13_033829| [-7.72804e-01 -7.88868e-01 -1.51732e+00  2.67411e+00  4.06295e-01
21Feb13_033829|  -8.92510e-01]
21Feb13_033829| [ 6.46004e-01  5.12295e-01  7.01179e-01 -4.54621e-01  3.75918e-01
21Feb13_033829|   1.49924e+00]
21Feb13_033829| [ 1.52278e+00  1.92058e+00 -9.65125e-01 -4.80307e-01  5.46888e-01
21Feb13_033829|   2.24850e+00]
21Feb13_033829| [ 4.66992e-01  7.44738e-01  2.04032e+00 -7.52850e-01  4.39795e-01
21Feb13_033829|  -1.30633e+00]
21Feb13_033829| [ 5.36590e-03  2.71827e-01 -9.00687e-01 -1.69175e+00  2.60630e-01
21Feb13_033829|  -1.17641e-01]
21Feb13_033829| [-1.89419e+00  5.86120e-01  3.17287e-01  1.23132e+00  8.29902e-01
21Feb13_033829|  -2.27367e-01]
21Feb13_033829| [-9.93682e-01 -4.88945e-01  1.53959e+00 -2.17389e+00  4.91149e-01
21Feb13_033829|  -1.53693e-01]
21Feb13_033829| [-2.37496e+00  1.80554e+00  8.46161e-01 -8.02585e-02 -4.71501e-01
21Feb13_033829|   9.27510e-01]
21Feb13_033829| [ 6.71329e-01  7.64780e-01  1.79372e+00  1.27631e+00  2.45948e-01
21Feb13_033829|  -3.84121e-01]
21Feb13_033829| [ 1.38052e-03  1.00208e-01 -7.26106e-01  2.08987e+00  6.05057e-01
21Feb13_033829|  -3.44705e-01]
21Feb13_033829| [-6.40448e-01 -1.25756e+00 -6.91855e-01 -6.60281e-01 -5.32415e-01
21Feb13_033829|   4.82907e-01]
21Feb13_033829| [-8.29951e-01 -1.45360e-02 -5.18103e-01 -6.96224e-01  9.92941e-01
21Feb13_033829|  -3.74757e-01]
21Feb13_033829| [ 5.04431e-01  1.30316e+00 -7.61889e-01 -5.64505e-01 -1.86976e+00
21Feb13_033829|  -1.65515e+00]
21Feb13_033829| [ 1.80792e+00  9.99541e-01 -7.60678e-01  5.74908e-01 -1.53949e-01
21Feb13_033829|  -5.10970e-01]
21Feb13_033829| [ 5.74980e-01 -2.02913e+00 -5.90122e-04  2.24040e-01  2.40596e+00
21Feb13_033829|   1.13780e+00]
21Feb13_033829| [ 5.37268e-01 -1.13424e+00 -1.13375e+00  9.51094e-01 -2.61279e+00
21Feb13_033829|   3.09503e+00]
21Feb13_033829| [-7.43876e-01 -7.91567e-01 -1.42315e-01 -5.44246e-01 -1.31291e+00
21Feb13_033829|   8.00366e-01]
21Feb13_033829| [-4.43500e-01  5.01447e-01  7.37639e-01 -8.86292e-01 -1.43796e-01
21Feb13_033829|  -4.43199e-01]
21Feb13_033829| [-8.09815e-01 -5.40442e-01 -8.18936e-01 -2.62253e-01  1.23623e+00
21Feb13_033829|  -1.68396e-01]
21Feb13_033829| [-1.41040e+00 -1.68646e+00  6.51829e-01  1.33127e+00 -3.55390e-01
21Feb13_033829|  -6.44956e-01]
21Feb13_033829| [ 1.02374e+00  1.38475e+00 -1.60690e+00  1.39313e+00  1.52072e-01
21Feb13_033829|   1.78248e+00]
21Feb13_033829| [ 5.73046e-01 -1.24317e-01 -9.46218e-01 -9.92492e-01  7.18726e-01
21Feb13_033829|  -1.17057e+00]
21Feb13_033829| [ 7.12853e-01 -2.02767e+00  9.54969e-01  2.94993e-01  3.47986e-01
21Feb13_033829|   6.63350e-01]
21Feb13_033829| [-1.54972e-01 -2.25426e-02 -6.84809e-01  1.52444e+00 -3.08307e-01
21Feb13_033829|   6.16589e-01]
21Feb13_033829| [-2.68374e+00 -4.22414e-01 -8.89236e-01 -1.93846e+00 -6.21410e-03
21Feb13_033829|   2.43379e-02]
21Feb13_033829| [ 1.09577e+00 -1.55455e+00 -6.10941e-02  1.52828e-01 -7.03620e-01
21Feb13_033829|   1.09147e-01]
21Feb13_033829| [-7.87936e-01  6.89893e-01  9.67818e-03 -1.11178e+00 -9.82087e-01
21Feb13_033829|  -2.04381e-02]
21Feb13_033829| [-2.17261e+00 -1.22041e-01 -2.73620e-01 -8.36236e-01 -1.38438e+00
21Feb13_033829|  -2.87446e+00]
21Feb13_033829| [-1.27789e+00 -2.22055e+00  8.59278e-01  1.76093e+00  1.70142e+00
21Feb13_033829|  -3.61876e-01]
21Feb13_033829| [-1.67503e-01 -1.63536e-01 -9.50598e-01  4.35036e-01  5.75847e-01
21Feb13_033829|  -8.25957e-01]
21Feb13_033829| [ 2.38600e-01  6.87028e-01 -1.93100e-01 -1.37955e+00 -1.44922e+00
21Feb13_033829|  -5.58933e-01]
21Feb13_033829| [ 1.39524e+00 -1.73409e+00  5.43499e-01  4.06335e-01  1.47732e+00
21Feb13_033829|  -1.58348e+00]
21Feb13_033829| [ 2.93958e-01 -1.60558e-01 -6.19102e-01  2.12392e+00 -5.84554e-01
21Feb13_033829|  -1.08076e+00]
21Feb13_033829| [-1.03545e+00 -5.95621e-01 -4.88036e-01  2.22136e+00  1.27135e+00
21Feb13_033829|   1.21194e+00]
21Feb13_033829| [ 4.53245e-01 -4.35898e-01  9.15575e-01  5.54548e-01  2.31589e+00
21Feb13_033829|  -1.49880e-01]
21Feb13_033829| [ 1.95697e-01 -7.10320e-01  2.11797e+00  2.19429e-01 -8.34045e-01
21Feb13_033829|   6.75304e-01]
21Feb13_033829| [-1.09139e+00 -4.01523e-01  1.57825e+00 -3.63577e-01  1.27839e+00
21Feb13_033829|  -1.36927e+00]
21Feb13_033829| [-1.11411e+00  8.48703e-01 -1.23858e+00  6.59452e-02  6.16666e-01
21Feb13_033829|  -1.01983e+00]
21Feb13_033829| [ 8.64455e-01 -9.64796e-01  1.83325e+00  7.13131e-01 -1.19417e-01
21Feb13_033829|   1.24116e+00]
21Feb13_033829| [ 8.48703e-01 -1.26355e+00  1.89405e-01 -3.56211e-01  1.75192e+00
21Feb13_033829|  -9.35049e-01]
21Feb13_033829| [-6.05565e-01  1.49776e-01 -5.52038e-01  7.30625e-01  7.54976e-01
21Feb13_033829|  -1.13010e-01]]
21Feb13_033829|-- Bias --
21Feb13_033829|[-0.96395 -1.81574  0.59648 -0.89546  0.53643 -0.54271]
21Feb13_033829|Layer 1:
21Feb13_033829|-- Config --
21Feb13_033829|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_033829|-- Weights --
21Feb13_033829|[[-0.15615 -0.20495]
21Feb13_033829| [-0.32598  1.06694]
21Feb13_033829| [-1.47486  2.25005]
21Feb13_033829| [ 0.99958 -0.64832]
21Feb13_033829| [-0.41273 -1.27368]
21Feb13_033829| [-0.24560 -0.41985]]
21Feb13_033829|-- Bias --
21Feb13_033829|[0.71852 0.71224]
21Feb13_033829|Predicting the validation and test data with the Best final individual.
21Feb13_033836| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_033836|-----------  ------------------  --------------------  ----------
21Feb13_033836|Validation         41.74                  6             0.00775
21Feb13_033836|   Test            36.23                  6             0.01189
21Feb13_033836|-------------------- Test #4 --------------------
21Feb13_033836|Best final individual weights
21Feb13_033836|Individual:
21Feb13_033836|-- Constant hidden layers --
21Feb13_033836|False
21Feb13_033836|Layer 0:
21Feb13_033836|-- Config --
21Feb13_033836|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_033836|-- Weights --
21Feb13_033836|[[-3.22596e+00  8.15030e-02 -6.01515e-01 -4.22099e-01  1.44663e+00
21Feb13_033836|  -1.61649e+00]
21Feb13_033836| [-1.50985e+00 -8.80248e-01  4.97777e-01 -1.13432e+00 -2.07553e-01
21Feb13_033836|  -1.33127e-01]
21Feb13_033836| [-4.93230e-01  9.20894e-01 -6.80714e-01 -2.06675e-01 -1.67587e+00
21Feb13_033836|  -6.52652e-01]
21Feb13_033836| [-2.05655e+00 -1.26240e-01  1.02608e+00  3.31071e-01  2.72223e+00
21Feb13_033836|  -1.74184e-01]
21Feb13_033836| [-3.69830e-01  6.68594e-01  2.26357e-01  2.51533e-01 -6.70313e-01
21Feb13_033836|   2.55592e-01]
21Feb13_033836| [-2.36286e+00  3.86648e-01 -2.15750e+00  1.36469e-02 -1.48716e-01
21Feb13_033836|   1.85106e-02]
21Feb13_033836| [-1.32345e+00  1.17064e-01  4.67906e-01  1.18407e+00 -3.34708e-01
21Feb13_033836|   1.09335e+00]
21Feb13_033836| [ 4.64573e-02 -4.21817e-01 -2.00697e-02  6.73155e-01  2.22709e+00
21Feb13_033836|   1.05368e+00]
21Feb13_033836| [ 1.09741e+00 -4.08370e-01  1.22170e-01  1.54974e+00 -1.16833e-01
21Feb13_033836|   7.13909e-01]
21Feb13_033836| [ 5.46404e-01  2.46330e-01 -1.10982e+00  1.25920e+00 -3.52503e-01
21Feb13_033836|  -1.05035e+00]
21Feb13_033836| [ 3.91003e-01 -4.99730e-01 -1.00691e+00  1.39055e-01  1.92670e-01
21Feb13_033836|  -2.41086e+00]
21Feb13_033836| [-2.87157e-01  2.24456e+00  3.52979e-01  7.50725e-01  3.94071e-01
21Feb13_033836|   1.45677e+00]
21Feb13_033836| [ 1.91678e-02  1.30795e+00  1.99890e+00  2.12176e-01 -1.05133e+00
21Feb13_033836|  -1.54555e+00]
21Feb13_033836| [-1.57311e+00 -1.51965e+00 -1.47786e+00  8.92305e-01 -1.53035e+00
21Feb13_033836|   3.74029e-01]
21Feb13_033836| [-6.10475e-01  7.15578e-01  9.61852e-01  1.61375e+00 -1.90442e+00
21Feb13_033836|  -2.29618e-01]
21Feb13_033836| [ 8.88482e-01  5.42253e-01  1.36180e+00  1.49804e+00 -3.01915e-01
21Feb13_033836|  -1.64657e+00]
21Feb13_033836| [-7.72804e-01 -7.88868e-01 -1.51732e+00  2.67411e+00  4.06295e-01
21Feb13_033836|  -8.92510e-01]
21Feb13_033836| [ 6.46004e-01  5.12295e-01  7.01179e-01 -4.54621e-01  3.75918e-01
21Feb13_033836|   1.49924e+00]
21Feb13_033836| [ 1.52278e+00  1.92058e+00 -9.65125e-01 -4.80307e-01  5.46888e-01
21Feb13_033836|   2.24850e+00]
21Feb13_033836| [ 4.66992e-01  7.44738e-01  2.04032e+00 -7.52850e-01  4.39795e-01
21Feb13_033836|  -1.30633e+00]
21Feb13_033836| [ 5.36590e-03  2.71827e-01 -9.00687e-01 -1.69175e+00  2.60630e-01
21Feb13_033836|  -1.17641e-01]
21Feb13_033836| [-1.89419e+00  5.86120e-01  3.17287e-01  1.23132e+00  8.29902e-01
21Feb13_033836|  -2.27367e-01]
21Feb13_033836| [-9.93682e-01 -4.88945e-01  1.53959e+00 -2.17389e+00  4.91149e-01
21Feb13_033836|  -1.53693e-01]
21Feb13_033836| [-2.37496e+00  1.80554e+00  8.46161e-01 -8.02585e-02 -4.71501e-01
21Feb13_033836|   9.27510e-01]
21Feb13_033836| [ 6.71329e-01  7.64780e-01  1.79372e+00  1.27631e+00  2.45948e-01
21Feb13_033836|  -3.84121e-01]
21Feb13_033836| [ 1.38052e-03  1.00208e-01 -7.26106e-01  2.08987e+00  6.05057e-01
21Feb13_033836|  -3.44705e-01]
21Feb13_033836| [-6.40448e-01 -1.25756e+00 -6.91855e-01 -6.60281e-01 -5.32415e-01
21Feb13_033836|   4.82907e-01]
21Feb13_033836| [-8.29951e-01 -1.45360e-02 -5.18103e-01 -6.96224e-01  9.92941e-01
21Feb13_033836|  -3.74757e-01]
21Feb13_033836| [ 5.04431e-01  1.30316e+00 -7.61889e-01 -5.64505e-01 -1.86976e+00
21Feb13_033836|  -1.65515e+00]
21Feb13_033836| [ 1.80792e+00  9.99541e-01 -7.60678e-01  5.74908e-01 -1.53949e-01
21Feb13_033836|  -5.10970e-01]
21Feb13_033836| [ 5.74980e-01 -2.02913e+00 -5.90122e-04  2.24040e-01  2.40596e+00
21Feb13_033836|   1.13780e+00]
21Feb13_033836| [ 5.37268e-01 -1.13424e+00 -1.13375e+00  9.51094e-01 -2.61279e+00
21Feb13_033836|   3.09503e+00]
21Feb13_033836| [-7.43876e-01 -7.91567e-01 -1.42315e-01 -5.44246e-01 -1.31291e+00
21Feb13_033836|   8.00366e-01]
21Feb13_033836| [-4.43500e-01  5.01447e-01  7.37639e-01 -8.86292e-01 -1.43796e-01
21Feb13_033836|  -4.43199e-01]
21Feb13_033836| [-8.09815e-01 -5.40442e-01 -8.18936e-01 -2.62253e-01  1.23623e+00
21Feb13_033836|  -1.68396e-01]
21Feb13_033836| [-1.41040e+00 -1.68646e+00  6.51829e-01  1.33127e+00 -3.55390e-01
21Feb13_033836|  -6.44956e-01]
21Feb13_033836| [ 1.02374e+00  1.38475e+00 -1.60690e+00  1.39313e+00  1.52072e-01
21Feb13_033836|   1.78248e+00]
21Feb13_033836| [ 5.73046e-01 -1.24317e-01 -9.46218e-01 -9.92492e-01  7.18726e-01
21Feb13_033836|  -1.17057e+00]
21Feb13_033836| [ 7.12853e-01 -2.02767e+00  9.54969e-01  2.94993e-01  3.47986e-01
21Feb13_033836|   6.63350e-01]
21Feb13_033836| [-1.54972e-01 -2.25426e-02 -6.84809e-01  1.52444e+00 -3.08307e-01
21Feb13_033836|   6.16589e-01]
21Feb13_033836| [-2.68374e+00 -4.22414e-01 -8.89236e-01 -1.93846e+00 -6.21410e-03
21Feb13_033836|   2.43379e-02]
21Feb13_033836| [ 1.09577e+00 -1.55455e+00 -6.10941e-02  1.52828e-01 -7.03620e-01
21Feb13_033836|   1.09147e-01]
21Feb13_033836| [-7.87936e-01  6.89893e-01  9.67818e-03 -1.11178e+00 -9.82087e-01
21Feb13_033836|  -2.04381e-02]
21Feb13_033836| [-2.17261e+00 -1.22041e-01 -2.73620e-01 -8.36236e-01 -1.38438e+00
21Feb13_033836|  -2.87446e+00]
21Feb13_033836| [-1.27789e+00 -2.22055e+00  8.59278e-01  1.76093e+00  1.70142e+00
21Feb13_033836|  -3.61876e-01]
21Feb13_033836| [-1.67503e-01 -1.63536e-01 -9.50598e-01  4.35036e-01  5.75847e-01
21Feb13_033836|  -8.25957e-01]
21Feb13_033836| [ 2.38600e-01  6.87028e-01 -1.93100e-01 -1.37955e+00 -1.44922e+00
21Feb13_033836|  -5.58933e-01]
21Feb13_033836| [ 1.39524e+00 -1.73409e+00  5.43499e-01  4.06335e-01  1.47732e+00
21Feb13_033836|  -1.58348e+00]
21Feb13_033836| [ 2.93958e-01 -1.60558e-01 -6.19102e-01  2.12392e+00 -5.84554e-01
21Feb13_033836|  -1.08076e+00]
21Feb13_033836| [-1.03545e+00 -5.95621e-01 -4.88036e-01  2.22136e+00  1.27135e+00
21Feb13_033836|   1.21194e+00]
21Feb13_033836| [ 4.53245e-01 -4.35898e-01  9.15575e-01  5.54548e-01  2.31589e+00
21Feb13_033836|  -1.49880e-01]
21Feb13_033836| [ 1.95697e-01 -7.10320e-01  2.11797e+00  2.19429e-01 -8.34045e-01
21Feb13_033836|   6.75304e-01]
21Feb13_033836| [-1.09139e+00 -4.01523e-01  1.57825e+00 -3.63577e-01  1.27839e+00
21Feb13_033836|  -1.36927e+00]
21Feb13_033836| [-1.11411e+00  8.48703e-01 -1.23858e+00  6.59452e-02  6.16666e-01
21Feb13_033836|  -1.01983e+00]
21Feb13_033836| [ 8.64455e-01 -9.64796e-01  1.83325e+00  7.13131e-01 -1.19417e-01
21Feb13_033836|   1.24116e+00]
21Feb13_033836| [ 8.48703e-01 -1.26355e+00  1.89405e-01 -3.56211e-01  1.75192e+00
21Feb13_033836|  -9.35049e-01]
21Feb13_033836| [-6.05565e-01  1.49776e-01 -5.52038e-01  7.30625e-01  7.54976e-01
21Feb13_033836|  -1.13010e-01]]
21Feb13_033836|-- Bias --
21Feb13_033836|[-0.96395 -1.81574  0.59648 -0.89546  0.53643 -0.54271]
21Feb13_033836|Layer 1:
21Feb13_033836|-- Config --
21Feb13_033836|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_033836|-- Weights --
21Feb13_033836|[[-0.15615 -0.20495]
21Feb13_033836| [-0.32598  1.06694]
21Feb13_033836| [-1.47486  2.25005]
21Feb13_033836| [ 0.99958 -0.64832]
21Feb13_033836| [-0.41273 -1.27368]
21Feb13_033836| [-0.24560 -0.41985]]
21Feb13_033836|-- Bias --
21Feb13_033836|[0.71852 0.71224]
21Feb13_033836|Predicting the validation and test data with the Best final individual.
21Feb13_033843| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_033843|-----------  ------------------  --------------------  ----------
21Feb13_033843|Validation         41.48                  6             0.01804
21Feb13_033843|   Test            36.23                  6             0.01189
21Feb13_033843|-------------------- Test #5 --------------------
21Feb13_033843|Best final individual weights
21Feb13_033843|Individual:
21Feb13_033843|-- Constant hidden layers --
21Feb13_033843|False
21Feb13_033843|Layer 0:
21Feb13_033843|-- Config --
21Feb13_033843|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_033843|-- Weights --
21Feb13_033843|[[-3.22596e+00  8.15030e-02 -6.01515e-01 -4.22099e-01  1.44663e+00
21Feb13_033843|  -1.61649e+00]
21Feb13_033843| [-1.50985e+00 -8.80248e-01  4.97777e-01 -1.13432e+00 -2.07553e-01
21Feb13_033843|  -1.33127e-01]
21Feb13_033843| [-4.93230e-01  9.20894e-01 -6.80714e-01 -2.06675e-01 -1.67587e+00
21Feb13_033843|  -6.52652e-01]
21Feb13_033843| [-2.05655e+00 -1.26240e-01  1.02608e+00  3.31071e-01  2.72223e+00
21Feb13_033843|  -1.74184e-01]
21Feb13_033843| [-3.69830e-01  6.68594e-01  2.26357e-01  2.51533e-01 -6.70313e-01
21Feb13_033843|   2.55592e-01]
21Feb13_033843| [-2.36286e+00  3.86648e-01 -2.15750e+00  1.36469e-02 -1.48716e-01
21Feb13_033843|   1.85106e-02]
21Feb13_033843| [-1.32345e+00  1.17064e-01  4.67906e-01  1.18407e+00 -3.34708e-01
21Feb13_033843|   1.09335e+00]
21Feb13_033843| [ 4.64573e-02 -4.21817e-01 -2.00697e-02  6.73155e-01  2.22709e+00
21Feb13_033843|   1.05368e+00]
21Feb13_033843| [ 1.09741e+00 -4.08370e-01  1.22170e-01  1.54974e+00 -1.16833e-01
21Feb13_033843|   7.13909e-01]
21Feb13_033843| [ 5.46404e-01  2.46330e-01 -1.10982e+00  1.25920e+00 -3.52503e-01
21Feb13_033843|  -1.05035e+00]
21Feb13_033843| [ 3.91003e-01 -4.99730e-01 -1.00691e+00  1.39055e-01  1.92670e-01
21Feb13_033843|  -2.41086e+00]
21Feb13_033843| [-2.87157e-01  2.24456e+00  3.52979e-01  7.50725e-01  3.94071e-01
21Feb13_033843|   1.45677e+00]
21Feb13_033843| [ 1.91678e-02  1.30795e+00  1.99890e+00  2.12176e-01 -1.05133e+00
21Feb13_033843|  -1.54555e+00]
21Feb13_033843| [-1.57311e+00 -1.51965e+00 -1.47786e+00  8.92305e-01 -1.53035e+00
21Feb13_033843|   3.74029e-01]
21Feb13_033843| [-6.10475e-01  7.15578e-01  9.61852e-01  1.61375e+00 -1.90442e+00
21Feb13_033843|  -2.29618e-01]
21Feb13_033843| [ 8.88482e-01  5.42253e-01  1.36180e+00  1.49804e+00 -3.01915e-01
21Feb13_033843|  -1.64657e+00]
21Feb13_033843| [-7.72804e-01 -7.88868e-01 -1.51732e+00  2.67411e+00  4.06295e-01
21Feb13_033843|  -8.92510e-01]
21Feb13_033843| [ 6.46004e-01  5.12295e-01  7.01179e-01 -4.54621e-01  3.75918e-01
21Feb13_033843|   1.49924e+00]
21Feb13_033843| [ 1.52278e+00  1.92058e+00 -9.65125e-01 -4.80307e-01  5.46888e-01
21Feb13_033843|   2.24850e+00]
21Feb13_033843| [ 4.66992e-01  7.44738e-01  2.04032e+00 -7.52850e-01  4.39795e-01
21Feb13_033843|  -1.30633e+00]
21Feb13_033843| [ 5.36590e-03  2.71827e-01 -9.00687e-01 -1.69175e+00  2.60630e-01
21Feb13_033843|  -1.17641e-01]
21Feb13_033843| [-1.89419e+00  5.86120e-01  3.17287e-01  1.23132e+00  8.29902e-01
21Feb13_033843|  -2.27367e-01]
21Feb13_033843| [-9.93682e-01 -4.88945e-01  1.53959e+00 -2.17389e+00  4.91149e-01
21Feb13_033843|  -1.53693e-01]
21Feb13_033843| [-2.37496e+00  1.80554e+00  8.46161e-01 -8.02585e-02 -4.71501e-01
21Feb13_033843|   9.27510e-01]
21Feb13_033843| [ 6.71329e-01  7.64780e-01  1.79372e+00  1.27631e+00  2.45948e-01
21Feb13_033843|  -3.84121e-01]
21Feb13_033843| [ 1.38052e-03  1.00208e-01 -7.26106e-01  2.08987e+00  6.05057e-01
21Feb13_033843|  -3.44705e-01]
21Feb13_033843| [-6.40448e-01 -1.25756e+00 -6.91855e-01 -6.60281e-01 -5.32415e-01
21Feb13_033843|   4.82907e-01]
21Feb13_033843| [-8.29951e-01 -1.45360e-02 -5.18103e-01 -6.96224e-01  9.92941e-01
21Feb13_033843|  -3.74757e-01]
21Feb13_033843| [ 5.04431e-01  1.30316e+00 -7.61889e-01 -5.64505e-01 -1.86976e+00
21Feb13_033843|  -1.65515e+00]
21Feb13_033843| [ 1.80792e+00  9.99541e-01 -7.60678e-01  5.74908e-01 -1.53949e-01
21Feb13_033843|  -5.10970e-01]
21Feb13_033843| [ 5.74980e-01 -2.02913e+00 -5.90122e-04  2.24040e-01  2.40596e+00
21Feb13_033843|   1.13780e+00]
21Feb13_033843| [ 5.37268e-01 -1.13424e+00 -1.13375e+00  9.51094e-01 -2.61279e+00
21Feb13_033843|   3.09503e+00]
21Feb13_033843| [-7.43876e-01 -7.91567e-01 -1.42315e-01 -5.44246e-01 -1.31291e+00
21Feb13_033843|   8.00366e-01]
21Feb13_033843| [-4.43500e-01  5.01447e-01  7.37639e-01 -8.86292e-01 -1.43796e-01
21Feb13_033843|  -4.43199e-01]
21Feb13_033843| [-8.09815e-01 -5.40442e-01 -8.18936e-01 -2.62253e-01  1.23623e+00
21Feb13_033843|  -1.68396e-01]
21Feb13_033843| [-1.41040e+00 -1.68646e+00  6.51829e-01  1.33127e+00 -3.55390e-01
21Feb13_033843|  -6.44956e-01]
21Feb13_033843| [ 1.02374e+00  1.38475e+00 -1.60690e+00  1.39313e+00  1.52072e-01
21Feb13_033843|   1.78248e+00]
21Feb13_033843| [ 5.73046e-01 -1.24317e-01 -9.46218e-01 -9.92492e-01  7.18726e-01
21Feb13_033843|  -1.17057e+00]
21Feb13_033843| [ 7.12853e-01 -2.02767e+00  9.54969e-01  2.94993e-01  3.47986e-01
21Feb13_033843|   6.63350e-01]
21Feb13_033843| [-1.54972e-01 -2.25426e-02 -6.84809e-01  1.52444e+00 -3.08307e-01
21Feb13_033843|   6.16589e-01]
21Feb13_033843| [-2.68374e+00 -4.22414e-01 -8.89236e-01 -1.93846e+00 -6.21410e-03
21Feb13_033843|   2.43379e-02]
21Feb13_033843| [ 1.09577e+00 -1.55455e+00 -6.10941e-02  1.52828e-01 -7.03620e-01
21Feb13_033843|   1.09147e-01]
21Feb13_033843| [-7.87936e-01  6.89893e-01  9.67818e-03 -1.11178e+00 -9.82087e-01
21Feb13_033843|  -2.04381e-02]
21Feb13_033843| [-2.17261e+00 -1.22041e-01 -2.73620e-01 -8.36236e-01 -1.38438e+00
21Feb13_033843|  -2.87446e+00]
21Feb13_033843| [-1.27789e+00 -2.22055e+00  8.59278e-01  1.76093e+00  1.70142e+00
21Feb13_033843|  -3.61876e-01]
21Feb13_033843| [-1.67503e-01 -1.63536e-01 -9.50598e-01  4.35036e-01  5.75847e-01
21Feb13_033843|  -8.25957e-01]
21Feb13_033843| [ 2.38600e-01  6.87028e-01 -1.93100e-01 -1.37955e+00 -1.44922e+00
21Feb13_033843|  -5.58933e-01]
21Feb13_033843| [ 1.39524e+00 -1.73409e+00  5.43499e-01  4.06335e-01  1.47732e+00
21Feb13_033843|  -1.58348e+00]
21Feb13_033843| [ 2.93958e-01 -1.60558e-01 -6.19102e-01  2.12392e+00 -5.84554e-01
21Feb13_033843|  -1.08076e+00]
21Feb13_033843| [-1.03545e+00 -5.95621e-01 -4.88036e-01  2.22136e+00  1.27135e+00
21Feb13_033843|   1.21194e+00]
21Feb13_033843| [ 4.53245e-01 -4.35898e-01  9.15575e-01  5.54548e-01  2.31589e+00
21Feb13_033843|  -1.49880e-01]
21Feb13_033843| [ 1.95697e-01 -7.10320e-01  2.11797e+00  2.19429e-01 -8.34045e-01
21Feb13_033843|   6.75304e-01]
21Feb13_033843| [-1.09139e+00 -4.01523e-01  1.57825e+00 -3.63577e-01  1.27839e+00
21Feb13_033843|  -1.36927e+00]
21Feb13_033843| [-1.11411e+00  8.48703e-01 -1.23858e+00  6.59452e-02  6.16666e-01
21Feb13_033843|  -1.01983e+00]
21Feb13_033843| [ 8.64455e-01 -9.64796e-01  1.83325e+00  7.13131e-01 -1.19417e-01
21Feb13_033843|   1.24116e+00]
21Feb13_033843| [ 8.48703e-01 -1.26355e+00  1.89405e-01 -3.56211e-01  1.75192e+00
21Feb13_033843|  -9.35049e-01]
21Feb13_033843| [-6.05565e-01  1.49776e-01 -5.52038e-01  7.30625e-01  7.54976e-01
21Feb13_033843|  -1.13010e-01]]
21Feb13_033843|-- Bias --
21Feb13_033843|[-0.96395 -1.81574  0.59648 -0.89546  0.53643 -0.54271]
21Feb13_033843|Layer 1:
21Feb13_033843|-- Config --
21Feb13_033843|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_033843|-- Weights --
21Feb13_033843|[[-0.15615 -0.20495]
21Feb13_033843| [-0.32598  1.06694]
21Feb13_033843| [-1.47486  2.25005]
21Feb13_033843| [ 0.99958 -0.64832]
21Feb13_033843| [-0.41273 -1.27368]
21Feb13_033843| [-0.24560 -0.41985]]
21Feb13_033843|-- Bias --
21Feb13_033843|[0.71852 0.71224]
21Feb13_033843|Predicting the validation and test data with the Best final individual.
21Feb13_033850| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_033850|-----------  ------------------  --------------------  ----------
21Feb13_033850|Validation         41.22                  6             0.02318
21Feb13_033850|   Test            36.32                  6             0.01484
21Feb13_033850|-------------------- Test #6 --------------------
21Feb13_033850|Best final individual weights
21Feb13_033850|Individual:
21Feb13_033850|-- Constant hidden layers --
21Feb13_033850|False
21Feb13_033850|Layer 0:
21Feb13_033850|-- Config --
21Feb13_033850|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_033850|-- Weights --
21Feb13_033850|[[-3.22596e+00  8.15030e-02 -6.01515e-01 -4.22099e-01  1.44663e+00
21Feb13_033850|  -1.61649e+00]
21Feb13_033850| [-1.50985e+00 -8.80248e-01  4.97777e-01 -1.13432e+00 -2.07553e-01
21Feb13_033850|  -1.33127e-01]
21Feb13_033850| [-4.93230e-01  9.20894e-01 -6.80714e-01 -2.06675e-01 -1.67587e+00
21Feb13_033850|  -6.52652e-01]
21Feb13_033850| [-2.05655e+00 -1.26240e-01  1.02608e+00  3.31071e-01  2.72223e+00
21Feb13_033850|  -1.74184e-01]
21Feb13_033850| [-3.69830e-01  6.68594e-01  2.26357e-01  2.51533e-01 -6.70313e-01
21Feb13_033850|   2.55592e-01]
21Feb13_033850| [-2.36286e+00  3.86648e-01 -2.15750e+00  1.36469e-02 -1.48716e-01
21Feb13_033850|   1.85106e-02]
21Feb13_033850| [-1.32345e+00  1.17064e-01  4.67906e-01  1.18407e+00 -3.34708e-01
21Feb13_033850|   1.09335e+00]
21Feb13_033850| [ 4.64573e-02 -4.21817e-01 -2.00697e-02  6.73155e-01  2.22709e+00
21Feb13_033850|   1.05368e+00]
21Feb13_033850| [ 1.09741e+00 -4.08370e-01  1.22170e-01  1.54974e+00 -1.16833e-01
21Feb13_033850|   7.13909e-01]
21Feb13_033850| [ 5.46404e-01  2.46330e-01 -1.10982e+00  1.25920e+00 -3.52503e-01
21Feb13_033850|  -1.05035e+00]
21Feb13_033850| [ 3.91003e-01 -4.99730e-01 -1.00691e+00  1.39055e-01  1.92670e-01
21Feb13_033850|  -2.41086e+00]
21Feb13_033850| [-2.87157e-01  2.24456e+00  3.52979e-01  7.50725e-01  3.94071e-01
21Feb13_033850|   1.45677e+00]
21Feb13_033850| [ 1.91678e-02  1.30795e+00  1.99890e+00  2.12176e-01 -1.05133e+00
21Feb13_033850|  -1.54555e+00]
21Feb13_033850| [-1.57311e+00 -1.51965e+00 -1.47786e+00  8.92305e-01 -1.53035e+00
21Feb13_033850|   3.74029e-01]
21Feb13_033850| [-6.10475e-01  7.15578e-01  9.61852e-01  1.61375e+00 -1.90442e+00
21Feb13_033850|  -2.29618e-01]
21Feb13_033850| [ 8.88482e-01  5.42253e-01  1.36180e+00  1.49804e+00 -3.01915e-01
21Feb13_033850|  -1.64657e+00]
21Feb13_033850| [-7.72804e-01 -7.88868e-01 -1.51732e+00  2.67411e+00  4.06295e-01
21Feb13_033850|  -8.92510e-01]
21Feb13_033850| [ 6.46004e-01  5.12295e-01  7.01179e-01 -4.54621e-01  3.75918e-01
21Feb13_033850|   1.49924e+00]
21Feb13_033850| [ 1.52278e+00  1.92058e+00 -9.65125e-01 -4.80307e-01  5.46888e-01
21Feb13_033850|   2.24850e+00]
21Feb13_033850| [ 4.66992e-01  7.44738e-01  2.04032e+00 -7.52850e-01  4.39795e-01
21Feb13_033850|  -1.30633e+00]
21Feb13_033850| [ 5.36590e-03  2.71827e-01 -9.00687e-01 -1.69175e+00  2.60630e-01
21Feb13_033850|  -1.17641e-01]
21Feb13_033850| [-1.89419e+00  5.86120e-01  3.17287e-01  1.23132e+00  8.29902e-01
21Feb13_033850|  -2.27367e-01]
21Feb13_033850| [-9.93682e-01 -4.88945e-01  1.53959e+00 -2.17389e+00  4.91149e-01
21Feb13_033850|  -1.53693e-01]
21Feb13_033850| [-2.37496e+00  1.80554e+00  8.46161e-01 -8.02585e-02 -4.71501e-01
21Feb13_033850|   9.27510e-01]
21Feb13_033850| [ 6.71329e-01  7.64780e-01  1.79372e+00  1.27631e+00  2.45948e-01
21Feb13_033850|  -3.84121e-01]
21Feb13_033850| [ 1.38052e-03  1.00208e-01 -7.26106e-01  2.08987e+00  6.05057e-01
21Feb13_033850|  -3.44705e-01]
21Feb13_033850| [-6.40448e-01 -1.25756e+00 -6.91855e-01 -6.60281e-01 -5.32415e-01
21Feb13_033850|   4.82907e-01]
21Feb13_033850| [-8.29951e-01 -1.45360e-02 -5.18103e-01 -6.96224e-01  9.92941e-01
21Feb13_033850|  -3.74757e-01]
21Feb13_033850| [ 5.04431e-01  1.30316e+00 -7.61889e-01 -5.64505e-01 -1.86976e+00
21Feb13_033850|  -1.65515e+00]
21Feb13_033850| [ 1.80792e+00  9.99541e-01 -7.60678e-01  5.74908e-01 -1.53949e-01
21Feb13_033850|  -5.10970e-01]
21Feb13_033850| [ 5.74980e-01 -2.02913e+00 -5.90122e-04  2.24040e-01  2.40596e+00
21Feb13_033850|   1.13780e+00]
21Feb13_033850| [ 5.37268e-01 -1.13424e+00 -1.13375e+00  9.51094e-01 -2.61279e+00
21Feb13_033850|   3.09503e+00]
21Feb13_033850| [-7.43876e-01 -7.91567e-01 -1.42315e-01 -5.44246e-01 -1.31291e+00
21Feb13_033850|   8.00366e-01]
21Feb13_033850| [-4.43500e-01  5.01447e-01  7.37639e-01 -8.86292e-01 -1.43796e-01
21Feb13_033850|  -4.43199e-01]
21Feb13_033850| [-8.09815e-01 -5.40442e-01 -8.18936e-01 -2.62253e-01  1.23623e+00
21Feb13_033850|  -1.68396e-01]
21Feb13_033850| [-1.41040e+00 -1.68646e+00  6.51829e-01  1.33127e+00 -3.55390e-01
21Feb13_033850|  -6.44956e-01]
21Feb13_033850| [ 1.02374e+00  1.38475e+00 -1.60690e+00  1.39313e+00  1.52072e-01
21Feb13_033850|   1.78248e+00]
21Feb13_033850| [ 5.73046e-01 -1.24317e-01 -9.46218e-01 -9.92492e-01  7.18726e-01
21Feb13_033850|  -1.17057e+00]
21Feb13_033850| [ 7.12853e-01 -2.02767e+00  9.54969e-01  2.94993e-01  3.47986e-01
21Feb13_033850|   6.63350e-01]
21Feb13_033850| [-1.54972e-01 -2.25426e-02 -6.84809e-01  1.52444e+00 -3.08307e-01
21Feb13_033850|   6.16589e-01]
21Feb13_033850| [-2.68374e+00 -4.22414e-01 -8.89236e-01 -1.93846e+00 -6.21410e-03
21Feb13_033850|   2.43379e-02]
21Feb13_033850| [ 1.09577e+00 -1.55455e+00 -6.10941e-02  1.52828e-01 -7.03620e-01
21Feb13_033850|   1.09147e-01]
21Feb13_033850| [-7.87936e-01  6.89893e-01  9.67818e-03 -1.11178e+00 -9.82087e-01
21Feb13_033850|  -2.04381e-02]
21Feb13_033850| [-2.17261e+00 -1.22041e-01 -2.73620e-01 -8.36236e-01 -1.38438e+00
21Feb13_033850|  -2.87446e+00]
21Feb13_033850| [-1.27789e+00 -2.22055e+00  8.59278e-01  1.76093e+00  1.70142e+00
21Feb13_033850|  -3.61876e-01]
21Feb13_033850| [-1.67503e-01 -1.63536e-01 -9.50598e-01  4.35036e-01  5.75847e-01
21Feb13_033850|  -8.25957e-01]
21Feb13_033850| [ 2.38600e-01  6.87028e-01 -1.93100e-01 -1.37955e+00 -1.44922e+00
21Feb13_033850|  -5.58933e-01]
21Feb13_033850| [ 1.39524e+00 -1.73409e+00  5.43499e-01  4.06335e-01  1.47732e+00
21Feb13_033850|  -1.58348e+00]
21Feb13_033850| [ 2.93958e-01 -1.60558e-01 -6.19102e-01  2.12392e+00 -5.84554e-01
21Feb13_033850|  -1.08076e+00]
21Feb13_033850| [-1.03545e+00 -5.95621e-01 -4.88036e-01  2.22136e+00  1.27135e+00
21Feb13_033850|   1.21194e+00]
21Feb13_033850| [ 4.53245e-01 -4.35898e-01  9.15575e-01  5.54548e-01  2.31589e+00
21Feb13_033850|  -1.49880e-01]
21Feb13_033850| [ 1.95697e-01 -7.10320e-01  2.11797e+00  2.19429e-01 -8.34045e-01
21Feb13_033850|   6.75304e-01]
21Feb13_033850| [-1.09139e+00 -4.01523e-01  1.57825e+00 -3.63577e-01  1.27839e+00
21Feb13_033850|  -1.36927e+00]
21Feb13_033850| [-1.11411e+00  8.48703e-01 -1.23858e+00  6.59452e-02  6.16666e-01
21Feb13_033850|  -1.01983e+00]
21Feb13_033850| [ 8.64455e-01 -9.64796e-01  1.83325e+00  7.13131e-01 -1.19417e-01
21Feb13_033850|   1.24116e+00]
21Feb13_033850| [ 8.48703e-01 -1.26355e+00  1.89405e-01 -3.56211e-01  1.75192e+00
21Feb13_033850|  -9.35049e-01]
21Feb13_033850| [-6.05565e-01  1.49776e-01 -5.52038e-01  7.30625e-01  7.54976e-01
21Feb13_033850|  -1.13010e-01]]
21Feb13_033850|-- Bias --
21Feb13_033850|[-0.96395 -1.81574  0.59648 -0.89546  0.53643 -0.54271]
21Feb13_033850|Layer 1:
21Feb13_033850|-- Config --
21Feb13_033850|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_033850|-- Weights --
21Feb13_033850|[[-0.15615 -0.20495]
21Feb13_033850| [-0.32598  1.06694]
21Feb13_033850| [-1.47486  2.25005]
21Feb13_033850| [ 0.99958 -0.64832]
21Feb13_033850| [-0.41273 -1.27368]
21Feb13_033850| [-0.24560 -0.41985]]
21Feb13_033850|-- Bias --
21Feb13_033850|[0.71852 0.71224]
21Feb13_033850|Predicting the validation and test data with the Best final individual.
21Feb13_033857| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_033857|-----------  ------------------  --------------------  ----------
21Feb13_033857|Validation         41.30                  6             0.02317
21Feb13_033857|   Test            36.23                  6             0.01189
21Feb13_033857|-------------------- Test #7 --------------------
21Feb13_033857|Best final individual weights
21Feb13_033857|Individual:
21Feb13_033857|-- Constant hidden layers --
21Feb13_033857|False
21Feb13_033857|Layer 0:
21Feb13_033857|-- Config --
21Feb13_033857|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_033857|-- Weights --
21Feb13_033857|[[-3.22596e+00  8.15030e-02 -6.01515e-01 -4.22099e-01  1.44663e+00
21Feb13_033857|  -1.61649e+00]
21Feb13_033857| [-1.50985e+00 -8.80248e-01  4.97777e-01 -1.13432e+00 -2.07553e-01
21Feb13_033857|  -1.33127e-01]
21Feb13_033857| [-4.93230e-01  9.20894e-01 -6.80714e-01 -2.06675e-01 -1.67587e+00
21Feb13_033857|  -6.52652e-01]
21Feb13_033857| [-2.05655e+00 -1.26240e-01  1.02608e+00  3.31071e-01  2.72223e+00
21Feb13_033857|  -1.74184e-01]
21Feb13_033857| [-3.69830e-01  6.68594e-01  2.26357e-01  2.51533e-01 -6.70313e-01
21Feb13_033857|   2.55592e-01]
21Feb13_033857| [-2.36286e+00  3.86648e-01 -2.15750e+00  1.36469e-02 -1.48716e-01
21Feb13_033857|   1.85106e-02]
21Feb13_033857| [-1.32345e+00  1.17064e-01  4.67906e-01  1.18407e+00 -3.34708e-01
21Feb13_033857|   1.09335e+00]
21Feb13_033857| [ 4.64573e-02 -4.21817e-01 -2.00697e-02  6.73155e-01  2.22709e+00
21Feb13_033857|   1.05368e+00]
21Feb13_033857| [ 1.09741e+00 -4.08370e-01  1.22170e-01  1.54974e+00 -1.16833e-01
21Feb13_033857|   7.13909e-01]
21Feb13_033857| [ 5.46404e-01  2.46330e-01 -1.10982e+00  1.25920e+00 -3.52503e-01
21Feb13_033857|  -1.05035e+00]
21Feb13_033857| [ 3.91003e-01 -4.99730e-01 -1.00691e+00  1.39055e-01  1.92670e-01
21Feb13_033857|  -2.41086e+00]
21Feb13_033857| [-2.87157e-01  2.24456e+00  3.52979e-01  7.50725e-01  3.94071e-01
21Feb13_033857|   1.45677e+00]
21Feb13_033857| [ 1.91678e-02  1.30795e+00  1.99890e+00  2.12176e-01 -1.05133e+00
21Feb13_033857|  -1.54555e+00]
21Feb13_033857| [-1.57311e+00 -1.51965e+00 -1.47786e+00  8.92305e-01 -1.53035e+00
21Feb13_033857|   3.74029e-01]
21Feb13_033857| [-6.10475e-01  7.15578e-01  9.61852e-01  1.61375e+00 -1.90442e+00
21Feb13_033857|  -2.29618e-01]
21Feb13_033857| [ 8.88482e-01  5.42253e-01  1.36180e+00  1.49804e+00 -3.01915e-01
21Feb13_033857|  -1.64657e+00]
21Feb13_033857| [-7.72804e-01 -7.88868e-01 -1.51732e+00  2.67411e+00  4.06295e-01
21Feb13_033857|  -8.92510e-01]
21Feb13_033857| [ 6.46004e-01  5.12295e-01  7.01179e-01 -4.54621e-01  3.75918e-01
21Feb13_033857|   1.49924e+00]
21Feb13_033857| [ 1.52278e+00  1.92058e+00 -9.65125e-01 -4.80307e-01  5.46888e-01
21Feb13_033857|   2.24850e+00]
21Feb13_033857| [ 4.66992e-01  7.44738e-01  2.04032e+00 -7.52850e-01  4.39795e-01
21Feb13_033857|  -1.30633e+00]
21Feb13_033857| [ 5.36590e-03  2.71827e-01 -9.00687e-01 -1.69175e+00  2.60630e-01
21Feb13_033857|  -1.17641e-01]
21Feb13_033857| [-1.89419e+00  5.86120e-01  3.17287e-01  1.23132e+00  8.29902e-01
21Feb13_033857|  -2.27367e-01]
21Feb13_033857| [-9.93682e-01 -4.88945e-01  1.53959e+00 -2.17389e+00  4.91149e-01
21Feb13_033857|  -1.53693e-01]
21Feb13_033857| [-2.37496e+00  1.80554e+00  8.46161e-01 -8.02585e-02 -4.71501e-01
21Feb13_033857|   9.27510e-01]
21Feb13_033857| [ 6.71329e-01  7.64780e-01  1.79372e+00  1.27631e+00  2.45948e-01
21Feb13_033857|  -3.84121e-01]
21Feb13_033857| [ 1.38052e-03  1.00208e-01 -7.26106e-01  2.08987e+00  6.05057e-01
21Feb13_033857|  -3.44705e-01]
21Feb13_033857| [-6.40448e-01 -1.25756e+00 -6.91855e-01 -6.60281e-01 -5.32415e-01
21Feb13_033857|   4.82907e-01]
21Feb13_033857| [-8.29951e-01 -1.45360e-02 -5.18103e-01 -6.96224e-01  9.92941e-01
21Feb13_033857|  -3.74757e-01]
21Feb13_033857| [ 5.04431e-01  1.30316e+00 -7.61889e-01 -5.64505e-01 -1.86976e+00
21Feb13_033857|  -1.65515e+00]
21Feb13_033857| [ 1.80792e+00  9.99541e-01 -7.60678e-01  5.74908e-01 -1.53949e-01
21Feb13_033857|  -5.10970e-01]
21Feb13_033857| [ 5.74980e-01 -2.02913e+00 -5.90122e-04  2.24040e-01  2.40596e+00
21Feb13_033857|   1.13780e+00]
21Feb13_033857| [ 5.37268e-01 -1.13424e+00 -1.13375e+00  9.51094e-01 -2.61279e+00
21Feb13_033857|   3.09503e+00]
21Feb13_033857| [-7.43876e-01 -7.91567e-01 -1.42315e-01 -5.44246e-01 -1.31291e+00
21Feb13_033857|   8.00366e-01]
21Feb13_033857| [-4.43500e-01  5.01447e-01  7.37639e-01 -8.86292e-01 -1.43796e-01
21Feb13_033857|  -4.43199e-01]
21Feb13_033857| [-8.09815e-01 -5.40442e-01 -8.18936e-01 -2.62253e-01  1.23623e+00
21Feb13_033857|  -1.68396e-01]
21Feb13_033857| [-1.41040e+00 -1.68646e+00  6.51829e-01  1.33127e+00 -3.55390e-01
21Feb13_033857|  -6.44956e-01]
21Feb13_033857| [ 1.02374e+00  1.38475e+00 -1.60690e+00  1.39313e+00  1.52072e-01
21Feb13_033857|   1.78248e+00]
21Feb13_033857| [ 5.73046e-01 -1.24317e-01 -9.46218e-01 -9.92492e-01  7.18726e-01
21Feb13_033857|  -1.17057e+00]
21Feb13_033857| [ 7.12853e-01 -2.02767e+00  9.54969e-01  2.94993e-01  3.47986e-01
21Feb13_033857|   6.63350e-01]
21Feb13_033857| [-1.54972e-01 -2.25426e-02 -6.84809e-01  1.52444e+00 -3.08307e-01
21Feb13_033857|   6.16589e-01]
21Feb13_033857| [-2.68374e+00 -4.22414e-01 -8.89236e-01 -1.93846e+00 -6.21410e-03
21Feb13_033857|   2.43379e-02]
21Feb13_033857| [ 1.09577e+00 -1.55455e+00 -6.10941e-02  1.52828e-01 -7.03620e-01
21Feb13_033857|   1.09147e-01]
21Feb13_033857| [-7.87936e-01  6.89893e-01  9.67818e-03 -1.11178e+00 -9.82087e-01
21Feb13_033857|  -2.04381e-02]
21Feb13_033857| [-2.17261e+00 -1.22041e-01 -2.73620e-01 -8.36236e-01 -1.38438e+00
21Feb13_033857|  -2.87446e+00]
21Feb13_033857| [-1.27789e+00 -2.22055e+00  8.59278e-01  1.76093e+00  1.70142e+00
21Feb13_033857|  -3.61876e-01]
21Feb13_033857| [-1.67503e-01 -1.63536e-01 -9.50598e-01  4.35036e-01  5.75847e-01
21Feb13_033857|  -8.25957e-01]
21Feb13_033857| [ 2.38600e-01  6.87028e-01 -1.93100e-01 -1.37955e+00 -1.44922e+00
21Feb13_033857|  -5.58933e-01]
21Feb13_033857| [ 1.39524e+00 -1.73409e+00  5.43499e-01  4.06335e-01  1.47732e+00
21Feb13_033857|  -1.58348e+00]
21Feb13_033857| [ 2.93958e-01 -1.60558e-01 -6.19102e-01  2.12392e+00 -5.84554e-01
21Feb13_033857|  -1.08076e+00]
21Feb13_033857| [-1.03545e+00 -5.95621e-01 -4.88036e-01  2.22136e+00  1.27135e+00
21Feb13_033857|   1.21194e+00]
21Feb13_033857| [ 4.53245e-01 -4.35898e-01  9.15575e-01  5.54548e-01  2.31589e+00
21Feb13_033857|  -1.49880e-01]
21Feb13_033857| [ 1.95697e-01 -7.10320e-01  2.11797e+00  2.19429e-01 -8.34045e-01
21Feb13_033857|   6.75304e-01]
21Feb13_033857| [-1.09139e+00 -4.01523e-01  1.57825e+00 -3.63577e-01  1.27839e+00
21Feb13_033857|  -1.36927e+00]
21Feb13_033857| [-1.11411e+00  8.48703e-01 -1.23858e+00  6.59452e-02  6.16666e-01
21Feb13_033857|  -1.01983e+00]
21Feb13_033857| [ 8.64455e-01 -9.64796e-01  1.83325e+00  7.13131e-01 -1.19417e-01
21Feb13_033857|   1.24116e+00]
21Feb13_033857| [ 8.48703e-01 -1.26355e+00  1.89405e-01 -3.56211e-01  1.75192e+00
21Feb13_033857|  -9.35049e-01]
21Feb13_033857| [-6.05565e-01  1.49776e-01 -5.52038e-01  7.30625e-01  7.54976e-01
21Feb13_033857|  -1.13010e-01]]
21Feb13_033857|-- Bias --
21Feb13_033857|[-0.96395 -1.81574  0.59648 -0.89546  0.53643 -0.54271]
21Feb13_033857|Layer 1:
21Feb13_033857|-- Config --
21Feb13_033857|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_033857|-- Weights --
21Feb13_033857|[[-0.15615 -0.20495]
21Feb13_033857| [-0.32598  1.06694]
21Feb13_033857| [-1.47486  2.25005]
21Feb13_033857| [ 0.99958 -0.64832]
21Feb13_033857| [-0.41273 -1.27368]
21Feb13_033857| [-0.24560 -0.41985]]
21Feb13_033857|-- Bias --
21Feb13_033857|[0.71852 0.71224]
21Feb13_033857|Predicting the validation and test data with the Best final individual.
21Feb13_033904| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_033904|-----------  ------------------  --------------------  ----------
21Feb13_033904|Validation         41.30                  6             0.02317
21Feb13_033904|   Test            36.23                  6             0.01485
21Feb13_033904|-------------------- Test #8 --------------------
21Feb13_033904|Best final individual weights
21Feb13_033904|Individual:
21Feb13_033904|-- Constant hidden layers --
21Feb13_033904|False
21Feb13_033904|Layer 0:
21Feb13_033904|-- Config --
21Feb13_033904|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_033904|-- Weights --
21Feb13_033904|[[-3.22596e+00  8.15030e-02 -6.01515e-01 -4.22099e-01  1.44663e+00
21Feb13_033904|  -1.61649e+00]
21Feb13_033904| [-1.50985e+00 -8.80248e-01  4.97777e-01 -1.13432e+00 -2.07553e-01
21Feb13_033904|  -1.33127e-01]
21Feb13_033904| [-4.93230e-01  9.20894e-01 -6.80714e-01 -2.06675e-01 -1.67587e+00
21Feb13_033904|  -6.52652e-01]
21Feb13_033904| [-2.05655e+00 -1.26240e-01  1.02608e+00  3.31071e-01  2.72223e+00
21Feb13_033904|  -1.74184e-01]
21Feb13_033904| [-3.69830e-01  6.68594e-01  2.26357e-01  2.51533e-01 -6.70313e-01
21Feb13_033904|   2.55592e-01]
21Feb13_033904| [-2.36286e+00  3.86648e-01 -2.15750e+00  1.36469e-02 -1.48716e-01
21Feb13_033904|   1.85106e-02]
21Feb13_033904| [-1.32345e+00  1.17064e-01  4.67906e-01  1.18407e+00 -3.34708e-01
21Feb13_033904|   1.09335e+00]
21Feb13_033904| [ 4.64573e-02 -4.21817e-01 -2.00697e-02  6.73155e-01  2.22709e+00
21Feb13_033904|   1.05368e+00]
21Feb13_033904| [ 1.09741e+00 -4.08370e-01  1.22170e-01  1.54974e+00 -1.16833e-01
21Feb13_033904|   7.13909e-01]
21Feb13_033904| [ 5.46404e-01  2.46330e-01 -1.10982e+00  1.25920e+00 -3.52503e-01
21Feb13_033904|  -1.05035e+00]
21Feb13_033904| [ 3.91003e-01 -4.99730e-01 -1.00691e+00  1.39055e-01  1.92670e-01
21Feb13_033904|  -2.41086e+00]
21Feb13_033904| [-2.87157e-01  2.24456e+00  3.52979e-01  7.50725e-01  3.94071e-01
21Feb13_033904|   1.45677e+00]
21Feb13_033904| [ 1.91678e-02  1.30795e+00  1.99890e+00  2.12176e-01 -1.05133e+00
21Feb13_033904|  -1.54555e+00]
21Feb13_033904| [-1.57311e+00 -1.51965e+00 -1.47786e+00  8.92305e-01 -1.53035e+00
21Feb13_033904|   3.74029e-01]
21Feb13_033904| [-6.10475e-01  7.15578e-01  9.61852e-01  1.61375e+00 -1.90442e+00
21Feb13_033904|  -2.29618e-01]
21Feb13_033904| [ 8.88482e-01  5.42253e-01  1.36180e+00  1.49804e+00 -3.01915e-01
21Feb13_033904|  -1.64657e+00]
21Feb13_033904| [-7.72804e-01 -7.88868e-01 -1.51732e+00  2.67411e+00  4.06295e-01
21Feb13_033904|  -8.92510e-01]
21Feb13_033904| [ 6.46004e-01  5.12295e-01  7.01179e-01 -4.54621e-01  3.75918e-01
21Feb13_033904|   1.49924e+00]
21Feb13_033904| [ 1.52278e+00  1.92058e+00 -9.65125e-01 -4.80307e-01  5.46888e-01
21Feb13_033904|   2.24850e+00]
21Feb13_033904| [ 4.66992e-01  7.44738e-01  2.04032e+00 -7.52850e-01  4.39795e-01
21Feb13_033904|  -1.30633e+00]
21Feb13_033904| [ 5.36590e-03  2.71827e-01 -9.00687e-01 -1.69175e+00  2.60630e-01
21Feb13_033904|  -1.17641e-01]
21Feb13_033904| [-1.89419e+00  5.86120e-01  3.17287e-01  1.23132e+00  8.29902e-01
21Feb13_033904|  -2.27367e-01]
21Feb13_033904| [-9.93682e-01 -4.88945e-01  1.53959e+00 -2.17389e+00  4.91149e-01
21Feb13_033904|  -1.53693e-01]
21Feb13_033904| [-2.37496e+00  1.80554e+00  8.46161e-01 -8.02585e-02 -4.71501e-01
21Feb13_033904|   9.27510e-01]
21Feb13_033904| [ 6.71329e-01  7.64780e-01  1.79372e+00  1.27631e+00  2.45948e-01
21Feb13_033904|  -3.84121e-01]
21Feb13_033904| [ 1.38052e-03  1.00208e-01 -7.26106e-01  2.08987e+00  6.05057e-01
21Feb13_033904|  -3.44705e-01]
21Feb13_033904| [-6.40448e-01 -1.25756e+00 -6.91855e-01 -6.60281e-01 -5.32415e-01
21Feb13_033904|   4.82907e-01]
21Feb13_033904| [-8.29951e-01 -1.45360e-02 -5.18103e-01 -6.96224e-01  9.92941e-01
21Feb13_033904|  -3.74757e-01]
21Feb13_033904| [ 5.04431e-01  1.30316e+00 -7.61889e-01 -5.64505e-01 -1.86976e+00
21Feb13_033904|  -1.65515e+00]
21Feb13_033904| [ 1.80792e+00  9.99541e-01 -7.60678e-01  5.74908e-01 -1.53949e-01
21Feb13_033904|  -5.10970e-01]
21Feb13_033904| [ 5.74980e-01 -2.02913e+00 -5.90122e-04  2.24040e-01  2.40596e+00
21Feb13_033904|   1.13780e+00]
21Feb13_033904| [ 5.37268e-01 -1.13424e+00 -1.13375e+00  9.51094e-01 -2.61279e+00
21Feb13_033904|   3.09503e+00]
21Feb13_033904| [-7.43876e-01 -7.91567e-01 -1.42315e-01 -5.44246e-01 -1.31291e+00
21Feb13_033904|   8.00366e-01]
21Feb13_033904| [-4.43500e-01  5.01447e-01  7.37639e-01 -8.86292e-01 -1.43796e-01
21Feb13_033904|  -4.43199e-01]
21Feb13_033904| [-8.09815e-01 -5.40442e-01 -8.18936e-01 -2.62253e-01  1.23623e+00
21Feb13_033904|  -1.68396e-01]
21Feb13_033904| [-1.41040e+00 -1.68646e+00  6.51829e-01  1.33127e+00 -3.55390e-01
21Feb13_033904|  -6.44956e-01]
21Feb13_033904| [ 1.02374e+00  1.38475e+00 -1.60690e+00  1.39313e+00  1.52072e-01
21Feb13_033904|   1.78248e+00]
21Feb13_033904| [ 5.73046e-01 -1.24317e-01 -9.46218e-01 -9.92492e-01  7.18726e-01
21Feb13_033904|  -1.17057e+00]
21Feb13_033904| [ 7.12853e-01 -2.02767e+00  9.54969e-01  2.94993e-01  3.47986e-01
21Feb13_033904|   6.63350e-01]
21Feb13_033904| [-1.54972e-01 -2.25426e-02 -6.84809e-01  1.52444e+00 -3.08307e-01
21Feb13_033904|   6.16589e-01]
21Feb13_033904| [-2.68374e+00 -4.22414e-01 -8.89236e-01 -1.93846e+00 -6.21410e-03
21Feb13_033904|   2.43379e-02]
21Feb13_033904| [ 1.09577e+00 -1.55455e+00 -6.10941e-02  1.52828e-01 -7.03620e-01
21Feb13_033904|   1.09147e-01]
21Feb13_033904| [-7.87936e-01  6.89893e-01  9.67818e-03 -1.11178e+00 -9.82087e-01
21Feb13_033904|  -2.04381e-02]
21Feb13_033904| [-2.17261e+00 -1.22041e-01 -2.73620e-01 -8.36236e-01 -1.38438e+00
21Feb13_033904|  -2.87446e+00]
21Feb13_033904| [-1.27789e+00 -2.22055e+00  8.59278e-01  1.76093e+00  1.70142e+00
21Feb13_033904|  -3.61876e-01]
21Feb13_033904| [-1.67503e-01 -1.63536e-01 -9.50598e-01  4.35036e-01  5.75847e-01
21Feb13_033904|  -8.25957e-01]
21Feb13_033904| [ 2.38600e-01  6.87028e-01 -1.93100e-01 -1.37955e+00 -1.44922e+00
21Feb13_033904|  -5.58933e-01]
21Feb13_033904| [ 1.39524e+00 -1.73409e+00  5.43499e-01  4.06335e-01  1.47732e+00
21Feb13_033904|  -1.58348e+00]
21Feb13_033904| [ 2.93958e-01 -1.60558e-01 -6.19102e-01  2.12392e+00 -5.84554e-01
21Feb13_033904|  -1.08076e+00]
21Feb13_033904| [-1.03545e+00 -5.95621e-01 -4.88036e-01  2.22136e+00  1.27135e+00
21Feb13_033904|   1.21194e+00]
21Feb13_033904| [ 4.53245e-01 -4.35898e-01  9.15575e-01  5.54548e-01  2.31589e+00
21Feb13_033904|  -1.49880e-01]
21Feb13_033904| [ 1.95697e-01 -7.10320e-01  2.11797e+00  2.19429e-01 -8.34045e-01
21Feb13_033904|   6.75304e-01]
21Feb13_033904| [-1.09139e+00 -4.01523e-01  1.57825e+00 -3.63577e-01  1.27839e+00
21Feb13_033904|  -1.36927e+00]
21Feb13_033904| [-1.11411e+00  8.48703e-01 -1.23858e+00  6.59452e-02  6.16666e-01
21Feb13_033904|  -1.01983e+00]
21Feb13_033904| [ 8.64455e-01 -9.64796e-01  1.83325e+00  7.13131e-01 -1.19417e-01
21Feb13_033904|   1.24116e+00]
21Feb13_033904| [ 8.48703e-01 -1.26355e+00  1.89405e-01 -3.56211e-01  1.75192e+00
21Feb13_033904|  -9.35049e-01]
21Feb13_033904| [-6.05565e-01  1.49776e-01 -5.52038e-01  7.30625e-01  7.54976e-01
21Feb13_033904|  -1.13010e-01]]
21Feb13_033904|-- Bias --
21Feb13_033904|[-0.96395 -1.81574  0.59648 -0.89546  0.53643 -0.54271]
21Feb13_033904|Layer 1:
21Feb13_033904|-- Config --
21Feb13_033904|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_033904|-- Weights --
21Feb13_033904|[[-0.15615 -0.20495]
21Feb13_033904| [-0.32598  1.06694]
21Feb13_033904| [-1.47486  2.25005]
21Feb13_033904| [ 0.99958 -0.64832]
21Feb13_033904| [-0.41273 -1.27368]
21Feb13_033904| [-0.24560 -0.41985]]
21Feb13_033904|-- Bias --
21Feb13_033904|[0.71852 0.71224]
21Feb13_033904|Predicting the validation and test data with the Best final individual.
21Feb13_033911| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_033911|-----------  ------------------  --------------------  ----------
21Feb13_033911|Validation         41.22                  6             0.02573
21Feb13_033911|   Test            36.23                  6             0.01189
21Feb13_033911|-------------------- Test #9 --------------------
21Feb13_033911|Best final individual weights
21Feb13_033911|Individual:
21Feb13_033911|-- Constant hidden layers --
21Feb13_033911|False
21Feb13_033911|Layer 0:
21Feb13_033911|-- Config --
21Feb13_033911|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_033911|-- Weights --
21Feb13_033911|[[-3.22596e+00  8.15030e-02 -6.01515e-01 -4.22099e-01  1.44663e+00
21Feb13_033911|  -1.61649e+00]
21Feb13_033911| [-1.50985e+00 -8.80248e-01  4.97777e-01 -1.13432e+00 -2.07553e-01
21Feb13_033911|  -1.33127e-01]
21Feb13_033911| [-4.93230e-01  9.20894e-01 -6.80714e-01 -2.06675e-01 -1.67587e+00
21Feb13_033911|  -6.52652e-01]
21Feb13_033911| [-2.05655e+00 -1.26240e-01  1.02608e+00  3.31071e-01  2.72223e+00
21Feb13_033911|  -1.74184e-01]
21Feb13_033911| [-3.69830e-01  6.68594e-01  2.26357e-01  2.51533e-01 -6.70313e-01
21Feb13_033911|   2.55592e-01]
21Feb13_033911| [-2.36286e+00  3.86648e-01 -2.15750e+00  1.36469e-02 -1.48716e-01
21Feb13_033911|   1.85106e-02]
21Feb13_033911| [-1.32345e+00  1.17064e-01  4.67906e-01  1.18407e+00 -3.34708e-01
21Feb13_033911|   1.09335e+00]
21Feb13_033911| [ 4.64573e-02 -4.21817e-01 -2.00697e-02  6.73155e-01  2.22709e+00
21Feb13_033911|   1.05368e+00]
21Feb13_033911| [ 1.09741e+00 -4.08370e-01  1.22170e-01  1.54974e+00 -1.16833e-01
21Feb13_033911|   7.13909e-01]
21Feb13_033911| [ 5.46404e-01  2.46330e-01 -1.10982e+00  1.25920e+00 -3.52503e-01
21Feb13_033911|  -1.05035e+00]
21Feb13_033911| [ 3.91003e-01 -4.99730e-01 -1.00691e+00  1.39055e-01  1.92670e-01
21Feb13_033911|  -2.41086e+00]
21Feb13_033911| [-2.87157e-01  2.24456e+00  3.52979e-01  7.50725e-01  3.94071e-01
21Feb13_033911|   1.45677e+00]
21Feb13_033911| [ 1.91678e-02  1.30795e+00  1.99890e+00  2.12176e-01 -1.05133e+00
21Feb13_033911|  -1.54555e+00]
21Feb13_033911| [-1.57311e+00 -1.51965e+00 -1.47786e+00  8.92305e-01 -1.53035e+00
21Feb13_033911|   3.74029e-01]
21Feb13_033911| [-6.10475e-01  7.15578e-01  9.61852e-01  1.61375e+00 -1.90442e+00
21Feb13_033911|  -2.29618e-01]
21Feb13_033911| [ 8.88482e-01  5.42253e-01  1.36180e+00  1.49804e+00 -3.01915e-01
21Feb13_033911|  -1.64657e+00]
21Feb13_033911| [-7.72804e-01 -7.88868e-01 -1.51732e+00  2.67411e+00  4.06295e-01
21Feb13_033911|  -8.92510e-01]
21Feb13_033911| [ 6.46004e-01  5.12295e-01  7.01179e-01 -4.54621e-01  3.75918e-01
21Feb13_033911|   1.49924e+00]
21Feb13_033911| [ 1.52278e+00  1.92058e+00 -9.65125e-01 -4.80307e-01  5.46888e-01
21Feb13_033911|   2.24850e+00]
21Feb13_033911| [ 4.66992e-01  7.44738e-01  2.04032e+00 -7.52850e-01  4.39795e-01
21Feb13_033911|  -1.30633e+00]
21Feb13_033911| [ 5.36590e-03  2.71827e-01 -9.00687e-01 -1.69175e+00  2.60630e-01
21Feb13_033911|  -1.17641e-01]
21Feb13_033911| [-1.89419e+00  5.86120e-01  3.17287e-01  1.23132e+00  8.29902e-01
21Feb13_033911|  -2.27367e-01]
21Feb13_033911| [-9.93682e-01 -4.88945e-01  1.53959e+00 -2.17389e+00  4.91149e-01
21Feb13_033911|  -1.53693e-01]
21Feb13_033911| [-2.37496e+00  1.80554e+00  8.46161e-01 -8.02585e-02 -4.71501e-01
21Feb13_033911|   9.27510e-01]
21Feb13_033911| [ 6.71329e-01  7.64780e-01  1.79372e+00  1.27631e+00  2.45948e-01
21Feb13_033911|  -3.84121e-01]
21Feb13_033911| [ 1.38052e-03  1.00208e-01 -7.26106e-01  2.08987e+00  6.05057e-01
21Feb13_033911|  -3.44705e-01]
21Feb13_033911| [-6.40448e-01 -1.25756e+00 -6.91855e-01 -6.60281e-01 -5.32415e-01
21Feb13_033911|   4.82907e-01]
21Feb13_033911| [-8.29951e-01 -1.45360e-02 -5.18103e-01 -6.96224e-01  9.92941e-01
21Feb13_033911|  -3.74757e-01]
21Feb13_033911| [ 5.04431e-01  1.30316e+00 -7.61889e-01 -5.64505e-01 -1.86976e+00
21Feb13_033911|  -1.65515e+00]
21Feb13_033911| [ 1.80792e+00  9.99541e-01 -7.60678e-01  5.74908e-01 -1.53949e-01
21Feb13_033911|  -5.10970e-01]
21Feb13_033911| [ 5.74980e-01 -2.02913e+00 -5.90122e-04  2.24040e-01  2.40596e+00
21Feb13_033911|   1.13780e+00]
21Feb13_033911| [ 5.37268e-01 -1.13424e+00 -1.13375e+00  9.51094e-01 -2.61279e+00
21Feb13_033911|   3.09503e+00]
21Feb13_033911| [-7.43876e-01 -7.91567e-01 -1.42315e-01 -5.44246e-01 -1.31291e+00
21Feb13_033911|   8.00366e-01]
21Feb13_033911| [-4.43500e-01  5.01447e-01  7.37639e-01 -8.86292e-01 -1.43796e-01
21Feb13_033911|  -4.43199e-01]
21Feb13_033911| [-8.09815e-01 -5.40442e-01 -8.18936e-01 -2.62253e-01  1.23623e+00
21Feb13_033911|  -1.68396e-01]
21Feb13_033911| [-1.41040e+00 -1.68646e+00  6.51829e-01  1.33127e+00 -3.55390e-01
21Feb13_033911|  -6.44956e-01]
21Feb13_033911| [ 1.02374e+00  1.38475e+00 -1.60690e+00  1.39313e+00  1.52072e-01
21Feb13_033911|   1.78248e+00]
21Feb13_033911| [ 5.73046e-01 -1.24317e-01 -9.46218e-01 -9.92492e-01  7.18726e-01
21Feb13_033911|  -1.17057e+00]
21Feb13_033911| [ 7.12853e-01 -2.02767e+00  9.54969e-01  2.94993e-01  3.47986e-01
21Feb13_033911|   6.63350e-01]
21Feb13_033911| [-1.54972e-01 -2.25426e-02 -6.84809e-01  1.52444e+00 -3.08307e-01
21Feb13_033911|   6.16589e-01]
21Feb13_033911| [-2.68374e+00 -4.22414e-01 -8.89236e-01 -1.93846e+00 -6.21410e-03
21Feb13_033911|   2.43379e-02]
21Feb13_033911| [ 1.09577e+00 -1.55455e+00 -6.10941e-02  1.52828e-01 -7.03620e-01
21Feb13_033911|   1.09147e-01]
21Feb13_033911| [-7.87936e-01  6.89893e-01  9.67818e-03 -1.11178e+00 -9.82087e-01
21Feb13_033911|  -2.04381e-02]
21Feb13_033911| [-2.17261e+00 -1.22041e-01 -2.73620e-01 -8.36236e-01 -1.38438e+00
21Feb13_033911|  -2.87446e+00]
21Feb13_033911| [-1.27789e+00 -2.22055e+00  8.59278e-01  1.76093e+00  1.70142e+00
21Feb13_033911|  -3.61876e-01]
21Feb13_033911| [-1.67503e-01 -1.63536e-01 -9.50598e-01  4.35036e-01  5.75847e-01
21Feb13_033911|  -8.25957e-01]
21Feb13_033911| [ 2.38600e-01  6.87028e-01 -1.93100e-01 -1.37955e+00 -1.44922e+00
21Feb13_033911|  -5.58933e-01]
21Feb13_033911| [ 1.39524e+00 -1.73409e+00  5.43499e-01  4.06335e-01  1.47732e+00
21Feb13_033911|  -1.58348e+00]
21Feb13_033911| [ 2.93958e-01 -1.60558e-01 -6.19102e-01  2.12392e+00 -5.84554e-01
21Feb13_033911|  -1.08076e+00]
21Feb13_033911| [-1.03545e+00 -5.95621e-01 -4.88036e-01  2.22136e+00  1.27135e+00
21Feb13_033911|   1.21194e+00]
21Feb13_033911| [ 4.53245e-01 -4.35898e-01  9.15575e-01  5.54548e-01  2.31589e+00
21Feb13_033911|  -1.49880e-01]
21Feb13_033911| [ 1.95697e-01 -7.10320e-01  2.11797e+00  2.19429e-01 -8.34045e-01
21Feb13_033911|   6.75304e-01]
21Feb13_033911| [-1.09139e+00 -4.01523e-01  1.57825e+00 -3.63577e-01  1.27839e+00
21Feb13_033911|  -1.36927e+00]
21Feb13_033911| [-1.11411e+00  8.48703e-01 -1.23858e+00  6.59452e-02  6.16666e-01
21Feb13_033911|  -1.01983e+00]
21Feb13_033911| [ 8.64455e-01 -9.64796e-01  1.83325e+00  7.13131e-01 -1.19417e-01
21Feb13_033911|   1.24116e+00]
21Feb13_033911| [ 8.48703e-01 -1.26355e+00  1.89405e-01 -3.56211e-01  1.75192e+00
21Feb13_033911|  -9.35049e-01]
21Feb13_033911| [-6.05565e-01  1.49776e-01 -5.52038e-01  7.30625e-01  7.54976e-01
21Feb13_033911|  -1.13010e-01]]
21Feb13_033911|-- Bias --
21Feb13_033911|[-0.96395 -1.81574  0.59648 -0.89546  0.53643 -0.54271]
21Feb13_033911|Layer 1:
21Feb13_033911|-- Config --
21Feb13_033911|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_033911|-- Weights --
21Feb13_033911|[[-0.15615 -0.20495]
21Feb13_033911| [-0.32598  1.06694]
21Feb13_033911| [-1.47486  2.25005]
21Feb13_033911| [ 0.99958 -0.64832]
21Feb13_033911| [-0.41273 -1.27368]
21Feb13_033911| [-0.24560 -0.41985]]
21Feb13_033911|-- Bias --
21Feb13_033911|[0.71852 0.71224]
21Feb13_033911|Predicting the validation and test data with the Best final individual.
21Feb13_033918| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_033918|-----------  ------------------  --------------------  ----------
21Feb13_033918|Validation         41.30                  6             0.02317
21Feb13_033918|   Test            36.66                  6             0.00297
21Feb13_033918|-------------------- Test #10 --------------------
21Feb13_033918|Best final individual weights
21Feb13_033918|Individual:
21Feb13_033918|-- Constant hidden layers --
21Feb13_033918|False
21Feb13_033918|Layer 0:
21Feb13_033918|-- Config --
21Feb13_033918|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_033918|-- Weights --
21Feb13_033918|[[-3.22596e+00  8.15030e-02 -6.01515e-01 -4.22099e-01  1.44663e+00
21Feb13_033918|  -1.61649e+00]
21Feb13_033918| [-1.50985e+00 -8.80248e-01  4.97777e-01 -1.13432e+00 -2.07553e-01
21Feb13_033918|  -1.33127e-01]
21Feb13_033918| [-4.93230e-01  9.20894e-01 -6.80714e-01 -2.06675e-01 -1.67587e+00
21Feb13_033918|  -6.52652e-01]
21Feb13_033918| [-2.05655e+00 -1.26240e-01  1.02608e+00  3.31071e-01  2.72223e+00
21Feb13_033918|  -1.74184e-01]
21Feb13_033918| [-3.69830e-01  6.68594e-01  2.26357e-01  2.51533e-01 -6.70313e-01
21Feb13_033918|   2.55592e-01]
21Feb13_033918| [-2.36286e+00  3.86648e-01 -2.15750e+00  1.36469e-02 -1.48716e-01
21Feb13_033918|   1.85106e-02]
21Feb13_033918| [-1.32345e+00  1.17064e-01  4.67906e-01  1.18407e+00 -3.34708e-01
21Feb13_033918|   1.09335e+00]
21Feb13_033918| [ 4.64573e-02 -4.21817e-01 -2.00697e-02  6.73155e-01  2.22709e+00
21Feb13_033918|   1.05368e+00]
21Feb13_033918| [ 1.09741e+00 -4.08370e-01  1.22170e-01  1.54974e+00 -1.16833e-01
21Feb13_033918|   7.13909e-01]
21Feb13_033918| [ 5.46404e-01  2.46330e-01 -1.10982e+00  1.25920e+00 -3.52503e-01
21Feb13_033918|  -1.05035e+00]
21Feb13_033918| [ 3.91003e-01 -4.99730e-01 -1.00691e+00  1.39055e-01  1.92670e-01
21Feb13_033918|  -2.41086e+00]
21Feb13_033918| [-2.87157e-01  2.24456e+00  3.52979e-01  7.50725e-01  3.94071e-01
21Feb13_033918|   1.45677e+00]
21Feb13_033918| [ 1.91678e-02  1.30795e+00  1.99890e+00  2.12176e-01 -1.05133e+00
21Feb13_033918|  -1.54555e+00]
21Feb13_033918| [-1.57311e+00 -1.51965e+00 -1.47786e+00  8.92305e-01 -1.53035e+00
21Feb13_033918|   3.74029e-01]
21Feb13_033918| [-6.10475e-01  7.15578e-01  9.61852e-01  1.61375e+00 -1.90442e+00
21Feb13_033918|  -2.29618e-01]
21Feb13_033918| [ 8.88482e-01  5.42253e-01  1.36180e+00  1.49804e+00 -3.01915e-01
21Feb13_033918|  -1.64657e+00]
21Feb13_033918| [-7.72804e-01 -7.88868e-01 -1.51732e+00  2.67411e+00  4.06295e-01
21Feb13_033918|  -8.92510e-01]
21Feb13_033918| [ 6.46004e-01  5.12295e-01  7.01179e-01 -4.54621e-01  3.75918e-01
21Feb13_033918|   1.49924e+00]
21Feb13_033918| [ 1.52278e+00  1.92058e+00 -9.65125e-01 -4.80307e-01  5.46888e-01
21Feb13_033918|   2.24850e+00]
21Feb13_033918| [ 4.66992e-01  7.44738e-01  2.04032e+00 -7.52850e-01  4.39795e-01
21Feb13_033918|  -1.30633e+00]
21Feb13_033918| [ 5.36590e-03  2.71827e-01 -9.00687e-01 -1.69175e+00  2.60630e-01
21Feb13_033918|  -1.17641e-01]
21Feb13_033918| [-1.89419e+00  5.86120e-01  3.17287e-01  1.23132e+00  8.29902e-01
21Feb13_033918|  -2.27367e-01]
21Feb13_033918| [-9.93682e-01 -4.88945e-01  1.53959e+00 -2.17389e+00  4.91149e-01
21Feb13_033918|  -1.53693e-01]
21Feb13_033918| [-2.37496e+00  1.80554e+00  8.46161e-01 -8.02585e-02 -4.71501e-01
21Feb13_033918|   9.27510e-01]
21Feb13_033918| [ 6.71329e-01  7.64780e-01  1.79372e+00  1.27631e+00  2.45948e-01
21Feb13_033918|  -3.84121e-01]
21Feb13_033918| [ 1.38052e-03  1.00208e-01 -7.26106e-01  2.08987e+00  6.05057e-01
21Feb13_033918|  -3.44705e-01]
21Feb13_033918| [-6.40448e-01 -1.25756e+00 -6.91855e-01 -6.60281e-01 -5.32415e-01
21Feb13_033918|   4.82907e-01]
21Feb13_033918| [-8.29951e-01 -1.45360e-02 -5.18103e-01 -6.96224e-01  9.92941e-01
21Feb13_033918|  -3.74757e-01]
21Feb13_033918| [ 5.04431e-01  1.30316e+00 -7.61889e-01 -5.64505e-01 -1.86976e+00
21Feb13_033918|  -1.65515e+00]
21Feb13_033918| [ 1.80792e+00  9.99541e-01 -7.60678e-01  5.74908e-01 -1.53949e-01
21Feb13_033918|  -5.10970e-01]
21Feb13_033918| [ 5.74980e-01 -2.02913e+00 -5.90122e-04  2.24040e-01  2.40596e+00
21Feb13_033918|   1.13780e+00]
21Feb13_033918| [ 5.37268e-01 -1.13424e+00 -1.13375e+00  9.51094e-01 -2.61279e+00
21Feb13_033918|   3.09503e+00]
21Feb13_033918| [-7.43876e-01 -7.91567e-01 -1.42315e-01 -5.44246e-01 -1.31291e+00
21Feb13_033918|   8.00366e-01]
21Feb13_033918| [-4.43500e-01  5.01447e-01  7.37639e-01 -8.86292e-01 -1.43796e-01
21Feb13_033918|  -4.43199e-01]
21Feb13_033918| [-8.09815e-01 -5.40442e-01 -8.18936e-01 -2.62253e-01  1.23623e+00
21Feb13_033918|  -1.68396e-01]
21Feb13_033918| [-1.41040e+00 -1.68646e+00  6.51829e-01  1.33127e+00 -3.55390e-01
21Feb13_033918|  -6.44956e-01]
21Feb13_033918| [ 1.02374e+00  1.38475e+00 -1.60690e+00  1.39313e+00  1.52072e-01
21Feb13_033918|   1.78248e+00]
21Feb13_033918| [ 5.73046e-01 -1.24317e-01 -9.46218e-01 -9.92492e-01  7.18726e-01
21Feb13_033918|  -1.17057e+00]
21Feb13_033918| [ 7.12853e-01 -2.02767e+00  9.54969e-01  2.94993e-01  3.47986e-01
21Feb13_033918|   6.63350e-01]
21Feb13_033918| [-1.54972e-01 -2.25426e-02 -6.84809e-01  1.52444e+00 -3.08307e-01
21Feb13_033918|   6.16589e-01]
21Feb13_033918| [-2.68374e+00 -4.22414e-01 -8.89236e-01 -1.93846e+00 -6.21410e-03
21Feb13_033918|   2.43379e-02]
21Feb13_033918| [ 1.09577e+00 -1.55455e+00 -6.10941e-02  1.52828e-01 -7.03620e-01
21Feb13_033918|   1.09147e-01]
21Feb13_033918| [-7.87936e-01  6.89893e-01  9.67818e-03 -1.11178e+00 -9.82087e-01
21Feb13_033918|  -2.04381e-02]
21Feb13_033918| [-2.17261e+00 -1.22041e-01 -2.73620e-01 -8.36236e-01 -1.38438e+00
21Feb13_033918|  -2.87446e+00]
21Feb13_033918| [-1.27789e+00 -2.22055e+00  8.59278e-01  1.76093e+00  1.70142e+00
21Feb13_033918|  -3.61876e-01]
21Feb13_033918| [-1.67503e-01 -1.63536e-01 -9.50598e-01  4.35036e-01  5.75847e-01
21Feb13_033918|  -8.25957e-01]
21Feb13_033918| [ 2.38600e-01  6.87028e-01 -1.93100e-01 -1.37955e+00 -1.44922e+00
21Feb13_033918|  -5.58933e-01]
21Feb13_033918| [ 1.39524e+00 -1.73409e+00  5.43499e-01  4.06335e-01  1.47732e+00
21Feb13_033918|  -1.58348e+00]
21Feb13_033918| [ 2.93958e-01 -1.60558e-01 -6.19102e-01  2.12392e+00 -5.84554e-01
21Feb13_033918|  -1.08076e+00]
21Feb13_033918| [-1.03545e+00 -5.95621e-01 -4.88036e-01  2.22136e+00  1.27135e+00
21Feb13_033918|   1.21194e+00]
21Feb13_033918| [ 4.53245e-01 -4.35898e-01  9.15575e-01  5.54548e-01  2.31589e+00
21Feb13_033918|  -1.49880e-01]
21Feb13_033918| [ 1.95697e-01 -7.10320e-01  2.11797e+00  2.19429e-01 -8.34045e-01
21Feb13_033918|   6.75304e-01]
21Feb13_033918| [-1.09139e+00 -4.01523e-01  1.57825e+00 -3.63577e-01  1.27839e+00
21Feb13_033918|  -1.36927e+00]
21Feb13_033918| [-1.11411e+00  8.48703e-01 -1.23858e+00  6.59452e-02  6.16666e-01
21Feb13_033918|  -1.01983e+00]
21Feb13_033918| [ 8.64455e-01 -9.64796e-01  1.83325e+00  7.13131e-01 -1.19417e-01
21Feb13_033918|   1.24116e+00]
21Feb13_033918| [ 8.48703e-01 -1.26355e+00  1.89405e-01 -3.56211e-01  1.75192e+00
21Feb13_033918|  -9.35049e-01]
21Feb13_033918| [-6.05565e-01  1.49776e-01 -5.52038e-01  7.30625e-01  7.54976e-01
21Feb13_033918|  -1.13010e-01]]
21Feb13_033918|-- Bias --
21Feb13_033918|[-0.96395 -1.81574  0.59648 -0.89546  0.53643 -0.54271]
21Feb13_033918|Layer 1:
21Feb13_033918|-- Config --
21Feb13_033918|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_033918|-- Weights --
21Feb13_033918|[[-0.15615 -0.20495]
21Feb13_033918| [-0.32598  1.06694]
21Feb13_033918| [-1.47486  2.25005]
21Feb13_033918| [ 0.99958 -0.64832]
21Feb13_033918| [-0.41273 -1.27368]
21Feb13_033918| [-0.24560 -0.41985]]
21Feb13_033918|-- Bias --
21Feb13_033918|[0.71852 0.71224]
21Feb13_033918|Predicting the validation and test data with the Best final individual.
21Feb13_033925| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_033925|-----------  ------------------  --------------------  ----------
21Feb13_033925|Validation         41.91                  6             0.00517
21Feb13_033925|   Test            36.32                  6             0.01484
21Feb13_033925|-------------------- Test #11 --------------------
21Feb13_033925|Best final individual weights
21Feb13_033925|Individual:
21Feb13_033925|-- Constant hidden layers --
21Feb13_033925|False
21Feb13_033925|Layer 0:
21Feb13_033925|-- Config --
21Feb13_033925|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_033925|-- Weights --
21Feb13_033925|[[-3.22596e+00  8.15030e-02 -6.01515e-01 -4.22099e-01  1.44663e+00
21Feb13_033925|  -1.61649e+00]
21Feb13_033925| [-1.50985e+00 -8.80248e-01  4.97777e-01 -1.13432e+00 -2.07553e-01
21Feb13_033925|  -1.33127e-01]
21Feb13_033925| [-4.93230e-01  9.20894e-01 -6.80714e-01 -2.06675e-01 -1.67587e+00
21Feb13_033925|  -6.52652e-01]
21Feb13_033925| [-2.05655e+00 -1.26240e-01  1.02608e+00  3.31071e-01  2.72223e+00
21Feb13_033925|  -1.74184e-01]
21Feb13_033925| [-3.69830e-01  6.68594e-01  2.26357e-01  2.51533e-01 -6.70313e-01
21Feb13_033925|   2.55592e-01]
21Feb13_033925| [-2.36286e+00  3.86648e-01 -2.15750e+00  1.36469e-02 -1.48716e-01
21Feb13_033925|   1.85106e-02]
21Feb13_033925| [-1.32345e+00  1.17064e-01  4.67906e-01  1.18407e+00 -3.34708e-01
21Feb13_033925|   1.09335e+00]
21Feb13_033925| [ 4.64573e-02 -4.21817e-01 -2.00697e-02  6.73155e-01  2.22709e+00
21Feb13_033925|   1.05368e+00]
21Feb13_033925| [ 1.09741e+00 -4.08370e-01  1.22170e-01  1.54974e+00 -1.16833e-01
21Feb13_033925|   7.13909e-01]
21Feb13_033925| [ 5.46404e-01  2.46330e-01 -1.10982e+00  1.25920e+00 -3.52503e-01
21Feb13_033925|  -1.05035e+00]
21Feb13_033925| [ 3.91003e-01 -4.99730e-01 -1.00691e+00  1.39055e-01  1.92670e-01
21Feb13_033925|  -2.41086e+00]
21Feb13_033925| [-2.87157e-01  2.24456e+00  3.52979e-01  7.50725e-01  3.94071e-01
21Feb13_033925|   1.45677e+00]
21Feb13_033925| [ 1.91678e-02  1.30795e+00  1.99890e+00  2.12176e-01 -1.05133e+00
21Feb13_033925|  -1.54555e+00]
21Feb13_033925| [-1.57311e+00 -1.51965e+00 -1.47786e+00  8.92305e-01 -1.53035e+00
21Feb13_033925|   3.74029e-01]
21Feb13_033925| [-6.10475e-01  7.15578e-01  9.61852e-01  1.61375e+00 -1.90442e+00
21Feb13_033925|  -2.29618e-01]
21Feb13_033925| [ 8.88482e-01  5.42253e-01  1.36180e+00  1.49804e+00 -3.01915e-01
21Feb13_033925|  -1.64657e+00]
21Feb13_033925| [-7.72804e-01 -7.88868e-01 -1.51732e+00  2.67411e+00  4.06295e-01
21Feb13_033925|  -8.92510e-01]
21Feb13_033925| [ 6.46004e-01  5.12295e-01  7.01179e-01 -4.54621e-01  3.75918e-01
21Feb13_033925|   1.49924e+00]
21Feb13_033925| [ 1.52278e+00  1.92058e+00 -9.65125e-01 -4.80307e-01  5.46888e-01
21Feb13_033925|   2.24850e+00]
21Feb13_033925| [ 4.66992e-01  7.44738e-01  2.04032e+00 -7.52850e-01  4.39795e-01
21Feb13_033925|  -1.30633e+00]
21Feb13_033925| [ 5.36590e-03  2.71827e-01 -9.00687e-01 -1.69175e+00  2.60630e-01
21Feb13_033925|  -1.17641e-01]
21Feb13_033925| [-1.89419e+00  5.86120e-01  3.17287e-01  1.23132e+00  8.29902e-01
21Feb13_033925|  -2.27367e-01]
21Feb13_033925| [-9.93682e-01 -4.88945e-01  1.53959e+00 -2.17389e+00  4.91149e-01
21Feb13_033925|  -1.53693e-01]
21Feb13_033925| [-2.37496e+00  1.80554e+00  8.46161e-01 -8.02585e-02 -4.71501e-01
21Feb13_033925|   9.27510e-01]
21Feb13_033925| [ 6.71329e-01  7.64780e-01  1.79372e+00  1.27631e+00  2.45948e-01
21Feb13_033925|  -3.84121e-01]
21Feb13_033925| [ 1.38052e-03  1.00208e-01 -7.26106e-01  2.08987e+00  6.05057e-01
21Feb13_033925|  -3.44705e-01]
21Feb13_033925| [-6.40448e-01 -1.25756e+00 -6.91855e-01 -6.60281e-01 -5.32415e-01
21Feb13_033925|   4.82907e-01]
21Feb13_033925| [-8.29951e-01 -1.45360e-02 -5.18103e-01 -6.96224e-01  9.92941e-01
21Feb13_033925|  -3.74757e-01]
21Feb13_033925| [ 5.04431e-01  1.30316e+00 -7.61889e-01 -5.64505e-01 -1.86976e+00
21Feb13_033925|  -1.65515e+00]
21Feb13_033925| [ 1.80792e+00  9.99541e-01 -7.60678e-01  5.74908e-01 -1.53949e-01
21Feb13_033925|  -5.10970e-01]
21Feb13_033925| [ 5.74980e-01 -2.02913e+00 -5.90122e-04  2.24040e-01  2.40596e+00
21Feb13_033925|   1.13780e+00]
21Feb13_033925| [ 5.37268e-01 -1.13424e+00 -1.13375e+00  9.51094e-01 -2.61279e+00
21Feb13_033925|   3.09503e+00]
21Feb13_033925| [-7.43876e-01 -7.91567e-01 -1.42315e-01 -5.44246e-01 -1.31291e+00
21Feb13_033925|   8.00366e-01]
21Feb13_033925| [-4.43500e-01  5.01447e-01  7.37639e-01 -8.86292e-01 -1.43796e-01
21Feb13_033925|  -4.43199e-01]
21Feb13_033925| [-8.09815e-01 -5.40442e-01 -8.18936e-01 -2.62253e-01  1.23623e+00
21Feb13_033925|  -1.68396e-01]
21Feb13_033925| [-1.41040e+00 -1.68646e+00  6.51829e-01  1.33127e+00 -3.55390e-01
21Feb13_033925|  -6.44956e-01]
21Feb13_033925| [ 1.02374e+00  1.38475e+00 -1.60690e+00  1.39313e+00  1.52072e-01
21Feb13_033925|   1.78248e+00]
21Feb13_033925| [ 5.73046e-01 -1.24317e-01 -9.46218e-01 -9.92492e-01  7.18726e-01
21Feb13_033925|  -1.17057e+00]
21Feb13_033925| [ 7.12853e-01 -2.02767e+00  9.54969e-01  2.94993e-01  3.47986e-01
21Feb13_033925|   6.63350e-01]
21Feb13_033925| [-1.54972e-01 -2.25426e-02 -6.84809e-01  1.52444e+00 -3.08307e-01
21Feb13_033925|   6.16589e-01]
21Feb13_033925| [-2.68374e+00 -4.22414e-01 -8.89236e-01 -1.93846e+00 -6.21410e-03
21Feb13_033925|   2.43379e-02]
21Feb13_033925| [ 1.09577e+00 -1.55455e+00 -6.10941e-02  1.52828e-01 -7.03620e-01
21Feb13_033925|   1.09147e-01]
21Feb13_033925| [-7.87936e-01  6.89893e-01  9.67818e-03 -1.11178e+00 -9.82087e-01
21Feb13_033925|  -2.04381e-02]
21Feb13_033925| [-2.17261e+00 -1.22041e-01 -2.73620e-01 -8.36236e-01 -1.38438e+00
21Feb13_033925|  -2.87446e+00]
21Feb13_033925| [-1.27789e+00 -2.22055e+00  8.59278e-01  1.76093e+00  1.70142e+00
21Feb13_033925|  -3.61876e-01]
21Feb13_033925| [-1.67503e-01 -1.63536e-01 -9.50598e-01  4.35036e-01  5.75847e-01
21Feb13_033925|  -8.25957e-01]
21Feb13_033925| [ 2.38600e-01  6.87028e-01 -1.93100e-01 -1.37955e+00 -1.44922e+00
21Feb13_033925|  -5.58933e-01]
21Feb13_033925| [ 1.39524e+00 -1.73409e+00  5.43499e-01  4.06335e-01  1.47732e+00
21Feb13_033925|  -1.58348e+00]
21Feb13_033925| [ 2.93958e-01 -1.60558e-01 -6.19102e-01  2.12392e+00 -5.84554e-01
21Feb13_033925|  -1.08076e+00]
21Feb13_033925| [-1.03545e+00 -5.95621e-01 -4.88036e-01  2.22136e+00  1.27135e+00
21Feb13_033925|   1.21194e+00]
21Feb13_033925| [ 4.53245e-01 -4.35898e-01  9.15575e-01  5.54548e-01  2.31589e+00
21Feb13_033925|  -1.49880e-01]
21Feb13_033925| [ 1.95697e-01 -7.10320e-01  2.11797e+00  2.19429e-01 -8.34045e-01
21Feb13_033925|   6.75304e-01]
21Feb13_033925| [-1.09139e+00 -4.01523e-01  1.57825e+00 -3.63577e-01  1.27839e+00
21Feb13_033925|  -1.36927e+00]
21Feb13_033925| [-1.11411e+00  8.48703e-01 -1.23858e+00  6.59452e-02  6.16666e-01
21Feb13_033925|  -1.01983e+00]
21Feb13_033925| [ 8.64455e-01 -9.64796e-01  1.83325e+00  7.13131e-01 -1.19417e-01
21Feb13_033925|   1.24116e+00]
21Feb13_033925| [ 8.48703e-01 -1.26355e+00  1.89405e-01 -3.56211e-01  1.75192e+00
21Feb13_033925|  -9.35049e-01]
21Feb13_033925| [-6.05565e-01  1.49776e-01 -5.52038e-01  7.30625e-01  7.54976e-01
21Feb13_033925|  -1.13010e-01]]
21Feb13_033925|-- Bias --
21Feb13_033925|[-0.96395 -1.81574  0.59648 -0.89546  0.53643 -0.54271]
21Feb13_033925|Layer 1:
21Feb13_033925|-- Config --
21Feb13_033925|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_033925|-- Weights --
21Feb13_033925|[[-0.15615 -0.20495]
21Feb13_033925| [-0.32598  1.06694]
21Feb13_033925| [-1.47486  2.25005]
21Feb13_033925| [ 0.99958 -0.64832]
21Feb13_033925| [-0.41273 -1.27368]
21Feb13_033925| [-0.24560 -0.41985]]
21Feb13_033925|-- Bias --
21Feb13_033925|[0.71852 0.71224]
21Feb13_033925|Predicting the validation and test data with the Best final individual.
21Feb13_033933| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_033933|-----------  ------------------  --------------------  ----------
21Feb13_033933|Validation         41.48                  6             0.02060
21Feb13_033933|   Test            36.49                  6             0.01187
21Feb13_033933|-------------------- Test #12 --------------------
21Feb13_033933|Best final individual weights
21Feb13_033933|Individual:
21Feb13_033933|-- Constant hidden layers --
21Feb13_033933|False
21Feb13_033933|Layer 0:
21Feb13_033933|-- Config --
21Feb13_033933|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_033933|-- Weights --
21Feb13_033933|[[-3.22596e+00  8.15030e-02 -6.01515e-01 -4.22099e-01  1.44663e+00
21Feb13_033933|  -1.61649e+00]
21Feb13_033933| [-1.50985e+00 -8.80248e-01  4.97777e-01 -1.13432e+00 -2.07553e-01
21Feb13_033933|  -1.33127e-01]
21Feb13_033933| [-4.93230e-01  9.20894e-01 -6.80714e-01 -2.06675e-01 -1.67587e+00
21Feb13_033933|  -6.52652e-01]
21Feb13_033933| [-2.05655e+00 -1.26240e-01  1.02608e+00  3.31071e-01  2.72223e+00
21Feb13_033933|  -1.74184e-01]
21Feb13_033933| [-3.69830e-01  6.68594e-01  2.26357e-01  2.51533e-01 -6.70313e-01
21Feb13_033933|   2.55592e-01]
21Feb13_033933| [-2.36286e+00  3.86648e-01 -2.15750e+00  1.36469e-02 -1.48716e-01
21Feb13_033933|   1.85106e-02]
21Feb13_033933| [-1.32345e+00  1.17064e-01  4.67906e-01  1.18407e+00 -3.34708e-01
21Feb13_033933|   1.09335e+00]
21Feb13_033933| [ 4.64573e-02 -4.21817e-01 -2.00697e-02  6.73155e-01  2.22709e+00
21Feb13_033933|   1.05368e+00]
21Feb13_033933| [ 1.09741e+00 -4.08370e-01  1.22170e-01  1.54974e+00 -1.16833e-01
21Feb13_033933|   7.13909e-01]
21Feb13_033933| [ 5.46404e-01  2.46330e-01 -1.10982e+00  1.25920e+00 -3.52503e-01
21Feb13_033933|  -1.05035e+00]
21Feb13_033933| [ 3.91003e-01 -4.99730e-01 -1.00691e+00  1.39055e-01  1.92670e-01
21Feb13_033933|  -2.41086e+00]
21Feb13_033933| [-2.87157e-01  2.24456e+00  3.52979e-01  7.50725e-01  3.94071e-01
21Feb13_033933|   1.45677e+00]
21Feb13_033933| [ 1.91678e-02  1.30795e+00  1.99890e+00  2.12176e-01 -1.05133e+00
21Feb13_033933|  -1.54555e+00]
21Feb13_033933| [-1.57311e+00 -1.51965e+00 -1.47786e+00  8.92305e-01 -1.53035e+00
21Feb13_033933|   3.74029e-01]
21Feb13_033933| [-6.10475e-01  7.15578e-01  9.61852e-01  1.61375e+00 -1.90442e+00
21Feb13_033933|  -2.29618e-01]
21Feb13_033933| [ 8.88482e-01  5.42253e-01  1.36180e+00  1.49804e+00 -3.01915e-01
21Feb13_033933|  -1.64657e+00]
21Feb13_033933| [-7.72804e-01 -7.88868e-01 -1.51732e+00  2.67411e+00  4.06295e-01
21Feb13_033933|  -8.92510e-01]
21Feb13_033933| [ 6.46004e-01  5.12295e-01  7.01179e-01 -4.54621e-01  3.75918e-01
21Feb13_033933|   1.49924e+00]
21Feb13_033933| [ 1.52278e+00  1.92058e+00 -9.65125e-01 -4.80307e-01  5.46888e-01
21Feb13_033933|   2.24850e+00]
21Feb13_033933| [ 4.66992e-01  7.44738e-01  2.04032e+00 -7.52850e-01  4.39795e-01
21Feb13_033933|  -1.30633e+00]
21Feb13_033933| [ 5.36590e-03  2.71827e-01 -9.00687e-01 -1.69175e+00  2.60630e-01
21Feb13_033933|  -1.17641e-01]
21Feb13_033933| [-1.89419e+00  5.86120e-01  3.17287e-01  1.23132e+00  8.29902e-01
21Feb13_033933|  -2.27367e-01]
21Feb13_033933| [-9.93682e-01 -4.88945e-01  1.53959e+00 -2.17389e+00  4.91149e-01
21Feb13_033933|  -1.53693e-01]
21Feb13_033933| [-2.37496e+00  1.80554e+00  8.46161e-01 -8.02585e-02 -4.71501e-01
21Feb13_033933|   9.27510e-01]
21Feb13_033933| [ 6.71329e-01  7.64780e-01  1.79372e+00  1.27631e+00  2.45948e-01
21Feb13_033933|  -3.84121e-01]
21Feb13_033933| [ 1.38052e-03  1.00208e-01 -7.26106e-01  2.08987e+00  6.05057e-01
21Feb13_033933|  -3.44705e-01]
21Feb13_033933| [-6.40448e-01 -1.25756e+00 -6.91855e-01 -6.60281e-01 -5.32415e-01
21Feb13_033933|   4.82907e-01]
21Feb13_033933| [-8.29951e-01 -1.45360e-02 -5.18103e-01 -6.96224e-01  9.92941e-01
21Feb13_033933|  -3.74757e-01]
21Feb13_033933| [ 5.04431e-01  1.30316e+00 -7.61889e-01 -5.64505e-01 -1.86976e+00
21Feb13_033933|  -1.65515e+00]
21Feb13_033933| [ 1.80792e+00  9.99541e-01 -7.60678e-01  5.74908e-01 -1.53949e-01
21Feb13_033933|  -5.10970e-01]
21Feb13_033933| [ 5.74980e-01 -2.02913e+00 -5.90122e-04  2.24040e-01  2.40596e+00
21Feb13_033933|   1.13780e+00]
21Feb13_033933| [ 5.37268e-01 -1.13424e+00 -1.13375e+00  9.51094e-01 -2.61279e+00
21Feb13_033933|   3.09503e+00]
21Feb13_033933| [-7.43876e-01 -7.91567e-01 -1.42315e-01 -5.44246e-01 -1.31291e+00
21Feb13_033933|   8.00366e-01]
21Feb13_033933| [-4.43500e-01  5.01447e-01  7.37639e-01 -8.86292e-01 -1.43796e-01
21Feb13_033933|  -4.43199e-01]
21Feb13_033933| [-8.09815e-01 -5.40442e-01 -8.18936e-01 -2.62253e-01  1.23623e+00
21Feb13_033933|  -1.68396e-01]
21Feb13_033933| [-1.41040e+00 -1.68646e+00  6.51829e-01  1.33127e+00 -3.55390e-01
21Feb13_033933|  -6.44956e-01]
21Feb13_033933| [ 1.02374e+00  1.38475e+00 -1.60690e+00  1.39313e+00  1.52072e-01
21Feb13_033933|   1.78248e+00]
21Feb13_033933| [ 5.73046e-01 -1.24317e-01 -9.46218e-01 -9.92492e-01  7.18726e-01
21Feb13_033933|  -1.17057e+00]
21Feb13_033933| [ 7.12853e-01 -2.02767e+00  9.54969e-01  2.94993e-01  3.47986e-01
21Feb13_033933|   6.63350e-01]
21Feb13_033933| [-1.54972e-01 -2.25426e-02 -6.84809e-01  1.52444e+00 -3.08307e-01
21Feb13_033933|   6.16589e-01]
21Feb13_033933| [-2.68374e+00 -4.22414e-01 -8.89236e-01 -1.93846e+00 -6.21410e-03
21Feb13_033933|   2.43379e-02]
21Feb13_033933| [ 1.09577e+00 -1.55455e+00 -6.10941e-02  1.52828e-01 -7.03620e-01
21Feb13_033933|   1.09147e-01]
21Feb13_033933| [-7.87936e-01  6.89893e-01  9.67818e-03 -1.11178e+00 -9.82087e-01
21Feb13_033933|  -2.04381e-02]
21Feb13_033933| [-2.17261e+00 -1.22041e-01 -2.73620e-01 -8.36236e-01 -1.38438e+00
21Feb13_033933|  -2.87446e+00]
21Feb13_033933| [-1.27789e+00 -2.22055e+00  8.59278e-01  1.76093e+00  1.70142e+00
21Feb13_033933|  -3.61876e-01]
21Feb13_033933| [-1.67503e-01 -1.63536e-01 -9.50598e-01  4.35036e-01  5.75847e-01
21Feb13_033933|  -8.25957e-01]
21Feb13_033933| [ 2.38600e-01  6.87028e-01 -1.93100e-01 -1.37955e+00 -1.44922e+00
21Feb13_033933|  -5.58933e-01]
21Feb13_033933| [ 1.39524e+00 -1.73409e+00  5.43499e-01  4.06335e-01  1.47732e+00
21Feb13_033933|  -1.58348e+00]
21Feb13_033933| [ 2.93958e-01 -1.60558e-01 -6.19102e-01  2.12392e+00 -5.84554e-01
21Feb13_033933|  -1.08076e+00]
21Feb13_033933| [-1.03545e+00 -5.95621e-01 -4.88036e-01  2.22136e+00  1.27135e+00
21Feb13_033933|   1.21194e+00]
21Feb13_033933| [ 4.53245e-01 -4.35898e-01  9.15575e-01  5.54548e-01  2.31589e+00
21Feb13_033933|  -1.49880e-01]
21Feb13_033933| [ 1.95697e-01 -7.10320e-01  2.11797e+00  2.19429e-01 -8.34045e-01
21Feb13_033933|   6.75304e-01]
21Feb13_033933| [-1.09139e+00 -4.01523e-01  1.57825e+00 -3.63577e-01  1.27839e+00
21Feb13_033933|  -1.36927e+00]
21Feb13_033933| [-1.11411e+00  8.48703e-01 -1.23858e+00  6.59452e-02  6.16666e-01
21Feb13_033933|  -1.01983e+00]
21Feb13_033933| [ 8.64455e-01 -9.64796e-01  1.83325e+00  7.13131e-01 -1.19417e-01
21Feb13_033933|   1.24116e+00]
21Feb13_033933| [ 8.48703e-01 -1.26355e+00  1.89405e-01 -3.56211e-01  1.75192e+00
21Feb13_033933|  -9.35049e-01]
21Feb13_033933| [-6.05565e-01  1.49776e-01 -5.52038e-01  7.30625e-01  7.54976e-01
21Feb13_033933|  -1.13010e-01]]
21Feb13_033933|-- Bias --
21Feb13_033933|[-0.96395 -1.81574  0.59648 -0.89546  0.53643 -0.54271]
21Feb13_033933|Layer 1:
21Feb13_033933|-- Config --
21Feb13_033933|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_033933|-- Weights --
21Feb13_033933|[[-0.15615 -0.20495]
21Feb13_033933| [-0.32598  1.06694]
21Feb13_033933| [-1.47486  2.25005]
21Feb13_033933| [ 0.99958 -0.64832]
21Feb13_033933| [-0.41273 -1.27368]
21Feb13_033933| [-0.24560 -0.41985]]
21Feb13_033933|-- Bias --
21Feb13_033933|[0.71852 0.71224]
21Feb13_033933|Predicting the validation and test data with the Best final individual.
21Feb13_033940| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_033940|-----------  ------------------  --------------------  ----------
21Feb13_033940|Validation         41.39                  6             0.02571
21Feb13_033940|   Test            36.66                  6             0.00890
21Feb13_033940|-------------------- Test #13 --------------------
21Feb13_033940|Best final individual weights
21Feb13_033940|Individual:
21Feb13_033940|-- Constant hidden layers --
21Feb13_033940|False
21Feb13_033940|Layer 0:
21Feb13_033940|-- Config --
21Feb13_033940|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_033940|-- Weights --
21Feb13_033940|[[-3.22596e+00  8.15030e-02 -6.01515e-01 -4.22099e-01  1.44663e+00
21Feb13_033940|  -1.61649e+00]
21Feb13_033940| [-1.50985e+00 -8.80248e-01  4.97777e-01 -1.13432e+00 -2.07553e-01
21Feb13_033940|  -1.33127e-01]
21Feb13_033940| [-4.93230e-01  9.20894e-01 -6.80714e-01 -2.06675e-01 -1.67587e+00
21Feb13_033940|  -6.52652e-01]
21Feb13_033940| [-2.05655e+00 -1.26240e-01  1.02608e+00  3.31071e-01  2.72223e+00
21Feb13_033940|  -1.74184e-01]
21Feb13_033940| [-3.69830e-01  6.68594e-01  2.26357e-01  2.51533e-01 -6.70313e-01
21Feb13_033940|   2.55592e-01]
21Feb13_033940| [-2.36286e+00  3.86648e-01 -2.15750e+00  1.36469e-02 -1.48716e-01
21Feb13_033940|   1.85106e-02]
21Feb13_033940| [-1.32345e+00  1.17064e-01  4.67906e-01  1.18407e+00 -3.34708e-01
21Feb13_033940|   1.09335e+00]
21Feb13_033940| [ 4.64573e-02 -4.21817e-01 -2.00697e-02  6.73155e-01  2.22709e+00
21Feb13_033940|   1.05368e+00]
21Feb13_033940| [ 1.09741e+00 -4.08370e-01  1.22170e-01  1.54974e+00 -1.16833e-01
21Feb13_033940|   7.13909e-01]
21Feb13_033940| [ 5.46404e-01  2.46330e-01 -1.10982e+00  1.25920e+00 -3.52503e-01
21Feb13_033940|  -1.05035e+00]
21Feb13_033940| [ 3.91003e-01 -4.99730e-01 -1.00691e+00  1.39055e-01  1.92670e-01
21Feb13_033940|  -2.41086e+00]
21Feb13_033940| [-2.87157e-01  2.24456e+00  3.52979e-01  7.50725e-01  3.94071e-01
21Feb13_033940|   1.45677e+00]
21Feb13_033940| [ 1.91678e-02  1.30795e+00  1.99890e+00  2.12176e-01 -1.05133e+00
21Feb13_033940|  -1.54555e+00]
21Feb13_033940| [-1.57311e+00 -1.51965e+00 -1.47786e+00  8.92305e-01 -1.53035e+00
21Feb13_033940|   3.74029e-01]
21Feb13_033940| [-6.10475e-01  7.15578e-01  9.61852e-01  1.61375e+00 -1.90442e+00
21Feb13_033940|  -2.29618e-01]
21Feb13_033940| [ 8.88482e-01  5.42253e-01  1.36180e+00  1.49804e+00 -3.01915e-01
21Feb13_033940|  -1.64657e+00]
21Feb13_033940| [-7.72804e-01 -7.88868e-01 -1.51732e+00  2.67411e+00  4.06295e-01
21Feb13_033940|  -8.92510e-01]
21Feb13_033940| [ 6.46004e-01  5.12295e-01  7.01179e-01 -4.54621e-01  3.75918e-01
21Feb13_033940|   1.49924e+00]
21Feb13_033940| [ 1.52278e+00  1.92058e+00 -9.65125e-01 -4.80307e-01  5.46888e-01
21Feb13_033940|   2.24850e+00]
21Feb13_033940| [ 4.66992e-01  7.44738e-01  2.04032e+00 -7.52850e-01  4.39795e-01
21Feb13_033940|  -1.30633e+00]
21Feb13_033940| [ 5.36590e-03  2.71827e-01 -9.00687e-01 -1.69175e+00  2.60630e-01
21Feb13_033940|  -1.17641e-01]
21Feb13_033940| [-1.89419e+00  5.86120e-01  3.17287e-01  1.23132e+00  8.29902e-01
21Feb13_033940|  -2.27367e-01]
21Feb13_033940| [-9.93682e-01 -4.88945e-01  1.53959e+00 -2.17389e+00  4.91149e-01
21Feb13_033940|  -1.53693e-01]
21Feb13_033940| [-2.37496e+00  1.80554e+00  8.46161e-01 -8.02585e-02 -4.71501e-01
21Feb13_033940|   9.27510e-01]
21Feb13_033940| [ 6.71329e-01  7.64780e-01  1.79372e+00  1.27631e+00  2.45948e-01
21Feb13_033940|  -3.84121e-01]
21Feb13_033940| [ 1.38052e-03  1.00208e-01 -7.26106e-01  2.08987e+00  6.05057e-01
21Feb13_033940|  -3.44705e-01]
21Feb13_033940| [-6.40448e-01 -1.25756e+00 -6.91855e-01 -6.60281e-01 -5.32415e-01
21Feb13_033940|   4.82907e-01]
21Feb13_033940| [-8.29951e-01 -1.45360e-02 -5.18103e-01 -6.96224e-01  9.92941e-01
21Feb13_033940|  -3.74757e-01]
21Feb13_033940| [ 5.04431e-01  1.30316e+00 -7.61889e-01 -5.64505e-01 -1.86976e+00
21Feb13_033940|  -1.65515e+00]
21Feb13_033940| [ 1.80792e+00  9.99541e-01 -7.60678e-01  5.74908e-01 -1.53949e-01
21Feb13_033940|  -5.10970e-01]
21Feb13_033940| [ 5.74980e-01 -2.02913e+00 -5.90122e-04  2.24040e-01  2.40596e+00
21Feb13_033940|   1.13780e+00]
21Feb13_033940| [ 5.37268e-01 -1.13424e+00 -1.13375e+00  9.51094e-01 -2.61279e+00
21Feb13_033940|   3.09503e+00]
21Feb13_033940| [-7.43876e-01 -7.91567e-01 -1.42315e-01 -5.44246e-01 -1.31291e+00
21Feb13_033940|   8.00366e-01]
21Feb13_033940| [-4.43500e-01  5.01447e-01  7.37639e-01 -8.86292e-01 -1.43796e-01
21Feb13_033940|  -4.43199e-01]
21Feb13_033940| [-8.09815e-01 -5.40442e-01 -8.18936e-01 -2.62253e-01  1.23623e+00
21Feb13_033940|  -1.68396e-01]
21Feb13_033940| [-1.41040e+00 -1.68646e+00  6.51829e-01  1.33127e+00 -3.55390e-01
21Feb13_033940|  -6.44956e-01]
21Feb13_033940| [ 1.02374e+00  1.38475e+00 -1.60690e+00  1.39313e+00  1.52072e-01
21Feb13_033940|   1.78248e+00]
21Feb13_033940| [ 5.73046e-01 -1.24317e-01 -9.46218e-01 -9.92492e-01  7.18726e-01
21Feb13_033940|  -1.17057e+00]
21Feb13_033940| [ 7.12853e-01 -2.02767e+00  9.54969e-01  2.94993e-01  3.47986e-01
21Feb13_033940|   6.63350e-01]
21Feb13_033940| [-1.54972e-01 -2.25426e-02 -6.84809e-01  1.52444e+00 -3.08307e-01
21Feb13_033940|   6.16589e-01]
21Feb13_033940| [-2.68374e+00 -4.22414e-01 -8.89236e-01 -1.93846e+00 -6.21410e-03
21Feb13_033940|   2.43379e-02]
21Feb13_033940| [ 1.09577e+00 -1.55455e+00 -6.10941e-02  1.52828e-01 -7.03620e-01
21Feb13_033940|   1.09147e-01]
21Feb13_033940| [-7.87936e-01  6.89893e-01  9.67818e-03 -1.11178e+00 -9.82087e-01
21Feb13_033940|  -2.04381e-02]
21Feb13_033940| [-2.17261e+00 -1.22041e-01 -2.73620e-01 -8.36236e-01 -1.38438e+00
21Feb13_033940|  -2.87446e+00]
21Feb13_033940| [-1.27789e+00 -2.22055e+00  8.59278e-01  1.76093e+00  1.70142e+00
21Feb13_033940|  -3.61876e-01]
21Feb13_033940| [-1.67503e-01 -1.63536e-01 -9.50598e-01  4.35036e-01  5.75847e-01
21Feb13_033940|  -8.25957e-01]
21Feb13_033940| [ 2.38600e-01  6.87028e-01 -1.93100e-01 -1.37955e+00 -1.44922e+00
21Feb13_033940|  -5.58933e-01]
21Feb13_033940| [ 1.39524e+00 -1.73409e+00  5.43499e-01  4.06335e-01  1.47732e+00
21Feb13_033940|  -1.58348e+00]
21Feb13_033940| [ 2.93958e-01 -1.60558e-01 -6.19102e-01  2.12392e+00 -5.84554e-01
21Feb13_033940|  -1.08076e+00]
21Feb13_033940| [-1.03545e+00 -5.95621e-01 -4.88036e-01  2.22136e+00  1.27135e+00
21Feb13_033940|   1.21194e+00]
21Feb13_033940| [ 4.53245e-01 -4.35898e-01  9.15575e-01  5.54548e-01  2.31589e+00
21Feb13_033940|  -1.49880e-01]
21Feb13_033940| [ 1.95697e-01 -7.10320e-01  2.11797e+00  2.19429e-01 -8.34045e-01
21Feb13_033940|   6.75304e-01]
21Feb13_033940| [-1.09139e+00 -4.01523e-01  1.57825e+00 -3.63577e-01  1.27839e+00
21Feb13_033940|  -1.36927e+00]
21Feb13_033940| [-1.11411e+00  8.48703e-01 -1.23858e+00  6.59452e-02  6.16666e-01
21Feb13_033940|  -1.01983e+00]
21Feb13_033940| [ 8.64455e-01 -9.64796e-01  1.83325e+00  7.13131e-01 -1.19417e-01
21Feb13_033940|   1.24116e+00]
21Feb13_033940| [ 8.48703e-01 -1.26355e+00  1.89405e-01 -3.56211e-01  1.75192e+00
21Feb13_033940|  -9.35049e-01]
21Feb13_033940| [-6.05565e-01  1.49776e-01 -5.52038e-01  7.30625e-01  7.54976e-01
21Feb13_033940|  -1.13010e-01]]
21Feb13_033940|-- Bias --
21Feb13_033940|[-0.96395 -1.81574  0.59648 -0.89546  0.53643 -0.54271]
21Feb13_033940|Layer 1:
21Feb13_033940|-- Config --
21Feb13_033940|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_033940|-- Weights --
21Feb13_033940|[[-0.15615 -0.20495]
21Feb13_033940| [-0.32598  1.06694]
21Feb13_033940| [-1.47486  2.25005]
21Feb13_033940| [ 0.99958 -0.64832]
21Feb13_033940| [-0.41273 -1.27368]
21Feb13_033940| [-0.24560 -0.41985]]
21Feb13_033940|-- Bias --
21Feb13_033940|[0.71852 0.71224]
21Feb13_033940|Predicting the validation and test data with the Best final individual.
21Feb13_033947| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_033947|-----------  ------------------  --------------------  ----------
21Feb13_033947|Validation         41.39                  6             0.02316
21Feb13_033947|   Test            36.58                  6             0.00298
21Feb13_033947|-------------------- Test #14 --------------------
21Feb13_033947|Best final individual weights
21Feb13_033947|Individual:
21Feb13_033947|-- Constant hidden layers --
21Feb13_033947|False
21Feb13_033947|Layer 0:
21Feb13_033947|-- Config --
21Feb13_033947|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_033947|-- Weights --
21Feb13_033947|[[-3.22596e+00  8.15030e-02 -6.01515e-01 -4.22099e-01  1.44663e+00
21Feb13_033947|  -1.61649e+00]
21Feb13_033947| [-1.50985e+00 -8.80248e-01  4.97777e-01 -1.13432e+00 -2.07553e-01
21Feb13_033947|  -1.33127e-01]
21Feb13_033947| [-4.93230e-01  9.20894e-01 -6.80714e-01 -2.06675e-01 -1.67587e+00
21Feb13_033947|  -6.52652e-01]
21Feb13_033947| [-2.05655e+00 -1.26240e-01  1.02608e+00  3.31071e-01  2.72223e+00
21Feb13_033947|  -1.74184e-01]
21Feb13_033947| [-3.69830e-01  6.68594e-01  2.26357e-01  2.51533e-01 -6.70313e-01
21Feb13_033947|   2.55592e-01]
21Feb13_033947| [-2.36286e+00  3.86648e-01 -2.15750e+00  1.36469e-02 -1.48716e-01
21Feb13_033947|   1.85106e-02]
21Feb13_033947| [-1.32345e+00  1.17064e-01  4.67906e-01  1.18407e+00 -3.34708e-01
21Feb13_033947|   1.09335e+00]
21Feb13_033947| [ 4.64573e-02 -4.21817e-01 -2.00697e-02  6.73155e-01  2.22709e+00
21Feb13_033947|   1.05368e+00]
21Feb13_033947| [ 1.09741e+00 -4.08370e-01  1.22170e-01  1.54974e+00 -1.16833e-01
21Feb13_033947|   7.13909e-01]
21Feb13_033947| [ 5.46404e-01  2.46330e-01 -1.10982e+00  1.25920e+00 -3.52503e-01
21Feb13_033947|  -1.05035e+00]
21Feb13_033947| [ 3.91003e-01 -4.99730e-01 -1.00691e+00  1.39055e-01  1.92670e-01
21Feb13_033947|  -2.41086e+00]
21Feb13_033947| [-2.87157e-01  2.24456e+00  3.52979e-01  7.50725e-01  3.94071e-01
21Feb13_033947|   1.45677e+00]
21Feb13_033947| [ 1.91678e-02  1.30795e+00  1.99890e+00  2.12176e-01 -1.05133e+00
21Feb13_033947|  -1.54555e+00]
21Feb13_033947| [-1.57311e+00 -1.51965e+00 -1.47786e+00  8.92305e-01 -1.53035e+00
21Feb13_033947|   3.74029e-01]
21Feb13_033947| [-6.10475e-01  7.15578e-01  9.61852e-01  1.61375e+00 -1.90442e+00
21Feb13_033947|  -2.29618e-01]
21Feb13_033947| [ 8.88482e-01  5.42253e-01  1.36180e+00  1.49804e+00 -3.01915e-01
21Feb13_033947|  -1.64657e+00]
21Feb13_033947| [-7.72804e-01 -7.88868e-01 -1.51732e+00  2.67411e+00  4.06295e-01
21Feb13_033947|  -8.92510e-01]
21Feb13_033947| [ 6.46004e-01  5.12295e-01  7.01179e-01 -4.54621e-01  3.75918e-01
21Feb13_033947|   1.49924e+00]
21Feb13_033947| [ 1.52278e+00  1.92058e+00 -9.65125e-01 -4.80307e-01  5.46888e-01
21Feb13_033947|   2.24850e+00]
21Feb13_033947| [ 4.66992e-01  7.44738e-01  2.04032e+00 -7.52850e-01  4.39795e-01
21Feb13_033947|  -1.30633e+00]
21Feb13_033947| [ 5.36590e-03  2.71827e-01 -9.00687e-01 -1.69175e+00  2.60630e-01
21Feb13_033947|  -1.17641e-01]
21Feb13_033947| [-1.89419e+00  5.86120e-01  3.17287e-01  1.23132e+00  8.29902e-01
21Feb13_033947|  -2.27367e-01]
21Feb13_033947| [-9.93682e-01 -4.88945e-01  1.53959e+00 -2.17389e+00  4.91149e-01
21Feb13_033947|  -1.53693e-01]
21Feb13_033947| [-2.37496e+00  1.80554e+00  8.46161e-01 -8.02585e-02 -4.71501e-01
21Feb13_033947|   9.27510e-01]
21Feb13_033947| [ 6.71329e-01  7.64780e-01  1.79372e+00  1.27631e+00  2.45948e-01
21Feb13_033947|  -3.84121e-01]
21Feb13_033947| [ 1.38052e-03  1.00208e-01 -7.26106e-01  2.08987e+00  6.05057e-01
21Feb13_033947|  -3.44705e-01]
21Feb13_033947| [-6.40448e-01 -1.25756e+00 -6.91855e-01 -6.60281e-01 -5.32415e-01
21Feb13_033947|   4.82907e-01]
21Feb13_033947| [-8.29951e-01 -1.45360e-02 -5.18103e-01 -6.96224e-01  9.92941e-01
21Feb13_033947|  -3.74757e-01]
21Feb13_033947| [ 5.04431e-01  1.30316e+00 -7.61889e-01 -5.64505e-01 -1.86976e+00
21Feb13_033947|  -1.65515e+00]
21Feb13_033947| [ 1.80792e+00  9.99541e-01 -7.60678e-01  5.74908e-01 -1.53949e-01
21Feb13_033947|  -5.10970e-01]
21Feb13_033947| [ 5.74980e-01 -2.02913e+00 -5.90122e-04  2.24040e-01  2.40596e+00
21Feb13_033947|   1.13780e+00]
21Feb13_033947| [ 5.37268e-01 -1.13424e+00 -1.13375e+00  9.51094e-01 -2.61279e+00
21Feb13_033947|   3.09503e+00]
21Feb13_033947| [-7.43876e-01 -7.91567e-01 -1.42315e-01 -5.44246e-01 -1.31291e+00
21Feb13_033947|   8.00366e-01]
21Feb13_033947| [-4.43500e-01  5.01447e-01  7.37639e-01 -8.86292e-01 -1.43796e-01
21Feb13_033947|  -4.43199e-01]
21Feb13_033947| [-8.09815e-01 -5.40442e-01 -8.18936e-01 -2.62253e-01  1.23623e+00
21Feb13_033947|  -1.68396e-01]
21Feb13_033947| [-1.41040e+00 -1.68646e+00  6.51829e-01  1.33127e+00 -3.55390e-01
21Feb13_033947|  -6.44956e-01]
21Feb13_033947| [ 1.02374e+00  1.38475e+00 -1.60690e+00  1.39313e+00  1.52072e-01
21Feb13_033947|   1.78248e+00]
21Feb13_033947| [ 5.73046e-01 -1.24317e-01 -9.46218e-01 -9.92492e-01  7.18726e-01
21Feb13_033947|  -1.17057e+00]
21Feb13_033947| [ 7.12853e-01 -2.02767e+00  9.54969e-01  2.94993e-01  3.47986e-01
21Feb13_033947|   6.63350e-01]
21Feb13_033947| [-1.54972e-01 -2.25426e-02 -6.84809e-01  1.52444e+00 -3.08307e-01
21Feb13_033947|   6.16589e-01]
21Feb13_033947| [-2.68374e+00 -4.22414e-01 -8.89236e-01 -1.93846e+00 -6.21410e-03
21Feb13_033947|   2.43379e-02]
21Feb13_033947| [ 1.09577e+00 -1.55455e+00 -6.10941e-02  1.52828e-01 -7.03620e-01
21Feb13_033947|   1.09147e-01]
21Feb13_033947| [-7.87936e-01  6.89893e-01  9.67818e-03 -1.11178e+00 -9.82087e-01
21Feb13_033947|  -2.04381e-02]
21Feb13_033947| [-2.17261e+00 -1.22041e-01 -2.73620e-01 -8.36236e-01 -1.38438e+00
21Feb13_033947|  -2.87446e+00]
21Feb13_033947| [-1.27789e+00 -2.22055e+00  8.59278e-01  1.76093e+00  1.70142e+00
21Feb13_033947|  -3.61876e-01]
21Feb13_033947| [-1.67503e-01 -1.63536e-01 -9.50598e-01  4.35036e-01  5.75847e-01
21Feb13_033947|  -8.25957e-01]
21Feb13_033947| [ 2.38600e-01  6.87028e-01 -1.93100e-01 -1.37955e+00 -1.44922e+00
21Feb13_033947|  -5.58933e-01]
21Feb13_033947| [ 1.39524e+00 -1.73409e+00  5.43499e-01  4.06335e-01  1.47732e+00
21Feb13_033947|  -1.58348e+00]
21Feb13_033947| [ 2.93958e-01 -1.60558e-01 -6.19102e-01  2.12392e+00 -5.84554e-01
21Feb13_033947|  -1.08076e+00]
21Feb13_033947| [-1.03545e+00 -5.95621e-01 -4.88036e-01  2.22136e+00  1.27135e+00
21Feb13_033947|   1.21194e+00]
21Feb13_033947| [ 4.53245e-01 -4.35898e-01  9.15575e-01  5.54548e-01  2.31589e+00
21Feb13_033947|  -1.49880e-01]
21Feb13_033947| [ 1.95697e-01 -7.10320e-01  2.11797e+00  2.19429e-01 -8.34045e-01
21Feb13_033947|   6.75304e-01]
21Feb13_033947| [-1.09139e+00 -4.01523e-01  1.57825e+00 -3.63577e-01  1.27839e+00
21Feb13_033947|  -1.36927e+00]
21Feb13_033947| [-1.11411e+00  8.48703e-01 -1.23858e+00  6.59452e-02  6.16666e-01
21Feb13_033947|  -1.01983e+00]
21Feb13_033947| [ 8.64455e-01 -9.64796e-01  1.83325e+00  7.13131e-01 -1.19417e-01
21Feb13_033947|   1.24116e+00]
21Feb13_033947| [ 8.48703e-01 -1.26355e+00  1.89405e-01 -3.56211e-01  1.75192e+00
21Feb13_033947|  -9.35049e-01]
21Feb13_033947| [-6.05565e-01  1.49776e-01 -5.52038e-01  7.30625e-01  7.54976e-01
21Feb13_033947|  -1.13010e-01]]
21Feb13_033947|-- Bias --
21Feb13_033947|[-0.96395 -1.81574  0.59648 -0.89546  0.53643 -0.54271]
21Feb13_033947|Layer 1:
21Feb13_033947|-- Config --
21Feb13_033947|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_033947|-- Weights --
21Feb13_033947|[[-0.15615 -0.20495]
21Feb13_033947| [-0.32598  1.06694]
21Feb13_033947| [-1.47486  2.25005]
21Feb13_033947| [ 0.99958 -0.64832]
21Feb13_033947| [-0.41273 -1.27368]
21Feb13_033947| [-0.24560 -0.41985]]
21Feb13_033947|-- Bias --
21Feb13_033947|[0.71852 0.71224]
21Feb13_033947|Predicting the validation and test data with the Best final individual.
21Feb13_033954| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_033954|-----------  ------------------  --------------------  ----------
21Feb13_033954|Validation         41.74                  6             0.01033
21Feb13_033954|   Test            36.40                  6             0.00298
2021-02-13 03:39:55.089912: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
21Feb13_033955|Data summary: Train
21Feb13_033955|data.shape = (2300, 57)
21Feb13_033955|labels.shape = (2300,)
21Feb13_033955|Class distribution:
21Feb13_033955|	0 - 1389 (0.60)
21Feb13_033955|	1 - 911 (0.40)
21Feb13_033955|Data summary: Validation
21Feb13_033955|data.shape = (1150, 57)
21Feb13_033955|labels.shape = (1150,)
21Feb13_033955|Class distribution:
21Feb13_033955|	0 - 667 (0.58)
21Feb13_033955|	1 - 483 (0.42)
21Feb13_033955|Data summary: Test
21Feb13_033955|data.shape = (1151, 57)
21Feb13_033955|labels.shape = (1151,)
21Feb13_033955|Class distribution:
21Feb13_033955|	0 - 732 (0.64)
21Feb13_033955|	1 - 419 (0.36)
21Feb13_033955|Selected configuration values
21Feb13_033955|-- Dataset name: spambase2
21Feb13_033955|-- Initial population size: 64
21Feb13_033955|-- Maximun number of generations: 32
21Feb13_033955|-- Neurons per hidden layer range: (2, 20)
21Feb13_033955|-- Hidden layers number range: (1, 3)
21Feb13_033955|-- Crossover probability: 0.5
21Feb13_033955|-- Bias gene mutation probability: 0.2
21Feb13_033955|-- Weights gene mutation probability: 0.75
21Feb13_033955|-- Neuron mutation probability: 0.3
21Feb13_033955|-- Layer mutation probability: 0.3
21Feb13_033955|-- Constant hidden layers: False
21Feb13_033955|-- Seed: 31415
21Feb13_033955|Entering GA
21Feb13_033955|Start the algorithm
2021-02-13 03:39:55.926218: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-13 03:39:55.926749: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-02-13 03:39:55.946693: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-13 03:39:55.947012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.71GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s
2021-02-13 03:39:55.947025: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-02-13 03:39:55.948473: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-02-13 03:39:55.948507: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-02-13 03:39:55.949004: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-02-13 03:39:55.949133: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-02-13 03:39:55.949202: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-13 03:39:55.949602: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-02-13 03:39:55.949643: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-13 03:39:55.949650: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-02-13 03:39:55.949846: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-02-13 03:39:55.950601: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-13 03:39:55.950616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-13 03:39:55.950619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      
2021-02-13 03:39:55.995455: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-02-13 03:39:55.995824: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3493635000 Hz
/home/jmerelo/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype("int32")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn('`model.predict_classes()` is deprecated and '
21Feb13_034359|-- Generation 1 --
21Feb13_034359|    -- Crossed 0 individual pairs.
21Feb13_034359|    -- Mutated 32 individuals.
21Feb13_034759|    -- Evaluated 64 individuals.
21Feb13_034759|    Summary of generation 1:
21Feb13_034759| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_034759|-----------  ------------------  --------------------  ----------
21Feb13_034759|    Max            42.70                152.00          0.01805
21Feb13_034759|    Avg            42.01                38.36           0.00129
21Feb13_034759|    Min            41.39                 3.00           0.00000
21Feb13_034759|    Std             0.13                31.76           0.00277
21Feb13_034759|   Best            41.39                38.00           0.01805
21Feb13_034759|-- Generation 2 --
21Feb13_034759|    -- Crossed 1 individual pairs.
21Feb13_034759|    -- Mutated 32 individuals.
21Feb13_035154|    -- Evaluated 64 individuals.
21Feb13_035154|    Summary of generation 2:
21Feb13_035154| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_035154|-----------  ------------------  --------------------  ----------
21Feb13_035154|    Max            44.00                68.00           0.02572
21Feb13_035154|    Avg            42.00                20.38           0.00242
21Feb13_035154|    Min            41.30                 2.00           0.00000
21Feb13_035154|    Std             0.31                13.72           0.00490
21Feb13_035154|   Best            41.30                38.00           0.02572
21Feb13_035154|-- Generation 3 --
21Feb13_035154|    -- Crossed 2 individual pairs.
21Feb13_035154|    -- Mutated 32 individuals.
21Feb13_035546|    -- Evaluated 64 individuals.
21Feb13_035546|    Summary of generation 3:
21Feb13_035546| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_035546|-----------  ------------------  --------------------  ----------
21Feb13_035546|    Max            42.26                45.00           0.00774
21Feb13_035546|    Avg            41.98                16.03           0.00113
21Feb13_035546|    Min            41.83                 2.00           0.00000
21Feb13_035546|    Std             0.06                11.61           0.00182
21Feb13_035546|   Best            41.83                11.00           0.00517
21Feb13_035546|-- Generation 4 --
21Feb13_035546|    -- Crossed 4 individual pairs.
21Feb13_035546|    -- Mutated 32 individuals.
21Feb13_035937|    -- Evaluated 64 individuals.
21Feb13_035937|    Summary of generation 4:
21Feb13_035937| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_035937|-----------  ------------------  --------------------  ----------
21Feb13_035937|    Max            42.43                38.00           0.01805
21Feb13_035937|    Avg            41.96                10.86           0.00210
21Feb13_035937|    Min            41.39                 2.00           0.00000
21Feb13_035937|    Std             0.14                10.15           0.00400
21Feb13_035937|   Best            41.39                 5.00           0.01805
21Feb13_035937|-- Generation 5 --
21Feb13_035937|    -- Crossed 2 individual pairs.
21Feb13_035937|    -- Mutated 32 individuals.
21Feb13_040326|    -- Evaluated 64 individuals.
21Feb13_040326|    Summary of generation 5:
21Feb13_040326| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_040326|-----------  ------------------  --------------------  ----------
21Feb13_040326|    Max            42.52                66.00           0.79529
21Feb13_040326|    Avg            41.68                11.84           0.02621
21Feb13_040326|    Min            26.43                 2.00           0.00000
21Feb13_040326|    Std             1.94                12.74           0.13263
21Feb13_040326|   Best            26.43                12.00           0.73215
21Feb13_040326|-- Generation 6 --
21Feb13_040326|    -- Crossed 5 individual pairs.
21Feb13_040326|    -- Mutated 32 individuals.
21Feb13_040717|    -- Evaluated 64 individuals.
21Feb13_040717|    Summary of generation 6:
21Feb13_040717| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_040717|-----------  ------------------  --------------------  ----------
21Feb13_040717|    Max            42.35                63.00           0.70186
21Feb13_040717|    Avg            41.43                13.83           0.02375
21Feb13_040717|    Min            25.04                 2.00           0.00000
21Feb13_040717|    Std             2.84                14.99           0.11600
21Feb13_040717|   Best            25.04                10.00           0.70186
21Feb13_040717|-- Generation 7 --
21Feb13_040717|    -- Crossed 4 individual pairs.
21Feb13_040717|    -- Mutated 32 individuals.
21Feb13_041108|    -- Evaluated 64 individuals.
21Feb13_041108|    Summary of generation 7:
21Feb13_041108| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_041108|-----------  ------------------  --------------------  ----------
21Feb13_041108|    Max            51.65                66.00           0.79920
21Feb13_041108|    Avg            41.94                15.42           0.02252
21Feb13_041108|    Min            32.26                 2.00           0.00000
21Feb13_041108|    Std             1.72                16.23           0.11163
21Feb13_041108|   Best            32.26                10.00           0.43557
21Feb13_041108|-- Generation 8 --
21Feb13_041108|    -- Crossed 2 individual pairs.
21Feb13_041108|    -- Mutated 32 individuals.
21Feb13_041500|    -- Evaluated 64 individuals.
21Feb13_041500|    Summary of generation 8:
21Feb13_041500| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_041500|-----------  ------------------  --------------------  ----------
21Feb13_041500|    Max            42.17                57.00           0.79501
21Feb13_041500|    Avg            41.43                13.81           0.02519
21Feb13_041500|    Min            26.17                 2.00           0.00000
21Feb13_041500|    Std             2.74                13.00           0.12386
21Feb13_041500|   Best            26.17                10.00           0.79501
21Feb13_041500|-- Generation 9 --
21Feb13_041500|    -- Crossed 5 individual pairs.
21Feb13_041500|    -- Mutated 32 individuals.
21Feb13_041849|    -- Evaluated 64 individuals.
21Feb13_041849|    Summary of generation 9:
21Feb13_041849| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_041849|-----------  ------------------  --------------------  ----------
21Feb13_041849|    Max            42.26                38.00           0.54477
21Feb13_041849|    Avg            41.71                10.00           0.01214
21Feb13_041849|    Min            28.17                 2.00           0.00000
21Feb13_041849|    Std             1.71                 8.40           0.06728
21Feb13_041849|   Best            28.17                18.00           0.54477
21Feb13_041849|-- Generation 10 --
21Feb13_041849|    -- Crossed 6 individual pairs.
21Feb13_041849|    -- Mutated 32 individuals.
21Feb13_042238|    -- Evaluated 64 individuals.
21Feb13_042238|    Summary of generation 10:
21Feb13_042238| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_042238|-----------  ------------------  --------------------  ----------
21Feb13_042238|    Max            42.17                36.00           0.39591
21Feb13_042238|    Avg            41.81                 9.34           0.01219
21Feb13_042238|    Min            38.52                 2.00           0.00000
21Feb13_042238|    Std             0.53                 9.18           0.05227
21Feb13_042238|   Best            38.52                14.00           0.39591
21Feb13_042238|-- Generation 11 --
21Feb13_042238|    -- Crossed 5 individual pairs.
21Feb13_042238|    -- Mutated 32 individuals.
21Feb13_042628|    -- Evaluated 64 individuals.
21Feb13_042628|    Summary of generation 11:
21Feb13_042628| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_042628|-----------  ------------------  --------------------  ----------
21Feb13_042628|    Max            42.17                66.00           0.69325
21Feb13_042628|    Avg            41.71                 9.11           0.01342
21Feb13_042628|    Min            27.65                 2.00           0.00000
21Feb13_042628|    Std             1.78                 9.66           0.08574
21Feb13_042628|   Best            27.65                14.00           0.69325
21Feb13_042628|-- Generation 12 --
21Feb13_042628|    -- Crossed 7 individual pairs.
21Feb13_042628|    -- Mutated 32 individuals.
21Feb13_043016|    -- Evaluated 64 individuals.
21Feb13_043016|    Summary of generation 12:
21Feb13_043016| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_043016|-----------  ------------------  --------------------  ----------
21Feb13_043016|    Max            42.35                38.00           0.77012
21Feb13_043016|    Avg            41.70                 8.02           0.01619
21Feb13_043016|    Min            29.48                 2.00           0.00000
21Feb13_043016|    Std             1.55                 7.62           0.09510
21Feb13_043016|   Best            29.48                14.00           0.77012
21Feb13_043016|-- Generation 13 --
21Feb13_043016|    -- Crossed 6 individual pairs.
21Feb13_043016|    -- Mutated 32 individuals.
21Feb13_043403|    -- Evaluated 64 individuals.
21Feb13_043403|    Summary of generation 13:
21Feb13_043403| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_043403|-----------  ------------------  --------------------  ----------
21Feb13_043403|    Max            42.26                36.00           0.76583
21Feb13_043403|    Avg            41.75                 6.86           0.01568
21Feb13_043403|    Min            31.13                 2.00           0.00000
21Feb13_043403|    Std             1.35                 6.42           0.09461
21Feb13_043403|   Best            31.13                14.00           0.76583
21Feb13_043403|-- Generation 14 --
21Feb13_043403|    -- Crossed 10 individual pairs.
21Feb13_043403|    -- Mutated 32 individuals.
21Feb13_043752|    -- Evaluated 64 individuals.
21Feb13_043752|    Summary of generation 14:
21Feb13_043752| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_043752|-----------  ------------------  --------------------  ----------
21Feb13_043752|    Max            42.61                36.00           0.77071
21Feb13_043752|    Avg            41.52                 8.28           0.02702
21Feb13_043752|    Min            28.43                 2.00           0.00000
21Feb13_043752|    Std             2.15                 7.32           0.12704
21Feb13_043752|   Best            28.43                12.00           0.69512
21Feb13_043752|-- Generation 15 --
21Feb13_043752|    -- Crossed 1 individual pairs.
21Feb13_043752|    -- Mutated 32 individuals.
21Feb13_044142|    -- Evaluated 64 individuals.
21Feb13_044142|    Summary of generation 15:
21Feb13_044142| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_044142|-----------  ------------------  --------------------  ----------
21Feb13_044142|    Max            42.17                36.00           0.75327
21Feb13_044142|    Avg            41.56                 8.03           0.02695
21Feb13_044142|    Min            30.26                 2.00           0.00000
21Feb13_044142|    Std             1.88                 6.23           0.12544
21Feb13_044142|   Best            30.26                14.00           0.69506
21Feb13_044142|-- Generation 16 --
21Feb13_044142|    -- Crossed 6 individual pairs.
21Feb13_044142|    -- Mutated 32 individuals.
21Feb13_044532|    -- Evaluated 64 individuals.
21Feb13_044532|    Summary of generation 16:
21Feb13_044532| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_044532|-----------  ------------------  --------------------  ----------
21Feb13_044532|    Max            46.43                69.00           0.05185
21Feb13_044532|    Avg            41.97                 8.00           0.00501
21Feb13_044532|    Min            41.30                 2.00           0.00000
21Feb13_044532|    Std             0.59                10.03           0.00774
21Feb13_044532|   Best            41.30                 5.00           0.02317
21Feb13_044532|-- Generation 17 --
21Feb13_044532|    -- Crossed 6 individual pairs.
21Feb13_044532|    -- Mutated 32 individuals.
21Feb13_044920|    -- Evaluated 64 individuals.
21Feb13_044920|    Summary of generation 17:
21Feb13_044920| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_044920|-----------  ------------------  --------------------  ----------
21Feb13_044920|    Max            42.43                36.00           0.02317
21Feb13_044920|    Avg            41.88                 5.55           0.00448
21Feb13_044920|    Min            41.30                 2.00           0.00000
21Feb13_044920|    Std             0.19                 6.07           0.00526
21Feb13_044920|   Best            41.30                 6.00           0.02317
21Feb13_044920|-- Generation 18 --
21Feb13_044920|    -- Crossed 2 individual pairs.
21Feb13_044920|    -- Mutated 32 individuals.
21Feb13_045307|    -- Evaluated 64 individuals.
21Feb13_045307|    Summary of generation 18:
21Feb13_045307| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_045307|-----------  ------------------  --------------------  ----------
21Feb13_045307|    Max            42.17                69.00           0.02062
21Feb13_045307|    Avg            41.92                 6.53           0.00351
21Feb13_045307|    Min            41.30                 2.00           0.00000
21Feb13_045307|    Std             0.16                 9.75           0.00457
21Feb13_045307|   Best            41.30                 7.00           0.02062
21Feb13_045307|-- Generation 19 --
21Feb13_045307|    -- Crossed 5 individual pairs.
21Feb13_045307|    -- Mutated 32 individuals.
21Feb13_045654|    -- Evaluated 64 individuals.
21Feb13_045654|    Summary of generation 19:
21Feb13_045654| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_045654|-----------  ------------------  --------------------  ----------
21Feb13_045654|    Max            42.09                36.00           0.71048
21Feb13_045654|    Avg            41.81                 5.77           0.01510
21Feb13_045654|    Min            37.39                 2.00           0.00000
21Feb13_045654|    Std             0.58                 6.78           0.08774
21Feb13_045654|   Best            37.39                20.00           0.71048
21Feb13_045654|-- Generation 20 --
21Feb13_045654|    -- Crossed 1 individual pairs.
21Feb13_045654|    -- Mutated 32 individuals.
21Feb13_050042|    -- Evaluated 64 individuals.
21Feb13_050042|    Summary of generation 20:
21Feb13_050042| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_050042|-----------  ------------------  --------------------  ----------
21Feb13_050042|    Max            42.09                36.00           0.01805
21Feb13_050042|    Avg            41.91                 6.50           0.00315
21Feb13_050042|    Min            41.39                 2.00           0.00000
21Feb13_050042|    Std             0.12                 7.31           0.00352
21Feb13_050042|   Best            41.39                 5.00           0.01805
21Feb13_050042|-- Generation 21 --
21Feb13_050042|    -- Crossed 6 individual pairs.
21Feb13_050042|    -- Mutated 32 individuals.
21Feb13_050429|    -- Evaluated 64 individuals.
21Feb13_050429|    Summary of generation 21:
21Feb13_050429| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_050429|-----------  ------------------  --------------------  ----------
21Feb13_050429|    Max            42.17                36.00           0.02317
21Feb13_050429|    Avg            41.86                 5.66           0.00472
21Feb13_050429|    Min            41.30                 2.00           0.00000
21Feb13_050429|    Std             0.18                 6.61           0.00563
21Feb13_050429|   Best            41.30                 5.00           0.02317
21Feb13_050429|-- Generation 22 --
21Feb13_050429|    -- Crossed 5 individual pairs.
21Feb13_050429|    -- Mutated 32 individuals.
21Feb13_050817|    -- Evaluated 64 individuals.
21Feb13_050817|    Summary of generation 22:
21Feb13_050817| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_050817|-----------  ------------------  --------------------  ----------
21Feb13_050817|    Max            42.09                36.00           0.02061
21Feb13_050817|    Avg            41.87                 6.12           0.00416
21Feb13_050817|    Min            41.39                 2.00           0.00000
21Feb13_050817|    Std             0.15                 6.72           0.00443
21Feb13_050817|   Best            41.39                 5.00           0.02061
21Feb13_050817|-- Generation 23 --
21Feb13_050817|    -- Crossed 3 individual pairs.
21Feb13_050817|    -- Mutated 32 individuals.
21Feb13_051206|    -- Evaluated 64 individuals.
21Feb13_051206|    Summary of generation 23:
21Feb13_051206| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_051206|-----------  ------------------  --------------------  ----------
21Feb13_051206|    Max            42.17                36.00           0.02061
21Feb13_051206|    Avg            41.88                 6.53           0.00432
21Feb13_051206|    Min            41.39                 2.00           0.00000
21Feb13_051206|    Std             0.13                 6.50           0.00403
21Feb13_051206|   Best            41.39                 5.00           0.01805
21Feb13_051206|-- Generation 24 --
21Feb13_051206|    -- Crossed 6 individual pairs.
21Feb13_051206|    -- Mutated 32 individuals.
21Feb13_051554|    -- Evaluated 64 individuals.
21Feb13_051554|    Summary of generation 24:
21Feb13_051554| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_051554|-----------  ------------------  --------------------  ----------
21Feb13_051554|    Max            42.17                69.00           0.02062
21Feb13_051554|    Avg            41.86                 7.48           0.00516
21Feb13_051554|    Min            41.30                 2.00           0.00000
21Feb13_051554|    Std             0.17                10.08           0.00497
21Feb13_051554|   Best            41.30                 3.00           0.02062
21Feb13_051554|-- Generation 25 --
21Feb13_051554|    -- Crossed 2 individual pairs.
21Feb13_051554|    -- Mutated 32 individuals.
21Feb13_051943|    -- Evaluated 64 individuals.
21Feb13_051943|    Summary of generation 25:
21Feb13_051943| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_051943|-----------  ------------------  --------------------  ----------
21Feb13_051943|    Max            42.09                36.00           0.02062
21Feb13_051943|    Avg            41.86                 7.05           0.00464
21Feb13_051943|    Min            41.30                 2.00           0.00000
21Feb13_051943|    Std             0.14                 6.84           0.00452
21Feb13_051943|   Best            41.30                 4.00           0.02062
21Feb13_051943|-- Generation 26 --
21Feb13_051943|    -- Crossed 4 individual pairs.
21Feb13_051943|    -- Mutated 32 individuals.
21Feb13_052329|    -- Evaluated 64 individuals.
21Feb13_052329|    Summary of generation 26:
21Feb13_052329| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_052329|-----------  ------------------  --------------------  ----------
21Feb13_052329|    Max            42.09                20.00           0.02318
21Feb13_052329|    Avg            41.84                 5.77           0.00508
21Feb13_052329|    Min            41.22                 2.00           0.00000
21Feb13_052329|    Std             0.19                 4.08           0.00523
21Feb13_052329|   Best            41.22                 3.00           0.02318
21Feb13_052329|-- Generation 27 --
21Feb13_052329|    -- Crossed 5 individual pairs.
21Feb13_052329|    -- Mutated 32 individuals.
21Feb13_052718|    -- Evaluated 64 individuals.
21Feb13_052718|    Summary of generation 27:
21Feb13_052718| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_052718|-----------  ------------------  --------------------  ----------
21Feb13_052718|    Max            42.09                16.00           0.02318
21Feb13_052718|    Avg            41.80                 5.70           0.00629
21Feb13_052718|    Min            41.22                 2.00           0.00000
21Feb13_052718|    Std             0.20                 3.94           0.00595
21Feb13_052718|   Best            41.22                 6.00           0.02318
21Feb13_052718|-- Generation 28 --
21Feb13_052718|    -- Crossed 7 individual pairs.
21Feb13_052718|    -- Mutated 32 individuals.
21Feb13_053106|    -- Evaluated 64 individuals.
21Feb13_053106|    Summary of generation 28:
21Feb13_053106| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_053106|-----------  ------------------  --------------------  ----------
21Feb13_053106|    Max            42.17                24.00           0.64214
21Feb13_053106|    Avg            41.65                 5.73           0.01548
21Feb13_053106|    Min            29.48                 2.00           0.00000
21Feb13_053106|    Std             1.54                 4.51           0.07913
21Feb13_053106|   Best            29.48                16.00           0.64214
21Feb13_053106|-- Generation 29 --
21Feb13_053106|    -- Crossed 2 individual pairs.
21Feb13_053106|    -- Mutated 32 individuals.
21Feb13_053454|    -- Evaluated 64 individuals.
21Feb13_053454|    Summary of generation 29:
21Feb13_053454| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_053454|-----------  ------------------  --------------------  ----------
21Feb13_053454|    Max            51.39                18.00           0.79773
21Feb13_053454|    Avg            41.95                 5.80           0.01888
21Feb13_053454|    Min            41.13                 2.00           0.00000
21Feb13_053454|    Std             1.21                 4.37           0.09831
21Feb13_053454|   Best            41.13                 4.00           0.02575
21Feb13_053454|-- Generation 30 --
21Feb13_053454|    -- Crossed 7 individual pairs.
21Feb13_053454|    -- Mutated 32 individuals.
21Feb13_053840|    -- Evaluated 64 individuals.
21Feb13_053840|    Summary of generation 30:
21Feb13_053840| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_053840|-----------  ------------------  --------------------  ----------
21Feb13_053840|    Max            42.17                24.00           0.02318
21Feb13_053840|    Avg            41.83                 5.27           0.00549
21Feb13_053840|    Min            41.22                 2.00           0.00000
21Feb13_053840|    Std             0.17                 4.20           0.00498
21Feb13_053840|   Best            41.22                 5.00           0.02318
21Feb13_053840|-- Generation 31 --
21Feb13_053840|    -- Crossed 6 individual pairs.
21Feb13_053840|    -- Mutated 32 individuals.
21Feb13_054228|    -- Evaluated 64 individuals.
21Feb13_054228|    Summary of generation 31:
21Feb13_054228| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_054228|-----------  ------------------  --------------------  ----------
21Feb13_054228|    Max            42.00                20.00           0.02318
21Feb13_054228|    Avg            41.79                 4.86           0.00690
21Feb13_054228|    Min            41.22                 2.00           0.00000
21Feb13_054228|    Std             0.19                 3.73           0.00596
21Feb13_054228|   Best            41.22                 3.00           0.02318
21Feb13_054228|-- Generation 32 --
21Feb13_054228|    -- Crossed 5 individual pairs.
21Feb13_054228|    -- Mutated 32 individuals.
21Feb13_054617|    -- Evaluated 64 individuals.
21Feb13_054617|    Summary of generation 32:
21Feb13_054617| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_054617|-----------  ------------------  --------------------  ----------
21Feb13_054617|    Max            42.26                24.00           0.02062
21Feb13_054617|    Avg            41.84                 5.92           0.00581
21Feb13_054617|    Min            41.30                 2.00           0.00000
21Feb13_054617|    Std             0.21                 5.00           0.00580
21Feb13_054617|   Best            41.30                 3.00           0.02062
21Feb13_054617|Best initial individual weights
21Feb13_054617|Individual:
21Feb13_054617|-- Constant hidden layers --
21Feb13_054617|False
21Feb13_054617|Layer 0:
21Feb13_054617|-- Config --
21Feb13_054617|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 14, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_054617|-- Weights --
21Feb13_054617|[[-0.46755 -0.77923  0.54917 -0.28189 -0.72659 -0.27127 -0.27090 -0.70110
21Feb13_054617|  -0.67504 -0.55383  0.05413 -0.54585  0.33416 -0.40920]
21Feb13_054617| [-0.63500  0.50563  0.57366  0.56179  0.04949  0.13217  0.41463  0.93392
21Feb13_054617|   0.61458  0.96459 -0.18538 -0.13505  0.57914 -0.52395]
21Feb13_054617| [-0.68746 -0.76013 -0.94302  0.63098 -0.51538  0.18933 -0.84177  0.74255
21Feb13_054617|   0.86109 -0.27253 -0.84093 -0.97103 -0.02308  0.93169]
21Feb13_054617| [-0.30389 -0.64730  0.82087 -0.31786 -0.85760 -0.53174 -0.24099  0.67567
21Feb13_054617|   0.06588 -0.45133 -0.21639 -0.44111 -0.61620 -0.17649]
21Feb13_054617| [ 0.48191 -0.65488 -0.21573 -0.77382  0.08877 -0.42943  0.31791  0.19963
21Feb13_054617|   0.68021 -0.01578  0.68440  0.17655 -0.21113  0.67186]
21Feb13_054617| [-0.36815  0.65794 -0.13217 -0.31720  0.76634  0.27196  0.95938  0.33809
21Feb13_054617|   0.19009  0.33029 -0.46957 -0.33031 -0.51404  0.65862]
21Feb13_054617| [-0.65723  0.89409  0.22717  0.66331 -0.65923  0.79128 -0.98129  0.85470
21Feb13_054617|  -0.14172 -0.04193 -0.47613  0.48781  0.68267 -0.66590]
21Feb13_054617| [-0.52649  0.13025 -0.62663 -0.42792  0.22186 -0.95757 -0.54927  0.85846
21Feb13_054617|   0.31648  0.71487 -0.43083  0.44347 -0.23840 -0.29771]
21Feb13_054617| [ 0.66666 -0.29194  0.36156 -0.76444  0.85348 -0.92589 -0.67688 -0.59105
21Feb13_054617|  -0.14206 -0.14664 -0.95610 -0.12937  0.30125 -0.16216]
21Feb13_054617| [ 0.77747  0.46685 -0.71306  0.32989 -0.87164 -0.11013  0.19666  0.73410
21Feb13_054617|  -0.29764  0.99239 -0.68544  0.41165 -0.64248 -0.97687]
21Feb13_054617| [ 0.17007 -0.65841  0.72035  0.09167  0.85914  0.22927 -0.25043 -0.23306
21Feb13_054617|   0.72466  0.74012  0.43476  0.85579 -0.95528 -0.61712]
21Feb13_054617| [-0.09915 -0.54507 -0.26888  0.02218  0.58739 -0.06694  0.07394 -0.71029
21Feb13_054617|  -0.70699 -0.17378 -0.26204 -0.54108  0.87105  0.37003]
21Feb13_054617| [-0.87676  0.79843  0.13830  0.73610 -0.35602  0.07624  0.58797  0.93769
21Feb13_054617|  -0.47112 -0.88784 -0.32329  0.57694  0.54031  0.46209]
21Feb13_054617| [ 0.56833  0.00229 -0.63767 -0.25082  0.87251  0.72852 -0.35706 -0.32574
21Feb13_054617|   0.00338 -0.96495 -0.24423  0.83795  0.17704 -0.52730]
21Feb13_054617| [ 0.57389  0.43306 -0.14668  0.09726 -0.40905  0.48410  0.46706  0.29093
21Feb13_054617|  -0.73066 -0.42228 -0.50998  0.90495  0.38869  0.16695]
21Feb13_054617| [-0.38641 -0.90524 -0.68245 -0.18039  0.28617  0.95451  0.31495  0.98373
21Feb13_054617|   0.03790 -0.42415 -0.77936 -0.83630  0.24380 -0.33397]
21Feb13_054617| [ 0.45738 -0.32376  0.96332 -0.16096  0.31168 -0.94554  0.35925 -0.69530
21Feb13_054617|  -0.03069 -0.91449 -0.94713 -0.87442  0.37907  0.83374]
21Feb13_054617| [ 0.82631 -0.40539  0.37464  0.84534  0.25362 -0.91741 -0.31505  0.86890
21Feb13_054617|  -0.89153 -0.90321  0.55294 -0.19362 -0.49542 -0.19912]
21Feb13_054617| [ 0.45632 -0.68250 -0.38370 -0.52120 -0.03266 -0.74606 -0.97861 -0.15550
21Feb13_054617|  -0.33213  0.11576  0.28994  0.00440  0.65196 -0.58094]
21Feb13_054617| [-0.08531  0.13013 -0.49165  0.13948  0.90958 -0.93520  0.58653 -0.14145
21Feb13_054617|  -0.31804  0.99202 -0.46123 -0.67566  0.72270  0.07720]
21Feb13_054617| [-0.18701  0.84394  0.21217  0.94145 -0.47411  0.61988  0.95344 -0.18707
21Feb13_054617|   0.26361 -0.55127  0.19663  0.91693  0.70662 -0.93054]
21Feb13_054617| [-0.24922 -0.65816  0.12943  0.71089 -0.96074 -0.49543 -0.74916  0.72108
21Feb13_054617|   0.47341 -0.33704  0.60085 -0.79768  0.05831  0.93894]
21Feb13_054617| [-0.56027 -0.07417 -0.59317  0.17038  0.89351 -0.58669  0.76195 -0.97400
21Feb13_054617|  -0.26234  0.01124 -0.37019 -0.07945  0.30678 -0.05190]
21Feb13_054617| [ 0.33030 -0.80606 -0.15583  0.36617  0.51910 -0.23815 -0.41574  0.84538
21Feb13_054617|  -0.24786  0.45644  0.55059  0.62875  0.62044 -0.20357]
21Feb13_054617| [ 0.04941  0.26053 -0.36386 -0.34913  0.91955  0.05273 -0.94165 -0.78189
21Feb13_054617|  -0.57974 -0.22811  0.72354 -0.04255  0.26185  0.37401]
21Feb13_054617| [-0.02059 -0.55773  0.72546 -0.82885 -0.73287  0.45804 -0.78944  0.74713
21Feb13_054617|  -0.89593  0.72724 -0.44896 -0.14313 -0.67643 -0.03675]
21Feb13_054617| [ 0.12220 -0.58125 -0.12500  0.26843  0.12176  0.77053  0.22442 -0.89966
21Feb13_054617|   0.09096 -0.24841 -0.27943  0.37594 -0.79211 -0.43915]
21Feb13_054617| [ 0.13685 -0.46444 -0.80102  0.04904  0.90523 -0.51614 -0.62836 -0.04136
21Feb13_054617|  -0.72900  0.62896 -0.29738  0.27190 -0.76503  0.74540]
21Feb13_054617| [ 0.18538 -0.44490 -0.03086 -0.72017  0.82826  0.04552  0.19502  0.01582
21Feb13_054617|   0.07019  0.26265 -0.61195  0.70762 -0.68833  0.59056]
21Feb13_054617| [-0.19076 -0.40389  0.94951  0.81209 -0.24990 -0.73472  0.35684  0.54594
21Feb13_054617|   0.02705 -0.70092 -0.75131  0.28926 -0.76413  0.90106]
21Feb13_054617| [ 0.89491 -0.44966 -0.07129  0.47477 -0.31786  0.19173  0.56299  0.78493
21Feb13_054617|  -0.85890 -0.80598 -0.03673 -0.18087  0.92364  0.04843]
21Feb13_054617| [ 0.30403  0.77247 -0.84687  0.76203  0.25237  0.62157 -0.18053 -0.91906
21Feb13_054617|  -0.04765  0.20249 -0.65221 -0.05052 -0.41625 -0.65536]
21Feb13_054617| [-0.84187 -0.80188 -0.99497  0.76603 -0.71492 -0.17111 -0.28120  0.80320
21Feb13_054617|  -0.07261  0.71081  0.01508  0.97961 -0.05309  0.42977]
21Feb13_054617| [-0.19072  0.97039 -0.08302 -0.04211 -0.01337 -0.48400 -0.52995  0.19069
21Feb13_054617|   0.01795  0.45507  0.01718 -0.36766 -0.31757  0.80225]
21Feb13_054617| [-0.56903  0.23408  0.70376 -0.67078  0.15573 -0.23159  0.47725  0.93539
21Feb13_054617|  -0.75790  0.53202 -0.84788  0.79902 -0.71951 -0.63768]
21Feb13_054617| [-0.02086  0.23811  0.84799  0.66904  0.62595  0.79239  0.14162 -0.69665
21Feb13_054617|  -0.17673  0.36012 -0.10827 -0.54487 -0.94652  0.64132]
21Feb13_054617| [ 0.54057 -0.52721  0.19858  0.46209  0.25979  0.46581 -0.43188 -0.25092
21Feb13_054617|   0.10142  0.36981  0.29653 -0.60029  0.63754  0.78518]
21Feb13_054617| [-0.73536  0.15757 -0.67765  0.94100  0.55251  0.93236 -0.09504 -0.25668
21Feb13_054617|  -0.49745 -0.08851  0.21545 -0.20070  0.23399  0.94390]
21Feb13_054617| [ 0.40157 -0.64885 -0.99951 -0.73596  0.83216  0.13883 -0.43141 -0.25660
21Feb13_054617|  -0.64869  0.18746 -0.14855 -0.29644 -0.08967  0.09011]
21Feb13_054617| [ 0.24532 -0.25469 -0.27555 -0.26078 -0.06836  0.97940  0.31619 -0.83638
21Feb13_054617|   0.25254 -0.18261  0.58487  0.57371 -0.33039 -0.26035]
21Feb13_054617| [-0.40443 -0.03473  0.67337 -0.52501  0.15891 -0.25029 -0.86421 -0.50345
21Feb13_054617|   0.23077 -0.70594  0.38123 -0.14116  0.24608  0.30380]
21Feb13_054617| [-0.91157 -0.71115 -0.08024  0.43313 -0.66540  0.97313 -0.73091 -0.81121
21Feb13_054617|  -0.12058 -0.15718  0.36369  0.79179  0.96340 -0.40657]
21Feb13_054617| [-0.14059 -0.01148 -0.02677  0.33900 -0.10768 -0.17529 -0.80387 -0.53018
21Feb13_054617|  -0.19863 -0.71902  0.15616  0.81354 -0.49761 -0.06255]
21Feb13_054617| [-0.24706 -0.06008 -0.57834  0.30502 -0.16921 -0.90075  0.78975 -0.91475
21Feb13_054617|   0.17278 -0.06501 -0.82514  0.42792  0.50567  0.31420]
21Feb13_054617| [ 0.19858  0.27139 -0.66526  0.22931 -0.91885 -0.57502  0.66730 -0.08919
21Feb13_054617|   0.48485  0.41713 -0.43555  0.42449 -0.02396  0.92678]
21Feb13_054617| [-0.26449 -0.66167  0.92432 -0.34591 -0.84237 -0.20862 -0.38663  0.70631
21Feb13_054617|  -0.58894  0.28492 -0.75196  0.78287 -0.76882  0.60073]
21Feb13_054617| [-0.90089  0.36008 -0.62836  0.05717  0.16910 -0.42677 -0.29327 -0.07989
21Feb13_054617|   0.83425 -0.46170 -0.83419  0.47481  0.22246  0.00845]
21Feb13_054617| [-0.01303 -0.79612  0.01337  0.96383  0.88888  0.40733  0.52040 -0.78910
21Feb13_054617|   0.54808  0.80667 -0.18360 -0.64126 -0.39695 -0.66319]
21Feb13_054617| [-0.88076  0.98424  0.92610  0.64666 -0.31894 -0.82556 -0.27707  0.04045
21Feb13_054617|   0.66390  0.99121 -0.43994 -0.56351 -0.88577 -0.78906]
21Feb13_054617| [-0.08809 -0.47914  0.74437  0.18616  0.14492  0.91897 -0.78420  0.19567
21Feb13_054617|   0.21651  0.11022 -0.63077  0.25838 -0.62852 -0.54420]
21Feb13_054617| [ 0.83666 -0.13041  0.11889  0.48108 -0.65844 -0.93334 -0.35183 -0.71039
21Feb13_054617|   0.25408  0.40921 -0.96035  0.03882  0.23292 -0.23146]
21Feb13_054617| [-0.42276 -0.88165  0.91051 -0.26078 -0.60459 -0.88375  0.06035  0.28531
21Feb13_054617|  -0.85402  0.32638  0.75647 -0.52785  0.49295  0.07150]
21Feb13_054617| [ 0.41227 -0.53332 -0.86738  0.05626  0.12633 -0.18304  0.78693  0.76589
21Feb13_054617|   0.23618  0.20811  0.34520 -0.59405 -0.24790 -0.64175]
21Feb13_054617| [ 0.16112  0.08361  0.09088  0.19541 -0.26349  0.25044 -0.58915  0.33944
21Feb13_054617|  -0.83164  0.61911  0.32780 -0.96216  0.97785 -0.34160]
21Feb13_054617| [ 0.42787 -0.25634 -0.11060  0.91572  0.65583 -0.19126  0.55396 -0.93986
21Feb13_054617|   0.87875  0.03214 -0.49125 -0.78175 -0.92747  0.36487]
21Feb13_054617| [-0.74605 -0.47039  0.66455 -0.40278 -0.45182 -0.79306 -0.10554 -0.06691
21Feb13_054617|   0.41563 -0.07006  0.15794 -0.88368 -0.54811  0.06069]
21Feb13_054617| [-0.25592 -0.72120 -0.35502 -0.55513  0.21451 -0.66825  0.21368  0.77818
21Feb13_054617|   0.95608 -0.27384 -0.23671 -0.50859 -0.15268  0.22426]]
21Feb13_054617|-- Bias --
21Feb13_054617|[-0.31320 -0.24309  0.70469  0.03150 -0.67450  0.49415  0.71057  0.56074
21Feb13_054617| -0.68882 -0.02550  0.88238 -0.30120  0.61236 -0.98547]
21Feb13_054617|Layer 1:
21Feb13_054617|-- Config --
21Feb13_054617|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 14], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_054617|-- Weights --
21Feb13_054617|[[ 0.98573 -0.10612]
21Feb13_054617| [-0.84650 -0.91832]
21Feb13_054617| [-0.43497 -0.92411]
21Feb13_054617| [-0.33475  0.47765]
21Feb13_054617| [ 0.03103 -0.47578]
21Feb13_054617| [-0.40987 -0.23556]
21Feb13_054617| [ 0.94394  0.01566]
21Feb13_054617| [ 0.73003  0.37218]
21Feb13_054617| [ 0.70222 -0.45412]
21Feb13_054617| [-0.23121 -0.00197]
21Feb13_054617| [ 0.27099  0.18396]
21Feb13_054617| [ 0.80007  0.70964]
21Feb13_054617| [-0.41310  0.94902]
21Feb13_054617| [-0.11261 -0.90297]]
21Feb13_054617|-- Bias --
21Feb13_054617|[-0.28704  0.27496]
21Feb13_054617|Predicting the validation and test data with the Best initial individual.
21Feb13_054624| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_054624|-----------  ------------------  --------------------  ----------
21Feb13_054624|Validation         41.39                  14            0.01805
21Feb13_054624|   Test            36.23                  14            0.00596
21Feb13_054624|-------------------- Test #0 --------------------
21Feb13_054624|Best final individual weights
21Feb13_054624|Individual:
21Feb13_054624|-- Constant hidden layers --
21Feb13_054624|False
21Feb13_054624|Layer 0:
21Feb13_054624|-- Config --
21Feb13_054624|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_054624|-- Weights --
21Feb13_054624|[[-0.58131  0.41104 -0.62368]
21Feb13_054624| [ 0.69656 -1.02993 -0.20603]
21Feb13_054624| [-1.86788  2.30608 -0.81731]
21Feb13_054624| [ 2.35696  1.24218 -0.92105]
21Feb13_054624| [-0.61245  1.01963 -0.41972]
21Feb13_054624| [-0.79454 -0.79620 -1.73701]
21Feb13_054624| [-1.13615 -0.38489 -0.82265]
21Feb13_054624| [-0.25325 -1.16213  0.70843]
21Feb13_054624| [ 0.83976  0.00993 -0.70265]
21Feb13_054624| [ 0.03684  0.08167 -0.17511]
21Feb13_054624| [ 0.57322 -0.08752  0.19502]
21Feb13_054624| [ 0.89737  1.16408 -0.22033]
21Feb13_054624| [ 0.44220  0.98258  1.32976]
21Feb13_054624| [ 0.14725 -0.31934 -0.22376]
21Feb13_054624| [-0.48317  1.49892 -0.58919]
21Feb13_054624| [-0.92600 -0.13766 -0.87815]
21Feb13_054624| [ 0.49251  0.54697  2.15955]
21Feb13_054624| [-1.54885  0.99749 -0.01751]
21Feb13_054624| [-0.25372 -1.31307  0.28582]
21Feb13_054624| [ 0.22894  0.35440  0.55132]
21Feb13_054624| [ 0.40985  0.84636 -0.09488]
21Feb13_054624| [ 0.25282  0.95784 -0.20253]
21Feb13_054624| [ 1.38163 -0.00593 -0.16853]
21Feb13_054624| [ 0.45233  1.00133  1.55658]
21Feb13_054624| [-0.04314 -0.28648 -0.91586]
21Feb13_054624| [ 0.52062 -1.41258  1.36297]
21Feb13_054624| [ 0.19469 -0.40620 -0.80653]
21Feb13_054624| [-0.92176  0.82471  0.88854]
21Feb13_054624| [ 0.08866 -0.43584  1.31285]
21Feb13_054624| [ 2.28433 -0.37639  1.71487]
21Feb13_054624| [-1.29992  0.11704  0.96791]
21Feb13_054624| [ 0.01865  0.75131  0.94805]
21Feb13_054624| [-1.38934 -0.85679 -1.03067]
21Feb13_054624| [ 1.08457  0.92298 -1.79844]
21Feb13_054624| [ 1.45389 -0.34044 -0.13392]
21Feb13_054624| [ 0.63791 -0.99181  0.83168]
21Feb13_054624| [ 1.01793 -0.84685  0.50036]
21Feb13_054624| [-0.50065 -1.16125  0.03549]
21Feb13_054624| [-0.67174 -0.13235  0.05094]
21Feb13_054624| [-0.65057  0.27166 -0.33921]
21Feb13_054624| [ 1.04472 -0.02756 -0.87296]
21Feb13_054624| [ 0.10613  0.07959  0.42727]
21Feb13_054624| [ 0.07967  0.39679  1.02531]
21Feb13_054624| [ 1.82264 -0.32392 -2.71293]
21Feb13_054624| [ 1.83116 -0.68393 -1.06911]
21Feb13_054624| [-0.65866  0.55609  0.45198]
21Feb13_054624| [ 0.15390 -0.12530 -0.49443]
21Feb13_054624| [ 1.03811 -0.82233 -1.38641]
21Feb13_054624| [ 1.20222  0.67180  0.52163]
21Feb13_054624| [-0.58928  1.11110  0.79006]
21Feb13_054624| [ 0.87426  0.30426 -0.44848]
21Feb13_054624| [ 0.69579 -0.36500 -0.34569]
21Feb13_054624| [ 0.78584 -0.89277  0.94968]
21Feb13_054624| [ 1.11890  0.55386 -0.30582]
21Feb13_054624| [-0.30253  1.01131 -0.38667]
21Feb13_054624| [ 0.60845  0.73766  0.25496]
21Feb13_054624| [-0.70400 -0.39828 -0.29869]]
21Feb13_054624|-- Bias --
21Feb13_054624|[-0.92461  0.60117 -0.43775]
21Feb13_054624|Layer 1:
21Feb13_054624|-- Config --
21Feb13_054624|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_054624|-- Weights --
21Feb13_054624|[[-0.47251  1.36579]
21Feb13_054624| [-0.20704  0.40126]
21Feb13_054624| [-1.70310  1.22032]]
21Feb13_054624|-- Bias --
21Feb13_054624|[-0.67142  0.13605]
21Feb13_054624|Predicting the validation and test data with the Best final individual.
21Feb13_054631| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_054631|-----------  ------------------  --------------------  ----------
21Feb13_054631|Validation         41.48                  3             0.01548
21Feb13_054631|   Test            36.40                  3             0.00595
21Feb13_054631|-------------------- Test #1 --------------------
21Feb13_054631|Best final individual weights
21Feb13_054631|Individual:
21Feb13_054631|-- Constant hidden layers --
21Feb13_054631|False
21Feb13_054631|Layer 0:
21Feb13_054631|-- Config --
21Feb13_054631|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_054631|-- Weights --
21Feb13_054631|[[-0.58131  0.41104 -0.62368]
21Feb13_054631| [ 0.69656 -1.02993 -0.20603]
21Feb13_054631| [-1.86788  2.30608 -0.81731]
21Feb13_054631| [ 2.35696  1.24218 -0.92105]
21Feb13_054631| [-0.61245  1.01963 -0.41972]
21Feb13_054631| [-0.79454 -0.79620 -1.73701]
21Feb13_054631| [-1.13615 -0.38489 -0.82265]
21Feb13_054631| [-0.25325 -1.16213  0.70843]
21Feb13_054631| [ 0.83976  0.00993 -0.70265]
21Feb13_054631| [ 0.03684  0.08167 -0.17511]
21Feb13_054631| [ 0.57322 -0.08752  0.19502]
21Feb13_054631| [ 0.89737  1.16408 -0.22033]
21Feb13_054631| [ 0.44220  0.98258  1.32976]
21Feb13_054631| [ 0.14725 -0.31934 -0.22376]
21Feb13_054631| [-0.48317  1.49892 -0.58919]
21Feb13_054631| [-0.92600 -0.13766 -0.87815]
21Feb13_054631| [ 0.49251  0.54697  2.15955]
21Feb13_054631| [-1.54885  0.99749 -0.01751]
21Feb13_054631| [-0.25372 -1.31307  0.28582]
21Feb13_054631| [ 0.22894  0.35440  0.55132]
21Feb13_054631| [ 0.40985  0.84636 -0.09488]
21Feb13_054631| [ 0.25282  0.95784 -0.20253]
21Feb13_054631| [ 1.38163 -0.00593 -0.16853]
21Feb13_054631| [ 0.45233  1.00133  1.55658]
21Feb13_054631| [-0.04314 -0.28648 -0.91586]
21Feb13_054631| [ 0.52062 -1.41258  1.36297]
21Feb13_054631| [ 0.19469 -0.40620 -0.80653]
21Feb13_054631| [-0.92176  0.82471  0.88854]
21Feb13_054631| [ 0.08866 -0.43584  1.31285]
21Feb13_054631| [ 2.28433 -0.37639  1.71487]
21Feb13_054631| [-1.29992  0.11704  0.96791]
21Feb13_054631| [ 0.01865  0.75131  0.94805]
21Feb13_054631| [-1.38934 -0.85679 -1.03067]
21Feb13_054631| [ 1.08457  0.92298 -1.79844]
21Feb13_054631| [ 1.45389 -0.34044 -0.13392]
21Feb13_054631| [ 0.63791 -0.99181  0.83168]
21Feb13_054631| [ 1.01793 -0.84685  0.50036]
21Feb13_054631| [-0.50065 -1.16125  0.03549]
21Feb13_054631| [-0.67174 -0.13235  0.05094]
21Feb13_054631| [-0.65057  0.27166 -0.33921]
21Feb13_054631| [ 1.04472 -0.02756 -0.87296]
21Feb13_054631| [ 0.10613  0.07959  0.42727]
21Feb13_054631| [ 0.07967  0.39679  1.02531]
21Feb13_054631| [ 1.82264 -0.32392 -2.71293]
21Feb13_054631| [ 1.83116 -0.68393 -1.06911]
21Feb13_054631| [-0.65866  0.55609  0.45198]
21Feb13_054631| [ 0.15390 -0.12530 -0.49443]
21Feb13_054631| [ 1.03811 -0.82233 -1.38641]
21Feb13_054631| [ 1.20222  0.67180  0.52163]
21Feb13_054631| [-0.58928  1.11110  0.79006]
21Feb13_054631| [ 0.87426  0.30426 -0.44848]
21Feb13_054631| [ 0.69579 -0.36500 -0.34569]
21Feb13_054631| [ 0.78584 -0.89277  0.94968]
21Feb13_054631| [ 1.11890  0.55386 -0.30582]
21Feb13_054631| [-0.30253  1.01131 -0.38667]
21Feb13_054631| [ 0.60845  0.73766  0.25496]
21Feb13_054631| [-0.70400 -0.39828 -0.29869]]
21Feb13_054631|-- Bias --
21Feb13_054631|[-0.92461  0.60117 -0.43775]
21Feb13_054631|Layer 1:
21Feb13_054631|-- Config --
21Feb13_054631|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_054631|-- Weights --
21Feb13_054631|[[-0.47251  1.36579]
21Feb13_054631| [-0.20704  0.40126]
21Feb13_054631| [-1.70310  1.22032]]
21Feb13_054631|-- Bias --
21Feb13_054631|[-0.67142  0.13605]
21Feb13_054631|Predicting the validation and test data with the Best final individual.
21Feb13_054638| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_054638|-----------  ------------------  --------------------  ----------
21Feb13_054638|Validation         41.39                  3             0.01805
21Feb13_054638|   Test            36.40                  3             0.00595
21Feb13_054638|-------------------- Test #2 --------------------
21Feb13_054638|Best final individual weights
21Feb13_054638|Individual:
21Feb13_054638|-- Constant hidden layers --
21Feb13_054638|False
21Feb13_054638|Layer 0:
21Feb13_054638|-- Config --
21Feb13_054638|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_054638|-- Weights --
21Feb13_054638|[[-0.58131  0.41104 -0.62368]
21Feb13_054638| [ 0.69656 -1.02993 -0.20603]
21Feb13_054638| [-1.86788  2.30608 -0.81731]
21Feb13_054638| [ 2.35696  1.24218 -0.92105]
21Feb13_054638| [-0.61245  1.01963 -0.41972]
21Feb13_054638| [-0.79454 -0.79620 -1.73701]
21Feb13_054638| [-1.13615 -0.38489 -0.82265]
21Feb13_054638| [-0.25325 -1.16213  0.70843]
21Feb13_054638| [ 0.83976  0.00993 -0.70265]
21Feb13_054638| [ 0.03684  0.08167 -0.17511]
21Feb13_054638| [ 0.57322 -0.08752  0.19502]
21Feb13_054638| [ 0.89737  1.16408 -0.22033]
21Feb13_054638| [ 0.44220  0.98258  1.32976]
21Feb13_054638| [ 0.14725 -0.31934 -0.22376]
21Feb13_054638| [-0.48317  1.49892 -0.58919]
21Feb13_054638| [-0.92600 -0.13766 -0.87815]
21Feb13_054638| [ 0.49251  0.54697  2.15955]
21Feb13_054638| [-1.54885  0.99749 -0.01751]
21Feb13_054638| [-0.25372 -1.31307  0.28582]
21Feb13_054638| [ 0.22894  0.35440  0.55132]
21Feb13_054638| [ 0.40985  0.84636 -0.09488]
21Feb13_054638| [ 0.25282  0.95784 -0.20253]
21Feb13_054638| [ 1.38163 -0.00593 -0.16853]
21Feb13_054638| [ 0.45233  1.00133  1.55658]
21Feb13_054638| [-0.04314 -0.28648 -0.91586]
21Feb13_054638| [ 0.52062 -1.41258  1.36297]
21Feb13_054638| [ 0.19469 -0.40620 -0.80653]
21Feb13_054638| [-0.92176  0.82471  0.88854]
21Feb13_054638| [ 0.08866 -0.43584  1.31285]
21Feb13_054638| [ 2.28433 -0.37639  1.71487]
21Feb13_054638| [-1.29992  0.11704  0.96791]
21Feb13_054638| [ 0.01865  0.75131  0.94805]
21Feb13_054638| [-1.38934 -0.85679 -1.03067]
21Feb13_054638| [ 1.08457  0.92298 -1.79844]
21Feb13_054638| [ 1.45389 -0.34044 -0.13392]
21Feb13_054638| [ 0.63791 -0.99181  0.83168]
21Feb13_054638| [ 1.01793 -0.84685  0.50036]
21Feb13_054638| [-0.50065 -1.16125  0.03549]
21Feb13_054638| [-0.67174 -0.13235  0.05094]
21Feb13_054638| [-0.65057  0.27166 -0.33921]
21Feb13_054638| [ 1.04472 -0.02756 -0.87296]
21Feb13_054638| [ 0.10613  0.07959  0.42727]
21Feb13_054638| [ 0.07967  0.39679  1.02531]
21Feb13_054638| [ 1.82264 -0.32392 -2.71293]
21Feb13_054638| [ 1.83116 -0.68393 -1.06911]
21Feb13_054638| [-0.65866  0.55609  0.45198]
21Feb13_054638| [ 0.15390 -0.12530 -0.49443]
21Feb13_054638| [ 1.03811 -0.82233 -1.38641]
21Feb13_054638| [ 1.20222  0.67180  0.52163]
21Feb13_054638| [-0.58928  1.11110  0.79006]
21Feb13_054638| [ 0.87426  0.30426 -0.44848]
21Feb13_054638| [ 0.69579 -0.36500 -0.34569]
21Feb13_054638| [ 0.78584 -0.89277  0.94968]
21Feb13_054638| [ 1.11890  0.55386 -0.30582]
21Feb13_054638| [-0.30253  1.01131 -0.38667]
21Feb13_054638| [ 0.60845  0.73766  0.25496]
21Feb13_054638| [-0.70400 -0.39828 -0.29869]]
21Feb13_054638|-- Bias --
21Feb13_054638|[-0.92461  0.60117 -0.43775]
21Feb13_054638|Layer 1:
21Feb13_054638|-- Config --
21Feb13_054638|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_054638|-- Weights --
21Feb13_054638|[[-0.47251  1.36579]
21Feb13_054638| [-0.20704  0.40126]
21Feb13_054638| [-1.70310  1.22032]]
21Feb13_054638|-- Bias --
21Feb13_054638|[-0.67142  0.13605]
21Feb13_054638|Predicting the validation and test data with the Best final individual.
21Feb13_054645| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_054645|-----------  ------------------  --------------------  ----------
21Feb13_054645|Validation         41.39                  3             0.01805
21Feb13_054645|   Test            36.23                  3             0.01189
21Feb13_054645|-------------------- Test #3 --------------------
21Feb13_054645|Best final individual weights
21Feb13_054645|Individual:
21Feb13_054645|-- Constant hidden layers --
21Feb13_054645|False
21Feb13_054645|Layer 0:
21Feb13_054645|-- Config --
21Feb13_054645|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_054645|-- Weights --
21Feb13_054645|[[-0.58131  0.41104 -0.62368]
21Feb13_054645| [ 0.69656 -1.02993 -0.20603]
21Feb13_054645| [-1.86788  2.30608 -0.81731]
21Feb13_054645| [ 2.35696  1.24218 -0.92105]
21Feb13_054645| [-0.61245  1.01963 -0.41972]
21Feb13_054645| [-0.79454 -0.79620 -1.73701]
21Feb13_054645| [-1.13615 -0.38489 -0.82265]
21Feb13_054645| [-0.25325 -1.16213  0.70843]
21Feb13_054645| [ 0.83976  0.00993 -0.70265]
21Feb13_054645| [ 0.03684  0.08167 -0.17511]
21Feb13_054645| [ 0.57322 -0.08752  0.19502]
21Feb13_054645| [ 0.89737  1.16408 -0.22033]
21Feb13_054645| [ 0.44220  0.98258  1.32976]
21Feb13_054645| [ 0.14725 -0.31934 -0.22376]
21Feb13_054645| [-0.48317  1.49892 -0.58919]
21Feb13_054645| [-0.92600 -0.13766 -0.87815]
21Feb13_054645| [ 0.49251  0.54697  2.15955]
21Feb13_054645| [-1.54885  0.99749 -0.01751]
21Feb13_054645| [-0.25372 -1.31307  0.28582]
21Feb13_054645| [ 0.22894  0.35440  0.55132]
21Feb13_054645| [ 0.40985  0.84636 -0.09488]
21Feb13_054645| [ 0.25282  0.95784 -0.20253]
21Feb13_054645| [ 1.38163 -0.00593 -0.16853]
21Feb13_054645| [ 0.45233  1.00133  1.55658]
21Feb13_054645| [-0.04314 -0.28648 -0.91586]
21Feb13_054645| [ 0.52062 -1.41258  1.36297]
21Feb13_054645| [ 0.19469 -0.40620 -0.80653]
21Feb13_054645| [-0.92176  0.82471  0.88854]
21Feb13_054645| [ 0.08866 -0.43584  1.31285]
21Feb13_054645| [ 2.28433 -0.37639  1.71487]
21Feb13_054645| [-1.29992  0.11704  0.96791]
21Feb13_054645| [ 0.01865  0.75131  0.94805]
21Feb13_054645| [-1.38934 -0.85679 -1.03067]
21Feb13_054645| [ 1.08457  0.92298 -1.79844]
21Feb13_054645| [ 1.45389 -0.34044 -0.13392]
21Feb13_054645| [ 0.63791 -0.99181  0.83168]
21Feb13_054645| [ 1.01793 -0.84685  0.50036]
21Feb13_054645| [-0.50065 -1.16125  0.03549]
21Feb13_054645| [-0.67174 -0.13235  0.05094]
21Feb13_054645| [-0.65057  0.27166 -0.33921]
21Feb13_054645| [ 1.04472 -0.02756 -0.87296]
21Feb13_054645| [ 0.10613  0.07959  0.42727]
21Feb13_054645| [ 0.07967  0.39679  1.02531]
21Feb13_054645| [ 1.82264 -0.32392 -2.71293]
21Feb13_054645| [ 1.83116 -0.68393 -1.06911]
21Feb13_054645| [-0.65866  0.55609  0.45198]
21Feb13_054645| [ 0.15390 -0.12530 -0.49443]
21Feb13_054645| [ 1.03811 -0.82233 -1.38641]
21Feb13_054645| [ 1.20222  0.67180  0.52163]
21Feb13_054645| [-0.58928  1.11110  0.79006]
21Feb13_054645| [ 0.87426  0.30426 -0.44848]
21Feb13_054645| [ 0.69579 -0.36500 -0.34569]
21Feb13_054645| [ 0.78584 -0.89277  0.94968]
21Feb13_054645| [ 1.11890  0.55386 -0.30582]
21Feb13_054645| [-0.30253  1.01131 -0.38667]
21Feb13_054645| [ 0.60845  0.73766  0.25496]
21Feb13_054645| [-0.70400 -0.39828 -0.29869]]
21Feb13_054645|-- Bias --
21Feb13_054645|[-0.92461  0.60117 -0.43775]
21Feb13_054645|Layer 1:
21Feb13_054645|-- Config --
21Feb13_054645|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_054645|-- Weights --
21Feb13_054645|[[-0.47251  1.36579]
21Feb13_054645| [-0.20704  0.40126]
21Feb13_054645| [-1.70310  1.22032]]
21Feb13_054645|-- Bias --
21Feb13_054645|[-0.67142  0.13605]
21Feb13_054645|Predicting the validation and test data with the Best final individual.
21Feb13_054652| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_054652|-----------  ------------------  --------------------  ----------
21Feb13_054652|Validation         41.39                  3             0.01805
21Feb13_054652|   Test            36.32                  3             0.00892
21Feb13_054652|-------------------- Test #4 --------------------
21Feb13_054652|Best final individual weights
21Feb13_054652|Individual:
21Feb13_054652|-- Constant hidden layers --
21Feb13_054652|False
21Feb13_054652|Layer 0:
21Feb13_054652|-- Config --
21Feb13_054652|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_054652|-- Weights --
21Feb13_054652|[[-0.58131  0.41104 -0.62368]
21Feb13_054652| [ 0.69656 -1.02993 -0.20603]
21Feb13_054652| [-1.86788  2.30608 -0.81731]
21Feb13_054652| [ 2.35696  1.24218 -0.92105]
21Feb13_054652| [-0.61245  1.01963 -0.41972]
21Feb13_054652| [-0.79454 -0.79620 -1.73701]
21Feb13_054652| [-1.13615 -0.38489 -0.82265]
21Feb13_054652| [-0.25325 -1.16213  0.70843]
21Feb13_054652| [ 0.83976  0.00993 -0.70265]
21Feb13_054652| [ 0.03684  0.08167 -0.17511]
21Feb13_054652| [ 0.57322 -0.08752  0.19502]
21Feb13_054652| [ 0.89737  1.16408 -0.22033]
21Feb13_054652| [ 0.44220  0.98258  1.32976]
21Feb13_054652| [ 0.14725 -0.31934 -0.22376]
21Feb13_054652| [-0.48317  1.49892 -0.58919]
21Feb13_054652| [-0.92600 -0.13766 -0.87815]
21Feb13_054652| [ 0.49251  0.54697  2.15955]
21Feb13_054652| [-1.54885  0.99749 -0.01751]
21Feb13_054652| [-0.25372 -1.31307  0.28582]
21Feb13_054652| [ 0.22894  0.35440  0.55132]
21Feb13_054652| [ 0.40985  0.84636 -0.09488]
21Feb13_054652| [ 0.25282  0.95784 -0.20253]
21Feb13_054652| [ 1.38163 -0.00593 -0.16853]
21Feb13_054652| [ 0.45233  1.00133  1.55658]
21Feb13_054652| [-0.04314 -0.28648 -0.91586]
21Feb13_054652| [ 0.52062 -1.41258  1.36297]
21Feb13_054652| [ 0.19469 -0.40620 -0.80653]
21Feb13_054652| [-0.92176  0.82471  0.88854]
21Feb13_054652| [ 0.08866 -0.43584  1.31285]
21Feb13_054652| [ 2.28433 -0.37639  1.71487]
21Feb13_054652| [-1.29992  0.11704  0.96791]
21Feb13_054652| [ 0.01865  0.75131  0.94805]
21Feb13_054652| [-1.38934 -0.85679 -1.03067]
21Feb13_054652| [ 1.08457  0.92298 -1.79844]
21Feb13_054652| [ 1.45389 -0.34044 -0.13392]
21Feb13_054652| [ 0.63791 -0.99181  0.83168]
21Feb13_054652| [ 1.01793 -0.84685  0.50036]
21Feb13_054652| [-0.50065 -1.16125  0.03549]
21Feb13_054652| [-0.67174 -0.13235  0.05094]
21Feb13_054652| [-0.65057  0.27166 -0.33921]
21Feb13_054652| [ 1.04472 -0.02756 -0.87296]
21Feb13_054652| [ 0.10613  0.07959  0.42727]
21Feb13_054652| [ 0.07967  0.39679  1.02531]
21Feb13_054652| [ 1.82264 -0.32392 -2.71293]
21Feb13_054652| [ 1.83116 -0.68393 -1.06911]
21Feb13_054652| [-0.65866  0.55609  0.45198]
21Feb13_054652| [ 0.15390 -0.12530 -0.49443]
21Feb13_054652| [ 1.03811 -0.82233 -1.38641]
21Feb13_054652| [ 1.20222  0.67180  0.52163]
21Feb13_054652| [-0.58928  1.11110  0.79006]
21Feb13_054652| [ 0.87426  0.30426 -0.44848]
21Feb13_054652| [ 0.69579 -0.36500 -0.34569]
21Feb13_054652| [ 0.78584 -0.89277  0.94968]
21Feb13_054652| [ 1.11890  0.55386 -0.30582]
21Feb13_054652| [-0.30253  1.01131 -0.38667]
21Feb13_054652| [ 0.60845  0.73766  0.25496]
21Feb13_054652| [-0.70400 -0.39828 -0.29869]]
21Feb13_054652|-- Bias --
21Feb13_054652|[-0.92461  0.60117 -0.43775]
21Feb13_054652|Layer 1:
21Feb13_054652|-- Config --
21Feb13_054652|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_054652|-- Weights --
21Feb13_054652|[[-0.47251  1.36579]
21Feb13_054652| [-0.20704  0.40126]
21Feb13_054652| [-1.70310  1.22032]]
21Feb13_054652|-- Bias --
21Feb13_054652|[-0.67142  0.13605]
21Feb13_054652|Predicting the validation and test data with the Best final individual.
21Feb13_054659| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_054659|-----------  ------------------  --------------------  ----------
21Feb13_054659|Validation         41.39                  3             0.01805
21Feb13_054659|   Test            36.23                  3             0.01189
21Feb13_054659|-------------------- Test #5 --------------------
21Feb13_054659|Best final individual weights
21Feb13_054659|Individual:
21Feb13_054659|-- Constant hidden layers --
21Feb13_054659|False
21Feb13_054659|Layer 0:
21Feb13_054659|-- Config --
21Feb13_054659|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_054659|-- Weights --
21Feb13_054659|[[-0.58131  0.41104 -0.62368]
21Feb13_054659| [ 0.69656 -1.02993 -0.20603]
21Feb13_054659| [-1.86788  2.30608 -0.81731]
21Feb13_054659| [ 2.35696  1.24218 -0.92105]
21Feb13_054659| [-0.61245  1.01963 -0.41972]
21Feb13_054659| [-0.79454 -0.79620 -1.73701]
21Feb13_054659| [-1.13615 -0.38489 -0.82265]
21Feb13_054659| [-0.25325 -1.16213  0.70843]
21Feb13_054659| [ 0.83976  0.00993 -0.70265]
21Feb13_054659| [ 0.03684  0.08167 -0.17511]
21Feb13_054659| [ 0.57322 -0.08752  0.19502]
21Feb13_054659| [ 0.89737  1.16408 -0.22033]
21Feb13_054659| [ 0.44220  0.98258  1.32976]
21Feb13_054659| [ 0.14725 -0.31934 -0.22376]
21Feb13_054659| [-0.48317  1.49892 -0.58919]
21Feb13_054659| [-0.92600 -0.13766 -0.87815]
21Feb13_054659| [ 0.49251  0.54697  2.15955]
21Feb13_054659| [-1.54885  0.99749 -0.01751]
21Feb13_054659| [-0.25372 -1.31307  0.28582]
21Feb13_054659| [ 0.22894  0.35440  0.55132]
21Feb13_054659| [ 0.40985  0.84636 -0.09488]
21Feb13_054659| [ 0.25282  0.95784 -0.20253]
21Feb13_054659| [ 1.38163 -0.00593 -0.16853]
21Feb13_054659| [ 0.45233  1.00133  1.55658]
21Feb13_054659| [-0.04314 -0.28648 -0.91586]
21Feb13_054659| [ 0.52062 -1.41258  1.36297]
21Feb13_054659| [ 0.19469 -0.40620 -0.80653]
21Feb13_054659| [-0.92176  0.82471  0.88854]
21Feb13_054659| [ 0.08866 -0.43584  1.31285]
21Feb13_054659| [ 2.28433 -0.37639  1.71487]
21Feb13_054659| [-1.29992  0.11704  0.96791]
21Feb13_054659| [ 0.01865  0.75131  0.94805]
21Feb13_054659| [-1.38934 -0.85679 -1.03067]
21Feb13_054659| [ 1.08457  0.92298 -1.79844]
21Feb13_054659| [ 1.45389 -0.34044 -0.13392]
21Feb13_054659| [ 0.63791 -0.99181  0.83168]
21Feb13_054659| [ 1.01793 -0.84685  0.50036]
21Feb13_054659| [-0.50065 -1.16125  0.03549]
21Feb13_054659| [-0.67174 -0.13235  0.05094]
21Feb13_054659| [-0.65057  0.27166 -0.33921]
21Feb13_054659| [ 1.04472 -0.02756 -0.87296]
21Feb13_054659| [ 0.10613  0.07959  0.42727]
21Feb13_054659| [ 0.07967  0.39679  1.02531]
21Feb13_054659| [ 1.82264 -0.32392 -2.71293]
21Feb13_054659| [ 1.83116 -0.68393 -1.06911]
21Feb13_054659| [-0.65866  0.55609  0.45198]
21Feb13_054659| [ 0.15390 -0.12530 -0.49443]
21Feb13_054659| [ 1.03811 -0.82233 -1.38641]
21Feb13_054659| [ 1.20222  0.67180  0.52163]
21Feb13_054659| [-0.58928  1.11110  0.79006]
21Feb13_054659| [ 0.87426  0.30426 -0.44848]
21Feb13_054659| [ 0.69579 -0.36500 -0.34569]
21Feb13_054659| [ 0.78584 -0.89277  0.94968]
21Feb13_054659| [ 1.11890  0.55386 -0.30582]
21Feb13_054659| [-0.30253  1.01131 -0.38667]
21Feb13_054659| [ 0.60845  0.73766  0.25496]
21Feb13_054659| [-0.70400 -0.39828 -0.29869]]
21Feb13_054659|-- Bias --
21Feb13_054659|[-0.92461  0.60117 -0.43775]
21Feb13_054659|Layer 1:
21Feb13_054659|-- Config --
21Feb13_054659|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_054659|-- Weights --
21Feb13_054659|[[-0.47251  1.36579]
21Feb13_054659| [-0.20704  0.40126]
21Feb13_054659| [-1.70310  1.22032]]
21Feb13_054659|-- Bias --
21Feb13_054659|[-0.67142  0.13605]
21Feb13_054659|Predicting the validation and test data with the Best final individual.
21Feb13_054706| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_054706|-----------  ------------------  --------------------  ----------
21Feb13_054706|Validation         41.39                  3             0.01805
21Feb13_054706|   Test            36.23                  3             0.01189
21Feb13_054706|-------------------- Test #6 --------------------
21Feb13_054706|Best final individual weights
21Feb13_054706|Individual:
21Feb13_054706|-- Constant hidden layers --
21Feb13_054706|False
21Feb13_054706|Layer 0:
21Feb13_054706|-- Config --
21Feb13_054706|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_054706|-- Weights --
21Feb13_054706|[[-0.58131  0.41104 -0.62368]
21Feb13_054706| [ 0.69656 -1.02993 -0.20603]
21Feb13_054706| [-1.86788  2.30608 -0.81731]
21Feb13_054706| [ 2.35696  1.24218 -0.92105]
21Feb13_054706| [-0.61245  1.01963 -0.41972]
21Feb13_054706| [-0.79454 -0.79620 -1.73701]
21Feb13_054706| [-1.13615 -0.38489 -0.82265]
21Feb13_054706| [-0.25325 -1.16213  0.70843]
21Feb13_054706| [ 0.83976  0.00993 -0.70265]
21Feb13_054706| [ 0.03684  0.08167 -0.17511]
21Feb13_054706| [ 0.57322 -0.08752  0.19502]
21Feb13_054706| [ 0.89737  1.16408 -0.22033]
21Feb13_054706| [ 0.44220  0.98258  1.32976]
21Feb13_054706| [ 0.14725 -0.31934 -0.22376]
21Feb13_054706| [-0.48317  1.49892 -0.58919]
21Feb13_054706| [-0.92600 -0.13766 -0.87815]
21Feb13_054706| [ 0.49251  0.54697  2.15955]
21Feb13_054706| [-1.54885  0.99749 -0.01751]
21Feb13_054706| [-0.25372 -1.31307  0.28582]
21Feb13_054706| [ 0.22894  0.35440  0.55132]
21Feb13_054706| [ 0.40985  0.84636 -0.09488]
21Feb13_054706| [ 0.25282  0.95784 -0.20253]
21Feb13_054706| [ 1.38163 -0.00593 -0.16853]
21Feb13_054706| [ 0.45233  1.00133  1.55658]
21Feb13_054706| [-0.04314 -0.28648 -0.91586]
21Feb13_054706| [ 0.52062 -1.41258  1.36297]
21Feb13_054706| [ 0.19469 -0.40620 -0.80653]
21Feb13_054706| [-0.92176  0.82471  0.88854]
21Feb13_054706| [ 0.08866 -0.43584  1.31285]
21Feb13_054706| [ 2.28433 -0.37639  1.71487]
21Feb13_054706| [-1.29992  0.11704  0.96791]
21Feb13_054706| [ 0.01865  0.75131  0.94805]
21Feb13_054706| [-1.38934 -0.85679 -1.03067]
21Feb13_054706| [ 1.08457  0.92298 -1.79844]
21Feb13_054706| [ 1.45389 -0.34044 -0.13392]
21Feb13_054706| [ 0.63791 -0.99181  0.83168]
21Feb13_054706| [ 1.01793 -0.84685  0.50036]
21Feb13_054706| [-0.50065 -1.16125  0.03549]
21Feb13_054706| [-0.67174 -0.13235  0.05094]
21Feb13_054706| [-0.65057  0.27166 -0.33921]
21Feb13_054706| [ 1.04472 -0.02756 -0.87296]
21Feb13_054706| [ 0.10613  0.07959  0.42727]
21Feb13_054706| [ 0.07967  0.39679  1.02531]
21Feb13_054706| [ 1.82264 -0.32392 -2.71293]
21Feb13_054706| [ 1.83116 -0.68393 -1.06911]
21Feb13_054706| [-0.65866  0.55609  0.45198]
21Feb13_054706| [ 0.15390 -0.12530 -0.49443]
21Feb13_054706| [ 1.03811 -0.82233 -1.38641]
21Feb13_054706| [ 1.20222  0.67180  0.52163]
21Feb13_054706| [-0.58928  1.11110  0.79006]
21Feb13_054706| [ 0.87426  0.30426 -0.44848]
21Feb13_054706| [ 0.69579 -0.36500 -0.34569]
21Feb13_054706| [ 0.78584 -0.89277  0.94968]
21Feb13_054706| [ 1.11890  0.55386 -0.30582]
21Feb13_054706| [-0.30253  1.01131 -0.38667]
21Feb13_054706| [ 0.60845  0.73766  0.25496]
21Feb13_054706| [-0.70400 -0.39828 -0.29869]]
21Feb13_054706|-- Bias --
21Feb13_054706|[-0.92461  0.60117 -0.43775]
21Feb13_054706|Layer 1:
21Feb13_054706|-- Config --
21Feb13_054706|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_054706|-- Weights --
21Feb13_054706|[[-0.47251  1.36579]
21Feb13_054706| [-0.20704  0.40126]
21Feb13_054706| [-1.70310  1.22032]]
21Feb13_054706|-- Bias --
21Feb13_054706|[-0.67142  0.13605]
21Feb13_054706|Predicting the validation and test data with the Best final individual.
21Feb13_054713| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_054713|-----------  ------------------  --------------------  ----------
21Feb13_054713|Validation         41.30                  3             0.02062
21Feb13_054713|   Test            36.23                  3             0.01189
21Feb13_054713|-------------------- Test #7 --------------------
21Feb13_054713|Best final individual weights
21Feb13_054713|Individual:
21Feb13_054713|-- Constant hidden layers --
21Feb13_054713|False
21Feb13_054713|Layer 0:
21Feb13_054713|-- Config --
21Feb13_054713|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_054713|-- Weights --
21Feb13_054713|[[-0.58131  0.41104 -0.62368]
21Feb13_054713| [ 0.69656 -1.02993 -0.20603]
21Feb13_054713| [-1.86788  2.30608 -0.81731]
21Feb13_054713| [ 2.35696  1.24218 -0.92105]
21Feb13_054713| [-0.61245  1.01963 -0.41972]
21Feb13_054713| [-0.79454 -0.79620 -1.73701]
21Feb13_054713| [-1.13615 -0.38489 -0.82265]
21Feb13_054713| [-0.25325 -1.16213  0.70843]
21Feb13_054713| [ 0.83976  0.00993 -0.70265]
21Feb13_054713| [ 0.03684  0.08167 -0.17511]
21Feb13_054713| [ 0.57322 -0.08752  0.19502]
21Feb13_054713| [ 0.89737  1.16408 -0.22033]
21Feb13_054713| [ 0.44220  0.98258  1.32976]
21Feb13_054713| [ 0.14725 -0.31934 -0.22376]
21Feb13_054713| [-0.48317  1.49892 -0.58919]
21Feb13_054713| [-0.92600 -0.13766 -0.87815]
21Feb13_054713| [ 0.49251  0.54697  2.15955]
21Feb13_054713| [-1.54885  0.99749 -0.01751]
21Feb13_054713| [-0.25372 -1.31307  0.28582]
21Feb13_054713| [ 0.22894  0.35440  0.55132]
21Feb13_054713| [ 0.40985  0.84636 -0.09488]
21Feb13_054713| [ 0.25282  0.95784 -0.20253]
21Feb13_054713| [ 1.38163 -0.00593 -0.16853]
21Feb13_054713| [ 0.45233  1.00133  1.55658]
21Feb13_054713| [-0.04314 -0.28648 -0.91586]
21Feb13_054713| [ 0.52062 -1.41258  1.36297]
21Feb13_054713| [ 0.19469 -0.40620 -0.80653]
21Feb13_054713| [-0.92176  0.82471  0.88854]
21Feb13_054713| [ 0.08866 -0.43584  1.31285]
21Feb13_054713| [ 2.28433 -0.37639  1.71487]
21Feb13_054713| [-1.29992  0.11704  0.96791]
21Feb13_054713| [ 0.01865  0.75131  0.94805]
21Feb13_054713| [-1.38934 -0.85679 -1.03067]
21Feb13_054713| [ 1.08457  0.92298 -1.79844]
21Feb13_054713| [ 1.45389 -0.34044 -0.13392]
21Feb13_054713| [ 0.63791 -0.99181  0.83168]
21Feb13_054713| [ 1.01793 -0.84685  0.50036]
21Feb13_054713| [-0.50065 -1.16125  0.03549]
21Feb13_054713| [-0.67174 -0.13235  0.05094]
21Feb13_054713| [-0.65057  0.27166 -0.33921]
21Feb13_054713| [ 1.04472 -0.02756 -0.87296]
21Feb13_054713| [ 0.10613  0.07959  0.42727]
21Feb13_054713| [ 0.07967  0.39679  1.02531]
21Feb13_054713| [ 1.82264 -0.32392 -2.71293]
21Feb13_054713| [ 1.83116 -0.68393 -1.06911]
21Feb13_054713| [-0.65866  0.55609  0.45198]
21Feb13_054713| [ 0.15390 -0.12530 -0.49443]
21Feb13_054713| [ 1.03811 -0.82233 -1.38641]
21Feb13_054713| [ 1.20222  0.67180  0.52163]
21Feb13_054713| [-0.58928  1.11110  0.79006]
21Feb13_054713| [ 0.87426  0.30426 -0.44848]
21Feb13_054713| [ 0.69579 -0.36500 -0.34569]
21Feb13_054713| [ 0.78584 -0.89277  0.94968]
21Feb13_054713| [ 1.11890  0.55386 -0.30582]
21Feb13_054713| [-0.30253  1.01131 -0.38667]
21Feb13_054713| [ 0.60845  0.73766  0.25496]
21Feb13_054713| [-0.70400 -0.39828 -0.29869]]
21Feb13_054713|-- Bias --
21Feb13_054713|[-0.92461  0.60117 -0.43775]
21Feb13_054713|Layer 1:
21Feb13_054713|-- Config --
21Feb13_054713|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_054713|-- Weights --
21Feb13_054713|[[-0.47251  1.36579]
21Feb13_054713| [-0.20704  0.40126]
21Feb13_054713| [-1.70310  1.22032]]
21Feb13_054713|-- Bias --
21Feb13_054713|[-0.67142  0.13605]
21Feb13_054713|Predicting the validation and test data with the Best final individual.
21Feb13_054720| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_054720|-----------  ------------------  --------------------  ----------
21Feb13_054720|Validation         41.30                  3             0.02062
21Feb13_054720|   Test            36.32                  3             0.00892
21Feb13_054720|-------------------- Test #8 --------------------
21Feb13_054720|Best final individual weights
21Feb13_054720|Individual:
21Feb13_054720|-- Constant hidden layers --
21Feb13_054720|False
21Feb13_054720|Layer 0:
21Feb13_054720|-- Config --
21Feb13_054720|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_054720|-- Weights --
21Feb13_054720|[[-0.58131  0.41104 -0.62368]
21Feb13_054720| [ 0.69656 -1.02993 -0.20603]
21Feb13_054720| [-1.86788  2.30608 -0.81731]
21Feb13_054720| [ 2.35696  1.24218 -0.92105]
21Feb13_054720| [-0.61245  1.01963 -0.41972]
21Feb13_054720| [-0.79454 -0.79620 -1.73701]
21Feb13_054720| [-1.13615 -0.38489 -0.82265]
21Feb13_054720| [-0.25325 -1.16213  0.70843]
21Feb13_054720| [ 0.83976  0.00993 -0.70265]
21Feb13_054720| [ 0.03684  0.08167 -0.17511]
21Feb13_054720| [ 0.57322 -0.08752  0.19502]
21Feb13_054720| [ 0.89737  1.16408 -0.22033]
21Feb13_054720| [ 0.44220  0.98258  1.32976]
21Feb13_054720| [ 0.14725 -0.31934 -0.22376]
21Feb13_054720| [-0.48317  1.49892 -0.58919]
21Feb13_054720| [-0.92600 -0.13766 -0.87815]
21Feb13_054720| [ 0.49251  0.54697  2.15955]
21Feb13_054720| [-1.54885  0.99749 -0.01751]
21Feb13_054720| [-0.25372 -1.31307  0.28582]
21Feb13_054720| [ 0.22894  0.35440  0.55132]
21Feb13_054720| [ 0.40985  0.84636 -0.09488]
21Feb13_054720| [ 0.25282  0.95784 -0.20253]
21Feb13_054720| [ 1.38163 -0.00593 -0.16853]
21Feb13_054720| [ 0.45233  1.00133  1.55658]
21Feb13_054720| [-0.04314 -0.28648 -0.91586]
21Feb13_054720| [ 0.52062 -1.41258  1.36297]
21Feb13_054720| [ 0.19469 -0.40620 -0.80653]
21Feb13_054720| [-0.92176  0.82471  0.88854]
21Feb13_054720| [ 0.08866 -0.43584  1.31285]
21Feb13_054720| [ 2.28433 -0.37639  1.71487]
21Feb13_054720| [-1.29992  0.11704  0.96791]
21Feb13_054720| [ 0.01865  0.75131  0.94805]
21Feb13_054720| [-1.38934 -0.85679 -1.03067]
21Feb13_054720| [ 1.08457  0.92298 -1.79844]
21Feb13_054720| [ 1.45389 -0.34044 -0.13392]
21Feb13_054720| [ 0.63791 -0.99181  0.83168]
21Feb13_054720| [ 1.01793 -0.84685  0.50036]
21Feb13_054720| [-0.50065 -1.16125  0.03549]
21Feb13_054720| [-0.67174 -0.13235  0.05094]
21Feb13_054720| [-0.65057  0.27166 -0.33921]
21Feb13_054720| [ 1.04472 -0.02756 -0.87296]
21Feb13_054720| [ 0.10613  0.07959  0.42727]
21Feb13_054720| [ 0.07967  0.39679  1.02531]
21Feb13_054720| [ 1.82264 -0.32392 -2.71293]
21Feb13_054720| [ 1.83116 -0.68393 -1.06911]
21Feb13_054720| [-0.65866  0.55609  0.45198]
21Feb13_054720| [ 0.15390 -0.12530 -0.49443]
21Feb13_054720| [ 1.03811 -0.82233 -1.38641]
21Feb13_054720| [ 1.20222  0.67180  0.52163]
21Feb13_054720| [-0.58928  1.11110  0.79006]
21Feb13_054720| [ 0.87426  0.30426 -0.44848]
21Feb13_054720| [ 0.69579 -0.36500 -0.34569]
21Feb13_054720| [ 0.78584 -0.89277  0.94968]
21Feb13_054720| [ 1.11890  0.55386 -0.30582]
21Feb13_054720| [-0.30253  1.01131 -0.38667]
21Feb13_054720| [ 0.60845  0.73766  0.25496]
21Feb13_054720| [-0.70400 -0.39828 -0.29869]]
21Feb13_054720|-- Bias --
21Feb13_054720|[-0.92461  0.60117 -0.43775]
21Feb13_054720|Layer 1:
21Feb13_054720|-- Config --
21Feb13_054720|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_054720|-- Weights --
21Feb13_054720|[[-0.47251  1.36579]
21Feb13_054720| [-0.20704  0.40126]
21Feb13_054720| [-1.70310  1.22032]]
21Feb13_054720|-- Bias --
21Feb13_054720|[-0.67142  0.13605]
21Feb13_054720|Predicting the validation and test data with the Best final individual.
21Feb13_054727| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_054727|-----------  ------------------  --------------------  ----------
21Feb13_054727|Validation         41.39                  3             0.01805
21Feb13_054727|   Test            36.32                  3             0.00892
21Feb13_054727|-------------------- Test #9 --------------------
21Feb13_054727|Best final individual weights
21Feb13_054727|Individual:
21Feb13_054727|-- Constant hidden layers --
21Feb13_054727|False
21Feb13_054727|Layer 0:
21Feb13_054727|-- Config --
21Feb13_054727|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_054727|-- Weights --
21Feb13_054727|[[-0.58131  0.41104 -0.62368]
21Feb13_054727| [ 0.69656 -1.02993 -0.20603]
21Feb13_054727| [-1.86788  2.30608 -0.81731]
21Feb13_054727| [ 2.35696  1.24218 -0.92105]
21Feb13_054727| [-0.61245  1.01963 -0.41972]
21Feb13_054727| [-0.79454 -0.79620 -1.73701]
21Feb13_054727| [-1.13615 -0.38489 -0.82265]
21Feb13_054727| [-0.25325 -1.16213  0.70843]
21Feb13_054727| [ 0.83976  0.00993 -0.70265]
21Feb13_054727| [ 0.03684  0.08167 -0.17511]
21Feb13_054727| [ 0.57322 -0.08752  0.19502]
21Feb13_054727| [ 0.89737  1.16408 -0.22033]
21Feb13_054727| [ 0.44220  0.98258  1.32976]
21Feb13_054727| [ 0.14725 -0.31934 -0.22376]
21Feb13_054727| [-0.48317  1.49892 -0.58919]
21Feb13_054727| [-0.92600 -0.13766 -0.87815]
21Feb13_054727| [ 0.49251  0.54697  2.15955]
21Feb13_054727| [-1.54885  0.99749 -0.01751]
21Feb13_054727| [-0.25372 -1.31307  0.28582]
21Feb13_054727| [ 0.22894  0.35440  0.55132]
21Feb13_054727| [ 0.40985  0.84636 -0.09488]
21Feb13_054727| [ 0.25282  0.95784 -0.20253]
21Feb13_054727| [ 1.38163 -0.00593 -0.16853]
21Feb13_054727| [ 0.45233  1.00133  1.55658]
21Feb13_054727| [-0.04314 -0.28648 -0.91586]
21Feb13_054727| [ 0.52062 -1.41258  1.36297]
21Feb13_054727| [ 0.19469 -0.40620 -0.80653]
21Feb13_054727| [-0.92176  0.82471  0.88854]
21Feb13_054727| [ 0.08866 -0.43584  1.31285]
21Feb13_054727| [ 2.28433 -0.37639  1.71487]
21Feb13_054727| [-1.29992  0.11704  0.96791]
21Feb13_054727| [ 0.01865  0.75131  0.94805]
21Feb13_054727| [-1.38934 -0.85679 -1.03067]
21Feb13_054727| [ 1.08457  0.92298 -1.79844]
21Feb13_054727| [ 1.45389 -0.34044 -0.13392]
21Feb13_054727| [ 0.63791 -0.99181  0.83168]
21Feb13_054727| [ 1.01793 -0.84685  0.50036]
21Feb13_054727| [-0.50065 -1.16125  0.03549]
21Feb13_054727| [-0.67174 -0.13235  0.05094]
21Feb13_054727| [-0.65057  0.27166 -0.33921]
21Feb13_054727| [ 1.04472 -0.02756 -0.87296]
21Feb13_054727| [ 0.10613  0.07959  0.42727]
21Feb13_054727| [ 0.07967  0.39679  1.02531]
21Feb13_054727| [ 1.82264 -0.32392 -2.71293]
21Feb13_054727| [ 1.83116 -0.68393 -1.06911]
21Feb13_054727| [-0.65866  0.55609  0.45198]
21Feb13_054727| [ 0.15390 -0.12530 -0.49443]
21Feb13_054727| [ 1.03811 -0.82233 -1.38641]
21Feb13_054727| [ 1.20222  0.67180  0.52163]
21Feb13_054727| [-0.58928  1.11110  0.79006]
21Feb13_054727| [ 0.87426  0.30426 -0.44848]
21Feb13_054727| [ 0.69579 -0.36500 -0.34569]
21Feb13_054727| [ 0.78584 -0.89277  0.94968]
21Feb13_054727| [ 1.11890  0.55386 -0.30582]
21Feb13_054727| [-0.30253  1.01131 -0.38667]
21Feb13_054727| [ 0.60845  0.73766  0.25496]
21Feb13_054727| [-0.70400 -0.39828 -0.29869]]
21Feb13_054727|-- Bias --
21Feb13_054727|[-0.92461  0.60117 -0.43775]
21Feb13_054727|Layer 1:
21Feb13_054727|-- Config --
21Feb13_054727|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_054727|-- Weights --
21Feb13_054727|[[-0.47251  1.36579]
21Feb13_054727| [-0.20704  0.40126]
21Feb13_054727| [-1.70310  1.22032]]
21Feb13_054727|-- Bias --
21Feb13_054727|[-0.67142  0.13605]
21Feb13_054727|Predicting the validation and test data with the Best final individual.
21Feb13_054734| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_054734|-----------  ------------------  --------------------  ----------
21Feb13_054734|Validation         41.39                  3             0.01805
21Feb13_054734|   Test            36.23                  3             0.01189
21Feb13_054734|-------------------- Test #10 --------------------
21Feb13_054734|Best final individual weights
21Feb13_054734|Individual:
21Feb13_054734|-- Constant hidden layers --
21Feb13_054734|False
21Feb13_054734|Layer 0:
21Feb13_054734|-- Config --
21Feb13_054734|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_054734|-- Weights --
21Feb13_054734|[[-0.58131  0.41104 -0.62368]
21Feb13_054734| [ 0.69656 -1.02993 -0.20603]
21Feb13_054734| [-1.86788  2.30608 -0.81731]
21Feb13_054734| [ 2.35696  1.24218 -0.92105]
21Feb13_054734| [-0.61245  1.01963 -0.41972]
21Feb13_054734| [-0.79454 -0.79620 -1.73701]
21Feb13_054734| [-1.13615 -0.38489 -0.82265]
21Feb13_054734| [-0.25325 -1.16213  0.70843]
21Feb13_054734| [ 0.83976  0.00993 -0.70265]
21Feb13_054734| [ 0.03684  0.08167 -0.17511]
21Feb13_054734| [ 0.57322 -0.08752  0.19502]
21Feb13_054734| [ 0.89737  1.16408 -0.22033]
21Feb13_054734| [ 0.44220  0.98258  1.32976]
21Feb13_054734| [ 0.14725 -0.31934 -0.22376]
21Feb13_054734| [-0.48317  1.49892 -0.58919]
21Feb13_054734| [-0.92600 -0.13766 -0.87815]
21Feb13_054734| [ 0.49251  0.54697  2.15955]
21Feb13_054734| [-1.54885  0.99749 -0.01751]
21Feb13_054734| [-0.25372 -1.31307  0.28582]
21Feb13_054734| [ 0.22894  0.35440  0.55132]
21Feb13_054734| [ 0.40985  0.84636 -0.09488]
21Feb13_054734| [ 0.25282  0.95784 -0.20253]
21Feb13_054734| [ 1.38163 -0.00593 -0.16853]
21Feb13_054734| [ 0.45233  1.00133  1.55658]
21Feb13_054734| [-0.04314 -0.28648 -0.91586]
21Feb13_054734| [ 0.52062 -1.41258  1.36297]
21Feb13_054734| [ 0.19469 -0.40620 -0.80653]
21Feb13_054734| [-0.92176  0.82471  0.88854]
21Feb13_054734| [ 0.08866 -0.43584  1.31285]
21Feb13_054734| [ 2.28433 -0.37639  1.71487]
21Feb13_054734| [-1.29992  0.11704  0.96791]
21Feb13_054734| [ 0.01865  0.75131  0.94805]
21Feb13_054734| [-1.38934 -0.85679 -1.03067]
21Feb13_054734| [ 1.08457  0.92298 -1.79844]
21Feb13_054734| [ 1.45389 -0.34044 -0.13392]
21Feb13_054734| [ 0.63791 -0.99181  0.83168]
21Feb13_054734| [ 1.01793 -0.84685  0.50036]
21Feb13_054734| [-0.50065 -1.16125  0.03549]
21Feb13_054734| [-0.67174 -0.13235  0.05094]
21Feb13_054734| [-0.65057  0.27166 -0.33921]
21Feb13_054734| [ 1.04472 -0.02756 -0.87296]
21Feb13_054734| [ 0.10613  0.07959  0.42727]
21Feb13_054734| [ 0.07967  0.39679  1.02531]
21Feb13_054734| [ 1.82264 -0.32392 -2.71293]
21Feb13_054734| [ 1.83116 -0.68393 -1.06911]
21Feb13_054734| [-0.65866  0.55609  0.45198]
21Feb13_054734| [ 0.15390 -0.12530 -0.49443]
21Feb13_054734| [ 1.03811 -0.82233 -1.38641]
21Feb13_054734| [ 1.20222  0.67180  0.52163]
21Feb13_054734| [-0.58928  1.11110  0.79006]
21Feb13_054734| [ 0.87426  0.30426 -0.44848]
21Feb13_054734| [ 0.69579 -0.36500 -0.34569]
21Feb13_054734| [ 0.78584 -0.89277  0.94968]
21Feb13_054734| [ 1.11890  0.55386 -0.30582]
21Feb13_054734| [-0.30253  1.01131 -0.38667]
21Feb13_054734| [ 0.60845  0.73766  0.25496]
21Feb13_054734| [-0.70400 -0.39828 -0.29869]]
21Feb13_054734|-- Bias --
21Feb13_054734|[-0.92461  0.60117 -0.43775]
21Feb13_054734|Layer 1:
21Feb13_054734|-- Config --
21Feb13_054734|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_054734|-- Weights --
21Feb13_054734|[[-0.47251  1.36579]
21Feb13_054734| [-0.20704  0.40126]
21Feb13_054734| [-1.70310  1.22032]]
21Feb13_054734|-- Bias --
21Feb13_054734|[-0.67142  0.13605]
21Feb13_054734|Predicting the validation and test data with the Best final individual.
21Feb13_054741| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_054741|-----------  ------------------  --------------------  ----------
21Feb13_054741|Validation         41.39                  3             0.01805
21Feb13_054741|   Test            36.32                  3             0.00892
21Feb13_054741|-------------------- Test #11 --------------------
21Feb13_054741|Best final individual weights
21Feb13_054741|Individual:
21Feb13_054741|-- Constant hidden layers --
21Feb13_054741|False
21Feb13_054741|Layer 0:
21Feb13_054741|-- Config --
21Feb13_054741|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_054741|-- Weights --
21Feb13_054741|[[-0.58131  0.41104 -0.62368]
21Feb13_054741| [ 0.69656 -1.02993 -0.20603]
21Feb13_054741| [-1.86788  2.30608 -0.81731]
21Feb13_054741| [ 2.35696  1.24218 -0.92105]
21Feb13_054741| [-0.61245  1.01963 -0.41972]
21Feb13_054741| [-0.79454 -0.79620 -1.73701]
21Feb13_054741| [-1.13615 -0.38489 -0.82265]
21Feb13_054741| [-0.25325 -1.16213  0.70843]
21Feb13_054741| [ 0.83976  0.00993 -0.70265]
21Feb13_054741| [ 0.03684  0.08167 -0.17511]
21Feb13_054741| [ 0.57322 -0.08752  0.19502]
21Feb13_054741| [ 0.89737  1.16408 -0.22033]
21Feb13_054741| [ 0.44220  0.98258  1.32976]
21Feb13_054741| [ 0.14725 -0.31934 -0.22376]
21Feb13_054741| [-0.48317  1.49892 -0.58919]
21Feb13_054741| [-0.92600 -0.13766 -0.87815]
21Feb13_054741| [ 0.49251  0.54697  2.15955]
21Feb13_054741| [-1.54885  0.99749 -0.01751]
21Feb13_054741| [-0.25372 -1.31307  0.28582]
21Feb13_054741| [ 0.22894  0.35440  0.55132]
21Feb13_054741| [ 0.40985  0.84636 -0.09488]
21Feb13_054741| [ 0.25282  0.95784 -0.20253]
21Feb13_054741| [ 1.38163 -0.00593 -0.16853]
21Feb13_054741| [ 0.45233  1.00133  1.55658]
21Feb13_054741| [-0.04314 -0.28648 -0.91586]
21Feb13_054741| [ 0.52062 -1.41258  1.36297]
21Feb13_054741| [ 0.19469 -0.40620 -0.80653]
21Feb13_054741| [-0.92176  0.82471  0.88854]
21Feb13_054741| [ 0.08866 -0.43584  1.31285]
21Feb13_054741| [ 2.28433 -0.37639  1.71487]
21Feb13_054741| [-1.29992  0.11704  0.96791]
21Feb13_054741| [ 0.01865  0.75131  0.94805]
21Feb13_054741| [-1.38934 -0.85679 -1.03067]
21Feb13_054741| [ 1.08457  0.92298 -1.79844]
21Feb13_054741| [ 1.45389 -0.34044 -0.13392]
21Feb13_054741| [ 0.63791 -0.99181  0.83168]
21Feb13_054741| [ 1.01793 -0.84685  0.50036]
21Feb13_054741| [-0.50065 -1.16125  0.03549]
21Feb13_054741| [-0.67174 -0.13235  0.05094]
21Feb13_054741| [-0.65057  0.27166 -0.33921]
21Feb13_054741| [ 1.04472 -0.02756 -0.87296]
21Feb13_054741| [ 0.10613  0.07959  0.42727]
21Feb13_054741| [ 0.07967  0.39679  1.02531]
21Feb13_054741| [ 1.82264 -0.32392 -2.71293]
21Feb13_054741| [ 1.83116 -0.68393 -1.06911]
21Feb13_054741| [-0.65866  0.55609  0.45198]
21Feb13_054741| [ 0.15390 -0.12530 -0.49443]
21Feb13_054741| [ 1.03811 -0.82233 -1.38641]
21Feb13_054741| [ 1.20222  0.67180  0.52163]
21Feb13_054741| [-0.58928  1.11110  0.79006]
21Feb13_054741| [ 0.87426  0.30426 -0.44848]
21Feb13_054741| [ 0.69579 -0.36500 -0.34569]
21Feb13_054741| [ 0.78584 -0.89277  0.94968]
21Feb13_054741| [ 1.11890  0.55386 -0.30582]
21Feb13_054741| [-0.30253  1.01131 -0.38667]
21Feb13_054741| [ 0.60845  0.73766  0.25496]
21Feb13_054741| [-0.70400 -0.39828 -0.29869]]
21Feb13_054741|-- Bias --
21Feb13_054741|[-0.92461  0.60117 -0.43775]
21Feb13_054741|Layer 1:
21Feb13_054741|-- Config --
21Feb13_054741|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_054741|-- Weights --
21Feb13_054741|[[-0.47251  1.36579]
21Feb13_054741| [-0.20704  0.40126]
21Feb13_054741| [-1.70310  1.22032]]
21Feb13_054741|-- Bias --
21Feb13_054741|[-0.67142  0.13605]
21Feb13_054741|Predicting the validation and test data with the Best final individual.
21Feb13_054748| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_054748|-----------  ------------------  --------------------  ----------
21Feb13_054748|Validation         41.30                  3             0.02062
21Feb13_054748|   Test            36.32                  3             0.00892
21Feb13_054748|-------------------- Test #12 --------------------
21Feb13_054748|Best final individual weights
21Feb13_054748|Individual:
21Feb13_054748|-- Constant hidden layers --
21Feb13_054748|False
21Feb13_054748|Layer 0:
21Feb13_054748|-- Config --
21Feb13_054748|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_054748|-- Weights --
21Feb13_054748|[[-0.58131  0.41104 -0.62368]
21Feb13_054748| [ 0.69656 -1.02993 -0.20603]
21Feb13_054748| [-1.86788  2.30608 -0.81731]
21Feb13_054748| [ 2.35696  1.24218 -0.92105]
21Feb13_054748| [-0.61245  1.01963 -0.41972]
21Feb13_054748| [-0.79454 -0.79620 -1.73701]
21Feb13_054748| [-1.13615 -0.38489 -0.82265]
21Feb13_054748| [-0.25325 -1.16213  0.70843]
21Feb13_054748| [ 0.83976  0.00993 -0.70265]
21Feb13_054748| [ 0.03684  0.08167 -0.17511]
21Feb13_054748| [ 0.57322 -0.08752  0.19502]
21Feb13_054748| [ 0.89737  1.16408 -0.22033]
21Feb13_054748| [ 0.44220  0.98258  1.32976]
21Feb13_054748| [ 0.14725 -0.31934 -0.22376]
21Feb13_054748| [-0.48317  1.49892 -0.58919]
21Feb13_054748| [-0.92600 -0.13766 -0.87815]
21Feb13_054748| [ 0.49251  0.54697  2.15955]
21Feb13_054748| [-1.54885  0.99749 -0.01751]
21Feb13_054748| [-0.25372 -1.31307  0.28582]
21Feb13_054748| [ 0.22894  0.35440  0.55132]
21Feb13_054748| [ 0.40985  0.84636 -0.09488]
21Feb13_054748| [ 0.25282  0.95784 -0.20253]
21Feb13_054748| [ 1.38163 -0.00593 -0.16853]
21Feb13_054748| [ 0.45233  1.00133  1.55658]
21Feb13_054748| [-0.04314 -0.28648 -0.91586]
21Feb13_054748| [ 0.52062 -1.41258  1.36297]
21Feb13_054748| [ 0.19469 -0.40620 -0.80653]
21Feb13_054748| [-0.92176  0.82471  0.88854]
21Feb13_054748| [ 0.08866 -0.43584  1.31285]
21Feb13_054748| [ 2.28433 -0.37639  1.71487]
21Feb13_054748| [-1.29992  0.11704  0.96791]
21Feb13_054748| [ 0.01865  0.75131  0.94805]
21Feb13_054748| [-1.38934 -0.85679 -1.03067]
21Feb13_054748| [ 1.08457  0.92298 -1.79844]
21Feb13_054748| [ 1.45389 -0.34044 -0.13392]
21Feb13_054748| [ 0.63791 -0.99181  0.83168]
21Feb13_054748| [ 1.01793 -0.84685  0.50036]
21Feb13_054748| [-0.50065 -1.16125  0.03549]
21Feb13_054748| [-0.67174 -0.13235  0.05094]
21Feb13_054748| [-0.65057  0.27166 -0.33921]
21Feb13_054748| [ 1.04472 -0.02756 -0.87296]
21Feb13_054748| [ 0.10613  0.07959  0.42727]
21Feb13_054748| [ 0.07967  0.39679  1.02531]
21Feb13_054748| [ 1.82264 -0.32392 -2.71293]
21Feb13_054748| [ 1.83116 -0.68393 -1.06911]
21Feb13_054748| [-0.65866  0.55609  0.45198]
21Feb13_054748| [ 0.15390 -0.12530 -0.49443]
21Feb13_054748| [ 1.03811 -0.82233 -1.38641]
21Feb13_054748| [ 1.20222  0.67180  0.52163]
21Feb13_054748| [-0.58928  1.11110  0.79006]
21Feb13_054748| [ 0.87426  0.30426 -0.44848]
21Feb13_054748| [ 0.69579 -0.36500 -0.34569]
21Feb13_054748| [ 0.78584 -0.89277  0.94968]
21Feb13_054748| [ 1.11890  0.55386 -0.30582]
21Feb13_054748| [-0.30253  1.01131 -0.38667]
21Feb13_054748| [ 0.60845  0.73766  0.25496]
21Feb13_054748| [-0.70400 -0.39828 -0.29869]]
21Feb13_054748|-- Bias --
21Feb13_054748|[-0.92461  0.60117 -0.43775]
21Feb13_054748|Layer 1:
21Feb13_054748|-- Config --
21Feb13_054748|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_054748|-- Weights --
21Feb13_054748|[[-0.47251  1.36579]
21Feb13_054748| [-0.20704  0.40126]
21Feb13_054748| [-1.70310  1.22032]]
21Feb13_054748|-- Bias --
21Feb13_054748|[-0.67142  0.13605]
21Feb13_054748|Predicting the validation and test data with the Best final individual.
21Feb13_054755| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_054755|-----------  ------------------  --------------------  ----------
21Feb13_054755|Validation         41.30                  3             0.02062
21Feb13_054755|   Test            36.23                  3             0.01189
21Feb13_054755|-------------------- Test #13 --------------------
21Feb13_054755|Best final individual weights
21Feb13_054755|Individual:
21Feb13_054755|-- Constant hidden layers --
21Feb13_054755|False
21Feb13_054755|Layer 0:
21Feb13_054755|-- Config --
21Feb13_054755|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_054755|-- Weights --
21Feb13_054755|[[-0.58131  0.41104 -0.62368]
21Feb13_054755| [ 0.69656 -1.02993 -0.20603]
21Feb13_054755| [-1.86788  2.30608 -0.81731]
21Feb13_054755| [ 2.35696  1.24218 -0.92105]
21Feb13_054755| [-0.61245  1.01963 -0.41972]
21Feb13_054755| [-0.79454 -0.79620 -1.73701]
21Feb13_054755| [-1.13615 -0.38489 -0.82265]
21Feb13_054755| [-0.25325 -1.16213  0.70843]
21Feb13_054755| [ 0.83976  0.00993 -0.70265]
21Feb13_054755| [ 0.03684  0.08167 -0.17511]
21Feb13_054755| [ 0.57322 -0.08752  0.19502]
21Feb13_054755| [ 0.89737  1.16408 -0.22033]
21Feb13_054755| [ 0.44220  0.98258  1.32976]
21Feb13_054755| [ 0.14725 -0.31934 -0.22376]
21Feb13_054755| [-0.48317  1.49892 -0.58919]
21Feb13_054755| [-0.92600 -0.13766 -0.87815]
21Feb13_054755| [ 0.49251  0.54697  2.15955]
21Feb13_054755| [-1.54885  0.99749 -0.01751]
21Feb13_054755| [-0.25372 -1.31307  0.28582]
21Feb13_054755| [ 0.22894  0.35440  0.55132]
21Feb13_054755| [ 0.40985  0.84636 -0.09488]
21Feb13_054755| [ 0.25282  0.95784 -0.20253]
21Feb13_054755| [ 1.38163 -0.00593 -0.16853]
21Feb13_054755| [ 0.45233  1.00133  1.55658]
21Feb13_054755| [-0.04314 -0.28648 -0.91586]
21Feb13_054755| [ 0.52062 -1.41258  1.36297]
21Feb13_054755| [ 0.19469 -0.40620 -0.80653]
21Feb13_054755| [-0.92176  0.82471  0.88854]
21Feb13_054755| [ 0.08866 -0.43584  1.31285]
21Feb13_054755| [ 2.28433 -0.37639  1.71487]
21Feb13_054755| [-1.29992  0.11704  0.96791]
21Feb13_054755| [ 0.01865  0.75131  0.94805]
21Feb13_054755| [-1.38934 -0.85679 -1.03067]
21Feb13_054755| [ 1.08457  0.92298 -1.79844]
21Feb13_054755| [ 1.45389 -0.34044 -0.13392]
21Feb13_054755| [ 0.63791 -0.99181  0.83168]
21Feb13_054755| [ 1.01793 -0.84685  0.50036]
21Feb13_054755| [-0.50065 -1.16125  0.03549]
21Feb13_054755| [-0.67174 -0.13235  0.05094]
21Feb13_054755| [-0.65057  0.27166 -0.33921]
21Feb13_054755| [ 1.04472 -0.02756 -0.87296]
21Feb13_054755| [ 0.10613  0.07959  0.42727]
21Feb13_054755| [ 0.07967  0.39679  1.02531]
21Feb13_054755| [ 1.82264 -0.32392 -2.71293]
21Feb13_054755| [ 1.83116 -0.68393 -1.06911]
21Feb13_054755| [-0.65866  0.55609  0.45198]
21Feb13_054755| [ 0.15390 -0.12530 -0.49443]
21Feb13_054755| [ 1.03811 -0.82233 -1.38641]
21Feb13_054755| [ 1.20222  0.67180  0.52163]
21Feb13_054755| [-0.58928  1.11110  0.79006]
21Feb13_054755| [ 0.87426  0.30426 -0.44848]
21Feb13_054755| [ 0.69579 -0.36500 -0.34569]
21Feb13_054755| [ 0.78584 -0.89277  0.94968]
21Feb13_054755| [ 1.11890  0.55386 -0.30582]
21Feb13_054755| [-0.30253  1.01131 -0.38667]
21Feb13_054755| [ 0.60845  0.73766  0.25496]
21Feb13_054755| [-0.70400 -0.39828 -0.29869]]
21Feb13_054755|-- Bias --
21Feb13_054755|[-0.92461  0.60117 -0.43775]
21Feb13_054755|Layer 1:
21Feb13_054755|-- Config --
21Feb13_054755|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_054755|-- Weights --
21Feb13_054755|[[-0.47251  1.36579]
21Feb13_054755| [-0.20704  0.40126]
21Feb13_054755| [-1.70310  1.22032]]
21Feb13_054755|-- Bias --
21Feb13_054755|[-0.67142  0.13605]
21Feb13_054755|Predicting the validation and test data with the Best final individual.
21Feb13_054802| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_054802|-----------  ------------------  --------------------  ----------
21Feb13_054802|Validation         41.39                  3             0.01805
21Feb13_054802|   Test            36.32                  3             0.00892
21Feb13_054802|-------------------- Test #14 --------------------
21Feb13_054802|Best final individual weights
21Feb13_054802|Individual:
21Feb13_054802|-- Constant hidden layers --
21Feb13_054802|False
21Feb13_054802|Layer 0:
21Feb13_054802|-- Config --
21Feb13_054802|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_054802|-- Weights --
21Feb13_054802|[[-0.58131  0.41104 -0.62368]
21Feb13_054802| [ 0.69656 -1.02993 -0.20603]
21Feb13_054802| [-1.86788  2.30608 -0.81731]
21Feb13_054802| [ 2.35696  1.24218 -0.92105]
21Feb13_054802| [-0.61245  1.01963 -0.41972]
21Feb13_054802| [-0.79454 -0.79620 -1.73701]
21Feb13_054802| [-1.13615 -0.38489 -0.82265]
21Feb13_054802| [-0.25325 -1.16213  0.70843]
21Feb13_054802| [ 0.83976  0.00993 -0.70265]
21Feb13_054802| [ 0.03684  0.08167 -0.17511]
21Feb13_054802| [ 0.57322 -0.08752  0.19502]
21Feb13_054802| [ 0.89737  1.16408 -0.22033]
21Feb13_054802| [ 0.44220  0.98258  1.32976]
21Feb13_054802| [ 0.14725 -0.31934 -0.22376]
21Feb13_054802| [-0.48317  1.49892 -0.58919]
21Feb13_054802| [-0.92600 -0.13766 -0.87815]
21Feb13_054802| [ 0.49251  0.54697  2.15955]
21Feb13_054802| [-1.54885  0.99749 -0.01751]
21Feb13_054802| [-0.25372 -1.31307  0.28582]
21Feb13_054802| [ 0.22894  0.35440  0.55132]
21Feb13_054802| [ 0.40985  0.84636 -0.09488]
21Feb13_054802| [ 0.25282  0.95784 -0.20253]
21Feb13_054802| [ 1.38163 -0.00593 -0.16853]
21Feb13_054802| [ 0.45233  1.00133  1.55658]
21Feb13_054802| [-0.04314 -0.28648 -0.91586]
21Feb13_054802| [ 0.52062 -1.41258  1.36297]
21Feb13_054802| [ 0.19469 -0.40620 -0.80653]
21Feb13_054802| [-0.92176  0.82471  0.88854]
21Feb13_054802| [ 0.08866 -0.43584  1.31285]
21Feb13_054802| [ 2.28433 -0.37639  1.71487]
21Feb13_054802| [-1.29992  0.11704  0.96791]
21Feb13_054802| [ 0.01865  0.75131  0.94805]
21Feb13_054802| [-1.38934 -0.85679 -1.03067]
21Feb13_054802| [ 1.08457  0.92298 -1.79844]
21Feb13_054802| [ 1.45389 -0.34044 -0.13392]
21Feb13_054802| [ 0.63791 -0.99181  0.83168]
21Feb13_054802| [ 1.01793 -0.84685  0.50036]
21Feb13_054802| [-0.50065 -1.16125  0.03549]
21Feb13_054802| [-0.67174 -0.13235  0.05094]
21Feb13_054802| [-0.65057  0.27166 -0.33921]
21Feb13_054802| [ 1.04472 -0.02756 -0.87296]
21Feb13_054802| [ 0.10613  0.07959  0.42727]
21Feb13_054802| [ 0.07967  0.39679  1.02531]
21Feb13_054802| [ 1.82264 -0.32392 -2.71293]
21Feb13_054802| [ 1.83116 -0.68393 -1.06911]
21Feb13_054802| [-0.65866  0.55609  0.45198]
21Feb13_054802| [ 0.15390 -0.12530 -0.49443]
21Feb13_054802| [ 1.03811 -0.82233 -1.38641]
21Feb13_054802| [ 1.20222  0.67180  0.52163]
21Feb13_054802| [-0.58928  1.11110  0.79006]
21Feb13_054802| [ 0.87426  0.30426 -0.44848]
21Feb13_054802| [ 0.69579 -0.36500 -0.34569]
21Feb13_054802| [ 0.78584 -0.89277  0.94968]
21Feb13_054802| [ 1.11890  0.55386 -0.30582]
21Feb13_054802| [-0.30253  1.01131 -0.38667]
21Feb13_054802| [ 0.60845  0.73766  0.25496]
21Feb13_054802| [-0.70400 -0.39828 -0.29869]]
21Feb13_054802|-- Bias --
21Feb13_054802|[-0.92461  0.60117 -0.43775]
21Feb13_054802|Layer 1:
21Feb13_054802|-- Config --
21Feb13_054802|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_054802|-- Weights --
21Feb13_054802|[[-0.47251  1.36579]
21Feb13_054802| [-0.20704  0.40126]
21Feb13_054802| [-1.70310  1.22032]]
21Feb13_054802|-- Bias --
21Feb13_054802|[-0.67142  0.13605]
21Feb13_054802|Predicting the validation and test data with the Best final individual.
21Feb13_054809| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_054809|-----------  ------------------  --------------------  ----------
21Feb13_054809|Validation         41.39                  3             0.01805
21Feb13_054809|   Test            36.23                  3             0.01189
2021-02-13 05:48:10.703600: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
21Feb13_054811|Data summary: Train
21Feb13_054811|data.shape = (2300, 57)
21Feb13_054811|labels.shape = (2300,)
21Feb13_054811|Class distribution:
21Feb13_054811|	0 - 1389 (0.60)
21Feb13_054811|	1 - 911 (0.40)
21Feb13_054811|Data summary: Validation
21Feb13_054811|data.shape = (1150, 57)
21Feb13_054811|labels.shape = (1150,)
21Feb13_054811|Class distribution:
21Feb13_054811|	0 - 667 (0.58)
21Feb13_054811|	1 - 483 (0.42)
21Feb13_054811|Data summary: Test
21Feb13_054811|data.shape = (1151, 57)
21Feb13_054811|labels.shape = (1151,)
21Feb13_054811|Class distribution:
21Feb13_054811|	0 - 732 (0.64)
21Feb13_054811|	1 - 419 (0.36)
21Feb13_054811|Selected configuration values
21Feb13_054811|-- Dataset name: spambase2
21Feb13_054811|-- Initial population size: 64
21Feb13_054811|-- Maximun number of generations: 32
21Feb13_054811|-- Neurons per hidden layer range: (2, 20)
21Feb13_054811|-- Hidden layers number range: (1, 3)
21Feb13_054811|-- Crossover probability: 0.5
21Feb13_054811|-- Bias gene mutation probability: 0.2
21Feb13_054811|-- Weights gene mutation probability: 0.75
21Feb13_054811|-- Neuron mutation probability: 0.3
21Feb13_054811|-- Layer mutation probability: 0.3
21Feb13_054811|-- Constant hidden layers: False
21Feb13_054811|-- Seed: 31415
21Feb13_054811|Entering GA
21Feb13_054811|Start the algorithm
2021-02-13 05:48:11.539281: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-13 05:48:11.539810: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-02-13 05:48:11.563110: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-13 05:48:11.563430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.71GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s
2021-02-13 05:48:11.563443: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-02-13 05:48:11.564891: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-02-13 05:48:11.564918: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-02-13 05:48:11.565423: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-02-13 05:48:11.565553: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-02-13 05:48:11.565623: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-13 05:48:11.566034: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-02-13 05:48:11.566074: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-13 05:48:11.566080: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-02-13 05:48:11.566282: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-02-13 05:48:11.567014: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-13 05:48:11.567027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-13 05:48:11.567030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      
2021-02-13 05:48:11.611883: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-02-13 05:48:11.612215: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3493635000 Hz
/home/jmerelo/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype("int32")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn('`model.predict_classes()` is deprecated and '
21Feb13_055213|-- Generation 1 --
21Feb13_055213|    -- Crossed 2 individual pairs.
21Feb13_055213|    -- Mutated 32 individuals.
21Feb13_055609|    -- Evaluated 64 individuals.
21Feb13_055609|    Summary of generation 1:
21Feb13_055609| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_055609|-----------  ------------------  --------------------  ----------
21Feb13_055609|    Max            42.43                120.00          0.33160
21Feb13_055609|    Avg            41.86                32.41           0.00688
21Feb13_055609|    Min            33.22                 3.00           0.00000
21Feb13_055609|    Std             1.10                29.05           0.04102
21Feb13_055609|   Best            33.22                16.00           0.33160
21Feb13_055609|-- Generation 2 --
21Feb13_055609|    -- Crossed 1 individual pairs.
21Feb13_055609|    -- Mutated 32 individuals.
21Feb13_060003|    -- Evaluated 64 individuals.
21Feb13_060003|    Summary of generation 2:
21Feb13_060003| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_060003|-----------  ------------------  --------------------  ----------
21Feb13_060003|    Max            42.17                120.00          0.54018
21Feb13_060003|    Avg            41.57                21.03           0.01756
21Feb13_060003|    Min            27.74                 3.00           0.00000
21Feb13_060003|    Std             2.36                23.49           0.09113
21Feb13_060003|   Best            27.74                16.00           0.50901
21Feb13_060003|-- Generation 3 --
21Feb13_060003|    -- Crossed 1 individual pairs.
21Feb13_060003|    -- Mutated 32 individuals.
21Feb13_060354|    -- Evaluated 64 individuals.
21Feb13_060354|    Summary of generation 3:
21Feb13_060354| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_060354|-----------  ------------------  --------------------  ----------
21Feb13_060354|    Max            43.22                52.00           0.71286
21Feb13_060354|    Avg            41.58                12.53           0.02152
21Feb13_060354|    Min            28.09                 3.00           0.00000
21Feb13_060354|    Std             2.26                10.92           0.10759
21Feb13_060354|   Best            28.09                16.00           0.50988
21Feb13_060354|-- Generation 4 --
21Feb13_060354|    -- Crossed 5 individual pairs.
21Feb13_060354|    -- Mutated 32 individuals.
21Feb13_060743|    -- Evaluated 64 individuals.
21Feb13_060743|    Summary of generation 4:
21Feb13_060743| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_060743|-----------  ------------------  --------------------  ----------
21Feb13_060743|    Max            42.17                54.00           0.31220
21Feb13_060743|    Avg            41.84                11.27           0.00637
21Feb13_060743|    Min            32.43                 2.00           0.00000
21Feb13_060743|    Std             1.19                11.37           0.03859
21Feb13_060743|   Best            32.43                16.00           0.31220
21Feb13_060743|-- Generation 5 --
21Feb13_060743|    -- Crossed 4 individual pairs.
21Feb13_060743|    -- Mutated 32 individuals.
21Feb13_061132|    -- Evaluated 64 individuals.
21Feb13_061132|    Summary of generation 5:
21Feb13_061132| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_061132|-----------  ------------------  --------------------  ----------
21Feb13_061132|    Max            42.26                52.00           0.42459
21Feb13_061132|    Avg            41.74                 9.55           0.00918
21Feb13_061132|    Min            29.57                 2.00           0.00000
21Feb13_061132|    Std             1.54                10.28           0.05250
21Feb13_061132|   Best            29.57                16.00           0.42459
21Feb13_061132|-- Generation 6 --
21Feb13_061132|    -- Crossed 6 individual pairs.
21Feb13_061132|    -- Mutated 32 individuals.
21Feb13_061522|    -- Evaluated 64 individuals.
21Feb13_061522|    Summary of generation 6:
21Feb13_061522| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_061522|-----------  ------------------  --------------------  ----------
21Feb13_061522|    Max            42.26                52.00           0.42904
21Feb13_061522|    Avg            41.75                14.12           0.00913
21Feb13_061522|    Min            29.30                 2.00           0.00000
21Feb13_061522|    Std             1.57                12.89           0.05301
21Feb13_061522|   Best            29.30                16.00           0.42904
21Feb13_061522|-- Generation 7 --
21Feb13_061522|    -- Crossed 4 individual pairs.
21Feb13_061522|    -- Mutated 32 individuals.
21Feb13_061914|    -- Evaluated 64 individuals.
21Feb13_061914|    Summary of generation 7:
21Feb13_061914| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_061914|-----------  ------------------  --------------------  ----------
21Feb13_061914|    Max            42.35                90.00           0.21068
21Feb13_061914|    Avg            41.85                16.95           0.00660
21Feb13_061914|    Min            36.52                 2.00           0.00000
21Feb13_061914|    Std             0.69                18.36           0.02617
21Feb13_061914|   Best            36.52                16.00           0.21068
21Feb13_061914|-- Generation 8 --
21Feb13_061914|    -- Crossed 4 individual pairs.
21Feb13_061914|    -- Mutated 32 individuals.
21Feb13_062304|    -- Evaluated 64 individuals.
21Feb13_062304|    Summary of generation 8:
21Feb13_062304| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_062304|-----------  ------------------  --------------------  ----------
21Feb13_062304|    Max            42.17                66.00           0.52125
21Feb13_062304|    Avg            41.69                12.30           0.01190
21Feb13_062304|    Min            27.83                 3.00           0.00000
21Feb13_062304|    Std             1.76                11.60           0.06439
21Feb13_062304|   Best            27.83                16.00           0.52125
21Feb13_062304|-- Generation 9 --
21Feb13_062304|    -- Crossed 6 individual pairs.
21Feb13_062304|    -- Mutated 32 individuals.
21Feb13_062653|    -- Evaluated 64 individuals.
21Feb13_062653|    Summary of generation 9:
21Feb13_062653| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_062653|-----------  ------------------  --------------------  ----------
21Feb13_062653|    Max            42.43                54.00           0.52172
21Feb13_062653|    Avg            41.49                 9.83           0.01894
21Feb13_062653|    Min            27.57                 3.00           0.00000
21Feb13_062653|    Std             2.50                 8.78           0.08817
21Feb13_062653|   Best            27.57                16.00           0.49682
21Feb13_062653|-- Generation 10 --
21Feb13_062653|    -- Crossed 8 individual pairs.
21Feb13_062653|    -- Mutated 32 individuals.
21Feb13_063041|    -- Evaluated 64 individuals.
21Feb13_063041|    Summary of generation 10:
21Feb13_063041| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_063041|-----------  ------------------  --------------------  ----------
21Feb13_063041|    Max            42.09                36.00           0.01291
21Feb13_063041|    Avg            41.94                 8.25           0.00262
21Feb13_063041|    Min            41.57                 3.00           0.00000
21Feb13_063041|    Std             0.07                 7.24           0.00248
21Feb13_063041|   Best            41.57                 5.00           0.01291
21Feb13_063041|-- Generation 11 --
21Feb13_063041|    -- Crossed 10 individual pairs.
21Feb13_063041|    -- Mutated 32 individuals.
21Feb13_063429|    -- Evaluated 64 individuals.
21Feb13_063429|    Summary of generation 11:
21Feb13_063429| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_063429|-----------  ------------------  --------------------  ----------
21Feb13_063429|    Max            42.09                32.00           0.16373
21Feb13_063429|    Avg            41.89                 7.72           0.00530
21Feb13_063429|    Min            40.26                 3.00           0.00000
21Feb13_063429|    Std             0.24                 6.36           0.02036
21Feb13_063429|   Best            40.26                14.00           0.16373
21Feb13_063429|-- Generation 12 --
21Feb13_063429|    -- Crossed 4 individual pairs.
21Feb13_063429|    -- Mutated 32 individuals.
21Feb13_063815|    -- Evaluated 64 individuals.
21Feb13_063815|    Summary of generation 12:
21Feb13_063815| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_063815|-----------  ------------------  --------------------  ----------
21Feb13_063815|    Max            42.09                20.00           0.32318
21Feb13_063815|    Avg            41.86                 5.52           0.00767
21Feb13_063815|    Min            38.00                 3.00           0.00000
21Feb13_063815|    Std             0.49                 3.30           0.03984
21Feb13_063815|   Best            38.00                14.00           0.32318
21Feb13_063815|-- Generation 13 --
21Feb13_063815|    -- Crossed 4 individual pairs.
21Feb13_063815|    -- Mutated 32 individuals.
21Feb13_064203|    -- Evaluated 64 individuals.
21Feb13_064203|    Summary of generation 13:
21Feb13_064203| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_064203|-----------  ------------------  --------------------  ----------
21Feb13_064203|    Max            42.61                20.00           0.02059
21Feb13_064203|    Avg            41.94                 6.66           0.00258
21Feb13_064203|    Min            41.39                 3.00           0.00000
21Feb13_064203|    Std             0.13                 4.84           0.00341
21Feb13_064203|   Best            41.39                 5.00           0.01805
21Feb13_064203|-- Generation 14 --
21Feb13_064203|    -- Crossed 9 individual pairs.
21Feb13_064203|    -- Mutated 32 individuals.
21Feb13_064549|    -- Evaluated 64 individuals.
21Feb13_064549|    Summary of generation 14:
21Feb13_064549| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_064549|-----------  ------------------  --------------------  ----------
21Feb13_064549|    Max            42.09                20.00           0.02062
21Feb13_064549|    Avg            41.91                 5.45           0.00283
21Feb13_064549|    Min            41.30                 2.00           0.00000
21Feb13_064549|    Std             0.11                 3.88           0.00346
21Feb13_064549|   Best            41.30                 5.00           0.02062
21Feb13_064549|-- Generation 15 --
21Feb13_064549|    -- Crossed 8 individual pairs.
21Feb13_064549|    -- Mutated 32 individuals.
21Feb13_064937|    -- Evaluated 64 individuals.
21Feb13_064937|    Summary of generation 15:
21Feb13_064937| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_064937|-----------  ------------------  --------------------  ----------
21Feb13_064937|    Max            42.09                20.00           0.64772
21Feb13_064937|    Avg            41.72                 6.28           0.01282
21Feb13_064937|    Min            28.17                 3.00           0.00000
21Feb13_064937|    Std             1.71                 4.58           0.08006
21Feb13_064937|   Best            28.17                14.00           0.64772
21Feb13_064937|-- Generation 16 --
21Feb13_064937|    -- Crossed 5 individual pairs.
21Feb13_064937|    -- Mutated 32 individuals.
21Feb13_065324|    -- Evaluated 64 individuals.
21Feb13_065324|    Summary of generation 16:
21Feb13_065324| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_065324|-----------  ------------------  --------------------  ----------
21Feb13_065324|    Max            47.13                20.00           0.80985
21Feb13_065324|    Avg            41.78                 5.69           0.02665
21Feb13_065324|    Min            28.43                 2.00           0.00000
21Feb13_065324|    Std             1.81                 4.12           0.13094
21Feb13_065324|   Best            28.43                14.00           0.69659
21Feb13_065324|-- Generation 17 --
21Feb13_065324|    -- Crossed 6 individual pairs.
21Feb13_065324|    -- Mutated 32 individuals.
21Feb13_065712|    -- Evaluated 64 individuals.
21Feb13_065712|    Summary of generation 17:
21Feb13_065712| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_065712|-----------  ------------------  --------------------  ----------
21Feb13_065712|    Max            42.09                20.00           0.76759
21Feb13_065712|    Avg            41.49                 5.98           0.02628
21Feb13_065712|    Min            29.04                 2.00           0.00000
21Feb13_065712|    Std             2.23                 4.66           0.12584
21Feb13_065712|   Best            29.04                20.00           0.76759
21Feb13_065712|-- Generation 18 --
21Feb13_065712|    -- Crossed 2 individual pairs.
21Feb13_065712|    -- Mutated 32 individuals.
21Feb13_070101|    -- Evaluated 64 individuals.
21Feb13_070101|    Summary of generation 18:
21Feb13_070101| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_070101|-----------  ------------------  --------------------  ----------
21Feb13_070101|    Max            42.52                45.00           0.79427
21Feb13_070101|    Avg            41.29                 7.33           0.04040
21Feb13_070101|    Min            27.13                 2.00           0.00000
21Feb13_070101|    Std             2.76                 7.02           0.16323
21Feb13_070101|   Best            27.13                10.00           0.79427
21Feb13_070101|-- Generation 19 --
21Feb13_070101|    -- Crossed 4 individual pairs.
21Feb13_070101|    -- Mutated 32 individuals.
21Feb13_070449|    -- Evaluated 64 individuals.
21Feb13_070449|    Summary of generation 19:
21Feb13_070449| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_070449|-----------  ------------------  --------------------  ----------
21Feb13_070449|    Max            42.17                39.00           0.16772
21Feb13_070449|    Avg            41.89                 7.61           0.00621
21Feb13_070449|    Min            40.87                 2.00           0.00000
21Feb13_070449|    Std             0.22                 7.14           0.02103
21Feb13_070449|   Best            40.87                16.00           0.16772
21Feb13_070449|-- Generation 20 --
21Feb13_070449|    -- Crossed 6 individual pairs.
21Feb13_070449|    -- Mutated 32 individuals.
21Feb13_070837|    -- Evaluated 64 individuals.
21Feb13_070837|    Summary of generation 20:
21Feb13_070837| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_070837|-----------  ------------------  --------------------  ----------
21Feb13_070837|    Max            42.17                27.00           0.02317
21Feb13_070837|    Avg            41.91                 6.36           0.00311
21Feb13_070837|    Min            41.30                 2.00           0.00000
21Feb13_070837|    Std             0.15                 5.72           0.00449
21Feb13_070837|   Best            41.30                 6.00           0.02317
21Feb13_070837|-- Generation 21 --
21Feb13_070837|    -- Crossed 7 individual pairs.
21Feb13_070837|    -- Mutated 32 individuals.
21Feb13_071225|    -- Evaluated 64 individuals.
21Feb13_071225|    Summary of generation 21:
21Feb13_071225| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_071225|-----------  ------------------  --------------------  ----------
21Feb13_071225|    Max            42.17                20.00           0.02062
21Feb13_071225|    Avg            41.90                 5.81           0.00335
21Feb13_071225|    Min            41.30                 2.00           0.00000
21Feb13_071225|    Std             0.16                 5.23           0.00464
21Feb13_071225|   Best            41.30                 6.00           0.02062
21Feb13_071225|-- Generation 22 --
21Feb13_071225|    -- Crossed 10 individual pairs.
21Feb13_071225|    -- Mutated 32 individuals.
21Feb13_071613|    -- Evaluated 64 individuals.
21Feb13_071613|    Summary of generation 22:
21Feb13_071613| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_071613|-----------  ------------------  --------------------  ----------
21Feb13_071613|    Max            42.00                20.00           0.02062
21Feb13_071613|    Avg            41.88                 5.72           0.00375
21Feb13_071613|    Min            41.30                 2.00           0.00000
21Feb13_071613|    Std             0.15                 5.33           0.00458
21Feb13_071613|   Best            41.30                 3.00           0.02062
21Feb13_071613|-- Generation 23 --
21Feb13_071613|    -- Crossed 7 individual pairs.
21Feb13_071613|    -- Mutated 32 individuals.
21Feb13_072003|    -- Evaluated 64 individuals.
21Feb13_072003|    Summary of generation 23:
21Feb13_072003| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_072003|-----------  ------------------  --------------------  ----------
21Feb13_072003|    Max            42.17                39.00           0.75739
21Feb13_072003|    Avg            41.57                 7.47           0.01728
21Feb13_072003|    Min            25.65                 2.00           0.00000
21Feb13_072003|    Std             2.02                 7.82           0.09350
21Feb13_072003|   Best            25.65                39.00           0.75739
21Feb13_072003|-- Generation 24 --
21Feb13_072003|    -- Crossed 4 individual pairs.
21Feb13_072003|    -- Mutated 32 individuals.
21Feb13_072353|    -- Evaluated 64 individuals.
21Feb13_072353|    Summary of generation 24:
21Feb13_072353| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_072353|-----------  ------------------  --------------------  ----------
21Feb13_072353|    Max            45.30                42.00           0.81451
21Feb13_072353|    Avg            41.66                 9.56           0.03848
21Feb13_072353|    Min            28.52                 2.00           0.00000
21Feb13_072353|    Std             1.74                 9.45           0.15349
21Feb13_072353|   Best            28.52                39.00           0.52292
21Feb13_072353|-- Generation 25 --
21Feb13_072353|    -- Crossed 2 individual pairs.
21Feb13_072353|    -- Mutated 32 individuals.
21Feb13_072742|    -- Evaluated 64 individuals.
21Feb13_072742|    Summary of generation 25:
21Feb13_072742| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_072742|-----------  ------------------  --------------------  ----------
21Feb13_072742|    Max            43.22                39.00           0.68930
21Feb13_072742|    Avg            41.52                 8.48           0.02313
21Feb13_072742|    Min            25.22                 2.00           0.00000
21Feb13_072742|    Std             2.15                 8.98           0.09796
21Feb13_072742|   Best            25.22                39.00           0.68930
21Feb13_072742|-- Generation 26 --
21Feb13_072742|    -- Crossed 5 individual pairs.
21Feb13_072742|    -- Mutated 32 individuals.
21Feb13_073132|    -- Evaluated 64 individuals.
21Feb13_073132|    Summary of generation 26:
21Feb13_073132| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_073132|-----------  ------------------  --------------------  ----------
21Feb13_073132|    Max            42.43                60.00           0.86424
21Feb13_073132|    Avg            40.80                 8.95           0.05262
21Feb13_073132|    Min            22.78                 2.00           0.00000
21Feb13_073132|    Std             3.95                10.24           0.18079
21Feb13_073132|   Best            22.78                39.00           0.86424
21Feb13_073132|-- Generation 27 --
21Feb13_073132|    -- Crossed 2 individual pairs.
21Feb13_073132|    -- Mutated 32 individuals.
21Feb13_073525|    -- Evaluated 64 individuals.
21Feb13_073525|    Summary of generation 27:
21Feb13_073525| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_073525|-----------  ------------------  --------------------  ----------
21Feb13_073525|    Max            42.00                100.00          0.80687
21Feb13_073525|    Avg            40.52                13.28           0.07740
21Feb13_073525|    Min            23.74                 2.00           0.00000
21Feb13_073525|    Std             4.02                15.74           0.21390
21Feb13_073525|   Best            23.74                27.00           0.71517
21Feb13_073525|-- Generation 28 --
21Feb13_073525|    -- Crossed 2 individual pairs.
21Feb13_073525|    -- Mutated 32 individuals.
21Feb13_073918|    -- Evaluated 64 individuals.
21Feb13_073918|    Summary of generation 28:
21Feb13_073918| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_073918|-----------  ------------------  --------------------  ----------
21Feb13_073918|    Max            42.09                64.00           0.74089
21Feb13_073918|    Avg            40.90                12.47           0.04869
21Feb13_073918|    Min            25.13                 2.00           0.00000
21Feb13_073918|    Std             3.40                13.65           0.16056
21Feb13_073918|   Best            25.13                27.00           0.71046
21Feb13_073918|-- Generation 29 --
21Feb13_073918|    -- Crossed 5 individual pairs.
21Feb13_073918|    -- Mutated 32 individuals.
21Feb13_074309|    -- Evaluated 64 individuals.
21Feb13_074309|    Summary of generation 29:
21Feb13_074309| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_074309|-----------  ------------------  --------------------  ----------
21Feb13_074309|    Max            42.17                64.00           0.72883
21Feb13_074309|    Avg            40.93                11.77           0.04507
21Feb13_074309|    Min            27.74                 2.00           0.00000
21Feb13_074309|    Std             3.22                13.94           0.14460
21Feb13_074309|   Best            27.74                64.00           0.55458
21Feb13_074309|-- Generation 30 --
21Feb13_074309|    -- Crossed 3 individual pairs.
21Feb13_074309|    -- Mutated 32 individuals.
21Feb13_074701|    -- Evaluated 64 individuals.
21Feb13_074701|    Summary of generation 30:
21Feb13_074701| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_074701|-----------  ------------------  --------------------  ----------
21Feb13_074701|    Max            42.17                65.00           0.82133
21Feb13_074701|    Avg            40.43                12.41           0.05972
21Feb13_074701|    Min            24.00                 2.00           0.00000
21Feb13_074701|    Std             4.21                17.11           0.16833
21Feb13_074701|   Best            24.00                64.00           0.82133
21Feb13_074701|-- Generation 31 --
21Feb13_074701|    -- Crossed 2 individual pairs.
21Feb13_074701|    -- Mutated 32 individuals.
21Feb13_075054|    -- Evaluated 64 individuals.
21Feb13_075054|    Summary of generation 31:
21Feb13_075054| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_075054|-----------  ------------------  --------------------  ----------
21Feb13_075054|    Max            42.70                64.00           0.76829
21Feb13_075054|    Avg            40.50                14.44           0.06577
21Feb13_075054|    Min            21.39                 2.00           0.00000
21Feb13_075054|    Std             4.12                18.03           0.17820
21Feb13_075054|   Best            21.39                64.00           0.76829
21Feb13_075054|-- Generation 32 --
21Feb13_075054|    -- Crossed 2 individual pairs.
21Feb13_075054|    -- Mutated 32 individuals.
21Feb13_075446|    -- Evaluated 64 individuals.
21Feb13_075446|    Summary of generation 32:
21Feb13_075446| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_075446|-----------  ------------------  --------------------  ----------
21Feb13_075446|    Max            42.35                64.00           0.75101
21Feb13_075446|    Avg            40.48                12.88           0.06141
21Feb13_075446|    Min            24.26                 2.00           0.00000
21Feb13_075446|    Std             3.72                17.36           0.15887
21Feb13_075446|   Best            24.26                10.00           0.75101
21Feb13_075446|Best initial individual weights
21Feb13_075446|Individual:
21Feb13_075446|-- Constant hidden layers --
21Feb13_075446|False
21Feb13_075446|Layer 0:
21Feb13_075446|-- Config --
21Feb13_075446|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 14, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075446|-- Weights --
21Feb13_075446|[[-0.46755 -0.77923  0.54917 -0.28189 -0.72659 -0.27127 -0.27090 -0.70110
21Feb13_075446|  -0.67504 -0.55383  0.05413 -0.54585  0.33416 -0.40920]
21Feb13_075446| [-0.63500  0.50563  0.57366  0.56179  0.04949  0.13217  0.41463  0.93392
21Feb13_075446|   0.61458  0.96459 -0.18538 -0.13505  0.57914 -0.52395]
21Feb13_075446| [-0.68746 -0.76013 -0.94302  0.63098 -0.51538  0.18933 -0.84177  0.74255
21Feb13_075446|   0.86109 -0.27253 -0.84093 -0.97103 -0.02308  0.93169]
21Feb13_075446| [-0.30389 -0.64730  0.82087 -0.31786 -0.85760 -0.53174 -0.24099  0.67567
21Feb13_075446|   0.06588 -0.45133 -0.21639 -0.44111 -0.61620 -0.17649]
21Feb13_075446| [ 0.48191 -0.65488 -0.21573 -0.77382  0.08877 -0.42943  0.31791  0.19963
21Feb13_075446|   0.68021 -0.01578  0.68440  0.17655 -0.21113  0.67186]
21Feb13_075446| [-0.36815  0.65794 -0.13217 -0.31720  0.76634  0.27196  0.95938  0.33809
21Feb13_075446|   0.19009  0.33029 -0.46957 -0.33031 -0.51404  0.65862]
21Feb13_075446| [-0.65723  0.89409  0.22717  0.66331 -0.65923  0.79128 -0.98129  0.85470
21Feb13_075446|  -0.14172 -0.04193 -0.47613  0.48781  0.68267 -0.66590]
21Feb13_075446| [-0.52649  0.13025 -0.62663 -0.42792  0.22186 -0.95757 -0.54927  0.85846
21Feb13_075446|   0.31648  0.71487 -0.43083  0.44347 -0.23840 -0.29771]
21Feb13_075446| [ 0.66666 -0.29194  0.36156 -0.76444  0.85348 -0.92589 -0.67688 -0.59105
21Feb13_075446|  -0.14206 -0.14664 -0.95610 -0.12937  0.30125 -0.16216]
21Feb13_075446| [ 0.77747  0.46685 -0.71306  0.32989 -0.87164 -0.11013  0.19666  0.73410
21Feb13_075446|  -0.29764  0.99239 -0.68544  0.41165 -0.64248 -0.97687]
21Feb13_075446| [ 0.17007 -0.65841  0.72035  0.09167  0.85914  0.22927 -0.25043 -0.23306
21Feb13_075446|   0.72466  0.74012  0.43476  0.85579 -0.95528 -0.61712]
21Feb13_075446| [-0.09915 -0.54507 -0.26888  0.02218  0.58739 -0.06694  0.07394 -0.71029
21Feb13_075446|  -0.70699 -0.17378 -0.26204 -0.54108  0.87105  0.37003]
21Feb13_075446| [-0.87676  0.79843  0.13830  0.73610 -0.35602  0.07624  0.58797  0.93769
21Feb13_075446|  -0.47112 -0.88784 -0.32329  0.57694  0.54031  0.46209]
21Feb13_075446| [ 0.56833  0.00229 -0.63767 -0.25082  0.87251  0.72852 -0.35706 -0.32574
21Feb13_075446|   0.00338 -0.96495 -0.24423  0.83795  0.17704 -0.52730]
21Feb13_075446| [ 0.57389  0.43306 -0.14668  0.09726 -0.40905  0.48410  0.46706  0.29093
21Feb13_075446|  -0.73066 -0.42228 -0.50998  0.90495  0.38869  0.16695]
21Feb13_075446| [-0.38641 -0.90524 -0.68245 -0.18039  0.28617  0.95451  0.31495  0.98373
21Feb13_075446|   0.03790 -0.42415 -0.77936 -0.83630  0.24380 -0.33397]
21Feb13_075446| [ 0.45738 -0.32376  0.96332 -0.16096  0.31168 -0.94554  0.35925 -0.69530
21Feb13_075446|  -0.03069 -0.91449 -0.94713 -0.87442  0.37907  0.83374]
21Feb13_075446| [ 0.82631 -0.40539  0.37464  0.84534  0.25362 -0.91741 -0.31505  0.86890
21Feb13_075446|  -0.89153 -0.90321  0.55294 -0.19362 -0.49542 -0.19912]
21Feb13_075446| [ 0.45632 -0.68250 -0.38370 -0.52120 -0.03266 -0.74606 -0.97861 -0.15550
21Feb13_075446|  -0.33213  0.11576  0.28994  0.00440  0.65196 -0.58094]
21Feb13_075446| [-0.08531  0.13013 -0.49165  0.13948  0.90958 -0.93520  0.58653 -0.14145
21Feb13_075446|  -0.31804  0.99202 -0.46123 -0.67566  0.72270  0.07720]
21Feb13_075446| [-0.18701  0.84394  0.21217  0.94145 -0.47411  0.61988  0.95344 -0.18707
21Feb13_075446|   0.26361 -0.55127  0.19663  0.91693  0.70662 -0.93054]
21Feb13_075446| [-0.24922 -0.65816  0.12943  0.71089 -0.96074 -0.49543 -0.74916  0.72108
21Feb13_075446|   0.47341 -0.33704  0.60085 -0.79768  0.05831  0.93894]
21Feb13_075446| [-0.56027 -0.07417 -0.59317  0.17038  0.89351 -0.58669  0.76195 -0.97400
21Feb13_075446|  -0.26234  0.01124 -0.37019 -0.07945  0.30678 -0.05190]
21Feb13_075446| [ 0.33030 -0.80606 -0.15583  0.36617  0.51910 -0.23815 -0.41574  0.84538
21Feb13_075446|  -0.24786  0.45644  0.55059  0.62875  0.62044 -0.20357]
21Feb13_075446| [ 0.04941  0.26053 -0.36386 -0.34913  0.91955  0.05273 -0.94165 -0.78189
21Feb13_075446|  -0.57974 -0.22811  0.72354 -0.04255  0.26185  0.37401]
21Feb13_075446| [-0.02059 -0.55773  0.72546 -0.82885 -0.73287  0.45804 -0.78944  0.74713
21Feb13_075446|  -0.89593  0.72724 -0.44896 -0.14313 -0.67643 -0.03675]
21Feb13_075446| [ 0.12220 -0.58125 -0.12500  0.26843  0.12176  0.77053  0.22442 -0.89966
21Feb13_075446|   0.09096 -0.24841 -0.27943  0.37594 -0.79211 -0.43915]
21Feb13_075446| [ 0.13685 -0.46444 -0.80102  0.04904  0.90523 -0.51614 -0.62836 -0.04136
21Feb13_075446|  -0.72900  0.62896 -0.29738  0.27190 -0.76503  0.74540]
21Feb13_075446| [ 0.18538 -0.44490 -0.03086 -0.72017  0.82826  0.04552  0.19502  0.01582
21Feb13_075446|   0.07019  0.26265 -0.61195  0.70762 -0.68833  0.59056]
21Feb13_075446| [-0.19076 -0.40389  0.94951  0.81209 -0.24990 -0.73472  0.35684  0.54594
21Feb13_075446|   0.02705 -0.70092 -0.75131  0.28926 -0.76413  0.90106]
21Feb13_075446| [ 0.89491 -0.44966 -0.07129  0.47477 -0.31786  0.19173  0.56299  0.78493
21Feb13_075446|  -0.85890 -0.80598 -0.03673 -0.18087  0.92364  0.04843]
21Feb13_075446| [ 0.30403  0.77247 -0.84687  0.76203  0.25237  0.62157 -0.18053 -0.91906
21Feb13_075446|  -0.04765  0.20249 -0.65221 -0.05052 -0.41625 -0.65536]
21Feb13_075446| [-0.84187 -0.80188 -0.99497  0.76603 -0.71492 -0.17111 -0.28120  0.80320
21Feb13_075446|  -0.07261  0.71081  0.01508  0.97961 -0.05309  0.42977]
21Feb13_075446| [-0.19072  0.97039 -0.08302 -0.04211 -0.01337 -0.48400 -0.52995  0.19069
21Feb13_075446|   0.01795  0.45507  0.01718 -0.36766 -0.31757  0.80225]
21Feb13_075446| [-0.56903  0.23408  0.70376 -0.67078  0.15573 -0.23159  0.47725  0.93539
21Feb13_075446|  -0.75790  0.53202 -0.84788  0.79902 -0.71951 -0.63768]
21Feb13_075446| [-0.02086  0.23811  0.84799  0.66904  0.62595  0.79239  0.14162 -0.69665
21Feb13_075446|  -0.17673  0.36012 -0.10827 -0.54487 -0.94652  0.64132]
21Feb13_075446| [ 0.54057 -0.52721  0.19858  0.46209  0.25979  0.46581 -0.43188 -0.25092
21Feb13_075446|   0.10142  0.36981  0.29653 -0.60029  0.63754  0.78518]
21Feb13_075446| [-0.73536  0.15757 -0.67765  0.94100  0.55251  0.93236 -0.09504 -0.25668
21Feb13_075446|  -0.49745 -0.08851  0.21545 -0.20070  0.23399  0.94390]
21Feb13_075446| [ 0.40157 -0.64885 -0.99951 -0.73596  0.83216  0.13883 -0.43141 -0.25660
21Feb13_075446|  -0.64869  0.18746 -0.14855 -0.29644 -0.08967  0.09011]
21Feb13_075446| [ 0.24532 -0.25469 -0.27555 -0.26078 -0.06836  0.97940  0.31619 -0.83638
21Feb13_075446|   0.25254 -0.18261  0.58487  0.57371 -0.33039 -0.26035]
21Feb13_075446| [-0.40443 -0.03473  0.67337 -0.52501  0.15891 -0.25029 -0.86421 -0.50345
21Feb13_075446|   0.23077 -0.70594  0.38123 -0.14116  0.24608  0.30380]
21Feb13_075446| [-0.91157 -0.71115 -0.08024  0.43313 -0.66540  0.97313 -0.73091 -0.81121
21Feb13_075446|  -0.12058 -0.15718  0.36369  0.79179  0.96340 -0.40657]
21Feb13_075446| [-0.14059 -0.01148 -0.02677  0.33900 -0.10768 -0.17529 -0.80387 -0.53018
21Feb13_075446|  -0.19863 -0.71902  0.15616  0.81354 -0.49761 -0.06255]
21Feb13_075446| [-0.24706 -0.06008 -0.57834  0.30502 -0.16921 -0.90075  0.78975 -0.91475
21Feb13_075446|   0.17278 -0.06501 -0.82514  0.42792  0.50567  0.31420]
21Feb13_075446| [ 0.19858  0.27139 -0.66526  0.22931 -0.91885 -0.57502  0.66730 -0.08919
21Feb13_075446|   0.48485  0.41713 -0.43555  0.42449 -0.02396  0.92678]
21Feb13_075446| [-0.26449 -0.66167  0.92432 -0.34591 -0.84237 -0.20862 -0.38663  0.70631
21Feb13_075446|  -0.58894  0.28492 -0.75196  0.78287 -0.76882  0.60073]
21Feb13_075446| [-0.90089  0.36008 -0.62836  0.05717  0.16910 -0.42677 -0.29327 -0.07989
21Feb13_075446|   0.83425 -0.46170 -0.83419  0.47481  0.22246  0.00845]
21Feb13_075446| [-0.01303 -0.79612  0.01337  0.96383  0.88888  0.40733  0.52040 -0.78910
21Feb13_075446|   0.54808  0.80667 -0.18360 -0.64126 -0.39695 -0.66319]
21Feb13_075446| [-0.88076  0.98424  0.92610  0.64666 -0.31894 -0.82556 -0.27707  0.04045
21Feb13_075446|   0.66390  0.99121 -0.43994 -0.56351 -0.88577 -0.78906]
21Feb13_075446| [-0.08809 -0.47914  0.74437  0.18616  0.14492  0.91897 -0.78420  0.19567
21Feb13_075446|   0.21651  0.11022 -0.63077  0.25838 -0.62852 -0.54420]
21Feb13_075446| [ 0.83666 -0.13041  0.11889  0.48108 -0.65844 -0.93334 -0.35183 -0.71039
21Feb13_075446|   0.25408  0.40921 -0.96035  0.03882  0.23292 -0.23146]
21Feb13_075446| [-0.42276 -0.88165  0.91051 -0.26078 -0.60459 -0.88375  0.06035  0.28531
21Feb13_075446|  -0.85402  0.32638  0.75647 -0.52785  0.49295  0.07150]
21Feb13_075446| [ 0.41227 -0.53332 -0.86738  0.05626  0.12633 -0.18304  0.78693  0.76589
21Feb13_075446|   0.23618  0.20811  0.34520 -0.59405 -0.24790 -0.64175]
21Feb13_075446| [ 0.16112  0.08361  0.09088  0.19541 -0.26349  0.25044 -0.58915  0.33944
21Feb13_075446|  -0.83164  0.61911  0.32780 -0.96216  0.97785 -0.34160]
21Feb13_075446| [ 0.42787 -0.25634 -0.11060  0.91572  0.65583 -0.19126  0.55396 -0.93986
21Feb13_075446|   0.87875  0.03214 -0.49125 -0.78175 -0.92747  0.36487]
21Feb13_075446| [-0.74605 -0.47039  0.66455 -0.40278 -0.45182 -0.79306 -0.10554 -0.06691
21Feb13_075446|   0.41563 -0.07006  0.15794 -0.88368 -0.54811  0.06069]
21Feb13_075446| [-0.25592 -0.72120 -0.35502 -0.55513  0.21451 -0.66825  0.21368  0.77818
21Feb13_075446|   0.95608 -0.27384 -0.23671 -0.50859 -0.15268  0.22426]]
21Feb13_075446|-- Bias --
21Feb13_075446|[-0.31320 -0.24309  0.70469  0.03150 -0.67450  0.49415  0.71057  0.56074
21Feb13_075446| -0.68882 -0.02550  0.88238 -0.30120  0.61236 -0.98547]
21Feb13_075446|Layer 1:
21Feb13_075446|-- Config --
21Feb13_075446|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 14], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075446|-- Weights --
21Feb13_075446|[[ 0.98573 -0.10612]
21Feb13_075446| [-0.84650 -0.91832]
21Feb13_075446| [-0.43497 -0.92411]
21Feb13_075446| [-0.33475  0.47765]
21Feb13_075446| [ 0.03103 -0.47578]
21Feb13_075446| [-0.40987 -0.23556]
21Feb13_075446| [ 0.94394  0.01566]
21Feb13_075446| [ 0.73003  0.37218]
21Feb13_075446| [ 0.70222 -0.45412]
21Feb13_075446| [-0.23121 -0.00197]
21Feb13_075446| [ 0.27099  0.18396]
21Feb13_075446| [ 0.80007  0.70964]
21Feb13_075446| [-0.41310  0.94902]
21Feb13_075446| [-0.11261 -0.90297]]
21Feb13_075446|-- Bias --
21Feb13_075446|[-0.28704  0.27496]
21Feb13_075446|Predicting the validation and test data with the Best initial individual.
21Feb13_075453| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_075453|-----------  ------------------  --------------------  ----------
21Feb13_075453|Validation         41.48                  14            0.01804
21Feb13_075453|   Test            36.40                  14            0.00298
21Feb13_075453|-------------------- Test #0 --------------------
21Feb13_075453|Best final individual weights
21Feb13_075453|Individual:
21Feb13_075453|-- Constant hidden layers --
21Feb13_075453|False
21Feb13_075453|Layer 0:
21Feb13_075453|-- Config --
21Feb13_075453|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075453|-- Weights --
21Feb13_075453|[[-0.98192  2.18776]
21Feb13_075453| [ 1.36181 -0.03133]
21Feb13_075453| [-1.51057 -0.81071]
21Feb13_075453| [-1.37120  1.24322]
21Feb13_075453| [-1.44656 -0.07166]
21Feb13_075453| [-0.33160 -0.54925]
21Feb13_075453| [-0.27603  0.05499]
21Feb13_075453| [-0.52643 -0.94541]
21Feb13_075453| [ 0.77352 -0.77929]
21Feb13_075453| [-0.78685  2.00375]
21Feb13_075453| [-0.03225  1.36285]
21Feb13_075453| [ 1.16759 -0.17512]
21Feb13_075453| [ 1.96945  0.65644]
21Feb13_075453| [ 0.34031 -0.28614]
21Feb13_075453| [ 0.21669  1.27974]
21Feb13_075453| [-0.53328 -0.04319]
21Feb13_075453| [ 0.31221 -0.99855]
21Feb13_075453| [-1.55754 -0.44905]
21Feb13_075453| [-0.29405 -0.47457]
21Feb13_075453| [ 0.07410 -1.47955]
21Feb13_075453| [ 0.81225  0.24792]
21Feb13_075453| [-0.25531 -0.63857]
21Feb13_075453| [-0.60003  1.02933]
21Feb13_075453| [-0.24001  0.01843]
21Feb13_075453| [-0.25906 -0.23601]
21Feb13_075453| [-0.80102 -0.75297]
21Feb13_075453| [-0.54057 -1.70199]
21Feb13_075453| [-0.42099  1.19162]
21Feb13_075453| [-2.56151  0.59214]
21Feb13_075453| [ 0.57421  0.12865]
21Feb13_075453| [-0.29238 -1.00280]
21Feb13_075453| [-1.46771  0.48386]
21Feb13_075453| [ 0.17135 -0.70636]
21Feb13_075453| [ 0.35498  0.20340]
21Feb13_075453| [-0.43889  1.20021]
21Feb13_075453| [ 0.04770  0.49488]
21Feb13_075453| [-0.46033  0.84764]
21Feb13_075453| [-0.41902 -0.98022]
21Feb13_075453| [ 1.81072 -0.77099]
21Feb13_075453| [-1.74697  0.59184]
21Feb13_075453| [ 1.64992  0.11187]
21Feb13_075453| [ 0.77992  0.37821]
21Feb13_075453| [-2.12165  2.01171]
21Feb13_075453| [ 1.30141  1.24190]
21Feb13_075453| [ 1.24811 -0.28526]
21Feb13_075453| [-0.54868  0.03093]
21Feb13_075453| [-0.31287 -0.08426]
21Feb13_075453| [ 0.94870 -0.94260]
21Feb13_075453| [-0.12743 -0.51211]
21Feb13_075453| [ 0.53225  0.44268]
21Feb13_075453| [ 0.80939  1.09781]
21Feb13_075453| [-0.22462 -1.82410]
21Feb13_075453| [ 0.07646 -0.26167]
21Feb13_075453| [ 1.52753 -0.23276]
21Feb13_075453| [ 0.16874  1.20935]
21Feb13_075453| [-1.32969  1.07150]
21Feb13_075453| [ 0.09808 -0.38115]]
21Feb13_075453|-- Bias --
21Feb13_075453|[-1.01651  0.89052]
21Feb13_075453|Layer 1:
21Feb13_075453|-- Config --
21Feb13_075453|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075453|-- Weights --
21Feb13_075453|[[-0.02046  0.03273 -0.59168]
21Feb13_075453| [-0.47079  0.41283 -0.44959]]
21Feb13_075453|-- Bias --
21Feb13_075453|[0.70671 0.25419 0.80107]
21Feb13_075453|Layer 2:
21Feb13_075453|-- Config --
21Feb13_075453|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075453|-- Weights --
21Feb13_075453|[[-0.64505  1.37443]
21Feb13_075453| [ 0.11218 -0.02318]
21Feb13_075453| [ 0.72243  0.09855]]
21Feb13_075453|-- Bias --
21Feb13_075453|[1.01305 0.99977]
21Feb13_075453|Predicting the validation and test data with the Best final individual.
21Feb13_075500| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_075500|-----------  ------------------  --------------------  ----------
21Feb13_075500|Validation         28.52                  10            0.47976
21Feb13_075500|   Test            27.37                  10            0.68560
21Feb13_075500|-------------------- Test #1 --------------------
21Feb13_075500|Best final individual weights
21Feb13_075500|Individual:
21Feb13_075500|-- Constant hidden layers --
21Feb13_075500|False
21Feb13_075500|Layer 0:
21Feb13_075500|-- Config --
21Feb13_075500|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075500|-- Weights --
21Feb13_075500|[[-0.98192  2.18776]
21Feb13_075500| [ 1.36181 -0.03133]
21Feb13_075500| [-1.51057 -0.81071]
21Feb13_075500| [-1.37120  1.24322]
21Feb13_075500| [-1.44656 -0.07166]
21Feb13_075500| [-0.33160 -0.54925]
21Feb13_075500| [-0.27603  0.05499]
21Feb13_075500| [-0.52643 -0.94541]
21Feb13_075500| [ 0.77352 -0.77929]
21Feb13_075500| [-0.78685  2.00375]
21Feb13_075500| [-0.03225  1.36285]
21Feb13_075500| [ 1.16759 -0.17512]
21Feb13_075500| [ 1.96945  0.65644]
21Feb13_075500| [ 0.34031 -0.28614]
21Feb13_075500| [ 0.21669  1.27974]
21Feb13_075500| [-0.53328 -0.04319]
21Feb13_075500| [ 0.31221 -0.99855]
21Feb13_075500| [-1.55754 -0.44905]
21Feb13_075500| [-0.29405 -0.47457]
21Feb13_075500| [ 0.07410 -1.47955]
21Feb13_075500| [ 0.81225  0.24792]
21Feb13_075500| [-0.25531 -0.63857]
21Feb13_075500| [-0.60003  1.02933]
21Feb13_075500| [-0.24001  0.01843]
21Feb13_075500| [-0.25906 -0.23601]
21Feb13_075500| [-0.80102 -0.75297]
21Feb13_075500| [-0.54057 -1.70199]
21Feb13_075500| [-0.42099  1.19162]
21Feb13_075500| [-2.56151  0.59214]
21Feb13_075500| [ 0.57421  0.12865]
21Feb13_075500| [-0.29238 -1.00280]
21Feb13_075500| [-1.46771  0.48386]
21Feb13_075500| [ 0.17135 -0.70636]
21Feb13_075500| [ 0.35498  0.20340]
21Feb13_075500| [-0.43889  1.20021]
21Feb13_075500| [ 0.04770  0.49488]
21Feb13_075500| [-0.46033  0.84764]
21Feb13_075500| [-0.41902 -0.98022]
21Feb13_075500| [ 1.81072 -0.77099]
21Feb13_075500| [-1.74697  0.59184]
21Feb13_075500| [ 1.64992  0.11187]
21Feb13_075500| [ 0.77992  0.37821]
21Feb13_075500| [-2.12165  2.01171]
21Feb13_075500| [ 1.30141  1.24190]
21Feb13_075500| [ 1.24811 -0.28526]
21Feb13_075500| [-0.54868  0.03093]
21Feb13_075500| [-0.31287 -0.08426]
21Feb13_075500| [ 0.94870 -0.94260]
21Feb13_075500| [-0.12743 -0.51211]
21Feb13_075500| [ 0.53225  0.44268]
21Feb13_075500| [ 0.80939  1.09781]
21Feb13_075500| [-0.22462 -1.82410]
21Feb13_075500| [ 0.07646 -0.26167]
21Feb13_075500| [ 1.52753 -0.23276]
21Feb13_075500| [ 0.16874  1.20935]
21Feb13_075500| [-1.32969  1.07150]
21Feb13_075500| [ 0.09808 -0.38115]]
21Feb13_075500|-- Bias --
21Feb13_075500|[-1.01651  0.89052]
21Feb13_075500|Layer 1:
21Feb13_075500|-- Config --
21Feb13_075500|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075500|-- Weights --
21Feb13_075500|[[-0.02046  0.03273 -0.59168]
21Feb13_075500| [-0.47079  0.41283 -0.44959]]
21Feb13_075500|-- Bias --
21Feb13_075500|[0.70671 0.25419 0.80107]
21Feb13_075500|Layer 2:
21Feb13_075500|-- Config --
21Feb13_075500|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075500|-- Weights --
21Feb13_075500|[[-0.64505  1.37443]
21Feb13_075500| [ 0.11218 -0.02318]
21Feb13_075500| [ 0.72243  0.09855]]
21Feb13_075500|-- Bias --
21Feb13_075500|[1.01305 0.99977]
21Feb13_075500|Predicting the validation and test data with the Best final individual.
21Feb13_075508| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_075508|-----------  ------------------  --------------------  ----------
21Feb13_075508|Validation         27.48                  10            0.66069
21Feb13_075508|   Test            36.40                  10            0.00000
21Feb13_075508|-------------------- Test #2 --------------------
21Feb13_075508|Best final individual weights
21Feb13_075508|Individual:
21Feb13_075508|-- Constant hidden layers --
21Feb13_075508|False
21Feb13_075508|Layer 0:
21Feb13_075508|-- Config --
21Feb13_075508|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075508|-- Weights --
21Feb13_075508|[[-0.98192  2.18776]
21Feb13_075508| [ 1.36181 -0.03133]
21Feb13_075508| [-1.51057 -0.81071]
21Feb13_075508| [-1.37120  1.24322]
21Feb13_075508| [-1.44656 -0.07166]
21Feb13_075508| [-0.33160 -0.54925]
21Feb13_075508| [-0.27603  0.05499]
21Feb13_075508| [-0.52643 -0.94541]
21Feb13_075508| [ 0.77352 -0.77929]
21Feb13_075508| [-0.78685  2.00375]
21Feb13_075508| [-0.03225  1.36285]
21Feb13_075508| [ 1.16759 -0.17512]
21Feb13_075508| [ 1.96945  0.65644]
21Feb13_075508| [ 0.34031 -0.28614]
21Feb13_075508| [ 0.21669  1.27974]
21Feb13_075508| [-0.53328 -0.04319]
21Feb13_075508| [ 0.31221 -0.99855]
21Feb13_075508| [-1.55754 -0.44905]
21Feb13_075508| [-0.29405 -0.47457]
21Feb13_075508| [ 0.07410 -1.47955]
21Feb13_075508| [ 0.81225  0.24792]
21Feb13_075508| [-0.25531 -0.63857]
21Feb13_075508| [-0.60003  1.02933]
21Feb13_075508| [-0.24001  0.01843]
21Feb13_075508| [-0.25906 -0.23601]
21Feb13_075508| [-0.80102 -0.75297]
21Feb13_075508| [-0.54057 -1.70199]
21Feb13_075508| [-0.42099  1.19162]
21Feb13_075508| [-2.56151  0.59214]
21Feb13_075508| [ 0.57421  0.12865]
21Feb13_075508| [-0.29238 -1.00280]
21Feb13_075508| [-1.46771  0.48386]
21Feb13_075508| [ 0.17135 -0.70636]
21Feb13_075508| [ 0.35498  0.20340]
21Feb13_075508| [-0.43889  1.20021]
21Feb13_075508| [ 0.04770  0.49488]
21Feb13_075508| [-0.46033  0.84764]
21Feb13_075508| [-0.41902 -0.98022]
21Feb13_075508| [ 1.81072 -0.77099]
21Feb13_075508| [-1.74697  0.59184]
21Feb13_075508| [ 1.64992  0.11187]
21Feb13_075508| [ 0.77992  0.37821]
21Feb13_075508| [-2.12165  2.01171]
21Feb13_075508| [ 1.30141  1.24190]
21Feb13_075508| [ 1.24811 -0.28526]
21Feb13_075508| [-0.54868  0.03093]
21Feb13_075508| [-0.31287 -0.08426]
21Feb13_075508| [ 0.94870 -0.94260]
21Feb13_075508| [-0.12743 -0.51211]
21Feb13_075508| [ 0.53225  0.44268]
21Feb13_075508| [ 0.80939  1.09781]
21Feb13_075508| [-0.22462 -1.82410]
21Feb13_075508| [ 0.07646 -0.26167]
21Feb13_075508| [ 1.52753 -0.23276]
21Feb13_075508| [ 0.16874  1.20935]
21Feb13_075508| [-1.32969  1.07150]
21Feb13_075508| [ 0.09808 -0.38115]]
21Feb13_075508|-- Bias --
21Feb13_075508|[-1.01651  0.89052]
21Feb13_075508|Layer 1:
21Feb13_075508|-- Config --
21Feb13_075508|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075508|-- Weights --
21Feb13_075508|[[-0.02046  0.03273 -0.59168]
21Feb13_075508| [-0.47079  0.41283 -0.44959]]
21Feb13_075508|-- Bias --
21Feb13_075508|[0.70671 0.25419 0.80107]
21Feb13_075508|Layer 2:
21Feb13_075508|-- Config --
21Feb13_075508|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075508|-- Weights --
21Feb13_075508|[[-0.64505  1.37443]
21Feb13_075508| [ 0.11218 -0.02318]
21Feb13_075508| [ 0.72243  0.09855]]
21Feb13_075508|-- Bias --
21Feb13_075508|[1.01305 0.99977]
21Feb13_075508|Predicting the validation and test data with the Best final individual.
21Feb13_075515| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_075515|-----------  ------------------  --------------------  ----------
21Feb13_075515|Validation         42.00                  10            0.00000
21Feb13_075515|   Test            27.72                  10            0.53785
21Feb13_075515|-------------------- Test #3 --------------------
21Feb13_075515|Best final individual weights
21Feb13_075515|Individual:
21Feb13_075515|-- Constant hidden layers --
21Feb13_075515|False
21Feb13_075515|Layer 0:
21Feb13_075515|-- Config --
21Feb13_075515|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075515|-- Weights --
21Feb13_075515|[[-0.98192  2.18776]
21Feb13_075515| [ 1.36181 -0.03133]
21Feb13_075515| [-1.51057 -0.81071]
21Feb13_075515| [-1.37120  1.24322]
21Feb13_075515| [-1.44656 -0.07166]
21Feb13_075515| [-0.33160 -0.54925]
21Feb13_075515| [-0.27603  0.05499]
21Feb13_075515| [-0.52643 -0.94541]
21Feb13_075515| [ 0.77352 -0.77929]
21Feb13_075515| [-0.78685  2.00375]
21Feb13_075515| [-0.03225  1.36285]
21Feb13_075515| [ 1.16759 -0.17512]
21Feb13_075515| [ 1.96945  0.65644]
21Feb13_075515| [ 0.34031 -0.28614]
21Feb13_075515| [ 0.21669  1.27974]
21Feb13_075515| [-0.53328 -0.04319]
21Feb13_075515| [ 0.31221 -0.99855]
21Feb13_075515| [-1.55754 -0.44905]
21Feb13_075515| [-0.29405 -0.47457]
21Feb13_075515| [ 0.07410 -1.47955]
21Feb13_075515| [ 0.81225  0.24792]
21Feb13_075515| [-0.25531 -0.63857]
21Feb13_075515| [-0.60003  1.02933]
21Feb13_075515| [-0.24001  0.01843]
21Feb13_075515| [-0.25906 -0.23601]
21Feb13_075515| [-0.80102 -0.75297]
21Feb13_075515| [-0.54057 -1.70199]
21Feb13_075515| [-0.42099  1.19162]
21Feb13_075515| [-2.56151  0.59214]
21Feb13_075515| [ 0.57421  0.12865]
21Feb13_075515| [-0.29238 -1.00280]
21Feb13_075515| [-1.46771  0.48386]
21Feb13_075515| [ 0.17135 -0.70636]
21Feb13_075515| [ 0.35498  0.20340]
21Feb13_075515| [-0.43889  1.20021]
21Feb13_075515| [ 0.04770  0.49488]
21Feb13_075515| [-0.46033  0.84764]
21Feb13_075515| [-0.41902 -0.98022]
21Feb13_075515| [ 1.81072 -0.77099]
21Feb13_075515| [-1.74697  0.59184]
21Feb13_075515| [ 1.64992  0.11187]
21Feb13_075515| [ 0.77992  0.37821]
21Feb13_075515| [-2.12165  2.01171]
21Feb13_075515| [ 1.30141  1.24190]
21Feb13_075515| [ 1.24811 -0.28526]
21Feb13_075515| [-0.54868  0.03093]
21Feb13_075515| [-0.31287 -0.08426]
21Feb13_075515| [ 0.94870 -0.94260]
21Feb13_075515| [-0.12743 -0.51211]
21Feb13_075515| [ 0.53225  0.44268]
21Feb13_075515| [ 0.80939  1.09781]
21Feb13_075515| [-0.22462 -1.82410]
21Feb13_075515| [ 0.07646 -0.26167]
21Feb13_075515| [ 1.52753 -0.23276]
21Feb13_075515| [ 0.16874  1.20935]
21Feb13_075515| [-1.32969  1.07150]
21Feb13_075515| [ 0.09808 -0.38115]]
21Feb13_075515|-- Bias --
21Feb13_075515|[-1.01651  0.89052]
21Feb13_075515|Layer 1:
21Feb13_075515|-- Config --
21Feb13_075515|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075515|-- Weights --
21Feb13_075515|[[-0.02046  0.03273 -0.59168]
21Feb13_075515| [-0.47079  0.41283 -0.44959]]
21Feb13_075515|-- Bias --
21Feb13_075515|[0.70671 0.25419 0.80107]
21Feb13_075515|Layer 2:
21Feb13_075515|-- Config --
21Feb13_075515|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075515|-- Weights --
21Feb13_075515|[[-0.64505  1.37443]
21Feb13_075515| [ 0.11218 -0.02318]
21Feb13_075515| [ 0.72243  0.09855]]
21Feb13_075515|-- Bias --
21Feb13_075515|[1.01305 0.99977]
21Feb13_075515|Predicting the validation and test data with the Best final individual.
21Feb13_075522| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_075522|-----------  ------------------  --------------------  ----------
21Feb13_075522|Validation         30.00                  10            0.44831
21Feb13_075522|   Test            25.89                  10            0.41778
21Feb13_075522|-------------------- Test #4 --------------------
21Feb13_075522|Best final individual weights
21Feb13_075522|Individual:
21Feb13_075522|-- Constant hidden layers --
21Feb13_075522|False
21Feb13_075522|Layer 0:
21Feb13_075522|-- Config --
21Feb13_075522|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075522|-- Weights --
21Feb13_075522|[[-0.98192  2.18776]
21Feb13_075522| [ 1.36181 -0.03133]
21Feb13_075522| [-1.51057 -0.81071]
21Feb13_075522| [-1.37120  1.24322]
21Feb13_075522| [-1.44656 -0.07166]
21Feb13_075522| [-0.33160 -0.54925]
21Feb13_075522| [-0.27603  0.05499]
21Feb13_075522| [-0.52643 -0.94541]
21Feb13_075522| [ 0.77352 -0.77929]
21Feb13_075522| [-0.78685  2.00375]
21Feb13_075522| [-0.03225  1.36285]
21Feb13_075522| [ 1.16759 -0.17512]
21Feb13_075522| [ 1.96945  0.65644]
21Feb13_075522| [ 0.34031 -0.28614]
21Feb13_075522| [ 0.21669  1.27974]
21Feb13_075522| [-0.53328 -0.04319]
21Feb13_075522| [ 0.31221 -0.99855]
21Feb13_075522| [-1.55754 -0.44905]
21Feb13_075522| [-0.29405 -0.47457]
21Feb13_075522| [ 0.07410 -1.47955]
21Feb13_075522| [ 0.81225  0.24792]
21Feb13_075522| [-0.25531 -0.63857]
21Feb13_075522| [-0.60003  1.02933]
21Feb13_075522| [-0.24001  0.01843]
21Feb13_075522| [-0.25906 -0.23601]
21Feb13_075522| [-0.80102 -0.75297]
21Feb13_075522| [-0.54057 -1.70199]
21Feb13_075522| [-0.42099  1.19162]
21Feb13_075522| [-2.56151  0.59214]
21Feb13_075522| [ 0.57421  0.12865]
21Feb13_075522| [-0.29238 -1.00280]
21Feb13_075522| [-1.46771  0.48386]
21Feb13_075522| [ 0.17135 -0.70636]
21Feb13_075522| [ 0.35498  0.20340]
21Feb13_075522| [-0.43889  1.20021]
21Feb13_075522| [ 0.04770  0.49488]
21Feb13_075522| [-0.46033  0.84764]
21Feb13_075522| [-0.41902 -0.98022]
21Feb13_075522| [ 1.81072 -0.77099]
21Feb13_075522| [-1.74697  0.59184]
21Feb13_075522| [ 1.64992  0.11187]
21Feb13_075522| [ 0.77992  0.37821]
21Feb13_075522| [-2.12165  2.01171]
21Feb13_075522| [ 1.30141  1.24190]
21Feb13_075522| [ 1.24811 -0.28526]
21Feb13_075522| [-0.54868  0.03093]
21Feb13_075522| [-0.31287 -0.08426]
21Feb13_075522| [ 0.94870 -0.94260]
21Feb13_075522| [-0.12743 -0.51211]
21Feb13_075522| [ 0.53225  0.44268]
21Feb13_075522| [ 0.80939  1.09781]
21Feb13_075522| [-0.22462 -1.82410]
21Feb13_075522| [ 0.07646 -0.26167]
21Feb13_075522| [ 1.52753 -0.23276]
21Feb13_075522| [ 0.16874  1.20935]
21Feb13_075522| [-1.32969  1.07150]
21Feb13_075522| [ 0.09808 -0.38115]]
21Feb13_075522|-- Bias --
21Feb13_075522|[-1.01651  0.89052]
21Feb13_075522|Layer 1:
21Feb13_075522|-- Config --
21Feb13_075522|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075522|-- Weights --
21Feb13_075522|[[-0.02046  0.03273 -0.59168]
21Feb13_075522| [-0.47079  0.41283 -0.44959]]
21Feb13_075522|-- Bias --
21Feb13_075522|[0.70671 0.25419 0.80107]
21Feb13_075522|Layer 2:
21Feb13_075522|-- Config --
21Feb13_075522|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075522|-- Weights --
21Feb13_075522|[[-0.64505  1.37443]
21Feb13_075522| [ 0.11218 -0.02318]
21Feb13_075522| [ 0.72243  0.09855]]
21Feb13_075522|-- Bias --
21Feb13_075522|[1.01305 0.99977]
21Feb13_075522|Predicting the validation and test data with the Best final individual.
21Feb13_075530| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_075530|-----------  ------------------  --------------------  ----------
21Feb13_075530|Validation         28.52                  10            0.49436
21Feb13_075530|   Test            36.40                  10            0.00000
21Feb13_075530|-------------------- Test #5 --------------------
21Feb13_075530|Best final individual weights
21Feb13_075530|Individual:
21Feb13_075530|-- Constant hidden layers --
21Feb13_075530|False
21Feb13_075530|Layer 0:
21Feb13_075530|-- Config --
21Feb13_075530|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075530|-- Weights --
21Feb13_075530|[[-0.98192  2.18776]
21Feb13_075530| [ 1.36181 -0.03133]
21Feb13_075530| [-1.51057 -0.81071]
21Feb13_075530| [-1.37120  1.24322]
21Feb13_075530| [-1.44656 -0.07166]
21Feb13_075530| [-0.33160 -0.54925]
21Feb13_075530| [-0.27603  0.05499]
21Feb13_075530| [-0.52643 -0.94541]
21Feb13_075530| [ 0.77352 -0.77929]
21Feb13_075530| [-0.78685  2.00375]
21Feb13_075530| [-0.03225  1.36285]
21Feb13_075530| [ 1.16759 -0.17512]
21Feb13_075530| [ 1.96945  0.65644]
21Feb13_075530| [ 0.34031 -0.28614]
21Feb13_075530| [ 0.21669  1.27974]
21Feb13_075530| [-0.53328 -0.04319]
21Feb13_075530| [ 0.31221 -0.99855]
21Feb13_075530| [-1.55754 -0.44905]
21Feb13_075530| [-0.29405 -0.47457]
21Feb13_075530| [ 0.07410 -1.47955]
21Feb13_075530| [ 0.81225  0.24792]
21Feb13_075530| [-0.25531 -0.63857]
21Feb13_075530| [-0.60003  1.02933]
21Feb13_075530| [-0.24001  0.01843]
21Feb13_075530| [-0.25906 -0.23601]
21Feb13_075530| [-0.80102 -0.75297]
21Feb13_075530| [-0.54057 -1.70199]
21Feb13_075530| [-0.42099  1.19162]
21Feb13_075530| [-2.56151  0.59214]
21Feb13_075530| [ 0.57421  0.12865]
21Feb13_075530| [-0.29238 -1.00280]
21Feb13_075530| [-1.46771  0.48386]
21Feb13_075530| [ 0.17135 -0.70636]
21Feb13_075530| [ 0.35498  0.20340]
21Feb13_075530| [-0.43889  1.20021]
21Feb13_075530| [ 0.04770  0.49488]
21Feb13_075530| [-0.46033  0.84764]
21Feb13_075530| [-0.41902 -0.98022]
21Feb13_075530| [ 1.81072 -0.77099]
21Feb13_075530| [-1.74697  0.59184]
21Feb13_075530| [ 1.64992  0.11187]
21Feb13_075530| [ 0.77992  0.37821]
21Feb13_075530| [-2.12165  2.01171]
21Feb13_075530| [ 1.30141  1.24190]
21Feb13_075530| [ 1.24811 -0.28526]
21Feb13_075530| [-0.54868  0.03093]
21Feb13_075530| [-0.31287 -0.08426]
21Feb13_075530| [ 0.94870 -0.94260]
21Feb13_075530| [-0.12743 -0.51211]
21Feb13_075530| [ 0.53225  0.44268]
21Feb13_075530| [ 0.80939  1.09781]
21Feb13_075530| [-0.22462 -1.82410]
21Feb13_075530| [ 0.07646 -0.26167]
21Feb13_075530| [ 1.52753 -0.23276]
21Feb13_075530| [ 0.16874  1.20935]
21Feb13_075530| [-1.32969  1.07150]
21Feb13_075530| [ 0.09808 -0.38115]]
21Feb13_075530|-- Bias --
21Feb13_075530|[-1.01651  0.89052]
21Feb13_075530|Layer 1:
21Feb13_075530|-- Config --
21Feb13_075530|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075530|-- Weights --
21Feb13_075530|[[-0.02046  0.03273 -0.59168]
21Feb13_075530| [-0.47079  0.41283 -0.44959]]
21Feb13_075530|-- Bias --
21Feb13_075530|[0.70671 0.25419 0.80107]
21Feb13_075530|Layer 2:
21Feb13_075530|-- Config --
21Feb13_075530|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075530|-- Weights --
21Feb13_075530|[[-0.64505  1.37443]
21Feb13_075530| [ 0.11218 -0.02318]
21Feb13_075530| [ 0.72243  0.09855]]
21Feb13_075530|-- Bias --
21Feb13_075530|[1.01305 0.99977]
21Feb13_075530|Predicting the validation and test data with the Best final individual.
21Feb13_075537| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_075537|-----------  ------------------  --------------------  ----------
21Feb13_075537|Validation         42.00                  10            0.00000
21Feb13_075537|   Test            36.40                  10            0.00000
21Feb13_075537|-------------------- Test #6 --------------------
21Feb13_075537|Best final individual weights
21Feb13_075537|Individual:
21Feb13_075537|-- Constant hidden layers --
21Feb13_075537|False
21Feb13_075537|Layer 0:
21Feb13_075537|-- Config --
21Feb13_075537|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075537|-- Weights --
21Feb13_075537|[[-0.98192  2.18776]
21Feb13_075537| [ 1.36181 -0.03133]
21Feb13_075537| [-1.51057 -0.81071]
21Feb13_075537| [-1.37120  1.24322]
21Feb13_075537| [-1.44656 -0.07166]
21Feb13_075537| [-0.33160 -0.54925]
21Feb13_075537| [-0.27603  0.05499]
21Feb13_075537| [-0.52643 -0.94541]
21Feb13_075537| [ 0.77352 -0.77929]
21Feb13_075537| [-0.78685  2.00375]
21Feb13_075537| [-0.03225  1.36285]
21Feb13_075537| [ 1.16759 -0.17512]
21Feb13_075537| [ 1.96945  0.65644]
21Feb13_075537| [ 0.34031 -0.28614]
21Feb13_075537| [ 0.21669  1.27974]
21Feb13_075537| [-0.53328 -0.04319]
21Feb13_075537| [ 0.31221 -0.99855]
21Feb13_075537| [-1.55754 -0.44905]
21Feb13_075537| [-0.29405 -0.47457]
21Feb13_075537| [ 0.07410 -1.47955]
21Feb13_075537| [ 0.81225  0.24792]
21Feb13_075537| [-0.25531 -0.63857]
21Feb13_075537| [-0.60003  1.02933]
21Feb13_075537| [-0.24001  0.01843]
21Feb13_075537| [-0.25906 -0.23601]
21Feb13_075537| [-0.80102 -0.75297]
21Feb13_075537| [-0.54057 -1.70199]
21Feb13_075537| [-0.42099  1.19162]
21Feb13_075537| [-2.56151  0.59214]
21Feb13_075537| [ 0.57421  0.12865]
21Feb13_075537| [-0.29238 -1.00280]
21Feb13_075537| [-1.46771  0.48386]
21Feb13_075537| [ 0.17135 -0.70636]
21Feb13_075537| [ 0.35498  0.20340]
21Feb13_075537| [-0.43889  1.20021]
21Feb13_075537| [ 0.04770  0.49488]
21Feb13_075537| [-0.46033  0.84764]
21Feb13_075537| [-0.41902 -0.98022]
21Feb13_075537| [ 1.81072 -0.77099]
21Feb13_075537| [-1.74697  0.59184]
21Feb13_075537| [ 1.64992  0.11187]
21Feb13_075537| [ 0.77992  0.37821]
21Feb13_075537| [-2.12165  2.01171]
21Feb13_075537| [ 1.30141  1.24190]
21Feb13_075537| [ 1.24811 -0.28526]
21Feb13_075537| [-0.54868  0.03093]
21Feb13_075537| [-0.31287 -0.08426]
21Feb13_075537| [ 0.94870 -0.94260]
21Feb13_075537| [-0.12743 -0.51211]
21Feb13_075537| [ 0.53225  0.44268]
21Feb13_075537| [ 0.80939  1.09781]
21Feb13_075537| [-0.22462 -1.82410]
21Feb13_075537| [ 0.07646 -0.26167]
21Feb13_075537| [ 1.52753 -0.23276]
21Feb13_075537| [ 0.16874  1.20935]
21Feb13_075537| [-1.32969  1.07150]
21Feb13_075537| [ 0.09808 -0.38115]]
21Feb13_075537|-- Bias --
21Feb13_075537|[-1.01651  0.89052]
21Feb13_075537|Layer 1:
21Feb13_075537|-- Config --
21Feb13_075537|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075537|-- Weights --
21Feb13_075537|[[-0.02046  0.03273 -0.59168]
21Feb13_075537| [-0.47079  0.41283 -0.44959]]
21Feb13_075537|-- Bias --
21Feb13_075537|[0.70671 0.25419 0.80107]
21Feb13_075537|Layer 2:
21Feb13_075537|-- Config --
21Feb13_075537|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075537|-- Weights --
21Feb13_075537|[[-0.64505  1.37443]
21Feb13_075537| [ 0.11218 -0.02318]
21Feb13_075537| [ 0.72243  0.09855]]
21Feb13_075537|-- Bias --
21Feb13_075537|[1.01305 0.99977]
21Feb13_075537|Predicting the validation and test data with the Best final individual.
21Feb13_075545| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_075545|-----------  ------------------  --------------------  ----------
21Feb13_075545|Validation         42.00                  10            0.00000
21Feb13_075545|   Test            36.40                  10            0.00000
21Feb13_075545|-------------------- Test #7 --------------------
21Feb13_075545|Best final individual weights
21Feb13_075545|Individual:
21Feb13_075545|-- Constant hidden layers --
21Feb13_075545|False
21Feb13_075545|Layer 0:
21Feb13_075545|-- Config --
21Feb13_075545|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075545|-- Weights --
21Feb13_075545|[[-0.98192  2.18776]
21Feb13_075545| [ 1.36181 -0.03133]
21Feb13_075545| [-1.51057 -0.81071]
21Feb13_075545| [-1.37120  1.24322]
21Feb13_075545| [-1.44656 -0.07166]
21Feb13_075545| [-0.33160 -0.54925]
21Feb13_075545| [-0.27603  0.05499]
21Feb13_075545| [-0.52643 -0.94541]
21Feb13_075545| [ 0.77352 -0.77929]
21Feb13_075545| [-0.78685  2.00375]
21Feb13_075545| [-0.03225  1.36285]
21Feb13_075545| [ 1.16759 -0.17512]
21Feb13_075545| [ 1.96945  0.65644]
21Feb13_075545| [ 0.34031 -0.28614]
21Feb13_075545| [ 0.21669  1.27974]
21Feb13_075545| [-0.53328 -0.04319]
21Feb13_075545| [ 0.31221 -0.99855]
21Feb13_075545| [-1.55754 -0.44905]
21Feb13_075545| [-0.29405 -0.47457]
21Feb13_075545| [ 0.07410 -1.47955]
21Feb13_075545| [ 0.81225  0.24792]
21Feb13_075545| [-0.25531 -0.63857]
21Feb13_075545| [-0.60003  1.02933]
21Feb13_075545| [-0.24001  0.01843]
21Feb13_075545| [-0.25906 -0.23601]
21Feb13_075545| [-0.80102 -0.75297]
21Feb13_075545| [-0.54057 -1.70199]
21Feb13_075545| [-0.42099  1.19162]
21Feb13_075545| [-2.56151  0.59214]
21Feb13_075545| [ 0.57421  0.12865]
21Feb13_075545| [-0.29238 -1.00280]
21Feb13_075545| [-1.46771  0.48386]
21Feb13_075545| [ 0.17135 -0.70636]
21Feb13_075545| [ 0.35498  0.20340]
21Feb13_075545| [-0.43889  1.20021]
21Feb13_075545| [ 0.04770  0.49488]
21Feb13_075545| [-0.46033  0.84764]
21Feb13_075545| [-0.41902 -0.98022]
21Feb13_075545| [ 1.81072 -0.77099]
21Feb13_075545| [-1.74697  0.59184]
21Feb13_075545| [ 1.64992  0.11187]
21Feb13_075545| [ 0.77992  0.37821]
21Feb13_075545| [-2.12165  2.01171]
21Feb13_075545| [ 1.30141  1.24190]
21Feb13_075545| [ 1.24811 -0.28526]
21Feb13_075545| [-0.54868  0.03093]
21Feb13_075545| [-0.31287 -0.08426]
21Feb13_075545| [ 0.94870 -0.94260]
21Feb13_075545| [-0.12743 -0.51211]
21Feb13_075545| [ 0.53225  0.44268]
21Feb13_075545| [ 0.80939  1.09781]
21Feb13_075545| [-0.22462 -1.82410]
21Feb13_075545| [ 0.07646 -0.26167]
21Feb13_075545| [ 1.52753 -0.23276]
21Feb13_075545| [ 0.16874  1.20935]
21Feb13_075545| [-1.32969  1.07150]
21Feb13_075545| [ 0.09808 -0.38115]]
21Feb13_075545|-- Bias --
21Feb13_075545|[-1.01651  0.89052]
21Feb13_075545|Layer 1:
21Feb13_075545|-- Config --
21Feb13_075545|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075545|-- Weights --
21Feb13_075545|[[-0.02046  0.03273 -0.59168]
21Feb13_075545| [-0.47079  0.41283 -0.44959]]
21Feb13_075545|-- Bias --
21Feb13_075545|[0.70671 0.25419 0.80107]
21Feb13_075545|Layer 2:
21Feb13_075545|-- Config --
21Feb13_075545|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075545|-- Weights --
21Feb13_075545|[[-0.64505  1.37443]
21Feb13_075545| [ 0.11218 -0.02318]
21Feb13_075545| [ 0.72243  0.09855]]
21Feb13_075545|-- Bias --
21Feb13_075545|[1.01305 0.99977]
21Feb13_075545|Predicting the validation and test data with the Best final individual.
21Feb13_075552| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_075552|-----------  ------------------  --------------------  ----------
21Feb13_075552|Validation         42.00                  10            0.00000
21Feb13_075552|   Test            26.85                  10            0.52073
21Feb13_075552|-------------------- Test #8 --------------------
21Feb13_075552|Best final individual weights
21Feb13_075552|Individual:
21Feb13_075552|-- Constant hidden layers --
21Feb13_075552|False
21Feb13_075552|Layer 0:
21Feb13_075552|-- Config --
21Feb13_075552|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075552|-- Weights --
21Feb13_075552|[[-0.98192  2.18776]
21Feb13_075552| [ 1.36181 -0.03133]
21Feb13_075552| [-1.51057 -0.81071]
21Feb13_075552| [-1.37120  1.24322]
21Feb13_075552| [-1.44656 -0.07166]
21Feb13_075552| [-0.33160 -0.54925]
21Feb13_075552| [-0.27603  0.05499]
21Feb13_075552| [-0.52643 -0.94541]
21Feb13_075552| [ 0.77352 -0.77929]
21Feb13_075552| [-0.78685  2.00375]
21Feb13_075552| [-0.03225  1.36285]
21Feb13_075552| [ 1.16759 -0.17512]
21Feb13_075552| [ 1.96945  0.65644]
21Feb13_075552| [ 0.34031 -0.28614]
21Feb13_075552| [ 0.21669  1.27974]
21Feb13_075552| [-0.53328 -0.04319]
21Feb13_075552| [ 0.31221 -0.99855]
21Feb13_075552| [-1.55754 -0.44905]
21Feb13_075552| [-0.29405 -0.47457]
21Feb13_075552| [ 0.07410 -1.47955]
21Feb13_075552| [ 0.81225  0.24792]
21Feb13_075552| [-0.25531 -0.63857]
21Feb13_075552| [-0.60003  1.02933]
21Feb13_075552| [-0.24001  0.01843]
21Feb13_075552| [-0.25906 -0.23601]
21Feb13_075552| [-0.80102 -0.75297]
21Feb13_075552| [-0.54057 -1.70199]
21Feb13_075552| [-0.42099  1.19162]
21Feb13_075552| [-2.56151  0.59214]
21Feb13_075552| [ 0.57421  0.12865]
21Feb13_075552| [-0.29238 -1.00280]
21Feb13_075552| [-1.46771  0.48386]
21Feb13_075552| [ 0.17135 -0.70636]
21Feb13_075552| [ 0.35498  0.20340]
21Feb13_075552| [-0.43889  1.20021]
21Feb13_075552| [ 0.04770  0.49488]
21Feb13_075552| [-0.46033  0.84764]
21Feb13_075552| [-0.41902 -0.98022]
21Feb13_075552| [ 1.81072 -0.77099]
21Feb13_075552| [-1.74697  0.59184]
21Feb13_075552| [ 1.64992  0.11187]
21Feb13_075552| [ 0.77992  0.37821]
21Feb13_075552| [-2.12165  2.01171]
21Feb13_075552| [ 1.30141  1.24190]
21Feb13_075552| [ 1.24811 -0.28526]
21Feb13_075552| [-0.54868  0.03093]
21Feb13_075552| [-0.31287 -0.08426]
21Feb13_075552| [ 0.94870 -0.94260]
21Feb13_075552| [-0.12743 -0.51211]
21Feb13_075552| [ 0.53225  0.44268]
21Feb13_075552| [ 0.80939  1.09781]
21Feb13_075552| [-0.22462 -1.82410]
21Feb13_075552| [ 0.07646 -0.26167]
21Feb13_075552| [ 1.52753 -0.23276]
21Feb13_075552| [ 0.16874  1.20935]
21Feb13_075552| [-1.32969  1.07150]
21Feb13_075552| [ 0.09808 -0.38115]]
21Feb13_075552|-- Bias --
21Feb13_075552|[-1.01651  0.89052]
21Feb13_075552|Layer 1:
21Feb13_075552|-- Config --
21Feb13_075552|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075552|-- Weights --
21Feb13_075552|[[-0.02046  0.03273 -0.59168]
21Feb13_075552| [-0.47079  0.41283 -0.44959]]
21Feb13_075552|-- Bias --
21Feb13_075552|[0.70671 0.25419 0.80107]
21Feb13_075552|Layer 2:
21Feb13_075552|-- Config --
21Feb13_075552|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075552|-- Weights --
21Feb13_075552|[[-0.64505  1.37443]
21Feb13_075552| [ 0.11218 -0.02318]
21Feb13_075552| [ 0.72243  0.09855]]
21Feb13_075552|-- Bias --
21Feb13_075552|[1.01305 0.99977]
21Feb13_075552|Predicting the validation and test data with the Best final individual.
21Feb13_075559| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_075559|-----------  ------------------  --------------------  ----------
21Feb13_075559|Validation         32.87                  10            0.35059
21Feb13_075559|   Test            25.72                  10            0.43813
21Feb13_075559|-------------------- Test #9 --------------------
21Feb13_075559|Best final individual weights
21Feb13_075559|Individual:
21Feb13_075559|-- Constant hidden layers --
21Feb13_075559|False
21Feb13_075559|Layer 0:
21Feb13_075559|-- Config --
21Feb13_075559|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075559|-- Weights --
21Feb13_075559|[[-0.98192  2.18776]
21Feb13_075559| [ 1.36181 -0.03133]
21Feb13_075559| [-1.51057 -0.81071]
21Feb13_075559| [-1.37120  1.24322]
21Feb13_075559| [-1.44656 -0.07166]
21Feb13_075559| [-0.33160 -0.54925]
21Feb13_075559| [-0.27603  0.05499]
21Feb13_075559| [-0.52643 -0.94541]
21Feb13_075559| [ 0.77352 -0.77929]
21Feb13_075559| [-0.78685  2.00375]
21Feb13_075559| [-0.03225  1.36285]
21Feb13_075559| [ 1.16759 -0.17512]
21Feb13_075559| [ 1.96945  0.65644]
21Feb13_075559| [ 0.34031 -0.28614]
21Feb13_075559| [ 0.21669  1.27974]
21Feb13_075559| [-0.53328 -0.04319]
21Feb13_075559| [ 0.31221 -0.99855]
21Feb13_075559| [-1.55754 -0.44905]
21Feb13_075559| [-0.29405 -0.47457]
21Feb13_075559| [ 0.07410 -1.47955]
21Feb13_075559| [ 0.81225  0.24792]
21Feb13_075559| [-0.25531 -0.63857]
21Feb13_075559| [-0.60003  1.02933]
21Feb13_075559| [-0.24001  0.01843]
21Feb13_075559| [-0.25906 -0.23601]
21Feb13_075559| [-0.80102 -0.75297]
21Feb13_075559| [-0.54057 -1.70199]
21Feb13_075559| [-0.42099  1.19162]
21Feb13_075559| [-2.56151  0.59214]
21Feb13_075559| [ 0.57421  0.12865]
21Feb13_075559| [-0.29238 -1.00280]
21Feb13_075559| [-1.46771  0.48386]
21Feb13_075559| [ 0.17135 -0.70636]
21Feb13_075559| [ 0.35498  0.20340]
21Feb13_075559| [-0.43889  1.20021]
21Feb13_075559| [ 0.04770  0.49488]
21Feb13_075559| [-0.46033  0.84764]
21Feb13_075559| [-0.41902 -0.98022]
21Feb13_075559| [ 1.81072 -0.77099]
21Feb13_075559| [-1.74697  0.59184]
21Feb13_075559| [ 1.64992  0.11187]
21Feb13_075559| [ 0.77992  0.37821]
21Feb13_075559| [-2.12165  2.01171]
21Feb13_075559| [ 1.30141  1.24190]
21Feb13_075559| [ 1.24811 -0.28526]
21Feb13_075559| [-0.54868  0.03093]
21Feb13_075559| [-0.31287 -0.08426]
21Feb13_075559| [ 0.94870 -0.94260]
21Feb13_075559| [-0.12743 -0.51211]
21Feb13_075559| [ 0.53225  0.44268]
21Feb13_075559| [ 0.80939  1.09781]
21Feb13_075559| [-0.22462 -1.82410]
21Feb13_075559| [ 0.07646 -0.26167]
21Feb13_075559| [ 1.52753 -0.23276]
21Feb13_075559| [ 0.16874  1.20935]
21Feb13_075559| [-1.32969  1.07150]
21Feb13_075559| [ 0.09808 -0.38115]]
21Feb13_075559|-- Bias --
21Feb13_075559|[-1.01651  0.89052]
21Feb13_075559|Layer 1:
21Feb13_075559|-- Config --
21Feb13_075559|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075559|-- Weights --
21Feb13_075559|[[-0.02046  0.03273 -0.59168]
21Feb13_075559| [-0.47079  0.41283 -0.44959]]
21Feb13_075559|-- Bias --
21Feb13_075559|[0.70671 0.25419 0.80107]
21Feb13_075559|Layer 2:
21Feb13_075559|-- Config --
21Feb13_075559|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075559|-- Weights --
21Feb13_075559|[[-0.64505  1.37443]
21Feb13_075559| [ 0.11218 -0.02318]
21Feb13_075559| [ 0.72243  0.09855]]
21Feb13_075559|-- Bias --
21Feb13_075559|[1.01305 0.99977]
21Feb13_075559|Predicting the validation and test data with the Best final individual.
21Feb13_075606| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_075606|-----------  ------------------  --------------------  ----------
21Feb13_075606|Validation         30.78                  10            0.41801
21Feb13_075606|   Test            36.40                  10            0.00000
21Feb13_075606|-------------------- Test #10 --------------------
21Feb13_075606|Best final individual weights
21Feb13_075606|Individual:
21Feb13_075606|-- Constant hidden layers --
21Feb13_075606|False
21Feb13_075606|Layer 0:
21Feb13_075606|-- Config --
21Feb13_075606|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075606|-- Weights --
21Feb13_075606|[[-0.98192  2.18776]
21Feb13_075606| [ 1.36181 -0.03133]
21Feb13_075606| [-1.51057 -0.81071]
21Feb13_075606| [-1.37120  1.24322]
21Feb13_075606| [-1.44656 -0.07166]
21Feb13_075606| [-0.33160 -0.54925]
21Feb13_075606| [-0.27603  0.05499]
21Feb13_075606| [-0.52643 -0.94541]
21Feb13_075606| [ 0.77352 -0.77929]
21Feb13_075606| [-0.78685  2.00375]
21Feb13_075606| [-0.03225  1.36285]
21Feb13_075606| [ 1.16759 -0.17512]
21Feb13_075606| [ 1.96945  0.65644]
21Feb13_075606| [ 0.34031 -0.28614]
21Feb13_075606| [ 0.21669  1.27974]
21Feb13_075606| [-0.53328 -0.04319]
21Feb13_075606| [ 0.31221 -0.99855]
21Feb13_075606| [-1.55754 -0.44905]
21Feb13_075606| [-0.29405 -0.47457]
21Feb13_075606| [ 0.07410 -1.47955]
21Feb13_075606| [ 0.81225  0.24792]
21Feb13_075606| [-0.25531 -0.63857]
21Feb13_075606| [-0.60003  1.02933]
21Feb13_075606| [-0.24001  0.01843]
21Feb13_075606| [-0.25906 -0.23601]
21Feb13_075606| [-0.80102 -0.75297]
21Feb13_075606| [-0.54057 -1.70199]
21Feb13_075606| [-0.42099  1.19162]
21Feb13_075606| [-2.56151  0.59214]
21Feb13_075606| [ 0.57421  0.12865]
21Feb13_075606| [-0.29238 -1.00280]
21Feb13_075606| [-1.46771  0.48386]
21Feb13_075606| [ 0.17135 -0.70636]
21Feb13_075606| [ 0.35498  0.20340]
21Feb13_075606| [-0.43889  1.20021]
21Feb13_075606| [ 0.04770  0.49488]
21Feb13_075606| [-0.46033  0.84764]
21Feb13_075606| [-0.41902 -0.98022]
21Feb13_075606| [ 1.81072 -0.77099]
21Feb13_075606| [-1.74697  0.59184]
21Feb13_075606| [ 1.64992  0.11187]
21Feb13_075606| [ 0.77992  0.37821]
21Feb13_075606| [-2.12165  2.01171]
21Feb13_075606| [ 1.30141  1.24190]
21Feb13_075606| [ 1.24811 -0.28526]
21Feb13_075606| [-0.54868  0.03093]
21Feb13_075606| [-0.31287 -0.08426]
21Feb13_075606| [ 0.94870 -0.94260]
21Feb13_075606| [-0.12743 -0.51211]
21Feb13_075606| [ 0.53225  0.44268]
21Feb13_075606| [ 0.80939  1.09781]
21Feb13_075606| [-0.22462 -1.82410]
21Feb13_075606| [ 0.07646 -0.26167]
21Feb13_075606| [ 1.52753 -0.23276]
21Feb13_075606| [ 0.16874  1.20935]
21Feb13_075606| [-1.32969  1.07150]
21Feb13_075606| [ 0.09808 -0.38115]]
21Feb13_075606|-- Bias --
21Feb13_075606|[-1.01651  0.89052]
21Feb13_075606|Layer 1:
21Feb13_075606|-- Config --
21Feb13_075606|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075606|-- Weights --
21Feb13_075606|[[-0.02046  0.03273 -0.59168]
21Feb13_075606| [-0.47079  0.41283 -0.44959]]
21Feb13_075606|-- Bias --
21Feb13_075606|[0.70671 0.25419 0.80107]
21Feb13_075606|Layer 2:
21Feb13_075606|-- Config --
21Feb13_075606|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075606|-- Weights --
21Feb13_075606|[[-0.64505  1.37443]
21Feb13_075606| [ 0.11218 -0.02318]
21Feb13_075606| [ 0.72243  0.09855]]
21Feb13_075606|-- Bias --
21Feb13_075606|[1.01305 0.99977]
21Feb13_075606|Predicting the validation and test data with the Best final individual.
21Feb13_075614| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_075614|-----------  ------------------  --------------------  ----------
21Feb13_075614|Validation         30.87                  10            0.37665
21Feb13_075614|   Test            27.37                  10            0.40512
21Feb13_075614|-------------------- Test #11 --------------------
21Feb13_075614|Best final individual weights
21Feb13_075614|Individual:
21Feb13_075614|-- Constant hidden layers --
21Feb13_075614|False
21Feb13_075614|Layer 0:
21Feb13_075614|-- Config --
21Feb13_075614|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075614|-- Weights --
21Feb13_075614|[[-0.98192  2.18776]
21Feb13_075614| [ 1.36181 -0.03133]
21Feb13_075614| [-1.51057 -0.81071]
21Feb13_075614| [-1.37120  1.24322]
21Feb13_075614| [-1.44656 -0.07166]
21Feb13_075614| [-0.33160 -0.54925]
21Feb13_075614| [-0.27603  0.05499]
21Feb13_075614| [-0.52643 -0.94541]
21Feb13_075614| [ 0.77352 -0.77929]
21Feb13_075614| [-0.78685  2.00375]
21Feb13_075614| [-0.03225  1.36285]
21Feb13_075614| [ 1.16759 -0.17512]
21Feb13_075614| [ 1.96945  0.65644]
21Feb13_075614| [ 0.34031 -0.28614]
21Feb13_075614| [ 0.21669  1.27974]
21Feb13_075614| [-0.53328 -0.04319]
21Feb13_075614| [ 0.31221 -0.99855]
21Feb13_075614| [-1.55754 -0.44905]
21Feb13_075614| [-0.29405 -0.47457]
21Feb13_075614| [ 0.07410 -1.47955]
21Feb13_075614| [ 0.81225  0.24792]
21Feb13_075614| [-0.25531 -0.63857]
21Feb13_075614| [-0.60003  1.02933]
21Feb13_075614| [-0.24001  0.01843]
21Feb13_075614| [-0.25906 -0.23601]
21Feb13_075614| [-0.80102 -0.75297]
21Feb13_075614| [-0.54057 -1.70199]
21Feb13_075614| [-0.42099  1.19162]
21Feb13_075614| [-2.56151  0.59214]
21Feb13_075614| [ 0.57421  0.12865]
21Feb13_075614| [-0.29238 -1.00280]
21Feb13_075614| [-1.46771  0.48386]
21Feb13_075614| [ 0.17135 -0.70636]
21Feb13_075614| [ 0.35498  0.20340]
21Feb13_075614| [-0.43889  1.20021]
21Feb13_075614| [ 0.04770  0.49488]
21Feb13_075614| [-0.46033  0.84764]
21Feb13_075614| [-0.41902 -0.98022]
21Feb13_075614| [ 1.81072 -0.77099]
21Feb13_075614| [-1.74697  0.59184]
21Feb13_075614| [ 1.64992  0.11187]
21Feb13_075614| [ 0.77992  0.37821]
21Feb13_075614| [-2.12165  2.01171]
21Feb13_075614| [ 1.30141  1.24190]
21Feb13_075614| [ 1.24811 -0.28526]
21Feb13_075614| [-0.54868  0.03093]
21Feb13_075614| [-0.31287 -0.08426]
21Feb13_075614| [ 0.94870 -0.94260]
21Feb13_075614| [-0.12743 -0.51211]
21Feb13_075614| [ 0.53225  0.44268]
21Feb13_075614| [ 0.80939  1.09781]
21Feb13_075614| [-0.22462 -1.82410]
21Feb13_075614| [ 0.07646 -0.26167]
21Feb13_075614| [ 1.52753 -0.23276]
21Feb13_075614| [ 0.16874  1.20935]
21Feb13_075614| [-1.32969  1.07150]
21Feb13_075614| [ 0.09808 -0.38115]]
21Feb13_075614|-- Bias --
21Feb13_075614|[-1.01651  0.89052]
21Feb13_075614|Layer 1:
21Feb13_075614|-- Config --
21Feb13_075614|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075614|-- Weights --
21Feb13_075614|[[-0.02046  0.03273 -0.59168]
21Feb13_075614| [-0.47079  0.41283 -0.44959]]
21Feb13_075614|-- Bias --
21Feb13_075614|[0.70671 0.25419 0.80107]
21Feb13_075614|Layer 2:
21Feb13_075614|-- Config --
21Feb13_075614|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075614|-- Weights --
21Feb13_075614|[[-0.64505  1.37443]
21Feb13_075614| [ 0.11218 -0.02318]
21Feb13_075614| [ 0.72243  0.09855]]
21Feb13_075614|-- Bias --
21Feb13_075614|[1.01305 0.99977]
21Feb13_075614|Predicting the validation and test data with the Best final individual.
21Feb13_075621| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_075621|-----------  ------------------  --------------------  ----------
21Feb13_075621|Validation         42.00                  10            0.00000
21Feb13_075621|   Test            36.40                  10            0.00000
21Feb13_075621|-------------------- Test #12 --------------------
21Feb13_075621|Best final individual weights
21Feb13_075621|Individual:
21Feb13_075621|-- Constant hidden layers --
21Feb13_075621|False
21Feb13_075621|Layer 0:
21Feb13_075621|-- Config --
21Feb13_075621|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075621|-- Weights --
21Feb13_075621|[[-0.98192  2.18776]
21Feb13_075621| [ 1.36181 -0.03133]
21Feb13_075621| [-1.51057 -0.81071]
21Feb13_075621| [-1.37120  1.24322]
21Feb13_075621| [-1.44656 -0.07166]
21Feb13_075621| [-0.33160 -0.54925]
21Feb13_075621| [-0.27603  0.05499]
21Feb13_075621| [-0.52643 -0.94541]
21Feb13_075621| [ 0.77352 -0.77929]
21Feb13_075621| [-0.78685  2.00375]
21Feb13_075621| [-0.03225  1.36285]
21Feb13_075621| [ 1.16759 -0.17512]
21Feb13_075621| [ 1.96945  0.65644]
21Feb13_075621| [ 0.34031 -0.28614]
21Feb13_075621| [ 0.21669  1.27974]
21Feb13_075621| [-0.53328 -0.04319]
21Feb13_075621| [ 0.31221 -0.99855]
21Feb13_075621| [-1.55754 -0.44905]
21Feb13_075621| [-0.29405 -0.47457]
21Feb13_075621| [ 0.07410 -1.47955]
21Feb13_075621| [ 0.81225  0.24792]
21Feb13_075621| [-0.25531 -0.63857]
21Feb13_075621| [-0.60003  1.02933]
21Feb13_075621| [-0.24001  0.01843]
21Feb13_075621| [-0.25906 -0.23601]
21Feb13_075621| [-0.80102 -0.75297]
21Feb13_075621| [-0.54057 -1.70199]
21Feb13_075621| [-0.42099  1.19162]
21Feb13_075621| [-2.56151  0.59214]
21Feb13_075621| [ 0.57421  0.12865]
21Feb13_075621| [-0.29238 -1.00280]
21Feb13_075621| [-1.46771  0.48386]
21Feb13_075621| [ 0.17135 -0.70636]
21Feb13_075621| [ 0.35498  0.20340]
21Feb13_075621| [-0.43889  1.20021]
21Feb13_075621| [ 0.04770  0.49488]
21Feb13_075621| [-0.46033  0.84764]
21Feb13_075621| [-0.41902 -0.98022]
21Feb13_075621| [ 1.81072 -0.77099]
21Feb13_075621| [-1.74697  0.59184]
21Feb13_075621| [ 1.64992  0.11187]
21Feb13_075621| [ 0.77992  0.37821]
21Feb13_075621| [-2.12165  2.01171]
21Feb13_075621| [ 1.30141  1.24190]
21Feb13_075621| [ 1.24811 -0.28526]
21Feb13_075621| [-0.54868  0.03093]
21Feb13_075621| [-0.31287 -0.08426]
21Feb13_075621| [ 0.94870 -0.94260]
21Feb13_075621| [-0.12743 -0.51211]
21Feb13_075621| [ 0.53225  0.44268]
21Feb13_075621| [ 0.80939  1.09781]
21Feb13_075621| [-0.22462 -1.82410]
21Feb13_075621| [ 0.07646 -0.26167]
21Feb13_075621| [ 1.52753 -0.23276]
21Feb13_075621| [ 0.16874  1.20935]
21Feb13_075621| [-1.32969  1.07150]
21Feb13_075621| [ 0.09808 -0.38115]]
21Feb13_075621|-- Bias --
21Feb13_075621|[-1.01651  0.89052]
21Feb13_075621|Layer 1:
21Feb13_075621|-- Config --
21Feb13_075621|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075621|-- Weights --
21Feb13_075621|[[-0.02046  0.03273 -0.59168]
21Feb13_075621| [-0.47079  0.41283 -0.44959]]
21Feb13_075621|-- Bias --
21Feb13_075621|[0.70671 0.25419 0.80107]
21Feb13_075621|Layer 2:
21Feb13_075621|-- Config --
21Feb13_075621|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075621|-- Weights --
21Feb13_075621|[[-0.64505  1.37443]
21Feb13_075621| [ 0.11218 -0.02318]
21Feb13_075621| [ 0.72243  0.09855]]
21Feb13_075621|-- Bias --
21Feb13_075621|[1.01305 0.99977]
21Feb13_075621|Predicting the validation and test data with the Best final individual.
21Feb13_075629| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_075629|-----------  ------------------  --------------------  ----------
21Feb13_075629|Validation         28.26                  10            0.45055
21Feb13_075629|   Test            30.84                  10            0.21801
21Feb13_075629|-------------------- Test #13 --------------------
21Feb13_075629|Best final individual weights
21Feb13_075629|Individual:
21Feb13_075629|-- Constant hidden layers --
21Feb13_075629|False
21Feb13_075629|Layer 0:
21Feb13_075629|-- Config --
21Feb13_075629|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075629|-- Weights --
21Feb13_075629|[[-0.98192  2.18776]
21Feb13_075629| [ 1.36181 -0.03133]
21Feb13_075629| [-1.51057 -0.81071]
21Feb13_075629| [-1.37120  1.24322]
21Feb13_075629| [-1.44656 -0.07166]
21Feb13_075629| [-0.33160 -0.54925]
21Feb13_075629| [-0.27603  0.05499]
21Feb13_075629| [-0.52643 -0.94541]
21Feb13_075629| [ 0.77352 -0.77929]
21Feb13_075629| [-0.78685  2.00375]
21Feb13_075629| [-0.03225  1.36285]
21Feb13_075629| [ 1.16759 -0.17512]
21Feb13_075629| [ 1.96945  0.65644]
21Feb13_075629| [ 0.34031 -0.28614]
21Feb13_075629| [ 0.21669  1.27974]
21Feb13_075629| [-0.53328 -0.04319]
21Feb13_075629| [ 0.31221 -0.99855]
21Feb13_075629| [-1.55754 -0.44905]
21Feb13_075629| [-0.29405 -0.47457]
21Feb13_075629| [ 0.07410 -1.47955]
21Feb13_075629| [ 0.81225  0.24792]
21Feb13_075629| [-0.25531 -0.63857]
21Feb13_075629| [-0.60003  1.02933]
21Feb13_075629| [-0.24001  0.01843]
21Feb13_075629| [-0.25906 -0.23601]
21Feb13_075629| [-0.80102 -0.75297]
21Feb13_075629| [-0.54057 -1.70199]
21Feb13_075629| [-0.42099  1.19162]
21Feb13_075629| [-2.56151  0.59214]
21Feb13_075629| [ 0.57421  0.12865]
21Feb13_075629| [-0.29238 -1.00280]
21Feb13_075629| [-1.46771  0.48386]
21Feb13_075629| [ 0.17135 -0.70636]
21Feb13_075629| [ 0.35498  0.20340]
21Feb13_075629| [-0.43889  1.20021]
21Feb13_075629| [ 0.04770  0.49488]
21Feb13_075629| [-0.46033  0.84764]
21Feb13_075629| [-0.41902 -0.98022]
21Feb13_075629| [ 1.81072 -0.77099]
21Feb13_075629| [-1.74697  0.59184]
21Feb13_075629| [ 1.64992  0.11187]
21Feb13_075629| [ 0.77992  0.37821]
21Feb13_075629| [-2.12165  2.01171]
21Feb13_075629| [ 1.30141  1.24190]
21Feb13_075629| [ 1.24811 -0.28526]
21Feb13_075629| [-0.54868  0.03093]
21Feb13_075629| [-0.31287 -0.08426]
21Feb13_075629| [ 0.94870 -0.94260]
21Feb13_075629| [-0.12743 -0.51211]
21Feb13_075629| [ 0.53225  0.44268]
21Feb13_075629| [ 0.80939  1.09781]
21Feb13_075629| [-0.22462 -1.82410]
21Feb13_075629| [ 0.07646 -0.26167]
21Feb13_075629| [ 1.52753 -0.23276]
21Feb13_075629| [ 0.16874  1.20935]
21Feb13_075629| [-1.32969  1.07150]
21Feb13_075629| [ 0.09808 -0.38115]]
21Feb13_075629|-- Bias --
21Feb13_075629|[-1.01651  0.89052]
21Feb13_075629|Layer 1:
21Feb13_075629|-- Config --
21Feb13_075629|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075629|-- Weights --
21Feb13_075629|[[-0.02046  0.03273 -0.59168]
21Feb13_075629| [-0.47079  0.41283 -0.44959]]
21Feb13_075629|-- Bias --
21Feb13_075629|[0.70671 0.25419 0.80107]
21Feb13_075629|Layer 2:
21Feb13_075629|-- Config --
21Feb13_075629|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075629|-- Weights --
21Feb13_075629|[[-0.64505  1.37443]
21Feb13_075629| [ 0.11218 -0.02318]
21Feb13_075629| [ 0.72243  0.09855]]
21Feb13_075629|-- Bias --
21Feb13_075629|[1.01305 0.99977]
21Feb13_075629|Predicting the validation and test data with the Best final individual.
21Feb13_075636| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_075636|-----------  ------------------  --------------------  ----------
21Feb13_075636|Validation         35.13                  10            0.23250
21Feb13_075636|   Test            33.54                  10            0.09655
21Feb13_075636|-------------------- Test #14 --------------------
21Feb13_075636|Best final individual weights
21Feb13_075636|Individual:
21Feb13_075636|-- Constant hidden layers --
21Feb13_075636|False
21Feb13_075636|Layer 0:
21Feb13_075636|-- Config --
21Feb13_075636|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 2, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075636|-- Weights --
21Feb13_075636|[[-0.98192  2.18776]
21Feb13_075636| [ 1.36181 -0.03133]
21Feb13_075636| [-1.51057 -0.81071]
21Feb13_075636| [-1.37120  1.24322]
21Feb13_075636| [-1.44656 -0.07166]
21Feb13_075636| [-0.33160 -0.54925]
21Feb13_075636| [-0.27603  0.05499]
21Feb13_075636| [-0.52643 -0.94541]
21Feb13_075636| [ 0.77352 -0.77929]
21Feb13_075636| [-0.78685  2.00375]
21Feb13_075636| [-0.03225  1.36285]
21Feb13_075636| [ 1.16759 -0.17512]
21Feb13_075636| [ 1.96945  0.65644]
21Feb13_075636| [ 0.34031 -0.28614]
21Feb13_075636| [ 0.21669  1.27974]
21Feb13_075636| [-0.53328 -0.04319]
21Feb13_075636| [ 0.31221 -0.99855]
21Feb13_075636| [-1.55754 -0.44905]
21Feb13_075636| [-0.29405 -0.47457]
21Feb13_075636| [ 0.07410 -1.47955]
21Feb13_075636| [ 0.81225  0.24792]
21Feb13_075636| [-0.25531 -0.63857]
21Feb13_075636| [-0.60003  1.02933]
21Feb13_075636| [-0.24001  0.01843]
21Feb13_075636| [-0.25906 -0.23601]
21Feb13_075636| [-0.80102 -0.75297]
21Feb13_075636| [-0.54057 -1.70199]
21Feb13_075636| [-0.42099  1.19162]
21Feb13_075636| [-2.56151  0.59214]
21Feb13_075636| [ 0.57421  0.12865]
21Feb13_075636| [-0.29238 -1.00280]
21Feb13_075636| [-1.46771  0.48386]
21Feb13_075636| [ 0.17135 -0.70636]
21Feb13_075636| [ 0.35498  0.20340]
21Feb13_075636| [-0.43889  1.20021]
21Feb13_075636| [ 0.04770  0.49488]
21Feb13_075636| [-0.46033  0.84764]
21Feb13_075636| [-0.41902 -0.98022]
21Feb13_075636| [ 1.81072 -0.77099]
21Feb13_075636| [-1.74697  0.59184]
21Feb13_075636| [ 1.64992  0.11187]
21Feb13_075636| [ 0.77992  0.37821]
21Feb13_075636| [-2.12165  2.01171]
21Feb13_075636| [ 1.30141  1.24190]
21Feb13_075636| [ 1.24811 -0.28526]
21Feb13_075636| [-0.54868  0.03093]
21Feb13_075636| [-0.31287 -0.08426]
21Feb13_075636| [ 0.94870 -0.94260]
21Feb13_075636| [-0.12743 -0.51211]
21Feb13_075636| [ 0.53225  0.44268]
21Feb13_075636| [ 0.80939  1.09781]
21Feb13_075636| [-0.22462 -1.82410]
21Feb13_075636| [ 0.07646 -0.26167]
21Feb13_075636| [ 1.52753 -0.23276]
21Feb13_075636| [ 0.16874  1.20935]
21Feb13_075636| [-1.32969  1.07150]
21Feb13_075636| [ 0.09808 -0.38115]]
21Feb13_075636|-- Bias --
21Feb13_075636|[-1.01651  0.89052]
21Feb13_075636|Layer 1:
21Feb13_075636|-- Config --
21Feb13_075636|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 2], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075636|-- Weights --
21Feb13_075636|[[-0.02046  0.03273 -0.59168]
21Feb13_075636| [-0.47079  0.41283 -0.44959]]
21Feb13_075636|-- Bias --
21Feb13_075636|[0.70671 0.25419 0.80107]
21Feb13_075636|Layer 2:
21Feb13_075636|-- Config --
21Feb13_075636|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_075636|-- Weights --
21Feb13_075636|[[-0.64505  1.37443]
21Feb13_075636| [ 0.11218 -0.02318]
21Feb13_075636| [ 0.72243  0.09855]]
21Feb13_075636|-- Bias --
21Feb13_075636|[1.01305 0.99977]
21Feb13_075636|Predicting the validation and test data with the Best final individual.
21Feb13_075643| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_075643|-----------  ------------------  --------------------  ----------
21Feb13_075643|Validation         28.00                  10            0.51190
21Feb13_075643|   Test            30.67                  10            0.78285
2021-02-13 07:56:44.397267: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
21Feb13_075645|Data summary: Train
21Feb13_075645|data.shape = (2300, 57)
21Feb13_075645|labels.shape = (2300,)
21Feb13_075645|Class distribution:
21Feb13_075645|	0 - 1389 (0.60)
21Feb13_075645|	1 - 911 (0.40)
21Feb13_075645|Data summary: Validation
21Feb13_075645|data.shape = (1150, 57)
21Feb13_075645|labels.shape = (1150,)
21Feb13_075645|Class distribution:
21Feb13_075645|	0 - 667 (0.58)
21Feb13_075645|	1 - 483 (0.42)
21Feb13_075645|Data summary: Test
21Feb13_075645|data.shape = (1151, 57)
21Feb13_075645|labels.shape = (1151,)
21Feb13_075645|Class distribution:
21Feb13_075645|	0 - 732 (0.64)
21Feb13_075645|	1 - 419 (0.36)
21Feb13_075645|Selected configuration values
21Feb13_075645|-- Dataset name: spambase2
21Feb13_075645|-- Initial population size: 64
21Feb13_075645|-- Maximun number of generations: 32
21Feb13_075645|-- Neurons per hidden layer range: (2, 20)
21Feb13_075645|-- Hidden layers number range: (1, 3)
21Feb13_075645|-- Crossover probability: 0.5
21Feb13_075645|-- Bias gene mutation probability: 0.2
21Feb13_075645|-- Weights gene mutation probability: 0.75
21Feb13_075645|-- Neuron mutation probability: 0.3
21Feb13_075645|-- Layer mutation probability: 0.3
21Feb13_075645|-- Constant hidden layers: False
21Feb13_075645|-- Seed: 31415
21Feb13_075645|Entering GA
21Feb13_075645|Start the algorithm
2021-02-13 07:56:45.278947: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-13 07:56:45.279504: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-02-13 07:56:45.303000: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-13 07:56:45.303334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.71GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s
2021-02-13 07:56:45.303349: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-02-13 07:56:45.304827: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-02-13 07:56:45.304863: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-02-13 07:56:45.305373: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-02-13 07:56:45.305510: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-02-13 07:56:45.305583: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-13 07:56:45.306000: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-02-13 07:56:45.306042: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-13 07:56:45.306048: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-02-13 07:56:45.306244: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-02-13 07:56:45.307102: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-13 07:56:45.307121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-13 07:56:45.307124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      
2021-02-13 07:56:45.357682: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-02-13 07:56:45.358016: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3493635000 Hz
/home/jmerelo/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype("int32")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn('`model.predict_classes()` is deprecated and '
21Feb13_080046|-- Generation 1 --
21Feb13_080046|    -- Crossed 1 individual pairs.
21Feb13_080046|    -- Mutated 32 individuals.
21Feb13_080444|    -- Evaluated 64 individuals.
21Feb13_080444|    Summary of generation 1:
21Feb13_080444| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_080444|-----------  ------------------  --------------------  ----------
21Feb13_080444|    Max            42.43                159.00          0.72022
21Feb13_080444|    Avg            41.51                40.30           0.02110
21Feb13_080444|    Min            23.13                 3.00           0.00000
21Feb13_080444|    Std             2.77                35.65           0.10493
21Feb13_080444|   Best            23.13                57.00           0.72022
21Feb13_080444|-- Generation 2 --
21Feb13_080444|    -- Crossed 3 individual pairs.
21Feb13_080444|    -- Mutated 32 individuals.
21Feb13_080838|    -- Evaluated 64 individuals.
21Feb13_080838|    Summary of generation 2:
21Feb13_080838| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_080838|-----------  ------------------  --------------------  ----------
21Feb13_080838|    Max            42.26                159.00          0.71457
21Feb13_080838|    Avg            41.59                24.23           0.02338
21Feb13_080838|    Min            28.96                 3.00           0.00000
21Feb13_080838|    Std             2.26                27.52           0.12101
21Feb13_080838|   Best            28.96                14.00           0.67866
21Feb13_080838|-- Generation 3 --
21Feb13_080838|    -- Crossed 2 individual pairs.
21Feb13_080838|    -- Mutated 32 individuals.
21Feb13_081230|    -- Evaluated 64 individuals.
21Feb13_081230|    Summary of generation 3:
21Feb13_081230| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_081230|-----------  ------------------  --------------------  ----------
21Feb13_081230|    Max            42.35                60.00           0.01805
21Feb13_081230|    Avg            41.98                14.72           0.00194
21Feb13_081230|    Min            41.39                 2.00           0.00000
21Feb13_081230|    Std             0.13                12.67           0.00400
21Feb13_081230|   Best            41.39                 6.00           0.01805
21Feb13_081230|-- Generation 4 --
21Feb13_081230|    -- Crossed 3 individual pairs.
21Feb13_081230|    -- Mutated 32 individuals.
21Feb13_081618|    -- Evaluated 64 individuals.
21Feb13_081618|    Summary of generation 4:
21Feb13_081618| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_081618|-----------  ------------------  --------------------  ----------
21Feb13_081618|    Max            53.83                28.00           0.79373
21Feb13_081618|    Avg            41.92                 8.55           0.02529
21Feb13_081618|    Min            27.22                 2.00           0.00000
21Feb13_081618|    Std             2.37                 6.45           0.13130
21Feb13_081618|   Best            27.22                24.00           0.71660
21Feb13_081618|-- Generation 5 --
21Feb13_081618|    -- Crossed 2 individual pairs.
21Feb13_081618|    -- Mutated 32 individuals.
21Feb13_082006|    -- Evaluated 64 individuals.
21Feb13_082006|    Summary of generation 5:
21Feb13_082006| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_082006|-----------  ------------------  --------------------  ----------
21Feb13_082006|    Max            42.17                24.00           0.80160
21Feb13_082006|    Avg            41.77                 8.06           0.01454
21Feb13_082006|    Min            29.13                 2.00           0.00000
21Feb13_082006|    Std             1.60                 6.17           0.09924
21Feb13_082006|   Best            29.13                24.00           0.80160
21Feb13_082006|-- Generation 6 --
21Feb13_082006|    -- Crossed 5 individual pairs.
21Feb13_082006|    -- Mutated 32 individuals.
21Feb13_082355|    -- Evaluated 64 individuals.
21Feb13_082355|    Summary of generation 6:
21Feb13_082355| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_082355|-----------  ------------------  --------------------  ----------
21Feb13_082355|    Max            42.17                51.00           0.81019
21Feb13_082355|    Avg            41.71                 9.50           0.02533
21Feb13_082355|    Min            27.39                 2.00           0.00000
21Feb13_082355|    Std             1.84                 9.29           0.13315
21Feb13_082355|   Best            27.39                 8.00           0.72034
21Feb13_082355|-- Generation 7 --
21Feb13_082355|    -- Crossed 5 individual pairs.
21Feb13_082355|    -- Mutated 32 individuals.
21Feb13_082743|    -- Evaluated 64 individuals.
21Feb13_082743|    Summary of generation 7:
21Feb13_082743| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_082743|-----------  ------------------  --------------------  ----------
21Feb13_082743|    Max            44.61                51.00           0.60825
21Feb13_082743|    Avg            41.82                 8.31           0.01100
21Feb13_082743|    Min            28.70                 2.00           0.00000
21Feb13_082743|    Std             1.69                 8.28           0.07528
21Feb13_082743|   Best            28.70                 8.00           0.60825
21Feb13_082743|-- Generation 8 --
21Feb13_082743|    -- Crossed 4 individual pairs.
21Feb13_082743|    -- Mutated 32 individuals.
21Feb13_083132|    -- Evaluated 64 individuals.
21Feb13_083132|    Summary of generation 8:
21Feb13_083132| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_083132|-----------  ------------------  --------------------  ----------
21Feb13_083132|    Max            42.26                30.00           0.71341
21Feb13_083132|    Avg            41.74                 6.95           0.01307
21Feb13_083132|    Min            26.00                 2.00           0.00000
21Feb13_083132|    Std             1.99                 6.96           0.08849
21Feb13_083132|   Best            26.00                 8.00           0.71341
21Feb13_083132|-- Generation 9 --
21Feb13_083132|    -- Crossed 4 individual pairs.
21Feb13_083132|    -- Mutated 32 individuals.
21Feb13_083521|    -- Evaluated 64 individuals.
21Feb13_083521|    Summary of generation 9:
21Feb13_083521| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_083521|-----------  ------------------  --------------------  ----------
21Feb13_083521|    Max            42.09                32.00           0.56976
21Feb13_083521|    Avg            41.66                 7.38           0.01813
21Feb13_083521|    Min            28.96                 2.00           0.00000
21Feb13_083521|    Std             1.79                 7.25           0.08898
21Feb13_083521|   Best            28.96                 8.00           0.56976
21Feb13_083521|-- Generation 10 --
21Feb13_083521|    -- Crossed 4 individual pairs.
21Feb13_083521|    -- Mutated 32 individuals.
21Feb13_083909|    -- Evaluated 64 individuals.
21Feb13_083909|    Summary of generation 10:
21Feb13_083909| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_083909|-----------  ------------------  --------------------  ----------
21Feb13_083909|    Max            42.09                24.00           0.74970
21Feb13_083909|    Avg            41.61                 7.00           0.02024
21Feb13_083909|    Min            25.04                 2.00           0.00000
21Feb13_083909|    Std             2.18                 5.79           0.10645
21Feb13_083909|   Best            25.04                 8.00           0.74970
21Feb13_083909|-- Generation 11 --
21Feb13_083909|    -- Crossed 3 individual pairs.
21Feb13_083910|    -- Mutated 32 individuals.
21Feb13_084300|    -- Evaluated 64 individuals.
21Feb13_084300|    Summary of generation 11:
21Feb13_084300| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_084300|-----------  ------------------  --------------------  ----------
21Feb13_084300|    Max            42.43                42.00           0.01033
21Feb13_084300|    Avg            41.98                 9.42           0.00121
21Feb13_084300|    Min            41.74                 2.00           0.00000
21Feb13_084300|    Std             0.09                 8.23           0.00219
21Feb13_084300|   Best            41.74                12.00           0.01033
21Feb13_084300|-- Generation 12 --
21Feb13_084300|    -- Crossed 6 individual pairs.
21Feb13_084300|    -- Mutated 32 individuals.
21Feb13_084650|    -- Evaluated 64 individuals.
21Feb13_084650|    Summary of generation 12:
21Feb13_084650| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_084650|-----------  ------------------  --------------------  ----------
21Feb13_084650|    Max            42.09                39.00           0.69276
21Feb13_084650|    Avg            41.69                 8.94           0.01228
21Feb13_084650|    Min            24.17                 2.00           0.00000
21Feb13_084650|    Std             2.21                 8.99           0.08576
21Feb13_084650|   Best            24.17                30.00           0.69276
21Feb13_084650|-- Generation 13 --
21Feb13_084650|    -- Crossed 5 individual pairs.
21Feb13_084650|    -- Mutated 32 individuals.
21Feb13_085040|    -- Evaluated 64 individuals.
21Feb13_085040|    Summary of generation 13:
21Feb13_085040| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_085040|-----------  ------------------  --------------------  ----------
21Feb13_085040|    Max            42.09                63.00           0.82602
21Feb13_085040|    Avg            41.69                10.92           0.01545
21Feb13_085040|    Min            26.61                 2.00           0.00000
21Feb13_085040|    Std             1.90                10.89           0.10218
21Feb13_085040|   Best            26.61                20.00           0.82602
21Feb13_085040|-- Generation 14 --
21Feb13_085040|    -- Crossed 2 individual pairs.
21Feb13_085040|    -- Mutated 32 individuals.
21Feb13_085429|    -- Evaluated 64 individuals.
21Feb13_085429|    Summary of generation 14:
21Feb13_085429| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_085429|-----------  ------------------  --------------------  ----------
21Feb13_085429|    Max            42.09                36.00           0.01290
21Feb13_085429|    Avg            41.92                12.72           0.00347
21Feb13_085429|    Min            41.65                 2.00           0.00000
21Feb13_085429|    Std             0.09                 8.52           0.00271
21Feb13_085429|   Best            41.65                11.00           0.01290
21Feb13_085429|-- Generation 15 --
21Feb13_085429|    -- Crossed 4 individual pairs.
21Feb13_085429|    -- Mutated 32 individuals.
21Feb13_085820|    -- Evaluated 64 individuals.
21Feb13_085820|    Summary of generation 15:
21Feb13_085820| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_085820|-----------  ------------------  --------------------  ----------
21Feb13_085820|    Max            42.17                36.00           0.02831
21Feb13_085820|    Avg            41.91                11.56           0.00375
21Feb13_085820|    Min            41.04                 2.00           0.00000
21Feb13_085820|    Std             0.15                 7.24           0.00405
21Feb13_085820|   Best            41.04                13.00           0.02831
21Feb13_085820|-- Generation 16 --
21Feb13_085820|    -- Crossed 4 individual pairs.
21Feb13_085820|    -- Mutated 32 individuals.
21Feb13_090209|    -- Evaluated 64 individuals.
21Feb13_090209|    Summary of generation 16:
21Feb13_090209| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_090209|-----------  ------------------  --------------------  ----------
21Feb13_090209|    Max            42.17                32.00           0.01291
21Feb13_090209|    Avg            41.92                11.28           0.00343
21Feb13_090209|    Min            41.57                 2.00           0.00000
21Feb13_090209|    Std             0.11                 7.05           0.00310
21Feb13_090209|   Best            41.57                11.00           0.01291
21Feb13_090209|-- Generation 17 --
21Feb13_090209|    -- Crossed 4 individual pairs.
21Feb13_090209|    -- Mutated 32 individuals.
21Feb13_090558|    -- Evaluated 64 individuals.
21Feb13_090558|    Summary of generation 17:
21Feb13_090558| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_090558|-----------  ------------------  --------------------  ----------
21Feb13_090558|    Max            42.26                36.00           0.09601
21Feb13_090558|    Avg            41.88                11.23           0.00558
21Feb13_090558|    Min            39.48                 2.00           0.00000
21Feb13_090558|    Std             0.32                 7.92           0.01178
21Feb13_090558|   Best            39.48                22.00           0.09601
21Feb13_090558|-- Generation 18 --
21Feb13_090558|    -- Crossed 5 individual pairs.
21Feb13_090558|    -- Mutated 32 individuals.
21Feb13_090947|    -- Evaluated 64 individuals.
21Feb13_090947|    Summary of generation 18:
21Feb13_090947| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_090947|-----------  ------------------  --------------------  ----------
21Feb13_090947|    Max            42.09                34.00           0.56255
21Feb13_090947|    Avg            41.87                11.27           0.01283
21Feb13_090947|    Min            39.91                 2.00           0.00000
21Feb13_090947|    Std             0.27                 7.41           0.06935
21Feb13_090947|   Best            39.91                12.00           0.56255
21Feb13_090947|-- Generation 19 --
21Feb13_090947|    -- Crossed 3 individual pairs.
21Feb13_090947|    -- Mutated 32 individuals.
21Feb13_091336|    -- Evaluated 64 individuals.
21Feb13_091336|    Summary of generation 19:
21Feb13_091336| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_091336|-----------  ------------------  --------------------  ----------
21Feb13_091336|    Max            42.78                36.00           0.78958
21Feb13_091336|    Avg            41.60                11.56           0.01734
21Feb13_091336|    Min            23.57                 2.00           0.00000
21Feb13_091336|    Std             2.28                 7.91           0.09737
21Feb13_091336|   Best            23.57                32.00           0.78958
21Feb13_091336|-- Generation 20 --
21Feb13_091336|    -- Crossed 4 individual pairs.
21Feb13_091336|    -- Mutated 32 individuals.
21Feb13_091725|    -- Evaluated 64 individuals.
21Feb13_091725|    Summary of generation 20:
21Feb13_091725| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_091725|-----------  ------------------  --------------------  ----------
21Feb13_091725|    Max            42.09                57.00           0.58439
21Feb13_091725|    Avg            41.64                12.52           0.01373
21Feb13_091725|    Min            26.78                 2.00           0.00000
21Feb13_091725|    Std             1.87                 9.28           0.07196
21Feb13_091725|   Best            26.78                22.00           0.58439
21Feb13_091725|-- Generation 21 --
21Feb13_091725|    -- Crossed 4 individual pairs.
21Feb13_091725|    -- Mutated 32 individuals.
21Feb13_092113|    -- Evaluated 64 individuals.
21Feb13_092113|    Summary of generation 21:
21Feb13_092113| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_092113|-----------  ------------------  --------------------  ----------
21Feb13_092113|    Max            42.17                32.00           0.01548
21Feb13_092113|    Avg            41.87                12.16           0.00472
21Feb13_092113|    Min            41.48                 2.00           0.00000
21Feb13_092113|    Std             0.14                 6.49           0.00372
21Feb13_092113|   Best            41.48                11.00           0.01548
21Feb13_092113|-- Generation 22 --
21Feb13_092113|    -- Crossed 5 individual pairs.
21Feb13_092113|    -- Mutated 32 individuals.
21Feb13_092500|    -- Evaluated 64 individuals.
21Feb13_092500|    Summary of generation 22:
21Feb13_092500| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_092500|-----------  ------------------  --------------------  ----------
21Feb13_092500|    Max            42.09                36.00           0.02573
21Feb13_092500|    Avg            41.85                13.92           0.00581
21Feb13_092500|    Min            41.22                 2.00           0.00000
21Feb13_092500|    Std             0.17                 7.59           0.00505
21Feb13_092500|   Best            41.22                11.00           0.02573
21Feb13_092500|-- Generation 23 --
21Feb13_092500|    -- Crossed 6 individual pairs.
21Feb13_092500|    -- Mutated 32 individuals.
21Feb13_092848|    -- Evaluated 64 individuals.
21Feb13_092848|    Summary of generation 23:
21Feb13_092848| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_092848|-----------  ------------------  --------------------  ----------
21Feb13_092848|    Max            42.17                32.00           0.34305
21Feb13_092848|    Avg            41.74                13.69           0.00996
21Feb13_092848|    Min            33.65                 3.00           0.00000
21Feb13_092848|    Std             1.03                 7.00           0.04212
21Feb13_092848|   Best            33.65                12.00           0.34305
21Feb13_092848|-- Generation 24 --
21Feb13_092848|    -- Crossed 1 individual pairs.
21Feb13_092848|    -- Mutated 32 individuals.
21Feb13_093236|    -- Evaluated 64 individuals.
21Feb13_093236|    Summary of generation 24:
21Feb13_093236| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_093236|-----------  ------------------  --------------------  ----------
21Feb13_093236|    Max            42.09                34.00           0.02318
21Feb13_093236|    Avg            41.83                13.25           0.00674
21Feb13_093236|    Min            41.22                 3.00           0.00000
21Feb13_093236|    Std             0.17                 6.87           0.00477
21Feb13_093236|   Best            41.22                11.00           0.02318
21Feb13_093236|-- Generation 25 --
21Feb13_093236|    -- Crossed 3 individual pairs.
21Feb13_093236|    -- Mutated 32 individuals.
21Feb13_093624|    -- Evaluated 64 individuals.
21Feb13_093624|    Summary of generation 25:
21Feb13_093624| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_093624|-----------  ------------------  --------------------  ----------
21Feb13_093624|    Max            42.35                32.00           0.03085
21Feb13_093624|    Avg            41.85                12.66           0.00613
21Feb13_093624|    Min            41.04                 2.00           0.00000
21Feb13_093624|    Std             0.17                 6.70           0.00476
21Feb13_093624|   Best            41.04                13.00           0.03085
21Feb13_093624|-- Generation 26 --
21Feb13_093624|    -- Crossed 4 individual pairs.
21Feb13_093624|    -- Mutated 32 individuals.
21Feb13_094015|    -- Evaluated 64 individuals.
21Feb13_094015|    Summary of generation 26:
21Feb13_094015| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_094015|-----------  ------------------  --------------------  ----------
21Feb13_094015|    Max            42.17                32.00           0.48504
21Feb13_094015|    Avg            41.62                13.67           0.01403
21Feb13_094015|    Min            28.61                 3.00           0.00000
21Feb13_094015|    Std             1.65                 7.25           0.05955
21Feb13_094015|   Best            28.61                28.00           0.48504
21Feb13_094015|-- Generation 27 --
21Feb13_094015|    -- Crossed 6 individual pairs.
21Feb13_094015|    -- Mutated 32 individuals.
21Feb13_094403|    -- Evaluated 64 individuals.
21Feb13_094403|    Summary of generation 27:
21Feb13_094403| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_094403|-----------  ------------------  --------------------  ----------
21Feb13_094403|    Max            42.09                34.00           0.01805
21Feb13_094403|    Avg            41.84                13.84           0.00553
21Feb13_094403|    Min            41.39                 3.00           0.00000
21Feb13_094403|    Std             0.13                 8.49           0.00400
21Feb13_094403|   Best            41.39                10.00           0.01805
21Feb13_094403|-- Generation 28 --
21Feb13_094403|    -- Crossed 5 individual pairs.
21Feb13_094403|    -- Mutated 32 individuals.
21Feb13_094750|    -- Evaluated 64 individuals.
21Feb13_094750|    Summary of generation 28:
21Feb13_094750| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_094750|-----------  ------------------  --------------------  ----------
21Feb13_094750|    Max            42.26                32.00           0.02828
21Feb13_094750|    Avg            41.85                11.92           0.00545
21Feb13_094750|    Min            41.22                 3.00           0.00000
21Feb13_094750|    Std             0.15                 7.42           0.00435
21Feb13_094750|   Best            41.22                12.00           0.02828
21Feb13_094750|-- Generation 29 --
21Feb13_094750|    -- Crossed 4 individual pairs.
21Feb13_094750|    -- Mutated 32 individuals.
21Feb13_095137|    -- Evaluated 64 individuals.
21Feb13_095137|    Summary of generation 29:
21Feb13_095137| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_095137|-----------  ------------------  --------------------  ----------
21Feb13_095137|    Max            42.00                34.00           0.02318
21Feb13_095137|    Avg            41.81                11.33           0.00654
21Feb13_095137|    Min            41.22                 3.00           0.00000
21Feb13_095137|    Std             0.15                 6.73           0.00447
21Feb13_095137|   Best            41.22                 3.00           0.02318
21Feb13_095137|-- Generation 30 --
21Feb13_095137|    -- Crossed 5 individual pairs.
21Feb13_095137|    -- Mutated 32 individuals.
21Feb13_095524|    -- Evaluated 64 individuals.
21Feb13_095524|    Summary of generation 30:
21Feb13_095524| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_095524|-----------  ------------------  --------------------  ----------
21Feb13_095524|    Max            42.17                32.00           0.32723
21Feb13_095524|    Avg            41.79                11.75           0.01105
21Feb13_095524|    Min            39.13                 3.00           0.00000
21Feb13_095524|    Std             0.37                 7.01           0.04004
21Feb13_095524|   Best            39.13                24.00           0.32723
21Feb13_095524|-- Generation 31 --
21Feb13_095524|    -- Crossed 5 individual pairs.
21Feb13_095524|    -- Mutated 32 individuals.
21Feb13_095910|    -- Evaluated 64 individuals.
21Feb13_095910|    Summary of generation 31:
21Feb13_095910| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_095910|-----------  ------------------  --------------------  ----------
21Feb13_095910|    Max            42.26                32.00           0.48775
21Feb13_095910|    Avg            41.62                10.83           0.01371
21Feb13_095910|    Min            28.26                 3.00           0.00000
21Feb13_095910|    Std             1.69                 5.79           0.05989
21Feb13_095910|   Best            28.26                22.00           0.48775
21Feb13_095910|-- Generation 32 --
21Feb13_095911|    -- Crossed 3 individual pairs.
21Feb13_095911|    -- Mutated 32 individuals.
21Feb13_100257|    -- Evaluated 64 individuals.
21Feb13_100257|    Summary of generation 32:
21Feb13_100257| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_100257|-----------  ------------------  --------------------  ----------
21Feb13_100257|    Max            42.26                34.00           0.81633
21Feb13_100257|    Avg            41.15                11.95           0.04374
21Feb13_100257|    Min            27.30                 2.00           0.00000
21Feb13_100257|    Std             2.67                 8.49           0.14890
21Feb13_100257|   Best            27.30                30.00           0.53850
21Feb13_100257|Best initial individual weights
21Feb13_100257|Individual:
21Feb13_100257|-- Constant hidden layers --
21Feb13_100257|False
21Feb13_100257|Layer 0:
21Feb13_100257|-- Config --
21Feb13_100257|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 12, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100257|-- Weights --
21Feb13_100257|[[-0.19605  0.07843 -0.31094 -0.44735  0.88644 -0.41005 -0.92737 -0.51939
21Feb13_100257|   0.90379 -0.86722 -0.58442  0.02119]
21Feb13_100257| [ 0.54780 -0.13999  0.86992  0.67643  0.63457 -0.26414 -0.76365  0.83511
21Feb13_100257|  -0.82664  0.19916 -0.42085  0.14112]
21Feb13_100257| [ 0.92815 -0.99412 -0.30782  0.33834  0.85210 -0.59432 -0.14883 -0.83946
21Feb13_100257|   0.13172 -0.59112 -0.69063  0.18870]
21Feb13_100257| [-0.29746  0.71772 -0.72497 -0.03391 -0.60978  0.53162 -0.51971 -0.07740
21Feb13_100257|   0.00958 -0.35158  0.49349 -0.32340]
21Feb13_100257| [ 0.73546 -0.41176 -0.89296 -0.36846  0.69857 -0.98545 -0.61422 -0.97115
21Feb13_100257|  -0.19382  0.30549 -0.61369 -0.53775]
21Feb13_100257| [-0.51907  0.84979 -0.74659  0.37694  0.20955 -0.42773  0.25342 -0.24185
21Feb13_100257|  -0.58571 -0.54052  0.01641 -0.62195]
21Feb13_100257| [-0.36637 -0.59648  0.90641 -0.32917  0.70252 -0.97759  0.77156 -0.54336
21Feb13_100257|  -0.63097  0.58684  0.56565 -0.38443]
21Feb13_100257| [ 0.47220  0.19322 -0.64569 -0.14107 -0.23431 -0.86701  0.92105  0.34531
21Feb13_100257|   0.09836 -0.70972 -0.53027  0.34415]
21Feb13_100257| [-0.49035 -0.87304 -0.34528 -0.41579 -0.02059  0.39221  0.63551 -0.02803
21Feb13_100257|   0.44723 -0.62434 -0.21190 -0.96922]
21Feb13_100257| [ 0.47460 -0.96286 -0.81731 -0.84472 -0.58155 -0.99043 -0.50158  0.76152
21Feb13_100257|  -0.66560  0.79135  0.71026 -0.67793]
21Feb13_100257| [-0.42166  0.23994 -0.27482  0.14800  0.78420  0.88895  0.05267  0.92468
21Feb13_100257|  -0.37922  0.40907 -0.89761  0.70309]
21Feb13_100257| [ 0.23497  0.83372  0.42807  0.56853  0.54153  0.17151 -0.62377  0.18507
21Feb13_100257|  -0.10411  0.43054  0.67748  0.67758]
21Feb13_100257| [-0.28291  0.67700 -0.98110 -0.29177  0.72729  0.68055 -0.72082  0.09379
21Feb13_100257|   0.96378  0.01188  0.59201  0.76149]
21Feb13_100257| [-0.96321  0.66574  0.54272  0.71254 -0.23570 -0.36536  0.12429  0.62568
21Feb13_100257|  -0.86305  0.27439 -0.72802 -0.24864]
21Feb13_100257| [ 0.25755  0.85144  0.89615  0.36624  0.74994 -0.25647  0.71113 -0.03721
21Feb13_100257|   0.82653  0.37424  0.83053 -0.82677]
21Feb13_100257| [-0.97377  0.78579  0.75967 -0.55092  0.00956  0.04794 -0.65977 -0.97425
21Feb13_100257|   0.96404  0.93558 -0.52538 -0.09205]
21Feb13_100257| [-0.49035  0.28430 -0.55656  0.72426 -0.25637  0.49226 -0.63246  0.93147
21Feb13_100257|  -0.70175  0.24880 -0.85245  0.52518]
21Feb13_100257| [ 0.14856  0.83873  0.91845 -0.63496  0.64931 -0.50770  0.64919 -0.25568
21Feb13_100257|   0.35826 -0.96666  0.00619 -0.18926]
21Feb13_100257| [-0.82902 -0.36322 -0.53492 -0.38547  0.05838  0.84041  0.33463  0.61662
21Feb13_100257|   0.94323  0.95252 -0.95489  0.85206]
21Feb13_100257| [-0.23396  0.06864 -0.59064  0.89709 -0.72366 -0.90802  0.45986  0.53240
21Feb13_100257|  -0.28547 -0.19042  0.64039  0.22830]
21Feb13_100257| [-0.23733  0.69326 -0.74659 -0.32152  0.78239 -0.47993  0.13189 -0.07797
21Feb13_100257|   0.37458  0.71434 -0.06358 -0.49027]
21Feb13_100257| [-0.21645 -0.79396  0.64866  0.23994 -0.60308 -0.64577  0.00575  0.21900
21Feb13_100257|   0.27866 -0.71745  0.57862  0.71158]
21Feb13_100257| [-0.69314 -0.97062  0.69243 -0.56022 -0.09135  0.42521 -0.21484  0.52052
21Feb13_100257|  -0.98040  0.58351  0.94285  0.23907]
21Feb13_100257| [ 0.71315 -0.76245  0.73926 -0.36028  0.14879 -0.28182  0.70512  0.16512
21Feb13_100257|  -0.26497 -0.62287 -0.56888  0.27728]
21Feb13_100257| [-0.14341  0.32688 -0.69707  0.69129  0.06504  0.05570 -0.37368 -0.05829
21Feb13_100257|  -0.87000  0.30138  0.49973  0.47099]
21Feb13_100257| [ 0.28947  0.04095  0.22699 -0.93123 -0.42627 -0.26099 -0.17880 -0.61384
21Feb13_100257|  -0.95795 -0.96474  0.78375  0.48800]
21Feb13_100257| [-0.37158  0.77551  0.61333 -0.88781 -0.60543  0.97582 -0.39711  0.19084
21Feb13_100257|   0.55603  0.03797 -0.29924 -0.13715]
21Feb13_100257| [-0.43702 -0.62190  0.10465 -0.66108 -0.48485  0.78160  0.05362 -0.93961
21Feb13_100257|   0.91432  0.33658  0.49788 -0.84850]
21Feb13_100257| [-0.22827 -0.54119 -0.75249  0.35169  0.86876  0.57233  0.15445 -0.03650
21Feb13_100257|  -0.67703 -0.21074 -0.34815 -0.83224]
21Feb13_100257| [ 0.67886  0.23712 -0.37183 -0.72408  0.88807  0.44770 -0.57875  0.58158
21Feb13_100257|   0.91498 -0.06441 -0.40422 -0.24614]
21Feb13_100257| [ 0.51750  0.72238 -0.00673 -0.64053 -0.28162  0.45487  0.81996 -0.89515
21Feb13_100257|  -0.62003 -0.98783 -0.21311 -0.63064]
21Feb13_100257| [ 0.88583  0.67272  0.01083 -0.82272  0.42140 -0.00875 -0.76958 -0.74108
21Feb13_100257|  -0.39316 -0.60818  0.80695 -0.94411]
21Feb13_100257| [-0.12317  0.22841  0.43555  0.00737  0.08288  0.72114  0.04557 -0.41808
21Feb13_100257|  -0.17800  0.36074 -0.38920 -0.38308]
21Feb13_100257| [ 0.96319 -0.56238 -0.85366  0.42553  0.76722  0.86755  0.31466 -0.97535
21Feb13_100257|  -0.24420 -0.66968 -0.46896  0.01382]
21Feb13_100257| [-0.53134 -0.13708  0.85415 -0.59263 -0.98367 -0.61404 -0.29060 -0.67819
21Feb13_100257|   0.54436 -0.26752 -0.13594 -0.12892]
21Feb13_100257| [-0.56091  0.28911 -0.42022  0.82477 -0.14640 -0.84944  0.35816 -0.57915
21Feb13_100257|  -0.29321  0.02515  0.91416  0.19156]
21Feb13_100257| [ 0.64422  0.21984 -0.15120  0.67097 -0.67070  0.27165  0.42312  0.21395
21Feb13_100257|   0.55535 -0.82562 -0.69462  0.04223]
21Feb13_100257| [-0.37478  0.69891 -0.18261 -0.74082 -0.58298 -0.27973 -0.25535 -0.05790
21Feb13_100257|   0.28104  0.37456 -0.78458  0.98888]
21Feb13_100257| [ 0.79270 -0.20668  0.90887  0.71744 -0.86420 -0.01662 -0.89604 -0.47720
21Feb13_100257|  -0.35188  0.92008 -0.11690  0.90128]
21Feb13_100257| [ 0.88351 -0.61784 -0.81267  0.46418  0.07434  0.20029  0.35680  0.21159
21Feb13_100257|   0.28852  0.24978 -0.79977 -0.75581]
21Feb13_100257| [-0.45852 -0.90347  0.29606  0.97336  0.48387  0.27566 -0.88302  0.10429
21Feb13_100257|  -0.69749  0.08334 -0.12432  0.12389]
21Feb13_100257| [-0.65315 -0.68237 -0.54046 -0.55815  0.71787  0.42769 -0.67949  0.87854
21Feb13_100257|  -0.21407  0.32648  0.43295  0.81105]
21Feb13_100257| [ 0.86888 -0.01829 -0.65935 -0.12922 -0.49685 -0.29120  0.59147  0.05010
21Feb13_100257|   0.99542 -0.69550  0.89021 -0.07593]
21Feb13_100257| [-0.07381  0.01267  0.27307  0.26282  0.55441  0.37188 -0.69164 -0.81718
21Feb13_100257|  -0.58826 -0.69340  0.61993 -0.81237]
21Feb13_100257| [ 0.47530  0.76146 -0.75428  0.29860 -0.70760  0.47941  0.27492 -0.48234
21Feb13_100257|  -0.37542  0.57442  0.75267  0.59246]
21Feb13_100257| [ 0.76064 -0.57826  0.05341  0.87807  0.84498  0.06661  0.90881  0.31908
21Feb13_100257|  -0.21196  0.59415 -0.47988 -0.47217]
21Feb13_100257| [-0.28526 -0.87198 -0.92021 -0.60794  0.14081 -0.02440  0.37672 -0.87611
21Feb13_100257|   0.96127  0.82308 -0.28009  0.40356]
21Feb13_100257| [ 0.47211  0.76738 -0.10357 -0.69428 -0.59205  0.89460  0.26135  0.62380
21Feb13_100257|  -0.73577 -0.11552  0.56692 -0.29719]
21Feb13_100257| [-0.69816 -0.22653  0.52731 -0.85516 -0.04646  0.29010 -0.57031  0.81468
21Feb13_100257|  -0.78263  0.25604 -0.04043  0.48321]
21Feb13_100257| [ 0.61664 -0.79005  0.85570  0.99050 -0.76268 -0.15055 -0.47442  0.92101
21Feb13_100257|   0.33762 -0.47616  0.61102 -0.14568]
21Feb13_100257| [-0.98857  0.41528 -0.03773  0.12596 -0.63205 -0.54454  0.31730 -0.43739
21Feb13_100257|   0.25380 -0.39261 -0.22879 -0.30079]
21Feb13_100257| [ 0.52388 -0.43451 -0.90933  0.29969  0.06616  0.26314 -0.85982  0.84794
21Feb13_100257|  -0.16671  0.35711  0.17694 -0.96064]
21Feb13_100257| [ 0.95040 -0.29663 -0.96590  0.65854  0.39026  0.84997 -0.88826  0.26184
21Feb13_100257|   0.65504  0.17684  0.16152  0.29320]
21Feb13_100257| [ 0.33709  0.64327  0.01201  0.71039  0.75608 -0.49551 -0.27296 -0.06805
21Feb13_100257|   0.77896 -0.94024  0.08091  0.40313]
21Feb13_100257| [-0.92593  0.92289 -0.22076  0.49120  0.27038 -0.14117  0.80761 -0.51965
21Feb13_100257|  -0.10907 -0.80936 -0.08340 -0.79857]
21Feb13_100257| [ 0.27108  0.23921  0.56876 -0.60416 -0.97617 -0.82345 -0.10345  0.54576
21Feb13_100257|  -0.65979 -0.65457 -0.09434 -0.66730]
21Feb13_100257| [ 0.02155 -0.14211 -0.99671 -0.14367 -0.75401  0.02729 -0.58660  0.83371
21Feb13_100257|   0.79378 -0.94277 -0.40400 -0.04899]]
21Feb13_100257|-- Bias --
21Feb13_100257|[-0.06936  0.81912 -0.76323 -0.14845  0.82192 -0.47927  0.18733  0.18279
21Feb13_100257|  0.26160 -0.14867 -0.84828 -0.28023]
21Feb13_100257|Layer 1:
21Feb13_100257|-- Config --
21Feb13_100257|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 12], 'dtype': 'float32', 'units': 13, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100257|-- Weights --
21Feb13_100257|[[-0.57173  0.45862 -0.93055  0.27222 -0.31226  0.49269  0.89742  0.87860
21Feb13_100257|   0.49316  0.36076 -0.24065  0.45448  0.30401]
21Feb13_100257| [ 0.76531  0.02320 -0.50047 -0.99102  0.48545 -0.77912  0.56844  0.96540
21Feb13_100257|  -0.89874 -0.56777  0.48467 -0.81119 -0.81628]
21Feb13_100257| [-0.64124  0.69401  0.65246 -0.87333  0.42127  0.56195 -0.64966  0.43706
21Feb13_100257|  -0.51348  0.79681  0.30271  0.44589  0.26467]
21Feb13_100257| [ 0.01534  0.05613  0.66673 -0.55747 -0.76006  0.44190 -0.94739 -0.56112
21Feb13_100257|   0.16647 -0.75245  0.47271  0.69006 -0.75609]
21Feb13_100257| [-0.64328  0.42864  0.29471  0.98091  0.98114 -0.01799 -0.96118  0.38420
21Feb13_100257|   0.88607  0.78591 -0.34685  0.27648  0.29606]
21Feb13_100257| [-0.76313 -0.84946  0.54851 -0.95567 -0.68968 -0.57704 -0.48457 -0.90418
21Feb13_100257|  -0.87021  0.31319 -0.90413 -0.84682 -0.45598]
21Feb13_100257| [ 0.72830 -0.26779 -0.48676 -0.67729  0.70218 -0.78320 -0.05996  0.48424
21Feb13_100257|   0.13209 -0.68140 -0.31684 -0.21140  0.64393]
21Feb13_100257| [-0.08896 -0.67439 -0.91435 -0.80077 -0.21941 -0.38012  0.24216  0.22865
21Feb13_100257|   0.50473  0.01475 -0.50273 -0.88155 -0.37004]
21Feb13_100257| [-0.03534  0.29444  0.73037 -0.60714 -0.35843 -0.52162  0.30658 -0.92155
21Feb13_100257|  -0.19878 -0.10421  0.26349  0.23258  0.74541]
21Feb13_100257| [-0.21702 -0.69264 -0.92070  0.55909 -0.12296  0.30133 -0.84777  0.71586
21Feb13_100257|  -0.41361 -0.55813  0.03293  0.17605 -0.13972]
21Feb13_100257| [ 0.70693 -0.83315  0.33310  0.99375 -0.04897 -0.16629  0.70070  0.97647
21Feb13_100257|   0.44050  0.47363  0.75527 -0.22757  0.78307]
21Feb13_100257| [-0.99479 -0.93452  0.11239 -0.37449 -0.77745 -0.08740 -0.27977  0.37414
21Feb13_100257|   0.03453 -0.66167  0.86707  0.44771 -0.85046]]
21Feb13_100257|-- Bias --
21Feb13_100257|[-0.22277  0.83949 -0.70049  0.03933  0.57748  0.71452 -0.29214  0.39634
21Feb13_100257|  0.54944  0.29891 -0.87087 -0.77254 -0.41071]
21Feb13_100257|Layer 2:
21Feb13_100257|-- Config --
21Feb13_100257|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 13], 'dtype': 'float32', 'units': 12, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100257|-- Weights --
21Feb13_100257|[[-0.75345  0.82041  0.04849 -0.83599 -0.69648 -0.24535 -0.85909 -0.91052
21Feb13_100257|  -0.46901 -0.11820  0.26560  0.42036]
21Feb13_100257| [-0.18624 -0.32704  0.56431  0.55305  0.24353  0.53524  0.11738  0.78421
21Feb13_100257|   0.74729  0.23266  0.53427 -0.75229]
21Feb13_100257| [ 0.13256 -0.31279  0.71021  0.84543 -0.88442 -0.09185  0.82471 -0.90378
21Feb13_100257|  -0.43064 -0.53632  0.31068  0.87027]
21Feb13_100257| [-0.78067 -0.90836  0.45889 -0.90384 -0.69513  0.99596 -0.92463  0.77969
21Feb13_100257|  -0.91035  0.57951 -0.53052  0.96491]
21Feb13_100257| [-0.49284  0.20410 -0.02961  0.26687 -0.55357 -0.18649 -0.70445  0.48148
21Feb13_100257|  -0.68050  0.47158 -0.14382 -0.25341]
21Feb13_100257| [-0.41660 -0.28967 -0.31947  0.69810 -0.60047 -0.66932  0.51894  0.75638
21Feb13_100257|  -0.28920 -0.07668  0.74483  0.35902]
21Feb13_100257| [ 0.30943 -0.29638  0.74220 -0.85318  0.07532  0.99619 -0.96969 -0.83090
21Feb13_100257|  -0.98442  0.96339  0.50345  0.25660]
21Feb13_100257| [-0.86632  0.06937  0.95079  0.44295 -0.88993 -0.45000  0.34496  0.85712
21Feb13_100257|   0.63799 -0.39126  0.84951 -0.73572]
21Feb13_100257| [ 0.86307  0.45271  0.44937  0.82734  0.70615  0.13552 -0.75375  0.09041
21Feb13_100257|  -0.09981 -0.17969  0.47685 -0.31866]
21Feb13_100257| [-0.96734  0.58934 -0.64497  0.27275 -0.98437  0.01854 -0.74254 -0.36858
21Feb13_100257|   0.38864  0.70922 -0.77080 -0.20631]
21Feb13_100257| [ 0.75202  0.63334  0.27752 -0.36737  0.23842  0.26132 -0.66486  0.20808
21Feb13_100257|   0.68710 -0.45993 -0.07293  0.54639]
21Feb13_100257| [-0.91705 -0.64543 -0.39068  0.13141 -0.59270 -0.81381  0.45448 -0.22837
21Feb13_100257|   0.77646 -0.79930  0.84100  0.59053]
21Feb13_100257| [ 0.16885  0.46316  0.25173  0.71703 -0.33081 -0.46487  0.46158 -0.88760
21Feb13_100257|  -0.06960  0.43596  0.01917 -0.52323]]
21Feb13_100257|-- Bias --
21Feb13_100257|[ 0.19064 -0.21748 -0.13248  0.04699  0.78749 -0.15081 -0.13054 -0.40562
21Feb13_100257| -0.24176  0.41348 -0.63690 -0.70923]
21Feb13_100257|Layer 3:
21Feb13_100257|-- Config --
21Feb13_100257|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 12], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100257|-- Weights --
21Feb13_100257|[[-0.51409  0.33569]
21Feb13_100257| [ 0.07022  0.17244]
21Feb13_100257| [-0.91282  0.47924]
21Feb13_100257| [ 0.62431 -0.00280]
21Feb13_100257| [ 0.72239  0.50121]
21Feb13_100257| [ 0.19713  0.24329]
21Feb13_100257| [-0.60572 -0.15440]
21Feb13_100257| [-0.81091 -0.25537]
21Feb13_100257| [ 0.58884  0.32903]
21Feb13_100257| [-0.80206  0.49467]
21Feb13_100257| [-0.59875  0.90423]
21Feb13_100257| [ 0.14118 -0.50429]]
21Feb13_100257|-- Bias --
21Feb13_100257|[ 0.73243 -0.93830]
21Feb13_100257|Predicting the validation and test data with the Best initial individual.
21Feb13_100305| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_100305|-----------  ------------------  --------------------  ----------
21Feb13_100305|Validation         42.09                 111            0.00000
21Feb13_100305|   Test            36.32                 111            0.00298
21Feb13_100305|-------------------- Test #0 --------------------
21Feb13_100305|Best final individual weights
21Feb13_100305|Individual:
21Feb13_100305|-- Constant hidden layers --
21Feb13_100305|False
21Feb13_100305|Layer 0:
21Feb13_100305|-- Config --
21Feb13_100305|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 11, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100305|-- Weights --
21Feb13_100305|[[-1.06145e+00  8.68922e-01 -1.14379e+00 -1.49459e-01 -5.92039e-01
21Feb13_100305|  -2.35241e-01 -1.40309e+00  2.12924e+00  1.77198e-01  3.19702e-01
21Feb13_100305|  -4.23758e-01]
21Feb13_100305| [-7.60973e-01 -1.69902e+00  5.70321e-01  7.00329e-02  7.06671e-01
21Feb13_100305|   3.27493e-01 -1.70808e+00 -1.16196e+00  9.48272e-02  6.65005e-01
21Feb13_100305|   1.23887e+00]
21Feb13_100305| [-5.76717e-01  4.39987e-01 -4.71900e-01  9.84744e-01 -6.70632e-01
21Feb13_100305|  -8.05147e-02  4.07717e-01  1.82295e+00 -3.65259e-01  2.94562e-02
21Feb13_100305|   4.58511e-01]
21Feb13_100305| [ 1.51511e+00  9.93966e-01  3.08471e-01 -5.70096e-01  8.84235e-02
21Feb13_100305|  -3.23449e-01 -2.17552e-02  1.61666e+00  6.74902e-02 -2.42173e-01
21Feb13_100305|  -1.07711e+00]
21Feb13_100305| [ 7.49020e-01  1.03034e+00  1.53014e+00 -1.66588e+00 -1.34224e-01
21Feb13_100305|   1.92903e+00 -2.20672e+00  1.52629e-01 -9.97077e-01 -4.47184e-01
21Feb13_100305|  -1.17110e+00]
21Feb13_100305| [ 5.15382e-01  1.00118e+00 -1.08350e+00  1.03880e+00 -4.68603e-01
21Feb13_100305|  -4.59197e-02  1.11058e+00  9.17544e-01  1.33730e-01  6.53965e-02
21Feb13_100305|  -1.13911e+00]
21Feb13_100305| [-2.04317e+00 -6.76921e-01  7.78254e-01 -1.17217e+00 -1.67455e+00
21Feb13_100305|  -1.57760e-02  8.21084e-01 -1.13921e-01  7.37767e-01 -2.98292e-01
21Feb13_100305|   2.92646e-01]
21Feb13_100305| [-8.01681e-01 -9.13592e-01 -7.13092e-01  1.16235e+00 -5.79811e-01
21Feb13_100305|   5.53346e-01 -3.23183e-01 -5.66910e-02  1.05090e+00 -4.89620e-01
21Feb13_100305|  -1.40866e-01]
21Feb13_100305| [-6.85763e-01  4.32546e-01  2.07281e-01  1.86934e-01  1.03855e+00
21Feb13_100305|  -2.61743e-02 -1.45446e+00  2.99914e-01  9.96893e-01  5.16927e-01
21Feb13_100305|  -9.72506e-01]
21Feb13_100305| [ 6.87732e-01  8.12844e-01  3.51990e-01 -1.28179e+00 -1.00846e-02
21Feb13_100305|  -2.28308e-01  1.61447e+00 -2.91772e-01  1.12608e+00  6.13314e-01
21Feb13_100305|  -7.64936e-01]
21Feb13_100305| [ 3.88583e-01  3.89122e-02 -7.32680e-01 -1.74359e-01 -1.04680e+00
21Feb13_100305|   1.41735e+00  3.14067e-01 -1.41835e-01 -5.39265e-01 -8.08813e-01
21Feb13_100305|   6.58712e-01]
21Feb13_100305| [-6.68434e-01 -9.77746e-01  1.42569e+00 -2.64191e-01 -4.41971e-01
21Feb13_100305|   3.89653e-01  1.19610e+00 -1.70441e+00  2.60850e-01 -1.16352e+00
21Feb13_100305|   6.53371e-01]
21Feb13_100305| [ 2.16387e+00  1.21870e+00 -1.34441e-01 -8.61036e-01 -6.09299e-01
21Feb13_100305|   7.85750e-01 -9.41396e-01 -5.31235e-01  4.44708e-02 -5.08207e-01
21Feb13_100305|  -2.45830e+00]
21Feb13_100305| [-8.92729e-01 -2.15613e-01 -3.99405e-01  1.63387e+00 -8.65849e-01
21Feb13_100305|   7.58911e-01  7.49706e-01 -2.11143e+00  1.56748e-01  7.64897e-01
21Feb13_100305|  -1.13879e+00]
21Feb13_100305| [-8.57088e-01 -1.62365e-03  1.26530e+00 -2.22604e+00 -2.28715e+00
21Feb13_100305|  -9.99604e-02 -2.40021e-01  3.35970e-01 -8.82544e-01  4.85761e-01
21Feb13_100305|  -2.24202e+00]
21Feb13_100305| [ 5.52215e-01  8.52156e-02 -2.37466e-01  1.07672e+00  1.54941e+00
21Feb13_100305|   1.99606e-01 -1.34808e+00  7.53511e-01 -5.99088e-01  5.98790e-02
21Feb13_100305|  -1.07950e-01]
21Feb13_100305| [ 2.67109e+00 -1.75176e+00 -6.16214e-01 -1.86800e+00  5.99501e-01
21Feb13_100305|  -1.10529e+00 -2.74849e+00  6.11555e-01  9.78547e-03 -3.97459e-01
21Feb13_100305|   2.92660e-01]
21Feb13_100305| [ 4.54863e-01 -9.09117e-01 -8.30196e-01  1.50206e+00 -1.73504e+00
21Feb13_100305|  -1.30648e+00  5.55948e-01 -7.54174e-01  2.05420e+00  1.38864e+00
21Feb13_100305|   5.29561e-01]
21Feb13_100305| [-4.85366e-01 -3.53531e-01  9.05198e-01  7.65456e-01 -1.64749e+00
21Feb13_100305|   5.69847e-01  2.50378e-01  7.85001e-01 -1.45661e+00  8.34665e-02
21Feb13_100305|   8.15879e-01]
21Feb13_100305| [ 1.25727e+00  2.46577e-01  5.85987e-01  5.77962e-01 -2.59665e-01
21Feb13_100305|  -1.17493e-01  1.60910e+00  9.12990e-01  1.44670e+00  5.22422e-01
21Feb13_100305|  -1.94187e+00]
21Feb13_100305| [ 1.33867e-01 -1.27358e+00 -3.47982e-01 -6.08657e-02 -1.30348e-01
21Feb13_100305|  -1.17219e+00  1.24909e+00 -1.11782e+00  8.64220e-01  5.61000e-01
21Feb13_100305|  -1.48212e+00]
21Feb13_100305| [ 1.78205e+00 -2.50466e-01  1.33657e+00 -1.73845e+00  1.81425e+00
21Feb13_100305|  -8.02280e-01 -1.16246e+00  1.15245e+00 -3.53401e-01  6.57431e-01
21Feb13_100305|   9.30205e-01]
21Feb13_100305| [-3.03807e-01 -5.34010e-01 -5.36033e-02  1.22986e+00 -7.73593e-01
21Feb13_100305|  -2.41838e-02  9.47047e-01  1.63950e+00  8.57850e-01  7.18366e-01
21Feb13_100305|   6.19340e-01]
21Feb13_100305| [-1.56874e+00  9.13052e-01 -1.80219e+00 -6.85706e-02 -1.52747e-01
21Feb13_100305|  -1.23654e+00  7.66763e-01  8.76849e-01  1.38192e+00  1.74758e-01
21Feb13_100305|   9.19395e-01]
21Feb13_100305| [-3.41080e-01 -1.01680e+00 -7.82347e-01  5.72435e-01  1.21957e+00
21Feb13_100305|  -1.70168e+00  1.35596e+00 -1.36994e+00  6.54260e-01  2.17154e+00
21Feb13_100305|  -6.51639e-01]
21Feb13_100305| [-4.25343e-01  1.74798e+00  9.89404e-01 -1.04295e+00 -5.27053e-03
21Feb13_100305|   1.42040e+00  1.70140e+00 -5.47912e-01  2.85277e-01 -3.08635e-01
21Feb13_100305|  -1.87522e+00]
21Feb13_100305| [-2.65662e+00 -2.02900e+00 -1.49073e-01 -1.86322e-01 -6.15986e-01
21Feb13_100305|   1.02607e+00  7.96644e-01 -5.96812e-01  1.99503e-01 -1.24498e+00
21Feb13_100305|   1.01419e+00]
21Feb13_100305| [-1.31259e+00 -4.54363e-01  1.06493e-01  1.22074e+00  1.74518e-01
21Feb13_100305|  -5.57725e-01 -1.40429e+00  6.75301e-01  1.36944e+00 -3.09052e-01
21Feb13_100305|   1.21379e-01]
21Feb13_100305| [-1.66580e+00 -6.50639e-01  5.46120e-01 -1.25566e+00 -5.04851e-01
21Feb13_100305|  -5.49479e-01  1.11882e-01 -4.76139e-01 -4.81819e-01 -1.14210e-01
21Feb13_100305|  -1.57996e+00]
21Feb13_100305| [-7.64196e-01  1.06296e+00 -7.61805e-01 -1.49152e+00  9.36859e-01
21Feb13_100305|  -1.03321e+00 -2.87637e-01 -2.47389e-01  2.61926e-01  8.37227e-01
21Feb13_100305|  -3.42333e-01]
21Feb13_100305| [ 7.46572e-01 -1.58035e+00  8.02182e-01 -5.66302e-01 -8.47290e-01
21Feb13_100305|  -6.34161e-01  1.74178e+00  1.27802e+00  1.67001e+00 -7.94473e-01
21Feb13_100305|   1.10741e+00]
21Feb13_100305| [-6.74261e-01  5.99487e-01 -1.80403e+00 -1.02671e+00 -1.54235e+00
21Feb13_100305|  -1.26515e+00  4.29489e-01  8.21419e-01  1.06895e+00  1.13029e+00
21Feb13_100305|   7.65765e-01]
21Feb13_100305| [ 3.93528e-01 -5.92774e-01  5.40870e-01  9.02092e-01 -1.02404e+00
21Feb13_100305|  -1.10673e+00  2.35611e-01 -1.02808e+00  1.83820e-01  4.85873e-01
21Feb13_100305|  -1.59386e+00]
21Feb13_100305| [ 7.49489e-01 -6.49799e-01  1.34338e+00  2.12189e+00 -7.31882e-01
21Feb13_100305|   5.88080e-01  2.20549e+00 -1.06942e+00 -1.29756e+00 -7.96579e-01
21Feb13_100305|  -5.81803e-01]
21Feb13_100305| [-1.75688e-01  7.50212e-01 -1.37744e+00 -3.66415e-01  8.48990e-01
21Feb13_100305|  -1.88524e-01  1.13690e+00  1.33830e-01 -1.38609e+00 -3.92856e-01
21Feb13_100305|   5.05161e-01]
21Feb13_100305| [-1.56803e-01  6.44681e-01  4.29331e-01 -2.67595e-02  1.86944e+00
21Feb13_100305|   2.86790e+00  6.18832e-02  3.55496e-01  7.56248e-03 -1.48327e+00
21Feb13_100305|  -3.39873e-01]
21Feb13_100305| [-2.54559e-01 -1.85204e+00 -4.10288e-01 -8.81453e-01 -2.11431e-01
21Feb13_100305|   1.19889e+00  1.26373e+00 -6.36870e-01  1.26338e+00  5.36597e-01
21Feb13_100305|   1.31875e-02]
21Feb13_100305| [-6.96596e-02 -5.38534e-01  5.48522e-01  5.84182e-02  6.63353e-01
21Feb13_100305|  -8.82974e-01  8.67865e-01 -4.46778e-01  3.78957e-01 -1.73884e+00
21Feb13_100305|   7.87282e-01]
21Feb13_100305| [-9.53666e-01  9.80083e-01 -2.38978e-01 -1.94127e-01 -1.09625e+00
21Feb13_100305|   6.84617e-01 -1.90861e+00 -1.46974e+00  1.49925e-01 -6.42909e-01
21Feb13_100305|   1.10172e+00]
21Feb13_100305| [ 1.25790e-03  6.28597e-01  5.34003e-01  2.97309e-01  1.63498e+00
21Feb13_100305|   9.24999e-01 -2.69857e-01 -2.42502e+00  4.21238e-01  3.03054e-01
21Feb13_100305|  -3.28666e-01]
21Feb13_100305| [ 4.96081e-01  3.19527e-01  6.41207e-01  2.65925e-01  1.49075e+00
21Feb13_100305|   1.26551e-01 -3.97150e-01  1.17863e-01  3.16032e-01  1.62457e-01
21Feb13_100305|  -1.75157e+00]
21Feb13_100305| [ 1.07827e+00 -6.03883e-01 -1.79069e+00  3.62297e-01  1.72510e-01
21Feb13_100305|   2.07369e-01  2.87312e+00 -1.17485e+00  6.05597e-01 -1.01342e+00
21Feb13_100305|  -1.48620e+00]
21Feb13_100305| [ 2.10119e-01 -1.00618e+00 -1.21833e+00  1.51138e-01 -2.10391e+00
21Feb13_100305|  -9.70180e-01  1.51398e-01  3.86319e-01 -1.29116e+00  7.64629e-01
21Feb13_100305|   1.55391e+00]
21Feb13_100305| [-5.61712e-01  9.73611e-01 -1.11945e+00  6.21880e-02 -1.36018e+00
21Feb13_100305|   6.40626e-01  1.72919e-01 -8.32757e-02 -4.69855e-01  2.27406e+00
21Feb13_100305|   4.90539e-01]
21Feb13_100305| [ 9.10147e-01 -8.16175e-01  8.75446e-01 -5.79670e-01 -7.61116e-01
21Feb13_100305|  -1.51932e+00 -3.06235e-02 -4.15810e-01 -6.32631e-01  1.75909e+00
21Feb13_100305|   2.17078e-01]
21Feb13_100305| [-7.08015e-02  2.82435e+00  1.20172e+00 -2.33629e-01 -1.32451e+00
21Feb13_100305|  -3.79960e-01 -9.94142e-01  5.68075e-01 -2.52394e-02  2.67676e-01
21Feb13_100305|   1.39104e+00]
21Feb13_100305| [ 1.25990e+00  3.83043e-01 -5.14876e-01 -5.66390e-01  6.97171e-01
21Feb13_100305|  -4.78790e-02  1.40391e+00 -1.59839e+00  2.40815e+00 -2.11341e-01
21Feb13_100305|  -6.09598e-01]
21Feb13_100305| [-9.09803e-01  1.21788e+00 -4.90502e-02 -2.38674e+00 -1.07796e+00
21Feb13_100305|   1.50503e+00  9.89401e-01 -7.67240e-02 -2.39136e-01 -1.23826e+00
21Feb13_100305|   9.26134e-02]
21Feb13_100305| [-1.84424e+00 -1.25659e+00  1.59797e+00 -1.15697e+00  1.06948e+00
21Feb13_100305|   4.16988e-01 -6.95885e-01  1.64775e+00  2.71237e-01  1.15771e+00
21Feb13_100305|  -9.32049e-02]
21Feb13_100305| [-5.90352e-01  7.55237e-02 -9.82628e-01  1.09728e+00 -1.32232e+00
21Feb13_100305|  -5.82659e-02  9.41700e-01 -8.22310e-02  1.52491e+00 -8.38811e-01
21Feb13_100305|  -3.71191e-01]
21Feb13_100305| [ 4.89785e-01  7.09934e-01  9.23224e-01 -1.16146e-01 -1.29886e+00
21Feb13_100305|  -8.44858e-01 -8.82313e-01  7.77497e-01  1.31740e+00 -7.86706e-01
21Feb13_100305|  -2.09546e+00]
21Feb13_100305| [-1.73451e+00  7.97409e-01  8.43432e-01 -9.64302e-01  1.37347e+00
21Feb13_100305|  -7.45391e-01  1.70867e-01 -1.36756e+00  5.82947e-01 -8.68562e-01
21Feb13_100305|   1.52281e+00]
21Feb13_100305| [ 4.00468e-01  1.96305e+00  2.45851e+00 -2.24292e-01  1.02207e+00
21Feb13_100305|  -3.21156e-01 -2.24026e-01  8.81373e-01 -4.33565e-01  2.26966e+00
21Feb13_100305|  -6.45783e-01]
21Feb13_100305| [-1.03032e-01  1.48460e+00  3.46312e-01 -1.19882e+00  1.66240e+00
21Feb13_100305|  -3.14884e-01  1.01077e+00 -6.85286e-03 -6.98216e-01 -8.47058e-01
21Feb13_100305|  -5.50347e-01]
21Feb13_100305| [-1.11871e+00 -3.47026e-02 -3.39108e-01 -2.64636e-02 -7.06458e-01
21Feb13_100305|   1.63302e-01  1.31775e+00 -1.90493e+00  7.70172e-01 -1.46652e+00
21Feb13_100305|   7.78757e-01]
21Feb13_100305| [-4.22403e-01  1.77868e+00 -2.99659e-01 -9.52842e-01  4.45016e-01
21Feb13_100305|   1.60657e-01 -2.50497e+00 -7.00889e-01 -9.19795e-01 -8.47184e-01
21Feb13_100305|  -2.65355e-01]
21Feb13_100305| [-7.24223e-01  9.33796e-01  6.35998e-01 -4.00108e-01 -3.21069e-01
21Feb13_100305|  -1.09825e-01  2.10246e+00  4.11840e-01 -1.23415e+00 -6.89791e-01
21Feb13_100305|   2.08588e+00]]
21Feb13_100305|-- Bias --
21Feb13_100305|[-0.37416  0.16993 -0.26367  0.66001 -0.03379  0.80785  0.01432 -0.35067
21Feb13_100305|  0.36146  0.54304 -0.66491]
21Feb13_100305|Layer 1:
21Feb13_100305|-- Config --
21Feb13_100305|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 11], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100305|-- Weights --
21Feb13_100305|[[ 0.46273 -0.52633  0.15311 -0.90421]
21Feb13_100305| [-0.74445  0.54112  0.87680  0.47482]
21Feb13_100305| [-0.26719  0.17345  0.03642 -0.34925]
21Feb13_100305| [-0.58874  0.51152 -0.29307 -0.83212]
21Feb13_100305| [ 0.47815 -0.42503 -0.70618  0.59181]
21Feb13_100305| [-0.41898 -0.52488  0.41435 -0.03709]
21Feb13_100305| [-0.86538 -0.59482 -0.23110  0.07142]
21Feb13_100305| [ 0.14002 -0.88633  0.43298  0.45916]
21Feb13_100305| [-0.13044 -0.48032 -0.74848  0.34067]
21Feb13_100305| [ 0.52895  0.74501  0.12361 -0.14643]
21Feb13_100305| [ 0.58188  0.58465  0.38240  0.65996]]
21Feb13_100305|-- Bias --
21Feb13_100305|[-0.76731  0.51896 -0.80290  0.22809]
21Feb13_100305|Layer 2:
21Feb13_100305|-- Config --
21Feb13_100305|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100305|-- Weights --
21Feb13_100305|[[-1.53127  0.04037]
21Feb13_100305| [ 0.13677 -1.46193]
21Feb13_100305| [-1.11724  0.35367]
21Feb13_100305| [ 0.49422  0.28831]]
21Feb13_100305|-- Bias --
21Feb13_100305|[ 0.11773 -0.60451]
21Feb13_100305|Predicting the validation and test data with the Best final individual.
21Feb13_100313| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_100313|-----------  ------------------  --------------------  ----------
21Feb13_100313|Validation         42.09                  30            0.00000
21Feb13_100313|   Test            36.40                  30            0.00000
21Feb13_100313|-------------------- Test #1 --------------------
21Feb13_100313|Best final individual weights
21Feb13_100313|Individual:
21Feb13_100313|-- Constant hidden layers --
21Feb13_100313|False
21Feb13_100313|Layer 0:
21Feb13_100313|-- Config --
21Feb13_100313|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 11, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100313|-- Weights --
21Feb13_100313|[[-1.06145e+00  8.68922e-01 -1.14379e+00 -1.49459e-01 -5.92039e-01
21Feb13_100313|  -2.35241e-01 -1.40309e+00  2.12924e+00  1.77198e-01  3.19702e-01
21Feb13_100313|  -4.23758e-01]
21Feb13_100313| [-7.60973e-01 -1.69902e+00  5.70321e-01  7.00329e-02  7.06671e-01
21Feb13_100313|   3.27493e-01 -1.70808e+00 -1.16196e+00  9.48272e-02  6.65005e-01
21Feb13_100313|   1.23887e+00]
21Feb13_100313| [-5.76717e-01  4.39987e-01 -4.71900e-01  9.84744e-01 -6.70632e-01
21Feb13_100313|  -8.05147e-02  4.07717e-01  1.82295e+00 -3.65259e-01  2.94562e-02
21Feb13_100313|   4.58511e-01]
21Feb13_100313| [ 1.51511e+00  9.93966e-01  3.08471e-01 -5.70096e-01  8.84235e-02
21Feb13_100313|  -3.23449e-01 -2.17552e-02  1.61666e+00  6.74902e-02 -2.42173e-01
21Feb13_100313|  -1.07711e+00]
21Feb13_100313| [ 7.49020e-01  1.03034e+00  1.53014e+00 -1.66588e+00 -1.34224e-01
21Feb13_100313|   1.92903e+00 -2.20672e+00  1.52629e-01 -9.97077e-01 -4.47184e-01
21Feb13_100313|  -1.17110e+00]
21Feb13_100313| [ 5.15382e-01  1.00118e+00 -1.08350e+00  1.03880e+00 -4.68603e-01
21Feb13_100313|  -4.59197e-02  1.11058e+00  9.17544e-01  1.33730e-01  6.53965e-02
21Feb13_100313|  -1.13911e+00]
21Feb13_100313| [-2.04317e+00 -6.76921e-01  7.78254e-01 -1.17217e+00 -1.67455e+00
21Feb13_100313|  -1.57760e-02  8.21084e-01 -1.13921e-01  7.37767e-01 -2.98292e-01
21Feb13_100313|   2.92646e-01]
21Feb13_100313| [-8.01681e-01 -9.13592e-01 -7.13092e-01  1.16235e+00 -5.79811e-01
21Feb13_100313|   5.53346e-01 -3.23183e-01 -5.66910e-02  1.05090e+00 -4.89620e-01
21Feb13_100313|  -1.40866e-01]
21Feb13_100313| [-6.85763e-01  4.32546e-01  2.07281e-01  1.86934e-01  1.03855e+00
21Feb13_100313|  -2.61743e-02 -1.45446e+00  2.99914e-01  9.96893e-01  5.16927e-01
21Feb13_100313|  -9.72506e-01]
21Feb13_100313| [ 6.87732e-01  8.12844e-01  3.51990e-01 -1.28179e+00 -1.00846e-02
21Feb13_100313|  -2.28308e-01  1.61447e+00 -2.91772e-01  1.12608e+00  6.13314e-01
21Feb13_100313|  -7.64936e-01]
21Feb13_100313| [ 3.88583e-01  3.89122e-02 -7.32680e-01 -1.74359e-01 -1.04680e+00
21Feb13_100313|   1.41735e+00  3.14067e-01 -1.41835e-01 -5.39265e-01 -8.08813e-01
21Feb13_100313|   6.58712e-01]
21Feb13_100313| [-6.68434e-01 -9.77746e-01  1.42569e+00 -2.64191e-01 -4.41971e-01
21Feb13_100313|   3.89653e-01  1.19610e+00 -1.70441e+00  2.60850e-01 -1.16352e+00
21Feb13_100313|   6.53371e-01]
21Feb13_100313| [ 2.16387e+00  1.21870e+00 -1.34441e-01 -8.61036e-01 -6.09299e-01
21Feb13_100313|   7.85750e-01 -9.41396e-01 -5.31235e-01  4.44708e-02 -5.08207e-01
21Feb13_100313|  -2.45830e+00]
21Feb13_100313| [-8.92729e-01 -2.15613e-01 -3.99405e-01  1.63387e+00 -8.65849e-01
21Feb13_100313|   7.58911e-01  7.49706e-01 -2.11143e+00  1.56748e-01  7.64897e-01
21Feb13_100313|  -1.13879e+00]
21Feb13_100313| [-8.57088e-01 -1.62365e-03  1.26530e+00 -2.22604e+00 -2.28715e+00
21Feb13_100313|  -9.99604e-02 -2.40021e-01  3.35970e-01 -8.82544e-01  4.85761e-01
21Feb13_100313|  -2.24202e+00]
21Feb13_100313| [ 5.52215e-01  8.52156e-02 -2.37466e-01  1.07672e+00  1.54941e+00
21Feb13_100313|   1.99606e-01 -1.34808e+00  7.53511e-01 -5.99088e-01  5.98790e-02
21Feb13_100313|  -1.07950e-01]
21Feb13_100313| [ 2.67109e+00 -1.75176e+00 -6.16214e-01 -1.86800e+00  5.99501e-01
21Feb13_100313|  -1.10529e+00 -2.74849e+00  6.11555e-01  9.78547e-03 -3.97459e-01
21Feb13_100313|   2.92660e-01]
21Feb13_100313| [ 4.54863e-01 -9.09117e-01 -8.30196e-01  1.50206e+00 -1.73504e+00
21Feb13_100313|  -1.30648e+00  5.55948e-01 -7.54174e-01  2.05420e+00  1.38864e+00
21Feb13_100313|   5.29561e-01]
21Feb13_100313| [-4.85366e-01 -3.53531e-01  9.05198e-01  7.65456e-01 -1.64749e+00
21Feb13_100313|   5.69847e-01  2.50378e-01  7.85001e-01 -1.45661e+00  8.34665e-02
21Feb13_100313|   8.15879e-01]
21Feb13_100313| [ 1.25727e+00  2.46577e-01  5.85987e-01  5.77962e-01 -2.59665e-01
21Feb13_100313|  -1.17493e-01  1.60910e+00  9.12990e-01  1.44670e+00  5.22422e-01
21Feb13_100313|  -1.94187e+00]
21Feb13_100313| [ 1.33867e-01 -1.27358e+00 -3.47982e-01 -6.08657e-02 -1.30348e-01
21Feb13_100313|  -1.17219e+00  1.24909e+00 -1.11782e+00  8.64220e-01  5.61000e-01
21Feb13_100313|  -1.48212e+00]
21Feb13_100313| [ 1.78205e+00 -2.50466e-01  1.33657e+00 -1.73845e+00  1.81425e+00
21Feb13_100313|  -8.02280e-01 -1.16246e+00  1.15245e+00 -3.53401e-01  6.57431e-01
21Feb13_100313|   9.30205e-01]
21Feb13_100313| [-3.03807e-01 -5.34010e-01 -5.36033e-02  1.22986e+00 -7.73593e-01
21Feb13_100313|  -2.41838e-02  9.47047e-01  1.63950e+00  8.57850e-01  7.18366e-01
21Feb13_100313|   6.19340e-01]
21Feb13_100313| [-1.56874e+00  9.13052e-01 -1.80219e+00 -6.85706e-02 -1.52747e-01
21Feb13_100313|  -1.23654e+00  7.66763e-01  8.76849e-01  1.38192e+00  1.74758e-01
21Feb13_100313|   9.19395e-01]
21Feb13_100313| [-3.41080e-01 -1.01680e+00 -7.82347e-01  5.72435e-01  1.21957e+00
21Feb13_100313|  -1.70168e+00  1.35596e+00 -1.36994e+00  6.54260e-01  2.17154e+00
21Feb13_100313|  -6.51639e-01]
21Feb13_100313| [-4.25343e-01  1.74798e+00  9.89404e-01 -1.04295e+00 -5.27053e-03
21Feb13_100313|   1.42040e+00  1.70140e+00 -5.47912e-01  2.85277e-01 -3.08635e-01
21Feb13_100313|  -1.87522e+00]
21Feb13_100313| [-2.65662e+00 -2.02900e+00 -1.49073e-01 -1.86322e-01 -6.15986e-01
21Feb13_100313|   1.02607e+00  7.96644e-01 -5.96812e-01  1.99503e-01 -1.24498e+00
21Feb13_100313|   1.01419e+00]
21Feb13_100313| [-1.31259e+00 -4.54363e-01  1.06493e-01  1.22074e+00  1.74518e-01
21Feb13_100313|  -5.57725e-01 -1.40429e+00  6.75301e-01  1.36944e+00 -3.09052e-01
21Feb13_100313|   1.21379e-01]
21Feb13_100313| [-1.66580e+00 -6.50639e-01  5.46120e-01 -1.25566e+00 -5.04851e-01
21Feb13_100313|  -5.49479e-01  1.11882e-01 -4.76139e-01 -4.81819e-01 -1.14210e-01
21Feb13_100313|  -1.57996e+00]
21Feb13_100313| [-7.64196e-01  1.06296e+00 -7.61805e-01 -1.49152e+00  9.36859e-01
21Feb13_100313|  -1.03321e+00 -2.87637e-01 -2.47389e-01  2.61926e-01  8.37227e-01
21Feb13_100313|  -3.42333e-01]
21Feb13_100313| [ 7.46572e-01 -1.58035e+00  8.02182e-01 -5.66302e-01 -8.47290e-01
21Feb13_100313|  -6.34161e-01  1.74178e+00  1.27802e+00  1.67001e+00 -7.94473e-01
21Feb13_100313|   1.10741e+00]
21Feb13_100313| [-6.74261e-01  5.99487e-01 -1.80403e+00 -1.02671e+00 -1.54235e+00
21Feb13_100313|  -1.26515e+00  4.29489e-01  8.21419e-01  1.06895e+00  1.13029e+00
21Feb13_100313|   7.65765e-01]
21Feb13_100313| [ 3.93528e-01 -5.92774e-01  5.40870e-01  9.02092e-01 -1.02404e+00
21Feb13_100313|  -1.10673e+00  2.35611e-01 -1.02808e+00  1.83820e-01  4.85873e-01
21Feb13_100313|  -1.59386e+00]
21Feb13_100313| [ 7.49489e-01 -6.49799e-01  1.34338e+00  2.12189e+00 -7.31882e-01
21Feb13_100313|   5.88080e-01  2.20549e+00 -1.06942e+00 -1.29756e+00 -7.96579e-01
21Feb13_100313|  -5.81803e-01]
21Feb13_100313| [-1.75688e-01  7.50212e-01 -1.37744e+00 -3.66415e-01  8.48990e-01
21Feb13_100313|  -1.88524e-01  1.13690e+00  1.33830e-01 -1.38609e+00 -3.92856e-01
21Feb13_100313|   5.05161e-01]
21Feb13_100313| [-1.56803e-01  6.44681e-01  4.29331e-01 -2.67595e-02  1.86944e+00
21Feb13_100313|   2.86790e+00  6.18832e-02  3.55496e-01  7.56248e-03 -1.48327e+00
21Feb13_100313|  -3.39873e-01]
21Feb13_100313| [-2.54559e-01 -1.85204e+00 -4.10288e-01 -8.81453e-01 -2.11431e-01
21Feb13_100313|   1.19889e+00  1.26373e+00 -6.36870e-01  1.26338e+00  5.36597e-01
21Feb13_100313|   1.31875e-02]
21Feb13_100313| [-6.96596e-02 -5.38534e-01  5.48522e-01  5.84182e-02  6.63353e-01
21Feb13_100313|  -8.82974e-01  8.67865e-01 -4.46778e-01  3.78957e-01 -1.73884e+00
21Feb13_100313|   7.87282e-01]
21Feb13_100313| [-9.53666e-01  9.80083e-01 -2.38978e-01 -1.94127e-01 -1.09625e+00
21Feb13_100313|   6.84617e-01 -1.90861e+00 -1.46974e+00  1.49925e-01 -6.42909e-01
21Feb13_100313|   1.10172e+00]
21Feb13_100313| [ 1.25790e-03  6.28597e-01  5.34003e-01  2.97309e-01  1.63498e+00
21Feb13_100313|   9.24999e-01 -2.69857e-01 -2.42502e+00  4.21238e-01  3.03054e-01
21Feb13_100313|  -3.28666e-01]
21Feb13_100313| [ 4.96081e-01  3.19527e-01  6.41207e-01  2.65925e-01  1.49075e+00
21Feb13_100313|   1.26551e-01 -3.97150e-01  1.17863e-01  3.16032e-01  1.62457e-01
21Feb13_100313|  -1.75157e+00]
21Feb13_100313| [ 1.07827e+00 -6.03883e-01 -1.79069e+00  3.62297e-01  1.72510e-01
21Feb13_100313|   2.07369e-01  2.87312e+00 -1.17485e+00  6.05597e-01 -1.01342e+00
21Feb13_100313|  -1.48620e+00]
21Feb13_100313| [ 2.10119e-01 -1.00618e+00 -1.21833e+00  1.51138e-01 -2.10391e+00
21Feb13_100313|  -9.70180e-01  1.51398e-01  3.86319e-01 -1.29116e+00  7.64629e-01
21Feb13_100313|   1.55391e+00]
21Feb13_100313| [-5.61712e-01  9.73611e-01 -1.11945e+00  6.21880e-02 -1.36018e+00
21Feb13_100313|   6.40626e-01  1.72919e-01 -8.32757e-02 -4.69855e-01  2.27406e+00
21Feb13_100313|   4.90539e-01]
21Feb13_100313| [ 9.10147e-01 -8.16175e-01  8.75446e-01 -5.79670e-01 -7.61116e-01
21Feb13_100313|  -1.51932e+00 -3.06235e-02 -4.15810e-01 -6.32631e-01  1.75909e+00
21Feb13_100313|   2.17078e-01]
21Feb13_100313| [-7.08015e-02  2.82435e+00  1.20172e+00 -2.33629e-01 -1.32451e+00
21Feb13_100313|  -3.79960e-01 -9.94142e-01  5.68075e-01 -2.52394e-02  2.67676e-01
21Feb13_100313|   1.39104e+00]
21Feb13_100313| [ 1.25990e+00  3.83043e-01 -5.14876e-01 -5.66390e-01  6.97171e-01
21Feb13_100313|  -4.78790e-02  1.40391e+00 -1.59839e+00  2.40815e+00 -2.11341e-01
21Feb13_100313|  -6.09598e-01]
21Feb13_100313| [-9.09803e-01  1.21788e+00 -4.90502e-02 -2.38674e+00 -1.07796e+00
21Feb13_100313|   1.50503e+00  9.89401e-01 -7.67240e-02 -2.39136e-01 -1.23826e+00
21Feb13_100313|   9.26134e-02]
21Feb13_100313| [-1.84424e+00 -1.25659e+00  1.59797e+00 -1.15697e+00  1.06948e+00
21Feb13_100313|   4.16988e-01 -6.95885e-01  1.64775e+00  2.71237e-01  1.15771e+00
21Feb13_100313|  -9.32049e-02]
21Feb13_100313| [-5.90352e-01  7.55237e-02 -9.82628e-01  1.09728e+00 -1.32232e+00
21Feb13_100313|  -5.82659e-02  9.41700e-01 -8.22310e-02  1.52491e+00 -8.38811e-01
21Feb13_100313|  -3.71191e-01]
21Feb13_100313| [ 4.89785e-01  7.09934e-01  9.23224e-01 -1.16146e-01 -1.29886e+00
21Feb13_100313|  -8.44858e-01 -8.82313e-01  7.77497e-01  1.31740e+00 -7.86706e-01
21Feb13_100313|  -2.09546e+00]
21Feb13_100313| [-1.73451e+00  7.97409e-01  8.43432e-01 -9.64302e-01  1.37347e+00
21Feb13_100313|  -7.45391e-01  1.70867e-01 -1.36756e+00  5.82947e-01 -8.68562e-01
21Feb13_100313|   1.52281e+00]
21Feb13_100313| [ 4.00468e-01  1.96305e+00  2.45851e+00 -2.24292e-01  1.02207e+00
21Feb13_100313|  -3.21156e-01 -2.24026e-01  8.81373e-01 -4.33565e-01  2.26966e+00
21Feb13_100313|  -6.45783e-01]
21Feb13_100313| [-1.03032e-01  1.48460e+00  3.46312e-01 -1.19882e+00  1.66240e+00
21Feb13_100313|  -3.14884e-01  1.01077e+00 -6.85286e-03 -6.98216e-01 -8.47058e-01
21Feb13_100313|  -5.50347e-01]
21Feb13_100313| [-1.11871e+00 -3.47026e-02 -3.39108e-01 -2.64636e-02 -7.06458e-01
21Feb13_100313|   1.63302e-01  1.31775e+00 -1.90493e+00  7.70172e-01 -1.46652e+00
21Feb13_100313|   7.78757e-01]
21Feb13_100313| [-4.22403e-01  1.77868e+00 -2.99659e-01 -9.52842e-01  4.45016e-01
21Feb13_100313|   1.60657e-01 -2.50497e+00 -7.00889e-01 -9.19795e-01 -8.47184e-01
21Feb13_100313|  -2.65355e-01]
21Feb13_100313| [-7.24223e-01  9.33796e-01  6.35998e-01 -4.00108e-01 -3.21069e-01
21Feb13_100313|  -1.09825e-01  2.10246e+00  4.11840e-01 -1.23415e+00 -6.89791e-01
21Feb13_100313|   2.08588e+00]]
21Feb13_100313|-- Bias --
21Feb13_100313|[-0.37416  0.16993 -0.26367  0.66001 -0.03379  0.80785  0.01432 -0.35067
21Feb13_100313|  0.36146  0.54304 -0.66491]
21Feb13_100313|Layer 1:
21Feb13_100313|-- Config --
21Feb13_100313|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 11], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100313|-- Weights --
21Feb13_100313|[[ 0.46273 -0.52633  0.15311 -0.90421]
21Feb13_100313| [-0.74445  0.54112  0.87680  0.47482]
21Feb13_100313| [-0.26719  0.17345  0.03642 -0.34925]
21Feb13_100313| [-0.58874  0.51152 -0.29307 -0.83212]
21Feb13_100313| [ 0.47815 -0.42503 -0.70618  0.59181]
21Feb13_100313| [-0.41898 -0.52488  0.41435 -0.03709]
21Feb13_100313| [-0.86538 -0.59482 -0.23110  0.07142]
21Feb13_100313| [ 0.14002 -0.88633  0.43298  0.45916]
21Feb13_100313| [-0.13044 -0.48032 -0.74848  0.34067]
21Feb13_100313| [ 0.52895  0.74501  0.12361 -0.14643]
21Feb13_100313| [ 0.58188  0.58465  0.38240  0.65996]]
21Feb13_100313|-- Bias --
21Feb13_100313|[-0.76731  0.51896 -0.80290  0.22809]
21Feb13_100313|Layer 2:
21Feb13_100313|-- Config --
21Feb13_100313|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100313|-- Weights --
21Feb13_100313|[[-1.53127  0.04037]
21Feb13_100313| [ 0.13677 -1.46193]
21Feb13_100313| [-1.11724  0.35367]
21Feb13_100313| [ 0.49422  0.28831]]
21Feb13_100313|-- Bias --
21Feb13_100313|[ 0.11773 -0.60451]
21Feb13_100313|Predicting the validation and test data with the Best final individual.
21Feb13_100320| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_100320|-----------  ------------------  --------------------  ----------
21Feb13_100320|Validation         42.00                  30            0.00000
21Feb13_100320|   Test            29.45                  30            0.25591
21Feb13_100320|-------------------- Test #2 --------------------
21Feb13_100320|Best final individual weights
21Feb13_100320|Individual:
21Feb13_100320|-- Constant hidden layers --
21Feb13_100320|False
21Feb13_100320|Layer 0:
21Feb13_100320|-- Config --
21Feb13_100320|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 11, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100320|-- Weights --
21Feb13_100320|[[-1.06145e+00  8.68922e-01 -1.14379e+00 -1.49459e-01 -5.92039e-01
21Feb13_100320|  -2.35241e-01 -1.40309e+00  2.12924e+00  1.77198e-01  3.19702e-01
21Feb13_100320|  -4.23758e-01]
21Feb13_100320| [-7.60973e-01 -1.69902e+00  5.70321e-01  7.00329e-02  7.06671e-01
21Feb13_100320|   3.27493e-01 -1.70808e+00 -1.16196e+00  9.48272e-02  6.65005e-01
21Feb13_100320|   1.23887e+00]
21Feb13_100320| [-5.76717e-01  4.39987e-01 -4.71900e-01  9.84744e-01 -6.70632e-01
21Feb13_100320|  -8.05147e-02  4.07717e-01  1.82295e+00 -3.65259e-01  2.94562e-02
21Feb13_100320|   4.58511e-01]
21Feb13_100320| [ 1.51511e+00  9.93966e-01  3.08471e-01 -5.70096e-01  8.84235e-02
21Feb13_100320|  -3.23449e-01 -2.17552e-02  1.61666e+00  6.74902e-02 -2.42173e-01
21Feb13_100320|  -1.07711e+00]
21Feb13_100320| [ 7.49020e-01  1.03034e+00  1.53014e+00 -1.66588e+00 -1.34224e-01
21Feb13_100320|   1.92903e+00 -2.20672e+00  1.52629e-01 -9.97077e-01 -4.47184e-01
21Feb13_100320|  -1.17110e+00]
21Feb13_100320| [ 5.15382e-01  1.00118e+00 -1.08350e+00  1.03880e+00 -4.68603e-01
21Feb13_100320|  -4.59197e-02  1.11058e+00  9.17544e-01  1.33730e-01  6.53965e-02
21Feb13_100320|  -1.13911e+00]
21Feb13_100320| [-2.04317e+00 -6.76921e-01  7.78254e-01 -1.17217e+00 -1.67455e+00
21Feb13_100320|  -1.57760e-02  8.21084e-01 -1.13921e-01  7.37767e-01 -2.98292e-01
21Feb13_100320|   2.92646e-01]
21Feb13_100320| [-8.01681e-01 -9.13592e-01 -7.13092e-01  1.16235e+00 -5.79811e-01
21Feb13_100320|   5.53346e-01 -3.23183e-01 -5.66910e-02  1.05090e+00 -4.89620e-01
21Feb13_100320|  -1.40866e-01]
21Feb13_100320| [-6.85763e-01  4.32546e-01  2.07281e-01  1.86934e-01  1.03855e+00
21Feb13_100320|  -2.61743e-02 -1.45446e+00  2.99914e-01  9.96893e-01  5.16927e-01
21Feb13_100320|  -9.72506e-01]
21Feb13_100320| [ 6.87732e-01  8.12844e-01  3.51990e-01 -1.28179e+00 -1.00846e-02
21Feb13_100320|  -2.28308e-01  1.61447e+00 -2.91772e-01  1.12608e+00  6.13314e-01
21Feb13_100320|  -7.64936e-01]
21Feb13_100320| [ 3.88583e-01  3.89122e-02 -7.32680e-01 -1.74359e-01 -1.04680e+00
21Feb13_100320|   1.41735e+00  3.14067e-01 -1.41835e-01 -5.39265e-01 -8.08813e-01
21Feb13_100320|   6.58712e-01]
21Feb13_100320| [-6.68434e-01 -9.77746e-01  1.42569e+00 -2.64191e-01 -4.41971e-01
21Feb13_100320|   3.89653e-01  1.19610e+00 -1.70441e+00  2.60850e-01 -1.16352e+00
21Feb13_100320|   6.53371e-01]
21Feb13_100320| [ 2.16387e+00  1.21870e+00 -1.34441e-01 -8.61036e-01 -6.09299e-01
21Feb13_100320|   7.85750e-01 -9.41396e-01 -5.31235e-01  4.44708e-02 -5.08207e-01
21Feb13_100320|  -2.45830e+00]
21Feb13_100320| [-8.92729e-01 -2.15613e-01 -3.99405e-01  1.63387e+00 -8.65849e-01
21Feb13_100320|   7.58911e-01  7.49706e-01 -2.11143e+00  1.56748e-01  7.64897e-01
21Feb13_100320|  -1.13879e+00]
21Feb13_100320| [-8.57088e-01 -1.62365e-03  1.26530e+00 -2.22604e+00 -2.28715e+00
21Feb13_100320|  -9.99604e-02 -2.40021e-01  3.35970e-01 -8.82544e-01  4.85761e-01
21Feb13_100320|  -2.24202e+00]
21Feb13_100320| [ 5.52215e-01  8.52156e-02 -2.37466e-01  1.07672e+00  1.54941e+00
21Feb13_100320|   1.99606e-01 -1.34808e+00  7.53511e-01 -5.99088e-01  5.98790e-02
21Feb13_100320|  -1.07950e-01]
21Feb13_100320| [ 2.67109e+00 -1.75176e+00 -6.16214e-01 -1.86800e+00  5.99501e-01
21Feb13_100320|  -1.10529e+00 -2.74849e+00  6.11555e-01  9.78547e-03 -3.97459e-01
21Feb13_100320|   2.92660e-01]
21Feb13_100320| [ 4.54863e-01 -9.09117e-01 -8.30196e-01  1.50206e+00 -1.73504e+00
21Feb13_100320|  -1.30648e+00  5.55948e-01 -7.54174e-01  2.05420e+00  1.38864e+00
21Feb13_100320|   5.29561e-01]
21Feb13_100320| [-4.85366e-01 -3.53531e-01  9.05198e-01  7.65456e-01 -1.64749e+00
21Feb13_100320|   5.69847e-01  2.50378e-01  7.85001e-01 -1.45661e+00  8.34665e-02
21Feb13_100320|   8.15879e-01]
21Feb13_100320| [ 1.25727e+00  2.46577e-01  5.85987e-01  5.77962e-01 -2.59665e-01
21Feb13_100320|  -1.17493e-01  1.60910e+00  9.12990e-01  1.44670e+00  5.22422e-01
21Feb13_100320|  -1.94187e+00]
21Feb13_100320| [ 1.33867e-01 -1.27358e+00 -3.47982e-01 -6.08657e-02 -1.30348e-01
21Feb13_100320|  -1.17219e+00  1.24909e+00 -1.11782e+00  8.64220e-01  5.61000e-01
21Feb13_100320|  -1.48212e+00]
21Feb13_100320| [ 1.78205e+00 -2.50466e-01  1.33657e+00 -1.73845e+00  1.81425e+00
21Feb13_100320|  -8.02280e-01 -1.16246e+00  1.15245e+00 -3.53401e-01  6.57431e-01
21Feb13_100320|   9.30205e-01]
21Feb13_100320| [-3.03807e-01 -5.34010e-01 -5.36033e-02  1.22986e+00 -7.73593e-01
21Feb13_100320|  -2.41838e-02  9.47047e-01  1.63950e+00  8.57850e-01  7.18366e-01
21Feb13_100320|   6.19340e-01]
21Feb13_100320| [-1.56874e+00  9.13052e-01 -1.80219e+00 -6.85706e-02 -1.52747e-01
21Feb13_100320|  -1.23654e+00  7.66763e-01  8.76849e-01  1.38192e+00  1.74758e-01
21Feb13_100320|   9.19395e-01]
21Feb13_100320| [-3.41080e-01 -1.01680e+00 -7.82347e-01  5.72435e-01  1.21957e+00
21Feb13_100320|  -1.70168e+00  1.35596e+00 -1.36994e+00  6.54260e-01  2.17154e+00
21Feb13_100320|  -6.51639e-01]
21Feb13_100320| [-4.25343e-01  1.74798e+00  9.89404e-01 -1.04295e+00 -5.27053e-03
21Feb13_100320|   1.42040e+00  1.70140e+00 -5.47912e-01  2.85277e-01 -3.08635e-01
21Feb13_100320|  -1.87522e+00]
21Feb13_100320| [-2.65662e+00 -2.02900e+00 -1.49073e-01 -1.86322e-01 -6.15986e-01
21Feb13_100320|   1.02607e+00  7.96644e-01 -5.96812e-01  1.99503e-01 -1.24498e+00
21Feb13_100320|   1.01419e+00]
21Feb13_100320| [-1.31259e+00 -4.54363e-01  1.06493e-01  1.22074e+00  1.74518e-01
21Feb13_100320|  -5.57725e-01 -1.40429e+00  6.75301e-01  1.36944e+00 -3.09052e-01
21Feb13_100320|   1.21379e-01]
21Feb13_100320| [-1.66580e+00 -6.50639e-01  5.46120e-01 -1.25566e+00 -5.04851e-01
21Feb13_100320|  -5.49479e-01  1.11882e-01 -4.76139e-01 -4.81819e-01 -1.14210e-01
21Feb13_100320|  -1.57996e+00]
21Feb13_100320| [-7.64196e-01  1.06296e+00 -7.61805e-01 -1.49152e+00  9.36859e-01
21Feb13_100320|  -1.03321e+00 -2.87637e-01 -2.47389e-01  2.61926e-01  8.37227e-01
21Feb13_100320|  -3.42333e-01]
21Feb13_100320| [ 7.46572e-01 -1.58035e+00  8.02182e-01 -5.66302e-01 -8.47290e-01
21Feb13_100320|  -6.34161e-01  1.74178e+00  1.27802e+00  1.67001e+00 -7.94473e-01
21Feb13_100320|   1.10741e+00]
21Feb13_100320| [-6.74261e-01  5.99487e-01 -1.80403e+00 -1.02671e+00 -1.54235e+00
21Feb13_100320|  -1.26515e+00  4.29489e-01  8.21419e-01  1.06895e+00  1.13029e+00
21Feb13_100320|   7.65765e-01]
21Feb13_100320| [ 3.93528e-01 -5.92774e-01  5.40870e-01  9.02092e-01 -1.02404e+00
21Feb13_100320|  -1.10673e+00  2.35611e-01 -1.02808e+00  1.83820e-01  4.85873e-01
21Feb13_100320|  -1.59386e+00]
21Feb13_100320| [ 7.49489e-01 -6.49799e-01  1.34338e+00  2.12189e+00 -7.31882e-01
21Feb13_100320|   5.88080e-01  2.20549e+00 -1.06942e+00 -1.29756e+00 -7.96579e-01
21Feb13_100320|  -5.81803e-01]
21Feb13_100320| [-1.75688e-01  7.50212e-01 -1.37744e+00 -3.66415e-01  8.48990e-01
21Feb13_100320|  -1.88524e-01  1.13690e+00  1.33830e-01 -1.38609e+00 -3.92856e-01
21Feb13_100320|   5.05161e-01]
21Feb13_100320| [-1.56803e-01  6.44681e-01  4.29331e-01 -2.67595e-02  1.86944e+00
21Feb13_100320|   2.86790e+00  6.18832e-02  3.55496e-01  7.56248e-03 -1.48327e+00
21Feb13_100320|  -3.39873e-01]
21Feb13_100320| [-2.54559e-01 -1.85204e+00 -4.10288e-01 -8.81453e-01 -2.11431e-01
21Feb13_100320|   1.19889e+00  1.26373e+00 -6.36870e-01  1.26338e+00  5.36597e-01
21Feb13_100320|   1.31875e-02]
21Feb13_100320| [-6.96596e-02 -5.38534e-01  5.48522e-01  5.84182e-02  6.63353e-01
21Feb13_100320|  -8.82974e-01  8.67865e-01 -4.46778e-01  3.78957e-01 -1.73884e+00
21Feb13_100320|   7.87282e-01]
21Feb13_100320| [-9.53666e-01  9.80083e-01 -2.38978e-01 -1.94127e-01 -1.09625e+00
21Feb13_100320|   6.84617e-01 -1.90861e+00 -1.46974e+00  1.49925e-01 -6.42909e-01
21Feb13_100320|   1.10172e+00]
21Feb13_100320| [ 1.25790e-03  6.28597e-01  5.34003e-01  2.97309e-01  1.63498e+00
21Feb13_100320|   9.24999e-01 -2.69857e-01 -2.42502e+00  4.21238e-01  3.03054e-01
21Feb13_100320|  -3.28666e-01]
21Feb13_100320| [ 4.96081e-01  3.19527e-01  6.41207e-01  2.65925e-01  1.49075e+00
21Feb13_100320|   1.26551e-01 -3.97150e-01  1.17863e-01  3.16032e-01  1.62457e-01
21Feb13_100320|  -1.75157e+00]
21Feb13_100320| [ 1.07827e+00 -6.03883e-01 -1.79069e+00  3.62297e-01  1.72510e-01
21Feb13_100320|   2.07369e-01  2.87312e+00 -1.17485e+00  6.05597e-01 -1.01342e+00
21Feb13_100320|  -1.48620e+00]
21Feb13_100320| [ 2.10119e-01 -1.00618e+00 -1.21833e+00  1.51138e-01 -2.10391e+00
21Feb13_100320|  -9.70180e-01  1.51398e-01  3.86319e-01 -1.29116e+00  7.64629e-01
21Feb13_100320|   1.55391e+00]
21Feb13_100320| [-5.61712e-01  9.73611e-01 -1.11945e+00  6.21880e-02 -1.36018e+00
21Feb13_100320|   6.40626e-01  1.72919e-01 -8.32757e-02 -4.69855e-01  2.27406e+00
21Feb13_100320|   4.90539e-01]
21Feb13_100320| [ 9.10147e-01 -8.16175e-01  8.75446e-01 -5.79670e-01 -7.61116e-01
21Feb13_100320|  -1.51932e+00 -3.06235e-02 -4.15810e-01 -6.32631e-01  1.75909e+00
21Feb13_100320|   2.17078e-01]
21Feb13_100320| [-7.08015e-02  2.82435e+00  1.20172e+00 -2.33629e-01 -1.32451e+00
21Feb13_100320|  -3.79960e-01 -9.94142e-01  5.68075e-01 -2.52394e-02  2.67676e-01
21Feb13_100320|   1.39104e+00]
21Feb13_100320| [ 1.25990e+00  3.83043e-01 -5.14876e-01 -5.66390e-01  6.97171e-01
21Feb13_100320|  -4.78790e-02  1.40391e+00 -1.59839e+00  2.40815e+00 -2.11341e-01
21Feb13_100320|  -6.09598e-01]
21Feb13_100320| [-9.09803e-01  1.21788e+00 -4.90502e-02 -2.38674e+00 -1.07796e+00
21Feb13_100320|   1.50503e+00  9.89401e-01 -7.67240e-02 -2.39136e-01 -1.23826e+00
21Feb13_100320|   9.26134e-02]
21Feb13_100320| [-1.84424e+00 -1.25659e+00  1.59797e+00 -1.15697e+00  1.06948e+00
21Feb13_100320|   4.16988e-01 -6.95885e-01  1.64775e+00  2.71237e-01  1.15771e+00
21Feb13_100320|  -9.32049e-02]
21Feb13_100320| [-5.90352e-01  7.55237e-02 -9.82628e-01  1.09728e+00 -1.32232e+00
21Feb13_100320|  -5.82659e-02  9.41700e-01 -8.22310e-02  1.52491e+00 -8.38811e-01
21Feb13_100320|  -3.71191e-01]
21Feb13_100320| [ 4.89785e-01  7.09934e-01  9.23224e-01 -1.16146e-01 -1.29886e+00
21Feb13_100320|  -8.44858e-01 -8.82313e-01  7.77497e-01  1.31740e+00 -7.86706e-01
21Feb13_100320|  -2.09546e+00]
21Feb13_100320| [-1.73451e+00  7.97409e-01  8.43432e-01 -9.64302e-01  1.37347e+00
21Feb13_100320|  -7.45391e-01  1.70867e-01 -1.36756e+00  5.82947e-01 -8.68562e-01
21Feb13_100320|   1.52281e+00]
21Feb13_100320| [ 4.00468e-01  1.96305e+00  2.45851e+00 -2.24292e-01  1.02207e+00
21Feb13_100320|  -3.21156e-01 -2.24026e-01  8.81373e-01 -4.33565e-01  2.26966e+00
21Feb13_100320|  -6.45783e-01]
21Feb13_100320| [-1.03032e-01  1.48460e+00  3.46312e-01 -1.19882e+00  1.66240e+00
21Feb13_100320|  -3.14884e-01  1.01077e+00 -6.85286e-03 -6.98216e-01 -8.47058e-01
21Feb13_100320|  -5.50347e-01]
21Feb13_100320| [-1.11871e+00 -3.47026e-02 -3.39108e-01 -2.64636e-02 -7.06458e-01
21Feb13_100320|   1.63302e-01  1.31775e+00 -1.90493e+00  7.70172e-01 -1.46652e+00
21Feb13_100320|   7.78757e-01]
21Feb13_100320| [-4.22403e-01  1.77868e+00 -2.99659e-01 -9.52842e-01  4.45016e-01
21Feb13_100320|   1.60657e-01 -2.50497e+00 -7.00889e-01 -9.19795e-01 -8.47184e-01
21Feb13_100320|  -2.65355e-01]
21Feb13_100320| [-7.24223e-01  9.33796e-01  6.35998e-01 -4.00108e-01 -3.21069e-01
21Feb13_100320|  -1.09825e-01  2.10246e+00  4.11840e-01 -1.23415e+00 -6.89791e-01
21Feb13_100320|   2.08588e+00]]
21Feb13_100320|-- Bias --
21Feb13_100320|[-0.37416  0.16993 -0.26367  0.66001 -0.03379  0.80785  0.01432 -0.35067
21Feb13_100320|  0.36146  0.54304 -0.66491]
21Feb13_100320|Layer 1:
21Feb13_100320|-- Config --
21Feb13_100320|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 11], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100320|-- Weights --
21Feb13_100320|[[ 0.46273 -0.52633  0.15311 -0.90421]
21Feb13_100320| [-0.74445  0.54112  0.87680  0.47482]
21Feb13_100320| [-0.26719  0.17345  0.03642 -0.34925]
21Feb13_100320| [-0.58874  0.51152 -0.29307 -0.83212]
21Feb13_100320| [ 0.47815 -0.42503 -0.70618  0.59181]
21Feb13_100320| [-0.41898 -0.52488  0.41435 -0.03709]
21Feb13_100320| [-0.86538 -0.59482 -0.23110  0.07142]
21Feb13_100320| [ 0.14002 -0.88633  0.43298  0.45916]
21Feb13_100320| [-0.13044 -0.48032 -0.74848  0.34067]
21Feb13_100320| [ 0.52895  0.74501  0.12361 -0.14643]
21Feb13_100320| [ 0.58188  0.58465  0.38240  0.65996]]
21Feb13_100320|-- Bias --
21Feb13_100320|[-0.76731  0.51896 -0.80290  0.22809]
21Feb13_100320|Layer 2:
21Feb13_100320|-- Config --
21Feb13_100320|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100320|-- Weights --
21Feb13_100320|[[-1.53127  0.04037]
21Feb13_100320| [ 0.13677 -1.46193]
21Feb13_100320| [-1.11724  0.35367]
21Feb13_100320| [ 0.49422  0.28831]]
21Feb13_100320|-- Bias --
21Feb13_100320|[ 0.11773 -0.60451]
21Feb13_100320|Predicting the validation and test data with the Best final individual.
21Feb13_100327| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_100327|-----------  ------------------  --------------------  ----------
21Feb13_100327|Validation         42.00                  30            0.00000
21Feb13_100327|   Test            36.40                  30            0.00000
21Feb13_100327|-------------------- Test #3 --------------------
21Feb13_100327|Best final individual weights
21Feb13_100327|Individual:
21Feb13_100327|-- Constant hidden layers --
21Feb13_100327|False
21Feb13_100327|Layer 0:
21Feb13_100327|-- Config --
21Feb13_100327|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 11, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100327|-- Weights --
21Feb13_100327|[[-1.06145e+00  8.68922e-01 -1.14379e+00 -1.49459e-01 -5.92039e-01
21Feb13_100327|  -2.35241e-01 -1.40309e+00  2.12924e+00  1.77198e-01  3.19702e-01
21Feb13_100327|  -4.23758e-01]
21Feb13_100327| [-7.60973e-01 -1.69902e+00  5.70321e-01  7.00329e-02  7.06671e-01
21Feb13_100327|   3.27493e-01 -1.70808e+00 -1.16196e+00  9.48272e-02  6.65005e-01
21Feb13_100327|   1.23887e+00]
21Feb13_100327| [-5.76717e-01  4.39987e-01 -4.71900e-01  9.84744e-01 -6.70632e-01
21Feb13_100327|  -8.05147e-02  4.07717e-01  1.82295e+00 -3.65259e-01  2.94562e-02
21Feb13_100327|   4.58511e-01]
21Feb13_100327| [ 1.51511e+00  9.93966e-01  3.08471e-01 -5.70096e-01  8.84235e-02
21Feb13_100327|  -3.23449e-01 -2.17552e-02  1.61666e+00  6.74902e-02 -2.42173e-01
21Feb13_100327|  -1.07711e+00]
21Feb13_100327| [ 7.49020e-01  1.03034e+00  1.53014e+00 -1.66588e+00 -1.34224e-01
21Feb13_100327|   1.92903e+00 -2.20672e+00  1.52629e-01 -9.97077e-01 -4.47184e-01
21Feb13_100327|  -1.17110e+00]
21Feb13_100327| [ 5.15382e-01  1.00118e+00 -1.08350e+00  1.03880e+00 -4.68603e-01
21Feb13_100327|  -4.59197e-02  1.11058e+00  9.17544e-01  1.33730e-01  6.53965e-02
21Feb13_100327|  -1.13911e+00]
21Feb13_100327| [-2.04317e+00 -6.76921e-01  7.78254e-01 -1.17217e+00 -1.67455e+00
21Feb13_100327|  -1.57760e-02  8.21084e-01 -1.13921e-01  7.37767e-01 -2.98292e-01
21Feb13_100327|   2.92646e-01]
21Feb13_100327| [-8.01681e-01 -9.13592e-01 -7.13092e-01  1.16235e+00 -5.79811e-01
21Feb13_100327|   5.53346e-01 -3.23183e-01 -5.66910e-02  1.05090e+00 -4.89620e-01
21Feb13_100327|  -1.40866e-01]
21Feb13_100327| [-6.85763e-01  4.32546e-01  2.07281e-01  1.86934e-01  1.03855e+00
21Feb13_100327|  -2.61743e-02 -1.45446e+00  2.99914e-01  9.96893e-01  5.16927e-01
21Feb13_100327|  -9.72506e-01]
21Feb13_100327| [ 6.87732e-01  8.12844e-01  3.51990e-01 -1.28179e+00 -1.00846e-02
21Feb13_100327|  -2.28308e-01  1.61447e+00 -2.91772e-01  1.12608e+00  6.13314e-01
21Feb13_100327|  -7.64936e-01]
21Feb13_100327| [ 3.88583e-01  3.89122e-02 -7.32680e-01 -1.74359e-01 -1.04680e+00
21Feb13_100327|   1.41735e+00  3.14067e-01 -1.41835e-01 -5.39265e-01 -8.08813e-01
21Feb13_100327|   6.58712e-01]
21Feb13_100327| [-6.68434e-01 -9.77746e-01  1.42569e+00 -2.64191e-01 -4.41971e-01
21Feb13_100327|   3.89653e-01  1.19610e+00 -1.70441e+00  2.60850e-01 -1.16352e+00
21Feb13_100327|   6.53371e-01]
21Feb13_100327| [ 2.16387e+00  1.21870e+00 -1.34441e-01 -8.61036e-01 -6.09299e-01
21Feb13_100327|   7.85750e-01 -9.41396e-01 -5.31235e-01  4.44708e-02 -5.08207e-01
21Feb13_100327|  -2.45830e+00]
21Feb13_100327| [-8.92729e-01 -2.15613e-01 -3.99405e-01  1.63387e+00 -8.65849e-01
21Feb13_100327|   7.58911e-01  7.49706e-01 -2.11143e+00  1.56748e-01  7.64897e-01
21Feb13_100327|  -1.13879e+00]
21Feb13_100327| [-8.57088e-01 -1.62365e-03  1.26530e+00 -2.22604e+00 -2.28715e+00
21Feb13_100327|  -9.99604e-02 -2.40021e-01  3.35970e-01 -8.82544e-01  4.85761e-01
21Feb13_100327|  -2.24202e+00]
21Feb13_100327| [ 5.52215e-01  8.52156e-02 -2.37466e-01  1.07672e+00  1.54941e+00
21Feb13_100327|   1.99606e-01 -1.34808e+00  7.53511e-01 -5.99088e-01  5.98790e-02
21Feb13_100327|  -1.07950e-01]
21Feb13_100327| [ 2.67109e+00 -1.75176e+00 -6.16214e-01 -1.86800e+00  5.99501e-01
21Feb13_100327|  -1.10529e+00 -2.74849e+00  6.11555e-01  9.78547e-03 -3.97459e-01
21Feb13_100327|   2.92660e-01]
21Feb13_100327| [ 4.54863e-01 -9.09117e-01 -8.30196e-01  1.50206e+00 -1.73504e+00
21Feb13_100327|  -1.30648e+00  5.55948e-01 -7.54174e-01  2.05420e+00  1.38864e+00
21Feb13_100327|   5.29561e-01]
21Feb13_100327| [-4.85366e-01 -3.53531e-01  9.05198e-01  7.65456e-01 -1.64749e+00
21Feb13_100327|   5.69847e-01  2.50378e-01  7.85001e-01 -1.45661e+00  8.34665e-02
21Feb13_100327|   8.15879e-01]
21Feb13_100327| [ 1.25727e+00  2.46577e-01  5.85987e-01  5.77962e-01 -2.59665e-01
21Feb13_100327|  -1.17493e-01  1.60910e+00  9.12990e-01  1.44670e+00  5.22422e-01
21Feb13_100327|  -1.94187e+00]
21Feb13_100327| [ 1.33867e-01 -1.27358e+00 -3.47982e-01 -6.08657e-02 -1.30348e-01
21Feb13_100327|  -1.17219e+00  1.24909e+00 -1.11782e+00  8.64220e-01  5.61000e-01
21Feb13_100327|  -1.48212e+00]
21Feb13_100327| [ 1.78205e+00 -2.50466e-01  1.33657e+00 -1.73845e+00  1.81425e+00
21Feb13_100327|  -8.02280e-01 -1.16246e+00  1.15245e+00 -3.53401e-01  6.57431e-01
21Feb13_100327|   9.30205e-01]
21Feb13_100327| [-3.03807e-01 -5.34010e-01 -5.36033e-02  1.22986e+00 -7.73593e-01
21Feb13_100327|  -2.41838e-02  9.47047e-01  1.63950e+00  8.57850e-01  7.18366e-01
21Feb13_100327|   6.19340e-01]
21Feb13_100327| [-1.56874e+00  9.13052e-01 -1.80219e+00 -6.85706e-02 -1.52747e-01
21Feb13_100327|  -1.23654e+00  7.66763e-01  8.76849e-01  1.38192e+00  1.74758e-01
21Feb13_100327|   9.19395e-01]
21Feb13_100327| [-3.41080e-01 -1.01680e+00 -7.82347e-01  5.72435e-01  1.21957e+00
21Feb13_100327|  -1.70168e+00  1.35596e+00 -1.36994e+00  6.54260e-01  2.17154e+00
21Feb13_100327|  -6.51639e-01]
21Feb13_100327| [-4.25343e-01  1.74798e+00  9.89404e-01 -1.04295e+00 -5.27053e-03
21Feb13_100327|   1.42040e+00  1.70140e+00 -5.47912e-01  2.85277e-01 -3.08635e-01
21Feb13_100327|  -1.87522e+00]
21Feb13_100327| [-2.65662e+00 -2.02900e+00 -1.49073e-01 -1.86322e-01 -6.15986e-01
21Feb13_100327|   1.02607e+00  7.96644e-01 -5.96812e-01  1.99503e-01 -1.24498e+00
21Feb13_100327|   1.01419e+00]
21Feb13_100327| [-1.31259e+00 -4.54363e-01  1.06493e-01  1.22074e+00  1.74518e-01
21Feb13_100327|  -5.57725e-01 -1.40429e+00  6.75301e-01  1.36944e+00 -3.09052e-01
21Feb13_100327|   1.21379e-01]
21Feb13_100327| [-1.66580e+00 -6.50639e-01  5.46120e-01 -1.25566e+00 -5.04851e-01
21Feb13_100327|  -5.49479e-01  1.11882e-01 -4.76139e-01 -4.81819e-01 -1.14210e-01
21Feb13_100327|  -1.57996e+00]
21Feb13_100327| [-7.64196e-01  1.06296e+00 -7.61805e-01 -1.49152e+00  9.36859e-01
21Feb13_100327|  -1.03321e+00 -2.87637e-01 -2.47389e-01  2.61926e-01  8.37227e-01
21Feb13_100327|  -3.42333e-01]
21Feb13_100327| [ 7.46572e-01 -1.58035e+00  8.02182e-01 -5.66302e-01 -8.47290e-01
21Feb13_100327|  -6.34161e-01  1.74178e+00  1.27802e+00  1.67001e+00 -7.94473e-01
21Feb13_100327|   1.10741e+00]
21Feb13_100327| [-6.74261e-01  5.99487e-01 -1.80403e+00 -1.02671e+00 -1.54235e+00
21Feb13_100327|  -1.26515e+00  4.29489e-01  8.21419e-01  1.06895e+00  1.13029e+00
21Feb13_100327|   7.65765e-01]
21Feb13_100327| [ 3.93528e-01 -5.92774e-01  5.40870e-01  9.02092e-01 -1.02404e+00
21Feb13_100327|  -1.10673e+00  2.35611e-01 -1.02808e+00  1.83820e-01  4.85873e-01
21Feb13_100327|  -1.59386e+00]
21Feb13_100327| [ 7.49489e-01 -6.49799e-01  1.34338e+00  2.12189e+00 -7.31882e-01
21Feb13_100327|   5.88080e-01  2.20549e+00 -1.06942e+00 -1.29756e+00 -7.96579e-01
21Feb13_100327|  -5.81803e-01]
21Feb13_100327| [-1.75688e-01  7.50212e-01 -1.37744e+00 -3.66415e-01  8.48990e-01
21Feb13_100327|  -1.88524e-01  1.13690e+00  1.33830e-01 -1.38609e+00 -3.92856e-01
21Feb13_100327|   5.05161e-01]
21Feb13_100327| [-1.56803e-01  6.44681e-01  4.29331e-01 -2.67595e-02  1.86944e+00
21Feb13_100327|   2.86790e+00  6.18832e-02  3.55496e-01  7.56248e-03 -1.48327e+00
21Feb13_100327|  -3.39873e-01]
21Feb13_100327| [-2.54559e-01 -1.85204e+00 -4.10288e-01 -8.81453e-01 -2.11431e-01
21Feb13_100327|   1.19889e+00  1.26373e+00 -6.36870e-01  1.26338e+00  5.36597e-01
21Feb13_100327|   1.31875e-02]
21Feb13_100327| [-6.96596e-02 -5.38534e-01  5.48522e-01  5.84182e-02  6.63353e-01
21Feb13_100327|  -8.82974e-01  8.67865e-01 -4.46778e-01  3.78957e-01 -1.73884e+00
21Feb13_100327|   7.87282e-01]
21Feb13_100327| [-9.53666e-01  9.80083e-01 -2.38978e-01 -1.94127e-01 -1.09625e+00
21Feb13_100327|   6.84617e-01 -1.90861e+00 -1.46974e+00  1.49925e-01 -6.42909e-01
21Feb13_100327|   1.10172e+00]
21Feb13_100327| [ 1.25790e-03  6.28597e-01  5.34003e-01  2.97309e-01  1.63498e+00
21Feb13_100327|   9.24999e-01 -2.69857e-01 -2.42502e+00  4.21238e-01  3.03054e-01
21Feb13_100327|  -3.28666e-01]
21Feb13_100327| [ 4.96081e-01  3.19527e-01  6.41207e-01  2.65925e-01  1.49075e+00
21Feb13_100327|   1.26551e-01 -3.97150e-01  1.17863e-01  3.16032e-01  1.62457e-01
21Feb13_100327|  -1.75157e+00]
21Feb13_100327| [ 1.07827e+00 -6.03883e-01 -1.79069e+00  3.62297e-01  1.72510e-01
21Feb13_100327|   2.07369e-01  2.87312e+00 -1.17485e+00  6.05597e-01 -1.01342e+00
21Feb13_100327|  -1.48620e+00]
21Feb13_100327| [ 2.10119e-01 -1.00618e+00 -1.21833e+00  1.51138e-01 -2.10391e+00
21Feb13_100327|  -9.70180e-01  1.51398e-01  3.86319e-01 -1.29116e+00  7.64629e-01
21Feb13_100327|   1.55391e+00]
21Feb13_100327| [-5.61712e-01  9.73611e-01 -1.11945e+00  6.21880e-02 -1.36018e+00
21Feb13_100327|   6.40626e-01  1.72919e-01 -8.32757e-02 -4.69855e-01  2.27406e+00
21Feb13_100327|   4.90539e-01]
21Feb13_100327| [ 9.10147e-01 -8.16175e-01  8.75446e-01 -5.79670e-01 -7.61116e-01
21Feb13_100327|  -1.51932e+00 -3.06235e-02 -4.15810e-01 -6.32631e-01  1.75909e+00
21Feb13_100327|   2.17078e-01]
21Feb13_100327| [-7.08015e-02  2.82435e+00  1.20172e+00 -2.33629e-01 -1.32451e+00
21Feb13_100327|  -3.79960e-01 -9.94142e-01  5.68075e-01 -2.52394e-02  2.67676e-01
21Feb13_100327|   1.39104e+00]
21Feb13_100327| [ 1.25990e+00  3.83043e-01 -5.14876e-01 -5.66390e-01  6.97171e-01
21Feb13_100327|  -4.78790e-02  1.40391e+00 -1.59839e+00  2.40815e+00 -2.11341e-01
21Feb13_100327|  -6.09598e-01]
21Feb13_100327| [-9.09803e-01  1.21788e+00 -4.90502e-02 -2.38674e+00 -1.07796e+00
21Feb13_100327|   1.50503e+00  9.89401e-01 -7.67240e-02 -2.39136e-01 -1.23826e+00
21Feb13_100327|   9.26134e-02]
21Feb13_100327| [-1.84424e+00 -1.25659e+00  1.59797e+00 -1.15697e+00  1.06948e+00
21Feb13_100327|   4.16988e-01 -6.95885e-01  1.64775e+00  2.71237e-01  1.15771e+00
21Feb13_100327|  -9.32049e-02]
21Feb13_100327| [-5.90352e-01  7.55237e-02 -9.82628e-01  1.09728e+00 -1.32232e+00
21Feb13_100327|  -5.82659e-02  9.41700e-01 -8.22310e-02  1.52491e+00 -8.38811e-01
21Feb13_100327|  -3.71191e-01]
21Feb13_100327| [ 4.89785e-01  7.09934e-01  9.23224e-01 -1.16146e-01 -1.29886e+00
21Feb13_100327|  -8.44858e-01 -8.82313e-01  7.77497e-01  1.31740e+00 -7.86706e-01
21Feb13_100327|  -2.09546e+00]
21Feb13_100327| [-1.73451e+00  7.97409e-01  8.43432e-01 -9.64302e-01  1.37347e+00
21Feb13_100327|  -7.45391e-01  1.70867e-01 -1.36756e+00  5.82947e-01 -8.68562e-01
21Feb13_100327|   1.52281e+00]
21Feb13_100327| [ 4.00468e-01  1.96305e+00  2.45851e+00 -2.24292e-01  1.02207e+00
21Feb13_100327|  -3.21156e-01 -2.24026e-01  8.81373e-01 -4.33565e-01  2.26966e+00
21Feb13_100327|  -6.45783e-01]
21Feb13_100327| [-1.03032e-01  1.48460e+00  3.46312e-01 -1.19882e+00  1.66240e+00
21Feb13_100327|  -3.14884e-01  1.01077e+00 -6.85286e-03 -6.98216e-01 -8.47058e-01
21Feb13_100327|  -5.50347e-01]
21Feb13_100327| [-1.11871e+00 -3.47026e-02 -3.39108e-01 -2.64636e-02 -7.06458e-01
21Feb13_100327|   1.63302e-01  1.31775e+00 -1.90493e+00  7.70172e-01 -1.46652e+00
21Feb13_100327|   7.78757e-01]
21Feb13_100327| [-4.22403e-01  1.77868e+00 -2.99659e-01 -9.52842e-01  4.45016e-01
21Feb13_100327|   1.60657e-01 -2.50497e+00 -7.00889e-01 -9.19795e-01 -8.47184e-01
21Feb13_100327|  -2.65355e-01]
21Feb13_100327| [-7.24223e-01  9.33796e-01  6.35998e-01 -4.00108e-01 -3.21069e-01
21Feb13_100327|  -1.09825e-01  2.10246e+00  4.11840e-01 -1.23415e+00 -6.89791e-01
21Feb13_100327|   2.08588e+00]]
21Feb13_100327|-- Bias --
21Feb13_100327|[-0.37416  0.16993 -0.26367  0.66001 -0.03379  0.80785  0.01432 -0.35067
21Feb13_100327|  0.36146  0.54304 -0.66491]
21Feb13_100327|Layer 1:
21Feb13_100327|-- Config --
21Feb13_100327|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 11], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100327|-- Weights --
21Feb13_100327|[[ 0.46273 -0.52633  0.15311 -0.90421]
21Feb13_100327| [-0.74445  0.54112  0.87680  0.47482]
21Feb13_100327| [-0.26719  0.17345  0.03642 -0.34925]
21Feb13_100327| [-0.58874  0.51152 -0.29307 -0.83212]
21Feb13_100327| [ 0.47815 -0.42503 -0.70618  0.59181]
21Feb13_100327| [-0.41898 -0.52488  0.41435 -0.03709]
21Feb13_100327| [-0.86538 -0.59482 -0.23110  0.07142]
21Feb13_100327| [ 0.14002 -0.88633  0.43298  0.45916]
21Feb13_100327| [-0.13044 -0.48032 -0.74848  0.34067]
21Feb13_100327| [ 0.52895  0.74501  0.12361 -0.14643]
21Feb13_100327| [ 0.58188  0.58465  0.38240  0.65996]]
21Feb13_100327|-- Bias --
21Feb13_100327|[-0.76731  0.51896 -0.80290  0.22809]
21Feb13_100327|Layer 2:
21Feb13_100327|-- Config --
21Feb13_100327|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100327|-- Weights --
21Feb13_100327|[[-1.53127  0.04037]
21Feb13_100327| [ 0.13677 -1.46193]
21Feb13_100327| [-1.11724  0.35367]
21Feb13_100327| [ 0.49422  0.28831]]
21Feb13_100327|-- Bias --
21Feb13_100327|[ 0.11773 -0.60451]
21Feb13_100327|Predicting the validation and test data with the Best final individual.
21Feb13_100335| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_100335|-----------  ------------------  --------------------  ----------
21Feb13_100335|Validation         42.00                  30            0.00000
21Feb13_100335|   Test            36.49                  30            0.00298
21Feb13_100335|-------------------- Test #4 --------------------
21Feb13_100335|Best final individual weights
21Feb13_100335|Individual:
21Feb13_100335|-- Constant hidden layers --
21Feb13_100335|False
21Feb13_100335|Layer 0:
21Feb13_100335|-- Config --
21Feb13_100335|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 11, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100335|-- Weights --
21Feb13_100335|[[-1.06145e+00  8.68922e-01 -1.14379e+00 -1.49459e-01 -5.92039e-01
21Feb13_100335|  -2.35241e-01 -1.40309e+00  2.12924e+00  1.77198e-01  3.19702e-01
21Feb13_100335|  -4.23758e-01]
21Feb13_100335| [-7.60973e-01 -1.69902e+00  5.70321e-01  7.00329e-02  7.06671e-01
21Feb13_100335|   3.27493e-01 -1.70808e+00 -1.16196e+00  9.48272e-02  6.65005e-01
21Feb13_100335|   1.23887e+00]
21Feb13_100335| [-5.76717e-01  4.39987e-01 -4.71900e-01  9.84744e-01 -6.70632e-01
21Feb13_100335|  -8.05147e-02  4.07717e-01  1.82295e+00 -3.65259e-01  2.94562e-02
21Feb13_100335|   4.58511e-01]
21Feb13_100335| [ 1.51511e+00  9.93966e-01  3.08471e-01 -5.70096e-01  8.84235e-02
21Feb13_100335|  -3.23449e-01 -2.17552e-02  1.61666e+00  6.74902e-02 -2.42173e-01
21Feb13_100335|  -1.07711e+00]
21Feb13_100335| [ 7.49020e-01  1.03034e+00  1.53014e+00 -1.66588e+00 -1.34224e-01
21Feb13_100335|   1.92903e+00 -2.20672e+00  1.52629e-01 -9.97077e-01 -4.47184e-01
21Feb13_100335|  -1.17110e+00]
21Feb13_100335| [ 5.15382e-01  1.00118e+00 -1.08350e+00  1.03880e+00 -4.68603e-01
21Feb13_100335|  -4.59197e-02  1.11058e+00  9.17544e-01  1.33730e-01  6.53965e-02
21Feb13_100335|  -1.13911e+00]
21Feb13_100335| [-2.04317e+00 -6.76921e-01  7.78254e-01 -1.17217e+00 -1.67455e+00
21Feb13_100335|  -1.57760e-02  8.21084e-01 -1.13921e-01  7.37767e-01 -2.98292e-01
21Feb13_100335|   2.92646e-01]
21Feb13_100335| [-8.01681e-01 -9.13592e-01 -7.13092e-01  1.16235e+00 -5.79811e-01
21Feb13_100335|   5.53346e-01 -3.23183e-01 -5.66910e-02  1.05090e+00 -4.89620e-01
21Feb13_100335|  -1.40866e-01]
21Feb13_100335| [-6.85763e-01  4.32546e-01  2.07281e-01  1.86934e-01  1.03855e+00
21Feb13_100335|  -2.61743e-02 -1.45446e+00  2.99914e-01  9.96893e-01  5.16927e-01
21Feb13_100335|  -9.72506e-01]
21Feb13_100335| [ 6.87732e-01  8.12844e-01  3.51990e-01 -1.28179e+00 -1.00846e-02
21Feb13_100335|  -2.28308e-01  1.61447e+00 -2.91772e-01  1.12608e+00  6.13314e-01
21Feb13_100335|  -7.64936e-01]
21Feb13_100335| [ 3.88583e-01  3.89122e-02 -7.32680e-01 -1.74359e-01 -1.04680e+00
21Feb13_100335|   1.41735e+00  3.14067e-01 -1.41835e-01 -5.39265e-01 -8.08813e-01
21Feb13_100335|   6.58712e-01]
21Feb13_100335| [-6.68434e-01 -9.77746e-01  1.42569e+00 -2.64191e-01 -4.41971e-01
21Feb13_100335|   3.89653e-01  1.19610e+00 -1.70441e+00  2.60850e-01 -1.16352e+00
21Feb13_100335|   6.53371e-01]
21Feb13_100335| [ 2.16387e+00  1.21870e+00 -1.34441e-01 -8.61036e-01 -6.09299e-01
21Feb13_100335|   7.85750e-01 -9.41396e-01 -5.31235e-01  4.44708e-02 -5.08207e-01
21Feb13_100335|  -2.45830e+00]
21Feb13_100335| [-8.92729e-01 -2.15613e-01 -3.99405e-01  1.63387e+00 -8.65849e-01
21Feb13_100335|   7.58911e-01  7.49706e-01 -2.11143e+00  1.56748e-01  7.64897e-01
21Feb13_100335|  -1.13879e+00]
21Feb13_100335| [-8.57088e-01 -1.62365e-03  1.26530e+00 -2.22604e+00 -2.28715e+00
21Feb13_100335|  -9.99604e-02 -2.40021e-01  3.35970e-01 -8.82544e-01  4.85761e-01
21Feb13_100335|  -2.24202e+00]
21Feb13_100335| [ 5.52215e-01  8.52156e-02 -2.37466e-01  1.07672e+00  1.54941e+00
21Feb13_100335|   1.99606e-01 -1.34808e+00  7.53511e-01 -5.99088e-01  5.98790e-02
21Feb13_100335|  -1.07950e-01]
21Feb13_100335| [ 2.67109e+00 -1.75176e+00 -6.16214e-01 -1.86800e+00  5.99501e-01
21Feb13_100335|  -1.10529e+00 -2.74849e+00  6.11555e-01  9.78547e-03 -3.97459e-01
21Feb13_100335|   2.92660e-01]
21Feb13_100335| [ 4.54863e-01 -9.09117e-01 -8.30196e-01  1.50206e+00 -1.73504e+00
21Feb13_100335|  -1.30648e+00  5.55948e-01 -7.54174e-01  2.05420e+00  1.38864e+00
21Feb13_100335|   5.29561e-01]
21Feb13_100335| [-4.85366e-01 -3.53531e-01  9.05198e-01  7.65456e-01 -1.64749e+00
21Feb13_100335|   5.69847e-01  2.50378e-01  7.85001e-01 -1.45661e+00  8.34665e-02
21Feb13_100335|   8.15879e-01]
21Feb13_100335| [ 1.25727e+00  2.46577e-01  5.85987e-01  5.77962e-01 -2.59665e-01
21Feb13_100335|  -1.17493e-01  1.60910e+00  9.12990e-01  1.44670e+00  5.22422e-01
21Feb13_100335|  -1.94187e+00]
21Feb13_100335| [ 1.33867e-01 -1.27358e+00 -3.47982e-01 -6.08657e-02 -1.30348e-01
21Feb13_100335|  -1.17219e+00  1.24909e+00 -1.11782e+00  8.64220e-01  5.61000e-01
21Feb13_100335|  -1.48212e+00]
21Feb13_100335| [ 1.78205e+00 -2.50466e-01  1.33657e+00 -1.73845e+00  1.81425e+00
21Feb13_100335|  -8.02280e-01 -1.16246e+00  1.15245e+00 -3.53401e-01  6.57431e-01
21Feb13_100335|   9.30205e-01]
21Feb13_100335| [-3.03807e-01 -5.34010e-01 -5.36033e-02  1.22986e+00 -7.73593e-01
21Feb13_100335|  -2.41838e-02  9.47047e-01  1.63950e+00  8.57850e-01  7.18366e-01
21Feb13_100335|   6.19340e-01]
21Feb13_100335| [-1.56874e+00  9.13052e-01 -1.80219e+00 -6.85706e-02 -1.52747e-01
21Feb13_100335|  -1.23654e+00  7.66763e-01  8.76849e-01  1.38192e+00  1.74758e-01
21Feb13_100335|   9.19395e-01]
21Feb13_100335| [-3.41080e-01 -1.01680e+00 -7.82347e-01  5.72435e-01  1.21957e+00
21Feb13_100335|  -1.70168e+00  1.35596e+00 -1.36994e+00  6.54260e-01  2.17154e+00
21Feb13_100335|  -6.51639e-01]
21Feb13_100335| [-4.25343e-01  1.74798e+00  9.89404e-01 -1.04295e+00 -5.27053e-03
21Feb13_100335|   1.42040e+00  1.70140e+00 -5.47912e-01  2.85277e-01 -3.08635e-01
21Feb13_100335|  -1.87522e+00]
21Feb13_100335| [-2.65662e+00 -2.02900e+00 -1.49073e-01 -1.86322e-01 -6.15986e-01
21Feb13_100335|   1.02607e+00  7.96644e-01 -5.96812e-01  1.99503e-01 -1.24498e+00
21Feb13_100335|   1.01419e+00]
21Feb13_100335| [-1.31259e+00 -4.54363e-01  1.06493e-01  1.22074e+00  1.74518e-01
21Feb13_100335|  -5.57725e-01 -1.40429e+00  6.75301e-01  1.36944e+00 -3.09052e-01
21Feb13_100335|   1.21379e-01]
21Feb13_100335| [-1.66580e+00 -6.50639e-01  5.46120e-01 -1.25566e+00 -5.04851e-01
21Feb13_100335|  -5.49479e-01  1.11882e-01 -4.76139e-01 -4.81819e-01 -1.14210e-01
21Feb13_100335|  -1.57996e+00]
21Feb13_100335| [-7.64196e-01  1.06296e+00 -7.61805e-01 -1.49152e+00  9.36859e-01
21Feb13_100335|  -1.03321e+00 -2.87637e-01 -2.47389e-01  2.61926e-01  8.37227e-01
21Feb13_100335|  -3.42333e-01]
21Feb13_100335| [ 7.46572e-01 -1.58035e+00  8.02182e-01 -5.66302e-01 -8.47290e-01
21Feb13_100335|  -6.34161e-01  1.74178e+00  1.27802e+00  1.67001e+00 -7.94473e-01
21Feb13_100335|   1.10741e+00]
21Feb13_100335| [-6.74261e-01  5.99487e-01 -1.80403e+00 -1.02671e+00 -1.54235e+00
21Feb13_100335|  -1.26515e+00  4.29489e-01  8.21419e-01  1.06895e+00  1.13029e+00
21Feb13_100335|   7.65765e-01]
21Feb13_100335| [ 3.93528e-01 -5.92774e-01  5.40870e-01  9.02092e-01 -1.02404e+00
21Feb13_100335|  -1.10673e+00  2.35611e-01 -1.02808e+00  1.83820e-01  4.85873e-01
21Feb13_100335|  -1.59386e+00]
21Feb13_100335| [ 7.49489e-01 -6.49799e-01  1.34338e+00  2.12189e+00 -7.31882e-01
21Feb13_100335|   5.88080e-01  2.20549e+00 -1.06942e+00 -1.29756e+00 -7.96579e-01
21Feb13_100335|  -5.81803e-01]
21Feb13_100335| [-1.75688e-01  7.50212e-01 -1.37744e+00 -3.66415e-01  8.48990e-01
21Feb13_100335|  -1.88524e-01  1.13690e+00  1.33830e-01 -1.38609e+00 -3.92856e-01
21Feb13_100335|   5.05161e-01]
21Feb13_100335| [-1.56803e-01  6.44681e-01  4.29331e-01 -2.67595e-02  1.86944e+00
21Feb13_100335|   2.86790e+00  6.18832e-02  3.55496e-01  7.56248e-03 -1.48327e+00
21Feb13_100335|  -3.39873e-01]
21Feb13_100335| [-2.54559e-01 -1.85204e+00 -4.10288e-01 -8.81453e-01 -2.11431e-01
21Feb13_100335|   1.19889e+00  1.26373e+00 -6.36870e-01  1.26338e+00  5.36597e-01
21Feb13_100335|   1.31875e-02]
21Feb13_100335| [-6.96596e-02 -5.38534e-01  5.48522e-01  5.84182e-02  6.63353e-01
21Feb13_100335|  -8.82974e-01  8.67865e-01 -4.46778e-01  3.78957e-01 -1.73884e+00
21Feb13_100335|   7.87282e-01]
21Feb13_100335| [-9.53666e-01  9.80083e-01 -2.38978e-01 -1.94127e-01 -1.09625e+00
21Feb13_100335|   6.84617e-01 -1.90861e+00 -1.46974e+00  1.49925e-01 -6.42909e-01
21Feb13_100335|   1.10172e+00]
21Feb13_100335| [ 1.25790e-03  6.28597e-01  5.34003e-01  2.97309e-01  1.63498e+00
21Feb13_100335|   9.24999e-01 -2.69857e-01 -2.42502e+00  4.21238e-01  3.03054e-01
21Feb13_100335|  -3.28666e-01]
21Feb13_100335| [ 4.96081e-01  3.19527e-01  6.41207e-01  2.65925e-01  1.49075e+00
21Feb13_100335|   1.26551e-01 -3.97150e-01  1.17863e-01  3.16032e-01  1.62457e-01
21Feb13_100335|  -1.75157e+00]
21Feb13_100335| [ 1.07827e+00 -6.03883e-01 -1.79069e+00  3.62297e-01  1.72510e-01
21Feb13_100335|   2.07369e-01  2.87312e+00 -1.17485e+00  6.05597e-01 -1.01342e+00
21Feb13_100335|  -1.48620e+00]
21Feb13_100335| [ 2.10119e-01 -1.00618e+00 -1.21833e+00  1.51138e-01 -2.10391e+00
21Feb13_100335|  -9.70180e-01  1.51398e-01  3.86319e-01 -1.29116e+00  7.64629e-01
21Feb13_100335|   1.55391e+00]
21Feb13_100335| [-5.61712e-01  9.73611e-01 -1.11945e+00  6.21880e-02 -1.36018e+00
21Feb13_100335|   6.40626e-01  1.72919e-01 -8.32757e-02 -4.69855e-01  2.27406e+00
21Feb13_100335|   4.90539e-01]
21Feb13_100335| [ 9.10147e-01 -8.16175e-01  8.75446e-01 -5.79670e-01 -7.61116e-01
21Feb13_100335|  -1.51932e+00 -3.06235e-02 -4.15810e-01 -6.32631e-01  1.75909e+00
21Feb13_100335|   2.17078e-01]
21Feb13_100335| [-7.08015e-02  2.82435e+00  1.20172e+00 -2.33629e-01 -1.32451e+00
21Feb13_100335|  -3.79960e-01 -9.94142e-01  5.68075e-01 -2.52394e-02  2.67676e-01
21Feb13_100335|   1.39104e+00]
21Feb13_100335| [ 1.25990e+00  3.83043e-01 -5.14876e-01 -5.66390e-01  6.97171e-01
21Feb13_100335|  -4.78790e-02  1.40391e+00 -1.59839e+00  2.40815e+00 -2.11341e-01
21Feb13_100335|  -6.09598e-01]
21Feb13_100335| [-9.09803e-01  1.21788e+00 -4.90502e-02 -2.38674e+00 -1.07796e+00
21Feb13_100335|   1.50503e+00  9.89401e-01 -7.67240e-02 -2.39136e-01 -1.23826e+00
21Feb13_100335|   9.26134e-02]
21Feb13_100335| [-1.84424e+00 -1.25659e+00  1.59797e+00 -1.15697e+00  1.06948e+00
21Feb13_100335|   4.16988e-01 -6.95885e-01  1.64775e+00  2.71237e-01  1.15771e+00
21Feb13_100335|  -9.32049e-02]
21Feb13_100335| [-5.90352e-01  7.55237e-02 -9.82628e-01  1.09728e+00 -1.32232e+00
21Feb13_100335|  -5.82659e-02  9.41700e-01 -8.22310e-02  1.52491e+00 -8.38811e-01
21Feb13_100335|  -3.71191e-01]
21Feb13_100335| [ 4.89785e-01  7.09934e-01  9.23224e-01 -1.16146e-01 -1.29886e+00
21Feb13_100335|  -8.44858e-01 -8.82313e-01  7.77497e-01  1.31740e+00 -7.86706e-01
21Feb13_100335|  -2.09546e+00]
21Feb13_100335| [-1.73451e+00  7.97409e-01  8.43432e-01 -9.64302e-01  1.37347e+00
21Feb13_100335|  -7.45391e-01  1.70867e-01 -1.36756e+00  5.82947e-01 -8.68562e-01
21Feb13_100335|   1.52281e+00]
21Feb13_100335| [ 4.00468e-01  1.96305e+00  2.45851e+00 -2.24292e-01  1.02207e+00
21Feb13_100335|  -3.21156e-01 -2.24026e-01  8.81373e-01 -4.33565e-01  2.26966e+00
21Feb13_100335|  -6.45783e-01]
21Feb13_100335| [-1.03032e-01  1.48460e+00  3.46312e-01 -1.19882e+00  1.66240e+00
21Feb13_100335|  -3.14884e-01  1.01077e+00 -6.85286e-03 -6.98216e-01 -8.47058e-01
21Feb13_100335|  -5.50347e-01]
21Feb13_100335| [-1.11871e+00 -3.47026e-02 -3.39108e-01 -2.64636e-02 -7.06458e-01
21Feb13_100335|   1.63302e-01  1.31775e+00 -1.90493e+00  7.70172e-01 -1.46652e+00
21Feb13_100335|   7.78757e-01]
21Feb13_100335| [-4.22403e-01  1.77868e+00 -2.99659e-01 -9.52842e-01  4.45016e-01
21Feb13_100335|   1.60657e-01 -2.50497e+00 -7.00889e-01 -9.19795e-01 -8.47184e-01
21Feb13_100335|  -2.65355e-01]
21Feb13_100335| [-7.24223e-01  9.33796e-01  6.35998e-01 -4.00108e-01 -3.21069e-01
21Feb13_100335|  -1.09825e-01  2.10246e+00  4.11840e-01 -1.23415e+00 -6.89791e-01
21Feb13_100335|   2.08588e+00]]
21Feb13_100335|-- Bias --
21Feb13_100335|[-0.37416  0.16993 -0.26367  0.66001 -0.03379  0.80785  0.01432 -0.35067
21Feb13_100335|  0.36146  0.54304 -0.66491]
21Feb13_100335|Layer 1:
21Feb13_100335|-- Config --
21Feb13_100335|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 11], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100335|-- Weights --
21Feb13_100335|[[ 0.46273 -0.52633  0.15311 -0.90421]
21Feb13_100335| [-0.74445  0.54112  0.87680  0.47482]
21Feb13_100335| [-0.26719  0.17345  0.03642 -0.34925]
21Feb13_100335| [-0.58874  0.51152 -0.29307 -0.83212]
21Feb13_100335| [ 0.47815 -0.42503 -0.70618  0.59181]
21Feb13_100335| [-0.41898 -0.52488  0.41435 -0.03709]
21Feb13_100335| [-0.86538 -0.59482 -0.23110  0.07142]
21Feb13_100335| [ 0.14002 -0.88633  0.43298  0.45916]
21Feb13_100335| [-0.13044 -0.48032 -0.74848  0.34067]
21Feb13_100335| [ 0.52895  0.74501  0.12361 -0.14643]
21Feb13_100335| [ 0.58188  0.58465  0.38240  0.65996]]
21Feb13_100335|-- Bias --
21Feb13_100335|[-0.76731  0.51896 -0.80290  0.22809]
21Feb13_100335|Layer 2:
21Feb13_100335|-- Config --
21Feb13_100335|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100335|-- Weights --
21Feb13_100335|[[-1.53127  0.04037]
21Feb13_100335| [ 0.13677 -1.46193]
21Feb13_100335| [-1.11724  0.35367]
21Feb13_100335| [ 0.49422  0.28831]]
21Feb13_100335|-- Bias --
21Feb13_100335|[ 0.11773 -0.60451]
21Feb13_100335|Predicting the validation and test data with the Best final individual.
21Feb13_100342| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_100342|-----------  ------------------  --------------------  ----------
21Feb13_100342|Validation         26.17                  30            0.57099
21Feb13_100342|   Test            36.32                  30            0.00298
21Feb13_100342|-------------------- Test #5 --------------------
21Feb13_100342|Best final individual weights
21Feb13_100342|Individual:
21Feb13_100342|-- Constant hidden layers --
21Feb13_100342|False
21Feb13_100342|Layer 0:
21Feb13_100342|-- Config --
21Feb13_100342|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 11, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100342|-- Weights --
21Feb13_100342|[[-1.06145e+00  8.68922e-01 -1.14379e+00 -1.49459e-01 -5.92039e-01
21Feb13_100342|  -2.35241e-01 -1.40309e+00  2.12924e+00  1.77198e-01  3.19702e-01
21Feb13_100342|  -4.23758e-01]
21Feb13_100342| [-7.60973e-01 -1.69902e+00  5.70321e-01  7.00329e-02  7.06671e-01
21Feb13_100342|   3.27493e-01 -1.70808e+00 -1.16196e+00  9.48272e-02  6.65005e-01
21Feb13_100342|   1.23887e+00]
21Feb13_100342| [-5.76717e-01  4.39987e-01 -4.71900e-01  9.84744e-01 -6.70632e-01
21Feb13_100342|  -8.05147e-02  4.07717e-01  1.82295e+00 -3.65259e-01  2.94562e-02
21Feb13_100342|   4.58511e-01]
21Feb13_100342| [ 1.51511e+00  9.93966e-01  3.08471e-01 -5.70096e-01  8.84235e-02
21Feb13_100342|  -3.23449e-01 -2.17552e-02  1.61666e+00  6.74902e-02 -2.42173e-01
21Feb13_100342|  -1.07711e+00]
21Feb13_100342| [ 7.49020e-01  1.03034e+00  1.53014e+00 -1.66588e+00 -1.34224e-01
21Feb13_100342|   1.92903e+00 -2.20672e+00  1.52629e-01 -9.97077e-01 -4.47184e-01
21Feb13_100342|  -1.17110e+00]
21Feb13_100342| [ 5.15382e-01  1.00118e+00 -1.08350e+00  1.03880e+00 -4.68603e-01
21Feb13_100342|  -4.59197e-02  1.11058e+00  9.17544e-01  1.33730e-01  6.53965e-02
21Feb13_100342|  -1.13911e+00]
21Feb13_100342| [-2.04317e+00 -6.76921e-01  7.78254e-01 -1.17217e+00 -1.67455e+00
21Feb13_100342|  -1.57760e-02  8.21084e-01 -1.13921e-01  7.37767e-01 -2.98292e-01
21Feb13_100342|   2.92646e-01]
21Feb13_100342| [-8.01681e-01 -9.13592e-01 -7.13092e-01  1.16235e+00 -5.79811e-01
21Feb13_100342|   5.53346e-01 -3.23183e-01 -5.66910e-02  1.05090e+00 -4.89620e-01
21Feb13_100342|  -1.40866e-01]
21Feb13_100342| [-6.85763e-01  4.32546e-01  2.07281e-01  1.86934e-01  1.03855e+00
21Feb13_100342|  -2.61743e-02 -1.45446e+00  2.99914e-01  9.96893e-01  5.16927e-01
21Feb13_100342|  -9.72506e-01]
21Feb13_100342| [ 6.87732e-01  8.12844e-01  3.51990e-01 -1.28179e+00 -1.00846e-02
21Feb13_100342|  -2.28308e-01  1.61447e+00 -2.91772e-01  1.12608e+00  6.13314e-01
21Feb13_100342|  -7.64936e-01]
21Feb13_100342| [ 3.88583e-01  3.89122e-02 -7.32680e-01 -1.74359e-01 -1.04680e+00
21Feb13_100342|   1.41735e+00  3.14067e-01 -1.41835e-01 -5.39265e-01 -8.08813e-01
21Feb13_100342|   6.58712e-01]
21Feb13_100342| [-6.68434e-01 -9.77746e-01  1.42569e+00 -2.64191e-01 -4.41971e-01
21Feb13_100342|   3.89653e-01  1.19610e+00 -1.70441e+00  2.60850e-01 -1.16352e+00
21Feb13_100342|   6.53371e-01]
21Feb13_100342| [ 2.16387e+00  1.21870e+00 -1.34441e-01 -8.61036e-01 -6.09299e-01
21Feb13_100342|   7.85750e-01 -9.41396e-01 -5.31235e-01  4.44708e-02 -5.08207e-01
21Feb13_100342|  -2.45830e+00]
21Feb13_100342| [-8.92729e-01 -2.15613e-01 -3.99405e-01  1.63387e+00 -8.65849e-01
21Feb13_100342|   7.58911e-01  7.49706e-01 -2.11143e+00  1.56748e-01  7.64897e-01
21Feb13_100342|  -1.13879e+00]
21Feb13_100342| [-8.57088e-01 -1.62365e-03  1.26530e+00 -2.22604e+00 -2.28715e+00
21Feb13_100342|  -9.99604e-02 -2.40021e-01  3.35970e-01 -8.82544e-01  4.85761e-01
21Feb13_100342|  -2.24202e+00]
21Feb13_100342| [ 5.52215e-01  8.52156e-02 -2.37466e-01  1.07672e+00  1.54941e+00
21Feb13_100342|   1.99606e-01 -1.34808e+00  7.53511e-01 -5.99088e-01  5.98790e-02
21Feb13_100342|  -1.07950e-01]
21Feb13_100342| [ 2.67109e+00 -1.75176e+00 -6.16214e-01 -1.86800e+00  5.99501e-01
21Feb13_100342|  -1.10529e+00 -2.74849e+00  6.11555e-01  9.78547e-03 -3.97459e-01
21Feb13_100342|   2.92660e-01]
21Feb13_100342| [ 4.54863e-01 -9.09117e-01 -8.30196e-01  1.50206e+00 -1.73504e+00
21Feb13_100342|  -1.30648e+00  5.55948e-01 -7.54174e-01  2.05420e+00  1.38864e+00
21Feb13_100342|   5.29561e-01]
21Feb13_100342| [-4.85366e-01 -3.53531e-01  9.05198e-01  7.65456e-01 -1.64749e+00
21Feb13_100342|   5.69847e-01  2.50378e-01  7.85001e-01 -1.45661e+00  8.34665e-02
21Feb13_100342|   8.15879e-01]
21Feb13_100342| [ 1.25727e+00  2.46577e-01  5.85987e-01  5.77962e-01 -2.59665e-01
21Feb13_100342|  -1.17493e-01  1.60910e+00  9.12990e-01  1.44670e+00  5.22422e-01
21Feb13_100342|  -1.94187e+00]
21Feb13_100342| [ 1.33867e-01 -1.27358e+00 -3.47982e-01 -6.08657e-02 -1.30348e-01
21Feb13_100342|  -1.17219e+00  1.24909e+00 -1.11782e+00  8.64220e-01  5.61000e-01
21Feb13_100342|  -1.48212e+00]
21Feb13_100342| [ 1.78205e+00 -2.50466e-01  1.33657e+00 -1.73845e+00  1.81425e+00
21Feb13_100342|  -8.02280e-01 -1.16246e+00  1.15245e+00 -3.53401e-01  6.57431e-01
21Feb13_100342|   9.30205e-01]
21Feb13_100342| [-3.03807e-01 -5.34010e-01 -5.36033e-02  1.22986e+00 -7.73593e-01
21Feb13_100342|  -2.41838e-02  9.47047e-01  1.63950e+00  8.57850e-01  7.18366e-01
21Feb13_100342|   6.19340e-01]
21Feb13_100342| [-1.56874e+00  9.13052e-01 -1.80219e+00 -6.85706e-02 -1.52747e-01
21Feb13_100342|  -1.23654e+00  7.66763e-01  8.76849e-01  1.38192e+00  1.74758e-01
21Feb13_100342|   9.19395e-01]
21Feb13_100342| [-3.41080e-01 -1.01680e+00 -7.82347e-01  5.72435e-01  1.21957e+00
21Feb13_100342|  -1.70168e+00  1.35596e+00 -1.36994e+00  6.54260e-01  2.17154e+00
21Feb13_100342|  -6.51639e-01]
21Feb13_100342| [-4.25343e-01  1.74798e+00  9.89404e-01 -1.04295e+00 -5.27053e-03
21Feb13_100342|   1.42040e+00  1.70140e+00 -5.47912e-01  2.85277e-01 -3.08635e-01
21Feb13_100342|  -1.87522e+00]
21Feb13_100342| [-2.65662e+00 -2.02900e+00 -1.49073e-01 -1.86322e-01 -6.15986e-01
21Feb13_100342|   1.02607e+00  7.96644e-01 -5.96812e-01  1.99503e-01 -1.24498e+00
21Feb13_100342|   1.01419e+00]
21Feb13_100342| [-1.31259e+00 -4.54363e-01  1.06493e-01  1.22074e+00  1.74518e-01
21Feb13_100342|  -5.57725e-01 -1.40429e+00  6.75301e-01  1.36944e+00 -3.09052e-01
21Feb13_100342|   1.21379e-01]
21Feb13_100342| [-1.66580e+00 -6.50639e-01  5.46120e-01 -1.25566e+00 -5.04851e-01
21Feb13_100342|  -5.49479e-01  1.11882e-01 -4.76139e-01 -4.81819e-01 -1.14210e-01
21Feb13_100342|  -1.57996e+00]
21Feb13_100342| [-7.64196e-01  1.06296e+00 -7.61805e-01 -1.49152e+00  9.36859e-01
21Feb13_100342|  -1.03321e+00 -2.87637e-01 -2.47389e-01  2.61926e-01  8.37227e-01
21Feb13_100342|  -3.42333e-01]
21Feb13_100342| [ 7.46572e-01 -1.58035e+00  8.02182e-01 -5.66302e-01 -8.47290e-01
21Feb13_100342|  -6.34161e-01  1.74178e+00  1.27802e+00  1.67001e+00 -7.94473e-01
21Feb13_100342|   1.10741e+00]
21Feb13_100342| [-6.74261e-01  5.99487e-01 -1.80403e+00 -1.02671e+00 -1.54235e+00
21Feb13_100342|  -1.26515e+00  4.29489e-01  8.21419e-01  1.06895e+00  1.13029e+00
21Feb13_100342|   7.65765e-01]
21Feb13_100342| [ 3.93528e-01 -5.92774e-01  5.40870e-01  9.02092e-01 -1.02404e+00
21Feb13_100342|  -1.10673e+00  2.35611e-01 -1.02808e+00  1.83820e-01  4.85873e-01
21Feb13_100342|  -1.59386e+00]
21Feb13_100342| [ 7.49489e-01 -6.49799e-01  1.34338e+00  2.12189e+00 -7.31882e-01
21Feb13_100342|   5.88080e-01  2.20549e+00 -1.06942e+00 -1.29756e+00 -7.96579e-01
21Feb13_100342|  -5.81803e-01]
21Feb13_100342| [-1.75688e-01  7.50212e-01 -1.37744e+00 -3.66415e-01  8.48990e-01
21Feb13_100342|  -1.88524e-01  1.13690e+00  1.33830e-01 -1.38609e+00 -3.92856e-01
21Feb13_100342|   5.05161e-01]
21Feb13_100342| [-1.56803e-01  6.44681e-01  4.29331e-01 -2.67595e-02  1.86944e+00
21Feb13_100342|   2.86790e+00  6.18832e-02  3.55496e-01  7.56248e-03 -1.48327e+00
21Feb13_100342|  -3.39873e-01]
21Feb13_100342| [-2.54559e-01 -1.85204e+00 -4.10288e-01 -8.81453e-01 -2.11431e-01
21Feb13_100342|   1.19889e+00  1.26373e+00 -6.36870e-01  1.26338e+00  5.36597e-01
21Feb13_100342|   1.31875e-02]
21Feb13_100342| [-6.96596e-02 -5.38534e-01  5.48522e-01  5.84182e-02  6.63353e-01
21Feb13_100342|  -8.82974e-01  8.67865e-01 -4.46778e-01  3.78957e-01 -1.73884e+00
21Feb13_100342|   7.87282e-01]
21Feb13_100342| [-9.53666e-01  9.80083e-01 -2.38978e-01 -1.94127e-01 -1.09625e+00
21Feb13_100342|   6.84617e-01 -1.90861e+00 -1.46974e+00  1.49925e-01 -6.42909e-01
21Feb13_100342|   1.10172e+00]
21Feb13_100342| [ 1.25790e-03  6.28597e-01  5.34003e-01  2.97309e-01  1.63498e+00
21Feb13_100342|   9.24999e-01 -2.69857e-01 -2.42502e+00  4.21238e-01  3.03054e-01
21Feb13_100342|  -3.28666e-01]
21Feb13_100342| [ 4.96081e-01  3.19527e-01  6.41207e-01  2.65925e-01  1.49075e+00
21Feb13_100342|   1.26551e-01 -3.97150e-01  1.17863e-01  3.16032e-01  1.62457e-01
21Feb13_100342|  -1.75157e+00]
21Feb13_100342| [ 1.07827e+00 -6.03883e-01 -1.79069e+00  3.62297e-01  1.72510e-01
21Feb13_100342|   2.07369e-01  2.87312e+00 -1.17485e+00  6.05597e-01 -1.01342e+00
21Feb13_100342|  -1.48620e+00]
21Feb13_100342| [ 2.10119e-01 -1.00618e+00 -1.21833e+00  1.51138e-01 -2.10391e+00
21Feb13_100342|  -9.70180e-01  1.51398e-01  3.86319e-01 -1.29116e+00  7.64629e-01
21Feb13_100342|   1.55391e+00]
21Feb13_100342| [-5.61712e-01  9.73611e-01 -1.11945e+00  6.21880e-02 -1.36018e+00
21Feb13_100342|   6.40626e-01  1.72919e-01 -8.32757e-02 -4.69855e-01  2.27406e+00
21Feb13_100342|   4.90539e-01]
21Feb13_100342| [ 9.10147e-01 -8.16175e-01  8.75446e-01 -5.79670e-01 -7.61116e-01
21Feb13_100342|  -1.51932e+00 -3.06235e-02 -4.15810e-01 -6.32631e-01  1.75909e+00
21Feb13_100342|   2.17078e-01]
21Feb13_100342| [-7.08015e-02  2.82435e+00  1.20172e+00 -2.33629e-01 -1.32451e+00
21Feb13_100342|  -3.79960e-01 -9.94142e-01  5.68075e-01 -2.52394e-02  2.67676e-01
21Feb13_100342|   1.39104e+00]
21Feb13_100342| [ 1.25990e+00  3.83043e-01 -5.14876e-01 -5.66390e-01  6.97171e-01
21Feb13_100342|  -4.78790e-02  1.40391e+00 -1.59839e+00  2.40815e+00 -2.11341e-01
21Feb13_100342|  -6.09598e-01]
21Feb13_100342| [-9.09803e-01  1.21788e+00 -4.90502e-02 -2.38674e+00 -1.07796e+00
21Feb13_100342|   1.50503e+00  9.89401e-01 -7.67240e-02 -2.39136e-01 -1.23826e+00
21Feb13_100342|   9.26134e-02]
21Feb13_100342| [-1.84424e+00 -1.25659e+00  1.59797e+00 -1.15697e+00  1.06948e+00
21Feb13_100342|   4.16988e-01 -6.95885e-01  1.64775e+00  2.71237e-01  1.15771e+00
21Feb13_100342|  -9.32049e-02]
21Feb13_100342| [-5.90352e-01  7.55237e-02 -9.82628e-01  1.09728e+00 -1.32232e+00
21Feb13_100342|  -5.82659e-02  9.41700e-01 -8.22310e-02  1.52491e+00 -8.38811e-01
21Feb13_100342|  -3.71191e-01]
21Feb13_100342| [ 4.89785e-01  7.09934e-01  9.23224e-01 -1.16146e-01 -1.29886e+00
21Feb13_100342|  -8.44858e-01 -8.82313e-01  7.77497e-01  1.31740e+00 -7.86706e-01
21Feb13_100342|  -2.09546e+00]
21Feb13_100342| [-1.73451e+00  7.97409e-01  8.43432e-01 -9.64302e-01  1.37347e+00
21Feb13_100342|  -7.45391e-01  1.70867e-01 -1.36756e+00  5.82947e-01 -8.68562e-01
21Feb13_100342|   1.52281e+00]
21Feb13_100342| [ 4.00468e-01  1.96305e+00  2.45851e+00 -2.24292e-01  1.02207e+00
21Feb13_100342|  -3.21156e-01 -2.24026e-01  8.81373e-01 -4.33565e-01  2.26966e+00
21Feb13_100342|  -6.45783e-01]
21Feb13_100342| [-1.03032e-01  1.48460e+00  3.46312e-01 -1.19882e+00  1.66240e+00
21Feb13_100342|  -3.14884e-01  1.01077e+00 -6.85286e-03 -6.98216e-01 -8.47058e-01
21Feb13_100342|  -5.50347e-01]
21Feb13_100342| [-1.11871e+00 -3.47026e-02 -3.39108e-01 -2.64636e-02 -7.06458e-01
21Feb13_100342|   1.63302e-01  1.31775e+00 -1.90493e+00  7.70172e-01 -1.46652e+00
21Feb13_100342|   7.78757e-01]
21Feb13_100342| [-4.22403e-01  1.77868e+00 -2.99659e-01 -9.52842e-01  4.45016e-01
21Feb13_100342|   1.60657e-01 -2.50497e+00 -7.00889e-01 -9.19795e-01 -8.47184e-01
21Feb13_100342|  -2.65355e-01]
21Feb13_100342| [-7.24223e-01  9.33796e-01  6.35998e-01 -4.00108e-01 -3.21069e-01
21Feb13_100342|  -1.09825e-01  2.10246e+00  4.11840e-01 -1.23415e+00 -6.89791e-01
21Feb13_100342|   2.08588e+00]]
21Feb13_100342|-- Bias --
21Feb13_100342|[-0.37416  0.16993 -0.26367  0.66001 -0.03379  0.80785  0.01432 -0.35067
21Feb13_100342|  0.36146  0.54304 -0.66491]
21Feb13_100342|Layer 1:
21Feb13_100342|-- Config --
21Feb13_100342|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 11], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100342|-- Weights --
21Feb13_100342|[[ 0.46273 -0.52633  0.15311 -0.90421]
21Feb13_100342| [-0.74445  0.54112  0.87680  0.47482]
21Feb13_100342| [-0.26719  0.17345  0.03642 -0.34925]
21Feb13_100342| [-0.58874  0.51152 -0.29307 -0.83212]
21Feb13_100342| [ 0.47815 -0.42503 -0.70618  0.59181]
21Feb13_100342| [-0.41898 -0.52488  0.41435 -0.03709]
21Feb13_100342| [-0.86538 -0.59482 -0.23110  0.07142]
21Feb13_100342| [ 0.14002 -0.88633  0.43298  0.45916]
21Feb13_100342| [-0.13044 -0.48032 -0.74848  0.34067]
21Feb13_100342| [ 0.52895  0.74501  0.12361 -0.14643]
21Feb13_100342| [ 0.58188  0.58465  0.38240  0.65996]]
21Feb13_100342|-- Bias --
21Feb13_100342|[-0.76731  0.51896 -0.80290  0.22809]
21Feb13_100342|Layer 2:
21Feb13_100342|-- Config --
21Feb13_100342|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100342|-- Weights --
21Feb13_100342|[[-1.53127  0.04037]
21Feb13_100342| [ 0.13677 -1.46193]
21Feb13_100342| [-1.11724  0.35367]
21Feb13_100342| [ 0.49422  0.28831]]
21Feb13_100342|-- Bias --
21Feb13_100342|[ 0.11773 -0.60451]
21Feb13_100342|Predicting the validation and test data with the Best final individual.
21Feb13_100349| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_100349|-----------  ------------------  --------------------  ----------
21Feb13_100349|Validation         42.00                  30            0.00000
21Feb13_100349|   Test            36.40                  30            0.00000
21Feb13_100349|-------------------- Test #6 --------------------
21Feb13_100349|Best final individual weights
21Feb13_100349|Individual:
21Feb13_100349|-- Constant hidden layers --
21Feb13_100349|False
21Feb13_100349|Layer 0:
21Feb13_100349|-- Config --
21Feb13_100349|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 11, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100349|-- Weights --
21Feb13_100349|[[-1.06145e+00  8.68922e-01 -1.14379e+00 -1.49459e-01 -5.92039e-01
21Feb13_100349|  -2.35241e-01 -1.40309e+00  2.12924e+00  1.77198e-01  3.19702e-01
21Feb13_100349|  -4.23758e-01]
21Feb13_100349| [-7.60973e-01 -1.69902e+00  5.70321e-01  7.00329e-02  7.06671e-01
21Feb13_100349|   3.27493e-01 -1.70808e+00 -1.16196e+00  9.48272e-02  6.65005e-01
21Feb13_100349|   1.23887e+00]
21Feb13_100349| [-5.76717e-01  4.39987e-01 -4.71900e-01  9.84744e-01 -6.70632e-01
21Feb13_100349|  -8.05147e-02  4.07717e-01  1.82295e+00 -3.65259e-01  2.94562e-02
21Feb13_100349|   4.58511e-01]
21Feb13_100349| [ 1.51511e+00  9.93966e-01  3.08471e-01 -5.70096e-01  8.84235e-02
21Feb13_100349|  -3.23449e-01 -2.17552e-02  1.61666e+00  6.74902e-02 -2.42173e-01
21Feb13_100349|  -1.07711e+00]
21Feb13_100349| [ 7.49020e-01  1.03034e+00  1.53014e+00 -1.66588e+00 -1.34224e-01
21Feb13_100349|   1.92903e+00 -2.20672e+00  1.52629e-01 -9.97077e-01 -4.47184e-01
21Feb13_100349|  -1.17110e+00]
21Feb13_100349| [ 5.15382e-01  1.00118e+00 -1.08350e+00  1.03880e+00 -4.68603e-01
21Feb13_100349|  -4.59197e-02  1.11058e+00  9.17544e-01  1.33730e-01  6.53965e-02
21Feb13_100349|  -1.13911e+00]
21Feb13_100349| [-2.04317e+00 -6.76921e-01  7.78254e-01 -1.17217e+00 -1.67455e+00
21Feb13_100349|  -1.57760e-02  8.21084e-01 -1.13921e-01  7.37767e-01 -2.98292e-01
21Feb13_100349|   2.92646e-01]
21Feb13_100349| [-8.01681e-01 -9.13592e-01 -7.13092e-01  1.16235e+00 -5.79811e-01
21Feb13_100349|   5.53346e-01 -3.23183e-01 -5.66910e-02  1.05090e+00 -4.89620e-01
21Feb13_100349|  -1.40866e-01]
21Feb13_100349| [-6.85763e-01  4.32546e-01  2.07281e-01  1.86934e-01  1.03855e+00
21Feb13_100349|  -2.61743e-02 -1.45446e+00  2.99914e-01  9.96893e-01  5.16927e-01
21Feb13_100349|  -9.72506e-01]
21Feb13_100349| [ 6.87732e-01  8.12844e-01  3.51990e-01 -1.28179e+00 -1.00846e-02
21Feb13_100349|  -2.28308e-01  1.61447e+00 -2.91772e-01  1.12608e+00  6.13314e-01
21Feb13_100349|  -7.64936e-01]
21Feb13_100349| [ 3.88583e-01  3.89122e-02 -7.32680e-01 -1.74359e-01 -1.04680e+00
21Feb13_100349|   1.41735e+00  3.14067e-01 -1.41835e-01 -5.39265e-01 -8.08813e-01
21Feb13_100349|   6.58712e-01]
21Feb13_100349| [-6.68434e-01 -9.77746e-01  1.42569e+00 -2.64191e-01 -4.41971e-01
21Feb13_100349|   3.89653e-01  1.19610e+00 -1.70441e+00  2.60850e-01 -1.16352e+00
21Feb13_100349|   6.53371e-01]
21Feb13_100349| [ 2.16387e+00  1.21870e+00 -1.34441e-01 -8.61036e-01 -6.09299e-01
21Feb13_100349|   7.85750e-01 -9.41396e-01 -5.31235e-01  4.44708e-02 -5.08207e-01
21Feb13_100349|  -2.45830e+00]
21Feb13_100349| [-8.92729e-01 -2.15613e-01 -3.99405e-01  1.63387e+00 -8.65849e-01
21Feb13_100349|   7.58911e-01  7.49706e-01 -2.11143e+00  1.56748e-01  7.64897e-01
21Feb13_100349|  -1.13879e+00]
21Feb13_100349| [-8.57088e-01 -1.62365e-03  1.26530e+00 -2.22604e+00 -2.28715e+00
21Feb13_100349|  -9.99604e-02 -2.40021e-01  3.35970e-01 -8.82544e-01  4.85761e-01
21Feb13_100349|  -2.24202e+00]
21Feb13_100349| [ 5.52215e-01  8.52156e-02 -2.37466e-01  1.07672e+00  1.54941e+00
21Feb13_100349|   1.99606e-01 -1.34808e+00  7.53511e-01 -5.99088e-01  5.98790e-02
21Feb13_100349|  -1.07950e-01]
21Feb13_100349| [ 2.67109e+00 -1.75176e+00 -6.16214e-01 -1.86800e+00  5.99501e-01
21Feb13_100349|  -1.10529e+00 -2.74849e+00  6.11555e-01  9.78547e-03 -3.97459e-01
21Feb13_100349|   2.92660e-01]
21Feb13_100349| [ 4.54863e-01 -9.09117e-01 -8.30196e-01  1.50206e+00 -1.73504e+00
21Feb13_100349|  -1.30648e+00  5.55948e-01 -7.54174e-01  2.05420e+00  1.38864e+00
21Feb13_100349|   5.29561e-01]
21Feb13_100349| [-4.85366e-01 -3.53531e-01  9.05198e-01  7.65456e-01 -1.64749e+00
21Feb13_100349|   5.69847e-01  2.50378e-01  7.85001e-01 -1.45661e+00  8.34665e-02
21Feb13_100349|   8.15879e-01]
21Feb13_100349| [ 1.25727e+00  2.46577e-01  5.85987e-01  5.77962e-01 -2.59665e-01
21Feb13_100349|  -1.17493e-01  1.60910e+00  9.12990e-01  1.44670e+00  5.22422e-01
21Feb13_100349|  -1.94187e+00]
21Feb13_100349| [ 1.33867e-01 -1.27358e+00 -3.47982e-01 -6.08657e-02 -1.30348e-01
21Feb13_100349|  -1.17219e+00  1.24909e+00 -1.11782e+00  8.64220e-01  5.61000e-01
21Feb13_100349|  -1.48212e+00]
21Feb13_100349| [ 1.78205e+00 -2.50466e-01  1.33657e+00 -1.73845e+00  1.81425e+00
21Feb13_100349|  -8.02280e-01 -1.16246e+00  1.15245e+00 -3.53401e-01  6.57431e-01
21Feb13_100349|   9.30205e-01]
21Feb13_100349| [-3.03807e-01 -5.34010e-01 -5.36033e-02  1.22986e+00 -7.73593e-01
21Feb13_100349|  -2.41838e-02  9.47047e-01  1.63950e+00  8.57850e-01  7.18366e-01
21Feb13_100349|   6.19340e-01]
21Feb13_100349| [-1.56874e+00  9.13052e-01 -1.80219e+00 -6.85706e-02 -1.52747e-01
21Feb13_100349|  -1.23654e+00  7.66763e-01  8.76849e-01  1.38192e+00  1.74758e-01
21Feb13_100349|   9.19395e-01]
21Feb13_100349| [-3.41080e-01 -1.01680e+00 -7.82347e-01  5.72435e-01  1.21957e+00
21Feb13_100349|  -1.70168e+00  1.35596e+00 -1.36994e+00  6.54260e-01  2.17154e+00
21Feb13_100349|  -6.51639e-01]
21Feb13_100349| [-4.25343e-01  1.74798e+00  9.89404e-01 -1.04295e+00 -5.27053e-03
21Feb13_100349|   1.42040e+00  1.70140e+00 -5.47912e-01  2.85277e-01 -3.08635e-01
21Feb13_100349|  -1.87522e+00]
21Feb13_100349| [-2.65662e+00 -2.02900e+00 -1.49073e-01 -1.86322e-01 -6.15986e-01
21Feb13_100349|   1.02607e+00  7.96644e-01 -5.96812e-01  1.99503e-01 -1.24498e+00
21Feb13_100349|   1.01419e+00]
21Feb13_100349| [-1.31259e+00 -4.54363e-01  1.06493e-01  1.22074e+00  1.74518e-01
21Feb13_100349|  -5.57725e-01 -1.40429e+00  6.75301e-01  1.36944e+00 -3.09052e-01
21Feb13_100349|   1.21379e-01]
21Feb13_100349| [-1.66580e+00 -6.50639e-01  5.46120e-01 -1.25566e+00 -5.04851e-01
21Feb13_100349|  -5.49479e-01  1.11882e-01 -4.76139e-01 -4.81819e-01 -1.14210e-01
21Feb13_100349|  -1.57996e+00]
21Feb13_100349| [-7.64196e-01  1.06296e+00 -7.61805e-01 -1.49152e+00  9.36859e-01
21Feb13_100349|  -1.03321e+00 -2.87637e-01 -2.47389e-01  2.61926e-01  8.37227e-01
21Feb13_100349|  -3.42333e-01]
21Feb13_100349| [ 7.46572e-01 -1.58035e+00  8.02182e-01 -5.66302e-01 -8.47290e-01
21Feb13_100349|  -6.34161e-01  1.74178e+00  1.27802e+00  1.67001e+00 -7.94473e-01
21Feb13_100349|   1.10741e+00]
21Feb13_100349| [-6.74261e-01  5.99487e-01 -1.80403e+00 -1.02671e+00 -1.54235e+00
21Feb13_100349|  -1.26515e+00  4.29489e-01  8.21419e-01  1.06895e+00  1.13029e+00
21Feb13_100349|   7.65765e-01]
21Feb13_100349| [ 3.93528e-01 -5.92774e-01  5.40870e-01  9.02092e-01 -1.02404e+00
21Feb13_100349|  -1.10673e+00  2.35611e-01 -1.02808e+00  1.83820e-01  4.85873e-01
21Feb13_100349|  -1.59386e+00]
21Feb13_100349| [ 7.49489e-01 -6.49799e-01  1.34338e+00  2.12189e+00 -7.31882e-01
21Feb13_100349|   5.88080e-01  2.20549e+00 -1.06942e+00 -1.29756e+00 -7.96579e-01
21Feb13_100349|  -5.81803e-01]
21Feb13_100349| [-1.75688e-01  7.50212e-01 -1.37744e+00 -3.66415e-01  8.48990e-01
21Feb13_100349|  -1.88524e-01  1.13690e+00  1.33830e-01 -1.38609e+00 -3.92856e-01
21Feb13_100349|   5.05161e-01]
21Feb13_100349| [-1.56803e-01  6.44681e-01  4.29331e-01 -2.67595e-02  1.86944e+00
21Feb13_100349|   2.86790e+00  6.18832e-02  3.55496e-01  7.56248e-03 -1.48327e+00
21Feb13_100349|  -3.39873e-01]
21Feb13_100349| [-2.54559e-01 -1.85204e+00 -4.10288e-01 -8.81453e-01 -2.11431e-01
21Feb13_100349|   1.19889e+00  1.26373e+00 -6.36870e-01  1.26338e+00  5.36597e-01
21Feb13_100349|   1.31875e-02]
21Feb13_100349| [-6.96596e-02 -5.38534e-01  5.48522e-01  5.84182e-02  6.63353e-01
21Feb13_100349|  -8.82974e-01  8.67865e-01 -4.46778e-01  3.78957e-01 -1.73884e+00
21Feb13_100349|   7.87282e-01]
21Feb13_100349| [-9.53666e-01  9.80083e-01 -2.38978e-01 -1.94127e-01 -1.09625e+00
21Feb13_100349|   6.84617e-01 -1.90861e+00 -1.46974e+00  1.49925e-01 -6.42909e-01
21Feb13_100349|   1.10172e+00]
21Feb13_100349| [ 1.25790e-03  6.28597e-01  5.34003e-01  2.97309e-01  1.63498e+00
21Feb13_100349|   9.24999e-01 -2.69857e-01 -2.42502e+00  4.21238e-01  3.03054e-01
21Feb13_100349|  -3.28666e-01]
21Feb13_100349| [ 4.96081e-01  3.19527e-01  6.41207e-01  2.65925e-01  1.49075e+00
21Feb13_100349|   1.26551e-01 -3.97150e-01  1.17863e-01  3.16032e-01  1.62457e-01
21Feb13_100349|  -1.75157e+00]
21Feb13_100349| [ 1.07827e+00 -6.03883e-01 -1.79069e+00  3.62297e-01  1.72510e-01
21Feb13_100349|   2.07369e-01  2.87312e+00 -1.17485e+00  6.05597e-01 -1.01342e+00
21Feb13_100349|  -1.48620e+00]
21Feb13_100349| [ 2.10119e-01 -1.00618e+00 -1.21833e+00  1.51138e-01 -2.10391e+00
21Feb13_100349|  -9.70180e-01  1.51398e-01  3.86319e-01 -1.29116e+00  7.64629e-01
21Feb13_100349|   1.55391e+00]
21Feb13_100349| [-5.61712e-01  9.73611e-01 -1.11945e+00  6.21880e-02 -1.36018e+00
21Feb13_100349|   6.40626e-01  1.72919e-01 -8.32757e-02 -4.69855e-01  2.27406e+00
21Feb13_100349|   4.90539e-01]
21Feb13_100349| [ 9.10147e-01 -8.16175e-01  8.75446e-01 -5.79670e-01 -7.61116e-01
21Feb13_100349|  -1.51932e+00 -3.06235e-02 -4.15810e-01 -6.32631e-01  1.75909e+00
21Feb13_100349|   2.17078e-01]
21Feb13_100349| [-7.08015e-02  2.82435e+00  1.20172e+00 -2.33629e-01 -1.32451e+00
21Feb13_100349|  -3.79960e-01 -9.94142e-01  5.68075e-01 -2.52394e-02  2.67676e-01
21Feb13_100349|   1.39104e+00]
21Feb13_100349| [ 1.25990e+00  3.83043e-01 -5.14876e-01 -5.66390e-01  6.97171e-01
21Feb13_100349|  -4.78790e-02  1.40391e+00 -1.59839e+00  2.40815e+00 -2.11341e-01
21Feb13_100349|  -6.09598e-01]
21Feb13_100349| [-9.09803e-01  1.21788e+00 -4.90502e-02 -2.38674e+00 -1.07796e+00
21Feb13_100349|   1.50503e+00  9.89401e-01 -7.67240e-02 -2.39136e-01 -1.23826e+00
21Feb13_100349|   9.26134e-02]
21Feb13_100349| [-1.84424e+00 -1.25659e+00  1.59797e+00 -1.15697e+00  1.06948e+00
21Feb13_100349|   4.16988e-01 -6.95885e-01  1.64775e+00  2.71237e-01  1.15771e+00
21Feb13_100349|  -9.32049e-02]
21Feb13_100349| [-5.90352e-01  7.55237e-02 -9.82628e-01  1.09728e+00 -1.32232e+00
21Feb13_100349|  -5.82659e-02  9.41700e-01 -8.22310e-02  1.52491e+00 -8.38811e-01
21Feb13_100349|  -3.71191e-01]
21Feb13_100349| [ 4.89785e-01  7.09934e-01  9.23224e-01 -1.16146e-01 -1.29886e+00
21Feb13_100349|  -8.44858e-01 -8.82313e-01  7.77497e-01  1.31740e+00 -7.86706e-01
21Feb13_100349|  -2.09546e+00]
21Feb13_100349| [-1.73451e+00  7.97409e-01  8.43432e-01 -9.64302e-01  1.37347e+00
21Feb13_100349|  -7.45391e-01  1.70867e-01 -1.36756e+00  5.82947e-01 -8.68562e-01
21Feb13_100349|   1.52281e+00]
21Feb13_100349| [ 4.00468e-01  1.96305e+00  2.45851e+00 -2.24292e-01  1.02207e+00
21Feb13_100349|  -3.21156e-01 -2.24026e-01  8.81373e-01 -4.33565e-01  2.26966e+00
21Feb13_100349|  -6.45783e-01]
21Feb13_100349| [-1.03032e-01  1.48460e+00  3.46312e-01 -1.19882e+00  1.66240e+00
21Feb13_100349|  -3.14884e-01  1.01077e+00 -6.85286e-03 -6.98216e-01 -8.47058e-01
21Feb13_100349|  -5.50347e-01]
21Feb13_100349| [-1.11871e+00 -3.47026e-02 -3.39108e-01 -2.64636e-02 -7.06458e-01
21Feb13_100349|   1.63302e-01  1.31775e+00 -1.90493e+00  7.70172e-01 -1.46652e+00
21Feb13_100349|   7.78757e-01]
21Feb13_100349| [-4.22403e-01  1.77868e+00 -2.99659e-01 -9.52842e-01  4.45016e-01
21Feb13_100349|   1.60657e-01 -2.50497e+00 -7.00889e-01 -9.19795e-01 -8.47184e-01
21Feb13_100349|  -2.65355e-01]
21Feb13_100349| [-7.24223e-01  9.33796e-01  6.35998e-01 -4.00108e-01 -3.21069e-01
21Feb13_100349|  -1.09825e-01  2.10246e+00  4.11840e-01 -1.23415e+00 -6.89791e-01
21Feb13_100349|   2.08588e+00]]
21Feb13_100349|-- Bias --
21Feb13_100349|[-0.37416  0.16993 -0.26367  0.66001 -0.03379  0.80785  0.01432 -0.35067
21Feb13_100349|  0.36146  0.54304 -0.66491]
21Feb13_100349|Layer 1:
21Feb13_100349|-- Config --
21Feb13_100349|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 11], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100349|-- Weights --
21Feb13_100349|[[ 0.46273 -0.52633  0.15311 -0.90421]
21Feb13_100349| [-0.74445  0.54112  0.87680  0.47482]
21Feb13_100349| [-0.26719  0.17345  0.03642 -0.34925]
21Feb13_100349| [-0.58874  0.51152 -0.29307 -0.83212]
21Feb13_100349| [ 0.47815 -0.42503 -0.70618  0.59181]
21Feb13_100349| [-0.41898 -0.52488  0.41435 -0.03709]
21Feb13_100349| [-0.86538 -0.59482 -0.23110  0.07142]
21Feb13_100349| [ 0.14002 -0.88633  0.43298  0.45916]
21Feb13_100349| [-0.13044 -0.48032 -0.74848  0.34067]
21Feb13_100349| [ 0.52895  0.74501  0.12361 -0.14643]
21Feb13_100349| [ 0.58188  0.58465  0.38240  0.65996]]
21Feb13_100349|-- Bias --
21Feb13_100349|[-0.76731  0.51896 -0.80290  0.22809]
21Feb13_100349|Layer 2:
21Feb13_100349|-- Config --
21Feb13_100349|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100349|-- Weights --
21Feb13_100349|[[-1.53127  0.04037]
21Feb13_100349| [ 0.13677 -1.46193]
21Feb13_100349| [-1.11724  0.35367]
21Feb13_100349| [ 0.49422  0.28831]]
21Feb13_100349|-- Bias --
21Feb13_100349|[ 0.11773 -0.60451]
21Feb13_100349|Predicting the validation and test data with the Best final individual.
21Feb13_100357| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_100357|-----------  ------------------  --------------------  ----------
21Feb13_100357|Validation         42.00                  30            0.00000
21Feb13_100357|   Test            36.49                  30            0.00298
21Feb13_100357|-------------------- Test #7 --------------------
21Feb13_100357|Best final individual weights
21Feb13_100357|Individual:
21Feb13_100357|-- Constant hidden layers --
21Feb13_100357|False
21Feb13_100357|Layer 0:
21Feb13_100357|-- Config --
21Feb13_100357|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 11, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100357|-- Weights --
21Feb13_100357|[[-1.06145e+00  8.68922e-01 -1.14379e+00 -1.49459e-01 -5.92039e-01
21Feb13_100357|  -2.35241e-01 -1.40309e+00  2.12924e+00  1.77198e-01  3.19702e-01
21Feb13_100357|  -4.23758e-01]
21Feb13_100357| [-7.60973e-01 -1.69902e+00  5.70321e-01  7.00329e-02  7.06671e-01
21Feb13_100357|   3.27493e-01 -1.70808e+00 -1.16196e+00  9.48272e-02  6.65005e-01
21Feb13_100357|   1.23887e+00]
21Feb13_100357| [-5.76717e-01  4.39987e-01 -4.71900e-01  9.84744e-01 -6.70632e-01
21Feb13_100357|  -8.05147e-02  4.07717e-01  1.82295e+00 -3.65259e-01  2.94562e-02
21Feb13_100357|   4.58511e-01]
21Feb13_100357| [ 1.51511e+00  9.93966e-01  3.08471e-01 -5.70096e-01  8.84235e-02
21Feb13_100357|  -3.23449e-01 -2.17552e-02  1.61666e+00  6.74902e-02 -2.42173e-01
21Feb13_100357|  -1.07711e+00]
21Feb13_100357| [ 7.49020e-01  1.03034e+00  1.53014e+00 -1.66588e+00 -1.34224e-01
21Feb13_100357|   1.92903e+00 -2.20672e+00  1.52629e-01 -9.97077e-01 -4.47184e-01
21Feb13_100357|  -1.17110e+00]
21Feb13_100357| [ 5.15382e-01  1.00118e+00 -1.08350e+00  1.03880e+00 -4.68603e-01
21Feb13_100357|  -4.59197e-02  1.11058e+00  9.17544e-01  1.33730e-01  6.53965e-02
21Feb13_100357|  -1.13911e+00]
21Feb13_100357| [-2.04317e+00 -6.76921e-01  7.78254e-01 -1.17217e+00 -1.67455e+00
21Feb13_100357|  -1.57760e-02  8.21084e-01 -1.13921e-01  7.37767e-01 -2.98292e-01
21Feb13_100357|   2.92646e-01]
21Feb13_100357| [-8.01681e-01 -9.13592e-01 -7.13092e-01  1.16235e+00 -5.79811e-01
21Feb13_100357|   5.53346e-01 -3.23183e-01 -5.66910e-02  1.05090e+00 -4.89620e-01
21Feb13_100357|  -1.40866e-01]
21Feb13_100357| [-6.85763e-01  4.32546e-01  2.07281e-01  1.86934e-01  1.03855e+00
21Feb13_100357|  -2.61743e-02 -1.45446e+00  2.99914e-01  9.96893e-01  5.16927e-01
21Feb13_100357|  -9.72506e-01]
21Feb13_100357| [ 6.87732e-01  8.12844e-01  3.51990e-01 -1.28179e+00 -1.00846e-02
21Feb13_100357|  -2.28308e-01  1.61447e+00 -2.91772e-01  1.12608e+00  6.13314e-01
21Feb13_100357|  -7.64936e-01]
21Feb13_100357| [ 3.88583e-01  3.89122e-02 -7.32680e-01 -1.74359e-01 -1.04680e+00
21Feb13_100357|   1.41735e+00  3.14067e-01 -1.41835e-01 -5.39265e-01 -8.08813e-01
21Feb13_100357|   6.58712e-01]
21Feb13_100357| [-6.68434e-01 -9.77746e-01  1.42569e+00 -2.64191e-01 -4.41971e-01
21Feb13_100357|   3.89653e-01  1.19610e+00 -1.70441e+00  2.60850e-01 -1.16352e+00
21Feb13_100357|   6.53371e-01]
21Feb13_100357| [ 2.16387e+00  1.21870e+00 -1.34441e-01 -8.61036e-01 -6.09299e-01
21Feb13_100357|   7.85750e-01 -9.41396e-01 -5.31235e-01  4.44708e-02 -5.08207e-01
21Feb13_100357|  -2.45830e+00]
21Feb13_100357| [-8.92729e-01 -2.15613e-01 -3.99405e-01  1.63387e+00 -8.65849e-01
21Feb13_100357|   7.58911e-01  7.49706e-01 -2.11143e+00  1.56748e-01  7.64897e-01
21Feb13_100357|  -1.13879e+00]
21Feb13_100357| [-8.57088e-01 -1.62365e-03  1.26530e+00 -2.22604e+00 -2.28715e+00
21Feb13_100357|  -9.99604e-02 -2.40021e-01  3.35970e-01 -8.82544e-01  4.85761e-01
21Feb13_100357|  -2.24202e+00]
21Feb13_100357| [ 5.52215e-01  8.52156e-02 -2.37466e-01  1.07672e+00  1.54941e+00
21Feb13_100357|   1.99606e-01 -1.34808e+00  7.53511e-01 -5.99088e-01  5.98790e-02
21Feb13_100357|  -1.07950e-01]
21Feb13_100357| [ 2.67109e+00 -1.75176e+00 -6.16214e-01 -1.86800e+00  5.99501e-01
21Feb13_100357|  -1.10529e+00 -2.74849e+00  6.11555e-01  9.78547e-03 -3.97459e-01
21Feb13_100357|   2.92660e-01]
21Feb13_100357| [ 4.54863e-01 -9.09117e-01 -8.30196e-01  1.50206e+00 -1.73504e+00
21Feb13_100357|  -1.30648e+00  5.55948e-01 -7.54174e-01  2.05420e+00  1.38864e+00
21Feb13_100357|   5.29561e-01]
21Feb13_100357| [-4.85366e-01 -3.53531e-01  9.05198e-01  7.65456e-01 -1.64749e+00
21Feb13_100357|   5.69847e-01  2.50378e-01  7.85001e-01 -1.45661e+00  8.34665e-02
21Feb13_100357|   8.15879e-01]
21Feb13_100357| [ 1.25727e+00  2.46577e-01  5.85987e-01  5.77962e-01 -2.59665e-01
21Feb13_100357|  -1.17493e-01  1.60910e+00  9.12990e-01  1.44670e+00  5.22422e-01
21Feb13_100357|  -1.94187e+00]
21Feb13_100357| [ 1.33867e-01 -1.27358e+00 -3.47982e-01 -6.08657e-02 -1.30348e-01
21Feb13_100357|  -1.17219e+00  1.24909e+00 -1.11782e+00  8.64220e-01  5.61000e-01
21Feb13_100357|  -1.48212e+00]
21Feb13_100357| [ 1.78205e+00 -2.50466e-01  1.33657e+00 -1.73845e+00  1.81425e+00
21Feb13_100357|  -8.02280e-01 -1.16246e+00  1.15245e+00 -3.53401e-01  6.57431e-01
21Feb13_100357|   9.30205e-01]
21Feb13_100357| [-3.03807e-01 -5.34010e-01 -5.36033e-02  1.22986e+00 -7.73593e-01
21Feb13_100357|  -2.41838e-02  9.47047e-01  1.63950e+00  8.57850e-01  7.18366e-01
21Feb13_100357|   6.19340e-01]
21Feb13_100357| [-1.56874e+00  9.13052e-01 -1.80219e+00 -6.85706e-02 -1.52747e-01
21Feb13_100357|  -1.23654e+00  7.66763e-01  8.76849e-01  1.38192e+00  1.74758e-01
21Feb13_100357|   9.19395e-01]
21Feb13_100357| [-3.41080e-01 -1.01680e+00 -7.82347e-01  5.72435e-01  1.21957e+00
21Feb13_100357|  -1.70168e+00  1.35596e+00 -1.36994e+00  6.54260e-01  2.17154e+00
21Feb13_100357|  -6.51639e-01]
21Feb13_100357| [-4.25343e-01  1.74798e+00  9.89404e-01 -1.04295e+00 -5.27053e-03
21Feb13_100357|   1.42040e+00  1.70140e+00 -5.47912e-01  2.85277e-01 -3.08635e-01
21Feb13_100357|  -1.87522e+00]
21Feb13_100357| [-2.65662e+00 -2.02900e+00 -1.49073e-01 -1.86322e-01 -6.15986e-01
21Feb13_100357|   1.02607e+00  7.96644e-01 -5.96812e-01  1.99503e-01 -1.24498e+00
21Feb13_100357|   1.01419e+00]
21Feb13_100357| [-1.31259e+00 -4.54363e-01  1.06493e-01  1.22074e+00  1.74518e-01
21Feb13_100357|  -5.57725e-01 -1.40429e+00  6.75301e-01  1.36944e+00 -3.09052e-01
21Feb13_100357|   1.21379e-01]
21Feb13_100357| [-1.66580e+00 -6.50639e-01  5.46120e-01 -1.25566e+00 -5.04851e-01
21Feb13_100357|  -5.49479e-01  1.11882e-01 -4.76139e-01 -4.81819e-01 -1.14210e-01
21Feb13_100357|  -1.57996e+00]
21Feb13_100357| [-7.64196e-01  1.06296e+00 -7.61805e-01 -1.49152e+00  9.36859e-01
21Feb13_100357|  -1.03321e+00 -2.87637e-01 -2.47389e-01  2.61926e-01  8.37227e-01
21Feb13_100357|  -3.42333e-01]
21Feb13_100357| [ 7.46572e-01 -1.58035e+00  8.02182e-01 -5.66302e-01 -8.47290e-01
21Feb13_100357|  -6.34161e-01  1.74178e+00  1.27802e+00  1.67001e+00 -7.94473e-01
21Feb13_100357|   1.10741e+00]
21Feb13_100357| [-6.74261e-01  5.99487e-01 -1.80403e+00 -1.02671e+00 -1.54235e+00
21Feb13_100357|  -1.26515e+00  4.29489e-01  8.21419e-01  1.06895e+00  1.13029e+00
21Feb13_100357|   7.65765e-01]
21Feb13_100357| [ 3.93528e-01 -5.92774e-01  5.40870e-01  9.02092e-01 -1.02404e+00
21Feb13_100357|  -1.10673e+00  2.35611e-01 -1.02808e+00  1.83820e-01  4.85873e-01
21Feb13_100357|  -1.59386e+00]
21Feb13_100357| [ 7.49489e-01 -6.49799e-01  1.34338e+00  2.12189e+00 -7.31882e-01
21Feb13_100357|   5.88080e-01  2.20549e+00 -1.06942e+00 -1.29756e+00 -7.96579e-01
21Feb13_100357|  -5.81803e-01]
21Feb13_100357| [-1.75688e-01  7.50212e-01 -1.37744e+00 -3.66415e-01  8.48990e-01
21Feb13_100357|  -1.88524e-01  1.13690e+00  1.33830e-01 -1.38609e+00 -3.92856e-01
21Feb13_100357|   5.05161e-01]
21Feb13_100357| [-1.56803e-01  6.44681e-01  4.29331e-01 -2.67595e-02  1.86944e+00
21Feb13_100357|   2.86790e+00  6.18832e-02  3.55496e-01  7.56248e-03 -1.48327e+00
21Feb13_100357|  -3.39873e-01]
21Feb13_100357| [-2.54559e-01 -1.85204e+00 -4.10288e-01 -8.81453e-01 -2.11431e-01
21Feb13_100357|   1.19889e+00  1.26373e+00 -6.36870e-01  1.26338e+00  5.36597e-01
21Feb13_100357|   1.31875e-02]
21Feb13_100357| [-6.96596e-02 -5.38534e-01  5.48522e-01  5.84182e-02  6.63353e-01
21Feb13_100357|  -8.82974e-01  8.67865e-01 -4.46778e-01  3.78957e-01 -1.73884e+00
21Feb13_100357|   7.87282e-01]
21Feb13_100357| [-9.53666e-01  9.80083e-01 -2.38978e-01 -1.94127e-01 -1.09625e+00
21Feb13_100357|   6.84617e-01 -1.90861e+00 -1.46974e+00  1.49925e-01 -6.42909e-01
21Feb13_100357|   1.10172e+00]
21Feb13_100357| [ 1.25790e-03  6.28597e-01  5.34003e-01  2.97309e-01  1.63498e+00
21Feb13_100357|   9.24999e-01 -2.69857e-01 -2.42502e+00  4.21238e-01  3.03054e-01
21Feb13_100357|  -3.28666e-01]
21Feb13_100357| [ 4.96081e-01  3.19527e-01  6.41207e-01  2.65925e-01  1.49075e+00
21Feb13_100357|   1.26551e-01 -3.97150e-01  1.17863e-01  3.16032e-01  1.62457e-01
21Feb13_100357|  -1.75157e+00]
21Feb13_100357| [ 1.07827e+00 -6.03883e-01 -1.79069e+00  3.62297e-01  1.72510e-01
21Feb13_100357|   2.07369e-01  2.87312e+00 -1.17485e+00  6.05597e-01 -1.01342e+00
21Feb13_100357|  -1.48620e+00]
21Feb13_100357| [ 2.10119e-01 -1.00618e+00 -1.21833e+00  1.51138e-01 -2.10391e+00
21Feb13_100357|  -9.70180e-01  1.51398e-01  3.86319e-01 -1.29116e+00  7.64629e-01
21Feb13_100357|   1.55391e+00]
21Feb13_100357| [-5.61712e-01  9.73611e-01 -1.11945e+00  6.21880e-02 -1.36018e+00
21Feb13_100357|   6.40626e-01  1.72919e-01 -8.32757e-02 -4.69855e-01  2.27406e+00
21Feb13_100357|   4.90539e-01]
21Feb13_100357| [ 9.10147e-01 -8.16175e-01  8.75446e-01 -5.79670e-01 -7.61116e-01
21Feb13_100357|  -1.51932e+00 -3.06235e-02 -4.15810e-01 -6.32631e-01  1.75909e+00
21Feb13_100357|   2.17078e-01]
21Feb13_100357| [-7.08015e-02  2.82435e+00  1.20172e+00 -2.33629e-01 -1.32451e+00
21Feb13_100357|  -3.79960e-01 -9.94142e-01  5.68075e-01 -2.52394e-02  2.67676e-01
21Feb13_100357|   1.39104e+00]
21Feb13_100357| [ 1.25990e+00  3.83043e-01 -5.14876e-01 -5.66390e-01  6.97171e-01
21Feb13_100357|  -4.78790e-02  1.40391e+00 -1.59839e+00  2.40815e+00 -2.11341e-01
21Feb13_100357|  -6.09598e-01]
21Feb13_100357| [-9.09803e-01  1.21788e+00 -4.90502e-02 -2.38674e+00 -1.07796e+00
21Feb13_100357|   1.50503e+00  9.89401e-01 -7.67240e-02 -2.39136e-01 -1.23826e+00
21Feb13_100357|   9.26134e-02]
21Feb13_100357| [-1.84424e+00 -1.25659e+00  1.59797e+00 -1.15697e+00  1.06948e+00
21Feb13_100357|   4.16988e-01 -6.95885e-01  1.64775e+00  2.71237e-01  1.15771e+00
21Feb13_100357|  -9.32049e-02]
21Feb13_100357| [-5.90352e-01  7.55237e-02 -9.82628e-01  1.09728e+00 -1.32232e+00
21Feb13_100357|  -5.82659e-02  9.41700e-01 -8.22310e-02  1.52491e+00 -8.38811e-01
21Feb13_100357|  -3.71191e-01]
21Feb13_100357| [ 4.89785e-01  7.09934e-01  9.23224e-01 -1.16146e-01 -1.29886e+00
21Feb13_100357|  -8.44858e-01 -8.82313e-01  7.77497e-01  1.31740e+00 -7.86706e-01
21Feb13_100357|  -2.09546e+00]
21Feb13_100357| [-1.73451e+00  7.97409e-01  8.43432e-01 -9.64302e-01  1.37347e+00
21Feb13_100357|  -7.45391e-01  1.70867e-01 -1.36756e+00  5.82947e-01 -8.68562e-01
21Feb13_100357|   1.52281e+00]
21Feb13_100357| [ 4.00468e-01  1.96305e+00  2.45851e+00 -2.24292e-01  1.02207e+00
21Feb13_100357|  -3.21156e-01 -2.24026e-01  8.81373e-01 -4.33565e-01  2.26966e+00
21Feb13_100357|  -6.45783e-01]
21Feb13_100357| [-1.03032e-01  1.48460e+00  3.46312e-01 -1.19882e+00  1.66240e+00
21Feb13_100357|  -3.14884e-01  1.01077e+00 -6.85286e-03 -6.98216e-01 -8.47058e-01
21Feb13_100357|  -5.50347e-01]
21Feb13_100357| [-1.11871e+00 -3.47026e-02 -3.39108e-01 -2.64636e-02 -7.06458e-01
21Feb13_100357|   1.63302e-01  1.31775e+00 -1.90493e+00  7.70172e-01 -1.46652e+00
21Feb13_100357|   7.78757e-01]
21Feb13_100357| [-4.22403e-01  1.77868e+00 -2.99659e-01 -9.52842e-01  4.45016e-01
21Feb13_100357|   1.60657e-01 -2.50497e+00 -7.00889e-01 -9.19795e-01 -8.47184e-01
21Feb13_100357|  -2.65355e-01]
21Feb13_100357| [-7.24223e-01  9.33796e-01  6.35998e-01 -4.00108e-01 -3.21069e-01
21Feb13_100357|  -1.09825e-01  2.10246e+00  4.11840e-01 -1.23415e+00 -6.89791e-01
21Feb13_100357|   2.08588e+00]]
21Feb13_100357|-- Bias --
21Feb13_100357|[-0.37416  0.16993 -0.26367  0.66001 -0.03379  0.80785  0.01432 -0.35067
21Feb13_100357|  0.36146  0.54304 -0.66491]
21Feb13_100357|Layer 1:
21Feb13_100357|-- Config --
21Feb13_100357|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 11], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100357|-- Weights --
21Feb13_100357|[[ 0.46273 -0.52633  0.15311 -0.90421]
21Feb13_100357| [-0.74445  0.54112  0.87680  0.47482]
21Feb13_100357| [-0.26719  0.17345  0.03642 -0.34925]
21Feb13_100357| [-0.58874  0.51152 -0.29307 -0.83212]
21Feb13_100357| [ 0.47815 -0.42503 -0.70618  0.59181]
21Feb13_100357| [-0.41898 -0.52488  0.41435 -0.03709]
21Feb13_100357| [-0.86538 -0.59482 -0.23110  0.07142]
21Feb13_100357| [ 0.14002 -0.88633  0.43298  0.45916]
21Feb13_100357| [-0.13044 -0.48032 -0.74848  0.34067]
21Feb13_100357| [ 0.52895  0.74501  0.12361 -0.14643]
21Feb13_100357| [ 0.58188  0.58465  0.38240  0.65996]]
21Feb13_100357|-- Bias --
21Feb13_100357|[-0.76731  0.51896 -0.80290  0.22809]
21Feb13_100357|Layer 2:
21Feb13_100357|-- Config --
21Feb13_100357|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100357|-- Weights --
21Feb13_100357|[[-1.53127  0.04037]
21Feb13_100357| [ 0.13677 -1.46193]
21Feb13_100357| [-1.11724  0.35367]
21Feb13_100357| [ 0.49422  0.28831]]
21Feb13_100357|-- Bias --
21Feb13_100357|[ 0.11773 -0.60451]
21Feb13_100357|Predicting the validation and test data with the Best final individual.
21Feb13_100404| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_100404|-----------  ------------------  --------------------  ----------
21Feb13_100404|Validation         42.00                  30            0.00000
21Feb13_100404|   Test            36.32                  30            0.00298
21Feb13_100404|-------------------- Test #8 --------------------
21Feb13_100404|Best final individual weights
21Feb13_100404|Individual:
21Feb13_100404|-- Constant hidden layers --
21Feb13_100404|False
21Feb13_100404|Layer 0:
21Feb13_100404|-- Config --
21Feb13_100404|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 11, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100404|-- Weights --
21Feb13_100404|[[-1.06145e+00  8.68922e-01 -1.14379e+00 -1.49459e-01 -5.92039e-01
21Feb13_100404|  -2.35241e-01 -1.40309e+00  2.12924e+00  1.77198e-01  3.19702e-01
21Feb13_100404|  -4.23758e-01]
21Feb13_100404| [-7.60973e-01 -1.69902e+00  5.70321e-01  7.00329e-02  7.06671e-01
21Feb13_100404|   3.27493e-01 -1.70808e+00 -1.16196e+00  9.48272e-02  6.65005e-01
21Feb13_100404|   1.23887e+00]
21Feb13_100404| [-5.76717e-01  4.39987e-01 -4.71900e-01  9.84744e-01 -6.70632e-01
21Feb13_100404|  -8.05147e-02  4.07717e-01  1.82295e+00 -3.65259e-01  2.94562e-02
21Feb13_100404|   4.58511e-01]
21Feb13_100404| [ 1.51511e+00  9.93966e-01  3.08471e-01 -5.70096e-01  8.84235e-02
21Feb13_100404|  -3.23449e-01 -2.17552e-02  1.61666e+00  6.74902e-02 -2.42173e-01
21Feb13_100404|  -1.07711e+00]
21Feb13_100404| [ 7.49020e-01  1.03034e+00  1.53014e+00 -1.66588e+00 -1.34224e-01
21Feb13_100404|   1.92903e+00 -2.20672e+00  1.52629e-01 -9.97077e-01 -4.47184e-01
21Feb13_100404|  -1.17110e+00]
21Feb13_100404| [ 5.15382e-01  1.00118e+00 -1.08350e+00  1.03880e+00 -4.68603e-01
21Feb13_100404|  -4.59197e-02  1.11058e+00  9.17544e-01  1.33730e-01  6.53965e-02
21Feb13_100404|  -1.13911e+00]
21Feb13_100404| [-2.04317e+00 -6.76921e-01  7.78254e-01 -1.17217e+00 -1.67455e+00
21Feb13_100404|  -1.57760e-02  8.21084e-01 -1.13921e-01  7.37767e-01 -2.98292e-01
21Feb13_100404|   2.92646e-01]
21Feb13_100404| [-8.01681e-01 -9.13592e-01 -7.13092e-01  1.16235e+00 -5.79811e-01
21Feb13_100404|   5.53346e-01 -3.23183e-01 -5.66910e-02  1.05090e+00 -4.89620e-01
21Feb13_100404|  -1.40866e-01]
21Feb13_100404| [-6.85763e-01  4.32546e-01  2.07281e-01  1.86934e-01  1.03855e+00
21Feb13_100404|  -2.61743e-02 -1.45446e+00  2.99914e-01  9.96893e-01  5.16927e-01
21Feb13_100404|  -9.72506e-01]
21Feb13_100404| [ 6.87732e-01  8.12844e-01  3.51990e-01 -1.28179e+00 -1.00846e-02
21Feb13_100404|  -2.28308e-01  1.61447e+00 -2.91772e-01  1.12608e+00  6.13314e-01
21Feb13_100404|  -7.64936e-01]
21Feb13_100404| [ 3.88583e-01  3.89122e-02 -7.32680e-01 -1.74359e-01 -1.04680e+00
21Feb13_100404|   1.41735e+00  3.14067e-01 -1.41835e-01 -5.39265e-01 -8.08813e-01
21Feb13_100404|   6.58712e-01]
21Feb13_100404| [-6.68434e-01 -9.77746e-01  1.42569e+00 -2.64191e-01 -4.41971e-01
21Feb13_100404|   3.89653e-01  1.19610e+00 -1.70441e+00  2.60850e-01 -1.16352e+00
21Feb13_100404|   6.53371e-01]
21Feb13_100404| [ 2.16387e+00  1.21870e+00 -1.34441e-01 -8.61036e-01 -6.09299e-01
21Feb13_100404|   7.85750e-01 -9.41396e-01 -5.31235e-01  4.44708e-02 -5.08207e-01
21Feb13_100404|  -2.45830e+00]
21Feb13_100404| [-8.92729e-01 -2.15613e-01 -3.99405e-01  1.63387e+00 -8.65849e-01
21Feb13_100404|   7.58911e-01  7.49706e-01 -2.11143e+00  1.56748e-01  7.64897e-01
21Feb13_100404|  -1.13879e+00]
21Feb13_100404| [-8.57088e-01 -1.62365e-03  1.26530e+00 -2.22604e+00 -2.28715e+00
21Feb13_100404|  -9.99604e-02 -2.40021e-01  3.35970e-01 -8.82544e-01  4.85761e-01
21Feb13_100404|  -2.24202e+00]
21Feb13_100404| [ 5.52215e-01  8.52156e-02 -2.37466e-01  1.07672e+00  1.54941e+00
21Feb13_100404|   1.99606e-01 -1.34808e+00  7.53511e-01 -5.99088e-01  5.98790e-02
21Feb13_100404|  -1.07950e-01]
21Feb13_100404| [ 2.67109e+00 -1.75176e+00 -6.16214e-01 -1.86800e+00  5.99501e-01
21Feb13_100404|  -1.10529e+00 -2.74849e+00  6.11555e-01  9.78547e-03 -3.97459e-01
21Feb13_100404|   2.92660e-01]
21Feb13_100404| [ 4.54863e-01 -9.09117e-01 -8.30196e-01  1.50206e+00 -1.73504e+00
21Feb13_100404|  -1.30648e+00  5.55948e-01 -7.54174e-01  2.05420e+00  1.38864e+00
21Feb13_100404|   5.29561e-01]
21Feb13_100404| [-4.85366e-01 -3.53531e-01  9.05198e-01  7.65456e-01 -1.64749e+00
21Feb13_100404|   5.69847e-01  2.50378e-01  7.85001e-01 -1.45661e+00  8.34665e-02
21Feb13_100404|   8.15879e-01]
21Feb13_100404| [ 1.25727e+00  2.46577e-01  5.85987e-01  5.77962e-01 -2.59665e-01
21Feb13_100404|  -1.17493e-01  1.60910e+00  9.12990e-01  1.44670e+00  5.22422e-01
21Feb13_100404|  -1.94187e+00]
21Feb13_100404| [ 1.33867e-01 -1.27358e+00 -3.47982e-01 -6.08657e-02 -1.30348e-01
21Feb13_100404|  -1.17219e+00  1.24909e+00 -1.11782e+00  8.64220e-01  5.61000e-01
21Feb13_100404|  -1.48212e+00]
21Feb13_100404| [ 1.78205e+00 -2.50466e-01  1.33657e+00 -1.73845e+00  1.81425e+00
21Feb13_100404|  -8.02280e-01 -1.16246e+00  1.15245e+00 -3.53401e-01  6.57431e-01
21Feb13_100404|   9.30205e-01]
21Feb13_100404| [-3.03807e-01 -5.34010e-01 -5.36033e-02  1.22986e+00 -7.73593e-01
21Feb13_100404|  -2.41838e-02  9.47047e-01  1.63950e+00  8.57850e-01  7.18366e-01
21Feb13_100404|   6.19340e-01]
21Feb13_100404| [-1.56874e+00  9.13052e-01 -1.80219e+00 -6.85706e-02 -1.52747e-01
21Feb13_100404|  -1.23654e+00  7.66763e-01  8.76849e-01  1.38192e+00  1.74758e-01
21Feb13_100404|   9.19395e-01]
21Feb13_100404| [-3.41080e-01 -1.01680e+00 -7.82347e-01  5.72435e-01  1.21957e+00
21Feb13_100404|  -1.70168e+00  1.35596e+00 -1.36994e+00  6.54260e-01  2.17154e+00
21Feb13_100404|  -6.51639e-01]
21Feb13_100404| [-4.25343e-01  1.74798e+00  9.89404e-01 -1.04295e+00 -5.27053e-03
21Feb13_100404|   1.42040e+00  1.70140e+00 -5.47912e-01  2.85277e-01 -3.08635e-01
21Feb13_100404|  -1.87522e+00]
21Feb13_100404| [-2.65662e+00 -2.02900e+00 -1.49073e-01 -1.86322e-01 -6.15986e-01
21Feb13_100404|   1.02607e+00  7.96644e-01 -5.96812e-01  1.99503e-01 -1.24498e+00
21Feb13_100404|   1.01419e+00]
21Feb13_100404| [-1.31259e+00 -4.54363e-01  1.06493e-01  1.22074e+00  1.74518e-01
21Feb13_100404|  -5.57725e-01 -1.40429e+00  6.75301e-01  1.36944e+00 -3.09052e-01
21Feb13_100404|   1.21379e-01]
21Feb13_100404| [-1.66580e+00 -6.50639e-01  5.46120e-01 -1.25566e+00 -5.04851e-01
21Feb13_100404|  -5.49479e-01  1.11882e-01 -4.76139e-01 -4.81819e-01 -1.14210e-01
21Feb13_100404|  -1.57996e+00]
21Feb13_100404| [-7.64196e-01  1.06296e+00 -7.61805e-01 -1.49152e+00  9.36859e-01
21Feb13_100404|  -1.03321e+00 -2.87637e-01 -2.47389e-01  2.61926e-01  8.37227e-01
21Feb13_100404|  -3.42333e-01]
21Feb13_100404| [ 7.46572e-01 -1.58035e+00  8.02182e-01 -5.66302e-01 -8.47290e-01
21Feb13_100404|  -6.34161e-01  1.74178e+00  1.27802e+00  1.67001e+00 -7.94473e-01
21Feb13_100404|   1.10741e+00]
21Feb13_100404| [-6.74261e-01  5.99487e-01 -1.80403e+00 -1.02671e+00 -1.54235e+00
21Feb13_100404|  -1.26515e+00  4.29489e-01  8.21419e-01  1.06895e+00  1.13029e+00
21Feb13_100404|   7.65765e-01]
21Feb13_100404| [ 3.93528e-01 -5.92774e-01  5.40870e-01  9.02092e-01 -1.02404e+00
21Feb13_100404|  -1.10673e+00  2.35611e-01 -1.02808e+00  1.83820e-01  4.85873e-01
21Feb13_100404|  -1.59386e+00]
21Feb13_100404| [ 7.49489e-01 -6.49799e-01  1.34338e+00  2.12189e+00 -7.31882e-01
21Feb13_100404|   5.88080e-01  2.20549e+00 -1.06942e+00 -1.29756e+00 -7.96579e-01
21Feb13_100404|  -5.81803e-01]
21Feb13_100404| [-1.75688e-01  7.50212e-01 -1.37744e+00 -3.66415e-01  8.48990e-01
21Feb13_100404|  -1.88524e-01  1.13690e+00  1.33830e-01 -1.38609e+00 -3.92856e-01
21Feb13_100404|   5.05161e-01]
21Feb13_100404| [-1.56803e-01  6.44681e-01  4.29331e-01 -2.67595e-02  1.86944e+00
21Feb13_100404|   2.86790e+00  6.18832e-02  3.55496e-01  7.56248e-03 -1.48327e+00
21Feb13_100404|  -3.39873e-01]
21Feb13_100404| [-2.54559e-01 -1.85204e+00 -4.10288e-01 -8.81453e-01 -2.11431e-01
21Feb13_100404|   1.19889e+00  1.26373e+00 -6.36870e-01  1.26338e+00  5.36597e-01
21Feb13_100404|   1.31875e-02]
21Feb13_100404| [-6.96596e-02 -5.38534e-01  5.48522e-01  5.84182e-02  6.63353e-01
21Feb13_100404|  -8.82974e-01  8.67865e-01 -4.46778e-01  3.78957e-01 -1.73884e+00
21Feb13_100404|   7.87282e-01]
21Feb13_100404| [-9.53666e-01  9.80083e-01 -2.38978e-01 -1.94127e-01 -1.09625e+00
21Feb13_100404|   6.84617e-01 -1.90861e+00 -1.46974e+00  1.49925e-01 -6.42909e-01
21Feb13_100404|   1.10172e+00]
21Feb13_100404| [ 1.25790e-03  6.28597e-01  5.34003e-01  2.97309e-01  1.63498e+00
21Feb13_100404|   9.24999e-01 -2.69857e-01 -2.42502e+00  4.21238e-01  3.03054e-01
21Feb13_100404|  -3.28666e-01]
21Feb13_100404| [ 4.96081e-01  3.19527e-01  6.41207e-01  2.65925e-01  1.49075e+00
21Feb13_100404|   1.26551e-01 -3.97150e-01  1.17863e-01  3.16032e-01  1.62457e-01
21Feb13_100404|  -1.75157e+00]
21Feb13_100404| [ 1.07827e+00 -6.03883e-01 -1.79069e+00  3.62297e-01  1.72510e-01
21Feb13_100404|   2.07369e-01  2.87312e+00 -1.17485e+00  6.05597e-01 -1.01342e+00
21Feb13_100404|  -1.48620e+00]
21Feb13_100404| [ 2.10119e-01 -1.00618e+00 -1.21833e+00  1.51138e-01 -2.10391e+00
21Feb13_100404|  -9.70180e-01  1.51398e-01  3.86319e-01 -1.29116e+00  7.64629e-01
21Feb13_100404|   1.55391e+00]
21Feb13_100404| [-5.61712e-01  9.73611e-01 -1.11945e+00  6.21880e-02 -1.36018e+00
21Feb13_100404|   6.40626e-01  1.72919e-01 -8.32757e-02 -4.69855e-01  2.27406e+00
21Feb13_100404|   4.90539e-01]
21Feb13_100404| [ 9.10147e-01 -8.16175e-01  8.75446e-01 -5.79670e-01 -7.61116e-01
21Feb13_100404|  -1.51932e+00 -3.06235e-02 -4.15810e-01 -6.32631e-01  1.75909e+00
21Feb13_100404|   2.17078e-01]
21Feb13_100404| [-7.08015e-02  2.82435e+00  1.20172e+00 -2.33629e-01 -1.32451e+00
21Feb13_100404|  -3.79960e-01 -9.94142e-01  5.68075e-01 -2.52394e-02  2.67676e-01
21Feb13_100404|   1.39104e+00]
21Feb13_100404| [ 1.25990e+00  3.83043e-01 -5.14876e-01 -5.66390e-01  6.97171e-01
21Feb13_100404|  -4.78790e-02  1.40391e+00 -1.59839e+00  2.40815e+00 -2.11341e-01
21Feb13_100404|  -6.09598e-01]
21Feb13_100404| [-9.09803e-01  1.21788e+00 -4.90502e-02 -2.38674e+00 -1.07796e+00
21Feb13_100404|   1.50503e+00  9.89401e-01 -7.67240e-02 -2.39136e-01 -1.23826e+00
21Feb13_100404|   9.26134e-02]
21Feb13_100404| [-1.84424e+00 -1.25659e+00  1.59797e+00 -1.15697e+00  1.06948e+00
21Feb13_100404|   4.16988e-01 -6.95885e-01  1.64775e+00  2.71237e-01  1.15771e+00
21Feb13_100404|  -9.32049e-02]
21Feb13_100404| [-5.90352e-01  7.55237e-02 -9.82628e-01  1.09728e+00 -1.32232e+00
21Feb13_100404|  -5.82659e-02  9.41700e-01 -8.22310e-02  1.52491e+00 -8.38811e-01
21Feb13_100404|  -3.71191e-01]
21Feb13_100404| [ 4.89785e-01  7.09934e-01  9.23224e-01 -1.16146e-01 -1.29886e+00
21Feb13_100404|  -8.44858e-01 -8.82313e-01  7.77497e-01  1.31740e+00 -7.86706e-01
21Feb13_100404|  -2.09546e+00]
21Feb13_100404| [-1.73451e+00  7.97409e-01  8.43432e-01 -9.64302e-01  1.37347e+00
21Feb13_100404|  -7.45391e-01  1.70867e-01 -1.36756e+00  5.82947e-01 -8.68562e-01
21Feb13_100404|   1.52281e+00]
21Feb13_100404| [ 4.00468e-01  1.96305e+00  2.45851e+00 -2.24292e-01  1.02207e+00
21Feb13_100404|  -3.21156e-01 -2.24026e-01  8.81373e-01 -4.33565e-01  2.26966e+00
21Feb13_100404|  -6.45783e-01]
21Feb13_100404| [-1.03032e-01  1.48460e+00  3.46312e-01 -1.19882e+00  1.66240e+00
21Feb13_100404|  -3.14884e-01  1.01077e+00 -6.85286e-03 -6.98216e-01 -8.47058e-01
21Feb13_100404|  -5.50347e-01]
21Feb13_100404| [-1.11871e+00 -3.47026e-02 -3.39108e-01 -2.64636e-02 -7.06458e-01
21Feb13_100404|   1.63302e-01  1.31775e+00 -1.90493e+00  7.70172e-01 -1.46652e+00
21Feb13_100404|   7.78757e-01]
21Feb13_100404| [-4.22403e-01  1.77868e+00 -2.99659e-01 -9.52842e-01  4.45016e-01
21Feb13_100404|   1.60657e-01 -2.50497e+00 -7.00889e-01 -9.19795e-01 -8.47184e-01
21Feb13_100404|  -2.65355e-01]
21Feb13_100404| [-7.24223e-01  9.33796e-01  6.35998e-01 -4.00108e-01 -3.21069e-01
21Feb13_100404|  -1.09825e-01  2.10246e+00  4.11840e-01 -1.23415e+00 -6.89791e-01
21Feb13_100404|   2.08588e+00]]
21Feb13_100404|-- Bias --
21Feb13_100404|[-0.37416  0.16993 -0.26367  0.66001 -0.03379  0.80785  0.01432 -0.35067
21Feb13_100404|  0.36146  0.54304 -0.66491]
21Feb13_100404|Layer 1:
21Feb13_100404|-- Config --
21Feb13_100404|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 11], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100404|-- Weights --
21Feb13_100404|[[ 0.46273 -0.52633  0.15311 -0.90421]
21Feb13_100404| [-0.74445  0.54112  0.87680  0.47482]
21Feb13_100404| [-0.26719  0.17345  0.03642 -0.34925]
21Feb13_100404| [-0.58874  0.51152 -0.29307 -0.83212]
21Feb13_100404| [ 0.47815 -0.42503 -0.70618  0.59181]
21Feb13_100404| [-0.41898 -0.52488  0.41435 -0.03709]
21Feb13_100404| [-0.86538 -0.59482 -0.23110  0.07142]
21Feb13_100404| [ 0.14002 -0.88633  0.43298  0.45916]
21Feb13_100404| [-0.13044 -0.48032 -0.74848  0.34067]
21Feb13_100404| [ 0.52895  0.74501  0.12361 -0.14643]
21Feb13_100404| [ 0.58188  0.58465  0.38240  0.65996]]
21Feb13_100404|-- Bias --
21Feb13_100404|[-0.76731  0.51896 -0.80290  0.22809]
21Feb13_100404|Layer 2:
21Feb13_100404|-- Config --
21Feb13_100404|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100404|-- Weights --
21Feb13_100404|[[-1.53127  0.04037]
21Feb13_100404| [ 0.13677 -1.46193]
21Feb13_100404| [-1.11724  0.35367]
21Feb13_100404| [ 0.49422  0.28831]]
21Feb13_100404|-- Bias --
21Feb13_100404|[ 0.11773 -0.60451]
21Feb13_100404|Predicting the validation and test data with the Best final individual.
21Feb13_100412| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_100412|-----------  ------------------  --------------------  ----------
21Feb13_100412|Validation         42.17                  30            0.00000
21Feb13_100412|   Test            36.40                  30            0.00298
21Feb13_100412|-------------------- Test #9 --------------------
21Feb13_100412|Best final individual weights
21Feb13_100412|Individual:
21Feb13_100412|-- Constant hidden layers --
21Feb13_100412|False
21Feb13_100412|Layer 0:
21Feb13_100412|-- Config --
21Feb13_100412|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 11, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100412|-- Weights --
21Feb13_100412|[[-1.06145e+00  8.68922e-01 -1.14379e+00 -1.49459e-01 -5.92039e-01
21Feb13_100412|  -2.35241e-01 -1.40309e+00  2.12924e+00  1.77198e-01  3.19702e-01
21Feb13_100412|  -4.23758e-01]
21Feb13_100412| [-7.60973e-01 -1.69902e+00  5.70321e-01  7.00329e-02  7.06671e-01
21Feb13_100412|   3.27493e-01 -1.70808e+00 -1.16196e+00  9.48272e-02  6.65005e-01
21Feb13_100412|   1.23887e+00]
21Feb13_100412| [-5.76717e-01  4.39987e-01 -4.71900e-01  9.84744e-01 -6.70632e-01
21Feb13_100412|  -8.05147e-02  4.07717e-01  1.82295e+00 -3.65259e-01  2.94562e-02
21Feb13_100412|   4.58511e-01]
21Feb13_100412| [ 1.51511e+00  9.93966e-01  3.08471e-01 -5.70096e-01  8.84235e-02
21Feb13_100412|  -3.23449e-01 -2.17552e-02  1.61666e+00  6.74902e-02 -2.42173e-01
21Feb13_100412|  -1.07711e+00]
21Feb13_100412| [ 7.49020e-01  1.03034e+00  1.53014e+00 -1.66588e+00 -1.34224e-01
21Feb13_100412|   1.92903e+00 -2.20672e+00  1.52629e-01 -9.97077e-01 -4.47184e-01
21Feb13_100412|  -1.17110e+00]
21Feb13_100412| [ 5.15382e-01  1.00118e+00 -1.08350e+00  1.03880e+00 -4.68603e-01
21Feb13_100412|  -4.59197e-02  1.11058e+00  9.17544e-01  1.33730e-01  6.53965e-02
21Feb13_100412|  -1.13911e+00]
21Feb13_100412| [-2.04317e+00 -6.76921e-01  7.78254e-01 -1.17217e+00 -1.67455e+00
21Feb13_100412|  -1.57760e-02  8.21084e-01 -1.13921e-01  7.37767e-01 -2.98292e-01
21Feb13_100412|   2.92646e-01]
21Feb13_100412| [-8.01681e-01 -9.13592e-01 -7.13092e-01  1.16235e+00 -5.79811e-01
21Feb13_100412|   5.53346e-01 -3.23183e-01 -5.66910e-02  1.05090e+00 -4.89620e-01
21Feb13_100412|  -1.40866e-01]
21Feb13_100412| [-6.85763e-01  4.32546e-01  2.07281e-01  1.86934e-01  1.03855e+00
21Feb13_100412|  -2.61743e-02 -1.45446e+00  2.99914e-01  9.96893e-01  5.16927e-01
21Feb13_100412|  -9.72506e-01]
21Feb13_100412| [ 6.87732e-01  8.12844e-01  3.51990e-01 -1.28179e+00 -1.00846e-02
21Feb13_100412|  -2.28308e-01  1.61447e+00 -2.91772e-01  1.12608e+00  6.13314e-01
21Feb13_100412|  -7.64936e-01]
21Feb13_100412| [ 3.88583e-01  3.89122e-02 -7.32680e-01 -1.74359e-01 -1.04680e+00
21Feb13_100412|   1.41735e+00  3.14067e-01 -1.41835e-01 -5.39265e-01 -8.08813e-01
21Feb13_100412|   6.58712e-01]
21Feb13_100412| [-6.68434e-01 -9.77746e-01  1.42569e+00 -2.64191e-01 -4.41971e-01
21Feb13_100412|   3.89653e-01  1.19610e+00 -1.70441e+00  2.60850e-01 -1.16352e+00
21Feb13_100412|   6.53371e-01]
21Feb13_100412| [ 2.16387e+00  1.21870e+00 -1.34441e-01 -8.61036e-01 -6.09299e-01
21Feb13_100412|   7.85750e-01 -9.41396e-01 -5.31235e-01  4.44708e-02 -5.08207e-01
21Feb13_100412|  -2.45830e+00]
21Feb13_100412| [-8.92729e-01 -2.15613e-01 -3.99405e-01  1.63387e+00 -8.65849e-01
21Feb13_100412|   7.58911e-01  7.49706e-01 -2.11143e+00  1.56748e-01  7.64897e-01
21Feb13_100412|  -1.13879e+00]
21Feb13_100412| [-8.57088e-01 -1.62365e-03  1.26530e+00 -2.22604e+00 -2.28715e+00
21Feb13_100412|  -9.99604e-02 -2.40021e-01  3.35970e-01 -8.82544e-01  4.85761e-01
21Feb13_100412|  -2.24202e+00]
21Feb13_100412| [ 5.52215e-01  8.52156e-02 -2.37466e-01  1.07672e+00  1.54941e+00
21Feb13_100412|   1.99606e-01 -1.34808e+00  7.53511e-01 -5.99088e-01  5.98790e-02
21Feb13_100412|  -1.07950e-01]
21Feb13_100412| [ 2.67109e+00 -1.75176e+00 -6.16214e-01 -1.86800e+00  5.99501e-01
21Feb13_100412|  -1.10529e+00 -2.74849e+00  6.11555e-01  9.78547e-03 -3.97459e-01
21Feb13_100412|   2.92660e-01]
21Feb13_100412| [ 4.54863e-01 -9.09117e-01 -8.30196e-01  1.50206e+00 -1.73504e+00
21Feb13_100412|  -1.30648e+00  5.55948e-01 -7.54174e-01  2.05420e+00  1.38864e+00
21Feb13_100412|   5.29561e-01]
21Feb13_100412| [-4.85366e-01 -3.53531e-01  9.05198e-01  7.65456e-01 -1.64749e+00
21Feb13_100412|   5.69847e-01  2.50378e-01  7.85001e-01 -1.45661e+00  8.34665e-02
21Feb13_100412|   8.15879e-01]
21Feb13_100412| [ 1.25727e+00  2.46577e-01  5.85987e-01  5.77962e-01 -2.59665e-01
21Feb13_100412|  -1.17493e-01  1.60910e+00  9.12990e-01  1.44670e+00  5.22422e-01
21Feb13_100412|  -1.94187e+00]
21Feb13_100412| [ 1.33867e-01 -1.27358e+00 -3.47982e-01 -6.08657e-02 -1.30348e-01
21Feb13_100412|  -1.17219e+00  1.24909e+00 -1.11782e+00  8.64220e-01  5.61000e-01
21Feb13_100412|  -1.48212e+00]
21Feb13_100412| [ 1.78205e+00 -2.50466e-01  1.33657e+00 -1.73845e+00  1.81425e+00
21Feb13_100412|  -8.02280e-01 -1.16246e+00  1.15245e+00 -3.53401e-01  6.57431e-01
21Feb13_100412|   9.30205e-01]
21Feb13_100412| [-3.03807e-01 -5.34010e-01 -5.36033e-02  1.22986e+00 -7.73593e-01
21Feb13_100412|  -2.41838e-02  9.47047e-01  1.63950e+00  8.57850e-01  7.18366e-01
21Feb13_100412|   6.19340e-01]
21Feb13_100412| [-1.56874e+00  9.13052e-01 -1.80219e+00 -6.85706e-02 -1.52747e-01
21Feb13_100412|  -1.23654e+00  7.66763e-01  8.76849e-01  1.38192e+00  1.74758e-01
21Feb13_100412|   9.19395e-01]
21Feb13_100412| [-3.41080e-01 -1.01680e+00 -7.82347e-01  5.72435e-01  1.21957e+00
21Feb13_100412|  -1.70168e+00  1.35596e+00 -1.36994e+00  6.54260e-01  2.17154e+00
21Feb13_100412|  -6.51639e-01]
21Feb13_100412| [-4.25343e-01  1.74798e+00  9.89404e-01 -1.04295e+00 -5.27053e-03
21Feb13_100412|   1.42040e+00  1.70140e+00 -5.47912e-01  2.85277e-01 -3.08635e-01
21Feb13_100412|  -1.87522e+00]
21Feb13_100412| [-2.65662e+00 -2.02900e+00 -1.49073e-01 -1.86322e-01 -6.15986e-01
21Feb13_100412|   1.02607e+00  7.96644e-01 -5.96812e-01  1.99503e-01 -1.24498e+00
21Feb13_100412|   1.01419e+00]
21Feb13_100412| [-1.31259e+00 -4.54363e-01  1.06493e-01  1.22074e+00  1.74518e-01
21Feb13_100412|  -5.57725e-01 -1.40429e+00  6.75301e-01  1.36944e+00 -3.09052e-01
21Feb13_100412|   1.21379e-01]
21Feb13_100412| [-1.66580e+00 -6.50639e-01  5.46120e-01 -1.25566e+00 -5.04851e-01
21Feb13_100412|  -5.49479e-01  1.11882e-01 -4.76139e-01 -4.81819e-01 -1.14210e-01
21Feb13_100412|  -1.57996e+00]
21Feb13_100412| [-7.64196e-01  1.06296e+00 -7.61805e-01 -1.49152e+00  9.36859e-01
21Feb13_100412|  -1.03321e+00 -2.87637e-01 -2.47389e-01  2.61926e-01  8.37227e-01
21Feb13_100412|  -3.42333e-01]
21Feb13_100412| [ 7.46572e-01 -1.58035e+00  8.02182e-01 -5.66302e-01 -8.47290e-01
21Feb13_100412|  -6.34161e-01  1.74178e+00  1.27802e+00  1.67001e+00 -7.94473e-01
21Feb13_100412|   1.10741e+00]
21Feb13_100412| [-6.74261e-01  5.99487e-01 -1.80403e+00 -1.02671e+00 -1.54235e+00
21Feb13_100412|  -1.26515e+00  4.29489e-01  8.21419e-01  1.06895e+00  1.13029e+00
21Feb13_100412|   7.65765e-01]
21Feb13_100412| [ 3.93528e-01 -5.92774e-01  5.40870e-01  9.02092e-01 -1.02404e+00
21Feb13_100412|  -1.10673e+00  2.35611e-01 -1.02808e+00  1.83820e-01  4.85873e-01
21Feb13_100412|  -1.59386e+00]
21Feb13_100412| [ 7.49489e-01 -6.49799e-01  1.34338e+00  2.12189e+00 -7.31882e-01
21Feb13_100412|   5.88080e-01  2.20549e+00 -1.06942e+00 -1.29756e+00 -7.96579e-01
21Feb13_100412|  -5.81803e-01]
21Feb13_100412| [-1.75688e-01  7.50212e-01 -1.37744e+00 -3.66415e-01  8.48990e-01
21Feb13_100412|  -1.88524e-01  1.13690e+00  1.33830e-01 -1.38609e+00 -3.92856e-01
21Feb13_100412|   5.05161e-01]
21Feb13_100412| [-1.56803e-01  6.44681e-01  4.29331e-01 -2.67595e-02  1.86944e+00
21Feb13_100412|   2.86790e+00  6.18832e-02  3.55496e-01  7.56248e-03 -1.48327e+00
21Feb13_100412|  -3.39873e-01]
21Feb13_100412| [-2.54559e-01 -1.85204e+00 -4.10288e-01 -8.81453e-01 -2.11431e-01
21Feb13_100412|   1.19889e+00  1.26373e+00 -6.36870e-01  1.26338e+00  5.36597e-01
21Feb13_100412|   1.31875e-02]
21Feb13_100412| [-6.96596e-02 -5.38534e-01  5.48522e-01  5.84182e-02  6.63353e-01
21Feb13_100412|  -8.82974e-01  8.67865e-01 -4.46778e-01  3.78957e-01 -1.73884e+00
21Feb13_100412|   7.87282e-01]
21Feb13_100412| [-9.53666e-01  9.80083e-01 -2.38978e-01 -1.94127e-01 -1.09625e+00
21Feb13_100412|   6.84617e-01 -1.90861e+00 -1.46974e+00  1.49925e-01 -6.42909e-01
21Feb13_100412|   1.10172e+00]
21Feb13_100412| [ 1.25790e-03  6.28597e-01  5.34003e-01  2.97309e-01  1.63498e+00
21Feb13_100412|   9.24999e-01 -2.69857e-01 -2.42502e+00  4.21238e-01  3.03054e-01
21Feb13_100412|  -3.28666e-01]
21Feb13_100412| [ 4.96081e-01  3.19527e-01  6.41207e-01  2.65925e-01  1.49075e+00
21Feb13_100412|   1.26551e-01 -3.97150e-01  1.17863e-01  3.16032e-01  1.62457e-01
21Feb13_100412|  -1.75157e+00]
21Feb13_100412| [ 1.07827e+00 -6.03883e-01 -1.79069e+00  3.62297e-01  1.72510e-01
21Feb13_100412|   2.07369e-01  2.87312e+00 -1.17485e+00  6.05597e-01 -1.01342e+00
21Feb13_100412|  -1.48620e+00]
21Feb13_100412| [ 2.10119e-01 -1.00618e+00 -1.21833e+00  1.51138e-01 -2.10391e+00
21Feb13_100412|  -9.70180e-01  1.51398e-01  3.86319e-01 -1.29116e+00  7.64629e-01
21Feb13_100412|   1.55391e+00]
21Feb13_100412| [-5.61712e-01  9.73611e-01 -1.11945e+00  6.21880e-02 -1.36018e+00
21Feb13_100412|   6.40626e-01  1.72919e-01 -8.32757e-02 -4.69855e-01  2.27406e+00
21Feb13_100412|   4.90539e-01]
21Feb13_100412| [ 9.10147e-01 -8.16175e-01  8.75446e-01 -5.79670e-01 -7.61116e-01
21Feb13_100412|  -1.51932e+00 -3.06235e-02 -4.15810e-01 -6.32631e-01  1.75909e+00
21Feb13_100412|   2.17078e-01]
21Feb13_100412| [-7.08015e-02  2.82435e+00  1.20172e+00 -2.33629e-01 -1.32451e+00
21Feb13_100412|  -3.79960e-01 -9.94142e-01  5.68075e-01 -2.52394e-02  2.67676e-01
21Feb13_100412|   1.39104e+00]
21Feb13_100412| [ 1.25990e+00  3.83043e-01 -5.14876e-01 -5.66390e-01  6.97171e-01
21Feb13_100412|  -4.78790e-02  1.40391e+00 -1.59839e+00  2.40815e+00 -2.11341e-01
21Feb13_100412|  -6.09598e-01]
21Feb13_100412| [-9.09803e-01  1.21788e+00 -4.90502e-02 -2.38674e+00 -1.07796e+00
21Feb13_100412|   1.50503e+00  9.89401e-01 -7.67240e-02 -2.39136e-01 -1.23826e+00
21Feb13_100412|   9.26134e-02]
21Feb13_100412| [-1.84424e+00 -1.25659e+00  1.59797e+00 -1.15697e+00  1.06948e+00
21Feb13_100412|   4.16988e-01 -6.95885e-01  1.64775e+00  2.71237e-01  1.15771e+00
21Feb13_100412|  -9.32049e-02]
21Feb13_100412| [-5.90352e-01  7.55237e-02 -9.82628e-01  1.09728e+00 -1.32232e+00
21Feb13_100412|  -5.82659e-02  9.41700e-01 -8.22310e-02  1.52491e+00 -8.38811e-01
21Feb13_100412|  -3.71191e-01]
21Feb13_100412| [ 4.89785e-01  7.09934e-01  9.23224e-01 -1.16146e-01 -1.29886e+00
21Feb13_100412|  -8.44858e-01 -8.82313e-01  7.77497e-01  1.31740e+00 -7.86706e-01
21Feb13_100412|  -2.09546e+00]
21Feb13_100412| [-1.73451e+00  7.97409e-01  8.43432e-01 -9.64302e-01  1.37347e+00
21Feb13_100412|  -7.45391e-01  1.70867e-01 -1.36756e+00  5.82947e-01 -8.68562e-01
21Feb13_100412|   1.52281e+00]
21Feb13_100412| [ 4.00468e-01  1.96305e+00  2.45851e+00 -2.24292e-01  1.02207e+00
21Feb13_100412|  -3.21156e-01 -2.24026e-01  8.81373e-01 -4.33565e-01  2.26966e+00
21Feb13_100412|  -6.45783e-01]
21Feb13_100412| [-1.03032e-01  1.48460e+00  3.46312e-01 -1.19882e+00  1.66240e+00
21Feb13_100412|  -3.14884e-01  1.01077e+00 -6.85286e-03 -6.98216e-01 -8.47058e-01
21Feb13_100412|  -5.50347e-01]
21Feb13_100412| [-1.11871e+00 -3.47026e-02 -3.39108e-01 -2.64636e-02 -7.06458e-01
21Feb13_100412|   1.63302e-01  1.31775e+00 -1.90493e+00  7.70172e-01 -1.46652e+00
21Feb13_100412|   7.78757e-01]
21Feb13_100412| [-4.22403e-01  1.77868e+00 -2.99659e-01 -9.52842e-01  4.45016e-01
21Feb13_100412|   1.60657e-01 -2.50497e+00 -7.00889e-01 -9.19795e-01 -8.47184e-01
21Feb13_100412|  -2.65355e-01]
21Feb13_100412| [-7.24223e-01  9.33796e-01  6.35998e-01 -4.00108e-01 -3.21069e-01
21Feb13_100412|  -1.09825e-01  2.10246e+00  4.11840e-01 -1.23415e+00 -6.89791e-01
21Feb13_100412|   2.08588e+00]]
21Feb13_100412|-- Bias --
21Feb13_100412|[-0.37416  0.16993 -0.26367  0.66001 -0.03379  0.80785  0.01432 -0.35067
21Feb13_100412|  0.36146  0.54304 -0.66491]
21Feb13_100412|Layer 1:
21Feb13_100412|-- Config --
21Feb13_100412|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 11], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100412|-- Weights --
21Feb13_100412|[[ 0.46273 -0.52633  0.15311 -0.90421]
21Feb13_100412| [-0.74445  0.54112  0.87680  0.47482]
21Feb13_100412| [-0.26719  0.17345  0.03642 -0.34925]
21Feb13_100412| [-0.58874  0.51152 -0.29307 -0.83212]
21Feb13_100412| [ 0.47815 -0.42503 -0.70618  0.59181]
21Feb13_100412| [-0.41898 -0.52488  0.41435 -0.03709]
21Feb13_100412| [-0.86538 -0.59482 -0.23110  0.07142]
21Feb13_100412| [ 0.14002 -0.88633  0.43298  0.45916]
21Feb13_100412| [-0.13044 -0.48032 -0.74848  0.34067]
21Feb13_100412| [ 0.52895  0.74501  0.12361 -0.14643]
21Feb13_100412| [ 0.58188  0.58465  0.38240  0.65996]]
21Feb13_100412|-- Bias --
21Feb13_100412|[-0.76731  0.51896 -0.80290  0.22809]
21Feb13_100412|Layer 2:
21Feb13_100412|-- Config --
21Feb13_100412|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100412|-- Weights --
21Feb13_100412|[[-1.53127  0.04037]
21Feb13_100412| [ 0.13677 -1.46193]
21Feb13_100412| [-1.11724  0.35367]
21Feb13_100412| [ 0.49422  0.28831]]
21Feb13_100412|-- Bias --
21Feb13_100412|[ 0.11773 -0.60451]
21Feb13_100412|Predicting the validation and test data with the Best final individual.
21Feb13_100419| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_100419|-----------  ------------------  --------------------  ----------
21Feb13_100419|Validation         42.00                  30            0.00000
21Feb13_100419|   Test            36.40                  30            0.00000
21Feb13_100419|-------------------- Test #10 --------------------
21Feb13_100419|Best final individual weights
21Feb13_100419|Individual:
21Feb13_100419|-- Constant hidden layers --
21Feb13_100419|False
21Feb13_100419|Layer 0:
21Feb13_100419|-- Config --
21Feb13_100419|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 11, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100419|-- Weights --
21Feb13_100419|[[-1.06145e+00  8.68922e-01 -1.14379e+00 -1.49459e-01 -5.92039e-01
21Feb13_100419|  -2.35241e-01 -1.40309e+00  2.12924e+00  1.77198e-01  3.19702e-01
21Feb13_100419|  -4.23758e-01]
21Feb13_100419| [-7.60973e-01 -1.69902e+00  5.70321e-01  7.00329e-02  7.06671e-01
21Feb13_100419|   3.27493e-01 -1.70808e+00 -1.16196e+00  9.48272e-02  6.65005e-01
21Feb13_100419|   1.23887e+00]
21Feb13_100419| [-5.76717e-01  4.39987e-01 -4.71900e-01  9.84744e-01 -6.70632e-01
21Feb13_100419|  -8.05147e-02  4.07717e-01  1.82295e+00 -3.65259e-01  2.94562e-02
21Feb13_100419|   4.58511e-01]
21Feb13_100419| [ 1.51511e+00  9.93966e-01  3.08471e-01 -5.70096e-01  8.84235e-02
21Feb13_100419|  -3.23449e-01 -2.17552e-02  1.61666e+00  6.74902e-02 -2.42173e-01
21Feb13_100419|  -1.07711e+00]
21Feb13_100419| [ 7.49020e-01  1.03034e+00  1.53014e+00 -1.66588e+00 -1.34224e-01
21Feb13_100419|   1.92903e+00 -2.20672e+00  1.52629e-01 -9.97077e-01 -4.47184e-01
21Feb13_100419|  -1.17110e+00]
21Feb13_100419| [ 5.15382e-01  1.00118e+00 -1.08350e+00  1.03880e+00 -4.68603e-01
21Feb13_100419|  -4.59197e-02  1.11058e+00  9.17544e-01  1.33730e-01  6.53965e-02
21Feb13_100419|  -1.13911e+00]
21Feb13_100419| [-2.04317e+00 -6.76921e-01  7.78254e-01 -1.17217e+00 -1.67455e+00
21Feb13_100419|  -1.57760e-02  8.21084e-01 -1.13921e-01  7.37767e-01 -2.98292e-01
21Feb13_100419|   2.92646e-01]
21Feb13_100419| [-8.01681e-01 -9.13592e-01 -7.13092e-01  1.16235e+00 -5.79811e-01
21Feb13_100419|   5.53346e-01 -3.23183e-01 -5.66910e-02  1.05090e+00 -4.89620e-01
21Feb13_100419|  -1.40866e-01]
21Feb13_100419| [-6.85763e-01  4.32546e-01  2.07281e-01  1.86934e-01  1.03855e+00
21Feb13_100419|  -2.61743e-02 -1.45446e+00  2.99914e-01  9.96893e-01  5.16927e-01
21Feb13_100419|  -9.72506e-01]
21Feb13_100419| [ 6.87732e-01  8.12844e-01  3.51990e-01 -1.28179e+00 -1.00846e-02
21Feb13_100419|  -2.28308e-01  1.61447e+00 -2.91772e-01  1.12608e+00  6.13314e-01
21Feb13_100419|  -7.64936e-01]
21Feb13_100419| [ 3.88583e-01  3.89122e-02 -7.32680e-01 -1.74359e-01 -1.04680e+00
21Feb13_100419|   1.41735e+00  3.14067e-01 -1.41835e-01 -5.39265e-01 -8.08813e-01
21Feb13_100419|   6.58712e-01]
21Feb13_100419| [-6.68434e-01 -9.77746e-01  1.42569e+00 -2.64191e-01 -4.41971e-01
21Feb13_100419|   3.89653e-01  1.19610e+00 -1.70441e+00  2.60850e-01 -1.16352e+00
21Feb13_100419|   6.53371e-01]
21Feb13_100419| [ 2.16387e+00  1.21870e+00 -1.34441e-01 -8.61036e-01 -6.09299e-01
21Feb13_100419|   7.85750e-01 -9.41396e-01 -5.31235e-01  4.44708e-02 -5.08207e-01
21Feb13_100419|  -2.45830e+00]
21Feb13_100419| [-8.92729e-01 -2.15613e-01 -3.99405e-01  1.63387e+00 -8.65849e-01
21Feb13_100419|   7.58911e-01  7.49706e-01 -2.11143e+00  1.56748e-01  7.64897e-01
21Feb13_100419|  -1.13879e+00]
21Feb13_100419| [-8.57088e-01 -1.62365e-03  1.26530e+00 -2.22604e+00 -2.28715e+00
21Feb13_100419|  -9.99604e-02 -2.40021e-01  3.35970e-01 -8.82544e-01  4.85761e-01
21Feb13_100419|  -2.24202e+00]
21Feb13_100419| [ 5.52215e-01  8.52156e-02 -2.37466e-01  1.07672e+00  1.54941e+00
21Feb13_100419|   1.99606e-01 -1.34808e+00  7.53511e-01 -5.99088e-01  5.98790e-02
21Feb13_100419|  -1.07950e-01]
21Feb13_100419| [ 2.67109e+00 -1.75176e+00 -6.16214e-01 -1.86800e+00  5.99501e-01
21Feb13_100419|  -1.10529e+00 -2.74849e+00  6.11555e-01  9.78547e-03 -3.97459e-01
21Feb13_100419|   2.92660e-01]
21Feb13_100419| [ 4.54863e-01 -9.09117e-01 -8.30196e-01  1.50206e+00 -1.73504e+00
21Feb13_100419|  -1.30648e+00  5.55948e-01 -7.54174e-01  2.05420e+00  1.38864e+00
21Feb13_100419|   5.29561e-01]
21Feb13_100419| [-4.85366e-01 -3.53531e-01  9.05198e-01  7.65456e-01 -1.64749e+00
21Feb13_100419|   5.69847e-01  2.50378e-01  7.85001e-01 -1.45661e+00  8.34665e-02
21Feb13_100419|   8.15879e-01]
21Feb13_100419| [ 1.25727e+00  2.46577e-01  5.85987e-01  5.77962e-01 -2.59665e-01
21Feb13_100419|  -1.17493e-01  1.60910e+00  9.12990e-01  1.44670e+00  5.22422e-01
21Feb13_100419|  -1.94187e+00]
21Feb13_100419| [ 1.33867e-01 -1.27358e+00 -3.47982e-01 -6.08657e-02 -1.30348e-01
21Feb13_100419|  -1.17219e+00  1.24909e+00 -1.11782e+00  8.64220e-01  5.61000e-01
21Feb13_100419|  -1.48212e+00]
21Feb13_100419| [ 1.78205e+00 -2.50466e-01  1.33657e+00 -1.73845e+00  1.81425e+00
21Feb13_100419|  -8.02280e-01 -1.16246e+00  1.15245e+00 -3.53401e-01  6.57431e-01
21Feb13_100419|   9.30205e-01]
21Feb13_100419| [-3.03807e-01 -5.34010e-01 -5.36033e-02  1.22986e+00 -7.73593e-01
21Feb13_100419|  -2.41838e-02  9.47047e-01  1.63950e+00  8.57850e-01  7.18366e-01
21Feb13_100419|   6.19340e-01]
21Feb13_100419| [-1.56874e+00  9.13052e-01 -1.80219e+00 -6.85706e-02 -1.52747e-01
21Feb13_100419|  -1.23654e+00  7.66763e-01  8.76849e-01  1.38192e+00  1.74758e-01
21Feb13_100419|   9.19395e-01]
21Feb13_100419| [-3.41080e-01 -1.01680e+00 -7.82347e-01  5.72435e-01  1.21957e+00
21Feb13_100419|  -1.70168e+00  1.35596e+00 -1.36994e+00  6.54260e-01  2.17154e+00
21Feb13_100419|  -6.51639e-01]
21Feb13_100419| [-4.25343e-01  1.74798e+00  9.89404e-01 -1.04295e+00 -5.27053e-03
21Feb13_100419|   1.42040e+00  1.70140e+00 -5.47912e-01  2.85277e-01 -3.08635e-01
21Feb13_100419|  -1.87522e+00]
21Feb13_100419| [-2.65662e+00 -2.02900e+00 -1.49073e-01 -1.86322e-01 -6.15986e-01
21Feb13_100419|   1.02607e+00  7.96644e-01 -5.96812e-01  1.99503e-01 -1.24498e+00
21Feb13_100419|   1.01419e+00]
21Feb13_100419| [-1.31259e+00 -4.54363e-01  1.06493e-01  1.22074e+00  1.74518e-01
21Feb13_100419|  -5.57725e-01 -1.40429e+00  6.75301e-01  1.36944e+00 -3.09052e-01
21Feb13_100419|   1.21379e-01]
21Feb13_100419| [-1.66580e+00 -6.50639e-01  5.46120e-01 -1.25566e+00 -5.04851e-01
21Feb13_100419|  -5.49479e-01  1.11882e-01 -4.76139e-01 -4.81819e-01 -1.14210e-01
21Feb13_100419|  -1.57996e+00]
21Feb13_100419| [-7.64196e-01  1.06296e+00 -7.61805e-01 -1.49152e+00  9.36859e-01
21Feb13_100419|  -1.03321e+00 -2.87637e-01 -2.47389e-01  2.61926e-01  8.37227e-01
21Feb13_100419|  -3.42333e-01]
21Feb13_100419| [ 7.46572e-01 -1.58035e+00  8.02182e-01 -5.66302e-01 -8.47290e-01
21Feb13_100419|  -6.34161e-01  1.74178e+00  1.27802e+00  1.67001e+00 -7.94473e-01
21Feb13_100419|   1.10741e+00]
21Feb13_100419| [-6.74261e-01  5.99487e-01 -1.80403e+00 -1.02671e+00 -1.54235e+00
21Feb13_100419|  -1.26515e+00  4.29489e-01  8.21419e-01  1.06895e+00  1.13029e+00
21Feb13_100419|   7.65765e-01]
21Feb13_100419| [ 3.93528e-01 -5.92774e-01  5.40870e-01  9.02092e-01 -1.02404e+00
21Feb13_100419|  -1.10673e+00  2.35611e-01 -1.02808e+00  1.83820e-01  4.85873e-01
21Feb13_100419|  -1.59386e+00]
21Feb13_100419| [ 7.49489e-01 -6.49799e-01  1.34338e+00  2.12189e+00 -7.31882e-01
21Feb13_100419|   5.88080e-01  2.20549e+00 -1.06942e+00 -1.29756e+00 -7.96579e-01
21Feb13_100419|  -5.81803e-01]
21Feb13_100419| [-1.75688e-01  7.50212e-01 -1.37744e+00 -3.66415e-01  8.48990e-01
21Feb13_100419|  -1.88524e-01  1.13690e+00  1.33830e-01 -1.38609e+00 -3.92856e-01
21Feb13_100419|   5.05161e-01]
21Feb13_100419| [-1.56803e-01  6.44681e-01  4.29331e-01 -2.67595e-02  1.86944e+00
21Feb13_100419|   2.86790e+00  6.18832e-02  3.55496e-01  7.56248e-03 -1.48327e+00
21Feb13_100419|  -3.39873e-01]
21Feb13_100419| [-2.54559e-01 -1.85204e+00 -4.10288e-01 -8.81453e-01 -2.11431e-01
21Feb13_100419|   1.19889e+00  1.26373e+00 -6.36870e-01  1.26338e+00  5.36597e-01
21Feb13_100419|   1.31875e-02]
21Feb13_100419| [-6.96596e-02 -5.38534e-01  5.48522e-01  5.84182e-02  6.63353e-01
21Feb13_100419|  -8.82974e-01  8.67865e-01 -4.46778e-01  3.78957e-01 -1.73884e+00
21Feb13_100419|   7.87282e-01]
21Feb13_100419| [-9.53666e-01  9.80083e-01 -2.38978e-01 -1.94127e-01 -1.09625e+00
21Feb13_100419|   6.84617e-01 -1.90861e+00 -1.46974e+00  1.49925e-01 -6.42909e-01
21Feb13_100419|   1.10172e+00]
21Feb13_100419| [ 1.25790e-03  6.28597e-01  5.34003e-01  2.97309e-01  1.63498e+00
21Feb13_100419|   9.24999e-01 -2.69857e-01 -2.42502e+00  4.21238e-01  3.03054e-01
21Feb13_100419|  -3.28666e-01]
21Feb13_100419| [ 4.96081e-01  3.19527e-01  6.41207e-01  2.65925e-01  1.49075e+00
21Feb13_100419|   1.26551e-01 -3.97150e-01  1.17863e-01  3.16032e-01  1.62457e-01
21Feb13_100419|  -1.75157e+00]
21Feb13_100419| [ 1.07827e+00 -6.03883e-01 -1.79069e+00  3.62297e-01  1.72510e-01
21Feb13_100419|   2.07369e-01  2.87312e+00 -1.17485e+00  6.05597e-01 -1.01342e+00
21Feb13_100419|  -1.48620e+00]
21Feb13_100419| [ 2.10119e-01 -1.00618e+00 -1.21833e+00  1.51138e-01 -2.10391e+00
21Feb13_100419|  -9.70180e-01  1.51398e-01  3.86319e-01 -1.29116e+00  7.64629e-01
21Feb13_100419|   1.55391e+00]
21Feb13_100419| [-5.61712e-01  9.73611e-01 -1.11945e+00  6.21880e-02 -1.36018e+00
21Feb13_100419|   6.40626e-01  1.72919e-01 -8.32757e-02 -4.69855e-01  2.27406e+00
21Feb13_100419|   4.90539e-01]
21Feb13_100419| [ 9.10147e-01 -8.16175e-01  8.75446e-01 -5.79670e-01 -7.61116e-01
21Feb13_100419|  -1.51932e+00 -3.06235e-02 -4.15810e-01 -6.32631e-01  1.75909e+00
21Feb13_100419|   2.17078e-01]
21Feb13_100419| [-7.08015e-02  2.82435e+00  1.20172e+00 -2.33629e-01 -1.32451e+00
21Feb13_100419|  -3.79960e-01 -9.94142e-01  5.68075e-01 -2.52394e-02  2.67676e-01
21Feb13_100419|   1.39104e+00]
21Feb13_100419| [ 1.25990e+00  3.83043e-01 -5.14876e-01 -5.66390e-01  6.97171e-01
21Feb13_100419|  -4.78790e-02  1.40391e+00 -1.59839e+00  2.40815e+00 -2.11341e-01
21Feb13_100419|  -6.09598e-01]
21Feb13_100419| [-9.09803e-01  1.21788e+00 -4.90502e-02 -2.38674e+00 -1.07796e+00
21Feb13_100419|   1.50503e+00  9.89401e-01 -7.67240e-02 -2.39136e-01 -1.23826e+00
21Feb13_100419|   9.26134e-02]
21Feb13_100419| [-1.84424e+00 -1.25659e+00  1.59797e+00 -1.15697e+00  1.06948e+00
21Feb13_100419|   4.16988e-01 -6.95885e-01  1.64775e+00  2.71237e-01  1.15771e+00
21Feb13_100419|  -9.32049e-02]
21Feb13_100419| [-5.90352e-01  7.55237e-02 -9.82628e-01  1.09728e+00 -1.32232e+00
21Feb13_100419|  -5.82659e-02  9.41700e-01 -8.22310e-02  1.52491e+00 -8.38811e-01
21Feb13_100419|  -3.71191e-01]
21Feb13_100419| [ 4.89785e-01  7.09934e-01  9.23224e-01 -1.16146e-01 -1.29886e+00
21Feb13_100419|  -8.44858e-01 -8.82313e-01  7.77497e-01  1.31740e+00 -7.86706e-01
21Feb13_100419|  -2.09546e+00]
21Feb13_100419| [-1.73451e+00  7.97409e-01  8.43432e-01 -9.64302e-01  1.37347e+00
21Feb13_100419|  -7.45391e-01  1.70867e-01 -1.36756e+00  5.82947e-01 -8.68562e-01
21Feb13_100419|   1.52281e+00]
21Feb13_100419| [ 4.00468e-01  1.96305e+00  2.45851e+00 -2.24292e-01  1.02207e+00
21Feb13_100419|  -3.21156e-01 -2.24026e-01  8.81373e-01 -4.33565e-01  2.26966e+00
21Feb13_100419|  -6.45783e-01]
21Feb13_100419| [-1.03032e-01  1.48460e+00  3.46312e-01 -1.19882e+00  1.66240e+00
21Feb13_100419|  -3.14884e-01  1.01077e+00 -6.85286e-03 -6.98216e-01 -8.47058e-01
21Feb13_100419|  -5.50347e-01]
21Feb13_100419| [-1.11871e+00 -3.47026e-02 -3.39108e-01 -2.64636e-02 -7.06458e-01
21Feb13_100419|   1.63302e-01  1.31775e+00 -1.90493e+00  7.70172e-01 -1.46652e+00
21Feb13_100419|   7.78757e-01]
21Feb13_100419| [-4.22403e-01  1.77868e+00 -2.99659e-01 -9.52842e-01  4.45016e-01
21Feb13_100419|   1.60657e-01 -2.50497e+00 -7.00889e-01 -9.19795e-01 -8.47184e-01
21Feb13_100419|  -2.65355e-01]
21Feb13_100419| [-7.24223e-01  9.33796e-01  6.35998e-01 -4.00108e-01 -3.21069e-01
21Feb13_100419|  -1.09825e-01  2.10246e+00  4.11840e-01 -1.23415e+00 -6.89791e-01
21Feb13_100419|   2.08588e+00]]
21Feb13_100419|-- Bias --
21Feb13_100419|[-0.37416  0.16993 -0.26367  0.66001 -0.03379  0.80785  0.01432 -0.35067
21Feb13_100419|  0.36146  0.54304 -0.66491]
21Feb13_100419|Layer 1:
21Feb13_100419|-- Config --
21Feb13_100419|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 11], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100419|-- Weights --
21Feb13_100419|[[ 0.46273 -0.52633  0.15311 -0.90421]
21Feb13_100419| [-0.74445  0.54112  0.87680  0.47482]
21Feb13_100419| [-0.26719  0.17345  0.03642 -0.34925]
21Feb13_100419| [-0.58874  0.51152 -0.29307 -0.83212]
21Feb13_100419| [ 0.47815 -0.42503 -0.70618  0.59181]
21Feb13_100419| [-0.41898 -0.52488  0.41435 -0.03709]
21Feb13_100419| [-0.86538 -0.59482 -0.23110  0.07142]
21Feb13_100419| [ 0.14002 -0.88633  0.43298  0.45916]
21Feb13_100419| [-0.13044 -0.48032 -0.74848  0.34067]
21Feb13_100419| [ 0.52895  0.74501  0.12361 -0.14643]
21Feb13_100419| [ 0.58188  0.58465  0.38240  0.65996]]
21Feb13_100419|-- Bias --
21Feb13_100419|[-0.76731  0.51896 -0.80290  0.22809]
21Feb13_100419|Layer 2:
21Feb13_100419|-- Config --
21Feb13_100419|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100419|-- Weights --
21Feb13_100419|[[-1.53127  0.04037]
21Feb13_100419| [ 0.13677 -1.46193]
21Feb13_100419| [-1.11724  0.35367]
21Feb13_100419| [ 0.49422  0.28831]]
21Feb13_100419|-- Bias --
21Feb13_100419|[ 0.11773 -0.60451]
21Feb13_100419|Predicting the validation and test data with the Best final individual.
21Feb13_100426| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_100426|-----------  ------------------  --------------------  ----------
21Feb13_100426|Validation         42.00                  30            0.00000
21Feb13_100426|   Test            36.49                  30            0.00298
21Feb13_100426|-------------------- Test #11 --------------------
21Feb13_100426|Best final individual weights
21Feb13_100426|Individual:
21Feb13_100426|-- Constant hidden layers --
21Feb13_100426|False
21Feb13_100426|Layer 0:
21Feb13_100426|-- Config --
21Feb13_100426|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 11, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100426|-- Weights --
21Feb13_100426|[[-1.06145e+00  8.68922e-01 -1.14379e+00 -1.49459e-01 -5.92039e-01
21Feb13_100426|  -2.35241e-01 -1.40309e+00  2.12924e+00  1.77198e-01  3.19702e-01
21Feb13_100426|  -4.23758e-01]
21Feb13_100426| [-7.60973e-01 -1.69902e+00  5.70321e-01  7.00329e-02  7.06671e-01
21Feb13_100426|   3.27493e-01 -1.70808e+00 -1.16196e+00  9.48272e-02  6.65005e-01
21Feb13_100426|   1.23887e+00]
21Feb13_100426| [-5.76717e-01  4.39987e-01 -4.71900e-01  9.84744e-01 -6.70632e-01
21Feb13_100426|  -8.05147e-02  4.07717e-01  1.82295e+00 -3.65259e-01  2.94562e-02
21Feb13_100426|   4.58511e-01]
21Feb13_100426| [ 1.51511e+00  9.93966e-01  3.08471e-01 -5.70096e-01  8.84235e-02
21Feb13_100426|  -3.23449e-01 -2.17552e-02  1.61666e+00  6.74902e-02 -2.42173e-01
21Feb13_100426|  -1.07711e+00]
21Feb13_100426| [ 7.49020e-01  1.03034e+00  1.53014e+00 -1.66588e+00 -1.34224e-01
21Feb13_100426|   1.92903e+00 -2.20672e+00  1.52629e-01 -9.97077e-01 -4.47184e-01
21Feb13_100426|  -1.17110e+00]
21Feb13_100426| [ 5.15382e-01  1.00118e+00 -1.08350e+00  1.03880e+00 -4.68603e-01
21Feb13_100426|  -4.59197e-02  1.11058e+00  9.17544e-01  1.33730e-01  6.53965e-02
21Feb13_100426|  -1.13911e+00]
21Feb13_100426| [-2.04317e+00 -6.76921e-01  7.78254e-01 -1.17217e+00 -1.67455e+00
21Feb13_100426|  -1.57760e-02  8.21084e-01 -1.13921e-01  7.37767e-01 -2.98292e-01
21Feb13_100426|   2.92646e-01]
21Feb13_100426| [-8.01681e-01 -9.13592e-01 -7.13092e-01  1.16235e+00 -5.79811e-01
21Feb13_100426|   5.53346e-01 -3.23183e-01 -5.66910e-02  1.05090e+00 -4.89620e-01
21Feb13_100426|  -1.40866e-01]
21Feb13_100426| [-6.85763e-01  4.32546e-01  2.07281e-01  1.86934e-01  1.03855e+00
21Feb13_100426|  -2.61743e-02 -1.45446e+00  2.99914e-01  9.96893e-01  5.16927e-01
21Feb13_100426|  -9.72506e-01]
21Feb13_100426| [ 6.87732e-01  8.12844e-01  3.51990e-01 -1.28179e+00 -1.00846e-02
21Feb13_100426|  -2.28308e-01  1.61447e+00 -2.91772e-01  1.12608e+00  6.13314e-01
21Feb13_100426|  -7.64936e-01]
21Feb13_100426| [ 3.88583e-01  3.89122e-02 -7.32680e-01 -1.74359e-01 -1.04680e+00
21Feb13_100426|   1.41735e+00  3.14067e-01 -1.41835e-01 -5.39265e-01 -8.08813e-01
21Feb13_100426|   6.58712e-01]
21Feb13_100426| [-6.68434e-01 -9.77746e-01  1.42569e+00 -2.64191e-01 -4.41971e-01
21Feb13_100426|   3.89653e-01  1.19610e+00 -1.70441e+00  2.60850e-01 -1.16352e+00
21Feb13_100426|   6.53371e-01]
21Feb13_100426| [ 2.16387e+00  1.21870e+00 -1.34441e-01 -8.61036e-01 -6.09299e-01
21Feb13_100426|   7.85750e-01 -9.41396e-01 -5.31235e-01  4.44708e-02 -5.08207e-01
21Feb13_100426|  -2.45830e+00]
21Feb13_100426| [-8.92729e-01 -2.15613e-01 -3.99405e-01  1.63387e+00 -8.65849e-01
21Feb13_100426|   7.58911e-01  7.49706e-01 -2.11143e+00  1.56748e-01  7.64897e-01
21Feb13_100426|  -1.13879e+00]
21Feb13_100426| [-8.57088e-01 -1.62365e-03  1.26530e+00 -2.22604e+00 -2.28715e+00
21Feb13_100426|  -9.99604e-02 -2.40021e-01  3.35970e-01 -8.82544e-01  4.85761e-01
21Feb13_100426|  -2.24202e+00]
21Feb13_100426| [ 5.52215e-01  8.52156e-02 -2.37466e-01  1.07672e+00  1.54941e+00
21Feb13_100426|   1.99606e-01 -1.34808e+00  7.53511e-01 -5.99088e-01  5.98790e-02
21Feb13_100426|  -1.07950e-01]
21Feb13_100426| [ 2.67109e+00 -1.75176e+00 -6.16214e-01 -1.86800e+00  5.99501e-01
21Feb13_100426|  -1.10529e+00 -2.74849e+00  6.11555e-01  9.78547e-03 -3.97459e-01
21Feb13_100426|   2.92660e-01]
21Feb13_100426| [ 4.54863e-01 -9.09117e-01 -8.30196e-01  1.50206e+00 -1.73504e+00
21Feb13_100426|  -1.30648e+00  5.55948e-01 -7.54174e-01  2.05420e+00  1.38864e+00
21Feb13_100426|   5.29561e-01]
21Feb13_100426| [-4.85366e-01 -3.53531e-01  9.05198e-01  7.65456e-01 -1.64749e+00
21Feb13_100426|   5.69847e-01  2.50378e-01  7.85001e-01 -1.45661e+00  8.34665e-02
21Feb13_100426|   8.15879e-01]
21Feb13_100426| [ 1.25727e+00  2.46577e-01  5.85987e-01  5.77962e-01 -2.59665e-01
21Feb13_100426|  -1.17493e-01  1.60910e+00  9.12990e-01  1.44670e+00  5.22422e-01
21Feb13_100426|  -1.94187e+00]
21Feb13_100426| [ 1.33867e-01 -1.27358e+00 -3.47982e-01 -6.08657e-02 -1.30348e-01
21Feb13_100426|  -1.17219e+00  1.24909e+00 -1.11782e+00  8.64220e-01  5.61000e-01
21Feb13_100426|  -1.48212e+00]
21Feb13_100426| [ 1.78205e+00 -2.50466e-01  1.33657e+00 -1.73845e+00  1.81425e+00
21Feb13_100426|  -8.02280e-01 -1.16246e+00  1.15245e+00 -3.53401e-01  6.57431e-01
21Feb13_100426|   9.30205e-01]
21Feb13_100426| [-3.03807e-01 -5.34010e-01 -5.36033e-02  1.22986e+00 -7.73593e-01
21Feb13_100426|  -2.41838e-02  9.47047e-01  1.63950e+00  8.57850e-01  7.18366e-01
21Feb13_100426|   6.19340e-01]
21Feb13_100426| [-1.56874e+00  9.13052e-01 -1.80219e+00 -6.85706e-02 -1.52747e-01
21Feb13_100426|  -1.23654e+00  7.66763e-01  8.76849e-01  1.38192e+00  1.74758e-01
21Feb13_100426|   9.19395e-01]
21Feb13_100426| [-3.41080e-01 -1.01680e+00 -7.82347e-01  5.72435e-01  1.21957e+00
21Feb13_100426|  -1.70168e+00  1.35596e+00 -1.36994e+00  6.54260e-01  2.17154e+00
21Feb13_100426|  -6.51639e-01]
21Feb13_100426| [-4.25343e-01  1.74798e+00  9.89404e-01 -1.04295e+00 -5.27053e-03
21Feb13_100426|   1.42040e+00  1.70140e+00 -5.47912e-01  2.85277e-01 -3.08635e-01
21Feb13_100426|  -1.87522e+00]
21Feb13_100426| [-2.65662e+00 -2.02900e+00 -1.49073e-01 -1.86322e-01 -6.15986e-01
21Feb13_100426|   1.02607e+00  7.96644e-01 -5.96812e-01  1.99503e-01 -1.24498e+00
21Feb13_100426|   1.01419e+00]
21Feb13_100426| [-1.31259e+00 -4.54363e-01  1.06493e-01  1.22074e+00  1.74518e-01
21Feb13_100426|  -5.57725e-01 -1.40429e+00  6.75301e-01  1.36944e+00 -3.09052e-01
21Feb13_100426|   1.21379e-01]
21Feb13_100426| [-1.66580e+00 -6.50639e-01  5.46120e-01 -1.25566e+00 -5.04851e-01
21Feb13_100426|  -5.49479e-01  1.11882e-01 -4.76139e-01 -4.81819e-01 -1.14210e-01
21Feb13_100426|  -1.57996e+00]
21Feb13_100426| [-7.64196e-01  1.06296e+00 -7.61805e-01 -1.49152e+00  9.36859e-01
21Feb13_100426|  -1.03321e+00 -2.87637e-01 -2.47389e-01  2.61926e-01  8.37227e-01
21Feb13_100426|  -3.42333e-01]
21Feb13_100426| [ 7.46572e-01 -1.58035e+00  8.02182e-01 -5.66302e-01 -8.47290e-01
21Feb13_100426|  -6.34161e-01  1.74178e+00  1.27802e+00  1.67001e+00 -7.94473e-01
21Feb13_100426|   1.10741e+00]
21Feb13_100426| [-6.74261e-01  5.99487e-01 -1.80403e+00 -1.02671e+00 -1.54235e+00
21Feb13_100426|  -1.26515e+00  4.29489e-01  8.21419e-01  1.06895e+00  1.13029e+00
21Feb13_100426|   7.65765e-01]
21Feb13_100426| [ 3.93528e-01 -5.92774e-01  5.40870e-01  9.02092e-01 -1.02404e+00
21Feb13_100426|  -1.10673e+00  2.35611e-01 -1.02808e+00  1.83820e-01  4.85873e-01
21Feb13_100426|  -1.59386e+00]
21Feb13_100426| [ 7.49489e-01 -6.49799e-01  1.34338e+00  2.12189e+00 -7.31882e-01
21Feb13_100426|   5.88080e-01  2.20549e+00 -1.06942e+00 -1.29756e+00 -7.96579e-01
21Feb13_100426|  -5.81803e-01]
21Feb13_100426| [-1.75688e-01  7.50212e-01 -1.37744e+00 -3.66415e-01  8.48990e-01
21Feb13_100426|  -1.88524e-01  1.13690e+00  1.33830e-01 -1.38609e+00 -3.92856e-01
21Feb13_100426|   5.05161e-01]
21Feb13_100426| [-1.56803e-01  6.44681e-01  4.29331e-01 -2.67595e-02  1.86944e+00
21Feb13_100426|   2.86790e+00  6.18832e-02  3.55496e-01  7.56248e-03 -1.48327e+00
21Feb13_100426|  -3.39873e-01]
21Feb13_100426| [-2.54559e-01 -1.85204e+00 -4.10288e-01 -8.81453e-01 -2.11431e-01
21Feb13_100426|   1.19889e+00  1.26373e+00 -6.36870e-01  1.26338e+00  5.36597e-01
21Feb13_100426|   1.31875e-02]
21Feb13_100426| [-6.96596e-02 -5.38534e-01  5.48522e-01  5.84182e-02  6.63353e-01
21Feb13_100426|  -8.82974e-01  8.67865e-01 -4.46778e-01  3.78957e-01 -1.73884e+00
21Feb13_100426|   7.87282e-01]
21Feb13_100426| [-9.53666e-01  9.80083e-01 -2.38978e-01 -1.94127e-01 -1.09625e+00
21Feb13_100426|   6.84617e-01 -1.90861e+00 -1.46974e+00  1.49925e-01 -6.42909e-01
21Feb13_100426|   1.10172e+00]
21Feb13_100426| [ 1.25790e-03  6.28597e-01  5.34003e-01  2.97309e-01  1.63498e+00
21Feb13_100426|   9.24999e-01 -2.69857e-01 -2.42502e+00  4.21238e-01  3.03054e-01
21Feb13_100426|  -3.28666e-01]
21Feb13_100426| [ 4.96081e-01  3.19527e-01  6.41207e-01  2.65925e-01  1.49075e+00
21Feb13_100426|   1.26551e-01 -3.97150e-01  1.17863e-01  3.16032e-01  1.62457e-01
21Feb13_100426|  -1.75157e+00]
21Feb13_100426| [ 1.07827e+00 -6.03883e-01 -1.79069e+00  3.62297e-01  1.72510e-01
21Feb13_100426|   2.07369e-01  2.87312e+00 -1.17485e+00  6.05597e-01 -1.01342e+00
21Feb13_100426|  -1.48620e+00]
21Feb13_100426| [ 2.10119e-01 -1.00618e+00 -1.21833e+00  1.51138e-01 -2.10391e+00
21Feb13_100426|  -9.70180e-01  1.51398e-01  3.86319e-01 -1.29116e+00  7.64629e-01
21Feb13_100426|   1.55391e+00]
21Feb13_100426| [-5.61712e-01  9.73611e-01 -1.11945e+00  6.21880e-02 -1.36018e+00
21Feb13_100426|   6.40626e-01  1.72919e-01 -8.32757e-02 -4.69855e-01  2.27406e+00
21Feb13_100426|   4.90539e-01]
21Feb13_100426| [ 9.10147e-01 -8.16175e-01  8.75446e-01 -5.79670e-01 -7.61116e-01
21Feb13_100426|  -1.51932e+00 -3.06235e-02 -4.15810e-01 -6.32631e-01  1.75909e+00
21Feb13_100426|   2.17078e-01]
21Feb13_100426| [-7.08015e-02  2.82435e+00  1.20172e+00 -2.33629e-01 -1.32451e+00
21Feb13_100426|  -3.79960e-01 -9.94142e-01  5.68075e-01 -2.52394e-02  2.67676e-01
21Feb13_100426|   1.39104e+00]
21Feb13_100426| [ 1.25990e+00  3.83043e-01 -5.14876e-01 -5.66390e-01  6.97171e-01
21Feb13_100426|  -4.78790e-02  1.40391e+00 -1.59839e+00  2.40815e+00 -2.11341e-01
21Feb13_100426|  -6.09598e-01]
21Feb13_100426| [-9.09803e-01  1.21788e+00 -4.90502e-02 -2.38674e+00 -1.07796e+00
21Feb13_100426|   1.50503e+00  9.89401e-01 -7.67240e-02 -2.39136e-01 -1.23826e+00
21Feb13_100426|   9.26134e-02]
21Feb13_100426| [-1.84424e+00 -1.25659e+00  1.59797e+00 -1.15697e+00  1.06948e+00
21Feb13_100426|   4.16988e-01 -6.95885e-01  1.64775e+00  2.71237e-01  1.15771e+00
21Feb13_100426|  -9.32049e-02]
21Feb13_100426| [-5.90352e-01  7.55237e-02 -9.82628e-01  1.09728e+00 -1.32232e+00
21Feb13_100426|  -5.82659e-02  9.41700e-01 -8.22310e-02  1.52491e+00 -8.38811e-01
21Feb13_100426|  -3.71191e-01]
21Feb13_100426| [ 4.89785e-01  7.09934e-01  9.23224e-01 -1.16146e-01 -1.29886e+00
21Feb13_100426|  -8.44858e-01 -8.82313e-01  7.77497e-01  1.31740e+00 -7.86706e-01
21Feb13_100426|  -2.09546e+00]
21Feb13_100426| [-1.73451e+00  7.97409e-01  8.43432e-01 -9.64302e-01  1.37347e+00
21Feb13_100426|  -7.45391e-01  1.70867e-01 -1.36756e+00  5.82947e-01 -8.68562e-01
21Feb13_100426|   1.52281e+00]
21Feb13_100426| [ 4.00468e-01  1.96305e+00  2.45851e+00 -2.24292e-01  1.02207e+00
21Feb13_100426|  -3.21156e-01 -2.24026e-01  8.81373e-01 -4.33565e-01  2.26966e+00
21Feb13_100426|  -6.45783e-01]
21Feb13_100426| [-1.03032e-01  1.48460e+00  3.46312e-01 -1.19882e+00  1.66240e+00
21Feb13_100426|  -3.14884e-01  1.01077e+00 -6.85286e-03 -6.98216e-01 -8.47058e-01
21Feb13_100426|  -5.50347e-01]
21Feb13_100426| [-1.11871e+00 -3.47026e-02 -3.39108e-01 -2.64636e-02 -7.06458e-01
21Feb13_100426|   1.63302e-01  1.31775e+00 -1.90493e+00  7.70172e-01 -1.46652e+00
21Feb13_100426|   7.78757e-01]
21Feb13_100426| [-4.22403e-01  1.77868e+00 -2.99659e-01 -9.52842e-01  4.45016e-01
21Feb13_100426|   1.60657e-01 -2.50497e+00 -7.00889e-01 -9.19795e-01 -8.47184e-01
21Feb13_100426|  -2.65355e-01]
21Feb13_100426| [-7.24223e-01  9.33796e-01  6.35998e-01 -4.00108e-01 -3.21069e-01
21Feb13_100426|  -1.09825e-01  2.10246e+00  4.11840e-01 -1.23415e+00 -6.89791e-01
21Feb13_100426|   2.08588e+00]]
21Feb13_100426|-- Bias --
21Feb13_100426|[-0.37416  0.16993 -0.26367  0.66001 -0.03379  0.80785  0.01432 -0.35067
21Feb13_100426|  0.36146  0.54304 -0.66491]
21Feb13_100426|Layer 1:
21Feb13_100426|-- Config --
21Feb13_100426|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 11], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100426|-- Weights --
21Feb13_100426|[[ 0.46273 -0.52633  0.15311 -0.90421]
21Feb13_100426| [-0.74445  0.54112  0.87680  0.47482]
21Feb13_100426| [-0.26719  0.17345  0.03642 -0.34925]
21Feb13_100426| [-0.58874  0.51152 -0.29307 -0.83212]
21Feb13_100426| [ 0.47815 -0.42503 -0.70618  0.59181]
21Feb13_100426| [-0.41898 -0.52488  0.41435 -0.03709]
21Feb13_100426| [-0.86538 -0.59482 -0.23110  0.07142]
21Feb13_100426| [ 0.14002 -0.88633  0.43298  0.45916]
21Feb13_100426| [-0.13044 -0.48032 -0.74848  0.34067]
21Feb13_100426| [ 0.52895  0.74501  0.12361 -0.14643]
21Feb13_100426| [ 0.58188  0.58465  0.38240  0.65996]]
21Feb13_100426|-- Bias --
21Feb13_100426|[-0.76731  0.51896 -0.80290  0.22809]
21Feb13_100426|Layer 2:
21Feb13_100426|-- Config --
21Feb13_100426|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100426|-- Weights --
21Feb13_100426|[[-1.53127  0.04037]
21Feb13_100426| [ 0.13677 -1.46193]
21Feb13_100426| [-1.11724  0.35367]
21Feb13_100426| [ 0.49422  0.28831]]
21Feb13_100426|-- Bias --
21Feb13_100426|[ 0.11773 -0.60451]
21Feb13_100426|Predicting the validation and test data with the Best final individual.
21Feb13_100434| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_100434|-----------  ------------------  --------------------  ----------
21Feb13_100434|Validation         42.35                  30            0.00515
21Feb13_100434|   Test            36.40                  30            0.00298
21Feb13_100434|-------------------- Test #12 --------------------
21Feb13_100434|Best final individual weights
21Feb13_100434|Individual:
21Feb13_100434|-- Constant hidden layers --
21Feb13_100434|False
21Feb13_100434|Layer 0:
21Feb13_100434|-- Config --
21Feb13_100434|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 11, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100434|-- Weights --
21Feb13_100434|[[-1.06145e+00  8.68922e-01 -1.14379e+00 -1.49459e-01 -5.92039e-01
21Feb13_100434|  -2.35241e-01 -1.40309e+00  2.12924e+00  1.77198e-01  3.19702e-01
21Feb13_100434|  -4.23758e-01]
21Feb13_100434| [-7.60973e-01 -1.69902e+00  5.70321e-01  7.00329e-02  7.06671e-01
21Feb13_100434|   3.27493e-01 -1.70808e+00 -1.16196e+00  9.48272e-02  6.65005e-01
21Feb13_100434|   1.23887e+00]
21Feb13_100434| [-5.76717e-01  4.39987e-01 -4.71900e-01  9.84744e-01 -6.70632e-01
21Feb13_100434|  -8.05147e-02  4.07717e-01  1.82295e+00 -3.65259e-01  2.94562e-02
21Feb13_100434|   4.58511e-01]
21Feb13_100434| [ 1.51511e+00  9.93966e-01  3.08471e-01 -5.70096e-01  8.84235e-02
21Feb13_100434|  -3.23449e-01 -2.17552e-02  1.61666e+00  6.74902e-02 -2.42173e-01
21Feb13_100434|  -1.07711e+00]
21Feb13_100434| [ 7.49020e-01  1.03034e+00  1.53014e+00 -1.66588e+00 -1.34224e-01
21Feb13_100434|   1.92903e+00 -2.20672e+00  1.52629e-01 -9.97077e-01 -4.47184e-01
21Feb13_100434|  -1.17110e+00]
21Feb13_100434| [ 5.15382e-01  1.00118e+00 -1.08350e+00  1.03880e+00 -4.68603e-01
21Feb13_100434|  -4.59197e-02  1.11058e+00  9.17544e-01  1.33730e-01  6.53965e-02
21Feb13_100434|  -1.13911e+00]
21Feb13_100434| [-2.04317e+00 -6.76921e-01  7.78254e-01 -1.17217e+00 -1.67455e+00
21Feb13_100434|  -1.57760e-02  8.21084e-01 -1.13921e-01  7.37767e-01 -2.98292e-01
21Feb13_100434|   2.92646e-01]
21Feb13_100434| [-8.01681e-01 -9.13592e-01 -7.13092e-01  1.16235e+00 -5.79811e-01
21Feb13_100434|   5.53346e-01 -3.23183e-01 -5.66910e-02  1.05090e+00 -4.89620e-01
21Feb13_100434|  -1.40866e-01]
21Feb13_100434| [-6.85763e-01  4.32546e-01  2.07281e-01  1.86934e-01  1.03855e+00
21Feb13_100434|  -2.61743e-02 -1.45446e+00  2.99914e-01  9.96893e-01  5.16927e-01
21Feb13_100434|  -9.72506e-01]
21Feb13_100434| [ 6.87732e-01  8.12844e-01  3.51990e-01 -1.28179e+00 -1.00846e-02
21Feb13_100434|  -2.28308e-01  1.61447e+00 -2.91772e-01  1.12608e+00  6.13314e-01
21Feb13_100434|  -7.64936e-01]
21Feb13_100434| [ 3.88583e-01  3.89122e-02 -7.32680e-01 -1.74359e-01 -1.04680e+00
21Feb13_100434|   1.41735e+00  3.14067e-01 -1.41835e-01 -5.39265e-01 -8.08813e-01
21Feb13_100434|   6.58712e-01]
21Feb13_100434| [-6.68434e-01 -9.77746e-01  1.42569e+00 -2.64191e-01 -4.41971e-01
21Feb13_100434|   3.89653e-01  1.19610e+00 -1.70441e+00  2.60850e-01 -1.16352e+00
21Feb13_100434|   6.53371e-01]
21Feb13_100434| [ 2.16387e+00  1.21870e+00 -1.34441e-01 -8.61036e-01 -6.09299e-01
21Feb13_100434|   7.85750e-01 -9.41396e-01 -5.31235e-01  4.44708e-02 -5.08207e-01
21Feb13_100434|  -2.45830e+00]
21Feb13_100434| [-8.92729e-01 -2.15613e-01 -3.99405e-01  1.63387e+00 -8.65849e-01
21Feb13_100434|   7.58911e-01  7.49706e-01 -2.11143e+00  1.56748e-01  7.64897e-01
21Feb13_100434|  -1.13879e+00]
21Feb13_100434| [-8.57088e-01 -1.62365e-03  1.26530e+00 -2.22604e+00 -2.28715e+00
21Feb13_100434|  -9.99604e-02 -2.40021e-01  3.35970e-01 -8.82544e-01  4.85761e-01
21Feb13_100434|  -2.24202e+00]
21Feb13_100434| [ 5.52215e-01  8.52156e-02 -2.37466e-01  1.07672e+00  1.54941e+00
21Feb13_100434|   1.99606e-01 -1.34808e+00  7.53511e-01 -5.99088e-01  5.98790e-02
21Feb13_100434|  -1.07950e-01]
21Feb13_100434| [ 2.67109e+00 -1.75176e+00 -6.16214e-01 -1.86800e+00  5.99501e-01
21Feb13_100434|  -1.10529e+00 -2.74849e+00  6.11555e-01  9.78547e-03 -3.97459e-01
21Feb13_100434|   2.92660e-01]
21Feb13_100434| [ 4.54863e-01 -9.09117e-01 -8.30196e-01  1.50206e+00 -1.73504e+00
21Feb13_100434|  -1.30648e+00  5.55948e-01 -7.54174e-01  2.05420e+00  1.38864e+00
21Feb13_100434|   5.29561e-01]
21Feb13_100434| [-4.85366e-01 -3.53531e-01  9.05198e-01  7.65456e-01 -1.64749e+00
21Feb13_100434|   5.69847e-01  2.50378e-01  7.85001e-01 -1.45661e+00  8.34665e-02
21Feb13_100434|   8.15879e-01]
21Feb13_100434| [ 1.25727e+00  2.46577e-01  5.85987e-01  5.77962e-01 -2.59665e-01
21Feb13_100434|  -1.17493e-01  1.60910e+00  9.12990e-01  1.44670e+00  5.22422e-01
21Feb13_100434|  -1.94187e+00]
21Feb13_100434| [ 1.33867e-01 -1.27358e+00 -3.47982e-01 -6.08657e-02 -1.30348e-01
21Feb13_100434|  -1.17219e+00  1.24909e+00 -1.11782e+00  8.64220e-01  5.61000e-01
21Feb13_100434|  -1.48212e+00]
21Feb13_100434| [ 1.78205e+00 -2.50466e-01  1.33657e+00 -1.73845e+00  1.81425e+00
21Feb13_100434|  -8.02280e-01 -1.16246e+00  1.15245e+00 -3.53401e-01  6.57431e-01
21Feb13_100434|   9.30205e-01]
21Feb13_100434| [-3.03807e-01 -5.34010e-01 -5.36033e-02  1.22986e+00 -7.73593e-01
21Feb13_100434|  -2.41838e-02  9.47047e-01  1.63950e+00  8.57850e-01  7.18366e-01
21Feb13_100434|   6.19340e-01]
21Feb13_100434| [-1.56874e+00  9.13052e-01 -1.80219e+00 -6.85706e-02 -1.52747e-01
21Feb13_100434|  -1.23654e+00  7.66763e-01  8.76849e-01  1.38192e+00  1.74758e-01
21Feb13_100434|   9.19395e-01]
21Feb13_100434| [-3.41080e-01 -1.01680e+00 -7.82347e-01  5.72435e-01  1.21957e+00
21Feb13_100434|  -1.70168e+00  1.35596e+00 -1.36994e+00  6.54260e-01  2.17154e+00
21Feb13_100434|  -6.51639e-01]
21Feb13_100434| [-4.25343e-01  1.74798e+00  9.89404e-01 -1.04295e+00 -5.27053e-03
21Feb13_100434|   1.42040e+00  1.70140e+00 -5.47912e-01  2.85277e-01 -3.08635e-01
21Feb13_100434|  -1.87522e+00]
21Feb13_100434| [-2.65662e+00 -2.02900e+00 -1.49073e-01 -1.86322e-01 -6.15986e-01
21Feb13_100434|   1.02607e+00  7.96644e-01 -5.96812e-01  1.99503e-01 -1.24498e+00
21Feb13_100434|   1.01419e+00]
21Feb13_100434| [-1.31259e+00 -4.54363e-01  1.06493e-01  1.22074e+00  1.74518e-01
21Feb13_100434|  -5.57725e-01 -1.40429e+00  6.75301e-01  1.36944e+00 -3.09052e-01
21Feb13_100434|   1.21379e-01]
21Feb13_100434| [-1.66580e+00 -6.50639e-01  5.46120e-01 -1.25566e+00 -5.04851e-01
21Feb13_100434|  -5.49479e-01  1.11882e-01 -4.76139e-01 -4.81819e-01 -1.14210e-01
21Feb13_100434|  -1.57996e+00]
21Feb13_100434| [-7.64196e-01  1.06296e+00 -7.61805e-01 -1.49152e+00  9.36859e-01
21Feb13_100434|  -1.03321e+00 -2.87637e-01 -2.47389e-01  2.61926e-01  8.37227e-01
21Feb13_100434|  -3.42333e-01]
21Feb13_100434| [ 7.46572e-01 -1.58035e+00  8.02182e-01 -5.66302e-01 -8.47290e-01
21Feb13_100434|  -6.34161e-01  1.74178e+00  1.27802e+00  1.67001e+00 -7.94473e-01
21Feb13_100434|   1.10741e+00]
21Feb13_100434| [-6.74261e-01  5.99487e-01 -1.80403e+00 -1.02671e+00 -1.54235e+00
21Feb13_100434|  -1.26515e+00  4.29489e-01  8.21419e-01  1.06895e+00  1.13029e+00
21Feb13_100434|   7.65765e-01]
21Feb13_100434| [ 3.93528e-01 -5.92774e-01  5.40870e-01  9.02092e-01 -1.02404e+00
21Feb13_100434|  -1.10673e+00  2.35611e-01 -1.02808e+00  1.83820e-01  4.85873e-01
21Feb13_100434|  -1.59386e+00]
21Feb13_100434| [ 7.49489e-01 -6.49799e-01  1.34338e+00  2.12189e+00 -7.31882e-01
21Feb13_100434|   5.88080e-01  2.20549e+00 -1.06942e+00 -1.29756e+00 -7.96579e-01
21Feb13_100434|  -5.81803e-01]
21Feb13_100434| [-1.75688e-01  7.50212e-01 -1.37744e+00 -3.66415e-01  8.48990e-01
21Feb13_100434|  -1.88524e-01  1.13690e+00  1.33830e-01 -1.38609e+00 -3.92856e-01
21Feb13_100434|   5.05161e-01]
21Feb13_100434| [-1.56803e-01  6.44681e-01  4.29331e-01 -2.67595e-02  1.86944e+00
21Feb13_100434|   2.86790e+00  6.18832e-02  3.55496e-01  7.56248e-03 -1.48327e+00
21Feb13_100434|  -3.39873e-01]
21Feb13_100434| [-2.54559e-01 -1.85204e+00 -4.10288e-01 -8.81453e-01 -2.11431e-01
21Feb13_100434|   1.19889e+00  1.26373e+00 -6.36870e-01  1.26338e+00  5.36597e-01
21Feb13_100434|   1.31875e-02]
21Feb13_100434| [-6.96596e-02 -5.38534e-01  5.48522e-01  5.84182e-02  6.63353e-01
21Feb13_100434|  -8.82974e-01  8.67865e-01 -4.46778e-01  3.78957e-01 -1.73884e+00
21Feb13_100434|   7.87282e-01]
21Feb13_100434| [-9.53666e-01  9.80083e-01 -2.38978e-01 -1.94127e-01 -1.09625e+00
21Feb13_100434|   6.84617e-01 -1.90861e+00 -1.46974e+00  1.49925e-01 -6.42909e-01
21Feb13_100434|   1.10172e+00]
21Feb13_100434| [ 1.25790e-03  6.28597e-01  5.34003e-01  2.97309e-01  1.63498e+00
21Feb13_100434|   9.24999e-01 -2.69857e-01 -2.42502e+00  4.21238e-01  3.03054e-01
21Feb13_100434|  -3.28666e-01]
21Feb13_100434| [ 4.96081e-01  3.19527e-01  6.41207e-01  2.65925e-01  1.49075e+00
21Feb13_100434|   1.26551e-01 -3.97150e-01  1.17863e-01  3.16032e-01  1.62457e-01
21Feb13_100434|  -1.75157e+00]
21Feb13_100434| [ 1.07827e+00 -6.03883e-01 -1.79069e+00  3.62297e-01  1.72510e-01
21Feb13_100434|   2.07369e-01  2.87312e+00 -1.17485e+00  6.05597e-01 -1.01342e+00
21Feb13_100434|  -1.48620e+00]
21Feb13_100434| [ 2.10119e-01 -1.00618e+00 -1.21833e+00  1.51138e-01 -2.10391e+00
21Feb13_100434|  -9.70180e-01  1.51398e-01  3.86319e-01 -1.29116e+00  7.64629e-01
21Feb13_100434|   1.55391e+00]
21Feb13_100434| [-5.61712e-01  9.73611e-01 -1.11945e+00  6.21880e-02 -1.36018e+00
21Feb13_100434|   6.40626e-01  1.72919e-01 -8.32757e-02 -4.69855e-01  2.27406e+00
21Feb13_100434|   4.90539e-01]
21Feb13_100434| [ 9.10147e-01 -8.16175e-01  8.75446e-01 -5.79670e-01 -7.61116e-01
21Feb13_100434|  -1.51932e+00 -3.06235e-02 -4.15810e-01 -6.32631e-01  1.75909e+00
21Feb13_100434|   2.17078e-01]
21Feb13_100434| [-7.08015e-02  2.82435e+00  1.20172e+00 -2.33629e-01 -1.32451e+00
21Feb13_100434|  -3.79960e-01 -9.94142e-01  5.68075e-01 -2.52394e-02  2.67676e-01
21Feb13_100434|   1.39104e+00]
21Feb13_100434| [ 1.25990e+00  3.83043e-01 -5.14876e-01 -5.66390e-01  6.97171e-01
21Feb13_100434|  -4.78790e-02  1.40391e+00 -1.59839e+00  2.40815e+00 -2.11341e-01
21Feb13_100434|  -6.09598e-01]
21Feb13_100434| [-9.09803e-01  1.21788e+00 -4.90502e-02 -2.38674e+00 -1.07796e+00
21Feb13_100434|   1.50503e+00  9.89401e-01 -7.67240e-02 -2.39136e-01 -1.23826e+00
21Feb13_100434|   9.26134e-02]
21Feb13_100434| [-1.84424e+00 -1.25659e+00  1.59797e+00 -1.15697e+00  1.06948e+00
21Feb13_100434|   4.16988e-01 -6.95885e-01  1.64775e+00  2.71237e-01  1.15771e+00
21Feb13_100434|  -9.32049e-02]
21Feb13_100434| [-5.90352e-01  7.55237e-02 -9.82628e-01  1.09728e+00 -1.32232e+00
21Feb13_100434|  -5.82659e-02  9.41700e-01 -8.22310e-02  1.52491e+00 -8.38811e-01
21Feb13_100434|  -3.71191e-01]
21Feb13_100434| [ 4.89785e-01  7.09934e-01  9.23224e-01 -1.16146e-01 -1.29886e+00
21Feb13_100434|  -8.44858e-01 -8.82313e-01  7.77497e-01  1.31740e+00 -7.86706e-01
21Feb13_100434|  -2.09546e+00]
21Feb13_100434| [-1.73451e+00  7.97409e-01  8.43432e-01 -9.64302e-01  1.37347e+00
21Feb13_100434|  -7.45391e-01  1.70867e-01 -1.36756e+00  5.82947e-01 -8.68562e-01
21Feb13_100434|   1.52281e+00]
21Feb13_100434| [ 4.00468e-01  1.96305e+00  2.45851e+00 -2.24292e-01  1.02207e+00
21Feb13_100434|  -3.21156e-01 -2.24026e-01  8.81373e-01 -4.33565e-01  2.26966e+00
21Feb13_100434|  -6.45783e-01]
21Feb13_100434| [-1.03032e-01  1.48460e+00  3.46312e-01 -1.19882e+00  1.66240e+00
21Feb13_100434|  -3.14884e-01  1.01077e+00 -6.85286e-03 -6.98216e-01 -8.47058e-01
21Feb13_100434|  -5.50347e-01]
21Feb13_100434| [-1.11871e+00 -3.47026e-02 -3.39108e-01 -2.64636e-02 -7.06458e-01
21Feb13_100434|   1.63302e-01  1.31775e+00 -1.90493e+00  7.70172e-01 -1.46652e+00
21Feb13_100434|   7.78757e-01]
21Feb13_100434| [-4.22403e-01  1.77868e+00 -2.99659e-01 -9.52842e-01  4.45016e-01
21Feb13_100434|   1.60657e-01 -2.50497e+00 -7.00889e-01 -9.19795e-01 -8.47184e-01
21Feb13_100434|  -2.65355e-01]
21Feb13_100434| [-7.24223e-01  9.33796e-01  6.35998e-01 -4.00108e-01 -3.21069e-01
21Feb13_100434|  -1.09825e-01  2.10246e+00  4.11840e-01 -1.23415e+00 -6.89791e-01
21Feb13_100434|   2.08588e+00]]
21Feb13_100434|-- Bias --
21Feb13_100434|[-0.37416  0.16993 -0.26367  0.66001 -0.03379  0.80785  0.01432 -0.35067
21Feb13_100434|  0.36146  0.54304 -0.66491]
21Feb13_100434|Layer 1:
21Feb13_100434|-- Config --
21Feb13_100434|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 11], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100434|-- Weights --
21Feb13_100434|[[ 0.46273 -0.52633  0.15311 -0.90421]
21Feb13_100434| [-0.74445  0.54112  0.87680  0.47482]
21Feb13_100434| [-0.26719  0.17345  0.03642 -0.34925]
21Feb13_100434| [-0.58874  0.51152 -0.29307 -0.83212]
21Feb13_100434| [ 0.47815 -0.42503 -0.70618  0.59181]
21Feb13_100434| [-0.41898 -0.52488  0.41435 -0.03709]
21Feb13_100434| [-0.86538 -0.59482 -0.23110  0.07142]
21Feb13_100434| [ 0.14002 -0.88633  0.43298  0.45916]
21Feb13_100434| [-0.13044 -0.48032 -0.74848  0.34067]
21Feb13_100434| [ 0.52895  0.74501  0.12361 -0.14643]
21Feb13_100434| [ 0.58188  0.58465  0.38240  0.65996]]
21Feb13_100434|-- Bias --
21Feb13_100434|[-0.76731  0.51896 -0.80290  0.22809]
21Feb13_100434|Layer 2:
21Feb13_100434|-- Config --
21Feb13_100434|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100434|-- Weights --
21Feb13_100434|[[-1.53127  0.04037]
21Feb13_100434| [ 0.13677 -1.46193]
21Feb13_100434| [-1.11724  0.35367]
21Feb13_100434| [ 0.49422  0.28831]]
21Feb13_100434|-- Bias --
21Feb13_100434|[ 0.11773 -0.60451]
21Feb13_100434|Predicting the validation and test data with the Best final individual.
21Feb13_100441| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_100441|-----------  ------------------  --------------------  ----------
21Feb13_100441|Validation         42.00                  30            0.00000
21Feb13_100441|   Test            36.40                  30            0.00595
21Feb13_100441|-------------------- Test #13 --------------------
21Feb13_100441|Best final individual weights
21Feb13_100441|Individual:
21Feb13_100441|-- Constant hidden layers --
21Feb13_100441|False
21Feb13_100441|Layer 0:
21Feb13_100441|-- Config --
21Feb13_100441|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 11, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100441|-- Weights --
21Feb13_100441|[[-1.06145e+00  8.68922e-01 -1.14379e+00 -1.49459e-01 -5.92039e-01
21Feb13_100441|  -2.35241e-01 -1.40309e+00  2.12924e+00  1.77198e-01  3.19702e-01
21Feb13_100441|  -4.23758e-01]
21Feb13_100441| [-7.60973e-01 -1.69902e+00  5.70321e-01  7.00329e-02  7.06671e-01
21Feb13_100441|   3.27493e-01 -1.70808e+00 -1.16196e+00  9.48272e-02  6.65005e-01
21Feb13_100441|   1.23887e+00]
21Feb13_100441| [-5.76717e-01  4.39987e-01 -4.71900e-01  9.84744e-01 -6.70632e-01
21Feb13_100441|  -8.05147e-02  4.07717e-01  1.82295e+00 -3.65259e-01  2.94562e-02
21Feb13_100441|   4.58511e-01]
21Feb13_100441| [ 1.51511e+00  9.93966e-01  3.08471e-01 -5.70096e-01  8.84235e-02
21Feb13_100441|  -3.23449e-01 -2.17552e-02  1.61666e+00  6.74902e-02 -2.42173e-01
21Feb13_100441|  -1.07711e+00]
21Feb13_100441| [ 7.49020e-01  1.03034e+00  1.53014e+00 -1.66588e+00 -1.34224e-01
21Feb13_100441|   1.92903e+00 -2.20672e+00  1.52629e-01 -9.97077e-01 -4.47184e-01
21Feb13_100441|  -1.17110e+00]
21Feb13_100441| [ 5.15382e-01  1.00118e+00 -1.08350e+00  1.03880e+00 -4.68603e-01
21Feb13_100441|  -4.59197e-02  1.11058e+00  9.17544e-01  1.33730e-01  6.53965e-02
21Feb13_100441|  -1.13911e+00]
21Feb13_100441| [-2.04317e+00 -6.76921e-01  7.78254e-01 -1.17217e+00 -1.67455e+00
21Feb13_100441|  -1.57760e-02  8.21084e-01 -1.13921e-01  7.37767e-01 -2.98292e-01
21Feb13_100441|   2.92646e-01]
21Feb13_100441| [-8.01681e-01 -9.13592e-01 -7.13092e-01  1.16235e+00 -5.79811e-01
21Feb13_100441|   5.53346e-01 -3.23183e-01 -5.66910e-02  1.05090e+00 -4.89620e-01
21Feb13_100441|  -1.40866e-01]
21Feb13_100441| [-6.85763e-01  4.32546e-01  2.07281e-01  1.86934e-01  1.03855e+00
21Feb13_100441|  -2.61743e-02 -1.45446e+00  2.99914e-01  9.96893e-01  5.16927e-01
21Feb13_100441|  -9.72506e-01]
21Feb13_100441| [ 6.87732e-01  8.12844e-01  3.51990e-01 -1.28179e+00 -1.00846e-02
21Feb13_100441|  -2.28308e-01  1.61447e+00 -2.91772e-01  1.12608e+00  6.13314e-01
21Feb13_100441|  -7.64936e-01]
21Feb13_100441| [ 3.88583e-01  3.89122e-02 -7.32680e-01 -1.74359e-01 -1.04680e+00
21Feb13_100441|   1.41735e+00  3.14067e-01 -1.41835e-01 -5.39265e-01 -8.08813e-01
21Feb13_100441|   6.58712e-01]
21Feb13_100441| [-6.68434e-01 -9.77746e-01  1.42569e+00 -2.64191e-01 -4.41971e-01
21Feb13_100441|   3.89653e-01  1.19610e+00 -1.70441e+00  2.60850e-01 -1.16352e+00
21Feb13_100441|   6.53371e-01]
21Feb13_100441| [ 2.16387e+00  1.21870e+00 -1.34441e-01 -8.61036e-01 -6.09299e-01
21Feb13_100441|   7.85750e-01 -9.41396e-01 -5.31235e-01  4.44708e-02 -5.08207e-01
21Feb13_100441|  -2.45830e+00]
21Feb13_100441| [-8.92729e-01 -2.15613e-01 -3.99405e-01  1.63387e+00 -8.65849e-01
21Feb13_100441|   7.58911e-01  7.49706e-01 -2.11143e+00  1.56748e-01  7.64897e-01
21Feb13_100441|  -1.13879e+00]
21Feb13_100441| [-8.57088e-01 -1.62365e-03  1.26530e+00 -2.22604e+00 -2.28715e+00
21Feb13_100441|  -9.99604e-02 -2.40021e-01  3.35970e-01 -8.82544e-01  4.85761e-01
21Feb13_100441|  -2.24202e+00]
21Feb13_100441| [ 5.52215e-01  8.52156e-02 -2.37466e-01  1.07672e+00  1.54941e+00
21Feb13_100441|   1.99606e-01 -1.34808e+00  7.53511e-01 -5.99088e-01  5.98790e-02
21Feb13_100441|  -1.07950e-01]
21Feb13_100441| [ 2.67109e+00 -1.75176e+00 -6.16214e-01 -1.86800e+00  5.99501e-01
21Feb13_100441|  -1.10529e+00 -2.74849e+00  6.11555e-01  9.78547e-03 -3.97459e-01
21Feb13_100441|   2.92660e-01]
21Feb13_100441| [ 4.54863e-01 -9.09117e-01 -8.30196e-01  1.50206e+00 -1.73504e+00
21Feb13_100441|  -1.30648e+00  5.55948e-01 -7.54174e-01  2.05420e+00  1.38864e+00
21Feb13_100441|   5.29561e-01]
21Feb13_100441| [-4.85366e-01 -3.53531e-01  9.05198e-01  7.65456e-01 -1.64749e+00
21Feb13_100441|   5.69847e-01  2.50378e-01  7.85001e-01 -1.45661e+00  8.34665e-02
21Feb13_100441|   8.15879e-01]
21Feb13_100441| [ 1.25727e+00  2.46577e-01  5.85987e-01  5.77962e-01 -2.59665e-01
21Feb13_100441|  -1.17493e-01  1.60910e+00  9.12990e-01  1.44670e+00  5.22422e-01
21Feb13_100441|  -1.94187e+00]
21Feb13_100441| [ 1.33867e-01 -1.27358e+00 -3.47982e-01 -6.08657e-02 -1.30348e-01
21Feb13_100441|  -1.17219e+00  1.24909e+00 -1.11782e+00  8.64220e-01  5.61000e-01
21Feb13_100441|  -1.48212e+00]
21Feb13_100441| [ 1.78205e+00 -2.50466e-01  1.33657e+00 -1.73845e+00  1.81425e+00
21Feb13_100441|  -8.02280e-01 -1.16246e+00  1.15245e+00 -3.53401e-01  6.57431e-01
21Feb13_100441|   9.30205e-01]
21Feb13_100441| [-3.03807e-01 -5.34010e-01 -5.36033e-02  1.22986e+00 -7.73593e-01
21Feb13_100441|  -2.41838e-02  9.47047e-01  1.63950e+00  8.57850e-01  7.18366e-01
21Feb13_100441|   6.19340e-01]
21Feb13_100441| [-1.56874e+00  9.13052e-01 -1.80219e+00 -6.85706e-02 -1.52747e-01
21Feb13_100441|  -1.23654e+00  7.66763e-01  8.76849e-01  1.38192e+00  1.74758e-01
21Feb13_100441|   9.19395e-01]
21Feb13_100441| [-3.41080e-01 -1.01680e+00 -7.82347e-01  5.72435e-01  1.21957e+00
21Feb13_100441|  -1.70168e+00  1.35596e+00 -1.36994e+00  6.54260e-01  2.17154e+00
21Feb13_100441|  -6.51639e-01]
21Feb13_100441| [-4.25343e-01  1.74798e+00  9.89404e-01 -1.04295e+00 -5.27053e-03
21Feb13_100441|   1.42040e+00  1.70140e+00 -5.47912e-01  2.85277e-01 -3.08635e-01
21Feb13_100441|  -1.87522e+00]
21Feb13_100441| [-2.65662e+00 -2.02900e+00 -1.49073e-01 -1.86322e-01 -6.15986e-01
21Feb13_100441|   1.02607e+00  7.96644e-01 -5.96812e-01  1.99503e-01 -1.24498e+00
21Feb13_100441|   1.01419e+00]
21Feb13_100441| [-1.31259e+00 -4.54363e-01  1.06493e-01  1.22074e+00  1.74518e-01
21Feb13_100441|  -5.57725e-01 -1.40429e+00  6.75301e-01  1.36944e+00 -3.09052e-01
21Feb13_100441|   1.21379e-01]
21Feb13_100441| [-1.66580e+00 -6.50639e-01  5.46120e-01 -1.25566e+00 -5.04851e-01
21Feb13_100441|  -5.49479e-01  1.11882e-01 -4.76139e-01 -4.81819e-01 -1.14210e-01
21Feb13_100441|  -1.57996e+00]
21Feb13_100441| [-7.64196e-01  1.06296e+00 -7.61805e-01 -1.49152e+00  9.36859e-01
21Feb13_100441|  -1.03321e+00 -2.87637e-01 -2.47389e-01  2.61926e-01  8.37227e-01
21Feb13_100441|  -3.42333e-01]
21Feb13_100441| [ 7.46572e-01 -1.58035e+00  8.02182e-01 -5.66302e-01 -8.47290e-01
21Feb13_100441|  -6.34161e-01  1.74178e+00  1.27802e+00  1.67001e+00 -7.94473e-01
21Feb13_100441|   1.10741e+00]
21Feb13_100441| [-6.74261e-01  5.99487e-01 -1.80403e+00 -1.02671e+00 -1.54235e+00
21Feb13_100441|  -1.26515e+00  4.29489e-01  8.21419e-01  1.06895e+00  1.13029e+00
21Feb13_100441|   7.65765e-01]
21Feb13_100441| [ 3.93528e-01 -5.92774e-01  5.40870e-01  9.02092e-01 -1.02404e+00
21Feb13_100441|  -1.10673e+00  2.35611e-01 -1.02808e+00  1.83820e-01  4.85873e-01
21Feb13_100441|  -1.59386e+00]
21Feb13_100441| [ 7.49489e-01 -6.49799e-01  1.34338e+00  2.12189e+00 -7.31882e-01
21Feb13_100441|   5.88080e-01  2.20549e+00 -1.06942e+00 -1.29756e+00 -7.96579e-01
21Feb13_100441|  -5.81803e-01]
21Feb13_100441| [-1.75688e-01  7.50212e-01 -1.37744e+00 -3.66415e-01  8.48990e-01
21Feb13_100441|  -1.88524e-01  1.13690e+00  1.33830e-01 -1.38609e+00 -3.92856e-01
21Feb13_100441|   5.05161e-01]
21Feb13_100441| [-1.56803e-01  6.44681e-01  4.29331e-01 -2.67595e-02  1.86944e+00
21Feb13_100441|   2.86790e+00  6.18832e-02  3.55496e-01  7.56248e-03 -1.48327e+00
21Feb13_100441|  -3.39873e-01]
21Feb13_100441| [-2.54559e-01 -1.85204e+00 -4.10288e-01 -8.81453e-01 -2.11431e-01
21Feb13_100441|   1.19889e+00  1.26373e+00 -6.36870e-01  1.26338e+00  5.36597e-01
21Feb13_100441|   1.31875e-02]
21Feb13_100441| [-6.96596e-02 -5.38534e-01  5.48522e-01  5.84182e-02  6.63353e-01
21Feb13_100441|  -8.82974e-01  8.67865e-01 -4.46778e-01  3.78957e-01 -1.73884e+00
21Feb13_100441|   7.87282e-01]
21Feb13_100441| [-9.53666e-01  9.80083e-01 -2.38978e-01 -1.94127e-01 -1.09625e+00
21Feb13_100441|   6.84617e-01 -1.90861e+00 -1.46974e+00  1.49925e-01 -6.42909e-01
21Feb13_100441|   1.10172e+00]
21Feb13_100441| [ 1.25790e-03  6.28597e-01  5.34003e-01  2.97309e-01  1.63498e+00
21Feb13_100441|   9.24999e-01 -2.69857e-01 -2.42502e+00  4.21238e-01  3.03054e-01
21Feb13_100441|  -3.28666e-01]
21Feb13_100441| [ 4.96081e-01  3.19527e-01  6.41207e-01  2.65925e-01  1.49075e+00
21Feb13_100441|   1.26551e-01 -3.97150e-01  1.17863e-01  3.16032e-01  1.62457e-01
21Feb13_100441|  -1.75157e+00]
21Feb13_100441| [ 1.07827e+00 -6.03883e-01 -1.79069e+00  3.62297e-01  1.72510e-01
21Feb13_100441|   2.07369e-01  2.87312e+00 -1.17485e+00  6.05597e-01 -1.01342e+00
21Feb13_100441|  -1.48620e+00]
21Feb13_100441| [ 2.10119e-01 -1.00618e+00 -1.21833e+00  1.51138e-01 -2.10391e+00
21Feb13_100441|  -9.70180e-01  1.51398e-01  3.86319e-01 -1.29116e+00  7.64629e-01
21Feb13_100441|   1.55391e+00]
21Feb13_100441| [-5.61712e-01  9.73611e-01 -1.11945e+00  6.21880e-02 -1.36018e+00
21Feb13_100441|   6.40626e-01  1.72919e-01 -8.32757e-02 -4.69855e-01  2.27406e+00
21Feb13_100441|   4.90539e-01]
21Feb13_100441| [ 9.10147e-01 -8.16175e-01  8.75446e-01 -5.79670e-01 -7.61116e-01
21Feb13_100441|  -1.51932e+00 -3.06235e-02 -4.15810e-01 -6.32631e-01  1.75909e+00
21Feb13_100441|   2.17078e-01]
21Feb13_100441| [-7.08015e-02  2.82435e+00  1.20172e+00 -2.33629e-01 -1.32451e+00
21Feb13_100441|  -3.79960e-01 -9.94142e-01  5.68075e-01 -2.52394e-02  2.67676e-01
21Feb13_100441|   1.39104e+00]
21Feb13_100441| [ 1.25990e+00  3.83043e-01 -5.14876e-01 -5.66390e-01  6.97171e-01
21Feb13_100441|  -4.78790e-02  1.40391e+00 -1.59839e+00  2.40815e+00 -2.11341e-01
21Feb13_100441|  -6.09598e-01]
21Feb13_100441| [-9.09803e-01  1.21788e+00 -4.90502e-02 -2.38674e+00 -1.07796e+00
21Feb13_100441|   1.50503e+00  9.89401e-01 -7.67240e-02 -2.39136e-01 -1.23826e+00
21Feb13_100441|   9.26134e-02]
21Feb13_100441| [-1.84424e+00 -1.25659e+00  1.59797e+00 -1.15697e+00  1.06948e+00
21Feb13_100441|   4.16988e-01 -6.95885e-01  1.64775e+00  2.71237e-01  1.15771e+00
21Feb13_100441|  -9.32049e-02]
21Feb13_100441| [-5.90352e-01  7.55237e-02 -9.82628e-01  1.09728e+00 -1.32232e+00
21Feb13_100441|  -5.82659e-02  9.41700e-01 -8.22310e-02  1.52491e+00 -8.38811e-01
21Feb13_100441|  -3.71191e-01]
21Feb13_100441| [ 4.89785e-01  7.09934e-01  9.23224e-01 -1.16146e-01 -1.29886e+00
21Feb13_100441|  -8.44858e-01 -8.82313e-01  7.77497e-01  1.31740e+00 -7.86706e-01
21Feb13_100441|  -2.09546e+00]
21Feb13_100441| [-1.73451e+00  7.97409e-01  8.43432e-01 -9.64302e-01  1.37347e+00
21Feb13_100441|  -7.45391e-01  1.70867e-01 -1.36756e+00  5.82947e-01 -8.68562e-01
21Feb13_100441|   1.52281e+00]
21Feb13_100441| [ 4.00468e-01  1.96305e+00  2.45851e+00 -2.24292e-01  1.02207e+00
21Feb13_100441|  -3.21156e-01 -2.24026e-01  8.81373e-01 -4.33565e-01  2.26966e+00
21Feb13_100441|  -6.45783e-01]
21Feb13_100441| [-1.03032e-01  1.48460e+00  3.46312e-01 -1.19882e+00  1.66240e+00
21Feb13_100441|  -3.14884e-01  1.01077e+00 -6.85286e-03 -6.98216e-01 -8.47058e-01
21Feb13_100441|  -5.50347e-01]
21Feb13_100441| [-1.11871e+00 -3.47026e-02 -3.39108e-01 -2.64636e-02 -7.06458e-01
21Feb13_100441|   1.63302e-01  1.31775e+00 -1.90493e+00  7.70172e-01 -1.46652e+00
21Feb13_100441|   7.78757e-01]
21Feb13_100441| [-4.22403e-01  1.77868e+00 -2.99659e-01 -9.52842e-01  4.45016e-01
21Feb13_100441|   1.60657e-01 -2.50497e+00 -7.00889e-01 -9.19795e-01 -8.47184e-01
21Feb13_100441|  -2.65355e-01]
21Feb13_100441| [-7.24223e-01  9.33796e-01  6.35998e-01 -4.00108e-01 -3.21069e-01
21Feb13_100441|  -1.09825e-01  2.10246e+00  4.11840e-01 -1.23415e+00 -6.89791e-01
21Feb13_100441|   2.08588e+00]]
21Feb13_100441|-- Bias --
21Feb13_100441|[-0.37416  0.16993 -0.26367  0.66001 -0.03379  0.80785  0.01432 -0.35067
21Feb13_100441|  0.36146  0.54304 -0.66491]
21Feb13_100441|Layer 1:
21Feb13_100441|-- Config --
21Feb13_100441|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 11], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100441|-- Weights --
21Feb13_100441|[[ 0.46273 -0.52633  0.15311 -0.90421]
21Feb13_100441| [-0.74445  0.54112  0.87680  0.47482]
21Feb13_100441| [-0.26719  0.17345  0.03642 -0.34925]
21Feb13_100441| [-0.58874  0.51152 -0.29307 -0.83212]
21Feb13_100441| [ 0.47815 -0.42503 -0.70618  0.59181]
21Feb13_100441| [-0.41898 -0.52488  0.41435 -0.03709]
21Feb13_100441| [-0.86538 -0.59482 -0.23110  0.07142]
21Feb13_100441| [ 0.14002 -0.88633  0.43298  0.45916]
21Feb13_100441| [-0.13044 -0.48032 -0.74848  0.34067]
21Feb13_100441| [ 0.52895  0.74501  0.12361 -0.14643]
21Feb13_100441| [ 0.58188  0.58465  0.38240  0.65996]]
21Feb13_100441|-- Bias --
21Feb13_100441|[-0.76731  0.51896 -0.80290  0.22809]
21Feb13_100441|Layer 2:
21Feb13_100441|-- Config --
21Feb13_100441|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100441|-- Weights --
21Feb13_100441|[[-1.53127  0.04037]
21Feb13_100441| [ 0.13677 -1.46193]
21Feb13_100441| [-1.11724  0.35367]
21Feb13_100441| [ 0.49422  0.28831]]
21Feb13_100441|-- Bias --
21Feb13_100441|[ 0.11773 -0.60451]
21Feb13_100441|Predicting the validation and test data with the Best final individual.
21Feb13_100448| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_100448|-----------  ------------------  --------------------  ----------
21Feb13_100448|Validation         42.17                  30            0.00000
21Feb13_100448|   Test            36.32                  30            0.00298
21Feb13_100448|-------------------- Test #14 --------------------
21Feb13_100448|Best final individual weights
21Feb13_100448|Individual:
21Feb13_100448|-- Constant hidden layers --
21Feb13_100448|False
21Feb13_100448|Layer 0:
21Feb13_100448|-- Config --
21Feb13_100448|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 11, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100448|-- Weights --
21Feb13_100448|[[-1.06145e+00  8.68922e-01 -1.14379e+00 -1.49459e-01 -5.92039e-01
21Feb13_100448|  -2.35241e-01 -1.40309e+00  2.12924e+00  1.77198e-01  3.19702e-01
21Feb13_100448|  -4.23758e-01]
21Feb13_100448| [-7.60973e-01 -1.69902e+00  5.70321e-01  7.00329e-02  7.06671e-01
21Feb13_100448|   3.27493e-01 -1.70808e+00 -1.16196e+00  9.48272e-02  6.65005e-01
21Feb13_100448|   1.23887e+00]
21Feb13_100448| [-5.76717e-01  4.39987e-01 -4.71900e-01  9.84744e-01 -6.70632e-01
21Feb13_100448|  -8.05147e-02  4.07717e-01  1.82295e+00 -3.65259e-01  2.94562e-02
21Feb13_100448|   4.58511e-01]
21Feb13_100448| [ 1.51511e+00  9.93966e-01  3.08471e-01 -5.70096e-01  8.84235e-02
21Feb13_100448|  -3.23449e-01 -2.17552e-02  1.61666e+00  6.74902e-02 -2.42173e-01
21Feb13_100448|  -1.07711e+00]
21Feb13_100448| [ 7.49020e-01  1.03034e+00  1.53014e+00 -1.66588e+00 -1.34224e-01
21Feb13_100448|   1.92903e+00 -2.20672e+00  1.52629e-01 -9.97077e-01 -4.47184e-01
21Feb13_100448|  -1.17110e+00]
21Feb13_100448| [ 5.15382e-01  1.00118e+00 -1.08350e+00  1.03880e+00 -4.68603e-01
21Feb13_100448|  -4.59197e-02  1.11058e+00  9.17544e-01  1.33730e-01  6.53965e-02
21Feb13_100448|  -1.13911e+00]
21Feb13_100448| [-2.04317e+00 -6.76921e-01  7.78254e-01 -1.17217e+00 -1.67455e+00
21Feb13_100448|  -1.57760e-02  8.21084e-01 -1.13921e-01  7.37767e-01 -2.98292e-01
21Feb13_100448|   2.92646e-01]
21Feb13_100448| [-8.01681e-01 -9.13592e-01 -7.13092e-01  1.16235e+00 -5.79811e-01
21Feb13_100448|   5.53346e-01 -3.23183e-01 -5.66910e-02  1.05090e+00 -4.89620e-01
21Feb13_100448|  -1.40866e-01]
21Feb13_100448| [-6.85763e-01  4.32546e-01  2.07281e-01  1.86934e-01  1.03855e+00
21Feb13_100448|  -2.61743e-02 -1.45446e+00  2.99914e-01  9.96893e-01  5.16927e-01
21Feb13_100448|  -9.72506e-01]
21Feb13_100448| [ 6.87732e-01  8.12844e-01  3.51990e-01 -1.28179e+00 -1.00846e-02
21Feb13_100448|  -2.28308e-01  1.61447e+00 -2.91772e-01  1.12608e+00  6.13314e-01
21Feb13_100448|  -7.64936e-01]
21Feb13_100448| [ 3.88583e-01  3.89122e-02 -7.32680e-01 -1.74359e-01 -1.04680e+00
21Feb13_100448|   1.41735e+00  3.14067e-01 -1.41835e-01 -5.39265e-01 -8.08813e-01
21Feb13_100448|   6.58712e-01]
21Feb13_100448| [-6.68434e-01 -9.77746e-01  1.42569e+00 -2.64191e-01 -4.41971e-01
21Feb13_100448|   3.89653e-01  1.19610e+00 -1.70441e+00  2.60850e-01 -1.16352e+00
21Feb13_100448|   6.53371e-01]
21Feb13_100448| [ 2.16387e+00  1.21870e+00 -1.34441e-01 -8.61036e-01 -6.09299e-01
21Feb13_100448|   7.85750e-01 -9.41396e-01 -5.31235e-01  4.44708e-02 -5.08207e-01
21Feb13_100448|  -2.45830e+00]
21Feb13_100448| [-8.92729e-01 -2.15613e-01 -3.99405e-01  1.63387e+00 -8.65849e-01
21Feb13_100448|   7.58911e-01  7.49706e-01 -2.11143e+00  1.56748e-01  7.64897e-01
21Feb13_100448|  -1.13879e+00]
21Feb13_100448| [-8.57088e-01 -1.62365e-03  1.26530e+00 -2.22604e+00 -2.28715e+00
21Feb13_100448|  -9.99604e-02 -2.40021e-01  3.35970e-01 -8.82544e-01  4.85761e-01
21Feb13_100448|  -2.24202e+00]
21Feb13_100448| [ 5.52215e-01  8.52156e-02 -2.37466e-01  1.07672e+00  1.54941e+00
21Feb13_100448|   1.99606e-01 -1.34808e+00  7.53511e-01 -5.99088e-01  5.98790e-02
21Feb13_100448|  -1.07950e-01]
21Feb13_100448| [ 2.67109e+00 -1.75176e+00 -6.16214e-01 -1.86800e+00  5.99501e-01
21Feb13_100448|  -1.10529e+00 -2.74849e+00  6.11555e-01  9.78547e-03 -3.97459e-01
21Feb13_100448|   2.92660e-01]
21Feb13_100448| [ 4.54863e-01 -9.09117e-01 -8.30196e-01  1.50206e+00 -1.73504e+00
21Feb13_100448|  -1.30648e+00  5.55948e-01 -7.54174e-01  2.05420e+00  1.38864e+00
21Feb13_100448|   5.29561e-01]
21Feb13_100448| [-4.85366e-01 -3.53531e-01  9.05198e-01  7.65456e-01 -1.64749e+00
21Feb13_100448|   5.69847e-01  2.50378e-01  7.85001e-01 -1.45661e+00  8.34665e-02
21Feb13_100448|   8.15879e-01]
21Feb13_100448| [ 1.25727e+00  2.46577e-01  5.85987e-01  5.77962e-01 -2.59665e-01
21Feb13_100448|  -1.17493e-01  1.60910e+00  9.12990e-01  1.44670e+00  5.22422e-01
21Feb13_100448|  -1.94187e+00]
21Feb13_100448| [ 1.33867e-01 -1.27358e+00 -3.47982e-01 -6.08657e-02 -1.30348e-01
21Feb13_100448|  -1.17219e+00  1.24909e+00 -1.11782e+00  8.64220e-01  5.61000e-01
21Feb13_100448|  -1.48212e+00]
21Feb13_100448| [ 1.78205e+00 -2.50466e-01  1.33657e+00 -1.73845e+00  1.81425e+00
21Feb13_100448|  -8.02280e-01 -1.16246e+00  1.15245e+00 -3.53401e-01  6.57431e-01
21Feb13_100448|   9.30205e-01]
21Feb13_100448| [-3.03807e-01 -5.34010e-01 -5.36033e-02  1.22986e+00 -7.73593e-01
21Feb13_100448|  -2.41838e-02  9.47047e-01  1.63950e+00  8.57850e-01  7.18366e-01
21Feb13_100448|   6.19340e-01]
21Feb13_100448| [-1.56874e+00  9.13052e-01 -1.80219e+00 -6.85706e-02 -1.52747e-01
21Feb13_100448|  -1.23654e+00  7.66763e-01  8.76849e-01  1.38192e+00  1.74758e-01
21Feb13_100448|   9.19395e-01]
21Feb13_100448| [-3.41080e-01 -1.01680e+00 -7.82347e-01  5.72435e-01  1.21957e+00
21Feb13_100448|  -1.70168e+00  1.35596e+00 -1.36994e+00  6.54260e-01  2.17154e+00
21Feb13_100448|  -6.51639e-01]
21Feb13_100448| [-4.25343e-01  1.74798e+00  9.89404e-01 -1.04295e+00 -5.27053e-03
21Feb13_100448|   1.42040e+00  1.70140e+00 -5.47912e-01  2.85277e-01 -3.08635e-01
21Feb13_100448|  -1.87522e+00]
21Feb13_100448| [-2.65662e+00 -2.02900e+00 -1.49073e-01 -1.86322e-01 -6.15986e-01
21Feb13_100448|   1.02607e+00  7.96644e-01 -5.96812e-01  1.99503e-01 -1.24498e+00
21Feb13_100448|   1.01419e+00]
21Feb13_100448| [-1.31259e+00 -4.54363e-01  1.06493e-01  1.22074e+00  1.74518e-01
21Feb13_100448|  -5.57725e-01 -1.40429e+00  6.75301e-01  1.36944e+00 -3.09052e-01
21Feb13_100448|   1.21379e-01]
21Feb13_100448| [-1.66580e+00 -6.50639e-01  5.46120e-01 -1.25566e+00 -5.04851e-01
21Feb13_100448|  -5.49479e-01  1.11882e-01 -4.76139e-01 -4.81819e-01 -1.14210e-01
21Feb13_100448|  -1.57996e+00]
21Feb13_100448| [-7.64196e-01  1.06296e+00 -7.61805e-01 -1.49152e+00  9.36859e-01
21Feb13_100448|  -1.03321e+00 -2.87637e-01 -2.47389e-01  2.61926e-01  8.37227e-01
21Feb13_100448|  -3.42333e-01]
21Feb13_100448| [ 7.46572e-01 -1.58035e+00  8.02182e-01 -5.66302e-01 -8.47290e-01
21Feb13_100448|  -6.34161e-01  1.74178e+00  1.27802e+00  1.67001e+00 -7.94473e-01
21Feb13_100448|   1.10741e+00]
21Feb13_100448| [-6.74261e-01  5.99487e-01 -1.80403e+00 -1.02671e+00 -1.54235e+00
21Feb13_100448|  -1.26515e+00  4.29489e-01  8.21419e-01  1.06895e+00  1.13029e+00
21Feb13_100448|   7.65765e-01]
21Feb13_100448| [ 3.93528e-01 -5.92774e-01  5.40870e-01  9.02092e-01 -1.02404e+00
21Feb13_100448|  -1.10673e+00  2.35611e-01 -1.02808e+00  1.83820e-01  4.85873e-01
21Feb13_100448|  -1.59386e+00]
21Feb13_100448| [ 7.49489e-01 -6.49799e-01  1.34338e+00  2.12189e+00 -7.31882e-01
21Feb13_100448|   5.88080e-01  2.20549e+00 -1.06942e+00 -1.29756e+00 -7.96579e-01
21Feb13_100448|  -5.81803e-01]
21Feb13_100448| [-1.75688e-01  7.50212e-01 -1.37744e+00 -3.66415e-01  8.48990e-01
21Feb13_100448|  -1.88524e-01  1.13690e+00  1.33830e-01 -1.38609e+00 -3.92856e-01
21Feb13_100448|   5.05161e-01]
21Feb13_100448| [-1.56803e-01  6.44681e-01  4.29331e-01 -2.67595e-02  1.86944e+00
21Feb13_100448|   2.86790e+00  6.18832e-02  3.55496e-01  7.56248e-03 -1.48327e+00
21Feb13_100448|  -3.39873e-01]
21Feb13_100448| [-2.54559e-01 -1.85204e+00 -4.10288e-01 -8.81453e-01 -2.11431e-01
21Feb13_100448|   1.19889e+00  1.26373e+00 -6.36870e-01  1.26338e+00  5.36597e-01
21Feb13_100448|   1.31875e-02]
21Feb13_100448| [-6.96596e-02 -5.38534e-01  5.48522e-01  5.84182e-02  6.63353e-01
21Feb13_100448|  -8.82974e-01  8.67865e-01 -4.46778e-01  3.78957e-01 -1.73884e+00
21Feb13_100448|   7.87282e-01]
21Feb13_100448| [-9.53666e-01  9.80083e-01 -2.38978e-01 -1.94127e-01 -1.09625e+00
21Feb13_100448|   6.84617e-01 -1.90861e+00 -1.46974e+00  1.49925e-01 -6.42909e-01
21Feb13_100448|   1.10172e+00]
21Feb13_100448| [ 1.25790e-03  6.28597e-01  5.34003e-01  2.97309e-01  1.63498e+00
21Feb13_100448|   9.24999e-01 -2.69857e-01 -2.42502e+00  4.21238e-01  3.03054e-01
21Feb13_100448|  -3.28666e-01]
21Feb13_100448| [ 4.96081e-01  3.19527e-01  6.41207e-01  2.65925e-01  1.49075e+00
21Feb13_100448|   1.26551e-01 -3.97150e-01  1.17863e-01  3.16032e-01  1.62457e-01
21Feb13_100448|  -1.75157e+00]
21Feb13_100448| [ 1.07827e+00 -6.03883e-01 -1.79069e+00  3.62297e-01  1.72510e-01
21Feb13_100448|   2.07369e-01  2.87312e+00 -1.17485e+00  6.05597e-01 -1.01342e+00
21Feb13_100448|  -1.48620e+00]
21Feb13_100448| [ 2.10119e-01 -1.00618e+00 -1.21833e+00  1.51138e-01 -2.10391e+00
21Feb13_100448|  -9.70180e-01  1.51398e-01  3.86319e-01 -1.29116e+00  7.64629e-01
21Feb13_100448|   1.55391e+00]
21Feb13_100448| [-5.61712e-01  9.73611e-01 -1.11945e+00  6.21880e-02 -1.36018e+00
21Feb13_100448|   6.40626e-01  1.72919e-01 -8.32757e-02 -4.69855e-01  2.27406e+00
21Feb13_100448|   4.90539e-01]
21Feb13_100448| [ 9.10147e-01 -8.16175e-01  8.75446e-01 -5.79670e-01 -7.61116e-01
21Feb13_100448|  -1.51932e+00 -3.06235e-02 -4.15810e-01 -6.32631e-01  1.75909e+00
21Feb13_100448|   2.17078e-01]
21Feb13_100448| [-7.08015e-02  2.82435e+00  1.20172e+00 -2.33629e-01 -1.32451e+00
21Feb13_100448|  -3.79960e-01 -9.94142e-01  5.68075e-01 -2.52394e-02  2.67676e-01
21Feb13_100448|   1.39104e+00]
21Feb13_100448| [ 1.25990e+00  3.83043e-01 -5.14876e-01 -5.66390e-01  6.97171e-01
21Feb13_100448|  -4.78790e-02  1.40391e+00 -1.59839e+00  2.40815e+00 -2.11341e-01
21Feb13_100448|  -6.09598e-01]
21Feb13_100448| [-9.09803e-01  1.21788e+00 -4.90502e-02 -2.38674e+00 -1.07796e+00
21Feb13_100448|   1.50503e+00  9.89401e-01 -7.67240e-02 -2.39136e-01 -1.23826e+00
21Feb13_100448|   9.26134e-02]
21Feb13_100448| [-1.84424e+00 -1.25659e+00  1.59797e+00 -1.15697e+00  1.06948e+00
21Feb13_100448|   4.16988e-01 -6.95885e-01  1.64775e+00  2.71237e-01  1.15771e+00
21Feb13_100448|  -9.32049e-02]
21Feb13_100448| [-5.90352e-01  7.55237e-02 -9.82628e-01  1.09728e+00 -1.32232e+00
21Feb13_100448|  -5.82659e-02  9.41700e-01 -8.22310e-02  1.52491e+00 -8.38811e-01
21Feb13_100448|  -3.71191e-01]
21Feb13_100448| [ 4.89785e-01  7.09934e-01  9.23224e-01 -1.16146e-01 -1.29886e+00
21Feb13_100448|  -8.44858e-01 -8.82313e-01  7.77497e-01  1.31740e+00 -7.86706e-01
21Feb13_100448|  -2.09546e+00]
21Feb13_100448| [-1.73451e+00  7.97409e-01  8.43432e-01 -9.64302e-01  1.37347e+00
21Feb13_100448|  -7.45391e-01  1.70867e-01 -1.36756e+00  5.82947e-01 -8.68562e-01
21Feb13_100448|   1.52281e+00]
21Feb13_100448| [ 4.00468e-01  1.96305e+00  2.45851e+00 -2.24292e-01  1.02207e+00
21Feb13_100448|  -3.21156e-01 -2.24026e-01  8.81373e-01 -4.33565e-01  2.26966e+00
21Feb13_100448|  -6.45783e-01]
21Feb13_100448| [-1.03032e-01  1.48460e+00  3.46312e-01 -1.19882e+00  1.66240e+00
21Feb13_100448|  -3.14884e-01  1.01077e+00 -6.85286e-03 -6.98216e-01 -8.47058e-01
21Feb13_100448|  -5.50347e-01]
21Feb13_100448| [-1.11871e+00 -3.47026e-02 -3.39108e-01 -2.64636e-02 -7.06458e-01
21Feb13_100448|   1.63302e-01  1.31775e+00 -1.90493e+00  7.70172e-01 -1.46652e+00
21Feb13_100448|   7.78757e-01]
21Feb13_100448| [-4.22403e-01  1.77868e+00 -2.99659e-01 -9.52842e-01  4.45016e-01
21Feb13_100448|   1.60657e-01 -2.50497e+00 -7.00889e-01 -9.19795e-01 -8.47184e-01
21Feb13_100448|  -2.65355e-01]
21Feb13_100448| [-7.24223e-01  9.33796e-01  6.35998e-01 -4.00108e-01 -3.21069e-01
21Feb13_100448|  -1.09825e-01  2.10246e+00  4.11840e-01 -1.23415e+00 -6.89791e-01
21Feb13_100448|   2.08588e+00]]
21Feb13_100448|-- Bias --
21Feb13_100448|[-0.37416  0.16993 -0.26367  0.66001 -0.03379  0.80785  0.01432 -0.35067
21Feb13_100448|  0.36146  0.54304 -0.66491]
21Feb13_100448|Layer 1:
21Feb13_100448|-- Config --
21Feb13_100448|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 11], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100448|-- Weights --
21Feb13_100448|[[ 0.46273 -0.52633  0.15311 -0.90421]
21Feb13_100448| [-0.74445  0.54112  0.87680  0.47482]
21Feb13_100448| [-0.26719  0.17345  0.03642 -0.34925]
21Feb13_100448| [-0.58874  0.51152 -0.29307 -0.83212]
21Feb13_100448| [ 0.47815 -0.42503 -0.70618  0.59181]
21Feb13_100448| [-0.41898 -0.52488  0.41435 -0.03709]
21Feb13_100448| [-0.86538 -0.59482 -0.23110  0.07142]
21Feb13_100448| [ 0.14002 -0.88633  0.43298  0.45916]
21Feb13_100448| [-0.13044 -0.48032 -0.74848  0.34067]
21Feb13_100448| [ 0.52895  0.74501  0.12361 -0.14643]
21Feb13_100448| [ 0.58188  0.58465  0.38240  0.65996]]
21Feb13_100448|-- Bias --
21Feb13_100448|[-0.76731  0.51896 -0.80290  0.22809]
21Feb13_100448|Layer 2:
21Feb13_100448|-- Config --
21Feb13_100448|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_100448|-- Weights --
21Feb13_100448|[[-1.53127  0.04037]
21Feb13_100448| [ 0.13677 -1.46193]
21Feb13_100448| [-1.11724  0.35367]
21Feb13_100448| [ 0.49422  0.28831]]
21Feb13_100448|-- Bias --
21Feb13_100448|[ 0.11773 -0.60451]
21Feb13_100448|Predicting the validation and test data with the Best final individual.
21Feb13_100456| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_100456|-----------  ------------------  --------------------  ----------
21Feb13_100456|Validation         42.00                  30            0.00259
21Feb13_100456|   Test            36.40                  30            0.00298
2021-02-13 10:04:56.961480: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
21Feb13_100457|Data summary: Train
21Feb13_100457|data.shape = (2300, 57)
21Feb13_100457|labels.shape = (2300,)
21Feb13_100457|Class distribution:
21Feb13_100457|	0 - 1389 (0.60)
21Feb13_100457|	1 - 911 (0.40)
21Feb13_100457|Data summary: Validation
21Feb13_100457|data.shape = (1150, 57)
21Feb13_100457|labels.shape = (1150,)
21Feb13_100457|Class distribution:
21Feb13_100457|	0 - 667 (0.58)
21Feb13_100457|	1 - 483 (0.42)
21Feb13_100457|Data summary: Test
21Feb13_100457|data.shape = (1151, 57)
21Feb13_100457|labels.shape = (1151,)
21Feb13_100457|Class distribution:
21Feb13_100457|	0 - 732 (0.64)
21Feb13_100457|	1 - 419 (0.36)
21Feb13_100457|Selected configuration values
21Feb13_100457|-- Dataset name: spambase2
21Feb13_100457|-- Initial population size: 64
21Feb13_100457|-- Maximun number of generations: 32
21Feb13_100457|-- Neurons per hidden layer range: (2, 20)
21Feb13_100457|-- Hidden layers number range: (1, 3)
21Feb13_100457|-- Crossover probability: 0.5
21Feb13_100457|-- Bias gene mutation probability: 0.2
21Feb13_100457|-- Weights gene mutation probability: 0.75
21Feb13_100457|-- Neuron mutation probability: 0.3
21Feb13_100457|-- Layer mutation probability: 0.3
21Feb13_100457|-- Constant hidden layers: False
21Feb13_100457|-- Seed: 31415
21Feb13_100457|Entering GA
21Feb13_100457|Start the algorithm
2021-02-13 10:04:57.820469: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-13 10:04:57.821015: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-02-13 10:04:57.842695: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-13 10:04:57.843015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.71GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s
2021-02-13 10:04:57.843029: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-02-13 10:04:57.844498: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-02-13 10:04:57.844530: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-02-13 10:04:57.845042: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-02-13 10:04:57.845175: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-02-13 10:04:57.845246: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-13 10:04:57.845672: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-02-13 10:04:57.845715: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-13 10:04:57.845721: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-02-13 10:04:57.845917: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-02-13 10:04:57.846798: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-13 10:04:57.846816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-13 10:04:57.846819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      
2021-02-13 10:04:57.903689: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-02-13 10:04:57.904018: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3493635000 Hz
/home/jmerelo/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype("int32")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn('`model.predict_classes()` is deprecated and '
21Feb13_100858|-- Generation 1 --
21Feb13_100858|    -- Crossed 1 individual pairs.
21Feb13_100858|    -- Mutated 32 individuals.
21Feb13_101256|    -- Evaluated 64 individuals.
21Feb13_101256|    Summary of generation 1:
21Feb13_101256| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_101256|-----------  ------------------  --------------------  ----------
21Feb13_101256|    Max            53.74                168.00          0.79174
21Feb13_101256|    Avg            42.17                39.06           0.01411
21Feb13_101256|    Min            41.39                 3.00           0.00000
21Feb13_101256|    Std             1.46                36.29           0.09803
21Feb13_101256|   Best            41.39                 8.00           0.01805
21Feb13_101256|-- Generation 2 --
21Feb13_101256|    -- Crossed 1 individual pairs.
21Feb13_101256|    -- Mutated 32 individuals.
21Feb13_101649|    -- Evaluated 64 individuals.
21Feb13_101649|    Summary of generation 2:
21Feb13_101649| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_101649|-----------  ------------------  --------------------  ----------
21Feb13_101649|    Max            42.35                62.00           0.02060
21Feb13_101649|    Avg            42.00                17.64           0.00165
21Feb13_101649|    Min            41.48                 3.00           0.00000
21Feb13_101649|    Std             0.14                13.67           0.00366
21Feb13_101649|   Best            41.48                11.00           0.02060
21Feb13_101649|-- Generation 3 --
21Feb13_101649|    -- Crossed 2 individual pairs.
21Feb13_101649|    -- Mutated 32 individuals.
21Feb13_102039|    -- Evaluated 64 individuals.
21Feb13_102039|    Summary of generation 3:
21Feb13_102039| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_102039|-----------  ------------------  --------------------  ----------
21Feb13_102039|    Max            42.17                48.00           0.11094
21Feb13_102039|    Avg            41.94                11.44           0.00323
21Feb13_102039|    Min            38.78                 2.00           0.00000
21Feb13_102039|    Std             0.40                 8.36           0.01384
21Feb13_102039|   Best            38.78                10.00           0.11094
21Feb13_102039|-- Generation 4 --
21Feb13_102039|    -- Crossed 3 individual pairs.
21Feb13_102039|    -- Mutated 32 individuals.
21Feb13_102428|    -- Evaluated 64 individuals.
21Feb13_102428|    Summary of generation 4:
21Feb13_102428| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_102428|-----------  ------------------  --------------------  ----------
21Feb13_102428|    Max            42.17                48.00           0.23717
21Feb13_102428|    Avg            41.88                 9.98           0.00548
21Feb13_102428|    Min            36.61                 2.00           0.00000
21Feb13_102428|    Std             0.68                 8.95           0.02943
21Feb13_102428|   Best            36.61                13.00           0.23717
21Feb13_102428|-- Generation 5 --
21Feb13_102428|    -- Crossed 2 individual pairs.
21Feb13_102428|    -- Mutated 32 individuals.
21Feb13_102817|    -- Evaluated 64 individuals.
21Feb13_102817|    Summary of generation 5:
21Feb13_102817| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_102817|-----------  ------------------  --------------------  ----------
21Feb13_102817|    Max            42.52                42.00           0.26670
21Feb13_102817|    Avg            41.88                 9.41           0.00578
21Feb13_102817|    Min            35.65                 2.00           0.00000
21Feb13_102817|    Std             0.80                 7.63           0.03304
21Feb13_102817|   Best            35.65                13.00           0.26670
21Feb13_102817|-- Generation 6 --
21Feb13_102817|    -- Crossed 4 individual pairs.
21Feb13_102817|    -- Mutated 32 individuals.
21Feb13_103207|    -- Evaluated 64 individuals.
21Feb13_103207|    Summary of generation 6:
21Feb13_103207| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_103207|-----------  ------------------  --------------------  ----------
21Feb13_103207|    Max            42.26                34.00           0.73400
21Feb13_103207|    Avg            41.75                10.27           0.01324
21Feb13_103207|    Min            27.57                 2.00           0.00000
21Feb13_103207|    Std             1.79                 7.59           0.09086
21Feb13_103207|   Best            27.57                20.00           0.73400
21Feb13_103207|-- Generation 7 --
21Feb13_103207|    -- Crossed 4 individual pairs.
21Feb13_103207|    -- Mutated 32 individuals.
21Feb13_103556|    -- Evaluated 64 individuals.
21Feb13_103556|    Summary of generation 7:
21Feb13_103556| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_103556|-----------  ------------------  --------------------  ----------
21Feb13_103556|    Max            42.17                42.00           0.00775
21Feb13_103556|    Avg            41.96                10.28           0.00145
21Feb13_103556|    Min            41.74                 2.00           0.00000
21Feb13_103556|    Std             0.07                 9.84           0.00198
21Feb13_103556|   Best            41.74                14.00           0.00775
21Feb13_103556|-- Generation 8 --
21Feb13_103556|    -- Crossed 5 individual pairs.
21Feb13_103556|    -- Mutated 32 individuals.
21Feb13_103945|    -- Evaluated 64 individuals.
21Feb13_103945|    Summary of generation 8:
21Feb13_103945| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_103945|-----------  ------------------  --------------------  ----------
21Feb13_103945|    Max            42.17                39.00           0.74289
21Feb13_103945|    Avg            41.72                10.05           0.01359
21Feb13_103945|    Min            26.61                 2.00           0.00000
21Feb13_103945|    Std             1.91                 7.98           0.09192
21Feb13_103945|   Best            26.61                10.00           0.74289
21Feb13_103945|-- Generation 9 --
21Feb13_103945|    -- Crossed 0 individual pairs.
21Feb13_103945|    -- Mutated 32 individuals.
21Feb13_104336|    -- Evaluated 64 individuals.
21Feb13_104336|    Summary of generation 9:
21Feb13_104336| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_104336|-----------  ------------------  --------------------  ----------
21Feb13_104336|    Max            42.17                36.00           0.82958
21Feb13_104336|    Avg            41.45                10.58           0.02830
21Feb13_104336|    Min            23.22                 2.00           0.00000
21Feb13_104336|    Std             2.82                 7.32           0.14207
21Feb13_104336|   Best            23.22                14.00           0.80836
21Feb13_104336|-- Generation 10 --
21Feb13_104336|    -- Crossed 3 individual pairs.
21Feb13_104336|    -- Mutated 32 individuals.
21Feb13_104727|    -- Evaluated 64 individuals.
21Feb13_104727|    Summary of generation 10:
21Feb13_104727| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_104727|-----------  ------------------  --------------------  ----------
21Feb13_104727|    Max            42.17                45.00           0.02829
21Feb13_104727|    Avg            41.91                12.19           0.00399
21Feb13_104727|    Min            41.13                 4.00           0.00000
21Feb13_104727|    Std             0.19                 8.49           0.00531
21Feb13_104727|   Best            41.13                 9.00           0.02829
21Feb13_104727|-- Generation 11 --
21Feb13_104727|    -- Crossed 2 individual pairs.
21Feb13_104727|    -- Mutated 32 individuals.
21Feb13_105118|    -- Evaluated 64 individuals.
21Feb13_105118|    Summary of generation 11:
21Feb13_105118| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_105118|-----------  ------------------  --------------------  ----------
21Feb13_105118|    Max            42.43                36.00           0.08279
21Feb13_105118|    Avg            41.96                12.19           0.00368
21Feb13_105118|    Min            41.22                 4.00           0.00000
21Feb13_105118|    Std             0.15                 7.55           0.01056
21Feb13_105118|   Best            41.22                 4.00           0.02318
21Feb13_105118|-- Generation 12 --
21Feb13_105118|    -- Crossed 5 individual pairs.
21Feb13_105118|    -- Mutated 32 individuals.
21Feb13_105511|    -- Evaluated 64 individuals.
21Feb13_105511|    Summary of generation 12:
21Feb13_105511| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_105511|-----------  ------------------  --------------------  ----------
21Feb13_105511|    Max            42.43                60.00           0.49729
21Feb13_105511|    Avg            41.59                11.95           0.01705
21Feb13_105511|    Min            28.09                 4.00           0.00000
21Feb13_105511|    Std             1.94                 9.71           0.07442
21Feb13_105511|   Best            28.09                36.00           0.49729
21Feb13_105511|-- Generation 13 --
21Feb13_105511|    -- Crossed 7 individual pairs.
21Feb13_105511|    -- Mutated 32 individuals.
21Feb13_105902|    -- Evaluated 64 individuals.
21Feb13_105902|    Summary of generation 13:
21Feb13_105902| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_105902|-----------  ------------------  --------------------  ----------
21Feb13_105902|    Max            42.17                36.00           0.70364
21Feb13_105902|    Avg            41.65                 9.38           0.01451
21Feb13_105902|    Min            24.96                 4.00           0.00000
21Feb13_105902|    Std             2.11                 6.51           0.08691
21Feb13_105902|   Best            24.96                36.00           0.70364
21Feb13_105902|-- Generation 14 --
21Feb13_105902|    -- Crossed 5 individual pairs.
21Feb13_105902|    -- Mutated 32 individuals.
21Feb13_110252|    -- Evaluated 64 individuals.
21Feb13_110252|    Summary of generation 14:
21Feb13_110252| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_110252|-----------  ------------------  --------------------  ----------
21Feb13_110252|    Max            43.04                36.00           0.77555
21Feb13_110252|    Avg            41.65                10.02           0.01539
21Feb13_110252|    Min            23.65                 4.00           0.00000
21Feb13_110252|    Std             2.28                 7.42           0.09585
21Feb13_110252|   Best            23.65                36.00           0.77555
21Feb13_110252|-- Generation 15 --
21Feb13_110252|    -- Crossed 4 individual pairs.
21Feb13_110252|    -- Mutated 32 individuals.
21Feb13_110643|    -- Evaluated 64 individuals.
21Feb13_110643|    Summary of generation 15:
21Feb13_110643| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_110643|-----------  ------------------  --------------------  ----------
21Feb13_110643|    Max            50.17                36.00           0.80148
21Feb13_110643|    Avg            42.04                 8.91           0.01639
21Feb13_110643|    Min            40.78                 4.00           0.00000
21Feb13_110643|    Std             1.04                 6.69           0.09907
21Feb13_110643|   Best            40.78                20.00           0.03597
21Feb13_110643|-- Generation 16 --
21Feb13_110643|    -- Crossed 4 individual pairs.
21Feb13_110643|    -- Mutated 32 individuals.
21Feb13_111031|    -- Evaluated 64 individuals.
21Feb13_111031|    Summary of generation 16:
21Feb13_111031| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_111031|-----------  ------------------  --------------------  ----------
21Feb13_111031|    Max            42.17                24.00           0.02061
21Feb13_111031|    Avg            41.92                 8.88           0.00327
21Feb13_111031|    Min            41.39                 4.00           0.00000
21Feb13_111031|    Std             0.13                 5.92           0.00416
21Feb13_111031|   Best            41.39                 4.00           0.02061
21Feb13_111031|-- Generation 17 --
21Feb13_111031|    -- Crossed 6 individual pairs.
21Feb13_111031|    -- Mutated 32 individuals.
21Feb13_111419|    -- Evaluated 64 individuals.
21Feb13_111419|    Summary of generation 17:
21Feb13_111419| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_111419|-----------  ------------------  --------------------  ----------
21Feb13_111419|    Max            42.61                28.00           0.02060
21Feb13_111419|    Avg            41.92                 7.77           0.00416
21Feb13_111419|    Min            41.48                 4.00           0.00000
21Feb13_111419|    Std             0.15                 5.56           0.00419
21Feb13_111419|   Best            41.48                 4.00           0.02060
21Feb13_111419|-- Generation 18 --
21Feb13_111419|    -- Crossed 5 individual pairs.
21Feb13_111419|    -- Mutated 32 individuals.
21Feb13_111806|    -- Evaluated 64 individuals.
21Feb13_111806|    Summary of generation 18:
21Feb13_111806| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_111806|-----------  ------------------  --------------------  ----------
21Feb13_111806|    Max            42.61                20.00           0.02552
21Feb13_111806|    Avg            41.91                 7.53           0.00439
21Feb13_111806|    Min            41.39                 3.00           0.00000
21Feb13_111806|    Std             0.17                 4.89           0.00513
21Feb13_111806|   Best            41.39                 4.00           0.02061
21Feb13_111806|-- Generation 19 --
21Feb13_111806|    -- Crossed 5 individual pairs.
21Feb13_111806|    -- Mutated 32 individuals.
21Feb13_112155|    -- Evaluated 64 individuals.
21Feb13_112155|    Summary of generation 19:
21Feb13_112155| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_112155|-----------  ------------------  --------------------  ----------
21Feb13_112155|    Max            42.09                36.00           0.41473
21Feb13_112155|    Avg            41.70                 7.73           0.01031
21Feb13_112155|    Min            29.65                 4.00           0.00000
21Feb13_112155|    Std             1.52                 5.85           0.05112
21Feb13_112155|   Best            29.65                16.00           0.41473
21Feb13_112155|-- Generation 20 --
21Feb13_112155|    -- Crossed 3 individual pairs.
21Feb13_112155|    -- Mutated 32 individuals.
21Feb13_112543|    -- Evaluated 64 individuals.
21Feb13_112543|    Summary of generation 20:
21Feb13_112543| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_112543|-----------  ------------------  --------------------  ----------
21Feb13_112543|    Max            54.09                18.00           0.79182
21Feb13_112543|    Avg            42.10                 7.48           0.01592
21Feb13_112543|    Min            41.39                 4.00           0.00000
21Feb13_112543|    Std             1.51                 4.65           0.09783
21Feb13_112543|   Best            41.39                 4.00           0.02061
21Feb13_112543|-- Generation 21 --
21Feb13_112543|    -- Crossed 7 individual pairs.
21Feb13_112543|    -- Mutated 32 individuals.
21Feb13_112931|    -- Evaluated 64 individuals.
21Feb13_112931|    Summary of generation 21:
21Feb13_112931| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_112931|-----------  ------------------  --------------------  ----------
21Feb13_112931|    Max            42.09                26.00           0.02316
21Feb13_112931|    Avg            41.90                 7.27           0.00387
21Feb13_112931|    Min            41.39                 3.00           0.00000
21Feb13_112931|    Std             0.11                 5.00           0.00376
21Feb13_112931|   Best            41.39                 4.00           0.02316
21Feb13_112931|-- Generation 22 --
21Feb13_112931|    -- Crossed 6 individual pairs.
21Feb13_112931|    -- Mutated 32 individuals.
21Feb13_113320|    -- Evaluated 64 individuals.
21Feb13_113320|    Summary of generation 22:
21Feb13_113320| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_113320|-----------  ------------------  --------------------  ----------
21Feb13_113320|    Max            42.09                20.00           0.02061
21Feb13_113320|    Avg            41.87                 7.39           0.00456
21Feb13_113320|    Min            41.39                 3.00           0.00000
21Feb13_113320|    Std             0.14                 4.92           0.00412
21Feb13_113320|   Best            41.39                 4.00           0.02061
21Feb13_113320|-- Generation 23 --
21Feb13_113320|    -- Crossed 4 individual pairs.
21Feb13_113320|    -- Mutated 32 individuals.
21Feb13_113708|    -- Evaluated 64 individuals.
21Feb13_113708|    Summary of generation 23:
21Feb13_113708| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_113708|-----------  ------------------  --------------------  ----------
21Feb13_113708|    Max            42.17                20.00           0.02062
21Feb13_113708|    Avg            41.89                 7.02           0.00396
21Feb13_113708|    Min            41.30                 3.00           0.00000
21Feb13_113708|    Std             0.13                 4.55           0.00344
21Feb13_113708|   Best            41.30                 4.00           0.02062
21Feb13_113708|-- Generation 24 --
21Feb13_113708|    -- Crossed 5 individual pairs.
21Feb13_113708|    -- Mutated 32 individuals.
21Feb13_114059|    -- Evaluated 64 individuals.
21Feb13_114059|    Summary of generation 24:
21Feb13_114059| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_114059|-----------  ------------------  --------------------  ----------
21Feb13_114059|    Max            42.09                39.00           0.02317
21Feb13_114059|    Avg            41.86                 8.64           0.00516
21Feb13_114059|    Min            41.30                 3.00           0.00000
21Feb13_114059|    Std             0.16                 7.56           0.00493
21Feb13_114059|   Best            41.30                 4.00           0.02317
21Feb13_114059|-- Generation 25 --
21Feb13_114059|    -- Crossed 4 individual pairs.
21Feb13_114059|    -- Mutated 32 individuals.
21Feb13_114451|    -- Evaluated 64 individuals.
21Feb13_114451|    Summary of generation 25:
21Feb13_114451| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_114451|-----------  ------------------  --------------------  ----------
21Feb13_114451|    Max            42.09                20.00           0.50916
21Feb13_114451|    Avg            41.48                 8.00           0.01944
21Feb13_114451|    Min            29.04                 3.00           0.00000
21Feb13_114451|    Std             2.19                 5.39           0.08474
21Feb13_114451|   Best            29.04                18.00           0.50916
21Feb13_114451|-- Generation 26 --
21Feb13_114451|    -- Crossed 5 individual pairs.
21Feb13_114451|    -- Mutated 32 individuals.
21Feb13_114842|    -- Evaluated 64 individuals.
21Feb13_114842|    Summary of generation 26:
21Feb13_114842| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_114842|-----------  ------------------  --------------------  ----------
21Feb13_114842|    Max            42.09                27.00           0.57516
21Feb13_114842|    Avg            41.65                 7.92           0.01355
21Feb13_114842|    Min            27.65                 3.00           0.00000
21Feb13_114842|    Std             1.77                 5.86           0.07089
21Feb13_114842|   Best            27.65                16.00           0.57516
21Feb13_114842|-- Generation 27 --
21Feb13_114842|    -- Crossed 4 individual pairs.
21Feb13_114842|    -- Mutated 32 individuals.
21Feb13_115233|    -- Evaluated 64 individuals.
21Feb13_115233|    Summary of generation 27:
21Feb13_115233| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_115233|-----------  ------------------  --------------------  ----------
21Feb13_115233|    Max            42.17                36.00           0.51925
21Feb13_115233|    Avg            41.44                 9.12           0.02115
21Feb13_115233|    Min            27.91                 2.00           0.00000
21Feb13_115233|    Std             2.33                 7.25           0.08600
21Feb13_115233|   Best            27.91                16.00           0.51925
21Feb13_115233|-- Generation 28 --
21Feb13_115233|    -- Crossed 5 individual pairs.
21Feb13_115233|    -- Mutated 32 individuals.
21Feb13_115624|    -- Evaluated 64 individuals.
21Feb13_115624|    Summary of generation 28:
21Feb13_115624| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_115624|-----------  ------------------  --------------------  ----------
21Feb13_115624|    Max            42.09                36.00           0.51190
21Feb13_115624|    Avg            41.45                 9.50           0.01991
21Feb13_115624|    Min            28.00                 3.00           0.00000
21Feb13_115624|    Std             2.25                 7.99           0.08268
21Feb13_115624|   Best            28.00                16.00           0.51190
21Feb13_115624|-- Generation 29 --
21Feb13_115624|    -- Crossed 3 individual pairs.
21Feb13_115624|    -- Mutated 32 individuals.
21Feb13_120015|    -- Evaluated 64 individuals.
21Feb13_120015|    Summary of generation 29:
21Feb13_120015| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_120015|-----------  ------------------  --------------------  ----------
21Feb13_120015|    Max            42.17                36.00           0.50225
21Feb13_120015|    Avg            41.47                 8.39           0.01896
21Feb13_120015|    Min            28.26                 3.00           0.00000
21Feb13_120015|    Std             2.21                 7.24           0.07854
21Feb13_120015|   Best            28.26                16.00           0.50225
21Feb13_120015|-- Generation 30 --
21Feb13_120015|    -- Crossed 9 individual pairs.
21Feb13_120015|    -- Mutated 32 individuals.
21Feb13_120405|    -- Evaluated 64 individuals.
21Feb13_120405|    Summary of generation 30:
21Feb13_120405| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_120405|-----------  ------------------  --------------------  ----------
21Feb13_120405|    Max            42.09                36.00           0.52702
21Feb13_120405|    Avg            41.62                 7.59           0.01396
21Feb13_120405|    Min            27.65                 3.00           0.00000
21Feb13_120405|    Std             1.77                 6.00           0.06507
21Feb13_120405|   Best            27.65                36.00           0.52702
21Feb13_120405|-- Generation 31 --
21Feb13_120405|    -- Crossed 7 individual pairs.
21Feb13_120405|    -- Mutated 32 individuals.
21Feb13_120754|    -- Evaluated 64 individuals.
21Feb13_120754|    Summary of generation 31:
21Feb13_120754| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_120754|-----------  ------------------  --------------------  ----------
21Feb13_120754|    Max            42.70                36.00           0.62340
21Feb13_120754|    Avg            41.40                 7.81           0.02252
21Feb13_120754|    Min            26.87                 3.00           0.00000
21Feb13_120754|    Std             2.45                 6.98           0.09381
21Feb13_120754|   Best            26.87                36.00           0.62340
21Feb13_120754|-- Generation 32 --
21Feb13_120754|    -- Crossed 8 individual pairs.
21Feb13_120754|    -- Mutated 32 individuals.
21Feb13_121143|    -- Evaluated 64 individuals.
21Feb13_121143|    Summary of generation 32:
21Feb13_121143| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_121143|-----------  ------------------  --------------------  ----------
21Feb13_121143|    Max            42.17                39.00           0.58348
21Feb13_121143|    Avg            41.47                 7.97           0.02658
21Feb13_121143|    Min            26.52                 3.00           0.00000
21Feb13_121143|    Std             2.02                 7.99           0.08758
21Feb13_121143|   Best            26.52                36.00           0.58348
21Feb13_121143|Best initial individual weights
21Feb13_121143|Individual:
21Feb13_121143|-- Constant hidden layers --
21Feb13_121143|False
21Feb13_121143|Layer 0:
21Feb13_121143|-- Config --
21Feb13_121143|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 20, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121143|-- Weights --
21Feb13_121143|[[-0.30181 -0.15362 -0.48666 ...  0.61759 -0.62451 -0.68770]
21Feb13_121143| [-0.16485 -0.91106  0.11455 ...  0.62811  0.59004  0.67663]
21Feb13_121143| [ 0.66670 -0.53955  0.76871 ...  0.90593 -0.33725  0.66349]
21Feb13_121143| ...
21Feb13_121143| [ 0.74212  0.43331  0.21794 ... -0.85508 -0.73513 -0.10327]
21Feb13_121143| [ 0.29165 -0.62873  0.72641 ...  0.00672 -0.75629 -0.43344]
21Feb13_121143| [ 0.65928 -0.57377  0.41399 ...  0.32549 -0.53415 -0.14265]]
21Feb13_121143|-- Bias --
21Feb13_121143|[ 0.61749  0.97539 -0.60871 -0.85802 -0.68649  0.51916 -0.73066 -0.74063
21Feb13_121143| -0.28857  0.79686  0.32803  0.61286 -0.51342 -0.02403 -0.84712 -0.56623
21Feb13_121143|  0.92202 -0.65565 -0.41887  0.85299]
21Feb13_121143|Layer 1:
21Feb13_121143|-- Config --
21Feb13_121143|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 20], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121143|-- Weights --
21Feb13_121143|[[-0.88293  0.48020]
21Feb13_121143| [ 0.27579  0.47702]
21Feb13_121143| [ 0.81058 -0.39665]
21Feb13_121143| [-0.69273  0.44718]
21Feb13_121143| [-0.65195 -0.92312]
21Feb13_121143| [-0.53533  0.03780]
21Feb13_121143| [-0.86804  0.83938]
21Feb13_121143| [ 0.02226  0.28598]
21Feb13_121143| [-0.06074 -0.09518]
21Feb13_121143| [-0.17731 -0.00217]
21Feb13_121143| [ 0.07123  0.56603]
21Feb13_121143| [-0.08943 -0.32805]
21Feb13_121143| [-0.90467 -0.19086]
21Feb13_121143| [ 0.06311  0.45915]
21Feb13_121143| [ 0.16673  0.87915]
21Feb13_121143| [-0.99304 -0.85099]
21Feb13_121143| [ 0.67033 -0.19807]
21Feb13_121143| [-0.50418 -0.93930]
21Feb13_121143| [-0.53824 -0.78628]
21Feb13_121143| [ 0.65487 -0.37587]]
21Feb13_121143|-- Bias --
21Feb13_121143|[0.97703 0.96510]
21Feb13_121143|Predicting the validation and test data with the Best initial individual.
21Feb13_121150| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_121150|-----------  ------------------  --------------------  ----------
21Feb13_121150|Validation         42.17                  20            0.00258
21Feb13_121150|   Test            36.32                  20            0.00298
21Feb13_121150|-------------------- Test #0 --------------------
21Feb13_121150|Best final individual weights
21Feb13_121150|Individual:
21Feb13_121150|-- Constant hidden layers --
21Feb13_121150|False
21Feb13_121150|Layer 0:
21Feb13_121150|-- Config --
21Feb13_121150|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121150|-- Weights --
21Feb13_121150|[[ 0.63638 -0.20563 -0.46748  0.36212]
21Feb13_121150| [-0.22569 -0.52990 -1.70224 -0.11042]
21Feb13_121150| [-0.01823 -0.16278 -0.33268 -1.79564]
21Feb13_121150| [ 0.44877  0.32665  0.25922  0.12485]
21Feb13_121150| [-0.24588 -2.19455 -0.08046  0.81960]
21Feb13_121150| [ 0.54427  0.28873 -1.78972  0.41910]
21Feb13_121150| [-0.69198 -0.02289 -1.92958  0.32782]
21Feb13_121150| [-0.78503  0.66093  1.37772 -1.48476]
21Feb13_121150| [ 1.54812  0.42435 -0.31442 -0.17611]
21Feb13_121150| [ 1.94045  0.79061  0.31325  0.39846]
21Feb13_121150| [ 0.81259  1.28494 -0.42398  0.73768]
21Feb13_121150| [ 0.24812 -1.03749 -0.32424 -0.22649]
21Feb13_121150| [-0.10656 -0.80897 -0.16817 -1.69896]
21Feb13_121150| [ 0.17005  2.23605 -1.56675  0.50354]
21Feb13_121150| [-0.74027 -0.07039 -0.56526  0.24764]
21Feb13_121150| [ 0.24215  1.05626 -0.61433  0.72223]
21Feb13_121150| [-3.21616 -0.99370 -0.70992 -1.26517]
21Feb13_121150| [-0.63804  0.43694  0.67759  0.11887]
21Feb13_121150| [-0.03764 -1.07512  0.56036 -0.09506]
21Feb13_121150| [-0.05633  1.29383 -0.65992  0.07654]
21Feb13_121150| [ 0.54311  0.30714  1.42644  2.72569]
21Feb13_121150| [-1.00185 -0.09399 -0.43646 -0.97593]
21Feb13_121150| [ 0.78104  0.64037 -0.07888 -0.94235]
21Feb13_121150| [ 0.36292 -2.09381 -0.14759 -0.57450]
21Feb13_121150| [ 0.98177  0.47143 -0.71689  0.87222]
21Feb13_121150| [ 0.64560 -1.51019 -0.08943  0.17061]
21Feb13_121150| [-0.05811 -0.65097  1.17154  0.01508]
21Feb13_121150| [ 1.10455  0.40564  0.46023 -0.68888]
21Feb13_121150| [-0.99141  0.40317 -0.72143 -1.11914]
21Feb13_121150| [-0.57071 -0.24300  0.15319  0.12984]
21Feb13_121150| [-0.77877 -0.72042 -1.33874 -0.26930]
21Feb13_121150| [ 0.45731 -1.45936 -0.94053 -2.01562]
21Feb13_121150| [ 0.66473 -0.46017 -0.47228 -0.41096]
21Feb13_121150| [ 0.17837  0.27083 -0.01682  0.32447]
21Feb13_121150| [ 0.96631 -0.25649 -0.83279  2.07308]
21Feb13_121150| [ 0.11932  1.10674  0.87761 -1.17589]
21Feb13_121150| [-0.29668 -1.06887 -2.04195 -0.93875]
21Feb13_121150| [ 0.36581  1.00476 -1.10789 -0.30620]
21Feb13_121150| [-0.35525  1.21057  0.20561  0.43313]
21Feb13_121150| [-2.02128 -1.06479  0.24020  0.09220]
21Feb13_121150| [-1.45281  1.00135 -1.07230 -1.41216]
21Feb13_121150| [-1.85581 -2.18106  1.21803  0.35416]
21Feb13_121150| [-1.08240  0.46387  0.12432  0.95257]
21Feb13_121150| [ 0.71253  0.03984 -0.79262  3.36370]
21Feb13_121150| [-0.53377 -0.94682 -1.48878 -0.46760]
21Feb13_121150| [-0.94888  0.08111  0.71320  0.19591]
21Feb13_121150| [ 0.40268 -1.63278 -0.12703  0.30461]
21Feb13_121150| [-0.27445  1.33890 -0.51833  0.80592]
21Feb13_121150| [ 0.59842 -1.09413  1.23234  0.58744]
21Feb13_121150| [-0.56340 -0.59958  1.10615 -1.02877]
21Feb13_121150| [ 0.73186  1.26425  1.56679 -0.28415]
21Feb13_121150| [ 1.61531  1.09254  0.10319 -0.96841]
21Feb13_121150| [ 0.71621 -1.06734 -1.46109  0.27923]
21Feb13_121150| [ 0.16600  0.29021  0.26385 -1.28921]
21Feb13_121150| [ 0.86279  0.35615  1.41976 -0.32959]
21Feb13_121150| [ 0.91697 -0.03368 -0.47800  0.48218]
21Feb13_121150| [ 0.34812 -0.02552 -1.17485 -0.07619]]
21Feb13_121150|-- Bias --
21Feb13_121150|[ 1.43486 -0.37836  0.90214  0.52973]
21Feb13_121150|Layer 1:
21Feb13_121150|-- Config --
21Feb13_121150|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121150|-- Weights --
21Feb13_121150|[[ 0.00473 -0.54749  0.74398]
21Feb13_121150| [-0.10074  0.03358  0.52254]
21Feb13_121150| [-0.65340  1.25823  0.80018]
21Feb13_121150| [-0.65787  0.15553 -0.28078]]
21Feb13_121150|-- Bias --
21Feb13_121150|[-0.79202  1.42146 -0.58308]
21Feb13_121150|Layer 2:
21Feb13_121150|-- Config --
21Feb13_121150|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121150|-- Weights --
21Feb13_121150|[[ 0.10221  0.77446 -0.37401 -0.20485  0.06422]
21Feb13_121150| [-0.98663  0.10920 -0.48505 -0.60013  0.32397]
21Feb13_121150| [-0.58271  0.81561 -0.47697  0.99162 -0.51476]]
21Feb13_121150|-- Bias --
21Feb13_121150|[ 0.34898  0.20875 -0.68469 -0.24530  0.12589]
21Feb13_121150|Layer 3:
21Feb13_121150|-- Config --
21Feb13_121150|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121150|-- Weights --
21Feb13_121150|[[-1.05547 -1.17480]
21Feb13_121150| [ 0.43780  1.28908]
21Feb13_121150| [-1.15457  0.60478]
21Feb13_121150| [-0.50464 -0.51282]
21Feb13_121150| [-0.84696 -0.20512]]
21Feb13_121150|-- Bias --
21Feb13_121150|[-0.90212  0.80792]
21Feb13_121150|Predicting the validation and test data with the Best final individual.
21Feb13_121158| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_121158|-----------  ------------------  --------------------  ----------
21Feb13_121158|Validation         28.52                  36            0.49073
21Feb13_121158|   Test            36.40                  36            0.00000
21Feb13_121158|-------------------- Test #1 --------------------
21Feb13_121158|Best final individual weights
21Feb13_121158|Individual:
21Feb13_121158|-- Constant hidden layers --
21Feb13_121158|False
21Feb13_121158|Layer 0:
21Feb13_121158|-- Config --
21Feb13_121158|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121158|-- Weights --
21Feb13_121158|[[ 0.63638 -0.20563 -0.46748  0.36212]
21Feb13_121158| [-0.22569 -0.52990 -1.70224 -0.11042]
21Feb13_121158| [-0.01823 -0.16278 -0.33268 -1.79564]
21Feb13_121158| [ 0.44877  0.32665  0.25922  0.12485]
21Feb13_121158| [-0.24588 -2.19455 -0.08046  0.81960]
21Feb13_121158| [ 0.54427  0.28873 -1.78972  0.41910]
21Feb13_121158| [-0.69198 -0.02289 -1.92958  0.32782]
21Feb13_121158| [-0.78503  0.66093  1.37772 -1.48476]
21Feb13_121158| [ 1.54812  0.42435 -0.31442 -0.17611]
21Feb13_121158| [ 1.94045  0.79061  0.31325  0.39846]
21Feb13_121158| [ 0.81259  1.28494 -0.42398  0.73768]
21Feb13_121158| [ 0.24812 -1.03749 -0.32424 -0.22649]
21Feb13_121158| [-0.10656 -0.80897 -0.16817 -1.69896]
21Feb13_121158| [ 0.17005  2.23605 -1.56675  0.50354]
21Feb13_121158| [-0.74027 -0.07039 -0.56526  0.24764]
21Feb13_121158| [ 0.24215  1.05626 -0.61433  0.72223]
21Feb13_121158| [-3.21616 -0.99370 -0.70992 -1.26517]
21Feb13_121158| [-0.63804  0.43694  0.67759  0.11887]
21Feb13_121158| [-0.03764 -1.07512  0.56036 -0.09506]
21Feb13_121158| [-0.05633  1.29383 -0.65992  0.07654]
21Feb13_121158| [ 0.54311  0.30714  1.42644  2.72569]
21Feb13_121158| [-1.00185 -0.09399 -0.43646 -0.97593]
21Feb13_121158| [ 0.78104  0.64037 -0.07888 -0.94235]
21Feb13_121158| [ 0.36292 -2.09381 -0.14759 -0.57450]
21Feb13_121158| [ 0.98177  0.47143 -0.71689  0.87222]
21Feb13_121158| [ 0.64560 -1.51019 -0.08943  0.17061]
21Feb13_121158| [-0.05811 -0.65097  1.17154  0.01508]
21Feb13_121158| [ 1.10455  0.40564  0.46023 -0.68888]
21Feb13_121158| [-0.99141  0.40317 -0.72143 -1.11914]
21Feb13_121158| [-0.57071 -0.24300  0.15319  0.12984]
21Feb13_121158| [-0.77877 -0.72042 -1.33874 -0.26930]
21Feb13_121158| [ 0.45731 -1.45936 -0.94053 -2.01562]
21Feb13_121158| [ 0.66473 -0.46017 -0.47228 -0.41096]
21Feb13_121158| [ 0.17837  0.27083 -0.01682  0.32447]
21Feb13_121158| [ 0.96631 -0.25649 -0.83279  2.07308]
21Feb13_121158| [ 0.11932  1.10674  0.87761 -1.17589]
21Feb13_121158| [-0.29668 -1.06887 -2.04195 -0.93875]
21Feb13_121158| [ 0.36581  1.00476 -1.10789 -0.30620]
21Feb13_121158| [-0.35525  1.21057  0.20561  0.43313]
21Feb13_121158| [-2.02128 -1.06479  0.24020  0.09220]
21Feb13_121158| [-1.45281  1.00135 -1.07230 -1.41216]
21Feb13_121158| [-1.85581 -2.18106  1.21803  0.35416]
21Feb13_121158| [-1.08240  0.46387  0.12432  0.95257]
21Feb13_121158| [ 0.71253  0.03984 -0.79262  3.36370]
21Feb13_121158| [-0.53377 -0.94682 -1.48878 -0.46760]
21Feb13_121158| [-0.94888  0.08111  0.71320  0.19591]
21Feb13_121158| [ 0.40268 -1.63278 -0.12703  0.30461]
21Feb13_121158| [-0.27445  1.33890 -0.51833  0.80592]
21Feb13_121158| [ 0.59842 -1.09413  1.23234  0.58744]
21Feb13_121158| [-0.56340 -0.59958  1.10615 -1.02877]
21Feb13_121158| [ 0.73186  1.26425  1.56679 -0.28415]
21Feb13_121158| [ 1.61531  1.09254  0.10319 -0.96841]
21Feb13_121158| [ 0.71621 -1.06734 -1.46109  0.27923]
21Feb13_121158| [ 0.16600  0.29021  0.26385 -1.28921]
21Feb13_121158| [ 0.86279  0.35615  1.41976 -0.32959]
21Feb13_121158| [ 0.91697 -0.03368 -0.47800  0.48218]
21Feb13_121158| [ 0.34812 -0.02552 -1.17485 -0.07619]]
21Feb13_121158|-- Bias --
21Feb13_121158|[ 1.43486 -0.37836  0.90214  0.52973]
21Feb13_121158|Layer 1:
21Feb13_121158|-- Config --
21Feb13_121158|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121158|-- Weights --
21Feb13_121158|[[ 0.00473 -0.54749  0.74398]
21Feb13_121158| [-0.10074  0.03358  0.52254]
21Feb13_121158| [-0.65340  1.25823  0.80018]
21Feb13_121158| [-0.65787  0.15553 -0.28078]]
21Feb13_121158|-- Bias --
21Feb13_121158|[-0.79202  1.42146 -0.58308]
21Feb13_121158|Layer 2:
21Feb13_121158|-- Config --
21Feb13_121158|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121158|-- Weights --
21Feb13_121158|[[ 0.10221  0.77446 -0.37401 -0.20485  0.06422]
21Feb13_121158| [-0.98663  0.10920 -0.48505 -0.60013  0.32397]
21Feb13_121158| [-0.58271  0.81561 -0.47697  0.99162 -0.51476]]
21Feb13_121158|-- Bias --
21Feb13_121158|[ 0.34898  0.20875 -0.68469 -0.24530  0.12589]
21Feb13_121158|Layer 3:
21Feb13_121158|-- Config --
21Feb13_121158|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121158|-- Weights --
21Feb13_121158|[[-1.05547 -1.17480]
21Feb13_121158| [ 0.43780  1.28908]
21Feb13_121158| [-1.15457  0.60478]
21Feb13_121158| [-0.50464 -0.51282]
21Feb13_121158| [-0.84696 -0.20512]]
21Feb13_121158|-- Bias --
21Feb13_121158|[-0.90212  0.80792]
21Feb13_121158|Predicting the validation and test data with the Best final individual.
21Feb13_121206| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_121206|-----------  ------------------  --------------------  ----------
21Feb13_121206|Validation         42.00                  36            0.00000
21Feb13_121206|   Test            23.54                  36            0.54504
21Feb13_121206|-------------------- Test #2 --------------------
21Feb13_121206|Best final individual weights
21Feb13_121206|Individual:
21Feb13_121206|-- Constant hidden layers --
21Feb13_121206|False
21Feb13_121206|Layer 0:
21Feb13_121206|-- Config --
21Feb13_121206|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121206|-- Weights --
21Feb13_121206|[[ 0.63638 -0.20563 -0.46748  0.36212]
21Feb13_121206| [-0.22569 -0.52990 -1.70224 -0.11042]
21Feb13_121206| [-0.01823 -0.16278 -0.33268 -1.79564]
21Feb13_121206| [ 0.44877  0.32665  0.25922  0.12485]
21Feb13_121206| [-0.24588 -2.19455 -0.08046  0.81960]
21Feb13_121206| [ 0.54427  0.28873 -1.78972  0.41910]
21Feb13_121206| [-0.69198 -0.02289 -1.92958  0.32782]
21Feb13_121206| [-0.78503  0.66093  1.37772 -1.48476]
21Feb13_121206| [ 1.54812  0.42435 -0.31442 -0.17611]
21Feb13_121206| [ 1.94045  0.79061  0.31325  0.39846]
21Feb13_121206| [ 0.81259  1.28494 -0.42398  0.73768]
21Feb13_121206| [ 0.24812 -1.03749 -0.32424 -0.22649]
21Feb13_121206| [-0.10656 -0.80897 -0.16817 -1.69896]
21Feb13_121206| [ 0.17005  2.23605 -1.56675  0.50354]
21Feb13_121206| [-0.74027 -0.07039 -0.56526  0.24764]
21Feb13_121206| [ 0.24215  1.05626 -0.61433  0.72223]
21Feb13_121206| [-3.21616 -0.99370 -0.70992 -1.26517]
21Feb13_121206| [-0.63804  0.43694  0.67759  0.11887]
21Feb13_121206| [-0.03764 -1.07512  0.56036 -0.09506]
21Feb13_121206| [-0.05633  1.29383 -0.65992  0.07654]
21Feb13_121206| [ 0.54311  0.30714  1.42644  2.72569]
21Feb13_121206| [-1.00185 -0.09399 -0.43646 -0.97593]
21Feb13_121206| [ 0.78104  0.64037 -0.07888 -0.94235]
21Feb13_121206| [ 0.36292 -2.09381 -0.14759 -0.57450]
21Feb13_121206| [ 0.98177  0.47143 -0.71689  0.87222]
21Feb13_121206| [ 0.64560 -1.51019 -0.08943  0.17061]
21Feb13_121206| [-0.05811 -0.65097  1.17154  0.01508]
21Feb13_121206| [ 1.10455  0.40564  0.46023 -0.68888]
21Feb13_121206| [-0.99141  0.40317 -0.72143 -1.11914]
21Feb13_121206| [-0.57071 -0.24300  0.15319  0.12984]
21Feb13_121206| [-0.77877 -0.72042 -1.33874 -0.26930]
21Feb13_121206| [ 0.45731 -1.45936 -0.94053 -2.01562]
21Feb13_121206| [ 0.66473 -0.46017 -0.47228 -0.41096]
21Feb13_121206| [ 0.17837  0.27083 -0.01682  0.32447]
21Feb13_121206| [ 0.96631 -0.25649 -0.83279  2.07308]
21Feb13_121206| [ 0.11932  1.10674  0.87761 -1.17589]
21Feb13_121206| [-0.29668 -1.06887 -2.04195 -0.93875]
21Feb13_121206| [ 0.36581  1.00476 -1.10789 -0.30620]
21Feb13_121206| [-0.35525  1.21057  0.20561  0.43313]
21Feb13_121206| [-2.02128 -1.06479  0.24020  0.09220]
21Feb13_121206| [-1.45281  1.00135 -1.07230 -1.41216]
21Feb13_121206| [-1.85581 -2.18106  1.21803  0.35416]
21Feb13_121206| [-1.08240  0.46387  0.12432  0.95257]
21Feb13_121206| [ 0.71253  0.03984 -0.79262  3.36370]
21Feb13_121206| [-0.53377 -0.94682 -1.48878 -0.46760]
21Feb13_121206| [-0.94888  0.08111  0.71320  0.19591]
21Feb13_121206| [ 0.40268 -1.63278 -0.12703  0.30461]
21Feb13_121206| [-0.27445  1.33890 -0.51833  0.80592]
21Feb13_121206| [ 0.59842 -1.09413  1.23234  0.58744]
21Feb13_121206| [-0.56340 -0.59958  1.10615 -1.02877]
21Feb13_121206| [ 0.73186  1.26425  1.56679 -0.28415]
21Feb13_121206| [ 1.61531  1.09254  0.10319 -0.96841]
21Feb13_121206| [ 0.71621 -1.06734 -1.46109  0.27923]
21Feb13_121206| [ 0.16600  0.29021  0.26385 -1.28921]
21Feb13_121206| [ 0.86279  0.35615  1.41976 -0.32959]
21Feb13_121206| [ 0.91697 -0.03368 -0.47800  0.48218]
21Feb13_121206| [ 0.34812 -0.02552 -1.17485 -0.07619]]
21Feb13_121206|-- Bias --
21Feb13_121206|[ 1.43486 -0.37836  0.90214  0.52973]
21Feb13_121206|Layer 1:
21Feb13_121206|-- Config --
21Feb13_121206|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121206|-- Weights --
21Feb13_121206|[[ 0.00473 -0.54749  0.74398]
21Feb13_121206| [-0.10074  0.03358  0.52254]
21Feb13_121206| [-0.65340  1.25823  0.80018]
21Feb13_121206| [-0.65787  0.15553 -0.28078]]
21Feb13_121206|-- Bias --
21Feb13_121206|[-0.79202  1.42146 -0.58308]
21Feb13_121206|Layer 2:
21Feb13_121206|-- Config --
21Feb13_121206|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121206|-- Weights --
21Feb13_121206|[[ 0.10221  0.77446 -0.37401 -0.20485  0.06422]
21Feb13_121206| [-0.98663  0.10920 -0.48505 -0.60013  0.32397]
21Feb13_121206| [-0.58271  0.81561 -0.47697  0.99162 -0.51476]]
21Feb13_121206|-- Bias --
21Feb13_121206|[ 0.34898  0.20875 -0.68469 -0.24530  0.12589]
21Feb13_121206|Layer 3:
21Feb13_121206|-- Config --
21Feb13_121206|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121206|-- Weights --
21Feb13_121206|[[-1.05547 -1.17480]
21Feb13_121206| [ 0.43780  1.28908]
21Feb13_121206| [-1.15457  0.60478]
21Feb13_121206| [-0.50464 -0.51282]
21Feb13_121206| [-0.84696 -0.20512]]
21Feb13_121206|-- Bias --
21Feb13_121206|[-0.90212  0.80792]
21Feb13_121206|Predicting the validation and test data with the Best final individual.
21Feb13_121213| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_121213|-----------  ------------------  --------------------  ----------
21Feb13_121213|Validation         28.35                  36            0.48570
21Feb13_121213|   Test            25.37                  36            0.50695
21Feb13_121213|-------------------- Test #3 --------------------
21Feb13_121213|Best final individual weights
21Feb13_121213|Individual:
21Feb13_121213|-- Constant hidden layers --
21Feb13_121213|False
21Feb13_121213|Layer 0:
21Feb13_121213|-- Config --
21Feb13_121213|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121213|-- Weights --
21Feb13_121213|[[ 0.63638 -0.20563 -0.46748  0.36212]
21Feb13_121213| [-0.22569 -0.52990 -1.70224 -0.11042]
21Feb13_121213| [-0.01823 -0.16278 -0.33268 -1.79564]
21Feb13_121213| [ 0.44877  0.32665  0.25922  0.12485]
21Feb13_121213| [-0.24588 -2.19455 -0.08046  0.81960]
21Feb13_121213| [ 0.54427  0.28873 -1.78972  0.41910]
21Feb13_121213| [-0.69198 -0.02289 -1.92958  0.32782]
21Feb13_121213| [-0.78503  0.66093  1.37772 -1.48476]
21Feb13_121213| [ 1.54812  0.42435 -0.31442 -0.17611]
21Feb13_121213| [ 1.94045  0.79061  0.31325  0.39846]
21Feb13_121213| [ 0.81259  1.28494 -0.42398  0.73768]
21Feb13_121213| [ 0.24812 -1.03749 -0.32424 -0.22649]
21Feb13_121213| [-0.10656 -0.80897 -0.16817 -1.69896]
21Feb13_121213| [ 0.17005  2.23605 -1.56675  0.50354]
21Feb13_121213| [-0.74027 -0.07039 -0.56526  0.24764]
21Feb13_121213| [ 0.24215  1.05626 -0.61433  0.72223]
21Feb13_121213| [-3.21616 -0.99370 -0.70992 -1.26517]
21Feb13_121213| [-0.63804  0.43694  0.67759  0.11887]
21Feb13_121213| [-0.03764 -1.07512  0.56036 -0.09506]
21Feb13_121213| [-0.05633  1.29383 -0.65992  0.07654]
21Feb13_121213| [ 0.54311  0.30714  1.42644  2.72569]
21Feb13_121213| [-1.00185 -0.09399 -0.43646 -0.97593]
21Feb13_121213| [ 0.78104  0.64037 -0.07888 -0.94235]
21Feb13_121213| [ 0.36292 -2.09381 -0.14759 -0.57450]
21Feb13_121213| [ 0.98177  0.47143 -0.71689  0.87222]
21Feb13_121213| [ 0.64560 -1.51019 -0.08943  0.17061]
21Feb13_121213| [-0.05811 -0.65097  1.17154  0.01508]
21Feb13_121213| [ 1.10455  0.40564  0.46023 -0.68888]
21Feb13_121213| [-0.99141  0.40317 -0.72143 -1.11914]
21Feb13_121213| [-0.57071 -0.24300  0.15319  0.12984]
21Feb13_121213| [-0.77877 -0.72042 -1.33874 -0.26930]
21Feb13_121213| [ 0.45731 -1.45936 -0.94053 -2.01562]
21Feb13_121213| [ 0.66473 -0.46017 -0.47228 -0.41096]
21Feb13_121213| [ 0.17837  0.27083 -0.01682  0.32447]
21Feb13_121213| [ 0.96631 -0.25649 -0.83279  2.07308]
21Feb13_121213| [ 0.11932  1.10674  0.87761 -1.17589]
21Feb13_121213| [-0.29668 -1.06887 -2.04195 -0.93875]
21Feb13_121213| [ 0.36581  1.00476 -1.10789 -0.30620]
21Feb13_121213| [-0.35525  1.21057  0.20561  0.43313]
21Feb13_121213| [-2.02128 -1.06479  0.24020  0.09220]
21Feb13_121213| [-1.45281  1.00135 -1.07230 -1.41216]
21Feb13_121213| [-1.85581 -2.18106  1.21803  0.35416]
21Feb13_121213| [-1.08240  0.46387  0.12432  0.95257]
21Feb13_121213| [ 0.71253  0.03984 -0.79262  3.36370]
21Feb13_121213| [-0.53377 -0.94682 -1.48878 -0.46760]
21Feb13_121213| [-0.94888  0.08111  0.71320  0.19591]
21Feb13_121213| [ 0.40268 -1.63278 -0.12703  0.30461]
21Feb13_121213| [-0.27445  1.33890 -0.51833  0.80592]
21Feb13_121213| [ 0.59842 -1.09413  1.23234  0.58744]
21Feb13_121213| [-0.56340 -0.59958  1.10615 -1.02877]
21Feb13_121213| [ 0.73186  1.26425  1.56679 -0.28415]
21Feb13_121213| [ 1.61531  1.09254  0.10319 -0.96841]
21Feb13_121213| [ 0.71621 -1.06734 -1.46109  0.27923]
21Feb13_121213| [ 0.16600  0.29021  0.26385 -1.28921]
21Feb13_121213| [ 0.86279  0.35615  1.41976 -0.32959]
21Feb13_121213| [ 0.91697 -0.03368 -0.47800  0.48218]
21Feb13_121213| [ 0.34812 -0.02552 -1.17485 -0.07619]]
21Feb13_121213|-- Bias --
21Feb13_121213|[ 1.43486 -0.37836  0.90214  0.52973]
21Feb13_121213|Layer 1:
21Feb13_121213|-- Config --
21Feb13_121213|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121213|-- Weights --
21Feb13_121213|[[ 0.00473 -0.54749  0.74398]
21Feb13_121213| [-0.10074  0.03358  0.52254]
21Feb13_121213| [-0.65340  1.25823  0.80018]
21Feb13_121213| [-0.65787  0.15553 -0.28078]]
21Feb13_121213|-- Bias --
21Feb13_121213|[-0.79202  1.42146 -0.58308]
21Feb13_121213|Layer 2:
21Feb13_121213|-- Config --
21Feb13_121213|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121213|-- Weights --
21Feb13_121213|[[ 0.10221  0.77446 -0.37401 -0.20485  0.06422]
21Feb13_121213| [-0.98663  0.10920 -0.48505 -0.60013  0.32397]
21Feb13_121213| [-0.58271  0.81561 -0.47697  0.99162 -0.51476]]
21Feb13_121213|-- Bias --
21Feb13_121213|[ 0.34898  0.20875 -0.68469 -0.24530  0.12589]
21Feb13_121213|Layer 3:
21Feb13_121213|-- Config --
21Feb13_121213|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121213|-- Weights --
21Feb13_121213|[[-1.05547 -1.17480]
21Feb13_121213| [ 0.43780  1.28908]
21Feb13_121213| [-1.15457  0.60478]
21Feb13_121213| [-0.50464 -0.51282]
21Feb13_121213| [-0.84696 -0.20512]]
21Feb13_121213|-- Bias --
21Feb13_121213|[-0.90212  0.80792]
21Feb13_121213|Predicting the validation and test data with the Best final individual.
21Feb13_121221| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_121221|-----------  ------------------  --------------------  ----------
21Feb13_121221|Validation         42.00                  36            0.00000
21Feb13_121221|   Test            25.72                  36            0.42491
21Feb13_121221|-------------------- Test #4 --------------------
21Feb13_121221|Best final individual weights
21Feb13_121221|Individual:
21Feb13_121221|-- Constant hidden layers --
21Feb13_121221|False
21Feb13_121221|Layer 0:
21Feb13_121221|-- Config --
21Feb13_121221|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121221|-- Weights --
21Feb13_121221|[[ 0.63638 -0.20563 -0.46748  0.36212]
21Feb13_121221| [-0.22569 -0.52990 -1.70224 -0.11042]
21Feb13_121221| [-0.01823 -0.16278 -0.33268 -1.79564]
21Feb13_121221| [ 0.44877  0.32665  0.25922  0.12485]
21Feb13_121221| [-0.24588 -2.19455 -0.08046  0.81960]
21Feb13_121221| [ 0.54427  0.28873 -1.78972  0.41910]
21Feb13_121221| [-0.69198 -0.02289 -1.92958  0.32782]
21Feb13_121221| [-0.78503  0.66093  1.37772 -1.48476]
21Feb13_121221| [ 1.54812  0.42435 -0.31442 -0.17611]
21Feb13_121221| [ 1.94045  0.79061  0.31325  0.39846]
21Feb13_121221| [ 0.81259  1.28494 -0.42398  0.73768]
21Feb13_121221| [ 0.24812 -1.03749 -0.32424 -0.22649]
21Feb13_121221| [-0.10656 -0.80897 -0.16817 -1.69896]
21Feb13_121221| [ 0.17005  2.23605 -1.56675  0.50354]
21Feb13_121221| [-0.74027 -0.07039 -0.56526  0.24764]
21Feb13_121221| [ 0.24215  1.05626 -0.61433  0.72223]
21Feb13_121221| [-3.21616 -0.99370 -0.70992 -1.26517]
21Feb13_121221| [-0.63804  0.43694  0.67759  0.11887]
21Feb13_121221| [-0.03764 -1.07512  0.56036 -0.09506]
21Feb13_121221| [-0.05633  1.29383 -0.65992  0.07654]
21Feb13_121221| [ 0.54311  0.30714  1.42644  2.72569]
21Feb13_121221| [-1.00185 -0.09399 -0.43646 -0.97593]
21Feb13_121221| [ 0.78104  0.64037 -0.07888 -0.94235]
21Feb13_121221| [ 0.36292 -2.09381 -0.14759 -0.57450]
21Feb13_121221| [ 0.98177  0.47143 -0.71689  0.87222]
21Feb13_121221| [ 0.64560 -1.51019 -0.08943  0.17061]
21Feb13_121221| [-0.05811 -0.65097  1.17154  0.01508]
21Feb13_121221| [ 1.10455  0.40564  0.46023 -0.68888]
21Feb13_121221| [-0.99141  0.40317 -0.72143 -1.11914]
21Feb13_121221| [-0.57071 -0.24300  0.15319  0.12984]
21Feb13_121221| [-0.77877 -0.72042 -1.33874 -0.26930]
21Feb13_121221| [ 0.45731 -1.45936 -0.94053 -2.01562]
21Feb13_121221| [ 0.66473 -0.46017 -0.47228 -0.41096]
21Feb13_121221| [ 0.17837  0.27083 -0.01682  0.32447]
21Feb13_121221| [ 0.96631 -0.25649 -0.83279  2.07308]
21Feb13_121221| [ 0.11932  1.10674  0.87761 -1.17589]
21Feb13_121221| [-0.29668 -1.06887 -2.04195 -0.93875]
21Feb13_121221| [ 0.36581  1.00476 -1.10789 -0.30620]
21Feb13_121221| [-0.35525  1.21057  0.20561  0.43313]
21Feb13_121221| [-2.02128 -1.06479  0.24020  0.09220]
21Feb13_121221| [-1.45281  1.00135 -1.07230 -1.41216]
21Feb13_121221| [-1.85581 -2.18106  1.21803  0.35416]
21Feb13_121221| [-1.08240  0.46387  0.12432  0.95257]
21Feb13_121221| [ 0.71253  0.03984 -0.79262  3.36370]
21Feb13_121221| [-0.53377 -0.94682 -1.48878 -0.46760]
21Feb13_121221| [-0.94888  0.08111  0.71320  0.19591]
21Feb13_121221| [ 0.40268 -1.63278 -0.12703  0.30461]
21Feb13_121221| [-0.27445  1.33890 -0.51833  0.80592]
21Feb13_121221| [ 0.59842 -1.09413  1.23234  0.58744]
21Feb13_121221| [-0.56340 -0.59958  1.10615 -1.02877]
21Feb13_121221| [ 0.73186  1.26425  1.56679 -0.28415]
21Feb13_121221| [ 1.61531  1.09254  0.10319 -0.96841]
21Feb13_121221| [ 0.71621 -1.06734 -1.46109  0.27923]
21Feb13_121221| [ 0.16600  0.29021  0.26385 -1.28921]
21Feb13_121221| [ 0.86279  0.35615  1.41976 -0.32959]
21Feb13_121221| [ 0.91697 -0.03368 -0.47800  0.48218]
21Feb13_121221| [ 0.34812 -0.02552 -1.17485 -0.07619]]
21Feb13_121221|-- Bias --
21Feb13_121221|[ 1.43486 -0.37836  0.90214  0.52973]
21Feb13_121221|Layer 1:
21Feb13_121221|-- Config --
21Feb13_121221|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121221|-- Weights --
21Feb13_121221|[[ 0.00473 -0.54749  0.74398]
21Feb13_121221| [-0.10074  0.03358  0.52254]
21Feb13_121221| [-0.65340  1.25823  0.80018]
21Feb13_121221| [-0.65787  0.15553 -0.28078]]
21Feb13_121221|-- Bias --
21Feb13_121221|[-0.79202  1.42146 -0.58308]
21Feb13_121221|Layer 2:
21Feb13_121221|-- Config --
21Feb13_121221|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121221|-- Weights --
21Feb13_121221|[[ 0.10221  0.77446 -0.37401 -0.20485  0.06422]
21Feb13_121221| [-0.98663  0.10920 -0.48505 -0.60013  0.32397]
21Feb13_121221| [-0.58271  0.81561 -0.47697  0.99162 -0.51476]]
21Feb13_121221|-- Bias --
21Feb13_121221|[ 0.34898  0.20875 -0.68469 -0.24530  0.12589]
21Feb13_121221|Layer 3:
21Feb13_121221|-- Config --
21Feb13_121221|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121221|-- Weights --
21Feb13_121221|[[-1.05547 -1.17480]
21Feb13_121221| [ 0.43780  1.28908]
21Feb13_121221| [-1.15457  0.60478]
21Feb13_121221| [-0.50464 -0.51282]
21Feb13_121221| [-0.84696 -0.20512]]
21Feb13_121221|-- Bias --
21Feb13_121221|[-0.90212  0.80792]
21Feb13_121221|Predicting the validation and test data with the Best final individual.
21Feb13_121229| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_121229|-----------  ------------------  --------------------  ----------
21Feb13_121229|Validation         29.30                  36            0.46119
21Feb13_121229|   Test            25.20                  36            0.47831
21Feb13_121229|-------------------- Test #5 --------------------
21Feb13_121229|Best final individual weights
21Feb13_121229|Individual:
21Feb13_121229|-- Constant hidden layers --
21Feb13_121229|False
21Feb13_121229|Layer 0:
21Feb13_121229|-- Config --
21Feb13_121229|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121229|-- Weights --
21Feb13_121229|[[ 0.63638 -0.20563 -0.46748  0.36212]
21Feb13_121229| [-0.22569 -0.52990 -1.70224 -0.11042]
21Feb13_121229| [-0.01823 -0.16278 -0.33268 -1.79564]
21Feb13_121229| [ 0.44877  0.32665  0.25922  0.12485]
21Feb13_121229| [-0.24588 -2.19455 -0.08046  0.81960]
21Feb13_121229| [ 0.54427  0.28873 -1.78972  0.41910]
21Feb13_121229| [-0.69198 -0.02289 -1.92958  0.32782]
21Feb13_121229| [-0.78503  0.66093  1.37772 -1.48476]
21Feb13_121229| [ 1.54812  0.42435 -0.31442 -0.17611]
21Feb13_121229| [ 1.94045  0.79061  0.31325  0.39846]
21Feb13_121229| [ 0.81259  1.28494 -0.42398  0.73768]
21Feb13_121229| [ 0.24812 -1.03749 -0.32424 -0.22649]
21Feb13_121229| [-0.10656 -0.80897 -0.16817 -1.69896]
21Feb13_121229| [ 0.17005  2.23605 -1.56675  0.50354]
21Feb13_121229| [-0.74027 -0.07039 -0.56526  0.24764]
21Feb13_121229| [ 0.24215  1.05626 -0.61433  0.72223]
21Feb13_121229| [-3.21616 -0.99370 -0.70992 -1.26517]
21Feb13_121229| [-0.63804  0.43694  0.67759  0.11887]
21Feb13_121229| [-0.03764 -1.07512  0.56036 -0.09506]
21Feb13_121229| [-0.05633  1.29383 -0.65992  0.07654]
21Feb13_121229| [ 0.54311  0.30714  1.42644  2.72569]
21Feb13_121229| [-1.00185 -0.09399 -0.43646 -0.97593]
21Feb13_121229| [ 0.78104  0.64037 -0.07888 -0.94235]
21Feb13_121229| [ 0.36292 -2.09381 -0.14759 -0.57450]
21Feb13_121229| [ 0.98177  0.47143 -0.71689  0.87222]
21Feb13_121229| [ 0.64560 -1.51019 -0.08943  0.17061]
21Feb13_121229| [-0.05811 -0.65097  1.17154  0.01508]
21Feb13_121229| [ 1.10455  0.40564  0.46023 -0.68888]
21Feb13_121229| [-0.99141  0.40317 -0.72143 -1.11914]
21Feb13_121229| [-0.57071 -0.24300  0.15319  0.12984]
21Feb13_121229| [-0.77877 -0.72042 -1.33874 -0.26930]
21Feb13_121229| [ 0.45731 -1.45936 -0.94053 -2.01562]
21Feb13_121229| [ 0.66473 -0.46017 -0.47228 -0.41096]
21Feb13_121229| [ 0.17837  0.27083 -0.01682  0.32447]
21Feb13_121229| [ 0.96631 -0.25649 -0.83279  2.07308]
21Feb13_121229| [ 0.11932  1.10674  0.87761 -1.17589]
21Feb13_121229| [-0.29668 -1.06887 -2.04195 -0.93875]
21Feb13_121229| [ 0.36581  1.00476 -1.10789 -0.30620]
21Feb13_121229| [-0.35525  1.21057  0.20561  0.43313]
21Feb13_121229| [-2.02128 -1.06479  0.24020  0.09220]
21Feb13_121229| [-1.45281  1.00135 -1.07230 -1.41216]
21Feb13_121229| [-1.85581 -2.18106  1.21803  0.35416]
21Feb13_121229| [-1.08240  0.46387  0.12432  0.95257]
21Feb13_121229| [ 0.71253  0.03984 -0.79262  3.36370]
21Feb13_121229| [-0.53377 -0.94682 -1.48878 -0.46760]
21Feb13_121229| [-0.94888  0.08111  0.71320  0.19591]
21Feb13_121229| [ 0.40268 -1.63278 -0.12703  0.30461]
21Feb13_121229| [-0.27445  1.33890 -0.51833  0.80592]
21Feb13_121229| [ 0.59842 -1.09413  1.23234  0.58744]
21Feb13_121229| [-0.56340 -0.59958  1.10615 -1.02877]
21Feb13_121229| [ 0.73186  1.26425  1.56679 -0.28415]
21Feb13_121229| [ 1.61531  1.09254  0.10319 -0.96841]
21Feb13_121229| [ 0.71621 -1.06734 -1.46109  0.27923]
21Feb13_121229| [ 0.16600  0.29021  0.26385 -1.28921]
21Feb13_121229| [ 0.86279  0.35615  1.41976 -0.32959]
21Feb13_121229| [ 0.91697 -0.03368 -0.47800  0.48218]
21Feb13_121229| [ 0.34812 -0.02552 -1.17485 -0.07619]]
21Feb13_121229|-- Bias --
21Feb13_121229|[ 1.43486 -0.37836  0.90214  0.52973]
21Feb13_121229|Layer 1:
21Feb13_121229|-- Config --
21Feb13_121229|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121229|-- Weights --
21Feb13_121229|[[ 0.00473 -0.54749  0.74398]
21Feb13_121229| [-0.10074  0.03358  0.52254]
21Feb13_121229| [-0.65340  1.25823  0.80018]
21Feb13_121229| [-0.65787  0.15553 -0.28078]]
21Feb13_121229|-- Bias --
21Feb13_121229|[-0.79202  1.42146 -0.58308]
21Feb13_121229|Layer 2:
21Feb13_121229|-- Config --
21Feb13_121229|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121229|-- Weights --
21Feb13_121229|[[ 0.10221  0.77446 -0.37401 -0.20485  0.06422]
21Feb13_121229| [-0.98663  0.10920 -0.48505 -0.60013  0.32397]
21Feb13_121229| [-0.58271  0.81561 -0.47697  0.99162 -0.51476]]
21Feb13_121229|-- Bias --
21Feb13_121229|[ 0.34898  0.20875 -0.68469 -0.24530  0.12589]
21Feb13_121229|Layer 3:
21Feb13_121229|-- Config --
21Feb13_121229|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121229|-- Weights --
21Feb13_121229|[[-1.05547 -1.17480]
21Feb13_121229| [ 0.43780  1.28908]
21Feb13_121229| [-1.15457  0.60478]
21Feb13_121229| [-0.50464 -0.51282]
21Feb13_121229| [-0.84696 -0.20512]]
21Feb13_121229|-- Bias --
21Feb13_121229|[-0.90212  0.80792]
21Feb13_121229|Predicting the validation and test data with the Best final individual.
21Feb13_121236| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_121236|-----------  ------------------  --------------------  ----------
21Feb13_121236|Validation         30.43                  36            0.42837
21Feb13_121236|   Test            26.15                  36            0.40140
21Feb13_121236|-------------------- Test #6 --------------------
21Feb13_121236|Best final individual weights
21Feb13_121236|Individual:
21Feb13_121236|-- Constant hidden layers --
21Feb13_121236|False
21Feb13_121236|Layer 0:
21Feb13_121236|-- Config --
21Feb13_121236|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121236|-- Weights --
21Feb13_121236|[[ 0.63638 -0.20563 -0.46748  0.36212]
21Feb13_121236| [-0.22569 -0.52990 -1.70224 -0.11042]
21Feb13_121236| [-0.01823 -0.16278 -0.33268 -1.79564]
21Feb13_121236| [ 0.44877  0.32665  0.25922  0.12485]
21Feb13_121236| [-0.24588 -2.19455 -0.08046  0.81960]
21Feb13_121236| [ 0.54427  0.28873 -1.78972  0.41910]
21Feb13_121236| [-0.69198 -0.02289 -1.92958  0.32782]
21Feb13_121236| [-0.78503  0.66093  1.37772 -1.48476]
21Feb13_121236| [ 1.54812  0.42435 -0.31442 -0.17611]
21Feb13_121236| [ 1.94045  0.79061  0.31325  0.39846]
21Feb13_121236| [ 0.81259  1.28494 -0.42398  0.73768]
21Feb13_121236| [ 0.24812 -1.03749 -0.32424 -0.22649]
21Feb13_121236| [-0.10656 -0.80897 -0.16817 -1.69896]
21Feb13_121236| [ 0.17005  2.23605 -1.56675  0.50354]
21Feb13_121236| [-0.74027 -0.07039 -0.56526  0.24764]
21Feb13_121236| [ 0.24215  1.05626 -0.61433  0.72223]
21Feb13_121236| [-3.21616 -0.99370 -0.70992 -1.26517]
21Feb13_121236| [-0.63804  0.43694  0.67759  0.11887]
21Feb13_121236| [-0.03764 -1.07512  0.56036 -0.09506]
21Feb13_121236| [-0.05633  1.29383 -0.65992  0.07654]
21Feb13_121236| [ 0.54311  0.30714  1.42644  2.72569]
21Feb13_121236| [-1.00185 -0.09399 -0.43646 -0.97593]
21Feb13_121236| [ 0.78104  0.64037 -0.07888 -0.94235]
21Feb13_121236| [ 0.36292 -2.09381 -0.14759 -0.57450]
21Feb13_121236| [ 0.98177  0.47143 -0.71689  0.87222]
21Feb13_121236| [ 0.64560 -1.51019 -0.08943  0.17061]
21Feb13_121236| [-0.05811 -0.65097  1.17154  0.01508]
21Feb13_121236| [ 1.10455  0.40564  0.46023 -0.68888]
21Feb13_121236| [-0.99141  0.40317 -0.72143 -1.11914]
21Feb13_121236| [-0.57071 -0.24300  0.15319  0.12984]
21Feb13_121236| [-0.77877 -0.72042 -1.33874 -0.26930]
21Feb13_121236| [ 0.45731 -1.45936 -0.94053 -2.01562]
21Feb13_121236| [ 0.66473 -0.46017 -0.47228 -0.41096]
21Feb13_121236| [ 0.17837  0.27083 -0.01682  0.32447]
21Feb13_121236| [ 0.96631 -0.25649 -0.83279  2.07308]
21Feb13_121236| [ 0.11932  1.10674  0.87761 -1.17589]
21Feb13_121236| [-0.29668 -1.06887 -2.04195 -0.93875]
21Feb13_121236| [ 0.36581  1.00476 -1.10789 -0.30620]
21Feb13_121236| [-0.35525  1.21057  0.20561  0.43313]
21Feb13_121236| [-2.02128 -1.06479  0.24020  0.09220]
21Feb13_121236| [-1.45281  1.00135 -1.07230 -1.41216]
21Feb13_121236| [-1.85581 -2.18106  1.21803  0.35416]
21Feb13_121236| [-1.08240  0.46387  0.12432  0.95257]
21Feb13_121236| [ 0.71253  0.03984 -0.79262  3.36370]
21Feb13_121236| [-0.53377 -0.94682 -1.48878 -0.46760]
21Feb13_121236| [-0.94888  0.08111  0.71320  0.19591]
21Feb13_121236| [ 0.40268 -1.63278 -0.12703  0.30461]
21Feb13_121236| [-0.27445  1.33890 -0.51833  0.80592]
21Feb13_121236| [ 0.59842 -1.09413  1.23234  0.58744]
21Feb13_121236| [-0.56340 -0.59958  1.10615 -1.02877]
21Feb13_121236| [ 0.73186  1.26425  1.56679 -0.28415]
21Feb13_121236| [ 1.61531  1.09254  0.10319 -0.96841]
21Feb13_121236| [ 0.71621 -1.06734 -1.46109  0.27923]
21Feb13_121236| [ 0.16600  0.29021  0.26385 -1.28921]
21Feb13_121236| [ 0.86279  0.35615  1.41976 -0.32959]
21Feb13_121236| [ 0.91697 -0.03368 -0.47800  0.48218]
21Feb13_121236| [ 0.34812 -0.02552 -1.17485 -0.07619]]
21Feb13_121236|-- Bias --
21Feb13_121236|[ 1.43486 -0.37836  0.90214  0.52973]
21Feb13_121236|Layer 1:
21Feb13_121236|-- Config --
21Feb13_121236|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121236|-- Weights --
21Feb13_121236|[[ 0.00473 -0.54749  0.74398]
21Feb13_121236| [-0.10074  0.03358  0.52254]
21Feb13_121236| [-0.65340  1.25823  0.80018]
21Feb13_121236| [-0.65787  0.15553 -0.28078]]
21Feb13_121236|-- Bias --
21Feb13_121236|[-0.79202  1.42146 -0.58308]
21Feb13_121236|Layer 2:
21Feb13_121236|-- Config --
21Feb13_121236|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121236|-- Weights --
21Feb13_121236|[[ 0.10221  0.77446 -0.37401 -0.20485  0.06422]
21Feb13_121236| [-0.98663  0.10920 -0.48505 -0.60013  0.32397]
21Feb13_121236| [-0.58271  0.81561 -0.47697  0.99162 -0.51476]]
21Feb13_121236|-- Bias --
21Feb13_121236|[ 0.34898  0.20875 -0.68469 -0.24530  0.12589]
21Feb13_121236|Layer 3:
21Feb13_121236|-- Config --
21Feb13_121236|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121236|-- Weights --
21Feb13_121236|[[-1.05547 -1.17480]
21Feb13_121236| [ 0.43780  1.28908]
21Feb13_121236| [-1.15457  0.60478]
21Feb13_121236| [-0.50464 -0.51282]
21Feb13_121236| [-0.84696 -0.20512]]
21Feb13_121236|-- Bias --
21Feb13_121236|[-0.90212  0.80792]
21Feb13_121236|Predicting the validation and test data with the Best final individual.
21Feb13_121244| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_121244|-----------  ------------------  --------------------  ----------
21Feb13_121244|Validation         42.00                  36            0.00000
21Feb13_121244|   Test            36.40                  36            0.00000
21Feb13_121244|-------------------- Test #7 --------------------
21Feb13_121244|Best final individual weights
21Feb13_121244|Individual:
21Feb13_121244|-- Constant hidden layers --
21Feb13_121244|False
21Feb13_121244|Layer 0:
21Feb13_121244|-- Config --
21Feb13_121244|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121244|-- Weights --
21Feb13_121244|[[ 0.63638 -0.20563 -0.46748  0.36212]
21Feb13_121244| [-0.22569 -0.52990 -1.70224 -0.11042]
21Feb13_121244| [-0.01823 -0.16278 -0.33268 -1.79564]
21Feb13_121244| [ 0.44877  0.32665  0.25922  0.12485]
21Feb13_121244| [-0.24588 -2.19455 -0.08046  0.81960]
21Feb13_121244| [ 0.54427  0.28873 -1.78972  0.41910]
21Feb13_121244| [-0.69198 -0.02289 -1.92958  0.32782]
21Feb13_121244| [-0.78503  0.66093  1.37772 -1.48476]
21Feb13_121244| [ 1.54812  0.42435 -0.31442 -0.17611]
21Feb13_121244| [ 1.94045  0.79061  0.31325  0.39846]
21Feb13_121244| [ 0.81259  1.28494 -0.42398  0.73768]
21Feb13_121244| [ 0.24812 -1.03749 -0.32424 -0.22649]
21Feb13_121244| [-0.10656 -0.80897 -0.16817 -1.69896]
21Feb13_121244| [ 0.17005  2.23605 -1.56675  0.50354]
21Feb13_121244| [-0.74027 -0.07039 -0.56526  0.24764]
21Feb13_121244| [ 0.24215  1.05626 -0.61433  0.72223]
21Feb13_121244| [-3.21616 -0.99370 -0.70992 -1.26517]
21Feb13_121244| [-0.63804  0.43694  0.67759  0.11887]
21Feb13_121244| [-0.03764 -1.07512  0.56036 -0.09506]
21Feb13_121244| [-0.05633  1.29383 -0.65992  0.07654]
21Feb13_121244| [ 0.54311  0.30714  1.42644  2.72569]
21Feb13_121244| [-1.00185 -0.09399 -0.43646 -0.97593]
21Feb13_121244| [ 0.78104  0.64037 -0.07888 -0.94235]
21Feb13_121244| [ 0.36292 -2.09381 -0.14759 -0.57450]
21Feb13_121244| [ 0.98177  0.47143 -0.71689  0.87222]
21Feb13_121244| [ 0.64560 -1.51019 -0.08943  0.17061]
21Feb13_121244| [-0.05811 -0.65097  1.17154  0.01508]
21Feb13_121244| [ 1.10455  0.40564  0.46023 -0.68888]
21Feb13_121244| [-0.99141  0.40317 -0.72143 -1.11914]
21Feb13_121244| [-0.57071 -0.24300  0.15319  0.12984]
21Feb13_121244| [-0.77877 -0.72042 -1.33874 -0.26930]
21Feb13_121244| [ 0.45731 -1.45936 -0.94053 -2.01562]
21Feb13_121244| [ 0.66473 -0.46017 -0.47228 -0.41096]
21Feb13_121244| [ 0.17837  0.27083 -0.01682  0.32447]
21Feb13_121244| [ 0.96631 -0.25649 -0.83279  2.07308]
21Feb13_121244| [ 0.11932  1.10674  0.87761 -1.17589]
21Feb13_121244| [-0.29668 -1.06887 -2.04195 -0.93875]
21Feb13_121244| [ 0.36581  1.00476 -1.10789 -0.30620]
21Feb13_121244| [-0.35525  1.21057  0.20561  0.43313]
21Feb13_121244| [-2.02128 -1.06479  0.24020  0.09220]
21Feb13_121244| [-1.45281  1.00135 -1.07230 -1.41216]
21Feb13_121244| [-1.85581 -2.18106  1.21803  0.35416]
21Feb13_121244| [-1.08240  0.46387  0.12432  0.95257]
21Feb13_121244| [ 0.71253  0.03984 -0.79262  3.36370]
21Feb13_121244| [-0.53377 -0.94682 -1.48878 -0.46760]
21Feb13_121244| [-0.94888  0.08111  0.71320  0.19591]
21Feb13_121244| [ 0.40268 -1.63278 -0.12703  0.30461]
21Feb13_121244| [-0.27445  1.33890 -0.51833  0.80592]
21Feb13_121244| [ 0.59842 -1.09413  1.23234  0.58744]
21Feb13_121244| [-0.56340 -0.59958  1.10615 -1.02877]
21Feb13_121244| [ 0.73186  1.26425  1.56679 -0.28415]
21Feb13_121244| [ 1.61531  1.09254  0.10319 -0.96841]
21Feb13_121244| [ 0.71621 -1.06734 -1.46109  0.27923]
21Feb13_121244| [ 0.16600  0.29021  0.26385 -1.28921]
21Feb13_121244| [ 0.86279  0.35615  1.41976 -0.32959]
21Feb13_121244| [ 0.91697 -0.03368 -0.47800  0.48218]
21Feb13_121244| [ 0.34812 -0.02552 -1.17485 -0.07619]]
21Feb13_121244|-- Bias --
21Feb13_121244|[ 1.43486 -0.37836  0.90214  0.52973]
21Feb13_121244|Layer 1:
21Feb13_121244|-- Config --
21Feb13_121244|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121244|-- Weights --
21Feb13_121244|[[ 0.00473 -0.54749  0.74398]
21Feb13_121244| [-0.10074  0.03358  0.52254]
21Feb13_121244| [-0.65340  1.25823  0.80018]
21Feb13_121244| [-0.65787  0.15553 -0.28078]]
21Feb13_121244|-- Bias --
21Feb13_121244|[-0.79202  1.42146 -0.58308]
21Feb13_121244|Layer 2:
21Feb13_121244|-- Config --
21Feb13_121244|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121244|-- Weights --
21Feb13_121244|[[ 0.10221  0.77446 -0.37401 -0.20485  0.06422]
21Feb13_121244| [-0.98663  0.10920 -0.48505 -0.60013  0.32397]
21Feb13_121244| [-0.58271  0.81561 -0.47697  0.99162 -0.51476]]
21Feb13_121244|-- Bias --
21Feb13_121244|[ 0.34898  0.20875 -0.68469 -0.24530  0.12589]
21Feb13_121244|Layer 3:
21Feb13_121244|-- Config --
21Feb13_121244|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121244|-- Weights --
21Feb13_121244|[[-1.05547 -1.17480]
21Feb13_121244| [ 0.43780  1.28908]
21Feb13_121244| [-1.15457  0.60478]
21Feb13_121244| [-0.50464 -0.51282]
21Feb13_121244| [-0.84696 -0.20512]]
21Feb13_121244|-- Bias --
21Feb13_121244|[-0.90212  0.80792]
21Feb13_121244|Predicting the validation and test data with the Best final individual.
21Feb13_121252| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_121252|-----------  ------------------  --------------------  ----------
21Feb13_121252|Validation         27.22                  36            0.55776
21Feb13_121252|   Test            24.24                  36            0.59713
21Feb13_121252|-------------------- Test #8 --------------------
21Feb13_121252|Best final individual weights
21Feb13_121252|Individual:
21Feb13_121252|-- Constant hidden layers --
21Feb13_121252|False
21Feb13_121252|Layer 0:
21Feb13_121252|-- Config --
21Feb13_121252|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121252|-- Weights --
21Feb13_121252|[[ 0.63638 -0.20563 -0.46748  0.36212]
21Feb13_121252| [-0.22569 -0.52990 -1.70224 -0.11042]
21Feb13_121252| [-0.01823 -0.16278 -0.33268 -1.79564]
21Feb13_121252| [ 0.44877  0.32665  0.25922  0.12485]
21Feb13_121252| [-0.24588 -2.19455 -0.08046  0.81960]
21Feb13_121252| [ 0.54427  0.28873 -1.78972  0.41910]
21Feb13_121252| [-0.69198 -0.02289 -1.92958  0.32782]
21Feb13_121252| [-0.78503  0.66093  1.37772 -1.48476]
21Feb13_121252| [ 1.54812  0.42435 -0.31442 -0.17611]
21Feb13_121252| [ 1.94045  0.79061  0.31325  0.39846]
21Feb13_121252| [ 0.81259  1.28494 -0.42398  0.73768]
21Feb13_121252| [ 0.24812 -1.03749 -0.32424 -0.22649]
21Feb13_121252| [-0.10656 -0.80897 -0.16817 -1.69896]
21Feb13_121252| [ 0.17005  2.23605 -1.56675  0.50354]
21Feb13_121252| [-0.74027 -0.07039 -0.56526  0.24764]
21Feb13_121252| [ 0.24215  1.05626 -0.61433  0.72223]
21Feb13_121252| [-3.21616 -0.99370 -0.70992 -1.26517]
21Feb13_121252| [-0.63804  0.43694  0.67759  0.11887]
21Feb13_121252| [-0.03764 -1.07512  0.56036 -0.09506]
21Feb13_121252| [-0.05633  1.29383 -0.65992  0.07654]
21Feb13_121252| [ 0.54311  0.30714  1.42644  2.72569]
21Feb13_121252| [-1.00185 -0.09399 -0.43646 -0.97593]
21Feb13_121252| [ 0.78104  0.64037 -0.07888 -0.94235]
21Feb13_121252| [ 0.36292 -2.09381 -0.14759 -0.57450]
21Feb13_121252| [ 0.98177  0.47143 -0.71689  0.87222]
21Feb13_121252| [ 0.64560 -1.51019 -0.08943  0.17061]
21Feb13_121252| [-0.05811 -0.65097  1.17154  0.01508]
21Feb13_121252| [ 1.10455  0.40564  0.46023 -0.68888]
21Feb13_121252| [-0.99141  0.40317 -0.72143 -1.11914]
21Feb13_121252| [-0.57071 -0.24300  0.15319  0.12984]
21Feb13_121252| [-0.77877 -0.72042 -1.33874 -0.26930]
21Feb13_121252| [ 0.45731 -1.45936 -0.94053 -2.01562]
21Feb13_121252| [ 0.66473 -0.46017 -0.47228 -0.41096]
21Feb13_121252| [ 0.17837  0.27083 -0.01682  0.32447]
21Feb13_121252| [ 0.96631 -0.25649 -0.83279  2.07308]
21Feb13_121252| [ 0.11932  1.10674  0.87761 -1.17589]
21Feb13_121252| [-0.29668 -1.06887 -2.04195 -0.93875]
21Feb13_121252| [ 0.36581  1.00476 -1.10789 -0.30620]
21Feb13_121252| [-0.35525  1.21057  0.20561  0.43313]
21Feb13_121252| [-2.02128 -1.06479  0.24020  0.09220]
21Feb13_121252| [-1.45281  1.00135 -1.07230 -1.41216]
21Feb13_121252| [-1.85581 -2.18106  1.21803  0.35416]
21Feb13_121252| [-1.08240  0.46387  0.12432  0.95257]
21Feb13_121252| [ 0.71253  0.03984 -0.79262  3.36370]
21Feb13_121252| [-0.53377 -0.94682 -1.48878 -0.46760]
21Feb13_121252| [-0.94888  0.08111  0.71320  0.19591]
21Feb13_121252| [ 0.40268 -1.63278 -0.12703  0.30461]
21Feb13_121252| [-0.27445  1.33890 -0.51833  0.80592]
21Feb13_121252| [ 0.59842 -1.09413  1.23234  0.58744]
21Feb13_121252| [-0.56340 -0.59958  1.10615 -1.02877]
21Feb13_121252| [ 0.73186  1.26425  1.56679 -0.28415]
21Feb13_121252| [ 1.61531  1.09254  0.10319 -0.96841]
21Feb13_121252| [ 0.71621 -1.06734 -1.46109  0.27923]
21Feb13_121252| [ 0.16600  0.29021  0.26385 -1.28921]
21Feb13_121252| [ 0.86279  0.35615  1.41976 -0.32959]
21Feb13_121252| [ 0.91697 -0.03368 -0.47800  0.48218]
21Feb13_121252| [ 0.34812 -0.02552 -1.17485 -0.07619]]
21Feb13_121252|-- Bias --
21Feb13_121252|[ 1.43486 -0.37836  0.90214  0.52973]
21Feb13_121252|Layer 1:
21Feb13_121252|-- Config --
21Feb13_121252|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121252|-- Weights --
21Feb13_121252|[[ 0.00473 -0.54749  0.74398]
21Feb13_121252| [-0.10074  0.03358  0.52254]
21Feb13_121252| [-0.65340  1.25823  0.80018]
21Feb13_121252| [-0.65787  0.15553 -0.28078]]
21Feb13_121252|-- Bias --
21Feb13_121252|[-0.79202  1.42146 -0.58308]
21Feb13_121252|Layer 2:
21Feb13_121252|-- Config --
21Feb13_121252|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121252|-- Weights --
21Feb13_121252|[[ 0.10221  0.77446 -0.37401 -0.20485  0.06422]
21Feb13_121252| [-0.98663  0.10920 -0.48505 -0.60013  0.32397]
21Feb13_121252| [-0.58271  0.81561 -0.47697  0.99162 -0.51476]]
21Feb13_121252|-- Bias --
21Feb13_121252|[ 0.34898  0.20875 -0.68469 -0.24530  0.12589]
21Feb13_121252|Layer 3:
21Feb13_121252|-- Config --
21Feb13_121252|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121252|-- Weights --
21Feb13_121252|[[-1.05547 -1.17480]
21Feb13_121252| [ 0.43780  1.28908]
21Feb13_121252| [-1.15457  0.60478]
21Feb13_121252| [-0.50464 -0.51282]
21Feb13_121252| [-0.84696 -0.20512]]
21Feb13_121252|-- Bias --
21Feb13_121252|[-0.90212  0.80792]
21Feb13_121252|Predicting the validation and test data with the Best final individual.
21Feb13_121300| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_121300|-----------  ------------------  --------------------  ----------
21Feb13_121300|Validation         27.57                  36            0.52018
21Feb13_121300|   Test            25.02                  36            0.55807
21Feb13_121300|-------------------- Test #9 --------------------
21Feb13_121300|Best final individual weights
21Feb13_121300|Individual:
21Feb13_121300|-- Constant hidden layers --
21Feb13_121300|False
21Feb13_121300|Layer 0:
21Feb13_121300|-- Config --
21Feb13_121300|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121300|-- Weights --
21Feb13_121300|[[ 0.63638 -0.20563 -0.46748  0.36212]
21Feb13_121300| [-0.22569 -0.52990 -1.70224 -0.11042]
21Feb13_121300| [-0.01823 -0.16278 -0.33268 -1.79564]
21Feb13_121300| [ 0.44877  0.32665  0.25922  0.12485]
21Feb13_121300| [-0.24588 -2.19455 -0.08046  0.81960]
21Feb13_121300| [ 0.54427  0.28873 -1.78972  0.41910]
21Feb13_121300| [-0.69198 -0.02289 -1.92958  0.32782]
21Feb13_121300| [-0.78503  0.66093  1.37772 -1.48476]
21Feb13_121300| [ 1.54812  0.42435 -0.31442 -0.17611]
21Feb13_121300| [ 1.94045  0.79061  0.31325  0.39846]
21Feb13_121300| [ 0.81259  1.28494 -0.42398  0.73768]
21Feb13_121300| [ 0.24812 -1.03749 -0.32424 -0.22649]
21Feb13_121300| [-0.10656 -0.80897 -0.16817 -1.69896]
21Feb13_121300| [ 0.17005  2.23605 -1.56675  0.50354]
21Feb13_121300| [-0.74027 -0.07039 -0.56526  0.24764]
21Feb13_121300| [ 0.24215  1.05626 -0.61433  0.72223]
21Feb13_121300| [-3.21616 -0.99370 -0.70992 -1.26517]
21Feb13_121300| [-0.63804  0.43694  0.67759  0.11887]
21Feb13_121300| [-0.03764 -1.07512  0.56036 -0.09506]
21Feb13_121300| [-0.05633  1.29383 -0.65992  0.07654]
21Feb13_121300| [ 0.54311  0.30714  1.42644  2.72569]
21Feb13_121300| [-1.00185 -0.09399 -0.43646 -0.97593]
21Feb13_121300| [ 0.78104  0.64037 -0.07888 -0.94235]
21Feb13_121300| [ 0.36292 -2.09381 -0.14759 -0.57450]
21Feb13_121300| [ 0.98177  0.47143 -0.71689  0.87222]
21Feb13_121300| [ 0.64560 -1.51019 -0.08943  0.17061]
21Feb13_121300| [-0.05811 -0.65097  1.17154  0.01508]
21Feb13_121300| [ 1.10455  0.40564  0.46023 -0.68888]
21Feb13_121300| [-0.99141  0.40317 -0.72143 -1.11914]
21Feb13_121300| [-0.57071 -0.24300  0.15319  0.12984]
21Feb13_121300| [-0.77877 -0.72042 -1.33874 -0.26930]
21Feb13_121300| [ 0.45731 -1.45936 -0.94053 -2.01562]
21Feb13_121300| [ 0.66473 -0.46017 -0.47228 -0.41096]
21Feb13_121300| [ 0.17837  0.27083 -0.01682  0.32447]
21Feb13_121300| [ 0.96631 -0.25649 -0.83279  2.07308]
21Feb13_121300| [ 0.11932  1.10674  0.87761 -1.17589]
21Feb13_121300| [-0.29668 -1.06887 -2.04195 -0.93875]
21Feb13_121300| [ 0.36581  1.00476 -1.10789 -0.30620]
21Feb13_121300| [-0.35525  1.21057  0.20561  0.43313]
21Feb13_121300| [-2.02128 -1.06479  0.24020  0.09220]
21Feb13_121300| [-1.45281  1.00135 -1.07230 -1.41216]
21Feb13_121300| [-1.85581 -2.18106  1.21803  0.35416]
21Feb13_121300| [-1.08240  0.46387  0.12432  0.95257]
21Feb13_121300| [ 0.71253  0.03984 -0.79262  3.36370]
21Feb13_121300| [-0.53377 -0.94682 -1.48878 -0.46760]
21Feb13_121300| [-0.94888  0.08111  0.71320  0.19591]
21Feb13_121300| [ 0.40268 -1.63278 -0.12703  0.30461]
21Feb13_121300| [-0.27445  1.33890 -0.51833  0.80592]
21Feb13_121300| [ 0.59842 -1.09413  1.23234  0.58744]
21Feb13_121300| [-0.56340 -0.59958  1.10615 -1.02877]
21Feb13_121300| [ 0.73186  1.26425  1.56679 -0.28415]
21Feb13_121300| [ 1.61531  1.09254  0.10319 -0.96841]
21Feb13_121300| [ 0.71621 -1.06734 -1.46109  0.27923]
21Feb13_121300| [ 0.16600  0.29021  0.26385 -1.28921]
21Feb13_121300| [ 0.86279  0.35615  1.41976 -0.32959]
21Feb13_121300| [ 0.91697 -0.03368 -0.47800  0.48218]
21Feb13_121300| [ 0.34812 -0.02552 -1.17485 -0.07619]]
21Feb13_121300|-- Bias --
21Feb13_121300|[ 1.43486 -0.37836  0.90214  0.52973]
21Feb13_121300|Layer 1:
21Feb13_121300|-- Config --
21Feb13_121300|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121300|-- Weights --
21Feb13_121300|[[ 0.00473 -0.54749  0.74398]
21Feb13_121300| [-0.10074  0.03358  0.52254]
21Feb13_121300| [-0.65340  1.25823  0.80018]
21Feb13_121300| [-0.65787  0.15553 -0.28078]]
21Feb13_121300|-- Bias --
21Feb13_121300|[-0.79202  1.42146 -0.58308]
21Feb13_121300|Layer 2:
21Feb13_121300|-- Config --
21Feb13_121300|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121300|-- Weights --
21Feb13_121300|[[ 0.10221  0.77446 -0.37401 -0.20485  0.06422]
21Feb13_121300| [-0.98663  0.10920 -0.48505 -0.60013  0.32397]
21Feb13_121300| [-0.58271  0.81561 -0.47697  0.99162 -0.51476]]
21Feb13_121300|-- Bias --
21Feb13_121300|[ 0.34898  0.20875 -0.68469 -0.24530  0.12589]
21Feb13_121300|Layer 3:
21Feb13_121300|-- Config --
21Feb13_121300|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121300|-- Weights --
21Feb13_121300|[[-1.05547 -1.17480]
21Feb13_121300| [ 0.43780  1.28908]
21Feb13_121300| [-1.15457  0.60478]
21Feb13_121300| [-0.50464 -0.51282]
21Feb13_121300| [-0.84696 -0.20512]]
21Feb13_121300|-- Bias --
21Feb13_121300|[-0.90212  0.80792]
21Feb13_121300|Predicting the validation and test data with the Best final individual.
21Feb13_121307| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_121307|-----------  ------------------  --------------------  ----------
21Feb13_121307|Validation         27.48                  36            0.53802
21Feb13_121307|   Test            25.20                  36            0.52578
21Feb13_121307|-------------------- Test #10 --------------------
21Feb13_121307|Best final individual weights
21Feb13_121307|Individual:
21Feb13_121307|-- Constant hidden layers --
21Feb13_121307|False
21Feb13_121307|Layer 0:
21Feb13_121307|-- Config --
21Feb13_121307|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121307|-- Weights --
21Feb13_121307|[[ 0.63638 -0.20563 -0.46748  0.36212]
21Feb13_121307| [-0.22569 -0.52990 -1.70224 -0.11042]
21Feb13_121307| [-0.01823 -0.16278 -0.33268 -1.79564]
21Feb13_121307| [ 0.44877  0.32665  0.25922  0.12485]
21Feb13_121307| [-0.24588 -2.19455 -0.08046  0.81960]
21Feb13_121307| [ 0.54427  0.28873 -1.78972  0.41910]
21Feb13_121307| [-0.69198 -0.02289 -1.92958  0.32782]
21Feb13_121307| [-0.78503  0.66093  1.37772 -1.48476]
21Feb13_121307| [ 1.54812  0.42435 -0.31442 -0.17611]
21Feb13_121307| [ 1.94045  0.79061  0.31325  0.39846]
21Feb13_121307| [ 0.81259  1.28494 -0.42398  0.73768]
21Feb13_121307| [ 0.24812 -1.03749 -0.32424 -0.22649]
21Feb13_121307| [-0.10656 -0.80897 -0.16817 -1.69896]
21Feb13_121307| [ 0.17005  2.23605 -1.56675  0.50354]
21Feb13_121307| [-0.74027 -0.07039 -0.56526  0.24764]
21Feb13_121307| [ 0.24215  1.05626 -0.61433  0.72223]
21Feb13_121307| [-3.21616 -0.99370 -0.70992 -1.26517]
21Feb13_121307| [-0.63804  0.43694  0.67759  0.11887]
21Feb13_121307| [-0.03764 -1.07512  0.56036 -0.09506]
21Feb13_121307| [-0.05633  1.29383 -0.65992  0.07654]
21Feb13_121307| [ 0.54311  0.30714  1.42644  2.72569]
21Feb13_121307| [-1.00185 -0.09399 -0.43646 -0.97593]
21Feb13_121307| [ 0.78104  0.64037 -0.07888 -0.94235]
21Feb13_121307| [ 0.36292 -2.09381 -0.14759 -0.57450]
21Feb13_121307| [ 0.98177  0.47143 -0.71689  0.87222]
21Feb13_121307| [ 0.64560 -1.51019 -0.08943  0.17061]
21Feb13_121307| [-0.05811 -0.65097  1.17154  0.01508]
21Feb13_121307| [ 1.10455  0.40564  0.46023 -0.68888]
21Feb13_121307| [-0.99141  0.40317 -0.72143 -1.11914]
21Feb13_121307| [-0.57071 -0.24300  0.15319  0.12984]
21Feb13_121307| [-0.77877 -0.72042 -1.33874 -0.26930]
21Feb13_121307| [ 0.45731 -1.45936 -0.94053 -2.01562]
21Feb13_121307| [ 0.66473 -0.46017 -0.47228 -0.41096]
21Feb13_121307| [ 0.17837  0.27083 -0.01682  0.32447]
21Feb13_121307| [ 0.96631 -0.25649 -0.83279  2.07308]
21Feb13_121307| [ 0.11932  1.10674  0.87761 -1.17589]
21Feb13_121307| [-0.29668 -1.06887 -2.04195 -0.93875]
21Feb13_121307| [ 0.36581  1.00476 -1.10789 -0.30620]
21Feb13_121307| [-0.35525  1.21057  0.20561  0.43313]
21Feb13_121307| [-2.02128 -1.06479  0.24020  0.09220]
21Feb13_121307| [-1.45281  1.00135 -1.07230 -1.41216]
21Feb13_121307| [-1.85581 -2.18106  1.21803  0.35416]
21Feb13_121307| [-1.08240  0.46387  0.12432  0.95257]
21Feb13_121307| [ 0.71253  0.03984 -0.79262  3.36370]
21Feb13_121307| [-0.53377 -0.94682 -1.48878 -0.46760]
21Feb13_121307| [-0.94888  0.08111  0.71320  0.19591]
21Feb13_121307| [ 0.40268 -1.63278 -0.12703  0.30461]
21Feb13_121307| [-0.27445  1.33890 -0.51833  0.80592]
21Feb13_121307| [ 0.59842 -1.09413  1.23234  0.58744]
21Feb13_121307| [-0.56340 -0.59958  1.10615 -1.02877]
21Feb13_121307| [ 0.73186  1.26425  1.56679 -0.28415]
21Feb13_121307| [ 1.61531  1.09254  0.10319 -0.96841]
21Feb13_121307| [ 0.71621 -1.06734 -1.46109  0.27923]
21Feb13_121307| [ 0.16600  0.29021  0.26385 -1.28921]
21Feb13_121307| [ 0.86279  0.35615  1.41976 -0.32959]
21Feb13_121307| [ 0.91697 -0.03368 -0.47800  0.48218]
21Feb13_121307| [ 0.34812 -0.02552 -1.17485 -0.07619]]
21Feb13_121307|-- Bias --
21Feb13_121307|[ 1.43486 -0.37836  0.90214  0.52973]
21Feb13_121307|Layer 1:
21Feb13_121307|-- Config --
21Feb13_121307|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121307|-- Weights --
21Feb13_121307|[[ 0.00473 -0.54749  0.74398]
21Feb13_121307| [-0.10074  0.03358  0.52254]
21Feb13_121307| [-0.65340  1.25823  0.80018]
21Feb13_121307| [-0.65787  0.15553 -0.28078]]
21Feb13_121307|-- Bias --
21Feb13_121307|[-0.79202  1.42146 -0.58308]
21Feb13_121307|Layer 2:
21Feb13_121307|-- Config --
21Feb13_121307|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121307|-- Weights --
21Feb13_121307|[[ 0.10221  0.77446 -0.37401 -0.20485  0.06422]
21Feb13_121307| [-0.98663  0.10920 -0.48505 -0.60013  0.32397]
21Feb13_121307| [-0.58271  0.81561 -0.47697  0.99162 -0.51476]]
21Feb13_121307|-- Bias --
21Feb13_121307|[ 0.34898  0.20875 -0.68469 -0.24530  0.12589]
21Feb13_121307|Layer 3:
21Feb13_121307|-- Config --
21Feb13_121307|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121307|-- Weights --
21Feb13_121307|[[-1.05547 -1.17480]
21Feb13_121307| [ 0.43780  1.28908]
21Feb13_121307| [-1.15457  0.60478]
21Feb13_121307| [-0.50464 -0.51282]
21Feb13_121307| [-0.84696 -0.20512]]
21Feb13_121307|-- Bias --
21Feb13_121307|[-0.90212  0.80792]
21Feb13_121307|Predicting the validation and test data with the Best final individual.
21Feb13_121315| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_121315|-----------  ------------------  --------------------  ----------
21Feb13_121315|Validation         42.00                  36            0.00000
21Feb13_121315|   Test            24.76                  36            0.59536
21Feb13_121315|-------------------- Test #11 --------------------
21Feb13_121315|Best final individual weights
21Feb13_121315|Individual:
21Feb13_121315|-- Constant hidden layers --
21Feb13_121315|False
21Feb13_121315|Layer 0:
21Feb13_121315|-- Config --
21Feb13_121315|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121315|-- Weights --
21Feb13_121315|[[ 0.63638 -0.20563 -0.46748  0.36212]
21Feb13_121315| [-0.22569 -0.52990 -1.70224 -0.11042]
21Feb13_121315| [-0.01823 -0.16278 -0.33268 -1.79564]
21Feb13_121315| [ 0.44877  0.32665  0.25922  0.12485]
21Feb13_121315| [-0.24588 -2.19455 -0.08046  0.81960]
21Feb13_121315| [ 0.54427  0.28873 -1.78972  0.41910]
21Feb13_121315| [-0.69198 -0.02289 -1.92958  0.32782]
21Feb13_121315| [-0.78503  0.66093  1.37772 -1.48476]
21Feb13_121315| [ 1.54812  0.42435 -0.31442 -0.17611]
21Feb13_121315| [ 1.94045  0.79061  0.31325  0.39846]
21Feb13_121315| [ 0.81259  1.28494 -0.42398  0.73768]
21Feb13_121315| [ 0.24812 -1.03749 -0.32424 -0.22649]
21Feb13_121315| [-0.10656 -0.80897 -0.16817 -1.69896]
21Feb13_121315| [ 0.17005  2.23605 -1.56675  0.50354]
21Feb13_121315| [-0.74027 -0.07039 -0.56526  0.24764]
21Feb13_121315| [ 0.24215  1.05626 -0.61433  0.72223]
21Feb13_121315| [-3.21616 -0.99370 -0.70992 -1.26517]
21Feb13_121315| [-0.63804  0.43694  0.67759  0.11887]
21Feb13_121315| [-0.03764 -1.07512  0.56036 -0.09506]
21Feb13_121315| [-0.05633  1.29383 -0.65992  0.07654]
21Feb13_121315| [ 0.54311  0.30714  1.42644  2.72569]
21Feb13_121315| [-1.00185 -0.09399 -0.43646 -0.97593]
21Feb13_121315| [ 0.78104  0.64037 -0.07888 -0.94235]
21Feb13_121315| [ 0.36292 -2.09381 -0.14759 -0.57450]
21Feb13_121315| [ 0.98177  0.47143 -0.71689  0.87222]
21Feb13_121315| [ 0.64560 -1.51019 -0.08943  0.17061]
21Feb13_121315| [-0.05811 -0.65097  1.17154  0.01508]
21Feb13_121315| [ 1.10455  0.40564  0.46023 -0.68888]
21Feb13_121315| [-0.99141  0.40317 -0.72143 -1.11914]
21Feb13_121315| [-0.57071 -0.24300  0.15319  0.12984]
21Feb13_121315| [-0.77877 -0.72042 -1.33874 -0.26930]
21Feb13_121315| [ 0.45731 -1.45936 -0.94053 -2.01562]
21Feb13_121315| [ 0.66473 -0.46017 -0.47228 -0.41096]
21Feb13_121315| [ 0.17837  0.27083 -0.01682  0.32447]
21Feb13_121315| [ 0.96631 -0.25649 -0.83279  2.07308]
21Feb13_121315| [ 0.11932  1.10674  0.87761 -1.17589]
21Feb13_121315| [-0.29668 -1.06887 -2.04195 -0.93875]
21Feb13_121315| [ 0.36581  1.00476 -1.10789 -0.30620]
21Feb13_121315| [-0.35525  1.21057  0.20561  0.43313]
21Feb13_121315| [-2.02128 -1.06479  0.24020  0.09220]
21Feb13_121315| [-1.45281  1.00135 -1.07230 -1.41216]
21Feb13_121315| [-1.85581 -2.18106  1.21803  0.35416]
21Feb13_121315| [-1.08240  0.46387  0.12432  0.95257]
21Feb13_121315| [ 0.71253  0.03984 -0.79262  3.36370]
21Feb13_121315| [-0.53377 -0.94682 -1.48878 -0.46760]
21Feb13_121315| [-0.94888  0.08111  0.71320  0.19591]
21Feb13_121315| [ 0.40268 -1.63278 -0.12703  0.30461]
21Feb13_121315| [-0.27445  1.33890 -0.51833  0.80592]
21Feb13_121315| [ 0.59842 -1.09413  1.23234  0.58744]
21Feb13_121315| [-0.56340 -0.59958  1.10615 -1.02877]
21Feb13_121315| [ 0.73186  1.26425  1.56679 -0.28415]
21Feb13_121315| [ 1.61531  1.09254  0.10319 -0.96841]
21Feb13_121315| [ 0.71621 -1.06734 -1.46109  0.27923]
21Feb13_121315| [ 0.16600  0.29021  0.26385 -1.28921]
21Feb13_121315| [ 0.86279  0.35615  1.41976 -0.32959]
21Feb13_121315| [ 0.91697 -0.03368 -0.47800  0.48218]
21Feb13_121315| [ 0.34812 -0.02552 -1.17485 -0.07619]]
21Feb13_121315|-- Bias --
21Feb13_121315|[ 1.43486 -0.37836  0.90214  0.52973]
21Feb13_121315|Layer 1:
21Feb13_121315|-- Config --
21Feb13_121315|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121315|-- Weights --
21Feb13_121315|[[ 0.00473 -0.54749  0.74398]
21Feb13_121315| [-0.10074  0.03358  0.52254]
21Feb13_121315| [-0.65340  1.25823  0.80018]
21Feb13_121315| [-0.65787  0.15553 -0.28078]]
21Feb13_121315|-- Bias --
21Feb13_121315|[-0.79202  1.42146 -0.58308]
21Feb13_121315|Layer 2:
21Feb13_121315|-- Config --
21Feb13_121315|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121315|-- Weights --
21Feb13_121315|[[ 0.10221  0.77446 -0.37401 -0.20485  0.06422]
21Feb13_121315| [-0.98663  0.10920 -0.48505 -0.60013  0.32397]
21Feb13_121315| [-0.58271  0.81561 -0.47697  0.99162 -0.51476]]
21Feb13_121315|-- Bias --
21Feb13_121315|[ 0.34898  0.20875 -0.68469 -0.24530  0.12589]
21Feb13_121315|Layer 3:
21Feb13_121315|-- Config --
21Feb13_121315|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121315|-- Weights --
21Feb13_121315|[[-1.05547 -1.17480]
21Feb13_121315| [ 0.43780  1.28908]
21Feb13_121315| [-1.15457  0.60478]
21Feb13_121315| [-0.50464 -0.51282]
21Feb13_121315| [-0.84696 -0.20512]]
21Feb13_121315|-- Bias --
21Feb13_121315|[-0.90212  0.80792]
21Feb13_121315|Predicting the validation and test data with the Best final individual.
21Feb13_121323| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_121323|-----------  ------------------  --------------------  ----------
21Feb13_121323|Validation         30.00                  36            0.44266
21Feb13_121323|   Test            25.54                  36            0.48571
21Feb13_121323|-------------------- Test #12 --------------------
21Feb13_121323|Best final individual weights
21Feb13_121323|Individual:
21Feb13_121323|-- Constant hidden layers --
21Feb13_121323|False
21Feb13_121323|Layer 0:
21Feb13_121323|-- Config --
21Feb13_121323|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121323|-- Weights --
21Feb13_121323|[[ 0.63638 -0.20563 -0.46748  0.36212]
21Feb13_121323| [-0.22569 -0.52990 -1.70224 -0.11042]
21Feb13_121323| [-0.01823 -0.16278 -0.33268 -1.79564]
21Feb13_121323| [ 0.44877  0.32665  0.25922  0.12485]
21Feb13_121323| [-0.24588 -2.19455 -0.08046  0.81960]
21Feb13_121323| [ 0.54427  0.28873 -1.78972  0.41910]
21Feb13_121323| [-0.69198 -0.02289 -1.92958  0.32782]
21Feb13_121323| [-0.78503  0.66093  1.37772 -1.48476]
21Feb13_121323| [ 1.54812  0.42435 -0.31442 -0.17611]
21Feb13_121323| [ 1.94045  0.79061  0.31325  0.39846]
21Feb13_121323| [ 0.81259  1.28494 -0.42398  0.73768]
21Feb13_121323| [ 0.24812 -1.03749 -0.32424 -0.22649]
21Feb13_121323| [-0.10656 -0.80897 -0.16817 -1.69896]
21Feb13_121323| [ 0.17005  2.23605 -1.56675  0.50354]
21Feb13_121323| [-0.74027 -0.07039 -0.56526  0.24764]
21Feb13_121323| [ 0.24215  1.05626 -0.61433  0.72223]
21Feb13_121323| [-3.21616 -0.99370 -0.70992 -1.26517]
21Feb13_121323| [-0.63804  0.43694  0.67759  0.11887]
21Feb13_121323| [-0.03764 -1.07512  0.56036 -0.09506]
21Feb13_121323| [-0.05633  1.29383 -0.65992  0.07654]
21Feb13_121323| [ 0.54311  0.30714  1.42644  2.72569]
21Feb13_121323| [-1.00185 -0.09399 -0.43646 -0.97593]
21Feb13_121323| [ 0.78104  0.64037 -0.07888 -0.94235]
21Feb13_121323| [ 0.36292 -2.09381 -0.14759 -0.57450]
21Feb13_121323| [ 0.98177  0.47143 -0.71689  0.87222]
21Feb13_121323| [ 0.64560 -1.51019 -0.08943  0.17061]
21Feb13_121323| [-0.05811 -0.65097  1.17154  0.01508]
21Feb13_121323| [ 1.10455  0.40564  0.46023 -0.68888]
21Feb13_121323| [-0.99141  0.40317 -0.72143 -1.11914]
21Feb13_121323| [-0.57071 -0.24300  0.15319  0.12984]
21Feb13_121323| [-0.77877 -0.72042 -1.33874 -0.26930]
21Feb13_121323| [ 0.45731 -1.45936 -0.94053 -2.01562]
21Feb13_121323| [ 0.66473 -0.46017 -0.47228 -0.41096]
21Feb13_121323| [ 0.17837  0.27083 -0.01682  0.32447]
21Feb13_121323| [ 0.96631 -0.25649 -0.83279  2.07308]
21Feb13_121323| [ 0.11932  1.10674  0.87761 -1.17589]
21Feb13_121323| [-0.29668 -1.06887 -2.04195 -0.93875]
21Feb13_121323| [ 0.36581  1.00476 -1.10789 -0.30620]
21Feb13_121323| [-0.35525  1.21057  0.20561  0.43313]
21Feb13_121323| [-2.02128 -1.06479  0.24020  0.09220]
21Feb13_121323| [-1.45281  1.00135 -1.07230 -1.41216]
21Feb13_121323| [-1.85581 -2.18106  1.21803  0.35416]
21Feb13_121323| [-1.08240  0.46387  0.12432  0.95257]
21Feb13_121323| [ 0.71253  0.03984 -0.79262  3.36370]
21Feb13_121323| [-0.53377 -0.94682 -1.48878 -0.46760]
21Feb13_121323| [-0.94888  0.08111  0.71320  0.19591]
21Feb13_121323| [ 0.40268 -1.63278 -0.12703  0.30461]
21Feb13_121323| [-0.27445  1.33890 -0.51833  0.80592]
21Feb13_121323| [ 0.59842 -1.09413  1.23234  0.58744]
21Feb13_121323| [-0.56340 -0.59958  1.10615 -1.02877]
21Feb13_121323| [ 0.73186  1.26425  1.56679 -0.28415]
21Feb13_121323| [ 1.61531  1.09254  0.10319 -0.96841]
21Feb13_121323| [ 0.71621 -1.06734 -1.46109  0.27923]
21Feb13_121323| [ 0.16600  0.29021  0.26385 -1.28921]
21Feb13_121323| [ 0.86279  0.35615  1.41976 -0.32959]
21Feb13_121323| [ 0.91697 -0.03368 -0.47800  0.48218]
21Feb13_121323| [ 0.34812 -0.02552 -1.17485 -0.07619]]
21Feb13_121323|-- Bias --
21Feb13_121323|[ 1.43486 -0.37836  0.90214  0.52973]
21Feb13_121323|Layer 1:
21Feb13_121323|-- Config --
21Feb13_121323|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121323|-- Weights --
21Feb13_121323|[[ 0.00473 -0.54749  0.74398]
21Feb13_121323| [-0.10074  0.03358  0.52254]
21Feb13_121323| [-0.65340  1.25823  0.80018]
21Feb13_121323| [-0.65787  0.15553 -0.28078]]
21Feb13_121323|-- Bias --
21Feb13_121323|[-0.79202  1.42146 -0.58308]
21Feb13_121323|Layer 2:
21Feb13_121323|-- Config --
21Feb13_121323|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121323|-- Weights --
21Feb13_121323|[[ 0.10221  0.77446 -0.37401 -0.20485  0.06422]
21Feb13_121323| [-0.98663  0.10920 -0.48505 -0.60013  0.32397]
21Feb13_121323| [-0.58271  0.81561 -0.47697  0.99162 -0.51476]]
21Feb13_121323|-- Bias --
21Feb13_121323|[ 0.34898  0.20875 -0.68469 -0.24530  0.12589]
21Feb13_121323|Layer 3:
21Feb13_121323|-- Config --
21Feb13_121323|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121323|-- Weights --
21Feb13_121323|[[-1.05547 -1.17480]
21Feb13_121323| [ 0.43780  1.28908]
21Feb13_121323| [-1.15457  0.60478]
21Feb13_121323| [-0.50464 -0.51282]
21Feb13_121323| [-0.84696 -0.20512]]
21Feb13_121323|-- Bias --
21Feb13_121323|[-0.90212  0.80792]
21Feb13_121323|Predicting the validation and test data with the Best final individual.
21Feb13_121330| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_121330|-----------  ------------------  --------------------  ----------
21Feb13_121330|Validation         27.22                  36            0.55947
21Feb13_121330|   Test            25.98                  36            0.53734
21Feb13_121330|-------------------- Test #13 --------------------
21Feb13_121330|Best final individual weights
21Feb13_121330|Individual:
21Feb13_121330|-- Constant hidden layers --
21Feb13_121330|False
21Feb13_121330|Layer 0:
21Feb13_121330|-- Config --
21Feb13_121330|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121330|-- Weights --
21Feb13_121330|[[ 0.63638 -0.20563 -0.46748  0.36212]
21Feb13_121330| [-0.22569 -0.52990 -1.70224 -0.11042]
21Feb13_121330| [-0.01823 -0.16278 -0.33268 -1.79564]
21Feb13_121330| [ 0.44877  0.32665  0.25922  0.12485]
21Feb13_121330| [-0.24588 -2.19455 -0.08046  0.81960]
21Feb13_121330| [ 0.54427  0.28873 -1.78972  0.41910]
21Feb13_121330| [-0.69198 -0.02289 -1.92958  0.32782]
21Feb13_121330| [-0.78503  0.66093  1.37772 -1.48476]
21Feb13_121330| [ 1.54812  0.42435 -0.31442 -0.17611]
21Feb13_121330| [ 1.94045  0.79061  0.31325  0.39846]
21Feb13_121330| [ 0.81259  1.28494 -0.42398  0.73768]
21Feb13_121330| [ 0.24812 -1.03749 -0.32424 -0.22649]
21Feb13_121330| [-0.10656 -0.80897 -0.16817 -1.69896]
21Feb13_121330| [ 0.17005  2.23605 -1.56675  0.50354]
21Feb13_121330| [-0.74027 -0.07039 -0.56526  0.24764]
21Feb13_121330| [ 0.24215  1.05626 -0.61433  0.72223]
21Feb13_121330| [-3.21616 -0.99370 -0.70992 -1.26517]
21Feb13_121330| [-0.63804  0.43694  0.67759  0.11887]
21Feb13_121330| [-0.03764 -1.07512  0.56036 -0.09506]
21Feb13_121330| [-0.05633  1.29383 -0.65992  0.07654]
21Feb13_121330| [ 0.54311  0.30714  1.42644  2.72569]
21Feb13_121330| [-1.00185 -0.09399 -0.43646 -0.97593]
21Feb13_121330| [ 0.78104  0.64037 -0.07888 -0.94235]
21Feb13_121330| [ 0.36292 -2.09381 -0.14759 -0.57450]
21Feb13_121330| [ 0.98177  0.47143 -0.71689  0.87222]
21Feb13_121330| [ 0.64560 -1.51019 -0.08943  0.17061]
21Feb13_121330| [-0.05811 -0.65097  1.17154  0.01508]
21Feb13_121330| [ 1.10455  0.40564  0.46023 -0.68888]
21Feb13_121330| [-0.99141  0.40317 -0.72143 -1.11914]
21Feb13_121330| [-0.57071 -0.24300  0.15319  0.12984]
21Feb13_121330| [-0.77877 -0.72042 -1.33874 -0.26930]
21Feb13_121330| [ 0.45731 -1.45936 -0.94053 -2.01562]
21Feb13_121330| [ 0.66473 -0.46017 -0.47228 -0.41096]
21Feb13_121330| [ 0.17837  0.27083 -0.01682  0.32447]
21Feb13_121330| [ 0.96631 -0.25649 -0.83279  2.07308]
21Feb13_121330| [ 0.11932  1.10674  0.87761 -1.17589]
21Feb13_121330| [-0.29668 -1.06887 -2.04195 -0.93875]
21Feb13_121330| [ 0.36581  1.00476 -1.10789 -0.30620]
21Feb13_121330| [-0.35525  1.21057  0.20561  0.43313]
21Feb13_121330| [-2.02128 -1.06479  0.24020  0.09220]
21Feb13_121330| [-1.45281  1.00135 -1.07230 -1.41216]
21Feb13_121330| [-1.85581 -2.18106  1.21803  0.35416]
21Feb13_121330| [-1.08240  0.46387  0.12432  0.95257]
21Feb13_121330| [ 0.71253  0.03984 -0.79262  3.36370]
21Feb13_121330| [-0.53377 -0.94682 -1.48878 -0.46760]
21Feb13_121330| [-0.94888  0.08111  0.71320  0.19591]
21Feb13_121330| [ 0.40268 -1.63278 -0.12703  0.30461]
21Feb13_121330| [-0.27445  1.33890 -0.51833  0.80592]
21Feb13_121330| [ 0.59842 -1.09413  1.23234  0.58744]
21Feb13_121330| [-0.56340 -0.59958  1.10615 -1.02877]
21Feb13_121330| [ 0.73186  1.26425  1.56679 -0.28415]
21Feb13_121330| [ 1.61531  1.09254  0.10319 -0.96841]
21Feb13_121330| [ 0.71621 -1.06734 -1.46109  0.27923]
21Feb13_121330| [ 0.16600  0.29021  0.26385 -1.28921]
21Feb13_121330| [ 0.86279  0.35615  1.41976 -0.32959]
21Feb13_121330| [ 0.91697 -0.03368 -0.47800  0.48218]
21Feb13_121330| [ 0.34812 -0.02552 -1.17485 -0.07619]]
21Feb13_121330|-- Bias --
21Feb13_121330|[ 1.43486 -0.37836  0.90214  0.52973]
21Feb13_121330|Layer 1:
21Feb13_121330|-- Config --
21Feb13_121330|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121330|-- Weights --
21Feb13_121330|[[ 0.00473 -0.54749  0.74398]
21Feb13_121330| [-0.10074  0.03358  0.52254]
21Feb13_121330| [-0.65340  1.25823  0.80018]
21Feb13_121330| [-0.65787  0.15553 -0.28078]]
21Feb13_121330|-- Bias --
21Feb13_121330|[-0.79202  1.42146 -0.58308]
21Feb13_121330|Layer 2:
21Feb13_121330|-- Config --
21Feb13_121330|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121330|-- Weights --
21Feb13_121330|[[ 0.10221  0.77446 -0.37401 -0.20485  0.06422]
21Feb13_121330| [-0.98663  0.10920 -0.48505 -0.60013  0.32397]
21Feb13_121330| [-0.58271  0.81561 -0.47697  0.99162 -0.51476]]
21Feb13_121330|-- Bias --
21Feb13_121330|[ 0.34898  0.20875 -0.68469 -0.24530  0.12589]
21Feb13_121330|Layer 3:
21Feb13_121330|-- Config --
21Feb13_121330|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121330|-- Weights --
21Feb13_121330|[[-1.05547 -1.17480]
21Feb13_121330| [ 0.43780  1.28908]
21Feb13_121330| [-1.15457  0.60478]
21Feb13_121330| [-0.50464 -0.51282]
21Feb13_121330| [-0.84696 -0.20512]]
21Feb13_121330|-- Bias --
21Feb13_121330|[-0.90212  0.80792]
21Feb13_121330|Predicting the validation and test data with the Best final individual.
21Feb13_121338| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_121338|-----------  ------------------  --------------------  ----------
21Feb13_121338|Validation         29.39                  36            0.44219
21Feb13_121338|   Test            35.27                  36            0.06158
21Feb13_121338|-------------------- Test #14 --------------------
21Feb13_121338|Best final individual weights
21Feb13_121338|Individual:
21Feb13_121338|-- Constant hidden layers --
21Feb13_121338|False
21Feb13_121338|Layer 0:
21Feb13_121338|-- Config --
21Feb13_121338|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121338|-- Weights --
21Feb13_121338|[[ 0.63638 -0.20563 -0.46748  0.36212]
21Feb13_121338| [-0.22569 -0.52990 -1.70224 -0.11042]
21Feb13_121338| [-0.01823 -0.16278 -0.33268 -1.79564]
21Feb13_121338| [ 0.44877  0.32665  0.25922  0.12485]
21Feb13_121338| [-0.24588 -2.19455 -0.08046  0.81960]
21Feb13_121338| [ 0.54427  0.28873 -1.78972  0.41910]
21Feb13_121338| [-0.69198 -0.02289 -1.92958  0.32782]
21Feb13_121338| [-0.78503  0.66093  1.37772 -1.48476]
21Feb13_121338| [ 1.54812  0.42435 -0.31442 -0.17611]
21Feb13_121338| [ 1.94045  0.79061  0.31325  0.39846]
21Feb13_121338| [ 0.81259  1.28494 -0.42398  0.73768]
21Feb13_121338| [ 0.24812 -1.03749 -0.32424 -0.22649]
21Feb13_121338| [-0.10656 -0.80897 -0.16817 -1.69896]
21Feb13_121338| [ 0.17005  2.23605 -1.56675  0.50354]
21Feb13_121338| [-0.74027 -0.07039 -0.56526  0.24764]
21Feb13_121338| [ 0.24215  1.05626 -0.61433  0.72223]
21Feb13_121338| [-3.21616 -0.99370 -0.70992 -1.26517]
21Feb13_121338| [-0.63804  0.43694  0.67759  0.11887]
21Feb13_121338| [-0.03764 -1.07512  0.56036 -0.09506]
21Feb13_121338| [-0.05633  1.29383 -0.65992  0.07654]
21Feb13_121338| [ 0.54311  0.30714  1.42644  2.72569]
21Feb13_121338| [-1.00185 -0.09399 -0.43646 -0.97593]
21Feb13_121338| [ 0.78104  0.64037 -0.07888 -0.94235]
21Feb13_121338| [ 0.36292 -2.09381 -0.14759 -0.57450]
21Feb13_121338| [ 0.98177  0.47143 -0.71689  0.87222]
21Feb13_121338| [ 0.64560 -1.51019 -0.08943  0.17061]
21Feb13_121338| [-0.05811 -0.65097  1.17154  0.01508]
21Feb13_121338| [ 1.10455  0.40564  0.46023 -0.68888]
21Feb13_121338| [-0.99141  0.40317 -0.72143 -1.11914]
21Feb13_121338| [-0.57071 -0.24300  0.15319  0.12984]
21Feb13_121338| [-0.77877 -0.72042 -1.33874 -0.26930]
21Feb13_121338| [ 0.45731 -1.45936 -0.94053 -2.01562]
21Feb13_121338| [ 0.66473 -0.46017 -0.47228 -0.41096]
21Feb13_121338| [ 0.17837  0.27083 -0.01682  0.32447]
21Feb13_121338| [ 0.96631 -0.25649 -0.83279  2.07308]
21Feb13_121338| [ 0.11932  1.10674  0.87761 -1.17589]
21Feb13_121338| [-0.29668 -1.06887 -2.04195 -0.93875]
21Feb13_121338| [ 0.36581  1.00476 -1.10789 -0.30620]
21Feb13_121338| [-0.35525  1.21057  0.20561  0.43313]
21Feb13_121338| [-2.02128 -1.06479  0.24020  0.09220]
21Feb13_121338| [-1.45281  1.00135 -1.07230 -1.41216]
21Feb13_121338| [-1.85581 -2.18106  1.21803  0.35416]
21Feb13_121338| [-1.08240  0.46387  0.12432  0.95257]
21Feb13_121338| [ 0.71253  0.03984 -0.79262  3.36370]
21Feb13_121338| [-0.53377 -0.94682 -1.48878 -0.46760]
21Feb13_121338| [-0.94888  0.08111  0.71320  0.19591]
21Feb13_121338| [ 0.40268 -1.63278 -0.12703  0.30461]
21Feb13_121338| [-0.27445  1.33890 -0.51833  0.80592]
21Feb13_121338| [ 0.59842 -1.09413  1.23234  0.58744]
21Feb13_121338| [-0.56340 -0.59958  1.10615 -1.02877]
21Feb13_121338| [ 0.73186  1.26425  1.56679 -0.28415]
21Feb13_121338| [ 1.61531  1.09254  0.10319 -0.96841]
21Feb13_121338| [ 0.71621 -1.06734 -1.46109  0.27923]
21Feb13_121338| [ 0.16600  0.29021  0.26385 -1.28921]
21Feb13_121338| [ 0.86279  0.35615  1.41976 -0.32959]
21Feb13_121338| [ 0.91697 -0.03368 -0.47800  0.48218]
21Feb13_121338| [ 0.34812 -0.02552 -1.17485 -0.07619]]
21Feb13_121338|-- Bias --
21Feb13_121338|[ 1.43486 -0.37836  0.90214  0.52973]
21Feb13_121338|Layer 1:
21Feb13_121338|-- Config --
21Feb13_121338|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121338|-- Weights --
21Feb13_121338|[[ 0.00473 -0.54749  0.74398]
21Feb13_121338| [-0.10074  0.03358  0.52254]
21Feb13_121338| [-0.65340  1.25823  0.80018]
21Feb13_121338| [-0.65787  0.15553 -0.28078]]
21Feb13_121338|-- Bias --
21Feb13_121338|[-0.79202  1.42146 -0.58308]
21Feb13_121338|Layer 2:
21Feb13_121338|-- Config --
21Feb13_121338|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121338|-- Weights --
21Feb13_121338|[[ 0.10221  0.77446 -0.37401 -0.20485  0.06422]
21Feb13_121338| [-0.98663  0.10920 -0.48505 -0.60013  0.32397]
21Feb13_121338| [-0.58271  0.81561 -0.47697  0.99162 -0.51476]]
21Feb13_121338|-- Bias --
21Feb13_121338|[ 0.34898  0.20875 -0.68469 -0.24530  0.12589]
21Feb13_121338|Layer 3:
21Feb13_121338|-- Config --
21Feb13_121338|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_121338|-- Weights --
21Feb13_121338|[[-1.05547 -1.17480]
21Feb13_121338| [ 0.43780  1.28908]
21Feb13_121338| [-1.15457  0.60478]
21Feb13_121338| [-0.50464 -0.51282]
21Feb13_121338| [-0.84696 -0.20512]]
21Feb13_121338|-- Bias --
21Feb13_121338|[-0.90212  0.80792]
21Feb13_121338|Predicting the validation and test data with the Best final individual.
21Feb13_121345| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_121345|-----------  ------------------  --------------------  ----------
21Feb13_121345|Validation         35.74                  36            0.22282
21Feb13_121345|   Test            25.54                  36            0.47520
2021-02-13 12:13:46.657275: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
21Feb13_121347|Data summary: Train
21Feb13_121347|data.shape = (2300, 57)
21Feb13_121347|labels.shape = (2300,)
21Feb13_121347|Class distribution:
21Feb13_121347|	0 - 1389 (0.60)
21Feb13_121347|	1 - 911 (0.40)
21Feb13_121347|Data summary: Validation
21Feb13_121347|data.shape = (1150, 57)
21Feb13_121347|labels.shape = (1150,)
21Feb13_121347|Class distribution:
21Feb13_121347|	0 - 667 (0.58)
21Feb13_121347|	1 - 483 (0.42)
21Feb13_121347|Data summary: Test
21Feb13_121347|data.shape = (1151, 57)
21Feb13_121347|labels.shape = (1151,)
21Feb13_121347|Class distribution:
21Feb13_121347|	0 - 732 (0.64)
21Feb13_121347|	1 - 419 (0.36)
21Feb13_121347|Selected configuration values
21Feb13_121347|-- Dataset name: spambase2
21Feb13_121347|-- Initial population size: 64
21Feb13_121347|-- Maximun number of generations: 32
21Feb13_121347|-- Neurons per hidden layer range: (2, 20)
21Feb13_121347|-- Hidden layers number range: (1, 3)
21Feb13_121347|-- Crossover probability: 0.5
21Feb13_121347|-- Bias gene mutation probability: 0.2
21Feb13_121347|-- Weights gene mutation probability: 0.75
21Feb13_121347|-- Neuron mutation probability: 0.3
21Feb13_121347|-- Layer mutation probability: 0.3
21Feb13_121347|-- Constant hidden layers: False
21Feb13_121347|-- Seed: 31415
21Feb13_121347|Entering GA
21Feb13_121347|Start the algorithm
2021-02-13 12:13:47.526001: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-13 12:13:47.526542: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-02-13 12:13:47.547167: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-13 12:13:47.547516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.71GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s
2021-02-13 12:13:47.547533: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-02-13 12:13:47.549139: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-02-13 12:13:47.549177: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-02-13 12:13:47.549721: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-02-13 12:13:47.549877: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-02-13 12:13:47.549956: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-13 12:13:47.550368: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-02-13 12:13:47.550409: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-13 12:13:47.550415: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-02-13 12:13:47.550611: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-02-13 12:13:47.551491: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-13 12:13:47.551521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-13 12:13:47.551524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      
2021-02-13 12:13:47.605297: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-02-13 12:13:47.605619: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3493635000 Hz
/home/jmerelo/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype("int32")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn('`model.predict_classes()` is deprecated and '
21Feb13_121748|-- Generation 1 --
21Feb13_121748|    -- Crossed 1 individual pairs.
21Feb13_121748|    -- Mutated 32 individuals.
21Feb13_122145|    -- Evaluated 64 individuals.
21Feb13_122145|    Summary of generation 1:
21Feb13_122145| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_122145|-----------  ------------------  --------------------  ----------
21Feb13_122145|    Max            43.65                153.00          0.81167
21Feb13_122145|    Avg            41.78                37.73           0.02727
21Feb13_122145|    Min            26.78                 2.00           0.00000
21Feb13_122145|    Std             1.91                34.45           0.14078
21Feb13_122145|   Best            26.78                26.00           0.80993
21Feb13_122145|-- Generation 2 --
21Feb13_122145|    -- Crossed 0 individual pairs.
21Feb13_122145|    -- Mutated 32 individuals.
21Feb13_122538|    -- Evaluated 64 individuals.
21Feb13_122538|    Summary of generation 2:
21Feb13_122538| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_122538|-----------  ------------------  --------------------  ----------
21Feb13_122538|    Max            42.52                102.00          0.31750
21Feb13_122538|    Avg            41.89                24.31           0.00694
21Feb13_122538|    Min            35.39                 3.00           0.00000
21Feb13_122538|    Std             0.83                21.46           0.03935
21Feb13_122538|   Best            35.39                22.00           0.31750
21Feb13_122538|-- Generation 3 --
21Feb13_122538|    -- Crossed 1 individual pairs.
21Feb13_122538|    -- Mutated 32 individuals.
21Feb13_122930|    -- Evaluated 64 individuals.
21Feb13_122930|    Summary of generation 3:
21Feb13_122930| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_122930|-----------  ------------------  --------------------  ----------
21Feb13_122930|    Max            42.26                57.00           0.75060
21Feb13_122930|    Avg            41.73                14.64           0.01350
21Feb13_122930|    Min            26.00                 2.00           0.00000
21Feb13_122930|    Std             1.99                12.43           0.09295
21Feb13_122930|   Best            26.00                16.00           0.75060
21Feb13_122930|-- Generation 4 --
21Feb13_122930|    -- Crossed 2 individual pairs.
21Feb13_122930|    -- Mutated 32 individuals.
21Feb13_123320|    -- Evaluated 64 individuals.
21Feb13_123320|    Summary of generation 4:
21Feb13_123320| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_123320|-----------  ------------------  --------------------  ----------
21Feb13_123320|    Max            42.26                50.00           0.01291
21Feb13_123320|    Avg            41.99                12.39           0.00129
21Feb13_123320|    Min            41.57                 2.00           0.00000
21Feb13_123320|    Std             0.09                12.33           0.00242
21Feb13_123320|   Best            41.57                20.00           0.01291
21Feb13_123320|-- Generation 5 --
21Feb13_123320|    -- Crossed 2 individual pairs.
21Feb13_123320|    -- Mutated 32 individuals.
21Feb13_123708|    -- Evaluated 64 individuals.
21Feb13_123708|    Summary of generation 5:
21Feb13_123708| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_123708|-----------  ------------------  --------------------  ----------
21Feb13_123708|    Max            42.09                50.00           0.01805
21Feb13_123708|    Avg            41.97                 9.83           0.00145
21Feb13_123708|    Min            41.39                 2.00           0.00000
21Feb13_123708|    Std             0.09                11.34           0.00269
21Feb13_123708|   Best            41.39                 5.00           0.01805
21Feb13_123708|-- Generation 6 --
21Feb13_123708|    -- Crossed 5 individual pairs.
21Feb13_123708|    -- Mutated 32 individuals.
21Feb13_124058|    -- Evaluated 64 individuals.
21Feb13_124058|    Summary of generation 6:
21Feb13_124058| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_124058|-----------  ------------------  --------------------  ----------
21Feb13_124058|    Max            42.26                48.00           0.49955
21Feb13_124058|    Avg            41.76                 9.00           0.00985
21Feb13_124058|    Min            29.30                 2.00           0.00000
21Feb13_124058|    Std             1.58                 9.82           0.06207
21Feb13_124058|   Best            29.30                 3.00           0.49955
21Feb13_124058|-- Generation 7 --
21Feb13_124058|    -- Crossed 5 individual pairs.
21Feb13_124058|    -- Mutated 32 individuals.
21Feb13_124447|    -- Evaluated 64 individuals.
21Feb13_124447|    Summary of generation 7:
21Feb13_124447| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_124447|-----------  ------------------  --------------------  ----------
21Feb13_124447|    Max            42.00                48.00           0.43100
21Feb13_124447|    Avg            41.90                 8.89           0.00855
21Feb13_124447|    Min            39.30                 2.00           0.00000
21Feb13_124447|    Std             0.36                 9.75           0.05342
21Feb13_124447|   Best            39.30                18.00           0.43100
21Feb13_124447|-- Generation 8 --
21Feb13_124447|    -- Crossed 4 individual pairs.
21Feb13_124447|    -- Mutated 32 individuals.
21Feb13_124838|    -- Evaluated 64 individuals.
21Feb13_124838|    Summary of generation 8:
21Feb13_124838| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_124838|-----------  ------------------  --------------------  ----------
21Feb13_124838|    Max            42.17                48.00           0.42511
21Feb13_124838|    Avg            41.89                 9.50           0.00850
21Feb13_124838|    Min            37.83                 2.00           0.00000
21Feb13_124838|    Std             0.53                10.98           0.05265
21Feb13_124838|   Best            37.83                18.00           0.42511
21Feb13_124838|-- Generation 9 --
21Feb13_124838|    -- Crossed 2 individual pairs.
21Feb13_124838|    -- Mutated 32 individuals.
21Feb13_125227|    -- Evaluated 64 individuals.
21Feb13_125227|    Summary of generation 9:
21Feb13_125227| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_125227|-----------  ------------------  --------------------  ----------
21Feb13_125227|    Max            42.35                50.00           0.59256
21Feb13_125227|    Avg            41.67                10.45           0.01897
21Feb13_125227|    Min            27.39                 2.00           0.00000
21Feb13_125227|    Std             1.88                12.05           0.09771
21Feb13_125227|   Best            27.39                20.00           0.59256
21Feb13_125227|-- Generation 10 --
21Feb13_125227|    -- Crossed 6 individual pairs.
21Feb13_125227|    -- Mutated 32 individuals.
21Feb13_125618|    -- Evaluated 64 individuals.
21Feb13_125618|    Summary of generation 10:
21Feb13_125618| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_125618|-----------  ------------------  --------------------  ----------
21Feb13_125618|    Max            42.17                50.00           0.54472
21Feb13_125618|    Avg            41.48                11.17           0.02578
21Feb13_125618|    Min            28.70                 2.00           0.00000
21Feb13_125618|    Std             2.04                12.02           0.09973
21Feb13_125618|   Best            28.70                14.00           0.47565
21Feb13_125618|-- Generation 11 --
21Feb13_125618|    -- Crossed 5 individual pairs.
21Feb13_125618|    -- Mutated 32 individuals.
21Feb13_130013|    -- Evaluated 64 individuals.
21Feb13_130013|    Summary of generation 11:
21Feb13_130013| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_130013|-----------  ------------------  --------------------  ----------
21Feb13_130013|    Max            52.61                56.00           0.83068
21Feb13_130013|    Avg            41.79                16.30           0.04614
21Feb13_130013|    Min            30.17                 2.00           0.00000
21Feb13_130013|    Std             2.13                13.64           0.17304
21Feb13_130013|   Best            30.17                14.00           0.42322
21Feb13_130013|-- Generation 12 --
21Feb13_130013|    -- Crossed 4 individual pairs.
21Feb13_130013|    -- Mutated 32 individuals.
21Feb13_130409|    -- Evaluated 64 individuals.
21Feb13_130409|    Summary of generation 12:
21Feb13_130409| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_130409|-----------  ------------------  --------------------  ----------
21Feb13_130409|    Max            42.61                66.00           0.81434
21Feb13_130409|    Avg            41.68                17.17           0.02189
21Feb13_130409|    Min            33.48                 2.00           0.00000
21Feb13_130409|    Std             1.36                11.63           0.10671
21Feb13_130409|   Best            33.48                12.00           0.81434
21Feb13_130409|-- Generation 13 --
21Feb13_130409|    -- Crossed 4 individual pairs.
21Feb13_130409|    -- Mutated 32 individuals.
21Feb13_130802|    -- Evaluated 64 individuals.
21Feb13_130802|    Summary of generation 13:
21Feb13_130802| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_130802|-----------  ------------------  --------------------  ----------
21Feb13_130802|    Max            42.70                36.00           0.58453
21Feb13_130802|    Avg            41.37                13.11           0.02832
21Feb13_130802|    Min            27.30                 2.00           0.00000
21Feb13_130802|    Std             2.47                 6.45           0.10239
21Feb13_130802|   Best            27.30                14.00           0.58453
21Feb13_130802|-- Generation 14 --
21Feb13_130802|    -- Crossed 3 individual pairs.
21Feb13_130802|    -- Mutated 32 individuals.
21Feb13_131157|    -- Evaluated 64 individuals.
21Feb13_131157|    Summary of generation 14:
21Feb13_131157| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_131157|-----------  ------------------  --------------------  ----------
21Feb13_131157|    Max            42.26                33.00           0.54803
21Feb13_131157|    Avg            41.29                13.16           0.03153
21Feb13_131157|    Min            28.43                 2.00           0.00000
21Feb13_131157|    Std             2.59                 7.25           0.10703
21Feb13_131157|   Best            28.43                14.00           0.49820
21Feb13_131157|-- Generation 15 --
21Feb13_131157|    -- Crossed 6 individual pairs.
21Feb13_131157|    -- Mutated 32 individuals.
21Feb13_131549|    -- Evaluated 64 individuals.
21Feb13_131549|    Summary of generation 15:
21Feb13_131549| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_131549|-----------  ------------------  --------------------  ----------
21Feb13_131549|    Max            42.26                36.00           0.48731
21Feb13_131549|    Avg            41.38                11.55           0.02945
21Feb13_131549|    Min            28.43                 2.00           0.00000
21Feb13_131549|    Std             2.43                 7.56           0.10647
21Feb13_131549|   Best            28.43                14.00           0.48731
21Feb13_131549|-- Generation 16 --
21Feb13_131549|    -- Crossed 2 individual pairs.
21Feb13_131549|    -- Mutated 32 individuals.
21Feb13_131943|    -- Evaluated 64 individuals.
21Feb13_131943|    Summary of generation 16:
21Feb13_131943| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_131943|-----------  ------------------  --------------------  ----------
21Feb13_131943|    Max            42.43                39.00           0.78366
21Feb13_131943|    Avg            41.13                13.50           0.03780
21Feb13_131943|    Min            25.22                 2.00           0.00000
21Feb13_131943|    Std             3.21                 9.11           0.14024
21Feb13_131943|   Best            25.22                 5.00           0.78366
21Feb13_131943|-- Generation 17 --
21Feb13_131943|    -- Crossed 2 individual pairs.
21Feb13_131943|    -- Mutated 32 individuals.
21Feb13_132336|    -- Evaluated 64 individuals.
21Feb13_132336|    Summary of generation 17:
21Feb13_132336| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_132336|-----------  ------------------  --------------------  ----------
21Feb13_132336|    Max            42.43                42.00           0.56335
21Feb13_132336|    Avg            41.16                10.92           0.03312
21Feb13_132336|    Min            27.65                 2.00           0.00000
21Feb13_132336|    Std             2.91                 8.15           0.11400
21Feb13_132336|   Best            27.65                16.00           0.56335
21Feb13_132336|-- Generation 18 --
21Feb13_132336|    -- Crossed 5 individual pairs.
21Feb13_132336|    -- Mutated 32 individuals.
21Feb13_132725|    -- Evaluated 64 individuals.
21Feb13_132725|    Summary of generation 18:
21Feb13_132725| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_132725|-----------  ------------------  --------------------  ----------
21Feb13_132725|    Max            42.00                33.00           0.59914
21Feb13_132725|    Avg            41.62                 8.61           0.01468
21Feb13_132725|    Min            27.39                 2.00           0.00000
21Feb13_132725|    Std             1.83                 5.87           0.07497
21Feb13_132725|   Best            27.39                14.00           0.59914
21Feb13_132725|-- Generation 19 --
21Feb13_132725|    -- Crossed 3 individual pairs.
21Feb13_132725|    -- Mutated 32 individuals.
21Feb13_133111|    -- Evaluated 64 individuals.
21Feb13_133111|    Summary of generation 19:
21Feb13_133111| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_133111|-----------  ------------------  --------------------  ----------
21Feb13_133111|    Max            42.09                33.00           0.56192
21Feb13_133111|    Avg            41.48                 7.42           0.01868
21Feb13_133111|    Min            26.96                 2.00           0.00000
21Feb13_133111|    Std             2.32                 5.96           0.08396
21Feb13_133111|   Best            26.96                20.00           0.56192
21Feb13_133111|-- Generation 20 --
21Feb13_133111|    -- Crossed 4 individual pairs.
21Feb13_133111|    -- Mutated 32 individuals.
21Feb13_133457|    -- Evaluated 64 individuals.
21Feb13_133457|    Summary of generation 20:
21Feb13_133457| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_133457|-----------  ------------------  --------------------  ----------
21Feb13_133457|    Max            42.35                24.00           0.74261
21Feb13_133457|    Avg            41.45                 6.81           0.02297
21Feb13_133457|    Min            25.04                 2.00           0.00000
21Feb13_133457|    Std             2.64                 5.06           0.11228
21Feb13_133457|   Best            25.04                18.00           0.74261
21Feb13_133457|-- Generation 21 --
21Feb13_133457|    -- Crossed 5 individual pairs.
21Feb13_133457|    -- Mutated 32 individuals.
21Feb13_133843|    -- Evaluated 64 individuals.
21Feb13_133843|    Summary of generation 21:
21Feb13_133843| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_133843|-----------  ------------------  --------------------  ----------
21Feb13_133843|    Max            42.17                20.00           0.49413
21Feb13_133843|    Avg            41.72                 6.47           0.01039
21Feb13_133843|    Min            28.61                 2.00           0.00000
21Feb13_133843|    Std             1.66                 4.69           0.06102
21Feb13_133843|   Best            28.61                14.00           0.49413
21Feb13_133843|-- Generation 22 --
21Feb13_133843|    -- Crossed 6 individual pairs.
21Feb13_133843|    -- Mutated 32 individuals.
21Feb13_134230|    -- Evaluated 64 individuals.
21Feb13_134230|    Summary of generation 22:
21Feb13_134230| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_134230|-----------  ------------------  --------------------  ----------
21Feb13_134230|    Max            42.09                20.00           0.51794
21Feb13_134230|    Avg            41.32                 6.38           0.02554
21Feb13_134230|    Min            27.74                 2.00           0.00000
21Feb13_134230|    Std             2.67                 4.56           0.09892
21Feb13_134230|   Best            27.74                16.00           0.51794
21Feb13_134230|-- Generation 23 --
21Feb13_134230|    -- Crossed 4 individual pairs.
21Feb13_134230|    -- Mutated 32 individuals.
21Feb13_134615|    -- Evaluated 64 individuals.
21Feb13_134615|    Summary of generation 23:
21Feb13_134615| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_134615|-----------  ------------------  --------------------  ----------
21Feb13_134615|    Max            42.43                18.00           0.53571
21Feb13_134615|    Avg            41.27                 5.97           0.02662
21Feb13_134615|    Min            27.04                 2.00           0.00000
21Feb13_134615|    Std             2.78                 4.07           0.10171
21Feb13_134615|   Best            27.04                12.00           0.53571
21Feb13_134615|-- Generation 24 --
21Feb13_134615|    -- Crossed 6 individual pairs.
21Feb13_134615|    -- Mutated 32 individuals.
21Feb13_135002|    -- Evaluated 64 individuals.
21Feb13_135002|    Summary of generation 24:
21Feb13_135002| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_135002|-----------  ------------------  --------------------  ----------
21Feb13_135002|    Max            42.09                27.00           0.72883
21Feb13_135002|    Avg            41.15                 7.31           0.03479
21Feb13_135002|    Min            28.26                 2.00           0.00000
21Feb13_135002|    Std             2.88                 5.97           0.12363
21Feb13_135002|   Best            28.26                12.00           0.72883
21Feb13_135002|-- Generation 25 --
21Feb13_135002|    -- Crossed 5 individual pairs.
21Feb13_135002|    -- Mutated 32 individuals.
21Feb13_135351|    -- Evaluated 64 individuals.
21Feb13_135351|    Summary of generation 25:
21Feb13_135351| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_135351|-----------  ------------------  --------------------  ----------
21Feb13_135351|    Max            42.17                52.00           0.83969
21Feb13_135351|    Avg            39.97                 9.44           0.09250
21Feb13_135351|    Min            21.74                 2.00           0.00000
21Feb13_135351|    Std             4.98                 9.88           0.21933
21Feb13_135351|   Best            21.74                52.00           0.75993
21Feb13_135351|-- Generation 26 --
21Feb13_135351|    -- Crossed 4 individual pairs.
21Feb13_135351|    -- Mutated 32 individuals.
21Feb13_135741|    -- Evaluated 64 individuals.
21Feb13_135741|    Summary of generation 26:
21Feb13_135741| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_135741|-----------  ------------------  --------------------  ----------
21Feb13_135741|    Max            42.09                52.00           0.65309
21Feb13_135741|    Avg            39.96                10.73           0.07950
21Feb13_135741|    Min            26.96                 2.00           0.00000
21Feb13_135741|    Std             4.41                10.32           0.16879
21Feb13_135741|   Best            26.96                12.00           0.65309
21Feb13_135741|-- Generation 27 --
21Feb13_135741|    -- Crossed 2 individual pairs.
21Feb13_135741|    -- Mutated 32 individuals.
21Feb13_140133|    -- Evaluated 64 individuals.
21Feb13_140133|    Summary of generation 27:
21Feb13_140133| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_140133|-----------  ------------------  --------------------  ----------
21Feb13_140133|    Max            42.35                39.00           0.77905
21Feb13_140133|    Avg            39.74                12.38           0.09764
21Feb13_140133|    Min            25.04                 2.00           0.00000
21Feb13_140133|    Std             4.78                10.68           0.20092
21Feb13_140133|   Best            25.04                39.00           0.72827
21Feb13_140133|-- Generation 28 --
21Feb13_140133|    -- Crossed 2 individual pairs.
21Feb13_140133|    -- Mutated 32 individuals.
21Feb13_140527|    -- Evaluated 64 individuals.
21Feb13_140527|    Summary of generation 28:
21Feb13_140527| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_140527|-----------  ------------------  --------------------  ----------
21Feb13_140527|    Max            50.87                56.00           0.81943
21Feb13_140527|    Avg            39.83                14.25           0.10625
21Feb13_140527|    Min            23.83                 2.00           0.00000
21Feb13_140527|    Std             5.18                12.48           0.22420
21Feb13_140527|   Best            23.83                42.00           0.71043
21Feb13_140527|-- Generation 29 --
21Feb13_140527|    -- Crossed 4 individual pairs.
21Feb13_140527|    -- Mutated 32 individuals.
21Feb13_140920|    -- Evaluated 64 individuals.
21Feb13_140920|    Summary of generation 29:
21Feb13_140920| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_140920|-----------  ------------------  --------------------  ----------
21Feb13_140920|    Max            42.17                56.00           0.66913
21Feb13_140920|    Avg            39.84                14.34           0.08966
21Feb13_140920|    Min            27.04                 2.00           0.00000
21Feb13_140920|    Std             4.56                12.99           0.18071
21Feb13_140920|   Best            27.04                27.00           0.51623
21Feb13_140920|-- Generation 30 --
21Feb13_140920|    -- Crossed 4 individual pairs.
21Feb13_140920|    -- Mutated 32 individuals.
21Feb13_141317|    -- Evaluated 64 individuals.
21Feb13_141317|    Summary of generation 30:
21Feb13_141317| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_141317|-----------  ------------------  --------------------  ----------
21Feb13_141317|    Max            42.00                56.00           0.76862
21Feb13_141317|    Avg            38.77                16.41           0.12544
21Feb13_141317|    Min            23.74                 2.00           0.00000
21Feb13_141317|    Std             5.73                12.35           0.22616
21Feb13_141317|   Best            23.74                14.00           0.73566
21Feb13_141317|-- Generation 31 --
21Feb13_141317|    -- Crossed 2 individual pairs.
21Feb13_141317|    -- Mutated 32 individuals.
21Feb13_141713|    -- Evaluated 64 individuals.
21Feb13_141713|    Summary of generation 31:
21Feb13_141713| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_141713|-----------  ------------------  --------------------  ----------
21Feb13_141713|    Max            42.09                45.00           0.66170
21Feb13_141713|    Avg            38.57                16.80           0.13595
21Feb13_141713|    Min            24.26                 2.00           0.00000
21Feb13_141713|    Std             5.84                 9.97           0.22121
21Feb13_141713|   Best            24.26                18.00           0.66170
21Feb13_141713|-- Generation 32 --
21Feb13_141713|    -- Crossed 3 individual pairs.
21Feb13_141713|    -- Mutated 32 individuals.
21Feb13_142111|    -- Evaluated 64 individuals.
21Feb13_142111|    Summary of generation 32:
21Feb13_142111| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_142111|-----------  ------------------  --------------------  ----------
21Feb13_142111|    Max            42.09                64.00           0.81889
21Feb13_142111|    Avg            37.35                21.34           0.18643
21Feb13_142111|    Min            24.61                 2.00           0.00000
21Feb13_142111|    Std             6.31                14.31           0.25328
21Feb13_142111|   Best            24.61                60.00           0.66214
21Feb13_142111|Best initial individual weights
21Feb13_142111|Individual:
21Feb13_142111|-- Constant hidden layers --
21Feb13_142111|False
21Feb13_142111|Layer 0:
21Feb13_142111|-- Config --
21Feb13_142111|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142111|-- Weights --
21Feb13_142111|[[-0.27202 -0.86357 -0.55480 -0.23305 -0.86065  0.00935]
21Feb13_142111| [ 0.79962  0.37670  0.29685  0.27749  0.49011 -0.69201]
21Feb13_142111| [ 0.14479  0.91685 -0.48781  0.43998  0.63560 -0.30697]
21Feb13_142111| [ 0.38698  0.86287 -0.71294  0.64752 -0.03047 -0.77785]
21Feb13_142111| [ 0.48209  0.66076  0.64751  0.81042 -0.07483  0.42515]
21Feb13_142111| [ 0.55955 -0.47655 -0.07712 -0.63479 -0.35794  0.52636]
21Feb13_142111| [ 0.38576  0.23223  0.25353  0.73450 -0.90178 -0.96369]
21Feb13_142111| [ 0.11039  0.36714  0.33686  0.01774  0.45868  0.81669]
21Feb13_142111| [-0.79637  0.26224 -0.03232  0.48232 -0.15309  0.61156]
21Feb13_142111| [-0.88621  0.90413  0.87744 -0.64355 -0.40369 -0.97981]
21Feb13_142111| [-0.68940  0.06179 -0.18424  0.08150 -0.45878  0.41370]
21Feb13_142111| [-0.36044 -0.13559  0.65226 -0.07204  0.54308  0.16062]
21Feb13_142111| [ 0.11714  0.93671 -0.29633  0.99754  0.45369 -0.70753]
21Feb13_142111| [ 0.64728 -0.33413 -0.57208 -0.73568  0.75425 -0.55104]
21Feb13_142111| [-0.99999 -0.96058  0.33387  0.28233 -0.17633  0.03884]
21Feb13_142111| [-0.31698 -0.57029  0.10048  0.21559 -0.52309  0.33687]
21Feb13_142111| [ 0.61192 -0.96178 -0.06414 -0.36741  0.15685  0.02906]
21Feb13_142111| [-0.75997 -0.73378  0.49810  0.83880 -0.83756 -0.54574]
21Feb13_142111| [ 0.84699 -0.24948  0.54050  0.73535 -0.06642 -0.14727]
21Feb13_142111| [-0.94868 -0.55371 -0.60216  0.40726 -0.98034 -0.48830]
21Feb13_142111| [ 0.83709 -0.79262  0.03398 -0.48243 -0.43785 -0.35972]
21Feb13_142111| [-0.44328  0.52441 -0.25583  0.35182 -0.83091 -0.39106]
21Feb13_142111| [-0.15833  0.20269  0.54130 -0.37920  0.09680  0.17172]
21Feb13_142111| [ 0.39523 -0.09539 -0.94133 -0.81601 -0.29414  0.09808]
21Feb13_142111| [ 0.86566 -0.82514  0.72303  0.62921 -0.61237  0.81126]
21Feb13_142111| [ 0.76870  0.06416 -0.11886 -0.75631 -0.12365 -0.72666]
21Feb13_142111| [ 0.89288  0.41306 -0.54112  0.04405 -0.79963  0.73224]
21Feb13_142111| [ 0.93553  0.89126 -0.61857  0.87545 -0.23947  0.75701]
21Feb13_142111| [-0.82086  0.81521  0.86256 -0.74272 -0.12443 -0.22844]
21Feb13_142111| [ 0.97160  0.41439 -0.41378 -0.28541  0.97440  0.41257]
21Feb13_142111| [ 0.70964  0.93589  0.10477  0.43589 -0.53252 -0.32168]
21Feb13_142111| [ 0.78787 -0.33435  0.99010 -0.65538  0.82368  0.49009]
21Feb13_142111| [ 0.22751  0.13008 -0.77326 -0.52830  0.50907  0.36905]
21Feb13_142111| [-0.27162 -0.36135  0.67608 -0.27532  0.90150  0.01127]
21Feb13_142111| [ 0.32844  0.99962 -0.09280  0.45964  0.99188 -0.46898]
21Feb13_142111| [-0.18508  0.43122 -0.20933  0.22437 -0.38523 -0.93105]
21Feb13_142111| [-0.71925  0.06113  0.19689 -0.43143 -0.18550 -0.84294]
21Feb13_142111| [-0.26779 -0.36079  0.46561  0.91330  0.52255 -0.08778]
21Feb13_142111| [-0.77037  0.39767  0.64833 -0.98560  0.46858  0.31212]
21Feb13_142111| [-0.85160 -0.84100 -0.57533 -0.89125 -0.26714 -0.03784]
21Feb13_142111| [-0.45978 -0.09001 -0.25873 -0.50100  0.50007  0.36246]
21Feb13_142111| [ 0.24085  0.09905  0.63589  0.41544  0.94690 -0.17740]
21Feb13_142111| [ 0.37276 -0.55653  0.03085 -0.57053  0.64921  0.77760]
21Feb13_142111| [-0.15149  0.70665 -0.89632  0.21282 -0.46831 -0.02174]
21Feb13_142111| [-0.90518 -0.77970  0.95331  0.59768  0.52171 -0.16887]
21Feb13_142111| [-0.91831  0.02967 -0.06979  0.13512 -0.23631 -0.64488]
21Feb13_142111| [ 0.97479 -0.94377  0.06324  0.51263  0.92015  0.33195]
21Feb13_142111| [-0.23392  0.17446 -0.00269  0.39550  0.16762  0.49246]
21Feb13_142111| [-0.38197 -0.12955 -0.15881  0.40103 -0.44224  0.28044]
21Feb13_142111| [-0.18428 -0.43672  0.17268 -0.61813  0.37910  0.10582]
21Feb13_142111| [-0.90436 -0.34919  0.78535  0.66625 -0.73042 -0.71018]
21Feb13_142111| [ 0.51032 -0.77746 -0.44325  0.84430 -0.30217 -0.29958]
21Feb13_142111| [ 0.68940  0.61874 -0.16478 -0.15758 -0.13000  0.90632]
21Feb13_142111| [ 0.03548 -0.47831  0.42708 -0.16343 -0.95208  0.69563]
21Feb13_142111| [-0.01411  0.20035  0.12539 -0.96161  0.92710 -0.77067]
21Feb13_142111| [ 0.81703  0.44147  0.72058 -0.81223 -0.67418 -0.85267]
21Feb13_142111| [-0.26530  0.72399 -0.58999 -0.15740  0.39892 -0.58918]]
21Feb13_142111|-- Bias --
21Feb13_142111|[ 0.23050  0.64820 -0.64277 -0.41900 -0.54681  0.15437]
21Feb13_142111|Layer 1:
21Feb13_142111|-- Config --
21Feb13_142111|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 7, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142111|-- Weights --
21Feb13_142111|[[-0.50321 -0.80875 -0.60144 -0.65045  0.61886 -0.77767  0.32772]
21Feb13_142111| [-0.04845 -0.89529  0.64487 -0.62765 -0.63134  0.05243 -0.44669]
21Feb13_142111| [-0.43718  0.21711  0.81639 -0.51368 -0.99854 -0.22537  0.94769]
21Feb13_142111| [-0.24806 -0.09443  0.39011  0.48081 -0.14372 -0.70297 -0.89667]
21Feb13_142111| [ 0.70687  0.42155  0.18340 -0.17501  0.52040  0.16771  0.10606]
21Feb13_142111| [ 0.44794  0.33101  0.53886 -0.17021  0.78118 -0.81555  0.43746]]
21Feb13_142111|-- Bias --
21Feb13_142111|[-0.73477  0.09614 -0.39402 -0.10087  0.57570 -0.12327  0.59815]
21Feb13_142111|Layer 2:
21Feb13_142111|-- Config --
21Feb13_142111|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 7], 'dtype': 'float32', 'units': 10, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142111|-- Weights --
21Feb13_142111|[[ 0.31908 -0.68092  0.42155  0.77600 -0.73710 -0.39887 -0.07843  0.23743
21Feb13_142111|   0.15714 -0.76581]
21Feb13_142111| [ 0.86369 -0.12993 -0.24148  0.53900  0.76709  0.96250 -0.56779 -0.90161
21Feb13_142111|  -0.05478 -0.07884]
21Feb13_142111| [ 0.55244  0.08052  0.06876 -0.21762  0.03301  0.12657 -0.10267 -0.45140
21Feb13_142111|   0.74279 -0.68060]
21Feb13_142111| [-0.82927  0.38658 -0.24283 -0.60293  0.98747 -0.55144  0.76581  0.09305
21Feb13_142111|   0.25851  0.32179]
21Feb13_142111| [ 0.50403 -0.55046  0.84432 -0.88204 -0.35981  0.51384 -0.70348  0.60683
21Feb13_142111|  -0.43326  0.96808]
21Feb13_142111| [-0.55850  0.68494  0.22628  0.92543 -0.20070  0.79557  0.78836  0.80610
21Feb13_142111|   0.78859 -0.65676]
21Feb13_142111| [-0.65413 -0.45252 -0.64423  0.93837  0.67689 -0.63509 -0.98556 -0.70209
21Feb13_142111|   0.15696  0.38727]]
21Feb13_142111|-- Bias --
21Feb13_142111|[ 0.74117  0.06232 -0.97740  0.25194  0.96653  0.46481  0.25293  0.37737
21Feb13_142111| -0.98026 -0.39274]
21Feb13_142111|Layer 3:
21Feb13_142111|-- Config --
21Feb13_142111|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 10], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142111|-- Weights --
21Feb13_142111|[[ 0.00457 -0.86221]
21Feb13_142111| [ 0.78832  0.80619]
21Feb13_142111| [ 0.15057 -0.18753]
21Feb13_142111| [ 0.89929 -0.85656]
21Feb13_142111| [ 0.75527  0.29249]
21Feb13_142111| [-0.45525  0.95025]
21Feb13_142111| [ 0.35702  0.60776]
21Feb13_142111| [ 0.11856 -0.18745]
21Feb13_142111| [-0.97968 -0.74320]
21Feb13_142111| [-0.86733  0.80774]]
21Feb13_142111|-- Bias --
21Feb13_142111|[ 0.82786 -0.37827]
21Feb13_142111|Predicting the validation and test data with the Best initial individual.
21Feb13_142119| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_142119|-----------  ------------------  --------------------  ----------
21Feb13_142119|Validation         42.00                  69            0.00000
21Feb13_142119|   Test            36.40                  69            0.00000
21Feb13_142119|-------------------- Test #0 --------------------
21Feb13_142119|Best final individual weights
21Feb13_142119|Individual:
21Feb13_142119|-- Constant hidden layers --
21Feb13_142119|False
21Feb13_142119|Layer 0:
21Feb13_142119|-- Config --
21Feb13_142119|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142119|-- Weights --
21Feb13_142119|[[ 0.02949 -0.21314  0.55793  0.94607]
21Feb13_142119| [ 0.54494 -0.13388 -2.18850 -1.24993]
21Feb13_142119| [ 0.93127  1.54713 -1.88607 -0.91833]
21Feb13_142119| [ 1.62068 -1.57946  1.11151 -1.08695]
21Feb13_142119| [-0.13260 -1.08318 -0.13056  0.45542]
21Feb13_142119| [ 0.94915 -2.11720 -0.44845 -0.65953]
21Feb13_142119| [-0.64718 -0.16743  0.02334  0.33071]
21Feb13_142119| [-1.07101  1.09343  0.26311 -1.11749]
21Feb13_142119| [ 0.56855  0.82184  0.09730  1.03642]
21Feb13_142119| [ 0.76488 -0.31078 -1.04293  1.01107]
21Feb13_142119| [-0.29389  0.27353 -0.81799 -0.17169]
21Feb13_142119| [ 0.24918 -0.80413  1.51971  0.71629]
21Feb13_142119| [-2.11237  0.00422  0.01234 -0.57667]
21Feb13_142119| [ 0.34287 -0.19948  1.26816  0.16127]
21Feb13_142119| [-0.91898 -1.02408  1.21625  0.92165]
21Feb13_142119| [ 0.76676  0.05713 -1.36992 -0.04595]
21Feb13_142119| [-1.44810 -2.18811  0.93788  0.13606]
21Feb13_142119| [ 0.29511 -1.39121  0.32393 -0.14500]
21Feb13_142119| [ 0.96472 -0.35223 -1.09012  0.08188]
21Feb13_142119| [ 1.48560  0.49421 -1.59223  0.14491]
21Feb13_142119| [ 0.18934 -1.26769 -0.10912 -0.47963]
21Feb13_142119| [-0.44269 -0.17148  1.06782 -0.61087]
21Feb13_142119| [-0.30918 -1.14679  0.50587  1.28981]
21Feb13_142119| [ 1.51410 -0.05018 -0.39714  0.50568]
21Feb13_142119| [-0.21365  0.18890  0.56575  1.31303]
21Feb13_142119| [-0.16921  1.72134  1.18461  0.44631]
21Feb13_142119| [-1.45355  0.12022  0.47873  0.34247]
21Feb13_142119| [ 2.01437  1.12297 -1.23181 -0.72050]
21Feb13_142119| [ 0.88136 -1.88762  2.99802 -0.55849]
21Feb13_142119| [ 1.11605 -1.56203 -0.95603 -0.65256]
21Feb13_142119| [-0.05084 -0.82509  0.48180 -0.67476]
21Feb13_142119| [ 0.88123 -1.28858 -0.34791  0.77095]
21Feb13_142119| [-0.48507  1.87882 -1.18653 -0.71579]
21Feb13_142119| [-1.11419  0.57237  0.23759  0.42143]
21Feb13_142119| [ 0.31364  1.12433 -0.04251  0.06594]
21Feb13_142119| [-0.39339  1.31314  0.13296 -0.94228]
21Feb13_142119| [-0.19858 -0.45873  1.62016 -0.93511]
21Feb13_142119| [-0.46561 -0.49773 -0.32500  0.39146]
21Feb13_142119| [-1.61218 -0.50043  0.00800 -0.21099]
21Feb13_142119| [-1.53767 -0.12508  0.71776 -0.91764]
21Feb13_142119| [ 0.50227 -0.94228  1.48876  0.12533]
21Feb13_142119| [-0.51106  1.38447 -0.57766 -0.97504]
21Feb13_142119| [ 0.25174  0.47641  0.08750  0.27316]
21Feb13_142119| [-1.13272 -0.53631 -0.48822  0.84947]
21Feb13_142119| [ 0.57720 -2.95375 -0.60135 -0.09821]
21Feb13_142119| [-0.09633 -0.42220  0.24097  1.42855]
21Feb13_142119| [-0.52775  0.05644 -0.89810 -0.04806]
21Feb13_142119| [-0.07008  0.22178 -0.47030 -0.34568]
21Feb13_142119| [ 0.43623  0.25271  0.24773 -0.53334]
21Feb13_142119| [ 1.21597  0.23156  2.65709  0.47534]
21Feb13_142119| [-0.74570 -1.09628 -0.87167 -0.51895]
21Feb13_142119| [ 0.46274  1.50951  1.33863 -0.51660]
21Feb13_142119| [-0.31580  0.18597  1.04952 -0.07211]
21Feb13_142119| [-0.43048  0.73167 -0.52510 -0.23014]
21Feb13_142119| [-0.83409  1.23814 -0.69833 -1.07845]
21Feb13_142119| [ 1.02077  0.47418 -0.67184  0.98280]
21Feb13_142119| [-0.68248  0.26652 -1.45227 -0.91863]]
21Feb13_142119|-- Bias --
21Feb13_142119|[ 0.50862 -1.23259  0.93057  0.35182]
21Feb13_142119|Layer 1:
21Feb13_142119|-- Config --
21Feb13_142119|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142119|-- Weights --
21Feb13_142119|[[-0.24992  0.17455 -0.36398]
21Feb13_142119| [ 0.44349 -1.50812  0.10051]
21Feb13_142119| [ 0.59669  1.40652  0.37593]
21Feb13_142119| [ 0.15579 -0.41164  0.10084]]
21Feb13_142119|-- Bias --
21Feb13_142119|[ 0.42031 -0.74011 -0.09551]
21Feb13_142119|Layer 2:
21Feb13_142119|-- Config --
21Feb13_142119|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142119|-- Weights --
21Feb13_142119|[[ 0.83726 -0.58719 -0.25875]
21Feb13_142119| [ 0.23241 -0.56623  0.60034]
21Feb13_142119| [ 0.00312 -0.29054  0.18592]]
21Feb13_142119|-- Bias --
21Feb13_142119|[-0.15630 -0.49053  0.15590]
21Feb13_142119|Layer 3:
21Feb13_142119|-- Config --
21Feb13_142119|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142119|-- Weights --
21Feb13_142119|[[-0.52235  0.22995 -0.65947  0.49342  0.37135]
21Feb13_142119| [-0.45052  0.02024  0.53104 -0.90713 -0.24140]
21Feb13_142119| [ 0.51543  0.46501 -0.15932 -0.09711 -0.36513]]
21Feb13_142119|-- Bias --
21Feb13_142119|[-0.55117  0.70809 -0.97830  0.37990  0.72931]
21Feb13_142119|Layer 4:
21Feb13_142119|-- Config --
21Feb13_142119|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142119|-- Weights --
21Feb13_142119|[[ 0.52944  0.12605]
21Feb13_142119| [ 0.63284 -0.38526]
21Feb13_142119| [ 0.67527  0.29750]
21Feb13_142119| [ 0.40740  0.97812]
21Feb13_142119| [ 0.02274  0.52747]]
21Feb13_142119|-- Bias --
21Feb13_142119|[-0.11042  0.13756]
21Feb13_142119|Predicting the validation and test data with the Best final individual.
21Feb13_142127| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_142127|-----------  ------------------  --------------------  ----------
21Feb13_142127|Validation         26.70                  60            0.69934
21Feb13_142127|   Test            36.40                  60            0.00000
21Feb13_142127|-------------------- Test #1 --------------------
21Feb13_142127|Best final individual weights
21Feb13_142127|Individual:
21Feb13_142127|-- Constant hidden layers --
21Feb13_142127|False
21Feb13_142127|Layer 0:
21Feb13_142127|-- Config --
21Feb13_142127|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142127|-- Weights --
21Feb13_142127|[[ 0.02949 -0.21314  0.55793  0.94607]
21Feb13_142127| [ 0.54494 -0.13388 -2.18850 -1.24993]
21Feb13_142127| [ 0.93127  1.54713 -1.88607 -0.91833]
21Feb13_142127| [ 1.62068 -1.57946  1.11151 -1.08695]
21Feb13_142127| [-0.13260 -1.08318 -0.13056  0.45542]
21Feb13_142127| [ 0.94915 -2.11720 -0.44845 -0.65953]
21Feb13_142127| [-0.64718 -0.16743  0.02334  0.33071]
21Feb13_142127| [-1.07101  1.09343  0.26311 -1.11749]
21Feb13_142127| [ 0.56855  0.82184  0.09730  1.03642]
21Feb13_142127| [ 0.76488 -0.31078 -1.04293  1.01107]
21Feb13_142127| [-0.29389  0.27353 -0.81799 -0.17169]
21Feb13_142127| [ 0.24918 -0.80413  1.51971  0.71629]
21Feb13_142127| [-2.11237  0.00422  0.01234 -0.57667]
21Feb13_142127| [ 0.34287 -0.19948  1.26816  0.16127]
21Feb13_142127| [-0.91898 -1.02408  1.21625  0.92165]
21Feb13_142127| [ 0.76676  0.05713 -1.36992 -0.04595]
21Feb13_142127| [-1.44810 -2.18811  0.93788  0.13606]
21Feb13_142127| [ 0.29511 -1.39121  0.32393 -0.14500]
21Feb13_142127| [ 0.96472 -0.35223 -1.09012  0.08188]
21Feb13_142127| [ 1.48560  0.49421 -1.59223  0.14491]
21Feb13_142127| [ 0.18934 -1.26769 -0.10912 -0.47963]
21Feb13_142127| [-0.44269 -0.17148  1.06782 -0.61087]
21Feb13_142127| [-0.30918 -1.14679  0.50587  1.28981]
21Feb13_142127| [ 1.51410 -0.05018 -0.39714  0.50568]
21Feb13_142127| [-0.21365  0.18890  0.56575  1.31303]
21Feb13_142127| [-0.16921  1.72134  1.18461  0.44631]
21Feb13_142127| [-1.45355  0.12022  0.47873  0.34247]
21Feb13_142127| [ 2.01437  1.12297 -1.23181 -0.72050]
21Feb13_142127| [ 0.88136 -1.88762  2.99802 -0.55849]
21Feb13_142127| [ 1.11605 -1.56203 -0.95603 -0.65256]
21Feb13_142127| [-0.05084 -0.82509  0.48180 -0.67476]
21Feb13_142127| [ 0.88123 -1.28858 -0.34791  0.77095]
21Feb13_142127| [-0.48507  1.87882 -1.18653 -0.71579]
21Feb13_142127| [-1.11419  0.57237  0.23759  0.42143]
21Feb13_142127| [ 0.31364  1.12433 -0.04251  0.06594]
21Feb13_142127| [-0.39339  1.31314  0.13296 -0.94228]
21Feb13_142127| [-0.19858 -0.45873  1.62016 -0.93511]
21Feb13_142127| [-0.46561 -0.49773 -0.32500  0.39146]
21Feb13_142127| [-1.61218 -0.50043  0.00800 -0.21099]
21Feb13_142127| [-1.53767 -0.12508  0.71776 -0.91764]
21Feb13_142127| [ 0.50227 -0.94228  1.48876  0.12533]
21Feb13_142127| [-0.51106  1.38447 -0.57766 -0.97504]
21Feb13_142127| [ 0.25174  0.47641  0.08750  0.27316]
21Feb13_142127| [-1.13272 -0.53631 -0.48822  0.84947]
21Feb13_142127| [ 0.57720 -2.95375 -0.60135 -0.09821]
21Feb13_142127| [-0.09633 -0.42220  0.24097  1.42855]
21Feb13_142127| [-0.52775  0.05644 -0.89810 -0.04806]
21Feb13_142127| [-0.07008  0.22178 -0.47030 -0.34568]
21Feb13_142127| [ 0.43623  0.25271  0.24773 -0.53334]
21Feb13_142127| [ 1.21597  0.23156  2.65709  0.47534]
21Feb13_142127| [-0.74570 -1.09628 -0.87167 -0.51895]
21Feb13_142127| [ 0.46274  1.50951  1.33863 -0.51660]
21Feb13_142127| [-0.31580  0.18597  1.04952 -0.07211]
21Feb13_142127| [-0.43048  0.73167 -0.52510 -0.23014]
21Feb13_142127| [-0.83409  1.23814 -0.69833 -1.07845]
21Feb13_142127| [ 1.02077  0.47418 -0.67184  0.98280]
21Feb13_142127| [-0.68248  0.26652 -1.45227 -0.91863]]
21Feb13_142127|-- Bias --
21Feb13_142127|[ 0.50862 -1.23259  0.93057  0.35182]
21Feb13_142127|Layer 1:
21Feb13_142127|-- Config --
21Feb13_142127|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142127|-- Weights --
21Feb13_142127|[[-0.24992  0.17455 -0.36398]
21Feb13_142127| [ 0.44349 -1.50812  0.10051]
21Feb13_142127| [ 0.59669  1.40652  0.37593]
21Feb13_142127| [ 0.15579 -0.41164  0.10084]]
21Feb13_142127|-- Bias --
21Feb13_142127|[ 0.42031 -0.74011 -0.09551]
21Feb13_142127|Layer 2:
21Feb13_142127|-- Config --
21Feb13_142127|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142127|-- Weights --
21Feb13_142127|[[ 0.83726 -0.58719 -0.25875]
21Feb13_142127| [ 0.23241 -0.56623  0.60034]
21Feb13_142127| [ 0.00312 -0.29054  0.18592]]
21Feb13_142127|-- Bias --
21Feb13_142127|[-0.15630 -0.49053  0.15590]
21Feb13_142127|Layer 3:
21Feb13_142127|-- Config --
21Feb13_142127|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142127|-- Weights --
21Feb13_142127|[[-0.52235  0.22995 -0.65947  0.49342  0.37135]
21Feb13_142127| [-0.45052  0.02024  0.53104 -0.90713 -0.24140]
21Feb13_142127| [ 0.51543  0.46501 -0.15932 -0.09711 -0.36513]]
21Feb13_142127|-- Bias --
21Feb13_142127|[-0.55117  0.70809 -0.97830  0.37990  0.72931]
21Feb13_142127|Layer 4:
21Feb13_142127|-- Config --
21Feb13_142127|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142127|-- Weights --
21Feb13_142127|[[ 0.52944  0.12605]
21Feb13_142127| [ 0.63284 -0.38526]
21Feb13_142127| [ 0.67527  0.29750]
21Feb13_142127| [ 0.40740  0.97812]
21Feb13_142127| [ 0.02274  0.52747]]
21Feb13_142127|-- Bias --
21Feb13_142127|[-0.11042  0.13756]
21Feb13_142127|Predicting the validation and test data with the Best final individual.
21Feb13_142135| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_142135|-----------  ------------------  --------------------  ----------
21Feb13_142135|Validation         37.91                  60            0.37054
21Feb13_142135|   Test            36.40                  60            0.00000
21Feb13_142135|-------------------- Test #2 --------------------
21Feb13_142135|Best final individual weights
21Feb13_142135|Individual:
21Feb13_142135|-- Constant hidden layers --
21Feb13_142135|False
21Feb13_142135|Layer 0:
21Feb13_142135|-- Config --
21Feb13_142135|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142135|-- Weights --
21Feb13_142135|[[ 0.02949 -0.21314  0.55793  0.94607]
21Feb13_142135| [ 0.54494 -0.13388 -2.18850 -1.24993]
21Feb13_142135| [ 0.93127  1.54713 -1.88607 -0.91833]
21Feb13_142135| [ 1.62068 -1.57946  1.11151 -1.08695]
21Feb13_142135| [-0.13260 -1.08318 -0.13056  0.45542]
21Feb13_142135| [ 0.94915 -2.11720 -0.44845 -0.65953]
21Feb13_142135| [-0.64718 -0.16743  0.02334  0.33071]
21Feb13_142135| [-1.07101  1.09343  0.26311 -1.11749]
21Feb13_142135| [ 0.56855  0.82184  0.09730  1.03642]
21Feb13_142135| [ 0.76488 -0.31078 -1.04293  1.01107]
21Feb13_142135| [-0.29389  0.27353 -0.81799 -0.17169]
21Feb13_142135| [ 0.24918 -0.80413  1.51971  0.71629]
21Feb13_142135| [-2.11237  0.00422  0.01234 -0.57667]
21Feb13_142135| [ 0.34287 -0.19948  1.26816  0.16127]
21Feb13_142135| [-0.91898 -1.02408  1.21625  0.92165]
21Feb13_142135| [ 0.76676  0.05713 -1.36992 -0.04595]
21Feb13_142135| [-1.44810 -2.18811  0.93788  0.13606]
21Feb13_142135| [ 0.29511 -1.39121  0.32393 -0.14500]
21Feb13_142135| [ 0.96472 -0.35223 -1.09012  0.08188]
21Feb13_142135| [ 1.48560  0.49421 -1.59223  0.14491]
21Feb13_142135| [ 0.18934 -1.26769 -0.10912 -0.47963]
21Feb13_142135| [-0.44269 -0.17148  1.06782 -0.61087]
21Feb13_142135| [-0.30918 -1.14679  0.50587  1.28981]
21Feb13_142135| [ 1.51410 -0.05018 -0.39714  0.50568]
21Feb13_142135| [-0.21365  0.18890  0.56575  1.31303]
21Feb13_142135| [-0.16921  1.72134  1.18461  0.44631]
21Feb13_142135| [-1.45355  0.12022  0.47873  0.34247]
21Feb13_142135| [ 2.01437  1.12297 -1.23181 -0.72050]
21Feb13_142135| [ 0.88136 -1.88762  2.99802 -0.55849]
21Feb13_142135| [ 1.11605 -1.56203 -0.95603 -0.65256]
21Feb13_142135| [-0.05084 -0.82509  0.48180 -0.67476]
21Feb13_142135| [ 0.88123 -1.28858 -0.34791  0.77095]
21Feb13_142135| [-0.48507  1.87882 -1.18653 -0.71579]
21Feb13_142135| [-1.11419  0.57237  0.23759  0.42143]
21Feb13_142135| [ 0.31364  1.12433 -0.04251  0.06594]
21Feb13_142135| [-0.39339  1.31314  0.13296 -0.94228]
21Feb13_142135| [-0.19858 -0.45873  1.62016 -0.93511]
21Feb13_142135| [-0.46561 -0.49773 -0.32500  0.39146]
21Feb13_142135| [-1.61218 -0.50043  0.00800 -0.21099]
21Feb13_142135| [-1.53767 -0.12508  0.71776 -0.91764]
21Feb13_142135| [ 0.50227 -0.94228  1.48876  0.12533]
21Feb13_142135| [-0.51106  1.38447 -0.57766 -0.97504]
21Feb13_142135| [ 0.25174  0.47641  0.08750  0.27316]
21Feb13_142135| [-1.13272 -0.53631 -0.48822  0.84947]
21Feb13_142135| [ 0.57720 -2.95375 -0.60135 -0.09821]
21Feb13_142135| [-0.09633 -0.42220  0.24097  1.42855]
21Feb13_142135| [-0.52775  0.05644 -0.89810 -0.04806]
21Feb13_142135| [-0.07008  0.22178 -0.47030 -0.34568]
21Feb13_142135| [ 0.43623  0.25271  0.24773 -0.53334]
21Feb13_142135| [ 1.21597  0.23156  2.65709  0.47534]
21Feb13_142135| [-0.74570 -1.09628 -0.87167 -0.51895]
21Feb13_142135| [ 0.46274  1.50951  1.33863 -0.51660]
21Feb13_142135| [-0.31580  0.18597  1.04952 -0.07211]
21Feb13_142135| [-0.43048  0.73167 -0.52510 -0.23014]
21Feb13_142135| [-0.83409  1.23814 -0.69833 -1.07845]
21Feb13_142135| [ 1.02077  0.47418 -0.67184  0.98280]
21Feb13_142135| [-0.68248  0.26652 -1.45227 -0.91863]]
21Feb13_142135|-- Bias --
21Feb13_142135|[ 0.50862 -1.23259  0.93057  0.35182]
21Feb13_142135|Layer 1:
21Feb13_142135|-- Config --
21Feb13_142135|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142135|-- Weights --
21Feb13_142135|[[-0.24992  0.17455 -0.36398]
21Feb13_142135| [ 0.44349 -1.50812  0.10051]
21Feb13_142135| [ 0.59669  1.40652  0.37593]
21Feb13_142135| [ 0.15579 -0.41164  0.10084]]
21Feb13_142135|-- Bias --
21Feb13_142135|[ 0.42031 -0.74011 -0.09551]
21Feb13_142135|Layer 2:
21Feb13_142135|-- Config --
21Feb13_142135|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142135|-- Weights --
21Feb13_142135|[[ 0.83726 -0.58719 -0.25875]
21Feb13_142135| [ 0.23241 -0.56623  0.60034]
21Feb13_142135| [ 0.00312 -0.29054  0.18592]]
21Feb13_142135|-- Bias --
21Feb13_142135|[-0.15630 -0.49053  0.15590]
21Feb13_142135|Layer 3:
21Feb13_142135|-- Config --
21Feb13_142135|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142135|-- Weights --
21Feb13_142135|[[-0.52235  0.22995 -0.65947  0.49342  0.37135]
21Feb13_142135| [-0.45052  0.02024  0.53104 -0.90713 -0.24140]
21Feb13_142135| [ 0.51543  0.46501 -0.15932 -0.09711 -0.36513]]
21Feb13_142135|-- Bias --
21Feb13_142135|[-0.55117  0.70809 -0.97830  0.37990  0.72931]
21Feb13_142135|Layer 4:
21Feb13_142135|-- Config --
21Feb13_142135|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142135|-- Weights --
21Feb13_142135|[[ 0.52944  0.12605]
21Feb13_142135| [ 0.63284 -0.38526]
21Feb13_142135| [ 0.67527  0.29750]
21Feb13_142135| [ 0.40740  0.97812]
21Feb13_142135| [ 0.02274  0.52747]]
21Feb13_142135|-- Bias --
21Feb13_142135|[-0.11042  0.13756]
21Feb13_142135|Predicting the validation and test data with the Best final individual.
21Feb13_142143| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_142143|-----------  ------------------  --------------------  ----------
21Feb13_142143|Validation         42.00                  60            0.00000
21Feb13_142143|   Test            36.40                  60            0.00000
21Feb13_142143|-------------------- Test #3 --------------------
21Feb13_142143|Best final individual weights
21Feb13_142143|Individual:
21Feb13_142143|-- Constant hidden layers --
21Feb13_142143|False
21Feb13_142143|Layer 0:
21Feb13_142143|-- Config --
21Feb13_142143|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142143|-- Weights --
21Feb13_142143|[[ 0.02949 -0.21314  0.55793  0.94607]
21Feb13_142143| [ 0.54494 -0.13388 -2.18850 -1.24993]
21Feb13_142143| [ 0.93127  1.54713 -1.88607 -0.91833]
21Feb13_142143| [ 1.62068 -1.57946  1.11151 -1.08695]
21Feb13_142143| [-0.13260 -1.08318 -0.13056  0.45542]
21Feb13_142143| [ 0.94915 -2.11720 -0.44845 -0.65953]
21Feb13_142143| [-0.64718 -0.16743  0.02334  0.33071]
21Feb13_142143| [-1.07101  1.09343  0.26311 -1.11749]
21Feb13_142143| [ 0.56855  0.82184  0.09730  1.03642]
21Feb13_142143| [ 0.76488 -0.31078 -1.04293  1.01107]
21Feb13_142143| [-0.29389  0.27353 -0.81799 -0.17169]
21Feb13_142143| [ 0.24918 -0.80413  1.51971  0.71629]
21Feb13_142143| [-2.11237  0.00422  0.01234 -0.57667]
21Feb13_142143| [ 0.34287 -0.19948  1.26816  0.16127]
21Feb13_142143| [-0.91898 -1.02408  1.21625  0.92165]
21Feb13_142143| [ 0.76676  0.05713 -1.36992 -0.04595]
21Feb13_142143| [-1.44810 -2.18811  0.93788  0.13606]
21Feb13_142143| [ 0.29511 -1.39121  0.32393 -0.14500]
21Feb13_142143| [ 0.96472 -0.35223 -1.09012  0.08188]
21Feb13_142143| [ 1.48560  0.49421 -1.59223  0.14491]
21Feb13_142143| [ 0.18934 -1.26769 -0.10912 -0.47963]
21Feb13_142143| [-0.44269 -0.17148  1.06782 -0.61087]
21Feb13_142143| [-0.30918 -1.14679  0.50587  1.28981]
21Feb13_142143| [ 1.51410 -0.05018 -0.39714  0.50568]
21Feb13_142143| [-0.21365  0.18890  0.56575  1.31303]
21Feb13_142143| [-0.16921  1.72134  1.18461  0.44631]
21Feb13_142143| [-1.45355  0.12022  0.47873  0.34247]
21Feb13_142143| [ 2.01437  1.12297 -1.23181 -0.72050]
21Feb13_142143| [ 0.88136 -1.88762  2.99802 -0.55849]
21Feb13_142143| [ 1.11605 -1.56203 -0.95603 -0.65256]
21Feb13_142143| [-0.05084 -0.82509  0.48180 -0.67476]
21Feb13_142143| [ 0.88123 -1.28858 -0.34791  0.77095]
21Feb13_142143| [-0.48507  1.87882 -1.18653 -0.71579]
21Feb13_142143| [-1.11419  0.57237  0.23759  0.42143]
21Feb13_142143| [ 0.31364  1.12433 -0.04251  0.06594]
21Feb13_142143| [-0.39339  1.31314  0.13296 -0.94228]
21Feb13_142143| [-0.19858 -0.45873  1.62016 -0.93511]
21Feb13_142143| [-0.46561 -0.49773 -0.32500  0.39146]
21Feb13_142143| [-1.61218 -0.50043  0.00800 -0.21099]
21Feb13_142143| [-1.53767 -0.12508  0.71776 -0.91764]
21Feb13_142143| [ 0.50227 -0.94228  1.48876  0.12533]
21Feb13_142143| [-0.51106  1.38447 -0.57766 -0.97504]
21Feb13_142143| [ 0.25174  0.47641  0.08750  0.27316]
21Feb13_142143| [-1.13272 -0.53631 -0.48822  0.84947]
21Feb13_142143| [ 0.57720 -2.95375 -0.60135 -0.09821]
21Feb13_142143| [-0.09633 -0.42220  0.24097  1.42855]
21Feb13_142143| [-0.52775  0.05644 -0.89810 -0.04806]
21Feb13_142143| [-0.07008  0.22178 -0.47030 -0.34568]
21Feb13_142143| [ 0.43623  0.25271  0.24773 -0.53334]
21Feb13_142143| [ 1.21597  0.23156  2.65709  0.47534]
21Feb13_142143| [-0.74570 -1.09628 -0.87167 -0.51895]
21Feb13_142143| [ 0.46274  1.50951  1.33863 -0.51660]
21Feb13_142143| [-0.31580  0.18597  1.04952 -0.07211]
21Feb13_142143| [-0.43048  0.73167 -0.52510 -0.23014]
21Feb13_142143| [-0.83409  1.23814 -0.69833 -1.07845]
21Feb13_142143| [ 1.02077  0.47418 -0.67184  0.98280]
21Feb13_142143| [-0.68248  0.26652 -1.45227 -0.91863]]
21Feb13_142143|-- Bias --
21Feb13_142143|[ 0.50862 -1.23259  0.93057  0.35182]
21Feb13_142143|Layer 1:
21Feb13_142143|-- Config --
21Feb13_142143|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142143|-- Weights --
21Feb13_142143|[[-0.24992  0.17455 -0.36398]
21Feb13_142143| [ 0.44349 -1.50812  0.10051]
21Feb13_142143| [ 0.59669  1.40652  0.37593]
21Feb13_142143| [ 0.15579 -0.41164  0.10084]]
21Feb13_142143|-- Bias --
21Feb13_142143|[ 0.42031 -0.74011 -0.09551]
21Feb13_142143|Layer 2:
21Feb13_142143|-- Config --
21Feb13_142143|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142143|-- Weights --
21Feb13_142143|[[ 0.83726 -0.58719 -0.25875]
21Feb13_142143| [ 0.23241 -0.56623  0.60034]
21Feb13_142143| [ 0.00312 -0.29054  0.18592]]
21Feb13_142143|-- Bias --
21Feb13_142143|[-0.15630 -0.49053  0.15590]
21Feb13_142143|Layer 3:
21Feb13_142143|-- Config --
21Feb13_142143|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142143|-- Weights --
21Feb13_142143|[[-0.52235  0.22995 -0.65947  0.49342  0.37135]
21Feb13_142143| [-0.45052  0.02024  0.53104 -0.90713 -0.24140]
21Feb13_142143| [ 0.51543  0.46501 -0.15932 -0.09711 -0.36513]]
21Feb13_142143|-- Bias --
21Feb13_142143|[-0.55117  0.70809 -0.97830  0.37990  0.72931]
21Feb13_142143|Layer 4:
21Feb13_142143|-- Config --
21Feb13_142143|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142143|-- Weights --
21Feb13_142143|[[ 0.52944  0.12605]
21Feb13_142143| [ 0.63284 -0.38526]
21Feb13_142143| [ 0.67527  0.29750]
21Feb13_142143| [ 0.40740  0.97812]
21Feb13_142143| [ 0.02274  0.52747]]
21Feb13_142143|-- Bias --
21Feb13_142143|[-0.11042  0.13756]
21Feb13_142143|Predicting the validation and test data with the Best final individual.
21Feb13_142151| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_142151|-----------  ------------------  --------------------  ----------
21Feb13_142151|Validation         42.00                  60            0.00000
21Feb13_142151|   Test            23.98                  60            0.66011
21Feb13_142151|-------------------- Test #4 --------------------
21Feb13_142151|Best final individual weights
21Feb13_142151|Individual:
21Feb13_142151|-- Constant hidden layers --
21Feb13_142151|False
21Feb13_142151|Layer 0:
21Feb13_142151|-- Config --
21Feb13_142151|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142151|-- Weights --
21Feb13_142151|[[ 0.02949 -0.21314  0.55793  0.94607]
21Feb13_142151| [ 0.54494 -0.13388 -2.18850 -1.24993]
21Feb13_142151| [ 0.93127  1.54713 -1.88607 -0.91833]
21Feb13_142151| [ 1.62068 -1.57946  1.11151 -1.08695]
21Feb13_142151| [-0.13260 -1.08318 -0.13056  0.45542]
21Feb13_142151| [ 0.94915 -2.11720 -0.44845 -0.65953]
21Feb13_142151| [-0.64718 -0.16743  0.02334  0.33071]
21Feb13_142151| [-1.07101  1.09343  0.26311 -1.11749]
21Feb13_142151| [ 0.56855  0.82184  0.09730  1.03642]
21Feb13_142151| [ 0.76488 -0.31078 -1.04293  1.01107]
21Feb13_142151| [-0.29389  0.27353 -0.81799 -0.17169]
21Feb13_142151| [ 0.24918 -0.80413  1.51971  0.71629]
21Feb13_142151| [-2.11237  0.00422  0.01234 -0.57667]
21Feb13_142151| [ 0.34287 -0.19948  1.26816  0.16127]
21Feb13_142151| [-0.91898 -1.02408  1.21625  0.92165]
21Feb13_142151| [ 0.76676  0.05713 -1.36992 -0.04595]
21Feb13_142151| [-1.44810 -2.18811  0.93788  0.13606]
21Feb13_142151| [ 0.29511 -1.39121  0.32393 -0.14500]
21Feb13_142151| [ 0.96472 -0.35223 -1.09012  0.08188]
21Feb13_142151| [ 1.48560  0.49421 -1.59223  0.14491]
21Feb13_142151| [ 0.18934 -1.26769 -0.10912 -0.47963]
21Feb13_142151| [-0.44269 -0.17148  1.06782 -0.61087]
21Feb13_142151| [-0.30918 -1.14679  0.50587  1.28981]
21Feb13_142151| [ 1.51410 -0.05018 -0.39714  0.50568]
21Feb13_142151| [-0.21365  0.18890  0.56575  1.31303]
21Feb13_142151| [-0.16921  1.72134  1.18461  0.44631]
21Feb13_142151| [-1.45355  0.12022  0.47873  0.34247]
21Feb13_142151| [ 2.01437  1.12297 -1.23181 -0.72050]
21Feb13_142151| [ 0.88136 -1.88762  2.99802 -0.55849]
21Feb13_142151| [ 1.11605 -1.56203 -0.95603 -0.65256]
21Feb13_142151| [-0.05084 -0.82509  0.48180 -0.67476]
21Feb13_142151| [ 0.88123 -1.28858 -0.34791  0.77095]
21Feb13_142151| [-0.48507  1.87882 -1.18653 -0.71579]
21Feb13_142151| [-1.11419  0.57237  0.23759  0.42143]
21Feb13_142151| [ 0.31364  1.12433 -0.04251  0.06594]
21Feb13_142151| [-0.39339  1.31314  0.13296 -0.94228]
21Feb13_142151| [-0.19858 -0.45873  1.62016 -0.93511]
21Feb13_142151| [-0.46561 -0.49773 -0.32500  0.39146]
21Feb13_142151| [-1.61218 -0.50043  0.00800 -0.21099]
21Feb13_142151| [-1.53767 -0.12508  0.71776 -0.91764]
21Feb13_142151| [ 0.50227 -0.94228  1.48876  0.12533]
21Feb13_142151| [-0.51106  1.38447 -0.57766 -0.97504]
21Feb13_142151| [ 0.25174  0.47641  0.08750  0.27316]
21Feb13_142151| [-1.13272 -0.53631 -0.48822  0.84947]
21Feb13_142151| [ 0.57720 -2.95375 -0.60135 -0.09821]
21Feb13_142151| [-0.09633 -0.42220  0.24097  1.42855]
21Feb13_142151| [-0.52775  0.05644 -0.89810 -0.04806]
21Feb13_142151| [-0.07008  0.22178 -0.47030 -0.34568]
21Feb13_142151| [ 0.43623  0.25271  0.24773 -0.53334]
21Feb13_142151| [ 1.21597  0.23156  2.65709  0.47534]
21Feb13_142151| [-0.74570 -1.09628 -0.87167 -0.51895]
21Feb13_142151| [ 0.46274  1.50951  1.33863 -0.51660]
21Feb13_142151| [-0.31580  0.18597  1.04952 -0.07211]
21Feb13_142151| [-0.43048  0.73167 -0.52510 -0.23014]
21Feb13_142151| [-0.83409  1.23814 -0.69833 -1.07845]
21Feb13_142151| [ 1.02077  0.47418 -0.67184  0.98280]
21Feb13_142151| [-0.68248  0.26652 -1.45227 -0.91863]]
21Feb13_142151|-- Bias --
21Feb13_142151|[ 0.50862 -1.23259  0.93057  0.35182]
21Feb13_142151|Layer 1:
21Feb13_142151|-- Config --
21Feb13_142151|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142151|-- Weights --
21Feb13_142151|[[-0.24992  0.17455 -0.36398]
21Feb13_142151| [ 0.44349 -1.50812  0.10051]
21Feb13_142151| [ 0.59669  1.40652  0.37593]
21Feb13_142151| [ 0.15579 -0.41164  0.10084]]
21Feb13_142151|-- Bias --
21Feb13_142151|[ 0.42031 -0.74011 -0.09551]
21Feb13_142151|Layer 2:
21Feb13_142151|-- Config --
21Feb13_142151|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142151|-- Weights --
21Feb13_142151|[[ 0.83726 -0.58719 -0.25875]
21Feb13_142151| [ 0.23241 -0.56623  0.60034]
21Feb13_142151| [ 0.00312 -0.29054  0.18592]]
21Feb13_142151|-- Bias --
21Feb13_142151|[-0.15630 -0.49053  0.15590]
21Feb13_142151|Layer 3:
21Feb13_142151|-- Config --
21Feb13_142151|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142151|-- Weights --
21Feb13_142151|[[-0.52235  0.22995 -0.65947  0.49342  0.37135]
21Feb13_142151| [-0.45052  0.02024  0.53104 -0.90713 -0.24140]
21Feb13_142151| [ 0.51543  0.46501 -0.15932 -0.09711 -0.36513]]
21Feb13_142151|-- Bias --
21Feb13_142151|[-0.55117  0.70809 -0.97830  0.37990  0.72931]
21Feb13_142151|Layer 4:
21Feb13_142151|-- Config --
21Feb13_142151|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142151|-- Weights --
21Feb13_142151|[[ 0.52944  0.12605]
21Feb13_142151| [ 0.63284 -0.38526]
21Feb13_142151| [ 0.67527  0.29750]
21Feb13_142151| [ 0.40740  0.97812]
21Feb13_142151| [ 0.02274  0.52747]]
21Feb13_142151|-- Bias --
21Feb13_142151|[-0.11042  0.13756]
21Feb13_142151|Predicting the validation and test data with the Best final individual.
21Feb13_142159| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_142159|-----------  ------------------  --------------------  ----------
21Feb13_142159|Validation         26.96                  60            0.73181
21Feb13_142159|   Test            36.40                  60            0.00000
21Feb13_142159|-------------------- Test #5 --------------------
21Feb13_142159|Best final individual weights
21Feb13_142159|Individual:
21Feb13_142159|-- Constant hidden layers --
21Feb13_142159|False
21Feb13_142159|Layer 0:
21Feb13_142159|-- Config --
21Feb13_142159|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142159|-- Weights --
21Feb13_142159|[[ 0.02949 -0.21314  0.55793  0.94607]
21Feb13_142159| [ 0.54494 -0.13388 -2.18850 -1.24993]
21Feb13_142159| [ 0.93127  1.54713 -1.88607 -0.91833]
21Feb13_142159| [ 1.62068 -1.57946  1.11151 -1.08695]
21Feb13_142159| [-0.13260 -1.08318 -0.13056  0.45542]
21Feb13_142159| [ 0.94915 -2.11720 -0.44845 -0.65953]
21Feb13_142159| [-0.64718 -0.16743  0.02334  0.33071]
21Feb13_142159| [-1.07101  1.09343  0.26311 -1.11749]
21Feb13_142159| [ 0.56855  0.82184  0.09730  1.03642]
21Feb13_142159| [ 0.76488 -0.31078 -1.04293  1.01107]
21Feb13_142159| [-0.29389  0.27353 -0.81799 -0.17169]
21Feb13_142159| [ 0.24918 -0.80413  1.51971  0.71629]
21Feb13_142159| [-2.11237  0.00422  0.01234 -0.57667]
21Feb13_142159| [ 0.34287 -0.19948  1.26816  0.16127]
21Feb13_142159| [-0.91898 -1.02408  1.21625  0.92165]
21Feb13_142159| [ 0.76676  0.05713 -1.36992 -0.04595]
21Feb13_142159| [-1.44810 -2.18811  0.93788  0.13606]
21Feb13_142159| [ 0.29511 -1.39121  0.32393 -0.14500]
21Feb13_142159| [ 0.96472 -0.35223 -1.09012  0.08188]
21Feb13_142159| [ 1.48560  0.49421 -1.59223  0.14491]
21Feb13_142159| [ 0.18934 -1.26769 -0.10912 -0.47963]
21Feb13_142159| [-0.44269 -0.17148  1.06782 -0.61087]
21Feb13_142159| [-0.30918 -1.14679  0.50587  1.28981]
21Feb13_142159| [ 1.51410 -0.05018 -0.39714  0.50568]
21Feb13_142159| [-0.21365  0.18890  0.56575  1.31303]
21Feb13_142159| [-0.16921  1.72134  1.18461  0.44631]
21Feb13_142159| [-1.45355  0.12022  0.47873  0.34247]
21Feb13_142159| [ 2.01437  1.12297 -1.23181 -0.72050]
21Feb13_142159| [ 0.88136 -1.88762  2.99802 -0.55849]
21Feb13_142159| [ 1.11605 -1.56203 -0.95603 -0.65256]
21Feb13_142159| [-0.05084 -0.82509  0.48180 -0.67476]
21Feb13_142159| [ 0.88123 -1.28858 -0.34791  0.77095]
21Feb13_142159| [-0.48507  1.87882 -1.18653 -0.71579]
21Feb13_142159| [-1.11419  0.57237  0.23759  0.42143]
21Feb13_142159| [ 0.31364  1.12433 -0.04251  0.06594]
21Feb13_142159| [-0.39339  1.31314  0.13296 -0.94228]
21Feb13_142159| [-0.19858 -0.45873  1.62016 -0.93511]
21Feb13_142159| [-0.46561 -0.49773 -0.32500  0.39146]
21Feb13_142159| [-1.61218 -0.50043  0.00800 -0.21099]
21Feb13_142159| [-1.53767 -0.12508  0.71776 -0.91764]
21Feb13_142159| [ 0.50227 -0.94228  1.48876  0.12533]
21Feb13_142159| [-0.51106  1.38447 -0.57766 -0.97504]
21Feb13_142159| [ 0.25174  0.47641  0.08750  0.27316]
21Feb13_142159| [-1.13272 -0.53631 -0.48822  0.84947]
21Feb13_142159| [ 0.57720 -2.95375 -0.60135 -0.09821]
21Feb13_142159| [-0.09633 -0.42220  0.24097  1.42855]
21Feb13_142159| [-0.52775  0.05644 -0.89810 -0.04806]
21Feb13_142159| [-0.07008  0.22178 -0.47030 -0.34568]
21Feb13_142159| [ 0.43623  0.25271  0.24773 -0.53334]
21Feb13_142159| [ 1.21597  0.23156  2.65709  0.47534]
21Feb13_142159| [-0.74570 -1.09628 -0.87167 -0.51895]
21Feb13_142159| [ 0.46274  1.50951  1.33863 -0.51660]
21Feb13_142159| [-0.31580  0.18597  1.04952 -0.07211]
21Feb13_142159| [-0.43048  0.73167 -0.52510 -0.23014]
21Feb13_142159| [-0.83409  1.23814 -0.69833 -1.07845]
21Feb13_142159| [ 1.02077  0.47418 -0.67184  0.98280]
21Feb13_142159| [-0.68248  0.26652 -1.45227 -0.91863]]
21Feb13_142159|-- Bias --
21Feb13_142159|[ 0.50862 -1.23259  0.93057  0.35182]
21Feb13_142159|Layer 1:
21Feb13_142159|-- Config --
21Feb13_142159|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142159|-- Weights --
21Feb13_142159|[[-0.24992  0.17455 -0.36398]
21Feb13_142159| [ 0.44349 -1.50812  0.10051]
21Feb13_142159| [ 0.59669  1.40652  0.37593]
21Feb13_142159| [ 0.15579 -0.41164  0.10084]]
21Feb13_142159|-- Bias --
21Feb13_142159|[ 0.42031 -0.74011 -0.09551]
21Feb13_142159|Layer 2:
21Feb13_142159|-- Config --
21Feb13_142159|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142159|-- Weights --
21Feb13_142159|[[ 0.83726 -0.58719 -0.25875]
21Feb13_142159| [ 0.23241 -0.56623  0.60034]
21Feb13_142159| [ 0.00312 -0.29054  0.18592]]
21Feb13_142159|-- Bias --
21Feb13_142159|[-0.15630 -0.49053  0.15590]
21Feb13_142159|Layer 3:
21Feb13_142159|-- Config --
21Feb13_142159|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142159|-- Weights --
21Feb13_142159|[[-0.52235  0.22995 -0.65947  0.49342  0.37135]
21Feb13_142159| [-0.45052  0.02024  0.53104 -0.90713 -0.24140]
21Feb13_142159| [ 0.51543  0.46501 -0.15932 -0.09711 -0.36513]]
21Feb13_142159|-- Bias --
21Feb13_142159|[-0.55117  0.70809 -0.97830  0.37990  0.72931]
21Feb13_142159|Layer 4:
21Feb13_142159|-- Config --
21Feb13_142159|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142159|-- Weights --
21Feb13_142159|[[ 0.52944  0.12605]
21Feb13_142159| [ 0.63284 -0.38526]
21Feb13_142159| [ 0.67527  0.29750]
21Feb13_142159| [ 0.40740  0.97812]
21Feb13_142159| [ 0.02274  0.52747]]
21Feb13_142159|-- Bias --
21Feb13_142159|[-0.11042  0.13756]
21Feb13_142159|Predicting the validation and test data with the Best final individual.
21Feb13_142207| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_142207|-----------  ------------------  --------------------  ----------
21Feb13_142207|Validation         42.00                  60            0.00000
21Feb13_142207|   Test            36.40                  60            0.00000
21Feb13_142207|-------------------- Test #6 --------------------
21Feb13_142207|Best final individual weights
21Feb13_142207|Individual:
21Feb13_142207|-- Constant hidden layers --
21Feb13_142207|False
21Feb13_142207|Layer 0:
21Feb13_142207|-- Config --
21Feb13_142207|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142207|-- Weights --
21Feb13_142207|[[ 0.02949 -0.21314  0.55793  0.94607]
21Feb13_142207| [ 0.54494 -0.13388 -2.18850 -1.24993]
21Feb13_142207| [ 0.93127  1.54713 -1.88607 -0.91833]
21Feb13_142207| [ 1.62068 -1.57946  1.11151 -1.08695]
21Feb13_142207| [-0.13260 -1.08318 -0.13056  0.45542]
21Feb13_142207| [ 0.94915 -2.11720 -0.44845 -0.65953]
21Feb13_142207| [-0.64718 -0.16743  0.02334  0.33071]
21Feb13_142207| [-1.07101  1.09343  0.26311 -1.11749]
21Feb13_142207| [ 0.56855  0.82184  0.09730  1.03642]
21Feb13_142207| [ 0.76488 -0.31078 -1.04293  1.01107]
21Feb13_142207| [-0.29389  0.27353 -0.81799 -0.17169]
21Feb13_142207| [ 0.24918 -0.80413  1.51971  0.71629]
21Feb13_142207| [-2.11237  0.00422  0.01234 -0.57667]
21Feb13_142207| [ 0.34287 -0.19948  1.26816  0.16127]
21Feb13_142207| [-0.91898 -1.02408  1.21625  0.92165]
21Feb13_142207| [ 0.76676  0.05713 -1.36992 -0.04595]
21Feb13_142207| [-1.44810 -2.18811  0.93788  0.13606]
21Feb13_142207| [ 0.29511 -1.39121  0.32393 -0.14500]
21Feb13_142207| [ 0.96472 -0.35223 -1.09012  0.08188]
21Feb13_142207| [ 1.48560  0.49421 -1.59223  0.14491]
21Feb13_142207| [ 0.18934 -1.26769 -0.10912 -0.47963]
21Feb13_142207| [-0.44269 -0.17148  1.06782 -0.61087]
21Feb13_142207| [-0.30918 -1.14679  0.50587  1.28981]
21Feb13_142207| [ 1.51410 -0.05018 -0.39714  0.50568]
21Feb13_142207| [-0.21365  0.18890  0.56575  1.31303]
21Feb13_142207| [-0.16921  1.72134  1.18461  0.44631]
21Feb13_142207| [-1.45355  0.12022  0.47873  0.34247]
21Feb13_142207| [ 2.01437  1.12297 -1.23181 -0.72050]
21Feb13_142207| [ 0.88136 -1.88762  2.99802 -0.55849]
21Feb13_142207| [ 1.11605 -1.56203 -0.95603 -0.65256]
21Feb13_142207| [-0.05084 -0.82509  0.48180 -0.67476]
21Feb13_142207| [ 0.88123 -1.28858 -0.34791  0.77095]
21Feb13_142207| [-0.48507  1.87882 -1.18653 -0.71579]
21Feb13_142207| [-1.11419  0.57237  0.23759  0.42143]
21Feb13_142207| [ 0.31364  1.12433 -0.04251  0.06594]
21Feb13_142207| [-0.39339  1.31314  0.13296 -0.94228]
21Feb13_142207| [-0.19858 -0.45873  1.62016 -0.93511]
21Feb13_142207| [-0.46561 -0.49773 -0.32500  0.39146]
21Feb13_142207| [-1.61218 -0.50043  0.00800 -0.21099]
21Feb13_142207| [-1.53767 -0.12508  0.71776 -0.91764]
21Feb13_142207| [ 0.50227 -0.94228  1.48876  0.12533]
21Feb13_142207| [-0.51106  1.38447 -0.57766 -0.97504]
21Feb13_142207| [ 0.25174  0.47641  0.08750  0.27316]
21Feb13_142207| [-1.13272 -0.53631 -0.48822  0.84947]
21Feb13_142207| [ 0.57720 -2.95375 -0.60135 -0.09821]
21Feb13_142207| [-0.09633 -0.42220  0.24097  1.42855]
21Feb13_142207| [-0.52775  0.05644 -0.89810 -0.04806]
21Feb13_142207| [-0.07008  0.22178 -0.47030 -0.34568]
21Feb13_142207| [ 0.43623  0.25271  0.24773 -0.53334]
21Feb13_142207| [ 1.21597  0.23156  2.65709  0.47534]
21Feb13_142207| [-0.74570 -1.09628 -0.87167 -0.51895]
21Feb13_142207| [ 0.46274  1.50951  1.33863 -0.51660]
21Feb13_142207| [-0.31580  0.18597  1.04952 -0.07211]
21Feb13_142207| [-0.43048  0.73167 -0.52510 -0.23014]
21Feb13_142207| [-0.83409  1.23814 -0.69833 -1.07845]
21Feb13_142207| [ 1.02077  0.47418 -0.67184  0.98280]
21Feb13_142207| [-0.68248  0.26652 -1.45227 -0.91863]]
21Feb13_142207|-- Bias --
21Feb13_142207|[ 0.50862 -1.23259  0.93057  0.35182]
21Feb13_142207|Layer 1:
21Feb13_142207|-- Config --
21Feb13_142207|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142207|-- Weights --
21Feb13_142207|[[-0.24992  0.17455 -0.36398]
21Feb13_142207| [ 0.44349 -1.50812  0.10051]
21Feb13_142207| [ 0.59669  1.40652  0.37593]
21Feb13_142207| [ 0.15579 -0.41164  0.10084]]
21Feb13_142207|-- Bias --
21Feb13_142207|[ 0.42031 -0.74011 -0.09551]
21Feb13_142207|Layer 2:
21Feb13_142207|-- Config --
21Feb13_142207|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142207|-- Weights --
21Feb13_142207|[[ 0.83726 -0.58719 -0.25875]
21Feb13_142207| [ 0.23241 -0.56623  0.60034]
21Feb13_142207| [ 0.00312 -0.29054  0.18592]]
21Feb13_142207|-- Bias --
21Feb13_142207|[-0.15630 -0.49053  0.15590]
21Feb13_142207|Layer 3:
21Feb13_142207|-- Config --
21Feb13_142207|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142207|-- Weights --
21Feb13_142207|[[-0.52235  0.22995 -0.65947  0.49342  0.37135]
21Feb13_142207| [-0.45052  0.02024  0.53104 -0.90713 -0.24140]
21Feb13_142207| [ 0.51543  0.46501 -0.15932 -0.09711 -0.36513]]
21Feb13_142207|-- Bias --
21Feb13_142207|[-0.55117  0.70809 -0.97830  0.37990  0.72931]
21Feb13_142207|Layer 4:
21Feb13_142207|-- Config --
21Feb13_142207|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142207|-- Weights --
21Feb13_142207|[[ 0.52944  0.12605]
21Feb13_142207| [ 0.63284 -0.38526]
21Feb13_142207| [ 0.67527  0.29750]
21Feb13_142207| [ 0.40740  0.97812]
21Feb13_142207| [ 0.02274  0.52747]]
21Feb13_142207|-- Bias --
21Feb13_142207|[-0.11042  0.13756]
21Feb13_142207|Predicting the validation and test data with the Best final individual.
21Feb13_142215| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_142215|-----------  ------------------  --------------------  ----------
21Feb13_142215|Validation         28.78                  60            0.72284
21Feb13_142215|   Test            25.89                  60            0.69773
21Feb13_142215|-------------------- Test #7 --------------------
21Feb13_142215|Best final individual weights
21Feb13_142215|Individual:
21Feb13_142215|-- Constant hidden layers --
21Feb13_142215|False
21Feb13_142215|Layer 0:
21Feb13_142215|-- Config --
21Feb13_142215|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142215|-- Weights --
21Feb13_142215|[[ 0.02949 -0.21314  0.55793  0.94607]
21Feb13_142215| [ 0.54494 -0.13388 -2.18850 -1.24993]
21Feb13_142215| [ 0.93127  1.54713 -1.88607 -0.91833]
21Feb13_142215| [ 1.62068 -1.57946  1.11151 -1.08695]
21Feb13_142215| [-0.13260 -1.08318 -0.13056  0.45542]
21Feb13_142215| [ 0.94915 -2.11720 -0.44845 -0.65953]
21Feb13_142215| [-0.64718 -0.16743  0.02334  0.33071]
21Feb13_142215| [-1.07101  1.09343  0.26311 -1.11749]
21Feb13_142215| [ 0.56855  0.82184  0.09730  1.03642]
21Feb13_142215| [ 0.76488 -0.31078 -1.04293  1.01107]
21Feb13_142215| [-0.29389  0.27353 -0.81799 -0.17169]
21Feb13_142215| [ 0.24918 -0.80413  1.51971  0.71629]
21Feb13_142215| [-2.11237  0.00422  0.01234 -0.57667]
21Feb13_142215| [ 0.34287 -0.19948  1.26816  0.16127]
21Feb13_142215| [-0.91898 -1.02408  1.21625  0.92165]
21Feb13_142215| [ 0.76676  0.05713 -1.36992 -0.04595]
21Feb13_142215| [-1.44810 -2.18811  0.93788  0.13606]
21Feb13_142215| [ 0.29511 -1.39121  0.32393 -0.14500]
21Feb13_142215| [ 0.96472 -0.35223 -1.09012  0.08188]
21Feb13_142215| [ 1.48560  0.49421 -1.59223  0.14491]
21Feb13_142215| [ 0.18934 -1.26769 -0.10912 -0.47963]
21Feb13_142215| [-0.44269 -0.17148  1.06782 -0.61087]
21Feb13_142215| [-0.30918 -1.14679  0.50587  1.28981]
21Feb13_142215| [ 1.51410 -0.05018 -0.39714  0.50568]
21Feb13_142215| [-0.21365  0.18890  0.56575  1.31303]
21Feb13_142215| [-0.16921  1.72134  1.18461  0.44631]
21Feb13_142215| [-1.45355  0.12022  0.47873  0.34247]
21Feb13_142215| [ 2.01437  1.12297 -1.23181 -0.72050]
21Feb13_142215| [ 0.88136 -1.88762  2.99802 -0.55849]
21Feb13_142215| [ 1.11605 -1.56203 -0.95603 -0.65256]
21Feb13_142215| [-0.05084 -0.82509  0.48180 -0.67476]
21Feb13_142215| [ 0.88123 -1.28858 -0.34791  0.77095]
21Feb13_142215| [-0.48507  1.87882 -1.18653 -0.71579]
21Feb13_142215| [-1.11419  0.57237  0.23759  0.42143]
21Feb13_142215| [ 0.31364  1.12433 -0.04251  0.06594]
21Feb13_142215| [-0.39339  1.31314  0.13296 -0.94228]
21Feb13_142215| [-0.19858 -0.45873  1.62016 -0.93511]
21Feb13_142215| [-0.46561 -0.49773 -0.32500  0.39146]
21Feb13_142215| [-1.61218 -0.50043  0.00800 -0.21099]
21Feb13_142215| [-1.53767 -0.12508  0.71776 -0.91764]
21Feb13_142215| [ 0.50227 -0.94228  1.48876  0.12533]
21Feb13_142215| [-0.51106  1.38447 -0.57766 -0.97504]
21Feb13_142215| [ 0.25174  0.47641  0.08750  0.27316]
21Feb13_142215| [-1.13272 -0.53631 -0.48822  0.84947]
21Feb13_142215| [ 0.57720 -2.95375 -0.60135 -0.09821]
21Feb13_142215| [-0.09633 -0.42220  0.24097  1.42855]
21Feb13_142215| [-0.52775  0.05644 -0.89810 -0.04806]
21Feb13_142215| [-0.07008  0.22178 -0.47030 -0.34568]
21Feb13_142215| [ 0.43623  0.25271  0.24773 -0.53334]
21Feb13_142215| [ 1.21597  0.23156  2.65709  0.47534]
21Feb13_142215| [-0.74570 -1.09628 -0.87167 -0.51895]
21Feb13_142215| [ 0.46274  1.50951  1.33863 -0.51660]
21Feb13_142215| [-0.31580  0.18597  1.04952 -0.07211]
21Feb13_142215| [-0.43048  0.73167 -0.52510 -0.23014]
21Feb13_142215| [-0.83409  1.23814 -0.69833 -1.07845]
21Feb13_142215| [ 1.02077  0.47418 -0.67184  0.98280]
21Feb13_142215| [-0.68248  0.26652 -1.45227 -0.91863]]
21Feb13_142215|-- Bias --
21Feb13_142215|[ 0.50862 -1.23259  0.93057  0.35182]
21Feb13_142215|Layer 1:
21Feb13_142215|-- Config --
21Feb13_142215|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142215|-- Weights --
21Feb13_142215|[[-0.24992  0.17455 -0.36398]
21Feb13_142215| [ 0.44349 -1.50812  0.10051]
21Feb13_142215| [ 0.59669  1.40652  0.37593]
21Feb13_142215| [ 0.15579 -0.41164  0.10084]]
21Feb13_142215|-- Bias --
21Feb13_142215|[ 0.42031 -0.74011 -0.09551]
21Feb13_142215|Layer 2:
21Feb13_142215|-- Config --
21Feb13_142215|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142215|-- Weights --
21Feb13_142215|[[ 0.83726 -0.58719 -0.25875]
21Feb13_142215| [ 0.23241 -0.56623  0.60034]
21Feb13_142215| [ 0.00312 -0.29054  0.18592]]
21Feb13_142215|-- Bias --
21Feb13_142215|[-0.15630 -0.49053  0.15590]
21Feb13_142215|Layer 3:
21Feb13_142215|-- Config --
21Feb13_142215|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142215|-- Weights --
21Feb13_142215|[[-0.52235  0.22995 -0.65947  0.49342  0.37135]
21Feb13_142215| [-0.45052  0.02024  0.53104 -0.90713 -0.24140]
21Feb13_142215| [ 0.51543  0.46501 -0.15932 -0.09711 -0.36513]]
21Feb13_142215|-- Bias --
21Feb13_142215|[-0.55117  0.70809 -0.97830  0.37990  0.72931]
21Feb13_142215|Layer 4:
21Feb13_142215|-- Config --
21Feb13_142215|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142215|-- Weights --
21Feb13_142215|[[ 0.52944  0.12605]
21Feb13_142215| [ 0.63284 -0.38526]
21Feb13_142215| [ 0.67527  0.29750]
21Feb13_142215| [ 0.40740  0.97812]
21Feb13_142215| [ 0.02274  0.52747]]
21Feb13_142215|-- Bias --
21Feb13_142215|[-0.11042  0.13756]
21Feb13_142215|Predicting the validation and test data with the Best final individual.
21Feb13_142223| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_142223|-----------  ------------------  --------------------  ----------
21Feb13_142223|Validation         42.00                  60            0.00000
21Feb13_142223|   Test            36.40                  60            0.00000
21Feb13_142223|-------------------- Test #8 --------------------
21Feb13_142223|Best final individual weights
21Feb13_142223|Individual:
21Feb13_142223|-- Constant hidden layers --
21Feb13_142223|False
21Feb13_142223|Layer 0:
21Feb13_142223|-- Config --
21Feb13_142223|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142223|-- Weights --
21Feb13_142223|[[ 0.02949 -0.21314  0.55793  0.94607]
21Feb13_142223| [ 0.54494 -0.13388 -2.18850 -1.24993]
21Feb13_142223| [ 0.93127  1.54713 -1.88607 -0.91833]
21Feb13_142223| [ 1.62068 -1.57946  1.11151 -1.08695]
21Feb13_142223| [-0.13260 -1.08318 -0.13056  0.45542]
21Feb13_142223| [ 0.94915 -2.11720 -0.44845 -0.65953]
21Feb13_142223| [-0.64718 -0.16743  0.02334  0.33071]
21Feb13_142223| [-1.07101  1.09343  0.26311 -1.11749]
21Feb13_142223| [ 0.56855  0.82184  0.09730  1.03642]
21Feb13_142223| [ 0.76488 -0.31078 -1.04293  1.01107]
21Feb13_142223| [-0.29389  0.27353 -0.81799 -0.17169]
21Feb13_142223| [ 0.24918 -0.80413  1.51971  0.71629]
21Feb13_142223| [-2.11237  0.00422  0.01234 -0.57667]
21Feb13_142223| [ 0.34287 -0.19948  1.26816  0.16127]
21Feb13_142223| [-0.91898 -1.02408  1.21625  0.92165]
21Feb13_142223| [ 0.76676  0.05713 -1.36992 -0.04595]
21Feb13_142223| [-1.44810 -2.18811  0.93788  0.13606]
21Feb13_142223| [ 0.29511 -1.39121  0.32393 -0.14500]
21Feb13_142223| [ 0.96472 -0.35223 -1.09012  0.08188]
21Feb13_142223| [ 1.48560  0.49421 -1.59223  0.14491]
21Feb13_142223| [ 0.18934 -1.26769 -0.10912 -0.47963]
21Feb13_142223| [-0.44269 -0.17148  1.06782 -0.61087]
21Feb13_142223| [-0.30918 -1.14679  0.50587  1.28981]
21Feb13_142223| [ 1.51410 -0.05018 -0.39714  0.50568]
21Feb13_142223| [-0.21365  0.18890  0.56575  1.31303]
21Feb13_142223| [-0.16921  1.72134  1.18461  0.44631]
21Feb13_142223| [-1.45355  0.12022  0.47873  0.34247]
21Feb13_142223| [ 2.01437  1.12297 -1.23181 -0.72050]
21Feb13_142223| [ 0.88136 -1.88762  2.99802 -0.55849]
21Feb13_142223| [ 1.11605 -1.56203 -0.95603 -0.65256]
21Feb13_142223| [-0.05084 -0.82509  0.48180 -0.67476]
21Feb13_142223| [ 0.88123 -1.28858 -0.34791  0.77095]
21Feb13_142223| [-0.48507  1.87882 -1.18653 -0.71579]
21Feb13_142223| [-1.11419  0.57237  0.23759  0.42143]
21Feb13_142223| [ 0.31364  1.12433 -0.04251  0.06594]
21Feb13_142223| [-0.39339  1.31314  0.13296 -0.94228]
21Feb13_142223| [-0.19858 -0.45873  1.62016 -0.93511]
21Feb13_142223| [-0.46561 -0.49773 -0.32500  0.39146]
21Feb13_142223| [-1.61218 -0.50043  0.00800 -0.21099]
21Feb13_142223| [-1.53767 -0.12508  0.71776 -0.91764]
21Feb13_142223| [ 0.50227 -0.94228  1.48876  0.12533]
21Feb13_142223| [-0.51106  1.38447 -0.57766 -0.97504]
21Feb13_142223| [ 0.25174  0.47641  0.08750  0.27316]
21Feb13_142223| [-1.13272 -0.53631 -0.48822  0.84947]
21Feb13_142223| [ 0.57720 -2.95375 -0.60135 -0.09821]
21Feb13_142223| [-0.09633 -0.42220  0.24097  1.42855]
21Feb13_142223| [-0.52775  0.05644 -0.89810 -0.04806]
21Feb13_142223| [-0.07008  0.22178 -0.47030 -0.34568]
21Feb13_142223| [ 0.43623  0.25271  0.24773 -0.53334]
21Feb13_142223| [ 1.21597  0.23156  2.65709  0.47534]
21Feb13_142223| [-0.74570 -1.09628 -0.87167 -0.51895]
21Feb13_142223| [ 0.46274  1.50951  1.33863 -0.51660]
21Feb13_142223| [-0.31580  0.18597  1.04952 -0.07211]
21Feb13_142223| [-0.43048  0.73167 -0.52510 -0.23014]
21Feb13_142223| [-0.83409  1.23814 -0.69833 -1.07845]
21Feb13_142223| [ 1.02077  0.47418 -0.67184  0.98280]
21Feb13_142223| [-0.68248  0.26652 -1.45227 -0.91863]]
21Feb13_142223|-- Bias --
21Feb13_142223|[ 0.50862 -1.23259  0.93057  0.35182]
21Feb13_142223|Layer 1:
21Feb13_142223|-- Config --
21Feb13_142223|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142223|-- Weights --
21Feb13_142223|[[-0.24992  0.17455 -0.36398]
21Feb13_142223| [ 0.44349 -1.50812  0.10051]
21Feb13_142223| [ 0.59669  1.40652  0.37593]
21Feb13_142223| [ 0.15579 -0.41164  0.10084]]
21Feb13_142223|-- Bias --
21Feb13_142223|[ 0.42031 -0.74011 -0.09551]
21Feb13_142223|Layer 2:
21Feb13_142223|-- Config --
21Feb13_142223|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142223|-- Weights --
21Feb13_142223|[[ 0.83726 -0.58719 -0.25875]
21Feb13_142223| [ 0.23241 -0.56623  0.60034]
21Feb13_142223| [ 0.00312 -0.29054  0.18592]]
21Feb13_142223|-- Bias --
21Feb13_142223|[-0.15630 -0.49053  0.15590]
21Feb13_142223|Layer 3:
21Feb13_142223|-- Config --
21Feb13_142223|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142223|-- Weights --
21Feb13_142223|[[-0.52235  0.22995 -0.65947  0.49342  0.37135]
21Feb13_142223| [-0.45052  0.02024  0.53104 -0.90713 -0.24140]
21Feb13_142223| [ 0.51543  0.46501 -0.15932 -0.09711 -0.36513]]
21Feb13_142223|-- Bias --
21Feb13_142223|[-0.55117  0.70809 -0.97830  0.37990  0.72931]
21Feb13_142223|Layer 4:
21Feb13_142223|-- Config --
21Feb13_142223|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142223|-- Weights --
21Feb13_142223|[[ 0.52944  0.12605]
21Feb13_142223| [ 0.63284 -0.38526]
21Feb13_142223| [ 0.67527  0.29750]
21Feb13_142223| [ 0.40740  0.97812]
21Feb13_142223| [ 0.02274  0.52747]]
21Feb13_142223|-- Bias --
21Feb13_142223|[-0.11042  0.13756]
21Feb13_142223|Predicting the validation and test data with the Best final individual.
21Feb13_142231| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_142231|-----------  ------------------  --------------------  ----------
21Feb13_142231|Validation         29.22                  60            0.69112
21Feb13_142231|   Test            36.40                  60            0.00000
21Feb13_142231|-------------------- Test #9 --------------------
21Feb13_142231|Best final individual weights
21Feb13_142231|Individual:
21Feb13_142231|-- Constant hidden layers --
21Feb13_142231|False
21Feb13_142231|Layer 0:
21Feb13_142231|-- Config --
21Feb13_142231|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142231|-- Weights --
21Feb13_142231|[[ 0.02949 -0.21314  0.55793  0.94607]
21Feb13_142231| [ 0.54494 -0.13388 -2.18850 -1.24993]
21Feb13_142231| [ 0.93127  1.54713 -1.88607 -0.91833]
21Feb13_142231| [ 1.62068 -1.57946  1.11151 -1.08695]
21Feb13_142231| [-0.13260 -1.08318 -0.13056  0.45542]
21Feb13_142231| [ 0.94915 -2.11720 -0.44845 -0.65953]
21Feb13_142231| [-0.64718 -0.16743  0.02334  0.33071]
21Feb13_142231| [-1.07101  1.09343  0.26311 -1.11749]
21Feb13_142231| [ 0.56855  0.82184  0.09730  1.03642]
21Feb13_142231| [ 0.76488 -0.31078 -1.04293  1.01107]
21Feb13_142231| [-0.29389  0.27353 -0.81799 -0.17169]
21Feb13_142231| [ 0.24918 -0.80413  1.51971  0.71629]
21Feb13_142231| [-2.11237  0.00422  0.01234 -0.57667]
21Feb13_142231| [ 0.34287 -0.19948  1.26816  0.16127]
21Feb13_142231| [-0.91898 -1.02408  1.21625  0.92165]
21Feb13_142231| [ 0.76676  0.05713 -1.36992 -0.04595]
21Feb13_142231| [-1.44810 -2.18811  0.93788  0.13606]
21Feb13_142231| [ 0.29511 -1.39121  0.32393 -0.14500]
21Feb13_142231| [ 0.96472 -0.35223 -1.09012  0.08188]
21Feb13_142231| [ 1.48560  0.49421 -1.59223  0.14491]
21Feb13_142231| [ 0.18934 -1.26769 -0.10912 -0.47963]
21Feb13_142231| [-0.44269 -0.17148  1.06782 -0.61087]
21Feb13_142231| [-0.30918 -1.14679  0.50587  1.28981]
21Feb13_142231| [ 1.51410 -0.05018 -0.39714  0.50568]
21Feb13_142231| [-0.21365  0.18890  0.56575  1.31303]
21Feb13_142231| [-0.16921  1.72134  1.18461  0.44631]
21Feb13_142231| [-1.45355  0.12022  0.47873  0.34247]
21Feb13_142231| [ 2.01437  1.12297 -1.23181 -0.72050]
21Feb13_142231| [ 0.88136 -1.88762  2.99802 -0.55849]
21Feb13_142231| [ 1.11605 -1.56203 -0.95603 -0.65256]
21Feb13_142231| [-0.05084 -0.82509  0.48180 -0.67476]
21Feb13_142231| [ 0.88123 -1.28858 -0.34791  0.77095]
21Feb13_142231| [-0.48507  1.87882 -1.18653 -0.71579]
21Feb13_142231| [-1.11419  0.57237  0.23759  0.42143]
21Feb13_142231| [ 0.31364  1.12433 -0.04251  0.06594]
21Feb13_142231| [-0.39339  1.31314  0.13296 -0.94228]
21Feb13_142231| [-0.19858 -0.45873  1.62016 -0.93511]
21Feb13_142231| [-0.46561 -0.49773 -0.32500  0.39146]
21Feb13_142231| [-1.61218 -0.50043  0.00800 -0.21099]
21Feb13_142231| [-1.53767 -0.12508  0.71776 -0.91764]
21Feb13_142231| [ 0.50227 -0.94228  1.48876  0.12533]
21Feb13_142231| [-0.51106  1.38447 -0.57766 -0.97504]
21Feb13_142231| [ 0.25174  0.47641  0.08750  0.27316]
21Feb13_142231| [-1.13272 -0.53631 -0.48822  0.84947]
21Feb13_142231| [ 0.57720 -2.95375 -0.60135 -0.09821]
21Feb13_142231| [-0.09633 -0.42220  0.24097  1.42855]
21Feb13_142231| [-0.52775  0.05644 -0.89810 -0.04806]
21Feb13_142231| [-0.07008  0.22178 -0.47030 -0.34568]
21Feb13_142231| [ 0.43623  0.25271  0.24773 -0.53334]
21Feb13_142231| [ 1.21597  0.23156  2.65709  0.47534]
21Feb13_142231| [-0.74570 -1.09628 -0.87167 -0.51895]
21Feb13_142231| [ 0.46274  1.50951  1.33863 -0.51660]
21Feb13_142231| [-0.31580  0.18597  1.04952 -0.07211]
21Feb13_142231| [-0.43048  0.73167 -0.52510 -0.23014]
21Feb13_142231| [-0.83409  1.23814 -0.69833 -1.07845]
21Feb13_142231| [ 1.02077  0.47418 -0.67184  0.98280]
21Feb13_142231| [-0.68248  0.26652 -1.45227 -0.91863]]
21Feb13_142231|-- Bias --
21Feb13_142231|[ 0.50862 -1.23259  0.93057  0.35182]
21Feb13_142231|Layer 1:
21Feb13_142231|-- Config --
21Feb13_142231|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142231|-- Weights --
21Feb13_142231|[[-0.24992  0.17455 -0.36398]
21Feb13_142231| [ 0.44349 -1.50812  0.10051]
21Feb13_142231| [ 0.59669  1.40652  0.37593]
21Feb13_142231| [ 0.15579 -0.41164  0.10084]]
21Feb13_142231|-- Bias --
21Feb13_142231|[ 0.42031 -0.74011 -0.09551]
21Feb13_142231|Layer 2:
21Feb13_142231|-- Config --
21Feb13_142231|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142231|-- Weights --
21Feb13_142231|[[ 0.83726 -0.58719 -0.25875]
21Feb13_142231| [ 0.23241 -0.56623  0.60034]
21Feb13_142231| [ 0.00312 -0.29054  0.18592]]
21Feb13_142231|-- Bias --
21Feb13_142231|[-0.15630 -0.49053  0.15590]
21Feb13_142231|Layer 3:
21Feb13_142231|-- Config --
21Feb13_142231|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142231|-- Weights --
21Feb13_142231|[[-0.52235  0.22995 -0.65947  0.49342  0.37135]
21Feb13_142231| [-0.45052  0.02024  0.53104 -0.90713 -0.24140]
21Feb13_142231| [ 0.51543  0.46501 -0.15932 -0.09711 -0.36513]]
21Feb13_142231|-- Bias --
21Feb13_142231|[-0.55117  0.70809 -0.97830  0.37990  0.72931]
21Feb13_142231|Layer 4:
21Feb13_142231|-- Config --
21Feb13_142231|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142231|-- Weights --
21Feb13_142231|[[ 0.52944  0.12605]
21Feb13_142231| [ 0.63284 -0.38526]
21Feb13_142231| [ 0.67527  0.29750]
21Feb13_142231| [ 0.40740  0.97812]
21Feb13_142231| [ 0.02274  0.52747]]
21Feb13_142231|-- Bias --
21Feb13_142231|[-0.11042  0.13756]
21Feb13_142231|Predicting the validation and test data with the Best final individual.
21Feb13_142239| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_142239|-----------  ------------------  --------------------  ----------
21Feb13_142239|Validation         42.00                  60            0.00000
21Feb13_142239|   Test            26.85                  60            0.70742
21Feb13_142239|-------------------- Test #10 --------------------
21Feb13_142239|Best final individual weights
21Feb13_142239|Individual:
21Feb13_142239|-- Constant hidden layers --
21Feb13_142239|False
21Feb13_142239|Layer 0:
21Feb13_142239|-- Config --
21Feb13_142239|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142239|-- Weights --
21Feb13_142239|[[ 0.02949 -0.21314  0.55793  0.94607]
21Feb13_142239| [ 0.54494 -0.13388 -2.18850 -1.24993]
21Feb13_142239| [ 0.93127  1.54713 -1.88607 -0.91833]
21Feb13_142239| [ 1.62068 -1.57946  1.11151 -1.08695]
21Feb13_142239| [-0.13260 -1.08318 -0.13056  0.45542]
21Feb13_142239| [ 0.94915 -2.11720 -0.44845 -0.65953]
21Feb13_142239| [-0.64718 -0.16743  0.02334  0.33071]
21Feb13_142239| [-1.07101  1.09343  0.26311 -1.11749]
21Feb13_142239| [ 0.56855  0.82184  0.09730  1.03642]
21Feb13_142239| [ 0.76488 -0.31078 -1.04293  1.01107]
21Feb13_142239| [-0.29389  0.27353 -0.81799 -0.17169]
21Feb13_142239| [ 0.24918 -0.80413  1.51971  0.71629]
21Feb13_142239| [-2.11237  0.00422  0.01234 -0.57667]
21Feb13_142239| [ 0.34287 -0.19948  1.26816  0.16127]
21Feb13_142239| [-0.91898 -1.02408  1.21625  0.92165]
21Feb13_142239| [ 0.76676  0.05713 -1.36992 -0.04595]
21Feb13_142239| [-1.44810 -2.18811  0.93788  0.13606]
21Feb13_142239| [ 0.29511 -1.39121  0.32393 -0.14500]
21Feb13_142239| [ 0.96472 -0.35223 -1.09012  0.08188]
21Feb13_142239| [ 1.48560  0.49421 -1.59223  0.14491]
21Feb13_142239| [ 0.18934 -1.26769 -0.10912 -0.47963]
21Feb13_142239| [-0.44269 -0.17148  1.06782 -0.61087]
21Feb13_142239| [-0.30918 -1.14679  0.50587  1.28981]
21Feb13_142239| [ 1.51410 -0.05018 -0.39714  0.50568]
21Feb13_142239| [-0.21365  0.18890  0.56575  1.31303]
21Feb13_142239| [-0.16921  1.72134  1.18461  0.44631]
21Feb13_142239| [-1.45355  0.12022  0.47873  0.34247]
21Feb13_142239| [ 2.01437  1.12297 -1.23181 -0.72050]
21Feb13_142239| [ 0.88136 -1.88762  2.99802 -0.55849]
21Feb13_142239| [ 1.11605 -1.56203 -0.95603 -0.65256]
21Feb13_142239| [-0.05084 -0.82509  0.48180 -0.67476]
21Feb13_142239| [ 0.88123 -1.28858 -0.34791  0.77095]
21Feb13_142239| [-0.48507  1.87882 -1.18653 -0.71579]
21Feb13_142239| [-1.11419  0.57237  0.23759  0.42143]
21Feb13_142239| [ 0.31364  1.12433 -0.04251  0.06594]
21Feb13_142239| [-0.39339  1.31314  0.13296 -0.94228]
21Feb13_142239| [-0.19858 -0.45873  1.62016 -0.93511]
21Feb13_142239| [-0.46561 -0.49773 -0.32500  0.39146]
21Feb13_142239| [-1.61218 -0.50043  0.00800 -0.21099]
21Feb13_142239| [-1.53767 -0.12508  0.71776 -0.91764]
21Feb13_142239| [ 0.50227 -0.94228  1.48876  0.12533]
21Feb13_142239| [-0.51106  1.38447 -0.57766 -0.97504]
21Feb13_142239| [ 0.25174  0.47641  0.08750  0.27316]
21Feb13_142239| [-1.13272 -0.53631 -0.48822  0.84947]
21Feb13_142239| [ 0.57720 -2.95375 -0.60135 -0.09821]
21Feb13_142239| [-0.09633 -0.42220  0.24097  1.42855]
21Feb13_142239| [-0.52775  0.05644 -0.89810 -0.04806]
21Feb13_142239| [-0.07008  0.22178 -0.47030 -0.34568]
21Feb13_142239| [ 0.43623  0.25271  0.24773 -0.53334]
21Feb13_142239| [ 1.21597  0.23156  2.65709  0.47534]
21Feb13_142239| [-0.74570 -1.09628 -0.87167 -0.51895]
21Feb13_142239| [ 0.46274  1.50951  1.33863 -0.51660]
21Feb13_142239| [-0.31580  0.18597  1.04952 -0.07211]
21Feb13_142239| [-0.43048  0.73167 -0.52510 -0.23014]
21Feb13_142239| [-0.83409  1.23814 -0.69833 -1.07845]
21Feb13_142239| [ 1.02077  0.47418 -0.67184  0.98280]
21Feb13_142239| [-0.68248  0.26652 -1.45227 -0.91863]]
21Feb13_142239|-- Bias --
21Feb13_142239|[ 0.50862 -1.23259  0.93057  0.35182]
21Feb13_142239|Layer 1:
21Feb13_142239|-- Config --
21Feb13_142239|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142239|-- Weights --
21Feb13_142239|[[-0.24992  0.17455 -0.36398]
21Feb13_142239| [ 0.44349 -1.50812  0.10051]
21Feb13_142239| [ 0.59669  1.40652  0.37593]
21Feb13_142239| [ 0.15579 -0.41164  0.10084]]
21Feb13_142239|-- Bias --
21Feb13_142239|[ 0.42031 -0.74011 -0.09551]
21Feb13_142239|Layer 2:
21Feb13_142239|-- Config --
21Feb13_142239|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142239|-- Weights --
21Feb13_142239|[[ 0.83726 -0.58719 -0.25875]
21Feb13_142239| [ 0.23241 -0.56623  0.60034]
21Feb13_142239| [ 0.00312 -0.29054  0.18592]]
21Feb13_142239|-- Bias --
21Feb13_142239|[-0.15630 -0.49053  0.15590]
21Feb13_142239|Layer 3:
21Feb13_142239|-- Config --
21Feb13_142239|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142239|-- Weights --
21Feb13_142239|[[-0.52235  0.22995 -0.65947  0.49342  0.37135]
21Feb13_142239| [-0.45052  0.02024  0.53104 -0.90713 -0.24140]
21Feb13_142239| [ 0.51543  0.46501 -0.15932 -0.09711 -0.36513]]
21Feb13_142239|-- Bias --
21Feb13_142239|[-0.55117  0.70809 -0.97830  0.37990  0.72931]
21Feb13_142239|Layer 4:
21Feb13_142239|-- Config --
21Feb13_142239|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142239|-- Weights --
21Feb13_142239|[[ 0.52944  0.12605]
21Feb13_142239| [ 0.63284 -0.38526]
21Feb13_142239| [ 0.67527  0.29750]
21Feb13_142239| [ 0.40740  0.97812]
21Feb13_142239| [ 0.02274  0.52747]]
21Feb13_142239|-- Bias --
21Feb13_142239|[-0.11042  0.13756]
21Feb13_142239|Predicting the validation and test data with the Best final individual.
21Feb13_142247| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_142247|-----------  ------------------  --------------------  ----------
21Feb13_142247|Validation         42.00                  60            0.00000
21Feb13_142247|   Test            36.40                  60            0.00000
21Feb13_142247|-------------------- Test #11 --------------------
21Feb13_142247|Best final individual weights
21Feb13_142247|Individual:
21Feb13_142247|-- Constant hidden layers --
21Feb13_142247|False
21Feb13_142247|Layer 0:
21Feb13_142247|-- Config --
21Feb13_142247|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142247|-- Weights --
21Feb13_142247|[[ 0.02949 -0.21314  0.55793  0.94607]
21Feb13_142247| [ 0.54494 -0.13388 -2.18850 -1.24993]
21Feb13_142247| [ 0.93127  1.54713 -1.88607 -0.91833]
21Feb13_142247| [ 1.62068 -1.57946  1.11151 -1.08695]
21Feb13_142247| [-0.13260 -1.08318 -0.13056  0.45542]
21Feb13_142247| [ 0.94915 -2.11720 -0.44845 -0.65953]
21Feb13_142247| [-0.64718 -0.16743  0.02334  0.33071]
21Feb13_142247| [-1.07101  1.09343  0.26311 -1.11749]
21Feb13_142247| [ 0.56855  0.82184  0.09730  1.03642]
21Feb13_142247| [ 0.76488 -0.31078 -1.04293  1.01107]
21Feb13_142247| [-0.29389  0.27353 -0.81799 -0.17169]
21Feb13_142247| [ 0.24918 -0.80413  1.51971  0.71629]
21Feb13_142247| [-2.11237  0.00422  0.01234 -0.57667]
21Feb13_142247| [ 0.34287 -0.19948  1.26816  0.16127]
21Feb13_142247| [-0.91898 -1.02408  1.21625  0.92165]
21Feb13_142247| [ 0.76676  0.05713 -1.36992 -0.04595]
21Feb13_142247| [-1.44810 -2.18811  0.93788  0.13606]
21Feb13_142247| [ 0.29511 -1.39121  0.32393 -0.14500]
21Feb13_142247| [ 0.96472 -0.35223 -1.09012  0.08188]
21Feb13_142247| [ 1.48560  0.49421 -1.59223  0.14491]
21Feb13_142247| [ 0.18934 -1.26769 -0.10912 -0.47963]
21Feb13_142247| [-0.44269 -0.17148  1.06782 -0.61087]
21Feb13_142247| [-0.30918 -1.14679  0.50587  1.28981]
21Feb13_142247| [ 1.51410 -0.05018 -0.39714  0.50568]
21Feb13_142247| [-0.21365  0.18890  0.56575  1.31303]
21Feb13_142247| [-0.16921  1.72134  1.18461  0.44631]
21Feb13_142247| [-1.45355  0.12022  0.47873  0.34247]
21Feb13_142247| [ 2.01437  1.12297 -1.23181 -0.72050]
21Feb13_142247| [ 0.88136 -1.88762  2.99802 -0.55849]
21Feb13_142247| [ 1.11605 -1.56203 -0.95603 -0.65256]
21Feb13_142247| [-0.05084 -0.82509  0.48180 -0.67476]
21Feb13_142247| [ 0.88123 -1.28858 -0.34791  0.77095]
21Feb13_142247| [-0.48507  1.87882 -1.18653 -0.71579]
21Feb13_142247| [-1.11419  0.57237  0.23759  0.42143]
21Feb13_142247| [ 0.31364  1.12433 -0.04251  0.06594]
21Feb13_142247| [-0.39339  1.31314  0.13296 -0.94228]
21Feb13_142247| [-0.19858 -0.45873  1.62016 -0.93511]
21Feb13_142247| [-0.46561 -0.49773 -0.32500  0.39146]
21Feb13_142247| [-1.61218 -0.50043  0.00800 -0.21099]
21Feb13_142247| [-1.53767 -0.12508  0.71776 -0.91764]
21Feb13_142247| [ 0.50227 -0.94228  1.48876  0.12533]
21Feb13_142247| [-0.51106  1.38447 -0.57766 -0.97504]
21Feb13_142247| [ 0.25174  0.47641  0.08750  0.27316]
21Feb13_142247| [-1.13272 -0.53631 -0.48822  0.84947]
21Feb13_142247| [ 0.57720 -2.95375 -0.60135 -0.09821]
21Feb13_142247| [-0.09633 -0.42220  0.24097  1.42855]
21Feb13_142247| [-0.52775  0.05644 -0.89810 -0.04806]
21Feb13_142247| [-0.07008  0.22178 -0.47030 -0.34568]
21Feb13_142247| [ 0.43623  0.25271  0.24773 -0.53334]
21Feb13_142247| [ 1.21597  0.23156  2.65709  0.47534]
21Feb13_142247| [-0.74570 -1.09628 -0.87167 -0.51895]
21Feb13_142247| [ 0.46274  1.50951  1.33863 -0.51660]
21Feb13_142247| [-0.31580  0.18597  1.04952 -0.07211]
21Feb13_142247| [-0.43048  0.73167 -0.52510 -0.23014]
21Feb13_142247| [-0.83409  1.23814 -0.69833 -1.07845]
21Feb13_142247| [ 1.02077  0.47418 -0.67184  0.98280]
21Feb13_142247| [-0.68248  0.26652 -1.45227 -0.91863]]
21Feb13_142247|-- Bias --
21Feb13_142247|[ 0.50862 -1.23259  0.93057  0.35182]
21Feb13_142247|Layer 1:
21Feb13_142247|-- Config --
21Feb13_142247|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142247|-- Weights --
21Feb13_142247|[[-0.24992  0.17455 -0.36398]
21Feb13_142247| [ 0.44349 -1.50812  0.10051]
21Feb13_142247| [ 0.59669  1.40652  0.37593]
21Feb13_142247| [ 0.15579 -0.41164  0.10084]]
21Feb13_142247|-- Bias --
21Feb13_142247|[ 0.42031 -0.74011 -0.09551]
21Feb13_142247|Layer 2:
21Feb13_142247|-- Config --
21Feb13_142247|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142247|-- Weights --
21Feb13_142247|[[ 0.83726 -0.58719 -0.25875]
21Feb13_142247| [ 0.23241 -0.56623  0.60034]
21Feb13_142247| [ 0.00312 -0.29054  0.18592]]
21Feb13_142247|-- Bias --
21Feb13_142247|[-0.15630 -0.49053  0.15590]
21Feb13_142247|Layer 3:
21Feb13_142247|-- Config --
21Feb13_142247|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142247|-- Weights --
21Feb13_142247|[[-0.52235  0.22995 -0.65947  0.49342  0.37135]
21Feb13_142247| [-0.45052  0.02024  0.53104 -0.90713 -0.24140]
21Feb13_142247| [ 0.51543  0.46501 -0.15932 -0.09711 -0.36513]]
21Feb13_142247|-- Bias --
21Feb13_142247|[-0.55117  0.70809 -0.97830  0.37990  0.72931]
21Feb13_142247|Layer 4:
21Feb13_142247|-- Config --
21Feb13_142247|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142247|-- Weights --
21Feb13_142247|[[ 0.52944  0.12605]
21Feb13_142247| [ 0.63284 -0.38526]
21Feb13_142247| [ 0.67527  0.29750]
21Feb13_142247| [ 0.40740  0.97812]
21Feb13_142247| [ 0.02274  0.52747]]
21Feb13_142247|-- Bias --
21Feb13_142247|[-0.11042  0.13756]
21Feb13_142247|Predicting the validation and test data with the Best final individual.
21Feb13_142255| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_142255|-----------  ------------------  --------------------  ----------
21Feb13_142255|Validation         42.00                  60            0.00000
21Feb13_142255|   Test            23.89                  60            0.60020
21Feb13_142255|-------------------- Test #12 --------------------
21Feb13_142255|Best final individual weights
21Feb13_142255|Individual:
21Feb13_142255|-- Constant hidden layers --
21Feb13_142255|False
21Feb13_142255|Layer 0:
21Feb13_142255|-- Config --
21Feb13_142255|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142255|-- Weights --
21Feb13_142255|[[ 0.02949 -0.21314  0.55793  0.94607]
21Feb13_142255| [ 0.54494 -0.13388 -2.18850 -1.24993]
21Feb13_142255| [ 0.93127  1.54713 -1.88607 -0.91833]
21Feb13_142255| [ 1.62068 -1.57946  1.11151 -1.08695]
21Feb13_142255| [-0.13260 -1.08318 -0.13056  0.45542]
21Feb13_142255| [ 0.94915 -2.11720 -0.44845 -0.65953]
21Feb13_142255| [-0.64718 -0.16743  0.02334  0.33071]
21Feb13_142255| [-1.07101  1.09343  0.26311 -1.11749]
21Feb13_142255| [ 0.56855  0.82184  0.09730  1.03642]
21Feb13_142255| [ 0.76488 -0.31078 -1.04293  1.01107]
21Feb13_142255| [-0.29389  0.27353 -0.81799 -0.17169]
21Feb13_142255| [ 0.24918 -0.80413  1.51971  0.71629]
21Feb13_142255| [-2.11237  0.00422  0.01234 -0.57667]
21Feb13_142255| [ 0.34287 -0.19948  1.26816  0.16127]
21Feb13_142255| [-0.91898 -1.02408  1.21625  0.92165]
21Feb13_142255| [ 0.76676  0.05713 -1.36992 -0.04595]
21Feb13_142255| [-1.44810 -2.18811  0.93788  0.13606]
21Feb13_142255| [ 0.29511 -1.39121  0.32393 -0.14500]
21Feb13_142255| [ 0.96472 -0.35223 -1.09012  0.08188]
21Feb13_142255| [ 1.48560  0.49421 -1.59223  0.14491]
21Feb13_142255| [ 0.18934 -1.26769 -0.10912 -0.47963]
21Feb13_142255| [-0.44269 -0.17148  1.06782 -0.61087]
21Feb13_142255| [-0.30918 -1.14679  0.50587  1.28981]
21Feb13_142255| [ 1.51410 -0.05018 -0.39714  0.50568]
21Feb13_142255| [-0.21365  0.18890  0.56575  1.31303]
21Feb13_142255| [-0.16921  1.72134  1.18461  0.44631]
21Feb13_142255| [-1.45355  0.12022  0.47873  0.34247]
21Feb13_142255| [ 2.01437  1.12297 -1.23181 -0.72050]
21Feb13_142255| [ 0.88136 -1.88762  2.99802 -0.55849]
21Feb13_142255| [ 1.11605 -1.56203 -0.95603 -0.65256]
21Feb13_142255| [-0.05084 -0.82509  0.48180 -0.67476]
21Feb13_142255| [ 0.88123 -1.28858 -0.34791  0.77095]
21Feb13_142255| [-0.48507  1.87882 -1.18653 -0.71579]
21Feb13_142255| [-1.11419  0.57237  0.23759  0.42143]
21Feb13_142255| [ 0.31364  1.12433 -0.04251  0.06594]
21Feb13_142255| [-0.39339  1.31314  0.13296 -0.94228]
21Feb13_142255| [-0.19858 -0.45873  1.62016 -0.93511]
21Feb13_142255| [-0.46561 -0.49773 -0.32500  0.39146]
21Feb13_142255| [-1.61218 -0.50043  0.00800 -0.21099]
21Feb13_142255| [-1.53767 -0.12508  0.71776 -0.91764]
21Feb13_142255| [ 0.50227 -0.94228  1.48876  0.12533]
21Feb13_142255| [-0.51106  1.38447 -0.57766 -0.97504]
21Feb13_142255| [ 0.25174  0.47641  0.08750  0.27316]
21Feb13_142255| [-1.13272 -0.53631 -0.48822  0.84947]
21Feb13_142255| [ 0.57720 -2.95375 -0.60135 -0.09821]
21Feb13_142255| [-0.09633 -0.42220  0.24097  1.42855]
21Feb13_142255| [-0.52775  0.05644 -0.89810 -0.04806]
21Feb13_142255| [-0.07008  0.22178 -0.47030 -0.34568]
21Feb13_142255| [ 0.43623  0.25271  0.24773 -0.53334]
21Feb13_142255| [ 1.21597  0.23156  2.65709  0.47534]
21Feb13_142255| [-0.74570 -1.09628 -0.87167 -0.51895]
21Feb13_142255| [ 0.46274  1.50951  1.33863 -0.51660]
21Feb13_142255| [-0.31580  0.18597  1.04952 -0.07211]
21Feb13_142255| [-0.43048  0.73167 -0.52510 -0.23014]
21Feb13_142255| [-0.83409  1.23814 -0.69833 -1.07845]
21Feb13_142255| [ 1.02077  0.47418 -0.67184  0.98280]
21Feb13_142255| [-0.68248  0.26652 -1.45227 -0.91863]]
21Feb13_142255|-- Bias --
21Feb13_142255|[ 0.50862 -1.23259  0.93057  0.35182]
21Feb13_142255|Layer 1:
21Feb13_142255|-- Config --
21Feb13_142255|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142255|-- Weights --
21Feb13_142255|[[-0.24992  0.17455 -0.36398]
21Feb13_142255| [ 0.44349 -1.50812  0.10051]
21Feb13_142255| [ 0.59669  1.40652  0.37593]
21Feb13_142255| [ 0.15579 -0.41164  0.10084]]
21Feb13_142255|-- Bias --
21Feb13_142255|[ 0.42031 -0.74011 -0.09551]
21Feb13_142255|Layer 2:
21Feb13_142255|-- Config --
21Feb13_142255|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142255|-- Weights --
21Feb13_142255|[[ 0.83726 -0.58719 -0.25875]
21Feb13_142255| [ 0.23241 -0.56623  0.60034]
21Feb13_142255| [ 0.00312 -0.29054  0.18592]]
21Feb13_142255|-- Bias --
21Feb13_142255|[-0.15630 -0.49053  0.15590]
21Feb13_142255|Layer 3:
21Feb13_142255|-- Config --
21Feb13_142255|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142255|-- Weights --
21Feb13_142255|[[-0.52235  0.22995 -0.65947  0.49342  0.37135]
21Feb13_142255| [-0.45052  0.02024  0.53104 -0.90713 -0.24140]
21Feb13_142255| [ 0.51543  0.46501 -0.15932 -0.09711 -0.36513]]
21Feb13_142255|-- Bias --
21Feb13_142255|[-0.55117  0.70809 -0.97830  0.37990  0.72931]
21Feb13_142255|Layer 4:
21Feb13_142255|-- Config --
21Feb13_142255|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142255|-- Weights --
21Feb13_142255|[[ 0.52944  0.12605]
21Feb13_142255| [ 0.63284 -0.38526]
21Feb13_142255| [ 0.67527  0.29750]
21Feb13_142255| [ 0.40740  0.97812]
21Feb13_142255| [ 0.02274  0.52747]]
21Feb13_142255|-- Bias --
21Feb13_142255|[-0.11042  0.13756]
21Feb13_142255|Predicting the validation and test data with the Best final individual.
21Feb13_142303| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_142303|-----------  ------------------  --------------------  ----------
21Feb13_142303|Validation         42.00                  60            0.00000
21Feb13_142303|   Test            36.84                  60            0.02649
21Feb13_142303|-------------------- Test #13 --------------------
21Feb13_142303|Best final individual weights
21Feb13_142303|Individual:
21Feb13_142303|-- Constant hidden layers --
21Feb13_142303|False
21Feb13_142303|Layer 0:
21Feb13_142303|-- Config --
21Feb13_142303|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142303|-- Weights --
21Feb13_142303|[[ 0.02949 -0.21314  0.55793  0.94607]
21Feb13_142303| [ 0.54494 -0.13388 -2.18850 -1.24993]
21Feb13_142303| [ 0.93127  1.54713 -1.88607 -0.91833]
21Feb13_142303| [ 1.62068 -1.57946  1.11151 -1.08695]
21Feb13_142303| [-0.13260 -1.08318 -0.13056  0.45542]
21Feb13_142303| [ 0.94915 -2.11720 -0.44845 -0.65953]
21Feb13_142303| [-0.64718 -0.16743  0.02334  0.33071]
21Feb13_142303| [-1.07101  1.09343  0.26311 -1.11749]
21Feb13_142303| [ 0.56855  0.82184  0.09730  1.03642]
21Feb13_142303| [ 0.76488 -0.31078 -1.04293  1.01107]
21Feb13_142303| [-0.29389  0.27353 -0.81799 -0.17169]
21Feb13_142303| [ 0.24918 -0.80413  1.51971  0.71629]
21Feb13_142303| [-2.11237  0.00422  0.01234 -0.57667]
21Feb13_142303| [ 0.34287 -0.19948  1.26816  0.16127]
21Feb13_142303| [-0.91898 -1.02408  1.21625  0.92165]
21Feb13_142303| [ 0.76676  0.05713 -1.36992 -0.04595]
21Feb13_142303| [-1.44810 -2.18811  0.93788  0.13606]
21Feb13_142303| [ 0.29511 -1.39121  0.32393 -0.14500]
21Feb13_142303| [ 0.96472 -0.35223 -1.09012  0.08188]
21Feb13_142303| [ 1.48560  0.49421 -1.59223  0.14491]
21Feb13_142303| [ 0.18934 -1.26769 -0.10912 -0.47963]
21Feb13_142303| [-0.44269 -0.17148  1.06782 -0.61087]
21Feb13_142303| [-0.30918 -1.14679  0.50587  1.28981]
21Feb13_142303| [ 1.51410 -0.05018 -0.39714  0.50568]
21Feb13_142303| [-0.21365  0.18890  0.56575  1.31303]
21Feb13_142303| [-0.16921  1.72134  1.18461  0.44631]
21Feb13_142303| [-1.45355  0.12022  0.47873  0.34247]
21Feb13_142303| [ 2.01437  1.12297 -1.23181 -0.72050]
21Feb13_142303| [ 0.88136 -1.88762  2.99802 -0.55849]
21Feb13_142303| [ 1.11605 -1.56203 -0.95603 -0.65256]
21Feb13_142303| [-0.05084 -0.82509  0.48180 -0.67476]
21Feb13_142303| [ 0.88123 -1.28858 -0.34791  0.77095]
21Feb13_142303| [-0.48507  1.87882 -1.18653 -0.71579]
21Feb13_142303| [-1.11419  0.57237  0.23759  0.42143]
21Feb13_142303| [ 0.31364  1.12433 -0.04251  0.06594]
21Feb13_142303| [-0.39339  1.31314  0.13296 -0.94228]
21Feb13_142303| [-0.19858 -0.45873  1.62016 -0.93511]
21Feb13_142303| [-0.46561 -0.49773 -0.32500  0.39146]
21Feb13_142303| [-1.61218 -0.50043  0.00800 -0.21099]
21Feb13_142303| [-1.53767 -0.12508  0.71776 -0.91764]
21Feb13_142303| [ 0.50227 -0.94228  1.48876  0.12533]
21Feb13_142303| [-0.51106  1.38447 -0.57766 -0.97504]
21Feb13_142303| [ 0.25174  0.47641  0.08750  0.27316]
21Feb13_142303| [-1.13272 -0.53631 -0.48822  0.84947]
21Feb13_142303| [ 0.57720 -2.95375 -0.60135 -0.09821]
21Feb13_142303| [-0.09633 -0.42220  0.24097  1.42855]
21Feb13_142303| [-0.52775  0.05644 -0.89810 -0.04806]
21Feb13_142303| [-0.07008  0.22178 -0.47030 -0.34568]
21Feb13_142303| [ 0.43623  0.25271  0.24773 -0.53334]
21Feb13_142303| [ 1.21597  0.23156  2.65709  0.47534]
21Feb13_142303| [-0.74570 -1.09628 -0.87167 -0.51895]
21Feb13_142303| [ 0.46274  1.50951  1.33863 -0.51660]
21Feb13_142303| [-0.31580  0.18597  1.04952 -0.07211]
21Feb13_142303| [-0.43048  0.73167 -0.52510 -0.23014]
21Feb13_142303| [-0.83409  1.23814 -0.69833 -1.07845]
21Feb13_142303| [ 1.02077  0.47418 -0.67184  0.98280]
21Feb13_142303| [-0.68248  0.26652 -1.45227 -0.91863]]
21Feb13_142303|-- Bias --
21Feb13_142303|[ 0.50862 -1.23259  0.93057  0.35182]
21Feb13_142303|Layer 1:
21Feb13_142303|-- Config --
21Feb13_142303|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142303|-- Weights --
21Feb13_142303|[[-0.24992  0.17455 -0.36398]
21Feb13_142303| [ 0.44349 -1.50812  0.10051]
21Feb13_142303| [ 0.59669  1.40652  0.37593]
21Feb13_142303| [ 0.15579 -0.41164  0.10084]]
21Feb13_142303|-- Bias --
21Feb13_142303|[ 0.42031 -0.74011 -0.09551]
21Feb13_142303|Layer 2:
21Feb13_142303|-- Config --
21Feb13_142303|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142303|-- Weights --
21Feb13_142303|[[ 0.83726 -0.58719 -0.25875]
21Feb13_142303| [ 0.23241 -0.56623  0.60034]
21Feb13_142303| [ 0.00312 -0.29054  0.18592]]
21Feb13_142303|-- Bias --
21Feb13_142303|[-0.15630 -0.49053  0.15590]
21Feb13_142303|Layer 3:
21Feb13_142303|-- Config --
21Feb13_142303|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142303|-- Weights --
21Feb13_142303|[[-0.52235  0.22995 -0.65947  0.49342  0.37135]
21Feb13_142303| [-0.45052  0.02024  0.53104 -0.90713 -0.24140]
21Feb13_142303| [ 0.51543  0.46501 -0.15932 -0.09711 -0.36513]]
21Feb13_142303|-- Bias --
21Feb13_142303|[-0.55117  0.70809 -0.97830  0.37990  0.72931]
21Feb13_142303|Layer 4:
21Feb13_142303|-- Config --
21Feb13_142303|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142303|-- Weights --
21Feb13_142303|[[ 0.52944  0.12605]
21Feb13_142303| [ 0.63284 -0.38526]
21Feb13_142303| [ 0.67527  0.29750]
21Feb13_142303| [ 0.40740  0.97812]
21Feb13_142303| [ 0.02274  0.52747]]
21Feb13_142303|-- Bias --
21Feb13_142303|[-0.11042  0.13756]
21Feb13_142303|Predicting the validation and test data with the Best final individual.
21Feb13_142311| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_142311|-----------  ------------------  --------------------  ----------
21Feb13_142311|Validation         24.70                  60            0.68191
21Feb13_142311|   Test            25.98                  60            0.69238
21Feb13_142311|-------------------- Test #14 --------------------
21Feb13_142311|Best final individual weights
21Feb13_142311|Individual:
21Feb13_142311|-- Constant hidden layers --
21Feb13_142311|False
21Feb13_142311|Layer 0:
21Feb13_142311|-- Config --
21Feb13_142311|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142311|-- Weights --
21Feb13_142311|[[ 0.02949 -0.21314  0.55793  0.94607]
21Feb13_142311| [ 0.54494 -0.13388 -2.18850 -1.24993]
21Feb13_142311| [ 0.93127  1.54713 -1.88607 -0.91833]
21Feb13_142311| [ 1.62068 -1.57946  1.11151 -1.08695]
21Feb13_142311| [-0.13260 -1.08318 -0.13056  0.45542]
21Feb13_142311| [ 0.94915 -2.11720 -0.44845 -0.65953]
21Feb13_142311| [-0.64718 -0.16743  0.02334  0.33071]
21Feb13_142311| [-1.07101  1.09343  0.26311 -1.11749]
21Feb13_142311| [ 0.56855  0.82184  0.09730  1.03642]
21Feb13_142311| [ 0.76488 -0.31078 -1.04293  1.01107]
21Feb13_142311| [-0.29389  0.27353 -0.81799 -0.17169]
21Feb13_142311| [ 0.24918 -0.80413  1.51971  0.71629]
21Feb13_142311| [-2.11237  0.00422  0.01234 -0.57667]
21Feb13_142311| [ 0.34287 -0.19948  1.26816  0.16127]
21Feb13_142311| [-0.91898 -1.02408  1.21625  0.92165]
21Feb13_142311| [ 0.76676  0.05713 -1.36992 -0.04595]
21Feb13_142311| [-1.44810 -2.18811  0.93788  0.13606]
21Feb13_142311| [ 0.29511 -1.39121  0.32393 -0.14500]
21Feb13_142311| [ 0.96472 -0.35223 -1.09012  0.08188]
21Feb13_142311| [ 1.48560  0.49421 -1.59223  0.14491]
21Feb13_142311| [ 0.18934 -1.26769 -0.10912 -0.47963]
21Feb13_142311| [-0.44269 -0.17148  1.06782 -0.61087]
21Feb13_142311| [-0.30918 -1.14679  0.50587  1.28981]
21Feb13_142311| [ 1.51410 -0.05018 -0.39714  0.50568]
21Feb13_142311| [-0.21365  0.18890  0.56575  1.31303]
21Feb13_142311| [-0.16921  1.72134  1.18461  0.44631]
21Feb13_142311| [-1.45355  0.12022  0.47873  0.34247]
21Feb13_142311| [ 2.01437  1.12297 -1.23181 -0.72050]
21Feb13_142311| [ 0.88136 -1.88762  2.99802 -0.55849]
21Feb13_142311| [ 1.11605 -1.56203 -0.95603 -0.65256]
21Feb13_142311| [-0.05084 -0.82509  0.48180 -0.67476]
21Feb13_142311| [ 0.88123 -1.28858 -0.34791  0.77095]
21Feb13_142311| [-0.48507  1.87882 -1.18653 -0.71579]
21Feb13_142311| [-1.11419  0.57237  0.23759  0.42143]
21Feb13_142311| [ 0.31364  1.12433 -0.04251  0.06594]
21Feb13_142311| [-0.39339  1.31314  0.13296 -0.94228]
21Feb13_142311| [-0.19858 -0.45873  1.62016 -0.93511]
21Feb13_142311| [-0.46561 -0.49773 -0.32500  0.39146]
21Feb13_142311| [-1.61218 -0.50043  0.00800 -0.21099]
21Feb13_142311| [-1.53767 -0.12508  0.71776 -0.91764]
21Feb13_142311| [ 0.50227 -0.94228  1.48876  0.12533]
21Feb13_142311| [-0.51106  1.38447 -0.57766 -0.97504]
21Feb13_142311| [ 0.25174  0.47641  0.08750  0.27316]
21Feb13_142311| [-1.13272 -0.53631 -0.48822  0.84947]
21Feb13_142311| [ 0.57720 -2.95375 -0.60135 -0.09821]
21Feb13_142311| [-0.09633 -0.42220  0.24097  1.42855]
21Feb13_142311| [-0.52775  0.05644 -0.89810 -0.04806]
21Feb13_142311| [-0.07008  0.22178 -0.47030 -0.34568]
21Feb13_142311| [ 0.43623  0.25271  0.24773 -0.53334]
21Feb13_142311| [ 1.21597  0.23156  2.65709  0.47534]
21Feb13_142311| [-0.74570 -1.09628 -0.87167 -0.51895]
21Feb13_142311| [ 0.46274  1.50951  1.33863 -0.51660]
21Feb13_142311| [-0.31580  0.18597  1.04952 -0.07211]
21Feb13_142311| [-0.43048  0.73167 -0.52510 -0.23014]
21Feb13_142311| [-0.83409  1.23814 -0.69833 -1.07845]
21Feb13_142311| [ 1.02077  0.47418 -0.67184  0.98280]
21Feb13_142311| [-0.68248  0.26652 -1.45227 -0.91863]]
21Feb13_142311|-- Bias --
21Feb13_142311|[ 0.50862 -1.23259  0.93057  0.35182]
21Feb13_142311|Layer 1:
21Feb13_142311|-- Config --
21Feb13_142311|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142311|-- Weights --
21Feb13_142311|[[-0.24992  0.17455 -0.36398]
21Feb13_142311| [ 0.44349 -1.50812  0.10051]
21Feb13_142311| [ 0.59669  1.40652  0.37593]
21Feb13_142311| [ 0.15579 -0.41164  0.10084]]
21Feb13_142311|-- Bias --
21Feb13_142311|[ 0.42031 -0.74011 -0.09551]
21Feb13_142311|Layer 2:
21Feb13_142311|-- Config --
21Feb13_142311|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142311|-- Weights --
21Feb13_142311|[[ 0.83726 -0.58719 -0.25875]
21Feb13_142311| [ 0.23241 -0.56623  0.60034]
21Feb13_142311| [ 0.00312 -0.29054  0.18592]]
21Feb13_142311|-- Bias --
21Feb13_142311|[-0.15630 -0.49053  0.15590]
21Feb13_142311|Layer 3:
21Feb13_142311|-- Config --
21Feb13_142311|{'name': 'Hidden4', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142311|-- Weights --
21Feb13_142311|[[-0.52235  0.22995 -0.65947  0.49342  0.37135]
21Feb13_142311| [-0.45052  0.02024  0.53104 -0.90713 -0.24140]
21Feb13_142311| [ 0.51543  0.46501 -0.15932 -0.09711 -0.36513]]
21Feb13_142311|-- Bias --
21Feb13_142311|[-0.55117  0.70809 -0.97830  0.37990  0.72931]
21Feb13_142311|Layer 4:
21Feb13_142311|-- Config --
21Feb13_142311|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_142311|-- Weights --
21Feb13_142311|[[ 0.52944  0.12605]
21Feb13_142311| [ 0.63284 -0.38526]
21Feb13_142311| [ 0.67527  0.29750]
21Feb13_142311| [ 0.40740  0.97812]
21Feb13_142311| [ 0.02274  0.52747]]
21Feb13_142311|-- Bias --
21Feb13_142311|[-0.11042  0.13756]
21Feb13_142311|Predicting the validation and test data with the Best final individual.
21Feb13_142319| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_142319|-----------  ------------------  --------------------  ----------
21Feb13_142319|Validation         42.00                  60            0.00000
21Feb13_142319|   Test            36.40                  60            0.00000
2021-02-13 14:23:19.879385: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
21Feb13_142320|Data summary: Train
21Feb13_142320|data.shape = (2300, 57)
21Feb13_142320|labels.shape = (2300,)
21Feb13_142320|Class distribution:
21Feb13_142320|	0 - 1389 (0.60)
21Feb13_142320|	1 - 911 (0.40)
21Feb13_142320|Data summary: Validation
21Feb13_142320|data.shape = (1150, 57)
21Feb13_142320|labels.shape = (1150,)
21Feb13_142320|Class distribution:
21Feb13_142320|	0 - 667 (0.58)
21Feb13_142320|	1 - 483 (0.42)
21Feb13_142320|Data summary: Test
21Feb13_142320|data.shape = (1151, 57)
21Feb13_142320|labels.shape = (1151,)
21Feb13_142320|Class distribution:
21Feb13_142320|	0 - 732 (0.64)
21Feb13_142320|	1 - 419 (0.36)
21Feb13_142320|Selected configuration values
21Feb13_142320|-- Dataset name: spambase2
21Feb13_142320|-- Initial population size: 64
21Feb13_142320|-- Maximun number of generations: 32
21Feb13_142320|-- Neurons per hidden layer range: (2, 20)
21Feb13_142320|-- Hidden layers number range: (1, 3)
21Feb13_142320|-- Crossover probability: 0.5
21Feb13_142320|-- Bias gene mutation probability: 0.2
21Feb13_142320|-- Weights gene mutation probability: 0.75
21Feb13_142320|-- Neuron mutation probability: 0.3
21Feb13_142320|-- Layer mutation probability: 0.3
21Feb13_142320|-- Constant hidden layers: False
21Feb13_142320|-- Seed: 31415
21Feb13_142320|Entering GA
21Feb13_142320|Start the algorithm
2021-02-13 14:23:20.739968: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-13 14:23:20.740514: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-02-13 14:23:20.763341: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-13 14:23:20.763689: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.71GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s
2021-02-13 14:23:20.763708: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-02-13 14:23:20.765350: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-02-13 14:23:20.765394: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-02-13 14:23:20.765985: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-02-13 14:23:20.766134: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-02-13 14:23:20.766212: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-13 14:23:20.766633: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-02-13 14:23:20.766677: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-13 14:23:20.766683: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-02-13 14:23:20.766919: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-02-13 14:23:20.767774: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-13 14:23:20.767794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-13 14:23:20.767798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      
2021-02-13 14:23:20.817733: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-02-13 14:23:20.818090: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3493635000 Hz
/home/jmerelo/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype("int32")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn('`model.predict_classes()` is deprecated and '
21Feb13_142722|-- Generation 1 --
21Feb13_142722|    -- Crossed 1 individual pairs.
21Feb13_142722|    -- Mutated 32 individuals.
21Feb13_143120|    -- Evaluated 64 individuals.
21Feb13_143120|    Summary of generation 1:
21Feb13_143120| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_143120|-----------  ------------------  --------------------  ----------
21Feb13_143120|    Max            42.70                159.00          0.78937
21Feb13_143120|    Avg            41.75                44.62           0.01471
21Feb13_143120|    Min            25.13                 3.00           0.00000
21Feb13_143120|    Std             2.10                45.24           0.09771
21Feb13_143120|   Best            25.13                69.00           0.78937
21Feb13_143120|-- Generation 2 --
21Feb13_143120|    -- Crossed 5 individual pairs.
21Feb13_143120|    -- Mutated 32 individuals.
21Feb13_143514|    -- Evaluated 64 individuals.
21Feb13_143514|    Summary of generation 2:
21Feb13_143514| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_143514|-----------  ------------------  --------------------  ----------
21Feb13_143514|    Max            42.35                69.00           0.05357
21Feb13_143514|    Avg            41.95                21.69           0.00334
21Feb13_143514|    Min            40.78                 3.00           0.00000
21Feb13_143514|    Std             0.21                20.26           0.00768
21Feb13_143514|   Best            40.78                12.00           0.05357
21Feb13_143514|-- Generation 3 --
21Feb13_143514|    -- Crossed 1 individual pairs.
21Feb13_143514|    -- Mutated 32 individuals.
21Feb13_143905|    -- Evaluated 64 individuals.
21Feb13_143905|    Summary of generation 3:
21Feb13_143905| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_143905|-----------  ------------------  --------------------  ----------
21Feb13_143905|    Max            50.78                102.00          0.80187
21Feb13_143905|    Avg            42.10                17.98           0.01545
21Feb13_143905|    Min            41.39                 3.00           0.00000
21Feb13_143905|    Std             1.10                21.57           0.09952
21Feb13_143905|   Best            41.39                11.00           0.01805
21Feb13_143905|-- Generation 4 --
21Feb13_143905|    -- Crossed 5 individual pairs.
21Feb13_143905|    -- Mutated 32 individuals.
21Feb13_144253|    -- Evaluated 64 individuals.
21Feb13_144253|    Summary of generation 4:
21Feb13_144253| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_144253|-----------  ------------------  --------------------  ----------
21Feb13_144253|    Max            42.26                64.00           0.01805
21Feb13_144253|    Avg            42.00                11.78           0.00145
21Feb13_144253|    Min            41.39                 3.00           0.00000
21Feb13_144253|    Std             0.11                13.65           0.00295
21Feb13_144253|   Best            41.39                 5.00           0.01805
21Feb13_144253|-- Generation 5 --
21Feb13_144253|    -- Crossed 6 individual pairs.
21Feb13_144253|    -- Mutated 32 individuals.
21Feb13_144641|    -- Evaluated 64 individuals.
21Feb13_144641|    Summary of generation 5:
21Feb13_144641| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_144641|-----------  ------------------  --------------------  ----------
21Feb13_144641|    Max            42.17                64.00           0.58326
21Feb13_144641|    Avg            41.62                10.05           0.01876
21Feb13_144641|    Min            27.74                 2.00           0.00000
21Feb13_144641|    Std             2.09                11.90           0.09783
21Feb13_144641|   Best            27.74                30.00           0.58326
21Feb13_144641|-- Generation 6 --
21Feb13_144641|    -- Crossed 5 individual pairs.
21Feb13_144641|    -- Mutated 32 individuals.
21Feb13_145030|    -- Evaluated 64 individuals.
21Feb13_145030|    Summary of generation 6:
21Feb13_145030| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_145030|-----------  ------------------  --------------------  ----------
21Feb13_145030|    Max            42.17                64.00           0.81749
21Feb13_145030|    Avg            41.77                 9.39           0.01370
21Feb13_145030|    Min            27.91                 2.00           0.00000
21Feb13_145030|    Std             1.75                10.50           0.10128
21Feb13_145030|   Best            27.91                20.00           0.81749
21Feb13_145030|-- Generation 7 --
21Feb13_145030|    -- Crossed 3 individual pairs.
21Feb13_145030|    -- Mutated 32 individuals.
21Feb13_145418|    -- Evaluated 64 individuals.
21Feb13_145418|    Summary of generation 7:
21Feb13_145418| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_145418|-----------  ------------------  --------------------  ----------
21Feb13_145418|    Max            42.70                64.00           0.77105
21Feb13_145418|    Avg            41.76                 9.02           0.01334
21Feb13_145418|    Min            26.87                 2.00           0.00000
21Feb13_145418|    Std             1.88                11.86           0.09551
21Feb13_145418|   Best            26.87                14.00           0.77105
21Feb13_145418|-- Generation 8 --
21Feb13_145418|    -- Crossed 6 individual pairs.
21Feb13_145418|    -- Mutated 32 individuals.
21Feb13_145805|    -- Evaluated 64 individuals.
21Feb13_145805|    Summary of generation 8:
21Feb13_145805| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_145805|-----------  ------------------  --------------------  ----------
21Feb13_145805|    Max            42.09                30.00           0.75206
21Feb13_145805|    Avg            41.68                 6.42           0.02133
21Feb13_145805|    Min            29.22                 2.00           0.00000
21Feb13_145805|    Std             1.68                 6.00           0.11144
21Feb13_145805|   Best            29.22                 8.00           0.75206
21Feb13_145805|-- Generation 9 --
21Feb13_145805|    -- Crossed 3 individual pairs.
21Feb13_145805|    -- Mutated 32 individuals.
21Feb13_150152|    -- Evaluated 64 individuals.
21Feb13_150152|    Summary of generation 9:
21Feb13_150152| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_150152|-----------  ------------------  --------------------  ----------
21Feb13_150152|    Max            42.17                28.00           0.02062
21Feb13_150152|    Avg            41.96                 8.17           0.00202
21Feb13_150152|    Min            41.30                 2.00           0.00000
21Feb13_150152|    Std             0.11                 6.74           0.00311
21Feb13_150152|   Best            41.30                10.00           0.02062
21Feb13_150152|-- Generation 10 --
21Feb13_150152|    -- Crossed 5 individual pairs.
21Feb13_150152|    -- Mutated 32 individuals.
21Feb13_150540|    -- Evaluated 64 individuals.
21Feb13_150540|    Summary of generation 10:
21Feb13_150540| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_150540|-----------  ------------------  --------------------  ----------
21Feb13_150540|    Max            42.17                28.00           0.64516
21Feb13_150540|    Avg            41.69                 8.50           0.01263
21Feb13_150540|    Min            26.00                 2.00           0.00000
21Feb13_150540|    Std             1.98                 6.55           0.07973
21Feb13_150540|   Best            26.00                14.00           0.64516
21Feb13_150540|-- Generation 11 --
21Feb13_150540|    -- Crossed 3 individual pairs.
21Feb13_150540|    -- Mutated 32 individuals.
21Feb13_150929|    -- Evaluated 64 individuals.
21Feb13_150929|    Summary of generation 11:
21Feb13_150929| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_150929|-----------  ------------------  --------------------  ----------
21Feb13_150929|    Max            53.04                30.00           0.80354
21Feb13_150929|    Avg            41.83                11.50           0.02744
21Feb13_150929|    Min            24.17                 2.00           0.00000
21Feb13_150929|    Std             2.62                 7.62           0.13864
21Feb13_150929|   Best            24.17                22.00           0.80354
21Feb13_150929|-- Generation 12 --
21Feb13_150929|    -- Crossed 6 individual pairs.
21Feb13_150929|    -- Mutated 32 individuals.
21Feb13_151316|    -- Evaluated 64 individuals.
21Feb13_151316|    Summary of generation 12:
21Feb13_151316| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_151316|-----------  ------------------  --------------------  ----------
21Feb13_151316|    Max            42.09                26.00           0.32312
21Feb13_151316|    Avg            41.76                 8.89           0.00852
21Feb13_151316|    Min            32.17                 2.00           0.00000
21Feb13_151316|    Std             1.21                 5.49           0.03975
21Feb13_151316|   Best            32.17                26.00           0.32312
21Feb13_151316|-- Generation 13 --
21Feb13_151316|    -- Crossed 7 individual pairs.
21Feb13_151316|    -- Mutated 32 individuals.
21Feb13_151703|    -- Evaluated 64 individuals.
21Feb13_151703|    Summary of generation 13:
21Feb13_151703| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_151703|-----------  ------------------  --------------------  ----------
21Feb13_151703|    Max            42.26                30.00           0.32573
21Feb13_151703|    Avg            41.79                 9.06           0.00872
21Feb13_151703|    Min            33.04                 2.00           0.00000
21Feb13_151703|    Std             1.11                 6.02           0.04000
21Feb13_151703|   Best            33.04                26.00           0.32573
21Feb13_151703|-- Generation 14 --
21Feb13_151703|    -- Crossed 6 individual pairs.
21Feb13_151703|    -- Mutated 32 individuals.
21Feb13_152051|    -- Evaluated 64 individuals.
21Feb13_152051|    Summary of generation 14:
21Feb13_152051| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_152051|-----------  ------------------  --------------------  ----------
21Feb13_152051|    Max            42.17                51.00           0.05365
21Feb13_152051|    Avg            41.91                 9.38           0.00423
21Feb13_152051|    Min            40.52                 2.00           0.00000
21Feb13_152051|    Std             0.20                 7.86           0.00652
21Feb13_152051|   Best            40.52                32.00           0.05365
21Feb13_152051|-- Generation 15 --
21Feb13_152051|    -- Crossed 4 individual pairs.
21Feb13_152051|    -- Mutated 32 individuals.
21Feb13_152441|    -- Evaluated 64 individuals.
21Feb13_152441|    Summary of generation 15:
21Feb13_152441| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_152441|-----------  ------------------  --------------------  ----------
21Feb13_152441|    Max            42.00                32.00           0.82887
21Feb13_152441|    Avg            41.65                10.58           0.01663
21Feb13_152441|    Min            25.83                 2.00           0.00000
21Feb13_152441|    Std             2.00                 7.59           0.10237
21Feb13_152441|   Best            25.83                32.00           0.82887
21Feb13_152441|-- Generation 16 --
21Feb13_152441|    -- Crossed 5 individual pairs.
21Feb13_152441|    -- Mutated 32 individuals.
21Feb13_152830|    -- Evaluated 64 individuals.
21Feb13_152830|    Summary of generation 16:
21Feb13_152830| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_152830|-----------  ------------------  --------------------  ----------
21Feb13_152830|    Max            46.43                32.00           0.81205
21Feb13_152830|    Avg            41.71                10.95           0.02811
21Feb13_152830|    Min            24.96                 2.00           0.00000
21Feb13_152830|    Std             2.19                 7.84           0.13705
21Feb13_152830|   Best            24.96                26.00           0.76954
21Feb13_152830|-- Generation 17 --
21Feb13_152830|    -- Crossed 3 individual pairs.
21Feb13_152830|    -- Mutated 32 individuals.
21Feb13_153217|    -- Evaluated 64 individuals.
21Feb13_153217|    Summary of generation 17:
21Feb13_153217| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_153217|-----------  ------------------  --------------------  ----------
21Feb13_153217|    Max            42.52                54.00           0.00775
21Feb13_153217|    Avg            41.90                 9.47           0.00388
21Feb13_153217|    Min            41.74                 2.00           0.00000
21Feb13_153217|    Std             0.12                 8.30           0.00237
21Feb13_153217|   Best            41.74                 8.00           0.00775
21Feb13_153217|-- Generation 18 --
21Feb13_153217|    -- Crossed 4 individual pairs.
21Feb13_153217|    -- Mutated 32 individuals.
21Feb13_153605|    -- Evaluated 64 individuals.
21Feb13_153605|    Summary of generation 18:
21Feb13_153605| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_153605|-----------  ------------------  --------------------  ----------
21Feb13_153605|    Max            42.17                30.00           0.00775
21Feb13_153605|    Avg            41.89                 9.77           0.00388
21Feb13_153605|    Min            41.74                 2.00           0.00000
21Feb13_153605|    Std             0.09                 7.00           0.00224
21Feb13_153605|   Best            41.74                 8.00           0.00775
21Feb13_153605|-- Generation 19 --
21Feb13_153605|    -- Crossed 7 individual pairs.
21Feb13_153605|    -- Mutated 32 individuals.
21Feb13_153953|    -- Evaluated 64 individuals.
21Feb13_153953|    Summary of generation 19:
21Feb13_153953| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_153953|-----------  ------------------  --------------------  ----------
21Feb13_153953|    Max            42.09                30.00           0.04608
21Feb13_153953|    Avg            41.87                 9.94           0.00516
21Feb13_153953|    Min            40.70                 2.00           0.00000
21Feb13_153953|    Std             0.17                 6.58           0.00549
21Feb13_153953|   Best            40.70                22.00           0.04608
21Feb13_153953|-- Generation 20 --
21Feb13_153953|    -- Crossed 7 individual pairs.
21Feb13_153953|    -- Mutated 32 individuals.
21Feb13_154340|    -- Evaluated 64 individuals.
21Feb13_154340|    Summary of generation 20:
21Feb13_154340| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_154340|-----------  ------------------  --------------------  ----------
21Feb13_154340|    Max            42.52                30.00           0.81248
21Feb13_154340|    Avg            41.55                10.73           0.01778
21Feb13_154340|    Min            21.74                 2.00           0.00000
21Feb13_154340|    Std             2.50                 6.78           0.10019
21Feb13_154340|   Best            21.74                24.00           0.81248
21Feb13_154340|-- Generation 21 --
21Feb13_154340|    -- Crossed 10 individual pairs.
21Feb13_154340|    -- Mutated 32 individuals.
21Feb13_154728|    -- Evaluated 64 individuals.
21Feb13_154728|    Summary of generation 21:
21Feb13_154728| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_154728|-----------  ------------------  --------------------  ----------
21Feb13_154728|    Max            42.35                26.00           0.02061
21Feb13_154728|    Avg            41.87                10.22           0.00496
21Feb13_154728|    Min            41.39                 2.00           0.00000
21Feb13_154728|    Std             0.12                 6.40           0.00323
21Feb13_154728|   Best            41.39                 8.00           0.02061
21Feb13_154728|-- Generation 22 --
21Feb13_154728|    -- Crossed 7 individual pairs.
21Feb13_154728|    -- Mutated 32 individuals.
21Feb13_155115|    -- Evaluated 64 individuals.
21Feb13_155115|    Summary of generation 22:
21Feb13_155115| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_155115|-----------  ------------------  --------------------  ----------
21Feb13_155115|    Max            42.09                26.00           0.02318
21Feb13_155115|    Avg            41.85                 8.66           0.00545
21Feb13_155115|    Min            41.22                 2.00           0.00000
21Feb13_155115|    Std             0.14                 5.23           0.00403
21Feb13_155115|   Best            41.22                 9.00           0.02318
21Feb13_155115|-- Generation 23 --
21Feb13_155115|    -- Crossed 7 individual pairs.
21Feb13_155115|    -- Mutated 32 individuals.
21Feb13_155502|    -- Evaluated 64 individuals.
21Feb13_155502|    Summary of generation 23:
21Feb13_155502| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_155502|-----------  ------------------  --------------------  ----------
21Feb13_155502|    Max            42.09                26.00           0.03085
21Feb13_155502|    Avg            41.84                 9.33           0.00577
21Feb13_155502|    Min            41.04                 2.00           0.00000
21Feb13_155502|    Std             0.15                 5.88           0.00450
21Feb13_155502|   Best            41.04                 8.00           0.03085
21Feb13_155502|-- Generation 24 --
21Feb13_155502|    -- Crossed 6 individual pairs.
21Feb13_155502|    -- Mutated 32 individuals.
21Feb13_155849|    -- Evaluated 64 individuals.
21Feb13_155849|    Summary of generation 24:
21Feb13_155849| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_155849|-----------  ------------------  --------------------  ----------
21Feb13_155849|    Max            42.52                26.00           0.77213
21Feb13_155849|    Avg            41.58                 8.86           0.01803
21Feb13_155849|    Min            25.39                 2.00           0.00000
21Feb13_155849|    Std             2.05                 6.21           0.09516
21Feb13_155849|   Best            25.39                20.00           0.77213
21Feb13_155849|-- Generation 25 --
21Feb13_155849|    -- Crossed 6 individual pairs.
21Feb13_155849|    -- Mutated 32 individuals.
21Feb13_160239|    -- Evaluated 64 individuals.
21Feb13_160239|    Summary of generation 25:
21Feb13_160239| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_160239|-----------  ------------------  --------------------  ----------
21Feb13_160239|    Max            42.26                45.00           0.68623
21Feb13_160239|    Avg            41.22                 9.38           0.03138
21Feb13_160239|    Min            26.52                 2.00           0.00000
21Feb13_160239|    Std             2.91                 7.89           0.12278
21Feb13_160239|   Best            26.52                20.00           0.64823
21Feb13_160239|-- Generation 26 --
21Feb13_160239|    -- Crossed 5 individual pairs.
21Feb13_160239|    -- Mutated 32 individuals.
21Feb13_160627|    -- Evaluated 64 individuals.
21Feb13_160627|    Summary of generation 26:
21Feb13_160627| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_160627|-----------  ------------------  --------------------  ----------
21Feb13_160627|    Max            43.65                33.00           0.82595
21Feb13_160627|    Avg            41.25                 8.81           0.05234
21Feb13_160627|    Min            22.43                 2.00           0.00000
21Feb13_160627|    Std             3.06                 8.04           0.18124
21Feb13_160627|   Best            22.43                14.00           0.79912
21Feb13_160627|-- Generation 27 --
21Feb13_160627|    -- Crossed 6 individual pairs.
21Feb13_160627|    -- Mutated 32 individuals.
21Feb13_161016|    -- Evaluated 64 individuals.
21Feb13_161016|    Summary of generation 27:
21Feb13_161016| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_161016|-----------  ------------------  --------------------  ----------
21Feb13_161016|    Max            42.17                45.00           0.82981
21Feb13_161016|    Avg            41.05                10.03           0.04237
21Feb13_161016|    Min            24.17                 2.00           0.00000
21Feb13_161016|    Std             3.53                 8.57           0.16697
21Feb13_161016|   Best            24.17                12.00           0.82200
21Feb13_161016|-- Generation 28 --
21Feb13_161016|    -- Crossed 4 individual pairs.
21Feb13_161016|    -- Mutated 32 individuals.
21Feb13_161405|    -- Evaluated 64 individuals.
21Feb13_161405|    Summary of generation 28:
21Feb13_161405| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_161405|-----------  ------------------  --------------------  ----------
21Feb13_161405|    Max            46.70                24.00           0.80892
21Feb13_161405|    Avg            41.58                 8.16           0.03226
21Feb13_161405|    Min            31.65                 2.00           0.00000
21Feb13_161405|    Std             1.54                 6.40           0.11397
21Feb13_161405|   Best            31.65                22.00           0.37506
21Feb13_161405|-- Generation 29 --
21Feb13_161405|    -- Crossed 5 individual pairs.
21Feb13_161405|    -- Mutated 32 individuals.
21Feb13_161753|    -- Evaluated 64 individuals.
21Feb13_161753|    Summary of generation 29:
21Feb13_161753| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_161753|-----------  ------------------  --------------------  ----------
21Feb13_161753|    Max            51.22                42.00           0.79826
21Feb13_161753|    Avg            41.45                10.17           0.03820
21Feb13_161753|    Min            25.39                 2.00           0.00000
21Feb13_161753|    Std             3.03                 7.72           0.14177
21Feb13_161753|   Best            25.39                12.00           0.63117
21Feb13_161753|-- Generation 30 --
21Feb13_161753|    -- Crossed 3 individual pairs.
21Feb13_161753|    -- Mutated 32 individuals.
21Feb13_162143|    -- Evaluated 64 individuals.
21Feb13_162143|    Summary of generation 30:
21Feb13_162143| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_162143|-----------  ------------------  --------------------  ----------
21Feb13_162143|    Max            42.17                48.00           0.70603
21Feb13_162143|    Avg            41.29                 9.41           0.02937
21Feb13_162143|    Min            25.13                 2.00           0.00000
21Feb13_162143|    Std             2.69                 8.86           0.12111
21Feb13_162143|   Best            25.13                48.00           0.70603
21Feb13_162143|-- Generation 31 --
21Feb13_162143|    -- Crossed 4 individual pairs.
21Feb13_162143|    -- Mutated 32 individuals.
21Feb13_162534|    -- Evaluated 64 individuals.
21Feb13_162534|    Summary of generation 31:
21Feb13_162534| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_162534|-----------  ------------------  --------------------  ----------
21Feb13_162534|    Max            54.09                48.00           0.79407
21Feb13_162534|    Avg            41.57                11.11           0.03805
21Feb13_162534|    Min            28.61                 2.00           0.00000
21Feb13_162534|    Std             2.79                 9.94           0.14178
21Feb13_162534|   Best            28.61                22.00           0.49051
21Feb13_162534|-- Generation 32 --
21Feb13_162534|    -- Crossed 4 individual pairs.
21Feb13_162534|    -- Mutated 32 individuals.
21Feb13_162923|    -- Evaluated 64 individuals.
21Feb13_162923|    Summary of generation 32:
21Feb13_162923| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_162923|-----------  ------------------  --------------------  ----------
21Feb13_162923|    Max            53.04                51.00           0.82745
21Feb13_162923|    Avg            41.56                11.78           0.04089
21Feb13_162923|    Min            27.57                 2.00           0.00000
21Feb13_162923|    Std             2.69                10.76           0.15116
21Feb13_162923|   Best            27.57                51.00           0.49500
21Feb13_162923|Best initial individual weights
21Feb13_162923|Individual:
21Feb13_162923|-- Constant hidden layers --
21Feb13_162923|False
21Feb13_162923|Layer 0:
21Feb13_162923|-- Config --
21Feb13_162923|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_162923|-- Weights --
21Feb13_162923|[[-0.27202 -0.86357 -0.55480 -0.23305 -0.86065  0.00935]
21Feb13_162923| [ 0.79962  0.37670  0.29685  0.27749  0.49011 -0.69201]
21Feb13_162923| [ 0.14479  0.91685 -0.48781  0.43998  0.63560 -0.30697]
21Feb13_162923| [ 0.38698  0.86287 -0.71294  0.64752 -0.03047 -0.77785]
21Feb13_162923| [ 0.48209  0.66076  0.64751  0.81042 -0.07483  0.42515]
21Feb13_162923| [ 0.55955 -0.47655 -0.07712 -0.63479 -0.35794  0.52636]
21Feb13_162923| [ 0.38576  0.23223  0.25353  0.73450 -0.90178 -0.96369]
21Feb13_162923| [ 0.11039  0.36714  0.33686  0.01774  0.45868  0.81669]
21Feb13_162923| [-0.79637  0.26224 -0.03232  0.48232 -0.15309  0.61156]
21Feb13_162923| [-0.88621  0.90413  0.87744 -0.64355 -0.40369 -0.97981]
21Feb13_162923| [-0.68940  0.06179 -0.18424  0.08150 -0.45878  0.41370]
21Feb13_162923| [-0.36044 -0.13559  0.65226 -0.07204  0.54308  0.16062]
21Feb13_162923| [ 0.11714  0.93671 -0.29633  0.99754  0.45369 -0.70753]
21Feb13_162923| [ 0.64728 -0.33413 -0.57208 -0.73568  0.75425 -0.55104]
21Feb13_162923| [-0.99999 -0.96058  0.33387  0.28233 -0.17633  0.03884]
21Feb13_162923| [-0.31698 -0.57029  0.10048  0.21559 -0.52309  0.33687]
21Feb13_162923| [ 0.61192 -0.96178 -0.06414 -0.36741  0.15685  0.02906]
21Feb13_162923| [-0.75997 -0.73378  0.49810  0.83880 -0.83756 -0.54574]
21Feb13_162923| [ 0.84699 -0.24948  0.54050  0.73535 -0.06642 -0.14727]
21Feb13_162923| [-0.94868 -0.55371 -0.60216  0.40726 -0.98034 -0.48830]
21Feb13_162923| [ 0.83709 -0.79262  0.03398 -0.48243 -0.43785 -0.35972]
21Feb13_162923| [-0.44328  0.52441 -0.25583  0.35182 -0.83091 -0.39106]
21Feb13_162923| [-0.15833  0.20269  0.54130 -0.37920  0.09680  0.17172]
21Feb13_162923| [ 0.39523 -0.09539 -0.94133 -0.81601 -0.29414  0.09808]
21Feb13_162923| [ 0.86566 -0.82514  0.72303  0.62921 -0.61237  0.81126]
21Feb13_162923| [ 0.76870  0.06416 -0.11886 -0.75631 -0.12365 -0.72666]
21Feb13_162923| [ 0.89288  0.41306 -0.54112  0.04405 -0.79963  0.73224]
21Feb13_162923| [ 0.93553  0.89126 -0.61857  0.87545 -0.23947  0.75701]
21Feb13_162923| [-0.82086  0.81521  0.86256 -0.74272 -0.12443 -0.22844]
21Feb13_162923| [ 0.97160  0.41439 -0.41378 -0.28541  0.97440  0.41257]
21Feb13_162923| [ 0.70964  0.93589  0.10477  0.43589 -0.53252 -0.32168]
21Feb13_162923| [ 0.78787 -0.33435  0.99010 -0.65538  0.82368  0.49009]
21Feb13_162923| [ 0.22751  0.13008 -0.77326 -0.52830  0.50907  0.36905]
21Feb13_162923| [-0.27162 -0.36135  0.67608 -0.27532  0.90150  0.01127]
21Feb13_162923| [ 0.32844  0.99962 -0.09280  0.45964  0.99188 -0.46898]
21Feb13_162923| [-0.18508  0.43122 -0.20933  0.22437 -0.38523 -0.93105]
21Feb13_162923| [-0.71925  0.06113  0.19689 -0.43143 -0.18550 -0.84294]
21Feb13_162923| [-0.26779 -0.36079  0.46561  0.91330  0.52255 -0.08778]
21Feb13_162923| [-0.77037  0.39767  0.64833 -0.98560  0.46858  0.31212]
21Feb13_162923| [-0.85160 -0.84100 -0.57533 -0.89125 -0.26714 -0.03784]
21Feb13_162923| [-0.45978 -0.09001 -0.25873 -0.50100  0.50007  0.36246]
21Feb13_162923| [ 0.24085  0.09905  0.63589  0.41544  0.94690 -0.17740]
21Feb13_162923| [ 0.37276 -0.55653  0.03085 -0.57053  0.64921  0.77760]
21Feb13_162923| [-0.15149  0.70665 -0.89632  0.21282 -0.46831 -0.02174]
21Feb13_162923| [-0.90518 -0.77970  0.95331  0.59768  0.52171 -0.16887]
21Feb13_162923| [-0.91831  0.02967 -0.06979  0.13512 -0.23631 -0.64488]
21Feb13_162923| [ 0.97479 -0.94377  0.06324  0.51263  0.92015  0.33195]
21Feb13_162923| [-0.23392  0.17446 -0.00269  0.39550  0.16762  0.49246]
21Feb13_162923| [-0.38197 -0.12955 -0.15881  0.40103 -0.44224  0.28044]
21Feb13_162923| [-0.18428 -0.43672  0.17268 -0.61813  0.37910  0.10582]
21Feb13_162923| [-0.90436 -0.34919  0.78535  0.66625 -0.73042 -0.71018]
21Feb13_162923| [ 0.51032 -0.77746 -0.44325  0.84430 -0.30217 -0.29958]
21Feb13_162923| [ 0.68940  0.61874 -0.16478 -0.15758 -0.13000  0.90632]
21Feb13_162923| [ 0.03548 -0.47831  0.42708 -0.16343 -0.95208  0.69563]
21Feb13_162923| [-0.01411  0.20035  0.12539 -0.96161  0.92710 -0.77067]
21Feb13_162923| [ 0.81703  0.44147  0.72058 -0.81223 -0.67418 -0.85267]
21Feb13_162923| [-0.26530  0.72399 -0.58999 -0.15740  0.39892 -0.58918]]
21Feb13_162923|-- Bias --
21Feb13_162923|[ 0.23050  0.64820 -0.64277 -0.41900 -0.54681  0.15437]
21Feb13_162923|Layer 1:
21Feb13_162923|-- Config --
21Feb13_162923|{'name': 'Hidden1', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 7, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_162923|-- Weights --
21Feb13_162923|[[-0.50321 -0.80875 -0.60144 -0.65045  0.61886 -0.77767  0.32772]
21Feb13_162923| [-0.04845 -0.89529  0.64487 -0.62765 -0.63134  0.05243 -0.44669]
21Feb13_162923| [-0.43718  0.21711  0.81639 -0.51368 -0.99854 -0.22537  0.94769]
21Feb13_162923| [-0.24806 -0.09443  0.39011  0.48081 -0.14372 -0.70297 -0.89667]
21Feb13_162923| [ 0.70687  0.42155  0.18340 -0.17501  0.52040  0.16771  0.10606]
21Feb13_162923| [ 0.44794  0.33101  0.53886 -0.17021  0.78118 -0.81555  0.43746]]
21Feb13_162923|-- Bias --
21Feb13_162923|[-0.73477  0.09614 -0.39402 -0.10087  0.57570 -0.12327  0.59815]
21Feb13_162923|Layer 2:
21Feb13_162923|-- Config --
21Feb13_162923|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 7], 'dtype': 'float32', 'units': 10, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_162923|-- Weights --
21Feb13_162923|[[ 0.31908 -0.68092  0.42155  0.77600 -0.73710 -0.39887 -0.07843  0.23743
21Feb13_162923|   0.15714 -0.76581]
21Feb13_162923| [ 0.86369 -0.12993 -0.24148  0.53900  0.76709  0.96250 -0.56779 -0.90161
21Feb13_162923|  -0.05478 -0.07884]
21Feb13_162923| [ 0.55244  0.08052  0.06876 -0.21762  0.03301  0.12657 -0.10267 -0.45140
21Feb13_162923|   0.74279 -0.68060]
21Feb13_162923| [-0.82927  0.38658 -0.24283 -0.60293  0.98747 -0.55144  0.76581  0.09305
21Feb13_162923|   0.25851  0.32179]
21Feb13_162923| [ 0.50403 -0.55046  0.84432 -0.88204 -0.35981  0.51384 -0.70348  0.60683
21Feb13_162923|  -0.43326  0.96808]
21Feb13_162923| [-0.55850  0.68494  0.22628  0.92543 -0.20070  0.79557  0.78836  0.80610
21Feb13_162923|   0.78859 -0.65676]
21Feb13_162923| [-0.65413 -0.45252 -0.64423  0.93837  0.67689 -0.63509 -0.98556 -0.70209
21Feb13_162923|   0.15696  0.38727]]
21Feb13_162923|-- Bias --
21Feb13_162923|[ 0.74117  0.06232 -0.97740  0.25194  0.96653  0.46481  0.25293  0.37737
21Feb13_162923| -0.98026 -0.39274]
21Feb13_162923|Layer 3:
21Feb13_162923|-- Config --
21Feb13_162923|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 10], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_162923|-- Weights --
21Feb13_162923|[[ 0.00457 -0.86221]
21Feb13_162923| [ 0.78832  0.80619]
21Feb13_162923| [ 0.15057 -0.18753]
21Feb13_162923| [ 0.89929 -0.85656]
21Feb13_162923| [ 0.75527  0.29249]
21Feb13_162923| [-0.45525  0.95025]
21Feb13_162923| [ 0.35702  0.60776]
21Feb13_162923| [ 0.11856 -0.18745]
21Feb13_162923| [-0.97968 -0.74320]
21Feb13_162923| [-0.86733  0.80774]]
21Feb13_162923|-- Bias --
21Feb13_162923|[ 0.82786 -0.37827]
21Feb13_162923|Predicting the validation and test data with the Best initial individual.
21Feb13_162931| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_162931|-----------  ------------------  --------------------  ----------
21Feb13_162931|Validation         42.00                  69            0.00000
21Feb13_162931|   Test            36.40                  69            0.00000
21Feb13_162931|-------------------- Test #0 --------------------
21Feb13_162931|Best final individual weights
21Feb13_162931|Individual:
21Feb13_162931|-- Constant hidden layers --
21Feb13_162931|False
21Feb13_162931|Layer 0:
21Feb13_162931|-- Config --
21Feb13_162931|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 8, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_162931|-- Weights --
21Feb13_162931|[[-7.96509e-01 -1.15059e+00 -6.26034e-01 -2.57608e-01 -1.16276e+00
21Feb13_162931|   2.17486e-01 -9.34321e-01  1.47903e-01]
21Feb13_162931| [ 1.83510e+00 -1.21927e-01 -7.21994e-01 -3.87175e-01  1.44182e+00
21Feb13_162931|  -5.60339e-01 -1.69323e+00  3.84702e-01]
21Feb13_162931| [ 2.29647e+00  4.98135e-01 -5.82819e-01 -6.51931e-01 -5.00483e-01
21Feb13_162931|  -5.21971e-01  1.02927e+00  1.39999e-01]
21Feb13_162931| [-1.71433e+00  5.20461e-01  1.07786e-01  1.72497e-01  8.17631e-01
21Feb13_162931|  -1.23382e-01 -7.64470e-01  6.85373e-01]
21Feb13_162931| [ 5.32175e-02  1.59085e+00  2.07908e+00 -1.24494e+00  2.20682e+00
21Feb13_162931|  -1.25821e+00 -1.66929e+00  1.94038e+00]
21Feb13_162931| [ 3.73667e-01  1.74451e+00  1.26327e-01  1.39647e+00  1.05080e+00
21Feb13_162931|   2.43187e-01  2.53561e-02  2.31324e-01]
21Feb13_162931| [-1.12310e+00 -1.74495e+00  1.77094e+00 -4.73527e-01  8.36949e-01
21Feb13_162931|   7.71774e-01 -4.35311e-01  1.53145e+00]
21Feb13_162931| [ 2.13217e+00  1.37125e+00 -9.20890e-01  1.06924e+00 -1.32771e+00
21Feb13_162931|   7.09898e-01  1.11439e+00 -1.27760e+00]
21Feb13_162931| [-1.77403e-02 -4.28601e-01  1.65835e+00 -1.87197e-01  1.00957e+00
21Feb13_162931|   2.55297e-01  1.06387e-01  1.21832e+00]
21Feb13_162931| [ 2.16525e+00 -1.25784e-01 -5.41529e-01  1.97828e-01  2.28966e+00
21Feb13_162931|  -1.46028e+00  4.98379e-03 -4.40688e-01]
21Feb13_162931| [-7.39511e-02  2.47569e-01 -2.23324e-01 -2.69329e+00 -1.10672e+00
21Feb13_162931|   1.29711e+00 -1.02474e+00 -3.36463e-01]
21Feb13_162931| [ 7.56693e-01 -1.07233e-01 -6.28270e-01  9.12612e-01 -8.77877e-01
21Feb13_162931|  -9.20839e-01 -2.24401e-01 -1.13295e+00]
21Feb13_162931| [-9.56727e-01 -1.86328e+00 -1.69292e-01  1.09894e+00 -7.25733e-01
21Feb13_162931|   7.74090e-01  4.02577e-01 -6.00141e-01]
21Feb13_162931| [-1.51671e+00 -9.25981e-02 -3.63639e-01 -5.52293e-02  3.65719e-01
21Feb13_162931|  -2.63172e-01 -9.22686e-01 -1.59066e+00]
21Feb13_162931| [ 6.19485e-01  1.04762e+00  1.15913e-01  7.68427e-01  9.88362e-01
21Feb13_162931|   4.00572e-01  1.01580e+00 -1.00402e+00]
21Feb13_162931| [ 7.91163e-01 -1.28156e+00 -3.72928e-01  1.20917e+00  7.26087e-02
21Feb13_162931|   1.23038e+00 -7.97295e-01  7.15324e-01]
21Feb13_162931| [ 7.69403e-01 -2.23882e+00 -4.06537e-01 -8.30657e-01 -1.85295e+00
21Feb13_162931|  -3.96728e-01 -1.32753e-01  1.40371e+00]
21Feb13_162931| [ 8.63582e-01 -4.52795e-01  3.96789e-01  7.20922e-01  9.68883e-01
21Feb13_162931|   5.76722e-01 -8.25456e-02 -9.35541e-01]
21Feb13_162931| [-7.49275e-01 -9.06243e-01  1.18676e+00  5.39848e-01  1.41834e+00
21Feb13_162931|   4.33185e-01 -6.77846e-01 -6.19523e-01]
21Feb13_162931| [-8.91000e-01 -4.94536e-01  5.48779e-01  2.33437e+00  1.49354e+00
21Feb13_162931|  -5.62471e-01  7.67750e-01  5.34580e-01]
21Feb13_162931| [-2.22339e+00 -9.48349e-02  1.11523e-01 -1.88580e+00  1.55613e+00
21Feb13_162931|  -2.63893e+00  1.54688e+00  3.23628e-01]
21Feb13_162931| [-8.55111e-01  8.53349e-02 -7.83263e-01 -1.51315e+00  1.04588e+00
21Feb13_162931|  -1.91727e-02  1.95011e+00  3.79730e-01]
21Feb13_162931| [ 2.51049e+00 -5.71821e-01 -3.88096e-01 -5.52635e-01 -6.13567e-01
21Feb13_162931|  -1.58586e+00  1.50576e+00 -3.00998e-01]
21Feb13_162931| [ 1.93294e+00  3.34612e-01  1.64052e+00 -6.15246e-02  1.30100e+00
21Feb13_162931|   1.76044e+00 -3.04681e-01  1.12959e+00]
21Feb13_162931| [-1.54512e+00  8.03853e-01  7.85451e-01 -6.07936e-01  1.46778e+00
21Feb13_162931|  -2.14726e-01  3.85177e-01  8.03591e-01]
21Feb13_162931| [-7.43437e-01 -9.54122e-01  1.29250e-01  6.55511e-01  2.19896e-01
21Feb13_162931|  -3.25329e-01 -1.79744e+00  1.49641e+00]
21Feb13_162931| [-1.06592e-01  1.44267e+00 -9.93954e-01 -1.01275e+00 -1.80724e+00
21Feb13_162931|  -1.61250e+00  3.80720e-01  1.00622e+00]
21Feb13_162931| [-1.24952e+00 -9.83355e-01 -1.52174e+00 -6.88709e-02 -1.82968e+00
21Feb13_162931|  -1.70623e+00  5.64768e-01  1.84679e+00]
21Feb13_162931| [-2.16342e-01  9.31138e-01  4.23135e-01  6.51742e-01  1.10173e+00
21Feb13_162931|  -5.06868e-01  1.23298e+00 -4.11005e-01]
21Feb13_162931| [-6.95216e-01 -3.15809e-01 -2.07574e+00  1.38096e+00 -1.71834e+00
21Feb13_162931|  -1.00945e+00 -1.93909e+00 -1.90334e-01]
21Feb13_162931| [ 1.07621e+00  9.00909e-02 -1.16790e+00  6.47977e-01  4.48710e-01
21Feb13_162931|  -2.35271e+00  1.03246e+00  9.83788e-01]
21Feb13_162931| [-1.87550e+00 -1.35257e+00  7.95260e-01  1.64205e+00  6.37801e-01
21Feb13_162931|  -1.21482e+00 -1.45812e+00 -1.58185e-01]
21Feb13_162931| [ 4.31964e-01 -2.36822e-01  2.71119e-01 -1.28570e-01 -1.53996e+00
21Feb13_162931|   5.51374e-01  8.51521e-01 -1.87252e-03]
21Feb13_162931| [ 7.36059e-01  2.03168e+00 -2.68137e-01  1.70106e+00  8.03452e-01
21Feb13_162931|  -9.28072e-01  3.15312e+00  5.03465e-01]
21Feb13_162931| [ 1.80659e+00 -4.69960e-01  5.45626e-02  3.79517e-01 -9.48898e-01
21Feb13_162931|   3.17335e-01  4.23174e-02  1.25038e-01]
21Feb13_162931| [-1.36823e+00 -1.09100e+00  5.58333e-01 -1.75850e+00 -5.38353e-01
21Feb13_162931|   1.32464e+00 -1.44645e+00 -8.10629e-01]
21Feb13_162931| [ 1.34275e+00 -1.41251e+00 -4.78630e-01  1.46547e+00  5.64584e-01
21Feb13_162931|  -1.16980e+00 -2.78855e-01  9.98143e-01]
21Feb13_162931| [ 2.09905e+00  1.12670e-01 -2.75076e-02  3.01802e-01 -4.44158e-01
21Feb13_162931|   5.97231e-01 -4.45245e-01 -6.24110e-01]
21Feb13_162931| [ 1.47398e-01  4.79586e-01 -1.51079e-01 -1.26635e+00 -1.86360e+00
21Feb13_162931|   3.85638e-01 -2.26102e-01 -5.36332e-01]
21Feb13_162931| [ 2.39414e+00 -1.49220e+00  1.71112e+00 -3.26483e-02 -7.30602e-01
21Feb13_162931|  -7.71260e-01  1.35484e+00  1.46918e-01]
21Feb13_162931| [-8.79683e-01  2.04363e-01 -1.00453e+00  4.97801e-01  5.37708e-01
21Feb13_162931|   4.84817e-02  1.46449e-01  1.00633e+00]
21Feb13_162931| [ 9.87510e-01 -1.73494e+00 -3.97664e-01 -1.86384e+00 -1.37373e-01
21Feb13_162931|   9.58713e-01  7.88842e-01 -5.64893e-01]
21Feb13_162931| [ 1.23733e+00 -6.34561e-01  1.62916e-01  7.97154e-01  2.56756e-03
21Feb13_162931|  -5.26820e-01  1.12518e+00 -7.32085e-02]
21Feb13_162931| [ 9.60993e-02  2.80900e+00  1.96107e+00  2.67847e-01 -9.99283e-01
21Feb13_162931|  -4.52254e-01 -1.16903e+00  5.34274e-01]
21Feb13_162931| [ 1.46344e-01 -1.36033e-01  1.46780e+00  5.16901e-01 -2.00846e-01
21Feb13_162931|  -9.87830e-01  7.06146e-01  8.09746e-01]
21Feb13_162931| [ 1.55725e+00  7.75166e-01 -6.09187e-01  4.12681e-01  9.89784e-01
21Feb13_162931|  -3.28362e-01 -8.20779e-01 -1.15257e+00]
21Feb13_162931| [ 4.80557e-01  1.49401e-01 -8.28445e-01 -7.57686e-01 -1.21364e-01
21Feb13_162931|  -3.60461e-01 -1.25299e+00  1.96698e+00]
21Feb13_162931| [-4.30322e-01 -3.22697e+00 -4.46022e-01 -1.86729e+00  1.57431e+00
21Feb13_162931|   1.75365e-01  6.92210e-03 -6.13423e-01]
21Feb13_162931| [-1.34320e+00 -2.25301e+00  7.42062e-01 -6.16108e-01 -1.65630e-01
21Feb13_162931|  -4.69016e-01  1.84444e+00  3.27314e-01]
21Feb13_162931| [-5.16134e-02  2.23419e+00 -5.91959e-01  9.32150e-01 -1.06772e+00
21Feb13_162931|  -5.11523e-01  6.85844e-01 -1.03689e+00]
21Feb13_162931| [-1.30007e+00 -3.59148e-01  3.35093e-01  4.66641e-01  6.22570e-01
21Feb13_162931|  -1.71881e+00  7.41306e-01  1.11108e+00]
21Feb13_162931| [-2.00853e-01 -9.24747e-01 -2.19487e-01  6.18157e-01  6.43791e-01
21Feb13_162931|  -1.30594e+00  8.00212e-01  5.97219e-01]
21Feb13_162931| [-1.19358e+00 -5.99902e-01 -1.36178e+00  6.16698e-02 -1.07130e+00
21Feb13_162931|  -9.13657e-01 -5.31884e-01  5.48692e-01]
21Feb13_162931| [ 1.17813e+00 -8.97985e-01  1.95108e+00  2.09820e-01  2.84393e-03
21Feb13_162931|   1.23481e+00 -1.68539e-01  2.33940e-01]
21Feb13_162931| [-9.10662e-01  1.46989e+00 -1.08973e+00 -7.32452e-01 -2.41675e+00
21Feb13_162931|  -4.44959e-01  1.16536e+00 -9.01145e-01]
21Feb13_162931| [-8.82564e-01  7.05310e-01 -1.01819e+00 -2.26405e+00 -1.34282e+00
21Feb13_162931|   6.97505e-01  1.34754e+00 -2.32821e+00]
21Feb13_162931| [-4.48054e-01 -1.49619e+00  7.66455e-01  1.28585e-02  2.52223e-01
21Feb13_162931|  -1.68540e+00 -9.38609e-02 -2.02003e+00]]
21Feb13_162931|-- Bias --
21Feb13_162931|[ 1.17808e-03 -4.44270e-01  8.22591e-02  1.09959e+00 -3.08221e-01
21Feb13_162931|  1.75965e-01 -1.99442e-01 -1.41265e+00]
21Feb13_162931|Layer 1:
21Feb13_162931|-- Config --
21Feb13_162931|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 8], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_162931|-- Weights --
21Feb13_162931|[[-0.98226  0.24821  1.19463]
21Feb13_162931| [ 0.22008  1.26392 -0.48812]
21Feb13_162931| [ 0.36979  0.18930  0.10872]
21Feb13_162931| [-0.31853  0.06591 -0.63823]
21Feb13_162931| [-1.04688  0.28658  0.05164]
21Feb13_162931| [-0.46144  0.29281  0.32274]
21Feb13_162931| [-1.38143  0.64735 -0.30380]
21Feb13_162931| [ 0.42874 -0.73215 -0.07617]]
21Feb13_162931|-- Bias --
21Feb13_162931|[ 0.11283 -0.91883 -0.02107]
21Feb13_162931|Layer 2:
21Feb13_162931|-- Config --
21Feb13_162931|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_162931|-- Weights --
21Feb13_162931|[[-1.30873  0.76809  0.90757 -0.59244  0.54910 -0.47315]
21Feb13_162931| [-0.99187 -0.37179  0.74019 -0.16616  0.19931 -0.01629]
21Feb13_162931| [ 1.03741 -0.10805  0.70718 -0.07401 -0.40500 -0.37353]]
21Feb13_162931|-- Bias --
21Feb13_162931|[ 0.24190 -0.18750 -1.26833 -0.88541 -0.79598  0.36384]
21Feb13_162931|Layer 3:
21Feb13_162931|-- Config --
21Feb13_162931|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_162931|-- Weights --
21Feb13_162931|[[-0.60635  0.23318]
21Feb13_162931| [-0.14250  0.55489]
21Feb13_162931| [-0.48538 -0.15199]
21Feb13_162931| [ 0.42067 -0.62737]
21Feb13_162931| [-0.99709  0.64501]
21Feb13_162931| [-0.25790  0.29907]]
21Feb13_162931|-- Bias --
21Feb13_162931|[-0.14887  1.00429]
21Feb13_162931|Predicting the validation and test data with the Best final individual.
21Feb13_162939| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_162939|-----------  ------------------  --------------------  ----------
21Feb13_162939|Validation         27.22                  51            0.54570
21Feb13_162939|   Test            36.40                  51            0.00000
21Feb13_162939|-------------------- Test #1 --------------------
21Feb13_162939|Best final individual weights
21Feb13_162939|Individual:
21Feb13_162939|-- Constant hidden layers --
21Feb13_162939|False
21Feb13_162939|Layer 0:
21Feb13_162939|-- Config --
21Feb13_162939|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 8, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_162939|-- Weights --
21Feb13_162939|[[-7.96509e-01 -1.15059e+00 -6.26034e-01 -2.57608e-01 -1.16276e+00
21Feb13_162939|   2.17486e-01 -9.34321e-01  1.47903e-01]
21Feb13_162939| [ 1.83510e+00 -1.21927e-01 -7.21994e-01 -3.87175e-01  1.44182e+00
21Feb13_162939|  -5.60339e-01 -1.69323e+00  3.84702e-01]
21Feb13_162939| [ 2.29647e+00  4.98135e-01 -5.82819e-01 -6.51931e-01 -5.00483e-01
21Feb13_162939|  -5.21971e-01  1.02927e+00  1.39999e-01]
21Feb13_162939| [-1.71433e+00  5.20461e-01  1.07786e-01  1.72497e-01  8.17631e-01
21Feb13_162939|  -1.23382e-01 -7.64470e-01  6.85373e-01]
21Feb13_162939| [ 5.32175e-02  1.59085e+00  2.07908e+00 -1.24494e+00  2.20682e+00
21Feb13_162939|  -1.25821e+00 -1.66929e+00  1.94038e+00]
21Feb13_162939| [ 3.73667e-01  1.74451e+00  1.26327e-01  1.39647e+00  1.05080e+00
21Feb13_162939|   2.43187e-01  2.53561e-02  2.31324e-01]
21Feb13_162939| [-1.12310e+00 -1.74495e+00  1.77094e+00 -4.73527e-01  8.36949e-01
21Feb13_162939|   7.71774e-01 -4.35311e-01  1.53145e+00]
21Feb13_162939| [ 2.13217e+00  1.37125e+00 -9.20890e-01  1.06924e+00 -1.32771e+00
21Feb13_162939|   7.09898e-01  1.11439e+00 -1.27760e+00]
21Feb13_162939| [-1.77403e-02 -4.28601e-01  1.65835e+00 -1.87197e-01  1.00957e+00
21Feb13_162939|   2.55297e-01  1.06387e-01  1.21832e+00]
21Feb13_162939| [ 2.16525e+00 -1.25784e-01 -5.41529e-01  1.97828e-01  2.28966e+00
21Feb13_162939|  -1.46028e+00  4.98379e-03 -4.40688e-01]
21Feb13_162939| [-7.39511e-02  2.47569e-01 -2.23324e-01 -2.69329e+00 -1.10672e+00
21Feb13_162939|   1.29711e+00 -1.02474e+00 -3.36463e-01]
21Feb13_162939| [ 7.56693e-01 -1.07233e-01 -6.28270e-01  9.12612e-01 -8.77877e-01
21Feb13_162939|  -9.20839e-01 -2.24401e-01 -1.13295e+00]
21Feb13_162939| [-9.56727e-01 -1.86328e+00 -1.69292e-01  1.09894e+00 -7.25733e-01
21Feb13_162939|   7.74090e-01  4.02577e-01 -6.00141e-01]
21Feb13_162939| [-1.51671e+00 -9.25981e-02 -3.63639e-01 -5.52293e-02  3.65719e-01
21Feb13_162939|  -2.63172e-01 -9.22686e-01 -1.59066e+00]
21Feb13_162939| [ 6.19485e-01  1.04762e+00  1.15913e-01  7.68427e-01  9.88362e-01
21Feb13_162939|   4.00572e-01  1.01580e+00 -1.00402e+00]
21Feb13_162939| [ 7.91163e-01 -1.28156e+00 -3.72928e-01  1.20917e+00  7.26087e-02
21Feb13_162939|   1.23038e+00 -7.97295e-01  7.15324e-01]
21Feb13_162939| [ 7.69403e-01 -2.23882e+00 -4.06537e-01 -8.30657e-01 -1.85295e+00
21Feb13_162939|  -3.96728e-01 -1.32753e-01  1.40371e+00]
21Feb13_162939| [ 8.63582e-01 -4.52795e-01  3.96789e-01  7.20922e-01  9.68883e-01
21Feb13_162939|   5.76722e-01 -8.25456e-02 -9.35541e-01]
21Feb13_162939| [-7.49275e-01 -9.06243e-01  1.18676e+00  5.39848e-01  1.41834e+00
21Feb13_162939|   4.33185e-01 -6.77846e-01 -6.19523e-01]
21Feb13_162939| [-8.91000e-01 -4.94536e-01  5.48779e-01  2.33437e+00  1.49354e+00
21Feb13_162939|  -5.62471e-01  7.67750e-01  5.34580e-01]
21Feb13_162939| [-2.22339e+00 -9.48349e-02  1.11523e-01 -1.88580e+00  1.55613e+00
21Feb13_162939|  -2.63893e+00  1.54688e+00  3.23628e-01]
21Feb13_162939| [-8.55111e-01  8.53349e-02 -7.83263e-01 -1.51315e+00  1.04588e+00
21Feb13_162939|  -1.91727e-02  1.95011e+00  3.79730e-01]
21Feb13_162939| [ 2.51049e+00 -5.71821e-01 -3.88096e-01 -5.52635e-01 -6.13567e-01
21Feb13_162939|  -1.58586e+00  1.50576e+00 -3.00998e-01]
21Feb13_162939| [ 1.93294e+00  3.34612e-01  1.64052e+00 -6.15246e-02  1.30100e+00
21Feb13_162939|   1.76044e+00 -3.04681e-01  1.12959e+00]
21Feb13_162939| [-1.54512e+00  8.03853e-01  7.85451e-01 -6.07936e-01  1.46778e+00
21Feb13_162939|  -2.14726e-01  3.85177e-01  8.03591e-01]
21Feb13_162939| [-7.43437e-01 -9.54122e-01  1.29250e-01  6.55511e-01  2.19896e-01
21Feb13_162939|  -3.25329e-01 -1.79744e+00  1.49641e+00]
21Feb13_162939| [-1.06592e-01  1.44267e+00 -9.93954e-01 -1.01275e+00 -1.80724e+00
21Feb13_162939|  -1.61250e+00  3.80720e-01  1.00622e+00]
21Feb13_162939| [-1.24952e+00 -9.83355e-01 -1.52174e+00 -6.88709e-02 -1.82968e+00
21Feb13_162939|  -1.70623e+00  5.64768e-01  1.84679e+00]
21Feb13_162939| [-2.16342e-01  9.31138e-01  4.23135e-01  6.51742e-01  1.10173e+00
21Feb13_162939|  -5.06868e-01  1.23298e+00 -4.11005e-01]
21Feb13_162939| [-6.95216e-01 -3.15809e-01 -2.07574e+00  1.38096e+00 -1.71834e+00
21Feb13_162939|  -1.00945e+00 -1.93909e+00 -1.90334e-01]
21Feb13_162939| [ 1.07621e+00  9.00909e-02 -1.16790e+00  6.47977e-01  4.48710e-01
21Feb13_162939|  -2.35271e+00  1.03246e+00  9.83788e-01]
21Feb13_162939| [-1.87550e+00 -1.35257e+00  7.95260e-01  1.64205e+00  6.37801e-01
21Feb13_162939|  -1.21482e+00 -1.45812e+00 -1.58185e-01]
21Feb13_162939| [ 4.31964e-01 -2.36822e-01  2.71119e-01 -1.28570e-01 -1.53996e+00
21Feb13_162939|   5.51374e-01  8.51521e-01 -1.87252e-03]
21Feb13_162939| [ 7.36059e-01  2.03168e+00 -2.68137e-01  1.70106e+00  8.03452e-01
21Feb13_162939|  -9.28072e-01  3.15312e+00  5.03465e-01]
21Feb13_162939| [ 1.80659e+00 -4.69960e-01  5.45626e-02  3.79517e-01 -9.48898e-01
21Feb13_162939|   3.17335e-01  4.23174e-02  1.25038e-01]
21Feb13_162939| [-1.36823e+00 -1.09100e+00  5.58333e-01 -1.75850e+00 -5.38353e-01
21Feb13_162939|   1.32464e+00 -1.44645e+00 -8.10629e-01]
21Feb13_162939| [ 1.34275e+00 -1.41251e+00 -4.78630e-01  1.46547e+00  5.64584e-01
21Feb13_162939|  -1.16980e+00 -2.78855e-01  9.98143e-01]
21Feb13_162939| [ 2.09905e+00  1.12670e-01 -2.75076e-02  3.01802e-01 -4.44158e-01
21Feb13_162939|   5.97231e-01 -4.45245e-01 -6.24110e-01]
21Feb13_162939| [ 1.47398e-01  4.79586e-01 -1.51079e-01 -1.26635e+00 -1.86360e+00
21Feb13_162939|   3.85638e-01 -2.26102e-01 -5.36332e-01]
21Feb13_162939| [ 2.39414e+00 -1.49220e+00  1.71112e+00 -3.26483e-02 -7.30602e-01
21Feb13_162939|  -7.71260e-01  1.35484e+00  1.46918e-01]
21Feb13_162939| [-8.79683e-01  2.04363e-01 -1.00453e+00  4.97801e-01  5.37708e-01
21Feb13_162939|   4.84817e-02  1.46449e-01  1.00633e+00]
21Feb13_162939| [ 9.87510e-01 -1.73494e+00 -3.97664e-01 -1.86384e+00 -1.37373e-01
21Feb13_162939|   9.58713e-01  7.88842e-01 -5.64893e-01]
21Feb13_162939| [ 1.23733e+00 -6.34561e-01  1.62916e-01  7.97154e-01  2.56756e-03
21Feb13_162939|  -5.26820e-01  1.12518e+00 -7.32085e-02]
21Feb13_162939| [ 9.60993e-02  2.80900e+00  1.96107e+00  2.67847e-01 -9.99283e-01
21Feb13_162939|  -4.52254e-01 -1.16903e+00  5.34274e-01]
21Feb13_162939| [ 1.46344e-01 -1.36033e-01  1.46780e+00  5.16901e-01 -2.00846e-01
21Feb13_162939|  -9.87830e-01  7.06146e-01  8.09746e-01]
21Feb13_162939| [ 1.55725e+00  7.75166e-01 -6.09187e-01  4.12681e-01  9.89784e-01
21Feb13_162939|  -3.28362e-01 -8.20779e-01 -1.15257e+00]
21Feb13_162939| [ 4.80557e-01  1.49401e-01 -8.28445e-01 -7.57686e-01 -1.21364e-01
21Feb13_162939|  -3.60461e-01 -1.25299e+00  1.96698e+00]
21Feb13_162939| [-4.30322e-01 -3.22697e+00 -4.46022e-01 -1.86729e+00  1.57431e+00
21Feb13_162939|   1.75365e-01  6.92210e-03 -6.13423e-01]
21Feb13_162939| [-1.34320e+00 -2.25301e+00  7.42062e-01 -6.16108e-01 -1.65630e-01
21Feb13_162939|  -4.69016e-01  1.84444e+00  3.27314e-01]
21Feb13_162939| [-5.16134e-02  2.23419e+00 -5.91959e-01  9.32150e-01 -1.06772e+00
21Feb13_162939|  -5.11523e-01  6.85844e-01 -1.03689e+00]
21Feb13_162939| [-1.30007e+00 -3.59148e-01  3.35093e-01  4.66641e-01  6.22570e-01
21Feb13_162939|  -1.71881e+00  7.41306e-01  1.11108e+00]
21Feb13_162939| [-2.00853e-01 -9.24747e-01 -2.19487e-01  6.18157e-01  6.43791e-01
21Feb13_162939|  -1.30594e+00  8.00212e-01  5.97219e-01]
21Feb13_162939| [-1.19358e+00 -5.99902e-01 -1.36178e+00  6.16698e-02 -1.07130e+00
21Feb13_162939|  -9.13657e-01 -5.31884e-01  5.48692e-01]
21Feb13_162939| [ 1.17813e+00 -8.97985e-01  1.95108e+00  2.09820e-01  2.84393e-03
21Feb13_162939|   1.23481e+00 -1.68539e-01  2.33940e-01]
21Feb13_162939| [-9.10662e-01  1.46989e+00 -1.08973e+00 -7.32452e-01 -2.41675e+00
21Feb13_162939|  -4.44959e-01  1.16536e+00 -9.01145e-01]
21Feb13_162939| [-8.82564e-01  7.05310e-01 -1.01819e+00 -2.26405e+00 -1.34282e+00
21Feb13_162939|   6.97505e-01  1.34754e+00 -2.32821e+00]
21Feb13_162939| [-4.48054e-01 -1.49619e+00  7.66455e-01  1.28585e-02  2.52223e-01
21Feb13_162939|  -1.68540e+00 -9.38609e-02 -2.02003e+00]]
21Feb13_162939|-- Bias --
21Feb13_162939|[ 1.17808e-03 -4.44270e-01  8.22591e-02  1.09959e+00 -3.08221e-01
21Feb13_162939|  1.75965e-01 -1.99442e-01 -1.41265e+00]
21Feb13_162939|Layer 1:
21Feb13_162939|-- Config --
21Feb13_162939|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 8], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_162939|-- Weights --
21Feb13_162939|[[-0.98226  0.24821  1.19463]
21Feb13_162939| [ 0.22008  1.26392 -0.48812]
21Feb13_162939| [ 0.36979  0.18930  0.10872]
21Feb13_162939| [-0.31853  0.06591 -0.63823]
21Feb13_162939| [-1.04688  0.28658  0.05164]
21Feb13_162939| [-0.46144  0.29281  0.32274]
21Feb13_162939| [-1.38143  0.64735 -0.30380]
21Feb13_162939| [ 0.42874 -0.73215 -0.07617]]
21Feb13_162939|-- Bias --
21Feb13_162939|[ 0.11283 -0.91883 -0.02107]
21Feb13_162939|Layer 2:
21Feb13_162939|-- Config --
21Feb13_162939|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_162939|-- Weights --
21Feb13_162939|[[-1.30873  0.76809  0.90757 -0.59244  0.54910 -0.47315]
21Feb13_162939| [-0.99187 -0.37179  0.74019 -0.16616  0.19931 -0.01629]
21Feb13_162939| [ 1.03741 -0.10805  0.70718 -0.07401 -0.40500 -0.37353]]
21Feb13_162939|-- Bias --
21Feb13_162939|[ 0.24190 -0.18750 -1.26833 -0.88541 -0.79598  0.36384]
21Feb13_162939|Layer 3:
21Feb13_162939|-- Config --
21Feb13_162939|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_162939|-- Weights --
21Feb13_162939|[[-0.60635  0.23318]
21Feb13_162939| [-0.14250  0.55489]
21Feb13_162939| [-0.48538 -0.15199]
21Feb13_162939| [ 0.42067 -0.62737]
21Feb13_162939| [-0.99709  0.64501]
21Feb13_162939| [-0.25790  0.29907]]
21Feb13_162939|-- Bias --
21Feb13_162939|[-0.14887  1.00429]
21Feb13_162939|Predicting the validation and test data with the Best final individual.
21Feb13_162946| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_162946|-----------  ------------------  --------------------  ----------
21Feb13_162946|Validation         42.00                  51            0.00000
21Feb13_162946|   Test            25.80                  51            0.48077
21Feb13_162946|-------------------- Test #2 --------------------
21Feb13_162946|Best final individual weights
21Feb13_162946|Individual:
21Feb13_162946|-- Constant hidden layers --
21Feb13_162946|False
21Feb13_162946|Layer 0:
21Feb13_162946|-- Config --
21Feb13_162946|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 8, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_162946|-- Weights --
21Feb13_162946|[[-7.96509e-01 -1.15059e+00 -6.26034e-01 -2.57608e-01 -1.16276e+00
21Feb13_162946|   2.17486e-01 -9.34321e-01  1.47903e-01]
21Feb13_162946| [ 1.83510e+00 -1.21927e-01 -7.21994e-01 -3.87175e-01  1.44182e+00
21Feb13_162946|  -5.60339e-01 -1.69323e+00  3.84702e-01]
21Feb13_162946| [ 2.29647e+00  4.98135e-01 -5.82819e-01 -6.51931e-01 -5.00483e-01
21Feb13_162946|  -5.21971e-01  1.02927e+00  1.39999e-01]
21Feb13_162946| [-1.71433e+00  5.20461e-01  1.07786e-01  1.72497e-01  8.17631e-01
21Feb13_162946|  -1.23382e-01 -7.64470e-01  6.85373e-01]
21Feb13_162946| [ 5.32175e-02  1.59085e+00  2.07908e+00 -1.24494e+00  2.20682e+00
21Feb13_162946|  -1.25821e+00 -1.66929e+00  1.94038e+00]
21Feb13_162946| [ 3.73667e-01  1.74451e+00  1.26327e-01  1.39647e+00  1.05080e+00
21Feb13_162946|   2.43187e-01  2.53561e-02  2.31324e-01]
21Feb13_162946| [-1.12310e+00 -1.74495e+00  1.77094e+00 -4.73527e-01  8.36949e-01
21Feb13_162946|   7.71774e-01 -4.35311e-01  1.53145e+00]
21Feb13_162946| [ 2.13217e+00  1.37125e+00 -9.20890e-01  1.06924e+00 -1.32771e+00
21Feb13_162946|   7.09898e-01  1.11439e+00 -1.27760e+00]
21Feb13_162946| [-1.77403e-02 -4.28601e-01  1.65835e+00 -1.87197e-01  1.00957e+00
21Feb13_162946|   2.55297e-01  1.06387e-01  1.21832e+00]
21Feb13_162946| [ 2.16525e+00 -1.25784e-01 -5.41529e-01  1.97828e-01  2.28966e+00
21Feb13_162946|  -1.46028e+00  4.98379e-03 -4.40688e-01]
21Feb13_162946| [-7.39511e-02  2.47569e-01 -2.23324e-01 -2.69329e+00 -1.10672e+00
21Feb13_162946|   1.29711e+00 -1.02474e+00 -3.36463e-01]
21Feb13_162946| [ 7.56693e-01 -1.07233e-01 -6.28270e-01  9.12612e-01 -8.77877e-01
21Feb13_162946|  -9.20839e-01 -2.24401e-01 -1.13295e+00]
21Feb13_162946| [-9.56727e-01 -1.86328e+00 -1.69292e-01  1.09894e+00 -7.25733e-01
21Feb13_162946|   7.74090e-01  4.02577e-01 -6.00141e-01]
21Feb13_162946| [-1.51671e+00 -9.25981e-02 -3.63639e-01 -5.52293e-02  3.65719e-01
21Feb13_162946|  -2.63172e-01 -9.22686e-01 -1.59066e+00]
21Feb13_162946| [ 6.19485e-01  1.04762e+00  1.15913e-01  7.68427e-01  9.88362e-01
21Feb13_162946|   4.00572e-01  1.01580e+00 -1.00402e+00]
21Feb13_162946| [ 7.91163e-01 -1.28156e+00 -3.72928e-01  1.20917e+00  7.26087e-02
21Feb13_162946|   1.23038e+00 -7.97295e-01  7.15324e-01]
21Feb13_162946| [ 7.69403e-01 -2.23882e+00 -4.06537e-01 -8.30657e-01 -1.85295e+00
21Feb13_162946|  -3.96728e-01 -1.32753e-01  1.40371e+00]
21Feb13_162946| [ 8.63582e-01 -4.52795e-01  3.96789e-01  7.20922e-01  9.68883e-01
21Feb13_162946|   5.76722e-01 -8.25456e-02 -9.35541e-01]
21Feb13_162946| [-7.49275e-01 -9.06243e-01  1.18676e+00  5.39848e-01  1.41834e+00
21Feb13_162946|   4.33185e-01 -6.77846e-01 -6.19523e-01]
21Feb13_162946| [-8.91000e-01 -4.94536e-01  5.48779e-01  2.33437e+00  1.49354e+00
21Feb13_162946|  -5.62471e-01  7.67750e-01  5.34580e-01]
21Feb13_162946| [-2.22339e+00 -9.48349e-02  1.11523e-01 -1.88580e+00  1.55613e+00
21Feb13_162946|  -2.63893e+00  1.54688e+00  3.23628e-01]
21Feb13_162946| [-8.55111e-01  8.53349e-02 -7.83263e-01 -1.51315e+00  1.04588e+00
21Feb13_162946|  -1.91727e-02  1.95011e+00  3.79730e-01]
21Feb13_162946| [ 2.51049e+00 -5.71821e-01 -3.88096e-01 -5.52635e-01 -6.13567e-01
21Feb13_162946|  -1.58586e+00  1.50576e+00 -3.00998e-01]
21Feb13_162946| [ 1.93294e+00  3.34612e-01  1.64052e+00 -6.15246e-02  1.30100e+00
21Feb13_162946|   1.76044e+00 -3.04681e-01  1.12959e+00]
21Feb13_162946| [-1.54512e+00  8.03853e-01  7.85451e-01 -6.07936e-01  1.46778e+00
21Feb13_162946|  -2.14726e-01  3.85177e-01  8.03591e-01]
21Feb13_162946| [-7.43437e-01 -9.54122e-01  1.29250e-01  6.55511e-01  2.19896e-01
21Feb13_162946|  -3.25329e-01 -1.79744e+00  1.49641e+00]
21Feb13_162946| [-1.06592e-01  1.44267e+00 -9.93954e-01 -1.01275e+00 -1.80724e+00
21Feb13_162946|  -1.61250e+00  3.80720e-01  1.00622e+00]
21Feb13_162946| [-1.24952e+00 -9.83355e-01 -1.52174e+00 -6.88709e-02 -1.82968e+00
21Feb13_162946|  -1.70623e+00  5.64768e-01  1.84679e+00]
21Feb13_162946| [-2.16342e-01  9.31138e-01  4.23135e-01  6.51742e-01  1.10173e+00
21Feb13_162946|  -5.06868e-01  1.23298e+00 -4.11005e-01]
21Feb13_162946| [-6.95216e-01 -3.15809e-01 -2.07574e+00  1.38096e+00 -1.71834e+00
21Feb13_162946|  -1.00945e+00 -1.93909e+00 -1.90334e-01]
21Feb13_162946| [ 1.07621e+00  9.00909e-02 -1.16790e+00  6.47977e-01  4.48710e-01
21Feb13_162946|  -2.35271e+00  1.03246e+00  9.83788e-01]
21Feb13_162946| [-1.87550e+00 -1.35257e+00  7.95260e-01  1.64205e+00  6.37801e-01
21Feb13_162946|  -1.21482e+00 -1.45812e+00 -1.58185e-01]
21Feb13_162946| [ 4.31964e-01 -2.36822e-01  2.71119e-01 -1.28570e-01 -1.53996e+00
21Feb13_162946|   5.51374e-01  8.51521e-01 -1.87252e-03]
21Feb13_162946| [ 7.36059e-01  2.03168e+00 -2.68137e-01  1.70106e+00  8.03452e-01
21Feb13_162946|  -9.28072e-01  3.15312e+00  5.03465e-01]
21Feb13_162946| [ 1.80659e+00 -4.69960e-01  5.45626e-02  3.79517e-01 -9.48898e-01
21Feb13_162946|   3.17335e-01  4.23174e-02  1.25038e-01]
21Feb13_162946| [-1.36823e+00 -1.09100e+00  5.58333e-01 -1.75850e+00 -5.38353e-01
21Feb13_162946|   1.32464e+00 -1.44645e+00 -8.10629e-01]
21Feb13_162946| [ 1.34275e+00 -1.41251e+00 -4.78630e-01  1.46547e+00  5.64584e-01
21Feb13_162946|  -1.16980e+00 -2.78855e-01  9.98143e-01]
21Feb13_162946| [ 2.09905e+00  1.12670e-01 -2.75076e-02  3.01802e-01 -4.44158e-01
21Feb13_162946|   5.97231e-01 -4.45245e-01 -6.24110e-01]
21Feb13_162946| [ 1.47398e-01  4.79586e-01 -1.51079e-01 -1.26635e+00 -1.86360e+00
21Feb13_162946|   3.85638e-01 -2.26102e-01 -5.36332e-01]
21Feb13_162946| [ 2.39414e+00 -1.49220e+00  1.71112e+00 -3.26483e-02 -7.30602e-01
21Feb13_162946|  -7.71260e-01  1.35484e+00  1.46918e-01]
21Feb13_162946| [-8.79683e-01  2.04363e-01 -1.00453e+00  4.97801e-01  5.37708e-01
21Feb13_162946|   4.84817e-02  1.46449e-01  1.00633e+00]
21Feb13_162946| [ 9.87510e-01 -1.73494e+00 -3.97664e-01 -1.86384e+00 -1.37373e-01
21Feb13_162946|   9.58713e-01  7.88842e-01 -5.64893e-01]
21Feb13_162946| [ 1.23733e+00 -6.34561e-01  1.62916e-01  7.97154e-01  2.56756e-03
21Feb13_162946|  -5.26820e-01  1.12518e+00 -7.32085e-02]
21Feb13_162946| [ 9.60993e-02  2.80900e+00  1.96107e+00  2.67847e-01 -9.99283e-01
21Feb13_162946|  -4.52254e-01 -1.16903e+00  5.34274e-01]
21Feb13_162946| [ 1.46344e-01 -1.36033e-01  1.46780e+00  5.16901e-01 -2.00846e-01
21Feb13_162946|  -9.87830e-01  7.06146e-01  8.09746e-01]
21Feb13_162946| [ 1.55725e+00  7.75166e-01 -6.09187e-01  4.12681e-01  9.89784e-01
21Feb13_162946|  -3.28362e-01 -8.20779e-01 -1.15257e+00]
21Feb13_162946| [ 4.80557e-01  1.49401e-01 -8.28445e-01 -7.57686e-01 -1.21364e-01
21Feb13_162946|  -3.60461e-01 -1.25299e+00  1.96698e+00]
21Feb13_162946| [-4.30322e-01 -3.22697e+00 -4.46022e-01 -1.86729e+00  1.57431e+00
21Feb13_162946|   1.75365e-01  6.92210e-03 -6.13423e-01]
21Feb13_162946| [-1.34320e+00 -2.25301e+00  7.42062e-01 -6.16108e-01 -1.65630e-01
21Feb13_162946|  -4.69016e-01  1.84444e+00  3.27314e-01]
21Feb13_162946| [-5.16134e-02  2.23419e+00 -5.91959e-01  9.32150e-01 -1.06772e+00
21Feb13_162946|  -5.11523e-01  6.85844e-01 -1.03689e+00]
21Feb13_162946| [-1.30007e+00 -3.59148e-01  3.35093e-01  4.66641e-01  6.22570e-01
21Feb13_162946|  -1.71881e+00  7.41306e-01  1.11108e+00]
21Feb13_162946| [-2.00853e-01 -9.24747e-01 -2.19487e-01  6.18157e-01  6.43791e-01
21Feb13_162946|  -1.30594e+00  8.00212e-01  5.97219e-01]
21Feb13_162946| [-1.19358e+00 -5.99902e-01 -1.36178e+00  6.16698e-02 -1.07130e+00
21Feb13_162946|  -9.13657e-01 -5.31884e-01  5.48692e-01]
21Feb13_162946| [ 1.17813e+00 -8.97985e-01  1.95108e+00  2.09820e-01  2.84393e-03
21Feb13_162946|   1.23481e+00 -1.68539e-01  2.33940e-01]
21Feb13_162946| [-9.10662e-01  1.46989e+00 -1.08973e+00 -7.32452e-01 -2.41675e+00
21Feb13_162946|  -4.44959e-01  1.16536e+00 -9.01145e-01]
21Feb13_162946| [-8.82564e-01  7.05310e-01 -1.01819e+00 -2.26405e+00 -1.34282e+00
21Feb13_162946|   6.97505e-01  1.34754e+00 -2.32821e+00]
21Feb13_162946| [-4.48054e-01 -1.49619e+00  7.66455e-01  1.28585e-02  2.52223e-01
21Feb13_162946|  -1.68540e+00 -9.38609e-02 -2.02003e+00]]
21Feb13_162946|-- Bias --
21Feb13_162946|[ 1.17808e-03 -4.44270e-01  8.22591e-02  1.09959e+00 -3.08221e-01
21Feb13_162946|  1.75965e-01 -1.99442e-01 -1.41265e+00]
21Feb13_162946|Layer 1:
21Feb13_162946|-- Config --
21Feb13_162946|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 8], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_162946|-- Weights --
21Feb13_162946|[[-0.98226  0.24821  1.19463]
21Feb13_162946| [ 0.22008  1.26392 -0.48812]
21Feb13_162946| [ 0.36979  0.18930  0.10872]
21Feb13_162946| [-0.31853  0.06591 -0.63823]
21Feb13_162946| [-1.04688  0.28658  0.05164]
21Feb13_162946| [-0.46144  0.29281  0.32274]
21Feb13_162946| [-1.38143  0.64735 -0.30380]
21Feb13_162946| [ 0.42874 -0.73215 -0.07617]]
21Feb13_162946|-- Bias --
21Feb13_162946|[ 0.11283 -0.91883 -0.02107]
21Feb13_162946|Layer 2:
21Feb13_162946|-- Config --
21Feb13_162946|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_162946|-- Weights --
21Feb13_162946|[[-1.30873  0.76809  0.90757 -0.59244  0.54910 -0.47315]
21Feb13_162946| [-0.99187 -0.37179  0.74019 -0.16616  0.19931 -0.01629]
21Feb13_162946| [ 1.03741 -0.10805  0.70718 -0.07401 -0.40500 -0.37353]]
21Feb13_162946|-- Bias --
21Feb13_162946|[ 0.24190 -0.18750 -1.26833 -0.88541 -0.79598  0.36384]
21Feb13_162946|Layer 3:
21Feb13_162946|-- Config --
21Feb13_162946|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_162946|-- Weights --
21Feb13_162946|[[-0.60635  0.23318]
21Feb13_162946| [-0.14250  0.55489]
21Feb13_162946| [-0.48538 -0.15199]
21Feb13_162946| [ 0.42067 -0.62737]
21Feb13_162946| [-0.99709  0.64501]
21Feb13_162946| [-0.25790  0.29907]]
21Feb13_162946|-- Bias --
21Feb13_162946|[-0.14887  1.00429]
21Feb13_162946|Predicting the validation and test data with the Best final individual.
21Feb13_162954| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_162954|-----------  ------------------  --------------------  ----------
21Feb13_162954|Validation         27.13                  51            0.52313
21Feb13_162954|   Test            26.15                  51            0.42819
21Feb13_162954|-------------------- Test #3 --------------------
21Feb13_162954|Best final individual weights
21Feb13_162954|Individual:
21Feb13_162954|-- Constant hidden layers --
21Feb13_162954|False
21Feb13_162954|Layer 0:
21Feb13_162954|-- Config --
21Feb13_162954|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 8, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_162954|-- Weights --
21Feb13_162954|[[-7.96509e-01 -1.15059e+00 -6.26034e-01 -2.57608e-01 -1.16276e+00
21Feb13_162954|   2.17486e-01 -9.34321e-01  1.47903e-01]
21Feb13_162954| [ 1.83510e+00 -1.21927e-01 -7.21994e-01 -3.87175e-01  1.44182e+00
21Feb13_162954|  -5.60339e-01 -1.69323e+00  3.84702e-01]
21Feb13_162954| [ 2.29647e+00  4.98135e-01 -5.82819e-01 -6.51931e-01 -5.00483e-01
21Feb13_162954|  -5.21971e-01  1.02927e+00  1.39999e-01]
21Feb13_162954| [-1.71433e+00  5.20461e-01  1.07786e-01  1.72497e-01  8.17631e-01
21Feb13_162954|  -1.23382e-01 -7.64470e-01  6.85373e-01]
21Feb13_162954| [ 5.32175e-02  1.59085e+00  2.07908e+00 -1.24494e+00  2.20682e+00
21Feb13_162954|  -1.25821e+00 -1.66929e+00  1.94038e+00]
21Feb13_162954| [ 3.73667e-01  1.74451e+00  1.26327e-01  1.39647e+00  1.05080e+00
21Feb13_162954|   2.43187e-01  2.53561e-02  2.31324e-01]
21Feb13_162954| [-1.12310e+00 -1.74495e+00  1.77094e+00 -4.73527e-01  8.36949e-01
21Feb13_162954|   7.71774e-01 -4.35311e-01  1.53145e+00]
21Feb13_162954| [ 2.13217e+00  1.37125e+00 -9.20890e-01  1.06924e+00 -1.32771e+00
21Feb13_162954|   7.09898e-01  1.11439e+00 -1.27760e+00]
21Feb13_162954| [-1.77403e-02 -4.28601e-01  1.65835e+00 -1.87197e-01  1.00957e+00
21Feb13_162954|   2.55297e-01  1.06387e-01  1.21832e+00]
21Feb13_162954| [ 2.16525e+00 -1.25784e-01 -5.41529e-01  1.97828e-01  2.28966e+00
21Feb13_162954|  -1.46028e+00  4.98379e-03 -4.40688e-01]
21Feb13_162954| [-7.39511e-02  2.47569e-01 -2.23324e-01 -2.69329e+00 -1.10672e+00
21Feb13_162954|   1.29711e+00 -1.02474e+00 -3.36463e-01]
21Feb13_162954| [ 7.56693e-01 -1.07233e-01 -6.28270e-01  9.12612e-01 -8.77877e-01
21Feb13_162954|  -9.20839e-01 -2.24401e-01 -1.13295e+00]
21Feb13_162954| [-9.56727e-01 -1.86328e+00 -1.69292e-01  1.09894e+00 -7.25733e-01
21Feb13_162954|   7.74090e-01  4.02577e-01 -6.00141e-01]
21Feb13_162954| [-1.51671e+00 -9.25981e-02 -3.63639e-01 -5.52293e-02  3.65719e-01
21Feb13_162954|  -2.63172e-01 -9.22686e-01 -1.59066e+00]
21Feb13_162954| [ 6.19485e-01  1.04762e+00  1.15913e-01  7.68427e-01  9.88362e-01
21Feb13_162954|   4.00572e-01  1.01580e+00 -1.00402e+00]
21Feb13_162954| [ 7.91163e-01 -1.28156e+00 -3.72928e-01  1.20917e+00  7.26087e-02
21Feb13_162954|   1.23038e+00 -7.97295e-01  7.15324e-01]
21Feb13_162954| [ 7.69403e-01 -2.23882e+00 -4.06537e-01 -8.30657e-01 -1.85295e+00
21Feb13_162954|  -3.96728e-01 -1.32753e-01  1.40371e+00]
21Feb13_162954| [ 8.63582e-01 -4.52795e-01  3.96789e-01  7.20922e-01  9.68883e-01
21Feb13_162954|   5.76722e-01 -8.25456e-02 -9.35541e-01]
21Feb13_162954| [-7.49275e-01 -9.06243e-01  1.18676e+00  5.39848e-01  1.41834e+00
21Feb13_162954|   4.33185e-01 -6.77846e-01 -6.19523e-01]
21Feb13_162954| [-8.91000e-01 -4.94536e-01  5.48779e-01  2.33437e+00  1.49354e+00
21Feb13_162954|  -5.62471e-01  7.67750e-01  5.34580e-01]
21Feb13_162954| [-2.22339e+00 -9.48349e-02  1.11523e-01 -1.88580e+00  1.55613e+00
21Feb13_162954|  -2.63893e+00  1.54688e+00  3.23628e-01]
21Feb13_162954| [-8.55111e-01  8.53349e-02 -7.83263e-01 -1.51315e+00  1.04588e+00
21Feb13_162954|  -1.91727e-02  1.95011e+00  3.79730e-01]
21Feb13_162954| [ 2.51049e+00 -5.71821e-01 -3.88096e-01 -5.52635e-01 -6.13567e-01
21Feb13_162954|  -1.58586e+00  1.50576e+00 -3.00998e-01]
21Feb13_162954| [ 1.93294e+00  3.34612e-01  1.64052e+00 -6.15246e-02  1.30100e+00
21Feb13_162954|   1.76044e+00 -3.04681e-01  1.12959e+00]
21Feb13_162954| [-1.54512e+00  8.03853e-01  7.85451e-01 -6.07936e-01  1.46778e+00
21Feb13_162954|  -2.14726e-01  3.85177e-01  8.03591e-01]
21Feb13_162954| [-7.43437e-01 -9.54122e-01  1.29250e-01  6.55511e-01  2.19896e-01
21Feb13_162954|  -3.25329e-01 -1.79744e+00  1.49641e+00]
21Feb13_162954| [-1.06592e-01  1.44267e+00 -9.93954e-01 -1.01275e+00 -1.80724e+00
21Feb13_162954|  -1.61250e+00  3.80720e-01  1.00622e+00]
21Feb13_162954| [-1.24952e+00 -9.83355e-01 -1.52174e+00 -6.88709e-02 -1.82968e+00
21Feb13_162954|  -1.70623e+00  5.64768e-01  1.84679e+00]
21Feb13_162954| [-2.16342e-01  9.31138e-01  4.23135e-01  6.51742e-01  1.10173e+00
21Feb13_162954|  -5.06868e-01  1.23298e+00 -4.11005e-01]
21Feb13_162954| [-6.95216e-01 -3.15809e-01 -2.07574e+00  1.38096e+00 -1.71834e+00
21Feb13_162954|  -1.00945e+00 -1.93909e+00 -1.90334e-01]
21Feb13_162954| [ 1.07621e+00  9.00909e-02 -1.16790e+00  6.47977e-01  4.48710e-01
21Feb13_162954|  -2.35271e+00  1.03246e+00  9.83788e-01]
21Feb13_162954| [-1.87550e+00 -1.35257e+00  7.95260e-01  1.64205e+00  6.37801e-01
21Feb13_162954|  -1.21482e+00 -1.45812e+00 -1.58185e-01]
21Feb13_162954| [ 4.31964e-01 -2.36822e-01  2.71119e-01 -1.28570e-01 -1.53996e+00
21Feb13_162954|   5.51374e-01  8.51521e-01 -1.87252e-03]
21Feb13_162954| [ 7.36059e-01  2.03168e+00 -2.68137e-01  1.70106e+00  8.03452e-01
21Feb13_162954|  -9.28072e-01  3.15312e+00  5.03465e-01]
21Feb13_162954| [ 1.80659e+00 -4.69960e-01  5.45626e-02  3.79517e-01 -9.48898e-01
21Feb13_162954|   3.17335e-01  4.23174e-02  1.25038e-01]
21Feb13_162954| [-1.36823e+00 -1.09100e+00  5.58333e-01 -1.75850e+00 -5.38353e-01
21Feb13_162954|   1.32464e+00 -1.44645e+00 -8.10629e-01]
21Feb13_162954| [ 1.34275e+00 -1.41251e+00 -4.78630e-01  1.46547e+00  5.64584e-01
21Feb13_162954|  -1.16980e+00 -2.78855e-01  9.98143e-01]
21Feb13_162954| [ 2.09905e+00  1.12670e-01 -2.75076e-02  3.01802e-01 -4.44158e-01
21Feb13_162954|   5.97231e-01 -4.45245e-01 -6.24110e-01]
21Feb13_162954| [ 1.47398e-01  4.79586e-01 -1.51079e-01 -1.26635e+00 -1.86360e+00
21Feb13_162954|   3.85638e-01 -2.26102e-01 -5.36332e-01]
21Feb13_162954| [ 2.39414e+00 -1.49220e+00  1.71112e+00 -3.26483e-02 -7.30602e-01
21Feb13_162954|  -7.71260e-01  1.35484e+00  1.46918e-01]
21Feb13_162954| [-8.79683e-01  2.04363e-01 -1.00453e+00  4.97801e-01  5.37708e-01
21Feb13_162954|   4.84817e-02  1.46449e-01  1.00633e+00]
21Feb13_162954| [ 9.87510e-01 -1.73494e+00 -3.97664e-01 -1.86384e+00 -1.37373e-01
21Feb13_162954|   9.58713e-01  7.88842e-01 -5.64893e-01]
21Feb13_162954| [ 1.23733e+00 -6.34561e-01  1.62916e-01  7.97154e-01  2.56756e-03
21Feb13_162954|  -5.26820e-01  1.12518e+00 -7.32085e-02]
21Feb13_162954| [ 9.60993e-02  2.80900e+00  1.96107e+00  2.67847e-01 -9.99283e-01
21Feb13_162954|  -4.52254e-01 -1.16903e+00  5.34274e-01]
21Feb13_162954| [ 1.46344e-01 -1.36033e-01  1.46780e+00  5.16901e-01 -2.00846e-01
21Feb13_162954|  -9.87830e-01  7.06146e-01  8.09746e-01]
21Feb13_162954| [ 1.55725e+00  7.75166e-01 -6.09187e-01  4.12681e-01  9.89784e-01
21Feb13_162954|  -3.28362e-01 -8.20779e-01 -1.15257e+00]
21Feb13_162954| [ 4.80557e-01  1.49401e-01 -8.28445e-01 -7.57686e-01 -1.21364e-01
21Feb13_162954|  -3.60461e-01 -1.25299e+00  1.96698e+00]
21Feb13_162954| [-4.30322e-01 -3.22697e+00 -4.46022e-01 -1.86729e+00  1.57431e+00
21Feb13_162954|   1.75365e-01  6.92210e-03 -6.13423e-01]
21Feb13_162954| [-1.34320e+00 -2.25301e+00  7.42062e-01 -6.16108e-01 -1.65630e-01
21Feb13_162954|  -4.69016e-01  1.84444e+00  3.27314e-01]
21Feb13_162954| [-5.16134e-02  2.23419e+00 -5.91959e-01  9.32150e-01 -1.06772e+00
21Feb13_162954|  -5.11523e-01  6.85844e-01 -1.03689e+00]
21Feb13_162954| [-1.30007e+00 -3.59148e-01  3.35093e-01  4.66641e-01  6.22570e-01
21Feb13_162954|  -1.71881e+00  7.41306e-01  1.11108e+00]
21Feb13_162954| [-2.00853e-01 -9.24747e-01 -2.19487e-01  6.18157e-01  6.43791e-01
21Feb13_162954|  -1.30594e+00  8.00212e-01  5.97219e-01]
21Feb13_162954| [-1.19358e+00 -5.99902e-01 -1.36178e+00  6.16698e-02 -1.07130e+00
21Feb13_162954|  -9.13657e-01 -5.31884e-01  5.48692e-01]
21Feb13_162954| [ 1.17813e+00 -8.97985e-01  1.95108e+00  2.09820e-01  2.84393e-03
21Feb13_162954|   1.23481e+00 -1.68539e-01  2.33940e-01]
21Feb13_162954| [-9.10662e-01  1.46989e+00 -1.08973e+00 -7.32452e-01 -2.41675e+00
21Feb13_162954|  -4.44959e-01  1.16536e+00 -9.01145e-01]
21Feb13_162954| [-8.82564e-01  7.05310e-01 -1.01819e+00 -2.26405e+00 -1.34282e+00
21Feb13_162954|   6.97505e-01  1.34754e+00 -2.32821e+00]
21Feb13_162954| [-4.48054e-01 -1.49619e+00  7.66455e-01  1.28585e-02  2.52223e-01
21Feb13_162954|  -1.68540e+00 -9.38609e-02 -2.02003e+00]]
21Feb13_162954|-- Bias --
21Feb13_162954|[ 1.17808e-03 -4.44270e-01  8.22591e-02  1.09959e+00 -3.08221e-01
21Feb13_162954|  1.75965e-01 -1.99442e-01 -1.41265e+00]
21Feb13_162954|Layer 1:
21Feb13_162954|-- Config --
21Feb13_162954|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 8], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_162954|-- Weights --
21Feb13_162954|[[-0.98226  0.24821  1.19463]
21Feb13_162954| [ 0.22008  1.26392 -0.48812]
21Feb13_162954| [ 0.36979  0.18930  0.10872]
21Feb13_162954| [-0.31853  0.06591 -0.63823]
21Feb13_162954| [-1.04688  0.28658  0.05164]
21Feb13_162954| [-0.46144  0.29281  0.32274]
21Feb13_162954| [-1.38143  0.64735 -0.30380]
21Feb13_162954| [ 0.42874 -0.73215 -0.07617]]
21Feb13_162954|-- Bias --
21Feb13_162954|[ 0.11283 -0.91883 -0.02107]
21Feb13_162954|Layer 2:
21Feb13_162954|-- Config --
21Feb13_162954|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_162954|-- Weights --
21Feb13_162954|[[-1.30873  0.76809  0.90757 -0.59244  0.54910 -0.47315]
21Feb13_162954| [-0.99187 -0.37179  0.74019 -0.16616  0.19931 -0.01629]
21Feb13_162954| [ 1.03741 -0.10805  0.70718 -0.07401 -0.40500 -0.37353]]
21Feb13_162954|-- Bias --
21Feb13_162954|[ 0.24190 -0.18750 -1.26833 -0.88541 -0.79598  0.36384]
21Feb13_162954|Layer 3:
21Feb13_162954|-- Config --
21Feb13_162954|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_162954|-- Weights --
21Feb13_162954|[[-0.60635  0.23318]
21Feb13_162954| [-0.14250  0.55489]
21Feb13_162954| [-0.48538 -0.15199]
21Feb13_162954| [ 0.42067 -0.62737]
21Feb13_162954| [-0.99709  0.64501]
21Feb13_162954| [-0.25790  0.29907]]
21Feb13_162954|-- Bias --
21Feb13_162954|[-0.14887  1.00429]
21Feb13_162954|Predicting the validation and test data with the Best final individual.
21Feb13_163002| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_163002|-----------  ------------------  --------------------  ----------
21Feb13_163002|Validation         28.43                  51            0.50897
21Feb13_163002|   Test            25.80                  51            0.48287
21Feb13_163002|-------------------- Test #4 --------------------
21Feb13_163002|Best final individual weights
21Feb13_163002|Individual:
21Feb13_163002|-- Constant hidden layers --
21Feb13_163002|False
21Feb13_163002|Layer 0:
21Feb13_163002|-- Config --
21Feb13_163002|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 8, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163002|-- Weights --
21Feb13_163002|[[-7.96509e-01 -1.15059e+00 -6.26034e-01 -2.57608e-01 -1.16276e+00
21Feb13_163002|   2.17486e-01 -9.34321e-01  1.47903e-01]
21Feb13_163002| [ 1.83510e+00 -1.21927e-01 -7.21994e-01 -3.87175e-01  1.44182e+00
21Feb13_163002|  -5.60339e-01 -1.69323e+00  3.84702e-01]
21Feb13_163002| [ 2.29647e+00  4.98135e-01 -5.82819e-01 -6.51931e-01 -5.00483e-01
21Feb13_163002|  -5.21971e-01  1.02927e+00  1.39999e-01]
21Feb13_163002| [-1.71433e+00  5.20461e-01  1.07786e-01  1.72497e-01  8.17631e-01
21Feb13_163002|  -1.23382e-01 -7.64470e-01  6.85373e-01]
21Feb13_163002| [ 5.32175e-02  1.59085e+00  2.07908e+00 -1.24494e+00  2.20682e+00
21Feb13_163002|  -1.25821e+00 -1.66929e+00  1.94038e+00]
21Feb13_163002| [ 3.73667e-01  1.74451e+00  1.26327e-01  1.39647e+00  1.05080e+00
21Feb13_163002|   2.43187e-01  2.53561e-02  2.31324e-01]
21Feb13_163002| [-1.12310e+00 -1.74495e+00  1.77094e+00 -4.73527e-01  8.36949e-01
21Feb13_163002|   7.71774e-01 -4.35311e-01  1.53145e+00]
21Feb13_163002| [ 2.13217e+00  1.37125e+00 -9.20890e-01  1.06924e+00 -1.32771e+00
21Feb13_163002|   7.09898e-01  1.11439e+00 -1.27760e+00]
21Feb13_163002| [-1.77403e-02 -4.28601e-01  1.65835e+00 -1.87197e-01  1.00957e+00
21Feb13_163002|   2.55297e-01  1.06387e-01  1.21832e+00]
21Feb13_163002| [ 2.16525e+00 -1.25784e-01 -5.41529e-01  1.97828e-01  2.28966e+00
21Feb13_163002|  -1.46028e+00  4.98379e-03 -4.40688e-01]
21Feb13_163002| [-7.39511e-02  2.47569e-01 -2.23324e-01 -2.69329e+00 -1.10672e+00
21Feb13_163002|   1.29711e+00 -1.02474e+00 -3.36463e-01]
21Feb13_163002| [ 7.56693e-01 -1.07233e-01 -6.28270e-01  9.12612e-01 -8.77877e-01
21Feb13_163002|  -9.20839e-01 -2.24401e-01 -1.13295e+00]
21Feb13_163002| [-9.56727e-01 -1.86328e+00 -1.69292e-01  1.09894e+00 -7.25733e-01
21Feb13_163002|   7.74090e-01  4.02577e-01 -6.00141e-01]
21Feb13_163002| [-1.51671e+00 -9.25981e-02 -3.63639e-01 -5.52293e-02  3.65719e-01
21Feb13_163002|  -2.63172e-01 -9.22686e-01 -1.59066e+00]
21Feb13_163002| [ 6.19485e-01  1.04762e+00  1.15913e-01  7.68427e-01  9.88362e-01
21Feb13_163002|   4.00572e-01  1.01580e+00 -1.00402e+00]
21Feb13_163002| [ 7.91163e-01 -1.28156e+00 -3.72928e-01  1.20917e+00  7.26087e-02
21Feb13_163002|   1.23038e+00 -7.97295e-01  7.15324e-01]
21Feb13_163002| [ 7.69403e-01 -2.23882e+00 -4.06537e-01 -8.30657e-01 -1.85295e+00
21Feb13_163002|  -3.96728e-01 -1.32753e-01  1.40371e+00]
21Feb13_163002| [ 8.63582e-01 -4.52795e-01  3.96789e-01  7.20922e-01  9.68883e-01
21Feb13_163002|   5.76722e-01 -8.25456e-02 -9.35541e-01]
21Feb13_163002| [-7.49275e-01 -9.06243e-01  1.18676e+00  5.39848e-01  1.41834e+00
21Feb13_163002|   4.33185e-01 -6.77846e-01 -6.19523e-01]
21Feb13_163002| [-8.91000e-01 -4.94536e-01  5.48779e-01  2.33437e+00  1.49354e+00
21Feb13_163002|  -5.62471e-01  7.67750e-01  5.34580e-01]
21Feb13_163002| [-2.22339e+00 -9.48349e-02  1.11523e-01 -1.88580e+00  1.55613e+00
21Feb13_163002|  -2.63893e+00  1.54688e+00  3.23628e-01]
21Feb13_163002| [-8.55111e-01  8.53349e-02 -7.83263e-01 -1.51315e+00  1.04588e+00
21Feb13_163002|  -1.91727e-02  1.95011e+00  3.79730e-01]
21Feb13_163002| [ 2.51049e+00 -5.71821e-01 -3.88096e-01 -5.52635e-01 -6.13567e-01
21Feb13_163002|  -1.58586e+00  1.50576e+00 -3.00998e-01]
21Feb13_163002| [ 1.93294e+00  3.34612e-01  1.64052e+00 -6.15246e-02  1.30100e+00
21Feb13_163002|   1.76044e+00 -3.04681e-01  1.12959e+00]
21Feb13_163002| [-1.54512e+00  8.03853e-01  7.85451e-01 -6.07936e-01  1.46778e+00
21Feb13_163002|  -2.14726e-01  3.85177e-01  8.03591e-01]
21Feb13_163002| [-7.43437e-01 -9.54122e-01  1.29250e-01  6.55511e-01  2.19896e-01
21Feb13_163002|  -3.25329e-01 -1.79744e+00  1.49641e+00]
21Feb13_163002| [-1.06592e-01  1.44267e+00 -9.93954e-01 -1.01275e+00 -1.80724e+00
21Feb13_163002|  -1.61250e+00  3.80720e-01  1.00622e+00]
21Feb13_163002| [-1.24952e+00 -9.83355e-01 -1.52174e+00 -6.88709e-02 -1.82968e+00
21Feb13_163002|  -1.70623e+00  5.64768e-01  1.84679e+00]
21Feb13_163002| [-2.16342e-01  9.31138e-01  4.23135e-01  6.51742e-01  1.10173e+00
21Feb13_163002|  -5.06868e-01  1.23298e+00 -4.11005e-01]
21Feb13_163002| [-6.95216e-01 -3.15809e-01 -2.07574e+00  1.38096e+00 -1.71834e+00
21Feb13_163002|  -1.00945e+00 -1.93909e+00 -1.90334e-01]
21Feb13_163002| [ 1.07621e+00  9.00909e-02 -1.16790e+00  6.47977e-01  4.48710e-01
21Feb13_163002|  -2.35271e+00  1.03246e+00  9.83788e-01]
21Feb13_163002| [-1.87550e+00 -1.35257e+00  7.95260e-01  1.64205e+00  6.37801e-01
21Feb13_163002|  -1.21482e+00 -1.45812e+00 -1.58185e-01]
21Feb13_163002| [ 4.31964e-01 -2.36822e-01  2.71119e-01 -1.28570e-01 -1.53996e+00
21Feb13_163002|   5.51374e-01  8.51521e-01 -1.87252e-03]
21Feb13_163002| [ 7.36059e-01  2.03168e+00 -2.68137e-01  1.70106e+00  8.03452e-01
21Feb13_163002|  -9.28072e-01  3.15312e+00  5.03465e-01]
21Feb13_163002| [ 1.80659e+00 -4.69960e-01  5.45626e-02  3.79517e-01 -9.48898e-01
21Feb13_163002|   3.17335e-01  4.23174e-02  1.25038e-01]
21Feb13_163002| [-1.36823e+00 -1.09100e+00  5.58333e-01 -1.75850e+00 -5.38353e-01
21Feb13_163002|   1.32464e+00 -1.44645e+00 -8.10629e-01]
21Feb13_163002| [ 1.34275e+00 -1.41251e+00 -4.78630e-01  1.46547e+00  5.64584e-01
21Feb13_163002|  -1.16980e+00 -2.78855e-01  9.98143e-01]
21Feb13_163002| [ 2.09905e+00  1.12670e-01 -2.75076e-02  3.01802e-01 -4.44158e-01
21Feb13_163002|   5.97231e-01 -4.45245e-01 -6.24110e-01]
21Feb13_163002| [ 1.47398e-01  4.79586e-01 -1.51079e-01 -1.26635e+00 -1.86360e+00
21Feb13_163002|   3.85638e-01 -2.26102e-01 -5.36332e-01]
21Feb13_163002| [ 2.39414e+00 -1.49220e+00  1.71112e+00 -3.26483e-02 -7.30602e-01
21Feb13_163002|  -7.71260e-01  1.35484e+00  1.46918e-01]
21Feb13_163002| [-8.79683e-01  2.04363e-01 -1.00453e+00  4.97801e-01  5.37708e-01
21Feb13_163002|   4.84817e-02  1.46449e-01  1.00633e+00]
21Feb13_163002| [ 9.87510e-01 -1.73494e+00 -3.97664e-01 -1.86384e+00 -1.37373e-01
21Feb13_163002|   9.58713e-01  7.88842e-01 -5.64893e-01]
21Feb13_163002| [ 1.23733e+00 -6.34561e-01  1.62916e-01  7.97154e-01  2.56756e-03
21Feb13_163002|  -5.26820e-01  1.12518e+00 -7.32085e-02]
21Feb13_163002| [ 9.60993e-02  2.80900e+00  1.96107e+00  2.67847e-01 -9.99283e-01
21Feb13_163002|  -4.52254e-01 -1.16903e+00  5.34274e-01]
21Feb13_163002| [ 1.46344e-01 -1.36033e-01  1.46780e+00  5.16901e-01 -2.00846e-01
21Feb13_163002|  -9.87830e-01  7.06146e-01  8.09746e-01]
21Feb13_163002| [ 1.55725e+00  7.75166e-01 -6.09187e-01  4.12681e-01  9.89784e-01
21Feb13_163002|  -3.28362e-01 -8.20779e-01 -1.15257e+00]
21Feb13_163002| [ 4.80557e-01  1.49401e-01 -8.28445e-01 -7.57686e-01 -1.21364e-01
21Feb13_163002|  -3.60461e-01 -1.25299e+00  1.96698e+00]
21Feb13_163002| [-4.30322e-01 -3.22697e+00 -4.46022e-01 -1.86729e+00  1.57431e+00
21Feb13_163002|   1.75365e-01  6.92210e-03 -6.13423e-01]
21Feb13_163002| [-1.34320e+00 -2.25301e+00  7.42062e-01 -6.16108e-01 -1.65630e-01
21Feb13_163002|  -4.69016e-01  1.84444e+00  3.27314e-01]
21Feb13_163002| [-5.16134e-02  2.23419e+00 -5.91959e-01  9.32150e-01 -1.06772e+00
21Feb13_163002|  -5.11523e-01  6.85844e-01 -1.03689e+00]
21Feb13_163002| [-1.30007e+00 -3.59148e-01  3.35093e-01  4.66641e-01  6.22570e-01
21Feb13_163002|  -1.71881e+00  7.41306e-01  1.11108e+00]
21Feb13_163002| [-2.00853e-01 -9.24747e-01 -2.19487e-01  6.18157e-01  6.43791e-01
21Feb13_163002|  -1.30594e+00  8.00212e-01  5.97219e-01]
21Feb13_163002| [-1.19358e+00 -5.99902e-01 -1.36178e+00  6.16698e-02 -1.07130e+00
21Feb13_163002|  -9.13657e-01 -5.31884e-01  5.48692e-01]
21Feb13_163002| [ 1.17813e+00 -8.97985e-01  1.95108e+00  2.09820e-01  2.84393e-03
21Feb13_163002|   1.23481e+00 -1.68539e-01  2.33940e-01]
21Feb13_163002| [-9.10662e-01  1.46989e+00 -1.08973e+00 -7.32452e-01 -2.41675e+00
21Feb13_163002|  -4.44959e-01  1.16536e+00 -9.01145e-01]
21Feb13_163002| [-8.82564e-01  7.05310e-01 -1.01819e+00 -2.26405e+00 -1.34282e+00
21Feb13_163002|   6.97505e-01  1.34754e+00 -2.32821e+00]
21Feb13_163002| [-4.48054e-01 -1.49619e+00  7.66455e-01  1.28585e-02  2.52223e-01
21Feb13_163002|  -1.68540e+00 -9.38609e-02 -2.02003e+00]]
21Feb13_163002|-- Bias --
21Feb13_163002|[ 1.17808e-03 -4.44270e-01  8.22591e-02  1.09959e+00 -3.08221e-01
21Feb13_163002|  1.75965e-01 -1.99442e-01 -1.41265e+00]
21Feb13_163002|Layer 1:
21Feb13_163002|-- Config --
21Feb13_163002|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 8], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163002|-- Weights --
21Feb13_163002|[[-0.98226  0.24821  1.19463]
21Feb13_163002| [ 0.22008  1.26392 -0.48812]
21Feb13_163002| [ 0.36979  0.18930  0.10872]
21Feb13_163002| [-0.31853  0.06591 -0.63823]
21Feb13_163002| [-1.04688  0.28658  0.05164]
21Feb13_163002| [-0.46144  0.29281  0.32274]
21Feb13_163002| [-1.38143  0.64735 -0.30380]
21Feb13_163002| [ 0.42874 -0.73215 -0.07617]]
21Feb13_163002|-- Bias --
21Feb13_163002|[ 0.11283 -0.91883 -0.02107]
21Feb13_163002|Layer 2:
21Feb13_163002|-- Config --
21Feb13_163002|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163002|-- Weights --
21Feb13_163002|[[-1.30873  0.76809  0.90757 -0.59244  0.54910 -0.47315]
21Feb13_163002| [-0.99187 -0.37179  0.74019 -0.16616  0.19931 -0.01629]
21Feb13_163002| [ 1.03741 -0.10805  0.70718 -0.07401 -0.40500 -0.37353]]
21Feb13_163002|-- Bias --
21Feb13_163002|[ 0.24190 -0.18750 -1.26833 -0.88541 -0.79598  0.36384]
21Feb13_163002|Layer 3:
21Feb13_163002|-- Config --
21Feb13_163002|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163002|-- Weights --
21Feb13_163002|[[-0.60635  0.23318]
21Feb13_163002| [-0.14250  0.55489]
21Feb13_163002| [-0.48538 -0.15199]
21Feb13_163002| [ 0.42067 -0.62737]
21Feb13_163002| [-0.99709  0.64501]
21Feb13_163002| [-0.25790  0.29907]]
21Feb13_163002|-- Bias --
21Feb13_163002|[-0.14887  1.00429]
21Feb13_163002|Predicting the validation and test data with the Best final individual.
21Feb13_163010| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_163010|-----------  ------------------  --------------------  ----------
21Feb13_163010|Validation         27.65                  51            0.49478
21Feb13_163010|   Test            25.98                  51            0.45693
21Feb13_163010|-------------------- Test #5 --------------------
21Feb13_163010|Best final individual weights
21Feb13_163010|Individual:
21Feb13_163010|-- Constant hidden layers --
21Feb13_163010|False
21Feb13_163010|Layer 0:
21Feb13_163010|-- Config --
21Feb13_163010|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 8, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163010|-- Weights --
21Feb13_163010|[[-7.96509e-01 -1.15059e+00 -6.26034e-01 -2.57608e-01 -1.16276e+00
21Feb13_163010|   2.17486e-01 -9.34321e-01  1.47903e-01]
21Feb13_163010| [ 1.83510e+00 -1.21927e-01 -7.21994e-01 -3.87175e-01  1.44182e+00
21Feb13_163010|  -5.60339e-01 -1.69323e+00  3.84702e-01]
21Feb13_163010| [ 2.29647e+00  4.98135e-01 -5.82819e-01 -6.51931e-01 -5.00483e-01
21Feb13_163010|  -5.21971e-01  1.02927e+00  1.39999e-01]
21Feb13_163010| [-1.71433e+00  5.20461e-01  1.07786e-01  1.72497e-01  8.17631e-01
21Feb13_163010|  -1.23382e-01 -7.64470e-01  6.85373e-01]
21Feb13_163010| [ 5.32175e-02  1.59085e+00  2.07908e+00 -1.24494e+00  2.20682e+00
21Feb13_163010|  -1.25821e+00 -1.66929e+00  1.94038e+00]
21Feb13_163010| [ 3.73667e-01  1.74451e+00  1.26327e-01  1.39647e+00  1.05080e+00
21Feb13_163010|   2.43187e-01  2.53561e-02  2.31324e-01]
21Feb13_163010| [-1.12310e+00 -1.74495e+00  1.77094e+00 -4.73527e-01  8.36949e-01
21Feb13_163010|   7.71774e-01 -4.35311e-01  1.53145e+00]
21Feb13_163010| [ 2.13217e+00  1.37125e+00 -9.20890e-01  1.06924e+00 -1.32771e+00
21Feb13_163010|   7.09898e-01  1.11439e+00 -1.27760e+00]
21Feb13_163010| [-1.77403e-02 -4.28601e-01  1.65835e+00 -1.87197e-01  1.00957e+00
21Feb13_163010|   2.55297e-01  1.06387e-01  1.21832e+00]
21Feb13_163010| [ 2.16525e+00 -1.25784e-01 -5.41529e-01  1.97828e-01  2.28966e+00
21Feb13_163010|  -1.46028e+00  4.98379e-03 -4.40688e-01]
21Feb13_163010| [-7.39511e-02  2.47569e-01 -2.23324e-01 -2.69329e+00 -1.10672e+00
21Feb13_163010|   1.29711e+00 -1.02474e+00 -3.36463e-01]
21Feb13_163010| [ 7.56693e-01 -1.07233e-01 -6.28270e-01  9.12612e-01 -8.77877e-01
21Feb13_163010|  -9.20839e-01 -2.24401e-01 -1.13295e+00]
21Feb13_163010| [-9.56727e-01 -1.86328e+00 -1.69292e-01  1.09894e+00 -7.25733e-01
21Feb13_163010|   7.74090e-01  4.02577e-01 -6.00141e-01]
21Feb13_163010| [-1.51671e+00 -9.25981e-02 -3.63639e-01 -5.52293e-02  3.65719e-01
21Feb13_163010|  -2.63172e-01 -9.22686e-01 -1.59066e+00]
21Feb13_163010| [ 6.19485e-01  1.04762e+00  1.15913e-01  7.68427e-01  9.88362e-01
21Feb13_163010|   4.00572e-01  1.01580e+00 -1.00402e+00]
21Feb13_163010| [ 7.91163e-01 -1.28156e+00 -3.72928e-01  1.20917e+00  7.26087e-02
21Feb13_163010|   1.23038e+00 -7.97295e-01  7.15324e-01]
21Feb13_163010| [ 7.69403e-01 -2.23882e+00 -4.06537e-01 -8.30657e-01 -1.85295e+00
21Feb13_163010|  -3.96728e-01 -1.32753e-01  1.40371e+00]
21Feb13_163010| [ 8.63582e-01 -4.52795e-01  3.96789e-01  7.20922e-01  9.68883e-01
21Feb13_163010|   5.76722e-01 -8.25456e-02 -9.35541e-01]
21Feb13_163010| [-7.49275e-01 -9.06243e-01  1.18676e+00  5.39848e-01  1.41834e+00
21Feb13_163010|   4.33185e-01 -6.77846e-01 -6.19523e-01]
21Feb13_163010| [-8.91000e-01 -4.94536e-01  5.48779e-01  2.33437e+00  1.49354e+00
21Feb13_163010|  -5.62471e-01  7.67750e-01  5.34580e-01]
21Feb13_163010| [-2.22339e+00 -9.48349e-02  1.11523e-01 -1.88580e+00  1.55613e+00
21Feb13_163010|  -2.63893e+00  1.54688e+00  3.23628e-01]
21Feb13_163010| [-8.55111e-01  8.53349e-02 -7.83263e-01 -1.51315e+00  1.04588e+00
21Feb13_163010|  -1.91727e-02  1.95011e+00  3.79730e-01]
21Feb13_163010| [ 2.51049e+00 -5.71821e-01 -3.88096e-01 -5.52635e-01 -6.13567e-01
21Feb13_163010|  -1.58586e+00  1.50576e+00 -3.00998e-01]
21Feb13_163010| [ 1.93294e+00  3.34612e-01  1.64052e+00 -6.15246e-02  1.30100e+00
21Feb13_163010|   1.76044e+00 -3.04681e-01  1.12959e+00]
21Feb13_163010| [-1.54512e+00  8.03853e-01  7.85451e-01 -6.07936e-01  1.46778e+00
21Feb13_163010|  -2.14726e-01  3.85177e-01  8.03591e-01]
21Feb13_163010| [-7.43437e-01 -9.54122e-01  1.29250e-01  6.55511e-01  2.19896e-01
21Feb13_163010|  -3.25329e-01 -1.79744e+00  1.49641e+00]
21Feb13_163010| [-1.06592e-01  1.44267e+00 -9.93954e-01 -1.01275e+00 -1.80724e+00
21Feb13_163010|  -1.61250e+00  3.80720e-01  1.00622e+00]
21Feb13_163010| [-1.24952e+00 -9.83355e-01 -1.52174e+00 -6.88709e-02 -1.82968e+00
21Feb13_163010|  -1.70623e+00  5.64768e-01  1.84679e+00]
21Feb13_163010| [-2.16342e-01  9.31138e-01  4.23135e-01  6.51742e-01  1.10173e+00
21Feb13_163010|  -5.06868e-01  1.23298e+00 -4.11005e-01]
21Feb13_163010| [-6.95216e-01 -3.15809e-01 -2.07574e+00  1.38096e+00 -1.71834e+00
21Feb13_163010|  -1.00945e+00 -1.93909e+00 -1.90334e-01]
21Feb13_163010| [ 1.07621e+00  9.00909e-02 -1.16790e+00  6.47977e-01  4.48710e-01
21Feb13_163010|  -2.35271e+00  1.03246e+00  9.83788e-01]
21Feb13_163010| [-1.87550e+00 -1.35257e+00  7.95260e-01  1.64205e+00  6.37801e-01
21Feb13_163010|  -1.21482e+00 -1.45812e+00 -1.58185e-01]
21Feb13_163010| [ 4.31964e-01 -2.36822e-01  2.71119e-01 -1.28570e-01 -1.53996e+00
21Feb13_163010|   5.51374e-01  8.51521e-01 -1.87252e-03]
21Feb13_163010| [ 7.36059e-01  2.03168e+00 -2.68137e-01  1.70106e+00  8.03452e-01
21Feb13_163010|  -9.28072e-01  3.15312e+00  5.03465e-01]
21Feb13_163010| [ 1.80659e+00 -4.69960e-01  5.45626e-02  3.79517e-01 -9.48898e-01
21Feb13_163010|   3.17335e-01  4.23174e-02  1.25038e-01]
21Feb13_163010| [-1.36823e+00 -1.09100e+00  5.58333e-01 -1.75850e+00 -5.38353e-01
21Feb13_163010|   1.32464e+00 -1.44645e+00 -8.10629e-01]
21Feb13_163010| [ 1.34275e+00 -1.41251e+00 -4.78630e-01  1.46547e+00  5.64584e-01
21Feb13_163010|  -1.16980e+00 -2.78855e-01  9.98143e-01]
21Feb13_163010| [ 2.09905e+00  1.12670e-01 -2.75076e-02  3.01802e-01 -4.44158e-01
21Feb13_163010|   5.97231e-01 -4.45245e-01 -6.24110e-01]
21Feb13_163010| [ 1.47398e-01  4.79586e-01 -1.51079e-01 -1.26635e+00 -1.86360e+00
21Feb13_163010|   3.85638e-01 -2.26102e-01 -5.36332e-01]
21Feb13_163010| [ 2.39414e+00 -1.49220e+00  1.71112e+00 -3.26483e-02 -7.30602e-01
21Feb13_163010|  -7.71260e-01  1.35484e+00  1.46918e-01]
21Feb13_163010| [-8.79683e-01  2.04363e-01 -1.00453e+00  4.97801e-01  5.37708e-01
21Feb13_163010|   4.84817e-02  1.46449e-01  1.00633e+00]
21Feb13_163010| [ 9.87510e-01 -1.73494e+00 -3.97664e-01 -1.86384e+00 -1.37373e-01
21Feb13_163010|   9.58713e-01  7.88842e-01 -5.64893e-01]
21Feb13_163010| [ 1.23733e+00 -6.34561e-01  1.62916e-01  7.97154e-01  2.56756e-03
21Feb13_163010|  -5.26820e-01  1.12518e+00 -7.32085e-02]
21Feb13_163010| [ 9.60993e-02  2.80900e+00  1.96107e+00  2.67847e-01 -9.99283e-01
21Feb13_163010|  -4.52254e-01 -1.16903e+00  5.34274e-01]
21Feb13_163010| [ 1.46344e-01 -1.36033e-01  1.46780e+00  5.16901e-01 -2.00846e-01
21Feb13_163010|  -9.87830e-01  7.06146e-01  8.09746e-01]
21Feb13_163010| [ 1.55725e+00  7.75166e-01 -6.09187e-01  4.12681e-01  9.89784e-01
21Feb13_163010|  -3.28362e-01 -8.20779e-01 -1.15257e+00]
21Feb13_163010| [ 4.80557e-01  1.49401e-01 -8.28445e-01 -7.57686e-01 -1.21364e-01
21Feb13_163010|  -3.60461e-01 -1.25299e+00  1.96698e+00]
21Feb13_163010| [-4.30322e-01 -3.22697e+00 -4.46022e-01 -1.86729e+00  1.57431e+00
21Feb13_163010|   1.75365e-01  6.92210e-03 -6.13423e-01]
21Feb13_163010| [-1.34320e+00 -2.25301e+00  7.42062e-01 -6.16108e-01 -1.65630e-01
21Feb13_163010|  -4.69016e-01  1.84444e+00  3.27314e-01]
21Feb13_163010| [-5.16134e-02  2.23419e+00 -5.91959e-01  9.32150e-01 -1.06772e+00
21Feb13_163010|  -5.11523e-01  6.85844e-01 -1.03689e+00]
21Feb13_163010| [-1.30007e+00 -3.59148e-01  3.35093e-01  4.66641e-01  6.22570e-01
21Feb13_163010|  -1.71881e+00  7.41306e-01  1.11108e+00]
21Feb13_163010| [-2.00853e-01 -9.24747e-01 -2.19487e-01  6.18157e-01  6.43791e-01
21Feb13_163010|  -1.30594e+00  8.00212e-01  5.97219e-01]
21Feb13_163010| [-1.19358e+00 -5.99902e-01 -1.36178e+00  6.16698e-02 -1.07130e+00
21Feb13_163010|  -9.13657e-01 -5.31884e-01  5.48692e-01]
21Feb13_163010| [ 1.17813e+00 -8.97985e-01  1.95108e+00  2.09820e-01  2.84393e-03
21Feb13_163010|   1.23481e+00 -1.68539e-01  2.33940e-01]
21Feb13_163010| [-9.10662e-01  1.46989e+00 -1.08973e+00 -7.32452e-01 -2.41675e+00
21Feb13_163010|  -4.44959e-01  1.16536e+00 -9.01145e-01]
21Feb13_163010| [-8.82564e-01  7.05310e-01 -1.01819e+00 -2.26405e+00 -1.34282e+00
21Feb13_163010|   6.97505e-01  1.34754e+00 -2.32821e+00]
21Feb13_163010| [-4.48054e-01 -1.49619e+00  7.66455e-01  1.28585e-02  2.52223e-01
21Feb13_163010|  -1.68540e+00 -9.38609e-02 -2.02003e+00]]
21Feb13_163010|-- Bias --
21Feb13_163010|[ 1.17808e-03 -4.44270e-01  8.22591e-02  1.09959e+00 -3.08221e-01
21Feb13_163010|  1.75965e-01 -1.99442e-01 -1.41265e+00]
21Feb13_163010|Layer 1:
21Feb13_163010|-- Config --
21Feb13_163010|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 8], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163010|-- Weights --
21Feb13_163010|[[-0.98226  0.24821  1.19463]
21Feb13_163010| [ 0.22008  1.26392 -0.48812]
21Feb13_163010| [ 0.36979  0.18930  0.10872]
21Feb13_163010| [-0.31853  0.06591 -0.63823]
21Feb13_163010| [-1.04688  0.28658  0.05164]
21Feb13_163010| [-0.46144  0.29281  0.32274]
21Feb13_163010| [-1.38143  0.64735 -0.30380]
21Feb13_163010| [ 0.42874 -0.73215 -0.07617]]
21Feb13_163010|-- Bias --
21Feb13_163010|[ 0.11283 -0.91883 -0.02107]
21Feb13_163010|Layer 2:
21Feb13_163010|-- Config --
21Feb13_163010|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163010|-- Weights --
21Feb13_163010|[[-1.30873  0.76809  0.90757 -0.59244  0.54910 -0.47315]
21Feb13_163010| [-0.99187 -0.37179  0.74019 -0.16616  0.19931 -0.01629]
21Feb13_163010| [ 1.03741 -0.10805  0.70718 -0.07401 -0.40500 -0.37353]]
21Feb13_163010|-- Bias --
21Feb13_163010|[ 0.24190 -0.18750 -1.26833 -0.88541 -0.79598  0.36384]
21Feb13_163010|Layer 3:
21Feb13_163010|-- Config --
21Feb13_163010|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163010|-- Weights --
21Feb13_163010|[[-0.60635  0.23318]
21Feb13_163010| [-0.14250  0.55489]
21Feb13_163010| [-0.48538 -0.15199]
21Feb13_163010| [ 0.42067 -0.62737]
21Feb13_163010| [-0.99709  0.64501]
21Feb13_163010| [-0.25790  0.29907]]
21Feb13_163010|-- Bias --
21Feb13_163010|[-0.14887  1.00429]
21Feb13_163010|Predicting the validation and test data with the Best final individual.
21Feb13_163017| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_163017|-----------  ------------------  --------------------  ----------
21Feb13_163017|Validation         27.30                  51            0.53850
21Feb13_163017|   Test            26.24                  51            0.43892
21Feb13_163017|-------------------- Test #6 --------------------
21Feb13_163017|Best final individual weights
21Feb13_163017|Individual:
21Feb13_163017|-- Constant hidden layers --
21Feb13_163017|False
21Feb13_163017|Layer 0:
21Feb13_163017|-- Config --
21Feb13_163017|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 8, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163017|-- Weights --
21Feb13_163017|[[-7.96509e-01 -1.15059e+00 -6.26034e-01 -2.57608e-01 -1.16276e+00
21Feb13_163017|   2.17486e-01 -9.34321e-01  1.47903e-01]
21Feb13_163017| [ 1.83510e+00 -1.21927e-01 -7.21994e-01 -3.87175e-01  1.44182e+00
21Feb13_163017|  -5.60339e-01 -1.69323e+00  3.84702e-01]
21Feb13_163017| [ 2.29647e+00  4.98135e-01 -5.82819e-01 -6.51931e-01 -5.00483e-01
21Feb13_163017|  -5.21971e-01  1.02927e+00  1.39999e-01]
21Feb13_163017| [-1.71433e+00  5.20461e-01  1.07786e-01  1.72497e-01  8.17631e-01
21Feb13_163017|  -1.23382e-01 -7.64470e-01  6.85373e-01]
21Feb13_163017| [ 5.32175e-02  1.59085e+00  2.07908e+00 -1.24494e+00  2.20682e+00
21Feb13_163017|  -1.25821e+00 -1.66929e+00  1.94038e+00]
21Feb13_163017| [ 3.73667e-01  1.74451e+00  1.26327e-01  1.39647e+00  1.05080e+00
21Feb13_163017|   2.43187e-01  2.53561e-02  2.31324e-01]
21Feb13_163017| [-1.12310e+00 -1.74495e+00  1.77094e+00 -4.73527e-01  8.36949e-01
21Feb13_163017|   7.71774e-01 -4.35311e-01  1.53145e+00]
21Feb13_163017| [ 2.13217e+00  1.37125e+00 -9.20890e-01  1.06924e+00 -1.32771e+00
21Feb13_163017|   7.09898e-01  1.11439e+00 -1.27760e+00]
21Feb13_163017| [-1.77403e-02 -4.28601e-01  1.65835e+00 -1.87197e-01  1.00957e+00
21Feb13_163017|   2.55297e-01  1.06387e-01  1.21832e+00]
21Feb13_163017| [ 2.16525e+00 -1.25784e-01 -5.41529e-01  1.97828e-01  2.28966e+00
21Feb13_163017|  -1.46028e+00  4.98379e-03 -4.40688e-01]
21Feb13_163017| [-7.39511e-02  2.47569e-01 -2.23324e-01 -2.69329e+00 -1.10672e+00
21Feb13_163017|   1.29711e+00 -1.02474e+00 -3.36463e-01]
21Feb13_163017| [ 7.56693e-01 -1.07233e-01 -6.28270e-01  9.12612e-01 -8.77877e-01
21Feb13_163017|  -9.20839e-01 -2.24401e-01 -1.13295e+00]
21Feb13_163017| [-9.56727e-01 -1.86328e+00 -1.69292e-01  1.09894e+00 -7.25733e-01
21Feb13_163017|   7.74090e-01  4.02577e-01 -6.00141e-01]
21Feb13_163017| [-1.51671e+00 -9.25981e-02 -3.63639e-01 -5.52293e-02  3.65719e-01
21Feb13_163017|  -2.63172e-01 -9.22686e-01 -1.59066e+00]
21Feb13_163017| [ 6.19485e-01  1.04762e+00  1.15913e-01  7.68427e-01  9.88362e-01
21Feb13_163017|   4.00572e-01  1.01580e+00 -1.00402e+00]
21Feb13_163017| [ 7.91163e-01 -1.28156e+00 -3.72928e-01  1.20917e+00  7.26087e-02
21Feb13_163017|   1.23038e+00 -7.97295e-01  7.15324e-01]
21Feb13_163017| [ 7.69403e-01 -2.23882e+00 -4.06537e-01 -8.30657e-01 -1.85295e+00
21Feb13_163017|  -3.96728e-01 -1.32753e-01  1.40371e+00]
21Feb13_163017| [ 8.63582e-01 -4.52795e-01  3.96789e-01  7.20922e-01  9.68883e-01
21Feb13_163017|   5.76722e-01 -8.25456e-02 -9.35541e-01]
21Feb13_163017| [-7.49275e-01 -9.06243e-01  1.18676e+00  5.39848e-01  1.41834e+00
21Feb13_163017|   4.33185e-01 -6.77846e-01 -6.19523e-01]
21Feb13_163017| [-8.91000e-01 -4.94536e-01  5.48779e-01  2.33437e+00  1.49354e+00
21Feb13_163017|  -5.62471e-01  7.67750e-01  5.34580e-01]
21Feb13_163017| [-2.22339e+00 -9.48349e-02  1.11523e-01 -1.88580e+00  1.55613e+00
21Feb13_163017|  -2.63893e+00  1.54688e+00  3.23628e-01]
21Feb13_163017| [-8.55111e-01  8.53349e-02 -7.83263e-01 -1.51315e+00  1.04588e+00
21Feb13_163017|  -1.91727e-02  1.95011e+00  3.79730e-01]
21Feb13_163017| [ 2.51049e+00 -5.71821e-01 -3.88096e-01 -5.52635e-01 -6.13567e-01
21Feb13_163017|  -1.58586e+00  1.50576e+00 -3.00998e-01]
21Feb13_163017| [ 1.93294e+00  3.34612e-01  1.64052e+00 -6.15246e-02  1.30100e+00
21Feb13_163017|   1.76044e+00 -3.04681e-01  1.12959e+00]
21Feb13_163017| [-1.54512e+00  8.03853e-01  7.85451e-01 -6.07936e-01  1.46778e+00
21Feb13_163017|  -2.14726e-01  3.85177e-01  8.03591e-01]
21Feb13_163017| [-7.43437e-01 -9.54122e-01  1.29250e-01  6.55511e-01  2.19896e-01
21Feb13_163017|  -3.25329e-01 -1.79744e+00  1.49641e+00]
21Feb13_163017| [-1.06592e-01  1.44267e+00 -9.93954e-01 -1.01275e+00 -1.80724e+00
21Feb13_163017|  -1.61250e+00  3.80720e-01  1.00622e+00]
21Feb13_163017| [-1.24952e+00 -9.83355e-01 -1.52174e+00 -6.88709e-02 -1.82968e+00
21Feb13_163017|  -1.70623e+00  5.64768e-01  1.84679e+00]
21Feb13_163017| [-2.16342e-01  9.31138e-01  4.23135e-01  6.51742e-01  1.10173e+00
21Feb13_163017|  -5.06868e-01  1.23298e+00 -4.11005e-01]
21Feb13_163017| [-6.95216e-01 -3.15809e-01 -2.07574e+00  1.38096e+00 -1.71834e+00
21Feb13_163017|  -1.00945e+00 -1.93909e+00 -1.90334e-01]
21Feb13_163017| [ 1.07621e+00  9.00909e-02 -1.16790e+00  6.47977e-01  4.48710e-01
21Feb13_163017|  -2.35271e+00  1.03246e+00  9.83788e-01]
21Feb13_163017| [-1.87550e+00 -1.35257e+00  7.95260e-01  1.64205e+00  6.37801e-01
21Feb13_163017|  -1.21482e+00 -1.45812e+00 -1.58185e-01]
21Feb13_163017| [ 4.31964e-01 -2.36822e-01  2.71119e-01 -1.28570e-01 -1.53996e+00
21Feb13_163017|   5.51374e-01  8.51521e-01 -1.87252e-03]
21Feb13_163017| [ 7.36059e-01  2.03168e+00 -2.68137e-01  1.70106e+00  8.03452e-01
21Feb13_163017|  -9.28072e-01  3.15312e+00  5.03465e-01]
21Feb13_163017| [ 1.80659e+00 -4.69960e-01  5.45626e-02  3.79517e-01 -9.48898e-01
21Feb13_163017|   3.17335e-01  4.23174e-02  1.25038e-01]
21Feb13_163017| [-1.36823e+00 -1.09100e+00  5.58333e-01 -1.75850e+00 -5.38353e-01
21Feb13_163017|   1.32464e+00 -1.44645e+00 -8.10629e-01]
21Feb13_163017| [ 1.34275e+00 -1.41251e+00 -4.78630e-01  1.46547e+00  5.64584e-01
21Feb13_163017|  -1.16980e+00 -2.78855e-01  9.98143e-01]
21Feb13_163017| [ 2.09905e+00  1.12670e-01 -2.75076e-02  3.01802e-01 -4.44158e-01
21Feb13_163017|   5.97231e-01 -4.45245e-01 -6.24110e-01]
21Feb13_163017| [ 1.47398e-01  4.79586e-01 -1.51079e-01 -1.26635e+00 -1.86360e+00
21Feb13_163017|   3.85638e-01 -2.26102e-01 -5.36332e-01]
21Feb13_163017| [ 2.39414e+00 -1.49220e+00  1.71112e+00 -3.26483e-02 -7.30602e-01
21Feb13_163017|  -7.71260e-01  1.35484e+00  1.46918e-01]
21Feb13_163017| [-8.79683e-01  2.04363e-01 -1.00453e+00  4.97801e-01  5.37708e-01
21Feb13_163017|   4.84817e-02  1.46449e-01  1.00633e+00]
21Feb13_163017| [ 9.87510e-01 -1.73494e+00 -3.97664e-01 -1.86384e+00 -1.37373e-01
21Feb13_163017|   9.58713e-01  7.88842e-01 -5.64893e-01]
21Feb13_163017| [ 1.23733e+00 -6.34561e-01  1.62916e-01  7.97154e-01  2.56756e-03
21Feb13_163017|  -5.26820e-01  1.12518e+00 -7.32085e-02]
21Feb13_163017| [ 9.60993e-02  2.80900e+00  1.96107e+00  2.67847e-01 -9.99283e-01
21Feb13_163017|  -4.52254e-01 -1.16903e+00  5.34274e-01]
21Feb13_163017| [ 1.46344e-01 -1.36033e-01  1.46780e+00  5.16901e-01 -2.00846e-01
21Feb13_163017|  -9.87830e-01  7.06146e-01  8.09746e-01]
21Feb13_163017| [ 1.55725e+00  7.75166e-01 -6.09187e-01  4.12681e-01  9.89784e-01
21Feb13_163017|  -3.28362e-01 -8.20779e-01 -1.15257e+00]
21Feb13_163017| [ 4.80557e-01  1.49401e-01 -8.28445e-01 -7.57686e-01 -1.21364e-01
21Feb13_163017|  -3.60461e-01 -1.25299e+00  1.96698e+00]
21Feb13_163017| [-4.30322e-01 -3.22697e+00 -4.46022e-01 -1.86729e+00  1.57431e+00
21Feb13_163017|   1.75365e-01  6.92210e-03 -6.13423e-01]
21Feb13_163017| [-1.34320e+00 -2.25301e+00  7.42062e-01 -6.16108e-01 -1.65630e-01
21Feb13_163017|  -4.69016e-01  1.84444e+00  3.27314e-01]
21Feb13_163017| [-5.16134e-02  2.23419e+00 -5.91959e-01  9.32150e-01 -1.06772e+00
21Feb13_163017|  -5.11523e-01  6.85844e-01 -1.03689e+00]
21Feb13_163017| [-1.30007e+00 -3.59148e-01  3.35093e-01  4.66641e-01  6.22570e-01
21Feb13_163017|  -1.71881e+00  7.41306e-01  1.11108e+00]
21Feb13_163017| [-2.00853e-01 -9.24747e-01 -2.19487e-01  6.18157e-01  6.43791e-01
21Feb13_163017|  -1.30594e+00  8.00212e-01  5.97219e-01]
21Feb13_163017| [-1.19358e+00 -5.99902e-01 -1.36178e+00  6.16698e-02 -1.07130e+00
21Feb13_163017|  -9.13657e-01 -5.31884e-01  5.48692e-01]
21Feb13_163017| [ 1.17813e+00 -8.97985e-01  1.95108e+00  2.09820e-01  2.84393e-03
21Feb13_163017|   1.23481e+00 -1.68539e-01  2.33940e-01]
21Feb13_163017| [-9.10662e-01  1.46989e+00 -1.08973e+00 -7.32452e-01 -2.41675e+00
21Feb13_163017|  -4.44959e-01  1.16536e+00 -9.01145e-01]
21Feb13_163017| [-8.82564e-01  7.05310e-01 -1.01819e+00 -2.26405e+00 -1.34282e+00
21Feb13_163017|   6.97505e-01  1.34754e+00 -2.32821e+00]
21Feb13_163017| [-4.48054e-01 -1.49619e+00  7.66455e-01  1.28585e-02  2.52223e-01
21Feb13_163017|  -1.68540e+00 -9.38609e-02 -2.02003e+00]]
21Feb13_163017|-- Bias --
21Feb13_163017|[ 1.17808e-03 -4.44270e-01  8.22591e-02  1.09959e+00 -3.08221e-01
21Feb13_163017|  1.75965e-01 -1.99442e-01 -1.41265e+00]
21Feb13_163017|Layer 1:
21Feb13_163017|-- Config --
21Feb13_163017|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 8], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163017|-- Weights --
21Feb13_163017|[[-0.98226  0.24821  1.19463]
21Feb13_163017| [ 0.22008  1.26392 -0.48812]
21Feb13_163017| [ 0.36979  0.18930  0.10872]
21Feb13_163017| [-0.31853  0.06591 -0.63823]
21Feb13_163017| [-1.04688  0.28658  0.05164]
21Feb13_163017| [-0.46144  0.29281  0.32274]
21Feb13_163017| [-1.38143  0.64735 -0.30380]
21Feb13_163017| [ 0.42874 -0.73215 -0.07617]]
21Feb13_163017|-- Bias --
21Feb13_163017|[ 0.11283 -0.91883 -0.02107]
21Feb13_163017|Layer 2:
21Feb13_163017|-- Config --
21Feb13_163017|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163017|-- Weights --
21Feb13_163017|[[-1.30873  0.76809  0.90757 -0.59244  0.54910 -0.47315]
21Feb13_163017| [-0.99187 -0.37179  0.74019 -0.16616  0.19931 -0.01629]
21Feb13_163017| [ 1.03741 -0.10805  0.70718 -0.07401 -0.40500 -0.37353]]
21Feb13_163017|-- Bias --
21Feb13_163017|[ 0.24190 -0.18750 -1.26833 -0.88541 -0.79598  0.36384]
21Feb13_163017|Layer 3:
21Feb13_163017|-- Config --
21Feb13_163017|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163017|-- Weights --
21Feb13_163017|[[-0.60635  0.23318]
21Feb13_163017| [-0.14250  0.55489]
21Feb13_163017| [-0.48538 -0.15199]
21Feb13_163017| [ 0.42067 -0.62737]
21Feb13_163017| [-0.99709  0.64501]
21Feb13_163017| [-0.25790  0.29907]]
21Feb13_163017|-- Bias --
21Feb13_163017|[-0.14887  1.00429]
21Feb13_163017|Predicting the validation and test data with the Best final individual.
21Feb13_163025| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_163025|-----------  ------------------  --------------------  ----------
21Feb13_163025|Validation         27.30                  51            0.51195
21Feb13_163025|   Test            26.24                  51            0.50843
21Feb13_163025|-------------------- Test #7 --------------------
21Feb13_163025|Best final individual weights
21Feb13_163025|Individual:
21Feb13_163025|-- Constant hidden layers --
21Feb13_163025|False
21Feb13_163025|Layer 0:
21Feb13_163025|-- Config --
21Feb13_163025|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 8, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163025|-- Weights --
21Feb13_163025|[[-7.96509e-01 -1.15059e+00 -6.26034e-01 -2.57608e-01 -1.16276e+00
21Feb13_163025|   2.17486e-01 -9.34321e-01  1.47903e-01]
21Feb13_163025| [ 1.83510e+00 -1.21927e-01 -7.21994e-01 -3.87175e-01  1.44182e+00
21Feb13_163025|  -5.60339e-01 -1.69323e+00  3.84702e-01]
21Feb13_163025| [ 2.29647e+00  4.98135e-01 -5.82819e-01 -6.51931e-01 -5.00483e-01
21Feb13_163025|  -5.21971e-01  1.02927e+00  1.39999e-01]
21Feb13_163025| [-1.71433e+00  5.20461e-01  1.07786e-01  1.72497e-01  8.17631e-01
21Feb13_163025|  -1.23382e-01 -7.64470e-01  6.85373e-01]
21Feb13_163025| [ 5.32175e-02  1.59085e+00  2.07908e+00 -1.24494e+00  2.20682e+00
21Feb13_163025|  -1.25821e+00 -1.66929e+00  1.94038e+00]
21Feb13_163025| [ 3.73667e-01  1.74451e+00  1.26327e-01  1.39647e+00  1.05080e+00
21Feb13_163025|   2.43187e-01  2.53561e-02  2.31324e-01]
21Feb13_163025| [-1.12310e+00 -1.74495e+00  1.77094e+00 -4.73527e-01  8.36949e-01
21Feb13_163025|   7.71774e-01 -4.35311e-01  1.53145e+00]
21Feb13_163025| [ 2.13217e+00  1.37125e+00 -9.20890e-01  1.06924e+00 -1.32771e+00
21Feb13_163025|   7.09898e-01  1.11439e+00 -1.27760e+00]
21Feb13_163025| [-1.77403e-02 -4.28601e-01  1.65835e+00 -1.87197e-01  1.00957e+00
21Feb13_163025|   2.55297e-01  1.06387e-01  1.21832e+00]
21Feb13_163025| [ 2.16525e+00 -1.25784e-01 -5.41529e-01  1.97828e-01  2.28966e+00
21Feb13_163025|  -1.46028e+00  4.98379e-03 -4.40688e-01]
21Feb13_163025| [-7.39511e-02  2.47569e-01 -2.23324e-01 -2.69329e+00 -1.10672e+00
21Feb13_163025|   1.29711e+00 -1.02474e+00 -3.36463e-01]
21Feb13_163025| [ 7.56693e-01 -1.07233e-01 -6.28270e-01  9.12612e-01 -8.77877e-01
21Feb13_163025|  -9.20839e-01 -2.24401e-01 -1.13295e+00]
21Feb13_163025| [-9.56727e-01 -1.86328e+00 -1.69292e-01  1.09894e+00 -7.25733e-01
21Feb13_163025|   7.74090e-01  4.02577e-01 -6.00141e-01]
21Feb13_163025| [-1.51671e+00 -9.25981e-02 -3.63639e-01 -5.52293e-02  3.65719e-01
21Feb13_163025|  -2.63172e-01 -9.22686e-01 -1.59066e+00]
21Feb13_163025| [ 6.19485e-01  1.04762e+00  1.15913e-01  7.68427e-01  9.88362e-01
21Feb13_163025|   4.00572e-01  1.01580e+00 -1.00402e+00]
21Feb13_163025| [ 7.91163e-01 -1.28156e+00 -3.72928e-01  1.20917e+00  7.26087e-02
21Feb13_163025|   1.23038e+00 -7.97295e-01  7.15324e-01]
21Feb13_163025| [ 7.69403e-01 -2.23882e+00 -4.06537e-01 -8.30657e-01 -1.85295e+00
21Feb13_163025|  -3.96728e-01 -1.32753e-01  1.40371e+00]
21Feb13_163025| [ 8.63582e-01 -4.52795e-01  3.96789e-01  7.20922e-01  9.68883e-01
21Feb13_163025|   5.76722e-01 -8.25456e-02 -9.35541e-01]
21Feb13_163025| [-7.49275e-01 -9.06243e-01  1.18676e+00  5.39848e-01  1.41834e+00
21Feb13_163025|   4.33185e-01 -6.77846e-01 -6.19523e-01]
21Feb13_163025| [-8.91000e-01 -4.94536e-01  5.48779e-01  2.33437e+00  1.49354e+00
21Feb13_163025|  -5.62471e-01  7.67750e-01  5.34580e-01]
21Feb13_163025| [-2.22339e+00 -9.48349e-02  1.11523e-01 -1.88580e+00  1.55613e+00
21Feb13_163025|  -2.63893e+00  1.54688e+00  3.23628e-01]
21Feb13_163025| [-8.55111e-01  8.53349e-02 -7.83263e-01 -1.51315e+00  1.04588e+00
21Feb13_163025|  -1.91727e-02  1.95011e+00  3.79730e-01]
21Feb13_163025| [ 2.51049e+00 -5.71821e-01 -3.88096e-01 -5.52635e-01 -6.13567e-01
21Feb13_163025|  -1.58586e+00  1.50576e+00 -3.00998e-01]
21Feb13_163025| [ 1.93294e+00  3.34612e-01  1.64052e+00 -6.15246e-02  1.30100e+00
21Feb13_163025|   1.76044e+00 -3.04681e-01  1.12959e+00]
21Feb13_163025| [-1.54512e+00  8.03853e-01  7.85451e-01 -6.07936e-01  1.46778e+00
21Feb13_163025|  -2.14726e-01  3.85177e-01  8.03591e-01]
21Feb13_163025| [-7.43437e-01 -9.54122e-01  1.29250e-01  6.55511e-01  2.19896e-01
21Feb13_163025|  -3.25329e-01 -1.79744e+00  1.49641e+00]
21Feb13_163025| [-1.06592e-01  1.44267e+00 -9.93954e-01 -1.01275e+00 -1.80724e+00
21Feb13_163025|  -1.61250e+00  3.80720e-01  1.00622e+00]
21Feb13_163025| [-1.24952e+00 -9.83355e-01 -1.52174e+00 -6.88709e-02 -1.82968e+00
21Feb13_163025|  -1.70623e+00  5.64768e-01  1.84679e+00]
21Feb13_163025| [-2.16342e-01  9.31138e-01  4.23135e-01  6.51742e-01  1.10173e+00
21Feb13_163025|  -5.06868e-01  1.23298e+00 -4.11005e-01]
21Feb13_163025| [-6.95216e-01 -3.15809e-01 -2.07574e+00  1.38096e+00 -1.71834e+00
21Feb13_163025|  -1.00945e+00 -1.93909e+00 -1.90334e-01]
21Feb13_163025| [ 1.07621e+00  9.00909e-02 -1.16790e+00  6.47977e-01  4.48710e-01
21Feb13_163025|  -2.35271e+00  1.03246e+00  9.83788e-01]
21Feb13_163025| [-1.87550e+00 -1.35257e+00  7.95260e-01  1.64205e+00  6.37801e-01
21Feb13_163025|  -1.21482e+00 -1.45812e+00 -1.58185e-01]
21Feb13_163025| [ 4.31964e-01 -2.36822e-01  2.71119e-01 -1.28570e-01 -1.53996e+00
21Feb13_163025|   5.51374e-01  8.51521e-01 -1.87252e-03]
21Feb13_163025| [ 7.36059e-01  2.03168e+00 -2.68137e-01  1.70106e+00  8.03452e-01
21Feb13_163025|  -9.28072e-01  3.15312e+00  5.03465e-01]
21Feb13_163025| [ 1.80659e+00 -4.69960e-01  5.45626e-02  3.79517e-01 -9.48898e-01
21Feb13_163025|   3.17335e-01  4.23174e-02  1.25038e-01]
21Feb13_163025| [-1.36823e+00 -1.09100e+00  5.58333e-01 -1.75850e+00 -5.38353e-01
21Feb13_163025|   1.32464e+00 -1.44645e+00 -8.10629e-01]
21Feb13_163025| [ 1.34275e+00 -1.41251e+00 -4.78630e-01  1.46547e+00  5.64584e-01
21Feb13_163025|  -1.16980e+00 -2.78855e-01  9.98143e-01]
21Feb13_163025| [ 2.09905e+00  1.12670e-01 -2.75076e-02  3.01802e-01 -4.44158e-01
21Feb13_163025|   5.97231e-01 -4.45245e-01 -6.24110e-01]
21Feb13_163025| [ 1.47398e-01  4.79586e-01 -1.51079e-01 -1.26635e+00 -1.86360e+00
21Feb13_163025|   3.85638e-01 -2.26102e-01 -5.36332e-01]
21Feb13_163025| [ 2.39414e+00 -1.49220e+00  1.71112e+00 -3.26483e-02 -7.30602e-01
21Feb13_163025|  -7.71260e-01  1.35484e+00  1.46918e-01]
21Feb13_163025| [-8.79683e-01  2.04363e-01 -1.00453e+00  4.97801e-01  5.37708e-01
21Feb13_163025|   4.84817e-02  1.46449e-01  1.00633e+00]
21Feb13_163025| [ 9.87510e-01 -1.73494e+00 -3.97664e-01 -1.86384e+00 -1.37373e-01
21Feb13_163025|   9.58713e-01  7.88842e-01 -5.64893e-01]
21Feb13_163025| [ 1.23733e+00 -6.34561e-01  1.62916e-01  7.97154e-01  2.56756e-03
21Feb13_163025|  -5.26820e-01  1.12518e+00 -7.32085e-02]
21Feb13_163025| [ 9.60993e-02  2.80900e+00  1.96107e+00  2.67847e-01 -9.99283e-01
21Feb13_163025|  -4.52254e-01 -1.16903e+00  5.34274e-01]
21Feb13_163025| [ 1.46344e-01 -1.36033e-01  1.46780e+00  5.16901e-01 -2.00846e-01
21Feb13_163025|  -9.87830e-01  7.06146e-01  8.09746e-01]
21Feb13_163025| [ 1.55725e+00  7.75166e-01 -6.09187e-01  4.12681e-01  9.89784e-01
21Feb13_163025|  -3.28362e-01 -8.20779e-01 -1.15257e+00]
21Feb13_163025| [ 4.80557e-01  1.49401e-01 -8.28445e-01 -7.57686e-01 -1.21364e-01
21Feb13_163025|  -3.60461e-01 -1.25299e+00  1.96698e+00]
21Feb13_163025| [-4.30322e-01 -3.22697e+00 -4.46022e-01 -1.86729e+00  1.57431e+00
21Feb13_163025|   1.75365e-01  6.92210e-03 -6.13423e-01]
21Feb13_163025| [-1.34320e+00 -2.25301e+00  7.42062e-01 -6.16108e-01 -1.65630e-01
21Feb13_163025|  -4.69016e-01  1.84444e+00  3.27314e-01]
21Feb13_163025| [-5.16134e-02  2.23419e+00 -5.91959e-01  9.32150e-01 -1.06772e+00
21Feb13_163025|  -5.11523e-01  6.85844e-01 -1.03689e+00]
21Feb13_163025| [-1.30007e+00 -3.59148e-01  3.35093e-01  4.66641e-01  6.22570e-01
21Feb13_163025|  -1.71881e+00  7.41306e-01  1.11108e+00]
21Feb13_163025| [-2.00853e-01 -9.24747e-01 -2.19487e-01  6.18157e-01  6.43791e-01
21Feb13_163025|  -1.30594e+00  8.00212e-01  5.97219e-01]
21Feb13_163025| [-1.19358e+00 -5.99902e-01 -1.36178e+00  6.16698e-02 -1.07130e+00
21Feb13_163025|  -9.13657e-01 -5.31884e-01  5.48692e-01]
21Feb13_163025| [ 1.17813e+00 -8.97985e-01  1.95108e+00  2.09820e-01  2.84393e-03
21Feb13_163025|   1.23481e+00 -1.68539e-01  2.33940e-01]
21Feb13_163025| [-9.10662e-01  1.46989e+00 -1.08973e+00 -7.32452e-01 -2.41675e+00
21Feb13_163025|  -4.44959e-01  1.16536e+00 -9.01145e-01]
21Feb13_163025| [-8.82564e-01  7.05310e-01 -1.01819e+00 -2.26405e+00 -1.34282e+00
21Feb13_163025|   6.97505e-01  1.34754e+00 -2.32821e+00]
21Feb13_163025| [-4.48054e-01 -1.49619e+00  7.66455e-01  1.28585e-02  2.52223e-01
21Feb13_163025|  -1.68540e+00 -9.38609e-02 -2.02003e+00]]
21Feb13_163025|-- Bias --
21Feb13_163025|[ 1.17808e-03 -4.44270e-01  8.22591e-02  1.09959e+00 -3.08221e-01
21Feb13_163025|  1.75965e-01 -1.99442e-01 -1.41265e+00]
21Feb13_163025|Layer 1:
21Feb13_163025|-- Config --
21Feb13_163025|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 8], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163025|-- Weights --
21Feb13_163025|[[-0.98226  0.24821  1.19463]
21Feb13_163025| [ 0.22008  1.26392 -0.48812]
21Feb13_163025| [ 0.36979  0.18930  0.10872]
21Feb13_163025| [-0.31853  0.06591 -0.63823]
21Feb13_163025| [-1.04688  0.28658  0.05164]
21Feb13_163025| [-0.46144  0.29281  0.32274]
21Feb13_163025| [-1.38143  0.64735 -0.30380]
21Feb13_163025| [ 0.42874 -0.73215 -0.07617]]
21Feb13_163025|-- Bias --
21Feb13_163025|[ 0.11283 -0.91883 -0.02107]
21Feb13_163025|Layer 2:
21Feb13_163025|-- Config --
21Feb13_163025|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163025|-- Weights --
21Feb13_163025|[[-1.30873  0.76809  0.90757 -0.59244  0.54910 -0.47315]
21Feb13_163025| [-0.99187 -0.37179  0.74019 -0.16616  0.19931 -0.01629]
21Feb13_163025| [ 1.03741 -0.10805  0.70718 -0.07401 -0.40500 -0.37353]]
21Feb13_163025|-- Bias --
21Feb13_163025|[ 0.24190 -0.18750 -1.26833 -0.88541 -0.79598  0.36384]
21Feb13_163025|Layer 3:
21Feb13_163025|-- Config --
21Feb13_163025|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163025|-- Weights --
21Feb13_163025|[[-0.60635  0.23318]
21Feb13_163025| [-0.14250  0.55489]
21Feb13_163025| [-0.48538 -0.15199]
21Feb13_163025| [ 0.42067 -0.62737]
21Feb13_163025| [-0.99709  0.64501]
21Feb13_163025| [-0.25790  0.29907]]
21Feb13_163025|-- Bias --
21Feb13_163025|[-0.14887  1.00429]
21Feb13_163025|Predicting the validation and test data with the Best final individual.
21Feb13_163033| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_163033|-----------  ------------------  --------------------  ----------
21Feb13_163033|Validation         28.00                  51            0.48841
21Feb13_163033|   Test            26.06                  51            0.46524
21Feb13_163033|-------------------- Test #8 --------------------
21Feb13_163033|Best final individual weights
21Feb13_163033|Individual:
21Feb13_163033|-- Constant hidden layers --
21Feb13_163033|False
21Feb13_163033|Layer 0:
21Feb13_163033|-- Config --
21Feb13_163033|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 8, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163033|-- Weights --
21Feb13_163033|[[-7.96509e-01 -1.15059e+00 -6.26034e-01 -2.57608e-01 -1.16276e+00
21Feb13_163033|   2.17486e-01 -9.34321e-01  1.47903e-01]
21Feb13_163033| [ 1.83510e+00 -1.21927e-01 -7.21994e-01 -3.87175e-01  1.44182e+00
21Feb13_163033|  -5.60339e-01 -1.69323e+00  3.84702e-01]
21Feb13_163033| [ 2.29647e+00  4.98135e-01 -5.82819e-01 -6.51931e-01 -5.00483e-01
21Feb13_163033|  -5.21971e-01  1.02927e+00  1.39999e-01]
21Feb13_163033| [-1.71433e+00  5.20461e-01  1.07786e-01  1.72497e-01  8.17631e-01
21Feb13_163033|  -1.23382e-01 -7.64470e-01  6.85373e-01]
21Feb13_163033| [ 5.32175e-02  1.59085e+00  2.07908e+00 -1.24494e+00  2.20682e+00
21Feb13_163033|  -1.25821e+00 -1.66929e+00  1.94038e+00]
21Feb13_163033| [ 3.73667e-01  1.74451e+00  1.26327e-01  1.39647e+00  1.05080e+00
21Feb13_163033|   2.43187e-01  2.53561e-02  2.31324e-01]
21Feb13_163033| [-1.12310e+00 -1.74495e+00  1.77094e+00 -4.73527e-01  8.36949e-01
21Feb13_163033|   7.71774e-01 -4.35311e-01  1.53145e+00]
21Feb13_163033| [ 2.13217e+00  1.37125e+00 -9.20890e-01  1.06924e+00 -1.32771e+00
21Feb13_163033|   7.09898e-01  1.11439e+00 -1.27760e+00]
21Feb13_163033| [-1.77403e-02 -4.28601e-01  1.65835e+00 -1.87197e-01  1.00957e+00
21Feb13_163033|   2.55297e-01  1.06387e-01  1.21832e+00]
21Feb13_163033| [ 2.16525e+00 -1.25784e-01 -5.41529e-01  1.97828e-01  2.28966e+00
21Feb13_163033|  -1.46028e+00  4.98379e-03 -4.40688e-01]
21Feb13_163033| [-7.39511e-02  2.47569e-01 -2.23324e-01 -2.69329e+00 -1.10672e+00
21Feb13_163033|   1.29711e+00 -1.02474e+00 -3.36463e-01]
21Feb13_163033| [ 7.56693e-01 -1.07233e-01 -6.28270e-01  9.12612e-01 -8.77877e-01
21Feb13_163033|  -9.20839e-01 -2.24401e-01 -1.13295e+00]
21Feb13_163033| [-9.56727e-01 -1.86328e+00 -1.69292e-01  1.09894e+00 -7.25733e-01
21Feb13_163033|   7.74090e-01  4.02577e-01 -6.00141e-01]
21Feb13_163033| [-1.51671e+00 -9.25981e-02 -3.63639e-01 -5.52293e-02  3.65719e-01
21Feb13_163033|  -2.63172e-01 -9.22686e-01 -1.59066e+00]
21Feb13_163033| [ 6.19485e-01  1.04762e+00  1.15913e-01  7.68427e-01  9.88362e-01
21Feb13_163033|   4.00572e-01  1.01580e+00 -1.00402e+00]
21Feb13_163033| [ 7.91163e-01 -1.28156e+00 -3.72928e-01  1.20917e+00  7.26087e-02
21Feb13_163033|   1.23038e+00 -7.97295e-01  7.15324e-01]
21Feb13_163033| [ 7.69403e-01 -2.23882e+00 -4.06537e-01 -8.30657e-01 -1.85295e+00
21Feb13_163033|  -3.96728e-01 -1.32753e-01  1.40371e+00]
21Feb13_163033| [ 8.63582e-01 -4.52795e-01  3.96789e-01  7.20922e-01  9.68883e-01
21Feb13_163033|   5.76722e-01 -8.25456e-02 -9.35541e-01]
21Feb13_163033| [-7.49275e-01 -9.06243e-01  1.18676e+00  5.39848e-01  1.41834e+00
21Feb13_163033|   4.33185e-01 -6.77846e-01 -6.19523e-01]
21Feb13_163033| [-8.91000e-01 -4.94536e-01  5.48779e-01  2.33437e+00  1.49354e+00
21Feb13_163033|  -5.62471e-01  7.67750e-01  5.34580e-01]
21Feb13_163033| [-2.22339e+00 -9.48349e-02  1.11523e-01 -1.88580e+00  1.55613e+00
21Feb13_163033|  -2.63893e+00  1.54688e+00  3.23628e-01]
21Feb13_163033| [-8.55111e-01  8.53349e-02 -7.83263e-01 -1.51315e+00  1.04588e+00
21Feb13_163033|  -1.91727e-02  1.95011e+00  3.79730e-01]
21Feb13_163033| [ 2.51049e+00 -5.71821e-01 -3.88096e-01 -5.52635e-01 -6.13567e-01
21Feb13_163033|  -1.58586e+00  1.50576e+00 -3.00998e-01]
21Feb13_163033| [ 1.93294e+00  3.34612e-01  1.64052e+00 -6.15246e-02  1.30100e+00
21Feb13_163033|   1.76044e+00 -3.04681e-01  1.12959e+00]
21Feb13_163033| [-1.54512e+00  8.03853e-01  7.85451e-01 -6.07936e-01  1.46778e+00
21Feb13_163033|  -2.14726e-01  3.85177e-01  8.03591e-01]
21Feb13_163033| [-7.43437e-01 -9.54122e-01  1.29250e-01  6.55511e-01  2.19896e-01
21Feb13_163033|  -3.25329e-01 -1.79744e+00  1.49641e+00]
21Feb13_163033| [-1.06592e-01  1.44267e+00 -9.93954e-01 -1.01275e+00 -1.80724e+00
21Feb13_163033|  -1.61250e+00  3.80720e-01  1.00622e+00]
21Feb13_163033| [-1.24952e+00 -9.83355e-01 -1.52174e+00 -6.88709e-02 -1.82968e+00
21Feb13_163033|  -1.70623e+00  5.64768e-01  1.84679e+00]
21Feb13_163033| [-2.16342e-01  9.31138e-01  4.23135e-01  6.51742e-01  1.10173e+00
21Feb13_163033|  -5.06868e-01  1.23298e+00 -4.11005e-01]
21Feb13_163033| [-6.95216e-01 -3.15809e-01 -2.07574e+00  1.38096e+00 -1.71834e+00
21Feb13_163033|  -1.00945e+00 -1.93909e+00 -1.90334e-01]
21Feb13_163033| [ 1.07621e+00  9.00909e-02 -1.16790e+00  6.47977e-01  4.48710e-01
21Feb13_163033|  -2.35271e+00  1.03246e+00  9.83788e-01]
21Feb13_163033| [-1.87550e+00 -1.35257e+00  7.95260e-01  1.64205e+00  6.37801e-01
21Feb13_163033|  -1.21482e+00 -1.45812e+00 -1.58185e-01]
21Feb13_163033| [ 4.31964e-01 -2.36822e-01  2.71119e-01 -1.28570e-01 -1.53996e+00
21Feb13_163033|   5.51374e-01  8.51521e-01 -1.87252e-03]
21Feb13_163033| [ 7.36059e-01  2.03168e+00 -2.68137e-01  1.70106e+00  8.03452e-01
21Feb13_163033|  -9.28072e-01  3.15312e+00  5.03465e-01]
21Feb13_163033| [ 1.80659e+00 -4.69960e-01  5.45626e-02  3.79517e-01 -9.48898e-01
21Feb13_163033|   3.17335e-01  4.23174e-02  1.25038e-01]
21Feb13_163033| [-1.36823e+00 -1.09100e+00  5.58333e-01 -1.75850e+00 -5.38353e-01
21Feb13_163033|   1.32464e+00 -1.44645e+00 -8.10629e-01]
21Feb13_163033| [ 1.34275e+00 -1.41251e+00 -4.78630e-01  1.46547e+00  5.64584e-01
21Feb13_163033|  -1.16980e+00 -2.78855e-01  9.98143e-01]
21Feb13_163033| [ 2.09905e+00  1.12670e-01 -2.75076e-02  3.01802e-01 -4.44158e-01
21Feb13_163033|   5.97231e-01 -4.45245e-01 -6.24110e-01]
21Feb13_163033| [ 1.47398e-01  4.79586e-01 -1.51079e-01 -1.26635e+00 -1.86360e+00
21Feb13_163033|   3.85638e-01 -2.26102e-01 -5.36332e-01]
21Feb13_163033| [ 2.39414e+00 -1.49220e+00  1.71112e+00 -3.26483e-02 -7.30602e-01
21Feb13_163033|  -7.71260e-01  1.35484e+00  1.46918e-01]
21Feb13_163033| [-8.79683e-01  2.04363e-01 -1.00453e+00  4.97801e-01  5.37708e-01
21Feb13_163033|   4.84817e-02  1.46449e-01  1.00633e+00]
21Feb13_163033| [ 9.87510e-01 -1.73494e+00 -3.97664e-01 -1.86384e+00 -1.37373e-01
21Feb13_163033|   9.58713e-01  7.88842e-01 -5.64893e-01]
21Feb13_163033| [ 1.23733e+00 -6.34561e-01  1.62916e-01  7.97154e-01  2.56756e-03
21Feb13_163033|  -5.26820e-01  1.12518e+00 -7.32085e-02]
21Feb13_163033| [ 9.60993e-02  2.80900e+00  1.96107e+00  2.67847e-01 -9.99283e-01
21Feb13_163033|  -4.52254e-01 -1.16903e+00  5.34274e-01]
21Feb13_163033| [ 1.46344e-01 -1.36033e-01  1.46780e+00  5.16901e-01 -2.00846e-01
21Feb13_163033|  -9.87830e-01  7.06146e-01  8.09746e-01]
21Feb13_163033| [ 1.55725e+00  7.75166e-01 -6.09187e-01  4.12681e-01  9.89784e-01
21Feb13_163033|  -3.28362e-01 -8.20779e-01 -1.15257e+00]
21Feb13_163033| [ 4.80557e-01  1.49401e-01 -8.28445e-01 -7.57686e-01 -1.21364e-01
21Feb13_163033|  -3.60461e-01 -1.25299e+00  1.96698e+00]
21Feb13_163033| [-4.30322e-01 -3.22697e+00 -4.46022e-01 -1.86729e+00  1.57431e+00
21Feb13_163033|   1.75365e-01  6.92210e-03 -6.13423e-01]
21Feb13_163033| [-1.34320e+00 -2.25301e+00  7.42062e-01 -6.16108e-01 -1.65630e-01
21Feb13_163033|  -4.69016e-01  1.84444e+00  3.27314e-01]
21Feb13_163033| [-5.16134e-02  2.23419e+00 -5.91959e-01  9.32150e-01 -1.06772e+00
21Feb13_163033|  -5.11523e-01  6.85844e-01 -1.03689e+00]
21Feb13_163033| [-1.30007e+00 -3.59148e-01  3.35093e-01  4.66641e-01  6.22570e-01
21Feb13_163033|  -1.71881e+00  7.41306e-01  1.11108e+00]
21Feb13_163033| [-2.00853e-01 -9.24747e-01 -2.19487e-01  6.18157e-01  6.43791e-01
21Feb13_163033|  -1.30594e+00  8.00212e-01  5.97219e-01]
21Feb13_163033| [-1.19358e+00 -5.99902e-01 -1.36178e+00  6.16698e-02 -1.07130e+00
21Feb13_163033|  -9.13657e-01 -5.31884e-01  5.48692e-01]
21Feb13_163033| [ 1.17813e+00 -8.97985e-01  1.95108e+00  2.09820e-01  2.84393e-03
21Feb13_163033|   1.23481e+00 -1.68539e-01  2.33940e-01]
21Feb13_163033| [-9.10662e-01  1.46989e+00 -1.08973e+00 -7.32452e-01 -2.41675e+00
21Feb13_163033|  -4.44959e-01  1.16536e+00 -9.01145e-01]
21Feb13_163033| [-8.82564e-01  7.05310e-01 -1.01819e+00 -2.26405e+00 -1.34282e+00
21Feb13_163033|   6.97505e-01  1.34754e+00 -2.32821e+00]
21Feb13_163033| [-4.48054e-01 -1.49619e+00  7.66455e-01  1.28585e-02  2.52223e-01
21Feb13_163033|  -1.68540e+00 -9.38609e-02 -2.02003e+00]]
21Feb13_163033|-- Bias --
21Feb13_163033|[ 1.17808e-03 -4.44270e-01  8.22591e-02  1.09959e+00 -3.08221e-01
21Feb13_163033|  1.75965e-01 -1.99442e-01 -1.41265e+00]
21Feb13_163033|Layer 1:
21Feb13_163033|-- Config --
21Feb13_163033|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 8], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163033|-- Weights --
21Feb13_163033|[[-0.98226  0.24821  1.19463]
21Feb13_163033| [ 0.22008  1.26392 -0.48812]
21Feb13_163033| [ 0.36979  0.18930  0.10872]
21Feb13_163033| [-0.31853  0.06591 -0.63823]
21Feb13_163033| [-1.04688  0.28658  0.05164]
21Feb13_163033| [-0.46144  0.29281  0.32274]
21Feb13_163033| [-1.38143  0.64735 -0.30380]
21Feb13_163033| [ 0.42874 -0.73215 -0.07617]]
21Feb13_163033|-- Bias --
21Feb13_163033|[ 0.11283 -0.91883 -0.02107]
21Feb13_163033|Layer 2:
21Feb13_163033|-- Config --
21Feb13_163033|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163033|-- Weights --
21Feb13_163033|[[-1.30873  0.76809  0.90757 -0.59244  0.54910 -0.47315]
21Feb13_163033| [-0.99187 -0.37179  0.74019 -0.16616  0.19931 -0.01629]
21Feb13_163033| [ 1.03741 -0.10805  0.70718 -0.07401 -0.40500 -0.37353]]
21Feb13_163033|-- Bias --
21Feb13_163033|[ 0.24190 -0.18750 -1.26833 -0.88541 -0.79598  0.36384]
21Feb13_163033|Layer 3:
21Feb13_163033|-- Config --
21Feb13_163033|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163033|-- Weights --
21Feb13_163033|[[-0.60635  0.23318]
21Feb13_163033| [-0.14250  0.55489]
21Feb13_163033| [-0.48538 -0.15199]
21Feb13_163033| [ 0.42067 -0.62737]
21Feb13_163033| [-0.99709  0.64501]
21Feb13_163033| [-0.25790  0.29907]]
21Feb13_163033|-- Bias --
21Feb13_163033|[-0.14887  1.00429]
21Feb13_163033|Predicting the validation and test data with the Best final individual.
21Feb13_163041| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_163041|-----------  ------------------  --------------------  ----------
21Feb13_163041|Validation         27.30                  51            0.54198
21Feb13_163041|   Test            25.46                  51            0.50052
21Feb13_163041|-------------------- Test #9 --------------------
21Feb13_163041|Best final individual weights
21Feb13_163041|Individual:
21Feb13_163041|-- Constant hidden layers --
21Feb13_163041|False
21Feb13_163041|Layer 0:
21Feb13_163041|-- Config --
21Feb13_163041|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 8, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163041|-- Weights --
21Feb13_163041|[[-7.96509e-01 -1.15059e+00 -6.26034e-01 -2.57608e-01 -1.16276e+00
21Feb13_163041|   2.17486e-01 -9.34321e-01  1.47903e-01]
21Feb13_163041| [ 1.83510e+00 -1.21927e-01 -7.21994e-01 -3.87175e-01  1.44182e+00
21Feb13_163041|  -5.60339e-01 -1.69323e+00  3.84702e-01]
21Feb13_163041| [ 2.29647e+00  4.98135e-01 -5.82819e-01 -6.51931e-01 -5.00483e-01
21Feb13_163041|  -5.21971e-01  1.02927e+00  1.39999e-01]
21Feb13_163041| [-1.71433e+00  5.20461e-01  1.07786e-01  1.72497e-01  8.17631e-01
21Feb13_163041|  -1.23382e-01 -7.64470e-01  6.85373e-01]
21Feb13_163041| [ 5.32175e-02  1.59085e+00  2.07908e+00 -1.24494e+00  2.20682e+00
21Feb13_163041|  -1.25821e+00 -1.66929e+00  1.94038e+00]
21Feb13_163041| [ 3.73667e-01  1.74451e+00  1.26327e-01  1.39647e+00  1.05080e+00
21Feb13_163041|   2.43187e-01  2.53561e-02  2.31324e-01]
21Feb13_163041| [-1.12310e+00 -1.74495e+00  1.77094e+00 -4.73527e-01  8.36949e-01
21Feb13_163041|   7.71774e-01 -4.35311e-01  1.53145e+00]
21Feb13_163041| [ 2.13217e+00  1.37125e+00 -9.20890e-01  1.06924e+00 -1.32771e+00
21Feb13_163041|   7.09898e-01  1.11439e+00 -1.27760e+00]
21Feb13_163041| [-1.77403e-02 -4.28601e-01  1.65835e+00 -1.87197e-01  1.00957e+00
21Feb13_163041|   2.55297e-01  1.06387e-01  1.21832e+00]
21Feb13_163041| [ 2.16525e+00 -1.25784e-01 -5.41529e-01  1.97828e-01  2.28966e+00
21Feb13_163041|  -1.46028e+00  4.98379e-03 -4.40688e-01]
21Feb13_163041| [-7.39511e-02  2.47569e-01 -2.23324e-01 -2.69329e+00 -1.10672e+00
21Feb13_163041|   1.29711e+00 -1.02474e+00 -3.36463e-01]
21Feb13_163041| [ 7.56693e-01 -1.07233e-01 -6.28270e-01  9.12612e-01 -8.77877e-01
21Feb13_163041|  -9.20839e-01 -2.24401e-01 -1.13295e+00]
21Feb13_163041| [-9.56727e-01 -1.86328e+00 -1.69292e-01  1.09894e+00 -7.25733e-01
21Feb13_163041|   7.74090e-01  4.02577e-01 -6.00141e-01]
21Feb13_163041| [-1.51671e+00 -9.25981e-02 -3.63639e-01 -5.52293e-02  3.65719e-01
21Feb13_163041|  -2.63172e-01 -9.22686e-01 -1.59066e+00]
21Feb13_163041| [ 6.19485e-01  1.04762e+00  1.15913e-01  7.68427e-01  9.88362e-01
21Feb13_163041|   4.00572e-01  1.01580e+00 -1.00402e+00]
21Feb13_163041| [ 7.91163e-01 -1.28156e+00 -3.72928e-01  1.20917e+00  7.26087e-02
21Feb13_163041|   1.23038e+00 -7.97295e-01  7.15324e-01]
21Feb13_163041| [ 7.69403e-01 -2.23882e+00 -4.06537e-01 -8.30657e-01 -1.85295e+00
21Feb13_163041|  -3.96728e-01 -1.32753e-01  1.40371e+00]
21Feb13_163041| [ 8.63582e-01 -4.52795e-01  3.96789e-01  7.20922e-01  9.68883e-01
21Feb13_163041|   5.76722e-01 -8.25456e-02 -9.35541e-01]
21Feb13_163041| [-7.49275e-01 -9.06243e-01  1.18676e+00  5.39848e-01  1.41834e+00
21Feb13_163041|   4.33185e-01 -6.77846e-01 -6.19523e-01]
21Feb13_163041| [-8.91000e-01 -4.94536e-01  5.48779e-01  2.33437e+00  1.49354e+00
21Feb13_163041|  -5.62471e-01  7.67750e-01  5.34580e-01]
21Feb13_163041| [-2.22339e+00 -9.48349e-02  1.11523e-01 -1.88580e+00  1.55613e+00
21Feb13_163041|  -2.63893e+00  1.54688e+00  3.23628e-01]
21Feb13_163041| [-8.55111e-01  8.53349e-02 -7.83263e-01 -1.51315e+00  1.04588e+00
21Feb13_163041|  -1.91727e-02  1.95011e+00  3.79730e-01]
21Feb13_163041| [ 2.51049e+00 -5.71821e-01 -3.88096e-01 -5.52635e-01 -6.13567e-01
21Feb13_163041|  -1.58586e+00  1.50576e+00 -3.00998e-01]
21Feb13_163041| [ 1.93294e+00  3.34612e-01  1.64052e+00 -6.15246e-02  1.30100e+00
21Feb13_163041|   1.76044e+00 -3.04681e-01  1.12959e+00]
21Feb13_163041| [-1.54512e+00  8.03853e-01  7.85451e-01 -6.07936e-01  1.46778e+00
21Feb13_163041|  -2.14726e-01  3.85177e-01  8.03591e-01]
21Feb13_163041| [-7.43437e-01 -9.54122e-01  1.29250e-01  6.55511e-01  2.19896e-01
21Feb13_163041|  -3.25329e-01 -1.79744e+00  1.49641e+00]
21Feb13_163041| [-1.06592e-01  1.44267e+00 -9.93954e-01 -1.01275e+00 -1.80724e+00
21Feb13_163041|  -1.61250e+00  3.80720e-01  1.00622e+00]
21Feb13_163041| [-1.24952e+00 -9.83355e-01 -1.52174e+00 -6.88709e-02 -1.82968e+00
21Feb13_163041|  -1.70623e+00  5.64768e-01  1.84679e+00]
21Feb13_163041| [-2.16342e-01  9.31138e-01  4.23135e-01  6.51742e-01  1.10173e+00
21Feb13_163041|  -5.06868e-01  1.23298e+00 -4.11005e-01]
21Feb13_163041| [-6.95216e-01 -3.15809e-01 -2.07574e+00  1.38096e+00 -1.71834e+00
21Feb13_163041|  -1.00945e+00 -1.93909e+00 -1.90334e-01]
21Feb13_163041| [ 1.07621e+00  9.00909e-02 -1.16790e+00  6.47977e-01  4.48710e-01
21Feb13_163041|  -2.35271e+00  1.03246e+00  9.83788e-01]
21Feb13_163041| [-1.87550e+00 -1.35257e+00  7.95260e-01  1.64205e+00  6.37801e-01
21Feb13_163041|  -1.21482e+00 -1.45812e+00 -1.58185e-01]
21Feb13_163041| [ 4.31964e-01 -2.36822e-01  2.71119e-01 -1.28570e-01 -1.53996e+00
21Feb13_163041|   5.51374e-01  8.51521e-01 -1.87252e-03]
21Feb13_163041| [ 7.36059e-01  2.03168e+00 -2.68137e-01  1.70106e+00  8.03452e-01
21Feb13_163041|  -9.28072e-01  3.15312e+00  5.03465e-01]
21Feb13_163041| [ 1.80659e+00 -4.69960e-01  5.45626e-02  3.79517e-01 -9.48898e-01
21Feb13_163041|   3.17335e-01  4.23174e-02  1.25038e-01]
21Feb13_163041| [-1.36823e+00 -1.09100e+00  5.58333e-01 -1.75850e+00 -5.38353e-01
21Feb13_163041|   1.32464e+00 -1.44645e+00 -8.10629e-01]
21Feb13_163041| [ 1.34275e+00 -1.41251e+00 -4.78630e-01  1.46547e+00  5.64584e-01
21Feb13_163041|  -1.16980e+00 -2.78855e-01  9.98143e-01]
21Feb13_163041| [ 2.09905e+00  1.12670e-01 -2.75076e-02  3.01802e-01 -4.44158e-01
21Feb13_163041|   5.97231e-01 -4.45245e-01 -6.24110e-01]
21Feb13_163041| [ 1.47398e-01  4.79586e-01 -1.51079e-01 -1.26635e+00 -1.86360e+00
21Feb13_163041|   3.85638e-01 -2.26102e-01 -5.36332e-01]
21Feb13_163041| [ 2.39414e+00 -1.49220e+00  1.71112e+00 -3.26483e-02 -7.30602e-01
21Feb13_163041|  -7.71260e-01  1.35484e+00  1.46918e-01]
21Feb13_163041| [-8.79683e-01  2.04363e-01 -1.00453e+00  4.97801e-01  5.37708e-01
21Feb13_163041|   4.84817e-02  1.46449e-01  1.00633e+00]
21Feb13_163041| [ 9.87510e-01 -1.73494e+00 -3.97664e-01 -1.86384e+00 -1.37373e-01
21Feb13_163041|   9.58713e-01  7.88842e-01 -5.64893e-01]
21Feb13_163041| [ 1.23733e+00 -6.34561e-01  1.62916e-01  7.97154e-01  2.56756e-03
21Feb13_163041|  -5.26820e-01  1.12518e+00 -7.32085e-02]
21Feb13_163041| [ 9.60993e-02  2.80900e+00  1.96107e+00  2.67847e-01 -9.99283e-01
21Feb13_163041|  -4.52254e-01 -1.16903e+00  5.34274e-01]
21Feb13_163041| [ 1.46344e-01 -1.36033e-01  1.46780e+00  5.16901e-01 -2.00846e-01
21Feb13_163041|  -9.87830e-01  7.06146e-01  8.09746e-01]
21Feb13_163041| [ 1.55725e+00  7.75166e-01 -6.09187e-01  4.12681e-01  9.89784e-01
21Feb13_163041|  -3.28362e-01 -8.20779e-01 -1.15257e+00]
21Feb13_163041| [ 4.80557e-01  1.49401e-01 -8.28445e-01 -7.57686e-01 -1.21364e-01
21Feb13_163041|  -3.60461e-01 -1.25299e+00  1.96698e+00]
21Feb13_163041| [-4.30322e-01 -3.22697e+00 -4.46022e-01 -1.86729e+00  1.57431e+00
21Feb13_163041|   1.75365e-01  6.92210e-03 -6.13423e-01]
21Feb13_163041| [-1.34320e+00 -2.25301e+00  7.42062e-01 -6.16108e-01 -1.65630e-01
21Feb13_163041|  -4.69016e-01  1.84444e+00  3.27314e-01]
21Feb13_163041| [-5.16134e-02  2.23419e+00 -5.91959e-01  9.32150e-01 -1.06772e+00
21Feb13_163041|  -5.11523e-01  6.85844e-01 -1.03689e+00]
21Feb13_163041| [-1.30007e+00 -3.59148e-01  3.35093e-01  4.66641e-01  6.22570e-01
21Feb13_163041|  -1.71881e+00  7.41306e-01  1.11108e+00]
21Feb13_163041| [-2.00853e-01 -9.24747e-01 -2.19487e-01  6.18157e-01  6.43791e-01
21Feb13_163041|  -1.30594e+00  8.00212e-01  5.97219e-01]
21Feb13_163041| [-1.19358e+00 -5.99902e-01 -1.36178e+00  6.16698e-02 -1.07130e+00
21Feb13_163041|  -9.13657e-01 -5.31884e-01  5.48692e-01]
21Feb13_163041| [ 1.17813e+00 -8.97985e-01  1.95108e+00  2.09820e-01  2.84393e-03
21Feb13_163041|   1.23481e+00 -1.68539e-01  2.33940e-01]
21Feb13_163041| [-9.10662e-01  1.46989e+00 -1.08973e+00 -7.32452e-01 -2.41675e+00
21Feb13_163041|  -4.44959e-01  1.16536e+00 -9.01145e-01]
21Feb13_163041| [-8.82564e-01  7.05310e-01 -1.01819e+00 -2.26405e+00 -1.34282e+00
21Feb13_163041|   6.97505e-01  1.34754e+00 -2.32821e+00]
21Feb13_163041| [-4.48054e-01 -1.49619e+00  7.66455e-01  1.28585e-02  2.52223e-01
21Feb13_163041|  -1.68540e+00 -9.38609e-02 -2.02003e+00]]
21Feb13_163041|-- Bias --
21Feb13_163041|[ 1.17808e-03 -4.44270e-01  8.22591e-02  1.09959e+00 -3.08221e-01
21Feb13_163041|  1.75965e-01 -1.99442e-01 -1.41265e+00]
21Feb13_163041|Layer 1:
21Feb13_163041|-- Config --
21Feb13_163041|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 8], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163041|-- Weights --
21Feb13_163041|[[-0.98226  0.24821  1.19463]
21Feb13_163041| [ 0.22008  1.26392 -0.48812]
21Feb13_163041| [ 0.36979  0.18930  0.10872]
21Feb13_163041| [-0.31853  0.06591 -0.63823]
21Feb13_163041| [-1.04688  0.28658  0.05164]
21Feb13_163041| [-0.46144  0.29281  0.32274]
21Feb13_163041| [-1.38143  0.64735 -0.30380]
21Feb13_163041| [ 0.42874 -0.73215 -0.07617]]
21Feb13_163041|-- Bias --
21Feb13_163041|[ 0.11283 -0.91883 -0.02107]
21Feb13_163041|Layer 2:
21Feb13_163041|-- Config --
21Feb13_163041|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163041|-- Weights --
21Feb13_163041|[[-1.30873  0.76809  0.90757 -0.59244  0.54910 -0.47315]
21Feb13_163041| [-0.99187 -0.37179  0.74019 -0.16616  0.19931 -0.01629]
21Feb13_163041| [ 1.03741 -0.10805  0.70718 -0.07401 -0.40500 -0.37353]]
21Feb13_163041|-- Bias --
21Feb13_163041|[ 0.24190 -0.18750 -1.26833 -0.88541 -0.79598  0.36384]
21Feb13_163041|Layer 3:
21Feb13_163041|-- Config --
21Feb13_163041|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163041|-- Weights --
21Feb13_163041|[[-0.60635  0.23318]
21Feb13_163041| [-0.14250  0.55489]
21Feb13_163041| [-0.48538 -0.15199]
21Feb13_163041| [ 0.42067 -0.62737]
21Feb13_163041| [-0.99709  0.64501]
21Feb13_163041| [-0.25790  0.29907]]
21Feb13_163041|-- Bias --
21Feb13_163041|[-0.14887  1.00429]
21Feb13_163041|Predicting the validation and test data with the Best final individual.
21Feb13_163048| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_163048|-----------  ------------------  --------------------  ----------
21Feb13_163048|Validation         35.74                  51            0.20710
21Feb13_163048|   Test            27.80                  51            0.31094
21Feb13_163048|-------------------- Test #10 --------------------
21Feb13_163048|Best final individual weights
21Feb13_163048|Individual:
21Feb13_163048|-- Constant hidden layers --
21Feb13_163048|False
21Feb13_163048|Layer 0:
21Feb13_163048|-- Config --
21Feb13_163048|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 8, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163048|-- Weights --
21Feb13_163048|[[-7.96509e-01 -1.15059e+00 -6.26034e-01 -2.57608e-01 -1.16276e+00
21Feb13_163048|   2.17486e-01 -9.34321e-01  1.47903e-01]
21Feb13_163048| [ 1.83510e+00 -1.21927e-01 -7.21994e-01 -3.87175e-01  1.44182e+00
21Feb13_163048|  -5.60339e-01 -1.69323e+00  3.84702e-01]
21Feb13_163048| [ 2.29647e+00  4.98135e-01 -5.82819e-01 -6.51931e-01 -5.00483e-01
21Feb13_163048|  -5.21971e-01  1.02927e+00  1.39999e-01]
21Feb13_163048| [-1.71433e+00  5.20461e-01  1.07786e-01  1.72497e-01  8.17631e-01
21Feb13_163048|  -1.23382e-01 -7.64470e-01  6.85373e-01]
21Feb13_163048| [ 5.32175e-02  1.59085e+00  2.07908e+00 -1.24494e+00  2.20682e+00
21Feb13_163048|  -1.25821e+00 -1.66929e+00  1.94038e+00]
21Feb13_163048| [ 3.73667e-01  1.74451e+00  1.26327e-01  1.39647e+00  1.05080e+00
21Feb13_163048|   2.43187e-01  2.53561e-02  2.31324e-01]
21Feb13_163048| [-1.12310e+00 -1.74495e+00  1.77094e+00 -4.73527e-01  8.36949e-01
21Feb13_163048|   7.71774e-01 -4.35311e-01  1.53145e+00]
21Feb13_163048| [ 2.13217e+00  1.37125e+00 -9.20890e-01  1.06924e+00 -1.32771e+00
21Feb13_163048|   7.09898e-01  1.11439e+00 -1.27760e+00]
21Feb13_163048| [-1.77403e-02 -4.28601e-01  1.65835e+00 -1.87197e-01  1.00957e+00
21Feb13_163048|   2.55297e-01  1.06387e-01  1.21832e+00]
21Feb13_163048| [ 2.16525e+00 -1.25784e-01 -5.41529e-01  1.97828e-01  2.28966e+00
21Feb13_163048|  -1.46028e+00  4.98379e-03 -4.40688e-01]
21Feb13_163048| [-7.39511e-02  2.47569e-01 -2.23324e-01 -2.69329e+00 -1.10672e+00
21Feb13_163048|   1.29711e+00 -1.02474e+00 -3.36463e-01]
21Feb13_163048| [ 7.56693e-01 -1.07233e-01 -6.28270e-01  9.12612e-01 -8.77877e-01
21Feb13_163048|  -9.20839e-01 -2.24401e-01 -1.13295e+00]
21Feb13_163048| [-9.56727e-01 -1.86328e+00 -1.69292e-01  1.09894e+00 -7.25733e-01
21Feb13_163048|   7.74090e-01  4.02577e-01 -6.00141e-01]
21Feb13_163048| [-1.51671e+00 -9.25981e-02 -3.63639e-01 -5.52293e-02  3.65719e-01
21Feb13_163048|  -2.63172e-01 -9.22686e-01 -1.59066e+00]
21Feb13_163048| [ 6.19485e-01  1.04762e+00  1.15913e-01  7.68427e-01  9.88362e-01
21Feb13_163048|   4.00572e-01  1.01580e+00 -1.00402e+00]
21Feb13_163048| [ 7.91163e-01 -1.28156e+00 -3.72928e-01  1.20917e+00  7.26087e-02
21Feb13_163048|   1.23038e+00 -7.97295e-01  7.15324e-01]
21Feb13_163048| [ 7.69403e-01 -2.23882e+00 -4.06537e-01 -8.30657e-01 -1.85295e+00
21Feb13_163048|  -3.96728e-01 -1.32753e-01  1.40371e+00]
21Feb13_163048| [ 8.63582e-01 -4.52795e-01  3.96789e-01  7.20922e-01  9.68883e-01
21Feb13_163048|   5.76722e-01 -8.25456e-02 -9.35541e-01]
21Feb13_163048| [-7.49275e-01 -9.06243e-01  1.18676e+00  5.39848e-01  1.41834e+00
21Feb13_163048|   4.33185e-01 -6.77846e-01 -6.19523e-01]
21Feb13_163048| [-8.91000e-01 -4.94536e-01  5.48779e-01  2.33437e+00  1.49354e+00
21Feb13_163048|  -5.62471e-01  7.67750e-01  5.34580e-01]
21Feb13_163048| [-2.22339e+00 -9.48349e-02  1.11523e-01 -1.88580e+00  1.55613e+00
21Feb13_163048|  -2.63893e+00  1.54688e+00  3.23628e-01]
21Feb13_163048| [-8.55111e-01  8.53349e-02 -7.83263e-01 -1.51315e+00  1.04588e+00
21Feb13_163048|  -1.91727e-02  1.95011e+00  3.79730e-01]
21Feb13_163048| [ 2.51049e+00 -5.71821e-01 -3.88096e-01 -5.52635e-01 -6.13567e-01
21Feb13_163048|  -1.58586e+00  1.50576e+00 -3.00998e-01]
21Feb13_163048| [ 1.93294e+00  3.34612e-01  1.64052e+00 -6.15246e-02  1.30100e+00
21Feb13_163048|   1.76044e+00 -3.04681e-01  1.12959e+00]
21Feb13_163048| [-1.54512e+00  8.03853e-01  7.85451e-01 -6.07936e-01  1.46778e+00
21Feb13_163048|  -2.14726e-01  3.85177e-01  8.03591e-01]
21Feb13_163048| [-7.43437e-01 -9.54122e-01  1.29250e-01  6.55511e-01  2.19896e-01
21Feb13_163048|  -3.25329e-01 -1.79744e+00  1.49641e+00]
21Feb13_163048| [-1.06592e-01  1.44267e+00 -9.93954e-01 -1.01275e+00 -1.80724e+00
21Feb13_163048|  -1.61250e+00  3.80720e-01  1.00622e+00]
21Feb13_163048| [-1.24952e+00 -9.83355e-01 -1.52174e+00 -6.88709e-02 -1.82968e+00
21Feb13_163048|  -1.70623e+00  5.64768e-01  1.84679e+00]
21Feb13_163048| [-2.16342e-01  9.31138e-01  4.23135e-01  6.51742e-01  1.10173e+00
21Feb13_163048|  -5.06868e-01  1.23298e+00 -4.11005e-01]
21Feb13_163048| [-6.95216e-01 -3.15809e-01 -2.07574e+00  1.38096e+00 -1.71834e+00
21Feb13_163048|  -1.00945e+00 -1.93909e+00 -1.90334e-01]
21Feb13_163048| [ 1.07621e+00  9.00909e-02 -1.16790e+00  6.47977e-01  4.48710e-01
21Feb13_163048|  -2.35271e+00  1.03246e+00  9.83788e-01]
21Feb13_163048| [-1.87550e+00 -1.35257e+00  7.95260e-01  1.64205e+00  6.37801e-01
21Feb13_163048|  -1.21482e+00 -1.45812e+00 -1.58185e-01]
21Feb13_163048| [ 4.31964e-01 -2.36822e-01  2.71119e-01 -1.28570e-01 -1.53996e+00
21Feb13_163048|   5.51374e-01  8.51521e-01 -1.87252e-03]
21Feb13_163048| [ 7.36059e-01  2.03168e+00 -2.68137e-01  1.70106e+00  8.03452e-01
21Feb13_163048|  -9.28072e-01  3.15312e+00  5.03465e-01]
21Feb13_163048| [ 1.80659e+00 -4.69960e-01  5.45626e-02  3.79517e-01 -9.48898e-01
21Feb13_163048|   3.17335e-01  4.23174e-02  1.25038e-01]
21Feb13_163048| [-1.36823e+00 -1.09100e+00  5.58333e-01 -1.75850e+00 -5.38353e-01
21Feb13_163048|   1.32464e+00 -1.44645e+00 -8.10629e-01]
21Feb13_163048| [ 1.34275e+00 -1.41251e+00 -4.78630e-01  1.46547e+00  5.64584e-01
21Feb13_163048|  -1.16980e+00 -2.78855e-01  9.98143e-01]
21Feb13_163048| [ 2.09905e+00  1.12670e-01 -2.75076e-02  3.01802e-01 -4.44158e-01
21Feb13_163048|   5.97231e-01 -4.45245e-01 -6.24110e-01]
21Feb13_163048| [ 1.47398e-01  4.79586e-01 -1.51079e-01 -1.26635e+00 -1.86360e+00
21Feb13_163048|   3.85638e-01 -2.26102e-01 -5.36332e-01]
21Feb13_163048| [ 2.39414e+00 -1.49220e+00  1.71112e+00 -3.26483e-02 -7.30602e-01
21Feb13_163048|  -7.71260e-01  1.35484e+00  1.46918e-01]
21Feb13_163048| [-8.79683e-01  2.04363e-01 -1.00453e+00  4.97801e-01  5.37708e-01
21Feb13_163048|   4.84817e-02  1.46449e-01  1.00633e+00]
21Feb13_163048| [ 9.87510e-01 -1.73494e+00 -3.97664e-01 -1.86384e+00 -1.37373e-01
21Feb13_163048|   9.58713e-01  7.88842e-01 -5.64893e-01]
21Feb13_163048| [ 1.23733e+00 -6.34561e-01  1.62916e-01  7.97154e-01  2.56756e-03
21Feb13_163048|  -5.26820e-01  1.12518e+00 -7.32085e-02]
21Feb13_163048| [ 9.60993e-02  2.80900e+00  1.96107e+00  2.67847e-01 -9.99283e-01
21Feb13_163048|  -4.52254e-01 -1.16903e+00  5.34274e-01]
21Feb13_163048| [ 1.46344e-01 -1.36033e-01  1.46780e+00  5.16901e-01 -2.00846e-01
21Feb13_163048|  -9.87830e-01  7.06146e-01  8.09746e-01]
21Feb13_163048| [ 1.55725e+00  7.75166e-01 -6.09187e-01  4.12681e-01  9.89784e-01
21Feb13_163048|  -3.28362e-01 -8.20779e-01 -1.15257e+00]
21Feb13_163048| [ 4.80557e-01  1.49401e-01 -8.28445e-01 -7.57686e-01 -1.21364e-01
21Feb13_163048|  -3.60461e-01 -1.25299e+00  1.96698e+00]
21Feb13_163048| [-4.30322e-01 -3.22697e+00 -4.46022e-01 -1.86729e+00  1.57431e+00
21Feb13_163048|   1.75365e-01  6.92210e-03 -6.13423e-01]
21Feb13_163048| [-1.34320e+00 -2.25301e+00  7.42062e-01 -6.16108e-01 -1.65630e-01
21Feb13_163048|  -4.69016e-01  1.84444e+00  3.27314e-01]
21Feb13_163048| [-5.16134e-02  2.23419e+00 -5.91959e-01  9.32150e-01 -1.06772e+00
21Feb13_163048|  -5.11523e-01  6.85844e-01 -1.03689e+00]
21Feb13_163048| [-1.30007e+00 -3.59148e-01  3.35093e-01  4.66641e-01  6.22570e-01
21Feb13_163048|  -1.71881e+00  7.41306e-01  1.11108e+00]
21Feb13_163048| [-2.00853e-01 -9.24747e-01 -2.19487e-01  6.18157e-01  6.43791e-01
21Feb13_163048|  -1.30594e+00  8.00212e-01  5.97219e-01]
21Feb13_163048| [-1.19358e+00 -5.99902e-01 -1.36178e+00  6.16698e-02 -1.07130e+00
21Feb13_163048|  -9.13657e-01 -5.31884e-01  5.48692e-01]
21Feb13_163048| [ 1.17813e+00 -8.97985e-01  1.95108e+00  2.09820e-01  2.84393e-03
21Feb13_163048|   1.23481e+00 -1.68539e-01  2.33940e-01]
21Feb13_163048| [-9.10662e-01  1.46989e+00 -1.08973e+00 -7.32452e-01 -2.41675e+00
21Feb13_163048|  -4.44959e-01  1.16536e+00 -9.01145e-01]
21Feb13_163048| [-8.82564e-01  7.05310e-01 -1.01819e+00 -2.26405e+00 -1.34282e+00
21Feb13_163048|   6.97505e-01  1.34754e+00 -2.32821e+00]
21Feb13_163048| [-4.48054e-01 -1.49619e+00  7.66455e-01  1.28585e-02  2.52223e-01
21Feb13_163048|  -1.68540e+00 -9.38609e-02 -2.02003e+00]]
21Feb13_163048|-- Bias --
21Feb13_163048|[ 1.17808e-03 -4.44270e-01  8.22591e-02  1.09959e+00 -3.08221e-01
21Feb13_163048|  1.75965e-01 -1.99442e-01 -1.41265e+00]
21Feb13_163048|Layer 1:
21Feb13_163048|-- Config --
21Feb13_163048|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 8], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163048|-- Weights --
21Feb13_163048|[[-0.98226  0.24821  1.19463]
21Feb13_163048| [ 0.22008  1.26392 -0.48812]
21Feb13_163048| [ 0.36979  0.18930  0.10872]
21Feb13_163048| [-0.31853  0.06591 -0.63823]
21Feb13_163048| [-1.04688  0.28658  0.05164]
21Feb13_163048| [-0.46144  0.29281  0.32274]
21Feb13_163048| [-1.38143  0.64735 -0.30380]
21Feb13_163048| [ 0.42874 -0.73215 -0.07617]]
21Feb13_163048|-- Bias --
21Feb13_163048|[ 0.11283 -0.91883 -0.02107]
21Feb13_163048|Layer 2:
21Feb13_163048|-- Config --
21Feb13_163048|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163048|-- Weights --
21Feb13_163048|[[-1.30873  0.76809  0.90757 -0.59244  0.54910 -0.47315]
21Feb13_163048| [-0.99187 -0.37179  0.74019 -0.16616  0.19931 -0.01629]
21Feb13_163048| [ 1.03741 -0.10805  0.70718 -0.07401 -0.40500 -0.37353]]
21Feb13_163048|-- Bias --
21Feb13_163048|[ 0.24190 -0.18750 -1.26833 -0.88541 -0.79598  0.36384]
21Feb13_163048|Layer 3:
21Feb13_163048|-- Config --
21Feb13_163048|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163048|-- Weights --
21Feb13_163048|[[-0.60635  0.23318]
21Feb13_163048| [-0.14250  0.55489]
21Feb13_163048| [-0.48538 -0.15199]
21Feb13_163048| [ 0.42067 -0.62737]
21Feb13_163048| [-0.99709  0.64501]
21Feb13_163048| [-0.25790  0.29907]]
21Feb13_163048|-- Bias --
21Feb13_163048|[-0.14887  1.00429]
21Feb13_163048|Predicting the validation and test data with the Best final individual.
21Feb13_163056| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_163056|-----------  ------------------  --------------------  ----------
21Feb13_163056|Validation         28.52                  51            0.45182
21Feb13_163056|   Test            25.46                  51            0.45407
21Feb13_163056|-------------------- Test #11 --------------------
21Feb13_163056|Best final individual weights
21Feb13_163056|Individual:
21Feb13_163056|-- Constant hidden layers --
21Feb13_163056|False
21Feb13_163056|Layer 0:
21Feb13_163056|-- Config --
21Feb13_163056|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 8, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163056|-- Weights --
21Feb13_163056|[[-7.96509e-01 -1.15059e+00 -6.26034e-01 -2.57608e-01 -1.16276e+00
21Feb13_163056|   2.17486e-01 -9.34321e-01  1.47903e-01]
21Feb13_163056| [ 1.83510e+00 -1.21927e-01 -7.21994e-01 -3.87175e-01  1.44182e+00
21Feb13_163056|  -5.60339e-01 -1.69323e+00  3.84702e-01]
21Feb13_163056| [ 2.29647e+00  4.98135e-01 -5.82819e-01 -6.51931e-01 -5.00483e-01
21Feb13_163056|  -5.21971e-01  1.02927e+00  1.39999e-01]
21Feb13_163056| [-1.71433e+00  5.20461e-01  1.07786e-01  1.72497e-01  8.17631e-01
21Feb13_163056|  -1.23382e-01 -7.64470e-01  6.85373e-01]
21Feb13_163056| [ 5.32175e-02  1.59085e+00  2.07908e+00 -1.24494e+00  2.20682e+00
21Feb13_163056|  -1.25821e+00 -1.66929e+00  1.94038e+00]
21Feb13_163056| [ 3.73667e-01  1.74451e+00  1.26327e-01  1.39647e+00  1.05080e+00
21Feb13_163056|   2.43187e-01  2.53561e-02  2.31324e-01]
21Feb13_163056| [-1.12310e+00 -1.74495e+00  1.77094e+00 -4.73527e-01  8.36949e-01
21Feb13_163056|   7.71774e-01 -4.35311e-01  1.53145e+00]
21Feb13_163056| [ 2.13217e+00  1.37125e+00 -9.20890e-01  1.06924e+00 -1.32771e+00
21Feb13_163056|   7.09898e-01  1.11439e+00 -1.27760e+00]
21Feb13_163056| [-1.77403e-02 -4.28601e-01  1.65835e+00 -1.87197e-01  1.00957e+00
21Feb13_163056|   2.55297e-01  1.06387e-01  1.21832e+00]
21Feb13_163056| [ 2.16525e+00 -1.25784e-01 -5.41529e-01  1.97828e-01  2.28966e+00
21Feb13_163056|  -1.46028e+00  4.98379e-03 -4.40688e-01]
21Feb13_163056| [-7.39511e-02  2.47569e-01 -2.23324e-01 -2.69329e+00 -1.10672e+00
21Feb13_163056|   1.29711e+00 -1.02474e+00 -3.36463e-01]
21Feb13_163056| [ 7.56693e-01 -1.07233e-01 -6.28270e-01  9.12612e-01 -8.77877e-01
21Feb13_163056|  -9.20839e-01 -2.24401e-01 -1.13295e+00]
21Feb13_163056| [-9.56727e-01 -1.86328e+00 -1.69292e-01  1.09894e+00 -7.25733e-01
21Feb13_163056|   7.74090e-01  4.02577e-01 -6.00141e-01]
21Feb13_163056| [-1.51671e+00 -9.25981e-02 -3.63639e-01 -5.52293e-02  3.65719e-01
21Feb13_163056|  -2.63172e-01 -9.22686e-01 -1.59066e+00]
21Feb13_163056| [ 6.19485e-01  1.04762e+00  1.15913e-01  7.68427e-01  9.88362e-01
21Feb13_163056|   4.00572e-01  1.01580e+00 -1.00402e+00]
21Feb13_163056| [ 7.91163e-01 -1.28156e+00 -3.72928e-01  1.20917e+00  7.26087e-02
21Feb13_163056|   1.23038e+00 -7.97295e-01  7.15324e-01]
21Feb13_163056| [ 7.69403e-01 -2.23882e+00 -4.06537e-01 -8.30657e-01 -1.85295e+00
21Feb13_163056|  -3.96728e-01 -1.32753e-01  1.40371e+00]
21Feb13_163056| [ 8.63582e-01 -4.52795e-01  3.96789e-01  7.20922e-01  9.68883e-01
21Feb13_163056|   5.76722e-01 -8.25456e-02 -9.35541e-01]
21Feb13_163056| [-7.49275e-01 -9.06243e-01  1.18676e+00  5.39848e-01  1.41834e+00
21Feb13_163056|   4.33185e-01 -6.77846e-01 -6.19523e-01]
21Feb13_163056| [-8.91000e-01 -4.94536e-01  5.48779e-01  2.33437e+00  1.49354e+00
21Feb13_163056|  -5.62471e-01  7.67750e-01  5.34580e-01]
21Feb13_163056| [-2.22339e+00 -9.48349e-02  1.11523e-01 -1.88580e+00  1.55613e+00
21Feb13_163056|  -2.63893e+00  1.54688e+00  3.23628e-01]
21Feb13_163056| [-8.55111e-01  8.53349e-02 -7.83263e-01 -1.51315e+00  1.04588e+00
21Feb13_163056|  -1.91727e-02  1.95011e+00  3.79730e-01]
21Feb13_163056| [ 2.51049e+00 -5.71821e-01 -3.88096e-01 -5.52635e-01 -6.13567e-01
21Feb13_163056|  -1.58586e+00  1.50576e+00 -3.00998e-01]
21Feb13_163056| [ 1.93294e+00  3.34612e-01  1.64052e+00 -6.15246e-02  1.30100e+00
21Feb13_163056|   1.76044e+00 -3.04681e-01  1.12959e+00]
21Feb13_163056| [-1.54512e+00  8.03853e-01  7.85451e-01 -6.07936e-01  1.46778e+00
21Feb13_163056|  -2.14726e-01  3.85177e-01  8.03591e-01]
21Feb13_163056| [-7.43437e-01 -9.54122e-01  1.29250e-01  6.55511e-01  2.19896e-01
21Feb13_163056|  -3.25329e-01 -1.79744e+00  1.49641e+00]
21Feb13_163056| [-1.06592e-01  1.44267e+00 -9.93954e-01 -1.01275e+00 -1.80724e+00
21Feb13_163056|  -1.61250e+00  3.80720e-01  1.00622e+00]
21Feb13_163056| [-1.24952e+00 -9.83355e-01 -1.52174e+00 -6.88709e-02 -1.82968e+00
21Feb13_163056|  -1.70623e+00  5.64768e-01  1.84679e+00]
21Feb13_163056| [-2.16342e-01  9.31138e-01  4.23135e-01  6.51742e-01  1.10173e+00
21Feb13_163056|  -5.06868e-01  1.23298e+00 -4.11005e-01]
21Feb13_163056| [-6.95216e-01 -3.15809e-01 -2.07574e+00  1.38096e+00 -1.71834e+00
21Feb13_163056|  -1.00945e+00 -1.93909e+00 -1.90334e-01]
21Feb13_163056| [ 1.07621e+00  9.00909e-02 -1.16790e+00  6.47977e-01  4.48710e-01
21Feb13_163056|  -2.35271e+00  1.03246e+00  9.83788e-01]
21Feb13_163056| [-1.87550e+00 -1.35257e+00  7.95260e-01  1.64205e+00  6.37801e-01
21Feb13_163056|  -1.21482e+00 -1.45812e+00 -1.58185e-01]
21Feb13_163056| [ 4.31964e-01 -2.36822e-01  2.71119e-01 -1.28570e-01 -1.53996e+00
21Feb13_163056|   5.51374e-01  8.51521e-01 -1.87252e-03]
21Feb13_163056| [ 7.36059e-01  2.03168e+00 -2.68137e-01  1.70106e+00  8.03452e-01
21Feb13_163056|  -9.28072e-01  3.15312e+00  5.03465e-01]
21Feb13_163056| [ 1.80659e+00 -4.69960e-01  5.45626e-02  3.79517e-01 -9.48898e-01
21Feb13_163056|   3.17335e-01  4.23174e-02  1.25038e-01]
21Feb13_163056| [-1.36823e+00 -1.09100e+00  5.58333e-01 -1.75850e+00 -5.38353e-01
21Feb13_163056|   1.32464e+00 -1.44645e+00 -8.10629e-01]
21Feb13_163056| [ 1.34275e+00 -1.41251e+00 -4.78630e-01  1.46547e+00  5.64584e-01
21Feb13_163056|  -1.16980e+00 -2.78855e-01  9.98143e-01]
21Feb13_163056| [ 2.09905e+00  1.12670e-01 -2.75076e-02  3.01802e-01 -4.44158e-01
21Feb13_163056|   5.97231e-01 -4.45245e-01 -6.24110e-01]
21Feb13_163056| [ 1.47398e-01  4.79586e-01 -1.51079e-01 -1.26635e+00 -1.86360e+00
21Feb13_163056|   3.85638e-01 -2.26102e-01 -5.36332e-01]
21Feb13_163056| [ 2.39414e+00 -1.49220e+00  1.71112e+00 -3.26483e-02 -7.30602e-01
21Feb13_163056|  -7.71260e-01  1.35484e+00  1.46918e-01]
21Feb13_163056| [-8.79683e-01  2.04363e-01 -1.00453e+00  4.97801e-01  5.37708e-01
21Feb13_163056|   4.84817e-02  1.46449e-01  1.00633e+00]
21Feb13_163056| [ 9.87510e-01 -1.73494e+00 -3.97664e-01 -1.86384e+00 -1.37373e-01
21Feb13_163056|   9.58713e-01  7.88842e-01 -5.64893e-01]
21Feb13_163056| [ 1.23733e+00 -6.34561e-01  1.62916e-01  7.97154e-01  2.56756e-03
21Feb13_163056|  -5.26820e-01  1.12518e+00 -7.32085e-02]
21Feb13_163056| [ 9.60993e-02  2.80900e+00  1.96107e+00  2.67847e-01 -9.99283e-01
21Feb13_163056|  -4.52254e-01 -1.16903e+00  5.34274e-01]
21Feb13_163056| [ 1.46344e-01 -1.36033e-01  1.46780e+00  5.16901e-01 -2.00846e-01
21Feb13_163056|  -9.87830e-01  7.06146e-01  8.09746e-01]
21Feb13_163056| [ 1.55725e+00  7.75166e-01 -6.09187e-01  4.12681e-01  9.89784e-01
21Feb13_163056|  -3.28362e-01 -8.20779e-01 -1.15257e+00]
21Feb13_163056| [ 4.80557e-01  1.49401e-01 -8.28445e-01 -7.57686e-01 -1.21364e-01
21Feb13_163056|  -3.60461e-01 -1.25299e+00  1.96698e+00]
21Feb13_163056| [-4.30322e-01 -3.22697e+00 -4.46022e-01 -1.86729e+00  1.57431e+00
21Feb13_163056|   1.75365e-01  6.92210e-03 -6.13423e-01]
21Feb13_163056| [-1.34320e+00 -2.25301e+00  7.42062e-01 -6.16108e-01 -1.65630e-01
21Feb13_163056|  -4.69016e-01  1.84444e+00  3.27314e-01]
21Feb13_163056| [-5.16134e-02  2.23419e+00 -5.91959e-01  9.32150e-01 -1.06772e+00
21Feb13_163056|  -5.11523e-01  6.85844e-01 -1.03689e+00]
21Feb13_163056| [-1.30007e+00 -3.59148e-01  3.35093e-01  4.66641e-01  6.22570e-01
21Feb13_163056|  -1.71881e+00  7.41306e-01  1.11108e+00]
21Feb13_163056| [-2.00853e-01 -9.24747e-01 -2.19487e-01  6.18157e-01  6.43791e-01
21Feb13_163056|  -1.30594e+00  8.00212e-01  5.97219e-01]
21Feb13_163056| [-1.19358e+00 -5.99902e-01 -1.36178e+00  6.16698e-02 -1.07130e+00
21Feb13_163056|  -9.13657e-01 -5.31884e-01  5.48692e-01]
21Feb13_163056| [ 1.17813e+00 -8.97985e-01  1.95108e+00  2.09820e-01  2.84393e-03
21Feb13_163056|   1.23481e+00 -1.68539e-01  2.33940e-01]
21Feb13_163056| [-9.10662e-01  1.46989e+00 -1.08973e+00 -7.32452e-01 -2.41675e+00
21Feb13_163056|  -4.44959e-01  1.16536e+00 -9.01145e-01]
21Feb13_163056| [-8.82564e-01  7.05310e-01 -1.01819e+00 -2.26405e+00 -1.34282e+00
21Feb13_163056|   6.97505e-01  1.34754e+00 -2.32821e+00]
21Feb13_163056| [-4.48054e-01 -1.49619e+00  7.66455e-01  1.28585e-02  2.52223e-01
21Feb13_163056|  -1.68540e+00 -9.38609e-02 -2.02003e+00]]
21Feb13_163056|-- Bias --
21Feb13_163056|[ 1.17808e-03 -4.44270e-01  8.22591e-02  1.09959e+00 -3.08221e-01
21Feb13_163056|  1.75965e-01 -1.99442e-01 -1.41265e+00]
21Feb13_163056|Layer 1:
21Feb13_163056|-- Config --
21Feb13_163056|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 8], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163056|-- Weights --
21Feb13_163056|[[-0.98226  0.24821  1.19463]
21Feb13_163056| [ 0.22008  1.26392 -0.48812]
21Feb13_163056| [ 0.36979  0.18930  0.10872]
21Feb13_163056| [-0.31853  0.06591 -0.63823]
21Feb13_163056| [-1.04688  0.28658  0.05164]
21Feb13_163056| [-0.46144  0.29281  0.32274]
21Feb13_163056| [-1.38143  0.64735 -0.30380]
21Feb13_163056| [ 0.42874 -0.73215 -0.07617]]
21Feb13_163056|-- Bias --
21Feb13_163056|[ 0.11283 -0.91883 -0.02107]
21Feb13_163056|Layer 2:
21Feb13_163056|-- Config --
21Feb13_163056|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163056|-- Weights --
21Feb13_163056|[[-1.30873  0.76809  0.90757 -0.59244  0.54910 -0.47315]
21Feb13_163056| [-0.99187 -0.37179  0.74019 -0.16616  0.19931 -0.01629]
21Feb13_163056| [ 1.03741 -0.10805  0.70718 -0.07401 -0.40500 -0.37353]]
21Feb13_163056|-- Bias --
21Feb13_163056|[ 0.24190 -0.18750 -1.26833 -0.88541 -0.79598  0.36384]
21Feb13_163056|Layer 3:
21Feb13_163056|-- Config --
21Feb13_163056|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163056|-- Weights --
21Feb13_163056|[[-0.60635  0.23318]
21Feb13_163056| [-0.14250  0.55489]
21Feb13_163056| [-0.48538 -0.15199]
21Feb13_163056| [ 0.42067 -0.62737]
21Feb13_163056| [-0.99709  0.64501]
21Feb13_163056| [-0.25790  0.29907]]
21Feb13_163056|-- Bias --
21Feb13_163056|[-0.14887  1.00429]
21Feb13_163056|Predicting the validation and test data with the Best final individual.
21Feb13_163104| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_163104|-----------  ------------------  --------------------  ----------
21Feb13_163104|Validation         28.70                  51            0.46825
21Feb13_163104|   Test            25.72                  51            0.45119
21Feb13_163104|-------------------- Test #12 --------------------
21Feb13_163104|Best final individual weights
21Feb13_163104|Individual:
21Feb13_163104|-- Constant hidden layers --
21Feb13_163104|False
21Feb13_163104|Layer 0:
21Feb13_163104|-- Config --
21Feb13_163104|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 8, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163104|-- Weights --
21Feb13_163104|[[-7.96509e-01 -1.15059e+00 -6.26034e-01 -2.57608e-01 -1.16276e+00
21Feb13_163104|   2.17486e-01 -9.34321e-01  1.47903e-01]
21Feb13_163104| [ 1.83510e+00 -1.21927e-01 -7.21994e-01 -3.87175e-01  1.44182e+00
21Feb13_163104|  -5.60339e-01 -1.69323e+00  3.84702e-01]
21Feb13_163104| [ 2.29647e+00  4.98135e-01 -5.82819e-01 -6.51931e-01 -5.00483e-01
21Feb13_163104|  -5.21971e-01  1.02927e+00  1.39999e-01]
21Feb13_163104| [-1.71433e+00  5.20461e-01  1.07786e-01  1.72497e-01  8.17631e-01
21Feb13_163104|  -1.23382e-01 -7.64470e-01  6.85373e-01]
21Feb13_163104| [ 5.32175e-02  1.59085e+00  2.07908e+00 -1.24494e+00  2.20682e+00
21Feb13_163104|  -1.25821e+00 -1.66929e+00  1.94038e+00]
21Feb13_163104| [ 3.73667e-01  1.74451e+00  1.26327e-01  1.39647e+00  1.05080e+00
21Feb13_163104|   2.43187e-01  2.53561e-02  2.31324e-01]
21Feb13_163104| [-1.12310e+00 -1.74495e+00  1.77094e+00 -4.73527e-01  8.36949e-01
21Feb13_163104|   7.71774e-01 -4.35311e-01  1.53145e+00]
21Feb13_163104| [ 2.13217e+00  1.37125e+00 -9.20890e-01  1.06924e+00 -1.32771e+00
21Feb13_163104|   7.09898e-01  1.11439e+00 -1.27760e+00]
21Feb13_163104| [-1.77403e-02 -4.28601e-01  1.65835e+00 -1.87197e-01  1.00957e+00
21Feb13_163104|   2.55297e-01  1.06387e-01  1.21832e+00]
21Feb13_163104| [ 2.16525e+00 -1.25784e-01 -5.41529e-01  1.97828e-01  2.28966e+00
21Feb13_163104|  -1.46028e+00  4.98379e-03 -4.40688e-01]
21Feb13_163104| [-7.39511e-02  2.47569e-01 -2.23324e-01 -2.69329e+00 -1.10672e+00
21Feb13_163104|   1.29711e+00 -1.02474e+00 -3.36463e-01]
21Feb13_163104| [ 7.56693e-01 -1.07233e-01 -6.28270e-01  9.12612e-01 -8.77877e-01
21Feb13_163104|  -9.20839e-01 -2.24401e-01 -1.13295e+00]
21Feb13_163104| [-9.56727e-01 -1.86328e+00 -1.69292e-01  1.09894e+00 -7.25733e-01
21Feb13_163104|   7.74090e-01  4.02577e-01 -6.00141e-01]
21Feb13_163104| [-1.51671e+00 -9.25981e-02 -3.63639e-01 -5.52293e-02  3.65719e-01
21Feb13_163104|  -2.63172e-01 -9.22686e-01 -1.59066e+00]
21Feb13_163104| [ 6.19485e-01  1.04762e+00  1.15913e-01  7.68427e-01  9.88362e-01
21Feb13_163104|   4.00572e-01  1.01580e+00 -1.00402e+00]
21Feb13_163104| [ 7.91163e-01 -1.28156e+00 -3.72928e-01  1.20917e+00  7.26087e-02
21Feb13_163104|   1.23038e+00 -7.97295e-01  7.15324e-01]
21Feb13_163104| [ 7.69403e-01 -2.23882e+00 -4.06537e-01 -8.30657e-01 -1.85295e+00
21Feb13_163104|  -3.96728e-01 -1.32753e-01  1.40371e+00]
21Feb13_163104| [ 8.63582e-01 -4.52795e-01  3.96789e-01  7.20922e-01  9.68883e-01
21Feb13_163104|   5.76722e-01 -8.25456e-02 -9.35541e-01]
21Feb13_163104| [-7.49275e-01 -9.06243e-01  1.18676e+00  5.39848e-01  1.41834e+00
21Feb13_163104|   4.33185e-01 -6.77846e-01 -6.19523e-01]
21Feb13_163104| [-8.91000e-01 -4.94536e-01  5.48779e-01  2.33437e+00  1.49354e+00
21Feb13_163104|  -5.62471e-01  7.67750e-01  5.34580e-01]
21Feb13_163104| [-2.22339e+00 -9.48349e-02  1.11523e-01 -1.88580e+00  1.55613e+00
21Feb13_163104|  -2.63893e+00  1.54688e+00  3.23628e-01]
21Feb13_163104| [-8.55111e-01  8.53349e-02 -7.83263e-01 -1.51315e+00  1.04588e+00
21Feb13_163104|  -1.91727e-02  1.95011e+00  3.79730e-01]
21Feb13_163104| [ 2.51049e+00 -5.71821e-01 -3.88096e-01 -5.52635e-01 -6.13567e-01
21Feb13_163104|  -1.58586e+00  1.50576e+00 -3.00998e-01]
21Feb13_163104| [ 1.93294e+00  3.34612e-01  1.64052e+00 -6.15246e-02  1.30100e+00
21Feb13_163104|   1.76044e+00 -3.04681e-01  1.12959e+00]
21Feb13_163104| [-1.54512e+00  8.03853e-01  7.85451e-01 -6.07936e-01  1.46778e+00
21Feb13_163104|  -2.14726e-01  3.85177e-01  8.03591e-01]
21Feb13_163104| [-7.43437e-01 -9.54122e-01  1.29250e-01  6.55511e-01  2.19896e-01
21Feb13_163104|  -3.25329e-01 -1.79744e+00  1.49641e+00]
21Feb13_163104| [-1.06592e-01  1.44267e+00 -9.93954e-01 -1.01275e+00 -1.80724e+00
21Feb13_163104|  -1.61250e+00  3.80720e-01  1.00622e+00]
21Feb13_163104| [-1.24952e+00 -9.83355e-01 -1.52174e+00 -6.88709e-02 -1.82968e+00
21Feb13_163104|  -1.70623e+00  5.64768e-01  1.84679e+00]
21Feb13_163104| [-2.16342e-01  9.31138e-01  4.23135e-01  6.51742e-01  1.10173e+00
21Feb13_163104|  -5.06868e-01  1.23298e+00 -4.11005e-01]
21Feb13_163104| [-6.95216e-01 -3.15809e-01 -2.07574e+00  1.38096e+00 -1.71834e+00
21Feb13_163104|  -1.00945e+00 -1.93909e+00 -1.90334e-01]
21Feb13_163104| [ 1.07621e+00  9.00909e-02 -1.16790e+00  6.47977e-01  4.48710e-01
21Feb13_163104|  -2.35271e+00  1.03246e+00  9.83788e-01]
21Feb13_163104| [-1.87550e+00 -1.35257e+00  7.95260e-01  1.64205e+00  6.37801e-01
21Feb13_163104|  -1.21482e+00 -1.45812e+00 -1.58185e-01]
21Feb13_163104| [ 4.31964e-01 -2.36822e-01  2.71119e-01 -1.28570e-01 -1.53996e+00
21Feb13_163104|   5.51374e-01  8.51521e-01 -1.87252e-03]
21Feb13_163104| [ 7.36059e-01  2.03168e+00 -2.68137e-01  1.70106e+00  8.03452e-01
21Feb13_163104|  -9.28072e-01  3.15312e+00  5.03465e-01]
21Feb13_163104| [ 1.80659e+00 -4.69960e-01  5.45626e-02  3.79517e-01 -9.48898e-01
21Feb13_163104|   3.17335e-01  4.23174e-02  1.25038e-01]
21Feb13_163104| [-1.36823e+00 -1.09100e+00  5.58333e-01 -1.75850e+00 -5.38353e-01
21Feb13_163104|   1.32464e+00 -1.44645e+00 -8.10629e-01]
21Feb13_163104| [ 1.34275e+00 -1.41251e+00 -4.78630e-01  1.46547e+00  5.64584e-01
21Feb13_163104|  -1.16980e+00 -2.78855e-01  9.98143e-01]
21Feb13_163104| [ 2.09905e+00  1.12670e-01 -2.75076e-02  3.01802e-01 -4.44158e-01
21Feb13_163104|   5.97231e-01 -4.45245e-01 -6.24110e-01]
21Feb13_163104| [ 1.47398e-01  4.79586e-01 -1.51079e-01 -1.26635e+00 -1.86360e+00
21Feb13_163104|   3.85638e-01 -2.26102e-01 -5.36332e-01]
21Feb13_163104| [ 2.39414e+00 -1.49220e+00  1.71112e+00 -3.26483e-02 -7.30602e-01
21Feb13_163104|  -7.71260e-01  1.35484e+00  1.46918e-01]
21Feb13_163104| [-8.79683e-01  2.04363e-01 -1.00453e+00  4.97801e-01  5.37708e-01
21Feb13_163104|   4.84817e-02  1.46449e-01  1.00633e+00]
21Feb13_163104| [ 9.87510e-01 -1.73494e+00 -3.97664e-01 -1.86384e+00 -1.37373e-01
21Feb13_163104|   9.58713e-01  7.88842e-01 -5.64893e-01]
21Feb13_163104| [ 1.23733e+00 -6.34561e-01  1.62916e-01  7.97154e-01  2.56756e-03
21Feb13_163104|  -5.26820e-01  1.12518e+00 -7.32085e-02]
21Feb13_163104| [ 9.60993e-02  2.80900e+00  1.96107e+00  2.67847e-01 -9.99283e-01
21Feb13_163104|  -4.52254e-01 -1.16903e+00  5.34274e-01]
21Feb13_163104| [ 1.46344e-01 -1.36033e-01  1.46780e+00  5.16901e-01 -2.00846e-01
21Feb13_163104|  -9.87830e-01  7.06146e-01  8.09746e-01]
21Feb13_163104| [ 1.55725e+00  7.75166e-01 -6.09187e-01  4.12681e-01  9.89784e-01
21Feb13_163104|  -3.28362e-01 -8.20779e-01 -1.15257e+00]
21Feb13_163104| [ 4.80557e-01  1.49401e-01 -8.28445e-01 -7.57686e-01 -1.21364e-01
21Feb13_163104|  -3.60461e-01 -1.25299e+00  1.96698e+00]
21Feb13_163104| [-4.30322e-01 -3.22697e+00 -4.46022e-01 -1.86729e+00  1.57431e+00
21Feb13_163104|   1.75365e-01  6.92210e-03 -6.13423e-01]
21Feb13_163104| [-1.34320e+00 -2.25301e+00  7.42062e-01 -6.16108e-01 -1.65630e-01
21Feb13_163104|  -4.69016e-01  1.84444e+00  3.27314e-01]
21Feb13_163104| [-5.16134e-02  2.23419e+00 -5.91959e-01  9.32150e-01 -1.06772e+00
21Feb13_163104|  -5.11523e-01  6.85844e-01 -1.03689e+00]
21Feb13_163104| [-1.30007e+00 -3.59148e-01  3.35093e-01  4.66641e-01  6.22570e-01
21Feb13_163104|  -1.71881e+00  7.41306e-01  1.11108e+00]
21Feb13_163104| [-2.00853e-01 -9.24747e-01 -2.19487e-01  6.18157e-01  6.43791e-01
21Feb13_163104|  -1.30594e+00  8.00212e-01  5.97219e-01]
21Feb13_163104| [-1.19358e+00 -5.99902e-01 -1.36178e+00  6.16698e-02 -1.07130e+00
21Feb13_163104|  -9.13657e-01 -5.31884e-01  5.48692e-01]
21Feb13_163104| [ 1.17813e+00 -8.97985e-01  1.95108e+00  2.09820e-01  2.84393e-03
21Feb13_163104|   1.23481e+00 -1.68539e-01  2.33940e-01]
21Feb13_163104| [-9.10662e-01  1.46989e+00 -1.08973e+00 -7.32452e-01 -2.41675e+00
21Feb13_163104|  -4.44959e-01  1.16536e+00 -9.01145e-01]
21Feb13_163104| [-8.82564e-01  7.05310e-01 -1.01819e+00 -2.26405e+00 -1.34282e+00
21Feb13_163104|   6.97505e-01  1.34754e+00 -2.32821e+00]
21Feb13_163104| [-4.48054e-01 -1.49619e+00  7.66455e-01  1.28585e-02  2.52223e-01
21Feb13_163104|  -1.68540e+00 -9.38609e-02 -2.02003e+00]]
21Feb13_163104|-- Bias --
21Feb13_163104|[ 1.17808e-03 -4.44270e-01  8.22591e-02  1.09959e+00 -3.08221e-01
21Feb13_163104|  1.75965e-01 -1.99442e-01 -1.41265e+00]
21Feb13_163104|Layer 1:
21Feb13_163104|-- Config --
21Feb13_163104|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 8], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163104|-- Weights --
21Feb13_163104|[[-0.98226  0.24821  1.19463]
21Feb13_163104| [ 0.22008  1.26392 -0.48812]
21Feb13_163104| [ 0.36979  0.18930  0.10872]
21Feb13_163104| [-0.31853  0.06591 -0.63823]
21Feb13_163104| [-1.04688  0.28658  0.05164]
21Feb13_163104| [-0.46144  0.29281  0.32274]
21Feb13_163104| [-1.38143  0.64735 -0.30380]
21Feb13_163104| [ 0.42874 -0.73215 -0.07617]]
21Feb13_163104|-- Bias --
21Feb13_163104|[ 0.11283 -0.91883 -0.02107]
21Feb13_163104|Layer 2:
21Feb13_163104|-- Config --
21Feb13_163104|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163104|-- Weights --
21Feb13_163104|[[-1.30873  0.76809  0.90757 -0.59244  0.54910 -0.47315]
21Feb13_163104| [-0.99187 -0.37179  0.74019 -0.16616  0.19931 -0.01629]
21Feb13_163104| [ 1.03741 -0.10805  0.70718 -0.07401 -0.40500 -0.37353]]
21Feb13_163104|-- Bias --
21Feb13_163104|[ 0.24190 -0.18750 -1.26833 -0.88541 -0.79598  0.36384]
21Feb13_163104|Layer 3:
21Feb13_163104|-- Config --
21Feb13_163104|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163104|-- Weights --
21Feb13_163104|[[-0.60635  0.23318]
21Feb13_163104| [-0.14250  0.55489]
21Feb13_163104| [-0.48538 -0.15199]
21Feb13_163104| [ 0.42067 -0.62737]
21Feb13_163104| [-0.99709  0.64501]
21Feb13_163104| [-0.25790  0.29907]]
21Feb13_163104|-- Bias --
21Feb13_163104|[-0.14887  1.00429]
21Feb13_163104|Predicting the validation and test data with the Best final individual.
21Feb13_163111| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_163111|-----------  ------------------  --------------------  ----------
21Feb13_163111|Validation         30.78                  51            0.38082
21Feb13_163111|   Test            31.54                  51            0.17775
21Feb13_163111|-------------------- Test #13 --------------------
21Feb13_163111|Best final individual weights
21Feb13_163111|Individual:
21Feb13_163111|-- Constant hidden layers --
21Feb13_163111|False
21Feb13_163111|Layer 0:
21Feb13_163111|-- Config --
21Feb13_163111|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 8, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163111|-- Weights --
21Feb13_163111|[[-7.96509e-01 -1.15059e+00 -6.26034e-01 -2.57608e-01 -1.16276e+00
21Feb13_163111|   2.17486e-01 -9.34321e-01  1.47903e-01]
21Feb13_163111| [ 1.83510e+00 -1.21927e-01 -7.21994e-01 -3.87175e-01  1.44182e+00
21Feb13_163111|  -5.60339e-01 -1.69323e+00  3.84702e-01]
21Feb13_163111| [ 2.29647e+00  4.98135e-01 -5.82819e-01 -6.51931e-01 -5.00483e-01
21Feb13_163111|  -5.21971e-01  1.02927e+00  1.39999e-01]
21Feb13_163111| [-1.71433e+00  5.20461e-01  1.07786e-01  1.72497e-01  8.17631e-01
21Feb13_163111|  -1.23382e-01 -7.64470e-01  6.85373e-01]
21Feb13_163111| [ 5.32175e-02  1.59085e+00  2.07908e+00 -1.24494e+00  2.20682e+00
21Feb13_163111|  -1.25821e+00 -1.66929e+00  1.94038e+00]
21Feb13_163111| [ 3.73667e-01  1.74451e+00  1.26327e-01  1.39647e+00  1.05080e+00
21Feb13_163111|   2.43187e-01  2.53561e-02  2.31324e-01]
21Feb13_163111| [-1.12310e+00 -1.74495e+00  1.77094e+00 -4.73527e-01  8.36949e-01
21Feb13_163111|   7.71774e-01 -4.35311e-01  1.53145e+00]
21Feb13_163111| [ 2.13217e+00  1.37125e+00 -9.20890e-01  1.06924e+00 -1.32771e+00
21Feb13_163111|   7.09898e-01  1.11439e+00 -1.27760e+00]
21Feb13_163111| [-1.77403e-02 -4.28601e-01  1.65835e+00 -1.87197e-01  1.00957e+00
21Feb13_163111|   2.55297e-01  1.06387e-01  1.21832e+00]
21Feb13_163111| [ 2.16525e+00 -1.25784e-01 -5.41529e-01  1.97828e-01  2.28966e+00
21Feb13_163111|  -1.46028e+00  4.98379e-03 -4.40688e-01]
21Feb13_163111| [-7.39511e-02  2.47569e-01 -2.23324e-01 -2.69329e+00 -1.10672e+00
21Feb13_163111|   1.29711e+00 -1.02474e+00 -3.36463e-01]
21Feb13_163111| [ 7.56693e-01 -1.07233e-01 -6.28270e-01  9.12612e-01 -8.77877e-01
21Feb13_163111|  -9.20839e-01 -2.24401e-01 -1.13295e+00]
21Feb13_163111| [-9.56727e-01 -1.86328e+00 -1.69292e-01  1.09894e+00 -7.25733e-01
21Feb13_163111|   7.74090e-01  4.02577e-01 -6.00141e-01]
21Feb13_163111| [-1.51671e+00 -9.25981e-02 -3.63639e-01 -5.52293e-02  3.65719e-01
21Feb13_163111|  -2.63172e-01 -9.22686e-01 -1.59066e+00]
21Feb13_163111| [ 6.19485e-01  1.04762e+00  1.15913e-01  7.68427e-01  9.88362e-01
21Feb13_163111|   4.00572e-01  1.01580e+00 -1.00402e+00]
21Feb13_163111| [ 7.91163e-01 -1.28156e+00 -3.72928e-01  1.20917e+00  7.26087e-02
21Feb13_163111|   1.23038e+00 -7.97295e-01  7.15324e-01]
21Feb13_163111| [ 7.69403e-01 -2.23882e+00 -4.06537e-01 -8.30657e-01 -1.85295e+00
21Feb13_163111|  -3.96728e-01 -1.32753e-01  1.40371e+00]
21Feb13_163111| [ 8.63582e-01 -4.52795e-01  3.96789e-01  7.20922e-01  9.68883e-01
21Feb13_163111|   5.76722e-01 -8.25456e-02 -9.35541e-01]
21Feb13_163111| [-7.49275e-01 -9.06243e-01  1.18676e+00  5.39848e-01  1.41834e+00
21Feb13_163111|   4.33185e-01 -6.77846e-01 -6.19523e-01]
21Feb13_163111| [-8.91000e-01 -4.94536e-01  5.48779e-01  2.33437e+00  1.49354e+00
21Feb13_163111|  -5.62471e-01  7.67750e-01  5.34580e-01]
21Feb13_163111| [-2.22339e+00 -9.48349e-02  1.11523e-01 -1.88580e+00  1.55613e+00
21Feb13_163111|  -2.63893e+00  1.54688e+00  3.23628e-01]
21Feb13_163111| [-8.55111e-01  8.53349e-02 -7.83263e-01 -1.51315e+00  1.04588e+00
21Feb13_163111|  -1.91727e-02  1.95011e+00  3.79730e-01]
21Feb13_163111| [ 2.51049e+00 -5.71821e-01 -3.88096e-01 -5.52635e-01 -6.13567e-01
21Feb13_163111|  -1.58586e+00  1.50576e+00 -3.00998e-01]
21Feb13_163111| [ 1.93294e+00  3.34612e-01  1.64052e+00 -6.15246e-02  1.30100e+00
21Feb13_163111|   1.76044e+00 -3.04681e-01  1.12959e+00]
21Feb13_163111| [-1.54512e+00  8.03853e-01  7.85451e-01 -6.07936e-01  1.46778e+00
21Feb13_163111|  -2.14726e-01  3.85177e-01  8.03591e-01]
21Feb13_163111| [-7.43437e-01 -9.54122e-01  1.29250e-01  6.55511e-01  2.19896e-01
21Feb13_163111|  -3.25329e-01 -1.79744e+00  1.49641e+00]
21Feb13_163111| [-1.06592e-01  1.44267e+00 -9.93954e-01 -1.01275e+00 -1.80724e+00
21Feb13_163111|  -1.61250e+00  3.80720e-01  1.00622e+00]
21Feb13_163111| [-1.24952e+00 -9.83355e-01 -1.52174e+00 -6.88709e-02 -1.82968e+00
21Feb13_163111|  -1.70623e+00  5.64768e-01  1.84679e+00]
21Feb13_163111| [-2.16342e-01  9.31138e-01  4.23135e-01  6.51742e-01  1.10173e+00
21Feb13_163111|  -5.06868e-01  1.23298e+00 -4.11005e-01]
21Feb13_163111| [-6.95216e-01 -3.15809e-01 -2.07574e+00  1.38096e+00 -1.71834e+00
21Feb13_163111|  -1.00945e+00 -1.93909e+00 -1.90334e-01]
21Feb13_163111| [ 1.07621e+00  9.00909e-02 -1.16790e+00  6.47977e-01  4.48710e-01
21Feb13_163111|  -2.35271e+00  1.03246e+00  9.83788e-01]
21Feb13_163111| [-1.87550e+00 -1.35257e+00  7.95260e-01  1.64205e+00  6.37801e-01
21Feb13_163111|  -1.21482e+00 -1.45812e+00 -1.58185e-01]
21Feb13_163111| [ 4.31964e-01 -2.36822e-01  2.71119e-01 -1.28570e-01 -1.53996e+00
21Feb13_163111|   5.51374e-01  8.51521e-01 -1.87252e-03]
21Feb13_163111| [ 7.36059e-01  2.03168e+00 -2.68137e-01  1.70106e+00  8.03452e-01
21Feb13_163111|  -9.28072e-01  3.15312e+00  5.03465e-01]
21Feb13_163111| [ 1.80659e+00 -4.69960e-01  5.45626e-02  3.79517e-01 -9.48898e-01
21Feb13_163111|   3.17335e-01  4.23174e-02  1.25038e-01]
21Feb13_163111| [-1.36823e+00 -1.09100e+00  5.58333e-01 -1.75850e+00 -5.38353e-01
21Feb13_163111|   1.32464e+00 -1.44645e+00 -8.10629e-01]
21Feb13_163111| [ 1.34275e+00 -1.41251e+00 -4.78630e-01  1.46547e+00  5.64584e-01
21Feb13_163111|  -1.16980e+00 -2.78855e-01  9.98143e-01]
21Feb13_163111| [ 2.09905e+00  1.12670e-01 -2.75076e-02  3.01802e-01 -4.44158e-01
21Feb13_163111|   5.97231e-01 -4.45245e-01 -6.24110e-01]
21Feb13_163111| [ 1.47398e-01  4.79586e-01 -1.51079e-01 -1.26635e+00 -1.86360e+00
21Feb13_163111|   3.85638e-01 -2.26102e-01 -5.36332e-01]
21Feb13_163111| [ 2.39414e+00 -1.49220e+00  1.71112e+00 -3.26483e-02 -7.30602e-01
21Feb13_163111|  -7.71260e-01  1.35484e+00  1.46918e-01]
21Feb13_163111| [-8.79683e-01  2.04363e-01 -1.00453e+00  4.97801e-01  5.37708e-01
21Feb13_163111|   4.84817e-02  1.46449e-01  1.00633e+00]
21Feb13_163111| [ 9.87510e-01 -1.73494e+00 -3.97664e-01 -1.86384e+00 -1.37373e-01
21Feb13_163111|   9.58713e-01  7.88842e-01 -5.64893e-01]
21Feb13_163111| [ 1.23733e+00 -6.34561e-01  1.62916e-01  7.97154e-01  2.56756e-03
21Feb13_163111|  -5.26820e-01  1.12518e+00 -7.32085e-02]
21Feb13_163111| [ 9.60993e-02  2.80900e+00  1.96107e+00  2.67847e-01 -9.99283e-01
21Feb13_163111|  -4.52254e-01 -1.16903e+00  5.34274e-01]
21Feb13_163111| [ 1.46344e-01 -1.36033e-01  1.46780e+00  5.16901e-01 -2.00846e-01
21Feb13_163111|  -9.87830e-01  7.06146e-01  8.09746e-01]
21Feb13_163111| [ 1.55725e+00  7.75166e-01 -6.09187e-01  4.12681e-01  9.89784e-01
21Feb13_163111|  -3.28362e-01 -8.20779e-01 -1.15257e+00]
21Feb13_163111| [ 4.80557e-01  1.49401e-01 -8.28445e-01 -7.57686e-01 -1.21364e-01
21Feb13_163111|  -3.60461e-01 -1.25299e+00  1.96698e+00]
21Feb13_163111| [-4.30322e-01 -3.22697e+00 -4.46022e-01 -1.86729e+00  1.57431e+00
21Feb13_163111|   1.75365e-01  6.92210e-03 -6.13423e-01]
21Feb13_163111| [-1.34320e+00 -2.25301e+00  7.42062e-01 -6.16108e-01 -1.65630e-01
21Feb13_163111|  -4.69016e-01  1.84444e+00  3.27314e-01]
21Feb13_163111| [-5.16134e-02  2.23419e+00 -5.91959e-01  9.32150e-01 -1.06772e+00
21Feb13_163111|  -5.11523e-01  6.85844e-01 -1.03689e+00]
21Feb13_163111| [-1.30007e+00 -3.59148e-01  3.35093e-01  4.66641e-01  6.22570e-01
21Feb13_163111|  -1.71881e+00  7.41306e-01  1.11108e+00]
21Feb13_163111| [-2.00853e-01 -9.24747e-01 -2.19487e-01  6.18157e-01  6.43791e-01
21Feb13_163111|  -1.30594e+00  8.00212e-01  5.97219e-01]
21Feb13_163111| [-1.19358e+00 -5.99902e-01 -1.36178e+00  6.16698e-02 -1.07130e+00
21Feb13_163111|  -9.13657e-01 -5.31884e-01  5.48692e-01]
21Feb13_163111| [ 1.17813e+00 -8.97985e-01  1.95108e+00  2.09820e-01  2.84393e-03
21Feb13_163111|   1.23481e+00 -1.68539e-01  2.33940e-01]
21Feb13_163111| [-9.10662e-01  1.46989e+00 -1.08973e+00 -7.32452e-01 -2.41675e+00
21Feb13_163111|  -4.44959e-01  1.16536e+00 -9.01145e-01]
21Feb13_163111| [-8.82564e-01  7.05310e-01 -1.01819e+00 -2.26405e+00 -1.34282e+00
21Feb13_163111|   6.97505e-01  1.34754e+00 -2.32821e+00]
21Feb13_163111| [-4.48054e-01 -1.49619e+00  7.66455e-01  1.28585e-02  2.52223e-01
21Feb13_163111|  -1.68540e+00 -9.38609e-02 -2.02003e+00]]
21Feb13_163111|-- Bias --
21Feb13_163111|[ 1.17808e-03 -4.44270e-01  8.22591e-02  1.09959e+00 -3.08221e-01
21Feb13_163111|  1.75965e-01 -1.99442e-01 -1.41265e+00]
21Feb13_163111|Layer 1:
21Feb13_163111|-- Config --
21Feb13_163111|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 8], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163111|-- Weights --
21Feb13_163111|[[-0.98226  0.24821  1.19463]
21Feb13_163111| [ 0.22008  1.26392 -0.48812]
21Feb13_163111| [ 0.36979  0.18930  0.10872]
21Feb13_163111| [-0.31853  0.06591 -0.63823]
21Feb13_163111| [-1.04688  0.28658  0.05164]
21Feb13_163111| [-0.46144  0.29281  0.32274]
21Feb13_163111| [-1.38143  0.64735 -0.30380]
21Feb13_163111| [ 0.42874 -0.73215 -0.07617]]
21Feb13_163111|-- Bias --
21Feb13_163111|[ 0.11283 -0.91883 -0.02107]
21Feb13_163111|Layer 2:
21Feb13_163111|-- Config --
21Feb13_163111|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163111|-- Weights --
21Feb13_163111|[[-1.30873  0.76809  0.90757 -0.59244  0.54910 -0.47315]
21Feb13_163111| [-0.99187 -0.37179  0.74019 -0.16616  0.19931 -0.01629]
21Feb13_163111| [ 1.03741 -0.10805  0.70718 -0.07401 -0.40500 -0.37353]]
21Feb13_163111|-- Bias --
21Feb13_163111|[ 0.24190 -0.18750 -1.26833 -0.88541 -0.79598  0.36384]
21Feb13_163111|Layer 3:
21Feb13_163111|-- Config --
21Feb13_163111|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163111|-- Weights --
21Feb13_163111|[[-0.60635  0.23318]
21Feb13_163111| [-0.14250  0.55489]
21Feb13_163111| [-0.48538 -0.15199]
21Feb13_163111| [ 0.42067 -0.62737]
21Feb13_163111| [-0.99709  0.64501]
21Feb13_163111| [-0.25790  0.29907]]
21Feb13_163111|-- Bias --
21Feb13_163111|[-0.14887  1.00429]
21Feb13_163111|Predicting the validation and test data with the Best final individual.
21Feb13_163119| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_163119|-----------  ------------------  --------------------  ----------
21Feb13_163119|Validation         33.22                  51            0.29398
21Feb13_163119|   Test            26.50                  51            0.39601
21Feb13_163119|-------------------- Test #14 --------------------
21Feb13_163119|Best final individual weights
21Feb13_163119|Individual:
21Feb13_163119|-- Constant hidden layers --
21Feb13_163119|False
21Feb13_163119|Layer 0:
21Feb13_163119|-- Config --
21Feb13_163119|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 8, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163119|-- Weights --
21Feb13_163119|[[-7.96509e-01 -1.15059e+00 -6.26034e-01 -2.57608e-01 -1.16276e+00
21Feb13_163119|   2.17486e-01 -9.34321e-01  1.47903e-01]
21Feb13_163119| [ 1.83510e+00 -1.21927e-01 -7.21994e-01 -3.87175e-01  1.44182e+00
21Feb13_163119|  -5.60339e-01 -1.69323e+00  3.84702e-01]
21Feb13_163119| [ 2.29647e+00  4.98135e-01 -5.82819e-01 -6.51931e-01 -5.00483e-01
21Feb13_163119|  -5.21971e-01  1.02927e+00  1.39999e-01]
21Feb13_163119| [-1.71433e+00  5.20461e-01  1.07786e-01  1.72497e-01  8.17631e-01
21Feb13_163119|  -1.23382e-01 -7.64470e-01  6.85373e-01]
21Feb13_163119| [ 5.32175e-02  1.59085e+00  2.07908e+00 -1.24494e+00  2.20682e+00
21Feb13_163119|  -1.25821e+00 -1.66929e+00  1.94038e+00]
21Feb13_163119| [ 3.73667e-01  1.74451e+00  1.26327e-01  1.39647e+00  1.05080e+00
21Feb13_163119|   2.43187e-01  2.53561e-02  2.31324e-01]
21Feb13_163119| [-1.12310e+00 -1.74495e+00  1.77094e+00 -4.73527e-01  8.36949e-01
21Feb13_163119|   7.71774e-01 -4.35311e-01  1.53145e+00]
21Feb13_163119| [ 2.13217e+00  1.37125e+00 -9.20890e-01  1.06924e+00 -1.32771e+00
21Feb13_163119|   7.09898e-01  1.11439e+00 -1.27760e+00]
21Feb13_163119| [-1.77403e-02 -4.28601e-01  1.65835e+00 -1.87197e-01  1.00957e+00
21Feb13_163119|   2.55297e-01  1.06387e-01  1.21832e+00]
21Feb13_163119| [ 2.16525e+00 -1.25784e-01 -5.41529e-01  1.97828e-01  2.28966e+00
21Feb13_163119|  -1.46028e+00  4.98379e-03 -4.40688e-01]
21Feb13_163119| [-7.39511e-02  2.47569e-01 -2.23324e-01 -2.69329e+00 -1.10672e+00
21Feb13_163119|   1.29711e+00 -1.02474e+00 -3.36463e-01]
21Feb13_163119| [ 7.56693e-01 -1.07233e-01 -6.28270e-01  9.12612e-01 -8.77877e-01
21Feb13_163119|  -9.20839e-01 -2.24401e-01 -1.13295e+00]
21Feb13_163119| [-9.56727e-01 -1.86328e+00 -1.69292e-01  1.09894e+00 -7.25733e-01
21Feb13_163119|   7.74090e-01  4.02577e-01 -6.00141e-01]
21Feb13_163119| [-1.51671e+00 -9.25981e-02 -3.63639e-01 -5.52293e-02  3.65719e-01
21Feb13_163119|  -2.63172e-01 -9.22686e-01 -1.59066e+00]
21Feb13_163119| [ 6.19485e-01  1.04762e+00  1.15913e-01  7.68427e-01  9.88362e-01
21Feb13_163119|   4.00572e-01  1.01580e+00 -1.00402e+00]
21Feb13_163119| [ 7.91163e-01 -1.28156e+00 -3.72928e-01  1.20917e+00  7.26087e-02
21Feb13_163119|   1.23038e+00 -7.97295e-01  7.15324e-01]
21Feb13_163119| [ 7.69403e-01 -2.23882e+00 -4.06537e-01 -8.30657e-01 -1.85295e+00
21Feb13_163119|  -3.96728e-01 -1.32753e-01  1.40371e+00]
21Feb13_163119| [ 8.63582e-01 -4.52795e-01  3.96789e-01  7.20922e-01  9.68883e-01
21Feb13_163119|   5.76722e-01 -8.25456e-02 -9.35541e-01]
21Feb13_163119| [-7.49275e-01 -9.06243e-01  1.18676e+00  5.39848e-01  1.41834e+00
21Feb13_163119|   4.33185e-01 -6.77846e-01 -6.19523e-01]
21Feb13_163119| [-8.91000e-01 -4.94536e-01  5.48779e-01  2.33437e+00  1.49354e+00
21Feb13_163119|  -5.62471e-01  7.67750e-01  5.34580e-01]
21Feb13_163119| [-2.22339e+00 -9.48349e-02  1.11523e-01 -1.88580e+00  1.55613e+00
21Feb13_163119|  -2.63893e+00  1.54688e+00  3.23628e-01]
21Feb13_163119| [-8.55111e-01  8.53349e-02 -7.83263e-01 -1.51315e+00  1.04588e+00
21Feb13_163119|  -1.91727e-02  1.95011e+00  3.79730e-01]
21Feb13_163119| [ 2.51049e+00 -5.71821e-01 -3.88096e-01 -5.52635e-01 -6.13567e-01
21Feb13_163119|  -1.58586e+00  1.50576e+00 -3.00998e-01]
21Feb13_163119| [ 1.93294e+00  3.34612e-01  1.64052e+00 -6.15246e-02  1.30100e+00
21Feb13_163119|   1.76044e+00 -3.04681e-01  1.12959e+00]
21Feb13_163119| [-1.54512e+00  8.03853e-01  7.85451e-01 -6.07936e-01  1.46778e+00
21Feb13_163119|  -2.14726e-01  3.85177e-01  8.03591e-01]
21Feb13_163119| [-7.43437e-01 -9.54122e-01  1.29250e-01  6.55511e-01  2.19896e-01
21Feb13_163119|  -3.25329e-01 -1.79744e+00  1.49641e+00]
21Feb13_163119| [-1.06592e-01  1.44267e+00 -9.93954e-01 -1.01275e+00 -1.80724e+00
21Feb13_163119|  -1.61250e+00  3.80720e-01  1.00622e+00]
21Feb13_163119| [-1.24952e+00 -9.83355e-01 -1.52174e+00 -6.88709e-02 -1.82968e+00
21Feb13_163119|  -1.70623e+00  5.64768e-01  1.84679e+00]
21Feb13_163119| [-2.16342e-01  9.31138e-01  4.23135e-01  6.51742e-01  1.10173e+00
21Feb13_163119|  -5.06868e-01  1.23298e+00 -4.11005e-01]
21Feb13_163119| [-6.95216e-01 -3.15809e-01 -2.07574e+00  1.38096e+00 -1.71834e+00
21Feb13_163119|  -1.00945e+00 -1.93909e+00 -1.90334e-01]
21Feb13_163119| [ 1.07621e+00  9.00909e-02 -1.16790e+00  6.47977e-01  4.48710e-01
21Feb13_163119|  -2.35271e+00  1.03246e+00  9.83788e-01]
21Feb13_163119| [-1.87550e+00 -1.35257e+00  7.95260e-01  1.64205e+00  6.37801e-01
21Feb13_163119|  -1.21482e+00 -1.45812e+00 -1.58185e-01]
21Feb13_163119| [ 4.31964e-01 -2.36822e-01  2.71119e-01 -1.28570e-01 -1.53996e+00
21Feb13_163119|   5.51374e-01  8.51521e-01 -1.87252e-03]
21Feb13_163119| [ 7.36059e-01  2.03168e+00 -2.68137e-01  1.70106e+00  8.03452e-01
21Feb13_163119|  -9.28072e-01  3.15312e+00  5.03465e-01]
21Feb13_163119| [ 1.80659e+00 -4.69960e-01  5.45626e-02  3.79517e-01 -9.48898e-01
21Feb13_163119|   3.17335e-01  4.23174e-02  1.25038e-01]
21Feb13_163119| [-1.36823e+00 -1.09100e+00  5.58333e-01 -1.75850e+00 -5.38353e-01
21Feb13_163119|   1.32464e+00 -1.44645e+00 -8.10629e-01]
21Feb13_163119| [ 1.34275e+00 -1.41251e+00 -4.78630e-01  1.46547e+00  5.64584e-01
21Feb13_163119|  -1.16980e+00 -2.78855e-01  9.98143e-01]
21Feb13_163119| [ 2.09905e+00  1.12670e-01 -2.75076e-02  3.01802e-01 -4.44158e-01
21Feb13_163119|   5.97231e-01 -4.45245e-01 -6.24110e-01]
21Feb13_163119| [ 1.47398e-01  4.79586e-01 -1.51079e-01 -1.26635e+00 -1.86360e+00
21Feb13_163119|   3.85638e-01 -2.26102e-01 -5.36332e-01]
21Feb13_163119| [ 2.39414e+00 -1.49220e+00  1.71112e+00 -3.26483e-02 -7.30602e-01
21Feb13_163119|  -7.71260e-01  1.35484e+00  1.46918e-01]
21Feb13_163119| [-8.79683e-01  2.04363e-01 -1.00453e+00  4.97801e-01  5.37708e-01
21Feb13_163119|   4.84817e-02  1.46449e-01  1.00633e+00]
21Feb13_163119| [ 9.87510e-01 -1.73494e+00 -3.97664e-01 -1.86384e+00 -1.37373e-01
21Feb13_163119|   9.58713e-01  7.88842e-01 -5.64893e-01]
21Feb13_163119| [ 1.23733e+00 -6.34561e-01  1.62916e-01  7.97154e-01  2.56756e-03
21Feb13_163119|  -5.26820e-01  1.12518e+00 -7.32085e-02]
21Feb13_163119| [ 9.60993e-02  2.80900e+00  1.96107e+00  2.67847e-01 -9.99283e-01
21Feb13_163119|  -4.52254e-01 -1.16903e+00  5.34274e-01]
21Feb13_163119| [ 1.46344e-01 -1.36033e-01  1.46780e+00  5.16901e-01 -2.00846e-01
21Feb13_163119|  -9.87830e-01  7.06146e-01  8.09746e-01]
21Feb13_163119| [ 1.55725e+00  7.75166e-01 -6.09187e-01  4.12681e-01  9.89784e-01
21Feb13_163119|  -3.28362e-01 -8.20779e-01 -1.15257e+00]
21Feb13_163119| [ 4.80557e-01  1.49401e-01 -8.28445e-01 -7.57686e-01 -1.21364e-01
21Feb13_163119|  -3.60461e-01 -1.25299e+00  1.96698e+00]
21Feb13_163119| [-4.30322e-01 -3.22697e+00 -4.46022e-01 -1.86729e+00  1.57431e+00
21Feb13_163119|   1.75365e-01  6.92210e-03 -6.13423e-01]
21Feb13_163119| [-1.34320e+00 -2.25301e+00  7.42062e-01 -6.16108e-01 -1.65630e-01
21Feb13_163119|  -4.69016e-01  1.84444e+00  3.27314e-01]
21Feb13_163119| [-5.16134e-02  2.23419e+00 -5.91959e-01  9.32150e-01 -1.06772e+00
21Feb13_163119|  -5.11523e-01  6.85844e-01 -1.03689e+00]
21Feb13_163119| [-1.30007e+00 -3.59148e-01  3.35093e-01  4.66641e-01  6.22570e-01
21Feb13_163119|  -1.71881e+00  7.41306e-01  1.11108e+00]
21Feb13_163119| [-2.00853e-01 -9.24747e-01 -2.19487e-01  6.18157e-01  6.43791e-01
21Feb13_163119|  -1.30594e+00  8.00212e-01  5.97219e-01]
21Feb13_163119| [-1.19358e+00 -5.99902e-01 -1.36178e+00  6.16698e-02 -1.07130e+00
21Feb13_163119|  -9.13657e-01 -5.31884e-01  5.48692e-01]
21Feb13_163119| [ 1.17813e+00 -8.97985e-01  1.95108e+00  2.09820e-01  2.84393e-03
21Feb13_163119|   1.23481e+00 -1.68539e-01  2.33940e-01]
21Feb13_163119| [-9.10662e-01  1.46989e+00 -1.08973e+00 -7.32452e-01 -2.41675e+00
21Feb13_163119|  -4.44959e-01  1.16536e+00 -9.01145e-01]
21Feb13_163119| [-8.82564e-01  7.05310e-01 -1.01819e+00 -2.26405e+00 -1.34282e+00
21Feb13_163119|   6.97505e-01  1.34754e+00 -2.32821e+00]
21Feb13_163119| [-4.48054e-01 -1.49619e+00  7.66455e-01  1.28585e-02  2.52223e-01
21Feb13_163119|  -1.68540e+00 -9.38609e-02 -2.02003e+00]]
21Feb13_163119|-- Bias --
21Feb13_163119|[ 1.17808e-03 -4.44270e-01  8.22591e-02  1.09959e+00 -3.08221e-01
21Feb13_163119|  1.75965e-01 -1.99442e-01 -1.41265e+00]
21Feb13_163119|Layer 1:
21Feb13_163119|-- Config --
21Feb13_163119|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 8], 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163119|-- Weights --
21Feb13_163119|[[-0.98226  0.24821  1.19463]
21Feb13_163119| [ 0.22008  1.26392 -0.48812]
21Feb13_163119| [ 0.36979  0.18930  0.10872]
21Feb13_163119| [-0.31853  0.06591 -0.63823]
21Feb13_163119| [-1.04688  0.28658  0.05164]
21Feb13_163119| [-0.46144  0.29281  0.32274]
21Feb13_163119| [-1.38143  0.64735 -0.30380]
21Feb13_163119| [ 0.42874 -0.73215 -0.07617]]
21Feb13_163119|-- Bias --
21Feb13_163119|[ 0.11283 -0.91883 -0.02107]
21Feb13_163119|Layer 2:
21Feb13_163119|-- Config --
21Feb13_163119|{'name': 'Hidden3', 'trainable': True, 'batch_input_shape': [None, 3], 'dtype': 'float32', 'units': 6, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163119|-- Weights --
21Feb13_163119|[[-1.30873  0.76809  0.90757 -0.59244  0.54910 -0.47315]
21Feb13_163119| [-0.99187 -0.37179  0.74019 -0.16616  0.19931 -0.01629]
21Feb13_163119| [ 1.03741 -0.10805  0.70718 -0.07401 -0.40500 -0.37353]]
21Feb13_163119|-- Bias --
21Feb13_163119|[ 0.24190 -0.18750 -1.26833 -0.88541 -0.79598  0.36384]
21Feb13_163119|Layer 3:
21Feb13_163119|-- Config --
21Feb13_163119|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 6], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_163119|-- Weights --
21Feb13_163119|[[-0.60635  0.23318]
21Feb13_163119| [-0.14250  0.55489]
21Feb13_163119| [-0.48538 -0.15199]
21Feb13_163119| [ 0.42067 -0.62737]
21Feb13_163119| [-0.99709  0.64501]
21Feb13_163119| [-0.25790  0.29907]]
21Feb13_163119|-- Bias --
21Feb13_163119|[-0.14887  1.00429]
21Feb13_163119|Predicting the validation and test data with the Best final individual.
21Feb13_163127| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_163127|-----------  ------------------  --------------------  ----------
21Feb13_163127|Validation         42.00                  51            0.00000
21Feb13_163127|   Test            25.72                  51            0.46621
2021-02-13 16:31:28.122144: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
21Feb13_163128|Data summary: Train
21Feb13_163128|data.shape = (2300, 57)
21Feb13_163128|labels.shape = (2300,)
21Feb13_163128|Class distribution:
21Feb13_163128|	0 - 1389 (0.60)
21Feb13_163128|	1 - 911 (0.40)
21Feb13_163128|Data summary: Validation
21Feb13_163128|data.shape = (1150, 57)
21Feb13_163128|labels.shape = (1150,)
21Feb13_163128|Class distribution:
21Feb13_163128|	0 - 667 (0.58)
21Feb13_163128|	1 - 483 (0.42)
21Feb13_163128|Data summary: Test
21Feb13_163128|data.shape = (1151, 57)
21Feb13_163128|labels.shape = (1151,)
21Feb13_163128|Class distribution:
21Feb13_163128|	0 - 732 (0.64)
21Feb13_163128|	1 - 419 (0.36)
21Feb13_163128|Selected configuration values
21Feb13_163128|-- Dataset name: spambase2
21Feb13_163128|-- Initial population size: 64
21Feb13_163128|-- Maximun number of generations: 32
21Feb13_163128|-- Neurons per hidden layer range: (2, 20)
21Feb13_163128|-- Hidden layers number range: (1, 3)
21Feb13_163128|-- Crossover probability: 0.5
21Feb13_163128|-- Bias gene mutation probability: 0.2
21Feb13_163128|-- Weights gene mutation probability: 0.75
21Feb13_163128|-- Neuron mutation probability: 0.3
21Feb13_163128|-- Layer mutation probability: 0.3
21Feb13_163128|-- Constant hidden layers: False
21Feb13_163128|-- Seed: 31415
21Feb13_163128|Entering GA
21Feb13_163128|Start the algorithm
2021-02-13 16:31:28.970658: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-13 16:31:28.971208: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-02-13 16:31:28.995106: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-02-13 16:31:28.995424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.71GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s
2021-02-13 16:31:28.995439: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-02-13 16:31:28.996904: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-02-13 16:31:28.996933: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-02-13 16:31:28.997451: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-02-13 16:31:28.997584: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-02-13 16:31:28.997656: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-13 16:31:28.998077: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-02-13 16:31:28.998119: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmerelo/Code/torch/install/lib:/home/jmerelo/Code/torch/install/lib:
2021-02-13 16:31:28.998125: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-02-13 16:31:28.998325: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-02-13 16:31:28.999178: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-02-13 16:31:28.999193: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-13 16:31:28.999196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      
2021-02-13 16:31:29.044396: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-02-13 16:31:29.044736: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3493635000 Hz
/home/jmerelo/.pyenv/versions/3.8.6/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype("int32")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn('`model.predict_classes()` is deprecated and '
21Feb13_163532|-- Generation 1 --
21Feb13_163532|    -- Crossed 0 individual pairs.
21Feb13_163532|    -- Mutated 32 individuals.
21Feb13_163928|    -- Evaluated 64 individuals.
21Feb13_163928|    Summary of generation 1:
21Feb13_163928| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_163928|-----------  ------------------  --------------------  ----------
21Feb13_163928|    Max            42.35                111.00          0.00517
21Feb13_163928|    Avg            42.01                32.05           0.00093
21Feb13_163928|    Min            41.83                 2.00           0.00000
21Feb13_163928|    Std             0.08                28.43           0.00161
21Feb13_163928|   Best            41.83                 9.00           0.00517
21Feb13_163928|-- Generation 2 --
21Feb13_163928|    -- Crossed 2 individual pairs.
21Feb13_163928|    -- Mutated 32 individuals.
21Feb13_164321|    -- Evaluated 64 individuals.
21Feb13_164321|    Summary of generation 2:
21Feb13_164321| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_164321|-----------  ------------------  --------------------  ----------
21Feb13_164321|    Max            42.61                66.00           0.02575
21Feb13_164321|    Avg            42.00                17.84           0.00206
21Feb13_164321|    Min            41.13                 2.00           0.00000
21Feb13_164321|    Std             0.18                15.43           0.00382
21Feb13_164321|   Best            41.13                 9.00           0.02575
21Feb13_164321|-- Generation 3 --
21Feb13_164321|    -- Crossed 4 individual pairs.
21Feb13_164321|    -- Mutated 32 individuals.
21Feb13_164710|    -- Evaluated 64 individuals.
21Feb13_164710|    Summary of generation 3:
21Feb13_164710| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_164710|-----------  ------------------  --------------------  ----------
21Feb13_164710|    Max            42.87                66.00           0.80758
21Feb13_164710|    Avg            41.98                10.81           0.01496
21Feb13_164710|    Min            41.39                 2.00           0.00000
21Feb13_164710|    Std             0.19                10.06           0.09996
21Feb13_164710|   Best            41.39                16.00           0.01805
21Feb13_164710|-- Generation 4 --
21Feb13_164711|    -- Crossed 3 individual pairs.
21Feb13_164711|    -- Mutated 32 individuals.
21Feb13_165101|    -- Evaluated 64 individuals.
21Feb13_165101|    Summary of generation 4:
21Feb13_165101| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_165101|-----------  ------------------  --------------------  ----------
21Feb13_165101|    Max            42.35                69.00           0.02061
21Feb13_165101|    Avg            41.97                12.44           0.00222
21Feb13_165101|    Min            41.39                 2.00           0.00000
21Feb13_165101|    Std             0.14                13.25           0.00427
21Feb13_165101|   Best            41.39                16.00           0.02061
21Feb13_165101|-- Generation 5 --
21Feb13_165101|    -- Crossed 0 individual pairs.
21Feb13_165101|    -- Mutated 32 individuals.
21Feb13_165451|    -- Evaluated 64 individuals.
21Feb13_165451|    Summary of generation 5:
21Feb13_165451| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_165451|-----------  ------------------  --------------------  ----------
21Feb13_165451|    Max            42.17                69.00           0.01804
21Feb13_165451|    Avg            41.96                12.16           0.00210
21Feb13_165451|    Min            41.48                 2.00           0.00000
21Feb13_165451|    Std             0.11                15.52           0.00410
21Feb13_165451|   Best            41.48                 6.00           0.01804
21Feb13_165451|-- Generation 6 --
21Feb13_165451|    -- Crossed 3 individual pairs.
21Feb13_165451|    -- Mutated 32 individuals.
21Feb13_165841|    -- Evaluated 64 individuals.
21Feb13_165841|    Summary of generation 6:
21Feb13_165841| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_165841|-----------  ------------------  --------------------  ----------
21Feb13_165841|    Max            42.26                40.00           0.82795
21Feb13_165841|    Avg            41.68                 9.70           0.02154
21Feb13_165841|    Min            29.91                 2.00           0.00000
21Feb13_165841|    Std             1.67                 7.52           0.11337
21Feb13_165841|   Best            29.91                28.00           0.40635
21Feb13_165841|-- Generation 7 --
21Feb13_165841|    -- Crossed 5 individual pairs.
21Feb13_165841|    -- Mutated 32 individuals.
21Feb13_170230|    -- Evaluated 64 individuals.
21Feb13_170230|    Summary of generation 7:
21Feb13_170230| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_170230|-----------  ------------------  --------------------  ----------
21Feb13_170230|    Max            42.17                57.00           0.01803
21Feb13_170230|    Avg            41.96                11.20           0.00178
21Feb13_170230|    Min            41.57                 2.00           0.00000
21Feb13_170230|    Std             0.09                10.90           0.00328
21Feb13_170230|   Best            41.57                16.00           0.01803
21Feb13_170230|-- Generation 8 --
21Feb13_170230|    -- Crossed 5 individual pairs.
21Feb13_170230|    -- Mutated 32 individuals.
21Feb13_170620|    -- Evaluated 64 individuals.
21Feb13_170620|    Summary of generation 8:
21Feb13_170620| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_170620|-----------  ------------------  --------------------  ----------
21Feb13_170620|    Max            42.26                34.00           0.01805
21Feb13_170620|    Avg            41.98                 9.97           0.00214
21Feb13_170620|    Min            41.39                 2.00           0.00000
21Feb13_170620|    Std             0.12                 7.66           0.00318
21Feb13_170620|   Best            41.39                13.00           0.01805
21Feb13_170620|-- Generation 9 --
21Feb13_170620|    -- Crossed 5 individual pairs.
21Feb13_170620|    -- Mutated 32 individuals.
21Feb13_171009|    -- Evaluated 64 individuals.
21Feb13_171009|    Summary of generation 9:
21Feb13_171009| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_171009|-----------  ------------------  --------------------  ----------
21Feb13_171009|    Max            42.52                42.00           0.80424
21Feb13_171009|    Avg            41.69                 9.00           0.01487
21Feb13_171009|    Min            24.35                 2.00           0.00000
21Feb13_171009|    Std             2.19                 7.30           0.09954
21Feb13_171009|   Best            24.35                16.00           0.80424
21Feb13_171009|-- Generation 10 --
21Feb13_171009|    -- Crossed 3 individual pairs.
21Feb13_171009|    -- Mutated 32 individuals.
21Feb13_171358|    -- Evaluated 64 individuals.
21Feb13_171358|    Summary of generation 10:
21Feb13_171358| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_171358|-----------  ------------------  --------------------  ----------
21Feb13_171358|    Max            42.17                36.00           0.79390
21Feb13_171358|    Avg            41.45                 9.42           0.02585
21Feb13_171358|    Min            25.74                 2.00           0.00000
21Feb13_171358|    Std             2.73                 8.48           0.12928
21Feb13_171358|   Best            25.74                36.00           0.79390
21Feb13_171358|-- Generation 11 --
21Feb13_171358|    -- Crossed 3 individual pairs.
21Feb13_171358|    -- Mutated 32 individuals.
21Feb13_171751|    -- Evaluated 64 individuals.
21Feb13_171751|    Summary of generation 11:
21Feb13_171751| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_171751|-----------  ------------------  --------------------  ----------
21Feb13_171751|    Max            52.52                44.00           0.82842
21Feb13_171751|    Avg            41.81                13.58           0.06088
21Feb13_171751|    Min            31.91                 2.00           0.00000
21Feb13_171751|    Std             2.29                11.24           0.19241
21Feb13_171751|   Best            31.91                36.00           0.82842
21Feb13_171751|-- Generation 12 --
21Feb13_171751|    -- Crossed 3 individual pairs.
21Feb13_171751|    -- Mutated 32 individuals.
21Feb13_172143|    -- Evaluated 64 individuals.
21Feb13_172143|    Summary of generation 12:
21Feb13_172143| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_172143|-----------  ------------------  --------------------  ----------
21Feb13_172143|    Max            44.61                68.00           0.81884
21Feb13_172143|    Avg            41.75                13.84           0.01610
21Feb13_172143|    Min            28.61                 2.00           0.00000
21Feb13_172143|    Std             1.70                14.19           0.10129
21Feb13_172143|   Best            28.61                 8.00           0.81884
21Feb13_172143|-- Generation 13 --
21Feb13_172143|    -- Crossed 4 individual pairs.
21Feb13_172143|    -- Mutated 32 individuals.
21Feb13_172534|    -- Evaluated 64 individuals.
21Feb13_172534|    Summary of generation 13:
21Feb13_172534| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_172534|-----------  ------------------  --------------------  ----------
21Feb13_172534|    Max            42.17                66.00           0.02573
21Feb13_172534|    Avg            41.89                13.89           0.00467
21Feb13_172534|    Min            41.22                 2.00           0.00000
21Feb13_172534|    Std             0.22                13.12           0.00718
21Feb13_172534|   Best            41.22                12.00           0.02573
21Feb13_172534|-- Generation 14 --
21Feb13_172534|    -- Crossed 3 individual pairs.
21Feb13_172534|    -- Mutated 32 individuals.
21Feb13_172925|    -- Evaluated 64 individuals.
21Feb13_172925|    Summary of generation 14:
21Feb13_172925| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_172925|-----------  ------------------  --------------------  ----------
21Feb13_172925|    Max            42.17                63.00           0.71308
21Feb13_172925|    Avg            41.36                14.59           0.02351
21Feb13_172925|    Min            21.74                 2.00           0.00000
21Feb13_172925|    Std             2.93                11.12           0.10239
21Feb13_172925|   Best            21.74                34.00           0.71308
21Feb13_172925|-- Generation 15 --
21Feb13_172925|    -- Crossed 3 individual pairs.
21Feb13_172925|    -- Mutated 32 individuals.
21Feb13_173317|    -- Evaluated 64 individuals.
21Feb13_173317|    Summary of generation 15:
21Feb13_173317| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_173317|-----------  ------------------  --------------------  ----------
21Feb13_173317|    Max            52.26                66.00           0.79621
21Feb13_173317|    Avg            41.80                16.23           0.02671
21Feb13_173317|    Min            28.70                 2.00           0.00000
21Feb13_173317|    Std             2.11                13.19           0.11421
21Feb13_173317|   Best            28.70                34.00           0.49028
21Feb13_173317|-- Generation 16 --
21Feb13_173317|    -- Crossed 4 individual pairs.
21Feb13_173317|    -- Mutated 32 individuals.
21Feb13_173709|    -- Evaluated 64 individuals.
21Feb13_173709|    Summary of generation 16:
21Feb13_173709| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_173709|-----------  ------------------  --------------------  ----------
21Feb13_173709|    Max            42.09                44.00           0.11117
21Feb13_173709|    Avg            41.80                17.12           0.00801
21Feb13_173709|    Min            38.43                 2.00           0.00000
21Feb13_173709|    Std             0.47                10.00           0.01610
21Feb13_173709|   Best            38.43                12.00           0.11117
21Feb13_173709|-- Generation 17 --
21Feb13_173709|    -- Crossed 2 individual pairs.
21Feb13_173709|    -- Mutated 32 individuals.
21Feb13_174102|    -- Evaluated 64 individuals.
21Feb13_174102|    Summary of generation 17:
21Feb13_174102| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_174102|-----------  ------------------  --------------------  ----------
21Feb13_174102|    Max            42.26                40.00           0.20069
21Feb13_174102|    Avg            41.72                15.70           0.01075
21Feb13_174102|    Min            37.39                 2.00           0.00000
21Feb13_174102|    Std             0.61                 9.44           0.02539
21Feb13_174102|   Best            37.39                15.00           0.20069
21Feb13_174102|-- Generation 18 --
21Feb13_174102|    -- Crossed 3 individual pairs.
21Feb13_174102|    -- Mutated 32 individuals.
21Feb13_174453|    -- Evaluated 64 individuals.
21Feb13_174453|    Summary of generation 18:
21Feb13_174453| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_174453|-----------  ------------------  --------------------  ----------
21Feb13_174453|    Max            42.09                42.00           0.60970
21Feb13_174453|    Avg            41.59                14.72           0.01616
21Feb13_174453|    Min            24.43                 2.00           0.00000
21Feb13_174453|    Std             2.17                 8.43           0.07538
21Feb13_174453|   Best            24.43                32.00           0.60970
21Feb13_174453|-- Generation 19 --
21Feb13_174453|    -- Crossed 1 individual pairs.
21Feb13_174453|    -- Mutated 32 individuals.
21Feb13_174846|    -- Evaluated 64 individuals.
21Feb13_174846|    Summary of generation 19:
21Feb13_174846| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_174846|-----------  ------------------  --------------------  ----------
21Feb13_174846|    Max            42.09                42.00           0.02573
21Feb13_174846|    Avg            41.84                15.48           0.00593
21Feb13_174846|    Min            41.22                 2.00           0.00000
21Feb13_174846|    Std             0.21                 9.83           0.00647
21Feb13_174846|   Best            41.22                11.00           0.02573
21Feb13_174846|-- Generation 20 --
21Feb13_174846|    -- Crossed 1 individual pairs.
21Feb13_174846|    -- Mutated 32 individuals.
21Feb13_175237|    -- Evaluated 64 individuals.
21Feb13_175237|    Summary of generation 20:
21Feb13_175237| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_175237|-----------  ------------------  --------------------  ----------
21Feb13_175237|    Max            42.17                40.00           0.03850
21Feb13_175237|    Avg            41.77                14.75           0.00806
21Feb13_175237|    Min            40.78                 2.00           0.00000
21Feb13_175237|    Std             0.29                 9.23           0.00836
21Feb13_175237|   Best            40.78                11.00           0.03850
21Feb13_175237|-- Generation 21 --
21Feb13_175237|    -- Crossed 3 individual pairs.
21Feb13_175237|    -- Mutated 32 individuals.
21Feb13_175629|    -- Evaluated 64 individuals.
21Feb13_175629|    Summary of generation 21:
21Feb13_175629| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_175629|-----------  ------------------  --------------------  ----------
21Feb13_175629|    Max            42.09                38.00           0.02318
21Feb13_175629|    Avg            41.85                14.41           0.00613
21Feb13_175629|    Min            41.22                 2.00           0.00000
21Feb13_175629|    Std             0.21                 9.09           0.00617
21Feb13_175629|   Best            41.22                15.00           0.02318
21Feb13_175629|-- Generation 22 --
21Feb13_175629|    -- Crossed 4 individual pairs.
21Feb13_175629|    -- Mutated 32 individuals.
21Feb13_180018|    -- Evaluated 64 individuals.
21Feb13_180018|    Summary of generation 22:
21Feb13_180018| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_180018|-----------  ------------------  --------------------  ----------
21Feb13_180018|    Max            42.35                36.00           0.02315
21Feb13_180018|    Avg            41.80                12.75           0.00730
21Feb13_180018|    Min            41.30                 4.00           0.00000
21Feb13_180018|    Std             0.22                 6.85           0.00661
21Feb13_180018|   Best            41.30                 9.00           0.02062
21Feb13_180018|-- Generation 23 --
21Feb13_180018|    -- Crossed 1 individual pairs.
21Feb13_180018|    -- Mutated 32 individuals.
21Feb13_180408|    -- Evaluated 64 individuals.
21Feb13_180408|    Summary of generation 23:
21Feb13_180408| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_180408|-----------  ------------------  --------------------  ----------
21Feb13_180408|    Max            42.17                40.00           0.02318
21Feb13_180408|    Avg            41.78                13.30           0.00822
21Feb13_180408|    Min            41.22                 4.00           0.00000
21Feb13_180408|    Std             0.28                 8.42           0.00792
21Feb13_180408|   Best            41.22                11.00           0.02318
21Feb13_180408|-- Generation 24 --
21Feb13_180408|    -- Crossed 4 individual pairs.
21Feb13_180408|    -- Mutated 32 individuals.
21Feb13_180800|    -- Evaluated 64 individuals.
21Feb13_180800|    Summary of generation 24:
21Feb13_180800| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_180800|-----------  ------------------  --------------------  ----------
21Feb13_180800|    Max            42.61                40.00           0.02573
21Feb13_180800|    Avg            41.76                13.17           0.00918
21Feb13_180800|    Min            41.22                 4.00           0.00000
21Feb13_180800|    Std             0.29                 8.11           0.00816
21Feb13_180800|   Best            41.22                11.00           0.02318
21Feb13_180800|-- Generation 25 --
21Feb13_180800|    -- Crossed 2 individual pairs.
21Feb13_180800|    -- Mutated 32 individuals.
21Feb13_181153|    -- Evaluated 64 individuals.
21Feb13_181153|    Summary of generation 25:
21Feb13_181153| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_181153|-----------  ------------------  --------------------  ----------
21Feb13_181153|    Max            42.17                40.00           0.02318
21Feb13_181153|    Avg            41.83                12.47           0.00685
21Feb13_181153|    Min            41.22                 3.00           0.00000
21Feb13_181153|    Std             0.23                 7.79           0.00628
21Feb13_181153|   Best            41.22                14.00           0.02318
21Feb13_181153|-- Generation 26 --
21Feb13_181153|    -- Crossed 5 individual pairs.
21Feb13_181153|    -- Mutated 32 individuals.
21Feb13_181543|    -- Evaluated 64 individuals.
21Feb13_181543|    Summary of generation 26:
21Feb13_181543| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_181543|-----------  ------------------  --------------------  ----------
21Feb13_181543|    Max            42.09                42.00           0.02318
21Feb13_181543|    Avg            41.80                13.73           0.00734
21Feb13_181543|    Min            41.22                 4.00           0.00000
21Feb13_181543|    Std             0.24                 9.70           0.00668
21Feb13_181543|   Best            41.22                13.00           0.02318
21Feb13_181543|-- Generation 27 --
21Feb13_181543|    -- Crossed 1 individual pairs.
21Feb13_181543|    -- Mutated 32 individuals.
21Feb13_181934|    -- Evaluated 64 individuals.
21Feb13_181934|    Summary of generation 27:
21Feb13_181934| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_181934|-----------  ------------------  --------------------  ----------
21Feb13_181934|    Max            42.35                64.00           0.02573
21Feb13_181934|    Avg            41.80                13.58           0.00806
21Feb13_181934|    Min            41.22                 4.00           0.00000
21Feb13_181934|    Std             0.29                 9.89           0.00740
21Feb13_181934|   Best            41.22                13.00           0.02318
21Feb13_181934|-- Generation 28 --
21Feb13_181934|    -- Crossed 2 individual pairs.
21Feb13_181934|    -- Mutated 32 individuals.
21Feb13_182324|    -- Evaluated 64 individuals.
21Feb13_182324|    Summary of generation 28:
21Feb13_182324| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_182324|-----------  ------------------  --------------------  ----------
21Feb13_182324|    Max            42.26                38.00           0.05873
21Feb13_182324|    Avg            41.72                13.27           0.00990
21Feb13_182324|    Min            40.26                 3.00           0.00000
21Feb13_182324|    Std             0.33                 8.83           0.00998
21Feb13_182324|   Best            40.26                16.00           0.05873
21Feb13_182324|-- Generation 29 --
21Feb13_182324|    -- Crossed 4 individual pairs.
21Feb13_182324|    -- Mutated 32 individuals.
21Feb13_182715|    -- Evaluated 64 individuals.
21Feb13_182715|    Summary of generation 29:
21Feb13_182715| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_182715|-----------  ------------------  --------------------  ----------
21Feb13_182715|    Max            42.17                40.00           0.05368
21Feb13_182715|    Avg            41.80                12.72           0.00697
21Feb13_182715|    Min            40.43                 4.00           0.00000
21Feb13_182715|    Std             0.28                 9.75           0.00876
21Feb13_182715|   Best            40.43                16.00           0.05368
21Feb13_182715|-- Generation 30 --
21Feb13_182715|    -- Crossed 2 individual pairs.
21Feb13_182715|    -- Mutated 32 individuals.
21Feb13_183104|    -- Evaluated 64 individuals.
21Feb13_183104|    Summary of generation 30:
21Feb13_183104| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_183104|-----------  ------------------  --------------------  ----------
21Feb13_183104|    Max            42.17                38.00           0.22439
21Feb13_183104|    Avg            41.71                11.16           0.01104
21Feb13_183104|    Min            36.26                 3.00           0.00000
21Feb13_183104|    Std             0.73                 8.57           0.02825
21Feb13_183104|   Best            36.26                16.00           0.22439
21Feb13_183104|-- Generation 31 --
21Feb13_183104|    -- Crossed 2 individual pairs.
21Feb13_183104|    -- Mutated 32 individuals.
21Feb13_183455|    -- Evaluated 64 individuals.
21Feb13_183455|    Summary of generation 31:
21Feb13_183455| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_183455|-----------  ------------------  --------------------  ----------
21Feb13_183455|    Max            42.70                36.00           0.77036
21Feb13_183455|    Avg            41.79                10.06           0.01880
21Feb13_183455|    Min            37.22                 3.00           0.00000
21Feb13_183455|    Std             0.62                 6.42           0.09500
21Feb13_183455|   Best            37.22                16.00           0.77036
21Feb13_183455|-- Generation 32 --
21Feb13_183455|    -- Crossed 1 individual pairs.
21Feb13_183455|    -- Mutated 32 individuals.
21Feb13_183846|    -- Evaluated 64 individuals.
21Feb13_183846|    Summary of generation 32:
21Feb13_183846| Statistic    Accuracy error %    Neuron/Layer score    F2 score
21Feb13_183846|-----------  ------------------  --------------------  ----------
21Feb13_183846|    Max            53.48                34.00           0.79365
21Feb13_183846|    Avg            41.94                10.12           0.02459
21Feb13_183846|    Min            38.96                 4.00           0.00000
21Feb13_183846|    Std             1.51                 6.61           0.10641
21Feb13_183846|   Best            38.96                18.00           0.35698
21Feb13_183846|Best initial individual weights
21Feb13_183846|Individual:
21Feb13_183846|-- Constant hidden layers --
21Feb13_183846|False
21Feb13_183846|Layer 0:
21Feb13_183846|-- Config --
21Feb13_183846|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 11, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_183846|-- Weights --
21Feb13_183846|[[-0.29576  0.44171  0.90013 -0.67922 -0.39729 -0.40263 -0.04202  0.08496
21Feb13_183846|   0.19256  0.41763 -0.24910]
21Feb13_183846| [ 0.47493 -0.67691  0.52223  0.92034  0.93101 -0.85934  0.61073  0.49136
21Feb13_183846|  -0.57326 -0.74076 -0.79649]
21Feb13_183846| [-0.19879  0.46529  0.21105  0.45887 -0.72253  0.41490  0.79793 -0.30828
21Feb13_183846|   0.25210 -0.63916 -0.53387]
21Feb13_183846| [ 0.14632  0.09562  0.13535  0.51707 -0.55555  0.15363  0.01683 -0.13500
21Feb13_183846|   0.87463 -0.63349  0.73259]
21Feb13_183846| [ 0.18647 -0.51428 -0.93035 -0.97888 -0.81124  0.42160 -0.76787  0.54877
21Feb13_183846|   0.74036 -0.67404 -0.66504]
21Feb13_183846| [-0.67870  0.45223 -0.37491  0.59901 -0.51989  0.22216  0.49236  0.56033
21Feb13_183846|  -0.35836  0.35994  0.55326]
21Feb13_183846| [-0.85862 -0.64388  0.59068 -0.99511  0.96639  0.45897 -0.97818 -0.61082
21Feb13_183846|   0.59509 -0.58225 -0.78013]
21Feb13_183846| [-0.41616  0.48318 -0.47935  0.60946  0.21410 -0.08904 -0.96585 -0.04995
21Feb13_183846|   0.62368 -0.73073  0.97219]
21Feb13_183846| [-0.17193  0.50680 -0.14093  0.74261 -0.92535 -0.16094 -0.84764  0.01603
21Feb13_183846|  -0.35258 -0.11580  0.13854]
21Feb13_183846| [ 0.77768  0.99810  0.06076 -0.64347 -0.54477 -0.14330 -0.06569  0.86989
21Feb13_183846|  -0.11544  0.54092  0.53981]
21Feb13_183846| [ 0.65170 -0.92989 -0.19214  0.96298  0.81013 -0.67034  0.82829 -0.33340
21Feb13_183846|  -0.11748 -0.37341  0.32247]
21Feb13_183846| [-0.24216  0.09957  0.72394 -0.06990 -0.34305  0.05443 -0.33588  0.47261
21Feb13_183846|  -0.75247  0.95147 -0.61440]
21Feb13_183846| [-0.89314 -0.84457 -0.28706 -0.46024  0.04331  0.42584  0.87819 -0.17375
21Feb13_183846|  -0.45340  0.34670  0.63683]
21Feb13_183846| [-0.05969  0.05102  0.03684 -0.81817  0.19725 -0.57510  0.42830  0.11246
21Feb13_183846|   0.94414 -0.24328  0.08999]
21Feb13_183846| [-0.40440 -0.67323  0.44669 -0.52153 -0.76404  0.28184  0.14262 -0.84181
21Feb13_183846|  -0.72081 -0.78985 -0.29508]
21Feb13_183846| [ 0.92388  0.99360  0.85258 -0.63939 -0.03349  0.40591 -0.37523 -0.27652
21Feb13_183846|  -0.49979  0.62500  0.59817]
21Feb13_183846| [ 0.62915  0.72273  0.79188  0.03677  0.82216 -0.69465  0.68928  0.66152
21Feb13_183846|   0.36424 -0.45319  0.83669]
21Feb13_183846| [ 0.03153 -0.48924 -0.64073  0.37862 -0.24840  0.44365 -0.19640  0.54182
21Feb13_183846|  -0.67521  0.36251 -0.89945]
21Feb13_183846| [-0.79120  0.82310 -0.05409  0.54136  0.77593 -0.71341 -0.36023 -0.84678
21Feb13_183846|   0.26197  0.35918 -0.83492]
21Feb13_183846| [-0.28186  0.99550  0.62717  0.80755 -0.56914  0.91476  0.28779 -0.78664
21Feb13_183846|  -0.27508 -0.01966 -0.48291]
21Feb13_183846| [ 0.88834  0.53014  0.35742  0.94366  0.65878  0.38323 -0.96544  0.93123
21Feb13_183846|   0.63960  0.63535 -0.46926]
21Feb13_183846| [ 0.45002  0.67483 -0.96693 -0.69815  0.02970 -0.61388 -0.81626  0.43638
21Feb13_183846|   0.29674 -0.56912  0.08677]
21Feb13_183846| [-0.13865  0.23134  0.65175  0.02864  0.32709 -0.42827 -0.25479 -0.61408
21Feb13_183846|   0.02793 -0.91917 -0.54231]
21Feb13_183846| [-0.99842 -0.11173  0.73087  0.94943 -0.01869 -0.01638 -0.46550  0.30141
21Feb13_183846|  -0.05369 -0.87358  0.39794]
21Feb13_183846| [ 0.78462  0.27529  0.79753  0.45045 -0.76238  0.32652 -0.79247 -0.23391
21Feb13_183846|   0.19755 -0.20175 -0.26996]
21Feb13_183846| [-0.00426 -0.70702 -0.27396 -0.47884  0.02352 -0.76399 -0.42811  0.44411
21Feb13_183846|  -0.35013 -0.28976 -0.31532]
21Feb13_183846| [ 0.36183  0.14226 -0.04661  0.31445 -0.42451 -0.84823 -0.88133 -0.96984
21Feb13_183846|  -0.81685  0.81182  0.13656]
21Feb13_183846| [-0.60907  0.42451  0.29491 -0.46852  0.78885  0.20030 -0.38119 -0.54307
21Feb13_183846|  -0.78533  0.03419 -0.48764]
21Feb13_183846| [ 0.22941  0.92714 -0.74982  0.58576 -0.64095  0.31465  0.14736  0.37728
21Feb13_183846|  -0.88395  0.01660 -0.48622]
21Feb13_183846| [ 0.11337  0.23404 -0.06600  0.27416 -0.01675 -0.15693  0.48697  0.28708
21Feb13_183846|   0.68547 -0.18628 -0.33336]
21Feb13_183846| [-0.68801  0.12030  0.52869  0.03536 -0.66741  0.36721  0.05309 -0.56489
21Feb13_183846|  -0.15327 -0.85319 -0.74260]
21Feb13_183846| [-0.10616 -0.41975 -0.05051  0.17304 -0.87530 -0.19831  0.83959 -0.71838
21Feb13_183846|   0.42196 -0.55286 -0.92074]
21Feb13_183846| [-0.14150 -0.87233 -0.29700  0.48172  0.27235  0.00437 -0.06600 -0.85195
21Feb13_183846|  -0.13544 -0.44674 -0.53926]
21Feb13_183846| [-0.94904 -0.21754 -0.06643 -0.41229  0.84909 -0.86020 -0.11523  0.49364
21Feb13_183846|   0.87791  0.59266 -0.01598]
21Feb13_183846| [ 0.43678 -0.97180 -0.91202 -0.32709 -0.40804 -0.38986 -0.80275 -0.12827
21Feb13_183846|  -0.14983  0.78031  0.94472]
21Feb13_183846| [ 0.09362  0.12280  0.44496  0.81658  0.23281  0.75600  0.43491  0.09108
21Feb13_183846|   0.70670 -0.31504 -0.14322]
21Feb13_183846| [-0.55823 -0.59812 -0.21541  0.32501  0.25693 -0.67641  0.74696 -0.97160
21Feb13_183846|  -0.23376  0.70688 -0.79409]
21Feb13_183846| [ 0.04609 -0.20207 -0.77610  0.53143  0.95253  0.65050  0.54157 -0.24706
21Feb13_183846|   0.79107  0.55921 -0.11719]
21Feb13_183846| [-0.67773  0.95721 -0.84428 -0.88051 -0.93167  0.42388 -0.43337 -0.83657
21Feb13_183846|  -0.25593  0.43029  0.79844]
21Feb13_183846| [ 0.77510  0.02649 -0.94974 -0.19331 -0.99427 -0.46967 -0.58294 -0.35727
21Feb13_183846|   0.92875  0.37809  0.76197]
21Feb13_183846| [-0.52250 -0.62252  0.61463  0.75560  0.12808  0.47657  0.20933 -0.68188
21Feb13_183846|   0.95615 -0.85965 -0.58901]
21Feb13_183846| [-0.29330  0.97664  0.63705  0.49555  0.13610 -0.07304  0.95707  0.32469
21Feb13_183846|   0.14671  0.59363 -0.49901]
21Feb13_183846| [ 0.73249 -0.18657  0.83322 -0.28426  0.24491  0.19713  0.48414  0.15126
21Feb13_183846|   0.45775 -0.12371  0.50424]
21Feb13_183846| [-0.49974 -0.24168 -0.48402  0.73610 -0.04308 -0.79545 -0.27158  0.11203
21Feb13_183846|   0.48799 -0.26679  0.36018]
21Feb13_183846| [ 0.45858 -0.85714  0.92189 -0.16526  0.71189 -0.25251 -0.02545  0.39237
21Feb13_183846|  -0.48677 -0.69279 -0.58604]
21Feb13_183846| [-0.20202  0.65799  0.46645  0.38929 -0.68372  0.84869 -0.12614 -0.50276
21Feb13_183846|   0.08758 -0.76666  0.84266]
21Feb13_183846| [-0.45524  0.04646  0.67728  0.59735 -0.54596  0.38150 -0.66395  0.02403
21Feb13_183846|  -0.98324  0.08609  0.79063]
21Feb13_183846| [ 0.15928  0.64826 -0.21082 -0.68342  0.67169  0.23875  0.29847  0.00488
21Feb13_183846|   0.48168  0.28575 -0.95257]
21Feb13_183846| [-0.77984 -0.11936 -0.90815  0.86596  0.77760 -0.74816 -0.88634 -0.99337
21Feb13_183846|  -0.34641 -0.64570  0.12533]
21Feb13_183846| [-0.72284  0.20483 -0.48588 -0.00654  0.36727  0.29562 -0.62051 -0.76325
21Feb13_183846|   0.17198  0.58959 -0.17821]
21Feb13_183846| [-0.93115 -0.10329 -0.56331  0.04189  0.59153  0.50150 -0.81420  0.71884
21Feb13_183846|  -0.27439 -0.99572 -0.37961]
21Feb13_183846| [-0.90947 -0.24039  0.51574  0.18926  0.88074  0.79405  0.33308 -0.75612
21Feb13_183846|   0.49840 -0.49200 -0.11378]
21Feb13_183846| [-0.31649 -0.57316 -0.76818 -0.95569  0.77239  0.48581  0.78517 -0.76635
21Feb13_183846|  -0.45484 -0.14335  0.10823]
21Feb13_183846| [ 0.81253  0.35428  0.22109  0.73372 -0.91041 -0.74838 -0.35725 -0.81841
21Feb13_183846|   0.21316  0.32486  0.40128]
21Feb13_183846| [-0.81834  0.57764  0.92182  0.33726 -0.30333 -0.04800  0.83304  0.43958
21Feb13_183846|  -0.64812  0.94559  0.01033]
21Feb13_183846| [ 0.48196  0.26653  0.77869 -0.47694 -0.85232  0.49088  0.09418  0.53945
21Feb13_183846|  -0.64240 -0.48429  0.71164]
21Feb13_183846| [-0.49896  0.76619  0.19463  0.49981  0.34442 -0.19091  0.93672  0.00971
21Feb13_183846|   0.74970  0.01320 -0.97981]]
21Feb13_183846|-- Bias --
21Feb13_183846|[-0.52460  0.52210  0.23662 -0.54722 -0.16964  0.21425 -0.28974 -0.66275
21Feb13_183846|  0.37977  0.92358  0.49915]
21Feb13_183846|Layer 1:
21Feb13_183846|-- Config --
21Feb13_183846|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 11], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_183846|-- Weights --
21Feb13_183846|[[ 0.16314  0.83166]
21Feb13_183846| [ 0.31256 -0.10962]
21Feb13_183846| [-0.58012 -0.50993]
21Feb13_183846| [-0.77112 -0.63298]
21Feb13_183846| [-0.92198  0.22610]
21Feb13_183846| [ 0.06620 -0.58917]
21Feb13_183846| [ 0.89231  0.75125]
21Feb13_183846| [-0.93385  0.54358]
21Feb13_183846| [ 0.59636  0.12484]
21Feb13_183846| [ 0.67557 -0.43479]
21Feb13_183846| [-0.49289 -0.00622]]
21Feb13_183846|-- Bias --
21Feb13_183846|[-0.35739 -0.71180]
21Feb13_183846|Predicting the validation and test data with the Best initial individual.
21Feb13_183853| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_183853|-----------  ------------------  --------------------  ----------
21Feb13_183853|Validation         41.57                  11            0.01547
21Feb13_183853|   Test            36.58                  11            0.00000
21Feb13_183853|-------------------- Test #0 --------------------
21Feb13_183853|Best final individual weights
21Feb13_183853|Individual:
21Feb13_183853|-- Constant hidden layers --
21Feb13_183853|False
21Feb13_183853|Layer 0:
21Feb13_183853|-- Config --
21Feb13_183853|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_183853|-- Weights --
21Feb13_183853|[[-1.87472e-01 -1.88423e+00 -9.87479e-02 -4.31576e-01]
21Feb13_183853| [ 7.47578e-01 -8.61812e-01 -1.03859e+00  6.81397e-02]
21Feb13_183853| [-1.04232e+00  1.71195e+00 -4.16856e-01 -4.98514e-01]
21Feb13_183853| [ 1.35466e+00 -6.63542e-01  7.24879e-01  2.25979e-02]
21Feb13_183853| [ 2.16981e-01 -2.10882e+00 -1.46954e+00 -6.08573e-01]
21Feb13_183853| [ 6.47638e-02  1.08814e+00  6.86203e-02  9.30175e-01]
21Feb13_183853| [-2.44488e+00  1.55556e+00  1.90865e-01  1.59360e-01]
21Feb13_183853| [-6.06958e-01 -1.30643e-01  7.80295e-01  1.68866e+00]
21Feb13_183853| [ 7.24409e-01 -1.27327e+00 -2.36592e-02 -7.70925e-01]
21Feb13_183853| [ 8.20815e-01  1.41478e-02  1.57561e+00  3.89599e-01]
21Feb13_183853| [ 5.19426e-01  7.54468e-01 -2.58818e-02 -5.31621e-01]
21Feb13_183853| [ 1.59397e+00  1.31399e+00  4.31820e-02  4.73847e-01]
21Feb13_183853| [ 6.12200e-01 -8.79955e-01 -1.86201e-01 -1.90943e+00]
21Feb13_183853| [ 3.40432e-01  1.02790e+00 -1.15314e+00 -1.40468e+00]
21Feb13_183853| [ 4.70886e-01 -8.98456e-01  2.17497e+00  1.29145e-01]
21Feb13_183853| [ 8.53325e-01  1.53881e+00  8.59108e-01  5.58786e-01]
21Feb13_183853| [-1.34194e+00 -8.61258e-01  4.02439e-01 -9.96468e-01]
21Feb13_183853| [-1.33269e+00  6.41410e-01 -5.15019e-02 -7.72709e-01]
21Feb13_183853| [-4.69262e-01  2.41285e-01 -1.26819e+00 -4.79252e-01]
21Feb13_183853| [-1.25819e+00 -2.15944e-01 -5.82515e-01 -3.71993e-01]
21Feb13_183853| [-2.08817e+00 -2.39077e-01  5.19126e-01 -6.39950e-02]
21Feb13_183853| [-2.16821e-01 -5.79153e-01 -1.25299e-01 -5.39553e-01]
21Feb13_183853| [ 6.63347e-01  2.32524e-01  3.53160e-01 -3.17821e-01]
21Feb13_183853| [ 1.10172e+00  3.34007e-01 -1.28144e+00 -9.99387e-01]
21Feb13_183853| [ 6.14747e-01  1.74699e-02 -2.53533e-01 -4.93268e-01]
21Feb13_183853| [-1.68123e-01 -3.75621e-02 -4.00563e-01 -1.06499e+00]
21Feb13_183853| [ 1.68917e+00  8.38239e-01 -2.68816e-02 -9.26705e-01]
21Feb13_183853| [ 8.16397e-01  1.47216e+00 -3.72165e-01  8.01488e-02]
21Feb13_183853| [-1.87213e-01  3.60063e-01  2.18543e-01  5.02950e-01]
21Feb13_183853| [ 7.33804e-01 -1.95159e-01 -1.82285e+00  5.14853e-01]
21Feb13_183853| [ 6.88558e-01 -1.07087e-01 -2.67856e+00 -1.83088e+00]
21Feb13_183853| [-2.26892e-01 -1.79768e+00  1.38529e+00 -1.06190e+00]
21Feb13_183853| [ 7.06417e-01 -3.75030e-01 -8.33602e-02  1.51313e-02]
21Feb13_183853| [ 4.07669e-01 -4.07600e-02  8.65359e-01 -6.48309e-01]
21Feb13_183853| [ 1.59318e+00  1.49862e+00 -1.22730e+00 -4.75797e-02]
21Feb13_183853| [ 2.23448e+00  5.81611e-01  9.70576e-01 -1.16943e+00]
21Feb13_183853| [ 1.27520e+00  1.46452e-01 -1.77996e+00 -3.68113e-01]
21Feb13_183853| [ 2.64911e-01  1.29363e+00 -7.55651e-01  1.31616e+00]
21Feb13_183853| [-3.15699e-01 -9.42947e-01  3.59613e-01  1.53691e+00]
21Feb13_183853| [-1.83237e+00 -2.82041e-01  1.15458e-01  9.14966e-01]
21Feb13_183853| [ 5.41912e-01  1.03547e+00  1.89459e-01 -3.11293e-01]
21Feb13_183853| [-8.48413e-01 -7.65092e-01  1.52671e+00  2.32680e+00]
21Feb13_183853| [-9.07727e-01  1.26484e+00  1.84065e-03  2.89181e-01]
21Feb13_183853| [-7.76721e-01  1.73275e+00 -2.00253e-01  5.13027e-01]
21Feb13_183853| [-3.14822e-01  6.65239e-01 -8.33827e-01 -9.31808e-01]
21Feb13_183853| [-1.06577e+00 -6.56160e-01  7.07962e-01 -7.41742e-01]
21Feb13_183853| [ 1.37495e+00 -9.98537e-01 -1.26291e-01  7.35705e-01]
21Feb13_183853| [-7.81532e-01  4.81725e-01  9.72613e-01  1.14711e+00]
21Feb13_183853| [ 1.39228e+00 -1.10795e+00  6.18742e-01 -8.23983e-01]
21Feb13_183853| [-1.21496e+00 -9.27339e-01  1.46112e+00 -1.58060e-01]
21Feb13_183853| [-1.47877e-01  3.00039e-01 -1.16124e-01 -2.49785e-01]
21Feb13_183853| [ 1.34618e+00 -4.10722e-01 -2.01150e+00 -2.75159e-01]
21Feb13_183853| [ 3.26027e-01 -2.31842e+00 -9.63079e-01  1.40506e+00]
21Feb13_183853| [ 2.37497e-01 -8.86651e-02 -8.09815e-03 -2.75301e-01]
21Feb13_183853| [-9.43558e-01  3.27714e-02  1.37072e+00 -6.87180e-01]
21Feb13_183853| [-2.73140e-01 -1.03409e+00  4.18114e-01  2.63792e+00]
21Feb13_183853| [-1.29274e+00  5.68486e-01 -3.70493e-01 -1.79609e+00]]
21Feb13_183853|-- Bias --
21Feb13_183853|[ 0.47797 -0.46841  0.80042  0.85704]
21Feb13_183853|Layer 1:
21Feb13_183853|-- Config --
21Feb13_183853|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_183853|-- Weights --
21Feb13_183853|[[-0.07388 -0.44630  0.00582 -0.38753  0.04666]
21Feb13_183853| [ 0.56150  0.18177  0.10598  0.12676 -0.22741]
21Feb13_183853| [ 0.36995 -0.63866  0.59360 -0.34067  0.28075]
21Feb13_183853| [-0.02730 -0.58961 -0.21658  0.00403  0.22317]]
21Feb13_183853|-- Bias --
21Feb13_183853|[ 0.60577  0.01906  0.49354 -0.12722 -0.48520]
21Feb13_183853|Layer 2:
21Feb13_183853|-- Config --
21Feb13_183853|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_183853|-- Weights --
21Feb13_183853|[[ 0.86200 -1.33193]
21Feb13_183853| [-2.22124  1.37832]
21Feb13_183853| [-0.02313 -0.06435]
21Feb13_183853| [ 0.48998 -0.56779]
21Feb13_183853| [-0.10810  0.00308]]
21Feb13_183853|-- Bias --
21Feb13_183853|[-0.07638  0.02979]
21Feb13_183853|Predicting the validation and test data with the Best final individual.
21Feb13_183901| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_183901|-----------  ------------------  --------------------  ----------
21Feb13_183901|Validation         40.61                  18            0.12165
21Feb13_183901|   Test            36.14                  18            0.32048
21Feb13_183901|-------------------- Test #1 --------------------
21Feb13_183901|Best final individual weights
21Feb13_183901|Individual:
21Feb13_183901|-- Constant hidden layers --
21Feb13_183901|False
21Feb13_183901|Layer 0:
21Feb13_183901|-- Config --
21Feb13_183901|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_183901|-- Weights --
21Feb13_183901|[[-1.87472e-01 -1.88423e+00 -9.87479e-02 -4.31576e-01]
21Feb13_183901| [ 7.47578e-01 -8.61812e-01 -1.03859e+00  6.81397e-02]
21Feb13_183901| [-1.04232e+00  1.71195e+00 -4.16856e-01 -4.98514e-01]
21Feb13_183901| [ 1.35466e+00 -6.63542e-01  7.24879e-01  2.25979e-02]
21Feb13_183901| [ 2.16981e-01 -2.10882e+00 -1.46954e+00 -6.08573e-01]
21Feb13_183901| [ 6.47638e-02  1.08814e+00  6.86203e-02  9.30175e-01]
21Feb13_183901| [-2.44488e+00  1.55556e+00  1.90865e-01  1.59360e-01]
21Feb13_183901| [-6.06958e-01 -1.30643e-01  7.80295e-01  1.68866e+00]
21Feb13_183901| [ 7.24409e-01 -1.27327e+00 -2.36592e-02 -7.70925e-01]
21Feb13_183901| [ 8.20815e-01  1.41478e-02  1.57561e+00  3.89599e-01]
21Feb13_183901| [ 5.19426e-01  7.54468e-01 -2.58818e-02 -5.31621e-01]
21Feb13_183901| [ 1.59397e+00  1.31399e+00  4.31820e-02  4.73847e-01]
21Feb13_183901| [ 6.12200e-01 -8.79955e-01 -1.86201e-01 -1.90943e+00]
21Feb13_183901| [ 3.40432e-01  1.02790e+00 -1.15314e+00 -1.40468e+00]
21Feb13_183901| [ 4.70886e-01 -8.98456e-01  2.17497e+00  1.29145e-01]
21Feb13_183901| [ 8.53325e-01  1.53881e+00  8.59108e-01  5.58786e-01]
21Feb13_183901| [-1.34194e+00 -8.61258e-01  4.02439e-01 -9.96468e-01]
21Feb13_183901| [-1.33269e+00  6.41410e-01 -5.15019e-02 -7.72709e-01]
21Feb13_183901| [-4.69262e-01  2.41285e-01 -1.26819e+00 -4.79252e-01]
21Feb13_183901| [-1.25819e+00 -2.15944e-01 -5.82515e-01 -3.71993e-01]
21Feb13_183901| [-2.08817e+00 -2.39077e-01  5.19126e-01 -6.39950e-02]
21Feb13_183901| [-2.16821e-01 -5.79153e-01 -1.25299e-01 -5.39553e-01]
21Feb13_183901| [ 6.63347e-01  2.32524e-01  3.53160e-01 -3.17821e-01]
21Feb13_183901| [ 1.10172e+00  3.34007e-01 -1.28144e+00 -9.99387e-01]
21Feb13_183901| [ 6.14747e-01  1.74699e-02 -2.53533e-01 -4.93268e-01]
21Feb13_183901| [-1.68123e-01 -3.75621e-02 -4.00563e-01 -1.06499e+00]
21Feb13_183901| [ 1.68917e+00  8.38239e-01 -2.68816e-02 -9.26705e-01]
21Feb13_183901| [ 8.16397e-01  1.47216e+00 -3.72165e-01  8.01488e-02]
21Feb13_183901| [-1.87213e-01  3.60063e-01  2.18543e-01  5.02950e-01]
21Feb13_183901| [ 7.33804e-01 -1.95159e-01 -1.82285e+00  5.14853e-01]
21Feb13_183901| [ 6.88558e-01 -1.07087e-01 -2.67856e+00 -1.83088e+00]
21Feb13_183901| [-2.26892e-01 -1.79768e+00  1.38529e+00 -1.06190e+00]
21Feb13_183901| [ 7.06417e-01 -3.75030e-01 -8.33602e-02  1.51313e-02]
21Feb13_183901| [ 4.07669e-01 -4.07600e-02  8.65359e-01 -6.48309e-01]
21Feb13_183901| [ 1.59318e+00  1.49862e+00 -1.22730e+00 -4.75797e-02]
21Feb13_183901| [ 2.23448e+00  5.81611e-01  9.70576e-01 -1.16943e+00]
21Feb13_183901| [ 1.27520e+00  1.46452e-01 -1.77996e+00 -3.68113e-01]
21Feb13_183901| [ 2.64911e-01  1.29363e+00 -7.55651e-01  1.31616e+00]
21Feb13_183901| [-3.15699e-01 -9.42947e-01  3.59613e-01  1.53691e+00]
21Feb13_183901| [-1.83237e+00 -2.82041e-01  1.15458e-01  9.14966e-01]
21Feb13_183901| [ 5.41912e-01  1.03547e+00  1.89459e-01 -3.11293e-01]
21Feb13_183901| [-8.48413e-01 -7.65092e-01  1.52671e+00  2.32680e+00]
21Feb13_183901| [-9.07727e-01  1.26484e+00  1.84065e-03  2.89181e-01]
21Feb13_183901| [-7.76721e-01  1.73275e+00 -2.00253e-01  5.13027e-01]
21Feb13_183901| [-3.14822e-01  6.65239e-01 -8.33827e-01 -9.31808e-01]
21Feb13_183901| [-1.06577e+00 -6.56160e-01  7.07962e-01 -7.41742e-01]
21Feb13_183901| [ 1.37495e+00 -9.98537e-01 -1.26291e-01  7.35705e-01]
21Feb13_183901| [-7.81532e-01  4.81725e-01  9.72613e-01  1.14711e+00]
21Feb13_183901| [ 1.39228e+00 -1.10795e+00  6.18742e-01 -8.23983e-01]
21Feb13_183901| [-1.21496e+00 -9.27339e-01  1.46112e+00 -1.58060e-01]
21Feb13_183901| [-1.47877e-01  3.00039e-01 -1.16124e-01 -2.49785e-01]
21Feb13_183901| [ 1.34618e+00 -4.10722e-01 -2.01150e+00 -2.75159e-01]
21Feb13_183901| [ 3.26027e-01 -2.31842e+00 -9.63079e-01  1.40506e+00]
21Feb13_183901| [ 2.37497e-01 -8.86651e-02 -8.09815e-03 -2.75301e-01]
21Feb13_183901| [-9.43558e-01  3.27714e-02  1.37072e+00 -6.87180e-01]
21Feb13_183901| [-2.73140e-01 -1.03409e+00  4.18114e-01  2.63792e+00]
21Feb13_183901| [-1.29274e+00  5.68486e-01 -3.70493e-01 -1.79609e+00]]
21Feb13_183901|-- Bias --
21Feb13_183901|[ 0.47797 -0.46841  0.80042  0.85704]
21Feb13_183901|Layer 1:
21Feb13_183901|-- Config --
21Feb13_183901|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_183901|-- Weights --
21Feb13_183901|[[-0.07388 -0.44630  0.00582 -0.38753  0.04666]
21Feb13_183901| [ 0.56150  0.18177  0.10598  0.12676 -0.22741]
21Feb13_183901| [ 0.36995 -0.63866  0.59360 -0.34067  0.28075]
21Feb13_183901| [-0.02730 -0.58961 -0.21658  0.00403  0.22317]]
21Feb13_183901|-- Bias --
21Feb13_183901|[ 0.60577  0.01906  0.49354 -0.12722 -0.48520]
21Feb13_183901|Layer 2:
21Feb13_183901|-- Config --
21Feb13_183901|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_183901|-- Weights --
21Feb13_183901|[[ 0.86200 -1.33193]
21Feb13_183901| [-2.22124  1.37832]
21Feb13_183901| [-0.02313 -0.06435]
21Feb13_183901| [ 0.48998 -0.56779]
21Feb13_183901| [-0.10810  0.00308]]
21Feb13_183901|-- Bias --
21Feb13_183901|[-0.07638  0.02979]
21Feb13_183901|Predicting the validation and test data with the Best final individual.
21Feb13_183908| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_183908|-----------  ------------------  --------------------  ----------
21Feb13_183908|Validation         41.13                  18            0.09990
21Feb13_183908|   Test            35.88                  18            0.02666
21Feb13_183908|-------------------- Test #2 --------------------
21Feb13_183908|Best final individual weights
21Feb13_183908|Individual:
21Feb13_183908|-- Constant hidden layers --
21Feb13_183908|False
21Feb13_183908|Layer 0:
21Feb13_183908|-- Config --
21Feb13_183908|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_183908|-- Weights --
21Feb13_183908|[[-1.87472e-01 -1.88423e+00 -9.87479e-02 -4.31576e-01]
21Feb13_183908| [ 7.47578e-01 -8.61812e-01 -1.03859e+00  6.81397e-02]
21Feb13_183908| [-1.04232e+00  1.71195e+00 -4.16856e-01 -4.98514e-01]
21Feb13_183908| [ 1.35466e+00 -6.63542e-01  7.24879e-01  2.25979e-02]
21Feb13_183908| [ 2.16981e-01 -2.10882e+00 -1.46954e+00 -6.08573e-01]
21Feb13_183908| [ 6.47638e-02  1.08814e+00  6.86203e-02  9.30175e-01]
21Feb13_183908| [-2.44488e+00  1.55556e+00  1.90865e-01  1.59360e-01]
21Feb13_183908| [-6.06958e-01 -1.30643e-01  7.80295e-01  1.68866e+00]
21Feb13_183908| [ 7.24409e-01 -1.27327e+00 -2.36592e-02 -7.70925e-01]
21Feb13_183908| [ 8.20815e-01  1.41478e-02  1.57561e+00  3.89599e-01]
21Feb13_183908| [ 5.19426e-01  7.54468e-01 -2.58818e-02 -5.31621e-01]
21Feb13_183908| [ 1.59397e+00  1.31399e+00  4.31820e-02  4.73847e-01]
21Feb13_183908| [ 6.12200e-01 -8.79955e-01 -1.86201e-01 -1.90943e+00]
21Feb13_183908| [ 3.40432e-01  1.02790e+00 -1.15314e+00 -1.40468e+00]
21Feb13_183908| [ 4.70886e-01 -8.98456e-01  2.17497e+00  1.29145e-01]
21Feb13_183908| [ 8.53325e-01  1.53881e+00  8.59108e-01  5.58786e-01]
21Feb13_183908| [-1.34194e+00 -8.61258e-01  4.02439e-01 -9.96468e-01]
21Feb13_183908| [-1.33269e+00  6.41410e-01 -5.15019e-02 -7.72709e-01]
21Feb13_183908| [-4.69262e-01  2.41285e-01 -1.26819e+00 -4.79252e-01]
21Feb13_183908| [-1.25819e+00 -2.15944e-01 -5.82515e-01 -3.71993e-01]
21Feb13_183908| [-2.08817e+00 -2.39077e-01  5.19126e-01 -6.39950e-02]
21Feb13_183908| [-2.16821e-01 -5.79153e-01 -1.25299e-01 -5.39553e-01]
21Feb13_183908| [ 6.63347e-01  2.32524e-01  3.53160e-01 -3.17821e-01]
21Feb13_183908| [ 1.10172e+00  3.34007e-01 -1.28144e+00 -9.99387e-01]
21Feb13_183908| [ 6.14747e-01  1.74699e-02 -2.53533e-01 -4.93268e-01]
21Feb13_183908| [-1.68123e-01 -3.75621e-02 -4.00563e-01 -1.06499e+00]
21Feb13_183908| [ 1.68917e+00  8.38239e-01 -2.68816e-02 -9.26705e-01]
21Feb13_183908| [ 8.16397e-01  1.47216e+00 -3.72165e-01  8.01488e-02]
21Feb13_183908| [-1.87213e-01  3.60063e-01  2.18543e-01  5.02950e-01]
21Feb13_183908| [ 7.33804e-01 -1.95159e-01 -1.82285e+00  5.14853e-01]
21Feb13_183908| [ 6.88558e-01 -1.07087e-01 -2.67856e+00 -1.83088e+00]
21Feb13_183908| [-2.26892e-01 -1.79768e+00  1.38529e+00 -1.06190e+00]
21Feb13_183908| [ 7.06417e-01 -3.75030e-01 -8.33602e-02  1.51313e-02]
21Feb13_183908| [ 4.07669e-01 -4.07600e-02  8.65359e-01 -6.48309e-01]
21Feb13_183908| [ 1.59318e+00  1.49862e+00 -1.22730e+00 -4.75797e-02]
21Feb13_183908| [ 2.23448e+00  5.81611e-01  9.70576e-01 -1.16943e+00]
21Feb13_183908| [ 1.27520e+00  1.46452e-01 -1.77996e+00 -3.68113e-01]
21Feb13_183908| [ 2.64911e-01  1.29363e+00 -7.55651e-01  1.31616e+00]
21Feb13_183908| [-3.15699e-01 -9.42947e-01  3.59613e-01  1.53691e+00]
21Feb13_183908| [-1.83237e+00 -2.82041e-01  1.15458e-01  9.14966e-01]
21Feb13_183908| [ 5.41912e-01  1.03547e+00  1.89459e-01 -3.11293e-01]
21Feb13_183908| [-8.48413e-01 -7.65092e-01  1.52671e+00  2.32680e+00]
21Feb13_183908| [-9.07727e-01  1.26484e+00  1.84065e-03  2.89181e-01]
21Feb13_183908| [-7.76721e-01  1.73275e+00 -2.00253e-01  5.13027e-01]
21Feb13_183908| [-3.14822e-01  6.65239e-01 -8.33827e-01 -9.31808e-01]
21Feb13_183908| [-1.06577e+00 -6.56160e-01  7.07962e-01 -7.41742e-01]
21Feb13_183908| [ 1.37495e+00 -9.98537e-01 -1.26291e-01  7.35705e-01]
21Feb13_183908| [-7.81532e-01  4.81725e-01  9.72613e-01  1.14711e+00]
21Feb13_183908| [ 1.39228e+00 -1.10795e+00  6.18742e-01 -8.23983e-01]
21Feb13_183908| [-1.21496e+00 -9.27339e-01  1.46112e+00 -1.58060e-01]
21Feb13_183908| [-1.47877e-01  3.00039e-01 -1.16124e-01 -2.49785e-01]
21Feb13_183908| [ 1.34618e+00 -4.10722e-01 -2.01150e+00 -2.75159e-01]
21Feb13_183908| [ 3.26027e-01 -2.31842e+00 -9.63079e-01  1.40506e+00]
21Feb13_183908| [ 2.37497e-01 -8.86651e-02 -8.09815e-03 -2.75301e-01]
21Feb13_183908| [-9.43558e-01  3.27714e-02  1.37072e+00 -6.87180e-01]
21Feb13_183908| [-2.73140e-01 -1.03409e+00  4.18114e-01  2.63792e+00]
21Feb13_183908| [-1.29274e+00  5.68486e-01 -3.70493e-01 -1.79609e+00]]
21Feb13_183908|-- Bias --
21Feb13_183908|[ 0.47797 -0.46841  0.80042  0.85704]
21Feb13_183908|Layer 1:
21Feb13_183908|-- Config --
21Feb13_183908|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_183908|-- Weights --
21Feb13_183908|[[-0.07388 -0.44630  0.00582 -0.38753  0.04666]
21Feb13_183908| [ 0.56150  0.18177  0.10598  0.12676 -0.22741]
21Feb13_183908| [ 0.36995 -0.63866  0.59360 -0.34067  0.28075]
21Feb13_183908| [-0.02730 -0.58961 -0.21658  0.00403  0.22317]]
21Feb13_183908|-- Bias --
21Feb13_183908|[ 0.60577  0.01906  0.49354 -0.12722 -0.48520]
21Feb13_183908|Layer 2:
21Feb13_183908|-- Config --
21Feb13_183908|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_183908|-- Weights --
21Feb13_183908|[[ 0.86200 -1.33193]
21Feb13_183908| [-2.22124  1.37832]
21Feb13_183908| [-0.02313 -0.06435]
21Feb13_183908| [ 0.48998 -0.56779]
21Feb13_183908| [-0.10810  0.00308]]
21Feb13_183908|-- Bias --
21Feb13_183908|[-0.07638  0.02979]
21Feb13_183908|Predicting the validation and test data with the Best final individual.
21Feb13_183916| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_183916|-----------  ------------------  --------------------  ----------
21Feb13_183916|Validation         40.26                  18            0.06371
21Feb13_183916|   Test            35.79                  18            0.04125
21Feb13_183916|-------------------- Test #3 --------------------
21Feb13_183916|Best final individual weights
21Feb13_183916|Individual:
21Feb13_183916|-- Constant hidden layers --
21Feb13_183916|False
21Feb13_183916|Layer 0:
21Feb13_183916|-- Config --
21Feb13_183916|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_183916|-- Weights --
21Feb13_183916|[[-1.87472e-01 -1.88423e+00 -9.87479e-02 -4.31576e-01]
21Feb13_183916| [ 7.47578e-01 -8.61812e-01 -1.03859e+00  6.81397e-02]
21Feb13_183916| [-1.04232e+00  1.71195e+00 -4.16856e-01 -4.98514e-01]
21Feb13_183916| [ 1.35466e+00 -6.63542e-01  7.24879e-01  2.25979e-02]
21Feb13_183916| [ 2.16981e-01 -2.10882e+00 -1.46954e+00 -6.08573e-01]
21Feb13_183916| [ 6.47638e-02  1.08814e+00  6.86203e-02  9.30175e-01]
21Feb13_183916| [-2.44488e+00  1.55556e+00  1.90865e-01  1.59360e-01]
21Feb13_183916| [-6.06958e-01 -1.30643e-01  7.80295e-01  1.68866e+00]
21Feb13_183916| [ 7.24409e-01 -1.27327e+00 -2.36592e-02 -7.70925e-01]
21Feb13_183916| [ 8.20815e-01  1.41478e-02  1.57561e+00  3.89599e-01]
21Feb13_183916| [ 5.19426e-01  7.54468e-01 -2.58818e-02 -5.31621e-01]
21Feb13_183916| [ 1.59397e+00  1.31399e+00  4.31820e-02  4.73847e-01]
21Feb13_183916| [ 6.12200e-01 -8.79955e-01 -1.86201e-01 -1.90943e+00]
21Feb13_183916| [ 3.40432e-01  1.02790e+00 -1.15314e+00 -1.40468e+00]
21Feb13_183916| [ 4.70886e-01 -8.98456e-01  2.17497e+00  1.29145e-01]
21Feb13_183916| [ 8.53325e-01  1.53881e+00  8.59108e-01  5.58786e-01]
21Feb13_183916| [-1.34194e+00 -8.61258e-01  4.02439e-01 -9.96468e-01]
21Feb13_183916| [-1.33269e+00  6.41410e-01 -5.15019e-02 -7.72709e-01]
21Feb13_183916| [-4.69262e-01  2.41285e-01 -1.26819e+00 -4.79252e-01]
21Feb13_183916| [-1.25819e+00 -2.15944e-01 -5.82515e-01 -3.71993e-01]
21Feb13_183916| [-2.08817e+00 -2.39077e-01  5.19126e-01 -6.39950e-02]
21Feb13_183916| [-2.16821e-01 -5.79153e-01 -1.25299e-01 -5.39553e-01]
21Feb13_183916| [ 6.63347e-01  2.32524e-01  3.53160e-01 -3.17821e-01]
21Feb13_183916| [ 1.10172e+00  3.34007e-01 -1.28144e+00 -9.99387e-01]
21Feb13_183916| [ 6.14747e-01  1.74699e-02 -2.53533e-01 -4.93268e-01]
21Feb13_183916| [-1.68123e-01 -3.75621e-02 -4.00563e-01 -1.06499e+00]
21Feb13_183916| [ 1.68917e+00  8.38239e-01 -2.68816e-02 -9.26705e-01]
21Feb13_183916| [ 8.16397e-01  1.47216e+00 -3.72165e-01  8.01488e-02]
21Feb13_183916| [-1.87213e-01  3.60063e-01  2.18543e-01  5.02950e-01]
21Feb13_183916| [ 7.33804e-01 -1.95159e-01 -1.82285e+00  5.14853e-01]
21Feb13_183916| [ 6.88558e-01 -1.07087e-01 -2.67856e+00 -1.83088e+00]
21Feb13_183916| [-2.26892e-01 -1.79768e+00  1.38529e+00 -1.06190e+00]
21Feb13_183916| [ 7.06417e-01 -3.75030e-01 -8.33602e-02  1.51313e-02]
21Feb13_183916| [ 4.07669e-01 -4.07600e-02  8.65359e-01 -6.48309e-01]
21Feb13_183916| [ 1.59318e+00  1.49862e+00 -1.22730e+00 -4.75797e-02]
21Feb13_183916| [ 2.23448e+00  5.81611e-01  9.70576e-01 -1.16943e+00]
21Feb13_183916| [ 1.27520e+00  1.46452e-01 -1.77996e+00 -3.68113e-01]
21Feb13_183916| [ 2.64911e-01  1.29363e+00 -7.55651e-01  1.31616e+00]
21Feb13_183916| [-3.15699e-01 -9.42947e-01  3.59613e-01  1.53691e+00]
21Feb13_183916| [-1.83237e+00 -2.82041e-01  1.15458e-01  9.14966e-01]
21Feb13_183916| [ 5.41912e-01  1.03547e+00  1.89459e-01 -3.11293e-01]
21Feb13_183916| [-8.48413e-01 -7.65092e-01  1.52671e+00  2.32680e+00]
21Feb13_183916| [-9.07727e-01  1.26484e+00  1.84065e-03  2.89181e-01]
21Feb13_183916| [-7.76721e-01  1.73275e+00 -2.00253e-01  5.13027e-01]
21Feb13_183916| [-3.14822e-01  6.65239e-01 -8.33827e-01 -9.31808e-01]
21Feb13_183916| [-1.06577e+00 -6.56160e-01  7.07962e-01 -7.41742e-01]
21Feb13_183916| [ 1.37495e+00 -9.98537e-01 -1.26291e-01  7.35705e-01]
21Feb13_183916| [-7.81532e-01  4.81725e-01  9.72613e-01  1.14711e+00]
21Feb13_183916| [ 1.39228e+00 -1.10795e+00  6.18742e-01 -8.23983e-01]
21Feb13_183916| [-1.21496e+00 -9.27339e-01  1.46112e+00 -1.58060e-01]
21Feb13_183916| [-1.47877e-01  3.00039e-01 -1.16124e-01 -2.49785e-01]
21Feb13_183916| [ 1.34618e+00 -4.10722e-01 -2.01150e+00 -2.75159e-01]
21Feb13_183916| [ 3.26027e-01 -2.31842e+00 -9.63079e-01  1.40506e+00]
21Feb13_183916| [ 2.37497e-01 -8.86651e-02 -8.09815e-03 -2.75301e-01]
21Feb13_183916| [-9.43558e-01  3.27714e-02  1.37072e+00 -6.87180e-01]
21Feb13_183916| [-2.73140e-01 -1.03409e+00  4.18114e-01  2.63792e+00]
21Feb13_183916| [-1.29274e+00  5.68486e-01 -3.70493e-01 -1.79609e+00]]
21Feb13_183916|-- Bias --
21Feb13_183916|[ 0.47797 -0.46841  0.80042  0.85704]
21Feb13_183916|Layer 1:
21Feb13_183916|-- Config --
21Feb13_183916|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_183916|-- Weights --
21Feb13_183916|[[-0.07388 -0.44630  0.00582 -0.38753  0.04666]
21Feb13_183916| [ 0.56150  0.18177  0.10598  0.12676 -0.22741]
21Feb13_183916| [ 0.36995 -0.63866  0.59360 -0.34067  0.28075]
21Feb13_183916| [-0.02730 -0.58961 -0.21658  0.00403  0.22317]]
21Feb13_183916|-- Bias --
21Feb13_183916|[ 0.60577  0.01906  0.49354 -0.12722 -0.48520]
21Feb13_183916|Layer 2:
21Feb13_183916|-- Config --
21Feb13_183916|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_183916|-- Weights --
21Feb13_183916|[[ 0.86200 -1.33193]
21Feb13_183916| [-2.22124  1.37832]
21Feb13_183916| [-0.02313 -0.06435]
21Feb13_183916| [ 0.48998 -0.56779]
21Feb13_183916| [-0.10810  0.00308]]
21Feb13_183916|-- Bias --
21Feb13_183916|[-0.07638  0.02979]
21Feb13_183916|Predicting the validation and test data with the Best final individual.
21Feb13_183923| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_183923|-----------  ------------------  --------------------  ----------
21Feb13_183923|Validation         45.30                  18            0.66642
21Feb13_183923|   Test            35.62                  18            0.06429
21Feb13_183923|-------------------- Test #4 --------------------
21Feb13_183923|Best final individual weights
21Feb13_183923|Individual:
21Feb13_183923|-- Constant hidden layers --
21Feb13_183923|False
21Feb13_183923|Layer 0:
21Feb13_183923|-- Config --
21Feb13_183923|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_183923|-- Weights --
21Feb13_183923|[[-1.87472e-01 -1.88423e+00 -9.87479e-02 -4.31576e-01]
21Feb13_183923| [ 7.47578e-01 -8.61812e-01 -1.03859e+00  6.81397e-02]
21Feb13_183923| [-1.04232e+00  1.71195e+00 -4.16856e-01 -4.98514e-01]
21Feb13_183923| [ 1.35466e+00 -6.63542e-01  7.24879e-01  2.25979e-02]
21Feb13_183923| [ 2.16981e-01 -2.10882e+00 -1.46954e+00 -6.08573e-01]
21Feb13_183923| [ 6.47638e-02  1.08814e+00  6.86203e-02  9.30175e-01]
21Feb13_183923| [-2.44488e+00  1.55556e+00  1.90865e-01  1.59360e-01]
21Feb13_183923| [-6.06958e-01 -1.30643e-01  7.80295e-01  1.68866e+00]
21Feb13_183923| [ 7.24409e-01 -1.27327e+00 -2.36592e-02 -7.70925e-01]
21Feb13_183923| [ 8.20815e-01  1.41478e-02  1.57561e+00  3.89599e-01]
21Feb13_183923| [ 5.19426e-01  7.54468e-01 -2.58818e-02 -5.31621e-01]
21Feb13_183923| [ 1.59397e+00  1.31399e+00  4.31820e-02  4.73847e-01]
21Feb13_183923| [ 6.12200e-01 -8.79955e-01 -1.86201e-01 -1.90943e+00]
21Feb13_183923| [ 3.40432e-01  1.02790e+00 -1.15314e+00 -1.40468e+00]
21Feb13_183923| [ 4.70886e-01 -8.98456e-01  2.17497e+00  1.29145e-01]
21Feb13_183923| [ 8.53325e-01  1.53881e+00  8.59108e-01  5.58786e-01]
21Feb13_183923| [-1.34194e+00 -8.61258e-01  4.02439e-01 -9.96468e-01]
21Feb13_183923| [-1.33269e+00  6.41410e-01 -5.15019e-02 -7.72709e-01]
21Feb13_183923| [-4.69262e-01  2.41285e-01 -1.26819e+00 -4.79252e-01]
21Feb13_183923| [-1.25819e+00 -2.15944e-01 -5.82515e-01 -3.71993e-01]
21Feb13_183923| [-2.08817e+00 -2.39077e-01  5.19126e-01 -6.39950e-02]
21Feb13_183923| [-2.16821e-01 -5.79153e-01 -1.25299e-01 -5.39553e-01]
21Feb13_183923| [ 6.63347e-01  2.32524e-01  3.53160e-01 -3.17821e-01]
21Feb13_183923| [ 1.10172e+00  3.34007e-01 -1.28144e+00 -9.99387e-01]
21Feb13_183923| [ 6.14747e-01  1.74699e-02 -2.53533e-01 -4.93268e-01]
21Feb13_183923| [-1.68123e-01 -3.75621e-02 -4.00563e-01 -1.06499e+00]
21Feb13_183923| [ 1.68917e+00  8.38239e-01 -2.68816e-02 -9.26705e-01]
21Feb13_183923| [ 8.16397e-01  1.47216e+00 -3.72165e-01  8.01488e-02]
21Feb13_183923| [-1.87213e-01  3.60063e-01  2.18543e-01  5.02950e-01]
21Feb13_183923| [ 7.33804e-01 -1.95159e-01 -1.82285e+00  5.14853e-01]
21Feb13_183923| [ 6.88558e-01 -1.07087e-01 -2.67856e+00 -1.83088e+00]
21Feb13_183923| [-2.26892e-01 -1.79768e+00  1.38529e+00 -1.06190e+00]
21Feb13_183923| [ 7.06417e-01 -3.75030e-01 -8.33602e-02  1.51313e-02]
21Feb13_183923| [ 4.07669e-01 -4.07600e-02  8.65359e-01 -6.48309e-01]
21Feb13_183923| [ 1.59318e+00  1.49862e+00 -1.22730e+00 -4.75797e-02]
21Feb13_183923| [ 2.23448e+00  5.81611e-01  9.70576e-01 -1.16943e+00]
21Feb13_183923| [ 1.27520e+00  1.46452e-01 -1.77996e+00 -3.68113e-01]
21Feb13_183923| [ 2.64911e-01  1.29363e+00 -7.55651e-01  1.31616e+00]
21Feb13_183923| [-3.15699e-01 -9.42947e-01  3.59613e-01  1.53691e+00]
21Feb13_183923| [-1.83237e+00 -2.82041e-01  1.15458e-01  9.14966e-01]
21Feb13_183923| [ 5.41912e-01  1.03547e+00  1.89459e-01 -3.11293e-01]
21Feb13_183923| [-8.48413e-01 -7.65092e-01  1.52671e+00  2.32680e+00]
21Feb13_183923| [-9.07727e-01  1.26484e+00  1.84065e-03  2.89181e-01]
21Feb13_183923| [-7.76721e-01  1.73275e+00 -2.00253e-01  5.13027e-01]
21Feb13_183923| [-3.14822e-01  6.65239e-01 -8.33827e-01 -9.31808e-01]
21Feb13_183923| [-1.06577e+00 -6.56160e-01  7.07962e-01 -7.41742e-01]
21Feb13_183923| [ 1.37495e+00 -9.98537e-01 -1.26291e-01  7.35705e-01]
21Feb13_183923| [-7.81532e-01  4.81725e-01  9.72613e-01  1.14711e+00]
21Feb13_183923| [ 1.39228e+00 -1.10795e+00  6.18742e-01 -8.23983e-01]
21Feb13_183923| [-1.21496e+00 -9.27339e-01  1.46112e+00 -1.58060e-01]
21Feb13_183923| [-1.47877e-01  3.00039e-01 -1.16124e-01 -2.49785e-01]
21Feb13_183923| [ 1.34618e+00 -4.10722e-01 -2.01150e+00 -2.75159e-01]
21Feb13_183923| [ 3.26027e-01 -2.31842e+00 -9.63079e-01  1.40506e+00]
21Feb13_183923| [ 2.37497e-01 -8.86651e-02 -8.09815e-03 -2.75301e-01]
21Feb13_183923| [-9.43558e-01  3.27714e-02  1.37072e+00 -6.87180e-01]
21Feb13_183923| [-2.73140e-01 -1.03409e+00  4.18114e-01  2.63792e+00]
21Feb13_183923| [-1.29274e+00  5.68486e-01 -3.70493e-01 -1.79609e+00]]
21Feb13_183923|-- Bias --
21Feb13_183923|[ 0.47797 -0.46841  0.80042  0.85704]
21Feb13_183923|Layer 1:
21Feb13_183923|-- Config --
21Feb13_183923|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_183923|-- Weights --
21Feb13_183923|[[-0.07388 -0.44630  0.00582 -0.38753  0.04666]
21Feb13_183923| [ 0.56150  0.18177  0.10598  0.12676 -0.22741]
21Feb13_183923| [ 0.36995 -0.63866  0.59360 -0.34067  0.28075]
21Feb13_183923| [-0.02730 -0.58961 -0.21658  0.00403  0.22317]]
21Feb13_183923|-- Bias --
21Feb13_183923|[ 0.60577  0.01906  0.49354 -0.12722 -0.48520]
21Feb13_183923|Layer 2:
21Feb13_183923|-- Config --
21Feb13_183923|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_183923|-- Weights --
21Feb13_183923|[[ 0.86200 -1.33193]
21Feb13_183923| [-2.22124  1.37832]
21Feb13_183923| [-0.02313 -0.06435]
21Feb13_183923| [ 0.48998 -0.56779]
21Feb13_183923| [-0.10810  0.00308]]
21Feb13_183923|-- Bias --
21Feb13_183923|[-0.07638  0.02979]
21Feb13_183923|Predicting the validation and test data with the Best final individual.
21Feb13_183931| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_183931|-----------  ------------------  --------------------  ----------
21Feb13_183931|Validation         39.57                  18            0.30443
21Feb13_183931|   Test            38.05                  18            0.39074
21Feb13_183931|-------------------- Test #5 --------------------
21Feb13_183931|Best final individual weights
21Feb13_183931|Individual:
21Feb13_183931|-- Constant hidden layers --
21Feb13_183931|False
21Feb13_183931|Layer 0:
21Feb13_183931|-- Config --
21Feb13_183931|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_183931|-- Weights --
21Feb13_183931|[[-1.87472e-01 -1.88423e+00 -9.87479e-02 -4.31576e-01]
21Feb13_183931| [ 7.47578e-01 -8.61812e-01 -1.03859e+00  6.81397e-02]
21Feb13_183931| [-1.04232e+00  1.71195e+00 -4.16856e-01 -4.98514e-01]
21Feb13_183931| [ 1.35466e+00 -6.63542e-01  7.24879e-01  2.25979e-02]
21Feb13_183931| [ 2.16981e-01 -2.10882e+00 -1.46954e+00 -6.08573e-01]
21Feb13_183931| [ 6.47638e-02  1.08814e+00  6.86203e-02  9.30175e-01]
21Feb13_183931| [-2.44488e+00  1.55556e+00  1.90865e-01  1.59360e-01]
21Feb13_183931| [-6.06958e-01 -1.30643e-01  7.80295e-01  1.68866e+00]
21Feb13_183931| [ 7.24409e-01 -1.27327e+00 -2.36592e-02 -7.70925e-01]
21Feb13_183931| [ 8.20815e-01  1.41478e-02  1.57561e+00  3.89599e-01]
21Feb13_183931| [ 5.19426e-01  7.54468e-01 -2.58818e-02 -5.31621e-01]
21Feb13_183931| [ 1.59397e+00  1.31399e+00  4.31820e-02  4.73847e-01]
21Feb13_183931| [ 6.12200e-01 -8.79955e-01 -1.86201e-01 -1.90943e+00]
21Feb13_183931| [ 3.40432e-01  1.02790e+00 -1.15314e+00 -1.40468e+00]
21Feb13_183931| [ 4.70886e-01 -8.98456e-01  2.17497e+00  1.29145e-01]
21Feb13_183931| [ 8.53325e-01  1.53881e+00  8.59108e-01  5.58786e-01]
21Feb13_183931| [-1.34194e+00 -8.61258e-01  4.02439e-01 -9.96468e-01]
21Feb13_183931| [-1.33269e+00  6.41410e-01 -5.15019e-02 -7.72709e-01]
21Feb13_183931| [-4.69262e-01  2.41285e-01 -1.26819e+00 -4.79252e-01]
21Feb13_183931| [-1.25819e+00 -2.15944e-01 -5.82515e-01 -3.71993e-01]
21Feb13_183931| [-2.08817e+00 -2.39077e-01  5.19126e-01 -6.39950e-02]
21Feb13_183931| [-2.16821e-01 -5.79153e-01 -1.25299e-01 -5.39553e-01]
21Feb13_183931| [ 6.63347e-01  2.32524e-01  3.53160e-01 -3.17821e-01]
21Feb13_183931| [ 1.10172e+00  3.34007e-01 -1.28144e+00 -9.99387e-01]
21Feb13_183931| [ 6.14747e-01  1.74699e-02 -2.53533e-01 -4.93268e-01]
21Feb13_183931| [-1.68123e-01 -3.75621e-02 -4.00563e-01 -1.06499e+00]
21Feb13_183931| [ 1.68917e+00  8.38239e-01 -2.68816e-02 -9.26705e-01]
21Feb13_183931| [ 8.16397e-01  1.47216e+00 -3.72165e-01  8.01488e-02]
21Feb13_183931| [-1.87213e-01  3.60063e-01  2.18543e-01  5.02950e-01]
21Feb13_183931| [ 7.33804e-01 -1.95159e-01 -1.82285e+00  5.14853e-01]
21Feb13_183931| [ 6.88558e-01 -1.07087e-01 -2.67856e+00 -1.83088e+00]
21Feb13_183931| [-2.26892e-01 -1.79768e+00  1.38529e+00 -1.06190e+00]
21Feb13_183931| [ 7.06417e-01 -3.75030e-01 -8.33602e-02  1.51313e-02]
21Feb13_183931| [ 4.07669e-01 -4.07600e-02  8.65359e-01 -6.48309e-01]
21Feb13_183931| [ 1.59318e+00  1.49862e+00 -1.22730e+00 -4.75797e-02]
21Feb13_183931| [ 2.23448e+00  5.81611e-01  9.70576e-01 -1.16943e+00]
21Feb13_183931| [ 1.27520e+00  1.46452e-01 -1.77996e+00 -3.68113e-01]
21Feb13_183931| [ 2.64911e-01  1.29363e+00 -7.55651e-01  1.31616e+00]
21Feb13_183931| [-3.15699e-01 -9.42947e-01  3.59613e-01  1.53691e+00]
21Feb13_183931| [-1.83237e+00 -2.82041e-01  1.15458e-01  9.14966e-01]
21Feb13_183931| [ 5.41912e-01  1.03547e+00  1.89459e-01 -3.11293e-01]
21Feb13_183931| [-8.48413e-01 -7.65092e-01  1.52671e+00  2.32680e+00]
21Feb13_183931| [-9.07727e-01  1.26484e+00  1.84065e-03  2.89181e-01]
21Feb13_183931| [-7.76721e-01  1.73275e+00 -2.00253e-01  5.13027e-01]
21Feb13_183931| [-3.14822e-01  6.65239e-01 -8.33827e-01 -9.31808e-01]
21Feb13_183931| [-1.06577e+00 -6.56160e-01  7.07962e-01 -7.41742e-01]
21Feb13_183931| [ 1.37495e+00 -9.98537e-01 -1.26291e-01  7.35705e-01]
21Feb13_183931| [-7.81532e-01  4.81725e-01  9.72613e-01  1.14711e+00]
21Feb13_183931| [ 1.39228e+00 -1.10795e+00  6.18742e-01 -8.23983e-01]
21Feb13_183931| [-1.21496e+00 -9.27339e-01  1.46112e+00 -1.58060e-01]
21Feb13_183931| [-1.47877e-01  3.00039e-01 -1.16124e-01 -2.49785e-01]
21Feb13_183931| [ 1.34618e+00 -4.10722e-01 -2.01150e+00 -2.75159e-01]
21Feb13_183931| [ 3.26027e-01 -2.31842e+00 -9.63079e-01  1.40506e+00]
21Feb13_183931| [ 2.37497e-01 -8.86651e-02 -8.09815e-03 -2.75301e-01]
21Feb13_183931| [-9.43558e-01  3.27714e-02  1.37072e+00 -6.87180e-01]
21Feb13_183931| [-2.73140e-01 -1.03409e+00  4.18114e-01  2.63792e+00]
21Feb13_183931| [-1.29274e+00  5.68486e-01 -3.70493e-01 -1.79609e+00]]
21Feb13_183931|-- Bias --
21Feb13_183931|[ 0.47797 -0.46841  0.80042  0.85704]
21Feb13_183931|Layer 1:
21Feb13_183931|-- Config --
21Feb13_183931|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_183931|-- Weights --
21Feb13_183931|[[-0.07388 -0.44630  0.00582 -0.38753  0.04666]
21Feb13_183931| [ 0.56150  0.18177  0.10598  0.12676 -0.22741]
21Feb13_183931| [ 0.36995 -0.63866  0.59360 -0.34067  0.28075]
21Feb13_183931| [-0.02730 -0.58961 -0.21658  0.00403  0.22317]]
21Feb13_183931|-- Bias --
21Feb13_183931|[ 0.60577  0.01906  0.49354 -0.12722 -0.48520]
21Feb13_183931|Layer 2:
21Feb13_183931|-- Config --
21Feb13_183931|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_183931|-- Weights --
21Feb13_183931|[[ 0.86200 -1.33193]
21Feb13_183931| [-2.22124  1.37832]
21Feb13_183931| [-0.02313 -0.06435]
21Feb13_183931| [ 0.48998 -0.56779]
21Feb13_183931| [-0.10810  0.00308]]
21Feb13_183931|-- Bias --
21Feb13_183931|[-0.07638  0.02979]
21Feb13_183931|Predicting the validation and test data with the Best final individual.
21Feb13_183938| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_183938|-----------  ------------------  --------------------  ----------
21Feb13_183938|Validation         41.48                  18            0.04587
21Feb13_183938|   Test            35.45                  18            0.06151
21Feb13_183938|-------------------- Test #6 --------------------
21Feb13_183938|Best final individual weights
21Feb13_183938|Individual:
21Feb13_183938|-- Constant hidden layers --
21Feb13_183938|False
21Feb13_183938|Layer 0:
21Feb13_183938|-- Config --
21Feb13_183938|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_183938|-- Weights --
21Feb13_183938|[[-1.87472e-01 -1.88423e+00 -9.87479e-02 -4.31576e-01]
21Feb13_183938| [ 7.47578e-01 -8.61812e-01 -1.03859e+00  6.81397e-02]
21Feb13_183938| [-1.04232e+00  1.71195e+00 -4.16856e-01 -4.98514e-01]
21Feb13_183938| [ 1.35466e+00 -6.63542e-01  7.24879e-01  2.25979e-02]
21Feb13_183938| [ 2.16981e-01 -2.10882e+00 -1.46954e+00 -6.08573e-01]
21Feb13_183938| [ 6.47638e-02  1.08814e+00  6.86203e-02  9.30175e-01]
21Feb13_183938| [-2.44488e+00  1.55556e+00  1.90865e-01  1.59360e-01]
21Feb13_183938| [-6.06958e-01 -1.30643e-01  7.80295e-01  1.68866e+00]
21Feb13_183938| [ 7.24409e-01 -1.27327e+00 -2.36592e-02 -7.70925e-01]
21Feb13_183938| [ 8.20815e-01  1.41478e-02  1.57561e+00  3.89599e-01]
21Feb13_183938| [ 5.19426e-01  7.54468e-01 -2.58818e-02 -5.31621e-01]
21Feb13_183938| [ 1.59397e+00  1.31399e+00  4.31820e-02  4.73847e-01]
21Feb13_183938| [ 6.12200e-01 -8.79955e-01 -1.86201e-01 -1.90943e+00]
21Feb13_183938| [ 3.40432e-01  1.02790e+00 -1.15314e+00 -1.40468e+00]
21Feb13_183938| [ 4.70886e-01 -8.98456e-01  2.17497e+00  1.29145e-01]
21Feb13_183938| [ 8.53325e-01  1.53881e+00  8.59108e-01  5.58786e-01]
21Feb13_183938| [-1.34194e+00 -8.61258e-01  4.02439e-01 -9.96468e-01]
21Feb13_183938| [-1.33269e+00  6.41410e-01 -5.15019e-02 -7.72709e-01]
21Feb13_183938| [-4.69262e-01  2.41285e-01 -1.26819e+00 -4.79252e-01]
21Feb13_183938| [-1.25819e+00 -2.15944e-01 -5.82515e-01 -3.71993e-01]
21Feb13_183938| [-2.08817e+00 -2.39077e-01  5.19126e-01 -6.39950e-02]
21Feb13_183938| [-2.16821e-01 -5.79153e-01 -1.25299e-01 -5.39553e-01]
21Feb13_183938| [ 6.63347e-01  2.32524e-01  3.53160e-01 -3.17821e-01]
21Feb13_183938| [ 1.10172e+00  3.34007e-01 -1.28144e+00 -9.99387e-01]
21Feb13_183938| [ 6.14747e-01  1.74699e-02 -2.53533e-01 -4.93268e-01]
21Feb13_183938| [-1.68123e-01 -3.75621e-02 -4.00563e-01 -1.06499e+00]
21Feb13_183938| [ 1.68917e+00  8.38239e-01 -2.68816e-02 -9.26705e-01]
21Feb13_183938| [ 8.16397e-01  1.47216e+00 -3.72165e-01  8.01488e-02]
21Feb13_183938| [-1.87213e-01  3.60063e-01  2.18543e-01  5.02950e-01]
21Feb13_183938| [ 7.33804e-01 -1.95159e-01 -1.82285e+00  5.14853e-01]
21Feb13_183938| [ 6.88558e-01 -1.07087e-01 -2.67856e+00 -1.83088e+00]
21Feb13_183938| [-2.26892e-01 -1.79768e+00  1.38529e+00 -1.06190e+00]
21Feb13_183938| [ 7.06417e-01 -3.75030e-01 -8.33602e-02  1.51313e-02]
21Feb13_183938| [ 4.07669e-01 -4.07600e-02  8.65359e-01 -6.48309e-01]
21Feb13_183938| [ 1.59318e+00  1.49862e+00 -1.22730e+00 -4.75797e-02]
21Feb13_183938| [ 2.23448e+00  5.81611e-01  9.70576e-01 -1.16943e+00]
21Feb13_183938| [ 1.27520e+00  1.46452e-01 -1.77996e+00 -3.68113e-01]
21Feb13_183938| [ 2.64911e-01  1.29363e+00 -7.55651e-01  1.31616e+00]
21Feb13_183938| [-3.15699e-01 -9.42947e-01  3.59613e-01  1.53691e+00]
21Feb13_183938| [-1.83237e+00 -2.82041e-01  1.15458e-01  9.14966e-01]
21Feb13_183938| [ 5.41912e-01  1.03547e+00  1.89459e-01 -3.11293e-01]
21Feb13_183938| [-8.48413e-01 -7.65092e-01  1.52671e+00  2.32680e+00]
21Feb13_183938| [-9.07727e-01  1.26484e+00  1.84065e-03  2.89181e-01]
21Feb13_183938| [-7.76721e-01  1.73275e+00 -2.00253e-01  5.13027e-01]
21Feb13_183938| [-3.14822e-01  6.65239e-01 -8.33827e-01 -9.31808e-01]
21Feb13_183938| [-1.06577e+00 -6.56160e-01  7.07962e-01 -7.41742e-01]
21Feb13_183938| [ 1.37495e+00 -9.98537e-01 -1.26291e-01  7.35705e-01]
21Feb13_183938| [-7.81532e-01  4.81725e-01  9.72613e-01  1.14711e+00]
21Feb13_183938| [ 1.39228e+00 -1.10795e+00  6.18742e-01 -8.23983e-01]
21Feb13_183938| [-1.21496e+00 -9.27339e-01  1.46112e+00 -1.58060e-01]
21Feb13_183938| [-1.47877e-01  3.00039e-01 -1.16124e-01 -2.49785e-01]
21Feb13_183938| [ 1.34618e+00 -4.10722e-01 -2.01150e+00 -2.75159e-01]
21Feb13_183938| [ 3.26027e-01 -2.31842e+00 -9.63079e-01  1.40506e+00]
21Feb13_183938| [ 2.37497e-01 -8.86651e-02 -8.09815e-03 -2.75301e-01]
21Feb13_183938| [-9.43558e-01  3.27714e-02  1.37072e+00 -6.87180e-01]
21Feb13_183938| [-2.73140e-01 -1.03409e+00  4.18114e-01  2.63792e+00]
21Feb13_183938| [-1.29274e+00  5.68486e-01 -3.70493e-01 -1.79609e+00]]
21Feb13_183938|-- Bias --
21Feb13_183938|[ 0.47797 -0.46841  0.80042  0.85704]
21Feb13_183938|Layer 1:
21Feb13_183938|-- Config --
21Feb13_183938|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_183938|-- Weights --
21Feb13_183938|[[-0.07388 -0.44630  0.00582 -0.38753  0.04666]
21Feb13_183938| [ 0.56150  0.18177  0.10598  0.12676 -0.22741]
21Feb13_183938| [ 0.36995 -0.63866  0.59360 -0.34067  0.28075]
21Feb13_183938| [-0.02730 -0.58961 -0.21658  0.00403  0.22317]]
21Feb13_183938|-- Bias --
21Feb13_183938|[ 0.60577  0.01906  0.49354 -0.12722 -0.48520]
21Feb13_183938|Layer 2:
21Feb13_183938|-- Config --
21Feb13_183938|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_183938|-- Weights --
21Feb13_183938|[[ 0.86200 -1.33193]
21Feb13_183938| [-2.22124  1.37832]
21Feb13_183938| [-0.02313 -0.06435]
21Feb13_183938| [ 0.48998 -0.56779]
21Feb13_183938| [-0.10810  0.00308]]
21Feb13_183938|-- Bias --
21Feb13_183938|[-0.07638  0.02979]
21Feb13_183938|Predicting the validation and test data with the Best final individual.
21Feb13_183945| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_183945|-----------  ------------------  --------------------  ----------
21Feb13_183945|Validation         40.43                  18            0.30907
21Feb13_183945|   Test            36.32                  18            0.09753
21Feb13_183945|-------------------- Test #7 --------------------
21Feb13_183945|Best final individual weights
21Feb13_183945|Individual:
21Feb13_183945|-- Constant hidden layers --
21Feb13_183945|False
21Feb13_183945|Layer 0:
21Feb13_183945|-- Config --
21Feb13_183945|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_183945|-- Weights --
21Feb13_183945|[[-1.87472e-01 -1.88423e+00 -9.87479e-02 -4.31576e-01]
21Feb13_183945| [ 7.47578e-01 -8.61812e-01 -1.03859e+00  6.81397e-02]
21Feb13_183945| [-1.04232e+00  1.71195e+00 -4.16856e-01 -4.98514e-01]
21Feb13_183945| [ 1.35466e+00 -6.63542e-01  7.24879e-01  2.25979e-02]
21Feb13_183945| [ 2.16981e-01 -2.10882e+00 -1.46954e+00 -6.08573e-01]
21Feb13_183945| [ 6.47638e-02  1.08814e+00  6.86203e-02  9.30175e-01]
21Feb13_183945| [-2.44488e+00  1.55556e+00  1.90865e-01  1.59360e-01]
21Feb13_183945| [-6.06958e-01 -1.30643e-01  7.80295e-01  1.68866e+00]
21Feb13_183945| [ 7.24409e-01 -1.27327e+00 -2.36592e-02 -7.70925e-01]
21Feb13_183945| [ 8.20815e-01  1.41478e-02  1.57561e+00  3.89599e-01]
21Feb13_183945| [ 5.19426e-01  7.54468e-01 -2.58818e-02 -5.31621e-01]
21Feb13_183945| [ 1.59397e+00  1.31399e+00  4.31820e-02  4.73847e-01]
21Feb13_183945| [ 6.12200e-01 -8.79955e-01 -1.86201e-01 -1.90943e+00]
21Feb13_183945| [ 3.40432e-01  1.02790e+00 -1.15314e+00 -1.40468e+00]
21Feb13_183945| [ 4.70886e-01 -8.98456e-01  2.17497e+00  1.29145e-01]
21Feb13_183945| [ 8.53325e-01  1.53881e+00  8.59108e-01  5.58786e-01]
21Feb13_183945| [-1.34194e+00 -8.61258e-01  4.02439e-01 -9.96468e-01]
21Feb13_183945| [-1.33269e+00  6.41410e-01 -5.15019e-02 -7.72709e-01]
21Feb13_183945| [-4.69262e-01  2.41285e-01 -1.26819e+00 -4.79252e-01]
21Feb13_183945| [-1.25819e+00 -2.15944e-01 -5.82515e-01 -3.71993e-01]
21Feb13_183945| [-2.08817e+00 -2.39077e-01  5.19126e-01 -6.39950e-02]
21Feb13_183945| [-2.16821e-01 -5.79153e-01 -1.25299e-01 -5.39553e-01]
21Feb13_183945| [ 6.63347e-01  2.32524e-01  3.53160e-01 -3.17821e-01]
21Feb13_183945| [ 1.10172e+00  3.34007e-01 -1.28144e+00 -9.99387e-01]
21Feb13_183945| [ 6.14747e-01  1.74699e-02 -2.53533e-01 -4.93268e-01]
21Feb13_183945| [-1.68123e-01 -3.75621e-02 -4.00563e-01 -1.06499e+00]
21Feb13_183945| [ 1.68917e+00  8.38239e-01 -2.68816e-02 -9.26705e-01]
21Feb13_183945| [ 8.16397e-01  1.47216e+00 -3.72165e-01  8.01488e-02]
21Feb13_183945| [-1.87213e-01  3.60063e-01  2.18543e-01  5.02950e-01]
21Feb13_183945| [ 7.33804e-01 -1.95159e-01 -1.82285e+00  5.14853e-01]
21Feb13_183945| [ 6.88558e-01 -1.07087e-01 -2.67856e+00 -1.83088e+00]
21Feb13_183945| [-2.26892e-01 -1.79768e+00  1.38529e+00 -1.06190e+00]
21Feb13_183945| [ 7.06417e-01 -3.75030e-01 -8.33602e-02  1.51313e-02]
21Feb13_183945| [ 4.07669e-01 -4.07600e-02  8.65359e-01 -6.48309e-01]
21Feb13_183945| [ 1.59318e+00  1.49862e+00 -1.22730e+00 -4.75797e-02]
21Feb13_183945| [ 2.23448e+00  5.81611e-01  9.70576e-01 -1.16943e+00]
21Feb13_183945| [ 1.27520e+00  1.46452e-01 -1.77996e+00 -3.68113e-01]
21Feb13_183945| [ 2.64911e-01  1.29363e+00 -7.55651e-01  1.31616e+00]
21Feb13_183945| [-3.15699e-01 -9.42947e-01  3.59613e-01  1.53691e+00]
21Feb13_183945| [-1.83237e+00 -2.82041e-01  1.15458e-01  9.14966e-01]
21Feb13_183945| [ 5.41912e-01  1.03547e+00  1.89459e-01 -3.11293e-01]
21Feb13_183945| [-8.48413e-01 -7.65092e-01  1.52671e+00  2.32680e+00]
21Feb13_183945| [-9.07727e-01  1.26484e+00  1.84065e-03  2.89181e-01]
21Feb13_183945| [-7.76721e-01  1.73275e+00 -2.00253e-01  5.13027e-01]
21Feb13_183945| [-3.14822e-01  6.65239e-01 -8.33827e-01 -9.31808e-01]
21Feb13_183945| [-1.06577e+00 -6.56160e-01  7.07962e-01 -7.41742e-01]
21Feb13_183945| [ 1.37495e+00 -9.98537e-01 -1.26291e-01  7.35705e-01]
21Feb13_183945| [-7.81532e-01  4.81725e-01  9.72613e-01  1.14711e+00]
21Feb13_183945| [ 1.39228e+00 -1.10795e+00  6.18742e-01 -8.23983e-01]
21Feb13_183945| [-1.21496e+00 -9.27339e-01  1.46112e+00 -1.58060e-01]
21Feb13_183945| [-1.47877e-01  3.00039e-01 -1.16124e-01 -2.49785e-01]
21Feb13_183945| [ 1.34618e+00 -4.10722e-01 -2.01150e+00 -2.75159e-01]
21Feb13_183945| [ 3.26027e-01 -2.31842e+00 -9.63079e-01  1.40506e+00]
21Feb13_183945| [ 2.37497e-01 -8.86651e-02 -8.09815e-03 -2.75301e-01]
21Feb13_183945| [-9.43558e-01  3.27714e-02  1.37072e+00 -6.87180e-01]
21Feb13_183945| [-2.73140e-01 -1.03409e+00  4.18114e-01  2.63792e+00]
21Feb13_183945| [-1.29274e+00  5.68486e-01 -3.70493e-01 -1.79609e+00]]
21Feb13_183945|-- Bias --
21Feb13_183945|[ 0.47797 -0.46841  0.80042  0.85704]
21Feb13_183945|Layer 1:
21Feb13_183945|-- Config --
21Feb13_183945|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_183945|-- Weights --
21Feb13_183945|[[-0.07388 -0.44630  0.00582 -0.38753  0.04666]
21Feb13_183945| [ 0.56150  0.18177  0.10598  0.12676 -0.22741]
21Feb13_183945| [ 0.36995 -0.63866  0.59360 -0.34067  0.28075]
21Feb13_183945| [-0.02730 -0.58961 -0.21658  0.00403  0.22317]]
21Feb13_183945|-- Bias --
21Feb13_183945|[ 0.60577  0.01906  0.49354 -0.12722 -0.48520]
21Feb13_183945|Layer 2:
21Feb13_183945|-- Config --
21Feb13_183945|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_183945|-- Weights --
21Feb13_183945|[[ 0.86200 -1.33193]
21Feb13_183945| [-2.22124  1.37832]
21Feb13_183945| [-0.02313 -0.06435]
21Feb13_183945| [ 0.48998 -0.56779]
21Feb13_183945| [-0.10810  0.00308]]
21Feb13_183945|-- Bias --
21Feb13_183945|[-0.07638  0.02979]
21Feb13_183945|Predicting the validation and test data with the Best final individual.
21Feb13_183953| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_183953|-----------  ------------------  --------------------  ----------
21Feb13_183953|Validation         40.43                  18            0.06116
21Feb13_183953|   Test            36.14                  18            0.06407
21Feb13_183953|-------------------- Test #8 --------------------
21Feb13_183953|Best final individual weights
21Feb13_183953|Individual:
21Feb13_183953|-- Constant hidden layers --
21Feb13_183953|False
21Feb13_183953|Layer 0:
21Feb13_183953|-- Config --
21Feb13_183953|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_183953|-- Weights --
21Feb13_183953|[[-1.87472e-01 -1.88423e+00 -9.87479e-02 -4.31576e-01]
21Feb13_183953| [ 7.47578e-01 -8.61812e-01 -1.03859e+00  6.81397e-02]
21Feb13_183953| [-1.04232e+00  1.71195e+00 -4.16856e-01 -4.98514e-01]
21Feb13_183953| [ 1.35466e+00 -6.63542e-01  7.24879e-01  2.25979e-02]
21Feb13_183953| [ 2.16981e-01 -2.10882e+00 -1.46954e+00 -6.08573e-01]
21Feb13_183953| [ 6.47638e-02  1.08814e+00  6.86203e-02  9.30175e-01]
21Feb13_183953| [-2.44488e+00  1.55556e+00  1.90865e-01  1.59360e-01]
21Feb13_183953| [-6.06958e-01 -1.30643e-01  7.80295e-01  1.68866e+00]
21Feb13_183953| [ 7.24409e-01 -1.27327e+00 -2.36592e-02 -7.70925e-01]
21Feb13_183953| [ 8.20815e-01  1.41478e-02  1.57561e+00  3.89599e-01]
21Feb13_183953| [ 5.19426e-01  7.54468e-01 -2.58818e-02 -5.31621e-01]
21Feb13_183953| [ 1.59397e+00  1.31399e+00  4.31820e-02  4.73847e-01]
21Feb13_183953| [ 6.12200e-01 -8.79955e-01 -1.86201e-01 -1.90943e+00]
21Feb13_183953| [ 3.40432e-01  1.02790e+00 -1.15314e+00 -1.40468e+00]
21Feb13_183953| [ 4.70886e-01 -8.98456e-01  2.17497e+00  1.29145e-01]
21Feb13_183953| [ 8.53325e-01  1.53881e+00  8.59108e-01  5.58786e-01]
21Feb13_183953| [-1.34194e+00 -8.61258e-01  4.02439e-01 -9.96468e-01]
21Feb13_183953| [-1.33269e+00  6.41410e-01 -5.15019e-02 -7.72709e-01]
21Feb13_183953| [-4.69262e-01  2.41285e-01 -1.26819e+00 -4.79252e-01]
21Feb13_183953| [-1.25819e+00 -2.15944e-01 -5.82515e-01 -3.71993e-01]
21Feb13_183953| [-2.08817e+00 -2.39077e-01  5.19126e-01 -6.39950e-02]
21Feb13_183953| [-2.16821e-01 -5.79153e-01 -1.25299e-01 -5.39553e-01]
21Feb13_183953| [ 6.63347e-01  2.32524e-01  3.53160e-01 -3.17821e-01]
21Feb13_183953| [ 1.10172e+00  3.34007e-01 -1.28144e+00 -9.99387e-01]
21Feb13_183953| [ 6.14747e-01  1.74699e-02 -2.53533e-01 -4.93268e-01]
21Feb13_183953| [-1.68123e-01 -3.75621e-02 -4.00563e-01 -1.06499e+00]
21Feb13_183953| [ 1.68917e+00  8.38239e-01 -2.68816e-02 -9.26705e-01]
21Feb13_183953| [ 8.16397e-01  1.47216e+00 -3.72165e-01  8.01488e-02]
21Feb13_183953| [-1.87213e-01  3.60063e-01  2.18543e-01  5.02950e-01]
21Feb13_183953| [ 7.33804e-01 -1.95159e-01 -1.82285e+00  5.14853e-01]
21Feb13_183953| [ 6.88558e-01 -1.07087e-01 -2.67856e+00 -1.83088e+00]
21Feb13_183953| [-2.26892e-01 -1.79768e+00  1.38529e+00 -1.06190e+00]
21Feb13_183953| [ 7.06417e-01 -3.75030e-01 -8.33602e-02  1.51313e-02]
21Feb13_183953| [ 4.07669e-01 -4.07600e-02  8.65359e-01 -6.48309e-01]
21Feb13_183953| [ 1.59318e+00  1.49862e+00 -1.22730e+00 -4.75797e-02]
21Feb13_183953| [ 2.23448e+00  5.81611e-01  9.70576e-01 -1.16943e+00]
21Feb13_183953| [ 1.27520e+00  1.46452e-01 -1.77996e+00 -3.68113e-01]
21Feb13_183953| [ 2.64911e-01  1.29363e+00 -7.55651e-01  1.31616e+00]
21Feb13_183953| [-3.15699e-01 -9.42947e-01  3.59613e-01  1.53691e+00]
21Feb13_183953| [-1.83237e+00 -2.82041e-01  1.15458e-01  9.14966e-01]
21Feb13_183953| [ 5.41912e-01  1.03547e+00  1.89459e-01 -3.11293e-01]
21Feb13_183953| [-8.48413e-01 -7.65092e-01  1.52671e+00  2.32680e+00]
21Feb13_183953| [-9.07727e-01  1.26484e+00  1.84065e-03  2.89181e-01]
21Feb13_183953| [-7.76721e-01  1.73275e+00 -2.00253e-01  5.13027e-01]
21Feb13_183953| [-3.14822e-01  6.65239e-01 -8.33827e-01 -9.31808e-01]
21Feb13_183953| [-1.06577e+00 -6.56160e-01  7.07962e-01 -7.41742e-01]
21Feb13_183953| [ 1.37495e+00 -9.98537e-01 -1.26291e-01  7.35705e-01]
21Feb13_183953| [-7.81532e-01  4.81725e-01  9.72613e-01  1.14711e+00]
21Feb13_183953| [ 1.39228e+00 -1.10795e+00  6.18742e-01 -8.23983e-01]
21Feb13_183953| [-1.21496e+00 -9.27339e-01  1.46112e+00 -1.58060e-01]
21Feb13_183953| [-1.47877e-01  3.00039e-01 -1.16124e-01 -2.49785e-01]
21Feb13_183953| [ 1.34618e+00 -4.10722e-01 -2.01150e+00 -2.75159e-01]
21Feb13_183953| [ 3.26027e-01 -2.31842e+00 -9.63079e-01  1.40506e+00]
21Feb13_183953| [ 2.37497e-01 -8.86651e-02 -8.09815e-03 -2.75301e-01]
21Feb13_183953| [-9.43558e-01  3.27714e-02  1.37072e+00 -6.87180e-01]
21Feb13_183953| [-2.73140e-01 -1.03409e+00  4.18114e-01  2.63792e+00]
21Feb13_183953| [-1.29274e+00  5.68486e-01 -3.70493e-01 -1.79609e+00]]
21Feb13_183953|-- Bias --
21Feb13_183953|[ 0.47797 -0.46841  0.80042  0.85704]
21Feb13_183953|Layer 1:
21Feb13_183953|-- Config --
21Feb13_183953|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_183953|-- Weights --
21Feb13_183953|[[-0.07388 -0.44630  0.00582 -0.38753  0.04666]
21Feb13_183953| [ 0.56150  0.18177  0.10598  0.12676 -0.22741]
21Feb13_183953| [ 0.36995 -0.63866  0.59360 -0.34067  0.28075]
21Feb13_183953| [-0.02730 -0.58961 -0.21658  0.00403  0.22317]]
21Feb13_183953|-- Bias --
21Feb13_183953|[ 0.60577  0.01906  0.49354 -0.12722 -0.48520]
21Feb13_183953|Layer 2:
21Feb13_183953|-- Config --
21Feb13_183953|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_183953|-- Weights --
21Feb13_183953|[[ 0.86200 -1.33193]
21Feb13_183953| [-2.22124  1.37832]
21Feb13_183953| [-0.02313 -0.06435]
21Feb13_183953| [ 0.48998 -0.56779]
21Feb13_183953| [-0.10810  0.00308]]
21Feb13_183953|-- Bias --
21Feb13_183953|[-0.07638  0.02979]
21Feb13_183953|Predicting the validation and test data with the Best final individual.
21Feb13_184000| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_184000|-----------  ------------------  --------------------  ----------
21Feb13_184000|Validation         37.30                  18            0.35616
21Feb13_184000|   Test            36.40                  18            0.00000
21Feb13_184000|-------------------- Test #9 --------------------
21Feb13_184000|Best final individual weights
21Feb13_184000|Individual:
21Feb13_184000|-- Constant hidden layers --
21Feb13_184000|False
21Feb13_184000|Layer 0:
21Feb13_184000|-- Config --
21Feb13_184000|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_184000|-- Weights --
21Feb13_184000|[[-1.87472e-01 -1.88423e+00 -9.87479e-02 -4.31576e-01]
21Feb13_184000| [ 7.47578e-01 -8.61812e-01 -1.03859e+00  6.81397e-02]
21Feb13_184000| [-1.04232e+00  1.71195e+00 -4.16856e-01 -4.98514e-01]
21Feb13_184000| [ 1.35466e+00 -6.63542e-01  7.24879e-01  2.25979e-02]
21Feb13_184000| [ 2.16981e-01 -2.10882e+00 -1.46954e+00 -6.08573e-01]
21Feb13_184000| [ 6.47638e-02  1.08814e+00  6.86203e-02  9.30175e-01]
21Feb13_184000| [-2.44488e+00  1.55556e+00  1.90865e-01  1.59360e-01]
21Feb13_184000| [-6.06958e-01 -1.30643e-01  7.80295e-01  1.68866e+00]
21Feb13_184000| [ 7.24409e-01 -1.27327e+00 -2.36592e-02 -7.70925e-01]
21Feb13_184000| [ 8.20815e-01  1.41478e-02  1.57561e+00  3.89599e-01]
21Feb13_184000| [ 5.19426e-01  7.54468e-01 -2.58818e-02 -5.31621e-01]
21Feb13_184000| [ 1.59397e+00  1.31399e+00  4.31820e-02  4.73847e-01]
21Feb13_184000| [ 6.12200e-01 -8.79955e-01 -1.86201e-01 -1.90943e+00]
21Feb13_184000| [ 3.40432e-01  1.02790e+00 -1.15314e+00 -1.40468e+00]
21Feb13_184000| [ 4.70886e-01 -8.98456e-01  2.17497e+00  1.29145e-01]
21Feb13_184000| [ 8.53325e-01  1.53881e+00  8.59108e-01  5.58786e-01]
21Feb13_184000| [-1.34194e+00 -8.61258e-01  4.02439e-01 -9.96468e-01]
21Feb13_184000| [-1.33269e+00  6.41410e-01 -5.15019e-02 -7.72709e-01]
21Feb13_184000| [-4.69262e-01  2.41285e-01 -1.26819e+00 -4.79252e-01]
21Feb13_184000| [-1.25819e+00 -2.15944e-01 -5.82515e-01 -3.71993e-01]
21Feb13_184000| [-2.08817e+00 -2.39077e-01  5.19126e-01 -6.39950e-02]
21Feb13_184000| [-2.16821e-01 -5.79153e-01 -1.25299e-01 -5.39553e-01]
21Feb13_184000| [ 6.63347e-01  2.32524e-01  3.53160e-01 -3.17821e-01]
21Feb13_184000| [ 1.10172e+00  3.34007e-01 -1.28144e+00 -9.99387e-01]
21Feb13_184000| [ 6.14747e-01  1.74699e-02 -2.53533e-01 -4.93268e-01]
21Feb13_184000| [-1.68123e-01 -3.75621e-02 -4.00563e-01 -1.06499e+00]
21Feb13_184000| [ 1.68917e+00  8.38239e-01 -2.68816e-02 -9.26705e-01]
21Feb13_184000| [ 8.16397e-01  1.47216e+00 -3.72165e-01  8.01488e-02]
21Feb13_184000| [-1.87213e-01  3.60063e-01  2.18543e-01  5.02950e-01]
21Feb13_184000| [ 7.33804e-01 -1.95159e-01 -1.82285e+00  5.14853e-01]
21Feb13_184000| [ 6.88558e-01 -1.07087e-01 -2.67856e+00 -1.83088e+00]
21Feb13_184000| [-2.26892e-01 -1.79768e+00  1.38529e+00 -1.06190e+00]
21Feb13_184000| [ 7.06417e-01 -3.75030e-01 -8.33602e-02  1.51313e-02]
21Feb13_184000| [ 4.07669e-01 -4.07600e-02  8.65359e-01 -6.48309e-01]
21Feb13_184000| [ 1.59318e+00  1.49862e+00 -1.22730e+00 -4.75797e-02]
21Feb13_184000| [ 2.23448e+00  5.81611e-01  9.70576e-01 -1.16943e+00]
21Feb13_184000| [ 1.27520e+00  1.46452e-01 -1.77996e+00 -3.68113e-01]
21Feb13_184000| [ 2.64911e-01  1.29363e+00 -7.55651e-01  1.31616e+00]
21Feb13_184000| [-3.15699e-01 -9.42947e-01  3.59613e-01  1.53691e+00]
21Feb13_184000| [-1.83237e+00 -2.82041e-01  1.15458e-01  9.14966e-01]
21Feb13_184000| [ 5.41912e-01  1.03547e+00  1.89459e-01 -3.11293e-01]
21Feb13_184000| [-8.48413e-01 -7.65092e-01  1.52671e+00  2.32680e+00]
21Feb13_184000| [-9.07727e-01  1.26484e+00  1.84065e-03  2.89181e-01]
21Feb13_184000| [-7.76721e-01  1.73275e+00 -2.00253e-01  5.13027e-01]
21Feb13_184000| [-3.14822e-01  6.65239e-01 -8.33827e-01 -9.31808e-01]
21Feb13_184000| [-1.06577e+00 -6.56160e-01  7.07962e-01 -7.41742e-01]
21Feb13_184000| [ 1.37495e+00 -9.98537e-01 -1.26291e-01  7.35705e-01]
21Feb13_184000| [-7.81532e-01  4.81725e-01  9.72613e-01  1.14711e+00]
21Feb13_184000| [ 1.39228e+00 -1.10795e+00  6.18742e-01 -8.23983e-01]
21Feb13_184000| [-1.21496e+00 -9.27339e-01  1.46112e+00 -1.58060e-01]
21Feb13_184000| [-1.47877e-01  3.00039e-01 -1.16124e-01 -2.49785e-01]
21Feb13_184000| [ 1.34618e+00 -4.10722e-01 -2.01150e+00 -2.75159e-01]
21Feb13_184000| [ 3.26027e-01 -2.31842e+00 -9.63079e-01  1.40506e+00]
21Feb13_184000| [ 2.37497e-01 -8.86651e-02 -8.09815e-03 -2.75301e-01]
21Feb13_184000| [-9.43558e-01  3.27714e-02  1.37072e+00 -6.87180e-01]
21Feb13_184000| [-2.73140e-01 -1.03409e+00  4.18114e-01  2.63792e+00]
21Feb13_184000| [-1.29274e+00  5.68486e-01 -3.70493e-01 -1.79609e+00]]
21Feb13_184000|-- Bias --
21Feb13_184000|[ 0.47797 -0.46841  0.80042  0.85704]
21Feb13_184000|Layer 1:
21Feb13_184000|-- Config --
21Feb13_184000|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_184000|-- Weights --
21Feb13_184000|[[-0.07388 -0.44630  0.00582 -0.38753  0.04666]
21Feb13_184000| [ 0.56150  0.18177  0.10598  0.12676 -0.22741]
21Feb13_184000| [ 0.36995 -0.63866  0.59360 -0.34067  0.28075]
21Feb13_184000| [-0.02730 -0.58961 -0.21658  0.00403  0.22317]]
21Feb13_184000|-- Bias --
21Feb13_184000|[ 0.60577  0.01906  0.49354 -0.12722 -0.48520]
21Feb13_184000|Layer 2:
21Feb13_184000|-- Config --
21Feb13_184000|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_184000|-- Weights --
21Feb13_184000|[[ 0.86200 -1.33193]
21Feb13_184000| [-2.22124  1.37832]
21Feb13_184000| [-0.02313 -0.06435]
21Feb13_184000| [ 0.48998 -0.56779]
21Feb13_184000| [-0.10810  0.00308]]
21Feb13_184000|-- Bias --
21Feb13_184000|[-0.07638  0.02979]
21Feb13_184000|Predicting the validation and test data with the Best final individual.
21Feb13_184008| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_184008|-----------  ------------------  --------------------  ----------
21Feb13_184008|Validation         38.96                  18            0.11803
21Feb13_184008|   Test            35.27                  18            0.06158
21Feb13_184008|-------------------- Test #10 --------------------
21Feb13_184008|Best final individual weights
21Feb13_184008|Individual:
21Feb13_184008|-- Constant hidden layers --
21Feb13_184008|False
21Feb13_184008|Layer 0:
21Feb13_184008|-- Config --
21Feb13_184008|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_184008|-- Weights --
21Feb13_184008|[[-1.87472e-01 -1.88423e+00 -9.87479e-02 -4.31576e-01]
21Feb13_184008| [ 7.47578e-01 -8.61812e-01 -1.03859e+00  6.81397e-02]
21Feb13_184008| [-1.04232e+00  1.71195e+00 -4.16856e-01 -4.98514e-01]
21Feb13_184008| [ 1.35466e+00 -6.63542e-01  7.24879e-01  2.25979e-02]
21Feb13_184008| [ 2.16981e-01 -2.10882e+00 -1.46954e+00 -6.08573e-01]
21Feb13_184008| [ 6.47638e-02  1.08814e+00  6.86203e-02  9.30175e-01]
21Feb13_184008| [-2.44488e+00  1.55556e+00  1.90865e-01  1.59360e-01]
21Feb13_184008| [-6.06958e-01 -1.30643e-01  7.80295e-01  1.68866e+00]
21Feb13_184008| [ 7.24409e-01 -1.27327e+00 -2.36592e-02 -7.70925e-01]
21Feb13_184008| [ 8.20815e-01  1.41478e-02  1.57561e+00  3.89599e-01]
21Feb13_184008| [ 5.19426e-01  7.54468e-01 -2.58818e-02 -5.31621e-01]
21Feb13_184008| [ 1.59397e+00  1.31399e+00  4.31820e-02  4.73847e-01]
21Feb13_184008| [ 6.12200e-01 -8.79955e-01 -1.86201e-01 -1.90943e+00]
21Feb13_184008| [ 3.40432e-01  1.02790e+00 -1.15314e+00 -1.40468e+00]
21Feb13_184008| [ 4.70886e-01 -8.98456e-01  2.17497e+00  1.29145e-01]
21Feb13_184008| [ 8.53325e-01  1.53881e+00  8.59108e-01  5.58786e-01]
21Feb13_184008| [-1.34194e+00 -8.61258e-01  4.02439e-01 -9.96468e-01]
21Feb13_184008| [-1.33269e+00  6.41410e-01 -5.15019e-02 -7.72709e-01]
21Feb13_184008| [-4.69262e-01  2.41285e-01 -1.26819e+00 -4.79252e-01]
21Feb13_184008| [-1.25819e+00 -2.15944e-01 -5.82515e-01 -3.71993e-01]
21Feb13_184008| [-2.08817e+00 -2.39077e-01  5.19126e-01 -6.39950e-02]
21Feb13_184008| [-2.16821e-01 -5.79153e-01 -1.25299e-01 -5.39553e-01]
21Feb13_184008| [ 6.63347e-01  2.32524e-01  3.53160e-01 -3.17821e-01]
21Feb13_184008| [ 1.10172e+00  3.34007e-01 -1.28144e+00 -9.99387e-01]
21Feb13_184008| [ 6.14747e-01  1.74699e-02 -2.53533e-01 -4.93268e-01]
21Feb13_184008| [-1.68123e-01 -3.75621e-02 -4.00563e-01 -1.06499e+00]
21Feb13_184008| [ 1.68917e+00  8.38239e-01 -2.68816e-02 -9.26705e-01]
21Feb13_184008| [ 8.16397e-01  1.47216e+00 -3.72165e-01  8.01488e-02]
21Feb13_184008| [-1.87213e-01  3.60063e-01  2.18543e-01  5.02950e-01]
21Feb13_184008| [ 7.33804e-01 -1.95159e-01 -1.82285e+00  5.14853e-01]
21Feb13_184008| [ 6.88558e-01 -1.07087e-01 -2.67856e+00 -1.83088e+00]
21Feb13_184008| [-2.26892e-01 -1.79768e+00  1.38529e+00 -1.06190e+00]
21Feb13_184008| [ 7.06417e-01 -3.75030e-01 -8.33602e-02  1.51313e-02]
21Feb13_184008| [ 4.07669e-01 -4.07600e-02  8.65359e-01 -6.48309e-01]
21Feb13_184008| [ 1.59318e+00  1.49862e+00 -1.22730e+00 -4.75797e-02]
21Feb13_184008| [ 2.23448e+00  5.81611e-01  9.70576e-01 -1.16943e+00]
21Feb13_184008| [ 1.27520e+00  1.46452e-01 -1.77996e+00 -3.68113e-01]
21Feb13_184008| [ 2.64911e-01  1.29363e+00 -7.55651e-01  1.31616e+00]
21Feb13_184008| [-3.15699e-01 -9.42947e-01  3.59613e-01  1.53691e+00]
21Feb13_184008| [-1.83237e+00 -2.82041e-01  1.15458e-01  9.14966e-01]
21Feb13_184008| [ 5.41912e-01  1.03547e+00  1.89459e-01 -3.11293e-01]
21Feb13_184008| [-8.48413e-01 -7.65092e-01  1.52671e+00  2.32680e+00]
21Feb13_184008| [-9.07727e-01  1.26484e+00  1.84065e-03  2.89181e-01]
21Feb13_184008| [-7.76721e-01  1.73275e+00 -2.00253e-01  5.13027e-01]
21Feb13_184008| [-3.14822e-01  6.65239e-01 -8.33827e-01 -9.31808e-01]
21Feb13_184008| [-1.06577e+00 -6.56160e-01  7.07962e-01 -7.41742e-01]
21Feb13_184008| [ 1.37495e+00 -9.98537e-01 -1.26291e-01  7.35705e-01]
21Feb13_184008| [-7.81532e-01  4.81725e-01  9.72613e-01  1.14711e+00]
21Feb13_184008| [ 1.39228e+00 -1.10795e+00  6.18742e-01 -8.23983e-01]
21Feb13_184008| [-1.21496e+00 -9.27339e-01  1.46112e+00 -1.58060e-01]
21Feb13_184008| [-1.47877e-01  3.00039e-01 -1.16124e-01 -2.49785e-01]
21Feb13_184008| [ 1.34618e+00 -4.10722e-01 -2.01150e+00 -2.75159e-01]
21Feb13_184008| [ 3.26027e-01 -2.31842e+00 -9.63079e-01  1.40506e+00]
21Feb13_184008| [ 2.37497e-01 -8.86651e-02 -8.09815e-03 -2.75301e-01]
21Feb13_184008| [-9.43558e-01  3.27714e-02  1.37072e+00 -6.87180e-01]
21Feb13_184008| [-2.73140e-01 -1.03409e+00  4.18114e-01  2.63792e+00]
21Feb13_184008| [-1.29274e+00  5.68486e-01 -3.70493e-01 -1.79609e+00]]
21Feb13_184008|-- Bias --
21Feb13_184008|[ 0.47797 -0.46841  0.80042  0.85704]
21Feb13_184008|Layer 1:
21Feb13_184008|-- Config --
21Feb13_184008|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_184008|-- Weights --
21Feb13_184008|[[-0.07388 -0.44630  0.00582 -0.38753  0.04666]
21Feb13_184008| [ 0.56150  0.18177  0.10598  0.12676 -0.22741]
21Feb13_184008| [ 0.36995 -0.63866  0.59360 -0.34067  0.28075]
21Feb13_184008| [-0.02730 -0.58961 -0.21658  0.00403  0.22317]]
21Feb13_184008|-- Bias --
21Feb13_184008|[ 0.60577  0.01906  0.49354 -0.12722 -0.48520]
21Feb13_184008|Layer 2:
21Feb13_184008|-- Config --
21Feb13_184008|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_184008|-- Weights --
21Feb13_184008|[[ 0.86200 -1.33193]
21Feb13_184008| [-2.22124  1.37832]
21Feb13_184008| [-0.02313 -0.06435]
21Feb13_184008| [ 0.48998 -0.56779]
21Feb13_184008| [-0.10810  0.00308]]
21Feb13_184008|-- Bias --
21Feb13_184008|[-0.07638  0.02979]
21Feb13_184008|Predicting the validation and test data with the Best final individual.
21Feb13_184015| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_184015|-----------  ------------------  --------------------  ----------
21Feb13_184015|Validation         40.87                  18            0.06596
21Feb13_184015|   Test            36.32                  18            0.19029
21Feb13_184015|-------------------- Test #11 --------------------
21Feb13_184015|Best final individual weights
21Feb13_184015|Individual:
21Feb13_184015|-- Constant hidden layers --
21Feb13_184015|False
21Feb13_184015|Layer 0:
21Feb13_184015|-- Config --
21Feb13_184015|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_184015|-- Weights --
21Feb13_184015|[[-1.87472e-01 -1.88423e+00 -9.87479e-02 -4.31576e-01]
21Feb13_184015| [ 7.47578e-01 -8.61812e-01 -1.03859e+00  6.81397e-02]
21Feb13_184015| [-1.04232e+00  1.71195e+00 -4.16856e-01 -4.98514e-01]
21Feb13_184015| [ 1.35466e+00 -6.63542e-01  7.24879e-01  2.25979e-02]
21Feb13_184015| [ 2.16981e-01 -2.10882e+00 -1.46954e+00 -6.08573e-01]
21Feb13_184015| [ 6.47638e-02  1.08814e+00  6.86203e-02  9.30175e-01]
21Feb13_184015| [-2.44488e+00  1.55556e+00  1.90865e-01  1.59360e-01]
21Feb13_184015| [-6.06958e-01 -1.30643e-01  7.80295e-01  1.68866e+00]
21Feb13_184015| [ 7.24409e-01 -1.27327e+00 -2.36592e-02 -7.70925e-01]
21Feb13_184015| [ 8.20815e-01  1.41478e-02  1.57561e+00  3.89599e-01]
21Feb13_184015| [ 5.19426e-01  7.54468e-01 -2.58818e-02 -5.31621e-01]
21Feb13_184015| [ 1.59397e+00  1.31399e+00  4.31820e-02  4.73847e-01]
21Feb13_184015| [ 6.12200e-01 -8.79955e-01 -1.86201e-01 -1.90943e+00]
21Feb13_184015| [ 3.40432e-01  1.02790e+00 -1.15314e+00 -1.40468e+00]
21Feb13_184015| [ 4.70886e-01 -8.98456e-01  2.17497e+00  1.29145e-01]
21Feb13_184015| [ 8.53325e-01  1.53881e+00  8.59108e-01  5.58786e-01]
21Feb13_184015| [-1.34194e+00 -8.61258e-01  4.02439e-01 -9.96468e-01]
21Feb13_184015| [-1.33269e+00  6.41410e-01 -5.15019e-02 -7.72709e-01]
21Feb13_184015| [-4.69262e-01  2.41285e-01 -1.26819e+00 -4.79252e-01]
21Feb13_184015| [-1.25819e+00 -2.15944e-01 -5.82515e-01 -3.71993e-01]
21Feb13_184015| [-2.08817e+00 -2.39077e-01  5.19126e-01 -6.39950e-02]
21Feb13_184015| [-2.16821e-01 -5.79153e-01 -1.25299e-01 -5.39553e-01]
21Feb13_184015| [ 6.63347e-01  2.32524e-01  3.53160e-01 -3.17821e-01]
21Feb13_184015| [ 1.10172e+00  3.34007e-01 -1.28144e+00 -9.99387e-01]
21Feb13_184015| [ 6.14747e-01  1.74699e-02 -2.53533e-01 -4.93268e-01]
21Feb13_184015| [-1.68123e-01 -3.75621e-02 -4.00563e-01 -1.06499e+00]
21Feb13_184015| [ 1.68917e+00  8.38239e-01 -2.68816e-02 -9.26705e-01]
21Feb13_184015| [ 8.16397e-01  1.47216e+00 -3.72165e-01  8.01488e-02]
21Feb13_184015| [-1.87213e-01  3.60063e-01  2.18543e-01  5.02950e-01]
21Feb13_184015| [ 7.33804e-01 -1.95159e-01 -1.82285e+00  5.14853e-01]
21Feb13_184015| [ 6.88558e-01 -1.07087e-01 -2.67856e+00 -1.83088e+00]
21Feb13_184015| [-2.26892e-01 -1.79768e+00  1.38529e+00 -1.06190e+00]
21Feb13_184015| [ 7.06417e-01 -3.75030e-01 -8.33602e-02  1.51313e-02]
21Feb13_184015| [ 4.07669e-01 -4.07600e-02  8.65359e-01 -6.48309e-01]
21Feb13_184015| [ 1.59318e+00  1.49862e+00 -1.22730e+00 -4.75797e-02]
21Feb13_184015| [ 2.23448e+00  5.81611e-01  9.70576e-01 -1.16943e+00]
21Feb13_184015| [ 1.27520e+00  1.46452e-01 -1.77996e+00 -3.68113e-01]
21Feb13_184015| [ 2.64911e-01  1.29363e+00 -7.55651e-01  1.31616e+00]
21Feb13_184015| [-3.15699e-01 -9.42947e-01  3.59613e-01  1.53691e+00]
21Feb13_184015| [-1.83237e+00 -2.82041e-01  1.15458e-01  9.14966e-01]
21Feb13_184015| [ 5.41912e-01  1.03547e+00  1.89459e-01 -3.11293e-01]
21Feb13_184015| [-8.48413e-01 -7.65092e-01  1.52671e+00  2.32680e+00]
21Feb13_184015| [-9.07727e-01  1.26484e+00  1.84065e-03  2.89181e-01]
21Feb13_184015| [-7.76721e-01  1.73275e+00 -2.00253e-01  5.13027e-01]
21Feb13_184015| [-3.14822e-01  6.65239e-01 -8.33827e-01 -9.31808e-01]
21Feb13_184015| [-1.06577e+00 -6.56160e-01  7.07962e-01 -7.41742e-01]
21Feb13_184015| [ 1.37495e+00 -9.98537e-01 -1.26291e-01  7.35705e-01]
21Feb13_184015| [-7.81532e-01  4.81725e-01  9.72613e-01  1.14711e+00]
21Feb13_184015| [ 1.39228e+00 -1.10795e+00  6.18742e-01 -8.23983e-01]
21Feb13_184015| [-1.21496e+00 -9.27339e-01  1.46112e+00 -1.58060e-01]
21Feb13_184015| [-1.47877e-01  3.00039e-01 -1.16124e-01 -2.49785e-01]
21Feb13_184015| [ 1.34618e+00 -4.10722e-01 -2.01150e+00 -2.75159e-01]
21Feb13_184015| [ 3.26027e-01 -2.31842e+00 -9.63079e-01  1.40506e+00]
21Feb13_184015| [ 2.37497e-01 -8.86651e-02 -8.09815e-03 -2.75301e-01]
21Feb13_184015| [-9.43558e-01  3.27714e-02  1.37072e+00 -6.87180e-01]
21Feb13_184015| [-2.73140e-01 -1.03409e+00  4.18114e-01  2.63792e+00]
21Feb13_184015| [-1.29274e+00  5.68486e-01 -3.70493e-01 -1.79609e+00]]
21Feb13_184015|-- Bias --
21Feb13_184015|[ 0.47797 -0.46841  0.80042  0.85704]
21Feb13_184015|Layer 1:
21Feb13_184015|-- Config --
21Feb13_184015|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_184015|-- Weights --
21Feb13_184015|[[-0.07388 -0.44630  0.00582 -0.38753  0.04666]
21Feb13_184015| [ 0.56150  0.18177  0.10598  0.12676 -0.22741]
21Feb13_184015| [ 0.36995 -0.63866  0.59360 -0.34067  0.28075]
21Feb13_184015| [-0.02730 -0.58961 -0.21658  0.00403  0.22317]]
21Feb13_184015|-- Bias --
21Feb13_184015|[ 0.60577  0.01906  0.49354 -0.12722 -0.48520]
21Feb13_184015|Layer 2:
21Feb13_184015|-- Config --
21Feb13_184015|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_184015|-- Weights --
21Feb13_184015|[[ 0.86200 -1.33193]
21Feb13_184015| [-2.22124  1.37832]
21Feb13_184015| [-0.02313 -0.06435]
21Feb13_184015| [ 0.48998 -0.56779]
21Feb13_184015| [-0.10810  0.00308]]
21Feb13_184015|-- Bias --
21Feb13_184015|[-0.07638  0.02979]
21Feb13_184015|Predicting the validation and test data with the Best final individual.
21Feb13_184023| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_184023|-----------  ------------------  --------------------  ----------
21Feb13_184023|Validation         39.30                  18            0.33682
21Feb13_184023|   Test            35.97                  18            0.04120
21Feb13_184023|-------------------- Test #12 --------------------
21Feb13_184023|Best final individual weights
21Feb13_184023|Individual:
21Feb13_184023|-- Constant hidden layers --
21Feb13_184023|False
21Feb13_184023|Layer 0:
21Feb13_184023|-- Config --
21Feb13_184023|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_184023|-- Weights --
21Feb13_184023|[[-1.87472e-01 -1.88423e+00 -9.87479e-02 -4.31576e-01]
21Feb13_184023| [ 7.47578e-01 -8.61812e-01 -1.03859e+00  6.81397e-02]
21Feb13_184023| [-1.04232e+00  1.71195e+00 -4.16856e-01 -4.98514e-01]
21Feb13_184023| [ 1.35466e+00 -6.63542e-01  7.24879e-01  2.25979e-02]
21Feb13_184023| [ 2.16981e-01 -2.10882e+00 -1.46954e+00 -6.08573e-01]
21Feb13_184023| [ 6.47638e-02  1.08814e+00  6.86203e-02  9.30175e-01]
21Feb13_184023| [-2.44488e+00  1.55556e+00  1.90865e-01  1.59360e-01]
21Feb13_184023| [-6.06958e-01 -1.30643e-01  7.80295e-01  1.68866e+00]
21Feb13_184023| [ 7.24409e-01 -1.27327e+00 -2.36592e-02 -7.70925e-01]
21Feb13_184023| [ 8.20815e-01  1.41478e-02  1.57561e+00  3.89599e-01]
21Feb13_184023| [ 5.19426e-01  7.54468e-01 -2.58818e-02 -5.31621e-01]
21Feb13_184023| [ 1.59397e+00  1.31399e+00  4.31820e-02  4.73847e-01]
21Feb13_184023| [ 6.12200e-01 -8.79955e-01 -1.86201e-01 -1.90943e+00]
21Feb13_184023| [ 3.40432e-01  1.02790e+00 -1.15314e+00 -1.40468e+00]
21Feb13_184023| [ 4.70886e-01 -8.98456e-01  2.17497e+00  1.29145e-01]
21Feb13_184023| [ 8.53325e-01  1.53881e+00  8.59108e-01  5.58786e-01]
21Feb13_184023| [-1.34194e+00 -8.61258e-01  4.02439e-01 -9.96468e-01]
21Feb13_184023| [-1.33269e+00  6.41410e-01 -5.15019e-02 -7.72709e-01]
21Feb13_184023| [-4.69262e-01  2.41285e-01 -1.26819e+00 -4.79252e-01]
21Feb13_184023| [-1.25819e+00 -2.15944e-01 -5.82515e-01 -3.71993e-01]
21Feb13_184023| [-2.08817e+00 -2.39077e-01  5.19126e-01 -6.39950e-02]
21Feb13_184023| [-2.16821e-01 -5.79153e-01 -1.25299e-01 -5.39553e-01]
21Feb13_184023| [ 6.63347e-01  2.32524e-01  3.53160e-01 -3.17821e-01]
21Feb13_184023| [ 1.10172e+00  3.34007e-01 -1.28144e+00 -9.99387e-01]
21Feb13_184023| [ 6.14747e-01  1.74699e-02 -2.53533e-01 -4.93268e-01]
21Feb13_184023| [-1.68123e-01 -3.75621e-02 -4.00563e-01 -1.06499e+00]
21Feb13_184023| [ 1.68917e+00  8.38239e-01 -2.68816e-02 -9.26705e-01]
21Feb13_184023| [ 8.16397e-01  1.47216e+00 -3.72165e-01  8.01488e-02]
21Feb13_184023| [-1.87213e-01  3.60063e-01  2.18543e-01  5.02950e-01]
21Feb13_184023| [ 7.33804e-01 -1.95159e-01 -1.82285e+00  5.14853e-01]
21Feb13_184023| [ 6.88558e-01 -1.07087e-01 -2.67856e+00 -1.83088e+00]
21Feb13_184023| [-2.26892e-01 -1.79768e+00  1.38529e+00 -1.06190e+00]
21Feb13_184023| [ 7.06417e-01 -3.75030e-01 -8.33602e-02  1.51313e-02]
21Feb13_184023| [ 4.07669e-01 -4.07600e-02  8.65359e-01 -6.48309e-01]
21Feb13_184023| [ 1.59318e+00  1.49862e+00 -1.22730e+00 -4.75797e-02]
21Feb13_184023| [ 2.23448e+00  5.81611e-01  9.70576e-01 -1.16943e+00]
21Feb13_184023| [ 1.27520e+00  1.46452e-01 -1.77996e+00 -3.68113e-01]
21Feb13_184023| [ 2.64911e-01  1.29363e+00 -7.55651e-01  1.31616e+00]
21Feb13_184023| [-3.15699e-01 -9.42947e-01  3.59613e-01  1.53691e+00]
21Feb13_184023| [-1.83237e+00 -2.82041e-01  1.15458e-01  9.14966e-01]
21Feb13_184023| [ 5.41912e-01  1.03547e+00  1.89459e-01 -3.11293e-01]
21Feb13_184023| [-8.48413e-01 -7.65092e-01  1.52671e+00  2.32680e+00]
21Feb13_184023| [-9.07727e-01  1.26484e+00  1.84065e-03  2.89181e-01]
21Feb13_184023| [-7.76721e-01  1.73275e+00 -2.00253e-01  5.13027e-01]
21Feb13_184023| [-3.14822e-01  6.65239e-01 -8.33827e-01 -9.31808e-01]
21Feb13_184023| [-1.06577e+00 -6.56160e-01  7.07962e-01 -7.41742e-01]
21Feb13_184023| [ 1.37495e+00 -9.98537e-01 -1.26291e-01  7.35705e-01]
21Feb13_184023| [-7.81532e-01  4.81725e-01  9.72613e-01  1.14711e+00]
21Feb13_184023| [ 1.39228e+00 -1.10795e+00  6.18742e-01 -8.23983e-01]
21Feb13_184023| [-1.21496e+00 -9.27339e-01  1.46112e+00 -1.58060e-01]
21Feb13_184023| [-1.47877e-01  3.00039e-01 -1.16124e-01 -2.49785e-01]
21Feb13_184023| [ 1.34618e+00 -4.10722e-01 -2.01150e+00 -2.75159e-01]
21Feb13_184023| [ 3.26027e-01 -2.31842e+00 -9.63079e-01  1.40506e+00]
21Feb13_184023| [ 2.37497e-01 -8.86651e-02 -8.09815e-03 -2.75301e-01]
21Feb13_184023| [-9.43558e-01  3.27714e-02  1.37072e+00 -6.87180e-01]
21Feb13_184023| [-2.73140e-01 -1.03409e+00  4.18114e-01  2.63792e+00]
21Feb13_184023| [-1.29274e+00  5.68486e-01 -3.70493e-01 -1.79609e+00]]
21Feb13_184023|-- Bias --
21Feb13_184023|[ 0.47797 -0.46841  0.80042  0.85704]
21Feb13_184023|Layer 1:
21Feb13_184023|-- Config --
21Feb13_184023|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_184023|-- Weights --
21Feb13_184023|[[-0.07388 -0.44630  0.00582 -0.38753  0.04666]
21Feb13_184023| [ 0.56150  0.18177  0.10598  0.12676 -0.22741]
21Feb13_184023| [ 0.36995 -0.63866  0.59360 -0.34067  0.28075]
21Feb13_184023| [-0.02730 -0.58961 -0.21658  0.00403  0.22317]]
21Feb13_184023|-- Bias --
21Feb13_184023|[ 0.60577  0.01906  0.49354 -0.12722 -0.48520]
21Feb13_184023|Layer 2:
21Feb13_184023|-- Config --
21Feb13_184023|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_184023|-- Weights --
21Feb13_184023|[[ 0.86200 -1.33193]
21Feb13_184023| [-2.22124  1.37832]
21Feb13_184023| [-0.02313 -0.06435]
21Feb13_184023| [ 0.48998 -0.56779]
21Feb13_184023| [-0.10810  0.00308]]
21Feb13_184023|-- Bias --
21Feb13_184023|[-0.07638  0.02979]
21Feb13_184023|Predicting the validation and test data with the Best final individual.
21Feb13_184030| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_184030|-----------  ------------------  --------------------  ----------
21Feb13_184030|Validation         41.39                  18            0.06576
21Feb13_184030|   Test            35.71                  18            0.05569
21Feb13_184030|-------------------- Test #13 --------------------
21Feb13_184030|Best final individual weights
21Feb13_184030|Individual:
21Feb13_184030|-- Constant hidden layers --
21Feb13_184030|False
21Feb13_184030|Layer 0:
21Feb13_184030|-- Config --
21Feb13_184030|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_184030|-- Weights --
21Feb13_184030|[[-1.87472e-01 -1.88423e+00 -9.87479e-02 -4.31576e-01]
21Feb13_184030| [ 7.47578e-01 -8.61812e-01 -1.03859e+00  6.81397e-02]
21Feb13_184030| [-1.04232e+00  1.71195e+00 -4.16856e-01 -4.98514e-01]
21Feb13_184030| [ 1.35466e+00 -6.63542e-01  7.24879e-01  2.25979e-02]
21Feb13_184030| [ 2.16981e-01 -2.10882e+00 -1.46954e+00 -6.08573e-01]
21Feb13_184030| [ 6.47638e-02  1.08814e+00  6.86203e-02  9.30175e-01]
21Feb13_184030| [-2.44488e+00  1.55556e+00  1.90865e-01  1.59360e-01]
21Feb13_184030| [-6.06958e-01 -1.30643e-01  7.80295e-01  1.68866e+00]
21Feb13_184030| [ 7.24409e-01 -1.27327e+00 -2.36592e-02 -7.70925e-01]
21Feb13_184030| [ 8.20815e-01  1.41478e-02  1.57561e+00  3.89599e-01]
21Feb13_184030| [ 5.19426e-01  7.54468e-01 -2.58818e-02 -5.31621e-01]
21Feb13_184030| [ 1.59397e+00  1.31399e+00  4.31820e-02  4.73847e-01]
21Feb13_184030| [ 6.12200e-01 -8.79955e-01 -1.86201e-01 -1.90943e+00]
21Feb13_184030| [ 3.40432e-01  1.02790e+00 -1.15314e+00 -1.40468e+00]
21Feb13_184030| [ 4.70886e-01 -8.98456e-01  2.17497e+00  1.29145e-01]
21Feb13_184030| [ 8.53325e-01  1.53881e+00  8.59108e-01  5.58786e-01]
21Feb13_184030| [-1.34194e+00 -8.61258e-01  4.02439e-01 -9.96468e-01]
21Feb13_184030| [-1.33269e+00  6.41410e-01 -5.15019e-02 -7.72709e-01]
21Feb13_184030| [-4.69262e-01  2.41285e-01 -1.26819e+00 -4.79252e-01]
21Feb13_184030| [-1.25819e+00 -2.15944e-01 -5.82515e-01 -3.71993e-01]
21Feb13_184030| [-2.08817e+00 -2.39077e-01  5.19126e-01 -6.39950e-02]
21Feb13_184030| [-2.16821e-01 -5.79153e-01 -1.25299e-01 -5.39553e-01]
21Feb13_184030| [ 6.63347e-01  2.32524e-01  3.53160e-01 -3.17821e-01]
21Feb13_184030| [ 1.10172e+00  3.34007e-01 -1.28144e+00 -9.99387e-01]
21Feb13_184030| [ 6.14747e-01  1.74699e-02 -2.53533e-01 -4.93268e-01]
21Feb13_184030| [-1.68123e-01 -3.75621e-02 -4.00563e-01 -1.06499e+00]
21Feb13_184030| [ 1.68917e+00  8.38239e-01 -2.68816e-02 -9.26705e-01]
21Feb13_184030| [ 8.16397e-01  1.47216e+00 -3.72165e-01  8.01488e-02]
21Feb13_184030| [-1.87213e-01  3.60063e-01  2.18543e-01  5.02950e-01]
21Feb13_184030| [ 7.33804e-01 -1.95159e-01 -1.82285e+00  5.14853e-01]
21Feb13_184030| [ 6.88558e-01 -1.07087e-01 -2.67856e+00 -1.83088e+00]
21Feb13_184030| [-2.26892e-01 -1.79768e+00  1.38529e+00 -1.06190e+00]
21Feb13_184030| [ 7.06417e-01 -3.75030e-01 -8.33602e-02  1.51313e-02]
21Feb13_184030| [ 4.07669e-01 -4.07600e-02  8.65359e-01 -6.48309e-01]
21Feb13_184030| [ 1.59318e+00  1.49862e+00 -1.22730e+00 -4.75797e-02]
21Feb13_184030| [ 2.23448e+00  5.81611e-01  9.70576e-01 -1.16943e+00]
21Feb13_184030| [ 1.27520e+00  1.46452e-01 -1.77996e+00 -3.68113e-01]
21Feb13_184030| [ 2.64911e-01  1.29363e+00 -7.55651e-01  1.31616e+00]
21Feb13_184030| [-3.15699e-01 -9.42947e-01  3.59613e-01  1.53691e+00]
21Feb13_184030| [-1.83237e+00 -2.82041e-01  1.15458e-01  9.14966e-01]
21Feb13_184030| [ 5.41912e-01  1.03547e+00  1.89459e-01 -3.11293e-01]
21Feb13_184030| [-8.48413e-01 -7.65092e-01  1.52671e+00  2.32680e+00]
21Feb13_184030| [-9.07727e-01  1.26484e+00  1.84065e-03  2.89181e-01]
21Feb13_184030| [-7.76721e-01  1.73275e+00 -2.00253e-01  5.13027e-01]
21Feb13_184030| [-3.14822e-01  6.65239e-01 -8.33827e-01 -9.31808e-01]
21Feb13_184030| [-1.06577e+00 -6.56160e-01  7.07962e-01 -7.41742e-01]
21Feb13_184030| [ 1.37495e+00 -9.98537e-01 -1.26291e-01  7.35705e-01]
21Feb13_184030| [-7.81532e-01  4.81725e-01  9.72613e-01  1.14711e+00]
21Feb13_184030| [ 1.39228e+00 -1.10795e+00  6.18742e-01 -8.23983e-01]
21Feb13_184030| [-1.21496e+00 -9.27339e-01  1.46112e+00 -1.58060e-01]
21Feb13_184030| [-1.47877e-01  3.00039e-01 -1.16124e-01 -2.49785e-01]
21Feb13_184030| [ 1.34618e+00 -4.10722e-01 -2.01150e+00 -2.75159e-01]
21Feb13_184030| [ 3.26027e-01 -2.31842e+00 -9.63079e-01  1.40506e+00]
21Feb13_184030| [ 2.37497e-01 -8.86651e-02 -8.09815e-03 -2.75301e-01]
21Feb13_184030| [-9.43558e-01  3.27714e-02  1.37072e+00 -6.87180e-01]
21Feb13_184030| [-2.73140e-01 -1.03409e+00  4.18114e-01  2.63792e+00]
21Feb13_184030| [-1.29274e+00  5.68486e-01 -3.70493e-01 -1.79609e+00]]
21Feb13_184030|-- Bias --
21Feb13_184030|[ 0.47797 -0.46841  0.80042  0.85704]
21Feb13_184030|Layer 1:
21Feb13_184030|-- Config --
21Feb13_184030|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_184030|-- Weights --
21Feb13_184030|[[-0.07388 -0.44630  0.00582 -0.38753  0.04666]
21Feb13_184030| [ 0.56150  0.18177  0.10598  0.12676 -0.22741]
21Feb13_184030| [ 0.36995 -0.63866  0.59360 -0.34067  0.28075]
21Feb13_184030| [-0.02730 -0.58961 -0.21658  0.00403  0.22317]]
21Feb13_184030|-- Bias --
21Feb13_184030|[ 0.60577  0.01906  0.49354 -0.12722 -0.48520]
21Feb13_184030|Layer 2:
21Feb13_184030|-- Config --
21Feb13_184030|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_184030|-- Weights --
21Feb13_184030|[[ 0.86200 -1.33193]
21Feb13_184030| [-2.22124  1.37832]
21Feb13_184030| [-0.02313 -0.06435]
21Feb13_184030| [ 0.48998 -0.56779]
21Feb13_184030| [-0.10810  0.00308]]
21Feb13_184030|-- Bias --
21Feb13_184030|[-0.07638  0.02979]
21Feb13_184030|Predicting the validation and test data with the Best final individual.
21Feb13_184037| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_184037|-----------  ------------------  --------------------  ----------
21Feb13_184037|Validation         36.87                  18            0.30267
21Feb13_184037|   Test            36.40                  18            0.00000
21Feb13_184037|-------------------- Test #14 --------------------
21Feb13_184037|Best final individual weights
21Feb13_184037|Individual:
21Feb13_184037|-- Constant hidden layers --
21Feb13_184037|False
21Feb13_184037|Layer 0:
21Feb13_184037|-- Config --
21Feb13_184037|{'name': 'Hidden0', 'trainable': True, 'batch_input_shape': [None, 57], 'dtype': 'float32', 'units': 4, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_184037|-- Weights --
21Feb13_184037|[[-1.87472e-01 -1.88423e+00 -9.87479e-02 -4.31576e-01]
21Feb13_184037| [ 7.47578e-01 -8.61812e-01 -1.03859e+00  6.81397e-02]
21Feb13_184037| [-1.04232e+00  1.71195e+00 -4.16856e-01 -4.98514e-01]
21Feb13_184037| [ 1.35466e+00 -6.63542e-01  7.24879e-01  2.25979e-02]
21Feb13_184037| [ 2.16981e-01 -2.10882e+00 -1.46954e+00 -6.08573e-01]
21Feb13_184037| [ 6.47638e-02  1.08814e+00  6.86203e-02  9.30175e-01]
21Feb13_184037| [-2.44488e+00  1.55556e+00  1.90865e-01  1.59360e-01]
21Feb13_184037| [-6.06958e-01 -1.30643e-01  7.80295e-01  1.68866e+00]
21Feb13_184037| [ 7.24409e-01 -1.27327e+00 -2.36592e-02 -7.70925e-01]
21Feb13_184037| [ 8.20815e-01  1.41478e-02  1.57561e+00  3.89599e-01]
21Feb13_184037| [ 5.19426e-01  7.54468e-01 -2.58818e-02 -5.31621e-01]
21Feb13_184037| [ 1.59397e+00  1.31399e+00  4.31820e-02  4.73847e-01]
21Feb13_184037| [ 6.12200e-01 -8.79955e-01 -1.86201e-01 -1.90943e+00]
21Feb13_184037| [ 3.40432e-01  1.02790e+00 -1.15314e+00 -1.40468e+00]
21Feb13_184037| [ 4.70886e-01 -8.98456e-01  2.17497e+00  1.29145e-01]
21Feb13_184037| [ 8.53325e-01  1.53881e+00  8.59108e-01  5.58786e-01]
21Feb13_184037| [-1.34194e+00 -8.61258e-01  4.02439e-01 -9.96468e-01]
21Feb13_184037| [-1.33269e+00  6.41410e-01 -5.15019e-02 -7.72709e-01]
21Feb13_184037| [-4.69262e-01  2.41285e-01 -1.26819e+00 -4.79252e-01]
21Feb13_184037| [-1.25819e+00 -2.15944e-01 -5.82515e-01 -3.71993e-01]
21Feb13_184037| [-2.08817e+00 -2.39077e-01  5.19126e-01 -6.39950e-02]
21Feb13_184037| [-2.16821e-01 -5.79153e-01 -1.25299e-01 -5.39553e-01]
21Feb13_184037| [ 6.63347e-01  2.32524e-01  3.53160e-01 -3.17821e-01]
21Feb13_184037| [ 1.10172e+00  3.34007e-01 -1.28144e+00 -9.99387e-01]
21Feb13_184037| [ 6.14747e-01  1.74699e-02 -2.53533e-01 -4.93268e-01]
21Feb13_184037| [-1.68123e-01 -3.75621e-02 -4.00563e-01 -1.06499e+00]
21Feb13_184037| [ 1.68917e+00  8.38239e-01 -2.68816e-02 -9.26705e-01]
21Feb13_184037| [ 8.16397e-01  1.47216e+00 -3.72165e-01  8.01488e-02]
21Feb13_184037| [-1.87213e-01  3.60063e-01  2.18543e-01  5.02950e-01]
21Feb13_184037| [ 7.33804e-01 -1.95159e-01 -1.82285e+00  5.14853e-01]
21Feb13_184037| [ 6.88558e-01 -1.07087e-01 -2.67856e+00 -1.83088e+00]
21Feb13_184037| [-2.26892e-01 -1.79768e+00  1.38529e+00 -1.06190e+00]
21Feb13_184037| [ 7.06417e-01 -3.75030e-01 -8.33602e-02  1.51313e-02]
21Feb13_184037| [ 4.07669e-01 -4.07600e-02  8.65359e-01 -6.48309e-01]
21Feb13_184037| [ 1.59318e+00  1.49862e+00 -1.22730e+00 -4.75797e-02]
21Feb13_184037| [ 2.23448e+00  5.81611e-01  9.70576e-01 -1.16943e+00]
21Feb13_184037| [ 1.27520e+00  1.46452e-01 -1.77996e+00 -3.68113e-01]
21Feb13_184037| [ 2.64911e-01  1.29363e+00 -7.55651e-01  1.31616e+00]
21Feb13_184037| [-3.15699e-01 -9.42947e-01  3.59613e-01  1.53691e+00]
21Feb13_184037| [-1.83237e+00 -2.82041e-01  1.15458e-01  9.14966e-01]
21Feb13_184037| [ 5.41912e-01  1.03547e+00  1.89459e-01 -3.11293e-01]
21Feb13_184037| [-8.48413e-01 -7.65092e-01  1.52671e+00  2.32680e+00]
21Feb13_184037| [-9.07727e-01  1.26484e+00  1.84065e-03  2.89181e-01]
21Feb13_184037| [-7.76721e-01  1.73275e+00 -2.00253e-01  5.13027e-01]
21Feb13_184037| [-3.14822e-01  6.65239e-01 -8.33827e-01 -9.31808e-01]
21Feb13_184037| [-1.06577e+00 -6.56160e-01  7.07962e-01 -7.41742e-01]
21Feb13_184037| [ 1.37495e+00 -9.98537e-01 -1.26291e-01  7.35705e-01]
21Feb13_184037| [-7.81532e-01  4.81725e-01  9.72613e-01  1.14711e+00]
21Feb13_184037| [ 1.39228e+00 -1.10795e+00  6.18742e-01 -8.23983e-01]
21Feb13_184037| [-1.21496e+00 -9.27339e-01  1.46112e+00 -1.58060e-01]
21Feb13_184037| [-1.47877e-01  3.00039e-01 -1.16124e-01 -2.49785e-01]
21Feb13_184037| [ 1.34618e+00 -4.10722e-01 -2.01150e+00 -2.75159e-01]
21Feb13_184037| [ 3.26027e-01 -2.31842e+00 -9.63079e-01  1.40506e+00]
21Feb13_184037| [ 2.37497e-01 -8.86651e-02 -8.09815e-03 -2.75301e-01]
21Feb13_184037| [-9.43558e-01  3.27714e-02  1.37072e+00 -6.87180e-01]
21Feb13_184037| [-2.73140e-01 -1.03409e+00  4.18114e-01  2.63792e+00]
21Feb13_184037| [-1.29274e+00  5.68486e-01 -3.70493e-01 -1.79609e+00]]
21Feb13_184037|-- Bias --
21Feb13_184037|[ 0.47797 -0.46841  0.80042  0.85704]
21Feb13_184037|Layer 1:
21Feb13_184037|-- Config --
21Feb13_184037|{'name': 'Hidden2', 'trainable': True, 'batch_input_shape': [None, 4], 'dtype': 'float32', 'units': 5, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_184037|-- Weights --
21Feb13_184037|[[-0.07388 -0.44630  0.00582 -0.38753  0.04666]
21Feb13_184037| [ 0.56150  0.18177  0.10598  0.12676 -0.22741]
21Feb13_184037| [ 0.36995 -0.63866  0.59360 -0.34067  0.28075]
21Feb13_184037| [-0.02730 -0.58961 -0.21658  0.00403  0.22317]]
21Feb13_184037|-- Bias --
21Feb13_184037|[ 0.60577  0.01906  0.49354 -0.12722 -0.48520]
21Feb13_184037|Layer 2:
21Feb13_184037|-- Config --
21Feb13_184037|{'name': 'OutputLayer', 'trainable': True, 'batch_input_shape': [None, 5], 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
21Feb13_184037|-- Weights --
21Feb13_184037|[[ 0.86200 -1.33193]
21Feb13_184037| [-2.22124  1.37832]
21Feb13_184037| [-0.02313 -0.06435]
21Feb13_184037| [ 0.48998 -0.56779]
21Feb13_184037| [-0.10810  0.00308]]
21Feb13_184037|-- Bias --
21Feb13_184037|[-0.07638  0.02979]
21Feb13_184037|Predicting the validation and test data with the Best final individual.
21Feb13_184045| Partition    Accuracy error %    Neuron/layer score    F2 score
21Feb13_184045|-----------  ------------------  --------------------  ----------
21Feb13_184045|Validation         41.83                  18            0.35746
21Feb13_184045|   Test            35.10                  18            0.05879
