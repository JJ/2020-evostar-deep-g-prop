\documentclass[runningheads]{llncs}
%
\usepackage{graphics, graphicx, float}
\usepackage{algpseudocode,algorithm}
\usepackage{hyperref}
\def\algorithmautorefname{Algorithm}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{xstring}
\usepackage[nointegrals]{wasysym}
\usepackage{MnSymbol}
\usepackage{booktabs} % For formal tables
\graphicspath{ {../images/} }

\definecolor{NavyBlue}{HTML}{000080}
\definecolor{Magenta}{HTML}{FF00FF}
\definecolor{Orange}{HTML}{FFA500}
\definecolor{CornflowerBlue}{HTML}{6495ED}
\definecolor{YellowGreen}{HTML}{9ACD32}
\definecolor{Gray}{HTML}{BEBEBE}
\definecolor{Yellow}{HTML}{FFFF00}
\definecolor{GreenYellow}{HTML}{ADFF2F}
\definecolor{ForestGreen}{HTML}{228B22}
\definecolor{Lavender}{HTML}{FFC0CB}
\definecolor{SkyBlue}{HTML}{87CEEB}
\definecolor{NavyBlue}{HTML}{000080}
\definecolor{Goldenrod}{HTML}{DDF700}
\definecolor{VioletRed}{HTML}{D02090}
\definecolor{CornflowerBlue}{HTML}{6495ED}
\definecolor{LimeGreen}{HTML}{32CD32}


% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
% \renewcommand\UrlFont{\color{blue}\rmfamily}

\begin{document}
%
\title{}
%
%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{First Author\inst{1}\orcidID{0000-1111-2222-3333} \and
Second Author\inst{2,3}\orcidID{1111-2222-3333-4444} \and
Third Author\inst{3}\orcidID{2222--3333-4444-5555}}
%
\authorrunning{F. Author et al.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{Princeton University, Princeton NJ 08544, USA \and
Springer Heidelberg, Tiergartenstr. 17, 69121 Heidelberg, Germany
\email{lncs@springer.com}\\
\url{http://www.springer.com/gp/computer-science/lncs} \and
ABC Institute, Rupert-Karls-University Heidelberg, Heidelberg, Germany\\
\email{\{abc,lncs\}@uni-heidelberg.de}}
%
\maketitle              % typeset the header of the contribution

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}

In order to solve classification problems using artificial neural
networks (ANN), it is of great importance the optimization of the
network architecture. Evolutionary neural networks provide an
alternative for this task of designing the neural network, i.e. the
number of layers, number of neurons per layer and the weights of the
ANN. This is not a new challenge; as a matter of fact a number of
methods were proposed during the early years of this century,
including G-Prop, a hybrid neurogenetic algorithm that optimized
initial weights and the number of layers of multilayer perceptrons for
different kind of tasks. Using the general concept of this algorithm
as a baseline, we have rewritten the method using off-the-shelf tools
and libraries; modern testing and deployment tools have been also
employed. On top of that algorithm, we have added a ``deep'' component
by being able not only to evolve the number of neurons, but also the
number of layers in the neural net. In this paper we show how this has
been achieved using the new Deep-G-Prop framework, which we present
here for the first time, and how this new framewok is able to beat the
previous instance in accuracy, with very competitive running times.

\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

Using artificial neural networks (ANN) requires establishing the
structure in layers and connections between them, the parameters (such
as initial weights) and a set of learning constants. This is still
true for deep learning architectures \cite{goodfellow,nielsen}, where
a design parameter is added: the number of layers in the architecture,
every one with its own set of parameters, like the number of neurons
in every layer.

Evolutionary neural networks are an efficient way of searching for the
architecture and the weights of the ANN, and this was proved
repeatedly for {\em shallow} architectures (with a single hidden
layer) since late in the previous century
\cite{CastilloNPL,stanley2002evolving}. However, in most cases design
of the structure and conectivities of the different layers, as
indicated by \cite{miikkulainen2019evolving}, is still mostly done by
hand. This is mainly due to the above mentioned fact that search
spaces are huge, so using rules of thumb (such as the ones mentioned
in \cite{qolomany2017parameters} of using certain formulas to set the
number of layers) to decide on those parameters
are a way of fixing part of the search space, letting the deep
learning algorithm themselves figure out the weights, whose
optimization, in these cases, is able to cover big spans of the search
space.

We can also, however, fix a part of the architecture, choosing a
multilayer perceptron trained with backpropagation, whose initial
weights as well as biases evolve using an evoltuionary algorithm. This
algorithm was called (\emph{G-Prop} (as in Genetic Back-Propatagion)
and was originally presented in \cite{castilloNC,CastilloNPL}. This
method leverages the capabilities of two classes of algorithms: the
ability of EA to find a solution close to the global optimum, and the
ability of the back-propagation algorithm (BP) to tune a solution and
reach the nearest local minimum by means of local search from the
solution found by the EA.

This initial G-Prop algorithm was limited, first, by the fact that
most of it had to be programmed from scratch, since there were few (if
any) off-the-shelf software that could do this kind of task; it
additionally, available computational capability limited the size of
the search space; this was limited further by limiting evolution to
single-layer multilayer perceptrons. The aim of this paper is to
present an algorithm that searches over the initial weights, number of
hidden layers and hidden layer sizes of a MLP, based on a EA and
QuickPropagation, a version of BackPropagation. % Is this true? What
                                % version of backpropagation are you
                                % using? - JJ

The remainder of this paper is structured as follows: 
section \ref{sec:soa} makes a short overview of the methods to design ANN.
In section \ref{method} it is fully described the proposed model.
Section \ref{sec:res} describes the results obtained, 
followed by a brief conclusion in Section \ref{sec:conclus}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{State of the Art}
\label{soa}

% This contains a very good
% review. https://www.sciencedirect.com/science/article/pii/S0925231200003027?casa_token=LZtZakZguVsAAAAA:iQNvGVO5fAQO6ED-pnBhQ5Ab-ZuYP7tIdFcpBurr9hdCzNnQAKwwKUoaY6_fEbiQx5fPiktf
Searching the parameter space of neural networks, including deep
learning algorithms, has been a problem that has been traditionally
approached in a number of ways. {\em Incremental algorithms}, in
general, will depart from a specific architecture, number of layers
and elements in every layer, and offer a series of heuristic
procedures to add/eliminate layers and/or hidden-layer neurons in
those layers. This was, for a certain amount of time, the preferred
way of doing this kind of thing, according to classical reviews such
as the one by Alpaydim \cite{Alpaydim}. However, simultaneously a
series of evolutionary heuristics were starting to be applied for the
same purpose, as revealed by Balakrishnan and Honavar's review
\cite{balakrishnan95:EDNA}. This taxonomy classifies evolutionary
design of the architecture of neural nets along three different axes
(plus one for application domain): genotype representation, network
topology, and a third axes that includes basically everything else,
``variables of evolution''.

A more precise classification of evolved neural architectures would include, from our point of
view: \begin{itemize}
  \item Fixed or variable architecture. Irrespective of the kind of
    data structured used to represent it, what is relevant is if that
    representation allows for a variation of the architectural
    parameters, that is, adding or eliminating new nodes, layers, or
    in general nodes and edges in a graph representation of the
    architecture.
  \item Articulation of the neural learning method. There is a whole
    range of possibilities, from letting the evolutionary process set
    all weights and other parameters, to using learning process just
    to find the success rate, with additional possibilities like
    evaluating success {\em before applying learning} (to take
    advantage of the Baldwin effect \cite{castillo-2006}) to applying
    a few cycles of learning that will become part of the codified
    solution.
  \item How lack of determination of the fitness is taken into account
    in evolution. Either from the fact that an stochastic algorithm is
    used to train the neural net before evaluating fitness, or the
    fact that the data set might not be totally fixed but subject to
    randomness, the fitness of a neural net cannot be pinned down to a
    single, crisp, number. This randomness in the fitness can be taken
    into account during the selection phase
    \cite{DBLP:conf/ijcci/MereloLFGCCRMG15}, or not.

% Another good review: miikkulainen2019evolving

\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Proposed Method}
\label{method}

The general algorithm will proceed like the \autoref{alg:ga} shows.

\begin{algorithm}
  \caption{Genetic Algorithm loop}\label{alg:ga}
  \begin{algorithmic}[1]
    \State \textit{evaluate initial populatialgoritmoon}
    \While{\textit{max fit is less than ideal and there are generations left}}
    \If{\textit{max fit hasn't improved in some generations}}
    \State \textit{Stop algorithm}
    \EndIf
    \State \textit{select the offspring from the best population individuals}
    \State \textit{apply crossover to the offspring}
    \State \textit{apply mutations to the offspring}
    \State \textit{replace the worst population individuals with the modified offspring}
    \EndWhile
  \end{algorithmic}
\end{algorithm}

This is a canonical evolutionary algorithm. The key of the algorithm is
in the different parts used, that extend and enhance those used by the
original G-Prop. \begin{itemize}

  \item The {\em crossover} function will swap the ``neurons'' together with
    their connections. Main difference with respect to original G-Prop is that,
    in this case, there can be several hidden layers, so the connections might
    be either to output or to another layers. The crossover only ocurrs when
    the two models selected for it have the same structure (same number of
    layers ans neurons per layers).

  \item There are several kinds of {\em mutation} operators: (initial) weights,
    biases, as well as changing the number of neurons and/or
    layers. The neuron will be added last in the randomly selected layer,
    and it will be eliminated in the same way. Since the actual position of the
    neurons is arbitrary, it does not really matter where the neuron
    is added or eliminated. The layer add/eliminate mutator is the
    main difference with respect to G-Prop, which used only one
    layer. In this case, only the last hidden layer can be eliminated. When a
    layer is eliminated, the weights from the previous layer to the eliminated
    one are kept, adding randomly generated weights and biases if the output
    layer (newly connected with this previous layer) have more ``neurons'' than
    the recently deleted layer. When adding a new hidden layer, the connections
    between the last hidden layer and the output layer are recicled, and the
    connections between the newly created layer and the output layer are
    calculated randomly (running simmilar fix as when we delete the layer).
\end{itemize}

We need the fitness function to exert parsimony pressure, which is why
we take into account not only the testing values reached after
training, but also the overal size of the network. This will follow
the Equation \ref{eq:hidden-score}:

\begin{figure}
    \centering
    \caption{
        DeepGProp NN model score equation.
    }
    \label{eq:hidden-score}
    \begin{equation}
        score = (\sum_{i=0}^{nhl} nu_{i}) \times nhl
    \end{equation}
\end{figure}

Being $nhl$ the number of hidden layers and $nu_{i}$ the number
of neurons for the layer $i$. So in summary, the score will be the
global number of neurons multiplied by the number of hidden layers.

The whole code for this has been released under a free license in
GitHub. % Add URL later.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Results}
\label{sec:res}

% Something should be said about the experimental setup.

All the results found in this sections related with DeepGProp
\cite{deep-g-prop} where obtained in a laptop with the specs shown in the
\autoref{tab:setup}. The OS installed in the laptop is GNU/Linux, using the
distribution ArchLinux (kernel version \texttt{5.9.2-arch1-1}).

\begin{table}[]
  \centering
  \caption{DeepGProp results laptop specs.}
  \label{tab:setup}
  \begin{tabular}{|l|l|}
  \hline
    Spec & Value                                             \\ \hline
    CPU  & Intel(R) Core(TM) i7-3612QM CPU 2.10GHz (8 cores) \\ \hline
    MEM  & 6GB (2+4) DDR3                                    \\ \hline
  \end{tabular}
\end{table}

% Also about the progression of the experiments: first a single layer,
% then more layers.

We followed a progression path of increasing complexity in terms of models
execution. First we trained a clasic multilayer perceptron with a fixed number
of layers and neurons per layer, modifying the hidden layer weights and biases
for some of them. The second step was to replicate the method used in GProp
\cite{g-prop}: % [pedro]  it makes no sense including that citation that takes you to the paper in the journal web page. Instead, we should cite   \cite{castilloNC,CastilloNPL} 
models with one hidden layer and a random variable number of
neurons for it. For the last case, we evolved the models changing the number of
hidden layers and neurons per layer.

In these results, we will try to use the same metrics as the ones
proposed in GProp. We are going to use Equation
\ref{eq:hidden-score} as fitness score, where $nhl$ is the number of
hidden layers and $nu_{i}$ the number of neurons in layer $i$; what we
will try is to minimize the number of layers, and then of neurons in
every layer.

% El porcentaje de error (en Inglés \emph{accuracy error}) viene dado por el
% número de ejemplos bien clasificados dividido entre el número de ejemplos
% totales. Es la medida principal utilizada en GProp\cite{g-prop} para la
% comparación con otros algoritmos, intentando minimizar ésta. Tanto en la
% publicación como en este trabajo también se busca minimizar el número de
% neuronas del perceptrón multicapa para así obtener una solución más sencilla y
% óptima. Dado que no solo se realizan pruebas con una sola capa oculta, la
% puntuación de las neuronas viene dada por la expresión de la
% \autoref{eq:hidden-score}, siendo $nhl$ el número de capas ocultas que tiene el
% modelo y $nu_{i}$ el número de neuronas de la capa $i$. Con esta operación se
% busca primero minimizar el número de capas y después el número de neuronas de
% cada capa.

% Notas de la traducción:
% Para los lectores de estos papers la formula de la exactitud de un clasificador es conocida.
% Cambié lo de sencillo y óptimo por conceptos más utilizados en el área. - M

We compare against other classification algorithms using accuracy as a
performance metric, as was used in the GProp paper \cite{g-prop}. We hope to
increase the generalization of the model and avoid overfitting by reducing the
network's complexity, we try to accomplish this by reducing the
overall number of neurons in the MLP; this was also the intention of the GProp
authors. Because we test with one or more hidden layers, we obtain the network's
score using the expression \autoref{eq:hidden-score}, where $nhl$ is the model's
number of hidden layers and $nu_{i}$ is the number of neurons in layer {i}. With
this expression, we aim to minimize the number of layers first, and then the number of
neurons per layer.


\begin{equation}
  score = (\sum_{i=0}^{nhl} nu_{i}) \times nhl
\end{equation}


% La métrica F2 score es una definida como la media armónica ponderada entre
% precisión (\emph{precision})\footnote{Fracción de instancias que son de la
% clase relevante. Esto es: el número de ejemplos que pertenecen a la clase
% relevante dividido por el número total de ejemplos que se han predicho.} y
% sensibilidad (\emph{recall})\footnote{Fracción de instancias de la clase
% relevante que se han clasificado bien.}. Por un lado, si los datos están
% desbalanceados la precisión puede salir alta pero la sensibilidad saldrá baja.
% Usando cómo parámetro de ponderación el número dos, le damos más importancia a
% la sensibilidad, para evitar lo antes comentado.


We selected the following parameters for the network:

\begin{itemize}
\item Activation function: We selected a (\emph{rectified linear unit}) ReLU 
      activation function for hidden layers and Softmax for the output layer.
\item Optimization algorithm: We used the Stochastic Gradient Descend 
      (SGD) backpropagation algorithm with a learning rate value of \texttt{0.01}.
\item Loss function: We selected the cross-entropy loss function.
\end{itemize}


% En cuanto al entrenamiento y propagación hacia atrás de los modelos se han
% utilizado los siguientes parámetros:

% \begin{itemize}

%     \item Función de activación: método aplicado a la sumatoria de los valores
%     de activación de la capa anterior por sus pesos mas un sesgo. La salida de
%     esta función define la activación de la neurona actual. Para este parámetro
%     se ha utilizado la función de activación ReLU (\emph{rectified linear
%     unit}) que cumple la siguiente función dado un valor $x$ la activación de
%     la neurona viene dada por $max(x, 0)$. Para la capa de salida, sin embargo,
%     se ha utilizado la función Softmax que configura las neuronas de salida de
%     manera que todas las activaciones suman 1 y se sitúen en el rango
%     $[0.0, 1.0]$.

%     \item Optimizador: algoritmo utilizado para entrenar la red neuronal con la
%     propagación hacia atrás buscando la minimización de la función de pérdida.
%     Como optimizador se ha utilizado SGD, gradiente descendiente estocástico
%     del Inglés, que utilizando pequeños grupos de datos (\emph{batches})
%     calcula las modificaciones necesarias en el conjunto de pesos y sesgos
%     global obteniendo finalmente el gradiente que se aplicará a éstos para así
%     mejorar las capacidades de clasificación del modelo con respecto a los
%     datos de entrenamiento.

%     \item Función de pérdida: también conocida como función de costo o función
%     objetivo es la cuál se quiere minimizar, es decir, obtener una mejor
%     predictibilidad de los datos por parte del modelo. Se ha elegido como
%     función de pérdida la entropía cruzada entre clases partiendo de la función
%     de activación de la última capa (softmax).

% \end{itemize}


When referring to a certain number of layers, we will be talking about hidden
layers because the input and output layers are fixed depending on the problem.
To compare our results against the GProp algorithm we mentioned earlier in
section \autoref{chap:introduction}, we selected the Proben1 \cite{Proben1}
dataset and other classification datasets found in the UCI \cite{uci}
repository. Results shown are the mean of five runs with different random
generator seeds ( 
%  \code{2017725297}, \code{3842001146}, \code{788305541},
%\code{1367677890}, and \code{3074644809}. We obtained these seeds using the
%\code{getrandbits} function from the \code{random} 
module found in Python's
standard library.

% Siempre que se refiera a un número de capas concreto se estará hablando de las
% capas ocultas, dado que la tanto la capa de entrada como la de salida son
% necesarias y de estructura fija.

% Para las pruebas se han utilizado tanto algunos conjuntos de datos de
% Proben1\cite{Proben1}\footnote{Base de datos dedicada a comparar redes
% neuronales} como otros conjuntos de datos conocidos (por ejemplo,
% \emph{Spambase} encontrados en la web de UCI\cite{uci}) para poder comparar
% los resultados obtenidos con GProp ya mencionado en la
% introducción\autoref{chap:introduction}.

% Los datos mostrados en la mayoría de las tablas constituyen la media de cinco
% ejecuciones realizadas con semillas distintas. Se han utilizado las semillas:
% \code{2017725297}, \code{3842001146}, \code{788305541}, \code{1367677890} y
% \code{3074644809}. Éstas han sido obtenidas aleatoriamente haciendo uso de la
% función \code{getrandbits} del módulo \code{random} de Python.

% \begin{minted}[]{python}
% from random import getrandbits
% for _ in range(5):
%     print(getrandbits(32))
% \end{minted}

% %
% % no structure modification
% %

% \section{Evolución de población sin modificación de estructura}

% En esta sección se han realizado pruebas con distintas estructuras fijas. En
% concreto se va a comparar la diferencia entre evolucionar modelos con y sin
% modificar los pesos contenidos en las capas ocultas. Se han elegido los valores
% de número de neuronas y número de capas manualmente.

% Comprobando las dos primeras tablas podemos observar datos muy similares para
% el porcentaje de error obtenido en el problema \emph{cancer1}\cite{uci}. Obteniendo
% mejor resultado el algoritmo sin modificar las capas internas
% (\autoref{tab:fixed-7-1-const-can1}) con un $2.86\%$ de error frente al
% $3.09\%$ (en \autoref{tab:fixed-7-1-noconst-can1}) de la población con capas
% internas modificadas podemos suponer que dada la pequeña cantidad de individuos
% y generaciones con las que se ha ejecutado el algoritmo, no da pie a mejorar el
% resultado demasiado. A parte vemos en la \autoref{tab:fixed-7-1-inicial-can1}
% que de base, la distribución uniforme utilizada para generar los genes de los
% individuos llega a dar resultados muy buenos. Otra razón de esta discrepancia,
% simple pero importante, es cómo se ordenan los datos dentro de un mismo
% problema.  % Se refiere a los individuos en la población o en la tabla?? - M
% Entonces, se han realizado pruebas con poblaciones e individuos más
% grandes para poder ver que efectivamente se mejora el resultado si se mutan las
% capas ocultas. También se prueba con otra partición del mismo problema para ver
% cómo efectivamente ahí si mejora.

\subsection{Evolution of Neworks with a Fixed Architecture}

In this section, we compare the evolution of networks with and without weight
evolution. For this, we present the results of comparing the evolution networks
with fixed architectures, in which we manually chose the number of layers and
neurons in them. In this case, what we try to establish is a new
baseline for results, while also trying to reproduce the originally
published results. Since more than a dozen years have passed, we were
also interested in finding out the speed with which the whole
operation could be performed, despite being Python a priori a slower
language than C++, which was the original language.

In the first two tables, we can see very similar results % similar to
                                % what? - JJ
regarding accuracy for
the \emph{cancer1} dataset \cite{uci}, with the network with fixed hidden layers
(\autoref{tab:fixed-7-1-const-can1}) obtaining the best result with an accuracy
of $2.86\%$ against the $3.09\%$ (in \autoref{tab:fixed-7-1-noconst-can1}) from
the population with modified hidden layers. We can suppose that this result is
because of a low number of generations and having a small population. Moreover,
we can see in \autoref{tab:fixed-7-1-inicial-can1} that the uniform
distribution used to generate the population produces good results from the
beginning. Another reason for this discrepancy, which is basic but important, is
how the algorithm sorts the data within a problem. Because of that, we tested
with larger populations and individuals to see if results are effectively
improved when hidden layers are mutated. We also tested with another partition
of the same dataset to further prove this intuition.

% You need to say how many runs were made to reach these values. Was
% it a single run? If so, we need to make more runs and compute
% averages over them - JJ
 \begin{table}
     \centering
     \caption{
%         Resultados de test del mejor individuo final tras 10 generaciones con
%         20 individuos iniciales y 7 neuronas por individuo haciendo operaciones
%         sobre las capas internas para el problema \emph{cancer1}.
These results were obtained by the best individual after ten generations, 
with an initial population of twenty individuals and initially seven neurons each. 
The evolution optimized the hidden layers of networks classifying the \emph{cancer1} dataset.}
     \label{tab:fixed-7-1-noconst-can1}
     \begin{tabular}{rlll}
         \textbf{Measure}   & \textbf{Accuracy error \%} & \textbf{\# neurons} & \textbf{F2 score} \\
         \hline
        \textbf{Mean}      & $3.09\ \pm\ 0.58$      & $6.80\ \pm\ 0.40$       & $0.94739\ \pm\ 0.01944$ \\
         \textbf{Max}       & $4.00$                 & $7.00$                  & $0.97473$               \\
         \textbf{Min}       & $2.29$                 & $6.00$                  & $0.91912$               \\
     \end{tabular}
 \end{table}

 \begin{table}
     \centering
     \caption{
%         Resultados de test del mejor individuo final tras 10 generaciones con
%         20 individuos iniciales y 7 neuronas por individuo sin hacer
%         operaciones sobre las capas internas para el problema \emph{cancer1}.
These results were obtained by the best individual after ten generations, with
an initial population of twenty individuals and initially seven
neurons each. % These parameters need to be justified. 20 individuals
              % do not look like a lot. Is there a way to run the
              % experiments again? - JJ
This evolution did not optimize the hidden layers, again for networks
classifying the \emph{cancer1} dataset.}
     \label{tab:fixed-7-1-const-can1}
     \begin{tabular}{rlll}
        \textbf{Measure}   & \textbf{Accuracy error \%} & \textbf{\# neurons} & \textbf{F2 score} \\
         \hline
         \textbf{Mean}      & $2.86\ \pm\ 0.63$      & $6.80\ \pm\ 0.40$       & $0.95103\ \pm\ 0.02021$ \\
         \textbf{Max}       & $3.43$                 & $7.00$                  & $0.98921$               \\
         \textbf{Min}       & $1.71$                 & $6.00$                  & $0.93407$               \\
     \end{tabular}
 \end{table}

 \begin{table}
     \centering
     \caption{
%         Resultados de test del mejor individuo inicial en una población de 20
%         individuos con 7 neuronas en 1 capa oculta cada uno para el problema
%         \emph{cancer1}.
These results were obtained by the best individual after ten generations, with
an initial population of twenty individuals and initially seven neurons each, fixed to 
only one hidden layer. For networks classifying the \emph{cancer1} dataset.}
     \label{tab:fixed-7-1-inicial-can1}
     \begin{tabular}{rlll}
         \textbf{Measure}   & \textbf{Accuracy error \%} & \textbf{\# neurons} & \textbf{F2 score} \\
         \hline
         \textbf{Mean}      & $3.20\ \pm\ 0.46$      & $6.80\ \pm\ 0.40$       & $0.94226\ \pm\ 0.01156$ \\
         \textbf{Max}       & $3.43$                 & $7.00$                  & $0.96364$               \\
         \textbf{Min}       & $2.29$                 & $6.00$                  & $0.93407$               \\
     \end{tabular}
 \end{table}

% En este experimento se ha ejecutado dos veces el algoritmo: una sin modificar
% los pesos ni cruzar las neuronas de las capas internas y otra al revés. Ahora
% sí observamos en la \autoref{tab:fixed-8-2-comp-can1} comprobamos una mejora
% considerable tanto en los valores de test y validación para el porcentaje de
% error.

In this experiment, we execute the algorithm two times: one without modifying
the weights nor crossing neurons in hidden layers, and the other with
modifications. Now, if we observe Table~\autoref{tab:fixed-8-2-comp-can1}, we
notice a considerable improvement in accuracy for both training and validation.

\begin{table}
    \centering
    \caption{
%         Resultados de validación y test del mejor individuo inicial en una
%         población de 50 individuos con 8 neuronas en cada una de las 2 capas
%         ocultas durante 20 generaciones para el problema \emph{cancer1}.
Validation and test results for the best individual from a population of 50,
configured with eight neurons in each of the two hidden layers, through 20
generations for the \emph{cancer1} dataset.}
     \label{tab:fixed-8-2-comp-can1}
     \begin{tabular}{rllll}
         \textbf{Hidden l.} & \textbf{Partition}  & \textbf{Accuracy error \%} & \textbf{Neuron/Layer score} & \textbf{F2 score} \\
         \hline
         \textbf{Constant}  & \textbf{Validation} & $0.57$                 &        $32$             &      $0.98765$ \\
                        & \textbf{Test}       & $2.86$                 &        $32$             &      $0.96014$ \\
         \textbf{Mutables}  & \textbf{Validation} & $0.00$                 &        $32$             &      $1.00000$ \\
                        & \textbf{Test}       & $2.29$                 &        $32$             &      $0.98566$ \\
     \end{tabular}
 \end{table}

% Por el contrario, si comparamos el primer ejemplo con los datos obtenidos para
% el problema \emph{cancer2}, parece que sí que mejora el algoritmo al no mantener
% constantes los pesos de la capa oculta (véanse las tablas
% \ref{tab:fixed-7-1-noconst-can2} y \ref{tab:fixed-7-1-const-can2}).

On the other hand, if we compare the first instance with the results for the
\emph{cancer2} dataset, it seems that the algorithm's accuracy improves while
not keeping the weights in the hidden layer fixed. See Tables
\ref{tab:fixed-7-1-noconst-can2} and \ref{tab:fixed-7-1-const-can2}).

 \begin{table}
     \centering
     \caption{
%         Resultados de test del mejor individuo final tras 10 generaciones con
%         20 individuos iniciales y 7 neuronas por individuo haciendo operaciones
%         sobre las capas internas para el problema \emph{cancer2}.
Test results for the best individual after ten generations with twenty initial
individuals and seven neurons per individual. In this case, the algorithm
operates over the hidden layers for the \emph{cancer2} dataset.
     }
     \label{tab:fixed-7-1-noconst-can2}
     \begin{tabular}{rlll}
         \textbf{Measure}   & \textbf{Accuracy error \%} & \textbf{\# neurons} & \textbf{F2 score} \\
         \hline
         \textbf{Mean}      & $1.94\ \pm\ 0.28$ & $6.80\ \pm\ 0.40$  & $0.98258\ \pm\ 0.00272$ \\
         \textbf{Max}       & $2.29$            & $7.00$             & $0.98432$               \\
         \textbf{Min}       & $1.71$            & $6.00$             & $0.97731$               \\
     \end{tabular}
 \end{table}

 \begin{table}
     \centering
     \caption{
%         Resultados de test del mejor individuo final tras 10 generaciones con
%         20 individuos iniciales y 7 neuronas por individuo sin hacer
%         operaciones sobre las capas internas para el problema \emph{cancer2}.
Test results for the \emph{cancer2} dataset, with the best individual after ten
generations with twenty initial individuals and seven neurons per individual. In
this case, the algorithm did not change the hidden layers.
     }
     \label{tab:fixed-7-1-const-can2}
     \begin{tabular}{rlll}
         \textbf{Measure}   & \textbf{Accuracy error \%} & \textbf{\# neurons} & \textbf{F2 score} \\
         \hline
         \textbf{Mean}      & $2.29\ \pm\ 0.36$ & $6.80\ \pm\ 0.40$  & $0.97943\ \pm\ 0.00339$ \\
         \textbf{Max}       & $2.86$            & $7.00$             & $0.98432$               \\
         \textbf{Min}       & $1.71$            & $6.00$             & $0.97561$               \\
     \end{tabular}
   \end{table}

% Se puede sacar en claro que generalmente al realizar pequeñas modificaciones en
% los modelos de perceptrones multicapa se obtienen mejores resultados que si no
% se hace. En las siguientes secciones se explorarán nuevas mutaciones más
% complejas ya modificando la estructura del perceptrón multicapa de generación
% en generación.

% \section{Evolución de población con modificación de número de neuronas:
% reproducción de resultados}

% En esta sección se compararán los anteriores resultados con similares obtenidos
% cambiando el número de neuronas de cada individuo a medida que avanzan las
% generaciones.

% En la \autoref{tab:gprop-deepgprop-cancer} podemos observar los resultados
% obtenidos tanto por \emph{G-Prop} como \emph{DeepGProp} para la siguiente
% configuración: población de 20 individuos, máximo de 10 generaciones, tamaño
% inicial de neuronas entre 2 y 20 y probabilidad de cruce de $0.5$. En general
% se ve mejor rendimiento para el algoritmo \emph{G-Prop} con un número de
% neuronas menor en todos los casos y mejores resultados de precisión en las
% particiones 1 y 2. Aun así, los datos son bastante similares y vemos una clara
% mejora por parte de \emph{DeepGProp} en la segunda partición. Se intuye que
% \emph{G-Prop} sortea mejor los mínimos locales que \emph{DeepGProp}.

% \begin{table}
%     \centering
%     \caption{
%         Comparación de los resultados obtenidos en los problemas de \emph{cancer}
%         por DeepGProp y GProp.
%     }
%     \label{tab:gprop-deepgprop-cancer}
%     \begin{tabular}{rllll}
%         \textbf{Partition} & \textbf{Algorithm} & \textbf{Accuracy error \%} & \textbf{\# neurons}      & \textbf{F2 score}           \\
%         \hline
%         \textbf{Cancer1}   & G-Prop         & $1.0\ \pm\ 0.5$        & $3.2\ \pm\ 0.8$     & $--$                    \\
%                        & DeepGProp      & $2.52\ \pm\ 0.28$      & $13.60\ \pm\ 6.02$  & $0.96668\ \pm\ 0.00670$ \\
%         \textbf{Cancer2}   & G-Prop         & $4.4\ \pm\ 0.4$        & $6.7\ \pm\ 2.3$     & $--$                    \\
%                        & DeepGProp      & $2.29\ \pm\ 0.00$      & $10.20\ \pm\ 4.58$  & $0.97943\ \pm\ 0.00260$ \\
%         \textbf{Cancer2}   & G-Prop         & $3.0\ \pm\ 0.7$        & $4.3\ \pm\ 1.7$     & $--$                    \\
%                        & DeepGProp      & $4.46\ \pm\ 0.43$      & $21.60\ \pm\ 17.83$ & $0.95952\ \pm\ 0.00285$ \\
%     \end{tabular}
% \end{table}

% Continuando con el problema \emph{DNA Helicases}\cite{dna-heliases}, igual que
% en los resultados anteriores, se ha obtenido la media de 5 ejecuciones con
% distintas semillas (ver inicio del \autoref{chap:analysis}). Observando los
% resultados de la \autoref{tab:gprop-deepgprop-miniheli} vemos una gran
% diferencia en todos los campos. La precisión alcanzada por \emph{DeepGProp} es
% inmensamente inferior a la que consigue \emph{G-Prop} ejecutando con el mismo
% máximo de generaciones. De forma similar, aunque se han aumentado las
% generaciones para la segunda prueba de 10 a 50, no cambia demasiado el
% resultado, quedando igualmente muy por encima de \emph{G-Prop}. Aunque en
% problemas con número de entradas pequeño parece que se desenvuelven de forma
% similar, al aumentar las características del problema se diferencian mucho el
% uno del otro.

% \begin{table}
%     \centering
%     \caption{
%         Comparación de los resultados obtenidos en los problemas de
%         \emph{Helicases} por DeepGProp y GProp.
%     }
%     \label{tab:gprop-deepgprop-miniheli}
%     \begin{tabular}{rllll}
%         \textbf{DNA Helicases} &    & \textbf{Accuracy error \%} & \textbf{\# neurons}     & \textbf{F2 score}\\
%         \hline
%         \textbf{G-Prop}    & 10 gen & $6\ \pm\ 3$            & $7.3\ \pm\ 3.9$     & $--$                    \\
%         \textbf{DeepGProp} & 10 gen & $25.67\ \pm\ 5.23$     & $11.80\ \pm\ 6.01$  & $0.70976\ \pm\ 0.07727$ \\
%                        & 50 gen & $21.00\ \pm\ 5.01$     & $15.00\ \pm\ 4.38$  & $0.72556\ \pm\ 0.06024$ \\
%     \end{tabular}
% \end{table}

% Aparte se aprecia claramente la diferencia entre los datos de validación
% (\autoref{tab:deepgprop-miniheli-validation}) y los de test comentados
% anteriormente. Está ocurriendo un sobre ajuste a los datos de validación muy
% grande de media. En el caso anterior del conjunto de \emph{cancer} no existe
% tal diferencia entre validación y test como existe para el programa \emph{DNA
% Helicases}. Se probará en la siguiente sección que con número variable de capas
% debería mejorar el resultado.

% \begin{table}
%     \centering
%     \caption{
%         Resultados de validación del mejor individuo final tras 10 y 50
%         generaciones respectivamente.
%     }
%     \label{tab:deepgprop-miniheli-validation}
%     \begin{tabular}{rlll}
%         \textbf{\# generations} & \textbf{Accuracy error \%} & \textbf{\# neurons} & \textbf{F2 score} \\
%         \hline
%         \textbf{10}             & $11.19\ \pm\ 1.36$ & $11.80\ \pm\ 6.01$ & $0.88280\ \pm\ 0.03664$ \\
%         \textbf{50}             & $2.71\ \pm\ 2.30$ & $15.00\ \pm\ 4.38$ & $0.98952\ \pm\ 0.00887$ \\
%     \end{tabular}
% \end{table}

% \section{Evolución de población con modificación de número de neuronas y capas}

% Siguiendo con los resultados obtenidos en la sección anterior, aquí se suma un
% nuevo operador que permite añadir o quitar capas en la última posición de las
% capas ocultas del modelo. Siendo cierto que se ve una mejora a los datos
% obtenidos en ejecuciones con una sola capa oculta, no se llega a alcanzar en
% ningún caso los resultados aportados por \emph{G-Prop}.

% Por ejemplo, viendo el problema de \emph{DNA Helicases}, en la
% \autoref{tab:gprop-deepgprop-miniheli-multihidden} (teniendo en cuenta que
% la puntuación de las capas ocultas se calcula como visto en
% \autoref{eq:hidden-score}) vemos una mejora ligera del resultado tras 50
% generaciones. Aún así, sigue siendo mejor de lejos \emph{G-Prop}.

% \begin{table}
%     \centering
%     \caption{
%         Comparación de los resultados obtenidos en los problemas de
%         \emph{Helicases} por DeepGProp y GProp.
%     }
%     \label{tab:gprop-deepgprop-miniheli-multihidden}
%     \begin{tabular}{rllll}
%         \textbf{Algorithm} &  & \textbf{Acc error \%} & \textbf{\# neurons/hidden layers}     & \textbf{F2 score}\\
%         \textbf{(\# layers)}& &                       & \textbf{score}                        &                   \\
%         \hline
%         \textbf{G-Prop (1)}       & 10 gen & $6\ \pm\ 3$        & $7.3\ \pm\ 3.9$     & $--$                    \\
%         \textbf{DeepGProp (1)}     & 10 gen & $25.67\ \pm\ 5.23$ & $11.80\ \pm\ 6.01$  & $0.70976\ \pm\ 0.07727$ \\
%                                    & 50 gen & $21.00\ \pm\ 5.01$ & $15.00\ \pm\ 4.38$  & $0.72556\ \pm\ 0.06024$ \\
%         \textbf{DeepGProp (>1)}    & 50 gen & $18.67\ \pm\ 2.45$ & $23.80\ \pm\ 24.25$ & $0.82569\ \pm\ 0.04718$ \\
%     \end{tabular}
% \end{table}

% Podemos recalcar que añadiéndole la posibilidad de utilizar número variable de
% capas ocultas, el algoritmo \emph{DeepGProp} generaliza mejor para el problema
% \emph{DNA Helicases}. Esto es observable en la tabla con los resultados de
% validación de esta última ejecución
% (\autoref{tab:gprop-deepgprop-miniheli-multihidden-validation}) dado que la
% diferencia entre porcentaje de error en el test y en la validación es más
% pequeña. También al ser superior el porcentaje conseguido en la validación para
% 50 generaciones notamos un menor sobre ajuste a los datos de validación.

% \begin{table}
%     \centering
%     \caption{
%         Resultados de validación del mejor individuo final tras 50
%         generaciones.
%     }
%     \label{tab:gprop-deepgprop-miniheli-multihidden-validation}
%     \begin{tabular}{rlll}
%         \textbf{Accuracy error \%} & \textbf{\# neurons} & \textbf{F2 score} \\
%         \hline
%         $8.13\ \pm\ 3.62$ & $23.80\ \pm\ 24.25$ & $0.88853\ \pm\ 0.06346$ \\
%     \end{tabular}
% \end{table}

% Tratando algún problema más complejo como \emph{spambase} se obtienen
% resultados malos (véase las tablas \ref{tab:spambase-onelayer} y
% \ref{tab:spambase-onelayer}). Tras lanzar multiples ejecuciones a partir de
% soluciones obtenidas por DeepGProp, parece que siempre se alcanza un mínimo
% local cuando la pérdida llega a $\approx\ 0.6$. Entonces el mejor resultado que
% obtiene es alrededor de $35\%$ de error. Para la primera tabla, los resultados
% se han obtenido lanzando el algoritmo con número de neuronas variable entre 2 y
% 20 y una capa oculta. La segunda prueba se ha realizado con número de capas
% ocultas variable y una población inicial con el rango $[2,50]$ de neuronas para
% cada capa oculta obtenida también aleatoriamente. Sería interesante realizar
% pruebas con el algoritmo G-prop con este tipo de problemas para compararlos.


% \begin{table}
%     \centering
%     \caption{
%         Comparación de los resultados obtenidos en el problema de
%         \emph{spambase} para las tres particiones. Algoritmo ejecutado con 1
%         capa fija.
%     }
%     \label{tab:spambase-onelayer}
%     \begin{tabular}{rllll}
%         \textbf{Partition} & \textbf{Accuracy error \%} & \textbf{\# neurons} & \textbf{F2 score} \\
%         \hline
%         \textbf{Spambase1}   & $36.80\ \pm\ 0.98$ & $10.80\ \pm\ 3.76$ & $0.03004\ \pm\ 0.04402$ \\
%         \textbf{Spambase2}   & $38.30\ \pm\ 0.88$ & $12.60\ \pm\ 2.87$ & $0.04019\ \pm\ 0.04078$ \\
%         \textbf{Spambase2}   & $37.64\ \pm\ 1.64$ & $16.40\ \pm\ 1.85$ & $0.05150\ \pm\ 0.06956$ \\
%     \end{tabular}
% \end{table}

% \begin{table}
%     \centering
%     \caption{
%         Comparación de los resultados obtenidos en el problema de
%         \emph{spambase} para las tres particiones. Algoritmo ejecutado con
%         múltiples capas variables.
%     }
%     \label{tab:spambase-onelayer}
%     \begin{tabular}{rllll}
%         \textbf{Partition} & \textbf{Accuracy error \%} & \textbf{\# neurons} & \textbf{F2 score} \\
%         \hline
%         \textbf{Spambase1}   & $41.46\ \pm\ 10.75$ & $17.80\ \pm\ 6.71$ & $0.30304\ \pm\ 0.37119$ \\
%         \textbf{Spambase2}   & $35.13\ \pm\ 4.94$ & $29.40\ \pm\ 20.16$ & $0.28133\ \pm\ 0.34343$ \\
%         \textbf{Spambase2}   & $40.07\ \pm\ 12.26$ & $31.00\ \pm\ 14.48$ & $0.32100\ \pm\ 0.39295$ \\
%     \end{tabular}
%   \end{table}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusions and future work}
\label{sec:conclus}

In this paper an approach to optimise the architecture (i.e. the initial weights, number of hidden layers and hidden layer sizes) of multilayer perceptrons with multiple layers using an EA has been proposed. % [pedro] tune this sentence to specify what has been developed
The proposed method is based on the ability of the EA to find a solution close to the global optimum, and the ability of the training algorithm to tune the solution and reach the nearest local minimum.

Obtained results show that the proposed evolutionary method obtains BLABLABLA % [pedro] please, finish this sentence explaining what has been obtained


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Acknowledgments}

The work is
supported by the so and so.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{splncs04}
\bibliography{geneura,deep-g-prop,gprop,gpropnpl} 

\end{document}
